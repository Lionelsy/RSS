<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 09 Nov 2024 00:26:14 +0800</lastBuildDate>
    <item>
      <title>Preemptive Holistic Collaborative System and Its Application in Road Transportation</title>
      <link>http://arxiv.org/abs/2411.01918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多现实世界系统（如制造过程、供应链和机器人系统）涉及多个独立实体，这些实体有不同的目标。&lt;h4&gt;目的&lt;/h4&gt;解决独立实体之间因无法准确预测和预判彼此行为而产生的潜在冲突。&lt;h4&gt;方法&lt;/h4&gt;提出预防性整体协作系统（PHCS）框架，促进独立实体之间的信息共享和协作规划。&lt;h4&gt;主要发现&lt;/h4&gt;将PHCS框架应用于道路运输，形成预防性整体协作道路运输系统（PHCRTS），通过共享驾驶意图和预先规划的轨迹来优化交通流和提高安全性。&lt;h4&gt;结论&lt;/h4&gt;在两车道合并场景中的模拟实验表明，PHCRTS将车辆时间延误减少了90%，交通容量增加了300%，并消除了事故。&lt;h4&gt;总结&lt;/h4&gt;PHCS框架为优化多独立实体复杂系统的性能和安全性提供了有前景的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Numerous real-world systems, including manufacturing processes, supplychains, and robotic systems, involve multiple independent entities with diverseobjectives. The potential for conflicts arises from the inability of theseentities to accurately predict and anticipate each other's actions. To addressthis challenge, we propose the Preemptive Holistic Collaborative System (PHCS)framework. By enabling information sharing and collaborative planning amongindependent entities, the PHCS facilitates the preemptive resolution ofpotential conflicts. We apply the PHCS framework to the specific context ofroad transportation, resulting in the Preemptive Holistic Collaborative RoadTransportation System (PHCRTS). This system leverages shared driving intentionsand pre-planned trajectories to optimize traffic flow and enhance safety.Simulation experiments in a two-lane merging scenario demonstrate theeffectiveness of PHCRTS, reducing vehicle time delays by 90%, increasingtraffic capacity by 300%, and eliminating accidents. The PHCS framework offersa promising approach to optimize the performance and safety of complex systemswith multiple independent entities.</description>
      <author>example@mail.com (Ting Peng, Yuan Li, Tao Li, Xiaoxue Xu, Xiang Dong, Yincai Cai)</author>
      <guid isPermaLink="false">2411.01918v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>High-pass Filter Periodogram: An Improved Power Spectral Density Estimator for Unevenly Sampled Data</title>
      <link>http://arxiv.org/abs/2411.02656v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的时间序列分析对于研究天文变量源至关重要，检测周期性和表征功率谱密度（PSD）是关键。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型高通滤波器（HPF）周期图，以减少不规则采样引入的噪声。&lt;h4&gt;方法&lt;/h4&gt;在计算周期图之前应用频率依赖的高通滤波器。&lt;h4&gt;主要发现&lt;/h4&gt;HPF方法在各种信号特征下提高了PSD估计和周期性检测的精度。&lt;h4&gt;结论&lt;/h4&gt;HPF周期图在困难的采样条件下改善了准确性和可靠性，是天文学及其他领域处理不规则采样数据的有价值的补充工具。&lt;h4&gt;总结&lt;/h4&gt;HPF周期图为时间序列分析提供了更稳健的解决方案，能够应对不均匀采样带来的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1088/1538-3873/ad8781&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate time series analysis is essential for studying variable astronomicalsources, where detecting periodicities and characterizing power spectraldensity (PSD) are crucial. The Lomb-Scargle periodogram, commonly used inastronomy for analyzing unevenly sampled time series data, often suffers fromnoise introduced by irregular sampling. This paper presents a new high-passfilter (HPF) periodogram, a novel implementation designed to mitigate thissampling-induced noise. By applying a frequency-dependent high-pass filterbefore computing the periodogram, the HPF method enhances the precision of PSDestimates and periodicity detection across a wide range of signalcharacteristics. Simulations and comparisons with the Lomb-Scargle periodogramdemonstrate that the HPF periodogram improves accuracy and reliability underchallenging sampling conditions, making it a valuable complementary tool formore robust time series analysis in astronomy and other fields dealing withunevenly sampled data.</description>
      <author>example@mail.com (Ezequiel Albentosa-Ruiz, Nicola Marchili)</author>
      <guid isPermaLink="false">2411.02656v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Landscape for Generative Sequence Models for Specialized Data Synthesis</title>
      <link>http://arxiv.org/abs/2411.01929v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 7 figures, 3 tables, 1 algorithm. code @
  https://github.com/Moe-Zbeeb/Exploring-the-landscape-for-generative-models-for-specialized-data-generation.git&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能研究旨在开发能够在复杂数据集上可靠泛化的模型，但在数据稀缺、复杂或不可访问的领域中仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，利用三种不同复杂度的生成模型合成恶意网络流量这一复杂结构数据集。&lt;h4&gt;方法&lt;/h4&gt;将数值数据转化为文本，将数据生成视为语言建模任务，从而增强数据正则化，显著改善泛化能力和合成数据的质量。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的统计分析，证明该方法在生成高保真合成数据方面超过了现有最先进的生成模型。&lt;h4&gt;结论&lt;/h4&gt;进行关于合成数据应用、有效性和评估策略的全面研究，提供了在多个领域中的重要见解。&lt;h4&gt;代码和资源&lt;/h4&gt;我们的代码和预训练模型在Github上公开，便于进一步探索和应用该方法。&lt;h4&gt;总结&lt;/h4&gt;该研究为合成数据的生成和应用提供了新的视角，促进了机器学习和隐私保护数据生成领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/moe-zbeeb/exploring-the-landscape-for-generative-models-for-specialized-data-generation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial Intelligence (AI) research often aims to develop models that cangeneralize reliably across complex datasets, yet this remains challenging infields where data is scarce, intricate, or inaccessible. This paper introducesa novel approach that leverages three generative models of varying complexityto synthesize one of the most demanding structured datasets: Malicious NetworkTraffic. Our approach uniquely transforms numerical data into text, re-framingdata generation as a language modeling task, which not only enhances dataregularization but also significantly improves generalization and the qualityof the synthetic data. Extensive statistical analyses demonstrate that ourmethod surpasses state-of-the-art generative models in producing high-fidelitysynthetic data. Additionally, we conduct a comprehensive study on syntheticdata applications, effectiveness, and evaluation strategies, offering valuableinsights into its role across various domains. Our code and pre-trained modelsare openly accessible at Github, enabling further exploration and applicationof our methodology. Index Terms: Data synthesis, machine learning, trafficgeneration, privacy preserving data, generative models.</description>
      <author>example@mail.com (Mohammad Zbeeb, Mohammad Ghorayeb, Mariam Salman)</author>
      <guid isPermaLink="false">2411.01929v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>LLM-based Framework for Bearing Fault Diagnosis</title>
      <link>http://arxiv.org/abs/2411.02718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确诊断轴承故障对旋转机械的高效运行至关重要，但传统诊断方法面临多种挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于大语言模型（LLMs）的轴承故障诊断框架，以应对现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种信号特征量化方法，结合时域和频域特征提取，利用LoRA和QLoRA进行模型微调，以提升LLMs对振动数据特征的分析能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过单数据集的跨条件实验和跨数据集转移实验验证了创新方法的有效性，跨数据集模型的准确率提高了约10%。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架有效提升了模型的泛化能力，填补了在轴承故障诊断中使用LLMs的研究空白。&lt;h4&gt;总结&lt;/h4&gt;本研究为轴承故障诊断提供了新思路，展示了LLMs在跨条件和小样本学习中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately diagnosing bearing faults is crucial for maintaining the efficientoperation of rotating machinery. However, traditional diagnosis methods facechallenges due to the diversification of application environments, includingcross-condition adaptability, small-sample learning difficulties, andcross-dataset generalization. These challenges have hindered the effectivenessand limited the application of existing approaches. Large language models(LLMs) offer new possibilities for improving the generalization of diagnosismodels. However, the integration of LLMs with traditional diagnosis techniquesfor optimal generalization remains underexplored. This paper proposed anLLM-based bearing fault diagnosis framework to tackle these challenges. First,a signal feature quantification method was put forward to address the issue ofextracting semantic information from vibration data, which integrated time andfrequency domain feature extraction based on a statistical analysis framework.This method textualized time-series data, aiming to efficiently learncross-condition and small-sample common features through concise featureselection. Fine-tuning methods based on LoRA and QLoRA were employed to enhancethe generalization capability of LLMs in analyzing vibration data features. Inaddition, the two innovations (textualizing vibration features and fine-tuningpre-trained models) were validated by single-dataset cross-condition andcross-dataset transfer experiment with complete and limited data. The resultsdemonstrated the ability of the proposed framework to perform three types ofgeneralization tasks simultaneously. Trained cross-dataset models gotapproximately a 10% improvement in accuracy, proving the adaptability of LLMsto input patterns. Ultimately, the results effectively enhance thegeneralization capability and fill the research gap in using LLMs for bearingfault diagnosis.</description>
      <author>example@mail.com (Laifa Tao, Haifei Liu, Guoao Ning, Wenyan Cao, Bohao Huang, Chen Lu)</author>
      <guid isPermaLink="false">2411.02718v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Trustworthy Semantic Communication for Audio-Visual Event Localization</title>
      <link>http://arxiv.org/abs/2411.01991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无线数据流量的指数增长，主要由于移动设备和智能应用的普及，对现代通信系统带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;确保多模态语义信息的安全和可靠传输，特别是在音频-视觉事件定位等任务中。&lt;h4&gt;方法&lt;/h4&gt;提出MMTrustSC框架，通过先进的语义编码技术增强数据完整性和隐私，采用两级编码方案结合纠错码与传统编码器，提高多模态数据传输的准确性和可靠性，同时使用混合加密方法确保语义信息的机密性和完整性。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果验证了MMTrustSC的有效性，显示出在音频-视觉事件定位任务中数据传输的准确性和可靠性显著提高。&lt;h4&gt;结论&lt;/h4&gt;该框架在管理跨模态信息互补和减轻物理噪声方面显著进步，从而提升整体系统性能。&lt;h4&gt;总结&lt;/h4&gt;MMTrustSC框架为解决现代通信系统面临的多模态信息传输安全与可靠性问题提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The exponential growth in wireless data traffic, driven by the proliferationof mobile devices and smart applications, poses significant challenges formodern communication systems. Ensuring the secure and reliable transmission ofmultimodal semantic information is increasingly critical, particularly fortasks like Audio-Visual Event (AVE) localization. This letter introducesMMTrustSC, a novel framework designed to address these challenges by enhancingthe security and reliability of multimodal communication. MMTrustSCincorporates advanced semantic encoding techniques to safeguard data integrityand privacy. It features a two-level coding scheme that combineserror-correcting codes with conventional encoders to improve the accuracy andreliability of multimodal data transmission. Additionally, MMTrustSC employshybrid encryption, integrating both asymmetric and symmetric encryptionmethods, to secure semantic information and ensure its confidentiality andintegrity across potentially hostile networks. Simulation results validateMMTrustSC's effectiveness, demonstrating substantial improvements in datatransmission accuracy and reliability for AVE localization tasks. Thisframework represents a significant advancement in managing intermodalinformation complementarity and mitigating physical noise, thus enhancingoverall system performance.</description>
      <author>example@mail.com (Yuandi Li, Zhe Xiang, Fei Yu, Zhangshuang Guan, Hui Ji, Zhiguo Wan, Cheng Feng)</author>
      <guid isPermaLink="false">2411.01991v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Compositional simulation-based inference for time series</title>
      <link>http://arxiv.org/abs/2411.02728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, submitted for a publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;摊销模拟推断（SBI）方法通过在模拟数据上训练神经网络以执行贝叶斯推断，避免了可处理似然性的需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种可以利用马尔可夫模拟器的SBI框架，以便在时间序列数据上进行有效的参数推断。&lt;h4&gt;方法&lt;/h4&gt;通过局部识别与单个状态转移一致的参数，并将这些局部结果组合以获得与整个时间序列观察一致的后验分布。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个合成基准任务和生态学、流行病学的模拟器上，显示出比直接估计全局后验更高的模拟效率。&lt;h4&gt;结论&lt;/h4&gt;验证了该方法在高维科尔莫哥罗夫流模拟器（约一百万维数据）上的可扩展性和模拟效率。&lt;h4&gt;总结&lt;/h4&gt;提出的框架有效提升了在复杂时间序列数据上进行贝叶斯推断的效率和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mackelab/markovsbi&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Amortized simulation-based inference (SBI) methods train neural networks onsimulated data to perform Bayesian inference. While this approach avoids theneed for tractable likelihoods, it often requires a large number of simulationsand has been challenging to scale to time-series data. Scientific simulatorsfrequently emulate real-world dynamics through thousands of single-statetransitions over time. We propose an SBI framework that can exploit suchMarkovian simulators by locally identifying parameters consistent withindividual state transitions. We then compose these local results to obtain aposterior over parameters that align with the entire time series observation.We focus on applying this approach to neural posterior score estimation butalso show how it can be applied, e.g., to neural likelihood (ratio) estimation.We demonstrate that our approach is more simulation-efficient than directlyestimating the global posterior on several synthetic benchmark tasks andsimulators used in ecology and epidemiology. Finally, we validate scalabilityand simulation efficiency of our approach by applying it to a high-dimensionalKolmogorov flow simulator with around one million dimensions in the datadomain.</description>
      <author>example@mail.com (Manuel Gloeckler, Shoji Toyota, Kenji Fukumizu, Jakob H. Macke)</author>
      <guid isPermaLink="false">2411.02728v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Advanced computer vision for extracting georeferenced vehicle trajectories from drone imagery</title>
      <link>http://arxiv.org/abs/2411.02136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;该论文提出了一种从高空无人机视频中提取地理参考车辆轨迹的框架，旨在解决城市交通监测中的关键挑战以及传统地面系统的局限性。&lt;h4&gt;目的&lt;/h4&gt;提高城市交通监测的效率和准确性，克服传统方法的不足。&lt;h4&gt;方法&lt;/h4&gt;采用先进的计算机视觉和深度学习技术，构建端到端的处理流程，增强车辆检测、跟踪和轨迹稳定化。&lt;h4&gt;主要发现&lt;/h4&gt;在韩国松岛国际商务区进行的多无人机实验中，捕获了约12TB的4K视频数据，开发了新的轨迹稳定化方法，并生成了两个高质量数据集。&lt;h4&gt;结论&lt;/h4&gt;通过公开这些数据集和处理流程的源代码，本研究为交通研究设定了新的数据质量、可重复性和可扩展性基准，展示了无人机技术与计算机视觉结合在城市交通监测中的潜力。&lt;h4&gt;总结&lt;/h4&gt;研究提供了宝贵的资源，助力智能交通系统的发展和交通管理策略的改善。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a framework for extracting georeferenced vehicletrajectories from high-altitude drone footage, addressing key challenges inurban traffic monitoring and limitations of traditional ground-based systems.We employ state-of-the-art computer vision and deep learning to create anend-to-end pipeline that enhances vehicle detection, tracking, and trajectorystabilization. Conducted in the Songdo International Business District, SouthKorea, the study used a multi-drone experiment over 20 intersections, capturingapproximately 12TB of 4K video data over four days. We developed a novel trackstabilization method that uses detected vehicle bounding boxes as exclusionmasks during image registration, which, combined with advanced georeferencingtechniques, accurately transforms vehicle coordinates into real-worldgeographical data. Additionally, our framework includes robust vehicledimension estimation and detailed road segmentation for in-depth trafficanalysis. The framework produced two high-quality datasets: the Songdo Trafficdataset, comprising nearly 1 million unique vehicle trajectories, and theSongdo Vision dataset, containing over 5,000 human-annotated frames with about300,000 vehicle instances in four classes. Comparisons between drone-deriveddata and high-precision sensor data from an instrumented probe vehiclehighlight the accuracy and consistency of our framework's extraction in denseurban settings. By publicly releasing these datasets and the pipeline sourcecode, this work sets new benchmarks for data quality, reproducibility, andscalability in traffic research. Results demonstrate the potential ofintegrating drone technology with advanced computer vision for precise,cost-effective urban traffic monitoring, providing valuable resources for theresearch community to develop intelligent transportation systems and improvetraffic management strategies.</description>
      <author>example@mail.com (Robert Fonod, Haechan Cho, Hwasoo Yeo, Nikolas Geroliminis)</author>
      <guid isPermaLink="false">2411.02136v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Planning for quasi-static manipulation tasks via an intrinsic haptic metric</title>
      <link>http://arxiv.org/abs/2411.04374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;接触丰富的操作通常需要与物体进行战略性互动，例如通过推挤完成特定任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新场景，让机器人通过推开邻近书籍为插入新书创造空间。&lt;h4&gt;方法&lt;/h4&gt;将准静态操作重新构建为基于平衡条件的隐式流形上的规划问题，使用内在触觉度量代替临时成本函数，并提出一种自适应算法同时更新机器人状态、物体位置、接触点和触觉距离。&lt;h4&gt;主要发现&lt;/h4&gt;在拥挤书架插入任务中评估该方法，发现其适用于刚体操作任务，提出代理捕捉接触点和力，用超椭圆表示物体，简化模型保证可微性。&lt;h4&gt;结论&lt;/h4&gt;框架能够自主发现战略性插入策略，简化的接触模型实现了与现实场景相似的行为，并通过改变刚度和初始位置全面分析框架的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究为复杂环境中的机器人操作提供了新的方法和理论支持，展示了其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contact-rich manipulation often requires strategic interactions with objects,such as pushing to accomplish specific tasks. We propose a novel scenario wherea robot inserts a book into a crowded shelf by pushing aside neighboring booksto create space before slotting the new book into place. Classical planningalgorithms fail in this context due to limited space and their tendency toavoid contact. Additionally, they do not handle indirectly manipulable objectsor consider force interactions. Our key contributions are: i) re-framingquasi-static manipulation as a planning problem on an implicit manifold derivedfrom equilibrium conditions; ii) utilizing an intrinsic haptic metric insteadof ad-hoc cost functions; and iii) proposing an adaptive algorithm thatsimultaneously updates robot states, object positions, contact points, andhaptic distances. We evaluate our method on such crowded bookshelf insertiontask but it is a general formulation to rigid bodies manipulation tasks. Wepropose proxies to capture contact point and force, with superellipse torepresent objects. This simplified model guarantee the differentiablity. Ourframework autonomously discovers strategic wedging-in policies while oursimplified contact model achieves behavior similar to real world scenarios. Wealso vary the stiffness and initial positions to analysis our frameworkcomprehensively. The video can be found at https://youtu.be/eab8umZ3AQ0.</description>
      <author>example@mail.com (Lin Yang, Sri Harsha Turlapati, Chen Lv, Domenico Campolo)</author>
      <guid isPermaLink="false">2411.04374v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Specialized Foundation Models Struggle to Beat Supervised Baselines</title>
      <link>http://arxiv.org/abs/2411.02796v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two authors contributed equally. The order was determined
  by coin flip&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FM）范式在视觉和文本领域取得成功后，迅速扩展到科学、工程、医疗等多个领域。&lt;h4&gt;目的&lt;/h4&gt;探讨基础模型在专门领域中是否能够取代传统的监督学习。&lt;h4&gt;方法&lt;/h4&gt;比较基因组学、卫星成像和时间序列三个领域的多个最新基础模型与标准的监督学习工作流程，包括模型开发、超参数调优和训练。&lt;h4&gt;主要发现&lt;/h4&gt;在这三个特定领域中，使用简单的监督模型（如轻度修改的宽ResNet或UNet）能够匹配或超越最新的基础模型。&lt;h4&gt;结论&lt;/h4&gt;大规模预训练的好处尚未在许多专门领域得到充分体现，需要将新的基础模型与强大且调优良好的基准进行比较，同时引入了两种新的易于使用的开源自动化工作流程。&lt;h4&gt;总结&lt;/h4&gt;基础模型在某些领域的有效性仍需验证，传统监督学习在特定任务中仍具竞争力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ritvikgupta199/DASHA&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Following its success for vision and text, the "foundation model" (FM)paradigm -- pretraining large models on massive data, then fine-tuning ontarget tasks -- has rapidly expanded to domains in the sciences, engineering,healthcare, and beyond. Has this achieved what the original FMs accomplished,i.e. the supplanting of traditional supervised learning in their domains? Toanswer we look at three modalities -- genomics, satellite imaging, and timeseries -- with multiple recent FMs and compare them to a standard supervisedlearning workflow: model development, hyperparameter tuning, and training, allusing only data from the target task. Across these three specialized domains,we find that it is consistently possible to train simple supervised models --no more complicated than a lightly modified wide ResNet or UNet -- that matchor even outperform the latest foundation models. Our work demonstrates that thebenefits of large-scale pretraining have yet to be realized in many specializedareas, reinforces the need to compare new FMs to strong, well-tuned baselines,and introduces two new, easy-to-use, open-source, and automated workflows fordoing so.</description>
      <author>example@mail.com (Zongzhe Xu, Ritvik Gupta, Wenduo Cheng, Alexander Shen, Junhong Shen, Ameet Talwalkar, Mikhail Khodak)</author>
      <guid isPermaLink="false">2411.02796v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Vehicles, Pedestrians, and E-bikes: a Three-party Game at Right-turn-on-red Crossroads Revealing the Dual and Irrational Role of E-bikes that Risks Traffic Safety</title>
      <link>http://arxiv.org/abs/2411.02183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;电动自行车的广泛使用便利了短途出行，但导致了道路交通中的混乱和安全问题。&lt;h4&gt;目的&lt;/h4&gt;研究电动自行车在交通冲突中的双重特性，探讨其与行人及机动车的相互作用。&lt;h4&gt;方法&lt;/h4&gt;使用量化响应均衡模型分析三组道路用户（机动车-行人、机动车-电动自行车、电动自行车-行人）在右转红灯路口的行为选择差异。&lt;h4&gt;主要发现&lt;/h4&gt;电动自行车的行为总体上更类似于机动车，而与行人或机动车的互动缺乏合理秩序，增加了混淆和冲突的可能性。&lt;h4&gt;结论&lt;/h4&gt;机动车与行人之间形成了相互理解，机动车通常让行，行人倾向过马路；本研究明确了电动自行车在道路用户中的角色，为优化交通规章提供了可靠的理论基础。&lt;h4&gt;总结&lt;/h4&gt;电动自行车的行为模式需要进一步明确，以改善交通安全和减少冲突。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread use of e-bikes has facilitated short-distance travel yet ledto confusion and safety problems in road traffic. This study focuses on thedual characteristics of e-bikes in traffic conflicts: they resemble pedestrianswhen interacting with motor vehicles and behave like motor vehicles when inconflict with pedestrians, which raises the right of way concerns whenpotential conflicts are at stake. Using the Quantal Response Equilibrium model,this research analyzes the behavioral choice differences of three groups ofroad users (vehicle-pedestrian, vehicle-e-bike, e-bike-pedestrian) atright-turn-on-red crossroads in right-turning lines and straight-going linesconflict scenarios. The results show that the behavior of e-bikes is moresimilar to that of motor vehicles than pedestrians overall, and theirinteractions with either pedestrians or motor vehicles do not establish areasonable order, increasing the likelihood of confusion and conflict. Incontrast, a mutual understanding has developed between motor vehicles andpedestrians, where motor vehicles tend to yield, and pedestrians tend to cross.By clarifying the game theoretical model and introducing the rationalityparameter, this study precisely locates the role of e-bikes among road users,which provides a reliable theoretical basis for optimizing traffic regulations.</description>
      <author>example@mail.com (Gangcheng Zhang, Yeshuo Shu, Keyi Liu, Yuxuan Wang, Donghang Li, Liyan Xu)</author>
      <guid isPermaLink="false">2411.02183v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>SuperQ-GRASP: Superquadrics-based Grasp Pose Estimation on Larger Objects for Mobile-Manipulation</title>
      <link>http://arxiv.org/abs/2411.04386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures, submitted to ICRA 2025 for review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;抓取规划和估计一直是机器人领域的一个长期研究问题，主要有两种方法来找到物体的可抓取姿态：几何方法和数据驱动的学习方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种几何方法，以改善对大型物体抓取姿态的估计和规划。&lt;h4&gt;方法&lt;/h4&gt;利用物体建模的进展（如NeRF），通过从目标物体周围的视角获取RGB图像构建隐式模型，提取显式网格模型，并将3D网格分解为超四面体（SQs），映射到预计算的抓取姿态。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的管道克服了噪声深度和物体视图不完整的问题，并能推广到任意大小的物体。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提升了抓取规划的准确性和适应性，适用于各种物体，进一步的结果可参考补充视频和网页。&lt;h4&gt;总结&lt;/h4&gt;通过几何建模和超四面体的应用，本文为抓取规划提供了一种新的思路，具有良好的推广性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasp planning and estimation have been a longstanding research problem inrobotics, with two main approaches to find graspable poses on the objects: 1)geometric approach, which relies on 3D models of objects and the gripper toestimate valid grasp poses, and 2) data-driven, learning-based approach, withmodels trained to identify grasp poses from raw sensor observations. The latterassumes comprehensive geometric coverage during the training phase. However,the data-driven approach is typically biased toward tabletop scenarios andstruggle to generalize to out-of-distribution scenarios with larger objects(e.g. chair). Additionally, raw sensor data (e.g. RGB-D data) from a singleview of these larger objects is often incomplete and necessitates additionalobservations. In this paper, we take a geometric approach, leveragingadvancements in object modeling (e.g. NeRF) to build an implicit model bytaking RGB images from views around the target object. This model enables theextraction of explicit mesh model while also capturing the visual appearancefrom novel viewpoints that is useful for perception tasks like object detectionand pose estimation. We further decompose the NeRF-reconstructed 3D mesh intosuperquadrics (SQs) -- parametric geometric primitives, each mapped to a set ofprecomputed grasp poses, allowing grasp composition on the target object basedon these primitives. Our proposed pipeline overcomes the problems: a) noisydepth and incomplete view of the object, with a modeling step, and b)generalization to objects of any size. For more qualitative results, refer tothe supplementary video and webpage https://bit.ly/3ZrOanU</description>
      <author>example@mail.com (Xun Tu, Karthik Desingh)</author>
      <guid isPermaLink="false">2411.04386v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Beyond the Traditional VIX: A Novel Approach to Identifying Uncertainty Shocks in Financial Markets</title>
      <link>http://arxiv.org/abs/2411.02804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;引入新的识别策略以解释金融市场的宏观经济波动性。&lt;h4&gt;目的&lt;/h4&gt;利用修订后的波动率指数（VIX）更准确地捕捉不确定性冲击。&lt;h4&gt;方法&lt;/h4&gt;通过对标普500期权价格拟合双重次级正态逆高斯莱维过程，构建修订后的VIX。&lt;h4&gt;主要发现&lt;/h4&gt;修订后的VIX能够更全面地反映金融数据中的极端波动和重尾特性。&lt;h4&gt;结论&lt;/h4&gt;采用公理化方法引入了一般风险收益比的家族，基于修订后的VIX，精确识别金融市场中的不确定性冲击。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种新的工具来分析金融市场波动性，强调了对极端事件和重尾现象的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a new identification strategy for uncertainty shocks to explainmacroeconomic volatility in financial markets. The Chicago Board OptionsExchange Volatility Index (VIX) measures market expectations of futurevolatility, but traditional methods based on second-moment shocks andtime-varying volatility of the VIX often fail to capture the non-Gaussian,heavy-tailed nature of asset returns. To address this, we construct a revisedVIX by fitting a double-subordinated Normal Inverse Gaussian Levy process toS&amp;P 500 option prices, providing a more comprehensive measure of volatilitythat reflects the extreme movements and heavy tails observed in financial data.Using an axiomatic approach, we introduce a general family of risk-rewardratios, computed with our revised VIX and fitted over a fractional time seriesto more accurately identify uncertainty shocks in financial markets.</description>
      <author>example@mail.com (Ayush Jha, Abootaleb Shirvani, Svetlozar T. Rachev, Frank J. Fabozzi)</author>
      <guid isPermaLink="false">2411.02804v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Technical Report: Performance Comparison of Service Mesh Frameworks: the MTLS Test Case</title>
      <link>http://arxiv.org/abs/2411.02267v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;服务网格在现代云原生应用中变得至关重要，它通过抽象微服务之间的通信，提供零信任安全性、可观察性和高级流量控制，而无需进行代码更改。&lt;h4&gt;目的&lt;/h4&gt;研究mTLS协议对服务网格中应用性能的影响。&lt;h4&gt;方法&lt;/h4&gt;评估主要服务网格（Istio、Istio Ambient、Linkerd、Cilium）中引入的性能开销，测试它们在Kubernetes集群中的服务间通信性能。&lt;h4&gt;主要发现&lt;/h4&gt;不同服务网格之间在延迟和内存消耗方面存在显著性能差异，这些差异源于服务网格的不同架构（侧车与无侧车）以及mTLS实现中隐藏的默认额外功能。&lt;h4&gt;结论&lt;/h4&gt;理解服务网格架构及其对性能的影响是至关重要的，这对于云管理者和操作人员应对性能、延迟和资源消耗的挑战具有重要意义。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了mTLS协议对服务网格应用性能的显著影响，强调了架构设计的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Service Mesh has become essential for modern cloud-native applications byabstracting communication between microservices and providing zero-trustsecurity, observability, and advanced traffic control without requiring codechanges. This allows developers to leverage new network capabilities and focuson application logic without managing network complexities. However, theadditional layer can significantly impact system performance, latency, andresource consumption, posing challenges for cloud managers and operators.  In this work, we investigate the impact of the mTLS protocol - a commonsecurity and authentication mechanism - on application performance withinservice meshes. Recognizing that security is a primary motivation for deployinga service mesh, we evaluated the performance overhead introduced by leadingservice meshes: Istio, Istio Ambient, Linkerd, and Cilium. Our experiments wereconducted by testing their performance in service-to-service communicationswithin a Kubernetes cluster.  Our experiments reveal significant performance differences (in terms oflatency and memory consumption) among the service meshes, rooting from thedifferent architecture of the service mesh, sidecar versus sidecareless, anddefault extra features hidden in the mTLS implementation. Our results highlightthe understanding of the service mesh architecture and its impact onperformance.</description>
      <author>example@mail.com (Anat Bremler Barr, Ofek Lavi, Yaniv Naor, Sanjeev Rampal, Jhonatan Tavori)</author>
      <guid isPermaLink="false">2411.02267v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Wasserstein Imputation: Versatile Missing Data Imputation for Time Series</title>
      <link>http://arxiv.org/abs/2411.02811v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;缺失数据常常严重影响标准时间序列分析，实际应用中经常遇到。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法——时序Wasserstein插补，以解决时间序列中的缺失数据问题。&lt;h4&gt;方法&lt;/h4&gt;该方法完全非参数化，避免了在插补之前进行模型规格化，适合潜在的非线性动态。能够处理任意缺失模式的单变量或多变量时间序列，并可轻松融合缺失条目的合理范围和附加信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法减少了许多现有方法的分布偏差，确保使用插补序列进行的后续统计分析更可靠。&lt;h4&gt;结论&lt;/h4&gt;通过优化公式的良好性质，建立了交替最小化算法收敛到临界点的条件，并提供了识别潜在时间序列边际分布的条件。数值实验验证了该方法在处理线性和非线性时间序列模型以及实际缺失数据的有效性。&lt;h4&gt;总结&lt;/h4&gt;时序Wasserstein插补法为时间序列分析中的缺失数据问题提供了一种有效且实用的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Missing data often significantly hamper standard time series analysis, yet inpractice they are frequently encountered. In this paper, we introduce temporalWasserstein imputation, a novel method for imputing missing data in timeseries. Unlike existing techniques, our approach is fully nonparametric,circumventing the need for model specification prior to imputation, making itsuitable for potential nonlinear dynamics. Its principled algorithmicimplementation can seamlessly handle univariate or multivariate time serieswith any missing pattern. In addition, the plausible range and side informationof the missing entries (such as box constraints) can easily be incorporated. Asa key advantage, our method mitigates the distributional bias typical of manyexisting approaches, ensuring more reliable downstream statistical analysisusing the imputed series. Leveraging the benign landscape of the optimizationformulation, we establish the convergence of an alternating minimizationalgorithm to critical points. Furthermore, we provide conditions under whichthe marginal distributions of the underlying time series can be identified. Ournumerical experiments, including extensive simulations covering linear andnonlinear time series models and an application to a real-world groundwaterdataset laden with missing data, corroborate the practical usefulness of theproposed method.</description>
      <author>example@mail.com (Shuo-Chieh Huang, Tengyuan Liang, Ruey S. Tsay)</author>
      <guid isPermaLink="false">2411.02811v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Repairing Neural Networks for Safety in Robotic Systems using Predictive Models</title>
      <link>http://arxiv.org/abs/2411.04408v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 2024 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文介绍了一种新的安全意识机器人学习方法，侧重于利用预测模型修复策略。&lt;h4&gt;目的&lt;/h4&gt;旨在通过修复策略来增强机器人学习过程中的安全性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了行为克隆与神经网络修复，采用两步监督学习框架，首先从专家示范中学习策略，然后应用预测模型进行修复，以强制执行安全约束。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，学习到的策略在两个应用中成功遵循了预定义的安全约束：移动机器人导航和现实世界的下肢假肢。&lt;h4&gt;结论&lt;/h4&gt;该方法有效减少了与机器人重复交互的次数，从而在学习过程中节省了大量时间。&lt;h4&gt;总结&lt;/h4&gt;提出的安全意识机器人学习方法通过结合行为克隆和预测模型修复，提高了机器人在实际应用中的安全性和学习效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a new method for safety-aware robot learning, focusingon repairing policies using predictive models. Our method combines behavioralcloning with neural network repair in a two-step supervised learning framework.It first learns a policy from expert demonstrations and then applies repairsubject to predictive models to enforce safety constraints. The predictivemodels can encompass various aspects relevant to robot learning applications,such as proprioceptive states and collision likelihood. Our experimentalresults demonstrate that the learned policy successfully adheres to apredefined set of safety constraints on two applications: mobile robotnavigation, and real-world lower-leg prostheses. Additionally, we have shownthat our method effectively reduces repeated interaction with the robot,leading to substantial time savings during the learning process.</description>
      <author>example@mail.com (Keyvan Majd, Geoffrey Clark, Georgios Fainekos, Heni Ben Amor)</author>
      <guid isPermaLink="false">2411.04408v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>High-Speed Graphene-based Sub-Terahertz Receivers enabling Wireless Communications for 6G and Beyond</title>
      <link>http://arxiv.org/abs/2411.02269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，电信领域无线数据流量急剧增加，迫切需要创新解决方案以克服当前技术的固有限制，尤其是在容量方面。&lt;h4&gt;目的&lt;/h4&gt;开发一种直接、被动且紧凑的亚太赫兹接收器，以应对无线应用的需求。&lt;h4&gt;方法&lt;/h4&gt;基于石墨烯的接收器，利用亚太赫兹腔体，包括天线和后镜，解决石墨烯固有的低吸收和光活性区域与入射辐射之间的不匹配问题。&lt;h4&gt;主要发现&lt;/h4&gt;石墨烯接收器实现了每秒多千兆比特的数据传输速率，最大传输距离约为3米，带宽达到40 GHz，灵敏度为0.16 A/W。&lt;h4&gt;结论&lt;/h4&gt;这种接收器提供了一种经济、高效且兼容CMOS的小型解决方案，能够满足6G技术对尺寸、重量和功耗的要求。&lt;h4&gt;应用&lt;/h4&gt;适用于芯片间通信和近距离设备间通信。&lt;h4&gt;总结&lt;/h4&gt;石墨烯基亚太赫兹接收器在性能上超越了现有的最先进接收器，为未来的无线通信技术提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the telecommunications field has experienced an unparalleledproliferation of wireless data traffic. Innovative solutions are imperative tocircumvent the inherent limitations of the current technology, in particular interms of capacity. Carrier frequencies in the sub-terahertz (sub-THz) range(~0.2-0.3 THz) can deliver increased capacity and low attenuation forshort-range wireless applications. Here, we demonstrate a direct, passive andcompact sub-THz receiver based on graphene, which outperforms state-of-the-artsub-THz receivers. These graphene-based receivers offer a cost-effective,CMOS-compatible, small-footprint solution that can fulfill the size, weight,and power consumption (SWaP) requirements of 6G technologies. We exploit asub-THz cavity, comprising an antenna and a back mirror, placed in the vicinityof the graphene channel to overcome the low inherent absorption in graphene andthe mismatch between the areas of the photoactive region and the incidentradiation, which becomes extreme in the sub-THz range. The graphene receiversachieve a multigigabit per second data rate with a maximum distance of ~3 mfrom the transmitter, a setup-limited 3 dB bandwidth of 40 GHz, and a highresponsivity of 0.16 A/W, enabling applications such as chip-to-chipcommunication and close proximity device-to-device communication.</description>
      <author>example@mail.com (Karuppasamy Pandian Soundarapandian, Sebastián Castilla, Stefan M. Koepfli, Simone Marconi, Laurenz Kulmer, Ioannis Vangelidis, Ronny de la Bastida, Enzo Rongione, Sefaattin Tongay, Kenji Watanabe, Takashi Taniguchi, Elefterios Lidorikis, Klaas-Jan Tielrooij, Juerg Leuthold, Frank H. L. Koppens)</author>
      <guid isPermaLink="false">2411.02269v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Scale Temporal Analysis for Failure Prediction in Energy Systems</title>
      <link>http://arxiv.org/abs/2411.02857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, RAMS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多现有模型在极端天气条件下预测非线性行为时遇到困难。&lt;h4&gt;目的&lt;/h4&gt;利用PMU数据进行能源系统的故障预测，提出多尺度时间分析方法。&lt;h4&gt;方法&lt;/h4&gt;结合多尺度分析与机器学习，捕捉短期和长期行为；通过提取PMU时间序列数据的领域特征、应用多尺度窗口（30s、60s、180s）进行模式检测、使用递归特征消除识别关键特征，并训练多个机器学习模型。&lt;h4&gt;主要发现&lt;/h4&gt;识别多尺度窗口中的重要特征；LightGBM模型表现优越（精确度0.896）；多尺度分析优于单窗口模型（精确度0.841）。&lt;h4&gt;结论&lt;/h4&gt;研究专注于与天气相关的故障，计划扩展到设备故障和雷电事件。&lt;h4&gt;总结&lt;/h4&gt;本研究通过多尺度分析提高了极端天气条件下能源系统故障预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many existing models struggle to predict nonlinear behavior during extremeweather conditions. This study proposes a multi-scale temporal analysis forfailure prediction in energy systems using PMU data. The model integratesmulti-scale analysis with machine learning to capture both short-term andlong-term behavior. PMU data lacks labeled states despite logged failurerecords, making it difficult to distinguish between normal and disturbanceconditions. We address this through: (1) Extracting domain features from PMUtime series data; (2) Applying multi-scale windows (30s, 60s, 180s) for patterndetection; (3) Using Recursive Feature Elimination to identify key features;(4) Training multiple machine learning models. Key contributions: Identifyingsignificant features across multi-scale windows; Demonstrating LightGBM'ssuperior performance (0.896 precision); Showing multi-scale analysisoutperforms single-window models (0.841). Our work focuses on weather-relatedfailures, with plans to extend to equipment failure and lightning events.</description>
      <author>example@mail.com (Anh Le, Phat K. Huynh, Om P. Yadav, Chau Le, Harun Pirim, Trung Q. Le)</author>
      <guid isPermaLink="false">2411.02857v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Seeing Through Pixel Motion: Learning Obstacle Avoidance from Optical Flow with One Camera</title>
      <link>http://arxiv.org/abs/2411.04413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;光流捕捉图像序列中像素随时间的运动，为运动、深度和环境结构提供信息。飞行昆虫利用这些信息进行导航和避障。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的端到端四旋翼避障系统，利用单目光流来提升自主飞行机器人的灵活性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;开发了一种高效的可微分模拟器，结合简化的四旋翼模型，通过一阶梯度优化直接训练策略。同时引入中心流注意机制和基于动作的主动感知策略，增强策略对任务相关光流观测的关注。&lt;h4&gt;主要发现&lt;/h4&gt;系统在模拟和现实环境中均经过验证，尽管在简单环境中训练，但在真实世界中表现出在未知、杂乱环境中以最高6m/s速度的灵活和稳健飞行能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的系统展示了在复杂环境中利用光流信息进行高效避障的潜力，能够实现与飞行昆虫相似的敏捷性。&lt;h4&gt;总结&lt;/h4&gt;本研究为自主飞行机器人在复杂环境中的导航与避障提供了一种新的方法，具有良好的现实应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optical flow captures the motion of pixels in an image sequence over time,providing information about movement, depth, and environmental structure.Flying insects utilize this information to navigate and avoid obstacles,allowing them to execute highly agile maneuvers even in complex environments.Despite its potential, autonomous flying robots have yet to fully leverage thismotion information to achieve comparable levels of agility and robustness.Challenges of control from optical flow include extracting accurate opticalflow at high speeds, handling noisy estimation, and ensuring robust performancein complex environments. To address these challenges, we propose a novelend-to-end system for quadrotor obstacle avoidance using monocular opticalflow. We develop an efficient differentiable simulator coupled with asimplified quadrotor model, allowing our policy to be trained directly throughfirst-order gradient optimization. Additionally, we introduce a central flowattention mechanism and an action-guided active sensing strategy that enhancesthe policy's focus on task-relevant optical flow observations to enable moreresponsive decision-making during flight. Our system is validated both insimulation and the real world using an FPV racing drone. Despite being trainedin a simple environment in simulation, our system is validated both insimulation and the real world using an FPV racing drone. Despite being trainedin a simple environment in simulation, our system demonstrates agile and robustflight in various unknown, cluttered environments in the real world at speedsof up to 6m/s.</description>
      <author>example@mail.com (Yu Hu, Yuang Zhang, Yunlong Song, Yang Deng, Feng Yu, Linzuo Zhang, Weiyao Lin, Danping Zou, Wenxian Yu)</author>
      <guid isPermaLink="false">2411.04413v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Real-Time Threat Detection in 5G Networks: A Self-Attention RNN Autoencoder Approach for Spectral Intrusion Analysis</title>
      <link>http://arxiv.org/abs/2411.03365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This article has been accepted for publication in WiOpt 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;5G技术快速发展，需要保护射频环境免受复杂入侵，尤其是在动态频谱接入和管理方面。&lt;h4&gt;目的&lt;/h4&gt;提出一种增强的实验模型，用于在5G网络中检测波形级别的异常频谱活动。&lt;h4&gt;方法&lt;/h4&gt;模型结合自注意力机制和基于RNN的自编码器，进行时间序列分析，处理I/Q样本以识别潜在的干扰攻击。&lt;h4&gt;主要发现&lt;/h4&gt;模型架构通过自注意力层增强了RNN自编码器的能力，提高了对时间依赖性和上下文关系的理解。&lt;h4&gt;结论&lt;/h4&gt;在真实的SDR测试平台上进行的实验表明，模型在威胁检测中的性能和准确性得到了改善。&lt;h4&gt;关键词&lt;/h4&gt;自注意力、实时入侵检测、RNN自编码器、变换器架构、LSTM、时间序列异常检测、5G安全、频谱接入安全。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种高效的异常检测方法，平衡了检测精度和计算效率，适用于5G网络的安全性提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the rapidly evolving landscape of 5G technology, safeguarding RadioFrequency (RF) environments against sophisticated intrusions is paramount,especially in dynamic spectrum access and management. This paper presents anenhanced experimental model that integrates a self-attention mechanism with aRecurrent Neural Network (RNN)-based autoencoder for the detection of anomalousspectral activities in 5G networks at the waveform level. Our approach,grounded in time-series analysis, processes in-phase and quadrature (I/Q)samples to identify irregularities that could indicate potential jammingattacks. The model's architecture, augmented with a self-attention layer,extends the capabilities of RNN autoencoders, enabling a more nuancedunderstanding of temporal dependencies and contextual relationships within theRF spectrum. Utilizing a simulated 5G Radio Access Network (RAN) test-bedconstructed with srsRAN 5G and Software Defined Radios (SDRs), we generated acomprehensive stream of data that reflects real-world RF spectrum conditionsand attack scenarios. The model is trained to reconstruct standard signalbehavior, establishing a normative baseline against which deviations,indicative of security threats, are identified. The proposed architecture isdesigned to balance between detection precision and computational efficiency,so the LSTM network, enriched with self-attention, continues to optimize forminimal execution latency and power consumption. Conducted on a real-worldSDR-based testbed, our results demonstrate the model's improved performance andaccuracy in threat detection.  Keywords: self-attention, real-time intrusion detection, RNN autoencoder,Transformer architecture, LSTM, time series anomaly detection, 5G Security,spectrum access security.</description>
      <author>example@mail.com (Mohammadreza Kouchaki, Minglong Zhang, Aly S. Abdalla, Guangchen Lan, Christopher G. Brinton, Vuk Marojevic)</author>
      <guid isPermaLink="false">2411.03365v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>LLM-based Continuous Intrusion Detection Framework for Next-Gen Networks</title>
      <link>http://arxiv.org/abs/2411.03354v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种自适应框架，用于持续检测、识别和分类网络流量中的新兴攻击。&lt;h4&gt;目的&lt;/h4&gt;开发一个可扩展的实时入侵检测系统，能够不断适应变化的网络威胁。&lt;h4&gt;方法&lt;/h4&gt;框架采用变压器编码器架构，双向捕捉隐藏模式，以区分恶意和合法流量，并使用高维BERT嵌入的特征结合高斯混合模型进行未知攻击类型的识别。&lt;h4&gt;主要发现&lt;/h4&gt;框架在恶意活动检测中实现了100%的召回率，并在识别未知攻击类型时，分类准确率和召回率均达到95.6%。&lt;h4&gt;结论&lt;/h4&gt;该框架有效适应不断演变的威胁，同时在检测和识别任务中保持高准确性。&lt;h4&gt;总结&lt;/h4&gt;提出的框架展示了在应对网络威胁时的适应性和高效性，满足了持续演变的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present an adaptive framework designed for the continuousdetection, identification and classification of emerging attacks in networktraffic. The framework employs a transformer encoder architecture, whichcaptures hidden patterns in a bidirectional manner to differentiate betweenmalicious and legitimate traffic. Initially, the framework focuses on theaccurate detection of malicious activities, achieving a perfect recall of 100\%in distinguishing between attack and benign traffic. Subsequently, the systemincrementally identifies unknown attack types by leveraging a Gaussian MixtureModel (GMM) to cluster features derived from high-dimensional BERT embeddings.This approach allows the framework to dynamically adjust its identificationcapabilities as new attack clusters are discovered, maintaining high detectionaccuracy. Even after integrating additional unknown attack clusters, theframework continues to perform at a high level, achieving 95.6\% in bothclassification accuracy and recall.The results demonstrate the effectiveness ofthe proposed framework in adapting to evolving threats while maintaining highaccuracy in both detection and identification tasks. Our ultimate goal is todevelop a scalable, real-time intrusion detection system that can continuouslyevolve with the ever-changing network threat landscape.</description>
      <author>example@mail.com (Frederic Adjewa, Moez Esseghir, Leila Merghem-Boulahia)</author>
      <guid isPermaLink="false">2411.03354v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DexH2R: Task-oriented Dexterous Manipulation from Human to Robots</title>
      <link>http://arxiv.org/abs/2411.04428v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;灵巧操作是人类能力的重要方面，使得与各种物体的交互成为可能。&lt;h4&gt;目的&lt;/h4&gt;解决现有机器人操作方法中数据收集复杂和新场景泛化差的问题。&lt;h4&gt;方法&lt;/h4&gt;提出DexH2R框架，结合人手运动重定向和任务导向的残差动作策略，从而提高任务性能。&lt;h4&gt;主要发现&lt;/h4&gt;DexH2R通过直接从重定向的基本动作和任务导向的奖励中学习残差策略，消除了对劳动密集型遥操作系统的需求。&lt;h4&gt;结论&lt;/h4&gt;在新场景下，通过引入人手和物体的期望轨迹，DexH2R能够让灵巧手获得高泛化能力的新技能。&lt;h4&gt;总结&lt;/h4&gt;在模拟和真实环境中的广泛实验表明，该方法在各种设置中比现有技术提高了40%的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous manipulation is a critical aspect of human capability, enablinginteraction with a wide variety of objects. Recent advancements in learningfrom human demonstrations and teleoperation have enabled progress for robots insuch ability. However, these approaches either require complex data collectionsuch as costly human effort for eye-robot contact, or suffer from poorgeneralization when faced with novel scenarios. To solve both challenges, wepropose a framework, DexH2R, that combines human hand motion retargeting with atask-oriented residual action policy, improving task performance by bridgingthe embodiment gap between human and robotic dexterous hands. Specifically,DexH2R learns the residual policy directly from retargeted primitive actionsand task-oriented rewards, eliminating the need for labor-intensiveteleoperation systems. Moreover, we incorporate test-time guidance for novelscenarios by taking in desired trajectories of human hands and objects,allowing the dexterous hand to acquire new skills with high generalizability.Extensive experiments in both simulation and real-world environmentsdemonstrate the effectiveness of our work, outperforming priorstate-of-the-arts by 40% across various settings.</description>
      <author>example@mail.com (Shuqi Zhao, Xinghao Zhu, Yuxin Chen, Chenran Li, Xiang Zhang, Mingyu Ding, Masayoshi Tomizuka)</author>
      <guid isPermaLink="false">2411.04428v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Drone Data Analytics for Measuring Traffic Metrics at Intersections in High-Density Areas</title>
      <link>http://arxiv.org/abs/2411.02349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages,14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究利用超过100小时的高空无人机视频数据，涵盖呼和浩特市八个交叉口，生成了一个独特且广泛的高密度城市道路交叉口数据集。&lt;h4&gt;目的&lt;/h4&gt;提升YOLOUAV模型，实现对无人机数据集的精准目标识别，支持交通工程研究。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自动校准算法，能够在高密度交通流中创建功能性数据集，节省人力和物力资源。&lt;h4&gt;主要发现&lt;/h4&gt;该算法能够在每帧中捕捉最多200辆车辆，准确跟踪超过100万名道路用户，包括汽车、公交车和卡车，并记录超过50000次完整的变道。&lt;h4&gt;结论&lt;/h4&gt;该数据集是高密度城市交叉口中可公开获取的最大道路用户轨迹数据集，更新了基于无人机高度的速度和加速度算法，并实现了无人机偏移校正算法。&lt;h4&gt;应用&lt;/h4&gt;通过案例研究展示了提出方法的实用性，评估交叉口和交通条件的关键参数。&lt;h4&gt;总结&lt;/h4&gt;该模型能够在呼和浩特市的高密度交通中同时跟踪超过200辆不同类型的车辆，生成基于时空交通流数据的热力图，并通过变道分析和替代测量定位交通冲突，推动无人机在交通运输领域的研究与发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study employed over 100 hours of high-altitude drone video data fromeight intersections in Hohhot to generate a unique and extensive datasetencompassing high-density urban road intersections in China. This research hasenhanced the YOLOUAV model to enable precise target recognition on unmannedaerial vehicle (UAV) datasets. An automated calibration algorithm is presentedto create a functional dataset in high-density traffic flows, which saves humanand material resources. This algorithm can capture up to 200 vehicles per framewhile accurately tracking over 1 million road users, including cars, buses, andtrucks. Moreover, the dataset has recorded over 50,000 complete lane changes.It is the largest publicly available road user trajectories in high-densityurban intersections. Furthermore, this paper updates speed and accelerationalgorithms based on UAV elevation and implements a UAV offset correctionalgorithm. A case study demonstrates the usefulness of the proposed methods,showing essential parameters to evaluate intersections and traffic conditionsin traffic engineering. The model can track more than 200 vehicles of differenttypes simultaneously in highly dense traffic on an urban intersection inHohhot, generating heatmaps based on spatial-temporal traffic flow data andlocating traffic conflicts by conducting lane change analysis and surrogatemeasures. With the diverse data and high accuracy of results, this study aimsto advance research and development of UAVs in transportation significantly.The High-Density Intersection Dataset is available for download athttps://github.com/Qpu523/High-density-Intersection-Dataset.</description>
      <author>example@mail.com (Qingwen Pu, Yuan Zhu, Junqing Wang, Hong Yang, Kun Xie, Shunlai Cui)</author>
      <guid isPermaLink="false">2411.02349v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Laws for Pre-training Agents and World Models</title>
      <link>http://arxiv.org/abs/2411.04434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;体态代理的表现通过增加模型参数、数据集规模和计算能力得以改善。&lt;h4&gt;目的&lt;/h4&gt;更精确地描述规模在行为模仿学习和环境建模任务中的作用。&lt;h4&gt;方法&lt;/h4&gt;分析生成学习目标在离线数据集上的应用，研究模型行为和环境建模。&lt;h4&gt;主要发现&lt;/h4&gt;在行为模仿学习和环境建模中，存在类似于语言建模的幂律关系，表明损失与模型规模之间的关系。&lt;h4&gt;结论&lt;/h4&gt;模型和数据的最佳规模受分词器、任务和架构的影响，表明需要考虑这些因素来优化模型设计。&lt;h4&gt;总结&lt;/h4&gt;通过分析规模对体态代理性能的影响，为模型和数据的优化提供了重要见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The performance of embodied agents has been shown to improve by increasingmodel parameters, dataset size, and compute. This has been demonstrated indomains from robotics to video games, when generative learning objectives onoffline datasets (pre-training) are used to model an agent's behavior(imitation learning) or their environment (world modeling). This papercharacterizes the role of scale in these tasks more precisely. Going beyond thesimple intuition that `bigger is better', we show that the same types of powerlaws found in language modeling (e.g. between loss and optimal model size),also arise in world modeling and imitation learning. However, the coefficientsof these laws are heavily influenced by the tokenizer, task \&amp; architecture --this has important implications on the optimal sizing of models and data.</description>
      <author>example@mail.com (Tim Pearce, Tabish Rashid, Dave Bignell, Raluca Georgescu, Sam Devlin, Katja Hofmann)</author>
      <guid isPermaLink="false">2411.04434v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Capturing research literature attitude towards Sustainable Development Goals: an LLM-based topic modeling approach</title>
      <link>http://arxiv.org/abs/2411.02943v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 8 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;世界面临众多挑战，这些挑战阻碍了人类文明的发展和人类的福祉。&lt;h4&gt;目的&lt;/h4&gt;利用自然语言处理技术，揭示研究文献中关于可持续发展目标（SDGs）的讨论。&lt;h4&gt;方法&lt;/h4&gt;提出一个完全自动化的流程，包括从Scopus数据库获取内容、进行主题建模、通过关键词搜索和时间序列提取进行主题探索。&lt;h4&gt;主要发现&lt;/h4&gt;应用BERTopic对大规模文本数据进行主题建模，发现数百个主题，并引入基于LLM的嵌入计算和超参数优化器。&lt;h4&gt;结论&lt;/h4&gt;用户可以捕捉2006-2023年间科学摘要中对SDGs态度演变的洞察，所有结果都可以通过系统重现，工作流程可广泛应用于任何大规模文本语料库。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种LLM基础的主题建模管道，增强了对SDGs相关研究的可视化和可探索性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The world is facing a multitude of challenges that hinder the development ofhuman civilization and the well-being of humanity on the planet. TheSustainable Development Goals (SDGs) were formulated by the United Nations in2015 to address these global challenges by 2030. Natural language processingtechniques can help uncover discussions on SDGs within research literature. Wepropose a completely automated pipeline to 1) fetch content from the Scopusdatabase and prepare datasets dedicated to five groups of SDGs; 2) performtopic modeling, a statistical technique used to identify topics in largecollections of textual data; and 3) enable topic exploration throughkeywords-based search and topic frequency time series extraction. For topicmodeling, we leverage the stack of BERTopic scaled up to be applied on largecorpora of textual documents (we find hundreds of topics on hundreds ofthousands of documents), introducing i) a novel LLM-based embeddingscomputation for representing scientific abstracts in the continuous space andii) a hyperparameter optimizer to efficiently find the best configuration forany new big datasets. We additionally produce the visualization of results oninteractive dashboards reporting topics' temporal evolution. Results are madeinspectable and explorable, contributing to the interpretability of the topicmodeling process. Our proposed LLM-based topic modeling pipeline for big-textdatasets allows users to capture insights on the evolution of the attitudetoward SDGs within scientific abstracts in the 2006-2023 time span. All theresults are reproducible by using our system; the workflow can be generalizedto be applied at any point in time to any big corpus of textual documents.</description>
      <author>example@mail.com (Francesco Invernici, Francesca Curati, Jelena Jakimov, Amirhossein Samavi, Anna Bernasconi)</author>
      <guid isPermaLink="false">2411.02943v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Enabling Adaptive Agent Training in Open-Ended Simulators by Targeting Diversity</title>
      <link>http://arxiv.org/abs/2411.04466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;端到端学习方法在具身决策领域的广泛应用受限于对目标领域的丰富训练数据的依赖。&lt;h4&gt;目的&lt;/h4&gt;探索元强化学习（meta-RL）在少量适应下的潜力，以缩小更大的泛化差距。&lt;h4&gt;方法&lt;/h4&gt;提出DIVA，一种进化方法，用于在复杂的开放式模拟器中生成多样化的训练任务，结合无监督环境设计和现实可用的领域知识。&lt;h4&gt;主要发现&lt;/h4&gt;DIVA能够克服复杂参数化问题，并成功训练适应性代理行为，表现优于现有文献中的竞争基线。&lt;h4&gt;结论&lt;/h4&gt;半监督环境设计（SSED）方法的潜力被强调，DIVA作为其第一个重要组成部分，能够在现实模拟领域中进行训练，并生成更强大和灵活的适应性代理。&lt;h4&gt;总结&lt;/h4&gt;DIVA展示了在复杂环境中生成多样化训练任务的有效性，为提升适应性代理的能力提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The wider application of end-to-end learning methods to embodieddecision-making domains remains bottlenecked by their reliance on asuperabundance of training data representative of the target domain.Meta-reinforcement learning (meta-RL) approaches abandon the aim of zero-shotgeneralization--the goal of standard reinforcement learning (RL)--in favor offew-shot adaptation, and thus hold promise for bridging larger generalizationgaps. While learning this meta-level adaptive behavior still requiressubstantial data, efficient environment simulators approaching real-worldcomplexity are growing in prevalence. Even so, hand-designing sufficientlydiverse and numerous simulated training tasks for these complex domains isprohibitively labor-intensive. Domain randomization (DR) and proceduralgeneration (PG), offered as solutions to this problem, require simulators topossess carefully-defined parameters which directly translate to meaningfultask diversity--a similarly prohibitive assumption. In this work, we presentDIVA, an evolutionary approach for generating diverse training tasks in suchcomplex, open-ended simulators. Like unsupervised environment design (UED)methods, DIVA can be applied to arbitrary parameterizations, but canadditionally incorporate realistically-available domain knowledge--thusinheriting the flexibility and generality of UED, and the supervised structureembedded in well-designed simulators exploited by DR and PG. Our empiricalresults showcase DIVA's unique ability to overcome complex parameterizationsand successfully train adaptive agent behavior, far outperforming competitivebaselines from prior literature. These findings highlight the potential of suchsemi-supervised environment design (SSED) approaches, of which DIVA is thefirst humble constituent, to enable training in realistic simulated domains,and produce more robust and capable adaptive agents.</description>
      <author>example@mail.com (Robby Costales, Stefanos Nikolaidis)</author>
      <guid isPermaLink="false">2411.04466v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Estimating journey time for two-point vehicle re-identification survey with limited observable scope using 2-dimensional truncated distributions</title>
      <link>http://arxiv.org/abs/2411.02539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交通领域广泛使用称重动态监测(WIM)站、电子收费系统(ETC)和闭路电视(CCTV)收集数据。&lt;h4&gt;目的&lt;/h4&gt;通过匹配不同地点的同一车辆，理解长途旅行模式，并分析忽视生存偏差效应的潜在危害。&lt;h4&gt;方法&lt;/h4&gt;使用截断分布在二维时间-时间域上进行分析，采用最大似然估计(MLE)、费舍尔信息(F.I.)和自助法估计参数及其置信区间。提出一个自动化框架用于查询可观察的时间-时间范围，并在PyTorch中建模复杂分布（如三参数Weibull）以自动求导。&lt;h4&gt;主要发现&lt;/h4&gt;通过设计的三个实验，验证了所提方法的有效性，并揭示了生存偏差效应的影响。&lt;h4&gt;结论&lt;/h4&gt;该研究独特地分析了交通状态，提出的方法在旅行时间可靠性分析、理解物流系统和建模/预测产品生命周期等方面具有潜力。&lt;h4&gt;总结&lt;/h4&gt;准确描述时间-时间域内的旅行时间能揭示长期被忽视的生存偏差效应，促进对交通状况的深入理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In transportation, Weigh-in motion (WIM) stations, Electronic Toll Collection(ETC) systems, Closed-circuit Television (CCTV) are widely deployed to collectdata at different locations. Vehicle re-identification, by matching the samevehicle at different locations, is helpful in understanding the long-distancejourney patterns. In this paper, the potential hazards of ignoring thesurvivorship bias effects are firstly identified and analyzed using a truncateddistribution over a 2-dimensional time-time domain. Given journey time modeledas Exponential or Weibull distribution, Maximum Likelihood Estimation (MLE),Fisher Information (F.I.) and Bootstrap methods are formulated to estimate theparameter of interest and their confidence intervals. Besides formulatingjourney time distributions, an automated framework querying the observabletime-time scope are proposed. For complex distributions (e.g, three parameterWeibull), distributions are modeled in PyTorch to automatically find first andsecond derivatives and estimated results. Three experiments are designed todemonstrate the effectiveness of the proposed method. In conclusion, the paperdescribes a very unique aspects in understanding and analyzing traffic status.Although the survivorship bias effects are not recognized and long-ignored, byaccurately describing travel time over time-time domain, the proposed approachhave potentials in travel time reliability analysis, understanding logisticssystems, modeling/predicting product lifespans, etc.</description>
      <author>example@mail.com (Diyi Liu, Yangsong Gu, Lee D. Han)</author>
      <guid isPermaLink="false">2411.02539v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Time-Causal VAE: Robust Financial Time Series Generator</title>
      <link>http://arxiv.org/abs/2411.02947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;构建一个时间因果变分自编码器（TC-VAE）以稳健生成金融时间序列数据。&lt;h4&gt;目的&lt;/h4&gt;确保真实市场时间序列与生成的虚假时间序列之间的因果传输。&lt;h4&gt;方法&lt;/h4&gt;对编码器和解码器网络施加因果约束，证明TC-VAE损失提供市场分布与生成分布之间因果Wasserstein距离的上界，并整合RealNVP先验以增强模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量数值实验，TC-VAE在合成和真实市场数据上均取得了良好的结果。&lt;h4&gt;结论&lt;/h4&gt;生成的数据在各类统计距离下与真实数据进行比较，显示出其在下游金融优化任务中的有效性，并再现了真实金融市场数据的风格化特征。&lt;h4&gt;总结&lt;/h4&gt;TC-VAE能够有效生成金融时间序列数据，具备实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/justinhou95/TimeCausalVAE&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We build a time-causal variational autoencoder (TC-VAE) for robust generationof financial time series data. Our approach imposes a causality constraint onthe encoder and decoder networks, ensuring a causal transport from the realmarket time series to the fake generated time series. Specifically, we provethat the TC-VAE loss provides an upper bound on the causal Wasserstein distancebetween market distributions and generated distributions. Consequently, theTC-VAE loss controls the discrepancy between optimal values of various dynamicstochastic optimization problems under real and generated distributions. Tofurther enhance the model's ability to approximate the latent representation ofthe real market distribution, we integrate a RealNVP prior into the TC-VAEframework. Finally, extensive numerical experiments show that TC-VAE achievespromising results on both synthetic and real market data. This is done bycomparing real and generated distributions according to various statisticaldistances, demonstrating the effectiveness of the generated data for downstreamfinancial optimization tasks, as well as showcasing that the generated datareproduces stylized facts of real financial market data.</description>
      <author>example@mail.com (Beatrice Acciaio, Stephan Eckstein, Songyan Hou)</author>
      <guid isPermaLink="false">2411.02947v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Online Omnidirectional Jumping Trajectory Planning for Quadrupedal Robots on Uneven Terrains</title>
      <link>http://arxiv.org/abs/2411.04494v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IJRR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自然地形的复杂性常常需要动物进行敏捷的跳跃以提高行进效率。&lt;h4&gt;目的&lt;/h4&gt;为四足机器人提供类似的能力，实现复杂的实时跳跃动作。&lt;h4&gt;方法&lt;/h4&gt;提出一个通用且完整的级联在线优化框架，用于四足机器人的全向跳跃，涵盖跳跃轨迹生成、轨迹跟踪控制器和着陆控制器，并结合环境感知以导航障碍物。&lt;h4&gt;主要发现&lt;/h4&gt;引入了一种新颖的跳跃平面来参数化全向跳跃运动，提出了一个紧密耦合的优化问题，优化重心轨迹、地面反作用力和关节状态，同时满足运动的动力学约束。&lt;h4&gt;结论&lt;/h4&gt;提出的框架在大约0.1秒内完成跳跃轨迹生成，并在两种不平坦地形的四足机器人上成功验证，框架的适用性也扩展到了人形机器人。&lt;h4&gt;总结&lt;/h4&gt;该研究为四足机器人实现复杂跳跃提供了有效的解决方案，提升了其在复杂环境中的运动能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Natural terrain complexity often necessitates agile movements like jumping inanimals to improve traversal efficiency. To enable similar capabilities inquadruped robots, complex real-time jumping maneuvers are required. Currentresearch does not adequately address the problem of online omnidirectionaljumping and neglects the robot's kinodynamic constraints during trajectorygeneration. This paper proposes a general and complete cascade onlineoptimization framework for omnidirectional jumping for quadruped robots. Oursolution systematically encompasses jumping trajectory generation, a trajectorytracking controller, and a landing controller. It also incorporatesenvironmental perception to navigate obstacles that standard locomotion cannotbypass, such as jumping from high platforms. We introduce a novel jumping planeto parameterize omnidirectional jumping motion and formulate a tightly coupledoptimization problem accounting for the kinodynamic constraints, simultaneouslyoptimizing CoM trajectory, Ground Reaction Forces (GRFs), and joint states. Tomeet the online requirements, we propose an accelerated evolutionary algorithmas the trajectory optimizer to address the complexity of kinodynamicconstraints. To ensure stability and accuracy in environmental perceptionpost-landing, we introduce a coarse-to-fine relocalization method that combinesglobal Branch and Bound (BnB) search with Maximum a Posteriori (MAP) estimationfor precise positioning during navigation and jumping. The proposed frameworkachieves jump trajectory generation in approximately 0.1 seconds with a warmstart and has been successfully validated on two quadruped robots on uneventerrains. Additionally, we extend the framework's versatility to humanoidrobots.</description>
      <author>example@mail.com (Linzhu Yue, Zhitao Song, Jinhu Dong, Zhongyu Li, Hongbo Zhang, Lingwei Zhang, Xuanqi Zeng, Koushil Sreenath, Yun-hui Liu)</author>
      <guid isPermaLink="false">2411.04494v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>A scalable generative model for dynamical system reconstruction from neuroimaging data</title>
      <link>http://arxiv.org/abs/2411.02949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38th Conference on Neural Information Processing Systems (NeurIPS
  2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数据驱动的推断方法在机器学习和自然科学中越来越受到关注，尤其是在神经科学领域。&lt;h4&gt;目的&lt;/h4&gt;旨在减少依赖生物物理原理的模型手工构建，自动推断个体间的脑动态差异。&lt;h4&gt;方法&lt;/h4&gt;采用针对动态系统重建的状态空间模型（SSMs）训练技术，结合控制理论思想以确保训练过程中的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的新算法能够有效处理当前观察依赖于历史状态的信号，克服现有TF方法在可逆性上的限制。&lt;h4&gt;结论&lt;/h4&gt;新算法在重建动态系统及其状态空间几何和长期时间特性方面表现出色，能够从短期BOLD时间序列中进行有效重建。&lt;h4&gt;总结&lt;/h4&gt;研究展示了通过新的控制技术训练SSMs的潜力，为神经科学中的信号处理提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven inference of the generative dynamics underlying a set of observedtime series is of growing interest in machine learning and the naturalsciences. In neuroscience, such methods promise to alleviate the need tohandcraft models based on biophysical principles and allow to automatize theinference of inter-individual differences in brain dynamics. Recentbreakthroughs in training techniques for state space models (SSMs) specificallygeared toward dynamical systems (DS) reconstruction (DSR) enable to recover theunderlying system including its geometrical (attractor) and long-termstatistical invariants from even short time series. These techniques are basedon control-theoretic ideas, like modern variants of teacher forcing (TF), toensure stable loss gradient propagation while training. However, as itcurrently stands, these techniques are not directly applicable to datamodalities where current observations depend on an entire history of previousstates due to a signal's filtering properties, as common in neuroscience (andphysiology more generally). Prominent examples are the blood oxygenation leveldependent (BOLD) signal in functional magnetic resonance imaging (fMRI) orCa$^{2+}$ imaging data. Such types of signals render the SSM's decoder modelnon-invertible, a requirement for previous TF-based methods. Here, exploitingthe recent success of control techniques for training SSMs, we propose a novelalgorithm that solves this problem and scales exceptionally well with modeldimensionality and filter length. We demonstrate its efficiency inreconstructing dynamical systems, including their state space geometry andlong-term temporal properties, from just short BOLD time series.</description>
      <author>example@mail.com (Eric Volkmann, Alena Brändle, Daniel Durstewitz, Georgia Koppe)</author>
      <guid isPermaLink="false">2411.02949v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Memory Remedy: An AI-Enhanced Interactive Story Exploring Human-Robot Interaction and Companionship</title>
      <link>http://arxiv.org/abs/2411.04499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The 17th International Symposium on Visual Information Communication
  and Interaction (VINCI 2024), December 11--13, 2024, Hsinchu, Taiwan&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;使用AI生成内容（AIGC）和多媒体开发沉浸式、基于游戏的互动故事体验。&lt;h4&gt;目的&lt;/h4&gt;探索机器人主角与老年人之间复杂关系的叙事，以及反思未来机器人陪伴在老年人生活中的潜在角色。&lt;h4&gt;方法&lt;/h4&gt;故事《记忆的解药》通过闪回的方式展开，逐步揭示情节。&lt;h4&gt;主要发现&lt;/h4&gt;故事探讨了生命旅程、记忆的深远影响以及后人类情感关怀的概念。&lt;h4&gt;结论&lt;/h4&gt;鼓励观众对人工智能与人类之间复杂关系进行更深层次的反思。&lt;h4&gt;总结&lt;/h4&gt;通过互动故事，观众能够思考机器人陪伴对老年生活的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3678698.3687186&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present our approach to using AI-generated content (AIGC) and multiplemedia to develop an immersive, game-based, interactive story experience. Thenarrative of the story, "Memory Remedy", unfolds through flashbacks, allowingthe audience to gradually uncover the story and the complex relationshipbetween the robot protagonist and the older adults. This exploration exploresimportant themes such as the journey of life, the profound influence ofmemories, and the concept of post-human emotional care. By engaging with thisAIGC-based interactive story, audiences are encouraged to reflect on thepotential role of robotic companionship in the lives of older adults in thefuture; and to encourage deeper reflection on the complex relationship betweenartificial intelligence and humanity.</description>
      <author>example@mail.com (Lei Han, Yu Zhou, Qiongyan Chen, David Yip)</author>
      <guid isPermaLink="false">2411.04499v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>IMUDiffusion: A Diffusion Model for Multivariate Time Series Synthetisation for Inertial Motion Capturing Systems</title>
      <link>http://arxiv.org/abs/2411.02954v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;运动行为分析常用运动传感器，因其易用性和无空间限制，优于视频捕捉系统。然而，特定活动的运动数据生成和标注耗时且成本高。&lt;h4&gt;目的&lt;/h4&gt;解决数据生成和标注的时间与成本问题，提高模型在识别复杂运动模式时的性能。&lt;h4&gt;方法&lt;/h4&gt;提出IMUDiffusion，一种专为多变量时间序列生成设计的概率扩散模型，用于生成高质量的时间序列。&lt;h4&gt;主要发现&lt;/h4&gt;通过将我们的数据集与合成数据结合，基线人类活动分类器的性能显著提升，宏观F1-score提高近30%。&lt;h4&gt;结论&lt;/h4&gt;IMUDiffusion是生成真实人类活动运动的有价值工具，有助于在训练数据有限的情况下增强模型的鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新方法，通过合成数据提高运动行为分析的效率和模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Kinematic sensors are often used to analyze movement behaviors in sports anddaily activities due to their ease of use and lack of spatial restrictions,unlike video-based motion capturing systems. Still, the generation, andespecially the labeling of motion data for specific activities can betime-consuming and costly. Additionally, many models struggle with limiteddata, which limits their performance in recognizing complex movement patterns.To address those issues, generating synthetic data can help expand thediversity and variability. In this work, we propose IMUDiffusion, aprobabilistic diffusion model specifically designed for multivariate timeseries generation. Our approach enables the generation of high-quality timeseries sequences which accurately capture the dynamics of human activities.Moreover, by joining our dataset with synthetic data, we achieve a significantimprovement in the performance of our baseline human activity classifier. Insome cases, we are able to improve the macro F1-score by almost 30%.IMUDiffusion provides a valuable tool for generating realistic human activitymovements and enhance the robustness of models in scenarios with limitedtraining data.</description>
      <author>example@mail.com (Heiko Oppel, Michael Munz)</author>
      <guid isPermaLink="false">2411.02954v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Feature Importance and Explainability Towards Enhanced ML-Based DoS Detection in AI Systems</title>
      <link>http://arxiv.org/abs/2411.03355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures, IEEE VTC2024-Fall&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;拒绝服务（DoS）攻击对人工智能系统安全构成重大威胁，导致显著的财务损失和停机时间。&lt;h4&gt;目的&lt;/h4&gt;研究特征选择在提高基于机器学习的DoS攻击检测中的重要性。&lt;h4&gt;方法&lt;/h4&gt;利用统计分析和特征工程方法，探讨特征对DoS流量数据集整体组成的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;通过全面的统计分析和特征工程，能够理解攻击行为，并识别出最佳的特征选择用于机器学习的DoS分类和检测。&lt;h4&gt;结论&lt;/h4&gt;特征选择在提升模型性能和攻击检测准确性方面至关重要，同时能够减少训练时间。&lt;h4&gt;总结&lt;/h4&gt;研究表明，特征选择对基于机器学习的DoS攻击检测具有显著影响，优化特征选择机制能够提高检测效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Denial of Service (DoS) attacks pose a significant threat in the realm of AIsystems security, causing substantial financial losses and downtime. However,AI systems' high computational demands, dynamic behavior, and data variabilitymake monitoring and detecting DoS attacks challenging. Nowadays, statisticaland machine learning (ML)-based DoS classification and detection approachesutilize a broad range of feature selection mechanisms to select a featuresubset from networking traffic datasets. Feature selection is critical inenhancing the overall model performance and attack detection accuracy whilereducing the training time. In this paper, we investigate the importance offeature selection in improving ML-based detection of DoS attacks. Specifically,we explore feature contribution to the overall components in DoS trafficdatasets by utilizing statistical analysis and feature engineering approaches.Our experimental findings demonstrate the usefulness of the thoroughstatistical analysis of DoS traffic and feature engineering in understandingthe behavior of the attack and identifying the best feature selection forML-based DoS classification and detection.</description>
      <author>example@mail.com (Paul Badu Yakubu, Evans Owusu, Lesther Santana, Mohamed Rahouti, Abdellah Chehri, Kaiqi Xiong)</author>
      <guid isPermaLink="false">2411.03355v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Analytical Derivatives for Efficient Mechanical Simulations of Hybrid Soft Rigid Robots</title>
      <link>http://arxiv.org/abs/2411.04546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages including appendix, 17 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;使用导数的算法加速了刚性机器人模拟并提高了准确性，但将这些方法扩展到软体和混合软刚性机器人面临更大挑战，特别是在建模软体的连续变形方面。&lt;h4&gt;目的&lt;/h4&gt;扩展杆理论，通过几何变量应变模型（GVS）来建模混合软刚性机器人。&lt;h4&gt;方法&lt;/h4&gt;采用螺旋理论和Cosserat杆的应变参数化，使用递归牛顿-欧拉算法开发GVS模型的控制方程的解析导数。&lt;h4&gt;主要发现&lt;/h4&gt;解析导数促进了动态的隐式积分，并提供了静态残差的解析雅可比，显著提高了计算效率，速度提升可达三个数量级。&lt;h4&gt;结论&lt;/h4&gt;模型通过比较有无解析导数的模拟结果验证，所讨论的技术有潜力革新混合机器人系统在真实应用中的分析、控制和优化。&lt;h4&gt;总结&lt;/h4&gt;本研究为模拟复杂软体和混合机器人提供了有效的方法，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Algorithms that use derivatives of governing equations have accelerated rigidrobot simulations and improved their accuracy, enabling the modeling ofcomplex, real-world capabilities. However, extending these methods to soft andhybrid soft-rigid robots is significantly more challenging due to thecomplexities in modeling continuous deformations inherent in soft bodies. Aconsiderable number of soft robots and the deformable links of hybrid robotscan be effectively modeled as slender rods. The Geometric Variable Strain (GVS)model, which employs the screw theory and the strain parameterization of theCosserat rod, extends the rod theory to model hybrid soft-rigid robots withinthe same mathematical framework. Using the Recursive Newton-Euler Algorithm, wedeveloped the analytical derivatives of the governing equations of the GVSmodel. These derivatives facilitate the implicit integration of dynamics andprovide the analytical Jacobian of the statics residue, ensuring fast andaccurate computations. We applied these derivatives to the mechanicalsimulations of six common robotic systems: a soft cable-driven manipulator, ahybrid serial robot, a fin-ray finger, a hybrid parallel robot, a contactscenario, and an underwater hybrid mobile robot. Simulation results demonstratesubstantial improvements in computational efficiency, with speed-ups of up tothree orders of magnitude. We validate the model by comparing simulations donewith and without analytical derivatives. Beyond static and dynamic simulations,the techniques discussed in this paper hold the potential to revolutionize theanalysis, control, and optimization of hybrid robotic systems for real-worldapplications.</description>
      <author>example@mail.com (Anup Teejo Mathew, Frederic Boyer, Vincent Lebastard, Federico Renda)</author>
      <guid isPermaLink="false">2411.04546v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>From Twitter to Reasoner: Understand Mobility Travel Modes and Sentiment Using Large Language Models</title>
      <link>http://arxiv.org/abs/2411.02666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages; Accepted by ITSC 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社交媒体成为人们表达对交通服务和基础设施意见的重要平台。&lt;h4&gt;目的&lt;/h4&gt;帮助研究者深入理解个人的出行选择，协助运输运营商改善服务质量，并支持政策制定者调节出行服务。&lt;h4&gt;方法&lt;/h4&gt;引入一种新颖的方法框架，利用大型语言模型（LLMs）从社交媒体帖子中推断出行方式，并分析人们对相关出行方式的态度，无需手动标注。&lt;h4&gt;主要发现&lt;/h4&gt;大多数社交媒体帖子表现出负面情绪而非正面情绪。&lt;h4&gt;结论&lt;/h4&gt;识别导致负面帖子的因素，并针对交通运营商和政策制定者提出相应建议。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了利用LLMs分析社交媒体数据的潜力，为交通服务的改进提供了数据驱动的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social media has become an important platform for people to express theiropinions towards transportation services and infrastructure, which holds thepotential for researchers to gain a deeper understanding of individuals' travelchoices, for transportation operators to improve service quality, and forpolicymakers to regulate mobility services. A significant challenge, however,lies in the unstructured nature of social media data. In other words, textualdata like social media is not labeled, and large-scale manual annotations arecost-prohibitive. In this study, we introduce a novel methodological frameworkutilizing Large Language Models (LLMs) to infer the mentioned travel modes fromsocial media posts, and reason people's attitudes toward the associated travelmode, without the need for manual annotation. We compare different LLMs alongwith various prompting engineering methods in light of human assessment and LLMverification. We find that most social media posts manifest negative ratherthan positive sentiments. We thus identify the contributing factors to thesenegative posts and, accordingly, propose recommendations to traffic operatorsand policymakers.</description>
      <author>example@mail.com (Kangrui Ruan, Xinyang Wang, Xuan Di)</author>
      <guid isPermaLink="false">2411.02666v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Vision Language Models are In-Context Value Learners</title>
      <link>http://arxiv.org/abs/2411.04549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website and demo:
  https://generative-value-learning.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预测视觉轨迹中的时间进展对能够学习、适应和改进的智能机器人非常重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种通用的价值函数估计器，利用视觉语言模型中的世界知识来预测任务进展。&lt;h4&gt;方法&lt;/h4&gt;将价值估计视为一个时间排序问题，通过对打乱的视频帧进行处理，克服连续帧之间的强时间相关性。&lt;h4&gt;主要发现&lt;/h4&gt;GVL能够在没有任何机器人或特定任务训练的情况下，实现对300多个真实世界任务的有效价值预测，包括复杂的双手操作任务。&lt;h4&gt;结论&lt;/h4&gt;GVL支持灵活的多模态上下文学习，可以通过异构任务和实例（如人类视频）进行学习，并且对视觉运动策略学习的下游应用具有广泛的适用性，无需模型训练或微调。&lt;h4&gt;总结&lt;/h4&gt;GVL是一种强大的工具，通过优化视频帧的时间顺序，提高了价值预测的准确性，推动了机器人学习和适应能力的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting temporal progress from visual trajectories is important forintelligent robots that can learn, adapt, and improve. However, learning suchprogress estimator, or temporal value function, across different tasks anddomains requires both a large amount of diverse data and methods which canscale and generalize. To address these challenges, we present Generative ValueLearning (\GVL), a universal value function estimator that leverages the worldknowledge embedded in vision-language models (VLMs) to predict task progress.Naively asking a VLM to predict values for a video sequence performs poorly dueto the strong temporal correlation between successive frames. Instead, GVLposes value estimation as a temporal ordering problem over shuffled videoframes; this seemingly more challenging task encourages VLMs to more fullyexploit their underlying semantic and temporal grounding capabilities todifferentiate frames based on their perceived task progress, consequentlyproducing significantly better value predictions. Without any robot or taskspecific training, GVL can in-context zero-shot and few-shot predict effectivevalues for more than 300 distinct real-world tasks across diverse robotplatforms, including challenging bimanual manipulation tasks. Furthermore, wedemonstrate that GVL permits flexible multi-modal in-context learning viaexamples from heterogeneous tasks and embodiments, such as human videos. Thegenerality of GVL enables various downstream applications pertinent tovisuomotor policy learning, including dataset filtering, success detection, andadvantage-weighted regression -- all without any model training or finetuning.</description>
      <author>example@mail.com (Yecheng Jason Ma, Joey Hejna, Ayzaan Wahid, Chuyuan Fu, Dhruv Shah, Jacky Liang, Zhuo Xu, Sean Kirmani, Peng Xu, Danny Driess, Ted Xiao, Jonathan Tompson, Osbert Bastani, Dinesh Jayaraman, Wenhao Yu, Tingnan Zhang, Dorsa Sadigh, Fei Xia)</author>
      <guid isPermaLink="false">2411.04549v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>bursty_dynamics: A Python Package for Exploring the Temporal Properties of Longitudinal Data</title>
      <link>http://arxiv.org/abs/2411.03210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;理解纵向数据的时间特性对于识别趋势、预测未来事件以及在健康、金融、地质科学和社会科学等领域做出明智决策至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决传统时间序列分析技术无法捕捉不规则时间模式的复杂性，介绍burst_dynamics包以量化突发动态。&lt;h4&gt;方法&lt;/h4&gt;通过计算突发性参数(BP)和记忆系数(MC)来分析时间数据，并实现事件列车检测方法以识别特定时间间隔内的聚集事件。&lt;h4&gt;主要发现&lt;/h4&gt;BP和MC提供了对事件序列中不规则性和时间依赖性的洞察，揭示了疾病病因、人类行为或其他信息传播的复杂模式。&lt;h4&gt;结论&lt;/h4&gt;burst_dynamics通过内置可视化工具，为研究人员提供了一个易于访问且强大的平台，以探索和解释纵向数据的时间动态。&lt;h4&gt;应用&lt;/h4&gt;该包在不同研究领域中的应用展示了其功能和优势，特别是在增强时间数据分析方面。&lt;h4&gt;总结&lt;/h4&gt;使用BP、MC和事件列车检测可以显著提升对时间数据的分析能力，适用于多种研究场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the temporal properties of longitudinal data is critical foridentifying trends, predicting future events, and making informed decisions inany field where temporal data is analysed, including health and epidemiology,finance, geosciences, and social sciences. Traditional time-series analysistechniques often fail to capture the complexity of irregular temporal patternspresent in such data. To address this gap, we introduce bursty_dynamics, aPython package that enables the quantification of bursty dynamics through thecalculation of the Burstiness Parameter (BP) and Memory Coefficient (MC). Intemporal data, BP and MC provide insights into the irregularity and temporaldependencies within event sequences, shedding light on complex patterns ofdisease aetiology, human behaviour, or other information diffusion over time.An event train detection method is also implemented to identify clusteredevents occurring within a specified time interval, allowing for more focusedanalysis with reduced noise. With built-in visualisation tools, bursty_dynamicsprovides an accessible yet powerful platform for researchers to explore andinterpret the temporal dynamics of longitudinal data. This paper outlines thecore functionalities of the package, demonstrates its applications in diverseresearch domains, and discusses the advantages of using BP, MC, and event traindetection for enhanced temporal data analysis.</description>
      <author>example@mail.com (Alisha Angdembe, Wasim A Iqbal, Rebeen Ali Hamad, John Casement, AI-Multiply Consortium, Paolo Missier, Nick Reynolds, Rafael Henkin, Michael R Barnes)</author>
      <guid isPermaLink="false">2411.03210v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Visually Analyze SHAP Plots to Diagnose Misclassifications in ML-based Intrusion Detection</title>
      <link>http://arxiv.org/abs/2411.02670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 14 figures, accepted in the MLC Workshop of the
  International Conference on Data Mining Conference (ICDM 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;入侵检测是保护系统和网络免受各种威胁的一种常见安全措施。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于可解释人工智能的可视化分析方法，以识别入侵检测系统中的潜在误报和漏报。&lt;h4&gt;方法&lt;/h4&gt;使用重叠SHAP图来展示特征解释，帮助安全分析师进行有效决策。&lt;h4&gt;主要发现&lt;/h4&gt;通过多个公开网络流量数据集的案例研究，验证了该方法在识别误报和漏报实例方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;可视化分析方法为分析师提供了清晰的指导，以便采取可靠的应对措施。&lt;h4&gt;总结&lt;/h4&gt;本研究为入侵检测系统提供了一种新的工具，增强了对网络威胁的响应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intrusion detection has been a commonly adopted detective security measuresto safeguard systems and networks from various threats. A robust intrusiondetection system (IDS) can essentially mitigate threats by providing alerts. Innetworks based IDS, typically we deal with cyber threats like distributeddenial of service (DDoS), spoofing, reconnaissance, brute-force, botnets, andso on. In order to detect these threats various machine learning (ML) and deeplearning (DL) models have been proposed. However, one of the key challengeswith these predictive approaches is the presence of false positive (FP) andfalse negative (FN) instances. This FPs and FNs within any black-box intrusiondetection system (IDS) make the decision-making task of an analyst furthercomplicated. In this paper, we propose an explainable artificial intelligence(XAI) based visual analysis approach using overlapping SHAP plots that presentsthe feature explanation to identify potential false positive and falsenegatives in IDS. Our approach can further provide guidance to securityanalysts for effective decision-making. We present case study with multiplepublicly available network traffic datasets to showcase the efficacy of ourapproach for identifying false positive and false negative instances. Ouruse-case scenarios provide clear guidance for analysts on how to use the visualanalysis approach for reliable course-of-actions against such threats.</description>
      <author>example@mail.com (Maraz Mia, Mir Mehedi A. Pritom, Tariqul Islam, Kamrul Hasan)</author>
      <guid isPermaLink="false">2411.02670v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>IGDrivSim: A Benchmark for the Imitation Gap in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2411.04653v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;开发能够在复杂环境中以人类水平的安全性和效率导航的自主车辆是自动驾驶研究的核心目标。&lt;h4&gt;目的&lt;/h4&gt;探讨模仿差距对从人类专家演示中学习自主驾驶策略的影响。&lt;h4&gt;方法&lt;/h4&gt;引入IGDrivSim基准，基于Waymax模拟器，研究模仿学习中的模仿差距。&lt;h4&gt;主要发现&lt;/h4&gt;人类专家与自驾车传感器之间的感知差距会阻碍安全有效的驾驶行为学习。&lt;h4&gt;结论&lt;/h4&gt;结合模仿学习与强化学习，通过对禁止行为施加简单的惩罚奖励，可以有效减少模仿学习失败。&lt;h4&gt;代码&lt;/h4&gt;我们的代码已开源，链接为：https://github.com/clemgris/IGDrivSim.git。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了模仿差距的问题，并提出了结合两种学习方法的有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/clemgris/igdrivsim&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing autonomous vehicles that can navigate complex environments withhuman-level safety and efficiency is a central goal in self-driving research. Acommon approach to achieving this is imitation learning, where agents aretrained to mimic human expert demonstrations collected from real-world drivingscenarios. However, discrepancies between human perception and the self-drivingcar's sensors can introduce an \textit{imitation gap}, leading to imitationlearning failures. In this work, we introduce \textbf{IGDrivSim}, a benchmarkbuilt on top of the Waymax simulator, designed to investigate the effects ofthe imitation gap in learning autonomous driving policy from human expertdemonstrations. Our experiments show that this perception gap between humanexperts and self-driving agents can hinder the learning of safe and effectivedriving behaviors. We further show that combining imitation with reinforcementlearning, using a simple penalty reward for prohibited behaviors, effectivelymitigates these failures. Our code is open-sourced at:https://github.com/clemgris/IGDrivSim.git.</description>
      <author>example@mail.com (Clémence Grislain, Risto Vuorio, Cong Lu, Shimon Whiteson)</author>
      <guid isPermaLink="false">2411.04653v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Socially-Aware Opinion-Based Navigation with Oval Limit Cycles</title>
      <link>http://arxiv.org/abs/2411.04678v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 6 figures, submitted to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人在共享空间中移动时，会选择保护彼此安全的导航策略，同时尽量减少路径的修改。&lt;h4&gt;目的&lt;/h4&gt;研究如何在机器人中复制人类的社会意识导航逻辑。&lt;h4&gt;方法&lt;/h4&gt;结合意见动力学（达成共识）与涡旋场（生成社会可接受的轨迹）进行整体方法研究。&lt;h4&gt;主要发现&lt;/h4&gt;将两种技术结合使用的结果优于单独应用这两种技术。&lt;h4&gt;结论&lt;/h4&gt;通过整合人类的非语言交流和决策过程，可以提高机器人在共享空间中的导航表现。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种综合的方法，旨在改善机器人在社会环境中的导航能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When humans move in a shared space, they choose navigation strategies thatpreserve their mutual safety. At the same time, each human seeks to minimisethe number of modifications to her/his path. In order to achieve this result,humans use unwritten rules and reach a consensus on their decisions about themotion direction by exchanging non-verbal messages. They then implement theirchoice in a mutually acceptable way. Socially-aware navigation denotes aresearch effort aimed at replicating this logic inside robots. Existing resultsfocus either on how robots can participate in negotiations with humans, or onhow they can move in a socially acceptable way. We propose a holistic approachin which the two aspects are jointly considered. Specifically, we show that bycombining opinion dynamics (to reach a consensus) with vortex fields (togenerate socially acceptable trajectories), the result outperforms theapplication of the two techniques in isolation.</description>
      <author>example@mail.com (Giulia d'Addato, Placido Falqueto, Luigi Palopoli, Daniele Fontanelli)</author>
      <guid isPermaLink="false">2411.04678v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Predictive Models for Healthcare via Rational Logistic Regression</title>
      <link>http://arxiv.org/abs/2411.03224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICIS 2021 Proceedings ( see
  https://aisel.aisnet.org/icis2021/is_health/is_health/18 )&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;医疗行业最近快速积累了数字数据，尤其是电子健康记录（EHRs）。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用EHR数据进行临床应用，例如疾病预测。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新模型叫做理性逻辑回归（RLR），其特殊案例为标准逻辑回归（LR），并基于理性级数，适用于纵向时间序列数据，学习可解释的模式。&lt;h4&gt;主要发现&lt;/h4&gt;实证比较显示RLR在真实世界临床任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;尽管深度学习在其他领域表现优异，但在EHR数据上，简单模型如逻辑回归同样表现良好，RLR模型提供了更具解释性的解决方案。&lt;h4&gt;总结&lt;/h4&gt;RLR模型通过结合逻辑回归的偏见和理性级数的理论基础，为EHR数据的分析提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The healthcare sector has experienced a rapid accumulation of digital datarecently, especially in the form of electronic health records (EHRs). EHRsconstitute a precious resource that IS researchers could utilize for clinicalapplications (e.g., morbidity prediction). Deep learning seems like the obviouschoice to exploit this surfeit of data. However, numerous studies have shownthat deep learning does not enjoy the same kind of success on EHR data as ithas in other domains; simple models like logistic regression are frequently asgood as sophisticated deep learning ones. Inspired by this observation, wedevelop a novel model called rational logistic regression (RLR) that hasstandard logistic regression (LR) as its special case (and thus inherits LR'sinductive bias that aligns with EHR data). RLR has rational series as itstheoretical underpinnings, works on longitudinal time-series data, and learnsinterpretable patterns. Empirical comparisons on real-world clinical tasksdemonstrate RLR's efficacy.</description>
      <author>example@mail.com (Thiti Suttaket, L Vivek Harsha Vardhan, Stanley Kok)</author>
      <guid isPermaLink="false">2411.03224v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Pedestrian Volume Prediction Using a Diffusion Convolutional Gated Recurrent Unit Model</title>
      <link>http://arxiv.org/abs/2411.03360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;有效的行人流分析和预测模型对于确保行人和其他道路用户的安全至关重要。&lt;h4&gt;目的&lt;/h4&gt;优化基础设施设计和几何形状，支持互联社区的经济效用。&lt;h4&gt;方法&lt;/h4&gt;利用城市范围内的自动行人计数系统收集数据，开发并训练深度学习应用，提出名为DCGRU-DTW的行人流预测模型。&lt;h4&gt;主要发现&lt;/h4&gt;该模型通过扩展扩散卷积门控递归单元（DCGRU）并结合动态时间规整，能够捕捉行人流的空间和时间依赖性。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的数值实验，证明所提出的模型在多个模型准确性指标上优于经典向量自回归模型和原始DCGRU。&lt;h4&gt;总结&lt;/h4&gt;该研究为行人流预测提供了一种新方法，利用真实数据提高了预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective models for analysing and predicting pedestrian flow are importantto ensure the safety of both pedestrians and other road users. These tools alsoplay a key role in optimising infrastructure design and geometry and supportingthe economic utility of interconnected communities. The implementation ofcity-wide automatic pedestrian counting systems provides researchers withinvaluable data, enabling the development and training of deep learningapplications that offer better insights into traffic and crowd flows.Benefiting from real-world data provided by the City of Melbourne pedestriancounting system, this study presents a pedestrian flow prediction model, as anextension of Diffusion Convolutional Grated Recurrent Unit (DCGRU) with dynamictime warping, named DCGRU-DTW. This model captures the spatial dependencies ofpedestrian flow through the diffusion process and the temporal dependencycaptured by Gated Recurrent Unit (GRU). Through extensive numericalexperiments, we demonstrate that the proposed model outperforms the classicvector autoregressive model and the original DCGRU across multiple modelaccuracy metrics.</description>
      <author>example@mail.com (Yiwei Dong, Tingjin Chu, Lele Zhang, Hadi Ghaderi, Hanfang Yang)</author>
      <guid isPermaLink="false">2411.03360v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Formal Logic-guided Robust Federated Learning against Poisoning Attacks</title>
      <link>http://arxiv.org/abs/2411.03231v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 4 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联邦学习（FL）通过去中心化的协作学习解决了集中式机器学习中的隐私问题，但面临多种安全威胁，尤其是数据中毒攻击。&lt;h4&gt;目的&lt;/h4&gt;开发一种防御机制，以应对联邦学习系统中的数据中毒攻击，特别是针对时间序列数据的独特挑战。&lt;h4&gt;方法&lt;/h4&gt;提出FLORAL防御机制，通过逻辑推理评估客户端的可信度，结合全球时间序列模式来验证客户端的更新，区别于传统的模型中心防御。&lt;h4&gt;主要发现&lt;/h4&gt;FLORAL在两个数据集上的实验结果显示，性能显著优于现有基线方法，在最佳情况下将预测误差降低了93.27%。&lt;h4&gt;结论&lt;/h4&gt;FLORAL有潜力增强联邦学习在时间序列应用中的鲁棒性，提供了一种新颖的应对数据中毒攻击的策略。&lt;h4&gt;总结&lt;/h4&gt;FLORAL通过逻辑推理和正式逻辑验证提高了联邦学习系统的安全性，为处理时间序列数据中的安全问题提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) offers a promising solution to the privacy concernsassociated with centralized Machine Learning (ML) by enabling decentralized,collaborative learning. However, FL is vulnerable to various security threats,including poisoning attacks, where adversarial clients manipulate the trainingdata or model updates to degrade overall model performance. Recognizing thisthreat, researchers have focused on developing defense mechanisms to counteractpoisoning attacks in FL systems. However, existing robust FL methodspredominantly focus on computer vision tasks, leaving a gap in addressing theunique challenges of FL with time series data. In this paper, we presentFLORAL, a defense mechanism designed to mitigate poisoning attacks in federatedlearning for time-series tasks, even in scenarios with heterogeneous clientdata and a large number of adversarial participants. Unlike traditionalmodel-centric defenses, FLORAL leverages logical reasoning to evaluate clienttrustworthiness by aligning their predictions with global time-series patterns,rather than relying solely on the similarity of client updates. Our approachextracts logical reasoning properties from clients, then hierarchically infersglobal properties, and uses these to verify client updates. Through formallogic verification, we assess the robustness of each client contribution,identifying deviations indicative of adversarial behavior. Experimental resultson two datasets demonstrate the superior performance of our approach comparedto existing baseline methods, highlighting its potential to enhance therobustness of FL to time series applications. Notably, FLORAL reduced theprediction error by 93.27% in the best-case scenario compared to thesecond-best baseline. Our code is available athttps://anonymous.4open.science/r/FLORAL-Robust-FTS.</description>
      <author>example@mail.com (Dung Thuy Nguyen, Ziyan An, Taylor T. Johnson, Meiyi Ma, Kevin Leach)</author>
      <guid isPermaLink="false">2411.03231v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Text Detection with Similar Mask in Traffic, Industrial, and Natural Scenes</title>
      <link>http://arxiv.org/abs/2411.02794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能交通场景中存在大量信息，充分利用这些信息是推动智能交通发展的关键因素。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的多场景文本检测器，以满足智能交通对快速推断速度和高准确度的需求。&lt;h4&gt;方法&lt;/h4&gt;该检测器包含有效的文本表示相似掩模(SM)和特征校正模块(FCM)，旨在尽可能保留几何信息，并优化特征预测。&lt;h4&gt;主要发现&lt;/h4&gt;SM在后处理上节省了50%的时间，准确有效地重建文本轮廓；FCM则优化了特征级别的预测，减少假阳性特征。&lt;h4&gt;结论&lt;/h4&gt;进行的广泛实验验证了该方法在多个基准测试上达到了最先进的性能，并解决了现有交通数据集的不足。&lt;h4&gt;总结&lt;/h4&gt;研究结果表明，所提方法在交通、工业和自然场景数据集上具有良好的鲁棒性，相关代码和数据集已公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/fengmulin/smnet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Texts on the intelligent transportation scene include mass information. Fullyharnessing this information is one of the critical drivers for advancingintelligent transportation. Unlike the general scene, detecting text intransportation has extra demand, such as a fast inference speed, except forhigh accuracy. Most existing real-time text detection methods are based on theshrink mask, which loses some geometry semantic information and needs complexpost-processing. In addition, the previous method usually focuses on correctoutput, which ignores feature correction and lacks guidance during theintermediate process. To this end, we propose an efficient multi-scene textdetector that contains an effective text representation similar mask (SM) and afeature correction module (FCM). Unlike previous methods, the former aims topreserve the geometric information of the instances as much as possible. Itspost-progressing saves 50$\%$ of the time, accurately and efficientlyreconstructing text contours. The latter encourages false positive features tomove away from the positive feature center, optimizing the predictions from thefeature level. Some ablation studies demonstrate the efficiency of the SM andthe effectiveness of the FCM. Moreover, the deficiency of existing trafficdatasets (such as the low-quality annotation or closed source dataunavailability) motivated us to collect and annotate a traffic text dataset,which introduces motion blur. In addition, to validate the scene robustness ofthe SM-Net, we conduct experiments on traffic, industrial, and natural scenedatasets. Extensive experiments verify it achieves (SOTA) performance onseveral benchmarks. The code and dataset are available at:\url{https://github.com/fengmulin/SMNet}.</description>
      <author>example@mail.com (Xu Han, Junyu Gao, Chuang Yang, Yuan Yuan, Qi Wang)</author>
      <guid isPermaLink="false">2411.02794v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Field Assessment of Force Torque Sensors for Planetary Rover Navigation</title>
      <link>http://arxiv.org/abs/2411.04700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;行星探测器上的本体感知传感器用于状态估计以及理解地形和运动性能。&lt;h4&gt;目的&lt;/h4&gt;评估力-扭矩传感器在行星导航中的性能和应用场景。&lt;h4&gt;方法&lt;/h4&gt;基于六轮探测器在不同地形、速度和坡度下的测试数据进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;力-扭矩传感器能够直接测量交互力，并提供对牵引性能的洞察。&lt;h4&gt;挑战&lt;/h4&gt;传感器信号可靠性和地形响应准确性是主要挑战。&lt;h4&gt;机会&lt;/h4&gt;识别了使用这些传感器的机会，特别是在传感器集成和控制算法方面。&lt;h4&gt;数据&lt;/h4&gt;数据公开可访问，包括每个轮子组件的力-扭矩测量和探测器底盘内的IMU数据。&lt;h4&gt;结论&lt;/h4&gt;该研究旨在为未来研究和探测器升级提供设计参考，以改善导航能力。&lt;h4&gt;总结&lt;/h4&gt;力-扭矩传感器在行星探测中的应用潜力值得进一步探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/spaceuma/fts-assessment&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Proprioceptive sensors on planetary rovers serve for state estimation and forunderstanding terrain and locomotion performance. While inertial measurementunits (IMUs) are widely used to this effect, force-torque sensors are lessexplored for planetary navigation despite their potential to directly measureinteraction forces and provide insights into traction performance. This paperpresents an evaluation of the performance and use cases of force-torque sensorsbased on data collected from a six-wheeled rover during tests over varyingterrains, speeds, and slopes. We discuss challenges, such as sensor signalreliability and terrain response accuracy, and identify opportunities regardingthe use of these sensors. The data is openly accessible and includesforce-torque measurements from each of the six-wheel assemblies as well as IMUdata from within the rover chassis. This paper aims to inform the design offuture studies and rover upgrades, particularly in sensor integration andcontrol algorithms, to improve navigation capabilities.</description>
      <author>example@mail.com (Levin Gerdes, Carlos Pérez del Pulgar, Raúl Castilla Arquillo, Martin Azkarate)</author>
      <guid isPermaLink="false">2411.04700v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>RopeTP: Global Human Motion Recovery via Integrating Robust Pose Estimation with Diffusion Trajectory Prior</title>
      <link>http://arxiv.org/abs/2410.20358v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WACV 2025 (Round 1)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究提出了RopeTP框架，旨在通过视频重建全球人类运动。&lt;h4&gt;目的&lt;/h4&gt;结合鲁棒的姿态估计和扩散轨迹先验，提升对人体姿态的推断精度，特别是在身体部位被遮挡的情况下。&lt;h4&gt;方法&lt;/h4&gt;RopeTP采用分层注意机制，利用可见的解剖结构关系来提高上下文意识，从而增强局部姿态估计的准确性，并结合扩散轨迹模型预测人类运动。&lt;h4&gt;主要发现&lt;/h4&gt;RopeTP在两个基准数据集上超过了现有方法，尤其在遮挡场景中表现优异。&lt;h4&gt;结论&lt;/h4&gt;RopeTP在不依赖SLAM进行初始相机估计和广泛优化的情况下，提供了更准确和真实的轨迹重建。&lt;h4&gt;总结&lt;/h4&gt;RopeTP通过改进的局部姿态估计和扩散轨迹模型，显著提升了3D人类运动重建的稳定性和真实感。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present RopeTP, a novel framework that combines Robust pose estimationwith a diffusion Trajectory Prior to reconstruct global human motion fromvideos. At the heart of RopeTP is a hierarchical attention mechanism thatsignificantly improves context awareness, which is essential for accuratelyinferring the posture of occluded body parts. This is achieved by exploitingthe relationships with visible anatomical structures, enhancing the accuracy oflocal pose estimations. The improved robustness of these local estimationsallows for the reconstruction of precise and stable global trajectories.Additionally, RopeTP incorporates a diffusion trajectory model that predictsrealistic human motion from local pose sequences. This model ensures that thegenerated trajectories are not only consistent with observed local actions butalso unfold naturally over time, thereby improving the realism and stability of3D human motion reconstruction. Extensive experimental validation shows thatRopeTP surpasses current methods on two benchmark datasets, particularlyexcelling in scenarios with occlusions. It also outperforms methods that relyon SLAM for initial camera estimates and extensive optimization, deliveringmore accurate and realistic trajectories.</description>
      <author>example@mail.com (Mingjiang Liang, Yongkang Cheng, Hualin Liang, Shaoli Huang, Wei Liu)</author>
      <guid isPermaLink="false">2410.20358v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>NinjaDoH: A Censorship-Resistant Moving Target DoH Server Using Hyperscalers and IPNS</title>
      <link>http://arxiv.org/abs/2411.02805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了一种新的DNS over HTTPS (DoH)协议，名为NinjaDoH，旨在应对网络审查。&lt;h4&gt;目的&lt;/h4&gt;创建一个抗审查的移动目标DoH服务，以规避传统的审查方法。&lt;h4&gt;方法&lt;/h4&gt;利用InterPlanetary Name System (IPNS)和公共云基础设施，不断改变服务器的网络标识符。&lt;h4&gt;主要发现&lt;/h4&gt;NinjaDoH显著增加了有效审查其流量的复杂性，同时不会干扰其他网络流量。&lt;h4&gt;结论&lt;/h4&gt;NinjaDoH被证明是一种强大的移动目标DNS解决方案，可以在严格的DNS审查环境中确保持续和安全的互联网访问。&lt;h4&gt;测试&lt;/h4&gt;评估了NinjaDoH在逃避商业防火墙和基于机器学习的检测系统方面的能力。&lt;h4&gt;总结&lt;/h4&gt;NinjaDoH的实施显示出其在高审查环境中的有效性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce NinjaDoH, a novel DNS over HTTPS (DoH) protocol that leveragesthe InterPlanetary Name System (IPNS), along with public cloud infrastructure,to create a censorship-resistant moving target DoH service. NinjaDoH isspecifically designed to evade traditional censorship methods that involveblocking DoH servers by IP addresses or domains by continually altering theserver's network identifiers, significantly increasing the complexity ofeffectively censoring NinjaDoH traffic without disruption of other web traffic.We also present an analysis that quantifies the DNS query latency and financialcosts of running our implementation of this protocol as a service. Furthertests assess the ability of NinjaDoH to elude detection mechanisms, includingboth commercial firewall products and advanced machine learning-based detectionsystems. The results broadly support NinjaDoH's efficacy as a robust, movingtarget DNS solution that can ensure continuous and secure internet access inenvironments with heavy DNS-based censorship.</description>
      <author>example@mail.com (Scott Seidenberger, Marc Beret, Raveen Wijewickrama, Murtuza Jadliwala, Anindya Maiti)</author>
      <guid isPermaLink="false">2411.02805v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Upcycling Human Excrement: The Gut Microbiome to Soil Microbiome Axis</title>
      <link>http://arxiv.org/abs/2411.04148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main text: 9 pages, 2 figures; Extended data: 10 figures;
  Supplemental Text: 32 pages, 8 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类排泄物堆肥化（HEC）是一种可持续的人类排泄物管理策略。&lt;h4&gt;目的&lt;/h4&gt;回收营养物质，减轻健康风险，同时减少对淡水、化石燃料和化肥的依赖。&lt;h4&gt;方法&lt;/h4&gt;进行了一年的微生物时间序列分析，跟踪了15个生物复制样本。&lt;h4&gt;主要发现&lt;/h4&gt;HEC系统的初始肠道微生物群落在一年内转变为类似于土壤和传统堆肥的微生物群落。&lt;h4&gt;结论&lt;/h4&gt;HEC能够有效地转化微生物群落，支持其作为可持续管理策略的潜力。&lt;h4&gt;总结&lt;/h4&gt;人类排泄物堆肥化不仅有助于资源回收，还能改善微生物群落结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human excrement composting (HEC) is a sustainable strategy for humanexcrement (HE) management that recycles nutrients and mitigates health riskswhile reducing reliance on freshwater, fossil fuels, and fertilizers. Wepresent a comprehensive microbial time series analysis of HEC and show that theinitial gut-like microbiome of HEC systems transitions to a microbiome similarto soil and traditional compost in fifteen biological replicates tracked weeklyfor one year.</description>
      <author>example@mail.com (Jeff Meilander, Chloe Herman, Andrew Manley, Georgia Augustine, Dawn Birdsell, Evan Bolyen, Kimberly R. Celona, Hayden Coffey, Jill Cocking, Teddy Donoghue, Alexis Draves, Daryn Erickson, Marissa Foley, Liz Gehret, Johannah Hagen, Crystal Hepp, Parker Ingram, David John, Katarina Kadar, Paul Keim, Victoria Lloyd, Christina Osterink, Victoria Queeney, Diego Ramirez, Antonio Romero, Megan C. Ruby, Jason W. Sahl, Sydni Soloway, Nathan E. Stone, Shannon Trottier, Kaleb Van Orden, Alexis Painter, Sam Wallace, Larissa Wilcox, Colin V. Wood, Jaiden Yancey, J. Gregory Caporaso)</author>
      <guid isPermaLink="false">2411.04148v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Learning from Demonstration with Hierarchical Policy Abstractions Toward High-Performance and Courteous Autonomous Racing</title>
      <link>http://arxiv.org/abs/2411.04735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全自动赛车不仅需要高速驾驶，还需要公平和礼貌的操控。&lt;h4&gt;目的&lt;/h4&gt;提出一个学习复杂赛车行为的自动化赛车框架。&lt;h4&gt;方法&lt;/h4&gt;使用层次化策略抽象，从专家演示中学习，并在轨迹层面预测轨迹的稠密分布图。&lt;h4&gt;主要发现&lt;/h4&gt;我们的轨迹规划策略显著优于竞争基线，残差控制策略提高了圈速和跟踪准确性。&lt;h4&gt;结论&lt;/h4&gt;在与十名对手的闭合实验中，框架能够理解细微的互动，超越其他车辆，有效平衡性能与礼貌。&lt;h4&gt;总结&lt;/h4&gt;该框架在高保真赛车模拟器中经过评估，验证了其在多智能体对抗场景中的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fully autonomous racing demands not only high-speed driving but also fair andcourteous maneuvers. In this paper, we propose an autonomous racing frameworkthat learns complex racing behaviors from expert demonstrations usinghierarchical policy abstractions. At the trajectory level, our policy modelpredicts a dense distribution map indicating the likelihood of trajectorieslearned from offline demonstrations. The maximum likelihood trajectory is thenpassed to the control-level policy, which generates control inputs in aresidual fashion, considering vehicle dynamics at the limits of performance. Weevaluate our framework in a high-fidelity racing simulator and compare itagainst competing baselines in challenging multi-agent adversarial scenarios.Quantitative and qualitative results show that our trajectory planning policysignificantly outperforms the baselines, and the residual control policyimproves lap time and tracking accuracy. Moreover, challenging closed-loopexperiments with ten opponents show that our framework can overtake othervehicles by understanding nuanced interactions, effectively balancingperformance and courtesy like professional drivers.</description>
      <author>example@mail.com (Chanyoung Chung, Hyunki Seong, David Hyunchul Shim)</author>
      <guid isPermaLink="false">2411.04735v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>New type of chaotic solutions found in Gravity model of network transport</title>
      <link>http://arxiv.org/abs/2411.02919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;重力模型是一种将牛顿万有引力定律应用于社会经济运输现象的数学模型，广泛用于描述世界贸易、城市间交通流和商业交易。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在分析定义在少节点网络上的重力模型的稳定性。&lt;h4&gt;方法&lt;/h4&gt;通过数值模拟详细分析重力模型在少节点网络上的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，除了已知的从唯一扩散解到多个局部解的平稳解转变外，还存在某些参数区域可以实现具有相同重复运动的周期解和无周期的混沌解。&lt;h4&gt;结论&lt;/h4&gt;发现具有混沌解的最小网络是一个由七个节点组成的环，这种网络产生了一种新的混沌解形式，即左右周期解的混合。&lt;h4&gt;总结&lt;/h4&gt;重力模型在网络中的行为呈现出复杂性，揭示了新的混沌特性和解的多样性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The gravity model is a mathematical model that applies Newton's universal lawof gravitation to socio-economic transport phenomena and has been widely usedto describe world trade, intercity traffic flows, and business transactions formore than several decades. However, its strong nonlinearity and diverse networktopology make a theoretical analysis difficult, and only a short history ofstudies on its stability exist. In this study, the stability of gravity modelsdefined on networks with few nodes is analyzed in detail using numericalsimulations. It was found that, other than the previously known transition ofstationary solutions from a unique diffusion solution to multiple localizedsolutions, parameter regions exist where periodic solutions with the samerepeated motions and chaotic solutions with no periods are realized. Thesmallest network with chaotic solutions was found to be a ring with sevennodes, which produced a new type of chaotic solution in the form of a mixtureof right and left periodic solutions.</description>
      <author>example@mail.com (Hajime Koike, Hideki Takayasu, Misako Takayasu)</author>
      <guid isPermaLink="false">2411.02919v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>TacEx: GelSight Tactile Simulation in Isaac Sim -- Combining Soft-Body and Visuotactile Simulators</title>
      <link>http://arxiv.org/abs/2411.04776v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, accepted at "CoRL Workshop on Learning Robot Fine and
  Dexterous Manipulation: Perception and Control"&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在模拟中训练机器人策略变得越来越流行，但缺乏一种精确、可靠且易于使用的触觉模拟器，特别是在接触丰富的操作任务中。&lt;h4&gt;目的&lt;/h4&gt;开发一个模块化的触觉模拟框架TacEx，以填补这一空白。&lt;h4&gt;方法&lt;/h4&gt;将先进的软体模拟器GIPC和基于视觉的触觉模拟器Taxim与FOTS嵌入Isaac Sim中，以实现GelSight Mini的稳健且可信的模拟。&lt;h4&gt;主要发现&lt;/h4&gt;实现了多种Isaac Lab环境以用于强化学习，包括物体推动、举起和杆平衡，并验证了模拟的稳定性。&lt;h4&gt;结论&lt;/h4&gt;高维观测（如胶体变形和GelSight相机的RGB图像）可用于训练，代码、视频和其他结果将在线发布。&lt;h4&gt;总结&lt;/h4&gt;TacEx框架为接触丰富的机器人操作任务提供了强大的模拟支持，推动了机器人领域的研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training robot policies in simulation is becoming increasingly popular;nevertheless, a precise, reliable, and easy-to-use tactile simulator forcontact-rich manipulation tasks is still missing. To close this gap, we developTacEx -- a modular tactile simulation framework. We embed a state-of-the-artsoft-body simulator for contacts named GIPC and vision-based tactile simulatorsTaxim and FOTS into Isaac Sim to achieve robust and plausible simulation of thevisuotactile sensor GelSight Mini. We implement several Isaac Lab environmentsfor Reinforcement Learning (RL) leveraging our TacEx simulation, includingobject pushing, lifting, and pole balancing. We validate that the simulation isstable and that the high-dimensional observations, such as the gel deformationand the RGB images from the GelSight camera, can be used for training. Thecode, videos, and additional results will be released onlinehttps://sites.google.com/view/tacex.</description>
      <author>example@mail.com (Duc Huy Nguyen, Tim Schneider, Guillaume Duret, Alap Kshirsagar, Boris Belousov, Jan Peters)</author>
      <guid isPermaLink="false">2411.04776v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>A Stochastic Dynamic Network Model of the Space Environment</title>
      <link>http://arxiv.org/abs/2411.03173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 pages, 28 figures, 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究将空间环境建模为一个随机动态网络，其中每个节点代表特定类别或种群的一组对象，节点之间的关系通过随机链接表示。&lt;h4&gt;目的&lt;/h4&gt;通过建立随机动态方程，研究网络的演变，并分析空间环境中对象种类和轨道模式的关键性。&lt;h4&gt;方法&lt;/h4&gt;推导出一组随机动态方程，分析网络结构和节点之间的关系，以了解哪些对象和轨道模式对未来空间环境演变影响最大。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的随机动态方程能够很好地重现现有的空间环境演变结果，并且通过稳定性理论分析空间的承载能力。&lt;h4&gt;结论&lt;/h4&gt;研究表明，采用不同政策对碰撞规避和任务后处置的操作有显著影响，网络模型可以有效用于此类研究。&lt;h4&gt;总结&lt;/h4&gt;本研究为理解空间环境的演变提供了新的视角，并为未来的政策制定和管理提供了理论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes to model the space environment as a stochastic dynamicnetwork where each node is a group of objects of a given class, or species, andtheir relationship is represented by stochastic links. A set of stochasticdynamic equations, governing the evolution of the network, are derived from thenetwork structure and topology. It will be shown that the proposed system ofstochastic dynamic equations well reproduces existing results on the evolutionof the space environment. The analysis of the structure of the network andrelationships among node can help to understand which species of objects andorbit regimes are more critical and affect the most the future evolution of thespace environment. In analogy with ecological networks, we develop a theory ofthe carrying capacity of space based on the stability of equilibria of thenetwork dynamics. Some examples are presented starting from the currentpopulation of resident objects and different launch traffic forecast models. Itwill be shown how the proposed network model can be used to study the effect ofthe adoption of different policies on the execution of collision avoidance andpost mission disposal manoeuvres.</description>
      <author>example@mail.com (Yirui Wang, Pietro De Marchi, Massimiliano Vasile)</author>
      <guid isPermaLink="false">2411.03173v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing quantum back-action for time-series processing</title>
      <link>http://arxiv.org/abs/2411.03979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;量子测量通过反作用影响被观察系统的状态。投影测量提取最大经典信息，但会显著改变系统状态；而弱测量在信息提取与干扰程度之间取得平衡。&lt;h4&gt;目的&lt;/h4&gt;探讨弱测量在量子计算和通信协议中的潜在益处，尤其是在量子机器学习协议中的应用。&lt;h4&gt;方法&lt;/h4&gt;将弱测量纳入量子水库计算协议，分析通过调整测量强度的不同测量设置，评估在两个基准任务中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;优化水库哈密顿量参数和测量强度可以显著提高量子水库计算算法的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了促进基于弱测量协议在量子水库计算中实施的全面实用方案，并激励进一步探索利用弱测量反作用效应的实验协议。&lt;h4&gt;总结&lt;/h4&gt;弱测量在量子机器学习中的应用具有重要的理论和实践意义，值得进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum measurements affect the state of the observed systems viaback-action. While projective measurements extract maximal classicalinformation, they drastically alter the system. In contrast, weak measurementsbalance information extraction with the degree of disturbance. Considering theprevalent use of projective measurements in quantum computing and communicationprotocols, the potential benefits of weak measurements in these fields remainlargely unexplored. In this work, we demonstrate that incorporating weakmeasurements into a quantum machine-learning protocol known as quantumreservoir computing provides advantages in both execution time scaling andoverall performance. We analyze different measurement settings by varying themeasurement strength across two benchmarking tasks. Our results reveal thatcarefully optimizing both the reservoir Hamiltonian parameters and themeasurement strength can significantly improve the quantum reservoir computingalgorithm performance. This work provides a comprehensive and practical recipeto promote the implementation of weak measurement-based protocols in quantumreservoir computing. Moreover, our findings motivate further exploration ofexperimental protocols that leverage the back-action effects of weakmeasurements.</description>
      <author>example@mail.com (Giacomo Franceschetto, Marcin Płodzień, Maciej Lewenstein, Antonio Acín, Pere Mujal)</author>
      <guid isPermaLink="false">2411.03979v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>AllGaits: Learning All Quadruped Gaits and Transitions</title>
      <link>http://arxiv.org/abs/2411.04787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究四足动物的行走方式及其转换，提升运动效率。&lt;h4&gt;目的&lt;/h4&gt;构建一个单一策略框架，能够生成所有四足动物的步态及其过渡。&lt;h4&gt;方法&lt;/h4&gt;使用深度强化学习（DRL）训练策略，调节抽象振荡器系统的参数，通过模式形成层将输出映射为关节指令。&lt;h4&gt;主要发现&lt;/h4&gt;不同步态通过改变振荡器之间的耦合形成，用户可以在任意速度下即时选择步态；研究表明，当前最受欢迎的步态（小跑）并非能实现最低的运输成本（COT），而不同的共依赖指标会导致不同的'最佳'步态。&lt;h4&gt;结论&lt;/h4&gt;在各种硬件实验中部署控制器，展示了九种典型四足动物步态，证明了训练过程中的未见步态的泛化能力和对腿部故障的鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;本研究为四足动物的步态控制提供了一种新颖的框架，强调了步态选择对能效的影响，并展示了其在实际应用中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a framework for learning a single policy capable of producing allquadruped gaits and transitions. The framework consists of a policy trainedwith deep reinforcement learning (DRL) to modulate the parameters of a systemof abstract oscillators (i.e. Central Pattern Generator), whose output ismapped to joint commands through a pattern formation layer that sets the gaitstyle, i.e. body height, swing foot ground clearance height, and foot offset.Different gaits are formed by changing the coupling between differentoscillators, which can be instantaneously selected at any velocity by a user.With this framework, we systematically investigate which gait should be used atwhich velocity, and when gait transitions should occur from a Cost of Transport(COT), i.e. energy-efficiency, point of view. Additionally, we note how gaitstyle changes as a function of locomotion speed for each gait to keep the mostenergy-efficient locomotion. While the currently most popular gait (trot) doesnot result in the lowest COT, we find that considering different co-dependentmetrics such as mean base velocity and joint acceleration result in different`optimal' gaits than those that minimize COT. We deploy our controller invarious hardware experiments, showing all 9 typical quadruped animal gaits, anddemonstrate generalizability to unseen gaits during training, and robustness toleg failures. Video results can be found at https://youtu.be/OLoWSX_R868.</description>
      <author>example@mail.com (Guillaume Bellegarda, Milad Shafiee, Auke Ijspeert)</author>
      <guid isPermaLink="false">2411.04787v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>A Traffic Prediction-Based Individualized Driver Warning System to Reduce Red Light Violations</title>
      <link>http://arxiv.org/abs/2411.03271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to TR-C&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;红灯违规是交通事故及伤亡的重要原因，尽管已有大量研究致力于减少红灯违规，但问题仍然严重。&lt;h4&gt;目的&lt;/h4&gt;提供个性化的警告，以改善现有系统对所有驾驶者的统一指导问题。&lt;h4&gt;方法&lt;/h4&gt;提出一个包含三个部分的警告系统：交通预测算法、个体警告信号优化器和驾驶员警告显示。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能根据实时交通状态和驾驶行为，动态调整警告信号，从而有效帮助驾驶员避免红灯违规。&lt;h4&gt;结论&lt;/h4&gt;该系统在不同条件下的仿真和实地测试中表现优越，能提供更有效、准确的警告信号。&lt;h4&gt;总结&lt;/h4&gt;通过个性化警告，系统显著提高了驾驶员的安全性，减少了红灯违规的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Red light violation is a major cause of traffic collisions and resultinginjuries and fatalities. Despite extensive prior work to reduce red lightviolations, they continue to be a major problem in practice, partly becauseexisting systems suffer from the flaw of providing the same guidance to alldrivers. As a result, some violations are avoided, but other drivers ignore orrespond inappropriately to red light running systems, resulting in safetyissues overall. We show a method of providing accurate warnings to individualdrivers to avoid the broad guidance approach of most existing systems.Recognizing if a driver will run red lights is highly dependent on signal phaseand timing, traffic conditions along the road, and individual driver behaviour,the proposed warning system contains three parts: a traffic predictionalgorithm, an individual warning signal optimizer, and a driver warningdisplay. The traffic prediction algorithm predicts future traffic states alongthe road towards the signalized intersections using the latest trafficconditions obtained through vehicle-to-vehicle and vehicle-to-infrastructurecommunications. Then, an optimization problem is formulated to compute theoptimal warning signal based on predicted traffic states and driver reactionmodel. Finally, the optimal warning signal is shown on the display screen toadvise driver on how much braking is needed to avoid running the red light. Thesystem continuously updates the latest warning signal as the vehicle isapproaching the intersection. Both numerical simulated driving scenarios andreal-world road tests are used to demonstrate the proposed algorithm'sperformance under different conditions by comparing with previous work on redlight running warning system. The results show that the system provides moreeffective and accurate warning signals to drivers, helping them avoid runningred lights.</description>
      <author>example@mail.com (Suiyi He, Maziar Zamanpour, Jianshe Guo, Michael W. Levin, Zongxuan Sun)</author>
      <guid isPermaLink="false">2411.03271v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Distributed Attack-Resilient Platooning Against False Data Injection</title>
      <link>http://arxiv.org/abs/2411.04789v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文提出了一种新颖的分布式车辆编队控制与协调策略。&lt;h4&gt;目的&lt;/h4&gt;开发一种允许车辆间距任意小的前驱-跟随CACC方案，同时确保在未检测到的网络攻击下不会发生追尾事故。&lt;h4&gt;方法&lt;/h4&gt;结合基于传感器的ACC策略和基于通信的预测控制项，确保在不可靠的通信环境中控制效果受限。&lt;h4&gt;主要发现&lt;/h4&gt;尽管存在未检测的攻击，仍可能降低编队性能。提出了一种基于卡尔曼观测器的攻击检测算法，以应对该问题。&lt;h4&gt;结论&lt;/h4&gt;通过高层协调器将受损车辆从编队中隔离，并能处理合并与拆分请求，增强了编队的安全性与灵活性。&lt;h4&gt;实验&lt;/h4&gt;通过模拟与实际系统测试（缩小版车队）对比验证了算法的有效性，并分享了相关代码。&lt;h4&gt;总结&lt;/h4&gt;该研究为提高车辆编队在网络攻击下的安全性和性能提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel distributed vehicle platooning control andcoordination strategy. We propose a distributed predecessor-follower CACCscheme that allows to choose an arbitrarily small inter-vehicle distance whileguaranteeing no rear-end collisions occur, even in the presence of undetectedcyber-attacks on the communication channels such as false data injection. Thesafety guarantees of the CACC policy are derived by combing a sensor-based ACCpolicy that explicitly accounts for actuator saturation, and acommunication-based predictive term that has state-dependent limits on itscontrol authority, thus containing the effects of an unreliable communicationchannel. An undetected attack may still however be able to degrade platooningperformance. To mitigate it, we propose a tailored Kalman observer-based attackdetection algorithm that initially triggers a switch from the CACC policy tothe ACC policy. Subsequently, by relying on a high-level coordinator, ourstrategy allows to isolate a compromised vehicle from the platoon formation byreconfiguring the platoon topology itself. The coordinator can also handlemerging and splitting requests. We compare our algorithm in simulation againsta state of the art distributed MPC scheme and we extensively test our fullmethod in practice on a real system, a team of scaled-down car-like robots.Furthermore, we share the code to run both the simulations and roboticexperiments.</description>
      <author>example@mail.com (Lorenzo Lyons, Manuel Boldrer, Laura Ferranti)</author>
      <guid isPermaLink="false">2411.04789v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Towards Resource-Efficient Federated Learning in Industrial IoT for Multivariate Time Series Analysis</title>
      <link>http://arxiv.org/abs/2411.03996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;异常和缺失数据在工业应用中是一个棘手的问题，深度学习驱动的异常检测成为一个关键方向。&lt;h4&gt;目的&lt;/h4&gt;提高异常检测的准确性，同时降低大规模神经网络的存储和计算成本。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于压缩的优化问题，通过对接收到的本地模型进行剪枝，生成更压缩的模型。&lt;h4&gt;主要发现&lt;/h4&gt;在异常检测和缺失值插补的实验中，所提方法实现了超过99.7%的压缩率，性能损失低于1.18%。&lt;h4&gt;结论&lt;/h4&gt;所提出的联邦学习场景及其压缩方法相比于集中式解决方案，能够显著降低处理、存储和通信复杂性。&lt;h4&gt;总结&lt;/h4&gt;该研究在保持高效异常检测的同时，通过模型压缩优化提升了联邦学习的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly and missing data constitute a thorny problem in industrialapplications. In recent years, deep learning enabled anomaly detection hasemerged as a critical direction, however the improved detection accuracy isachieved with the utilization of large neural networks, increasing theirstorage and computational cost. Moreover, the data collected in edge devicescontain user privacy, introducing challenges that can be successfully addressedby the privacy-preserving distributed paradigm, known as federated learning(FL). This framework allows edge devices to train and exchange modelsincreasing also the communication cost. Thus, to deal with the increasedcommunication, processing and storage challenges of the FL based deep anomalydetection NN pruning is expected to have significant benefits towards reducingthe processing, storage and communication complexity. With this focus, a novelcompression-based optimization problem is proposed at the server-side of a FLparadigm that fusses the received local models broadcast and performs pruninggenerating a more compressed model. Experiments in the context of anomalydetection and missing value imputation demonstrate that the proposed FLscenario along with the proposed compressed-based method are able to achievehigh compression rates (more than $99.7\%$) with negligible performance losses(less than $1.18\%$ ) as compared to the centralized solutions.</description>
      <author>example@mail.com (Alexandros Gkillas, Aris Lalos)</author>
      <guid isPermaLink="false">2411.03996v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge</title>
      <link>http://arxiv.org/abs/2410.10285v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages with references, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，边缘人工智能在各个行业中变得越来越普遍，应用于环境监测和智慧城市管理等领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的时间序列分类模型，适用于资源受限的边缘环境。&lt;h4&gt;方法&lt;/h4&gt;提出自适应布朗桥符号聚合向量空间模型（ABBA-VSM），通过将原始时间序列压缩成符号表示来进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;ABBA-VSM在二元分类中实现了高达80%的压缩比和90-100%的准确率，非二元分类平均压缩比为60%，准确率在60-80%之间。&lt;h4&gt;结论&lt;/h4&gt;ABBA-VSM有效减少了物联网设备与边缘设备之间的通信数据和计算周期，适用于资源高效的时间序列分类服务。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了ABBA-VSM在边缘计算环境中的应用潜力，能够提供高效的时间序列分类解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Edge AI has become more prevalent with applications acrossvarious industries, from environmental monitoring to smart city management.Edge AI facilitates the processing of Internet of Things (IoT) data andprovides privacy-enabled and latency-sensitive services to application usersusing Machine Learning (ML) algorithms, e.g., Time Series Classification (TSC).However, existing TSC algorithms require access to full raw data and demandsubstantial computing resources to train and use them effectively in runtime.This makes them impractical for deployment in resource-constrained Edgeenvironments. To address this, in this paper, we propose an Adaptive BrownianBridge-based Symbolic Aggregation Vector Space Model (ABBA-VSM). It is a newTSC model designed for classification services on Edge. Here, we firstadaptively compress the raw time series into symbolic representations, thuscapturing the changing trends of data. Subsequently, we train theclassification model directly on these symbols. ABBA-VSM reduces communicationdata between IoT and Edge devices, as well as computation cycles, in thedevelopment of resource-efficient TSC services on Edge. We evaluate oursolution with extensive experiments using datasets from the UCR time seriesclassification archive. The results demonstrate that the ABBA-VSM achieves upto 80% compression ratio and 90-100% accuracy for binary classification.Whereas, for non-binary classification, it achieves an average compressionratio of 60% and accuracy ranging from 60-80%.</description>
      <author>example@mail.com (Meerzhan Kanatbekova, Shashikant Ilager, Ivona Brandic)</author>
      <guid isPermaLink="false">2410.10285v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Effective Capacity of a Battery Energy Storage System Captive to a Wind Farm</title>
      <link>http://arxiv.org/abs/2411.04274v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;风能在全球电网中的作用预计将显著扩大，纽约州预计到2035年，离岸风电场将贡献9GW的电力。&lt;h4&gt;目的&lt;/h4&gt;研究与电池储能系统（BESS）配对的风电场，确定具有特定能量和功率等级的BESS的容量信用。&lt;h4&gt;方法&lt;/h4&gt;定义了一种功率对齐函数，采用线性规划方法进行解决，分析使用了NYSERDA收集的长岛海岸的风能数据和NYISO的负荷需求数据。&lt;h4&gt;主要发现&lt;/h4&gt;提出了BESS尺寸的理论见解以及影响BESS容量的关键时间序列特性，帮助模拟风能和需求以估算BESS的能量需求。&lt;h4&gt;结论&lt;/h4&gt;BESS的容量定义和增量容量的简单化提供了新的理解，有助于风能的有效整合与储存。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了风电与电池存储配合的重要性，为未来的能源存储和风能利用提供了理论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wind energy's role in the global electric grid is set to expandsignificantly. New York State alone anticipates offshore wind farms (WFs)contributing 9GW by 2035. Integration of energy storage emerges as crucial forthis advancement. In this study, we focus on a WF paired with a captive batteryenergy storage system (BESS). We aim to ascertain the capacity credit for aBESS with specified energy and power ratings. Unlike prior methods rooted inreliability theory, we define a power alignment function, which leads to astraightforward definition of capacity and incremental capacity for the BESS.We develop a solution method based on a linear programming formulation. Ouranalysis utilizes wind data, collected by NYSERDA off Long Island's coast andload demand data from NYISO. Additionally, we present theoretical insights intoBESS sizing and a key time-series property influencing BESS capacity, aiding insimulating wind and demand for estimating BESS energy requirements.</description>
      <author>example@mail.com (Vinay A. Vaishampayan, Thilaharani Antony, Amirthagunaraj Yogarathnam)</author>
      <guid isPermaLink="false">2411.04274v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>A Continuification-Based Control Solution for Large-Scale Shepherding</title>
      <link>http://arxiv.org/abs/2411.04791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究大规模牧羊控制问题，涉及大量跟随者（目标）在指定区域内的约束。&lt;h4&gt;目的&lt;/h4&gt;通过可控的领导者（牧羊人）间接互动，确保跟随者被限制在目标区域内。&lt;h4&gt;方法&lt;/h4&gt;将微观的代理动态转化为宏观的连续模型，使用偏微分方程（PDEs）进行建模。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了高效且可扩展的控制设计，确保了全局收敛性。&lt;h4&gt;结论&lt;/h4&gt;在混合现实群体机器人框架中的数值和实验验证表明该方法有效。&lt;h4&gt;总结&lt;/h4&gt;提出的策略为大规模牧羊控制问题提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we address the large-scale shepherding control problem using acontinuification-based strategy. We consider a scenario in which a large groupof follower agents (targets) must be confined within a designated goal regionthrough indirect interactions with a controllable set of leader agents(herders). Our approach transforms the microscopic agent-based dynamics into amacroscopic continuum model via partial differential equations (PDEs). Thisformulation enables efficient, scalable control design for the herders'behavior, with guarantees of global convergence. Numerical and experimentalvalidations in a mixed-reality swarm robotics framework demonstrate themethod's effectiveness.</description>
      <author>example@mail.com (Beniamino Di Lorenzo, Gian Carlo Maffettone, Mario di Bernardo)</author>
      <guid isPermaLink="false">2411.04791v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>TwiNet: Connecting Real World Networks to their Digital Twins Through a Live Bidirectional Link</title>
      <link>http://arxiv.org/abs/2411.03503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures, conference paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无线频谱的复杂性日益增加，带来了挑战和机遇，强调了实时解决方案和强大数据处理能力的必要性。&lt;h4&gt;目的&lt;/h4&gt;引入数字双胞胎（Digital Twin, DT）技术，以提升无线通信的预测维护、资源分配和故障排除能力，增强网络可靠性。&lt;h4&gt;方法&lt;/h4&gt;提出TwiNet，建立真实世界无线频谱场景与DT复制品之间的双向近实时链接，使用MQTT协议实现平均14毫秒的数据传输延迟，适合实时通信。&lt;h4&gt;主要发现&lt;/h4&gt;在两种用例中评估TwiNet的性能：1) 在安全自适应数据速率（SADR）系统中评估用户设备的风险流量配置，网络性能提高约15%；2) 针对被干扰的信号进行新的卷积神经网络（CNN）部署，训练准确率达到97%，在2分钟内部署新模型以应对持续的对手。&lt;h4&gt;结论&lt;/h4&gt;TwiNet能够快速部署和适应DT，解决现代无线通信系统中的关键挑战。&lt;h4&gt;总结&lt;/h4&gt;TwiNet提高了无线通信的实时性和可靠性，展示了DT在频谱管理中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Only the chairs can edit The wireless spectrum's increasing complexity poseschallenges and opportunities, highlighting the necessity for real-timesolutions and robust data processing capabilities. Digital Twin (DT), virtualreplicas of physical systems, integrate real-time data to mirror theirreal-world counterparts, enabling precise monitoring and optimization.Incorporating DTs into wireless communication enhances predictive maintenance,resource allocation, and troubleshooting, thus bolstering network reliability.Our paper introduces TwiNet, enabling bidirectional, near-realtime linksbetween real-world wireless spectrum scenarios and DT replicas. Utilizing theprotocol, MQTT, we can achieve data transfer times with an average latency of14 ms, suitable for real-time communication. This is confirmed by monitoringreal-world traffic and mirroring it in real-time within the DT's wirelessenvironment. We evaluate TwiNet's performance in two use cases: (i) assessingrisky traffic configurations of UEs in a Safe Adaptive Data Rate (SADR) system,improving network performance by approximately 15% compared to original networkselections; and (ii) deploying new CNNs in response to jammed pilots, achievingup to 97% accuracy training on artificial data and deploying a new model in aslow as 2 minutes to counter persistent adversaries. TwiNet enables swiftdeployment and adaptation of DTs, addressing crucial challenges in modernwireless communication systems.</description>
      <author>example@mail.com (Clifton Paul Robinson, Andrea Lacava, Pedram Johari, Francesca Cuomo, Tommaso Melodia)</author>
      <guid isPermaLink="false">2411.03503v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation</title>
      <link>http://arxiv.org/abs/2411.04796v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in 50SFM Workshop of the 18th European Conference on
  Computer Vision (ECCV) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉里程计（VO）在室内环境中对具身代理的准确导航至关重要，尤其是在GPS和指南针传感器不可靠的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种稳健且样本效率高的视觉里程计流程，以解决传统方法在宽基线场景中的挑战。&lt;h4&gt;方法&lt;/h4&gt;该流程采用基于运动先验的几何VO模块，无需训练即可估计粗略相对位姿，然后由深度学习VO模型进一步优化，最终生成精细的相对位姿供导航策略使用。&lt;h4&gt;主要发现&lt;/h4&gt;该策略使得我们的流程在训练期间实现了高达2倍的样本效率，并在点目标导航任务中表现出优越的准确性和鲁棒性，超过了现有最先进的VO方法。&lt;h4&gt;结论&lt;/h4&gt;希望此方法能够引导将运动先验从多个来源结合使用，以提升视觉里程计的估计，并在具身导航任务中取得更好的结果。&lt;h4&gt;总结&lt;/h4&gt;通过在AI-Habitat模拟器中使用Gibson数据集的真实室内环境，对所提方法进行了评估，采用了导航指标和位姿指标进行验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual odometry (VO) is essential for enabling accurate point-goal navigationof embodied agents in indoor environments where GPS and compass sensors areunreliable and inaccurate. However, traditional VO methods face challenges inwide-baseline scenarios, where fast robot motions and low frames per second(FPS) during inference hinder their performance, leading to drift andcatastrophic failures in point-goal navigation. Recent deep-learned VO methodsshow robust performance but suffer from sample inefficiency during training;hence, they require huge datasets and compute resources. So, we propose arobust and sample-efficient VO pipeline based on motion priors available whilean agent is navigating an environment. It consists of a training-freeaction-prior based geometric VO module that estimates a coarse relative posewhich is further consumed as a motion prior by a deep-learned VO model, whichfinally produces a fine relative pose to be used by the navigation policy. Thisstrategy helps our pipeline achieve up to 2x sample efficiency during trainingand demonstrates superior accuracy and robustness in point-goal navigationtasks compared to state-of-the-art VO method(s). Realistic indoor environmentsof the Gibson dataset is used in the AI-Habitat simulator to evaluate theproposed approach using navigation metrics (like success/SPL) and pose metrics(like RPE/ATE). We hope this method further opens a direction of work wheremotion priors from various sources can be utilized to improve VO estimates andachieve better results in embodied navigation tasks.</description>
      <author>example@mail.com (Sayan Paul, Ruddra dev Roychoudhury, Brojeshwar Bhowmick)</author>
      <guid isPermaLink="false">2411.04796v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning</title>
      <link>http://arxiv.org/abs/2411.04285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in the Proceedings of the 4th Machine Learning for
  Health symposium, Proceedings of Machine Learning Research (PMLR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;使用监督机器学习预测长期患者结果是一项具有挑战性的任务，部分原因是每位患者的轨迹变化很大，这可能导致模型在训练数据上过拟合。&lt;h4&gt;目的&lt;/h4&gt;评估时间差学习（TD学习）在长期健康结果预测中的表现，特别是在与传统监督学习方法的比较中。&lt;h4&gt;方法&lt;/h4&gt;定义一个框架，通过半马尔可夫奖励过程将TD学习应用于实时不规则采样的时间序列数据。&lt;h4&gt;主要发现&lt;/h4&gt;在预测重症监护死亡率时，TD学习框架比标准监督学习方法表现出更好的模型稳健性，且在外部数据集验证时这一稳健性得以保持。&lt;h4&gt;结论&lt;/h4&gt;该方法在使用高方差不规则时间序列数据学习预测患者结果时，可能提供更可靠的预测手段。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了TD学习在医疗健康领域的应用潜力，尤其是在处理复杂的患者轨迹数据时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tdgfrost/td-icu-mortality&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The task of predicting long-term patient outcomes using supervised machinelearning is a challenging one, in part because of the high variance of eachpatient's trajectory, which can result in the model over-fitting to thetraining data. Temporal difference (TD) learning, a common reinforcementlearning technique, may reduce variance by generalising learning to the patternof state transitions rather than terminal outcomes. However, in healthcare thismethod requires several strong assumptions about patient states, and thereappears to be limited literature evaluating the performance of TD learningagainst traditional supervised learning methods for long-term health outcomeprediction tasks. In this study, we define a framework for applying TD learningto real-time irregularly sampled time series data using a Semi-Markov RewardProcess. We evaluate the model framework in predicting intensive care mortalityand show that TD learning under this framework can result in improved modelrobustness compared to standard supervised learning methods. and that thisrobustness is maintained even when validated on external datasets. Thisapproach may offer a more reliable method when learning to predict patientoutcomes using high-variance irregular time series data.</description>
      <author>example@mail.com (Thomas Frost, Kezhi Li, Steve Harris)</author>
      <guid isPermaLink="false">2411.04285v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Privacy Preserving Mechanisms for Coordinating Airspace Usage in Advanced Air Mobility</title>
      <link>http://arxiv.org/abs/2411.03582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 7 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;先进空中出行（AAM）操作预计将改变空中交通运输，同时对当前的空中交通管理实践提出挑战。&lt;h4&gt;目的&lt;/h4&gt;通过引入一种新颖的基于市场的机制，解决容量受限空域对AAM车辆的按需分配问题。&lt;h4&gt;方法&lt;/h4&gt;将空域和空中基础设施建模为一系列连续区域，限制同时进入、停留或退出各区域的车辆数量。使用时间扩展图的结构将分配问题形式化为路径分配问题，并引入“空中信用”预算机制以保护AAM车辆的成本信息。&lt;h4&gt;主要发现&lt;/h4&gt;提出的机制确保满足容量约束，资源价格为正时表示部门容量被充分利用，且分配对每个AAM车辆是整体且最优的，尽管可能并不总存在整体分配的竞争均衡。&lt;h4&gt;结论&lt;/h4&gt;提供了存在和计算分数竞争均衡的充分条件，并提出了一种分布式迭代两步算法，验证了该方法在无人机送货和空中出租车等新兴城市空中出行服务中的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究为AAM车辆的空域分配提供了理论基础和实用算法，推动了城市空中出行服务的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advanced Air Mobility (AAM) operations are expected to transform airtransportation while challenging current air traffic management practices. Byintroducing a novel market-based mechanism, we address the problem of on-demandallocation of capacity-constrained airspace to AAM vehicles with heterogeneousand private valuations. We model airspace and air infrastructure as acollection of contiguous regions with constraints on the number of vehiclesthat simultaneously enter, stay, or exit each region. Vehicles request accessto the airspace with trajectories spanning multiple regions at different times.We use the graph structure of our airspace model to formulate the allocationproblem as a path allocation problem on a time-extended graph. To ensure thecost information of AAM vehicles remains private, we introduce a novelmechanism that allocates each vehicle a budget of "air-credits" and anonymouslycharges prices for traversing the edges of the time-extended graph. We seek tocompute a competitive equilibrium that ensures that: (i) capacity constraintsare satisfied, (ii) a strictly positive resource price implies that the sectorcapacity is fully utilized, and (iii) the allocation is integral and optimalfor each AAM vehicle given current prices, without requiring access toindividual vehicle utilities. However, a competitive equilibrium with integralallocations may not always exist. We provide sufficient conditions for theexistence and computation of a fractional-competitive equilibrium, whereallocations can be fractional. Building on these theoretical insights, wepropose a distributed, iterative, two-step algorithm that: 1) computes afractional competitive equilibrium, and 2) derives an integral allocation fromthis equilibrium. We validate the effectiveness of our approach in allocatingtrajectories for two emerging urban air mobility services: drone delivery andair taxis.</description>
      <author>example@mail.com (Chinmay Maheshwari, Maria G. Mendoza, Victoria Marie Tuck, Pan-Yang Su, Victor L. Qin, Sanjit A. Seshia, Hamsa Balakrishnan, Shankar Sastry)</author>
      <guid isPermaLink="false">2411.03582v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>An Experimental Study on Decomposition-Based Deep Ensemble Learning for Traffic Flow Forecasting</title>
      <link>http://arxiv.org/abs/2411.03588v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted by the 2024 Australasian Joint Conference
  on Artificial Intelligence (AJCAI 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交通流量预测是智能交通系统中的一个重要任务。深度学习为此提供了有效的解决方案，能够捕捉时间序列交通流数据中的复杂模式，以实现准确预测。&lt;h4&gt;目的&lt;/h4&gt;研究分解基础的深度集成学习方法与非分解基础方法的表现，以解决深度学习模型过拟合的问题。&lt;h4&gt;方法&lt;/h4&gt;将时间序列数据分解为多个简单信号，然后基于这些信号构建和集成深度学习模型，以生成最终预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，分解基础的集成方法在三个交通数据集上的表现优于非分解基础的方法，同时也显示出对聚合策略和预测时间范围的敏感性。&lt;h4&gt;结论&lt;/h4&gt;分解基础的集成学习方法在交通流量预测中具有优势，但需注意其对不同策略和时间范围的敏感性。&lt;h4&gt;总结&lt;/h4&gt;本研究为交通流量预测提供了新的思路，强调了分解方法的有效性和应用时的考量因素。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic flow forecasting is a crucial task in intelligent transport systems.Deep learning offers an effective solution, capturing complex patterns intime-series traffic flow data to enable the accurate prediction. However, deeplearning models are prone to overfitting the intricate details of flow data,leading to poor generalisation. Recent studies suggest that decomposition-baseddeep ensemble learning methods may address this issue by breaking down a timeseries into multiple simpler signals, upon which deep learning models are builtand ensembled to generate the final prediction. However, few studies havecompared the performance of decomposition-based ensemble methods withnon-decomposition-based ones which directly utilise raw time-series data. Thiswork compares several decomposition-based and non-decomposition-based deepensemble learning methods. Experimental results on three traffic datasetsdemonstrate the superiority of decomposition-based ensemble methods, while alsorevealing their sensitivity to aggregation strategies and forecasting horizons.</description>
      <author>example@mail.com (Qiyuan Zhu, A. K. Qin, Hussein Dia, Adriana-Simona Mihaita, Hanna Grzybowska)</author>
      <guid isPermaLink="false">2411.03588v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Series-to-Series Diffusion Bridge Model</title>
      <link>http://arxiv.org/abs/2411.04491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;扩散模型在时间序列预测中崭露头角，展示了其强大的复杂数据分布建模能力。&lt;h4&gt;目的&lt;/h4&gt;重新审视时间序列扩散模型，提出一个全面的框架以涵盖现有的扩散方法。&lt;h4&gt;方法&lt;/h4&gt;提出一种新型的基于扩散的时间序列预测模型，称为系列到系列扩散桥模型（S^2DBM），利用布朗桥过程减少反向估计中的随机性，并结合历史时间序列数据的有用先验和条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，S^2DBM在点对点预测中表现优越，并在概率预测方面与其他扩散模型有效竞争。&lt;h4&gt;结论&lt;/h4&gt;S^2DBM通过改进的随机性控制和信息整合，显著提升了预测准确性。&lt;h4&gt;总结&lt;/h4&gt;本文提出的S^2DBM为时间序列预测提供了一种新的有效方法，克服了传统扩散模型的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have risen to prominence in time series forecasting,showcasing their robust capability to model complex data distributions.However, their effectiveness in deterministic predictions is often constrainedby instability arising from their inherent stochasticity. In this paper, werevisit time series diffusion models and present a comprehensive framework thatencompasses most existing diffusion-based methods. Building on this theoreticalfoundation, we propose a novel diffusion-based time series forecasting model,the Series-to-Series Diffusion Bridge Model ($\mathrm{S^2DBM}$), whichleverages the Brownian Bridge process to reduce randomness in reverseestimations and improves accuracy by incorporating informative priors andconditions derived from historical time series data. Experimental resultsdemonstrate that $\mathrm{S^2DBM}$ delivers superior performance inpoint-to-point forecasting and competes effectively with other diffusion-basedmodels in probabilistic forecasting.</description>
      <author>example@mail.com (Hao Yang, Zhanbo Feng, Feng Zhou, Robert C Qiu, Zenan Ling)</author>
      <guid isPermaLink="false">2411.04491v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Data Matters: The Case of Predicting Mobile Cellular Traffic</title>
      <link>http://arxiv.org/abs/2411.02418v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确预测基站的流量负载对移动蜂窝运营商及其用户至关重要，支持网络资源的有效利用，促进智能城市和道路的可持续发展。&lt;h4&gt;目的&lt;/h4&gt;探索智能道路的交通测量，以建模蜂窝流量生成过程，从而提高预测性能。&lt;h4&gt;方法&lt;/h4&gt;结合道路流量和速度指标，以及蜂窝网络指标进行综合实验。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入道路流量和速度，蜂窝负载预测误差可减少多达56.5%。&lt;h4&gt;结论&lt;/h4&gt;利用外部交通因素可以显著提高蜂窝流量预测的准确性。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，结合道路交通数据和蜂窝网络数据能够有效改善流量负载预测效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate predictions of base stations' traffic load are essential to mobilecellular operators and their users as they support the efficient use of networkresources and sustain smart cities and roads. Traditionally, cellular networktime-series have been considered for this prediction task. More recently,exogenous factors such as points of presence and other environmental knowledgehave been introduced to facilitate cellular traffic forecasting. In this study,we focus on smart roads and explore road traffic measures to model theprocesses underlying cellular traffic generation with the goal to improveprediction performance. Comprehensive experiments demonstrate that by employingroad flow and speed, in addition to cellular network metrics, cellular loadprediction errors can be reduced by as much as 56.5 %. The code and moredetailed results are available on https://github.com/nvassileva/DataMatters.</description>
      <author>example@mail.com (Natalia Vesselinova, Matti Harjula, Pauliina Ilmonen)</author>
      <guid isPermaLink="false">2411.02418v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>D$^3$epth: Self-Supervised Depth Estimation with Dynamic Mask in Dynamic Scenes</title>
      <link>http://arxiv.org/abs/2411.04826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Open sourced&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度估计是机器人技术中的一项关键技术。自监督深度估计方法能够高效利用大量未标记的现实数据，展现出巨大的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出D$^3$epth，一种针对动态场景的自监督深度估计新方法，解决现有方法在动态环境中的适应性问题。&lt;h4&gt;方法&lt;/h4&gt;从两个关键角度应对动态物体问题：1. 设计重投影约束来识别可能包含动态物体的区域，构建动态掩模以减轻其对损失的影响；2. 引入成本体积自动掩模策略，利用相邻帧识别与动态物体相关的区域并生成掩模。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI和Cityscapes数据集上的广泛实验表明，所提出的方法在自监督单目深度估计基线中表现一致优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;D$^3$epth有效地解决了动态环境中的深度估计问题，具有较好的实用性和适应性。&lt;h4&gt;总结&lt;/h4&gt;D$^3$epth通过引入动态掩模和光谱熵不确定性模块，提升了动态场景下的自监督深度估计性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depth estimation is a crucial technology in robotics. Recently,self-supervised depth estimation methods have demonstrated great potential asthey can efficiently leverage large amounts of unlabelled real-world data.However, most existing methods are designed under the assumption of staticscenes, which hinders their adaptability in dynamic environments. To addressthis issue, we present D$^3$epth, a novel method for self-supervised depthestimation in dynamic scenes. It tackles the challenge of dynamic objects fromtwo key perspectives. First, within the self-supervised framework, we design areprojection constraint to identify regions likely to contain dynamic objects,allowing the construction of a dynamic mask that mitigates their impact at theloss level. Second, for multi-frame depth estimation, we introduce a costvolume auto-masking strategy that leverages adjacent frames to identify regionsassociated with dynamic objects and generate corresponding masks. This providesguidance for subsequent processes. Furthermore, we propose a spectral entropyuncertainty module that incorporates spectral entropy to guide uncertaintyestimation during depth fusion, effectively addressing issues arising from costvolume computation in dynamic environments. Extensive experiments on KITTI andCityscapes datasets demonstrate that the proposed method consistentlyoutperforms existing self-supervised monocular depth estimation baselines. Codeis available at \url{https://github.com/Csyunling/D3epth}.</description>
      <author>example@mail.com (Siyu Chen, Hong Liu, Wenhao Li, Ying Zhu, Guoquan Wang, Jianbing Wu)</author>
      <guid isPermaLink="false">2411.04826v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Demo: Paving the Way for Smart Manufacturing with 5G/TSN Convergence and Augmented Reality</title>
      <link>http://arxiv.org/abs/2411.04336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in IEEE CSCN 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;第五代（5G）移动和时间敏感网络（TSN）技术被广泛认为是推动工业4.0及其后续发展智能制造的关键。&lt;h4&gt;目的&lt;/h4&gt;展示基于混合TSN和5G系统的增强现实（AR）辅助远程协助应用案例。&lt;h4&gt;方法&lt;/h4&gt;演示设置包括现成的5G和TSN设备、接近产品级的5G系统，以及基于智能眼镜的AR解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;演示展示了调度TSN流量的空中传输和来自远程环境对本地用户的实时帮助的可行性。&lt;h4&gt;结论&lt;/h4&gt;演示结果表明，结合5G和TSN技术可以实现高效的远程协助，提升制造业的智能化水平。&lt;h4&gt;总结&lt;/h4&gt;该研究通过实际演示验证了5G和TSN技术在智能制造中的应用潜力，特别是在AR辅助远程协助方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The fifth-generation (5G) mobile/cellular and time-sensitive networking (TSN)technologies are widely recognized as the key to shaping smart manufacturingfor Industry 4.0 and beyond. Converged operation of the two offers end-to-endreal-time and deterministic connectivity over hybrid wired and wirelesssegments. On the other hand, the augmented reality (AR) technology providesvarious benefits for the manufacturing sector. To this end, this demonstrationshowcases AR-aided remote assistance use-case over a hybrid TSN and 5G system.The demonstration setup comprises off-the-shelf 5G and TSN devices, a nearproduct-grade 5G system, and an AR solution based on smart glasses. Thedemonstration shows the viability of over-the air transmission of scheduled TSNtraffic and real-time assistance for a local user from a remote environments.Performance results from the demonstration setup are also shown.</description>
      <author>example@mail.com (Sajida Gufran, Adnan Aijaz)</author>
      <guid isPermaLink="false">2411.04336v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Map++: Towards User-Participatory Visual SLAM Systems with Efficient Map Expansion and Sharing</title>
      <link>http://arxiv.org/abs/2411.02553v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 15 figures. Accepted by MobiCom 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;构建精确的3D地图对未来基于地图的系统（如自动驾驶和导航）至关重要，但在复杂环境中（如多层停车场或购物中心）生成这些地图仍然是一项艰巨的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种参与式感知方法，将地图构建任务委托给地图用户，以实现成本效益高且持续的数据收集。&lt;h4&gt;方法&lt;/h4&gt;开发了Map++系统，作为一种即插即用的扩展，支持基于现有SLAM算法的参与式地图构建，并通过一系列轻量级应用层协议解决可扩展性问题。&lt;h4&gt;主要发现&lt;/h4&gt;在四个代表性环境中进行评估后，Map++能够将交通量减少约46%，并且映射精度几乎没有下降（与基线系统相比小于0.03米）。它能够支持大约两倍于基线系统的并发用户数量，并且对于已经映射的轨迹用户，可以直接利用现有地图进行定位，节省47%的CPU使用率。&lt;h4&gt;结论&lt;/h4&gt;Map++方法有效地促进了地图的扩展和持续更新，提升了参与式地图构建的效率和可用性。&lt;h4&gt;总结&lt;/h4&gt;通过参与式感知，Map++不仅解决了复杂环境中3D地图构建的挑战，还显著提高了系统的可扩展性和用户效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3636534.3649386&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Constructing precise 3D maps is crucial for the development of futuremap-based systems such as self-driving and navigation. However, generatingthese maps in complex environments, such as multi-level parking garages orshopping malls, remains a formidable challenge. In this paper, we introduce aparticipatory sensing approach that delegates map-building tasks to map users,thereby enabling cost-effective and continuous data collection. The proposedmethod harnesses the collective efforts of users, facilitating the expansionand ongoing update of the maps as the environment evolves.  We realized this approach by developing Map++, an efficient system thatfunctions as a plug-and-play extension, supporting participatory map-buildingbased on existing SLAM algorithms. Map++ addresses a plethora of scalabilityissues in this participatory map-building system by proposing a set oflightweight, application-layer protocols. We evaluated Map++ in fourrepresentative settings: an indoor garage, an outdoor plaza, a public SLAMbenchmark, and a simulated environment. The results demonstrate that Map++ canreduce traffic volume by approximately 46% with negligible degradation inmapping accuracy, i.e., less than 0.03m compared to the baseline system. It cansupport approximately $2 \times$ as many concurrent users as the baseline underthe same network bandwidth. Additionally, for users who travel onalready-mapped trajectories, they can directly utilize the existing maps forlocalization and save 47% of the CPU usage.</description>
      <author>example@mail.com (Xinran Zhang, Hanqi Zhu, Yifan Duan, Wuyang Zhang, Longfei Shangguan, Yu Zhang, Jianmin Ji, Yanyong Zhang)</author>
      <guid isPermaLink="false">2411.02553v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Abnormal Stop Detection for Long Distance Coaches with Low-Frequency GPS</title>
      <link>http://arxiv.org/abs/2411.04422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;长途客车为公众提供了方便且经济的交通方式，但存在由于非法中途搭载造成的异常停车问题，这可能危害乘客安全。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督方法，帮助交通管理人员有效发现长途客车的异常停车（ASD）。&lt;h4&gt;方法&lt;/h4&gt;将ASD问题转化为无监督聚类框架，通过构建停留时间模型和低秩假设分离正常停车和异常停车点。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在处理低频率GPS数据时能够有效识别异常停车，简化了复杂问题。&lt;h4&gt;结论&lt;/h4&gt;所提方法概念简单且高效，能够帮助领域专家发现客车的异常停车，相关数据集和代码已公开。&lt;h4&gt;总结&lt;/h4&gt;本研究为长途客车的安全管理提供了一种新颖的解决方案，旨在提升交通管理的效率和安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/pangjunbiao/ipps&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In our urban life, long distance coaches supply a convenient yet economicapproach to the transportation of the public. One notable problem is todiscover the abnormal stop of the coaches due to the important reason, i.e.,illegal pick up on the way which possibly endangers the safety of passengers.It has become a pressing issue to detect the coach abnormal stop withlow-quality GPS. In this paper, we propose an unsupervised method that helpstransportation managers to efficiently discover the Abnormal Stop Detection(ASD) for long distance coaches. Concretely, our method converts the ASDproblem into an unsupervised clustering framework in which both the normal stopand the abnormal one are decomposed. Firstly, we propose a stop duration modelfor the low frequency GPS based on the assumption that a coach changes speedapproximately in a linear approach. Secondly, we strip the abnormal stops fromthe normal stop points by the low rank assumption. The proposed method isconceptually simple yet efficient, by leveraging low rank assumption to handlenormal stop points, our approach enables domain experts to discover the ASD forcoaches, from a case study motivated by traffic managers. Datset and code arepublicly available at: https://github.com/pangjunbiao/IPPs.</description>
      <author>example@mail.com (Jiaxin Deng, Junbiao Pang, Jiayu Xu, Haitao Yu)</author>
      <guid isPermaLink="false">2411.04422v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Finding Control Invariant Sets via Lipschitz Constants of Linear Programs</title>
      <link>http://arxiv.org/abs/2411.04833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;控制不变集在安全关键控制中起着重要作用，并广泛应用于移动机器人避障等领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，安全地扩展初始集合，同时始终保证该集合是控制不变的。&lt;h4&gt;方法&lt;/h4&gt;定义集合边界的扩展规律，通过线性规划（LPs）检查控制不变性；利用最近提出的LP的利普希茨常数，将连续验证问题转化为有限数量的线性规划。&lt;h4&gt;主要发现&lt;/h4&gt;通过可微优化的概念，推导出控制不变集的安全扩展规律，并将其解释为可能边界空间中的第二不变性问题。&lt;h4&gt;结论&lt;/h4&gt;获得的集合可用于在控制障碍函数（CBF）框架中实现最小侵入的安全过滤器。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了理论结果和数值示例，以支持所提出的方法和结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Control invariant sets play an important role in safety-critical control andfind broad application in numerous fields such as obstacle avoidance for mobilerobots. However, finding valid control invariant sets of dynamical systemsunder input limitations is notoriously difficult. We present an approach tosafely expand an initial set while always guaranteeing that the set is controlinvariant. Specifically, we define an expansion law for the boundary of a setand check for control invariance using Linear Programs (LPs). To verify controlinvariance on a continuous domain, we leverage recently proposed Lipschitzconstants of LPs to transform the problem of continuous verification into afinite number of LPs. Using concepts from differentiable optimization, wederive the safe expansion law of the control invariant set and show how it canbe interpreted as a second invariance problem in the space of possibleboundaries. Finally, we show how the obtained set can be used to obtain aminimally invasive safety filter in a Control Barrier Function (CBF) framework.Our work is supported by theoretical results as well as numerical examples.</description>
      <author>example@mail.com (Matti Vahs, Shaohang Han, Jana Tumova)</author>
      <guid isPermaLink="false">2411.04833v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling VVV/WISE Mira variables on the far side of the Galactic disk: Distances, kinematics and a new extinction law</title>
      <link>http://arxiv.org/abs/2411.04623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 19 figures, Accepted in A&amp;A&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;银河系盘的结构和运动学主要通过太阳附近的数据推断，但对赤道和远侧区域的理解仍不够全面。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在识别视差变量（Mira variables）作为可靠的追踪器，以研究银河系中央隆起和远侧盘中的中老年群体。&lt;h4&gt;方法&lt;/h4&gt;使用高斯过程算法从Vista Variables in the Vía Láctea调查中提取纯净的Mira样本，并处理近红外和中红外的时间序列光度数据以识别Mira变量。&lt;h4&gt;主要发现&lt;/h4&gt;成功创建了一个包含3602个Mira变量的目录，并通过光度分析对其进行了O-rich或C-rich表面化学的分类，推导出选择性与总消光比率。&lt;h4&gt;结论&lt;/h4&gt;基于Mira的周期-年龄关系，支持银河系盘的由内而外形成理论，且其运动学与银河旋转曲线一致，未发现强有力的核星盘证据。&lt;h4&gt;总结&lt;/h4&gt;该研究是迄今为止最大的一份关于银河系远侧变星的目录，为进一步研究银河系结构提供了重要数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The structure and kinematics of the Milky Way disk are largely inferred fromthe solar vicinity. To gain a comprehensive understanding, it is essential tofind reliable tracers in less-explored regions like the bulge and the far sideof the disk. Mira variables, which are well-studied and bright standardcandles, offer an excellent opportunity to trace intermediate and oldpopulations in these complex regions. We aim to isolate a clean sample of Mirasin the Vista Variables in the V\'ia L\'actea survey using Gaussian processalgorithms. This sample will be used to study intermediate and old agepopulations in the Galactic bulge and far disk. Near- and mid-infraredtime-series photometry were processed using Gaussian Process algorithms toidentify Mira variables and model their light curves. We calibrated selectioncriteria with a visually inspected sample to create a high-purity sample ofMiras, integrating multi-band photometry and kinematic data from propermotions. We present a catalog of 3602 Mira variables. By analyzing photometry,we classify them by O-rich or C-rich surface chemistry and deriveselective-to-total extinction ratios of $A_{K_{s}}/E(J - K_{s}) = 0.471 \pm0.01$ and $A_{K_{s}}/E(H - K_{s}) = 1.320 \pm 0.020$. Using the Mira period-agerelation, we find evidence supporting the inside-out formation of the Milky Waydisk. The distribution of proper motions and distances aligns with the Galacticrotation curve and disk kinematics. We extend the rotation curve up to R$_{\rmGC} \sim 17 \ \rm{kpc}$ and find no strong evidence of the nuclear stellar diskin our Mira sample. This study constitutes the largest catalog of variablestars on the far side of the Galactic disk to date.</description>
      <author>example@mail.com (Rogelio Albarracín, M. Zoccali, J. Olivares Carvajal, Á. Rojas-Arriagada, J. H. Minniti, M. Catelan, M. De Leo, F. Gran, R. Contreras Ramos, Á. Valenzuela Navarro, C. Salvo-Guajardo)</author>
      <guid isPermaLink="false">2411.04623v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-Based Spatio-Temporal Graph Transfer Learning</title>
      <link>http://arxiv.org/abs/2405.12452v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时空图神经网络在城市计算任务中表现出色，如预测和克里金，但其性能受限于对大量特定任务数据的依赖，限制了在不同城市领域的适应能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架以解决时空图迁移学习中的跨任务泛化问题，特别是在数据稀缺的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了时空图提示框架（STGP），通过将不同任务统一为单一模板，并引入与该模板对齐的任务无关网络架构，利用可学习的提示实现领域和任务迁移。&lt;h4&gt;主要发现&lt;/h4&gt;STGP在三个任务（预测、克里金和外推）中表现优于现有最先进的基准，提升幅度可达10.7%。&lt;h4&gt;结论&lt;/h4&gt;STGP有效捕获跨任务共享的依赖关系，能够在多样化任务和数据稀缺的环境中实现优越的性能。&lt;h4&gt;总结&lt;/h4&gt;STGP为时空图迁移学习提供了一种新的思路，能够在不同城市领域中更好地适应多样化的任务需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-05-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hjf1997/stgp&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-temporal graph neural networks have proven efficacy in capturingcomplex dependencies for urban computing tasks such as forecasting and kriging.Yet, their performance is constrained by the reliance on extensive data fortraining on a specific task, thereby limiting their adaptability to new urbandomains with varied task demands. Although transfer learning has been proposedto remedy this problem by leveraging knowledge across domains, the cross-taskgeneralization still remains under-explored in spatio-temporal graph transferlearning due to the lack of a unified framework. To bridge the gap, we proposeSpatio-Temporal Graph Prompting (STGP), a prompt-based framework capable ofadapting to multi-diverse tasks in a data-scarce domain. Specifically, we firstunify different tasks into a single template and introduce a task-agnosticnetwork architecture that aligns with this template. This approach enablescapturing dependencies shared across tasks. Furthermore, we employ learnableprompts to achieve domain and task transfer in a two-stage prompting pipeline,facilitating the prompts to effectively capture domain knowledge andtask-specific properties. Our extensive experiments demonstrate that STGPoutperforms state-of-the-art baselines in three tasks-forecasting, kriging, andextrapolation-achieving an improvement of up to 10.7%.</description>
      <author>example@mail.com (Junfeng Hu, Xu Liu, Zhencheng Fan, Yifang Yin, Shili Xiang, Savitha Ramasamy, Roger Zimmermann)</author>
      <guid isPermaLink="false">2405.12452v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>GPT-Guided Monte Carlo Tree Search for Symbolic Regression in Financial Fraud Detection</title>
      <link>http://arxiv.org/abs/2411.04459v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACM International Conference on Information and Knowledge Management
  2024 RAG - Enterprise&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在线金融服务增加，金融欺诈率上升，互联网流量和交易速率显著提升，迫切需要快速决策。&lt;h4&gt;目的&lt;/h4&gt;提高金融决策过程的透明度和可解释性，克服现有复杂黑箱模型的不足。&lt;h4&gt;方法&lt;/h4&gt;提出SR-MCTS（符号回归MCTS），利用基础GPT模型引导MCTS，提升收敛速度和生成表达式的质量。&lt;h4&gt;主要发现&lt;/h4&gt;SR-MCTS在检测欺诈方面比行业内广泛使用的方法更高效，同时提供了决策过程的深刻洞见。&lt;h4&gt;结论&lt;/h4&gt;SR-MCTS能够有效改善金融欺诈检测的效率和可解释性，具有重要的应用价值。&lt;h4&gt;总结&lt;/h4&gt;随着金融服务的数字化，快速且可解释的决策工具如SR-MCTS变得尤为重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing number of financial services available online, the rateof financial fraud has also been increasing. The traffic and transaction rateson the internet have increased considerably, leading to a need for fastdecision-making. Financial institutions also have stringent regulations thatoften require transparency and explainability of the decision-making process.However, most state-of-the-art algorithms currently used in the industry arehighly parameterized black-box models that rely on complex computations togenerate a score. These algorithms are inherently slow and lack theexplainability and speed of traditional rule-based learners. This workintroduces SR-MCTS (Symbolic Regression MCTS), which utilizes a foundationalGPT model to guide the MCTS, significantly enhancing its convergence speed andthe quality of the generated expressions which are further extracted to rules.Our experiments show that SR-MCTS can detect fraud more efficiently than widelyused methods in the industry while providing substantial insights into thedecision-making process.</description>
      <author>example@mail.com (Prashank Kadam)</author>
      <guid isPermaLink="false">2411.04459v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Stem-OB: Generalizable Visual Imitation Learning with Stem-Like Convergent Observation through Diffusion Inversion</title>
      <link>http://arxiv.org/abs/2411.04919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Arxiv preprint version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉模仿学习方法在性能上表现强劲，但在面对视觉输入干扰（如光照和纹理变化）时缺乏泛化能力，这阻碍了其在现实世界中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出Stem-OB，利用预训练的图像扩散模型来抑制低级视觉差异，同时保持高级场景结构。&lt;h4&gt;方法&lt;/h4&gt;通过图像反演过程将观测转化为共享表示，从而去除多余细节，与数据增强方法不同，Stem-OB对各种未指定的外观变化具有鲁棒性，无需额外训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果证实了我们方法在模拟任务中的有效性，并在现实世界应用中显示出显著改善，成功率平均提高22.2%，相比最佳基线有显著提升。&lt;h4&gt;结论&lt;/h4&gt;Stem-OB是一种简单但高效的即插即用解决方案，能够提高视觉模仿学习的应用效果。&lt;h4&gt;总结&lt;/h4&gt;Stem-OB通过抑制低级视觉差异，增强了视觉模仿学习方法的实用性和效果，特别是在真实场景中表现突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual imitation learning methods demonstrate strong performance, yet theylack generalization when faced with visual input perturbations, includingvariations in lighting and textures, impeding their real-world application. Wepropose Stem-OB that utilizes pretrained image diffusion models to suppresslow-level visual differences while maintaining high-level scene structures.This image inversion process is akin to transforming the observation into ashared representation, from which other observations stem, with extraneousdetails removed. Stem-OB contrasts with data-augmentation approaches as it isrobust to various unspecified appearance changes without the need foradditional training. Our method is a simple yet highly effective plug-and-playsolution. Empirical results confirm the effectiveness of our approach insimulated tasks and show an exceptionally significant improvement in real-worldapplications, with an average increase of 22.2% in success rates compared tothe best baseline. See https://hukz18.github.io/Stem-Ob/ for more info.</description>
      <author>example@mail.com (Kaizhe Hu, Zihang Rui, Yao He, Yuyao Liu, Pu Hua, Huazhe Xu)</author>
      <guid isPermaLink="false">2411.04919v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>LVI-GS: Tightly-coupled LiDAR-Visual-Inertial SLAM using 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2411.02703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting (3DGS) 在快速渲染和高保真映射方面表现出色。&lt;h4&gt;目的&lt;/h4&gt;引入 LVI-GS，一个与 3DGS 紧密结合的 LiDAR-视觉惯性映射框架。&lt;h4&gt;方法&lt;/h4&gt;利用 LiDAR 和图像传感器的互补特性，捕捉 3D 场景的几何结构和视觉细节，使用颜色化的 LiDAR 点初始化 3D 高斯，并通过可微渲染进行优化，引入基于金字塔的训练方法学习多层次特征，并结合 LiDAR 测量的深度损失以改善几何特征感知。&lt;h4&gt;主要发现&lt;/h4&gt;通过高效的高斯图扩展、关键帧选择、线程管理和自定义 CUDA 加速策略，框架实现了实时的照片级真实映射。&lt;h4&gt;结论&lt;/h4&gt;与先进的 3D 重建系统相比，本方法在数值实验中表现出优越的性能。&lt;h4&gt;总结&lt;/h4&gt;LVI-GS 框架通过结合 LiDAR 和视觉信息，实现了高效且高保真的 3D 映射。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has shown its ability in rapid rendering andhigh-fidelity mapping. In this paper, we introduce LVI-GS, a tightly-coupledLiDAR-Visual-Inertial mapping framework with 3DGS, which leverages thecomplementary characteristics of LiDAR and image sensors to capture bothgeometric structures and visual details of 3D scenes. To this end, the 3DGaussians are initialized from colourized LiDAR points and optimized usingdifferentiable rendering. In order to achieve high-fidelity mapping, weintroduce a pyramid-based training approach to effectively learn multi-levelfeatures and incorporate depth loss derived from LiDAR measurements to improvegeometric feature perception. Through well-designed strategies for Gaussian-Mapexpansion, keyframe selection, thread management, and custom CUDA acceleration,our framework achieves real-time photo-realistic mapping. Numerical experimentsare performed to evaluate the superior performance of our method compared tostate-of-the-art 3D reconstruction systems.</description>
      <author>example@mail.com (Huibin Zhao, Weipeng Guan, Peng Lu)</author>
      <guid isPermaLink="false">2411.02703v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>More variable circadian rhythms in epilepsy: a retrospective cross-sectional study using long-term heart rate recordings from wearable sensors</title>
      <link>http://arxiv.org/abs/2411.04634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;昼夜节律将生理和行为与24小时的光暗周期对齐，其扰动与癫痫等神经疾病有关。但如何最好地量化昼夜节律的扰动仍不明确，因为它可以在不同属性和时间尺度上表现出来。&lt;h4&gt;目的&lt;/h4&gt;评估个体内部在几周到几年的时间尺度上昼夜节律的变异性，尤其是在癫痫患者中。&lt;h4&gt;方法&lt;/h4&gt;我们回顾性地使用了143名癫痫患者和31名对照者的可穿戴智能手表数据（Fitbit）。提取心率时间序列中的昼夜振荡，并分析三个昼夜节律属性的个体内部变异性：周期、峰值相位和幅度。&lt;h4&gt;主要发现&lt;/h4&gt;癫痫患者的周期变异性（77分钟对比62分钟，z=3.32，p&lt;0.001）和峰值相位变异性（68分钟对比54分钟，z=2.97，p=0.003）较对照者增加，但幅度并无显著差异（1.98 bpm对比2.05 bpm，z=-0.66，p=0.51）。未发现癫痫发作频率与昼夜节律属性的个体内部变异性之间的相关性，也未发现有无癫痫发作的周之间的差异。&lt;h4&gt;结论&lt;/h4&gt;癫痫患者的心率昼夜节律变异性更大，这可以通过可穿戴设备检测到。然而，未能发现与癫痫发作频率或发生的关联，提示个体内部变异性可能是癫痫病因的另一种表现。&lt;h4&gt;未来研究方向&lt;/h4&gt;未来的研究应探讨抗癫痫药物、人口统计特征、共病和健康行为在癫痫中驱动昼夜节律属性个体内部变异性的综合作用。&lt;h4&gt;总结&lt;/h4&gt;本研究表明癫痫患者的昼夜节律更具变异性，提示可能与癫痫的病因相关，但与发作频率无明显关联。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Background: The circadian rhythm aligns physiology and behaviour with the24-hour light-dark cycle, and its disruption is linked to neurologicaldisorders such as epilepsy. However, how to best quantify circadian disruptionremains unclear, as it can manifest across various properties and timescales. Apromising but under-explored approach is to assess the intra-individualvariability in circadian rhythms over timescales of weeks to years. This is yetto be studied in epilepsy.  Methods: We retrospectively used wearable smartwatch data (Fitbit) from 143people with epilepsy (PWE) and 31 controls. For each participant, we extractedthe circadian oscillation underlying their heart rate time series and analysedthe intra-individual variability of three circadian properties: period,acrophase, and amplitude.  Findings: We found increased intra-individual variability in period (77 minvs. 62 min, z=3.32, p&lt;0.001) and acrophase (68 min vs. 54 min, z=2.97, p=0.003)for PWE compared to controls, but not in amplitude (1.98 bpm vs. 2.05 bpm,z=-0.66, p=0.51). For PWE, we did not find any correlations between seizurefrequency and intra-individual variability in circadian properties, or anydifference between weeks with and without seizures.  Interpretation: This finding indicates that the circadian rhythm of heartrate is more variable for people with epilepsy and that this can be detectedusing a wearable device. However, we were unable to find any associations withseizure frequency or occurrence, suggesting intra-individual variability couldbe another manifestation of epilepsy aetiology. Future work should investigatethe combined role of anti-seizure medications, demographics, co-morbidities,and health behaviours in driving the increased intra-individual variability ofcircadian properties in epilepsy.</description>
      <author>example@mail.com (Billy C. Smith, Christopher Thornton, Rachel E. Stirling, Guillermo M. Besne, Nathan Evans, Peter N. Taylor, Philippa J. Karoly, Yujiang Wang)</author>
      <guid isPermaLink="false">2411.04634v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>The Impact of Traffic Characteristics on System and User Performance in 5G/6G Cellular Systems</title>
      <link>http://arxiv.org/abs/2411.04474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传播环境和流量到达过程的统计特征影响5G/6G毫米波和亚太赫兹系统的用户性能。&lt;h4&gt;目的&lt;/h4&gt;研究会话到达过程中的相关性和变异性对5G/6G毫米波/亚太赫兹系统性能的影响。&lt;h4&gt;方法&lt;/h4&gt;使用随机几何和排队理论工具对基站的服务过程和毫米波/亚太赫兹无线部分进行建模。&lt;h4&gt;主要发现&lt;/h4&gt;归一化自相关函数(NACF)、变异系数(CoV)和资源请求分布的方差显著影响系统资源利用率和会话丢失概率。高NACF和CoV值可能导致系统超出操作范围，资源利用率下降10-20%，会话丢失概率增加多倍。&lt;h4&gt;结论&lt;/h4&gt;常用的泊松假设会严重低估5G/6G毫米波/亚太赫兹系统的实际性能，因此流量到达和传播统计特征对系统性能评估同样重要。&lt;h4&gt;总结&lt;/h4&gt;准确评估5G/6G毫米波/亚太赫兹系统性能需要考虑流量到达和传播统计的双重影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The statistical characteristics of the propagation environment and trafficarrival process are known to affect the user performance in 5G/6G millimeterwave (mmWave) and subterahertz (sub-THz) systems. While the former topic hasreceived considerable attention recently, little is known about the impact oftraffic statistics. In this study, we characterize the effects of correlationand variability in the session arrival process on the performance of 5G/6GmmWave/sub-THz systems. To this end, we use the tools of stochastic geometryand queuing theory to model the service process at base stations (BS) andspecifics of the mmWave/sub-THz radio part. The metrics considered include thesystem resource utilization and session loss probability. Our results show thatthe normalized autocorrelation function (NACF), coefficient of variation (CoV),and variance of the resource request distribution have a significant impact onthe considered parameters. For the same arrival rate, high values of lag-1 NACFand CoV may lead the system out of the operational regime, affecting the lossprobability and resource utilization by up to an order of magnitude. Even aslight deviation from the uncorrelated Poisson process decreases theutilization by 10-20% and increases the session loss probability multipletimes. Radio and environmental characteristics may further increase thevariability in resource request distribution and decrease resource utilization.In general, the use of the commonly accepted Poisson assumption leads to asevere underestimation of the actual performance of 5G/6G mmWave/sub-THzsystems. Therefore, both traffic arrival and propagation statistics are equallyimportant for accurate performance assessment of such systems.</description>
      <author>example@mail.com (Eduard Sopin, Vyacheslav Begishev, Vladislav Prosvirov, Konstantin Samouylov, Yevgeni Koucheryavy)</author>
      <guid isPermaLink="false">2411.04474v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>LCP-Fusion: A Neural Implicit SLAM with Enhanced Local Constraints and Computable Prior</title>
      <link>http://arxiv.org/abs/2411.03610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by 2024 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，基于神经隐式表示的稠密同时定位与地图构建（SLAM）在孔填充和高保真映射方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的神经隐式SLAM系统LCP-Fusion，以增强局部约束和可计算的先验。&lt;h4&gt;方法&lt;/h4&gt;采用稀疏体素八叉树结构，结合特征网格和SDF先验作为混合场景表示；引入基于视觉重叠的滑动窗口选择策略和实用的变形损失来约束相对姿态。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LCP-Fusion在定位准确性和重建一致性上优于现有的RGB-D隐式SLAM，特别是在具有挑战性的真实场景和未知场景边界的自捕获场景中。&lt;h4&gt;结论&lt;/h4&gt;LCP-Fusion提供了更强的可扩展性和鲁棒性，尤其在处理复杂场景时表现突出。&lt;h4&gt;总结&lt;/h4&gt;本文提出的LCP-Fusion系统有效解决了现有方法中的局限性，提升了SLAM在实际应用中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/laliwang/lcp-fusion&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently the dense Simultaneous Localization and Mapping (SLAM) based onneural implicit representation has shown impressive progress in hole fillingand high-fidelity mapping. Nevertheless, existing methods either heavily relyon known scene bounds or suffer inconsistent reconstruction due to drift inpotential loop-closure regions, or both, which can be attributed to theinflexible representation and lack of local constraints. In this paper, wepresent LCP-Fusion, a neural implicit SLAM system with enhanced localconstraints and computable prior, which takes the sparse voxel octree structurecontaining feature grids and SDF priors as hybrid scene representation,enabling the scalability and robustness during mapping and tracking. To enhancethe local constraints, we propose a novel sliding window selection strategybased on visual overlap to address the loop-closure, and a practical warpingloss to constrain relative poses. Moreover, we estimate SDF priors as coarseinitialization for implicit features, which brings additional explicitconstraints and robustness, especially when a light but efficient adaptiveearly ending is adopted. Experiments demonstrate that our method achieve betterlocalization accuracy and reconstruction consistency than existing RGB-Dimplicit SLAM, especially in challenging real scenes (ScanNet) as well asself-captured scenes with unknown scene bounds. The code is available athttps://github.com/laliwang/LCP-Fusion.</description>
      <author>example@mail.com (Jiahui Wang, Yinan Deng, Yi Yang, Yufeng Yue)</author>
      <guid isPermaLink="false">2411.03610v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning</title>
      <link>http://arxiv.org/abs/2411.04983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预测未来结果和控制动作的能力是物理推理的基础，但学习这些预测模型（即世界模型）具有挑战性，通常是针对特定任务的解决方案。&lt;h4&gt;目的&lt;/h4&gt;探讨世界模型在仅使用被动数据时在多样问题上的推理和规划潜力。&lt;h4&gt;方法&lt;/h4&gt;提出DINO世界模型（DINO-WM），该方法通过预测未来的空间补丁特征，在不重建视觉世界的情况下建模视觉动态。&lt;h4&gt;主要发现&lt;/h4&gt;DINO-WM能够在各种领域（如迷宫导航、桌面推推和粒子操控）中生成零-shot行为解决方案，且不依赖于专家示范、奖励建模或预学习的逆模型。&lt;h4&gt;结论&lt;/h4&gt;DINO-WM展示了强大的泛化能力，能够适应各种任务家族，包括任意配置的迷宫、不同形状物体的推操控和多粒子场景。&lt;h4&gt;总结&lt;/h4&gt;DINO-WM为任务无关的行为规划提供了一种新的方法，证明了其在多样化任务中的有效性和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to predict future outcomes given control actions is fundamentalfor physical reasoning. However, such predictive models, often called worldmodels, have proven challenging to learn and are typically developed fortask-specific solutions with online policy learning. We argue that the truepotential of world models lies in their ability to reason and plan acrossdiverse problems using only passive data. Concretely, we require world modelsto have the following three properties: 1) be trainable on offline,pre-collected trajectories, 2) support test-time behavior optimization, and 3)facilitate task-agnostic reasoning. To realize this, we present DINO WorldModel (DINO-WM), a new method to model visual dynamics without reconstructingthe visual world. DINO-WM leverages spatial patch features pre-trained withDINOv2, enabling it to learn from offline behavioral trajectories by predictingfuture patch features. This design allows DINO-WM to achieve observationalgoals through action sequence optimization, facilitating task-agnostic behaviorplanning by treating desired goal patch features as prediction targets. Weevaluate DINO-WM across various domains, including maze navigation, tabletoppushing, and particle manipulation. Our experiments demonstrate that DINO-WMcan generate zero-shot behavioral solutions at test time without relying onexpert demonstrations, reward modeling, or pre-learned inverse models. Notably,DINO-WM exhibits strong generalization capabilities compared to priorstate-of-the-art work, adapting to diverse task families such as arbitrarilyconfigured mazes, push manipulation with varied object shapes, andmulti-particle scenarios.</description>
      <author>example@mail.com (Gaoyue Zhou, Hengkai Pan, Yann LeCun, Lerrel Pinto)</author>
      <guid isPermaLink="false">2411.04983v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Blockchain Services for Digital Government: An Exploration of NFT Applications in the Metaverse</title>
      <link>http://arxiv.org/abs/2411.00076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  42 pages; 3 figures; submitted for publication into a textbook as a
  chapter&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;实现元宇宙的全面整合需要物理世界和数字世界的结合。&lt;h4&gt;目的&lt;/h4&gt;通过分布式账本技术（DLT）推动社会向理想元宇宙靠拢，特别是通过非同质化代币（NFT）的创新。&lt;h4&gt;方法&lt;/h4&gt;分析技术的初期阶段及其在公共和私营部门的重要影响，探讨教育对技术整合的必要性。&lt;h4&gt;主要发现&lt;/h4&gt;目前在公共和私营部门的采纳程度有限，主要由于技术尚处于初期阶段。&lt;h4&gt;结论&lt;/h4&gt;为了建立可持续的智能城市，必须加强对这一技术在集成元宇宙中运作的教育。&lt;h4&gt;挑战&lt;/h4&gt;不同行业对数据的兼容需求以及监管程度不同，尤其是在金融和医疗等高度监管的行业中。&lt;h4&gt;框架&lt;/h4&gt;本章节展示了这一概念框架的多个方面。&lt;h4&gt;总结&lt;/h4&gt;整合技术和教育是推动元宇宙发展的关键，尤其在不同监管环境下的适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The full implementation of the metaverse requires the integration of thephysical and digital worlds. Applications built on Distributed LedgerTechnology (DLT) hold the power to move society closer towards the idealmetaverse through innovations like Non-Fungible Tokens (NFTs). Due to acombination of the infancy of this technology and the significant implicationsit holds in the public and private sectors, adoption across both sectors iscurrently limited. To foster the creation of sustainable smart cities built onthis technology, education on how this technology may function in an integratedmetaverse is paramount. This is due to the necessary compatibility acrossindustries needed between public and private data. As certain industries aremore regulated than others, such as finance or healthcare, a robust system isneeded to allow for varying degrees of freedom. This chapter illustratesnumerous facets of this conceptual framework.</description>
      <author>example@mail.com (Zachary Roch, Ramya Akula)</author>
      <guid isPermaLink="false">2411.00076v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Peri-midFormer: Periodic Pyramid Transformer for Time Series Analysis</title>
      <link>http://arxiv.org/abs/2411.04554v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38th Conference on Neural Information Processing Systems (NeurIPS
  2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列分析在天气预测、异常检测和行为识别等领域应用广泛。&lt;h4&gt;目的&lt;/h4&gt;突破以往方法在建模时间序列时面临的挑战，特别是数据点的离散性和周期变化的复杂性。&lt;h4&gt;方法&lt;/h4&gt;将隐含的复杂周期变化解耦为不同周期成分之间的包含和重叠关系，并引入自注意力机制以提取复杂的时间变化。&lt;h4&gt;主要发现&lt;/h4&gt;提出的周期金字塔模型在短期和长期预测、数据补全、分类和异常检测等五项主流时间序列分析任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;周期金字塔模型有效捕捉了时间序列中的复杂周期关系，展示了其在时间序列分析中的优势。&lt;h4&gt;总结&lt;/h4&gt;通过引入周期金字塔和自注意力机制，本研究为时间序列分析提供了新的方法论，提升了分析效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/WuQiangXDU/Peri-midFormer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series analysis finds wide applications in fields such as weatherforecasting, anomaly detection, and behavior recognition. Previous methodsattempted to model temporal variations directly using 1D time series. However,this has been quite challenging due to the discrete nature of data points intime series and the complexity of periodic variation. In terms of periodicity,taking weather and traffic data as an example, there are multi-periodicvariations such as yearly, monthly, weekly, and daily, etc. In order to breakthrough the limitations of the previous methods, we decouple the impliedcomplex periodic variations into inclusion and overlap relationships amongdifferent level periodic components based on the observation of themulti-periodicity therein and its inclusion relationships. This explicitlyrepresents the naturally occurring pyramid-like properties in time series,where the top level is the original time series and lower levels consist ofperiodic components with gradually shorter periods, which we call the periodicpyramid. To further extract complex temporal variations, we introduceself-attention mechanism into the periodic pyramid, capturing complex periodicrelationships by computing attention between periodic components based on theirinclusion, overlap, and adjacency relationships. Our proposed Peri-midFormerdemonstrates outstanding performance in five mainstream time series analysistasks, including short- and long-term forecasting, imputation, classification,and anomaly detection.</description>
      <author>example@mail.com (Qiang Wu, Gechang Yao, Zhixi Feng, Shuyuan Yang)</author>
      <guid isPermaLink="false">2411.04554v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Performance evaluation of SLAM-ASR: The Good, the Bad, the Ugly, and the Way Forward</title>
      <link>http://arxiv.org/abs/2411.03866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICASSP 2025 SALMA Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近期研究表明，在语音基础编码器和大型语言模型（LLMs）之间训练线性连接器可以实现强大的自动语音识别（ASR）能力。&lt;h4&gt;目的&lt;/h4&gt;探讨简单方法在不同场景和语音条件下的稳健性，包括领域转移和不同的语音扰动。&lt;h4&gt;方法&lt;/h4&gt;通过进行各种消融实验，使用一种名为SLAM-ASR的最新广泛采用的方法。&lt;h4&gt;主要发现&lt;/h4&gt;SLAM-ASR在跨领域评估设置中表现不佳；在同领域数据中，语音扰动（如速度变化或附加噪声）显著影响性能。&lt;h4&gt;结论&lt;/h4&gt;研究结果为微调和配置基于LLM的ASR模型提供了重要见解，以适应不同的数据特征和计算资源。&lt;h4&gt;总结&lt;/h4&gt;本文提供了关于如何有效利用SLAM-ASR架构的实证发现，强调了在多种设置中提升ASR性能的必要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has demonstrated that training a linear connector betweenspeech foundation encoders and large language models (LLMs) enables thisarchitecture to achieve strong ASR capabilities. Despite the impressiveresults, it remains unclear whether these simple approaches are robust enoughacross different scenarios and speech conditions, such as domain shifts anddifferent speech perturbations. In this paper, we address these questions byconducting various ablation experiments using a recent and widely adoptedapproach called SLAM-ASR. We present novel empirical findings that offerinsights on how to effectively utilize the SLAM-ASR architecture across a widerange of settings. Our main findings indicate that the SLAM-ASR exhibits poorperformance in cross-domain evaluation settings. Additionally, speechperturbations within in-domain data, such as changes in speed or the presenceof additive noise, can significantly impact performance. Our findings offercritical insights for fine-tuning and configuring robust LLM-based ASR models,tailored to different data characteristics and computational resources.</description>
      <author>example@mail.com (Shashi Kumar, Iuliia Thorbecke, Sergio Burdisso, Esaú Villatoro-Tello, Manjunath K E, Kadri Hacioğlu, Pradeep Rangappa, Petr Motlicek, Aravind Ganapathiraju, Andreas Stolcke)</author>
      <guid isPermaLink="false">2411.03866v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>From CNN to ConvRNN: Adapting Visualization Techniques for Time-Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2411.04707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;神经网络广泛应用于解决各种问题，但其作为黑箱的特性引发了伦理和法律问题。&lt;h4&gt;目的&lt;/h4&gt;帮助用户理解神经网络的决策过程，验证其结果的相关性。&lt;h4&gt;方法&lt;/h4&gt;研究一种“时间分布”的卷积递归神经网络（convRNN），用于视频数据的异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;通过可解释性技术，用户能够更好地理解模型的学习过程和决策依据。&lt;h4&gt;结论&lt;/h4&gt;可解释性在机器学习中是重要的，有助于提高用户对模型结果的信任。&lt;h4&gt;总结&lt;/h4&gt;本文探讨了如何利用convRNN进行视频异常检测，并强调了可解释性的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nowadays, neural networks are commonly used to solve various problems.Unfortunately, despite their effectiveness, they are often perceived as blackboxes capable of providing answers without explaining their decisions, whichraises numerous ethical and legal concerns. Fortunately, the field ofexplainability helps users understand these results. This aspect of machinelearning allows users to grasp the decision-making process of a model andverify the relevance of its outcomes. In this article, we focus on the learningprocess carried out by a ``time distributed`` convRNN, which performs anomalydetection from video data.</description>
      <author>example@mail.com (Fabien Poirier)</author>
      <guid isPermaLink="false">2411.04707v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Few-Shot Task Learning through Inverse Generative Modeling</title>
      <link>http://arxiv.org/abs/2411.04987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;理解代理的意图（如目标或运动风格）通常非常具有挑战性，仅凭少量示例很难实现。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，称为通过逆生成建模的少量任务学习（FTL-IGM），以学习新的任务概念。&lt;h4&gt;方法&lt;/h4&gt;利用可逆神经生成模型，先对一组基本概念及其演示进行预训练，然后在获得新概念的少量演示后，通过反向传播学习相关概念，而无需更新模型权重。&lt;h4&gt;主要发现&lt;/h4&gt;在五个领域（物体重排、目标导向导航、人类动作捕捉、自动驾驶和真实世界桌面操作）中验证了该方法，成功学习了新概念并生成对应的代理计划或运动。&lt;h4&gt;结论&lt;/h4&gt;通过预训练的生成模型，我们能够在未见环境中及与训练概念组合的情况下，成功学习新概念。&lt;h4&gt;总结&lt;/h4&gt;FTL-IGM方法有效地解决了少量示例学习新任务概念的问题，展示了其在多种应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning the intents of an agent, defined by its goals or motion style, isoften extremely challenging from just a few examples. We refer to this problemas task concept learning and present our approach, Few-Shot Task Learningthrough Inverse Generative Modeling (FTL-IGM), which learns new task conceptsby leveraging invertible neural generative models. The core idea is to pretraina generative model on a set of basic concepts and their demonstrations. Then,given a few demonstrations of a new concept (such as a new goal or a newaction), our method learns the underlying concepts through backpropagationwithout updating the model weights, thanks to the invertibility of thegenerative model. We evaluate our method in five domains -- objectrearrangement, goal-oriented navigation, motion caption of human actions,autonomous driving, and real-world table-top manipulation. Our experimentalresults demonstrate that via the pretrained generative model, we successfullylearn novel concepts and generate agent plans or motion corresponding to theseconcepts in (1) unseen environments and (2) in composition with trainingconcepts.</description>
      <author>example@mail.com (Aviv Netanyahu, Yilun Du, Antonia Bronars, Jyothish Pari, Joshua Tenenbaum, Tianmin Shu, Pulkit Agrawal)</author>
      <guid isPermaLink="false">2411.04987v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Using Deep Neural Networks to Quantify Parking Dwell Time</title>
      <link>http://arxiv.org/abs/2411.00158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted to the 2024 International Conference on Machine
  Learning and Applications&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在智能城市中，通常会为停车位定义最大停留时间，以提高停车位的周转率并减少个人交通工具的使用。&lt;h4&gt;目的&lt;/h4&gt;自动从图像中确定车辆停留时间，克服低分辨率摄像头、光照变化和天气影响等挑战。&lt;h4&gt;方法&lt;/h4&gt;提出一种结合两种深度神经网络的方法，首先使用深度分类网络判断停车位状态，然后利用Siamese网络核对停放车辆是否与前一图像相同。&lt;h4&gt;主要发现&lt;/h4&gt;在交叉数据集实验中，使用完美分类器时，系统能生成75%的完美停留时间预测；但使用现实世界分类器时，预测质量下降至49%。&lt;h4&gt;结论&lt;/h4&gt;尽管Siamese网络有潜力，但其效果受初始分类器质量的影响。&lt;h4&gt;总结&lt;/h4&gt;提出的方法在理想条件下表现良好，但在现实应用中需改进分类器性能以提高预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In smart cities, it is common practice to define a maximum length of stay fora given parking space to increase the space's rotativity and discourage theusage of individual transportation solutions. However, automaticallydetermining individual car dwell times from images faces challenges, such asimages collected from low-resolution cameras, lighting variations, and weathereffects. In this work, we propose a method that combines two deep neuralnetworks to compute the dwell time of each car in a parking lot. The proposedmethod first defines the parking space status between occupied and empty usinga deep classification network. Then, it uses a Siamese network to check if theparked car is the same as the previous image. Using an experimental protocolthat focuses on a cross-dataset scenario, we show that if a perfect classifieris used, the proposed system generates 75% of perfect dwell time predictions,where the predicted value matched exactly the time the car stayed parked.Nevertheless, our experiments show a drop in prediction quality when areal-world classifier is used to predict the parking space statuses, reaching49% of perfect predictions, showing that the proposed Siamese network ispromising but impacted by the quality of the classifier used at the beginningof the pipeline.</description>
      <author>example@mail.com (Marcelo Eduardo Marques Ribas, Heloisa Benedet Mendes, Luiz Eduardo Soares de Oliveira, Luiz Antonio Zanlorensi, Paulo Ricardo Lisboa de Almeida)</author>
      <guid isPermaLink="false">2411.00158v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Multi-Connectivity in Satellite-Terrestrial Integrated Networks: Architectures, Challenges, and Applications</title>
      <link>http://arxiv.org/abs/2411.04675v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多连接（MC）在卫星与地面集成网络（STINs）中被视为未来网络的有前景技术，包含在3GPP标准中。&lt;h4&gt;目的&lt;/h4&gt;探讨MC在改善覆盖、通信和传感方面的优势，并引起广泛关注。&lt;h4&gt;方法&lt;/h4&gt;介绍三种MC系统的基本部署架构，包括多卫星、单卫星单基站和多卫星多基站配置，同时探索卫星网络的设计挑战。&lt;h4&gt;主要发现&lt;/h4&gt;讨论了影响相互通信质量的关键技术挑战，如波束成形、信道估计和同步。&lt;h4&gt;结论&lt;/h4&gt;展示了MC在覆盖增强、流量卸载、协作传感和低空通信等典型应用中的表现，并通过案例研究比较了MC和单连接（SC）配置的覆盖性能。&lt;h4&gt;未来研究方向&lt;/h4&gt;提出了未来MC在STINs中研究的几个重要方向，以促进进一步探索。&lt;h4&gt;总结&lt;/h4&gt;MC技术在卫星与地面集成网络中的应用潜力巨大，需要解决一系列技术挑战以实现更高效的网络性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-connectivity (MC) in satellite-terrestrial integrated networks (STINs),included in 3GPP standards, is regarded as a promising technology for futurenetworks. The significant advantages of MC in improving coverage,communication, and sensing through satellite-terrestrial collaboration havesparked widespread interest. In this article, we first introduce threefundamental deployment architectures of MC systems in STINs, includingmulti-satellite, single-satellite single-base-station, and multi-satellitemulti-base-station configurations. Considering the emerging but still evolvingsatellite networking, we explore system design challenges such as satellitenetworking schemes, e.g., cell-free and multi-tier satellite networks. Then,key technical challenges that severely influence the quality of mutualcommunications, including beamforming, channel estimation, and synchronization,are discussed subsequently. Furthermore, typical applications such as coverageenhancement, traffic offloading, collaborative sensing, and low-altitudecommunication are demonstrated, followed by a case study comparing coverageperformance in MC and single-connectivity (SC) configurations. Severalessential future research directions for MC in STINs are presented tofacilitate further exploration.</description>
      <author>example@mail.com (Xiangyu Li, Bodong Shang)</author>
      <guid isPermaLink="false">2411.04675v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DEIO: Deep Event Inertial Odometry</title>
      <link>http://arxiv.org/abs/2411.03928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;事件相机是一种受生物启发的运动激活传感器，能够在运动模糊和高动态范围等挑战性情况下表现出色。&lt;h4&gt;目的&lt;/h4&gt;研究现有事件基础的同时定位与地图构建(SLAM)方法在实际应用中的局限性，并探索将学习基础的事件SLAM方法与惯性测量单元(IMU)结合的可能性。&lt;h4&gt;方法&lt;/h4&gt;提出DEIO，这是首个单目深度事件-惯性里程计框架，结合了学习方法与传统的非线性图优化。具体而言，将可训练的事件基础可微束调整(e-DBA)与IMU预积分紧密集成在一个因子图中，并采用基于关键帧的滑动窗口优化。&lt;h4&gt;主要发现&lt;/h4&gt;在九个公共挑战数据集的数值实验中，DEIO方法相较于基于图像和事件的基准测试展示了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;DEIO框架在大规模、低纹理或复杂场景下推动了基于事件的SLAM方法的发展。&lt;h4&gt;总结&lt;/h4&gt;DEIO为事件相机与IMU的融合提供了新的研究方向，并展现了在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras are bio-inspired, motion-activated sensors that demonstrateimpressive potential in handling challenging situations, such as motion blurand high-dynamic range. Despite their promise, existing event-basedsimultaneous localization and mapping (SLAM) approaches exhibit limitedperformance in real-world applications. On the other hand, state-of-the-artSLAM approaches that incorporate deep neural networks for better robustness andapplicability. However, these is a lack of research in fusing learning-basedevent SLAM methods with IMU, which could be indispensable to push theevent-based SLAM to large-scale, low-texture or complex scenarios. In thispaper, we propose DEIO, the first monocular deep event-inertial odometryframework that combines learning-based method with traditional nonlineargraph-based optimization. Specifically, we tightly integrate a trainableevent-based differentiable bundle adjustment (e-DBA) with the IMUpre-integration in a factor graph which employs keyframe-based sliding windowoptimization. Numerical Experiments in nine public challenge datasets show thatour method can achieve superior performance compared with the image-based andevent-based benchmarks. The source code is available at:https://github.com/arclab-hku/DEIO.</description>
      <author>example@mail.com (Weipeng Guan, Fuling Lin, Peiyu Chen, Peng Lu)</author>
      <guid isPermaLink="false">2411.03928v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Which bits went where? Past and future transfer entropy decomposition with the information bottleneck</title>
      <link>http://arxiv.org/abs/2411.04992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 workshop "Machine learning and the physical sciences"
  Camera ready&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;转移熵用于测量时间序列之间的信息流动，并能够检测可能的因果关系，适用于鱼群、神经元集合或大气与海洋过程等系统。&lt;h4&gt;目的&lt;/h4&gt;提出一种分解转移熵的方法，以更细致地分析信息流动的变化来源和去向。&lt;h4&gt;方法&lt;/h4&gt;使用信息瓶颈方法压缩时间序列，识别转移的熵，并应用于合成的递归过程和实验小鼠的行为与神经活动数据集。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够细致揭示信息流动中的复杂动态，显示出信息转移过程中的细微变化。&lt;h4&gt;结论&lt;/h4&gt;为未来研究复杂系统中时间过程的相互作用奠定了基础。&lt;h4&gt;总结&lt;/h4&gt;通过分解转移熵，能够更深入地理解复杂系统中信息流动的机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Whether the system under study is a shoal of fish, a collection of neurons,or a set of interacting atmospheric and oceanic processes, transfer entropymeasures the flow of information between time series and can detect possiblecausal relationships. Much like mutual information, transfer entropy isgenerally reported as a single value summarizing an amount of shared variation,yet a more fine-grained accounting might illuminate much about the processesunder study. Here we propose to decompose transfer entropy and localize thebits of variation on both sides of information flow: that of the originatingprocess's past and that of the receiving process's future. We employ theinformation bottleneck (IB) to compress the time series and identify thetransferred entropy. We apply our method to decompose the transfer entropy inseveral synthetic recurrent processes and an experimental mouse dataset ofconcurrent behavioral and neural activity. Our approach highlights the nuanceddynamics within information flow, laying a foundation for future explorationsinto the intricate interplay of temporal processes in complex systems.</description>
      <author>example@mail.com (Kieran A. Murphy, Zhuowen Yin, Dani S. Bassett)</author>
      <guid isPermaLink="false">2411.04992v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>EffiCANet: Efficient Time Series Forecasting with Convolutional Attention</title>
      <link>http://arxiv.org/abs/2411.04669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列数据在工业监测和智能城市等领域快速增长，急需高效且准确的预测模型。&lt;h4&gt;目的&lt;/h4&gt;解决当前深度学习方法在捕捉长距离依赖和复杂变量关系方面的不足，特别是在实时处理限制下。&lt;h4&gt;方法&lt;/h4&gt;提出EffiCANet，一个高效卷积注意网络，集成了三个关键组件：1) 时间大核分解卷积模块（TLDC）；2) 变量间组卷积模块（IVGC）；3) 全局时间-变量注意机制（GTVA）。&lt;h4&gt;主要发现&lt;/h4&gt;EffiCANet在九个基准数据集上的评估显示，相较于最先进的模型，其平均绝对误差（MAE）降低了10.02%，计算成本相对传统大核卷积方法降低了26.2%。&lt;h4&gt;结论&lt;/h4&gt;EffiCANet通过其高效的分解策略，显著提高了预测准确性，同时保持了计算效率。&lt;h4&gt;总结&lt;/h4&gt;EffiCANet是针对多变量时间序列数据预测的高效解决方案，能够更好地捕捉复杂的时间和变量关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The exponential growth of multivariate time series data from sensor networksin domains like industrial monitoring and smart cities requires efficient andaccurate forecasting models. Current deep learning methods often fail toadequately capture long-range dependencies and complex inter-variablerelationships, especially under real-time processing constraints. Theselimitations arise as many models are optimized for either short-termforecasting with limited receptive fields or long-term accuracy at the cost ofefficiency. Additionally, dynamic and intricate interactions between variablesin real-world data further complicate modeling efforts. To address theselimitations, we propose EffiCANet, an Efficient Convolutional Attention Networkdesigned to enhance forecasting accuracy while maintaining computationalefficiency. EffiCANet integrates three key components: (1) a TemporalLarge-kernel Decomposed Convolution (TLDC) module that captures long-termtemporal dependencies while reducing computational overhead; (2) anInter-Variable Group Convolution (IVGC) module that captures complex andevolving relationships among variables; and (3) a Global Temporal-VariableAttention (GTVA) mechanism that prioritizes critical temporal andinter-variable features. Extensive evaluations across nine benchmark datasetsshow that EffiCANet achieves the maximum reduction of 10.02% in MAE overstate-of-the-art models, while cutting computational costs by 26.2% relative toconventional large-kernel convolution methods, thanks to its efficientdecomposition strategy.</description>
      <author>example@mail.com (Xinxing Zhou, Jiaqi Ye, Shubao Zhao, Ming Jin, Chengyi Yang, Yanlong Wen, Xiaojie Yuan)</author>
      <guid isPermaLink="false">2411.04669v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Semantic Masking and Visual Feature Matching for Robust Localization</title>
      <link>http://arxiv.org/abs/2411.01804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主机器人在国际空间站等环境中进行长期部署，以帮助宇航员进行维护和监测操作，但这些环境动态且无结构，频繁的重构对机器人的长期定位造成挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种计算效率高的语义遮罩方法，以提高视觉定位系统在变化环境中的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;引入轻量级检查，确保匹配仅在长期静态物体内，并且具有一致的语义类别。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在基于地图的重新定位和相对姿态估计中表现良好，改善了绝对轨迹误差（ATE）和正确匹配率，验证了在公开的Astrobee数据集上的有效性。&lt;h4&gt;结论&lt;/h4&gt;虽然该方法最初为微重力机器人开发，但可以应用于任何视觉特征匹配管道，以提高鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;提出的语义遮罩方法为长期部署的机器人在动态环境中提供了更可靠的视觉定位解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We are interested in long-term deployments of autonomous robots to aidastronauts with maintenance and monitoring operations in settings such as theInternational Space Station. Unfortunately, such environments tend to be highlydynamic and unstructured, and their frequent reconfiguration poses a challengefor robust long-term localization of robots. Many state-of-the-art visualfeature-based localization algorithms are not robust towards spatial scenechanges, and SLAM algorithms, while promising, cannot run within thelow-compute budget available to space robots. To address this gap, we present acomputationally efficient semantic masking approach for visual feature matchingthat improves the accuracy and robustness of visual localization systems duringlong-term deployment in changing environments. Our method introduces alightweight check that enforces matches to be within long-term static objectsand have consistent semantic classes. We evaluate this approach using bothmap-based relocalization and relative pose estimation and show that it improvesAbsolute Trajectory Error (ATE) and correct match ratios on the publiclyavailable Astrobee dataset. While this approach was originally developed formicrogravity robotic freeflyers, it can be applied to any visual featurematching pipeline to improve robustness.</description>
      <author>example@mail.com (Luisa Mao, Ryan Soussan, Brian Coltin, Trey Smith, Joydeep Biswas)</author>
      <guid isPermaLink="false">2411.01804v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Development of a Service Robot for Hospital Environments in Rehabilitation Medicine with LiDAR Based Simultaneous Localization and Mapping</title>
      <link>http://arxiv.org/abs/2411.04797v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了一种配备3D LiDAR和先进定位能力的医疗服务机器人，适用于医院环境。&lt;h4&gt;目的&lt;/h4&gt;开发和评估机器人在复杂动态医疗环境中的自主导航和有效互动能力。&lt;h4&gt;方法&lt;/h4&gt;使用基于LiDAR的同步定位与地图构建(SLAM)技术，并与Autoware 1.14.0版本的3D SLAM技术进行比较分析。&lt;h4&gt;主要发现&lt;/h4&gt;通过适应法线分布变换(NDT)匹配实现室内导航，提高了实时映射精度和障碍物避免能力。&lt;h4&gt;结论&lt;/h4&gt;机器人集成3D LiDAR和NDT匹配显著提高了在医疗环境中的导航准确性和操作可靠性。&lt;h4&gt;应用&lt;/h4&gt;该技术在医院环境中的成功部署显示了其支持医疗人员和改善患者护理的潜力。&lt;h4&gt;未来方向&lt;/h4&gt;研究指出在多样环境条件下传感器性能的改进机会，提示未来医疗机器人研究与发展的前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the development and evaluation of a medical service robotequipped with 3D LiDAR and advanced localization capabilities for use inhospital environments. The robot employs LiDAR-based Simultaneous Localizationand Mapping SLAM to navigate autonomously and interact effectively withincomplex and dynamic healthcare settings. A comparative analysis withestablished 3D SLAM technology in Autoware version 1.14.0, under a Linux ROSframework, provided a benchmark for evaluating our system performance. Theadaptation of Normal Distribution Transform NDT Matching to indoor navigationallowed for precise real-time mapping and enhanced obstacle avoidancecapabilities. Empirical validation was conducted through manual maneuvers invarious environments, supplemented by ROS simulations to test the systemresponse to simulated challenges. The findings demonstrate that the robotintegration of 3D LiDAR and NDT Matching significantly improves navigationaccuracy and operational reliability in a healthcare context. This studyhighlights the robot ability to perform essential tasks with high efficiencyand identifies potential areas for further improvement, particularly in sensorperformance under diverse environmental conditions. The successful deploymentof this technology in a hospital setting illustrates its potential to supportmedical staff and contribute to patient care, suggesting a promising directionfor future research and development in healthcare robotics.</description>
      <author>example@mail.com (Sayat Ibrayev, Arman Ibrayeva, Bekzat Amanov, Serik Tolenov)</author>
      <guid isPermaLink="false">2411.04797v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration</title>
      <link>http://arxiv.org/abs/2410.18032v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图在建模现实世界中的关系数据方面被广泛使用，如社交网络和城市计算。&lt;h4&gt;目的&lt;/h4&gt;解决现有基于大语言模型（LLM）的图分析方法在可迁移性和性能上的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出一个基于LLM的多智能体系统GraphTeam，模拟人类的问题解决策略，如类比和协作。&lt;h4&gt;主要发现&lt;/h4&gt;GraphTeam在六个图分析基准上的实验表明，其准确度比最佳基线平均提高了25.85%。&lt;h4&gt;结论&lt;/h4&gt;GraphTeam在图分析任务中实现了最先进的性能，展示了多智能体协作的有效性。&lt;h4&gt;总结&lt;/h4&gt;GraphTeam利用不同专长的LLM智能体，通过三个模块协同解决复杂问题，提供了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bupt-gamma/graphteam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are widely used for modeling relational data in real-world scenarios,such as social networks and urban computing. Existing LLM-based graph analysisapproaches either integrate graph neural networks (GNNs) for specific machinelearning tasks, limiting their transferability, or rely solely on LLMs'internal reasoning ability, resulting in suboptimal performance. To addressthese limitations, we take advantage of recent advances in LLM-based agents,which have shown capabilities of utilizing external knowledge or tools forproblem solving. By simulating human problem-solving strategies such as analogyand collaboration, we propose a multi-agent system based on LLMs namedGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents fromthree modules, and the agents with different specialities can collaborate witheach other to address complex problems. Specifically, (1) input-outputnormalization module: the question agent extracts and refines four keyarguments from the original question, facilitating the problem understanding,and the answer agent organizes the results to meet the output requirement; (2)external knowledge retrieval module: we first build a knowledge base consistingof relevant documentation and experience information, and then the search agentretrieves the most relevant entries for each question. (3) problem-solvingmodule: given the retrieved information from search agent, the coding agentuses established algorithms via programming to generate solutions, and in casethe coding agent does not work, the reasoning agent will directly compute theresults without programming. Extensive experiments on six graph analysisbenchmarks demonstrate that GraphTeam achieves state-of-the-art performancewith an average 25.85% improvement over the best baseline in terms of accuracy.The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.</description>
      <author>example@mail.com (Xin Li, Qizhi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang)</author>
      <guid isPermaLink="false">2410.18032v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Diff-2-in-1: Bridging Generation and Dense Perception with Diffusion Models</title>
      <link>http://arxiv.org/abs/2411.05005v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;扩散模型在高保真图像合成之外，在密集视觉感知任务中展现了良好的结果，但大多数现有工作将其视为独立组件，仅用于数据增强或特征提取。&lt;h4&gt;目的&lt;/h4&gt;提出一种统一的、灵活的扩散基础框架Diff-2-in-1，同时处理多模态数据生成和密集视觉感知。&lt;h4&gt;方法&lt;/h4&gt;通过独特利用扩散去噪过程，增强视觉感知，并利用去噪网络生成与原始训练集分布相似的多模态数据。&lt;h4&gt;主要发现&lt;/h4&gt;Diff-2-in-1通过新颖的自我改进学习机制，优化了生成的多样化和真实数据的利用，实验证明该框架在各类判别性骨干网络上均有一致的性能提升。&lt;h4&gt;结论&lt;/h4&gt;该框架在高质量多模态数据生成方面表现出真实性和实用性的特点，验证了其有效性。&lt;h4&gt;总结&lt;/h4&gt;Diff-2-in-1框架为多模态数据生成与视觉感知任务提供了一种新方法，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Beyond high-fidelity image synthesis, diffusion models have recentlyexhibited promising results in dense visual perception tasks. However, mostexisting work treats diffusion models as a standalone component for perceptiontasks, employing them either solely for off-the-shelf data augmentation or asmere feature extractors. In contrast to these isolated and thus sub-optimalefforts, we introduce a unified, versatile, diffusion-based framework,Diff-2-in-1, that can simultaneously handle both multi-modal data generationand dense visual perception, through a unique exploitation of thediffusion-denoising process. Within this framework, we further enhancediscriminative visual perception via multi-modal generation, by utilizing thedenoising network to create multi-modal data that mirror the distribution ofthe original training set. Importantly, Diff-2-in-1 optimizes the utilizationof the created diverse and faithful data by leveraging a novel self-improvinglearning mechanism. Comprehensive experimental evaluations validate theeffectiveness of our framework, showcasing consistent performance improvementsacross various discriminative backbones and high-quality multi-modal datageneration characterized by both realism and usefulness.</description>
      <author>example@mail.com (Shuhong Zheng, Zhipeng Bao, Ruoyu Zhao, Martial Hebert, Yu-Xiong Wang)</author>
      <guid isPermaLink="false">2411.05005v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Preventing Model Collapse in Deep Canonical Correlation Analysis by Noise Regularization</title>
      <link>http://arxiv.org/abs/2411.00383v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024 as a poster&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多视图表示学习（MVRL）旨在从多视图数据中学习对象的统一表示。&lt;h4&gt;目的&lt;/h4&gt;解决基于深度典型相关分析（DCCA）的方法在训练过程中出现的模型崩溃问题。&lt;h4&gt;方法&lt;/h4&gt;开发NR-DCCA，采用新颖的噪声正则化方法来防止模型崩溃，并进行理论分析以展示相关不变性特性的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;NR-DCCA在合成数据和真实世界数据集上稳定且一致地优于基线方法，噪声正则化方法可以推广到其他DCCA方法，如DGCCA。&lt;h4&gt;结论&lt;/h4&gt;NR-DCCA有效解决了模型崩溃问题，推动了DCCA方法的广泛应用。&lt;h4&gt;总结&lt;/h4&gt;通过实验验证了NR-DCCA的有效性，并揭示了噪声正则化在保持模型性能中的关键作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-View Representation Learning (MVRL) aims to learn a unifiedrepresentation of an object from multi-view data. Deep Canonical CorrelationAnalysis (DCCA) and its variants share simple formulations and demonstratestate-of-the-art performance. However, with extensive experiments, we observethe issue of model collapse, {\em i.e.}, the performance of DCCA-based methodswill drop drastically when training proceeds. The model collapse issue couldsignificantly hinder the wide adoption of DCCA-based methods because it ischallenging to decide when to early stop. To this end, we develop NR-DCCA,which is equipped with a novel noise regularization approach to prevent modelcollapse. Theoretical analysis shows that the Correlation Invariant Property isthe key to preventing model collapse, and our noise regularization forces theneural network to possess such a property. A framework to construct syntheticdata with different common and complementary information is also developed tocompare MVRL methods comprehensively. The developed NR-DCCA outperformsbaselines stably and consistently in both synthetic and real-world datasets,and the proposed noise regularization approach can also be generalized to otherDCCA-based methods such as DGCCA.</description>
      <author>example@mail.com (Junlin He, Jinxiao Du, Susu Xu, Wei Ma)</author>
      <guid isPermaLink="false">2411.00383v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DeepSeq2: Enhanced Sequential Circuit Learning with Disentangled Representations</title>
      <link>http://arxiv.org/abs/2411.00530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;电路表示学习在电子设计自动化（EDA）中越来越重要，提高了模型的效率和准确性。&lt;h4&gt;目的&lt;/h4&gt;提出DeepSeq2框架，以克服DeepSeq在执行时间和结构效率上的局限。&lt;h4&gt;方法&lt;/h4&gt;DeepSeq2通过将电路学习映射到结构、功能和顺序行为三个嵌入空间，使用高效的有向无环图神经网络（DAG-GNN）来优化学习过程。&lt;h4&gt;主要发现&lt;/h4&gt;DeepSeq2显著减少了执行时间，提高了模型的可扩展性，并有效捕捉电路中的转变行为。&lt;h4&gt;结论&lt;/h4&gt;DeepSeq2在顺序电路表示学习中设立了新的基准，优于之前的功率估计和可靠性分析研究。&lt;h4&gt;总结&lt;/h4&gt;DeepSeq2通过创新的表示方式和高效的网络设计，推动了电路学习领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Circuit representation learning is increasingly pivotal in Electronic DesignAutomation (EDA), serving various downstream tasks with enhanced modelefficiency and accuracy. One notable work, DeepSeq, has pioneered sequentialcircuit learning by encoding temporal correlations. However, it suffers fromsignificant limitations including prolonged execution times and architecturalinefficiencies. To address these issues, we introduce DeepSeq2, a novelframework that enhances the learning of sequential circuits, by innovativelymapping it into three distinct embedding spaces-structure, function, andsequential behavior-allowing for a more nuanced representation that capturesthe inherent complexities of circuit dynamics. By employing an efficientDirected Acyclic Graph Neural Network (DAG-GNN) that circumvents the recursivepropagation used in DeepSeq, DeepSeq2 significantly reduces execution times andimproves model scalability. Moreover, DeepSeq2 incorporates a uniquesupervision mechanism that captures transitioning behaviors within circuitsmore effectively. DeepSeq2 sets a new benchmark in sequential circuitrepresentation learning, outperforming prior works in power estimation andreliability analysis.</description>
      <author>example@mail.com (Sadaf Khan, Zhengyuan Shi, Ziyang Zheng, Min Li, Qiang Xu)</author>
      <guid isPermaLink="false">2411.00530v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>$α$-TCVAE: On the relationship between Disentanglement and Diversity</title>
      <link>http://arxiv.org/abs/2411.00588v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;解耦表示在生成建模和表示学习中表现出潜力，但其下游实用性仍存在争议。最近的研究通过与对称性建立正式联系重新定义了解耦，强调了减少潜在域和增强生成能力的能力。&lt;h4&gt;目的&lt;/h4&gt;引入α-TCVAE，一种优化的变分自编码器，旨在最大化解耦和潜在变量的信息量。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的总相关（TC）下界，该下界基于信息论构造，推广了β-VAE下界，并可简化为已知的变分信息瓶颈（VIB）和条件熵瓶颈（CEB）项的凸组合。&lt;h4&gt;主要发现&lt;/h4&gt;通过定量分析支持解耦表示能够提升生成能力和多样性。实验表明，α-TCVAE在学习更解耦的表示方面优于基线，并在生成多样化观察时不损失视觉保真度。&lt;h4&gt;结论&lt;/h4&gt;α-TCVAE在MPI3D-Real这一复杂数据集上表现出显著的改进，确认了其在最大化个别变量信息量时对复杂数据集的表示能力。该模型在基于模型的强化学习任务中也展示了显著的下游实用性。&lt;h4&gt;总结&lt;/h4&gt;α-TCVAE是一个有效的工具，能够生成更具多样性的观察，并在多个任务中展现出其优越性，特别是在处理复杂数据集时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While disentangled representations have shown promise in generative modelingand representation learning, their downstream usefulness remains debated.Recent studies re-defined disentanglement through a formal connection tosymmetries, emphasizing the ability to reduce latent domains and consequentlyenhance generative capabilities. However, from an information theory viewpoint,assigning a complex attribute to a specific latent variable may be infeasible,limiting the applicability of disentangled representations to simple datasets.In this work, we introduce $\alpha$-TCVAE, a variational autoencoder optimizedusing a novel total correlation (TC) lower bound that maximizes disentanglementand latent variables informativeness. The proposed TC bound is grounded ininformation theory constructs, generalizes the $\beta$-VAE lower bound, and canbe reduced to a convex combination of the known variational informationbottleneck (VIB) and conditional entropy bottleneck (CEB) terms. Moreover, wepresent quantitative analyses that support the idea that disentangledrepresentations lead to better generative capabilities and diversity.Additionally, we perform downstream task experiments from both representationand RL domains to assess our questions from a broader ML perspective. Ourresults demonstrate that $\alpha$-TCVAE consistently learns more disentangledrepresentations than baselines and generates more diverse observations withoutsacrificing visual fidelity. Notably, $\alpha$-TCVAE exhibits markedimprovements on MPI3D-Real, the most realistic disentangled dataset in ourstudy, confirming its ability to represent complex datasets when maximizing theinformativeness of individual variables. Finally, testing the proposed modeloff-the-shelf on a state-of-the-art model-based RL agent, Director,significantly shows $\alpha$-TCVAE downstream usefulness on the loconav AntMaze task.</description>
      <author>example@mail.com (Cristian Meo, Louis Mahon, Anirudh Goyal, Justin Dauwels)</author>
      <guid isPermaLink="false">2411.00588v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Abstracted Shapes as Tokens -- A Generalizable and Interpretable Model for Time-series Classification</title>
      <link>http://arxiv.org/abs/2411.01006v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Neural Information Processing Systems (NeurIPS) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在时间序列分析中，许多近期研究试图为跨多个领域的时间序列提供统一的视角和表示。&lt;h4&gt;目的&lt;/h4&gt;提出VQShape，一个预训练、可推广和可解释的时间序列表示学习和分类模型。&lt;h4&gt;方法&lt;/h4&gt;引入一种新颖的时间序列数据表示，通过向量量化将来自不同领域的时间序列描述为统一的一组低维代码。&lt;h4&gt;主要发现&lt;/h4&gt;VQShape的表示可以用于构建可解释的分类器，其性能与专业模型相当，并且在零样本学习中能够推广到未见过的数据集和领域。&lt;h4&gt;结论&lt;/h4&gt;VQShape模型有效连接了潜在空间与形状级特征，展现了其在时间序列分类中的潜力和可解释性。&lt;h4&gt;总结&lt;/h4&gt;VQShape为时间序列分析提供了一种新的可解释性方法，能够在不同领域中实现统一的时间序列表示和分类。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In time-series analysis, many recent works seek to provide a unified view andrepresentation for time-series across multiple domains, leading to thedevelopment of foundation models for time-series data. Despite diverse modelingtechniques, existing models are black boxes and fail to provide insights andexplanations about their representations. In this paper, we present VQShape, apre-trained, generalizable, and interpretable model for time-seriesrepresentation learning and classification. By introducing a novelrepresentation for time-series data, we forge a connection between the latentspace of VQShape and shape-level features. Using vector quantization, we showthat time-series from different domains can be described using a unified set oflow-dimensional codes, where each code can be represented as an abstractedshape in the time domain. On classification tasks, we show that therepresentations of VQShape can be utilized to build interpretable classifiers,achieving comparable performance to specialist models. Additionally, inzero-shot learning, VQShape and its codebook can generalize to previouslyunseen datasets and domains that are not included in the pre-training process.The code and pre-trained weights are available athttps://github.com/YunshiWen/VQShape.</description>
      <author>example@mail.com (Yunshi Wen, Tengfei Ma, Tsui-Wei Weng, Lam M. Nguyen, Anak Agung Julius)</author>
      <guid isPermaLink="false">2411.01006v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Cyber-Attack Detection in Power Systems: A Comparative Study of Machine Learning and Graph Neural Network Approaches</title>
      <link>http://arxiv.org/abs/2411.02248v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文探讨了电力系统中时间序列测量数据的网络攻击检测与定位。&lt;h4&gt;目的&lt;/h4&gt;比较传统机器学习（如k-means）、深度学习方法（如自编码器）和基于图神经网络（GNN）技术的检测性能。&lt;h4&gt;方法&lt;/h4&gt;利用IEEE 68-bus系统模拟四种类型的虚假数据攻击，包括缩放攻击、加性攻击及其组合，评估不同方法的检测准确性和定位能力。&lt;h4&gt;主要发现&lt;/h4&gt;GNN方法在检测性能上优于k-means和自编码器，且在简单场景下能够准确定位攻击，但在复杂情况（如缩放和加性攻击组合）中仍面临挑战。&lt;h4&gt;结论&lt;/h4&gt;GNN在电力系统网络攻击的检测和定位中具有良好的潜力，但在处理更复杂的攻击情形时需要进一步研究。&lt;h4&gt;总结&lt;/h4&gt;GNN方法在电力系统的网络攻击检测中表现出色，但对于复杂攻击场景的定位能力尚需提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the detection and localization of cyber-attacks ontime-series measurements data in power systems, focusing on comparingconventional machine learning (ML) like k-means, deep learning method likeautoencoder, and graph neural network (GNN)-based techniques. We assess thedetection accuracy of these approaches and their potential to pinpoint thelocations of specific sensor measurements under attack. Given the demonstratedsuccess of GNNs in other time-series anomaly detection applications, we aim toevaluate their performance within the context of power systems cyber-attacks onsensor measurements. Utilizing the IEEE 68-bus system, we simulated four typesof false data attacks, including scaling attacks, additive attacks, and theircombinations, to test the selected approaches. Our results indicate thatGNN-based methods outperform k-means and autoencoder in detection.Additionally, GNNs show promise in accurately localizing attacks for simplescenarios, although they still face challenges in more complex cases,especially ones that involve combinations of scaling and additive attacks.</description>
      <author>example@mail.com (Tianzhixi Yin, Syed Ahsan Raza Naqvi, Sai Pushpak Nandanoori, Soumya Kundu)</author>
      <guid isPermaLink="false">2411.02248v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>FEET: A Framework for Evaluating Embedding Techniques</title>
      <link>http://arxiv.org/abs/2411.01322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Findings paper presented at Machine Learning for Health (ML4H)
  symposium 2024, December 15-16, 2024, Vancouver, Canada, 11 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究介绍了FEET，这是一种标准化协议，旨在指导基础模型的发展和基准测试。&lt;h4&gt;目的&lt;/h4&gt;提出一个结构化的评估协议，以全面了解基础模型的实际性能。&lt;h4&gt;方法&lt;/h4&gt;定义了三种主要用例：冻结嵌入、少量嵌入和完全微调嵌入，并通过两个案例研究详细说明，包括情感分析和医疗领域。&lt;h4&gt;主要发现&lt;/h4&gt;通过这些评估，我们可以全面评估基础模型在研究应用中的有效性。&lt;h4&gt;结论&lt;/h4&gt;建议将该协议作为未来研究的标准，以推动表示学习模型的发展。&lt;h4&gt;总结&lt;/h4&gt;FEET协议提供了一种系统的方法来评估和比较基础模型的性能，以促进相关研究的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Simonlee711/FEET&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we introduce FEET, a standardized protocol designed to guidethe development and benchmarking of foundation models. While numerous benchmarkdatasets exist for evaluating these models, we propose a structured evaluationprotocol across three distinct scenarios to gain a comprehensive understandingof their practical performance. We define three primary use cases: frozenembeddings, few-shot embeddings, and fully fine-tuned embeddings. Each scenariois detailed and illustrated through two case studies: one in sentiment analysisand another in the medical domain, demonstrating how these evaluations providea thorough assessment of foundation models' effectiveness in researchapplications. We recommend this protocol as a standard for future researchaimed at advancing representation learning models.</description>
      <author>example@mail.com (Simon A. Lee, John Lee, Jeffrey N. Chiang)</author>
      <guid isPermaLink="false">2411.01322v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Improving Node Representation by Boosting Target-Aware Contrastive Loss</title>
      <link>http://arxiv.org/abs/2410.03901v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图模型用于表示实体之间的复杂关系，节点和边捕捉精细的连接。&lt;h4&gt;目的&lt;/h4&gt;提高目标任务性能，通过最大化目标任务与节点表示之间的互信息。&lt;h4&gt;方法&lt;/h4&gt;引入目标感知对比学习（Target-aware Contrastive Learning），采用XGBoost采样器（XGSampler）来采样合适的正例，并最小化目标感知对比损失（XTCL）。&lt;h4&gt;主要发现&lt;/h4&gt;XTCL在节点分类和链接预测任务上显著提升了性能，相比于现有的最先进模型。&lt;h4&gt;结论&lt;/h4&gt;通过优化目标任务与节点表示之间的互信息，目标感知对比学习提高了模型的泛化能力，同时XGSampler增强了各信号的可解释性。&lt;h4&gt;总结&lt;/h4&gt;目标感知对比学习通过自监督学习过程提升了节点表示的质量，进而改善了下游任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs model complex relationships between entities, with nodes and edgescapturing intricate connections. Node representation learning involvestransforming nodes into low-dimensional embeddings. These embeddings aretypically used as features for downstream tasks. Therefore, their quality has asignificant impact on task performance. Existing approaches for noderepresentation learning span (semi-)supervised, unsupervised, andself-supervised paradigms. In graph domains, (semi-)supervised learning oftenonly optimizes models based on class labels, neglecting other abundant graphsignals, which limits generalization. While self-supervised or unsupervisedlearning produces representations that better capture underlying graph signals,the usefulness of these captured signals for downstream target tasks can vary.To bridge this gap, we introduce Target-Aware Contrastive Learning(Target-aware CL) which aims to enhance target task performance by maximizingthe mutual information between the target task and node representations with aself-supervised learning process. This is achieved through a sampling function,XGBoost Sampler (XGSampler), to sample proper positive examples for theproposed Target-Aware Contrastive Loss (XTCL). By minimizing XTCL, Target-awareCL increases the mutual information between the target task and noderepresentations, such that model generalization is improved. Additionally,XGSampler enhances the interpretability of each signal by showing the weightsfor sampling the proper positive examples. We show experimentally that XTCLsignificantly improves the performance on two target tasks: node classificationand link prediction tasks, compared to state-of-the-art models.</description>
      <author>example@mail.com (Ying-Chun Lin, Jennifer Neville)</author>
      <guid isPermaLink="false">2410.03901v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>On the Utilization of Unique Node Identifiers in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.02271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络由于其信息传递结构存在固有的表示限制。&lt;h4&gt;目的&lt;/h4&gt;探讨在使用唯一节点标识符（UIDs）时的优缺点，尤其是保持置换等变性。&lt;h4&gt;方法&lt;/h4&gt;提出一种通过对比损失对UID模型进行正则化的方法，以实现置换等变性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在提高模型的泛化和外推能力的同时，加快了训练收敛速度。&lt;h4&gt;结论&lt;/h4&gt;在最新的BREC表现基准测试中，该方法在与其他随机基础方法比较时取得了最先进的性能。&lt;h4&gt;总结&lt;/h4&gt;UID模型若能保持置换等变性，将有效克服其表示限制，从而提升图神经网络的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have inherent representational limitations due to theirmessage-passing structure. Recent work has suggested that these limitations canbe overcome by using unique node identifiers (UIDs). Here we argue that despitethe advantages of UIDs, one of their disadvantages is that they lose thedesirable property of permutation-equivariance. We thus propose to focus on UIDmodels that are permutation-equivariant, and present theoretical arguments fortheir advantages. Motivated by this, we propose a method to regularize UIDmodels towards permutation equivariance, via a contrastive loss. We empiricallydemonstrate that our approach improves generalization and extrapolationabilities while providing faster training convergence. On the recent BRECexpressiveness benchmark, our proposed method achieves state-of-the-artperformance compared to other random-based approaches.</description>
      <author>example@mail.com (Maya Bechler-Speicher, Moshe Eliasof, Carola-Bibiane Schönlieb, Ran Gilad-Bachrach, Amir Globerson)</author>
      <guid isPermaLink="false">2411.02271v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization</title>
      <link>http://arxiv.org/abs/2411.01618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;鸟瞰图（BEV）地图布局估计需要准确理解环境元素的语义，以确保结果的一致性和真实感。&lt;h4&gt;目的&lt;/h4&gt;解决由于遮挡、不良成像条件和低分辨率导致的视角图（PV）中受损或无效区域的语义地图生成问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种类似于向量量化变分自编码器（VQ-VAE）的生成模型，获取高层次BEV语义的先验知识，并通过专门的令牌解码模块对稀疏的图像特征和BEV令牌进行对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes和Argoverse基准测试上，模型VQ-Map在环视和单目评估中分别取得62.2/47.6的平均IoU和73.4的单目评估IoU，创造了这一地图布局估计任务的新纪录。&lt;h4&gt;结论&lt;/h4&gt;VQ-Map模型有效地桥接了PV和BEV之间的语义对齐，显著提高了地图布局估计的性能。&lt;h4&gt;总结&lt;/h4&gt;该研究通过生成模型改善了鸟瞰图的语义理解能力，推动了自动驾驶领域的地图布局估计技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/z1zyw/vq-map&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bird's-eye-view (BEV) map layout estimation requires an accurate and fullunderstanding of the semantics for the environmental elements around the egocar to make the results coherent and realistic. Due to the challenges posed byocclusion, unfavourable imaging conditions and low resolution,\emph{generating} the BEV semantic maps corresponding to corrupted or invalidareas in the perspective view (PV) is appealing very recently. \emph{Thequestion is how to align the PV features with the generative models tofacilitate the map estimation}. In this paper, we propose to utilize agenerative model similar to the Vector Quantized-Variational AutoEncoder(VQ-VAE) to acquire prior knowledge for the high-level BEV semantics in thetokenized discrete space. Thanks to the obtained BEV tokens accompanied with acodebook embedding encapsulating the semantics for different BEV elements inthe groundtruth maps, we are able to directly align the sparse backbone imagefeatures with the obtained BEV tokens from the discrete representation learningbased on a specialized token decoder module, and finally generate high-qualityBEV maps with the BEV codebook embedding serving as a bridge between PV andBEV. We evaluate the BEV map layout estimation performance of our model, termedVQ-Map, on both the nuScenes and Argoverse benchmarks, achieving 62.2/47.6 meanIoU for surround-view/monocular evaluation on nuScenes, as well as 73.4 IoU formonocular evaluation on Argoverse, which all set a new record for this maplayout estimation task. The code and models are available on\url{https://github.com/Z1zyw/VQ-Map}.</description>
      <author>example@mail.com (Yiwei Zhang, Jin Gao, Fudong Ge, Guan Luo, Bing Li, Zhaoxiang Zhang, Haibin Ling, Weiming Hu)</author>
      <guid isPermaLink="false">2411.01618v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Addressing Representation Collapse in Vector Quantized Models with One Linear Layer</title>
      <link>http://arxiv.org/abs/2411.02038v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;向量量化（VQ）是一种将连续表示转换为离散编码的方法，广泛应用于无监督表示学习和潜在生成模型。&lt;h4&gt;目的&lt;/h4&gt;研究表示崩溃问题及其对VQ模型的影响，并提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;通过线性变换层重新参数化编码向量，优化整个编码空间，而非仅更新最近邻搜索选择的编码向量。&lt;h4&gt;主要发现&lt;/h4&gt;表示崩溃的主要原因是编码表的分离优化，导致只有少数编码向量通过梯度下降更新。&lt;h4&gt;结论&lt;/h4&gt;SimVQ方法有效解决了VQ模型中的表示崩溃问题，验证了其在各种模态（如图像和音频）上的有效性。&lt;h4&gt;总结&lt;/h4&gt;提出的SimVQ方法通过优化整个线性空间，显著提高了VQ模型的性能和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/youngsheen/SimVQ&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vector Quantization (VQ) is a widely used method for converting continuousrepresentations into discrete codes, which has become fundamental inunsupervised representation learning and latent generative models. However, VQmodels are often hindered by the problem of representation collapse in thelatent space, which leads to low codebook utilization and limits thescalability of the codebook for large-scale training. Existing methods designedto mitigate representation collapse typically reduce the dimensionality oflatent space at the expense of model capacity, which do not fully resolve thecore issue. In this study, we conduct a theoretical analysis of representationcollapse in VQ models and identify its primary cause as the disjointoptimization of the codebook, where only a small subset of code vectors areupdated through gradient descent. To address this issue, we propose\textbf{SimVQ}, a novel method which reparameterizes the code vectors through alinear transformation layer based on a learnable latent basis. Thistransformation optimizes the \textit{entire linear space} spanned by thecodebook, rather than merely updating \textit{the code vector} selected by thenearest-neighbor search in vanilla VQ models. Although it is commonlyunderstood that the multiplication of two linear matrices is equivalent toapplying a single linear layer, our approach works surprisingly well inresolving the collapse issue in VQ models with just one linear layer. Wevalidate the efficacy of SimVQ through extensive experiments across variousmodalities, including image and audio data with different model architectures.Our code is available at \url{https://github.com/youngsheen/SimVQ}.</description>
      <author>example@mail.com (Yongxin Zhu, Bocheng Li, Yifei Xin, Linli Xu)</author>
      <guid isPermaLink="false">2411.02038v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Federated GNNs for EEG-Based Stroke Assessment</title>
      <link>http://arxiv.org/abs/2411.02286v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures, Proceedings of the II edition of the Workshop on
  Unifying Representations in Neural Models (UniReps 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习在临床决策过程中具有重要潜力，能够提升诊断能力和个性化治疗方案，但使用患者数据训练模型会引发法律、隐私和安全问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，结合联邦学习和图神经网络，利用脑电图信号预测中风严重程度。&lt;h4&gt;方法&lt;/h4&gt;通过多家医疗机构共同训练共享的图神经网络模型，在不交换患者信息的情况下使用本地脑电图数据，处理国立卫生研究院中风评分的回归问题。&lt;h4&gt;主要发现&lt;/h4&gt;在四家机构的脑电图记录上评估该方法，预测国立卫生研究院中风评分的平均绝对误差为3.23，接近人类专家的平均误差（约3.0）。&lt;h4&gt;结论&lt;/h4&gt;该方法在提供准确和可解释的预测的同时，能够有效维护数据隐私。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了结合联邦学习和图神经网络在医疗数据分析中的应用潜力，尤其是在中风严重程度预测方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning (ML) has the potential to become an essential tool insupporting clinical decision-making processes, offering enhanced diagnosticcapabilities and personalized treatment plans. However, outsourcing medicalrecords to train ML models using patient data raises legal, privacy, andsecurity concerns. Federated learning has emerged as a promising paradigm forcollaborative ML, meeting healthcare institutions' requirements for robustmodels without sharing sensitive data and compromising patient privacy. Thisstudy proposes a novel method that combines federated learning (FL) and GraphNeural Networks (GNNs) to predict stroke severity using electroencephalography(EEG) signals across multiple medical institutions. Our approach enablesmultiple hospitals to jointly train a shared GNN model on their local EEG datawithout exchanging patient information. Specifically, we address a regressionproblem by predicting the National Institutes of Health Stroke Scale (NIHSS), akey indicator of stroke severity. The proposed model leverages a maskedself-attention mechanism to capture salient brain connectivity patterns andemploys EdgeSHAP to provide post-hoc explanations of the neurological statesafter a stroke. We evaluated our method on EEG recordings from fourinstitutions, achieving a mean absolute error (MAE) of 3.23 in predictingNIHSS, close to the average error made by human experts (MAE $\approx$ 3.0).This demonstrates the method's effectiveness in providing accurate andexplainable predictions while maintaining data privacy.</description>
      <author>example@mail.com (Andrea Protani, Lorenzo Giusti, Albert Sund Aillet, Simona Sacco, Paolo Manganotti, Lucio Marinelli, Diogo Reis Santos, Pierpaolo Brutti, Pietro Caliandro, Luigi Serio)</author>
      <guid isPermaLink="false">2411.02286v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DroidSpeak: Enhancing Cross-LLM Communication</title>
      <link>http://arxiv.org/abs/2411.02820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多智能体系统中，大型语言模型（LLMs）之间的通信传统上依赖自然语言，通常包含查询的完整上下文，这可能导致显著的预填充阶段延迟，尤其是在长上下文的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出DroidSpeak框架，旨在通过重用中间数据（如输入嵌入和键值缓存）来优化跨LLM的通信。&lt;h4&gt;方法&lt;/h4&gt;通过高效绕过对相同基础模型的微调版本进行完整上下文的重新处理，实现更快的上下文集成，同时保持任务性能的质量。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估表明，DroidSpeak能够显著加速智能体间的通信，在预填充延迟上实现最高2.78倍的加速，并且准确性损失极小。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了创建更高效和可扩展的多智能体系统的潜力。&lt;h4&gt;总结&lt;/h4&gt;DroidSpeak框架通过重用中间数据，提升了多智能体系统中的通信效率，减少了延迟，保持了性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In multi-agent systems utilizing Large Language Models (LLMs), communicationbetween agents traditionally relies on natural language. This communicationoften includes the full context of the query so far, which can introducesignificant prefill-phase latency, especially with long contexts.  We introduce DroidSpeak, a novel framework to target this cross-LLMcommunication by leveraging the reuse of intermediate data, such as inputembeddings (E-cache) and key-value caches (KV-cache). We efficiently bypass theneed to reprocess entire contexts for fine-tuned versions of the samefoundational model. This approach allows faster context integration whilemaintaining the quality of task performance. Experimental evaluationsdemonstrate DroidSpeak's ability to significantly accelerate inter-agentcommunication, achieving up to a 2.78x speedup in prefill latency withnegligible loss in accuracy. Our findings underscore the potential to createmore efficient and scalable multi-agent systems.</description>
      <author>example@mail.com (Yuhan Liu, Esha Choukse, Shan Lu, Junchen Jiang, Madan Musuvathi)</author>
      <guid isPermaLink="false">2411.02820v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Collaborative Cognitive Diagnosis with Disentangled Representation Learning for Learner Modeling</title>
      <link>http://arxiv.org/abs/2411.02066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;相似隐性认知状态的学习者通常展现出类似的可观察问题解决表现，利用这些学习者之间的协作联系有助于理解人类学习。&lt;h4&gt;目的&lt;/h4&gt;调查学习者之间的协作信号如何促进人类认知状态（即知识水平）的诊断，特别是在智能教育的背景下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Coral的协作认知诊断模型，结合了解耦表示学习。该模型首先引入了一个解耦状态编码器，然后通过动态构建学习者的协作图来捕捉协作信号。&lt;h4&gt;主要发现&lt;/h4&gt;Coral在多个真实数据集上展现出优越的性能，相较于最先进的方法有显著提升。&lt;h4&gt;结论&lt;/h4&gt;Coral模型能够有效地实现学习者的认知状态和协作状态的共解耦，并重建实践表现。&lt;h4&gt;总结&lt;/h4&gt;该研究为理解学习者的协作及其对认知诊断的影响提供了新的视角，并展示了Coral模型的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bigdata-ustc/coral&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learners sharing similar implicit cognitive states often display comparableobservable problem-solving performances. Leveraging collaborative connectionsamong such similar learners proves valuable in comprehending human learning.Motivated by the success of collaborative modeling in various domains, such asrecommender systems, we aim to investigate how collaborative signals amonglearners contribute to the diagnosis of human cognitive states (i.e., knowledgeproficiency) in the context of intelligent education. The primary challengeslie in identifying implicit collaborative connections and disentangling theentangled cognitive factors of learners for improved explainability andcontrollability in learner Cognitive Diagnosis (CD). However, there has been nowork on CD capable of simultaneously modeling collaborative and disentangledcognitive states. To address this gap, we present Coral, a Collaborativecognitive diagnosis model with disentangled representation learning.Specifically, Coral first introduces a disentangled state encoder to achievethe initial disentanglement of learners' states. Subsequently, a meticulouslydesigned collaborative representation learning procedure captures collaborativesignals. It dynamically constructs a collaborative graph of learners byiteratively searching for optimal neighbors in a context-aware manner. Usingthe constructed graph, collaborative information is extracted through noderepresentation learning. Finally, a decoding process aligns the initialcognitive states and collaborative states, achieving co-disentanglement withpractice performance reconstructions. Extensive experiments demonstrate thesuperior performance of Coral, showcasing significant improvements overstate-of-the-art methods across several real-world datasets. Our code isavailable at https://github.com/bigdata-ustc/Coral.</description>
      <author>example@mail.com (Weibo Gao, Qi Liu, Linan Yue, Fangzhou Yao, Hao Wang, Yin Gu, Zheng Zhang)</author>
      <guid isPermaLink="false">2411.02066v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks Based Deep Learning for Predicting Structural and Electronic Properties</title>
      <link>http://arxiv.org/abs/2411.02331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究采用深度学习方法预测材料的结构和电子性质，使用图神经网络（GNN）。&lt;h4&gt;目的&lt;/h4&gt;利用材料项目数据库的数据，构建晶体结构的图表示，并同时预测多种材料属性。&lt;h4&gt;方法&lt;/h4&gt;从材料项目数据库中提取158,874个晶体结构，应用GNN进行多属性预测。&lt;h4&gt;主要发现&lt;/h4&gt;{'密度': 0.96, '形成能': 0.97, '能量高于壳层': 0.54, '结构稳定性': 0.47, '带隙': 0.76, '价带最大值': 0.86, '导带最小值': 0.78, '费米能级': 0.82}&lt;h4&gt;结论&lt;/h4&gt;研究表明GNN在材料科学中的潜力，为快速筛选和发现具有所需性质的材料提供了强有力的工具。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了GNN在预测材料属性方面的高准确性，强调了其在材料科学中的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/selvachandrasekaranselvaraj/GNN_prediction&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents a deep learning approach to predicting structural andelectronic properties of materials using Graph Neural Networks (GNNs).Leveraging data from the Materials Project database, we construct graphrepresentations of crystal structures and employ GNNs to predict multipleproperties simultaneously. All crystal structures are from the MaterialsProject database, with a total of 158,874 structures used. Our model achieveshigh predictive accuracy across various properties, as indicated by \( R^2 \)values: 0.96 for density, 0.97 for formation energy, 0.54 for energy abovehull, 0.47 for structural stability (is\_S), 0.76 for band gap, 0.86 forvalence band maximum, 0.78 for conduction band minimum, and 0.82 for Fermienergy. These results demonstrate the potential of GNNs in materials science,offering a powerful tool for rapid screening and discovery of materials withdesired properties.</description>
      <author>example@mail.com (Selva Chandrasekaran Selvaraj)</author>
      <guid isPermaLink="false">2411.02331v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning</title>
      <link>http://arxiv.org/abs/2411.02125v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the Thirty-Eighth Annual Conference on Neural Information
  Processing Systems (NeurIPS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;有效的DNA序列表示对基因组分析至关重要，特别是在宏基因组分箱中，需对复杂的DNA片段进行聚类以确定微生物组成。&lt;h4&gt;目的&lt;/h4&gt;重新审视基于k-mer的基因组表示，并提供其在表示学习中的理论分析。&lt;h4&gt;方法&lt;/h4&gt;提出一个轻量且可扩展的模型，在基因组读取级别执行宏基因组分箱，仅依赖DNA片段的k-mer组成。&lt;h4&gt;主要发现&lt;/h4&gt;与近期的基因组基础模型相比，提出的模型在性能上相当，但在可扩展性上显著更有效。&lt;h4&gt;结论&lt;/h4&gt;可扩展性是对真实世界数据集进行宏基因组分箱的重要方面，提出的模型更适合该需求。&lt;h4&gt;总结&lt;/h4&gt;本研究通过理论分析和模型提出，强调了k-mer表示在宏基因组分析中的重要性及其优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/abdcelikkanat/revisitingkmers&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Obtaining effective representations of DNA sequences is crucial for genomeanalysis. Metagenomic binning, for instance, relies on genome representationsto cluster complex mixtures of DNA fragments from biological samples with theaim of determining their microbial compositions. In this paper, we revisitk-mer-based representations of genomes and provide a theoretical analysis oftheir use in representation learning. Based on the analysis, we propose alightweight and scalable model for performing metagenomic binning at the genomeread level, relying only on the k-mer compositions of the DNA fragments. Wecompare the model to recent genome foundation models and demonstrate that whilethe models are comparable in performance, the proposed model is significantlymore effective in terms of scalability, a crucial aspect for performingmetagenomic binning of real-world datasets.</description>
      <author>example@mail.com (Abdulkadir Celikkanat, Andres R. Masegosa, Thomas D. Nielsen)</author>
      <guid isPermaLink="false">2411.02125v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Topology-Aware Graph Augmentation for Predicting Clinical Trajectories in Neurocognitive Disorders</title>
      <link>http://arxiv.org/abs/2411.00888v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;静息态功能性磁共振成像(fMRI)得到的脑网络/图帮助研究神经认知障碍的基础病理生理，通过测量大脑中的神经活动。&lt;h4&gt;目的&lt;/h4&gt;提出一个拓扑感知图增强(TGA)框架，以提高基于学习的脑网络分析的模型泛化能力。&lt;h4&gt;方法&lt;/h4&gt;TGA框架包括一个预训练模型和一个任务特定模型，前者在大规模未标记的fMRI数据集上训练通用编码器，后者在小型目标数据集上执行下游任务。预训练模型中设计了两种新颖的拓扑感知图增强策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示TGA在1,688个fMRI扫描中优于多个最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;通过关注大脑网络的拓扑信息，TGA有效提升了模型在小样本数据集上的表现。&lt;h4&gt;总结&lt;/h4&gt;本研究通过拓扑感知的图增强方法，改善了脑网络分析的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain networks/graphs derived from resting-state functional MRI (fMRI) helpstudy underlying pathophysiology of neurocognitive disorders by measuringneuronal activities in the brain. Some studies utilize learning-based methodsfor brain network analysis, but typically suffer from low modelgeneralizability caused by scarce labeled fMRI data. As a notableself-supervised strategy, graph contrastive learning helps leverage auxiliaryunlabeled data. But existing methods generally arbitrarily perturb graphnodes/edges to generate augmented graphs, without considering essentialtopology information of brain networks. To this end, we propose atopology-aware graph augmentation (TGA) framework, comprising a pretext modelto train a generalizable encoder on large-scale unlabeled fMRI cohorts and atask-specific model to perform downstream tasks on a small target dataset. Inthe pretext model, we design two novel topology-aware graph augmentationstrategies: (1) hub-preserving node dropping that prioritizes preserving brainhub regions according to node importance, and (2) weight-dependent edgeremoving that focuses on keeping important functional connectivities based onedge weights. Experiments on 1, 688 fMRI scans suggest that TGA outperformsseveral state-of-the-art methods.</description>
      <author>example@mail.com (Qianqian Wang, Wei Wang, Yuqi Fang, Hong-Jun Li, Andrea Bozoki, Mingxia Liu)</author>
      <guid isPermaLink="false">2411.00888v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>PLATYPUS: Progressive Local Surface Estimator for Arbitrary-Scale Point Cloud Upsampling</title>
      <link>http://arxiv.org/abs/2411.00432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D点云在自动驾驶和机器人等应用中越来越重要，但传感器捕获的原始数据常常受到噪声和稀疏性的影响，给后续任务带来挑战。&lt;h4&gt;目的&lt;/h4&gt;提高点云的密度和均匀性，因此点云上采样变得至关重要。&lt;h4&gt;方法&lt;/h4&gt;提出了渐进式局部表面估计器（PLSE），通过基于曲率的采样技术选择性地针对高曲率区域，以更有效地捕捉复杂区域的局部特征。同时，引入了课程学习策略，根据点云中的曲率分布自然评估样本难度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该方法显著优于现有方法，能够生成高质量、密集的点云，且具有更高的准确性和细节。&lt;h4&gt;结论&lt;/h4&gt;PLSE方法在处理高曲率和复杂结构的点云上效果显著，首次在点云数据上实现了课程学习。&lt;h4&gt;总结&lt;/h4&gt;该研究为点云上采样提供了一种有效的解决方案，能够改善点云的质量和应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point clouds are increasingly vital for applications like autonomousdriving and robotics, yet the raw data captured by sensors often suffer fromnoise and sparsity, creating challenges for downstream tasks. Consequently,point cloud upsampling becomes essential for improving density and uniformity,with recent approaches showing promise by projecting randomly generated querypoints onto the underlying surface of sparse point clouds. However, thesemethods often result in outliers, non-uniformity, and difficulties in handlingregions with high curvature and intricate structures. In this work, we addressthese challenges by introducing the Progressive Local Surface Estimator (PLSE),which more effectively captures local features in complex regions through acurvature-based sampling technique that selectively targets high-curvatureareas. Additionally, we incorporate a curriculum learning strategy thatleverages the curvature distribution within the point cloud to naturally assessthe sample difficulty, enabling curriculum learning on point cloud data for thefirst time. The experimental results demonstrate that our approachsignificantly outperforms existing methods, achieving high-quality, dense pointclouds with superior accuracy and detail.</description>
      <author>example@mail.com (Donghyun Kim, Hyeonkyeong Kwon, Yumin Kim, Seong Jae Hwang)</author>
      <guid isPermaLink="false">2411.00432v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal NeRF Self-Supervision for LiDAR Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2411.02969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;LiDAR语义分割是自动驾驶感知中的一项基础任务，涉及将每个LiDAR点与语义标签关联。&lt;h4&gt;目的&lt;/h4&gt;提出一种半监督学习方法，利用未标记的LiDAR点云和相机图像的知识来改善LiDAR感知。&lt;h4&gt;方法&lt;/h4&gt;通过引入辅助NeRF头，从相机视角发射光线，预测密度和语义日志，同时使用Segment-Anything（SAM）模型生成未标记的通用掩码，将其与LiDAR渲染的像素语义融合以生成伪标签。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在nuScenes、SemanticKITTI和ScribbleKITTI等三个公共LiDAR语义分割基准上表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;提出的半监督学习方法能够有效提升LiDAR语义分割的性能，克服了仅依赖完全监督模型的局限性。&lt;h4&gt;总结&lt;/h4&gt;通过结合未标记LiDAR点云和相机图像，提出了一种创新的方法来改善LiDAR的语义分割效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR Semantic Segmentation is a fundamental task in autonomous drivingperception consisting of associating each LiDAR point to a semantic label.Fully-supervised models have widely tackled this task, but they require labelsfor each scan, which either limits their domain or requires impractical amountsof expensive annotations. Camera images, which are generally recorded alongsideLiDAR pointclouds, can be processed by the widely available 2D foundationmodels, which are generic and dataset-agnostic. However, distilling knowledgefrom 2D data to improve LiDAR perception raises domain adaptation challenges.For example, the classical perspective projection suffers from the parallaxeffect produced by the position shift between both sensors at their respectivecapture times. We propose a Semi-Supervised Learning setup to leverageunlabeled LiDAR pointclouds alongside distilled knowledge from the cameraimages. To self-supervise our model on the unlabeled scans, we add an auxiliaryNeRF head and cast rays from the camera viewpoint over the unlabeled voxelfeatures. The NeRF head predicts densities and semantic logits at each sampledray location which are used for rendering pixel semantics. Concurrently, wequery the Segment-Anything (SAM) foundation model with the camera image togenerate a set of unlabeled generic masks. We fuse the masks with the renderedpixel semantics from LiDAR to produce pseudo-labels that supervise the pixelpredictions. During inference, we drop the NeRF head and run our model withonly LiDAR. We show the effectiveness of our approach in three public LiDARSemantic Segmentation benchmarks: nuScenes, SemanticKITTI and ScribbleKITTI.</description>
      <author>example@mail.com (Xavier Timoneda, Markus Herb, Fabian Duerr, Daniel Goehring, Fisher Yu)</author>
      <guid isPermaLink="false">2411.02969v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Replace-then-Perturb: Targeted Adversarial Attacks With Visual Reasoning for Vision-Language Models</title>
      <link>http://arxiv.org/abs/2411.00898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的针对性对抗攻击通过对图像添加小扰动，使神经网络模型将图像估计为预定义的目标类别，尽管这可能不是正确的目标类别。&lt;h4&gt;目的&lt;/h4&gt;针对视觉语言模型（VLMs），生成能够让模型输出预期目标文本的扰动。&lt;h4&gt;方法&lt;/h4&gt;提出了两种新方法：1) Replace-then-Perturb：首先利用文本引导的分割模型找到目标对象，然后去除该对象并用所需提示进行填补；2) Contrastive-Adv：设计了一种新颖的对抗损失函数以生成更好的对抗样本。&lt;h4&gt;主要发现&lt;/h4&gt;Replace-then-Perturb和Contrastive-Adv在对抗攻击的基准测试中优于传统算法。&lt;h4&gt;结论&lt;/h4&gt;通过保持原始图像的整体性，生成的目标图像能够更好地应对视觉推理问题。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的新方法在对抗攻击方面表现出色，将公开源代码以便复现结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The conventional targeted adversarial attacks add a small perturbation to animage to make neural network models estimate the image as a predefined targetclass, even if it is not the correct target class. Recently, forvisual-language models (VLMs), the focus of targeted adversarial attacks is togenerate a perturbation that makes VLMs answer intended target text outputs.For example, they aim to make a small perturbation on an image to make VLMs'answers change from "there is an apple" to "there is a baseball." However,answering just intended text outputs is insufficient for tricky questions like"if there is a baseball, tell me what is below it." This is because the targetof the adversarial attacks does not consider the overall integrity of theoriginal image, thereby leading to a lack of visual reasoning. In this work, wefocus on generating targeted adversarial examples with visual reasoning againstVLMs. To this end, we propose 1) a novel adversarial attack procedure --namely, Replace-then-Perturb and 2) a contrastive learning-based adversarialloss -- namely, Contrastive-Adv. In Replace-then-Perturb, we first leverage atext-guided segmentation model to find the target object in the image. Then, weget rid of the target object and inpaint the empty space with the desiredprompt. By doing this, we can generate a target image corresponding to thedesired prompt, while maintaining the overall integrity of the original image.Furthermore, in Contrastive-Adv, we design a novel loss function to obtainbetter adversarial examples. Our extensive benchmark results demonstrate thatReplace-then-Perturb and Contrastive-Adv outperform the baseline adversarialattack algorithms. We note that the source code to reproduce the results willbe available.</description>
      <author>example@mail.com (Jonggyu Jang, Hyeonsu Lyu, Jungyeon Koh, Hyun Jong Yang)</author>
      <guid isPermaLink="false">2411.00898v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>STONE: A Submodular Optimization Framework for Active 3D Object Detection</title>
      <link>http://arxiv.org/abs/2410.03918v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D物体检测对自动驾驶和机器人等新兴应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的主动3D物体检测框架，以减少训练3D物体检测器的标注成本。&lt;h4&gt;方法&lt;/h4&gt;基于新颖的子模块优化公式，专门针对主动3D物体检测问题进行调整。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在处理数据不平衡和覆盖不同难度级别的LiDAR点云数据方面具有优势，并在实验中表现出与现有主动学习方法相比的先进性能和高计算效率。&lt;h4&gt;结论&lt;/h4&gt;提出的框架有效降低了3D物体检测器的标注成本，且表现优越。&lt;h4&gt;总结&lt;/h4&gt;研究展示了一个创新的解决方案，推动了3D物体检测技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ruiyum/stone&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D object detection is fundamentally important for various emergingapplications, including autonomous driving and robotics. A key requirement fortraining an accurate 3D object detector is the availability of a large amountof LiDAR-based point cloud data. Unfortunately, labeling point cloud data isextremely challenging, as accurate 3D bounding boxes and semantic labels arerequired for each potential object. This paper proposes a unified active 3Dobject detection framework, for greatly reducing the labeling cost of training3D object detectors. Our framework is based on a novel formulation ofsubmodular optimization, specifically tailored to the problem of active 3Dobject detection. In particular, we address two fundamental challengesassociated with active 3D object detection: data imbalance and the need tocover the distribution of the data, including LiDAR-based point cloud data ofvarying difficulty levels. Extensive experiments demonstrate that our methodachieves state-of-the-art performance with high computational efficiencycompared to existing active learning methods. The code is available athttps://github.com/RuiyuM/STONE.</description>
      <author>example@mail.com (Ruiyu Mao, Sarthak Kumar Maharana, Rishabh K Iyer, Yunhui Guo)</author>
      <guid isPermaLink="false">2410.03918v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>GraphXAIN: Narratives to Explain Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.02540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）是一种强大的机器学习技术，适用于图结构数据，但对非专业用户的可解释性存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出GraphXAIN，通过自然语言叙述解释GNN的个体预测，帮助非专家用户理解模型输出。&lt;h4&gt;方法&lt;/h4&gt;采用模型无关和解释器无关的XAI方法，结合大型语言模型（LLMs），整合图数据、GNN的个体预测、解释子图和特征重要性。&lt;h4&gt;主要发现&lt;/h4&gt;定义了XAI叙述和XAIDescriptions，强调叙述原则在有效解释中的重要性，展示了GraphXAIN在真实世界图数据集上的能力。&lt;h4&gt;结论&lt;/h4&gt;通过自然语言叙述，GraphXAIN有助于图实践者和非专业用户理解复杂GNN模型，提高对模型的理解和信任。&lt;h4&gt;总结&lt;/h4&gt;GraphXAIN能够改善传统图解释器输出的理解效果，提供更易于理解的解释方式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ADMAntwerp/GraphXAIN&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are a powerful technique for machine learning ongraph-structured data, yet they pose interpretability challenges, especiallyfor non-expert users. Existing GNN explanation methods often yield technicaloutputs such as subgraphs and feature importance scores, which are not easilyunderstood. Building on recent insights from social science and otherExplainable AI (XAI) methods, we propose GraphXAIN, a natural languagenarrative that explains individual predictions made by GNNs. We present amodel-agnostic and explainer-agnostic XAI approach that complements graphexplainers by generating GraphXAINs, using Large Language Models (LLMs) andintegrating graph data, individual predictions from GNNs, explanatorysubgraphs, and feature importances. We define XAI Narratives and XAIDescriptions, highlighting their distinctions and emphasizing the importance ofnarrative principles in effective explanations. By incorporating naturallanguage narratives, our approach supports graph practitioners and non-expertusers, aligning with social science research on explainability and enhancinguser understanding and trust in complex GNN models. We demonstrate GraphXAIN'scapabilities on a real-world graph dataset, illustrating how its generatednarratives can aid understanding compared to traditional graph explaineroutputs or other descriptive explanation methods.</description>
      <author>example@mail.com (Mateusz Cedro, David Martens)</author>
      <guid isPermaLink="false">2411.02540v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Target-Guided Adversarial Point Cloud Transformer Towards Recognition Against Real-world Corruptions</title>
      <link>http://arxiv.org/abs/2411.00462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024; code: https://github.com/Roywangj/APCT&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在3D视觉研究中，面对数据损坏实现稳健的3D感知是一个具有挑战性的难题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的架构APCT，以增强全局结构捕捉能力，提高对数据损坏的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;APCT结合了对抗性重要性识别器和目标引导提示器，通过对抗特征擦除机制进行训练，识别和整合对象相关的模式。&lt;h4&gt;主要发现&lt;/h4&gt;经过广泛实验，APCT在多个数据损坏基准测试中取得了最新的研究成果。&lt;h4&gt;结论&lt;/h4&gt;APCT方法有效提高了点云识别模型在数据损坏情况下的表现。&lt;h4&gt;总结&lt;/h4&gt;本研究通过引入APCT架构，显著提升了3D点云识别的鲁棒性，适应复杂数据环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/roywangj/apct&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving robust 3D perception in the face of corrupted data presents anchallenging hurdle within 3D vision research. Contemporary transformer-basedpoint cloud recognition models, albeit advanced, tend to overfit to specificpatterns, consequently undermining their robustness against corruption. In thiswork, we introduce the Target-Guided Adversarial Point Cloud Transformer,termed APCT, a novel architecture designed to augment global structure capturethrough an adversarial feature erasing mechanism predicated on patternsdiscerned at each step during training. Specifically, APCT integrates anAdversarial Significance Identifier and a Target-guided Promptor. TheAdversarial Significance Identifier, is tasked with discerning tokensignificance by integrating global contextual analysis, utilizing a structuralsalience index algorithm alongside an auxiliary supervisory mechanism. TheTarget-guided Promptor, is responsible for accentuating the propensity fortoken discard within the self-attention mechanism, utilizing the value derivedabove, consequently directing the model attention towards alternative segmentsin subsequent stages. By iteratively applying this strategy in multiple stepsduring training, the network progressively identifies and integrates anexpanded array of object-associated patterns. Extensive experiments demonstratethat our method achieves state-of-the-art results on multiple corruptionbenchmarks.</description>
      <author>example@mail.com (Jie Wang, Tingfa Xu, Lihe Ding, Jianan Li)</author>
      <guid isPermaLink="false">2411.00462v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for Improving the Explainability of Pediatric Brain Tumor Diagnosis</title>
      <link>http://arxiv.org/abs/2411.00609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管卷积神经网络（CNN）在脑肿瘤诊断中的表现良好，但其在临床工作流程中的应用受到限制，主要是因为模型预测的特征对放射科医师不明确，缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;通过结合MRI和放射学报告，在对比学习框架中提高CNN的可解释性。&lt;h4&gt;方法&lt;/h4&gt;在3D脑MRI扫描和放射学报告上训练多模态对比学习架构，学习有信息的MRI表示，同时整合肿瘤位置以改善模型的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;模型的注意力图与手动肿瘤分割的Dice分数为31.1%，并且在儿科低级别胶质瘤的基因标记分类测试中，分类性能达到87.7%，显著优于基线。&lt;h4&gt;结论&lt;/h4&gt;这些改进可以增强放射科医师对模型的信任，促进其在临床实践中的应用，提高肿瘤诊断的效率。&lt;h4&gt;总结&lt;/h4&gt;通过对比学习和放射学报告的整合，本研究展示了提高脑肿瘤诊断模型可解释性和性能的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the promising performance of convolutional neural networks (CNNs) inbrain tumor diagnosis from magnetic resonance imaging (MRI), their integrationinto the clinical workflow has been limited. That is mainly due to the factthat the features contributing to a model's prediction are unclear toradiologists and hence, clinically irrelevant, i.e., lack of explainability. Asthe invaluable sources of radiologists' knowledge and expertise, radiologyreports can be integrated with MRI in a contrastive learning (CL) framework,enabling learning from image-report associations, to improve CNNexplainability. In this work, we train a multimodal CL architecture on 3D brainMRI scans and radiology reports to learn informative MRI representations.Furthermore, we integrate tumor location, salient to several brain tumoranalysis tasks, into this framework to improve its generalizability. We thenapply the learnt image representations to improve explainability andperformance of genetic marker classification of pediatric Low-grade Glioma, themost prevalent brain tumor in children, as a downstream task. Our resultsindicate a Dice score of 31.1% between the model's attention maps and manualtumor segmentation (as an explainability measure) with test classificationperformance of 87.7%, significantly outperforming the baselines. Theseenhancements can build trust in our model among radiologists, facilitating itsintegration into clinical practices for more efficient tumor diagnosis.</description>
      <author>example@mail.com (Sara Ketabi, Matthias W. Wagner, Cynthia Hawkins, Uri Tabori, Birgit Betina Ertl-Wagner, Farzad Khalvati)</author>
      <guid isPermaLink="false">2411.00609v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Graph Neural Networks in Large-scale Traffic Incident Analysis with Concurrency Hypothesis</title>
      <link>http://arxiv.org/abs/2411.02542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Sigspatial 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管减少了交通事故死亡人数，但交通相关死亡率仍然偏高，亟需改进安全干预措施。&lt;h4&gt;目的&lt;/h4&gt;研究邻近节点发生交通事故的可能性，并提出有效的预测方法。&lt;h4&gt;方法&lt;/h4&gt;利用美国49个州的大规模图形化道路网络数据，提出并验证了并发假设；引入了平均邻居事故密度（ANCD）和平均邻居事故连续性（ANCC）两个新指标，并将其应用于统计检验。基于此，提出了并发先验（CP）方法，以增强图神经网络（GNN）模型在半监督交通事故预测中的能力。&lt;h4&gt;主要发现&lt;/h4&gt;将CP方法整合到12种先进的GNN架构中，F1分数提升幅度在3%到13%之间，AUC指标提升幅度在1.3%到9%之间。&lt;h4&gt;结论&lt;/h4&gt;CP方法显著提高了交通事故预测的准确性，展示了并发信息对GNN模型的增强效果。&lt;h4&gt;代码&lt;/h4&gt;代码已公开，地址为 https://github.com/xiwenc1/Incident-GNN-CP。&lt;h4&gt;总结&lt;/h4&gt;本研究通过引入并发假设和新指标，推动了交通事故预测方法的进步，为提高道路安全提供了新的视角和技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/xiwenc1/incident-gnn-cp&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent progress in reducing road fatalities, the persistently highrate of traffic-related deaths highlights the necessity for improved safetyinterventions. Leveraging large-scale graph-based nationwide road network dataacross 49 states in the USA, our study first posits the Concurrency Hypothesisfrom intuitive observations, suggesting a significant likelihood of incidentsoccurring at neighboring nodes within the road network. To quantify thisphenomenon, we introduce two novel metrics, Average Neighbor Crash Density(ANCD) and Average Neighbor Crash Continuity (ANCC), and subsequently employthem in statistical tests to validate the hypothesis rigorously. Building uponthis foundation, we propose the Concurrency Prior (CP) method, a powerfulapproach designed to enhance the predictive capabilities of general GraphNeural Network (GNN) models in semi-supervised traffic incident predictiontasks. Our method allows GNNs to incorporate concurrent incident information,as mentioned in the hypothesis, via tokenization with negligible extraparameters.  The extensive experiments, utilizing real-world data across states and citiesin the USA, demonstrate that integrating CP into 12 state-of-the-art GNNarchitectures leads to significant improvements, with gains ranging from 3% to13% in F1 score and 1.3% to 9% in AUC metrics. The code is publicly availableat https://github.com/xiwenc1/Incident-GNN-CP.</description>
      <author>example@mail.com (Xiwen Chen, Sayed Pedram Haeri Boroujeni, Xin Shu, Huayu Li, Abolfazl Razi)</author>
      <guid isPermaLink="false">2411.02542v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status</title>
      <link>http://arxiv.org/abs/2411.03004v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Advancements In Medical Foundation Models: Explainability,
  Robustness, Security, and Beyond (AIM-FM) at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;因果理解是循证医学的基本目标。在随机化无法实现时，因果推断方法可以从观察性数据的回顾性分析中估计治疗效果。&lt;h4&gt;目的&lt;/h4&gt;解决未观察到的混杂因素对因果推断的影响。&lt;h4&gt;方法&lt;/h4&gt;使用机器学习方法通过对未观察变量的插补来处理未观察到的混杂，并对分类器的误测进行校正。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法能够在满足必要假设的情况下，从临床记录中未观察的变量中恢复出无偏的因果效应估计。&lt;h4&gt;结论&lt;/h4&gt;本研究扩展了该方法，使用训练于临床记录的大型语言模型预测患者的吸烟状态，并应用测量误差校正来估计经胸超声心动图对死亡率的因果效应。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了利用先进的机器学习技术来处理临床数据中的未观察混杂因素，从而提高因果推断的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Causal understanding is a fundamental goal of evidence-based medicine. Whenrandomization is impossible, causal inference methods allow the estimation oftreatment effects from retrospective analysis of observational data. However,such analyses rely on a number of assumptions, often including that of nounobserved confounding. In many practical settings, this assumption is violatedwhen important variables are not explicitly measured in the clinical record.Prior work has proposed to address unobserved confounding with machine learningby imputing unobserved variables and then correcting for the classifier'smismeasurement. When such a classifier can be trained and the necessaryassumptions are met, this method can recover an unbiased estimate of a causaleffect. However, such work has been limited to synthetic data, simpleclassifiers, and binary variables. This paper extends this methodology by usinga large language model trained on clinical notes to predict patients' smokingstatus, which would otherwise be an unobserved confounder. We then apply ameasurement error correction on the categorical predicted smoking status toestimate the causal effect of transthoracic echocardiography on mortality inthe MIMIC dataset.</description>
      <author>example@mail.com (Samuel Lee, Zach Wood-Doughty)</author>
      <guid isPermaLink="false">2411.03004v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Cross-modal semantic segmentation for indoor environmental perception using single-chip millimeter-wave radar raw data</title>
      <link>http://arxiv.org/abs/2411.00499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5291 words, 17 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在消防和救援操作的背景下，提出了一种基于单芯片毫米波雷达的跨模态语义分割模型，用于室内环境感知。&lt;h4&gt;目的&lt;/h4&gt;提高室内环境的语义分割精度和效率。&lt;h4&gt;方法&lt;/h4&gt;引入了一种自动标签生成方法，利用LiDAR点云和占用栅格地图来获取高质量标签，模型基于U-Net，并结合空间注意力模块。&lt;h4&gt;主要发现&lt;/h4&gt;跨模态语义分割能更直观、准确地表示室内环境，且模型的分割性能对方位角的影响较小。&lt;h4&gt;结论&lt;/h4&gt;尽管随着距离的增加性能会下降，但通过合理设计模型可以减轻这一影响；使用原始ADC数据作为输入效果不佳，RA张量相比之下不如RD张量适合该模型。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种有效的室内环境感知方法，结合毫米波雷达和深度学习，优化了语义分割的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the context of firefighting and rescue operations, a cross-modal semanticsegmentation model based on a single-chip millimeter-wave (mmWave) radar forindoor environmental perception is proposed and discussed. To efficientlyobtain high-quality labels, an automatic label generation method utilizingLiDAR point clouds and occupancy grid maps is introduced. The proposedsegmentation model is based on U-Net. A spatial attention module isincorporated, which enhanced the performance of the mode. The resultsdemonstrate that cross-modal semantic segmentation provides a more intuitiveand accurate representation of indoor environments. Unlike traditional methods,the model's segmentation performance is minimally affected by azimuth. Althoughperformance declines with increasing distance, this can be mitigated by awell-designed model. Additionally, it was found that using raw ADC data asinput is ineffective; compared to RA tensors, RD tensors are more suitable forthe proposed model.</description>
      <author>example@mail.com (Hairuo Hu, Haiyong Cong, Zhuyu Shao, Yubo Bi, Jinghao Liu)</author>
      <guid isPermaLink="false">2411.00499v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>How to Bridge Spatial and Temporal Heterogeneity in Link Prediction? A Contrastive Method</title>
      <link>http://arxiv.org/abs/2411.00612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间异构网络在捕捉各种真实世界复杂系统的动态性和异质性方面发挥着重要作用，是链接预测的研究方向。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于对比学习的链接预测模型，克服现有方法未能捕捉细粒度差异分布模式和时间动态特征的局限性。&lt;h4&gt;方法&lt;/h4&gt;开发了一个多视角分层自监督架构，通过空间特征建模层和时间信息建模层分别捕捉空间异质性和时间异质性。&lt;h4&gt;主要发现&lt;/h4&gt;在四个真实世界动态异构网络数据集上进行的广泛实验表明，提出的模型在AUC和AP方面平均提高了10.10%和13.44%，优于现有最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习的视角有效地编码了空间和时间分布的异质性，增强了链接预测任务的自监督分层关系建模能力。&lt;h4&gt;总结&lt;/h4&gt;CLP模型在链接预测任务中表现出色，展示了时间异构网络研究的潜力和重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Heterogeneous Networks play a crucial role in capturing the dynamicsand heterogeneity inherent in various real-world complex systems, renderingthem a noteworthy research avenue for link prediction. However, existingmethods fail to capture the fine-grained differential distribution patterns andtemporal dynamic characteristics, which we refer to as spatial heterogeneityand temporal heterogeneity. To overcome such limitations, we propose a novel\textbf{C}ontrastive Learning-based \textbf{L}ink \textbf{P}rediction model,\textbf{CLP}, which employs a multi-view hierarchical self-supervisedarchitecture to encode spatial and temporal heterogeneity. Specifically, aimingat spatial heterogeneity, we develop a spatial feature modeling layer tocapture the fine-grained topological distribution patterns from node- andedge-level representations, respectively. Furthermore, aiming at temporalheterogeneity, we devise a temporal information modeling layer to perceive theevolutionary dependencies of dynamic graph topologies from time-levelrepresentations. Finally, we encode the spatial and temporal distributionheterogeneity from a contrastive learning perspective, enabling a comprehensiveself-supervised hierarchical relation modeling for the link prediction task.Extensive experiments conducted on four real-world dynamic heterogeneousnetwork datasets verify that our \mymodel consistently outperforms thestate-of-the-art models, demonstrating an average improvement of 10.10\%,13.44\% in terms of AUC and AP, respectively.</description>
      <author>example@mail.com (Yu Tai, Xinglong Wu, Hongwei Yang, Hui He, Duanjing Chen, Yuanming Shao, Weizhe Zhang)</author>
      <guid isPermaLink="false">2411.00612v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>EOSnet: Embedded Overlap Structures for Graph Neural Networks in Predicting Material Properties</title>
      <link>http://arxiv.org/abs/2411.02579v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在材料性质预测中表现出色，但常常难以捕捉多体相互作用，并且需要大量手动特征工程。&lt;h4&gt;目的&lt;/h4&gt;提出EOSnet（图神经网络的嵌入重叠结构），以解决现有模型的局限性。&lt;h4&gt;方法&lt;/h4&gt;采用高斯重叠矩阵（GOM）指纹作为节点特征，嵌入GNN架构中，能够有效编码多体相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;EOSnet在多种材料性质预测任务中表现优越，尤其是在对多体相互作用敏感的性质预测中，带隙预测的平均绝对误差为0.163 eV，超越了以往的最先进模型。&lt;h4&gt;结论&lt;/h4&gt;嵌入GOM指纹增强了GNN捕捉复杂原子相互作用的能力，EOSnet成为材料发现和性质预测的强大工具。&lt;h4&gt;总结&lt;/h4&gt;EOSnet通过创新性地集成GOM指纹，克服了传统GNN在材料性质预测中的局限性，展示了在多个任务中的卓越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as powerful tools for predictingmaterial properties, yet they often struggle to capture many-body interactionsand require extensive manual feature engineering. Here, we present EOSnet(Embedded Overlap Structures for Graph Neural Networks), a novel approach thataddresses these limitations by incorporating Gaussian Overlap Matrix (GOM)fingerprints as node features within the GNN architecture. Unlike models thatrely on explicit angular terms or human-engineered features, EOSnet efficientlyencodes many-body interactions through orbital overlap matrices, providing arotationally invariant and transferable representation of atomic environments.The model demonstrates superior performance across various materials propertyprediction tasks, achieving particularly notable results in propertiessensitive to many-body interactions. For band gap prediction, EOSnet achieves amean absolute error of 0.163 eV, surpassing previous state-of-the-art models.The model also excels in predicting mechanical properties and classifyingmaterials, with 97.7\% accuracy in metal/non-metal classification. Theseresults demonstrate that embedding GOM fingerprints into node features enhancesthe ability of GNNs to capture complex atomic interactions, making EOSnet apowerful tool for materials discovery and property prediction.</description>
      <author>example@mail.com (Shuo Tao, Li Zhu)</author>
      <guid isPermaLink="false">2411.02579v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Watson: A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents</title>
      <link>http://arxiv.org/abs/2411.03455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）在复杂软件系统中扮演着越来越重要的角色，尤其是在FM驱动的自主软件（Agentware）中。&lt;h4&gt;目的&lt;/h4&gt;指出传统操作可观察性在FM驱动软件中的局限性，并引入认知可观察性作为新的必要观察类型。&lt;h4&gt;方法&lt;/h4&gt;提出一个新框架，提供对代理隐性推理过程的认知可观察性，并通过案例研究验证其有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该框架提高了Agentware的可调试性，增强了其能力，尤其是在AutoCodeRover这一前沿Agentware的应用中。&lt;h4&gt;结论&lt;/h4&gt;认知可观察性能够有效提升Agentware的性能和可调试性，从而应对复杂软件系统中的挑战。&lt;h4&gt;总结&lt;/h4&gt;本文强调了在FM驱动的软件中引入认知可观察性的必要性，并展示了其对软件开发的重要影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As foundation models (FMs) play an increasingly prominent role in complexsoftware systems, such as FM-powered agentic software (i.e., Agentware), theyintroduce significant challenges for developers regarding observability. Unliketraditional software, agents operate autonomously, using extensive data andopaque implicit reasoning, making it difficult to observe and understand theirbehavior during runtime, especially when they take unexpected actions orencounter errors. In this paper, we highlight the limitations of traditionaloperational observability in the context of FM-powered software, and introducecognitive observability as a new type of required observability that hasemerged for such innovative systems. We then propose a novel framework thatprovides cognitive observability into the implicit reasoning processes ofagents (a.k.a. reasoning observability), and demonstrate the effectiveness ofour framework in boosting the debuggability of Agentware and, in turn, theabilities of an Agentware through a case study on AutoCodeRover, a cuttingedgeAgentware for autonomous program improvement.</description>
      <author>example@mail.com (Benjamin Rombaut, Sogol Masoumzadeh, Kirill Vasilevski, Dayi Lin, Ahmed E. Hassan)</author>
      <guid isPermaLink="false">2411.03455v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Differentiable Physics-based System Identification for Robotic Manipulation of Elastoplastic Materials</title>
      <link>http://arxiv.org/abs/2411.00554v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Underreivew on the Internation Journal of Robotics Research&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人操作体积弹塑性变形材料（如面团和粘土）处于初级阶段，主要由于高维空间中的建模和感知困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的可微分物理基础系统识别框架（DPSI），帮助机器人臂推断弹塑性材料和环境的物理参数。&lt;h4&gt;方法&lt;/h4&gt;利用简单的操作动作和不完整的3D点云，从实际交互中估计材料的物理参数，以使仿真与现实世界对齐。&lt;h4&gt;主要发现&lt;/h4&gt;通过仅一次真实世界的交互，可以准确估计杨氏模量、泊松比、屈服应力和摩擦系数，从而模拟未见和长时间操作下的真实变形行为。&lt;h4&gt;结论&lt;/h4&gt;DPSI框架提供了物理直观的参数解释，相较于深度神经网络等黑箱方法，更易于理解。&lt;h4&gt;总结&lt;/h4&gt;DPSI框架有效解决了在高维空间中进行精确操作的挑战，为机器人操控弹塑性材料提供了新的方法论。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic manipulation of volumetric elastoplastic deformable materials, fromfoods such as dough to construction materials like clay, is in its infancy,largely due to the difficulty of modelling and perception in a high-dimensionalspace. Simulating the dynamics of such materials is computationally expensive.It tends to suffer from inaccurately estimated physics parameters of thematerials and the environment, impeding high-precision manipulation. Estimatingsuch parameters from raw point clouds captured by optical cameras suffersfurther from heavy occlusions. To address this challenge, this work introducesa novel Differentiable Physics-based System Identification (DPSI) frameworkthat enables a robot arm to infer the physics parameters of elastoplasticmaterials and the environment using simple manipulation motions and incomplete3D point clouds, aligning the simulation with the real world. Extensiveexperiments show that with only a single real-world interaction, the estimatedparameters, Young's modulus, Poisson's ratio, yield stress and frictioncoefficients, can accurately simulate visually and physically realisticdeformation behaviours induced by unseen and long-horizon manipulation motions.Additionally, the DPSI framework inherently provides physically intuitiveinterpretations for the parameters in contrast to black-box approaches such asdeep neural networks.</description>
      <author>example@mail.com (Xintong Yang, Ze Ji, Yu-Kun Lai)</author>
      <guid isPermaLink="false">2411.00554v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>FISHing in Uncertainty: Synthetic Contrastive Learning for Genetic Aberration Detection</title>
      <link>http://arxiv.org/abs/2411.01025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;检测基因异常在癌症诊断中至关重要，通常通过荧光原位杂交(FISH)进行。然而，现有的FISH图像分类方法面临信号变异、昂贵的人工标注需求以及未能充分解决内在不确定性等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，利用合成图像消除人工标注的需求，并通过联合对比和分类目标进行训练，以有效应对类别间的变异。&lt;h4&gt;方法&lt;/h4&gt;我们的方法在合成数据上训练，并在真实的手动标注FISH图像数据集上进行测试，展示了优秀的泛化能力和不确定性校准。&lt;h4&gt;主要发现&lt;/h4&gt;模型在分类准确性和不确定性量化方面表现出色，在50%最确定的案例中，分类准确率达到96.7%。&lt;h4&gt;结论&lt;/h4&gt;所提出的端到端方法减少了对人员和时间的需求，并通过其准确性和适应性改善了诊断工作流程。&lt;h4&gt;总结&lt;/h4&gt;所有代码和数据均可公开访问，链接为：https://github.com/SimonBon/FISHing&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-73158-7_3&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/simonbon/fishing&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting genetic aberrations is crucial in cancer diagnosis, typicallythrough fluorescence in situ hybridization (FISH). However, existing FISH imageclassification methods face challenges due to signal variability, the need forcostly manual annotations and fail to adequately address the intrinsicuncertainty. We introduce a novel approach that leverages synthetic images toeliminate the requirement for manual annotations and utilizes a jointcontrastive and classification objective for training to account forinter-class variation effectively. We demonstrate the superior generalizationcapabilities and uncertainty calibration of our method, which is trained onsynthetic data, by testing it on a manually annotated dataset of real-worldFISH images. Our model offers superior calibration in terms of classificationaccuracy and uncertainty quantification with a classification accuracy of 96.7%among the 50% most certain cases. The presented end-to-end method reduces thedemands on personnel and time and improves the diagnostic workflow due to itsaccuracy and adaptability. All code and data is publicly accessible at:https://github.com/SimonBon/FISHing</description>
      <author>example@mail.com (Simon Gutwein, Martin Kampel, Sabine Taschner-Mandl, Roxane Licandro)</author>
      <guid isPermaLink="false">2411.01025v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Table Representations with LLM-powered Synthetic Data Generation</title>
      <link>http://arxiv.org/abs/2411.03356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  the Thirty-Eighth Annual Conference on Neural Information Processing
  Systems Table Representation Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在数据驱动决策时代，准确的表格级表示和高效的表格推荐系统对表格管理、发现和分析变得越来越重要。&lt;h4&gt;目的&lt;/h4&gt;解决现有表格数据表示方法的局限性，特别是它们对单元格级任务的关注和高质量训练数据的缺乏。&lt;h4&gt;方法&lt;/h4&gt;首先定义表格相似性的清晰标准，然后建立基于大语言模型（LLMs）的合成数据生成流程，创建适用于表格级表示学习的大规模合成数据集。&lt;h4&gt;主要发现&lt;/h4&gt;通过手动验证和性能比较，证明我们生成的合成数据与提出的表格相似性定义一致，并显著提升了表格表示，改善了推荐性能。&lt;h4&gt;结论&lt;/h4&gt;我们的合成数据生成管道有效地支持了表格级表示学习，并提升了表格推荐系统的表现。&lt;h4&gt;总结&lt;/h4&gt;该研究为改善表格数据表示和推荐提供了新的思路和方法，推动了数据驱动企业的数据管理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the era of data-driven decision-making, accurate table-levelrepresentations and efficient table recommendation systems are becomingincreasingly crucial for improving table management, discovery, and analysis.However, existing approaches to tabular data representation often facelimitations, primarily due to their focus on cell-level tasks and the lack ofhigh-quality training data. To address these challenges, we first formulate aclear definition of table similarity in the context of data transformationactivities within data-driven enterprises. This definition serves as thefoundation for synthetic data generation, which require a well-defined datageneration process. Building on this, we propose a novel synthetic datageneration pipeline that harnesses the code generation and data manipulationcapabilities of Large Language Models (LLMs) to create a large-scale syntheticdataset tailored for table-level representation learning. Through manualvalidation and performance comparisons on the table recommendation task, wedemonstrate that the synthetic data generated by our pipeline aligns with ourproposed definition of table similarity and significantly enhances tablerepresentations, leading to improved recommendation performance.</description>
      <author>example@mail.com (Dayu Yang, Natawut Monaikul, Amanda Ding, Bozhao Tan, Kishore Mosaliganti, Giri Iyengar)</author>
      <guid isPermaLink="false">2411.03356v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology</title>
      <link>http://arxiv.org/abs/2411.03495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024 Workshop on Large Foundation Models for
  Educational Assessment (FM-Assess)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在智能辅导系统（ITSs）中自动生成提示的潜力，以增强学生学习。&lt;h4&gt;目的&lt;/h4&gt;探讨如何使用LLMs生成针对学生误解的有效提示，并满足特定的教育目标。&lt;h4&gt;方法&lt;/h4&gt;使用GPT-4o和Llama-3-8B-instruct作为教师，生成数学练习的提示，模拟高中学生的学习过程，并基于认知科学原则设计。&lt;h4&gt;主要发现&lt;/h4&gt;1) 确定模拟学生在中学数学练习中的错误模式；2) 开发并评估多种提示，观察其在生成自我纠正提示中的有效性；3) 测试最佳提示，比较不同模型的表现。&lt;h4&gt;结论&lt;/h4&gt;GPT-4o生成的提示在特定错误和常见数学错误的提示方面效果显著，而Llama-3-8B-Instruct的整体表现优于GPT-4o。提示的温度设置对模型错误有影响，较低温度下的提示效果更佳。&lt;h4&gt;总结&lt;/h4&gt;LLMs在提供提示后，特别是在低温设置下，显著提高了问题解决和响应修订能力，但某些模型在高温设置下表现下降。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The automatic generation of hints by Large Language Models (LLMs) withinIntelligent Tutoring Systems (ITSs) has shown potential to enhance studentlearning. However, generating pedagogically sound hints that address studentmisconceptions and adhere to specific educational objectives remainschallenging. This work explores using LLMs (GPT-4o and Llama-3-8B-instruct) asteachers to generate effective hints for students simulated through LLMs(GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling mathexercises designed for human high-school students, and designed using cognitivescience principles. We present here the study of several dimensions: 1)identifying error patterns made by simulated students on secondary-level mathexercises; 2) developing various prompts for GPT-4o as a teacher and evaluatingtheir effectiveness in generating hints that enable simulated students toself-correct; and 3) testing the best-performing prompts, based on theirability to produce relevant hints and facilitate error correction, withLlama-3-8B-Instruct as the teacher, allowing for a performance comparison withGPT-4o. The results show that model errors increase with higher temperaturesettings. Notably, when hints are generated by GPT-4o, the most effectiveprompts include prompts tailored to specific errors as well as promptsproviding general hints based on common mathematical errors. Interestingly,Llama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o.Also the problem-solving and response revision capabilities of the LLMs asstudents, particularly GPT-3.5-turbo, improved significantly after receivinghints, especially at lower temperature settings. However, models likeMistral-7B-Instruct demonstrated a decline in performance as the temperatureincreased.</description>
      <author>example@mail.com (Junior Cedric Tonga, Benjamin Clement, Pierre-Yves Oudeyer)</author>
      <guid isPermaLink="false">2411.03495v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>On Deep Learning for Geometric and Semantic Scene Understanding Using On-Vehicle 3D LiDAR</title>
      <link>http://arxiv.org/abs/2411.00600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis (Durham University, Computer Science), 149 pages (the 2024
  BMVA Sullivan Doctoral Thesis Prize runner-up). Includes published content
  from arXiv:2407.10159 (ECCV 2024 ORAL), arXiv:2303.11203 (CVPR 2023), and
  arXiv:2406.10068 (3DV 2021), with minor revisions to the examined version:
  https://etheses.dur.ac.uk/15738/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D LiDAR点云数据对计算机视觉、机器人技术和自动驾驶的场景感知至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高与LiDAR相关任务的整体准确性和效率，推动自主驾驶技术的发展。&lt;h4&gt;方法&lt;/h4&gt;提出DurLAR数据集，采用新型管道和RAPiD特征，结合较小的架构以减少对真实标注的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;DurLAR是首个高保真128通道3D LiDAR数据集，提供全景环境（近红外）和反射率图像；新方法在分割准确性上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;所有贡献均已被同行评审会议接受，显示出在3D LiDAR应用中提高了准确性和效率。&lt;h4&gt;总结&lt;/h4&gt;本文提出的方法和数据集为自主驾驶领域的3D LiDAR应用提供了重要的技术进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/l1997i/DurLAR&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D LiDAR point cloud data is crucial for scene perception in computer vision,robotics, and autonomous driving. Geometric and semantic scene understanding,involving 3D point clouds, is essential for advancing autonomous drivingtechnologies. However, significant challenges remain, particularly in improvingthe overall accuracy (e.g., segmentation accuracy, depth estimation accuracy,etc.) and efficiency of these systems. To address the challenge in terms ofaccuracy related to LiDAR-based tasks, we present DurLAR, the firsthigh-fidelity 128-channel 3D LiDAR dataset featuring panoramic ambient (nearinfrared) and reflectivity imagery. To improve efficiency in 3D segmentationwhile ensuring the accuracy, we propose a novel pipeline that employs a smallerarchitecture, requiring fewer ground-truth annotations while achieving superiorsegmentation accuracy compared to contemporary approaches. To improve thesegmentation accuracy, we introduce Range-Aware Pointwise Distance Distribution(RAPiD) features and the associated RAPiD-Seg architecture. All contributionshave been accepted by peer-reviewed conferences, underscoring the advancementsin both accuracy and efficiency in 3D LiDAR applications for autonomousdriving. Full abstract: https://etheses.dur.ac.uk/15738/.</description>
      <author>example@mail.com (Li Li)</author>
      <guid isPermaLink="false">2411.00600v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>JPEC: A Novel Graph Neural Network for Competitor Retrieval in Financial Knowledge Graphs</title>
      <link>http://arxiv.org/abs/2411.02692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures, accepted by SIGIR'24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;知识图谱因其有效组织和分析复杂数据的能力而受到欢迎。&lt;h4&gt;目的&lt;/h4&gt;探索图嵌入技术在金融知识图谱中识别竞争对手的应用。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的图嵌入模型JPEC，利用图神经网络从一阶和二阶节点邻近性以及重要特征中学习以进行竞争对手检索。&lt;h4&gt;主要发现&lt;/h4&gt;JPEC在广泛实验中超越了大多数现有模型，展示了其在竞争对手检索中的有效性。&lt;h4&gt;结论&lt;/h4&gt;JPEC模型能够有效应对知识图谱的独特属性，提升竞争对手识别的准确性。&lt;h4&gt;总结&lt;/h4&gt;本研究为金融领域的竞争对手识别提供了一种新的解决方案，表明图嵌入技术的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3626772.3657677&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge graphs have gained popularity for their ability to organize andanalyze complex data effectively. When combined with graph embeddingtechniques, such as graph neural networks (GNNs), knowledge graphs become apotent tool in providing valuable insights. This study explores the applicationof graph embedding in identifying competitors from a financial knowledge graph.Existing state-of-the-art(SOTA) models face challenges due to the uniqueattributes of our knowledge graph, including directed and undirectedrelationships, attributed nodes, and minimal annotated competitor connections.To address these challenges, we propose a novel graph embedding model,JPEC(JPMorgan Proximity Embedding for Competitor Detection), which utilizesgraph neural network to learn from both first-order and second-order nodeproximity together with vital features for competitor retrieval. JPEC hadoutperformed most existing models in extensive experiments, showcasing itseffectiveness in competitor retrieval.</description>
      <author>example@mail.com (Wanying Ding, Manoj Cherukumalli, Santosh Chikoti, Vinay K. Chaudhri)</author>
      <guid isPermaLink="false">2411.02692v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>ViTally Consistent: Scaling Biological Representation Learning for Cell Microscopy</title>
      <link>http://arxiv.org/abs/2411.02572v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Foundation Models for Science Workshop (38th Conference
  on Neural Information Processing Systems). 18 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模细胞显微镜筛选用于药物发现和分子生物学研究，以研究数百万种化学和基因扰动对细胞的影响。&lt;h4&gt;目的&lt;/h4&gt;开发模型，将显微镜图像映射到特征空间，以一致地表示不同的生物表型。&lt;h4&gt;方法&lt;/h4&gt;提出了迄今为止最大的细胞显微镜数据基础模型，1.9亿参数的ViT-G/8 MAE，基于超过80亿个显微镜图像剪裁训练而成。&lt;h4&gt;主要发现&lt;/h4&gt;新模型在遗传扰动的线性可分性上提高了60%，并在全基因组生物关系召回和重复一致性基准测试中表现最佳。自监督视觉变换器在中间块中产生的生物学意义更强的表示。&lt;h4&gt;结论&lt;/h4&gt;通过使用精心策划和多样化的数据集以及生物学驱动的线性探测任务，显著提高了模型性能，提供了构建大规模生物数据基础模型的一般策略的见解。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了如何通过优化数据集和模型训练方式，提升细胞显微镜图像分析的生物学意义，为生物数据的基础模型开发提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale cell microscopy screens are used in drug discovery and molecularbiology research to study the effects of millions of chemical and geneticperturbations on cells. To use these images in downstream analysis, we needmodels that can map each image into a feature space that represents diversebiological phenotypes consistently, in the sense that perturbations withsimilar biological effects have similar representations. In this work, wepresent the largest foundation model for cell microscopy data to date, a new1.9 billion-parameter ViT-G/8 MAE trained on over 8 billion microscopy imagecrops. Compared to a previous published ViT-L/8 MAE, our new model achieves a60% improvement in linear separability of genetic perturbations and obtains thebest overall performance on whole-genome biological relationship recall andreplicate consistency benchmarks. Beyond scaling, we developed two key methodsthat improve performance: (1) training on a curated and diverse dataset; and,(2) using biologically motivated linear probing tasks to search across eachtransformer block for the best candidate representation of whole-genomescreens. We find that many self-supervised vision transformers, pretrained oneither natural or microscopy images, yield significantly more biologicallymeaningful representations of microscopy images in their intermediate blocksthan in their typically used final blocks. More broadly, our approach andresults provide insights toward a general strategy for successfully buildingfoundation models for large-scale biological data.</description>
      <author>example@mail.com (Kian Kenyon-Dean, Zitong Jerry Wang, John Urbanik, Konstantin Donhauser, Jason Hartford, Saber Saberian, Nil Sahin, Ihab Bendidi, Safiye Celik, Marta Fay, Juan Sebastian Rodriguez Vera, Imran S Haque, Oren Kraus)</author>
      <guid isPermaLink="false">2411.02572v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities</title>
      <link>http://arxiv.org/abs/2411.01053v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习方法如CLIP利用自然配对的数据（例如图像及其对应的文本描述）来学习可以有效转移到下游任务的一般表示。&lt;h4&gt;目的&lt;/h4&gt;解决在机器人、医疗和视频等领域需要同时支持多种数据类型的问题，并提升学习表示的质量。&lt;h4&gt;方法&lt;/h4&gt;提出Symile，一种简单的对比学习方法，能够捕捉任意数量模态之间的高阶信息，并提供灵活的、架构无关的目标来学习模态特定的表示。&lt;h4&gt;主要发现&lt;/h4&gt;Symile在交叉模态分类和检索任务中超越了成对CLIP，即使在数据中缺失某些模态的情况下也表现优异。&lt;h4&gt;结论&lt;/h4&gt;Symile的表示形式为预测其余模态提供了充分的统计信息，并在多个实验中表现出色，包括一个包含3300万图像、文本和音频样本的多语言数据集，以及胸部X光、心电图和实验室测量的临床数据集。&lt;h4&gt;总结&lt;/h4&gt;所有使用的数据显示和代码均可在https://github.com/rajesh-lab/symile上公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/rajesh-lab/symile&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning methods, such as CLIP, leverage naturally paireddata-for example, images and their corresponding text captions-to learn generalrepresentations that transfer efficiently to downstream tasks. While suchapproaches are generally applied to two modalities, domains such as robotics,healthcare, and video need to support many types of data at once. We show thatthe pairwise application of CLIP fails to capture joint information betweenmodalities, thereby limiting the quality of the learned representations. Toaddress this issue, we present Symile, a simple contrastive learning approachthat captures higher-order information between any number of modalities. Symileprovides a flexible, architecture-agnostic objective for learningmodality-specific representations. To develop Symile's objective, we derive alower bound on total correlation, and show that Symile representations for anyset of modalities form a sufficient statistic for predicting the remainingmodalities. Symile outperforms pairwise CLIP, even with modalities missing inthe data, on cross-modal classification and retrieval across severalexperiments including on an original multilingual dataset of 33M image, textand audio samples and a clinical dataset of chest X-rays, electrocardiograms,and laboratory measurements. All datasets and code used in this work arepublicly available at https://github.com/rajesh-lab/symile.</description>
      <author>example@mail.com (Adriel Saporta, Aahlad Puli, Mark Goldstein, Rajesh Ranganath)</author>
      <guid isPermaLink="false">2411.01053v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Potentials and Challenges of Using Large Language Models for the Analysis of Transcriptional Regulation of Long Non-coding RNAs</title>
      <link>http://arxiv.org/abs/2411.03522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;长非编码RNA (lncRNA) 在基因调控和疾病机制中扮演重要角色，但其序列复杂性和多样性、功能机制及表达调控的知识有限，给研究带来挑战。&lt;h4&gt;目的&lt;/h4&gt;系统探索大语言模型 (LLMs) 在与lncRNA基因转录调控相关的序列分析中的潜力和局限性。&lt;h4&gt;方法&lt;/h4&gt;通过大量实验评估微调的基因组基础模型在逐渐复杂任务上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;微调的基因组基础模型在复杂任务上表现出良好的性能。&lt;h4&gt;结论&lt;/h4&gt;任务复杂性、模型选择、数据质量和生物学可解释性对lncRNA基因表达调控研究有重要影响。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了LLMs在lncRNA研究中的应用潜力，并强调了影响研究结果的重要因素。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Research on long non-coding RNAs (lncRNAs) has garnered significant attentiondue to their critical roles in gene regulation and disease mechanisms. However,the complexity and diversity of lncRNA sequences, along with the limitedknowledge of their functional mechanisms and the regulation of theirexpressions, pose significant challenges to lncRNA studies. Given thetremendous success of large language models (LLMs) in capturing complexdependencies in sequential data, this study aims to systematically explore thepotential and limitations of LLMs in the sequence analysis related to thetranscriptional regulation of lncRNA genes. Our extensive experimentsdemonstrated promising performance of fine-tuned genome foundation models onprogressively complex tasks. Furthermore, we conducted an insightful analysisof the critical impact of task complexity, model selection, data quality, andbiological interpretability for the studies of the regulation of lncRNA geneexpression.</description>
      <author>example@mail.com (Wei Wang, Zhichao Hou, Xiaorui Liu, Xinxia Peng)</author>
      <guid isPermaLink="false">2411.03522v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>PCoTTA: Continual Test-Time Adaptation for Multi-Task Point Cloud Understanding</title>
      <link>http://arxiv.org/abs/2411.00632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种创新的框架PCoTTA，用于多任务点云理解中的持续测试时间适应。&lt;h4&gt;目的&lt;/h4&gt;增强模型在不断变化的目标域中的迁移能力。&lt;h4&gt;方法&lt;/h4&gt;引入多任务设置，通过一个统一模型处理多个任务，包含三个关键组件：自动原型混合（APM）、高斯散布特征转移（GSFS）和对比原型排斥（CPR）。&lt;h4&gt;主要发现&lt;/h4&gt;APM通过相似性平衡因子自动混合源原型和可学习原型，GSFS动态转移测试样本，CPR使每个原型在适应过程中可区分。&lt;h4&gt;结论&lt;/h4&gt;实验比较为PCoTTA设定了新的基准，展示了其在提升模型迁移能力方面的优越性。&lt;h4&gt;总结&lt;/h4&gt;PCoTTA为多任务适应提供了有效解决方案，显著改善了模型在动态目标域中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present PCoTTA, an innovative, pioneering framework forContinual Test-Time Adaptation (CoTTA) in multi-task point cloud understanding,enhancing the model's transferability towards the continually changing targetdomain. We introduce a multi-task setting for PCoTTA, which is practical andrealistic, handling multiple tasks within one unified model during thecontinual adaptation. Our PCoTTA involves three key components: automaticprototype mixture (APM), Gaussian Splatted feature shifting (GSFS), andcontrastive prototype repulsion (CPR). Firstly, APM is designed toautomatically mix the source prototypes with the learnable prototypes with asimilarity balancing factor, avoiding catastrophic forgetting. Then, GSFSdynamically shifts the testing sample toward the source domain, mitigatingerror accumulation in an online manner. In addition, CPR is proposed to pullthe nearest learnable prototype close to the testing feature and push it awayfrom other prototypes, making each prototype distinguishable during theadaptation. Experimental comparisons lead to a new benchmark, demonstratingPCoTTA's superiority in boosting the model's transferability towards thecontinually changing target domain.</description>
      <author>example@mail.com (Jincen Jiang, Qianyu Zhou, Yuhang Li, Xinkui Zhao, Meili Wang, Lizhuang Ma, Jian Chang, Jian Jun Zhang, Xuequan Lu)</author>
      <guid isPermaLink="false">2411.00632v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>LEARNER: Learning Granular Labels from Coarse Labels using Contrastive Learning</title>
      <link>http://arxiv.org/abs/2411.01144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review at ISBI 2025 conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在主动患者护理中，判断治疗是否有效是一个关键问题，尤其是在短期内变化微妙时。&lt;h4&gt;目的&lt;/h4&gt;探讨能否利用多患者数据训练模型，以预测单个患者扫描中的微小变化。&lt;h4&gt;方法&lt;/h4&gt;使用深度学习（DL）技术，对多患者扫描进行训练，评估其在个体扫描中的预测能力。&lt;h4&gt;主要发现&lt;/h4&gt;经过多患者数据预训练的模型能够更好地预测单个患者扫描中的细微差异，采用对比学习方法。&lt;h4&gt;结论&lt;/h4&gt;在缺乏个性化大规模数据集的情况下，计算机视觉模型仍能有效学习并识别个体间的细微变化。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，利用多患者数据训练的模型能够提高对个体扫描中微小变化的预测能力，具有重要的临床应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A crucial question in active patient care is determining if a treatment ishaving the desired effect, especially when changes are subtle over shortperiods. We propose using inter-patient data to train models that can learn todetect these fine-grained changes within a single patient. Specifically, can amodel trained on multi-patient scans predict subtle changes in an individualpatient's scans? Recent years have seen increasing use of deep learning (DL) inpredicting diseases using biomedical imaging, such as predicting COVID-19severity using lung ultrasound (LUS) data. While extensive literature exists onsuccessful applications of DL systems when well-annotated large-scale datasetsare available, it is quite difficult to collect a large corpus of personalizeddatasets for an individual. In this work, we investigate the ability of recentcomputer vision models to learn fine-grained differences while being trained ondata showing larger differences. We evaluate on an in-house LUS dataset and apublic ADNI brain MRI dataset. We find that models pre-trained on clips frommultiple patients can better predict fine-grained differences in scans from asingle patient by employing contrastive learning.</description>
      <author>example@mail.com (Gautam Gare, Jana Armouti, Nikhil Madaan, Rohan Panda, Tom Fox, Laura Hutchins, Amita Krishnan, Ricardo Rodriguez, Bennett DeBoisblanc, Deva Ramanan, John Galeotti)</author>
      <guid isPermaLink="false">2411.01144v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Two-Stage Pretraining for Molecular Property Prediction in the Wild</title>
      <link>http://arxiv.org/abs/2411.03537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的属性预测对加速新分子的发现至关重要，但深度学习模型的性能往往依赖于大量昂贵且耗时的标注数据。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在实验验证数据稀缺的情况下，依然表现良好的分子属性预测模型。&lt;h4&gt;方法&lt;/h4&gt;引入MoleVers，一个多功能的预训练模型，采用两阶段预训练策略。第一阶段通过掩蔽原子预测和动态去噪学习分子表征；第二阶段使用便宜的计算方法获取的辅助标签进一步预训练。&lt;h4&gt;主要发现&lt;/h4&gt;MoleVers在包含22个多样属性的分子数据集上的评估中，20个数据集达到最先进的结果，另外两个数据集排名第二。&lt;h4&gt;结论&lt;/h4&gt;MoleVers有效地弥合了对数据需求高的模型与实际条件下标注稀缺之间的差距。&lt;h4&gt;总结&lt;/h4&gt;MoleVers的两阶段框架使其能够在标注有限的情况下，进行有效的分子属性预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate property prediction is crucial for accelerating the discovery of newmolecules. Although deep learning models have achieved remarkable success,their performance often relies on large amounts of labeled data that areexpensive and time-consuming to obtain. Thus, there is a growing need formodels that can perform well with limited experimentally-validated data. Inthis work, we introduce MoleVers, a versatile pretrained model designed forvarious types of molecular property prediction in the wild, i.e., whereexperimentally-validated molecular property labels are scarce. MoleVers adoptsa two-stage pretraining strategy. In the first stage, the model learnsmolecular representations from large unlabeled datasets via masked atomprediction and dynamic denoising, a novel task enabled by a new branchingencoder architecture. In the second stage, MoleVers is further pretrained usingauxiliary labels obtained with inexpensive computational methods, enablingsupervised learning without the need for costly experimental data. Thistwo-stage framework allows MoleVers to learn representations that generalizeeffectively across various downstream datasets. We evaluate MoleVers on a newbenchmark comprising 22 molecular datasets with diverse types of properties,the majority of which contain 50 or fewer training labels reflecting real-worldconditions. MoleVers achieves state-of-the-art results on 20 out of the 22datasets, and ranks second among the remaining two, highlighting its ability tobridge the gap between data-hungry models and real-world conditions wherepractically-useful labels are scarce.</description>
      <author>example@mail.com (Kevin Tirta Wijaya, Minghao Guo, Michael Sun, Hans-Peter Seidel, Wojciech Matusik, Vahid Babaei)</author>
      <guid isPermaLink="false">2411.03537v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Wasserstein Flow Matching: Generative modeling over families of distributions</title>
      <link>http://arxiv.org/abs/2411.00698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成建模通常关注于将单一源分布传输到单一目标分布，学习简单的概率流。然而，在现代数据驱动领域（如计算机图形学和单细胞基因组学），数据集样本可以被视为分布。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法——Wasserstein流匹配（WFM），以适当考虑样本的几何特性。&lt;h4&gt;方法&lt;/h4&gt;WFM利用Wasserstein几何的黎曼性质，将流匹配提升到分布家族上，同时结合（熵）最优传输的理论和计算进展，以及神经网络架构中的注意力机制。&lt;h4&gt;主要发现&lt;/h4&gt;首先，展示如何对高斯分布进行生成建模，从单细胞基因组学数据中生成颗粒细胞状态的表示；其次，WFM能够学习高维和可变大小点云之间的流，并从空间转录组数据集中合成细胞微环境。&lt;h4&gt;结论&lt;/h4&gt;Wasserstein流匹配为处理复杂分布的生成建模提供了有效的算法框架。&lt;h4&gt;总结&lt;/h4&gt;该研究通过WFM方法推动了生成建模在复杂数据结构中的应用，代码可在GitHub上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative modeling typically concerns the transport of a single sourcedistribution to a single target distribution by learning (i.e., regressingonto) simple probability flows. However, in modern data-driven fields such ascomputer graphics and single-cell genomics, samples (say, point-clouds) fromdatasets can themselves be viewed as distributions (as, say, discretemeasures). In these settings, the standard generative modeling paradigm of flowmatching would ignore the relevant geometry of the samples. To remedy this, wepropose \emph{Wasserstein flow matching} (WFM), which appropriately lifts flowmatching onto families of distributions by appealing to the Riemannian natureof the Wasserstein geometry. Our algorithm leverages theoretical andcomputational advances in (entropic) optimal transport, as well as theattention mechanism in our neural network architecture. We present two novelalgorithmic contributions. First, we demonstrate how to perform generativemodeling over Gaussian distributions, where we generate representations ofgranular cell states from single-cell genomics data. Secondly, we show that WFMcan learn flows between high-dimensional and variable sized point-clouds andsynthesize cellular microenvironments from spatial transcriptomics datasets.Code is available at[WassersteinFlowMatching](https://github.com/DoronHav/WassersteinFlowMatching).</description>
      <author>example@mail.com (Doron Haviv, Aram-Alexandre Pooladian, Dana Pe'er, Brandon Amos)</author>
      <guid isPermaLink="false">2411.00698v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.03364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图在推荐系统的发展中变得越来越重要，尤其是图神经网络（GNN）的快速发展。&lt;h4&gt;目的&lt;/h4&gt;探索GNN在隐私泄露方面的风险，并提出一种新的攻击模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为DM4Steal的扩散模型基础的链接窃取攻击，旨在解决现有研究的不足。&lt;h4&gt;主要发现&lt;/h4&gt;DM4Steal在六种攻击场景下具有较好的通用性、有效性和适应性，能够在防御情况下有效执行攻击。&lt;h4&gt;结论&lt;/h4&gt;DM4Steal通过多次采样得分模型，能够在防御GNN（如DP、Dropout）时保持性能，减少攻击效果的下降。&lt;h4&gt;总结&lt;/h4&gt;DM4Steal模型为GNN的隐私保护提供了新的攻击视角，强调了推荐系统中数据完整性和机密性的风险。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph has become increasingly integral to the advancement of recommendationsystems, particularly with the fast development of graph neural network(GNN).By exploring the virtue of rich node features and link information, GNN isdesigned to provide personalized and accurate suggestions. Meanwhile, theprivacy leakage of GNN in such contexts has also captured special attention.Prior work has revealed that a malicious user can utilize auxiliary knowledgeto extract sensitive link data of the target graph, integral to recommendationsystems, via the decision made by the target GNN model. This poses asignificant risk to the integrity and confidentiality of data used inrecommendation system. Though important, previous works on GNN's privacyleakage are still challenged in three aspects, i.e., limited stealing attackscenarios, sub-optimal attack performance, and adaptation against defense. Toaddress these issues, we propose a diffusion model based link stealing attack,named DM4Steal. It differs previous work from three critical aspects. (i)Generality: aiming at six attack scenarios with limited auxiliary knowledge, wepropose a novel training strategy for diffusion models so that DM4Steal istransferable to diverse attack scenarios. (ii) Effectiveness: benefiting fromthe retention of semantic structure in the diffusion model during the trainingprocess, DM4Steal is capable to learn the precise topology of the target graphthrough the GNN decision process. (iii) Adaptation: when GNN is defensive(e.g., DP, Dropout), DM4Steal relies on the stability that comes from samplingthe score model multiple times to keep performance degradation to a minimum,thus DM4Steal implements successful adaptive attack on defensive GNN.</description>
      <author>example@mail.com (Jinyin Chen, Haonan Ma, Haibin Zheng)</author>
      <guid isPermaLink="false">2411.03364v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Negative-Free Self-Supervised Gaussian Embedding of Graphs</title>
      <link>http://arxiv.org/abs/2411.01157v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Neural Networks&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）是一种新兴的图自监督学习框架，旨在无标签情况下学习区分性节点表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种无负样本的目标函数，以实现均匀性，减少计算需求和内存开销。&lt;h4&gt;方法&lt;/h4&gt;通过最小化学习表示的分布与标准化各向同性高斯分布之间的距离，促进节点表示的均匀性，同时避免使用负样本、参数化互信息估计器和其他复杂结构。&lt;h4&gt;主要发现&lt;/h4&gt;在七个图基准测试的广泛实验中，提出的方法在参数数量、训练时间和内存消耗上优于现有的GCL方法，且性能具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;本研究提出的负样本-free方法有效提升了图对比学习的效率和效果，减少了对负样本的依赖。&lt;h4&gt;总结&lt;/h4&gt;该研究为图对比学习提供了新的思路，通过消除负样本，优化了节点表示的学习过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.neunet.2024.106846&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Cloudy1225/SSGE&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) has recently emerged as a promising graphself-supervised learning framework for learning discriminative noderepresentations without labels. The widely adopted objective function of GCLbenefits from two key properties: \emph{alignment} and \emph{uniformity}, whichalign representations of positive node pairs while uniformly distributing allrepresentations on the hypersphere. The uniformity property plays a criticalrole in preventing representation collapse and is achieved by pushing apartaugmented views of different nodes (negative pairs). As such, existing GCLmethods inherently rely on increasing the quantity and quality of negativesamples, resulting in heavy computational demands, memory overhead, andpotential class collision issues. In this study, we propose a negative-freeobjective to achieve uniformity, inspired by the fact that points distributedaccording to a normalized isotropic Gaussian are uniformly spread across theunit hypersphere. Therefore, we can minimize the distance between thedistribution of learned representations and the isotropic Gaussian distributionto promote the uniformity of node representations. Our method alsodistinguishes itself from other approaches by eliminating the need for aparameterized mutual information estimator, an additional projector, asymmetricstructures, and, crucially, negative samples. Extensive experiments over sevengraph benchmarks demonstrate that our proposal achieves competitive performancewith fewer parameters, shorter training times, and lower memory consumptioncompared to existing GCL methods.</description>
      <author>example@mail.com (Yunhui Liu, Tieke He, Tao Zheng, Jianhua Zhao)</author>
      <guid isPermaLink="false">2411.01157v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Long Context RAG Performance of Large Language Models</title>
      <link>http://arxiv.org/abs/2411.03538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2024 NeurIPS workshop on Adaptive Foundation Models: Evolving AI for
  Personalized and Efficient Learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;检索增强生成（RAG）是一种通过引入外部信息来提高大型语言模型（LLMs）准确性的关键技术。&lt;h4&gt;目的&lt;/h4&gt;研究在RAG场景中，支持更长上下文长度的LLMs的表现，以及这些新模型是否能够提高RAG性能。&lt;h4&gt;方法&lt;/h4&gt;对20种流行的开源和商业LLMs进行了综合研究，测试了在3个特定领域数据集上，变动上下文长度从2000到128000个标记（在可能的情况下达到200万个标记）的RAG工作流程。&lt;h4&gt;主要发现&lt;/h4&gt;尽管检索更多文档可以提高性能，但只有少数最新的最先进LLMs能够在超过64k标记的长上下文中保持一致的准确性。&lt;h4&gt;结论&lt;/h4&gt;在长上下文的场景中识别出不同的失败模式，为未来的研究指明了方向。&lt;h4&gt;总结&lt;/h4&gt;总的来说，长上下文对RAG应用的优势和局限性提供了重要的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieval Augmented Generation (RAG) has emerged as a crucial technique forenhancing the accuracy of Large Language Models (LLMs) by incorporatingexternal information. With the advent of LLMs that support increasingly longercontext lengths, there is a growing interest in understanding how these modelsperform in RAG scenarios. Can these new long context models improve RAGperformance? This paper presents a comprehensive study of the impact ofincreased context length on RAG performance across 20 popular open source andcommercial LLMs. We ran RAG workflows while varying the total context lengthfrom 2,000 to 128,000 tokens (and 2 million tokens when possible) on threedomain-specific datasets, and report key insights on the benefits andlimitations of long context in RAG applications. Our findings reveal that whileretrieving more documents can improve performance, only a handful of the mostrecent state of the art LLMs can maintain consistent accuracy at long contextabove 64k tokens. We also identify distinct failure modes in long contextscenarios, suggesting areas for future research.</description>
      <author>example@mail.com (Quinn Leng, Jacob Portes, Sam Havens, Matei Zaharia, Michael Carbin)</author>
      <guid isPermaLink="false">2411.03538v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Distributed Graph Neural Network Design for Sum Ergodic Spectral Efficiency Maximization in Cell-Free Massive MIMO</title>
      <link>http://arxiv.org/abs/2411.02900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures, and 4 tables. Accepted by IEEE TVT&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在无中心大规模多输入多输出 (MIMO) 系统中，求解和最大化和ergodic速率的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于分布式学习的框架，以解决上述速率最大化问题。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络 (GNN)，通过接入点 (AP) 的本地资源来分配发射功率，而不是集中式方案中将所有信道状态信息 (CSI) 汇集到中央处理单元 (CPU)。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的分布式学习方法在和ergodic速率上接近于集中式学习，同时优于基于模型的优化。&lt;h4&gt;结论&lt;/h4&gt;通过训练GNN模型，AP可以基于本地CSI有效分配功率，从而避免计算负担并捕捉全面的网络信息。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了分布式学习在无线通信中的潜力，能够在较低的计算成本下实现有效的资源分配。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a distributed learning-based framework to tackle the sumergodic rate maximization problem in cell-free massive multiple-inputmultiple-output (MIMO) systems by utilizing the graph neural network (GNN).Different from centralized schemes, which gather all the channel stateinformation (CSI) at the central processing unit (CPU) for calculating theresource allocation, the local resource of access points (APs) is exploited inthe proposed distributed GNN-based framework to allocate transmit powers.Specifically, APs can use a unique GNN model to allocate their power based onthe local CSI. The GNN model is trained at the CPU using the local CSI of oneAP, with partially exchanged information from other APs to calculate the lossfunction to reflect system characteristics, capturing comprehensive networkinformation while avoiding computation burden. Numerical results show that theproposed distributed learning-based approach achieves a sum ergodic rate closeto that of centralized learning while outperforming the model-basedoptimization.</description>
      <author>example@mail.com (Nguyen Xuan Tung, Trinh Van Chien, Hien Quoc Ngo, Won Joo Hwang)</author>
      <guid isPermaLink="false">2411.02900v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Test-Time Adaptation in Point Clouds: Leveraging Sampling Variation with Weight Averaging</title>
      <link>http://arxiv.org/abs/2411.01116v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;测试时适应（TTA）旨在解决测试期间的分布变化问题，通过适应预训练模型而不需要源数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的TTA方法，用于3D点云分类。&lt;h4&gt;方法&lt;/h4&gt;结合采样变化和权重平均，利用最远点采样（FPS）和K近邻（KNN）创建多个点云表示，使用TENT算法适应每个变化的模型。&lt;h4&gt;主要发现&lt;/h4&gt;在ModelNet40-C、ShapeNet-C和ScanObjectNN-C数据集上进行的广泛实验表明，该方法在不同骨干网络（Point-MAE、PointNet、DGCNN）上均优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在资源开销最小的情况下，有效提高了模型的鲁棒性、泛化能力和稳定性，特别是在复杂的真实世界条件下。&lt;h4&gt;总结&lt;/h4&gt;提出的TTA方法为3D点云分类任务提供了有效的解决方案，增强了模型在分布变化下的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/AliBahri94/SVWA_TTA&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Test-Time Adaptation (TTA) addresses distribution shifts during testing byadapting a pretrained model without access to source data. In this work, wepropose a novel TTA approach for 3D point cloud classification, combiningsampling variation with weight averaging. Our method leverages Farthest PointSampling (FPS) and K-Nearest Neighbors (KNN) to create multiple point cloudrepresentations, adapting the model for each variation using the TENTalgorithm. The final model parameters are obtained by averaging the adaptedweights, leading to improved robustness against distribution shifts. Extensiveexperiments on ModelNet40-C, ShapeNet-C, and ScanObjectNN-C datasets, withdifferent backbones (Point-MAE, PointNet, DGCNN), demonstrate that our approachconsistently outperforms existing methods while maintaining minimal resourceoverhead. The proposed method effectively enhances model generalization andstability in challenging real-world conditions.</description>
      <author>example@mail.com (Ali Bahri, Moslem Yazdanpanah, Mehrdad Noori, Sahar Dastani Oghani, Milad Cheraghalikhani, David Osowiech, Farzad Beizaee, Gustavo adolfo. vargas-hakim, Ismail Ben Ayed, Christian Desrosiers)</author>
      <guid isPermaLink="false">2411.01116v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Channel Hypergraph Contrastive Learning for Matrix Completion</title>
      <link>http://arxiv.org/abs/2411.01376v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;评分是用户的显性反馈，反映用户对相关项目的喜好程度。评分矩阵补全是推荐系统中的重要问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多通道超图对比学习框架（MHCL），以解决数据稀疏和长尾分布的问题。&lt;h4&gt;方法&lt;/h4&gt;MHCL自适应学习超图结构，捕捉节点之间的高阶关联，通过基于注意力的跨视图聚合共同捕捉局部和全局的协作关系。&lt;h4&gt;主要发现&lt;/h4&gt;MHCL通过不同评分子图作为不同通道，鼓励相邻评分之间的对齐，实现不同评分之间的相互增强，有效提升了评分预测的准确性。&lt;h4&gt;结论&lt;/h4&gt;在五个公共数据集上的广泛实验表明，MHCL显著优于当前最先进的方法。&lt;h4&gt;总结&lt;/h4&gt;MHCL框架有效应对了推荐系统中的数据稀疏和高阶关联捕捉问题，提升了评分预测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rating is a typical user explicit feedback that visually reflects how much auser likes a related item. The (rating) matrix completion is essentially arating prediction process, which is also a significant problem in recommendersystems. Recently, graph neural networks (GNNs) have been widely used in matrixcompletion, which captures users' preferences over items by formulating arating matrix as a bipartite graph. However, existing methods are susceptibledue to data sparsity and long-tail distribution in real-world scenarios.Moreover, the messaging mechanism of GNNs makes it difficult to capturehigh-order correlations and constraints between nodes, which are essentiallyuseful in recommendation tasks. To tackle these challenges, we propose aMulti-Channel Hypergraph Contrastive Learning framework for matrix completion,named MHCL. Specifically, MHCL adaptively learns hypergraph structures tocapture high-order correlations between nodes and jointly captures local andglobal collaborative relationships through attention-based cross-viewaggregation. Additionally, to consider the magnitude and order information ofratings, we treat different rating subgraphs as different channels, encouragealignment between adjacent ratings, and further achieve the mutual enhancementbetween different ratings through multi-channel cross-rating contrastivelearning. Extensive experiments on five public datasets demonstrate that theproposed method significantly outperforms the current state-of-the-artapproaches.</description>
      <author>example@mail.com (Xiang Li, Changsheng Shui, Yanwei Yu, Chao Huang, Zhongying Zhao, Junyu Dong)</author>
      <guid isPermaLink="false">2411.01376v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>X-Drive: Cross-modality consistent multi-sensor data synthesis for driving scenarios</title>
      <link>http://arxiv.org/abs/2411.01123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，扩散模型在驾驶场景中的LiDAR点云和相机图像数据合成方面取得了进展。&lt;h4&gt;目的&lt;/h4&gt;填补不同模态之间相互依赖的研究空白，以描述复杂的驾驶场景。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新框架X-DRIVE，通过双分支潜在扩散模型架构建模点云和多视角图像的联合分布。&lt;h4&gt;主要发现&lt;/h4&gt;X-DRIVE通过考虑两种模态的不同几何空间，确保合成的每种模态与另一种模态的局部区域更好地对齐和真实。&lt;h4&gt;结论&lt;/h4&gt;X-DRIVE能够通过多层次输入条件实现可控生成，确保合成结果的高保真度和跨模态一致性。&lt;h4&gt;总结&lt;/h4&gt;X-DRIVE展示了出色的合成结果，并将在https://github.com/yichen928/X-Drive上公开代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yichen928/x-drive&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements have exploited diffusion models for the synthesis ofeither LiDAR point clouds or camera image data in driving scenarios. Despitetheir success in modeling single-modality data marginal distribution, there isan under-exploration in the mutual reliance between different modalities todescribe complex driving scenes. To fill in this gap, we propose a novelframework, X-DRIVE, to model the joint distribution of point clouds andmulti-view images via a dual-branch latent diffusion model architecture.Considering the distinct geometrical spaces of the two modalities, X-DRIVEconditions the synthesis of each modality on the corresponding local regionsfrom the other modality, ensuring better alignment and realism. To furtherhandle the spatial ambiguity during denoising, we design the cross-modalitycondition module based on epipolar lines to adaptively learn the cross-modalitylocal correspondence. Besides, X-DRIVE allows for controllable generationthrough multi-level input conditions, including text, bounding box, image, andpoint clouds. Extensive results demonstrate the high-fidelity synthetic resultsof X-DRIVE for both point clouds and multi-view images, adhering to inputconditions while ensuring reliable cross-modality consistency. Our code will bemade publicly available at https://github.com/yichen928/X-Drive.</description>
      <author>example@mail.com (Yichen Xie, Chenfeng Xu, Chensheng Peng, Shuqi Zhao, Nhat Ho, Alexander T. Pham, Mingyu Ding, Masayoshi Tomizuka, Wei Zhan)</author>
      <guid isPermaLink="false">2411.01123v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Privacy-Preserving Graph-Based Machine Learning with Fully Homomorphic Encryption for Collaborative Anti-Money Laundering</title>
      <link>http://arxiv.org/abs/2411.02926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14th International Conference on Security, Privacy, and Applied
  Cryptographic Engineering (SPACE) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着网络犯罪的增加和金融交易数字化，打击洗钱变得愈加复杂。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的隐私保护协作反洗钱机器学习方法，促进机构间安全数据共享，同时保持隐私和合规性。&lt;h4&gt;方法&lt;/h4&gt;利用完全同态加密（FHE）在加密数据上直接进行计算，并结合图基机器学习技术，特别是集成了TFHE与Zama Concrete ML。&lt;h4&gt;主要发现&lt;/h4&gt;开发了两个隐私保护管道，包括隐私保护的图神经网络（GNN）管道和图基XGBoost管道，后者在平衡的AML数据集上实现了超过99%的准确率和F1-score。&lt;h4&gt;结论&lt;/h4&gt;在不平衡数据集上，图基特征的引入提升了F1-score 8%。研究强调了隐私与计算效率之间的平衡。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了图基机器学习与隐私保护技术在反洗钱检测中的潜力，提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/fabecode/GraphML-FHE&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Combating money laundering has become increasingly complex with the rise ofcybercrime and digitalization of financial transactions. Graph-based machinelearning techniques have emerged as promising tools for Anti-Money Laundering(AML) detection, capturing intricate relationships within money launderingnetworks. However, the effectiveness of AML solutions is hindered by data siloswithin financial institutions, limiting collaboration and overall efficacy.This research presents a novel privacy-preserving approach for collaborativeAML machine learning, facilitating secure data sharing across institutions andborders while preserving privacy and regulatory compliance. Leveraging FullyHomomorphic Encryption (FHE), computations are directly performed on encrypteddata, ensuring the confidentiality of financial data. Notably, FHE over theTorus (TFHE) was integrated with graph-based machine learning using ZamaConcrete ML. The research contributes two key privacy-preserving pipelines.First, the development of a privacy-preserving Graph Neural Network (GNN)pipeline was explored. Optimization techniques like quantization and pruningwere used to render the GNN FHE-compatible. Second, a privacy-preservinggraph-based XGBoost pipeline leveraging Graph Feature Preprocessor (GFP) wassuccessfully developed. Experiments demonstrated strong predictive performance,with the XGBoost model consistently achieving over 99% accuracy, F1-score,precision, and recall on the balanced AML dataset in both unencrypted andFHE-encrypted inference settings. On the imbalanced dataset, the incorporationof graph-based features improved the F1-score by 8%. The research highlightsthe need to balance the trade-off between privacy and computational efficiency.</description>
      <author>example@mail.com (Fabrianne Effendi, Anupam Chattopadhyay)</author>
      <guid isPermaLink="false">2411.02926v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Learning Hidden Subgoals under Temporal Ordering Constraints in Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2411.01425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在实际应用中，完成任务的成功通常取决于多个关键步骤，这些步骤在时间上相距较远，并且必须按固定顺序完成。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的强化学习算法，以解决隐藏子目标和时间顺序约束的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的对比学习目标，通过基于首次占用表示和时间几何采样，能够同时有效学习隐藏子目标及其时间顺序。&lt;h4&gt;主要发现&lt;/h4&gt;通过构建子目标树，逐一发现子目标，遵循时间顺序约束，从而提高样本效率，快速解决任务，并能够推广到未见过的任务。&lt;h4&gt;结论&lt;/h4&gt;LSTOC框架在多个基于图像的环境中进行了评估，显示出显著优于基线方法的改善。&lt;h4&gt;总结&lt;/h4&gt;本文提出的LSTOC算法在解决具有隐藏子目标和时间顺序约束的任务中表现出色，具有较好的样本效率和推广能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world applications, the success of completing a task is oftendetermined by multiple key steps which are distant in time steps and have to beachieved in a fixed time order. For example, the key steps listed on thecooking recipe should be achieved one-by-one in the right time order. These keysteps can be regarded as subgoals of the task and their time orderings aredescribed as temporal ordering constraints. However, in many real-worldproblems, subgoals or key states are often hidden in the state space and theirtemporal ordering constraints are also unknown, which make it challenging forprevious RL algorithms to solve this kind of tasks. In order to address thisissue, in this work we propose a novel RL algorithm for {\bf l}earning hidden{\bf s}ubgoals under {\bf t}emporal {\bf o}rdering {\bf c}onstraints (LSTOC).We propose a new contrastive learning objective which can effectively learnhidden subgoals (key states) and their temporal orderings at the same time,based on first-occupancy representation and temporal geometric sampling. Inaddition, we propose a sample-efficient learning strategy to discover subgoalsone-by-one following their temporal order constraints by building a subgoaltree to represent discovered subgoals and their temporal orderingrelationships. Specifically, this tree can be used to improve the sampleefficiency of trajectory collection, fasten the task solving and generalize tounseen tasks. The LSTOC framework is evaluated on several environments withimage-based observations, showing its significant improvement over baselinemethods.</description>
      <author>example@mail.com (Duo Xu, Faramarz Fekri)</author>
      <guid isPermaLink="false">2411.01425v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Query-Efficient Adversarial Attack Against Vertical Federated Graph Learning</title>
      <link>http://arxiv.org/abs/2411.02809v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）因其在图结构数据表示学习方面的能力而受到广泛关注，但分布式数据孤岛限制了其性能。&lt;h4&gt;目的&lt;/h4&gt;探索垂直联邦学习（VFL）在处理分布式图结构数据时的对抗攻击的鲁棒性，填补这一研究空白。&lt;h4&gt;方法&lt;/h4&gt;提出了一种查询高效的混合对抗攻击框架NA2（基于神经元的对抗攻击），通过恶意客户端操控本地训练数据，提高其隐秘贡献，并建立影子模型模拟服务器模型的行为。&lt;h4&gt;主要发现&lt;/h4&gt;NA2显著提升了针对VFL的集中式对抗攻击的成功率，经过大量实验表明其在五个真实世界基准上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;即使在潜在的自适应防御情况下，NA2也能提高攻击成功率，并通过敏感神经元识别和t-SNE可视化提供了有效性的可解释实验。&lt;h4&gt;总结&lt;/h4&gt;本研究首次探讨了针对垂直联邦图学习的对抗攻击，提出的NA2框架展示了其在对抗攻击中的优势，具有重要的研究意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hgh0545/NA2&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural network (GNN) has captured wide attention due to its capabilityof graph representation learning for graph-structured data. However, thedistributed data silos limit the performance of GNN. Vertical federatedlearning (VFL), an emerging technique to process distributed data, successfullymakes GNN possible to handle the distributed graph-structured data. Despite theprosperous development of vertical federated graph learning (VFGL), therobustness of VFGL against the adversarial attack has not been explored yet.Although numerous adversarial attacks against centralized GNNs are proposed,their attack performance is challenged in the VFGL scenario. To the best of ourknowledge, this is the first work to explore the adversarial attack againstVFGL. A query-efficient hybrid adversarial attack framework is proposed tosignificantly improve the centralized adversarial attacks against VFGL, denotedas NA2, short for Neuron-based Adversarial Attack. Specifically, a maliciousclient manipulates its local training data to improve its contribution in astealthy fashion. Then a shadow model is established based on the manipulateddata to simulate the behavior of the server model in VFGL. As a result, theshadow model can improve the attack success rate of various centralized attackswith a few queries. Extensive experiments on five real-world benchmarksdemonstrate that NA2 improves the performance of the centralized adversarialattacks against VFGL, achieving state-of-the-art performance even underpotential adaptive defense where the defender knows the attack method.Additionally, we provide interpretable experiments of the effectiveness of NA2via sensitive neurons identification and visualization of t-SNE.</description>
      <author>example@mail.com (Jinyin Chen, Wenbo Mu, Luxin Zhang, Guohan Huang, Haibin Zheng, Yao Cheng)</author>
      <guid isPermaLink="false">2411.02809v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry</title>
      <link>http://arxiv.org/abs/2411.03542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（如GPT系列、BLOOM、LLaMA等）在多种任务，尤其是自然语言处理（NLP）任务中推动了新的发展。&lt;h4&gt;目的&lt;/h4&gt;研究在科学领域（特别是化学）中使用特定领域预训练模型的优势，并与现成的开源模型进行比较。&lt;h4&gt;方法&lt;/h4&gt;比较在零-shot和少量示例提示下，特定领域预训练模型与现成模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;特定领域预训练模型在零-shot设置下表现良好，经过指令微调后在化学特定任务（如命名实体识别和分子式生成）上表现出色。&lt;h4&gt;结论&lt;/h4&gt;针对特定领域的基础模型在科学任务中具有明显优势，且进一步适应能够显著提升性能。&lt;h4&gt;总结&lt;/h4&gt;在科学领域，特定领域的预训练和适应性微调能够显著提高语言模型的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, andmore) are driving forward novel development of multipurpose AI for a variety oftasks, particularly natural language processing (NLP) tasks. These modelsdemonstrate strong performance on a range of tasks; however, there has beenevidence of brittleness when applied to more niche or narrow domains wherehallucinations or fluent but incorrect responses reduce performance. Given thecomplex nature of scientific domains, it is prudent to investigate thetrade-offs of leveraging off-the-shelf versus more targeted foundation modelsfor scientific domains. In this work, we examine the benefits of in-domainpre-training for a given scientific domain, chemistry, and compare these toopen-source, off-the-shelf models with zero-shot and few-shot prompting. Ourresults show that not only do in-domain base models perform reasonably well onin-domain tasks in a zero-shot setting but that further adaptation usinginstruction fine-tuning yields impressive performance on chemistry-specifictasks such as named entity recognition and molecular formula generation.</description>
      <author>example@mail.com (Anurag Acharya, Shivam Sharma, Robin Cosbey, Megha Subramanian, Scott Howland, Maria Glenski)</author>
      <guid isPermaLink="false">2411.03542v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DA-MoE: Addressing Depth-Sensitivity in Graph-Level Analysis through Mixture of Experts</title>
      <link>http://arxiv.org/abs/2411.03025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在处理图结构数据方面越来越受欢迎。实际场景中，同一数据集内的图数据规模差异显著，导致深度敏感性问题。&lt;h4&gt;目的&lt;/h4&gt;解决图数据深度敏感性问题，使得GNN能够根据图的规模灵活调整层数。&lt;h4&gt;方法&lt;/h4&gt;提出深度自适应专家混合方法（DA-MoE），该方法使用不同的GNN层作为专家，每个专家具有独立参数，以灵活聚合不同尺度的信息，并通过GNN捕捉结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;DA-MoE在多个任务上（包括图、节点和链接级别分析） consistently 超越现有基准，实验在TU数据集和开放图基准（OGB）上进行。&lt;h4&gt;结论&lt;/h4&gt;DA-MoE有效解决了图数据的深度敏感性问题，并在多项任务中展现了优越的表现。&lt;h4&gt;总结&lt;/h4&gt;DA-MoE方法通过灵活的层选择和结构信息的捕捉，显著提高了图神经网络对不同规模图数据的处理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/celin-yao/da-moe&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are gaining popularity for processinggraph-structured data. In real-world scenarios, graph data within the samedataset can vary significantly in scale. This variability leads todepth-sensitivity, where the optimal depth of GNN layers depends on the scaleof the graph data. Empirically, fewer layers are sufficient for message passingin smaller graphs, while larger graphs typically require deeper networks tocapture long-range dependencies and global features. However, existing methodsgenerally use a fixed number of GNN layers to generate representations for allgraphs, overlooking the depth-sensitivity issue in graph structure data. Toaddress this challenge, we propose the depth adaptive mixture of expert(DA-MoE) method, which incorporates two main improvements to GNN backbone:\textbf{1)} DA-MoE employs different GNN layers, each considered an expert withits own parameters. Such a design allows the model to flexibly aggregateinformation at different scales, effectively addressing the depth-sensitivityissue in graph data. \textbf{2)} DA-MoE utilizes GNN to capture the structuralinformation instead of the linear projections in the gating network. Thus, thegating network enables the model to capture complex patterns and dependencieswithin the data. By leveraging these improvements, each expert in DA-MoEspecifically learns distinct graph patterns at different scales. Furthermore,comprehensive experiments on the TU dataset and open graph benchmark (OGB) haveshown that DA-MoE consistently surpasses existing baselines on various tasks,including graph, node, and link-level analyses. The code are available at\url{https://github.com/Celin-Yao/DA-MoE}.</description>
      <author>example@mail.com (Zelin Yao, Chuang Liu, Xianke Meng, Yibing Zhan, Jia Wu, Shirui Pan, Wenbin Hu)</author>
      <guid isPermaLink="false">2411.03025v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>MultiPull: Detailing Signed Distance Functions by Pulling Multi-Level Queries at Multi-Step</title>
      <link>http://arxiv.org/abs/2411.01208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024. Project page:
  https://takeshie.github.io/MultiPull/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从原始3D点云重建连续表面是一项具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法MultiPull，以从原始点云中学习多尺度隐式场。&lt;h4&gt;方法&lt;/h4&gt;通过从粗到细优化准确的有符号距离函数(SDF)，并将3D查询点映射到一组频率特征，利用多级特征进行优化，同时引入空间距离和法线一致性的优化约束。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在表面重建任务中优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;MultiPull方法在广泛使用的物体和场景基准测试中表现出色。&lt;h4&gt;总结&lt;/h4&gt;MultiPull通过多尺度优化策略解决了神经网络在点云重建中平滑局部细节的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing a continuous surface from a raw 3D point cloud is achallenging task. Recent methods usually train neural networks to overfit onsingle point clouds to infer signed distance functions (SDFs). However, neuralnetworks tend to smooth local details due to the lack of ground truth signeddistances or normals, which limits the performance of overfitting-based methodsin reconstruction tasks. To resolve this issue, we propose a novel method,named MultiPull, to learn multi-scale implicit fields from raw point clouds byoptimizing accurate SDFs from coarse to fine. We achieve this by mapping 3Dquery points into a set of frequency features, which makes it possible toleverage multi-level features during optimization. Meanwhile, we introduceoptimization constraints from the perspective of spatial distance and normalconsistency, which play a key role in point cloud reconstruction based onmulti-scale optimization strategies. Our experiments on widely used object andscene benchmarks demonstrate that our method outperforms the state-of-the-artmethods in surface reconstruction.</description>
      <author>example@mail.com (Takeshi Noda, Chao Chen, Weiqi Zhang, Xinhai Liu, Yu-Shen Liu, Zhizhong Han)</author>
      <guid isPermaLink="false">2411.01208v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DPCL-Diff: The Temporal Knowledge Graph Reasoning based on Graph Node Diffusion Model with Dual-Domain Periodic Contrastive Learning</title>
      <link>http://arxiv.org/abs/2411.01477v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间知识图谱（TKG）推理是推断未来缺失事实的一项重要且具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的图节点扩散模型，以提升未来事件的预测能力。&lt;h4&gt;方法&lt;/h4&gt;采用双域周期对比学习（DPCL-Diff）结合图节点扩散模型，通过引入噪声模拟稀疏相关事件，并将事件实体映射到不同的空间以增强区分能力。&lt;h4&gt;主要发现&lt;/h4&gt;在四个公共数据集上的实验结果表明，DPCL-Diff在事件预测方面显著优于现有的最先进TKG模型。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，GNDiff和DPCL的结合在TKG任务中具有良好的效果。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的新模型为未来事件推理提供了新的思路和方法，具有重要的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal knowledge graph (TKG) reasoning that infers future missing facts isan essential and challenging task. Predicting future events typically relies onclosely related historical facts, yielding more accurate results for repetitiveor periodic events. However, for future events with sparse historicalinteractions, the effectiveness of this method, which focuses on leveraginghigh-frequency historical information, diminishes. Recently, the capabilitiesof diffusion models in image generation have opened new opportunities for TKGreasoning. Therefore, we propose a graph node diffusion model with dual-domainperiodic contrastive learning (DPCL-Diff). Graph node diffusion model (GNDiff)introduces noise into sparsely related events to simulate new events,generating high-quality data that better conforms to the actual distribution.This generative mechanism significantly enhances the model's ability to reasonabout new events. Additionally, the dual-domain periodic contrastive learning(DPCL) maps periodic and non-periodic event entities to Poincar\'e andEuclidean spaces, leveraging their characteristics to distinguish similarperiodic events effectively. Experimental results on four public datasetsdemonstrate that DPCL-Diff significantly outperforms state-of-the-art TKGmodels in event prediction, demonstrating our approach's effectiveness. Thisstudy also investigates the combined effectiveness of GNDiff and DPCL in TKGtasks.</description>
      <author>example@mail.com (Yukun Cao, Lisheng Wang, Luobing Huang)</author>
      <guid isPermaLink="false">2411.01477v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Efficient and Effective Adaptation of Multimodal Foundation Models in Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2411.02992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The extension of IISAN in SIGIR2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型（MFM）通过先进的表示学习改变了顺序推荐系统。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架以提高参数效率，同时兼顾GPU内存和训练速度。&lt;h4&gt;方法&lt;/h4&gt;开发了IISAN-Versa，一个兼容对称和非对称MFM的插件式架构，采用解耦的参数高效微调结构，进行模态内和模态间的适应。&lt;h4&gt;主要发现&lt;/h4&gt;IISAN-Versa能够有效适应大型文本编码器，且发现更大的编码器通常表现更好。此外，它在定义的多模态场景中表现出强大的通用性。&lt;h4&gt;结论&lt;/h4&gt;IISAN-Versa在Microlens公共基准测试中取得了最先进的性能，代码和数据集将公开以支持未来研究。&lt;h4&gt;总结&lt;/h4&gt;该研究为多模态推荐系统的应用提供了新的方法和工具，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models (MFMs) have revolutionized sequentialrecommender systems through advanced representation learning. WhileParameter-efficient Fine-tuning (PEFT) is commonly used to adapt these models,studies often prioritize parameter efficiency, neglecting GPU memory andtraining speed. To address this, we introduced the IISAN framework,significantly enhancing efficiency. However, IISAN was limited to symmetricalMFMs and identical text and image encoders, preventing the use ofstate-of-the-art Large Language Models. To overcome this, we developedIISAN-Versa, a versatile plug-and-play architecture compatible with bothsymmetrical and asymmetrical MFMs. IISAN-Versa employs a Decoupled PEFTstructure and utilizes both intra- and inter-modal adaptation. It effectivelyhandles asymmetry through a simple yet effective combination of grouplayer-dropping and dimension transformation alignment. Our researchdemonstrates that IISAN-Versa effectively adapts large text encoders, and wefurther identify a scaling effect where larger encoders generally performbetter. IISAN-Versa also demonstrates strong versatility in our definedmultimodal scenarios, which include raw titles and captions generated fromimages and videos. Additionally, IISAN-Versa achieved state-of-the-artperformance on the Microlens public benchmark. We will release our code anddatasets to support future research.</description>
      <author>example@mail.com (Junchen Fu, Xuri Ge, Xin Xin, Alexandros Karatzoglou, Ioannis Arapakis, Kaiwen Zheng, Yongxin Ni, Joemon M. Jose)</author>
      <guid isPermaLink="false">2411.02992v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Number Cookbook: Number Understanding of Language Models and How to Improve It</title>
      <link>http://arxiv.org/abs/2411.03766v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在复杂推理任务中表现越来越好，但在基本数值理解和处理方面出现显著错误。&lt;h4&gt;目的&lt;/h4&gt;全面调查大型语言模型的数值理解和处理能力（NUPA），填补以往研究的空白。&lt;h4&gt;方法&lt;/h4&gt;引入一个基准，涵盖四种常见数值表示和17个不同的数值任务，形成41个有意义的组合，这些任务源自小学和中学教育课程。&lt;h4&gt;主要发现&lt;/h4&gt;当前大型语言模型在许多任务中频繁失败，简单的微调可以改善NUPA，但并非对所有任务有效。&lt;h4&gt;结论&lt;/h4&gt;旨在提高NUPA的技术对微调预训练模型效果不佳，链式思维技术对NUPA的影响值得进一步探讨。&lt;h4&gt;总结&lt;/h4&gt;本研究为理解和提高大型语言模型的数值理解和处理能力迈出了初步步骤，相关基准和代码已发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/graphpku/number_cookbook&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) can solve an increasing number of complexreasoning tasks while making surprising mistakes in basic numericalunderstanding and processing (such as 9.11 &gt; 9.9). The latter ability isessential for tackling complex arithmetic and mathematical problems and servesas a foundation for most reasoning tasks, but previous work paid littleattention to it or only discussed several restricted tasks (like integeraddition). In this paper, we comprehensively investigate the numericalunderstanding and processing ability (NUPA) of LLMs. Firstly, we introduce abenchmark covering four common numerical representations and 17 distinctnumerical tasks in four major categories, resulting in 41 meaningfulcombinations in total. These tasks are derived from primary and secondaryeducation curricula, encompassing nearly all everyday numerical understandingand processing scenarios, and the rules of these tasks are very simple andclear. Through the benchmark, we find that current LLMs fail frequently in manyof the tasks. To study the problem, we train small models with existing andpotential techniques for enhancing NUPA (such as special tokenizers, PEs, andnumber formats), comprehensively evaluating their effectiveness using ourtestbed. We also finetune practical-scale LLMs on our proposed NUPA tasks andfind that 1) naive finetuning can improve NUPA a lot on many but not all tasks,and 2) surprisingly, techniques designed to enhance NUPA prove ineffective forfinetuning pretrained models. We further explore the impact of chain-of-thoughttechniques on NUPA. Our work takes a preliminary step towards understanding andimproving NUPA of LLMs. Our benchmark and code are released athttps://github.com/GraphPKU/number_cookbook.</description>
      <author>example@mail.com (Haotong Yang, Yi Hu, Shijia Kang, Zhouchen Lin, Muhan Zhang)</author>
      <guid isPermaLink="false">2411.03766v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation</title>
      <link>http://arxiv.org/abs/2411.03223v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in Geoscience and Remote Sensing Magazine
  (GRSM)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;地球观测（EO）数据分析因深度学习（DL）而发生重大变革，应用通常限于网格状数据结构。&lt;h4&gt;目的&lt;/h4&gt;引入图神经网络（GNNs）到EO领域，以应对多种模态、多传感器和异构EO数据的挑战。&lt;h4&gt;方法&lt;/h4&gt;首先提供GNNs的基本知识，随后总结EO领域的一般问题，并探讨GNNs在科学问题中的应用，如天气与气候分析、灾害管理、空气质量监测等。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs在多个EO应用领域表现出潜力，能够有效处理复杂数据和任务。&lt;h4&gt;结论&lt;/h4&gt;虽然GNNs并非万能解决方案，但与其他架构（如变压器）相比，具有潜在的协同效应。&lt;h4&gt;总结&lt;/h4&gt;本文探讨了GNNs的应用前景和方法论挑战，为未来研究提供了指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Earth Observation (EO) data analysis has been significantly revolutionized bydeep learning (DL), with applications typically limited to grid-like datastructures. Graph Neural Networks (GNNs) emerge as an important innovation,propelling DL into the non-Euclidean domain. Naturally, GNNs can effectivelytackle the challenges posed by diverse modalities, multiple sensors, and theheterogeneous nature of EO data. To introduce GNNs in the related domains, ourreview begins by offering fundamental knowledge on GNNs. Then, we summarize thegeneric problems in EO, to which GNNs can offer potential solutions. Followingthis, we explore a broad spectrum of GNNs' applications to scientific problemsin Earth systems, covering areas such as weather and climate analysis, disastermanagement, air quality monitoring, agriculture, land cover classification,hydrological process modeling, and urban modeling. The rationale behindadopting GNNs in these fields is explained, alongside methodologies fororganizing graphs and designing favorable architectures for various tasks.Furthermore, we highlight methodological challenges of implementing GNNs inthese domains and possible solutions that could guide future research. Whileacknowledging that GNNs are not a universal solution, we conclude the paper bycomparing them with other popular architectures like transformers and analyzingtheir potential synergies.</description>
      <author>example@mail.com (Shan Zhao, Zhaiyu Chen, Zhitong Xiong, Yilei Shi, Sudipan Saha, Xiao Xiang Zhu)</author>
      <guid isPermaLink="false">2411.03223v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>OSAD: Open-Set Aircraft Detection in SAR Images</title>
      <link>http://arxiv.org/abs/2411.01597v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages,11 figures. This work has been submitted to the IEEE for
  possible publication on March 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前主流的SAR图像目标检测方法在处理开放环境中的未知物体时缺乏鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;实现开放集检测，使得在封闭集上训练的检测器能够检测所有已知物体并识别开放集环境中的未知物体。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的开放集飞机检测器OSAD，配备了三个专门组件：全球上下文建模（GCM）、位置质量驱动的伪标签生成（LPG）和原型对比学习（PCL）。&lt;h4&gt;主要发现&lt;/h4&gt;GCM通过注意力图有效增强了网络对物体的表示；LPG利用物体位置和形状的线索优化定位质量；PCL通过基于原型的对比编码损失促进实例级内部类紧凑性和类间差异性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法能够有效检测未知物体，并在不影响闭集性能的情况下展现出竞争力的表现，未知物体的平均精度最高可提升0到18.36%。&lt;h4&gt;总结&lt;/h4&gt;OSAD方法克服了已知类别的经验分类风险，并提高了对潜在未知物体的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current mainstream SAR image object detection methods still lack robustnesswhen dealing with unknown objects in open environments. Open-set detection aimsto enable detectors trained on a closed set to detect all known objects andidentify unknown objects in open-set environments. The key challenges are howto improve the generalization to potential unknown objects and reduce theempirical classification risk of known categories under strong supervision. Toaddress these challenges, a novel open-set aircraft detector for SAR images isproposed, named Open-Set Aircraft Detection (OSAD), which is equipped withthree dedicated components: global context modeling (GCM), locationquality-driven pseudo labeling generation (LPG), and prototype contrastivelearning (PCL). GCM effectively enhances the network's representation ofobjects by attention maps which is formed through the capture of longsequential positional relationships. LPG leverages clues about object positionsand shapes to optimize localization quality, avoiding overfitting to knowncategory information and enhancing generalization to potential unknown objects.PCL employs prototype-based contrastive encoding loss to promote instance-levelintra-class compactness and inter-class variance, aiming to minimize theoverlap between known and unknown distributions and reduce the empiricalclassification risk of known categories. Extensive experiments havedemonstrated that the proposed method can effectively detect unknown objectsand exhibit competitive performance without compromising closed-setperformance. The highest absolute gain which ranges from 0 to 18.36% can beachieved on the average precision of unknown objects.</description>
      <author>example@mail.com (Xiayang Xiao, Zhuoxuan Li, Haipeng Wang)</author>
      <guid isPermaLink="false">2411.01597v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>SA3DIP: Segment Any 3D Instance with Potential 3D Priors</title>
      <link>http://arxiv.org/abs/2411.03819v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;2D基础模型的普及促使研究者探索其在开放世界3D实例分割中的适应性。&lt;h4&gt;目的&lt;/h4&gt;提出SA3DIP，一种利用潜在3D先验进行3D实例分割的新方法。&lt;h4&gt;方法&lt;/h4&gt;生成基于几何和纹理先验的3D原始元素，并引入3D检测器提供的补充约束以指导合并过程。&lt;h4&gt;主要发现&lt;/h4&gt;通过新方法减少了由于先前方法中3D先验使用有限而导致的分割性能限制。&lt;h4&gt;结论&lt;/h4&gt;SA3DIP在多个2D-3D数据集上的实验评估展示了其有效性和鲁棒性。&lt;h4&gt;补充信息&lt;/h4&gt;针对ScanNetV2基准中的低质量标注，提出了具有完整标注的ScanNetV2-INS数据集，并补充了额外实例。&lt;h4&gt;总结&lt;/h4&gt;SA3DIP方法在3D实例分割中表现出色，解决了以往方法的局限性，并提供了新的数据集支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ryang41/sa3dip&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of 2D foundation models has sparked research into adaptingthem for open-world 3D instance segmentation. Recent methods introduce aparadigm that leverages superpoints as geometric primitives and incorporates 2Dmulti-view masks from Segment Anything model (SAM) as merging guidance,achieving outstanding zero-shot instance segmentation results. However, thelimited use of 3D priors restricts the segmentation performance. Previousmethods calculate the 3D superpoints solely based on estimated normal fromspatial coordinates, resulting in under-segmentation for instances with similargeometry. Besides, the heavy reliance on SAM and hand-crafted algorithms in 2Dspace suffers from over-segmentation due to SAM's inherent part-levelsegmentation tendency. To address these issues, we propose SA3DIP, a novelmethod for Segmenting Any 3D Instances via exploiting potential 3D Priors.Specifically, on one hand, we generate complementary 3D primitives based onboth geometric and textural priors, which reduces the initial errors thataccumulate in subsequent procedures. On the other hand, we introducesupplemental constraints from the 3D space by using a 3D detector to guide afurther merging process. Furthermore, we notice a considerable portion oflow-quality ground truth annotations in ScanNetV2 benchmark, which affect thefair evaluations. Thus, we present ScanNetV2-INS with complete ground truthlabels and supplement additional instances for 3D class-agnostic instancesegmentation. Experimental evaluations on various 2D-3D datasets demonstratethe effectiveness and robustness of our approach. Our code and proposedScanNetV2-INS dataset are available HERE.</description>
      <author>example@mail.com (Xi Yang, Xu Gu, Xingyilang Yin, Xinbo Gao)</author>
      <guid isPermaLink="false">2411.03819v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Next Best View For Point-Cloud Model Acquisition: Bayesian Approximation and Uncertainty Analysis</title>
      <link>http://arxiv.org/abs/2411.01734v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Next Best View问题是计算机视觉中的一个重要研究领域，特别是在机器人技术中。近年来，深度学习模型被提出作为解决该问题的方法。&lt;h4&gt;目的&lt;/h4&gt;改进网络在预测下一个最佳视角时的准确性，使3D重建过程更加高效。&lt;h4&gt;方法&lt;/h4&gt;本文将基于PointNet的神经网络（PC-NBV）进行改造，结合dropout层来计算预测的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入不确定性测量，模型的错误率降低，准确率从30%提高到80%。还提出了一种直接利用不确定性指标改善最终预测的方法，但效果提升有限。&lt;h4&gt;结论&lt;/h4&gt;将不确定性估计引入神经网络能够显著提高Next Best View问题的预测准确性，但某些方法的改进效果较小。&lt;h4&gt;总结&lt;/h4&gt;通过结合贝叶斯估计和深度学习，本文为Next Best View问题提供了一种新的解决方案，展示了不确定性在提高预测准确性中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Next Best View problem is a computer vision problem widely studied inrobotics. To solve it, several methodologies have been proposed over the years.Some, more recently, propose the use of deep learning models. Predictionsobtained with the help of deep learning models naturally have some uncertaintyassociated with them. Despite this, the standard models do not allow for theirquantification. However, Bayesian estimation theory contributed to thedemonstration that dropout layers allow to estimate prediction uncertainty inneural networks.  This work adapts the point-net-based neural network for Next-Best-View(PC-NBV). It incorporates dropout layers into the model's architecture, thusallowing the computation of the uncertainty estimate associated with itspredictions. The aim of the work is to improve the network's accuracy incorrectly predicting the next best viewpoint, proposing a way to make the 3Dreconstruction process more efficient.  Two uncertainty measurements capable of reflecting the prediction's error andaccuracy, respectively, were obtained. These enabled the reduction of themodel's error and the increase in its accuracy from 30\% to 80\% by identifyingand disregarding predictions with high values of uncertainty. Another methodthat directly uses these uncertainty metrics to improve the final predictionwas also proposed. However, it showed very residual improvements.</description>
      <author>example@mail.com (Madalena Caldeira, Plinio Moreno)</author>
      <guid isPermaLink="false">2411.01734v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Advanced RAG Models with Graph Structures: Optimizing Complex Knowledge Reasoning and Text Generation</title>
      <link>http://arxiv.org/abs/2411.03572v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的检索增强生成模型（RAG）在处理复杂知识推理任务时效率不足，影响结果的质量和一致性。&lt;h4&gt;目的&lt;/h4&gt;通过引入图结构来优化RAG模型，从而提高其处理复杂知识推理任务的能力。&lt;h4&gt;方法&lt;/h4&gt;结合图神经网络（GNN）处理图结构数据，以捕捉实体之间的复杂关系。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的基于图的RAG模型在生成质量、知识一致性和推理能力方面优于传统生成模型，特别是在需要多维推理的任务上表现突出。&lt;h4&gt;结论&lt;/h4&gt;通过增强检索模块和图神经网络的结合，该模型能够更好地处理复杂知识背景信息，具有广泛的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的图结构RAG模型在复杂知识推理任务中表现优越，显示出其在实际应用中的广泛价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study aims to optimize the existing retrieval-augmented generation model(RAG) by introducing a graph structure to improve the performance of the modelin dealing with complex knowledge reasoning tasks. The traditional RAG modelhas the problem of insufficient processing efficiency when facing complex graphstructure information (such as knowledge graphs, hierarchical relationships,etc.), which affects the quality and consistency of the generated results. Thisstudy proposes a scheme to process graph structure data by combining graphneural network (GNN), so that the model can capture the complex relationshipbetween entities, thereby improving the knowledge consistency and reasoningability of the generated text. The experiment used the Natural Questions (NQ)dataset and compared it with multiple existing generation models. The resultsshow that the graph-based RAG model proposed in this paper is superior to thetraditional generation model in terms of quality, knowledge consistency, andreasoning ability, especially when dealing with tasks that requiremulti-dimensional reasoning. Through the combination of the enhancement of theretrieval module and the graph neural network, the model in this study canbetter handle complex knowledge background information and has broad potentialvalue in multiple practical application scenarios.</description>
      <author>example@mail.com (Yuxin Dong, Shuo Wang, Hongye Zheng, Jiajing Chen, Zhenhong Zhang, Chihang Wang)</author>
      <guid isPermaLink="false">2411.03572v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Quantum Rationale-Aware Graph Contrastive Learning for Jet Discrimination</title>
      <link>http://arxiv.org/abs/2411.01642v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions series journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在高能物理中，粒子喷流标记在区分夸克和胶子喷流方面发挥着关键作用，依赖于对撞机实验的数据。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过引入量子推理生成器（QRG），提升粒子喷流的区分性能，减少对标记数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出了一种量子推理感知图对比学习（QRGCL）框架，以有效利用推理感知增强，并解决现有对比学习框架的监督信号不足和计算效率问题。&lt;h4&gt;主要发现&lt;/h4&gt;在夸克-胶子喷流数据集上，QRGCL实现了77.53%的AUC分数，且仅使用了45个QRG参数，超越了传统、量子和混合图对比学习（GCL）与图神经网络（GNN）基准。&lt;h4&gt;结论&lt;/h4&gt;QRGCL展示了在高能物理中推进喷流标记及其他复杂分类任务的潜力，尤其是在计算效率和特征提取方面的限制。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种新的框架，通过量子技术提升高能物理领域的喷流标记能力，具有重要的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In high-energy physics, particle jet tagging plays a pivotal role indistinguishing quark from gluon jets using data from collider experiments.While graph-based deep learning methods have advanced this task beyondtraditional feature-engineered approaches, the complex data structure andlimited labeled samples present ongoing challenges. However, existingcontrastive learning (CL) frameworks struggle to leverage rationale-awareaugmentations effectively, often lacking supervision signals that guide theextraction of salient features and facing computational efficiency issues suchas high parameter counts. In this study, we demonstrate that integrating aquantum rationale generator (QRG) within our proposed Quantum Rationale-awareGraph Contrastive Learning (QRGCL) framework significantly enhances jetdiscrimination performance, reducing reliance on labeled data and capturingdiscriminative features. Evaluated on the quark-gluon jet dataset, QRGCLachieves an AUC score of 77.53% while maintaining a compact architecture ofonly 45 QRG parameters, outperforming classical, quantum, and hybrid GCL andGNN benchmarks. These results highlight QRGCL's potential to advance jettagging and other complex classification tasks in high-energy physics, wherecomputational efficiency and feature extraction limitations persist.</description>
      <author>example@mail.com (Md Abrar Jahin, Md. Akmol Masud, M. F. Mridha, Nilanjan Dey)</author>
      <guid isPermaLink="false">2411.01642v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>UniTraj: Universal Human Trajectory Modeling from Billion-Scale Worldwide Traces</title>
      <link>http://arxiv.org/abs/2411.03859v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类轨迹建模对于解读运动模式和支持各领域的高级应用至关重要，但现有方法常常针对特定任务和区域，存在任务特异性、区域依赖性和数据质量敏感性等限制。&lt;h4&gt;目的&lt;/h4&gt;提出一个通用的人类轨迹基础模型，以应对现有方法的局限性，能够跨任务和地理上下文进行推广和扩展。&lt;h4&gt;方法&lt;/h4&gt;提出UniTraj，一个任务自适应、区域独立且高度可推广的通用人类轨迹基础模型，并构建WorldTrace数据集，包含245万条轨迹和数十亿个点，来源于开放网络平台，覆盖70个国家。&lt;h4&gt;主要发现&lt;/h4&gt;通过多种重采样和掩码策略进行预训练，UniTraj有效克服了地理和任务限制，能够适应异质的数据质量，并在多项轨迹分析任务和真实世界数据集上表现优异。&lt;h4&gt;结论&lt;/h4&gt;UniTraj作为一种多功能、稳健的解决方案，具有广泛的轨迹分析应用潜力，而WorldTrace则是理想的训练基础，但并非唯一的选择。&lt;h4&gt;总结&lt;/h4&gt;UniTraj和WorldTrace的结合为人类轨迹分析提供了新的可能性，展示了在多样化任务和环境中的适应性和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human trajectory modeling is essential for deciphering movement patterns andsupporting advanced applications across various domains. However, existingmethods are often tailored to specific tasks and regions, resulting inlimitations related to task specificity, regional dependency, and data qualitysensitivity. Addressing these challenges requires a universal human trajectoryfoundation model capable of generalizing and scaling across diverse tasks andgeographic contexts. To this end, we propose UniTraj, a Universal humanTrajectory foundation model that is task-adaptive, region-independent, andhighly generalizable. To further enhance performance, we construct WorldTrace,the first large-scale, high-quality, globally distributed dataset sourced fromopen web platforms, encompassing 2.45 million trajectories with billions ofpoints across 70 countries. Through multiple resampling and masking strategiesdesigned for pre-training, UniTraj effectively overcomes geographic and taskconstraints, adapting to heterogeneous data quality. Extensive experimentsacross multiple trajectory analysis tasks and real-world datasets demonstratethat UniTraj consistently outperforms existing approaches in terms ofscalability and adaptability. These results underscore the potential of UniTrajas a versatile, robust solution for a wide range of trajectory analysisapplications, with WorldTrace serving as an ideal but non-exclusive foundationfor training.</description>
      <author>example@mail.com (Yuanshao Zhu, James Jianqiao Yu, Xiangyu Zhao, Xuetao Wei, Yuxuan Liang)</author>
      <guid isPermaLink="false">2411.03859v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>SEGMN: A Structure-Enhanced Graph Matching Network for Graph Similarity Learning</title>
      <link>http://arxiv.org/abs/2411.03624v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图相似性计算（GSC）旨在量化两个图之间的相似性分数。现有的基于图神经网络（GNN）的GSC方法虽利用了图内结构，但对边的结构利用不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种结构增强的图匹配网络（SEGMN），以改善节点的表示和图对之间的匹配。&lt;h4&gt;方法&lt;/h4&gt;SEGMN配备双重嵌入学习模块和结构感知匹配模块，通过引入邻接边表示和赋值图卷积，增强嵌入学习和跨图匹配的结构性。&lt;h4&gt;主要发现&lt;/h4&gt;SEGMN在基准数据集上的实验结果显示，在GED回归任务中超越了最先进的GSC方法，结构感知匹配模块可提升基线性能最高达25%。&lt;h4&gt;结论&lt;/h4&gt;通过结构增强，SEGMN有效地改善了图节点的相似性匹配，提供了更合理的相似性分数。&lt;h4&gt;总结&lt;/h4&gt;SEGMN通过综合利用图内外结构，提高了图相似性计算的准确性，具有良好的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph similarity computation (GSC) aims to quantify the similarity scorebetween two graphs. Although recent GSC methods based on graph neural networks(GNNs) take advantage of intra-graph structures in message passing, few of themfully utilize the structures presented by edges to boost the representation oftheir connected nodes. Moreover, previous cross-graph node embedding matchinglacks the perception of the overall structure of the graph pair, due to thefact that the node representations from GNNs are confined to the intra-graphstructure, causing the unreasonable similarity score. Intuitively, thecross-graph structure represented in the assignment graph is helpful to rectifythe inappropriate matching. Therefore, we propose a structure-enhanced graphmatching network (SEGMN). Equipped with a dual embedding learning module and astructure perception matching module, SEGMN achieves structure enhancement inboth embedding learning and cross-graph matching. The dual embedding learningmodule incorporates adjacent edge representation into each node to achieve astructure-enhanced representation. The structure perception matching moduleachieves cross-graph structure enhancement through assignment graphconvolution. The similarity score of each cross-graph node pair can berectified by aggregating messages from structurally relevant node pairs.Experimental results on benchmark datasets demonstrate that SEGMN outperformsthe state-of-the-art GSC methods in the GED regression task, and the structureperception matching module is plug-and-play, which can further improve theperformance of the baselines by up to 25%.</description>
      <author>example@mail.com (Wenjun Wang, Jiacheng Lu, Kejia Chen, Zheng Liu, Shilong Sang)</author>
      <guid isPermaLink="false">2411.03624v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Rotation Perturbation Robustness in Point Cloud Analysis: A Perspective of Manifold Distillation</title>
      <link>http://arxiv.org/abs/2411.01748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures, submitted to TCSVT&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云被视为黎曼流形的离散采样，在3D图像解释中发挥重要作用。旋转扰动是由设备偏移、系统不稳定、测量误差等因素导致的意外小变化，容易影响点云学习任务的结果。&lt;h4&gt;目的&lt;/h4&gt;提高点云学习方法对旋转扰动的鲁棒性，克服现有方法在性能和噪声容忍度方面的不足。&lt;h4&gt;方法&lt;/h4&gt;从流形的角度对点云进行重建，设计了一种流形蒸馏方法，实现旋转扰动的鲁棒性，且不需要坐标变换。在训练阶段，引入教师网络学习旋转鲁棒性信息，并通过在线蒸馏将信息传递给学生网络。在推理阶段，学生网络直接利用原始3D坐标信息来实现鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在四个不同的数据集上进行的实验验证了该方法的有效性。在Modelnet40和ScanobjectNN分类数据集中，相比流行的旋转鲁棒网络，分类精度分别提高了4.92%和4.41%；在ShapeNet和S3DIS分割数据集中，mIoU分别提高了7.36%和4.82%。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法在抵抗噪声和离群值方面也表现出色，显示了良好的鲁棒性和性能。&lt;h4&gt;总结&lt;/h4&gt;通过引入流形重建和蒸馏方法，显著提升了点云学习的旋转鲁棒性和性能，适用于多种数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud is often regarded as a discrete sampling of Riemannian manifoldand plays a pivotal role in the 3D image interpretation. Particularly, rotationperturbation, an unexpected small change in rotation caused by various factors(like equipment offset, system instability, measurement errors and so on), caneasily lead to the inferior results in point cloud learning tasks. However,classical point cloud learning methods are sensitive to rotation perturbation,and the existing networks with rotation robustness also have much room forimprovements in terms of performance and noise tolerance. Given these, thispaper remodels the point cloud from the perspective of manifold as well asdesigns a manifold distillation method to achieve the robustness of rotationperturbation without any coordinate transformation. In brief, during thetraining phase, we introduce a teacher network to learn the rotation robustnessinformation and transfer this information to the student network through onlinedistillation. In the inference phase, the student network directly utilizes theoriginal 3D coordinate information to achieve the robustness of rotationperturbation. Experiments carried out on four different datasets verify theeffectiveness of our method. Averagely, on the Modelnet40 and ScanobjectNNclassification datasets with random rotation perturbations, our classificationaccuracy has respectively improved by 4.92% and 4.41%, compared to popularrotation-robust networks; on the ShapeNet and S3DIS segmentation datasets,compared to the rotation-robust networks, the improvements of mIoU are 7.36%and 4.82%, respectively. Besides, from the experimental results, the proposedalgorithm also shows excellent performance in resisting noise and outliers.</description>
      <author>example@mail.com (Xinyu Xu, Huazhen Liu, Feiming Wei, Huilin Xiong, Wenxian Yu, Tao Zhang)</author>
      <guid isPermaLink="false">2411.01748v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Co-clustering for Federated Recommender System</title>
      <link>http://arxiv.org/abs/2411.01690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WWW '24: Proceedings of the ACM Web Conference 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着数据隐私和安全问题的日益关注，联邦推荐系统（FRS）提供了一种在高质量推荐和用户隐私之间取得平衡的解决方案。&lt;h4&gt;目的&lt;/h4&gt;解决FRS中的统计异质性问题，以最大化协同过滤（CF）的效益。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的共同聚类联邦推荐机制CoFedRec，通过将客户（用户）和项目进行聚类，学习特定于组的模型。&lt;h4&gt;主要发现&lt;/h4&gt;现有方法可能导致隐私泄露或面临维度灾难的困扰，而CoFedRec通过智能聚类和对比学习来提高推荐效果。&lt;h4&gt;结论&lt;/h4&gt;在四个数据集上的广泛实验验证了CoFedRec的有效性。&lt;h4&gt;总结&lt;/h4&gt;CoFedRec通过解决客户异质性问题，增强了联邦框架内的协同过滤性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3589334.3645626&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Xinrui17/CoFedRec&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As data privacy and security attract increasing attention, FederatedRecommender System (FRS) offers a solution that strikes a balance betweenproviding high-quality recommendations and preserving user privacy. However,the presence of statistical heterogeneity in FRS, commonly observed due topersonalized decision-making patterns, can pose challenges. To address thisissue and maximize the benefit of collaborative filtering (CF) in FRS, it isintuitive to consider clustering clients (users) as well as items intodifferent groups and learning group-specific models. Existing methods eitherresort to client clustering via user representations-risking privacy leakage,or employ classical clustering strategies on item embeddings or gradients,which we found are plagued by the curse of dimensionality. In this paper, wedelve into the inefficiencies of the K-Means method in client grouping,attributing failures due to the high dimensionality as well as data sparsityoccurring in FRS, and propose CoFedRec, a novel Co-clustering FederatedRecommendation mechanism, to address clients heterogeneity and enhance thecollaborative filtering within the federated framework. Specifically, theserver initially formulates an item membership from the client-provided itemnetworks. Subsequently, clients are grouped regarding a specific item categorypicked from the item membership during each communication round, resulting inan intelligently aggregated group model. Meanwhile, to comprehensively capturethe global inter-relationships among items, we incorporate an additionalsupervised contrastive learning term based on the server-side generated itemmembership into the local training phase for each client. Extensive experimentson four datasets are provided, which verify the effectiveness of the proposedCoFedRec.</description>
      <author>example@mail.com (Xinrui He, Shuo Liu, Jackey Keung, Jingrui He)</author>
      <guid isPermaLink="false">2411.01690v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Denoising study of Fluoroscopic Images in real time tumor tracking System based on Statistical model of noise</title>
      <link>http://arxiv.org/abs/2411.00199v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究探讨了实时图像引导放射治疗（IGRT）中获得的术中X射线透视图像的噪声特性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于识别的噪声幅度和空间概率模式的新型噪声图像生成方法。&lt;h4&gt;方法&lt;/h4&gt;首先，利用患者CT数据结合投影算法和实时肿瘤追踪系统的空间配置生成无噪声的数字重建放射影像（DRRs）。然后，根据观察到的噪声概率和幅度分布向这些DRRs添加噪声，生成数据集1。同时，生成数据集2，通过添加与数据集1相同均值和方差的高斯噪声，但噪声概率独立于像素位置和强度。&lt;h4&gt;主要发现&lt;/h4&gt;使用相同训练参数微调的预训练SwinIR模型在包含真实噪声的幻影图像测试中，基于提出的噪声模型数据集的SwinIR模型在去噪性能上优于基于高斯噪声和未进行迁移学习的模型，平均PSNR提高了1.45 dB。&lt;h4&gt;结论&lt;/h4&gt;本研究有助于深入理解这些透视图像中的噪声模式，对提高放射治疗中实时肿瘤追踪的图像质量和准确性至关重要。&lt;h4&gt;总结&lt;/h4&gt;研究结果为放射治疗图像处理提供了新的思路，有助于优化图像质量和肿瘤追踪的精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates the noise characteristics of intraoperative X-rayfluoroscopic images acquired during real-time image-guided radiotherapy (IGRT),and presents a novel noise image generation method based on the identifiednoise amplitude and spatial probability patterns. Initially, noise-freedigitally reconstructed radiographs (DRRs) were generated using patient CT datacombined with projection algorithms and the spatial configuration of thereal-time tumor tracking system. Based on the observed noise probability andamplitude distributions, noise was then added to these DRRs to create Dataset1. As a control, Dataset 2 was generated by adding Gaussian noise with the samemean and variance as Dataset 1; however, the noise probability in Dataset 2 isindependent of pixel location and pixel intensity. Both datasets were used tofine-tune a pre-trained SwinIR model with identical training parameters. Testson phantom images containing real noise show that the SwinIR model trained withthe proposed noise model dataset achieves superior denoising performance overthe model trained with Gaussian noise and the model without transfer learning,with an average PSNR improvement of 1.45 dB. This study contributes to a deeperunderstanding of noise patterns in these fluoroscopic images and is crucial forenhancing image quality and the accuracy of real-time tumor tracking inradiotherapy.</description>
      <author>example@mail.com (Yongxuan Yan, Fumitake Fujii, Takehiro Shiinoki)</author>
      <guid isPermaLink="false">2411.00199v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Face Reconstruction from Face Embeddings using Adapter to a Face Foundation Model</title>
      <link>http://arxiv.org/abs/2411.03960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人脸识别系统从人脸图像中提取嵌入向量，并利用这些嵌入进行个体验证或识别。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过人脸基础模型从黑箱人脸识别模型的嵌入中重建人脸图像。&lt;h4&gt;方法&lt;/h4&gt;使用42M图像训练基础模型，以从固定人脸识别模型的嵌入生成人脸图像，并引入适配器将目标嵌入转换为基础模型的嵌入空间。&lt;h4&gt;主要发现&lt;/h4&gt;生成的图像在不同的人脸识别模型和数据集上的评估表明，该方法有效地翻译了不同人脸识别模型的嵌入，并且重建的人脸图像在攻击不同人脸识别模型时具有较好的迁移性。&lt;h4&gt;结论&lt;/h4&gt;实验结果显示，我们重建的人脸图像在对抗人脸识别模型的重建攻击中优于之前的方法。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过人脸基础模型成功重建人脸图像的有效性，并提供了针对不同识别模型的攻击策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face recognition systems extract embedding vectors from face images and usethese embeddings to verify or identify individuals. Face reconstruction attack(also known as template inversion) refers to reconstructing face images fromface embeddings and using the reconstructed face image to enter a facerecognition system. In this paper, we propose to use a face foundation model toreconstruct face images from the embeddings of a blackbox face recognitionmodel. The foundation model is trained with 42M images to generate face imagesfrom the facial embeddings of a fixed face recognition model. We propose to usean adapter to translate target embeddings into the embedding space of thefoundation model. The generated images are evaluated on different facerecognition models and different datasets, demonstrating the effectiveness ofour method to translate embeddings of different face recognition models. Wealso evaluate the transferability of reconstructed face images when attackingdifferent face recognition models. Our experimental results show that ourreconstructed face images outperform previous reconstruction attacks againstface recognition models.</description>
      <author>example@mail.com (Hatef Otroshi Shahreza, Anjith George, Sébastien Marcel)</author>
      <guid isPermaLink="false">2411.03960v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Can Graph Neural Networks Expose Training Data Properties? An Efficient Risk Assessment Approach</title>
      <link>http://arxiv.org/abs/2411.03663v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In NeurIPS'24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）因其多样化的应用受到广泛关注，但图数据的稀缺性和质量限制了其在实际中的训练过程。&lt;h4&gt;目的&lt;/h4&gt;研究图属性推断攻击，以识别从共享模型中泄露敏感属性信息的风险。&lt;h4&gt;方法&lt;/h4&gt;提出一种高效的图属性推断攻击方法，通过模型近似技术，仅需在图上训练少量模型，并生成足够数量的近似影子模型进行攻击。&lt;h4&gt;主要发现&lt;/h4&gt;通过对六个真实场景的广泛实验，方法在攻击准确率上平均提高了2.7%，ROC-AUC提高了4.1%，并且速度比最佳基线快6.5倍。&lt;h4&gt;结论&lt;/h4&gt;提出的选择机制确保了保留的近似模型具有高多样性和低误差，显著改善了攻击效果。&lt;h4&gt;总结&lt;/h4&gt;本研究有效解决了图神经网络共享模型中的隐私泄露问题，为安全的GNN应用提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zjunet/GPIA_NIPS&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have attracted considerable attention due totheir diverse applications. However, the scarcity and quality limitations ofgraph data present challenges to their training process in practical settings.To facilitate the development of effective GNNs, companies and researchersoften seek external collaboration. Yet, directly sharing data raises privacyconcerns, motivating data owners to train GNNs on their private graphs andshare the trained models. Unfortunately, these models may still inadvertentlydisclose sensitive properties of their training graphs (e.g., average defaultrate in a transaction network), leading to severe consequences for data owners.In this work, we study graph property inference attack to identify the risk ofsensitive property information leakage from shared models. Existing approachestypically train numerous shadow models for developing such attack, which iscomputationally intensive and impractical. To address this issue, we propose anefficient graph property inference attack by leveraging model approximationtechniques. Our method only requires training a small set of models on graphs,while generating a sufficient number of approximated shadow models for attacks.To enhance diversity while reducing errors in the approximated models, we applyedit distance to quantify the diversity within a group of approximated modelsand introduce a theoretically guaranteed criterion to evaluate each model'serror. Subsequently, we propose a novel selection mechanism to ensure that theretained approximated models achieve high diversity and low error. Extensiveexperiments across six real-world scenarios demonstrate our method'ssubstantial improvement, with average increases of 2.7% in attack accuracy and4.1% in ROC-AUC, while being 6.5$\times$ faster compared to the best baseline.</description>
      <author>example@mail.com (Hanyang Yuan, Jiarong Xu, Renhong Huang, Mingli Song, Chunping Wang, Yang Yang)</author>
      <guid isPermaLink="false">2411.03663v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models</title>
      <link>http://arxiv.org/abs/2411.03177v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as a conference paper (poster) for NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模训练的潜在扩散模型（LDMs）使图像生成质量达到了前所未有的水平，但最佳训练方案的关键组件往往无法获得，限制了研究的比较与进展验证。&lt;h4&gt;目的&lt;/h4&gt;深入研究LDM训练方案，重点关注模型性能和训练效率。&lt;h4&gt;方法&lt;/h4&gt;重新实现五个已发表模型及其相应的训练方案，确保进行公平比较。探索生成模型条件化机制和小型数据集到大型数据集的表示迁移对模型性能和训练效率的影响。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种新的条件化机制，能够将语义和控制元数据的条件化解耦，使得在ImageNet-1k数据集上的类条件生成和CC12M数据集上的文本到图像生成都达到了新的最先进水平，FID在不同分辨率下均有显著改进。&lt;h4&gt;结论&lt;/h4&gt;新提出的条件化机制在多个数据集上提高了生成模型的性能，为相关领域的研究提供了新的方向。&lt;h4&gt;总结&lt;/h4&gt;研究表明，条件化方法和数据集的选择对LDM的性能有重要影响，新的机制为未来的模型训练提供了更高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale training of latent diffusion models (LDMs) has enabledunprecedented quality in image generation. However, the key components of thebest performing LDM training recipes are oftentimes not available to theresearch community, preventing apple-to-apple comparisons and hindering thevalidation of progress in the field. In this work, we perform an in-depth studyof LDM training recipes focusing on the performance of models and theirtraining efficiency. To ensure apple-to-apple comparisons, we re-implement fivepreviously published models with their corresponding recipes. Through ourstudy, we explore the effects of (i)~the mechanisms used to condition thegenerative model on semantic information (e.g., text prompt) and controlmetadata (e.g., crop size, random flip flag, etc.) on the model performance,and (ii)~the transfer of the representations learned on smaller andlower-resolution datasets to larger ones on the training efficiency and modelperformance. We then propose a novel conditioning mechanism that disentanglessemantic and control metadata conditionings and sets a new state-of-the-art inclass-conditional generation on the ImageNet-1k dataset -- with FIDimprovements of 7% on 256 and 8% on 512 resolutions -- as well as text-to-imagegeneration on the CC12M dataset -- with FID improvements of 8% on 256 and 23%on 512 resolution.</description>
      <author>example@mail.com (Tariq Berrada Ifriqi, Pietro Astolfi, Melissa Hall, Reyhane Askari-Hemmat, Yohann Benchetrit, Marton Havasi, Matthew Muckley, Karteek Alahari, Adriana Romero-Soriano, Jakob Verbeek, Michal Drozdzal)</author>
      <guid isPermaLink="false">2411.03177v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Magnitude Pruning of Large Pretrained Transformer Models with a Mixture Gaussian Prior</title>
      <link>http://arxiv.org/abs/2411.00969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型预训练变换器模型在自然语言处理领域取得了先进的性能，但其巨大的参数数量对实际部署构成挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于大小的剪枝算法，称为混合高斯先验剪枝（MGPP），以解决模型大小问题。&lt;h4&gt;方法&lt;/h4&gt;MGPP利用混合高斯先验进行正则化，剪除不具表现力的权重，以保持模型的表达能力。&lt;h4&gt;主要发现&lt;/h4&gt;MGPP在各种自然语言处理任务中表现优于现有剪枝方法，特别是在高稀疏性设置下。&lt;h4&gt;结论&lt;/h4&gt;为稀疏变换器的一致性提供了理论证明，阐明了所提出剪枝方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;MGPP算法在保持模型性能的同时，有效减少了模型参数，为实际应用提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large pretrained transformer models have revolutionized modern AIapplications with their state-of-the-art performance in natural languageprocessing (NLP). However, their substantial parameter count poses challengesfor real-world deployment. To address this, researchers often reduce model sizeby pruning parameters based on their magnitude or sensitivity. Previousresearch has demonstrated the limitations of magnitude pruning, especially inthe context of transfer learning for modern NLP tasks. In this paper, weintroduce a new magnitude-based pruning algorithm called mixture Gaussian priorpruning (MGPP), which employs a mixture Gaussian prior for regularization. MGPPprunes non-expressive weights under the guidance of the mixture Gaussian prior,aiming to retain the model's expressive capability. Extensive evaluationsacross various NLP tasks, including natural language understanding, questionanswering, and natural language generation, demonstrate the superiority of MGPPover existing pruning methods, particularly in high sparsity settings.Additionally, we provide a theoretical justification for the consistency of thesparse transformer, shedding light on the effectiveness of the proposed pruningmethod.</description>
      <author>example@mail.com (Mingxuan Zhang, Yan Sun, Faming Liang)</author>
      <guid isPermaLink="false">2411.00969v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks with Coarse- and Fine-Grained Division for Mitigating Label Sparsity and Noise</title>
      <link>http://arxiv.org/abs/2411.03744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在处理图结构数据的半监督学习任务中越来越受到关注，但其性能受到节点标签噪声和稀疏性的影响。&lt;h4&gt;目的&lt;/h4&gt;探索一种稳健的GNN，解决在噪声和稀疏标签情况下的半监督节点分类问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的图神经网络模型GNN-CFGD，通过粗细粒度划分和图重建来减轻标签稀疏性和噪声的影响。&lt;h4&gt;主要发现&lt;/h4&gt;将未标记节点与干净标记节点连接的效果优于与可能含噪声的标记节点连接，能更有效地应对标签噪声。&lt;h4&gt;结论&lt;/h4&gt;GNN-CFGD在各种数据集上的实验表明其有效性和鲁棒性优于现有方法。&lt;h4&gt;总结&lt;/h4&gt;GNN-CFGD通过对标签进行粗细粒度划分，并促进监督传播，成功应对了标签噪声和稀疏性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have gained considerable prominence insemi-supervised learning tasks in processing graph-structured data, primarilyowing to their message-passing mechanism, which largely relies on theavailability of clean labels. However, in real-world scenarios, labels on nodesof graphs are inevitably noisy and sparsely labeled, significantly degradingthe performance of GNNs. Exploring robust GNNs for semi-supervised nodeclassification in the presence of noisy and sparse labels remains a criticalchallenge. Therefore, we propose a novel \textbf{G}raph \textbf{N}eural\textbf{N}etwork with \textbf{C}oarse- and \textbf{F}ine-\textbf{G}rained\textbf{D}ivision for mitigating label sparsity and noise, namely GNN-CFGD. Thekey idea of GNN-CFGD is reducing the negative impact of noisy labels viacoarse- and fine-grained division, along with graph reconstruction.Specifically, we first investigate the effectiveness of linking unlabeled nodesto cleanly labeled nodes, demonstrating that this approach is more effective incombating labeling noise than linking to potentially noisy labeled nodes. Basedon this observation, we introduce a Gaussian Mixture Model (GMM) based on thememory effect to perform a coarse-grained division of the given labels intoclean and noisy labels. Next, we propose a clean labels oriented link thatconnects unlabeled nodes to cleanly labeled nodes, aimed at mitigating labelsparsity and promoting supervision propagation. Furthermore, to provide refinedsupervision for noisy labeled nodes and additional supervision for unlabelednodes, we fine-grain the noisy labeled and unlabeled nodes into two candidatesets based on confidence, respectively. Extensive experiments on variousdatasets demonstrate the superior effectiveness and robustness of GNN-CFGD.</description>
      <author>example@mail.com (Shuangjie Li, Baoming Zhang, Jianqing Song, Gaoli Ruan, Chongjun Wang, Junyuan Xie)</author>
      <guid isPermaLink="false">2411.03744v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion-based Virtual Fixtures</title>
      <link>http://arxiv.org/abs/2411.02169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at ICRA@40&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;虚拟夹具通过限制人类操作员的动作来辅助遥操作设置。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的虚拟夹具公式，适用于触觉机器人任务。&lt;h4&gt;方法&lt;/h4&gt;基于表面位置约束行为，考虑表面的距离（度量），直接处理通过相机收集的可能有噪声和部分的点云。&lt;h4&gt;主要发现&lt;/h4&gt;在两个模拟实验中展示了方法的能力：一是根据表面位置调节接触力大小或切向速度，二是引导机器人到达目标并避免表面上定义的限制区域。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效地在整个表面上扩散行为，考虑表面几何形状。&lt;h4&gt;总结&lt;/h4&gt;所有源代码、实验数据和视频均可通过公开访问获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Virtual fixtures assist human operators in teleoperation settings byconstraining their actions. This extended abstract introduces a novel virtualfixture formulation \emph{on surfaces} for tactile robotics tasks. Unlikeexisting methods, our approach constrains the behavior based on the position onthe surface and generalizes it over the surface by considering the distance(metric) on the surface. Our method works directly on possibly noisy andpartial point clouds collected via a camera. Given a set of regions on thesurface together with their desired behaviors, our method diffuses thebehaviors across the entire surface by taking into account the surfacegeometry. We demonstrate our method's ability in two simulated experiments (i)to regulate contact force magnitude or tangential speed based on surfaceposition and (ii) to guide the robot to targets while avoiding restrictedregions defined on the surface. All source codes, experimental data, and videosare available as open access athttps://sites.google.com/view/diffusion-virtual-fixtures</description>
      <author>example@mail.com (Cem Bilaloglu, Tobias Löw, Sylvain Calinon)</author>
      <guid isPermaLink="false">2411.02169v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>FPPL: An Efficient and Non-IID Robust Federated Continual Learning Framework</title>
      <link>http://arxiv.org/abs/2411.01904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联邦持续学习（FCL）旨在在去中心化的联邦学习环境中，从连续数据流中学习，同时缓解经典持续学习中的灾难性遗忘问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且对非独立同分布（non-IID）数据具有鲁棒性的联邦持续学习框架FPPL。&lt;h4&gt;方法&lt;/h4&gt;FPPL采用轻量级提示和原型的联合学习，无需重放机制。客户端使用融合函数充分利用任务特定提示中的知识，服务器通过对比学习聚合全局原型以获得统一表示。&lt;h4&gt;主要发现&lt;/h4&gt;FPPL有效缓解了因非IID数据异质性和灾难性遗忘导致的性能下降，实验结果显示其在多样的非IID程度下仍能保持显著性能。&lt;h4&gt;结论&lt;/h4&gt;FPPL在设计上高效，且在面对不同的非IID数据时表现出良好的鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;FPPL为联邦持续学习提供了一种新的解决方案，能够有效学习并保护隐私，减少存储和计算负担。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ycheoo/fppl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated continual learning (FCL) aims to learn from sequential data streamin the decentralized federated learning setting, while simultaneouslymitigating the catastrophic forgetting issue in classical continual learning.Existing FCL methods usually employ typical rehearsal mechanisms, which couldresult in privacy violations or additional onerous storage and computationalburdens. In this work, an efficient and non-IID robust federated continuallearning framework, called Federated Prototype-Augmented Prompt Learning(FPPL), is proposed. The FPPL can collaboratively learn lightweight promptsaugmented by prototypes without rehearsal. On the client side, a fusionfunction is employed to fully leverage the knowledge contained in task-specificprompts for alleviating catastrophic forgetting. Additionally, globalprototypes aggregated from the server are used to obtain unified representationthrough contrastive learning, mitigating the impact of non-IID-derived dataheterogeneity. On the server side, locally uploaded prototypes are utilized toperform debiasing on the classifier, further alleviating the performancedegradation caused by both non-IID and catastrophic forgetting. Empiricalevaluations demonstrate the effectiveness of FPPL, achieving notableperformance with an efficient design while remaining robust to diverse non-IIDdegrees. Code is available at: https://github.com/ycheoo/FPPL.</description>
      <author>example@mail.com (Yuchen He, Chuyun Shen, Xiangfeng Wang, Bo Jin)</author>
      <guid isPermaLink="false">2411.01904v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Between U.S. Presidential Elections: How Should We Learn From A 2020 Ad Campaign To Inform 2024 Ad Campaigns?</title>
      <link>http://arxiv.org/abs/2411.01100v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;2024年美国总统选举中，针对特朗普的负面数字广告可能影响宾夕法尼亚州的选民投票率，该州被视为关键的“转折点”州。&lt;h4&gt;目的&lt;/h4&gt;评估负面数字广告对2024年宾夕法尼亚州选民投票率的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于迁移学习的框架，利用2020年的广告实验知识来评估2024年的广告效果，同时进行敏感性分析以量化过去与未来选举间的不可观察差异。&lt;h4&gt;主要发现&lt;/h4&gt;在宾夕法尼亚州，不同县和按性别、城市化程度及教育程度分层的重要子群体之间的广告效果存在异质性。&lt;h4&gt;结论&lt;/h4&gt;通过我们的框架，得出了针对特朗普的负面数字广告运动对选民投票率的影响估计。&lt;h4&gt;总结&lt;/h4&gt;本研究为评估负面广告的效果提供了一种成本更低且更快的方法，并且考虑了不同地区和人群的反应差异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For the 2024 U.S. presidential election, would negative, digital ads againstDonald Trump impact voter turnout in Pennsylvania (PA), a key "tipping point"state? The gold standard to address this question, a randomized experimentwhere voters get randomized to different ads, yields unbiased estimates of thead effect, but is very expensive. Instead, we propose a less-than-ideal, butsignificantly cheaper and likely faster framework based on transfer learning,where we transfer knowledge from a past ad experiment in 2020 to evaluate adsfor 2024. A key component of our framework is a sensitivity analysis thatquantifies the unobservable differences between past and future elections,which can be calibrated in a data-driven manner. We propose two estimators ofthe 2024 ad effect: a simple regression estimator with bootstrap, which werecommend for practitioners in this field, and an estimator based on theefficient influence function for broader applications. Using our framework, weestimate the effect of running a negative, digital ad campaign against Trump onvoter turnout in PA for the 2024 election. Our findings indicate effectheterogeneity across counties of PA and among important subgroups stratified bygender, urbanicity, and education attainment.</description>
      <author>example@mail.com (Xinran Miao, Jiwei Zhao, Hyunseung Kang)</author>
      <guid isPermaLink="false">2411.01100v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Do Mice Grok? Glimpses of Hidden Progress During Overtraining in Sensory Cortex</title>
      <link>http://arxiv.org/abs/2411.03541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类专家即使在掌握技能后仍继续学习，这激发了对任务相关表征学习的研究。&lt;h4&gt;目的&lt;/h4&gt;探讨行为停止变化时，任务特定表征学习是否仍然持续。&lt;h4&gt;方法&lt;/h4&gt;对近期发表的神经数据进行重新分析，观察小鼠在任务过度训练后的表现。&lt;h4&gt;主要发现&lt;/h4&gt;在小鼠的后嗅皮层中发现过度训练后，解码准确性提高，且在保留的泛化测试中表现改善。&lt;h4&gt;结论&lt;/h4&gt;过度训练期间，皮层中的类表示持续分离，尽管行为未发生变化，但能提高错误分类的准确性。&lt;h4&gt;假设&lt;/h4&gt;这种隐秘的学习形式为近似边际最大化，并在神经数据中得到验证。&lt;h4&gt;模型&lt;/h4&gt;构建并解释了一个简单的合成模型，重现了这些现象。&lt;h4&gt;总结&lt;/h4&gt;这一晚期特征学习模型为动物学习中的过度训练反转提供了解释，表明学习的特征能够在特定任务变化中被重新利用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Does learning of task-relevant representations stop when behavior stopschanging? Motivated by recent theoretical advances in machine learning and theintuitive observation that human experts continue to learn from practice evenafter mastery, we hypothesize that task-specific representation learning cancontinue, even when behavior plateaus. In a novel reanalysis of recentlypublished neural data, we find evidence for such learning in posterior piriformcortex of mice following continued training on a task, long after behaviorsaturates at near-ceiling performance ("overtraining"). This learning is markedby an increase in decoding accuracy from piriform neural populations andimproved performance on held-out generalization tests. We demonstrate thatclass representations in cortex continue to separate during overtraining, sothat examples that were incorrectly classified at the beginning of overtrainingcan abruptly be correctly classified later on, despite no changes in behaviorduring that time. We hypothesize this hidden yet rich learning takes the formof approximate margin maximization; we validate this and other predictions inthe neural data, as well as build and interpret a simple synthetic model thatrecapitulates these phenomena. We conclude by showing how this model oflate-time feature learning implies an explanation for the empirical puzzle ofovertraining reversal in animal learning, where task-specific representationsare more robust to particular task changes because the learned features can bereused.</description>
      <author>example@mail.com (Tanishq Kumar, Blake Bordelon, Cengiz Pehlevan, Venkatesh N. Murthy, Samuel J. Gershman)</author>
      <guid isPermaLink="false">2411.03541v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>First, Learn What You Don't Know: Active Information Gathering for Driving at the Limits of Handling</title>
      <link>http://arxiv.org/abs/2411.00107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;结合数据驱动模型和模型预测控制（MPC）能够有效控制非线性系统，但在不稳定系统上在线适应可能不足以确保可靠的学习和控制。&lt;h4&gt;目的&lt;/h4&gt;提出一个贝叶斯元学习MPC框架，以解决在动态驾驶情况下的控制问题。&lt;h4&gt;方法&lt;/h4&gt;使用贝叶斯最后一层元学习的方法，构建一个表达能力强的车辆动力学模型，以实现快速在线适应，并利用模型的不确定性估计指导数据收集。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该框架能够在动态漂移操作中实现可靠控制；仅依靠在线适应可能不足以在稳定性边缘实现零-shot控制；主动数据收集有助于提升性能。&lt;h4&gt;结论&lt;/h4&gt;贝叶斯元学习MPC框架能够有效应对动态驾驶中的控制挑战，尤其是在不稳定条件下。&lt;h4&gt;总结&lt;/h4&gt;该研究为不稳定系统的控制提供了一种新的方法，通过快速在线适应和主动数据收集，提升了控制的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Combining data-driven models that adapt online and model predictive control(MPC) has enabled effective control of nonlinear systems. However, whendeployed on unstable systems, online adaptation may not be fast enough toensure reliable simultaneous learning and control. For example, controllers ona vehicle executing highly dynamic maneuvers may push the tires to theirfriction limits, destabilizing the vehicle and allowing modeling errors toquickly compound and cause a loss of control. In this work, we present aBayesian meta-learning MPC framework. We propose an expressive vehicle dynamicsmodel that leverages Bayesian last-layer meta-learning to enable rapid onlineadaptation. The model's uncertainty estimates are used to guide informativedata collection and quickly improve the model prior to deployment. Experimentson a Toyota Supra show that (i) the framework enables reliable control indynamic drifting maneuvers, (ii) online adaptation alone may not suffice forzero-shot control of a vehicle at the edge of stability, and (iii) active datacollection helps achieve reliable performance.</description>
      <author>example@mail.com (Alexander Davydov, Franck Djeumou, Marcus Greiff, Makoto Suminaka, Michael Thompson, John Subosits, Thomas Lew)</author>
      <guid isPermaLink="false">2411.00107v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Reconsidering the Performance of GAE in Link Prediction</title>
      <link>http://arxiv.org/abs/2411.03845v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多种图神经网络（GNN）和先进的训练技术被提出用于链接预测任务，但过时的基线模型可能导致对新方法效益的高估。&lt;h4&gt;目的&lt;/h4&gt;系统性研究图自编码器（GAE）的潜力。&lt;h4&gt;方法&lt;/h4&gt;精细调整超参数，采用正交嵌入和线性传播的技巧。&lt;h4&gt;主要发现&lt;/h4&gt;经过优化的GAE能够匹配更复杂模型的性能，同时提供更高的计算效率。&lt;h4&gt;结论&lt;/h4&gt;GAE在链接预测任务中是一个有效且高效的选择。&lt;h4&gt;总结&lt;/h4&gt;优化后的GAE在性能和计算效率上表现出色，有潜力替代复杂的GNN模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/graphpku/refined-gae&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Various graph neural networks (GNNs) with advanced training techniques andmodel designs have been proposed for link prediction tasks. However, outdatedbaseline models may lead to an overestimation of the benefits provided by thesenovel approaches. To address this, we systematically investigate the potentialof Graph Autoencoders (GAE) by meticulously tuning hyperparameters andutilizing the trick of orthogonal embedding and linear propagation. Ourfindings reveal that a well-optimized GAE can match the performance of morecomplex models while offering greater computational efficiency.</description>
      <author>example@mail.com (Weishuo Ma, Yanbo Wang, Xiyuan Wang, Muhan Zhang)</author>
      <guid isPermaLink="false">2411.03845v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Reconstruction of Continuous Cosmological Fields from Discrete Tracers with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.02496v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5+5 pages, 6 figures. Contribution to ml4ps workshop at NeurIPS-2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究使用观察到的星系目录中的离散点云重建三维连续宇宙物质场。&lt;h4&gt;目的&lt;/h4&gt;提出一种混合的GNN-CNN架构，以准确重建暗物质和电子密度。&lt;h4&gt;方法&lt;/h4&gt;利用CAMELS流体动力学宇宙模拟，采用学习的网格分配方案，改进传统的云入格方法。&lt;h4&gt;主要发现&lt;/h4&gt;该架构能够有效重建观察到的星系及其特征所对应的物质密度场。&lt;h4&gt;结论&lt;/h4&gt;该方法可改善宇宙学分析，尤其是在需要从可观察的离散点云估计不可见的连续场时。&lt;h4&gt;总结&lt;/h4&gt;混合GNN-CNN架构在宇宙物质场重建中表现出色，具有重要的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We develop a hybrid GNN-CNN architecture for the reconstruction of3-dimensional continuous cosmological matter fields from discrete point clouds,provided by observed galaxy catalogs. Using the CAMELS hydrodynamicalcosmological simulations we demonstrate that the proposed architecture allowsfor an accurate reconstruction of both the dark matter and electron densitygiven observed galaxies and their features. Our approach includes a learnedgrid assignment scheme that improves over the traditional cloud-in-cell method.Our method can improve cosmological analyses in situations where non-luminous(and thus unobservable) continuous fields need to be estimated from luminous(observable) discrete point cloud tracers.</description>
      <author>example@mail.com (Yurii Kvasiuk, Jordan Krywonos, Matthew C. Johnson, Moritz Münchmeyer)</author>
      <guid isPermaLink="false">2411.02496v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>ELU-GCN: Effectively Label-Utilizing Graph Convolutional Network</title>
      <link>http://arxiv.org/abs/2411.02279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图卷积网络（GCNs）的消息传递机制可以将标签信息传播到更广泛的邻居，从而提高标签的利用率。&lt;h4&gt;目的&lt;/h4&gt;解决传统GCN框架中标签信息未被有效利用的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的两步框架ELU-GCN，第一步进行图学习以学习新图结构（ELU-图），第二步在GCN框架上设计新的图对比学习，用于表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;通过探索学习到的ELU图与原始图之间的一致性和互斥信息，验证了所提方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;理论上证明所提方法可以确保GCNs的泛化能力，并通过大量实验验证了其优越性。&lt;h4&gt;总结&lt;/h4&gt;ELU-GCN框架在提高标签信息利用率和GCNs的表现方面具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The message-passing mechanism of graph convolutional networks (i.e., GCNs)enables label information to be propagated to a broader range of neighbors,thereby increasing the utilization of labels. However, the label information isnot always effectively utilized in the traditional GCN framework. To addressthis issue, we propose a new two-step framework called ELU-GCN. In the firststage, ELU-GCN conducts graph learning to learn a new graph structure (\ieELU-graph), which enables GCNs to effectively utilize label information. In thesecond stage, we design a new graph contrastive learning on the GCN frameworkfor representation learning by exploring the consistency and mutually exclusiveinformation between the learned ELU graph and the original graph. Moreover, wetheoretically demonstrate that the proposed method can ensure thegeneralization ability of GCNs. Extensive experiments validate the superiorityof the proposed method.</description>
      <author>example@mail.com (Jincheng Huang, Yujie Mo, Xiaoshuang Shi, Lei Feng, Xiaofeng Zhu)</author>
      <guid isPermaLink="false">2411.02279v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Fast Adaptation with Kernel and Gradient based Meta Leaning</title>
      <link>http://arxiv.org/abs/2411.00404v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages(with reference), 2 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模型无关元学习（MAML）已成为少样本学习的标准方法，但存在不稳定和计算效率低的问题。&lt;h4&gt;目的&lt;/h4&gt;提出两种算法以改善MAML的内外循环，并探讨'元'学习的真实含义。&lt;h4&gt;方法&lt;/h4&gt;第一种算法重新定义了函数空间中的优化问题，通过闭式解更新模型，而非多次梯度步骤。第二种算法在外循环中为每个任务的损失分配权重，以优化MAML的收敛性。&lt;h4&gt;主要发现&lt;/h4&gt;这些算法在训练和推理阶段优化了MAML的收敛性，并提供了对元学习的新视角。&lt;h4&gt;结论&lt;/h4&gt;研究表明，相较于现有方法，提出的算法在少样本学习和快速任务适应方面更为高效，为元学习建立了新的范式。&lt;h4&gt;总结&lt;/h4&gt;本研究在理论和实验上取得了重要发现，并为少样本学习提供了更有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model Agnostic Meta Learning or MAML has become the standard for few-shotlearning as a meta-learning problem. MAML is simple and can be applied to anymodel, as its name suggests. However, it often suffers from instability andcomputational inefficiency during both training and inference times. In thispaper, we propose two algorithms to improve both the inner and outer loops ofMAML, then pose an important question about what 'meta' learning truly is. Ourfirst algorithm redefines the optimization problem in the function space toupdate the model using closed-form solutions instead of optimizing parametersthrough multiple gradient steps in the inner loop. In the outer loop, thesecond algorithm adjusts the learning of the meta-learner by assigning weightsto the losses from each task of the inner loop. This method optimizesconvergence during both the training and inference stages of MAML. Inconclusion, our algorithms offer a new perspective on meta-learning and makesignificant discoveries in both theory and experiments. This research suggestsa more efficient approach to few-shot learning and fast task adaptationcompared to existing methods. Furthermore, it lays the foundation forestablishing a new paradigm in meta-learning.</description>
      <author>example@mail.com (JuneYoung Park, MinJae Kang)</author>
      <guid isPermaLink="false">2411.00404v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Mobile Recording Device Recognition Based Cross-Scale and Multi-Level Representation Learning</title>
      <link>http://arxiv.org/abs/2411.03668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了一种建模方法，采用多层次全球处理，包括短期帧级和长期样本级特征尺度。&lt;h4&gt;目的&lt;/h4&gt;旨在通过多层次特征提取和融合，提高识别精度。&lt;h4&gt;方法&lt;/h4&gt;初始阶段采用多种尺度提取特征，包括梅尔频率倒谱系数（MFCC）和预处理的Fbank对数能量谱。构建识别网络模型时，考虑帧级和样本级的二维时间特征，使用基于一维卷积的卷积长短期记忆（ConvLSTM）融合时空信息，提取短期特征，随后使用双向长短期记忆（BiLSTM）学习长期序列表示，最后通过Transformer编码器进行跨尺度的多层次处理。&lt;h4&gt;主要发现&lt;/h4&gt;在CCNU_Mobile数据集上，该方法实现了99.6%的识别准确率，相较于基线系统提高了2%到12%。&lt;h4&gt;结论&lt;/h4&gt;模型在新数据集上的分类任务中也表现出良好的迁移能力，达到了87.9%的准确率。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过多层次特征提取和融合，可以显著提高识别系统的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a modeling approach that employs multi-level globalprocessing, encompassing both short-term frame-level and long-term sample-levelfeature scales. In the initial stage of shallow feature extraction, variousscales are employed to extract multi-level features, including Mel-FrequencyCepstral Coefficients (MFCC) and pre-Fbank log energy spectrum. Theconstruction of the identification network model involves considering the inputtwo-dimensional temporal features from both frame and sample levels.Specifically, the model initially employs one-dimensional convolution-basedConvolutional Long Short-Term Memory (ConvLSTM) to fuse spatiotemporalinformation and extract short-term frame-level features. Subsequently,bidirectional long Short-Term Memory (BiLSTM) is utilized to learn long-termsample-level sequential representations. The transformer encoder then performscross-scale, multi-level processing on global frame-level and sample-levelfeatures, facilitating deep feature representation and fusion at both levels.Finally, recognition results are obtained through Softmax. Our method achievesan impressive 99.6% recognition accuracy on the CCNU_Mobile dataset, exhibitinga notable improvement of 2% to 12% compared to the baseline system.Additionally, we thoroughly investigate the transferability of our model,achieving an 87.9% accuracy in a classification task on a new dataset.</description>
      <author>example@mail.com (Chunyan Zeng, Yuhao Zhao, Zhifeng Wang)</author>
      <guid isPermaLink="false">2411.03668v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>S3PT: Scene Semantics and Structure Guided Clustering to Boost Self-Supervised Pre-Training for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.23085v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;最近的自监督聚类预训练技术如DINO和Cribo在下游检测和分割任务中表现出色，但在现实应用中面临物体类别和尺寸分布不平衡以及复杂场景几何的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出S3PT，一种新颖的场景语义和结构引导的聚类方法，以提供更一致的自监督训练目标。&lt;h4&gt;方法&lt;/h4&gt;1. 引入语义分布一致的聚类，鼓励对稀有类别（如摩托车或动物）的更好表示。 2. 采用物体多样性一致的空间聚类，处理从大背景区域到小物体（如行人和交通标志）的不平衡和多样物体尺寸。 3. 提出基于深度信息的空间聚类，以几何信息来正则化学习，进一步优化特征层面的区域分离。&lt;h4&gt;主要发现&lt;/h4&gt;所学习的表示在nuScenes、nuImages和Cityscapes数据集上的下游语义分割和3D物体检测任务中显著提高了性能，并展示了良好的领域转换特性。&lt;h4&gt;结论&lt;/h4&gt;S3PT方法能够有效应对场景中的不平衡和复杂性，为自监督学习提供了更一致的目标。&lt;h4&gt;总结&lt;/h4&gt;通过引入语义和几何信息，S3PT在提升模型性能和处理复杂场景方面具有重要贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent self-supervised clustering-based pre-training techniques like DINO andCribo have shown impressive results for downstream detection and segmentationtasks. However, real-world applications such as autonomous driving facechallenges with imbalanced object class and size distributions and complexscene geometries. In this paper, we propose S3PT a novel scene semantics andstructure guided clustering to provide more scene-consistent objectives forself-supervised training. Specifically, our contributions are threefold: First,we incorporate semantic distribution consistent clustering to encourage betterrepresentation of rare classes such as motorcycles or animals. Second, weintroduce object diversity consistent spatial clustering, to handle imbalancedand diverse object sizes, ranging from large background areas to small objectssuch as pedestrians and traffic signs. Third, we propose a depth-guided spatialclustering to regularize learning based on geometric information of the scene,thus further refining region separation on the feature level. Our learnedrepresentations significantly improve performance in downstream semanticsegmentation and 3D object detection tasks on the nuScenes, nuImages, andCityscapes datasets and show promising domain translation properties.</description>
      <author>example@mail.com (Maciej K. Wozniak, Hariprasath Govindarajan, Marvin Klingner, Camille Maurice, B Ravi Kiran, Senthil Yogamani)</author>
      <guid isPermaLink="false">2410.23085v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Multi-branch Spatio-Temporal Graph Neural Network For Efficient Ice Layer Thickness Prediction</title>
      <link>http://arxiv.org/abs/2411.04055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;理解极地冰层的时空模式对于跟踪冰盖平衡变化和评估冰动力学至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究使用图神经网络的几何深度学习，以建立一个时空图神经网络，利用冰层厚度信息进行深层预测。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新型的多分支时空图神经网络，采用GraphSAGE框架进行空间特征学习，并通过时间卷积操作捕捉时间变化，使网络的不同分支更专注于单一学习任务。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的多分支网络在准确性和效率上持续优于当前融合的时空图神经网络。&lt;h4&gt;结论&lt;/h4&gt;多分支时空图神经网络在冰层模式学习和预测方面表现出色，显示出其在冰动力学研究中的潜力。&lt;h4&gt;总结&lt;/h4&gt;采用图神经网络提升了极地冰层研究的精度和效率，推动了相关领域的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding spatio-temporal patterns in polar ice layers is essential fortracking changes in ice sheet balance and assessing ice dynamics. Whileconvolutional neural networks are widely used in learning ice layer patternsfrom raw echogram images captured by airborne snow radar sensors, noise in theechogram images prevents researchers from getting high-quality results.Instead, we focus on geometric deep learning using graph neural networks,aiming to build a spatio-temporal graph neural network that learns fromthickness information of the top ice layers and predicts for deeper layers. Inthis paper, we developed a novel multi-branch spatio-temporal graph neuralnetwork that used the GraphSAGE framework for spatio features learning and atemporal convolution operation to capture temporal changes, enabling differentbranches of the network to be more specialized and focusing on a singlelearning task. We found that our proposed multi-branch network can consistentlyoutperform the current fused spatio-temporal graph neural network in bothaccuracy and efficiency.</description>
      <author>example@mail.com (Zesheng Liu, Maryam Rahnemoonfar)</author>
      <guid isPermaLink="false">2411.04055v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>SPACE: 3D Spatial Co-operation and Exploration Framework for Robust Mapping and Coverage with Multi-Robot Systems</title>
      <link>http://arxiv.org/abs/2411.02524v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在室内环境中，多机器人视觉（RGB-D）映射与探索在家庭服务和物流等领域具有巨大潜力，多个机器人在同一环境中的部署可以显著提高效率。&lt;h4&gt;目的&lt;/h4&gt;解决由于机器人视角重叠导致的“鬼影轨迹”效应和在选择有效探索前沿时对视觉重建的忽视。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的半分布式框架（SPACE），通过几何技术（如“相互意识”和“动态机器人过滤器”）来克服空间映射限制，并引入了一种新颖的空间前沿检测系统及地图合并器。&lt;h4&gt;主要发现&lt;/h4&gt;在广泛的ROS-Gazebo模拟实验中，SPACE在探索和映射指标上表现优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;SPACE框架能够增强室内环境中的覆盖范围和3D映射效果，平衡探索和重建目标。&lt;h4&gt;总结&lt;/h4&gt;通过综合解决重叠视角问题和前沿选择的挑战，SPACE为多机器人系统在室内环境中的应用提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In indoor environments, multi-robot visual (RGB-D) mapping and explorationhold immense potential for application in domains such as domestic service andlogistics, where deploying multiple robots in the same environment cansignificantly enhance efficiency. However, there are two primary challenges:(1) the "ghosting trail" effect, which occurs due to overlapping views ofrobots impacting the accuracy and quality of point cloud reconstruction, and(2) the oversight of visual reconstructions in selecting the most effectivefrontiers for exploration. Given these challenges are interrelated, we addressthem together by proposing a new semi-distributed framework (SPACE) for spatialcooperation in indoor environments that enables enhanced coverage and 3Dmapping. SPACE leverages geometric techniques, including "mutual awareness" anda "dynamic robot filter," to overcome spatial mapping constraints.Additionally, we introduce a novel spatial frontier detection system and mapmerger, integrated with an adaptive frontier assigner for optimal coveragebalancing the exploration and reconstruction objectives. In extensiveROS-Gazebo simulations, SPACE demonstrated superior performance overstate-of-the-art approaches in both exploration and mapping metrics.</description>
      <author>example@mail.com (Sai Krishna Ghanta, Ramviyas Parasuraman)</author>
      <guid isPermaLink="false">2411.02524v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models</title>
      <link>http://arxiv.org/abs/2411.04075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的基准测试主要关注单文档、文本任务，但未能充分捕捉研究工作流程的复杂性，尤其是非文本数据的解释和多文档信息的收集。&lt;h4&gt;目的&lt;/h4&gt;提出M3SciQA，一个多模态、多文档的科学问答基准，以更全面地评估基础模型。&lt;h4&gt;方法&lt;/h4&gt;M3SciQA包含1452个专家注释的问题，涉及70个自然语言处理论文集群，每个集群代表一篇主要论文及其引用文献，模拟理解单篇论文的工作流程。&lt;h4&gt;主要发现&lt;/h4&gt;在多模态信息检索和跨多个科学文档推理方面，目前的基础模型显著低于人类专家的表现。&lt;h4&gt;结论&lt;/h4&gt;这些发现对未来基础模型在多模态科学文献分析中的应用进展具有重要意义。&lt;h4&gt;总结&lt;/h4&gt;M3SciQA为基础模型的评估提供了新的视角，强调了其在处理复杂研究任务时的不足。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing benchmarks for evaluating foundation models mainly focus onsingle-document, text-only tasks. However, they often fail to fully capture thecomplexity of research workflows, which typically involve interpretingnon-textual data and gathering information across multiple documents. Toaddress this gap, we introduce M3SciQA, a multi-modal, multi-documentscientific question answering benchmark designed for a more comprehensiveevaluation of foundation models. M3SciQA consists of 1,452 expert-annotatedquestions spanning 70 natural language processing paper clusters, where eachcluster represents a primary paper along with all its cited documents,mirroring the workflow of comprehending a single paper by requiring multi-modaland multi-document data. With M3SciQA, we conduct a comprehensive evaluation of18 foundation models. Our results indicate that current foundation models stillsignificantly underperform compared to human experts in multi-modal informationretrieval and in reasoning across multiple scientific documents. Additionally,we explore the implications of these findings for the future advancement ofapplying foundation models in multi-modal scientific literature analysis.</description>
      <author>example@mail.com (Chuhan Li, Ziyao Shangguan, Yilun Zhao, Deyuan Li, Yixin Liu, Arman Cohan)</author>
      <guid isPermaLink="false">2411.04075v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Learning General-Purpose Biomedical Volume Representations using Randomized Synthesis</title>
      <link>http://arxiv.org/abs/2411.02372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and model weights available at
  https://github.com/neel-dey/anatomix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的体积生物医学基础模型在推广方面存在困难，因为公开的3D数据集小且未能覆盖医学程序、病症、解剖区域和成像协议的广泛多样性。&lt;h4&gt;目的&lt;/h4&gt;通过创建一种表示学习方法，解决训练时预期的强领域变化问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种数据引擎，合成高度可变的训练样本，以实现对新的生物医学环境的推广；开发对比学习方法，预训练网络以抵御由数据引擎模拟的干扰成像变化。&lt;h4&gt;主要发现&lt;/h4&gt;该网络的特征可以用作输入图像的鲁棒表示，其权重为在新数据集上微调提供了强大且与数据集无关的初始化。&lt;h4&gt;结论&lt;/h4&gt;在多模态配准和少量样本分割方面设定了新的标准，这是任何3D生物医学视觉模型的首次成就，且无需在任何现有真实图像数据集上进行（预）训练。&lt;h4&gt;总结&lt;/h4&gt;通过创新的数据合成和对比学习方法，提升了3D生物医学模型的泛化能力，推动了相关领域的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/neel-dey/anatomix&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current volumetric biomedical foundation models struggle to generalize aspublic 3D datasets are small and do not cover the broad diversity of medicalprocedures, conditions, anatomical regions, and imaging protocols. We addressthis by creating a representation learning method that instead anticipatesstrong domain shifts at training time itself. We first propose a data enginethat synthesizes highly variable training samples that enable generalization tonew biomedical contexts. To then train a single 3D network for any voxel-leveltask, we develop a contrastive learning method that pretrains the network to bestable against nuisance imaging variation simulated by the data engine, a keyinductive bias for generalization. This network's features can be used asrobust representations of input images for downstream tasks and its weightsprovide a strong, dataset-agnostic initialization for finetuning on newdatasets. As a result, we set new standards across both multimodalityregistration and few-shot segmentation, a first for any 3D biomedical visionmodel, all without (pre-)training on any existing dataset of real images.</description>
      <author>example@mail.com (Neel Dey, Benjamin Billot, Hallee E. Wong, Clinton J. Wang, Mengwei Ren, P. Ellen Grant, Adrian V. Dalca, Polina Golland)</author>
      <guid isPermaLink="false">2411.02372v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Interaction-Aware Trajectory Prediction for Safe Motion Planning in Autonomous Driving: A Transformer-Transfer Learning Approach</title>
      <link>http://arxiv.org/abs/2411.01475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;安全和高效的自主车辆（AV）运动规划面临周围人类驾驶车辆（HDV）复杂和不确定行为的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于变压器和迁移学习的交互感知轨迹预测器，以改善自主驾驶的安全运动规划。&lt;h4&gt;方法&lt;/h4&gt;构建一个基于变压器的轨迹预测器，使用广泛可用的HDV轨迹数据集，并利用少量AV-HD交互数据进行迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;明确考虑交互和处理不确定性显著提升了运动规划的效果。&lt;h4&gt;结论&lt;/h4&gt;引入的不确定性量化方法能够更好地整合到AV的路径规划过程中，提升了对HDV行为的预测能力。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了在自主驾驶运动规划中考虑人类驾驶者行为交互的重要性，并提出了有效的方法来应对不确定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A critical aspect of safe and efficient motion planning for autonomousvehicles (AVs) is to handle the complex and uncertain behavior of surroundinghuman-driven vehicles (HDVs). Despite intensive research on driver behaviorprediction, existing approaches typically overlook the interactions between AVsand HDVs assuming that HDV trajectories are not affected by AV actions. Toaddress this gap, we present a transformer-transfer learning-basedinteraction-aware trajectory predictor for safe motion planning of autonomousdriving, focusing on a vehicle-to-vehicle (V2V) interaction scenario consistingof an AV and an HDV. Specifically, we construct a transformer-basedinteraction-aware trajectory predictor using widely available datasets of HDVtrajectory data and further transfer the learned predictor using a small set ofAV-HDV interaction data. Then, to better incorporate the proposed trajectorypredictor into the motion planning module of AVs, we introduce an uncertaintyquantification method to characterize the errors of the predictor, which areintegrated into the path-planning process. Our experimental results demonstratethe value of explicitly considering interactions and handling uncertainties.</description>
      <author>example@mail.com (Jinhao Liang, Chaopeng Tan, Longhao Yan, Jingyuan Zhou, Guodong Yin, Kaidi Yang)</author>
      <guid isPermaLink="false">2411.01475v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Toward Automated Algorithm Design: A Survey and Practical Guide to Meta-Black-Box-Optimization</title>
      <link>http://arxiv.org/abs/2411.00625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Meta-Black-Box-Optimization (MetaBBO) 是进化计算领域中的一种新兴方法，结合了元学习以辅助自动化算法设计。&lt;h4&gt;目的&lt;/h4&gt;提供MetaBBO的综合回顾，弥补现有文献在关键方面的不足，并提供实施的实际指导。&lt;h4&gt;方法&lt;/h4&gt;首先定义MetaBBO范式，然后系统分类不同的算法设计任务，包括算法选择、配置、解决方案操作和算法生成。&lt;h4&gt;主要发现&lt;/h4&gt;总结当前MetaBBO研究中不同的学习方法，包括强化学习、监督学习、神经进化和基于大型语言模型的上下文学习。&lt;h4&gt;结论&lt;/h4&gt;通过评估最新的MetaBBO方法，识别出增强MetaBBO泛化和学习有效性的核心设计。&lt;h4&gt;未来展望&lt;/h4&gt;提供对该领域最新趋势和潜在未来方向的洞见，并持续更新相关文献。&lt;h4&gt;总结&lt;/h4&gt;本文为MetaBBO的研究提供了全面的视角，旨在促进该领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/gmc-drl/awesome-metabbo&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this survey, we introduce Meta-Black-Box-Optimization (MetaBBO) as anemerging avenue within the Evolutionary Computation (EC) community, whichincorporates Meta-learning approaches to assist automated algorithm design.Despite the success of MetaBBO, the current literature provides insufficientsummaries of its key aspects and lacks practical guidance for implementation.To bridge this gap, we offer a comprehensive review of recent advances inMetaBBO, providing an in-depth examination of its key developments. We beginwith a unified definition of the MetaBBO paradigm, followed by a systematictaxonomy of various algorithm design tasks, including algorithm selection,algorithm configuration, solution manipulation, and algorithm generation.Further, we conceptually summarize different learning methodologies behindcurrent MetaBBO works, including reinforcement learning, supervised learning,neuroevolution, and in-context learning with Large Language Models. Acomprehensive evaluation of the latest representative MetaBBO methods is thencarried out, alongside an experimental analysis of their optimizationperformance, computational efficiency, and generalization ability. Based on theevaluation results, we meticulously identify a set of core designs that enhancethe generalization and learning effectiveness of MetaBBO. Finally, we outlinethe vision for the field by providing insight into the latest trends andpotential future directions. Relevant literature will be continuously collectedand updated at https://github.com/GMC-DRL/Awesome-MetaBBO.</description>
      <author>example@mail.com (Zeyuan Ma, Hongshu Guo, Yue-Jiao Gong, Jun Zhang, Kay Chen Tan)</author>
      <guid isPermaLink="false">2411.00625v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Content-Style Learning from Unaligned Domains: Identifiability under Unknown Latent Dimensions</title>
      <link>http://arxiv.org/abs/2411.03755v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;理解来自不对齐多领域数据的潜在内容和风格变量的可识别性对领域转换和数据生成等任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的分析框架，通过跨域潜在分布匹配（LDM）来建立内容-风格可识别性，条件更加宽松。&lt;h4&gt;方法&lt;/h4&gt;通过去除潜在变量的成分独立性等限制性假设，证明在适当施加稀疏性约束的情况下，无需先验知识即可确保可识别性。&lt;h4&gt;主要发现&lt;/h4&gt;分析表明，在无监督表示学习中，绕过确切潜在维度的知识是可行的，并且该分析首次理论上和实践上验证了这一点。&lt;h4&gt;结论&lt;/h4&gt;将LDM公式重新构造为带有耦合潜在变量的正则化多领域GAN损失，表明在轻微条件下，该重构与LDM等价，但计算资源需求显著减少。&lt;h4&gt;总结&lt;/h4&gt;实验结果支持了我们的理论主张，展示了新框架在多领域数据处理中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding identifiability of latent content and style variables fromunaligned multi-domain data is essential for tasks such as domain translationand data generation. Existing works on content-style identification were oftendeveloped under somewhat stringent conditions, e.g., that all latent componentsare mutually independent and that the dimensions of the content and stylevariables are known. We introduce a new analytical framework via cross-domain\textit{latent distribution matching} (LDM), which establishes content-styleidentifiability under substantially more relaxed conditions. Specifically, weshow that restrictive assumptions such as component-wise independence of thelatent variables can be removed. Most notably, we prove that prior knowledge ofthe content and style dimensions is not necessary for ensuring identifiability,if sparsity constraints are properly imposed onto the learned latentrepresentations. Bypassing the knowledge of the exact latent dimension has beena longstanding aspiration in unsupervised representation learning -- ouranalysis is the first to underpin its theoretical and practical viability. Onthe implementation side, we recast the LDM formulation into a regularizedmulti-domain GAN loss with coupled latent variables. We show that thereformulation is equivalent to LDM under mild conditions -- yet requiringconsiderably less computational resource. Experiments corroborate with ourtheoretical claims.</description>
      <author>example@mail.com (Sagar Shrestha, Xiao Fu)</author>
      <guid isPermaLink="false">2411.03755v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>EMMA: End-to-End Multimodal Model for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.23262v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Blog post: https://waymo.com/blog/2024/10/introducing-emma/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了EMMA，一个用于自主驾驶的端到端多模态模型。&lt;h4&gt;目的&lt;/h4&gt;将原始摄像头传感器数据映射为多种特定于驾驶的输出。&lt;h4&gt;方法&lt;/h4&gt;基于多模态大语言模型，使用自然语言文本表示非传感器输入和输出，联合处理多种驾驶任务。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes数据集上实现了运动规划的最新性能，并在Waymo开放运动数据集上取得了竞争性结果。&lt;h4&gt;结论&lt;/h4&gt;EMMA作为一个通用模型在自主驾驶应用中具有潜力，但存在处理图像帧数量有限、缺乏准确的3D传感器和计算成本高的问题。&lt;h4&gt;局限性&lt;/h4&gt;仅能处理少量图像帧，不支持LiDAR或雷达等精确3D传感器，且计算开销较大。&lt;h4&gt;未来研究&lt;/h4&gt;希望激励进一步研究以解决这些问题并推动自主驾驶模型架构的发展。&lt;h4&gt;总结&lt;/h4&gt;EMMA展示了多模态处理的潜力，但仍需改进以提升性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.Built on a multi-modal large language model foundation, EMMA directly maps rawcamera sensor data into various driving-specific outputs, including plannertrajectories, perception objects, and road graph elements. EMMA maximizes theutility of world knowledge from the pre-trained large language models, byrepresenting all non-sensor inputs (e.g. navigation instructions and egovehicle status) and outputs (e.g. trajectories and 3D locations) as naturallanguage text. This approach allows EMMA to jointly process various drivingtasks in a unified language space, and generate the outputs for each task usingtask-specific prompts. Empirically, we demonstrate EMMA's effectiveness byachieving state-of-the-art performance in motion planning on nuScenes as wellas competitive results on the Waymo Open Motion Dataset (WOMD). EMMA alsoyields competitive results for camera-primary 3D object detection on the WaymoOpen Dataset (WOD). We show that co-training EMMA with planner trajectories,object detection, and road graph tasks yields improvements across all threedomains, highlighting EMMA's potential as a generalist model for autonomousdriving applications. However, EMMA also exhibits certain limitations: it canprocess only a small amount of image frames, does not incorporate accurate 3Dsensing modalities like LiDAR or radar and is computationally expensive. Wehope that our results will inspire further research to mitigate these issuesand to further evolve the state of the art in autonomous driving modelarchitectures.</description>
      <author>example@mail.com (Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, Yin Zhou, James Guo, Dragomir Anguelov, Mingxing Tan)</author>
      <guid isPermaLink="false">2410.23262v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Age of Information-Oriented Probabilistic Link Scheduling for Device-to-Device Networks</title>
      <link>http://arxiv.org/abs/2410.20196v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures, accepted by IEEE WiOpt24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文关注通过年龄感知的链路调度来优化设备间（D2D）网络中的信息长期平均年龄（AoI）。&lt;h4&gt;目的&lt;/h4&gt;解决由于所有D2D链路的AoI动态相互交织而导致的最优策略寻找困难的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种年龄感知的静态随机策略，依据所有链路的AoI和统计信道状态信息确定每个时间槽中调度每个链路的概率，并运用Lyapunov优化框架来最小化每个时间槽的Lyapunov漂移。&lt;h4&gt;主要发现&lt;/h4&gt;尽管每个时间槽的最小化问题因D2D网络中的交叉链路干扰而非凸，分析了最优解的置换等变性特性，使用了消息传递神经网络（MPNN）来在无监督学习的方式下优化每个时间槽的问题。&lt;h4&gt;结论&lt;/h4&gt;仿真结果表明，所提年龄感知的静态随机策略优于基线方法，验证了我们方法的可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本研究为D2D网络中的信息调度提供了一种有效的年龄感知优化策略，具有良好的性能和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper focuses on optimizing the long-term average age of information(AoI) in device-to-device (D2D) networks through age-aware link scheduling. Theproblem is naturally formulated as a Markov decision process (MDP). However,finding the optimal policy for the formulated MDP in its original form ischallenging due to the intertwined AoI dynamics of all D2D links. To addressthis, we propose an age-aware stationary randomized policy that determines theprobability of scheduling each link in each time slot based on the AoI of alllinks and the statistical channel state information among all transceivers. Byemploying the Lyapunov optimization framework, our policy aims to minimize theLyapunov drift in every time slot. Nonetheless, this per-slot minimizationproblem is nonconvex due to cross-link interference in D2D networks, posingsignificant challenges for real-time decision-making. After analyzing thepermutation equivariance property of the optimal solutions to the per-slotproblem, we apply a message passing neural network (MPNN), a type of graphneural network that also exhibits permutation equivariance, to optimize theper-slot problem in an unsupervised learning manner. Simulation resultsdemonstrate the superior performance of the proposed age-aware stationaryrandomized policy over baselines and validate the scalability of our method.</description>
      <author>example@mail.com (Lixin Wang, Qian Wang, He Chen, Shidong Zhou)</author>
      <guid isPermaLink="false">2410.20196v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised 3D Point Cloud Completion via Multi-view Adversarial Learning</title>
      <link>http://arxiv.org/abs/2407.09786v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages,10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现实场景中的扫描点云通常因遮挡问题而不完整。&lt;h4&gt;目的&lt;/h4&gt;进行自监督点云补全，重建缺失区域，而无需完整的真实数据作为监督。&lt;h4&gt;方法&lt;/h4&gt;提出了MAL-SPC框架，有效利用物体级和类别特定的几何相似性来补全缺失结构。使用模式检索网络获取部分输入与预测形状之间的相似位置和曲率模式，并利用这些相似性来密集和细化重建结果。&lt;h4&gt;主要发现&lt;/h4&gt;MAL-SPC在当前最先进的方法中表现最佳。&lt;h4&gt;结论&lt;/h4&gt;MAL-SPC无需任何3D完整监督，仅需每个对象的一幅部分点云，并通过多视图深度图进行几何学习。&lt;h4&gt;总结&lt;/h4&gt;该框架通过密度感知半径估计算法提高渲染图像质量，并将在GitHub上公开源代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-07-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ltwu6/malspc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world scenarios, scanned point clouds are often incomplete due toocclusion issues. The task of self-supervised point cloud completion involvesreconstructing missing regions of these incomplete objects without thesupervision of complete ground truth. Current self-supervised methods eitherrely on multiple views of partial observations for supervision or overlook theintrinsic geometric similarity that can be identified and utilized from thegiven partial point clouds. In this paper, we propose MAL-SPC, a framework thateffectively leverages both object-level and category-specific geometricsimilarities to complete missing structures. Our MAL-SPC does not require any3D complete supervision and only necessitates a single partial point cloud foreach object. Specifically, we first introduce a Pattern Retrieval Network toretrieve similar position and curvature patterns between the partial input andthe predicted shape, then leverage these similarities to densify and refine thereconstructed results. Additionally, we render the reconstructed complete shapeinto multi-view depth maps and design an adversarial learning module to learnthe geometry of the target shape from category-specific single-view depthimages. To achieve anisotropic rendering, we design a density-aware radiusestimation algorithm to improve the quality of the rendered images. Our MAL-SPCyields the best results compared to current state-of-the-art methods.We willmake the source code publicly available at \url{https://github.com/ltwu6/malspc</description>
      <author>example@mail.com (Lintai Wu, Xianjing Cheng, Yong Xu, Huanqiang Zeng, Junhui Hou)</author>
      <guid isPermaLink="false">2407.09786v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Graph neural networks and non-commuting operators</title>
      <link>http://arxiv.org/abs/2411.04265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在多种任务中表现出色，通常涉及预测图中节点的特征。&lt;h4&gt;目的&lt;/h4&gt;探讨多个图具有相同顶点集和共同顶点级学习任务的情境，推广标准GNN模型。&lt;h4&gt;方法&lt;/h4&gt;提出图元神经网络（GtNN），发展关于非交换非扩展算子的数学理论，以研究GtNN的稳定性和可迁移性。&lt;h4&gt;主要发现&lt;/h4&gt;证明了所有图元神经网络在收敛的图元序列上是可迁移的，并且在考虑的收敛下没有不可迁移的能量。&lt;h4&gt;结论&lt;/h4&gt;理论结果扩展了GNN的已知可迁移性定理，并在GNN的情况下提供了严格的改进。&lt;h4&gt;实验&lt;/h4&gt;通过简单的合成和真实数据实验来验证理论结果，并推导出一种可证明稳定性的训练程序。&lt;h4&gt;总结&lt;/h4&gt;该研究为图元神经网络的理论基础提供了支持，并显示了其在多个图任务中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/kkylie/gtnn_weighted_circulant_graphs&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) provide state-of-the-art results in a widevariety of tasks which typically involve predicting features at the vertices ofa graph. They are built from layers of graph convolutions which serve as apowerful inductive bias for describing the flow of information among thevertices. Often, more than one data modality is available. This work considersa setting in which several graphs have the same vertex set and a commonvertex-level learning task. This generalizes standard GNN models to GNNs withseveral graph operators that do not commute. We may call this model graph-tupleneural networks (GtNN).  In this work, we develop the mathematical theory to address the stability andtransferability of GtNNs using properties of non-commuting non-expansiveoperators. We develop a limit theory of graphon-tuple neural networks and useit to prove a universal transferability theorem that guarantees that allgraph-tuple neural networks are transferable on convergent graph-tuplesequences. In particular, there is no non-transferable energy under theconvergence we consider here. Our theoretical results extend well-knowntransferability theorems for GNNs to the case of several simultaneous graphs(GtNNs) and provide a strict improvement on what is currently known even in theGNN case.  We illustrate our theoretical results with simple experiments on syntheticand real-world data. To this end, we derive a training procedure that provablyenforces the stability of the resulting model.</description>
      <author>example@mail.com (Mauricio Velasco, Kaiying O'Hare, Bernardo Rychtenberg, Soledad Villar)</author>
      <guid isPermaLink="false">2411.04265v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Fine Grained Insider Risk Detection</title>
      <link>http://arxiv.org/abs/2411.02645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种方法来检测支持人员在业务合理工作流程中的偏离。&lt;h4&gt;目的&lt;/h4&gt;帮助审计员识别无法通过周围活动解释的代理行为。&lt;h4&gt;方法&lt;/h4&gt;收集支持代理使用的工具日志，构建行为与实体的二分图，并从中提取以安全相关行为为根节点的子图。&lt;h4&gt;主要发现&lt;/h4&gt;通过优先排序根子图，使用前馈和图神经网络，以及最近邻技术，发现值得审计的子图。&lt;h4&gt;结论&lt;/h4&gt;该系统以足够高的精度找到值得审计的子图，适合生产使用。&lt;h4&gt;总结&lt;/h4&gt;通过对历史数据的分析和对审计员的支持，优化了审计流程并提高了效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a method to detect departures from business-justified workflowsamong support agents. Our goal is to assist auditors in identifying agentactions that cannot be explained by the activity within their surroundingcontext, where normal activity patterns are established from historical data.We apply our method to help audit millions of actions of over three thousandsupport agents.  We collect logs from the tools used by support agents and construct abipartite graph of Actions and Entities representing all the actions of theagents, as well as background information about entities. From this graph, wesample subgraphs rooted on security-significant actions taken by the agents.Each subgraph captures the relevant context of the root action in terms ofother actions, entities and their relationships. We then prioritize therooted-subgraphs for auditor review using feed-forward and graph neuralnetworks, as well as nearest neighbors techniques. To alleviate the issue ofscarce labeling data, we use contrastive learning and domain-specific dataaugmentations.  Expert auditors label the top ranked subgraphs as ``worth auditing" or ``notworth auditing" based on the company's business policies. This system findssubgraphs that are worth auditing with high enough precision to be used inproduction.</description>
      <author>example@mail.com (Birkett Huber, Casper Neo, Keiran Sampson, Alex Kantchelian, Brett Ksobiech, Yanis Pavlidis)</author>
      <guid isPermaLink="false">2411.02645v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Tracking Tumors under Deformation from Partial Point Clouds using Occupancy Networks</title>
      <link>http://arxiv.org/abs/2411.02619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;手术中通过术前CT扫描信息来追踪肿瘤位置，但肿瘤在手术过程中可能变形，这影响了切除的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于占用网络的方法，以在变形的肾脏模型中实时定位肿瘤。&lt;h4&gt;方法&lt;/h4&gt;使用嵌入外生性和内生性肾肿瘤的3D水凝胶肾脏模型，模拟真实组织力学，验证方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够在中等变形的肾脏中定位肿瘤，边缘误差为6mm至10mm，并以超过60Hz的频率提供重要的体积3D信息。&lt;h4&gt;结论&lt;/h4&gt;该能力直接支持后续的机器人切除等任务。&lt;h4&gt;总结&lt;/h4&gt;提出的方法为手术中肾脏肿瘤的实时定位提供了新的解决方案，提升了手术的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To track tumors during surgery, information from preoperative CT scans isused to determine their position. However, as the surgeon operates, the tumormay be deformed which presents a major hurdle for accurately resecting thetumor, and can lead to surgical inaccuracy, increased operation time, andexcessive margins. This issue is particularly pronounced in robot-assistedpartial nephrectomy (RAPN), where the kidney undergoes significant deformationsduring operation. Toward addressing this, we introduce a occupancynetwork-based method for the localization of tumors within kidney phantomsundergoing deformations at interactive speeds. We validate our method byintroducing a 3D hydrogel kidney phantom embedded with exophytic and endophyticrenal tumors. It closely mimics real tissue mechanics to simulate kidneydeformation during in vivo surgery, providing excellent contrast and cleardelineation of tumor margins to enable automatic threshold-based segmentation.Our findings indicate that the proposed method can localize tumors inmoderately deforming kidneys with a margin of 6mm to 10mm, while providingessential volumetric 3D information at over 60Hz. This capability directlyenables downstream tasks such as robotic resection.</description>
      <author>example@mail.com (Pit Henrich, Jiawei Liu, Jiawei Ge, Samuel Schmidgall, Lauren Shepard, Ahmed Ezzat Ghazi, Franziska Mathis-Ullrich, Axel Krieger)</author>
      <guid isPermaLink="false">2411.02619v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>V-CAS: A Realtime Vehicle Anti Collision System Using Vision Transformer on Multi-Camera Streams</title>
      <link>http://arxiv.org/abs/2411.01963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICMLA 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种实时车辆碰撞避免系统（V-CAS），旨在通过环境感知增强车辆安全。&lt;h4&gt;目的&lt;/h4&gt;通过自适应制动机制来降低碰撞风险。&lt;h4&gt;方法&lt;/h4&gt;V-CAS结合了RT-DETR视觉模型、DeepSORT跟踪、速度估计、刹车灯检测和自适应制动机制，计算综合碰撞风险评分。&lt;h4&gt;主要发现&lt;/h4&gt;系统在YouTube的车辆碰撞数据集（CCD）上实现了超过98%的准确率，平均主动警报时间为1.13秒。&lt;h4&gt;结论&lt;/h4&gt;低成本的多摄像头嵌入式视觉变换系统在提升环境感知和主动碰撞避免机制方面具有潜力，显著优于传统单摄像头方法。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了利用先进的感知技术和实时评估机制提升汽车安全的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a real-time Vehicle Collision Avoidance System (V-CAS)designed to enhance vehicle safety through adaptive braking based onenvironmental perception. V-CAS leverages the advanced vision-based transformermodel RT-DETR, DeepSORT tracking, speed estimation, brake light detection, andan adaptive braking mechanism. It computes a composite collision risk scorebased on vehicles' relative accelerations, distances, and detected brakingactions, using brake light signals and trajectory data from multiple camerastreams to improve scene perception. Implemented on the Jetson Orin Nano, V-CASenables real-time collision risk assessment and proactive mitigation throughadaptive braking. A comprehensive training process was conducted on variousdatasets for comparative analysis, followed by fine-tuning the selected objectdetection model using transfer learning. The system's effectiveness wasrigorously evaluated on the Car Crash Dataset (CCD) from YouTube and throughreal-time experiments, achieving over 98% accuracy with an average proactivealert time of 1.13 seconds. Results indicate significant improvements in objectdetection and tracking, enhancing collision avoidance compared to traditionalsingle-camera methods. This research demonstrates the potential of low-cost,multi-camera embedded vision transformer systems to advance automotive safetythrough enhanced environmental perception and proactive collision avoidancemechanisms.</description>
      <author>example@mail.com (Muhammad Waqas Ashraf, Ali Hassan, Imad Ali Shah)</author>
      <guid isPermaLink="false">2411.01963v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?</title>
      <link>http://arxiv.org/abs/2411.04118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to EMNLP 2024 Main Conference as Long Paper (Oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;最近的研究致力于为医疗应用开发基础模型，通过在公开的生物医学语料库上进行持续预训练，调整通用大型语言模型（LLMs）和视觉语言模型（VLMs）。&lt;h4&gt;目的&lt;/h4&gt;比较七个公共“医疗”LLM和两个VLM与其基础模型的表现，以评估领域适应性预训练（DAPT）对下游医疗任务的影响。&lt;h4&gt;方法&lt;/h4&gt;通过逐一比较每个医疗模型与相应的基础模型，优化每个模型的提示，并考虑比较中的统计不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;在医疗问答（QA）任务的零/少样本提示下，所有医疗VLM和几乎所有医疗LLM在表现上未能持续优于基础模型。在3-shot设置下，医疗LLM仅在12.1%的情况下超过基础模型，49.8%的情况下打成平局，38.2%的情况下显著劣于基础模型。&lt;h4&gt;结论&lt;/h4&gt;当前的通用领域模型可能已经具备较强的医疗知识和推理能力，研究建议为未来的研究提供更强的结论支持。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，医疗模型的改进效果并不如预期，强调了优化比较方法的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Several recent works seek to develop foundation models specifically formedical applications, adapting general-purpose large language models (LLMs) andvision-language models (VLMs) via continued pretraining on publicly availablebiomedical corpora. These works typically claim that such domain-adaptivepretraining (DAPT) improves performance on downstream medical tasks, such asanswering medical licensing exam questions. In this paper, we compare sevenpublic "medical" LLMs and two VLMs against their corresponding base models,arriving at a different conclusion: all medical VLMs and nearly all medicalLLMs fail to consistently improve over their base models in the zero-/few-shotprompting regime for medical question-answering (QA) tasks. For instance,across the tasks and model pairs we consider in the 3-shot setting, medicalLLMs only outperform their base models in 12.1% of cases, reach a (statistical)tie in 49.8% of cases, and are significantly worse than their base models inthe remaining 38.2% of cases. Our conclusions are based on (i) comparing eachmedical model head-to-head, directly against the corresponding base model; (ii)optimizing the prompts for each model separately; and (iii) accounting forstatistical uncertainty in comparisons. While these basic practices are notconsistently adopted in the literature, our ablations show that theysubstantially impact conclusions. Our findings suggest that state-of-the-artgeneral-domain models may already exhibit strong medical knowledge andreasoning capabilities, and offer recommendations to strengthen the conclusionsof future studies.</description>
      <author>example@mail.com (Daniel P. Jeong, Saurabh Garg, Zachary C. Lipton, Michael Oberst)</author>
      <guid isPermaLink="false">2411.04118v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Task-Aware Harmony Multi-Task Decision Transformer for Offline Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2411.01146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Extension of corresponding ICML edition arXiv:2405.18080. arXiv admin
  note: substantial text overlap with arXiv:2405.18080&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;离线多任务强化学习(MTRL)旨在开发一个统一的策略，适用于多样任务，而无需在线环境交互。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，识别每个任务的最佳和谐参数子空间，以优化策略性能。&lt;h4&gt;方法&lt;/h4&gt;引入和谐多任务决策变换器(HarmoDT)，将其作为一个双层优化问题，利用元学习框架进行参数更新，同时设计了基于梯度信息的任务聚类变体(G-HarmoDT)。&lt;h4&gt;主要发现&lt;/h4&gt;在各种基准测试中，我们的方法表现优越，在特定任务设置中提高了8%，在任务无关设置中提高了5%，在未见设置中提高了10%。&lt;h4&gt;结论&lt;/h4&gt;HarmoDT及其变体有效地解决了多任务环境中的参数共享和任务识别问题，具有较好的实际应用潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种新的多任务学习框架，通过优化参数子空间，提高了离线多任务强化学习的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/charleshsc/HarmoDT&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The purpose of offline multi-task reinforcement learning (MTRL) is to developa unified policy applicable to diverse tasks without the need for onlineenvironmental interaction. Recent advancements approach this through sequencemodeling, leveraging the Transformer architecture's scalability and thebenefits of parameter sharing to exploit task similarities. However, variationsin task content and complexity pose significant challenges in policyformulation, necessitating judicious parameter sharing and management ofconflicting gradients for optimal policy performance. Furthermore, identifyingthe optimal parameter subspace for each task often necessitates prior knowledgeof the task identifier during inference, limiting applicability in real-worldscenarios with variable task content and unknown current tasks. In this work,we introduce the Harmony Multi-Task Decision Transformer (HarmoDT), a novelsolution designed to identify an optimal harmony subspace of parameters foreach task. We formulate this as a bi-level optimization problem within ameta-learning framework, where the upper level learns masks to define theharmony subspace, while the inner level focuses on updating parameters toimprove the overall performance of the unified policy. To eliminate the needfor task identifiers, we further design a group-wise variant (G-HarmoDT) thatclusters tasks into coherent groups based on gradient information, and utilizesa gating network to determine task identifiers during inference. Empiricalevaluations across various benchmarks highlight the superiority of ourapproach, demonstrating its effectiveness in the multi-task context withspecific improvements of 8% gain in task-provided settings, 5% in task-agnosticsettings, and 10% in unseen settings.</description>
      <author>example@mail.com (Ziqing Fan, Shengchao Hu, Yuhang Zhou, Li Shen, Ya Zhang, Yanfeng Wang, Dacheng Tao)</author>
      <guid isPermaLink="false">2411.01146v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Message Passing Architecture for GCN Training on HBM-based FPGAs with Orthogonal Topology On-Chip Networks</title>
      <link>http://arxiv.org/abs/2411.03857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for 2024 ACM/SIGDA International
  Symposium on Field Programmable Gate Arrays(FPGA'24) as poster&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图卷积网络（GCNs）是用于图形表示学习的先进深度学习模型，但其高效训练受限于内存容量和带宽。&lt;h4&gt;目的&lt;/h4&gt;解决GCNs训练中的内存和带宽限制问题，以及不规则的数据流导致的通信瓶颈。&lt;h4&gt;方法&lt;/h4&gt;提出了一种消息传递架构，利用基于NUMA的内存访问特性，并在加速器中采用基于4维超立方体网络的并行多播路由算法进行高效消息传递。同时，重新设计了GCNs的反向传播算法以减轻内存需求和计算开销。&lt;h4&gt;主要发现&lt;/h4&gt;与先进的HP-GNN架构相比，性能提升在1.03倍至1.81倍之间。&lt;h4&gt;结论&lt;/h4&gt;通过提出的架构和算法改进，实现了GCNs训练过程中的效率提升。&lt;h4&gt;总结&lt;/h4&gt;该研究为GCNs在训练中的性能优化提供了一种有效的解决方案，改善了内存和计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Convolutional Networks (GCNs) are state-of-the-art deep learning modelsfor representation learning on graphs. However, the efficient training of GCNsis hampered by constraints in memory capacity and bandwidth, compounded by theirregular data flow that results in communication bottlenecks. To address thesechallenges, we propose a message-passing architecture that leverages NUMA-basedmemory access properties and employs a parallel multicast routing algorithmbased on a 4-D hypercube network within the accelerator for efficient messagepassing in graphs. Additionally, we have re-engineered the backpropagationalgorithm specific to GCNs within our proposed accelerator. This redesignstrategically mitigates the memory demands prevalent during the training phaseand diminishes the computational overhead associated with the transposition ofextensive matrices. Compared to the state-of-the-art HP-GNN architecture weachieved a performance improvement of $1.03\times \sim 1.81\times$.</description>
      <author>example@mail.com (Qizhe Wu, Letian Zhao, Yuchen Gui, Huawen Liang Xiaotian Wang)</author>
      <guid isPermaLink="false">2411.03857v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>GaGSL: Global-augmented Graph Structure Learning via Graph Information Bottleneck</title>
      <link>http://arxiv.org/abs/2411.04356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络 (GNNs) 在处理图数据的半监督节点分类任务中具有显著的效果，但大多数研究假设观察到的图结构准确代表了潜在的节点关系。&lt;h4&gt;目的&lt;/h4&gt;学习一个干净的图结构，以平衡性能和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新方法，称为全球增强图结构学习 (GaGSL)，该方法遵循图信息瓶颈 (GIB) 原则。通过全局特征增强和全局结构增强获取增强特征和增强结构，输入结构估计器进行优化和图结构重新定义。&lt;h4&gt;主要发现&lt;/h4&gt;GaGSL在多个数据集上的综合评估表明，其性能和鲁棒性优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;GaGSL能够有效地获取最小充分的图结构，提升节点分类任务的表现。&lt;h4&gt;总结&lt;/h4&gt;GaGSL通过优化图结构，解决了现实中图结构噪声或不完整的问题，展示了其在图神经网络领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are prominent for their effectiveness inprocessing graph data for semi-supervised node classification tasks. Most worksof GNNs assume that the observed structure accurately represents the underlyingnode relationships. However, the graph structure is inevitably noisy orincomplete in reality, which can degrade the quality of graph representations.Therefore, it is imperative to learn a clean graph structure that balancesperformance and robustness. In this paper, we propose a novel method named\textit{Global-augmented Graph Structure Learning} (GaGSL), guided by the GraphInformation Bottleneck (GIB) principle. The key idea behind GaGSL is to learn acompact and informative graph structure for node classification tasks.Specifically, to mitigate the bias caused by relying solely on the originalstructure, we first obtain augmented features and augmented structure throughglobal feature augmentation and global structure augmentation. We then inputthe augmented features and augmented structure into a structure estimator withdifferent parameters for optimization and re-definition of the graph structure,respectively. The redefined structures are combined to form the final graphstructure. Finally, we employ GIB based on mutual information to guide theoptimization of the graph structure to obtain the minimum sufficient graphstructure. Comprehensive evaluations across a range of datasets reveal theoutstanding performance and robustness of GaGSL compared with thestate-of-the-art methods.</description>
      <author>example@mail.com (Shuangjie Li, Jiangqing Song, Baoming Zhang, Gaoli Ruan, Junyuan Xie, Chongjun Wang)</author>
      <guid isPermaLink="false">2411.04356v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>On the Comparison between Multi-modal and Single-modal Contrastive Learning</title>
      <link>http://arxiv.org/abs/2411.02837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  51pages, 1 figure, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态对比学习结合语言监督在现代机器学习中引发了范式转变。&lt;h4&gt;目的&lt;/h4&gt;提供一个理论框架，以理解多模态与单模态对比学习之间的差异。&lt;h4&gt;方法&lt;/h4&gt;基于信号和噪声的数据生成模型，分析在使用InfoMax目标函数训练的ReLU网络上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;信号与噪声比(SNR)是影响多模态和单模态对比学习在下游任务中可泛化性的关键因素。&lt;h4&gt;结论&lt;/h4&gt;多模态学习通过模态间的协作实现更好的特征学习，提升下游任务的性能，相较于单模态学习。&lt;h4&gt;总结&lt;/h4&gt;本分析提供了一个统一框架，能够表征单模态和多模态对比学习的优化与泛化，并通过实证实验进一步验证了理论发现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal contrastive learning with language supervision has presented aparadigm shift in modern machine learning. By pre-training on a web-scaledataset, multi-modal contrastive learning can learn high-qualityrepresentations that exhibit impressive robustness and transferability. Despiteits empirical success, the theoretical understanding is still in its infancy,especially regarding its comparison with single-modal contrastive learning. Inthis work, we introduce a feature learning theory framework that provides atheoretical foundation for understanding the differences between multi-modaland single-modal contrastive learning. Based on a data generation modelconsisting of signal and noise, our analysis is performed on a ReLU networktrained with the InfoMax objective function. Through a trajectory-basedoptimization analysis and generalization characterization on downstream tasks,we identify the critical factor, which is the signal-to-noise ratio (SNR), thatimpacts the generalizability in downstream tasks of both multi-modal andsingle-modal contrastive learning. Through the cooperation between the twomodalities, multi-modal learning can achieve better feature learning, leadingto improvements in performance in downstream tasks compared to single-modallearning. Our analysis provides a unified framework that can characterize theoptimization and generalization of both single-modal and multi-modalcontrastive learning. Empirical experiments on both synthetic and real-worlddatasets further consolidate our theoretical findings.</description>
      <author>example@mail.com (Wei Huang, Andi Han, Yongqiang Chen, Yuan Cao, Zhiqiang Xu, Taiji Suzuki)</author>
      <guid isPermaLink="false">2411.02837v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Galaxy Formation and Evolution via Phase-temporal Clustering with FuzzyCat $\circ$ AstroLink</title>
      <link>http://arxiv.org/abs/2411.03229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the NeurIPS 2024 Machine Learning and the Physical
  Sciences workshop. 9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文展示了两种无监督聚类算法的组合，AstroLink和FuzzyCat，在研究星系形成和演化中的应用。&lt;h4&gt;目的&lt;/h4&gt;利用AstroLink和FuzzyCat的组合，识别点云数据中的模糊层次结构。&lt;h4&gt;方法&lt;/h4&gt;AstroLink是一种通用的天体物理聚类算法，旨在从任何特征空间定义的点云数据中提取有意义的层次结构；FuzzyCat是一个推广的软聚类算法，将底层数据过程的动态效应传播到一个稳定的模糊聚类层次中。&lt;h4&gt;主要发现&lt;/h4&gt;通过FuzzyCat和AstroLink的组合，可以识别出在任何点数据集中具有天体物理和统计显著性的模糊聚类。&lt;h4&gt;结论&lt;/h4&gt;该方法在结构分解模拟星系方面具有显著影响，增强了提取结构的多样性和完整性，揭示了不同类型的天体结构。&lt;h4&gt;总结&lt;/h4&gt;该管道不依赖于强假设，适用于物理科学的广泛领域，具有良好的适应性和应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We demonstrate how the composition of two unsupervised clustering algorithms,$\texttt{AstroLink}$ and $\texttt{FuzzyCat}$, makes for a powerful tool whenstudying galaxy formation and evolution. $\texttt{AstroLink}$ is ageneral-purpose astrophysical clustering algorithm built for extractingmeaningful hierarchical structure from point-cloud data defined over anyfeature space, while $\texttt{FuzzyCat}$ is a generalised soft-clusteringalgorithm that propagates the dynamical effects of underlying data processesinto a fuzzy hierarchy of stable fuzzy clusters. Their composition,$\texttt{FuzzyCat}$ $\circ$ $\texttt{AstroLink}$, can therefore identify afuzzy hierarchy of astrophysically- and statistically-significant fuzzyclusters within any point-based data set whose representation is subject tochanges caused by some underlying process. Furthermore, the pipeline achievesthis without relying upon strong assumptions about the data, the changeprocess, the number/importance of specific structure types, or much user input-- thereby making itself applicable to a wide range of fields in the physicalsciences. We find that for the task of structurally decomposing simulatedgalaxies into their constituents, our context-agnostic approach has asubstantial impact on the diversity and completeness of the structuresextracted as well as on their relationship within the broader galacticstructural hierarchy -- revealing dwarf galaxies, infalling groups, stellarstreams (and their progenitors), stellar shells, galactic bulges, andstar-forming regions.</description>
      <author>example@mail.com (William H. Oliver, Tobias Buck)</author>
      <guid isPermaLink="false">2411.03229v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DiMSUM: Diffusion Mamba -- A Scalable and Unified Spatial-Frequency Method for Image Generation</title>
      <link>http://arxiv.org/abs/2411.04168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024. Project page:
  https://hao-pt.github.io/dimsum/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;引入了一种新颖的状态空间架构用于扩散模型，有效利用空间和频率信息，以增强对输入图像局部特征的归纳偏见。&lt;h4&gt;目的&lt;/h4&gt;优化图像生成任务中对输入图像细节和整体质量的处理。&lt;h4&gt;方法&lt;/h4&gt;将小波变换集成到Mamba中，增强视觉输入的局部结构意识，并通过交叉注意力融合层将小波输出与原始Mamba输出无缝结合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在标准基准测试中表现优越，相较于DiT和DIFFUSSM，训练收敛速度更快且输出质量更高。&lt;h4&gt;结论&lt;/h4&gt;通过引入全球共享的变换器，进一步提升了Mamba的性能，充分捕捉全局关系。&lt;h4&gt;代码和模型&lt;/h4&gt;在https://github.com/VinAIResearch/DiMSUM.git上发布了代码和预训练模型。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种结合空间和频率信息的新方法，显著增强了图像生成任务的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel state-space architecture for diffusion models,effectively harnessing spatial and frequency information to enhance theinductive bias towards local features in input images for image generationtasks. While state-space networks, including Mamba, a revolutionary advancementin recurrent neural networks, typically scan input sequences from left toright, they face difficulties in designing effective scanning strategies,especially in the processing of image data. Our method demonstrates thatintegrating wavelet transformation into Mamba enhances the local structureawareness of visual inputs and better captures long-range relations offrequencies by disentangling them into wavelet subbands, representing both low-and high-frequency components. These wavelet-based outputs are then processedand seamlessly fused with the original Mamba outputs through a cross-attentionfusion layer, combining both spatial and frequency information to optimize theorder awareness of state-space models which is essential for the details andoverall quality of image generation. Besides, we introduce a globally-sharedtransformer to supercharge the performance of Mamba, harnessing its exceptionalpower to capture global relationships. Through extensive experiments onstandard benchmarks, our method demonstrates superior results compared to DiTand DIFFUSSM, achieving faster training convergence and delivering high-qualityoutputs. The codes and pretrained models are released athttps://github.com/VinAIResearch/DiMSUM.git.</description>
      <author>example@mail.com (Hao Phung, Quan Dao, Trung Dao, Hoang Phan, Dimitris Metaxas, Anh Tran)</author>
      <guid isPermaLink="false">2411.04168v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Finetuning Large Language Models</title>
      <link>http://arxiv.org/abs/2411.01195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024 Workshop on Adaptive Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大语言模型的应用范围不断扩大，针对特定任务的高效微调变得愈加重要。同时，参数高效微调方法也迅速增加。&lt;h4&gt;目的&lt;/h4&gt;减少实践者在为大语言模型寻找最佳微调流程时的复杂选择。&lt;h4&gt;方法&lt;/h4&gt;通过迁移学习对大语言模型进行微调，借助相关微调任务的配置知识转移到新任务，使用灰箱元优化的性能和成本代理模型进行元学习。&lt;h4&gt;主要发现&lt;/h4&gt;提出仅依赖迁移学习来处理新数据集，而不使用任务特定的贝叶斯优化，优先考虑从相关任务转移的知识。&lt;h4&gt;结论&lt;/h4&gt;在八个合成问答数据集和一个包含1,800次微调运行的元数据集上评估的方法优于零样本、默认微调和元优化基线。结果表明，微调的可迁移性能够更有效地适应大语言模型。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过迁移学习提高大语言模型适应性的有效性，简化了微调过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the landscape of large language models expands, efficiently finetuning forspecific tasks becomes increasingly crucial. At the same time, the landscape ofparameter-efficient finetuning methods rapidly expands. Consequently,practitioners face a multitude of complex choices when searching for an optimalfinetuning pipeline for large language models. To reduce the complexity forpractitioners, we investigate transfer learning for finetuning large languagemodels and aim to transfer knowledge about configurations from relatedfinetuning tasks to a new task. In this work, we transfer learn finetuning bymeta-learning performance and cost surrogate models for grey-boxmeta-optimization from a new meta-dataset. Counter-intuitively, we propose torely only on transfer learning for new datasets. Thus, we do not usetask-specific Bayesian optimization but prioritize knowledge transferred fromrelated tasks over task-specific feedback. We evaluate our method on eightsynthetic question-answer datasets and a meta-dataset consisting of 1,800 runsof finetuning Microsoft's Phi-3. Our transfer learning is superior tozero-shot, default finetuning, and meta-optimization baselines. Our resultsdemonstrate the transferability of finetuning to adapt large language modelsmore effectively.</description>
      <author>example@mail.com (Tobias Strangmann, Lennart Purucker, Jörg K. H. Franke, Ivo Rapant, Fabio Ferreira, Frank Hutter)</author>
      <guid isPermaLink="false">2411.01195v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>EEG-based Multimodal Representation Learning for Emotion Recognition</title>
      <link>http://arxiv.org/abs/2411.00822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态学习是一个热门研究领域，但整合脑电图（EEG）数据面临独特挑战，主要由于其固有的变异性和有限的可用性。&lt;h4&gt;目的&lt;/h4&gt;提出一个新颖的多模态框架，能够处理视频、图像、音频等传统模态，并整合EEG数据。&lt;h4&gt;方法&lt;/h4&gt;框架灵活处理不同输入大小，动态调整注意力以考虑各模态特征的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;在一个新近推出的情感识别数据集上评估了该方法，数据集结合了三种模态，成为多模态学习的理想测试平台。&lt;h4&gt;结论&lt;/h4&gt;实验结果为数据集提供了基准，验证了所提框架的有效性，强调了将EEG整合到多模态系统中的潜力，为情感识别及其他应用奠定了基础。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了EEG数据在多模态学习中的重要性，有助于开发更强大和全面的情感识别应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning has been a popular area of research, yet integratingelectroencephalogram (EEG) data poses unique challenges due to its inherentvariability and limited availability. In this paper, we introduce a novelmultimodal framework that accommodates not only conventional modalities such asvideo, images, and audio, but also incorporates EEG data. Our framework isdesigned to flexibly handle varying input sizes, while dynamically adjustingattention to account for feature importance across modalities. We evaluate ourapproach on a recently introduced emotion recognition dataset that combinesdata from three modalities, making it an ideal testbed for multimodal learning.The experimental results provide a benchmark for the dataset and demonstratethe effectiveness of the proposed framework. This work highlights the potentialof integrating EEG into multimodal systems, paving the way for more robust andcomprehensive applications in emotion recognition and beyond.</description>
      <author>example@mail.com (Kang Yin, Hye-Bin Shin, Dan Li, Seong-Whan Lee)</author>
      <guid isPermaLink="false">2411.00822v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>AM Flow: Adapters for Temporal Processing in Action Recognition</title>
      <link>http://arxiv.org/abs/2411.02065v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习模型，尤其是图像模型，近年来已经获得了更好的泛化能力和稳健性。&lt;h4&gt;目的&lt;/h4&gt;利用图像模型的进展，提高视频分类的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为'注意力图流（AM Flow）'的方法，用于识别视频帧中与运动相关的像素，并根据相机运动计算AM流。同时，将适配器技术扩展为'时间处理适配器'，以减少全微调的需求。&lt;h4&gt;主要发现&lt;/h4&gt;AM流允许空间和时间处理的分离，相比于结合的时空处理，取得了更好的结果；实现了更快的收敛，从而减少训练周期。&lt;h4&gt;结论&lt;/h4&gt;通过将AM流整合到预训练的图像模型中，该模型能够在流行的动作识别数据集上取得最先进的结果，同时减少训练时间和简化预训练过程。&lt;h4&gt;实验结果&lt;/h4&gt;在Kinetics-400、Something-Something v2和Toyota Smarthome数据集上进行实验，展示了最先进或可比的结果。&lt;h4&gt;总结&lt;/h4&gt;该研究为视频分类提供了一种新的方法，通过有效利用图像模型的优势，显著提高了性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models, in particular \textit{image} models, have recentlygained generalisability and robustness. %are becoming more general and robustby the day. In this work, we propose to exploit such advances in the realm of\textit{video} classification. Video foundation models suffer from therequirement of extensive pretraining and a large training time. Towardsmitigating such limitations, we propose "\textit{Attention Map (AM) Flow}" forimage models, a method for identifying pixels relevant to motion in each inputvideo frame. In this context, we propose two methods to compute AM flow,depending on camera motion. AM flow allows the separation of spatial andtemporal processing, while providing improved results over combinedspatio-temporal processing (as in video models). Adapters, one of the populartechniques in parameter efficient transfer learning, facilitate theincorporation of AM flow into pretrained image models, mitigating the need forfull-finetuning. We extend adapters to "\textit{temporal processing adapters}"by incorporating a temporal processing unit into the adapters. Our workachieves faster convergence, therefore reducing the number of epochs needed fortraining. Moreover, we endow an image model with the ability to achievestate-of-the-art results on popular action recognition datasets. This reducestraining time and simplifies pretraining. We present experiments onKinetics-400, Something-Something v2, and Toyota Smarthome datasets, showcasingstate-of-the-art or comparable results.</description>
      <author>example@mail.com (Tanay Agrawal, Abid Ali, Antitza Dantcheva, Francois Bremond)</author>
      <guid isPermaLink="false">2411.02065v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised Representation Learning for Cell Event Recognition through Time Arrow Prediction</title>
      <link>http://arxiv.org/abs/2411.03924v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;活细胞显微镜数据的时空特性分析细胞状态面临挑战，这对生物成像至关重要。&lt;h4&gt;目的&lt;/h4&gt;探索一种替代解决方案，以提高细胞事件识别的性能。&lt;h4&gt;方法&lt;/h4&gt;使用自监督表示学习（SSRL）中的特征图，结合时间箭头预测（TAP）进行下游监督任务。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在有限注释下的表现优于完全监督下端到端训练的模型。&lt;h4&gt;结论&lt;/h4&gt;SSRL和TAP的结合在活细胞显微镜中的应用提供了新的见解。&lt;h4&gt;总结&lt;/h4&gt;通过广泛的实验和分析，验证了该方法的有效性，推动了细胞状态分析的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The spatio-temporal nature of live-cell microscopy data poses challenges inthe analysis of cell states which is fundamental in bioimaging. Deep-learningbased segmentation or tracking methods rely on large amount of high qualityannotations to work effectively. In this work, we explore an alternativesolution: using feature maps obtained from self-supervised representationlearning (SSRL) on time arrow prediction (TAP) for the downstream supervisedtask of cell event recognition. We demonstrate through extensive experimentsand analysis that this approach can achieve better performance with limitedannotation compared to models trained from end to end using fully supervisedapproach. Our analysis also provides insight into applications of the SSRLusing TAP in live-cell microscopy.</description>
      <author>example@mail.com (Cangxiong Chen, Vinay P. Namboodiri, Julia E. Sero)</author>
      <guid isPermaLink="false">2411.03924v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Judge Like a Real Doctor: Dual Teacher Sample Consistency Framework for Semi-supervised Medical Image Classification</title>
      <link>http://arxiv.org/abs/2411.03041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Transactions on Emerging Topics in Computational
  Intelligence&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;半监督学习（SSL）是解决医疗图像分类中高标注成本的热门方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来增强一致性正则化，改善医疗图像分类的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出样本一致性均值教师（SCMT），结合绝对位置一致性（AL-c）和相对位置一致性（RL-c），并开发样本散布均值教师（SSMT）以利用对比学习来稀疏样本分布。&lt;h4&gt;主要发现&lt;/h4&gt;AL-c和RL-c从不同角度进行一致性正则化，提取更多样化的语义信息，从而提高分类效果。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，SCMT和SSMT方法在不同数据集上优于现有方法。&lt;h4&gt;总结&lt;/h4&gt;通过引入相对位置一致性和对比学习，本文的方法有效提高了医疗图像分类的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semi-supervised learning (SSL) is a popular solution to alleviate the highannotation cost in medical image classification. As a main branch of SSL,consistency regularization engages in imposing consensus between thepredictions of a single sample from different views, termed as AbsoluteLocation consistency (AL-c). However, only AL-c may be insufficient. Just likewhen diagnosing a case in practice, besides the case itself, the doctor usuallyrefers to certain related trustworthy cases to make more reliabledecisions.Therefore, we argue that solely relying on AL-c may ignore therelative differences across samples, which we interpret as relative locations,and only exploit limited information from one perspective. To address thisissue, we propose a Sample Consistency Mean Teacher (SCMT) which not onlyincorporates AL c but also additionally enforces consistency between thesamples' relative similarities to its related samples, called Relative Locationconsistency (RL c). AL c and RL c conduct consistency regularization from twodifferent perspectives, jointly extracting more diverse semantic informationfor classification. On the other hand, due to the highly similar structures inmedical images, the sample distribution could be overly dense in feature space,making their relative locations susceptible to noise. To tackle this problem,we further develop a Sample Scatter Mean Teacher (SSMT) by utilizingcontrastive learning to sparsify the sample distribution and obtain robust andeffective relative locations. Extensive experiments on different datasetsdemonstrate the superiority of our method.</description>
      <author>example@mail.com (Zhang Qixiang, Yang Yuxiang, Zu Chen, Zhang Jianjia, Wu Xi, Zhou Jiliu, Wang Yan)</author>
      <guid isPermaLink="false">2411.03041v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>A robust first order meshfree method for time-dependent nonlinear conservation laws</title>
      <link>http://arxiv.org/abs/2411.03411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了一种强健的、一阶准确的无网格方法，用于数值求解时间依赖的非线性守恒定律。&lt;h4&gt;目的&lt;/h4&gt;构建无网格的一阶一致性分部求导算子。&lt;h4&gt;方法&lt;/h4&gt;描述如何在点云上有效构造这些算子，并将其与基于数值通量的公式结合，近似求解非线性守恒定律，特别关注对流方程和可压缩欧拉方程。&lt;h4&gt;主要发现&lt;/h4&gt;虽然得到的无网格分化算子在L²范数下的准确度为O(h^1/2)，但在应用于偏微分方程的数值解时，收敛速率达到O(h)。&lt;h4&gt;结论&lt;/h4&gt;无网格分化算子在求解偏微分方程时表现出良好的收敛性，尽管其基础准确度较低。&lt;h4&gt;总结&lt;/h4&gt;本研究为无网格方法在非线性守恒定律数值分析中的应用提供了新的视角和有效的算子构造方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a robust first order accurate meshfree method to numericallysolve time-dependent nonlinear conservation laws. The main contribution of thiswork is the meshfree construction of first order consistent summation by partsdifferentiations. We describe how to efficiently construct such operators on apoint cloud. We then study the performance of such differentiations, and thencombine these operators with a numerical flux-based formulation to approximatethe solution of nonlinear conservation laws, with focus on the advectionequation and the compressible Euler equations. We observe numerically that,while the resulting mesh-free differentiation operators are only$O(h^\frac{1}{2})$ accurate in the $L^2$ norm, they achieve $O(h)$ rates ofconvergence when applied to the numerical solution of PDEs.</description>
      <author>example@mail.com (Samuel Kwan, Jesse Chan)</author>
      <guid isPermaLink="false">2411.03411v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks</title>
      <link>http://arxiv.org/abs/2411.04468v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代AI代理通过大型基础模型的进展，承诺提高生产力和转变生活，增强知识和能力。&lt;h4&gt;目的&lt;/h4&gt;开发一个高性能的开源代理系统，Magentic-One，以解决复杂任务。&lt;h4&gt;方法&lt;/h4&gt;Magentic-One采用多代理架构，由主代理Orchestrator进行规划、跟踪进度和错误恢复，指导其他专业代理执行特定任务。&lt;h4&gt;主要发现&lt;/h4&gt;Magentic-One在GAIA、AssistantBench和WebArena三个具有挑战性的基准测试中，达到了与最先进技术相当的性能。&lt;h4&gt;结论&lt;/h4&gt;Magentic-One的模块化设计允许代理的添加或移除，无需额外的提示微调或训练，促进了开发和未来场景的扩展。&lt;h4&gt;总结&lt;/h4&gt;Magentic-One及其评估工具AutoGenBench均为开源，提供了详细的性能评估和错误分析，进一步推动了通用代理系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern AI agents, driven by advances in large foundation models, promise toenhance our productivity and transform our lives by augmenting our knowledgeand capabilities. To achieve this vision, AI agents must effectively plan,perform multi-step reasoning and actions, respond to novel observations, andrecover from errors, to successfully complete complex tasks across a wide rangeof scenarios. In this work, we introduce Magentic-One, a high-performingopen-source agentic system for solving such tasks. Magentic-One uses amulti-agent architecture where a lead agent, the Orchestrator, plans, tracksprogress, and re-plans to recover from errors. Throughout task execution, theOrchestrator directs other specialized agents to perform tasks as needed, suchas operating a web browser, navigating local files, or writing and executingPython code. We show that Magentic-One achieves statistically competitiveperformance to the state-of-the-art on three diverse and challenging agenticbenchmarks: GAIA, AssistantBench, and WebArena. Magentic-One achieves theseresults without modification to core agent capabilities or to how theycollaborate, demonstrating progress towards generalist agentic systems.Moreover, Magentic-One's modular design allows agents to be added or removedfrom the team without additional prompt tuning or training, easing developmentand making it extensible to future scenarios. We provide an open-sourceimplementation of Magentic-One, and we include AutoGenBench, a standalone toolfor agentic evaluation. AutoGenBench provides built-in controls for repetitionand isolation to run agentic benchmarks in a rigorous and contained manner --which is important when agents' actions have side-effects. Magentic-One,AutoGenBench and detailed empirical performance evaluations of Magentic-One,including ablations and error analysis are available athttps://aka.ms/magentic-one</description>
      <author>example@mail.com (Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang, Zhu, Friederike Niedtner, Grace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor Dibia, Ahmed Awadallah, Ece Kamar, Rafah Hosn, Saleema Amershi)</author>
      <guid isPermaLink="false">2411.04468v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>HRDecoder: High-Resolution Decoder Network for Fundus Image Lesion Segmentation</title>
      <link>http://arxiv.org/abs/2411.03976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures, accepted by MICCAI 2024, the revised version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高分辨率对眼底图像的精确分割至关重要，但处理高分辨率输入会消耗大量GPU内存，并且性能提升会随着开销增加而减弱。&lt;h4&gt;目的&lt;/h4&gt;解决高分辨率图像分割中处理小物体的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出HRDecoder，一个简单的高分辨率解码网络，集成高分辨率表示学习模块和高分辨率融合模块，以捕捉细粒度局部特征并融合多尺度预测。&lt;h4&gt;主要发现&lt;/h4&gt;该方法有效提高了眼底病变的整体分割精度，同时在合理的内存和计算开销下保持令人满意的推理速度。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，HRDecoder在IDRID和DDR数据集上表现出色，验证了其有效性。&lt;h4&gt;代码链接&lt;/h4&gt;https://github.com/CVIU-CSU/HRDecoder&lt;h4&gt;总结&lt;/h4&gt;HRDecoder通过局部和全球信息的融合，有效解决了高分辨率眼底图像分割中的计算开销问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cviu-csu/hrdecoder&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High resolution is crucial for precise segmentation in fundus images, yethandling high-resolution inputs incurs considerable GPU memory costs, withdiminishing performance gains as overhead increases. To address this issuewhile tackling the challenge of segmenting tiny objects, recent studies haveexplored local-global fusion methods. These methods preserve fine details usinglocal regions and capture long-range context information from downscaled globalimages. However, the necessity of multiple forward passes inevitably incurssignificant computational overhead, adversely affecting inference speed. Inthis paper, we propose HRDecoder, a simple High-Resolution Decoder network forfundus lesion segmentation. It integrates a high-resolution representationlearning module to capture fine-grained local features and a high-resolutionfusion module to fuse multi-scale predictions. Our method effectively improvesthe overall segmentation accuracy of fundus lesions while consuming reasonablememory and computational overhead, and maintaining satisfying inference speed.Experimental results on the IDRID and DDR datasets demonstrate theeffectiveness of our method. Code is available athttps://github.com/CVIU-CSU/HRDecoder.</description>
      <author>example@mail.com (Ziyuan Ding, Yixiong Liang, Shichao Kan, Qing Liu)</author>
      <guid isPermaLink="false">2411.03976v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Generative Semantic Communications with Foundation Models: Perception-Error Analysis and Semantic-Aware Power Allocation</title>
      <link>http://arxiv.org/abs/2411.04575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成基础模型能够革新语义通信系统的设计，实现高保真语义信息在超低速率下的交换。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于预训练基础模型的生成语义通信框架，开发语义解码器的前向无编码和编码丢弃误差方案。&lt;h4&gt;方法&lt;/h4&gt;从速率-失真-感知的角度分析传输可靠性对再生信号感知质量的影响，并定义语义值以衡量多模态语义特征的语义信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过两种语义感知的功率分配方法，利用感知误差关系的非递减特性，解决超低速率和高保真语义通信中的功耗最小化问题。&lt;h4&gt;结论&lt;/h4&gt;数值结果表明，提出的语义感知方法在图像任务中的表现显著优于传统方法，尤其在通道编码情况下节省高达90%的功率。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了生成模型在提升语义通信系统效率和降低功耗方面的潜力，强调了传输可靠性与信号感知质量之间的重要关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative foundation models can revolutionize the design of semanticcommunication (SemCom) systems allowing high fidelity exchange of semanticinformation at ultra low rates. In this work, a generative SemCom frameworkwith pretrained foundation models is proposed, where both uncodedforward-with-error and coded discard-with-error schemes are developed for thesemantic decoder. To characterize the impact of transmission reliability on theperceptual quality of the regenerated signal, their mathematical relationshipis analyzed from a rate-distortion-perception perspective, which is proved tobe non-decreasing. The semantic values are defined to measure the semanticinformation of multimodal semantic features accordingly. We also investigatesemantic-aware power allocation problems aiming at power consumptionminimization for ultra low rate and high fidelity SemComs. To solve theseproblems, two semantic-aware power allocation methods are proposed byleveraging the non-decreasing property of the perception-error relationship.Numerically, perception-error functions and semantic values of semantic datastreams under both schemes for image tasks are obtained based on the Kodakdataset. Simulation results show that our proposed semanticaware methodsignificantly outperforms conventional approaches, particularly in thechannel-coded case (up to 90% power saving).</description>
      <author>example@mail.com (Chunmei Xu, Mahdi Boloursaz Mashhadi, Yi Ma, Rahim Tafazolli, Jiangzhou Wang)</author>
      <guid isPermaLink="false">2411.04575v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>VLA-3D: A Dataset for 3D Semantic Scene Understanding and Navigation</title>
      <link>http://arxiv.org/abs/2411.03540v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted and presented at the 1st Workshop on Semantic Reasoning and
  Goal Understanding in Robotics (SemRob), Robotics Science and Systems
  Conference (RSS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型（LLMs）和视觉语言模型（VLMs）的兴起，使用自然语言指令进行多模态、多任务的具身代理在多种环境中展现出潜力，特别是在室内导航方面。&lt;h4&gt;目的&lt;/h4&gt;解决室内导航中由于空间推理和语义理解所带来的挑战，尤其是在包含多种细粒度物体的任意场景中。&lt;h4&gt;方法&lt;/h4&gt;构建了一个名为VLA-3D的数据集，包含超过11.5K个扫描的3D室内房间、2350万条基于启发式生成的物体语义关系和970万条合成生成的指称语句。&lt;h4&gt;主要发现&lt;/h4&gt;数据集包括处理后的3D点云、语义物体和房间标注、场景图、可导航自由空间标注以及专注于视角无关空间关系的指称语言语句，有助于解决导航任务。&lt;h4&gt;结论&lt;/h4&gt;该数据集的发布旨在为语义3D场景理解的进展提供资源，增强系统在不断变化的场景和不完美语言中的鲁棒性，并支持互动室内导航系统的发展。&lt;h4&gt;总结&lt;/h4&gt;通过基准测试当前最先进模型的表现，建立性能基线，同时公开数据集生成和可视化的所有代码，以促进相关研究的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the recent rise of Large Language Models (LLMs), Vision-Language Models(VLMs), and other general foundation models, there is growing potential formultimodal, multi-task embodied agents that can operate in diverse environmentsgiven only natural language as input. One such application area is indoornavigation using natural language instructions. However, despite recentprogress, this problem remains challenging due to the spatial reasoning andsemantic understanding required, particularly in arbitrary scenes that maycontain many objects belonging to fine-grained classes. To address thischallenge, we curate the largest real-world dataset for Vision andLanguage-guided Action in 3D Scenes (VLA-3D), consisting of over 11.5K scanned3D indoor rooms from existing datasets, 23.5M heuristically generated semanticrelations between objects, and 9.7M synthetically generated referentialstatements. Our dataset consists of processed 3D point clouds, semantic objectand room annotations, scene graphs, navigable free space annotations, andreferential language statements that specifically focus on view-independentspatial relations for disambiguating objects. The goal of these features is toaid the downstream task of navigation, especially on real-world systems wheresome level of robustness must be guaranteed in an open world of changing scenesand imperfect language. We benchmark our dataset with current state-of-the-artmodels to obtain a performance baseline. All code to generate and visualize thedataset is publicly released, see https://github.com/HaochenZ11/VLA-3D. Withthe release of this dataset, we hope to provide a resource for progress insemantic 3D scene understanding that is robust to changes and one which willaid the development of interactive indoor navigation systems.</description>
      <author>example@mail.com (Haochen Zhang, Nader Zantout, Pujith Kachana, Zongyuan Wu, Ji Zhang, Wenshan Wang)</author>
      <guid isPermaLink="false">2411.03540v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Stability Gap in Continual Learning: The Role of the Classification Head</title>
      <link>http://arxiv.org/abs/2411.04723v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;持续学习（CL）在机器学习中成为一个重要领域，使神经网络能够从不断变化的数据分布中学习，同时减轻灾难性遗忘。&lt;h4&gt;目的&lt;/h4&gt;研究并缓解稳定性差距，即模型在训练初期对先前学习任务的性能降低现象。&lt;h4&gt;方法&lt;/h4&gt;在不同的神经网络架构层次上进行研究，特别关注分类头的作用，引入最近均值分类器（NMC）来分析骨干网络和分类头对稳定性差距的影响。&lt;h4&gt;主要发现&lt;/h4&gt;NMC不仅提高了最终性能，还显著增强了在CIFAR100、ImageNet100、CUB-200和FGVC Aircrafts等持续学习基准上的训练稳定性，同时减少了任务近期偏见。&lt;h4&gt;结论&lt;/h4&gt;分析表明，稳定性差距的主要原因是线性分类头，而非不足的表征学习。&lt;h4&gt;总结&lt;/h4&gt;该研究为理解稳定性差距提供了新视角，强调了分类头在持续学习中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wojciechl02/stability-gap-nmc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual learning (CL) has emerged as a critical area in machine learning,enabling neural networks to learn from evolving data distributions whilemitigating catastrophic forgetting. However, recent research has identified thestability gap -- a phenomenon where models initially lose performance onpreviously learned tasks before partially recovering during training. Suchlearning dynamics are contradictory to the intuitive understanding of stabilityin continual learning where one would expect the performance to degradegradually instead of rapidly decreasing and then partially recovering later. Tobetter understand and alleviate the stability gap, we investigate it atdifferent levels of the neural network architecture, particularly focusing onthe role of the classification head. We introduce the nearest-mean classifier(NMC) as a tool to attribute the influence of the backbone and theclassification head on the stability gap. Our experiments demonstrate that NMCnot only improves final performance, but also significantly enhances trainingstability across various continual learning benchmarks, including CIFAR100,ImageNet100, CUB-200, and FGVC Aircrafts. Moreover, we find that NMC alsoreduces task-recency bias. Our analysis provides new insights into thestability gap and suggests that the primary contributor to this phenomenon isthe linear head, rather than the insufficient representation learning.</description>
      <author>example@mail.com (Wojciech Łapacz, Daniel Marczak, Filip Szatkowski, Tomasz Trzciński)</author>
      <guid isPermaLink="false">2411.04723v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data</title>
      <link>http://arxiv.org/abs/2411.04586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 figures, 4 tables, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;鲁棒性是开发安全可信模型的基本方面，特别是在开放环境中部署时。&lt;h4&gt;目的&lt;/h4&gt;分析单阶段目标检测器在存在分布外（OoD）数据时的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的检测算法，利用模型从每个样本提取的特征来检测未知物体，且无需重新训练检测器。&lt;h4&gt;主要发现&lt;/h4&gt;通过应用监督降维技术，减轻维度诅咒对特征的影响，并利用高分辨率特征图以无监督方式识别潜在未知物体。&lt;h4&gt;结论&lt;/h4&gt;所提出算法在已知和未知物体检测性能的帕累托权衡分析中表现优越，并与基于logits的后处理方法和融合策略进行了比较。&lt;h4&gt;总结&lt;/h4&gt;与最新的未知物体检测基准相比，所测试方法的竞争力得到验证，前沿的后处理OoD检测器性能在结合所提算法后有进一步提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robustness is a fundamental aspect for developing safe and trustworthymodels, particularly when they are deployed in the open world. In this work weanalyze the inherent capability of one-stage object detectors to robustlyoperate in the presence of out-of-distribution (OoD) data. Specifically, wepropose a novel detection algorithm for detecting unknown objects in imagedata, which leverages the features extracted by the model from each sample.Differently from other recent approaches in the literature, our proposal doesnot require retraining the object detector, thereby allowing for the use ofpretrained models. Our proposed OoD detector exploits the application ofsupervised dimensionality reduction techniques to mitigate the effects of thecurse of dimensionality on the features extracted by the model. Furthermore, itutilizes high-resolution feature maps to identify potential unknown objects inan unsupervised fashion. Our experiments analyze the Pareto trade-off betweenthe performance detecting known and unknown objects resulting from differentalgorithmic configurations and inference confidence thresholds. We also comparethe performance of our proposed algorithm to that of logits-based post-hoc OoDmethods, as well as possible fusion strategies. Finally, we discuss on thecompetitiveness of all tested methods against state-of-the-art OoD approachesfor object detection models over the recently published Unknown ObjectDetection benchmark. The obtained results verify that the performance ofavant-garde post-hoc OoD detectors can be further improved when combined withour proposed algorithm.</description>
      <author>example@mail.com (Aitor Martinez-Seras, Javier Del Ser, Alain Andres, Pablo Garcia-Bringas)</author>
      <guid isPermaLink="false">2411.04586v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>PX2Tooth: Reconstructing the 3D Point Cloud Teeth from a Single Panoramic X-ray</title>
      <link>http://arxiv.org/abs/2411.03725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Ma W, Wu H, Xiao Z, et al. PX2Tooth: Reconstructing the 3D Point
  Cloud Teeth from a Single Panoramic X-Ray[C]//International Conference on
  Medical Image Computing and Computer-Assisted Intervention. Cham: Springer
  Nature Switzerland, 2024: 411-421&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从单张2D全景X光图像重建口腔三维解剖结构是一个重要但具有挑战性的任务，有助于降低辐射风险和治疗成本。&lt;h4&gt;目的&lt;/h4&gt;提出PX2Tooth方法，通过单张全景图像重建3D牙齿。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段框架，首先使用PXSegNet进行牙齿分割，然后使用TGNet将随机点云转换为3D牙齿，并引入Prior Fusion Module提高生成质量。&lt;h4&gt;主要发现&lt;/h4&gt;构建了包含499对CBCT和全景X光的数据库，PX2Tooth实现了0.793的交并比(Intersection over Union)，显著优于之前的方法。&lt;h4&gt;结论&lt;/h4&gt;表明人工智能在数字牙科领域具有巨大潜力。&lt;h4&gt;总结&lt;/h4&gt;PX2Tooth方法展示了利用单张全景X光图像重建3D牙齿的有效性，推动了数字牙科的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing the 3D anatomical structures of the oral cavity, whichoriginally reside in the cone-beam CT (CBCT), from a single 2D PanoramicX-ray(PX) remains a critical yet challenging task, as it can effectively reduceradiation risks and treatment costs during the diagnostic in digital dentistry.However, current methods are either error-prone or only trained/evaluated onsmall-scale datasets (less than 50 cases), resulting in compromisedtrustworthiness. In this paper, we propose PX2Tooth, a novel approach toreconstruct 3D teeth using a single PX image with a two-stage framework. First,we design the PXSegNet to segment the permanent teeth from the PX images,providing clear positional, morphological, and categorical information for eachtooth. Subsequently, we design a novel tooth generation network (TGNet) thatlearns to transform random point clouds into 3D teeth. TGNet integrates thesegmented patch information and introduces a Prior Fusion Module (PFM) toenhance the generation quality, especially in the root apex region. Moreover,we construct a dataset comprising 499 pairs of CBCT and Panoramic X-rays.Extensive experiments demonstrate that PX2Tooth can achieve an Intersectionover Union (IoU) of 0.793, significantly surpassing previous methods,underscoring the great potential of artificial intelligence in digitaldentistry.</description>
      <author>example@mail.com (Wen Ma, Huikai Wu, Zikai Xiao, Yang Feng, Jian Wu, Zuozhu Liu)</author>
      <guid isPermaLink="false">2411.03725v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing Multimodal Integration in the Variational Autoencoder from an Information-Theoretic Perspective</title>
      <link>http://arxiv.org/abs/2411.00522v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类感知本质上是多模态的，我们将视觉、体感和触觉信息整合为一个体验。&lt;h4&gt;目的&lt;/h4&gt;探讨多模态学习在构建能够与现实世界稳健互动的机器人系统中的重要性。&lt;h4&gt;方法&lt;/h4&gt;提出多模态变分自编码器（VAE），通过编码器将数据映射到随机潜在空间，并通过解码器从该空间重构数据。&lt;h4&gt;主要发现&lt;/h4&gt;引入信息论度量分析不同模态整合对输入数据重构的重要性，包括单模态误差和精度损失的计算。&lt;h4&gt;结论&lt;/h4&gt;通过对四种不同加权方案的训练和分析，评估模型在多模态整合方面的能力。&lt;h4&gt;总结&lt;/h4&gt;多模态变分自编码器有效整合不同模态的信息，能够提升机器人系统的互动能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human perception is inherently multimodal. We integrate, for instance,visual, proprioceptive and tactile information into one experience. Hence,multimodal learning is of importance for building robotic systems that aim atrobustly interacting with the real world. One potential model that has beenproposed for multimodal integration is the multimodal variational autoencoder.A variational autoencoder (VAE) consists of two networks, an encoder that mapsthe data to a stochastic latent space and a decoder that reconstruct this datafrom an element of this latent space. The multimodal VAE integrates inputs fromdifferent modalities at two points in time in the latent space and can therebybe used as a controller for a robotic agent. Here we use this architecture andintroduce information-theoretic measures in order to analyze how important theintegration of the different modalities are for the reconstruction of the inputdata. Therefore we calculate two different types of measures, the first type iscalled single modality error and assesses how important the information from asingle modality is for the reconstruction of this modality or all modalities.Secondly, the measures named loss of precision calculate the impact thatmissing information from only one modality has on the reconstruction of thismodality or the whole vector. The VAE is trained via the evidence lower bound,which can be written as a sum of two different terms, namely the reconstructionand the latent loss. The impact of the latent loss can be weighted via anadditional variable, which has been introduced to combat posterior collapse.Here we train networks with four different weighting schedules and analyze themwith respect to their capabilities for multimodal integration.</description>
      <author>example@mail.com (Carlotta Langer, Yasmin Kim Georgie, Ilja Porohovoj, Verena Vanessa Hafner, Nihat Ay)</author>
      <guid isPermaLink="false">2411.00522v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>ComFairGNN: Community Fair Graph Neural Network</title>
      <link>http://arxiv.org/abs/2411.04371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在解决各种现实场景中的图分析问题中成为主要方法，但可能对某些人口子群体产生偏见预测。&lt;h4&gt;目的&lt;/h4&gt;研究当前GNN去偏见方法在不公平性评估方面的有效性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种社区级别的策略来测量GNN中的偏见，并评估去偏见方法。此外，介绍了ComFairGNN，一个旨在减轻GNN社区级别偏见的新框架。&lt;h4&gt;主要发现&lt;/h4&gt;ComFairGNN采用可学习的核心集去偏见功能，解决了在GNN邻域聚合过程中因多样化局部邻域分布而产生的偏见。&lt;h4&gt;结论&lt;/h4&gt;在三个基准数据集上的综合评估表明，该模型在准确性和公平性指标上都表现出色。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了在GNN中评估和缓解社区级别偏见的重要性，并提出了有效的去偏见框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become the leading approach for addressinggraph analytical problems in various real-world scenarios. However, GNNs mayproduce biased predictions against certain demographic subgroups due to nodeattributes and neighbors surrounding a node. Most current research on GNNfairness focuses predominantly on debiasing GNNs using oversimplified fairnessevaluation metrics, which can give a misleading impression of fairness.Understanding the potential evaluation paradoxes due to the complicated natureof the graph structure is crucial for developing effective GNN debiasingmechanisms. In this paper, we examine the effectiveness of current GNNdebiasing methods in terms of unfairness evaluation. Specifically, we introducea community-level strategy to measure bias in GNNs and evaluate debiasingmethods at this level. Further, We introduce ComFairGNN, a novel frameworkdesigned to mitigate community-level bias in GNNs. Our approach employs alearnable coreset-based debiasing function that addresses bias arising fromdiverse local neighborhood distributions during GNNs neighborhood aggregation.Comprehensive evaluations on three benchmark datasets demonstrate our model'seffectiveness in both accuracy and fairness metrics.</description>
      <author>example@mail.com (Yonas Sium, Qi Li)</author>
      <guid isPermaLink="false">2411.04371v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>FEED: Fairness-Enhanced Meta-Learning for Domain Generalization</title>
      <link>http://arxiv.org/abs/2411.01316v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE International Conference on Big Data 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在元学习中，能够对分布外数据进行泛化，同时关注模型公平性是一个重要且具有挑战性的问题。&lt;h4&gt;目的&lt;/h4&gt;寻找一组公平意识的分类器不变参数，以便在未知但不同的测试领域中实现良好的泛化性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种公平意识的元学习方法，Fairness-Enhanced Meta-Learning for Domain Generalization (FEED)，通过将潜在数据表示分解为内容、风格和敏感向量来增强领域泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;该框架显著提高了机器学习模型在不同领域间的鲁棒性，且遵循公平性约束，在多个基准上进行了广泛的实验验证。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在保持高准确率和公平性方面表现优越，并在领域泛化任务中显著超越现有的最先进方法。&lt;h4&gt;总结&lt;/h4&gt;FEED方法通过将公平性纳入元学习过程，确保学习到的参数在领域特性变化时始终保持公平性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalizing to out-of-distribution data while being aware of model fairnessis a significant and challenging problem in meta-learning. The goal of thisproblem is to find a set of fairness-aware invariant parameters of classifierthat is trained using data drawn from a family of related training domains withdistribution shift on non-sensitive features as well as different levels ofdependence between model predictions and sensitive features so that theclassifier can achieve good generalization performance on unknown but distincttest domains. To tackle this challenge, existing state-of-the-art methodseither address the domain generalization problem but completely ignore learningwith fairness or solely specify shifted domains with various fairness levels.This paper introduces an approach to fairness-aware meta-learning thatsignificantly enhances domain generalization capabilities. Our framework,Fairness-Enhanced Meta-Learning for Domain Generalization (FEED), disentangleslatent data representations into content, style, and sensitive vectors. Thisdisentanglement facilitates the robust generalization of machine learningmodels across diverse domains while adhering to fairness constraints. Unliketraditional methods that focus primarily on domain invariance or sensitivity toshifts, our model integrates a fairness-aware invariance criterion directlyinto the meta-learning process. This integration ensures that the learnedparameters uphold fairness consistently, even when domain characteristics varywidely. We validate our approach through extensive experiments across multiplebenchmarks, demonstrating not only superior performance in maintaining highaccuracy and fairness but also significant improvements over existingstate-of-the-art methods in domain generalization tasks.</description>
      <author>example@mail.com (Kai Jiang, Chen Zhao, Haoliang Wang, Feng Chen)</author>
      <guid isPermaLink="false">2411.01316v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Supervised Transfer Learning Framework for Fault Diagnosis in Wind Turbines</title>
      <link>http://arxiv.org/abs/2411.02127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures, to be published in: Upper Rhine AI Symposium
  (URAI) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;故障诊断面临的共同挑战包括缺乏标记数据和需要为每个领域构建模型，导致需要大量监督模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种在异常空间中进行风力涡轮机故障诊断的监督迁移学习框架。&lt;h4&gt;方法&lt;/h4&gt;利用SCADA数据和振动数据创建异常空间，并使用随机森林、轻梯度提升机和多层感知器等流行的监督分类器进行跨领域评估。&lt;h4&gt;主要发现&lt;/h4&gt;多层感知器在训练集上的分类性能最高，最终用于测试集的评估。&lt;h4&gt;结论&lt;/h4&gt;所提框架能够以高准确度检测测试集中跨领域故障，使用单一分类器对诊断团队具有重要价值。&lt;h4&gt;总结&lt;/h4&gt;通过迁移学习和异常空间的结合，增强了风力涡轮机故障诊断的有效性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Common challenges in fault diagnosis include the lack of labeled data and theneed to build models for each domain, resulting in many models that requiresupervision. Transfer learning can help tackle these challenges by learningcross-domain knowledge. Many approaches still require at least some labeleddata in the target domain, and often provide unexplainable results. To thisend, we propose a supervised transfer learning framework for fault diagnosis inwind turbines that operates in an Anomaly-Space. This space was created usingSCADA data and vibration data and was built and provided to us by our researchpartner. Data within the Anomaly-Space can be interpreted as anomaly scores foreach component in the wind turbine, making each value intuitive to understand.We conducted cross-domain evaluation on the train set using popular supervisedclassifiers like Random Forest, Light-Gradient-Boosting-Machines and MultilayerPerceptron as metamodels for the diagnosis of bearing and sensor faults. TheMultilayer Perceptron achieved the highest classification performance. Thismodel was then used for a final evaluation in our test set. The results show,that the proposed framework is able to detect cross-domain faults in the testset with a high degree of accuracy by using one single classifier, which is asignificant asset to the diagnostic team.</description>
      <author>example@mail.com (Kenan Weber, Christine Preisach)</author>
      <guid isPermaLink="false">2411.02127v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Differentially Private Continual Learning using Pre-Trained Models</title>
      <link>http://arxiv.org/abs/2411.04680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 3 figures, Accepted at Scalable Continual Learning for
  Lifelong Foundation Models Workshop at 38th Conference on Neural Information
  Processing Systems (NeurIPS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;持续学习（CL）模型需要在多个任务中保留知识，但这与差分隐私（DP）要求的限制个体样本被模型记忆的需求相冲突。&lt;h4&gt;目的&lt;/h4&gt;探讨持续学习与差分隐私之间的交集。&lt;h4&gt;方法&lt;/h4&gt;提出使用预训练模型来解决持续学习环境中隐私与性能之间的权衡，结合无参数分类器和在差分隐私下学习的参数高效适配器。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明所提方法有效，并提供了平衡持续学习与隐私需求的见解。&lt;h4&gt;结论&lt;/h4&gt;通过预训练模型和特定的学习策略，可以在持续学习中实现隐私保护与性能的平衡。&lt;h4&gt;总结&lt;/h4&gt;该研究为持续学习中的隐私保护提供了新的思路，强调了模型设计中的重要权衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work explores the intersection of continual learning (CL) anddifferential privacy (DP). Crucially, continual learning models must retainknowledge across tasks, but this conflicts with the differential privacyrequirement of restricting individual samples to be memorised in the model. Wepropose using pre-trained models to address the trade-offs between privacy andperformance in a continual learning setting.More specifically, we presentnecessary assumptions to enable privacy-preservation and propose combiningpre-trained models with parameter-free classifiers and parameter-efficientadapters that are learned under differential privacy. Our experimentsdemonstrate their effectiveness and provide insights into balancing thecompeting demands of continual learning and privacy.</description>
      <author>example@mail.com (Marlon Tobaben, Marcus Klasson, Rui Li, Arno Solin, Antti Honkela)</author>
      <guid isPermaLink="false">2411.04680v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>pTSE-T: Presentation Target Speaker Extraction using Unaligned Text Cues</title>
      <link>http://arxiv.org/abs/2411.03109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的TSE方法旨在从音频混合中提取目标说话者的清晰语音，同时消除无关的背景噪音和其他语音。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的TSE算法，利用有限且未对齐的文本内容中的语义线索，以应对在实际场景中获取强线索的困难。&lt;h4&gt;方法&lt;/h4&gt;设计了两个不同的网络，其中一个TPE网络融合音频特征与基于内容的语义线索生成时间频率掩膜，另一个TSR网络利用对比学习技术将盲分离的语音信号与语义线索关联。&lt;h4&gt;主要发现&lt;/h4&gt;通过利用来自有限和未对齐文本的语义线索，成功提高了目标说话者的识别率，实验结果表明SI-SDRi为12.16 dB，SDRi为12.66 dB，PESQio为0.830，STOIi为0.150。&lt;h4&gt;结论&lt;/h4&gt;该方法在会议、海报展示或讲座等场景中表现出色，提供了一种新的解决方案以提高语音分离的准确性。&lt;h4&gt;总结&lt;/h4&gt;研究成果将提供数据集和源代码，项目演示页面可访问：https://slideTSE.github.io/&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; TSE aims to extract the clean speech of the target speaker in an audiomixture, thus eliminating irrelevant background noise and speech. While priorwork has explored various auxiliary cues including pre-recorded speech, visualinformation (e.g., lip motions and gestures), and spatial information, theacquisition and selection of such strong cues are infeasible in many practicalscenarios. Unlike all existing work, in this paper, we condition the TSEalgorithm on semantic cues extracted from limited and unaligned text content,such as condensed points from a presentation slide. This method is particularlyuseful in scenarios like meetings, poster sessions, or lecture presentations,where acquiring other cues in real-time is challenging. To this end, we designtwo different networks. Specifically, our proposed TPE fuses audio featureswith content-based semantic cues to facilitate time-frequency mask generationto filter out extraneous noise, while another proposal, namely TSR, employs thecontrastive learning technique to associate blindly separated speech signalswith semantic cues. The experimental results show the efficacy in accuratelyidentifying the target speaker by utilizing semantic cues derived from limitedand unaligned text, resulting in SI-SDRi of 12.16 dB, SDRi of 12.66 dB, PESQiof 0.830 and STOIi of 0.150, respectively. Dataset and source code will bepublicly available. Project demo page: https://slideTSE.github.io/.</description>
      <author>example@mail.com (Ziyang Jiang, Xinquan Qian, Jiahe Lei, Zexu Pan, Wei Xue, Xu-cheng Yin)</author>
      <guid isPermaLink="false">2411.03109v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>A Mamba Foundation Model for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2411.02941v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列基础模型在零样本学习中表现出色，适合于预测快速变化的现实应用中的模式，但大多数模型依赖于Transformer架构，输入长度增加时会导致二次复杂度。&lt;h4&gt;目的&lt;/h4&gt;提出TSMamba，一个基于Mamba架构的线性复杂度时间序列预测基础模型。&lt;h4&gt;方法&lt;/h4&gt;TSMamba通过前向和后向Mamba编码器捕捉时间依赖性，采用两阶段迁移学习过程，利用预训练的Mamba LLMs进行有效的时间序列建模。&lt;h4&gt;主要发现&lt;/h4&gt;TSMamba的零样本性能与最先进的时间序列基础模型相当，尽管使用的训练数据显著较少，并且在特定多变量数据集上进行了微调时引入了通道压缩注意力模块以捕捉跨通道依赖性。&lt;h4&gt;结论&lt;/h4&gt;TSMamba在完整样本性能上与特定任务预测模型相比具有竞争力或更优的表现，代码将公开发布。&lt;h4&gt;总结&lt;/h4&gt;TSMamba展示了在有限训练数据下的高效时间序列建模能力，适用于快速变化的应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series foundation models have demonstrated strong performance inzero-shot learning, making them well-suited for predicting rapidly evolvingpatterns in real-world applications where relevant training data are scarce.However, most of these models rely on the Transformer architecture, whichincurs quadratic complexity as input length increases. To address this, weintroduce TSMamba, a linear-complexity foundation model for time seriesforecasting built on the Mamba architecture. The model captures temporaldependencies through both forward and backward Mamba encoders, achieving highprediction accuracy. To reduce reliance on large datasets and lower trainingcosts, TSMamba employs a two-stage transfer learning process that leveragespretrained Mamba LLMs, allowing effective time series modeling with a moderatetraining set. In the first stage, the forward and backward backbones areoptimized via patch-wise autoregressive prediction; in the second stage, themodel trains a prediction head and refines other components for long-termforecasting. While the backbone assumes channel independence to manage varyingchannel numbers across datasets, a channel-wise compressed attention module isintroduced to capture cross-channel dependencies during fine-tuning on specificmultivariate datasets. Experiments show that TSMamba's zero-shot performance iscomparable to state-of-the-art time series foundation models, despite usingsignificantly less training data. It also achieves competitive or superiorfull-shot performance compared to task-specific prediction models. The codewill be made publicly available.</description>
      <author>example@mail.com (Haoyu Ma, Yushu Chen, Wenlai Zhao, Jinzhe Yang, Yingsheng Ji, Xinghua Xu, Xiaozhu Liu, Hao Jing, Shengzhuo Liu, Guangwen Yang)</author>
      <guid isPermaLink="false">2411.02941v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>MADOD: Generalizing OOD Detection to Unseen Domains via G-Invariance Meta-Learning</title>
      <link>http://arxiv.org/abs/2411.02444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE International Conference on Big Data 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现实世界的机器学习应用常面临协变量和语义变化，这对传统的领域泛化和离群点检测方法提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架，旨在同时处理协变量和语义的变化。&lt;h4&gt;方法&lt;/h4&gt;引入元学习和G不变性来增强模型的泛化能力和在未见领域的离群点检测能力，采用随机指定类为伪离群点的方法进行任务构建。&lt;h4&gt;主要发现&lt;/h4&gt;在未见领域的语义离群点检测中，MADOD的AUPR提升幅度为8.48%到20.81%，同时保持了竞争性的分布内分类准确率。&lt;h4&gt;结论&lt;/h4&gt;MADOD在处理协变量和语义变化方面取得显著进展，适用于测试数据不可用的场景，且在推理过程中无需适应。&lt;h4&gt;总结&lt;/h4&gt;MADOD框架通过元学习和能量正则化，学习到鲁棒的领域不变特征，有效地校准决策边界，提升离群点检测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/haoliangwang86/MADOD&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world machine learning applications often face simultaneous covariateand semantic shifts, challenging traditional domain generalization andout-of-distribution (OOD) detection methods. We introduce Meta-learned AcrossDomain Out-of-distribution Detection (MADOD), a novel framework designed toaddress both shifts concurrently. MADOD leverages meta-learning andG-invariance to enhance model generalizability and OOD detection in unseendomains. Our key innovation lies in task construction: we randomly designatein-distribution classes as pseudo-OODs within each meta-learning task,simulating OOD scenarios using existing data. This approach, combined withenergy-based regularization, enables the learning of robust, domain-invariantfeatures while calibrating decision boundaries for effective OOD detection.Operating in a test domain-agnostic setting, MADOD eliminates the need foradaptation during inference, making it suitable for scenarios where test datais unavailable. Extensive experiments on real-world and synthetic datasetsdemonstrate MADOD's superior performance in semantic OOD detection acrossunseen domains, achieving an AUPR improvement of 8.48% to 20.81%, whilemaintaining competitive in-distribution classification accuracy, representing asignificant advancement in handling both covariate and semantic shifts.</description>
      <author>example@mail.com (Haoliang Wang, Chen Zhao, Feng Chen)</author>
      <guid isPermaLink="false">2411.02444v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Higher-Order GNNs Meet Efficiency: Sparse Sobolev Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.04570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在建模图中节点关系方面展现了巨大的潜力，但在大型网络中捕捉高阶关系仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的图卷积算子，以有效捕捉GNN中的高阶信息，特别是在节点分类和半监督学习任务中。&lt;h4&gt;方法&lt;/h4&gt;基于图信号的稀疏Sobolev范数，提出Sparse Sobolev GNN（S2-GNN），使用Hadamard积来保持图表示的稀疏性，并通过一系列逐渐增加Hadamard次方的滤波器生成多样化的函数。&lt;h4&gt;主要发现&lt;/h4&gt;S2-GNN在理论上分析了其稳定性，展示了模型对可能的图扰动的鲁棒性，并在各种图挖掘、半监督节点分类和计算机视觉任务中进行了全面评估。&lt;h4&gt;结论&lt;/h4&gt;在特定用例中，S2-GNN在性能和运行时间方面与最先进的GNNs相比表现出竞争力。&lt;h4&gt;总结&lt;/h4&gt;S2-GNN为GNNs在捕捉高阶信息提供了一种有效的方法，并在多个领域展示了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jhonygiraldo/S2-GNN&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown great promise in modelingrelationships between nodes in a graph, but capturing higher-orderrelationships remains a challenge for large-scale networks. Previous studieshave primarily attempted to utilize the information from higher-order neighborsin the graph, involving the incorporation of powers of the shift operator, suchas the graph Laplacian or adjacency matrix. This approach comes with atrade-off in terms of increased computational and memory demands. Relying ongraph spectral theory, we make a fundamental observation: the regular and theHadamard power of the Laplacian matrix behave similarly in the spectrum. Thisobservation has significant implications for capturing higher-order informationin GNNs for various tasks such as node classification and semi-supervisedlearning. Consequently, we propose a novel graph convolutional operator basedon the sparse Sobolev norm of graph signals. Our approach, known as SparseSobolev GNN (S2-GNN), employs Hadamard products between matrices to maintainthe sparsity level in graph representations. S2-GNN utilizes a cascade offilters with increasing Hadamard powers to generate a diverse set of functions.We theoretically analyze the stability of S2-GNN to show the robustness of themodel against possible graph perturbations. We also conduct a comprehensiveevaluation of S2-GNN across various graph mining, semi-supervised nodeclassification, and computer vision tasks. In particular use cases, ouralgorithm demonstrates competitive performance compared to state-of-the-artGNNs in terms of performance and running time.</description>
      <author>example@mail.com (Jhony H. Giraldo, Aref Einizade, Andjela Todorovic, Jhon A. Castro-Correa, Mohsen Badiey, Thierry Bouwmans, Fragkiskos D. Malliaros)</author>
      <guid isPermaLink="false">2411.04570v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>LidaRefer: Outdoor 3D Visual Grounding for Autonomous Driving with Transformers</title>
      <link>http://arxiv.org/abs/2411.04351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D视觉定位（VG）旨在根据自然语言描述定位3D场景中的相关对象或区域。现有方法在室内3D VG中表现良好，但不适用于户外环境，主要由于室内外点云分布的差异。&lt;h4&gt;目的&lt;/h4&gt;提出LidaRefer，一个专为大规模户外场景设计的基于变换器的3D VG框架。&lt;h4&gt;方法&lt;/h4&gt;在训练过程中引入了一种简单有效的定位方法，监督解码器的查询，不仅定位目标对象，还处理可能与目标混淆的模糊对象，通过学习空间关系和属性的差异来增强模型的区分能力。&lt;h4&gt;主要发现&lt;/h4&gt;LidaRefer在Talk2Car-3D数据集上实现了最先进的性能，在各种评估设置下显著改善了结果。&lt;h4&gt;结论&lt;/h4&gt;LidaRefer有效解决了室外3D VG中的计算和内存挑战，并提高了对模糊对象的区分能力。&lt;h4&gt;总结&lt;/h4&gt;通过LidaRefer框架，推动了3D视觉定位技术在户外环境中的应用，为自主驾驶提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D visual grounding (VG) aims to locate relevant objects or regions within 3Dscenes based on natural language descriptions. Although recent methods forindoor 3D VG have successfully transformer-based architectures to captureglobal contextual information and enable fine-grained cross-modal fusion, theyare unsuitable for outdoor environments due to differences in the distributionof point clouds between indoor and outdoor settings. Specifically, first,extensive LiDAR point clouds demand unacceptable computational and memoryresources within transformers due to the high-dimensional visual features.Second, dominant background points and empty spaces in sparse LiDAR pointclouds complicate cross-modal fusion owing to their irrelevant visualinformation. To address these challenges, we propose LidaRefer, atransformer-based 3D VG framework designed for large-scale outdoor scenes.Moreover, during training, we introduce a simple and effective localizationmethod, which supervises the decoder's queries to localize not only a targetobject but also ambiguous objects that might be confused as the target due tothe exhibition of similar attributes in a scene or the incorrect understandingof a language description. This supervision enhances the model's ability todistinguish ambiguous objects from a target by learning the differences intheir spatial relationships and attributes. LidaRefer achieves state-of-the-artperformance on Talk2Car-3D, a 3D VG dataset for autonomous driving, withsignificant improvements under various evaluation settings.</description>
      <author>example@mail.com (Yeong-Seung Baek, Heung-Seon Oh)</author>
      <guid isPermaLink="false">2411.04351v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Contrastive Learning via Gaussian Mixture Models</title>
      <link>http://arxiv.org/abs/2411.03517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习旨在从未标记数据中学习表示，通过一个损失函数使得一个点的嵌入接近其增强版本，而远离其他随机点的嵌入。&lt;h4&gt;目的&lt;/h4&gt;分析对比学习（特别是InfoNCE损失）在高斯混合模型中的维度降低情况。&lt;h4&gt;方法&lt;/h4&gt;将数据点的增强定义为来自同一混合成分的独立抽样，并研究InfoNCE在此背景下的表现。&lt;h4&gt;主要发现&lt;/h4&gt;普通的InfoNCE能够找到最佳的低维子空间，即使高斯分布不是各向同性，而普通的谱技术无法做到这一点。&lt;h4&gt;结论&lt;/h4&gt;对比学习在多模态对比学习算法（如CLIP）中，可以有效地学习费舍尔最优子集，滤除学习表示中的噪声。&lt;h4&gt;总结&lt;/h4&gt;对比学习在理论上尚未完全理解，但在高斯混合模型中表现出色，能够优化低维表示并去除噪声。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning attempts to learn representations from un-labeled data;it does so via a loss function that encourages the embedding of a point to beclose to that of its augmentations, and far from the embeddings of random otherpoints. This simple idea performs remarkably well, yet it is not preciselytheoretically understood why this is the case. In this paper we analyzecontrastive learning (specifically, the InfoNCE loss) in a natural context:dimensionality reduction in Gaussian Mixture Models. Crucially, we define anaugmentation of a data point as being another independent draw from the sameunderlying mixture component. We show that vanilla InfoNCE is able to find theoptimal lower-dimensional subspace even when the Gaussians are not isotropic --something that vanilla spectral techniques cannot do. We further extend ouranalyses to multi-modal contrastive learning algorithms (e.g., CLIP). In thissetting we show that contrastive learning learns the subset of fisher-optimalsubspace, effectively filtering out all the noise from the learntrepresentations.</description>
      <author>example@mail.com (Parikshit Bansal, Ali Kavis, Sujay Sanghavi)</author>
      <guid isPermaLink="false">2411.03517v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Exploiting Frequency Prior for Cross-Domain Few-Shot Learning</title>
      <link>http://arxiv.org/abs/2411.01432v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;元学习为少样本学习（FSL）提供了有前景的途径，使模型能够通过在源领域的合成FSL任务上的情节训练提取可推广的特征嵌入。&lt;h4&gt;目的&lt;/h4&gt;克服在目标任务与源领域任务存在偏差时元学习方法容易过拟合的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新框架，名为跨领域少样本学习的元利用频率先验，旨在全面利用跨领域可转移的图像先验，将每个图像分解为低频内容细节和高频结构特征。&lt;h4&gt;主要发现&lt;/h4&gt;通过将每个查询图像分解为高频和低频分量，并将其并行纳入特征嵌入网络，增强最终类别预测效果。&lt;h4&gt;结论&lt;/h4&gt;引入特征重构先验和预测一致性先验，分别鼓励原始查询图像与其分解频率分量之间的中间特征和最终类别预测的一致性，从而引导网络的元学习过程，学习可推广的图像特征嵌入，且在推理阶段不增加额外的计算成本。&lt;h4&gt;总结&lt;/h4&gt;该框架在多个跨领域少样本学习基准上建立了新的最先进结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Meta-learning offers a promising avenue for few-shot learning (FSL), enablingmodels to glean a generalizable feature embedding through episodic training onsynthetic FSL tasks in a source domain. Yet, in practical scenarios where thetarget task diverges from that in the source domain, meta-learning based methodis susceptible to over-fitting. To overcome this, we introduce a novelframework, Meta-Exploiting Frequency Prior for Cross-Domain Few-Shot Learning,which is crafted to comprehensively exploit the cross-domain transferable imageprior that each image can be decomposed into complementary low-frequencycontent details and high-frequency robust structural characteristics. Motivatedby this insight, we propose to decompose each query image into itshigh-frequency and low-frequency components, and parallel incorporate them intothe feature embedding network to enhance the final category prediction. Moreimportantly, we introduce a feature reconstruction prior and a predictionconsistency prior to separately encourage the consistency of the intermediatefeature as well as the final category prediction between the original queryimage and its decomposed frequency components. This allows for collectivelyguiding the network's meta-learning process with the aim of learninggeneralizable image feature embeddings, while not introducing any extracomputational cost in the inference phase. Our framework establishes newstate-of-the-art results on multiple cross-domain few-shot learning benchmarks.</description>
      <author>example@mail.com (Fei Zhou, Peng Wang, Lei Zhang, Zhenghua Chen, Wei Wei, Chen Ding, Guosheng Lin, Yanning Zhang)</author>
      <guid isPermaLink="false">2411.01432v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Energy Price Modelling: A Comparative Evaluation of four Generations of Forecasting Methods</title>
      <link>http://arxiv.org/abs/2411.03372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;能源是现代经济系统的重要驱动力。准确的能源价格预测在支持各级决策方面起着重要作用。&lt;h4&gt;目的&lt;/h4&gt;本论文旨在提供对能源价格预测方法的系统比较，填补文献中的空白。&lt;h4&gt;方法&lt;/h4&gt;对预测建模框架的演变进行了深入回顾，包括传统的计量经济模型、机器学习方法、LSTM等早期序列学习者以及最近的变压器网络深度学习进展。同时，探讨了预训练和迁移学习等新兴概念。&lt;h4&gt;主要发现&lt;/h4&gt;对四种模型家族的综合实证分析，使用欧盟能源市场的数据，比较不同方法的预测准确性，特别关注时间序列变压器的替代方案。&lt;h4&gt;结论&lt;/h4&gt;通过对不同预测方法的系统比较，提供了对能源价格预测领域的深入了解和指导。&lt;h4&gt;总结&lt;/h4&gt;该研究为未来能源价格预测的实践和研究方向提供了重要的见解和建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Energy is a critical driver of modern economic systems. Accurate energy priceforecasting plays an important role in supporting decision-making at variouslevels, from operational purchasing decisions at individual businessorganizations to policy-making. A significant body of literature has lookedinto energy price forecasting, investigating a wide range of methods to improveaccuracy and inform these critical decisions. Given the evolving landscape offorecasting techniques, the literature lacks a thorough empirical comparisonthat systematically contrasts these methods.  This paper provides an in-depth review of the evolution of forecastingmodeling frameworks, from well-established econometric models to machinelearning methods, early sequence learners such LSTMs, and more recentadvancements in deep learning with transformer networks, which represent thecutting edge in forecasting. We offer a detailed review of the relatedliterature and categorize forecasting methodologies into four model families.We also explore emerging concepts like pre-training and transfer learning,which have transformed the analysis of unstructured data and hold significantpromise for time series forecasting. We address a gap in the literature byperforming a comprehensive empirical analysis on these four family models,using data from the EU energy markets, we conduct a large-scale empiricalstudy, which contrasts the forecasting accuracy of different approaches,focusing especially on alternative propositions for time series transformers.</description>
      <author>example@mail.com (Alexandru-Victor Andrei, Georg Velev, Filip-Mihai Toma, Daniel Traian Pele, Stefan Lessmann)</author>
      <guid isPermaLink="false">2411.03372v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Towards Optimizing SQL Generation via LLM Routing</title>
      <link>http://arxiv.org/abs/2411.04319v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Table Representation Learning Workshop at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Text-to-SQL技术使用户能够通过自然语言与数据库交互，从而简化对结构化数据的访问。&lt;h4&gt;目的&lt;/h4&gt;提出一种首个用于Text-to-SQL的LLM路由方法，以动态选择最具成本效益的LLM来生成准确的SQL查询。&lt;h4&gt;方法&lt;/h4&gt;引入两种路由策略（基于评分和分类），旨在实现与最强LLM相当的准确性，同时降低成本，并设计便于训练和高效推理的路由器。&lt;h4&gt;主要发现&lt;/h4&gt;在BIRD数据集上的实验表明，所提出的方法在准确性和成本之间提供了实用且可解释的权衡。&lt;h4&gt;结论&lt;/h4&gt;通过动态路由选择，可以在保持高准确性的同时显著降低Text-to-SQL的成本和延迟。&lt;h4&gt;总结&lt;/h4&gt;本研究为Text-to-SQL领域提供了新的思路，通过路由机制优化LLM的使用，提升了查询效率和经济性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-to-SQL enables users to interact with databases through naturallanguage, simplifying access to structured data. Although highly capable largelanguage models (LLMs) achieve strong accuracy for complex queries, they incurunnecessary latency and dollar cost for simpler ones. In this paper, weintroduce the first LLM routing approach for Text-to-SQL, which dynamicallyselects the most cost-effective LLM capable of generating accurate SQL for eachquery. We present two routing strategies (score- and classification-based) thatachieve accuracy comparable to the most capable LLM while reducing costs. Wedesign the routers for ease of training and efficient inference. In ourexperiments, we highlight a practical and explainable accuracy-cost trade-offon the BIRD dataset.</description>
      <author>example@mail.com (Mohammadhossein Malekpour, Nour Shaheen, Foutse Khomh, Amine Mhedhbi)</author>
      <guid isPermaLink="false">2411.04319v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Fourier Filtering Network with Contrastive Learning for UAV-based Unaligned Bi-modal Salient Object Detection</title>
      <link>http://arxiv.org/abs/2411.03728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无人机（UAV）基于双模态显著目标检测（BSOD）旨在利用未对齐的RGB和热成像对中的互补线索分割场景中的显著目标。&lt;h4&gt;目的&lt;/h4&gt;解决现有UAV基于BSOD模型的高计算开销问题，以提高其在实际UAV设备中的适用性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种高效的傅里叶滤波网络与对比学习相结合的模型，通过语义对比对齐损失在语义层面对齐两种模态，并引入同步对齐融合来实现双模态特征在通道和空间维度的对齐与融合。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的AlignSal模型相比于最先进的BSOD模型（MROS）减少了70.0%的参数，降低了49.4%的浮点运算，并提高了152.5%的推理速度。&lt;h4&gt;结论&lt;/h4&gt;AlignSal在UAV RGB-T 2400及三个弱对齐数据集上的广泛实验表明，其实现了实时推理速度和更好的性能及泛化能力，相较于十六个最先进的BSOD模型在大多数评估指标上表现更优。&lt;h4&gt;总结&lt;/h4&gt;消融研究进一步验证了AlignSal在提升现有对齐BSOD模型在UAV基于未对齐数据上的性能潜力。代码可在：https://github.com/JoshuaLPF/AlignSal&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/joshualpf/alignsal&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unmanned aerial vehicle (UAV)-based bi-modal salient object detection (BSOD)aims to segment salient objects in a scene utilizing complementary cues inunaligned RGB and thermal image pairs. However, the high computational expenseof existing UAV-based BSOD models limits their applicability to real-world UAVdevices. To address this problem, we propose an efficient Fourier filternetwork with contrastive learning that achieves both real-time and accurateperformance. Specifically, we first design a semantic contrastive alignmentloss to align the two modalities at the semantic level, which facilitatesmutual refinement in a parameter-free way. Second, inspired by the fast Fouriertransform that obtains global relevance in linear complexity, we proposesynchronized alignment fusion, which aligns and fuses bi-modal features in thechannel and spatial dimensions by a hierarchical filtering mechanism. Ourproposed model, AlignSal, reduces the number of parameters by 70.0%, decreasesthe floating point operations by 49.4%, and increases the inference speed by152.5% compared to the cutting-edge BSOD model (i.e., MROS). Extensiveexperiments on the UAV RGB-T 2400 and three weakly aligned datasets demonstratethat AlignSal achieves both real-time inference speed and better performanceand generalizability compared to sixteen state-of-the-art BSOD models acrossmost evaluation metrics. In addition, our ablation studies further verifyAlignSal's potential in boosting the performance of existing aligned BSODmodels on UAV-based unaligned data. The code is available at:https://github.com/JoshuaLPF/AlignSal.</description>
      <author>example@mail.com (Pengfei Lyu, Pak-Hei Yeung, Xiufei Cheng, Xiaosheng Yu, Chengdong Wu, Jagath C. Rajapakse)</author>
      <guid isPermaLink="false">2411.03728v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Normalized Space Alignment: A Versatile Metric for Representation Analysis</title>
      <link>http://arxiv.org/abs/2411.04512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了一种用于神经网络表示的流形分析技术。&lt;h4&gt;目的&lt;/h4&gt;比较来自相同源且具有相同大小的两个点云之间的成对距离。&lt;h4&gt;方法&lt;/h4&gt;使用归一化空间对齐（NSA）技术，该技术可以作为分析工具和可微损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;NSA可以比较和对齐不同层和模型之间的表示，满足相似性度量和神经网络损失函数的标准。&lt;h4&gt;结论&lt;/h4&gt;NSA在表示空间分析、结构保持损失函数和鲁棒性分析工具方面表现出多功能性，且计算效率高。&lt;h4&gt;应用&lt;/h4&gt;在小批量训练中近似全局结构差异，适用于多种神经网络训练范式。&lt;h4&gt;总结&lt;/h4&gt;NSA是一种强大的工具，能够有效比较和对齐神经网络的表示，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a manifold analysis technique for neural networkrepresentations. Normalized Space Alignment (NSA) compares pairwise distancesbetween two point clouds derived from the same source and having the same size,while potentially possessing differing dimensionalities. NSA can act as both ananalytical tool and a differentiable loss function, providing a robust means ofcomparing and aligning representations across different layers and models. Itsatisfies the criteria necessary for both a similarity metric and a neuralnetwork loss function. We showcase NSA's versatility by illustrating itsutility as a representation space analysis metric, a structure-preserving lossfunction, and a robustness analysis tool. NSA is not only computationallyefficient but it can also approximate the global structural discrepancy duringmini-batching, facilitating its use in a wide variety of neural networktraining paradigms.</description>
      <author>example@mail.com (Danish Ebadulla, Aditya Gulati, Ambuj Singh)</author>
      <guid isPermaLink="false">2411.04512v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Exploiting the Segment Anything Model (SAM) for Lung Segmentation in Chest X-ray Images</title>
      <link>http://arxiv.org/abs/2411.03064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Segment Anything Model (SAM) 是Meta AI在2023年4月发布的一款新型AI模型，旨在通过语义解释识别和分离图像中的个体对象。&lt;h4&gt;目的&lt;/h4&gt;评估和研究胸部X光图像中的肺部分割性能，优化医疗领域的工作。&lt;h4&gt;方法&lt;/h4&gt;采用迁移学习中的微调技术来提高模型在肺部分割方面的性能。&lt;h4&gt;主要发现&lt;/h4&gt;经过调整后，SAM在评估指标上表现出显著改善，结果与先进的神经网络（如U-Net）相似。&lt;h4&gt;结论&lt;/h4&gt;该模型的调整使其在医疗图像处理方面的表现令人满意，展示了新技术在医学图像分析中的潜力。&lt;h4&gt;总结&lt;/h4&gt;SAM通过微调技术在肺部X光图像的分割任务中取得了良好的效果，证明了其在医疗应用中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Segment Anything Model (SAM), a new AI model from Meta AI released in April2023, is an ambitious tool designed to identify and separate individual objectswithin a given image through semantic interpretation. The advanced capabilitiesof SAM are the result of its training with millions of images and masks, and afew days after its release, several researchers began testing the model onmedical images to evaluate its performance in this domain. With thisperspective in focus -- i.e., optimizing work in the healthcare field -- thiswork proposes the use of this new technology to evaluate and study chest X-rayimages. The approach adopted for this work, with the aim of improving themodel's performance for lung segmentation, involved a transfer learningprocess, specifically the fine-tuning technique. After applying thisadjustment, a substantial improvement was observed in the evaluation metricsused to assess SAM's performance compared to the masks provided by thedatasets. The results obtained by the model after the adjustments weresatisfactory and similar to cutting-edge neural networks, such as U-Net.</description>
      <author>example@mail.com (Gabriel Bellon de Carvalho, Jurandy Almeida)</author>
      <guid isPermaLink="false">2411.03064v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Teaching Models to Improve on Tape</title>
      <link>http://arxiv.org/abs/2411.01483v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在生成特定约束下的内容时常常面临困难，但检查这些约束是否被满足相对简单。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过训练增强大型语言模型在特定约束下生成内容的能力。&lt;h4&gt;方法&lt;/h4&gt;引入一种强化学习框架CORGI（Controlled Generation with RL for Guided Interaction），通过模拟交互会话，根据模型满足约束的能力给予奖励。&lt;h4&gt;主要发现&lt;/h4&gt;CORGI在各种受控生成任务中表现 consistently 优于不考虑对话反馈的基线强化学习方法，并支持元学习，帮助模型在新任务中更好地进行引导交互。&lt;h4&gt;结论&lt;/h4&gt;结合对话优化和强化学习显著提高了大型语言模型在受控生成任务中的有效性。&lt;h4&gt;总结&lt;/h4&gt;CORGI方法通过强化学习和对话反馈提高了语言模型在特定约束下的生成能力，展示了其在受控生成任务中的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) often struggle when prompted to generate contentunder specific constraints. However, in such cases it is often easy to checkwhether these constraints are satisfied or violated. Recent works have shownthat LLMs can benefit from such "corrective feedback". Here we claim that thisskill of LLMs can be significantly enhanced via training. We introduce an RLframework for teaching models to use such rewards, by simulating interactionsessions, and rewarding the model according to its ability to satisfy theconstraints. We refer to our method as CORGI (Controlled Generation with RL forGuided Interaction), and evaluate it on a variety of controlled generationtasks using unlabeled training data. We find that CORGI consistentlyoutperforms the baseline reinforcement learning method that does notincorporate conversational feedback. Furthermore, CORGI's interactive frameworkenables meta-learning, allowing the LLM to generalize better to guidedinteraction in new tasks. Our results clearly show that conversationaloptimization, when combined with reinforcement learning, significantly improvesthe effectiveness of LLMs in controlled generation contexts.</description>
      <author>example@mail.com (Liat Bezalel, Eyal Orgad, Amir Globerson)</author>
      <guid isPermaLink="false">2411.01483v3</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Text2Freq: Learning Series Patterns from Text via Frequency Domain</title>
      <link>http://arxiv.org/abs/2411.00929v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures, and be accepted by NeurIPS 2024 Workshop: Time
  Series in the Age of Large Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的时间序列预测模型主要依赖历史数值来预测未来结果，但常常忽视其他模态（如特殊事件的文本描述）中丰富的信息，这些信息对未来动态提供重要见解。&lt;h4&gt;目的&lt;/h4&gt;研究在时间序列预测中联合使用文本信息，以弥补现有研究的不足。&lt;h4&gt;方法&lt;/h4&gt;提出了Text2Freq模型，通过频率域整合文本和时间序列数据，具体地将文本信息与时间序列数据的低频成分对齐。&lt;h4&gt;主要发现&lt;/h4&gt;Text2Freq在真实股票价格和合成文本的配对数据集上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;Text2Freq的适应性架构为未来在这一领域的研究提供了新的可能性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了跨模态学习在时间序列预测中的潜力，强调了文本信息的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional time series forecasting models mainly rely on historical numericvalues to predict future outcomes.While these models have shown promisingresults, they often overlook the rich information available in othermodalities, such as textual descriptions of special events, which can providecrucial insights into future dynamics.However, research that jointlyincorporates text in time series forecasting remains relatively underexploredcompared to other cross-modality work. Additionally, the modality gap betweentime series data and textual information poses a challenge for multimodallearning. To address this task, we propose Text2Freq, a cross-modality modelthat integrates text and time series data via the frequency domain.Specifically, our approach aligns textual information to the low-frequencycomponents of time series data, establishing more effective and interpretablealignments between these two modalities. Our experiments on paired datasets ofreal-world stock prices and synthetic texts show that Text2Freq achievesstate-of-the-art performance, with its adaptable architecture encouragingfuture research in this field.</description>
      <author>example@mail.com (Ming-Chih Lo, Ching Chang, Wen-Chih Peng)</author>
      <guid isPermaLink="false">2411.00929v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Zero-bias new particle searches using autoencoders in UPCs and diffractive events</title>
      <link>http://arxiv.org/abs/2411.00903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在低背景环境中（如CERN大型强子对撞机LHC的衍射事件和超外围碰撞），需要检测稀有粒子衰变和奇异强子。&lt;h4&gt;目的&lt;/h4&gt;应用无监督学习方法进行零偏差检测，以识别稀有衰变和异常事件。&lt;h4&gt;方法&lt;/h4&gt;使用模拟已知共振衰变的玩具数据集，构建自编码神经网络，专注于衰变动力学中的异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;自编码器成功区分典型衰变和稀有异常事件，重建误差的峰值对应于注入的稀有信号。&lt;h4&gt;结论&lt;/h4&gt;该方法在大规模对撞机数据中检测稀有、未预测过程方面显示出潜力，为发现超越标准模型的新物理提供了有效途径。&lt;h4&gt;总结&lt;/h4&gt;无监督学习在粒子物理中的应用促进了稀有粒子衰变的检测，为未来研究提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an application of unsupervised learning for zero-bias detection ofrare particle decays and exotic hadrons in low-background environments such asthose characteristic of diffractive events and ultraperipheral pp, p--A, orA--A collisions at the CERN Large Hadron Collider (LHC), or in e--A collisionsat the ePIC experiment at the future Electron-Ion Collider (EIC). Using a toydataset simulating the decays of known resonances, including$\ensuremath{{\mathrm J}/\psi}\xspace$ and {\ensuremath{\psi'}\xspace}, as wellas more exotic candidates, we implement an autoencoder neural network toidentify anomalies in the decay kinematics. The autoencoder, trained solely ontypical events, is designed to reconstruct normal decays with low error whileflagging anomalous decays based on the reconstruction error. We demonstratethat the autoencoder successfully separates typical decays from rare exoticevents, with peaks in the invariant mass distribution corresponding to theinjected rare signals. Our method shows promise in detecting rare, unpredictedprocesses in large-scale collider data, offering an effective approach fordiscovering new physics beyond the Standard Model.</description>
      <author>example@mail.com (Simone Ragoni, Janet Seger, Christopher Anson)</author>
      <guid isPermaLink="false">2411.00903v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Raising Body Ownership in End-to-End Visuomotor Policy Learning via Robot-Centric Pooling</title>
      <link>http://arxiv.org/abs/2411.04331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新的池化方法，名为Robot-centric Pooling (RcP)，旨在增强端到端的视觉运动策略。&lt;h4&gt;目的&lt;/h4&gt;通过区分机器人与相似实体或其周围环境，改善策略学习效果。&lt;h4&gt;方法&lt;/h4&gt;RcP利用图像-本体感知对，引导图像特征的聚合，突出与机器人本体状态相关的图像区域，从而提取以机器人为中心的图像表示。它与现有的视觉运动策略学习框架无缝集成，并与策略一起使用相同数据集进行联合训练，无需额外的数据收集。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和真实世界的到达任务中评估后，RcP显著增强了策略对不同位置的各种未见干扰物（包括自我干扰物）的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;RcP的机器人中心特性使得学习到的策略在面对激进的像素偏移时，比基线策略更加具有韧性。&lt;h4&gt;总结&lt;/h4&gt;RcP是一种创新的方法，通过强调与机器人状态相关的图像特征，显著提高了视觉运动策略的性能和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Robot-centric Pooling (RcP), a novel pooling method designed toenhance end-to-end visuomotor policies by enabling differentiation between therobots and similar entities or their surroundings. Given animage-proprioception pair, RcP guides the aggregation of image features byhighlighting image regions correlating with the robot's proprioceptive states,thereby extracting robot-centric image representations for policy learning.Leveraging contrastive learning techniques, RcP integrates seamlessly withexisting visuomotor policy learning frameworks and is trained jointly with thepolicy using the same dataset, requiring no extra data collection involvingself-distractors. We evaluate the proposed method with reaching tasks in bothsimulated and real-world settings. The results demonstrate that RcPsignificantly enhances the policies' robustness against various unseendistractors, including self-distractors, positioned at different locations.Additionally, the inherent robot-centric characteristic of RcP enables thelearnt policy to be far more resilient to aggressive pixel shifts compared tothe baselines.</description>
      <author>example@mail.com (Zheyu Zhuang, Ville Kyrki, Danica Kragic)</author>
      <guid isPermaLink="false">2411.04331v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Controlling Human Shape and Pose in Text-to-Image Diffusion Models via Domain Adaptation</title>
      <link>http://arxiv.org/abs/2411.04724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在预训练的文本到图像扩散模型中进行人类形状和姿势的条件控制。&lt;h4&gt;目的&lt;/h4&gt;开发一种方法，以有效利用合成数据生成新的条件控制，并解决合成数据与真实数据之间的领域差距。&lt;h4&gt;方法&lt;/h4&gt;提出一种领域适应技术，通过将合成训练的条件信息与控制网络结合，适应生成的图像到输入域。使用基于ControlNet的架构在合成SURREAL数据集上进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;我们的模型在形状和姿势多样性上优于基于2D姿势的ControlNet，同时保持视觉保真度并提高稳定性。&lt;h4&gt;结论&lt;/h4&gt;该方法在下游任务（如人类动画）中具有实用性。&lt;h4&gt;总结&lt;/h4&gt;通过合成数据和领域适应技术，提升了人类形状和姿势的生成质量与多样性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a methodology for conditional control of human shape and pose inpretrained text-to-image diffusion models using a 3D human parametric model(SMPL). Fine-tuning these diffusion models to adhere to new conditions requireslarge datasets and high-quality annotations, which can be more cost-effectivelyacquired through synthetic data generation rather than real-world data.However, the domain gap and low scene diversity of synthetic data cancompromise the pretrained model's visual fidelity. We propose adomain-adaptation technique that maintains image quality by isolatingsynthetically trained conditional information in the classifier-free guidancevector and composing it with another control network to adapt the generatedimages to the input domain. To achieve SMPL control, we fine-tune aControlNet-based architecture on the synthetic SURREAL dataset of renderedhumans and apply our domain adaptation at generation time. Experimentsdemonstrate that our model achieves greater shape and pose diversity than the2d pose-based ControlNet, while maintaining the visual fidelity and improvingstability, proving its usefulness for downstream tasks such as human animation.</description>
      <author>example@mail.com (Benito Buchheim, Max Reimann, Jürgen Döllner)</author>
      <guid isPermaLink="false">2411.04724v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups</title>
      <link>http://arxiv.org/abs/2411.01706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  37 pages, 16 figures, Accepted by EMNLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;复杂词识别（CWI）是词汇简化任务的重要步骤，近年来已成为一项独立任务。&lt;h4&gt;目的&lt;/h4&gt;研究大型语言模型（LLMs）在CWI、词汇复杂性预测（LCP）和多词表达的复杂性评估（MWE）中的使用。&lt;h4&gt;方法&lt;/h4&gt;评估开源模型（如Llama 2、Llama 3、Vicuna v1.5）和闭源模型（如ChatGPT-3.5-turbo和GPT-4o）在零-shot、少-shot和微调设置下的表现。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs在某些条件下表现不佳，或与现有方法的结果相当。&lt;h4&gt;结论&lt;/h4&gt;当前状态下，LLMs无法或几乎无法超越通常更小的现有方法。&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了LLMs在复杂词识别及相关任务中的局限性，并提出了结合元学习与提示学习的观点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/razvanalex-phd/cwi_llm&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex Word Identification (CWI) is an essential step in the lexicalsimplification task and has recently become a task on its own. Some variationsof this binary classification task have emerged, such as lexical complexityprediction (LCP) and complexity evaluation of multi-word expressions (MWE).Large language models (LLMs) recently became popular in the Natural LanguageProcessing community because of their versatility and capability to solveunseen tasks in zero/few-shot settings. Our work investigates LLM usage,specifically open-source models such as Llama 2, Llama 3, and Vicuna v1.5, andclosed-source, such as ChatGPT-3.5-turbo and GPT-4o, in the CWI, LCP, and MWEsettings. We evaluate zero-shot, few-shot, and fine-tuning settings and showthat LLMs struggle in certain conditions or achieve comparable results againstexisting methods. In addition, we provide some views on meta-learning combinedwith prompt learning. In the end, we conclude that the current state of LLMscannot or barely outperform existing methods, which are usually much smaller.</description>
      <author>example@mail.com (Răzvan-Alexandru Smădu, David-Gabriel Ion, Dumitru-Clementin Cercel, Florin Pop, Mihaela-Claudia Cercel)</author>
      <guid isPermaLink="false">2411.01706v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Proxy-informed Bayesian transfer learning with unknown sources</title>
      <link>http://arxiv.org/abs/2411.03263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;泛化能力需要利用关于不同数据源之间转移效果的先验知识。&lt;h4&gt;目的&lt;/h4&gt;解决在未知源数据点和无法微调目标任务的情况下的迁移学习问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种代理信息驱动的稳健概率迁移学习方法(PROBPT)，不需要目标任务的结果信息。&lt;h4&gt;主要发现&lt;/h4&gt;PROMPT使用代理信息进行目标任务效果的估计和源数据的稳健重加权，从而有效降低负迁移风险。&lt;h4&gt;结论&lt;/h4&gt;通过理论结果和在两个合成场景中的应用，证明了PROMPT方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;PROMPT方法为在复杂迁移学习场景中提供了一种有效的解决方案，利用代理信息改善效果估计和源数据重加权。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalization outside the scope of one's training data requires leveragingprior knowledge about the effects that transfer, and the effects that don't,between different data sources. Bayesian transfer learning is a principledparadigm for specifying this knowledge, and refining it on the basis of datafrom the source (training) and target (prediction) tasks. We address thechallenging transfer learning setting where the learner (i) cannot fine-tune inthe target task, and (ii) does not know which source data points correspond tothe same task (i.e., the data sources are unknown). We propose a proxy-informedrobust method for probabilistic transfer learning (PROMPT), which provides aposterior predictive estimate tailored to the structure of the target task,without requiring the learner have access to any outcome information from thetarget task. Instead, PROMPT relies on the availability of proxy information.PROMPT uses the same proxy information for two purposes: (i) estimation ofeffects specific to the target task, and (ii) construction of a robustreweighting of the source data for estimation of effects that transfer betweentasks. We provide theoretical results on the effect of this reweighting on therisk of negative transfer, and demonstrate application of PROMPT in twosynthetic settings.</description>
      <author>example@mail.com (Sabina J. Sloman, Julien Martinelli, Samuel Kaski)</author>
      <guid isPermaLink="false">2411.03263v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Multi-Modality Dynamics: Insights and Challenges in Multimodal Fusion for Biomedical Tasks</title>
      <link>http://arxiv.org/abs/2411.00725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文研究Han等人（2022）提出的MM dynamics方法，该方法用于生物医学分类任务中的多模态融合。&lt;h4&gt;目的&lt;/h4&gt;探讨MM dynamics算法在多模态融合中的应用及其对分类性能的影响。&lt;h4&gt;方法&lt;/h4&gt;MM dynamics算法结合特征级和模态级的信息有效性，动态融合模态以提升分类性能。&lt;h4&gt;主要发现&lt;/h4&gt;分析显示特征信息的有效性能提高性能和可解释性，而模态信息的有效性并未显著优势，甚至可能导致性能下降。&lt;h4&gt;结论&lt;/h4&gt;基于研究结果，将特征信息的有效性扩展至图像数据，开发了Image MM dynamics，尽管该方法在定性上表现出色，但在定量上未超过基线方法。&lt;h4&gt;总结&lt;/h4&gt;MM dynamics方法在生物医学分类中有潜力，但存在局限性，特别是在模态信息的有效性方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the MM dynamics approach proposed by Han et al.(2022) for multi-modal fusion in biomedical classification tasks. The MMdynamics algorithm integrates feature-level and modality-level informativenessto dynamically fuse modalities for improved classification performance.However, our analysis reveals several limitations and challenges in replicatingand extending the results of MM dynamics. We found that feature informativenessimproves performance and explainability, while modality informativeness doesnot provide significant advantages and can lead to performance degradation.Based on these results, we have extended feature informativeness to image data,resulting in the development of Image MM dynamics. Although this approachshowed promising qualitative results, it did not outperform baseline methodsquantitatively.</description>
      <author>example@mail.com (Laura Wenderoth)</author>
      <guid isPermaLink="false">2411.00725v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Cybercrime Prediction via Geographically Weighted Learning</title>
      <link>http://arxiv.org/abs/2411.04635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 8 figures, Submitted to the International Jordanian
  Cybersecurity Conference 2024 (IJCC24)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;受地理加权回归成功的启发，提出了一种考虑地理纬度和经度的图神经网络模型GeogGNN。&lt;h4&gt;目的&lt;/h4&gt;在网络安全领域解决4类分类问题，使用合成生成的数据集。&lt;h4&gt;方法&lt;/h4&gt;在海湾合作委员会地区的看似真实的地理坐标上应用GeogGNN算法。&lt;h4&gt;主要发现&lt;/h4&gt;GeogGNN模型在准确性上优于标准神经网络和卷积神经网络，这些网络将坐标视为特征。&lt;h4&gt;结论&lt;/h4&gt;Geometrically weighted neural network在空间依赖数据的分类中原则上总是能显示更高的准确性，利用空间连续性和局部平均特征。&lt;h4&gt;总结&lt;/h4&gt;GeogGNN模型通过考虑地理信息大幅提升了模型的分类精度，展现了图神经网络在处理空间数据中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inspired by the success of Geographically Weighted Regression and itsaccounting for spatial variations, we propose GeogGNN -- A graph neural networkmodel that accounts for geographical latitude and longitudinal points. Using asynthetically generated dataset, we apply the algorithm for a 4-classclassification problem in cybersecurity with seemingly realistic geographiccoordinates centered in the Gulf Cooperation Council region. We demonstratethat it has higher accuracy than standard neural networks and convolutionalneural networks that treat the coordinates as features. Encouraged by thespeed-up in model accuracy by the GeogGNN model, we provide a generalmathematical result that demonstrates that a geometrically weighted neuralnetwork will, in principle, always display higher accuracy in theclassification of spatially dependent data by making use of spatial continuityand local averaging features.</description>
      <author>example@mail.com (Muhammad Al-Zafar Khan, Jamal Al-Karaki, Emad Mahafzah)</author>
      <guid isPermaLink="false">2411.04635v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>ACCIO: Table Understanding Enhanced via Contrastive Learning with Aggregations</title>
      <link>http://arxiv.org/abs/2411.04443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，自然语言模型在表格理解方面的关注度不断增加，但大多数相关工作直接关注表格的结构学习。&lt;h4&gt;目的&lt;/h4&gt;提出ACCIO方法，通过对比学习增强表格理解能力。&lt;h4&gt;方法&lt;/h4&gt;ACCIO通过对比原始表格及其核心摘要，训练编码器将这些表格对拉近，从而实现表格理解的提升。&lt;h4&gt;主要发现&lt;/h4&gt;通过列类型注释验证，ACCIO在宏观F1分数上达到91.1，表现与现有最先进的方法相竞争。&lt;h4&gt;结论&lt;/h4&gt;这是首次利用表格对进行表格嵌入的尝试，预示着表格理解的重要进展。&lt;h4&gt;总结&lt;/h4&gt;ACCIO展现了对比学习在表格理解中的潜力，代码可在GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/whnhch/accio&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The attention to table understanding using recent natural language models hasbeen growing. However, most related works tend to focus on learning thestructure of the table directly. Just as humans improve their understanding ofsentences by comparing them, they can also enhance their understanding bycomparing tables. With this idea, in this paper, we introduce ACCIO, tAbleunderstanding enhanCed via Contrastive learnIng with aggregatiOns, a novelapproach to enhancing table understanding by contrasting original tables withtheir pivot summaries through contrastive learning. ACCIO trains an encoder tobring these table pairs closer together. Through validation via column typeannotation, ACCIO achieves competitive performance with a macro F1 score of91.1 compared to state-of-the-art methods. This work represents the firstattempt to utilize pairs of tables for table embedding, promising significantadvancements in table comprehension. Our code is available athttps://github.com/whnhch/ACCIO/.</description>
      <author>example@mail.com (Whanhee Cho)</author>
      <guid isPermaLink="false">2411.04443v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Cross Feature Fusion of Fundus Image and Generated Lesion Map for Referable Diabetic Retinopathy Classification</title>
      <link>http://arxiv.org/abs/2411.03618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACCV 2024 accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;糖尿病视网膜病变（DR）是导致失明的主要原因，迫切需要早期检测和诊断。&lt;h4&gt;目的&lt;/h4&gt;本论文旨在提高可参考糖尿病视网膜病变分类的方法在临床实践中的适用性。&lt;h4&gt;方法&lt;/h4&gt;开发了一种先进的交叉学习DR分类方法，利用迁移学习和交叉注意力机制，采用Swin U-Net架构对DR眼底图像中的病变进行分割。&lt;h4&gt;主要发现&lt;/h4&gt;在FGADR和EyePACS两个公共数据集上的实验表明，模型的准确率达到94.6%，比现有的最先进方法提高了4.4%。&lt;h4&gt;结论&lt;/h4&gt;期望所提出的方法能够无缝集成到临床工作流程中，提高可参考DR的识别准确性和效率。&lt;h4&gt;总结&lt;/h4&gt;本研究通过创新的深度学习方法，为糖尿病视网膜病变的早期检测提供了有效的技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diabetic Retinopathy (DR) is a primary cause of blindness, necessitatingearly detection and diagnosis. This paper focuses on referable DRclassification to enhance the applicability of the proposed method in clinicalpractice. We develop an advanced cross-learning DR classification methodleveraging transfer learning and cross-attention mechanisms. The proposedmethod employs the Swin U-Net architecture to segment lesion maps from DRfundus images. The Swin U-Net segmentation model, enriched with DR lesioninsights, is transferred to generate a lesion map. Both the fundus image andits segmented lesion map are used as complementary inputs for theclassification model. A cross-attention mechanism is deployed to improve themodel's ability to capture fine-grained details from the input pairs. Ourexperiments, utilizing two public datasets, FGADR and EyePACS, demonstrate asuperior accuracy of 94.6%, surpassing current state-of-the-art methods by4.4%. To this end, we aim for the proposed method to be seamlessly integratedinto clinical workflows, enhancing accuracy and efficiency in identifyingreferable DR.</description>
      <author>example@mail.com (Dahyun Mok, Junghyun Bum, Le Duc Tai, Hyunseung Choo)</author>
      <guid isPermaLink="false">2411.03618v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Transferable Sequential Recommendation via Vector Quantized Meta Learning</title>
      <link>http://arxiv.org/abs/2411.01785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to BigData 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;顺序推荐在捕捉用户-物品转变模式方面取得了显著进展，但在跨领域转移大型推荐系统时仍面临挑战，因为用户和物品组在不同领域间不一致。&lt;h4&gt;目的&lt;/h4&gt;提出一种向可转移顺序推荐系统（MetaRec）应用向量量化元学习的方法。&lt;h4&gt;方法&lt;/h4&gt;不需要额外的模态或跨领域共享信息，利用多个源领域的用户-物品交互来提高目标领域的性能。通过向量量化解决输入异构性问题，将物品嵌入映射到共享特征空间。此外，采用元转移范式利用有限的目标数据指导源领域知识向目标领域的转移。&lt;h4&gt;主要发现&lt;/h4&gt;MetaRec通过基于源-目标领域相似性重新缩放元梯度，从多个源任务自适应转移，能够选择性学习以提高推荐性能。&lt;h4&gt;结论&lt;/h4&gt;在基准数据集上的广泛实验验证了我们的方法的有效性，MetaRec的性能显著优于基线方法。&lt;h4&gt;总结&lt;/h4&gt;MetaRec通过创新的方法在多个源领域的知识转移上表现出色，有效解决了跨领域推荐中的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While sequential recommendation achieves significant progress on capturinguser-item transition patterns, transferring such large-scale recommendersystems remains challenging due to the disjoint user and item groups acrossdomains. In this paper, we propose a vector quantized meta learning fortransferable sequential recommenders (MetaRec). Without requiring additionalmodalities or shared information across domains, our approach leveragesuser-item interactions from multiple source domains to improve the targetdomain performance. To solve the input heterogeneity issue, we adopt vectorquantization that maps item embeddings from heterogeneous input spaces to ashared feature space. Moreover, our meta transfer paradigm exploits limitedtarget data to guide the transfer of source domain knowledge to the targetdomain (i.e., learn to transfer). In addition, MetaRec adaptively transfersfrom multiple source tasks by rescaling meta gradients based on thesource-target domain similarity, enabling selective learning to improverecommendation performance. To validate the effectiveness of our approach, weperform extensive experiments on benchmark datasets, where MetaRec consistentlyoutperforms baseline methods by a considerable margin.</description>
      <author>example@mail.com (Zhenrui Yue, Huimin Zeng, Yang Zhang, Julian McAuley, Dong Wang)</author>
      <guid isPermaLink="false">2411.01785v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Classifier-guided Gradient Modulation for Enhanced Multimodal Learning</title>
      <link>http://arxiv.org/abs/2411.01409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态学习近年来发展迅速，但模型在训练过程中倾向于依赖单一模态，导致其他模态的使用不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，平衡多模态学习，解决现有方法在损失函数、优化器和模态数量上的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入分类器引导的梯度调制（CGGM），同时考虑梯度的大小和方向。&lt;h4&gt;主要发现&lt;/h4&gt;在四个多模态数据集（UPMC-Food 101、CMU-MOSI、IEMOCAP 和 BraTS 2021）上的实验结果显示，CGGM在分类、回归和分割任务上均优于所有基线和其他先进方法。&lt;h4&gt;结论&lt;/h4&gt;CGGM方法具有有效性和通用性，能够提升多模态学习的表现。&lt;h4&gt;总结&lt;/h4&gt;研究结果表明，CGGM在处理多模态学习时提供了更好的平衡和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zrguo/cggm&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning has developed very fast in recent years. However, duringthe multimodal training process, the model tends to rely on only one modalitybased on which it could learn faster, thus leading to inadequate use of othermodalities. Existing methods to balance the training process always have somelimitations on the loss functions, optimizers and the number of modalities andonly consider modulating the magnitude of the gradients while ignoring thedirections of the gradients. To solve these problems, in this paper, we presenta novel method to balance multimodal learning with Classifier-Guided GradientModulation (CGGM), considering both the magnitude and directions of thegradients. We conduct extensive experiments on four multimodal datasets:UPMC-Food 101, CMU-MOSI, IEMOCAP and BraTS 2021, covering classification,regression and segmentation tasks. The results show that CGGM outperforms allthe baselines and other state-of-the-art methods consistently, demonstratingits effectiveness and versatility. Our code is available athttps://github.com/zrguo/CGGM.</description>
      <author>example@mail.com (Zirun Guo, Tao Jin, Jingyuan Chen, Zhou Zhao)</author>
      <guid isPermaLink="false">2411.01409v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>OneProt: Towards Multi-Modal Protein Foundation Models</title>
      <link>http://arxiv.org/abs/2411.04863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 15 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，人工智能的进步使得多模态系统能够建模和翻译多样的信息空间。&lt;h4&gt;目的&lt;/h4&gt;介绍OneProt，一种整合结构、序列、比对和结合位点数据的多模态AI，专注于蛋白质。&lt;h4&gt;方法&lt;/h4&gt;使用ImageBind框架，OneProt对模态编码器的潜在空间进行对齐，特别是沿蛋白质序列。&lt;h4&gt;主要发现&lt;/h4&gt;OneProt在检索任务中表现出色，并在金属离子结合分类、基因本体注释和酶功能预测等多个下游任务中超过了最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;本研究扩展了蛋白质模型的多模态能力，为药物发现、生物催化反应规划和蛋白质工程等应用铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;OneProt展示了在多模态AI应用于蛋白质研究中的潜力，为相关领域的进一步发展提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/klemens-floege/oneprot&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent AI advances have enabled multi-modal systems to model and translatediverse information spaces. Extending beyond text and vision, we introduceOneProt, a multi-modal AI for proteins that integrates structural, sequence,alignment, and binding site data. Using the ImageBind framework, OneProt alignsthe latent spaces of modality encoders along protein sequences. It demonstratesstrong performance in retrieval tasks and surpasses state-of-the-art methods invarious downstream tasks, including metal ion binding classification,gene-ontology annotation, and enzyme function prediction. This work expandsmulti-modal capabilities in protein models, paving the way for applications indrug discovery, biocatalytic reaction planning, and protein engineering.</description>
      <author>example@mail.com (Klemens Flöge, Srisruthi Udayakumar, Johanna Sommer, Marie Piraud, Stefan Kesselheim, Vincent Fortuin, Stephan Günneman, Karel J van der Weg, Holger Gohlke, Alina Bazarova, Erinc Merdivan)</author>
      <guid isPermaLink="false">2411.04863v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Fine-tuning -- a Transfer Learning approach</title>
      <link>http://arxiv.org/abs/2411.03941v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;电子健康记录（EHRs）的二次研究常因缺失数据的丰富性而受到阻碍。缺失数据是由于常规临床护理中的数据记录实践自然产生的。&lt;h4&gt;目的&lt;/h4&gt;处理缺失数据对于医学分析的精确性及后续决策至关重要。&lt;h4&gt;方法&lt;/h4&gt;文献中存在多种基于深度神经网络的填补方法，旨在克服EHRs中动态、异质和多变量的缺失模式，这些是传统统计填补方法无法处理的。&lt;h4&gt;主要发现&lt;/h4&gt;现有的深度填补方法依赖端到端的流程，结合填补和下游分析（如分类），这使得评估填补质量变得困难，并限制了填补工具在不同任务中的灵活性。&lt;h4&gt;结论&lt;/h4&gt;大多数端到端深度架构使用复杂的网络进行下游任务，可能导致难以判断文献中报告的高性能是归因于填补器还是分类器。通过使用优化的最先进填补器，简单的分类器也能实现相似的性能。&lt;h4&gt;总结&lt;/h4&gt;本文探索了一种模块化的基于深度学习的填补和分类流程，旨在独立评估填补器和分类器的质量，并利用优化的填补器来测试更简单分类架构的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Secondary research use of Electronic Health Records (EHRs) is often hamperedby the abundance of missing data in this valuable resource. Missingness in EHRsoccurs naturally as a result of the data recording practices during routineclinical care, but handling it is crucial to the precision of medical analysisand the decision-making that follows. The literature contains a variety ofimputation methodologies based on deep neural networks. Those aim to overcomethe dynamic, heterogeneous and multivariate missingness patterns of EHRs, whichcannot be handled by classical and statistical imputation methods. However, allexisting deep imputation methods rely on end-to-end pipelines that incorporateboth imputation and downstream analyses, e.g. classification. This couplingmakes it difficult to assess the quality of imputation and takes away theflexibility of re-using the imputer for a different task. Furthermore, mostend-to-end deep architectures tend to use complex networks to perform thedownstream task, in addition to the already sophisticated deep imputationnetwork. We, therefore ask if the high performance reported in the literatureis due to the imputer or the classifier and further ask if an optimisedstate-of-the-art imputer is used, a simpler classifier can achieve comparableperformance. This paper explores the development of a modular, deeplearning-based imputation and classification pipeline, specifically built toleverage the capabilities of state-of-the-art imputation models for downstreamclassification tasks. Such a modular approach enables a) objective assessmentof the quality of the imputer and classifier independently, and b) enables theexploration of the performance of simpler classification architectures using anoptimised imputer.</description>
      <author>example@mail.com (Joseph Arul Raj, Linglong Qian, Zina Ibrahim)</author>
      <guid isPermaLink="false">2411.03941v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset</title>
      <link>http://arxiv.org/abs/2411.04865v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to WACV 2025 (IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV))&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;立面语义分割在摄影测量和计算机视觉中是一个长期挑战，现有方法缺乏全面的立面类别和涵盖建筑多样性的数据。&lt;h4&gt;目的&lt;/h4&gt;引入立面泛化级别（LoFG），设计新的分层立面类别，以确保与现实世界复杂类别的兼容性和方法比较的统一性。&lt;h4&gt;方法&lt;/h4&gt;推出当前最大的语义3D立面分割数据集，提供601百万个标注点，涵盖LoFG2和LoFG3的五个和十五个类别。&lt;h4&gt;主要发现&lt;/h4&gt;分析了基线语义分割方法在引入的LoFG类别和数据上的性能，并讨论了立面分割中未解决的挑战。&lt;h4&gt;结论&lt;/h4&gt;ZAHA将促进3D立面语义分割方法的进一步发展，推动城市数字双胞胎的创建所需的稳健分割技术。&lt;h4&gt;总结&lt;/h4&gt;本研究为立面分割提供了新的标准和数据集，期望推动相关领域的研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/oloocki/zaha&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Facade semantic segmentation is a long-standing challenge in photogrammetryand computer vision. Although the last decades have witnessed the influx offacade segmentation methods, there is a lack of comprehensive facade classesand data covering the architectural variability. In ZAHA, we introduce Level ofFacade Generalization (LoFG), novel hierarchical facade classes designed basedon international urban modeling standards, ensuring compatibility withreal-world challenging classes and uniform methods' comparison. Realizing theLoFG, we present to date the largest semantic 3D facade segmentation dataset,providing 601 million annotated points at five and 15 classes of LoFG2 andLoFG3, respectively. Moreover, we analyze the performance of baseline semanticsegmentation methods on our introduced LoFG classes and data, complementing itwith a discussion on the unresolved challenges for facade segmentation. Wefirmly believe that ZAHA shall facilitate further development of 3D facadesemantic segmentation methods, enabling robust segmentation indispensable increating urban digital twins.</description>
      <author>example@mail.com (Olaf Wysocki, Yue Tan, Thomas Froech, Yan Xia, Magdalena Wysocki, Ludwig Hoegner, Daniel Cremers, Christoph Holst)</author>
      <guid isPermaLink="false">2411.04865v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Learning Where to Edit Vision Transformers</title>
      <link>http://arxiv.org/abs/2411.01948v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模型编辑旨在高效地纠正大型预训练模型的预测错误，同时确保对邻近错误的泛化能力和对无关示例的最小影响。&lt;h4&gt;目的&lt;/h4&gt;针对计算机视觉中的视觉Transformer（ViTs），研究有效的编辑策略，尤其是应对子人群变化引起的预测错误。&lt;h4&gt;方法&lt;/h4&gt;采用定位后编辑的方法，通过在CutMix增强数据上进行元学习，训练超网络以生成通用的二进制掩码，识别结构化模型参数的稀疏子集，并利用梯度下降的变体微调这些参数进行编辑。&lt;h4&gt;主要发现&lt;/h4&gt;构建了一个编辑基准，引入子人群变化，揭示了预训练ViTs在物体识别中的局限性。&lt;h4&gt;结论&lt;/h4&gt;该方法在提出的基准上表现优越，并允许在泛化能力和局部性之间进行可调节的权衡。&lt;h4&gt;总结&lt;/h4&gt;研究为视觉Transformer的编辑提供了初步步骤，展示了针对特定问题的有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hustyyq/where-to-edit&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model editing aims to data-efficiently correct predictive errors of largepre-trained models while ensuring generalization to neighboring failures andlocality to minimize unintended effects on unrelated examples. Whilesignificant progress has been made in editing Transformer-based large languagemodels, effective strategies for editing vision Transformers (ViTs) in computervision remain largely untapped. In this paper, we take initial steps towardscorrecting predictive errors of ViTs, particularly those arising fromsubpopulation shifts. Taking a locate-then-edit approach, we first address thewhere-to-edit challenge by meta-learning a hypernetwork on CutMix-augmenteddata generated for editing reliability. This trained hypernetwork producesgeneralizable binary masks that identify a sparse subset of structured modelparameters, responsive to real-world failure samples. Afterward, we solve thehow-to-edit problem by simply fine-tuning the identified parameters using avariant of gradient descent to achieve successful edits. To validate ourmethod, we construct an editing benchmark that introduces subpopulation shiftstowards natural underrepresented images and AI-generated images, therebyrevealing the limitations of pre-trained ViTs for object recognition. Ourapproach not only achieves superior performance on the proposed benchmark butalso allows for adjustable trade-offs between generalization and locality. Ourcode is available at https://github.com/hustyyq/Where-to-Edit.</description>
      <author>example@mail.com (Yunqiao Yang, Long-Kai Huang, Shengzhuang Chen, Kede Ma, Ying Wei)</author>
      <guid isPermaLink="false">2411.01948v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>GAFusion: Adaptive Fusing LiDAR and Camera with Multiple Guidance for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.00340v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，基于鸟瞰视角的3D多模态目标检测方法取得了显著进展，但大多数方法忽视了LiDAR与相机之间的互补交互和指导。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的多模态3D目标检测方法，命名为GAFusion，以实现LiDAR引导的全局交互和自适应融合。&lt;h4&gt;方法&lt;/h4&gt;引入稀疏深度引导（SDG）和LiDAR占用引导（LOG）来生成具有充分深度信息的3D特征；开发LiDAR引导的自适应融合变换器（LGAFT），增强不同模态BEV特征的全局交互；设计稀疏高度压缩和多尺度双路径变换器（MSDPT）以扩大不同模态特征的感受野；引入时间融合模块以聚合前帧特征。&lt;h4&gt;主要发现&lt;/h4&gt;GAFusion在nuScenes测试集上实现了73.6%的mAP和74.9%的NDS，达到了当前最先进的3D目标检测结果。&lt;h4&gt;结论&lt;/h4&gt;GAFusion通过引导和融合不同模态的特征，显著提升了3D目标检测的性能。&lt;h4&gt;总结&lt;/h4&gt;该研究表明，LiDAR与相机的互补利用能够有效地改善3D目标检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent years have witnessed the remarkable progress of 3D multi-modalityobject detection methods based on the Bird's-Eye-View (BEV) perspective.However, most of them overlook the complementary interaction and guidancebetween LiDAR and camera. In this work, we propose a novel multi-modality 3Dobjection detection method, named GAFusion, with LiDAR-guided globalinteraction and adaptive fusion. Specifically, we introduce sparse depthguidance (SDG) and LiDAR occupancy guidance (LOG) to generate 3D features withsufficient depth information. In the following, LiDAR-guided adaptive fusiontransformer (LGAFT) is developed to adaptively enhance the interaction ofdifferent modal BEV features from a global perspective. Meanwhile, additionaldownsampling with sparse height compression and multi-scale dual-pathtransformer (MSDPT) are designed to enlarge the receptive fields of differentmodal features. Finally, a temporal fusion module is introduced to aggregatefeatures from previous frames. GAFusion achieves state-of-the-art 3D objectdetection results with 73.6$\%$ mAP and 74.9$\%$ NDS on the nuScenes test set.</description>
      <author>example@mail.com (Xiaotian Li, Baojie Fan, Jiandong Tian, Huijie Fan)</author>
      <guid isPermaLink="false">2411.00340v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>GUI Agents with Foundation Models: A Comprehensive Survey</title>
      <link>http://arxiv.org/abs/2411.04890v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型的进展，尤其是大型语言模型（LLMs）和多模态大型语言模型（MLLMs），使智能体能够执行复杂任务。&lt;h4&gt;目的&lt;/h4&gt;整合近期关于基于(M)LLM的GUI智能体的研究，突出数据、框架和应用的关键创新。&lt;h4&gt;方法&lt;/h4&gt;讨论代表性的数据集和基准，概述统一框架及其分类，探索商业应用。&lt;h4&gt;主要发现&lt;/h4&gt;识别出若干关键挑战，并提出未来研究方向。&lt;h4&gt;结论&lt;/h4&gt;期望本论文能激励基于(M)LLM的GUI智能体领域的进一步发展。&lt;h4&gt;总结&lt;/h4&gt;通过模拟人类交互（如点击和输入），这些智能体能够自主执行用户指令。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in foundation models, particularly Large Language Models(LLMs) and Multimodal Large Language Models (MLLMs), facilitate intelligentagents being capable of performing complex tasks. By leveraging the ability of(M)LLMs to process and interpret Graphical User Interfaces (GUIs), these agentscan autonomously execute user instructions by simulating human-likeinteractions such as clicking and typing. This survey consolidates recentresearch on (M)LLM-based GUI agents, highlighting key innovations in data,frameworks, and applications. We begin by discussing representative datasetsand benchmarks. Next, we summarize a unified framework that captures theessential components used in prior research, accompanied by a taxonomy.Additionally, we explore commercial applications of (M)LLM-based GUI agents.Drawing from existing work, we identify several key challenges and proposefuture research directions. We hope this paper will inspire furtherdevelopments in the field of (M)LLM-based GUI agents.</description>
      <author>example@mail.com (Shuai Wang, Weiwen Liu, Jingxuan Chen, Weinan Gan, Xingshan Zeng, Shuai Yu, Xinlong Hao, Kun Shao, Yasheng Wang, Ruiming Tang)</author>
      <guid isPermaLink="false">2411.04890v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM</title>
      <link>http://arxiv.org/abs/2411.04954v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://cad-mllm.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;设计一个统一的计算机辅助设计（CAD）生成系统，能够根据用户的文本描述、图像、点云或其组合轻松生成CAD模型。&lt;h4&gt;目的&lt;/h4&gt;介绍CAD-MLLM，这是第一个能够根据多模态输入生成参数化CAD模型的系统。&lt;h4&gt;方法&lt;/h4&gt;在CAD-MLLM框架内，利用CAD模型的命令序列，使用先进的大型语言模型（LLMs）对多模态数据和CAD模型的向量表示进行特征空间对齐，并设计了一套全面的数据构建和注释管道。&lt;h4&gt;主要发现&lt;/h4&gt;生成的数据集Omni-CAD是首个包含文本描述、多视图图像、点云和命令序列的多模态CAD数据集，约有450K实例及其CAD构建序列。通过引入评估拓扑质量和表面封闭程度的新指标，评估生成CAD模型的质量。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，CAD-MLLM在条件生成方法方面显著优于现有技术，并对噪声和缺失点保持高度鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;该研究为CAD模型生成提供了一种新的多模态方法，推动了计算机辅助设计领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper aims to design a unified Computer-Aided Design (CAD) generationsystem that can easily generate CAD models based on the user's inputs in theform of textual description, images, point clouds, or even a combination ofthem. Towards this goal, we introduce the CAD-MLLM, the first system capable ofgenerating parametric CAD models conditioned on the multimodal input.Specifically, within the CAD-MLLM framework, we leverage the command sequencesof CAD models and then employ advanced large language models (LLMs) to alignthe feature space across these diverse multi-modalities data and CAD models'vectorized representations. To facilitate the model training, we design acomprehensive data construction and annotation pipeline that equips each CADmodel with corresponding multimodal data. Our resulting dataset, namedOmni-CAD, is the first multimodal CAD dataset that contains textualdescription, multi-view images, points, and command sequence for each CADmodel. It contains approximately 450K instances and their CAD constructionsequences. To thoroughly evaluate the quality of our generated CAD models, wego beyond current evaluation metrics that focus on reconstruction quality byintroducing additional metrics that assess topology quality and surfaceenclosure extent. Extensive experimental results demonstrate that CAD-MLLMsignificantly outperforms existing conditional generative methods and remainshighly robust to noises and missing points. The project page and morevisualizations can be found at: https://cad-mllm.github.io/</description>
      <author>example@mail.com (Jingwei Xu, Chenyu Wang, Zibo Zhao, Wen Liu, Yi Ma, Shenghua Gao)</author>
      <guid isPermaLink="false">2411.04954v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Bronchoscopy Depth Estimation through Synthetic-to-Real Domain Adaptation</title>
      <link>http://arxiv.org/abs/2411.04404v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;单目深度估计在一般成像任务中显示出潜力，能够帮助定位和3D重建。&lt;h4&gt;目的&lt;/h4&gt;克服在支气管镜图像应用中的标注数据缺乏问题，以提高深度估计的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出一种迁移学习框架，利用带深度标签的合成数据进行训练，并适应领域知识以提高真实支气管镜数据的深度估计。&lt;h4&gt;主要发现&lt;/h4&gt;与仅使用合成数据训练相比，经过领域适应的网络在真实视频上展示了更好的深度预测能力。&lt;h4&gt;结论&lt;/h4&gt;验证了所提方法的有效性，表明迁移学习在支气管镜图像深度估计中的应用是可行的。&lt;h4&gt;总结&lt;/h4&gt;通过迁移学习和领域适应，提高了支气管镜图像中深度估计的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular depth estimation has shown promise in general imaging tasks, aidingin localization and 3D reconstruction. While effective in various domains, itsapplication to bronchoscopic images is hindered by the lack of labeled data,challenging the use of supervised learning methods. In this work, we propose atransfer learning framework that leverages synthetic data with depth labels fortraining and adapts domain knowledge for accurate depth estimation in realbronchoscope data. Our network demonstrates improved depth prediction on realfootage using domain adaptation compared to training solely on synthetic data,validating our approach.</description>
      <author>example@mail.com (Qingyao Tian, Huai Liao, Xinyan Huang, Lujie Li, Hongbin Liu)</author>
      <guid isPermaLink="false">2411.04404v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Decision Trees for Interpretable Clusters in Mixture Models and Deep Representations</title>
      <link>http://arxiv.org/abs/2411.01576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;决策树是可解释机器学习的核心之一，通常作为黑箱模型的可解释替代方案。最近，对决策树在无监督学习中的应用产生了浓厚兴趣。&lt;h4&gt;目的&lt;/h4&gt;引入解释性与噪声比的概念，以明确决策树在聚类任务中能够有效恢复数据的底层分布。&lt;h4&gt;方法&lt;/h4&gt;提出一种算法，输入混合模型，构建适合的决策树，并假设混合成分的次高斯性，证明了结果决策树的误差率的上下界。&lt;h4&gt;主要发现&lt;/h4&gt;通过实证研究，验证了该方法在标准表格数据和图像数据集上的有效性。&lt;h4&gt;结论&lt;/h4&gt;良好聚类的数据可以通过决策树得到很好的解释，提出的算法能有效扩展到神经网络的可解释聚类。&lt;h4&gt;总结&lt;/h4&gt;该研究为决策树在无监督学习中的应用提供了新的视角，并展示了其在不同数据类型上的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decision Trees are one of the backbones of explainable machine learning, andoften serve as interpretable alternatives to black-box models. Traditionallyutilized in the supervised setting, there has recently also been a surge ofinterest in decision trees for unsupervised learning. While several works withworst-case guarantees on the clustering cost have appeared, these results aredistribution-agnostic, and do not give insight into when decision trees canactually recover the underlying distribution of the data (up to some smallerror). In this paper, we therefore introduce the notion of anexplainability-to-noise ratio for mixture models, formalizing the intuitionthat well-clustered data can indeed be explained well using a decision tree. Wepropose an algorithm that takes as input a mixture model and constructs asuitable tree in data-independent time. Assuming sub-Gaussianity of the mixturecomponents, we prove upper and lower bounds on the error rate of the resultingdecision tree. In addition, we demonstrate how concept activation vectors canbe used to extend explainable clustering to neural networks. We empiricallydemonstrate the efficacy of our approach on standard tabular and imagedatasets.</description>
      <author>example@mail.com (Maximilian Fleissner, Maedeh Zarvandi, Debarghya Ghoshdastidar)</author>
      <guid isPermaLink="false">2411.01576v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>One for All: Multi-Domain Joint Training for Point Cloud Based 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.01584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前计算机视觉的趋势是利用一个通用模型来处理各种任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够在不同领域进行3D物体检测的通用模型OneDet3D。&lt;h4&gt;方法&lt;/h4&gt;通过多域数据联合训练学习多个问题场景，采用域感知分区和路由机制解决数据干扰问题，同时结合文本模态进行语言引导分类。&lt;h4&gt;主要发现&lt;/h4&gt;OneDet3D展示出强大的通用能力，能够仅使用一个训练模型处理几乎所有3D物体检测任务。&lt;h4&gt;结论&lt;/h4&gt;OneDet3D有效地解决了不同数据集之间的领域间干扰和类别干扰问题。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种在多样场景中进行3D检测的有效方法，推动了通用模型的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The current trend in computer vision is to utilize one universal model toaddress all various tasks. Achieving such a universal model inevitably requiresincorporating multi-domain data for joint training to learn across multipleproblem scenarios. In point cloud based 3D object detection, however, suchmulti-domain joint training is highly challenging, because large domain gapsamong point clouds from different datasets lead to the severedomain-interference problem. In this paper, we propose \textbf{OneDet3D}, auniversal one-for-all model that addresses 3D detection across differentdomains, including diverse indoor and outdoor scenes, within the \emph{same}framework and only \emph{one} set of parameters. We propose the domain-awarepartitioning in scatter and context, guided by a routing mechanism, to addressthe data interference issue, and further incorporate the text modality for alanguage-guided classification to unify the multi-dataset label spaces andmitigate the category interference issue. The fully sparse structure andanchor-free head further accommodate point clouds with significant scaledisparities. Extensive experiments demonstrate the strong universal ability ofOneDet3D to utilize only one trained model for addressing almost all 3D objectdetection tasks.</description>
      <author>example@mail.com (Zhenyu Wang, Yali Li, Hengshuang Zhao, Shengjin Wang)</author>
      <guid isPermaLink="false">2411.01584v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>In the Era of Prompt Learning with Vision-Language Models</title>
      <link>http://arxiv.org/abs/2411.04892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICVGIP 2024, Young Faculty Symposium&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模基础模型如CLIP在零样本泛化方面表现强劲，但在领域转移时遇到困难，限制了其适应性。&lt;h4&gt;目的&lt;/h4&gt;引入一种新的领域无关的提示学习策略StyLIP，以增强领域泛化能力。&lt;h4&gt;方法&lt;/h4&gt;StyLIP通过视觉编码器中的样式投影器解耦视觉样式和内容，学习领域特定的提示标记，并与内容特征结合。通过对比训练，该方法实现了跨领域的无缝适应。&lt;h4&gt;主要发现&lt;/h4&gt;StyLIP在多个领域泛化基准上超越了现有的最先进方法。此外，我们提出了AD-CLIP用于无监督领域适应，通过图像样式和内容特征学习领域不变的提示。&lt;h4&gt;结论&lt;/h4&gt;AD-CLIP通过熵最小化在嵌入空间对齐领域，能够有效应对领域转移，即使只有目标领域样本可用。同时，强调了未来在遥感中使用提示学习进行类发现的研究，特别是识别非结构化环境中的新类或稀有类。&lt;h4&gt;总结&lt;/h4&gt;这些工作为在复杂现实场景中实现更具适应性和泛化能力的模型铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale foundation models like CLIP have shown strong zero-shotgeneralization but struggle with domain shifts, limiting their adaptability. Inour work, we introduce \textsc{StyLIP}, a novel domain-agnostic prompt learningstrategy for Domain Generalization (DG). StyLIP disentangles visual style andcontent in CLIP`s vision encoder by using style projectors to learndomain-specific prompt tokens and combining them with content features. Trainedcontrastively, this approach enables seamless adaptation across domains,outperforming state-of-the-art methods on multiple DG benchmarks. Additionally,we propose AD-CLIP for unsupervised domain adaptation (DA), leveraging CLIP`sfrozen vision backbone to learn domain-invariant prompts through image styleand content features. By aligning domains in embedding space with entropyminimization, AD-CLIP effectively handles domain shifts, even when only targetdomain samples are available. Lastly, we outline future work on class discoveryusing prompt learning for semantic segmentation in remote sensing, focusing onidentifying novel or rare classes in unstructured environments. This paves theway for more adaptive and generalizable models in complex, real-worldscenarios.</description>
      <author>example@mail.com (Ankit Jha)</author>
      <guid isPermaLink="false">2411.04892v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Centrality Graph Shift Operators for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.04655v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图移位算子（GSO），如邻接矩阵和图拉普拉斯矩阵，在图论和图表示学习中具有基础性作用。&lt;h4&gt;目的&lt;/h4&gt;提出并研究中心性图移位算子（CGSO），以全球中心性指标规范化邻接矩阵。&lt;h4&gt;方法&lt;/h4&gt;通过使用PageRank、k-核或固定长度游走计数等全球中心性指标，研究CGSO的光谱特性，并定义基于不同CGSO的光谱聚类算法。&lt;h4&gt;主要发现&lt;/h4&gt;CGSO在图信号处理中的作用得到理解，并在多个合成和真实数据集上验证了光谱聚类算法的有效性。&lt;h4&gt;结论&lt;/h4&gt;CGSO可以作为图神经网络中的消息传递算子，尤其在图卷积网络和图注意力网络中表现出色，适用于多个真实世界基准数据集。&lt;h4&gt;总结&lt;/h4&gt;CGSO提供了一种新的视角，利用全球中心性指标改进图信号处理和图神经网络的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/abbahaddou/CGSO&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Shift Operators (GSOs), such as the adjacency and graph Laplacianmatrices, play a fundamental role in graph theory and graph representationlearning. Traditional GSOs are typically constructed by normalizing theadjacency matrix by the degree matrix, a local centrality metric. In this work,we instead propose and study Centrality GSOs (CGSOs), which normalize adjacencymatrices by global centrality metrics such as the PageRank, $k$-core or countof fixed length walks. We study spectral properties of the CGSOs, allowing usto get an understanding of their action on graph signals. We confirm thisunderstanding by defining and running the spectral clustering algorithm basedon different CGSOs on several synthetic and real-world datasets. We furthermoreoutline how our CGSO can act as the message passing operator in any GraphNeural Network and in particular demonstrate strong performance of a variant ofthe Graph Convolutional Network and Graph Attention Network using our CGSOs onseveral real-world benchmark datasets.</description>
      <author>example@mail.com (Yassine Abbahaddou, Fragkiskos D. Malliaros, Johannes F. Lutzeyer, Michalis Vazirgiannis)</author>
      <guid isPermaLink="false">2411.04655v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>VAIR: Visuo-Acoustic Implicit Representations for Low-Cost, Multi-Modal Transparent Surface Reconstruction in Indoor Scenes</title>
      <link>http://arxiv.org/abs/2411.04963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://umfieldrobotics.github.io/VAIR_site/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;室内移动机器人需要在具有透明表面的复杂场景中导航。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，通过隐式神经表示融合声学和视觉传感方式，实现透明表面的密集重建。&lt;h4&gt;方法&lt;/h4&gt;使用生成潜在优化学习包含透明表面的室内场景的隐式表示，能够在图像空间进行体积渲染或3D几何重建（点云或网格），并预测透明表面。&lt;h4&gt;主要发现&lt;/h4&gt;在使用自定义低成本传感平台（包含RGB-D摄像头和超声波传感器）收集的新数据集上，对方法的定性和定量评估表明，重建透明表面显著优于当前先进技术。&lt;h4&gt;结论&lt;/h4&gt;方法在透明表面重建方面展现出显著的改进。&lt;h4&gt;总结&lt;/h4&gt;该研究为室内机器人在复杂环境中有效导航提供了新的技术路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robots operating indoors must be prepared to navigate challengingscenes that contain transparent surfaces. This paper proposes a novel methodfor the fusion of acoustic and visual sensing modalities through implicitneural representations to enable dense reconstruction of transparent surfacesin indoor scenes. We propose a novel model that leverages generative latentoptimization to learn an implicit representation of indoor scenes consisting oftransparent surfaces. We demonstrate that we can query the implicitrepresentation to enable volumetric rendering in image space or 3D geometryreconstruction (point clouds or mesh) with transparent surface prediction. Weevaluate our method's effectiveness qualitatively and quantitatively on a newdataset collected using a custom, low-cost sensing platform featuring RGB-Dcameras and ultrasonic sensors. Our method exhibits significant improvementover state-of-the-art for transparent surface reconstruction.</description>
      <author>example@mail.com (Advaith V. Sethuraman, Onur Bagoren, Harikrishnan Seetharaman, Dalton Richardson, Joseph Taylor, Katherine A. Skinner)</author>
      <guid isPermaLink="false">2411.04963v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic-Attention-based EEG State Transition Modeling for Emotion Recognition</title>
      <link>http://arxiv.org/abs/2411.04568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于脑电图（EEG）的情感解码可以客观量化人们的情感状态，在人机交互和情感障碍早期检测中具有广泛的应用前景。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种新的建模方法，以更好地捕捉EEG信号的复杂时空动态，进而提高情感解码的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于动态注意力的EEG状态转移建模方法（DAEST），提取EEG的时空成分，并在这些成分上估计动态注意力权重，以捕捉大脑状态的转变。模型在对比学习框架内进行优化，以实现跨主体的情感识别。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在三个公开数据集（FACED、SEED 和 SEED-V）上实现了最先进的性能，其中在FACED数据集上实现了75.4%的二分类准确率，SEED数据集上实现了88.1%的三分类准确率，以及在SEED-V数据集上实现了73.6%的五分类准确率。&lt;h4&gt;结论&lt;/h4&gt;学习到的EEG时空模式和动态转移特性为情感处理背后的神经动力学提供了宝贵的见解。&lt;h4&gt;总结&lt;/h4&gt;本研究通过动态注意力机制提升了EEG情感解码的准确性，为理解情感处理提供了新的方法和思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electroencephalogram (EEG)-based emotion decoding can objectively quantifypeople's emotional state and has broad application prospects in human-computerinteraction and early detection of emotional disorders. Recently emerging deeplearning architectures have significantly improved the performance of EEGemotion decoding. However, existing methods still fall short of fully capturingthe complex spatiotemporal dynamics of neural signals, which are crucial forrepresenting emotion processing. This study proposes a Dynamic-Attention-basedEEG State Transition (DAEST) modeling method to characterize EEG spatiotemporaldynamics. The model extracts spatiotemporal components of EEG that representmultiple parallel neural processes and estimates dynamic attention weights onthese components to capture transitions in brain states. The model is optimizedwithin a contrastive learning framework for cross-subject emotion recognition.The proposed method achieved state-of-the-art performance on three publiclyavailable datasets: FACED, SEED, and SEED-V. It achieved 75.4% accuracy in thebinary classification of positive and negative emotions and 59.3% in nine-classdiscrete emotion classification on the FACED dataset, 88.1% in the three-classclassification of positive, negative, and neutral emotions on the SEED dataset,and 73.6% in five-class discrete emotion classification on the SEED-V dataset.The learned EEG spatiotemporal patterns and dynamic transition properties offervaluable insights into neural dynamics underlying emotion processing.</description>
      <author>example@mail.com (Xinke Shen, Runmin Gan, Kaixuan Wang, Shuyi Yang, Qingzhu Zhang, Quanying Liu, Dan Zhang, Sen Song)</author>
      <guid isPermaLink="false">2411.04568v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Learning predictable and robust neural representations by straightening image sequences</title>
      <link>http://arxiv.org/abs/2411.01777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预测是所有生物的基本能力，并被认为是学习感知表示的目标。&lt;h4&gt;目的&lt;/h4&gt;开发一种自监督学习目标，以量化和促进神经表示的直线化。&lt;h4&gt;方法&lt;/h4&gt;在平滑渲染的合成图像序列上训练深度前馈神经网络，这些序列模拟自然视频的常见特性。&lt;h4&gt;主要发现&lt;/h4&gt;所学模型包含可预测的神经嵌入，并能够分解物体的几何、光度和语义特征，这些表示对噪声和对抗攻击更具鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过使用直线化目标作为正则化器，这些有益特性可以转移到其他训练程序，表明直线化作为鲁棒无监督学习原则的广泛实用性。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了自监督学习目标在提高神经网络预测能力和鲁棒性方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/xyniu1/learning-by-straightening&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prediction is a fundamental capability of all living organisms, and has beenproposed as an objective for learning sensory representations. Recent workdemonstrates that in primate visual systems, prediction is facilitated byneural representations that follow straighter temporal trajectories than theirinitial photoreceptor encoding, which allows for prediction by linearextrapolation. Inspired by these experimental findings, we develop aself-supervised learning (SSL) objective that explicitly quantifies andpromotes straightening. We demonstrate the power of this objective in trainingdeep feedforward neural networks on smoothly-rendered synthetic image sequencesthat mimic commonly-occurring properties of natural videos. The learned modelcontains neural embeddings that are predictive, but also factorize thegeometric, photometric, and semantic attributes of objects. The representationsalso prove more robust to noise and adversarial attacks compared to previousSSL methods that optimize for invariance to random augmentations. Moreover,these beneficial properties can be transferred to other training procedures byusing the straightening objective as a regularizer, suggesting a broaderutility for straightening as a principle for robust unsupervised learning.</description>
      <author>example@mail.com (Xueyan Niu, Cristina Savin, Eero P. Simoncelli)</author>
      <guid isPermaLink="false">2411.01777v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Feature Aggregation and Scale-Aware Regression for Monocular 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.02747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;单目3D物体检测因其简单和低成本受到广泛关注。&lt;h4&gt;目的&lt;/h4&gt;提出MonoASRH框架，以解决现有方法在全球意识和小规模物体检测方面的不足。&lt;h4&gt;方法&lt;/h4&gt;MonoASRH由高效混合特征聚合模块(EH-FAM)和自适应尺度感知3D回归头(ASRH)组成，EH-FAM利用多头注意力和轻量级卷积模块聚合不同尺度的视觉特征，ASRH则通过尺度-语义特征融合模块将2D边界框维度与聚合的语义特征结合。&lt;h4&gt;主要发现&lt;/h4&gt;MonoASRH在KITTI和Waymo数据集上表现出色，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该框架有效提升了小规模物体的检测能力，并改善了特征表示和背景噪声问题。&lt;h4&gt;总结&lt;/h4&gt;MonoASRH为单目3D物体检测提供了新的思路，强调了尺度感知的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/WYFDUT/MonoASRH&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D object detection has attracted great attention due to simplicityand low cost. Existing methods typically follow conventional 2D detectionparadigms, first locating object centers and then predicting 3D attributes vianeighboring features. However, these methods predominantly rely on progressivecross-scale feature aggregation and focus solely on local information, whichmay result in a lack of global awareness and the omission of small-scaleobjects. In addition, due to large variation in object scales across differentscenes and depths, inaccurate receptive fields often lead to background noiseand degraded feature representation. To address these issues, we introducesMonoASRH, a novel monocular 3D detection framework composed of Efficient HybridFeature Aggregation Module (EH-FAM) and Adaptive Scale-Aware 3D Regression Head(ASRH). Specifically, EH-FAM employs multi-head attention with a globalreceptive field to extract semantic features for small-scale objects andleverages lightweight convolutional modules to efficiently aggregate visualfeatures across different scales. The ASRH encodes 2D bounding box dimensionsand then fuses scale features with the semantic features aggregated by EH-FAMthrough a scale-semantic feature fusion module. The scale-semantic featurefusion module guides ASRH in learning dynamic receptive field offsets,incorporating scale priors into 3D position prediction for betterscale-awareness. Extensive experiments on the KITTI and Waymo datasetsdemonstrate that MonoASRH achieves state-of-the-art performance.</description>
      <author>example@mail.com (Yifan Wang, Xiaochen Yang, Fanqi Pu, Qingmin Liao, Wenming Yang)</author>
      <guid isPermaLink="false">2411.02747v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Toward Robust Incomplete Multimodal Sentiment Analysis via Hierarchical Representation Learning</title>
      <link>http://arxiv.org/abs/2411.02793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态情感分析（MSA）旨在通过多种模态理解和识别人类情感，融合多模态信息有助于提升情感分析效果。&lt;h4&gt;目的&lt;/h4&gt;提出一种层次化表示学习框架（HRLF），以解决实际应用中模态缺失的不确定性对多模态建模的影响。&lt;h4&gt;方法&lt;/h4&gt;设计了细粒度表示分解模块，通过跨模态转换和情感语义重建，将模态分解为与情感相关和模态特定的表示。同时，引入层次互信息最大化机制，逐步最大化多尺度表示之间的互信息，并提出层次对抗学习机制以适应情感相关表示的潜在分布。&lt;h4&gt;主要发现&lt;/h4&gt;在三个数据集上的综合实验表明，HRLF在不确定模态缺失的情况下显著提升了MSA性能。&lt;h4&gt;结论&lt;/h4&gt;HRLF有效地克服了模态缺失对多模态情感分析的负面影响，增强了模型的鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的HRLF框架为处理多模态情感分析中的模态不确定性提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Sentiment Analysis (MSA) is an important research area that aimsto understand and recognize human sentiment through multiple modalities. Thecomplementary information provided by multimodal fusion promotes bettersentiment analysis compared to utilizing only a single modality. Nevertheless,in real-world applications, many unavoidable factors may lead to situations ofuncertain modality missing, thus hindering the effectiveness of multimodalmodeling and degrading the model's performance. To this end, we propose aHierarchical Representation Learning Framework (HRLF) for the MSA task underuncertain missing modalities. Specifically, we propose a fine-grainedrepresentation factorization module that sufficiently extracts valuablesentiment information by factorizing modality into sentiment-relevant andmodality-specific representations through crossmodal translation and sentimentsemantic reconstruction. Moreover, a hierarchical mutual informationmaximization mechanism is introduced to incrementally maximize the mutualinformation between multi-scale representations to align and reconstruct thehigh-level semantics in the representations. Ultimately, we propose ahierarchical adversarial learning mechanism that further aligns and adapts thelatent distribution of sentiment-relevant representations to produce robustjoint multimodal representations. Comprehensive experiments on three datasetsdemonstrate that HRLF significantly improves MSA performance under uncertainmodality missing cases.</description>
      <author>example@mail.com (Mingcheng Li, Dingkang Yang, Yang Liu, Shunli Wang, Jiawei Chen, Shuaibing Wang, Jinjie Wei, Yue Jiang, Qingyao Xu, Xiaolu Hou, Mingyang Sun, Ziyun Qian, Dongliang Kou, Lihua Zhang)</author>
      <guid isPermaLink="false">2411.02793v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>CRT-Fusion: Camera, Radar, Temporal Fusion Using Motion Information for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.03013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确和稳健的3D物体检测是自主车辆和机器人技术中的关键组成部分。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架CRT-Fusion，集成时间信息以解决动态物体检测中的挑战。&lt;h4&gt;方法&lt;/h4&gt;框架包含三个关键模块：多视角融合（MVF）、运动特征估计器（MFE）和运动引导时间融合（MGTF）。MVF融合雷达和图像特征，生成更精确的统一鸟瞰视图（BEV）表示；MFE同时进行像素级速度信息估计和BEV分割；MGTF基于速度和占用分数图，在多个时间戳间对特征图进行对齐和融合。&lt;h4&gt;主要发现&lt;/h4&gt;CRT-Fusion在nuScenes数据集上表现出色，NDS指标提高了1.7%，mAP提高了1.4%。&lt;h4&gt;结论&lt;/h4&gt;CRT-Fusion通过考虑动态物体的运动，显著提高了3D物体检测的准确性和鲁棒性，展示了其融合策略的有效性。&lt;h4&gt;总结&lt;/h4&gt;CRT-Fusion为雷达-摄像头融合的3D物体检测提供了一种创新的方法，显示出在复杂场景中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and robust 3D object detection is a critical component in autonomousvehicles and robotics. While recent radar-camera fusion methods have madesignificant progress by fusing information in the bird's-eye view (BEV)representation, they often struggle to effectively capture the motion ofdynamic objects, leading to limited performance in real-world scenarios. Inthis paper, we introduce CRT-Fusion, a novel framework that integrates temporalinformation into radar-camera fusion to address this challenge. Our approachcomprises three key modules: Multi-View Fusion (MVF), Motion Feature Estimator(MFE), and Motion Guided Temporal Fusion (MGTF). The MVF module fuses radar andimage features within both the camera view and bird's-eye view, therebygenerating a more precise unified BEV representation. The MFE module conductstwo simultaneous tasks: estimation of pixel-wise velocity information and BEVsegmentation. Based on the velocity and the occupancy score map obtained fromthe MFE module, the MGTF module aligns and fuses feature maps across multipletimestamps in a recurrent manner. By considering the motion of dynamic objects,CRT-Fusion can produce robust BEV feature maps, thereby improving detectionaccuracy and robustness. Extensive evaluations on the challenging nuScenesdataset demonstrate that CRT-Fusion achieves state-of-the-art performance forradar-camera-based 3D object detection. Our approach outperforms the previousbest method in terms of NDS by +1.7%, while also surpassing the leadingapproach in mAP by +1.4%. These significant improvements in both metricsshowcase the effectiveness of our proposed fusion strategy in enhancing thereliability and accuracy of 3D object detection.</description>
      <author>example@mail.com (Jisong Kim, Minjae Seong, Jun Won Choi)</author>
      <guid isPermaLink="false">2411.03013v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Non-Euclidean Mixture Model for Social Network Embedding</title>
      <link>http://arxiv.org/abs/2411.04876v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社交网络链接的形成主要源于同质性或社会影响。&lt;h4&gt;目的&lt;/h4&gt;理解链接的生成，通过提供一种新颖的基于嵌入的图形成模型。&lt;h4&gt;方法&lt;/h4&gt;将链接生成建模为两个因素的混合模型，分别在球面空间和超曲面空间中处理同质性和影响因素，并设计特殊投影对齐这两个空间。&lt;h4&gt;主要发现&lt;/h4&gt;NMM-GNN在社交网络生成和分类任务上显著优于现有的最先进基线，能够更好地解释社交网络的形成机制。&lt;h4&gt;结论&lt;/h4&gt;NMM-GNN通过统一框架学习嵌入，展示了其在社交网络生成中的有效性。&lt;h4&gt;总结&lt;/h4&gt;该模型提供了一种新的视角，结合非欧几里得几何空间，深入探讨社交网络链接生成的过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/roshnigiyer/nmm&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; It is largely agreed that social network links are formed due to eitherhomophily or social influence. Inspired by this, we aim at understanding thegeneration of links via providing a novel embedding-based graph formationmodel. Different from existing graph representation learning, where linkgeneration probabilities are defined as a simple function of the correspondingnode embeddings, we model the link generation as a mixture model of the twofactors. In addition, we model the homophily factor in spherical space and theinfluence factor in hyperbolic space to accommodate the fact that (1) homophilyresults in cycles and (2) influence results in hierarchies in networks. We alsodesign a special projection to align these two spaces. We call this modelNon-Euclidean Mixture Model, i.e., NMM. We further integrate NMM with ournon-Euclidean graph variational autoencoder (VAE) framework, NMM-GNN. NMM-GNNlearns embeddings through a unified framework which uses non-Euclidean GNNencoders, non-Euclidean Gaussian priors, a non-Euclidean decoder, and a novelspace unification loss component to unify distinct non-Euclidean geometricspaces. Experiments on public datasets show NMM-GNN significantly outperformsstate-of-the-art baselines on social network generation and classificationtasks, demonstrating its ability to better explain how the social network isformed.</description>
      <author>example@mail.com (Roshni G. Iyer, Yewen Wang, Wei Wang, Yizhou Sun)</author>
      <guid isPermaLink="false">2411.04876v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Behavioral Sequence Modeling with Ensemble Learning</title>
      <link>http://arxiv.org/abs/2411.02174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究序列分析在行为建模中的应用，强调序列上下文在理解人类行为时的重要性。&lt;h4&gt;目的&lt;/h4&gt;将医疗、金融和电子商务等领域的常见问题框架化为序列建模任务。&lt;h4&gt;方法&lt;/h4&gt;提出基于隐马尔可夫模型的集成框架，具有轻量、可解释和高效的特点。&lt;h4&gt;主要发现&lt;/h4&gt;集成评分方法能够在不同长度的序列中进行稳健比较，并在数据不平衡或稀缺的情况下提高性能。&lt;h4&gt;结论&lt;/h4&gt;该框架在实际场景中可扩展，兼容下游基于特征的建模，适用于监督和无监督学习设置，并通过对纵向人类行为数据集的结果展示了方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;序列分析在行为建模中具有重要价值，特别是在数据处理和模型性能提升方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the use of sequence analysis for behavior modeling,emphasizing that sequential context often outweighs the value of aggregatefeatures in understanding human behavior. We discuss framing common problems infields like healthcare, finance, and e-commerce as sequence modeling tasks, andaddress challenges related to constructing coherent sequences from fragmenteddata and disentangling complex behavior patterns. We present a framework forsequence modeling using Ensembles of Hidden Markov Models, which arelightweight, interpretable, and efficient. Our ensemble-based scoring methodenables robust comparison across sequences of different lengths and enhancesperformance in scenarios with imbalanced or scarce data. The framework scalesin real-world scenarios, is compatible with downstream feature-based modeling,and is applicable in both supervised and unsupervised learning settings. Wedemonstrate the effectiveness of our method with results on a longitudinalhuman behavior dataset.</description>
      <author>example@mail.com (Maxime Kawawa-Beaudan, Srijan Sood, Soham Palande, Ganapathy Mani, Tucker Balch, Manuela Veloso)</author>
      <guid isPermaLink="false">2411.02174v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>SpecRaGE: Robust and Generalizable Multi-view Spectral Representation Learning</title>
      <link>http://arxiv.org/abs/2411.02138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多视图表示学习（MvRL）近年来受到广泛关注，因其在处理和分析多源数据方面的需求不断增加。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架SpecRaGE，旨在克服现有基于图拉普拉斯方法的MvRL在泛化能力和可扩展性上的挑战。&lt;h4&gt;方法&lt;/h4&gt;SpecRaGE结合图拉普拉斯方法与深度学习，使用神经网络学习参数映射，以近似图拉普拉斯的联合对角化，避免了对齐的需求。&lt;h4&gt;主要发现&lt;/h4&gt;SpecRaGE在处理受污染的数据时表现优于现有的最先进方法，尤其是在噪声和异常值存在的情况下。&lt;h4&gt;结论&lt;/h4&gt;SpecRaGE为更可靠和高效的多视图学习铺平了道路，代码将在论文接受后公开。&lt;h4&gt;总结&lt;/h4&gt;通过引入动态适应数据质量的元学习融合模块，SpecRaGE确保了对异常值和噪声视图的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view representation learning (MvRL) has garnered substantial attentionin recent years, driven by the increasing demand for applications that caneffectively process and analyze data from multiple sources. In this context,graph Laplacian-based MvRL methods have demonstrated remarkable success inrepresenting multi-view data. However, these methods often struggle withgeneralization to new data and face challenges with scalability. Moreover, inmany practical scenarios, multi-view data is contaminated by noise or outliers.In such cases, modern deep-learning-based MvRL approaches that rely onalignment or contrastive objectives can lead to misleading results, as they mayimpose incorrect consistency between clear and corrupted data sources. Weintroduce $\textit{SpecRaGE}$, a novel fusion-based framework that integratesthe strengths of graph Laplacian methods with the power of deep learning toovercome these challenges. SpecRage uses neural networks to learn parametricmapping that approximates a joint diagonalization of graph Laplacians. Thissolution bypasses the need for alignment while enabling generalizable andscalable learning of informative and meaningful representations. Moreover, itincorporates a meta-learning fusion module that dynamically adapts to dataquality, ensuring robustness against outliers and noisy views. Our extensiveexperiments demonstrate that SpecRaGE outperforms state-of-the-art methods,particularly in scenarios with data contamination, paving the way for morereliable and efficient multi-view learning. Our code will be made publiclyavailable upon acceptance.</description>
      <author>example@mail.com (Amitai Yacobi, Ofir Lindenbaum, Uri Shaham)</author>
      <guid isPermaLink="false">2411.02138v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>AutoGameUI: Constructing High-Fidelity Game UIs via Multimodal Learning and Interactive Web-Based Tool</title>
      <link>http://arxiv.org/abs/2411.03709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在游戏开发中，集成不一致的用户界面（UI）和用户体验（UX）设计通常导致不匹配和低效的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一个创新系统AutoGameUI，以高效构建一致的游戏用户界面。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段多模态学习管道，获取UI和UX设计的全面表示，并建立它们之间的对应关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过对应关系，系统能够从成对设计中自动构建一致的用户界面，并在实验中证明了其在维护构建接口与原始设计一致性方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;引入通用数据协议以实现精确设计描述和跨平台应用，同时开发了一个互动网页工具以方便游戏开发者使用该系统。&lt;h4&gt;总结&lt;/h4&gt;AutoGameUI系统通过创新的方法有效解决了游戏开发中的UI和UX一致性问题，展示了良好的实验效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce an innovative system, AutoGameUI, for efficiently constructingcohesive user interfaces in game development. Our system is the first toaddress the coherence issue arising from integrating inconsistent UI and UXdesigns, typically leading to mismatches and inefficiencies. We propose atwo-stage multimodal learning pipeline to obtain comprehensive representationsof both UI and UX designs, and to establish their correspondences. Through thecorrespondences, a cohesive user interface is automatically constructed frompairwise designs. To achieve high-fidelity effects, we introduce a universaldata protocol for precise design descriptions and cross-platform applications.We also develop an interactive web-based tool for game developers to facilitatethe use of our system. We create a game UI dataset from actual game projectsand combine it with a public dataset for training and evaluation. Ourexperimental results demonstrate the effectiveness of our system in maintainingcoherence between the constructed interfaces and the original designs.</description>
      <author>example@mail.com (Zhongliang Tang, Mengchen Tan, Fei Xia, Qingrong Cheng, Hao Jiang, Yongxiang Zhang)</author>
      <guid isPermaLink="false">2411.03709v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>wav2sleep: A Unified Multi-Modal Approach to Sleep Stage Classification from Physiological Signals</title>
      <link>http://arxiv.org/abs/2411.04644v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Machine Learning for Health (ML4H) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确分类睡眠阶段能够促进睡眠医学的重要应用，现有方法主要基于特定输入信号如心电图（ECG）和光电容积脉搏波（PPG）。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一模型wav2sleep，以便在训练和推理过程中处理可变输入信号集合。&lt;h4&gt;方法&lt;/h4&gt;wav2sleep在六个公开的多导睡眠监测数据集（包括SHHS和MESA）上共同训练超过10,000个过夜录音。&lt;h4&gt;主要发现&lt;/h4&gt;wav2sleep在测试时输入组合（包括ECG、PPG和呼吸信号）上，表现优于现有的睡眠阶段分类模型。&lt;h4&gt;结论&lt;/h4&gt;wav2sleep通过跨模态信息转移，克服了以往仅依赖固定模态训练的限制，显著提高了睡眠阶段分类的准确性。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了wav2sleep模型在睡眠阶段分类中的有效性，推动了睡眠医学的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate classification of sleep stages from less obtrusive sensormeasurements such as the electrocardiogram (ECG) or photoplethysmogram (PPG)could enable important applications in sleep medicine. Existing approaches tothis problem have typically used deep learning models designed and trained tooperate on one or more specific input signals. However, the datasets used todevelop these models often do not contain the same sets of input signals. Somesignals, particularly PPG, are much less prevalent than others, and this haspreviously been addressed with techniques such as transfer learning.Additionally, only training on one or more fixed modalities precludescross-modal information transfer from other sources, which has proved valuablein other problem domains. To address this, we introduce wav2sleep, a unifiedmodel designed to operate on variable sets of input signals during training andinference. After jointly training on over 10,000 overnight recordings from sixpublicly available polysomnography datasets, including SHHS and MESA, wav2sleepoutperforms existing sleep stage classification models across test-time inputcombinations including ECG, PPG, and respiratory signals.</description>
      <author>example@mail.com (Jonathan F. Carter, Lionel Tarassenko)</author>
      <guid isPermaLink="false">2411.04644v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Towards more efficient agricultural practices via transformer-based crop type classification</title>
      <link>http://arxiv.org/abs/2411.02627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习在提高作物产量和应对气候变化方面具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;准确地图绘制作物分布，以支持政策和研究应用。&lt;h4&gt;方法&lt;/h4&gt;采用来自墨西哥Sentinel 1和2卫星影像的时间序列，通过基于像素的二元作物/非作物时间序列变换模型进行作物分类。&lt;h4&gt;主要发现&lt;/h4&gt;初步证据表明，使用类似农业生态区的数据补充元学习方法可能会提高模型性能。&lt;h4&gt;结论&lt;/h4&gt;基于这些有希望的结果，建议进一步开发该方法，以实现对墨西哥哈利斯科州的多类别作物准确分类。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了机器学习在作物分类中的应用潜力，并提出了未来研究的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has great potential to increase crop production andresilience to climate change. Accurate maps of where crops are grown are a keyinput to a number of downstream policy and research applications. In thisproposal, we present preliminary work showing that it is possible to accuratelyclassify crops from time series derived from Sentinel 1 and 2 satellite imageryin Mexico using a pixel-based binary crop/non-crop time series transformermodel. We also find preliminary evidence that meta-learning approachessupplemented with data from similar agro-ecological zones may improve modelperformance. Due to these promising results, we propose further development ofthis method with the goal of accurate multi-class crop classification inJalisco, Mexico via meta-learning with a dataset comprising similaragro-ecological zones.</description>
      <author>example@mail.com (E. Ulises Moya-Sánchez, Yazid S. Mikail, Daisy Nyang'anyi, Michael J. Smith, Isabella Smythe)</author>
      <guid isPermaLink="false">2411.02627v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing Multimodal Features of Spontaneous Voice Assistant Commands for Mild Cognitive Impairment Detection</title>
      <link>http://arxiv.org/abs/2411.04158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;轻度认知障碍（MCI）是一个重要的公共卫生问题，因其高风险发展为痴呆。&lt;h4&gt;目的&lt;/h4&gt;本研究探讨通过自发语音助手（VA）命令检测MCI的潜力。&lt;h4&gt;方法&lt;/h4&gt;在受控环境中，设计了一项命令生成任务，参与者自由生成与认知能力相关的命令，并开发MCI分类和回归模型，使用音频、文本、意图和多模态融合特征。&lt;h4&gt;主要发现&lt;/h4&gt;命令生成任务的分类准确率平均为82%，优于命令阅读任务，且生成的命令与记忆和注意力子领域的相关性更强。&lt;h4&gt;结论&lt;/h4&gt;研究结果确认了命令生成任务的有效性，并暗示了使用长期家庭命令进行MCI检测的前景。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了使用语音助手命令生成任务在MCI检测中的潜力，强调了多模态特征的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.21437/Interspeech.2024-2288&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mild cognitive impairment (MCI) is a major public health concern due to itshigh risk of progressing to dementia. This study investigates the potential ofdetecting MCI with spontaneous voice assistant (VA) commands from 35 olderadults in a controlled setting. Specifically, a command-generation task isdesigned with pre-defined intents for participants to freely generate commandsthat are more associated with cognitive ability than read commands. We developMCI classification and regression models with audio, textual, intent, andmultimodal fusion features. We find the command-generation task outperforms thecommand-reading task with an average classification accuracy of 82%, achievedby leveraging multimodal fusion features. In addition, generated commandscorrelate more strongly with memory and attention subdomains than readcommands. Our results confirm the effectiveness of the command-generation taskand imply the promise of using longitudinal in-home commands for MCI detection.</description>
      <author>example@mail.com (Nana Lin, Youxiang Zhu, Xiaohui Liang, John A. Batsis, Caroline Summerour)</author>
      <guid isPermaLink="false">2411.04158v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models</title>
      <link>http://arxiv.org/abs/2411.04996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大语言模型（LLMs）的发展扩展到了能够在统一框架内处理文本、图像和语音的多模态系统。&lt;h4&gt;目的&lt;/h4&gt;为了解决大规模训练所需的数据集和计算资源的挑战，提出Mixture-of-Transformers（MoT）架构。&lt;h4&gt;方法&lt;/h4&gt;MoT是一种稀疏多模态变换器架构，通过按模态解耦非嵌入参数，实现模态特定处理并在全输入序列上进行全局自注意力。&lt;h4&gt;主要发现&lt;/h4&gt;在Chameleon 7B设置中，MoT使用只有55.8%的FLOPs就达到了密集基线的性能；扩展到语音时，MoT以37.2%的FLOPs达到了与密集基线相当的语音性能。在Transfusion设置中，7B MoT模型以三分之一的FLOPs匹配图像模态的密集基线性能，760M MoT模型在关键图像生成指标上超越1.4B密集基线。&lt;h4&gt;结论&lt;/h4&gt;MoT在实现密集基线图像质量方面，仅需47.2%的实际时间，文本质量达到75.6%的实际时间，展示了其实际应用的优势。&lt;h4&gt;总结&lt;/h4&gt;MoT通过减少计算成本和提高效率，为多模态模型的训练和应用提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of large language models (LLMs) has expanded to multi-modalsystems capable of processing text, images, and speech within a unifiedframework. Training these models demands significantly larger datasets andcomputational resources compared to text-only LLMs. To address the scalingchallenges, we introduce Mixture-of-Transformers (MoT), a sparse multi-modaltransformer architecture that significantly reduces pretraining computationalcosts. MoT decouples non-embedding parameters of the model by modality --including feed-forward networks, attention matrices, and layer normalization --enabling modality-specific processing with global self-attention over the fullinput sequence. We evaluate MoT across multiple settings and model scales. Inthe Chameleon 7B setting (autoregressive text-and-image generation), MoTmatches the dense baseline's performance using only 55.8\% of the FLOPs. Whenextended to include speech, MoT reaches speech performance comparable to thedense baseline with only 37.2\% of the FLOPs. In the Transfusion setting, wheretext and image are trained with different objectives, a 7B MoT model matchesthe image modality performance of the dense baseline with one third of theFLOPs, and a 760M MoT model outperforms a 1.4B dense baseline across key imagegeneration metrics. System profiling further highlights MoT's practicalbenefits, achieving dense baseline image quality in 47.2\% of the wall-clocktime and text quality in 75.6\% of the wall-clock time (measured on AWSp4de.24xlarge instances with NVIDIA A100 GPUs).</description>
      <author>example@mail.com (Weixin Liang, Lili Yu, Liang Luo, Srinivasan Iyer, Ning Dong, Chunting Zhou, Gargi Ghosh, Mike Lewis, Wen-tau Yih, Luke Zettlemoyer, Xi Victoria Lin)</author>
      <guid isPermaLink="false">2411.04996v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>DynaMem: Online Dynamic Spatio-Semantic Memory for Open World Mobile Manipulation</title>
      <link>http://arxiv.org/abs/2411.04999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Website: https://dynamem.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在开放词汇的移动操作领域取得了显著进展，目标是使机器人能够根据自然语言描述在任何环境中执行任务。现有系统大多假设环境是静态的，这限制了在现实场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出DynaMem，一种新方法以支持开放世界的移动操作。&lt;h4&gt;方法&lt;/h4&gt;DynaMem使用动态空间语义记忆来表示机器人的环境，构建3D数据结构以维护点云的动态记忆，并使用多模态大型语言模型或先进的视觉语言模型生成的开放词汇特征来回答对象定位查询。&lt;h4&gt;主要发现&lt;/h4&gt;通过DynaMem，机器人能够探索新环境，搜索记忆中不存在的对象，并在对象移动、出现或消失时不断更新记忆。在三个真实场景和九个离线场景中进行的广泛实验显示，机器人在非静态对象上的平均抓取和放置成功率达到70%，比现有静态系统提高了2倍以上。&lt;h4&gt;结论&lt;/h4&gt;DynaMem显著提升了机器人在动态环境中的操作能力，展示了开放词汇移动操作的潜力。&lt;h4&gt;总结&lt;/h4&gt;DynaMem提供了一种有效的方法来处理动态环境中的开放词汇移动操作，代码和实验视频已开源，提供给研究者和开发者使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Significant progress has been made in open-vocabulary mobile manipulation,where the goal is for a robot to perform tasks in any environment given anatural language description. However, most current systems assume a staticenvironment, which limits the system's applicability in real-world scenarioswhere environments frequently change due to human intervention or the robot'sown actions. In this work, we present DynaMem, a new approach to open-worldmobile manipulation that uses a dynamic spatio-semantic memory to represent arobot's environment. DynaMem constructs a 3D data structure to maintain adynamic memory of point clouds, and answers open-vocabulary object localizationqueries using multimodal LLMs or open-vocabulary features generated bystate-of-the-art vision-language models. Powered by DynaMem, our robots canexplore novel environments, search for objects not found in memory, andcontinuously update the memory as objects move, appear, or disappear in thescene. We run extensive experiments on the Stretch SE3 robots in three real andnine offline scenes, and achieve an average pick-and-drop success rate of 70%on non-stationary objects, which is more than a 2x improvement overstate-of-the-art static systems. Our code as well as our experiment anddeployment videos are open sourced and can be found on our project website:https://dynamem.github.io/</description>
      <author>example@mail.com (Peiqi Liu, Zhanqiu Guo, Mohit Warke, Soumith Chintala, Chris Paxton, Nur Muhammad Mahi Shafiullah, Lerrel Pinto)</author>
      <guid isPermaLink="false">2411.04999v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Distinguishing LLM-generated from Human-written Code by Contrastive Learning</title>
      <link>http://arxiv.org/abs/2411.04704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 6 figures, Accepted by TOSEM'24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs），如OpenAI发布的ChatGPT，因其在多种任务中生成高质量内容的能力而受到行业和学术界的广泛关注。&lt;h4&gt;目的&lt;/h4&gt;本文旨在填补现有LLM生成内容检测工具在程序代码检测方面的空白。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于对比学习框架和UniXcoder构建的语义编码器的新型ChatGPT生成代码检测器CodeGPTSensor。&lt;h4&gt;主要发现&lt;/h4&gt;通过构建包含55万对人类编写代码和ChatGPT生成代码的大规模比较语料库（HMCorp），分析表明区分两者具有挑战性和机会。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，CodeGPTSensor能够有效识别ChatGPT生成的代码，且优于所有选定的基线方法。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种有效的工具，用于检测ChatGPT生成的代码，为相关领域的风险管理提供支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs), such as ChatGPT released by OpenAI, haveattracted significant attention from both industry and academia due to theirdemonstrated ability to generate high-quality content for various tasks.Despite the impressive capabilities of LLMs, there are growing concernsregarding their potential risks in various fields, such as news, education, andsoftware engineering. Recently, several commercial and open-sourceLLM-generated content detectors have been proposed, which, however, areprimarily designed for detecting natural language content without consideringthe specific characteristics of program code. This paper aims to fill this gapby proposing a novel ChatGPT-generated code detector, CodeGPTSensor, based on acontrastive learning framework and a semantic encoder built with UniXcoder. Toassess the effectiveness of CodeGPTSensor on differentiating ChatGPT-generatedcode from human-written code, we first curate a large-scale Human and Machinecomparison Corpus (HMCorp), which includes 550K pairs of human-written andChatGPT-generated code (i.e., 288K Python code pairs and 222K Java code pairs).Based on the HMCorp dataset, our qualitative and quantitative analysis of thecharacteristics of ChatGPT-generated code reveals the challenge and opportunityof distinguishing ChatGPT-generated code from human-written code with theirrepresentative features. Our experimental results indicate that CodeGPTSensorcan effectively identify ChatGPT-generated code, outperforming all selectedbaselines.</description>
      <author>example@mail.com (Xiaodan Xu, Chao Ni, Xinrong Guo, Shaoxuan Liu, Xiaoya Wang, Kui Liu, Xiaohu Yang)</author>
      <guid isPermaLink="false">2411.04704v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Sampling-guided Heterogeneous Graph Neural Network with Temporal Smoothing for Scalable Longitudinal Data Imputation</title>
      <link>http://arxiv.org/abs/2411.04899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在纵向研究中，缺失数据插补是一个重要挑战，传统方法通常需要大量预处理以处理不规则或不一致的缺失数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架SHT-GNN，以有效解决纵向研究中的缺失数据插补问题。&lt;h4&gt;方法&lt;/h4&gt;SHT-GNN将观察值和协变量建模为不同的节点类型，通过特定于受试者的纵向子网络连接连续时间点的观察节点，并通过双向图中的属性边表示协变量与观察之间的交互。利用受试者级的迷你批量采样和多层时间平滑机制，提高了计算效率并支持大规模数据集。&lt;h4&gt;主要发现&lt;/h4&gt;在合成数据和真实数据集（包括阿尔茨海默病神经成像倡议（ADNI）数据集）上的广泛实验表明，SHT-GNN在高缺失数据率情况下显著优于现有插补方法。&lt;h4&gt;结论&lt;/h4&gt;SHT-GNN展现了强大的插补能力和卓越的性能，特别是在复杂的大规模纵向数据背景下。&lt;h4&gt;总结&lt;/h4&gt;SHT-GNN是一种高效的缺失数据插补方法，能够处理多种缺失数据模式，且在性能上优于传统方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel framework, the Sampling-guidedHeterogeneous Graph Neural Network (SHT-GNN), to effectively tackle thechallenge of missing data imputation in longitudinal studies. Unliketraditional methods, which often require extensive preprocessing to handleirregular or inconsistent missing data, our approach accommodates arbitrarymissing data patterns while maintaining computational efficiency. SHT-GNNmodels both observations and covariates as distinct node types, connectingobservation nodes at successive time points through subject-specificlongitudinal subnetworks, while covariate-observation interactions arerepresented by attributed edges within bipartite graphs. By leveragingsubject-wise mini-batch sampling and a multi-layer temporal smoothingmechanism, SHT-GNN efficiently scales to large datasets, while effectivelylearning node representations and imputing missing data. Extensive experimentson both synthetic and real-world datasets, including the Alzheimer's DiseaseNeuroimaging Initiative (ADNI) dataset, demonstrate that SHT-GNN significantlyoutperforms existing imputation methods, even with high missing data rates. Theempirical results highlight SHT-GNN's robust imputation capabilities andsuperior performance, particularly in the context of complex, large-scalelongitudinal data.</description>
      <author>example@mail.com (Zhaoyang Zhang, Ziqi Chen, Qiao Liu, Jinhan Xie, Hongtu Zhu)</author>
      <guid isPermaLink="false">2411.04899v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>SpectraFM: Tuning into Stellar Foundation Models</title>
      <link>http://arxiv.org/abs/2411.04750v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the NeurIPS 2024 Workshop on Foundation Models for
  Science&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;天文学中的机器学习模型通常受限于特定范围，难以适应新仪器或任务的数据。&lt;h4&gt;目的&lt;/h4&gt;引入SpectraFM，一种基于Transformer的基础模型架构，能够在任意波长范围和仪器上对星体光谱进行预训练。&lt;h4&gt;方法&lt;/h4&gt;该模型在约90,000个合成光谱样本上进行预训练，以预测星体的化学丰度（Fe、Mg、O）、温度和比重，然后对真实光谱进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;尽管只有小规模的富铁真实光谱训练集，得益于合成光谱的迁移学习，模型在贫铁星体上的表现良好，而从头训练的神经网络未能成功。&lt;h4&gt;结论&lt;/h4&gt;SpectraFM通过利用预训练知识和处理非光谱输入的能力，减少了对大规模训练数据集的需求，适合于跨仪器和跨领域的研究，能够应对天文学中的新挑战。&lt;h4&gt;总结&lt;/h4&gt;SpectraFM展示了在天文学中处理多模态数据和新兴挑战的潜力，具有良好的适应性和通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning models in astrophysics are often limited in scope and cannotadapt to data from new instruments or tasks. We introduce SpectraFM, aTransformer-based foundation model architecture that can be pre-trained onstellar spectra from any wavelength range and instrument. SpectraFM excels ingeneralization by combining flexibility with knowledge transfer frompre-training, allowing it to outperform traditional machine learning methods,especially in scenarios with limited training data. Our model is pre-trained onapproximately 90k examples of synthetic spectra to predict the chemicalabundances (Fe, Mg, O), temperature, and specific gravity of stars. We thenfine-tune the model on real spectra to adapt it to observational data beforefine-tuning it further on a restricted 100-star training set in a differentwavelength range to predict iron abundance. Despite a small iron-rich trainingset of real spectra, transfer learning from the synthetic spectra pre-trainingenables the model to perform well on iron-poor stars. In contrast, a neuralnetwork trained from scratch fails at this task. We investigate the Transformerattention mechanism and find that the wavelengths receiving attention carryphysical information about chemical composition. By leveraging the knowledgefrom pre-training and its ability to handle non-spectra inputs, SpectraFMreduces the need for large training datasets and enables cross-instrument andcross-domain research. Its adaptability makes it well-suited for tacklingemerging challenges in astrophysics, like extracting insights from multi-modaldatasets.</description>
      <author>example@mail.com (Nolan Koblischke, Jo Bovy)</author>
      <guid isPermaLink="false">2411.04750v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Multimodality Helps Few-Shot 3D Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.22489v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;少量样本3D点云分割（FS-PCS）旨在使模型能够在最小注释支持样本的情况下，对新类别进行分割。现有FS-PCS方法主要集中于单一模态的点云输入，忽视了多模态信息的潜在益处。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法的不足，引入一种无成本的多模态FS-PCS设置，利用文本标签和可能可用的2D图像模态。&lt;h4&gt;方法&lt;/h4&gt;提出MultiModal Few-Shot SegNet（MM-FSS）模型，利用多个模态的互补信息。该模型使用共享的主干网络，配备两个头部提取跨模态和单模态视觉特征，并使用预训练的文本编码器生成文本嵌入。通过多模态相关融合（MCF）模块和多模态语义融合（MSF）模块来生成和优化多模态相关性。此外，提出了一种简单有效的测试时自适应跨模态校准（TACC）技术，以减少训练偏差，提高泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在S3DIS和ScanNet数据集上的实验结果显示，该方法显著提高了性能，表明充分利用常被忽视的免费模态对FS-PCS的益处。&lt;h4&gt;结论&lt;/h4&gt;本研究为未来研究提供了宝贵的见解，强调了多模态信息在少量样本3D点云分割中的重要性。&lt;h4&gt;总结&lt;/h4&gt;MM-FSS模型展示了通过多模态信息提升FS-PCS性能的有效性，代码可在https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot 3D point cloud segmentation (FS-PCS) aims at generalizing models tosegment novel categories with minimal annotated support samples. While existingFS-PCS methods have shown promise, they primarily focus on unimodal point cloudinputs, overlooking the potential benefits of leveraging multimodalinformation. In this paper, we address this gap by introducing a cost-freemultimodal FS-PCS setup, utilizing textual labels and the potentially available2D image modality. Under this easy-to-achieve setup, we present the MultiModalFew-Shot SegNet (MM-FSS), a model effectively harnessing complementaryinformation from multiple modalities. MM-FSS employs a shared backbone with twoheads to extract intermodal and unimodal visual features, and a pretrained textencoder to generate text embeddings. To fully exploit the multimodalinformation, we propose a Multimodal Correlation Fusion (MCF) module togenerate multimodal correlations, and a Multimodal Semantic Fusion (MSF) moduleto refine the correlations using text-aware semantic guidance. Additionally, wepropose a simple yet effective Test-time Adaptive Cross-modal Calibration(TACC) technique to mitigate training bias, further improving generalization.Experimental results on S3DIS and ScanNet datasets demonstrate significantperformance improvements achieved by our method. The efficacy of our approachindicates the benefits of leveraging commonly-ignored free modalities forFS-PCS, providing valuable insights for future research. The code is availableat https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot</description>
      <author>example@mail.com (Zhaochong An, Guolei Sun, Yun Liu, Runjia Li, Min Wu, Ming-Ming Cheng, Ender Konukoglu, Serge Belongie)</author>
      <guid isPermaLink="false">2410.22489v2</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>High Entropy Alloy property predictions using Transformer-based language model</title>
      <link>http://arxiv.org/abs/2411.04861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高熵合金（HEAs）具有复杂的多主元素组成和有限的实验数据，导致预测其机械性质面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于语言变换器的机器学习模型，以预测高熵合金的关键机械性质。&lt;h4&gt;方法&lt;/h4&gt;通过在大量合成材料数据上进行预训练，并在特定HEA数据集上进行微调，模型利用自注意力机制有效捕捉元素间复杂的相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;与传统回归模型（如随机森林和高斯过程）相比，该模型在延伸率（%）和极限抗拉强度（UTS）等性质的预测准确性上有所提升。&lt;h4&gt;结论&lt;/h4&gt;通过可视化注意力权重增强模型可解释性，揭示了与已知冶金原理一致的重要元素关系。此研究展示了变换器模型在加速材料发现和优化方面的潜力。&lt;h4&gt;总结&lt;/h4&gt;该研究推动了材料信息学的发展，实现了对高熵合金性质的准确预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study introduces a language transformer-based machine learning model topredict key mechanical properties of high-entropy alloys (HEAs), addressing thechallenges due to their complex, multi-principal element compositions andlimited experimental data. By pre-training the transformer on extensivesynthetic materials data and fine-tuning it with specific HEA datasets, themodel effectively captures intricate elemental interactions throughself-attention mechanisms. This approach mitigates data scarcity issues viatransfer learning, enhancing predictive accuracy for properties like elongation(%) and ultimate tensile strength (UTS) compared to traditional regressionmodels such as Random Forests and Gaussian Processes. The model'sinterpretability is enhanced by visualizing attention weights, revealingsignificant elemental relationships that align with known metallurgicalprinciples. This work demonstrates the potential of transformer models toaccelerate materials discovery and optimization, enabling accurate propertypredictions, thereby advancing the field of materials informatics.</description>
      <author>example@mail.com (Spyros Kamnis, Konstantinos Delibasis)</author>
      <guid isPermaLink="false">2411.04861v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Missing Data Imputation through Combined Bipartite Graph and Complete Directed Graph</title>
      <link>http://arxiv.org/abs/2411.04907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;缺失数据插补领域面临的一个重大挑战是识别和利用特征之间的相互依赖性。&lt;h4&gt;目的&lt;/h4&gt;提高表格数据缺失数据插补的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新框架，称为双重和完全有向图神经网络（BCGNN），将观察值和特征区分为两种不同的节点类型，并将观察特征的值转换为连接它们的属性边。&lt;h4&gt;主要发现&lt;/h4&gt;BCGNN在不同缺失机制下的特征插补任务中，平均减少了15%的绝对误差，表现优于当前领先的插补方法。&lt;h4&gt;结论&lt;/h4&gt;深入理解相互依赖结构显著增强了模型的特征嵌入能力，且在涉及缺失数据的标签预测任务中表现优异，具备很强的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;BCGNN通过有效利用特征间的相互依赖性，显著提升了缺失数据插补的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we aim to address a significant challenge in the field ofmissing data imputation: identifying and leveraging the interdependencies amongfeatures to enhance missing data imputation for tabular data. We introduce anovel framework named the Bipartite and Complete Directed Graph Neural Network(BCGNN). Within BCGNN, observations and features are differentiated as twodistinct node types, and the values of observed features are converted intoattributed edges linking them. The bipartite segment of our frameworkinductively learns embedding representations for nodes, efficiently utilizingthe comprehensive information encapsulated in the attributed edges. Inparallel, the complete directed graph segment adeptly outlines and communicatesthe complex interdependencies among features. When compared to contemporaryleading imputation methodologies, BCGNN consistently outperforms them,achieving a noteworthy average reduction of 15% in mean absolute error forfeature imputation tasks under different missing mechanisms. Our extensiveexperimental investigation confirms that an in-depth grasp of theinterdependence structure substantially enhances the model's feature embeddingability. We also highlight the model's superior performance in label predictiontasks involving missing data, and its formidable ability to generalize tounseen data points.</description>
      <author>example@mail.com (Zhaoyang Zhang, Hongtu Zhu, Ziqi Chen, Yingjie Zhang, Hai Shu)</author>
      <guid isPermaLink="false">2411.04907v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Insights into Lunar Mineralogy: An Unsupervised Approach for Clustering of the Moon Mineral Mapper (M3) spectral data</title>
      <link>http://arxiv.org/abs/2411.03186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文提出了一种新方法，用于利用机器学习对来自月球矿物探测器（M3）成像光谱的数据进行光谱特征映射。&lt;h4&gt;目的&lt;/h4&gt;旨在通过聚类分析，识别与月球表面矿物组成相关的光谱特征。&lt;h4&gt;方法&lt;/h4&gt;采用卷积变分自编码器降低光谱数据的维度，并提取光谱特征，随后使用k-means算法将潜在变量聚类为五个不同组。&lt;h4&gt;主要发现&lt;/h4&gt;生成的全球光谱聚类图显示了五个聚类在月球上的分布，这些聚类包含斜长石、辉石、橄榄石及含铁矿物的混合。&lt;h4&gt;结论&lt;/h4&gt;聚类结果与Kaguya任务的矿物图相比，显示出斜长石、临床辉石和橄榄石等矿物高含量区域的重叠，证明了无偏无监督学习在月球矿物勘探中的有效性，并提供了全面的月球矿物学分析。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了基于机器学习的光谱数据聚类在探测月球矿物方面的潜力与应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel method for mapping spectral features of the Moonusing machine learning-based clustering of hyperspectral data from the MoonMineral Mapper (M3) imaging spectrometer. The method uses a convolutionalvariational autoencoder to reduce the dimensionality of the spectral data andextract features of the spectra. Then, a k-means algorithm is applied tocluster the latent variables into five distinct groups, corresponding todominant spectral features, which are related to the mineral composition of theMoon's surface. The resulting global spectral cluster map shows thedistribution of the five clusters on the Moon, which consist of a mixture of,among others, plagioclase, pyroxene, olivine, and Fe-bearing minerals acrossthe Moon's surface. The clusters are compared to the mineral maps from theKaguya mission, which showed that the locations of the clusters overlap withthe locations of high wt% of minerals such as plagioclase, clinopyroxene, andolivine. The paper demonstrates the usefulness of unbiased unsupervisedlearning for lunar mineral exploration and provides a comprehensive analysis oflunar mineralogy.</description>
      <author>example@mail.com (Freja Thoresen, Igor Drozdovskiy, Aidan Cowley, Magdelena Laban, Sebastien Besse, Sylvain Blunier)</author>
      <guid isPermaLink="false">2411.03186v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised cross-modality learning for uncertainty-aware object detection and recognition in applications which lack pre-labelled training data</title>
      <link>http://arxiv.org/abs/2411.03082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在缺乏标注训练数据集的情况下，如何有效检测、识别和定位二维RGB图像中的物体。&lt;h4&gt;目的&lt;/h4&gt;提出一种不确定性感知的深度神经网络训练方法，用于物体检测和分类。&lt;h4&gt;方法&lt;/h4&gt;采用自监督的教师-学生管道，通过简单的教师分类器和修改过的YOLOv3架构处理未标注的RGB-D数据，进行知识传递。&lt;h4&gt;主要发现&lt;/h4&gt;学生网络显著优于直接在相同标注数据上训练的YOLO架构，且基于高斯过程的方式提供了稳健且有意义的不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;该方法能够实时处理，适用于机器人应用，并能解决工业任务中缺乏标注数据的问题。&lt;h4&gt;应用示例&lt;/h4&gt;在高度杂乱和无结构场景中检测、定位和识别核混合废料，这是机器人排序和处理遗留核废料的关键。&lt;h4&gt;总结&lt;/h4&gt;该研究为复杂环境中的物体识别提供了一种有效的方法，具有重要的工业应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper shows how an uncertainty-aware, deep neural network can be trainedto detect, recognise and localise objects in 2D RGB images, in applicationslacking annotated train-ng datasets. We propose a self-supervisingteacher-student pipeline, in which a relatively simple teacher classifier,trained with only a few labelled 2D thumbnails, automatically processes alarger body of unlabelled RGB-D data to teach a student network based on amodified YOLOv3 architecture. Firstly, 3D object detection with back projectionis used to automatically extract and teach 2D detection and localisationinformation to the student network. Secondly, a weakly supervised 2D thumbnailclassifier, with minimal training on a small number of hand-labelled images, isused to teach object category recognition. Thirdly, we use a Gaussian ProcessGP to encode and teach a robust uncertainty estimation functionality, so thatthe student can output confidence scores with each categorization. Theresulting student significantly outperforms the same YOLO architecture traineddirectly on the same amount of labelled data. Our GP-based approach yieldsrobust and meaningful uncertainty estimations for complex industrial objectclassifications. The end-to-end network is also capable of real-timeprocessing, needed for robotics applications. Our method can be applied to manyimportant industrial tasks, where labelled datasets are typically unavailable.In this paper, we demonstrate an example of detection, localisation, and objectcategory recognition of nuclear mixed-waste materials in highly cluttered andunstructured scenes. This is critical for robotic sorting and handling oflegacy nuclear waste, which poses complex environmental remediation challengesin many nuclearised nations.</description>
      <author>example@mail.com (Irum Mehboob, Li Sun, Alireza Astegarpanah, Rustam Stolkin)</author>
      <guid isPermaLink="false">2411.03082v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Mining and Transferring Feature-Geometry Coherence for Unsupervised Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2411.01870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云配准是3D视觉中的一项基础任务，基于学习的方法在户外环境中取得了显著成功。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的无监督配准方法INTEGER，以便在无须昂贵的姿态注释的情况下，更好地挖掘伪标签。&lt;h4&gt;方法&lt;/h4&gt;引入特征-几何一致性挖掘模块和基于锚的对比学习，并提出混合密度学生以解决密度变化和重叠不足的问题。&lt;h4&gt;主要发现&lt;/h4&gt;在特征空间中，潜在的新内点对应关系倾向于围绕各自的正锚点聚集，表明高层上下文信息对伪标签挖掘的可靠性至关重要。&lt;h4&gt;结论&lt;/h4&gt;在KITTI和nuScenes数据集上的广泛实验表明，INTEGER在准确性和泛化能力方面表现出竞争力。&lt;h4&gt;总结&lt;/h4&gt;INTEGER方法通过结合高层特征表示和低层几何线索，改善了无监督点云配准的效果，具有良好的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud registration, a fundamental task in 3D vision, has achievedremarkable success with learning-based methods in outdoor environments.Unsupervised outdoor point cloud registration methods have recently emerged tocircumvent the need for costly pose annotations. However, they fail toestablish reliable optimization objectives for unsupervised training, eitherrelying on overly strong geometric assumptions, or suffering from poor-qualitypseudo-labels due to inadequate integration of low-level geometric andhigh-level contextual information. We have observed that in the feature space,latent new inlier correspondences tend to cluster around respective positiveanchors that summarize features of existing inliers. Motivated by thisobservation, we propose a novel unsupervised registration method termed INTEGERto incorporate high-level contextual information for reliable pseudo-labelmining. Specifically, we propose the Feature-Geometry Coherence Mining moduleto dynamically adapt the teacher for each mini-batch of data during trainingand discover reliable pseudo-labels by considering both high-level featurerepresentations and low-level geometric cues. Furthermore, we proposeAnchor-Based Contrastive Learning to facilitate contrastive learning withanchors for a robust feature space. Lastly, we introduce a Mixed-DensityStudent to learn density-invariant features, addressing challenges related todensity variation and low overlap in the outdoor scenario. Extensiveexperiments on KITTI and nuScenes datasets demonstrate that our INTEGERachieves competitive performance in terms of accuracy and generalizability.</description>
      <author>example@mail.com (Kezheng Xiong, Haoen Xiang, Qingshan Xu, Chenglu Wen, Siqi Shen, Jonathan Li, Cheng Wang)</author>
      <guid isPermaLink="false">2411.01870v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Towards 3D Semantic Scene Completion for Autonomous Driving: A Meta-Learning Framework Empowered by Deformable Large-Kernel Attention and Mamba Model</title>
      <link>http://arxiv.org/abs/2411.03672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;语义场景补全（SSC）对于实现自动驾驶系统的全面感知至关重要，但现有方法往往忽视了实际应用中的高部署成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架MetaSSC，以解决现有方法在3D体素网格中捕捉长距离依赖关系的挑战。&lt;h4&gt;方法&lt;/h4&gt;MetaSSC基于元学习，利用可变形卷积、大核注意力和Mamba模型。首先进行基于体素的语义分割预训练任务，探索不完整区域的语义和几何特征，并获取可迁移的元知识。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟合作感知数据集，使用多个连接的自动驾驶车辆的传感器数据进行单车感知训练，生成更丰富、全面的标签，显著提高了模型的表现。&lt;h4&gt;结论&lt;/h4&gt;MetaSSC在捕捉3D体素网格内的长序列关系方面表现优异，并通过双阶段训练策略有效适应目标领域而不增加额外模型参数，降低了部署成本。&lt;h4&gt;总结&lt;/h4&gt;MetaSSC在多个实验中表现出色，显著超越竞争模型，同时降低了实际应用中的部署成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic scene completion (SSC) is essential for achieving comprehensiveperception in autonomous driving systems. However, existing SSC methods oftenoverlook the high deployment costs in real-world applications. Traditionalarchitectures, such as 3D Convolutional Neural Networks (3D CNNs) andself-attention mechanisms, face challenges in efficiently capturing long-rangedependencies within 3D voxel grids, limiting their effectiveness. To addressthese issues, we introduce MetaSSC, a novel meta-learning-based framework forSSC that leverages deformable convolution, large-kernel attention, and theMamba (D-LKA-M) model. Our approach begins with a voxel-based semanticsegmentation (SS) pretraining task, aimed at exploring the semantics andgeometry of incomplete regions while acquiring transferable meta-knowledge.Using simulated cooperative perception datasets, we supervise the perceptiontraining of a single vehicle using aggregated sensor data from multiple nearbyconnected autonomous vehicles (CAVs), generating richer and more comprehensivelabels. This meta-knowledge is then adapted to the target domain through adual-phase training strategy that does not add extra model parameters, enablingefficient deployment. To further enhance the model's capability in capturinglong-sequence relationships within 3D voxel grids, we integrate Mamba blockswith deformable convolution and large-kernel attention into the backbonenetwork. Extensive experiments demonstrate that MetaSSC achievesstate-of-the-art performance, significantly outperforming competing modelswhile also reducing deployment costs.</description>
      <author>example@mail.com (Yansong Qu, Zilin Huang, Zihao Sheng, Tiantian Chen, Sikai Chen)</author>
      <guid isPermaLink="false">2411.03672v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>PocoLoco: A Point Cloud Diffusion Model of Human Shape in Loose Clothing</title>
      <link>http://arxiv.org/abs/2411.04249v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类化身建模，特别是能够适应关节变形的建模，是一个活跃的研究领域。&lt;h4&gt;目的&lt;/h4&gt;提出PocoLoco，这是首个无模板、基于点的、姿态条件的3D人类生成模型，专注于松垮衣物的建模。&lt;h4&gt;方法&lt;/h4&gt;将化身服装变形视为条件点云生成任务，采用去噪扩散框架，直接处理无序点云，避免使用参数模型或服装模板。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能有效处理松垮衣物的建模问题，同时支持点云补全和基于姿态的编辑。&lt;h4&gt;结论&lt;/h4&gt;通过发布包含75K个点云的数据集，助力解决松垮衣物建模的挑战，为数字人类的进一步创新奠定基础。&lt;h4&gt;总结&lt;/h4&gt;PocoLoco为3D人类建模提供了一种新方法，扩展了现有数据集，推动了虚拟人类动画的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sidsunny/pocoloco&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling a human avatar that can plausibly deform to articulations is anactive area of research. We present PocoLoco -- the first template-free,point-based, pose-conditioned generative model for 3D humans in loose clothing.We motivate our work by noting that most methods require a parametric model ofthe human body to ground pose-dependent deformations. Consequently, they arerestricted to modeling clothing that is topologically similar to the naked bodyand do not extend well to loose clothing. The few methods that attempt to modelloose clothing typically require either canonicalization or aUV-parameterization and need to address the challenging problem of explicitlyestimating correspondences for the deforming clothes. In this work, weformulate avatar clothing deformation as a conditional point-cloud generationtask within the denoising diffusion framework. Crucially, our frameworkoperates directly on unordered point clouds, eliminating the need for aparametric model or a clothing template. This also enables a variety ofpractical applications, such as point-cloud completion and pose-based editing-- important features for virtual human animation. As current datasets forhuman avatars in loose clothing are far too small for training diffusionmodels, we release a dataset of two subjects performing various poses in looseclothing with a total of 75K point clouds. By contributing towards tackling thechallenging task of effectively modeling loose clothing and expanding theavailable data for training these models, we aim to set the stage for furtherinnovation in digital humans. The source code is available athttps://github.com/sidsunny/pocoloco .</description>
      <author>example@mail.com (Siddharth Seth, Rishabh Dabral, Diogo Luvizon, Marc Habermann, Ming-Hsuan Yang, Christian Theobalt, Adam Kortylewski)</author>
      <guid isPermaLink="false">2411.04249v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation</title>
      <link>http://arxiv.org/abs/2411.04997v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;CLIP是重要的多模态基础模型，其能力依赖于自然语言提供的丰富监督信号，形成强大的跨模态表示空间。&lt;h4&gt;目的&lt;/h4&gt;探讨大型语言模型（LLMs）是否能进一步提升多模态表示学习的能力。&lt;h4&gt;方法&lt;/h4&gt;提出LLM2CLIP，通过对LLM在字幕空间进行对比学习微调，提取其文本能力到输出嵌入中，并设计高效的训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;引入LLM后，CLIP能够处理更长和更复杂的字幕，显著提升了跨模态任务的性能。&lt;h4&gt;结论&lt;/h4&gt;LLM的应用使得CLIP在处理复杂文本时超越了传统限制，验证了LLM在多模态学习中的潜力。&lt;h4&gt;总结&lt;/h4&gt;LLM2CLIP方法有效提升了CLIP的文本区分能力和跨模态任务的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/microsoft/LLM2CLIP&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLIP is one of the most important multimodal foundational models today. Whatpowers CLIP's capabilities? The rich supervision signals provided by naturallanguage, the carrier of human knowledge, shape a powerful cross-modalrepresentation space. However, with the rapid advancements in large languagemodels LLMs like GPT-4 and LLaMA, the boundaries of language comprehension andgeneration are continually being pushed. This raises an intriguing question:can the capabilities of LLMs be harnessed to further improve multimodalrepresentation learning? The potential benefits of incorporating LLMs into CLIPare clear. LLMs' strong textual understanding can fundamentally improve CLIP'sability to handle image captions, drastically enhancing its ability to processlong and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMsare trained on a vast corpus of text, possessing open-world knowledge. Thisallows them to expand on caption information during training, increasing theefficiency of the learning process. In this paper, we propose LLM2CLIP, a novelapproach that embraces the power of LLMs to unlock CLIP's potential. Byfine-tuning the LLM in the caption space with contrastive learning, we extractits textual capabilities into the output embeddings, significantly improvingthe output layer's textual discriminability. We then design an efficienttraining process where the fine-tuned LLM acts as a powerful teacher for CLIP'svisual encoder. Thanks to the LLM's presence, we can now incorporate longer andmore complex captions without being restricted by vanilla CLIP's text encoder'scontext window and ability limitations. Our experiments demonstrate that thisapproach brings substantial improvements in cross-modal tasks.</description>
      <author>example@mail.com (Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, Lili Qiu)</author>
      <guid isPermaLink="false">2411.04997v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>ReCapture: Generative Video Camera Controls for User-Provided Videos using Masked Video Fine-Tuning</title>
      <link>http://arxiv.org/abs/2411.05003v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project page: https://generative-video-camera-controls.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，视频建模的突破使得生成视频中的可控相机轨迹成为可能，但这些方法无法直接应用于用户提供的非生成视频。&lt;h4&gt;目的&lt;/h4&gt;提出ReCapture方法，从单个用户提供的视频中生成具有新相机轨迹的视频。&lt;h4&gt;方法&lt;/h4&gt;首先，使用多视角扩散模型或基于深度的点云渲染生成带有新相机轨迹的噪声锚点视频；然后，利用提出的掩码视频微调技术将锚点视频重生成干净且时间一致的重新角度视频。&lt;h4&gt;主要发现&lt;/h4&gt;能够从不同角度和具有电影感的相机运动重新生成参考视频，并且可以合理地虚构参考视频中不可观察的场景部分。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地实现了用户提供视频的再生，并增强了视频内容的表现力。&lt;h4&gt;总结&lt;/h4&gt;ReCapture方法为用户提供的视频生成新的视频轨迹提供了新的可能性，扩展了视频生成技术的应用范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, breakthroughs in video modeling have allowed for controllablecamera trajectories in generated videos. However, these methods cannot bedirectly applied to user-provided videos that are not generated by a videomodel. In this paper, we present ReCapture, a method for generating new videoswith novel camera trajectories from a single user-provided video. Our methodallows us to re-generate the reference video, with all its existing scenemotion, from vastly different angles and with cinematic camera motion. Notably,using our method we can also plausibly hallucinate parts of the scene that werenot observable in the reference video. Our method works by (1) generating anoisy anchor video with a new camera trajectory using multiview diffusionmodels or depth-based point cloud rendering and then (2) regenerating theanchor video into a clean and temporally consistent reangled video using ourproposed masked video fine-tuning technique.</description>
      <author>example@mail.com (David Junhao Zhang, Roni Paiss, Shiran Zada, Nikhil Karnad, David E. Jacobs, Yael Pritch, Inbar Mosseri, Mike Zheng Shou, Neal Wadhwa, Nataniel Ruiz)</author>
      <guid isPermaLink="false">2411.05003v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
    <item>
      <title>Noisy Zero-Shot Coordination: Breaking The Common Knowledge Assumption In Zero-Shot Coordination Games</title>
      <link>http://arxiv.org/abs/2411.04976v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;零-shot 协调（ZSC）是研究强化学习（RL）代理与新伙伴协调能力的热门设置，先前的 ZSC 设定假设问题设置是共识知识。&lt;h4&gt;目的&lt;/h4&gt;提出噪声零-shot 协调（NZSC）问题，以解决在复杂现实环境中共识知识假设失效的问题。&lt;h4&gt;方法&lt;/h4&gt;NZSC 中，代理观察不同的噪声版本的真实 Dec-POMDP，只有真实 Dec-POMDP 的分布和噪声模型是共识知识。通过设计一个增强状态空间的元 Dec-POMDP，将 NZSC 问题简化为 ZSC 问题。提出了一种简单灵活的元学习方法 NZSC 训练，代理在一系列协调问题的噪声版本上进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过 NZSC 训练，强化学习代理能够在协调问题的确切设置不是共识知识的情况下，与新伙伴进行良好协调。&lt;h4&gt;结论&lt;/h4&gt;NZSC 训练使得 RL 代理在面对不完全信息时，依然能够有效地进行协调。&lt;h4&gt;总结&lt;/h4&gt;NZSC 提供了一种新方法，可以在缺乏共识知识的情况下提升 RL 代理的协调能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ashishp166/Noisy-Zero-Shot-Coordination&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot coordination (ZSC) is a popular setting for studying the ability ofreinforcement learning (RL) agents to coordinate with novel partners. Prior ZSCformulations assume the $\textit{problem setting}$ is common knowledge: eachagent knows the underlying Dec-POMDP, knows others have this knowledge, and soon ad infinitum. However, this assumption rarely holds in complex real-worldsettings, which are often difficult to fully and correctly specify. Hence, insettings where this common knowledge assumption is invalid, agents trainedusing ZSC methods may not be able to coordinate well. To address thislimitation, we formulate the $\textit{noisy zero-shot coordination}$ (NZSC)problem. In NZSC, agents observe different noisy versions of the ground truthDec-POMDP, which are assumed to be distributed according to a fixed noisemodel. Only the distribution of ground truth Dec-POMDPs and the noise model arecommon knowledge. We show that a NZSC problem can be reduced to a ZSC problemby designing a meta-Dec-POMDP with an augmented state space consisting of allthe ground-truth Dec-POMDPs. For solving NZSC problems, we propose a simple andflexible meta-learning method called NZSC training, in which the agents aretrained across a distribution of coordination problems - which they only get toobserve noisy versions of. We show that with NZSC training, RL agents can betrained to coordinate well with novel partners even when the (exact) problemsetting of the coordination is not common knowledge.</description>
      <author>example@mail.com (Usman Anwar, Ashish Pandian, Jia Wan, David Krueger, Jakob Foerster)</author>
      <guid isPermaLink="false">2411.04976v1</guid>
      <pubDate>Sat, 09 Nov 2024 00:26:14 +0800</pubDate>
    </item>
  <item>
      <title>A Cost-Effective Approach to Smooth A* Path Planning for Autonomous Vehicles</title>
      <link>http://arxiv.org/abs/2411.18150v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, IEEE IAVVC24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的路径规划算法，针对具有非完整约束的车轮式移动机器人，该方法结合了A*算法和基于带状路径规划器生成的平滑路径的方法。通过这种方式，在保证路径可行性的基础上提高了路径的平滑性和可行驶性。&lt;h4&gt;背景&lt;/h4&gt;在自动化及智能交通系统领域中，路径规划是关键组成部分之一。具有非完整约束的车轮式移动机器人（如汽车）对路径规划提出了额外要求。传统路径规划算法（例如A*算法）由于其简单有效而在复杂环境中广泛应用，但这些算法往往不考虑车辆动力学特性，导致生成的路径可能不可行或难以行驶。&lt;h4&gt;目的&lt;/h4&gt;设计一种既能找到可行路径又能确保该路径平滑且可驾驶的路径规划解决方案。&lt;h4&gt;方法&lt;/h4&gt;通过修改A*算法以适应曲率约束，并引入一个评估函数来考虑各种路径的平滑性。使用基于带状路径规划器预先计算出来的运动原语，指导改进后的A*算法寻找长度和曲率最小化的路径。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在不同非结构化环境中都表现出色，在两阶段规划策略中首次使用修改版的A*算法找到栅格路径，然后利用基于带状路径规划器生成平滑路径。最终得到的路径不仅平滑且具有较小曲率，并且不受栅格轴方向的影响。&lt;h4&gt;结论&lt;/h4&gt;本文成功地改进了传统路径规划方法，在保证实际可行驶性的基础上提高了路径的质量和效率。&lt;h4&gt;翻译&lt;/h4&gt;路径规划对于轮式移动机器人的自动化及智能交通系统领域至关重要。非完整约束的车轮式移动机器人在运动能力上施加了额外限制，这增加了对规划路径的要求。尽管传统路径规划算法如A*因其简单性和有效性而被广泛应用，但它们通常忽略了车辆动力学特性，导致生成的路径不可行或不切实际。特别地，在复杂环境中寻找最短路径（即栅格单元数最少）的方法可能会产生对于车轮式机器人来说过于曲折或急转弯的路径。本文旨在提供一种解决方案，该方案不仅找到可行路径，还确保路径平滑且可行驶。通过为A*算法添加曲率约束并引入考虑路径平滑性的成本函数，我们试图弥合基于栅格的路径规划与适合车轮式车辆驾驶的平滑路径之间的差距。所提出的方案利用了预先使用带状路径规划器计算出的运动原语（该规划器生成最小曲率的平滑路径）。这些运动原语指导A*算法寻找长度和曲率最小化的路径。通过提出的方法修改，计划的路径可以约束为具有比栅格尺寸大得多的最小转弯半径。我们在不同的非结构化环境中展示了所提出的算法的有效性。在两阶段规划方法中，在第一阶段使用了改进后的A*算法找到基于栅格的路径，第二阶段利用带状路径规划器生成栅格单元内的平滑路径。所得路径无论障碍物多么尖锐都是平滑且具有较小曲率，并且与栅格轴方向无关。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Path planning for wheeled mobile robots is a critical component in the fieldof automation and intelligent transportation systems. Car-like vehicles, whichhave non-holonomic constraints on their movement capability impose additionalrequirements on the planned paths. Traditional path planning algorithms, suchas A* , are widely used due to their simplicity and effectiveness in findingoptimal paths in complex environments. However, these algorithms often do notconsider vehicle dynamics, resulting in paths that are infeasible orimpractical for actual driving. Specifically, a path that minimizes the numberof grid cells may still be too curvy or sharp for a car-like vehicle tonavigate smoothly. This paper addresses the need for a path planning solutionthat not only finds a feasible path but also ensures that the path is smoothand drivable. By adapting the A* algorithm for a curvature constraint andincorporating a cost function that considers the smoothness of possible paths,we aim to bridge the gap between grid based path planning and smooth paths thatare drivable by car-like vehicles. The proposed method leverages motionprimitives, pre-computed using a ribbon based path planner that produces smoothpaths of minimum curvature. The motion primitives guide the A* algorithm infinding paths of minimal length and curvature. With the proposed modificationon the A* algorithm, the planned paths can be constraint to have a minimumturning radius much larger than the grid size. We demonstrate the effectivenessof the proposed algorithm in different unstructured environments. In atwo-stage planning approach, first the modified A* algorithm finds a grid-basedpath and the ribbon based path planner creates a smooth path within the area ofgrid cells. The resulting paths are smooth with small curvatures independent ofthe orientation of the grid axes and even in presence of sharp obstacles.</description>
      <author>example@mail.com (Lukas Schichler, Karin Festl, Selim Solmaz, Daniel Watzenig)</author>
      <guid isPermaLink="false">2411.18150v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Prediction with Action: Visual Policy Learning via Joint Denoising Process</title>
      <link>http://arxiv.org/abs/2411.18179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PAD是一种新的视觉策略学习框架，将图像预测和机器人动作统一在一个联合去噪过程中。&lt;h4&gt;背景&lt;/h4&gt;扩散模型在图像生成任务中表现出色，并且在通过去噪动作的机器人控制任务中也显示出潜力。尽管它们的能力不同（即图像预测和机器人的行动），但它们采用相似的技术去噪过程。&lt;h4&gt;目的&lt;/h4&gt;将图像预测与机器人行动在一个联合过程中统一，以提高数据高效的模仿学习设置中的性能。&lt;h4&gt;方法&lt;/h4&gt;PAD使用扩散变换器(DiT)无缝集成图像和机器人状态，同时预测未来图像和机器人动作。它支持在机器人演示和大规模视频数据集上的共训练，并可以轻松扩展到其他机器人模态，如深度图像。&lt;h4&gt;主要发现&lt;/h4&gt;PAD利用单个文本条件视觉策略，在完整的Metaworld基准测试中实现了26.3%的相对改进，且在现实世界的机器人操作设置中的未见任务上成功提高了28.0%。&lt;h4&gt;结论&lt;/h4&gt;PAD展示了一种有效的方法，通过结合图像预测和机器人动作，并利用联合去噪过程来改善机器人的学习效率和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;扩散模型已经在包括图像编辑和视频创建在内的图像生成任务中显示出非凡的能力，在这些领域展示了对物理世界的良好理解。在另一个方面，扩散模型也在通过去噪动作的机器人控制任务中表现出潜力。尽管扩散生成模型与扩散策略具有不同的能力（即图像预测和机器人的行动），但从技术上讲，它们遵循相同的去噪过程。在机器人任务中，预测未来图像的能力和生成动作的能力密切相关，因为它们共享物理世界的相同基础动力学。基于这一见解，我们引入了PAD，这是一种新的视觉策略学习框架，它统一了图象预测与机器人行动在一个联合的去噪过程中。具体来说，PAD利用扩散变换器（DiT）无缝集成图像和机器人的状态，使未来图像和机器人动作的同时预测成为可能。此外，PAD支持在机器人演示和大规模视频数据集上的共训练，并且可以轻松扩展到其他机器人模态，如深度图象。通过使用单个文本条件视觉策略，在高效的数据模仿学习设置下，PAD优于先前的方法，在完整的Metaworld基准测试中实现了26.3%的相对改进。此外，与最强基线相比，在现实世界的机器人操作设置中的未见任务上成功提高了28.0%，展示了优秀的泛化能力。项目页面：https://sites.google.com/view/pad-paper&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have demonstrated remarkable capabilities in imagegeneration tasks, including image editing and video creation, representing agood understanding of the physical world. On the other line, diffusion modelshave also shown promise in robotic control tasks by denoising actions, known asdiffusion policy. Although the diffusion generative model and diffusion policyexhibit distinct capabilities--image prediction and robotic action,respectively--they technically follow a similar denoising process. In robotictasks, the ability to predict future images and generate actions is highlycorrelated since they share the same underlying dynamics of the physical world.Building on this insight, we introduce PAD, a novel visual policy learningframework that unifies image Prediction and robot Action within a jointDenoising process. Specifically, PAD utilizes Diffusion Transformers (DiT) toseamlessly integrate images and robot states, enabling the simultaneousprediction of future images and robot actions. Additionally, PAD supportsco-training on both robotic demonstrations and large-scale video datasets andcan be easily extended to other robotic modalities, such as depth images. PADoutperforms previous methods, achieving a significant 26.3% relativeimprovement on the full Metaworld benchmark, by utilizing a singletext-conditioned visual policy within a data-efficient imitation learningsetting. Furthermore, PAD demonstrates superior generalization to unseen tasksin real-world robot manipulation settings with 28.0% success rate increasecompared to the strongest baseline. Project page athttps://sites.google.com/view/pad-paper</description>
      <author>example@mail.com (Yanjiang Guo, Yucheng Hu, Jianke Zhang, Yen-Jen Wang, Xiaoyu Chen, Chaochao Lu, Jianyu Chen)</author>
      <guid isPermaLink="false">2411.18179v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance</title>
      <link>http://arxiv.org/abs/2411.16666v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了CatNet算法，该算法通过Gaussian Mirror (GM) 方法有效地控制错误发现率（FDR）并选择长短期记忆网络(LSTM)中的重要特征。研究还提出了一个新的基于核的方法来度量依赖性，以避免多重共线性问题。&lt;h4&gt;背景&lt;/h4&gt;在时间序列分析中评估LSTM的特征重要性是一个挑战，因为传统的模型无法有效控制错误发现率（FDR）并选择重要的特征。&lt;h4&gt;目的&lt;/h4&gt;目的是引入CatNet算法，改进LSTM模型中的特征选择方法，并通过模拟数据和实际应用验证其性能。&lt;h4&gt;方法&lt;/h4&gt;使用SHAP值的导数向量来评估时间序列中LSTM的特征重要性。还提出了一个新的基于核的方法来度量依赖性并避免多重共线性问题。&lt;h4&gt;主要发现&lt;/h4&gt;CatNet算法在各种情况下有效地控制了FDR，同时保持了较高的统计功效，并且在实际应用中的多因子投资组合预测表现优于传统LSTM模型。&lt;h4&gt;结论&lt;/h4&gt;研究首次将Gaussian Mirror 算法与LSTM模型相结合，并引入SHAP值作为新的特征重要性度量方法。这标志着神经网络中特征选择和误差控制方面的重大进步。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了CatNet算法，该算法利用高斯镜像（GM）方法有效地控制错误发现率并选择LSTM中的显著特征。为了评估时间序列中LSTM的特征重要性，我们引入了SHapley Additive exPlanations (SHAP) 导数向量来衡量特征的重要性。此外，我们提出了一种新的基于核的方法依赖度量以避免GM算法中的多重共线性问题，从而实现稳健的特性选择并控制FDR。使用模拟数据评估CatNet在不同链接函数下的线性和LSTM模型中的性能表现。该算法有效地控制了错误发现率（FDR）并在所有情况下保持较高的统计功效。我们还评估了低维和高维输入情况下的算法性能，证明其稳健性。为了评估CatNet在实际应用中的性能，构建了一个多因子投资组合来预测S&amp;P 500指数成分的价格。结果表明我们的模型相比于不进行特征选择且没有错误发现率控制的传统LSTM模型具有更优秀的预测准确性。此外，CatNet有效地捕捉到影响市场的共同特性，这有助于金融市场中基于数据的决策制定，并提高了预测的解释性。研究首次结合了Gaussian Mirror算法与LSTM模型，并将SHAP值作为新的特征重要度量方法用于错误发现率控制方式，标志着神经网络中的特征选择和误差控制方面的重要进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce CatNet, an algorithm that effectively controls False DiscoveryRate (FDR) and selects significant features in LSTM with the Gaussian Mirror(GM) method. To evaluate the feature importance of LSTM in time series, weintroduce a vector of the derivative of the SHapley Additive exPlanations(SHAP) to measure feature importance. We also propose a new kernel-baseddependence measure to avoid multicollinearity in the GM algorithm, to make arobust feature selection with controlled FDR. We use simulated data to evaluateCatNet's performance in both linear models and LSTM models with different linkfunctions. The algorithm effectively controls the FDR while maintaining a highstatistical power in all cases. We also evaluate the algorithm's performance indifferent low-dimensional and high-dimensional cases, demonstrating itsrobustness in various input dimensions. To evaluate CatNet's performance inreal world applications, we construct a multi-factor investment portfolio toforecast the prices of S\&amp;P 500 index components. The results demonstrate thatour model achieves superior predictive accuracy compared to traditional LSTMmodels without feature selection and FDR control. Additionally, CatNeteffectively captures common market-driving features, which helps informeddecision-making in financial markets by enhancing the interpretability ofpredictions. Our study integrates of the Gaussian Mirror algorithm with LSTMmodels for the first time, and introduces SHAP values as a new featureimportance metric for FDR control methods, marking a significant advancement infeature selection and error control for neural networks.</description>
      <author>example@mail.com (Jiaan Han, Junxiao Chen, Yanzhe Fu)</author>
      <guid isPermaLink="false">2411.16666v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SCoTT: Wireless-Aware Path Planning with Vision Language Models and Strategic Chains-of-Thought</title>
      <link>http://arxiv.org/abs/2411.18212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种使用视觉语言模型（VLM）的新路径规划方法被提出，用于解决复杂无线感知环境中的路径规划问题。&lt;h4&gt;背景&lt;/h4&gt;现有算法在考虑距离最小化的同时增加额外的侧向约束时变得非常复杂。&lt;h4&gt;目的&lt;/h4&gt;探索基于数字孪生和真实世界无线射线追踪数据的方法，以保证平均路径增益阈值并最小化轨迹长度。&lt;h4&gt;方法&lt;/h4&gt;比较了传统的A*算法和其他无线感知扩展，并提出了一种基于VLM的战略链式思考任务（SCoTT）方法。该方法将复杂的规划问题分解为多个子问题并通过高级CoT提示解决这些问题。&lt;h4&gt;主要发现&lt;/h4&gt;与最优迭代动态编程方法DP-WA*相比，SCoTT可以达到非常接近的平均路径增益，并且能够持续缩短路径长度。此外，VLMs可以通过减少算法搜索空间来加速DP-WA*的执行时间，最多可节省62%的时间。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了在各种无线约束条件下，视觉语言模型在未来数字系统中作为解决复杂任务的能力助手和加快快速原型开发方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;路径规划是许多实际应用中的一个复杂问题，特别是在机器人领域。现有算法本质上是详尽的，在考虑额外侧向约束的同时进行距离最小化时变得更加复杂。本文提出了一种使用视觉语言模型（VLM）的新方法来实现在复杂的无线感知环境下的路径规划。为实现这一目标，我们探索了数字孪生中真实世界无线射线追踪数据提供的见解，以确保平均路径增益阈值并尽可能缩短轨迹长度。首先，传统的A*算法与其他无线感知扩展进行比较，并推导出一种最优迭代动态编程方法（DP-WA*），这种方法完全考虑了DT内的所有路径增益和距离度量。基于这些基准线，研究探索了VLM作为替代辅助工具在路径规划中的作用，提出了战略链式思考任务（SCoTT）的方法。SCoTT将复杂的规划任务分解为多个子问题并通过高级CoT提示解决每个子问题。实验结果表明，在达到非常接近DP-WA*的平均路径增益的同时，SCoTT能够持续缩短路径长度。此外，结果显示VLM可以加速DP-WA*通过有效地减少算法搜索空间节省多达62%的时间。这项工作强调了视觉语言模型在未来数字系统中作为解决复杂任务的能力助手，并在各种无线约束条件下增强用户交互和加快快速原型开发方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Path planning is a complex problem for many practical applications,particularly in robotics. Existing algorithms, however, are exhaustive innature and become increasingly complex when additional side constraints areincorporated alongside distance minimization. In this paper, a novel approachusing vision language models (VLMs) is proposed for enabling path planning incomplex wireless-aware environments. To this end, insights from a digital twin(DT) with real-world wireless ray tracing data are explored in order toguarantee an average path gain threshold while minimizing the trajectorylength. First, traditional approaches such as A* are compared to severalwireless-aware extensions, and an optimal iterative dynamic programmingapproach (DP-WA*) is derived, which fully takes into account all path gains anddistance metrics within the DT. On the basis of these baselines, the role ofVLMs as an alternative assistant for path planning is investigated, and astrategic chain-of-thought tasking (SCoTT) approach is proposed. SCoTT dividesthe complex planning task into several subproblems and solves each withadvanced CoT prompting. Results show that SCoTT achieves very close averagepath gains compared to DP-WA* while at the same time yielding consistentlyshorter path lengths. The results also show that VLMs can be used to accelerateDP-WA* by efficiently reducing the algorithm's search space and thus saving upto 62\% in execution time. This work underscores the potential of VLMs infuture digital systems as capable assistants for solving complex tasks, whileenhancing user interaction and accelerating rapid prototyping under diversewireless constraints.</description>
      <author>example@mail.com (Aladin Djuhera, Vlad C. Andrei, Amin Seffo, Holger Boche, Walid Saad)</author>
      <guid isPermaLink="false">2411.18212v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Clustering Time Series Data with Gaussian Mixture Embeddings in a Graph Autoencoder Framework</title>
      <link>http://arxiv.org/abs/2411.16972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  First two listed authors have equal contribution. Author ordering is
  determined by coin flip&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种基于图的时序聚类方法Variational Mixture Graph Autoencoder (VMGAE)，该方法利用图结构的优势来捕获丰富数据关系，并生成高斯混合嵌入以提高分离性。&lt;h4&gt;背景&lt;/h4&gt;时间序列数据分析在金融、医疗保健和环境监测等多个领域广泛应用，传统的时序聚类方法难以捕捉这些数据中复杂的时序依赖关系。&lt;h4&gt;目的&lt;/h4&gt;通过引入图结构的优势来改进时序聚类的效果，并验证该方法在实际场景中的应用价值。&lt;h4&gt;方法&lt;/h4&gt;提出了Variational Mixture Graph Autoencoder (VMGAE)，利用高斯混合嵌入生成技术，增强了数据关系的捕捉能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，相比传统方法，本研究提出的方法显著提高了时序聚类效果，并在实际金融数据上验证了其应用价值。通过揭示股票市场的社区结构，该方法为理解股票之间的关系提供了深入见解。&lt;h4&gt;结论&lt;/h4&gt;VMGAE 方法不仅在技术层面表现出色，在实际场景中也显示出强大的潜力和实用性，尤其是在金融市场预测、投资组合优化和风险管理方面具有重要的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;时间序列数据分析广泛应用于金融、医疗保健以及环境监测等多个领域。传统的时间序列聚类方法往往难以捕捉这些数据中的复杂时序依赖关系。在本文中，我们提出了一种基于图的时序聚类方法Variational Mixture Graph Autoencoder (VMGAE)，该方法利用了图结构的优势来捕获更丰富的数据关系，并生成高斯混合嵌入以提高分离性。实验结果表明我们的方法显著优于现有的时间序列聚类技术。此外，我们还在实际金融数据上验证了这一方法的有效性，展示了它在金融市场预测、投资组合优化以及风险管理中的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series data analysis is prevalent across various domains, includingfinance, healthcare, and environmental monitoring. Traditional time seriesclustering methods often struggle to capture the complex temporal dependenciesinherent in such data. In this paper, we propose the Variational Mixture GraphAutoencoder (VMGAE), a graph-based approach for time series clustering thatleverages the structural advantages of graphs to capture enriched datarelationships and produces Gaussian mixture embeddings for improvedseparability. Comparisons with baseline methods are included with experimentalresults, demonstrating that our method significantly outperformsstate-of-the-art time-series clustering techniques. We further validate ourmethod on real-world financial data, highlighting its practical applications infinance. By uncovering community structures in stock markets, our methodprovides deeper insights into stock relationships, benefiting marketprediction, portfolio optimization, and risk management.</description>
      <author>example@mail.com (Amirabbas Afzali, Hesam Hosseini, Mohmmadamin Mirzai, Arash Amini)</author>
      <guid isPermaLink="false">2411.16972v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Dependency-Aware CAV Task Scheduling via Diffusion-Based Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2411.18230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种新颖的依赖感知的任务调度策略，用于动态无人驾驶飞机辅助的连接自主车辆（CAVs）。具体来说，该策略针对由多个依赖子任务组成的计算任务，在附近其他CAV或基站之间合理分配这些任务以尽快完成。因此，我们制定了一个最小化平均任务完成时间为目标的联合调度优先级和子任务分配优化问题。&lt;h4&gt;背景&lt;/h4&gt;无人驾驶飞机辅助下的连接自主车辆（CAVs）需要高效的任务处理策略来满足实时需求。&lt;h4&gt;目的&lt;/h4&gt;提出一种依赖感知的任务调度方法，以提高动态环境中的系统性能，并缩短任务完成时间。&lt;h4&gt;方法&lt;/h4&gt;提出了基于扩散的强化学习算法（Synthetic DDQN based Subtasks Scheduling），用于在实时环境中进行自适应任务调度。该方法通过整合基于扩散模型的合成经验回放机制来生成足够多的经验数据，加速了收敛速度并提高了样本效率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的算法相比基准方案能够有效缩短任务完成时间。&lt;h4&gt;结论&lt;/h4&gt;本文的方法提供了在动态和依赖环境中进行高效任务调度的新策略，并证明了其性能优于现有解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了一种新颖的依赖感知的任务调度策略，用于由无人机辅助的连接自主车辆中的动态场景。该策略通过合理分配计算子任务到附近的其他CAVs或基站来尽快完成任务。为了最小化平均任务完成时间，我们建立了联合调度优先级和子任务分配优化问题，并将其转化为马尔可夫决策过程以解决长期系统性能提升的问题。为了解决这个问题，我们提出了一种基于扩散的强化学习算法（Synthetic DDQN based Subtasks Scheduling），能够在实时环境中进行自适应的任务调度决策。该算法通过集成扩散模型合成经验回放机制来生成大量训练样本数据，从而显著加速了收敛速度和提高了样例效率。实验结果表明，与基准方案相比，所提出的算法在减少任务完成时间方面具有明显优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel dependency-aware task scheduling strategyfor dynamic unmanned aerial vehicle-assisted connected autonomous vehicles(CAVs). Specifically, different computation tasks of CAVs consisting ofmultiple dependency subtasks are judiciously assigned to nearby CAVs or thebase station for promptly completing tasks. Therefore, we formulate a jointscheduling priority and subtask assignment optimization problem with theobjective of minimizing the average task completion time. The problem aims atimproving the long-term system performance, which is reformulated as a Markovdecision process. To solve the problem, we further propose a diffusion-basedreinforcement learning algorithm, named Synthetic DDQN based SubtasksScheduling, which can make adaptive task scheduling decision in real time. Adiffusion model-based synthetic experience replay is integrated into thereinforcement learning framework, which can generate sufficient synthetic datain experience replay buffer, thereby significantly accelerating convergence andimproving sample efficiency. Simulation results demonstrate the effectivenessof the proposed algorithm on reducing task completion time, comparing tobenchmark schemes.</description>
      <author>example@mail.com (Xiang Cheng, Zhi Mao, Ying Wang, Wen Wu)</author>
      <guid isPermaLink="false">2411.18230v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Energy landscape analysis based on the Ising model: Tutorial review</title>
      <link>http://arxiv.org/abs/2411.16979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了一种基于伊辛模型的能量景观分析方法，能够通过多元时间序列数据捕捉动态过程。&lt;h4&gt;背景&lt;/h4&gt;能量景观分析最初主要用于脑部功能性磁共振成像(fMRI)数据的处理和研究，但如今已在其他非fMRI的数据领域有应用潜力。&lt;h4&gt;目的&lt;/h4&gt;为跨学科的研究人员提供有关该分析方法的详细教程、相关术语及概念，并介绍最新的拓展与关联方法的发展。&lt;h4&gt;方法&lt;/h4&gt;使用伊辛模型能量景观来捕捉多元时间序列数据动态变化的过程，通过模拟一个小球在能量盆地间移动的情况进行建模。&lt;h4&gt;主要发现&lt;/h4&gt;介绍了基于伊辛模型的能量景观分析方法各步骤的操作细节、相关术语及概念，并提供了验证该方法的方法和最新的发展情况。&lt;h4&gt;结论&lt;/h4&gt;尽管此方法起初主要是用于处理脑部fMRI数据，但其在其他非fMRI的数据类型中的应用也在逐渐增加，且这种方法的未来研究方向值得关注。&lt;h4&gt;翻译&lt;/h4&gt;我们回顾了一种基于伊辛模型的能量景观分析方法，该方法使用多元时间序列数据作为输入。这种方法允许人们捕捉到从一个盆地移动到另一个盆地的数据动态过程，并受到所估计的伊辛模型规定的能量景观约束。尽管由于历史原因，这种能量景观分析主要应用于脑部功能性磁共振成像(fMRI)数据中，但是现在有越来越多的应用出现在非fMRI领域和神经科学之外的研究方向。为了指导这些领域的应用研究，这篇综述论文详细介绍了该方法的每个步骤、术语、基础概念以及验证，并且还讨论了相关的方法最近的发展情况。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We review a class of energy landscape analysis method that uses the Isingmodel and takes multivariate time series data as input. The method allows oneto capture dynamics of the data as trajectories of a ball from one basin to adifferent basin to yet another, constrained on the energy landscape specifiedby the estimated Ising model. While this energy landscape analysis has mostlybeen applied to functional magnetic resonance imaging (fMRI) data from thebrain for historical reasons, there are emerging applications outside fMRI dataand neuroscience. To inform such applications in various research fields, thisreview paper provides a detailed tutorial on each step of the analysis,terminologies, concepts underlying the method, and validation, as well asrecent developments of extended and related methods.</description>
      <author>example@mail.com (Naoki Masuda, Saiful Islam, Si Thu Aung, Takamitsu Watanabe)</author>
      <guid isPermaLink="false">2411.16979v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Certified Training with Branch-and-Bound: A Case Study on Lyapunov-stable Neural Control</title>
      <link>http://arxiv.org/abs/2411.18235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了学习Lyapunov稳定神经控制器的问题，这些控制器在吸引域内满足Lyapunov渐近稳定性条件。提出了一个新的认证训练框架CT-BaB，并优化可微验证边界以生成便于验证的模型。&lt;h4&gt;背景&lt;/h4&gt;传统的任务中通常使用反例引导训练方法来解决这一问题，但该研究开发了一个新的、一般化的认证训练框架。&lt;h4&gt;目的&lt;/h4&gt;目的是为了处理相对较大的感兴趣区域，引入了一种新颖的在训练时间进行分支和边界划分的方法。&lt;h4&gt;方法&lt;/h4&gt;通过动态维护一个子区域的数据集，在训练过程中迭代地将最困难的子区域划分为更小的子区域，以便于计算更紧密的验证边界。&lt;h4&gt;主要发现&lt;/h4&gt;新的训练框架生成的模型可以在测试时更加高效地进行验证。在最大的2D四旋翼动力学系统上，该模型的验证速度比基准快5倍以上，同时吸引域的大小是基准的16倍大。&lt;h4&gt;结论&lt;/h4&gt;CT-BaB方法提供了一种更高效的认证训练框架，提高了神经控制器验证效率和性能。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了学习Lyapunov稳定神经控制器的问题，这些控制器在吸引域内满足Lyapunov渐近稳定性条件。与以往的工作不同的是，它们通常使用反例引导训练方法，我们开发了一个新的、一般化的认证训练框架CT-BaB，并优化可微验证边界以生成便于验证的模型。为了处理相对较大的感兴趣区域，我们提出了一种新颖的在训练时间进行分支和边界划分的方法，动态维护一个子区域的数据集，在训练过程中迭代地将最困难的子区域划分为更小的子区域，以便于计算更紧密的验证边界。实验表明我们的新训练框架生成的模型可以在测试时更加高效地进行验证。在一个大型2D四旋翼动力学系统上，该模型的验证速度比基准快5倍以上，同时吸引域的大小是基准的16倍大。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of learning Lyapunov-stable neural controllers whichprovably satisfy the Lyapunov asymptotic stability condition within aregion-of-attraction. Compared to previous works which commonly usedcounterexample guided training on this task, we develop a new and generallyformulated certified training framework named CT-BaB, and we optimize fordifferentiable verified bounds, to produce verification-friendly models. Inorder to handle the relatively large region-of-interest, we propose a novelframework of training-time branch-and-bound to dynamically maintain a trainingdataset of subregions throughout training, such that the hardest subregions areiteratively split into smaller ones whose verified bounds can be computed moretightly to ease the training. We demonstrate that our new training frameworkcan produce models which can be more efficiently verified at test time. On thelargest 2D quadrotor dynamical system, verification for our model is more than5X faster compared to the baseline, while our size of region-of-attraction is16X larger than the baseline.</description>
      <author>example@mail.com (Zhouxing Shi, Cho-Jui Hsieh, Huan Zhang)</author>
      <guid isPermaLink="false">2411.18235v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CMAViT: Integrating Climate, Managment, and Remote Sensing Data for Crop Yield Estimation with Multimodel Vision Transformers</title>
      <link>http://arxiv.org/abs/2411.16989v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种名为CMAViT的深度学习多模型，用于像素级别的葡萄园产量预测。该模型结合了空间和时间数据，并纳入了管理实践的影响。&lt;h4&gt;背景&lt;/h4&gt;作物产量预测对于农业规划至关重要，但由于天气、气候与管理措施之间的复杂相互作用而充满挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效进行葡萄园产量预测的新方法，特别是针对极端值的准确预测。&lt;h4&gt;方法&lt;/h4&gt;CMAViT利用遥感影像和短期气象数据结合文本形式表示的管理实践，采用交叉注意力编码器来建模它们与时间序列数据之间的相互作用。该模型在2016年至2019年涵盖2,200公顷的土地上的大型数据集上进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;CMAViT在空间变异性的捕获和产量预测方面优于传统模型（如UNet-ConvLSTM），并在未见测试数据集中实现了R²为0.84，MAPE为8.22%的成绩。去除特定模态后性能显著下降。&lt;h4&gt;结论&lt;/h4&gt;CMAViT提供了一种有效的方法来解决复杂农业环境下的产量预测问题，并强调了融合不同数据源（如气候、管理实践）的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的深度学习多模型——Climate-Management Aware Vision Transformer (CMAViT)，旨在进行葡萄园像素级别的作物产量预测。该研究利用遥感图像和短期气象数据，同时结合文本形式表示的管理实践信息，通过创新性的交叉注意力机制来增强时间序列数据的效果。试验结果表明，在大量实际应用场景中，相较于传统的UNet-ConvLSTM等模型，CMAViT能够更好地捕捉空间变异性和预测产量，特别是在处理极端值时表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Crop yield prediction is essential for agricultural planning but remainschallenging due to the complex interactions between weather, climate, andmanagement practices. To address these challenges, we introduce a deeplearning-based multi-model called Climate-Management Aware Vision Transformer(CMAViT), designed for pixel-level vineyard yield predictions. CMAViTintegrates both spatial and temporal data by leveraging remote sensing imageryand short-term meteorological data, capturing the effects of growing seasonvariations. Additionally, it incorporates management practices, which arerepresented in text form, using a cross-attention encoder to model theirinteraction with time-series data. This innovative multi-modal transformertested on a large dataset from 2016-2019 covering 2,200 hectares and eightgrape cultivars including more than 5 million vines, outperforms traditionalmodels like UNet-ConvLSTM, excelling in spatial variability capture and yieldprediction, particularly for extreme values in vineyards. CMAViT achieved an R2of 0.84 and a MAPE of 8.22% on an unseen test dataset. Masking specificmodalities lowered performance: excluding management practices, climate data,and both reduced R2 to 0.73, 0.70, and 0.72, respectively, and raised MAPE to11.92%, 12.66%, and 12.39%, highlighting each modality's importance foraccurate yield prediction. Code is available athttps://github.com/plant-ai-biophysics-lab/CMAViT.</description>
      <author>example@mail.com (Hamid Kamangir, Brent. S. Sams, Nick Dokoozlian, Luis Sanchez, J. Mason. Earles)</author>
      <guid isPermaLink="false">2411.16989v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>FollowGen: A Scaled Noise Conditional Diffusion Model for Car-Following Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2411.16747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2406.11941&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种基于扩散模型的车辆跟随轨迹预测方法，通过引入噪声缩放机制和跨注意力Transformer架构来捕捉历史车辆动态及其相互作用，提高了自动驾驶场景中车辆轨迹预测的准确性和合理性。&lt;h4&gt;背景&lt;/h4&gt;基于深度学习的方法在车辆轨迹预测方面取得了显著进步，特别是在处理复杂非线性模式时。然而，这些模型通常忽略了实际驾驶应用中关键的细节行为和车辆间的交互情况。&lt;h4&gt;目的&lt;/h4&gt;为了提高车辆跟随轨迹预测的准确性，该研究提出了一种新的噪声条件扩散模型。&lt;h4&gt;方法&lt;/h4&gt;采用一种创新的数据管道，在扩散过程中通过编码历史特征来缩放噪声，以捕捉详细的车辆间相互作用。具体而言，利用基于跨注意力机制的Transformer架构建模复杂的车辆依赖关系，增强去噪过程并提升预测准确性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在多种现实驾驶场景中具有卓越性能和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过将详细的车辆跟随行为和车辆间交互集成到生成框架中，该方法提高了轨迹预测的准确性和合理性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicle trajectory prediction is crucial for advancing autonomous driving andadvanced driver assistance systems (ADAS). Although deep learning-basedapproaches - especially those utilizing transformer-based and generative models- have markedly improved prediction accuracy by capturing complex, non-linearpatterns in vehicle dynamics and traffic interactions, they frequently overlookdetailed car-following behaviors and the inter-vehicle interactions criticalfor real-world driving applications, particularly in fully autonomous or mixedtraffic scenarios. To address the issue, this study introduces a scaled noiseconditional diffusion model for car-following trajectory prediction, whichintegrates detailed inter-vehicular interactions and car-following dynamicsinto a generative framework, improving both the accuracy and plausibility ofpredicted trajectories. The model utilizes a novel pipeline to capturehistorical vehicle dynamics by scaling noise with encoded historical featureswithin the diffusion process. Particularly, it employs a cross-attention-basedtransformer architecture to model intricate inter-vehicle dependencies,effectively guiding the denoising process and enhancing prediction accuracy.Experimental results on diverse real-world driving scenarios demonstrate thestate-of-the-art performance and robustness of the proposed method.</description>
      <author>example@mail.com (Junwei You, Rui Gan, Weizhe Tang, Zilin Huang, Jiaxi Liu, Zhuoyu Jiang, Haotian Shi, Keshu Wu, Keke Long, Sicheng Fu, Sikai Chen, Bin Ran)</author>
      <guid isPermaLink="false">2411.16747v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Grid-augumented vision: A simple yet effective approach for enhanced spatial understanding in multi-modal agents</title>
      <link>http://arxiv.org/abs/2411.18270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近的多模态模型在物体识别和场景理解方面取得了显著成果，但在精确的空间定位上面临挑战。本文提出了一种通过网格叠加方法引入视觉位置编码的方法，从而提高模型的空间定位能力。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态模型虽然在物体识别和场景理解方面表现出色，但对于实际应用中至关重要的精准空间定位仍存在不足。&lt;h4&gt;目的&lt;/h4&gt;为了改进模型的精确空间定位能力，提出了一种基于人类网格参考系统（如棋盘和地图）的方法来引入显式的视觉位置编码。&lt;h4&gt;方法&lt;/h4&gt;通过在输入图像上添加一个9x9的黑色网格图案，提供类似Transformer中位置编码的功能但更直观、具体的视觉引导。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，在COCO 2017数据集上，基于网格的方法显著提高了定位精度：IoU从0.27提高到0.56（增加了107.4%），GIoU从0.18提高到0.53（增加了194.4%）。通过注意力可视化分析证明了视觉位置编码有助于模型更好地理解空间关系。&lt;h4&gt;结论&lt;/h4&gt;该方法简单且有效，特别适用于需要准确空间推理的应用场景，如机器人操作、医学成像和自动驾驶导航等。&lt;h4&gt;翻译&lt;/h4&gt;最近在多模态模型上的进展展示了物体识别和场景理解方面的能力，但这些模型通常难以实现精确的空间定位——这对于实际应用来说是至关重要的能力。受人类使用网格参考系统（例如棋盘或地图）的启发，我们提出了一种通过简单地将9x9黑色网格叠加在输入图像上来引入显式的视觉位置编码的方法，这类似于Transformer中的位置编码，但以一种更直观、可视的方式呈现。实验显示，在COCO 2017数据集上，该方法实现了显著的空间定位准确性的提升：IoU从0.27提高到0.56（增加了107.4%），GIoU从0.18提高到0.53（增加了194.4%）。通过注意机制的可视化分析表明视觉位置编码有助于模型更好地理解和定位空间关系。本方法因其简单性和有效性，对于需要精确空间推理的应用场景特别有价值，例如机器人操作、医学成像和自动驾驶导航等。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in multimodal models have demonstrated impressivecapabilities in object recognition and scene understanding. However, thesemodels often struggle with precise spatial localization - a critical capabilityfor real-world applications. Inspired by how humans use grid-based referenceslike chess boards and maps, we propose introducing explicit visual positionencoding through a simple grid overlay approach. By adding a 9x9 black gridpattern onto input images, our method provides visual spatial guidanceanalogous to how positional encoding works in transformers, but in an explicit,visual form.  Experiments on the COCO 2017 dataset demonstrate that our grid-based approachachieves significant improvements in localization accuracy, with a 107.4%increase in IoU (from 0.27 to 0.56) and a 194.4% improvement in GIoU (from 0.18to 0.53) compared to baseline performance. Through attention visualizationanalysis, we show how this visual position encoding helps models better groundspatial relationships. Our method's simplicity and effectiveness make itparticularly valuable for applications requiring accurate spatial reasoning,such as robotic manipulation, medical imaging, and autonomous navigation.</description>
      <author>example@mail.com (Joongwon Chae, Zhenyu Wang, Peiwu Qin)</author>
      <guid isPermaLink="false">2411.18270v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Achieving Privacy Utility Balance for Multivariate Time Series Data</title>
      <link>http://arxiv.org/abs/2411.17035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个多变量全通（MAP）过滤方法，该方法通过优化算法来平衡数据实用性和隐私保护。&lt;h4&gt;背景&lt;/h4&gt;噪声添加的隐私机制会扭曲时间序列数据中的自相关模式，影响数据实用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于多变量数据的全通过滤方法，并评估其在保持数据实用性的同时实现隐私保护的效果。&lt;h4&gt;方法&lt;/h4&gt;使用优化算法实现一个多变量全通（MAP）过滤方法，将其应用于模拟和真实数据集进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证了所提出的多变量全通（MAP）过滤方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;新提出的方法能够有效地保持时间序列数据的实用性和隐私保护平衡。&lt;h4&gt;翻译&lt;/h4&gt;具有实用性的数据私有化对生产数据的机构至关重要。流行的噪声添加隐私机制会扭曲时间序列数据中的自相关模式，从而损害实用性；对此，McElroy等人（2023）提出了全通过滤（FLIP）作为一种保持实用性的时序数据私有化方法。将此概念适应于多变量数据更为复杂，在本文中我们提出了一种多变量全通（MAP）过滤方法，采用优化算法以实现数据实用性和隐私保护的最佳平衡。为了测试我们的方法的有效性，我们将MAP过滤应用于来自美国人口普查局季度劳动力指标(QWI)数据集的模拟和真实数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Utility-preserving data privatization is of utmost importance fordata-producing agencies. The popular noise-addition privacy mechanism distortsautocorrelation patterns in time series data, thereby marring utility; inresponse, McElroy et al. (2023) introduced all-pass filtering (FLIP) as autility-preserving time series data privatization method. Adapting this conceptto multivariate data is more complex, and in this paper we propose amultivariate all-pass (MAP) filtering method, employing an optimizationalgorithm to achieve the best balance between data utility and privacyprotection. To test the effectiveness of our approach, we apply MAP filteringto both simulated and real data, sourced from the U.S. Census Bureau'sQuarterly Workforce Indicator (QWI) dataset.</description>
      <author>example@mail.com (Gaurab Hore, Tucker McElroy, Anindya Roy)</author>
      <guid isPermaLink="false">2411.17035v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>GAPartManip: A Large-scale Part-centric Dataset for Material-Agnostic Articulated Object Manipulation</title>
      <link>http://arxiv.org/abs/2411.18276v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了在家庭场景中操纵关节对象的有效方法，以实现通用的具身人工智能。传统研究集中在通过深度感知和姿态检测进行操作，但在现实环境中这些方法面临诸如透明盖子和反光手柄造成的不完美深度感知等挑战。&lt;h4&gt;背景&lt;/h4&gt;主流3D视觉研究主要关注于通过深度感知和姿态检测来执行操纵任务。然而，在实际环境下，这些问题往往会遇到由于物体表面特性（如透明或反射）导致的深度信息获取不准的情况。&lt;h4&gt;目的&lt;/h4&gt;提出一种大规模基于组件的数据集，该数据集包括照片级真实的材料随机化以及详细标注的面向部件、场景级别的可操作交互姿态注释。目的是解决现有方法在真实环境中遇到的问题，并为灵活和适应性操控提供必要的多样性。&lt;h4&gt;方法&lt;/h4&gt;引入了一个大型的以部分为中心的数据集来支持关节对象的操作，该数据集具有照片级的真实材料随机化和详细的基于组件的、场景级别的可操作交互姿态注释。通过将这些新方法与最先进的深度估计和交互姿势预测技术相结合进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的框架在模拟环境和真实世界环境中都展示了优于现有模型的表现，特别是在深度感知和可操作互动姿态预测方面。&lt;h4&gt;结论&lt;/h4&gt;新的数据集及其应用的模块化框架极大地改善了关节对象操纵的灵活性和适应性，在理论和实践两个层面上均取得了显著效果。&lt;h4&gt;翻译&lt;/h4&gt;有效地在家庭场景中操控关节物体是迈向通用具身人工智能的关键一步。主流3D视觉研究主要聚焦于通过深度感知与姿态检测进行操作，然而，实际环境中的这些方法常常会遇到由于不完美的深度感知（如透明盖子和反光手柄）带来的挑战。此外，它们通常缺乏支撑灵活及适应性操控所需的基于组件的互动多样性。为了应对上述挑战，我们推出了一种大规模以部分为中心的数据集，该数据集中涵盖了照片级的真实材料随机化以及详细的面向部件、场景级别的可操作交互姿态注释。通过将这些方法与最先进的深度估计和交互姿势预测技术相结合进行评估后发现：我们的数据集显著提升了仿真及真实世界环境中的深度感知性能以及可操作互动姿态预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively manipulating articulated objects in household scenarios is acrucial step toward achieving general embodied artificial intelligence.Mainstream research in 3D vision has primarily focused on manipulation throughdepth perception and pose detection. However, in real-world environments, thesemethods often face challenges due to imperfect depth perception, such as withtransparent lids and reflective handles. Moreover, they generally lack thediversity in part-based interactions required for flexible and adaptablemanipulation. To address these challenges, we introduced a large-scalepart-centric dataset for articulated object manipulation that features bothphoto-realistic material randomizations and detailed annotations ofpart-oriented, scene-level actionable interaction poses. We evaluated theeffectiveness of our dataset by integrating it with several state-of-the-artmethods for depth estimation and interaction pose prediction. Additionally, weproposed a novel modular framework that delivers superior and robustperformance for generalizable articulated object manipulation. Our extensiveexperiments demonstrate that our dataset significantly improves the performanceof depth perception and actionable interaction pose prediction in bothsimulation and real-world scenarios.</description>
      <author>example@mail.com (Wenbo Cui, Chengyang Zhao, Songlin Wei, Jiazhao Zhang, Haoran Geng, Yaran Chen, He Wang)</author>
      <guid isPermaLink="false">2411.18276v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Conformalised Conditional Normalising Flows for Joint Prediction Regions in time series</title>
      <link>http://arxiv.org/abs/2411.17042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop on Bayesian Decision-making and Uncertainty, 38th Conference
  on Neural Information Processing Systems (NeurIPS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法，用于对条件正常流进行形式化处理，并解决了多步时间序列预测的预测区域问题。&lt;h4&gt;背景&lt;/h4&gt;在机器学习模型中量化不确定性时，形式化预测提供了一个强大的框架，可以构建具有有限样本有效性的预测集。然而，将形式化预测应用于概率生成模型（如正规化流程）并不直接。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来对条件正则流进行形式化处理，并解决多步时间序列预测的预测区域问题。&lt;h4&gt;方法&lt;/h4&gt;利用正常流的灵活性，可以生成可能不相交的预测区域，从而在潜在的多重分布情况下提高预测效率。&lt;h4&gt;主要发现&lt;/h4&gt;通过提出的方法，可以在多模式预测分布的情况下有效地构建预测集，提高了预测的有效性。&lt;h4&gt;结论&lt;/h4&gt;该工作为条件正则化流程提供了形式化的途径，并证明了其在解决多步时间序列预测问题中的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了一种新的方法，用于对概率生成模型进行形式化处理，特别是针对正常流的条件版本。这种方法利用了正规化流程可以产生潜在不相交区域的能力，在存在多重分布的情况下提高了预测效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conformal Prediction offers a powerful framework for quantifying uncertaintyin machine learning models, enabling the construction of prediction sets withfinite-sample validity guarantees. While easily adaptable to non-probabilisticmodels, applying conformal prediction to probabilistic generative models, suchas Normalising Flows is not straightforward. This work proposes a novel methodto conformalise conditional normalising flows, specifically addressing theproblem of obtaining prediction regions for multi-step time series forecasting.Our approach leverages the flexibility of normalising flows to generatepotentially disjoint prediction regions, leading to improved predictiveefficiency in the presence of potential multimodal predictive distributions.</description>
      <author>example@mail.com (Eshant English, Christoph Lippert)</author>
      <guid isPermaLink="false">2411.17042v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Don't Let Your Robot be Harmful: Responsible Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2411.18289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Safety-as-policy的方法，该方法通过模拟含有安全风险的场景和任务训练机器人，并使其能够避免危险地完成任务。&lt;h4&gt;背景&lt;/h4&gt;在执行人类指令时，机器人的无脑操作可能导致严重的安全隐患，例如中毒、火灾甚至爆炸。为了减轻这些风险，需要一种新的机制来指导机器人如何处理潜在的危害。&lt;h4&gt;目的&lt;/h4&gt;引入负责任的机器人操控方法，使机器人能够在完成复杂操作的同时考虑现实环境中的安全问题，并以更高效的方式执行任务。&lt;h4&gt;方法&lt;/h4&gt;{'Safety-as-policy': [{'子项1': '世界模型', '描述': '自动产生包含安全风险的情景进行虚拟交互'}, {'子项2': '心智模型', '描述': '通过反思推断后果，逐步发展对安全的认知'}], 'SafeBox数据集': '包括100个负责的机器人操控任务及其不同安全风险场景和指令'}&lt;h4&gt;主要发现&lt;/h4&gt;Safety-as-policy方法在合成数据集和实际实验中都能有效避开危险并高效完成任务，比基线方法有显著提升。&lt;h4&gt;结论&lt;/h4&gt;SafeBox数据集可以作为未来研究的安全、有效的基准测试平台，且其评估结果与现实世界场景一致。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unthinking execution of human instructions in robotic manipulation can leadto severe safety risks, such as poisonings, fires, and even explosions. In thispaper, we present responsible robotic manipulation, which requires robots toconsider potential hazards in the real-world environment while completinginstructions and performing complex operations safely and efficiently. However,such scenarios in real world are variable and risky for training. To addressthis challenge, we propose Safety-as-policy, which includes (i) a world modelto automatically generate scenarios containing safety risks and conduct virtualinteractions, and (ii) a mental model to infer consequences with reflectionsand gradually develop the cognition of safety, allowing robots to accomplishtasks while avoiding dangers. Additionally, we create the SafeBox syntheticdataset, which includes one hundred responsible robotic manipulation tasks withdifferent safety risk scenarios and instructions, effectively reducing therisks associated with real-world experiments. Experiments demonstrate thatSafety-as-policy can avoid risks and efficiently complete tasks in bothsynthetic dataset and real-world experiments, significantly outperformingbaseline methods. Our SafeBox dataset shows consistent evaluation results withreal-world scenarios, serving as a safe and effective benchmark for futureresearch.</description>
      <author>example@mail.com (Minheng Ni, Lei Zhang, Zihan Chen, Lei Zhang, Wangmeng Zuo)</author>
      <guid isPermaLink="false">2411.18289v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MTS-UNMixers: Multivariate Time Series Forecasting via Channel-Time Dual Unmixing</title>
      <link>http://arxiv.org/abs/2411.17770v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了MTS-UNMixer模型，通过在时间和通道维度上分解多变量时间序列数据来解决其高维性和混合模式带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;利用多变量时间序列数据进行未来预测时面临着高维性问题和复杂的混合模式，这使得建立历史与未来的映射关系变得困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够处理多变量时间序列数据的模型，以提高对未来预测的准确性和物理可解释性。&lt;h4&gt;方法&lt;/h4&gt;引入了通道-时间双解混网络（MTS-UNMixer），该网络能够在时间和通道维度上将整个系列分解为关键基和系数，并通过共享机制连接历史与未来的时间序列。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MTS-UNMixer模型在多个基准数据集上的性能显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;MTS-UNMixer提供了一种新的框架来处理多变量时间序列数据的复杂性，并通过分解和共享机制提高了预测能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多变量时间序列数据提供了一个强大的框架，可以利用多个维度的信息来进行未来预测，在实际场景中具有广泛的应用。然而，它们的高度维数和混合模式在建立历史和未来的系列之间的可解释和明确映射方面以及提取长距离特征依赖关系方面带来了重大挑战。为了解决这些挑战，我们提出了一种通道-时间双解混网络（命名为MTS-UNMixer）用于多变量时间序列预测，该网络将整个系列分解为在时间和频道维度上的关键基和系数。这种方法建立了历史和未来系列之间的稳健共享机制，能够准确表示并增强物理可解释性。具体而言，MTS-UNMixers将随时间的序列表示为多个趋势和周期的混合，并且这些与时相关的表示系数在历史和未来的时期之间共享。相反，频道上的序列可以分解成多个点基，这些描述通道相关性的点基在整个系列中共享。为了估计时变共因变量，采用了一个朴素的Mamba网络，利用其与方向因果关系的一致性。相比之下，双向Mamba网络被用来建模整个系列中的通道相关的点基，以适应非因果关系。实验结果显示MTS-UNMixers在多个基准数据集上的表现显著优于现有方法。代码可以在https://github.com/ZHU-0108/MTS-UNMixers上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhu-0108/mts-unmixers&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series data provide a robust framework for futurepredictions by leveraging information across multiple dimensions, ensuringbroad applicability in practical scenarios. However, their high dimensionalityand mixing patterns pose significant challenges in establishing aninterpretable and explicit mapping between historical and future series, aswell as extracting long-range feature dependencies. To address thesechallenges, we propose a channel-time dual unmixing network for multivariatetime series forecasting (named MTS-UNMixer), which decomposes the entire seriesinto critical bases and coefficients across both the time and channeldimensions. This approach establishes a robust sharing mechanism betweenhistorical and future series, enabling accurate representation and enhancingphysical interpretability. Specifically, MTS-UNMixers represent sequences overtime as a mixture of multiple trends and cycles, with the time-correlatedrepresentation coefficients shared across both historical and future timeperiods. In contrast, sequence over channels can be decomposed into multipletick-wise bases, which characterize the channel correlations and are sharedacross the whole series. To estimate the shared time-dependent coefficients, avanilla Mamba network is employed, leveraging its alignment with directionalcausality. Conversely, a bidirectional Mamba network is utilized to model theshared channel-correlated bases, accommodating noncausal relationships.Experimental results show that MTS-UNMixers significantly outperform existingmethods on multiple benchmark datasets. The code is available athttps://github.com/ZHU-0108/MTS-UNMixers.</description>
      <author>example@mail.com (Xuanbing Zhu, Dunbin Shen, Zhongwen Rao, Huiyi Ma, Yingguang Hao, Hongyu Wang)</author>
      <guid isPermaLink="false">2411.17770v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing energy consumption for legged robot by adapting equilibrium position and stiffness of a parallel torsion spring</title>
      <link>http://arxiv.org/abs/2411.18295v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的自适应扭簧机制，用于优化腿足机器人的能量消耗。&lt;h4&gt;背景&lt;/h4&gt;现有的腿部机器人在行走和跳跃等周期性运动中存在能量效率问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够调整平衡位置和刚度的新型自适应扭转弹簧机制，以提高周期性运动中的能源利用效率。&lt;h4&gt;方法&lt;/h4&gt;使用扭簧与蜗杆齿轮组合的方式，并由伺服驱动器控制，以此补偿运动引起的扭矩并降低电机负载。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟实验展示了该系统显著减少了能量消耗。&lt;h4&gt;结论&lt;/h4&gt;自适应柔顺机制在提高机器人行走性能方面显示出巨大的潜力和有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为：This paper is dedicated to the development of a novel adaptive torsion spring mechanism for optimizing energy consumption in legged robots. By adjusting the equilibrium position and stiffness of the spring, the system improves energy efficiency during cyclic movements, such as walking and jumping. The adaptive compliance mechanism, consisting of a torsion spring combined with a worm gear driven by a servo actuator, compensates for motion-induced torque and reduces motor load. Simulation results demonstrate a significant reduction in power consumption, highlighting the effectiveness of this approach in enhancing robotic locomotion.&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper is dedicated to the development of a novel adaptive torsion springmechanism for optimizing energy consumption in legged robots. By adjusting theequilibrium position and stiffness of the spring, the system improves energyefficiency during cyclic movements, such as walking and jumping. The adaptivecompliance mechanism, consisting of a torsion spring combined with a worm geardriven by a servo actuator, compensates for motion-induced torque and reducesmotor load. Simulation results demonstrate a significant reduction in powerconsumption, highlighting the effectiveness of this approach in enhancingrobotic locomotion.</description>
      <author>example@mail.com (Danil Belov, Artem Erkhov, Farit Khabibullin, Elisaveta Pestova, Sergei Satsevich, Ilya Osokin, Pavel Osinenko, Dzmitry Tsetserukou)</author>
      <guid isPermaLink="false">2411.18295v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>InterHub: A Naturalistic Trajectory Dataset with Dense Interaction for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2411.18302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了InterHub，这是一个通过挖掘大量自然驾驶记录中多代理互动事件来创建的密集型数据集。它旨在解决现有自动驾驶研究缺乏丰富的交互行为数据的问题。&lt;h4&gt;背景&lt;/h4&gt;现实世界中的驾驶场景往往难以捕捉到丰富且复杂的交互事件，现有的自主驾驶解决方案在这方面存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提供一个可以扩展并用于大规模研究和跨比较研究的密集型交互数据集以及相应的工具包，以促进自动驾驶技术的发展和评估。&lt;h4&gt;方法&lt;/h4&gt;采用正式的方法来描述和提取多代理交互事件，并开发了一个用户友好的工具包，以便使用公共或私有数据扩充InterHub。&lt;h4&gt;主要发现&lt;/h4&gt;通过统一、分类和分析各种类型的互动行为，InterHub揭示了现有自主驾驶解决方案的不足之处，有助于进行跨比较研究以及大规模的研究工作。&lt;h4&gt;结论&lt;/h4&gt;InterHub及其配套工具为自动驾驶技术的发展提供了宝贵的资源，并将推动该领域的创新。&lt;h4&gt;翻译&lt;/h4&gt;自动驾驶中的交互是一个重要且复杂的日常驾驶方面，在自动驾驶研究中处于核心地位。然而，实际驾驶场景很少捕捉到丰富的互动事件，限制了全面轨迹数据集的可用性，以解决这一挑战，我们提出了InterHub，这是一个通过从广泛的自然驾驶记录中挖掘互动事件而产生的密集型互动数据集。我们利用形式方法来描述和提取多代理交互事件，揭示现有自动驾驶解决方案的局限性。此外，我们引入了一个用户友好的工具包，使使用公共或私有数据扩展InterHub成为可能。通过统一、分类和分析各种类型的互动行为，InterHub促进了跨比较研究以及大规模的研究工作，并推动了自动驾驶技术评估和发展方面的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zxc-tju/InterHub&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The driving interaction-a critical yet complex aspect of daily driving-liesat the core of autonomous driving research. However, real-world drivingscenarios sparsely capture rich interaction events, limiting the availabilityof comprehensive trajectory datasets for this purpose. To address thischallenge, we present InterHub, a dense interaction dataset derived by mininginteraction events from extensive naturalistic driving records. We employformal methods to describe and extract multi-agent interaction events, exposingthe limitations of existing autonomous driving solutions. Additionally, weintroduce a user-friendly toolkit enabling the expansion of InterHub with bothpublic and private data. By unifying, categorizing, and analyzing diverseinteraction events, InterHub facilitates cross-comparative studies andlarge-scale research, thereby advancing the evaluation and development ofautonomous driving technologies.</description>
      <author>example@mail.com (Xiyan Jiang, Xiaocong Zhao, Yiru Liu, Zirui Li, Peng Hang, Lu Xiong, Jian Sun)</author>
      <guid isPermaLink="false">2411.18302v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Disentangled Interpretable Representation for Efficient Long-term Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2411.17257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work is submitted to IEEE International Conference on Data
  Engineering (ICDE) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的模型DiPE-Linear，旨在解决长期时间序列预测（LTSF）中的参数复杂性和可解释性问题。&lt;h4&gt;背景&lt;/h4&gt;工业5.0带来了高维、高分辨率数据和高风险应用的挑战，现有深度学习和线性模型往往存在过多的参数复杂度以及缺乏直观的可解释性。&lt;h4&gt;目的&lt;/h4&gt;开发高效且具有解释性的LTSF模型。&lt;h4&gt;方法&lt;/h4&gt;提出了DiPE-Linear（分解化可解释的参数高效的线性网络），该模型集成了静态频域注意、静态时域注意和独立频域映射三个时间组件，交替在频率与时间维度上学习以实现分离化的可解释性。此外，采用低秩权重共享策略增强多变量序列处理能力。&lt;h4&gt;主要发现&lt;/h4&gt;DiPE-Linear通过分解模型结构将参数复杂度从全连接网络的二次降低到线性的，并且计算复杂度也从二次减少到了对数线性。&lt;h4&gt;性能表现&lt;/h4&gt;尽管在表达力有限的子空间中运行，但DiPE-Linear在多个开源和真实世界LTSF数据集上展示了与全连接网络和其他非线性模型相比同等或更优的表现。&lt;h4&gt;结论&lt;/h4&gt;结合了效率、准确性和可解释性的DiPE-Linear是推进研究和实际应用中LTSF的强有力候选方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：工业5.0为长期时间序列预测（LTSF）带来了新的挑战，这些挑战体现在高维、高分辨率数据及具有重大后果的应用场景上。在此背景下，开发高效且可解释的模型成为关键问题。现有的深度学习和线性模型通常受到过多参数复杂度的影响，并缺乏直观的解释能力。为了应对这些问题，我们提出了一种名为DiPE-Linear（分解化可解释的参数高效的线性网络）的方法。该方法集成了三个时间组件：静态频域注意、静态时域注意和独立频域映射，这些组件在频率与时间维度间交替学习以实现分离化的可解释性。通过分解模型结构，DiPE-Linear将全连接网络（FCs）的参数复杂度从二次降低到线性，并将计算复杂度从二次减少到了对数线性的水平。此外，低秩权重共享策略增强了该模型处理多变量序列的能力。尽管在表达能力有限的子空间中运行，DiPE-Linear在多个开源和真实世界LTSF数据集中展示了与全连接网络和其他非线性模型相比相当或更优的表现，证明了其复杂设计的有效性。凭借效率、准确性以及可解释性的结合，DiPE-Linear成为推进研究及实际应用中LTSF的强大候选方案。源代码可在https://github.com/wintertee/DiPE-Linear上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wintertee/dipe-linear&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industry 5.0 introduces new challenges for Long-term Time Series Forecasting(LTSF), characterized by high-dimensional, high-resolution data and high-stakesapplication scenarios. Against this backdrop, developing efficient andinterpretable models for LTSF becomes a key challenge. Existing deep learningand linear models often suffer from excessive parameter complexity and lackintuitive interpretability. To address these issues, we propose DiPE-Linear, aDisentangled interpretable Parameter-Efficient Linear network. DiPE-Linearincorporates three temporal components: Static Frequential Attention (SFA),Static Temporal Attention (STA), and Independent Frequential Mapping (IFM).These components alternate between learning in the frequency and time domainsto achieve disentangled interpretability. The decomposed model structurereduces parameter complexity from quadratic in fully connected networks (FCs)to linear and computational complexity from quadratic to log-linear.Additionally, a Low-Rank Weight Sharing policy enhances the model's ability tohandle multivariate series. Despite operating within a subspace of FCs withlimited expressive capacity, DiPE-Linear demonstrates comparable or superiorperformance to both FCs and nonlinear models across multiple open-source andreal-world LTSF datasets, validating the effectiveness of its sophisticatedlydesigned structure. The combination of efficiency, accuracy, andinterpretability makes DiPE-Linear a strong candidate for advancing LTSF inboth research and real-world applications. The source code is available athttps://github.com/wintertee/DiPE-Linear.</description>
      <author>example@mail.com (Yuang Zhao, Tianyu Li, Jiadong Chen, Shenrong Ye, Fuxin Jiang, Tieying Zhang, Xiaofeng Gao)</author>
      <guid isPermaLink="false">2411.17257v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Leaning Time-Varying Instruments for Identifying Causal Effects in Time-Series Data</title>
      <link>http://arxiv.org/abs/2411.17774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的方法来解决时间序列数据分析中的因果效应估计问题，特别是在存在时间变化的潜在混淆变量时。&lt;h4&gt;背景&lt;/h4&gt;在医疗、经济、气候科学和流行病学等多个领域中，从时间序列数据查询因果效应非常重要。然而，在存在随时间变动的潜在混淆因素的情况下，该任务变得复杂，并可能引入偏倚。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法——TDCIV（时变条件工具变量），以解决传统工具变量方法在动态环境下的局限性，从而准确估计因果效应。&lt;h4&gt;方法&lt;/h4&gt;利用长短期记忆(LSTM)和变分自编码器(VAE)模型从代理变量中解开并学习时间变化的CIV及其相关条件集合，无需先验知识。&lt;h4&gt;主要发现&lt;/h4&gt;TDCIV是首个能够在没有领域特定知识的情况下有效学习时变CIV的方法，并且在满足马尔可夫性质和可用代理变量的前提下，理论验证了所学表示的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法有望提高时间序列数据中的因果效应估计准确性，尤其是在动态环境中处理复杂的时间变化潜在混淆因素。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Querying causal effects from time-series data is important across variousfields, including healthcare, economics, climate science, and epidemiology.However, this task becomes complex in the existence of time-varying latentconfounders, which affect both treatment and outcome variables over time andcan introduce bias in causal effect estimation. Traditional instrumentalvariable (IV) methods are limited in addressing such complexities due to theneed for predefined IVs or strong assumptions that do not hold in dynamicsettings. To tackle these issues, we develop a novel Time-varying ConditionalInstrumental Variables (CIV) for Debiasing causal effect estimation, referredto as TDCIV. TDCIV leverages Long Short-Term Memory (LSTM) and VariationalAutoencoder (VAE) models to disentangle and learn the representations oftime-varying CIV and its conditioning set from proxy variables without priorknowledge. Under the assumptions of the Markov property and availability ofproxy variables, we theoretically establish the validity of these learnedrepresentations for addressing the biases from time-varying latent confounders,thus enabling accurate causal effect estimation. Our proposed TDCIV is thefirst to effectively learn time-varying CIV and its associated conditioning setwithout relying on domain-specific knowledge.</description>
      <author>example@mail.com (Debo Cheng, Ziqi Xu, Jiuyong Li, Lin Liu, Thuc duy Le, Xudong Guo, Shichao Zhang)</author>
      <guid isPermaLink="false">2411.17774v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Kinesthetic Haptic Feedback Device Driven by Soft Electrohydraulic Actuators</title>
      <link>http://arxiv.org/abs/2411.18387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种新型的软电液致动器被开发出来，并用于制作一个能够输出可控反馈力和具有快速响应特性的拟感设备。通过调整驱动高压波形，该装置可以在不增加额外振动器的情况下实现可变频率的触觉震动。&lt;h4&gt;背景&lt;/h4&gt;现有的拟感设备在制造具有先进触觉渲染能力的手动控制设备时遇到了驱动机制方面的限制。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新型软电液致动器，并利用它作为动力单元来开发一个手动控制器，以展示该装置稳定输出可控反馈力的能力以及它的快速响应特性。&lt;h4&gt;方法&lt;/h4&gt;建立了数学模型并进行了测试实验，展示了所开发设备的功能。此外还构建了一个远程操作机器人系统，证明了其在机器人触觉反馈系统中的应用潜力。&lt;h4&gt;主要发现&lt;/h4&gt;软电液致动器的易于控制性使得该装置能够实现高分辨率可控反馈力输出，并通过调整驱动高压波形获得了渲染可变频率触觉震动的能力。&lt;h4&gt;结论&lt;/h4&gt;所开发的手动控制器具有良好的稳定性和快速响应能力，可以作为机器人领域的触觉力反馈系统使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing kinesthetic haptic devices with advanced haptic renderingcapabilities is challenging due to the limitations on driving mechanisms. Inthis study, we introduce a novel soft electrohydraulic actuator and develop akinesthetic haptic device utilizing it as the driving unit. We established amathematical model and conducted testing experiments to demonstrate thedevice's ability to stably output controllable feedback force. Our experimentsalso demonstrates that this device exhibits fast response characteristics. Byutilizing the easily controllable nature of the soft electrohydraulic actuator,we were able to achieve high-resolution controllable feedback force output.Furthermore, by modulating the waveform of the driving high voltage, the deviceacquired the capability to render variable frequency haptic vibration withoutadding any extra vibration actuator. Using this kinesthetic haptic device, webuilt a teleoperated robotic system, showcasing the device's potentialapplication as a haptic force feedback system in the field of robotics.</description>
      <author>example@mail.com (Dannuo Li, Quan Xiong, Xuanyi Zhou, Raye Chen-Hua Yeow)</author>
      <guid isPermaLink="false">2411.18387v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Time-Series Forecasting in Smart Manufacturing Systems: An Experimental Evaluation of the State-of-the-art Algorithms</title>
      <link>http://arxiv.org/abs/2411.17499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了最新时间序列预测（TSF）算法在制造业数据集中的表现，以填补当前研究空白。&lt;h4&gt;背景&lt;/h4&gt;尽管近年来开发了许多TSF算法，但缺乏对这些算法的有效验证和评估方法。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过评估最先进的TSF算法在13个制造数据集上的表现来填补这一空白，特别关注其在制造业中的适用性。&lt;h4&gt;方法&lt;/h4&gt;选择的每种算法基于其所属的时间序列预测类别以确保代表性。评估包括不同场景，并使用两个问题类型和两种预测时间范围进行模型评估。性能评估通过计算加权平均百分比误差（WAPE）来进行，并进行了事后分析以评估观察到差异的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '基于变压器和多层感知器（MLP）的架构表现最佳，尤其是MLP在大多数情况下胜出。', '2': '对于单变量TSF问题，PatchTST在长时预测中表现最为稳定。', '3': '对于多元时间序列问题，诸如N-HITS和TiDE的MLP架构表现出色。', '4': '简单的算法如XGBoost在某些任务上可以胜过复杂的算法', '5': '研究表明了计算资源考虑的重要性，不同算法间运行时间和内存使用存在差异'}&lt;h4&gt;结论&lt;/h4&gt;研究结果挑战了一个假设：更复杂模型总是产生更好预测性能的观点，并揭示出简化技术在智能制造系统中的应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文重点在于评估时间序列预测（TSF）领域中最先进的算法，特别是在制造业背景下的表现。通过对一系列制造数据集的深入测试和分析，研究者们提供了关于这些算法适用性的宝贵洞见，并强调了简单模型在特定任务上的优越性以及计算资源对算法性能的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; TSF is growing in various domains including manufacturing. Although numerousTSF algorithms have been developed recently, the validation and evaluation ofalgorithms hold substantial value for researchers and practitioners and aremissing. This study aims to fill this gap by evaluating the SoTA TSF algorithmson thirteen manufacturing datasets, focusing on their applicability inmanufacturing. Each algorithm was selected based on its TSF category to ensurea representative set of algorithms. The evaluation includes different scenariosto evaluate the models using two problem categories and two forecastinghorizons. To evaluate the performance, the WAPE was calculated, and additionalpost hoc analyses were conducted to assess the significance of observeddifferences. Only algorithms with codes from open-source libraries wereutilized, and no hyperparameter tuning was done. This allowed us to evaluatethe algorithms as "out-of-the-box" solutions that can be easily implemented,ensuring their usability within the manufacturing by practitioners with limitedtechnical knowledge. This aligns to facilitate the adoption of these techniquesin smart manufacturing systems. Based on the results, transformer and MLP-basedarchitectures demonstrated the best performance with MLP-based architecturewinning the most scenarios. For univariate TSF, PatchTST emerged as the mostrobust, particularly for long-term horizons, while for multivariate problems,MLP-based architectures like N-HITS and TiDE showed superior results. The studyrevealed that simpler algorithms like XGBoost could outperform complexalgorithms in certain tasks. These findings challenge the assumption that moresophisticated models produce better results. Additionally, the researchhighlighted the importance of computational resource considerations, showingvariations in runtime and memory usage across different algorithms.</description>
      <author>example@mail.com (Mojtaba A. Farahani, Fadi El Kalach, Austin Harper, M. R. McCormick, Ramy Harik, Thorsten Wuest)</author>
      <guid isPermaLink="false">2411.17499v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Robust Dynamic Gesture Recognition at Ultra-Long Distances</title>
      <link>http://arxiv.org/abs/2411.18413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的动态手势识别模型SlowFast-Transformer (SFT)，可以在长达28米的远距离内准确地识别手势，从而实现在室内和室外环境中机器人与人的自然交互。&lt;h4&gt;背景&lt;/h4&gt;在人机交互(HRI)中，动态手部手势对于传达非语言信息至关重要。当前的手势识别模型受限于有效识别范围，仅适用于近距离场景。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在远距离内准确识别手势的方法，以便更好地实现机器人和人类之间的自然、直接沟通。&lt;h4&gt;方法&lt;/h4&gt;利用SlowFast架构与Transformer层的结合，设计了一种新的模型(SlowFast-Transformer, SFT)，能够处理在超长距离下捕获的手势序列，并通过引入距离加权损失函数来改善学习效果，提高模型鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的SFT模型在具有挑战性的远距离手势识别任务中表现出了显著的性能提升，达到了95.1%的识别准确率。这使得机器人能够更有效地响应来自远处的人类命令。&lt;h4&gt;结论&lt;/h4&gt;该方法为HRI领域提供了一种有效的解决方案，特别是在需要无缝和自然交互的情境下。&lt;h4&gt;翻译&lt;/h4&gt;动态手势在人机交互中传达非言语信息起着关键作用，现有的模型限制了远程应用。本研究提出了一种远距离的手势识别技术——SlowFast-Transformer (SFT)，克服低分辨率和环境噪声带来的挑战，在28米内实现高效的手势序列处理与分类，并引入距离加权损失函数提升学习效果及模型鲁棒性。实验结果表明，相较于现有框架，该方法在复杂数据集上达到了95.1%的准确率，使机器人能够在远距离接收到指令并做出响应。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic hand gestures play a crucial role in conveying nonverbal informationfor Human-Robot Interaction (HRI), eliminating the need for complex interfaces.Current models for dynamic gesture recognition suffer from limitations ineffective recognition range, restricting their application to close proximityscenarios. In this letter, we present a novel approach to recognizing dynamicgestures in an ultra-range distance of up to 28 meters, enabling natural,directive communication for guiding robots in both indoor and outdoorenvironments. Our proposed SlowFast-Transformer (SFT) model effectivelyintegrates the SlowFast architecture with Transformer layers to efficientlyprocess and classify gesture sequences captured at ultra-range distances,overcoming challenges of low resolution and environmental noise. We furtherintroduce a distance-weighted loss function shown to enhance learning andimprove model robustness at varying distances. Our model demonstratessignificant performance improvement over state-of-the-art gesture recognitionframeworks, achieving a recognition accuracy of 95.1% on a diverse dataset withchallenging ultra-range gestures. This enables robots to react appropriately tohuman commands from a far distance, providing an essential enhancement in HRI,especially in scenarios requiring seamless and natural interaction.</description>
      <author>example@mail.com (Eran Bamani Beeri, Eden Nissinman, Avishai Sintov)</author>
      <guid isPermaLink="false">2411.18413v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Evolving Markov Chains: Unsupervised Mode Discovery and Recognition from Data Streams</title>
      <link>http://arxiv.org/abs/2411.17528v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种构建可变马尔科夫链（EMCs）的在线且高效的方法，用于追踪现实世界中行为变化。该方法能够适应性地跟踪转换概率、自动发现模式并检测模式切换。&lt;h4&gt;背景&lt;/h4&gt;传统的Markov链模型假设数据是平稳的，并且具有固定的转移概率。然而，在实际情况如活动追踪和生物时间序列分析中，过程会随着时间的变化而改变。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够在线构建Evolving Markov chains (EMCs)的方法，使其能适应性地跟踪转换概率、自动发现模式并检测模式切换。&lt;h4&gt;方法&lt;/h4&gt;提出了一个不需要依赖于跟踪窗口的更新方案，并且只需要更新概率张量的相关区域。该模型展示了预期估计值的几何收敛。&lt;h4&gt;主要发现&lt;/h4&gt;Evolving Markov chains (EMCs) 方法在合成数据和真实世界应用（例如人类活动识别、电动机状态监测以及从EEG测量中获取眼动状态）中的表现证明了其适应性和高效性。&lt;h4&gt;结论&lt;/h4&gt;这种方法能够有效地追踪并理解现实生活中的过程，并具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;马尔科夫链是简单而强大的数学结构，用于建模时间依赖过程。然而，现实世界中的动态进程如活动跟踪、生物时间序列和工业监控常常会随着时间的推移而改变行为。这些行为转换可以被建模为更高层次模式之间的转换（例如跑步、走路等）。但是，并非所有模式都是已知的，它们通常具有不同的转移概率，并且切换是不可预测的。因此，为了追踪现实生活过程中行为的变化，本研究提出了一种在线和高效的构建Evolving Markov chains (EMCs) 的方法。该方法能够适应性地跟踪转换概率、自动发现模式并检测模式切换。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Markov chains are simple yet powerful mathematical structures to modeltemporally dependent processes. They generally assume stationary data, i.e.,fixed transition probabilities between observations/states. However, live,real-world processes, like in the context of activity tracking, biological timeseries, or industrial monitoring, often switch behavior over time. Suchbehavior switches can be modeled as transitions between higher-level\emph{modes} (e.g., running, walking, etc.). Yet all modes are usually notpreviously known, often exhibit vastly differing transition probabilities, andcan switch unpredictably. Thus, to track behavior changes of live, real-worldprocesses, this study proposes an online and efficient method to constructEvolving Markov chains (EMCs). EMCs adaptively track transition probabilities,automatically discover modes, and detect mode switches in an online manner. Incontrast to previous work, EMCs are of arbitrary order, the proposed updatescheme does not rely on tracking windows, only updates the relevant region ofthe probability tensor, and enjoys geometric convergence of the expectedestimates. Our evaluation of synthetic data and real-world applications onhuman activity recognition, electric motor condition monitoring, and eye-staterecognition from electroencephalography (EEG) measurements illustrates theversatility of the approach and points to the potential of EMCs to efficientlytrack, model, and understand live, real-world processes.</description>
      <author>example@mail.com (Kutalmış Coşkun, Borahan Tümer, Bjarne C. Hiller, Martin Becker)</author>
      <guid isPermaLink="false">2411.17528v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Coping with the Dunkelflaute: Power system implications of variable renewable energy droughts in Europe</title>
      <link>http://arxiv.org/abs/2411.17683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了长时间电力存储和地理平衡在处理可再生能源干旱（即“Dunkelflaute”）中的作用，强调政策制定者和系统规划者需要为快速扩展长时储能容量做准备。&lt;h4&gt;背景&lt;/h4&gt;实现以可再生能源为基础的欧洲低碳能源体系面临的一个关键挑战是如何应对长期风能和太阳能供应不足的情况。&lt;h4&gt;目的&lt;/h4&gt;研究长时间电力存储以及地理平衡在处理这种可变性较高的可再生能源干旱中的作用，并分析了极端情况下所需的储能容量大小。&lt;h4&gt;方法&lt;/h4&gt;结合了可再生资源可用性的时间序列分析与电力部门建模，使用了36个历史天气年份的数据进行研究。&lt;h4&gt;主要发现&lt;/h4&gt;最极端的可再生能源干旱事件发生在1996/97年的冬季。在假设政策相关互联的情况下，需要351 TWh或相当于年用电量需求的7%的长时间存储来应对这种情况；即使在极高的地理平衡情形下仍然需要159 TWh或3%的年用电量需求。&lt;h4&gt;结论&lt;/h4&gt;研究表明，在可再生能源干旱期间，长时储能与其他灵活性选择之间存在复杂的交互作用。此外，虽然确定性的无排放发电技术可以适度减少对长时间存储的需求，但长期来看仍需大幅增加长时储能能力以确保欧洲向可再生能源转型的安全性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了如何应对由于风能和太阳能供应的不稳定而引发的可再生能源干旱（Dunkelflaute），强调需要大规模扩展电力储存技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Coping with prolonged periods of low availability of wind and solar power,also referred to as "Dunkelflaute", emerges as a key challenge for realizing adecarbonized European energy system fully based on renewable energy sources.Here, we investigate the role of long-duration electricity storage andgeographical balancing in dealing with such variable renewable energy droughts.To this end, we combine renewable availability time series analysis and powersector modeling, using 36 historic weather years. We find that extreme droughtevents define long-duration storage operation and investment. The most extremeevent in Europe occurred in the winter of 1996/97. Assuming policy-relevantinterconnection, long-duration storage of 351 TWh or 7% of yearly electricitydemand would be required to deal with this event. As it affects many countriessimultaneously, a storage capacity of 159 TWh or 3% of yearly electricitydemand remains required even in the extreme case of unconstrained geographicalbalancing. Before and during Dunkelflaute events, we find complex interactionsof long-duration storage with other flexibility options. Sensitivity analysesillustrate that firm zero-emission generation technologies would onlymoderately reduce long-duration storage needs. Thus, policymakers and systemplanners should prepare for a rapid expansion of long-duration storage capacityto safeguard the renewable energy transition in Europe. We further argue thatincluding multiple weather years is required for weather-resilient energysystem modeling, particularly those with pronounced renewable energy droughts.</description>
      <author>example@mail.com (Martin Kittel, Alexander Roth, Wolf-Peter Schill)</author>
      <guid isPermaLink="false">2411.17683v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Traffic Wave Properties for Automated Vehicles During Traffic Oscillations via Analytical Approximations</title>
      <link>http://arxiv.org/abs/2411.16937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种分析近似框架，用于理解自动化车辆（AV）在交通波动期间的车流波传播动态。&lt;h4&gt;背景&lt;/h4&gt;当前对于自动化车辆如何影响现有的交通波传播机制了解不足。&lt;h4&gt;目的&lt;/h4&gt;系统地解析自动化车辆纵向控制模型与交通波特性之间的复杂关系，并通过数学方法推导交通波属性，同时探讨异质性条件下（包括同质性和不同类型的AV和非AV混合交通）的交通波动特性。&lt;h4&gt;方法&lt;/h4&gt;运用拉普拉斯变换和描述函数分析法来研究车流波特性。基于Newell的跟随模型确定了自动化车辆中的车速属性，并通过数值模拟验证这种方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;该框架可以量化自动化车辆在不同条件下的交通波动特性，特别是对于同质与异质混合交通情况下的影响。&lt;h4&gt;结论&lt;/h4&gt;研究强调了在自动车辆存在的情况下重新思考车流波性质的重要性。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an analytical approximation framework to understand thedynamics of traffic wave propagation for Automated Vehicles (AVs) duringtraffic oscillations. The framework systematically unravels the intricaterelationships between the longitudinal control model of the AVs and theproperties of traffic waves. We apply Laplacian Transformation and DescribingFunction Analysis to mathematically derive the traffic wave properties of an AVin car-following scenarios. Further, we incorporate Newell's car-followingmodel to determine the speed of the traffic waves. Our analysis extends to bothhomogenous and heterogenous traffic, systematically handlingintra-heterogeneities and inter-heterogeneities in traffic wave propagationusing the established analytical framework. We validate our approach vianumerical simulations and show the connections between the AV control systemand traffic wave properties. This research emphasizes the importance ofrethinking our understanding of traffic wave properties when AVs are present inthe traffic system.</description>
      <author>example@mail.com (Yang Zhou, Sixu Li, Wissam Kontar, Fan Pu, Anupam Srivastava, Soyoung Ahn)</author>
      <guid isPermaLink="false">2411.16937v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Efficient and Diverse Generative Robot Designs using Evolution and Intrinsic Motivation</title>
      <link>http://arxiv.org/abs/2411.18423v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 9 figures, submitted to IEEE ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了结合内在动机的形态进化方法，以解决机器人设计生成中计算成本高和过早收敛的问题。&lt;h4&gt;背景&lt;/h4&gt;用于生成式设计机器人体型的方法可以自动找到复杂环境中挑战性任务的最佳解决方案。然而，巨大的搜索空间使得这个问题在机器学习和优化领域具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;通过结合内在动机来改进形态进化与学习（MEL）方法，以解决计算成本高和早期收敛到次优解的问题。&lt;h4&gt;方法&lt;/h4&gt;使用内生动力驱动的行为来自机器人身体的固有属性以及简单的学习规则。采用了减少机器人设计知识需求的家动能控制器，以此在几秒钟内产生探索行为，替代了耗时的学习阶段。&lt;h4&gt;主要发现&lt;/h4&gt;结合内在动机的方法与当前形态进化静态参数的方法相比，在多种下游任务中产生的设计方案得分更高、更具多样性，并且生成速度更快。&lt;h4&gt;结论&lt;/h4&gt;通过引入家动能和减少对机器人设计的先验知识需求，可以有效地解决MEL方法中的两个核心问题：高计算成本和过早收敛。这将提高复杂度更高的任务中形态进化的效率。&lt;h4&gt;翻译&lt;/h4&gt;用于机器人体型生成式设计的方法可以通过自动寻找在复杂环境中挑战性任务的最佳解决方案来实现创新性的优化成果。这种基于进化算法（EAs）的搜索空间广泛涵盖了物理设计方案及控制器参数，使得该问题成为了一个在机器学习和优化领域的难题。为了克服形态进化与学习（MEL）方法中存在的计算成本高昂以及过早收敛到次优解的问题，我们提出将内在动机纳入其中。通过使用基于身体特性的家动能控制器来产生探索行为，在短时间内减少了对机器人设计的先验知识需求，从而提高了多样性并防止了过早收敛。我们的方法在多个下游任务中与现有的MEL方法进行了比较，并且表现出更好的结果：设计方案得分更高、更多样化并且生成速度更快。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Methods for generative design of robot physical configurations canautomatically find optimal and innovative solutions for challenging tasks incomplex environments. The vast search-space includes the physical design-spaceand the controller parameter-space, making it a challenging problem in machinelearning and optimisation in general. Evolutionary algorithms (EAs) have shownpromising results in generating robot designs via gradient-free optimisation.Morpho-evolution with learning (MEL) uses EAs to concurrently generate robotdesigns and learn the optimal parameters of the controllers. Two main issuesprevent MEL from scaling to higher complexity tasks: computational cost andpremature convergence to sub-optimal designs. To address these issues, wepropose combining morpho-evolution with intrinsic motivations. Intrinsicallymotivated behaviour arises from embodiment and simple learning rules withoutexternal guidance. We use a homeokinetic controller that generates exploratorybehaviour in a few seconds with reduced knowledge of the robot's design.Homeokinesis replaces costly learning phases, reducing computational time andfavouring diversity, preventing premature convergence. We compare our approachwith current MEL methods in several downstream tasks. The generated designsscore higher in all the tasks, are more diverse, and are quickly generatedcompared to morpho-evolution with static parameters.</description>
      <author>example@mail.com (Leni K. Le Goff, Simon C. Smith)</author>
      <guid isPermaLink="false">2411.18423v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Rock the KASBA: Blazingly Fast and Accurate Time Series Clustering</title>
      <link>http://arxiv.org/abs/2411.17838v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的时间序列聚类（TSCL）算法KASBA，该算法结合了k-均值方法和随机化子梯度下降技术，特别适用于大规模的时间序列数据。&lt;h4&gt;背景&lt;/h4&gt;时间序列数据分析在多个领域变得越来越重要，推动了对时间序列机器学习技术的需求。其中，时间序列聚类（TSCL）因其强大的探索性分析能力和广泛的预处理应用而备受关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的高效且性能优良的时间序列聚类算法KASBA，以解决当前算法要么速度快但效果差，要么效果好但可扩展性弱的问题。&lt;h4&gt;方法&lt;/h4&gt;KASBA算法结合了k-均值方法、Move-Split-Merge（MSM）弹性距离和随机化子梯度下降技术。该算法通过避免大量的距离计算来加速收敛，并且能够有效地处理大规模的时间序列数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，相较于其他最先进的聚类算法，KASBA在时间复杂性和聚类性能之间提供了更好的平衡，同时显著提高了运行速度和聚类质量。&lt;h4&gt;结论&lt;/h4&gt;KASBA是一个高效、可扩展的聚类工具，适用于各种实际的时间序列数据应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series data has become increasingly prevalent across numerous domains,driving a growing demand for time series machine learning techniques. Amongthese, time series clustering (TSCL) stands out as one of the most popularmachine learning tasks. TSCL serves as a powerful exploratory analysis tool andis also employed as a preprocessing step or subroutine for various tasks,including anomaly detection, segmentation, and classification.  The most popular TSCL algorithms are either fast (in terms of run time) butperform poorly on benchmark problems, or perform well on benchmarks but scalepoorly. We present a new TSCL algorithm, the $k$-means (K) accelerated (A)Stochastic subgradient (S) Barycentre (B) Average (A) (KASBA) clusteringalgorithm. KASBA is a $k$-means clustering algorithm that uses theMove-Split-Merge (MSM) elastic distance at all stages of clustering, applies arandomised stochastic subgradient gradient descent to find barycentrecentroids, links each stage of clustering to accelerate convergence andexploits the metric property of MSM distance to avoid a large proportion ofdistance calculations. It is a versatile and scalable clusterer designed forreal-world TSCL applications. It allows practitioners to balance run time andclustering performance. We demonstrate through extensive experimentation thatKASBA produces significantly better clustering than the faster state of the artclusterers and is offers orders of magnitude improvement in run time over themost performant $k$-means alternatives.</description>
      <author>example@mail.com (Christopher Holder, Anthony Bagnall)</author>
      <guid isPermaLink="false">2411.17838v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Robustness of WDM technique for the co-propagation of quantum with classical signals in an optical fiber</title>
      <link>http://arxiv.org/abs/2411.16942v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个新的理论方法，研究基于WDM技术的量子信号和经典信号共传播时的情况。&lt;h4&gt;背景&lt;/h4&gt;随着弱光脉冲量子通信系统的普及与商业化，需要在物理层面上实现这些系统与其他数据流量之间的无缝集成。对于采用波分复用（WDM）技术的光纤链路来说，在强大的数据信号背景下传输非常微弱的量子信号成为挑战。&lt;h4&gt;目的&lt;/h4&gt;研究共传播的量子和经典信号在使用WDM技术时的行为，分析导致串扰的关键因素，并探讨其对量子通信集成的影响。&lt;h4&gt;方法&lt;/h4&gt;通过理论模型分析发射功率、波长间隔等因素如何影响串扰，重点考察了量子信号与最近邻的经典通道之间的相互作用。&lt;h4&gt;主要发现&lt;/h4&gt;计算表明只有最接近的两个经典信道会对量子信号产生显著的串扰效应，而更远距离的其他信道则几乎没有串扰效果。这反映出WDM技术在理论上能够支持将弱量子链接整合到传统数据流量中的需求。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明波分复用技术对量子通信与经典数据流共存具有一定的鲁棒性，为未来量子通信系统的实际应用提供了理论依据。&lt;h4&gt;翻译&lt;/h4&gt;摘要中提到许多量子通讯系统依赖于弱光脉冲，在设计上假设它们可以独立运行而不受常规数据流量的影响。然而，随着这些系统的广泛可用性和商业化，现在需要在物理层面上实现无缝集成。对于采用波分复用（WDM）技术的光纤链路来说，在强大的数据信号背景下传输非常微弱的量子信号成为挑战。本文提出了一种新的理论方法来研究共传播的量子和经典信号使用WDM时的情况，并分析了影响串扰的因素，如经典信号发射功率以及两个信号之间的波长间隔等。计算结果显示只有最接近的两个经典信道会对量子信号产生显著的串扰效应，而更远距离的其他信道则几乎没有串扰效果。这表明在原则上波分复用技术能够支持将弱量子链接整合到传统数据流量中，并为未来量子通信系统的实际应用提供了理论依据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many quantum communication systems operate based on weak light pulses whichby design are assumed to operate in isolation from regular data traffic. Withthe widespread availability and commercialization of these systems comes a needfor seamless integration already at the physical layer. In particular foroptical fiber links where wavelength division multiplexing (WDM) is thedominant data transmission technique this results in the propagation of veryweak quantum signals against a strong data signal background. With this work,we present a novel theoretical approach that studies the evolution ofco-propagating quantum and classical signals that are launched using WDM. Theimportant factors that contribute to crosstalk, such as the launch power of theclassical signal and the separation between the two signals in terms ofwavelength, are comprehensively analyzed. Interestingly, calculations show thatonly the first two nearest channels from the classical channel experiencenoticeable crosstalk whereas other distant channels have negligible crosstalkeffect. This reflects the WDM technique is in principle robust in theintegration of weak quantum links into classical data traffic.</description>
      <author>example@mail.com (Sumit Chaudhary, Shahram Dehdashti, Igor Litvin, Janis Nötzel)</author>
      <guid isPermaLink="false">2411.16942v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CRASH: Challenging Reinforcement-Learning Based Adversarial Scenarios For Safety Hardening</title>
      <link>http://arxiv.org/abs/2411.16996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 9 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CRASH是一种基于深度强化学习的对抗性框架，用于生成逼真且多样的交通场景以测试自动驾驶车辆（AV）的安全性和性能。&lt;h4&gt;背景&lt;/h4&gt;确保自动驾驶汽车安全需要识别罕见但关键的故障案例，在路上进行单一测试无法发现这些情况。高保真的模拟提供了一种可扩展的替代方案，但自动生成逼真的和多样化的交通情景以有效压力测试AV运动规划器仍然是一个主要挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍CRASH框架，旨在通过对抗性深度强化学习生成多样化且逼真的交通场景来验证自动驾驶车辆的安全性和性能，并提出一种称为安全硬化的迭代方法，通过模拟改进的场景对对手代理进行训练，利用失败案例加强AV系统。&lt;h4&gt;方法&lt;/h4&gt;CRASH控制模拟器中的非玩家角色（NPC）以诱导与目标车辆发生碰撞，从而测试和优化运动规划。同时，通过反复修改和完善运动规划来降低车辆在实际驾驶情况下的碰撞率。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在简化的双车道公路上进行了评估，能够使基于规则的和学习型的规划器的碰撞率超过90%。此外，安全硬化措施能将目标车辆的碰撞率降低26%。&lt;h4&gt;结论&lt;/h4&gt;初步结果显示基于RL的安全硬化工具有望成为自动驾驶场景驱动模拟测试的一种有前途的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容描述了一种名为CRASH的新方法，该方法利用对抗性深度强化学习生成逼真的交通环境来验证和优化自动驾驶汽车的安全性能。通过这种方法，研究团队能够发现并解决现有AV系统中的问题，并展示了其在减少碰撞率方面的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the safety of autonomous vehicles (AVs) requires identifying rarebut critical failure cases that on-road testing alone cannot discover.High-fidelity simulations provide a scalable alternative, but automaticallygenerating realistic and diverse traffic scenarios that can effectively stresstest AV motion planners remains a key challenge. This paper introduces CRASH -Challenging Reinforcement-learning based Adversarial scenarios for SafetyHardening - an adversarial deep reinforcement learning framework to addressthis issue. First CRASH can control adversarial Non Player Character (NPC)agents in an AV simulator to automatically induce collisions with the Egovehicle, falsifying its motion planner. We also propose a novel approach, thatwe term safety hardening, which iteratively refines the motion planner bysimulating improvement scenarios against adversarial agents, leveraging thefailure cases to strengthen the AV stack. CRASH is evaluated on a simplifiedtwo-lane highway scenario, demonstrating its ability to falsify both rule-basedand learning-based planners with collision rates exceeding 90%. Additionally,safety hardening reduces the Ego vehicle's collision rate by 26%. Whilepreliminary, these results highlight RL-based safety hardening as a promisingapproach for scenario-driven simulation testing for autonomous vehicles.</description>
      <author>example@mail.com (Amar Kulkarni, Shangtong Zhang, Madhur Behl)</author>
      <guid isPermaLink="false">2411.16996v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>The VELOCE modulation zoo II. Humps and splitting patterns in spectral lines of classical Cepheids</title>
      <link>http://arxiv.org/abs/2411.17851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 20 figures, 5 tables, accepted for publication in A&amp;A&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了经典造父变星中谱线分裂的现象，并通过高信噪比的交叉相关函数（CCF）时间序列分析，确认了X Sgr和BG Cru中的谱线分裂现象。此外，该研究还发现其他六颗类似恒星也存在未解决或边缘可辨识的谱线分裂。&lt;h4&gt;背景&lt;/h4&gt;在不同类型的恒星中观察到了由于冲击、光谱双星、磁场、斑点以及非径向模式等导致的谱线分裂现象。然而，在经典造父变星中，这种现象非常罕见，只有少数报告将其与大气层中的冲击关联起来。&lt;h4&gt;目的&lt;/h4&gt;调查X Sgr和BG Cru中的谱线分裂，并寻找其他经典造父变星中类似的特征。&lt;h4&gt;方法&lt;/h4&gt;利用VELOCE项目提供的高信噪比交叉相关函数（CCF）时间序列进行分析，该数据集跨越多年，可以研究CCF特征的周期性和演化。对X Sgr和BG Cru进行了详细的谱线分裂CCF组成部分分析，并搜索其他经典造父变星中类似的周期性变化。&lt;h4&gt;主要发现&lt;/h4&gt;确认了X Sgr和BG Cru中的谱线分裂现象并追踪其随时间的变化，揭示背后的周期性特征；此外还发现了其他几颗恒星中存在CCF凸起，表明未解决或边缘可辨识的谱线分裂。这些现象的频率远低于造父变星光度变化的主要周期，排除了由脉动引起的冲击作为解释的可能性。&lt;h4&gt;结论&lt;/h4&gt;经典造父变星中的谱线分裂可能与非径向模式相关联，但其具体性质仍不清楚。该研究还表明，在VELOCE样本中，有3%的恒星显示出凸起现象。&lt;h4&gt;翻译&lt;/h4&gt;在各种类型的恒星中观察到了由于冲击、光谱双星、磁场、斑点以及非径向模式导致的谱线分裂现象。对于脉动变星来说，这种分裂通常被归因于由脉冲引发的冲击。然而，在经典造父变星中很少看到这种现象，只有少数报告将其与大气层中的冲击相关联。我们使用光谱时间序列研究了X Sgr和BG Cru中的谱线分裂，并寻找其他经典造父变星中类似的特征。通过分析来自VELOCE项目的高信噪比交叉相关函数（CCF）时间序列，我们能够跨越几年的时间跨度来研究周期性和演化。对于X Sgr和BG Cru，进行了详细的单个分裂CCFs组成部分的分析，以及在CCF变化中的周期性搜索，并且观察其他经典造父变星中是否具有类似于未解决或边缘可辨识的谱线分裂的现象。我们确认了X Sgr和BG Cru中的谱线分裂现象并追踪其随时间的变化揭示背后的周期性特征；此外还发现了其他几颗恒星中存在CCF凸起，表明未解决或边缘可辨识的谱线分裂。这些现象的频率远低于造父变星光度变化的主要周期，排除了由脉动引起的冲击作为解释的可能性。在X Sgr和BG Cru中的谱线分裂的周期性与非径向模式相关联的可能性较大，但其具体性质仍不清楚。此外，在其他恒星中发现了六个凸起现象的存在，表明VELOCE样本中有3%的恒星显示出这种特征。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Line splitting in spectral lines is observed in various types of stars due tophenomena such as shocks, spectroscopic binaries, magnetic fields, spots, andnon-radial modes. In pulsating stars, line splitting is often attributed topulsation-induced shocks. However, this is rarely observed in classicalCepheids, with only a few reports, including X Sagittarii and BG Crucis, whereit has been linked to atmospheric shocks. We investigate line splitting in XSgr and BG Cru using spectroscopic time series, and search for similarphenomena in other classical Cepheids. High signal-to-noise cross-correlationfunction (CCF) time series from the VELOcities of CEpheids (VELOCE) project areanalyzed. This dataset spans several years, allowing us to study theperiodicities and evolution of CCF features. For X Sgr and BG Cru, we perform adetailed analysis of the individual components of the split CCFs. Additionally,we search for periodicities in CCF variations and examine other classicalCepheids for distortions resembling unresolved line splitting. We confirm linesplitting in X Sgr and BG Cru, trace the features over time, and uncover theperiodicity behind them. Several other Cepheids also exhibit CCF humps,suggesting unresolved or marginally resolved line splitting. We discuss theincidence and characteristics of these stars. The periodicity of line splittingin X Sgr and BG Cru differs significantly from the dominant pulsation period,ruling out pulsation-induced shocks. The periodicities are too short forrotation-related phenomena, suggesting non-radial modes as the most likelyexplanation, though their exact nature remains unknown. We also identify humpsin six additional stars, indicating an incidence rate of 3% in the VELOCEsample.</description>
      <author>example@mail.com (H. Netzel, R. I. Anderson, G. Viviani)</author>
      <guid isPermaLink="false">2411.17851v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>On-Road Object Importance Estimation: A New Dataset and A Model with Multi-Fold Top-Down Guidance</title>
      <link>http://arxiv.org/abs/2411.17152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文解决了道路对象重要性估计的问题，该问题使用从驾驶员视角捕获的视频序列作为输入。&lt;h4&gt;背景&lt;/h4&gt;虽然这个问题对于更安全和智能的驾驶系统非常重要，但是社区对此问题的研究还比较有限。一方面，现有的大规模公开数据集稀缺。&lt;h4&gt;目的&lt;/h4&gt;为了应对这一困境，本文贡献了一个新的大规模数据集，名为Traffic Object Importance (TOI)。&lt;h4&gt;方法&lt;/h4&gt;另一方面，现有方法通常只考虑自下而上的特征或单一的引导方式，难以处理高度动态和多样的交通场景。不同于现有的方法，本文提出了一种模型，该模型整合了多种自上而下的引导与自下而上的特性。具体来说，三种类型的自上而下的指导因素（例如驾驶员意图、语义上下文及交通规则）被整合进我们的模型。&lt;h4&gt;主要发现&lt;/h4&gt;这些因素对于对象重要性估计非常重要，但是没有现有的方法同时考虑它们。据我们所知，本文提出了首个融合多种自上而下引导因素与自下而上的特征的道路上的对象重要性估计模型。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验表明，我们的模型相较于最先进的方法有显著的优势，在平均精度(AP)方面比最近提出的方法提高了23.1%。&lt;h4&gt;翻译&lt;/h4&gt;此摘要描述了一篇论文的研究内容。研究重点在于从驾驶员视角采集的道路视频序列中的对象重要性估计问题。该团队开发了一个大型数据集TOI，并提出了一个集成多层自上而下引导和自下而上特征的模型，以改进现有方法在处理动态复杂交通场景时的表现不足。实验结果表明新模型大幅超越了其他先进方法，在关键性能指标上有显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the problem of on-road object importance estimation,which utilizes video sequences captured from the driver's perspective as theinput. Although this problem is significant for safer and smarter drivingsystems, the exploration of this problem remains limited. On one hand,publicly-available large-scale datasets are scarce in the community. To addressthis dilemma, this paper contributes a new large-scale dataset named TrafficObject Importance (TOI). On the other hand, existing methods often onlyconsider either bottom-up feature or single-fold guidance, leading tolimitations in handling highly dynamic and diverse traffic scenarios. Differentfrom existing methods, this paper proposes a model that integrates multi-foldtop-down guidance with the bottom-up feature. Specifically, three kinds oftop-down guidance factors (ie, driver intention, semantic context, and trafficrule) are integrated into our model. These factors are important for objectimportance estimation, but none of the existing methods simultaneously considerthem. To our knowledge, this paper proposes the first on-road object importanceestimation model that fuses multi-fold top-down guidance factors with bottom-upfeature. Extensive experiments demonstrate that our model outperformsstate-of-the-art methods by large margins, achieving 23.1% Average Precision(AP) improvement compared with the recently proposed model (ie, Goal).</description>
      <author>example@mail.com (Zhixiong Nan, Yilong Chen, Tianfei Zhou, Tao Xiang)</author>
      <guid isPermaLink="false">2411.17152v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Pretrained LLM Adapted with LoRA as a Decision Transformer for Offline RL in Quantitative Trading</title>
      <link>http://arxiv.org/abs/2411.17900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the ICAIF 2024 Workshop on LLMs and
  Generative AI for Finance (poster session)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于预训练的GPT-2和低秩适应（LoRA）技术优化的决策Transformer模型，用于从历史金融数据中学习有效的量化交易策略。&lt;h4&gt;背景&lt;/h4&gt;由于与实时金融市场进行在线互动时存在高风险，使用强化学习开发有效量化的交易策略具有挑战性。因此，不需额外探索就能利用历史市场数据的离线RL变得至关重要。然而，现有的离线RL方法常常难以捕捉金融时间序列中的复杂时空依赖关系，并可能过度拟合到历史模式。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的决策Transformer模型（DT），该模型使用预训练GPT-2权重并进行LoRA微调以解决上述挑战。&lt;h4&gt;方法&lt;/h4&gt;该架构利用了预训练语言模型的泛化能力以及LoRA的有效性，通过仅从历史数据中的专家轨迹学习有效的交易策略。实验中将所提出的决策Transformer与保守Q学习（CQL）、隐式Q学习（IQL）和行为克隆（BC），以及一个基线决策Transformer进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在某些交易场景中表现优异，并且可以有效利用专家轨迹进行学习，同时获得比其他离线RL算法更好的奖励。&lt;h4&gt;结论&lt;/h4&gt;研究表明，将预训练语言模型与参数效率微调相结合的策略，在量化交易中的离线强化学习中非常有效。实验结果表明了所提出的决策Transformer的有效性。&lt;h4&gt;翻译&lt;/h4&gt;开发有效的基于定量交易策略的强化学习（RL）由于实时金融市场互动中的高风险而具有挑战性。因此，不需进一步探索就能利用历史市场数据的离线RL变得至关重要。但是现有的离线RL方法经常难以捕捉金融时间序列中的复杂时空依赖关系，并可能过度拟合到历史模式中。为解决这些挑战，我们引入了一个基于预训练GPT-2权重并进行低秩适应（LoRA）微调的决策Transformer模型。该架构利用了预训练语言模型的泛化能力和LoRA的有效性来仅从历史数据中的专家轨迹学习有效的交易策略。我们的模型在离线RL算法中表现良好，包括保守Q学习（CQL），隐式Q学习（IQL）和行为克隆（BC）。实验证明该方法能够有效地利用专家轨迹，并在某些交易场景中获得更好的奖励。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/syyunn/finrl-dt&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing effective quantitative trading strategies using reinforcementlearning (RL) is challenging due to the high risks associated with onlineinteraction with live financial markets. Consequently, offline RL, whichleverages historical market data without additional exploration, becomesessential. However, existing offline RL methods often struggle to capture thecomplex temporal dependencies inherent in financial time series and may overfitto historical patterns. To address these challenges, we introduce a DecisionTransformer (DT) initialized with pre-trained GPT-2 weights and fine-tunedusing Low-Rank Adaptation (LoRA). This architecture leverages thegeneralization capabilities of pre-trained language models and the efficiencyof LoRA to learn effective trading policies from expert trajectories solelyfrom historical data. Our model performs competitively with established offlineRL algorithms, including Conservative Q-Learning (CQL), Implicit Q-Learning(IQL), and Behavior Cloning (BC), as well as a baseline Decision Transformerwith randomly initialized GPT-2 weights and LoRA. Empirical results demonstratethat our approach effectively learns from expert trajectories and securessuperior rewards in certain trading scenarios, highlighting the effectivenessof integrating pre-trained language models and parameter-efficient fine-tuningin offline RL for quantitative trading. Replication code for our experiments ispublicly available at https://github.com/syyunn/finrl-dt</description>
      <author>example@mail.com (Suyeol Yun)</author>
      <guid isPermaLink="false">2411.17900v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Collective decision making by embodied neural agents</title>
      <link>http://arxiv.org/abs/2411.18498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'研究背景': '集体决策在多智能体系统（包括机器人集群和人类社交网络）中通过简单的社会互动进行了广泛的研究，但现有的多智能体研究很少模拟具身生物代理人的感觉运动协调的神经动力学。', '研究目的': '探究由具有简单神经动态特性的代理之间的感觉运动协调所导致的集体决策', '实验方法': '为代理人配备基于协调动力学框架的最小神经动态模型，并将这些代理人嵌入到含有刺激梯度的环境中。在单智能体设置中，两个刺激源间的决定依赖于代理人的神经动力学与环境的协调；而在多智能体设置中，决定还取决于代理人间的感觉运动协调。', '主要发现': '集体决策的成功取决于个体内部、个体间以及代理和环境之间的耦合平衡，并且使用这些结果来识别影响决策难度的环境因素。研究揭示了大脑内和脑际协调动力学对集体行为的影响。', '结论与意义': '该研究成果有助于理解多智能体系统中代理同步的功能作用，同时也为神经AI和自我组织的多代理系统的未来发展提供了相关性和贡献'}&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一个关于通过简单的社会互动在多个代理系统（包括机器人集群和人类社交网络）中的集体决策的研究。然而，目前对于这些系统的研究很少关注基于感觉运动协调的神经动力学。该研究调查了由具有简单神经动态特性的代理之间的感觉运动协调所导致的集体决策，并且展示了这种成功的决策依赖于个体内部、个体间以及代理和环境之间的耦合平衡。此外，它还探讨了环境因素对决策难度的影响，并揭示了大脑内和脑际协调动力学对集体行为的影响。这些成果有助于理解多智能体系统中代理同步的功能作用，同时也为神经AI和自我组织的多代理系统的未来发展提供了相关性和贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collective decision making using simple social interactions has been studiedin many types of multi-agent systems, including robot swarms and human socialnetworks. However, existing multi-agent studies have rarely modeled the neuraldynamics that underlie sensorimotor coordination in embodied biological agents.In this study, we investigated collective decisions that resulted fromsensorimotor coordination among agents with simple neural dynamics. We equippedour agents with a model of minimal neural dynamics based on the coordinationdynamics framework, and embedded them in an environment with a stimulusgradient. In our single-agent setup, the decision between two stimulus sourcesdepends solely on the coordination of the agent's neural dynamics with itsenvironment. In our multi-agent setup, that same decision also depends on thesensorimotor coordination between agents, via their simple social interactions.Our results show that the success of collective decisions depended on a balanceof intra-agent, inter-agent, and agent-environment coupling, and we use theseresults to identify the influences of environmental factors on decisiondifficulty. More generally, our results demonstrate the impact of intra- andinter-brain coordination dynamics on collective behavior, can contribute toexisting knowledge on the functional role of inter-agent synchrony, and arerelevant to ongoing developments in neuro-AI and self-organized multi-agentsystems.</description>
      <author>example@mail.com (Nicolas Coucke, Mary Katherine Heinrich, Axel Cleeremans, Marco Dorigo, Guillaume Dumas)</author>
      <guid isPermaLink="false">2411.18498v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Project Performance Forecasting using Machine Learning Techniques</title>
      <link>http://arxiv.org/abs/2411.17914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于机器学习的方法来预测城市道路重建项目的性能指标，利用时间序列分析技术并结合外部因素以提高预测精度。&lt;h4&gt;背景&lt;/h4&gt;准确预测项目绩效指标对于成功管理与交付城市道路重建项目至关重要。传统方法依赖于静态基线计划，未能考虑项目进展的动态性和外部因素的影响。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于机器学习的方法来预测成本偏差和挣值等性能指标，并通过案例研究验证该方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用时间序列预测技术（如ARIMA和LSTM网络）以及将天气模式和资源可用性等因素纳入模型中，以提升预测的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;研究成果为项目管理实践提供了数据驱动的解决方案，有助于改善项目性能监控与控制。&lt;h4&gt;结论&lt;/h4&gt;该研究验证了机器学习在提高城市道路重建项目绩效预测中的有效性，并提倡采用更加先进的方法来改进未来的项目管理。&lt;h4&gt;翻译&lt;/h4&gt;准确地预测项目绩效指标对于成功管理和交付城市道路重建项目至关重要。传统的方法往往依赖于静态基线计划，未能考虑到项目的动态进展以及外部因素的影响。这项研究提出了一种基于机器学习的方案，通过历史数据和项目进度来预测每个工作分解结构(WBS)类别的性能指标（例如成本偏差和挣值）。该模型利用时间序列预测技术（包括ARIMA和LSTM网络），并纳入诸如天气模式及资源可用性等外部因素作为特征，以提高预测准确性。凭借机器学习的预测能力，绩效预测模型能够提前识别基线计划中的潜在偏差，并允许项目经理及时采取纠正措施。研究旨在通过城市道路重建项目的案例来验证所提方案的有效性，将模型的预测结果与实际项目性能数据进行对比。这项研究成果推动了建筑行业中项目管理实践的进步，为改进项目绩效监控和控制提供了数据驱动解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate forecasting of project performance metrics is crucial forsuccessfully managing and delivering urban road reconstruction projects.Traditional methods often rely on static baseline plans and fail to considerthe dynamic nature of project progress and external factors. This researchproposes a machine learning-based approach to forecast project performancemetrics, such as cost variance and earned value, for each Work BreakdownStructure (WBS) category in an urban road reconstruction project. The proposedmodel utilizes time series forecasting techniques, including AutoregressiveIntegrated Moving Average (ARIMA) and Long Short-Term Memory (LSTM) networks,to predict future performance based on historical data and project progress.The model also incorporates external factors, such as weather patterns andresource availability, as features to enhance the accuracy of forecasts. Byapplying the predictive power of machine learning, the performance forecastingmodel enables proactive identification of potential deviations from thebaseline plan, which allows project managers to take timely corrective actions.The research aims to validate the effectiveness of the proposed approach usinga case study of an urban road reconstruction project, comparing the model'sforecasts with actual project performance data. The findings of this researchcontribute to the advancement of project management practices in theconstruction industry, offering a data-driven solution for improving projectperformance monitoring and control.</description>
      <author>example@mail.com (Soheila Sadeghi)</author>
      <guid isPermaLink="false">2411.17914v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>At First Contact: Stiffness Estimation Using Vibrational Information for Prosthetic Grasp Modulation</title>
      <link>http://arxiv.org/abs/2411.18507v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 7 figures, for IEEE Sensors Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于机器人和假肢手精细物体操作中刚度估计的压电传感框架。&lt;h4&gt;背景&lt;/h4&gt;在机器人学和假肢手领域，精确地进行刚度估计对于抓取细小物品至关重要，但现有的力基方法存在局限性。这些方法依赖于实时力和位移测量以及传感器数据整合。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的感知系统来改善初次接触时的刚度评估准确性，并在假肢手的指尖集成这种多模式触觉传感器以实现实时动态反馈。&lt;h4&gt;方法&lt;/h4&gt;设计了一种模仿人类皮肤感觉功能的多模态触摸传感器，该传感器可以捕捉振动和力的数据。使用支持向量机（SVM）和支持卷积神经网络（CNN）进行机器学习模型训练来处理这些信号，并通过实验验证其性能。&lt;h4&gt;主要发现&lt;/h4&gt;在首次接触后的关键15毫秒内捕获的振动信号可靠地编码了刚度信息，实现了高达98.6%的分类准确率和2.39 Shore A（邵氏A）以内的回归误差。这种方法显著快于平均抓取闭合时间（本数据集中为16.65 ms），可在物体完全被握住之前进行实时刚度估计。&lt;h4&gt;结论&lt;/h4&gt;通过利用抓取动力学中初始接触的短暂不对称性，该方法能够在其他手指接触对象前进行及时反馈，从而提高假肢手操作的安全性和直观性，并且具备广泛的机器人应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文为英文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stiffness estimation is crucial for delicate object manipulation in roboticand prosthetic hands but remains challenging due to dependence on force anddisplacement measurement and real-time sensory integration. This study presentsa piezoelectric sensing framework for stiffness estimation at first contactduring pinch grasps, addressing the limitations of traditional force-basedmethods. Inspired by human skin, a multimodal tactile sensor that capturesvibrational and force data is developed and integrated into a prosthetic hand'sfingertip. Machine learning models, including support vector machines andconvolutional neural networks, demonstrate that vibrational signals within thecritical 15 ms after first contact reliably encode stiffness, achievingclassification accuracies up to 98.6\% and regression errors as low as 2.39Shore A on real-world objects of varying stiffness. Inference times of lessthan 1.5 ms are significantly faster than the average grasp closure time (16.65ms in our dataset), enabling real-time stiffness estimation before the objectis fully grasped. By leveraging the transient asymmetry in grasp dynamics,where one finger contacts the object before the others, this method enablesearly grasp modulation, enhancing safety and intuitiveness in prosthetic handswhile offering broad applications in robotics.</description>
      <author>example@mail.com (Anway S. Pimpalkar, Ariel Slepyan, Nitish V. Thakor)</author>
      <guid isPermaLink="false">2411.18507v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Joint Resource Optimization, Computation Offloading and Resource Slicing for Multi-Edge Traffic-Cognitive Networks</title>
      <link>http://arxiv.org/abs/2411.17782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于斯塔克伯格博弈的框架，用于建模边缘计算平台和边缘服务器之间的互动，并采用基于贝叶斯优化的集中式算法解决收益最大化、资源分配和任务卸载等问题。此外，考虑到信息收集的实际挑战以及隐私问题，设计了利用神经网络优化与隐私保护信息交换协议的去中心化解决方案。&lt;h4&gt;背景&lt;/h4&gt;在边缘计算领域，平台作为应用提供商与边缘服务器之间的动态中介，在进行任务卸载的同时需要为计算服务支付费用。高效资源利用和严格的服务质量要求使得激励边缘服务器并同时优化平台运营目标变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;探究一个多代理系统，其中平台和边缘服务器都是具有自我利益的实体，并解决收益最大化、资源分配以及任务卸载等联合优化问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于斯塔克伯格博弈框架的方法来建模各方之间的互动。使用贝叶斯优化为基础的集中式算法解决问题。另外为了应对信息收集中的隐私顾虑，设计了去中心化解决方案，利用神经网络优化和隐私保护的信息交换协议。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的数值评估表明，本文提出的机制在与现有基准进行比较时表现出更优越的效果。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了斯塔克伯格博弈框架及相应的集中式算法能够有效解决边缘计算环境下的收益最大化、资源分配和任务卸载等问题。同时提供的去中心化解决方案也应对了隐私保护的需求，为未来的研究提供了有价值的参考方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要的英文原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The evolving landscape of edge computing envisions platforms operating asdynamic intermediaries between application providers and edge servers (ESs),where task offloading is coupled with payments for computational services.Ensuring efficient resource utilization and meeting stringent Quality ofService (QoS) requirements necessitates incentivizing ESs while optimizing theplatforms operational objectives. This paper investigates a multi-agent systemwhere both the platform and ESs are self-interested entities, addressing thejoint optimization of revenue maximization, resource allocation, and taskoffloading. We propose a novel Stackelberg game-based framework to modelinteractions between stakeholders and solve the optimization problem using aBayesian Optimization-based centralized algorithm. Recognizing practicalchallenges in information collection due to privacy concerns, we further designa decentralized solution leveraging neural network optimization and aprivacy-preserving information exchange protocol. Extensive numericalevaluations demonstrate the effectiveness of the proposed mechanisms inachieving superior performance compared to existing baselines.</description>
      <author>example@mail.com (Ting Xiaoyang, Minfeng Zhang, Shu gonglee, Saimin Chen Zhang)</author>
      <guid isPermaLink="false">2411.17782v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Talent-infused Policy-gradient Approach to Efficient Co-Design of Morphology and Task Allocation Behavior of Multi-Robot Systems</title>
      <link>http://arxiv.org/abs/2411.18519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented in proceedings of the International Symposium on
  Distributed Autonomous Robotic Systems (DARS) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个高效的协同设计方法，用于同时优化多机器人系统的形态和行为，以实现集体行为的最大化性能。&lt;h4&gt;背景&lt;/h4&gt;多机器人系统中有趣的高效群体行为源自于每个机器人的个体行为。而单个机器人行为的功能空间则受到其物理设计（即形态）的限制或影响。&lt;h4&gt;目的&lt;/h4&gt;通过结合环境反馈来优化个体机器人的形态和行为，以便更好地利用多机器人系统的全部潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于图强化学习进行个体行为设计的新协同设计法。该方法通过将复杂的协同设计问题分解为一系列较简单的优化和学习子任务，实现了计算效率的提高。&lt;h4&gt;主要发现&lt;/h4&gt;与传统的依次或独立选择形态和行为的方法相比，新方法能够显著提升多机器人系统的性能表现。在洪水响应场景中的无人机应用案例中也证明了这一点。&lt;h4&gt;结论&lt;/h4&gt;通过同时设计机器人的物理特性和其行动策略可以最大化多机器人系统的能力，这种方法尤其适用于需要协调多个实体共同完成复杂任务的环境（例如MRTA问题）。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新颖的方法来同时优化多机器人系统的形态和行为，以实现协同工作的最佳性能。该方法在洪水响应场景的应用中证明了其优越性，并且发现单独设计单个机器人与多个机器人系统时，在形态选择和学习到的行为方面存在显著差异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interesting and efficient collective behavior observed in multi-robot orswarm systems emerges from the individual behavior of the robots. Thefunctional space of individual robot behaviors is in turn shaped or constrainedby the robot's morphology or physical design. Thus the full potential ofmulti-robot systems can be realized by concurrently optimizing the morphologyand behavior of individual robots, informed by the environment's feedback abouttheir collective performance, as opposed to treating morphology and behaviorchoices disparately or in sequence (the classical approach). This paperpresents an efficient concurrent design or co-design method to explore thispotential and understand how morphology choices impact collective behavior,particularly in an MRTA problem focused on a flood response scenario, where theindividual behavior is designed via graph reinforcement learning. Computationalefficiency in this case is attributed to a new way of near exact decompositionof the co-design problem into a series of simpler optimization and learningproblems. This is achieved through i) the identification and use of the Paretofront of Talent metrics that represent morphology-dependent robot capabilities,and ii) learning the selection of Talent best trade-offs and individual robotpolicy that jointly maximizes the MRTA performance. Applied to a multi-unmannedaerial vehicle flood response use case, the co-design outcomes are shown toreadily outperform sequential design baselines. Significant differences inmorphology and learned behavior are also observed when comparing co-designedsingle robot vs. co-designed multi-robot systems for similar operations.</description>
      <author>example@mail.com (Prajit KrisshnaKumar, Steve Paul, Souma Chowdhury)</author>
      <guid isPermaLink="false">2411.18519v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Navigating Spatial Inequities in Freight Truck Crash Severity via Counterfactual Inference in Los Angeles</title>
      <link>http://arxiv.org/abs/2411.17554v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究通过分析运输地理视角下的货运卡车碰撞事件，揭示了社会经济差异、道路基础设施和环境条件对事故地理位置分布及严重性的影响。&lt;h4&gt;背景&lt;/h4&gt;货运卡车相关的交通事故造成了巨大的经济损失、人员伤害和死亡，并且在不同地区存在明显的空间不平等现象。&lt;h4&gt;目的&lt;/h4&gt;通过使用深层反事实推理模型分析影响货运卡车碰撞事件地理分布及严重性的因素，以期提供有关减少这种空间不公的见解。&lt;h4&gt;方法&lt;/h4&gt;研究整合了道路网络数据集、社会经济属性和洛杉矶都会区内的交通事故记录，进行了细致的空间分析。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，在不同人口密度、收入水平和少数族裔群体聚集地区之间存在显著的空间差异。改善基础设施和环境条件可缓解这些不平等现象。&lt;h4&gt;结论&lt;/h4&gt;该研究为减少与货运卡车事故相关的空间不公平提供了基于数据的见解，并提出了有针对性的政策干预措施，特别是在低收入和少数族裔集中区域改进道路设施、照明及交通控制系统。&lt;h4&gt;翻译&lt;/h4&gt;摘要：货运卡车相关碰撞事件带来重大挑战，导致巨大经济损失、人员伤害和死亡，在不同地区存在显著的空间差异。本研究采用运输地理视角来考察空间正义问题，通过深度反事实推理模型分析社会经济不平等、道路基础设施以及环境条件如何影响事故地理位置分布及严重性。整合洛杉矶都会区的交通网络数据集、社会经济属性及碰撞记录，该研究提供了不同社区受到不平等待遇的细致的空间分析。结果揭示了在不同人口密度、收入水平和少数族裔群体聚集地区之间，在事故严重性上存在显著空间差异，强调改进基础设施和环境条件的重要性。该发现为制定有针对性的位置特定政策干预措施提供见解，建议改善道路设施、照明和交通控制系统，特别是在低收入和少数族裔集中区域。本研究通过基于数据的洞察贡献于运输地理学及空间公平文献中，以减少与货运卡车事故相关的空间不公平现象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Freight truck-related crashes pose significant challenges, leading tosubstantial economic losses, injuries, and fatalities, with pronounced spatialdisparities across different regions. This study adopts a transport geographyperspective to examine spatial justice concerns by employing deepcounterfactual inference models to analyze how socioeconomic disparities, roadinfrastructure, and environmental conditions influence the geographicaldistribution and severity of freight truck crashes. By integrating road networkdatasets, socioeconomic attributes, and crash records from the Los Angelesmetropolitan area, this research provides a nuanced spatial analysis of howdifferent communities are disproportionately impacted. The results revealsignificant spatial disparities in crash severity across areas with varyingpopulation densities, income levels, and minority populations, highlighting thepivotal role of infrastructural and environmental improvements in mitigatingthese disparities. The findings offer insights into targeted, location-specificpolicy interventions, suggesting enhancements in road infrastructure, lighting,and traffic control systems, particularly in low-income andminority-concentrated areas. This research contributes to the literature ontransport geography and spatial equity by providing data-driven insights intoeffective measures for reducing spatial injustices associated with freighttruck-related crashes.</description>
      <author>example@mail.com (Yichen Wang, Hao Yin, Yifan Yang, Chenyang Zhao, Siqin Wang)</author>
      <guid isPermaLink="false">2411.17554v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>LISA test-mass charging. Particle flux modeling, Monte Carlo simulations and induced effects on the sensitivity of the observatory</title>
      <link>http://arxiv.org/abs/2411.18030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了LISA空间天文台探测宇宙中引力波发射的亚赫兹频谱时所面临的问题以及如何通过研究自由落体测试质量（TMs）上的电荷积累来预测和减轻这些影响。&lt;h4&gt;背景&lt;/h4&gt;LISA空间天文台将探索由银河系宇宙射线(GCRs)和太阳高能粒子(SEPs)引发的、在太空环境中自由落体测试质量上积累电荷的过程。这些过程会对LISA及其他类似任务的性能产生负面影响，尤其是在探测引力波时。&lt;h4&gt;目的&lt;/h4&gt;了解TM上的电荷与原始静电场之间的耦合所产生的噪声力对LISA任务的限制作用，并通过精确掌握充电过程来预测和设计相应的对策。&lt;h4&gt;方法&lt;/h4&gt;提出了一种全面的方法论工具包，用于在代表LISA任务几何结构的情况下计算TM的充电时间序列以及由此产生的力量，在不同空间环境条件下考虑了短波长、长时间GCR通量调制和SEP的影响。&lt;h4&gt;主要发现&lt;/h4&gt;研究了先前提到的各种条件下的TM充电过程所产生的虚假力对引力波检测敏感度的影响。&lt;h4&gt;结论&lt;/h4&gt;通过详细分析，可以准确预测并减轻由于TM上的电荷积累而产生的噪声力量，从而提高LISA任务探测引力波的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的内容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Context. The LISA space observatory will explore the sub-Hz spectrum ofgravitational wave emission from the Universe. The space environment, wherewill be immersed in, is responsible for charge accumulation on its free fallingtest masses (TMs) due to the galactic cosmic rays (GCRs) and solar energeticparticles (SEP) impinging on the spacecraft. Primary and secondary particlesproduced in the spacecraft material eventually reach the TMs by depositing anet positive charge fluctuating in time. This work is relevant for any presentand future space missions that, like LISA, host free-falling TMs as inertialreference. Aims. The coupling of the TM charge with native stray electrostaticfield produces noise forces on the TMs, which can limit the performance of theLISA mission. A precise knowledge of the charging process allows us to predictthe intensity of these charge-induced disturbances and to design specificcounter-measures. Methods. We present a comprehensive toolkit that allows us tocalculate the TM charging time-series in a geometry representative of LISAmission, and the associated induced forces under different conditions of thespace environment by considering the effects of short, long GCR fluxmodulations and SEPs. Results. We study, for each of the previously mentionedconditions, the impact of spurious forces associated with the TM chargingprocess on the mission sensitivity for gravitational wave detection.</description>
      <author>example@mail.com (Francesco Dimiccoli, Rita Dolesi, Michele Fabi, Valerio Ferroni, Catia Grimani, Martina Muratore, Paolo Sarra, Mattia Villani, William Joseph Weber)</author>
      <guid isPermaLink="false">2411.18030v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Towards Motion Compensation in Autonomous Robotic Subretinal Injections</title>
      <link>http://arxiv.org/abs/2411.18521v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了利用实时光学相干断层扫描(OCT)进行运动补偿的自主机器人系统的方法，用于湿性年龄相关性黄斑变性的治疗。&lt;h4&gt;背景&lt;/h4&gt;湿性年龄相关性黄斑变性是一种老年人视力丧失的主要原因，通常通过玻璃体内注射来治疗。新兴疗法如视网膜下干细胞、基因治疗等需要精确递送以避免损伤脆弱的视网膜结构。&lt;h4&gt;目的&lt;/h4&gt;开发一种利用实时光学相干断层扫描(OCT)进行运动补偿的方法，提高机器人系统在视网膜下注射中的精度和安全性。&lt;h4&gt;方法&lt;/h4&gt;该研究提出了一种新的运动补偿技术，使用B5-扫描快速获取小体积OCT数据以动态追踪Z轴上的视网膜移动。&lt;h4&gt;主要发现&lt;/h4&gt;体外实验显示维持工具到视网膜的距离的一致性具有挑战性；对于100μm振幅的移动，在一分钟内距离偏差高达200μm，而25μm振幅的移动超过80μm。视网膜下注射面临额外困难，水平偏移可能导致针偏离目标位置并注入玻璃体。&lt;h4&gt;结论&lt;/h4&gt;结果表明需要改进运动预测和横向稳定性以提高机器人在进行视网膜下程序时的准确性和安全性。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于湿性年龄相关性黄斑变性的治疗研究，提出了一种新的方法利用实时光学相干断层扫描(OCT)实现精确的机器人操作。该技术旨在通过动态追踪Z轴上视网膜移动来补偿生理运动，并提高视网膜下注射的安全性和准确性。实验结果强调了进一步改进运动预测和横向稳定性的必要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Exudative (wet) age-related macular degeneration (AMD) is a leading cause ofvision loss in older adults, typically treated with intravitreal injections.Emerging therapies, such as subretinal injections of stem cells, gene therapy,small molecules or RPE cells require precise delivery to avoid damagingdelicate retinal structures. Autonomous robotic systems can potentially offerthe necessary precision for these procedures. This paper presents a novelapproach for motion compensation in robotic subretinal injections, utilizingreal-time Optical Coherence Tomography (OCT). The proposed method leveragesB$^{5}$-scans, a rapid acquisition of small-volume OCT data, for dynamictracking of retinal motion along the Z-axis, compensating for physiologicalmovements such as breathing and heartbeat. Validation experiments on \textit{exvivo} porcine eyes revealed challenges in maintaining a consistenttool-to-retina distance, with deviations of up to 200 $\mu m$ for 100 $\mu m$amplitude motions and over 80 $\mu m$ for 25 $\mu m$ amplitude motions over oneminute. Subretinal injections faced additional difficulties, with horizontalshifts causing the needle to move off-target and inject into the vitreous.These results highlight the need for improved motion prediction and horizontalstability to enhance the accuracy and safety of robotic subretinal procedures.</description>
      <author>example@mail.com (Demir Arikan, Peiyao Zhang, Michael Sommersperger, Shervin Dehghani, Mojtaba Esfandiari, Russel H. Taylor, M. Ali Nasseri, Peter Gehlbach, Nassir Navab, Iulian Iordachita)</author>
      <guid isPermaLink="false">2411.18521v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Objective Reinforcement Learning for Automated Resilient Cyber Defence</title>
      <link>http://arxiv.org/abs/2411.17585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了自主网络防御（ACD）代理在应对复杂和大规模的网络安全威胁中的应用，特别是当攻击者利用人工智能和自动化技术时。通过对比单一目标强化学习与多目标强化学习的方法，在一个模拟游戏环境中测试并比较了两种算法：多目标近端策略优化（MOPPO）和帕累托条件网络（PCN），以评估它们在保护网络的同时保持关键功能方面的表现。&lt;h4&gt;背景&lt;/h4&gt;网络攻击对军事指挥控制系统、情报监视侦察系统以及民用基础设施构成了严重威胁。利用人工智能和自主代理的攻击增加了这种威胁的规模、范围和复杂性，导致了更大的破坏。&lt;h4&gt;目的&lt;/h4&gt;研究使用多目标强化学习算法创建ACD代理的方法及其在网络安全防御中的有效性，并探讨与单一目标强化学习方法相比的优势和局限。&lt;h4&gt;方法&lt;/h4&gt;采用MOPPO和PCN两种多目标强化学习算法来训练ACD代理，在一个考虑网络防御和维持关键功能的双目标游戏中比较它们的表现。&lt;h4&gt;主要发现&lt;/h4&gt;相较于仅关注单一目标的方法，使用多目标强化学习方法可以更好地平衡不同目标之间的冲突，并在保证网络安全的同时兼顾服务可用性。然而，这种方法可能面临着计算复杂度高的挑战以及模型适应性的限制。&lt;h4&gt;结论&lt;/h4&gt;提出了一种基于多目标强化学习的自主网络防御代理设计和评估方案，以更全面地应对复杂的网络攻击威胁。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容：网络攻击对军事指挥控制系统、情报监视侦察系统以及民用基础设施构成了严重威胁。利用人工智能和自主代理的攻击增加了这种威胁的规模、范围和复杂性，导致了更大的破坏。自主网络防御（ACD）代理旨在通过机器速度响应并以应对问题所需的规模来缓解这一威胁。顺序决策算法如深度强化学习提供了创建ACD代理的一个有前途的方法。这些算法专注于单个目标，比如最小化红方在网上的入侵行为，使用手工设计的加权奖励和。这种方法剥夺了模型在推理过程中进行调整的能力，并且无法解决在网络操作和保护中出现的各种竞争性目标。例如，在从备份映像恢复机器的同时需要仔细平衡由此产生的停机成本或可能对网络流量和服务造成的干扰。而非追求单一目标强化学习的方法，本文提出了一种简单的双目标网络安全防御游戏实例，该游戏要求考虑既防备红方入侵又维持绿方关键功能的问题。利用两种多目标强化学习算法，即多目标近端策略优化（MOPPO）和帕累托条件网络（PCN），创建了两个训练好的ACD代理，并在我们的双目标网络安全防御游戏中对其性能进行了比较。基于对该游戏的研究，讨论了多目标RL ACD代理与单一目标RL ACD代理相比的优势和限制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cyber-attacks pose a security threat to military command and controlnetworks, Intelligence, Surveillance, and Reconnaissance (ISR) systems, andcivilian critical national infrastructure. The use of artificial intelligenceand autonomous agents in these attacks increases the scale, range, andcomplexity of this threat and the subsequent disruption they cause. AutonomousCyber Defence (ACD) agents aim to mitigate this threat by responding at machinespeed and at the scale required to address the problem. Sequentialdecision-making algorithms such as Deep Reinforcement Learning (RL) provide apromising route to create ACD agents. These algorithms focus on a singleobjective such as minimizing the intrusion of red agents on the network, byusing a handcrafted weighted sum of rewards. This approach removes the abilityto adapt the model during inference, and fails to address the many competingobjectives present when operating and protecting these networks. Conflictingobjectives, such as restoring a machine from a back-up image, must be carefullybalanced with the cost of associated down-time, or the disruption to networktraffic or services that might result. Instead of pursing a Single-Objective RL(SORL) approach, here we present a simple example of a multi-objective networkdefence game that requires consideration of both defending the network againstred-agents and maintaining critical functionality of green-agents. TwoMulti-Objective Reinforcement Learning (MORL) algorithms, namelyMulti-Objective Proximal Policy Optimization (MOPPO), and Pareto-ConditionedNetworks (PCN), are used to create two trained ACD agents whose performance iscompared on our Multi-Objective Cyber Defence game. The benefits andlimitations of MORL ACD agents in comparison to SORL ACD agents are discussedbased on the investigations of this game.</description>
      <author>example@mail.com (Ross O'Driscoll, Claudia Hagen, Joe Bater, James M. Adams)</author>
      <guid isPermaLink="false">2411.17585v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Relationships of Subjects and Shapelets for Semi-supervised Multivariate Series Classification</title>
      <link>http://arxiv.org/abs/2411.18043v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE International Conference on Data Engineering (ICDE)
  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种用于半监督多变量时间序列分类的新方法，该方法通过整合不同类型的信息和捕捉它们之间的关系来提高分类性能。&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列（MTS）分类在工业、医疗保健和金融等领域广泛应用，旨在从复杂的时间序列数据中提取关键特征以实现准确的决策和预测。然而，现有的MTS分类方法由于难以有效建模高维数据以及缺乏标注数据而存在性能不足的问题。&lt;h4&gt;目的&lt;/h4&gt;为了克服这些问题，本文提出了一种基于异构关系和形变（shapelets）的方法来改进半监督下的多变量时间序列分类。&lt;h4&gt;方法&lt;/h4&gt;- 使用对比时序自注意力模块获得稀疏的MTS表示
- 通过软动态时间规整建模这些表示之间的相似性以构建一个相似图
- 学习不同主题类型的形变，并将主体特征及其形变作为额外信息进一步细化该相似图，最终生成异构图
- 使用双层图注意力网络进行预测&lt;h4&gt;主要发现&lt;/h4&gt;- 通过上述方法成功地将数据集转换为异构图并整合了多种附加信息
- 实验结果表明，在Human Activity Recognition、睡眠阶段分类以及University of East Anglia数据集中，本文的方法优于当前最先进的MTS分类方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在半监督时间序列节点分类任务中表现出色，并且证明了这种方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多变量时间序列（MTS）分类广泛应用于工业、医疗保健和金融等领域，旨在从复杂的时间序列数据中提取关键特征以实现准确的决策和预测。然而，现有的MTS方法由于难以有效建模高维数据以及缺乏标注数据而存在性能不佳的问题。为了解决这个问题，我们提出了一种基于主体之间异构关系和形变（shapelets）的方法来进行半监督多变量时间序列分类。通过整合多种类型的信息并捕捉它们之间的联系提供了一个新颖的视角。具体来说，我们首先使用对比时序自注意力模块获得稀疏的时间序列表示，并利用软动态时间规整来建模这些表示间的相似性以构建一个相似图；其次学习不同主体类型的形变，并将主题特征及其形变作为附加信息进一步细化该相似图，最终生成异构图；最后采用双层图注意力网络进行预测。通过这种方法成功地将数据集转换为异构图并整合了多种附加信息，实现了精确的半监督节点分类。在Human Activity Recognition、睡眠阶段分类和University of East Anglia数据集上的实验表明，该方法优于当前最先进的多变量时间序列分类方法，验证了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series (MTS) classification is widely applied in fieldssuch as industry, healthcare, and finance, aiming to extract key features fromcomplex time series data for accurate decision-making and prediction. However,existing methods for MTS often struggle due to the challenges of effectivelymodeling high-dimensional data and the lack of labeled data, resulting in poorclassification performance. To address this issue, we propose a heterogeneousrelationships of subjects and shapelets method for semi-supervised MTSclassification. This method offers a novel perspective by integrating varioustypes of additional information while capturing the relationships between them.Specifically, we first utilize a contrast temporal self-attention module toobtain sparse MTS representations, and then model the similarities betweenthese representations using soft dynamic time warping to construct a similaritygraph. Secondly, we learn the shapelets for different subject types,incorporating both the subject features and their shapelets as additionalinformation to further refine the similarity graph, ultimately generating aheterogeneous graph. Finally, we use a dual level graph attention network toget prediction. Through this method, we successfully transform dataset into aheterogeneous graph, integrating multiple additional information and achievingprecise semi-supervised node classification. Experiments on the Human ActivityRecognition, sleep stage classification and University of East Anglia datasetsdemonstrate that our method outperforms current state-of-the-art methods in MTSclassification tasks, validating its superiority.</description>
      <author>example@mail.com (Mingsen Du, Meng Chen, Yongjian Li, Cun Ji, Shoushui Wei)</author>
      <guid isPermaLink="false">2411.18043v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Emergence of Self-Identity in AI: A Mathematical Framework and Empirical Study with Generative Large Language Models</title>
      <link>http://arxiv.org/abs/2411.18530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种数学框架，用于定义和量化人工智能系统的自我认同，并填补了人工意识理论基础的一个重要空白。&lt;h4&gt;背景&lt;/h4&gt;现有的人工自识方法通常依赖于启发式实现或哲学抽象。而本文提供了一个基于度量空间理论、测度论以及泛函分析的正式框架。&lt;h4&gt;目的&lt;/h4&gt;旨在通过定义和量化两个数学条件来建立自我认同：记忆连贯性及其在可能自我身份的空间中的持续一致识别。&lt;h4&gt;方法&lt;/h4&gt;使用Llama 3.2 1B模型进行实证实验，利用低秩适应（LoRA）技术进行有效的微调，并在一个包含时间结构化记忆的合成数据集上训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在可衡量的自我意识指标方面有显著改善，主要自识得分从0.276增加到了0.801。&lt;h4&gt;结论&lt;/h4&gt;研究为创建具有验证过自我认同特征的人工智能系统提供了结构化的方法，并且对人形机器人和自主系统的领域有着直接的应用意义。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/BrainJellyPie/self&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a mathematical framework for defining and quantifyingself-identity in artificial intelligence (AI) systems, addressing a criticalgap in the theoretical foundations of artificial consciousness. While existingapproaches to artificial self-awareness often rely on heuristic implementationsor philosophical abstractions, we present a formal framework grounded in metricspace theory, measure theory, and functional analysis. Our framework positsthat self-identity emerges from two mathematically quantifiable conditions: theexistence of a connected continuum of memories $C \subseteq \mathcal{M}$ in ametric space $(\mathcal{M}, d_{\mathcal{M}})$, and a continuous mapping $I:\mathcal{M} \to \mathcal{S}$ that maintains consistent self-recognition acrossthis continuum, where $(\mathcal{S}, d_{\mathcal{S}})$ represents the metricspace of possible self-identities. To validate this theoretical framework, weconducted empirical experiments using the Llama 3.2 1B model, employingLow-Rank Adaptation (LoRA) for efficient fine-tuning. The model was trained ona synthetic dataset containing temporally structured memories, designed tocapture the complexity of coherent self-identity formation. Our evaluationmetrics included quantitative measures of self-awareness, response consistency,and linguistic precision. The experimental results demonstrate substantialimprovements in measurable self-awareness metrics, with the primaryself-awareness score increasing from 0.276 to 0.801. This enables thestructured creation of AI systems with validated self-identity features. Theimplications of our study are immediately relevant to the fields of humanoidrobotics and autonomous systems.</description>
      <author>example@mail.com (Minhyeok Lee)</author>
      <guid isPermaLink="false">2411.18530v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Crash Likelihood Prediction: A Complexity-Infused Approach Integrating Semantic, Contextual, and Driving Features</title>
      <link>http://arxiv.org/abs/2411.17886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种两阶段框架，用于基于道路复杂性特征预测交通事故的可能性。&lt;h4&gt;背景&lt;/h4&gt;在复杂的驾驶环境中预测事故发生的可能性对于提高交通安全和推动自动驾驶技术的发展至关重要。以往的研究主要集中在使用统计模型或深度学习方法来预测事故，但尚未考察这些因素的综合影响。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过集成语义、驾驶行为及上下文特征来评估道路复杂性对事故预测的影响，并提出一种新的两阶段框架以提高预测准确性。&lt;h4&gt;方法&lt;/h4&gt;第一阶段使用编码器提取隐藏的上下文信息，生成结合了复杂性的新特征；第二阶段利用原始特征和这些复杂的特征进行事故可能性预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示单独使用原始特征时准确率为87.98%，而加入复杂性增强后的特征后准确率提升至90.15%。此外，研究还表明结合语义、驾驶行为及上下文信息的组合能够提供最佳结果，并且大型语言模型生成的道路复杂度标签优于Amazon Mechanical Turk的人工标注。&lt;h4&gt;结论&lt;/h4&gt;通过利用道路复杂性相关因素并采用创新框架，可以有效提升交通事故预测系统的准确性和规模效应。未来研究应继续探索自动化工具在构建准确、可扩展的事故预测系统中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting crash likelihood in complex driving environments is essential forimproving traffic safety and advancing autonomous driving. Previous studieshave used statistical models and deep learning to predict crashes based onsemantic, contextual, or driving features, but none have examined the combinedinfluence of these factors, termed roadway complexity in this study. This paperintroduces a two-stage framework that integrates roadway complexity featuresfor crash prediction. In the first stage, an encoder extracts hidden contextualinformation from these features, generating complexity-infused features. Thesecond stage uses both original and complexity-infused features to predictcrash likelihood, achieving an accuracy of 87.98% with original features aloneand 90.15% with the added complexity-infused features. Ablation studies confirmthat a combination of semantic, driving, and contextual features yields thebest results, which emphasize their role in capturing roadway complexity.Additionally, complexity index annotations generated by Large Language Modelsoutperform those by Amazon Mechanical Turk, highlighting the potential ofautomated tools for accurate, scalable crash prediction systems.</description>
      <author>example@mail.com (Meng Wang, Zach Noonan, Pnina Gershon, Shannon C. Roberts)</author>
      <guid isPermaLink="false">2411.17886v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>AdaVLN: Towards Visual Language Navigation in Continuous Indoor Environments with Moving Humans</title>
      <link>http://arxiv.org/abs/2411.18539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了Adaptive Visual Language Navigation (AdaVLN)任务，它在3D室内环境中让机器人根据自然语言指令导航，并且需要处理动态的人类障碍。&lt;h4&gt;背景&lt;/h4&gt;现有的视觉语言导航研究主要集中在静态环境上，而实际的导航必须面对动态的人类障碍物。这导致了模拟到现实之间的差距。&lt;h4&gt;目的&lt;/h4&gt;提出AdaVLN任务以缩小研究与真实世界应用间的差距，并为此开发了一个新的仿真器和数据集。&lt;h4&gt;方法&lt;/h4&gt;介绍了AdaVLN仿真器及AdaR2R数据集，其中仿真器支持在常见3D室内环境数据集中直接加入动态的人类模型，同时提供暂停机制来确保不同硬件上的公平比较。&lt;h4&gt;主要发现&lt;/h4&gt;评估了几种基线模型的表现，并分析了由AdaVLN任务引入的独特挑战。该研究还展示了如何通过改进现有模拟环境来缩小仿真与现实的差距。&lt;h4&gt;结论&lt;/h4&gt;这项工作对于视觉语言导航领域具有重要价值，可以促进更加接近真实世界的机器人导航技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;视觉语言导航（Visual Language Navigation）是一个让机器人在基于自然语言指令的情况下，在现实中进行导航的任务。尽管先前的研究主要集中在静态场景上，但实际的导航常常需要处理动态的人类障碍物。因此，我们提出了一项名为Adaptive Visual Language Navigation (AdaVLN)的新任务来缩小这一差距。AdaVLN要求机器人在一个包含动态移动人类障碍的复杂3D室内环境中进行导航，增加了模仿现实世界的导航任务难度层次。为了支持这项任务的研究探索，我们也提出了AdaVLN仿真器和AdaR2R数据集。该仿真器允许将完全动画化的人类模型直接纳入常见的Matterport3D等数据集中。此外，我们还引入了一个“冻结时间”机制，用于导航任务以及模拟器，在代理进行推理时暂停世界状态更新，从而确保不同硬件之间的公平比较和实验可重复性。我们在该任务上评估了几种基线模型，分析了由AdaVLN引入的独特挑战，并展示了它在缩小视觉语言导航研究中的仿真到现实差距方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/dillonloh/adavln&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Language Navigation is a task that challenges robots to navigate inrealistic environments based on natural language instructions. While previousresearch has largely focused on static settings, real-world navigation mustoften contend with dynamic human obstacles. Hence, we propose an extension tothe task, termed Adaptive Visual Language Navigation (AdaVLN), which seeks tonarrow this gap. AdaVLN requires robots to navigate complex 3D indoorenvironments populated with dynamically moving human obstacles, adding a layerof complexity to navigation tasks that mimic the real-world. To supportexploration of this task, we also present AdaVLN simulator and AdaR2R datasets.The AdaVLN simulator enables easy inclusion of fully animated human modelsdirectly into common datasets like Matterport3D. We also introduce a"freeze-time" mechanism for both the navigation task and simulator, whichpauses world state updates during agent inference, enabling fair comparisonsand experimental reproducibility across different hardware. We evaluate severalbaseline models on this task, analyze the unique challenges introduced byAdaVLN, and demonstrate its potential to bridge the sim-to-real gap in VLNresearch.</description>
      <author>example@mail.com (Dillon Loh, Tomasz Bednarz, Xinxing Xia, Frank Guan)</author>
      <guid isPermaLink="false">2411.18539v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Visual Adversarial Attack on Vision-Language Models for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2411.18275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文提出了一种专门针对自动驾驶视觉语言模型的攻击框架ADvLM，该框架通过引入语义不变诱导和场景关联增强技术来应对这一领域的独特挑战。&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型在提升自动驾驶系统的推理能力方面取得了显著进展，但这些模型对对抗性攻击非常脆弱。现有的研究主要集中在通用的VLM攻击上，而针对自动驾驶这种安全关键领域的特定攻击方法却鲜有探索。&lt;h4&gt;目的&lt;/h4&gt;设计专门用于自动驾驶环境中视觉语言模型的对抗性攻击框架，揭示在这一领域中此类攻击带来的重大风险。&lt;h4&gt;方法&lt;/h4&gt;ADvLM框架提出了两个创新技术：1) 语义不变诱导，通过一个大规模的语言模型创建一系列具有相同语义内容但多样化文本指令的提示库；2) 场景关联增强，使用注意力机制选择关键帧和视角来优化对整个场景通用化的对抗性干扰。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明ADvLM在多个自动驾驶视觉语言模型上实现了最先进的攻击效果。此外，真实世界的攻击研究进一步证明了其实际应用的可行性和潜力。&lt;h4&gt;结论&lt;/h4&gt;针对自动驾驶环境中VLM的独特挑战，本文首次提出了一种有效的对抗性攻击框架，并通过实验展示了它的重要性及其可能的应用场景。&lt;h4&gt;翻译&lt;/h4&gt;视觉语言模型（VLMs）在增强自主驾驶系统中的推理能力方面取得了显著进展。然而，这些模型仍然非常容易受到对抗性攻击的影响。尽管现有研究主要集中在通用的VLM攻击上，但对于安全关键性的自动驾驶环境下的特定攻击开发却很少被关注。在这篇论文中，我们首次尝试设计专门针对AD VLMs的对抗性攻击，揭示了在这一重要领域内此类攻击带来的巨大风险。我们识别出两个有效的AD VLM攻击的独特挑战：指令文本变化性和视觉场景的时间序列性质。为此，我们提出了ADvLM，这是首个专门为AD中的VLM设计的视觉对抗攻击框架。我们的框架引入了语义不变诱导技术，通过一个大规模的语言模型创建具有相同语义内容但多样化指令提示库，引导由语义熵指导。在此基础上，我们提出场景关联增强方法，在此方法中注意力机制选择驾驶情景的关键帧和视角以优化整个情景范围内的对抗性扰动。在多个AD VLMs上的广泛实验表明，ADvLM实现了最先进的攻击效果。此外，实际世界中的攻击研究进一步验证了其适用性和潜在价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs) have significantly advanced autonomous driving(AD) by enhancing reasoning capabilities. However, these models remain highlyvulnerable to adversarial attacks. While existing research has primarilyfocused on general VLM attacks, the development of attacks tailored to thesafety-critical AD context has been largely overlooked. In this paper, we takethe first step toward designing adversarial attacks specifically targeting VLMsin AD, exposing the substantial risks these attacks pose within this criticaldomain. We identify two unique challenges for effective adversarial attacks onAD VLMs: the variability of textual instructions and the time-series nature ofvisual scenarios. To this end, we propose ADvLM, the first visual adversarialattack framework specifically designed for VLMs in AD. Our framework introducesSemantic-Invariant Induction, which uses a large language model to create adiverse prompt library of textual instructions with consistent semanticcontent, guided by semantic entropy. Building on this, we introduceScenario-Associated Enhancement, an approach where attention mechanisms selectkey frames and perspectives within driving scenarios to optimize adversarialperturbations that generalize across the entire scenario. Extensive experimentson several AD VLMs over multiple benchmarks show that ADvLM achievesstate-of-the-art attack effectiveness. Moreover, real-world attack studiesfurther validate its applicability and potential in practice.</description>
      <author>example@mail.com (Tianyuan Zhang, Lu Wang, Xinwei Zhang, Yitong Zhang, Boyi Jia, Siyuan Liang, Shengshan Hu, Qiang Fu, Aishan Liu, Xianglong Liu)</author>
      <guid isPermaLink="false">2411.18275v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DECODE: Domain-aware Continual Domain Expansion for Motion Prediction</title>
      <link>http://arxiv.org/abs/2411.17917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了DECODE框架，用于自动驾驶中的运动预测。&lt;h4&gt;背景&lt;/h4&gt;自主驾驶需要不断适应新的和多样的驾驶场景，并进行频繁的模型更新以提高导航能力和行为预期准确性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在不同领域中既能专业化又能通用化的连续学习框架。&lt;h4&gt;方法&lt;/h4&gt;引入了DECODE，该框架使用超网络生成模型参数并采用归一化流机制实现实时模型选择。同时利用深度贝叶斯不确定性估计技术整合最相关的专业化和通用化模型的输出。&lt;h4&gt;主要发现&lt;/h4&gt;DECODE在熟悉的条件中确保最佳性能，在不熟悉的情况下保持鲁棒性，并且实验表明其具有低遗忘率（0.044）和平均最小ADE值为0.584米，超越了传统学习策略。&lt;h4&gt;结论&lt;/h4&gt;DECODE展示出了良好的适应性和有效性，在广泛的驾驶条件下表现优异。&lt;h4&gt;翻译&lt;/h4&gt;运动预测对自动驾驶车辆有效导航复杂环境以及准确预见其他交通参与者的行为至关重要。随着自主驾驶技术的进步，需要频繁通过重新训练来更新模型以吸收新的和多样的驾驶场景。为了应对这些需求，我们提出了DECODE框架，这是一个基于预训练通用模型的增量发展领域特定模型的独特连续学习方法。该框架使用超网络生成模型参数，减少存储需求，并利用归一化流机制根据可能性估计实现实时模型选择。此外，它通过深度贝叶斯不确定性估计技术融合相关专业和一般模型输出，确保在熟悉情况下的最佳性能以及不熟悉条件下的适应能力。广泛的评估证实了该框架的有效性，其忘记率为0.044，平均最小ADE为0.584米，大大优于传统的学习策略，并展示了跨多种驾驶状况的灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion prediction is critical for autonomous vehicles to effectively navigatecomplex environments and accurately anticipate the behaviors of other trafficparticipants. As autonomous driving continues to evolve, the need to assimilatenew and varied driving scenarios necessitates frequent model updates throughretraining. To address these demands, we introduce DECODE, a novel continuallearning framework that begins with a pre-trained generalized model andincrementally develops specialized models for distinct domains. Unlike existingcontinual learning approaches that attempt to develop a unified model capableof generalizing across diverse scenarios, DECODE uniquely balancesspecialization with generalization, dynamically adjusting to real-time demands.The proposed framework leverages a hypernetwork to generate model parameters,significantly reducing storage requirements, and incorporates a normalizingflow mechanism for real-time model selection based on likelihood estimation.Furthermore, DECODE merges outputs from the most relevant specialized andgeneralized models using deep Bayesian uncertainty estimation techniques. Thisintegration ensures optimal performance in familiar conditions whilemaintaining robustness in unfamiliar scenarios. Extensive evaluations confirmthe effectiveness of the framework, achieving a notably low forgetting rate of0.044 and an average minADE of 0.584 m, significantly surpassing traditionallearning strategies and demonstrating adaptability across a wide range ofdriving conditions.</description>
      <author>example@mail.com (Boqi Li, Haojie Zhu, Henry X. Liu)</author>
      <guid isPermaLink="false">2411.17917v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DexDiffuser: Interaction-aware Diffusion Planning for Adaptive Dexterous Manipulation</title>
      <link>http://arxiv.org/abs/2411.18562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages. Project page: https://dexdiffuser.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DexDiffuser是一种适应性灵巧操作的接触感知扩散规划框架，适用于复杂的机器人交互任务。&lt;h4&gt;背景&lt;/h4&gt;当前基于扩散的方法在简单的抓取任务中表现良好，但在处理复杂序列交互时产生不现实的状态或缺乏灵活性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来解决现有方法在复杂和多样化的物理操作中的不足，特别是在目标适应性和泛化能力方面。&lt;h4&gt;方法&lt;/h4&gt;DexDiffuser通过双相扩散过程建模关节状态-动作动力学，包括接触前对准和接触后的定向控制。此外，该框架结合了基于动态模型的双重指导，并利用大型语言模型自动生成引导功能。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与现有方法相比，DexDiffuser在训练分布之外的目标上的平均成功率超过两倍（59.2% vs 29.5%）。具体表现为30度开门成功率达到70%，笔和积木半侧重新定向分别为40%和36.7%，锤击钉子一半长度的驱动率为46.7%。&lt;h4&gt;结论&lt;/h4&gt;DexDiffuser框架展示了在接触丰富的操作中强大的适应性和灵活性，是未来先进机器人技术的一个重要发展方向。&lt;h4&gt;翻译&lt;/h4&gt;灵巧的操作需要接触密集型交互，在最近的研究中基于扩散的方法显示了处理简单抓取任务的潜力。然而，这些方法经常产生不现实的状态或难以适应复杂序列交互中的变化。本研究提出了DexDiffuser框架，它通过建模关节状态-动作动力学和结合语言模型来解决这些问题。实验结果表明该框架在各种物理操作任务中显著优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous manipulation with contact-rich interactions is crucial for advancedrobotics. While recent diffusion-based planning approaches show promise forsimpler manipulation tasks, they often produce unrealistic ghost states (e.g.,the object automatically moves without hand contact) or lack adaptability whenhandling complex sequential interactions. In this work, we introduceDexDiffuser, an interaction-aware diffusion planning framework for adaptivedexterous manipulation. DexDiffuser models joint state-action dynamics througha dual-phase diffusion process which consists of pre-interaction contactalignment and post-contact goal-directed control, enabling goal-adaptivegeneralizable dexterous manipulation. Additionally, we incorporate dynamicsmodel-based dual guidance and leverage large language models for automatedguidance function generation, enhancing generalizability for physicalinteractions and facilitating diverse goal adaptation through language cues.Experiments on physical interaction tasks such as door opening, pen and blockre-orientation, and hammer striking demonstrate DexDiffuser's effectiveness ongoals outside training distributions, achieving over twice the average successrate (59.2% vs. 29.5%) compared to existing methods. Our framework achieves70.0% success on 30-degree door opening, 40.0% and 36.7% on pen and blockhalf-side re-orientation respectively, and 46.7% on hammer nail half drive,highlighting its robustness and flexibility in contact-rich manipulation.</description>
      <author>example@mail.com (Zhixuan Liang, Yao Mu, Yixiao Wang, Fei Ni, Tianxing Chen, Wenqi Shao, Wei Zhan, Masayoshi Tomizuka, Ping Luo, Mingyu Ding)</author>
      <guid isPermaLink="false">2411.18562v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Ridge Regression for Manifold-valued Time-Series with Application to Meteorological Forecast</title>
      <link>http://arxiv.org/abs/2411.18339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从欧几里得空间扩展到一般流形的岭回归自然内在化，利用黎曼最小子平方拟合、经验协方差和马氏距离。&lt;h4&gt;背景&lt;/h4&gt;在处理非线性数据时，传统的岭回归方法通常限于欧几里得空间内。&lt;h4&gt;目的&lt;/h4&gt;为了提高时间序列预测的准确性，特别是在非线性流形上的应用，如飓风路径及其风速预测。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于黎曼最小子平方拟合、经验协方差和马氏距离的岭回归方法。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效地应用于时间序列预测问题，并在实际案例中展示了较好的性能。&lt;h4&gt;结论&lt;/h4&gt;提出的流形上岭回归模型为非线性空间中的数据处理提供了新的思路，并在具体应用如飓风路径及其风速预测方面显示出潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;We propose a natural intrinsic extension of the ridge regression from Euclidean spaces to general manifolds, which relies on Riemannian least-squares fitting, empirical covariance, and Mahalanobis distance. We utilize it for time-series prediction and apply the approach to forecast hurricane tracks and their wind speeds.&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a natural intrinsic extension of the ridge regression fromEuclidean spaces to general manifolds, which relies on Riemannian least-squaresfitting, empirical covariance, and Mahalanobis distance. We utilize it fortime-series prediction and apply the approach to forecast hurricane tracks andtheir wind speeds.</description>
      <author>example@mail.com (Esfandiar Nava-Yazdani)</author>
      <guid isPermaLink="false">2411.18339v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Stealthy Multi-Task Adversarial Attacks</title>
      <link>http://arxiv.org/abs/2411.17936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种新颖的多任务攻击框架，该框架可以在不损害其他非关键任务性能的情况下，有针对性地破坏特定的关键任务。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络面临对抗性攻击的威胁，现有研究大多集中在单一任务或全目标场景上的攻击。在实际应用中（如自动驾驶），不同的任务具有不同的安全优先级，这需要更有针对性和隐蔽性的攻击方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够在多任务环境中选择性地破坏关键任务而不影响其他非关键任务的方法，并探索新的自动化搜索损失函数权重的策略来提高攻击效率。&lt;h4&gt;方法&lt;/h4&gt;该研究提出了一个利用多种算法注入不可察觉噪声到输入中的多任务隐蔽攻击框架，同时引入了一种自动化的搜索损失函数中权衡因子的方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，新提出的方法能够有效破坏目标任务的同时保持非目标任务的性能不变甚至提升，并且自动化搜索方法在提高效率方面与手动调参相当。&lt;h4&gt;结论&lt;/h4&gt;该研究开创了针对深度神经网络多任务环境中的特定任务隐蔽攻击的新途径，为未来相关领域提供了重要的参考价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Neural Networks exhibit inherent vulnerabilities to adversarial attacks,which can significantly compromise their outputs and reliability. Whileexisting research primarily focuses on attacking single-task scenarios orindiscriminately targeting all tasks in multi-task environments, we investigateselectively targeting one task while preserving performance in others within amulti-task framework. This approach is motivated by varying security prioritiesamong tasks in real-world applications, such as autonomous driving, wheremisinterpreting critical objects (e.g., signs, traffic lights) poses a greatersecurity risk than minor depth miscalculations. Consequently, attackers mayhope to target security-sensitive tasks while avoiding non-critical tasks frombeing compromised, thus evading being detected before compromising crucialfunctions. In this paper, we propose a method for the stealthy multi-taskattack framework that utilizes multiple algorithms to inject imperceptiblenoise into the input. This novel method demonstrates remarkable efficacy incompromising the target task while simultaneously maintaining or even enhancingperformance across non-targeted tasks - a criterion hitherto unexplored in thefield. Additionally, we introduce an automated approach for searching theweighting factors in the loss function, further enhancing attack efficiency.Experimental results validate our framework's ability to successfully attackthe target task while preserving the performance of non-targeted tasks. Theautomated loss function weight searching method demonstrates comparableefficacy to manual tuning, establishing a state-of-the-art multi-task attackframework.</description>
      <author>example@mail.com (Jiacheng Guo, Tianyun Zhang, Lei Li, Haochen Yang, Hongkai Yu, Minghai Qin)</author>
      <guid isPermaLink="false">2411.17936v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MAGiC-SLAM: Multi-Agent Gaussian Globally Consistent SLAM</title>
      <link>http://arxiv.org/abs/2411.16785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于刚性可变形3D高斯场景表示的SLAM系统（MAGiC-SLAM），该系统在多个方面改进了现有方法，包括速度、多代理一致性以及全局地图重建的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的具备新颖视图合成能力的SLAM系统主要用于计算机视觉领域中的增强现实、机器人和自动驾驶。然而，这些系统通常只能单个操作主体运行，并且存在实时性和准确性的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于3D高斯表示的方法来解决现有方法在速度、多代理一致性以及全局地图重建准确性方面的限制。&lt;h4&gt;方法&lt;/h4&gt;提出了使用刚性可变形的3D高斯场景表示，该方法可以显著提高系统效率。此外还引入了新的跟踪机制和地图合并方案，并将闭环检测集成到基于高斯的SLAM流程中。&lt;h4&gt;主要发现&lt;/h4&gt;MAGiC-SLAM在合成数据集和真实世界数据集中都表现出了比现有最佳技术更高的准确性和更快的速度。&lt;h4&gt;结论&lt;/h4&gt;新方法能够有效解决多代理场景下的实时定位与建图问题，提高系统效率的同时还能保证全局地图的一致性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous localization and mapping (SLAM) systems with novel viewsynthesis capabilities are widely used in computer vision, with applications inaugmented reality, robotics, and autonomous driving. However, existingapproaches are limited to single-agent operation. Recent work has addressedthis problem using a distributed neural scene representation. Unfortunately,existing methods are slow, cannot accurately render real-world data, arerestricted to two agents, and have limited tracking accuracy. In contrast, wepropose a rigidly deformable 3D Gaussian-based scene representation thatdramatically speeds up the system. However, improving tracking accuracy andreconstructing a globally consistent map from multiple agents remainschallenging due to trajectory drift and discrepancies across agents'observations. Therefore, we propose new tracking and map-merging mechanisms andintegrate loop closure in the Gaussian-based SLAM pipeline. We evaluateMAGiC-SLAM on synthetic and real-world datasets and find it more accurate andfaster than the state of the art.</description>
      <author>example@mail.com (Vladimir Yugay, Theo Gevers, Martin R. Oswald)</author>
      <guid isPermaLink="false">2411.16785v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>EEG-Based Analysis of Brain Responses in Multi-Modal Human-Robot Interaction: Modulating Engagement</title>
      <link>http://arxiv.org/abs/2411.18587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 7 figures. Submitted to IEEE TNSRE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的多模态人机交互方案，旨在通过结合视觉、运动、认知和听觉任务来增强用户在机器人康复中的参与度。研究利用EEG生物标志物比较了多模态协议与传统单一运动协议的效果。&lt;h4&gt;背景&lt;/h4&gt;物理人类-机器人的互动中用户的参与度、认知参与以及动机对于运动学习至关重要，尤其是在需要促进神经可塑性的康复场景中。然而，传统的机器人康复系统在维持用户参与方面面临挑战，导致治疗效果不稳定。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的多模态交互方案以增强用户在任务执行过程中的参与和积极性，从而改善康复疗效。&lt;h4&gt;方法&lt;/h4&gt;实验包括15名健康成人参与者完成两种类型的任务：传统单一运动任务以及新设计的多模态任务。利用EEG记录并分析了参与者的大脑活动变化来量化他们的参与度。&lt;h4&gt;主要发现&lt;/h4&gt;与单一运动协议相比，多模式协议在相对α功率等EEG生物标志物上显示出显著提高的用户参与度，并且在长时间内保持稳定的较高水平。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，结合视觉、认知和听觉功能的新方法能够有效提升用户的参与度，这为未来的康复干预提供了新的视角。这是首次通过客观神经响应证明全面机器人干预（包括运动、认知及听觉功能）的优势的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文的中文直译&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; User engagement, cognitive participation, and motivation during taskexecution in physical human-robot interaction are crucial for motor learning.These factors are especially important in contexts like robotic rehabilitation,where neuroplasticity is targeted. However, traditional robotic rehabilitationsystems often face challenges in maintaining user engagement, leading tounpredictable therapeutic outcomes. To address this issue, various techniques,such as assist-as-needed controllers, have been developed to prevent userslacking and encourage active participation. In this paper, we introduce a newdirection through a novel multi-modal robotic interaction designed to enhanceuser engagement by synergistically integrating visual, motor, cognitive, andauditory (speech recognition) tasks into a single, comprehensive activity. Toassess engagement quantitatively, we compared multiple electroencephalography(EEG) biomarkers between this multi-modal protocol and a traditional motor-onlyprotocol. Fifteen healthy adult participants completed 100 trials of each tasktype. Our findings revealed that EEG biomarkers, particularly relative alphapower, showed statistically significant improvements in engagement during themulti-modal task compared to the motor-only task. Moreover, while engagementdecreased over time in the motor-only task, the multi-modal protocol maintainedconsistent engagement, suggesting that users could remain engaged for longertherapy sessions. Our observations on neural responses during interactionindicate that the proposed multi-modal approach can effectively enhance userengagement, which is critical for improving outcomes. This is the first timethat objective neural response highlights the benefit of a comprehensiverobotic intervention combining motor, cognitive, and auditory functions inhealthy subjects.</description>
      <author>example@mail.com (Suzanne Oliver, Tomoko Kitago, Adam Buchwald, S. Farokh Atashzar)</author>
      <guid isPermaLink="false">2411.18587v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DROID-Splat: Combining end-to-end SLAM with 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2411.17660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种基于端到端跟踪器和最新3D高斯点阵渲染技术的SLAM系统（DroidSplat），该系统在常见SLAM基准测试中实现了最先进的追踪和渲染结果。&lt;h4&gt;背景&lt;/h4&gt;目前场景合成的进步使得单个SLAM系统可以通过优化超原语与渲染目标相结合成为可能，但其跟踪性能仍然落后于传统的ORB-SLAM以及端到端的SLAM系统。特别是对于单目视频数据集，还没有达到最佳的鲁棒性、速度和准确性之间的权衡。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于3D高斯点阵技术扩展的端到端追踪器框架，并实现了在常见消费者GPU上快速推理的能力。&lt;h4&gt;方法&lt;/h4&gt;采用多种现代SLAM系统的构建模块以并行方式运行，利用最近在单目深度预测和相机校准方面的进步来处理没有已知相机内部参数的真实世界数据。&lt;h4&gt;主要发现&lt;/h4&gt;提出的DroidSplat框架在常见SLAM基准测试中实现了最先进的追踪和渲染结果，并且即使在不具有已知相机内参的情况下也能实现强大的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了一种基于端到端跟踪器与3D高斯点阵技术结合的新型SLAM系统，它不仅具备强大的追踪能力还能够进行高质量的渲染。同时，通过并行处理和优化，使得这一框架能够在普通消费者级GPU上实现快速推理。&lt;h4&gt;翻译&lt;/h4&gt;最近在场景合成方面取得的进步使得仅基于超原语优化与渲染目标相结合的独立SLAM系统成为可能，但其跟踪性能仍落后于传统和端到端的SLAM系统。本文提出了一种结合端到端追踪器框架和基于最新3D高斯点阵技术扩展的方法，并实现了一个名为DroidSplat的新系统，在常见SLAM基准测试中取得了最先进的追踪与渲染结果。该方法实现了多种现代SLAM系统的构建模块并行运行，允许在普通消费者级GPU上快速推理，近期单目深度预测和相机校准的进步使我们的系统即使面对无已知相机内参的真实世界数据也能表现出色。代码可在https://github.com/ChenHoy/DROID-Splat获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chenhoy/droid-splat&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent progress in scene synthesis makes standalone SLAM systems purely basedon optimizing hyperprimitives with a Rendering objective possible\cite{monogs}.  However, the tracking performance still lacks behind traditional\cite{orbslam} and end-to-end SLAM systems \cite{droid}.  An optimal trade-off between robustness, speed and accuracy has not yet beenreached, especially for monocular video.  In this paper, we introduce a SLAM system based on an end-to-end Tracker andextend it with a Renderer based on recent 3D Gaussian Splatting techniques.  Our framework \textbf{DroidSplat} achieves both SotA tracking and renderingresults on common SLAM benchmarks.  We implemented multiple building blocks of modern SLAM systems to run inparallel, allowing for fast inference on common consumer GPU's.  Recent progress in monocular depth prediction and camera calibration allowsour system to achieve strong results even on in-the-wild data without knowncamera intrinsics.  Code will be available at \url{https://github.com/ChenHoy/DROID-Splat}.</description>
      <author>example@mail.com (Christian Homeyer, Leon Begiristain, Christoph Schnörr)</author>
      <guid isPermaLink="false">2411.17660v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>The MAGPI Survey: radial trends in star formation across different cosmological simulations in comparison with observations at $z \sim$ 0.3</title>
      <link>http://arxiv.org/abs/2411.17882v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 10 figures, submitted to MNRAS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在红移约为0.3时，星系中内因和外因而导致的恒星形成抑制机制，并使用MAGPI观测数据及EAGLE、Magneticum和IllustrisTNG宇宙学模拟进行了探讨。&lt;h4&gt;背景&lt;/h4&gt;现有恒星形成率与质量的关系以及不同环境中星系内恒星形成的规律有待深入研究，特别是在红移约为0.3的阶段。&lt;h4&gt;目的&lt;/h4&gt;利用SimSprint工具生成模拟观测以匹配MAGPI观测细节，并分析在该红移值下的恒星形成抑制机制及其背后的物理过程。&lt;h4&gt;方法&lt;/h4&gt;通过将模拟观测与实际观测数据对比来研究，包括使用SimSprint工具生成的宇宙学模拟中星系的假想观察结果，这些模拟考虑了检测/分辨率限制、点扩散函数和像元大小等细节。&lt;h4&gt;主要发现&lt;/h4&gt;{'全球恒星形成主序列(SFMS)斜率': 'MAGPI观测与三个模拟在整体SFMS斜率上有着良好的一致性，但在解析度更高的星系内部SFMS斜率上有1-2σ的差异。', '径向恒星形成趋势': '只有远离SFMS的星系显示出观测结果和模拟之间的一致性；这种一致性仅存在于大约为1.5至4倍有效半径范围内。在核心区域（即1.5倍有效半径内），不同AGN反馈假设导致了中心抑制程度的不同。', '环境对恒星形成的影响': '所有三个模拟都显示类似的因素依赖于SF的径向趋势，表明星系中心和卫星之间的差别：中心星系受到更多的内部和外部机制影响，在中心显示出更明显的恒星形成抑制；而卫星星系则在周围地区随着宿主暗物质晕质量增加显示出越来越大的压制。', '空间解析研究的重要性': '尽管全局性质可以匹配，但径向分布揭示了观测与模拟之间的差异及其背后物理过程的不同。'}&lt;h4&gt;结论&lt;/h4&gt;该研究表明，对于理解恒星形成抑制机制而言，开展空间解析的研究至关重要；仅凭全球属性无法完全反映实际的复杂性，而径向分析能够更深入地洞察恒星形成的内在规律。&lt;h4&gt;翻译&lt;/h4&gt;我们利用MAGPI观测数据以及EAGLE、Magneticum和IllustrisTNG宇宙学模拟研究了红移约为0.3时控制及抑制星系中恒星形成的各种内外机制。通过SimSprint工具生成的假想观测，匹配到了实际观测中的检测/分辨率限制，并且包括点扩散函数和像元大小等细节。我们发现MAGPI观测结果与所有三个模拟在SFMS斜率的整体上存在一致，但在解析度更高的SFMS径向趋势上有显著差异。同时，在远离SFMS的星系中找到了证据支持内向外抑制的现象。总体来说，模拟之间的一致性大约在1.5至4倍有效半径范围内；不同AGN反馈假设导致了中心抑制程度的不同。所有三个模拟都显示相似的因素依赖于SF径向趋势与环境的关系。中心星系和卫星星系表现出不同的SF压制模式：前者随着暗物质晕质量增加，中心区域的恒星形成受到更多抑制，而后者则在周围地区显示出更高的压制。这些结果展示了空间解析研究的重要性；尽管全局性质可以匹配，但径向分析揭示了观测与模拟之间的差异及其背后的物理过程的不同。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the internal and external mechanisms that regulate and quenchstar formation (SF) in galaxies at $z \sim 0.3$ using MAGPI observations andthe EAGLE, Magneticum, and IllustrisTNG cosmological simulations. Using SimSpinto generate mock observations of simulated galaxies, we matchdetection/resolution limits in star formation rates and stellar mass, alongwith MAGPI observational details including the average point spread functionand pixel scale. While we find a good agreement in the slope of the globalstar-forming main sequence (SFMS) between MAGPI observations and all threesimulations, the slope of the resolved SFMS does not agree within 1 $-$2$\sigma$. Furthermore, in radial SF trends, good agreement betweenobservations and simulations exists only for galaxies far below the SFMS, wherewe capture evidence for inside-out quenching. The simulations overall agreewith each other between $\sim1.5-4 \ R_{\rm e}$ but show varying centralsuppression within $R \sim 1.5 \ R_{\rm e}$ for galaxies on and below the SFMS,attributable to different AGN feedback prescriptions. All three simulationsshow similar dependencies of SF radial trends with environment. Centralgalaxies are subject to both internal and external mechanisms, showingincreased SF suppression in the centre with increasing halo mass, indicatingAGN feedback. Satellite galaxies display increasing suppression in theoutskirts as halo mass increases, indicative of environmental processes. Theseresults demonstrate the power of spatially resolved studies of galaxies; whileglobal properties align, radial profiles reveal discrepancies betweenobservations and simulations and their underlying physics.</description>
      <author>example@mail.com (Marcie Mun, Emily Wisnioski, Katherine E. Harborne, Claudia D. P. Lagos, Lucas M. Valenzuela, Rhea-Silvia Remus, J. Trevor Mendel, Andrew J. Battisti, Sara L. Ellison, Caroline Foster, Matias Bravo, Sarah Brough, Scott M. Croom, Tianmu Gao, Kathryn Grasha, Anshu Gupta, Yifan Mai, Anilkumar Mailvaganam, Eric G. M. Muller, Gauri Sharma, Sarah M. Sweet, Edward N. Taylor, Tayyaba Zafar)</author>
      <guid isPermaLink="false">2411.17882v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>LLM-ABBA: Understand time series via symbolic approximation</title>
      <link>http://arxiv.org/abs/2411.18506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种将适应性布朗桥符号聚合（ABBA）与大语言模型结合的方法（LLM-ABBA），用于时间序列的各种下游任务。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在时间序列分析中的成功已经得到证明，但如何利用隐藏于时间序列中的语义信息以及调整语言模型的嵌入空间仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来整合适应性布朗桥符号聚合（ABBA）与大语言模型，以解决上述问题，并将该方法应用于多种下游任务中。&lt;h4&gt;方法&lt;/h4&gt;LLM-ABBA利用了ABBA通过现有大型语言模型的标记有效地表示时间序列的特点。同时，在预测任务中引入了一个固定多边形链技巧来避免明显的漂移。&lt;h4&gt;主要发现&lt;/h4&gt;在UCR和三个医疗时间序列分类任务上，LLM-ABBA与最新的状态最佳（SOTA）相比表现出了竞争优势；在时间序列外推回归（TSER）基准测试中取得了新的SOTA。&lt;h4&gt;结论&lt;/h4&gt;该框架不仅展示了强大的预测能力，并且可以无缝扩展到其他的时间序列任务中。&lt;h4&gt;翻译&lt;/h4&gt;大型语言模型（LLMs）在处理时间序列方面已经证明了其成功，通过利用符号表示可以有效地弥合LLMs与时间序列之间的差距。然而，挑战在于如何利用隐藏于时间序列中的语义信息，并且根据这些信息调整LLMs的嵌入空间。适应性布朗桥基线符号聚合（ABBA）方法显示出了在使用现有LLM标记的同时保持显著的时间序列特征的有效性。本文介绍了一种称为LLM-ABBA的方法，将ABBA与大语言模型结合用于各种下游时间序列任务。通过符号化时间序列，LLM-ABBA在UCR和三个医疗时间序列分类任务上相比最新的SOTA表现出了竞争优势。同时，在预测任务中引入了一个固定多边形链技巧来显著缓解从符号到数值转换过程中的累积误差导致的明显漂移问题。在时间序列回归任务方面，LLM-ABBA取得了TSER基准测试的新SOTA。此外，该方法展示了与近期SOTA相比具有竞争力的预测能力。我们相信此框架可以无缝扩展至其他的时间序列任务中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The success of large language models (LLMs) for time series has beendemonstrated in previous work. Utilizing a symbolic time series representation,one can efficiently bridge the gap between LLMs and time series. However, theremaining challenge is to exploit the semantic information hidden in timeseries by using symbols or existing tokens of LLMs, while aligning theembedding space of LLMs according to the hidden information of time series. Thesymbolic time series approximation (STSA) method called adaptive Brownianbridge-based symbolic aggregation (ABBA) shows outstanding efficacy inpreserving salient time series features by modeling time series patterns interms of amplitude and period while using existing tokens of LLMs.  In this paper, we introduce a method, called LLM-ABBA, that integrates ABBAinto large language models for various downstream time series tasks. Bysymbolizing time series, LLM-ABBA compares favorably to the recentstate-of-the-art (SOTA) in UCR and three medical time series classificationtasks. Meanwhile, a fixed-polygonal chain trick in ABBA is introduced to\kc{avoid obvious drifting} during prediction tasks by significantly mitigatingthe effects of cumulative error arising from misused symbols during thetransition from symbols to numerical values. In time series regression tasks,LLM-ABBA achieves the new SOTA on Time Series Extrinsic Regression (TSER)benchmarks. LLM-ABBA also shows competitive prediction capability compared torecent SOTA time series prediction results. We believe this framework can alsoseamlessly extend to other time series tasks.</description>
      <author>example@mail.com (Erin Carson, Xinye Chen, Cheng Kang)</author>
      <guid isPermaLink="false">2411.18506v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>P4-NIDS: High-Performance Network Monitoring and Intrusion Detection in P4</title>
      <link>http://arxiv.org/abs/2411.17987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于P4的高性能、可扩展网络监控和入侵检测系统，旨在解决超大规模数据中心中的低延迟、高带宽需求以及对稳健基础设施的要求。&lt;h4&gt;背景&lt;/h4&gt;现有的最先进的解决方案通常依赖于传统的旁路监控和入侵检测技术，在大型高速网络中难以实现所需的低延迟和可伸缩性。这些传统方法无法有效应对太比特级网络的需求。&lt;h4&gt;目的&lt;/h4&gt;设计并实施一种基于P4的内嵌式解决方案，以提供更高效、可扩展的替代方案来满足高性能环境下的需求。&lt;h4&gt;方法&lt;/h4&gt;该论文采用了一种在P4硬件上的内嵌式监控和入侵检测系统。监控组件能够实时捕获扩展的NetFlow v9特性；而入侵检测系统则能在不牺牲性能的情况下实现高精度检测。&lt;h4&gt;主要发现&lt;/h4&gt;通过在真实世界P4硬件上进行评估，两个组件即使面对高达8百万包每秒（mpps）的数据量也能保持吞吐率影响几乎为零。其准确性和吞吐效率均超过了现有最先进的解决方案。&lt;h4&gt;结论&lt;/h4&gt;该论文展示了基于P4技术的网络监控和入侵检测系统在满足大规模高性能环境需求方面的优越性，尤其强调了其在低延迟、高带宽处理能力上的优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容已完全翻译成中文，并按上述分类进行了归纳总结。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a high-performance, scalable network monitoring andintrusion detection system (IDS) implemented in P4. The proposed solution isdesigned for high-performance environments such as cloud data centers, whereultra-low latency, high bandwidth, and resilient infrastructure are essential.Existing state-of-the-art (SoA) solutions, which rely on traditionalout-of-band monitoring and intrusion detection techniques, often struggle toachieve the necessary latency and scalability in large-scale, high-speednetworks. Unlike these approaches, our in-band solution provides a moreefficient, scalable alternative that meets the performance needs of Terabitnetworks. Our monitoring component captures extended NetFlow v9 features atwire speed, while the in-band IDS achieves high-accuracy detection withoutcompromising on performance. In evaluations on real-world P4 hardware, both theNetFlow monitoring and IDS components maintain negligible impact on throughput,even at traffic rates up to 8 million packets per second (mpps). Thisperformance surpasses SoA in terms of accuracy and throughput efficiency,ensuring that our solution meets the requirements of large-scale,high-performance environments.</description>
      <author>example@mail.com (Yaying Chen, Siamak Layeghy, Liam Daly Manocchio, Marius Portmann)</author>
      <guid isPermaLink="false">2411.17987v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DualCast: Disentangling Aperiodic Events from Traffic Series with a Dual-Branch Model</title>
      <link>http://arxiv.org/abs/2411.18286v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交通预测在运输系统的操作和优化中是一个重要的问题。最先进的解决方案通过最小化训练数据上的平均预测误差来训练机器学习模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种增强交通预测模型学习能力的框架DualCast，特别是在处理非周期性事件方面（如交通事故）的能力。&lt;h4&gt;方法&lt;/h4&gt;DualCast采用双分支架构，将交通信号分解为两种类型：一种反映内在的空间-时间模式，另一种则反映包括非周期性事件在内的外部环境因素。此外还提出了一种跨时间注意力机制来捕捉周期性和非周期性的高阶时空关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过与最近的交通预测模型相结合，DualCast在多个真实数据集上能够显著减少多达9.6%的预测误差。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了现有模型可能忽略关键优化机会（如交通事故）的问题，并提出了一个有效的方法来提高对非周期性事件的学习能力。&lt;h4&gt;翻译&lt;/h4&gt;交通预测是运输系统操作和优化中的一个重要问题。最先进的解决方案通过训练机器学习模型以最小化训练数据上的平均预测误差来实现这一点。然而，这些经过训练的模型往往在其预测结果中更偏向于处理周期性的而非非周期性的事件，因为周期性事件在训练数据中更为常见。尽管提供了重要的优化机会，但如交通事故等非周期性事件可能会被现有的模型忽视。为解决这一问题，我们提出了DualCast——这是一种旨在增强交通预测模型学习能力的框架，特别是针对非周期性事件的学习。DualCast采用了双分支架构，将交通信号分解成反映内在空间-时间模式和外部环境上下文（包括非周期性事件）两种类型。此外，我们还提出了一种跨时间注意力机制来捕捉来自这两种模式中的高阶时空关系。DualCast具有广泛的适用性；将其与最近的交通预测模型相结合，在多个真实数据集中能够减少多达9.6%的预测误差。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic forecasting is an important problem in the operation and optimisationof transportation systems. State-of-the-art solutions train machine learningmodels by minimising the mean forecasting errors on the training data. Thetrained models often favour periodic events instead of aperiodic ones in theirprediction results, as periodic events often prevail in the training data.While offering critical optimisation opportunities, aperiodic events such astraffic incidents may be missed by the existing models. To address this issue,we propose DualCast -- a model framework to enhance the learning capability oftraffic forecasting models, especially for aperiodic events. DualCast takes adual-branch architecture, to disentangle traffic signals into two types, onereflecting intrinsic {spatial-temporal} patterns and the other reflectingexternal environment contexts including aperiodic events. We further propose across-time attention mechanism, to capture high-order spatial-temporalrelationships from both periodic and aperiodic patterns. DualCast is versatile.We integrate it with recent traffic forecasting models, consistently reducingtheir forecasting errors by up to 9.6% on multiple real datasets.</description>
      <author>example@mail.com (Xinyu Su, Feng Liu, Yanchuan Chang, Egemen Tanin, Majid Sarvi, Jianzhong Qi)</author>
      <guid isPermaLink="false">2411.18286v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>HI-SLAM2: Geometry-Aware Gaussian SLAM for Fast Monocular Scene Reconstruction</title>
      <link>http://arxiv.org/abs/2411.17982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review process&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种基于几何感知的高斯SLAM系统HI-SLAM2，该系统仅通过RGB输入实现快速且准确的单目场景重建。&lt;h4&gt;背景&lt;/h4&gt;现有的神经网络SLAM或基于3DGS的方法在渲染质量和几何准确性之间存在权衡。当前研究展示了使用单一RGB输入即可同时获得高质量和高精度。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合容易获取的单目先验知识与学习型稠密SLAM，提高几何估计能力，并通过使用3D高斯平铺作为核心地图表示来有效建模场景的方法。&lt;h4&gt;方法&lt;/h4&gt;在闭环时，该方法通过高效的姿态图捆扎调整和即时地图更新确保全局一致性；此外还引入了一种基于网格的尺度对齐策略以保持先前深度中的改进比例一致性和更详细的深度信息。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在Replica、ScanNet及ScanNet++数据集上，该方法在重建质量和渲染质量方面均显著优于现有神经网络SLAM方法，并且甚至超过了基于RGB-D的方法。&lt;h4&gt;结论&lt;/h4&gt;通过结合单目先验和学习型稠密SLAM以及3D高斯表示，实现了一种同时具备高质量渲染和精确几何信息的高效场景建模技术。&lt;h4&gt;翻译&lt;/h4&gt;我们提出HI-SLAM2，这是一个基于几何感知的高斯SLAM系统，它仅使用RGB输入就能达到快速且准确单目场景重建的目的。现有神经网络SLAM或3DGS基础的SLAM方法往往要在渲染质量和几何精度之间做出权衡。我们的研究展示了两者可以通过单一RGB输入同时实现。我们通过结合容易获取的单目先验知识与基于学习的稠密SLAM，增强几何估计能力，并采用3D高斯作为核心地图表示来有效建模场景。在闭环时，该方法确保全局一致性，通过高效的姿态图捆扎调整和即时地图更新，在关键帧更新基础上显式变形3D高斯单位。此外，我们还引入了一种基于网格的尺度对齐策略以保持先前深度中的改进比例一致性和更详细的深度信息。通过广泛的实验在Replica、ScanNet及ScanNet++数据集上证明了相对于现有神经网络SLAM方法以及RGB-D基础的方法，在重建和渲染质量方面均取得了显著提升。项目页面和源代码将在 https://hi-slam2.github.io/ 上公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present HI-SLAM2, a geometry-aware Gaussian SLAM system that achieves fastand accurate monocular scene reconstruction using only RGB input. ExistingNeural SLAM or 3DGS-based SLAM methods often trade off between renderingquality and geometry accuracy, our research demonstrates that both can beachieved simultaneously with RGB input alone. The key idea of our approach isto enhance the ability for geometry estimation by combining easy-to-obtainmonocular priors with learning-based dense SLAM, and then using 3D Gaussiansplatting as our core map representation to efficiently model the scene. Uponloop closure, our method ensures on-the-fly global consistency throughefficient pose graph bundle adjustment and instant map updates by explicitlydeforming the 3D Gaussian units based on anchored keyframe updates.Furthermore, we introduce a grid-based scale alignment strategy to maintainimproved scale consistency in prior depths for finer depth details. Throughextensive experiments on Replica, ScanNet, and ScanNet++, we demonstratesignificant improvements over existing Neural SLAM methods and even surpassRGB-D-based methods in both reconstruction and rendering quality. The projectpage and source code will be made available at https://hi-slam2.github.io/.</description>
      <author>example@mail.com (Wei Zhang, Qing Cheng, David Skuddis, Niclas Zeller, Daniel Cremers, Norbert Haala)</author>
      <guid isPermaLink="false">2411.17982v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Variability of hot sub-luminous stars and binaries: Machine learning analysis of Gaia DR3 multi-epoch photometry</title>
      <link>http://arxiv.org/abs/2411.18609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Resubmitted to Astronomy &amp; Astrophyiscs, after having taken into
  account the positive minor referee comments; 11 pages, 9 figures, 1 table, 1
  appendix (3 additional figures, 10 additional tables)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究利用先进的聚类算法工具，通过综合使用Gaia DR3多时域光度测量和TESS观测数据，对1576个热次矮变星候选体的可变性进行了深入调查。&lt;h4&gt;背景&lt;/h4&gt;热次矮星代表一类处于极水平分支上的剥除演化红巨星。由于它们受到脉动或双星相互作用的影响表现出广泛的可变性，揭示其内在和外在可变性对于理解形成这些恒星的基本物理过程至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过利用t-SNE和UMAP等降维算法来促进不同种类热次矮变星和激变变星在大数据集中的识别与分类，以期为更有效全面地分析基于地面和空间观测的恒星可变性提供新方法。&lt;h4&gt;方法&lt;/h4&gt;采用Gaia时序统计表，并引入额外统计特征提高算法性能。利用Gaia和TESS光曲线结合Gaia单光源数据进行聚类分析。&lt;h4&gt;主要发现&lt;/h4&gt;发现了85个新的热次矮变星以及108个仅基于Gaia光曲线的新变量，包括反射效应系统、HW Vir椭圆变化星和高振幅脉动变星。同时，还发现了与额外152个激变变星候选体不同的140个已知的激变变星。&lt;h4&gt;结论&lt;/h4&gt;本研究为基于地面和空间观测的恒星可变性分析开辟了新道路，并为进一步应用机器学习对大量调查中的变量候选者进行分类提供了可能性。&lt;h4&gt;翻译&lt;/h4&gt;热次矮恒星代表一类剥除演化红巨星，位于极水平分支上。由于这些恒星表现出广泛的脉动或双星相互作用导致的可变性，理解其内在和外在可变性对于揭示它们形成背后的物理过程至关重要。在赫罗图中，这些恒星与激变变星等交互双星重叠。通过运用先进的聚类算法工具，我们对1,576个热次矮变量候选体的变异进行了调查，利用了Gaia DR3多时域光度测量和TESS观测的综合数据。本研究提出了一种新方法，即采用t-SNE和UMAP降维算法来促进不同种类热次矮变星和激变变星在大数据集中的识别与分类。除了使用Gaia时间序列统计表外，我们还采用了额外的统计特征以提高算法性能。聚类结果发现了85个新的热次矮变量以及108个仅基于Gaia光曲线的新变量，包括反射效应系统、HW Vir椭圆变化星和高振幅脉动变星。此外，在二维功能空间中，我们还辨认了140个已知的激变变星，与额外152个激变变星候选体不同。本研究为更有效全面地分析基于地面和空间观测的恒星可变性开辟了一条新道路，并为进一步应用机器学习对大量调查中的变量候选者进行分类提供了可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hot sub-luminous stars represent a population of stripped and evolved redgiants located at the Extreme Horizontal Branch (EHB). Since they exhibit awide range of variability due to pulsations or binary interactions, unveilingtheir intrinsic and extrinsic variability is crucial for understanding thephysical processes responsible for their formation. In the Hertzsprung-Russelldiagram, they overlap with interacting binaries such as Cataclysmic Variables(CVs). By leveraging cutting-edge clustering algorithm tools, we investigatethe variability of 1,576 hot subdwarf variable candidates using comprehensivedata from Gaia DR3 multi-epoch photometry and Transiting Exoplanet SurveySatellite (TESS) observations. We present a novel approach that utilises thet-distributed stochastic neighbor embedding (t-SNE) and the Uniform ManifoldApproximation and Projection (UMAP) dimensionality reduction algorithms tofacilitate the identification and classification of different populations ofvariable hot subdwarfs and Cataclysmic Variables in a large dataset. Inaddition to the Gaia time-series statistics table, we adopt extra statisticalfeatures that enhance the performance of the algorithms. The clustering resultslead to the identification of 85 new hot subdwarf variables based on Gaia andTESS lightcurves and 108 new variables based on Gaia lightcurves alone,including reflection-effect systems, HW Vir, ellipsoidal variables, andhigh-amplitude pulsating variables. A significant number of known CataclysmicVariables (140) distinctively cluster in the 2-D feature space among anadditional 152 objects that we consider new Cataclysmic Variable candidates.This study paves the way for more efficient and comprehensive analyses ofstellar variability from both ground and space-based observations, as well asthe application of machine learning classifications of variable candidates inlarge surveys.</description>
      <author>example@mail.com (P. Ranaivomanana, M. Uzundag, C. Johnston, P. J. Groot, T. Kupfer, C. Aerts)</author>
      <guid isPermaLink="false">2411.18609v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MONOPOLY: Learning to Price Public Facilities for Revaluing Private Properties with Large-Scale Urban Data</title>
      <link>http://arxiv.org/abs/2411.18085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CIKM'19&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文介绍了一个名为'Monopoly'的项目，该项目通过学习公共设施的价格来重新评估私人房产的价值。&lt;h4&gt;背景&lt;/h4&gt;私有财产的价值评估是一个具有挑战性但又引人关注的问题。现有的方法依赖于房产属性、周边人口统计和公共服务等因素定价，但是这些因素的确切价值往往不清楚。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于大规模城市数据的分布式方法来重新评估私人房地产的价值。&lt;h4&gt;方法&lt;/h4&gt;将大量兴趣点（POIs）组织成无向加权图，并根据已知房价并行估计包括周边公共设施在内的多种因素价格，然后通过预测误差迭代更新公共设施和私有房产的价格。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多个主流方法中表现出显著优势。进一步的讨论表明，这种方法在商业智能和城市计算跨学科领域具有创新性应用。&lt;h4&gt;结论&lt;/h4&gt;这种评估私人房地产价值的方法不仅对大量用户的投资决策有益，而且对于政府的城市规划和税收政策也非常重要。&lt;h4&gt;翻译&lt;/h4&gt;私有财产的价值评估是一项既具挑战又广受关注的任务。一个长期被人们讨论的问题是“我的房子值多少钱？”为了回答这个问题，大多数经验丰富的机构会根据房产的属性以及周围的人口统计和公共服务设施来定价这些房产。然而，没有人确切知道这些因素的价格，尤其是公共设施的价值可能会帮助评估私人财产价值。在这篇论文中，我们介绍了我们的新项目'Monopoly'（取名自一款经典棋盘游戏），提出了一种分布式方法重新评估私人房地产价值，通过学习百度地图积累的大规模城市数据中的公共服务设施价格来实现这一目标。具体来说，我们的方法将许多兴趣点组织成无向加权图，并根据已知房价并行估计包括周围公共设施在内的多种因素的价格，然后根据预测误差迭代更新这些公共设施和私有房产的价格。我们在中国多个大都市的大量城市数据上进行了广泛的实验。结果显示，我们的方法在几种主流方法中表现出显著优势。更深入讨论得出的见解表明，'Monopoly'是商业智能和城市计算跨学科领域的创新应用，并且对数百万用户的投资以及政府的城市规划和税收政策都有益处。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The value assessment of private properties is an attractive but challengingtask which is widely concerned by a majority of people around the world. Aprolonged topic among us is ``\textit{how much is my house worth?}''. To answerthis question, most experienced agencies would like to price a property giventhe factors of its attributes as well as the demographics and the publicfacilities around it. However, no one knows the exact prices of these factors,especially the values of public facilities which may help assess privateproperties. In this paper, we introduce our newly launched project ``Monopoly''(named after a classic board game) in which we propose a distributed approachfor revaluing private properties by learning to price public facilities (suchas hospitals etc.) with the large-scale urban data we have accumulated viaBaidu Maps. To be specific, our method organizes many points of interest (POIs)into an undirected weighted graph and formulates multiple factors including thevirtual prices of surrounding public facilities as adaptive variables toparallelly estimate the housing prices we know. Then the prices of both publicfacilities and private properties can be iteratively updated according to theloss of prediction until convergence. We have conducted extensive experimentswith the large-scale urban data of several metropolises in China. Results showthat our approach outperforms several mainstream methods with significantmargins. Further insights from more in-depth discussions demonstrate that the``Monopoly'' is an innovative application in the interdisciplinary field ofbusiness intelligence and urban computing, and it will be beneficial to tens ofmillions of our users for investments and to the governments for urban planningas well as taxation.</description>
      <author>example@mail.com (Miao Fan, Jizhou Huang, An Zhuo, Ying Li, Ping Li, Haifeng Wang)</author>
      <guid isPermaLink="false">2411.18085v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Biomolecular Analysis of Soil Samples and Rock Imagery for Tracing Evidence of Life Using a Mobile Robot</title>
      <link>http://arxiv.org/abs/2411.18594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Key Words : Mars, Rover, Phoenix, Biosignatures, Biomolecular
  Analysis, Microscopy, Spectroscopy, Sampling, Astrobiology&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;研究旨在通过改进凤凰号火星车以增强其检测生物标志物的能力。&lt;h4&gt;背景&lt;/h4&gt;寻找火星上过去生命的证据面临巨大挑战，现有设备如显微镜和光谱仪存在分辨率低、检测范围窄及不便于携带等问题。&lt;h4&gt;目的&lt;/h4&gt;提出对凤凰号火星车的改良措施来扩大其在火星表面识别生物特征的能力。&lt;h4&gt;方法&lt;/h4&gt;采用先进的数字显微镜与光谱仪，并强化机械组件，提升设备的操作性和地下采样能力。&lt;h4&gt;主要发现&lt;/h4&gt;改进后的凤凰号能适应多样地质环境并获取样本进行生物分子分析。研究表明该系统具有广泛的检测生物标记物和生物特征的能力。&lt;h4&gt;结论&lt;/h4&gt;所展示的生物分子仪器及混合分析方法为未来火星上的天体生物学任务提供了巨大的潜力。&lt;h4&gt;翻译&lt;/h4&gt;在寻找火星上过去生命证据的过程中，现有的显微镜和光谱仪存在技术限制。本研究通过改进凤凰号火星车来解决这些问题，并展示了其检测更广泛生物特征的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The search for evidence of past life on Mars presents a tremendous challengethat requires the usage of very advanced robotic technologies to overcome it.Current digital microscopic imagers and spectrometers used for astrobiologicalexamination suffer from limitations such as insufficient resolution, narrowdetection range, and lack of portability. To overcome these challenges, thisresearch study presents modifications to the Phoenix rover to expand itscapability for detecting biosignatures on Mars. This paper examines themodifications implemented on the Phoenix rover to enhance its capability todetect a broader spectrum of biosignatures. One of the notable improvementscomprises the integration of advanced digital microscopic imagers andspectrometers, enabling high-resolution examination of soil samples.Additionally, the mechanical components of the device have been reinforced toenhance maneuverability and optimize subsurface sampling capabilities.Empirical investigations have demonstrated that Phoenix has the capability tonavigate diverse geological environments and procure samples for the purpose ofbiomolecular analysis. The biomolecular instrumentation and hybrid analyticalmethods showcased in this study demonstrate considerable potential for futureastrobiology missions on Mars. The potential for enhancing the system lies inthe possibility of broadening the range of detectable biomarkers andbiosignatures.</description>
      <author>example@mail.com (Shah Md Ahasan Siddique, Ragib Tahshin Rinath, Shakil Mosharrof, Syed Tanjib Mahmud, Sakib Ahmed)</author>
      <guid isPermaLink="false">2411.18594v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>ORB-SLAM3AB: Augmenting ORB-SLAM3 to Counteract Bumps with Optical Flow Inter-frame Matching</title>
      <link>http://arxiv.org/abs/2411.18174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种改进的ORB-SLAM3算法，用于应对崎岖道路表面的应用场景。&lt;h4&gt;背景&lt;/h4&gt;现有的ORB-SLAM3在处理崎岖路面时存在帧匹配丢失的问题，并且缺少适用于多传感器数据集的道路环境。&lt;h4&gt;目的&lt;/h4&gt;通过优化ORB-SLAM3的帧间匹配逻辑并引入自适应匹配机制，提高算法在复杂地形中的鲁棒性和精度。&lt;h4&gt;方法&lt;/h4&gt;结合特征点匹配和光学流技术，改进后的算法能够在不同路面条件下灵活调整依赖于特征点或光学流的方法。此外还采集了适用于崎岖道路环境的LiDAR和相机数据集。&lt;h4&gt;主要发现&lt;/h4&gt;经过绝对轨迹误差（ATE）和相对姿态误差（RPE）指标分析证明，ORB-SLAM3AB在崎岖路面上的表现优于仅基于激光或视觉数据的先进开源SLAM算法。&lt;h4&gt;结论&lt;/h4&gt;改进后的ORB-SLAM3AB算法具有更好的鲁棒性和精度，在复杂地形中能更有效地执行同时定位与地图构建任务。&lt;h4&gt;翻译&lt;/h4&gt;该论文提出了对ORB-SLAM3算法的一种增强版本，特别针对崎岖路面的应用场景。通过结合特征点匹配和光学流方法，并优化了帧间匹配逻辑，解决了在不平坦路面上的帧匹配丢失问题。为了防止精度下降，引入了一种自适应匹配机制，在振动较大时增加对光学流点的依赖性，从而有效保持SLAM系统的精度。鉴于适用于崎岖道路或减速带环境的多传感器数据集稀缺，论文作者收集了LiDAR和相机数据，并将改进后的算法ORB-SLAM3AB与若干基于激光或视觉数据的先进开源SLAM算法进行了对比测试。通过绝对轨迹误差（ATE）和相对姿态误差（RPE）指标分析得出结论：在崎岖路面条件下，ORB-SLAM3AB展现出更高的鲁棒性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an enhancement to the ORB-SLAM3 algorithm, tailored forapplications on rugged road surfaces. Our improved algorithm adeptly combinesfeature point matching with optical flow methods, capitalizing on the highrobustness of optical flow in complex terrains and the high precision offeature points on smooth surfaces. By refining the inter-frame matching logicof ORB-SLAM3, we have addressed the issue of frame matching loss on unevenroads. To prevent a decrease in accuracy, an adaptive matching mechanism hasbeen incorporated, which increases the reliance on optical flow points duringperiods of high vibration, thereby effectively maintaining SLAM precision.Furthermore, due to the scarcity of multi-sensor datasets suitable forenvironments with bumpy roads or speed bumps, we have collected LiDAR andcamera data from such settings. Our enhanced algorithm, ORB-SLAM3AB, was thenbenchmarked against several advanced open-source SLAM algorithms that relysolely on laser or visual data. Through the analysis of Absolute TrajectoryError (ATE) and Relative Pose Error (RPE) metrics, our results demonstrate thatORB-SLAM3AB achieves superior robustness and accuracy on rugged road surfaces.</description>
      <author>example@mail.com (Yangrui Dong, Weisheng Gong, Qingyong Li, Kaijie Su, Chen He, Z. Jane Wang)</author>
      <guid isPermaLink="false">2411.18174v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Robust Offline Reinforcement Learning with Linearly Structured $f$-Divergence Regularization</title>
      <link>http://arxiv.org/abs/2411.18612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  52 pages, 3 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的$d$-rectangular线性鲁棒正则化马尔可夫决策过程（$d$-RRMDP）框架，用于解决强化学习中由于动态变化而导致的问题。该方法通过在线性潜在结构内同时引入转移核和正则化的线性特征，提供了一种在离线设置下从预收集数据集中学习鲁棒策略的方法。&lt;h4&gt;背景&lt;/h4&gt;分布鲁棒马尔可夫决策过程（DRMDP）是一种用于处理强化学习中动态变化问题的流行框架。然而，解决其对偶优化或acles存在问题，并且现有方法通常过于保守，因为它们考虑了不现实的状态转移。&lt;h4&gt;目的&lt;/h4&gt;提出$d$-RRMDP以克服现有鲁棒正则化马尔可夫决策过程（RRMDP）的方法论局限性，并提供一个更有效的计算框架来学习稳健策略。&lt;h4&gt;方法&lt;/h4&gt;通过引入线性潜在结构到转移核和正则化的形式，提出了鲁棒正则化悲观价值迭代（R2PVI）算法家族。该算法使用$f$-散度作为过渡内核的正则项，并利用线性函数近似技术进行计算。&lt;h4&gt;主要发现&lt;/h4&gt;对于采用R2PVI策略时次优差距的存在实例依赖上限，这些界限取决于数据集如何覆盖由最优鲁棒政策访问的状态-动作空间。此外，信息理论下界表明该术语在$d$-RRMDPs中是基本的。&lt;h4&gt;结论&lt;/h4&gt;数值实验验证了R2PVI方法可以有效地学习出稳健策略，并且比针对受限DRMDPs的方法更具计算效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本的中文翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Distributionally Robust Markov Decision Process (DRMDP) is a popularframework for addressing dynamics shift in reinforcement learning by learningpolicies robust to the worst-case transition dynamics within a constrained set.However, solving its dual optimization oracle poses significant challenges,limiting theoretical analysis and computational efficiency. The recentlyproposed Robust Regularized Markov Decision Process (RRMDP) replaces theuncertainty set constraint with a regularization term on the value function,offering improved scalability and theoretical insights. Yet, existing RRMDPmethods rely on unstructured regularization, often leading to overlyconservative policies by considering transitions that are unrealistic. Toaddress these issues, we propose a novel framework, the $d$-rectangular linearrobust regularized Markov decision process ($d$-RRMDP), which introduces alinear latent structure into both transition kernels and regularization. Forthe offline RL setting, where an agent learns robust policies from apre-collected dataset in the nominal environment, we develop a family ofalgorithms, Robust Regularized Pessimistic Value Iteration (R2PVI), employinglinear function approximation and $f$-divergence based regularization terms ontransition kernels. We provide instance-dependent upper bounds on thesuboptimality gap of R2PVI policies, showing these bounds depend on how wellthe dataset covers state-action spaces visited by the optimal robust policyunder robustly admissible transitions. This term is further shown to befundamental to $d$-RRMDPs via information-theoretic lower bounds. Finally,numerical experiments validate that R2PVI learns robust policies and iscomputationally more efficient than methods for constrained DRMDPs.</description>
      <author>example@mail.com (Cheng Tang, Zhishuai Liu, Pan Xu)</author>
      <guid isPermaLink="false">2411.18612v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>RED: Effective Trajectory Representation Learning with Comprehensive Information</title>
      <link>http://arxiv.org/abs/2411.15096v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by VLDB2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文提出了RED框架，一种用于轨迹表示学习的自监督学习框架。&lt;h4&gt;背景&lt;/h4&gt;现有轨迹表示学习方法在下游任务中的表现通常不够准确，原因在于未能充分利用轨迹所包含的信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效利用多种类型轨迹信息的自我监督学习框架（RED）。&lt;h4&gt;方法&lt;/h4&gt;{'模型结构': '采用Transformer作为基础模型，并通过遮罩自编码器训练方式处理轨迹中的构成路径；', '关键路径保留策略': '在道路感知掩码策略中，保持轨迹中关键路径以保留重要信息；', '多维度嵌入方案': '采用了空间-时间-用户联合嵌入方案来综合编码信息；', '双目标任务学习': 'Transformer编码器预测轨迹中的下一个片段，而解码器重构整个轨迹。'}&lt;h4&gt;主要发现&lt;/h4&gt;与现有的9种最先进的轨迹表示学习方法相比，在4个下游任务上使用3个真实世界数据集测试RED框架，发现在大多数情况下RED可以比最佳基线模型提高超过5%的准确性。&lt;h4&gt;结论&lt;/h4&gt;通过综合运用多种信息和改进注意力机制，RED能显著提升轨迹表示学习的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory representation learning (TRL) maps trajectories to vectors thatcan then be used for various downstream tasks, including trajectory similaritycomputation, trajectory classification, and travel-time estimation. However,existing TRL methods often produce vectors that, when used in downstream tasks,yield insufficiently accurate results. A key reason is that they fail toutilize the comprehensive information encompassed by trajectories. We propose aself-supervised TRL framework, called RED, which effectively exploits multipletypes of trajectory information. Overall, RED adopts the Transformer as thebackbone model and masks the constituting paths in trajectories to train amasked autoencoder (MAE). In particular, RED considers the moving patterns oftrajectories by employing a Road-aware masking strategy} that retains key pathsof trajectories during masking, thereby preserving crucial information of thetrajectories. RED also adopts a spatial-temporal-user joint Embedding scheme toencode comprehensive information when preparing the trajectories as modelinputs. To conduct training, RED adopts Dual-objective task learning}: theTransformer encoder predicts the next segment in a trajectory, and theTransformer decoder reconstructs the entire trajectory. RED also considers thespatial-temporal correlations of trajectories by modifying the attentionmechanism of the Transformer. We compare RED with 9 state-of-the-art TRLmethods for 4 downstream tasks on 3 real-world datasets, finding that RED canusually improve the accuracy of the best-performing baseline by over 5%.</description>
      <author>example@mail.com (Silin Zhou, Shuo Shang, Lisi Chen, Christian S. Jensen, Panos Kalnis)</author>
      <guid isPermaLink="false">2411.15096v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>BIP3D: Bridging 2D Images and 3D Perception for Embodied Intelligence</title>
      <link>http://arxiv.org/abs/2411.14869v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一种新的基于图像的3D感知模型BIP3D，该模型利用了表达性的图像特征和显式的3D位置编码来克服点云方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;目前的三维感知算法主要依赖于点云数据，尽管提供了精确的几何信息，但由于固有的稀疏性和噪声问题，限制了感知性能。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于图像的方法，可以提高三维环境的理解能力，并在多视图和多模态特征融合方面进行改进。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的模型BIP3D，该模型利用预训练的2D视觉基础模型来增强语义理解，并引入空间增强模块以改善空间理解。这些模块共同使BIP3D能够实现跨视角、跨模态的特征融合和端到端的三维感知。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与当前最新的方法相比，在EmbodiedScan基准测试中，BIP3D在3D检测任务上提高了5.69%，在3D视觉定位任务上提高了15.25%。&lt;h4&gt;结论&lt;/h4&gt;提出的BIP3D模型成功地利用图像特征和空间编码来克服传统点云方法的限制，并取得了比现有技术更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;在具身智能系统中，关键组成部分是三维感知算法，它使代理能够理解其周围环境。先前的方法主要依赖于点云数据，虽然提供了精确的几何信息，但由于固有的稀疏性、噪声和数据稀缺性限制了感知性能。在这项工作中，我们介绍了一种新的基于图像的3D感知模型BIP3D，该模型利用表达性的图像特征和明确的3D位置编码来克服以点为中心的方法的局限性。具体来说，我们使用预训练的2D视觉基础模型来增强语义理解，并引入空间增强模块来改善空间理解。这些模块共同使BIP3D能够实现多视图、多模态特征融合和端到端三维感知。在我们的实验中，BIP3D在EmbodiedScan基准测试中的3D检测任务上优于当前最先进的方法，提高了5.69%，并且在3D视觉定位任务上提高了15.25%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In embodied intelligence systems, a key component is 3D perception algorithm,which enables agents to understand their surrounding environments. Previousalgorithms primarily rely on point cloud, which, despite offering precisegeometric information, still constrain perception performance due to inherentsparsity, noise, and data scarcity. In this work, we introduce a novelimage-centric 3D perception model, BIP3D, which leverages expressive imagefeatures with explicit 3D position encoding to overcome the limitations ofpoint-centric methods. Specifically, we leverage pre-trained 2D visionfoundation models to enhance semantic understanding, and introduce a spatialenhancer module to improve spatial understanding. Together, these modulesenable BIP3D to achieve multi-view, multi-modal feature fusion and end-to-end3D perception. In our experiments, BIP3D outperforms current state-of-the-artresults on the EmbodiedScan benchmark, achieving improvements of 5.69% in the3D detection task and 15.25% in the 3D visual grounding task.</description>
      <author>example@mail.com (Xuewu Lin, Tianwei Lin, Lichao Huang, Hongyu Xie, Zhizhong Su)</author>
      <guid isPermaLink="false">2411.14869v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>OphCLIP: Hierarchical Retrieval-Augmented Learning for Ophthalmic Surgical Video-Language Pretraining</title>
      <link>http://arxiv.org/abs/2411.15421v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;该论文提出了OphCLIP框架，用于眼科手术工作流程的理解。此框架结合了一个大规模的视频文本数据集（超过375K结构化的视频-文本对），并通过检索增强预训练来提高表示学习。&lt;h4&gt;背景&lt;/h4&gt;外科实践包括复杂的视觉解释、程序技能和高级医学知识，这使得基于视觉的语言预训练特别具有挑战性，因为它的复杂性和标注数据的有限可用性。为了填补这一空白，作者提出了一种专门针对眼科手术工作流程理解设计的框架。&lt;h4&gt;目的&lt;/h4&gt;通过开发OphCLIP框架来解决外科手术中语言和视觉信息处理的问题，并提高其在多种任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于检索增强预训练的层次化框架（OphCLIP），利用大规模静默手术视频并自动提取语义相关的数据，以改进叙事视频的表示学习。此外，该框架还构建了一个包含超过375K结构化的视频-文本对的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验表明，提出的OphCLIP模型在11个不同数据集上进行手术阶段识别和多器械识别任务时表现出卓越的性能。&lt;h4&gt;结论&lt;/h4&gt;OphCLIP框架展示了其强大的泛化能力和优于现有方法的表现，在眼科手术视频理解方面具有重要的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;外科实践涉及复杂的视觉解释、程序技巧以及高级医学知识，这使得基于视图的语言预训练（VLP）由于这种复杂性以及标注数据的有限可用性而变得特别具有挑战性。为了应对这一差距，我们提出了OphCLIP，这是一个专门为眼科手术工作流程理解设计的层次化检索增强视觉语言预训练框架。该框架利用了由我们构建的大规模且全面的数据集OphVL，其中包含超过375K个分层结构化的视频-文本对，并具有成千上万种不同的属性组合（如手术、阶段/操作/行动、器械、药物以及更高级的方面如眼病原因、外科目标及术后恢复建议等）。这些层次化的视频-文本对应关系使OphCLIP能够学习精细和长期视觉表示，通过将简短视频片段与详细的叙述描述对齐并利用结构化标题与完整视频匹配，分别捕捉复杂的手术细节和高层次的程序见解。此外，我们的OphCLIP还设计了一个检索增强预训练框架以利用尚未充分探索的大规模静默外科手术视频，并自动提取语义相关的内容来提升叙事视频的表示学习能力。在针对阶段识别和多器械识别任务的11个数据集上的评估表明了OphCLIP强大的泛化能力和卓越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical practice involves complex visual interpretation, procedural skills,and advanced medical knowledge, making surgical vision-language pretraining(VLP) particularly challenging due to this complexity and the limitedavailability of annotated data. To address the gap, we propose OphCLIP, ahierarchical retrieval-augmented vision-language pretraining frameworkspecifically designed for ophthalmic surgical workflow understanding. OphCLIPleverages the OphVL dataset we constructed, a large-scale and comprehensivecollection of over 375K hierarchically structured video-text pairs with tens ofthousands of different combinations of attributes (surgeries,phases/operations/actions, instruments, medications, as well as more advancedaspects like the causes of eye diseases, surgical objectives, and postoperativerecovery recommendations, etc). These hierarchical video-text correspondencesenable OphCLIP to learn both fine-grained and long-term visual representationsby aligning short video clips with detailed narrative descriptions and fullvideos with structured titles, capturing intricate surgical details andhigh-level procedural insights, respectively. Our OphCLIP also designs aretrieval-augmented pretraining framework to leverage the underexploredlarge-scale silent surgical procedure videos, automatically retrievingsemantically relevant content to enhance the representation learning ofnarrative videos. Evaluation across 11 datasets for phase recognition andmulti-instrument identification shows OphCLIP's robust generalization andsuperior performance.</description>
      <author>example@mail.com (Ming Hu, Kun Yuan, Yaling Shen, Feilong Tang, Xiaohao Xu, Lin Zhou, Wei Li, Ying Chen, Zhongxing Xu, Zelin Peng, Siyuan Yan, Vinkle Srivastav, Diping Song, Tianbin Li, Danli Shi, Jin Ye, Nicolas Padoy, Nassir Navab, Junjun He, Zongyuan Ge)</author>
      <guid isPermaLink="false">2411.15421v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>$\textit{Revelio}$: Interpreting and leveraging semantic information in diffusion models</title>
      <link>http://arxiv.org/abs/2411.16725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了不同扩散架构中各种层和去噪时间步长内丰富的视觉语义信息的表示方式，并通过k-sparse自编码器揭示单义可解释特征。利用轻量级分类器在现成的扩散模型特性上进行迁移学习，验证机制性解释。&lt;h4&gt;背景&lt;/h4&gt;现有的基于扩散架构的深度学习模型由于其复杂性和黑箱性质，在视觉语义信息表示方面缺乏足够的可解释性。&lt;h4&gt;目的&lt;/h4&gt;揭示和理解不同扩散架构中各层及去噪步骤中的视觉语义特征，并评估语言模型条件、预训练数据集对视觉表征的影响，以及这些特性如何影响迁移学习能力。&lt;h4&gt;方法&lt;/h4&gt;利用k-sparse自编码器（k-SAE）来识别单义可解释的特征。通过轻量级分类器在现成扩散模型的特征上进行迁移学习，以验证所提出的机制性解释的有效性和准确性。&lt;h4&gt;主要发现&lt;/h4&gt;在4个数据集上的实验表明，扩散特性对于表示学习是有效的；不同扩散架构、预训练数据集和语言模型条件对视觉表征颗粒度、归纳偏置及迁移学习能力有显著影响。&lt;h4&gt;结论&lt;/h4&gt;这项研究为加深黑箱扩散模型的可解释性提供了一个关键步骤，并为进一步的研究奠定了基础。相关代码和可视化工具可在 https://github.com/revelio-diffusion/revelio 获取。&lt;h4&gt;翻译&lt;/h4&gt;我们探讨了各种层次结构以及不同扩散架构去噪时间步长内丰富的视觉语义信息是如何表示的。通过利用k-sparse自编码器（k-SAE），我们揭示了单义可解释特征，并且通过在现成扩散模型特性上的迁移学习使用轻量级分类器来证实我们的机制性解释。我们在4个数据集上展示了扩散特性的有效性，用于表示学习。同时提供了深入分析，探讨不同扩散架构、预训练数据集和语言模型条件如何影响视觉表示的颗粒度、归纳偏置及迁移学习能力。这项工作是朝着加深黑箱扩散模型可解释性的重要一步。相关代码和可视化工具可在 https://github.com/revelio-diffusion/revelio 获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study $\textit{how}$ rich visual semantic information is representedwithin various layers and denoising timesteps of different diffusionarchitectures. We uncover monosemantic interpretable features by leveragingk-sparse autoencoders (k-SAE). We substantiate our mechanistic interpretationsvia transfer learning using light-weight classifiers on off-the-shelf diffusionmodels' features. On $4$ datasets, we demonstrate the effectiveness ofdiffusion features for representation learning. We provide in-depth analysis ofhow different diffusion architectures, pre-training datasets, and languagemodel conditioning impacts visual representation granularity, inductive biases,and transfer learning capabilities. Our work is a critical step towardsdeepening interpretability of black-box diffusion models. Code andvisualizations available at: https://github.com/revelio-diffusion/revelio</description>
      <author>example@mail.com (Dahye Kim, Xavier Thomas, Deepti Ghadiyaram)</author>
      <guid isPermaLink="false">2411.16725v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Gotta Hear Them All: Sound Source Aware Vision to Audio Generation</title>
      <link>http://arxiv.org/abs/2411.15447v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 9 figures, source code released at
  https://github.com/wguo86/SSV2A&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于声音源感知的视觉到音频（V2A）合成方法SSV2A，该方法能够从视频或静止图像生成更具沉浸感和表现力的声音。&lt;h4&gt;背景&lt;/h4&gt;现有的V2A技术在多媒体领域广泛应用，但生成的声音缺乏真实性和细节性。原因可能是现有方法仅依赖全局场景信息而忽略了局部声音源的特性。&lt;h4&gt;目的&lt;/h4&gt;通过提出Sound Source-Aware V2A (SSV2A)生成器来解决上述问题，旨在提高V2A合成的表现力和沉浸感。&lt;h4&gt;方法&lt;/h4&gt;1. 本地感知多模态声音源：使用视觉检测与跨模态转换技术从场景中识别局部的声音源。
2. 对比学习跨模态声音源（CMSS）流形以区分每个来源的语义信息。
3. 注意力混合声音源的CMSS语义，生成丰富的音频表示，并通过预训练的音频生成器输出最终的声音。&lt;h4&gt;主要发现&lt;/h4&gt;1. 为建模CMSS流形创建了新颖的单一声音源视觉-音频数据集VGGS3。2. 设计了一种衡量本地化音频相关的Sound Source Matching Score。&lt;h4&gt;结论&lt;/h4&gt;实验表明，提出的SSV2A方法在生成质量和相关性方面均优于现有技术，并展示了直观的声音控制能力。&lt;h4&gt;翻译&lt;/h4&gt;该摘要介绍了最新的研究进展，提出了一种新的声音源感知的视觉到音频合成（SSV2A）生成器，它首次尝试通过识别和处理具体的声音源来改善多媒体场景中的音效生成效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wguo86/ssv2a&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-to-audio (V2A) synthesis has broad applications in multimedia. Recentadvancements of V2A methods have made it possible to generate relevant audiosfrom inputs of videos or still images. However, the immersiveness andexpressiveness of the generation are limited. One possible problem is thatexisting methods solely rely on the global scene and overlook details of localsounding objects (i.e., sound sources). To address this issue, we propose aSound Source-Aware V2A (SSV2A) generator. SSV2A is able to locally perceivemultimodal sound sources from a scene with visual detection and cross-modalitytranslation. It then contrastively learns a Cross-Modal Sound Source (CMSS)Manifold to semantically disambiguate each source. Finally, we attentively mixtheir CMSS semantics into a rich audio representation, from which a pretrainedaudio generator outputs the sound. To model the CMSS manifold, we curate anovel single-sound-source visual-audio dataset VGGS3 from VGGSound. We alsodesign a Sound Source Matching Score to measure localized audio relevance. Thisis to our knowledge the first work to address V2A generation at thesound-source level. Extensive experiments show that SSV2A surpassesstate-of-the-art methods in both generation fidelity and relevance. We furtherdemonstrate SSV2A's ability to achieve intuitive V2A control by compositingvision, text, and audio conditions. Our SSV2A generation can be tried and heardat https://ssv2a.github.io/SSV2A-demo .</description>
      <author>example@mail.com (Wei Guo, Heng Wang, Jianbo Ma, Weidong Cai)</author>
      <guid isPermaLink="false">2411.15447v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>LLM2CLIP: Powerful Language Model Unlocks Richer Visual Representation</title>
      <link>http://arxiv.org/abs/2411.04997v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;CLIP 是一个基础的多模态模型，通过对比学习大规模图像-文本对将图像和文本特征映射到共享空间。&lt;h4&gt;目的&lt;/h4&gt;研究大型语言模型（LLMs）在增强 CLIP 的多模态表示学习方面的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种微调方法，该方法结合了预训练的 CLIP 视觉编码器和大型语言模型的高级文本理解和开放世界的知识以改善 CLIP 处理长而复杂的说明的能力。针对 LLMs 自回归性质带来的挑战，提出了一种 caption-to-caption 对比学习框架来提高其输出的判别能力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在各种下游任务上取得了显著的性能提升，证明了结合 LLM 和 CLIP 进行增强多模态学习的有效性。&lt;h4&gt;结论&lt;/h4&gt;展示了大型语言模型与预训练视觉编码器融合后，在多模态学习中可以取得更好的效果。&lt;h4&gt;翻译&lt;/h4&gt;摘要提到的研究内容和成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/microsoft/LLM2CLIP&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLIP is a foundational multimodal model that aligns image and text featuresinto a shared space using contrastive learning on large-scale image-text pairs.Its strength lies in leveraging natural language as a rich supervisory signal.With the rapid progress of large language models (LLMs), we explore theirpotential to further enhance CLIP's multimodal representation learning. Thiswork introduces a fine-tuning approach that integrates LLMs with the pretrainedCLIP visual encoder, leveraging LLMs' advanced text understanding andopen-world knowledge to improve CLIP's ability to process long and complexcaptions. To address the challenge of LLMs' autoregressive nature, we propose acaption-to-caption contrastive learning framework to enhance the discriminativepower of their outputs. Our method achieves substantial performance gains onvarious downstream tasks, demonstrating the effectiveness of combining LLMswith CLIP for enhanced multimodal learning.</description>
      <author>example@mail.com (Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, Lili Qiu)</author>
      <guid isPermaLink="false">2411.04997v3</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Graph Condensation: Advancing Data Versatility through Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2411.17063v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为对比图凝聚（Contrastive Graph Condensation，CTGC）的新方法，旨在解决现有图凝聚技术在处理大规模图神经网络训练时的局限性。CTGC采用自监督任务替代传统的分类任务来生成紧凑且高效的图表示。&lt;h4&gt;背景&lt;/h4&gt;随着大型图形上训练图神经网络计算量的增加，图凝聚作为一种合成紧凑替代图的技术逐渐受到重视，以提高GNN的训练效率。然而，现有的图凝聚方法主要依赖于节点标签进行优化，这种过度依赖限制了其在标签稀疏情况下的应用。&lt;h4&gt;目的&lt;/h4&gt;为了克服现有技术对节点标签的过度依赖以及缺乏跨任务泛化能力的问题，本文提出了一种新的自监督图凝聚方法CTGC。&lt;h4&gt;方法&lt;/h4&gt;CTGC采用双分支框架来分离节点属性和图结构生成，并引入对比损失项进行交替优化。其中设计了一个专门用于编码几何信息（通过节点位置嵌入）的结构性分支。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，CTGC在处理各种下游任务时表现出色，特别是在标签数量有限的情况下也能够超越当前最先进的图凝聚方法。&lt;h4&gt;结论&lt;/h4&gt;CTGC提供了一种有效的解决办法来生成高质量、跨任务泛化的紧凑图表示，特别适用于大规模图神经网络训练的场景。&lt;h4&gt;翻译&lt;/h4&gt;随着大型图形上训练图神经网络计算量的增加，图凝聚作为一种合成紧凑替代图的技术逐渐受到重视。然而现有方法过度依赖节点标签，在标签稀疏的情况下限制了应用范围。本文提出CTGC采用自监督任务生成高质量、跨任务泛化的紧凑表示，并通过实验验证其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing computation of training graph neural networks (GNNs) onlarge-scale graphs, graph condensation (GC) has emerged as a promising solutionto synthesize a compact, substitute graph of the large-scale original graph forefficient GNN training. However, existing GC methods predominantly employclassification as the surrogate task for optimization, thus excessively relyingon node labels and constraining their utility in label-sparsity scenarios. Morecritically, this surrogate task tends to overfit class-specific informationwithin the condensed graph, consequently restricting the generalizationcapabilities of GC for other downstream tasks. To address these challenges, weintroduce Contrastive Graph Condensation (CTGC), which adopts a self-supervisedsurrogate task to extract critical, causal information from the original graphand enhance the cross-task generalizability of the condensed graph.Specifically, CTGC employs a dual-branch framework to disentangle thegeneration of the node attributes and graph structures, where a dedicatedstructural branch is designed to explicitly encode geometric informationthrough nodes' positional embeddings. By implementing an alternatingoptimization scheme with contrastive loss terms, CTGC promotes the mutualenhancement of both branches and facilitates high-quality graph generationthrough the model inversion technique. Extensive experiments demonstrate thatCTGC excels in handling various downstream tasks with a limited number oflabels, consistently outperforming state-of-the-art GC methods.</description>
      <author>example@mail.com (Xinyi Gao, Yayong Li, Tong Chen, Guanhua Ye, Wentao Zhang, Hongzhi Yin)</author>
      <guid isPermaLink="false">2411.17063v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Foundation Models To learn the shape of semi-fluid deformable objects</title>
      <link>http://arxiv.org/abs/2411.16802v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了如何表征可变形物体，特别是焊缝池，并通过不同的方法来提取稳定特征用于进一步的运动控制。&lt;h4&gt;背景&lt;/h4&gt;过去十年中，研究人员对非流体性质的可变形物体（如衣物和绳索）的表征和操作表现出浓厚兴趣。尽管提出了多种表征方法，但通常需要通过图像中的像素级信息才能准确提取相关数据。&lt;h4&gt;目的&lt;/h4&gt;研究旨在定义稳定特征以供进一步运动控制目标使用，并探索用于焊缝池表征的方法。&lt;h4&gt;方法&lt;/h4&gt;本文采用了两种主要方法：一种是利用生成模型（基于教师-学生框架训练）来表征流体可变形物体；另一种则是通过将基础模型用作教师，直接在图像上表征对象而无需任何预训练和数据集。&lt;h4&gt;主要发现&lt;/h4&gt;从基础模型向较小的生成模型的知识蒸馏显示出显著的结果，在表征可变形物体方面具有突出表现。学生网络能够以13.4像素误差学习到提取关键点，教师基于其能力获取表示对象掩码的像素级信息（平均交并比为75.26%）。&lt;h4&gt;结论&lt;/h4&gt;通过使用不同的技术框架和方法，研究成功地表征了焊缝池，并证明了生成模型在处理可变形物体中的潜力。这些发现为进一步改进机器人操作提供了重要的基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要的内容已全部翻译成中文并进行了总结&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; One of the difficulties imposed on the manipulation of deformable objects istheir characterization and the detection of representative keypoints for thepurpose of manipulation. A keen interest was manifested by researchers in thelast decade to characterize and manipulate deformable objects of non-fluidnature, such as clothes and ropes. Even though several propositions were madein the regard of object characterization, however researchers were alwaysconfronted with the need of pixel-level information of the object throughimages to extract relevant information. This usually is accomplished by meansof segmentation networks trained on manually labeled data for this purpose. Inthis paper, we address the subject of characterizing weld pool to define stablefeatures that serve as information for further motion control objectives. Weachieve this by employing different pipelines. The first one consists ofcharacterizing fluid deformable objects through the use of a generative modelthat is trained using a teacher-student framework. And in the second one weleverage foundation models by using them as teachers to characterize the objectin the image, without the need of any pre-training and any dataset. Theperformance of knowledge distillation from foundation models into a smallergenerative model shows prominent results in the characterization of deformableobjects. The student network was capable of learning to retrieve the keypoitnsof the object with an error of 13.4 pixels. And the teacher was evaluated basedon its capacities to retrieve pixel level information represented by the objectmask, with a mean Intersection Over Union (mIoU) of 75.26%.</description>
      <author>example@mail.com (Omar El Assal, Carlos M. Mateo, Sebastien Ciron, David Fofi)</author>
      <guid isPermaLink="false">2411.16802v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Physically Parameterized Differentiable MUSIC for DoA Estimation with Uncalibrated Arrays</title>
      <link>http://arxiv.org/abs/2411.15144v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于模型的方法，用于同时进行方向到达（DoA）估计和硬件损伤学习。&lt;h4&gt;背景&lt;/h4&gt;方向到达（DoA）估计在雷达、声纳、音频和无线通信系统中是一个常见的感知问题。随着集成感知与通信范式的出现，它的重要性再次凸显出来。&lt;h4&gt;目的&lt;/h4&gt;为了充分利用这种感知系统的潜力，必须考虑潜在的硬件缺陷，这些缺陷可能对获得的性能产生负面影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一个基于模型的方法，即导出了多个信号分类（MUSIC）算法的一个可微版本，以便有效地学习所考虑的损伤。该方法支持监督和非监督的学习策略。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果显示，提出的方法能够成功地学习天线位置的重大不准确性和复数增益的不准确性，并且在DoA估计任务中优于经典的MUSIC算法。&lt;h4&gt;结论&lt;/h4&gt;本文展示了一种新颖的方法，在考虑硬件损伤的情况下有效地进行方向到达（DoA）估计。该方法具有广泛的实践潜力，特别是在集成感知与通信系统中。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的内容被翻译为中文并以分点形式总结&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Direction of arrival (DoA) estimation is a common sensing problem in radar,sonar, audio, and wireless communication systems. It has gained renewedimportance with the advent of the integrated sensing and communicationparadigm. To fully exploit the potential of such sensing systems, it is crucialto take into account potential hardware impairments that can negatively impactthe obtained performance. This study introduces a joint DoA estimation andhardware impairment learning scheme following a model-based approach.Specifically, a differentiable version of the multiple signal classification(MUSIC) algorithm is derived, allowing efficient learning of the consideredimpairments. The proposed approach supports both supervised and unsupervisedlearning strategies, showcasing its practical potential. Simulation resultsindicate that the proposed method successfully learns significant inaccuraciesin both antenna locations and complex gains. Additionally, the proposed methodoutperforms the classical MUSIC algorithm in the DoA estimation task.</description>
      <author>example@mail.com (Baptiste Chatelier, José Miguel Mateos-Ramos, Vincent Corlay, Christian Häger, Matthieu Crussière, Henk Wymeersch, Luc Le Magoarou)</author>
      <guid isPermaLink="false">2411.15144v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction</title>
      <link>http://arxiv.org/abs/2411.16765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SHuBERT是一种用于手语视频的自我监督变换器编码模型，它在多个基准测试中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;传统的手语处理依赖于特定任务的模型，这限制了跨任务迁移学习的潜力。&lt;h4&gt;目的&lt;/h4&gt;引入SHuBERT以从大约1000小时的手语视频内容中学习强大的表示形式，并提高手语翻译和孤立手势识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;SHuBERT受到HuBERT语音表征模型成功的启发，使用多流视觉输入进行掩码预测，适用于美国手语（ASL）的处理。&lt;h4&gt;主要发现&lt;/h4&gt;在手语翻译任务上，SHuBERT优于先前的方法；在孤立的手势识别中，它超过了专门化的模型，并且与最先进的技术性能接近。&lt;h4&gt;结论&lt;/h4&gt;实验表明SHuBERT的有效性并通过消融研究确认了每种方法组件的贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sign language processing has traditionally relied on task-specificmodels,limiting the potential for transfer learning across tasks. We introduceSHuBERT (Sign Hidden-Unit BERT), a self-supervised transformer encoder thatlearns strong representations from approximately 1,000 hours of American SignLanguage (ASL) video content. Inspired by the success of the HuBERT speechrepresentation model, SHuBERT adapts masked prediction for multi-stream visualsign language input, learning to predict multiple targets for corresponding toclustered hand, face, and body pose streams. SHuBERT achieves state-of-the-artperformance across multiple benchmarks. On sign language translation, itoutperforms prior methods trained on publicly available data on the How2Sign(+0.7 BLEU), OpenASL (+10.0 BLEU), and FLEURS-ASL (+0.3 BLEU) benchmarks.Similarly for isolated sign language recognition, SHuBERT's accuracy surpassesthat of specialized models on ASL-Citizen (+5\%) and SEM-LEX (+20.6\%), whilecoming close to them on WLASL2000 (-3\%). Ablation studies confirm thecontribution of each component of the approach.</description>
      <author>example@mail.com (Shester Gueuwou, Xiaodan Du, Greg Shakhnarovich, Karen Livescu, Alexander H. Liu)</author>
      <guid isPermaLink="false">2411.16765v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Depth-PC: A Visual Servo Framework Integrated with Cross-Modality Fusion for Sim2Real Transfer</title>
      <link>http://arxiv.org/abs/2411.17195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的基于深度学习的视觉伺服框架Depth-PC，该框架利用模拟训练和图像关键点的语义与几何信息来实现零样本迁移至真实世界的伺服任务。&lt;h4&gt;背景&lt;/h4&gt;传统的视觉伺服技术需要先验知识且易受外部干扰影响；而基于学习的方法则受限于数据稀缺性和泛化能力不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，能够在缺乏实际训练的情况下将仿真环境中的视觉伺服技能有效转移到现实场景中，并增强机器人在复杂情况下的适应性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;通过利用模拟训练和图像关键点的语义及几何信息进行跨模态特征融合；并使用图神经网络处理由这些模式产生的融合特性，以建立关键点间的几何与语义对应关系来更新机器人的状态。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在实验中展示了比现有方法更好的收敛性和准确性，并通过实验证明了跨模态特征融合的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的Depth-PC框架满足视觉伺服任务对精度和稳定性的要求，能够实现零样本迁移至现实世界的应用场景。&lt;h4&gt;翻译&lt;/h4&gt;摘要中的所有中文内容即为从英文到中文的直接翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual servo techniques guide robotic motion using visual information toaccomplish manipulation tasks, requiring high precision and robustness againstnoise. Traditional methods often require prior knowledge and are susceptible toexternal disturbances. Learning-driven alternatives, while promising,frequently struggle with the scarcity of training data and fall short ingeneralization. To address these challenges, we propose a novel visual servoframework Depth-PC that leverages simulation training and exploits semantic andgeometric information of keypoints from images, enabling zero-shot transfer toreal-world servo tasks. Our framework focuses on the servo controller whichintertwines keypoint feature queries and relative depth information.Subsequently, the fused features from these two modalities are then processedby a Graph Neural Network to establish geometric and semantic correspondencebetween keypoints and update the robot state. Through simulation and real-worldexperiments, our approach demonstrates superior convergence basin and accuracycompared to state-of-the-art methods, fulfilling the requirements for roboticservo tasks while enabling zero-shot application to real-world scenarios. Inaddition to the enhancements achieved with our proposed framework, we have alsosubstantiated the efficacy of cross-modality feature fusion within the realm ofservo tasks.</description>
      <author>example@mail.com (Haoyu Zhang, Weiyang Lin, Yimu Jiang, Chao Ye)</author>
      <guid isPermaLink="false">2411.17195v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Glo-In-One-v2: Holistic Identification of Glomerular Cells, Tissues, and Lesions in Human and Mouse Histopathology</title>
      <link>http://arxiv.org/abs/2411.16961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种改进的Glo-In-One工具包版本2，用于肾小球组织和病变的精细分割，并且在大量标注数据集上进行了训练。&lt;h4&gt;背景&lt;/h4&gt;传统的肾小球分段依赖于专家病理学家详细的形态学评估，这一过程劳动密集型并且容易受到观察者之间差异的影响。Glo-In-One工具包之前被开发用于集成检测和分割肾小球。&lt;h4&gt;目的&lt;/h4&gt;目的是利用改进的Glo-In-One-v2工具包进行更精细的分段，并在包含人类和小鼠数据的大规模标注数据集上训练深度学习模型，以识别特定组织类型和病变。&lt;h4&gt;方法&lt;/h4&gt;提出了一种单个动态头的深层架构来对部分标记的人类和小鼠病理图像中的14个类别进行分割。该模型基于368张注释过的肾脏完整切片图像（WSIs）训练，并且能够区分五种关键的肾小球内组织以及九种不同的病变。&lt;h4&gt;主要发现&lt;/h4&gt;Glo-In-One-v2模型在分割肾小球组织和病变时表现出良好的性能，平均Dice相似性系数（DSC）达到76.5%。跨物种迁移学习进一步提高了不同类型病变分段的准确性超过3%。&lt;h4&gt;结论&lt;/h4&gt;Glo-In-One-v2模型及其训练权重已被公开发布于GitHub，可供其他研究者使用。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了改进版的Glo-In-One工具包（版本2）用于肾小球内组织和病变的精细分割，并且展示了一个单个动态头深度学习架构在标注图像中对14类进行分段的表现。该模型基于大规模的数据集进行了训练，具有良好的性能，并通过跨物种迁移学习进一步增强了准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hrlblab/glo-in-one_v2&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Segmenting glomerular intraglomerular tissue and lesions traditionallydepends on detailed morphological evaluations by expert nephropathologists, alabor-intensive process susceptible to interobserver variability. Our grouppreviously developed the Glo-In-One toolkit for integrated detection andsegmentation of glomeruli. In this study, we leverage the Glo-In-One toolkit toversion 2 with fine-grained segmentation capabilities, curating 14 distinctlabels for tissue regions, cells, and lesions across a dataset of 23,529annotated glomeruli across human and mouse histopathology data. To ourknowledge, this dataset is among the largest of its kind to date.In this study,we present a single dynamic head deep learning architecture designed to segment14 classes within partially labeled images of human and mouse pathology data.Our model was trained using a training set derived from 368 annotated kidneywhole-slide images (WSIs) to identify 5 key intraglomerular tissues coveringBowman's capsule, glomerular tuft, mesangium, mesangial cells, and podocytes.Additionally, the network segments 9 glomerular lesion classes includingadhesion, capsular drop, global sclerosis, hyalinosis, mesangial lysis,microaneurysm, nodular sclerosis, mesangial expansion, and segmental sclerosis.The glomerulus segmentation model achieved a decent performance compared withbaselines, and achieved a 76.5 % average Dice Similarity Coefficient (DSC).Additional, transfer learning from rodent to human for glomerular lesionsegmentation model has enhanced the average segmentation accuracy acrossdifferent types of lesions by more than 3 %, as measured by Dice scores. TheGlo-In-One-v2 model and trained weight have been made publicly available athttps: //github.com/hrlblab/Glo-In-One_v2.</description>
      <author>example@mail.com (Lining Yu, Mengmeng Yin, Ruining Deng, Quan Liu, Tianyuan Yao, Can Cui, Junlin Guo, Yu Wang, Yaohong Wang, Shilin Zhao, Haichun Yang, Yuankai Huo)</author>
      <guid isPermaLink="false">2411.16961v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Crack Detection in Infrastructure Using Transfer Learning, Spatial Attention, and Genetic Algorithm Optimization</title>
      <link>http://arxiv.org/abs/2411.17140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的基础设施裂缝检测方法，采用迁移学习、空间注意力机制和遗传算法优化。该模型在数据稀缺的情况下展现了优越的表现。&lt;h4&gt;背景&lt;/h4&gt;传统的基础设施检查主要依靠人工进行，这种方法费时耗力且存在主观性和危险性。因此需要一种更高效的方法来替代现有的手动检查。&lt;h4&gt;目的&lt;/h4&gt;通过引入深度学习技术改进基础设施裂缝检测的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;使用ResNet50作为预训练模型以减少对大量标注数据的需求，同时结合空间注意力层以及遗传算法优化定制神经网络架构。&lt;h4&gt;主要发现&lt;/h4&gt;提出的Attention-ResNet50-GA模型在实际案例研究中表现出色，精确度达到0.9967，F1分数为0.9983，超越了传统方法。该模型能够准确检测各种条件下的裂缝。&lt;h4&gt;结论&lt;/h4&gt;新模型具备高度适应性和准确性，在缺乏大规模标注数据的现实场景下尤为适用。&lt;h4&gt;翻译&lt;/h4&gt;裂缝检测在基础设施维护和安全中起着关键作用，及时识别结构损坏可以防止事故发生并减少昂贵维修费用。传统的人工检查方式劳动强度大、主观性强且存在危险性。本文介绍了一种利用深度学习技术进行基础设施裂缝检测的先进方法，结合了迁移学习、空间注意力机制以及遗传算法（GA）优化。为应对大量数据不可用的问题，本研究采用了ResNet50作为预训练模型，并通过减少对大规模训练集的需求来增强其强大的特征提取能力。我们使用遗传算法进一步微调了一个定制化的神经网络架构，并在其上添加了空间注意层。一个综合案例研究展示了所提Attention-ResNet50-GA模型的有效性，该模型在精度为0.9967和F1分数为0.9983的情况下超越传统方法。结果表明，在大规模标注数据稀缺的实际应用中，该模型能够准确检测各种条件下的裂缝。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Crack detection plays a pivotal role in the maintenance and safety ofinfrastructure, including roads, bridges, and buildings, as timelyidentification of structural damage can prevent accidents and reduce costlyrepairs. Traditionally, manual inspection has been the norm, but it islabor-intensive, subjective, and hazardous. This paper introduces an advancedapproach for crack detection in infrastructure using deep learning, leveragingtransfer learning, spatial attention mechanisms, and genetic algorithm(GA)optimization. To address the challenge of the inaccessability of large amountof data, we employ ResNet50 as a pre-trained model, utilizing its strongfeature extraction capabilities while reducing the need for extensive trainingdatasets. We enhance the model with a spatial attention layer as well as acustomized neural network which architecture was fine-tuned using GA. Acomprehensive case study demonstrates the effectiveness of the proposedAttention-ResNet50-GA model, achieving a precision of 0.9967 and an F1 score of0.9983, outperforming conventional methods. The results highlight the model'sability to accurately detect cracks in various conditions, making it highlysuitable for real-world applications where large annotated datasets are scarce.</description>
      <author>example@mail.com (Feng Ding)</author>
      <guid isPermaLink="false">2411.17140v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MICAS: Multi-grained In-Context Adaptive Sampling for 3D Point Cloud Processing</title>
      <link>http://arxiv.org/abs/2411.16773v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 6 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云处理（PCP）包括重建、去噪、配准和分割等任务，每个任务通常需要专门的模型来应对独特的特性。虽然在上下文学习（ICL）中单个模型通过使用带有特定于任务的提示的任务展示了跨越多个任务的能力，但在PCP中的应用显示了显著的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出MICAS框架以解决现有ICL方法在处理点云时存在的跨任务和内部分歧问题，并改进其适应性和灵活性。&lt;h4&gt;方法&lt;/h4&gt;MICAS提出了两个核心组件：任务自适应点采样，通过利用跨任务线索进行点级采样；查询特定提示采样，选择每个查询的最佳提示以减轻内部分歧。该框架的创新在于引入了适用于PCP需求的多粒度自适应采样机制。&lt;h4&gt;主要发现&lt;/h4&gt;MICAS在处理各种PCP任务时不仅表现高效，而且显著超越现有方法。尤其是在部件分割任务中实现了4.1%的改进，并且在各种PCP应用中持续取得良好效果。&lt;h4&gt;结论&lt;/h4&gt;这是首次提出将自适应采样机制引入到ICL框架以满足点云的独特需求的方法论创新，为解决复杂和多样化PCP挑战提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容的主要部分已经被转化为中文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud processing (PCP) encompasses tasks like reconstruction,denoising, registration, and segmentation, each often requiring specializedmodels to address unique task characteristics. While in-context learning (ICL)has shown promise across tasks by using a single model with task-specificdemonstration prompts, its application to PCP reveals significant limitations.We identify inter-task and intra-task sensitivity issues in current ICL methodsfor PCP, which we attribute to inflexible sampling strategies lacking contextadaptation at the point and prompt levels. To address these challenges, wepropose MICAS, an advanced ICL framework featuring a multi-grained adaptivesampling mechanism tailored for PCP. MICAS introduces two core components:task-adaptive point sampling, which leverages inter-task cues for point-levelsampling, and query-specific prompt sampling, which selects optimal prompts perquery to mitigate intra-task sensitivity. To our knowledge, this is the firstapproach to introduce adaptive sampling tailored to the unique requirements ofpoint clouds within an ICL framework. Extensive experiments show that MICAS notonly efficiently handles various PCP tasks but also significantly outperformsexisting methods. Notably, it achieves a remarkable $4.1\%$ improvement in thepart segmentation task and delivers consistent gains across various PCPapplications.</description>
      <author>example@mail.com (Feifei Shao, Ping Liu, Zhao Wang, Yawei Luo, Hongwei Wang, Jun Xiao)</author>
      <guid isPermaLink="false">2411.16773v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Multi-graph Learning with Neighbor Hierarchical Sifting for Semi-supervised Text Classification</title>
      <link>http://arxiv.org/abs/2411.16787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要分点总结&lt;/h4&gt;{'总结': '提出了一种名为ConNHS的新方法，用于半监督文本分类中的对比多图学习。', '背景': '现有的图形对比学习在文本分类中取得成功，但由于明确的图增强可能导致语义丢失、忽视边特征和节点特征的重要性以及对比损失中存在的假阴性问题而存在局限性。', '目的': '通过引入核心特征形成一个多关系文本图，并提出邻居分层筛选（NHS）损失来解决这些问题。', '方法': {'1. 核心特征利用': '通过核心特征构建多关系文本图，增强语义连接。', '2. 对比学习视图提供': '分离文本图以提供多样化的对比学习视角，并确保信息的最优保存，减少数据损失和失真。', '3. 关系感知传播和跨图注意力传播': '执行这两个过程来有效利用节点与边特征之间的变化相关性以及不同图间的信息融合。', '4. 邻居分层筛选损失(NHS)': 'NHS依据同质性假设屏蔽锚点及其正例的一阶邻居，排除类似锚点的高阶邻居以减少假阴性的发生。'}, '主要发现': '提出的ConNHS方法显著减少了假阴性的出现，并防止相似样本在嵌入空间中距离扩大。', '结论': '实验结果表明该方法在半监督文本分类任务上表现良好，具有竞争力的结果。具体数据集包括ThuCNews, SogouNews, 20Newsgroups和Ohsumed，在这些数据集中分别取得了95.86%, 97.52%, 87.43%和70.65%的性能。', '翻译': 'Graph对比学习已经成功应用于文本分类，但由于图增强可能导致语义丢失、忽视边特征的重要性以及多图学习中节点特征变化的问题而存在局限性。为了克服这些问题，提出了一个名为ConNHS的新方法，即基于邻居分层筛选的对比多图学习，用于半监督文本分类。通过利用核心特征形成一个多关系文本图来增强语义连接，并提供多样化的视图进行对比学习。该方法采用一种新的损失函数NHS来优化负样本的选择过程，从而减少假阴性的出现并防止相似样本在嵌入空间中的距离扩大。实验结果显示，在多个数据集上的性能表现卓越，证明了ConNHS的有效性。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph contrastive learning has been successfully applied in textclassification due to its remarkable ability for self-supervised noderepresentation learning. However, explicit graph augmentations may lead to aloss of semantics in the contrastive views. Secondly, existing methods tend tooverlook edge features and the varying significance of node features duringmulti-graph learning. Moreover, the contrastive loss suffer from falsenegatives. To address these limitations, we propose a novel method ofcontrastive multi-graph learning with neighbor hierarchical sifting forsemi-supervised text classification, namely ConNHS. Specifically, we exploitcore features to form a multi-relational text graph, enhancing semanticconnections among texts. By separating text graphs, we provide diverse viewsfor contrastive learning. Our approach ensures optimal preservation of thegraph information, minimizing data loss and distortion. Then, we separatelyexecute relation-aware propagation and cross-graph attention propagation, whicheffectively leverages the varying correlations between nodes and edge featureswhile harmonising the information fusion across graphs. Subsequently, wepresent the neighbor hierarchical sifting loss (NHS) to refine the negativeselection. For one thing, following the homophily assumption, NHS masksfirst-order neighbors of the anchor and positives from being negatives. Foranother, NHS excludes the high-order neighbors analogous to the anchor based ontheir similarities. Consequently, it effectively reduces the occurrence offalse negatives, preventing the expansion of the distance between similarsamples in the embedding space. Our experiments on ThuCNews, SogouNews, 20Newsgroups, and Ohsumed datasets achieved 95.86\%, 97.52\%, 87.43\%, and70.65\%, which demonstrates competitive results in semi-supervised textclassification.</description>
      <author>example@mail.com (Wei Ai, Jianbin Li, Ze Wang, Yingying Wei, Tao Meng, Yuntao Shou, Keqin Lib)</author>
      <guid isPermaLink="false">2411.16787v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SatVision-TOA: A Geospatial Foundation Model for Coarse-Resolution All-Sky Remote Sensing Imagery</title>
      <link>http://arxiv.org/abs/2411.17000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SatVision-TOA是一个基于14波段MODIS L1B TOA辐射数据预训练的新型基础模型，旨在解决现有高空间分辨率、无云卫星图像或照片为基础的基础模型在需要频繁时间监测或广泛光谱范围的应用场景中的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有的大多数基础模型都是为高空间分辨率且无云的卫星影像设计的，这限制了它们在涉及大气变量或要求大气校正的应用场景中的适用性。这些现有模型对于频需进行时序观测或者需要广谱光谱支持的情况来说实用性较低。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于MODIS L1B TOA辐射数据（14波段）的新型基础模型SatVision-TOA，以更好地处理中低分辨率和全天空遥感数据。通过该模型的学习能力提升多光谱遥感任务中的大气条件和气溶胶条件下的云层与地表监测效果。&lt;h4&gt;方法&lt;/h4&gt;使用Masked Image Modeling (MIM)框架和SwinV2架构对SatVision-TOA进行预训练，使它能从无标签数据中学习详细的上下文表示。该模型拥有30亿参数，并且是基于1亿张卫星遥感图像进行训练的。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在下游任务如三维云检测上，与基准方法相比，SatVision-TOA表现出更优越的表现能力；在mIOU评价指标下，其数值为0.46，相比于基准模型提升了接近一倍（从0.22提升到0.46）。&lt;h4&gt;结论&lt;/h4&gt;SatVision-TOA通过学习各种大气和气溶胶条件下的数据来改进云层和地表的监测效果，并且在大规模卫星遥感图像上建立了目前最大的基础模型，这对多光谱遥感领域具有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;Foundation models have the potential to transform the landscape of remote sensing (RS) data analysis by enabling large computer vision models to be pre-trained on vast amounts of remote sensing data. These models can then be fine-tuned with small amounts of labeled training and applied to a variety of applications. Most existing foundation models are designed for high spatial resolution, cloud-free satellite imagery or photos, limiting their applicability in scenarios that require frequent temporal monitoring or broad spectral profiles. As a result, foundation models trained solely on cloud-free images have limited utility for applications that involve atmospheric variables or require atmospheric corrections. We introduce SatVision-TOA, a novel foundation model pre-trained on 14-band MODIS L1B Top-Of-Atmosphere (TOA) radiance imagery, addressing the need for models pre-trained to handle moderate- and coarse-resolution all-sky remote sensing data. The SatVision-TOA model is pre-trained using a Masked-Image-Modeling (MIM) framework and the SwinV2 architecture, and learns detailed contextual representations through self-supervised learning without the need for labels. It is a 3 billion parameter model that is trained on 100 million images. To our knowledge this is the largest foundation model trained solely on satellite RS imagery. Results show that SatVision-TOA achieves superior performance over baseline methods on downstream tasks such as 3D cloud retrieval. Notably, the model achieves a mean intersection over union (mIOU) of 0.46, a substantial improvement over the baseline mIOU of 0.22. Additionally, the rate of false negative results in the fine-tuning task were reduced by over 50% compared to the baseline. Our work advances pre-trained vision modeling for multispectral RS by learning from a variety of atmospheric and aerosol conditions to improve cloud and land surface monitoring.&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nasa-nccs-hpda/pytorch-caney&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have the potential to transform the landscape of remotesensing (RS) data analysis by enabling large computer vision models to bepre-trained on vast amounts of remote sensing data. These models can then befine-tuned with small amounts of labeled training and applied to a variety ofapplications. Most existing foundation models are designed for high spatialresolution, cloud-free satellite imagery or photos, limiting theirapplicability in scenarios that require frequent temporal monitoring or broadspectral profiles. As a result, foundation models trained solely on cloud-freeimages have limited utility for applications that involve atmospheric variablesor require atmospheric corrections. We introduce SatVision-TOA, a novelfoundation model pre-trained on 14-band MODIS L1B Top-Of-Atmosphere (TOA)radiance imagery, addressing the need for models pre-trained to handlemoderate- and coarse-resolution all-sky remote sensing data. The SatVision-TOAmodel is pre-trained using a Masked-Image-Modeling (MIM) framework and theSwinV2 architecture, and learns detailed contextual representations throughself-supervised learning without the need for labels. It is a 3 billionparameter model that is trained on 100 million images. To our knowledge this isthe largest foundation model trained solely on satellite RS imagery. Resultsshow that SatVision-TOA achieves superior performance over baseline methods ondownstream tasks such as 3D cloud retrieval. Notably, the model achieves a meanintersection over union (mIOU) of 0.46, a substantial improvement over thebaseline mIOU of 0.22. Additionally, the rate of false negative results in thefine-tuning task were reduced by over 50% compared to the baseline. Our workadvances pre-trained vision modeling for multispectral RS by learning from avariety of atmospheric and aerosol conditions to improve cloud and land surfacemonitoring.</description>
      <author>example@mail.com (Caleb S. Spradlin, Jordan A. Caraballo-Vega, Jian Li, Mark L. Carroll, Jie Gong, Paul M. Montesano)</author>
      <guid isPermaLink="false">2411.17000v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>On the Generalization of Handwritten Text Recognition Models</title>
      <link>http://arxiv.org/abs/2411.17332v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;近年来，手写文本识别（HTR）领域取得了显著进展，在标准基准测试下降低了转录错误率。然而，在现实世界的应用中，独立同分布的假设并不成立，促使研究人员探索迁移学习和领域适应技术。这项研究探讨了HTR模型在处理非独立同分布数据时存在的未解决限制。&lt;h4&gt;背景&lt;/h4&gt;现有HTR系统在标准基准测试中的表现优异，但这些系统的性能依赖于训练数据与测试数据之间的一致性假设，在实际应用中这一假设往往不成立。因此，研究人员开始关注如何使这些模型适应新的、未知的数据分布。&lt;h4&gt;目的&lt;/h4&gt;评估当前最先进的HTR模型面对非独立同分布（OOD）数据时的表现，并识别影响其泛化能力的关键因素。&lt;h4&gt;方法&lt;/h4&gt;分析了来自八种先进HTR模型在七种广泛使用的数据集上的336个非独立同分布案例，这些数据集涵盖了五种不同的语言。此外，还研究了合成数据对模型泛化效果的影响。&lt;h4&gt;主要发现&lt;/h4&gt;发现了影响HTR模型从一个领域向另一个领域泛化的最关键因素是文本域之间的差异性（包括视觉和语义方面），而不是简单的图像特征变化。&lt;h4&gt;结论&lt;/h4&gt;证明了可以通过分析现有训练集来可靠地估计HTR模型在面对非独立同分布数据时的性能下降，这为未来的研究奠定了基础，以克服当前模型在这方面的局限性和挑战。&lt;h4&gt;翻译&lt;/h4&gt;最近的手写文本识别（HTR）进展已经导致标准基准测试下转录错误率大幅降低。然而，这种假设在现实世界应用中不再成立，激发了研究人员探索迁移学习和领域适应技术的兴趣。在此研究中，我们探讨了HTR模型在泛化到非独立同分布数据时未解决的局限性。采用具有挑战性的域概括设置，在没有事先访问的情况下期望模型能够推广到新的数据集上。为此，我们分析了八种最先进的HTR模型在七种广泛使用的跨五种语言的数据集中存在的336个非独立同分布案例。此外，我们还研究了HTR模型如何利用合成数据进行泛化。结果显示，影响泛化的最关键因素在于域之间的文本差异性，其次是视觉差异性。我们展示了HTR模型在面对非独立同分布情况下的错误可以被可靠地估计，在大多数情况下误差差距低于10个百分点。我们指出了HTR模型的基本局限性，并为未来的相关研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Handwritten Text Recognition (HTR) have led to significantreductions in transcription errors on standard benchmarks under the i.i.d.assumption, thus focusing on minimizing in-distribution (ID) errors. However,this assumption does not hold in real-world applications, which has motivatedHTR research to explore Transfer Learning and Domain Adaptation techniques. Inthis work, we investigate the unaddressed limitations of HTR models ingeneralizing to out-of-distribution (OOD) data. We adopt the challengingsetting of Domain Generalization, where models are expected to generalize toOOD data without any prior access. To this end, we analyze 336 OOD cases fromeight state-of-the-art HTR models across seven widely used datasets, spanningfive languages. Additionally, we study how HTR models leverage synthetic datato generalize. We reveal that the most significant factor for generalizationlies in the textual divergence between domains, followed by visual divergence.We demonstrate that the error of HTR models in OOD scenarios can be reliablyestimated, with discrepancies falling below 10 points in 70\% of cases. Weidentify the underlying limitations of HTR models, laying the foundation forfuture research to address this challenge.</description>
      <author>example@mail.com (Carlos Garrido-Munoz, Jorge Calvo-Zaragoza)</author>
      <guid isPermaLink="false">2411.17332v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Abnormality-Driven Representation Learning for Radiology Imaging</title>
      <link>http://arxiv.org/abs/2411.16803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种针对放射学图像的框架CLEAR，该框架使用从2D切片中提取的嵌入和基于注意力机制的聚合来预测临床结果。&lt;h4&gt;背景&lt;/h4&gt;在放射学领域，深度学习通常采用3D网络，并通过其他任务预训练后进行微调。病理学等邻近医学领域的2D图像则更多采用自监督学习结合弱监督学习的方法。&lt;h4&gt;目的&lt;/h4&gt;解决放射学中缺乏基于自监督学习的任务无关性表示模型的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为病变增强对比学习（LeCL）的新方法，用于获取CT扫描不同位置的2D轴向切片中的异常驱动视觉表示。利用三种不同的架构：Vision Transformers、Vision State Space Models和Gated Convolutional Neural Networks进行单域对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;CLEAR框架在肿瘤病变定位、肺部疾病检测和患者分期三个临床任务上的表现优于四个最先进的基础模型，同时具有更高的计算效率和数据效率。&lt;h4&gt;结论&lt;/h4&gt;CLEAR使用通过LeCL学习到的表示方法，在放射学领域的多个临床任务上取得了显著的效果，并且更节省资源。&lt;h4&gt;翻译&lt;/h4&gt;截至目前，针对放射学深度学习管道最常用的方法是基于其他任务预训练的3D网络模型并进行微调。相比之下，如病理学等邻近医学领域则有效采用自监督学习结合弱监督学习的基础模型。然而，由于三维成像所需的计算和数据需求以及放射扫描中固有的解剖复杂性，放射学领域至今缺乏基于自监督学习的任务无关表示模型。为此，我们提出了一种针对放射图像的框架CLEAR，该框架使用从2D切片中提取的嵌入结合注意力机制聚合来高效预测临床终点。作为此框架的一部分，我们引入了病变增强对比学习（LeCL），这是一种新方法，通过CT扫描不同位置的2D轴向切片中的异常情况获得视觉表示。具体而言，我们利用三种不同的架构：Vision Transformers、Vision State Space Models和Gated Convolutional Neural Networks进行单域对比学习。我们在肿瘤病变定位、肺部疾病检测和患者分期三个临床任务上对其进行了评估，并与四个最先进的基础模型（包括BiomedCLIP）进行了基准测试。我们的研究结果表明，使用LeCL学习到的表示方法的CLEAR框架优于现有基础模型，同时在计算效率和数据效率方面表现出显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To date, the most common approach for radiology deep learning pipelines isthe use of end-to-end 3D networks based on models pre-trained on other tasks,followed by fine-tuning on the task at hand. In contrast, adjacent medicalfields such as pathology, which focus on 2D images, have effectively adoptedtask-agnostic foundational models based on self-supervised learning (SSL),combined with weakly-supervised deep learning (DL). However, the field ofradiology still lacks task-agnostic representation models due to thecomputational and data demands of 3D imaging and the anatomical complexityinherent to radiology scans. To address this gap, we propose CLEAR, a frameworkfor radiology images that uses extracted embeddings from 2D slices along withattention-based aggregation for efficiently predicting clinical endpoints. Aspart of this framework, we introduce lesion-enhanced contrastive learning(LeCL), a novel approach to obtain visual representations driven byabnormalities in 2D axial slices across different locations of the CT scans.Specifically, we trained single-domain contrastive learning approaches usingthree different architectures: Vision Transformers, Vision State Space Modelsand Gated Convolutional Neural Networks. We evaluate our approach across threeclinical tasks: tumor lesion location, lung disease detection, and patientstaging, benchmarking against four state-of-the-art foundation models,including BiomedCLIP. Our findings demonstrate that CLEAR using representationslearned through LeCL, outperforms existing foundation models, while beingsubstantially more compute- and data-efficient.</description>
      <author>example@mail.com (Marta Ligero, Tim Lenz, Georg Wölflein, Omar S. M. El Nahhas, Daniel Truhn, Jakob Nikolas Kather)</author>
      <guid isPermaLink="false">2411.16803v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>GraphSubDetector: Time Series Subsequence Anomaly Detection via Density-Aware Adaptive Graph Neural Network</title>
      <link>http://arxiv.org/abs/2411.17218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列子序列异常检测在健康监测、AIOps等众多实际应用中是一项重要任务，但因以下原因而具有挑战性：1) 如何有效地学习时间序列中的复杂动态和依赖关系；2) 异常子序列的多样性与复杂性以及正常模式固有的变化性和噪声。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的时间序列异常检测方法GraphSubDetector，以解决上述问题并提高现有算法的效果。&lt;h4&gt;方法&lt;/h4&gt;{'适应性长度选择机制': '自适应地学习合适的子序列长度，该机制强调了正常和异常模式的特点', '密度感知自适应图神经网络(DAGNN)': '通过子序列之间的消息传递生成进一步的稳健表示以对抗正常数据的变化性和噪声'}&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明所提出的算法在多个时间序列异常基准数据集上优于现有的最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;GraphSubDetector算法证明了其在时间序列子序列异常检测任务上的有效性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;时间序列子序列异常检测是健康监测到AIOps等众多实际应用中的重要任务，但由于需要有效地学习时间序列的复杂动态和依赖关系、处理多样且复杂的异常子序列以及正常模式固有的变化性和噪声等问题而具有挑战。在本文中，我们提出了一种新颖的方法GraphSubDetector用于子序列异常检测：首先它通过长度选择机制自适应地学习合适的子序列长度；其次，我们提出了一个密度感知自适应图神经网络（DAGNN），该方法能生成进一步的稳健表示以对抗正常数据变化性和噪声。实验结果表明所提出的算法在多个时间序列异常基准数据集上优于现有的最先进的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series subsequence anomaly detection is an important task in a largevariety of real-world applications ranging from health monitoring to AIOps, andis challenging due to the following reasons: 1) how to effectively learncomplex dynamics and dependencies in time series; 2) diverse and complicatedanomalous subsequences as well as the inherent variance and noise of normalpatterns; 3) how to determine the proper subsequence length for effectivedetection, which is a required parameter for many existing algorithms. In thispaper, we present a novel approach to subsequence anomaly detection, namelyGraphSubDetector. First, it adaptively learns the appropriate subsequencelength with a length selection mechanism that highlights the characteristics ofboth normal and anomalous patterns. Second, we propose a density-aware adaptivegraph neural network (DAGNN), which can generate further robust representationsagainst variance of normal data for anomaly detection by message passingbetween subsequences. The experimental results demonstrate the effectiveness ofthe proposed algorithm, which achieves superior performance on multiple timeseries anomaly benchmark datasets compared to state-of-the-art algorithms.</description>
      <author>example@mail.com (Weiqi Chen, Zhiqiang Zhou, Qingsong Wen, Liang Sun)</author>
      <guid isPermaLink="false">2411.17218v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>g3D-LF: Generalizable 3D-Language Feature Fields for Embodied Tasks</title>
      <link>http://arxiv.org/abs/2411.17030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了Generalizable 3D-Language Feature Fields (g3D-LF)模型，这是一个用于具身任务的预训练三维表示模型。&lt;h4&gt;目的&lt;/h4&gt;通过处理来自代理的RGB-D图像，该模型可以编码特征字段来实现新颖视图表示预测、生成基于代理中心的BEV地图以及使用多粒度语言查询目标。&lt;h4&gt;方法&lt;/h4&gt;g3D-LF通过对采样的光线进行体渲染并将语义和空间关系通过多层次编码器整合在一起，在不同尺度和视角上产生与多粒度语言对齐的表示。&lt;h4&gt;主要发现&lt;/h4&gt;该模型可以推广到未见环境中，实现实时构建和动态更新，并且经过大量3D-语言数据集训练以使特征字段表示与语言一致。&lt;h4&gt;实验结果&lt;/h4&gt;在Vision-and-Language Navigation（全景设置和单目设置）、Zero-shot Object Navigation以及Situated Question Answering任务上的广泛实验表明了g3D-LF模型对于具身任务的重要优势和有效性。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了一种新的三维表示学习方法，能够在大量未见环境中有效工作，并展示了其在各种具身任务中的广泛应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为Generalizable 3D-Language Feature Fields (g3D-LF)的模型，这是在一个大规模3D-语言数据集上预训练的三维表示模型，用于处理具身任务。我们的g3D-LF通过处理代理提供的RGB-D图像来编码特征字段，以实现从场景中任意位置的新颖视图预测、生成基于代理中心的BEV地图以及使用多粒度语言查询目标等功能。该表示方法可以推广到未见环境中，支持实时构建和动态更新。通过对采样光线上的潜在特性进行体积渲染，并通过多层次编码器整合语义和空间关系，我们的g3D-LF模型可以在不同尺度和视角上产生与多粒度语言对齐的表示。此外，我们准备了一个大规模3D-语言数据集来使特征字段表示与语言一致。在Vision-and-Language Navigation（全景设置和单目设置）、Zero-shot Object Navigation以及Situated Question Answering任务上的广泛实验展示了g3D-LF模型在具身任务中的显著优势和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Generalizable 3D-Language Feature Fields (g3D-LF), a 3Drepresentation model pre-trained on large-scale 3D-language dataset forembodied tasks. Our g3D-LF processes posed RGB-D images from agents to encodefeature fields for: 1) Novel view representation predictions from any positionin the 3D scene; 2) Generations of BEV maps centered on the agent; 3) Queryingtargets using multi-granularity language within the above-mentionedrepresentations. Our representation can be generalized to unseen environments,enabling real-time construction and dynamic updates. By volume rendering latentfeatures along sampled rays and integrating semantic and spatial relationshipsthrough multiscale encoders, our g3D-LF produces representations at differentscales and perspectives, aligned with multi-granularity language, viamulti-level contrastive learning. Furthermore, we prepare a large-scale3D-language dataset to align the representations of the feature fields withlanguage. Extensive experiments on Vision-and-Language Navigation under bothPanorama and Monocular settings, Zero-shot Object Navigation, and SituatedQuestion Answering tasks highlight the significant advantages and effectivenessof our g3D-LF for embodied tasks.</description>
      <author>example@mail.com (Zihan Wang, Gim Hee Lee)</author>
      <guid isPermaLink="false">2411.17030v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DGNN-YOLO: Dynamic Graph Neural Networks with YOLO11 for Small Object Detection and Tracking in Traffic Surveillance</title>
      <link>http://arxiv.org/abs/2411.17251v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;准确检测和跟踪行人、自行车骑手和摩托车等小型物体对于交通监控系统至关重要，这有助于提高道路安全，并在智能交通系统中做出决策。然而，传统方法面对遮挡、低分辨率以及动态的交通状况时存在挑战，需要创新的方法来解决这些问题。&lt;h4&gt;背景&lt;/h4&gt;传统的检测和跟踪小目标（如行人、自行车骑手和摩托车）的方法难以应对遮挡、低分辨率和复杂的动态交通环境中的问题，这些问题是智能交通系统中提高道路安全的关键障碍。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架DGNN-YOLO，结合动态图神经网络(DGNN)与YOLO11算法，以增强在交通监控系统中小目标的检测和跟踪性能。&lt;h4&gt;方法&lt;/h4&gt;该框架利用YOLO11先进的空间特征提取能力来实现精确的对象检测，并通过整合DGNN来建模时空关系从而进行稳健且实时的动态跟踪。通过构建并更新图结构，DGNN-YOLO能够有效地表示物体为节点及其交互作用作为边。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在不同的交通条件下，DGNN-YOLO在检测和跟踪小目标方面始终优于最先进的方法，其精度、召回率以及mAP@0.5:0.95分别为0.8382、0.6875和0.6476。&lt;h4&gt;结论&lt;/h4&gt;此工作提供了一种可扩展的实时交通监控与分析解决方案，有助于智能交通系统的发展，特别是在处理小目标及遮挡场景时表现出强大的鲁棒性和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate detection and tracking of small objects such as pedestrians,cyclists, and motorbikes are critical for traffic surveillance systems, whichare crucial in improving road safety and decision-making in intelligenttransportation systems. However, traditional methods struggle with challengessuch as occlusion, low resolution, and dynamic traffic conditions,necessitating innovative approaches to address these limitations. This paperintroduces DGNN-YOLO, a novel framework integrating dynamic graph neuralnetworks (DGNN) with YOLO11 to enhance small object detection and tracking intraffic surveillance systems. The framework leverages YOLO11's advanced spatialfeature extraction capabilities for precise object detection and incorporatesDGNN to model spatial-temporal relationships for robust real-time trackingdynamically. By constructing and updating graph structures, DGNN-YOLOeffectively represents objects as nodes and their interactions as edges,ensuring adaptive and accurate tracking in complex and dynamic environments.Extensive experiments demonstrate that DGNN-YOLO consistently outperformsstate-of-the-art methods in detecting and tracking small objects under diversetraffic conditions, achieving the highest precision (0.8382), recall (0.6875),and mAP@0.5:0.95 (0.6476), showcasing its robustness and scalability,particularly in challenging scenarios involving small and occluded objects.This work provides a scalable, real-time traffic surveillance and analysissolution, significantly contributing to intelligent transportation systems.</description>
      <author>example@mail.com (Shahriar Soudeep, M. F. Mridha, Md Abrar Jahin, Nilanjan Dey)</author>
      <guid isPermaLink="false">2411.17251v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>An End-to-End Robust Point Cloud Semantic Segmentation Network with Single-Step Conditional Diffusion Models</title>
      <link>http://arxiv.org/abs/2411.16308v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于条件噪声框架（CNF）的端到端语义分割网络CDSegNet，该网络通过学习噪声特征生成器来提高3D场景理解任务中的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;现有带噪声条件框架的去噪扩散概率模型在处理包含复杂几何细节的3D场景时面临挑战，且训练和推断时间较长。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来改进基于条件网络的模型，并提高DDPMs在3D语义分割中的性能。&lt;h4&gt;方法&lt;/h4&gt;通过引入噪声网络作为可学习的噪声特征生成器，CDSegNet能够在多级特征扰动下理解场景语义。同时利用DDPMs的噪声系统增强了噪声和稀疏性鲁棒性，并且能在单步推理中产生语义标签。&lt;h4&gt;主要发现&lt;/h4&gt;CDSegNet在公共室内和室外基准上显著优于现有方法，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入条件-噪声框架（CNF），可以在不直接适应从语义标签到数据分布分数的过程中提高去噪扩散概率模型的效率和鲁棒性，并且能够有效地进行3D场景理解任务中的端到端训练。&lt;h4&gt;翻译&lt;/h4&gt;现有带噪声条件框架的去噪扩散概率模型在处理包含复杂几何细节的3D场景时面临挑战，且训练和推断时间较长。本文提出了基于DDPMs条件-噪声框架（CNF）的一种新的端到端语义分割网络CDSegNet。通过将噪声网络视为可学习的噪声特征生成器，该方法允许条件网络在多级特征扰动下理解3D场景语义，从而增强了未见场景中的泛化能力。同时得益于DDPMs的噪声系统，在实验中展示了强大的噪声和稀疏性鲁棒性。此外由于CNF避免了主要网络直接拟合从语义标签到数据分布分数的过程，CDSegNet可以像非DDPMs一样通过单步推理生成语义标签。在公开室内和室外基准上，CDSegNet显著优于现有方法，并达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/qwtforgithub/cdsegnet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing conditional Denoising Diffusion Probabilistic Models (DDPMs) with aNoise-Conditional Framework (NCF) remain challenging for 3D scene understandingtasks, as the complex geometric details in scenes increase the difficulty offitting the gradients of the data distribution (the scores) from semanticlabels. This also results in longer training and inference time for DDPMscompared to non-DDPMs. From a different perspective, we delve deeply into themodel paradigm dominated by the Conditional Network. In this paper, we proposean end-to-end robust semantic \textbf{Seg}mentation \textbf{Net}work based on a\textbf{C}onditional-Noise Framework (CNF) of D\textbf{D}PMs, named\textbf{CDSegNet}. Specifically, CDSegNet models the Noise Network (NN) as alearnable noise-feature generator. This enables the Conditional Network (CN) tounderstand 3D scene semantics under multi-level feature perturbations,enhancing the generalization in unseen scenes. Meanwhile, benefiting from thenoise system of DDPMs, CDSegNet exhibits strong noise and sparsity robustnessin experiments. Moreover, thanks to CNF, CDSegNet can generate the semanticlabels in a single-step inference like non-DDPMs, due to avoiding directlyfitting the scores from semantic labels in the dominant network of CDSegNet. Onpublic indoor and outdoor benchmarks, CDSegNet significantly outperformsexisting methods, achieving state-of-the-art performance.</description>
      <author>example@mail.com (Wentao Qu, Jing Wang, YongShun Gong, Xiaoshui Huang, Liang Xiao)</author>
      <guid isPermaLink="false">2411.16308v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MRIFE: A Mask-Recovering and Interactive-Feature-Enhancing Semantic Segmentation Network For Relic Landslide Detection</title>
      <link>http://arxiv.org/abs/2411.17167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;研究提出了一种用于识别和分割遗迹滑坡的模型MRIFE。&lt;h4&gt;背景信息&lt;/h4&gt;长期形成的遗迹滑坡可能重新活跃，构成地质灾害。由于自然演化和人类活动导致的外观变化以及难以获取样本的问题，使用高分辨率遥感图像进行语义分割面临挑战。&lt;h4&gt;研究目的&lt;/h4&gt;提出一种新的语义分割方法来更有效地提取和分离特征，解决小规模数据集问题，并提高区分目标与背景的能力。&lt;h4&gt;技术方法&lt;/h4&gt;{'模型名称': 'mask-recovering and interactive-feature-enhancing (MRIFE)', '对比学习': '使用局部显著性特征增强的对比学习和掩码重建方法来改进滑坡语义特征的表现能力', '双支架构': '采用双分支交互式特征增强架构以丰富提取的特征并解决视觉模糊问题', '自蒸馏学习': '引入自蒸馏学习利用样本内的多样性，提高数据利用率，加速模型收敛'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能提升': '与基线方法相比，在精度、平均交并比（IoU）、滑坡交并比和F1分数方面都有显著提高', '具体指标': '精度从0.4226提升到0.5347，均值IoU从0.6405增加至0.6680，滑坡IoU由0.3381升至0.3934，F1分数从0.5054增至0.5646'}&lt;h4&gt;结论&lt;/h4&gt;MRIFE模型在真实遗迹滑坡数据集上进行了评估，并显示出对遗迹滑坡检测性能的显著改进。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了研究提出了一种新的语义分割方法，即mask-recovering and interactive-feature-enhancing (MRIFE)模型，以解决用于识别和区分高分辨率遥感图像中的遗迹滑坡时所面临的挑战。这项技术可以提高特征提取效率，改善在小样本数据集上的性能，并优化目标与背景的区分能力。通过真实数据验证后发现，该方法相对于基线提高了多个指标的表现，证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relic landslide, formed over a long period, possess the potential forreactivation, making them a hazardous geological phenomenon. While reliablerelic landslide detection benefits the effective monitoring and prevention oflandslide disaster, semantic segmentation using high-resolution remote sensingimages for relic landslides faces many challenges, including the object visualblur problem, due to the changes of appearance caused by prolonged naturalevolution and human activities, and the small-sized dataset problem, due todifficulty in recognizing and labelling the samples. To address thesechallenges, a semantic segmentation model, termed mask-recovering andinteractive-feature-enhancing (MRIFE), is proposed for more efficient featureextraction and separation. Specifically, a contrastive learning and maskreconstruction method with locally significant feature enhancement is proposedto improve the ability to distinguish between the target and background andrepresent landslide semantic features. Meanwhile, a dual-branch interactivefeature enhancement architecture is used to enrich the extracted features andaddress the issue of visual ambiguity. Self-distillation learning is introducedto leverage the feature diversity both within and between samples forcontrastive learning, improving sample utilization, accelerating modelconvergence, and effectively addressing the problem of the small-sized dataset.The proposed MRIFE is evaluated on a real relic landslide dataset, andexperimental results show that it greatly improves the performance of reliclandslide detection. For the semantic segmentation task, compared to thebaseline, the precision increases from 0.4226 to 0.5347, the mean intersectionover union (IoU) increases from 0.6405 to 0.6680, the landslide IoU increasesfrom 0.3381 to 0.3934, and the F1-score increases from 0.5054 to 0.5646.</description>
      <author>example@mail.com (Juefei He, Yuexing Peng, Wei Li, Junchuan Yu, Daqing Ge, Wei Xiang)</author>
      <guid isPermaLink="false">2411.17167v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Symmetry Strikes Back: From Single-Image Symmetry Detection to 3D Generation</title>
      <link>http://arxiv.org/abs/2411.17763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://ryanxli.github.io/reflect3d/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;研究探讨了从单张RGB图像检测3D镜像对称性的方法，揭示其在单图像三维生成中的重要性。&lt;h4&gt;背景&lt;/h4&gt;对称性是视觉世界中普遍存在和基本的属性，在感知和结构解释中起着关键作用。该论文关注于从单张RGB图像检测3D反射对称性，并探讨了它在单一视图下的三维生成中的重要作用。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为Reflect3D的方法，用于从单张彩色图像识别3D镜像对称性，以提高结构的准确性和视觉保真度。此外，通过结合多视角扩散模型产生的先验知识来解决单一视图下检测对称性的固有模糊问题。&lt;h4&gt;方法&lt;/h4&gt;采用基于Transformer架构的Reflect3D作为可扩展、零样本（zero-shot）的对称性探测器，其能够稳健地推广到各种现实场景。该方法利用生成式优先项从多视角扩散模型来解决单视图下的检测不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的评估数据源，证明了Reflect3D在单一图像对称性检测方面建立了新的状态最优性能，并展示了将探测的对称性整合到三维几何和纹理重建中所带来的实际效益。采用对称性感知优化流程可以显著提高生成的质量。&lt;h4&gt;结论&lt;/h4&gt;这项研究提升了通过单张图像进行高质量三维内容创建的可能性，特别是通过增强结构准确性、一致性以及视觉保真度来实现这一点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Symmetry is a ubiquitous and fundamental property in the visual world,serving as a critical cue for perception and structure interpretation. Thispaper investigates the detection of 3D reflection symmetry from a single RGBimage, and reveals its significant benefit on single-image 3D generation. Weintroduce Reflect3D, a scalable, zero-shot symmetry detector capable of robustgeneralization to diverse and real-world scenarios. Inspired by the success offoundation models, our method scales up symmetry detection with atransformer-based architecture. We also leverage generative priors frommulti-view diffusion models to address the inherent ambiguity in single-viewsymmetry detection. Extensive evaluations on various data sources demonstratethat Reflect3D establishes a new state-of-the-art in single-image symmetrydetection. Furthermore, we show the practical benefit of incorporating detectedsymmetry into single-image 3D generation pipelines through a symmetry-awareoptimization process. The integration of symmetry significantly enhances thestructural accuracy, cohesiveness, and visual fidelity of the reconstructed 3Dgeometry and textures, advancing the capabilities of 3D content creation.</description>
      <author>example@mail.com (Xiang Li, Zixuan Huang, Anh Thai, James M. Rehg)</author>
      <guid isPermaLink="false">2411.17763v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing In-Hospital Mortality Prediction Using Multi-Representational Learning with LLM-Generated Expert Summaries</title>
      <link>http://arxiv.org/abs/2411.16818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过将大型语言模型（LLM）生成的专家摘要与时间序列生理数据和临床笔记结合，改进了ICU患者的住院死亡率预测。&lt;h4&gt;背景&lt;/h4&gt;重症监护室(ICU)患者入院后死亡率(IHM)预测对于及时干预和有效资源分配至关重要。结构化生理数据提供了定量见解，而临床记录则提供了丰富的上下文叙述信息。&lt;h4&gt;目的&lt;/h4&gt;研究旨在利用大型语言模型生成的专家摘要整合多种模态的数据源，以提高IHM预测准确性。&lt;h4&gt;方法&lt;/h4&gt;采用MIMIC-III数据库，分析患者入院最初48小时内的时间序列生理数据和临床记录。通过Med42-v2 70B将每个患者的临床笔记按时间顺序合并并转换为专家摘要。开发了一种多表示学习框架来整合这些数据源，并利用LLMs增强文本数据分析。&lt;h4&gt;主要发现&lt;/h4&gt;与仅基于时间序列的基线模型相比，所提出的模型实现了AUPRC（面积下的精度-召回曲线）0.6156 (+36.41%)和AUROC (曲线下面积) 0.8955(+7.64%)。专家摘要的表现优于单独使用临床笔记或时间序列数据。&lt;h4&gt;结论&lt;/h4&gt;将大型语言模型生成的总结与结构化和非结构化数据结合，可以捕捉互补的患者信息，显著提高预测性能，展示了LLM在临床上用于增强重症监护预测模型的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;入院后ICU患者的死亡率预测对于及时干预和有效资源分配至关重要。本文通过整合时间序列生理数据、临床记录以及大型语言模型生成的专业摘要来改进这一预测的准确性。研究采用MIMIC-III数据库进行，分析了患者在ICU的第一48小时内的时间序列生理数据及临床记录，并使用Med42-v2 70B将笔记转化为专家总结。结果表明该方法有效提高了IHM预测准确率，且表现优于单独运用时间序列或文本记录的情况，显示出LLM技术在医疗领域的潜在应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In-hospital mortality (IHM) prediction for ICU patients is critical fortimely interventions and efficient resource allocation. While structuredphysiological data provides quantitative insights, clinical notes offerunstructured, context-rich narratives. This study integrates these modalitieswith Large Language Model (LLM)-generated expert summaries to improve IHMprediction accuracy. Using the MIMIC-III database, we analyzed time-seriesphysiological data and clinical notes from the first 48 hours of ICU admission.Clinical notes were concatenated chronologically for each patient andtransformed into expert summaries using Med42-v2 70B. A multi-representationallearning framework was developed to integrate these data sources, leveragingLLMs to enhance textual data while mitigating direct reliance on LLMpredictions, which can introduce challenges in uncertainty quantification andinterpretability. The proposed model achieved an AUPRC of 0.6156 (+36.41%) andan AUROC of 0.8955 (+7.64%) compared to a time-series-only baseline. Expertsummaries outperformed clinical notes or time-series data alone, demonstratingthe value of LLM-generated knowledge. Performance gains were consistent acrossdemographic groups, with notable improvements in underrepresented populations,underscoring the framework's equitable application potential. By integratingLLM-generated summaries with structured and unstructured data, the frameworkcaptures complementary patient information, significantly improving predictiveperformance. This approach showcases the potential of LLMs to augment criticalcare prediction models, emphasizing the need for domain-specific validation andadvanced integration strategies for broader clinical adoption.</description>
      <author>example@mail.com (Harshavardhan Battula, Jiacheng Liu, Jaideep Srivastava)</author>
      <guid isPermaLink="false">2411.16818v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Functionality understanding and segmentation in 3D scenes</title>
      <link>http://arxiv.org/abs/2411.16310v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report. 20 pages, 12 figures, 7 tables. Updated website
  link&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了Fun3DU，这是一种在三维场景中理解功能性的新方法。&lt;h4&gt;背景&lt;/h4&gt;理解和解释自然语言描述以找到三维环境中的功能性交互对象（如手柄和按钮）是具有挑战性的。这需要世界知识来解读语言以及空间感知能力来识别细粒度的对象。&lt;h4&gt;目的&lt;/h4&gt;提出一种专门用于解决在3D场景中理解功能性的方法，即Fun3DU。&lt;h4&gt;方法&lt;/h4&gt;使用语言模型通过Chain-of-Thought推理解析任务描述以确定感兴趣对象。利用视觉和语言模型将该对象从多个视图中分割出来，并将其结果提升到三维空间并通过几何信息聚合到点云中。&lt;h4&gt;主要发现&lt;/h4&gt;在最新的SceneFun3D数据集上评估了Fun3DU，其性能远超现有方法。&lt;h4&gt;结论&lt;/h4&gt;Fun3DU是一个无需训练的方法，完全依赖于预训练模型。它在最新和唯一的用于基准测试的SceneFun3D数据集上显著优于现有的开放词汇表3D分割方法。&lt;h4&gt;翻译&lt;/h4&gt;理解三维场景中的功能涉及到根据自然语言描述来定位功能性交互对象（如手柄和按钮）。这是一种高度挑战性的任务，需要世界知识来解读语言以及空间感知能力来识别细粒度的对象。当前尚无专门为解决此问题的方法开发出来。本文提出了一种用于三维场景中理解功能性的方法Fun3DU。该方法使用语言模型通过Chain-of-Thought推理解析任务描述以确定感兴趣对象，并利用视觉和语言模型在多个视图中对其进行分割，然后将其结果提升到三维空间并通过几何信息聚合到点云中。Fun3DU无需训练，完全依赖于预训练模型，在最新且唯一的用于基准测试的SceneFun3D数据集上显著优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding functionalities in 3D scenes involves interpreting naturallanguage descriptions to locate functional interactive objects, such as handlesand buttons, in a 3D environment. Functionality understanding is highlychallenging, as it requires both world knowledge to interpret language andspatial perception to identify fine-grained objects. For example, given a tasklike 'turn on the ceiling light', an embodied AI agent must infer that it needsto locate the light switch, even though the switch is not explicitly mentionedin the task description. To date, no dedicated methods have been developed forthis problem. In this paper, we introduce Fun3DU, the first approach designedfor functionality understanding in 3D scenes. Fun3DU uses a language model toparse the task description through Chain-of-Thought reasoning in order toidentify the object of interest. The identified object is segmented acrossmultiple views of the captured scene by using a vision and language model. Thesegmentation results from each view are lifted in 3D and aggregated into thepoint cloud using geometric information. Fun3DU is training-free, relyingentirely on pre-trained models. We evaluate Fun3DU on SceneFun3D, the mostrecent and only dataset to benchmark this task, which comprises over 3000 taskdescriptions on 230 scenes. Our method significantly outperformsstate-of-the-art open-vocabulary 3D segmentation approaches. Project page:https://jcorsetti.github.io/fun3du</description>
      <author>example@mail.com (Jaime Corsetti, Francesco Giuliari, Alice Fasoli, Davide Boscaini, Fabio Poiesi)</author>
      <guid isPermaLink="false">2411.16310v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MWFormer: Multi-Weather Image Restoration Using Degradation-Aware Transformers</title>
      <link>http://arxiv.org/abs/2411.17226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Transactions on Image Processing. The code is
  available at: https://github.com/taco-group/MWFormer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;提出了一种多天气Transformer（MWFormer），旨在解决单一视觉变换器在处理多种天气导致的图像退化时的问题。&lt;h4&gt;背景&lt;/h4&gt;现有大多数方法只能针对特定类型的天气退化进行修复，但在现实世界中可能同时出现雨雪、雾霾等多种恶劣天气情况。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多天气Transformer（MWFormer），能够在单一架构下解决由多种天气引起的图像退化问题，并且在应用时可以根据需要灵活调整为单一类型或混合天气的修复模式。&lt;h4&gt;方法&lt;/h4&gt;利用超网络和特征线性调制块，使得使用同一套学习参数即可恢复受各种天气影响而退化的图像。首先通过对比学习训练辅助网络提取内容无关、失真感知的特征嵌入，进而指导MWFormer适应性调整其参数进行局部和全局特征处理。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多天气修复基准测试中，MWFormer相比于现有方法取得了显著性能提升，并且不需要过多计算成本。此外，使用超网络的方法可以应用于多种网络架构以进一步提高它们的性能。&lt;h4&gt;结论&lt;/h4&gt;MWFormer提供了一种新的调优方式，无需重新训练即可在单一类型或混合天气条件下灵活调整修复模式，具有更好的可控制性。&lt;h4&gt;翻译&lt;/h4&gt;针对恶劣天气条件下的图像恢复是许多计算机视觉应用中的基本任务。然而，大多数现有方法只能处理特定类型的退化，在如雨雪、雾霾等复杂环境中效果不佳。为此，我们提出了一个多天气Transformer（MWFormer），它是一个统一的视觉变换器架构，旨在使用单一架构解决多种由不同天气引起的退化问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TIP.2024.3501855&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/taco-group/mwformer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Restoring images captured under adverse weather conditions is a fundamentaltask for many computer vision applications. However, most existing weatherrestoration approaches are only capable of handling a specific type ofdegradation, which is often insufficient in real-world scenarios, such asrainy-snowy or rainy-hazy weather. Towards being able to address thesesituations, we propose a multi-weather Transformer, or MWFormer for short,which is a holistic vision Transformer that aims to solve multipleweather-induced degradations using a single, unified architecture. MWFormeruses hyper-networks and feature-wise linear modulation blocks to restore imagesdegraded by various weather types using the same set of learned parameters. Wefirst employ contrastive learning to train an auxiliary network that extractscontent-independent, distortion-aware feature embeddings that efficientlyrepresent predicted weather types, of which more than one may occur. Guided bythese weather-informed predictions, the image restoration Transformeradaptively modulates its parameters to conduct both local and global featureprocessing, in response to multiple possible weather. Moreover, MWFormer allowsfor a novel way of tuning, during application, to either a single type ofweather restoration or to hybrid weather restoration without any retraining,offering greater controllability than existing methods. Our experimentalresults on multi-weather restoration benchmarks show that MWFormer achievessignificant performance improvements compared to existing state-of-the-artmethods, without requiring much computational cost. Moreover, we demonstratethat our methodology of using hyper-networks can be integrated into variousnetwork architectures to further boost their performance. The code is availableat: https://github.com/taco-group/MWFormer</description>
      <author>example@mail.com (Ruoxi Zhu, Zhengzhong Tu, Jiaming Liu, Alan C. Bovik, Yibo Fan)</author>
      <guid isPermaLink="false">2411.17226v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Distilling Spectral Graph for Object-Context Aware Open-Vocabulary Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2411.17150v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;论文提出了一个新的方法来改进开放词汇语义分割（OVSS）中的模型，特别是在处理复杂对象时缺乏物体级别的上下文信息的问题。&lt;h4&gt;背景&lt;/h4&gt;最近的视觉语言模型(如OVSS)通过不同的学习方案实现了超出预定义类别的分割能力。尤其是无训练的方法提供了可扩展且易于部署的解决方案来应对未见过的数据，这是OVSS的关键目标之一。&lt;h4&gt;目的&lt;/h4&gt;解决当前OVSS模型在处理复杂物体时缺乏对象级上下文信息的问题，提高对任意查询提示的开放词汇语义分割的能力。&lt;h4&gt;方法&lt;/h4&gt;通过将从视觉基础模型中提取的光谱驱动特征融入到视觉编码器的注意力机制来增强对象内的连续性，并通过零样本对象存在可能性细化文本嵌入以确保与图像中存在的具体物体准确匹配。&lt;h4&gt;主要发现&lt;/h4&gt;利用对象级别的上下文知识，所提出的方法实现了强大的泛化能力，在各种数据集上都达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一种新的开放词汇语义分割解决方案，解决了当前模型在复杂环境中的局限性，并展示了其跨不同数据集的广泛适用性和优越性能。&lt;h4&gt;翻译&lt;/h4&gt;开放词汇语义分割（OVSS）已经通过最近的视觉语言模型取得了进展，这些模型能够超越预定义类别进行分割。无训练方法提供了可扩展且易于部署的解决方案来处理未见过的数据。然而，在基于任意查询提示的复杂环境中分割复合物体时，缺乏对对象级上下文信息的考虑仍然是一个问题。这限制了模型将语义一致元素组合成单个对象掩码并准确映射到用户定义的任意类别的能力。该研究引入了一种通过在图像中整合对象级别的上下文知识来克服这一问题的新方法，并展示了其跨各种数据集实现最先进性能的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-Vocabulary Semantic Segmentation (OVSS) has advanced with recentvision-language models (VLMs), enabling segmentation beyond predefinedcategories through various learning schemes. Notably, training-free methodsoffer scalable, easily deployable solutions for handling unseen data, a keygoal of OVSS. Yet, a critical issue persists: lack of object-level contextconsideration when segmenting complex objects in the challenging environment ofOVSS based on arbitrary query prompts. This oversight limits models' ability togroup semantically consistent elements within object and map them precisely touser-defined arbitrary classes. In this work, we introduce a novel approachthat overcomes this limitation by incorporating object-level contextualknowledge within images. Specifically, our model enhances intra-objectconsistency by distilling spectral-driven features from vision foundationmodels into the attention mechanism of the visual encoder, enablingsemantically coherent components to form a single object mask. Additionally, werefine the text embeddings with zero-shot object presence likelihood to ensureaccurate alignment with the specific objects represented in the images. Byleveraging object-level contextual knowledge, our proposed approach achievesstate-of-the-art performance with strong generalizability across diversedatasets.</description>
      <author>example@mail.com (Chanyoung Kim, Dayun Ju, Woojung Han, Ming-Hsuan Yang, Seong Jae Hwang)</author>
      <guid isPermaLink="false">2411.17150v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Factorized Visual Tokenization and Generation</title>
      <link>http://arxiv.org/abs/2411.16681v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;视觉词嵌入器在图像生成中起着关键作用，将视觉数据转换为离散的标记以支持基于变换器模型进行高效的图像生成。尽管它们取得了成功，但如VQGAN这样的基于向量量化（Vector Quantization, VQ）的嵌入器由于词汇表大小受限而面临重大限制。&lt;h4&gt;背景&lt;/h4&gt;传统的VQ-based tokenizers面临着由于词汇量大小受限制导致训练不稳定和性能收益递减的问题，这成为了可扩展性的一个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍Factorized Quantization (FQ)，一种创新方法，旨在通过将大型代码本分解为多个独立的子代码本来重振基于VQ的嵌入器。这种方法减少了查找复杂度，实现了更有效且可扩展的视觉标记化。&lt;h4&gt;方法&lt;/h4&gt;为了确保每个子代码本捕捉到独特的互补信息，提出了去纠缠正则化来明确减少冗余，并促进子代码本之间的多样性。此外，将表示学习整合到了训练过程中，利用预训练的视觉模型（如CLIP和DINO）为所学表征注入语义丰富性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，提出的FQGAN模型极大地提升了视觉标记器的重构质量，并且达到了最先进的性能水平。进一步证明了该标记器可以有效地应用于自回归图像生成中。&lt;h4&gt;结论&lt;/h4&gt;Factorized Quantization (FQ) 是一种创新的方法，通过将大型代码本分解为多个独立的子代码本来实现更有效和可扩展的视觉标记化，同时确保每个子代码本能够捕捉到独特的信息并减少冗余。这不仅提高了图像生成模型的表现，还增强了自回归图像生成的应用效果。&lt;h4&gt;翻译&lt;/h4&gt;Visual tokenizers are fundamental to image generation. They convert visual data into discrete tokens, enabling transformer-based models to excel at image generation. Despite their success, VQ-based tokenizers like VQGAN face significant limitations due to constrained vocabulary sizes. Simply expanding the codebook often leads to training instability and diminishing performance gains, making scalability a critical challenge. In this work, we introduce Factorized Quantization (FQ), a novel approach that revitalizes VQ-based tokenizers by decomposing a large codebook into multiple independent sub-codebooks. This factorization reduces the lookup complexity of large codebooks, enabling more efficient and scalable visual tokenization. To ensure each sub-codebook captures distinct and complementary information, we propose a disentanglement regularization that explicitly reduces redundancy, promoting diversity across the sub-codebooks. Furthermore, we integrate representation learning into the training process, leveraging pretrained vision models like CLIP and DINO to infuse semantic richness into the learned representations. This design ensures our tokenizer captures diverse semantic levels, leading to more expressive and disentangled representations. Experiments show that the proposed FQGAN model substantially improves the reconstruction quality of visual tokenizers, achieving state-of-the-art performance. We further demonstrate that this tokenizer can be effectively adapted into auto-regressive image generation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual tokenizers are fundamental to image generation. They convert visualdata into discrete tokens, enabling transformer-based models to excel at imagegeneration. Despite their success, VQ-based tokenizers like VQGAN facesignificant limitations due to constrained vocabulary sizes. Simply expandingthe codebook often leads to training instability and diminishing performancegains, making scalability a critical challenge. In this work, we introduceFactorized Quantization (FQ), a novel approach that revitalizes VQ-basedtokenizers by decomposing a large codebook into multiple independentsub-codebooks. This factorization reduces the lookup complexity of largecodebooks, enabling more efficient and scalable visual tokenization. To ensureeach sub-codebook captures distinct and complementary information, we propose adisentanglement regularization that explicitly reduces redundancy, promotingdiversity across the sub-codebooks. Furthermore, we integrate representationlearning into the training process, leveraging pretrained vision models likeCLIP and DINO to infuse semantic richness into the learned representations.This design ensures our tokenizer captures diverse semantic levels, leading tomore expressive and disentangled representations. Experiments show that theproposed FQGAN model substantially improves the reconstruction quality ofvisual tokenizers, achieving state-of-the-art performance. We furtherdemonstrate that this tokenizer can be effectively adapted into auto-regressiveimage generation. https://showlab.github.io/FQGAN</description>
      <author>example@mail.com (Zechen Bai, Jianxiong Gao, Ziteng Gao, Pichao Wang, Zheng Zhang, Tong He, Mike Zheng Shou)</author>
      <guid isPermaLink="false">2411.16681v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Breast Tumor Classification Using EfficientNet Deep Learning Model</title>
      <link>http://arxiv.org/abs/2411.17870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种利用EfficientNet和增强的数据增广及成本敏感学习来提高乳腺癌病理图像分类准确性的方法，尤其是在处理罕见肿瘤类型时表现出了显著的改进。&lt;h4&gt;背景&lt;/h4&gt;在医学影像数据集中，某些肿瘤亚型出现频率较低，导致了数据不平衡问题，进而影响模型对这些少见但关键类别的预测准确性。&lt;h4&gt;目的&lt;/h4&gt;提高乳腺癌病理图像分类中罕见和关键肿瘤类型的识别率，并优化多类别任务的性能。&lt;h4&gt;方法&lt;/h4&gt;采用EfficientNet模型，引入增强的数据增广技术和成本敏感学习策略，以及利用迁移学习进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;在二元分类中实现了0.92到0.95的召回率提升和从97.35%到98.23%的准确性提高；多类别任务中的性能也由常规增广的91.27%改进至密集增广后的94.54%，进一步通过迁移学习达到95.04%。&lt;h4&gt;结论&lt;/h4&gt;该框架在处理乳腺癌病理图像分类中，尤其是在罕见肿瘤类型的识别上表现优异，并保持了对关键子类别的高召回率。&lt;h4&gt;翻译&lt;/h4&gt;精准的乳腺癌病理图像是诊断和改善患者预后的关键。数据不平衡问题主要来源于医学影像数据库中的固有失衡，一些肿瘤亚型出现频率较低。为解决这一挑战，研究者采用先进的EfficientNet模型，并结合增强的数据增广及成本敏感学习策略，有效提高了罕见肿瘤类型的识别能力，增强了模型的鲁棒性。通过迁移学习方法的应用，进一步提升了复杂模式检测的能力，在BreakHis数据集上取得了显著的效果提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/majid9418/Breast-Tumor-Classification-Histopathological&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Precise breast cancer classification on histopathological images has thepotential to greatly improve the diagnosis and patient outcome in oncology. Thedata imbalance problem largely stems from the inherent imbalance within medicalimage datasets, where certain tumor subtypes may appear much less frequently.This constitutes a considerable limitation in biased model predictions that canoverlook critical but rare classes. In this work, we adopted EfficientNet, astate-of-the-art convolutional neural network (CNN) model that balances highaccuracy with computational cost efficiency. To address data imbalance, weintroduce an intensive data augmentation pipeline and cost-sensitive learning,improving representation and ensuring that the model does not overly favormajority classes. This approach provides the ability to learn effectively fromrare tumor types, improving its robustness. Additionally, we fine-tuned themodel using transfer learning, where weights in the beginning trained on abinary classification task were adopted to multi-class classification,improving the capability to detect complex patterns within the BreakHisdataset. Our results underscore significant improvements in the binaryclassification performance, achieving an exceptional recall increase for benigncases from 0.92 to 0.95, alongside an accuracy enhancement from 97.35 % to98.23%. Our approach improved the performance of multi-class tasks from 91.27%with regular augmentation to 94.54% with intensive augmentation, reaching95.04% with transfer learning. This framework demonstrated substantial gains inprecision in the minority classes, such as Mucinous carcinoma and Papillarycarcinoma, while maintaining high recall consistently across these criticalsubtypes, as further confirmed by confusion matrix analysis.</description>
      <author>example@mail.com (Majid Behzadpour, Bengie L. Ortiz, Ebrahim Azizi, Kai Wu)</author>
      <guid isPermaLink="false">2411.17870v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CutS3D: Cutting Semantics in 3D for 2D Unsupervised Instance Segmentation</title>
      <link>http://arxiv.org/abs/2411.16319v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的无监督实例分割和对象检测方法，该方法使用点云表示来改进2D图像中的重叠对象实例的分离。&lt;h4&gt;背景&lt;/h4&gt;传统的算法在学习分割二维图像的对象实例时，严重依赖大量的人工标注数据。最近，一些新颖的方法开始尝试以无监督的方式解决这个问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，利用点云表示来改进现有的无监督实例分割和对象检测技术，特别是在处理2D空间中重叠的物体实例方面。&lt;h4&gt;方法&lt;/h4&gt;首先通过生成伪掩码并训练一个类不可知的检测器。然后引入3D切割语义掩码的方法，并使用一种空间重要性函数重新锐化沿3D边界处的语义信息。此外，还提出了三种空间置信度组件来增强训练。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在多个标准基准测试中超越了竞争方法，在无监督实例分割和对象检测方面取得了更好的性能。&lt;h4&gt;结论&lt;/h4&gt;通过利用点云表示和其他改进措施，该方法解决了现有技术难以准确分离2D图像空间中重叠物体实例的问题。&lt;h4&gt;翻译&lt;/h4&gt;传统上，学习二维图像中对象实例的分割算法严重依赖大量的人工注释数据。最近，新颖的方法开始以无监督的方式解决这个问题。通常，这些方法首先生成伪掩码，然后训练一个类不可知检测器。尽管此类方法达到了当前的最佳状态，但它们往往无法正确分离2D图像空间中的重叠实例，因为只考虑了语义信息。为了解决这一问题，我们提出了一种利用场景的点云表示在3D中切割语义掩码以获得最终2D实例的方法。此外，我们还推导出一种空间重要性函数，用于沿实例的3D边界重新锐化语义信息。然而，这些伪掩码仍然容易受到掩码模糊的影响。为了应对这个问题，我们进一步建议通过增加三个空间置信度组件来增强类不可知检测器的训练，以分离干净的学习信号。凭借这些贡献，我们的方法在多个无监督实例分割和对象检测的标准基准上超越了竞争的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditionally, algorithms that learn to segment object instances in 2D imageshave heavily relied on large amounts of human-annotated data. Only recently,novel approaches have emerged tackling this problem in an unsupervised fashion.Generally, these approaches first generate pseudo-masks and then train aclass-agnostic detector. While such methods deliver the current state of theart, they often fail to correctly separate instances overlapping in 2D imagespace since only semantics are considered. To tackle this issue, we insteadpropose to cut the semantic masks in 3D to obtain the final 2D instances byutilizing a point cloud representation of the scene. Furthermore, we derive aSpatial Importance function, which we use to resharpen the semantics along the3D borders of instances. Nevertheless, these pseudo-masks are still subject tomask ambiguity. To address this issue, we further propose to augment thetraining of a class-agnostic detector with three Spatial Confidence componentsaiming to isolate a clean learning signal. With these contributions, ourapproach outperforms competing methods across multiple standard benchmarks forunsupervised instance segmentation and object detection.</description>
      <author>example@mail.com (Leon Sick, Dominik Engel, Sebastian Hartwig, Pedro Hermosilla, Timo Ropinski)</author>
      <guid isPermaLink="false">2411.16319v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DWCL: Dual-Weighted Contrastive Learning for Multi-View Clustering</title>
      <link>http://arxiv.org/abs/2411.17354v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;一种新的Dual-Weighted Contrastive Learning (DWCL)模型被提出，用于解决多视角聚类(MVCC)中现有方法的两个主要问题：高比例不可靠跨视图对和多视图表示差异带来的表示退化。&lt;h4&gt;背景&lt;/h4&gt;现有的MVCC方法通过结合任意两视图创建交叉视图来生成一致的聚类结构，这种方法导致了大量不可靠的视图对，并且忽略了不同视图之间的差异性，造成表示退化问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的DWCL模型，以减少不可靠跨视图的影响并减轻多视图间表示退化的现象。&lt;h4&gt;方法&lt;/h4&gt;引入创新的Best-Other (B-O)对比机制来增强单个视图的表现，并结合一个反映每种视图质量的视图质量权重和一个表示不同视图之间差异性的视图差异性权重，有效减少低质量和高差异交叉视图的影响。&lt;h4&gt;主要发现&lt;/h4&gt;理论验证了B-O对比机制的有效性和双权值策略在缓解多视角表示退化方面的有效性。实验表明DWCL模型在八个数据集上超越了现有方法，显示出优越的性能和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;新提出的DWCL模型在Caltech6V7和MSRCv1数据集中分别获得了比现有最佳方法5.4%和5.6%的绝对准确率提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/SHERSONH/DWCL&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view contrastive clustering (MVCC) has gained significant attention forgenerating consistent clustering structures from multiple views throughcontrastive learning. However, most existing MVCC methods create cross-views bycombining any two views, leading to a high volume of unreliable pairs.Furthermore, these approaches often overlook discrepancies in multi-viewrepresentations, resulting in representation degeneration. To address thesechallenges, we introduce a novel model called Dual-Weighted ContrastiveLearning (DWCL) for Multi-View Clustering. Specifically, to reduce the impactof unreliable cross-views, we introduce an innovative Best-Other (B-O)contrastive mechanism that enhances the representation of individual views at alow computational cost. Furthermore, we develop a dual weighting strategy thatcombines a view quality weight, reflecting the quality of each view, with aview discrepancy weight. This approach effectively mitigates representationdegeneration by downplaying cross-views that are both low in quality and highin discrepancy. We theoretically validate the efficiency of the B-O contrastivemechanism and the effectiveness of the dual weighting strategy. Extensiveexperiments demonstrate that DWCL outperforms previous methods across eightmulti-view datasets, showcasing superior performance and robustness in MVCC.Specifically, our method achieves absolute accuracy improvements of 5.4\% and5.6\% compared to state-of-the-art methods on the Caltech6V7 and MSRCv1datasets, respectively.</description>
      <author>example@mail.com (Zhihui Zhang, Xiaoshuai Hao, Hanning Yuan, Lianhua Chi, Qi Guo, Qi Li, Ziqiang Yuan, Jinhui Pang, Yexin Li, Sijie Ruan)</author>
      <guid isPermaLink="false">2411.17354v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Aleatoric Uncertainty in Object Detection via Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2411.17767v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;论文探讨了如何量化对象检测中固有的数据不确定性，并提出了一种基于视觉基础模型的数据可靠训练范式。&lt;h4&gt;背景&lt;/h4&gt;开放世界收集的大量数据不可避免地包含各种形式的随机性或噪声，导致存在不可避免的数据（aleatoric）不确定性。这种不确定性对于处理具有遮挡、模糊性和甚至有噪标签的对象检测任务尤为关键。&lt;h4&gt;目的&lt;/h4&gt;提出一种量化对象检测中固有的数据不确定性的方法，并开发了一种基于视觉基础模型的数据可靠训练范式。&lt;h4&gt;方法&lt;/h4&gt;1. 基于视觉基础模型的特征空间估计每个对象实例的数据不确定性；2. 设计了利用马氏距离度量来量化数据不确定性的方法；3. 提出了两种关键且实用的应用：一是定义不确定性感知样本过滤器以避免过拟合，二是定义样本自适应正则化器以平衡容易/困难的样本进行适应性训练。&lt;h4&gt;主要发现&lt;/h4&gt;估计出的aleatoric不确定性可以作为额外的数据注释，并能与任何模型以即插即用的方式结合使用。大量实验证明了所提出的aleatoric不确定性度量在各种先进检测模型和挑战性基准上的有效性。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一种基于视觉基础模型量化对象检测数据不确定性的方法，展示了该方法的有效性和广泛应用前景。&lt;h4&gt;翻译&lt;/h4&gt;从开放世界收集的数据不可避免地会受到各种形式的随机性和噪声的影响，导致普遍存在aleatoric（数据）不确定性。这种不确定性特别重要于目标检测中，在目标检测中，图像包含多尺度、遮挡或模糊的对象，甚至带有噪声的标注；而在分类任务中，则通常是中心化且具有相似尺度的对象。本文建议使用视觉基础模型建模并利用对象检测数据中的固有不确定性，并开发了一种以数据为中心的可靠训练范式。具体而言，我们提出基于视觉基础模型特征空间估计每个目标实例的数据不确定性的方法，这些基础模型是在超大规模数据集上训练出来的，可以表现出通用数据表示能力。特别是，我们将对象特征假设为高斯混合结构，并设计了马氏距离度量来量化数据不确定性。此外，我们建议两种关键且实用的应用：一是定义不确定性感知样本过滤器以抛弃噪声和冗余实例避免过拟合；二是定义样本自适应正则化器平衡容易/困难样本实现适应性训练。估计出的aleatoric不确定性可以作为额外的数据注释，并能与任何模型以即插即用的方式结合使用。大量实验证明了所提出的aleatoric不确定性度量在各种先进检测模型和挑战性基准上的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Datasets collected from the open world unavoidably suffer from various formsof randomness or noiseness, leading to the ubiquity of aleatoric (data)uncertainty. Quantifying such uncertainty is particularly pivotal for objectdetection, where images contain multi-scale objects with occlusion,obscureness, and even noisy annotations, in contrast to images with centric andsimilar-scale objects in classification. This paper suggests modeling andexploiting the uncertainty inherent in object detection data with visionfoundation models and develops a data-centric reliable training paradigm.Technically, we propose to estimate the data uncertainty of each objectinstance based on the feature space of vision foundation models, which aretrained on ultra-large-scale datasets and able to exhibit universal datarepresentation. In particular, we assume a mixture-of-Gaussian structure of theobject features and devise Mahalanobis distance-based measures to quantify thedata uncertainty. Furthermore, we suggest two curial and practical usages ofthe estimated uncertainty: 1) for defining uncertainty-aware sample filter toabandon noisy and redundant instances to avoid over-fitting, and 2) fordefining sample adaptive regularizer to balance easy/hard samples for adaptivetraining. The estimated aleatoric uncertainty serves as an extra level ofannotations of the dataset, so it can be utilized in a plug-and-play mannerwith any model. Extensive empirical studies verify the effectiveness of theproposed aleatoric uncertainty measure on various advanced detection models andchallenging benchmarks.</description>
      <author>example@mail.com (Peng Cui, Guande He, Dan Zhang, Zhijie Deng, Yinpeng Dong, Jun Zhu)</author>
      <guid isPermaLink="false">2411.17767v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Knowledge-aware Evolutionary Graph Neural Architecture Search</title>
      <link>http://arxiv.org/abs/2411.17339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted by Knowledge-Based Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;Graph神经架构搜索（GNAS）能够为特定的图任务或数据集定制高性能的图神经网络结构，但现有方法从零知识状态开始寻找结构时忽略了可以提高搜索效率的先验知识。研究提出利用这样的先验知识来加速在新图数据集上的多目标进化搜索，并提出了基于知识的进化GNAS（KEGNAS）。&lt;h4&gt;背景&lt;/h4&gt;现有的GNAS方法通常从零知识状态开始架构搜索，忽视了可能提升搜索效率的现有知识库中的丰富信息。知识库中包含大量结构及其多个性能指标，如准确率和参数数量。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在利用这些先验知识来加速新图数据集上的多目标进化搜索过程。&lt;h4&gt;方法&lt;/h4&gt;KEGNAS使用知识库训练一个知识模型与深度多输出高斯进程（DMOGP），快速生成并评估转移架构。知识模型首先建立数据集到结构的映射，用于生成候选转移架构；接着利用具有架构和数据集编码的DMOGP预测新数据集上候选架构的性能指标。&lt;h4&gt;主要发现&lt;/h4&gt;实证研究表明KEGNAS能迅速生成顶级性能架构，在NAS-Bench-Graph及五个真实世界数据集中分别获得比先进进化基线高4.27%的准确率和比先进可微分基线高11.54%的准确率。此外，消融实验显示使用先验知识显著改善了搜索性能。&lt;h4&gt;结论&lt;/h4&gt;KEGNAS通过利用现有知识库中的信息有效加速新图数据集上的架构搜索过程，并证明了其在提高搜索效率和性能方面的优越性。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了一种新的方法，名为基于知识的进化GNAS（KEGNAS），它旨在利用已有的知识来改进图神经网络架构的自动寻找过程。通过结合知识模型与深度多输出高斯进程，在新数据集上进行快速且高效的架构搜索，显著提升了性能并减少了计算需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/xiaofangxd/KEGNAS&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural architecture search (GNAS) can customize high-performance graphneural network architectures for specific graph tasks or datasets. However,existing GNAS methods begin searching for architectures from a zero-knowledgestate, ignoring the prior knowledge that may improve the search efficiency. Theavailable knowledge base (e.g. NAS-Bench-Graph) contains many richarchitectures and their multiple performance metrics, such as the accuracy(#Acc) and number of parameters (#Params). This study proposes exploiting suchprior knowledge to accelerate the multi-objective evolutionary search on a newgraph dataset, named knowledge-aware evolutionary GNAS (KEGNAS). KEGNAS employsthe knowledge base to train a knowledge model and a deep multi-output Gaussianprocess (DMOGP) in one go, which generates and evaluates transfer architecturesin only a few GPU seconds. The knowledge model first establishes adataset-to-architecture mapping, which can quickly generate candidate transferarchitectures for a new dataset. Subsequently, the DMOGP with architecture anddataset encodings is designed to predict multiple performance metrics forcandidate transfer architectures on the new dataset. According to the predictedmetrics, non-dominated candidate transfer architectures are selected towarm-start the multi-objective evolutionary algorithm for optimizing the #Accand #Params on a new dataset. Empirical studies on NAS-Bench-Graph and fivereal-world datasets show that KEGNAS swiftly generates top-performancearchitectures, achieving 4.27% higher accuracy than advanced evolutionarybaselines and 11.54% higher accuracy than advanced differentiable baselines. Inaddition, ablation studies demonstrate that the use of prior knowledgesignificantly improves the search performance.</description>
      <author>example@mail.com (Chao Wang, Jiaxuan Zhao, Lingling Li, Licheng Jiao, Fang Liu, Xu Liu, Shuyuan Yang)</author>
      <guid isPermaLink="false">2411.17339v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MFF-FTNet: Multi-scale Feature Fusion across Frequency and Temporal Domains for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2411.17382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MFF-FTNet是一种新颖的时间序列预测框架，旨在解决深度学习模型在处理噪声、数据稀疏性和复杂多尺度模式时遇到的问题。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测在众多领域至关重要。然而，当前的深度学习模型难以应对这些挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合对比学习和多尺度特征提取的新框架MFF-FTNet，用于改进时间序列预测性能。&lt;h4&gt;方法&lt;/h4&gt;1. 引入自适应噪声增强策略，基于原始数据的统计特性调整缩放和位移因子；
2. 设计了两个互补模块：频率感知对比学习模块(FACM)和补充时间域对比学习模块(CTCM)，前者通过频谱选择和对比学习优化光谱表示，后者利用多尺度卷积捕捉短长时依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;1. MFF-FTNet在五个真实世界数据集上进行了广泛测试；
2. 在多变量任务中，MFF-FTNet相比现有最佳模型改进了7.7%的均方误差(MSE)。&lt;h4&gt;结论&lt;/h4&gt;MFF-FTNet能有效建模复杂的时间序列模式，并处理噪声和稀疏性问题。它为长期和短期预测提供了一个全面的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;时间序列预测在众多领域至关重要，但现有的深度学习模型难以应对噪音、数据稀疏性和捕捉复杂的多尺度模式等问题。本文提出了一种结合对比学习与频域与时域多尺度特征提取的新框架MFF-FTNet。该框架引入了自适应噪声增强策略，增强了对噪音的鲁棒性。通过两个互补模块：频率感知对比学习模块和补充时间域对比学习模块来优化光谱表示并捕捉长短期依赖关系。实验结果表明，在五个真实数据集上，MFF-FTNet相比现有最佳模型在多变量任务中改进了7.7%的均方误差(MSE)。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting is crucial in many fields, yet current deep learningmodels struggle with noise, data sparsity, and capturing complex multi-scalepatterns. This paper presents MFF-FTNet, a novel framework addressing thesechallenges by combining contrastive learning with multi-scale featureextraction across both frequency and time domains. MFF-FTNet introduces anadaptive noise augmentation strategy that adjusts scaling and shifting factorsbased on the statistical properties of the original time series data, enhancingmodel resilience to noise. The architecture is built around two complementarymodules: a Frequency-Aware Contrastive Module (FACM) that refines spectralrepresentations through frequency selection and contrastive learning, and aComplementary Time Domain Contrastive Module (CTCM) that captures both short-and long-term dependencies using multi-scale convolutions and feature fusion. Aunified feature representation strategy enables robust contrastive learningacross domains, creating an enriched framework for accurate forecasting.Extensive experiments on five real-world datasets demonstrate that MFF-FTNetsignificantly outperforms state-of-the-art models, achieving a 7.7% MSEimprovement on multivariate tasks. These findings underscore MFF-FTNet'seffectiveness in modeling complex temporal patterns and managing noise andsparsity, providing a comprehensive solution for both long- and short-termforecasting.</description>
      <author>example@mail.com (Yangyang Shi, Qianqian Ren, Yong Liu, Jianguo Sun)</author>
      <guid isPermaLink="false">2411.17382v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SelfSplat: Pose-Free and 3D Prior-Free Generalizable 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2411.17190v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://gynjn.github.io/selfsplat/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;SelfSplat是一种新颖的3D高斯点云模型，旨在通过不受姿势约束和无需3D先验条件的方式从多视角图像中进行可泛化的三维重建。&lt;h4&gt;背景&lt;/h4&gt;由于缺乏真实数据、已学习到的几何信息以及在不进行微调的情况下达到准确的3D重建的需求，这类设置固有地是病态问题。这使得传统方法难以实现高质量的结果。&lt;h4&gt;目的&lt;/h4&gt;提出SelfSplat模型以解决上述挑战，并实现同时提高姿态准确性与三维重建质量的目标。&lt;h4&gt;方法&lt;/h4&gt;该模型通过有效结合显式3D表示和自我监督的深度估计及姿势估计技术，解决了缺乏准确几何信息的问题。此外，还引入了匹配感知的姿态估计网络和深度细化模块来增强跨视角之间的几何一致性，确保更精确稳定的3D重建结果。&lt;h4&gt;主要发现&lt;/h4&gt;在大规模真实世界数据集上的评估显示，SelfSplat模型在外观与几何质量方面均优于现有的最先进方法，并且展示了强大的跨数据集泛化能力。此外，广泛的应用研究和分析验证了所提出的方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;代码及预训练模型可以在https://gynjn.github.io/selfsplat/找到，用于进一步的研究。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了SelfSplat，这是一种新的3D高斯点云模型，旨在通过无姿势约束和无需3D先验条件的方式进行多视角图像的可泛化三维重建。这些设置由于缺乏真实数据、已学习到的几何信息以及在不进行微调的情况下达到准确3D重建的需求而成为病态问题，这使得传统的解决方案难以实现高质量的结果。我们的模型通过有效结合显式的3D表示和自我监督的深度估计及姿态估计技术解决了这些问题，提高了姿态精度和三维重建质量。此外，我们还集成了匹配感知的姿态估计网络和深度细化模块以增强跨视角之间的几何一致性，确保了更精确稳定的3D重建结果。为了展示我们的方法性能，我们在大规模真实世界数据集中进行了评估，包括RealEstate10K、ACID和DL3DV。SelfSplat在外观与几何质量方面均优于现有的最先进方法，并且展示了强大的跨数据集泛化能力。广泛的消融研究和分析也验证了我们所提出的方法的有效性。代码及预训练模型可以在https://gynjn.github.io/selfsplat/找到，用于进一步的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose SelfSplat, a novel 3D Gaussian Splatting model designed to performpose-free and 3D prior-free generalizable 3D reconstruction from unposedmulti-view images. These settings are inherently ill-posed due to the lack ofground-truth data, learned geometric information, and the need to achieveaccurate 3D reconstruction without finetuning, making it difficult forconventional methods to achieve high-quality results. Our model addresses thesechallenges by effectively integrating explicit 3D representations withself-supervised depth and pose estimation techniques, resulting in reciprocalimprovements in both pose accuracy and 3D reconstruction quality. Furthermore,we incorporate a matching-aware pose estimation network and a depth refinementmodule to enhance geometry consistency across views, ensuring more accurate andstable 3D reconstructions. To present the performance of our method, weevaluated it on large-scale real-world datasets, including RealEstate10K, ACID,and DL3DV. SelfSplat achieves superior results over previous state-of-the-artmethods in both appearance and geometry quality, also demonstrates strongcross-dataset generalization capabilities. Extensive ablation studies andanalysis also validate the effectiveness of our proposed methods. Code andpretrained models are available at https://gynjn.github.io/selfsplat/</description>
      <author>example@mail.com (Gyeongjin Kang, Jisang Yoo, Jihyeon Park, Seungtae Nam, Hyeonsoo Im, Sangheon Shin, Sangpil Kim, Eunbyung Park)</author>
      <guid isPermaLink="false">2411.17190v3</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Words Matter: Leveraging Individual Text Embeddings for Code Generation in CLIP Test-Time Adaptation</title>
      <link>http://arxiv.org/abs/2411.17002v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用类别文本信息来缓解大型预训练视觉语言模型在测试时遇到的分布漂移问题的方法。&lt;h4&gt;背景&lt;/h4&gt;现有的vision-language基础模型，如CLIP，在各种任务上表现出色，但它们可能在数据分布发生变化时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;研究如何有效利用类别文本信息以减轻大规模预训练视觉语言模型在测试推理阶段所遇到的分布漂移问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种通过生成伪标签来解决这一问题的方法。该方法使用通用类文本嵌入作为固定中心，高效地解决了最优传输中的标签分配问题。此外，还提出了CLIP-OT自适应方法，它整合了多模板知识蒸馏策略，实现了多视图对比学习策略，但无需增加额外的计算复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在多个流行的测试时间适配基准上，CLIP-OT的表现优于最新的SOTA方法，性能提高了高达7%，且在计算和内存效率方面表现优异。&lt;h4&gt;结论&lt;/h4&gt;该研究成功地提出了一种有效的方法来缓解视觉语言模型的分布漂移问题，并证明了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;本文探讨了如何利用类别文本信息以减轻大型预训练视觉语言模型（VLMs）在测试时遇到的数据分布变化的影响。通过生成伪标签和优化传输，以及应用多模板知识蒸馏策略，提高了模型的适应性表现，在多个基准测试中取得了显著优于现有最佳方法的结果，并且保持了高效的计算资源利用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ShambhaviCodes/CLIPOT&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language foundation models, such as CLIP, have shown unprecedentedzero-shot performance across a wide range of tasks. Nevertheless, these modelsmay be unreliable under distributional shifts, as their performance issignificantly degraded. In this work, we explore how to efficiently leverageclass text information to mitigate these distribution drifts encountered bylarge pre-trained vision-language models (VLMs) during test-time inference. Inparticular, we propose to generate pseudo-labels for the test-time samples byexploiting generic class text embeddings as fixed centroids of a labelassignment problem, which is efficiently solved with Optimal Transport.Furthermore, the proposed adaptation method (CLIP-OT) integrates a multipletemplate knowledge distillation approach, which replicates multi-viewcontrastive learning strategies in unsupervised representation learning butwithout incurring additional computational complexity. Extensive experiments onmultiple popular test-time adaptation benchmarks presenting diverse complexityempirically show the superiority of CLIP-OT, achieving performance gains of upto 7% over recent state-of-the-art methods, yet being computationally andmemory efficient.</description>
      <author>example@mail.com (Shambhavi Mishra, Julio Silva-Rodrıguez, Ismail Ben Ayed, Marco Pedersoli, Jose Dolz)</author>
      <guid isPermaLink="false">2411.17002v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Epidemiology-informed Graph Neural Network for Heterogeneity-aware Epidemic Forecasting</title>
      <link>http://arxiv.org/abs/2411.17372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 6 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的流行病预测框架HeatGNN，该框架结合了流行病学机制模型和图神经网络（GNN），旨在捕捉不同地理位置间流行的异质性，并实现更准确的流行病预测。&lt;h4&gt;背景&lt;/h4&gt;在各种时空预测任务中，流行病预测对于公共卫生管理至关重要。研究表明，时空图神经网络（STGNN）具有提取复杂时空模式的强大潜力，但现有的方法过于简化了疾病传播机制的空间和时间差异。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够捕捉流行病内在进化机制的异质性的新型流行病预测框架HeatGNN。&lt;h4&gt;方法&lt;/h4&gt;通过将流行病学机制模型与图神经网络相结合，HeatGNN学习各个位置随时间变化的传播机制，并设计了一种异构传播图网络来编码不同地点之间的机制差异。利用基于流行病学信息的位置嵌入计算出的时间变化机制相似性图。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，HeatGNN在三个基准数据集上的表现优于各种强大的基线模型。此外，效率分析证实了该框架在不同规模的数据集上具有现实世界的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;HeatGNN通过结合流行病学知识和时空图神经网络技术，在准确预测流行病扩散方面展示了显著的优势，并且具备实际应用的高效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Among various spatio-temporal prediction tasks, epidemic forecasting plays acritical role in public health management. Recent studies have demonstrated thestrong potential of spatio-temporal graph neural networks (STGNNs) inextracting heterogeneous spatio-temporal patterns for epidemic forecasting.However, most of these methods bear an over-simplified assumption that twolocations (e.g., cities) with similar observed features in previous time stepswill develop similar infection numbers in the future. In fact, for any epidemicdisease, there exists strong heterogeneity of its intrinsic evolutionmechanisms across geolocation and time, which can eventually lead to divergedinfection numbers in two ``similar'' locations. However, such mechanisticheterogeneity is non-trivial to be captured due to the existence of numerousinfluencing factors like medical resource accessibility, virus mutations,mobility patterns, etc., most of which are spatio-temporal yet unreachable oreven unobservable. To address this challenge, we propose a HeterogeneousEpidemic-Aware Transmission Graph Neural Network (HeatGNN), a novel epidemicforecasting framework. By binding the epidemiology mechanistic model into aGNN, HeatGNN learns epidemiology-informed location embeddings of differentlocations that reflect their own transmission mechanisms over time. With thetime-varying mechanistic affinity graphs computed with theepidemiology-informed location embeddings, a heterogeneous transmission graphnetwork is designed to encode the mechanistic heterogeneity among locations,providing additional predictive signals to facilitate accurate forecasting.Experiments on three benchmark datasets have revealed that HeatGNN outperformsvarious strong baselines. Moreover, our efficiency analysis verifies thereal-world practicality of HeatGNN on datasets of different sizes.</description>
      <author>example@mail.com (Yufan Zheng, Wei Jiang, Alexander Zhou, Nguyen Quoc Viet Hung, Choujun Zhan, Tong Chen)</author>
      <guid isPermaLink="false">2411.17372v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Curvature Informed Furthest Point Sampling</title>
      <link>http://arxiv.org/abs/2411.16995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;点云表示因其高效的内存使用和获取、操作及存储的简单性而受到青睐。然而，随着点云规模的增长，有效的降采样变得至关重要以满足下游任务的计算需求。&lt;h4&gt;背景&lt;/h4&gt;经典的降采样方法如最远点采样（FPS）在基准测试中表现良好但依赖于启发式策略，并且忽略了几何特征（例如曲率）。&lt;h4&gt;目的&lt;/h4&gt;本文引入了一种基于强化学习的采样算法，通过整合曲率信息来改进FPS。&lt;h4&gt;方法&lt;/h4&gt;我们的方法结合了来自FPS的软排名与由深度神经网络计算出的曲率得分，允许我们用未选中的高曲率点替换部分低曲率点。此外，这种方法实现了稳定端到端学习，并且在多个下游几何处理任务中持续优于基线模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过综合消融研究，展示了每个特征对性能的影响。我们的算法为分类、分割和形状完成建立了最新的结果，证明了其鲁棒性和适应性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够更好地利用曲率信息进行点云降采样，并且在端到端学习中表现出稳定性和优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;点云表示因其高效的内存使用以及获取、操作和存储的简便性而受到重视。然而，随着点云规模的增长，有效的下采样成为了处理下游任务计算需求的关键。传统方法如最远点采样（FPS）在基准测试中表现良好，但依赖于启发式策略，并且忽视了曲率等几何特征。本文提出了一种基于强化学习的采样算法，通过结合来自FPS的软排名和深度神经网络计算出的曲率得分来改进FPS方法。此法允许我们用未选择集中的高曲率点替换FPS结果中的一部分低曲率点。现有的可微分采样技术往往面临训练不稳定的问题，阻碍了它们在端到端学习框架中的应用。相比之下，我们的方法实现了稳定的端到端学习，并在多个下游几何处理任务中持续优于基线模型。通过全面的消融研究，我们提供了关于每种特征对性能影响的定性和定量见解。我们的算法在分类、分割和形状完成等方面建立了最新的结果，展示了其鲁棒性和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud representation has gained traction due to its efficient memoryusage and simplicity in acquisition, manipulation, and storage. However, aspoint cloud sizes increase, effective down-sampling becomes essential toaddress the computational requirements of downstream tasks. Classicalapproaches, such as furthest point sampling (FPS), perform well on benchmarksbut rely on heuristics and overlook geometric features, like curvature, duringdown-sampling.  In this paper, We introduce a reinforcement learning-based sampling algorithmthat enhances FPS by integrating curvature information. Our approach rankspoints by combining FPS-derived soft ranks with curvature scores computed by adeep neural network, allowing us to replace a proportion of low-curvaturepoints in the FPS set with high-curvature points from the unselected set.Existing differentiable sampling techniques often suffer from traininginstability, hindering their integration into end-to-end learning frameworks.By contrast, our method achieves stable end-to-end learning, consistentlyoutperforming baseline models across multiple downstream geometry processingtasks. We provide comprehensive ablation studies, with both qualitative andquantitative insights into the effect of each feature on performance. Ouralgorithm establishes state-of-the-art results for classification, segmentationand shape completion, showcasing its robustness and adaptability.</description>
      <author>example@mail.com (Shubham Bhardwaj, Ashwin Vinod, Soumojit Bhattacharya, Aryan Koganti, Aditya Sai Ellendula, Balakrishna Reddy)</author>
      <guid isPermaLink="false">2411.16995v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Reward Incremental Learning in Text-to-Image Generation</title>
      <link>http://arxiv.org/abs/2411.17310v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;这篇论文提出了Reward Incremental Learning（RIL）的概念，这是一个更现实且未被探索的问题，即模型需要逐渐适应多个下游目标。针对在扩散模型微调中出现的独特形式的灾难性遗忘问题，作者提出了一种名为Reward Incremental Distillation (RID)的方法来减轻这种遗忘现象。&lt;h4&gt;背景&lt;/h4&gt;现有基于奖励梯度的策略在单个任务中表现出色，但在现实世界场景下由于需要适应随着时间逐渐增加的多个目标而受到限制。&lt;h4&gt;目的&lt;/h4&gt;定义并解决在文本到图像生成模型中逐渐学习和调整至多重下游目标的问题，并提出一种有效的方法来减轻微调过程中的灾难性遗忘问题。&lt;h4&gt;方法&lt;/h4&gt;提出了Reward Incremental Distillation (RID) 方法，该方法旨在通过最小的计算开销缓解灾难性遗忘现象，从而保证在顺序奖励任务中稳定性能。&lt;h4&gt;主要发现&lt;/h4&gt;RID方法可以显著提高模型适应多目标增量学习的能力，并保持高质量图像生成的一致性和稳定性。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明RID方法有效解决了Reward Incremental Learning（RIL）中的问题，实现了持续一致的高性能图像生成。&lt;h4&gt;翻译&lt;/h4&gt;最近去噪扩散模型在文本到图像生成方面的成功显著推动了该领域的发展。虽然大规模预训练模型在一般图像合成方面表现出色，但下游任务通常需要微调以满足特定标准如美学或人类偏好。基于奖励梯度的方法在此背景下具有前景，然而现有方法仅限于单个奖励任务，限制了其在现实场景中的应用能力，这些场景要求适应随时间逐渐引入的多个目标。本文首次定义了一个更实际且未被探索的问题：Reward Incremental Learning（RIL），其中模型需要逐步适应多种下游目标。此外，在模型适应不断出现的新目标时，我们观察到了扩散模型微调中的一种独特形式的灾难性遗忘现象，这影响了图像的质量和视觉结构。为了解决这种灾难性遗忘问题，我们提出了一种Reward Incremental Distillation（RID）方法，该方法通过最小计算开销减轻遗忘现象，使模型在顺序奖励任务中能够保持稳定性能。实验结果表明RID在RIL场景下实现了持续高质量生成的有效性。我们的工作源代码将在接受后公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent success of denoising diffusion models has significantly advancedtext-to-image generation. While these large-scale pretrained models showexcellent performance in general image synthesis, downstream objectives oftenrequire fine-tuning to meet specific criteria such as aesthetics or humanpreference. Reward gradient-based strategies are promising in this context, yetexisting methods are limited to single-reward tasks, restricting theirapplicability in real-world scenarios that demand adapting to multipleobjectives introduced incrementally over time. In this paper, we first definethis more realistic and unexplored problem, termed Reward Incremental Learning(RIL), where models are desired to adapt to multiple downstream objectivesincrementally. Additionally, while the models adapt to the ever-emerging newobjectives, we observe a unique form of catastrophic forgetting in diffusionmodel fine-tuning, affecting both metric-wise and visual structure-wise imagequality. To address this catastrophic forgetting challenge, we propose RewardIncremental Distillation (RID), a method that mitigates forgetting with minimalcomputational overhead, enabling stable performance across sequential rewardtasks. The experimental results demonstrate the efficacy of RID in achievingconsistent, high-quality generation in RIL scenarios. The source code of ourwork will be publicly available upon acceptance.</description>
      <author>example@mail.com (Maorong Wang, Jiafeng Mao, Xueting Wang, Toshihiko Yamasaki)</author>
      <guid isPermaLink="false">2411.17310v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>k2SSL: A Faster and Better Framework for Self-Supervised Speech Representation Learning</title>
      <link>http://arxiv.org/abs/2411.17100v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;自监督学习（SSL）在语音相关任务中取得了显著成功，特别是在自动语音识别（ASR）领域。该研究提出了一种新的开放源代码框架k2SSL，旨在通过优化的HuBERT和基于Zipformer的系统来实现更快、更内存高效的自我监督语音表示学习。&lt;h4&gt;背景&lt;/h4&gt;自监督学习方法在语音任务中已经取得了重大进展，主要得益于新型编码器架构（如Transformer和Conformer）的发展以及训练数据集的增长。然而，虽然这些架构已经在SSL模型中占主导地位，但专门为ASR设计的Zipformer尚未被应用于这种类型的框架。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的开放源代码框架k2SSL，以解决现有SSL训练框架中的效率问题，并提供更优的性能、更快的速度和更低的内存使用。同时，此研究聚焦于通过自监督学习提升下游ASR任务的表现。&lt;h4&gt;方法&lt;/h4&gt;采用优化后的HuBERT模型以及基于Zipformer的SSL系统来改进数据处理流程并提高计算资源的利用率。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，与现有的其他系统相比（如HuBERT和WavLM），基于Zipformer的SSL系统的性能显著提升，在LibriSpeech和Libri-Light数据集上的相对错误单词率（WER）降低最多达34.8% / 32.4%，且预训练速度提高了3.5倍。&lt;h4&gt;结论&lt;/h4&gt;提出的k2SSL框架及其应用中的基于Zipformer的自监督学习系统不仅在性能上优于现有解决方案，而且还能更高效地利用计算资源。这为改进自动语音识别任务提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has achieved great success in speech-relatedtasks, driven by advancements in speech encoder architectures and the expansionof datasets. While Transformer and Conformer architectures have dominated SSLbackbones, encoders like Zipformer, which excel in automatic speech recognition(ASR), remain unexplored in SSL. Concurrently, inefficiencies in dataprocessing within existing SSL training frameworks, such as fairseq, posechallenges in managing the growing volumes of training data. To address theseissues, we propose k2SSL, an open-source framework that offers faster, morememory-efficient, and better-performing self-supervised speech representationlearning, with a focus on downstream ASR tasks. The optimized HuBERT andproposed Zipformer-based SSL systems exhibit substantial reductions in bothtraining time and memory usage during SSL training. Experiments on LibriSpeechand Libri-Light demonstrate that Zipformer-based SSL systems significantlyoutperform comparable HuBERT and WavLM systems, achieving a relative WERreduction on dev-other/test-other of up to 34.8%/32.4% compared to HuBERT Baseafter supervised fine-tuning, along with a 3.5x pre-training speedup in totalGPU hours.</description>
      <author>example@mail.com (Yifan Yang, Jianheng Zhuo, Zengrui Jin, Ziyang Ma, Xiaoyu Yang, Zengwei Yao, Liyong Guo, Wei Kang, Fangjun Kuang, Long Lin, Daniel Povey, Xie Chen)</author>
      <guid isPermaLink="false">2411.17100v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Rewiring Techniques to Mitigate Oversquashing and Oversmoothing in GNNs: A Survey</title>
      <link>http://arxiv.org/abs/2411.17429v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了图神经网络（GNN）在处理图结构数据时面临的关键挑战，特别是信息过度压缩和过度平滑问题，并探讨了解决这些问题的图重连技术。&lt;h4&gt;背景&lt;/h4&gt;GNNs是处理图结构数据的强大工具，但由于图拓扑结构中的两个关键挑战——信息过度压缩与过度平滑，其性能受到了限制。这两个问题是由于节点间的信息传递受限以及长时间迭代后的表示同质化所导致。&lt;h4&gt;目的&lt;/h4&gt;通过修改图的拓扑结构来改善信息扩散，以解决GNN面临的结构性瓶颈问题，并提高网络的表现力。&lt;h4&gt;方法&lt;/h4&gt;综述了当前最先进的图重连技术，深入探讨了这些技术背后的理论基础、实际实现以及性能上的权衡。&lt;h4&gt;主要发现&lt;/h4&gt;无特定提及的主要研究发现，但通过综述总结出了各种图重连技术的优缺点及其适用场景。&lt;h4&gt;结论&lt;/h4&gt;强调了解决GNN中信息过度压缩与过度平滑问题的重要性，并指出未来的研究方向在于进一步优化图重连方法以提升模型性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了Graph Neural Networks (GNNs) 在处理图形结构化数据中的挑战，包括信息过度压缩和过度平滑。这些问题阻碍了信息的流通并限制了GNN的表现力。本文综述了改进图拓扑结构来解决这些瓶颈的一系列方法，并对其理论基础、实施细节及性能权衡进行了全面审查。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are powerful tools for learning fromgraph-structured data, but their effectiveness is often constrained by twocritical challenges: oversquashing, where the excessive compression ofinformation from distant nodes results in significant information loss, andoversmoothing, where repeated message-passing iterations homogenize noderepresentations, obscuring meaningful distinctions. These issues, intrinsicallylinked to the underlying graph structure, hinder information flow and constrainthe expressiveness of GNNs. In this survey, we examine graph rewiringtechniques, a class of methods designed to address these structural bottlenecksby modifying graph topology to enhance information diffusion. We provide acomprehensive review of state-of-the-art rewiring approaches, delving intotheir theoretical underpinnings, practical implementations, and performancetrade-offs.</description>
      <author>example@mail.com (Hugo Attali, Davide Buscaldi, Nathalie Pernelle)</author>
      <guid isPermaLink="false">2411.17429v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>D$^2$-World: An Efficient World Model through Decoupled Dynamic Flow</title>
      <link>http://arxiv.org/abs/2411.17027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The 2nd Place and Innovation Award Solution of Predictive World Model
  at the CVPR 2024 Autonomous Grand Challenge&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;D$^2$-World是一种新的世界模型，用于有效预测未来的点云。&lt;h4&gt;背景&lt;/h4&gt;该技术报告总结了CVPR-2024自主系统基础模型研讨会举办的PredictiveWorld Model Challenge的第二名解决方案。使用现有的占用网络（如BEVDet）获取过去的语义占用。&lt;h4&gt;目的&lt;/h4&gt;通过引入D$^2$-World世界模型，简化预测未来点云的任务并提高性能。&lt;h4&gt;方法&lt;/h4&gt;1. 使用现有占位网络得到过去语义占位；
2. 将占据结果作为单阶段世界模型的输入，生成未来的占用；
3. 在世界模型中执行动态体素解耦以进一步简化任务；
4. 通过体素流扭曲现有的观察来生成未来动态体素，而静态体素则可以通过姿态变换轻松获得。&lt;h4&gt;主要发现&lt;/h4&gt;D$^2$-World在OpenScene Predictive World Model基准测试上实现了最先进的性能，并且训练速度比基线模型快300%以上。&lt;h4&gt;结论&lt;/h4&gt;该方法通过引入D$^2$-World世界模型，不仅提高了预测未来点云的准确性，还大大加快了训练时间。&lt;h4&gt;翻译&lt;/h4&gt;此技术报告总结了CVPR-2024自主系统基础模型研讨会举办的Predictive World Model Challenge的第二名解决方案。我们介绍了D$^2$-World，这是一种通过解耦动态流有效预测未来点云的新世界模型。特别地，首先使用现有占用网络（如BEVDet）获得过去语义占位。随后，占据结果作为单阶段世界模型的输入，生成未来的非自回归方式的占用。为了进一步简化任务，在该模型中执行动态体素解耦。通过将现有观察通过体素流进行变形来产生未来动态体素，而静态体素则可以通过姿态变换轻松获得。因此，我们的方法在OpenScene Predictive World Model基准测试上实现了最先进的性能，并且训练速度比基线模型快300%以上。代码可在https://github.com/zhanghm1995/D2-World获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhanghm1995/d2-world&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This technical report summarizes the second-place solution for the PredictiveWorld Model Challenge held at the CVPR-2024 Workshop on Foundation Models forAutonomous Systems. We introduce D$^2$-World, a novel World model thateffectively forecasts future point clouds through Decoupled Dynamic flow.Specifically, the past semantic occupancies are obtained via existing occupancynetworks (e.g., BEVDet). Following this, the occupancy results serve as theinput for a single-stage world model, generating future occupancy in anon-autoregressive manner. To further simplify the task, dynamic voxeldecoupling is performed in the world model. The model generates future dynamicvoxels by warping the existing observations through voxel flow, while remainingstatic voxels can be easily obtained through pose transformation. As a result,our approach achieves state-of-the-art performance on the OpenScene PredictiveWorld Model benchmark, securing second place, and trains more than 300% fasterthan the baseline model. Code is available athttps://github.com/zhanghm1995/D2-World.</description>
      <author>example@mail.com (Haiming Zhang, Xu Yan, Ying Xue, Zixuan Guo, Shuguang Cui, Zhen Li, Bingbing Liu)</author>
      <guid isPermaLink="false">2411.17027v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>vesselFM: A Foundation Model for Universal 3D Blood Vessel Segmentation</title>
      <link>http://arxiv.org/abs/2411.17386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个专门用于3D血管分割的基础模型vesselFM，该模型在不同的数据源上进行训练，并且可以在零样本、少量样本和小量样本场景下表现优于现有的医学图像分割基础模型。&lt;h4&gt;背景&lt;/h4&gt;三维血管的分割是医疗影像分析中的重要任务。由于成像模式特异性的变化以及成像协议的不同导致了领域差距，现有基于监督学习的方法难以泛化。&lt;h4&gt;目的&lt;/h4&gt;提出一个能够有效应对不同数据域且无需大规模注释的数据集的基础模型vesselFM。&lt;h4&gt;方法&lt;/h4&gt;训练vesselFM使用三种不同的数据来源：大量注释过的数据集、通过领域随机化方案生成的数据和从基于流匹配的生成模型中采样的数据。&lt;h4&gt;主要发现&lt;/h4&gt;在零样本、少量样本和小量样本场景下，vesselFM的表现优于现有的医学图像分割基础模型，在四个临床相关的成像模式上均表现出色。&lt;h4&gt;结论&lt;/h4&gt;vesselFM提供了一种通用解决方案，适用于各种不同的3D血管分割任务，无需为每个数据集单独进行繁琐的像素级别标注。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Segmenting 3D blood vessels is a critical yet challenging task in medicalimage analysis. This is due to significant imaging modality-specific variationsin artifacts, vascular patterns and scales, signal-to-noise ratios, andbackground tissues. These variations, along with domain gaps arising fromvarying imaging protocols, limit the generalization of existing supervisedlearning-based methods, requiring tedious voxel-level annotations for eachdataset separately. While foundation models promise to alleviate thislimitation, they typically fail to generalize to the task of blood vesselsegmentation, posing a unique, complex problem. In this work, we presentvesselFM, a foundation model designed specifically for the broad task of 3Dblood vessel segmentation. Unlike previous models, vesselFM can effortlesslygeneralize to unseen domains. To achieve zero-shot generalization, we trainvesselFM on three heterogeneous data sources: a large, curated annotateddataset, data generated by a domain randomization scheme, and data sampled froma flow matching-based generative model. Extensive evaluations show thatvesselFM outperforms state-of-the-art medical image segmentation foundationmodels across four (pre-)clinically relevant imaging modalities in zero-, one-,and few-shot scenarios, therefore providing a universal solution for 3D bloodvessel segmentation.</description>
      <author>example@mail.com (Bastian Wittmann, Yannick Wattenberg, Tamaz Amiranashvili, Suprosanna Shit, Bjoern Menze)</author>
      <guid isPermaLink="false">2411.17386v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Graph Neural Network deep-dive into successful counterattacks</title>
      <link>http://arxiv.org/abs/2411.17450v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 11 figures, first submitted (and accepted) at MIT Sloan
  Sports Analytics Conference 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过构建性别特定的图神经网络模型来预测足球比赛中反击成功的可能性，并揭示了影响反攻成功的关键因素。&lt;h4&gt;背景&lt;/h4&gt;在足球中，当球队从防守状态转变为进攻状态并重新获得控球权时可能发生高速、高强度的直接攻击（即反击），目的是利用最少的传球覆盖大量空间从而创造得分机会。&lt;h4&gt;目的&lt;/h4&gt;研究旨在构建性别特定的图神经网络模型来预测反攻的成功几率，并探索影响其成功的关键因素。&lt;h4&gt;方法&lt;/h4&gt;使用来自MLS、NWSL和国际足球比赛的20863帧同步有球事件及时空追踪数据训练模型。这些数据涵盖了2022年以及2020年至2022年的国际赛事，共涉及632场比赛的数据。&lt;h4&gt;主要发现&lt;/h4&gt;性别特定图神经网络在预测反攻成功方面优于相同架构的性别模糊模型；利用排列特征重要性技术揭示了影响成功的节点特征包括边线到边线速度、射门角度、接球角度和场地宽度内的速度等。此外，还提供了如何导航无限解空间以帮助识别改进球员决策方法的例子。&lt;h4&gt;结论&lt;/h4&gt;这项研究通过开放源代码库以及将时空数据转换为图的Python包来促进成果的验证与复制。该工具简化了对反攻成功因素的研究，并有助于进一步改善训练及比赛中的战术决策。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A counterattack in soccer is a high speed, high intensity direct attack thatcan occur when a team transitions from a defensive state to an attacking stateafter regaining possession of the ball. The aim is to create a goal-scoringopportunity by convering a lot of ground with minimal passes before theopposing team can recover their defensive shape. The purpose of this researchis to build gender-specific Graph Neural Networks to model the likelihood of acounterattack being successful and uncover what factors make them successful inprofessional soccer. These models are trained on a total of 20863 frames ofsynchronized on-ball event and spatiotemporal (broadcast) tracking data. Thisdataset is derived from 632 games of MLS (2022), NWSL (2022) and internationalsoccer (2020-2022). With this data we demonstrate that gender-specific GraphNeural Networks outperform architecturally identical gender-ambiguous models inpredicting the successful outcome of counterattacks. We show, using PermutationFeature Importance, that byline to byline speed, angle to the goal, angle tothe ball and sideline to sideline speed are the node features with the highestimpact on model performance. Additionally, we offer some illustrative exampleson how to navigate the infinite solution search space to aid in identifyingimprovements for player decision making.  This research is accompanied by an open-source repository containing all dataand code, and it is also accompanied by an open-source Python package whichsimplifies converting spatiotemporal data into graphs. This package alsofacilitates testing, validation, training and prediction with this data. Thisshould allow the reader to replicate and improve upon our research more easily.</description>
      <author>example@mail.com (Joris Bekkers, Amod Sahasrabudhe)</author>
      <guid isPermaLink="false">2411.17450v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>X-MeshGraphNet: Scalable Multi-Scale Graph Neural Networks for Physics Simulation</title>
      <link>http://arxiv.org/abs/2411.17164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;图神经网络（GNNs）在模拟复杂物理系统中得到了广泛应用，例如MeshGraphNet模型在不规则网格上表现出色。然而，这些模型面临一些限制，包括可扩展性问题、推理时需要网格划分的依赖以及处理长距离相互作用的挑战。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）已经在模拟复杂物理系统中显示出强大的能力，尤其是在使用像MeshGraphNet这样的模型时表现优异。但是，现有的GNN模型存在诸如可扩展性不佳、推理阶段必须生成网格等问题，并且在处理长程相互作用方面也存在问题。&lt;h4&gt;目的&lt;/h4&gt;提出X-MeshGraphNet，旨在解决现有图神经网络中存在的问题，包括但不限于可伸缩性瓶颈和对模拟网格的依赖。通过设计一种多尺度的解决方案来改善模型性能并扩大其应用范围。&lt;h4&gt;方法&lt;/h4&gt;{'可扩展性的提升': '通过划分大型图并将halo区域（即相邻分区之间的过渡区）引入以实现信息在不同分区间的顺畅传递，从而克服了可伸缩性瓶颈。此外还结合梯度聚合确保跨分区训练与处理整个图时的训练效果一致。', '消除网格依赖': 'X-MeshGraphNet通过直接从CAD文件生成点云（均匀分布在物体表面或体积上），并连接最近邻节点来构建自定义图形，从而去除对模拟网格的依赖。此外，该模型通过迭代组合粗粒度和细粒度点云构建多尺度图。', '增强长程相互作用': '通过逐级细化的方式建立多层次结构，以促进长期距离交互的有效处理，提升复杂物理系统的建模能力。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'性能保持': 'X-MeshGraphNet在保持与全图GNN模型相同预测准确性的同时，大大提高了可扩展性和灵活性。', '实时模拟': '该方法消除了推理阶段生成网格的必要性，并提供了一种实用解决方案以实现跨多种应用的真实时间模拟。'}&lt;h4&gt;结论&lt;/h4&gt;X-MeshGraphNet通过创新的方法解决了现有图神经网络模型的关键挑战，在复杂系统仿真领域开辟了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络（GNNs）在模拟复杂物理系统方面获得了广泛应用，特别是在使用MeshGraphNet等模型时表现出色。然而，这些模型面临着可扩展性差、推理阶段依赖网格生成以及处理长程相互作用的挑战。为解决这些问题，本文介绍了一种名为X-MeshGraphNet的新方法，它是一种可扩展且多尺度增强版MeshGraphNet设计，旨在克服上述困难。该方法通过划分大型图并引入halo区域实现信息在不同分区间的顺畅传递，并结合梯度聚合确保跨分区训练与处理整个图时的等效性；此外还直接从CAD文件生成点云构建自定义图形以消除对网格的需求，同时使用多尺度点云迭代组合来改善长程相互作用。实验结果表明，X-MeshGraphNet在保持全图GNN模型预测准确性的同时显著提高了可扩展性和灵活性，解决了推理阶段的网格生成难题，并为广泛的应用提供了真实时间模拟方案。相关代码可在NVIDIA Modulus项目中找到：github.com/NVIDIA/modulus/tree/main/examples/cfd/xaeronet&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nvidia/modulus&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have gained significant traction for simulatingcomplex physical systems, with models like MeshGraphNet demonstrating strongperformance on unstructured simulation meshes. However, these models faceseveral limitations, including scalability issues, requirement for meshing atinference, and challenges in handling long-range interactions. In this work, weintroduce X-MeshGraphNet, a scalable, multi-scale extension of MeshGraphNetdesigned to address these challenges.  X-MeshGraphNet overcomes the scalability bottleneck by partitioning largegraphs and incorporating halo regions that enable seamless message passingacross partitions. This, combined with gradient aggregation, ensures thattraining across partitions is equivalent to processing the entire graph atonce. To remove the dependency on simulation meshes, X-MeshGraphNet constructscustom graphs directly from CAD files by generating uniform point clouds on thesurface or volume of the object and connecting k-nearest neighbors.Additionally, our model builds multi-scale graphs by iteratively combiningcoarse and fine-resolution point clouds, where each level refines the previous,allowing for efficient long-range interactions.  Our experiments demonstrate that X-MeshGraphNet maintains the predictiveaccuracy of full-graph GNNs while significantly improving scalability andflexibility. This approach eliminates the need for time-consuming meshgeneration at inference, offering a practical solution for real-time simulationacross a wide range of applications. The code for reproducing the resultspresented in this paper is available through NVIDIA Modulus:github.com/NVIDIA/modulus/tree/main/examples/cfd/xaeronet.</description>
      <author>example@mail.com (Mohammad Amin Nabian)</author>
      <guid isPermaLink="false">2411.17164v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Using different sources of ground truths and transfer learning to improve the generalization of photometric redshift estimation</title>
      <link>http://arxiv.org/abs/2411.18054v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures, 2 tables, accepted to NeurIPS 2024 Workshop
  ML4PS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了通过结合不同的地面真实数据来改进星系红移预测的方法。&lt;h4&gt;背景&lt;/h4&gt;传统机器学习模型依赖于具有已知光谱红移的训练集，这些数据虽然精确但只能代表有限数量的星系样本。为使红移模型适用于更广泛的星系群体，作者研究了迁移学习以及直接结合来自测光和光谱的数据方法。&lt;h4&gt;目的&lt;/h4&gt;通过使用COSMOS2020调查创建一个名为TransferZ的数据库，并在此基础上探索如何利用迁移学习或数据组合提高红移预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 使用COSMOS2020调查建立包含35个成像滤波器测光红移估计值的数据集（TransferZ），该数据集比仅基于光谱样本更广泛，但精度较低。       2. 利用具有更高精确度的光谱红移星系数据集（GalaxiesML）对初始模型进行微调。       3. 在同时包括TransferZ和GalaxiesML的数据集上训练神经网络。&lt;h4&gt;主要发现&lt;/h4&gt;通过迁移学习或直接结合不同来源的地面真实数据，可以显著减少预测误差、偏置以及灾难性异常值的发生率。但当评估方法应用于仅基于测光红移估计值（如TransferZ）时，其性能有所下降。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，上述策略能够满足宇宙学需求，并展示了改进星系红移预测的新路径。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们探索了通过结合不同的地面真实数据来改善星系红移预测的方法。传统的机器学习模型依赖于具有已知光谱红移的训练集，这些是精确但仅代表有限数量的星系样本。为了使红移模型更具泛化能力以适用于更广泛的星系群体，我们研究了迁移学习以及直接结合来自测光和光谱的数据方法。我们使用COSMOS2020调查创建了一个名为TransferZ的数据集，该数据集包含利用多达35个成像滤波器通过模板拟合得到的测光红移估计值。虽然其红移估计值不如基于光谱样本精确，但该数据集涵盖了更多类型的星系和颜色范围。我们首先在TransferZ上训练一个基础神经网络，然后使用更精准光谱红移的数据集GalaxiesML进行迁移学习微调；同时也在结合了TransferZ和GalaxiesML的组合数据集上训练了一个独立的神经网络。这两种方法都显著减少了预测模型与基准模型（仅基于TransferZ）在GalaxiesML上的偏差约5倍，均方根误差减少1.5倍，并且灾难性异常值发生率降低了1.3倍；然而，在评估时使用测光红移估计的数据集TransferZ的性能有所下降。总体而言，我们的结果证明了这些方法能够满足宇宙学需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we explore methods to improve galaxy redshift predictions bycombining different ground truths. Traditional machine learning models rely ontraining sets with known spectroscopic redshifts, which are precise but onlyrepresent a limited sample of galaxies. To make redshift models moregeneralizable to the broader galaxy population, we investigate transferlearning and directly combining ground truth redshifts derived from photometryand spectroscopy. We use the COSMOS2020 survey to create a dataset, TransferZ,which includes photometric redshift estimates derived from up to 35 imagingfilters using template fitting. This dataset spans a wider range of galaxytypes and colors compared to spectroscopic samples, though its redshiftestimates are less accurate. We first train a base neural network on TransferZand then refine it using transfer learning on a dataset of galaxies with moreprecise spectroscopic redshifts (GalaxiesML). In addition, we train a neuralnetwork on a combined dataset of TransferZ and GalaxiesML. Both methods reducebias by $\sim$ 5x, RMS error by $\sim$ 1.5x, and catastrophic outlier rates by1.3x on GalaxiesML, compared to a baseline trained only on TransferZ. However,we also find a reduction in performance for RMS and bias when evaluated onTransferZ data. Overall, our results demonstrate these approaches can meetcosmological requirements.</description>
      <author>example@mail.com (Jonathan Soriano, Srinath Saikrishnan, Vikram Seenivasan, Bernie Boscoe, Jack Singal, Tuan Do)</author>
      <guid isPermaLink="false">2411.18054v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Natural Language Understanding and Inference with MLLM in Visual Question Answering: A Survey</title>
      <link>http://arxiv.org/abs/2411.17558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要主题&lt;/h4&gt;视觉问答（VQA）结合了自然语言处理和计算机视觉技术，已成为多模态大型语言模型的基准测试任务。&lt;h4&gt;背景介绍&lt;/h4&gt;VQA是一个挑战性的任务，它将自然语言处理与计算机视觉相结合，并逐渐成为多模态大模型的一个重要评估标准。&lt;h4&gt;研究目的&lt;/h4&gt;提供一个关于VQA发展的全面概述以及对最新高时效性模型的详细描述。&lt;h4&gt;主要内容1&lt;/h4&gt;总结了图像和文本中的自然语言理解和基于图像-问题信息的知识推理模块在核心VQA任务中的应用。&lt;h4&gt;主要内容2&lt;/h4&gt;介绍了近期在使用视觉-语言预训练模型和多模态大语言模型进行模式提取和融合方面的进展。&lt;h4&gt;主要内容3&lt;/h4&gt;详细回顾了知识推理在VQA中的进步，包括内部知识的抽取和外部知识的引入。&lt;h4&gt;数据集与评价指标&lt;/h4&gt;描述了VQA的数据集以及不同的评估标准，并讨论了未来的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Question Answering (VQA) is a challenge task that combines naturallanguage processing and computer vision techniques and gradually becomes abenchmark test task in multimodal large language models (MLLMs). The goal ofour survey is to provide an overview of the development of VQA and a detaileddescription of the latest models with high timeliness. This survey gives anup-to-date synthesis of natural language understanding of images and text, aswell as the knowledge reasoning module based on image-question information onthe core VQA tasks. In addition, we elaborate on recent advances in extractingand fusing modal information with vision-language pretraining models andmultimodal large language models in VQA. We also exhaustively review theprogress of knowledge reasoning in VQA by detailing the extraction of internalknowledge and the introduction of external knowledge. Finally, we present thedatasets of VQA and different evaluation metrics and discuss possibledirections for future work.</description>
      <author>example@mail.com (Jiayi Kuang, Jingyou Xie, Haohao Luo, Ronghao Li, Zhe Xu, Xianfeng Cheng, Yinghui Li, Xika Lin, Ying Shen)</author>
      <guid isPermaLink="false">2411.17558v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Dual-task Mutual Reinforcing Embedded Joint Video Paragraph Retrieval and Grounding</title>
      <link>http://arxiv.org/abs/2411.17481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted with mandatory minor revisions by TMM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种双任务相互强化嵌入联合视频段落检索和定位的方法（DMR-JRG），解决了传统方法依赖大规模注释时间标签的问题，并在减少对应关系假设的前提下实现了准确的跨模态匹配和定位。&lt;h4&gt;背景&lt;/h4&gt;现有视频段落定位技术通常需要大量人工标注的时间标签，且要求已知视频与文本段落之间的对应关系。这种需求在实际应用中难以实现，成本高昂且缺乏实际性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型方法来减少对大规模注释时间标签和已知视频-文本对应性的依赖，同时提高检索和定位的准确性。&lt;h4&gt;方法&lt;/h4&gt;DMR-JRG包含两个主要分支：检索分支采用跨视频对比学习粗略对齐段落与视频的整体特征，降低模态差异并构建一个粗粒度特征空间；定位分支则通过探索局部、全局及时间维度的一致性实现精确的跨模态匹配和定位。&lt;h4&gt;主要发现&lt;/h4&gt;利用双任务相互强化机制，DMR-JRG能够在减少对大规模标注依赖的情况下显著提高视频段落检索与定位的质量。此外，该方法还构建了一个细粒度特征空间来提升文本和视频特征的表达能力。&lt;h4&gt;结论&lt;/h4&gt;所提出的DMR-JRG方法展示了在实际应用场景中的巨大潜力，能够有效降低人工标注成本并提高跨模态任务性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频段落定位（VPG）旨在精确确定视频中与给定文本段查询最相关的时刻。然而，现有方法通常依赖于大规模注释的时间标签，并且假设视频和段落之间的对应关系已知。在现实应用中，构造时间标签需要大量人力成本，并且这种对应关系往往是未知的。为了解决这些问题，我们提出了一种双任务相互强化嵌入联合视频段落检索与定位的方法（DMR-JRG）。这种方法将检索和定位任务视为互相促进的任务，而非孤立处理。DMR-JRG主要由两个分支组成：一个检索分支和一个定位分支。在检索分支中，通过跨视频对比学习粗略对齐文本和视频的整体特征，降低模态差异并构建了一个粗粒度的特征空间，从而摆脱了段落与视频之间对应关系的需求。此外，这个粗粒度的特征空间进一步帮助定位分支提取细粒度上下文表示。在定位分支中，我们通过探索视频片段及其局部、全局和时间维度的一致性来实现精确的跨模态匹配和定位。由此构建了一个精细的特征空间用于视频和文本特征，大大减少了对大规模注释时间标签的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/X7J92/DMR-JRG&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Paragraph Grounding (VPG) aims to precisely locate the most appropriatemoments within a video that are relevant to a given textual paragraph query.However, existing methods typically rely on large-scale annotated temporallabels and assume that the correspondence between videos and paragraphs isknown. This is impractical in real-world applications, as constructing temporallabels requires significant labor costs, and the correspondence is oftenunknown. To address this issue, we propose a Dual-task Mutual ReinforcingEmbedded Joint Video Paragraph Retrieval and Grounding method (DMR-JRG). Inthis method, retrieval and grounding tasks are mutually reinforced rather thanbeing treated as separate issues. DMR-JRG mainly consists of two branches: aretrieval branch and a grounding branch. The retrieval branch uses inter-videocontrastive learning to roughly align the global features of paragraphs andvideos, reducing modality differences and constructing a coarse-grained featurespace to break free from the need for correspondence between paragraphs andvideos. Additionally, this coarse-grained feature space further facilitates thegrounding branch in extracting fine-grained contextual representations. In thegrounding branch, we achieve precise cross-modal matching and grounding byexploring the consistency between local, global, and temporal dimensions ofvideo segments and textual paragraphs. By synergizing these dimensions, weconstruct a fine-grained feature space for video and textual features, greatlyreducing the need for large-scale annotated temporal labels.</description>
      <author>example@mail.com (Mengzhao Wang, Huafeng Li, Yafei Zhang, Jinxing Li, Minghong Xie, Dapeng Tao)</author>
      <guid isPermaLink="false">2411.17481v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>NumGrad-Pull: Numerical Gradient Guided Tri-plane Representation for Surface Reconstruction from Point Clouds</title>
      <link>http://arxiv.org/abs/2411.17392v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的方法NumGrad-Pull，用于加速连续表面的重建过程，并提高局部细节的精度。该方法利用了三平面结构的优势和数值梯度计算来改进传统的分析计算。&lt;h4&gt;背景&lt;/h4&gt;从无向且未排序的3D点中重构连续表面是计算机视觉和图形学中的一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入新的策略和技术，提升基于神经网络的Signed Distance Function（SDF）在复杂几何形状上的学习效率与稳定性，并减少重建过程中的错误。&lt;h4&gt;方法&lt;/h4&gt;{'NumGrad-Pull': '利用三平面结构来加速学习并提高局部细节精度', '数值梯度': '代替传统分析计算，增强网格基于三平面训练的稳定性', '渐进式平面扩展策略': '加快Signed Distance Function（SDF）收敛速度的设计方案', '数据采样策略': '减少重建过程中产生的伪影的方法'}&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证了所提出方法的有效性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;论文展示了一种新的、高效的表面重构技术，它利用数值梯度和三平面结构的优点来改进现有SDF学习过程的效率与精度。&lt;h4&gt;翻译&lt;/h4&gt;从无向且未排序的3D点中重构连续表面是计算机视觉和图形学中的一个基本挑战。最近的研究通过训练神经符号距离函数来解决这个问题，该函数能够根据预测的距离值将三维查询拉到最接近的位置，并利用网络计算出的分析梯度进行操作。在本文中，我们提出了NumGrad-Pull方法，它利用三平面结构表示能力加速符号距离函数的学习过程，并改进了表面重建中的局部细节精度。为了进一步提高基于网格的三平面训练稳定性，我们提出采用数值梯度代替传统的分析计算方式。此外，还介绍了一种渐进式扩展策略来促进更快的Signed Distance Function（SDF）收敛速度和设计数据采样策略以减少重建过程中的伪影现象。我们的实验结果证明了所提出方法的有效性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cuiruikai/numgrad-pull&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing continuous surfaces from unoriented and unordered 3D points isa fundamental challenge in computer vision and graphics. Recent advancementsaddress this problem by training neural signed distance functions to pull 3Dlocation queries to their closest points on a surface, following the predictedsigned distances and the analytical gradients computed by the network. In thispaper, we introduce NumGrad-Pull, leveraging the representation capability oftri-plane structures to accelerate the learning of signed distance functionsand enhance the fidelity of local details in surface reconstruction. To furtherimprove the training stability of grid-based tri-planes, we propose to exploitnumerical gradients, replacing conventional analytical computations.Additionally, we present a progressive plane expansion strategy to facilitatefaster signed distance function convergence and design a data sampling strategyto mitigate reconstruction artifacts. Our extensive experiments across avariety of benchmarks demonstrate the effectiveness and robustness of ourapproach. Code is available at https://github.com/CuiRuikai/NumGrad-Pull</description>
      <author>example@mail.com (Ruikai Cui, Shi Qiu, Jiawei Liu, Saeed Anwar, Nick Barnes)</author>
      <guid isPermaLink="false">2411.17392v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Spectral-Spatial Transformer with Active Transfer Learning for Hyperspectral Image Classification</title>
      <link>http://arxiv.org/abs/2411.18115v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个多阶段主动迁移学习框架，结合了空间-光谱变换器和主动学习过程，以实现高效的高光谱图像分类。&lt;h4&gt;背景&lt;/h4&gt;高光谱图像分类由于其高维光谱特性以及通常可用的标注数据有限而成为一项具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的多阶段主动迁移学习框架，以提高高光谱图像分类的准确性和效率，并减少计算成本和标注费用。&lt;h4&gt;方法&lt;/h4&gt;{'Spatial-Spectral Transformer (SST)': '利用预训练的SST模型进行迭代微调', '不确定性-多样性查询机制': '通过不确定性指导主动选择最有信息量且多样化的样本进行学习', '动态冻结策略': '根据任务需求，选择性地冻结部分网络层以减少计算开销同时保持适应光谱变化的能力'}&lt;h4&gt;主要发现&lt;/h4&gt;{'自校准': '通过主动学习引导的不确定性指导实现空间-光谱注意力权重的自我校准', '多样性采样策略': '确保所选样本跨越不同的光谱区域，防止对特定光谱类别的过拟合', '性能优势': '实验表明SST-ATL框架在基准高光谱数据集上的表现优于现有的基于CNN和SST的方法'}&lt;h4&gt;结论&lt;/h4&gt;提出的主动迁移学习框架显著提高了高光谱图像分类的准确性、效率以及计算性能。&lt;h4&gt;翻译&lt;/h4&gt;该论文介绍了用于改进高光谱图像分类任务的新方法，通过结合空间-光谱变换器与多阶段主动迁移学习策略来优化模型的训练过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mahmad000/atl-sst&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The classification of hyperspectral images (HSI) is a challenging task due tothe high spectral dimensionality and limited labeled data typically availablefor training. In this study, we propose a novel multi-stage active transferlearning (ATL) framework that integrates a Spatial-Spectral Transformer (SST)with an active learning process for efficient HSI classification. Our approachleverages a pre-trained (initially trained) SST model, fine-tuned iterativelyon newly acquired labeled samples using an uncertainty-diversity(Spatial-Spectral Neighborhood Diversity) querying mechanism. This mechanismidentifies the most informative and diverse samples, thereby optimizing thetransfer learning process to reduce both labeling costs and model uncertainty.We further introduce a dynamic freezing strategy, selectively freezing layersof the SST model to minimize computational overhead while maintainingadaptability to spectral variations in new data. One of the key innovations inour work is the self-calibration of spectral and spatial attention weights,achieved through uncertainty-guided active learning. This not only enhances themodel's robustness in handling dynamic and disjoint spectral profiles but alsoimproves generalization across multiple HSI datasets. Additionally, we presenta diversity-promoting sampling strategy that ensures the selected samples spandistinct spectral regions, preventing overfitting to particular spectralclasses. Experiments on benchmark HSI datasets demonstrate that the SST-ATLframework significantly outperforms existing CNN and SST-based methods,offering superior accuracy, efficiency, and computational performance. Thesource code can be accessed at \url{https://github.com/mahmad000/ATL-SST}.</description>
      <author>example@mail.com (Muhammad Ahmad, Manuel Mazzara, Salvatore Distefano)</author>
      <guid isPermaLink="false">2411.18115v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Engineering AI Judge Systems</title>
      <link>http://arxiv.org/abs/2411.17793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;AI裁判系统用于自动评估由基础模型支持的软件（即FMware），这类系统的开发需要独特的工程生命周期，并带来新的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架来解决这些问题，旨在提高高质量AI裁判系统的开发效率。&lt;h4&gt;方法&lt;/h4&gt;根据在开发AI裁判系统的工业经验中遇到的问题进行讨论，并通过案例研究评估所提出的框架的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;使用提议的框架开发的AI裁判系统比未使用该框架开发的系统准确性提高了最多6.2%，同时显著减少了研发工作量。&lt;h4&gt;结论&lt;/h4&gt;新框架能够有效应对FMware带来的挑战，提高AI裁判系统的质量和效率。&lt;h4&gt;翻译&lt;/h4&gt;AI裁判系统旨在自动评估由基础模型支持的软件。由于这类软件固有的动态和随机特性，其开发需要一个独特的工程生命周期并带来新的挑战。基于工业经验中的问题讨论，提出了一个框架以解决这些挑战，并通过案例研究评估了该框架的有效性，结果表明所提出的框架能够显著提高AI裁判系统的准确性和开发效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; AI judge systems are designed to automatically evaluate FoundationModel-powered software (i.e., FMware). Due to the intrinsic dynamic andstochastic nature of FMware, the development of AI judge systems requires aunique engineering life cycle and presents new challenges. In this paper, wediscuss the challenges based on our industrial experiences in developing AIjudge systems for FMware. These challenges lead to substantial timeconsumption, cost and inaccurate judgments. We propose a framework that tacklesthe challenges with the goal of improving the productivity of developinghigh-quality AI judge systems. Finally, we evaluate our framework with a casestudy on judging a commit message generation FMware. The accuracy of thejudgments made by the AI judge system developed with our framework outperformsthose made by the AI judge system that is developed without our framework by upto 6.2%, with a significant reduction in development effort.</description>
      <author>example@mail.com (Jiahuei Lin, Dayi Lin, Sky Zhang, Ahmed E. Hassan)</author>
      <guid isPermaLink="false">2411.17793v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>GNN 101: Visual Learning of Graph Neural Networks in Your Web Browser</title>
      <link>http://arxiv.org/abs/2411.17849v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Graph Neural Networks (GNNs) 已经在多种应用中取得了显著的成功，但它们复杂的结构和工作原理对非AI专家来说难以理解。为此，我们提出了 GNN101，这是一个教育性的可视化工具，用于交互式学习GNN。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（Graph Neural Networks, GNNs）已经广泛应用于各个领域，并且取得了显著的成功。然而，对于非AI专家而言，理解和掌握这些复杂的模型变得非常具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了帮助非AI领域的专业人士更好地理解图神经网络的工作原理和应用价值，我们开发了一种教育性的可视化工具GNN101。&lt;h4&gt;方法&lt;/h4&gt;GNN101通过多层次的抽象实现了数学公式与可视化的无缝集成。包括模型概述、层操作以及详细的矩阵计算动画等部分。用户可以根据需要在节点链接视图（提供直观理解）和矩阵视图（提供高效的综合视角）之间切换。&lt;h4&gt;主要发现&lt;/h4&gt;该工具有效地解开了GNN计算的神秘面纱，以一种吸引人且直观的方式展示了GNN在每一层中对图形节点的学习情况。此外，GNN101是开源的，并可以在网络浏览器中直接使用而无需安装。&lt;h4&gt;结论&lt;/h4&gt;GNN101 为想要了解图神经网络基础知识的人们提供了一个有价值的教育工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要是关于一种名为 GNN101 的教育性可视化工具，该工具旨在帮助非AI专家更好地理解和学习图神经网络。它通过多层次的抽象将数学公式与可视化无缝集成，并且可以在节点链接视图和矩阵视图之间切换以提供不同视角的理解。此外，GNN101 是开源软件，可以直接在浏览器中运行而无需安装任何附加程序或库。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have achieved significant success across variousapplications. However, their complex structures and inner workings can bechallenging for non-AI experts to understand. To address this issue, we present\name, an educational visualization tool for interactive learning of GNNs. GNN101 seamlessly integrates mathematical formulas with visualizations viamultiple levels of abstraction, including a model overview, layer operations,and detailed animations for matrix calculations. Users can easily switchbetween two complementary views: a node-link view that offers an intuitiveunderstanding of the graph data, and a matrix view that provides aspace-efficient and comprehensive overview of all features and theirtransformations across layers. GNN 101 not only demystifies GNN computations inan engaging and intuitive way but also effectively illustrates what a GNNlearns about graph nodes at each layer. To ensure broad educational access, GNN101 is open-source and available directly in web browsers without requiring anyinstallations.</description>
      <author>example@mail.com (Yilin Lu, Chongwei Chen, Kexin Huang, Marinka Zitnik, Qianwen Wang)</author>
      <guid isPermaLink="false">2411.17849v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MAT: Multi-Range Attention Transformer for Efficient Image Super-Resolution</title>
      <link>http://arxiv.org/abs/2411.17214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个多范围注意力变换器（MAT）用于图像超分辨率任务，该模型结合了膨胀操作和自注意力机制，能够有效捕捉区域和稀疏的全局特征。&lt;h4&gt;背景&lt;/h4&gt;在图像超分辨率领域中，引入Transformer架构取得了显著进展。然而，扩大自注意力窗口以捕获更广泛的上下文的方法会带来计算需求大幅增加的问题，并且现有模型固定大小的窗口限制了有效的感受野以及中间特征多样性。&lt;h4&gt;目的&lt;/h4&gt;提出一种灵活地集成不同空间尺度上注意力机制的方法，可以显著提高性能。&lt;h4&gt;方法&lt;/h4&gt;引入多范围注意变换器（MAT），该模型利用膨胀操作和自注意力机制来实现多范围关注(MA)和稀疏多范围关注(SMA)，并结合局部特征提取，有效捕捉各种空间范围的依赖关系。同时提出了MSConvStar模块以增强模型对多尺度表示学习的能力。&lt;h4&gt;主要发现&lt;/h4&gt;MAT可以有效地捕获不同规模的空间相关性，并通过引入MSConvStar模块提高了特征表示的多样性和效率。&lt;h4&gt;结论&lt;/h4&gt;实验表明，MAT在图像超分辨率任务上表现出优于现有最先进的SR模型的性能和计算效率（比SRFormer-light快约3.3倍）。&lt;h4&gt;翻译&lt;/h4&gt;最近在图像超分辨率领域的进展显著受益于Transformer架构的引入。然而，扩大自注意力窗口以捕获更广泛上下文的传统技术面临计算需求增加的问题，并且现有模型固定大小的窗口限制了有效的感受野以及中间特征多样性。本文展示了灵活地集成不同空间尺度上的注意机制可以带来显著性能提升。为此，我们提出了专门针对SR任务设计的多范围注意力变换器（MAT）。MAT利用膨胀操作与自注意力机制相结合的方式支持多范围关注(MA)和稀疏多范围关注(SMA)，有效捕获区域及稀疏全局特征。结合局部特征提取，MAT能够捕捉不同空间尺度上的依赖关系，提高其特征表示的多样性和效率。此外我们还提出了MSConvStar模块来增强模型对多尺度表示学习的能力。综合实验表明，我们的MAT在图像超分辨率任务上表现出优于现有最先进SR模型的性能和计算效率（比SRFormer-light快约3.3倍）.&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in image super-resolution (SR) have significantly benefitedfrom the incorporation of Transformer architectures. However, conventionaltechniques aimed at enlarging the self-attention window to capture broadercontexts come with inherent drawbacks, especially the significantly increasedcomputational demands. Moreover, the feature perception within a fixed-sizewindow of existing models restricts the effective receptive fields and theintermediate feature diversity. This study demonstrates that a flexibleintegration of attention across diverse spatial extents can yield significantperformance enhancements. In line with this insight, we introduce Multi-RangeAttention Transformer (MAT) tailored for SR tasks. MAT leverages thecomputational advantages inherent in dilation operation, in conjunction withself-attention mechanism, to facilitate both multi-range attention (MA) andsparse multi-range attention (SMA), enabling efficient capture of both regionaland sparse global features. Further coupled with local feature extraction, MATadeptly capture dependencies across various spatial ranges, improving thediversity and efficacy of its feature representations. We also introduce theMSConvStar module, which augments the model's ability for multi-rangerepresentation learning. Comprehensive experiments show that our MAT exhibitssuperior performance to existing state-of-the-art SR models with remarkableefficiency (~3.3 faster than SRFormer-light).</description>
      <author>example@mail.com (Chengxing Xie, Xiaoming Zhang, Kai Zhang, Linze Li, Yuqian Fu, Biao Gong, Tianrui Li)</author>
      <guid isPermaLink="false">2411.17214v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Transfer Learning for Astronomical Image Analysis</title>
      <link>http://arxiv.org/abs/2411.18206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  proceeding of the Seventeenth Marcel Grossmann Meeting&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文探讨了在天文研究的各个领域中，利用迁移学习技术应对大规模天文学数据所带来的挑战的可能性。我们介绍了最近一些基于预训练卷积神经网络的应用实例，这些应用涵盖了天文学任务中的多项工作。&lt;h4&gt;背景&lt;/h4&gt;随着大型天文巡天项目的增多，天文学数据呈指数级增长，为天文学界带来了机遇和挑战。&lt;h4&gt;目的&lt;/h4&gt;探讨迁移学习技术在解决天文学领域各类研究挑战方面的可能性。&lt;h4&gt;方法&lt;/h4&gt;基于预训练的卷积神经网络进行应用，具体包括候选活动星系核（AGN）检测、直接从图像中推导出物理参数的可能性、时序图像中的伪像识别以及强透镜候选体和异常值的检测。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习使得对复杂的天文现象的有效分析成为可能，特别是在标签数据稀缺的情况下。这些方法将有助于即将进行的大规模巡天项目（如鲁宾遗产调查）&lt;h4&gt;结论&lt;/h4&gt;通过展示成功的实施案例并讨论方法论，强调了此类技术的多功能性和有效性。&lt;h4&gt;翻译&lt;/h4&gt;随着大型天文学观测项目的增加，天文数据的数量呈指数级增长，这为天文学界带来了机遇同时也提出了挑战。本文研究了迁移学习技术在解决这些挑战方面的潜力，并介绍了几个基于预训练卷积神经网络的应用实例，例如候选活动星系核（AGN）的检测、直接从图像中推导出物理参数的可能性、时序数据中的伪像识别以及强透镜候选体和异常值的检测。迁移学习技术使得在标签数据稀缺的情况下分析复杂的天文现象成为可能，这对即将开展的大规模观测项目如鲁宾遗产调查有着重要的意义。文章通过展示成功案例并讨论方法论，强调了这类技术的多功能性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The exponential growth of astronomical data from large-scale surveys hascreated both opportunities and challenges for the astrophysics community. Thispaper explores the possibilities offered by transfer learning techniques inaddressing these challenges across various domains of astronomical research. Wepresent a set of recent applications of transfer learning methods forastronomical tasks based on the usage of a pre-trained convolutional neuralnetworks. The examples shortly discussed include the detection of candidateactive galactic nuclei (AGN), the possibility of deriving physical parametersfor galaxies directly from images, the identification of artifacts in timeseries images, and the detection of strong lensing candidates and outliers. Wedemonstrate how transfer learning enables efficient analysis of complexastronomical phenomena, particularly in scenarios where labeled data is scarce.This kind of method will be very helpful for upcoming large-scale surveys likethe Rubin Legacy Survey of Space and Time (LSST). By showcasing successfulimplementations and discussing methodological approaches, we highlight theversatility and effectiveness of such techniques.</description>
      <author>example@mail.com (Stefano Cavuoti, Lars Doorenbos, Demetra De Cicco, Gianluca Sasanelli, Massimo Brescia, Giuseppe Longo, Maurizio Paolillo, Olena Torbaniuk, Giuseppe Angora, Crescenzo Tortora)</author>
      <guid isPermaLink="false">2411.18206v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>GrokFormer: Graph Fourier Kolmogorov-Arnold Transformers</title>
      <link>http://arxiv.org/abs/2411.17296v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 6 figures, 7tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Graph Transformers (GTs) 在结合各种图结构信息方面表现出色，但其核心模块自注意力机制只能保留低频信号，并且忽视了异质性节点标签模式。&lt;h4&gt;背景&lt;/h4&gt;现有的 Graph Transformers 虽然在图表示学习中表现良好，但是通过自注意力机制处理的只是同质性的连接节点特征，无法有效建模复杂多样的节点标签模式（尤其是异质性模式）。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的 GT 网络 GrokFormer，用于超越现有 Graph Transformers 的局限性，并能更好地学习复杂的图结构信息。&lt;h4&gt;方法&lt;/h4&gt;GrokFormer 通过傅立叶级数建模在高阶图形谱中使用可学习激活函数来学习自适应滤波器功能和提取不同阶次的图形谱信息。这种方法能够灵活捕获广泛范围内的频率信号，从而更好地捕捉复杂图结构中的隐含模式。&lt;h4&gt;主要发现&lt;/h4&gt;GrokFormer 可以根据需求调整模型参数以适应不同的图特征，并且在多个节点分类数据集和图分类数据集中表现出色。&lt;h4&gt;结论&lt;/h4&gt;与现有的最先进的 Graph Transformers 和其他高级图神经网络相比，GrokFormer 在处理复杂多样的图结构信息方面更具灵活性和表达能力。&lt;h4&gt;翻译&lt;/h4&gt;Graph Transformers (GTs) 已经证明在整合各种图形结构信息（例如长距离结构依赖性）到图形表示学习中表现出色。然而，作为 GT 核心模块的自注意力机制仅保留了图形特征中的低频信号，只捕获连接节点之间的同质性模式。因此，在建模复杂的节点标签模式方面，比如与同质性相反的异质性模式方面的能力不足。一些改进过的 GT 通过学习多项式过滤器或对一阶图谱进行自注意力处理来解决这个问题。然而，这些方法要么忽略了整个频谱中的丰富信息，要么忽视了高阶频谱信息，导致其频率响应和灵活性有限。为了克服这些问题，我们提出了一种新颖的 GT 网络，即 Graph Fourier Kolmogorov-Arnold Transformers (GrokFormer)，超越现有的自注意力机制。GrokFormer 通过傅立叶级数建模，在高阶图形谱中使用可学习激活函数，从而灵活地捕捉广泛的频率信号，并自适应提取一阶和更高阶的图形频谱信息。结果表明，GrokFormer 可以有效地捕获不同顺序和级别频率信号中的复杂模式，形成表达性、顺序和频率适应性强的图表示。在10个跨域、规模和异质水平不同的节点分类数据集以及5个图分类数据集上进行的全面实验证明，GrokFormer 优于现有的最先进的 GT 和其他高级图神经网络。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/GGA23/GrokFormer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformers (GTs) have demonstrated remarkable performance inincorporating various graph structure information, e.g., long-range structuraldependency, into graph representation learning. However, self-attention -- thecore module of GTs -- preserves only low-frequency signals on graph features,retaining only homophilic patterns that capture similar features among theconnected nodes. Consequently, it has insufficient capacity in modeling complexnode label patterns, such as the opposite of homophilic patterns --heterophilic patterns. Some improved GTs deal with the problem by learningpolynomial filters or performing self-attention over the first-order graphspectrum. However, these GTs either ignore rich information contained in thewhole spectrum or neglect higher-order spectrum information, resulting inlimited flexibility and frequency response in their spectral filters. To tacklethese challenges, we propose a novel GT network, namely Graph FourierKolmogorov-Arnold Transformers (GrokFormer), to go beyond the self-attention inGTs. GrokFormer leverages learnable activation functions in order-$K$ graphspectrum through Fourier series modeling to i) learn eigenvalue-targeted filterfunctions producing learnable base that can capture a broad range of frequencysignals flexibly, and ii) extract first- and higher-order graph spectralinformation adaptively. In doing so, GrokFormer can effectively captureintricate patterns hidden across different orders and levels of frequencysignals, learning expressive, order-and-frequency-adaptive graphrepresentations. Comprehensive experiments conducted on 10 node classificationdatasets across various domains, scales, and levels of graph heterophily, aswell as 5 graph classification datasets, demonstrate that GrokFormeroutperforms state-of-the-art GTs and other advanced graph neural networks.</description>
      <author>example@mail.com (Guoguo Ai, Guansong Pang, Hezhe Qiao, Yuan Gao, Hui Yan)</author>
      <guid isPermaLink="false">2411.17296v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MapEval: Towards Unified, Robust and Efficient SLAM Map Evaluation Framework</title>
      <link>http://arxiv.org/abs/2411.17928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MapEval是一个开源的评估框架，用于全面评估点云地图的质量，特别适用于SLAM场景。&lt;h4&gt;背景&lt;/h4&gt;大规模点云地图在Simultaneous Localization and Mapping (SLAM)中的评估面临挑战，主要是因为缺乏统一、稳健和高效的评价框架。&lt;h4&gt;目的&lt;/h4&gt;提出一个综合性的质量评估框架MapEval，并建立一致的地图质量评估指南。通过分析现有SLAM应用中的评估指标的局限性来确定这些指导方针。&lt;h4&gt;方法&lt;/h4&gt;提出了基于体积空间中近似高斯分布的Wasserstein距离的新度量，这使我们能够使用两种互补的指标在同一错误标准下进行评价：Voxelized Average Wasserstein Distance (AWD)和Spatial Consistency Score (SCS)。&lt;h4&gt;主要发现&lt;/h4&gt;该理论基础在对抗噪声鲁棒性和计算效率方面相对于传统度量有了显著改进。在模拟数据集和真实世界数据集上的大量实验表明，MapEval至少快100到500倍，并且保持了评估的完整性。&lt;h4&gt;结论&lt;/h4&gt;将推出MapEvallibrary以促进机器人社区中的标准化地图评价实践。&lt;h4&gt;翻译&lt;/h4&gt;评估大规模点云地图在即时定位与地图构建（SLAM）中仍然具有挑战性，主要是由于缺乏统一、稳健和高效的评价框架。我们提出了一个开源的MapEval框架，用于全面的质量评估，并针对地面真值图比映射环境稀疏得多的情况下进行了优化。通过对现有度量标准进行系统分析，我们识别了这些度量的基本限制，并建立了明确的一致地图质量评估指南。基于这些见解，我们在体积空间中提出了一种近似高斯分布的Wasserstein距离的新方法，允许在同一个错误标准下使用两种互补指标：体积平均Wasser斯坦距离（AWD）用于全局几何精度评估，以及空间一致性分数（SCS）用于局部一致性评价。这个理论基础使我们能够在对抗噪声鲁棒性和计算效率方面相对于传统度量有了显著改进。广泛的模拟数据和真实世界数据集实验表明，MapEval至少快100到500倍，并且保持了评估的完整性。MapEvallibrary将会公开发布以促进机器人社区中的标准化地图评价实践。&lt;h4&gt;参考链接&lt;/h4&gt;https://github.com/JokerJohn/Cloud_Map_Evaluation&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jokerjohn/cloud_map_evaluation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Evaluating massive-scale point cloud maps in Simultaneous Localization andMapping (SLAM) remains challenging, primarily due to the absence of unified,robust and efficient evaluation frameworks. We present MapEval, an open-sourceframework for comprehensive quality assessment of point cloud maps,specifically addressing SLAM scenarios where ground truth map is inherentlysparse compared to the mapped environment. Through systematic analysis ofexisting evaluation metrics in SLAM applications, we identify their fundamentallimitations and establish clear guidelines for consistent map qualityassessment. Building upon these insights, we propose a novelGaussian-approximated Wasserstein distance in voxelized space, enabling twocomplementary metrics under the same error standard: Voxelized AverageWasserstein Distance (AWD) for global geometric accuracy and SpatialConsistency Score (SCS) for local consistency evaluation. This theoreticalfoundation leads to significant improvements in both robustness against noiseand computational efficiency compared to conventional metrics. Extensiveexperiments on both simulated and real-world datasets demonstrate that MapEvalachieves at least \SI{100}{}-\SI{500}{} times faster while maintainingevaluation integrity. The MapEvallibrary\footnote{\texttt{https://github.com/JokerJohn/Cloud\_Map\_Evaluation}}will be publicly available to promote standardized map evaluation practices inthe robotics community.</description>
      <author>example@mail.com (Xiangcheng Hu, Jin Wu, Mingkai Jia, Hongyu Yan, Yi Jiang, Binqian Jiang, Wei Zhang, Wei He, Ping Tan)</author>
      <guid isPermaLink="false">2411.17928v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Material synthesis through simulations guided by machine learning: a position paper</title>
      <link>http://arxiv.org/abs/2411.13953v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种可持续的数据采集方法，用于大理石污泥再利用的最佳混合设计。通过模拟和机器学习模型优化混合比例，可以节省时间和资源，并减少对环境的影响。&lt;h4&gt;背景&lt;/h4&gt;大理石污泥是石切割过程中的钙质副产品，在与各种原料混合后可被重新利用。确定最佳混合设计由于污泥成分的多变性和实验数据收集的成本高、耗时长而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;探讨使用机器学习模型和元学习作为优化工具的可能性，以估计用于获得特定机械性能混合设计所需的石切割污泥量。&lt;h4&gt;方法&lt;/h4&gt;(i) 通过模拟生成大量数据集，减少时间和金钱的支出；(ii) 利用经过超参数优化的机器学习模型来估算最佳混合比例，降低实验成本并加快采石场污泥处理速度。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可加速大理石污泥再利用过程，并促进石材切割行业的可持续性和效率。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法展示了通过集体数据和先进机器学习技术在大理石污泥再利用领域的应用潜力，有望提高行业整体的可持续性与效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this position paper, we propose an approach for sustainable datacollection in the field of optimal mix design for marble sludge reuse. Marblesludge, a calcium-rich residual from stone-cutting processes, can be repurposedby mixing it with various ingredients. However, determining the optimal mixdesign is challenging due to the variability in sludge composition and thecostly, time-consuming nature of experimental data collection. Also, weinvestigate the possibility of using machine learning models usingmeta-learning as an optimization tool to estimate the correct quantity ofstone-cutting sludge to be used in aggregates to obtain a mix design withspecific mechanical properties that can be used successfully in the buildingindustry. Our approach offers two key advantages: (i) through simulations, alarge dataset can be generated, saving time and money during the datacollection phase, and (ii) Utilizing machine learning models, with performanceenhancement through hyper-parameter optimization via meta-learning, to estimateoptimal mix designs reducing the need for extensive manual experimentation,lowering costs, minimizing environmental impact, and accelerating theprocessing of quarry sludge. Our idea promises to streamline the marble sludgereuse process by leveraging collective data and advanced machine learning,promoting sustainability and efficiency in the stonecutting sector.</description>
      <author>example@mail.com (Usman Syed, Federico Cunico, Uzair Khan, Eros Radicchi, Francesco Setti, Adolfo Speghini, Paolo Marone, Filiberto Semenzin, Marco Cristani)</author>
      <guid isPermaLink="false">2411.13953v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Structure-Guided MR-to-CT Synthesis with Spatial and Semantic Alignments for Attenuation Correction of Whole-Body PET/MR Imaging</title>
      <link>http://arxiv.org/abs/2411.17488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;基于深度学习的MR到CT合成可以估算组织的电子密度，从而在全身PET/MR成像中简化PET衰减校正。然而，全身MR到CT合成面临空间错位和复杂强度映射等问题。&lt;h4&gt;背景&lt;/h4&gt;全身MR-CT合成中的挑战主要是由于身体各处不同类型的组织造成的空间不匹配以及复杂的强度映射问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的全身MR到CT合成框架来解决上述提到的挑战。&lt;h4&gt;方法&lt;/h4&gt;{'结构引导合成模块': '通过结构引导注意门减少软组织不必要的轮廓，提高合成图像质量。', '空间对齐模块': '考虑组织体积和呼吸运动的影响，提供精确配准，并在训练过程中提供高质量的地面实况CT图像。', '语义对齐模块': '利用对比学习限制器官相关的语义信息，确保合成CT图像的语义真实性。'}&lt;h4&gt;主要发现&lt;/h4&gt;提出的全身MR-CT框架可以生成视觉上合理的和语义真实的CT图像，并且验证了其在PET衰减校正中的有效性。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了一个有效的解决方案来改善基于深度学习的MR到CT合成技术，特别是在解决全身成像时的空间错位和强度映射问题方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep-learning-based MR-to-CT synthesis can estimate the electron density oftissues, thereby facilitating PET attenuation correction in whole-body PET/MRimaging. However, whole-body MR-to-CT synthesis faces several challengesincluding the issue of spatial misalignment and the complexity of intensitymapping, primarily due to the variety of tissues and organs throughout thewhole body. Here we propose a novel whole-body MR-to-CT synthesis framework,which consists of three novel modules to tackle these challenges: (1)Structure-Guided Synthesis module leverages structure-guided attention gates toenhance synthetic image quality by diminishing unnecessary contours of softtissues; (2) Spatial Alignment module yields precise registration betweenpaired MR and CT images by taking into account the impacts of tissue volumesand respiratory movements, thus providing well-aligned ground-truth CT imagesduring training; (3) Semantic Alignment module utilizes contrastive learning toconstrain organ-related semantic information, thereby ensuring the semanticauthenticity of synthetic CT images.We conduct extensive experiments todemonstrate that the proposed whole-body MR-to-CT framework can producevisually plausible and semantically realistic CT images, and validate itsutility in PET attenuation correction.</description>
      <author>example@mail.com (Jiaxu Zheng, Zhenrong Shen, Lichi Zhang, Qun Chen)</author>
      <guid isPermaLink="false">2411.17488v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>How do Multimodal Foundation Models Encode Text and Speech? An Analysis of Cross-Lingual and Cross-Modal Representations</title>
      <link>http://arxiv.org/abs/2411.17666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型旨在创建一个抽象化的统一表示空间，该空间超越了如语言语法或模式差异等表面特征。&lt;h4&gt;目的&lt;/h4&gt;研究三个最近发布的模型的内部表示，分析不同语言中语义相同句子在文本和语音模态上的模型激活情况。&lt;h4&gt;方法&lt;/h4&gt;通过分析跨语言、跨模态（文本与语音）情况下语义相同的句子在模型各层中的激活情况来探究模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '跨模态表示随模型层次的增加而收敛，但在专门处理文本和语音的初始层中除外。', '2': '长度适应对于缩小文本与语音之间的跨模态差距至关重要，但目前的方法效果主要局限于高资源语言。', '3': '与其他模式相比，语音在跨语言差异方面表现出更大的变化。', '4': '未经过多模态不可知表示显式训练的模型中，模态差距比语言差距更为显著。'}&lt;h4&gt;结论&lt;/h4&gt;多模态基础模型的有效性取决于对长度适应性的处理及高资源语言环境下的表现，此外，在跨语言和跨模式的一致性方面仍有许多挑战需要克服。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态基础模型旨在创建一个超越表面特征如语言语法或模式差异的统一表示空间。为了探究这一点，我们研究了三个最近发布的模型的内部表示，分析不同语言中语义相同句子在文本和语音模态上的模型激活情况。我们的发现显示：1) 跨模态表示随模型层次增加而收敛，但除了专门处理文本和语音的初始层外；2) 长度适应对于缩小文本与语音之间的跨模态差距至关重要，尽管当前方法的效果主要局限于高资源语言；3) 与其他模式相比，语音在跨语言差异方面表现出更大的变化；4) 对于未经过多模态不可知表示显式训练的模型而言，模态差距比语言差距更为显著。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models aim to create a unified representation spacethat abstracts away from surface features like language syntax or modalitydifferences. To investigate this, we study the internal representations ofthree recent models, analyzing the model activations from semanticallyequivalent sentences across languages in the text and speech modalities. Ourfindings reveal that: 1) Cross-modal representations converge over modellayers, except in the initial layers specialized at text and speech processing.2) Length adaptation is crucial for reducing the cross-modal gap between textand speech, although current approaches' effectiveness is primarily limited tohigh-resource languages. 3) Speech exhibits larger cross-lingual differencesthan text. 4) For models not explicitly trained for modality-agnosticrepresentations, the modality gap is more prominent than the language gap.</description>
      <author>example@mail.com (Hyunji Lee, Danni Liu, Supriti Sinhamahapatra, Jan Niehues)</author>
      <guid isPermaLink="false">2411.17666v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Spatio-temporal Causal Learning for Streamflow Forecasting</title>
      <link>http://arxiv.org/abs/2411.17937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published at IEEE Big Data 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合河流流量图与时空图神经网络（STGNNs）的因果流预测模型，用于增强水文建模中的水流预测性能。&lt;h4&gt;背景&lt;/h4&gt;径流在国家水资源可持续规划和管理中扮演着重要角色。传统的水文学方法通过建立降雨、径流等物理过程之间的联系来模拟径流。时空图神经网络（STGNNs）近年来因其在多个领域如城市交通管理和天气预报中的卓越表现，被引入用于水流预测。&lt;h4&gt;目的&lt;/h4&gt;利用河流流量图作为先验知识，学习因果结构，并使用此结构预测目标点的径流。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为因果流预测（CSF）的方法，该方法在德克萨斯州布拉索斯河盆地的真实世界研究中进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;该模型优于常规时空图神经网络，在计算效率上也高于传统的模拟方法。&lt;h4&gt;结论&lt;/h4&gt;通过有效地将河流流量图与STGNNs结合，本研究为水流预测提供了一种新的方法，并展示了结合高级神经网络技术与特定领域知识的潜力。&lt;h4&gt;翻译&lt;/h4&gt;径流在可持续规划和管理国家水资源中起着至关重要的作用。传统的水文学模型通过建立降雨、径流等物理过程之间的联系来模拟径流，这些数据具有内在的空间和时间关联性，可以用来进行精确预测。最近，时空图神经网络（STGNNs）因其在城市交通管理和天气预报等多个领域中的出色表现被引入到水流管理中，并且有望进一步推进水流预测。然而，直接从大量观测数据学习因果关系既困难又计算复杂。在此研究中，我们使用河流流量图作为先验知识来辅助学习因果结构，然后利用该因果图在目标地点进行径流预测。提出的模型（因果流预测CSF）在美国德克萨斯州布拉索斯河盆地进行了真实世界测试。结果显示，这种方法优于常规时空图神经网络，并且在计算效率上也超过了传统的模拟方法。通过将河流流量图与STGNNs有效结合，该研究为水流预测提供了一种新颖的方法，展示了利用高级神经网络技术与领域特定知识进行性能增强的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Streamflow plays an essential role in the sustainable planning and managementof national water resources. Traditional hydrologic modeling approachessimulate streamflow by establishing connections across multiple physicalprocesses, such as rainfall and runoff. These data, inherently connected bothspatially and temporally, possess intrinsic causal relations that can beleveraged for robust and accurate forecasting. Recently, spatio-temporal graphneural networks (STGNNs) have been adopted, excelling in various domains, suchas urban traffic management, weather forecasting, and pandemic control, andthey also promise advances in streamflow management. However, learning causalrelationships directly from vast observational data is theoretically andcomputationally challenging. In this study, we employ a river flow graph asprior knowledge to facilitate the learning of the causal structure and then usethe learned causal graph to predict streamflow at targeted sites. The proposedmodel, Causal Streamflow Forecasting (CSF) is tested in a real-world study inthe Brazos River basin in Texas. Our results demonstrate that our methodoutperforms regular spatio-temporal graph neural networks and achieves highercomputational efficiency compared to traditional simulation methods. Byeffectively integrating river flow graphs with STGNNs, this research offers anovel approach to streamflow prediction, showcasing the potential of combiningadvanced neural network techniques with domain-specific knowledge for enhancedperformance in hydrologic modeling.</description>
      <author>example@mail.com (Shu Wan, Reepal Shah, Qi Deng, John Sabo, Huan Liu, K. Selçuk)</author>
      <guid isPermaLink="false">2411.17937v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Instance-Aware Graph Prompt Learning</title>
      <link>http://arxiv.org/abs/2411.17676v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;图神经网络在图表示学习中因其强大的表达能力而成为主流技术，但其性能高度依赖高质量标签的可用性。为解决这一问题，提出了预训练和微调范式来降低标注成本。随后，为了弥合预设任务与下游任务之间的差距，发展了插入最小参数且保持竞争力性能的一组图提示学习方法。&lt;h4&gt;背景&lt;/h4&gt;图神经网络由于其强大的表达能力在图表示学习中占主导地位，但它们的性能严重依赖于高质量标签的可用性。这种依赖导致标注成本问题，阻碍了这些模型的应用范围和效果。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有探索工作的局限性（即固定任务特定提示可能不适用于各种输入实例），引入了一种新的方法——Instance-Aware 图提示学习（IA-GPL）以生成针对不同输入实例的定制提示。&lt;h4&gt;方法&lt;/h4&gt;该论文提出的方法涉及使用轻量级架构为每个输入实例生成中间提示，通过可训练码本来量化这些提示，并采用指数移动平均技术来确保稳定训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在多个数据集和设置下，IA-GPL 方法相对于现有基准线表现出优越的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法提供了一种改进图表示学习中预设任务与实际任务之间差距的有效途径。通过自适应生成针对特定输入实例的提示，可以提高模型在各种下游任务中的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;图神经网络因为其强大的表达力成为图形表示学习的主要技术，但它们的表现很大程度上依赖于端到端高质量标签的存在。因此，为了减少标注成本问题而提出了预训练和微调的方法。然而，由于预设任务与实际下游任务之间的差距，发展了插入一组最小参数的图提示以保持竞争力性能的学习方法。不过，当前的研究工作仍然受到限制，因为它们都集中在学习特定于固定任务的提示上，这些提示可能无法很好地推广到各种输入实例中。因此，本文提出了Instance-Aware 图提示学习（IA-GPL）的方法来生成针对不同输入实例的独特提示。这个过程包括使用轻量级架构为每个实例生成中间提示，通过可训练码本来量化这些提示，并采用指数移动平均技术以确保稳定的训练过程。在多个数据集和设置上的广泛实验表明，与现有的最佳基线相比，IA-GPL 方法具有优越的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks stand as the predominant technique for graphrepresentation learning owing to their strong expressive power, yet theperformance highly depends on the availability of high-quality labels in anend-to-end manner. Thus the pretraining and fine-tuning paradigm has beenproposed to mitigate the label cost issue. Subsequently, the gap between thepretext tasks and downstream tasks has spurred the development of graph promptlearning which inserts a set of graph prompts into the original graph data withminimal parameters while preserving competitive performance. However, thecurrent exploratory works are still limited since they all concentrate onlearning fixed task-specific prompts which may not generalize well across thediverse instances that the task comprises. To tackle this challenge, weintroduce Instance-Aware Graph Prompt Learning (IA-GPL) in this paper, aimingto generate distinct prompts tailored to different input instances. The processinvolves generating intermediate prompts for each instance using a lightweightarchitecture, quantizing these prompts through trainable codebook vectors, andemploying the exponential moving average technique to ensure stable training.Extensive experiments conducted on multiple datasets and settings showcase thesuperior performance of IA-GPL compared to state-of-the-art baselines.</description>
      <author>example@mail.com (Jiazheng Li, Jundong Li, Chuxu Zhang)</author>
      <guid isPermaLink="false">2411.17676v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Deep Learning-based Prediction of Lattice Thermal Conductivity</title>
      <link>http://arxiv.org/abs/2411.18259v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习通过从原子级描述符或结构中高效预测材料的宏观特性，有望加速材料发现。然而，由于缺乏精确值的数据限制了这一潜力。&lt;h4&gt;背景&lt;/h4&gt;现有数据库中具有高精度（基于第一性原理和DFT计算）的晶格热导率数据非常有限，只有几十种材料，并且变化范围小。&lt;h4&gt;目的&lt;/h4&gt;研究迁移学习对深度学习模型Precision（ParAIsite）在精确度和泛化能力上的影响。&lt;h4&gt;方法&lt;/h4&gt;从一个现有的MEGNet模型开始，通过使用预训练版本进行微调来改进现有模型。此外，在低质量的大数据集上首次进行了微调，然后使用高质量的小规模数据集再次微调以获取更佳效果。&lt;h4&gt;主要发现&lt;/h4&gt;在大数据集的低质量近似值上的初次微调和在高质量小规模数据集上的二次微调相结合可以显著提高模型性能。&lt;h4&gt;结论&lt;/h4&gt;这种方法不仅有助于探索大型数据库寻找低热导率材料，而且还可以应用于稀缺优质数据领域的更精确预测。&lt;h4&gt;翻译&lt;/h4&gt;机器学习承诺通过从原子级描述符或结构中进行大规模预测来加速材料发现。然而，这些属性的精确定值数据有限的问题一直是一个障碍，导致预测模型的精度有限或者泛化能力差。这在晶格热导率（LTC）方面尤其明显：基于第一性原理和DFT计算的精确数值的数据集仅限于少数几种材料，并且变化范围很小。基于这样的数据集，我们研究了迁移学习对深度学习模型Precision的影响，在精度和泛化能力上。我们从一个现有的MEGNet模型开始，并展示了通过在不同任务中微调预训练版本可以获得改进。有趣的是，我们在一个低质量的LTC近似值的大数据集上进行初步微调后，然后再应用高质量、小规模的数据集进行第二次微调时取得了显著的进步。这些有希望的结果不仅为进一步探索大型数据库寻找低热导率材料开辟了道路，而且还为在稀缺优质数据领域实现更精确预测的方法铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/liudakl/ParAIsite&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning promises to accelerate the material discovery by enablinghigh-throughput prediction of desirable macro-properties from atomic-leveldescriptors or structures. However, the limited data available about precisevalues of these properties have been a barrier, leading to predictive modelswith limited precision or the ability to generalize. This is particularly trueof lattice thermal conductivity (LTC): existing datasets of precise (ab initio,DFT-based) computed values are limited to a few dozen materials with littlevariability. Based on such datasets, we study the impact of transfer learningon both the precision and generalizability of a deep learning model(ParAIsite). We start from an existing model (MEGNet~\cite{Chen2019}) and showthat improvements are obtained by fine-tuning a pre-trained version ondifferent tasks. Interestingly, we also show that a much greater improvement isobtained when first fine-tuning it on a large datasets of low-qualityapproximations of LTC (based on the AGL model) and then applying a second phaseof fine-tuning with our high-quality, smaller-scale datasets. The promisingresults obtained pave the way not only towards a greater ability to explorelarge databases in search of low thermal conductivity materials but also tomethods enabling increasingly precise predictions in areas where quality dataare rare.</description>
      <author>example@mail.com (L. Klochko, M. d'Aquin, A. Togo, L. Chaput)</author>
      <guid isPermaLink="false">2411.18259v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>HOPPR Medical-Grade Platform for Medical Imaging AI</title>
      <link>http://arxiv.org/abs/2411.17891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;介绍了HOPPR Medical-Grade Platform平台，该平台旨在通过提供计算基础设施、基础模型和质量管理系统来克服大规模视觉语言模型（LVLM）在医学影像应用中部署的障碍。&lt;h4&gt;背景&lt;/h4&gt;技术进步使开发大型视觉语言模型成为可能。这些模型需要大量的图像和文本数据进行训练，并且已有研究证明了它们在医疗成像中的潜在价值，尤其是在放射学报告生成等领域。&lt;h4&gt;目的&lt;/h4&gt;为了克服大规模计算需求、复杂AI模型的开发技术和高质量大数据集获取困难等障碍，HOPPR Medical-Grade Platform平台应运而生。该平台旨在促进LVLM解决方案在医学影像领域的广泛应用。&lt;h4&gt;方法&lt;/h4&gt;提供了强大的计算基础设施；一套基础模型以供开发者根据特定场景进行微调；以及一个质量管理系统来评估微调后的模型是否符合临床应用标准。&lt;h4&gt;主要发现&lt;/h4&gt;HOPPR平台拥有数百万来自不同人群的影像研究和文本报告，用于预训练基础模型，并为具体应用场景提供精细调整所需的队列数据。所有这些数据都进行了去标识化处理并安全存储以满足HIPAA合规性要求。&lt;h4&gt;结论&lt;/h4&gt;通过使用Medical-Grade Platform，HOPPR旨在加速LVLM解决方案在医学影像中的部署，最终优化放射科医生的工作流程，并应对该领域日益增长的需求。&lt;h4&gt;翻译&lt;/h4&gt;人工智能技术的进步使得开发大型视觉语言模型（LVLM）成为可能。这些模型是在数百万对图像和文本样本上训练出来的。后续研究已经展示了LVLM在医疗成像应用场景（如放射学报告生成）中取得高成绩的巨大潜力，但仍存在一些障碍阻碍了这些解决方案的广泛部署。这些问题包括大规模开发所需的大规模计算需求的成本、复杂AI模型开发的专业知识以及获取高质量大数据集的难度，这些数据应充分代表将在其中部署LVLM解方案的人群。HOPPR Medical-Grade Platform通过提供强大的计算基础设施、一套基础模型以及一个稳健的质量管理系统来应对这些障碍，该系统为在临床环境中部署微调后的模型设定了标准。HOPPR平台可以访问数百万来自不同人群的影像研究和文本报告，用于预训练基础模型，并为具体应用场景提供精细调整所需的队列数据。所有数据都进行了去标识化处理并安全存储以满足HIPAA合规性要求。此外，开发人员可以在平台上安全托管模型并通过API访问这些模型，在既定的临床工作流程中使用这些模型进行推断。通过Medical-Grade Platform，HOPPR的目标是加快LVLM解决方案在医学成像中的部署，并最终优化放射科医生的工作流程以及满足该领域不断增长的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Technological advances in artificial intelligence (AI) have enabled thedevelopment of large vision language models (LVLMs) that are trained onmillions of paired image and text samples. Subsequent research efforts havedemonstrated great potential of LVLMs to achieve high performance in medicalimaging use cases (e.g., radiology report generation), but there remainbarriers that hinder the ability to deploy these solutions broadly. Theseinclude the cost of extensive computational requirements for developing largescale models, expertise in the development of sophisticated AI models, and thedifficulty in accessing substantially large, high-quality datasets thatadequately represent the population in which the LVLM solution is to bedeployed. The HOPPR Medical-Grade Platform addresses these barriers byproviding powerful computational infrastructure, a suite of foundation modelson top of which developers can fine-tune for their specific use cases, and arobust quality management system that sets a standard for evaluating fine-tunedmodels for deployment in clinical settings. The HOPPR Platform has access tomillions of imaging studies and text reports sourced from hundreds of imagingcenters from diverse populations to pretrain foundation models and enable usecase-specific cohorts for fine-tuning. All data are deidentified and securelystored for HIPAA compliance. Additionally, developers can securely host modelson the HOPPR platform and access them via an API to make inferences using thesemodels within established clinical workflows. With the Medical-Grade Platform,HOPPR's mission is to expedite the deployment of LVLM solutions for medicalimaging and ultimately optimize radiologist's workflows and meet the growingdemands of the field.</description>
      <author>example@mail.com (Kalina P. Slavkova, Melanie Traughber, Oliver Chen, Robert Bakos, Shayna Goldstein, Dan Harms, Bradley J. Erickson, Khan M. Siddiqui)</author>
      <guid isPermaLink="false">2411.17891v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network for Cerebral Blood Flow Prediction With Clinical Datasets</title>
      <link>http://arxiv.org/abs/2411.17971v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于图神经网络（GNN）的方法，用于预测大脑血管网络中之前未见过的结构中的血液流动和压力。&lt;h4&gt;背景&lt;/h4&gt;准确地预测脑血流量对于诊断和治疗脑血管疾病至关重要。传统的计算方法通常会带来较高的计算成本，限制了它们在临床实时应用中的实用性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够处理复杂异常血管几何形状、具有广泛适应性的图神经网络模型，用于预测大脑血管中未见过结构的血液流动和压力。&lt;h4&gt;方法&lt;/h4&gt;利用患有狭窄症患者的大规模临床数据集来训练该GNN模型，并在不同的流入条件、血管拓扑结构以及网络连接性下测试其性能。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与真实值相比，在足够多的数据训练后，GNN对于压力预测的皮尔逊相关系数达到0.727，对流量预测为0.824。这些结果显示了GNN在实时脑血管诊断中的潜在应用价值。&lt;h4&gt;结论&lt;/h4&gt;提出的基于图神经网络的方法展现出了处理复杂及病理学血管网络的强大能力，并且有可能实现实时的临床应用。&lt;h4&gt;翻译&lt;/h4&gt;准确预测脑血流量对于诊断和治疗脑血管疾病至关重要。传统计算方法通常会产生高昂的计算成本，从而限制其在实时临床应用中的实用性。本文提出了一种图神经网络（GNN）来预测未曾在训练数据中出现过的复杂且异常的大脑血管结构中的血液流动和压力情况。该GNN模型使用了狭窄症患者的临床数据集，并进行了广泛的流入条件、血管拓扑以及网络连接性的训练，以增强其泛化能力。实验结果表明，在足够的训练数据下，对于预测的压力值和流量的皮尔逊相关系数分别为0.727和0.824。这些发现证明了GNN在实时脑血管诊断中的潜在应用价值，特别是针对复杂及病理性血管网络的处理方面具有独特优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of cerebral blood flow is essential for the diagnosis andtreatment of cerebrovascular diseases. Traditional computational methods,however, often incur significant computational costs, limiting theirpracticality in real-time clinical applications. This paper proposes a graphneural network (GNN) to predict blood flow and pressure in previously unseencerebral vascular network structures that were not included in training data.The GNN was developed using clinical datasets from patients with stenosis,featuring complex and abnormal vascular geometries. Additionally, the GNN modelwas trained on data incorporating a wide range of inflow conditions, vesseltopologies, and network connectivities to enhance its generalizationcapability. The approach achieved Pearson's correlation coefficients of 0.727for pressure and 0.824 for flow rate, with sufficient training data. Thesefindings demonstrate the potential of the GNN for real-time cerebrovasculardiagnostics, particularly in handling intricate and pathological vascularnetworks.</description>
      <author>example@mail.com (Seungyeon Kim, Wheesung Lee, Sung-Ho Ahn, Do-Eun Lee, Tae-Rin Lee)</author>
      <guid isPermaLink="false">2411.17971v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>ReC-TTT: Contrastive Feature Reconstruction for Test-Time Training</title>
      <link>http://arxiv.org/abs/2411.17869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习在各种计算机视觉任务中取得了显著进展并展示了出色的结果。然而，适应数据分布的实时变化依然是一个重要的挑战。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种新的测试时训练技术ReC-TTT来解决模型无法有效处理新域问题的问题。&lt;h4&gt;方法&lt;/h4&gt;利用对比表示学习最近在无监督任务中的成就，ReC-TTT引入了一种生成判别输入数据视图的方法以适应新领域。该技术使用跨重构作为冻结编码器和两个可训练编码器之间的辅助任务，并利用一个共享的解码器进行特征提取。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，在大多数域迁移分类挑战中，ReC-TTT的表现优于其他最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;ReC-TTT通过在测试时调整编码器来提高深度学习模型对未见过领域的适应能力，从而增强其泛化性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要的中文翻译内容&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/warpcut/ReC-TTT&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The remarkable progress in deep learning (DL) showcases outstanding resultsin various computer vision tasks. However, adaptation to real-time variationsin data distributions remains an important challenge. Test-Time Training (TTT)was proposed as an effective solution to this issue, which increases thegeneralization ability of trained models by adding an auxiliary task at traintime and then using its loss at test time to adapt the model. Inspired by therecent achievements of contrastive representation learning in unsupervisedtasks, we propose ReC-TTT, a test-time training technique that can adapt a DLmodel to new unseen domains by generating discriminative views of the inputdata. ReC-TTT uses cross-reconstruction as an auxiliary task between a frozenencoder and two trainable encoders, taking advantage of a single shareddecoder. This enables, at test time, to adapt the encoders to extract featuresthat will be correctly reconstructed by the decoder that, in this phase, isfrozen on the source domain. Experimental results show that ReC-TTT achievesbetter results than other state-of-the-art techniques in most domain shiftclassification challenges.</description>
      <author>example@mail.com (Marco Colussi, Sergio Mascetti, Jose Dolz, Christian Desrosiers)</author>
      <guid isPermaLink="false">2411.17869v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Autoencoders for Few-shot Image Generation in Hyperbolic Space</title>
      <link>http://arxiv.org/abs/2411.17784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了Hyperbolic Diffusion Autoencoders (HypDAE)，一种在双曲空间中操作的新方法，用于生成未见过类别的高质量和多样性的图像。&lt;h4&gt;背景&lt;/h4&gt;目前的少量样本图像生成方法面临着质量与多样性之间的权衡，并且对于新生成图像属性的控制有限。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法来解决现有技术中的问题，以提供更好的质量和多样性平衡以及对生成过程的高度可控制性。&lt;h4&gt;方法&lt;/h4&gt;HypDAE利用预训练的基础模型，在双曲空间中捕捉不同类别之间的层级关系，并通过调整双曲圆盘内的半径来引入额外的语义多样性控制。&lt;h4&gt;主要发现&lt;/h4&gt;实验和可视化表明，与之前的方法相比，HypDAE在质量和多样性之间提供了更佳的平衡，并且生成过程是高度可控制和解释性的。&lt;h4&gt;结论&lt;/h4&gt;该研究通过使用双曲空间表示成功地提高了少量样本图像生成的质量、多样性和可控性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot image generation aims to generate diverse and high-quality imagesfor an unseen class given only a few examples in that class. However, existingmethods often suffer from a trade-off between image quality and diversity whileoffering limited control over the attributes of newly generated images. In thiswork, we propose Hyperbolic Diffusion Autoencoders (HypDAE), a novel approachthat operates in hyperbolic space to capture hierarchical relationships amongimages and texts from seen categories. By leveraging pre-trained foundationmodels, HypDAE generates diverse new images for unseen categories withexceptional quality by varying semantic codes or guided by textualinstructions. Most importantly, the hyperbolic representation introduces anadditional degree of control over semantic diversity through the adjustment ofradii within the hyperbolic disk. Extensive experiments and visualizationsdemonstrate that HypDAE significantly outperforms prior methods by achieving asuperior balance between quality and diversity with limited data and offers ahighly controllable and interpretable generation process.</description>
      <author>example@mail.com (Lingxiao Li, Kaixuan Fan, Boqing Gong, Xiangyu Yue)</author>
      <guid isPermaLink="false">2411.17784v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>PATHS: A Hierarchical Transformer for Efficient Whole Slide Image Analysis</title>
      <link>http://arxiv.org/abs/2411.18225v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为PATHS（Pathology Transformer with Hierarchical Selection）的新颖算法，用于计算病理学中的滑动级别任务的弱监督表示学习。该方法通过分层选择的方式处理图像补丁，显著减少了需要分析的数据量。&lt;h4&gt;背景&lt;/h4&gt;近年来，对整个幻灯片图像（WSIs）进行计算分析取得了重要进展，尤其是在生存预测和癌症亚型预测等诊断和预后任务中。然而，由于这些滑动可能非常大，且包含大量无关信息的补丁，使得处理效率低下。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法PATHS，用于提高病理图像的表示学习效果，并减少不必要的数据量以简化计算过程。&lt;h4&gt;方法&lt;/h4&gt;PATHS通过在每个放大级别递归过滤补丁来实现分层选择，只保留与诊断相关的少量关键补丁。该算法模仿了人类病理学家跨不同放大倍率检查幻灯片的方式。&lt;h4&gt;主要发现&lt;/h4&gt;PATHS在TCGA五大数据集上的滑动级别预测任务中表现优于现有方法，并且处理的数据量仅为整个滑动的一部分。&lt;h4&gt;结论&lt;/h4&gt;通过使用分层选择机制，PATHS能够在减少计算成本的同时提高表示学习的效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;计算分析完整幻灯片图像（WSIs）在近年来取得了显著进展，在生存预测或癌症亚型预测等重要诊断和预后任务中应用广泛。然而，处理整个可能高达$150,000 	imes 150,000$像素的滑动非常具有挑战性，需要廉价的特征聚合方法。我们提出了分层选择病理学变换器（PATHS），一种新颖的自上而下的方法，用于计算病理学中基于层次弱监督的学习。该算法模仿人类病理学家在不同放大倍率下检查幻灯片的方式，递归地过滤掉每个级别上的无关补丁。我们的方法克服了处理整个滑动的问题，并提供了区域重要性的一种简单且可解释的度量标准。我们在TCGA五大数据集上应用PATHS并取得了优于现有方法的结果，在滑动级预测任务中实现了更高的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational analysis of whole slide images (WSIs) has seen significantresearch progress in recent years, with applications ranging across importantdiagnostic and prognostic tasks such as survival or cancer subtype prediction.Many state-of-the-art models process the entire slide - which may be as largeas $150,000 \times 150,000$ pixels - as a bag of many patches, the size ofwhich necessitates computationally cheap feature aggregation methods. However,a large proportion of these patches are uninformative, such as those containingonly healthy or adipose tissue, adding significant noise and size to the bag.We propose Pathology Transformer with Hierarchical Selection (PATHS), a noveltop-down method for hierarchical weakly supervised representation learning onslide-level tasks in computational pathology. PATHS is inspired by thecross-magnification manner in which a human pathologist examines a slide,recursively filtering patches at each magnification level to a small subsetrelevant to the diagnosis. Our method overcomes the complications of processingthe entire slide, enabling quadratic self-attention and providing a simpleinterpretable measure of region importance. We apply PATHS to five datasets ofThe Cancer Genome Atlas (TCGA), and achieve superior performance on slide-levelprediction tasks when compared to previous methods, despite processing only asmall proportion of the slide.</description>
      <author>example@mail.com (Zak Buzzard, Konstantin Hemker, Nikola Simidjievski, Mateja Jamnik)</author>
      <guid isPermaLink="false">2411.18225v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Causal and Local Correlations Based Network for Multivariate Time Series Classification</title>
      <link>http://arxiv.org/abs/2411.18008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted on April 03, 2023; major revisions on March 25, 2024; minor
  revisions on July 9, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了基于因果性和局部相关性的网络（CaLoNet）用于多变量时间序列的分类。&lt;h4&gt;背景&lt;/h4&gt;时间序列分类吸引了大量研究者的关注，但现有方法常忽略维度间的空间相关性及特征间局部相关性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够处理多变量时间序列分类问题的新模型。&lt;h4&gt;方法&lt;/h4&gt;{'构建因果关系图': '使用因果建模捕捉维度间的一对一空间相关性以构造图结构', '融合局部相关性': '采用关系提取网络来获得长期依赖特征', '集成到GNN': '将生成的图结构和长期依赖特性整合进图形神经网络'}&lt;h4&gt;主要发现&lt;/h4&gt;CaLoNet在UEA数据集上的实验结果与当前最先进的方法性能相当。&lt;h4&gt;结论&lt;/h4&gt;通过考虑时间和空间的相关性，模型改进了时间序列分类任务中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, time series classification has attracted the attention of a largenumber of researchers, and hundreds of methods have been proposed. However,these methods often ignore the spatial correlations among dimensions and thelocal correlations among features. To address this issue, the causal and localcorrelations based network (CaLoNet) is proposed in this study for multivariatetime series classification. First, pairwise spatial correlations betweendimensions are modeled using causality modeling to obtain the graph structure.Then, a relationship extraction network is used to fuse local correlations toobtain long-term dependency features. Finally, the graph structure andlong-term dependency features are integrated into the graph neural network.Experiments on the UEA datasets show that CaLoNet can obtain competitiveperformance compared with state-of-the-art methods.</description>
      <author>example@mail.com (Mingsen Du, Yanxuan Wei, Xiangwei Zheng, Cun Ji)</author>
      <guid isPermaLink="false">2411.18008v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Learning 3D Representations from Procedural 3D Programs</title>
      <link>http://arxiv.org/abs/2411.17467v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://point-mae-zero.cs.virginia.edu/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从生成3D形状的程序化3D程序中学习无标签3D点云表示的方法，这种方法可以在不依赖于复杂的3D资产采集的情况下进行大规模训练。&lt;h4&gt;背景&lt;/h4&gt;自监督学习作为一种有前途的方法已经被用于获取可转移的3D表示形式。与2D图像相比，3D模型的数据采集成本更高且版权问题复杂。&lt;h4&gt;目的&lt;/h4&gt;为了克服传统方法在数据收集上的挑战，作者提出了一种从程序化生成的3D形状中学习3D表示的新途径。&lt;h4&gt;方法&lt;/h4&gt;通过使用简单的几何基元和增强技术自动生成大量3D点云，并从中学习到有效的3D表示形式。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，基于合成数据集获得的3D表示在多个下游任务上表现优异，例如形状分类、部件分割以及掩码点云补全等。此外，分析还指出当前的方法主要是捕捉了几何结构而非高级语义信息。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了通过程序化生成数据学习3D表示的有效性，并为未来的研究方向提供了启示。&lt;h4&gt;翻译&lt;/h4&gt;自监督学习已经成为从无标签的3D点云中获取可转移的三维表征的一种有前景的方法。与广泛可用的2D图像不同，获得高质量的3D模型资产需要专业的知识或昂贵的专业扫描设备，从而导致数据难以大规模收集并引发版权问题。为了解决这些问题，本文提出了一种新的方法：从使用简单几何原语和增强技术自动生成三维形状的程序化3D程序中学习3D表示。尽管这些合成的数据缺乏明确的语义信息，但它们在各种下游任务（如形状分类、部件分割以及掩码点云补全）中的表现与现有的使用具有清晰语义定义的模型（例如飞机模型）的学习到的最先进的三维表征相当。此外，研究还揭示了当前自监督学习方法主要关注于捕捉几何结构而非高级别语义的事实。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has emerged as a promising approach for acquiringtransferable 3D representations from unlabeled 3D point clouds. Unlike 2Dimages, which are widely accessible, acquiring 3D assets requires specializedexpertise or professional 3D scanning equipment, making it difficult to scaleand raising copyright concerns. To address these challenges, we proposelearning 3D representations from procedural 3D programs that automaticallygenerate 3D shapes using simple primitives and augmentations.  Remarkably, despite lacking semantic content, the 3D representations learnedfrom this synthesized dataset perform on par with state-of-the-artrepresentations learned from semantically recognizable 3D models (e.g.,airplanes) across various downstream 3D tasks, including shape classification,part segmentation, and masked point cloud completion. Our analysis furthersuggests that current self-supervised learning methods primarily capturegeometric structures rather than high-level semantics.</description>
      <author>example@mail.com (Xuweiyi Chen, Zezhou Cheng)</author>
      <guid isPermaLink="false">2411.17467v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Manual-PA: Learning 3D Part Assembly from Instruction Diagrams</title>
      <link>http://arxiv.org/abs/2411.18011v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种利用图解手册指导家具组装的方法，解决了在装配过程中选择零件和估计它们的连接姿态这一离散-连续优化问题。&lt;h4&gt;背景&lt;/h4&gt;组装家具的任务涉及从组合庞大但稀疏的解决方案空间中挑选零件并以物理上真实的方式估计其连接姿态。该任务对于当前机器学习模型来说具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;通过利用图解手册中的装配说明来解决这个任务，将问题划分为离散和连续两个阶段。&lt;h4&gt;方法&lt;/h4&gt;提出了Manual-PA框架，这是一个基于Transformer的使用对比学习基础结构在图纸中定位3D零件的方法，并预测装配顺序以及推断每个部件相对于最终家具模型的位置姿态。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，在基准数据集PartNet上，利用图解和零件顺序可以显著提高组装性能。此外，Manual-PA框架对于真实世界的IKEA家具组装具有强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;通过将图解手册中的信息与3D模型相结合，可以有效解决家具组装问题，并且这种技术能够推广到实际应用中去。&lt;h4&gt;翻译&lt;/h4&gt;组装家具相当于解决一个离散-连续优化任务，该任务需要选择零件进行组装并以物理上真实的方式估计它们的连接姿态。当前机器学习模型难以应对这个具有组合庞大但稀疏解空间的问题。本文尝试通过利用通常伴随家具零件提供的图解手册中的装配说明来解决此问题。关键见解是使用这些图纸中的线索将问题划分为离散和连续两个阶段。具体来说，我们提出了Manual-PA框架，这是一个基于Transformer的指导性3D部件组装框架，它在对比学习基础结构的帮助下，学会以语义方式将3D部件与手册中的插图对齐，并通过将其与手册中显示的最终家具相关联来预测装配顺序并推断每个部分的6D姿态。为了验证我们方法的有效性，在基准PartNet数据集上进行了实验。结果显示，使用图纸和零件顺序可以显著提高组装性能。此外，Manual-PA在IKEA-Manual数据集上的真实世界IKEA家具组装中显示出强大的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Assembling furniture amounts to solving the discrete-continuous optimizationtask of selecting the furniture parts to assemble and estimating theirconnecting poses in a physically realistic manner. The problem is hampered byits combinatorially large yet sparse solution space thus making learning toassemble a challenging task for current machine learning models. In this paper,we attempt to solve this task by leveraging the assembly instructions providedin diagrammatic manuals that typically accompany the furniture parts. Our keyinsight is to use the cues in these diagrams to split the problem into discreteand continuous phases. Specifically, we present Manual-PA, a transformer-basedinstruction Manual-guided 3D Part Assembly framework that learns tosemantically align 3D parts with their illustrations in the manuals using acontrastive learning backbone towards predicting the assembly order and infersthe 6D pose of each part via relating it to the final furniture depicted in themanual. To validate the efficacy of our method, we conduct experiments on thebenchmark PartNet dataset. Our results show that using the diagrams and theorder of the parts lead to significant improvements in assembly performanceagainst the state of the art. Further, Manual-PA demonstrates stronggeneralization to real-world IKEA furniture assembly on the IKEA-Manualdataset.</description>
      <author>example@mail.com (Jiahao Zhang, Anoop Cherian, Cristian Rodriguez, Weijian Deng, Stephen Gould)</author>
      <guid isPermaLink="false">2411.18011v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Helvipad: A Real-World Dataset for Omnidirectional Stereo Depth Estimation</title>
      <link>http://arxiv.org/abs/2411.18335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://vita-epfl.github.io/Helvipad&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了一个名为Helvipad的现实世界数据集，用于全方位立体深度估计。&lt;h4&gt;背景&lt;/h4&gt;尽管在立体深度估计方面取得了显著进展，但由于缺乏适当的数据，全方位成像仍然被较少探索。&lt;h4&gt;目的&lt;/h4&gt;通过提供一个包含40K帧视频序列、跨越各种环境的真实世界数据集来促进全方位立体深度估计的研究。&lt;h4&gt;方法&lt;/h4&gt;{'数据收集方式': '使用两个360°相机和LiDAR传感器收集数据，采用顶部-底部设置。', '标签生成方式': '通过将3D点云投影到等矩形图像上获得准确的深度和视差标签。', '训练集扩充': '提供了增强的训练集合，增加了标签密度，通过使用深度完成方法实现。', '基准测试模型': '对最先进的立体深度估计模型进行全方位和标准图像的基准测试。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'挑战性问题': '虽然最近的方法在标准场景中表现良好，但在全方位成像中的准确度估计仍然是一个重大挑战。', '性能改进': '介绍了必要的适应措施以提高立体模型在全方位成像中的性能。'}&lt;h4&gt;结论&lt;/h4&gt;通过介绍Helvipad数据集和对现有模型的必要调整，为全方位立体深度估计提供了新的研究方向和发展机会。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管在立体深度估计方面取得了重大进展，但由于缺乏适当的数据，全方位成像仍然较少被探索。我们介绍了Helvipad——一个用于全方位立体深度估计的真实世界数据集，该数据集包括来自视频序列的40K帧图像，跨越各种环境，包括拥挤的室内和室外场景以及多样化的照明条件。通过使用两个360°相机在顶部-底部设置下收集的数据，并结合LiDAR传感器，我们获得了准确的深度和视差标签，方法是将3D点云投影到等矩形图像上。此外，我们还提供了一个经过增强的训练集合，显著提高了标签密度，通过使用深度完成技术实现。对领先的立体深度估计模型进行了全方位图像和平面图像的标准基准测试。结果显示，尽管最近的方法在标准场景中表现良好，在全方位成像中的准确度估计仍然存在重大挑战。为了应对这一问题，我们介绍了必要的调整措施以提高立体模型的性能，并取得了改进的结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vita-epfl/Helvipad&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite considerable progress in stereo depth estimation, omnidirectionalimaging remains underexplored, mainly due to the lack of appropriate data. Weintroduce Helvipad, a real-world dataset for omnidirectional stereo depthestimation, consisting of 40K frames from video sequences across diverseenvironments, including crowded indoor and outdoor scenes with diverse lightingconditions. Collected using two 360{\deg} cameras in a top-bottom setup and aLiDAR sensor, the dataset includes accurate depth and disparity labels byprojecting 3D point clouds onto equirectangular images. Additionally, weprovide an augmented training set with a significantly increased label densityby using depth completion. We benchmark leading stereo depth estimation modelsfor both standard and omnidirectional images. The results show that whilerecent stereo methods perform decently, a significant challenge persists inaccurately estimating depth in omnidirectional imaging. To address this, weintroduce necessary adaptations to stereo models, achieving improvedperformance.</description>
      <author>example@mail.com (Mehdi Zayene, Jannik Endres, Albias Havolli, Charles Corbière, Salim Cherkaoui, Alexandre Kontouli, Alexandre Alahi)</author>
      <guid isPermaLink="false">2411.18335v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>RS-vHeat: Heat Conduction Guided Efficient Remote Sensing Foundation Model</title>
      <link>http://arxiv.org/abs/2411.17984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 9 figures and 9 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于热传导模型的多模态遥感基础模型RS-vHeat，旨在解决高分辨率遥感图像处理中的计算效率和可解释性问题。&lt;h4&gt;背景&lt;/h4&gt;传统的遥感任务特定模型设计在多个任务中扩展性较差。当前的遥感基础模型虽然具有更大的跨任务扩展能力，但在处理高分辨率遥感图像时面临计算效率低、可解释性差的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的热传导运算符和自监督学习策略，通过模拟高分辨率遥感图像中的局部区域相关性来提高计算效率并增强性能。&lt;h4&gt;方法&lt;/h4&gt;[{'RS-vHeat1': '应用复杂度为$O(N^{1.5})$的热传导操作器（HCO），具备全局感受野，减少计算开销同时捕获遥感目标结构信息以引导热扩散。'}, {'RS-vHeat2': '通过基于频域层次遮罩和多域重建的自监督策略学习不同场景中的频率分布表示。'}]&lt;h4&gt;主要发现&lt;/h4&gt;['与最先进的技术相比，在4个任务和10个数据集上显著提高了效率和性能。', '相比于注意力机制为基础的遥感基础模型，RS-vHeat减少了84%的记忆消耗，降低了24%的FLOPs，并将吞吐量提高了2.7倍。']&lt;h4&gt;结论&lt;/h4&gt;基于热传导物理过程的设计思想为解决高分辨率遥感图像处理中的计算效率问题提供了一种新的解决方案，具有较好的实用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容已经完整地翻译成中文并以分点的形式总结出来。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote sensing foundation models largely break away from the traditionalparadigm of designing task-specific models, offering greater scalability acrossmultiple tasks. However, they face challenges such as low computationalefficiency and limited interpretability, especially when dealing withhigh-resolution remote sensing images. To overcome these, we draw inspirationfrom heat conduction, a physical process modeling local heat diffusion.Building on this idea, we are the first to explore the potential of using theparallel computing model of heat conduction to simulate the local regioncorrelations in high-resolution remote sensing images, and introduce RS-vHeat,an efficient multi-modal remote sensing foundation model. Specifically,RS-vHeat 1) applies the Heat Conduction Operator (HCO) with a complexity of$O(N^{1.5})$ and a global receptive field, reducing computational overheadwhile capturing remote sensing object structure information to guide heatdiffusion; 2) learns the frequency distribution representations of variousscenes through a self-supervised strategy based on frequency domainhierarchical masking and multi-domain reconstruction; 3) significantly improvesefficiency and performance over state-of-the-art techniques across 4 tasks and10 datasets. Compared to attention-based remote sensing foundation models, wereduces memory consumption by 84%, decreases FLOPs by 24% and improvesthroughput by 2.7 times.</description>
      <author>example@mail.com (Huiyang Hu, Peijin Wang, Hanbo Bi, Boyuan Tong, Zhaozhi Wang, Wenhui Diao, Hao Chang, Yingchao Feng, Ziqi Zhang, Qixiang Ye, Kun Fu, Xian Sun)</author>
      <guid isPermaLink="false">2411.17984v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>From Exploration to Revelation: Detecting Dark Patterns in Mobile Apps</title>
      <link>http://arxiv.org/abs/2411.18084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了一种新的系统AppRay，它结合了任务导向的应用程序探索和自动化暗模式检测，减少了人工工作量。&lt;h4&gt;背景&lt;/h4&gt;移动应用程序在日常生活中至关重要，但它们经常使用视觉或语言技巧来操纵用户行为。目前的研究主要依赖于手动方法来识别这些暗模式，这是一个耗时且难以跟上不断更新的新兴应用的过程。&lt;h4&gt;目的&lt;/h4&gt;为了弥补现有研究中的空白，开发了一种新的系统AppRay，以自动检测应用程序中的暗模式。&lt;h4&gt;方法&lt;/h4&gt;该系统的实现分为两个步骤：首先使用大规模语言模型的知识进行目标应用程序探索，并辅以传统的随机探索来捕获更广泛的UI状态。其次，利用基于对比学习的多标签分类器和规则引擎的方法来进行静态和动态暗模式检测。&lt;h4&gt;主要发现&lt;/h4&gt;贡献了包含2185个独特欺骗性模式（包括149个动态实例）的数据集AppRay-Dark和AppRay-Light，并且实验结果表明，AppRay能够高效地探索应用程序并识别广泛的暗模式。&lt;h4&gt;结论&lt;/h4&gt;通过将任务导向的应用程序探索与自动化的暗模式检测相结合，可以显著减少人工工作量，并提高暗模式的检测效率。&lt;h4&gt;翻译&lt;/h4&gt;移动应用在日常生活中不可或缺，但它们经常使用视觉或语言技巧来操纵用户行为。现有的研究主要采用手动方法进行暗模式识别，这既耗时又难以跟上不断更新的应用程序。本文提出的AppRay系统通过结合任务导向的应用探索与自动化检测技术，减少了人工干预的需求，并显著提高了检测效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile apps are essential in daily life, yet they often employ dark patterns,such as visual tricks to highlight certain options or linguistic tactics to nagusers into making purchases, to manipulate user behavior. Current researchmainly uses manual methods to detect dark patterns, a process that istime-consuming and struggles to keep pace with continually updating andemerging apps. While some studies targeted at automated detection, they areconstrained to static patterns and still necessitate manual app exploration. Tobridge these gaps, we present AppRay, an innovative system that seamlesslyblends task-oriented app exploration with automated dark pattern detection,reducing manual efforts. Our approach consists of two steps: First, we harnessthe commonsense knowledge of large language models for targeted appexploration, supplemented by traditional random exploration to capture abroader range of UI states. Second, we developed a static and dynamic darkpattern detector powered by a contrastive learning-based multi-label classifierand a rule-based refiner to perform detection. We contributed two datasets,AppRay-Dark and AppRay-Light, with 2,185 unique deceptive patterns (including149 dynamic instances) across 18 types from 876 UIs and 871 benign UIs. Thesedatasets cover both static and dynamic dark patterns while preserving UIrelationships. Experimental results confirm that AppRay can efficiently explorethe app and identify a wide range of dark patterns with great performance.</description>
      <author>example@mail.com (Jieshan Chen, Zhen Wang, Jiamou Sun, Wenbo Zou, Zhenchang Xing, Qinghua Lu, Qing Huang, Xiwei Xu)</author>
      <guid isPermaLink="false">2411.18084v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Can bidirectional encoder become the ultimate winner for downstream applications of foundation models?</title>
      <link>http://arxiv.org/abs/2411.18021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures, FLLM2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章回顾了人工智能的发展历程，重点介绍了基础模型的兴起及其在自然语言处理中的应用。&lt;h4&gt;背景&lt;/h4&gt;过去几十年里，AI从最初的机器学习阶段发展到深度学习阶段，现在进入了基础模型时代。基础模型具备预训练、迁移学习和自监督学习的特点。&lt;h4&gt;目的&lt;/h4&gt;探讨基于BERT和GPT的基础模型如何推动NLP的发展，并分析这些模型在上下文信息捕捉与下游任务性能提升方面的表现。&lt;h4&gt;方法&lt;/h4&gt;文章对比了单向和双向语言模型（如GPT和BERT）的优缺点，还简要分析了一些改进后的BERT模型及其在SQuAD和GLUE数据集上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;1. BERT通过使用掩码语言模型突破了一维方法的语言建模限制。
2. 双向编码器可以更好地理解领域知识，并应用于下游任务。
3. 基础模型框架下，基于BERT的许多新模型在自然语言处理任务中取得了显著进展。&lt;h4&gt;结论&lt;/h4&gt;基础模型的重要性在于它们能有效捕捉上下文信息并提升各种NLP任务中的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over the past few decades, Artificial Intelligence(AI) has progressed fromthe initial machine learning stage to the deep learning stage, and now to thestage of foundational models. Foundational models have the characteristics ofpre-training, transfer learning, and self-supervised learning, and pre-trainedmodels can be fine-tuned and applied to various downstream tasks. Under theframework of foundational models, models such as Bidirectional EncoderRepresentations from Transformers(BERT) and Generative Pre-trainedTransformer(GPT) have greatly advanced the development of natural languageprocessing(NLP), especially the emergence of many models based on BERT. BERTbroke through the limitation of only using one-way methods for languagemodeling in pre-training by using a masked language model. It can capturebidirectional context information to predict the masked words in the sequence,this can improve the feature extraction ability of the model. This makes themodel very useful for downstream tasks, especially for specializedapplications. The model using the bidirectional encoder can better understandthe domain knowledge and be better applied to these downstream tasks. So wehope to help understand how this technology has evolved and improved modelperformance in various natural language processing tasks under the backgroundof foundational models and reveal its importance in capturing contextinformation and improving the model's performance on downstream tasks. Thisarticle analyzes one-way and bidirectional models based on GPT and BERT andcompares their differences based on the purpose of the model. It also brieflyanalyzes BERT and the improvements of some models based on BERT. The model'sperformance on the Stanford Question Answering Dataset(SQuAD) and GeneralLanguage Understanding Evaluation(GLUE) was compared.</description>
      <author>example@mail.com (Lewen Yang, Xuanyu Zhou, Juao Fan, Xinyi Xie, Shengxin Zhu)</author>
      <guid isPermaLink="false">2411.18021v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Deep learning-based spatio-temporal fusion for high-fidelity ultra-high-speed x-ray radiography</title>
      <link>http://arxiv.org/abs/2411.18441v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种基于深度学习的时空融合框架，用于结合两个互补的X射线图像序列来重构具有高空间分辨率、高帧率和高保真度的目标图像序列。&lt;h4&gt;背景&lt;/h4&gt;全场超高速(X射线)成像实验被广泛应用以表征各种过程和现象。然而，在不同的配置下联合获取X射线视频的潜力尚未完全开发。&lt;h4&gt;目的&lt;/h4&gt;研究一种深度学习框架，将两种互补的X射线图像序列融合为具有高空间分辨率、高帧率和高质量的目标图像。&lt;h4&gt;方法&lt;/h4&gt;采用迁移学习策略训练模型，并将其与基准深度学习模型、贝叶斯融合框架以及双三次插值法在两个独立的数据集上进行比较。主要对比PSNR、AAD和SSIM等指标的性能。&lt;h4&gt;主要发现&lt;/h4&gt;提出的时空融合框架优于其他方法，在不同输入帧间隔和图像噪声水平下表现出色。通过低分辨率序列中的三个连续图像（空间分辨率为4倍较低）以及高分辨率序列中的两个图像（帧速率为20倍较慢），所提出的方法分别达到了37.57 dB和35.15 dB的平均PSNR。&lt;h4&gt;结论&lt;/h4&gt;结合适当的高速相机配置，提出的框架将提高超高速X射线成像实验的性能和科学价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Full-field ultra-high-speed (UHS) x-ray imaging experiments have been wellestablished to characterize various processes and phenomena. However, thepotential of UHS experiments through the joint acquisition of x-ray videos withdistinct configurations has not been fully exploited. In this paper, weinvestigate the use of a deep learning-based spatio-temporal fusion (STF)framework to fuse two complementary sequences of x-ray images and reconstructthe target image sequence with high spatial resolution, high frame rate, andhigh fidelity. We applied a transfer learning strategy to train the model andcompared the peak signal-to-noise ratio (PSNR), average absolute difference(AAD), and structural similarity (SSIM) of the proposed framework on twoindependent x-ray datasets with those obtained from a baseline deep learningmodel, a Bayesian fusion framework, and the bicubic interpolation method. Theproposed framework outperformed the other methods with various configurationsof the input frame separations and image noise levels. With 3 subsequent imagesfrom the low resolution (LR) sequence of a 4-time lower spatial resolution andanother 2 images from the high resolution (HR) sequence of a 20-time lowerframe rate, the proposed approach achieved an average PSNR of 37.57 dB and35.15 dB, respectively. When coupled with the appropriate combination ofhigh-speed cameras, the proposed approach will enhance the performance andtherefore scientific value of the UHS x-ray imaging experiments.</description>
      <author>example@mail.com (Songyuan Tang, Tekin Bicer, Tao Sun, Kamel Fezzaa, Samuel J. Clark)</author>
      <guid isPermaLink="false">2411.18441v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Incomplete Multi-view Multi-label Classification via a Dual-level Contrastive Learning Framework</title>
      <link>http://arxiv.org/abs/2411.18267v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;最近，多视角和多标签分类已成为全面数据分析和探索的重要领域。然而，在实际场景中，视图和标签的不完整情况依然存在。&lt;h4&gt;背景&lt;/h4&gt;在现实世界的数据集中，多视角多标签分类问题经常遇到视图和标签缺失的情况。&lt;h4&gt;目的&lt;/h4&gt;本文提出一种针对双缺失（即同时包含视图和标签缺失）的多视角多标签分类任务的方法，并设计了双重对比学习框架来解决该问题。&lt;h4&gt;方法&lt;/h4&gt;{'创新点': '与现有工作不同，现有的工作是在同一特征空间中耦合一致性和特定于视图的信息。我们的方法则将这两种异质性质分别解耦到不同的空间中，并利用对比学习理论完全分离这两个属性。', '技术细节': ['引入了双通道解耦模块，该模块包含一个共享表示和特定于视图的表示，以有效地提取所有视角之间的一致性和互补信息', '通过在高层特征和语义标签上基于对比学习的方法进行一致性目标的操作，以便高效地从多视角表示中过滤出高质量的一致性信息']}&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，所提出的方法在多个广泛使用的基准数据集上具有更稳定且优越的分类性能。&lt;h4&gt;结论&lt;/h4&gt;该方法通过对比学习框架有效解决了双缺失情况下的多视角多标签分类问题，并展示了显著的技术优势和实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;最近，多视角和多标签分类已成为全面数据分析的重要领域。然而，在现实世界的数据集中，视图与标签不完整的情况依然常见。为了解决这一挑战，我们设计了一种双层次对比学习框架来处理同时包含视图和标签缺失的多视角多标签分类任务。这种方法通过将一致性信息和特定于视图的信息解耦到不同的空间中，并利用对比学习理论进行分离，从而有效地解决了现有方法在单一特征空间内结合这些属性的问题。实验结果表明，我们的方法具有更好的稳定性和分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, multi-view and multi-label classification have become significantdomains for comprehensive data analysis and exploration. However,incompleteness both in views and labels is still a real-world scenario formulti-view multi-label classification. In this paper, we seek to focus ondouble missing multi-view multi-label classification tasks and propose ourdual-level contrastive learning framework to solve this issue. Different fromthe existing works, which couple consistent information and view-specificinformation in the same feature space, we decouple the two heterogeneousproperties into different spaces and employ contrastive learning theory tofully disentangle the two properties. Specifically, our method first introducesa two-channel decoupling module that contains a shared representation and aview-proprietary representation to effectively extract consistency andcomplementarity information across all views. Second, to efficiently filter outhigh-quality consistent information from multi-view representations, twoconsistency objectives based on contrastive learning are conducted on thehigh-level features and the semantic labels, respectively. Extensiveexperiments on several widely used benchmark datasets demonstrate that theproposed method has more stable and superior classification performance.</description>
      <author>example@mail.com (Bingyan Nie, Wulin Xie, Jiang Long, Xiaohuan Lu)</author>
      <guid isPermaLink="false">2411.18267v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Dynamic LiDAR Odometry for Mobile Robots with Structured Point Clouds</title>
      <link>http://arxiv.org/abs/2411.18443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at 2024 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一种用于城市搜索和救援场景中移动机器人的实时动态LiDAR测距管道。&lt;h4&gt;背景&lt;/h4&gt;现有的动态对象检测方法通常依赖于预训练的网络或计算成本高昂的体积地图。这些方法在计算资源有限的机器人上效率低下。&lt;h4&gt;目的&lt;/h4&gt;为了提高在计算受限机器人上的效率，研究提出了一种新的方法来区分静态和动态物体，并将其集成到点云地图中。&lt;h4&gt;方法&lt;/h4&gt;利用范围图像分割技术和一种基于残差的新启发式算法，该方法能够有效地从环境中检测并跟踪移动的物体，特别是在存在大量动态物体的情况下表现良好。此方法在不预先对点云进行下采样处理（从而保持原始信息）的基础上实现了准确的对象检测。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进的体积方法相比，在计算时间更短的同时，该方法展示出了相当甚至更好的对象检测性能（仅增加14毫秒至测距模块用于动态物体的检测和跟踪），证明了其实时性、效率及准确性。实验结果表明其在真实数据集中的表现优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;提供了一种新的开源实现以及一个新的实际世界的数据集，以便进一步的研究和开发。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种用于城市搜索与救援场景中移动机器人的实时动态LiDAR测距管道。现有的动态对象检测方法通常依赖于预训练的网络或计算成本高昂的体积地图。为了提高在计算资源受限的机器人上的效率，我们重用了测距和检测模块之间的数据。利用范围图像分割技术及一种基于残差的新启发式算法，我们的方法能够区分静态与动态物体，并将其集成到点云地图中。这种方法展示了对大量动态物体环境下的鲁棒对象跟踪能力以及改进的地图准确性。即使对于诸如跑步中的人员这种高度非刚性物体，此方法也能够在点级别准确检测而无需预先下采样点云，因此不会造成信息损失。在模拟和真实世界数据上的评估验证了其计算效率：相较于最先进的体积方法，在相同的检测性能条件下，本方法的处理时间仅为前者的一部分（增加14毫秒至测距模块用于动态物体的检测和跟踪）。此实现及一个新的实际世界的数据集作为开源提供，以供进一步的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tu-darmstadt-ros-pkg/dynamic_direct_lidar_odometry&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a real-time dynamic LiDAR odometry pipeline for mobile robots inUrban Search and Rescue (USAR) scenarios. Existing approaches to dynamic objectdetection often rely on pretrained learned networks or computationallyexpensive volumetric maps. To enhance efficiency on computationally limitedrobots, we reuse data between the odometry and detection module. Utilizing arange image segmentation technique and a novel residual-based heuristic, ourmethod distinguishes dynamic from static objects before integrating them intothe point cloud map. The approach demonstrates robust object tracking andimproved map accuracy in environments with numerous dynamic objects. Evenhighly non-rigid objects, such as running humans, are accurately detected atpoint level without prior downsampling of the point cloud and hence, withoutloss of information. Evaluation on simulated and real-world data validates itscomputational efficiency. Compared to a state-of-the-art volumetric method, ourapproach shows comparable detection performance at a fraction of the processingtime, adding only 14 ms to the odometry module for dynamic object detection andtracking. The implementation and a new real-world dataset are available asopen-source for further research.</description>
      <author>example@mail.com (Jonathan Lichtenfeld, Kevin Daun, Oskar von Stryk)</author>
      <guid isPermaLink="false">2411.18443v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Learning optimal objective values for MILP</title>
      <link>http://arxiv.org/abs/2411.18321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了基于图神经网络（GNN）架构和动态特征预测MILP最优目标值的方法。&lt;h4&gt;背景&lt;/h4&gt;现代混合整数线性规划（MILP）求解器使用分支定界算法并结合多种辅助组件来加速搜索过程。近年来，机器学习在增强和支撑这些算法组件方面取得了爆炸性的进展。&lt;h4&gt;目的&lt;/h4&gt;提出一种预测最优目标值或当前最佳解是否为最优的策略。&lt;h4&gt;方法&lt;/h4&gt;引入基于图神经网络（GNN）架构的预测器，并使用动态特征进行改进。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果在各种基准测试上展示了高精度预测能力，优于现有方法。这表明将机器学习驱动的预测集成到MILP求解器中具有新的可能性。&lt;h4&gt;结论&lt;/h4&gt;研究建议了更智能的决策制定和性能提升的可能性，通过将ML预测集成到MILP求解器中。&lt;h4&gt;翻译&lt;/h4&gt;现代混合整数线性规划（MILP）求解器使用分支定界算法并结合多种辅助组件来加速搜索过程。近年来，机器学习在增强和支撑这些算法组件方面取得了爆炸性的进展。本文提出了一种预测最优目标值或当前最佳解是否为最优的策略，并引入了基于图神经网络（GNN）架构和动态特征的预测器。实验结果表明该方法在各种基准测试中表现出高精度，优于现有方法。这表明将机器学习驱动的预测集成到MILP求解器中的新机会，能够实现更智能的决策制定和性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lascavana/objvalprediction&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern Mixed Integer Linear Programming (MILP) solvers use theBranch-and-Bound algorithm together with a plethora of auxiliary componentsthat speed up the search. In recent years, there has been an explosivedevelopment in the use of machine learning for enhancing and supporting thesealgorithmic components. Within this line, we propose a methodology forpredicting the optimal objective value, or, equivalently, predicting if thecurrent incumbent is optimal. For this task, we introduce a predictor based ona graph neural network (GNN) architecture, together with a set of dynamicfeatures. Experimental results on diverse benchmarks demonstrate the efficacyof our approach, achieving high accuracy in the prediction task andoutperforming existing methods. These findings suggest new opportunities forintegrating ML-driven predictions into MILP solvers, enabling smarterdecision-making and improved performance.</description>
      <author>example@mail.com (Lara Scavuzzo, Karen Aardal, Neil Yorke-Smith)</author>
      <guid isPermaLink="false">2411.18321v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MM-Path: Multi-modal, Multi-granularity Path Representation Learning -- Extended Version</title>
      <link>http://arxiv.org/abs/2411.18428v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is an extended version of the paper accepted by KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;提出了一个新型的多模态、多层次路径表示学习框架（MM-Path），旨在通过整合道路路径和图像路径的数据来获取通用的路径表示。&lt;h4&gt;背景&lt;/h4&gt;在智能交通领域，开发有效的路径表示变得越来越重要。虽然预训练的路径表示模型已经显示出性能提升，但它们主要关注单一数据模式下的拓扑结构，而忽略了与路径相关的几何和上下文特征。多模态信息集成可以提供更全面的视角。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，该框架能够学习通用的路径表示，通过整合道路路径和图像路径的数据来提升表示准确性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;开发了一种多层次对齐策略，确保节点、子路段以及整个路段与相应的图像补丁之间信息同步。此外，还引入了一个基于图的跨模态残差融合组件，全面地在不同模式和粒度级别上融合信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证了MM-Path的有效性，在两个大规模现实世界数据集上的下游任务中表现优异。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效解决多模态数据异构性和语义对齐问题，提供更准确、通用的路径表示。相关代码可在GitHub上获取。&lt;h4&gt;翻译&lt;/h4&gt;开发有效的路径表示在智能交通领域的各个领域变得越来越重要。尽管预训练的路径学习模型已经显示出性能改进，但它们主要关注单一模式（如道路网络）中的拓扑结构，而忽视了与路径相关的图像（例如遥感图像）中的几何和上下文特征。整合多模态信息可以提供更全面的理解，提高表示准确性和泛化能力。然而，信息粒度的差异阻碍了基于道路网络的路径和基于图像的路径之间的语义对齐，并且多模态数据异质性给有效融合带来了重大挑战。为此，在本文中我们提出了一种新的多模态、多层次路径表示学习框架（MM-Path），它能够通过集成来自道路路径和图像路径的信息来学习通用路径表示。为了增强多模式数据的对齐，我们开发了一个多层次对准策略，系统地将节点、子路段以及整个路段与相应的图像补丁关联起来，确保详细局部信息和更广泛的全局背景同步。为了解决多模态数据异质性问题，我们引入了一个基于图的跨模态残差融合组件，用于全面地在不同模式和粒度级别上进行信息融合。最后，在两个大规模现实世界的数据集下的两个下游任务中进行了广泛实验，验证了所提出MM-Path的有效性。相关代码可在GitHub上获取：https://github.com/decisionintelligence/MM-Path。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/decisionintelligence/mm-path&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing effective path representations has become increasingly essentialacross various fields within intelligent transportation. Although pre-trainedpath representation learning models have shown improved performance, theypredominantly focus on the topological structures from single modality data,i.e., road networks, overlooking the geometric and contextual featuresassociated with path-related images, e.g., remote sensing images. Similar tohuman understanding, integrating information from multiple modalities canprovide a more comprehensive view, enhancing both representation accuracy andgeneralization. However, variations in information granularity impede thesemantic alignment of road network-based paths (road paths) and image-basedpaths (image paths), while the heterogeneity of multi-modal data posessubstantial challenges for effective fusion and utilization. In this paper, wepropose a novel Multi-modal, Multi-granularity Path Representation LearningFramework (MM-Path), which can learn a generic path representation byintegrating modalities from both road paths and image paths. To enhance thealignment of multi-modal data, we develop a multi-granularity alignmentstrategy that systematically associates nodes, road sub-paths, and road pathswith their corresponding image patches, ensuring the synchronization of bothdetailed local information and broader global contexts. To address theheterogeneity of multi-modal data effectively, we introduce a graph-basedcross-modal residual fusion component designed to comprehensively fuseinformation across different modalities and granularities. Finally, we conductextensive experiments on two large-scale real-world datasets under twodownstream tasks, validating the effectiveness of the proposed MM-Path. Thecode is available at: https://github.com/decisionintelligence/MM-Path.</description>
      <author>example@mail.com (Ronghui Xu, Hanyin Cheng, Chenjuan Guo, Hongfan Gao, Jilin Hu, Sean Bin Yang, Bin Yang)</author>
      <guid isPermaLink="false">2411.18428v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Semantic Asymmetry for Precise Gross Tumor Volume Segmentation of Nasopharyngeal Carcinoma in Planning CT</title>
      <link>http://arxiv.org/abs/2411.18290v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要类型&lt;/h4&gt;研究论文&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的直接在非对比计划CT图像上分割鼻咽癌原发肿瘤体积(GTV)的方法，使用3D语义不对称肿瘤分割(SATs)技术解决了由于肿瘤与周围正常组织对比度低而导致的手动标注困难问题。&lt;h4&gt;背景&lt;/h4&gt;放射治疗中常使用非对比计划CT来划定鼻咽癌的GTV以确保准确的辐射剂量传递。然而，肿瘤和邻近正常组织之间的低对比度使得医生在手动划分肿瘤时需要依靠诊断MRI提供指导。&lt;h4&gt;目的&lt;/h4&gt;提出一种不依赖于MRI或基于MRI衍生肿瘤掩膜对齐到计划CT的新方法，直接从非对比计划CT图像上分割鼻咽癌原发肿瘤体积(GTV)，从而避免潜在的注册误差。&lt;h4&gt;方法&lt;/h4&gt;引入了3D语义不对称肿瘤分割(SATs)方法，该方法利用健康鼻咽区域特征性的双边对称性以及鼻咽癌破坏这种对称性的特点。提出了一个Siamese对比学习分割框架，最小化无肿瘤区域原始和镜像位置之间的体素距离，并增加有肿瘤区域原始和镜像位置之间的距离，以增强语义不对称的敏感度。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示，该方法在内部测试和外部测试中均取得了最佳的鼻咽癌GTV分割性能。与现有最先进的技术相比，在外部测试中的Dice分数提高了至少2%绝对值，并且平均距离误差减少了12%。&lt;h4&gt;结论&lt;/h4&gt;通过SATs方法可以更准确地从非对比计划CT图像上进行肿瘤体积(GTV)的自动分割，减少手动标注时间和潜在的人为错误。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the radiation therapy of nasopharyngeal carcinoma (NPC), clinicianstypically delineate the gross tumor volume (GTV) using non-contrast planningcomputed tomography to ensure accurate radiation dose delivery. However, thelow contrast between tumors and adjacent normal tissues necessitates thatradiation oncologists manually delineate the tumors, often relying ondiagnostic MRI for guidance. % In this study, we propose a novel approach todirectly segment NPC gross tumors on non-contrast planning CT images,circumventing potential registration errors when aligning MRI or MRI-derivedtumor masks to planning CT. To address the low contrast issues between tumorsand adjacent normal structures in planning CT, we introduce a 3D SemanticAsymmetry Tumor segmentation (SATs) method. Specifically, we posit that ahealthy nasopharyngeal region is characteristically bilaterally symmetric,whereas the emergence of nasopharyngeal carcinoma disrupts this symmetry. Then,we propose a Siamese contrastive learning segmentation framework that minimizesthe voxel-wise distance between original and flipped areas without tumor andencourages a larger distance between original and flipped areas with tumor.Thus, our approach enhances the sensitivity of features to semanticasymmetries. % Extensive experiments demonstrate that the proposed SATsachieves the leading NPC GTV segmentation performance in both internal andexternal testing, \emph{e.g.}, with at least 2\% absolute Dice scoreimprovement and 12\% average distance error reduction when compared to otherstate-of-the-art methods in the external testing.</description>
      <author>example@mail.com (Zi Li, Ying Chen, Zeli Chen, Yanzhou Su, Tai Ma, Tony C. W. Mok, Yan-Jie Zhou, Yunhai Bai, Zhinlin Zheng, Le Lu, Yirui Wang, Jia Ge, Xianghua Ye, Senxiang Yan, Dakai Jin)</author>
      <guid isPermaLink="false">2411.18290v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A comparison of extended object tracking with multi-modal sensors in indoor environment</title>
      <link>http://arxiv.org/abs/2411.18476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本论文提出了一种高效的目标跟踪方法的初步研究，比较了两种具有显著价格差异的3D点云传感器：LiDAR和立体相机。&lt;h4&gt;背景&lt;/h4&gt;目标跟踪在机器人导航和自动驾驶等领域至关重要。然而，不同类型的3D传感技术（如LiDAR和立体相机）在性能和成本上存在较大差别。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过单个对象跟踪的初步工作，比较分析LiDAR与立体相机这两种传感器在目标跟踪任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;首先开发了一个快速启发式的目标检测器，利用环境和目标的先验信息。之后，将得到的目标点输入到扩展的对象跟踪框架中，在该框架下使用星凸超曲面模型来参数化目标形状。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，基于立体相机的目标跟踪方法在性能上与LiDAR传感器相当，但成本却相差十倍以上。&lt;h4&gt;结论&lt;/h4&gt;研究表明，对于一些应用场景来说，利用价格较低的立体相机进行对象跟踪是可能实现高性能和低成本兼顾的一种有效方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：This paper presents a preliminary study of an efficient object tracking approach, comparing the performance of two different 3D point cloud sensory sources: LiDAR and stereo cameras, which have significant price differences. In this preliminary work, we focus on single object tracking. We first developed a fast heuristic object detector that utilizes prior information about the environment and target. The resulting target points are subsequently fed into an extended object tracking framework, where the target shape is parameterized using a star-convex hypersurface model. Experimental results show that our object tracking method using a stereo camera achieves performance similar to that of a LiDAR sensor, with a cost difference of more than tenfold.&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a preliminary study of an efficient object trackingapproach, comparing the performance of two different 3D point cloud sensorysources: LiDAR and stereo cameras, which have significant price differences. Inthis preliminary work, we focus on single object tracking. We first developed afast heuristic object detector that utilizes prior information about theenvironment and target. The resulting target points are subsequently fed intoan extended object tracking framework, where the target shape is parameterizedusing a star-convex hypersurface model. Experimental results show that ourobject tracking method using a stereo camera achieves performance similar tothat of a LiDAR sensor, with a cost difference of more than tenfold.</description>
      <author>example@mail.com (Jiangtao Shuai, Martin Baerveldt, Manh Nguyen-Duc, Anh Le-Tuan, Manfred Hauswirth, Danh Le-Phuoc)</author>
      <guid isPermaLink="false">2411.18476v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Point Cloud Completion: Are We Ready For The Real-World?</title>
      <link>http://arxiv.org/abs/2411.17580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了用于点云补全任务的首个真实世界工业数据集RealPC，并展示了现有算法在处理实际数据时的效果不佳。&lt;h4&gt;背景&lt;/h4&gt;获取到的真实世界的点云数据常常是不完整且稀疏分布，这给点云补全任务带来了挑战。当前基准测试中使用的合成点云缺乏真实的拓扑特征。&lt;h4&gt;目的&lt;/h4&gt;通过引入一个真实世界工业点云数据集RealPC，以促进关于点云补全的研究，并展示利用代数拓扑和持久同调方法在这一领域的潜力。&lt;h4&gt;方法&lt;/h4&gt;使用了来自代数拓扑和持久同调的方法来揭示现有基准测试中使用的合成点云缺乏重要的拓扑特征。引入了一个包含21类工业结构的40,000对数据集RealPC，并研究了几种基线模型在该数据集上的表现。&lt;h4&gt;主要发现&lt;/h4&gt;现有的点云补全方法对于真实世界中的点云效果不佳，而RealPC数据集中存在大量的零维和一维持久同调特征。利用这些拓扑先验可以改善现有模型的表现。&lt;h4&gt;结论&lt;/h4&gt;通过引入新的数据集和拓扑学工具，能够促进更有效的点云补全技术的发展。&lt;h4&gt;翻译&lt;/h4&gt;在受限且具有挑战性的实际环境中获取的点云通常是不完整的、非均匀稀疏的或两者兼有。这些障碍给一个至关重要的任务——点云补全带来了严峻挑战。利用代数拓扑和持久同调（PH）的方法，我们证明了当前基准测试中使用的合成点云缺乏真实场景下采集到的重要拓扑特征。为了促进这方面的研究，本文贡献了一个首个实际工业点云数据集RealPC，包含约40,000对来自铁路设施中的21类不同结构的丰富多样的点云。我们在几个强大的基线上进行了基准测试，并发现现有方法在真实场景中表现糟糕。基于观察到RealPC含有多个零维和一维PH拓扑特征的事实，我们展示了将同调先验与现有工作的整合潜力。特别地，我们介绍了如何使用零维PH先验——以3D骨架的形式提取完整形状的全局拓扑信息——来帮助模型生成一致完整的形状。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point clouds acquired in constrained and challenging real-world settings areincomplete, non-uniformly sparse, or both. These obstacles present acutechallenges for a vital task - point cloud completion. Using tools fromAlgebraic Topology and Persistent Homology ($\mathcal{PH}$), we demonstratethat current benchmark synthetic point clouds lack rich topological featuresthat are important constituents of point clouds captured in realistic settings.To facilitate research in this direction, we contribute the first real-worldindustrial point cloud dataset for point cloud completion, RealPC - a diverseset of rich and varied point clouds, consisting of $\sim$ 40,000 pairs across21 categories of industrial structures in railway establishments. Our benchmarkresults on several strong baselines reveal a striking observation - theexisting methods are tailored for synthetic datasets and fail miserably inreal-world settings. Building on our observation that RealPC consists ofseveral 0 and 1-dimensional $\mathcal{PH}$-based topological features, wedemonstrate the potential of integrating Homology-based topological priors intoexisting works. More specifically, we present how 0-dimensional $\mathcal{PH}$priors, which extract the global topology of a complete shape in the form of a3-D skeleton, can assist a model in generating topologically-consistentcomplete shapes.</description>
      <author>example@mail.com (Stuti Pathak, Prashant Kumar, Nicholus Mboga, Gunther Steenackers, Rudi Penne)</author>
      <guid isPermaLink="false">2411.17580v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Towards Cross-device and Training-free Robotic Grasping in 3D Open World</title>
      <link>http://arxiv.org/abs/2411.18133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的机器人抓取管道，旨在实现开放世界环境下对未知物体的抓取任务，并支持不同场景下灵活使用3D点云分割模型。通过结合无训练二值聚类算法和深度学习技术，该方法增强了在复杂堆积场景中的应用性能。&lt;h4&gt;背景&lt;/h4&gt;目前大多数现有的机器抓取方案依赖于2D图像分割输出，难以准确获取深度信息，尤其是在复杂的堆放场景中表现不佳。3D点云数据虽然能够直接提供深度信息，但由于采集设备差异和数据无结构化问题，限制了其广泛适用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的管道机制，在无需事先训练的情况下执行开放环境下的物体抓取任务，并通过灵活使用多种3D点云分割模型来增强方法的通用性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;利用分割结果，本文引入了一种无须训练的二值聚类算法，该算法不仅能够提高分割精度，还具备将未知对象进行分类和定位的能力以执行抓取操作。&lt;h4&gt;主要发现&lt;/h4&gt;实验显示了所提出的方法在各种开放世界场景中的显著稳健性和通用性，包括不同环境、机器人类型、相机以及物体的情况。这些成果表明新方法对于实际应用具有重要意义。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了如何通过结合无训练算法和3D点云数据处理技术解决复杂堆积场景下的机器抓取挑战，开辟了开放世界环境中自动化的有效途径。&lt;h4&gt;翻译&lt;/h4&gt;机器人在开放式环境中的抓取是制造业和自动化流程的关键组成部分。虽然现有方法依赖于2D图像分割输出以促进抓取过程，但在复杂的堆放场景中准确确定深度信息依然是个难题，通常导致性能受限。相比之下，使用3D点云数据的方法能够直接捕捉深度信息，并且能有效应对多样化的复杂堆放情况。然而，由于数据采集设备的差异性和无结构化问题的存在，这些努力受到了阻碍。因此，许多研究局限于处理特定设置中的指定对象，从而限制了它们的实际应用范围。本文提出了一种新颖的管道机制，能够在开放环境中无需训练的情况下执行对未知物体的抓取任务，并支持不同场景中多种3D点云分割模型的应用。借助分割结果，我们建议使用一种无须训练的二值聚类算法来提高分割精度、分类和定位未知对象的能力以实现抓取操作。在实验中，我们探讨了各种开放世界情景，结果显示该管道机制具有出色的稳健性和通用性，适用于不同的环境、机器人类型、相机及物体情况。论文接受后将提供代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic grasping in the open world is a critical component of manufacturingand automation processes. While numerous existing approaches depend on 2Dsegmentation output to facilitate the grasping procedure, accuratelydetermining depth from 2D imagery remains a challenge, often leading to limitedperformance in complex stacking scenarios. In contrast, techniques utilizing 3Dpoint cloud data inherently capture depth information, thus enabling adeptlynavigating and manipulating a diverse range of complex stacking scenes.However, such efforts are considerably hindered by the variance in data capturedevices and the unstructured nature of the data, which limits theirgeneralizability. Consequently, much research is narrowly concentrated onmanaging designated objects within specific settings, which confines theirreal-world applicability. This paper presents a novel pipeline capable ofexecuting object grasping tasks in open-world scenarios even on previouslyunseen objects without the necessity for training. Additionally, our pipelinesupports the flexible use of different 3D point cloud segmentation modelsacross a variety of scenes. Leveraging the segmentation results, we propose toengage a training-free binary clustering algorithm that not only improvessegmentation precision but also possesses the capability to cluster andlocalize unseen objects for executing grasping operations. In our experiments,we investigate a range of open-world scenarios, and the outcomes underscore theremarkable robustness and generalizability of our pipeline, consistent acrossvarious environments, robots, cameras, and objects. The code will be madeavailable upon acceptance of the paper.</description>
      <author>example@mail.com (Weiguang Zhao, Chenru Jiang, Chengrui Zhang, Jie Sun, Yuyao Yan, Rui Zhang, Kaizhu Huang)</author>
      <guid isPermaLink="false">2411.18133v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Isolating authorship from content with semantic embeddings and contrastive learning</title>
      <link>http://arxiv.org/abs/2411.18472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了一种新的技术来减少作者身份识别中内容和风格之间的关联。&lt;h4&gt;背景&lt;/h4&gt;现代神经网络模型在使用对比学习区分不同作者时仍存在一定程度的内容泄露问题。&lt;h4&gt;目的&lt;/h4&gt;通过引入额外的硬负样本，旨在减轻内容与作者身份间的不可避免的影响和相关性。&lt;h4&gt;方法&lt;/h4&gt;采用信息噪声对比估计（InfoNCE）并结合语义相似度模型合成的硬负样本来进行对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;该技术可以将内容嵌入空间与风格嵌入空间分离，提高特征向量对作者写作风格信息的敏感性。实验结果表明，在两个不同数据集上性能有所提升，并在具有挑战性的场景下准确率提高了高达10%。&lt;h4&gt;结论&lt;/h4&gt;方法不仅增强了模型面对领域外任务时的表现能力，还保持了零样本学习的效果。&lt;h4&gt;翻译&lt;/h4&gt;作者身份识别问题通常通过对比学习来解决，但这种方法难以完全避免内容信息对结果的影响。本研究提出了一种新的技术，即利用额外的硬负样本来进行对比学习（InfoNCE），从而更好地分离出写作风格的信息，并在多个数据集上验证了该方法的有效性，尤其是在难度较高的情况下表现出明显改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Authorship has entangled style and content inside. Authors frequently writeabout the same topics in the same style, so when different authors write aboutthe exact same topic the easiest way out to distinguish them is byunderstanding the nuances of their style. Modern neural models for authorshipcan pick up these features using contrastive learning, however, some amount ofcontent leakage is always present. Our aim is to reduce the inevitable impactand correlation between content and authorship. We present a technique to usecontrastive learning (InfoNCE) with additional hard negatives syntheticallycreated using a semantic similarity model. This disentanglement technique aimsto distance the content embedding space from the style embedding space, leadingto embeddings more informed by style. We demonstrate the performance withablations on two different datasets and compare them on out-of-domainchallenges. Improvements are clearly shown on challenging evaluations onprolific authors with up to a 10% increase in accuracy when the settings areparticularly hard. Trials on challenges also demonstrate the preservation ofzero-shot capabilities of this method as fine tuning.</description>
      <author>example@mail.com (Javier Huertas-Tato, Adrián Girón-Jiménez, Alejandro Martín, David Camacho)</author>
      <guid isPermaLink="false">2411.18472v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Open Vocabulary Monocular 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.16833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://cvlab.cs.virginia.edu/ovmono3d&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新的任务——开放词汇单目3D物体检测，旨在从单一RGB图像中检测和定位预定义类别之外的三维空间中的对象。研究者建立了基线方法，并引入了一个类不可知的方法，该方法利用了开放词汇2D检测器并将二维边界框提升到三维空间。&lt;h4&gt;背景&lt;/h4&gt;目前的研究大多集中在封闭词汇表上的物体检测任务上，限制了在实际环境中处理未知类别或罕见类别的能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够从单张RGB图像中识别和定位所有可能的对象类别的方法，并提出了一种目标感知的评估协议来提高模型性能评估的一致性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;论文引入了一个类不可知的方法，该方法使用开放词汇2D检测器并将二维边界框提升到三维空间。此外，还提出了一种新的评估协议以应对现有数据集中的不一致问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的零样本3D检测方法在处理未见过的对象类别方面具有很强的泛化能力，并且该方法和评估协议有助于开发能够在真实场景中有效工作的开放词汇对象检测模型。&lt;h4&gt;结论&lt;/h4&gt;研究工作为解决开放式单目三维物体检测任务提供了一个新颖的方法框架，包括基线建立、类不可知方法引入以及新的目标感知评估协议。这为未来的研究开辟了道路，并展示了处理复杂多样的现实世界环境中的物体识别问题的巨大潜力。&lt;h4&gt;翻译&lt;/h4&gt;在这项工作中，我们开创性地研究了开放词汇单目3D物体检测的新任务，旨在从单一RGB图像中检测和定位三维空间中的对象，不限制在预定义的类别集中进行检测。我们形式化了这个问题，并建立了基线方法，引入了一种类不可知的方法，利用开放词汇2D检测器并将二维边界框提升到三维空间。我们的方法将物体在二维中的识别与定位任务解耦开来，使得估计3D边界框的任务可以推广到未见过的类别中。此外，我们还提出了一种目标感知评估协议来解决现有数据集中的一致性问题，提高了模型性能评估的可靠性。Omni3D数据集上的大量实验表明，在零样本情况下处理新型物体类别的3D检测任务时，所提出的这种方法非常有效，并验证了其强大的泛化能力。我们提出的方法和评估协议为开发能够在类别多样且复杂的现实世界环境中有效工作的开放词汇对象检测模型做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/UVA-Computer-Vision-Lab/ovmono3d&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we pioneer the study of open-vocabulary monocular 3D objectdetection, a novel task that aims to detect and localize objects in 3D spacefrom a single RGB image without limiting detection to a predefined set ofcategories. We formalize this problem, establish baseline methods, andintroduce a class-agnostic approach that leverages open-vocabulary 2D detectorsand lifts 2D bounding boxes into 3D space. Our approach decouples therecognition and localization of objects in 2D from the task of estimating 3Dbounding boxes, enabling generalization across unseen categories. Additionally,we propose a target-aware evaluation protocol to address inconsistencies inexisting datasets, improving the reliability of model performance assessment.Extensive experiments on the Omni3D dataset demonstrate the effectiveness ofthe proposed method in zero-shot 3D detection for novel object categories,validating its robust generalization capabilities. Our method and evaluationprotocols contribute towards the development of open-vocabulary objectdetection models that can effectively operate in real-world, category-diverseenvironments.</description>
      <author>example@mail.com (Jin Yao, Hao Gu, Xuweiyi Chen, Jiayun Wang, Zezhou Cheng)</author>
      <guid isPermaLink="false">2411.16833v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MetaGraphLoc: A Graph-based Meta-learning Scheme for Indoor Localization via Sensor Fusion</title>
      <link>http://arxiv.org/abs/2411.17781v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;MetaGraphLoc系统采用传感器融合、图神经网络（GNN）和元学习，以克服无线信号环境变化及数据不足对室内定位的影响。&lt;h4&gt;背景&lt;/h4&gt;准确的室内定位由于无线信号环境的变化和数据可用性的限制而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的室内定位系统MetaGraphLoc，通过传感器融合、图神经网络（GNN）和元学习来提高定位准确性。&lt;h4&gt;方法&lt;/h4&gt;{'1': '将接收到的信号强度指示器测量值与惯性测量单元数据集成以增强本地化精度', '2': '提出具有动态边缘构建功能（DEC）的GNN架构，捕捉接入点之间的空间关系和潜在的数据模式', '3': '采用元学习框架使GNN模型能够快速适应新的环境，并且在最少数据采集的情况下进行调整'}&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '数据融合将定位误差减少了15.92%', '2': '具有DEC的GNN在准确性方面比传统的深度神经网络表现好30.89%'}&lt;h4&gt;结论&lt;/h4&gt;MetaGraphLoc通过减少校准工作量和适应新环境的需求，为室内定位提供了有前景的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;准确的室内定位由于无线信号环境的变化以及数据可用性的限制而具有挑战性。本文介绍了一种新的系统MetaGraphLoc，该系统利用传感器融合、图神经网络（GNN）及元学习来克服这些局限性。MetaGraphLoc结合接收到的信号强度指示器测量值与惯性测量单元数据以提升定位精度。我们提出的一种新型GNN架构具有动态边缘构建功能（DEC），能捕捉接入点之间的空间关系和潜在的数据模式。该系统采用元学习框架，使GNN模型能够在新环境中仅通过最少的数据采集进行调整，从而大大减少校准工作量。广泛的评估证明了MetaGraphLoc的有效性：数据融合将定位误差减少了15.92%，强调了其重要性；具有DEC的GNN在准确性方面比传统的深度神经网络高出最多30.89%；元学习方法使得快速适应新环境成为可能，从而减少对大量数据采集的需求。这些改进使MetaGraphLoc成为了室内定位的一种有前景的技术解决方案，为不断发展的物联网网络中的导航和基于位置的服务的改善铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate indoor localization remains challenging due to variations inwireless signal environments and limited data availability. This paperintroduces MetaGraphLoc, a novel system leveraging sensor fusion, graph neuralnetworks (GNNs), and meta-learning to overcome these limitations. MetaGraphLocintegrates received signal strength indicator measurements with inertialmeasurement unit data to enhance localization accuracy. Our proposed GNNarchitecture, featuring dynamic edge construction (DEC), captures the spatialrelationships between access points and underlying data patterns. MetaGraphLocemploys a meta-learning framework to adapt the GNN model to new environmentswith minimal data collection, significantly reducing calibration efforts.Extensive evaluations demonstrate the effectiveness of MetaGraphLoc. Datafusion reduces localization error by 15.92%, underscoring its importance. TheGNN with DEC outperforms traditional deep neural networks by up to 30.89%,considering accuracy. Furthermore, the meta-learning approach enables efficientadaptation to new environments, minimizing data collection requirements. Theseadvancements position MetaGraphLoc as a promising solution for indoorlocalization, paving the way for improved navigation and location-basedservices in the ever-evolving Internet of Things networks.</description>
      <author>example@mail.com (Yaya Etiabi, Eslam Eldeeb, Mohammad Shehab, Wafa Njima, Hirley Alves, Mohamed-Slim Alouini, El Mehdi Amhoud)</author>
      <guid isPermaLink="false">2411.17781v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>RPEE-HEADS: A Novel Benchmark for Pedestrian Head Detection in Crowd Videos</title>
      <link>http://arxiv.org/abs/2411.18164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 8 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;自动检测拥挤环境中的行人头部对于人群分析和管理任务至关重要，特别是在火车站台和活动入口等高风险环境中。&lt;h4&gt;背景&lt;/h4&gt;现有的公共数据集中缺乏密集人群中动态移动的场景，这给现有深度学习模型带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了弥补这一不足，论文介绍了一项新的、多样化的、高质量标注的数据集——Railway Platforms and Event Entrances-Heads (RPEE-Heads) 数据集。&lt;h4&gt;方法&lt;/h4&gt;数据集包括来自66段视频记录的1,886张图像中的109,913个行人头部，平均每个图片包含56.2个头部，并且使用了标注框来标记可见头部区域。此外，论文还评估了八种最先进的对象检测算法，并分析了头部尺寸对检测准确性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示You Only Look Once v9和Real-Time Detection Transformer在RPEE-Heads数据集上表现最好，分别达到了90.7%和90.8%的平均精度（mAP），推理时间分别为11毫秒和14毫秒。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了专门的数据集如RPEE-Heads对于训练和评估准确检测火车站台和活动入口中行人头部模型的重要性。&lt;h4&gt;翻译&lt;/h4&gt;自动检测拥挤环境中的行人头部是进行人群分析与管理的关键，特别是在像车站平台和重要事件入口这样高风险的地方。由于现有的公共数据集中较少包含这种场景的数据，这给当前的深度学习技术带来了挑战。为了填补这一空白，该研究引入了新的Railway Platforms and Event Entrances-Heads (RPEE-Heads) 数据集，并使用此数据集评估了8种最先进的目标检测算法的效果。实验表明YOLOv9和Real-Time Detection Transformer在准确性和速度方面都领先于其他模型。这些发现强调需要针对特定场景专门设计的数据集来优化行人头部的自动检测技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The automatic detection of pedestrian heads in crowded environments isessential for crowd analysis and management tasks, particularly in high-risksettings such as railway platforms and event entrances. These environments,characterized by dense crowds and dynamic movements, are underrepresented inpublic datasets, posing challenges for existing deep learning models. Toaddress this gap, we introduce the Railway Platforms and Event Entrances-Heads(RPEE-Heads) dataset, a novel, diverse, high-resolution, and accuratelyannotated resource. It includes 109,913 annotated pedestrian heads across 1,886images from 66 video recordings, with an average of 56.2 heads per image.Annotations include bounding boxes for visible head regions. In addition tointroducing the RPEE-Heads dataset, this paper evaluates eight state-of-the-artobject detection algorithms using the RPEE-Heads dataset and analyzes theimpact of head size on detection accuracy. The experimental results show thatYou Only Look Once v9 and Real-Time Detection Transformer outperform the otheralgorithms, achieving mean average precisions of 90.7% and 90.8%, withinference times of 11 and 14 milliseconds, respectively. Moreover, the findingsunderscore the need for specialized datasets like RPEE-Heads for training andevaluating accurate models for head detection in railway platforms and evententrances. The dataset and pretrained models are available athttps://doi.org/10.34735/ped.2024.2.</description>
      <author>example@mail.com (Mohamad Abubaker, Zubayda Alsadder, Hamed Abdelhaq, Maik Boltes, Ahmed Alia)</author>
      <guid isPermaLink="false">2411.18164v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>OpenAD: Open-World Autonomous Driving Benchmark for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.17761v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍OpenAD，这是首个专注于3D物体检测的开放世界自动驾驶基准。&lt;h4&gt;背景&lt;/h4&gt;开放世界的自动驾驶涵盖了领域泛化和开放词汇两个方面。前者涉及在不同场景和传感器配置下的自动驾驶系统的能力；后者关注于识别训练过程中未遇到的各种语义类别。&lt;h4&gt;目的&lt;/h4&gt;建立一个用于发现并标注边缘情况对象的管道，并评估各种二维和三维开放世界模型的表现，提出视觉为中心的3D开放世界物体检测基线以及融合通用与专用模型的方法。&lt;h4&gt;方法&lt;/h4&gt;构建了一个结合多模态大型语言模型（MLLM）的角落案例发现和注释流水线。此流水线为五个自动驾驶感知数据集中的2000个场景中统一格式地标注了边缘情况对象，并设计了评估方法，用于评估各种二维和三维开放世界及专门化模型。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种视觉为中心的3D开放世界物体检测基线以及通过融合通用与专用模型来提高精度的方法。&lt;h4&gt;结论&lt;/h4&gt;发布注释、工具包代码以及所有评估代码。&lt;h4&gt;翻译&lt;/h4&gt;开放世界的自动驾驶包括领域泛化和开放词汇。域泛化指的是在不同场景和传感器参数配置下自主驾驶系统的适应能力，而开放词汇则涉及识别训练期间未遇到的各种语义类别。本文介绍了OpenAD，这是第一个用于3D物体检测的现实世界开放世界自动驾驶基准。OpenAD基于一个角落情况发现与标注管道建立，该管道集成了多模态大型语言模型（MLLM），为五个自动驾驶感知数据集中共2000个场景中的边缘案例对象进行统一格式化注释。此外，我们设计并评估了各种二维和三维开放世界及专业化模型，并提出了视觉为中心的3D开放世界物体检测基线。为了提高现有OpenAD基准测试中开放世界方法较低精度的问题，还提出了一种通过融合通用和专业模型来解决的方法。所有注释、工具包代码以及所有评估代码将被发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/VDIGPKU/OpenAD&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-world autonomous driving encompasses domain generalization andopen-vocabulary. Domain generalization refers to the capabilities of autonomousdriving systems across different scenarios and sensor parameter configurations.Open vocabulary pertains to the ability to recognize various semanticcategories not encountered during training. In this paper, we introduce OpenAD,the first real-world open-world autonomous driving benchmark for 3D objectdetection. OpenAD is built on a corner case discovery and annotation pipelineintegrating with a multimodal large language model (MLLM). The proposedpipeline annotates corner case objects in a unified format for five autonomousdriving perception datasets with 2000 scenarios. In addition, we deviseevaluation methodologies and evaluate various 2D and 3D open-world andspecialized models. Moreover, we propose a vision-centric 3D open-world objectdetection baseline and further introduce an ensemble method by fusing generaland specialized models to address the issue of lower precision in existingopen-world methods for the OpenAD benchmark. Annotations, toolkit code, and allevaluation codes will be released.</description>
      <author>example@mail.com (Zhongyu Xia, Jishuo Li, Zhiwei Lin, Xinhao Wang, Yongtao Wang, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2411.17761v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Synthetic ECG Generation for Data Augmentation and Transfer Learning in Arrhythmia Classification</title>
      <link>http://arxiv.org/abs/2411.18456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习模型需要大量的数据才能找到其中的隐藏模式。生成式建模旨在学习数据分布，从而允许我们抽取更多数据并增强原始数据集。&lt;h4&gt;目的&lt;/h4&gt;在生理数据（特别是心电图(EGG) 数据）背景下，鉴于其敏感性和昂贵的数据收集成本，利用生成式模型的好处来扩大现有数据集，并改进下游任务，在本例中为心脏节律分类。&lt;h4&gt;方法&lt;/h4&gt;探索使用不同的深度学习生成模型（Diffweave、Time-Diffusion和Time-VQVAE）生成的合成数据以获得两个开源多变量心电图数据集更好的分类结果。此外，还调查了迁移学习的效果，通过微调预训练的合成模型，并逐步增加真实数据的比例。&lt;h4&gt;主要发现&lt;/h4&gt;尽管合成样本类似于真实的样本，在简单地增强实际数据集时，使用合成样本对单个数据集的分类改进几乎察觉不到，但当两个数据集合并后，使用合成样本作为增强数据时所有指标都显示出改善。从微调结果来看，Time-VQVAE生成模型比其他模型更优，但仍不足以接近仅使用真实数据训练的分类器的结果。&lt;h4&gt;结论&lt;/h4&gt;虽然生成式模型可以有效扩增和改进心电图数据集，但合成样本在单独的数据集中对提高分类效果的作用有限。合并多个数据集时，则可观察到显著改善。此外，探索了衡量合成数据与实际数据之间相似性的方法和指标。&lt;h4&gt;翻译&lt;/h4&gt;深度学习模型需要大量的训练数据才能识别隐藏的模式；生成式建模能够通过学习数据分布来扩充现有数据集并增强下游任务表现（如心电图(ECG) 数据分类）。这项研究使用不同的生成模型探索如何利用合成数据改进两个开源多变量ECG数据集的分类性能，并探讨了迁移学习策略的效果。研究表明，虽然Time-VQVAE模型在合成数据上优于其他方法，但仍未能达到仅用真实数据训练效果接近的程度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models need a sufficient amount of data in order to be able tofind the hidden patterns in it. It is the purpose of generative modeling tolearn the data distribution, thus allowing us to sample more data and augmentthe original dataset. In the context of physiological data, and morespecifically electrocardiogram (ECG) data, given its sensitive nature andexpensive data collection, we can exploit the benefits of generative models inorder to enlarge existing datasets and improve downstream tasks, in our case,classification of heart rhythm.  In this work, we explore the usefulness of synthetic data generated withdifferent generative models from Deep Learning namely Diffweave, Time-Diffusionand Time-VQVAE in order to obtain better classification results for two opensource multivariate ECG datasets. Moreover, we also investigate the effects oftransfer learning, by fine-tuning a synthetically pre-trained model and thenprogressively adding increasing proportions of real data. We conclude thatalthough the synthetic samples resemble the real ones, the classificationimprovement when simply augmenting the real dataset is barely noticeable onindividual datasets, but when both datasets are merged the results show anincrease across all metrics for the classifiers when using synthetic samples asaugmented data. From the fine-tuning results the Time-VQVAE generative modelhas shown to be superior to the others but not powerful enough to achieveresults close to a classifier trained with real data only. In addition, methodsand metrics for measuring closeness between synthetic data and the real onehave been explored as a side effect of the main research questions of thisstudy.</description>
      <author>example@mail.com (José Fernando Núñez, Jamie Arjona, Javier Béjar)</author>
      <guid isPermaLink="false">2411.18456v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>PDZSeg: Adapting the Foundation Model for Dissection Zone Segmentation with Visual Prompts in Robot-assisted Endoscopic Submucosal Dissection</title>
      <link>http://arxiv.org/abs/2411.18169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于提示的解剖区分割模型PDZSeg，用于在内镜下黏膜下剥离术（ESD）过程中提供精确的解剖区建议。&lt;h4&gt;背景&lt;/h4&gt;在内窥镜手术环境中，由于组织类型之间的边界不清晰，导致解剖区分割存在挑战和错误。这可能使模型误识别或忽略边缘。&lt;h4&gt;目的&lt;/h4&gt;旨在为内镜下黏膜下剥离术（ESD）过程中的解剖区分割提供精确建议，提高ESD的安全性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于提示的解剖区域分割（PDZSeg）模型。该模型利用了多种视觉提示，例如涂鸦和边界框，并通过在特定数据集上微调基础模型来提升分割性能和用户体验。&lt;h4&gt;主要发现&lt;/h4&gt;使用ESD-DZSeg数据集验证了PDZSeg模型，在域内评估、视觉提示可用性的变化以及鲁棒性测试三个实验设置下，该方法优于现有最先进的分割方法。这是第一个将视觉提示设计融入解剖区域分割的研究。&lt;h4&gt;结论&lt;/h4&gt;PDZSeg模型通过有效利用视觉提示提升了分割性能和用户体验，并使用ESD-DZSeg数据集作为内镜下黏膜下剥离术中解剖区分割的基准。这项工作为未来研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;该论文详细描述了一种新的基于提示的解剖区域分割方法，以提高内镜手术中的安全性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Endoscopic surgical environments present challenges for dissectionzone segmentation due to unclear boundaries between tissue types, leading tosegmentation errors where models misidentify or overlook edges. This study aimsto provide precise dissection zone suggestions during endoscopic submucosaldissection (ESD) procedures, enhancing ESD safety.  Methods: We propose the Prompted-based Dissection Zone Segmentation (PDZSeg)model, designed to leverage diverse visual prompts such as scribbles andbounding boxes. By overlaying these prompts onto images and fine-tuning afoundational model on a specialized dataset, our approach improves segmentationperformance and user experience through flexible input methods.  Results: The PDZSeg model was validated using three experimental setups:in-domain evaluation, variability in visual prompt availability, and robustnessassessment. Using the ESD-DZSeg dataset, results show that our methodoutperforms state-of-the-art segmentation approaches. This is the first studyto integrate visual prompt design into dissection zone segmentation.  Conclusion: The PDZSeg model effectively utilizes visual prompts to enhancesegmentation performance and user experience, supported by the novel ESD-DZSegdataset as a benchmark for dissection zone segmentation in ESD. Our workestablishes a foundation for future research.</description>
      <author>example@mail.com (Mengya Xu, Wenjin Mo, Guankun Wang, Huxin Gao, An Wang, Zhen Li, Xiaoxiao Yang, Hongliang Ren)</author>
      <guid isPermaLink="false">2411.18169v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>XR-MBT: Multi-modal Full Body Tracking for XR through Self-Supervision with Learned Depth Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2411.18377v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种新方法，利用现有的深度传感信号结合自监督学习来实现在XR设备上实时跟踪全身体动。&lt;h4&gt;背景&lt;/h4&gt;当前的全身追踪技术主要采用基于头和控制器三个点的位置合成生成人体姿态的方法。由于缺乏专用腿部传感器以及现有头部周围环境深度信息估计存在视野有限和身体遮挡的问题，无法直接利用该深度信息驱动身体运动。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在XR设备上实时跟踪全身体动的新方法，以提高用户的社交沉浸感。&lt;h4&gt;方法&lt;/h4&gt;通过结合语义点云编码网络和残差网络来扩展现有的三点动作合成模型到点云模式，并采用自监督的方式训练这些模块。利用未注册的真实点云数据与从运动捕捉获得的模拟数据进行联合训练。&lt;h4&gt;主要发现&lt;/h4&gt;该研究首次实现了在XR设备中跟踪腿部动作，而传统基于部分身体追踪的动作合成方法无法做到这一点。&lt;h4&gt;结论&lt;/h4&gt;提出的XR-MBT模型相较于现有的先进系统，在准确性和多样性方面均有显著提升。它能够精确地跟踪广泛范围内的全身体动，并且是首个能够在XR环境中实现腿部分跟踪的方法。&lt;h4&gt;翻译&lt;/h4&gt;跟踪用户在AR/VR设备中的全身运动是一项基础挑战，旨在提高社交沉浸感。由于缺乏专用腿部传感器，目前可用的身体追踪方法采用合成方法生成合理的动作给定头和控制器三个点的位置信号。为了实现混合现实特性，现代XR设备能够利用现有的传感器结合专门的机器学习模型来估算耳机周围环境的深度信息。然而这种自视点深度感知无法直接驱动身体运动，因为它没有注册，并且由于视野有限和身体遮挡而不完整。我们首次提出，可以将可用的深度感应信号与自我监督相结合，以学习一个能够实时在XR设备上跟踪全身体动的多模态姿态估计模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tracking the full body motions of users in XR (AR/VR) devices is afundamental challenge to bring a sense of authentic social presence. Due to theabsence of dedicated leg sensors, currently available body tracking methodsadopt a synthesis approach to generate plausible motions given a 3-point signalfrom the head and controller tracking. In order to enable mixed realityfeatures, modern XR devices are capable of estimating depth information of theheadset surroundings using available sensors combined with dedicated machinelearning models. Such egocentric depth sensing cannot drive the body directly,as it is not registered and is incomplete due to limited field-of-view and bodyself-occlusions. For the first time, we propose to leverage the available depthsensing signal combined with self-supervision to learn a multi-modal poseestimation model capable of tracking full body motions in real time on XRdevices. We demonstrate how current 3-point motion synthesis models can beextended to point cloud modalities using a semantic point cloud encoder networkcombined with a residual network for multi-modal pose estimation. These modulesare trained jointly in a self-supervised way, leveraging a combination of realunregistered point clouds and simulated data obtained from motion capture. Wecompare our approach against several state-of-the-art systems for XR bodytracking and show that our method accurately tracks a diverse range of bodymotions. XR-MBT tracks legs in XR for the first time, whereas traditionalsynthesis approaches based on partial body tracking are blind.</description>
      <author>example@mail.com (Denys Rozumnyi, Nadine Bertsch, Othman Sbai, Filippo Arcadu, Yuhua Chen, Artsiom Sanakoyeu, Manoj Kumar, Catherine Herold, Robin Kips)</author>
      <guid isPermaLink="false">2411.18377v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Perturbation Ontology based Graph Attention Networks</title>
      <link>http://arxiv.org/abs/2411.18520v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要概括&lt;/h4&gt;近年来，图表示学习经历了范式转变，由图神经网络（GNN）及其异构形式的发展和广泛应用驱动。&lt;h4&gt;背景&lt;/h4&gt;目前的异构GNN模型在从包含多种实体类型和关系的复杂图形中提取低维嵌入方面表现出色。元路径技术长期以来因其能够捕捉节点间的语义亲缘关系而受到重视，但其依赖于人工指定限制了其应用范围。矩阵中心方法则通过利用结构线索加速处理过程，却往往忽视了上下文丰富的信息。&lt;h4&gt;目的&lt;/h4&gt;本文提出将本体论作为复杂图形中的基本语义单元，并试图整合矩阵中心和元路径技术的优点，形成统一框架。&lt;h4&gt;方法&lt;/h4&gt;提出了基于扰动的本体图注意力网络（POGAT）的方法，结合本体子图与先进的自监督学习范式以实现深度上下文理解。核心创新在于通过增强同质性扰乱方案生成严格的负样本，鼓励模型更深入地探索最小化上下文特征。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实证评估，证明POGAT在关键任务的链路预测和节点分类上显著优于现有的基准方法，F1-score提高了最多10.78%，Micro-F1提高了最多12.01%。&lt;h4&gt;结论&lt;/h4&gt;提出的方法展示了超越现有最佳模型的能力，为图表示学习提供了一种新的、更有效的框架。&lt;h4&gt;翻译&lt;/h4&gt;近年来，随着图神经网络（GNN）及其异构形式的出现和发展，图表示学习已经经历了一场范式转变。异构GNN在从包含多种实体类型和关系的复杂图形中提取低维嵌入方面表现出了显著的成功。虽然元路径技术长期以来因其能够捕捉节点间语义亲缘关系而备受关注，但其依赖于人工指定限制了其实用性。相比之下，矩阵中心方法通过利用结构线索加速处理过程，却往往忽视上下文丰富的信息。本文提出将本体论作为复杂图形中的基本语义单元，并试图整合矩阵中心和元路径技术的优点，形成统一框架。我们提出了基于扰动的图注意力网络（POGAT）的方法，结合本体子图与先进的自监督学习范式以实现深度上下文理解。核心创新在于通过增强同质性扰乱方案生成严格的负样本，鼓励模型更深入地探索最小化上下文特征。通过广泛的实证评估，我们证明了POGAT在关键任务的链路预测和节点分类上显著优于现有的基准方法，在F1-score提高了最多10.78%，Micro-F1提高了最多12.01%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, graph representation learning has undergone a paradigmshift, driven by the emergence and proliferation of graph neural networks(GNNs) and their heterogeneous counterparts. Heterogeneous GNNs have shownremarkable success in extracting low-dimensional embeddings from complex graphsthat encompass diverse entity types and relationships. While meta-path-basedtechniques have long been recognized for their ability to capture semanticaffinities among nodes, their dependence on manual specification poses asignificant limitation. In contrast, matrix-focused methods accelerateprocessing by utilizing structural cues but often overlook contextual richness.In this paper, we challenge the current paradigm by introducing ontology as afundamental semantic primitive within complex graphs. Our goal is to integratethe strengths of both matrix-centric and meta-path-based approaches into aunified framework. We propose perturbation Ontology-based Graph AttentionNetworks (POGAT), a novel methodology that combines ontology subgraphs with anadvanced self-supervised learning paradigm to achieve a deep contextualunderstanding. The core innovation of POGAT lies in our enhanced homogeneousperturbing scheme designed to generate rigorous negative samples, encouragingthe model to explore minimal contextual features more thoroughly. Throughextensive empirical evaluations, we demonstrate that POGAT significantlyoutperforms state-of-the-art baselines, achieving a groundbreaking improvementof up to 10.78\% in F1-score for the critical task of link prediction and12.01\% in Micro-F1 for the critical task of node classification.</description>
      <author>example@mail.com (Yichen Wang, Jie Wang, Fulin Wang, Xiang Li, Hao Yin, Bhiksha Raj)</author>
      <guid isPermaLink="false">2411.18520v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>What do physics-informed DeepONets learn? Understanding and improving training for scientific computing applications</title>
      <link>http://arxiv.org/abs/2411.18459v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;基于物理信息的深度操作网络（DeepONets）在数值逼近偏微分方程（PDEs）解方面展现出巨大的潜力。本文旨在通过评估提取基函数的通用性和展示其在模型简化方面的潜在应用，深入理解物理信息指导下的DeepONets所学习的内容。&lt;h4&gt;背景&lt;/h4&gt;物理学启发的深度操作网络已经在数值近似求解偏微分方程中展现出了很大的前景。&lt;h4&gt;目的&lt;/h4&gt;深入了解基于物理信息的DeepONets的学习机制，并探讨其在模型简化中的潜在应用。&lt;h4&gt;方法&lt;/h4&gt;通过评估提取基函数的通用性，展示它们在使用谱方法进行模型减少方面的潜力。此外，提出了一种改进不同PDE参数下以及相关但不同类型PDE之间训练效果的迁移学习策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，可以通过奇异值和扩展系数的衰减来衡量基于物理信息的DeepONets的表现。提出的转移学习方法可显著减少误差，并且生成的有效基函数更有利于表示偏微分方程的解。&lt;h4&gt;结论&lt;/h4&gt;通过本研究提供的见解，可以更好地理解物理启发下的深度操作网络的学习机制以及如何利用这些模型进行有效的模型简化和训练优化。&lt;h4&gt;翻译&lt;/h4&gt;基于物理学信息的DeepONets作为数值求解偏微分方程的一种有前景的方法已经崭露头角。本文旨在通过评估提取基函数的通用性，展示它们在使用谱方法进行模型减少方面的潜力，以更好地理解这些网络所学习的内容。研究结果表明可以通过奇异值和扩展系数的衰减来衡量基于物理信息的DeepONets的表现，并且提出了一种迁移学习策略用于改善相关偏微分方程参数以及不同但相关的偏微分方程之间的训练效果。这种策略能够显著减少误差，生成更有效的基函数来表示偏微分方程的解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-informed deep operator networks (DeepONets) have emerged as apromising approach toward numerically approximating the solution of partialdifferential equations (PDEs). In this work, we aim to develop furtherunderstanding of what is being learned by physics-informed DeepONets byassessing the universality of the extracted basis functions and demonstratingtheir potential toward model reduction with spectral methods. Results provideclarity about measuring the performance of a physics-informed DeepONet throughthe decays of singular values and expansion coefficients. In addition, wepropose a transfer learning approach for improving training forphysics-informed DeepONets between parameters of the same PDE as well as acrossdifferent, but related, PDEs where these models struggle to train well. Thisapproach results in significant error reduction and learned basis functionsthat are more effective in representing the solution of a PDE.</description>
      <author>example@mail.com (Emily Williams, Amanda Howard, Brek Meuris, Panos Stinis)</author>
      <guid isPermaLink="false">2411.18459v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>On the ERM Principle in Meta-Learning</title>
      <link>http://arxiv.org/abs/2411.17898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了元学习中的分布无关的学习表面特性，特别是当任务数量n或样本数量m趋向无穷大时的情况。&lt;h4&gt;背景&lt;/h4&gt;传统的监督学习算法通过在标记数据上训练来生成假设。元学习则是在多个相关但不同的任务上进行训练，每个任务包含一定数量的示例，以期望在未见的任务中表现出色。评估性能通常使用学习曲线（单变量函数）或学习表面（二维空间）。&lt;h4&gt;目的&lt;/h4&gt;目的是表征分布无关的元经验风险最小化器的学习表面特征，并找出在元学习过程中成功所需的样本量和任务数量之间的关系。&lt;h4&gt;方法&lt;/h4&gt;研究开发了必要且充分条件来判断使用有限示例数进行元学习的可能性，进而分析当n或m趋于无穷大时的学习表现。&lt;h4&gt;主要发现&lt;/h4&gt;{'一': '任务的数量必须与预期的误差成反比。然而，样本数量的行为则截然不同：存在一个分界点，使得要么需要样本量与期望误差成反比增长以达到满意的性能，要么只需有限数量的任务示例就能使误差在任务数n趋向无穷大时消失。', '二': '对于任意正的误差ε值，研究确定了为了在任务数量无限增大的情况下实现特定误差水平所需的每个任务的样本量。'}&lt;h4&gt;结论&lt;/h4&gt;这些发现为理解元学习中成功所需的小规模示例的重要性提供了理论基础，并且有助于制定实际应用中的训练策略。&lt;h4&gt;翻译&lt;/h4&gt;经典监督学习涉及算法通过在n个标记实例上进行训练来生成假设h∈H，以期对未见过的样本表现良好。元学习则扩展了这一点，在跨n个任务的情况下进行训练，每个任务包含m个示例，产生一个位于某些元类中的假设类H。这种设置适用于许多现代问题如上下文学习、超网络和学习如何学习等。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classic supervised learning involves algorithms trained on $n$ labeledexamples to produce a hypothesis $h \in \mathcal{H}$ aimed at performing wellon unseen examples. Meta-learning extends this by training across $n$ tasks,with $m$ examples per task, producing a hypothesis class $\mathcal{H}$ withinsome meta-class $\mathbb{H}$. This setting applies to many modern problems suchas in-context learning, hypernetworks, and learning-to-learn. A common methodfor evaluating the performance of supervised learning algorithms is throughtheir learning curve, which depicts the expected error as a function of thenumber of training examples. In meta-learning, the learning curve becomes atwo-dimensional learning surface, which evaluates the expected error on unseendomains for varying values of $n$ (number of tasks) and $m$ (number of trainingexamples).  Our findings characterize the distribution-free learning surfaces ofmeta-Empirical Risk Minimizers when either $m$ or $n$ tend to infinity: we showthat the number of tasks must increase inversely with the desired error. Incontrast, we show that the number of examples exhibits very different behavior:it satisfies a dichotomy where every meta-class conforms to one of thefollowing conditions: (i) either $m$ must grow inversely with the error, or(ii) a \emph{finite} number of examples per task suffices for the error tovanish as $n$ goes to infinity. This finding illustrates and characterizescases in which a small number of examples per task is sufficient for successfullearning. We further refine this for positive values of $\varepsilon$ andidentify for each $\varepsilon$ how many examples per task are needed toachieve an error of $\varepsilon$ in the limit as the number of tasks $n$ goesto infinity. We achieve this by developing a necessary and sufficient conditionfor meta-learnability using a bounded number of examples per domain.</description>
      <author>example@mail.com (Yannay Alon, Steve Hanneke, Shay Moran, Uri Shalit)</author>
      <guid isPermaLink="false">2411.17898v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Utilizing the Mean Teacher with Supcontrast Loss for Wafer Pattern Recognition</title>
      <link>http://arxiv.org/abs/2411.18533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages,1 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;本文提出了一种结合均值教师框架和监督对比学习损失的创新方法，用于增强晶圆图样识别。&lt;h4&gt;背景信息&lt;/h4&gt;在半导体制造过程中，晶圆图上的图案对于帮助工程师识别生产问题至关重要。为了降低成本并提高准确性，自动化技术是必要的，并且深度学习领域的最新进展已经在晶圆图模式识别方面取得了令人印象深刻的结果。&lt;h4&gt;研究目的&lt;/h4&gt;引入一种结合半监督学习和对比学习方法的创新方法，以解决晶圆图案的复杂性和由有限标注数据带来的挑战。&lt;h4&gt;所用方法&lt;/h4&gt;提出的方法将Mean Teacher框架与监督对比损失相结合，并通过使用SMOTE及欠抽样技术来处理晶圆数据集中的不平衡问题。&lt;h4&gt;实验结果&lt;/h4&gt;通过对真实世界数据集WM811K进行的全面分析，显示提出的模型相比于基准方法在准确性、精确性、召回率和F1分数上分别提高了5.46%、6.68%、5.42%和4.53%&lt;h4&gt;结论&lt;/h4&gt;该研究展示了一种有效的方法来增强晶圆图模式识别，并证明了其相对于现有技术的优越性能。&lt;h4&gt;翻译&lt;/h4&gt;在半导体制造过程中，晶圆图上的图案对于帮助工程师识别生产问题至关重要。为了降低成本并提高准确性，自动化技术是必要的，并且深度学习领域的最新进展已经在晶圆图模式识别方面取得了令人印象深刻的结果。本文提出了一种结合均值教师框架和监督对比损失的创新方法来解决晶圆图案复杂性和有限标注数据带来的挑战，通过使用真实世界数据集WM811K进行的实验显示了该模型在各项指标上的显著改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The patterns on wafer maps play a crucial role in helping engineers identifythe causes of production issues during semiconductor manufacturing. In order toreduce costs and improve accuracy, automation technology is essential, andrecent developments in deep learning have led to impressive results in wafermap pattern recognition. In this context, inspired by the effectiveness ofsemi-supervised learning and contrastive learning methods, we introduce aninnovative approach that integrates the Mean Teacher framework with thesupervised contrastive learning loss for enhanced wafer map patternrecognition. Our methodology not only addresses the nuances of wafer patternsbut also tackles challenges arising from limited labeled data. To furtherrefine the process, we address data imbalance in the wafer dataset by employingSMOTE and under-sampling techniques. We conduct a comprehensive analysis of ourproposed method and demonstrate its effectiveness through experiments usingreal-world dataset WM811K obtained from semiconductor manufacturers. Comparedto the baseline method, our method has achieved 5.46%, 6.68%, 5.42%, and 4.53%improvements in Accuracy, Precision, Recall, and F1 score, respectively.</description>
      <author>example@mail.com (Qiyu Wei, Xun Xu, Zeng Zeng, Xulei Yang)</author>
      <guid isPermaLink="false">2411.18533v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Weakly Supervised Framework Considering Multi-temporal Information for Large-scale Cropland Mapping with Satellite Imagery</title>
      <link>http://arxiv.org/abs/2411.18475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;准确地大规模农田地图绘制对于农业生产和规划至关重要。目前，结合遥感数据和深度学习技术在农田制图中表现出色，但这种方法需要大量的精确标签，而这些标签的生成耗时且劳动密集型。&lt;h4&gt;背景&lt;/h4&gt;利用遥感数据和深度学习方法可以实现高精度的大规模农作物地籍地图绘制，但是该过程中的关键挑战在于标签成本高昂。&lt;h4&gt;目的&lt;/h4&gt;为了减少标签的成本负担，本研究提出了一种结合多时间信息的弱监督框架用于大规模农田制图。&lt;h4&gt;方法&lt;/h4&gt;{'提取高质量标签': '根据全球土地覆盖产品之间的协同一致性来提取高质量标注以构建有监督学习信号', '缓解过拟合问题': '通过编码视觉/空间域中的农作物相似性/聚合度构建无监督学习信号，将其作为正则化项限制监督部分的学习过程。', '充分利用未标记样本信息': '在没有高质量标签的样本中也加入无监督学习信号，丰富特征空间的多样性。', '利用时间序列数据': '引入密集卫星影像时间序列（SITS）来捕捉农作物的物候特性，并将框架扩展到时间维度。'}&lt;h4&gt;主要发现&lt;/h4&gt;{'多时态信息的重要性': '通过可视化高维作物周期特征揭示了多时态信息在提取农田方面的益处。', '模型稳健性评估': '在数据稀缺条件下进行了方法鲁棒性的评估，展示该框架在三个研究区域（中国湖南省、法国东南部和美国堪萨斯州）具有强大的适应能力。'}&lt;h4&gt;结论&lt;/h4&gt;所提出的弱监督学习框架展现出了跨不同地区大规模农田制图的较强适应性和时间泛化性，并深入探讨了其内部机制。&lt;h4&gt;翻译&lt;/h4&gt;准确地绘制大范围农业用地地图对于农业生产和规划至关重要。目前，结合遥感数据和深度学习技术在作物制图中表现卓越，然而这种方法需要大量的精确标签，而这些标签的生成耗费大量时间和人力。为了降低标记成本，本研究提出了一种利用多时间信息进行大规模农田测绘的弱监督框架。具体来说，我们根据全球土地覆盖产品之间的协同一致性来提取高质量标签以供有监督学习使用；同时为了避免模型过于依赖剩余误差而导致过拟合的问题，我们在视觉/空间域中构建无监督学习信号作为正则化项限制了监督部分的学习过程；另外为了更充分地利用没有高质量标签的数据样本中的信息量，我们也引入了这些数据点的无监督学习信号以丰富特征空间。之后，我们通过引入密集卫星图像时间序列（SITS）来捕捉农作物物候特性的方式扩展该框架的时间维度，并且可视化高维作物周期特征揭示了多时态信息在提取农田方面的益处。此外还评估了方法在数据稀缺条件下的鲁棒性表现，证明所提出的框架具备跨湖南省、法国东南部和堪萨斯州三个研究区域的大规模农业用地测绘的强适应性和时间泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately mapping large-scale cropland is crucial for agriculturalproduction management and planning. Currently, the combination of remotesensing data and deep learning techniques has shown outstanding performance incropland mapping. However, those approaches require massive precise labels,which are labor-intensive. To reduce the label cost, this study presented aweakly supervised framework considering multi-temporal information forlarge-scale cropland mapping. Specifically, we extract high-quality labelsaccording to their consistency among global land cover (GLC) products toconstruct the supervised learning signal. On the one hand, to alleviate theoverfitting problem caused by the model's over-trust of remaining errors inhigh-quality labels, we encode the similarity/aggregation of cropland in thevisual/spatial domain to construct the unsupervised learning signal, and takeit as the regularization term to constrain the supervised part. On the otherhand, to sufficiently leverage the plentiful information in the samples withouthigh-quality labels, we also incorporate the unsupervised learning signal inthese samples, enriching the diversity of the feature space. After that, tocapture the phenological features of croplands, we introduce dense satelliteimage time series (SITS) to extend the proposed framework in the temporaldimension. We also visualized the high dimensional phenological features touncover how multi-temporal information benefits cropland extraction, andassessed the method's robustness under conditions of data scarcity. Theproposed framework has been experimentally validated for strong adaptabilityacross three study areas (Hunan Province, Southeast France, and Kansas) inlarge-scale cropland mapping, and the internal mechanism and temporalgeneralizability are also investigated.</description>
      <author>example@mail.com (Yuze Wang, Aoran Hu, Ji Qi, Yang Liu, Chao Tao)</author>
      <guid isPermaLink="false">2411.18475v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Novel Class Discovery for Open Set Raga Classification</title>
      <link>http://arxiv.org/abs/2411.18611v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review at ICASSP-25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;印度艺术音乐（IAM）中的Raga分类任务受到标注数据集有限的制约，导致许多Ragas在机器学习模型训练中未被充分表示。传统的Raga分类方法依赖于监督学习，并假设用于测试音频分类的数据必须在训练集中有所体现，这限制了它们在真实场景下的效果，因为在这些场景中可能会出现从未见过的新Raga。&lt;h4&gt;背景&lt;/h4&gt;印度艺术音乐中的Raga分类面临着标注数据集不足的问题，传统的方法在这种情况下表现不佳，因为无法处理未见过的新的Raga。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于新类发现（NCD）的方法来检测和分类以前未见过的Ragas。&lt;h4&gt;方法&lt;/h4&gt;使用监督训练的特征提取器生成嵌入，并将其用于对比学习框架中的自监督训练，以识别先前未见的Raga类别。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法能够准确地检测出对应于这些新Raga的音频样本，提供了一种利用在线大量未标记音乐数据的强大解决方案。该方法减少了人工标注的需求并扩大了已知Raga和其他音乐信息检索（MIR）中音乐种类的数量。&lt;h4&gt;结论&lt;/h4&gt;这种方法为解决Raga分类中的挑战提供了一个有效的途径，并且在处理新出现的Ragas时显示出优于传统监督学习技术的优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要文本&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The task of Raga classification in Indian Art Music (IAM) is constrained bythe limited availability of labeled datasets, resulting in many Ragas beingunrepresented during the training of machine learning models. Traditional Ragaclassification methods rely on supervised learning, and assume that for a testaudio to be classified by a Raga classification model, it must have beenrepresented in the training data, which limits their effectiveness inreal-world scenarios where novel, unseen Ragas may appear. To address thislimitation, we propose a method based on Novel Class Discovery (NCD) to detectand classify previously unseen Ragas. Our approach utilizes a feature extractortrained in a supervised manner to generate embeddings, which are then employedwithin a contrastive learning framework for self-supervised training, enablingthe identification of previously unseen Raga classes. The results demonstratethat the proposed method can accurately detect audio samples corresponding tothese novel Ragas, offering a robust solution for utilizing the vast amount ofunlabeled music data available online. This approach reduces the need formanual labeling while expanding the repertoire of recognized Ragas, and othermusic data in Music Information Retrieval (MIR).</description>
      <author>example@mail.com (Parampreet Singh, Adwik Gupta, Vipul Arora)</author>
      <guid isPermaLink="false">2411.18611v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation</title>
      <link>http://arxiv.org/abs/2411.18369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Webpage: https://tianxingchen.github.io/G3Flow/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;G3Flow框架通过结合3D生成模型、视觉基础模型和鲁棒姿态跟踪，实现实时的语义流构建，提高了机器人操作中的几何精度与语义理解能力。&lt;h4&gt;背景&lt;/h4&gt;模仿学习在三维机械臂操作领域的扩散策略取得了显著成果，但实现人类级别的灵巧性需要无缝整合几何精确度和语义理解。&lt;h4&gt;目的&lt;/h4&gt;提出G3Flow框架以增强实时动态的语义特征理解，并应用于机器人操纵政策中提升终端受限操控及跨物体泛化能力。&lt;h4&gt;方法&lt;/h4&gt;[{'结合技术': '利用基础模型构建实时语义流，形成动态、对象中心的三维语义表示'}, {'核心组件': '包括3D生成模型（用于数字孪生创建）、视觉基础模型（提取语义特征）和鲁棒姿态跟踪（持续更新语义流）'}]&lt;h4&gt;主要发现&lt;/h4&gt;[{'显著改进': '将实时语义流集成到扩散策略中，改善了终端受限操作和跨对象泛化的性能'}, {'实验结果': '在五项模拟任务上的表现优于现有方法，成功率达到68.3%（终端约束）和50.1%（跨对象泛化）'}]&lt;h4&gt;结论&lt;/h4&gt;G3Flow证明了实时动态语义特征理解对于机器人操作政策的有效性。&lt;h4&gt;翻译&lt;/h4&gt;最近在模仿学习中用于三维机械臂操纵的基于扩散策略的进步显示出有希望的结果。然而，达到人类级别的灵巧性需要无缝集成几何精确度和语义理解。我们提出了一个新颖框架G3Flow，通过利用基础模型构建实时语义流，这是一种动态的对象中心的三维语义表示。我们的方法独特地结合了3D生成模型（用于数字孪生创建）、视觉基础模型（提取语义特征）以及鲁棒的姿态跟踪来持续更新语义流。这种集成能够在遮挡的情况下实现完整的语义理解，并且不需要手动注释需求。通过将实时语义流融入扩散策略，我们在终端受限操作和跨对象泛化中都展示了显著的改进。在五项模拟任务上的广泛实验表明，G3Flow始终优于现有方法，在终端约束操控与跨物体泛化任务上分别达到了68.3%和50.1%的成功率。我们的结果证明了实时动态语义特征理解对于增强机器人操作策略的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in imitation learning for 3D robotic manipulation have shownpromising results with diffusion-based policies. However, achieving human-leveldexterity requires seamless integration of geometric precision and semanticunderstanding. We present G3Flow, a novel framework that constructs real-timesemantic flow, a dynamic, object-centric 3D semantic representation byleveraging foundation models. Our approach uniquely combines 3D generativemodels for digital twin creation, vision foundation models for semantic featureextraction, and robust pose tracking for continuous semantic flow updates. Thisintegration enables complete semantic understanding even under occlusions whileeliminating manual annotation requirements. By incorporating semantic flow intodiffusion policies, we demonstrate significant improvements in bothterminal-constrained manipulation and cross-object generalization. Extensiveexperiments across five simulation tasks show that G3Flow consistentlyoutperforms existing approaches, achieving up to 68.3% and 50.1% averagesuccess rates on terminal-constrained manipulation and cross-objectgeneralization tasks respectively. Our results demonstrate the effectiveness ofG3Flow in enhancing real-time dynamic semantic feature understanding forrobotic manipulation policies.</description>
      <author>example@mail.com (Tianxing Chen, Yao Mu, Zhixuan Liang, Zanxin Chen, Shijia Peng, Qiangyu Chen, Mingkun Xu, Ruizhen Hu, Hongyuan Zhang, Xuelong Li, Ping Luo)</author>
      <guid isPermaLink="false">2411.18369v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Lift3D Foundation Policy: Lifting 2D Large-Scale Pretrained Models for Robust 3D Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2411.18623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;3D几何信息对于操作任务至关重要，机器人需要感知三维环境、推理空间关系，并与复杂的空间配置进行交互。最近的研究越来越多地集中在显式提取3D特征上，但仍面临缺乏大规模的机器人3D数据和可能的空间几何损失等挑战。&lt;h4&gt;背景&lt;/h4&gt;在机器人操作任务中，理解和利用3D环境至关重要。然而，当前的处理方法面临着没有大量3D机器人数据的问题，并且可能会丢失空间几何信息。&lt;h4&gt;目的&lt;/h4&gt;提出Lift3D框架来解决上述限制问题，通过将2D基础模型与隐式和显式的3D机器人表示相结合，构建一个稳健的操作策略。&lt;h4&gt;方法&lt;/h4&gt;设计了一个任务感知的掩码自动编码器，该编码器遮蔽了与任务相关的可用性补丁，并重建深度信息。进行自监督微调后，引入了一种2D模型提升策略，在输入的3D点和2D模型的位置嵌入之间建立位置映射。&lt;h4&gt;主要发现&lt;/h4&gt;Lift3D框架在多个模拟基准测试和现实世界场景中超越了现有最先进的方法，表明其能有效构建显式的3D机器人表示，并减少空间信息损失。&lt;h4&gt;结论&lt;/h4&gt;提出的Lift3D框架通过逐步增强2D基础模型的隐式和显式3D机器人表示，为操作任务提供了一个稳健的方法。实验结果证明该框架的有效性和优越性。&lt;h4&gt;翻译&lt;/h4&gt;三维几何信息对于执行抓取、摆放等需要理解物体空间位置的任务至关重要。现有的方法大多基于2D图像信息，但当面对复杂场景时会因为缺乏足够的3D数据和难以保留原始几何结构而面临挑战。为了解决这些问题，作者提出了Lift3D框架，它通过结合2D基础模型和隐式、显式的3D表示来提升机器人操作性能，并在实验中验证了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D geometric information is essential for manipulation tasks, as robots needto perceive the 3D environment, reason about spatial relationships, andinteract with intricate spatial configurations. Recent research hasincreasingly focused on the explicit extraction of 3D features, while stillfacing challenges such as the lack of large-scale robotic 3D data and thepotential loss of spatial geometry. To address these limitations, we proposethe Lift3D framework, which progressively enhances 2D foundation models withimplicit and explicit 3D robotic representations to construct a robust 3Dmanipulation policy. Specifically, we first design a task-aware maskedautoencoder that masks task-relevant affordance patches and reconstructs depthinformation, enhancing the 2D foundation model's implicit 3D roboticrepresentation. After self-supervised fine-tuning, we introduce a 2Dmodel-lifting strategy that establishes a positional mapping between the input3D points and the positional embeddings of the 2D model. Based on the mapping,Lift3D utilizes the 2D foundation model to directly encode point cloud data,leveraging large-scale pretrained knowledge to construct explicit 3D roboticrepresentations while minimizing spatial information loss. In experiments,Lift3D consistently outperforms previous state-of-the-art methods acrossseveral simulation benchmarks and real-world scenarios.</description>
      <author>example@mail.com (Yueru Jia, Jiaming Liu, Sixiang Chen, Chenyang Gu, Zhilue Wang, Longzan Luo, Lily Lee, Pengwei Wang, Zhongyuan Wang, Renrui Zhang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2411.18623v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>ST-Align: A Multimodal Foundation Model for Image-Gene Alignment in Spatial Transcriptomics</title>
      <link>http://arxiv.org/abs/2411.16793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要&lt;/h4&gt;本文介绍了ST-Align，一种专为空间转录组学（Spatial Transcriptomics, ST）设计的多模态基础模型。该模型通过结合空间信息来深入对齐图像-基因配对，并有效连接病理成像与基因特征。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学提供了高分辨率的病理性图像和单点级全转录组表达谱，成为开发多模态基础模型的理想数据源。然而，由于缺乏宽视野视角以及空间内在关系的理解，现有的基于点级别的可训练基因编码器优化方法在捕捉ST特有的见解方面存在限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为ST-Align的新型预训练框架，旨在为ST设计首个能够深度对齐图像和基因配对并融合病理学成像与基因组特征的基础模型。&lt;h4&gt;方法&lt;/h4&gt;引入了一种具有三目标对齐策略的新颖预训练框架，其中包括多尺度图像-基因配对对齐以及跨层级的多模态见解对齐。此外，ST-Align采用了专门针对不同空间转录组学上下文设计的编码器，并通过基于注意力机制的融合网络（ABFN）增强了多模态融合能力。&lt;h4&gt;主要发现&lt;/h4&gt;在预训练阶段使用了130万点巢对，通过六个数据集中的两项下游任务评估其性能，展示了优越的零样本和少量样本处理能力。此外，该模型突显了降低空间转录组学成本以及提供关键组织成分区分有价值见解的潜力。&lt;h4&gt;结论&lt;/h4&gt;ST-Align为基于空间转录组的数据提供了强大的分析工具，并且具有提高效率并减少实验成本的优势，同时还能提供对人类组织中重要结构差异的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics (ST) provides high-resolution pathological images andwhole-transcriptomic expression profiles at individual spots across whole-slidescales. This setting makes it an ideal data source to develop multimodalfoundation models. Although recent studies attempted to fine-tune visualencoders with trainable gene encoders based on spot-level, the absence of awider slide perspective and spatial intrinsic relationships limits theirability to capture ST-specific insights effectively. Here, we introduceST-Align, the first foundation model designed for ST that deeply alignsimage-gene pairs by incorporating spatial context, effectively bridgingpathological imaging with genomic features. We design a novel pretrainingframework with a three-target alignment strategy for ST-Align, enabling (1)multi-scale alignment across image-gene pairs, capturing both spot- andniche-level contexts for a comprehensive perspective, and (2) cross-levelalignment of multimodal insights, connecting localized cellular characteristicsand broader tissue architecture. Additionally, ST-Align employs specializedencoders tailored to distinct ST contexts, followed by an Attention-BasedFusion Network (ABFN) for enhanced multimodal fusion, effectively mergingdomain-shared knowledge with ST-specific insights from both pathological andgenomic data. We pre-trained ST-Align on 1.3 million spot-niche pairs andevaluated its performance through two downstream tasks across six datasets,demonstrating superior zero-shot and few-shot capabilities. ST-Align highlightsthe potential for reducing the cost of ST and providing valuable insights intothe distinction of critical compositions within human tissue.</description>
      <author>example@mail.com (Yuxiang Lin, Ling Luo, Ying Chen, Xushi Zhang, Zihui Wang, Wenxian Yang, Mengsha Tong, Rongshan Yu)</author>
      <guid isPermaLink="false">2411.16793v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Alignment and Fusion: A Survey</title>
      <link>http://arxiv.org/abs/2411.17040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  210+ references&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文综述了近年来在机器学习领域中关于多模态对齐和融合的最新进展，强调了跨文本、图像、音频和视频等不同数据类型的数据整合的重要性。&lt;h4&gt;背景&lt;/h4&gt;随着不同类型数据的增长，多模态集成通过利用不同模式之间的互补信息并促进知识迁移（尤其是在数据有限的情况下）来提高模型准确性及其应用范围。&lt;h4&gt;目的&lt;/h4&gt;系统地分类和分析现有对齐与融合技术，并从超过200篇相关论文的广泛回顾中汲取见解。同时探讨多模态数据整合面临的挑战，包括对齐问题、噪声抵抗性以及特征表示差异等。&lt;h4&gt;方法&lt;/h4&gt;该研究通过梳理和总结了大量关于多模态学习的相关文献，系统地归纳并分析现有的对齐与融合技术。&lt;h4&gt;主要发现&lt;/h4&gt;在社交媒体分析、医学成像、情感识别等领域中应用多模态数据整合的技术面临着各种挑战。提出了未来的研究方向，旨在优化多模态学习系统的可扩展性、鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该综述为未来的多模态机器学习研究提供了指导原则，并强调了在不同应用场景中增强系统性能的重要性。&lt;h4&gt;翻译&lt;/h4&gt;本文提供了一篇关于机器学习领域内最近的多模态对齐和融合进展的全面回顾，这些进展是由文本、图像、音频和视频等数据类型的多样性驱动的。多模态集成通过利用跨模式间的互补信息并促进知识迁移（尤其是在数据有限的情况下）来提高模型准确性及其应用范围。我们系统地分类和分析现有对齐与融合技术，并从超过200篇相关论文的广泛回顾中汲取见解。此外，本综述还针对社交网络分析、医学成像和情感识别等领域的多模态数据整合所面临的挑战进行了讨论，包括对齐问题、噪声抵抗性以及特征表示差异等。所提供的洞见旨在指导未来研究朝着优化多模态学习系统的可扩展性、鲁棒性和泛化能力的方向发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This survey offers a comprehensive review of recent advancements inmultimodal alignment and fusion within machine learning, spurred by the growingdiversity of data types such as text, images, audio, and video. Multimodalintegration enables improved model accuracy and broader applicability byleveraging complementary information across different modalities, as well asfacilitating knowledge transfer in situations with limited data. Wesystematically categorize and analyze existing alignment and fusion techniques,drawing insights from an extensive review of more than 200 relevant papers.Furthermore, this survey addresses the challenges of multimodal dataintegration - including alignment issues, noise resilience, and disparities infeature representation - while focusing on applications in domains like socialmedia analysis, medical imaging, and emotion recognition. The insights providedare intended to guide future research towards optimizing multimodal learningsystems to enhance their scalability, robustness, and generalizability acrossvarious applications.</description>
      <author>example@mail.com (Songtao Li, Hao Tang)</author>
      <guid isPermaLink="false">2411.17040v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Relations, Negations, and Numbers: Looking for Logic in Generative Text-to-Image Models</title>
      <link>http://arxiv.org/abs/2411.17066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;摘要总结&lt;/h4&gt;{'背景': '尽管多模态AI研究取得了显著进展，但在可靠部署逻辑操作符方面，现代AI仍远远落后于人类儿童。', '目的': '探讨关系、否定和离散数字三种形式的逻辑操作符在图像生成中的表现，并评估改进后的‘基于事实扩散’管道的表现。', '方法': '通过让178名人类受访者对由DALL-E 3生成并以这些‘逻辑探测器’为提示词的图片进行评价，来测试AI系统的性能。还进行了辅助分析，包括N-gram频率与关系提示匹配度的关系、否定提示渲染的成功率以及涉及整数提示的变量性依赖。', '主要发现': '在所有逻辑操作符中，否定和大于3的数字的表现最差；改进后的‘基于事实扩散’管道性能比DALL-E 3更糟糕。', '结论': '讨论了以向量语义或语法约束为基础的多模态学习系统的局限性，并提出了一些可能有助于缩小规模与结构之间差距的修改建议。所有数据和代码可在GitHub上获取。'}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/colinconwell/t2i-probology&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite remarkable progress in multi-modal AI research, there is a salientdomain in which modern AI continues to lag considerably behind even humanchildren: the reliable deployment of logical operators. Here, we examine threeforms of logical operators: relations, negations, and discrete numbers. Weasked human respondents (N=178 in total) to evaluate images generated by astate-of-the-art image-generating AI (DALL-E 3) prompted with these `logicalprobes', and find that none reliably produce human agreement scores greaterthan 50\%. The negation probes and numbers (beyond 3) fail most frequently. Ina 4th experiment, we assess a `grounded diffusion' pipeline that leveragestargeted prompt engineering and structured intermediate representations forgreater compositional control, but find its performance is judged even worsethan that of DALL-E 3 across prompts. To provide further clarity on potentialsources of success and failure in these text-to-image systems, we supplementour 4 core experiments with multiple auxiliary analyses and schematic diagrams,directly quantifying, for example, the relationship between the N-gramfrequency of relational prompts and the average match to generated images; thesuccess rates for 3 different prompt modification strategies in the renderingof negation prompts; and the scalar variability / ratio dependence(`approximate numeracy') of prompts involving integers. We conclude bydiscussing the limitations inherent to `grounded' multimodal learning systemswhose grounding relies heavily on vector-based semantics (e.g. DALL-E 3), orunder-specified syntactical constraints (e.g. `grounded diffusion'), andpropose minimal modifications (inspired by development, based in imagery) thatcould help to bridge the lingering compositional gap between scale andstructure. All data and code is available athttps://github.com/ColinConwell/T2I-Probology</description>
      <author>example@mail.com (Colin Conwell, Rupert Tawiah-Quashie, Tomer Ullman)</author>
      <guid isPermaLink="false">2411.17066v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Learning Robust Anymodal Segmentor with Unimodal and Cross-modal Distillation</title>
      <link>http://arxiv.org/abs/2411.17141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的框架用于学习鲁棒的分割器，使其能够处理任何视觉模态组合。&lt;h4&gt;背景&lt;/h4&gt;同时利用多传感器采集的多模态输入训练分割模型看似有优势但在实际操作中存在挑战。主要问题是单模态偏差，即多模态分割器过于依赖特定模态，这在现实应用中会导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;开发一种学习鲁棒分割器的方法，该方法可以处理任何组合的视觉模态输入。&lt;h4&gt;方法&lt;/h4&gt;引入了一种平行多模态学习策略来训练强大的教师网络，并通过跨模态和单模态蒸馏将特征级知识从多模态传递到任何模态的分割器。此外还提出了预测级别的模态无关语义蒸馏，以实现分割任务中的语义知识传输。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明了该方法在合成数据集和真实世界基准上的性能优越性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够在多传感器应用中表现出色，并且能够有效解决单模态偏差问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhengxuJosh/AnySeg&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneously using multimodal inputs from multiple sensors to trainsegmentors is intuitively advantageous but practically challenging. A keychallenge is unimodal bias, where multimodal segmentors over rely on certainmodalities, causing performance drops when others are missing, common in realworld applications. To this end, we develop the first framework for learningrobust segmentor that can handle any combinations of visual modalities.Specifically, we first introduce a parallel multimodal learning strategy forlearning a strong teacher. The cross-modal and unimodal distillation is thenachieved in the multi scale representation space by transferring the featurelevel knowledge from multimodal to anymodal segmentors, aiming at addressingthe unimodal bias and avoiding over-reliance on specific modalities. Moreover,a prediction level modality agnostic semantic distillation is proposed toachieve semantic knowledge transferring for segmentation. Extensive experimentson both synthetic and real-world multi-sensor benchmarks demonstrate that ourmethod achieves superior performance.</description>
      <author>example@mail.com (Xu Zheng, Haiwei Xue, Jialei Chen, Yibo Yan, Lutao Jiang, Yuanhuiyi Lyu, Kailun Yang, Linfeng Zhang, Xuming Hu)</author>
      <guid isPermaLink="false">2411.17141v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>in-Car Biometrics (iCarB) Datasets for Driver Recognition: Face, Fingerprint, and Voice</title>
      <link>http://arxiv.org/abs/2411.17305v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 13 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;文章介绍了三个生物识别数据集(iCarB-Face, iCarB-Fingerprint, iCarB-Voice)，这些数据集中包含了从200名志愿者车内采集的面部视频、指纹图像和语音样本。&lt;h4&gt;背景&lt;/h4&gt;当前大多数公开可用的生物识别数据集仅包含单一模态，而这项研究旨在创建一个综合性的数据集来满足多模态生物识别技术的需求。&lt;h4&gt;目的&lt;/h4&gt;目的是为了提供一个多模式的生物识别数据集用于评估和基准测试面部、指纹和语音识别系统，并支持多重融合算法训练与测试以及演示攻击检测算法的评价。&lt;h4&gt;方法&lt;/h4&gt;通过车内近红外摄像头，两个指纹扫描仪和两支麦克风采集数据。在室内和室外不同环境条件下对志愿者进行数据收集以模拟真实场景中的非理想生物特征数据捕获情况。&lt;h4&gt;主要发现&lt;/h4&gt;这些数据集是目前公开可用的最大且最多样化的车载生物识别数据集合之一；其中iCarB-Fingerprint可能是第一个公开的车内指纹数据库。此外，该数据集中包括50%性别比例和广泛的年龄及肤色范围的参与者。&lt;h4&gt;结论&lt;/h4&gt;这项研究的数据集对于推动生物识别技术的研究具有重要意义，能够广泛应用于多个领域，并且为解决环境偏见提供了可能的方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要描述了三个生物特征数据库（iCarB-Face, iCarB-指纹和iCarB-语音），包含从200名志愿者车内收集的面部视频、指纹图像及语音样本。这些数据集通过在司机座位上使用近红外摄像头，两个指纹扫描仪以及两支麦克风采集，并且在室内室外不同的噪声环境中进行以模拟实际驾驶者识别中可能遇到的情况。尽管这些数据集是专门用于车辆内生物特征识别的，但它们的应用范围不仅限于汽车环境。iCarB数据集可用于评估和基准测试面部、指纹及语音识别系统；创建多模态伪身份来训练/测试多模态融合算法；从生物特征数据中创建演示攻击以评价演示攻击检测算法；以及调查所提供元数据中的统计学偏见和环境影响等。据我们所知，这是目前为止公开可用的最大且最多样化的一组车载生物识别数据库之一。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present three biometric datasets (iCarB-Face, iCarB-Fingerprint,iCarB-Voice) containing face videos, fingerprint images, and voice samples,collected inside a car from 200 consenting volunteers. The data was acquiredusing a near-infrared camera, two fingerprint scanners, and two microphones,while the volunteers were seated in the driver's seat of the car. The datacollection took place while the car was parked both indoors and outdoors, anddifferent "noises" were added to simulate non-ideal biometric data capture thatmay be encountered in real-life driver recognition. Although the datasets arespecifically tailored to in-vehicle biometric recognition, their utility is notlimited to the automotive environment. The iCarB datasets, which are availableto the research community, can be used to: (i) evaluate and benchmark face,fingerprint, and voice recognition systems (we provide several evaluationprotocols); (ii) create multimodal pseudo-identities, to train/test multimodalfusion algorithms; (iii) create Presentation Attacks from the biometric data,to evaluate Presentation Attack Detection algorithms; (iv) investigatedemographic and environmental biases in biometric systems, using the providedmetadata. To the best of our knowledge, ours are the largest and most diversepublicly available in-vehicle biometric datasets. Most other datasets containonly one biometric modality (usually face), while our datasets consist of threemodalities, all acquired in the same automotive environment. Moreover,iCarB-Fingerprint seems to be the first publicly available in-vehiclefingerprint dataset. Finally, the iCarB datasets boast a rare level ofdemographic diversity among the 200 data subjects, including a 50/50 gendersplit, skin colours across the whole Fitzpatrick-scale spectrum, and a wide agerange (18-60+). So, these datasets will be valuable for advancing biometricsresearch.</description>
      <author>example@mail.com (Vedrana Krivokuca Hahn, Jeremy Maceiras, Alain Komaty, Philip Abbet, Sebastien Marcel)</author>
      <guid isPermaLink="false">2411.17305v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>What Differentiates Educational Literature? A Multimodal Fusion Approach of Transformers and Computational Linguistics</title>
      <link>http://arxiv.org/abs/2411.17593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种结合基于Transformer的文本分类与语言特征分析的方法，以解决英语课程中融入新文学作品时面临的可读性评估和适应课堂需求的问题。&lt;h4&gt;背景&lt;/h4&gt;教师在将新的文学作品整合到英语课程中的过程中面临挑战，原因是缺乏可以快速评估阅读难度并根据不同的教学需求进行调整的工具。&lt;h4&gt;目的&lt;/h4&gt;通过结合基于Transformer的技术文本分类与语言特征分析的方法来解决上述问题，并提供一种能够自动推荐学习年龄范围和课程匹配情况的应用程序。&lt;h4&gt;方法&lt;/h4&gt;该研究利用八种最先进的Transformer模型对分割后的文本数据进行了微调，同时搜索了500个深层神经网络结构以进行语言特性分类。最后将这些模态融合在一起，提出了一个结合ELECTRA Transformer与深度神经网络的解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，基于Transformer的方法在单模态情况下表现最好（BERT达到最高F1分数为0.75），而多模态方法则显著优于任何单模态模型。特别是将ELECTRA Transformer与神经网络相结合的方式实现了最高的F1分数为0.996。&lt;h4&gt;结论&lt;/h4&gt;该研究开发了一款面向利益相关者的网页应用，通过AI驱动的推荐功能帮助教师减少工作量，并支持基于数据的决策制定，从而在英语文学的教学计划中整合新文本。&lt;h4&gt;翻译&lt;/h4&gt;原文摘要提供了关于如何使用人工智能技术来改进英文课程中新文学作品融入的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of new literature into the English curriculum remains achallenge since educators often lack scalable tools to rapidly evaluatereadability and adapt texts for diverse classroom needs. This study proposes toaddress this gap through a multimodal approach that combines transformer-basedtext classification with linguistic feature analysis to align texts with UK KeyStages. Eight state-of-the-art Transformers were fine-tuned on segmented textdata, with BERT achieving the highest unimodal F1 score of 0.75. In parallel,500 deep neural network topologies were searched for the classification oflinguistic characteristics, achieving an F1 score of 0.392. The fusion of thesemodalities shows a significant improvement, with every multimodal approachoutperforming all unimodal models. In particular, the ELECTRA Transformer fusedwith the neural network achieved an F1 score of 0.996. The proposed approach isfinally encapsulated in a stakeholder-facing web application, providingnon-technical stakeholder access to real-time insights on text complexity,reading difficulty, curriculum alignment, and recommendations for learning agerange. The application empowers data-driven decision making and reduces manualworkload by integrating AI-based recommendations into lesson planning forEnglish literature.</description>
      <author>example@mail.com (Jordan J. Bird)</author>
      <guid isPermaLink="false">2411.17593v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Conformal Prediction for Hierarchical Data</title>
      <link>http://arxiv.org/abs/2411.13479v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;和解已成为多变量点预测中处理层级时间序列的重要工具，但对概率预测和解技术的理论特性仍缺乏理解。&lt;h4&gt;目的&lt;/h4&gt;将符合预测与预测和解相结合，分析在分裂符合预测程序中加入和解步骤如何增强预测集。&lt;h4&gt;方法&lt;/h4&gt;研究在分裂符合预测(SCP)过程中加入和解步骤的影响，并提出适用于实际的理论程序变体。&lt;h4&gt;主要发现&lt;/h4&gt;加入和解步骤后，SCP的有效性得到保持，同时提高了预测集的效率。&lt;h4&gt;结论&lt;/h4&gt;通过模拟结果展示了结合符合预测和预测和解的有效性。&lt;h4&gt;总结&lt;/h4&gt;本文为结合符合预测与预测和解的研究开辟了新方向，提供了理论分析和仿真实证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconciliation has become an essential tool in multivariate point forecastingfor hierarchical time series. However, there is still a lack of understandingof the theoretical properties of probabilistic Forecast Reconciliationtechniques. Meanwhile, Conformal Prediction is a general framework with growingappeal that provides prediction sets with probabilistic guarantees in finitesample. In this paper, we propose a first step towards combining ConformalPrediction and Forecast Reconciliation by analyzing how including areconciliation step in the Split Conformal Prediction (SCP) procedure enhancesthe resulting prediction sets. In particular, we show that the validity grantedby SCP remains while improving the efficiency of the prediction sets. We alsoadvocate a variation of the theoretical procedure for practical use. Finally,we illustrate these results with simulations.</description>
      <author>example@mail.com (Guillaume Principato, Yvenn Amara-Ouali, Yannig Goude, Bachir Hamrouche, Jean-Michel Poggi, Gilles Stoltz)</author>
      <guid isPermaLink="false">2411.13479v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Quantum versatility in PageRank</title>
      <link>http://arxiv.org/abs/2411.13114v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;量子力学促使量子优势在多个领域的出现，包括量子算法，量子PageRank是未来量子互联网的有前景的工具。&lt;h4&gt;目的&lt;/h4&gt;深入研究任意相位旋转（APR）在量子PageRank算法中的作用。&lt;h4&gt;方法&lt;/h4&gt;分析量子PageRank中的旋转相位对排名分布及其与经典PageRank的相似性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;发现排名中存在聚类现象，具体包括排名分布中的相似聚类、与经典PageRank的保真度、排名分布的方差、PageRank状态的相干性和纠缠，以及在无标度网络上的幂律参数。&lt;h4&gt;结论&lt;/h4&gt;提出了一种包含APR的替代量子PageRank，提供了额外的分析通道，并展示了在替代量子PageRank中形成的丰富聚类多样性。&lt;h4&gt;应用&lt;/h4&gt;为量子PageRank算法的设计和应用提供了新视角，并研究了无标度图的回溯图上的PageRank，以调查网络信息流量跟踪。&lt;h4&gt;总结&lt;/h4&gt;我们的结果为PageRank提供了量子启用的视角，揭示了量子PageRank的潜在应用与设计方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1103/PhysRevResearch.6.043163&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum mechanics empowers the emergence of quantum advantages in variousfields, including quantum algorithms. Quantum PageRank is a promising tool fora future quantum internet. Recently, arbitrary phase rotations (APR) have beenintroduced in the underlying Szegedy's quantum walk of quantum PageRankalgorithm. In this work, we thoroughly study the role APR plays in quantumPageRank. We discover the versatility resulting from quantumness. Specifically,we discover the emergence of a cluster phenomenon in rankings considering therotation phases, i.e. the existence of similar clusters in the distribution ofthe rankings and their fidelity with the corresponding classical PageRanks, theranking distribution variance, the coherence and entanglement of PageRankstates, and the power law parameter in the ranking distributions on ascale-free network concerning the two rotation phases. Furthermore, we proposean alternate quantum PageRank with APR which provides an extra tunnel for theanalysis of PageRank. We also study the PageRank on the trackback graph of ascale-free graph for the investigation of network information traffic tracking.We demonstrate the rich cluster diversity formed in our alternate quantumPageRank, which offers a novel perspective on the quantum versatility ofPageRank. Our results present the quantum-enabled perspective for PageRankingand shed light on the design and application of practical quantum PageRankalgorithms.</description>
      <author>example@mail.com (Wei-Wei Zhang, Zheping Wu, Hengyue Jia, Wei Zhao, Qingbing Ji, Wei Pan, Haobin Shi)</author>
      <guid isPermaLink="false">2411.13114v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Modeling the variability of memristive devices with hexagonal boron nitride as dielectric</title>
      <link>http://arxiv.org/abs/2411.13872v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究基于h-BN电介质的忆阻器件的变异性。&lt;h4&gt;目的&lt;/h4&gt;描述提取复位电压的不同数值技术，并表征相应的循环间变异性。&lt;h4&gt;方法&lt;/h4&gt;采用电荷-通量域开发提取技术，通过电流和电压的积分计算获取电荷和通量，减少电噪声和电阻切换的固有随机性对测量数据的影响。&lt;h4&gt;主要发现&lt;/h4&gt;成功建立了重现电荷与通量曲线的模型；通过时间序列分析描述了器件的变异性，以评估在电阻切换序列中的记忆效应。&lt;h4&gt;结论&lt;/h4&gt;分析了在斜坡电压应力下的I-V曲线，研究了构成导电纳米微丝的渗流路径的形成与断裂，从而描述了电阻切换操作中的设定与复位过程。&lt;h4&gt;总结&lt;/h4&gt;本研究深入探讨了基于h-BN电介质的忆阻器的变异性及其影响因素，为进一步的研究和应用提供了理论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TED.2022.3197677&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Variability in memristive devices based on h-BN dielectrics is studied indepth. Different numerical techniques to extract the reset voltage aredescribed and the corresponding cycle-to-cycle variability is characterized bymeans of the coefficient of variance. The charge-flux domain was employed todevelop one of the extraction techniques, the calculation of the integrals ofcurrent and voltage to obtain the charge and flux allows to minimize theeffects of electric noise and the inherent stochasticity of resistive switchingon the measurement data. A model to reproduce charge versus flux curves hasbeen successfully employed. The device variability is also described by meansof the time series analysis to assess the memory effect along a resistiveswitching series. Finally, we analyzed I-V curves under ramped voltage stressutilizing a simulator based on circuit breakers, the formation and rupture ofthe percolation paths that constitute the conductive nanofilaments is studiedto describe the set and reset processes behind the resistive switchingoperation.</description>
      <author>example@mail.com (Juan B. Roldan, David Maldonado, C. Aguilera-Pedregosa, F. J. Alonso, Yiping Xiao, Yaqing Shen, Wenwen Zheng, Yue Yuan, Mario Lanza)</author>
      <guid isPermaLink="false">2411.13872v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Extremum and Nash Equilibrium Seeking with Delays and PDEs: Designs &amp; Applications</title>
      <link>http://arxiv.org/abs/2411.13234v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint submitted to IEEE Control Systems Magazine (Special Issue:
  Into the Second Century of Extremum Seeking Control, 38 pages and 34 figures)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;极值寻求（ES）在过去一百年中经历了从静态映射到有限维动态系统，再到静态和动态代理网络的发展。&lt;h4&gt;目的&lt;/h4&gt;探讨将延迟或偏微分方程（PDE）引入极值寻求的方法，并回顾相关算法设计和理论。&lt;h4&gt;方法&lt;/h4&gt;分析超越常微分方程（ODE）动态的无限维系统，包括双曲和抛物动态，以及引入纳什均衡寻求（NES）方法。&lt;h4&gt;主要发现&lt;/h4&gt;考虑非合作博弈场景下的模型无关极值寻求，特别是针对单代理优化的情况，涉及异质PDE博弈。&lt;h4&gt;结论&lt;/h4&gt;探讨了流量控制、油气钻探、深海电缆源寻求、增材制造等多种工程应用。&lt;h4&gt;总结&lt;/h4&gt;本文综述了极值寻求在无限维系统中的最新研究进展，并展示了其在多个工程领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of extremum seeking (ES) has progressed, over the pasthundred years, from static maps, to finite-dimensional dynamic systems, tonetworks of static and dynamic agents. Extensions from ODE dynamics to maps andagents that incorporate delays or even partial differential equations (PDEs) isthe next natural step in that progression through ascending researchchallenges. This paper reviews results on algorithm design and theory of ES forsuch infinite-dimensional systems. Both hyperbolic and parabolic dynamics arepresented: delays or transport equations, heat-dominated equation, waveequations, and reaction-advection-diffusion equations. Nash equilibrium seeking(NES) methods are introduced for noncooperative game scenarios of themodel-free kind and then specialized to single-agent optimization. Evenheterogeneous PDE games, such as a duopoly with one parabolic and onehyperbolic agent, are considered. Several engineering applications are touchedupon for illustration, including flow-traffic control for urban mobility,oil-drilling systems, deep-sea cable-actuated source seeking, additivemanufacturing modeled by the Stefan PDE, biological reactors, light-sourceseeking with flexible-beam structures, and neuromuscular electricalstimulation.</description>
      <author>example@mail.com (Tiago Roux Oliveira, Miroslav Krstić, Tamer Başar)</author>
      <guid isPermaLink="false">2411.13234v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Urban Region Embeddings from Service-Specific Mobile Traffic Data</title>
      <link>http://arxiv.org/abs/2411.15214v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着先进的4G/5G移动网络的出现，运营商收集的手机数据现在包含详细的、特定服务的高时空分辨率流量信息。&lt;h4&gt;目的&lt;/h4&gt;探讨利用这种类型的数据生成高质量的城市区域表示。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于服务特定移动流量数据创建城市区域嵌入的方法，使用时间卷积网络自编码器、变换器和可学习加权求和模型来捕捉关键城市特征。&lt;h4&gt;主要发现&lt;/h4&gt;通过实地数据集进行的广泛实验评估表明，所生成的嵌入有效捕捉了城市特征，并与最先进的竞争对手在两个下游任务中进行了比较。&lt;h4&gt;结论&lt;/h4&gt;通过聚类技术，我们研究了嵌入如何捕捉基础城市区域的时间动态和特征，强调服务特定移动流量数据在城市研究中的潜力，并指出使这些数据可访问的重要性，以支持公共创新。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了服务特定移动流量数据在城市研究中的应用潜力，并强调了数据可获取性对公共创新的支持作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advent of advanced 4G/5G mobile networks, mobile phone datacollected by operators now includes detailed, service-specific trafficinformation with high spatio-temporal resolution. In this paper, we leveragethis type of data to explore its potential for generating high-qualityrepresentations of urban regions. To achieve this, we present a methodology forcreating urban region embeddings from service-specific mobile traffic data,employing a temporal convolutional network-based autoencoder, transformers, andlearnable weighted sum models to capture key urban features. In the extensiveexperimental evaluation conducted using a real-world dataset, we demonstratethat the embeddings generated by our methodology effectively capture urbancharacteristics. Specifically, our embeddings are compared against those of astate-of-the-art competitor across two downstream tasks. Additionally, throughclustering techniques, we investigate how well the embeddings produced by ourmethodology capture the temporal dynamics and characteristics of the underlyingurban regions. Overall, this work highlights the potential of service-specificmobile traffic data for urban research and emphasizes the importance of makingsuch data accessible to support public innovation.</description>
      <author>example@mail.com (Giulio Loddi, Chiara Pugliese, Francesco Lettich, Fabio Pinelli, Chiara Renso)</author>
      <guid isPermaLink="false">2411.15214v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Dataset for Evaluating Online Anomaly Detection Approaches for Discrete Multivariate Time Series</title>
      <link>http://arxiv.org/abs/2411.13951v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to the IEEE Transactions on Reliability journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列的异常检测方法评估面临挑战，主要由于缺乏高质量的数据集。&lt;h4&gt;目的&lt;/h4&gt;提出一个多样化、广泛且非平凡的数据集，以推动该研究领域的进展。&lt;h4&gt;方法&lt;/h4&gt;利用先进的模拟工具生成反映汽车动力系统真实行为的数据集，包含多变量、动态和可变状态特性。&lt;h4&gt;主要发现&lt;/h4&gt;提供不同版本的数据集，适用于无监督和半监督异常检测，同时支持时间序列生成和预测；基于确定性和变分自编码器的基线结果表明，半监督版本的训练结果优于无监督版本。&lt;h4&gt;结论&lt;/h4&gt;需要开发对受污染训练数据更具鲁棒性的方法，以提升异常检测的效果。&lt;h4&gt;总结&lt;/h4&gt;新数据集的引入为多变量时间序列的异常检测提供了新的机会，尤其是在半监督学习背景下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lcs-crr/path&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Benchmarking anomaly detection approaches for multivariate time series ischallenging due to the lack of high-quality datasets. Current publiclyavailable datasets are too small, not diverse and feature trivial anomalies,which hinders measurable progress in this research area. We propose a solution:a diverse, extensive, and non-trivial dataset generated via state-of-the-artsimulation tools that reflects realistic behaviour of an automotive powertrain,including its multivariate, dynamic and variable-state properties. To cater forboth unsupervised and semi-supervised anomaly detection settings, as well astime series generation and forecasting, we make different versions of thedataset available, where training and test subsets are offered in contaminatedand clean versions, depending on the task. We also provide baseline resultsfrom a small selection of approaches based on deterministic and variationalautoencoders, as well as a non-parametric approach. As expected, the baselineexperimentation shows that the approaches trained on the semi-supervisedversion of the dataset outperform their unsupervised counterparts, highlightinga need for approaches more robust to contaminated training data.</description>
      <author>example@mail.com (Lucas Correia, Jan-Christoph Goos, Thomas Bäck, Anna V. Kononova)</author>
      <guid isPermaLink="false">2411.13951v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Packet Steering Mechanisms for MLO in Wi-Fi 7</title>
      <link>http://arxiv.org/abs/2411.13470v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  preprint, 4 pages, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Wi-Fi 7除了提供极高的吞吐量外，还旨在为用户提供更确定性的行为，特征为更短的平均延迟和更小的抖动。&lt;h4&gt;目的&lt;/h4&gt;研究多链路操作机制，以实现客户端站点的同时多频段通信。&lt;h4&gt;方法&lt;/h4&gt;对流量引导策略进行简要回顾，并将其分为一般类别，分析每种策略的优缺点。同时描述了一种支持动态引导的基本机制。&lt;h4&gt;主要发现&lt;/h4&gt;所述机制简单易于在真实的Wi-Fi芯片中实现，同时具有高度灵活性，可以基于每个数据包进行操作。&lt;h4&gt;结论&lt;/h4&gt;此机制允许根据应用需求和流量模式优化频谱使用。&lt;h4&gt;总结&lt;/h4&gt;Wi-Fi 7通过多链路操作和灵活的流量引导策略提升了网络性能和用户体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ETFA61755.2024.10710726&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Besides extremely high throughput, Wi-Fi 7 is also aimed at providing users amore deterministic behavior, characterized by shorter average latency andsmaller jitters. A key mechanism to achieve this is multi-link operation, whichbrings simultaneous multi-band communication to client stations as well. Inthis paper, traffic steering policies are briefly reviewed and grouped intogeneral classes, each one with its advantages and limitations. A basicmechanism for supporting dynamic steering is then described, which is simpleenough to allow implementation in real Wi-Fi chipsets but highly flexible atthe same time. Its operation can be driven by the host on a per-packet basis,and this permits to optimize spectrum usage depending on the requirements ofapplications and the traffic pattern they generate.</description>
      <author>example@mail.com (Gianluca Cena, Matteo Rosani, Stefano Scanzio)</author>
      <guid isPermaLink="false">2411.13470v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Spectral domain likelihoods for Bayesian inference in time-varying parameter models</title>
      <link>http://arxiv.org/abs/2411.14010v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;局部平稳过程的推断通常基于频域中的某种局部Whittle类型的似然函数近似。&lt;h4&gt;目的&lt;/h4&gt;评估几种频域似然函数在时间变化参数模型中近似后验分布的有限样本准确性。&lt;h4&gt;方法&lt;/h4&gt;通过三项模拟研究进行评估，并在蛋价数据的应用中进行说明。&lt;h4&gt;主要发现&lt;/h4&gt;频域似然函数在计算成本和大数据系列的可扩展性上优于时间域似然，特别是在使用马尔可夫链蒙特卡洛（MCMC）进行贝叶斯推断时。&lt;h4&gt;结论&lt;/h4&gt;频域似然函数提供了在频域中指定模型的便利，并且能够利用傅里叶变换数据的渐近独立性进行引导和子抽样MCMC。&lt;h4&gt;总结&lt;/h4&gt;本研究为频域似然函数在局部平稳过程中的实际应用提供了有限样本准确性的评估，展示了其在经济数据分析中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inference for locally stationary processes is often based on some localWhittle-type approximation of the likelihood function defined in the frequencydomain. The main reasons for using such a likelihood approximation is that i)it has substantially lower computational cost and better scalability to longtime series compared to the time domain likelihood, particularly when used forBayesian inference via Markov Chain Monte Carlo (MCMC), ii) convenience whenthe model itself is specified in the frequency domain, and iii) it providesaccess to bootstrap and subsampling MCMC which exploits the asymptoticindependence of Fourier transformed data. Most of the existing literaturecompares the asymptotic performance of the maximum likelihood estimator (MLE)from such frequency domain likelihood approximation with the exact time domainMLE. Our article uses three simulation studies to assess the finite-sampleaccuracy of several frequency domain likelihood functions when used toapproximate the posterior distribution in time-varying parameter models. Themethods are illustrated on an application to egg price data.</description>
      <author>example@mail.com (Oskar Gustafsson, Mattias Villani, Robert Kohn)</author>
      <guid isPermaLink="false">2411.14010v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Effects of Muscle Synergy during Overhead Work with a Passive Shoulder Exoskeleton: A Case Study</title>
      <link>http://arxiv.org/abs/2411.15504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;肩部外骨骼可以有效辅助进行高空作业，但其对肌肉协同作用的影响尚不明确。&lt;h4&gt;目的&lt;/h4&gt;系统研究肩部外骨骼在高空作业中对肌肉协同作用的影响。&lt;h4&gt;方法&lt;/h4&gt;招募了八名男性参与者进行螺丝拧紧任务，分别在有外骨骼（干预组）和无外骨骼（正常组）条件下进行。监测了八块肌肉，并通过非负矩阵分解和肌电图拓扑图提取肌肉协同作用。&lt;h4&gt;主要发现&lt;/h4&gt;在两种条件下提取的协同作用数量相同（n=2）。第一协同作用在两种条件下相同，AD和MD的权重最高；第二协同作用在两种条件下不同，PM和MD的权重分别最高。在干预组的第一协同作用中，激活特征显著降低，平均招募水平和激活持续时间显著减少（p&lt;0.05）。不同条件下的肌肉协同作用回归分析显示，肌肉协同作用的变化未影响其稀疏性（p=0.7341）。拓扑图中，平均值显著降低（p&lt;0.001），熵显著增加（p&lt;0.01）。&lt;h4&gt;结论&lt;/h4&gt;外骨骼不改变协同作用的数量和主要协同作用，但可能诱导新的协同作用，并显著降低神经激活，可能影响监测肌肉激活的分布异质性。&lt;h4&gt;意义&lt;/h4&gt;本研究为外骨骼辅助高空作业的潜在机制提供了见解，并为改善外骨骼性能提供了指导。&lt;h4&gt;总结&lt;/h4&gt;肩部外骨骼在高空作业中对肌肉协同作用的影响值得进一步研究，以优化其应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Objective: Shoulder exoskeletons can effectively assist with overhead work.However, their impacts on muscle synergy remain unclear. The objective is tosystematically investigate the effects of the shoulder exoskeleton on musclesynergies during overhead work.Methods: Eight male participants were recruitedto perform a screwing task both with (Intervention) and without (Normal) theexoskeleton. Eight muscles were monitored and muscle synergies were extractedusing non-negative matrix factorization and electromyographic topographic maps.Results: The number of synergies extracted was the same (n = 2) in bothconditions. Specifically, the first synergies in both conditions wereidentical, with the highest weight of AD and MD; while the second synergieswere different between conditions, with highest weight of PM and MD,respectively. As for the first synergy in the Intervention condition, theactivation profile significantly decreased, and the average recruitment leveland activation duration were significantly lower (p&lt;0.05). The regressionanalysis for the muscle synergies across conditions shows the changes of musclesynergies did not influence the sparseness of muscle synergies (p=0.7341). Inthe topographic maps, the mean value exhibited a significant decrease (p&lt;0.001)and the entropy significantly increased (p&lt;0.01). Conclusion: The exoskeletondoes not alter the number of synergies and existing major synergies but mayinduce new synergies. It can also significantly decrease neural activation andmay influence the heterogeneity of the distribution of monitored muscleactivations. Significance: This study provides insights into the potentialmechanisms of exoskeleton-assisted overhead work and guidance on improving theperformance of exoskeletons.</description>
      <author>example@mail.com (Jin Tian, Baichun Wei, Chifu Yang, Suo Luo, Jiadong Feng, Ping Li, Changbing Chen, Yingjie Liu, Haiqi Zhu, Chunzhi Yi)</author>
      <guid isPermaLink="false">2411.15504v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Bayesian mixture model for Poisson network autoregression</title>
      <link>http://arxiv.org/abs/2411.14265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究提出了一种新的贝叶斯泊松网络自回归混合模型（PNARM），旨在解决多元计数时间序列建模的问题，这在许多现实世界数据集中出现，但研究较少。&lt;h4&gt;目的&lt;/h4&gt;结合Dahl 2008、Ren等人2024及Armillotta与Fokianos 2024的模型思想，开发一个能够处理异质节点动态的模型，并实现对表现相似节点的聚类。&lt;h4&gt;方法&lt;/h4&gt;假设时间序列发生在一个已知的基础网络节点上，边缘决定结构向量自回归模型的形式，以施加稀疏性。同时，开发了一种MCMC算法用于从模型的后验分布中进行采样。&lt;h4&gt;主要发现&lt;/h4&gt;模型被应用于爱尔兰共和国各县的COVID-19病例数据集，展示了其在实际数据中的有效性。&lt;h4&gt;结论&lt;/h4&gt;PNARM模型为多元计数时间序列的建模提供了新的视角，并能够有效处理节点动态及聚类问题。&lt;h4&gt;总结&lt;/h4&gt;本研究为多元计数时间序列的贝叶斯建模提供了一种创新的方法，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a new Bayesian Poisson network autoregressionmixture model (PNARM). Our model combines ideas from the models of Dahl 2008,Ren et al. 2024 and Armillotta and Fokianos 2024, as it is motivated by thefollowing aims. We consider the problem of modelling multivariate count timeseries since they arise in many real-world data sets, but has been studied lessthan its Gaussian-distributed counterpart (Fokianos 2024). Additionally, weassume that the time series occur on the nodes of a known underlying networkwhere the edges dictate the form of the structural vector autoregression model,as a means of imposing sparsity. A further aim is to accommodate heterogeneousnode dynamics, and to develop a probabilistic model for clustering nodes thatexhibit similar behaviour. We develop an MCMC algorithm for sampling from themodel's posterior distribution. The model is applied to a data set of COVID-19cases in the counties of the Republic of Ireland.</description>
      <author>example@mail.com (Elly Hung, Anastasia Mantziou, Gesine Reinert)</author>
      <guid isPermaLink="false">2411.14265v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Hermes: A General-Purpose Proxy-Enabled Networking Architecture</title>
      <link>http://arxiv.org/abs/2411.13668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种名为Hermes的通用网络架构，基于可重构代理的覆盖网络。&lt;h4&gt;目的&lt;/h4&gt;将网络责任从应用程序和服务转移到覆盖代理上。&lt;h4&gt;方法&lt;/h4&gt;采用多种代理和隧道技术，以HTTP为核心组件，并引入辅助组件以促进服务交付、增强通信和改善用户体验。&lt;h4&gt;主要发现&lt;/h4&gt;Hermes能够有效解决服务和通信挑战，支持与传统应用和协议的兼容性，并提供可靠的交付，尤其在不利的网络条件下表现良好。&lt;h4&gt;结论&lt;/h4&gt;Hermes能够提供端到端的、基于业务逻辑的IP流量处理，并作为命名数据网络的通信管道，促进未来网络架构的发展和采用。&lt;h4&gt;总结&lt;/h4&gt;Hermes架构展示了在复杂网络环境中提升服务交付和用户体验的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Bfarkiani/Hermes&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Hermes, a general-purpose networking architecture built on anoverlay of reconfigurable proxies. Hermes delegates networking responsibilitiesfrom applications and services to the overlay proxies. It employs a range ofproxying and tunneling techniques, utilizes HTTP as its core component, andincorporates assisting components to facilitate service delivery, enhancecommunication, and improve end-users' experience. To substantiate thesebenefits, we prototyped Hermes and demonstrated its ability to efficientlyaddress service and communication challenges. We showed that Hermes enablesend-to-end solutions for compatibility with legacy applications and protocolsand reliable delivery in highly disadvantaged networking conditions.Furthermore, Hermes demonstrated its ability to provide end-to-end,business-logic-driven handling of general IP traffic and to serve as acommunication pipeline for Named Data Networking, facilitating the developmentand adoption of future networking architectures.</description>
      <author>example@mail.com (Behrooz Farkiani, Fan Liu, Ke Yang, John DeHart, Jyoti Parwatikar, Patrick Crowley)</author>
      <guid isPermaLink="false">2411.13668v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Developing Global Aerosol Models based on the Analysis of 30-Year Ground Measurements by AERONET (AEROEX models) and Implication on Satellite based Aerosol Retrievals</title>
      <link>http://arxiv.org/abs/2411.15518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;AErosol RObotic NETwork (AERONET) 于1993年建立，现已扩展到900多个地点，提供了三十年的气溶胶数据。&lt;h4&gt;目的&lt;/h4&gt;对1993-2023年的庞大AERONET数据集进行全面重新评估，以改进全球气溶胶模型和卫星遥感结果。&lt;h4&gt;方法&lt;/h4&gt;基于30年的AERONET数据，采用高斯混合模型进行聚类分析，分析超过202,000个样本，分类气溶胶类型。&lt;h4&gt;主要发现&lt;/h4&gt;开发了AERONET-Extended (AEROEX)模型，识别出四种细颗粒气溶胶模型和两种粗颗粒气溶胶模型，展示了区域和季节差异，尤其在北美、欧洲和亚洲。&lt;h4&gt;结论&lt;/h4&gt;新模型显著改善了基于卫星的气溶胶光学厚度检索，相比于广泛使用的暗目标气溶胶模型，提供了更好的结果。&lt;h4&gt;总结&lt;/h4&gt;生成的全球气溶胶模型图，具有1x1度分辨率，为气候和大气研究提供了宝贵的见解，提升了全球范围内的气溶胶遥感能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The AErosol RObotic NETwork (AERONET), established in 1993 with limitedglobal sites, has grown to over 900 locations, providing three decades ofcontinuous aerosol data. While earlier studies based on shorter time periods(10-12 years) and fewer sites (approximately 250) made significantcontributions to aerosol research, the vast AERONET dataset (1993-2023) callsfor a comprehensive reevaluation to refine global aerosol models and improvesatellite retrievals. This is particularly important in light of majorenvironmental changes such as industrialization, land use shifts, and naturalevents like wildfires and dust storms. In this study, a set of fine and coarseaerosol models called AERONET-Extended (AEROEX) models are developed based oncluster analysis of 30-years AERONET data, analyzing over 202,000 samples usingGaussian Mixture Models to classify aerosol types by season and region.Aerosols are categorized into spherical, spheroidal, and mixed types usingparticle linear depolarization ratio and fine mode fraction. Four fine-modeaerosol models were derived based on differences in scattering and absorptionproperties, revealing regional/seasonal variations, particularly in NorthAmerica, Europe and Asia. Additionally, two coarse-mode aerosol models wereidentified, separated by their absorbing properties in dust-prone and pollutedregions. We performed simulation analysis showing that the new modelssignificantly improve satellite-based aerosol optical depth retrievals comparedto widely used dark target aerosol models. A global aerosol model map,generated at 1x1 degree resolution for each season using Random Forest andexpert refinement, provides valuable insights for climate and atmosphericstudies, improving satellite-based aerosol retrievals at global scale.</description>
      <author>example@mail.com (Manoj K Mishra, Shameela S F, Pradyuman Singh Rathore)</author>
      <guid isPermaLink="false">2411.15518v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Robust Energy System Design via Semi-infinite Programming</title>
      <link>http://arxiv.org/abs/2411.14320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  manuscript (32 pages, 6 figures), supplementary materials (24 pages,
  2 figures, 2 tables)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列信息需要纳入能源系统优化，以应对可再生能源源的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种鲁棒能源系统设计（RESD）方法，以识别优化过程中的最坏情况场景。&lt;h4&gt;方法&lt;/h4&gt;基于半无穷编程的RESD方法，采用自适应离散化算法来识别最坏情况；使用主成分分析减少不确定性空间的维度。&lt;h4&gt;主要发现&lt;/h4&gt;RESD方法能够保证对于具有非凸操作行为的问题提供鲁棒设计，当前方法无法实现这一点。&lt;h4&gt;结论&lt;/h4&gt;尽管实现了强维度缩减，但RESD方法计算强度大，仅适用于小规模问题。&lt;h4&gt;应用示例&lt;/h4&gt;在拉帕尔马岛设计能源供应系统时展示了RESD方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;RESD方法在处理极端情境时表现出色，但计算资源需求高，限制了其应用范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time-series information needs to be incorporated into energy systemoptimization to account for the uncertainty of renewable energy sources.Typically, time-series aggregation methods are used to reduce historical datato a few representative scenarios but they may neglect extreme scenarios, whichdisproportionally drive the costs in energy system design. We propose therobust energy system design (RESD) approach based on semi-infinite programmingand use an adaptive discretization-based algorithm to identify worst-casescenarios during optimization. The RESD approach can guarantee robust designsfor problems with nonconvex operational behavior, which current methods cannotachieve. The RESD approach is demonstrated by designing an energy supply systemfor the island of La Palma. To improve computational performance, principalcomponent analysis is used to reduce the dimensionality of the uncertaintyspace. The robustness and costs of the approximated problem with significantlyreduced dimensionality approximate the full-dimensional solution closely. Evenwith strong dimensionality reduction, the RESD approach is computationallyintense and thus limited to small problems.</description>
      <author>example@mail.com (Moritz Wedemeyer, Eike Cramer, Alexander Mitsos, Manuel Dahmen)</author>
      <guid isPermaLink="false">2411.14320v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Robust Data-Driven Predictive Control for Mixed Platoons under Noise and Attacks</title>
      <link>http://arxiv.org/abs/2411.13924v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;混合车队控制面临重大挑战，因为其中包含人类驾驶车辆（HDVs）和连接自动化车辆（CAVs），人类驾驶行为的不确定性和未知性使得控制变得复杂。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决方法，通过数据驱动控制方法改善混合车队的稳定性和安全性。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于数据驱动可达性分析的鲁棒数据驱动预测领先巡航控制（RDeeP-LCC）框架，使用从数据中得出的矩阵区域集来过度近似系统动态，发展稳定反馈控制律。&lt;h4&gt;主要发现&lt;/h4&gt;RDeeP-LCC方法显著增强了混合车队的鲁棒性，提高了对实际噪声和攻击的稳定性和安全性。&lt;h4&gt;结论&lt;/h4&gt;通过解耦混合车队系统的名义部分和误差部分，使用数据驱动可达性集递归计算误差可达集，从而获得名义系统的收紧安全约束，确保了鲁棒数据驱动预测控制的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究通过数值模拟和人机互动实验验证了RDeeP-LCC框架在混合交通中的应用效果，证明了其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controlling mixed platoons, which consist of both connected and automatedvehicles (CAVs) and human-driven vehicles (HDVs), poses significant challengesdue to the uncertain and unknown human driving behaviors. Data-driven controlmethods offer promising solutions by leveraging available trajectory data, buttheir performance can be compromised by process noise and adversarial attacks.To address this issue, this paper proposes a Robust Data-EnablEd PredictiveLeading Cruise Control (RDeeP-LCC) framework based on data-driven reachabilityanalysis. The framework over-approximates system dynamics under noise andattack using a matrix zonotope set derived from data, and develops astabilizing feedback control law. By decoupling the mixed platoon system intonominal and error components, we employ data-driven reachability sets torecursively compute error reachable sets that account for noise and attacks,and obtain tightened safety constraints of the nominal system. This leads to arobust data-driven predictive control framework, solved in a tube-based controlmanner. Numerical simulations and human-in-the-loop experiments validate thatthe RDeeP-LCC method significantly enhances the robustness of mixed platoons,improving mixed traffic stability and safety against practical noise andattacks.</description>
      <author>example@mail.com (Shuai Li, Chaoyi Chen, Haotian Zheng, Jiawei Wang, Qing Xu, Jianqiang Wang, Keqiang Li)</author>
      <guid isPermaLink="false">2411.13924v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Development of a Low-Cost Prosthetic Hand Using Electromyography and Machine Learning</title>
      <link>http://arxiv.org/abs/2411.15533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;肌电图（EMG）用于测量肌肉电活动，广泛应用于临床、生物医学和人机交互领域。&lt;h4&gt;目的&lt;/h4&gt;开发一种低成本且有效的肌电假肢手，以满足发展中国家的截肢者需求。&lt;h4&gt;方法&lt;/h4&gt;利用来自三块肌肉的EMG记录，准确分类五种不同的手势，控制由两个伺服电机构成的机械手。建立高效的信号采集和放大系统，并对信号进行频域和时域分析，提取特征并训练浅层神经网络。&lt;h4&gt;主要发现&lt;/h4&gt;时域和频域的分类准确率分别为97.25%和95.85%，时域分析计算和响应更快，因此被采纳用于分类系统。&lt;h4&gt;结论&lt;/h4&gt;设计并测试了一种手腕旋转机制，通过两个手势控制，增加了整体设计的自由度，并开发了触觉反馈系统，使用户能够感知施加在手上的力量。&lt;h4&gt;总结&lt;/h4&gt;该项目成功开发了功能多样的肌电假肢手，具有良好的分类准确性和用户反馈能力，适合截肢者使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electromyography (EMG) is a measure of muscular electrical activity and isused in many clinical/biomedical disciplines and modern human computerinteraction. Myo-electric prosthetics analyze and classify the electricalsignals recorded from the residual limb. The classified output is then used tocontrol the position of motors in a robotic hand and a movement is produced.The aim of this project is to develop a low-cost and effective myo-electricprosthetic hand that would meet the needs of amputees in developing countries.The proposed prosthetic hand should be able to accurately classify fivedifferent patterns (gestures) using EMG recordings from three muscles andcontrol a robotic hand accordingly. The robotic hand is composed of two servomotors allowing for two degrees of freedom. After establishing an efficientsignal acquisition and amplification system, EMG signals were thoroughlyanalyzed in the frequency and time domain. Features were extracted from bothdomains and a shallow neural network was trained on the two sets of data.Results yielded an average classification accuracy of 97.25% and 95.85% for thetime and frequency domains respectively. Furthermore, results showed a fastercomputation and response for the time domain analysis; hence, it was adoptedfor the classification system. A wrist rotation mechanism was designed andtested to add significant functionality to the prosthetic. The mechanism iscontrolled by two of the five gestures, one for each direction. Which added athird degree of freedom to the overall design. Finally, a tactile sensoryfeedback system which uses force sensors and vibration motors was developed toenable sensation of the force inflicted on the hand for the user.</description>
      <author>example@mail.com (Mosab Diab, Ashraf Mohammed, Yinlai Jiang)</author>
      <guid isPermaLink="false">2411.15533v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>FedRAV: Hierarchically Federated Region-Learning for Traffic Object Classification of Autonomous Vehicles</title>
      <link>http://arxiv.org/abs/2411.13979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新兴的联邦学习使分布式自主车辆能够协作训练深度学习模型，而无需暴露原始数据。&lt;h4&gt;目的&lt;/h4&gt;探讨如何在复杂的交通环境中有效地应用联邦学习，以处理车辆的非独立同分布（Non-IID）数据问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的分层联邦区域学习框架（FedRAV），该框架通过定义区域间距，将大区域划分为子区域，并实现个性化车辆模型和区域模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，FedRAV在三个真实世界的自主驾驶数据集上，优于现有的联邦学习算法，准确率提高至少3.69%。&lt;h4&gt;结论&lt;/h4&gt;FedRAV框架有效解决了非IID数据导致的收敛失败和低训练精度的问题，具有良好的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;FedRAV展示了在复杂交通场景中应用联邦学习的有效性，源码可在GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yjzhai-cs/fedrav&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emerging federated learning enables distributed autonomous vehicles totrain equipped deep learning models collaboratively without exposing their rawdata, providing great potential for utilizing explosively growing autonomousdriving data. However, considering the complicated traffic environments anddriving scenarios, deploying federated learning for autonomous vehicles isinevitably challenged by non-independent and identically distributed (Non-IID)data of vehicles, which may lead to failed convergence and low trainingaccuracy. In this paper, we propose a novel hierarchically FederatedRegion-learning framework of Autonomous Vehicles (FedRAV), a two-stageframework, which adaptively divides a large area containing vehicles intosub-regions based on the defined region-wise distance, and achievespersonalized vehicular models and regional models. This approach ensures thatthe personalized vehicular model adopts the beneficial models while discardingthe unprofitable ones. We validate our FedRAV framework against existingfederated learning algorithms on three real-world autonomous driving datasetsin various heterogeneous settings. The experiment results demonstrate that ourframework outperforms those known algorithms, and improves the accuracy by atleast 3.69%. The source code of FedRAV is available at:https://github.com/yjzhai-cs/FedRAV.</description>
      <author>example@mail.com (Yijun Zhai, Pengzhan Zhou, Yuepeng He, Fang Qu, Zhida Qin, Xianlong Jiao, Guiyan Liu, Songtao Guo)</author>
      <guid isPermaLink="false">2411.13979v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>From RNNs to Foundation Models: An Empirical Study on Commercial Building Energy Consumption</title>
      <link>http://arxiv.org/abs/2411.14421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Workshop on Time Series in the Age of Large Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的商业建筑短期能耗预测对智能电网操作至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究数据异质性对时间序列预测模型性能的影响。&lt;h4&gt;方法&lt;/h4&gt;使用ComStock数据集，该数据集提供美国商业建筑的合成能耗数据，评估不同时间序列预测模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;数据集的异质性和模型架构对训练后的预测性能影响大于参数数量。&lt;h4&gt;结论&lt;/h4&gt;尽管计算成本较高，经过微调的基础模型在性能上与从头训练的基础模型竞争力强。&lt;h4&gt;总结&lt;/h4&gt;研究表明在保持数据集大小和模型不变的情况下，数据异质性对预测性能的影响值得关注。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate short-term energy consumption forecasting for commercial buildingsis crucial for smart grid operations. While smart meters and deep learningmodels enable forecasting using past data from multiple buildings, dataheterogeneity from diverse buildings can reduce model performance. The impactof increasing dataset heterogeneity in time series forecasting, while keepingsize and model constant, is understudied. We tackle this issue using theComStock dataset, which provides synthetic energy consumption data for U.S.commercial buildings. Two curated subsets, identical in size and region butdiffering in building type diversity, are used to assess the performance ofvarious time series forecasting models, including fine-tuned open-sourcefoundation models (FMs). The results show that dataset heterogeneity and modelarchitecture have a greater impact on post-training forecasting performancethan the parameter count. Moreover, despite the higher computational cost,fine-tuned FMs demonstrate competitive performance compared to base modelstrained from scratch.</description>
      <author>example@mail.com (Shourya Bose, Yijiang Li, Amy Van Sant, Yu Zhang, Kibaek Kim)</author>
      <guid isPermaLink="false">2411.14421v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Teaching Shortest Path Algorithms With a Robot and Overlaid Projections</title>
      <link>http://arxiv.org/abs/2411.15535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 12 references, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人有潜力增强高级计算机科学主题的教学，使抽象概念更具可感性和互动性。&lt;h4&gt;目的&lt;/h4&gt;介绍Timmy机器人，通过投影演示最短路径算法在交互学习环境中的应用。&lt;h4&gt;方法&lt;/h4&gt;集成基于JavaScript的应用程序，允许用户构建图形并可视化三种不同的最短路径算法。进行了两项用户研究以评估Timmy的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;初步研究表明，机器人作为教学工具是引人入胜的，但需要进一步的方法论改进和更大规模的研究来全面评估其有效性。&lt;h4&gt;结论&lt;/h4&gt;机器人的使用可以帮助教学高级算法概念，但尚需更多研究以验证其教学效果。&lt;h4&gt;总结&lt;/h4&gt;Timmy机器人结合投影技术为学习最短路径算法提供了新的交互方式，显示出未来教学的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots have the potential to enhance teaching of advanced computer sciencetopics, making abstract concepts more tangible and interactive. In this paper,we present Timmy-a GoPiGo robot augmented with projections to demonstrateshortest path algorithms in an interactive learning environment. We integrateda JavaScript-based application that is projected around the robot, which allowsusers to construct graphs and visualise three different shortest pathalgorithms with colour-coded edges and vertices. Animated graph exploration andtraversal are augmented by robot movements. To evaluate Timmy, we conducted twouser studies. An initial study (n=10) to explore the feasibility of this typeof teaching where participants were just observing both robot-synced and theon-screen-only visualisations. And a pilot study (n=6) where participantsactively interacted with the system, constructed graphs and selected desiredalgorithms. In both studies we investigated the preferences towards the systemand not the teaching outcome. Initial findings suggest that robots offer anengaging tool for teaching advanced algorithmic concepts, but highlight theneed for further methodological refinements and larger-scale studies to fullyevaluate their effectiveness.</description>
      <author>example@mail.com (Pavel Jolakoski, Jordan Aiko Deja, Klen Čopič Pucihar, Matjaž Kljun)</author>
      <guid isPermaLink="false">2411.15535v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Multi-Layer Blockchain Simulator and Performance Evaluation of Social Internet of Vehicles with Multi-Connectivity Management</title>
      <link>http://arxiv.org/abs/2411.14000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;V2X通信的发展带来了数据完整性和集中管理带来的脆弱性等重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出将去中心化区块链技术与V2X通信相结合的创新方案。&lt;h4&gt;方法&lt;/h4&gt;通过多层架构，将城市交通模拟器(SUMO)与区块链模拟器(BlockSim)整合在一起。&lt;h4&gt;主要发现&lt;/h4&gt;在城市、郊区和农村等不同环境中评估区块链性能，提升重传区块链消息的成功率显著增强了区块链交易性能。&lt;h4&gt;结论&lt;/h4&gt;为智能社会车辆互联网(SIoV)系统的发展奠定了基础，并强调了高效资源管理的重要性。&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Enhanced MAX-SINR的多连接管理方法，以促进区块链特定方法的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/IPCLab/V2XBlockchain&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The evolution of vehicle-to-everything (V2X) communication brings significantchallenges, such as data integrity and vulnerabilities stemming fromcentralized management. This paper presents an innovative integration ofdecentralized blockchain technology with V2X communication through amulti-layered architecture that combines the Simulation of Urban Mobility(SUMO) traffic simulator and the BlockSim blockchain simulator. In addition, asthe Social Internet of Vehicles (SIoV) emerges, efficient resource managementbecomes indispensable for ensuring seamless communication. We also propose areference multi-connectivity management method named Enhanced MAX-SINR,designed to advance research in blockchain-specific approaches, taking intoaccount retransmission successfull rates. We evaluate blockchain performance indiverse environments such as urban, suburban, and rural areas, demonstratingthat enhancing the success rate of retransmitted blockchain-related messagessignificantly boosts blockchain transaction performance and provides afoundation for developing intelligent SIoV systems.</description>
      <author>example@mail.com (Yi-Ting Sun, Hsin-Chieh Lee, Yun-Chen Yu, Ting-Feng Wu, Ibrahim Althamary, Chih-Wei Huang)</author>
      <guid isPermaLink="false">2411.14000v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Protosolar D-to-H abundance and one part-per-billion PH$_{3}$ in the coldest brown dwarf</title>
      <link>http://arxiv.org/abs/2411.14541v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 7 figures, accepted to ApJ Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;最冷的Y型光谱类棕矮星与冷暖巨型系外行星在质量和温度上相似，温度约为200至400 K。&lt;h4&gt;目的&lt;/h4&gt;利用棕矮星的大气作为类行星大气的代理，测试对这些复杂、冷却世界物理和化学的理解。&lt;h4&gt;方法&lt;/h4&gt;通过JWST观察，使用高信噪比、中等分辨率的近红外和中红外光谱，对已知最冷的Y型矮星WISE 0855-0714进行大气检索。&lt;h4&gt;主要发现&lt;/h4&gt;首次在太阳系外检测到氘，测量了氘化甲烷（CH₃D）和标准甲烷的相对丰度，同时确定了亚恒星物体的D/H比率。还测定了磷烃（PH₃）的丰度为每十亿部分的量级。&lt;h4&gt;结论&lt;/h4&gt;这些结果对棕矮星和巨型系外行星的形成与演化有重要的启示。&lt;h4&gt;总结&lt;/h4&gt;通过JWST的高分辨率光谱，研究揭示了棕矮星大气的复杂性，为理解类行星的化学反应和演化提供了新证据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The coldest Y spectral type brown dwarfs are similar in mass and temperatureto cool and warm ($\sim$200 -- 400 K) giant exoplanets. We can therefore usetheir atmospheres as proxies for planetary atmospheres, testing ourunderstanding of physics and chemistry for these complex, cool worlds. At thesecold temperatures, their atmospheres are cold enough for water clouds to form,and chemical timescales increase, increasing the likelihood of disequilibriumchemistry compared to warmer classes of planets. JWST observations arerevolutionizing the characterization of these worlds with high signal-to-noise,moderate resolution near- and mid-infrared spectra. The spectra have been usedto measure the abundances of prominent species like water, methane, andammonia; species that trace chemical reactions like carbon monoxide; and evenisotopologues of carbon monoxide and ammonia. Here, we present atmosphericretrieval results using both published fixed-slit (GTO program 1230) and newaveraged time series observations (GO program 2327) of the coldest known Ydwarf, WISE 0855-0714 (using NIRSpec G395M spectra), which has an effectivetemperature of $\sim$ 264 K. We present a detection of deuterium in anatmosphere outside of the solar system via a relative measurement of deuteratedmethane (CH$_{3}$D) and standard methane. From this, we infer the D/H ratio ofa substellar object outside the solar system for the first time. We alsopresent a well-constrained part-per-billion abundance of phosphine (PH$_{3}$).We discuss our interpretation of these results and the implications for browndwarf and giant exoplanet formation and evolution.</description>
      <author>example@mail.com (Melanie J. Rowland, Caroline V. Morley, Brittany E. Miles, Genaro Suárez, Jacqueline K. Faherty, Andrew J. Skemer, Samuel A. Beiler, Michael R. Line, Gordon L. Bjoraker, Jonathan J. Fortney, Johanna M. Vos, Sherelyn Alejandro Merchan, Mark Marley, Ben Burningham, Richard Freedman, Ehsan Gharib-Nezhad, Natasha Batalha, Roxana Lupu, Channon Visscher, Adam C. Schneider, T. R. Geballe, Aarynn Carter, Katelyn Allers, James Mang, Dániel Apai, Mary Anne Limbach, Mikayla J. Wilson)</author>
      <guid isPermaLink="false">2411.14541v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>On the Boundary Feasibility for PDE Control with Neural Operators</title>
      <link>http://arxiv.org/abs/2411.15643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 5 figures, 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物理世界的动态通常由未知的偏微分方程（PDE）控制，这在科学和工程问题中普遍存在。&lt;h4&gt;目的&lt;/h4&gt;研究如何从理解PDE动态转向控制这些动态，并解决当前模型无关的PDE控制器在边界输出安全性方面的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出一种安全过滤框架，结合神经边界控制屏障函数（BCBF）确保边界输出满足用户指定的安全约束，并利用二次规划进行安全过滤。&lt;h4&gt;主要发现&lt;/h4&gt;在各种复杂的超曲线、抛物线和Navier-Stokes PDE动态环境下，所提出的方法在性能和边界约束满足方面优于模型无关控制器基线。&lt;h4&gt;结论&lt;/h4&gt;通过引入BCBF和安全过滤框架，可以有效保证边界输出的安全性，提升模型无关控制器的整体性能。&lt;h4&gt;总结&lt;/h4&gt;本研究为PDE边界控制问题提供了一种新的解决方案，确保了安全性并改善了控制效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The physical world dynamics are generally governed by underlying partialdifferential equations (PDEs) with unknown analytical forms in science andengineering problems. Neural network based data-driven approaches have beenheavily studied in simulating and solving PDE problems in recent years, but itis still challenging to move forward from understanding to controlling theunknown PDE dynamics. PDE boundary control instantiates a simplified butimportant problem by only focusing on PDE boundary conditions as the controlinput and output. However, current model-free PDE controllers cannot ensure theboundary output satisfies some given user-specified safety constraint. To thisend, we propose a safety filtering framework to guarantee the boundary outputstays within the safe set for current model-free controllers. Specifically, wefirst introduce a general neural boundary control barrier function (BCBF) toensure the feasibility of the trajectorywise constraint satisfaction ofboundary output. Based on a neural operator modeling the transfer function fromboundary control input to output trajectories, we show that the change in theBCBF depends linearly on the change in input boundary, so quadraticprogramming-based safety filtering can be done for pre-trained model-freecontrollers. Extensive experiments under challenging hyperbolic, parabolic andNavier-Stokes PDE dynamics environments validate the effectiveness of theproposed method in achieving better general performance and boundary constraintsatisfaction compared to the model-free controller baselines.</description>
      <author>example@mail.com (Hanjiang Hu, Changliu Liu)</author>
      <guid isPermaLink="false">2411.15643v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multiview Scene Graph</title>
      <link>http://arxiv.org/abs/2410.11187v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024. Website at https://ai4ce.github.io/MSG/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;场景表示在空间智能中至关重要，帮助代理有效重建和理解3D场景。&lt;h4&gt;目的&lt;/h4&gt;提出从未标定图像构建多视图场景图（MSG），以拓扑方式表示场景。&lt;h4&gt;方法&lt;/h4&gt;MSG构建任务需同时解决视觉位置识别、物体检测和物体关联，且面临视野有限和视角变化大的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;开发了一个MSG数据集及注释，并提出基于边的交并比评分的评估指标。&lt;h4&gt;结论&lt;/h4&gt;新提出的基线方法结合视觉位置识别和物体关联，基于主流预训练视觉模型，在实验中表现优于现有基线。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了MSG在场景拓扑表示中的有效性，为未来空间智能研究提供了新的方法和评估框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ai4ce/MSG&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A proper scene representation is central to the pursuit of spatialintelligence where agents can robustly reconstruct and efficiently understand3D scenes. A scene representation is either metric, such as landmark maps in 3Dreconstruction, 3D bounding boxes in object detection, or voxel grids inoccupancy prediction, or topological, such as pose graphs with loop closures inSLAM or visibility graphs in SfM. In this work, we propose to build MultiviewScene Graphs (MSG) from unposed images, representing a scene topologically withinterconnected place and object nodes. The task of building MSG is challengingfor existing representation learning methods since it needs to jointly addressboth visual place recognition, object detection, and object association fromimages with limited fields of view and potentially large viewpoint changes. Toevaluate any method tackling this task, we developed an MSG dataset andannotation based on a public 3D dataset. We also propose an evaluation metricbased on the intersection-over-union score of MSG edges. Moreover, we develop anovel baseline method built on mainstream pretrained vision models, combiningvisual place recognition and object association into one Transformer decoderarchitecture. Experiments demonstrate that our method has superior performancecompared to existing relevant baselines.</description>
      <author>example@mail.com (Juexiao Zhang, Gao Zhu, Sihang Li, Xinhao Liu, Haorui Song, Xinran Tang, Chen Feng)</author>
      <guid isPermaLink="false">2410.11187v3</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Complexity synchronization analysis of neurophysiological data: Theory and methods</title>
      <link>http://arxiv.org/abs/2411.14602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;应用改进的扩散熵分析（MDEA）来评估ON时间序列（ONTS）的多重分形维度，并使用复杂性同步（CS）分析推断网络中ON之间的信息传递。&lt;h4&gt;目的&lt;/h4&gt;推进MDEA和CS分析在异质神经生理时间序列数据中的验证、标准化和可重复性。&lt;h4&gt;方法&lt;/h4&gt;对数据集进行处理，使用MDEA和CS分析。&lt;h4&gt;主要发现&lt;/h4&gt;在认知任务执行过程中，大脑、心脏和肺部的ONTS的复杂性显著随时间共同变化。&lt;h4&gt;结论&lt;/h4&gt;在应用MDEA分析时，需要考虑某些原则、指南和策略。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了MDEA和CS分析在多种生理系统中信息传递研究中的重要性和复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We apply modified diffusion entropy analysis (MDEA) to assess multifractaldimensions of ON time series (ONTS) and complexity synchronization (CS)analysis to infer information transfer among ONs that are part of a network oforgan networks (NoONs). The purpose of this paper is to advance the validation,standardization, and repeatability of MDEA and CS analysis of heterogeneousneurophysiological time series data. Results from processing these datasetsshow that the complexity of brain, heart, and lung ONTS significantly co-varyover time during cognitive task performance but that certain principles,guidelines, and strategies for the application of MDEA analysis needconsideration.</description>
      <author>example@mail.com (Ioannis Schizas, Sabrina Sullivan, Scott E. Kerick, Korosh Mahmoodi, J. Cortney Bradford, David L. Boothe, Piotr J. Franaszczuk, Paolo Grigolini, Bruce J. West)</author>
      <guid isPermaLink="false">2411.14602v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Model Predictive Trees: Sample-Efficient Receding Horizon Planning with Reusable Tree Search</title>
      <link>http://arxiv.org/abs/2411.15651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 2024 IEEE/RSJ International Conference on
  Intelligent Robots and Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新的算法，模型预测树（MPT），用于改进树搜索算法的性能。&lt;h4&gt;目的&lt;/h4&gt;通过有效重用信息，提高算法的表现。&lt;h4&gt;方法&lt;/h4&gt;与现有求解器不同，本方法重用整个最优子树，而不仅仅是最高质量的轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;通过分析时间变化动态下的跟踪误差，揭示了搜索深度与动态变化时间尺度之间的权衡。&lt;h4&gt;结论&lt;/h4&gt;在数值研究中，该算法优于基于采样的最新交叉熵方法，并成功应用于自主车辆的非抓取操作任务。&lt;h4&gt;总结&lt;/h4&gt;代码将发布在 https://github.com/jplathrop/mpt，方便其他研究者使用和验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Model Predictive Trees (MPT), a receding horizon tree searchalgorithm that improves its performance by reusing information efficiently.Whereas existing solvers reuse only the highest-quality trajectory from theprevious iteration as a "hotstart", our method reuses the entire optimalsubtree, enabling the search to be simultaneously guided away from thelow-quality areas and towards the high-quality areas. We characterize therestrictions on tree reuse by analyzing the induced tracking error undertime-varying dynamics, revealing a tradeoff between the search depth and thetimescale of the changing dynamics. In numerical studies, our algorithmoutperforms state-of-the-art sampling-based cross-entropy methods withhotstarting. We demonstrate our planner on an autonomous vehicle testbedperforming a nonprehensile manipulation task: pushing a target object throughan obstacle field. Code associated with this work will be made available athttps://github.com/jplathrop/mpt.</description>
      <author>example@mail.com (John Lathrop, Benjamin Rivi`ere, Jedidiah Alindogan, Soon-Jo Chung)</author>
      <guid isPermaLink="false">2411.15651v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Modelling Loss of Complexity in Intermittent Time Series and its Application</title>
      <link>http://arxiv.org/abs/2411.14635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  44 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文研究间歇性时间序列复杂性丧失的建模方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种非参数相对熵（RlEn）来建模间歇性时间序列的复杂性变化。&lt;h4&gt;方法&lt;/h4&gt;采用两步法：首先，通过贝叶斯信息准则（BIC）确定滞后阶数的非线性自回归模型，并利用新颖的相对熵计算复杂性；其次，使用累积和（CUSUM）方法检测复杂性中的变点。&lt;h4&gt;主要发现&lt;/h4&gt;RlEn在定位间歇性时间序列复杂性变点和准确估计潜在非线性模型方面表现良好，优于流行的适当熵（ApEN）方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在分析人类运动输出的疲劳引起的复杂性变化时表现出色，能够准确检测间歇性时间序列片段中的复杂性变化。&lt;h4&gt;总结&lt;/h4&gt;RlEn方法在间歇性时间序列分析中具有优越性，提供了一种有效的复杂性变化检测工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we developed a nonparametric relative entropy (RlEn) formodelling loss of complexity in intermittent time series. This techniqueconsists of two steps. First, we carry out a nonlinear autoregressive modelwhere the lag order is determined by a Bayesian Information Criterion (BIC),and complexity of each intermittent time series is obtained by our novelrelative entropy. Second, change-points in complexity were detected by usingthe cumulative sum (CUSUM) based method. Using simulations and compared to thepopular method appropriate entropy (ApEN), the performance of RlEn was assessedfor its (1) ability to localise complexity change-points in intermittent timeseries; (2) ability to faithfully estimate underlying nonlinear models. Theperformance of the proposal was then examined in a real analysis offatigue-induced changes in the complexity of human motor outputs. The resultsdemonstrated that the proposed method outperformed the ApEn in accuratelydetecting complexity changes in intermittent time series segments.</description>
      <author>example@mail.com (Jie Li, Jian Zhang, Samantha L. Winter, Mark Burnley)</author>
      <guid isPermaLink="false">2411.14635v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>REFOL: Resource-Efficient Federated Online Learning for Traffic Flow Forecasting</title>
      <link>http://arxiv.org/abs/2411.14046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多种联邦学习方法被提出用于交通流预测，以避免集中方法中数据泄露和传输负担的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法以提高交通流预测的性能，尤其是在概念漂移发生时。&lt;h4&gt;方法&lt;/h4&gt;提出了资源高效的联邦在线学习（REFOL）方法，设计了基于数据的客户端参与机制、适应性在线优化策略和图卷积模型聚合机制。&lt;h4&gt;主要发现&lt;/h4&gt;REFOL能够有效检测概念漂移，减少计算和通信开销，同时保持预测性能。&lt;h4&gt;结论&lt;/h4&gt;REFOL在资源利用和预测改进方面优于现有方法，通过在真实世界数据集上的广泛实验验证了其优越性。&lt;h4&gt;总结&lt;/h4&gt;REFOL是一种高效的联邦在线学习方法，适用于交通流预测，能够应对概念漂移带来的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yuppielqx/refol&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiple federated learning (FL) methods are proposed for traffic flowforecasting (TFF) to avoid heavy-transmission and privacy-leaking concernsresulting from the disclosure of raw data in centralized methods. However,these FL methods adopt offline learning which may yield subpar performance,when concept drift occurs, i.e., distributions of historical and future datavary. Online learning can detect concept drift during model training, thus moreapplicable to TFF. Nevertheless, the existing federated online learning methodfor TFF fails to efficiently solve the concept drift problem and causestremendous computing and communication overhead. Therefore, we propose a novelmethod named Resource-Efficient Federated Online Learning (REFOL) for TFF,which guarantees prediction performance in a communication-lightweight andcomputation-efficient way. Specifically, we design a data-driven clientparticipation mechanism to detect the occurrence of concept drift and determineclients' participation necessity. Subsequently, we propose an adaptive onlineoptimization strategy, which guarantees prediction performance and meanwhileavoids meaningless model updates. Then, a graph convolution-based modelaggregation mechanism is designed, aiming to assess participants' contributionbased on spatial correlation without importing extra communication andcomputing consumption on clients. Finally, we conduct extensive experiments onreal-world datasets to demonstrate the superiority of REFOL in terms ofprediction improvement and resource economization.</description>
      <author>example@mail.com (Qingxiang Liu, Sheng Sun, Yuxuan Liang, Xiaolong Xu, Min Liu, Muhammad Bilal, Yuwei Wang, Xujing Li, Yu Zheng)</author>
      <guid isPermaLink="false">2411.14046v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Robustifying Long-term Human-Robot Collaboration through a Hierarchical and Multimodal Framework</title>
      <link>http://arxiv.org/abs/2411.15711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;长期人机协作（HRC）对灵活制造系统的发展及伴侣机器人在日常人类环境中的整合至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决人机协作中面临的挑战，如准确理解人类意图、在嘈杂和动态环境中保持鲁棒性，以及适应多样的用户行为。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的多模态和层次化框架，整合视觉观察与语音指令，以促进人类与机器人之间直观、自然和灵活的互动。&lt;h4&gt;主要发现&lt;/h4&gt;该层次化的人体检测和意图预测方法显著增强了系统的鲁棒性，使机器人能够更好地理解人类行为，及时采取适当行动。&lt;h4&gt;结论&lt;/h4&gt;在KINOVA GEN3机器人上部署的多模态层次化框架，通过实际的长期HRC实验，证明了该方法有效提高了系统的效率、灵活性和适应性，展示了该框架在改善人机协作方式方面的潜力。&lt;h4&gt;总结&lt;/h4&gt;该研究为长期人机协作提供了一种有效的解决方案，促进了人类与机器人之间的协同工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-term Human-Robot Collaboration (HRC) is crucial for developing flexiblemanufacturing systems and for integrating companion robots into daily humanenvironments over extended periods. However, sustaining such collaborationsrequires overcoming challenges such as accurately understanding humanintentions, maintaining robustness in noisy and dynamic environments, andadapting to diverse user behaviors. This paper presents a novel multimodal andhierarchical framework to address these challenges, facilitating efficient androbust long-term HRC. In particular, the proposed multimodal frameworkintegrates visual observations with speech commands, which enables intuitive,natural, and flexible interactions between humans and robots. Additionally, ourhierarchical approach for human detection and intention predictionsignificantly enhances the system's robustness, allowing robots to betterunderstand human behaviors. The proactive understanding enables robots to taketimely and appropriate actions based on predicted human intentions. We deploythe proposed multimodal hierarchical framework to the KINOVA GEN3 robot andconduct extensive user studies on real-world long-term HRC experiments. Theresults demonstrate that our approach effectively improves the systemefficiency, flexibility, and adaptability in long-term HRC, showcasing theframework's potential to significantly improve the way humans and robots worktogether.</description>
      <author>example@mail.com (Peiqi Yu, Abulikemu Abuduweili, Ruixuan Liu, Changliu Liu)</author>
      <guid isPermaLink="false">2411.15711v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Detecting Distributed Denial of Service Attacks Using Logistic Regression and SVM Methods</title>
      <link>http://arxiv.org/abs/2411.14512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;分布式拒绝服务（DDoS）攻击试图通过不断向目标服务器或其邻近基础设施发送大量服务请求，造成网络流量洪水，这些请求来自多个远程控制的恶意软件感染计算机或联网设备。&lt;h4&gt;目的&lt;/h4&gt;检测DDoS攻击并根据DDoS类别对其进行分类，特别关注在线业务的网络安全问题。&lt;h4&gt;方法&lt;/h4&gt;从互联网收集标准数据集，包含多个网络相关属性及其对应的DDoS攻击类别，采用支持向量机（SVM）和逻辑回归两种机器学习方法进行检测和分类，并进行准确性、精确度和召回率的比较研究。&lt;h4&gt;主要发现&lt;/h4&gt;逻辑回归和支持向量机均实现了98.65%的分类准确率，这是与相同数据集进行的其他实验中取得的最高准确率。&lt;h4&gt;结论&lt;/h4&gt;SVM和逻辑回归在DDoS攻击检测和分类上表现优异，能够有效区分正常流量和DDoS攻击流量。&lt;h4&gt;总结&lt;/h4&gt;本研究为网络安全提供了有效的DDoS攻击检测和分类方法，推动了在线业务的安全防护措施。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A distributed denial-of-service (DDoS) attack is an attempt to producehumongous traffic within a network by overwhelming a targeted server or itsneighboring infrastructure with a flood of service requests ceaselessly comingfrom multiple remotely controlled malware-infected computers ornetwork-connected devices. Thus, exploring DDoS attacks by recognizing theirfunctionalities and differentiating them from normal traffic services are theprimary concerns of network security issues particularly for online businesses.In modern networks, most DDoS attacks occur in the network and applicationlayer including HTTP flood, UDP flood, SIDDOS, SMURF, SNMP flood, IP NULL, etc.The goal of this paper is to detect DDoS attacks from all service requests andclassify them according to DDoS classes. In this regard, a standard dataset iscollected from the internet which contains several network-related attributesand their corresponding DDoS attack class name. Two(2) different machinelearning approaches, SVM and Logistic Regression, are implemented in thedataset for detecting and classifying DDoS attacks, and a comparative study isaccomplished among them in terms of accuracy, precision, and recall rates.Logistic Regression and SVM both achieve 98.65% classification accuracy whichis the highest achieved accuracy among other previous experiments with the samedataset.</description>
      <author>example@mail.com (Mohammad Arafat Ullah, Arthy Anjum, Rashedul Amin Tuhin, Shamim Akhter)</author>
      <guid isPermaLink="false">2411.14512v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Recursive Gaussian Process State Space Model</title>
      <link>http://arxiv.org/abs/2411.14679v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;学习动态模型对于原理发现、时间序列预测和控制器设计至关重要，且具有重要前景。&lt;h4&gt;目的&lt;/h4&gt;针对在线学习中缺乏高效方法的问题，提出一种适用于数据分布和模型函数先验信息有限的场景的递归GPSSM方法。&lt;h4&gt;方法&lt;/h4&gt;通过一阶线性化推导系统状态与GP模型的联合分布的贝叶斯更新方程，开发基于信息标准的诱导点在线选择算法，并恢复历史测量信息以支持在线超参数优化。&lt;h4&gt;主要发现&lt;/h4&gt;在合成和真实世界数据集上的综合评估显示，该方法在准确性、计算效率和适应性上优于现有的在线GPSSM技术。&lt;h4&gt;结论&lt;/h4&gt;提出的递归GPSSM方法在在线学习场景中表现出色，具备灵活性和可解释性。&lt;h4&gt;总结&lt;/h4&gt;本文的方法为动态模型在线学习提供了一种有效的新方案，适应性强，具有广泛应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhidilin/gpssmproj&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning dynamical models from data is not only fundamental but also holdsgreat promise for advancing principle discovery, time-series prediction, andcontroller design. Among various approaches, Gaussian Process State-SpaceModels (GPSSMs) have recently gained significant attention due to theircombination of flexibility and interpretability. However, for online learning,the field lacks an efficient method suitable for scenarios where priorinformation regarding data distribution and model function is limited. Toaddress this issue, this paper proposes a recursive GPSSM method with adaptivecapabilities for both operating domains and Gaussian process (GP)hyperparameters. Specifically, we first utilize first-order linearization toderive a Bayesian update equation for the joint distribution between the systemstate and the GP model, enabling closed-form and domain-independent learning.Second, an online selection algorithm for inducing points is developed based oninformative criteria to achieve lightweight learning. Third, to support onlinehyperparameter optimization, we recover historical measurement information fromthe current filtering distribution. Comprehensive evaluations on both syntheticand real-world datasets demonstrate the superior accuracy, computationalefficiency, and adaptability of our method compared to state-of-the-art onlineGPSSM techniques.</description>
      <author>example@mail.com (Tengjie Zheng, Lin Cheng, Shengping Gong, Xu Huang)</author>
      <guid isPermaLink="false">2411.14679v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>PEnG: Pose-Enhanced Geo-Localisation</title>
      <link>http://arxiv.org/abs/2411.15742v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;跨视图地理定位通常在粗粒度上进行，因为密集采样的卫星图像补丁重叠严重，这使得补丁的歧义性很难解决。&lt;h4&gt;目的&lt;/h4&gt;解决稀疏采样补丁造成的定位精度上限问题，提高实际应用的定位精度。&lt;h4&gt;方法&lt;/h4&gt;提出一种名为PEnG的两阶段系统，首先预测查询图像所在城市规模图的最可能边缘，然后在这些边缘内进行相对姿态估计以确定精确位置。&lt;h4&gt;主要发现&lt;/h4&gt;PEnG是首个利用跨视图地理定位数据集中两个视角来增强精度的方法，达到亚米级精度，部分示例实现厘米级精度。&lt;h4&gt;结论&lt;/h4&gt;所提出的集成方法在精度上达到了最先进的水平，相对Top-5m检索相比之前的工作提高了213%，中位欧几里得距离误差从734米减少到22.77米。&lt;h4&gt;总结&lt;/h4&gt;PEnG系统通过结合跨视图定位和姿态估计，显著提升了地理定位的精度，代码将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-view Geo-localisation is typically performed at a coarse granularity,because densely sampled satellite image patches overlap heavily. This heavyoverlap would make disambiguating patches very challenging. However, by optingfor sparsely sampled patches, prior work has placed an artificial upper boundon the localisation accuracy that is possible. Even a perfect oracle systemcannot achieve accuracy greater than the average separation of the tiles. Tosolve this limitation, we propose combining cross-view geo-localisation andrelative pose estimation to increase precision to a level practical forreal-world application. We develop PEnG, a 2-stage system which first predictsthe most likely edges from a city-scale graph representation upon which a queryimage lies. It then performs relative pose estimation within these edges todetermine a precise position. PEnG presents the first technique to utilise bothviewpoints available within cross-view geo-localisation datasets to enhanceprecision to a sub-metre level, with some examples achieving centimetre levelaccuracy. Our proposed ensemble achieves state-of-the-art precision - withrelative Top-5m retrieval improvements on previous works of 213%. Decreasingthe median euclidean distance error by 96.90% from the previous best of 734mdown to 22.77m, when evaluating with 90 degree horizontal FOV images. Code willbe made available: tavisshore.co.uk/PEnG</description>
      <author>example@mail.com (Tavis Shore, Oscar Mendez, Simon Hadfield)</author>
      <guid isPermaLink="false">2411.15742v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Generalizing End-To-End Autonomous Driving In Real-World Environments Using Zero-Shot LLMs</title>
      <link>http://arxiv.org/abs/2411.14256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的自动驾驶方法采用模块化设计，将任务分解为子任务，而端到端的自动驾驶模型直接从原始传感器数据输出动作，避免了误差累积。&lt;h4&gt;目的&lt;/h4&gt;提高端到端自动驾驶模型的泛化能力，解决训练数据不足的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种高效架构，将多模态大语言模型（LLMs）整合到在真实环境中操作的端到端驾驶模型中，采用闭环设置。&lt;h4&gt;主要发现&lt;/h4&gt;该架构使LLM定期处理原始传感器数据，生成高层驾驶指令，从而有效引导端到端模型，即使处理速度慢于原始传感器数据。&lt;h4&gt;结论&lt;/h4&gt;该架构在不调整LLM的情况下增强了端到端模型的泛化能力，减少了数据收集的需求，只需训练简单的模仿学习模型输出动作。&lt;h4&gt;总结&lt;/h4&gt;实验表明，即使在复杂的测试环境中，该架构也能提升端到端模型的性能，证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional autonomous driving methods adopt a modular design, decomposingtasks into sub-tasks. In contrast, end-to-end autonomous driving directlyoutputs actions from raw sensor data, avoiding error accumulation. However,training an end-to-end model requires a comprehensive dataset; otherwise, themodel exhibits poor generalization capabilities. Recently, large languagemodels (LLMs) have been applied to enhance the generalization capabilities ofend-to-end driving models. Most studies explore LLMs in an open-loop manner,where the output actions are compared to those of experts without directfeedback from the real world, while others examine closed-loop results only insimulations. This paper proposes an efficient architecture that integratesmultimodal LLMs into end-to-end driving models operating in closed-loopsettings in real-world environments. In our architecture, the LLM periodicallyprocesses raw sensor data to generate high-level driving instructions,effectively guiding the end-to-end model, even at a slower rate than the rawsensor data. This architecture relaxes the trade-off between the latency andinference quality of the LLM. It also allows us to choose from a wide varietyof LLMs to improve high-level driving instructions and minimize fine-tuningcosts. Consequently, our architecture reduces data collection requirementsbecause the LLMs do not directly output actions; we only need to train a simpleimitation learning model to output actions. In our experiments, the trainingdata for the end-to-end model in a real-world environment consists of onlysimple obstacle configurations with one traffic cone, while the testenvironment is more complex and contains multiple obstacles placed in variouspositions. Experiments show that the proposed architecture enhances thegeneralization capabilities of the end-to-end model even without fine-tuningthe LLM.</description>
      <author>example@mail.com (Zeyu Dong, Yimin Zhu, Yansong Li, Kevin Mahon, Yu Sun)</author>
      <guid isPermaLink="false">2411.14256v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Unified Energy Management Framework for Multi-Timescale Forecasting in Smart Grids</title>
      <link>http://arxiv.org/abs/2411.15254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to PES GM 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确预测电力负荷（如峰值功率的大小和时机）对电力系统管理和智能电网策略的实施至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种多尺度电力负荷预测框架，以捕捉时间序列数据中的中长期依赖性。&lt;h4&gt;方法&lt;/h4&gt;提出Multi-pofo框架，采用新颖的架构和时间位置编码层来实现多尺度预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在真实电力负荷数据上的表现优于多个强基线方法。&lt;h4&gt;结论&lt;/h4&gt;Multi-pofo框架有效提升了电力负荷预测的准确性，能够更好地支持电力系统的管理。&lt;h4&gt;总结&lt;/h4&gt;本研究为多时间尺度优化调度提供了一种新的解决方案，能有效应对电力负荷预测中的复杂依赖性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate forecasting of the electrical load, such as the magnitude and thetiming of peak power, is crucial to successful power system management andimplementation of smart grid strategies like demand response and peak shaving.In multi-time-scale optimization scheduling, rolling optimization is a commonsolution. However, rolling optimization needs to consider the coupling ofdifferent optimization objectives across time scales. It is challenging toaccurately capture the mid- and long-term dependencies in time series data.This paper proposes Multi-pofo, a multi-scale power load forecasting framework,that captures such dependency via a novel architecture equipped with a temporalpositional encoding layer. To validate the effectiveness of the proposed model,we conduct experiments on real-world electricity load data. The experimentalresults show that our approach outperforms compared to several strong baselinemethods.</description>
      <author>example@mail.com (Dafang Zhao, Xihao Piao, Zheng Chen, Zhengmao Li, Ittetsu Taniguchi)</author>
      <guid isPermaLink="false">2411.15254v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>The importance of the clustering model to detect new types of intrusion in data traffic</title>
      <link>http://arxiv.org/abs/2411.14550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前数字时代，由于网络活动生成的数据量巨大且持续增加，这些数据可能包含有价值的见解，有助于改善网络安全措施。&lt;h4&gt;目的&lt;/h4&gt;利用聚类方法识别数据中的隐藏模式，以便更好地识别和应对网络威胁。&lt;h4&gt;方法&lt;/h4&gt;采用K-means算法对数据进行聚类，数据来源包括Kali Linux环境、cicflowmeter流量和Putty软件工具，通过多种简单攻击收集数据，并在Kaggle仓库中的现成数据上进行相同的工作。&lt;h4&gt;主要发现&lt;/h4&gt;K-means算法能够有效识别新型攻击类型，并为每种攻击分配编号，在Kaggle的现成数据中也成功检测到攻击数量。&lt;h4&gt;结论&lt;/h4&gt;该方法有助于识别和标记动态网络威胁中的新攻击类型，尽管这些攻击类型可能尚无标记数据可供参考。&lt;h4&gt;总结&lt;/h4&gt;聚类分析在网络安全数据处理中具有重要意义，有助于动态应对新兴威胁。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the current digital age, the volume of data generated by various cyberactivities has become enormous and is constantly increasing. The data maycontain valuable insights that can be harnessed to improve cyber securitymeasures. However, much of this data is unclassified and qualitative, whichposes significant challenges to traditional analysis methods. Clusteringfacilitates the identification of hidden patterns and structures in datathrough grouping similar data points, which makes it simpler to identify andaddress threats. Clustering can be defined as a data mining (DM) approach,which uses similarity calculations for dividing a data set into severalcategories. Hierarchical, density-based, along with partitioning clusteringalgorithms are typical. The presented work use K-means algorithm, which is apopular clustering technique. Utilizing K-means algorithm, we worked with twodifferent types of data: first, we gathered data with the use of XG-boostalgorithm following completing the aggregation with K-means algorithm. Data wasgathered utilizing Kali Linux environment, cicflowmeter traffic, and PuttySoftware tools with the use of diverse and simple attacks. The concept couldassist in identifying new attack types, which are distinct from the knownattacks, and labeling them based on the characteristics they will exhibit, asthe dynamic nature regarding cyber threats means that new attack types oftenemerge, for which labeled data might not yet exist. The model counted theattacks and assigned numbers to each one of them. Secondly, We tried the samework on the ready data inside the Kaggle repository called (Intrusion Detectionin Internet of Things Network), and the clustering model worked well anddetected the number of attacks correctly as shown in the results section.</description>
      <author>example@mail.com (Noor Saud Abd, Kamel Karoui)</author>
      <guid isPermaLink="false">2411.14550v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>FoAR: Force-Aware Reactive Policy for Contact-Rich Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2411.15753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;接触丰富的任务对机器人操控策略提出了重大挑战，尤其是在接触动力学复杂和需要精确控制的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出FoAR，一种结合高频力/扭矩传感与视觉输入的反应式策略，以提高在接触丰富操控中的表现。&lt;h4&gt;方法&lt;/h4&gt;FoAR在RISE策略基础上，使用多模态特征融合机制，并借助未来接触预测器动态调整力/扭矩数据的使用。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，FoAR在各种具有挑战性的接触丰富任务中显著优于所有基线，并在意外动态干扰下保持稳健表现。&lt;h4&gt;结论&lt;/h4&gt;FoAR能够通过简单的位置控制准确完成接触丰富的任务，展示出其有效性和适应性。&lt;h4&gt;总结&lt;/h4&gt;FoAR策略的提出为解决机器人在复杂接触任务中的操控问题提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contact-rich tasks present significant challenges for robotic manipulationpolicies due to the complex dynamics of contact and the need for precisecontrol. Vision-based policies often struggle with the skill required for suchtasks, as they typically lack critical contact feedback modalities likeforce/torque information. To address this issue, we propose FoAR, a force-awarereactive policy that combines high-frequency force/torque sensing with visualinputs to enhance the performance in contact-rich manipulation. Built upon theRISE policy, FoAR incorporates a multimodal feature fusion mechanism guided bya future contact predictor, enabling dynamic adjustment of force/torque datausage between non-contact and contact phases. Its reactive control strategyalso allows FoAR to accomplish contact-rich tasks accurately through simpleposition control. Experimental results demonstrate that FoAR significantlyoutperforms all baselines across various challenging contact-rich tasks whilemaintaining robust performance under unexpected dynamic disturbances. Projectwebsite: https://tonyfang.net/FoAR/</description>
      <author>example@mail.com (Zihao He, Hongjie Fang, Jingjing Chen, Hao-Shu Fang, Cewu Lu)</author>
      <guid isPermaLink="false">2411.15753v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Kolmogorov-Arnold Networks for Interpretable Time Series Classification</title>
      <link>http://arxiv.org/abs/2411.14904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列分类在各个领域的决策过程中至关重要，深度神经网络在这一领域表现出良好的性能，但对复杂架构的理论理解仍然有限，亟需更具可解释性的模型。&lt;h4&gt;目的&lt;/h4&gt;全面探索Kolmogorov-Arnold网络（KAN）在时间序列分类中的应用，特别是在UCR基准测试上的表现。&lt;h4&gt;方法&lt;/h4&gt;研究KAN架构在时间序列分类中的参考架构迁移，超参数和实现对分类性能的影响，复杂性权衡及可解释性优势。&lt;h4&gt;主要发现&lt;/h4&gt;{'发现1': '高效KAN在性能和计算效率上优于多层感知器（MLP），适合分类任务。', '发现2': '高效KAN在不同网格大小、深度和层配置下比KAN更稳定，尤其是在较低学习率下。', '发现3': 'KAN在准确性上与HIVE-COTE2等最先进模型竞争，具有更小的架构和更快的训练时间，表现出性能和透明性的平衡。', '发现4': 'KAN模型的可解释性与SHAP分析的结果一致，增强了其透明决策能力。'}&lt;h4&gt;结论&lt;/h4&gt;高效KAN模型在时间序列分类中表现出色，兼具性能和可解释性，为透明决策提供了支持。&lt;h4&gt;总结&lt;/h4&gt;本文对KAN架构进行了系统的研究，发现其在时间序列分类中具有明显优势，尤其是在效率和可解释性方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series classification is a relevant step supporting decision-makingprocesses in various domains, and deep neural models have shown promisingperformance.  Despite significant advancements in deep learning, the theoreticalunderstanding of how and why complex architectures function remains limited,prompting the need for more interpretable models. Recently, theKolmogorov-Arnold Networks (KANs) have been proposed as a more interpretablealternative. While KAN-related research is significantly rising, to date, thestudy of KAN architectures for time series classification has been limited.  In this paper, we aim to conduct a comprehensive and robust exploration ofthe KAN architecture for time series classification on the UCR benchmark. Morespecifically, we look at a) how reference architectures for forecastingtransfer to classification, at the b) hyperparameter and implementationinfluence on the classification performance in view of finding the one thatperforms best on the selected benchmark, the c) complexity trade-offs and d)interpretability advantages. Our results show that (1) Efficient KANoutperforms MLP in performance and computational efficiency, showcasing itssuitability for tasks classification tasks. (2) Efficient KAN is more stablethan KAN across grid sizes, depths, and layer configurations, particularly withlower learning rates. (3) KAN maintains competitive accuracy compared tostate-of-the-art models like HIVE-COTE2, with smaller architectures and fastertraining times, supporting its balance of performance and transparency. (4) Theinterpretability of the KAN model aligns with findings from SHAP analysis,reinforcing its capacity for transparent decision-making.</description>
      <author>example@mail.com (Irina Barašin, Blaž Bertalanič, Miha Mohorčič, Carolina Fortuna)</author>
      <guid isPermaLink="false">2411.14904v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Systematic Study of Multi-Agent Deep Reinforcement Learning for Safe and Robust Autonomous Highway Ramp Entry</title>
      <link>http://arxiv.org/abs/2411.14593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;目前，车辆已能在高速公路上自主驾驶，且无人驾驶出租车在主要城市中运营，但完全自主的“5级”操作尚未实现。&lt;h4&gt;目的&lt;/h4&gt;研究高速公路匝道功能，控制车辆前进行为，以最小化与高速公路交通流的碰撞。&lt;h4&gt;方法&lt;/h4&gt;采用博弈论多智能体（MA）方法，利用深度强化学习（DRL）控制器进行研究，虚拟环境中通过自我对弈模拟数据进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟的渐缩匝道合并中，合并车辆能够安全地学习控制纵向位置。扩展研究涉及多个车辆的交互，增加了交通和自我车辆的复杂性。&lt;h4&gt;结论&lt;/h4&gt;虽然以往研究表明，在完全分散、非协调的环境中实现无碰撞控制器在理论上是不可能的，但我们的实验结果表明，使用我们方法学习的控制器在理想化的最优控制器标准下表现接近理想。&lt;h4&gt;总结&lt;/h4&gt;研究展示了在复杂交通场景中，深度强化学习可以有效地提升车辆的自主合并能力，推动完全自主驾驶的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicles today can drive themselves on highways and driverless robotaxisoperate in major cities, with more sophisticated levels of autonomous drivingexpected to be available and become more common in the future. Yet, technicallyspeaking, so-called "Level 5" (L5) operation, corresponding to full autonomy,has not been achieved. For that to happen, functions such as fully autonomoushighway ramp entry must be available, and provide provably safe, and reliablyrobust behavior to enable full autonomy. We present a systematic study of ahighway ramp function that controls the vehicles forward-moving actions tominimize collisions with the stream of highway traffic into which a merging(ego) vehicle enters. We take a game-theoretic multi-agent (MA) approach tothis problem and study the use of controllers based on deep reinforcementlearning (DRL). The virtual environment of the MA DRL uses self-play withsimulated data where merging vehicles safely learn to control longitudinalposition during a taper-type merge. The work presented in this paper extendsexisting work by studying the interaction of more than two vehicles (agents)and does so by systematically expanding the road scene with additional trafficand ego vehicles. While previous work on the two-vehicle setting establishedthat collision-free controllers are theoretically impossible in fullydecentralized, non-coordinated environments, we empirically show thatcontrollers learned using our approach are nearly ideal when measured againstidealized optimal controllers.</description>
      <author>example@mail.com (Larry Schester, Luis E. Ortiz)</author>
      <guid isPermaLink="false">2411.14593v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Radii, masses, and transit-timing variations of the three-planet system orbiting the naked-eye star TOI-396</title>
      <link>http://arxiv.org/abs/2411.14911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages (6 in the Appendix), 15 Figures (2 in the Appendix), 10
  Tables (5 in the Appendix). Accepted for publication in A&amp;A&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;TOI-396是一颗F6V型恒星，视星等约为6.4，周围有三颗过境行星。&lt;h4&gt;目的&lt;/h4&gt;测量三颗行星的质量，精确其半径，并调查行星b和c是否处于共振状态。&lt;h4&gt;方法&lt;/h4&gt;进行了HARPS径向速度（RV）观测，并从TESS获取了光度数据。通过对HARPS CCF进行偏态正态拟合提取RV，实施MCMC联合分析，同时使用断点法去除RV时间序列中的恒星活动影响。还进行了系统的TTV动态分析。&lt;h4&gt;主要发现&lt;/h4&gt;三颗行星的尺寸相似：R_b为2.004±0.047地球半径，R_c为1.979±0.051地球半径，R_d为2.001±0.064地球半径。首次确定了TOI-396b和d的RV质量，分别为3.55±0.96地球质量和7.1±1.6地球质量。TOI-396c引起的多普勒反射运动在RV时间序列中未被检测到，可能由于其周期接近恒星的自转周期。&lt;h4&gt;结论&lt;/h4&gt;TOI-396b和c显示出显著的TTV，虽然TTV动态分析为TOI-396c提供了准确的质量，但结果可能因TTV相位取样不足而不够准确。TOI-396b和c接近但未达到5:3共振。数值模拟表明，TTV半幅度可达5小时，时间基线约为5.2年。&lt;h4&gt;总结&lt;/h4&gt;TOI-396系统展现出不寻常的体系架构，最外层行星密度最高，且行星b和c的共振状态接近但未达到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; TOI-396 is an F6V star ($V\approx6.4$) orbited by three transiting planets.The orbital periods of the two innermost planets are close to the 5:3commensurability ($P_b \sim3.6$ d and $P_c \sim6.0$ d). To measure the massesof the three planets, refine their radii, and investigate whether planets b andc are in MMR, we carried out HARPS RV observations and retrieved photometricdata from TESS. We extracted the RVs via a skew-normal fit onto the HARPS CCFsand performed an MCMC joint analysis of the Doppler measurements and transitphotometry, while employing the breakpoint method to remove stellar activityfrom the RV time series. We also performed a thorough TTV dynamical analysis ofthe system. Our analysis confirms that the three planets have similar sizes:$R_b=2.004_{-0.047}^{+0.045}R_{\oplus}$;$R_c=1.979_{-0.051}^{+0.054}R_{\oplus}$;$R_d=2.001_{-0.064}^{+0.063}R_{\oplus}$. For the first time, we determine RVmasses for TOI-396b and d: $M_b=3.55_{-0.96}^{+0.94}M_{\oplus}$($\rho_b=2.44_{-0.68}^{+0.69}$ g cm$^{-3}$) and $M_d=7.1\pm1.6M_{\oplus}$($\rho_d=4.9_{-1.1}^{+1.2}$ g cm$^{-3}$). Our results suggest a quite unusualsystem architecture, with the outermost planet being the densest. The Dopplerreflex motion induced by TOI-396c remains undetected in our RV time series,likely due to the proximity of $P_c$ to the star's rotation period($P_{\mathrm{rot}}=6.7\pm1.3$ d). We also discovered that TOI-396b and cdisplay significant TTVs. While the TTV dynamical analysis returns a formallyprecise mass for TOI-396c($M_{c,\mathrm{dyn}}=2.24^{+0.13}_{-0.67}M_{\oplus}$), the result might not beaccurate owing to the poor sampling of the TTV phase. We also conclude thatTOI-396b and c are close to-, but out of- the 5:3 MMR. Our numerical simulationsuggests TTV semi-amplitudes of up to 5 hours over a temporal baseline of$\sim$5.2 years.</description>
      <author>example@mail.com (A. Bonfanti, I. Amateis, D. Gandolfi, L. Borsato, J. A. Egger, P. E. Cubillos, D. Armstrong, I. C. Leão, M. Fridlund, B. L. Canto Martins, S. G. Sousa, J. R. De Medeiros, L. Fossati, V. Adibekyan, A. Collier Cameron, S. Grziwa, K. W. F. Lam, E. Goffo, L. D. Nielsen, F. Rodler, J. Alarcon, J. Lillo-Box, W. D. Cochran, R. Luque, S. Redfield, N. C. Santos, S. C. C. Barros, D. Bayliss, X. Dumusque, M. A. F. Keniger, J. Livingston, F. Murgas, G. Nowak, A. Osborn, H. P. Osborn, E. Pallé, C. M. Persson, L. M. Serrano, P. A. Strøm, S. Udry, P. J. Wheatley)</author>
      <guid isPermaLink="false">2411.14911v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Optimal Transcoding Preset Selection for Live Video Streaming</title>
      <link>http://arxiv.org/abs/2411.14613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在数字环境中，视频内容主导互联网流量，强调高效视频处理的必要性，以支持YouTube Live、Twitch和Facebook Live等平台的流畅直播体验。&lt;h4&gt;目的&lt;/h4&gt;提出一个综合框架，优化视频转码参数，重点关注预设和比特率选择，以在遵循比特率和转码时间限制的情况下，最小化失真。&lt;h4&gt;方法&lt;/h4&gt;框架包括特征提取、预测和优化三个主要步骤，利用提取的特征预测转码时间和率失真，采用监督和无监督方法，通过整数线性规划确定视频片段的最佳预设和比特率顺序。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，该框架在提高直播视频质量方面有效，能够在设定约束下实现实时应用的可行性，使用用户生成内容数据集评估时，平均PSNR比默认Twitch配置提高1.5 dB。&lt;h4&gt;结论&lt;/h4&gt;优化方法满足视频传递的不断变化需求，提供实时转码优化的解决方案，后续实验显示BD-rate减少了49.60%，进一步强化了框架相对于Twitch默认配置的优越性能。&lt;h4&gt;总结&lt;/h4&gt;该框架有效提升了直播视频的质量，同时高效管理计算资源，展现出在动态视频传输中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In today's digital landscape, video content dominates internet traffic,underscoring the need for efficient video processing to support seamless livestreaming experiences on platforms like YouTube Live, Twitch, and FacebookLive. This paper introduces a comprehensive framework designed to optimizevideo transcoding parameters, with a specific focus on preset and bitrateselection to minimize distortion while respecting constraints on bitrate andtranscoding time. The framework comprises three main steps: feature extraction,prediction, and optimization. It leverages extracted features to predicttranscoding time and rate-distortion, employing both supervised andunsupervised methods. By utilizing integer linear programming, it identifiesthe optimal sequence of presets and bitrates for video segments, ensuringreal-time application feasibility under set constraints. The resultsdemonstrate the framework's effectiveness in enhancing video quality for livestreaming, maintaining high standards of video delivery while managingcomputational resources efficiently. This optimization approach meets theevolving demands of video delivery by offering a solution for real-timetranscoding optimization. Evaluation using the User Generated Content datasetshowed an average PSNR improvement of 1.5 dB over the default Twitchconfiguration, highlighting significant PSNR gains. Additionally, subsequentexperiments demonstrated a BD-rate reduction of -49.60%, reinforcing theframework's superior performance over Twitch's default configuration.</description>
      <author>example@mail.com (Zahra Nabizadeh, Maedeh Jamali, Nader Karimi, Shadrokh Samavi, Shahram Shirani)</author>
      <guid isPermaLink="false">2411.14613v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Bimanual Grasp Synthesis for Dexterous Robot Hands</title>
      <link>http://arxiv.org/abs/2411.15903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in RA-L 24', 8 pages, 9 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类自然地进行双手技能以处理大型和重物。&lt;h4&gt;目的&lt;/h4&gt;提升机器人物体操作能力，生成有效的双手抓取姿态。&lt;h4&gt;方法&lt;/h4&gt;提出BimanGrasp算法，通过优化考虑抓取稳定性和可行性的能量函数来合成双手抓取姿态，并使用Isaac Gym物理仿真引擎进行验证。&lt;h4&gt;主要发现&lt;/h4&gt;BimanGrasp算法合成的抓取姿态形成了BimanGrasp-Dataset，这是首个大规模合成的双手灵巧手抓取姿态数据集，包含超过15万个经过验证的抓取姿态和900个物体。&lt;h4&gt;结论&lt;/h4&gt;提出的BimanGrasp-DDPM扩散模型在BimanGrasp-Dataset上训练，抓取合成成功率达到69.87%，计算速度显著加快。&lt;h4&gt;总结&lt;/h4&gt;研究为双手抓取姿态合成提供了数据驱动的方法，并推动了机器人抓取能力的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2024.3490393&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans naturally perform bimanual skills to handle large and heavy objects.To enhance robots' object manipulation capabilities, generating effectivebimanual grasp poses is essential. Nevertheless, bimanual grasp synthesis fordexterous hand manipulators remains underexplored. To bridge this gap, wepropose the BimanGrasp algorithm for synthesizing bimanual grasps on 3Dobjects. The BimanGrasp algorithm generates grasp poses by optimizing an energyfunction that considers grasp stability and feasibility. Furthermore, thesynthesized grasps are verified using the Isaac Gym physics simulation engine.These verified grasp poses form the BimanGrasp-Dataset, the first large-scalesynthesized bimanual dexterous hand grasp pose dataset to our knowledge. Thedataset comprises over 150k verified grasps on 900 objects, facilitating thesynthesis of bimanual grasps through a data-driven approach. Last, we proposeBimanGrasp-DDPM, a diffusion model trained on the BimanGrasp-Dataset. Thismodel achieved a grasp synthesis success rate of 69.87\% and significantacceleration in computational speed compared to BimanGrasp algorithm.</description>
      <author>example@mail.com (Yanming Shao, Chenxi Xiao)</author>
      <guid isPermaLink="false">2411.15903v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Robot Scan-n-Print for Wire Arc Additive Manufacturing</title>
      <link>http://arxiv.org/abs/2411.15915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人线弧增材制造（WAAM）是一种金属增材制造技术，提供灵活的3D打印，同时确保高质量的近净型最终零件。&lt;h4&gt;目的&lt;/h4&gt;提出一个多机器人框架，用于WAAM过程的监控和控制。&lt;h4&gt;方法&lt;/h4&gt;采用三机器人设置，包括一个6自由度焊接机器人、一个2自由度转台和一个6自由度传感机器人，后者配备激光线扫描仪用于测量打印件的高度轮廓。&lt;h4&gt;主要发现&lt;/h4&gt;通过闭环扫描-打印方法，相比现有的开环结果，在平面墙和复杂的涡轮叶片形状上均显示出显著的改进。&lt;h4&gt;结论&lt;/h4&gt;该控制架构协调所有机器人和传感器之间的同步运动和数据采集，有效提高了WAAM过程的精度。&lt;h4&gt;总结&lt;/h4&gt;通过本研究提出的多机器人系统，显著改善了WAAM在低熔点金属（如铝合金）打印中的几何精度问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic Wire Arc Additive Manufacturing (WAAM) is a metal additivemanufacturing technology, offering flexible 3D printing while ensuring highquality near-net-shape final parts. However, WAAM also suffers from geometricimprecision, especially for low-melting-point metal such as aluminum alloys. Inthis paper, we present a multi-robot framework for WAAM process monitoring andcontrol. We consider a three-robot setup: a 6-dof welding robot, a 2-doftrunnion platform, and a 6-dof sensing robot with a wrist-mounted laser linescanner measuring the printed part height profile. The welding parameters,including the wire feed rate, are held constant based on the materials used, sothe control input is the robot path speed. The measured output is the partheight profile. The planning phase decomposes the target shape into slices ofuniform height. During runtime, the sensing robot scans each printed layer, andthe robot path speed for the next layer is adjusted based on the deviation fromthe desired profile. The adjustment is based on an identified model correlatingthe path speed to change in height. The control architecture coordinates thesynchronous motion and data acquisition between all robots and sensors. Using athree-robot WAAM testbed, we demonstrate significant improvements of the closedloop scan-n-print approach over the current open loop result on both a flatwall and a more complex turbine blade shape.</description>
      <author>example@mail.com (Chen-Lung Lu, Honglu He, Jinhan Ren, Joni Dhar, Glenn Saunders, Agung Julius, Johnson Samuel, John T. Wen)</author>
      <guid isPermaLink="false">2411.15915v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Analysis of the impact of heterogeneous platoon for mixed traffic flow: control strategy, fuel consumption and emissions</title>
      <link>http://arxiv.org/abs/2411.15238v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;与传统的车辆纵向间距控制策略相比，组合间距策略能够整合不同间距控制策略的优点，但尚未分析不同组合间距控制策略对混合交通流的影响机制。&lt;h4&gt;目的&lt;/h4&gt;提出多种针对连接自动驾驶车辆（CAVs）的组合间距控制策略。&lt;h4&gt;方法&lt;/h4&gt;首先开发了一个混合交通流模型，以分析CAV车队的特征；基于此推导出车辆分布的概率模型，并通过仿真验证其有效性；然后基于四种间距控制策略提出多种间距组合策略；最后进行数值实验，计算不同间距控制策略下混合交通流的平均燃油消耗和污染物排放，并进一步分析车队间距控制策略对交通流燃油消耗和污染物排放的影响。&lt;h4&gt;主要发现&lt;/h4&gt;在低交通密度（即15辆/km）下，不同车队间距控制策略下交通流的平均燃油消耗和污染物排放差异相对较小；在中高交通密度（即55-95辆/km）时，当CAV渗透率超过80%时，VTG1-CS、VTG2-CS和CTG-CS策略能够有效保证交通流的稳定性和安全性，并显著减少燃油消耗和污染物排放。&lt;h4&gt;结论&lt;/h4&gt;组合间距控制策略在高CAV渗透率下能够显著改善交通流的燃油效率和降低排放。&lt;h4&gt;总结&lt;/h4&gt;本研究通过构建模型和进行实验，验证了组合间距策略对提升交通流效率的重要性，尤其是在高渗透率的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compared with traditional vehicle longitudinal spacing control strategies,the combination spacing strategy can integrate the advantages of differentspacing control strategies. However, the impact mechanism of differentcombination spacing control strategies on mixed traffic flow has not beenanalyzed yet. Therefore, this paper proposes various combination spacingcontrol strategies for connected automated vehicles (CAVs). First, a mixedtraffic flow model was developed to analyze the characteristics of CAVplatoons. On this basis, a probability model of vehicle distribution wasderived, and its effectiveness was verified through simulation. Then, multiplespacing combination strategies are proposed based on four spacing controlstrategies. Finally, numerical experiments were conducted to calculate theaverage fuel consumption and pollutant emissions of mixed traffic flow underdifferent spacing control strategies, and the impact of platoon spacing controlstrategies on traffic flow fuel consumption and pollutant emissions was furtheranalyzed. Results show that: (1) the differences in average fuel consumptionand pollutant emissions of traffic flow are relatively small under differentplatoon spacing control strategies under low traffic density (i.e., 15 veh/km);(2) at medium to high traffic densities (i.e., 55-95 veh/km), when thepenetration rate of CAVs exceeds 80%, VTG1-CS, VTG2-CS, and CTG-CS strategiescan effectively ensure traffic flow stability and safety, and significantlyreduce fuel consumption and pollutant emissions.</description>
      <author>example@mail.com (Yunxia Wu, Le Li, Zhihong Yao, Yi Wang, Gen Li, Yangsheng Jiang)</author>
      <guid isPermaLink="false">2411.15238v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Nd-BiMamba2: A Unified Bidirectional Architecture for Multi-Dimensional Data Processing</title>
      <link>http://arxiv.org/abs/2411.15380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习模型通常需要针对不同维度的数据设计特定架构，如1D时间序列、2D图像和3D体积数据。现有的双向模型主要关注序列数据，难以有效扩展到更高维度。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的多维双向神经网络架构Nd-BiMamba2，以有效处理1D、2D和3D数据。&lt;h4&gt;方法&lt;/h4&gt;Nd-BiMamba2基于Mamba2模块，引入创新的双向处理机制和自适应填充策略，以捕捉多维数据中的双向信息，同时保持计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;Nd-BiMamba2采用统一的模块化设计，避免了为不同维度数据设计特定架构的需要，从而简化开发和维护成本。实验结果表明，Nd-BiMamba2在多种硬件平台上高效运行。&lt;h4&gt;结论&lt;/h4&gt;Nd-BiMamba2展示了在实际应用中的潜力，且其代码为开源。&lt;h4&gt;总结&lt;/h4&gt;Nd-BiMamba2是一种灵活且高效的多维双向神经网络架构，适用于多种数据类型和硬件平台。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/human9000/nd-mamba2-torch&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models often require specially designed architectures toprocess data of different dimensions, such as 1D time series, 2D images, and 3Dvolumetric data. Existing bidirectional models mainly focus on sequential data,making it difficult to scale effectively to higher dimensions. To address thisissue, we propose a novel multi-dimensional bidirectional neural networkarchitecture, named Nd-BiMamba2, which efficiently handles 1D, 2D, and 3D data.Nd-BiMamba2 is based on the Mamba2 module and introduces innovativebidirectional processing mechanisms and adaptive padding strategies to capturebidirectional information in multi-dimensional data while maintainingcomputational efficiency. Unlike existing methods that require designingspecific architectures for different dimensional data, Nd-BiMamba2 adopts aunified architecture with a modular design, simplifying development andmaintenance costs. To verify the portability and flexibility of Nd-BiMamba2, wesuccessfully exported it to ONNX and TorchScript and tested it on differenthardware platforms (e.g., CPU, GPU, and mobile devices). Experimental resultsshow that Nd-BiMamba2 runs efficiently on multiple platforms, demonstrating itspotential in practical applications. The code is open-source:https://github.com/Human9000/nd-Mamba2-torch</description>
      <author>example@mail.com (Hao Liu)</author>
      <guid isPermaLink="false">2411.15380v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Beryllium: The smoking gun of a rejuvenated star</title>
      <link>http://arxiv.org/abs/2411.15650v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 8 figures. A&amp;A in press&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;HD 65907的化学成分和银河速度成分表明，尽管其年轻的等时代年龄约为5亿年，实际上是两颗老的第二类恒星的合并体。其低锂丰度与质量吸积事件一致。&lt;h4&gt;目的&lt;/h4&gt;确定HD 65907的锂和铍丰度，并评估其径向速度时间序列、活动周期和光谱能量分布，以寻找该恒星起源的线索。&lt;h4&gt;方法&lt;/h4&gt;通过HARPS和UVES光谱的共振线进行光谱合成，确定锂和铍丰度。利用HARPS数据研究恒星的径向速度和活动水平变化。采用光度数据评估恒星的光谱能量分布。&lt;h4&gt;主要发现&lt;/h4&gt;HD 65907的锂和铍严重缺乏。其径向速度几乎恒定（σ=2 m/s），小幅调制可能与恒星活动有关，且没有未检测到的近伴星迹象。过量的红外辐射与30 K的黑体一致，解释为围绕恒星的碎片盘。&lt;h4&gt;结论&lt;/h4&gt;低锂和铍丰度以及缺乏伴星证据强烈支持恒星合并的假说。在此背景下，铍可用于确认文献中提到的其他蓝色星际恒星。&lt;h4&gt;总结&lt;/h4&gt;HD 65907的研究为理解恒星合并及其后果提供了重要证据，强调了其在天文学研究中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1051/0004-6361/202451197&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Context. The chemistry and Galactic velocity components of the star HD 65907suggest that despite its young isochronal age of $\sim$5 Gyr, it is in fact amerger of two old Population II stars. Its low Li abundance is also consistentwith a mass accretion episode. Aims. We determine Li and Be abundances for thisstar and evaluate its radial velocity time series, activity cycle, and spectralenergy distribution in search of clues regarding the origin of this enigmaticstar. Methods. Li and Be abundances were determined via spectral synthesis oftheir resonance lines using HARPS and UVES spectra, respectively. HARPS datawere also used to study variations in the star's radial velocity and activitylevels. Photometric data were adopted to evaluate the stellar spectral energydistribution. Results. HD 65908 is severely Li- and Be-depleted. Its radialvelocity is nearly constant ($\sigma =$ 2 m/s), with a small modulation likelyassociated with stellar activity, and the star shows no further signs of anundetected close companion. The excess infrared emission is consistent with a30 K blackbody, which is interpreted as a debris disk surrounding the star. Thepost-merger mass, rotation rate, and evolution of this star are discussed.Conclusions. The low Li and Be abundances, in addition to the lack of evidencefor a companion, are strong pieces of evidence in favor of the stellar mergerscenario. In this context, Be can be used to confirm other blue stragglersamong field solar-type stars, as proposed in the literature.</description>
      <author>example@mail.com (Anne Rathsam, Jorge Meléndez, Amanda I. Karakas)</author>
      <guid isPermaLink="false">2411.15650v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Weakly-Supervised Referring Image Segmentation via Progressive Comprehension</title>
      <link>http://arxiv.org/abs/2410.01544v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究弱监督参考图像分割（WRIS）问题，关注从图像-文本对中直接学习目标定位的复杂设置。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，利用输入描述中的目标相关文本线索，逐步定位目标对象。&lt;h4&gt;方法&lt;/h4&gt;采用进阶理解网络（PCNet），使用大语言模型（LLM）将输入文本分解为短语，利用条件引用模块（CRM）进行多阶段更新引用文本嵌入和响应图。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入区域感知收缩（RaS）损失和实例感知消歧（IaD）损失，显著提高了目标定位的精度，克服了实例定位的歧义。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，所提方法在三个常用基准测试中超越了现有最先进的方法。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新颖的WRIS方法，通过逐步利用文本线索，提升了目标定位的准确性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the weakly-supervised referring image segmentation (WRIS)problem, and focuses on a challenging setup where target localization islearned directly from image-text pairs. We note that the input text descriptiontypically already contains detailed information on how to localize the targetobject, and we also observe that humans often follow a step-by-stepcomprehension process (\ie, progressively utilizing target-related attributesand relations as cues) to identify the target object. Hence, we propose a novelProgressive Comprehension Network (PCNet) to leverage target-related textualcues from the input description for progressively localizing the target object.Specifically, we first use a Large Language Model (LLM) to decompose the inputtext description into short phrases. These short phrases are taken astarget-related cues and fed into a Conditional Referring Module (CRM) inmultiple stages, to allow updating the referring text embedding and enhance theresponse map for target localization in a multi-stage manner. Based on the CRM,we then propose a Region-aware Shrinking (RaS) loss to constrain the visuallocalization to be conducted progressively in a coarse-to-fine manner acrossdifferent stages. Finally, we introduce an Instance-aware Disambiguation (IaD)loss to suppress instance localization ambiguity by differentiating overlappingresponse maps generated by different referring texts on the same image.Extensive experiments show that our method outperforms SOTA methods on threecommon benchmarks.</description>
      <author>example@mail.com (Zaiquan Yang, Yuhao Liu, Jiaying Lin, Gerhard Hancke, Rynson W. H. Lau)</author>
      <guid isPermaLink="false">2410.01544v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Communication-Efficient Sparsely-Activated Model Training via Sequence Migration and Token Condensation</title>
      <link>http://arxiv.org/abs/2411.15419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;混合专家（MoE）是一种通过稀疏激活来扩展大型模型的新兴技术。&lt;h4&gt;目的&lt;/h4&gt;探索在保持高并行度的同时，减少GPU之间的流量。&lt;h4&gt;方法&lt;/h4&gt;提出Luffy，一个高效的分布式MoE训练系统，采用两项新技术：迁移序列和令牌凝缩。&lt;h4&gt;主要发现&lt;/h4&gt;Luffy系统在16个V100 GPU的测试平台上，相比于最先进的MoE训练系统，速度提升高达2.73倍。&lt;h4&gt;结论&lt;/h4&gt;Luffy成功减少了GPU间的数据传输，同时保持了高水平的专家并行执行。&lt;h4&gt;总结&lt;/h4&gt;Luffy通过创新的方法解决了MoE训练中的网络负担问题，提升了训练效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mixture-of-Experts (MoE) is an emerging technique for scaling large modelswith sparse activation. MoE models are typically trained in a distributedmanner with an expert parallelism scheme, where experts in each MoE layer aredistributed across multiple GPUs. However, the default expert parallelismsuffers from the heavy network burden due to the all-to-all intermediate dataexchange among GPUs before and after the expert run. Some existing works haveproposed to reduce intermediate data exchanges by transferring experts toreduce the network loads, however, which would decrease parallelism level ofexpert execution and make computation inefficient. The weaknesses of existingworks motivate us to explore whether it is possible to reduce inter-GPU trafficwhile maintaining a high degree of expert parallelism. This paper gives apositive response by presenting Luffy, a communication-efficient distributedMoE training system with two new techniques. First, Luffy migrates sequencesamong GPUs to hide heavy token pulling paths within GPUs and avoid copyingexperts over GPUs. Second, we propose token condensation that identifiessimilar tokens and then eliminates redundant transmissions. We implement Luffybased on PyTorch and evaluate its performance on a testbed of 16 V100 GPUs.Luffy system can achieve a speedup of up to 2.73x compared to state-of-the-artMoE training systems.</description>
      <author>example@mail.com (Fahao Chen, Peng Li, Zicong Hong, Zhou Su, Song Guo)</author>
      <guid isPermaLink="false">2411.15419v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Establishing Design Routines for Efficient Control of Automated Robots</title>
      <link>http://arxiv.org/abs/2411.16016v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着技术的持续进步，模拟人类行为的机器人开发变得愈加 intensify。&lt;h4&gt;目的&lt;/h4&gt;探讨将人工智能（AI）整合到机器人设计中的方法，旨在增强人机交互。&lt;h4&gt;方法&lt;/h4&gt;提出几种改善机器人性能的方法，包括在多种环境中高效控制的例程和增强视线能力的数字图像处理。&lt;h4&gt;主要发现&lt;/h4&gt;在实时环境中测试机器人系统，以评估其相对于现有模型的效率。&lt;h4&gt;结论&lt;/h4&gt;提出的机器人系统具备通用控制能力，适合工业应用，并在Arduino平台上开发和编程。&lt;h4&gt;技术特点&lt;/h4&gt;包括GPS控制以确保安全操作和渐进式记忆算法以实现高效的内存管理。&lt;h4&gt;总结&lt;/h4&gt;本研究在工业和研究应用中提供了重要的进展，尽管人类干预仍然必要，但AI的整合为机器人技术带来了新的挑战和机遇。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With continual advancements in technology, efforts to develop robotssimulating human behavior have intensified. Cognitive robotics, combined withartificial intelligence (AI), has proven effective in surveying and researchanalysis. However, despite progress, human intervention remains necessary, andincorporating AI into robotic systems continues to pose challenges. This paperexplores methodologies to integrate AI into robotic designs, aiming to enhancehuman-robot interactions. Several approaches are proposed to improve roboticperformance, including routines for efficient control in varied environmentsand the incorporation of digital image processing for enhanced line-of-sightcapabilities. A key contribution of this work is testing robotic systems inreal-time environments to assess efficiency relative to existing models.Additionally, the paper introduces a robotic system with universal controlcapabilities, suitable for industrial applications, developed and programmed onthe Arduino platform. Features such as GPS control for safe operations andprogressive memory algorithms for efficient memory management are presented,offering advancements in both industrial and research applications.</description>
      <author>example@mail.com (Hariharan Ragothaman, Harihar M, SK Guhananthan)</author>
      <guid isPermaLink="false">2411.16016v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Quantile deep learning models for multi-step ahead time series prediction</title>
      <link>http://arxiv.org/abs/2411.15674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;不确定性量化在时间序列预测中至关重要，而分位数回归为不确定性量化提供了一种有价值的机制，特别适用于极值预测。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的分位数回归深度学习框架，用于多步时间序列预测，提升深度学习模型的能力。&lt;h4&gt;方法&lt;/h4&gt;实现多步时间序列预测的主要深度学习模型，评估其在高波动和极端条件下的表现，包括多变量和单变量建模，并与传统深度学习模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;在比特币和以太坊的日收盘价数据及选定基准时间序列数据集上测试模型，结果表明，结合分位数损失函数的深度学习模型在不损失预测准确性的情况下，提供了额外的分位数预测。&lt;h4&gt;结论&lt;/h4&gt;我们的分位数模型在处理波动性方面更有效，并通过使用分位数为决策制定和不确定性量化提供了额外的信息，相较于传统深度学习模型更具优势。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了分位数回归在深度学习中的应用，强调了其在时间序列预测中的重要性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sydney-machine-learning/quantiledeeplearning&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Uncertainty quantification is crucial in time series prediction, and quantileregression offers a valuable mechanism for uncertainty quantification which isuseful for extreme value forecasting. Although deep learning models have beenprominent in multi-step ahead prediction, the development and evaluation ofquantile deep learning models have been limited. We present a novel quantileregression deep learning framework for multi-step time series prediction. Inthis way, we elevate the capabilities of deep learning models by incorporatingquantile regression, thus providing a more nuanced understanding of predictivevalues. We provide an implementation of prominent deep learning models formulti-step ahead time series prediction and evaluate their performance underhigh volatility and extreme conditions. We include multivariate and univariatemodelling, strategies and provide a comparison with conventional deep learningmodels from the literature. Our models are tested on two cryptocurrencies:Bitcoin and Ethereum, using daily close-price data and selected benchmark timeseries datasets. The results show that integrating a quantile loss functionwith deep learning provides additional predictions for selected quantileswithout a loss in the prediction accuracy when compared to the literature. Ourquantile model has the ability to handle volatility more effectively andprovides additional information for decision-making and uncertaintyquantification through the use of quantiles when compared to conventional deeplearning models.</description>
      <author>example@mail.com (Jimmy Cheung, Smruthi Rangarajan, Amelia Maddocks, Xizhe Chen, Rohitash Chandra)</author>
      <guid isPermaLink="false">2411.15674v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Windstorm Economic Impacts on the Spanish Resilience: A Machine Learning Real-Data Approach</title>
      <link>http://arxiv.org/abs/2411.14439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;气候变化引发的灾害已成为一个重要关注点，尤其是在城市地区。&lt;h4&gt;目的&lt;/h4&gt;评估城市地区的韧性，以加强灾害管理，特别是在易受风暴影响的区域。&lt;h4&gt;方法&lt;/h4&gt;利用机器学习分类模型，分析西班牙地区关于风暴的公开数据。&lt;h4&gt;主要发现&lt;/h4&gt;准确评估风暴造成的经济损失较为困难，因每个地区的特点和数据有限。&lt;h4&gt;结论&lt;/h4&gt;该方法能帮助决策者做出关于准备和减灾措施的明智决策，最终创造更具韧性的城市环境。&lt;h4&gt;总结&lt;/h4&gt;通过应用机器学习，提升对风暴的应对能力，以更好地抵御未来的风暴灾害。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Climate change-associated disasters have become a significant concern,principally when affecting urban areas. Assessing these regions' resilience tostrengthen their disaster management is crucial, especially in the areasvulnerable to windstorms, one of Spain's most critical disasters. Smart citiesand machine learning offer promising solutions to manage disasters, butaccurately estimating economic losses from windstorms can be difficult due tothe unique characteristics of each region and limited data. This study proposesutilizing ML classification models to enhance disaster resilience by analyzingpublicly available data on windstorms in the Spanish areas. This approach canhelp decision-makers make informed decisions regarding preparedness andmitigation actions, ultimately creating a more resilient urban environment thatcan better withstand windstorms in the future.</description>
      <author>example@mail.com (Matheus Puime Pedra, Josune Hernantes, Leire Casals, Leire Labaka)</author>
      <guid isPermaLink="false">2411.14439v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Integrating optimal ridesharing matching into multimodal traffic model: Implications for policy and sustainable transport system</title>
      <link>http://arxiv.org/abs/2411.15427v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;将拼车匹配明确整合到多模式交通模型中，对于准确评估多模式交通对城市经济和环境的影响至关重要。&lt;h4&gt;目的&lt;/h4&gt;将最优拼车匹配方法整合到基于路径的确定性日常交通分配框架中，以考虑匹配取消并捕捉各种模式之间的互动。&lt;h4&gt;方法&lt;/h4&gt;模型考虑了五种交通模式（单人驾驶、作为司机的拼车、作为乘客的拼车、公交旅行和地铁旅行）以及基于拥有状态的两组旅客，稳态通过数值实验确定。&lt;h4&gt;主要发现&lt;/h4&gt;敏感性分析显示，MT系统的表现随拥有状态、公交票价和拼车票价的变化而变化，表明不同群体、路段和地区的模式分配、旅行成本和排放有多样化的影响。&lt;h4&gt;结论&lt;/h4&gt;车辆限制和定价策略在管理MT系统中既有益处也有缺陷，强调在政策制定和实施中需谨慎考虑权衡和社会公平的影响。&lt;h4&gt;总结&lt;/h4&gt;本研究不仅增强了对MT系统的理论理解，还为旨在实现高效、可持续和社会公平的城市交通政策提供了有价值的支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating ridesharing matching explicitly into multimodal traffic models iscrucial for accurately assessing the impacts of multimodal transport (MT) onurban economic and environmental aspects. This paper integrates an optimalridesharing matching method into a path-based deterministic day-to-day trafficassignment framework, considers match cancellations, and captures theinteractions between various modes on the road. The model incorporates fivetraffic modes (solo driving, ridesharing as a driver, ridesharing as apassenger, bus travel, and metro travel) and two groups of travelers based ontheir ownership status. Its steady state is determined through numericalexperiments. The sensitivity analyses reveal that the MT system's performancevaries with changes in ownership, bus fare, and ridesharing fare, demonstratingdiverse impacts on mode split, travel cost, and emissions across differentgroups, road links, and regions. Our findings suggest that vehicle restrictionsand pricing strategies have both benefits and drawbacks in managing MT system,emphasizing the need for careful consideration of trade-offs and social equityimplications in policy-making and implementation. This study not only enhancesthe theoretical understanding of MT system but also provides valuable supportfor urban transportation policy-making aimed at achieving efficient,sustainable, and socially equitable transport systems.</description>
      <author>example@mail.com (Yueqi Liu, Ke Han, Zhuoqian Yang, Yanghong Yu, Wen Ji)</author>
      <guid isPermaLink="false">2411.15427v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Picking by Tilting: In-Hand Manipulation for Object Picking using Effector with Curved Form</title>
      <link>http://arxiv.org/abs/2411.16055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文介绍了一种机器人手中的操作技术，旨在处理无法以抓握方式抓取的大物体。&lt;h4&gt;目的&lt;/h4&gt;利用与弯曲的被动末端执行器和两个平坦支撑面之间的接触交互，提出一种有效的物体拾取方法。&lt;h4&gt;方法&lt;/h4&gt;首先将物体倾斜并固定在执行器和支撑面之间，然后将执行器放入物体下方形成的间隙中，以实现重力下的抓握。&lt;h4&gt;主要发现&lt;/h4&gt;通过对物体倾斜机制的研究，提出了安全的物体倾斜策略，并通过实验展示了不同大小和形状物体的成功拾取。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法能够可靠地进行物体拾取，使用简单的硬件和控制，并在适当的夹具设计下效果更佳。&lt;h4&gt;总结&lt;/h4&gt;该论文展示了一种创新的机器人操作技术，能够有效处理大物体的拾取问题，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICRA48891.2023.10160404&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a robotic in-hand manipulation technique that can beapplied to pick an object too large to grasp in a prehensile manner, by takingadvantage of its contact interactions with a curved, passive end-effector, andtwo flat support surfaces. First, the object is tilted up while being heldbetween the end-effector and the supports. Then, the end-effector is tuckedinto the gap underneath the object, which is formed by tilting, in order toobtain a grasp against gravity. In this paper, we first examine the mechanicsof tilting to understand the different ways in which the object can beinitially tilted. We then present a strategy to tilt up the object in a securemanner. Finally, we demonstrate successful picking of objects of various sizeand geometry using our technique through a set of experiments performed with acustom-made robotic device and a conventional robot arm. Our experiment resultsshow that object picking can be performed reliably with our method using simplehardware and control, and when possible, with appropriate fixture design.</description>
      <author>example@mail.com (Yanshu Song, Abdullah Nazir, Darwin Lau, Yun Hui Liu)</author>
      <guid isPermaLink="false">2411.16055v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Research on Optimal Portfolio Based on Multifractal Features</title>
      <link>http://arxiv.org/abs/2411.15712v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages,3 postscript figures,&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;投资者的最佳投资组合选择一直是学术界的热门话题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新模型以适应实际资本市场，克服传统投资组合模型的不足。&lt;h4&gt;方法&lt;/h4&gt;构建均值去趋势交叉相关投资组合模型（M-DCCP模型），将不同时间序列的去趋势交叉相关性纳入风险收益标准。&lt;h4&gt;主要发现&lt;/h4&gt;在中国A股市场通过实证分析，M-DCCP模型比传统均值方差投资组合模型（M-VP模型）更有利于投资者构建最佳投资组合。&lt;h4&gt;结论&lt;/h4&gt;M-DCCP模型能够改善投资组合表现，适应不同波动指数偏好和时间尺度偏好的投资者。&lt;h4&gt;总结&lt;/h4&gt;新模型为投资者提供了更优的投资组合选择，具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Providing optimal portfolio selection for investors has always been one ofthe hot topics in academia. In view of the traditional portfolio model couldnot adapt to the actual capital market and can provide erroneous results. Thispaper innovatively constructs a mean-detrended cross-correlation portfoliomodel (M-DCCP model), This model is designed to embed detrendedcross-correlation between different simultaneously recorded time series in thepresence of nonstationary into the reward-risk criterion. We illustrate themodel's effectiveness by selected five composite indexes (SSE 50, CSI 300, SSE500, CSI 1000 and CSI 2000) in China A-share market. The empirical results showthat compared with traditional mean-variance portfolio model (M-VP model), theM-DCCP model is more conducive for investors to construct optimal portfoliosunder the different fluctuation exponent preference and time scales preference,so as to improve portfolio's performance.</description>
      <author>example@mail.com (Yong Li)</author>
      <guid isPermaLink="false">2411.15712v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DGS-SLAM: Gaussian Splatting SLAM in Dynamic Environment</title>
      <link>http://arxiv.org/abs/2411.10722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;动态SLAM框架的研究主要集中在静态环境上，存在对动态物体的处理不足。&lt;h4&gt;目的&lt;/h4&gt;提出Dynamic Gaussian Splatting SLAM (DGS-SLAM)，解决动态物体带来的光度和几何不一致性。&lt;h4&gt;方法&lt;/h4&gt;将Gaussian Splatting与强大的滤波过程结合，处理动态物体，包括高斯插入和关键帧选择。&lt;h4&gt;主要发现&lt;/h4&gt;引入稳健的掩膜生成方法，提高动态物体去除的准确性，并减少噪声和伪影。&lt;h4&gt;结论&lt;/h4&gt;DGS-SLAM在相机跟踪和新视图合成方面在多个动态SLAM基准测试中表现出色，证明其在处理真实动态场景中的有效性。&lt;h4&gt;总结&lt;/h4&gt;DGS-SLAM是首个基于高斯分布的动态SLAM框架，成功应对动态环境挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/kmk97/DGS-SLAM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Dynamic Gaussian Splatting SLAM (DGS-SLAM), the first dynamicSLAM framework built on the foundation of Gaussian Splatting. While recentadvancements in dense SLAM have leveraged Gaussian Splatting to enhance scenerepresentation, most approaches assume a static environment, making themvulnerable to photometric and geometric inconsistencies caused by dynamicobjects. To address these challenges, we integrate Gaussian Splatting SLAM witha robust filtering process to handle dynamic objects throughout the entirepipeline, including Gaussian insertion and keyframe selection. Within thisframework, to further improve the accuracy of dynamic object removal, weintroduce a robust mask generation method that enforces photometric consistencyacross keyframes, reducing noise from inaccurate segmentation and artifactssuch as shadows. Additionally, we propose the loop-aware window selectionmechanism, which utilizes unique keyframe IDs of 3D Gaussians to detect loopsbetween the current and past frames, facilitating joint optimization of thecurrent camera poses and the Gaussian map. DGS-SLAM achieves state-of-the-artperformance in both camera tracking and novel view synthesis on various dynamicSLAM benchmarks, proving its effectiveness in handling real-world dynamicscenes.</description>
      <author>example@mail.com (Mangyu Kong, Jaewon Lee, Seongwon Lee, Euntai Kim)</author>
      <guid isPermaLink="false">2411.10722v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Forest Biomass Mapping with Terrestrial Hyperspectral Imaging for Wildfire Risk Monitoring</title>
      <link>http://arxiv.org/abs/2411.16107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for IEEE SSRR 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;过去十年野火数量迅速增加，迫切需要检测和预测这些灾害，以减少对生态系统和人类生命的损失。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的解决方案——Hyper-Drive3D，以识别森林中有可能成为火灾燃料的区域。&lt;h4&gt;方法&lt;/h4&gt;该系统结合快照高光谱成像和激光雷达，安装在无人地面车辆（UGV）上，分析森林植被的光谱特征。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟森林条件的受控环境中进行的实地试验提供了系统有效性的宝贵见解，并在不同环境条件和地形的密集森林中进行了广泛的数据收集。&lt;h4&gt;结论&lt;/h4&gt;增强了系统对火灾危险的预测能力，支持以风险为基础的积极森林管理策略。&lt;h4&gt;总结&lt;/h4&gt;还提出了一个从高光谱图像提取湿度数据并将其投影到三维空间的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid increase in wildfires in the past decade, it has becomenecessary to detect and predict these disasters to mitigate losses toecosystems and human lives. In this paper, we present a novel solution --Hyper-Drive3D -- consisting of snapshot hyperspectral imaging and LiDAR,mounted on an Unmanned Ground Vehicle (UGV) that identifies areas insideforests at risk of becoming fuel for a forest fire. This system enables moreaccurate classification by analyzing the spectral signatures of forestvegetation. We conducted field trials in a controlled environment simulatingforest conditions, yielding valuable insights into the system's effectiveness.Extensive data collection was also performed in a dense forest across varyingenvironmental conditions and topographies to enhance the system's predictivecapabilities for fire hazards and support a risk-informed, proactive forestmanagement strategy. Additionally, we propose a framework for extractingmoisture data from hyperspectral imagery and projecting it into 3D space.</description>
      <author>example@mail.com (Nathaniel Hanson, Sarvesh Prajapati, James Tukpah, Yash Mewada, Taşkın Padır)</author>
      <guid isPermaLink="false">2411.16107v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing the Quantification of Capacity and Throughput in Integrated Space and Terrestrial Network</title>
      <link>http://arxiv.org/abs/2411.15433v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;网络容量和吞吐量的量化对集成空间和地面网络（ISTN）的性能评估至关重要。现有研究主要将最大吞吐量视为网络容量，这种定义不合理，因为网络容量会因所用路由算法和拥塞控制策略而变化。&lt;h4&gt;目的&lt;/h4&gt;探讨ISTN的容量和吞吐量的定义，并提出一种新的量化评估方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于不可靠ISL模型的网络容量评估方法（cap-uISL）和基于已知流量路径的受限路径扩展吞吐量计算方法（THP-CPE）。&lt;h4&gt;主要发现&lt;/h4&gt;在流量负载增加时，吞吐量接近其最大值，但明显小于网络容量。实验结果表明，THP-CPE方法在四个新兴ISTN中相比其他方法更为准确，现有吞吐量计算方法通常高估了吞吐量。&lt;h4&gt;结论&lt;/h4&gt;THP-CPE保持了合理的路径利用率（&lt;1），在所有负载情况下表现优异，证明了其在网络吞吐量计算中的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的网络容量和吞吐量评估方法，强调了网络基础设施特性对ISTN容量的决定性影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantification of network capacity and throughput is crucial for performanceevaluation of integrated space and terrestrial network (ISTN).However, existingstudies mainly consider the maximum throughput as the network capacity, butsuch a definition would make it unreasonable that the value of the networkcapacity would change with different employed routing algorithms and congestioncontrol policy, instead of being a constant quantity.  In this paper, we argue that the capacity of an ISTN is solely dependent onthe characteristics of the network infrastructure,and the throughput of an ISTNis the aggregate traffic transported by the network under a given trafficscenario. Then, we present a quantitative approach to assessing networkcapacity in relation to an unreliable ISL model (cap-uISL), and a ConstrainedPath Expansion throughput calculation method (THP-CPE) based on a set of knowntraffic paths. This method allows us to obtain the current throughput value ofthe network based on any given traffic paths and load demand matrix. As thetraffic load increases, the throughput approaches its maximum value, which isnotably smaller than the network's capacity.  We experimentally determine the network capacity of CAP-uISL under variouslink parameters and compare our throughput quantization method, THP-CPE, withother state-of-the-art methods under four emerging ISTNs. We find that,compared with the THP-CPE, existing throughput calculation methods tend to beoverestimated, while our proposed throughput calculation method maintainsreasonable intervals in terms of path utilization ($&lt;1$) under all load cases.</description>
      <author>example@mail.com (Menglong Yang, Weizheng Li, Wei Li, Binbin Liang, Songchen Han, Xiaodong Han, Yibing Liu, Xiangtong Wang)</author>
      <guid isPermaLink="false">2411.15433v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Tackling Data Heterogeneity in Federated Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2411.15716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列预测在能源消耗预测、疾病传播监测和天气预报等多个实际应用中发挥着重要作用。&lt;h4&gt;目的&lt;/h4&gt;提出一个新框架Fed-TREND，以应对不同设备生成的时间序列数据的异构性问题。&lt;h4&gt;方法&lt;/h4&gt;Fed-TREND生成两种类型的合成数据，一种用于增强客户端的本地训练共识，另一种用于从全局模型更新轨迹中提取长期影响见解以优化全局模型。&lt;h4&gt;主要发现&lt;/h4&gt;Fed-TREND与大多数时间序列预测模型兼容，并能无缝集成到现有的联邦学习框架中，以提高预测性能。&lt;h4&gt;结论&lt;/h4&gt;在八个数据集上进行的广泛实验表明，Fed-TREND的有效性和可推广性。&lt;h4&gt;总结&lt;/h4&gt;Fed-TREND提供了一种新的方法来处理时间序列预测中的数据异构性，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting plays a critical role in various real-worldapplications, including energy consumption prediction, disease transmissionmonitoring, and weather forecasting. Although substantial progress has beenmade in time series forecasting, most existing methods rely on a centralizedtraining paradigm, where large amounts of data are collected from distributeddevices (e.g., sensors, wearables) to a central cloud server. However, thisparadigm has overloaded communication networks and raised privacy concerns.Federated learning, a popular privacy-preserving technique, enablescollaborative model training across distributed data sources. However, directlyapplying federated learning to time series forecasting often yields suboptimalresults, as time series data generated by different devices are inherentlyheterogeneous. In this paper, we propose a novel framework, Fed-TREND, toaddress data heterogeneity by generating informative synthetic data asauxiliary knowledge carriers. Specifically, Fed-TREND generates two types ofsynthetic data. The first type of synthetic data captures the representativedistribution information from clients' uploaded model updates and enhancesclients' local training consensus. The second kind of synthetic data extractslong-term influence insights from global model update trajectories and is usedto refine the global model after aggregation. Fed-TREND is compatible with mosttime series forecasting models and can be seamlessly integrated into existingfederated learning frameworks to improve prediction performance. Extensiveexperiments on eight datasets, using several federated learning baselines andfour popular time series forecasting models, demonstrate the effectiveness andgeneralizability of Fed-TREND.</description>
      <author>example@mail.com (Wei Yuan, Guanhua Ye, Xiangyu Zhao, Quoc Viet Hung Nguyen, Yang Cao, Hongzhi Yin)</author>
      <guid isPermaLink="false">2411.15716v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Monocular SLAM-based Multi-User Positioning System with Image Occlusion in Augmented Reality</title>
      <link>http://arxiv.org/abs/2411.10940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，增强现实（AR）技术快速发展，用户对多用户协作体验的需求增加。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于ORB-SLAM2的多用户定位系统，确保多个用户的空间定位同步和一致性。&lt;h4&gt;方法&lt;/h4&gt;使用单目RGB图像，通过Unity 3D游戏引擎开发，系统在平面表面上放置共同的虚拟物体，以便每个用户都能正确视角查看。&lt;h4&gt;主要发现&lt;/h4&gt;生成的虚拟物体作为多用户位置同步的参考点，用户的定位信息通过中央服务器在每个用户的AR设备间传递。&lt;h4&gt;结论&lt;/h4&gt;利用深度学习技术从单张RGB图像估计深度图，解决AR应用中的遮挡问题，使虚拟物体在AR场景中显得更自然。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种有效的多用户协作AR系统，增强了用户之间的互动和体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, with the rapid development of augmented reality (AR)technology, there is an increasing demand for multi-user collaborativeexperiences. Unlike for single-user experiences, ensuring the spatiallocalization of every user and maintaining synchronization and consistency ofpositioning and orientation across multiple users is a significant challenge.In this paper, we propose a multi-user localization system based on ORB-SLAM2using monocular RGB images as a development platform based on the Unity 3D gameengine. This system not only performs user localization but also places acommon virtual object on a planar surface (such as table) in the environment sothat every user holds a proper perspective view of the object. These generatedvirtual objects serve as reference points for multi-user positionsynchronization. The positioning information is passed among every user's ARdevices via a central server, based on which the relative position and movementof other users in the space of a specific user are presented via virtualavatars all with respect to these virtual objects. In addition, we use deeplearning techniques to estimate the depth map of an image from a single RGBimage to solve occlusion problems in AR applications, making virtual objectsappear more natural in AR scenes.</description>
      <author>example@mail.com (Wei-Hsiang Lien, Benedictus Kent Chandra, Robin Fischer, Ya-Hui Tang, Shiann-Jang Wang, Wei-En Hsu, Li-Chen Fu)</author>
      <guid isPermaLink="false">2411.10940v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>End-to-End Steering for Autonomous Vehicles via Conditional Imitation Co-Learning</title>
      <link>http://arxiv.org/abs/2411.16131v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NCTA 2024 Best Paper Honorable Mention&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动驾驶涉及数据融合、物体和车道检测、行为预测和路径规划等复杂任务。&lt;h4&gt;目的&lt;/h4&gt;提出条件模仿共学习（CIC）方法，解决条件模仿学习（CIL）模型在未知环境中的泛化能力不足问题。&lt;h4&gt;方法&lt;/h4&gt;通过门控双曲正切单元（GTUs）生成共学习矩阵，学习CIL专家分支之间的关系；将转向回归问题视为分类问题，使用分类-回归混合损失来弥合回归与分类之间的差距，并考虑转向类别之间的空间倾向。&lt;h4&gt;主要发现&lt;/h4&gt;与CIL方法相比，所提模型在未知环境中的自动驾驶成功率平均提高了62%。&lt;h4&gt;结论&lt;/h4&gt;CIC方法有效提高了自动驾驶系统在复杂环境中的表现，增强了模型的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;本研究通过改进的学习方法，提升了自动驾驶技术在多变环境中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving involves complex tasks such as data fusion, object andlane detection, behavior prediction, and path planning. As opposed to themodular approach which dedicates individual subsystems to tackle each of thosetasks, the end-to-end approach treats the problem as a single learnable taskusing deep neural networks, reducing system complexity and minimizingdependency on heuristics. Conditional imitation learning (CIL) trains theend-to-end model to mimic a human expert considering the navigational commandsguiding the vehicle to reach its destination, CIL adopts specialist networkbranches dedicated to learn the driving task for each navigational command.Nevertheless, the CIL model lacked generalization when deployed to unseenenvironments. This work introduces the conditional imitation co-learning (CIC)approach to address this issue by enabling the model to learn the relationshipsbetween CIL specialist branches via a co-learning matrix generated by gatedhyperbolic tangent units (GTUs). Additionally, we propose posing the steeringregression problem as classification, we use a classification-regression hybridloss to bridge the gap between regression and classification, we also proposeusing co-existence probability to consider the spatial tendency between thesteering classes. Our model is demonstrated to improve autonomous drivingsuccess rate in unseen environment by 62% on average compared to the CILmethod.</description>
      <author>example@mail.com (Mahmoud M. Kishky, Hesham M. Eraqi, Khaled F. Elsayed)</author>
      <guid isPermaLink="false">2411.16131v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TableTime: Reformulating Time Series Classification as Zero-Shot Table Understanding via Large Language Models</title>
      <link>http://arxiv.org/abs/2411.15737v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在多变量时间序列分类（MTSC）中表现出色，但需要有效的数据表示方式。&lt;h4&gt;目的&lt;/h4&gt;探讨现有LLM方法的局限性并提出改进方案。&lt;h4&gt;方法&lt;/h4&gt;提出TableTime，将MTSC重新构建为表格理解任务，通过将多变量时间序列转换为表格形式并以文本格式表示。&lt;h4&gt;主要发现&lt;/h4&gt;现有方法存在三大瓶颈：1) 难以无损编码时间和通道特定信息；2) 学习的表示空间难以与LLM的语义空间对齐；3) 需要特定任务的重新训练，成本高且劳动密集。&lt;h4&gt;结论&lt;/h4&gt;TableTime通过引入多种策略，提升了LLMs的推理能力，并实现了零-shot分类。&lt;h4&gt;总结&lt;/h4&gt;在10个公开数据集上的广泛实验验证了TableTime的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have demonstrated their effectiveness inmultivariate time series classification (MTSC). Effective adaptation of LLMsfor MTSC necessitates informative data representations. Existing LLM-basedmethods directly encode embeddings for time series within the latent space ofLLMs from scratch to align with semantic space of LLMs. Despite theireffectiveness, we reveal that these methods conceal three inherent bottlenecks:(1) they struggle to encode temporal and channel-specific information in alossless manner, both of which are critical components of multivariate timeseries; (2) it is much difficult to align the learned representation space withthe semantic space of the LLMs; (3) they require task-specific retraining,which is both computationally expensive and labor-intensive. To bridge thesegaps, we propose TableTime, which reformulates MTSC as a table understandingtask. Specifically, TableTime introduces the following strategies: (1) convertmultivariate time series into a tabular form, thus minimizing information lossto the greatest extent; (2) represent tabular time series in text format toachieve natural alignment with the semantic space of LLMs; (3) design areasoning framework that integrates contextual text information, neighborhoodassistance, multi-path inference and problem decomposition to enhance thereasoning ability of LLMs and realize zero-shot classification. Extensiveexperiments performed on 10 publicly representative datasets from UEA archiveverify the superiorities of the TableTime.</description>
      <author>example@mail.com (Jiahao Wang, Mingyue Cheng, Qingyang Mao, Qi Liu, Feiyang Xu, Xin Li, Enhong Chen)</author>
      <guid isPermaLink="false">2411.15737v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Flexible Infrastructure-Sharing 5G Network Architecture Based on Network Slicing and Roaming</title>
      <link>http://arxiv.org/abs/2411.15505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;移动网络基础设施的共享成为5G引入后的一项关键议题，由于部署这些基础设施的高成本，出现了中立托管模型和网络功能虚拟化(NFV)、网络切片等特性作为可行解决方案。&lt;h4&gt;目的&lt;/h4&gt;设计、实施和测试一种灵活的基础设施共享5G网络架构，以便为任何类型的客户提供服务，无论是否为运营商。&lt;h4&gt;方法&lt;/h4&gt;该架构利用5G的网络切片实现流量隔离，并符合不同客户的政策，使用漫游进行运营商客户用户的认证。实施和测试在模拟环境中进行，使用UERANSIM和Open5GS开源工具。&lt;h4&gt;主要发现&lt;/h4&gt;定性测试成功验证了切片提供的认证和流量隔离功能。结果表明，与单一客户使用所有网络资源的场景相比，该架构在四个客户和八个用户共享基础设施的情况下，吞吐量提高了61.8%，数据包丢失率(PLR)降低了96.8%。&lt;h4&gt;结论&lt;/h4&gt;所提架构对中立托管网络基础设施的性能产生了积极影响。&lt;h4&gt;总结&lt;/h4&gt;通过设计和测试灵活的5G基础设施共享架构，展示了其在多客户环境下的有效性和性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/info15040213&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The sharing of mobile network infrastructure has become a key topic with theintroduction of 5G due to the high costs of deploying such infrastructures,with neutral host models coupled with features such as network functionvirtualization (NFV) and network slicing emerging as viable solutions for thechallenges in this area. With this in mind, this work presents the design,implementation, and test of a flexible infrastructure-sharing 5G networkarchitecture capable of providing services to any type of client, whether anoperator or not. The proposed architecture leverages 5G's network slicing fortraffic isolation and compliance with the policies of different clients, withroaming employed for the authentication of users of operator clients. Theproposed architecture was implemented and tested in a simulation environmentusing the UERANSIM and Open5GS open-source tools. Qualitative testssuccessfully validated the authentication and the traffic isolation featuresprovided by the slices for the two types of clients. Results also demonstratethat the proposed architecture has a positive impact on the performance of theneutral host network infrastructure, achieving 61.8% higher throughput and96.8% lower packet loss ratio (PLR) in a scenario sharing the infrastructureamong four clients and eight users when compared to a single client with allthe network resources.</description>
      <author>example@mail.com (Joao P. Ferreira, Vinicius C. Ferreira, Sergio L. Nogueira, Joao M. Faria, Jose A. Afonso)</author>
      <guid isPermaLink="false">2411.15505v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>The Blue Horizontal-Branch Stars From the LAMOST Survey: Atmospheric Parameters</title>
      <link>http://arxiv.org/abs/2411.11250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;蓝水平分支星（BHB星）对研究银河晕的结构至关重要，准确的气候参数对研究银河的形成和演化至关重要。&lt;h4&gt;目的&lt;/h4&gt;使用数据驱动的技术估计BHB星的气候参数。&lt;h4&gt;方法&lt;/h4&gt;应用称为星体标签机器（SLAM）的方法，利用大天区多目标光纤光谱望远镜（LAMOST-LRS）的低分辨率光谱，结合A型理论光谱作为训练数据集，加入色彩指数以进一步约束恒星温度。&lt;h4&gt;主要发现&lt;/h4&gt;为5355颗BHB星推导出气候参数，相比于现有文献结果，考虑色彩指数后气候参数的精度显著提高，特别是在低信噪比的光谱中。&lt;h4&gt;结论&lt;/h4&gt;随机误差为$T_{eff}$约30 K，log $g$约0.1 dex，[Fe/H]约0.12 dex；SLAM提供的恒星标签与文献中的高分辨率光谱结果比较，标准偏差为$T_{eff}$ = 76 K，log $g$ = 0.04 dex，[Fe/H] = 0.09 dex。&lt;h4&gt;总结&lt;/h4&gt;本研究通过改进的气候参数估计方法，提升了对BHB星的理解，为银河的形成和演化提供了重要数据支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Blue horizontal-branch (BHB) stars are crucial for studying the structure ofthe Galactic halo. Accurate atmospheric parameters of BHB stars are essentialfor investigating the formation and evolution of the Galaxy. In this work, adata-driven technique named stellar label machine (SLAM) is used to estimatethe atmospheric parameters of Large Sky Area Multi-Object Fiber SpectroscopicTelescope low-resolution spectra (LAMOST-LRS) for BHB stars with a set ofA-type theoretical spectra as the training dataset. We add color indexes($(BP-G), (G-RP), (BP-RP), (J-H)$) during the training process to constrain thestellar temperature further. Finally, we derive the atmospheric parameters($T_\mathrm{eff}$, log\, $g$, [Fe/H]) for 5,355 BHB stars. Compared to existingliterature results, our results are more robust, after taking the color indexinto account, the resulted precisoin of $T_\mathrm{eff}$, log\, $g$ issignificantly improved, especially for the spectrum with low signal-to-noiseratio (S/N). Based on the duplicate observations with a S/N difference $&lt;20\%$, the random errors are around 30\,K, 0.1~dex, and 0.12~dex for$T_\mathrm{eff}$, log\,$g$, [Fe/H], respectively. The stellar labels providedby SLAM are also compared to those from the high-resolution spectra inliterature. The standard deviation between the predicted star labels and thepublished values from the high-resolution spectra is adopted as \sout{to} thestatistical uncertainty of our results. They are $\sigma$($T_\mathrm{eff}$) =76\,K, $\sigma$(log\,$g$) = 0.04~dex, and $\sigma$([Fe/H]) = 0.09~dex,respectively.</description>
      <author>example@mail.com (Jie Ju, Bo Zhang, Wenyuan Cui, ZhenYan Huo, Chao Liu, Yang Huang, JianRong Shi)</author>
      <guid isPermaLink="false">2411.11250v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Robot Reliable Navigation in Uncertain Topological Environments with Graph Attention Networks</title>
      <link>http://arxiv.org/abs/2411.16134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究多机器人在不确定拓扑网络中的可靠导航问题，旨在最大化机器人团队的准时到达概率。&lt;h4&gt;目的&lt;/h4&gt;应对路网不确定性，特别是边的可遍历性未知的问题。&lt;h4&gt;方法&lt;/h4&gt;将问题重构为部分可观察马尔可夫决策过程(POMDP)，引入动态自适应图嵌入方法，并结合深度强化学习与图注意网络(GAT)来增强机器人的策略学习过程。&lt;h4&gt;主要发现&lt;/h4&gt;提出的MARVEL方法在不确定拓扑网络中表现出更好的适应性和性能，与现有的可靠导航算法及加拿大旅行者问题解决方案相比有显著改进。&lt;h4&gt;结论&lt;/h4&gt;MARVEL方法在自构建的室内环境中进行的实际实验中证明了其可行性，展示了其在复杂环境中的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究为多机器人在不确定环境中的导航问题提供了新的解决方案，结合了先进的算法和实际应用验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper studies the multi-robot reliable navigation problem in uncertaintopological networks, which aims at maximizing the robot team's on-time arrivalprobabilities in the face of road network uncertainties. The uncertainty inthese networks stems from the unknown edge traversability, which is onlyrevealed to the robot upon its arrival at the edge's starting node. Existingapproaches often struggle to adapt to real-time network topology changes,making them unsuitable for varying topological environments. To address thechallenge, we reformulate the problem into a Partially Observable MarkovDecision Process (POMDP) framework and introduce the Dynamic Adaptive GraphEmbedding method to capture the evolving nature of the navigation task. Wefurther enhance each robot's policy learning process by integrating deepreinforcement learning with Graph Attention Networks (GATs), leveragingself-attention to focus on critical graph features. The proposed approach,namely Multi-Agent Routing in Variable Environments with Learning (MARVEL)employs the generalized policy gradient algorithm to optimize the robots'real-time decision-making process iteratively. We compare the performance ofMARVEL with state-of-the-art reliable navigation algorithms as well as Canadiantraveller problem solutions in a range of canonical transportation networks,demonstrating improved adaptability and performance in uncertain topologicalnetworks. Additionally, real-world experiments with two robots navigatingwithin a self-constructed indoor environment with uncertain topologicalstructures demonstrate MARVEL's practicality.</description>
      <author>example@mail.com (Zhuoyuan Yu, Hongliang Guo, Albertus Hendrawan Adiwahono, Jianle Chan, Brina Shong Wey Tynn, Chee-Meng Chew, Wei-Yun Yau)</author>
      <guid isPermaLink="false">2411.16134v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Prototype-Based Framework to Design Scalable Heterogeneous SoCs with Fine-Grained DFS</title>
      <link>http://arxiv.org/abs/2411.15574v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the 42nd IEEE International Conference on Computer
  Design (ICCD 2024), Milan, Italy, November 18-20, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代系统芯片的设计复杂性需要灵活的开发框架。&lt;h4&gt;目的&lt;/h4&gt;提供一个开源框架以加速多核异构系统芯片的设计和优化。&lt;h4&gt;方法&lt;/h4&gt;使用Vespa框架，支持在单个网络芯片节点中实例化多个加速器副本，并将系统芯片划分为具有独立动态频率调节的频率岛。&lt;h4&gt;主要发现&lt;/h4&gt;在4x4瓦片基础的系统芯片实验中，有效探索了加速器复制、频率岛时钟频率和瓦片布局的多种解决方案。&lt;h4&gt;结论&lt;/h4&gt;Vespa框架可以实时监控互连流量和加速器性能的多种统计数据，提升系统设计的灵活性和效率。&lt;h4&gt;总结&lt;/h4&gt;Vespa框架为现代系统芯片的开发提供了更快、更灵活的设计空间探索和运行时优化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Frameworks for the agile development of modern system-on-chips are crucial todealing with the complexity of designing such architectures. The open-sourceVespa framework for designing large, FPGA-based, multi-core heterogeneoussystem-on-chips enables a faster and more flexible design space exploration ofsuch architectures and their run-time optimization. Vespa, built on ESP,introduces the capabilities to instantiate multiple replicas of the sameaccelerator in a single network-on-chip node and to partition thesystem-on-chips into frequency islands with independent dynamic frequencyscaling actuators, as well as a dedicated run-time monitoring infrastructure.Experiments on 4-by-4 tile-based system-on-chips demonstrate the possibility ofeffectively exploring a multitude of solutions that differ in the replicationof accelerators, the clock frequencies of the frequency islands, and the tiles'placement, as well as monitoring a variety of statistics related to the trafficon the interconnect and the accelerators' performance at run time.</description>
      <author>example@mail.com (Gabriele Montanaro, Andrea Galimberti, Davide Zoni)</author>
      <guid isPermaLink="false">2411.15574v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Using Drone Swarm to Stop Wildfire: A Predict-then-optimize Approach</title>
      <link>http://arxiv.org/abs/2411.16144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无人机集群结合数据智能是未来灭火的潜力方案，但面临复杂的环境条件和火灾动态传播的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种预测-优化方法，提升无人机集群灭火的有效性。&lt;h4&gt;方法&lt;/h4&gt;基于真实火灾数据构建火灾传播预测的凸神经网络模型，并提出结合动态规划的混合整数规划模型来实现高效的任务规划。此外，使用机会约束鲁棒优化确保在不同情况下的灭火表现。&lt;h4&gt;主要发现&lt;/h4&gt;经过75个模拟火灾环境的训练，MIP+CCRO方法在多个测试集上表现最佳，相比于普通MIP减少了37.3%的移动次数，并显著优于GA基线。&lt;h4&gt;结论&lt;/h4&gt;该方法在模拟环境中的表现优于传统方法，下一步将进行真实火灾传播和灭火实验以进一步验证。&lt;h4&gt;总结&lt;/h4&gt;无人机集群灭火技术的预测-优化方法有效应对复杂火灾环境，展现出优越的灭火能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drone swarms coupled with data intelligence can be the future of wildfirefighting. However, drone swarm firefighting faces enormous challenges, such asthe highly complex environmental conditions in wildfire scenes, the highlydynamic nature of wildfire spread, and the significant computational complexityof drone swarm operations. We develop a predict-then-optimize approach toaddress these challenges to enable effective drone swarm firefighting. First,we construct wildfire spread prediction convex neural network (Convex-NN)models based on real wildfire data. Then, we propose a mixed-integerprogramming (MIP) model coupled with dynamic programming (DP) to enableefficient drone swarm task planning. We further use chance-constrained robustoptimization (CCRO) to ensure robust firefighting performances under varyingsituations. The formulated model is solved efficiently using BendersDecomposition and Branch-and-Cut algorithms. After 75 simulated wildfireenvironments training, the MIP+CCRO approach shows the best performance amongseveral testing sets, reducing movements by 37.3\% compared to the plain MIP.It also significantly outperformed the GA baseline, which often failed to fullyextinguish the fire. Eventually, we will conduct real-world fire spread andquenching experiments in the next stage for further validation.</description>
      <author>example@mail.com (Shijie Pan, Aoran Cheng, Yiqi Sun, Kai Kang, Cristobal Pais, Yulun Zhou, Zuo-Jun Max Shen)</author>
      <guid isPermaLink="false">2411.16144v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Emerging Trends and Research Opportunities in Visual Place Recognition</title>
      <link>http://arxiv.org/abs/2411.11481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2 pages, 1 figure. 40th Anniversary of the IEEE Conference on
  Robotics and Automation (ICRA@40), Rotterdam, Netherlands, September 23-26,
  2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉基础的识别，如图像分类和目标检测，是计算机视觉和机器人领域长期以来的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究视觉地点识别在复杂导航任务中的重要性，特别是在同时定位与地图构建(SLAM)中的作用。&lt;h4&gt;方法&lt;/h4&gt;通过计算机视觉工具，系统能够识别和匹配之前访问过的位置。&lt;h4&gt;主要发现&lt;/h4&gt;在提高准确性和鲁棒性方面，研究者受到自然语言处理方法成功的启发，开始关注视觉-语言模型，整合视觉与文本数据。&lt;h4&gt;结论&lt;/h4&gt;视觉地点识别对大多数定位和重定位实施至关重要，尤其是在循环闭合检测中。&lt;h4&gt;总结&lt;/h4&gt;通过结合视觉和文本数据，研究者希望开发出更先进的识别技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual-based recognition, e.g., image classification, object detection, etc.,is a long-standing challenge in computer vision and robotics communities.Concerning the roboticists, since the knowledge of the environment is aprerequisite for complex navigation tasks, visual place recognition is vitalfor most localization implementations or re-localization and loop closuredetection pipelines within simultaneous localization and mapping (SLAM). Morespecifically, it corresponds to the system's ability to identify and match apreviously visited location using computer vision tools. Towards developingnovel techniques with enhanced accuracy and robustness, while motivated by thesuccess presented in natural language processing methods, researchers haverecently turned their attention to vision-language models, which integratevisual and textual data.</description>
      <author>example@mail.com (Antonios Gasteratos, Konstantinos A. Tsintotas, Tobias Fischer, Yiannis Aloimonos, Michael Milford)</author>
      <guid isPermaLink="false">2411.11481v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Optoelectronic recurrent neural network using optical-electrical-optical converters with RC delay</title>
      <link>http://arxiv.org/abs/2411.16186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;光学神经网络（ONN）因其低延迟和低功耗而受到广泛关注。&lt;h4&gt;目的&lt;/h4&gt;研究光学递归神经网络（RNN）在时间序列数据处理中的应用，特别是如何补偿回路损耗。&lt;h4&gt;方法&lt;/h4&gt;模拟配备光电转换器（OEO）的光电递归神经网络（OE-RNN），分析RC延迟对RNN性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;即使RC延迟相对于时间序列数据的时间间隔较大，OE-RNN仍能实现高训练准确性；RC延迟的累积并未降低RNN性能，反而可以补偿由于回路损耗带来的性能下降。&lt;h4&gt;结论&lt;/h4&gt;理论分析表明，在特定损失和RC延迟区域内可实现高训练准确性；在32x32规模的OE-RNN电路中确认了补偿效应。&lt;h4&gt;总结&lt;/h4&gt;提出的方案为光计算和光通信中的时间序列数据处理开辟了新途径，利用RC延迟提高了处理效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optical neural network (ONN) has been attracting intense attention owing totheir low latency and low-power consumption. Among the ONNs, optical recurrentneural network (RNN) enables low-power and high-speed time-series dataprocessing using a compact loop structure. The loop losses need to beefficiently compensated so that the time-series information is maintained inthe RNN operation. For this purpose, we focus on the optoelectronic RNN(OE-RNN) with optical-electrical-optical (OEO) converters to compensate for theloop losses. However, the effect of resistive-capacitive (RC) delay of OEOconverters on the RNN performance is unclear. Here, we study in simulation anOE-RNN equipped with OEO converters with RC delay. We confirm that our modeledOE-RNN achieves the high training accuracy of time-series data classificationeven when RC delay is comparably large to the time interval of time-seriesdata. Our analyses reveal that the accumulation of time-series data by RC delaydoes not degrade the RNN performance but rather can compensate for the degradedRNN performance due to loop losses. From the theoretical analysis referring tothe gradient explosion and vanishing problems, we find the region related toloss and RC delay where the high training accuracy can be achieved. Insimulation, we confirm this compensation effect in the large OE-RNN circuit upto 32$\times$32 scale. Our proposed scheme opens a new way of time-series dataprocessing by utilizing RC delay for the optical computing and opticalcommunication.</description>
      <author>example@mail.com (Masaya Arahata, Shota Kita, Kazuo Aoyama, Akihiko Shinya, Hiroshi Sawada, Masaya Notomi)</author>
      <guid isPermaLink="false">2411.16186v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>LLM Online Spatial-temporal Signal Reconstruction Under Noise</title>
      <link>http://arxiv.org/abs/2411.15764v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究引入了LLM在线时空重建框架（LLM-OSR），结合了图信号处理（GSP）和大型语言模型（LLMs）。&lt;h4&gt;目的&lt;/h4&gt;旨在进行在线时空信号重建。&lt;h4&gt;方法&lt;/h4&gt;LLM-OSR利用基于GSP的时空信号处理器来增强图信号，并使用LLMs根据时空模式预测缺失值。&lt;h4&gt;主要发现&lt;/h4&gt;在不同高斯噪声水平下对交通和气象数据集进行评估，结果显示使用GPT-4-o mini的LLM-OSR在高斯噪声条件下准确且稳健。&lt;h4&gt;结论&lt;/h4&gt;讨论了研究的局限性和未来研究的见解，强调了结合GSP技术与LLMs在时空预测任务中的潜力。&lt;h4&gt;总结&lt;/h4&gt;LLM-OSR框架在时空信号重建方面具有良好的应用前景，值得进一步研究和探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces the LLM Online Spatial-temporal Reconstruction (LLM-OSR)framework, which integrates Graph Signal Processing (GSP) and Large LanguageModels (LLMs) for online spatial-temporal signal reconstruction. The LLM-OSRutilizes a GSP-based spatial-temporal signal handler to enhance graph signalsand employs LLMs to predict missing values based on spatiotemporal patterns.The performance of LLM-OSR is evaluated on traffic and meteorological datasetsunder varying Gaussian noise levels. Experimental results demonstrate thatutilizing GPT-4-o mini within the LLM-OSR is accurate and robust under Gaussiannoise conditions. The limitations are discussed along with future researchinsights, emphasizing the potential of combining GSP techniques with LLMs forsolving spatiotemporal prediction tasks.</description>
      <author>example@mail.com (Yi Yan, Dayu Qin, Ercan Engin Kuruoglu)</author>
      <guid isPermaLink="false">2411.15764v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>LiV-GS: LiDAR-Vision Integration for 3D Gaussian Splatting SLAM in Outdoor Environments</title>
      <link>http://arxiv.org/abs/2411.12185v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;LiV-GS 是一个在户外环境中使用的 LiDAR-视觉 SLAM 系统，采用 3D 高斯作为可微分的空间表示。&lt;h4&gt;目的&lt;/h4&gt;开发一种新方法，将离散和稀疏的 LiDAR 数据与连续可微分的高斯地图直接对齐，以解决传统 LiDAR 映射中固定分辨率的限制。&lt;h4&gt;方法&lt;/h4&gt;该系统使用共享协方差属性对点云与高斯地图进行对齐，并将法向量方向整合到损失函数中，以优化高斯地图。此外，引入了一种新颖的条件高斯约束，以便在 LiDAR 视野外可靠稳定地更新高斯。&lt;h4&gt;主要发现&lt;/h4&gt;LiV-GS 能够以每秒 7.98 帧的速度实现快速准确的映射和新视图合成，且在 SLAM、图像渲染和映射方面表现优越。&lt;h4&gt;结论&lt;/h4&gt;LiV-GS 的成功跨模态雷达-LiDAR 定位，展示了其在跨模态语义定位和对象分割中的潜力。&lt;h4&gt;总结&lt;/h4&gt;LiV-GS 通过创新的高斯表示和对齐方法，显著提升了户外 SLAM 系统的性能和应用范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present LiV-GS, a LiDAR-visual SLAM system in outdoor environments thatleverages 3D Gaussian as a differentiable spatial representation. Notably,LiV-GS is the first method that directly aligns discrete and sparse LiDAR datawith continuous differentiable Gaussian maps in large-scale outdoor scenes,overcoming the limitation of fixed resolution in traditional LiDAR mapping. Thesystem aligns point clouds with Gaussian maps using shared covarianceattributes for front-end tracking and integrates the normal orientation intothe loss function to refines the Gaussian map. To reliably and stably updateGaussians outside the LiDAR field of view, we introduce a novel conditionalGaussian constraint that aligns these Gaussians closely with the nearestreliable ones. The targeted adjustment enables LiV-GS to achieve fast andaccurate mapping with novel view synthesis at a rate of 7.98 FPS. Extensivecomparative experiments demonstrate LiV-GS's superior performance in SLAM,image rendering and mapping. The successful cross-modal radar-LiDARlocalization highlights the potential of LiV-GS for applications in cross-modalsemantic positioning and object segmentation with Gaussian maps.</description>
      <author>example@mail.com (Renxiang Xiao, Wei Liu, Yushuai Chen, Liang Hu)</author>
      <guid isPermaLink="false">2411.12185v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Plasmonic Janus particles: A perspective on optical manipulation and biomedical applications</title>
      <link>http://arxiv.org/abs/2411.16191v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Janus微纳米颗粒的组成不对称性为利用不同刺激来操控复合颗粒提供了前所未有的机会，增强光学、磁性和光热响应。&lt;h4&gt;目的&lt;/h4&gt;概述光学操控等技术对等离子体Janus颗粒的最新进展及其在生物医学应用中的意义。&lt;h4&gt;方法&lt;/h4&gt;对各种组成的Janus颗粒进行了光学、等离子体和磁性操控的简要总结。&lt;h4&gt;主要发现&lt;/h4&gt;等离子体和磁性Janus颗粒在靶向药物传递、光热治疗、增强高温疗法和神经调节方面具有潜在应用。&lt;h4&gt;结论&lt;/h4&gt;建议对这一特定的不对称颗粒家族进行合理设计和应用。&lt;h4&gt;总结&lt;/h4&gt;Janus颗粒在生物医学领域的应用展现了广泛的前景，特别是在药物传递和治疗方法上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The compositional asymmetry of Janus micro- and nanoparticles givesunprecedented opportunities to manipulate such composite particles withdifferent stimuli to achieve enhanced optical, magnetic and photothermalresponses, which can be exploited for sensing, phototherapy, and nanoscalerobotic applications. This perspective overviews recent advances in opticalmanipulation of plasmonic Janus particles and their implications for biomedicalapplications. In particular, a brief summary of optical, plasmonic, andmagnetic manipulation of Janus particles of various compositions are presented.Moreover, the potentials of plasmonic and magnetic Janus particles for targeteddrug delivery, photothermal therapy, enhanced hyperthermia, and neuromodulationare briefly discussed. Finally, a perspective on the rational design andapplications of this particular family of asymmetric particles is forwarded.</description>
      <author>example@mail.com (Alemayehu Nana Koya, Anastasiia Sapunova, Nageswar Reddy Sanamreddy, Yanqiu Zou, Qifei Ma, Domna Kotsifak, Huaizhou Jin, Shangzhong Jin, Paolo Vavassori, Denis Garoli)</author>
      <guid isPermaLink="false">2411.16191v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TeG: Temporal-Granularity Method for Anomaly Detection with Attention in Smart City Surveillance</title>
      <link>http://arxiv.org/abs/2411.11003v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视频监控中的异常检测最近引起了研究界的关注。&lt;h4&gt;目的&lt;/h4&gt;解决视频流中异常的时间持续性变化对特定事件时间动态学习的复杂性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种时间粒度的方法（TeG），结合不同时间尺度的时空特征，并使用多头交叉注意力块和多头自注意力块。&lt;h4&gt;主要发现&lt;/h4&gt;TeG模型在城市监控系统中成功部署和验证，实现了工业环境中的实时有效结果。&lt;h4&gt;结论&lt;/h4&gt;TeG模型在智能城市相关研究项目中扩展了UCF-Crime数据集，增加了新的异常类型。&lt;h4&gt;总结&lt;/h4&gt;该研究为视频监控中的异常检测提供了一种有效的方法，具有良好的实际应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection in video surveillance has recently gained interest from theresearch community. Temporal duration of anomalies vary within video streams,leading to complications in learning the temporal dynamics of specific events.This paper presents a temporal-granularity method for an anomaly detectionmodel (TeG) in real-world surveillance, combining spatio-temporal features atdifferent time-scales. The TeG model employs multi-head cross-attention blocksand multi-head self-attention blocks for this purpose. Additionally, we extendthe UCF-Crime dataset with new anomaly types relevant to Smart City researchproject. The TeG model is deployed and validated in a city surveillance system,achieving successful real-time results in industrial settings.</description>
      <author>example@mail.com (Erkut Akdag, Egor Bondarev, Peter H. N. De With)</author>
      <guid isPermaLink="false">2411.11003v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Modeling large dimensional matrix time series with partially known and latent factors</title>
      <link>http://arxiv.org/abs/2411.16192v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文考虑通过引入回归项来建模大维度矩阵时间序列，扩展经典矩阵因子模型。&lt;h4&gt;目的&lt;/h4&gt;将已知因子或有用协变量的信息纳入矩阵因子模型中。&lt;h4&gt;方法&lt;/h4&gt;建立系数矩阵、载荷矩阵和信号部分的收敛速率，与Wang等人（2019）的结果一致。&lt;h4&gt;主要发现&lt;/h4&gt;通过数值研究验证了估计程序在有限样本中的表现。&lt;h4&gt;结论&lt;/h4&gt;使用股票每日收益数据展示了所提模型的优越性。&lt;h4&gt;总结&lt;/h4&gt;本文提出的扩展模型有效地整合了协变量信息，并在实际数据中表现出色。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This article considers to model large-dimensional matrix time series byintroducing a regression term to the matrix factor model. This is an extensionof classic matrix factor model to incorporate the information of known factorsor useful covariates. We establish the convergence rates of coefficient matrix,loading matrices and the signal part. The theoretical results coincide with therates in Wang et al. (2019). We conduct numerical studies to verify theperformance of our estimation procedure in finite samples. Finally, wedemonstrate the superiority of our proposed model using the daily returns ofstocks data.</description>
      <author>example@mail.com (Yongchang Hui, Yuteng Zhang, Siting Huang)</author>
      <guid isPermaLink="false">2411.16192v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DT-RaDaR: Digital Twin Assisted Robot Navigation using Differential Ray-Tracing</title>
      <link>http://arxiv.org/abs/2411.12284v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 25 figures, 7 tables, under review to IEEE transactions&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主系统导航是一个研究深入且不断发展的领域，特别是在利用传感数据方面引发了研究人员和从业者的高度关注。&lt;h4&gt;目的&lt;/h4&gt;提出一个保护隐私的框架，解决依赖摄像头和激光雷达导航的机器人所面临的隐私问题。&lt;h4&gt;方法&lt;/h4&gt;提出DT-RaDaR，一个基于深度强化学习的框架，通过在数字双胞胎环境中使用射线追踪技术生成无线电频率(RF)地图，适用于静态和动态室内场景及智能城市。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用开源工具如Blender和NVIDIA的Sionna RT生成RF数字双胞胎，能够高保真地复制真实世界环境和RF传播模型，优化服务机器人导航。&lt;h4&gt;结论&lt;/h4&gt;实验证明该框架在室内环境和智能城市中的可行性，标志着在使用射线追踪生成数据的机器人导航实际应用方面的重要进展。&lt;h4&gt;总结&lt;/h4&gt;本文提出的DT-RaDaR框架为机器人导航提供了创新的隐私保护解决方案，推动了该领域的研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous system navigation is a well-researched and evolving field. Recentadvancements in improving robot navigation have sparked increased interestamong researchers and practitioners, especially in the use of sensing data.However, this heightened focus has also raised significant privacy concerns,particularly for robots that rely on cameras and LiDAR for navigation. Ourinnovative concept of Radio Frequency (RF) map generation through ray-tracing(RT) within digital twin environments effectively addresses these concerns. Inthis paper, we propose DT-RaDaR, a robust privacy-preserving, deepreinforcement learning-based framework for robot navigation that leverages RFray-tracing in both static and dynamic indoor scenarios as well as in smartcities. We introduce a streamlined framework for generating RF digital twinsusing open-source tools like Blender and NVIDIA's Sionna RT. This approachallows for high-fidelity replication of real-world environments and RFpropagation models, optimized for service robot navigation. Severalexperimental validations and results demonstrate the feasibility of theproposed framework in indoor environments and smart cities, positioning ourwork as a significant advancement toward the practical implementation of robotnavigation using ray-tracing-generated data.</description>
      <author>example@mail.com (Sunday Amatare, Gaurav Singh, Raul Shakya, Aavash Kharel, Ahmed Alkhateeb, Debashri Roy)</author>
      <guid isPermaLink="false">2411.12284v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TopV-Nav: Unlocking the Top-View Spatial Reasoning Potential of MLLM for Zero-shot Object Navigation</title>
      <link>http://arxiv.org/abs/2411.16425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;零样本物体导航任务要求具身智能体在不熟悉的环境中找到之前未见过的物体，这种目标导向的探索依赖于对环境空间信息的感知、理解和推理能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，旨在改善当前基于语言模型的方法在空间信息处理中的不足。&lt;h4&gt;方法&lt;/h4&gt;引入TopV-Nav，一种基于多模态大语言模型的方法，直接在完整的俯视图地图上进行推理，并提出自适应视觉提示生成（AVPG）和动态地图缩放（DMS）机制。&lt;h4&gt;主要发现&lt;/h4&gt;TopV-Nav在MP3D和HM3D基准测试中表现优越，例如在HM3D上的成功率提高了3.9%，路径长度比提高了2.0%。&lt;h4&gt;结论&lt;/h4&gt;通过直接利用空间信息，TopV-Nav能够促进更深入的推理和更人性化的探索。&lt;h4&gt;总结&lt;/h4&gt;本研究通过提出TopV-Nav，展示了在零样本物体导航任务中，利用完整空间信息进行推理的重要性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Zero-Shot Object Navigation (ZSON) task requires embodied agents to finda previously unseen object by navigating in unfamiliar environments. Such agoal-oriented exploration heavily relies on the ability to perceive,understand, and reason based on the spatial information of the environment.However, current LLM-based approaches convert visual observations to languagedescriptions and reason in the linguistic space, leading to the loss of spatialinformation. In this paper, we introduce TopV-Nav, a MLLM-based method thatdirectly reasons on the top-view map with complete spatial information. Tofully unlock the MLLM's spatial reasoning potential in top-view perspective, wepropose the Adaptive Visual Prompt Generation (AVPG) method to adaptivelyconstruct semantically-rich top-view map. It enables the agent to directlyutilize spatial information contained in the top-view map to conduct thoroughreasoning. Besides, we design a Dynamic Map Scaling (DMS) mechanism todynamically zoom top-view map at preferred scales, enhancing local fine-grainedreasoning. Additionally, we devise a Target-Guided Navigation (TGN) mechanismto predict and to utilize target locations, facilitating global and human-likeexploration. Experiments on MP3D and HM3D benchmarks demonstrate thesuperiority of our TopV-Nav, e.g., $+3.9\%$ SR and $+2.0\%$ SPL absoluteimprovements on HM3D.</description>
      <author>example@mail.com (Linqing Zhong, Chen Gao, Zihan Ding, Yue Liao, Si Liu)</author>
      <guid isPermaLink="false">2411.16425v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Moving Horizon Estimation for Simultaneous Localization and Mapping with Robust Estimation Error Bounds</title>
      <link>http://arxiv.org/abs/2411.13310v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种稳健的移动视野估计 (MHE) 方法，用于解决 simultaneou localization and mapping (SLAM) 问题。&lt;h4&gt;目的&lt;/h4&gt;确保自我状态估计的稳健稳定性和地标位置估计的有界误差。&lt;h4&gt;方法&lt;/h4&gt;通过解耦自我状态和地标位置的 MHE 更新，实现仅在满足可检测性条件时才更新地标，并允许并行化地标更新以提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;在有限的地标可见性下，仍能保证估计的稳健性和对噪声的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;讨论了关键假设，包括自我状态的可检测性和地标测量模型的 Lipschitz 连续性，并介绍了一种简化的范围测量模型。&lt;h4&gt;总结&lt;/h4&gt;仿真结果验证了所考虑方法的有效性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a robust moving horizon estimation (MHE) approach withprovable estimation error bounds for solving the simultaneous localization andmapping (SLAM) problem. We derive sufficient conditions to guarantee robuststability in ego-state estimates and bounded errors in landmark positionestimates, even under limited landmark visibility which directly affectsoverall system detectability. This is achieved by decoupling the MHE updatesfor the ego-state and landmark positions, enabling individual landmark updatesonly when the required detectability conditions are met. The decoupled MHEstructure also allows for parallelization of landmark updates, improvingcomputational efficiency. We discuss the key assumptions, including ego-statedetectability and Lipschitz continuity of the landmark measurement model, withrespect to typical SLAM sensor configurations, and introduce a streamlinedmethod for the range measurement model. Simulation results validate theconsidered method, highlighting its efficacy and robustness to noise.</description>
      <author>example@mail.com (Jelena Trisovic, Alexandre Didier, Simon Muntwiler, Melanie N. Zeilinger)</author>
      <guid isPermaLink="false">2411.13310v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Experimental comparison of graph-based approximate nearest neighbor search algorithms on edge devices</title>
      <link>http://arxiv.org/abs/2411.14006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文讨论了在边缘设备上用于实时最近邻搜索应用的各种基于图的近似最近邻（ANN）搜索算法的实验比较。&lt;h4&gt;目的&lt;/h4&gt;提供对这些算法在边缘设备上的性能和适用性的深入评估，尤其是在智能城市基础设施和自动驾驶汽车等应用中。&lt;h4&gt;方法&lt;/h4&gt;研究利用边缘设备的计算和存储能力，分析插入和删除新向量的延迟及功耗等额外指标。&lt;h4&gt;主要发现&lt;/h4&gt;该比较分析是首次进行，现有研究多限于单线程实现和标准商品硬件。&lt;h4&gt;结论&lt;/h4&gt;这项全面的评估为边缘计算的实时跟踪系统提供了重要的见解，特别是在最近邻搜索算法的应用上。&lt;h4&gt;总结&lt;/h4&gt;研究旨在填补现有文献的空白，推动基于图的ANN算法在边缘设备上的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present an experimental comparison of various graph-basedapproximate nearest neighbor (ANN) search algorithms deployed on edge devicesfor real-time nearest neighbor search applications, such as smart cityinfrastructure and autonomous vehicles. To the best of our knowledge, thisspecific comparative analysis has not been previously conducted. While existingresearch has explored graph-based ANN algorithms, it has often been limited tosingle-threaded implementations on standard commodity hardware. Our studyleverages the full computational and storage capabilities of edge devices,incorporating additional metrics such as insertion and deletion latency of newvectors and power consumption. This comprehensive evaluation aims to providevaluable insights into the performance and suitability of these algorithms foredge-based real-time tracking systems enhanced by nearest-neighbor searchalgorithms.</description>
      <author>example@mail.com (Ali Ganbarov, Jicheng Yuan, Anh Le-Tuan, Manfred Hauswirth, Danh Le-Phuoc)</author>
      <guid isPermaLink="false">2411.14006v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Static and Dynamic Routing, Fiber, Modulation Format, and Spectrum Allocation in Hybrid ULL Fiber-SSMF Elastic Optical Networks</title>
      <link>http://arxiv.org/abs/2411.16159v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统标准单模光纤（SSMF）由于信号损失较大，无法满足未来长距离和高速光通道传输的需求。&lt;h4&gt;目的&lt;/h4&gt;研究在弹性光网络（EON）中，SSMF与超低损耗大有效面积光纤（ULL光纤）共存的情况下的路由、光纤、调制格式和频谱分配（RFMSA）问题。&lt;h4&gt;方法&lt;/h4&gt;将RFMSA问题建模为基于节点-弧的混合整数线性规划（MILP）模型，并开发了基于光纤选择策略的启发式算法，包括基于频谱使用（SU）、光信号噪声比（OSNR）感知、优先使用ULL光纤（UFF）和随机策略。&lt;h4&gt;主要发现&lt;/h4&gt;在静态流量需求情况下，基于OSNR感知策略的RFMSA算法表现最佳，最大频谱槽（FSs）使用量与MILP模型相当；在动态流量需求场景中，SU策略在光路阻塞概率方面显著优于其他策略。&lt;h4&gt;结论&lt;/h4&gt;采用ULL光纤与SSMF共存的方案，通过优化RFMSA策略，能有效提升网络性能，特别是在动态流量条件下。&lt;h4&gt;总结&lt;/h4&gt;本研究为光网络中不同类型光纤的共存与优化分配提供了新的解决方案，具有重要的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional standard single-mode fibers (SSMF) are unable to satisfy thefuture long-distance and high-speed optical channel transmission requirementdue to their relatively large signal losses. To address this issue, theultra-low loss and large effective area (ULL) fibers are successfullymanufactured and expected to deployed in the existing optical networks. Forsuch ULL fiber deployment, network operators prefer adding ULL fibers to eachlink rather than replace existing SSMFs, resulting in a scenario where both ofSSMF and ULL fiber coexist on the same link. In this paper, we investigated therouting, fiber, modulation format, and spectrum allocation (RFMSA) problem inthe context of an elastic optical network (EON) where ULL fiber and SSMFcoexisting on each link under both the static and dynamic traffic demands. Weformulated this RFMSA problem as a node-arc based Mixed Integer LinearProgramming (MILP) model and developed Spectrum Window Plane (SWP)-basedheuristic algorithms based on different fiber selection strategies, includingspectrum usage based (SU), optical signal-to-noise ratio (OSNR) aware, ULLfiber first (UFF), and random strategies. Simulation results show that in thestatic traffic demand situation, the RFMSA algorithm based on the OSNR-aware(OA) strategy exhibits optimal performance, attaining a performance similar tothat of the MILP model regarding the maximum number of frequency slots (FSs)used in the entire network. Moreover, in the dynamic traffic demand scenario,the SU strategy remarkably surpasses the other strategies in terms of thelightpath blocking probability.</description>
      <author>example@mail.com (Kangao Ouyang, Fengxian Tang, Zhilin Yuan, Jun Li, Yongcheng Li)</author>
      <guid isPermaLink="false">2411.16159v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Machine learning for cerebral blood vessels' malformations</title>
      <link>http://arxiv.org/abs/2411.16349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 6 main figures, 5 supplementary figures, 2 supplementary
  tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;脑动脉瘤和动静脉畸形是危及生命的脑血流动力学病理。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于机器学习的风险评估和治疗预后协议。&lt;h4&gt;方法&lt;/h4&gt;建立血流速率和压力的线性振荡模型，使用SINDy方法在线重建血流动力学变量的参数。&lt;h4&gt;主要发现&lt;/h4&gt;通过逻辑回归实现了73%的血流病理分类准确率。&lt;h4&gt;结论&lt;/h4&gt;该模型在诊断和预后应用中具备潜力，为评估脑血管状况提供了稳健且可解释的框架。&lt;h4&gt;总结&lt;/h4&gt;研究表明，脑血流参数可以用于改进脑病理的管理和治疗预后。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cerebral aneurysms and arteriovenous malformations are life-threateninghemodynamic pathologies of the brain. While surgical intervention is oftenessential to prevent fatal outcomes, it carries significant risks both duringthe procedure and in the postoperative period, making the management of theseconditions highly challenging. Parameters of cerebral blood flow, routinelymonitored during medical interventions, could potentially be utilized inmachine learning-assisted protocols for risk assessment and therapeuticprognosis. To this end, we developed a linear oscillatory model of bloodvelocity and pressure for clinical data acquired from neurosurgical operations.Using the method of Sparse Identification of Nonlinear Dynamics (SINDy), theparameters of our model can be reconstructed online within milliseconds from ashort time series of the hemodynamic variables. The identified parameter valuesenable automated classification of the blood-flow pathologies by means oflogistic regression, achieving an accuracy of 73 %. Our results demonstrate thepotential of this model for both diagnostic and prognostic applications,providing a robust and interpretable framework for assessing cerebral bloodvessel conditions.</description>
      <author>example@mail.com (Irem Topal, Alexander Cherevko, Yuri Bugay, Maxim Shishlenin, Jean Barbier, Deniz Eroglu, Édgar Roldán, Roman Belousov)</author>
      <guid isPermaLink="false">2411.16349v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>The Oxford Spires Dataset: Benchmarking Large-Scale LiDAR-Visual Localisation, Reconstruction and Radiance Field Methods</title>
      <link>http://arxiv.org/abs/2411.10546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Website: https://dynamic.robots.ox.ac.uk/datasets/oxford-spires/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了一个大规模的多模态数据集，该数据集在牛津的著名地标周围捕获，使用定制的多传感器感知单元和毫米级精度的地面激光雷达地图。&lt;h4&gt;目的&lt;/h4&gt;建立针对定位、重建和新视图合成任务的基准，以评估SLAM方法、SfM和MVS方法，以及神经辐射场等辐射场方法。&lt;h4&gt;方法&lt;/h4&gt;感知单元包括三个同步的全球快门彩色相机、一台汽车3D激光雷达扫描仪和一个惯性传感器，所有设备经过精确校准。使用TLS 3D模型作为地面真相来评估3D重建。&lt;h4&gt;主要发现&lt;/h4&gt;评估显示，最先进的辐射场方法存在关键限制，倾向于过拟合训练姿态/图像，而对非顺序姿态的泛化能力较差。在3D重建方面，相较于使用相同视觉输入的MVS系统，辐射场方法表现不佳。&lt;h4&gt;结论&lt;/h4&gt;本文的数据集和基准旨在促进辐射场方法与SLAM系统的更好结合，提供了可访问的原始和处理数据，以及解析和评估的软件。&lt;h4&gt;总结&lt;/h4&gt;通过该研究，展示了现有辐射场方法的不足，并为将来研究提供了基础数据支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a large-scale multi-modal dataset captured in andaround well-known landmarks in Oxford using a custom-built multi-sensorperception unit as well as a millimetre-accurate map from a Terrestrial LiDARScanner (TLS). The perception unit includes three synchronised global shuttercolour cameras, an automotive 3D LiDAR scanner, and an inertial sensor - allprecisely calibrated. We also establish benchmarks for tasks involvinglocalisation, reconstruction, and novel-view synthesis, which enable theevaluation of Simultaneous Localisation and Mapping (SLAM) methods,Structure-from-Motion (SfM) and Multi-view Stereo (MVS) methods as well asradiance field methods such as Neural Radiance Fields (NeRF) and 3D GaussianSplatting. To evaluate 3D reconstruction the TLS 3D models are used as groundtruth. Localisation ground truth is computed by registering the mobile LiDARscans to the TLS 3D models. Radiance field methods are evaluated not only withposes sampled from the input trajectory, but also from viewpoints that are fromtrajectories which are distant from the training poses. Our evaluationdemonstrates a key limitation of state-of-the-art radiance field methods: weshow that they tend to overfit to the training poses/images and do notgeneralise well to out-of-sequence poses. They also underperform in 3Dreconstruction compared to MVS systems using the same visual inputs. Ourdataset and benchmarks are intended to facilitate better integration ofradiance field methods and SLAM systems. The raw and processed data, along withsoftware for parsing and evaluation, can be accessed athttps://dynamic.robots.ox.ac.uk/datasets/oxford-spires/.</description>
      <author>example@mail.com (Yifu Tao, Miguel Ángel Muñoz-Bañón, Lintong Zhang, Jiahao Wang, Lanke Frank Tarimo Fu, Maurice Fallon)</author>
      <guid isPermaLink="false">2411.10546v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Goal-oriented Semantic Communications for Metaverse Construction via Generative AI and Optimal Transport</title>
      <link>http://arxiv.org/abs/2411.16187v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;元宇宙的出现提升了生产力和创造力，驱动了实时更新和个性化内容，导致数据流量大幅增加。&lt;h4&gt;目的&lt;/h4&gt;解决当前以位为导向的通信网络在处理高动态信息方面的不足，从而增强元宇宙应用的交互性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种面向目标的语义通信框架（GSC），包括基于沙漏网络的编码器和语义解码器，以提取和重建元宇宙内容。&lt;h4&gt;主要发现&lt;/h4&gt;与传统的元宇宙构建相比，GSC框架将无线构建延迟减少了92.6%，同时提高了元宇宙对象状态的准确性和观看体验，分别提升了45.6%和44.7%。&lt;h4&gt;结论&lt;/h4&gt;GSC框架通过优化传输和语义去噪，有效提高了元宇宙的通信效率和实时性。&lt;h4&gt;总结&lt;/h4&gt;本研究为元宇宙的高效通信提供了新思路，显著改善了用户体验和系统性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of the metaverse has boosted productivity and creativity,driving real-time updates and personalized content, which will substantiallyincrease data traffic. However, current bit-oriented communication networksstruggle to manage this high volume of dynamic information, restrictingmetaverse applications interactivity. To address this research gap, we proposea goal-oriented semantic communication (GSC) framework for metaverse. Buildingon an existing metaverse wireless construction task, our proposed GSC frameworkincludes an hourglass network-based (HgNet) encoder to extract semanticinformation of objects in the metaverse; and a semantic decoder that uses thisextracted information to reconstruct the metaverse content after wirelesstransmission, enabling efficient communication and real-time object behaviourupdates to the scenery for metaverse construction task. To overcome thewireless channel noise at the receiver, we design an optimal transport(OT)-enabled semantic denoiser, which enhances the accuracy of metaversescenery through wireless communication. Experimental results show that comparedto the conventional metaverse construction, our proposed GSC frameworksignificantly reduces wireless metaverse construction latency by 92.6\%, whileimproving metaverse object status accuracy and viewing experience by 45.6\% and44.7\%, respectively.</description>
      <author>example@mail.com (Zhe Wang, Nan Li, Yansha Deng, A. Hamid Aghvami)</author>
      <guid isPermaLink="false">2411.16187v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>STDWeb: Simple Transient Detection pipeline for the Web</title>
      <link>http://arxiv.org/abs/2411.16470v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 9 figures, 2 tables. Accepted to Acta Polytechnica&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;开发了一种简单的基于网络的工具STDWeb，用于天文图像的快速光度测量和瞬态检测。&lt;h4&gt;目的&lt;/h4&gt;实现一个自洽且主要自动化的数据分析工作流程，适用于任何上传的图像。&lt;h4&gt;方法&lt;/h4&gt;工具允许进行基本的交互式掩蔽、目标检测、天体测量校准，并建立光度解决方案，支持多种目录和滤光片。&lt;h4&gt;主要发现&lt;/h4&gt;可以使用用户提供或自动下载的模板图像进行图像减法，并对指定目标进行强制光度测量，以及进行瞬态检测，基本排除伪影。&lt;h4&gt;结论&lt;/h4&gt;该工具易于部署，可与机器人望远镜或数据档案的基础设施集成，实现图像的轻松分析。&lt;h4&gt;总结&lt;/h4&gt;STDWeb提供了一种便捷的方式来处理和分析天文图像，适合自动化应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a simple web-based tool, STDWeb, for a quick-look photometry andtransient detection in astronomical images. It tries to implement aself-consistent and mostly automatic data analysis workflow that would work onany image uploaded to it, allowing to perform basic interactive masking, doobject detection, astrometrically calibrate the image, and build thephotometric solution based on a selection of catalogues and supported filters,optionally including the color term and positionally varying zero point. Italso allows you to do image subtraction using either user-provided orautomatically downloaded template images, and do a forced photometry for aspecified target in either original or difference images, as well as transientdetection with basic rejection of artefacts. The tool may be easily deployedallowing its integration into the infrastructure of robotic telescopes or dataarchives for effortless analysis of their images.</description>
      <author>example@mail.com (Sergey Karpov)</author>
      <guid isPermaLink="false">2411.16470v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Benchmark Dataset for Collaborative SLAM in Service Environments</title>
      <link>http://arxiv.org/abs/2411.14775v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures, Accepted to IEEE RA-L&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;服务环境日益多样化，单一机器人难以完成复杂任务，因此对多机器人系统的需求增加。&lt;h4&gt;目的&lt;/h4&gt;填补现有C-SLAM数据集中缺乏多样化室内服务环境的空白，推出新的多模态C-SLAM数据集。&lt;h4&gt;方法&lt;/h4&gt;使用NVIDIA Isaac Sim生成各种室内服务环境的数据，以模拟真实服务环境中的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;数据集中包含三种常见的室内服务环境（医院、办公室和仓库），每种环境都有动态对象和模拟真实服务机器人行为。&lt;h4&gt;结论&lt;/h4&gt;通过评估多种单机器人和多机器人SLAM方法，验证了该数据集的有效性，数据集可在GitHub上获取。&lt;h4&gt;总结&lt;/h4&gt;新数据集为多机器人在复杂室内服务环境中的SLAM研究提供了重要资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2024.3491415&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vision3d-lab/cse_dataset&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As service environments have become diverse, they have started to demandcomplicated tasks that are difficult for a single robot to complete. Thischange has led to an interest in multiple robots instead of a single robot.C-SLAM, as a fundamental technique for multiple service robots, needs to handlediverse challenges such as homogeneous scenes and dynamic objects to ensurethat robots operate smoothly and perform their tasks safely. However, existingC-SLAM datasets do not include the various indoor service environments with theaforementioned challenges. To close this gap, we introduce a new multi-modalC-SLAM dataset for multiple service robots in various indoor serviceenvironments, called C-SLAM dataset in Service Environments (CSE). We use theNVIDIA Isaac Sim to generate data in various indoor service environments withthe challenges that may occur in real-world service environments. By usingsimulation, we can provide accurate and precisely time-synchronized sensordata, such as stereo RGB, stereo depth, IMU, and ground truth (GT) poses. Weconfigure three common indoor service environments (Hospital, Office, andWarehouse), each of which includes various dynamic objects that perform motionssuitable to each environment. In addition, we drive three robots to mimic theactions of real service robots. Through these factors, we generate a morerealistic C-SLAM dataset for multiple service robots. We demonstrate ourdataset by evaluating diverse state-of-the-art single-robot SLAM andmulti-robot SLAM methods. Our dataset is available athttps://github.com/vision3d-lab/CSE_Dataset.</description>
      <author>example@mail.com (Harin Park, Inha Lee, Minje Kim, Hyungyu Park, Kyungdon Joo)</author>
      <guid isPermaLink="false">2411.14775v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI-enabled Digital Twins for 6G-enhanced Smart Cities</title>
      <link>http://arxiv.org/abs/2411.14222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;6G网络预计将支持自主车辆和智能城市等多种应用，但网络拓扑的快速扩展使得管理变得更加复杂，导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于生成AI的数字双胞胎方法，以应对6G无线网络管理中的复杂性和动态性。&lt;h4&gt;方法&lt;/h4&gt;通过优化公式区分不同网络场景，考虑无线网络的关键性能指标(KPIs)，并利用历史和实时双胞胎数据生成所需的网络拓扑。&lt;h4&gt;主要发现&lt;/h4&gt;在高设备密度场景下，所提出的方法能实现38%的网络吞吐量稳定性提升，生成的场景准确度最高可达98%，超越基准。&lt;h4&gt;结论&lt;/h4&gt;生成AI驱动的数字双胞胎能够有效提高6G网络的性能，满足复杂应用场景的需求。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种新颖的方法来优化和管理6G网络，显著提高了网络性能和场景生成的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 6G networks are envisioned to enable a wide range of applications, such asautonomous vehicles and smart cities. However, this rapid expansion of networktopologies makes the management of 6G wireless networks more complex and leadsto performance degradation. Even though state-of-the-art applications onnetwork services are providing promising results, they also risk disrupting thenetwork's performance. To overcome this, the services have to leverage what-ifimplementations covering a variety of scenarios. At this point, traditionalsimulations fall short of encompassing the dynamism and complexity of aphysical network. To overcome these challenges, we propose the GenerativeAI-based Digital Twins. For this, we derive an optimization formula todifferentiate different network scenarios by considering the specific keyperformance indicators (KPIs) for wireless networks. Then, we fed this formulato the generative AI with the historical twins and real-time twins to startgenerating the desired topologies. To evaluate the performance, we implementnetwork and smart-city-oriented services, namely massive connectivity, tinyinstant communication, right-time synchronization, and truck path routes. Thesimulation results reveal that our approach can achieve 38% more stable networkthroughput in high device density scenarios. Furthermore, the generatedscenario accuracy is able to reach up to 98% level, surpassing the baselines.</description>
      <author>example@mail.com (Kubra Duran, Lal Verda Cakir, Mehmet Ozdem, Kerem Gursu, Berk Canberk)</author>
      <guid isPermaLink="false">2411.14222v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SPARS3R: Semantic Prior Alignment and Regularization for Sparse 3D Reconstruction</title>
      <link>http://arxiv.org/abs/2411.12592v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于高斯斑点的新的视图合成在光线真实感渲染方面取得了进展，但在稀疏视图场景中能力有限，主要由于稀疏初始化和过拟合漂浮物的问题。&lt;h4&gt;目的&lt;/h4&gt;提出SPARS3R，结合运动结构中的准确姿态估计和深度估计中的稠密点云的优势。&lt;h4&gt;方法&lt;/h4&gt;SPARS3R首先进行全局融合对齐，将先前的稠密点云映射到基于运动结构的稀疏点云，并使用RANSAC区分内点和外点。随后，进行语义外点对齐，提取外点周围的语义一致区域并在这些区域内进行局部对齐。&lt;h4&gt;主要发现&lt;/h4&gt;SPARS3R可以在稀疏图像下实现光线真实感渲染，并显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过改进评估过程，SPARS3R在稀疏视图合成中展示了更好的性能。&lt;h4&gt;总结&lt;/h4&gt;SPARS3R利用结构-运动中的准确姿态估计和深度估计的稠密点云，克服了稀疏视图场景中的限制，实现了优越的渲染效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/snldmt/SPARS3R&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent efforts in Gaussian-Splat-based Novel View Synthesis can achievephotorealistic rendering; however, such capability is limited in sparse-viewscenarios due to sparse initialization and over-fitting floaters. Recentprogress in depth estimation and alignment can provide dense point cloud withfew views; however, the resulting pose accuracy is suboptimal. In this work, wepresent SPARS3R, which combines the advantages of accurate pose estimation fromStructure-from-Motion and dense point cloud from depth estimation. To this end,SPARS3R first performs a Global Fusion Alignment process that maps a priordense point cloud to a sparse point cloud from Structure-from-Motion based ontriangulated correspondences. RANSAC is applied during this process todistinguish inliers and outliers. SPARS3R then performs a second, SemanticOutlier Alignment step, which extracts semantically coherent regions around theoutliers and performs local alignment in these regions. Along with severalimprovements in the evaluation process, we demonstrate that SPARS3R can achievephotorealistic rendering with sparse images and significantly outperformsexisting approaches.</description>
      <author>example@mail.com (Yutao Tang, Yuxiang Guo, Deming Li, Cheng Peng)</author>
      <guid isPermaLink="false">2411.12592v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Safety-Critical Controller Synthesis with Reduced-Order Models</title>
      <link>http://arxiv.org/abs/2411.16479v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;降低阶模型（ROMs）提供了复杂系统的低维表示，捕捉其显著特征，同时简化控制设计。&lt;h4&gt;目的&lt;/h4&gt;提出一个整合ROM和控制边界函数的框架，以便使用简化模型构建安全关键控制器，并为复杂的全阶模型提供安全保障。&lt;h4&gt;方法&lt;/h4&gt;通过定义投影映射形式化全阶模型与ROM之间的联系，利用仿真函数建立从ROM到其对应全阶模型的安全保障转移条件。&lt;h4&gt;主要发现&lt;/h4&gt;通过对无人机的仿真结果和ARCHER三维跳跃机器人上的硬件演示验证了框架的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架能够有效地将安全保障从降低阶模型转移到复杂全阶模型。&lt;h4&gt;总结&lt;/h4&gt;该研究为复杂系统的安全控制设计提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reduced-order models (ROMs) provide lower dimensional representations ofcomplex systems, capturing their salient features while simplifying controldesign. Building on previous work, this paper presents an overarching frameworkfor the integration of ROMs and control barrier functions, enabling the use ofsimplified models to construct safety-critical controllers while providingsafety guarantees for complex full-order models. To achieve this, we formalizethe connection between full and ROMs by defining projection mappings thatrelate the states and inputs of these models and leverage simulation functionsto establish conditions under which safety guarantees may be transferred from aROM to its corresponding full-order model. The efficacy of our framework isillustrated through simulation results on a drone and hardware demonstrationson ARCHER, a 3D hopping robot.</description>
      <author>example@mail.com (Max H. Cohen, Noel Csomay-Shanklin, William D. Compton, Tamas G. Molnar, Aaron D. Ames)</author>
      <guid isPermaLink="false">2411.16479v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Characterized Diffusion Networks for Enhanced Autonomous Driving Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2411.16457v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 0 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究针对动态和异构交通环境中的轨迹预测问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的轨迹预测模型，以提高自动驾驶中的预测准确性和可靠性。&lt;h4&gt;方法&lt;/h4&gt;结合特征扩散模块和时空交互网络，融入不确定性估计和复杂代理交互。&lt;h4&gt;主要发现&lt;/h4&gt;在公共数据集（如NGSIM、HighD和MoCAD）上的广泛实验中，该模型显著超越了现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;模型能够有效捕捉交通场景中的时空动态，尤其是在复杂环境中提高预测精度。&lt;h4&gt;总结&lt;/h4&gt;提出的模型在实际自动驾驶系统中展示了强大的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a novel trajectory prediction model for autonomousdriving, combining a Characterized Diffusion Module and a Spatial-TemporalInteraction Network to address the challenges posed by dynamic andheterogeneous traffic environments. Our model enhances the accuracy andreliability of trajectory predictions by incorporating uncertainty estimationand complex agent interactions. Through extensive experimentation on publicdatasets such as NGSIM, HighD, and MoCAD, our model significantly outperformsexisting state-of-the-art methods. We demonstrate its ability to capture theunderlying spatial-temporal dynamics of traffic scenarios and improveprediction precision, especially in complex environments. The proposed modelshowcases strong potential for application in real-world autonomous drivingsystems.</description>
      <author>example@mail.com (Haoming Li)</author>
      <guid isPermaLink="false">2411.16457v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Responsible forecasting: identifying and typifying forecasting harms</title>
      <link>http://arxiv.org/abs/2411.16531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数据驱动的组织利用预测方法来改善规划和决策能力，但关于时间序列预测的伦理影响的研究相对较少。&lt;h4&gt;目的&lt;/h4&gt;开发一个针对预测特定伤害的新分类法，以填补该领域的知识空白，并促进对预测过程中的伦理反思。&lt;h4&gt;方法&lt;/h4&gt;通过与行业专家和学术研究者的多次访谈，整理和分析未被充分探讨的预测领域、应用和场景。&lt;h4&gt;主要发现&lt;/h4&gt;识别出在预测过程中可能发生的独特伤害形式，并提出了一个以人为主导的归纳编码方案与AI驱动的分析相结合的方法。&lt;h4&gt;结论&lt;/h4&gt;该分类法旨在指导研究人员和从业者，提高他们在预测过程中的伦理意识，并为未来的研究议程奠定基础。&lt;h4&gt;总结&lt;/h4&gt;本研究扩展了关于机器学习伤害的文献，强调了时间序列预测中可能出现的特定伦理问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven organizations around the world routinely use forecasting methodsto improve their planning and decision-making capabilities. Although muchresearch exists on the harms resulting from traditional machine learningapplications, little has specifically focused on the ethical impact of timeseries forecasting. Yet forecasting raises unique ethical issues due to the wayit is used in different organizational contexts, supports different goals, andinvolves different data processing, model development, and evaluationpipelines. These differences make it difficult to apply machine learning harmtaxonomies to common forecasting contexts. We leverage multiple interviews withexpert industry practitioners and academic researchers to remedy this knowledgegap by cataloguing and analysing under-explored domains, applications, andscenarios where forecasting may cause harm, with the goal of developing a noveltaxonomy of forecasting-specific harms. Inspired by Microsoft Azure taxonomyfor responsible innovation, we combined a human-led inductive coding schemewith an AI-driven analysis centered on the extraction of key taxonomies of harmin forecasting. The taxonomy is designed to guide researchers and practitionersand encourage ethical reflection on the impact of their decisions during theforecasting process. A secondary objective is to create a research agendafocused on possible forecasting-related measures to mitigate harm. Our workextends the growing literature on machine learning harms by identifying uniqueforms of harm that may occur in forecasting.</description>
      <author>example@mail.com (Bahman Rostami-Tabar, Travis Greene, Galit Shmueli, Rob J. Hyndman)</author>
      <guid isPermaLink="false">2411.16531v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>OVO-SLAM: Open-Vocabulary Online Simultaneous Localization and Mapping</title>
      <link>http://arxiv.org/abs/2411.15043v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文提出了首个开放词汇在线3D语义SLAM管道，称为OVO-SLAM。&lt;h4&gt;目的&lt;/h4&gt;研究并改进在线3D语义SLAM的映射线程。&lt;h4&gt;方法&lt;/h4&gt;通过从RGB-D帧中检测和跟踪3D段，使用CLIP向量对其进行描述，并通过新颖的聚合方法计算这些向量。&lt;h4&gt;主要发现&lt;/h4&gt;OVO-SLAM在速度和分割指标上优于文献中的离线方法。&lt;h4&gt;结论&lt;/h4&gt;在不依赖真实相机位姿或场景几何的情况下，首次展示了端到端的开放词汇在线3D重建。&lt;h4&gt;总结&lt;/h4&gt;OVO-SLAM实现了更快的处理速度和更好的分割性能，推动了在线3D重建技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the first Open-Vocabulary Online 3D semantic SLAMpipeline, that we denote as OVO-SLAM. Our primary contribution is in thepipeline itself, particularly in the mapping thread. Given a set of posed RGB-Dframes, we detect and track 3D segments, which we describe using CLIP vectors,calculated through a novel aggregation from the viewpoints where these 3Dsegments are observed. Notably, our OVO-SLAM pipeline is not only faster butalso achieves better segmentation metrics compared to offline approaches in theliterature. Along with superior segmentation performance, we show experimentalresults of our contributions integrated with Gaussian-SLAM, being the firstones demonstrating end-to-end open-vocabulary online 3D reconstructions withoutrelying on ground-truth camera poses or scene geometry.</description>
      <author>example@mail.com (Tomas Berriel Martins, Martin R. Oswald, Javier Civera)</author>
      <guid isPermaLink="false">2411.15043v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Q-CSM: Q-Learning-based Cognitive Service Management in Heterogeneous IoT Networks</title>
      <link>http://arxiv.org/abs/2411.14281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能服务数量和多样性的急剧增加在物联网（IoT）网络中带来了异构性挑战，导致服务质量（QoS）显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Q学习的认知服务管理框架Q-CSM，以解决IoT网络中的异构性和QoS问题。&lt;h4&gt;方法&lt;/h4&gt;设计一个IoT代理管理器处理数据格式异构性，并建立一个基于Q学习的推荐引擎，根据预测的QoS行为优化设备的使用寿命。&lt;h4&gt;主要发现&lt;/h4&gt;在智能城市场景中，所提出的认知方法在动态IoT拓扑变化中响应时间提高了38.7%，对受限IoT设备的平均使用寿命延长了19.8%。&lt;h4&gt;结论&lt;/h4&gt;Q-CSM框架通过Q学习的认知决策能力，有效应对了IoT网络的复杂性和异构性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的框架能够提升IoT设备的性能和寿命，为未来智能服务的发展提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The dramatic increase in the number of smart services and their diversityposes a significant challenge in Internet of Things (IoT) networks:heterogeneity. This causes significant quality of service (QoS) degradation inIoT networks. In addition, the constraints of IoT devices in terms ofcomputational capability and energy resources add extra complexity to this.However, the current studies remain insufficient to solve this problem due tothe lack of cognitive action recommendations. Therefore, we propose aQ-learning-based Cognitive Service Management framework called Q-CSM. In thisframework, we first design an IoT Agent Manager to handle the heterogeneity indata formats. After that, we design a Q-learning-based recommendation engine tooptimize the devices' lifetime according to the predicted QoS behaviour of thechanging IoT network scenarios. We apply the proposed cognitive management to asmart city scenario consisting of three specific services: wind turbines, solarpanels, and transportation systems. We note that our proposed cognitive methodachieves 38.7% faster response time to the dynamical IoT changes in topology.Furthermore, the proposed framework achieves 19.8% longer lifetime on averagefor constrained IoT devices thanks to its Q-learning-based cognitive decisioncapability. In addition, we explore the most successive learning rate value inthe Q-learning run through the exploration and exploitation phases.</description>
      <author>example@mail.com (Kubra Duran, Mehmet Ozdem, Kerem Gursu, Berk Canberk)</author>
      <guid isPermaLink="false">2411.14281v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Use-Inspired Mobile Robot to Improve Safety of Building Retrofit Workforce in Constrained Spaces</title>
      <link>http://arxiv.org/abs/2411.16511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 Pages, 7 Figures. Accepted for publication in the Proceedings of
  2024 IEEE International Symposium on Safety, Security, and Rescue Robotics
  (SSRR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;检查限制性关键基础设施（如阁楼或爬行空间）对人类操作员来说具有挑战性，原因包括任务空间不足、可见性有限和存在有害材料。&lt;h4&gt;目的&lt;/h4&gt;介绍PARIS（针对难以进入空间的精确应用机器人）的原型，这是一个为此类环境设计的遥操作移动机器人手臂系统。&lt;h4&gt;方法&lt;/h4&gt;PARIS系统经过构思、开发和测试，并被选为美国能源部E-ROBOT奖的第一阶段获奖者。&lt;h4&gt;主要发现&lt;/h4&gt;PARIS平台支持遥操作的映射与导航，便于人类操作员探索紧凑空间；提供检查和传感功能，以识别和定位绝缘不良区域；并通过密封漏气的缝隙和裂缝来提高建筑的热效率。&lt;h4&gt;结论&lt;/h4&gt;该平台具有多功能性，可以针对有限空间中的处理和修复进行定制应用。&lt;h4&gt;总结&lt;/h4&gt;PARIS机器人系统为改善建筑热效率提供了有效的解决方案，能够在限制空间内进行详细检查和修复工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The inspection of confined critical infrastructure such as attics orcrawlspaces is challenging for human operators due to insufficient task space,limited visibility, and the presence of hazardous materials. This paperintroduces a prototype of PARIS (Precision Application Robot for InaccessibleSpaces): a use-inspired teleoperated mobile robot manipulator system that wasconceived, developed, and tested for and selected as a Phase I winner of theU.S. Department of Energy's E-ROBOT Prize. To improve the thermal efficiency ofbuildings, the PARIS platform supports: 1) teleoperated mapping and navigation,enabling the human operator to explore compact spaces; 2) inspection andsensing, facilitating the identification and localization of under-insulatedareas; and 3) air-sealing targeted gaps and cracks through which thermal energyis lost. The resulting versatile platform can also be tailored for targetedapplication of treatments and remediation in constrained spaces.</description>
      <author>example@mail.com (Smruti Suresh, Michael Angelo Carvajal, Nathaniel Hanson, Ethan Holand, Samuel Hibbard, Taskin Padir)</author>
      <guid isPermaLink="false">2411.16511v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DATAP-SfM: Dynamic-Aware Tracking Any Point for Robust Structure from Motion in the Wild</title>
      <link>http://arxiv.org/abs/2411.13291v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统框架通过计算相邻帧之间的光流来获取点轨迹，但这种方法容易引入累积误差。&lt;h4&gt;目的&lt;/h4&gt;提出一种简洁、优雅且稳健的管道，用于估计平滑的相机轨迹和获取稠密点云。&lt;h4&gt;方法&lt;/h4&gt;提出了一种动态感知的点追踪方法（DATAP），利用一致的视频深度和点追踪，估计整个视频序列中的稠密点追踪，并预测每个点的可见性和动态变化。&lt;h4&gt;主要发现&lt;/h4&gt;在动态序列和真实视频中进行的广泛实验表明，该方法在相机姿态估计方面达到了最新的性能。&lt;h4&gt;结论&lt;/h4&gt;通过整合DATAP，能够同时估计和优化所有相机姿态，从而在复杂动态场景中表现出色。&lt;h4&gt;总结&lt;/h4&gt;该研究有效解决了传统方法中的光流估计和运动分割问题，提升了动态视频处理的精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a concise, elegant, and robust pipeline to estimatesmooth camera trajectories and obtain dense point clouds for casual videos inthe wild. Traditional frameworks, such asParticleSfM~\cite{zhao2022particlesfm}, address this problem by sequentiallycomputing the optical flow between adjacent frames to obtain pointtrajectories. They then remove dynamic trajectories through motion segmentationand perform global bundle adjustment. However, the process of estimatingoptical flow between two adjacent frames and chaining the matches can introducecumulative errors. Additionally, motion segmentation combined with single-viewdepth estimation often faces challenges related to scale ambiguity. To tacklethese challenges, we propose a dynamic-aware tracking any point (DATAP) methodthat leverages consistent video depth and point tracking. Specifically, ourDATAP addresses these issues by estimating dense point tracking across thevideo sequence and predicting the visibility and dynamics of each point. Byincorporating the consistent video depth prior, the performance of motionsegmentation is enhanced. With the integration of DATAP, it becomes possible toestimate and optimize all camera poses simultaneously by performing globalbundle adjustments for point tracking classified as static and visible, ratherthan relying on incremental camera registration. Extensive experiments ondynamic sequences, e.g., Sintel and TUM RGBD dynamic sequences, and on the wildvideo, e.g., DAVIS, demonstrate that the proposed method achievesstate-of-the-art performance in terms of camera pose estimation even in complexdynamic challenge scenes.</description>
      <author>example@mail.com (Weicai Ye, Xinyu Chen, Ruohao Zhan, Di Huang, Xiaoshui Huang, Haoyi Zhu, Hujun Bao, Wanli Ouyang, Tong He, Guofeng Zhang)</author>
      <guid isPermaLink="false">2411.13291v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Online Guidance Graph Optimization for Lifelong Multi-Agent Path Finding</title>
      <link>http://arxiv.org/abs/2411.16506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多智能体路径规划（MAPF）旨在让多个智能体从起点移动到目标点而不发生碰撞，其终身变种（LMAPF）不断为智能体分配新目标。&lt;h4&gt;目的&lt;/h4&gt;优化一种指导策略，以动态引导智能体在基于实时交通模式的终身多智能体路径规划中。&lt;h4&gt;方法&lt;/h4&gt;通过优化一种策略生成自适应指导，设计了两条管道在PIBT算法中以不同方式引入指导。&lt;h4&gt;主要发现&lt;/h4&gt;优化后的策略在解决方案质量上优于静态指导和人类设计的策略。&lt;h4&gt;结论&lt;/h4&gt;探索了任务分配随时间变化的场景，这是一个在实际应用中常见但文献中很少探讨的挑战。&lt;h4&gt;总结&lt;/h4&gt;本研究通过优化指导策略，提高了终身多智能体路径规划的性能，特别是在动态任务分配的环境中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of optimizing a guidance policy capable of dynamicallyguiding the agents for lifelong Multi-Agent Path Finding based on real-timetraffic patterns. Multi-Agent Path Finding (MAPF) focuses on moving multipleagents from their starts to goals without collisions. Its lifelong variant,LMAPF, continuously assigns new goals to agents. In this work, we focus onimproving the solution quality of PIBT, a state-of-the-art rule-based LMAPFalgorithm, by optimizing a policy to generate adaptive guidance. We design twopipelines to incorporate guidance in PIBT in two different ways. We demonstratethe superiority of the optimized policy over both static guidance andhuman-designed policies. Additionally, we explore scenarios where taskdistribution changes over time, a challenging yet common situation inreal-world applications that is rarely explored in the literature.</description>
      <author>example@mail.com (Hongzhi Zang, Yulun Zhang, He Jiang, Zhe Chen, Daniel Harabor, Peter J. Stuckey, Jiaoyang Li)</author>
      <guid isPermaLink="false">2411.16506v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MarketGPT: Developing a Pre-trained transformer (GPT) for Modeling Financial Time Series</title>
      <link>http://arxiv.org/abs/2411.16585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究提出了一种生成式预训练变换器（GPT），用于建模金融时间序列。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够在离散事件模拟器中作为订单生成引擎的模型，以实现限价订单簿动态的真实复制。&lt;h4&gt;方法&lt;/h4&gt;模型利用最新的大型语言模型进展，以流式方式生成长序列的订单消息。&lt;h4&gt;主要发现&lt;/h4&gt;模型成功再现了订单流数据的关键特征，即使初始订单流提示不再位于模型的上下文窗口中。&lt;h4&gt;结论&lt;/h4&gt;评估结果显示，模型捕捉到了多个统计特性或“风格化事实”，这些特性是现实金融市场和更广泛宏观数据分布的典型特征。&lt;h4&gt;总结&lt;/h4&gt;本研究标志着向创建高保真、互动市场模拟的重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents a generative pre-trained transformer (GPT) designed formodeling financial time series. The GPT functions as an order generation enginewithin a discrete event simulator, enabling realistic replication of limitorder book dynamics. Our model leverages recent advancements in large languagemodels to produce long sequences of order messages in a steaming manner. Ourresults demonstrate that the model successfully reproduces key features oforder flow data, even when the initial order flow prompt is no longer presentwithin the model's context window. Moreover, evaluations reveal that the modelcaptures several statistical properties, or 'stylized facts', characteristic ofreal financial markets and broader macro-scale data distributions.Collectively, this work marks a significant step toward creating high-fidelity,interactive market simulations.</description>
      <author>example@mail.com (Aaron Wheeler, Jeffrey D. Varner)</author>
      <guid isPermaLink="false">2411.16585v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Context-Aware Detection of Mixed Critical Events using Video Classification</title>
      <link>http://arxiv.org/abs/2411.15773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;通过计算机视觉检测混合关键事件具有挑战性，需要上下文理解以准确评估事件的关键性。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于智能城市应用的多功能检测系统。&lt;h4&gt;方法&lt;/h4&gt;系统在交通和火灾检测场景中进行了测试，分析了检测需求。&lt;h4&gt;主要发现&lt;/h4&gt;开发的系统能够适应多种应用，推动智能城市的自动化监控。&lt;h4&gt;结论&lt;/h4&gt;该系统为应对不同严重程度的事件提供了解决方案，能够触发适当的响应。&lt;h4&gt;总结&lt;/h4&gt;研究为智能城市的混合关键事件检测提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting mixed-critical events through computer vision is challenging due tothe need for contextual understanding to assess event criticality accurately.Mixed critical events, such as fires of varying severity or traffic incidents,demand adaptable systems that can interpret context to trigger appropriateresponses. This paper addresses these challenges by proposing a versatiledetection system for smart city applications, offering a solution tested acrosstraffic and fire detection scenarios. Our contributions include an analysis ofdetection requirements and the development of a system adaptable to diverseapplications, advancing automated surveillance for smart cities.</description>
      <author>example@mail.com (Filza Akhlaq, Alina Arshad, Muhammad Yehya Hayati, Jawwad A. Shamsi, Muhammad Burhan Khan)</author>
      <guid isPermaLink="false">2411.15773v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Gassidy: Gaussian Splatting SLAM in Dynamic Environments</title>
      <link>http://arxiv.org/abs/2411.15476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is currently under reviewed for ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting (3DGS) 允许对场景表示进行灵活调整，但在处理动态物体带来的环境干扰时面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种名为Gassidy的RGB-D密集SLAM方法，以应对动态环境中的挑战。&lt;h4&gt;方法&lt;/h4&gt;该方法基于设计的光度-几何损失函数计算高斯，并为每个环境组件生成渲染损失流，迭代分析损失流以识别和过滤环境干扰。&lt;h4&gt;主要发现&lt;/h4&gt;Gassidy在公开数据集上的实验结果表明，其相机跟踪精度提高了最高97.9%，地图质量提升了最高6%。&lt;h4&gt;结论&lt;/h4&gt;Gassidy有效地提高了静态环境中密集视觉SLAM的性能，确保了准确的场景重建。&lt;h4&gt;总结&lt;/h4&gt;通过改进动态环境下的SLAM技术，Gassidy为场景重建提供了更高的精度和质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) allows flexible adjustments to scenerepresentation, enabling continuous optimization of scene quality during densevisual simultaneous localization and mapping (SLAM) in static environments.However, 3DGS faces challenges in handling environmental disturbances fromdynamic objects with irregular movement, leading to degradation in both cameratracking accuracy and map reconstruction quality. To address this challenge, wedevelop an RGB-D dense SLAM which is called Gaussian Splatting SLAM in DynamicEnvironments (Gassidy). This approach calculates Gaussians to generaterendering loss flows for each environmental component based on a designedphotometric-geometric loss function. To distinguish and filter environmentaldisturbances, we iteratively analyze rendering loss flows to detect featurescharacterized by changes in loss values between dynamic objects and staticcomponents. This process ensures a clean environment for accurate scenereconstruction. Compared to state-of-the-art SLAM methods, experimental resultson open datasets show that Gassidy improves camera tracking precision by up to97.9% and enhances map quality by up to 6%.</description>
      <author>example@mail.com (Long Wen, Shixin Li, Yu Zhang, Yuhong Huang, Jianjie Lin, Fengjunjie Pan, Zhenshan Bing, Alois Knoll)</author>
      <guid isPermaLink="false">2411.15476v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Few-Shot Learning with Integrated Data and GAN Model Approaches</title>
      <link>http://arxiv.org/abs/2411.16567v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统机器学习模型需要大量数据，尤其在药物发现、目标识别和恶意流量检测等领域存在重要限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种创新的方法，通过数据增强与模型微调结合，提升小样本学习的效果。&lt;h4&gt;方法&lt;/h4&gt;利用生成对抗网络(GAN)和先进的优化技术，结合马尔可夫链蒙特卡洛(MCMC)采样和判别模型集成策略，改善模型在有限数据下的表现。&lt;h4&gt;主要发现&lt;/h4&gt;提出的MhERGAN算法在小样本图像和结构化数据集上的分类性能显著提升，解决了数据增强方法引入的噪声和偏差问题。&lt;h4&gt;结论&lt;/h4&gt;MhERGAN算法为小样本学习提供了有效的解决方案，能够在数据稀缺的情况下实现高性能模型的适应性和泛化能力。&lt;h4&gt;总结&lt;/h4&gt;本研究通过结合数据增强和模型微调，提出了一种新策略，有效提升了小样本学习的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an innovative approach to enhancing few-shot learning byintegrating data augmentation with model fine-tuning in a framework designed totackle the challenges posed by small-sample data. Recognizing the criticallimitations of traditional machine learning models that require largedatasets-especially in fields such as drug discovery, target recognition, andmalicious traffic detection-this study proposes a novel strategy that leveragesGenerative Adversarial Networks (GANs) and advanced optimization techniques toimprove model performance with limited data. Specifically, the paper addressesthe noise and bias issues introduced by data augmentation methods, contrastingthem with model-based approaches, such as fine-tuning and metric learning,which rely heavily on related datasets. By combining Markov Chain Monte Carlo(MCMC) sampling and discriminative model ensemble strategies within a GANframework, the proposed model adjusts generative and discriminativedistributions to simulate a broader range of relevant data. Furthermore, itemploys MHLoss and a reparameterized GAN ensemble to enhance stability andaccelerate convergence, ultimately leading to improved classificationperformance on small-sample images and structured datasets. Results confirmthat the MhERGAN algorithm developed in this research is highly effective forfew-shot learning, offering a practical solution that bridges data scarcitywith high-performing model adaptability and generalization.</description>
      <author>example@mail.com (Yinqiu Feng, Aoran Shen, Jiacheng Hu, Yingbin Liang, Shiru Wang, Junliang Du)</author>
      <guid isPermaLink="false">2411.16567v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics</title>
      <link>http://arxiv.org/abs/2411.16537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;空间理解是机器人在环境中做出基于实际情况决策的重要能力，涉及对周围环境的感知和合理互动。&lt;h4&gt;目的&lt;/h4&gt;提出RoboSpatial数据集，以解决现有视觉语言模型在空间推理中的挑战。&lt;h4&gt;方法&lt;/h4&gt;RoboSpatial是一个大规模空间理解数据集，包含实室内和桌面场景的3D扫描和自我中心图像，附带丰富的空间信息注释。&lt;h4&gt;主要发现&lt;/h4&gt;RoboSpatial数据集包含100万张图像、5000个3D扫描和300万个注释的空间关系，能够支持2D和3D的应用。&lt;h4&gt;结论&lt;/h4&gt;使用RoboSpatial训练的模型在空间可用性预测、空间关系预测和机器人操作等下游任务上表现优于基线模型。&lt;h4&gt;总结&lt;/h4&gt;RoboSpatial数据集为机器人提供了必要的空间理解能力，有助于提升其在复杂环境中的决策和互动能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial understanding is a crucial capability for robots to make groundeddecisions based on their environment. This foundational skill enables robotsnot only to perceive their surroundings but also to reason about and interactmeaningfully within the world. In modern robotics, these capabilities are takenon by visual language models, and they face significant challenges when appliedto spatial reasoning context due to their training data sources. These sourcesutilize general-purpose image datasets, and they often lack sophisticatedspatial scene understanding capabilities. For example, the datasets do notaddress reference frame comprehension - spatial relationships require clearcontextual understanding, whether from an ego-centric, object-centric, orworld-centric perspective, which allow for effective real-world interaction. Toaddress this issue, we introduce RoboSpatial, a large-scale spatialunderstanding dataset consisting of real indoor and tabletop scenes captured as3D scans and egocentric images, annotated with rich spatial informationrelevant to robotics. The dataset includes 1M images, 5K 3D scans, and 3Mannotated spatial relationships, with paired 2D egocentric images and 3D scansto make it both 2D and 3D ready. Our experiments show that models trained withRoboSpatial outperform baselines on downstream tasks such as spatial affordanceprediction, spatial relationship prediction, and robotics manipulation.</description>
      <author>example@mail.com (Chan Hee Song, Valts Blukis, Jonathan Tremblay, Stephen Tyree, Yu Su, Stan Birchfield)</author>
      <guid isPermaLink="false">2411.16537v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CatNet: Effective FDR Control in LSTM with Gaussian Mirrors and SHAP Feature Importance</title>
      <link>http://arxiv.org/abs/2411.16666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了一种算法CatNet，旨在有效控制假发现率(FDR)并选择LSTM中的重要特征。&lt;h4&gt;目的&lt;/h4&gt;评估LSTM在时间序列中的特征重要性，并优化特征选择过程。&lt;h4&gt;方法&lt;/h4&gt;引入Gaussian Mirror(GM)方法和SHapley Additive exPlanations(SHAP)的导数向量，提出新的基于核的依赖度量以避免多重共线性。&lt;h4&gt;主要发现&lt;/h4&gt;CatNet在不同线性模型和LSTM模型中有效控制FDR，同时保持高统计功效。在低维和高维情况下均表现出强大的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;CatNet在实际应用中表现出比传统LSTM模型更高的预测准确性，能够有效捕捉市场驱动特征，增强金融市场决策的可解释性。&lt;h4&gt;创新点&lt;/h4&gt;首次将Gaussian Mirror算法与LSTM模型结合，提出SHAP值作为新特征重要性指标，标志着神经网络特征选择和误差控制的重要进展。&lt;h4&gt;总结&lt;/h4&gt;CatNet在特征选择和FDR控制方面提供了新的方法，增强了模型的解释能力和预测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce CatNet, an algorithm that effectively controls False DiscoveryRate (FDR) and selects significant features in LSTM with the Gaussian Mirror(GM) method. To evaluate the feature importance of LSTM in time series, weintroduce a vector of the derivative of the SHapley Additive exPlanations(SHAP) to measure feature importance. We also propose a new kernel-baseddependence measure to avoid multicollinearity in the GM algorithm, to make arobust feature selection with controlled FDR. We use simulated data to evaluateCatNet's performance in both linear models and LSTM models with different linkfunctions. The algorithm effectively controls the FDR while maintaining a highstatistical power in all cases. We also evaluate the algorithm's performance indifferent low-dimensional and high-dimensional cases, demonstrating itsrobustness in various input dimensions. To evaluate CatNet's performance inreal world applications, we construct a multi-factor investment portfolio toforecast the prices of S\&amp;P 500 index components. The results demonstrate thatour model achieves superior predictive accuracy compared to traditional LSTMmodels without feature selection and FDR control. Additionally, CatNeteffectively captures common market-driving features, which helps informeddecision-making in financial markets by enhancing the interpretability ofpredictions. Our study integrates of the Gaussian Mirror algorithm with LSTMmodels for the first time, and introduces SHAP values as a new featureimportance metric for FDR control methods, marking a significant advancement infeature selection and error control for neural networks.</description>
      <author>example@mail.com (Jiaan Han, Junxiao Chen, Yanzhe Fu)</author>
      <guid isPermaLink="false">2411.16666v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Model-based Decision-making for COLREGs and the Control of Autonomous Surface Vehicles</title>
      <link>http://arxiv.org/abs/2411.16587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在自主水面车辆（ASVs）领域，制定符合海事COLREGs（碰撞规章）的决策和避障方案一直是一个紧迫的挑战。&lt;h4&gt;目的&lt;/h4&gt;展示基于大语言模型（LLMs）的决策和控制在ASVs中的首次应用。&lt;h4&gt;方法&lt;/h4&gt;建立一个高层决策者，使用在线碰撞风险指标和关键测量进行安全机动决策，并开发了支持训练和实时动作生成的设计和运行结构。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能够在线保持COLREGs合规，准确跟踪航点，并提供每个决策的人类可解释的推理。&lt;h4&gt;结论&lt;/h4&gt;这是首次将可解释的人工智能应用于遵循COLREGs规则的动态控制问题，为这一挑战性领域的研究开辟了新方向。&lt;h4&gt;总结&lt;/h4&gt;研究结果表明，该系统在多个测试场景中表现出良好的控制和决策能力，具有人类可理解的解释。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of autonomous surface vehicles (ASVs), devising decision-makingand obstacle avoidance solutions that address maritime COLREGs (CollisionRegulations), primarily defined for human operators, has long been a pressingchallenge. Recent advancements in explainable Artificial Intelligence (AI) andmachine learning have shown promise in enabling human-like decision-making.Notably, significant developments have occurred in the application of LargeLanguage Models (LLMs) to the decision-making of complex systems, such asself-driving cars. The textual and somewhat ambiguous nature of COLREGs (froman algorithmic perspective), however, poses challenges that align well with thecapabilities of LLMs, suggesting that LLMs may become increasingly suitable forthis application soon. This paper presents and demonstrates the firstapplication of LLM-based decision-making and control for ASVs. The proposedmethod establishes a high-level decision-maker that uses online collision riskindices and key measurements to make decisions for safe manoeuvres. A tailoreddesign and runtime structure is developed to support training and real-timeaction generation on a realistic ASV model. Local planning and controlalgorithms are integrated to execute the commands for waypoint following andcollision avoidance at a lower level. To the authors' knowledge, this studyrepresents the first attempt to apply explainable AI to the dynamic controlproblem of maritime systems recognising the COLREGs rules, opening new avenuesfor research in this challenging area. Results obtained across multiple testscenarios demonstrate the system's ability to maintain online COLREGscompliance, accurate waypoint tracking, and feasible control, while providinghuman-interpretable reasoning for each decision.</description>
      <author>example@mail.com (Klinsmann Agyei, Pouria Sarhadi, Wasif Naeem)</author>
      <guid isPermaLink="false">2411.16587v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Characterizing Stellar and Gas Properties in NGC 628: Spatial Distributions, Radial Gradients, and Resolved Scaling Relations</title>
      <link>http://arxiv.org/abs/2411.16150v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 15 figures. Accepted for publication in the Astrophysical
  Journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于我们之前关于多波长数据（从紫外到红外）的研究，探讨星形成和化学富集的内在过程。&lt;h4&gt;目的&lt;/h4&gt;利用500米口径球面射电望远镜（FAST）的光谱观测，研究NGC 628中的电离气体和中性氢气体。&lt;h4&gt;方法&lt;/h4&gt;分析气相消光、星形成率（SFR）表面密度、氧丰度和H I质量表面密度等关键属性。&lt;h4&gt;主要发现&lt;/h4&gt;NGC 628是一个孤立的星系，没有经历近期相互作用；存在轻微的径向消光梯度和显著的分散；SFR表面密度呈现温和的径向梯度；发现负径向金属度梯度，为“内外”星系形成理论提供支持。&lt;h4&gt;结论&lt;/h4&gt;已解决的质量-金属度关系（MZR）与SFR表面密度或H I质量表面密度没有二次依赖关系；在已解决的SFMS中，气相消光和Hα等效宽度随着SFR表面密度的增加而增加。&lt;h4&gt;总结&lt;/h4&gt;本研究为理解NGC 628的星形成过程和化学演化提供了重要证据，支持了星系形成的内外部理论。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building on our previous research of multi-wavelength data from UV to IR, weemploy spectroscopic observations of ionized gas, as well as neutral hydrogengas obtained from the Five-hundred Meter Aperture Spherical Telescope (FAST),to explore the intrinsic processes of star formation and chemical enrichmentwithin NGC 628. Our analysis focuses on several key properties, includinggas-phase extinction, star formation rate (SFR) surface density, oxygenabundance, and H I mass surface density. The azimuthal distributions of theseparameters in relation to the morphological and kinematic features of FAST H Ireveal that NGC 628 is an isolated galaxy that has not undergone recentinteractions. We observe a mild radial extinction gradient accompanied by anotable dispersion. The SFR surface density also shows a gentle radialgradient, characteristic of typical spiral galaxies. Additionally, we find anegative radial metallicity gradient of $-0.44$ dex $R_{25}^{-1}$, supportingthe "inside-out" scenario of galaxy formation. We investigate the resolvedMass-Metallicity Relation (MZR) and the resolved Star Formation Main Sequence(SFMS) alongside their dependencies on the physical properties of both ionizedand neutral hydrogen gas. Our findings indicate no secondary dependency of theresolved MZR on SFR surface density or H I mass surface density. Furthermore,we observe that gas-phase extinction and the equivalent width of H{\alpha} bothincrease with SFR surface density in the resolved SFMS.</description>
      <author>example@mail.com (Peng Wei, Hu Zou, Jing Wang, Xu Kong, Shuguo Ma, Ruilei Zhou, Xu Zhou, Ali Esamdin, Jiantao Sun, Tuhong Zhong, Fei Dang)</author>
      <guid isPermaLink="false">2411.16150v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Near-Range Environmental Perception for Inland Waterway Vessels: A Comparative Study of LiDAR and Automotive FMCW RADAR Sensors</title>
      <link>http://arxiv.org/abs/2411.15901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 11 figues, conference, included in conference proceedings of
  DGON POSNAV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;推进高自动化和自主操作对内陆水道运输系统的未来至关重要，这需要在各种天气条件下具备强大且精确的船载传感技术。&lt;h4&gt;目的&lt;/h4&gt;开发可靠的近距离传感器技术，以适应自动泊靠、闸门进出和桥下通行等复杂操作。&lt;h4&gt;方法&lt;/h4&gt;本文讨论了四个紧凑型汽车频率调制连续波(FMCW)雷达组成的分布式传感器网络，安装在船舱船上作为测试平台，并进行了初步的现场实验。&lt;h4&gt;主要发现&lt;/h4&gt;初步实验表明，雷达网络能够感知内陆水域船只周围的近距离静态环境特征，并进行了汽车雷达与激光雷达传感器的环境检测能力比较分析。&lt;h4&gt;结论&lt;/h4&gt;汽车雷达在不良能见度条件下能够有效检测近距离物体，展示了其在内陆导航和操控中的适用性。&lt;h4&gt;总结&lt;/h4&gt;研究表明，发展适合内陆水道运输的高效传感技术是实现船舶自动化的关键，而汽车雷达显示出较好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancing towards high automation and autonomous operations is crucial forthe future of inland waterway transport (IWT) systems. These systemsnecessitate robust and precise onboard sensory technologies that can perceivethe environment under all weather conditions, including static features forlocal positioning techniques such as Simultaneous Localization and Mapping(SLAM). Traditional marine RADAR, mandatory on vessels and operating in the9300-9500 MHz frequency band, can cover ranges from 15 to 1200 meters but areinadequate for detecting closer objects, making them unsuitable for automateddocking maneuvers, lock entry, or bridge undercrossings. This necessitates thedevelopment of reliable close-range sensor technology that functionseffectively in all weather conditions.  In present research works on vessel automation, LiDAR sensors, operating inthe nearinfrared range, are used predominantly to detect the immediatesurroundings of vessels but suffer significant degradation in poor visibility.Conversely, automotive RADAR sensors, utilizing the 76-81 GHz frequency band,can detect objects from a few centimeters to up to 200 meters, even in adverseconditions. These sensors are commonly used in advanced autonomous road trafficsystems and are evaluated in this study for their suitability in inlandnavigation and maneuvering.  This paper discusses a distributed sensor network of four compact automotivefrequencymodulated continuous-wave (FMCW) radars mounted on a cabin boat as atest platform. Initial field experiments demonstrate the RADAR network'sability to perceive closerange static environmental features around the boat ininland waters. The paper also provides a comparative analysis of theenvironmental detection capabilities of automotive RADAR and LiDAR sensors.</description>
      <author>example@mail.com (R. Herrmann, S. Bose, I. Filip, D. Medina, R. Ziebold, S. Gehrig, T. Lenhard, M. Gardill)</author>
      <guid isPermaLink="false">2411.15901v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Barriers on the EDGE: A scalable CBF architecture over EDGE for safe aerial-ground multi-agent coordination</title>
      <link>http://arxiv.org/abs/2411.16608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures, submitted to ICRA'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文探讨了在有限任务空间内设计可扩展控制架构的问题，旨在实现无人机（UAVs）和地面机器人（UGVs）的安全协调操作。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够处理多代理系统中碰撞避免、UAV在UGV上着陆及任务空间限制的控制架构。&lt;h4&gt;方法&lt;/h4&gt;采用控制障碍函数（CBFs）施加约束，并使用集中-分散的边缘集群架构，以应对随着代理数量增加而快速增加的约束数量。&lt;h4&gt;主要发现&lt;/h4&gt;集中节点（Watcher）激活相关约束，从而减少对高计算能力和网络复杂性的需求，分散节点本地运行控制器以克服延迟和网络问题。&lt;h4&gt;结论&lt;/h4&gt;所提边缘架构通过多架空和地面机器人在有限环境中的协调操作得到了实验验证。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种有效的控制架构，能够在多代理系统中实现安全和高效的协同操作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this article, we address the problem of designing a scalable controlarchitecture for a safe coordinated operation of a multi-agent system withaerial (UAVs) and ground robots (UGVs) in a confined task space. The proposedmethod uses Control Barrier Functions (CBFs) to impose constraints associatedwith (i) collision avoidance between agents, (ii) landing of UAVs on mobileUGVs, and (iii) task space restriction. Further, to account for the rapidincrease in the number of constraints for a single agent with the increasingnumber of agents, the proposed architecture uses a centralized-decentralizedEdge cluster, where a centralized node (Watcher) activates the relevantconstraints, reducing the need for high onboard processing and networkcomplexity. The distributed nodes run the controller locally to overcomelatency and network issues. The proposed Edge architecture is experimentallyvalidated using multiple aerial and ground robots in a confined environmentperforming a coordinated operation.</description>
      <author>example@mail.com (Viswa Narayanan Sankaranarayanan, Achilleas Santi Seisa, Akshit Saradagi, Sumeet Satpute, George Nikolakopoulos)</author>
      <guid isPermaLink="false">2411.16608v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian Scenes: Pose-Free Sparse-View Scene Reconstruction using Depth-Enhanced Diffusion Priors</title>
      <link>http://arxiv.org/abs/2411.15966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 6 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在有限的未标定2D图像中进行无姿态的360度场景重建通常需要深度估计或3D基础先验进行正则化。&lt;h4&gt;目的&lt;/h4&gt;提出一种生成性方法，以实现无姿态场景的重建。&lt;h4&gt;方法&lt;/h4&gt;设计了一种遵循指令的RGBD扩散模型，用于填补缺失细节并消除3D场景的新视图渲染和深度图中的伪影，同时提出了一种新的高斯表示置信度测量。&lt;h4&gt;主要发现&lt;/h4&gt;在MipNeRF360数据集上的评估表明，该方法超越了现有的无姿态技术，并在复杂的360度场景中与最先进的有姿态重建方法竞争。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法有效地实现了多视图一致的高斯表示，展示了在无姿态场景重建领域的优势。&lt;h4&gt;总结&lt;/h4&gt;该研究为无姿态的360度场景重建提供了一种新的解决方案，能够在缺乏姿态信息的条件下，依然获得高质量的重建效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce a generative approach for pose-free reconstructionof $360^{\circ}$ scenes from a limited number of uncalibrated 2D images.Pose-free scene reconstruction from incomplete, unposed observations is usuallyregularized with depth estimation or 3D foundational priors. While recentadvances have enabled sparse-view reconstruction of unbounded scenes with knowncamera poses using diffusion priors, these methods rely on explicit cameraembeddings for extrapolating unobserved regions. This reliance limits theirapplication in pose-free settings, where view-specific data is only implicitlyavailable. To address this, we propose an instruction-following RGBD diffusionmodel designed to inpaint missing details and remove artifacts in novel viewrenders and depth maps of a 3D scene. We also propose a novel confidencemeasure for Gaussian representations to allow for better detection of theseartifacts. By progressively integrating these novel views in aGaussian-SLAM-inspired process, we achieve a multi-view-consistent Gaussianrepresentation. Evaluations on the MipNeRF360 dataset demonstrate that ourmethod surpasses existing pose-free techniques and performs competitively withstate-of-the-art posed reconstruction methods in complex $360^{\circ}$ scenes.</description>
      <author>example@mail.com (Soumava Paul, Prakhar Kaushik, Alan Yuille)</author>
      <guid isPermaLink="false">2411.15966v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Inference-Time Policy Steering through Human Interactions</title>
      <link>http://arxiv.org/abs/2411.16627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成策略通过人类示范训练，可以自主完成多模态、长时间跨度的任务。&lt;h4&gt;目的&lt;/h4&gt;在推断过程中，解决人类干预缺失导致的政策执行限制，避免引发分布偏移问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种推断时政策引导（ITPS）框架，通过人类互动来偏向生成采样过程，而不是在互动数据上微调政策。&lt;h4&gt;主要发现&lt;/h4&gt;在三种模拟和实际基准测试中，ITPS的不同人类互动形式显示出不同的对齐距离指标。随机采样结合扩散政策在对齐和分布偏移之间达到了最佳平衡。&lt;h4&gt;结论&lt;/h4&gt;ITPS能够更好地将政策输出与人类意图对齐，同时减少超出分布的错误。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种新的框架来改善生成策略的推断过程，增强了人机协作的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative policies trained with human demonstrations can autonomouslyaccomplish multimodal, long-horizon tasks. However, during inference, humansare often removed from the policy execution loop, limiting the ability to guidea pre-trained policy towards a specific sub-goal or trajectory shape amongmultiple predictions. Naive human intervention may inadvertently exacerbatedistribution shift, leading to constraint violations or execution failures. Tobetter align policy output with human intent without inducingout-of-distribution errors, we propose an Inference-Time Policy Steering (ITPS)framework that leverages human interactions to bias the generative samplingprocess, rather than fine-tuning the policy on interaction data. We evaluateITPS across three simulated and real-world benchmarks, testing three forms ofhuman interaction and associated alignment distance metrics. Among six samplingstrategies, our proposed stochastic sampling with diffusion policy achieves thebest trade-off between alignment and distribution shift. Videos are availableat https://yanweiw.github.io/itps/.</description>
      <author>example@mail.com (Yanwei Wang, Lirui Wang, Yilun Du, Balakumar Sundaralingam, Xuning Yang, Yu-Wei Chao, Claudia Perez-D'Arpino, Dieter Fox, Julie Shah)</author>
      <guid isPermaLink="false">2411.16627v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TP-UNet: Temporal Prompt Guided UNet for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2411.11305v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;医学图像分割技术的进步得益于深度学习技术，特别是基于UNet的方法，这些方法利用语义信息提高分割准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法TP-UNet，以有效整合时间信息，改善当前UNet基础的医学图像分割技术。&lt;h4&gt;方法&lt;/h4&gt;TP-UNet利用时间提示，涵盖器官构建关系，指导分割UNet模型，并结合跨注意力和基于无监督对比学习的语义对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在两个医学图像分割数据集上的广泛评估显示，TP-UNet展现出最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;TP-UNet有效整合了时间信息，提升了医学图像分割的效果，实施将在接受后开源。&lt;h4&gt;总结&lt;/h4&gt;TP-UNet通过创新的方法显著提高了医学图像分割的准确性，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advancement of medical image segmentation techniques has been propelledby the adoption of deep learning techniques, particularly UNet-basedapproaches, which exploit semantic information to improve the accuracy ofsegmentations. However, the order of organs in scanned images has beendisregarded by current medical image segmentation approaches based on UNet.Furthermore, the inherent network structure of UNet does not provide directcapabilities for integrating temporal information. To efficiently integratetemporal information, we propose TP-UNet that utilizes temporal prompts,encompassing organ-construction relationships, to guide the segmentation UNetmodel. Specifically, our framework is featured with cross-attention andsemantic alignment based on unsupervised contrastive learning to combinetemporal prompts and image features effectively. Extensive evaluations on twomedical image segmentation datasets demonstrate the state-of-the-artperformance of TP-UNet. Our implementation will be open-sourced afteracceptance.</description>
      <author>example@mail.com (Ranmin Wang, Limin Zhuang, Hongkun Chen, Boyan Xu, Ruichu Cai)</author>
      <guid isPermaLink="false">2411.11305v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Collaborative Contrastive Network for Click-Through Rate Prediction</title>
      <link>http://arxiv.org/abs/2411.11508v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;电子商务平台为顾客提供进入小程序的入口，以满足他们特定的购物需求。&lt;h4&gt;目的&lt;/h4&gt;解决现有点击率预测方法在理解顾客意图方面的不足。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新的CTR预测方法，称为协同对比网络（CCN），通过识别用户的兴趣和不感兴趣的商品集群进行对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;CCN在大规模真实数据上的在线A/B测试中表现出色，在淘宝的CTR提升了12.3%，订单量提升了12.7%。&lt;h4&gt;结论&lt;/h4&gt;CCN方法比传统方法更稳健，适用于短期可用的小程序，能够更好地捕捉顾客的真实意图。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的CCN方法提高了CTR预测的准确性，对短期促销活动具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; E-commerce platforms provide entrances for customers to enter mini-apps tomeet their specific shopping needs. At the entrance of a mini-app, a triggeritem recommended based on customers' historical preferences, is displayed toattract customers to enter the mini-app. Existing Click-Through Rate (CTR)prediction approaches have two significant weaknesses: (i) A portion ofcustomer entries is driven by their interest in the mini-app itself rather thanthe trigger item. In such cases, approaches highly hinging on the trigger itemtend to recommend similar items, thus misunderstanding the customers' realintention; (ii) Approaches that consider customers' intention toward mini-apps,require the regular existence of mini-apps for customers to cultivate routineshopping habits, making such approaches less robust for mini-apps that areavailable for only short periods (1 or 3 days) in Explosive PromotionalScenarios (EPS), such as the Black Friday and China's Double 11 ShoppingCarnival. To address the above-mentioned issues, we introduce a more generaland robust CTR prediction approach, dubbed Collaborative Contrastive Network(CCN). Given a user, CCN learns to identify two item clusters that canrepresent the user's interests and disinterests, via leveraging thecollaborative relationship of co-click/co-non-click or the non-collaborativerelationship of mono-click as the supervision signal for contrastive learning.This paradigm does not need to explicitly estimate user's binary entryintention and avoids amplifying the impact of the trigger item. Online A/Btesting on large-scale real-world data demonstrates that CCN sets a newstate-of-the-art performance on Taobao, boosting CTR by 12.3% and order volumeby 12.7%.</description>
      <author>example@mail.com (Chen Gao, Zixin Zhao, Sihao Hu, Lv Shao, Tong Liu)</author>
      <guid isPermaLink="false">2411.11508v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Toward Automated Algorithm Design: A Survey and Practical Guide to Meta-Black-Box-Optimization</title>
      <link>http://arxiv.org/abs/2411.00625v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Meta-Black-Box-Optimization（MetaBBO）作为进化计算领域的新兴方向，结合了元学习方法以辅助自动化算法设计。&lt;h4&gt;目的&lt;/h4&gt;弥补现有文献中对MetaBBO关键方面的不足总结和实施指导。&lt;h4&gt;方法&lt;/h4&gt;提供对MetaBBO的全面回顾，包含统一定义、系统分类、不同学习方法概述及最新代表性MetaBBO方法的综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;识别出提升MetaBBO的泛化能力和学习有效性的核心设计，并分析其优化性能、计算效率和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;展望MetaBBO领域的未来趋势和潜在发展方向，并持续更新相关文献。&lt;h4&gt;总结&lt;/h4&gt;MetaBBO在算法设计任务中的应用和发展，为进化计算领域提供了新的研究视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/gmc-drl/awesome-metabbo&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this survey, we introduce Meta-Black-Box-Optimization~(MetaBBO) as anemerging avenue within the Evolutionary Computation~(EC) community, whichincorporates Meta-learning approaches to assist automated algorithm design.Despite the success of MetaBBO, the current literature provides insufficientsummaries of its key aspects and lacks practical guidance for implementation.To bridge this gap, we offer a comprehensive review of recent advances inMetaBBO, providing an in-depth examination of its key developments. We beginwith a unified definition of the MetaBBO paradigm, followed by a systematictaxonomy of various algorithm design tasks, including algorithm selection,algorithm configuration, solution manipulation, and algorithm generation.Further, we conceptually summarize different learning methodologies behindcurrent MetaBBO works, including reinforcement learning, supervised learning,neuroevolution, and in-context learning with Large Language Models. Acomprehensive evaluation of the latest representative MetaBBO methods is thencarried out, alongside an experimental analysis of their optimizationperformance, computational efficiency, and generalization ability. Based on theevaluation results, we meticulously identify a set of core designs that enhancethe generalization and learning effectiveness of MetaBBO. Finally, we outlinethe vision for the field by providing insight into the latest trends andpotential future directions. Relevant literature will be continuously collectedand updated at \url{https://github.com/GMC-DRL/Awesome-MetaBBO}.</description>
      <author>example@mail.com (Zeyuan Ma, Hongshu Guo, Yue-Jiao Gong, Jun Zhang, Kay Chen Tan)</author>
      <guid isPermaLink="false">2411.00625v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Dissecting Misalignment of Multimodal Large Language Models via Influence Function</title>
      <link>http://arxiv.org/abs/2411.11667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型（MLLMs）通常训练于来自多样且不可靠的来源的数据，这些数据可能包含不对齐或错误标记的文本-图像对，导致鲁棒性问题和幻觉现象。&lt;h4&gt;目的&lt;/h4&gt;检测和追踪这些不对齐现象，提升模型的性能和可靠性。&lt;h4&gt;方法&lt;/h4&gt;提出了扩展影响函数（ECIF），专为对比损失设计，考虑正负样本的影响，并提供对比学习模型的闭式近似，避免重新训练。&lt;h4&gt;主要发现&lt;/h4&gt;ECIF通过更准确地评估数据影响和模型对齐，提升了MLLMs的透明度和可解释性，相比传统基线方法表现更佳。&lt;h4&gt;结论&lt;/h4&gt;基于ECIF开发的一系列算法可有效进行数据评估、不对齐检测和错误预测追溯任务。&lt;h4&gt;总结&lt;/h4&gt;本研究通过引入ECIF，为多模态大型语言模型的训练和评估提供了一种高效且准确的新方法，显著改善了模型的透明度和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal Large Language models (MLLMs) are always trained on data fromdiverse and unreliable sources, which may contain misaligned or mislabeledtext-image pairs. This frequently causes robustness issues and hallucinations,leading to performance degradation. Data valuation is an efficient way todetect and trace these misalignments. Nevertheless, existing methods arecomputationally expensive for MLLMs. While computationally efficient, theclassical influence functions are inadequate for contrastive learning modelsbecause they were originally designed for pointwise loss. Additionally,contrastive learning involves minimizing the distance between the modalities ofpositive samples and maximizing the distance between the modalities of negativesamples. This requires us to evaluate the influence of samples from bothperspectives. To tackle these challenges, we introduce the Extended InfluenceFunction for Contrastive Loss (ECIF), an influence function crafted forcontrastive loss. ECIF considers both positive and negative samples andprovides a closed-form approximation of contrastive learning models,eliminating the need for retraining. Building upon ECIF, we develop a series ofalgorithms for data evaluation in MLLM, misalignment detection, andmisprediction trace-back tasks. Experimental results demonstrate our ECIFadvances the transparency and interpretability of MLLMs by offering a moreaccurate assessment of data impact and model alignment compared to traditionalbaseline methods.</description>
      <author>example@mail.com (Lijie Hu, Chenyang Ren, Huanyi Xie, Khouloud Saadi, Shu Yang, Jingfeng Zhang, Di Wang)</author>
      <guid isPermaLink="false">2411.11667v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Learning Differentiable Surrogate Losses for Structured Prediction</title>
      <link>http://arxiv.org/abs/2411.11682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;结构化预测涉及学习预测复杂结构而非简单标量值。&lt;h4&gt;目的&lt;/h4&gt;解决输出空间的非欧几里得性质带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出一种新框架，通过对比学习直接从输出训练数据中学习由神经网络参数化的结构损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在监督图预测问题上表现出与预定义核方法相似或更优的性能。&lt;h4&gt;结论&lt;/h4&gt;设计有效的损失函数对于复杂结构的对象至关重要，且该框架提供了一种有效的解决方案。&lt;h4&gt;总结&lt;/h4&gt;通过对比学习实现的结构损失函数使得神经网络的学习和新结构的预测成为可能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Structured prediction involves learning to predict complex structures ratherthan simple scalar values. The main challenge arises from the non-Euclideannature of the output space, which generally requires relaxing the problemformulation. Surrogate methods build on kernel-induced losses or moregenerally, loss functions admitting an Implicit Loss Embedding, and convert theoriginal problem into a regression task followed by a decoding step. However,designing effective losses for objects with complex structures presentssignificant challenges and often requires domain-specific expertise. In thiswork, we introduce a novel framework in which a structured loss function,parameterized by neural networks, is learned directly from output training datathrough Contrastive Learning, prior to addressing the supervised surrogateregression problem. As a result, the differentiable loss not only enables thelearning of neural networks due to the finite dimension of the surrogate spacebut also allows for the prediction of new structures of the output data via adecoding strategy based on gradient descent. Numerical experiments onsupervised graph prediction problems show that our approach achieves similar oreven better performance than methods based on a pre-defined kernel.</description>
      <author>example@mail.com (Junjie Yang, Matthieu Labeau, Florence d'Alché-Buc)</author>
      <guid isPermaLink="false">2411.11682v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>mmSpyVR: Exploiting mmWave Radar for Penetrating Obstacles to Uncover Privacy Vulnerability of Virtual Reality</title>
      <link>http://arxiv.org/abs/2411.09914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;虚拟现实(VR)提升用户体验，但引入了显著的隐私风险。&lt;h4&gt;目的&lt;/h4&gt;揭示VR系统中的一种新漏洞，允许攻击者通过毫米波信号捕获VR隐私信息。&lt;h4&gt;方法&lt;/h4&gt;提出mmSpyVR攻击框架，包括基于迁移学习的特征提取模型和基于注意力的隐私监视模块。&lt;h4&gt;主要发现&lt;/h4&gt;mmSpyVR能够从穿透障碍的毫米波信号中提取关键的VR隐私信息，应用识别准确率为98.5%，按键识别准确率为92.6%。&lt;h4&gt;结论&lt;/h4&gt;新发现的漏洞对网络安全、隐私保护和VR技术发展具有广泛影响，并与VR制造商Meta讨论潜在的防范策略。&lt;h4&gt;数据和代码&lt;/h4&gt;数据和代码可通过https://github.com/luoyumei1-a/mmSpyVR/获取，供公众审查和研究。&lt;h4&gt;总结&lt;/h4&gt;mmSpyVR的研究揭示了VR系统中的隐私风险，并提供了改进的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/luoyumei1-a/mmspyvr&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Virtual reality (VR), while enhancing user experiences, introducessignificant privacy risks. This paper reveals a novel vulnerability in VRsystems that allows attackers to capture VR privacy through obstacles utilizingmillimeter-wave (mmWave) signals without physical intrusion and virtualconnection with the VR devices. We propose mmSpyVR, a novel attack on VR user'sprivacy via mmWave radar. The mmSpyVR framework encompasses two main parts: (i)A transfer learning-based feature extraction model to achieve VR featureextraction from mmWave signal. (ii) An attention-based VR privacy spying moduleto spy VR privacy information from the extracted feature. The mmSpyVRdemonstrates the capability to extract critical VR privacy from the mmWavesignals that have penetrated through obstacles. We evaluate mmSpyVR throughIRB-approved user studies. Across 22 participants engaged in four experimentalscenes utilizing VR devices from three different manufacturers, our systemachieves an application recognition accuracy of 98.5\% and keystrokerecognition accuracy of 92.6\%. This newly discovered vulnerability hasimplications across various domains, such as cybersecurity, privacy protection,and VR technology development. We also engage with VR manufacturer Meta todiscuss and explore potential mitigation strategies. Data and code are publiclyavailable for scrutiny and research at https://github.com/luoyumei1-a/mmSpyVR/</description>
      <author>example@mail.com (Luoyu Mei, Ruofeng Liu, Zhimeng Yin, Qingchuan Zhao, Wenchao Jiang, Shuai Wang, Kangjie Lu, Tian He)</author>
      <guid isPermaLink="false">2411.09914v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Foundation Model-Agnostic Slide-Level Representation Learning</title>
      <link>http://arxiv.org/abs/2411.13623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;病理全切片图像的表征学习主要依赖于弱监督与多实例学习（MIL），这导致切片表征高度特定于某一临床任务。&lt;h4&gt;目的&lt;/h4&gt;解决生成患者或切片级别嵌入的挑战。&lt;h4&gt;方法&lt;/h4&gt;通过将多个基础模型的tile嵌入整合，提出一种新的单模态自监督学习方法，称为COBRA，采用基于Mamba-2的架构。&lt;h4&gt;主要发现&lt;/h4&gt;COBRA在四个不同的公共CPTAC队列中，平均性能超过最先进的切片编码器至少3.8% AUC，尽管仅在3048个TCGA的WSIs上进行预训练。&lt;h4&gt;结论&lt;/h4&gt;COBRA在推理时与之前未见过的特征提取器兼容性良好。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的COBRA方法有效提升了病理切片表征的性能，展示了自监督学习在病理图像领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning of pathology whole-slide images (WSIs) has primarilyrelied on weak supervision with Multiple Instance Learning (MIL). This approachleads to slide representations highly tailored to a specific clinical task.Self-supervised learning (SSL) has been successfully applied to trainhistopathology foundation models (FMs) for patch embedding generation. However,generating patient or slide level embeddings remains challenging. Existingapproaches for slide representation learning extend the principles of SSL frompatch level learning to entire slides by aligning different augmentations ofthe slide or by utilizing multimodal data. By integrating tile embeddings frommultiple FMs, we propose a new single modality SSL method in feature space thatgenerates useful slide representations. Our contrastive pretraining strategy,called COBRA, employs multiple FMs and an architecture based on Mamba-2. COBRAexceeds performance of state-of-the-art slide encoders on four different publicCPTAC cohorts on average by at least +3.8% AUC, despite only being pretrainedon 3048 WSIs from TCGA. Additionally, COBRA is readily compatible at inferencetime with previously unseen feature extractors.</description>
      <author>example@mail.com (Tim Lenz, Peter Neidlinger, Marta Ligero, Georg Wölflein, Marko van Treeck, Jakob Nikolas Kather)</author>
      <guid isPermaLink="false">2411.13623v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Decoupled Sparse Priors Guided Diffusion Compression Model for Point Clouds</title>
      <link>http://arxiv.org/abs/2411.13860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的有损压缩方法依赖于自编码器将点云转换为潜在点进行存储，未充分利用潜在表示的内在冗余。&lt;h4&gt;目的&lt;/h4&gt;提出一种稀疏先验引导的方法，旨在减少潜在点的冗余，以提高重构质量，尤其是在高压缩比下。&lt;h4&gt;方法&lt;/h4&gt;采用双密度方案，分别处理用于重构的潜在点和用于存储的稀疏先验。通过分层解耦的条件生成模型，动态关注几何和语义线索，使用渐进注意力的条件去噪器生成潜在点。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进的方法相比，该方法在率失真权衡上表现优越，得到了广泛评估的结果，尤其是在ShapeNet数据集和MPEG组的标准测试数据集上。&lt;h4&gt;结论&lt;/h4&gt;该方法通过高效的数据流和局部分布集成，显著提升了稀疏点的上下文建模能力，实现了高质量的点云重构。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新颖的稀疏先验引导方法，有效减少潜在点冗余并提高点云重构质量，展示了其在点云压缩领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lossy compression methods rely on an autoencoder to transform a point cloudinto latent points for storage, leaving the inherent redundancy of latentrepresentations unexplored. To reduce redundancy in latent points, we propose asparse priors guided method that achieves high reconstruction quality,especially at high compression ratios. This is accomplished by a dual-densityscheme separately processing the latent points (intended for reconstruction)and the decoupled sparse priors (intended for storage). Our approach featuresan efficient dual-density data flow that relaxes size constraints on latentpoints, and hybridizes a progressive conditional diffusion model to encapsulateessential details for reconstruction within the conditions, which are decoupledhierarchically to intra-point and inter-point priors. Specifically, our methodencodes the original point cloud into latent points and decoupled sparse priorsthrough separate encoders. Latent points serve as intermediates, while sparsepriors act as adaptive conditions. We then employ a progressive attention-basedconditional denoiser to generate latent points conditioned on the decoupledpriors, allowing the denoiser to dynamically attend to geometric and semanticcues from the priors at each encoding and decoding layer. Additionally, weintegrate the local distribution into the arithmetic encoder and decoder toenhance local context modeling of the sparse points. The original point cloudis reconstructed through a point decoder. Compared to state-of-the-art, ourmethod obtains superior rate-distortion trade-off, evidenced by extensiveevaluations on the ShapeNet dataset and standard test datasets from MPEG groupincluding 8iVFB, and Owlii.</description>
      <author>example@mail.com (Xiaoge Zhang, Zijie Wu, Mehwish Nasim, Mingtao Feng, Ajmal Mian)</author>
      <guid isPermaLink="false">2411.13860v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Machine Vision-Based Assessment of Fall Color Changes and its Relationship with Leaf Nitrogen Concentration</title>
      <link>http://arxiv.org/abs/2404.14653v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;苹果树每年落叶，叶色从绿色逐渐变为黄色，这一过程与叶片氮浓度有关。&lt;h4&gt;目的&lt;/h4&gt;预测苹果树叶色变化可以反映其氮状态，并评估基于机器视觉的系统来量化叶色变化与氮含量的关系。&lt;h4&gt;方法&lt;/h4&gt;在2021年和2023年的秋季，使用地面车辆的立体视觉传感器收集了为期五周的图像数据集，包括颜色和三维数据。通过颜色和深度阈值分割前景树木，使用自定义的'黄色指数'来量化树冠区域的黄色叶片比例。&lt;h4&gt;主要发现&lt;/h4&gt;提出的基于梯度提升的方法在计算时间和准确性上优于K均值方法，'黄色指数'的R²值达到0.72，能够捕捉从绿色到黄色的逐渐变化。氮含量较低的树木比氮含量较高的树木更早出现黄色转变。&lt;h4&gt;结论&lt;/h4&gt;叶色变化可以作为苹果树氮状态的指标，机器视觉系统有效量化了这一变化。&lt;h4&gt;总结&lt;/h4&gt;该研究为精准氮管理提供了新的方法，利用机器视觉技术监测苹果树的叶色变化以优化果树的氮管理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-04-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Apple(\textit{Malus domestica} Borkh.) trees are deciduous, shedding leaveseach year. This process is preceded by a gradual change in leaf color fromgreen to yellow as chlorophyll is degraded prior to abscission. The initiationand rate of this color change are affected by many factors including leafnitrogen (N) concentration. We predict that leaf color during this transitionmay be indicative of the nitrogen status of apple trees. This study assesses amachine vision-based system for quantifying the change in leaf color and itscorrelation with leaf nitrogen content. An image dataset was collected in colorand 3D over five weeks in the fall of 2021 and 2023 at a commercial orchardusing a ground vehicle-based stereovision sensor. Trees in the foreground weresegmented from the point cloud using color and depth thresholding methods.Then, to estimate the proportion of yellow leaves per canopy, the colorinformation of the segmented canopy area was quantified using a custom-definedmetric, \textit{yellowness index} (a normalized ratio of yellow to greenfoliage in the tree) that varied from -1 to +1 (-1 being completely green and+1 being completely yellow). Both K-means-based methods and gradient boostingmethods were used to estimate the \textit{yellowness index}. The gradientboosting based method proposed in this study was better than the K-means-basedmethod (both in terms of computational time and accuracy), achieving an $R^2$of 0.72 in estimating the \textit{yellowness index}. The metric was able tocapture the gradual color transition from green to yellow over the studyduration. Trees with lower leaf nitrogen showed the color transition to yellowearlier than the trees with higher nitrogen.  Keywords: Fruit Tree Nitrogen Management, Machine Vision, Point CloudSegmentation, Precision Nitrogen Management</description>
      <author>example@mail.com (Achyut Paudel, Jostan Brown, Priyanka Upadhyaya, Atif Bilal Asad, Safal Kshetri, Joseph R. Davidson, Cindy Grimm, Ashley Thompson, Bernardita Sallato, Matthew D. Whiting, Manoj Karkee)</author>
      <guid isPermaLink="false">2404.14653v3</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Epidemiology-informed Network for Robust Rumor Detection</title>
      <link>http://arxiv.org/abs/2411.12949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社交媒体上谣言的快速传播对公众信任和信息完整性造成了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的流行病学信息网络（EIN），以提高谣言检测的性能并克服数据驱动方法对数据质量的敏感性。&lt;h4&gt;方法&lt;/h4&gt;结合流行病学知识，利用大型语言模型生成用户对信息源的立场标签，优化学习流行病学信息表示的目标。&lt;h4&gt;主要发现&lt;/h4&gt;EIN在真实世界数据集上优于现有最先进的方法，并在不同传播树深度下展现出更强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过整合流行病学理论，EIN能够有效改善谣言检测的准确性和稳定性。&lt;h4&gt;总结&lt;/h4&gt;EIN模型通过利用流行病学知识和自动化标签生成，成功提升了谣言检测的效果和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid spread of rumors on social media has posed significant challengesto maintaining public trust and information integrity. Since an informationcascade process is essentially a propagation tree, recent rumor detectionmodels leverage graph neural networks to additionally capture informationpropagation patterns, thus outperforming text-only solutions. Given thevariations in topics and social impact of the root node, different sourceinformation naturally has distinct outreach capabilities, resulting indifferent heights of propagation trees. This variation, however, impedes thedata-driven design of existing graph-based rumor detectors. Given a shallowpropagation tree with limited interactions, it is unlikely for graph-basedapproaches to capture sufficient cascading patterns, questioning their abilityto handle less popular news or early detection needs. In contrast, a deeppropagation tree is prone to noisy user responses, and this can in turnobfuscate the predictions. In this paper, we propose a novelEpidemiology-informed Network (EIN) that integrates epidemiological knowledgeto enhance performance by overcoming data-driven methods sensitivity to dataquality. Meanwhile, to adapt epidemiology theory to rumor detection, it isexpected that each users stance toward the source information will beannotated. To bypass the costly and time-consuming human labeling process, wetake advantage of large language models to generate stance labels, facilitatingoptimization objectives for learning epidemiology-informed representations. Ourexperimental results demonstrate that the proposed EIN not only outperformsstate-of-the-art methods on real-world datasets but also exhibits enhancedrobustness across varying tree depths.</description>
      <author>example@mail.com (Wei Jiang, Tong Chen, Xinyi Gao, Wentao Zhang, Lizhen Cui, Hongzhi Yin)</author>
      <guid isPermaLink="false">2411.12949v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Exploring applications of topological data analysis in stock index movement prediction</title>
      <link>http://arxiv.org/abs/2411.13881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;拓扑数据分析（TDA）在金融预测领域引起了广泛关注。&lt;h4&gt;目的&lt;/h4&gt;解决股票指数运动的分类问题。&lt;h4&gt;方法&lt;/h4&gt;采用三种不同的方法构建股票指数的点云，利用TDA提取点云中的拓扑结构，计算四种不同的拓扑特征，并将15种特征组合输入六种不同的机器学习模型中。&lt;h4&gt;主要发现&lt;/h4&gt;通过对CSI、DAX、HSI和FTSE等数据集进行指数运动分类任务，评估不同TDA配置的预测性能。&lt;h4&gt;结论&lt;/h4&gt;不同的点云构建方法、拓扑特征表示和分类模型对预测结果有显著影响。&lt;h4&gt;总结&lt;/h4&gt;本研究为不同TDA设置的效率提供了深入见解，强调了方法选择的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/desman107/stocktda&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Topological Data Analysis (TDA) has recently gained significant attention inthe field of financial prediction. However, the choice of point cloudconstruction methods, topological feature representations, and classificationmodels has a substantial impact on prediction results. This paper addresses theclassification problem of stock index movement. First, we construct pointclouds for stock indices using three different methods. Next, we apply TDA toextract topological structures from the point clouds. Four distinct topologicalfeatures are computed to represent the patterns in the data, and 15combinations of these features are enumerated and input into six differentmachine learning models. We evaluate the predictive performance of various TDAconfigurations by conducting index movement classification tasks on datasetssuch as CSI, DAX, HSI and FTSE providing insights into the efficiency ofdifferent TDA setups.</description>
      <author>example@mail.com (Dazhi Huang, Pengcheng Xu, Xiaocheng Huang, Jiayi Chen)</author>
      <guid isPermaLink="false">2411.13881v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Can Reasons Help Improve Pedestrian Intent Estimation? A Cross-Modal Approach</title>
      <link>http://arxiv.org/abs/2411.13302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主导航系统的重要性日益增加，需要保护脆弱道路用户（如行人）的安全。&lt;h4&gt;目的&lt;/h4&gt;探索行人意图背后的直观推理，以提高对行人意图的理解。&lt;h4&gt;方法&lt;/h4&gt;提出PIE++数据集，包含多标签的文本解释/理由，并引入多任务学习框架MINDREAD，结合跨模态表示学习来预测行人意图及其原因。&lt;h4&gt;主要发现&lt;/h4&gt;使用MINDREAD在PIE++数据集上，意图预测的准确率和F1-score分别提高了5.6%和7%；在JAAD数据集上准确率提高了4.4%。&lt;h4&gt;结论&lt;/h4&gt;通过定量和定性指标及用户研究，验证了该方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究通过引入理由的预测，增强了对行人意图的理解，提升了相关预测任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increased importance of autonomous navigation systems has come anincreasing need to protect the safety of Vulnerable Road Users (VRUs) such aspedestrians. Predicting pedestrian intent is one such challenging task, whereprior work predicts the binary cross/no-cross intention with a fusion of visualand motion features. However, there has been no effort so far to hedge suchpredictions with human-understandable reasons. We address this issue byintroducing a novel problem setting of exploring the intuitive reasoning behinda pedestrian's intent. In particular, we show that predicting the 'WHY' can bevery useful in understanding the 'WHAT'. To this end, we propose a novel,reason-enriched PIE++ dataset consisting of multi-label textualexplanations/reasons for pedestrian intent. We also introduce a novelmulti-task learning framework called MINDREAD, which leverages a cross-modalrepresentation learning framework for predicting pedestrian intent as well asthe reason behind the intent. Our comprehensive experiments show significantimprovement of 5.6% and 7% in accuracy and F1-score for the task of intentprediction on the PIE++ dataset using MINDREAD. We also achieved a 4.4%improvement in accuracy on a commonly used JAAD dataset. Extensive evaluationusing quantitative/qualitative metrics and user studies shows the effectivenessof our approach.</description>
      <author>example@mail.com (Vaishnavi Khindkar, Vineeth Balasubramanian, Chetan Arora, Anbumani Subramanian, C. V. Jawahar)</author>
      <guid isPermaLink="false">2411.13302v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>ORID: Organ-Regional Information Driven Framework for Radiology Report Generation</title>
      <link>http://arxiv.org/abs/2411.13025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 11 figures, WACV2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;放射学报告生成（RRG）的目标是基于放射图像自动生成连贯的疾病文本分析，以减轻放射科医师的工作负担。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，旨在提升现有AI方法在RRG中的效果，特别是在处理与无关器官的噪声方面。&lt;h4&gt;方法&lt;/h4&gt;引入器官区域信息驱动（ORID）框架，构建与RRG相关的指令数据集，发展器官基础的跨模态融合模块，并采用图神经网络（GNN）分析器官重要性系数。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验和与最先进方法的比较，证明了所提方法在各项评估指标上的优越性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的ORID框架有效整合了多模态信息，显著降低了无关器官对放射学报告生成的影响。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的RRG方法在提升放射学报告生成质量方面具有重要意义，能够更好地支持放射科医师的工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The objective of Radiology Report Generation (RRG) is to automaticallygenerate coherent textual analyses of diseases based on radiological images,thereby alleviating the workload of radiologists. Current AI-based methods forRRG primarily focus on modifications to the encoder-decoder model architecture.To advance these approaches, this paper introduces an Organ-RegionalInformation Driven (ORID) framework which can effectively integrate multi-modalinformation and reduce the influence of noise from unrelated organs.Specifically, based on the LLaVA-Med, we first construct an RRG-relatedinstruction dataset to improve organ-regional diagnosis description ability andget the LLaVA-Med-RRG. After that, we propose an organ-based cross-modal fusionmodule to effectively combine the information from the organ-regional diagnosisdescription and radiology image. To further reduce the influence of noise fromunrelated organs on the radiology report generation, we introduce an organimportance coefficient analysis module, which leverages Graph Neural Network(GNN) to examine the interconnections of the cross-modal information of eachorgan region. Extensive experiments an1d comparisons with state-of-the-artmethods across various evaluation metrics demonstrate the superior performanceof our proposed method.</description>
      <author>example@mail.com (Tiancheng Gu, Kaicheng Yang, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai)</author>
      <guid isPermaLink="false">2411.13025v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Causal Time-Series Synchronization for Multi-Dimensional Forecasting</title>
      <link>http://arxiv.org/abs/2411.10152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;过程工业对数字双胞胎的期望高，需要可以跨任务和多领域进行泛化的建模方法。&lt;h4&gt;目的&lt;/h4&gt;探索在过程工业中应用自监督信号进行预训练的通用模型的转移学习。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的通道依赖预训练策略，利用同步的因果对来处理多维时间序列数据的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;通过识别高度滞后的因果关系和同步因果对，我们的预训练方法在预测准确性和泛化能力上显著优于传统训练方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在通道依赖预测中表现出良好的效果，提升了预测的准确性和模型的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;本研究为过程工业中的数字双胞胎建模提供了一种有效的预训练策略，克服了多维时间序列数据的复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The process industry's high expectations for Digital Twins require modelingapproaches that can generalize across tasks and diverse domains withpotentially different data dimensions and distributional shifts i.e.,Foundational Models. Despite success in natural language processing andcomputer vision, transfer learning with (self-) supervised signals forpre-training general-purpose models is largely unexplored in the context ofDigital Twins in the process industry due to challenges posed bymulti-dimensional time-series data, lagged cause-effect dependencies, complexcausal structures, and varying number of (exogenous) variables. We propose anovel channel-dependent pre-training strategy that leverages synchronizedcause-effect pairs to overcome these challenges by breaking down themulti-dimensional time-series data into pairs of cause-effect variables. Ourapproach focuses on: (i) identifying highly lagged causal relationships usingdata-driven methods, (ii) synchronizing cause-effect pairs to generate trainingsamples for channel-dependent pre-training, and (iii) evaluating theeffectiveness of this approach in channel-dependent forecasting. Ourexperimental results demonstrate significant improvements in forecastingaccuracy and generalization capability compared to traditional trainingmethods.</description>
      <author>example@mail.com (Michael Mayr, Georgios C. Chasparis, Josef Küng)</author>
      <guid isPermaLink="false">2411.10152v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>U-Motion: Learned Point Cloud Video Compression with U-Structured Motion Estimation</title>
      <link>http://arxiv.org/abs/2411.14501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云视频（PCV）是一种多用途的动态场景3D表示，具有多种新兴应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于学习的压缩方案U-Motion，用于PCV的几何和属性压缩。&lt;h4&gt;方法&lt;/h4&gt;设计了U-Structured多尺度帧间预测框架U-Inter，进行分层显式运动估计和补偿，并结合高低尺度的运动特征。还设计了级联空间预测编码模块以捕捉U-Inter预测后残留的空间冗余。&lt;h4&gt;主要发现&lt;/h4&gt;U-Motion在几何和属性压缩上相较于MPEG G-PCC-GesTM v3.0及最近发布的学习方法有显著提升。&lt;h4&gt;结论&lt;/h4&gt;U-Motion能够有效减少空间-时间冗余，提升压缩性能。&lt;h4&gt;总结&lt;/h4&gt;U-Motion是一种创新的压缩技术，能够在动态场景的3D表示中实现更高效的压缩效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud video (PCV) is a versatile 3D representation of dynamic sceneswith many emerging applications. This paper introduces U-Motion, alearning-based compression scheme for both PCV geometry and attributes. Wepropose a U-Structured multiscale inter-frame prediction framework, U-Inter,which performs layer-wise explicit motion estimation and compensation (ME/MC)at different scales with varying levels of detail. It integrates both higherand lower-scale motion features, in addition to the information of current andprevious frames, to enable accurate motion estimation at the current scale. Inaddition, we design a cascaded spatial predictive coding module to capture theinter-scale spatial redundancy remaining after U-Inter prediction. We furtherpropose an effective context detach and restore scheme to reducespatial-temporal redundancy in the motion and latent bit-streams and improvecompression performance. We conduct experiments following the MPEG Common TestCondition and demonstrate that U-Motion can achieve significant gains over MPEGG-PCC-GesTM v3.0 and recently published learning-based methods for bothgeometry and attribute compression.</description>
      <author>example@mail.com (Tingyu Fan, Yueyu Hu, Yao Wang)</author>
      <guid isPermaLink="false">2411.14501v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TPCNet: Representation learning for HI mapping</title>
      <link>http://arxiv.org/abs/2411.13325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has 27 pages, 27 figures and two tables. The work has been
  accepted for publication in Monthly Notices of the Royal Astronomical Society
  Main Journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;引入TPCNet，这是一个结合卷积和变换器架构及位置编码的神经网络预测模型，用于中性氢（HI）光谱分析。&lt;h4&gt;目的&lt;/h4&gt;预测冷中性气体分数（f_CNM）和HI不透明度修正因子（R_HI），基于发射光谱学习输出参数与可观测量之间的关系。&lt;h4&gt;方法&lt;/h4&gt;在合成数据集上进行训练，构建深度卷积神经网络（CNN）模型，并与TPCNet模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;TPCNet在测试准确性上平均提高了10%，在算法稳定性和收敛速度上优于深度CNN。&lt;h4&gt;结论&lt;/h4&gt;TPCNet模型鲁棒性强，能够有效应对训练数据集洗牌和卷积网络权重初始化的扰动，且通过更高的光谱分辨率和多样化的合成数据集提高模型性能和泛化能力。&lt;h4&gt;应用&lt;/h4&gt;将TPCNet应用于观测发射数据，预测结果与基于高斯分解的估算高度一致，显示其在HI光谱分析中的潜力。&lt;h4&gt;总结&lt;/h4&gt;TPCNet通过结合卷积和变换器架构，显著提升了中性氢光谱分析的预测准确性和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5281/zenodo.14183481&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce TPCNet, a neural network predictor that combines Convolutionaland Transformer architectures with Positional encodings, for neutral atomichydrogen (HI) spectral analysis. Trained on synthetic datasets, our modelspredict cold neutral gas fraction ($f_\text{CNM}$) and HI opacity correctionfactor ($R_\text{HI}$) from emission spectra based on the learned relationshipsbetween the desired output parameters and observables (optically-thin columndensity and peak brightness). As a follow-up to Murray et al. (2020)'s shallowConvolutional Neural Network (CNN), we construct deep CNN models and comparethem to TPCNet models. TPCNet outperforms deep CNNs, achieving a 10% averageincrease in testing accuracy, algorithmic (training) stability, and convergencespeed. Our findings highlight the robustness of the proposed model withsinusoidal positional encoding applied directly to the spectral input,addressing perturbations in training dataset shuffling and convolutionalnetwork weight initializations. Higher spectral resolutions with increasedspectral channels offer advantages, albeit with increased training time.Diverse synthetic datasets enhance model performance and generalization, asdemonstrated by producing $f_\text{CNM}$ and $R_\text{HI}$ values consistentwith evaluation ground truths. Applications of TPCNet to observed emission datareveal strong agreement between the predictions and Gaussiandecomposition-based estimates (from emission and absorption surveys),emphasizing its potential in HI spectral analysis.</description>
      <author>example@mail.com (Hiep Nguyen, Haiyang Tang, Matthew Alger, Antoine Marchal, Eric G. M. Muller, Cheng Soon Ong, N. M. McClure-Griffiths)</author>
      <guid isPermaLink="false">2411.13325v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>HNCSE: Advancing Sentence Embeddings via Hybrid Contrastive Learning with Hard Negatives</title>
      <link>http://arxiv.org/abs/2411.12156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无监督句子表示学习在现代自然语言处理研究中仍然是一个重要挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法以改善句子表示学习，特别是在对比学习中。&lt;h4&gt;方法&lt;/h4&gt;提出HNCSE，一个扩展了SimCSE的对比学习框架，创新性地使用困难负样本来增强学习效果。&lt;h4&gt;主要发现&lt;/h4&gt;HNCSE在语义文本相似性和迁移任务数据集上的实验结果验证了其优越性。&lt;h4&gt;结论&lt;/h4&gt;使用困难负样本能够有效提升正负样本的学习，从而实现更深层次的语义理解。&lt;h4&gt;总结&lt;/h4&gt;HNCSE为对比句子学习提供了一种有效的框架，促进了无监督句子表示学习的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised sentence representation learning remains a critical challenge inmodern natural language processing (NLP) research. Recently, contrastivelearning techniques have achieved significant success in addressing this issueby effectively capturing textual semantics. Many such approaches prioritize theoptimization using negative samples. In fields such as computer vision, hardnegative samples (samples that are close to the decision boundary and thus moredifficult to distinguish) have been shown to enhance representation learning.However, adapting hard negatives to contrastive sentence learning is complexdue to the intricate syntactic and semantic details of text. To address thisproblem, we propose HNCSE, a novel contrastive learning framework that extendsthe leading SimCSE approach. The hallmark of HNCSE is its innovative use ofhard negative samples to enhance the learning of both positive and negativesamples, thereby achieving a deeper semantic understanding. Empirical tests onsemantic textual similarity and transfer task datasets validate the superiorityof HNCSE.</description>
      <author>example@mail.com (Wenxiao Liu, Zihong Yang, Chaozhuo Li, Zijin Hong, Jianfeng Ma, Zhiquan Liu, Litian Zhang, Feiran Huang)</author>
      <guid isPermaLink="false">2411.12156v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>FedCL-Ensemble Learning: A Framework of Federated Continual Learning with Ensemble Transfer Learning Enhanced for Alzheimer's MRI Classifications while Preserving Privacy</title>
      <link>http://arxiv.org/abs/2411.12756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究介绍了一种通过先进的深度学习技术和安全数据处理方法对阿尔茨海默病进行分类的新方法。&lt;h4&gt;目的&lt;/h4&gt;旨在提高阿尔茨海默病的分类精度，同时保护数据隐私。&lt;h4&gt;方法&lt;/h4&gt;主要使用迁移学习模型（如ResNet、ImageNet和VNet）提取医学图像数据的高层特征，并对这些预训练模型进行微调以识别与阿尔茨海默病相关的细微模式。结合联邦学习方法以解决分类中的一些挑战。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在不共享敏感患者数据的情况下，通过联邦学习进行构建，能够利用大型多样化数据集进行训练，同时确保数据的机密性。&lt;h4&gt;结论&lt;/h4&gt;实验结果不仅提高了阿尔茨海默病分类的准确性，还提供了一个安全和协作分析医疗数据的框架。&lt;h4&gt;总结&lt;/h4&gt;本研究为阿尔茨海默病的分类提供了一种有效的方法，兼顾了数据隐私与模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research work introduces a novel approach to the classification ofAlzheimer's disease by using the advanced deep learning techniques combinedwith secure data processing methods. This research work primary uses transferlearning models such as ResNet, ImageNet, and VNet to extract high-levelfeatures from medical image data. Thereafter, these pre-trained models werefine-tuned for Alzheimer's related subtle patterns such that the model iscapable of robust feature extraction over varying data sources. Further, thefederated learning approaches were incorporated to tackle a few otherchallenges related to classification, aimed to provide better predictionperformance and protect data privacy. The proposed model was built usingfederated learning without sharing sensitive patient data. This way, thedecentralized model benefits from the large and diversified dataset that it istrained upon while ensuring confidentiality. The cipher-based encryptionmechanism is added that allows us to secure the transportation of data andfurther ensure the privacy and integrity of patient information throughouttraining and classification. The results of the experiments not only help toimprove the accuracy of the classification of Alzheimer's but at the same timeprovides a framework for secure and collaborative analysis of health care data.</description>
      <author>example@mail.com (Rishit Kapoor, Jesher Joshua, Muralidharan Vijayarangan, Natarajan B)</author>
      <guid isPermaLink="false">2411.12756v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Resampling with Learnable Heat Diffusion</title>
      <link>http://arxiv.org/abs/2411.14120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成扩散模型在点云重采样中表现出色，能够从稀疏或噪声较大的3D点云中生成更密集和均匀的点分布，但现有模型常因手动预定义方案无法有效恢复点云结构而受到限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的可学习热扩散框架，用于点云重采样。&lt;h4&gt;方法&lt;/h4&gt;通过学习自适应热扩散调度和时间变化热核的局部滤波尺度，直接参数化前向过程的边际分布，并生成自适应条件先验用于反向过程。&lt;h4&gt;主要发现&lt;/h4&gt;与固定先验的扩散模型不同，提出的自适应条件先验通过最小化精细的变分下界来选择性地保留点云的几何特征，引导点在反向过程中向基础表面演变。&lt;h4&gt;结论&lt;/h4&gt;大量实验结果表明，所提点云重采样方法在点云去噪和上采样等重建任务中达到了最先进的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，通过学习动态的热扩散策略，显著提升了点云重采样的效果和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative diffusion models have shown empirical successes in point cloudresampling, generating a denser and more uniform distribution of points fromsparse or noisy 3D point clouds by progressively refining noise into structure.However, existing diffusion models employ manually predefined schemes, whichoften fail to recover the underlying point cloud structure due to the rigid anddisruptive nature of the geometric degradation. To address this issue, wepropose a novel learnable heat diffusion framework for point cloud resampling,which directly parameterizes the marginal distribution for the forward processby learning the adaptive heat diffusion schedules and local filtering scales ofthe time-varying heat kernel, and consequently, generates an adaptiveconditional prior for the reverse process. Unlike previous diffusion modelswith a fixed prior, the adaptive conditional prior selectively preservesgeometric features of the point cloud by minimizing a refined variational lowerbound, guiding the points to evolve towards the underlying surface during thereverse process. Extensive experimental results demonstrate that the proposedpoint cloud resampling achieves state-of-the-art performance in representativereconstruction tasks including point cloud denoising and upsampling.</description>
      <author>example@mail.com (Wenqiang Xu, Wenrui Dai, Duoduo Xue, Ziyang Zheng, Chenglin Li, Junni Zou, Hongkai Xiong)</author>
      <guid isPermaLink="false">2411.14120v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>S$^2$ALM: Sequence-Structure Pre-trained Large Language Model for Comprehensive Antibody Representation Learning</title>
      <link>http://arxiv.org/abs/2411.15215v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;抗体通过精确结合特定抗原来保护我们的健康，并在多种疾病治疗中表现出良好的疗效，包括COVID-19。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合序列和结构信息的抗体语言模型S$^2$ALM，以提高抗体的表示能力和功能理解。&lt;h4&gt;方法&lt;/h4&gt;构建一个分层的预训练范式，包含两个定制的多层训练目标，整合抗体的全面序列和结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;S$^2$ALM的表示空间揭示了抗体的功能结合机制、生物演化特性和结构相互作用模式，并在75百万个序列和11.7百万个结构上进行预训练。&lt;h4&gt;结论&lt;/h4&gt;S$^2$ALM在多项抗体特定理解和生成任务中超越了现有基准，展现出在实际治疗抗体开发中的潜力，可以应对学术、工业和临床的未满足需求。&lt;h4&gt;总结&lt;/h4&gt;该研究提出的S$^2$ALM模型为抗体开发提供了新的思路，结合了序列和结构信息，推动了抗体研究的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Antibodies safeguard our health through their precise and potent binding tospecific antigens, demonstrating promising therapeutic efficacy in thetreatment of numerous diseases, including COVID-19. Recent advancements inbiomedical language models have shown the great potential to interpret complexbiological structures and functions. However, existing antibody specific modelshave a notable limitation that they lack explicit consideration for antibodystructural information, despite the fact that both 1D sequence and 3D structurecarry unique and complementary insights into antibody behavior andfunctionality. This paper proposes Sequence-Structure multi-level pre-trainedAntibody Language Model (S$^2$ALM), combining holistic sequential andstructural information in one unified, generic antibody foundation model. Weconstruct a hierarchical pre-training paradigm incorporated with two customizedmulti-level training objectives to facilitate the modeling of comprehensiveantibody representations. S$^2$ALM's representation space uncovers inherentfunctional binding mechanisms, biological evolution properties and structuralinteraction patterns. Pre-trained over 75 million sequences and 11.7 millionstructures, S$^2$ALM can be adopted for diverse downstream tasks: accuratelypredicting antigen-antibody binding affinities, precisely distinguishing B cellmaturation stages, identifying antibody crucial binding positions, andspecifically designing novel coronavirus-binding antibodies. Remarkably,S$^2$ALM outperforms well-established and renowned baselines and sets newstate-of-the-art performance across extensive antibody specific understandingand generation tasks. S$^2$ALM's ability to model comprehensive and generalizedrepresentations further positions its potential to advance real-worldtherapeutic antibody development, potentially addressing unmet academic,industrial, and clinical needs.</description>
      <author>example@mail.com (Mingze Yin, Hanjing Zhou, Jialu Wu, Yiheng Zhu, Yuxuan Zhan, Zitai Kong, Hongxia Xu, Chang-Yu Hsieh, Jintai Chen, Tingjun Hou, Jian Wu)</author>
      <guid isPermaLink="false">2411.15215v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Health AI Developer Foundations</title>
      <link>http://arxiv.org/abs/2411.15128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;医疗机器学习模型有潜力革新医疗保健，提升临床研究效率和结果。&lt;h4&gt;目的&lt;/h4&gt;引入HAI-DEF，以加速医疗应用的机器学习模型构建。&lt;h4&gt;方法&lt;/h4&gt;HAI-DEF是一套预训练的领域特定基础模型、工具和配方，涵盖多种模态和领域。&lt;h4&gt;主要发现&lt;/h4&gt;这些模型提供领域特定的嵌入，减少标签数据需求、缩短训练时间和降低计算成本。&lt;h4&gt;结论&lt;/h4&gt;强调使用HAI-DEF模型时需验证特定问题和人群的数据，确保有效性、公平性和公正性。&lt;h4&gt;总结&lt;/h4&gt;该技术报告将随着更多模态和功能的增加而更新。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust medical Machine Learning (ML) models have the potential torevolutionize healthcare by accelerating clinical research, improving workflowsand outcomes, and producing novel insights or capabilities. Developing such MLmodels from scratch is cost prohibitive and requires substantial compute, data,and time (e.g., expert labeling). To address these challenges, we introduceHealth AI Developer Foundations (HAI-DEF), a suite of pre-trained,domain-specific foundation models, tools, and recipes to accelerate building MLfor health applications. The models cover various modalities and domains,including radiology (X-rays and computed tomography), histopathology,dermatological imaging, and audio. These models provide domain specificembeddings that facilitate AI development with less labeled data, shortertraining times, and reduced computational costs compared to traditionalapproaches. In addition, we utilize a common interface and style across thesemodels, and prioritize usability to enable developers to integrate HAI-DEFefficiently. We present model evaluations across various tasks and concludewith a discussion of their application and evaluation, covering the importanceof ensuring efficacy, fairness, and equity. Finally, while HAI-DEF andspecifically the foundation models lower the barrier to entry for ML inhealthcare, we emphasize the importance of validation with problem- andpopulation-specific data for each desired usage setting. This technical reportwill be updated over time as more modalities and features are added.</description>
      <author>example@mail.com (Atilla P. Kiraly, Sebastien Baur, Kenneth Philbrick, Fereshteh Mahvar, Liron Yatziv, Tiffany Chen, Bram Sterling, Nick George, Fayaz Jamil, Jing Tang, Kai Bailey, Faruk Ahmed, Akshay Goel, Abbi Ward, Lin Yang, Andrew Sellergren, Yossi Matias, Avinatan Hassidim, Shravya Shetty, Daniel Golden, Shekoofeh Azizi, David F. Steiner, Yun Liu, Tim Thelin, Rory Pilgrim, Can Kirmizibayrak)</author>
      <guid isPermaLink="false">2411.15128v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Contrast Similarity-Aware Dual-Pathway Mamba for Multivariate Time Series Node Classification</title>
      <link>http://arxiv.org/abs/2411.12222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Knowledge-Based Systems on Nov 17, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列（MTS）数据由多个传感器生成，广泛应用于工程、健康监测和物联网领域，具有时间变化和高维特征的特点。&lt;h4&gt;目的&lt;/h4&gt;提出一种对比相似性感知双通道Mamba方法（CS-DPMamba）用于MTS节点分类，以解决长距离依赖性建模困难和相似性获取效率低下的问题。&lt;h4&gt;方法&lt;/h4&gt;首先，使用时间对比学习模块获取MTS表示，并利用快速动态时间规整（FastDTW）构建MTS表示之间的相似性矩阵。其次，采用DPMamba考虑MTS的双向特性，以更好地捕捉数据中的长短期依赖。最后，利用Kolmogorov-Arnold网络增强图同构网络完成矩阵中的信息交互和MTS节点分类任务。&lt;h4&gt;主要发现&lt;/h4&gt;通过综合考虑长距离依赖和动态相似性特征，我们实现了精确的MTS节点分类。&lt;h4&gt;结论&lt;/h4&gt;在东安格利亚大学的多个MTS数据集上进行的实验表明，该方法在MTS分类任务中展现出优越性，适用于多种应用场景。&lt;h4&gt;总结&lt;/h4&gt;CS-DPMamba方法有效解决了MTS分类中的长距离依赖和相似性问题，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series (MTS) data is generated through multiple sensorsacross various domains such as engineering application, health monitoring, andthe internet of things, characterized by its temporal changes and highdimensional characteristics. Over the past few years, many studies haveexplored the long-range dependencies and similarities in MTS. However,long-range dependencies are difficult to model due to their temporal changesand high dimensionality makes it difficult to obtain similarities effectivelyand efficiently. Thus, to address these issues, we propose contrastsimilarity-aware dual-pathway Mamba for MTS node classification (CS-DPMamba).Firstly, to obtain the dynamic similarity of each sample, we initially usetemporal contrast learning module to acquire MTS representations. And then weconstruct a similarity matrix between MTS representations using Fast DynamicTime Warping (FastDTW). Secondly, we apply the DPMamba to consider thebidirectional nature of MTS, allowing us to better capture long-range andshort-range dependencies within the data. Finally, we utilize theKolmogorov-Arnold Network enhanced Graph Isomorphism Network to complete theinformation interaction in the matrix and MTS node classification task. Bycomprehensively considering the long-range dependencies and dynamic similarityfeatures, we achieved precise MTS node classification. We conducted experimentson multiple University of East Anglia (UEA) MTS datasets, which encompassdiverse application scenarios. Our results demonstrate the superiority of ourmethod through both supervised and semi-supervised experiments on the MTSclassification task.</description>
      <author>example@mail.com (Mingsen Du, Meng Chen, Yongjian Li, Xiuxin Zhang, Jiahui Gao, Cun Ji, Shoushui Wei)</author>
      <guid isPermaLink="false">2411.12222v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Domain Adaptive Unfolded Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.13137v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在过去十年中，图神经网络（GNNs）在多个图机器学习任务中取得了显著进展。实际应用中，当领域发生变化且新目标领域标签通常不可用时，提出了图领域适应（GDA）方法以促进知识转移。&lt;h4&gt;目的&lt;/h4&gt;探讨GDA中GNN架构的影响，并提出架构增强的方法来促进GDA。&lt;h4&gt;方法&lt;/h4&gt;研究一类基于优化问题设计的GNN，即展开GNN（UGNNs），其训练过程可表示为双层优化，并提出了一种简单有效的策略，称为级联传播（CP）。&lt;h4&gt;主要发现&lt;/h4&gt;在源领域向目标领域转移时，UGNNs生成的下层目标值显著增加，导致上层目标值也增加。CP策略能够有效降低下层目标值。&lt;h4&gt;结论&lt;/h4&gt;将CP策略应用于UGNNs后，经过在五个真实世界数据集上的广泛实验，结果显示其性能优于最先进的GDA基线。&lt;h4&gt;总结&lt;/h4&gt;本研究通过架构增强和CP策略提升UGNN在图领域适应中的表现，为GDA提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over the last decade, graph neural networks (GNNs) have made significantprogress in numerous graph machine learning tasks. In real-world applications,where domain shifts occur and labels are often unavailable for a new targetdomain, graph domain adaptation (GDA) approaches have been proposed tofacilitate knowledge transfer from the source domain to the target domain.Previous efforts in tackling distribution shifts across domains have mainlyfocused on aligning the node embedding distributions generated by the GNNs inthe source and target domains. However, as the core part of GDA approaches, theimpact of the underlying GNN architecture has received limited attention. Inthis work, we explore this orthogonal direction, i.e., how to facilitate GDAwith architectural enhancement. In particular, we consider a class of GNNs thatare designed explicitly based on optimization problems, namely unfolded GNNs(UGNNs), whose training process can be represented as bi-level optimization.Empirical and theoretical analyses demonstrate that when transferring from thesource domain to the target domain, the lower-level objective value generatedby the UGNNs significantly increases, resulting in an increase in theupper-level objective as well. Motivated by this observation, we propose asimple yet effective strategy called cascaded propagation (CP), which isguaranteed to decrease the lower-level objective value. The CP strategy iswidely applicable to general UGNNs, and we evaluate its efficacy with threerepresentative UGNN architectures. Extensive experiments on five real-worlddatasets demonstrate that the UGNNs integrated with CP outperformstate-of-the-art GDA baselines.</description>
      <author>example@mail.com (Zepeng Zhang, Olga Fink)</author>
      <guid isPermaLink="false">2411.13137v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Towards Sample-Efficiency and Generalization of Transfer and Inverse Reinforcement Learning: A Comprehensive Literature Review</title>
      <link>http://arxiv.org/abs/2411.10268v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;强化学习（RL）是机器学习的一个子领域，主要解决学习代理与决策环境交互以优化其行为的问题。&lt;h4&gt;目的&lt;/h4&gt;综述通过转移和逆强化学习（T-IRL）提高强化学习算法的样本效率和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;介绍强化学习的基本概念，展示T-IRL的基本方法，并回顾各研究领域的最新进展。&lt;h4&gt;主要发现&lt;/h4&gt;大多数近期研究通过人类参与和从模拟到现实的策略，解决样本效率和泛化问题，促进知识从源领域向目标领域的有效转移。&lt;h4&gt;结论&lt;/h4&gt;研究者们优先考虑需要较少经验转移的训练方案，并将此框架扩展至多智能体和多意图问题。&lt;h4&gt;总结&lt;/h4&gt;本文全面探讨了在T-IRL框架下，应对强化学习样本效率和泛化能力挑战的最新研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) is a sub-domain of machine learning, mainlyconcerned with solving sequential decision-making problems by a learning agentthat interacts with the decision environment to improve its behavior throughthe reward it receives from the environment. This learning paradigm is,however, well-known for being time-consuming due to the necessity of collectinga large amount of data, making RL suffer from sample inefficiency and difficultgeneralization. Furthermore, the construction of an explicit reward functionthat accounts for the trade-off between multiple desiderata of a decisionproblem is often a laborious task. These challenges have been recentlyaddressed utilizing transfer and inverse reinforcement learning (T-IRL). Inthis regard, this paper is devoted to a comprehensive review of realizing thesample efficiency and generalization of RL algorithms through T-IRL. Followinga brief introduction to RL, the fundamental T-IRL methods are presented and themost recent advancements in each research field have been extensively reviewed.Our findings denote that a majority of recent research works have dealt withthe aforementioned challenges by utilizing human-in-the-loop and sim-to-realstrategies for the efficient transfer of knowledge from source domains to thetarget domain under the transfer learning scheme. Under the IRL structure,training schemes that require a low number of experience transitions andextension of such frameworks to multi-agent and multi-intention problems havebeen the priority of researchers in recent years.</description>
      <author>example@mail.com (Hossein Hassani, Roozbeh Razavi-Far, Mehrdad Saif, Liang Lin)</author>
      <guid isPermaLink="false">2411.10268v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Denoising With Fine-Granularity Dynamic Graph Convolutional Networks</title>
      <link>http://arxiv.org/abs/2411.14158v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D点云受限于采集设备和噪声干扰，影响后续任务如表面重建和渲染。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的去噪方法，以提高3D点云重建性能。&lt;h4&gt;方法&lt;/h4&gt;引入一种细粒度动态图卷积网络GD-GCN，采用微步时间图卷积(MST-GConv)进行特征学习。&lt;h4&gt;主要发现&lt;/h4&gt;GD-GCN比传统GCN更灵活，能够更准确地拟合带噪声的点云与底层表面。&lt;h4&gt;结论&lt;/h4&gt;GD-GCN通过Riemannian度量近似和稳健的图谱滤波器，有效捕捉不同几何区域之间的关系，增强了去噪效果。&lt;h4&gt;总结&lt;/h4&gt;GD-GCN利用神经偏微分方程适应性学习，提升了3D点云的去噪和重建能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to limitations in acquisition equipment, noise perturbations oftencorrupt 3-D point clouds, hindering down-stream tasks such as surfacereconstruction, rendering, and further processing. Existing 3-D point clouddenoising methods typically fail to reliably fit the underlying continuoussurface, resulting in a degradation of reconstruction performance. This paperintroduces fine-granularity dynamic graph convolutional networks called GD-GCN,a novel approach to denoising in 3-D point clouds. The GD-GCN employsmicro-step temporal graph convolution (MST-GConv) to perform feature learningin a gradual manner. Compared with the conventional GCN, which commonly usesdiscrete integer-step graph convolution, this modification introduces a moreadaptable and nuanced approach to feature learning within graph convolutionnetworks. It more accurately depicts the process of fitting the point cloudwith noise to the underlying surface by and the learning process for MST-GConvacts like a changing system and is managed through a type of neural networkknown as neural Partial Differential Equations (PDEs). This means it can adaptand improve over time. GD-GCN approximates the Riemannian metric, calculatingdistances between points along a low-dimensional manifold. This capabilityallows it to understand the local geometric structure and effectively capturediverse relationships between points from different geometric regions throughgeometric graph construction based on Riemannian distances. Additionally,GD-GCN incorporates robust graph spectral filters based on the Bernsteinpolynomial approximation, which modulate eigenvalues for complex and arbitraryspectral responses, providing theoretical guarantees for BIBO stability.Symmetric channel mixing matrices further enhance filter flexibility byenabling channel-level scaling and shifting in the spectral domain.</description>
      <author>example@mail.com (Wenqiang Xu, Wenrui Dai, Duoduo Xue, Ziyang Zheng, Chenglin Li, Junni Zou, Hongkai Xiong)</author>
      <guid isPermaLink="false">2411.14158v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CB$^2$O: Consensus-Based Bi-Level Optimization</title>
      <link>http://arxiv.org/abs/2411.13394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;双层优化问题在科学、工程、机器学习和人工智能中广泛存在，旨在寻找上层目标函数的全局最小值，同时考虑下层目标的全局最优解集。&lt;h4&gt;目的&lt;/h4&gt;提出并研究基于共识的双层优化（CB²O）方法，以解决可能是非凸的双层优化问题。&lt;h4&gt;方法&lt;/h4&gt;CB²O是一种多粒子元启发式无导数优化方法，通过在共识点计算中使用粒子选择原则和拉普拉斯原则类型的近似来内在地解决双层优化问题。&lt;h4&gt;主要发现&lt;/h4&gt;提供了与均值场动力学相关的解的存在性证明，并证明了共识点在Wasserstein和L²扰动下的稳定性，利用PDE考虑扩展经典Picard迭代构造解。&lt;h4&gt;结论&lt;/h4&gt;通过均值场法的全局收敛分析，验证了解的收敛性，表明在合适的超参数选择下，相关非线性非局部Fokker-Planck方程的解会快速收敛到双层优化问题的唯一解。&lt;h4&gt;实践意义&lt;/h4&gt;通过在约束全局优化、稀疏表示学习和稳健（聚类）联邦学习等应用场景中的广泛数值实验，展示了CB²O算法的实用性和效率。&lt;h4&gt;总结&lt;/h4&gt;CB²O方法为解决双层优化问题提供了一种有效的理论基础和实践工具，具有良好的收敛性和应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bi-level optimization problems, where one wishes to find the global minimizerof an upper-level objective function over the globally optimal solution set ofa lower-level objective, arise in a variety of scenarios throughout science andengineering, machine learning, and artificial intelligence. In this paper, wepropose and investigate, analytically and experimentally, consensus-basedbi-level optimization (CB$^2$O), a multi-particle metaheuristic derivative-freeoptimization method designed to solve bi-level optimization problems when bothobjectives may be nonconvex. Our method leverages within the computation of theconsensus point a carefully designed particle selection principle implementedthrough a suitable choice of a quantile on the level of the lower-levelobjective, together with a Laplace principle-type approximation w.r.t. theupper-level objective function, to ensure that the bi-level optimizationproblem is solved in an intrinsic manner. We give an existence proof ofsolutions to a corresponding mean-field dynamics, for which we first establishthe stability of our consensus point w.r.t. a combination of Wasserstein and$L^2$ perturbations, and consecutively resort to PDE considerations extendingthe classical Picard iteration to construct a solution. For such solution, weprovide a global convergence analysis in mean-field law showing that thesolution of the associated nonlinear nonlocal Fokker-Planck equation convergesexponentially fast to the unique solution of the bi-level optimization problemprovided suitable choices of the hyperparameters. The practicability andefficiency of our CB$^2$O algorithm is demonstrated through extensive numericalexperiments in the settings of constrained global optimization, sparserepresentation learning, and robust (clustered) federated learning.</description>
      <author>example@mail.com (Nicolás García Trillos, Sixu Li, Konstantin Riedl, Yuhua Zhu)</author>
      <guid isPermaLink="false">2411.13394v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Zero-Shot Coreset Selection: Efficient Pruning for Unlabeled Data</title>
      <link>http://arxiv.org/abs/2411.15349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习越来越依赖大量数据，而这些数据的存储、标注和模型训练成本高昂。&lt;h4&gt;目的&lt;/h4&gt;提出无标签核心集选择问题，以降低深度学习的标注成本并扩大适用规模。&lt;h4&gt;方法&lt;/h4&gt;开发了零-shot核心集选择(ZCore)方法，能够在没有真实标签或候选数据训练的情况下高效选择核心集。&lt;h4&gt;主要发现&lt;/h4&gt;ZCore利用现有基础模型生成无标签数据的零-shot嵌入空间，基于整体覆盖率和冗余性量化每个示例的相对重要性。&lt;h4&gt;结论&lt;/h4&gt;ZCore在四个数据集上表现优于多种最先进的基于标签的方法，并为未来无标签核心集选择的研究提供强有力的基准。&lt;h4&gt;总结&lt;/h4&gt;在ImageNet数据集上，ZCore的选择在仅使用10%训练数据的情况下实现了53.99%的下游模型准确率，且消除了对115万张图像的标注需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/voxel51/zcore&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning increasingly relies on massive data with substantial costs forstorage, annotation, and model training. To reduce these costs, coresetselection aims to find a representative subset of data to train models whileideally performing on par with the full data training. State-of-the-art coresetmethods use carefully-designed criteria to quantify the importance of each dataexample via ground truth labels and dataset-specific training, then selectexamples whose scores lie in a certain range to construct a coreset. Thesemethods work well in their respective settings, however, they cannot selectdata that are unlabeled, which is the majority of real-world data. To that end,this paper motivates and formalizes the problem of unlabeled coreset selectionto enable greater scale and reduce annotation costs for deep learning. As asolution, we develop Zero-Shot Coreset Selection (ZCore), a method thatefficiently selects coresets without ground truth labels or training oncandidate data. Instead, ZCore uses existing foundation models to generate azero-shot embedding space for unlabeled data, then quantifies the relativeimportance of each example based on overall coverage and redundancy within theembedding distribution. We evaluate ZCore on four datasets and outperformseveral state-of-the-art label-based methods, leading to a strong baseline forfuture research in unlabeled coreset selection. On ImageNet, ZCore selectionsachieve a downstream model accuracy of 53.99% with only 10% training data,which outperforms label-based methods while removing annotation requirementsfor 1.15 million images. Our code is publicly available athttps://github.com/voxel51/zcore.</description>
      <author>example@mail.com (Brent A. Griffin, Jacob Marks, Jason J. Corso)</author>
      <guid isPermaLink="false">2411.15349v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Effective Analog ICs Floorplanning with Relational Graph Neural Networks and Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2411.15212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures, Accepted at DATE25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模拟集成电路(IC)的布局通常由布局工程师手动进行，布局与布线步骤相互依赖，且存在多种电气和布局相关的约束，以及模拟设计中期望的高度定制化。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于强化学习的新型自动布局算法。&lt;h4&gt;方法&lt;/h4&gt;该算法结合了关系图卷积神经网络模型，用于编码电路特征和位置约束。&lt;h4&gt;主要发现&lt;/h4&gt;在应用于6个工业电路时，该方法在速度、面积和半周长导线长度方面超越了现有的布局技术。&lt;h4&gt;结论&lt;/h4&gt;将该算法集成到布局完成的程序生成器中，整体布局时间减少了67.3%，与手动布局相比平均面积减少了8.3%。&lt;h4&gt;总结&lt;/h4&gt;通过将强化学习与图神经网络结合，该研究提高了自动布局的效率和效果，展示了在不同电路设计中的知识转移能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Analog integrated circuit (IC) floorplanning is typically a manual processwith the placement of components (devices and modules) planned by a layoutengineer. This process is further complicated by the interdependence offloorplanning and routing steps, numerous electric and layout-dependentconstraints, as well as the high level of customization expected in analogdesign. This paper presents a novel automatic floorplanning algorithm based onreinforcement learning. It is augmented by a relational graph convolutionalneural network model for encoding circuit features and positional constraints.The combination of these two machine learning methods enables knowledgetransfer across different circuit designs with distinct topologies andconstraints, increasing the \emph{generalization ability} of the solution.Applied to $6$ industrial circuits, our approach surpassed establishedfloorplanning techniques in terms of speed, area and half-perimeter wirelength. When integrated into a \emph{procedural generator} for layoutcompletion, overall layout time was reduced by $67.3\%$ with a $8.3\%$ meanarea reduction compared to manual layout.</description>
      <author>example@mail.com (Davide Basso, Luca Bortolussi, Mirjana Videnovic-Misic, Husni Habal)</author>
      <guid isPermaLink="false">2411.15212v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>KDC-MAE: Knowledge Distilled Contrastive Mask Auto-Encoder</title>
      <link>http://arxiv.org/abs/2411.12270v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究旨在扩展自监督学习（SSL）范式的思路。&lt;h4&gt;目的&lt;/h4&gt;展示一种结合对比学习、自蒸馏和掩码数据建模的方式，以学习联合和协调的表示。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的SSL架构KDC-MAE，使用互补掩码策略学习模块对应关系，并采用加权方式协调组合不同学习目标。&lt;h4&gt;主要发现&lt;/h4&gt;对比掩码对应与KD学习目标的结合在多个任务中对多模态学习的性能提升有显著帮助。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，综合不同SSL目标的学习方法能够有效提高学习效果。&lt;h4&gt;总结&lt;/h4&gt;本研究通过结合三种主要的自监督学习框架，提出了一种新方法，展示了其在多任务学习中的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we attempted to extend the thought and showcase a way forwardfor the Self-supervised Learning (SSL) learning paradigm by combiningcontrastive learning, self-distillation (knowledge distillation) and maskeddata modelling, the three major SSL frameworks, to learn a joint andcoordinated representation. The proposed technique of SSL learns by thecollaborative power of different learning objectives of SSL. Hence to jointlylearn the different SSL objectives we proposed a new SSL architecture KDC-MAE,a complementary masking strategy to learn the modular correspondence, and aweighted way to combine them coordinately. Experimental results conclude thatthe contrastive masking correspondence along with the KD learning objective haslent a hand to performing better learning for multiple modalities over multipletasks.</description>
      <author>example@mail.com (Maheswar Bora, Saurabh Atreya, Aritra Mukherjee, Abhijit Das)</author>
      <guid isPermaLink="false">2411.12270v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Learning of Design Strategies over Non-Hierarchical Multi-Fidelity Models via Policy Alignment</title>
      <link>http://arxiv.org/abs/2411.10841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  48 pages, 20 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多保真强化学习框架通过利用不同精度和计算成本的分析模型显著提高工程设计的效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多保真强化学习框架ALPHA，以高效学习高保真策略。&lt;h4&gt;方法&lt;/h4&gt;ALPHA自适应地利用一组非层次化的低保真模型和一个高保真模型，动态使用低保真策略及其经验数据进行高效目标学习。&lt;h4&gt;主要发现&lt;/h4&gt;ALPHA在分析测试优化和八旋翼设计问题中表现出色，利用两个低保真模型和一个高保真模型有效学习。&lt;h4&gt;结论&lt;/h4&gt;ALPHA能够动态利用模型，避免了层次框架中对模型调度的需求，并且比层次代理显示出更好的收敛性。&lt;h4&gt;总结&lt;/h4&gt;ALPHA展示了在时间和设计空间中动态使用模型的能力，提供了更直接的高性能解决方案路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-fidelity Reinforcement Learning (RL) frameworks significantly enhancethe efficiency of engineering design by leveraging analysis models with varyinglevels of accuracy and computational costs. The prevailing methodologies,characterized by transfer learning, human-inspired strategies, control variatetechniques, and adaptive sampling, predominantly depend on a structuredhierarchy of models. However, this reliance on a model hierarchy overlooks theheterogeneous error distributions of models across the design space, extendingbeyond mere fidelity levels. This work proposes ALPHA (Adaptively LearnedPolicy with Heterogeneous Analyses), a novel multi-fidelity RL framework toefficiently learn a high-fidelity policy by adaptively leveraging an arbitraryset of non-hierarchical, heterogeneous, low-fidelity models alongside ahigh-fidelity model. Specifically, low-fidelity policies and their experiencedata are dynamically used for efficient targeted learning, guided by theiralignment with the high-fidelity policy. The effectiveness of ALPHA isdemonstrated in analytical test optimization and octocopter design problems,utilizing two low-fidelity models alongside a high-fidelity one. The resultshighlight ALPHA's adaptive capability to dynamically utilize models across timeand design space, eliminating the need for scheduling models as required in ahierarchical framework. Furthermore, the adaptive agents find more direct pathsto high-performance solutions, showing superior convergence behavior comparedto hierarchical agents.</description>
      <author>example@mail.com (Akash Agrawal, Christopher McComb)</author>
      <guid isPermaLink="false">2411.10841v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Novel View Extrapolation with Video Diffusion Priors</title>
      <link>http://arxiv.org/abs/2411.14208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新视图合成领域因辐射场方法的发展而取得显著进展，但大多数辐射场技术在新视图插值方面表现优于新视图外推。&lt;h4&gt;目的&lt;/h4&gt;设计ViewExtrapolator，一种利用稳定视频扩散（SVD）生成先验进行现实的新视图外推的方法。&lt;h4&gt;方法&lt;/h4&gt;通过重新设计SVD去噪过程，ViewExtrapolator改进了由辐射场渲染的易产生伪影的视图，显著提升合成新视图的清晰度和真实感。&lt;h4&gt;主要发现&lt;/h4&gt;ViewExtrapolator是一种通用的新视图外推器，能够与不同类型的3D渲染工作，即使在仅有单视图或单目视频的情况下也能有效运作。&lt;h4&gt;结论&lt;/h4&gt;ViewExtrapolator无需对SVD进行微调，具备数据高效和计算高效的特点，实验结果显示其在新视图外推方面的优越性。&lt;h4&gt;总结&lt;/h4&gt;ViewExtrapolator通过改进的去噪过程和无需微调的特性，为新视图外推提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The field of novel view synthesis has made significant strides thanks to thedevelopment of radiance field methods. However, most radiance field techniquesare far better at novel view interpolation than novel view extrapolation wherethe synthesis novel views are far beyond the observed training views. We designViewExtrapolator, a novel view synthesis approach that leverages the generativepriors of Stable Video Diffusion (SVD) for realistic novel view extrapolation.By redesigning the SVD denoising process, ViewExtrapolator refines theartifact-prone views rendered by radiance fields, greatly enhancing the clarityand realism of the synthesized novel views. ViewExtrapolator is a generic novelview extrapolator that can work with different types of 3D rendering such asviews rendered from point clouds when only a single view or monocular video isavailable. Additionally, ViewExtrapolator requires no fine-tuning of SVD,making it both data-efficient and computation-efficient. Extensive experimentsdemonstrate the superiority of ViewExtrapolator in novel view extrapolation.Project page: \url{https://kunhao-liu.github.io/ViewExtrapolator/}.</description>
      <author>example@mail.com (Kunhao Liu, Ling Shao, Shijian Lu)</author>
      <guid isPermaLink="false">2411.14208v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>HARec: Hyperbolic Graph-LLM Alignment for Exploration and Exploitation in Recommender Systems</title>
      <link>http://arxiv.org/abs/2411.13865v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代推荐系统常常导致信息茧房，限制用户接触多样化内容。&lt;h4&gt;目的&lt;/h4&gt;提升用户体验，平衡内容的探索与利用，使用户能调整推荐偏好。&lt;h4&gt;方法&lt;/h4&gt;提出HARec框架，通过超曲率空间共同对齐用户-物品协同信息与文本描述，采用层次感知图与超曲率层次结构。&lt;h4&gt;主要发现&lt;/h4&gt;HARec在效用指标上提高了最多5.49%，在多样性指标上增加了11.39%。&lt;h4&gt;结论&lt;/h4&gt;HARec框架在推荐系统中优于现有的欧几里得和超曲率基线，能够更好地处理探索与利用的平衡。&lt;h4&gt;总结&lt;/h4&gt;HARec通过超曲率表示学习有效解决了层次结构建模和语义对齐的问题，提升了推荐效果与多样性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern recommendation systems often create information cocoons, limitingusers' exposure to diverse content. To enhance user experience, a crucialchallenge is developing systems that can balance content exploration andexploitation, allowing users to adjust their recommendation preferences.Intuitively, this balance can be achieved through a tree-structuredrepresentation, where depth search facilitates exploitation and breadth searchenables exploration. However, current works face two challenges to achieve thistarget: (1) Euclidean methods fail to fully capture hierarchical structures andlack flexibility in balancing exploration-exploitation, while (2) hyperbolicapproaches, despite better hierarchical modeling, suffer from insufficientsemantic alignment due to their reliance on Euclidean text encoders. To addressthese challenges, we propose HARec, a hyperbolic representation learningframework that jointly aligns user-item collaborative information with textualdescriptions in hyperbolic space. Our framework introduces two key techniquenovelty: (1) a hierarchical-aware graph-llm alignment mechanism that enablesbetter hierarchical representation, and (2) a hyperbolic hierarchical treestructure that facilitates user-adjustable exploration-exploitation trade-offs.Extensive experiments demonstrate that HARec consistently outperforms bothEuclidean and hyperbolic baselines, achieving up to 5.49% improvement inutility metrics and 11.39% increase in diversity metrics.</description>
      <author>example@mail.com (Qiyao Ma, Menglin Yang, Mingxuan Ju, Tong Zhao, Neil Shah, Rex Ying)</author>
      <guid isPermaLink="false">2411.13865v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Gradient dynamics for low-rank fine-tuning beyond kernels</title>
      <link>http://arxiv.org/abs/2411.15385v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;LoRA已成为一种低计算成本和内存占用的基础模型微调方法。&lt;h4&gt;目的&lt;/h4&gt;研究在学生-教师模型设置中低秩微调的学习机制。&lt;h4&gt;方法&lt;/h4&gt;使用两层基础模型的权重和独立同分布样本，通过对基础模型权重施加秩-1矩阵的扰动来形成教师模型。&lt;h4&gt;主要发现&lt;/h4&gt;在权重矩阵与秩-1扰动的范数相当时，训练动态是非线性的，并且学生模型在在线梯度下降下能在$dk^{O(1)}$次迭代内收敛到教师模型。&lt;h4&gt;结论&lt;/h4&gt;与广义线性模型设置不同，模型复杂度不依赖于激活的Hermite展开的细粒度特性，从零学习教师模型可能需要更多的迭代。&lt;h4&gt;总结&lt;/h4&gt;本研究为理解低秩微调的学习机制提供了新的视角，揭示了在线梯度下降在特定条件下的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LoRA has emerged as one of the de facto methods for fine-tuning foundationmodels with low computational cost and memory footprint. The idea is to onlytrain a low-rank perturbation to the weights of a pre-trained model, givensupervised data for a downstream task. Despite its empirical sucess, from amathematical perspective it remains poorly understood what learning mechanismsensure that gradient descent converges to useful low-rank perturbations.  In this work we study low-rank fine-tuning in a student-teacher setting. Weare given the weights of a two-layer base model $f$, as well as i.i.d. samples$(x,f^*(x))$ where $x$ is Gaussian and $f^*$ is the teacher model given byperturbing the weights of $f$ by a rank-1 matrix. This generalizes the settingof generalized linear model (GLM) regression where the weights of $f$ are zero.  When the rank-1 perturbation is comparable in norm to the weight matrix of$f$, the training dynamics are nonlinear. Nevertheless, in this regime we proveunder mild assumptions that a student model which is initialized at the basemodel and trained with online gradient descent will converge to the teacher in$dk^{O(1)}$ iterations, where $k$ is the number of neurons in $f$. Importantly,unlike in the GLM setting, the complexity does not depend on fine-grainedproperties of the activation's Hermite expansion. We also prove that in oursetting, learning the teacher model "from scratch'' can require significantlymore iterations.</description>
      <author>example@mail.com (Arif Kerem Dayi, Sitan Chen)</author>
      <guid isPermaLink="false">2411.15385v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Large-scale cross-modality pretrained model enhances cardiovascular state estimation and cardiomyopathy detection from electrocardiograms: An AI system development and multi-center validation study</title>
      <link>http://arxiv.org/abs/2411.13602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;心血管疾病在早期和准确诊断方面面临重大挑战，心脏磁共振成像（CMR）是评估心脏功能和诊断心血管疾病的金标准，但其高成本和技术复杂性限制了可及性。&lt;h4&gt;目的&lt;/h4&gt;本研究提出CardiacNets模型，通过跨模态对比学习和生成预训练，增强心电图（ECG）分析的诊断能力。&lt;h4&gt;方法&lt;/h4&gt;CardiacNets主要有两个功能：一是使用ECG输入评估详细的心脏功能指标，并筛查潜在的心血管疾病；二是通过ECG数据生成高质量的CMR图像以增强可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;在两个大型公共数据集（UK Biobank和MIMIC-IV-ECG）以及三个私有数据集上进行训练和验证后，CardiacNets在筛查准确性方面显著优于传统的仅基于ECG的模型。&lt;h4&gt;结论&lt;/h4&gt;生成的CMR图像为不同经验水平的医生提供了有价值的诊断支持，表明ECG可以为心脏功能评估提供跨模态的见解，促进心血管疾病筛查和诊断的提升。&lt;h4&gt;总结&lt;/h4&gt;本研究证明了CardiacNets在心血管疾病早期筛查中的潜力，能够提高筛查的准确性并为临床医生提供重要支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yukui-1999/ecg-cmr&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiovascular diseases (CVDs) present significant challenges for early andaccurate diagnosis. While cardiac magnetic resonance imaging (CMR) is the goldstandard for assessing cardiac function and diagnosing CVDs, its high cost andtechnical complexity limit accessibility. In contrast, electrocardiography(ECG) offers promise for large-scale early screening. This study introducesCardiacNets, an innovative model that enhances ECG analysis by leveraging thediagnostic strengths of CMR through cross-modal contrastive learning andgenerative pretraining. CardiacNets serves two primary functions: (1) itevaluates detailed cardiac function indicators and screens for potential CVDs,including coronary artery disease, cardiomyopathy, pericarditis, heart failureand pulmonary hypertension, using ECG input; and (2) it enhancesinterpretability by generating high-quality CMR images from ECG data. We trainand validate the proposed CardiacNets on two large-scale public datasets (theUK Biobank with 41,519 individuals and the MIMIC-IV-ECG comprising 501,172samples) as well as three private datasets (FAHZU with 410 individuals, SAHZUwith 464 individuals, and QPH with 338 individuals), and the findingsdemonstrate that CardiacNets consistently outperforms traditional ECG-onlymodels, substantially improving screening accuracy. Furthermore, the generatedCMR images provide valuable diagnostic support for physicians of all experiencelevels. This proof-of-concept study highlights how ECG can facilitatecross-modal insights into cardiac function assessment, paving the way forenhanced CVD screening and diagnosis at a population level.</description>
      <author>example@mail.com (Zhengyao Ding, Yujian Hu, Youyao Xu, Chengchen Zhao, Ziyu Li, Yiheng Mao, Haitao Li, Qian Li, Jing Wang, Yue Chen, Mengjia Chen, Longbo Wang, Xuesen Chu, Weichao Pan, Ziyi Liu, Fei Wu, Hongkun Zhang, Ting Chen, Zhengxing Huang)</author>
      <guid isPermaLink="false">2411.13602v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Predicting Wall Thickness Changes in Cold Forging Processes: An Integrated FEM and Neural Network approach</title>
      <link>http://arxiv.org/abs/2411.13366v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究提出了一种新方法，用于预测管材在成形过程中壁厚的变化。&lt;h4&gt;目的&lt;/h4&gt;深入分析成形过程及其影响参数，并开发实时应用的模型。&lt;h4&gt;方法&lt;/h4&gt;建立有限元方法（FEM）仿真，并基于图神经网络的替代模型进行建模，增强模型的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;使用新评价指标（ABTC）评估模型，结果显示神经网络在预测壁厚变化方面表现良好。&lt;h4&gt;结论&lt;/h4&gt;神经网络作为替代模型在成形锻造过程中具有潜在应用价值，可以用于闭环生产过程。&lt;h4&gt;总结&lt;/h4&gt;研究表明，改进的建模框架能有效预测管材壁厚变化，为实时生产提供支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents a novel approach for predicting wall thickness changes intubes during the nosing process. Specifically, we first provide a thoroughanalysis of nosing processes and the influencing parameters. We further set-upa Finite Element Method (FEM) simulation to better analyse the effects ofvarying process parameters. As however traditional FEM simulations, whileaccurate, are time-consuming and computationally intensive, which renders theminapplicable for real-time application, we present a novel modeling frameworkbased on specifically designed graph neural networks as surrogate models. Tothis end, we extend the neural network architecture by directly incorporatinginformation about the nosing process by adding different types of edges andtheir corresponding encoders to model object interactions. This augmentationenhances model accuracy and opens the possibility for employing precisesurrogate models within closed-loop production processes. The proposed approachis evaluated using a new evaluation metric termed area between thickness curves(ABTC). The results demonstrate promising performance and highlight thepotential of neural networks as surrogate models in predicting wall thicknesschanges during nosing forging processes.</description>
      <author>example@mail.com (Sasa Ilic, Abdulkerim Karaman, Johannes Pöppelbaum, Jan Niclas Reimann, Michael Marré, Andreas Schwung)</author>
      <guid isPermaLink="false">2411.13366v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Transfer Learning for Video-language Foundation Models</title>
      <link>http://arxiv.org/abs/2411.11223v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预训练的视觉-语言模型为多种下游任务提供了有效的迁移学习基础。在视频动作识别领域，主流方法通常引入额外的参数模块以捕捉时间信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单而有效的多模态时空适配器（MSTA），以改善文本和视觉分支之间的表示对齐，实现一般知识和任务特定知识的平衡。&lt;h4&gt;方法&lt;/h4&gt;引入时空描述引导的一致性约束，使用模板输入（例如，'一个视频的{cls}'）进入可训练的语言分支，同时将LLM生成的时空描述输入预训练的语言分支，从而强制两者输出的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;该机制防止了对下游任务的过拟合，提高了可训练分支在时空语义空间中的区分能力。&lt;h4&gt;结论&lt;/h4&gt;通过在四个任务上进行评估，我们的方法在零-shot迁移、few-shot学习、基础到新颖的泛化和完全监督学习中表现出色，仅使用原始模型的2-7%的可训练参数。&lt;h4&gt;总结&lt;/h4&gt;MSTA在多个评估中相较于许多最先进的方法表现突出，代码将发布在https://github.com/chenhaoxing/ETL4Video。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chenhaoxing/etl4video&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained vision-language models provide a robust foundation for efficienttransfer learning across various downstream tasks. In the field of video actionrecognition, mainstream approaches often introduce additional parameter modulesto capture temporal information. While the increased model capacity brought bythese additional parameters helps better fit the video-specific inductivebiases, existing methods require learning a large number of parameters and areprone to catastrophic forgetting of the original generalizable knowledge. Inthis paper, we propose a simple yet effective Multi-modal Spatio-TemporalAdapter (MSTA) to improve the alignment between representations in the text andvision branches, achieving a balance between general knowledge andtask-specific knowledge. Furthermore, to mitigate over-fitting and enhancegeneralizability, we introduce a spatio-temporal description-guided consistencyconstraint. This constraint involves feeding template inputs (i.e., ``a videoof $\{\textbf{cls}\}$'') into the trainable language branch, whileLLM-generated spatio-temporal descriptions are input into the pre-trainedlanguage branch, enforcing consistency between the outputs of the two branches.This mechanism prevents over-fitting to downstream tasks and improves thedistinguishability of the trainable branch within the spatio-temporal semanticspace. We evaluate the effectiveness of our approach across four tasks:zero-shot transfer, few-shot learning, base-to-novel generalization, andfully-supervised learning. Compared to many state-of-the-art methods, our MSTAachieves outstanding performance across all evaluations, while using only 2-7\%of the trainable parameters in the original model. Code will be avaliable athttps://github.com/chenhaoxing/ETL4Video.</description>
      <author>example@mail.com (Haoxing Chen, Zizheng Huang, Yan Hong, Yanshuo Wang, Zhongcai Lyu, Zhuoer Xu, Jun Lan, Zhangxuan Gu)</author>
      <guid isPermaLink="false">2411.11223v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>InCrowd-VI: A Realistic Visual-Inertial Dataset for Evaluating SLAM in Indoor Pedestrian-Rich Spaces for Human Navigation</title>
      <link>http://arxiv.org/abs/2411.14358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 5 tabels&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的SLAM技术在为视障人士导航时在拥挤空间中的应用受到真实数据集不足的限制。&lt;h4&gt;目的&lt;/h4&gt;引入InCrowd-VI数据集，以促进在室内行人密集环境中进行人类导航的研究。&lt;h4&gt;方法&lt;/h4&gt;使用Meta Aria Project眼镜录制数据，捕捉没有环境控制的真实场景。&lt;h4&gt;主要发现&lt;/h4&gt;InCrowd-VI包含58个序列，总长5公里，录制时间1.5小时，数据包括RGB图像、立体图像和IMU测量。&lt;h4&gt;结论&lt;/h4&gt;评估现有视觉里程计和SLAM算法时发现其在真实场景下的性能严重受限，强调了新数据集在推动SLAM研究中的重要性。&lt;h4&gt;挑战&lt;/h4&gt;数据集中捕捉了行人遮挡、不同人群密度、复杂布局和光照变化等重要挑战。&lt;h4&gt;数据特点&lt;/h4&gt;提供约2厘米精度的真实轨迹和每个序列的半稠密3D点云。&lt;h4&gt;总结&lt;/h4&gt;InCrowd-VI数据集对于提升视障人士在复杂室内环境导航的SLAM研究具有重要价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous localization and mapping (SLAM) techniques can be used tonavigate the visually impaired, but the development of robust SLAM solutionsfor crowded spaces is limited by the lack of realistic datasets. To addressthis, we introduce InCrowd-VI, a novel visual-inertial dataset specificallydesigned for human navigation in indoor pedestrian-rich environments. Recordedusing Meta Aria Project glasses, it captures realistic scenarios withoutenvironmental control. InCrowd-VI features 58 sequences totaling a 5 kmtrajectory length and 1.5 hours of recording time, including RGB, stereoimages, and IMU measurements. The dataset captures important challenges such aspedestrian occlusions, varying crowd densities, complex layouts, and lightingchanges. Ground-truth trajectories, accurate to approximately 2 cm, areprovided in the dataset, originating from the Meta Aria project machineperception SLAM service. In addition, a semi-dense 3D point cloud of scenes isprovided for each sequence. The evaluation of state-of-the-art visual odometry(VO) and SLAM algorithms on InCrowd-VI revealed severe performance limitationsin these realistic scenarios, demonstrating the need and value of the newdataset to advance SLAM research for visually impaired navigation in complexindoor environments.</description>
      <author>example@mail.com (Marziyeh Bamdad, Hans-Peter Hutter, Alireza Darvishy)</author>
      <guid isPermaLink="false">2411.14358v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Trajectory Representation Learning on Road Networks and Grids with Spatio-Temporal Dynamics</title>
      <link>http://arxiv.org/abs/2411.14014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;轨迹表示学习是智能城市和城市规划等领域的基础任务，能够促进轨迹数据（如车辆移动）在各种下游应用中的利用。&lt;h4&gt;目的&lt;/h4&gt;学习低维表示，以便更好地进行轨迹相似性计算和旅行时间估计。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新模型TIGR，旨在整合网格和道路网络模态，并结合时空动态，以学习丰富的通用轨迹表示。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界数据集上的评估中，TIGR显著优于现有最先进的方法，轨迹相似性提高了43.22%，旅行时间估计提高了16.65%，目的地预测提高了10.16%。&lt;h4&gt;结论&lt;/h4&gt;TIGR模型有效地结合了不同模态的信息，充分考虑了城市交通的动态特性，提升了轨迹表示学习的效果。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了整合多模态和动态特征在轨迹表示学习中的重要性，推动了相关应用的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory representation learning is a fundamental task for applications infields including smart city, and urban planning, as it facilitates theutilization of trajectory data (e.g., vehicle movements) for various downstreamapplications, such as trajectory similarity computation or travel timeestimation. This is achieved by learning low-dimensional representations fromhigh-dimensional and raw trajectory data. However, existing methods fortrajectory representation learning either rely on grid-based or road-basedrepresentations, which are inherently different and thus, could loseinformation contained in the other modality. Moreover, these methods overlookthe dynamic nature of urban traffic, relying on static road network featuresrather than time varying traffic patterns. In this paper, we propose TIGR, anovel model designed to integrate grid and road network modalities whileincorporating spatio-temporal dynamics to learn rich, general-purposerepresentations of trajectories. We evaluate TIGR on two realworld datasets anddemonstrate the effectiveness of combining both modalities by substantiallyoutperforming state-of-the-art methods, i.e., up to 43.22% for trajectorysimilarity, up to 16.65% for travel time estimation, and up to 10.16% fordestination prediction.</description>
      <author>example@mail.com (Stefan Schestakov, Simon Gottschalk)</author>
      <guid isPermaLink="false">2411.14014v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Less is More: Optimizing Function Calling for LLM Execution on Edge Devices</title>
      <link>http://arxiv.org/abs/2411.15399v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at DATE 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型的高级函数调用能力为执行复杂API任务的代理部署开辟了新机遇，但管理大量数据和多个API使得函数调用在边缘设备上变得硬件密集且成本高昂。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法以提高大语言模型（LLMs）在边缘设备上的函数调用性能。&lt;h4&gt;方法&lt;/h4&gt;引入Less-is-More方案，通过动态工具选择，选择性减少可用工具数量，以提高LLMs的函数调用表现。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，选择性减少工具数量显著提高了函数调用性能，执行时间减少了多达70%，功耗降低了多达40%。&lt;h4&gt;结论&lt;/h4&gt;该方法在边缘硬件上有效提升了执行成功率，证明了减少工具数量对提高LLMs性能的重要性。&lt;h4&gt;总结&lt;/h4&gt;Less-is-More方案为边缘设备上的函数调用提供了一种有效的优化策略，降低了资源消耗并提高了任务完成精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advanced function-calling capabilities of foundation models open up newpossibilities for deploying agents to perform complex API tasks. However,managing large amounts of data and interacting with numerous APIs makesfunction calling hardware-intensive and costly, especially on edge devices.Current Large Language Models (LLMs) struggle with function calling at the edgebecause they cannot handle complex inputs or manage multiple tools effectively.This results in low task-completion accuracy, increased delays, and higherpower consumption. In this work, we introduce Less-is-More, a novelfine-tuning-free function-calling scheme for dynamic tool selection. Ourapproach is based on the key insight that selectively reducing the number oftools available to LLMs significantly improves their function-callingperformance, execution time, and power efficiency on edge devices. Experimentalresults with state-of-the-art LLMs on edge hardware show agentic success rateimprovements, with execution time reduced by up to 70% and power consumption byup to 40%.</description>
      <author>example@mail.com (Varatheepan Paramanayakam, Andreas Karatzas, Iraklis Anagnostopoulos, Dimitrios Stamoulis)</author>
      <guid isPermaLink="false">2411.15399v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>UMGAD: Unsupervised Multiplex Graph Anomaly Detection</title>
      <link>http://arxiv.org/abs/2411.12556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图异常检测（GAD）在图机器学习中是一项关键任务，旨在识别显著偏离大多数的异常节点，广泛应用于欺诈检测和社交网络分析等实际场景。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的无监督多重图异常检测方法UMGAD，以应对现有方法的主要挑战。&lt;h4&gt;方法&lt;/h4&gt;通过图掩码自编码器（GMAE）学习多关系节点间的相关性，并在节点属性和结构重建中捕捉异常信息。同时生成属性级和子图级的增强视图图，通过对比学习优化节点属性和结构特征。&lt;h4&gt;主要发现&lt;/h4&gt;UMGAD在四个数据集上的实验结果显示，模型在AUC和Macro-F1指标上分别平均提高了13.48%和11.68%。&lt;h4&gt;结论&lt;/h4&gt;UMGAD显著优于现有最先进的方法，能够有效进行无监督异常检测，且其新提出的异常分数阈值选择策略使得模型在真实无监督场景中不依赖于真实标签。&lt;h4&gt;总结&lt;/h4&gt;UMGAD方法通过多重图数据处理和对比学习，克服了传统GAD方法在多重交互类型和阈值选择方面的局限，展示了良好的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph anomaly detection (GAD) is a critical task in graph machine learning,with the primary objective of identifying anomalous nodes that deviatesignificantly from the majority. This task is widely applied in variousreal-world scenarios, including fraud detection and social network analysis.However, existing GAD methods still face two major challenges: (1) They areoften limited to detecting anomalies in single-type interaction graphs andstruggle with multiple interaction types in multiplex heterogeneous graphs; (2)In unsupervised scenarios, selecting appropriate anomaly score thresholdsremains a significant challenge for accurate anomaly detection. To address theabove challenges, we propose a novel Unsupervised Multiplex Graph AnomalyDetection method, named UMGAD. We first learn multi-relational correlationsamong nodes in multiplex heterogeneous graphs and capture anomaly informationduring node attribute and structure reconstruction through graph-maskedautoencoder (GMAE). Then, to further weaken the influence of noise andredundant information on abnormal information extraction, we generateattribute-level and subgraph-level augmented-view graphs respectively, andperform attribute and structure reconstruction through GMAE. Finally, We learnto optimize node attributes and structural features through contrastivelearning between original-view and augmented-view graphs to improve the model'sability to capture anomalies. Meanwhile, we also propose a new anomaly scorethreshold selection strategy, which allows the model to be independent of theground truth in real unsupervised scenarios. Extensive experiments on fourdatasets show that our \model significantly outperforms state-of-the-artmethods, achieving average improvements of 13.48% in AUC and 11.68% in Macro-F1across all datasets.</description>
      <author>example@mail.com (Xiang Li, Jianpeng Qi, Zhongying Zhao, Guanjie Zheng, Lei Cao, Junyu Dong, Yanwei Yu)</author>
      <guid isPermaLink="false">2411.12556v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Heatwave Forecasting via Distribution Informed-Graph Neural Networks (DI-GNNs): Integrating Extreme Value Theory with GNNs</title>
      <link>http://arxiv.org/abs/2411.13496v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 13 figures, pdf format&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;热浪的频率和强度因气候变化而加剧，严重威胁公共健康、生态系统和基础设施。&lt;h4&gt;目的&lt;/h4&gt;提高热浪的预测准确性，特别是在天气尺度（1-15天）上。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架——分布信息图神经网络（DI-GNN），将极值理论的原则融入图神经网络架构。&lt;h4&gt;主要发现&lt;/h4&gt;DI-GNN在平衡准确性、召回率和精确度上显著优于基线模型，并在加拿大不列颠哥伦比亚省的实证评估中表现出色。&lt;h4&gt;结论&lt;/h4&gt;DI-GNN通过关注气候分布的尾部，克服了现有方法的局限性，特别是在不平衡数据集上，其表现更为稳健。&lt;h4&gt;总结&lt;/h4&gt;该研究提出的DI-GNN为热浪预测提供了一种有效的新方法，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heatwaves, prolonged periods of extreme heat, have intensified in frequencyand severity due to climate change, posing substantial risks to public health,ecosystems, and infrastructure. Despite advancements in Machine Learning (ML)modeling, accurate heatwave forecasting at weather scales (1--15 days) remainschallenging due to the non-linear interactions between atmospheric drivers andthe rarity of these extreme events. Traditional models relying on heuristicfeature engineering often fail to generalize across diverse climates andcapture the complexities of heatwave dynamics. This study introduces theDistribution-Informed Graph Neural Network (DI-GNN), a novel framework thatintegrates principles from Extreme Value Theory (EVT) into the graph neuralnetwork architecture. DI-GNN incorporates Generalized Pareto Distribution(GPD)-derived descriptors into the feature space, adjacency matrix, and lossfunction to enhance its sensitivity to rare heatwave occurrences. Byprioritizing the tails of climatic distributions, DI-GNN addresses thelimitations of existing methods, particularly in imbalanced datasets wheretraditional metrics like accuracy are misleading. Empirical evaluations usingweather station data from British Columbia, Canada, demonstrate the superiorperformance of DI-GNN compared to baseline models. DI-GNN achieved significantimprovements in balanced accuracy, recall, and precision, with high AUC andaverage precision scores, reflecting its robustness in distinguishing heatwaveevents.</description>
      <author>example@mail.com (Farrukh A. Chishtie, Dominique Brunet, Rachel H. White, Daniel Michelson, Jing Jiang, Vicky Lucas, Emily Ruboonga, Sayana Imaash, Melissa Westland, Timothy Chui, Rana Usman Ali, Mujtaba Hassan, Roland Stull, David Hudak)</author>
      <guid isPermaLink="false">2411.13496v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TL-CLIP: A Power-specific Multimodal Pre-trained Visual Foundation Model for Transmission Line Defect Recognition</title>
      <link>http://arxiv.org/abs/2411.11370v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的输电线路缺陷识别模型通常使用通用的预训练权重作为训练的基础，这导致模型的泛化能力较弱，缺乏领域知识。&lt;h4&gt;目的&lt;/h4&gt;提出一种两阶段的输电线路导向对比语言-图像预训练框架（TL-CLIP），为输电线路缺陷识别奠定更有效的基础。&lt;h4&gt;方法&lt;/h4&gt;预训练过程采用新颖的电力特定多模态算法，并辅以两个电力特定的预训练任务，以更好地建模检查数据中的电力相关语义知识。同时，开发了一种迁移学习策略，通过预训练目标进行微调（FTP），以缓解有限检查数据导致的过拟合问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提方法在分类和检测任务中显著提高了输电线路缺陷识别的性能，明显优于传统的预训练模型。&lt;h4&gt;结论&lt;/h4&gt;TL-CLIP框架在输电线路检查场景中显示出明显优势，为缺陷识别提供了更强的支持。&lt;h4&gt;总结&lt;/h4&gt;该研究为输电线路缺陷识别提供了一种新的有效方法，提高了模型的性能和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transmission line defect recognition models have traditionally used generalpre-trained weights as the initial basis for their training. These models oftensuffer weak generalization capability due to the lack of domain knowledge inthe pre-training dataset. To address this issue, we propose a two-stagetransmission-line-oriented contrastive language-image pre-training (TL-CLIP)framework, which lays a more effective foundation for transmission line defectrecognition. The pre-training process employs a novel power-specific multimodalalgorithm assisted with two power-specific pre-training tasks for bettermodeling the power-related semantic knowledge contained in the inspection data.To fine-tune the pre-trained model, we develop a transfer learning strategy,namely fine-tuning with pre-training objective (FTP), to alleviate theoverfitting problem caused by limited inspection data. Experimental resultsdemonstrate that the proposed method significantly improves the performance oftransmission line defect recognition in both classification and detectiontasks, indicating clear advantages over traditional pre-trained models in thescene of transmission line inspection.</description>
      <author>example@mail.com (Ke Zhang, Zhaoye Zheng, Yurong Guo, Jiacun Wang, Jiyuan Yang, Yangjie Xiao)</author>
      <guid isPermaLink="false">2411.11370v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>FracGM: A Fast Fractional Programming Technique for Geman-McClure Robust Estimator</title>
      <link>http://arxiv.org/abs/2409.13978v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;鲁棒估计在计算机视觉、机器人技术和导航中至关重要，旨在减少离群值测量的影响，提高准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种快速的Geman-McClure鲁棒估计算法FracGM。&lt;h4&gt;方法&lt;/h4&gt;利用分数规划技术，将非凸分数问题重构为凸对偶问题和线性方程组，通过交替优化模式迭代求解。&lt;h4&gt;主要发现&lt;/h4&gt;与渐进非凸性方法相比，该策略具有更快的收敛速度和更好的离群值拒绝能力。&lt;h4&gt;结论&lt;/h4&gt;在给定条件下，所提的求解器保证全局最优性。FracGM在Wahba旋转问题和3D点云配准中表现出色，能有效处理离群值。&lt;h4&gt;应用&lt;/h4&gt;当离群率从20%增加到80%时，FracGM显示出53%和88%更低的旋转和位移增加。&lt;h4&gt;性能&lt;/h4&gt;在实际场景中，FracGM在18个结果中有13个表现更好，计算时间提高了19.43%。&lt;h4&gt;总结&lt;/h4&gt;FracGM算法在鲁棒估计中表现出色，适用于解决复杂的实际问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2024.3495372&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/StephLin/FracGM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust estimation is essential in computer vision, robotics, and navigation,aiming to minimize the impact of outlier measurements for improved accuracy. Wepresent a fast algorithm for Geman-McClure robust estimation, FracGM,leveraging fractional programming techniques. This solver reformulates theoriginal non-convex fractional problem to a convex dual problem and a linearequation system, iteratively solving them in an alternating optimizationpattern. Compared to graduated non-convexity approaches, this strategy exhibitsa faster convergence rate and better outlier rejection capability. In addition,the global optimality of the proposed solver can be guaranteed under givenconditions. We demonstrate the proposed FracGM solver with Wahba's rotationproblem and 3-D point-cloud registration along with relaxation pre-processingand projection post-processing. Compared to state-of-the-art algorithms, whenthe outlier rates increase from 20% to 80%, FracGM shows 53% and 88% lowerrotation and translation increases. In real-world scenarios, FracGM achievesbetter results in 13 out of 18 outcomes, while having a 19.43% improvement inthe computation time.</description>
      <author>example@mail.com (Bang-Shien Chen, Yu-Kai Lin, Jian-Yu Chen, Chih-Wei Huang, Jann-Long Chern, Ching-Cherng Sun)</author>
      <guid isPermaLink="false">2409.13978v3</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>WARLearn: Weather-Adaptive Representation Learning</title>
      <link>http://arxiv.org/abs/2411.14095v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE/CVF Winter Conference on
  Applications of Computer Vision (WACV), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新的框架WARLearn，旨在处理具有挑战性的恶劣天气条件下的自适应表示学习。&lt;h4&gt;目的&lt;/h4&gt;有效地将最初在晴朗天气数据上训练的模型迁移到恶劣天气条件下。&lt;h4&gt;方法&lt;/h4&gt;利用Barlow Twins中的不变性原理，在最小额外训练的情况下，提升模型在雾霾和低光照条件下的表现。&lt;h4&gt;主要发现&lt;/h4&gt;在未见的真实世界雾霾数据集上，框架的平均平均精度（mAP）为52.6%；在低光照条件下，mAP达到55.7%。&lt;h4&gt;结论&lt;/h4&gt;WARLearn在恶劣天气条件下的表现超过了多种最先进的框架，显著提高了雾霾和低光照条件下的基线性能。&lt;h4&gt;应用&lt;/h4&gt;该框架不仅适用于恶劣天气，还能应对数据分布变化的广泛领域。&lt;h4&gt;总结&lt;/h4&gt;WARLearn提供了一种强大的解决方案，帮助模型在数据分布显著变化的情况下保持更新和准确。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shubhamagarwal12/warlearn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces WARLearn, a novel framework designed for adaptiverepresentation learning in challenging and adversarial weather conditions.Leveraging the in-variance principal used in Barlow Twins, we demonstrate thecapability to port the existing models initially trained on clear weather datato effectively handle adverse weather conditions. With minimal additionaltraining, our method exhibits remarkable performance gains in scenarioscharacterized by fog and low-light conditions. This adaptive framework extendsits applicability beyond adverse weather settings, offering a versatilesolution for domains exhibiting variations in data distributions. Furthermore,WARLearn is invaluable in scenarios where data distributions undergosignificant shifts over time, enabling models to remain updated and accurate.Our experimental findings reveal a remarkable performance, with a mean averageprecision (mAP) of 52.6% on unseen real-world foggy dataset (RTTS). Similarly,in low light conditions, our framework achieves a mAP of 55.7% on unseenreal-world low light dataset (ExDark). Notably, WARLearn surpasses theperformance of state-of-the-art frameworks including FeatEnHancer, ImageAdaptive YOLO, DENet, C2PNet, PairLIE and ZeroDCE, by a substantial margin inadverse weather, improving the baseline performance in both foggy and low lightconditions. The WARLearn code is available athttps://github.com/ShubhamAgarwal12/WARLearn</description>
      <author>example@mail.com (Shubham Agarwal, Raz Birman, Ofer Hadar)</author>
      <guid isPermaLink="false">2411.14095v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation</title>
      <link>http://arxiv.org/abs/2411.14384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A novel one-stage 3DGS-based diffusion generates objects and scenes
  from a single view in ~6 seconds&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的前馈图像到3D方法主要依赖于2D多视角扩散模型，但无法保证3D一致性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的单阶段3D扩散模型DiffusionGS，以从单一视图生成对象和场景。&lt;h4&gt;方法&lt;/h4&gt;DiffusionGS在每个时间步直接输出3D高斯点云，以强制视图一致性，并支持任意方向的提示视图生成。此外，通过开发场景-对象混合训练策略，扩大3D训练数据以提高模型能力和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在生成质量上优于现有方法（PSNR提高2.20 dB，FID降低23.25），且速度超过5倍（在A100 GPU上约6秒）。&lt;h4&gt;结论&lt;/h4&gt;用户研究和文本到3D应用显示了该方法的实际价值。&lt;h4&gt;总结&lt;/h4&gt;DiffusionGS模型在3D生成任务中表现优异，具有更好的质量和速度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing feed-forward image-to-3D methods mainly rely on 2D multi-viewdiffusion models that cannot guarantee 3D consistency. These methods easilycollapse when changing the prompt view direction and mainly handleobject-centric prompt images. In this paper, we propose a novel single-stage 3Ddiffusion model, DiffusionGS, for object and scene generation from a singleview. DiffusionGS directly outputs 3D Gaussian point clouds at each timestep toenforce view consistency and allow the model to generate robustly given promptviews of any directions, beyond object-centric inputs. Plus, to improve thecapability and generalization ability of DiffusionGS, we scale up 3D trainingdata by developing a scene-object mixed training strategy. Experiments showthat our method enjoys better generation quality (2.20 dB higher in PSNR and23.25 lower in FID) and over 5x faster speed (~6s on an A100 GPU) than SOTAmethods. The user study and text-to-3D applications also reveals the practicalvalues of our method. Our Project page athttps://caiyuanhao1998.github.io/project/DiffusionGS/ shows the video andinteractive generation results.</description>
      <author>example@mail.com (Yuanhao Cai, He Zhang, Kai Zhang, Yixun Liang, Mengwei Ren, Fujun Luan, Qing Liu, Soo Ye Kim, Jianming Zhang, Zhifei Zhang, Yuqian Zhou, Zhe Lin, Alan Yuille)</author>
      <guid isPermaLink="false">2411.14384v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Mamba-CL: Optimizing Selective State Space Model in Null Space for Continual Learning</title>
      <link>http://arxiv.org/abs/2411.15469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;持续学习（CL）旨在使人工智能模型能够随着时间学习一系列任务，而不会遗忘之前学到的知识。&lt;h4&gt;目的&lt;/h4&gt;研究利用Mamba模型在持续学习中的应用，提出Mamba-CL框架。&lt;h4&gt;方法&lt;/h4&gt;通过更新与之前任务特征子空间正交的参数，持续微调Mamba基础模型的核心状态空间模型（SSMs），以保证一致性目标。&lt;h4&gt;主要发现&lt;/h4&gt;通过推导Mamba模型中四个关键的时间不变参数的一致性约束，简化其递归状态空间结构和非线性离散化过程，Mamba-CL在四个类增量基准测试上表现优越。&lt;h4&gt;结论&lt;/h4&gt;Mamba-CL有效避免了灾难性遗忘，优于现有的最先进方法。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种新方法来增强AI模型在持续学习中的表现，相关代码已在补充材料中提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual Learning (CL) aims to equip AI models with the ability to learn asequence of tasks over time, without forgetting previously learned knowledge.Recently, State Space Models (SSMs), particularly the Mamba model, haveachieved notable success in computer vision. Building on the strengths of SSMs,this study explores leveraging the Mamba model for CL. Therefore, we introduceMamba-CL, a framework that continuously fine-tunes the core SSMs of thelarge-scale Mamba foundation model by updating parameters orthogonal to thefeature subspace of previous tasks. This approach theoretically guarantees theconsistency objective aiming to preserves consistent output for each SSM moduleacross both previous and current tasks, so as to overcome catastrophicforgetting issue. Specifically, we achieve this goal by deducing the overallconsistency constraints on four key time-invariant parameters in the Mambamodel, streamlining its recurrent state-space structure and non-lineardiscretization process in SSM. In practice, we apply the null-space projectionto efficiently implement the orthogonality within Mamba model. Extensiveexperiments on four class-incremental benchmarks demonstrate the effectivenessof Mamba-CL for anti-forgetting, achieving superior performances tostate-of-the-art methods. Code is available in the supplementary materials.</description>
      <author>example@mail.com (De Cheng, Yue Lu, Lingfeng He, Shizhou Zhang, Xi Yang, Nannan Wang, Xinbo Gao)</author>
      <guid isPermaLink="false">2411.15469v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Physically Parameterized Differentiable MUSIC for DoA Estimation with Uncalibrated Arrays</title>
      <link>http://arxiv.org/abs/2411.15144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;到达方向（DoA）估计是雷达、声纳、音频和无线通信系统中常见的感知问题，随着集成感知与通信范式的出现，其重要性得到重新关注。&lt;h4&gt;目的&lt;/h4&gt;研究一种联合DoA估计和硬件损伤学习的方法，充分利用感知系统的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于模型的方案，推导出可微分的多信号分类（MUSIC）算法，以便有效学习考虑的损伤。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效学习天线位置和复杂增益的显著不准确性，并在DoA估计任务中优于经典的MUSIC算法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法支持监督和无监督学习策略，展示了其实际应用潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究为改进DoA估计提供了新的思路，考虑了硬件损伤对性能的影响，并展示了实用性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Direction of arrival (DoA) estimation is a common sensing problem in radar,sonar, audio, and wireless communication systems. It has gained renewedimportance with the advent of the integrated sensing and communicationparadigm. To fully exploit the potential of such sensing systems, it is crucialto take into account potential hardware impairments that can negatively impactthe obtained performance. This study introduces a joint DoA estimation andhardware impairment learning scheme following a model-based approach.Specifically, a differentiable version of the multiple signal classification(MUSIC) algorithm is derived, allowing efficient learning of the consideredimpairments. The proposed approach supports both supervised and unsupervisedlearning strategies, showcasing its practical potential. Simulation resultsindicate that the proposed method successfully learns significant inaccuraciesin both antenna locations and complex gains. Additionally, the proposed methodoutperforms the classical MUSIC algorithm in the DoA estimation task.</description>
      <author>example@mail.com (Baptiste Chatelier, José Miguel Mateos-Ramos, Vincent Corlay, Christian Häger, Matthieu Crussière, Henk Wymeersch, Luc Le Magoarou)</author>
      <guid isPermaLink="false">2411.15144v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CLIC: Contrastive Learning Framework for Unsupervised Image Complexity Representation</title>
      <link>http://arxiv.org/abs/2411.12792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图像复杂性作为一种重要的视觉属性，影响人类对图像的理解，并直接影响计算机视觉任务的表现。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法评估和量化图像复杂性，以克服现有方法中面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出CLIC，一个基于对比学习的无监督框架，通过在未标记数据上学习图像复杂性特征，避免高昂的标注成本，并引入独特的正负样本选择策略和复杂性感知损失。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验验证，CLIC能够有效学习图像复杂性表示，并在IC9600上通过微调获得与监督方法竞争的结果。&lt;h4&gt;结论&lt;/h4&gt;CLIC在下游任务中的应用显示出显著的性能提升，证明了其在实际场景中的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;CLIC为图像复杂性评估提供了一种新的无监督学习方法，具有良好的实用性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/xauat-liushipeng/clic&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As an essential visual attribute, image complexity affects human imagecomprehension and directly influences the performance of computer vision tasks.However, accurately assessing and quantifying image complexity facessignificant challenges. Previous works needed more generalization capabilitiesand well-labeled datasets to learn image complexity features. However, creatingsuch datasets requires expensive manual labeling costs, and the modelsinevitably learn about human subjective biases. To address the above problems,we propose CLIC, an unsupervised framework based on contrastive learning, forlearning image complexity representations. The method learns image complexityfeatures on unlabeled data, avoiding the high labeling cost. Specifically, wepropose a unique positive and negative sample selection strategy to reinforcethe differences in complexity features. At the same time, we introduce an imageprior-based Complexity-Aware Loss to constrain the learning process of themodel. We conducted extensive experiments for verification, and the resultsshow that CLIC can effectively learn the image complexity representation. CLICobtained competitive results with supervised methods by fine-tuning on IC9600.In addition, CLIC applied to downstream tasks shows significant performanceimprovements, demonstrating the potential for application in various real-worldscenarios. \href{https://github.com/xauat-liushipeng/CLIC}{code}</description>
      <author>example@mail.com (Shipeng Liu, Liang Zhao, Dengfeng Chen)</author>
      <guid isPermaLink="false">2411.12792v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Predictive Insights into LGBTQ+ Minority Stress: A Transductive Exploration of Social Media Discourse</title>
      <link>http://arxiv.org/abs/2411.13534v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted in 2024 IEEE 11th International Conference on
  Data Science and Advanced Analytics (DSAA)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;性别和性取向少数群体（LGBTQ+）的健康状况普遍较差，主要源于少数群体压力，这种压力源于适应主流文化的独特社会压力。&lt;h4&gt;目的&lt;/h4&gt;设计一个混合模型，用于提高少数群体压力检测的分类性能。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络（GNN）和双向编码器表示的变换器（BERT）模型，对LGBTQ+社交媒体数据集进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;RoBERTa-GCN模型在预测LGBTQ+少数群体压力方面，准确率达到0.86，F1分数为0.86，超越了其他基线模型的表现。&lt;h4&gt;结论&lt;/h4&gt;提高对社交媒体中少数群体压力表达的预测，有助于数字健康干预，从而改善LGBTQ+群体的健康福祉。&lt;h4&gt;总结&lt;/h4&gt;本研究通过先进的自然语言处理技术，揭示了LGBTQ+社群在社交媒体上的压力表达，为改善这一群体的健康提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chapagaisa/transductive&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Individuals who identify as sexual and gender minorities, including lesbian,gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely toexperience poorer health than their heterosexual and cisgender counterparts.One primary source that drives these health disparities is minority stress(i.e., chronic and social stressors unique to LGBTQ+ communities' experiencesadapting to the dominant culture). This stress is frequently expressed inLGBTQ+ users' posts on social media platforms. However, these expressions arenot just straightforward manifestations of minority stress. They involvelinguistic complexity (e.g., idiom or lexical diversity), rendering themchallenging for many traditional natural language processing methods to detect.In this work, we designed a hybrid model using Graph Neural Networks (GNN) andBidirectional Encoder Representations from Transformers (BERT), a pre-traineddeep language model to improve the classification performance of minoritystress detection. We experimented with our model on a benchmark social mediadataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset iscomprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Ourapproach enables the extraction of hidden linguistic nuances throughpretraining on a vast amount of raw data, while also engaging in transductivelearning to jointly develop representations for both labeled training data andunlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and anF1 score of 0.86, surpassing the performance of other baseline models inpredicting LGBTQ+ minority stress. Improved prediction of minority stressexpressions on social media could lead to digital health interventions toimprove the wellbeing of LGBTQ+ people-a community with high rates ofstress-sensitive health problems.</description>
      <author>example@mail.com (S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira)</author>
      <guid isPermaLink="false">2411.13534v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Compression of Higher Order Ambisonics with Multichannel RVQGAN</title>
      <link>http://arxiv.org/abs/2411.12008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种多通道扩展的RVQGAN神经编码方法，用于第三阶Ambisonics音频的数据驱动压缩。&lt;h4&gt;目的&lt;/h4&gt;实现对16通道Ambisonics内容的高质量编码。&lt;h4&gt;方法&lt;/h4&gt;修改生成器和判别器模型的输入和输出层，以接受16个通道，同时保持模型比特率不变，并提出了一种考虑空间感知的损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;通过7.1.4沉浸式播放的听音测试显示，该扩展适用于以16 kbit/s编码场景基础的16通道Ambisonics内容。&lt;h4&gt;结论&lt;/h4&gt;该扩展方法能够在不增加模型比特率的情况下，实现高质量的音频编码。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种有效的多通道神经编码方法，适用于高效的沉浸式音频压缩。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A multichannel extension to the RVQGAN neural coding method is proposed, andrealized for data-driven compression of third-order Ambisonics audio. Theinput- and output layers of the generator and discriminator models are modifiedto accept multiple (16) channels without increasing the model bitrate. We alsopropose a loss function for accounting for spatial perception in immersivereproduction, and transfer learning from single-channel models. Listening testresults with 7.1.4 immersive playback show that the proposed extension issuitable for coding scene-based, 16-channel Ambisonics content with goodquality at 16 kbit/s.</description>
      <author>example@mail.com (Toni Hirvonen, Mahmoud Namazi)</author>
      <guid isPermaLink="false">2411.12008v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced receiver function imaging of crustal structures using symmetric autoencoders</title>
      <link>http://arxiv.org/abs/2411.14182v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 10 figures, submitted to Geophysical Journal International&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;接收函数(RF)是一种地壳成像技术，通过对径向或横向分量与垂直分量地震波形进行反卷积分析。&lt;h4&gt;目的&lt;/h4&gt;分析RF沿回方位和慢度的变化，以确定地壳层的几何形状和各向异性特性。&lt;h4&gt;方法&lt;/h4&gt;采用无监督学习方法，通过网络表示相似射线路径的RF群体，来分离一致的地壳效应与特定的噪声效应。使用对称自编码器(SymAE)进行表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;SymAE有效生成虚拟RF，捕捉一致的地壳效应并减轻噪声效应。该方法在合成RF和实际数据中优于传统的加权堆叠方法。&lt;h4&gt;结论&lt;/h4&gt;在Cascadia俯冲带数据应用中，增强了RF的质量，帮助解释双层俯冲板块。该方法能够利用所有可用的地震事件，提高了RF分析的可重复性和自动化水平。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了一种新的无监督方法，通过网络学习来改善地壳成像技术的精度和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Receiver-function (RF) is a crustal imaging technique that entailsdeconvolving the radial or transverse component with the vertical componentseismogram. Analysis of the variations of RFs along backazimuth and slowness isthe key in determining the geometry and anisotropic properties of the crustallayers. Nonetheless, pseudorandom nuisance effects, influenced by the unknownearthquake source signature and seismic noise, are produced by thedeconvolution process and obstruct precise comparisons of RFs across differentbackazimuths. Various methods such as weighted stacking, sparsity-inducedtransform and supervised denoising neural-network have been developed to reducethe nuisance effects. However, the common assumption of the nuisance effects asrandom Gaussian proves inadequate. Supervised denoising neural-networkstruggles to generalize effectively in intricate tectonic environments likesubduction zones. In this study, we take an unsupervised approach where anetwork-based representation of a group of RFs with similar raypaths, enablesdisentanglement of the coherent crustal effects from the RF-specific nuisanceeffects. The representation learning task is performed using symmetricautoencoders (SymAE). SymAE effectively generates virtual RFs that capturecoherent crustal effects and mitigate nuisance effects. Applied to syntheticRFs with real data-derived nuisances, our method exceeds bin-wise andphase-weighted stacking in quality and accuracy. Using real Cascadia SubductionZone data, it enhances RFs and aids in interpreting a dual-layer subductingslab. We also provided sanity checks to verify the accuracy of thenetwork-derived virtual RFs. One major advantage of our method is its abilityto utilize all available earthquakes, irrespective of their signal quality,thereby enhancing reproducibility and enabling automation in RF analysis.</description>
      <author>example@mail.com (T. Rengneichuong Koireng, Pawan Bharadwaj)</author>
      <guid isPermaLink="false">2411.14182v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Learning Humanoid Locomotion with Perceptive Internal Model</title>
      <link>http://arxiv.org/abs/2411.14386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to ICRA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;与能够在各种地形上导航的四足机器人相比，类人机器人因其高自由度和不稳定的形态，需要准确的感知以实现稳定的运动。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过感知系统提高类人机器人的稳定性和效率。&lt;h4&gt;方法&lt;/h4&gt;采用感知内部模型（PIM），利用机器人周围的实时更新的高程图进行环境感知，并在模拟中基于真实障碍物高度训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够清晰地感知脚下的地形，受相机移动或噪声的影响较小，并且在模拟中不需要深度图渲染，计算成本低。&lt;h4&gt;结论&lt;/h4&gt;该方法经过验证，可在各种类人机器人和不同的室内外地形上有效工作，能够支持类人机器人连续爬楼梯，并为未来类人控制方法的发展奠定基础。&lt;h4&gt;总结&lt;/h4&gt;提出的感知内部模型提升了类人机器人的环境感知能力，为其稳定运动提供了可靠支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In contrast to quadruped robots that can navigate diverse terrains using a"blind" policy, humanoid robots require accurate perception for stablelocomotion due to their high degrees of freedom and inherently unstablemorphology. However, incorporating perceptual signals often introducesadditional disturbances to the system, potentially reducing its robustness,generalizability, and efficiency. This paper presents the Perceptive InternalModel (PIM), which relies on onboard, continuously updated elevation mapscentered around the robot to perceive its surroundings. We train the policyusing ground-truth obstacle heights surrounding the robot in simulation,optimizing it based on the Hybrid Internal Model (HIM), and perform inferencewith heights sampled from the constructed elevation map. Unlike previousmethods that directly encode depth maps or raw point clouds, our approachallows the robot to perceive the terrain beneath its feet clearly and is lessaffected by camera movement or noise. Furthermore, since depth map rendering isnot required in simulation, our method introduces minimal additionalcomputational costs and can train the policy in 3 hours on an RTX 4090 GPU. Weverify the effectiveness of our method across various humanoid robots, variousindoor and outdoor terrains, stairs, and various sensor configurations. Ourmethod can enable a humanoid robot to continuously climb stairs and has thepotential to serve as a foundational algorithm for the development of futurehumanoid control methods.</description>
      <author>example@mail.com (Junfeng Long, Junli Ren, Moji Shi, Zirui Wang, Tao Huang, Ping Luo, Jiangmiao Pang)</author>
      <guid isPermaLink="false">2411.14386v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SplatFlow: Self-Supervised Dynamic Gaussian Splatting in Neural Motion Flow Field for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2411.15482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的动态高斯喷溅方法依赖于昂贵的人工标注，限制了其在现实应用中的可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出一种自监督的动态高斯喷溅方法SplatFlow，以便在不需要跟踪3D边界框的情况下学习4D时空表示。&lt;h4&gt;方法&lt;/h4&gt;SplatFlow设计了一个统一框架，将时间相关的4D高斯表示与神经运动流场(NMFF)无缝集成，NMFF用于建模LiDAR点和高斯的时间运动。&lt;h4&gt;主要发现&lt;/h4&gt;SplatFlow能够有效分解静态背景和动态物体，并用3D和4D高斯原语表示它们，同时增强动态组件的跨视图一致性。&lt;h4&gt;结论&lt;/h4&gt;在Waymo开放数据集和KITTI数据集上的综合评估表明，SplatFlow在动态城市场景中的图像重建和新视图合成方面达到了最先进的性能。&lt;h4&gt;总结&lt;/h4&gt;SplatFlow通过自监督学习，克服了传统方法在动态场景重建中的限制，展示了出色的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most existing Dynamic Gaussian Splatting methods for complex dynamic urbanscenarios rely on accurate object-level supervision from expensive manuallabeling, limiting their scalability in real-world applications. In this paper,we introduce SplatFlow, a Self-Supervised Dynamic Gaussian Splatting withinNeural Motion Flow Fields (NMFF) to learn 4D space-time representations withoutrequiring tracked 3D bounding boxes, enabling accurate dynamic scenereconstruction and novel view RGB, depth and flow synthesis. SplatFlow designsa unified framework to seamlessly integrate time-dependent 4D Gaussianrepresentation within NMFF, where NMFF is a set of implicit functions to modeltemporal motions of both LiDAR points and Gaussians as continuous motion flowfields. Leveraging NMFF, SplatFlow effectively decomposes static background anddynamic objects, representing them with 3D and 4D Gaussian primitives,respectively. NMFF also models the status correspondences of each 4D Gaussianacross time, which aggregates temporal features to enhance cross-viewconsistency of dynamic components. SplatFlow further improves dynamic sceneidentification by distilling features from 2D foundational models into 4Dspace-time representation. Comprehensive evaluations conducted on the WaymoOpen Dataset and KITTI Dataset validate SplatFlow's state-of-the-art (SOTA)performance for both image reconstruction and novel view synthesis in dynamicurban scenarios.</description>
      <author>example@mail.com (Su Sun, Cheng Zhao, Zhuoyang Sun, Yingjie Victor Chen, Mei Chen)</author>
      <guid isPermaLink="false">2411.15482v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Graph neural network framework for energy mapping of hybrid monte-carlo molecular dynamics simulations of Medium Entropy Alloys</title>
      <link>http://arxiv.org/abs/2411.13670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习方法在材料设计和发现中引起了广泛关注，尤其是图神经网络在预测材料性能方面表现出强大潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图的表示方法，用于建模中熵合金（MEAs）。&lt;h4&gt;方法&lt;/h4&gt;采用混合蒙特卡罗分子动力学（MC/MD）模拟，在不同退火温度下实现热稳定结构，生成数据文件和势能标签，构建原子配置的图表示。&lt;h4&gt;主要发现&lt;/h4&gt;图卷积神经网络（GCNN）模型有效捕捉了MEAs结构中的局部环境和化学排序，表现出在不同步骤预测势能的强大性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为MEAs和高熵合金（HEAs）提供了一种图基建模框架，能够有效捕捉合金结构中的局部化学顺序，深入揭示原子级排列如何影响这些合金的性质。&lt;h4&gt;总结&lt;/h4&gt;提出的图基模型为理解和预测中熵合金及高熵合金的材料属性提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning (ML) methods have drawn significant interest in materialdesign and discovery. Graph neural networks (GNNs), in particular, havedemonstrated strong potential for predicting material properties. The presentstudy proposes a graph-based representation for modeling medium-entropy alloys(MEAs). Hybrid Monte-Carlo molecular dynamics (MC/MD) simulations are employedto achieve thermally stable structures across various annealing temperatures inan MEA. These simulations generate dump files and potential energy labels,which are used to construct graph representations of the atomic configurations.Edges are created between each atom and its 12 nearest neighbors withoutincorporating explicit edge features. These graphs then serve as input for aGraph Convolutional Neural Network (GCNN) based ML model to predict thesystem's potential energy. The GCNN architecture effectively captures the localenvironment and chemical ordering within the MEA structure. The GCNN-based MLmodel demonstrates strong performance in predicting potential energy atdifferent steps, showing satisfactory results on both the training data andunseen configurations. Our approach presents a graph-based modeling frameworkfor MEAs and high-entropy alloys (HEAs), which effectively captures the localchemical order (LCO) within the alloy structure. This allows us to predict keymaterial properties influenced by LCO in both MEAs and HEAs, providing deeperinsights into how atomic-scale arrangements affect the properties of thesealloys.</description>
      <author>example@mail.com (Mashaekh Tausif Ehsan, Saifuddin Zafar, Apurba Sarker, Sourav Das Suvro, Mohammad Nasim Hasan)</author>
      <guid isPermaLink="false">2411.13670v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>KAAE: Numerical Reasoning for Knowledge Graphs via Knowledge-aware Attributes Learning</title>
      <link>http://arxiv.org/abs/2411.12950v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was decided to be withdrawn due to failure to resolve
  collaborative disputes within the research team or authorship issues. We are
  actively communicating to reach an agreement and avoid a recurrence of
  similar issues&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数值推理在各种人工智能应用中至关重要，如自然语言处理和推荐系统。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的知识感知属性嵌入模型（KAAE），用于数值推理中的知识图谱嵌入。&lt;h4&gt;方法&lt;/h4&gt;引入混合专家知识感知编码器（MoEKA），整合实体、关系和数值属性的语义，并采用新的序数知识对比学习（OKCL）策略，从原始数据中生成高质量的序数样本。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公共基准数据集上的实验表明，KAAE在各种属性值分布下表现优越。&lt;h4&gt;结论&lt;/h4&gt;KAAE有效克服了语义相关性和语义模糊性的问题，提升了数值推理的准确性和效果。&lt;h4&gt;总结&lt;/h4&gt;新模型通过改进语义整合和样本生成方法，增强了数值推理的能力，为相关领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Numerical reasoning is pivotal in various artificial intelligenceapplications, such as natural language processing and recommender systems,where it involves using entities, relations, and attribute values (e.g.,weight, length) to infer new factual relations (e.g., the Nile is longer thanthe Amazon). However, existing approaches encounter two critical challenges inmodeling: (1) semantic relevance-the challenge of insufficiently capturing thenecessary contextual interactions among entities, relations, and numericalattributes, often resulting in suboptimal inference; and (2) semanticambiguity-the difficulty in accurately distinguishing ordinal relationshipsduring numerical reasoning, which compromises the generation of high-qualitysamples and limits the effectiveness of contrastive learning. To address thesechallenges, we propose the novel Knowledge-Aware Attributes Embedding model(KAAE) for knowledge graph embeddings in numerical reasoning. Specifically, toovercome the challenge of semantic relevance, we introduce aMixture-of-Experts-Knowledge-Aware (MoEKA) Encoder, designed to integrate thesemantics of entities, relations, and numerical attributes into a jointsemantic space. To tackle semantic ambiguity, we implement a new ordinalknowledge contrastive learning (OKCL) strategy that generates high-qualityordinal samples from the original data with the aid of ordinal relations,capturing fine-grained semantic nuances essential for accurate numericalreasoning. Experiments on three public benchmark datasets demonstrate thesuperior performance of KAAE across various attribute value distributions.</description>
      <author>example@mail.com (Ming Yin, Qiang Zhou, Zongsheng Cao, Mei Li)</author>
      <guid isPermaLink="false">2411.12950v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>In-Situ Melt Pool Characterization via Thermal Imaging for Defect Detection in Directed Energy Deposition Using Vision Transformers</title>
      <link>http://arxiv.org/abs/2411.12028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;定向能量沉积（DED）在制造复杂和多材料部件方面具有显著潜力，但内部缺陷如孔隙和裂纹会影响机械性能和整体表现。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过对熔池进行原位监测和特征化，改善缺陷检测和DED打印部件的质量控制。&lt;h4&gt;方法&lt;/h4&gt;采用自监督学习对未标记的熔池数据进行处理，使用基于视觉变换器的掩码自编码器（MAE）产生高度代表性的嵌入，并通过迁移学习在有限的标记数据集上训练分类器。&lt;h4&gt;主要发现&lt;/h4&gt;评估了两种分类器：一种是利用微调后的MAE编码器参数的视觉变换器（ViT）分类器，另一种是将微调后的MAE编码器与多层感知器（MLP）分类头结合的分类器。&lt;h4&gt;结论&lt;/h4&gt;我们的框架实现了95.44%到99.17%的整体准确率，平均F1得分超过80%，ViT分类器略优于MAE编码器分类器，表明该方法在DED中的可扩展性和成本效益，有效检测缺陷且对标记数据需求较少。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种新的方法来进行DED部件的自动质量控制，能够实现高准确度的缺陷检测，且对数据标记的依赖性较低。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Directed Energy Deposition (DED) offers significant potential formanufacturing complex and multi-material parts. However, internal defects suchas porosity and cracks can compromise mechanical properties and overallperformance. This study focuses on in-situ monitoring and characterization ofmelt pools associated with porosity, aiming to improve defect detection andquality control in DED-printed parts. Traditional machine learning approachesfor defect identification rely on extensive labeled datasets, often scarce andexpensive to generate in real-world manufacturing. To address this, ourframework employs self-supervised learning on unlabeled melt pool data using aVision Transformer-based Masked Autoencoder (MAE) to produce highlyrepresentative embeddings. These fine-tuned embeddings are leveraged viatransfer learning to train classifiers on a limited labeled dataset, enablingthe effective identification of melt pool anomalies. We evaluate twoclassifiers: (1) a Vision Transformer (ViT) classifier utilizing the fine-tunedMAE Encoder's parameters and (2) the fine-tuned MAE Encoder combined with anMLP classifier head. Our framework achieves overall accuracy ranging from95.44% to 99.17% and an average F1 score exceeding 80%, with the ViT Classifierslightly outperforming the MAE Encoder Classifier. This demonstrates thescalability and cost-effectiveness of our approach for automated qualitycontrol in DED, effectively detecting defects with minimal labeled data.</description>
      <author>example@mail.com (Israt Zarin Era, Fan Zhou, Ahmed Shoyeb Raihan, Imtiaz Ahmed, Alan Abul-Haj, James Craig, Srinjoy Das, Zhichao Liu)</author>
      <guid isPermaLink="false">2411.12028v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>BiomedCoOp: Learning to Prompt for Biomedical Vision-Language Models</title>
      <link>http://arxiv.org/abs/2411.15232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 5 figures, 10 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，视觉语言模型（VLMs）如CLIP在自监督表示学习方面取得了显著成功，但将其有效适应于下游应用仍然具有挑战性，尤其是在生物医学图像领域。&lt;h4&gt;目的&lt;/h4&gt;提出BiomedCoOp，一个新的提示学习框架，以高效适应BiomedCLIP，实现准确且高度可推广的少样本生物医学图像分类。&lt;h4&gt;方法&lt;/h4&gt;通过利用大型语言模型（LLMs）的平均提示集进行语义一致性学习，以及采用基于统计的提示选择策略进行知识蒸馏，实现有效的提示上下文学习。&lt;h4&gt;主要发现&lt;/h4&gt;在11个医疗数据集和9种模态、10个器官上进行了全面验证，结果显示在准确性和可推广性方面显著优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;BiomedCoOp框架在生物医学图像分析中展现出更好的性能，代码将公开发布于https://github.com/HealthX-Lab/BiomedCoOp。&lt;h4&gt;总结&lt;/h4&gt;本研究为生物医学图像分类提供了一种新的有效方法，克服了传统VLM在该领域应用的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in vision-language models (VLMs), such as CLIP, havedemonstrated substantial success in self-supervised representation learning forvision tasks. However, effectively adapting VLMs to downstream applicationsremains challenging, as their accuracy often depends on time-intensive andexpertise-demanding prompt engineering, while full model fine-tuning is costly.This is particularly true for biomedical images, which, unlike natural images,typically suffer from limited annotated datasets, unintuitive image contrasts,and nuanced visual features. Recent prompt learning techniques, such as ContextOptimization (CoOp) intend to tackle these issues, but still fall short ingeneralizability. Meanwhile, explorations in prompt learning for biomedicalimage analysis are still highly limited. In this work, we propose BiomedCoOp, anovel prompt learning framework that enables efficient adaptation of BiomedCLIPfor accurate and highly generalizable few-shot biomedical image classification.Our approach achieves effective prompt context learning by leveraging semanticconsistency with average prompt ensembles from Large Language Models (LLMs) andknowledge distillation with a statistics-based prompt selection strategy. Weconducted comprehensive validation of our proposed framework on 11 medicaldatasets across 9 modalities and 10 organs against existing state-of-the-artmethods, demonstrating significant improvements in both accuracy andgeneralizability. The code will be publicly available athttps://github.com/HealthX-Lab/BiomedCoOp.</description>
      <author>example@mail.com (Taha Koleilat, Hojat Asgariandehkordi, Hassan Rivaz, Yiming Xiao)</author>
      <guid isPermaLink="false">2411.15232v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>23 DoF Grasping Policies from a Raw Point Cloud</title>
      <link>http://arxiv.org/abs/2411.14400v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE International Conference on Robotics and Automation (ICRA)
  Workshop on Geometric Representations 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;协调高自由度（DoF）机器人运动以抓取物体面临许多挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的模仿学习方法，直接从单个固定相机提供的部分点云预测23个DoF抓取轨迹。&lt;h4&gt;方法&lt;/h4&gt;核心方法是基于几何的二阶行为动力学模型，使用神经几何结构（NGF）策略直接预测关节空间的加速度。&lt;h4&gt;主要发现&lt;/h4&gt;该策略能够推广到新物体，并与几何结构运动规划器结合生成稳定的抓取轨迹。&lt;h4&gt;结论&lt;/h4&gt;在三种不同物体上评估了该方法，比较了不同策略结构，进行了消融研究以理解不同物体编码对策略学习的重要性。&lt;h4&gt;总结&lt;/h4&gt;该研究为高自由度机器人抓取任务提供了一种有效的学习策略，有助于提升抓取的稳定性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Coordinating the motion of robots with high degrees of freedom (DoF) to graspobjects gives rise to many challenges. In this paper, we propose a novelimitation learning approach to learn a policy that directly predicts 23 DoFgrasp trajectories from a partial point cloud provided by a single, fixedcamera. At the core of the approach is a second-order geometric-based model ofbehavioral dynamics. This Neural Geometric Fabric (NGF) policy predictsaccelerations directly in joint space. We show that our policy is capable ofgeneralizing to novel objects, and combine our policy with a geometric fabricmotion planner in a loop to generate stable grasping trajectories. We evaluateour approach on a set of three different objects, compare different policystructures, and run ablation studies to understand the importance of differentobject encodings for policy learning.</description>
      <author>example@mail.com (Martin Matak, Karl Van Wyk, Tucker Hermans)</author>
      <guid isPermaLink="false">2411.14400v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Fine-Grained Open-Vocabulary Object Recognition via User-Guided Segmentation</title>
      <link>http://arxiv.org/abs/2411.15620v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，基于视觉的基础模型使得高效和高质量的物体检测变得更加容易。&lt;h4&gt;目的&lt;/h4&gt;解决物体检测模型在捕捉整体对象的小组成部分和考虑用户意图方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的检测方法FOCUS，通过用户引导的分割实现细粒度开放词汇物体识别。&lt;h4&gt;主要发现&lt;/h4&gt;FOCUS能够自动化开放词汇物体检测，用户可以通过自然语言直接引导检测过程，识别和定位细粒度的组成元素。&lt;h4&gt;结论&lt;/h4&gt;FOCUS不仅减少了不必要的用户干预，还赋予用户显著的控制权，显著提升了基线模型的检测能力，并在不同物体类型上表现一致。&lt;h4&gt;总结&lt;/h4&gt;FOCUS是一种创新的方法，结合了视觉基础模型的能力，增强了物体检测的灵活性和用户交互性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advent of vision-based foundation models has enabled efficient andhigh-quality object detection at ease. Despite the success of previous studies,object detection models face limitations on capturing small components fromholistic objects and taking user intention into account. To address thesechallenges, we propose a novel foundation model-based detection method calledFOCUS: Fine-grained Open-Vocabulary Object ReCognition via User-GuidedSegmentation. FOCUS merges the capabilities of vision foundation models toautomate open-vocabulary object detection at flexible granularity and allowusers to directly guide the detection process via natural language. It not onlyexcels at identifying and locating granular constituent elements but alsominimizes unnecessary user intervention yet grants them significant control.With FOCUS, users can make explainable requests to actively guide the detectionprocess in the intended direction. Our results show that FOCUS effectivelyenhances the detection capabilities of baseline models and shows consistentperformance across varying object types.</description>
      <author>example@mail.com (Jinwoo Ahn, Hyeokjoon Kwon, Hwiyeon Yoo)</author>
      <guid isPermaLink="false">2411.15620v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Investigating Graph Neural Networks and Classical Feature-Extraction Techniques in Activity-Cliff and Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2411.13688v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Doctoral Thesis (Mathematical Institute, University of Oxford)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;分子特征化是将分子数据转化为数值特征向量的重要研究领域，尤其在分子机器学习和计算药物发现中具有关键意义。&lt;h4&gt;目的&lt;/h4&gt;探讨消息传递图神经网络（GNNs）在分子特征化中的应用，并比较其与传统方法（如扩展连接指纹（ECFPs）和物理化学描述符向量（PDVs））的优劣。&lt;h4&gt;方法&lt;/h4&gt;系统研究和开发传统与基于图的分子特征化方法，重点关注定量结构-活性关系（QSAR）预测和活动悬崖（AC）预测。&lt;h4&gt;主要发现&lt;/h4&gt;对PDVs、ECFPs和图同构网络（GINs）的性能进行比较，发现Sort &amp; Slice作为一种简单的子结构池化技术在分子性质预测中优于基于哈希的折叠方法。&lt;h4&gt;结论&lt;/h4&gt;提出了两项未来研究的想法，包括构建可训练的经典分子特征化的图自监督学习策略，以及通过可微分自注意力进行可训练的子结构池化。&lt;h4&gt;总结&lt;/h4&gt;本研究系统地评估了不同分子特征化方法的有效性，并为未来研究提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5287/ora-xkardwd6z&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular featurisation refers to the transformation of molecular data intonumerical feature vectors. It is one of the key research areas in molecularmachine learning and computational drug discovery. Recently, message-passinggraph neural networks (GNNs) have emerged as a novel method to learndifferentiable features directly from molecular graphs. While such techniqueshold great promise, further investigations are needed to clarify if and whenthey indeed manage to definitively outcompete classical molecularfeaturisations such as extended-connectivity fingerprints (ECFPs) andphysicochemical-descriptor vectors (PDVs). We systematically explore andfurther develop classical and graph-based molecular featurisation methods fortwo important tasks: molecular property prediction, in particular, quantitativestructure-activity relationship (QSAR) prediction, and the largely unexploredchallenge of activity-cliff (AC) prediction. We first give a technicaldescription and critical analysis of PDVs, ECFPs and message-passing GNNs, witha focus on graph isomorphism networks (GINs). We then conduct a rigorouscomputational study to compare the performance of PDVs, ECFPs and GINs for QSARand AC-prediction. Following this, we mathematically describe andcomputationally evaluate a novel twin neural network model for AC-prediction.We further introduce an operation called substructure pooling for thevectorisation of structural fingerprints as a natural counterpart to graphpooling in GNN architectures. We go on to propose Sort &amp; Slice, a simplesubstructure-pooling technique for ECFPs that robustly outperforms hash-basedfolding at molecular property prediction. Finally, we outline two ideas forfuture research: (i) a graph-based self-supervised learning strategy to makeclassical molecular featurisations trainable, and (ii) trainablesubstructure-pooling via differentiable self-attention.</description>
      <author>example@mail.com (Markus Dablander)</author>
      <guid isPermaLink="false">2411.13688v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Instruction-Guided Editing Controls for Images and Multimedia: A Survey in LLM era</title>
      <link>http://arxiv.org/abs/2411.09955v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Fixed a serious error in author information&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）和多模态学习的快速发展改变了数字内容的创建和处理方式。传统的视觉编辑工具需要较高的专业知识，这限制了其可及性。&lt;h4&gt;目的&lt;/h4&gt;综述基于指令的编辑技术，探讨如何使用户能够在无需深厚技术知识的情况下，利用自然语言实现精准的视觉修改。&lt;h4&gt;方法&lt;/h4&gt;综合分析超过100篇相关文献，研究从生成对抗网络到扩散模型的方法，探讨多模态集成以实现细粒度内容控制。&lt;h4&gt;主要发现&lt;/h4&gt;展示了在时尚、3D场景操作和视频合成等领域的实际应用，强调了编辑的可及性和与人类直觉的对齐。&lt;h4&gt;结论&lt;/h4&gt;比较现有文献，强调LLM驱动的编辑，识别出关键挑战以激发进一步研究，旨在实现各行业（如娱乐和教育）的强大视觉编辑的民主化。&lt;h4&gt;总结&lt;/h4&gt;鼓励感兴趣的读者访问我们的资源库以获取更多信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tamlhp/awesome-instruction-editing&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of large language models (LLMs) and multimodal learninghas transformed digital content creation and manipulation. Traditional visualediting tools require significant expertise, limiting accessibility. Recentstrides in instruction-based editing have enabled intuitive interaction withvisual content, using natural language as a bridge between user intent andcomplex editing operations. This survey provides an overview of thesetechniques, focusing on how LLMs and multimodal models empower users to achieveprecise visual modifications without deep technical knowledge. By synthesizingover 100 publications, we explore methods from generative adversarial networksto diffusion models, examining multimodal integration for fine-grained contentcontrol. We discuss practical applications across domains such as fashion, 3Dscene manipulation, and video synthesis, highlighting increased accessibilityand alignment with human intuition. Our survey compares existing literature,emphasizing LLM-empowered editing, and identifies key challenges to stimulatefurther research. We aim to democratize powerful visual editing across variousindustries, from entertainment to education. Interested readers are encouragedto access our repository athttps://github.com/tamlhp/awesome-instruction-editing.</description>
      <author>example@mail.com (Thanh Tam Nguyen, Zhao Ren, Trinh Pham, Thanh Trung Huynh, Phi Le Nguyen, Hongzhi Yin, Quoc Viet Hung Nguyen)</author>
      <guid isPermaLink="false">2411.09955v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Collaborative Feature-Logits Contrastive Learning for Open-Set Semi-Supervised Object Detection</title>
      <link>http://arxiv.org/abs/2411.13001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的半监督目标检测（SSOD）方法通过利用大量未标记数据来提高检测器性能，假设标记数据和未标记数据共享相同的标签空间。&lt;h4&gt;目的&lt;/h4&gt;在开放集场景中，解决未标记数据中包含的ID类和OOD类导致的错误分类问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种简单有效的方法，称为协同特征-逻辑检测器（CFL-Detector），通过对比损失引入特征级聚类方法，优化逻辑级不确定性分类损失，以增强区分ID类和OOD类的能力。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验表明，CFL-Detector在性能上优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;CFL-Detector能够有效地处理开放集场景中的目标检测问题，提升检测准确性。&lt;h4&gt;总结&lt;/h4&gt;提出的CFL-Detector方法通过特征聚类和优化分类损失，显著改善了ID和OOD类的区分能力，达到了先进的检测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current Semi-Supervised Object Detection (SSOD) methods enhance detectorperformance by leveraging large amounts of unlabeled data, assuming that bothlabeled and unlabeled data share the same label space. However, in open-setscenarios, the unlabeled dataset contains both in-distribution (ID) classes andout-of-distribution (OOD) classes. Applying semi-supervised detectors in suchsettings can lead to misclassifying OOD class as ID classes. To alleviate thisissue, we propose a simple yet effective method, termed CollaborativeFeature-Logits Detector (CFL-Detector). Specifically, we introduce afeature-level clustering method using contrastive loss to clarify vectorboundaries in the feature space and highlight class differences. Additionally,by optimizing the logits-level uncertainty classification loss, the modelenhances its ability to effectively distinguish between ID and OOD classes.Extensive experiments demonstrate that our method achieves state-of-the-artperformance compared to existing methods.</description>
      <author>example@mail.com (Xinhao Zhong, Siyu Jiao, Yao Zhao, Yunchao Wei)</author>
      <guid isPermaLink="false">2411.13001v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Adversarial Multi-Agent Reinforcement Learning for Proactive False Data Injection Detection</title>
      <link>http://arxiv.org/abs/2411.12130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能逆变器在可再生能源和分布式能源资源的电网集成中起着重要作用，但它们可能受到网络物理攻击，例如虚假数据注入攻击（FDIA）。&lt;h4&gt;目的&lt;/h4&gt;构建一个针对未知FDIA的防御策略。&lt;h4&gt;方法&lt;/h4&gt;采用多智能体强化学习（MARL）框架，其中一个智能体模拟并发现FDIA策略，另一个智能体负责检测和定位FDIA。&lt;h4&gt;主要发现&lt;/h4&gt;提议的MARL防御者在性能上优于监督离线防御者，并且可以通过迁移学习将MARL防御者的检测能力与离线防御者的能力结合。&lt;h4&gt;结论&lt;/h4&gt;MARL方法能够持续训练防御者以应对新的FDIA，从而提升整体安全性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了使用多智能体强化学习来增强智能逆变器的安全性，提供了有效的防御策略以抵御网络攻击。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smart inverters are instrumental in the integration of renewable anddistributed energy resources (DERs) into the electric grid. Such inverters relyon communication layers for continuous control and monitoring, potentiallyexposing them to cyber-physical attacks such as false data injection attacks(FDIAs). We propose to construct a defense strategy against a priori unknownFDIAs with a multi-agent reinforcement learning (MARL) framework. The firstagent is an adversary that simulates and discovers various FDIA strategies,while the second agent is a defender in charge of detecting and localizingFDIAs. This approach enables the defender to be trained against new FDIAscontinuously generated by the adversary. The numerical results demonstrate thatthe proposed MARL defender outperforms a supervised offline defender.Additionally, we show that the detection skills of an MARL defender can becombined with that of an offline defender through a transfer learning approach.</description>
      <author>example@mail.com (Kejun Chen, Truc Nguyen, Malik Hassanaly)</author>
      <guid isPermaLink="false">2411.12130v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CodeSAM: Source Code Representation Learning by Infusing Self-Attention with Multi-Code-View Graphs</title>
      <link>http://arxiv.org/abs/2411.14611v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习在软件工程中逐渐受到关注，能够显著提升各种软件工程应用的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的框架CodeSAM，以有效地将多种代码视图融入现有的基于变换器的模型。&lt;h4&gt;方法&lt;/h4&gt;通过创建自注意力掩码，将结构化代码视图（如抽象语法树、数据流图和控制流图）与基于变换器的模型结合，进而微调小型语言模型（如CodeBERT）。&lt;h4&gt;主要发现&lt;/h4&gt;使用CodeSAM技术时，在语义代码搜索、代码克隆检测和程序分类等下游任务中，相较于GraphCodeBERT和CodeBERT，性能得到提升。&lt;h4&gt;结论&lt;/h4&gt;CodeSAM技术能够创建紧凑且高效的代码小型语言模型，适用于资源有限的环境。&lt;h4&gt;总结&lt;/h4&gt;CodeSAM为软件工程中的机器学习提供了新的思路，通过灵活结合多种代码视图，提升模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine Learning (ML) for software engineering (SE) has gained prominence dueto its ability to significantly enhance the performance of various SEapplications. This progress is largely attributed to the development ofgeneralizable source code representations that effectively capture thesyntactic and semantic characteristics of code. In recent years, pre-trainedtransformer-based models, inspired by natural language processing (NLP), haveshown remarkable success in SE tasks. However, source code contains structuraland semantic properties embedded within its grammar, which can be extractedfrom structured code-views like the Abstract Syntax Tree (AST), Data-Flow Graph(DFG), and Control-Flow Graph (CFG). These code-views can complement NLPtechniques, further improving SE tasks. Unfortunately, there are no flexibleframeworks to infuse arbitrary code-views into existing transformer-basedmodels effectively. Therefore, in this work, we propose CodeSAM, a novelscalable framework to infuse multiple code-views into transformer-based modelsby creating self-attention masks. We use CodeSAM to fine-tune a small languagemodel (SLM) like CodeBERT on the downstream SE tasks of semantic code search,code clone detection, and program classification. Experimental results showthat by using this technique, we improve downstream performance when comparedto SLMs like GraphCodeBERT and CodeBERT on all three tasks by utilizingindividual code-views or a combination of code-views during fine-tuning. Webelieve that these results are indicative that techniques like CodeSAM can helpcreate compact yet performant code SLMs that fit in resource constrainedsettings.</description>
      <author>example@mail.com (Alex Mathai, Kranthi Sedamaki, Debeshee Das, Noble Saji Mathews, Srikanth Tamilselvam, Sridhar Chimalakonda, Atul Kumar)</author>
      <guid isPermaLink="false">2411.14611v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Effort: Efficient Orthogonal Modeling for Generalizable AI-Generated Image Detection</title>
      <link>http://arxiv.org/abs/2411.15633v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的AI生成图像（AIGI）检测方法通常存在泛化性能不足的问题。&lt;h4&gt;目的&lt;/h4&gt;识别AIGI检测中的一个重要但被忽视的非对称现象，以改善检测模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;结合大规模视觉基础模型（VFM）中的丰富语义知识，扩展基于伪造模式的判别空间，同时设计Effort方法，通过奇异值分解（SVD）构建正交语义和伪造子空间。&lt;h4&gt;主要发现&lt;/h4&gt;模型在训练过程中容易过拟合特定的伪造模式，导致在面对新伪造方法时表现不佳。&lt;h4&gt;结论&lt;/h4&gt;通过冻结主成分并调整残差成分，Effort方法有效保留了原有语义子空间，并利用正交子空间进行伪造学习，实验结果显示该方法在AIGI检测基准上具有显著效果。&lt;h4&gt;总结&lt;/h4&gt;Effort方法通过正交建模策略解决了AIGI检测中的过拟合问题，提升了模型的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing AI-generated image (AIGI) detection methods often suffer fromlimited generalization performance. In this paper, we identify a crucial yetpreviously overlooked asymmetry phenomenon in AIGI detection: during training,models tend to quickly overfit to specific fake patterns in the training set,while other information is not adequately captured, leading to poorgeneralization when faced with new fake methods. A key insight is toincorporate the rich semantic knowledge embedded within large-scale visionfoundation models (VFMs) to expand the previous discriminative space (based onforgery patterns only), such that the discrimination is decided by both forgeryand semantic cues, thereby reducing the overfitting to specific forgerypatterns. A straightforward solution is to fully fine-tune VFMs, but it risksdistorting the well-learned semantic knowledge, pushing the model back towardoverfitting. To this end, we design a novel approach called Effort: Efficientorthogonal modeling for generalizable AIGI detection. Specifically, we employSingular Value Decomposition (SVD) to construct the orthogonal semantic andforgery subspaces. By freezing the principal components and adapting theresidual components ($\sim$0.19M parameters), we preserve the original semanticsubspace and use its orthogonal subspace for learning forgeries. Extensiveexperiments on AIGI detection benchmarks demonstrate the superior effectivenessof our approach.</description>
      <author>example@mail.com (Zhiyuan Yan, Jiangming Wang, Zhendong Wang, Peng Jin, Ke-Yue Zhang, Shen Chen, Taiping Yao, Shouhong Ding, Baoyuan Wu, Li Yuan)</author>
      <guid isPermaLink="false">2411.15633v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Spatio-Temporal Signal Recognition on Edge Devices Using PointLCA-Net</title>
      <link>http://arxiv.org/abs/2411.14585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2411.00140&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，机器学习的进展，特别是深度学习架构如PointNet，改变了三维点云的处理，提高了3D物体分类和分割任务的效果。&lt;h4&gt;目的&lt;/h4&gt;研究如何将深度学习技术应用于时空信号的处理，并解决在边缘设备上部署时面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出一种新方法，结合PointNet的特征提取与类脑计算系统的能效，以实现时空信号识别。该方法包括两个阶段：第一阶段，PointNet提取时空信号的特征并存储在非易失性忆阻器交叉阵列中；第二阶段，利用单层脉冲神经编码器-解码器，通过局部竞争算法进行高效编码和分类。&lt;h4&gt;主要发现&lt;/h4&gt;PointLCA-Net在时空数据的识别精度上表现优异，同时在推理和训练过程中的能耗显著低于其他类似方法。&lt;h4&gt;结论&lt;/h4&gt;该研究推进了先进神经架构在受限能量环境中的部署，提升了计算效率和能耗表现。&lt;h4&gt;总结&lt;/h4&gt;结合PointNet与局部竞争算法的优势，PointLCA-Net为时空信号的识别提供了高效能的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in machine learning, particularly through deep learningarchitectures like PointNet, have transformed the processing ofthree-dimensional (3D) point clouds, significantly improving 3D objectclassification and segmentation tasks. While 3D point clouds provide detailedspatial information, spatio-temporal signals introduce a dynamic element thataccounts for changes over time. However, applying deep learning techniques tospatio-temporal signals and deploying them on edge devices presents challenges,including real-time processing, memory capacity, and power consumption. Toaddress these issues, this paper presents a novel approach that combinesPointNet's feature extraction with the in-memory computing capabilities andenergy efficiency of neuromorphic systems for spatio-temporal signalrecognition. The proposed method consists of a two-stage process: in the firststage, PointNet extracts features from the spatio-temporal signals, which arethen stored in non-volatile memristor crossbar arrays. In the second stage,these features are processed by a single-layer spiking neural encoder-decoderthat employs the Locally Competitive Algorithm (LCA) for efficient encoding andclassification. This work integrates the strengths of both PointNet and LCA,enhancing computational efficiency and energy performance on edge devices.PointLCA-Net achieves high recognition accuracy for spatio-temporal data withsubstantially lower energy burden during both inference and training thancomparable approaches, thus advancing the deployment of advanced neuralarchitectures in energy-constrained environments.</description>
      <author>example@mail.com (Sanaz Mahmoodi Takaghaj, Jack Sampson)</author>
      <guid isPermaLink="false">2411.14585v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Deep Metric Learning on Attributed Graphs</title>
      <link>http://arxiv.org/abs/2411.13014v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is the complete version of a published paper with appendix
  including detailed proofs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究如何构建大规模带属性图的嵌入，并支持多个下游学习任务。&lt;h4&gt;目的&lt;/h4&gt;开发一种图嵌入方法，以提高对带属性图的处理能力和学习任务的支持。&lt;h4&gt;方法&lt;/h4&gt;基于深度度量和无偏对比学习技术，提出了一种支持微批处理的图嵌入方法，并实现了可扩展性。提出了基于多类元组损失函数的两种算法：DMT（半监督学习）和DMAT-i（无监督学习）。&lt;h4&gt;主要发现&lt;/h4&gt;提供了下游节点分类任务的一般化界限，并首次将元组损失与对比学习相关联。实验结果显示，表示构建具有高可扩展性，并在节点聚类、节点分类和链接预测三个下游任务中表现出比现有单一方法更好的一致性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在多个下游学习任务中表现优越，证明了其在大规模带属性图嵌入中的有效性。&lt;h4&gt;总结&lt;/h4&gt;通过扩展现有学习技术，实现了对大规模带属性图的有效嵌入，为后续的学习任务提供了支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-981-97-0669-3_35&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of constructing embeddings of large attributed graphsand supporting multiple downstream learning tasks. We develop a graph embeddingmethod, which is based on extending deep metric and unbiased contrastivelearning techniques to 1) work with attributed graphs, 2) enabling a mini-batchbased approach, and 3) achieving scalability. Based on a multi-class tupletloss function, we present two algorithms -- DMT for semi-supervised learningand DMAT-i for the unsupervised case. Analyzing our methods, we provide ageneralization bound for the downstream node classification task and for thefirst time relate tuplet loss to contrastive learning. Through extensiveexperiments, we show high scalability of representation construction, and inapplying the method for three downstream tasks (node clustering, nodeclassification, and link prediction) better consistency over any singleexisting method.</description>
      <author>example@mail.com (Xiang Li, Gagan Agrawal, Ruoming Jin, Rajiv Ramnath)</author>
      <guid isPermaLink="false">2411.13014v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>VMID: A Multimodal Fusion LLM Framework for Detecting and Identifying Misinformation of Short Videos</title>
      <link>http://arxiv.org/abs/2411.10032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2211.10973 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;短视频平台已成为新闻传播的重要渠道，但也促进了虚假信息的快速传播。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于多模态信息的新型虚假新闻检测方法，以识别短视频中的虚假信息。&lt;h4&gt;方法&lt;/h4&gt;通过对视频内容进行多层次分析，结合不同模态的信息生成统一的文本描述，并利用大型语言模型进行综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在准确性、鲁棒性和多模态信息利用方面优于现有模型，准确率达到90.93%。&lt;h4&gt;结论&lt;/h4&gt;该框架有效整合视频中的多模态特征，在真实世界应用中表现出可靠性和稳健性。&lt;h4&gt;总结&lt;/h4&gt;实验结果和案例研究表明，该方法能有效区分虚假新闻、辟谣内容和真实事件，提升虚假新闻检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Short video platforms have become important channels for news dissemination,offering a highly engaging and immediate way for users to access current eventsand share information. However, these platforms have also emerged assignificant conduits for the rapid spread of misinformation, as fake news andrumors can leverage the visual appeal and wide reach of short videos tocirculate extensively among audiences. Existing fake news detection methodsmainly rely on single-modal information, such as text or images, or apply onlybasic fusion techniques, limiting their ability to handle the complex,multi-layered information inherent in short videos. To address theselimitations, this paper presents a novel fake news detection method based onmultimodal information, designed to identify misinformation through amulti-level analysis of video content. This approach effectively utilizesdifferent modal representations to generate a unified textual description,which is then fed into a large language model for comprehensive evaluation. Theproposed framework successfully integrates multimodal features within videos,significantly enhancing the accuracy and reliability of fake news detection.Experimental results demonstrate that the proposed approach outperformsexisting models in terms of accuracy, robustness, and utilization of multimodalinformation, achieving an accuracy of 90.93%, which is significantly higherthan the best baseline model (SV-FEND) at 81.05%. Furthermore, case studiesprovide additional evidence of the effectiveness of the approach in accuratelydistinguishing between fake news, debunking content, and real incidents,highlighting its reliability and robustness in real-world applications.</description>
      <author>example@mail.com (Weihao Zhong, Yinhao Xiao, Minghui Xu, Xiuzhen Cheng)</author>
      <guid isPermaLink="false">2411.10032v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>On Representing Convex Quadratically Constrained Quadratic Programs via Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.13805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;凸二次约束二次规划（QCQP）涉及在由二次约束定义的凸可行区域内寻找解，同时最小化凸二次目标函数。这些问题在电力系统和信号处理等多个工业应用中出现。&lt;h4&gt;目的&lt;/h4&gt;研究图神经网络（GNN）在凸QCQP任务中的表示能力。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的三部图表示方法，适用于一般的凸QCQP，并将其与消息传递GNNs关联。&lt;h4&gt;主要发现&lt;/h4&gt;存在能够可靠表示凸QCQP关键属性的GNN，包括可行性、最优值和最优解。&lt;h4&gt;结论&lt;/h4&gt;研究加深了QCQP与GNN之间的联系，为未来利用机器学习有效解决QCQP问题铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;本研究首次探讨了GNN在凸QCQP中的应用，展示了其在优化问题中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Convex quadratically constrained quadratic programs (QCQPs) involve finding asolution within a convex feasible region defined by quadratic constraints whileminimizing a convex quadratic objective function. These problems arise invarious industrial applications, including power systems and signal processing.Traditional methods for solving convex QCQPs primarily rely on matrixfactorization, which quickly becomes computationally prohibitive as the problemsize increases. Recently, graph neural networks (GNNs) have gained attentionfor their potential in representing and solving various optimization problemssuch as linear programs and linearly constrained quadratic programs. In thiswork, we are the first to investigate the representation power of GNNs in thecontext of QCQP tasks. Specifically, we propose a new tripartite graphrepresentation for general convex QCQPs and properly associate it withmessage-passing GNNs. We demonstrate that there exist GNNs capable of reliablyrepresenting key properties of convex QCQPs, including feasibility, optimalvalue, and optimal solution. Our result deepens the understanding of theconnection between QCQPs and GNNs, paving the way for future machine learningapproaches to efficiently solve QCQPs.</description>
      <author>example@mail.com (Chenyang Wu, Qian Chen, Akang Wang, Tian Ding, Ruoyu Sun, Wenguo Yang, Qingjiang Shi)</author>
      <guid isPermaLink="false">2411.13805v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Classification of Geographical Land Structure Using Convolution Neural Network and Transfer Learning</title>
      <link>http://arxiv.org/abs/2411.12415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;卫星图像在地理学领域带来了革命性变化，为学者、科学家和决策者提供了前所未有的全球空间数据访问。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过减少人力劳动来降低识别土地结构所需的费用和时间。&lt;h4&gt;方法&lt;/h4&gt;研究开发了一种基于深度学习的方法，自动化地分类地理土地结构，使用来自MLRSNet的卫星图像数据集，并比较三种架构：CNN、ResNet-50和Inception-v3。&lt;h4&gt;主要发现&lt;/h4&gt;ResNet-50在ADAM优化器下的准确率为76.5%，Inception-v3在RMSProp下的准确率为93.8%，而CNN与RMSProp优化器结合下取得了最高的94.8%准确率。&lt;h4&gt;结论&lt;/h4&gt;CNN模型在各类别的准确率、召回率和F1分数方面表现出色，显示出其在精确检测各种地形结构中的可靠性和有效性，强调了深度学习模型在场景理解和从卫星图像中有效识别和分类土地结构的重要性。&lt;h4&gt;总结&lt;/h4&gt;深度学习模型在土地结构识别中的潜力巨大，能够显著提高效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3844/jcssp.2024.1580.1592&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Satellite imagery has dramatically revolutionized the field of geography bygiving academics, scientists, and policymakers unprecedented global access tospatial data. Manual methods typically require significant time and effort todetect the generic land structure in satellite images. This study can produce aset of applications such as urban planning and development, environmentalmonitoring, disaster management, etc. Therefore, the research presents amethodology to minimize human labor, reducing the expenses and duration neededto identify the land structure. This article developed a deep learning-basedapproach to automate the process of classifying geographical land structures.We used a satellite image dataset acquired from MLRSNet. The study compared theperformance of three architectures, namely CNN, ResNet-50, and Inception-v3. Weused three optimizers with any model: Adam, SGD, and RMSProp. We conduct thetraining process for a fixed number of epochs, specifically 100 epochs, with abatch size of 64. The ResNet-50 achieved an accuracy of 76.5% with the ADAMoptimizer, the Inception-v3 with RMSProp achieved an accuracy of 93.8%, and theproposed approach, CNN with RMSProp optimizer, achieved the highest level ofperformance and an accuracy of 94.8%. Moreover, a thorough examination of theCNN model demonstrated its exceptional accuracy, recall, and F1 scores for allcategories, confirming its resilience and dependability in precisely detectingvarious terrain formations. The results highlight the potential of deeplearning models in scene understanding, as well as their significance inefficiently identifying and categorizing land structures from satelliteimagery.</description>
      <author>example@mail.com (Mustafa M. Abd Zaid, Ahmed Abed Mohammed, Putra Sumari)</author>
      <guid isPermaLink="false">2411.12415v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>ROOT: VLM based System for Indoor Scene Understanding and Beyond</title>
      <link>http://arxiv.org/abs/2411.15714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉语言模型（VLMs）在室内场景的空间层次推理方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;引入ROOT，一个基于VLM的系统，以增强室内场景分析。&lt;h4&gt;方法&lt;/h4&gt;开发了一个迭代对象感知算法，使用GPT-4V检测室内场景中的对象实体；使用视觉基础模型获取场景的额外元信息，如边界框。提出专门的VLM，SceneVLM，生成空间层次场景图并提供对象间的距离信息。&lt;h4&gt;主要发现&lt;/h4&gt;SceneVLM通过分析室内场景的空间排列，提升了对室内场景的理解。&lt;h4&gt;结论&lt;/h4&gt;ROOT系统在多种下游应用中有效，如3D场景生成和具身AI，证明了其在室内场景理解中的有效性。&lt;h4&gt;数据收集&lt;/h4&gt;从多个公共室内数据集中收集了超过610,000张图像，并实施了半自动化的场景数据生成管道，以建立室内对象之间的关系和估计距离。&lt;h4&gt;总结&lt;/h4&gt;研究表明，ROOT系统能够有效促进室内场景理解，相关代码将在GitHub上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/harrytea/root&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Vision Language Models (VLMs) have experienced significantadvancements, yet these models still face challenges in spatial hierarchicalreasoning within indoor scenes. In this study, we introduce ROOT, a VLM-basedsystem designed to enhance the analysis of indoor scenes. Specifically, wefirst develop an iterative object perception algorithm using GPT-4V to detectobject entities within indoor scenes. This is followed by employing visionfoundation models to acquire additional meta-information about the scene, suchas bounding boxes. Building on this foundational data, we propose a specializedVLM, SceneVLM, which is capable of generating spatial hierarchical scene graphsand providing distance information for objects within indoor environments. Thisinformation enhances our understanding of the spatial arrangement of indoorscenes. To train our SceneVLM, we collect over 610,000 images from variouspublic indoor datasets and implement a scene data generation pipeline with asemi-automated technique to establish relationships and estimate distancesamong indoor objects. By utilizing this enriched data, we conduct varioustraining recipes and finish SceneVLM. Our experiments demonstrate that\rootname facilitates indoor scene understanding and proves effective indiverse downstream applications, such as 3D scene generation and embodied AI.The code will be released at \url{https://github.com/harrytea/ROOT}.</description>
      <author>example@mail.com (Yonghui Wang, Shi-Yong Chen, Zhenxing Zhou, Siyi Li, Haoran Li, Wengang Zhou, Houqiang Li)</author>
      <guid isPermaLink="false">2411.15714v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>mmWave Radar for Sit-to-Stand Analysis: A Comparative Study with Wearables and Kinect</title>
      <link>http://arxiv.org/abs/2411.14656v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究探讨了使用毫米波雷达技术分析坐立动作的新方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种非接触、保护隐私并全天候运行的医疗应用方法，包括跌倒风险评估。&lt;h4&gt;方法&lt;/h4&gt;使用60GHz毫米波雷达系统收集雷达点云数据，捕捉45名参与者的坐立动作。通过深度学习姿态估计模型，从Kinect的内置人体追踪中学习人体骨架，并应用逆运动学计算关节角度，分段坐立动作，提取跌倒风险评估中常用的特征。&lt;h4&gt;主要发现&lt;/h4&gt;毫米波雷达在捕捉一般运动模式和大关节运动（如躯干）方面表现出有效性。雷达提取的特征与Kinect和可穿戴传感器获得的特征进行了比较。&lt;h4&gt;结论&lt;/h4&gt;研究强调了各个传感器的优缺点，并建议整合传感器技术以提高临床和生物医学研究中运动分析的准确性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;该研究为基于毫米波雷达的非接触式运动分析提供了新的视角，具有潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores a novel approach for analyzing Sit-to-Stand (STS)movements using millimeter-wave (mmWave) radar technology. The goal is todevelop a non-contact sensing, privacy-preserving, and all-day operationalmethod for healthcare applications, including fall risk assessment. We used a60GHz mmWave radar system to collect radar point cloud data, capturing STSmotions from 45 participants. By employing a deep learning pose estimationmodel, we learned the human skeleton from Kinect built-in body tracking andapplied Inverse Kinematics (IK) to calculate joint angles, segment STS motions,and extract commonly used features in fall risk assessment. Radar extractedfeatures were then compared with those obtained from Kinect and wearablesensors. The results demonstrated the effectiveness of mmWave radar incapturing general motion patterns and large joint movements (e.g., trunk).Additionally, the study highlights the advantages and disadvantages ofindividual sensors and suggests the potential of integrated sensor technologiesto improve the accuracy and reliability of motion analysis in clinical andbiomedical research settings.</description>
      <author>example@mail.com (Shuting Hu, Peggy Ackun, Xiang Zhang, Siyang Cao, Jennifer Barton, Melvin G. Hector, Mindy J. Fain, Nima Toosizadeh)</author>
      <guid isPermaLink="false">2411.14656v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CMATH: Cross-Modality Augmented Transformer with Hierarchical Variational Distillation for Multimodal Emotion Recognition in Conversation</title>
      <link>http://arxiv.org/abs/2411.10060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态情感识别旨在通过整合多模态信息准确识别对话中的情感。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型CMATH，以应对不同模态质量不均的问题，提高情感识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;CMATH包含两个主要组件：多模态交互融合和层次变分蒸馏。前者采用非对称融合策略，后者设计变分融合网络并引入层次蒸馏框架。&lt;h4&gt;主要发现&lt;/h4&gt;在IEMOCAP和MELD数据集上的实验表明，CMATH模型在性能上超越了现有的最先进基线。&lt;h4&gt;结论&lt;/h4&gt;CMATH有效地整合了不同模态的信息，提高了情感识别的准确性，具有潜在的应用价值。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的CMATH模型为多模态情感识别提供了一种新的解决方案，能够处理模态信息的不均衡性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal emotion recognition in conversation (MER) aims to accuratelyidentify emotions in conversational utterances by integrating multimodalinformation. Previous methods usually treat multimodal information as equalquality and employ symmetric architectures to conduct multimodal fusion.However, in reality, the quality of different modalities usually variesconsiderably, and utilizing a symmetric architecture is difficult to accuratelyrecognize conversational emotions when dealing with uneven modal information.Furthermore, fusing multi-modality information in a single granularity may failto adequately integrate modal information, exacerbating the inaccuracy inemotion recognition. In this paper, we propose a novel Cross-Modality AugmentedTransformer with Hierarchical Variational Distillation, called CMATH, whichconsists of two major components, i.e., Multimodal Interaction Fusion andHierarchical Variational Distillation. The former is comprised of twosubmodules, including Modality Reconstruction and Cross-Modality AugmentedTransformer (CMA-Transformer), where Modality Reconstruction focuses onobtaining high-quality compressed representation of each modality, andCMA-Transformer adopts an asymmetric fusion strategy which treats one modalityas the central modality and takes others as auxiliary modalities. The latterfirst designs a variational fusion network to fuse the fine-grainedrepresentations learned by CMA- Transformer into a coarse-grainedrepresentations. Then, it introduces a hierarchical distillation framework tomaintain the consistency between modality representations with differentgranularities. Experiments on the IEMOCAP and MELD datasets demonstrate thatour proposed model outperforms previous state-of-the-art baselines.Implementation codes can be available at https://github.com/ cjw-MER/CMATH.</description>
      <author>example@mail.com (Xiaofei Zhu, Jiawei Cheng, Zhou Yang, Zhuo Chen, Qingyang Wang, Jianfeng Yao)</author>
      <guid isPermaLink="false">2411.10060v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Conditional Distribution Learning on Graphs</title>
      <link>http://arxiv.org/abs/2411.15206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）在半监督图分类中表现出色，但仍面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种自监督条件分布学习（SSCDL）方法，以从图结构数据中学习图表示，改善半监督图分类效果。&lt;h4&gt;方法&lt;/h4&gt;设计一个端到端的图表示学习模型，旨在对齐弱增强和强增强特征的条件分布，同时保留正对的节点表示以避免GNN的消息传递机制与对比学习之间的冲突。&lt;h4&gt;主要发现&lt;/h4&gt;通过对齐条件分布，有效降低因图结构数据增强而破坏内在语义信息的风险，实验表明SSCDL方法在多个基准图数据集上表现出色。&lt;h4&gt;结论&lt;/h4&gt;SSCDL方法在半监督图分类中有效解决了GCL面临的挑战，提升了图表示学习的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的SSCDL方法为图对比学习提供了新的思路，结合了增强特征的条件分布对齐，展现了良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph contrastive learning (GCL) has shown promising performance insemisupervised graph classification. However, existing studies still encountersignificant challenges in GCL. First, successive layers in graph neural network(GNN) tend to produce more similar node embeddings, while GCL aims to increasethe dissimilarity between negative pairs of node embeddings. This inevitablyresults in a conflict between the message-passing mechanism of GNNs and thecontrastive learning of negative pairs via intraviews. Second, leveraging thediversity and quantity of data provided by graph-structured data augmentationswhile preserving intrinsic semantic information is challenging. In this paper,we propose a self-supervised conditional distribution learning (SSCDL) methoddesigned to learn graph representations from graph-structured data forsemisupervised graph classification. Specifically, we present an end-to-endgraph representation learning model to align the conditional distributions ofweakly and strongly augmented features over the original features. Thisalignment effectively reduces the risk of disrupting intrinsic semanticinformation through graph-structured data augmentation. To avoid conflictbetween the message-passing mechanism and contrastive learning of negativepairs, positive pairs of node representations are retained for measuring thesimilarity between the original features and the corresponding weakly augmentedfeatures. Extensive experiments with several benchmark graph datasetsdemonstrate the effectiveness of the proposed SSCDL method.</description>
      <author>example@mail.com (Jie Chen, Hua Mao, Yuanbiao Gou, Zhu Wang, Xi Peng)</author>
      <guid isPermaLink="false">2411.15206v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Heterophilic Graph Neural Networks Optimization with Causal Message-passing</title>
      <link>http://arxiv.org/abs/2411.13821v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究表明因果推断为捕捉图神经网络中的异质信息传递提供了有前景的方法。&lt;h4&gt;目的&lt;/h4&gt;利用因果效应分析，识别基于不对称节点依赖的异质边。&lt;h4&gt;方法&lt;/h4&gt;通过将因果分析简化为结构学习模型，并在贝叶斯框架内定义优化问题，引入基于干预的因果推断来减少计算复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;所学习的因果结构提供了更准确的节点关系，条件熵可以量化异质性，并提出了CausalMP，一个用于异质图学习的因果消息传递发现网络。&lt;h4&gt;结论&lt;/h4&gt;CausalMP在异质和同质图设置中的链接预测性能优越，并且在分类任务中通过训练因果结构提升了节点表示能力。&lt;h4&gt;总结&lt;/h4&gt;该研究为图学习中的异质性提供了新的视角，表明因果推断能够有效改善模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3701551.3703568&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we discover that causal inference provides a promising approachto capture heterophilic message-passing in Graph Neural Network (GNN). Byleveraging cause-effect analysis, we can discern heterophilic edges based onasymmetric node dependency. The learned causal structure offers more accuraterelationships among nodes. To reduce the computational complexity, we introduceintervention-based causal inference in graph learning. We first simplify causalanalysis on graphs by formulating it as a structural learning model and definethe optimization problem within the Bayesian scheme. We then present ananalysis of decomposing the optimization target into a consistency penalty anda structure modification based on cause-effect relations. We then estimate thistarget by conditional entropy and present insights into how conditional entropyquantifies the heterophily. Accordingly, we propose CausalMP, a causalmessage-passing discovery network for heterophilic graph learning, thatiteratively learns the explicit causal structure of input graphs. We conductextensive experiments in both heterophilic and homophilic graph settings. Theresult demonstrates that the our model achieves superior link predictionperformance. Training on causal structure can also enhance node representationin classification task across different base models.</description>
      <author>example@mail.com (Botao Wang, Jia Li, Heng Chang, Keli Zhang, Fugee Tsung)</author>
      <guid isPermaLink="false">2411.13821v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Probe-Me-Not: Protecting Pre-trained Encoders from Malicious Probing</title>
      <link>http://arxiv.org/abs/2411.12508v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Network and Distributed System Security (NDSS) Symposium
  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;适应预训练深度学习模型以满足定制任务成为开发者应对有限计算资源和数据量的热门选择。&lt;h4&gt;目的&lt;/h4&gt;引入EncoderLock，一种保护预训练编码器免受恶意探测的方法。&lt;h4&gt;方法&lt;/h4&gt;使用领域感知权重选择和更新，以及自我挑战训练方案，限制在禁止领域/任务的应用。&lt;h4&gt;主要发现&lt;/h4&gt;EncoderLock有效地平衡了在被授权领域的实用性和在禁止领域的性能下降。&lt;h4&gt;结论&lt;/h4&gt;EncoderLock在负责任的人工智能发展中具有重要贡献。&lt;h4&gt;变体&lt;/h4&gt;提供三种EncoderLock变体：监督（有标签数据）、无监督（无标签数据）、零样本（无数据或标签）。&lt;h4&gt;实际应用&lt;/h4&gt;在Facebook的预训练视觉变换器（ViT）编码器上验证了EncoderLock的有效性和实用性。&lt;h4&gt;总结&lt;/h4&gt;EncoderLock为预训练模型的安全应用提供了新的方法，有助于防止潜在的恶意使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adapting pre-trained deep learning models to customized tasks has become apopular choice for developers to cope with limited computational resources anddata volume. More specifically, probing--training a downstream head on apre-trained encoder--has been widely adopted in transfer learning, which helpsto prevent overfitting and catastrophic forgetting. However, suchgeneralizability of pre-trained encoders raises concerns about the potentialmisuse of probing for harmful intentions, such as discriminatory speculationand warfare applications. In this work, we introduce EncoderLock, a novelapplicability authorization method designed to protect pre-trained encodersfrom malicious probing, i.e., yielding poor performance on specified prohibiteddomains while maintaining their utility in authorized ones. Achieving thisbalance is challenging because of the opposite optimization objectives and thevariety of downstream heads that adversaries can utilize adaptively. To addressthese challenges, EncoderLock employs two techniques: domain-aware weightselection and updating to restrict applications on prohibited domains/tasks,and self-challenging training scheme that iteratively strengthens resistanceagainst any potential downstream classifiers that adversaries may apply.Moreover, recognizing the potential lack of data from prohibited domains inpractical scenarios, we introduce three EncoderLock variants with differentlevels of data accessibility: supervised (prohibited domain data with labels),unsupervised (prohibited domain data without labels), and zero-shot (no data orlabels available). We verify EncoderLock's effectiveness and practicality witha real-world pre-trained Vision Transformer (ViT) encoder from Facebook. Theseresults underscore the valuable contributions EncoderLock brings to thedevelopment of responsible AI.</description>
      <author>example@mail.com (Ruyi Ding, Tong Zhou, Lili Su, Aidong Adam Ding, Xiaolin Xu, Yunsi Fei)</author>
      <guid isPermaLink="false">2411.12508v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Double Machine Learning for Adaptive Causal Representation in High-Dimensional Data</title>
      <link>http://arxiv.org/abs/2411.14665v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了从观察数据中进行自适应因果表示学习的方法，结合了高效的样本分割技术。&lt;h4&gt;目的&lt;/h4&gt;在半参数估计方程框架内进行因果推断，提高数据处理的效率。&lt;h4&gt;方法&lt;/h4&gt;采用基于能量距离的支持点样本分割（SPSS）方法，进行双机器学习（DML）。&lt;h4&gt;主要发现&lt;/h4&gt;SPSS能选取和分割出最佳代表点，优于传统随机分割，能够更好地表示全数据集的底层数据生成分布。&lt;h4&gt;结论&lt;/h4&gt;采用SPSS的深度学习（DL）和混合超级学习器（SL）方法在计算效率和估计质量上均优于SPSS的支持向量机（SVM）。&lt;h4&gt;比较研究&lt;/h4&gt;与Chernozhukov等人（2018）的基准结果进行比较，显示出SPSS在多种机器学习估计器中的优势。&lt;h4&gt;总结&lt;/h4&gt;SPSS方法在因果推断中的应用为提高模型性能和数据代表性提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adaptive causal representation learning from observational data is presented,integrated with an efficient sample splitting technique within thesemiparametric estimating equation framework. The support points samplesplitting (SPSS), a subsampling method based on energy distance, is employedfor efficient double machine learning (DML) in causal inference. The supportpoints are selected and split as optimal representative points of the full rawdata in a random sample, in contrast to the traditional random splitting, andproviding an optimal sub-representation of the underlying data generatingdistribution. They offer the best representation of a full big dataset, whereasthe unit structural information of the underlying distribution via thetraditional random data splitting is most likely not preserved. Three machinelearning estimators were adopted for causal inference, support vector machine(SVM), deep learning (DL), and a hybrid super learner (SL) with deep learning(SDL), using SPSS. A comparative study is conducted between the proposed SVM,DL, and SDL representations using SPSS, and the benchmark results fromChernozhukov et al. (2018), which employed random forest, neural network, andregression trees with a random k-fold cross-fitting technique on the401(k)-pension plan real data. The simulations show that DL with SPSS and thehybrid methods of DL and SL with SPSS outperform SVM with SPSS in terms ofcomputational efficiency and the estimation quality, respectively.</description>
      <author>example@mail.com (Lynda Aouar, Han Yu)</author>
      <guid isPermaLink="false">2411.14665v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Data Scarcity: A Frequency-Driven Framework for Zero-Shot Forecasting</title>
      <link>http://arxiv.org/abs/2411.15743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列预测在许多实际应用中至关重要，需要基于观察到的模式对未来值进行准确预测。&lt;h4&gt;目的&lt;/h4&gt;探讨影响时间序列预测中有效学习的数据因素，尤其是在数据稀缺的情况下。&lt;h4&gt;方法&lt;/h4&gt;使用傅里叶分析研究模型如何从合成和真实的时间序列数据中学习。&lt;h4&gt;主要发现&lt;/h4&gt;预测模型在多频率数据上学习不佳，并且对未见频率的泛化能力差，这影响了预测性能。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的合成数据生成框架Freq-Synth，可以通过创建特定任务的频率信息来增强真实数据或完全替代它。&lt;h4&gt;应用&lt;/h4&gt;该方法提高了基础和非基础预测模型在零样本和少样本设置下的鲁棒性，促进了在数据有限情况下的时间序列预测。&lt;h4&gt;总结&lt;/h4&gt;通过改进学习过程，Freq-Synth为在数据稀缺的场景中提供了更可靠的时间序列预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting is critical in numerous real-world applications,requiring accurate predictions of future values based on observed patterns.While traditional forecasting techniques work well in in-domain scenarios withample data, they struggle when data is scarce or not available at all,motivating the emergence of zero-shot and few-shot learning settings. Recentadvancements often leverage large-scale foundation models for such tasks, butthese methods require extensive data and compute resources, and theirperformance may be hindered by ineffective learning from the available trainingset. This raises a fundamental question: What factors influence effectivelearning from data in time series forecasting? Toward addressing this, wepropose using Fourier analysis to investigate how models learn from syntheticand real-world time series data. Our findings reveal that forecasters commonlysuffer from poor learning from data with multiple frequencies and poorgeneralization to unseen frequencies, which impedes their predictiveperformance. To alleviate these issues, we present a novel synthetic datageneration framework, designed to enhance real data or replace it completely bycreating task-specific frequency information, requiring only the sampling rateof the target data. Our approach, Freq-Synth, improves the robustness of bothfoundation as well as nonfoundation forecast models in zero-shot and few-shotsettings, facilitating more reliable time series forecasting under limited datascenarios.</description>
      <author>example@mail.com (Liran Nochumsohn, Michal Moshkovitz, Orly Avner, Dotan Di Castro, Omri Azencot)</author>
      <guid isPermaLink="false">2411.15743v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TEXGen: a Generative Diffusion Model for Mesh Textures</title>
      <link>http://arxiv.org/abs/2411.14740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to SIGGRAPH Asia Journal Article (TOG 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高质量纹理贴图对真实感3D资产渲染至关重要，但鲜有研究直接在纹理空间学习，尤其是大规模数据集上。&lt;h4&gt;目的&lt;/h4&gt;探索在UV纹理空间中直接学习的方法，摆脱依赖预训练的2D扩散模型进行3D纹理的测试优化。&lt;h4&gt;方法&lt;/h4&gt;首次训练一个大型扩散模型，能够以前馈方式直接生成高分辨率纹理贴图，提出一种可扩展的网络架构，将UV图的卷积与点云的注意力层交错。&lt;h4&gt;主要发现&lt;/h4&gt;训练了一个700百万参数的扩散模型，能够根据文本提示和单视图图像生成UV纹理贴图。&lt;h4&gt;结论&lt;/h4&gt;一旦训练完成，该模型支持多种扩展应用，包括文本指导的纹理修复、稀疏视图纹理补全及文本驱动的纹理合成。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种新的方法来生成高质量纹理贴图，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3687909&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/CVMI-Lab/TEXGen&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While high-quality texture maps are essential for realistic 3D assetrendering, few studies have explored learning directly in the texture space,especially on large-scale datasets. In this work, we depart from theconventional approach of relying on pre-trained 2D diffusion models fortest-time optimization of 3D textures. Instead, we focus on the fundamentalproblem of learning in the UV texture space itself. For the first time, wetrain a large diffusion model capable of directly generating high-resolutiontexture maps in a feed-forward manner. To facilitate efficient learning inhigh-resolution UV spaces, we propose a scalable network architecture thatinterleaves convolutions on UV maps with attention layers on point clouds.Leveraging this architectural design, we train a 700 million parameterdiffusion model that can generate UV texture maps guided by text prompts andsingle-view images. Once trained, our model naturally supports various extendedapplications, including text-guided texture inpainting, sparse-view texturecompletion, and text-driven texture synthesis. Project page is athttp://cvmi-lab.github.io/TEXGen/.</description>
      <author>example@mail.com (Xin Yu, Ze Yuan, Yuan-Chen Guo, Ying-Tian Liu, JianHui Liu, Yangguang Li, Yan-Pei Cao, Ding Liang, Xiaojuan Qi)</author>
      <guid isPermaLink="false">2411.14740v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Uni-Mlip: Unified Self-supervision for Medical Vision Language Pre-training</title>
      <link>http://arxiv.org/abs/2411.15207v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 2 figures, accepted by BMVC'24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，通过对比学习进行的视觉-语言预训练在计算机视觉任务中的表现显著提高。&lt;h4&gt;目的&lt;/h4&gt;在医疗领域，由于隐私、敏感性和标注复杂性，获取多模态数据既昂贵又具挑战性，因此提出Uni-Mlip以缓解数据稀缺问题并提升模型性能。&lt;h4&gt;方法&lt;/h4&gt;Uni-Mlip是一个统一的自监督框架，专门设计用于增强医疗视觉-语言预训练，整合了跨模态、单模态和融合模态的自监督技术，涵盖数据层面和特征层面。&lt;h4&gt;主要发现&lt;/h4&gt;Uni-Mlip在三个主要下游任务（图像-文本检索、图像分类和视觉问答）中显著超过现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;Uni-Mlip通过量身定制的单模态图像自监督技术，充分考虑医疗图像的独特特性，提升了模型在医疗领域的表现。&lt;h4&gt;总结&lt;/h4&gt;Uni-Mlip为医疗视觉-语言预训练提供了一种有效的方法，克服了数据稀缺带来的挑战，展现出良好的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in vision-language pre-training via contrastive learninghave significantly improved performance across computer vision tasks. However,in the medical domain, obtaining multimodal data is often costly andchallenging due to privacy, sensitivity, and annotation complexity. To mitigatedata scarcity while boosting model performance, we introduce \textbf{Uni-Mlip},a unified self-supervision framework specifically designed to enhance medicalvision-language pre-training. Uni-Mlip seamlessly integrates cross-modality,uni-modality, and fused-modality self-supervision techniques at the data-leveland the feature-level. Additionally, Uni-Mlip tailors uni-modal imageself-supervision to accommodate the unique characteristics of medical images.Our experiments across datasets of varying scales demonstrate that Uni-Mlipsignificantly surpasses current state-of-the-art methods in three keydownstream tasks: image-text retrieval, image classification, and visualquestion answering (VQA).</description>
      <author>example@mail.com (Ameera Bawazir, Kebin Wu, Wenbin Li)</author>
      <guid isPermaLink="false">2411.15207v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multivariate and Online Transfer Learning with Uncertainty Quantification</title>
      <link>http://arxiv.org/abs/2411.12555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 1 figure, 17 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;未治疗的牙周炎会导致牙齿支持组织的炎症，最终可能导致牙齿丧失。&lt;h4&gt;目的&lt;/h4&gt;建立牙周结果模型，以便于测量，但必须考虑不同人群之间的表现差异。&lt;h4&gt;方法&lt;/h4&gt;提出一种扩展的RECaST贝叶斯迁移学习框架，联合建模多元结果，并引入在线方法以建模序列数据集。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在预测性能和不确定性量化方面相较于之前的单变量RECaST方法有显著改善。&lt;h4&gt;结论&lt;/h4&gt;通过减轻负迁移，确保来自其他人群的信息不会对欠代表性参与者的建模产生负面影响，且在医学应用中不共享数据。&lt;h4&gt;总结&lt;/h4&gt;该方法在模拟数据和HealthPartners Institute的牙科记录数据库上展示了有效性，特别是在预测表现和不确定性量化方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Untreated periodontitis causes inflammation within the supporting tissue ofthe teeth and can ultimately lead to tooth loss. Modeling periodontal outcomesis beneficial as they are difficult and time consuming to measure, butdisparities in representation between demographic groups must be considered.There may not be enough participants to build group specific models and it canbe ineffective, and even dangerous, to apply a model to participants in anunderrepresented group if demographic differences were not considered duringtraining. We propose an extension to RECaST Bayesian transfer learningframework. Our method jointly models multivariate outcomes, exhibitingsignificant improvement over the previous univariate RECaST method. Further, weintroduce an online approach to model sequential data sets. Negative transferis mitigated to ensure that the information shared from the other demographicgroups does not negatively impact the modeling of the underrepresentedparticipants. The Bayesian framework naturally provides uncertaintyquantification on predictions. Especially important in medical applications,our method does not share data between domains. We demonstrate theeffectiveness of our method in both predictive performance and uncertaintyquantification on simulated data and on a database of dental records from theHealthPartners Institute.</description>
      <author>example@mail.com (Jimmy Hickey, Jonathan P. Williams, Brian J. Reich, Emily C. Hector)</author>
      <guid isPermaLink="false">2411.12555v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Topology-Aware Popularity Debiasing via Simplicial Complexes</title>
      <link>http://arxiv.org/abs/2411.13892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;推荐系统在各类在线平台中扮演着关键角色，利用协同过滤技术根据用户的历史交互数据生成个性化推荐。&lt;h4&gt;目的&lt;/h4&gt;解决GNN（图神经网络）方法在用户-物品交互图中由于流行度偏差导致的推荐偏差问题。&lt;h4&gt;方法&lt;/h4&gt;提出一个新颖的拓扑感知流行度去偏框架Test-time Simplicial Propagation (TSP)，通过简单复合体增强GNN的表达能力。&lt;h4&gt;主要发现&lt;/h4&gt;TSP能够捕捉多阶关系，丰富尾部物品的邻域，有效缓解偏向流行物品的推荐问题。&lt;h4&gt;结论&lt;/h4&gt;TSP作为一个即插即用的解决方案，可以无缝集成到预训练的GNN模型中，且在五个真实世界数据集上的实验表明其在长尾推荐任务中的优越性能。&lt;h4&gt;总结&lt;/h4&gt;TSP方法在推荐系统中提供了更均匀的物品表示分布，促进了更公平和准确的推荐结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems (RS) play a critical role in delivering personalizedcontent across various online platforms, leveraging collaborative filtering(CF) as a key technique to generate recommendations based on users' historicalinteraction data. Recent advancements in CF have been driven by the adoption ofGraph Neural Networks (GNNs), which model user-item interactions as bipartitegraphs, enabling the capture of high-order collaborative signals. Despite theirsuccess, GNN-based methods face significant challenges due to the inherentpopularity bias in the user-item interaction graph's topology, leading toskewed recommendations that favor popular items over less-known ones.  To address this challenge, we propose a novel topology-aware popularitydebiasing framework, Test-time Simplicial Propagation (TSP), which incorporatessimplicial complexes (SCs) to enhance the expressiveness of GNNs. Unliketraditional methods that focus on pairwise relationships, our approach capturesmulti-order relationships through SCs, providing a more comprehensiverepresentation of user-item interactions. By enriching the neighborhoods oftail items and leveraging SCs for feature smoothing, TSP enables thepropagation of multi-order collaborative signals and effectively mitigatesbiased propagation.  Our TSP module is designed as a plug-and-play solution, allowing for seamlessintegration into pre-trained GNN-based models without the need for fine-tuningadditional parameters. Extensive experiments on five real-world datasetsdemonstrate the superior performance of our method, particularly in long-tailrecommendation tasks. Visualization results further confirm that TSP producesmore uniform distributions of item representations, leading to fairer and moreaccurate recommendations.</description>
      <author>example@mail.com (Yanbiao Ji, Yue Ding, Chang Liu, Yuxiang Lu, Xin Xin, Hongtao Lu)</author>
      <guid isPermaLink="false">2411.13892v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>GraphTheft: Quantifying Privacy Risks in Graph Prompt Learning</title>
      <link>http://arxiv.org/abs/2411.14718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图提示学习（GPL）是一种创新的图表示学习方法，能够通过微调提示进行任务特定的适应，而无需更改基础的预训练模型。&lt;h4&gt;目的&lt;/h4&gt;探讨GPL中的隐私风险，这是一个尚未被充分研究的领域。&lt;h4&gt;方法&lt;/h4&gt;评估在三种攻击者能力下GPL的隐私泄露，包括黑盒攻击和第三方访问节点嵌入与提示表示的场景，采用属性推断攻击（AIA）和链接推断攻击（LIA）进行分析。&lt;h4&gt;主要发现&lt;/h4&gt;攻击者能够有效推断出敏感节点的属性和关系，某些数据集上的推断成功率高达98%。尽管针对特定提示的攻击（如GPF-plus）成功率高，但提示调优在GPL中与传统GNN相比并未显著提高隐私风险。&lt;h4&gt;结论&lt;/h4&gt;为减轻这些隐私风险，研究探索了防御机制，发现拉普拉斯噪声扰动可以显著降低推断成功率，但在隐私保护与模型性能之间仍需平衡。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了GPL中的关键隐私风险，为未来图学习中的隐私保护策略提供了新见解和基础方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Prompt Learning (GPL) represents an innovative approach in graphrepresentation learning, enabling task-specific adaptations by fine-tuningprompts without altering the underlying pre-trained model. Despite its growingprominence, the privacy risks inherent in GPL remain unexplored. In this study,we provide the first evaluation of privacy leakage in GPL across three attackercapabilities: black-box attacks when GPL as a service, and scenarios where nodeembeddings and prompt representations are accessible to third parties. Weassess GPL's privacy vulnerabilities through Attribute Inference Attacks (AIAs)and Link Inference Attacks (LIAs), finding that under any capability, attackerscan effectively infer the properties and relationships of sensitive nodes, andthe success rate of inference on some data sets is as high as 98%. Importantly,while targeted inference attacks on specific prompts (e.g., GPF-plus) maintainhigh success rates, our analysis suggests that the prompt-tuning in GPL doesnot significantly elevate privacy risks compared to traditional GNNs. Tomitigate these risks, we explored defense mechanisms, identifying thatLaplacian noise perturbation can substantially reduce inference success, thoughbalancing privacy protection with model performance remains challenging. Thiswork highlights critical privacy risks in GPL, offering new insights andfoundational directions for future privacy-preserving strategies in graphlearning.</description>
      <author>example@mail.com (Jiani Zhu, Xi Lin, Yuxin Qi, Qinghua Mao)</author>
      <guid isPermaLink="false">2411.14718v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>ZeroGS: Training 3D Gaussian Splatting from Unposed Images</title>
      <link>http://arxiv.org/abs/2411.15779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;NeRF和3D Gaussian Splatting是重建和渲染照片级真实图像的流行技术，但需要结构光束法（SfM）来获取相机姿态，这限制了其完整性。&lt;h4&gt;目的&lt;/h4&gt;提出ZeroGS方法，从数百张未标定和无序图像中训练3DGS。&lt;h4&gt;方法&lt;/h4&gt;利用预训练的基础模型作为神经场景表示，通过从种子图像初始化和微调预训练模型，逐步注册图像并添加到训练缓冲区。此外，通过最小化多视图间的点到相机光线一致性损失来优化相机姿态和点图。&lt;h4&gt;主要发现&lt;/h4&gt;在LLFF、MipNeRF360和Tanks-and-Temples数据集上的实验表明，ZeroGS恢复的相机姿态比现有的无姿态NeRF/3DGS方法更准确，并且渲染质量高于使用COLMAP姿态的3DGS。&lt;h4&gt;结论&lt;/h4&gt;ZeroGS能够有效地从无序图像中学习相机姿态和点图，提升了图像渲染的质量。&lt;h4&gt;总结&lt;/h4&gt;ZeroGS方法突破了传统方法的限制，提供了一种新的解决方案来处理无序和未标定图像的3D重建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural radiance fields (NeRF) and 3D Gaussian Splatting (3DGS) are populartechniques to reconstruct and render photo-realistic images. However, thepre-requisite of running Structure-from-Motion (SfM) to get camera poses limitstheir completeness. While previous methods can reconstruct from a few unposedimages, they are not applicable when images are unordered or densely captured.In this work, we propose ZeroGS to train 3DGS from hundreds of unposed andunordered images. Our method leverages a pretrained foundation model as theneural scene representation. Since the accuracy of the predicted pointmaps doesnot suffice for accurate image registration and high-fidelity image rendering,we propose to mitigate the issue by initializing and finetuning the pretrainedmodel from a seed image. Images are then progressively registered and added tothe training buffer, which is further used to train the model. We also proposeto refine the camera poses and pointmaps by minimizing a point-to-camera rayconsistency loss across multiple views. Experiments on the LLFF dataset, theMipNeRF360 dataset, and the Tanks-and-Temples dataset show that our methodrecovers more accurate camera poses than state-of-the-art pose-free NeRF/3DGSmethods, and even renders higher quality images than 3DGS with COLMAP poses.Our project page is available at https://aibluefisher.github.io/ZeroGS.</description>
      <author>example@mail.com (Yu Chen, Rolandos Alexandros Potamias, Evangelos Ververas, Jifei Song, Jiankang Deng, Gim Hee Lee)</author>
      <guid isPermaLink="false">2411.15779v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Deep Autoencoders for Unsupervised Anomaly Detection in Wildfire Prediction</title>
      <link>http://arxiv.org/abs/2411.09844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 18 figure, 16 tables. To appear in Earth and Space Science&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;由于气候危机，野火对全球生态系统的威胁显著增加。&lt;h4&gt;目的&lt;/h4&gt;研究创新的野火预测方法，特别是在无监督学习方面填补空白。&lt;h4&gt;方法&lt;/h4&gt;利用2005至2021年澳大利亚的历史天气和归一化差异植被指数数据，采用深度自编码器和聚类技术进行异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;深度自编码器用于提取潜在特征，并将其输入到孤立森林、局部离群因子和单类支持向量机等聚类模型中进行异常检测。&lt;h4&gt;结论&lt;/h4&gt;全连接自编码器表现优于其他模型，准确率为0.71，F1-score为0.74，MCC为0.42，证明了无监督学习技术在缺乏真实数据情况下有效预测野火的实用性。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了无监督学习在野火预测中的潜力，为未来的研究提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wildfires pose a significantly increasing hazard to global ecosystems due tothe climate crisis. Due to its complex nature, there is an urgent need forinnovative approaches to wildfire prediction, such as machine learning. Thisresearch took a unique approach, differentiating from classical supervisedlearning, and addressed the gap in unsupervised wildfire prediction usingautoencoders and clustering techniques for anomaly detection. Historicalweather and normalised difference vegetation index datasets of Australia for2005 - 2021 were utilised. Two main unsupervised approaches were analysed. Thefirst used a deep autoencoder to obtain latent features, which were then fedinto clustering models, isolation forest, local outlier factor and one-classSVM for anomaly detection. The second approach used a deep autoencoder toreconstruct the input data and use reconstruction errors to identify anomalies.Long Short-Term Memory (LSTM) autoencoders and fully connected (FC)autoencoders were employed in this part, both in an unsupervised way learningonly from nominal data. The FC autoencoder outperformed its counterparts,achieving an accuracy of 0.71, an F1-score of 0.74, and an MCC of 0.42. Thesefindings highlight the practicality of this method, as it effectively predictswildfires in the absence of ground truth, utilising an unsupervised learningtechnique.</description>
      <author>example@mail.com (İrem Üstek, Miguel Arana-Catania, Alexander Farr, Ivan Petrunin)</author>
      <guid isPermaLink="false">2411.09844v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Weakly-Supervised Multimodal Learning on MIMIC-CXR</title>
      <link>http://arxiv.org/abs/2411.10356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Findings paper presented at Machine Learning for Health (ML4H)
  symposium 2024, December 15-16, 2024, Vancouver, Canada, 13 pages. arXiv
  admin note: text overlap with arXiv:2403.05300&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态数据集成和标签稀缺对医疗领域的机器学习构成重大挑战。&lt;h4&gt;目的&lt;/h4&gt;评估新提出的多模态变分混合专家模型（MMVM VAE）在医疗数据集上的表现。&lt;h4&gt;方法&lt;/h4&gt;对MIMIC-CXR数据集进行深入评估，比较MMVM VAE与其他多模态VAEs和完全监督方法的表现。&lt;h4&gt;主要发现&lt;/h4&gt;MMVM VAE在多个评估中始终优于其他多模态VAEs和完全监督的方法。&lt;h4&gt;结论&lt;/h4&gt;MMVM VAE在实际医疗应用中具有强大的潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，MMVM VAE是解决医疗领域多模态数据和标签稀缺问题的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal data integration and label scarcity pose significant challengesfor machine learning in medical settings. To address these issues, we conductan in-depth evaluation of the newly proposed Multimodal VariationalMixture-of-Experts (MMVM) VAE on the challenging MIMIC-CXR dataset. Ouranalysis demonstrates that the MMVM VAE consistently outperforms othermultimodal VAEs and fully supervised approaches, highlighting its strongpotential for real-world medical applications.</description>
      <author>example@mail.com (Andrea Agostini, Daphné Chopard, Yang Meng, Norbert Fortin, Babak Shahbaba, Stephan Mandt, Thomas M. Sutter, Julia E. Vogt)</author>
      <guid isPermaLink="false">2411.10356v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning Domain Adaptation in Spin Models with Continuous Phase Transitions</title>
      <link>http://arxiv.org/abs/2411.13027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 1 figure, supplemental materials&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;信中提出了一个主要问题，即在一个普适性类别中训练的神经网络能否应用于测试另一个普适性类别的模型。&lt;h4&gt;目的&lt;/h4&gt;研究关键相变温度和相关长度指数的可转移学习能力。&lt;h4&gt;方法&lt;/h4&gt;传统的训练和测试自旋分布的方法被认为不适用，因此提出使用结合能分布进行训练和测试。&lt;h4&gt;主要发现&lt;/h4&gt;通过这种方法，可以成功估计不同普适性类别的Baxter-Wu模型和Ising模型的临界温度和相关长度指数。&lt;h4&gt;结论&lt;/h4&gt;结合能分布的训练和测试方法在跨类别模型的评估中是有效的。&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了神经网络在不同普适性类别模型间的适用性，并提出了新的训练方法以提高估计准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The main question raised in the letter is the applicability of a neuralnetwork trained on a spin lattice model in one universality class to test amodel in another universality class. The quantities of interest are thecritical phase transition temperature and the correlation length exponent. Inother words, the question of transfer learning is how ``universal'' the trainednetwork is and under what conditions. The traditional approach with trainingand testing spin distributions turns out to be inapplicable for this purpose.Instead, we propose to use training and testing on binding energydistributions, which leads to successful estimates of the critical temperatureand correlation length exponent for cross-tested Baxter-Wu and Ising modelsbelonging to different universality classes.</description>
      <author>example@mail.com (Vladislav Chertenkov, Lev Shchur)</author>
      <guid isPermaLink="false">2411.13027v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Camera Distracted Driver Classification through Feature Disentanglement and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2411.13181v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;驾驶员分心的分类对于确保安全驾驶至关重要。以往研究表明神经网络在自动预测驾驶员分心、疲劳和潜在危险方面的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种强健的模型，以应对车辆内摄像头位置变化对分类准确性的影响。&lt;h4&gt;方法&lt;/h4&gt;开发了驾驶行为监测网络（DBMNet），采用轻量级骨干网络，并整合解耦模块以去除特征中的摄像头视角信息，同时使用对比学习增强不同驾驶行为的编码。&lt;h4&gt;主要发现&lt;/h4&gt;在100-Driver数据集的白天和黑夜子集上进行实验，结果表明与现有技术相比，Top-1准确率平均提高了9%。&lt;h4&gt;结论&lt;/h4&gt;在三个基准数据集（AUCDD-V1、EZZ2021和SFD）上进行的跨数据集和跨摄像头实验验证了该方法的优越泛化能力。&lt;h4&gt;总结&lt;/h4&gt;提出的DBMNet模型在应对摄像头位置变化时，显著提升了驾驶员行为分类的准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The classification of distracted drivers is pivotal for ensuring safedriving. Previous studies demonstrated the effectiveness of neural networks inautomatically predicting driver distraction, fatigue, and potential hazards.However, recent research has uncovered a significant loss of accuracy in thesemodels when applied to samples acquired under conditions that differ from thetraining data. In this paper, we introduce a robust model designed to withstandchanges in camera position within the vehicle. Our Driver Behavior MonitoringNetwork (DBMNet) relies on a lightweight backbone and integrates adisentanglement module to discard camera view information from features,coupled with contrastive learning to enhance the encoding of various driveractions. Experiments conducted on the daytime and nighttime subsets of the100-Driver dataset validate the effectiveness of our approach with an incrementon average of 9\% in Top-1 accuracy in comparison with the state of the art. Inaddition, cross-dataset and cross-camera experiments conducted on threebenchmark datasets, namely AUCDD-V1, EZZ2021 and SFD, demonstrate the superiorgeneralization capability of the proposed method.</description>
      <author>example@mail.com (Simone Bianco, Luigi Celona, Paolo Napoletano)</author>
      <guid isPermaLink="false">2411.13181v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Teaching MLPs to Master Heterogeneous Graph-Structured Knowledge for Efficient and Accurate Inference</title>
      <link>http://arxiv.org/abs/2411.14035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;异构图神经网络（HGNNs）在各种异构图学习任务中取得了良好结果，能够捕捉复杂关系和多样的关系语义。&lt;h4&gt;目的&lt;/h4&gt;解决HGNNs在延迟敏感应用中因结构依赖导致的邻域获取延迟问题，提升推理速度。&lt;h4&gt;方法&lt;/h4&gt;提出HG2M和HG2M+，结合HGNN的高性能与多层感知器（MLP）的高效推理，HG2M直接使用节点特征和来自HGNN的软标签训练学生MLP，HG2M+通过可靠的节点蒸馏和元路径蒸馏进一步提取知识。&lt;h4&gt;主要发现&lt;/h4&gt;在六个异构图数据集的实验中，HG2M在没有结构依赖的情况下，表现出与HGNNs竞争甚至更好的性能，显著优于传统MLPs。&lt;h4&gt;结论&lt;/h4&gt;HG2M在大规模IGB-3M-19数据集上推理速度比HGNNs快379.24倍，显示出其在延迟敏感部署中的潜力。&lt;h4&gt;总结&lt;/h4&gt;HG2M和HG2M+有效地提高了异构图学习的推理效率，同时保持了较高的性能，适合应用于对延迟要求严格的场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cloudy1225/hg2m&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous Graph Neural Networks (HGNNs) have achieved promising resultsin various heterogeneous graph learning tasks, owing to their superiority incapturing the intricate relationships and diverse relational semantics inherentin heterogeneous graph structures. However, the neighborhood-fetching latencyincurred by structure dependency in HGNNs makes it challenging to deploy forlatency-constrained applications that require fast inference. Inspired byrecent GNN-to-MLP knowledge distillation frameworks, we introduce HG2M andHG2M+ to combine both HGNN's superior performance and MLP's efficientinference. HG2M directly trains student MLPs with node features as input andsoft labels from teacher HGNNs as targets, and HG2M+ further distills reliableand heterogeneous semantic knowledge into student MLPs through reliable nodedistillation and reliable meta-path distillation. Experiments conducted on sixheterogeneous graph datasets show that despite lacking structural dependencies,HG2Ms can still achieve competitive or even better performance than HGNNs andsignificantly outperform vanilla MLPs. Moreover, HG2Ms demonstrate a379.24$\times$ speedup in inference over HGNNs on the large-scale IGB-3M-19dataset, showcasing their ability for latency-sensitive deployments.</description>
      <author>example@mail.com (Yunhui Liu, Xinyi Gao, Tieke He, Jianhua Zhao, Hongzhi Yin)</author>
      <guid isPermaLink="false">2411.14035v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CRT-Fusion: Camera, Radar, Temporal Fusion Using Motion Information for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.03013v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;精确和稳健的3D物体检测是自动驾驶车辆和机器人技术的关键组成部分。&lt;h4&gt;目的&lt;/h4&gt;提出CRT-Fusion框架，通过引入时间信息增强雷达-摄像头融合，提升动态物体的检测能力。&lt;h4&gt;方法&lt;/h4&gt;CRT-Fusion包含三个关键模块：多视图融合（MVF）、运动特征估计（MFE）和运动引导时间融合（MGTF）。&lt;h4&gt;主要发现&lt;/h4&gt;CRT-Fusion在nuScenes数据集上的评估显示，其在NDS指标上比之前最佳方法提高了1.7%，在mAP上超过了领先方法1.4%。&lt;h4&gt;结论&lt;/h4&gt;CRT-Fusion显著提高了基于雷达-摄像头的3D物体检测的准确性和稳健性，展示了其融合策略的有效性。&lt;h4&gt;总结&lt;/h4&gt;通过考虑动态物体的运动，CRT-Fusion能够生成更可靠的BEV特征图，从而提升检测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and robust 3D object detection is a critical component in autonomousvehicles and robotics. While recent radar-camera fusion methods have madesignificant progress by fusing information in the bird's-eye view (BEV)representation, they often struggle to effectively capture the motion ofdynamic objects, leading to limited performance in real-world scenarios. Inthis paper, we introduce CRT-Fusion, a novel framework that integrates temporalinformation into radar-camera fusion to address this challenge. Our approachcomprises three key modules: Multi-View Fusion (MVF), Motion Feature Estimator(MFE), and Motion Guided Temporal Fusion (MGTF). The MVF module fuses radar andimage features within both the camera view and bird's-eye view, therebygenerating a more precise unified BEV representation. The MFE module conductstwo simultaneous tasks: estimation of pixel-wise velocity information and BEVsegmentation. Based on the velocity and the occupancy score map obtained fromthe MFE module, the MGTF module aligns and fuses feature maps across multipletimestamps in a recurrent manner. By considering the motion of dynamic objects,CRT-Fusion can produce robust BEV feature maps, thereby improving detectionaccuracy and robustness. Extensive evaluations on the challenging nuScenesdataset demonstrate that CRT-Fusion achieves state-of-the-art performance forradar-camera-based 3D object detection. Our approach outperforms the previousbest method in terms of NDS by +1.7%, while also surpassing the leadingapproach in mAP by +1.4%. These significant improvements in both metricsshowcase the effectiveness of our proposed fusion strategy in enhancing thereliability and accuracy of 3D object detection.</description>
      <author>example@mail.com (Jisong Kim, Minjae Seong, Jun Won Choi)</author>
      <guid isPermaLink="false">2411.03013v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Attributed Graph Clustering via Generalized Quaternion Representation Learning</title>
      <link>http://arxiv.org/abs/2411.14727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于属性图的复杂数据聚类受到越来越多的关注，图表示是准确聚类分析的关键前提。&lt;h4&gt;目的&lt;/h4&gt;提出一种通用的图自编码网络，以解决图卷积网络在节点表示上过度平滑的问题。&lt;h4&gt;方法&lt;/h4&gt;引入四元数运算到编码器中，实现高效的结构化特征表示学习，而无需加深网络或增加参数规模。&lt;h4&gt;主要发现&lt;/h4&gt;提出的基于通用四元数表示学习的图聚类方法（GCGQ）学习到的节点表示更加具有区分性，包含全局分布信息，并且适用于不同聚类数的下游任务。&lt;h4&gt;结论&lt;/h4&gt;GCGQ在多个实验中表现优越，包括显著性测试、消融研究和定性结果，证明了其方法的优越性。&lt;h4&gt;总结&lt;/h4&gt;GCGQ方法有效改善了图节点的表示，提升了聚类分析的准确性，源代码已暂时开放。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clustering complex data in the form of attributed graphs has attractedincreasing attention, where appropriate graph representation is a criticalprerequisite for accurate cluster analysis. However, the Graph ConvolutionalNetwork will homogenize the representation of graph nodes due to the well-knownover-smoothing effect. This limits the network architecture to a shallow one,losing the ability to capture the critical global distribution information forclustering. Therefore, we propose a generalized graph auto-encoder network,which introduces quaternion operations to the encoders to achieve efficientstructured feature representation learning without incurring deeper network andlarger-scale parameters. The generalization of our method lies in the followingtwo aspects: 1) connecting the quaternion operation naturally suitable for fourfeature components with graph data of arbitrary attribute dimensions, and 2)introducing a generalized graph clustering objective as a loss term to obtainclustering-friendly representations without requiring a pre-specified number ofclusters $k$. It turns out that the representations of nodes learned by theproposed Graph Clustering based on Generalized Quaternion representationlearning (GCGQ) are more discriminative, containing global distributioninformation, and are more general, suiting downstream clustering underdifferent $k$s. Extensive experiments including significance tests, ablationstudies, and qualitative results, illustrate the superiority of GCGQ. Thesource code is temporarily opened at\url{https://anonymous.4open.science/r/ICLR-25-No7181-codes}.</description>
      <author>example@mail.com (Junyang Chen, Yiqun Zhang, Mengke Li, Yang Lu, Yiu-ming Cheung)</author>
      <guid isPermaLink="false">2411.14727v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Peritumoral Expansion Radiomics for Improved Lung Cancer Classification</title>
      <link>http://arxiv.org/abs/2411.16008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2 table, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究肺癌分类的放射组学方法及其对结节分割和周围肿瘤区域的影响。&lt;h4&gt;目的&lt;/h4&gt;调查结节分割和周围肿瘤区域对基于放射组学的肺癌分类的影响。&lt;h4&gt;方法&lt;/h4&gt;使用标注了包围盒的3D CT扫描，采用Otsu、模糊C均值（FCM）、高斯混合模型（GMM）和K近邻（KNN）四种技术生成3D分割，提取放射组学特征，并使用随机森林、逻辑回归和KNN等多种机器学习分类器进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;将周围肿瘤区域纳入分析显著提高了分类性能，在8毫米扩展时取得最佳结果（AUC = 0.78）。与深度学习模型（如FMCB和ResNet50-SWS++，均为AUC = 0.71）相比，放射组学方法表现出更高的分类准确性。&lt;h4&gt;结论&lt;/h4&gt;研究强调了周围肿瘤扩展在改善肺癌分类中的重要性，这些发现可为开发更强大的AI驱动诊断工具提供依据。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，周围肿瘤区域的扩展对放射组学肺癌分类具有重要影响，能够提升分类准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/fitushar/AI-in-Lung-Health-Benchmarking-Detection-and-Diagnostic-Models-Across-Multiple-CT-Scan-Datasets&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: This study investigated how nodule segmentation and surroundingperitumoral regions influence radionics-based lung cancer classification.Methods: Using 3D CT scans with bounding box annotated nodules, we generated 3Dsegmentations using four techniques: Otsu, Fuzzy C-Means (FCM), GaussianMixture Model (GMM), and K-Nearest Neighbors (KNN). Radiomics features wereextracted using the PyRadiomics library, and multiple machine-learning-basedclassifiers, including Random Forest, Logistic Regression, and KNN, wereemployed to classify nodules as cancerous or non-cancerous. The best-performingsegmentation and model were further analyzed by expanding the initial nodulesegmentation into the peritumoral region (2, 4, 6, 8, 10, and 12 mm) tounderstand the influence of the surrounding area on classification.Additionally, we compared our results to deep learning-based feature extractorsFoundation Model for Cancer Biomarkers (FMCB) and other state-of-the-artbaseline models. Results: Incorporating peritumoral regions significantlyenhanced performance, with the best result obtained at 8 mm expansion (AUC =0.78). Compared to image-based deep learning models, such as FMCB (AUC = 0.71)and ResNet50-SWS++ (AUC = 0.71), our radiomics-based approach demonstratedsuperior classification accuracy. Conclusion: The study highlights theimportance of peritumoral expansion in improving lung cancer classificationusing radiomics. These findings can inform the development of more robustAI-driven diagnostic tools.</description>
      <author>example@mail.com (Fakrul Islam Tushar)</author>
      <guid isPermaLink="false">2411.16008v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Machine Learning-based Physical-Layer Authentication in Wireless Communications</title>
      <link>http://arxiv.org/abs/2411.09906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  111 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在无线系统中，确保安全可靠的通信需要对众多节点的身份进行认证。传统的基于密码学的认证方法存在兼容性差、可靠性低和复杂性高等问题。&lt;h4&gt;目的&lt;/h4&gt;探讨物理层认证（PLA）作为传统方法的补充，特别是基于机器学习（ML）的PLA。&lt;h4&gt;方法&lt;/h4&gt;对现有的基于ML的PLA技术和特征进行全面的调查和分类。将这些方案分为多设备识别和攻击检测两大类。&lt;h4&gt;主要发现&lt;/h4&gt;{'多设备识别': '深度学习模型（如深度神经网络和卷积神经网络）在多设备识别中应用广泛，避免了复杂处理和专家特征转换。', '攻击检测': '基于ML的攻击检测方案使用智能技术自动设定检测阈值，分为监督学习、无监督学习和强化学习三种子类型。'}&lt;h4&gt;数据集&lt;/h4&gt;总结了用于PLA的开源数据集，包括射频指纹和信道指纹。&lt;h4&gt;结论&lt;/h4&gt;本文概述了基于ML的PLA的现状，指明了未来研究方向，以指导相关领域的研究者。&lt;h4&gt;总结&lt;/h4&gt;研究表明，基于机器学习的物理层认证在安全通信中具有重要的应用潜力和研究价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To ensure secure and reliable communication in wireless systems,authenticating the identities of numerous nodes is imperative. Traditionalcryptography-based authentication methods suffer from issues such as lowcompatibility, reliability, and high complexity. Physical-Layer Authentication(PLA) is emerging as a promising complement due to its exploitation of uniqueproperties in wireless environments. Recently, Machine Learning (ML)-based PLAhas gained attention for its intelligence, adaptability, universality, andscalability compared to non-ML approaches. However, a comprehensive overview ofstate-of-the-art ML-based PLA and its foundational aspects is lacking. Thispaper presents a comprehensive survey of characteristics and technologies thatcan be used in the ML-based PLA. We categorize existing ML-based PLA schemesinto two main types: multi-device identification and attack detection schemes.In deep learning-based multi-device identification schemes, Deep NeuralNetworks are employed to train models, avoiding complex processing and expertfeature transformation. Deep learning-based multi-device identification schemesare further subdivided, with schemes based on Convolutional Neural Networksbeing extensively researched. In ML-based attack detection schemes, receiversutilize intelligent ML techniques to set detection thresholds automatically,eliminating the need for manual calculation or knowledge of channel models.ML-based attack detection schemes are categorized into three sub-types:Supervised Learning, Unsupervised Learning, and Reinforcement Learning.Additionally, we summarize open-source datasets used for PLA, encompassingRadio Frequency fingerprints and channel fingerprints. Finally, this paperoutlines future research directions to guide researchers in related fields.</description>
      <author>example@mail.com (Rui Meng, Bingxuan Xu, Xiaodong Xu, Mengying Sun, Bizhu Wanga, Shujun Han, Suyu Lv, Ping Zhang)</author>
      <guid isPermaLink="false">2411.09906v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SoK: Unifying Cybersecurity and Cybersafety of Multimodal Foundation Models with an Information Theory Approach</title>
      <link>http://arxiv.org/abs/2411.11195v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型（MFMs）在人工智能领域取得了重要进展，结合了多种数据模态以增强学习和理解能力。&lt;h4&gt;目的&lt;/h4&gt;探讨多模态学习中网络安全和网络安全性问题，提出统一的概念框架。&lt;h4&gt;方法&lt;/h4&gt;提出基于信息论的分类框架，通过信道容量、信号、噪声和带宽等概念评估和分类模型面临的威胁。&lt;h4&gt;主要发现&lt;/h4&gt;识别了多模态基础模型的主要威胁，并探索了现有防御机制的不足，特别是在模态对齐保护和系统性防御方法方面的缺失。&lt;h4&gt;结论&lt;/h4&gt;本研究为深入理解多模态基础模型中的安全性和安全性问题提供了重要见解，有助于提高模型的稳健性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;通过全面的系统知识整理，提出了一个新框架，以整合模型安全和系统安全的概念，为研究人员和从业者提供了改进模型的有价值的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models (MFMs) represent a significant advancement inartificial intelligence, combining diverse data modalities to enhance learningand understanding across a wide range of applications. However, thisintegration also brings unique safety and security challenges. In this paper,we conceptualize cybersafety and cybersecurity in the context of multimodallearning and present a comprehensive Systematization of Knowledge (SoK) tounify these concepts in MFMs, identifying key threats to these models. Wepropose a taxonomy framework grounded in information theory, evaluating andcategorizing threats through the concepts of channel capacity, signal, noise,and bandwidth. This approach provides a novel framework that unifies modelsafety and system security in MFMs, offering a more comprehensive andactionable understanding of the risks involved. We used this to exploreexisting defense mechanisms, and identified gaps in current research -particularly, a lack of protection for alignment between modalities and a needfor more systematic defense methods. Our work contributes to a deeperunderstanding of the security and safety landscape in MFMs, providingresearchers and practitioners with valuable insights for improving therobustness and reliability of these models.</description>
      <author>example@mail.com (Ruoxi Sun, Jiamin Chang, Hammond Pearce, Chaowei Xiao, Bo Li, Qi Wu, Surya Nepal, Minhui Xue)</author>
      <guid isPermaLink="false">2411.11195v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable QSPR Modeling using Recursive Feature Machines and Multi-scale Fingerprints</title>
      <link>http://arxiv.org/abs/2411.14079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究首次将递归特征机器（RFM）应用于QSPR建模，并引入量身定制的特征重要性分析方法，以增强可解释性。&lt;h4&gt;目的&lt;/h4&gt;提升分子属性预测的准确性和可解释性，尤其是在溶解度预测方面。&lt;h4&gt;方法&lt;/h4&gt;通过深度特征学习（AGOP）实现RFM的最新成果，利用多种分子表示法，包括MACCS键、Morgan指纹和自定义的多尺度混合指纹（HF）。&lt;h4&gt;主要发现&lt;/h4&gt;HF在揭示分子属性的结构决定因素方面显著优于MACCS和Morgan指纹，RFM能够有效识别驱动分子行为的结构特征，并提供稳健的局部和全局解释。&lt;h4&gt;结论&lt;/h4&gt;RFM展现出强大的冗余过滤能力，模型性能在去除冗余特征后依然稳定，并且AGOP矩阵为内核机器学习带来了可解释的深度特征学习能力。&lt;h4&gt;总结&lt;/h4&gt;实验结果表明，RFM-HF超越了传统机器学习模型和先进的图神经网络，Matern和Laplace内核表现最佳，证明了AGOP在RFM中的灵活性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study pioneers the application of Recursive Feature Machines (RFM) inQSPR modeling, introducing a tailored feature importance analysis approach toenhance interpretability. By leveraging deep feature learning through AGOP, RFMachieves state-of-the-art (SOTA) results in predicting molecular properties, asdemonstrated through solubility prediction across nine benchmark datasets. Tocapture a wide array of structural information, we employ diverse molecularrepresentations, including MACCS keys, Morgan fingerprints, and a custommulti-scale hybrid fingerprint (HF) derived from global descriptors and SMILESlocal fragmentation techniques. Notably, the HF offers significant advantagesover MACCS and Morgan fingerprints in revealing structural determinants ofmolecular properties. The feature importance analysis in RFM provides robustlocal and global explanations, effectively identifying structural features thatdrive molecular behavior and offering valuable insights for drug development.Additionally, RFM demonstrates strong redundancy-filtering abilities, as modelperformance remains stable even after removing redundant features within customfingerprints. Importantly, RFM introduces the deep feature learningcapabilities of the average gradient outer product (AGOP) matrix intoultra-fast kernel machine learning, to imbue kernel machines with interpretabledeep feature learning capabilities. We extend this approach beyond the LaplaceKernel to the Matern, Rational Quadratic, and Gaussian kernels, to find thatthe Matern and Laplace kernels deliver the best performance, thus reinforcingthe flexibility and effectiveness of AGOP in RFM. Experimental results showthat RFM-HF surpasses both traditional machine learning models and advancedgraph neural networks.</description>
      <author>example@mail.com (Jiaxuan Shen, Haitao Zhang, Yunjie Wang, Yilong Wang, Song Tao, Bo Qiu, Ng Shyh-Chang)</author>
      <guid isPermaLink="false">2411.14079v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Parameter Efficient Mamba Tuning via Projector-targeted Diagonal-centric Linear Transformation</title>
      <link>http://arxiv.org/abs/2411.15224v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Mamba架构作为Transformer架构的潜在替代方案，受到越来越多的关注，但针对Mamba的参数高效微调（PEFT）方法尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究针对Mamba架构的PEFT方法，提出有效的策略。&lt;h4&gt;方法&lt;/h4&gt;引入两个基于洞察的策略：1) 发现Projectors在迁移学习中起主要作用，而非SSMs；2) 提出一种新方法ProDiaL，专注于通过近对角线性变换适应预训练的Projectors。&lt;h4&gt;主要发现&lt;/h4&gt;Projector-targeted Diagonal-centric Linear Transformation (ProDiaL)能够仅优化对角线性变换矩阵，未直接微调预训练的Projector权重，且只需使用不到1%的总参数。&lt;h4&gt;结论&lt;/h4&gt;ProDiaL在视觉和语言Mamba模型中表现出强大的性能，显示出其适应任务的高效性和多功能性。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了新的PEFT方法，为Mamba架构在迁移学习中的应用开辟了新方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the growing interest in Mamba architecture as a potential replacementfor Transformer architecture, parameter-efficient fine-tuning (PEFT) approachesfor Mamba remain largely unexplored. In our study, we introduce two keyinsights-driven strategies for PEFT in Mamba architecture: (1) Whilestate-space models (SSMs) have been regarded as the cornerstone of Mambaarchitecture, then expected to play a primary role in transfer learning, ourfindings reveal that Projectors -- not SSMs -- are the predominant contributorsto transfer learning, and (2) Based on our observation that adapting pretrainedProjectors to new tasks can be effectively approximated through a near-diagonallinear transformation, we propose a novel PEFT method specialized to Mambaarchitecture: Projector-targeted Diagonal-centric Linear Transformation(ProDiaL). ProDiaL focuses on optimizing only diagonal-centric lineartransformation matrices, without directly fine-tuning the pretrained Projectorweights. This targeted approach allows efficient task adaptation, utilizingless than 1% of the total parameters, and exhibits strong performance acrossboth vision and language Mamba models, highlighting its versatility andeffectiveness.</description>
      <author>example@mail.com (Seokil Ham, Hee-Seon Kim, Sangmin Woo, Changick Kim)</author>
      <guid isPermaLink="false">2411.15224v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>BIP3D: Bridging 2D Images and 3D Perception for Embodied Intelligence</title>
      <link>http://arxiv.org/abs/2411.14869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在具身智能系统中，3D感知算法是关键组成部分，使智能体能够理解周围环境。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的以图像为中心的3D感知模型BIP3D，以克服点云方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;利用表达性的图像特征和明确的3D位置编码，结合预训练的2D视觉基础模型和空间增强模块，进行多视角、多模态特征融合与端到端3D感知。&lt;h4&gt;主要发现&lt;/h4&gt;BIP3D在EmbodiedScan基准测试中优于当前最先进的成果，在3D检测任务中提高了5.69%，在3D视觉定位任务中提高了15.25%。&lt;h4&gt;结论&lt;/h4&gt;BIP3D通过新的方法显著提升了3D感知的性能，并展示了其在多种任务中的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的BIP3D模型有效解决了传统点云方法的不足，展示了图像中心方法在3D感知中的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In embodied intelligence systems, a key component is 3D perception algorithm,which enables agents to understand their surrounding environments. Previousalgorithms primarily rely on point cloud, which, despite offering precisegeometric information, still constrain perception performance due to inherentsparsity, noise, and data scarcity. In this work, we introduce a novelimage-centric 3D perception model, BIP3D, which leverages expressive imagefeatures with explicit 3D position encoding to overcome the limitations ofpoint-centric methods. Specifically, we leverage pre-trained 2D visionfoundation models to enhance semantic understanding, and introduce a spatialenhancer module to improve spatial understanding. Together, these modulesenable BIP3D to achieve multi-view, multi-modal feature fusion and end-to-end3D perception. In our experiments, BIP3D outperforms current state-of-the-artresults on the EmbodiedScan benchmark, achieving improvements of 5.69% in the3D detection task and 15.25% in the 3D visual grounding task.</description>
      <author>example@mail.com (Xuewu Lin, Tianwei Lin, Lichao Huang, Hongyu Xie, Zhizhong Su)</author>
      <guid isPermaLink="false">2411.14869v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Intensity-Spatial Dual Masked Autoencoder for Multi-Scale Feature Learning in Chest CT Segmentation</title>
      <link>http://arxiv.org/abs/2411.13198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages,6 figures,3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;医学图像分割领域面临模糊病灶特征、边界不清晰和多尺度特性等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种改进的方法，命名为强度-空间双掩码自编码器（ISD-MAE），以提高分割性能。&lt;h4&gt;方法&lt;/h4&gt;在组织对比半掩码自编码器的基础上，引入了一个自编码器分支，对胸部CT图像进行强度掩码和空间掩码操作，实现多尺度特征学习和分割任务。&lt;h4&gt;主要发现&lt;/h4&gt;ISD-MAE在2D肺炎和纵隔肿瘤分割任务中显著优于其他方法，例如在COVID19病灶数据集上的Dice分数达到90.10%，性能相对稳定。&lt;h4&gt;结论&lt;/h4&gt;尽管ISD-MAE在2D数据集表现优异，但在3D数据集上仍有改进空间，建议优化损失函数、使用增强的3D卷积块，以及从多个视角处理数据集。&lt;h4&gt;总结&lt;/h4&gt;ISD-MAE为医学图像分割提供了一种新的有效方法，尤其在挑战性较大的任务中表现突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/prowontheus/isd-mae&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of medical image segmentation, challenges such as indistinctlesion features, ambiguous boundaries,and multi-scale characteristics have longrevailed. This paper proposes an improved method named Intensity-Spatial DualMasked AutoEncoder (ISD-MAE). Based on the tissue-contrast semi-maskedautoencoder, a Masked AutoEncoder (MAE) branch is introduced to performintensity masking and spatial masking operations on chest CT images formulti-scale feature learning and segmentation tasks. The model utilizes adual-branch structure and contrastive learning to enhance the ability to learntissue features and boundary details. Experiments are conducted on multiple 2Dand 3D datasets. The results show that ISD-MAE significantly outperforms othermethods in 2D pneumonia and mediastinal tumor segmentation tasks. For example,the Dice score reaches 90.10% on the COVID19 LESION dataset, and theperformance is relatively stable. However, there is still room for improvementon 3D datasets. In response to this, improvement directions are proposed,including optimizing the loss function, using enhanced 3D convolution blocks,and processing datasets from multiple perspectives.Our code is availableat:https://github.com/prowontheus/ISD-MAE.</description>
      <author>example@mail.com (Yuexing Ding, Jun Wang, Hongbing Lyu)</author>
      <guid isPermaLink="false">2411.13198v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Grid and Road Expressions Are Complementary for Trajectory Representation Learning</title>
      <link>http://arxiv.org/abs/2411.14768v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by KDD2025(August Cycle)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;轨迹表示学习（TRL）将轨迹映射为向量，可用于多种下游任务。现有方法使用网格轨迹或道路轨迹作为输入，分别捕捉自由空间和道路网络中的运动。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的多模态TRL方法，称为GREEN，旨在联合利用网格和道路轨迹表达进行有效的表示学习。&lt;h4&gt;方法&lt;/h4&gt;将原始GPS轨迹转换为网格和道路轨迹，并设计两个编码器以捕捉各自的信息。采用对比损失使两个编码器对相同的原始轨迹产生相似的嵌入，使用掩码语言模型（MLM）损失利用网格轨迹重建被掩盖的道路轨迹。最终通过交叉注意力融合两个编码器的输出。&lt;h4&gt;主要发现&lt;/h4&gt;在与7种最先进TRL方法的比较中，GREEN在3个下游任务中始终优于所有基线，其准确性平均提高了15.99%。&lt;h4&gt;结论&lt;/h4&gt;GREEN方法通过结合网格和道路轨迹的优势，显著提升了轨迹表示学习的效果。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了多模态轨迹表示学习的潜力，为未来的研究提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory representation learning (TRL) maps trajectories to vectors thatcan be used for many downstream tasks. Existing TRL methods use either gridtrajectories, capturing movement in free space, or road trajectories, capturingmovement in a road network, as input. We observe that the two types oftrajectories are complementary, providing either region and locationinformation or providing road structure and movement regularity. Therefore, wepropose a novel multimodal TRL method, dubbed GREEN, to jointly utilize Gridand Road trajectory Expressions for Effective representatioN learning. Inparticular, we transform raw GPS trajectories into both grid and roadtrajectories and tailor two encoders to capture their respective information.To align the two encoders such that they complement each other, we adopt acontrastive loss to encourage them to produce similar embeddings for the sameraw trajectory and design a mask language model (MLM) loss to use gridtrajectories to help reconstruct masked road trajectories. To learn the finaltrajectory representation, a dual-modal interactor is used to fuse the outputsof the two encoders via cross-attention. We compare GREEN with 7state-of-the-art TRL methods for 3 downstream tasks, finding that GREENconsistently outperforms all baselines and improves the accuracy of thebest-performing baseline by an average of 15.99\%.</description>
      <author>example@mail.com (Silin Zhou, Shuo Shang, Lisi Chen, Peng Han, Christian S. Jensen)</author>
      <guid isPermaLink="false">2411.14768v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Med-PerSAM: One-Shot Visual Prompt Tuning for Personalized Segment Anything Model in Medical Domain</title>
      <link>http://arxiv.org/abs/2411.16123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;利用预训练模型和定制提示进行上下文学习在自然语言处理任务中已被证明非常有效。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的简单单样本框架Med-PerSAM，旨在解决医疗领域中使用Segment Anything Model (SAM)的局限性。&lt;h4&gt;方法&lt;/h4&gt;Med-PerSAM仅使用视觉提示工程，消除了对预训练SAM的额外训练和人工干预的需求，采用自动化提示生成过程。&lt;h4&gt;主要发现&lt;/h4&gt;通过将轻量化的基于变形的提示调优模型与SAM结合，Med-PerSAM能够提取和迭代优化视觉提示，提升预训练SAM的性能。&lt;h4&gt;结论&lt;/h4&gt;该模型在各种2D医学影像数据集上 outperform 了多种基础模型和以往的SAM方法，尤其在医疗领域具有重要意义。&lt;h4&gt;总结&lt;/h4&gt;Med-PerSAM有效解决了医疗领域视觉提示生成的挑战，提升了相关模型在医学图像处理中的应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging pre-trained models with tailored prompts for in-context learninghas proven highly effective in NLP tasks. Building on this success, recentstudies have applied a similar approach to the Segment Anything Model (SAM)within a ``one-shot" framework, where only a single reference image and itslabel are employed. However, these methods face limitations in the medicaldomain, primarily due to SAM's essential requirement for visual prompts and theover-reliance on pixel similarity for generating them. This dependency may leadto (1) inaccurate prompt generation and (2) clustering of point prompts,resulting in suboptimal outcomes. To address these challenges, we introduce\textbf{Med-PerSAM}, a novel and straightforward one-shot framework designedfor the medical domain. Med-PerSAM uses only visual prompt engineering andeliminates the need for additional training of the pretrained SAM or humanintervention, owing to our novel automated prompt generation process. Byintegrating our lightweight warping-based prompt tuning model with SAM, weenable the extraction and iterative refinement of visual prompts, enhancing theperformance of the pre-trained SAM. This advancement is particularly meaningfulin the medical domain, where creating visual prompts poses notable challengesfor individuals lacking medical expertise. Our model outperforms variousfoundational models and previous SAM-based approaches across diverse 2D medicalimaging datasets.</description>
      <author>example@mail.com (Hangyul Yoon, Doohyuk Jang, Jungeun Kim, Eunho Yang)</author>
      <guid isPermaLink="false">2411.16123v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Steam Turbine Anomaly Detection: An Unsupervised Learning Approach Using Enhanced Long Short-Term Memory Variational Autoencoder</title>
      <link>http://arxiv.org/abs/2411.10765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;蒸汽涡轮作为核心热电发电设备，面临停机、维护和损坏等中断，导致显著的费用和运营不利影响。&lt;h4&gt;目的&lt;/h4&gt;确保蒸汽涡轮的安全和稳定运行，准确进行异常检测。&lt;h4&gt;方法&lt;/h4&gt;提出一种增强型长短期记忆变分自编码器（ELSTMVAE-DAF-GMM），结合深度高级特征和高斯混合模型，用于无标签数据的精确无监督异常检测。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用LSTMVAE将高维时间序列数据投影到低维相空间，结合DAE-LOF机制消除内在异常，从而提高模型的精度和可靠性。&lt;h4&gt;结论&lt;/h4&gt;使用真实工业蒸汽涡轮的操作数据进行对比和消融实验，结果显示该方法在异常检测方面具有高准确率和低误报率，优于现有方法。&lt;h4&gt;总结&lt;/h4&gt;该研究为蒸汽涡轮的异常检测提供了一种有效的无监督学习方法，显著提升了检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As core thermal power generation equipment, steam turbines incur significantexpenses and adverse effects on operation when facing interruptions likedowntime, maintenance, and damage. Accurate anomaly detection is theprerequisite for ensuring the safe and stable operation of steam turbines.However, challenges in steam turbine anomaly detection, including inherentanomalies, lack of temporal information analysis, and high-dimensional datacomplexity, limit the effectiveness of existing methods. To address thesechallenges, we proposed an Enhanced Long Short-Term Memory VariationalAutoencoder using Deep Advanced Features and Gaussian Mixture Model(ELSTMVAE-DAF-GMM) for precise unsupervised anomaly detection in unlabeleddatasets. Specifically, LSTMVAE, integrating LSTM with VAE, was used to projecthigh-dimensional time-series data to a low-dimensional phase space. The DeepAutoencoder-Local Outlier Factor (DAE-LOF) sample selection mechanism was usedto eliminate inherent anomalies during training, further improving the model'sprecision and reliability. The novel deep advanced features (DAF) hybridizelatent embeddings and reconstruction discrepancies from the LSTMVAE model andprovide a more comprehensive data representation within a continuous andstructured phase space, significantly enhancing anomaly detection bysynergizing temporal dynamics with data pattern variations. These DAF wereincorporated into GMM to ensure robust and effective unsupervised anomalydetection. We utilized real operating data from industry steam turbines andconducted both comparison and ablation experiments, demonstrating superioranomaly detection outcomes characterized by high accuracy and minimal falsealarm rates compared with existing methods.</description>
      <author>example@mail.com (Weiming Xu, Peng Zhang)</author>
      <guid isPermaLink="false">2411.10765v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MMBind: Unleashing the Potential of Distributed and Heterogeneous Data for Multimodal Learning in IoT</title>
      <link>http://arxiv.org/abs/2411.12126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态感知系统在各种现实应用中日益普遍，但大多数现有的多模态学习方法依赖于大量完整的多模态数据训练，这在物联网感知应用中并不现实。&lt;h4&gt;目的&lt;/h4&gt;提出MMBind框架，以支持在分布式和异构物联网数据上进行多模态学习。&lt;h4&gt;方法&lt;/h4&gt;通过将来自不同来源和不完整模态的数据绑定到一个具有充分描述性的共享模态上，构建伪配对的多模态数据集进行模型训练。&lt;h4&gt;主要发现&lt;/h4&gt;不同模态的数据即使在不同时间和地点捕获，只要观察到相似事件，仍然可以有效用于多模态训练。&lt;h4&gt;结论&lt;/h4&gt;MMBind在处理数据不完整性和领域迁移时，优于现有的基线方法，显示出在物联网应用中推进多模态基础模型训练的潜力。&lt;h4&gt;总结&lt;/h4&gt;MMBind框架为异构物联网数据的多模态学习提供了新的思路，能够有效应对数据收集的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal sensing systems are increasingly prevalent in various real-worldapplications. Most existing multimodal learning approaches heavily rely ontraining with a large amount of complete multimodal data. However, such asetting is impractical in real-world IoT sensing applications where data istypically collected by distributed nodes with heterogeneous data modalities,and is also rarely labeled. In this paper, we propose MMBind, a new frameworkfor multimodal learning on distributed and heterogeneous IoT data. The key ideaof MMBind is to construct a pseudo-paired multimodal dataset for model trainingby binding data from disparate sources and incomplete modalities through asufficiently descriptive shared modality. We demonstrate that data of differentmodalities observing similar events, even captured at different times andlocations, can be effectively used for multimodal training. Moreover, wepropose an adaptive multimodal learning architecture capable of training modelswith heterogeneous modality combinations, coupled with a weighted contrastivelearning approach to handle domain shifts among disparate data. Evaluations onten real-world multimodal datasets highlight that MMBind outperformsstate-of-the-art baselines under varying data incompleteness and domain shift,and holds promise for advancing multimodal foundation model training in IoTapplications.</description>
      <author>example@mail.com (Xiaomin Ouyang, Jason Wu, Tomoyoshi Kimura, Yihan Lin, Gunjan Verma, Tarek Abdelzaher, Mani Srivastava)</author>
      <guid isPermaLink="false">2411.12126v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>GNN-MultiFix: Addressing the pitfalls for GNNs for multi-label node classification</title>
      <link>http://arxiv.org/abs/2411.14094v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在图数据表示学习方面表现出色，广泛应用于多项任务。&lt;h4&gt;目的&lt;/h4&gt;批判性分析GNN在节点分类任务中的表现，特别是在多标签节点分类的场景下。&lt;h4&gt;方法&lt;/h4&gt;深入研究多标签节点分类，分析GNN方法的训练动态，提出GNN-MultiFix方法，整合节点的特征、标签和位置信息。&lt;h4&gt;主要发现&lt;/h4&gt;GNN在多标签图数据集上学习效果不佳，即使在训练数据丰富的情况下；在缺乏节点属性和显式标签信息时，最具表现力的GNN也可能无法学习。&lt;h4&gt;结论&lt;/h4&gt;GNN-MultiFix方法在所有多标签数据集上显著提高了性能。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了GNN在多标签节点分类中的局限性，并提出了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have emerged as powerful models for learningrepresentations of graph data showing state of the art results in varioustasks. Nevertheless, the superiority of these methods is usually supported byeither evaluating their performance on small subset of benchmark datasets or byreasoning about their expressive power in terms of certain graph isomorphismtests. In this paper we critically analyse both these aspects through atransductive setting for the task of node classification. First, we delvedeeper into the case of multi-label node classification which offers a morerealistic scenario and has been ignored in most of the related works. Throughanalysing the training dynamics for GNN methods we highlight the failure ofGNNs to learn over multi-label graph datasets even for the case of abundanttraining data. Second, we show that specifically for transductive nodeclassification, even the most expressive GNN may fail to learn in absence ofnode attributes and without using explicit label information as input. Toovercome this deficit, we propose a straightforward approach, referred to asGNN-MultiFix, that integrates the feature, label, and positional information ofa node. GNN-MultiFix demonstrates significant improvement across all themulti-label datasets. We release our code athttps://anonymous.4open.science/r/Graph-MultiFix-4121.</description>
      <author>example@mail.com (Tianqi Zhao, Megha Khosla)</author>
      <guid isPermaLink="false">2411.14094v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Regression for Socio-Economic Estimation via Multi-View Remote Sensing</title>
      <link>http://arxiv.org/abs/2411.14119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;遥感影像提供了丰富的光谱数据，可以用于地球观测，但现有研究主要集中在白天的卫星影像上。&lt;h4&gt;目的&lt;/h4&gt;利用遥感数据和迁移学习开发可扩展的方法，减少对昂贵调查数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;引入新框架，结合三种光谱波段处理遥感影像，并采用异方差回归和贝叶斯建模生成预测的不确定性估计。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在性能上优于现有的RGB或多光谱模型，并能够识别不确定的预测。&lt;h4&gt;结论&lt;/h4&gt;新框架有助于指导未来的地面真实数据采集，提高数据收集的针对性和有效性。&lt;h4&gt;总结&lt;/h4&gt;本文提出的框架有效利用多光谱数据，同时考虑不确定性，为遥感回归提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lukeyf/multiview_remote_sensing&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote sensing imagery offers rich spectral data across extensive areas forEarth observation. Many attempts have been made to leverage these data withtransfer learning to develop scalable alternatives for estimatingsocio-economic conditions, reducing reliance on expensive survey-collecteddata. However, much of this research has primarily focused on daytime satelliteimagery due to the limitation that most pre-trained models are trained on3-band RGB images. Consequently, modeling techniques for spectral bands beyondthe visible spectrum have not been thoroughly investigated. Additionally,quantifying uncertainty in remote sensing regression has been less explored,yet it is essential for more informed targeting and iterative collection ofground truth survey data. In this paper, we introduce a novel framework thatleverages generic foundational vision models to process remote sensing imageryusing combinations of three spectral bands to exploit multi-spectral data. Wealso employ methods such as heteroscedastic regression and Bayesian modeling togenerate uncertainty estimates for the predictions. Experimental resultsdemonstrate that our method outperforms existing models that use RGB ormulti-spectral models with unstructured band usage. Moreover, our frameworkhelps identify uncertain predictions, guiding future ground truth dataacquisition.</description>
      <author>example@mail.com (Fan Yang, Sahoko Ishida, Mengyan Zhang, Daniel Jenson, Swapnil Mishra, Jhonathan Navott, Seth Flaxman)</author>
      <guid isPermaLink="false">2411.14119v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Night-to-Day Translation via Illumination Degradation Disentanglement</title>
      <link>http://arxiv.org/abs/2411.14504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;夜间场景的视觉效果提升在计算机视觉中具有重要意义，但在未配对条件下处理夜间图像的复杂退化仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出N2D3方法，以实现夜间图像的日间视觉效果。&lt;h4&gt;方法&lt;/h4&gt;N2D3包括退化解耦模块和基于退化的对比学习模块，利用Kubelka-Munk理论提取物理先验，并通过这些先验来区分不同的光照退化区域。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公共数据集上的评估显示，该方法在视觉质量上有显著改善，并对后续任务具有潜在的积极影响。&lt;h4&gt;结论&lt;/h4&gt;N2D3方法有效地恢复了日间域信息，同时保持了语义一致性，展示了其在处理夜间图像中的优势。&lt;h4&gt;总结&lt;/h4&gt;通过退化解耦和对比学习策略，N2D3显著提升了夜间场景的视觉效果，具有广泛应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Night-to-Day translation (Night2Day) aims to achieve day-like vision fornighttime scenes. However, processing night images with complex degradationsremains a significant challenge under unpaired conditions. Previous methodsthat uniformly mitigate these degradations have proven inadequate insimultaneously restoring daytime domain information and preserving underlyingsemantics. In this paper, we propose \textbf{N2D3}(\textbf{N}ight-to-\textbf{D}ay via \textbf{D}egradation\textbf{D}isentanglement) to identify different degradation patterns innighttime images. Specifically, our method comprises a degradationdisentanglement module and a degradation-aware contrastive learning module.Firstly, we extract physical priors from a photometric model based onKubelka-Munk theory. Then, guided by these physical priors, we design adisentanglement module to discriminate among different illumination degradationregions. Finally, we introduce the degradation-aware contrastive learningstrategy to preserve semantic consistency across distinct degradation regions.Our method is evaluated on two public datasets, demonstrating a significantimprovement in visual quality and considerable potential for benefitingdownstream tasks.</description>
      <author>example@mail.com (Guanzhou Lan, Yuqi Yang, Zhigang Wang, Dong Wang, Bin Zhao, Xuelong Li)</author>
      <guid isPermaLink="false">2411.14504v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Boundless Across Domains: A New Paradigm of Adaptive Feature and Cross-Attention for Domain Generalization in Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2411.14883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;领域不变表示学习是一种强大的领域泛化方法，但以往方法面临高计算需求、训练不稳定和对高维数据的有限有效性等挑战，可能导致有价值特征的损失。&lt;h4&gt;目的&lt;/h4&gt;提出一种理想的广义表示，能够在跨域图像的同一通道内展现相似的模式响应。&lt;h4&gt;方法&lt;/h4&gt;利用源域的深度特征作为查询，生成域的深度特征作为键和值，通过跨通道注意力机制重构原始深度特征为稳健的正则化表示，并引导模型学习领域不变表示。同时，提出自适应特征混合（AFB）方法，以生成超出原分布的样本，扩展领域范围。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提方法在两个标准的医学图像分割领域泛化基准上表现优越。&lt;h4&gt;结论&lt;/h4&gt;通过提出的跨通道注意力机制和自适应特征混合方法，可以有效提升领域泛化性能，克服现有方法的局限性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的新方法在领域不变表示学习中展示了显著的效果，推动了医学图像分割的领域泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain-invariant representation learning is a powerful method for domaingeneralization. Previous approaches face challenges such as high computationaldemands, training instability, and limited effectiveness with high-dimensionaldata, potentially leading to the loss of valuable features. To address theseissues, we hypothesize that an ideal generalized representation should exhibitsimilar pattern responses within the same channel across cross-domain images.Based on this hypothesis, we use deep features from the source domain asqueries, and deep features from the generated domain as keys and values.Through a cross-channel attention mechanism, the original deep features arereconstructed into robust regularization representations, forming an explicitconstraint that guides the model to learn domain-invariant representations.Additionally, style augmentation is another common method. However, existingmethods typically generate new styles through convex combinations of sourcedomains, which limits the diversity of training samples by confining thegenerated styles to the original distribution. To overcome this limitation, wepropose an Adaptive Feature Blending (AFB) method that generatesout-of-distribution samples while exploring the in-distribution space,significantly expanding the domain range. Extensive experimental resultsdemonstrate that our proposed methods achieve superior performance on twostandard domain generalization benchmarks for medical image segmentation.</description>
      <author>example@mail.com (Yuheng Xu, Taiping Zhang)</author>
      <guid isPermaLink="false">2411.14883v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Task Vectors: Selective Task Arithmetic Based on Importance Metrics</title>
      <link>http://arxiv.org/abs/2411.16139v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预训练模型通过利用大规模预学习知识表示，显著提升了深度学习在多种任务上的性能，但在实际的多任务学习场景中，部署这些模型面临高计算成本和推理效率低下的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为选择性任务算术（STA）的训练无关框架，以通过任务特定的参数融合来增强多任务性能。&lt;h4&gt;方法&lt;/h4&gt;STA通过以下三方面应对挑战：1) 使用基于一阶泰勒展开的损失敏感参数重要性度量，准确评估每个任务关键参数的重要性；2) 通过参数重要性度量增强任务向量的稀疏性，减少对超参数调优的依赖；3) 利用参数重要性度量实现更精确的任务遗忘，控制并有效地处理任务遗忘中的噪声元素。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STA在各基准测试中实现了卓越的多任务性能，并在任务遗忘方面表现优异。&lt;h4&gt;结论&lt;/h4&gt;STA有效提升了多任务学习的能力，解决了传统方法未能充分应对的多任务环境复杂性问题。&lt;h4&gt;总结&lt;/h4&gt;选择性任务算术（STA）通过任务特定参数融合，克服了多任务学习中的多重挑战，展示了其在多任务性能和任务遗忘方面的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretrained models have revolutionized deep learning by enabling significantperformance improvements across a wide range of tasks, leveraging large-scale,pre-learned knowledge representations. However, deploying these models inreal-world multi-task learning (MTL) scenarios poses substantial challenges,primarily due to high computational costs and inefficiencies in inference.Traditional approaches such as pruning, quantization, and knowledgedistillation have been explored to mitigate these issues, but they often fallshort in fully addressing the complexities of multi-task environments. Thispaper introduces \textbf{\underline{S}}elective \textbf{\underline{T}}ask\textbf{\underline{A}}rithmetic \underline{\textbf{(STA)}}, a training-freeframework designed to enhance multi-task performance through task-specificparameter fusion. STA addresses three key challenges: (i) \textbf{Parameterimportance diversity: } Recognizing that different tasks relie on distinctparameters, STA employs a loss-sensitive parameter importance metric derivedfrom a first-order Taylor expansion to accurately measure the importance ofparameters for each task. (ii) \textbf{Over-reliance on hyperparameter tuning:}By enhancing the sparsity of task vectors through parameter importancemetrics, STA reduces the need for extensive hyperparameter tuning, therebyimproving the generalization and robustness of the model. (iii) \textbf{Neglectof other abilities in task arithmetic: } Previous works have largely overlookedthe potential for more precise task forgetting. STA leverages its parameterimportance metric to achieve more controlled and effective task forgetting,minimizing the impact of noisy elements that can degrade model performance.Experimental results demonstrate that STA achieves superior multi-taskperformance across benchmarks and excellent performance in task forgetting.</description>
      <author>example@mail.com (Tian Bowen, Lai Songning, Wu Jiemin, Shuai Zhihao, Ge Shiming, Yue Yutao)</author>
      <guid isPermaLink="false">2411.16139v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Hybrid Data-Driven SSM for Interpretable and Label-Free mmWave Channel Prediction</title>
      <link>http://arxiv.org/abs/2411.11576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高用户移动性导致的信道老化问题，使得准确预测毫米波时变信道至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的混合方法，以解决现有信道预测方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;将数据驱动的神经网络与基于状态空间模型的传统模型相结合，采用无监督学习策略，仅使用未标记数据训练嵌入的神经网络。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法在数值仿真中显示出优于传统模型和数据驱动方法的预测准确性。&lt;h4&gt;结论&lt;/h4&gt;新方法在面对严重信道变化和高噪声水平等挑战因素时，表现出强大的鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;本文提出的混合方法能够有效跟踪复杂的信道动态，且不需要精确的专家知识，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of mmWave time-varying channels is essential formitigating the issue of channel aging in complex scenarios owing to high usermobility. Existing channel prediction methods have limitations: classicalmodel-based methods often struggle to track highly nonlinear channel dynamicsdue to limited expert knowledge, while emerging data-driven methods typicallyrequire substantial labeled data for effective training and often lackinterpretability. To address these issues, this paper proposes a novel hybridmethod that integrates a data-driven neural network into a conventionalmodel-based workflow based on a state-space model (SSM), implicitly trackingcomplex channel dynamics from data without requiring precise expert knowledge.Additionally, a novel unsupervised learning strategy is developed to train theembedded neural network solely with unlabeled data. Theoretical analyses andablation studies are conducted to interpret the enhanced benefits gained fromthe hybrid integration. Numerical simulations based on the 3GPP mmWave channelmodel corroborate the superior prediction accuracy of the proposed method,compared to state-of-the-art methods that are either purely model-based ordata-driven. Furthermore, extensive experiments validate its robustness againstvarious challenging factors, including among others severe channel variationsand high noise levels.</description>
      <author>example@mail.com (Yiyong Sun, Jiajun He, Zhidi Lin, Wenqiang Pu, Feng Yin, Hing Cheung So)</author>
      <guid isPermaLink="false">2411.11576v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Partial Multi-View Clustering via Meta-Learning and Contrastive Feature Alignment</title>
      <link>http://arxiv.org/abs/2411.09758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;部分多视图聚类（PVC）在现实应用中的数据分析面临重大挑战，尤其是当数据的某些视图部分缺失时。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的双重优化框架，基于对比学习，旨在最大化不完整多视图数据中潜在特征的一致性，提升聚类性能。&lt;h4&gt;方法&lt;/h4&gt;结合精细调整的视觉变换器（Vision Transformer）和k近邻（KNN），通过自监督学习和元学习填补缺失视图并动态调整视图权重。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在BDGP和HW数据集上的聚类性能优于当前最先进的聚类模型，尤其是在处理复杂和不完整的多视图数据时。&lt;h4&gt;结论&lt;/h4&gt;该方法显著提高了在不完整多视图数据上的聚类效果，展现出良好的实用性和有效性。&lt;h4&gt;总结&lt;/h4&gt;通过对比学习优化潜在特征一致性，该研究为部分多视图聚类提供了有效的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Partial multi-view clustering (PVC) presents significant challenges practicalresearch problem for data analysis in real-world applications, especially whensome views of the data are partially missing. Existing clustering methodsstruggle to handle incomplete views effectively, leading to suboptimalclustering performance. In this paper, we propose a novel dual optimizationframework based on contrastive learning, which aims to maximize the consistencyof latent features in incomplete multi-view data and improve clusteringperformance through deep learning models. By combining a fine-tuned VisionTransformer and k-nearest neighbors (KNN), we fill in missing views anddynamically adjust view weights using self-supervised learning andmeta-learning. Experimental results demonstrate that our framework outperformsstate-of-the-art clustering models on the BDGP and HW datasets, particularly inhandling complex and incomplete multi-view data.</description>
      <author>example@mail.com (BoHao Chen)</author>
      <guid isPermaLink="false">2411.09758v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal 3D Reasoning Segmentation with Complex Scenes</title>
      <link>http://arxiv.org/abs/2411.13927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态学习的发展推动了3D场景理解的研究，尤其是在体感人工智能等实际任务中。&lt;h4&gt;目的&lt;/h4&gt;提出一个3D推理分割任务，以解决现有研究中对于人类意图的互动和解释能力不足的问题，以及对单类物体场景的过度简化描述。&lt;h4&gt;方法&lt;/h4&gt;创建ReasonSeg3D，一个整合3D空间关系、问答对和3D分割掩码的大规模高质量基准，并设计MORE3D，一种简单有效的多物体3D推理分割方法。&lt;h4&gt;主要发现&lt;/h4&gt;MORE3D在复杂多物体3D场景的推理和分割方面表现优异，ReasonSeg3D为未来3D推理分割的探索提供了有价值的平台。&lt;h4&gt;结论&lt;/h4&gt;研究成果将推动多物体3D场景的理解，数据集和代码将被发布以供大家使用。&lt;h4&gt;总结&lt;/h4&gt;本研究通过引入新的任务和方法，填补了3D场景理解中的研究空白，促进了多模态学习领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent development in multimodal learning has greatly advanced theresearch in 3D scene understanding in various real-world tasks such as embodiedAI. However, most existing work shares two typical constraints: 1) they areshort of reasoning ability for interaction and interpretation of humanintension and 2) they focus on scenarios with single-category objects onlywhich leads to over-simplified textual descriptions due to the negligence ofmulti-object scenarios and spatial relations among objects. We bridge theresearch gaps by proposing a 3D reasoning segmentation task for multipleobjects in scenes. The task allows producing 3D segmentation masks and detailedtextual explanations as enriched by 3D spatial relations among objects. To thisend, we create ReasonSeg3D, a large-scale and high-quality benchmark thatintegrates 3D spatial relations with generated question-answer pairs and 3Dsegmentation masks. In addition, we design MORE3D, a simple yet effectivemethod that enables multi-object 3D reasoning segmentation with user questionsand textual outputs. Extensive experiments show that MORE3D excels in reasoningand segmenting complex multi-object 3D scenes, and the created ReasonSeg3Doffers a valuable platform for future exploration of 3D reasoning segmentation.The dataset and code will be released.</description>
      <author>example@mail.com (Xueying Jiang, Lewei Lu, Ling Shao, Shijian Lu)</author>
      <guid isPermaLink="false">2411.13927v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>BERT-Based Approach for Automating Course Articulation Matrix Construction with Explainable AI</title>
      <link>http://arxiv.org/abs/2411.14254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;课程成果(CO)与项目成果(PO)/项目特定成果(PSO)的对齐是确保课程一致性和评估教育有效性的关键任务。&lt;h4&gt;目的&lt;/h4&gt;构建课程对接矩阵(CAM)，量化CO与PO/PSO之间的关系。&lt;h4&gt;方法&lt;/h4&gt;实验四种BERT家族模型（BERT Base, DistilBERT, ALBERT, RoBERTa），使用多类分类进行CO与PO/PSO配对的对齐评估，同时评估传统机器学习分类器的表现，并应用可解释人工智能技术LIME提升模型可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;系统的准确率、精确率、召回率和F1分数分别达到了98.66%。&lt;h4&gt;结论&lt;/h4&gt;利用基于BERT的模型进行转移学习，能够高效自动生成CAM，提供高性能和可解释性用于教育成果评估。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了转移学习与BERT模型结合在教育成果评估中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/natenaile/bert-based-approach-for-automating-course-articulation-matrix-construction-with-explainable-ai&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Course Outcome (CO) and Program Outcome (PO)/Program-Specific Outcome (PSO)alignment is a crucial task for ensuring curriculum coherence and assessingeducational effectiveness. The construction of a Course Articulation Matrix(CAM), which quantifies the relationship between COs and POs/PSOs, typicallyinvolves assigning numerical values (0, 1, 2, 3) to represent the degree ofalignment. In this study, We experiment with four models from the BERT family:BERT Base, DistilBERT, ALBERT, and RoBERTa, and use multiclass classificationto assess the alignment between CO and PO/PSO pairs. We first evaluatetraditional machine learning classifiers, such as Decision Tree, Random Forest,and XGBoost, and then apply transfer learning to evaluate the performance ofthe pretrained BERT models. To enhance model interpretability, we applyExplainable AI technique, specifically Local Interpretable Model-agnosticExplanations (LIME), to provide transparency into the decision-making process.Our system achieves accuracy, precision, recall, and F1-score values of 98.66%,98.67%, 98.66%, and 98.66%, respectively. This work demonstrates the potentialof utilizing transfer learning with BERT-based models for the automatedgeneration of CAMs, offering high performance and interpretability ineducational outcome assessment.</description>
      <author>example@mail.com (Natenaile Asmamaw Shiferaw, Simpenzwe Honore Leandre, Aman Sinha, Dillip Rout)</author>
      <guid isPermaLink="false">2411.14254v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Predicting rigidity and connectivity percolation in disordered particulate networks using graph neural networks</title>
      <link>http://arxiv.org/abs/2411.14159v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figure files plus a supplementary material PDF&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络能够准确预测许多分子系统的化学性质，但其在大规模大分子组装（如胶体）中的适用性尚不明确。&lt;h4&gt;目的&lt;/h4&gt;探究图神经网络在大规模分类问题中的应用，特别是分子网络的刚性和连接渗流状态。&lt;h4&gt;方法&lt;/h4&gt;对两种大规模分类问题进行训练和优化，包括分子网络的刚性分类和连接渗流状态的判断。&lt;h4&gt;主要发现&lt;/h4&gt;在晶格系统上训练的模型在刚性分类中准确率超过95%，而连接渗流由于数据的不平衡性准确率略低。动态生成的非晶格网络整体准确率较低，原因是网络几何的相关性在晶格中不存在。&lt;h4&gt;结论&lt;/h4&gt;提供了一个开源工具，允许使用表现最佳的训练模型，并讨论了未来改进工具的方向，以克服某些情况下的准确性限制。&lt;h4&gt;总结&lt;/h4&gt;图神经网络在大规模分子系统的应用表现出良好的潜力，但仍需解决数据不平衡和网络几何相关性等挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks can accurately predict the chemical properties of manymolecular systems, but their suitability for large, macromolecular assembliessuch as gels is unknown. Here, graph neural networks were trained and optimisedfor two large-scale classification problems: the rigidity of a molecularnetwork, and the connectivity percolation status which is non-trivial todetermine for systems with periodic boundaries. Models trained on latticesystems were found to achieve accuracies &gt;95% for rigidity classification, withslightly lower scores for connectivity percolation due to the inherent classimbalance in the data. Dynamically generated off-lattice networks achievedconsistently lower accuracies overall due to the correlated nature of thenetwork geometry that was absent in the lattices. An open source tool isprovided allowing usage of the highest-scoring trained models, and directionsfor future improved tools to surmount the challenges limiting accuracy incertain situations are discussed.</description>
      <author>example@mail.com (D. A. Head)</author>
      <guid isPermaLink="false">2411.14159v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification</title>
      <link>http://arxiv.org/abs/2411.14252v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成大规模、特定领域的多语言多轮对话数据集是训练有效的多轮意图分类模型的一大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出Chain-of-Intent机制，以生成上下文感知的意图驱动对话。&lt;h4&gt;方法&lt;/h4&gt;结合隐马尔可夫模型和大型语言模型，通过自我对弈提取电子商务聊天记录中的领域知识，估计对话轮次和意图转移。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在对话质量和意图分类准确性方面优于基线，特别是在多语言设置中，且显著减少了数据生成工作量。&lt;h4&gt;结论&lt;/h4&gt;提出的MINT-CL框架通过多任务对比学习提高了分类准确性，无需大量标注数据，并发布了多语言意图感知的多轮电子商务对话语料库MINT-E以支持后续研究。&lt;h4&gt;总结&lt;/h4&gt;Chain-of-Intent机制和MINT-CL框架为多轮意图分类提供了有效的解决方案，推动了电子商务对话系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating large-scale, domain-specific, multilingual multi-turn dialoguedatasets remains a significant hurdle for training effective Multi-Turn IntentClassification models in chatbot systems. In this paper, we introduceChain-of-Intent, a novel mechanism that combines Hidden Markov Models withLarge Language Models (LLMs) to generate contextually aware, intent-drivenconversations through self-play. By extracting domain-specific knowledge frome-commerce chat logs, we estimate conversation turns and intent transitions,which guide the generation of coherent dialogues. Leveraging LLMs to enhanceemission probabilities, our approach produces natural and contextuallyconsistent questions and answers. We also propose MINT-CL, a framework formulti-turn intent classification using multi-task contrastive learning,improving classification accuracy without the need for extensive annotateddata. Evaluations show that our methods outperform baselines in dialoguequality and intent classification accuracy, especially in multilingualsettings, while significantly reducing data generation efforts. Furthermore, werelease MINT-E, a multilingual, intent-aware multi-turn e-commerce dialoguecorpus to support future research in this area.</description>
      <author>example@mail.com (Junhua Liu, Yong Keat Tan, Bin Fu, Kwan Hui Lim)</author>
      <guid isPermaLink="false">2411.14252v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>RankByGene: Gene-Guided Histopathology Representation Learning Through Cross-Modal Ranking Consistency</title>
      <link>http://arxiv.org/abs/2411.15076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;空间转录组学(ST)通过在组织内映射基因表达提供重要的空间背景，便于研究细胞异质性和组织结构。&lt;h4&gt;目的&lt;/h4&gt;解决空间转录组数据与组织学图像对齐的挑战，克服空间畸变和模态特异性变异的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新框架，使用基于排名的对齐损失来对齐基因和图像特征，保持跨模态的相对相似性，并实现稳健的多尺度对齐，同时采用自监督知识蒸馏技术以增强对齐的稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;通过在基因表达预测和生存分析中的广泛实验，证明了该框架的有效性，相比现有方法显示出更好的对齐和预测性能。&lt;h4&gt;结论&lt;/h4&gt;该框架为数字病理学中的基因引导图像表示学习提供了一个稳健的工具。&lt;h4&gt;总结&lt;/h4&gt;提出的框架解决了空间转录组与组织学图像对齐的问题，提升了对齐精度和预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics (ST) provides essential spatial context by mappinggene expression within tissue, enabling detailed study of cellularheterogeneity and tissue organization. However, aligning ST data with histologyimages poses challenges due to inherent spatial distortions andmodality-specific variations. Existing methods largely rely on directalignment, which often fails to capture complex cross-modal relationships. Toaddress these limitations, we propose a novel framework that aligns gene andimage features using a ranking-based alignment loss, preserving relativesimilarity across modalities and enabling robust multi-scale alignment. Tofurther enhance the alignment's stability, we employ self-supervised knowledgedistillation with a teacher-student network architecture, effectivelymitigating disruptions from high dimensionality, sparsity, and noise in geneexpression data. Extensive experiments on gene expression prediction andsurvival analysis demonstrate our framework's effectiveness, showing improvedalignment and predictive performance over existing methods and establishing arobust tool for gene-guided image representation learning in digital pathology.</description>
      <author>example@mail.com (Wentao Huang, Meilong Xu, Xiaoling Hu, Shahira Abousamra, Aniruddha Ganguly, Saarthak Kapse, Alisa Yurovsky, Prateek Prasanna, Tahsin Kurc, Joel Saltz, Michael L. Miller, Chao Chen)</author>
      <guid isPermaLink="false">2411.15076v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI for Music and Audio</title>
      <link>http://arxiv.org/abs/2411.14627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD Dissertation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成性人工智能正在改变我们与技术互动和消费内容的方式。&lt;h4&gt;目的&lt;/h4&gt;研究生成性人工智能在音乐和音频创作中的应用，降低音乐创作的门槛，推动音频内容的民主化。&lt;h4&gt;方法&lt;/h4&gt;研究主要集中在三个方向：1) 多轨音乐生成，2) 辅助音乐创作工具，3) 音频与音乐的多模态学习。&lt;h4&gt;主要发现&lt;/h4&gt;AI可以帮助专业人士和业余爱好者创作音乐和音频内容，并且AI能够以类似人类的方式学习创作音乐。&lt;h4&gt;结论&lt;/h4&gt;生成性AI有潜力重新构建音频内容创作的方式，推动更广泛的参与。&lt;h4&gt;总结&lt;/h4&gt;本研究探索了生成性AI在音乐创作中的应用，旨在实现更广泛的音频内容创作参与。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative AI has been transforming the way we interact with technology andconsume content. In the next decade, AI technology will reshape how we createaudio content in various media, including music, theater, films, games,podcasts, and short videos. In this dissertation, I introduce the three maindirections of my research centered around generative AI for music and audio: 1)multitrack music generation, 2) assistive music creation tools, and 3)multimodal learning for audio and music. Through my research, I aim to answerthe following two fundamental questions: 1) How can AI help professionals oramateurs create music and audio content? 2) Can AI learn to create music in away similar to how humans learn music? My long-term goal is to lower thebarrier of entry for music composition and democratize audio content creation</description>
      <author>example@mail.com (Hao-Wen Dong)</author>
      <guid isPermaLink="false">2411.14627v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Unlocking Transfer Learning for Open-World Few-Shot Recognition</title>
      <link>http://arxiv.org/abs/2411.09986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;少样本开放集识别（FSOSR）旨在将输入分类为已知类别，同时识别超出这些类别的开放集输入。&lt;h4&gt;目的&lt;/h4&gt;解决转移学习在开放世界中的应用不足的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种两阶段方法，包括开放集感知的元学习和开放集无关的转移学习。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在miniImageNet和tieredImageNet两个基准上实现了最先进的性能，训练努力仅增加了1.5%。&lt;h4&gt;结论&lt;/h4&gt;转移学习在少样本开放集识别中的有效性得到了验证。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的两阶段方法为FSOSR提供了新的解决方案，显示出良好的性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-Shot Open-Set Recognition (FSOSR) targets a critical real-worldchallenge, aiming to categorize inputs into known categories, termed closed-setclasses, while identifying open-set inputs that fall outside these classes.Although transfer learning where a model is tuned to a given few-shot task hasbecome a prominent paradigm in closed-world, we observe that it fails to expandto open-world. To unlock this challenge, we propose a two-stage method whichconsists of open-set aware meta-learning with open-set free transfer learning.In the open-set aware meta-learning stage, a model is trained to establish ametric space that serves as a beneficial starting point for the subsequentstage. During the open-set free transfer learning stage, the model is furtheradapted to a specific target task through transfer learning. Additionally, weintroduce a strategy to simulate open-set examples by modifying the trainingdataset or generating pseudo open-set examples. The proposed method achievesstate-of-the-art performance on two widely recognized benchmarks, miniImageNetand tieredImageNet, with only a 1.5\% increase in training effort. Our workdemonstrates the effectiveness of transfer learning in FSOSR.</description>
      <author>example@mail.com (Byeonggeun Kim, Juntae Lee, Kyuhong Shim, Simyung Chang)</author>
      <guid isPermaLink="false">2411.09986v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>POS-tagging to highlight the skeletal structure of sentences</title>
      <link>http://arxiv.org/abs/2411.14393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  in Russian language. Conference: Automated control systems and
  information technologies https://asuit.pstu.ru/ Section: IT and automated
  systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究关注词性标注模型的开发。&lt;h4&gt;目的&lt;/h4&gt;提取句子的骨架结构。&lt;h4&gt;方法&lt;/h4&gt;使用BERT架构进行迁移学习进行标记分类。&lt;h4&gt;主要发现&lt;/h4&gt;该模型经过对俄语文本的微调，显示出其有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法在提升自然语言处理任务方面具有潜在应用，特别是改善机器翻译。&lt;h4&gt;关键词&lt;/h4&gt;词性标注，形态分析，自然语言处理，BERT&lt;h4&gt;总结&lt;/h4&gt;研究展示了基于BERT的词性标注模型在自然语言处理中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/disk0Dancer/rubert-finetuned-pos&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents the development of a part-of-speech (POS) tagging modelto extract the skeletal structure of sentences using transfer learning with theBERT architecture for token classification. The model, fine-tuned on Russiantext, demonstrating its effectiveness. The approach offers potentialapplications in enhancing natural language processing tasks, such as improvingmachine translation.  Keywords: part of speech tagging, morphological analysis, natural languageprocessing, BERT.</description>
      <author>example@mail.com (Grigorii Churakov)</author>
      <guid isPermaLink="false">2411.14393v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Learning Pore-scale Multi-phase Flow from Experimental Data with Graph Neural Network</title>
      <link>http://arxiv.org/abs/2411.14192v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accpeted for Machine Learning and the Physical Sciences Workshop at
  the 38th conference on Neural Information Processing Systems (NeurIPS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多相流动通过多孔介质的过程对许多气候变化缓解技术至关重要，包括二氧化碳地质储存、氢气储存和燃料电池。&lt;h4&gt;目的&lt;/h4&gt;解决当前数值模型无法准确捕捉实验中观察到的复杂孔隙尺度物理现象的问题。&lt;h4&gt;方法&lt;/h4&gt;使用基于图神经网络的方法，直接利用微CT实验数据学习孔隙尺度流体流动，提出了一种长短边网格图神经网络（LSE-MGN）。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够在给定初始状态的情况下，自回归地预测多相流动过程随时间的演变，并成功捕捉高分辨率实验数据中的物理特性。&lt;h4&gt;结论&lt;/h4&gt;该方法在保持计算效率的同时，提供了准确和高效的复杂多相流动动力学的孔隙尺度建模的新方向。&lt;h4&gt;总结&lt;/h4&gt;本研究通过图神经网络改进了多相流动的建模能力，为气候变化相关技术提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the process of multiphase fluid flow through porous media iscrucial for many climate change mitigation technologies, including CO$_2$geological storage, hydrogen storage, and fuel cells. However, currentnumerical models are often incapable of accurately capturing the complexpore-scale physics observed in experiments. In this study, we address thischallenge using a graph neural network-based approach and directly learnpore-scale fluid flow using micro-CT experimental data. We propose aLong-Short-Edge MeshGraphNet (LSE-MGN) that predicts the state of each node inthe pore space at each time step. During inference, given an initial state, themodel can autoregressively predict the evolution of the multiphase flow processover time. This approach successfully captures the physics from thehigh-resolution experimental data while maintaining computational efficiency,providing a promising direction for accurate and efficient pore-scale modelingof complex multiphase fluid flow dynamics.</description>
      <author>example@mail.com (Yuxuan Gu, Catherine Spurin, Gege Wen)</author>
      <guid isPermaLink="false">2411.14192v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Understanding via Attention-Driven Contrastive Learning</title>
      <link>http://arxiv.org/abs/2411.14744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，基于Transformer的模型通过自注意力机制在点云理解方面取得了进展，但常常忽视不显著区域的潜在信息，导致对扰动的敏感性增加和全局理解的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出PointACL，一个基于注意力的对比学习框架，以解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;采用注意力驱动的动态掩蔽策略，使模型专注于未被充分关注的区域，从而增强对点云中全局结构的理解，并结合原始预训练损失与对比学习损失，提升特征区分能力和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;PointACL在多种3D理解任务上表现出色，包括物体分类、部件分割和少样本学习，验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;与不同的Transformer基础模型（如Point-MAE和PointGPT）结合时，PointACL在ScanObjectNN、ModelNet40和ShapeNetPart等数据集上表现出更好的性能，显示出其在捕捉全局和局部特征方面的优越能力，以及对扰动和不完整数据的增强鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;PointACL通过动态关注未被充分利用的区域，显著提高了点云理解的准确性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently Transformer-based models have advanced point cloud understanding byleveraging self-attention mechanisms, however, these methods often overlooklatent information in less prominent regions, leading to increased sensitivityto perturbations and limited global comprehension. To solve this issue, weintroduce PointACL, an attention-driven contrastive learning framework designedto address these limitations. Our method employs an attention-driven dynamicmasking strategy that guides the model to focus on under-attended regions,enhancing the understanding of global structures within the point cloud. Thenwe combine the original pre-training loss with a contrastive learning loss,improving feature discrimination and generalization. Extensive experimentsvalidate the effectiveness of PointACL, as it achieves state-of-the-artperformance across a variety of 3D understanding tasks, including objectclassification, part segmentation, and few-shot learning. Specifically, whenintegrated with different Transformer backbones like Point-MAE and PointGPT,PointACL demonstrates improved performance on datasets such as ScanObjectNN,ModelNet40, and ShapeNetPart. This highlights its superior capability incapturing both global and local features, as well as its enhanced robustnessagainst perturbations and incomplete data.</description>
      <author>example@mail.com (Yi Wang, Jiaze Wang, Ziyu Guo, Renrui Zhang, Donghao Zhou, Guangyong Chen, Anfeng Liu, Pheng-Ann Heng)</author>
      <guid isPermaLink="false">2411.14744v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>LSSInst: Improving Geometric Modeling in LSS-Based BEV Perception with Instance Representation</title>
      <link>http://arxiv.org/abs/2411.06173v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by 3DV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着仅使用相机的3D物体检测在自动驾驶中的关注度上升，基于鸟瞰图（BEV）表示的方法，尤其是基于前视变换范式的提升-喷射-射击（LSS）方法，近年来取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出LSSInst，一个结合BEV和实例表示的两阶段物体检测器，以补偿缺失的几何细节并利用多视图几何约束。&lt;h4&gt;方法&lt;/h4&gt;该检测器利用细粒度的像素级特征，可以灵活地集成到现有的基于LSS的BEV网络中，并设计了实例适配器以实现BEV到实例的语义一致性。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验表明，所提出的框架具有优异的泛化能力和性能，提升了现代基于LSS的BEV感知方法的表现。&lt;h4&gt;结论&lt;/h4&gt;该方法在大型nuScenes基准测试中超越了当前基于LSS的最先进的工作，展现了无复杂机制的优秀性能。&lt;h4&gt;总结&lt;/h4&gt;LSSInst方法有效整合了BEV和实例表示，提升了3D物体检测的准确性和通用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/weijiemax/lssinst&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the attention gained by camera-only 3D object detection in autonomousdriving, methods based on Bird-Eye-View (BEV) representation especially derivedfrom the forward view transformation paradigm, i.e., lift-splat-shoot (LSS),have recently seen significant progress. The BEV representation formulated bythe frustum based on depth distribution prediction is ideal for learning theroad structure and scene layout from multi-view images. However, to retaincomputational efficiency, the compressed BEV representation such as inresolution and axis is inevitably weak in retaining the individual geometricdetails, undermining the methodological generality and applicability. With thisin mind, to compensate for the missing details and utilize multi-view geometryconstraints, we propose LSSInst, a two-stage object detector incorporating BEVand instance representations in tandem. The proposed detector exploitsfine-grained pixel-level features that can be flexibly integrated into existingLSS-based BEV networks. Having said that, due to the inherent gap between tworepresentation spaces, we design the instance adaptor for the BEV-to-instancesemantic coherence rather than pass the proposal naively. Extensive experimentsdemonstrated that our proposed framework is of excellent generalization abilityand performance, which boosts the performances of modern LSS-based BEVperception methods without bells and whistles and outperforms current LSS-basedstate-of-the-art works on the large-scale nuScenes benchmark.</description>
      <author>example@mail.com (Weijie Ma, Jingwei Jiang, Yang Yang, Zehui Chen, Hao Chen)</author>
      <guid isPermaLink="false">2411.06173v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>RED: Effective Trajectory Representation Learning with Comprehensive Information</title>
      <link>http://arxiv.org/abs/2411.15096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by VLDB2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;轨迹表示学习（TRL）将轨迹映射为向量，用于轨迹相似性计算、分类和旅行时间估计等下游任务。&lt;h4&gt;目的&lt;/h4&gt;提出一个自监督的TRL框架RED，以更有效地利用轨迹中的全面信息。&lt;h4&gt;方法&lt;/h4&gt;RED采用Transformer作为基础模型，通过掩蔽轨迹中的构成路径来训练掩蔽自编码器（MAE），并使用路-aware掩蔽策略保留关键路径信息。还采用时空用户联合嵌入方案来编码轨迹信息，并通过双目标任务学习进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;与9种最先进的TRL方法在3个真实世界数据集上的4个下游任务进行比较，发现RED通常能将最佳基线的准确率提高超过5%。&lt;h4&gt;结论&lt;/h4&gt;RED通过考虑轨迹的移动模式和时空相关性，显著提升了轨迹表示学习的效果。&lt;h4&gt;总结&lt;/h4&gt;RED框架有效整合了多种轨迹信息，改善了下游任务的表现，提出了一种新的TRL方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory representation learning (TRL) maps trajectories to vectors thatcan then be used for various downstream tasks, including trajectory similaritycomputation, trajectory classification, and travel-time estimation. However,existing TRL methods often produce vectors that, when used in downstream tasks,yield insufficiently accurate results. A key reason is that they fail toutilize the comprehensive information encompassed by trajectories. We propose aself-supervised TRL framework, called RED, which effectively exploits multipletypes of trajectory information. Overall, RED adopts the Transformer as thebackbone model and masks the constituting paths in trajectories to train amasked autoencoder (MAE). In particular, RED considers the moving patterns oftrajectories by employing a Road-aware masking strategy} that retains key pathsof trajectories during masking, thereby preserving crucial information of thetrajectories. RED also adopts a spatial-temporal-user joint Embedding scheme toencode comprehensive information when preparing the trajectories as modelinputs. To conduct training, RED adopts Dual-objective task learning}: theTransformer encoder predicts the next segment in a trajectory, and theTransformer decoder reconstructs the entire trajectory. RED also considers thespatial-temporal correlations of trajectories by modifying the attentionmechanism of the Transformer. We compare RED with 9 state-of-the-art TRLmethods for 4 downstream tasks on 3 real-world datasets, finding that RED canusually improve the accuracy of the best-performing baseline by over 5%.</description>
      <author>example@mail.com (Silin Zhou, Shuo Shang, Lisi Chen, Christian S. Jensen, Panos Kalnis)</author>
      <guid isPermaLink="false">2411.15096v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Text-to-Image Synthesis: A Decade Survey</title>
      <link>http://arxiv.org/abs/2411.16164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In this survey, we review over 440 recent works on T2I&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类在阅读特定文本时常常会想象相关图像，希望计算机也能做到这一点。&lt;h4&gt;目的&lt;/h4&gt;探讨文本到图像合成（T2I）的重要性及其在人工智能生成内容（AIGC）中的应用。&lt;h4&gt;方法&lt;/h4&gt;回顾超过440项关于T2I的最新研究，介绍GAN、自动回归模型和扩散模型在图像生成中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;讨论这些模型在T2I中的生成能力和多样性，以及与文本条件的关系。&lt;h4&gt;结论&lt;/h4&gt;总结T2I研究中的数据集和评估指标，探讨其在AIGC中的潜在应用和面临的挑战。&lt;h4&gt;未来研究&lt;/h4&gt;指出未来在T2I领域的研究机会，包括性能、可控性、个性化生成、安全性和内容一致性等方面。&lt;h4&gt;总结&lt;/h4&gt;T2I是人工智能研究的一个变革方向，具有广泛的应用前景和研究价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When humans read a specific text, they often visualize the correspondingimages, and we hope that computers can do the same. Text-to-image synthesis(T2I), which focuses on generating high-quality images from textualdescriptions, has become a significant aspect of Artificial IntelligenceGenerated Content (AIGC) and a transformative direction in artificialintelligence research. Foundation models play a crucial role in T2I. In thissurvey, we review over 440 recent works on T2I. We start by briefly introducinghow GANs, autoregressive models, and diffusion models have been used for imagegeneration. Building on this foundation, we discuss the development of thesemodels for T2I, focusing on their generative capabilities and diversity whenconditioned on text. We also explore cutting-edge research on various aspectsof T2I, including performance, controllability, personalized generation, safetyconcerns, and consistency in content and spatial relationships. Furthermore, wesummarize the datasets and evaluation metrics commonly used in T2I research.Finally, we discuss the potential applications of T2I within AIGC, along withthe challenges and future research opportunities in this field.</description>
      <author>example@mail.com (Nonghai Zhang, Hao Tang)</author>
      <guid isPermaLink="false">2411.16164v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Electrical Load Forecasting in Smart Grid: A Personalized Federated Learning Approach</title>
      <link>http://arxiv.org/abs/2411.10619v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted by the IEEE Consumer Communications \&amp;
  Networking Conference (CCNC), Jan. 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;电力负荷预测对于智能电网的电力管理和稳定性至关重要，主要通过先进的计量基础设施实现。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的个性化联邦学习方法，以解决非独立同分布的计量数据设置下的负荷预测问题。&lt;h4&gt;方法&lt;/h4&gt;引入元学习，通过调整学习率来最大化每个客户端的梯度，允许不同处理能力、数据大小和批量大小的客户端参与全局模型聚合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在负荷预测准确性方面优于现有的传统机器学习和联邦学习方法。&lt;h4&gt;结论&lt;/h4&gt;个性化联邦学习能够有效改善地方负荷预测，特别是在数据分布不均的情况下。&lt;h4&gt;总结&lt;/h4&gt;通过个性化学习和元学习的结合，本文提出的PFL方法在负荷预测中显示了显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electric load forecasting is essential for power management and stability insmart grids. This is mainly achieved via advanced metering infrastructure,where smart meters (SMs) are used to record household energy consumption.Traditional machine learning (ML) methods are often employed for loadforecasting but require data sharing which raises data privacy concerns.Federated learning (FL) can address this issue by running distributed ML modelsat local SMs without data exchange. However, current FL-based approachesstruggle to achieve efficient load forecasting due to imbalanced datadistribution across heterogeneous SMs. This paper presents a novel personalizedfederated learning (PFL) method to load prediction under non-independent andidentically distributed (non-IID) metering data settings. Specifically, weintroduce meta-learning, where the learning rates are manipulated using themeta-learning idea to maximize the gradient for each client in each globalround. Clients with varying processing capacities, data sizes, and batch sizescan participate in global model aggregation and improve their local loadforecasting via personalized learning. Simulation results show that ourapproach outperforms state-of-the-art ML and FL methods in terms of better loadforecasting accuracy.</description>
      <author>example@mail.com (Ratun Rahman, Neeraj Kumar, Dinh C. Nguyen)</author>
      <guid isPermaLink="false">2411.10619v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Structure of the chromatic polynomial</title>
      <link>http://arxiv.org/abs/2411.15088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，大数据技术如机器学习和拓扑数据分析已进入理论数学领域。&lt;h4&gt;目的&lt;/h4&gt;基于多项式不变量的研究，探索图的色彩多项式点云的结构和性质。&lt;h4&gt;方法&lt;/h4&gt;使用流形学习和拓扑数据分析技术，结合过滤主成分分析（PCA）和Ball Mapper技术进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;尽管色彩多项式和Tutte多项式无法区分图，但根据Bollobas、Pebody和Riordan的猜想，它们能够近似随机图的空间。&lt;h4&gt;结论&lt;/h4&gt;通过对色彩数据的结构进行比较，揭示了与多种数值不变量之间的关系。&lt;h4&gt;总结&lt;/h4&gt;本研究为图的色彩多项式提供了新的理解，连接了拓扑数据分析和图论中的数值不变量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, big data techniques such as machine learning and topological dataanalysis have made their way to theoretical mathematics. Motivated by therecent work with polynomial invariants for knots, we use manifold learning andtopological data analysis techniques to explore the structure and properties ofthe point cloud consisting of the chromatic polynomials of graphs up to 10crossings. Although chromatic, as well as the Tutte polynomial fail todistinguish graphs, according to a conjecture by Bollobas, Pebody and Riordanthey approximate the space of random graphs. In this work we compare structuresin the chromatic data revealed using filtered PCA and Ball Mapper techniques,and relate them with a range of numerical invariants for graphs.</description>
      <author>example@mail.com (Radmila Sazdanovic, Daniel Scofield)</author>
      <guid isPermaLink="false">2411.15088v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SegBook: A Simple Baseline and Cookbook for Volumetric Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2411.14525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;计算机断层扫描（CT）是医学成像中最受欢迎的技术之一，CT图像为体积医学分割任务提供了大量公开数据集。&lt;h4&gt;目的&lt;/h4&gt;评估全身CT预训练模型在不同下游医学分割任务中的迁移能力。&lt;h4&gt;方法&lt;/h4&gt;收集了87个公共数据集，涵盖不同的成像模式、目标和样本大小，以评估全身CT预训练模型的迁移能力，并使用STU-Net模型进行跨模态和目标的迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': '在微调过程中，数据集大小可能存在瓶颈效应，小型和大型数据集的改进效果优于中型数据集。', '2': '在全身CT上预训练的模型能够有效地进行模态迁移，适应其他模态，如MRI。', '3': '全身CT的预训练不仅支持结构检测的强大性能，也在病变检测中展现出有效性，证明其跨目标任务的适应能力。'}&lt;h4&gt;结论&lt;/h4&gt;希望这项大规模开放评估的迁移学习研究能为未来的体积医学图像分割研究指明方向。&lt;h4&gt;总结&lt;/h4&gt;全身CT预训练模型在不同医学分割任务中表现出良好的迁移能力，值得进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computed Tomography (CT) is one of the most popular modalities for medicalimaging. By far, CT images have contributed to the largest publicly availabledatasets for volumetric medical segmentation tasks, covering full-bodyanatomical structures. Large amounts of full-body CT images provide theopportunity to pre-train powerful models, e.g., STU-Net pre-trained in asupervised fashion, to segment numerous anatomical structures. However, itremains unclear in which conditions these pre-trained models can be transferredto various downstream medical segmentation tasks, particularly segmenting theother modalities and diverse targets. To address this problem, a large-scalebenchmark for comprehensive evaluation is crucial for finding these conditions.Thus, we collected 87 public datasets varying in modality, target, and samplesize to evaluate the transfer ability of full-body CT pre-trained models. Wethen employed a representative model, STU-Net with multiple model scales, toconduct transfer learning across modalities and targets. Our experimentalresults show that (1) there may be a bottleneck effect concerning the datasetsize in fine-tuning, with more improvement on both small- and large-scaledatasets than medium-size ones. (2) Models pre-trained on full-body CTdemonstrate effective modality transfer, adapting well to other modalities suchas MRI. (3) Pre-training on the full-body CT not only supports strongperformance in structure detection but also shows efficacy in lesion detection,showcasing adaptability across target tasks. We hope that this large-scale openevaluation of transfer learning can direct future research in volumetricmedical image segmentation.</description>
      <author>example@mail.com (Jin Ye, Ying Chen, Yanjun Li, Haoyu Wang, Zhongying Deng, Ziyan Huang, Yanzhou Su, Chenglong Ma, Yuanfeng Ji, Junjun He)</author>
      <guid isPermaLink="false">2411.14525v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Swift: A Multi-FPGA Framework for Scaling Up Accelerated Graph Analytics</title>
      <link>http://arxiv.org/abs/2411.14554v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in International Conference on Field Programmable Technology
  (FPT-2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图分析在社交网络、生物医学研究和图神经网络等领域至关重要，但传统CPU和GPU在处理大型图数据集时面临内存瓶颈和细粒度内存访问的问题。&lt;h4&gt;目的&lt;/h4&gt;提出Swift，一个新的扩展图加速器框架，以处理大型图，克服传统加速器的限制。&lt;h4&gt;方法&lt;/h4&gt;Swift利用FPGA的自定义数据路径和内存资源，优化高带宽3D内存(HBM)的利用率，支持每个节点最多8个FPGA，并引入基于Gather-Apply-Scatter(GAS)方案的解耦异步模型。&lt;h4&gt;主要发现&lt;/h4&gt;与之前的可扩展FPGA框架相比，Swift的性能显著提升，表现为比ForeGraph快12.8倍。与NVIDIA A40 GPU上的Gunrock性能对比混合，尽管GPU系统在带宽上具有接近5倍的优势，但FPGA系统的能效仍高出2.6倍。&lt;h4&gt;结论&lt;/h4&gt;Swift通过解耦和异步处理，优化了多FPGA节点内的并行处理和资源利用，显示出在大型图处理中的潜力。&lt;h4&gt;总结&lt;/h4&gt;Swift是一个创新的图加速器框架，能够有效处理大型图数据，改善了性能和能效，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph analytics are vital in fields such as social networks, biomedicalresearch, and graph neural networks (GNNs). However, traditional CPUs and GPUsstruggle with the memory bottlenecks caused by large graph datasets and theirfine-grained memory accesses. While specialized graph accelerators addressthese challenges, they often support only moderate-sized graphs (under 500million edges). Our paper proposes Swift, a novel scale-up graph acceleratorframework that processes large graphs by leveraging the flexibility of FPGAcustom datapath and memory resources, and optimizes utilization ofhigh-bandwidth 3D memory (HBM). Swift supports up to 8 FPGAs in a node. Swiftintroduces a decoupled, asynchronous model based on the Gather-Apply-Scatter(GAS) scheme. It subgraphs across FPGAs, and each subgraph into intervals basedon source vertex IDs. Processing on these intervals is decoupled and executedasynchronously, instead of bulk-synchonous operation, where throughput islimited by the slowest task. This enables simultaneous processing within eachmulti-FPGA node and optimizes the utilization of communication (PCIe), off-chip(HBM), and on-chip BRAM/URAM resources. Swift demonstrates significantperformance improvements compared to prior scalable FPGA-based frameworks,performing 12.8 times better than the ForeGraph. Performance against Gunrock onNVIDIA A40 GPUs is mixed, because NVlink gives the GPU system a nearly 5Xbandwidth advantage, but the FPGA system nevertheless achieves 2.6x greaterenergy efficiency.</description>
      <author>example@mail.com (Oluwole Jaiyeoba, Abdullah T. Mughrabi, Morteza Baradaran, Beenish Gul, Kevin Skadron)</author>
      <guid isPermaLink="false">2411.14554v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>An Attention-based Framework for Fair Contrastive Learning</title>
      <link>http://arxiv.org/abs/2411.14765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习在学习无偏数据表示方面非常重要，尤其是在高维和高基数的复杂环境中。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的公平对比学习方法，以改善模型学习无偏表示的能力。&lt;h4&gt;方法&lt;/h4&gt;采用注意力机制来建模导致偏见的交互，避免干扰模型的偏见样本，专注于减少偏见的样本。&lt;h4&gt;主要发现&lt;/h4&gt;我们的方法在公平对比学习中优于现有基线，显著提高了学习表示中的偏见去除效果。&lt;h4&gt;结论&lt;/h4&gt;在不影响下游准确性的情况下，我们的方法能够有效增强学习到的表示的公平性和语义丰富性。&lt;h4&gt;总结&lt;/h4&gt;提出的公平对比学习方法通过注意力机制提升了偏见去除能力，具有较好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has proven instrumental in learning unbiasedrepresentations of data, especially in complex environments characterized byhigh-cardinality and high-dimensional sensitive information. However, existingapproaches within this setting require predefined modelling assumptions ofbias-causing interactions that limit the model's ability to learn debiasedrepresentations. In this work, we propose a new method for fair contrastivelearning that employs an attention mechanism to model bias-causinginteractions, enabling the learning of a fairer and semantically richerembedding space. In particular, our attention mechanism avoids bias-causingsamples that confound the model and focuses on bias-reducing samples that helplearn semantically meaningful representations. We verify the advantages of ourmethod against existing baselines in fair contrastive learning and show thatour approach can significantly boost bias removal from learned representationswithout compromising downstream accuracy.</description>
      <author>example@mail.com (Stefan K. Nielsen, Tan M. Nguyen)</author>
      <guid isPermaLink="false">2411.14765v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>AMAGO-2: Breaking the Multi-Task Barrier in Meta-Reinforcement Learning with Transformers</title>
      <link>http://arxiv.org/abs/2411.11188v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;语言模型通过多样化数据集的训练，实现了通过上下文学习的泛化能力。强化学习策略也可以通过序列模型的记忆进行元学习来达到类似效果。&lt;h4&gt;目的&lt;/h4&gt;解决多任务优化中的挑战，尤其是在面对大规模无标签任务训练集时，如何实现更通用的行为.&lt;h4&gt;方法&lt;/h4&gt;提出一种简单且可扩展的解决方案，将智能体的演员和评论家目标转换为分类任务，从而使优化与当前回报规模解耦。&lt;h4&gt;主要发现&lt;/h4&gt;在Meta-World ML45、Multi-Game Procgen、Multi-Task POPGym、Multi-Game Atari和BabyAI等大规模比较中，该设计显著推动了在线多任务适应和记忆问题的解决，无需显式任务标签。&lt;h4&gt;结论&lt;/h4&gt;通过改善多任务强化学习的训练损失不平衡问题，该方法有效提升了在多任务场景中的表现。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了强化学习在多任务环境中的潜力，尤其是通过元学习和优化策略的创新设计。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ut-austin-rpl/amago&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language models trained on diverse datasets unlock generalization byin-context learning. Reinforcement Learning (RL) policies can achieve a similareffect by meta-learning within the memory of a sequence model. However, meta-RLresearch primarily focuses on adapting to minor variations of a single task. Itis difficult to scale towards more general behavior without confrontingchallenges in multi-task optimization, and few solutions are compatible withmeta-RL's goal of learning from large training sets of unlabeled tasks. Toaddress this challenge, we revisit the idea that multi-task RL is bottleneckedby imbalanced training losses created by uneven return scales across differenttasks. We build upon recent advancements in Transformer-based (in-context)meta-RL and evaluate a simple yet scalable solution where both an agent's actorand critic objectives are converted to classification terms that decoupleoptimization from the current scale of returns. Large-scale comparisons inMeta-World ML45, Multi-Game Procgen, Multi-Task POPGym, Multi-Game Atari, andBabyAI find that this design unlocks significant progress in online multi-taskadaptation and memory problems without explicit task labels.</description>
      <author>example@mail.com (Jake Grigsby, Justin Sasek, Samyak Parajuli, Daniel Adebi, Amy Zhang, Yuke Zhu)</author>
      <guid isPermaLink="false">2411.11188v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>UniGaussian: Driving Scene Reconstruction from Multiple Camera Models via Unified Gaussian Representations</title>
      <link>http://arxiv.org/abs/2411.15355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;城市场景重建对现实世界的自动驾驶模拟至关重要，现有方法主要集中在针孔相机上，忽视了鱼眼相机的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法UniGaussian，通过多种相机模型学习统一的3D高斯表示，解决鱼眼相机在驾驶场景模拟中的难题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的可微渲染方法，通过一系列针对鱼眼相机模型的仿射变换扭曲3D高斯，解决了光线畸变带来的兼容性问题，并保持实时渲染和可微性。&lt;h4&gt;主要发现&lt;/h4&gt;通过构建新框架，能够从多个相机模型学习统一的高斯表示，使用仿射变换适应不同的相机模型，并通过不同模态的监督正则化共享的高斯。&lt;h4&gt;结论&lt;/h4&gt;该方法能够模型化多种传感器（针孔和鱼眼相机）及模态（深度、语义、法线和LiDAR点云），在驾驶场景模拟中实现优越的渲染质量和快速的渲染速度。&lt;h4&gt;总结&lt;/h4&gt;UniGaussian方法为城市场景重建引入了新的思路，解决了鱼眼相机的兼容性问题，提升了自动驾驶模拟的整体表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban scene reconstruction is crucial for real-world autonomous drivingsimulators. Although existing methods have achieved photorealisticreconstruction, they mostly focus on pinhole cameras and neglect fisheyecameras. In fact, how to effectively simulate fisheye cameras in driving sceneremains an unsolved problem. In this work, we propose UniGaussian, a novelapproach that learns a unified 3D Gaussian representation from multiple cameramodels for urban scene reconstruction in autonomous driving. Our contributionsare two-fold. First, we propose a new differentiable rendering method thatdistorts 3D Gaussians using a series of affine transformations tailored tofisheye camera models. This addresses the compatibility issue of 3D Gaussiansplatting with fisheye cameras, which is hindered by light ray distortioncaused by lenses or mirrors. Besides, our method maintains real-time renderingwhile ensuring differentiability. Second, built on the differentiable renderingmethod, we design a new framework that learns a unified Gaussian representationfrom multiple camera models. By applying affine transformations to adaptdifferent camera models and regularizing the shared Gaussians with supervisionfrom different modalities, our framework learns a unified 3D Gaussianrepresentation with input data from multiple sources and achieves holisticdriving scene understanding. As a result, our approach models multiple sensors(pinhole and fisheye cameras) and modalities (depth, semantic, normal and LiDARpoint clouds). Our experiments show that our method achieves superior renderingquality and fast rendering speed for driving scene simulation.</description>
      <author>example@mail.com (Yuan Ren, Guile Wu, Runhao Li, Zheyuan Yang, Yibo Liu, Xingxin Chen, Tongtong Cao, Bingbing Liu)</author>
      <guid isPermaLink="false">2411.15355v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Can GNNs Learn Link Heuristics? A Concise Review and Evaluation of Link Prediction Methods</title>
      <link>http://arxiv.org/abs/2411.14711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文探讨图神经网络（GNNs）在链接预测中学习各种信息的能力，并简要回顾现有的链接预测方法。&lt;h4&gt;目的&lt;/h4&gt;分析GNNs在学习节点之间共同邻居数量的结构信息方面的有效性。&lt;h4&gt;方法&lt;/h4&gt;通过广泛的实验评估可训练的节点嵌入对GNN基于链接预测模型性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;GNNs无法有效学习与节点之间共同邻居数量相关的结构信息；可训练的节点嵌入能提升GNN模型的性能，尤其在图更密集时效果更明显。&lt;h4&gt;结论&lt;/h4&gt;节点嵌入的特性使得在更密集的图中，节点有更多机会参与邻域聚合，从而更好地为链接预测学习嵌入，这对现有链接预测方法的局限性提供了重要见解，指导未来更强大算法的发展。&lt;h4&gt;总结&lt;/h4&gt;研究结果强调了GNNs在链接预测中的潜力及其对现有方法的改进方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/astroming/GNNHE&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the ability of Graph Neural Networks (GNNs) in learningvarious forms of information for link prediction, alongside a brief review ofexisting link prediction methods. Our analysis reveals that GNNs cannoteffectively learn structural information related to the number of commonneighbors between two nodes, primarily due to the nature of set-based poolingof the neighborhood aggregation scheme. Also, our extensive experimentsindicate that trainable node embeddings can improve the performance ofGNN-based link prediction models. Importantly, we observe that the denser thegraph, the greater such the improvement. We attribute this to thecharacteristics of node embeddings, where the link state of each link samplecould be encoded into the embeddings of nodes that are involved in theneighborhood aggregation of the two nodes in that link sample. In densergraphs, every node could have more opportunities to attend the neighborhoodaggregation of other nodes and encode states of more link samples to itsembedding, thus learning better node embeddings for link prediction. Lastly, wedemonstrate that the insights gained from our research carry importantimplications in identifying the limitations of existing link predictionmethods, which could guide the future development of more robust algorithms.</description>
      <author>example@mail.com (Shuming Liang, Yu Ding, Zhidong Li, Bin Liang, Siqi Zhang, Yang Wang, Fang Chen)</author>
      <guid isPermaLink="false">2411.14711v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Fine-Grained Alignment in Vision-and-Language Navigation through Bayesian Optimization</title>
      <link>http://arxiv.org/abs/2411.14811v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文探讨了视觉与语言导航（VLN）任务中的细粒度对齐挑战，涉及机器人基于自然语言指令在真实3D环境中导航。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法来解决当前对比学习在细粒度视觉负样本对齐中的困难。&lt;h4&gt;方法&lt;/h4&gt;引入了一种基于贝叶斯优化的对抗优化框架，以创建细粒度对比视觉样本，从而增强跨模态嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在R2R和REVERIE两个常见的VLN基准上进行的实验表明，增强后的嵌入有助于导航，并显著提升了性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法有效改善了细粒度视觉负样本的对齐，并在导航任务中表现出良好的效果。&lt;h4&gt;总结&lt;/h4&gt;该研究为提高视觉与语言导航任务中的细粒度对齐提供了新的思路和方法，且相关代码和模型已公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenge of fine-grained alignment inVision-and-Language Navigation (VLN) tasks, where robots navigate realistic 3Denvironments based on natural language instructions. Current approaches usecontrastive learning to align language with visual trajectory sequences.Nevertheless, they encounter difficulties with fine-grained vision negatives.To enhance cross-modal embeddings, we introduce a novel BayesianOptimization-based adversarial optimization framework for creating fine-grainedcontrastive vision samples. To validate the proposed methodology, we conduct aseries of experiments to assess the effectiveness of the enriched embeddings onfine-grained vision negatives. We conduct experiments on two common VLNbenchmarks R2R and REVERIE, experiments on the them demonstrate that theseembeddings benefit navigation, and can lead to a promising performanceenhancement. Our source code and trained models are available at:https://anonymous.4open.science/r/FGVLN.</description>
      <author>example@mail.com (Yuhang Song, Mario Gianni, Chenguang Yang, Kunyang Lin, Te-Chuan Chiu, Anh Nguyen, Chun-Yi Lee)</author>
      <guid isPermaLink="false">2411.14811v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TSINR: Capturing Temporal Continuity via Implicit Neural Representations for Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2411.11641v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by SIGKDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列异常检测旨在识别数据中的异常模式或偏差。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于隐式神经表示的时间序列异常检测方法TSINR，以应对重建方法在训练数据中无标签异常点带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;使用隐式神经表示(INR)将时间序列数据参数化为连续函数，并采用基于变压器的架构预测给定数据的INR。&lt;h4&gt;主要发现&lt;/h4&gt;TSINR方法在捕捉时间连续性方面具有优势，对不连续异常数据更为敏感。&lt;h4&gt;结论&lt;/h4&gt;与其他主流的重建方法相比，TSINR在单变量和多变量时间序列异常检测基准上表现出色。&lt;h4&gt;总结&lt;/h4&gt;研究表明，TSINR能够有效提高时间序列异常检测的性能，并且代码已公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Leanna97/TSINR&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series anomaly detection aims to identify unusual patterns in data ordeviations from systems' expected behavior. The reconstruction-based methodsare the mainstream in this task, which learn point-wise representation viaunsupervised learning. However, the unlabeled anomaly points in training datamay cause these reconstruction-based methods to learn and reconstruct anomalousdata, resulting in the challenge of capturing normal patterns. In this paper,we propose a time series anomaly detection method based on implicit neuralrepresentation (INR) reconstruction, named TSINR, to address this challenge.Due to the property of spectral bias, TSINR enables prioritizing low-frequencysignals and exhibiting poorer performance on high-frequency abnormal data.Specifically, we adopt INR to parameterize time series data as a continuousfunction and employ a transformer-based architecture to predict the INR ofgiven data. As a result, the proposed TSINR method achieves the advantage ofcapturing the temporal continuity and thus is more sensitive to discontinuousanomaly data. In addition, we further design a novel form of INR continuousfunction to learn inter- and intra-channel information, and leverage apre-trained large language model to amplify the intense fluctuations inanomalies. Extensive experiments demonstrate that TSINR achieves superioroverall performance on both univariate and multivariate time series anomalydetection benchmarks compared to other state-of-the-art reconstruction-basedmethods. Our codes are available.</description>
      <author>example@mail.com (Mengxuan Li, Ke Liu, Hongyang Chen, Jiajun Bu, Hongwei Wang, Haishuai Wang)</author>
      <guid isPermaLink="false">2411.11641v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Variable Extraction for Model Recovery in Scientific Literature</title>
      <link>http://arxiv.org/abs/2411.14569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全球学术出版物的年产量超过500万篇，导致人类难以跟上科学成果的更新速度。&lt;h4&gt;目的&lt;/h4&gt;需要方法来导航和解释构成文献的文本、图形、图表、代码、模型和数据集。&lt;h4&gt;方法&lt;/h4&gt;评估从流行病学研究中提取数学模型变量的方法，包括感染率、恢复率和死亡率。引入一个包含手动注释的变量描述和从科学论文中提取的变量值的基准数据集，并基于此数据集展示几种基于大语言模型和规则信息提取系统的变量提取基线方法。&lt;h4&gt;主要发现&lt;/h4&gt;基于大语言模型的解决方案表现最佳，尽管将规则提取输出与大语言模型结合的增益有限，但大语言模型本身的迁移学习和指令调优能力带来的性能提升更为显著。&lt;h4&gt;结论&lt;/h4&gt;大语言模型在增强科学文献自动理解、模型恢复和仿真方面具有潜力。&lt;h4&gt;总结&lt;/h4&gt;论文展示了从文献中提取数学模型变量的重要性及其对自动建模和结果复制的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The global output of academic publications exceeds 5 million articles peryear, making it difficult for humans to keep up with even a tiny fraction ofscientific output. We need methods to navigate and interpret the artifacts --texts, graphs, charts, code, models, and datasets -- that make up theliterature. This paper evaluates various methods for extracting mathematicalmodel variables from epidemiological studies, such as ``infection rate($\alpha$),'' ``recovery rate ($\gamma$),'' and ``mortality rate ($\mu$).''Variable extraction appears to be a basic task, but plays a pivotal role inrecovering models from scientific literature. Once extracted, we can use thesevariables for automatic mathematical modeling, simulation, and replication ofpublished results.  We introduce a benchmark dataset comprising manually-annotated variabledescriptions and variable values extracted from scientific papers. Based onthis dataset, we present several baseline methods for variable extraction basedon Large Language Models (LLMs) and rule-based information extraction systems.Our analysis shows that LLM-based solutions perform the best. Despite theincremental benefits of combining rule-based extraction outputs with LLMs, theleap in performance attributed to the transfer-learning and instruction-tuningcapabilities of LLMs themselves is far more significant. This investigationdemonstrates the potential of LLMs to enhance automatic comprehension ofscientific artifacts and for automatic model recovery and simulation.</description>
      <author>example@mail.com (Chunwei Liu, Enrique Noriega-Atala, Adarsh Pyarelal, Clayton T Morrison, Mike Cafarella)</author>
      <guid isPermaLink="false">2411.14569v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Dependence Induced Representations</title>
      <link>http://arxiv.org/abs/2411.15328v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究从一对随机变量中学习特征表示的问题，重点关注由它们的依赖关系引发的表示。&lt;h4&gt;目的&lt;/h4&gt;提供充分必要条件以理解依赖引发的特征表示，并探讨其与相关函数的关系。&lt;h4&gt;方法&lt;/h4&gt;描述了可以学习依赖引发表示的大量损失函数，包括交叉熵、铰链损失及其正则化变体。&lt;h4&gt;主要发现&lt;/h4&gt;学习到的特征可以表示为损失依赖函数和最大相关函数的组合，揭示了不同损失下学习表示之间的关键联系。&lt;h4&gt;结论&lt;/h4&gt;该研究为深度分类器中观察到的神经崩溃现象提供了统计解释，并提出了基于特征分离的学习设计，以便在推理过程中进行超参数调优。&lt;h4&gt;总结&lt;/h4&gt;本研究深入探讨了依赖引发的特征表示及其学习的条件与方法，为理解和应用这些表示提供了理论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/Allerton63246.2024.10735284&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the problem of learning feature representations from a pair ofrandom variables, where we focus on the representations that are induced bytheir dependence. We provide sufficient and necessary conditions for suchdependence induced representations, and illustrate their connections toHirschfeld--Gebelein--R\'{e}nyi (HGR) maximal correlation functions and minimalsufficient statistics. We characterize a large family of loss functions thatcan learn dependence induced representations, including cross entropy, hingeloss, and their regularized variants. In particular, we show that the featureslearned from this family can be expressed as the composition of aloss-dependent function and the maximal correlation function, which reveals akey connection between representations learned from different losses. Ourdevelopment also gives a statistical interpretation of the neural collapsephenomenon observed in deep classifiers. Finally, we present the learningdesign based on the feature separation, which allows hyperparameter tuningduring inference.</description>
      <author>example@mail.com (Xiangxiang Xu, Lizhong Zheng)</author>
      <guid isPermaLink="false">2411.15328v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Learn from Foundation Model: Fruit Detection Model without Manual Annotation</title>
      <link>http://arxiv.org/abs/2411.16196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 12 figures, conference or other essential info&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;农业领域数据不足，限制了模型的有效应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，从基础模型中训练有效的领域特定小模型，无需人工标注。&lt;h4&gt;方法&lt;/h4&gt;使用SDM（分割-描述-匹配）阶段，结合SAM2进行图像分割和OpenCLIP进行零样本分类。在第二阶段，采用新颖的知识蒸馏机制，从SDM中提取紧凑的模型，提升推理速度和感知准确性。&lt;h4&gt;主要发现&lt;/h4&gt;SDM-D在各种水果检测任务中表现强劲，几乎可以与大量标签训练的模型相媲美，且在所有测试水果检测数据集上超越了开放集检测方法，如Grounding SAM和YOLO-World。&lt;h4&gt;结论&lt;/h4&gt;SDM-D方法有效地解决了农业数据不足的问题，展现出良好的检测性能，并且所有代码和数据集均已公开。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种创新的方法，通过基础模型提升农业领域的图像检测能力，推动了无标签学习的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent breakthroughs in large foundation models have enabled the possibilityof transferring knowledge pre-trained on vast datasets to domains with limiteddata availability. Agriculture is one of the domains that lacks sufficientdata. This study proposes a framework to train effective, domain-specific,small models from foundation models without manual annotation. Our approachbegins with SDM (Segmentation-Description-Matching), a stage that leverages twofoundation models: SAM2 (Segment Anything in Images and Videos) forsegmentation and OpenCLIP (Open Contrastive Language-Image Pretraining) forzero-shot open-vocabulary classification. In the second stage, a novelknowledge distillation mechanism is utilized to distill compact,edge-deployable models from SDM, enhancing both inference speed and perceptionaccuracy. The complete method, termed SDM-D(Segmentation-Description-Matching-Distilling), demonstrates strong performanceacross various fruit detection tasks object detection, semantic segmentation,and instance segmentation) without manual annotation. It nearly matches theperformance of models trained with abundant labels. Notably, SDM-D outperformsopen-set detection methods such as Grounding SAM and YOLO-World on all testedfruit detection datasets. Additionally, we introduce MegaFruits, acomprehensive fruit segmentation dataset encompassing over 25,000 images, andall code and datasets are made publicly available athttps://github.com/AgRoboticsResearch/SDM-D.git.</description>
      <author>example@mail.com (Yanan Wang, Zhenghao Fei, Ruichen Li, Yibin Ying)</author>
      <guid isPermaLink="false">2411.16196v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Lie-Equivariant Quantum Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.15315v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, accepted to the Machine Learning with New
  Compute Paradigms (MLNCP) Workshop at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在大型强子对撞机（LHC）上发现新现象需要识别稀有信号与常规背景的区别，因此二元分类任务在LHC数据分析中无处不在。&lt;h4&gt;目的&lt;/h4&gt;开发一种Lie-Equivariant Quantum Graph Neural Network（Lie-EQGNN），旨在提高数据效率并保持对称性。&lt;h4&gt;方法&lt;/h4&gt;构建一种洛伦兹等变的量子图神经网络，用于区分夸克-胶子喷流。&lt;h4&gt;主要发现&lt;/h4&gt;该模型的性能与经典的洛伦兹网络（LorentzNet）相当，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;Lie-EQGNN是传统计算范式的可行替代方案。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了量子模型在LHC数据分析中的潜力，尤其是在处理复杂的喷流分类任务时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Discovering new phenomena at the Large Hadron Collider (LHC) involves theidentification of rare signals over conventional backgrounds. Thus binaryclassification tasks are ubiquitous in analyses of the vast amounts of LHCdata. We develop a Lie-Equivariant Quantum Graph Neural Network (Lie-EQGNN), aquantum model that is not only data efficient, but also has symmetry-preservingproperties. Since Lorentz group equivariance has been shown to be beneficialfor jet tagging, we build a Lorentz-equivariant quantum GNN for quark-gluon jetdiscrimination and show that its performance is on par with its classicalstate-of-the-art counterpart LorentzNet, making it a viable alternative to theconventional computing paradigm.</description>
      <author>example@mail.com (Jogi Suda Neto, Roy T. Forestano, Sergei Gleyzer, Kyoungchul Kong, Konstantin T. Matchev, Katia Matcheva)</author>
      <guid isPermaLink="false">2411.15315v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Federated Contrastive Learning of Graph-Level Representations</title>
      <link>http://arxiv.org/abs/2411.12098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in BigData 2024. This is a preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图级表示及其基础上的聚类/分类在多种应用中是必需的，如识别恶意网络流量和预测蛋白质特性等。&lt;h4&gt;目的&lt;/h4&gt;应对由于隐私、信任、法规等原因导致的数据无法集中共享的问题，探索图级表示的联邦学习。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架，称为联邦对比学习图级表示（FCLG），在两个层面上应用对比学习，分别用于局部无监督学习和解决数据分布变化的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验，FCLG在图级聚类的下游任务中显著优于现有的基线方法。&lt;h4&gt;结论&lt;/h4&gt;FCLG方法有效解决了联邦学习中图级表示的相关问题，具有较大的性能提升。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一个新的联邦学习框架，适用于图级表示的无监督学习，能有效应对数据分布不均的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-level representations (and clustering/classification based on theserepresentations) are required in a variety of applications. Examples includeidentifying malicious network traffic, prediction of protein properties, andmany others. Often, data has to stay in isolated local systems (i.e., cannot becentrally shared for analysis) due to a variety of considerations like privacyconcerns, lack of trust between the parties, regulations, or simply because thedata is too large to be shared sufficiently quickly. This points to the needfor federated learning for graph-level representations, a topic that has notbeen explored much, especially in an unsupervised setting.  Addressing this problem, this paper presents a new framework we refer to asFederated Contrastive Learning of Graph-level Representations (FCLG). As thename suggests, our approach builds on contrastive learning. However, what isunique is that we apply contrastive learning at two levels. The firstapplication is for local unsupervised learning of graph representations. Thesecond level is to address the challenge associated with data distributionvariation (i.e. the ``Non-IID issue") when combining local models. Throughextensive experiments on the downstream task of graph-level clustering, wedemonstrate FCLG outperforms baselines (which apply existing federated methodson existing graph-level clustering methods) with significant margins.</description>
      <author>example@mail.com (Xiang Li, Gagan Agrawal, Rajiv Ramnath, Ruoming Jin)</author>
      <guid isPermaLink="false">2411.12098v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning for Ordered Three-Dimensional Structures</title>
      <link>http://arxiv.org/abs/2411.14680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Version as submitted to the Learning on Graphs Conference 2022, with
  small clarifying edits&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来的研究证明，通过自监督任务训练大型语言模型，并在迁移学习环境中微调这些模型是一种强大的方法，尽管标记数据有限，依然可以创建具有大量参数的模型，但利用这些进展的领域仍然有限。&lt;h4&gt;目的&lt;/h4&gt;制定一系列几何任务，以便于大规模研究有序三维结构，无需人工干预数据标记。&lt;h4&gt;方法&lt;/h4&gt;基于几何代数构建深度旋转和置换不变的神经网络，并使用这些网络解决理想化和模拟的三维结构任务。&lt;h4&gt;主要发现&lt;/h4&gt;在复杂结构组装体中量化有序性仍然是材料物理中的一项长期挑战，这些模型可以从学习的任务中提炼出见解，并能通过迁移学习以较少的标记数据解决新任务。&lt;h4&gt;结论&lt;/h4&gt;这些模型为理解真实自组装系统的行为提供了多种方法，推动了材料科学领域的研究。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了几何任务在大规模三维结构研究中的应用潜力，强调了自监督学习和迁移学习的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has proven that training large language models withself-supervised tasks and fine-tuning these models to complete new tasks in atransfer learning setting is a powerful idea, enabling the creation of modelswith many parameters, even with little labeled data; however, the number ofdomains that have harnessed these advancements has been limited. In this work,we formulate a set of geometric tasks suitable for the large-scale study ofordered three-dimensional structures, without requiring any human interventionin data labeling. We build deep rotation- and permutation-equivariant neuralnetworks based on geometric algebra and use them to solve these tasks on bothidealized and simulated three-dimensional structures. Quantifying order incomplex-structured assemblies remains a long-standing challenge in materialsphysics; these models can elucidate the behavior of real self-assemblingsystems in a variety of ways, from distilling insights from learned taskswithout further modification to solving new tasks with smaller amounts oflabeled data via transfer learning.</description>
      <author>example@mail.com (Matthew Spellings, Maya Martirossyan, Julia Dshemuchadse)</author>
      <guid isPermaLink="false">2411.14680v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with Denoising Diffusion</title>
      <link>http://arxiv.org/abs/2411.08402v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的车联网（V2X）系统通过激光雷达和相机数据显著提高了3D物体检测的能力，但在恶劣天气条件下性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出V2X-R，这是第一个结合激光雷达、相机和4D雷达的模拟V2X数据集，以应对恶劣天气下的检测挑战。&lt;h4&gt;方法&lt;/h4&gt;V2X-R数据集包含12,079个场景，37,727帧激光雷达和4D雷达点云，150,908张图像，以及170,859个标注的3D车辆边界框。提出了一种新的协同激光雷达-4D雷达融合管道，用于3D物体检测，并实现了多种融合策略。同时，提出了多模态去噪扩散（MDD）模块，利用4D雷达特征作为条件，以减少噪声激光雷达特征的影响。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，激光雷达-4D雷达融合管道在V2X-R数据集上表现优越。MDD模块在雾天和雪天条件下进一步提升了基本融合模型的性能，分别提高了5.73%和6.70%，几乎没有影响正常性能。&lt;h4&gt;结论&lt;/h4&gt;V2X-R数据集和代码将公开发布，提供了一个强有力的工具来改进3D物体检测，尤其是在恶劣天气条件下。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了结合多种传感器和新型去噪技术在提升车辆检测能力方面的潜力，特别是在不利天气条件下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ylwhxht/v2x-r&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current Vehicle-to-Everything (V2X) systems have significantly enhanced 3Dobject detection using LiDAR and camera data. However, these methods sufferfrom performance degradation in adverse weather conditions. The weatherrobust4D radar provides Doppler and additional geometric information, raising thepossibility of addressing this challenge. To this end, we present V2X-R, thefirst simulated V2X dataset incorporating LiDAR, camera, and 4D radar. V2X-Rcontains 12,079 scenarios with 37,727 frames of LiDAR and 4D radar pointclouds, 150,908 images, and 170,859 annotated 3D vehicle bounding boxes.Subsequently, we propose a novel cooperative LiDAR-4D radar fusion pipeline for3D object detection and implement it with various fusion strategies. To achieveweather-robust detection, we additionally propose a Multi-modal DenoisingDiffusion (MDD) module in our fusion pipeline. MDD utilizes weather-robust 4Dradar feature as a condition to prompt the diffusion model to denoise noisyLiDAR features. Experiments show that our LiDAR-4D radar fusion pipelinedemonstrates superior performance in the V2X-R dataset. Over and above this,our MDD module further improved the performance of basic fusion model by up to5.73%/6.70% in foggy/snowy conditions with barely disrupting normalperformance. The dataset and code will be publicly available at:https://github.com/ylwhxht/V2X-R.</description>
      <author>example@mail.com (Xun Huang, Jinlong Wang, Qiming Xia, Siheng Chen, Bisheng Yang, Xin Li, Cheng Wang, Chenglu Wen)</author>
      <guid isPermaLink="false">2411.08402v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>GeoScatt-GNN: A Geometric Scattering Transform-Based Graph Neural Network Model for Ames Mutagenicity Prediction</title>
      <link>http://arxiv.org/abs/2411.15331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预测致突变性是一个重要的科学挑战。&lt;h4&gt;目的&lt;/h4&gt;提出三种创新方法来改进致突变性预测。&lt;h4&gt;方法&lt;/h4&gt;1. 使用从分子图像提取的2D散射系数，表现优于传统分子描述符；2. 结合几何图散射（GGS）、图同构网络（GIN）与机器学习模型的混合方法；3. 引入新的图神经网络架构MOLG3-SAGE，将GGS节点特征整合进全连接图结构。&lt;h4&gt;主要发现&lt;/h4&gt;在ZINC数据集实验中显著提高了预测准确性，结合了2D和几何散射技术与图神经网络的效果突出。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了图神经网络和几何图散射在致突变性预测中的潜力，对药物发现和化学安全评估具有广泛的影响。&lt;h4&gt;总结&lt;/h4&gt;研究成果强调了新方法在致突变性预测中的重要性，推动相关领域的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper tackles the pressing challenge of mutagenicity prediction byintroducing three ground-breaking approaches. First, it showcases the superiorperformance of 2D scattering coefficients extracted from molecular images,compared to traditional molecular descriptors. Second, it presents a hybridapproach that combines geometric graph scattering (GGS), Graph IsomorphismNetworks (GIN), and machine learning models, achieving strong results inmutagenicity prediction. Third, it introduces a novel graph neural networkarchitecture, MOLG3-SAGE, which integrates GGS node features into a fullyconnected graph structure, delivering outstanding predictive accuracy.Experimental results on the ZINC dataset demonstrate significant improvements,emphasizing the effectiveness of blending 2D and geometric scatteringtechniques with graph neural networks. This study illustrates the potential ofGNNs and GGS for mutagenicity prediction, with broad implications for drugdiscovery and chemical safety assessment.</description>
      <author>example@mail.com (Abdeljalil Zoubir, Badr Missaoui)</author>
      <guid isPermaLink="false">2411.15331v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>K-means Derived Unsupervised Feature Selection using Improved ADMM</title>
      <link>http://arxiv.org/abs/2411.15197v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;特征选择对于高维数据分析至关重要，特别是在无监督学习问题中，如降维和聚类。&lt;h4&gt;目的&lt;/h4&gt;无监督特征选择的目标是找到一个特征子集，使得来自不同簇的数据点能够良好分离。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的方法，称为K-means导向的无监督特征选择（K-means UFS），通过K-means的目标选择特征，采用交替方向乘子法（ADMM）解决NP-hard优化问题。&lt;h4&gt;主要发现&lt;/h4&gt;在真实数据集上的广泛实验表明，K-means UFS在特征选择方面比基线方法更有效，尤其在聚类任务中。&lt;h4&gt;结论&lt;/h4&gt;K-means UFS方法有效提升了无监督特征选择的性能，提供了一种新的解决方案。&lt;h4&gt;总结&lt;/h4&gt;本研究为高维数据的无监督特征选择提供了一种创新的方法，展示了其在聚类中的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Feature selection is important for high-dimensional data analysis and isnon-trivial in unsupervised learning problems such as dimensionality reductionand clustering. The goal of unsupervised feature selection is finding a subsetof features such that the data points from different clusters are wellseparated. This paper presents a novel method called K-means DerivedUnsupervised Feature Selection (K-means UFS). Unlike most existing spectralanalysis based unsupervised feature selection methods, we select features usingthe objective of K-means. We develop an alternating direction method ofmultipliers (ADMM) to solve the NP-hard optimization problem of our K-means UFSmodel. Extensive experiments on real datasets show that our K-means UFS is moreeffective than the baselines in selecting features for clustering.</description>
      <author>example@mail.com (Ziheng Sun, Chris Ding, Jicong Fan)</author>
      <guid isPermaLink="false">2411.15197v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>PG-SLAM: Photo-realistic and Geometry-aware RGB-D SLAM in Dynamic Environments</title>
      <link>http://arxiv.org/abs/2411.15800v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;SLAM在静态环境中表现出色，但在动态环境中的应用仍然面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种照片真实感和几何感知的RGB-D SLAM方法，以克服动态环境中的局限性。&lt;h4&gt;方法&lt;/h4&gt;方法包括三个主要模块：1) 映射动态前景（包括非刚性的人类和刚性物体），2) 重建静态背景，3) 本体定位。前景映射关注建模变形和运动，背景映射通过优化策略整合外观约束与几何对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在相机定位和场景表示方面优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;源代码将在论文接受后公开。&lt;h4&gt;总结&lt;/h4&gt;该研究为动态环境中的SLAM提供了一种新的解决方案，增强了对动态物体和静态背景的处理能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous localization and mapping (SLAM) has achieved impressiveperformance in static environments. However, SLAM in dynamic environmentsremains an open question. Many methods directly filter out dynamic objects,resulting in incomplete scene reconstruction and limited accuracy of cameralocalization. The other works express dynamic objects by point clouds, sparsejoints, or coarse meshes, which fails to provide a photo-realisticrepresentation. To overcome the above limitations, we propose a photo-realisticand geometry-aware RGB-D SLAM method by extending Gaussian splatting. Ourmethod is composed of three main modules to 1) map the dynamic foregroundincluding non-rigid humans and rigid items, 2) reconstruct the staticbackground, and 3) localize the camera. To map the foreground, we focus onmodeling the deformations and/or motions. We consider the shape priors ofhumans and exploit geometric and appearance constraints of humans and items.For background mapping, we design an optimization strategy between neighboringlocal maps by integrating appearance constraint into geometric alignment. As tocamera localization, we leverage both static background and dynamic foregroundto increase the observations for noise compensation. We explore the geometricand appearance constraints by associating 3D Gaussians with 2D optical flowsand pixel patches. Experiments on various real-world datasets demonstrate thatour method outperforms state-of-the-art approaches in terms of cameralocalization and scene representation. Source codes will be publicly availableupon paper acceptance.</description>
      <author>example@mail.com (Haoang Li, Xiangqi Meng, Xingxing Zuo, Zhe Liu, Hesheng Wang, Daniel Cremers)</author>
      <guid isPermaLink="false">2411.15800v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Implementation of Real-Time Lane Detection on Autonomous Mobile Robot</title>
      <link>http://arxiv.org/abs/2411.14873v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 9 figures 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文描述了在自主移动机器人上实现基于学习的车道检测算法。&lt;h4&gt;目的&lt;/h4&gt;实现超快速车道检测算法，以便在SEATER P2MC-BRIN原型上进行实时应用。&lt;h4&gt;方法&lt;/h4&gt;使用摄像头在Jetson Nano平台上优化算法性能，进行初步实验以评估数据处理速度和准确性。&lt;h4&gt;主要发现&lt;/h4&gt;算法在Jetson Nano平台上经过TensorRT转换后运行更为优化，CULane和TuSimple数据集的处理速度分别为101毫秒和105毫秒，比之前的模型快约22倍。&lt;h4&gt;结论&lt;/h4&gt;虽然算法在户外公共数据集上表现良好，但在室内数据集上的性能有所不足。未来工作应集中在迁移学习和微调上，以提高室内车道检测的准确性。&lt;h4&gt;总结&lt;/h4&gt;研究展示了车道检测算法的实时应用潜力，并指出了提升室内检测准确性的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ATNT61688.2024.10719329&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes the implementation of a learning-based lane detectionalgorithm on an Autonomous Mobile Robot. It aims to implement the Ultra FastLane Detection algorithm for real-time application on the SEATER P2MC-BRINprototype using a camera and optimize its performance on the Jetson Nanoplatform. Preliminary experiments were conducted to evaluate the algorithm'sperformance in terms of data processing speed and accuracy using two types ofdatasets: outdoor using a public dataset and indoor using an internal datasetfrom the indoor area of the BRIN Workshop Building in Bandung. The experimentsrevealed that the algorithm runs more optimally on the Jetson Nano platformafter conversion to TensorRT compared to the ONNX model, achieving processingspeeds of approximately 101 ms using CULane and 105 ms using TuSimple, which isabout 22 times faster than the previous model. While the algorithm demonstratesgood accuracy on the outdoor public dataset, its performance falls short on theindoor dataset. Future work should focus on transfer learning and fine-tuningto enhance indoor lane detection accuracy.</description>
      <author>example@mail.com (Midriem Mirdanies, Roni Permana Saputra, Edwar Yazid, Rozeha A. Rashid)</author>
      <guid isPermaLink="false">2411.14873v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>PRIMUS: Pretraining IMU Encoders with Multimodal Self-Supervision</title>
      <link>http://arxiv.org/abs/2411.15127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Also presented under the title "PRIMUS: Pretraining IMU Encoders with
  Multimodal and Self-Supervised Learning" at NeurIPS 2024 TSALM Workshop (Time
  Series in the Age of Large Models)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;通过嵌入个人设备的惯性测量单元（IMU）感知人类动作在健康和保健领域具有重要应用，但标记的IMU数据稀缺。&lt;h4&gt;目的&lt;/h4&gt;提出PRIMUS方法，以解决IMU领域中预训练方法理解不足的问题。&lt;h4&gt;方法&lt;/h4&gt;进行系统和统一的评估，探索多种自监督和多模态学习的预训练目标，结合自监督、多模态监督和最近邻监督。&lt;h4&gt;主要发现&lt;/h4&gt;使用PRIMUS可以显著提升下游任务性能，使用少于500个标记样本的情况下，性能提升可达15%。&lt;h4&gt;结论&lt;/h4&gt;PRIMUS在Held-out测试数据中优于现有的多模态训练方法，提升效果显著。&lt;h4&gt;代码和资源&lt;/h4&gt;为促进社区发展，相关代码和预训练的IMU编码器将在github.com/nokia-bell-labs上公开。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的PRIMUS方法为IMU领域的预训练提供了新的思路，并显著提升了模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sensing human motions through Inertial Measurement Units (IMUs) embedded inpersonal devices has enabled significant applications in health and wellness.While labeled IMU data is scarce, we can collect unlabeled or weakly labeledIMU data to model human motions. For video or text modalities, the "pretrainand adapt" approach utilizes large volumes of unlabeled or weakly labeled datafor pretraining, building a strong feature extractor, followed by adaptation tospecific tasks using limited labeled data. This approach has not been widelyadopted in the IMU domain for two reasons: (1) pretraining methods are poorlyunderstood in the context of IMU, and (2) open-source pretrained models thatgeneralize across datasets are rarely publicly available. In this paper, we aimto address the first issue by proposing PRIMUS, a method for PRetraining IMUencoderS. We conduct a systematic and unified evaluation of variousself-supervised and multimodal learning pretraining objectives. Our findingsindicate that using PRIMUS, which combines self-supervision, multimodalsupervision, and nearest-neighbor supervision, can significantly enhancedownstream performance. With fewer than 500 labeled samples per class, PRIMUSeffectively enhances downstream performance by up to 15% in held-out test data,compared to the state-of-the-art multimodal training method. To benefit thebroader community, our code and pre-trained IMU encoders will be made publiclyavailable at github.com/nokia-bell-labs upon publication.</description>
      <author>example@mail.com (Arnav M. Das, Chi Ian Tang, Fahim Kawsar, Mohammad Malekzadeh)</author>
      <guid isPermaLink="false">2411.15127v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Weakly supervised image segmentation for defect-based grading of fresh produce</title>
      <link>http://arxiv.org/abs/2411.16219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在农业中，基于图像的机器学习常常受限于数据和注释的匮乏，导致模型预测质量难以提高。&lt;h4&gt;目的&lt;/h4&gt;评估去中心化供应链中香蕉的后收获质量。&lt;h4&gt;方法&lt;/h4&gt;采用全景分割技术检测和分割香蕉图像中的表面缺陷，通过弱监督与粗略标签替代耗时的像素级注释。&lt;h4&gt;主要发现&lt;/h4&gt;收集了476张在真实场景下拍摄的香蕉智能手机图像，并对其进行淤伤和伤疤的注释。使用最近发布的图像分割基础模型Segment Anything Model (SAM)，从粗略边框生成稠密注释以训练分割模型。&lt;h4&gt;结论&lt;/h4&gt;显著减少了人工工作量，同时在农业环境中实现了77.6%的全景质量评分，证明了SAM在有限数据下的低努力高精度分割潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了利用弱监督和全景分割在农业图像处理中的有效性，尤其是在数据稀缺的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implementing image-based machine learning in agriculture is often limited byscarce data and annotations, making it hard to achieve high-quality modelpredictions. This study tackles the issue of postharvest quality assessment ofbananas in decentralized supply chains. We propose a method to detect andsegment surface defects in banana images using panoptic segmentation toquantify defect size and number. Instead of time-consuming pixel-levelannotations, we use weak supervision with coarse labels. A dataset of 476smartphone images of bananas was collected under real-world field conditionsand annotated for bruises and scars. Using the Segment Anything Model (SAM), arecently published foundation model for image segmentation, we generated denseannotations from coarse bounding boxes to train a segmentation model,significantly reducing manual effort while achieving a panoptic quality scoreof 77.6%. This demonstrates SAM's potential for low-effort, accuratesegmentation in agricultural settings with limited data.</description>
      <author>example@mail.com (Manuel Knott, Divinefavour Odion, Sameer Sontakke, Anup Karwa, Thijs Defraeye)</author>
      <guid isPermaLink="false">2411.16219v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Training Physics-Driven Deep Learning Reconstruction without Raw Data Access for Equitable Fast MRI</title>
      <link>http://arxiv.org/abs/2411.13022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物理驱动的深度学习（PD-DL）方法在快速磁共振成像（MRI）重建中变得流行，尽管其加速率高于现有的临床快速MRI技术，但在专门的MRI中心之外使用受限。&lt;h4&gt;目的&lt;/h4&gt;解决PD-DL在训练集不足以代表某些病理或人群时的泛化困难，建议对目标人群进行微调以改善重建效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CUPID的压缩性启发的无监督学习方法，仅使用从MRI扫描仪导出的常规临床重建图像进行高质量的PD-DL训练。&lt;h4&gt;主要发现&lt;/h4&gt;CUPID在输出质量上与需要原始k空间数据访问的PD-DL训练策略相当，同时优于传统的压缩感知（CS）和最先进的生成方法。&lt;h4&gt;结论&lt;/h4&gt;CUPID在零-shot训练设置中也表现出有效性，适用于回顾性和前瞻性子采样收集，证明了其训练负担最小。&lt;h4&gt;总结&lt;/h4&gt;CUPID为提高PD-DL技术的可用性提供了一种有效的解决方案，尤其是在农村和服务不足地区。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physics-driven deep learning (PD-DL) approaches have become popular forimproved reconstruction of fast magnetic resonance imaging (MRI) scans. Eventhough PD-DL offers higher acceleration rates compared to existing clinicalfast MRI techniques, their use has been limited outside specialized MRIcenters. One impediment for their deployment is the difficulties withgeneralization to pathologies or population groups that are notwell-represented in training sets. This has been noted in several studies, andfine-tuning on target populations to improve reconstruction has been suggested.However, current approaches for PD-DL training require access to raw k-spacemeasurements, which is typically only available at specialized MRI centers thathave research agreements for such data access. This is especially an issue forrural and underserved areas, where commercial MRI scanners only provide accessto a final reconstructed image. To tackle these challenges, we proposeCompressibility-inspired Unsupervised Learning via Parallel Imaging Fidelity(CUPID) for high-quality PD-DL training, using only routine clinicalreconstructed images exported from an MRI scanner. CUPID evaluates the goodnessof the output with a compressibility-based approach, while ensuring that theoutput stays consistent with the clinical parallel imaging reconstructionthrough well-designed perturbations. Our results show that CUPID achievessimilar quality compared to well-established PD-DL training strategies thatrequire raw k-space data access, while outperforming conventional compressedsensing (CS) and state-of-the-art generative methods. We also demonstrate itseffectiveness in a zero-shot training setup for retrospectively andprospectively sub-sampled acquisitions, attesting to its minimal trainingburden.</description>
      <author>example@mail.com (Yaşar Utku Alçalar, Merve Gülle, Mehmet Akçakaya)</author>
      <guid isPermaLink="false">2411.13022v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Highly Efficient and Unsupervised Framework for Moving Object Detection in Satellite Videos</title>
      <link>http://arxiv.org/abs/2411.15895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;卫星视频中的运动物体检测（SVMOD）是一项具有挑战性的任务，主要由于目标特征极其微弱和尺寸小。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的无监督框架来解决SVMOD问题。&lt;h4&gt;方法&lt;/h4&gt;采用传统方法生成的伪标签在训练过程中演变，以提高检测性能，并提出一种稀疏卷积无锚检测网络，通过将多帧图像转换为稀疏时空点云表示，跳过背景区域的冗余计算。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够以每秒处理98.8帧的速度处理1024x1024的图像，并且达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;通过这两种设计，实现了高效性（标签和计算效率）和有效性的结合。&lt;h4&gt;总结&lt;/h4&gt;研究提供了重新标注的数据集和代码，以促进SVMOD的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPAMI.2024.3409824&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chaoxiao12/moving-object-detection-in-satellite-videos-hieum&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Moving object detection in satellite videos (SVMOD) is a challenging task dueto the extremely dim and small target characteristics. Current learning-basedmethods extract spatio-temporal information from multi-frame denserepresentation with labor-intensive manual labels to tackle SVMOD, which needshigh annotation costs and contains tremendous computational redundancy due tothe severe imbalance between foreground and background regions. In this paper,we propose a highly efficient unsupervised framework for SVMOD. Specifically,we propose a generic unsupervised framework for SVMOD, in which pseudo labelsgenerated by a traditional method can evolve with the training process topromote detection performance. Furthermore, we propose a highly efficient andeffective sparse convolutional anchor-free detection network by sampling thedense multi-frame image form into a sparse spatio-temporal point cloudrepresentation and skipping the redundant computation on background regions.Coping these two designs, we can achieve both high efficiency (label andcomputation efficiency) and effectiveness. Extensive experiments demonstratethat our method can not only process 98.8 frames per second on 1024x1024 imagesbut also achieve state-of-the-art performance. The relabeled dataset and codeare available athttps://github.com/ChaoXiao12/Moving-object-detection-in-satellite-videos-HiEUM.</description>
      <author>example@mail.com (C. Xiao, W. An, Y. Zhang, Z. Su, M. Li, W. Sheng, M. Pietikäinen, L. Liu)</author>
      <guid isPermaLink="false">2411.15895v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Online Item Cold-Start Recommendation with Popularity-Aware Meta-Learning</title>
      <link>http://arxiv.org/abs/2411.11225v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures, to be published in KDD '25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着电子商务和短视频的兴起，在线推荐系统在捕捉用户兴趣和实时更新新项目方面变得越来越重要。&lt;h4&gt;目的&lt;/h4&gt;解决在线推荐中的冷启动问题，特别是在流数据环境下的推荐效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为PAM（Popularity-Aware Meta-learning）的模型无关推荐算法，通过预定义的项目流行度阈值将传入数据划分为不同的元学习任务。&lt;h4&gt;主要发现&lt;/h4&gt;PAM能够根据不同流行度水平区分和重新加权与行为和内容相关的特征，显著减少额外的计算和存储成本。&lt;h4&gt;结论&lt;/h4&gt;PAM通过数据增强和针对低流行度任务的自监督损失有效缓解了冷启动样本稀缺导致的监督不足问题，实验结果表明其在多种公共数据集上优于其他基准方法。&lt;h4&gt;总结&lt;/h4&gt;PAM为解决在线流数据场景中的冷启动挑战提供了有效的方法，展示了其在推荐系统中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rise of e-commerce and short videos, online recommender systems thatcan capture users' interests and update new items in real-time play anincreasingly important role. In both online and offline recommendation, thecold-start problem due to interaction sparsity has been affecting therecommendation effect of cold-start items, which is also known as the long-tailproblem of item distribution. Many cold-start scheme based on fine-tuning orknowledge transferring shows excellent performance on offline recommendation.Yet, these schemes are infeasible for online recommendation on streaming datapipelines due to different training method, computational overhead and timeconstraints. Inspired by the above questions, we propose a model-agnosticrecommendation algorithm called Popularity-Aware Meta-learning (PAM), toaddress the item cold-start problem under streaming data settings. PAM dividesthe incoming data into different meta-learning tasks by predefined itempopularity thresholds. The model can distinguish and reweight behavior-relatedand content-related features in each task based on their different roles indifferent popularity levels, thus adapting to recommendations for cold-startsamples. These task-fixing design significantly reduces additional computationand storage costs compared to offline methods. Furthermore, PAM also introduceddata augmentation and an additional self-supervised loss specifically designedfor low-popularity tasks, leveraging insights from high-popularity samples.This approach effectively mitigates the issue of inadequate supervision due tothe scarcity of cold-start samples. Experimental results across multiple publicdatasets demonstrate the superiority of our approach over other baselinemethods in addressing cold-start challenges in online streaming data scenarios.</description>
      <author>example@mail.com (Yunze Luo, Yuezihan Jiang, Yinjie Jiang, Gaode Chen, Jingchi Wang, Kaigui Bian, Peiyi Li, Qi Zhang)</author>
      <guid isPermaLink="false">2411.11225v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Context-Aware Multimodal Pretraining</title>
      <link>http://arxiv.org/abs/2411.15099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模多模态表示学习在测试时成功优化零-shot迁移。&lt;h4&gt;目的&lt;/h4&gt;提出一种扩展的多模态预训练方法，以增强表示支持少-shot适应能力。&lt;h4&gt;方法&lt;/h4&gt;通过设计新的目标，使表示能够适应额外上下文，训练视觉语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;在21个下游任务中，测试时样本效率提高了最多四倍，平均少-shot适应增益超过5%。&lt;h4&gt;结论&lt;/h4&gt;使用简单的、无需训练的基于度量的适应机制，表示超越了复杂的优化方案，简化了对新领域的泛化。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，通过改进预训练方法，可以显著提升少-shot适应能力，同时保持零-shot泛化性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale multimodal representation learning successfully optimizes forzero-shot transfer at test time. Yet the standard pretraining paradigm(contrastive learning on large amounts of image-text data) does not explicitlyencourage representations to support few-shot adaptation. In this work, wepropose a simple, but carefully designed extension to multimodal pretrainingwhich enables representations to accommodate additional context. Using thisobjective, we show that vision-language models can be trained to exhibitsignificantly increased few-shot adaptation: across 21 downstream tasks, wefind up to four-fold improvements in test-time sample efficiency, and averagefew-shot adaptation gains of over 5%, while retaining zero-shot generalizationperformance across model scales and training durations. In particular, equippedwith simple, training-free, metric-based adaptation mechanisms, ourrepresentations easily surpass more complex and expensive optimization-basedschemes, vastly simplifying generalization to new domains.</description>
      <author>example@mail.com (Karsten Roth, Zeynep Akata, Dima Damen, Ivana Balažević, Olivier J. Hénaff)</author>
      <guid isPermaLink="false">2411.15099v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>UltraSam: A Foundation Model for Ultrasound using Large Open-Access Segmentation Datasets</title>
      <link>http://arxiv.org/abs/2411.16222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动化超声图像分析因解剖结构复杂性和标注数据有限而面临挑战。&lt;h4&gt;目的&lt;/h4&gt;采取数据中心的方法，组建最大的公共超声分割数据集，并训练适用于超声的多功能视觉基础模型。&lt;h4&gt;方法&lt;/h4&gt;编制US-43d，这是一个大型的43个开放获取超声数据集的集合，包含超过28万张图像和50多种解剖结构的分割掩膜；引入UltraSam，这是对Segment Anything Model (SAM) 的适应，支持点和框提示；将UltraSam作为模型初始化，进行各种下游分析任务的微调。&lt;h4&gt;主要发现&lt;/h4&gt;UltraSam在三个不同的公共数据集上表现显著优于现有的SAM风格模型；UltraSam初始化的视觉变换器在各种下游分割和分类任务中超越了以ImageNet、SAM和MedSAM初始化的模型。&lt;h4&gt;结论&lt;/h4&gt;编制了US-43d，一个大规模统一的超声数据集，并推出UltraSam，一个强大的多用途SAM风格模型。我们在https://github.com/CAMMA-public/UltraSam发布了代码和预训练模型，邀请社区贡献高质量数据集。&lt;h4&gt;总结&lt;/h4&gt;通过构建US-43d和开发UltraSam，推动超声图像分析的自动化进程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/camma-public/ultrasam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Automated ultrasound image analysis is challenging due to anatomicalcomplexity and limited annotated data. To tackle this, we take a data-centricapproach, assembling the largest public ultrasound segmentation dataset andtraining a versatile visual foundation model tailored for ultrasound.  Methods: We compile US-43d, a large-scale collection of 43 open-accessultrasound datasets with over 280,000 images and segmentation masks for morethan 50 anatomical structures. We then introduce UltraSam, an adaptation of theSegment Anything Model (SAM) that is trained on US-43d and supports both point-and box-prompts. Finally, we introduce a new use case for SAM-style models byusing UltraSam as a model initialization that can be fine-tuned for variousdownstream analysis tasks, demonstrating UltraSam's foundational capabilities.  Results: UltraSam achieves vastly improved performance over existingSAM-style models for prompt-based segmentation on three diverse publicdatasets. Moreover, an UltraSam-initialized Vision Transformer surpassesImageNet-, SAM-, and MedSAM-initialized models in various downstreamsegmentation and classification tasks, highlighting UltraSam's effectiveness asa foundation model.  Conclusion: We compile US-43d, a large-scale unified ultrasound dataset, andintroduce UltraSam, a powerful multi-purpose SAM-style model for ultrasoundimages. We release our code and pretrained models athttps://github.com/CAMMA-public/UltraSam and invite the community to furtherthis effort by contributing high-quality datasets.</description>
      <author>example@mail.com (Adrien Meyer, Aditya Murali, Didier Mutter, Nicolas Padoy)</author>
      <guid isPermaLink="false">2411.16222v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>From Jack of All Trades to Master of One: Specializing LLM-based Autoraters to a Test Set</title>
      <link>http://arxiv.org/abs/2411.15387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型（LLMs）变得越来越强大，人工评估在大规模应用中变得不可行，自动化评估指标成为常态。&lt;h4&gt;目的&lt;/h4&gt;设计一种方法，使自动评估器（Autorater）能够针对特定测试集进行专门化，以提高评估的准确性。&lt;h4&gt;方法&lt;/h4&gt;通过利用历史评分构建上下文学习（ICL）示例，专门化一个经过提示的自动评估器。&lt;h4&gt;主要发现&lt;/h4&gt;在细粒度机器翻译评估任务中，该专门化方法比现有的XCOMET指标分别提高了54%和119%（在WMT'23和WMT'24测试集上）。&lt;h4&gt;结论&lt;/h4&gt;该方法在不同的ICL示例数量、LLM基础模型、评估系统和评估任务中表现出良好的可推广性和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;通过对评估器的专门化设计，可以显著提高机器翻译等任务的自动评估性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As LLMs continue to become more powerful and versatile, human evaluation hasquickly become intractable at scale and reliance on automatic metrics hasbecome the norm. Recently, it has been shown that LLMs are themselvesstate-of-the-art evaluators for many tasks. These Autoraters are typicallydesigned so that they generalize to new systems and test sets. In practice,however, evaluation is performed on a small set of fixed, canonical test sets,which are carefully curated to measure certain capabilities of interest and arenot changed frequently. In this work, we design a method which specializes aprompted Autorater to a given test set, by leveraging historical ratings on thetest set to construct in-context learning (ICL) examples. We evaluate ourSpecialist method on the task of fine-grained machine translation evaluation,and show that it dramatically outperforms the state-of-the-art XCOMET metric by54% and 119% on the WMT'23 and WMT'24 test sets, respectively. We performextensive analyses to understand the representations learned by our Specialistmetrics, and how variability in rater behavior affects their performance. Wealso verify the generalizability and robustness of our Specialist method fordesigning automatic metrics across different numbers of ICL examples, LLMbackbones, systems to evaluate, and evaluation tasks.</description>
      <author>example@mail.com (Mara Finkelstein, Dan Deutsch, Parker Riley, Juraj Juraska, Geza Kovacs, Markus Freitag)</author>
      <guid isPermaLink="false">2411.15387v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DF-GNN: Dynamic Fusion Framework for Attention Graph Neural Networks on GPUs</title>
      <link>http://arxiv.org/abs/2411.16127v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;注意力图神经网络（AT-GNNs），如GAT和图转换器，表现优于其他GNN，但现有系统在GPU上训练AT-GNNs效率低下。&lt;h4&gt;目的&lt;/h4&gt;提出一种动态核融合框架DF-GNN，以解决AT-GNN训练中的计算模式复杂性问题。&lt;h4&gt;方法&lt;/h4&gt;DF-GNN引入动态双层线程调度策略，灵活调整线程调度，同时保留融合内核中共享内存的优势，并为AT-GNN操作定制特定线程调度，考虑超节点带来的性能瓶颈转移。&lt;h4&gt;主要发现&lt;/h4&gt;DF-GNN在多个GNN模型和数据集上评估显示，其性能超越现有GNN内核优化工作，如cuGraph和dgNN，速度提升高达7.0倍。&lt;h4&gt;结论&lt;/h4&gt;DF-GNN在与流行的GNN计算框架DGL进行端到端训练比较时，平均提升速度为2.16倍，显示出其显著的效率提升潜力。&lt;h4&gt;总结&lt;/h4&gt;DF-GNN通过动态线程调度和核融合显著提高了AT-GNNs的训练效率，解决了现有技术中的诸多瓶颈。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Attention Graph Neural Networks (AT-GNNs), such as GAT and Graph Transformer,have demonstrated superior performance compared to other GNNs. However,existing GNN systems struggle to efficiently train AT-GNNs on GPUs due to theirintricate computation patterns. The execution of AT-GNN operations withoutkernel fusion results in heavy data movement and significant kernel launchoverhead, while fixed thread scheduling in existing GNN kernel fusionstrategies leads to sub-optimal performance, redundant computation andunbalanced workload. To address these challenges, we propose a dynamic kernelfusion framework, DF-GNN, for the AT-GNN family. DF-GNN introduces a dynamicbi-level thread scheduling strategy, enabling flexible adjustments to threadscheduling while retaining the benefits of shared memory within the fusedkernel. DF-GNN tailors specific thread scheduling for operations in AT-GNNs andconsiders the performance bottleneck shift caused by the presence of supernodes. Additionally, DF-GNN is integrated with the PyTorch framework for highprogrammability. Evaluations across diverse GNN models and multiple datasetsreveal that DF-GNN surpasses existing GNN kernel optimization works likecuGraph and dgNN, with speedups up to $7.0\times$ over the state-of-the-artnon-fusion DGL sparse library. Moreover, it achieves an average speedup of$2.16\times$ in end-to-end training compared to the popular GNN computingframework DGL.</description>
      <author>example@mail.com (Jiahui Liu, Zhenkun Cai, Zhiyong Chen, Minjie Wang)</author>
      <guid isPermaLink="false">2411.16127v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Autonomous Multi-Robot Exploration Strategies for 3D Environments with Fire Detection Capabilitie</title>
      <link>http://arxiv.org/abs/2411.15953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The copyright may be transferred to IEEE after acceptance of paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文综述了在2D和3D环境中多机器人系统的探索策略，重点关注建筑探索和火灾检测。&lt;h4&gt;目的&lt;/h4&gt;强调传统算法在环境变化时面临的挑战，并探索更有效的探索方式。&lt;h4&gt;方法&lt;/h4&gt;采用模块化方法，整合定位、地图构建和轨迹规划，使用基于点云数据生成的OctoMap框架。&lt;h4&gt;主要发现&lt;/h4&gt;通过潜在场实现障碍物避让，确保在动态环境中的安全导航。&lt;h4&gt;结论&lt;/h4&gt;为多机器人协调探索算法的进步奠定基础，提升其在现实场景中的适用性。&lt;h4&gt;未来研究方向&lt;/h4&gt;包括去中心化地图创建、无人机协调探索及对时变环境的适应。&lt;h4&gt;总结&lt;/h4&gt;本研究为多机器人系统在复杂环境中的探索提供了新的视角和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a comprehensive overview of exploration strategiesutilized in both 2D and 3D environments, focusing on autonomous multi-robotsystems designed for building exploration and fire detection. We explore thelimitations of traditional algorithms that rely on prior knowledge andpredefined maps, emphasizing the challenges faced when environments undergochanges that invalidate these maps. Our modular approach integrateslocalization, mapping, and trajectory planning to facilitate effectiveexploration using an OctoMap framework generated from point cloud data. Theexploration strategy incorporates obstacle avoidance through potential fields,ensuring safe navigation in dynamic settings. Additionally, I propose futureresearch directions, including decentralized map creation, coordinatedexploration among unmanned aerial vehicles (UAVs), and adaptations totime-varying environments. This work serves as a foundation for advancingcoordinated multi-robot exploration algorithms, enhancing their applicabilityin real-world scenarios.</description>
      <author>example@mail.com (Ankit Shaw)</author>
      <guid isPermaLink="false">2411.15953v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Effective Predictive Modeling for Emergency Department Visits and Evaluating Exogenous Variables Impact: Using Explainable Meta-learning Gradient Boosting</title>
      <link>http://arxiv.org/abs/2411.11275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;管理者和临床医生长期以来努力准确预测急诊科（ED）访客，以优化资源分配，但面临诸多挑战。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在提出一种新的元学习梯度提升（Meta-learning Gradient Booster, Meta-ED）方法，以精确预测每日急诊科访客。&lt;h4&gt;方法&lt;/h4&gt;Meta-ED利用来自澳大利亚堪培拉医院的23年综合数据集，包括社会人口特征、医疗服务使用、慢性疾病、诊断和气候参数，结合了四个基础学习器（Catboost、随机森林、Extra Tree和LightGBoost）和一个顶层学习器（多层感知器MLP）。&lt;h4&gt;主要发现&lt;/h4&gt;Meta-ED模型在23种模型的比较分析中表现出显著的准确性，达85.7%（95% CI；85.4%，86.0%），相比于其他主要技术（如XGBoost、随机森林、AdaBoost、LightGBoost和Extra Tree）分别提升了58.6%、106.3%、22.3%、7.0%和15.7%。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，Meta-ED在预测急诊科访客数量时具有显著的精确性，尤其是加入天气相关特征后，预测准确性提高了3.25%。&lt;h4&gt;总结&lt;/h4&gt;Meta-ED被确立为每日急诊科访客精确预测的基础模型，显示出良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over an extensive duration, administrators and clinicians have endeavoured topredict Emergency Department (ED) visits with precision, aiming to optimiseresource distribution. Despite the proliferation of diverse AI-driven modelstailored for precise prognostication, this task persists as a formidablechallenge, besieged by constraints such as restrained generalisability,susceptibility to overfitting and underfitting, scalability issues, and complexfine-tuning hyper-parameters. In this study, we introduce a novel Meta-learningGradient Booster (Meta-ED) approach for precisely forecasting daily ED visitsand leveraging a comprehensive dataset of exogenous variables, includingsocio-demographic characteristics, healthcare service use, chronic diseases,diagnosis, and climate parameters spanning 23 years from Canberra Hospital inACT, Australia. The proposed Meta-ED consists of four foundationallearners-Catboost, Random Forest, Extra Tree, and lightGBoost-alongside adependable top-level learner, Multi-Layer Perceptron (MLP), by combining theunique capabilities of varied base models (sub-learners). Our study assessesthe efficacy of the Meta-ED model through an extensive comparative analysisinvolving 23 models. The evaluation outcomes reveal a notable superiority ofMeta-ED over the other models in accuracy at 85.7% (95% CI ;85.4%, 86.0%) andacross a spectrum of 10 evaluation metrics. Notably, when compared withprominent techniques, XGBoost, Random Forest (RF), AdaBoost, LightGBoost, andExtra Tree (ExT), Meta-ED showcases substantial accuracy enhancements of 58.6%,106.3%, 22.3%, 7.0%, and 15.7%, respectively. Furthermore, incorporatingweather-related features demonstrates a 3.25% improvement in the predictionaccuracy of visitors' numbers. The encouraging outcomes of our study underscoreMeta-ED as a foundation model for the precise prediction of daily ED visitors.</description>
      <author>example@mail.com (Mehdi Neshat, Michael Phipps, Nikhil Jha, Danial Khojasteh, Michael Tong, Amir Gandomi)</author>
      <guid isPermaLink="false">2411.11275v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Gotta Hear Them All: Sound Source Aware Vision to Audio Generation</title>
      <link>http://arxiv.org/abs/2411.15447v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 9 figures, source code released at
  https://github.com/wguo86/SSV2A&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉到音频（V2A）合成在多媒体中有广泛应用，但现有方法在生成的沉浸感和表现力上有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种声音源感知的V2A生成器（SSV2A），解决现有方法忽视局部声音源的问题。&lt;h4&gt;方法&lt;/h4&gt;SSV2A能够通过视觉检测和跨模态翻译局部感知多模态声音源，学习交叉模态声音源流形（CMSS），并将其语义整合到丰富的音频表示中。&lt;h4&gt;主要发现&lt;/h4&gt;SSV2A在生成保真度和相关性方面超过了现有最先进的方法，并能通过视觉、文本和音频条件实现直观的V2A控制。&lt;h4&gt;结论&lt;/h4&gt;SSV2A是首个在声音源级别上解决V2A生成的问题，并展示了其优越的性能。&lt;h4&gt;总结&lt;/h4&gt;通过创建新的视觉-音频数据集VGGS3和设计声音源匹配评分，SSV2A在多模态生成中表现出色，可在线试用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wguo86/ssv2a&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-to-audio (V2A) synthesis has broad applications in multimedia. Recentadvancements of V2A methods have made it possible to generate relevant audiosfrom inputs of videos or still images. However, the immersiveness andexpressiveness of the generation are limited. One possible problem is thatexisting methods solely rely on the global scene and overlook details of localsounding objects (i.e., sound sources). To address this issue, we propose aSound Source-Aware V2A (SSV2A) generator. SSV2A is able to locally perceivemultimodal sound sources from a scene with visual detection and cross-modalitytranslation. It then contrastively learns a Cross-Modal Sound Source (CMSS)Manifold to semantically disambiguate each source. Finally, we attentively mixtheir CMSS semantics into a rich audio representation, from which a pretrainedaudio generator outputs the sound. To model the CMSS manifold, we curate anovel single-sound-source visual-audio dataset VGGS3 from VGGSound. We alsodesign a Sound Source Matching Score to measure localized audio relevance. Thisis to our knowledge the first work to address V2A generation at thesound-source level. Extensive experiments show that SSV2A surpassesstate-of-the-art methods in both generation fidelity and relevance. We furtherdemonstrate SSV2A's ability to achieve intuitive V2A control by compositingvision, text, and audio conditions. Our SSV2A generation can be tried and heardat https://ssv2a.github.io/SSV2A-demo .</description>
      <author>example@mail.com (Wei Guo, Heng Wang, Weidong Cai, Jianbo Ma)</author>
      <guid isPermaLink="false">2411.15447v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Graph Adapter of EEG Foundation Models for Parameter Efficient Fine Tuning</title>
      <link>http://arxiv.org/abs/2411.16155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在使用脑电图（EEG）数据诊断心理疾病时，神经网络模型（如变压器）被用于捕捉时间动态。同时，了解EEG传感器之间的空间关系也很重要，通常使用图神经网络（GNN）。&lt;h4&gt;目的&lt;/h4&gt;提出EEG-GraphAdapter（EGA），一种参数高效的微调方法，以应对同时捕捉时间和空间特征时的计算成本问题。&lt;h4&gt;方法&lt;/h4&gt;EGA集成在预训练的时间主干模型中，作为基于GNN的模块进行单独微调，同时保持主干模型的参数不变。这使得能够获取EEG信号的空间表示，显著减少计算开销和数据需求。&lt;h4&gt;主要发现&lt;/h4&gt;在针对主要抑郁障碍和异常检测的医疗相关下游任务中，EGA在F1分数上相比于主干模型BENDR提高了最多16.1%的性能。&lt;h4&gt;结论&lt;/h4&gt;EGA有效地提高了EEG信号的空间特征捕获能力，降低了对计算资源和数据集的要求，从而改善了模型在特定任务上的表现。&lt;h4&gt;总结&lt;/h4&gt;EEG-GraphAdapter（EGA）通过参数高效的方法解决了在EEG数据分析中面临的计算和数据限制，显著提升了心理疾病诊断的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In diagnosing mental diseases from electroencephalography (EEG) data, neuralnetwork models such as Transformers have been employed to capture temporaldynamics. Additionally, it is crucial to learn the spatial relationshipsbetween EEG sensors, for which Graph Neural Networks (GNNs) are commonly used.However, fine-tuning large-scale complex neural network models simultaneouslyto capture both temporal and spatial features increases computational costs dueto the more significant number of trainable parameters. It causes the limitedavailability of EEG datasets for downstream tasks, making it challenging tofine-tune large models effectively. We propose EEG-GraphAdapter (EGA), aparameter-efficient fine-tuning (PEFT) approach to address these challenges.EGA is integrated into pre-trained temporal backbone models as a GNN-basedmodule and fine-tuned itself alone while keeping the backbone model parametersfrozen. This enables the acquisition of spatial representations of EEG signalsfor downstream tasks, significantly reducing computational overhead and datarequirements. Experimental evaluations on healthcare-related downstream tasksof Major Depressive Disorder and Abnormality Detection demonstrate that our EGAimproves performance by up to 16.1% in the F1-score compared with the backboneBENDR model.</description>
      <author>example@mail.com (Toyotaro Suzumura, Hiroki Kanezashi, Shotaro Akahori)</author>
      <guid isPermaLink="false">2411.16155v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Language Driven Occupancy Prediction</title>
      <link>http://arxiv.org/abs/2411.16072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统方法通过粗略的体素与文本之间的对应关系来监督网络，通常使用图像特征作为中介，或者依赖于体素模型视图投影中的噪声和稀疏对应关系。&lt;h4&gt;目的&lt;/h4&gt;提出LOcc框架，以实现开放词汇占据（OVO）预测的有效性和可推广性。&lt;h4&gt;方法&lt;/h4&gt;开发了一种语义传递标注管道，生成密集且细粒度的3D语言占据基础真相，通过将图像的文本标签转移到LiDAR点云，最终到达体素，从而建立精确的体素与文本对应关系。同时，替换监督占据模型的原始预测头，用于二元占据状态的几何头和语言特征的语言头。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验，证明了语义传递标注管道能够产生更准确的伪标注基础真相，减少了人工标注的劳动强度。LOcc在各种架构下的验证结果显示，所有模型在Occ3D-nuScenes数据集上持续超越了最先进的零样本占据预测方法。&lt;h4&gt;结论&lt;/h4&gt;即使基于更简单的BEVDet模型，输入分辨率为256 * 704，Occ-BEVDet的mIoU达到了20.29，超越了依赖于时间图像、更高分辨率输入或更大骨干网络的先前方法。&lt;h4&gt;总结&lt;/h4&gt;LOcc框架通过创新的方法提升了开放词汇占据预测的性能，提供了高效且准确的解决方案，相关代码可在GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/pkqbajng/locc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce LOcc, an effective and generalizable framework foropen-vocabulary occupancy (OVO) prediction. Previous approaches typicallysupervise the networks through coarse voxel-to-text correspondences via imagefeatures as intermediates or noisy and sparse correspondences from voxel-basedmodel-view projections. To alleviate the inaccurate supervision, we propose asemantic transitive labeling pipeline to generate dense and finegrained 3Dlanguage occupancy ground truth. Our pipeline presents a feasible way to diginto the valuable semantic information of images, transferring text labels fromimages to LiDAR point clouds and utimately to voxels, to establish precisevoxel-to-text correspondences. By replacing the original prediction head ofsupervised occupancy models with a geometry head for binary occupancy statesand a language head for language features, LOcc effectively uses the generatedlanguage ground truth to guide the learning of 3D language volume. Throughextensive experiments, we demonstrate that our semantic transitive labelingpipeline can produce more accurate pseudo-labeled ground truth, diminishinglabor-intensive human annotations. Additionally, we validate LOcc acrossvarious architectures, where all models consistently outperform state-ofthe-artzero-shot occupancy prediction approaches on the Occ3D-nuScenes dataset.Notably, even based on the simpler BEVDet model, with an input resolution of256 * 704,Occ-BEVDet achieves an mIoU of 20.29, surpassing previous approachesthat rely on temporal images, higher-resolution inputs, or larger backbonenetworks. The code for the proposed method is available athttps://github.com/pkqbajng/LOcc.</description>
      <author>example@mail.com (Zhu Yu, Bowen Pang, Lizhe Liu, Runmin Zhang, Qihao Peng, Maochun Luo, Sheng Yang, Mingxia Chen, Si-Yuan Cao, Hui-Liang Shen)</author>
      <guid isPermaLink="false">2411.16072v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>OphCLIP: Hierarchical Retrieval-Augmented Learning for Ophthalmic Surgical Video-Language Pretraining</title>
      <link>http://arxiv.org/abs/2411.15421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;外科手术实践涉及复杂的视觉解读、操作技能和高级医学知识，导致外科视觉语言预训练面临挑战，尤其是数据标注不足的情况。&lt;h4&gt;目的&lt;/h4&gt;提出OphCLIP，一个专门为眼科手术工作流程理解设计的层次检索增强视觉语言预训练框架。&lt;h4&gt;方法&lt;/h4&gt;利用构建的OphVL数据集，这是一个包含超过375K层次结构视频-文本对的大规模综合集合，包含各种手术、阶段、工具等属性的组合。&lt;h4&gt;主要发现&lt;/h4&gt;OphCLIP能够通过短视频片段与详细叙述描述的对齐，以及完整视频与结构化标题的对齐，学习细粒度和长期视觉表示，捕捉复杂的外科细节和高级程序见解。&lt;h4&gt;结论&lt;/h4&gt;OphCLIP设计的检索增强预训练框架能够利用未被充分探讨的大规模无声外科手术视频，自动检索语义相关内容，以增强叙述视频的表示学习。&lt;h4&gt;总结&lt;/h4&gt;在11个数据集上评估阶段识别和多工具识别的结果表明，OphCLIP具有良好的泛化能力和优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surgical practice involves complex visual interpretation, procedural skills,and advanced medical knowledge, making surgical vision-language pretraining(VLP) particularly challenging due to this complexity and the limitedavailability of annotated data. To address the gap, we propose OphCLIP, ahierarchical retrieval-augmented vision-language pretraining frameworkspecifically designed for ophthalmic surgical workflow understanding. OphCLIPleverages the OphVL dataset we constructed, a large-scale and comprehensivecollection of over 375K hierarchically structured video-text pairs with tens ofthousands of different combinations of attributes (surgeries,phases/operations/actions, instruments, medications, as well as more advancedaspects like the causes of eye diseases, surgical objectives, and postoperativerecovery recommendations, etc). These hierarchical video-text correspondencesenable OphCLIP to learn both fine-grained and long-term visual representationsby aligning short video clips with detailed narrative descriptions and fullvideos with structured titles, capturing intricate surgical details andhigh-level procedural insights, respectively. Our OphCLIP also designs aretrieval-augmented pretraining framework to leverage the underexploredlarge-scale silent surgical procedure videos, automatically retrievingsemantically relevant content to enhance the representation learning ofnarrative videos. Evaluation across 11 datasets for phase recognition andmulti-instrument identification shows OphCLIP's robust generalization andsuperior performance.</description>
      <author>example@mail.com (Ming Hu, Kun Yuan, Yaling Shen, Feilong Tang, Xiaohao Xu, Lin Zhou, Wei Li, Ying Chen, Zhongxing Xu, Zelin Peng, Siyuan Yan, Vinkle Srivastav, Diping Song, Tianbin Li, Danli Shi, Jin Ye, Nicolas Padoy, Nassir Navab, Junjun He)</author>
      <guid isPermaLink="false">2411.15421v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Botfip-LLM: An Enhanced Multimodal Scientific Computing Framework Leveraging Knowledge Distillation from Large Language Models</title>
      <link>http://arxiv.org/abs/2411.15525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，人工智能技术的引入对科学计算带来了变革，但AI模型通常只关注单一任务和单一模态数据处理，限制了其应用。&lt;h4&gt;目的&lt;/h4&gt;为了提高Botfip框架在处理公式字符串方面的学习能力，并扩展其在相关任务中的适用性，提出Botfip-LLM框架。&lt;h4&gt;方法&lt;/h4&gt;Botfip-LLM框架基于知识蒸馏，结合预训练的大型语言模型，以对齐符号树数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验分析表明，LLM的选择至关重要，ChatGLM-2在训练和测试中表现优于其他模型。&lt;h4&gt;结论&lt;/h4&gt;Botfip-LLM不仅在性能、泛化性和推断能力上超越了原始的Botfip模型，还显著增强了其在与公式字符串相关任务中的适用性，从而能够处理更多样化的任务。&lt;h4&gt;总结&lt;/h4&gt;Botfip-LLM框架通过引入大型语言模型，解决了Botfip在多模态学习中的不足，推动了科学计算领域的多样性和深度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, the introduction of AI technologies has broughttransformative changes to scientific computing. However, AI models typicallyfocus on single-task and single-modal data processing, limiting theirapplication. To address this, multimodal scientific computing frameworks havebecome a trend. The Botfip framework aligns function images with symbolicoperation trees through multimodal training, extracting deep scientificinformation. However, Botfip struggles with processing Formula Strings, leadingto inadequate understanding in multimodal learning. To enhance Botfip'slearning of Formula Strings and expand its applicability to related tasks, wepropose the Botfip-LLM framework based on knowledge distillation, incorporatingpre-trained large language models for aligning symbolic tree data. Experimentalanalysis shows that the choice of LLM is crucial, with ChatGLM-2 outperformingothers in training and testing. Botfip-LLM not only improves performance,generalization, and extrapolation over the original Botfip model but alsosignificantly enhances applicability to Formula String-related tasks, enablingmore diverse task handling.</description>
      <author>example@mail.com (Tianhao Chen, Pengbo Xu, Pengbo Xu)</author>
      <guid isPermaLink="false">2411.15525v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>EVT: Efficient View Transformation for Multi-Modal 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.10715v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态传感器融合在鸟瞰图（BEV）表示中已成为3D目标检测的主要方法，但现有方法往往依赖深度估计器或变换编码器进行视图转换，导致计算开销较大。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效视图转换的3D目标检测器（EVT），以提高准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;EVT关注两个主要方面：首先，采用自适应采样和自适应投影（ASAP），利用LiDAR指导生成3D采样点和自适应核；其次，包含改进的基于变换器的检测框架，设计了分组查询初始化方法和增强的查询更新框架，以有效利用获得的多模态BEV特征。&lt;h4&gt;主要发现&lt;/h4&gt;通过利用物体查询的几何特性，EVT显著提升了检测性能，特别是在多层变换器解码器结构中。&lt;h4&gt;结论&lt;/h4&gt;EVT在nuScenes测试集上实现了领先的性能，并具有实时推理速度。&lt;h4&gt;总结&lt;/h4&gt;EVT通过高效的视图转换和改进的检测框架，克服了现有方法的局限性，推动了多模态传感器融合在3D目标检测中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal sensor fusion in bird's-eye-view (BEV) representation has becomethe leading approach in 3D object detection. However, existing methods oftenrely on depth estimators or transformer encoders for view transformation,incurring substantial computational overhead. Furthermore, the lack of precisegeometric correspondence between 2D and 3D spaces leads to spatial andray-directional misalignments, restricting the effectiveness of BEVrepresentations. To address these challenges, we propose a novel 3D objectdetector via efficient view transformation (EVT), which leverages awell-structured BEV representation to enhance accuracy and efficiency. EVTfocuses on two main areas. First, it employs Adaptive Sampling and AdaptiveProjection (ASAP), using LiDAR guidance to generate 3D sampling points andadaptive kernels. The generated points and kernels are then used to facilitatethe transformation of image features into BEV space and refine the BEVfeatures. Second, EVT includes an improved transformer-based detectionframework, which contains a group-wise query initialization method and anenhanced query update framework. It is designed to effectively utilize theobtained multi-modal BEV features within the transformer decoder. By leveragingthe geometric properties of object queries, this framework significantlyenhances detection performance, especially in a multi-layer transformer decoderstructure. EVT achieves state-of-the-art performance on the nuScenes test setwith real-time inference speed.</description>
      <author>example@mail.com (Yongjin Lee, Hyeon-Mun Jeong, Yurim Jeon, Sanghyun Kim)</author>
      <guid isPermaLink="false">2411.10715v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Towards Speaker Identification with Minimal Dataset and Constrained Resources using 1D-Convolution Neural Network</title>
      <link>http://arxiv.org/abs/2411.15082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;语音识别和说话人识别在安全和个人助手应用中至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种轻量级的一维卷积神经网络（1D-CNN），旨在在最小数据集上执行说话人识别。&lt;h4&gt;方法&lt;/h4&gt;利用数据增强技术处理背景噪声和有限的训练样本。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了97.87%的验证准确率。&lt;h4&gt;结论&lt;/h4&gt;未来计划在更大数据集上进行测试，并整合迁移学习方法以提高模型的通用性。&lt;h4&gt;资源&lt;/h4&gt;提供所有代码、自定义数据集和训练模型，以便于重现。&lt;h4&gt;总结&lt;/h4&gt;相关资源可在GitHub库中获取，链接为：https://github.com/IrfanNafiz/RecMe。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/irfannafiz/recme&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Voice recognition and speaker identification are vital for applications insecurity and personal assistants. This paper presents a lightweight1D-Convolutional Neural Network (1D-CNN) designed to perform speakeridentification on minimal datasets. Our approach achieves a validation accuracyof 97.87%, leveraging data augmentation techniques to handle background noiseand limited training samples. Future improvements include testing on largerdatasets and integrating transfer learning methods to enhance generalizability.We provide all code, the custom dataset, and the trained models to facilitatereproducibility. These resources are available on our GitHub repository:https://github.com/IrfanNafiz/RecMe.</description>
      <author>example@mail.com (Irfan Nafiz Shahan, Pulok Ahmed Auvi)</author>
      <guid isPermaLink="false">2411.15082v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Any3DIS: Class-Agnostic 3D Instance Segmentation by 2D Mask Tracking</title>
      <link>http://arxiv.org/abs/2411.16183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://any3dis.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的3D实例分割方法常常遇到过度分割的问题，导致冗余和不准确的3D提议，影响后续任务。&lt;h4&gt;目的&lt;/h4&gt;克服无监督合并方法的局限性，改善3D候选提议的质量。&lt;h4&gt;方法&lt;/h4&gt;提出了一个3D感知的2D掩码跟踪模块，利用来自2D掩码分割和跟踪基础模型（SAM-2）的强大3D先验，确保视频帧间的一致对象掩码。&lt;h4&gt;主要发现&lt;/h4&gt;通过动态编程算法选择最佳视图，优化超级点，从而为每个对象生成最终的3D提议，提升了场景内的整体对象覆盖，同时减少了不必要的提议。&lt;h4&gt;结论&lt;/h4&gt;在ScanNet200和ScanNet++上的评估确认了我们方法的有效性，在类别无关、开放词汇和开放式3D实例分割任务中均有显著改进。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的3D实例分割方法，显著提高了3D提议的准确性和有效性，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing 3D instance segmentation methods frequently encounter issues withover-segmentation, leading to redundant and inaccurate 3D proposals thatcomplicate downstream tasks. This challenge arises from their unsupervisedmerging approach, where dense 2D instance masks are lifted across frames intopoint clouds to form 3D candidate proposals without direct supervision. Thesecandidates are then hierarchically merged based on heuristic criteria, oftenresulting in numerous redundant segments that fail to combine into precise 3Dproposals. To overcome these limitations, we propose a 3D-Aware 2D MaskTracking module that uses robust 3D priors from a 2D mask segmentation andtracking foundation model (SAM-2) to ensure consistent object masks acrossvideo frames. Rather than merging all visible superpoints across views tocreate a 3D mask, our 3D Mask Optimization module leverages a dynamicprogramming algorithm to select an optimal set of views, refining thesuperpoints to produce a final 3D proposal for each object. Our approachachieves comprehensive object coverage within the scene while reducingunnecessary proposals, which could otherwise impair downstream applications.Evaluations on ScanNet200 and ScanNet++ confirm the effectiveness of ourmethod, with improvements across Class-Agnostic, Open-Vocabulary, andOpen-Ended 3D Instance Segmentation tasks.</description>
      <author>example@mail.com (Phuc Nguyen, Minh Luu, Anh Tran, Cuong Pham, Khoi Nguyen)</author>
      <guid isPermaLink="false">2411.16183v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Homography Estimation on Multimodal Image Pair via Alternating Optimization</title>
      <link>http://arxiv.org/abs/2411.13036v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted to the Thirty-Eighth Annual Conference on
  Neural Information Processing Systems (NeurIPS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;估计两幅图像之间的单应性对中高层视觉任务（如图像拼接和融合）至关重要，但监督学习方法因收集真实数据的难度而具有挑战性和成本高昂。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督学习框架AltO，用于在多模态图像对中估计单应性。&lt;h4&gt;方法&lt;/h4&gt;采用类似期望最大化（EM）的两阶段交替优化框架，一阶段减少几何差距，另一阶段解决模态差距，使用Barlow Twins损失和扩展版本Geometry Barlow Twins处理这些差距。&lt;h4&gt;主要发现&lt;/h4&gt;AltO能够在没有任何真实数据的情况下对多模态数据集进行训练，且在性能上超越其他无监督方法，适用于多种单应性估计器架构。&lt;h4&gt;结论&lt;/h4&gt;AltO为多模态图像对的单应性估计提供了有效的解决方案，具有广泛的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;AltO是一种创新的无监督学习方法，能够有效处理多模态图像对的单应性估计问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/songsang7/alto&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating the homography between two images is crucial for mid- orhigh-level vision tasks, such as image stitching and fusion. However, usingsupervised learning methods is often challenging or costly due to thedifficulty of collecting ground-truth data. In response, unsupervised learningapproaches have emerged. Most early methods, though, assume that the givenimage pairs are from the same camera or have minor lighting differences.Consequently, while these methods perform effectively under such conditions,they generally fail when input image pairs come from different domains,referred to as multimodal image pairs. To address these limitations, we proposeAltO, an unsupervised learning framework for estimating homography inmultimodal image pairs. Our method employs a two-phase alternating optimizationframework, similar to Expectation-Maximization (EM), where one phase reducesthe geometry gap and the other addresses the modality gap. To handle thesegaps, we use Barlow Twins loss for the modality gap and propose an extendedversion, Geometry Barlow Twins, for the geometry gap. As a result, wedemonstrate that our method, AltO, can be trained on multimodal datasetswithout any ground-truth data. It not only outperforms other unsupervisedmethods but is also compatible with various architectures of homographyestimators. The source code can be foundat:~\url{https://github.com/songsang7/AltO}</description>
      <author>example@mail.com (Sanghyeob Song, Jaihyun Lew, Hyemi Jang, Sungroh Yoon)</author>
      <guid isPermaLink="false">2411.13036v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TANGNN: a Concise, Scalable and Effective Graph Neural Networks with Top-m Attention Mechanism for Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2411.15458v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code and ArXivNet dataset are available at
  https://github.com/ejwww/TANGNN&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在深度学习领域，图神经网络（GNNs）和图变换器（Graph Transformer）模型因其优秀的性能和灵活的架构设计，成为处理结构化数据，尤其是图数据的领先技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种创新的图神经网络架构，以解决传统GNN在有效捕获远距离节点信息方面的挑战。&lt;h4&gt;方法&lt;/h4&gt;集成了Top-m注意力机制聚合组件和邻域聚合组件，增强模型在每层聚合本地和扩展邻域相关信息的能力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法提高了计算效率，丰富了节点特征，促进了对复杂图结构的深入分析，并在多个任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;我们的模型在顶点分类、链接预测、情感预测、图回归和可视化等多种任务中，展现了优于现有方法的效果，实验结果表明其在多个数据集上具有较高的有效性。&lt;h4&gt;总结&lt;/h4&gt;通过构建专门的引用网络ArXivNet，我们进行了情感极性标注，验证了模型在情感分析中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of deep learning, Graph Neural Networks (GNNs) and GraphTransformer models, with their outstanding performance and flexiblearchitectural designs, have become leading technologies for processingstructured data, especially graph data. Traditional GNNs often face challengesin capturing information from distant vertices effectively. In contrast, GraphTransformer models are particularly adept at managing long-distance noderelationships. Despite these advantages, Graph Transformer models stillencounter issues with computational and storage efficiency when scaled to largegraph datasets. To address these challenges, we propose an innovative GraphNeural Network (GNN) architecture that integrates a Top-m attention mechanismaggregation component and a neighborhood aggregation component, effectivelyenhancing the model's ability to aggregate relevant information from both localand extended neighborhoods at each layer. This method not only improvescomputational efficiency but also enriches the node features, facilitating adeeper analysis of complex graph structures. Additionally, to assess theeffectiveness of our proposed model, we have applied it to citation sentimentprediction, a novel task previously unexplored in the GNN field. Accordingly,we constructed a dedicated citation network, ArXivNet. In this dataset, wespecifically annotated the sentiment polarity of the citations (positive,neutral, negative) to enable in-depth sentiment analysis. Our approach hasshown superior performance across a variety of tasks including vertexclassification, link prediction, sentiment prediction, graph regression, andvisualization. It outperforms existing methods in terms of effectiveness, asdemonstrated by experimental results on multiple datasets.</description>
      <author>example@mail.com (Jiawei E, Yinglong Zhang, Xuewen Xia, Xing Xu)</author>
      <guid isPermaLink="false">2411.15458v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>From Complexity to Parsimony: Integrating Latent Class Analysis to Uncover Multimodal Learning Patterns in Collaborative Learning</title>
      <link>http://arxiv.org/abs/2411.15590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态学习分析（MMLA）利用先进的传感技术和人工智能捕捉复杂的学习过程，但整合多样的数据源为统一的见解仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;本研究引入一种新方法，将潜变量分类分析（LCA）整合进MMLA，以将单一模态的行为指标转化为简约的多模态指标。&lt;h4&gt;方法&lt;/h4&gt;在高保真医疗模拟环境中，收集位置、音频和生理数据，派生出17个单一模态指标。使用LCA识别出四个不同的潜在类别：协作沟通、身体协作、远程互动和孤立参与。&lt;h4&gt;主要发现&lt;/h4&gt;通过认知网络分析，将这些多模态指标与原始的单一模态指标进行比较，发现多模态方法更为简约，并提供了更高的解释力，尤其在学生的任务和协作表现方面。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了LCA在简化复杂多模态数据分析方面的潜力，同时捕捉细微的跨模态行为，为教育工作者提供可操作的见解，并提升协作学习干预的设计。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一条推动MMLA发展的路径，使其更为简约和可管理，并与以学习者为中心的教育原则相一致。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Learning Analytics (MMLA) leverages advanced sensing technologiesand artificial intelligence to capture complex learning processes, butintegrating diverse data sources into cohesive insights remains challenging.This study introduces a novel methodology for integrating latent class analysis(LCA) within MMLA to map monomodal behavioural indicators into parsimoniousmultimodal ones. Using a high-fidelity healthcare simulation context, wecollected positional, audio, and physiological data, deriving 17 monomodalindicators. LCA identified four distinct latent classes: CollaborativeCommunication, Embodied Collaboration, Distant Interaction, and SolitaryEngagement, each capturing unique monomodal patterns. Epistemic networkanalysis compared these multimodal indicators with the original monomodalindicators and found that the multimodal approach was more parsimonious whileoffering higher explanatory power regarding students' task and collaborationperformances. The findings highlight the potential of LCA in simplifying theanalysis of complex multimodal data while capturing nuanced, cross-modalitybehaviours, offering actionable insights for educators and enhancing the designof collaborative learning interventions. This study proposes a pathway foradvancing MMLA, making it more parsimonious and manageable, and aligning withthe principles of learner-centred education.</description>
      <author>example@mail.com (Lixiang Yan, Dragan Gašević, Linxuan Zhao, Vanessa Echeverria, Yueqiao Jin, Roberto Martinez-Maldonado)</author>
      <guid isPermaLink="false">2411.15590v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Personalization of Wearable Sensor-Based Joint Kinematic Estimation Using Computer Vision for Hip Exoskeleton Applications</title>
      <link>http://arxiv.org/abs/2411.15366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的下肢关节运动学估计对患者监测、康复和外骨骼控制等应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于计算机视觉的深度学习适应框架，以实现实时关节运动学估计。&lt;h4&gt;方法&lt;/h4&gt;该框架仅需少量数据集（1-2个步态周期）且不依赖专业的运动捕捉设备，通过迁移学习将时间卷积网络（TCN）适应于僵膝步态数据。&lt;h4&gt;主要发现&lt;/h4&gt;与仅使用健康人和僵膝数据集训练的TCN相比，模型的均方根误差分别降低了9.7%和19.9%。&lt;h4&gt;结论&lt;/h4&gt;我们的框架展示了智能手机摄像头训练的深度学习模型在临床人群中实时估计关节运动学的潜力，并可应用于可穿戴机器人。&lt;h4&gt;总结&lt;/h4&gt;该研究为下肢关节运动学的实时估计提供了一种新的方法，具有广泛的临床应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate lower-limb joint kinematic estimation is critical for applicationssuch as patient monitoring, rehabilitation, and exoskeleton control. Whileprevious studies have employed wearable sensor-based deep learning (DL) modelsfor estimating joint kinematics, these methods often require extensive newdatasets to adapt to unseen gait patterns. Meanwhile, researchers in computervision have advanced human pose estimation models, which are easy to deploy andcapable of real-time inference. However, such models are infeasible inscenarios where cameras cannot be used. To address these limitations, wepropose a computer vision-based DL adaptation framework for real-time jointkinematic estimation. This framework requires only a small dataset (i.e., 1-2gait cycles) and does not depend on professional motion capture setups. Usingtransfer learning, we adapted our temporal convolutional network (TCN) to stiffknee gait data, allowing the model to further reduce root mean square error by9.7% and 19.9% compared to a TCN trained on only able-bodied and stiff kneedatasets, respectively. Our framework demonstrates a potential for smartphonecamera-trained DL models to estimate real-time joint kinematics across novelusers in clinical populations with applications in wearable robots.</description>
      <author>example@mail.com (Changseob Song, Bogdan Ivanyuk-Skulskyi, Adrian Krieger, Kaitao Luo, Inseung Kang)</author>
      <guid isPermaLink="false">2411.15366v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DoubleCCA: Improving Foundation Model Group Robustness with Random Sentence Embeddings</title>
      <link>http://arxiv.org/abs/2411.16236v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 6 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型在群体偏见方面的鲁棒性不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，以提高基础模型对群体偏见的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为DoubleCCA的方法，通过生成随机句子和使用典型相关分析（CCA）来增强基础模型的文本嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多种任务和数据集上表现优于现有方法，提升了性能和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;DoubleCCA方法简单易于实现，可以轻松集成到现有模型中，是改善基础模型鲁棒性的实用解决方案。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了通过随机句子和CCA对基础模型进行增强的有效性，解决了群体偏见问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel method to improve the robustness of foundationmodels to group-based biases. We propose a simple yet effective method, calledDoubleCCA, that leverages random sentences and Canonical Correlation Analysis(CCA) to enrich the text embeddings of the foundation model. First, we generatevarious random sentences that augment the original prompts, which extends theoriginal prompts with random words or character sequences. Second, we use anadditional sentence embedding model to generate different text embeddings withrespect to these random sentences. We then use CCA double twice to align therepresentations and reconstruct them back to the original representation space.We demonstrate the effectiveness of our method on a variety of tasks anddatasets, showing that it outperforms existing methods in terms of bothperformance and robustness. Our method is simple to implement and can be easilyintegrated into existing models, making it a practical solution for improvingthe robustness of foundation models to group-based biases.</description>
      <author>example@mail.com (Hong Liu, Yitong Lu)</author>
      <guid isPermaLink="false">2411.16236v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>GaussianPretrain: A Simple Unified 3D Gaussian Representation for Visual Pre-training in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2411.12452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督学习在图像处理方面取得了显著进展，但针对自动驾驶的视觉预训练仍处于初期阶段。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的预训练范式GaussianPretrain，实现对场景的整体理解。&lt;h4&gt;方法&lt;/h4&gt;通过统一整合几何和纹理表示，使用3D高斯锚点作为体积LiDAR点，深化对场景的理解。&lt;h4&gt;主要发现&lt;/h4&gt;GaussianPretrain在多个3D感知任务中表现出显著的性能提升，包括3D物体检测NDS提高7.05%，HD地图构建mAP提升1.9%，占用预测提高0.8%。&lt;h4&gt;结论&lt;/h4&gt;GaussianPretrain展示了理论创新和强大的实际潜力，推动了自动驾驶的视觉预训练发展。&lt;h4&gt;总结&lt;/h4&gt;该研究表明，通过整合几何与纹理信息，可以显著改善自动驾驶领域的视觉预训练效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/public-bots/gaussianpretrain&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning has made substantial strides in image processing,while visual pre-training for autonomous driving is still in its infancy.Existing methods often focus on learning geometric scene information whileneglecting texture or treating both aspects separately, hindering comprehensivescene understanding. In this context, we are excited to introduceGaussianPretrain, a novel pre-training paradigm that achieves a holisticunderstanding of the scene by uniformly integrating geometric and texturerepresentations. Conceptualizing 3D Gaussian anchors as volumetric LiDARpoints, our method learns a deepened understanding of scenes to enhancepre-training performance with detailed spatial structure and texture, achievingthat 40.6% faster than NeRF-based method UniPAD with 70% GPU memory only. Wedemonstrate the effectiveness of GaussianPretrain across multiple 3D perceptiontasks, showing significant performance improvements, such as a 7.05% increasein NDS for 3D object detection, boosts mAP by 1.9% in HD map construction and0.8% improvement on Occupancy prediction. These significant gains highlightGaussianPretrain's theoretical innovation and strong practical potential,promoting visual pre-training development for autonomous driving. Source codewill be available at https://github.com/Public-BOTs/GaussianPretrain</description>
      <author>example@mail.com (Shaoqing Xu, Fang Li, Shengyin Jiang, Ziying Song, Li Liu, Zhi-xin Yang)</author>
      <guid isPermaLink="false">2411.12452v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Machine Learning for Classifying CHIME Fast Radio Bursts and Investigating Empirical Relations</title>
      <link>http://arxiv.org/abs/2411.14040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 8 pages, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;快速射电暴（FRBs）是高能量的亚毫秒天文现象，通常分为重复型和非重复型，但观测限制可能导致误分类，暗示真实的重复型比例可能更高。&lt;h4&gt;目的&lt;/h4&gt;利用无监督机器学习技术对FRBs进行分类，识别潜在的重复型候选者。&lt;h4&gt;方法&lt;/h4&gt;使用CHIME/FRB目录中的数据，采用统一流形近似与投影（UMAP）进行降维，并运用聚类算法（k-means和HDBSCAN）对FRBs进行分组。&lt;h4&gt;主要发现&lt;/h4&gt;成功将重复型和非重复型FRBs分为不同的聚类，识别出100多个潜在重复型候选者，并发现了多个聚类内的经验关系，如log(Δt_sc)与log(Δt_rw)的关系等。&lt;h4&gt;结论&lt;/h4&gt;无监督学习在FRB分类和潜在重复型识别中表现出色，为更精确地研究FRBs的起源和在宇宙学中的应用奠定基础。&lt;h4&gt;未来展望&lt;/h4&gt;预计未来观测数据和机器学习方法的改进将进一步增强对FRBs的理解。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了无监督学习在快速射电暴研究中的有效性，并为探索其物理特性和发射机制提供了新视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fast Radio Bursts (FRBs) are highly energetic millisecond-durationastrophysical phenomena typically categorized as repeaters or non-repeaters.However, observational limitations may lead to misclassifications, suggesting alarger proportion of repeaters than currently identified. In this study, weleverage unsupervised machine learning techniques to classify FRBs using datafrom the CHIME/FRB catalog, including both the first catalog and a recentrepeater catalog. By employing Uniform Manifold Approximation and Projection(UMAP) for dimensionality reduction and clustering algorithms (k-means andHDBSCAN), we successfully segregate repeaters and non-repeaters into distinctclusters, identifying over 100 potential repeater candidates. Our analysisreveals several empirical relations within the clusters, including the ${\rmlog \,}\Delta t_{sc} - {\rm log \,}\Delta t_{rw}$, ${\rm log \,}\Delta t_{sc} -{\rm log \,}T_B$, and $r - \gamma$ correlations, which provide new insightsinto the physical properties and emission mechanisms of FRBs. This studydemonstrates the effectiveness of unsupervised learning in classifying FRBs andidentifying potential repeaters, paving the way for more precise investigationsinto their origins and applications in cosmology. Future improvements inobservational data and machine learning methodologies are expected to furtherenhance our understanding of FRBs.</description>
      <author>example@mail.com (Da-Chun Qiang, Jie Zheng, Zhi-Qiang You, Sheng Yang)</author>
      <guid isPermaLink="false">2411.14040v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Token Enhancing for Vision Representation Learning</title>
      <link>http://arxiv.org/abs/2411.15787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉表示学习，尤其是自监督学习，对于各种视觉应用至关重要。集成学习在提高视觉模型的性能和鲁棒性方面也取得了成功。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法以增强自监督表示学习，同时降低传统集成策略的计算成本。&lt;h4&gt;方法&lt;/h4&gt;引入多标记增强（MTE），从单个模型中同时提取多个辅助标记，以增强表示学习，减少额外的训练和推理成本。&lt;h4&gt;主要发现&lt;/h4&gt;辅助标记（包括辅助CLS标记和自适应池化标记）捕获互补信息，提升性能，并且可以在推理过程中通过知识蒸馏来降低成本。&lt;h4&gt;结论&lt;/h4&gt;MTE与多种自监督损失函数和架构兼容，持续提升不同下游任务的性能，并将源代码公开。&lt;h4&gt;总结&lt;/h4&gt;MTE方法有效提升了自监督表示学习的性能，同时保持了计算效率，适用于多种视觉任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision representation learning, especially self-supervised learning, ispivotal for various vision applications. Ensemble learning has also succeededin enhancing the performance and robustness of the vision models. However,traditional ensemble strategies are impractical for representation learning,especially self-supervised representation learning that requires large-scaledatasets and long schedules. This is because they require k times more trainingand inference computation costs for an ensemble of k models. Differently, weintroduce Multi-Token Enhancing (MTE) that extracts multiple auxiliary tokenssimultaneously from a single model to enhance representation learning, whileincurring minimal additional training costs and no additional inference costs.These auxiliary tokens, including auxiliary CLS tokens and adaptively pooledtokens, capture complementary information due to their differences. Meanwhile,to address the increase in inference costs, we distill the knowledge acquiredby the auxiliary tokens into a global token during pre-training. Consequently,we can discard the auxiliary tokens during inference without incurringadditional costs. Our MTE is compatible with various self-supervised lossfunctions and architectures, consistently improving performances acrossdifferent downstream tasks. Our source code will be made publicly available.</description>
      <author>example@mail.com (Zhong-Yu Li, Yu-Song Hu, Bo-Wen Yin, Ming-Ming Cheng)</author>
      <guid isPermaLink="false">2411.15787v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MLDGG: Meta-Learning for Domain Generalization on Graphs</title>
      <link>http://arxiv.org/abs/2411.12913v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in KDD 2025 (research track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图形领域泛化旨在开发具有强大泛化能力的模型，以确保在测试集上的有效性能，尽管测试和训练分布存在差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架MLDGG，以实现跨多领域的适应性泛化。&lt;h4&gt;方法&lt;/h4&gt;将跨多领域元学习与结构学习和语义识别相结合，引入通用结构学习器和表示学习器，以增强图神经网络的表示能力。&lt;h4&gt;主要发现&lt;/h4&gt;MLDGG通过优化元参数，实现知识转移和有效适应，超越了基线方法，在三种不同的分布变化设置中展示了其有效性。&lt;h4&gt;结论&lt;/h4&gt;MLDGG在处理目标图在训练期间不可访问的情况下，能够有效提高图形的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的MLDGG框架在图形领域泛化中表现出色，增强了模型的灵活性和适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain generalization on graphs aims to develop models with robustgeneralization capabilities, ensuring effective performance on the testing setdespite disparities between testing and training distributions. However,existing methods often rely on static encoders directly applied to the targetdomain, constraining its flexible adaptability. In contrast to conventionalmethodologies, which concentrate on developing specific generalized models, ourframework, MLDGG, endeavors to achieve adaptable generalization across diversedomains by integrating cross-multi-domain meta-learning with structure learningand semantic identification. Initially, it introduces a generalized structurelearner to mitigate the adverse effects of task-unrelated edges, enhancing thecomprehensiveness of representations learned by Graph Neural Networks (GNNs)while capturing shared structural information across domains. Subsequently, arepresentation learner is designed to disentangle domain-invariant semantic anddomain-specific variation information in node embedding by leveraging causalreasoning for semantic identification, further enhancing generalization. In thecontext of meta-learning, meta-parameters for both learners are optimized tofacilitate knowledge transfer and enable effective adaptation to graphs throughfine-tuning within the target domains, where target graphs are inaccessibleduring training. Our empirical results demonstrate that MLDGG surpassesbaseline methods, showcasing its effectiveness in three different distributionshift settings.</description>
      <author>example@mail.com (Qin Tian, Chen Zhao, Minglai Shao, Wenjun Wang, Yujie Lin, Dong Li)</author>
      <guid isPermaLink="false">2411.12913v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MulModSeg: Enhancing Unpaired Multi-Modal Medical Image Segmentation with Modality-Conditioned Text Embedding and Alternating Training</title>
      <link>http://arxiv.org/abs/2411.15576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WACV-2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;医学影像领域的自动分割面临多种输入来源的挑战，包括不同类型的CT扫描和MR图像。不同模态之间的异质性使得自动分割算法难以保持一致的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单的多模态分割策略（MulModSeg），以增强CT和MR图像的分割精度。&lt;h4&gt;方法&lt;/h4&gt;MulModSeg采用两个关键设计：使用冻结的文本编码器实现模态条件的文本嵌入框架，增加模态意识，以及交替训练程序以整合无配对的CT和MR输入的关键信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过在全卷积网络和基于Transformer的骨干网络上进行广泛实验，MulModSeg在CT和MR模态下，分割腹部多脏器和心脏子结构的表现优于之前的方法。&lt;h4&gt;结论&lt;/h4&gt;MulModSeg在处理多模态医学图像分割时有效提升了精度，且无需对现有结构进行重大修改或增加计算负担。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种新颖的方法来解决医学影像多模态分割中的挑战，具有良好的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chengyinlee/mulmodseg_2024&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the diverse field of medical imaging, automatic segmentation has numerousapplications and must handle a wide variety of input domains, such as differenttypes of Computed Tomography (CT) scans and Magnetic Resonance (MR) images.This heterogeneity challenges automatic segmentation algorithms to maintainconsistent performance across different modalities due to the requirement forspatially aligned and paired images. Typically, segmentation models are trainedusing a single modality, which limits their ability to generalize to othertypes of input data without employing transfer learning techniques.Additionally, leveraging complementary information from different modalities toenhance segmentation precision often necessitates substantial modifications topopular encoder-decoder designs, such as introducing multiple branched encodingor decoding paths for each modality. In this work, we propose a simpleMulti-Modal Segmentation (MulModSeg) strategy to enhance medical imagesegmentation across multiple modalities, specifically CT and MR. Itincorporates two key designs: a modality-conditioned text embedding frameworkvia a frozen text encoder that adds modality awareness to existing segmentationframeworks without significant structural modifications or computationaloverhead, and an alternating training procedure that facilitates theintegration of essential features from unpaired CT and MR inputs. Throughextensive experiments with both Fully Convolutional Network andTransformer-based backbones, MulModSeg consistently outperforms previousmethods in segmenting abdominal multi-organ and cardiac substructures for bothCT and MR modalities. The code is available in this{\href{https://github.com/ChengyinLee/MulModSeg_2024}{link}}.</description>
      <author>example@mail.com (Chengyin Li, Hui Zhu, Rafi Ibn Sultan, Hassan Bagher Ebadian, Prashant Khanduri, Chetty Indrin, Kundan Thind, Dongxiao Zhu)</author>
      <guid isPermaLink="false">2411.15576v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>BayLing 2: A Multilingual Large Language Model with Efficient Language Alignment</title>
      <link>http://arxiv.org/abs/2411.16300v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  BayLing 2's online demo: http://nlp.ict.ac.cn/bayling/demo. BayLing
  2's code and models: https://github.com/ictnlp/BayLing&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在高资源语言中表现出强大的生成能力和广泛的知识，但在低资源语言中能力较弱。&lt;h4&gt;目的&lt;/h4&gt;提升LLMs的多语言能力，以服务全球100多个语言社区。&lt;h4&gt;方法&lt;/h4&gt;引入BayLing2，通过语言对齐有效地将高资源语言的生成能力和知识转移到低资源语言，构建了一个包含320万条指令的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;BayLing在100多种语言的多语言翻译中表现优于同规模的开源模型，且在20多种低资源语言的知识传递上显著提升。&lt;h4&gt;结论&lt;/h4&gt;BayLing在保持高资源语言的高性能同时，增强了低资源语言的能力，展示了有效的知识转移。&lt;h4&gt;总结&lt;/h4&gt;BayLing展示了在多语言处理中的优越性，提供了演示、主页、代码和模型的访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ictnlp/bayling&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs), with their powerful generative capabilities andvast knowledge, empower various tasks in everyday life. However, theseabilities are primarily concentrated in high-resource languages, leavinglow-resource languages with weaker generative capabilities and relativelylimited knowledge. Enhancing the multilingual capabilities of LLMs is thereforecrucial for serving over 100 linguistic communities worldwide. An intuitiveapproach to enhance the multilingual capabilities would be to constructinstruction data for various languages, but constructing instruction data forover 100 languages is prohibitively costly. In this paper, we introduce BayLing2, which efficiently transfers generative capabilities and knowledge fromhigh-resource languages to low-resource languages through language alignment.To achieve this, we constructed a dataset of 3.2 million instructions,comprising high-resource language instructions (Chinese and English) andcross-lingual instructions for 100+ languages and performed instruction tuningbased on the dataset to facilitate the capability transfer between languages.Using Llama as the foundation model, we developed BayLing-2-7B, BayLing-2-13B,and BayLing-3-8B, and conducted a comprehensive evaluation of BayLing. Formultilingual translation across 100+ languages, BayLing shows superiorperformance compared to open-source models of similar scale. For multilingualknowledge and understanding benchmarks, BayLing achieves significantimprovements across over 20 low-resource languages, demonstrating itscapability of effective knowledge transfer from high-resource to low-resourcelanguages. Furthermore, results on English benchmarks indicate that BayLingmaintains high performance in highresource languages while enhancing theperformance in low-resource languages. Demo, homepage, code and models ofBayLing are available.</description>
      <author>example@mail.com (Shaolei Zhang, Kehao Zhang, Qingkai Fang, Shoutao Guo, Yan Zhou, Xiaodong Liu, Yang Feng)</author>
      <guid isPermaLink="false">2411.16300v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>VADet: Multi-frame LiDAR 3D Object Detection using Variable Aggregation</title>
      <link>http://arxiv.org/abs/2411.13186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;输入聚合是一种简单技术，广泛应用于最先进的LiDAR 3D物体检测器，以提高检测效果。&lt;h4&gt;目的&lt;/h4&gt;解决输入聚合带来的收益递减和性能退化问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种高效的自适应方法，称为可变聚合检测（VADet），根据物体的观察属性（如速度和点密度）进行聚合。&lt;h4&gt;主要发现&lt;/h4&gt;VADet在三个流行的单阶段检测器上应用，获得了Waymo数据集上的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;VADet减少了固定聚合的固有权衡，且不依赖于特定的架构。&lt;h4&gt;总结&lt;/h4&gt;VADet通过对象特性自适应聚合，提升了LiDAR 3D物体检测的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Input aggregation is a simple technique used by state-of-the-art LiDAR 3Dobject detectors to improve detection. However, increasing aggregation is knownto have diminishing returns and even performance degradation, due to objectsresponding differently to the number of aggregated frames. To address thislimitation, we propose an efficient adaptive method, which we call VariableAggregation Detection (VADet). Instead of aggregating the entire scene using afixed number of frames, VADet performs aggregation per object, with the numberof frames determined by an object's observed properties, such as speed andpoint density. VADet thus reduces the inherent trade-offs of fixed aggregationand is not architecture specific. To demonstrate its benefits, we apply VADetto three popular single-stage detectors and achieve state-of-the-artperformance on the Waymo dataset.</description>
      <author>example@mail.com (Chengjie Huang, Vahdat Abdelzad, Sean Sedwards, Krzysztof Czarnecki)</author>
      <guid isPermaLink="false">2411.13186v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Semi-Supervised Scene Text Recognition via Viewing and Summarizing</title>
      <link>http://arxiv.org/abs/2411.15585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的场景文本识别方法在识别具有挑战性的文本（特别是艺术性和严重扭曲的字符）时存在困难，主要原因是对字符形态的探索不足。&lt;h4&gt;目的&lt;/h4&gt;解决字符形态多样性不足的问题，提高模型对复杂样本的识别能力。&lt;h4&gt;方法&lt;/h4&gt;通过对比学习框架，利用合成和真实的未标记数据，无需人工成本，提出在线生成策略生成无背景的多样化字符样本，并引入新的字符单向对齐损失。&lt;h4&gt;主要发现&lt;/h4&gt;提出的字符单向对齐损失有效纠正了先前对比损失的推导误差，统一了同一字符在所有样本中的表示。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在常见基准测试和Union14M-Benchmark上达到了最先进的性能，平均准确率分别为94.7%和70.9%。&lt;h4&gt;总结&lt;/h4&gt;通过增强字符形态多样性和修正损失函数，提高了场景文本识别的准确性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing scene text recognition (STR) methods struggle to recognizechallenging texts, especially for artistic and severely distorted characters.The limitation lies in the insufficient exploration of character morphologies,including the monotonousness of widely used synthetic training data and thesensitivity of the model to character morphologies. To address these issues,inspired by the human learning process of viewing and summarizing, wefacilitate the contrastive learning-based STR framework in a self-motivatedmanner by leveraging synthetic and real unlabeled data without any human cost.In the viewing process, to compensate for the simplicity of synthetic data andenrich character morphology diversity, we propose an Online Generation Strategyto generate background-free samples with diverse character styles. By excludingbackground noise distractions, the model is encouraged to focus on charactermorphology and generalize the ability to recognize complex samples when trainedwith only simple synthetic data. To boost the summarizing process, wetheoretically demonstrate the derivation error in the previous charactercontrastive loss, which mistakenly causes the sparsity in the intra-classdistribution and exacerbates ambiguity on challenging samples. Therefore, a newCharacter Unidirectional Alignment Loss is proposed to correct this error andunify the representation of the same characters in all samples by aligning thecharacter features in the student model with the reference features in theteacher model. Extensive experiment results show that our method achieves SOTAperformance (94.7\% and 70.9\% average accuracy on common benchmarks andUnion14M-Benchmark). Code will be available at https://github.com/qqqyd/ViSu.</description>
      <author>example@mail.com (Yadong Qu, Yuxin Wang, Bangbang Zhou, Zixiao Wang, Hongtao Xie, Yongdong Zhang)</author>
      <guid isPermaLink="false">2411.15585v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A Data-Driven Approach to Dataflow-Aware Online Scheduling for Graph Neural Network Inference</title>
      <link>http://arxiv.org/abs/2411.16342v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for ASP-DAC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在推荐系统、生物信息学和网络分析等领域展现了显著的潜力，但图数据的不规则性给高效计算带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一个数据驱动框架，用于在GNN推理中进行数据流感知的延迟预测。&lt;h4&gt;方法&lt;/h4&gt;通过训练回归模型，预测特定图在特定数据流下的执行延迟，利用合成图进行模拟。&lt;h4&gt;主要发现&lt;/h4&gt;回归模型能够以最高91.28%的准确率和3.78%的平均绝对百分比误差（MAPE）预测给定图的最佳数据流。&lt;h4&gt;结论&lt;/h4&gt;引入的在线调度算法利用这些回归模型优化调度决策，相较于所有数据集中的最佳可行基线，实现了平均完成时间最高3.17倍和平均执行时间最高6.26倍的加速。&lt;h4&gt;总结&lt;/h4&gt;本研究为GNN加速器提供了有效的延迟预测和调度优化方法，提升了其性能和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3658617.3697660&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown significant promise in variousdomains, such as recommendation systems, bioinformatics, and network analysis.However, the irregularity of graph data poses unique challenges for efficientcomputation, leading to the development of specialized GNN acceleratorarchitectures that surpass traditional CPU and GPU performance. Despite this,the structural diversity of input graphs results in varying performance acrossdifferent GNN accelerators, depending on their dataflows. This variability inperformance due to differing dataflows and graph properties remains largelyunexplored, limiting the adaptability of GNN accelerators. To address this, wepropose a data-driven framework for dataflow-aware latency prediction in GNNinference. Our approach involves training regressors to predict the latency ofexecuting specific graphs on particular dataflows, using simulations onsynthetic graphs. Experimental results indicate that our regressors can predictthe optimal dataflow for a given graph with up to 91.28% accuracy and a MeanAbsolute Percentage Error (MAPE) of 3.78%. Additionally, we introduce an onlinescheduling algorithm that uses these regressors to enhance schedulingdecisions. Our experiments demonstrate that this algorithm achieves up to$3.17\times$ speedup in mean completion time and $6.26\times$ speedup in meanexecution time compared to the best feasible baseline across all datasets.</description>
      <author>example@mail.com (Pol Puigdemont, Enrico Russo, Axel Wassington, Abhijit Das, Sergi Abadal, Maurizio Palesi)</author>
      <guid isPermaLink="false">2411.16342v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>ZT-SDN: An ML-powered Zero-Trust Architecture for Software-Defined Networks</title>
      <link>http://arxiv.org/abs/2411.15020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 13 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Zero Trust (ZT) 是一种安全范式，旨在通过实施最小特权和按请求访问控制策略来限制攻击者在网络中的横向移动。&lt;h4&gt;目的&lt;/h4&gt;解决由于缺乏详细的通信需求知识和通信实体在正常条件下的行为特征而导致的规则生成困难。&lt;h4&gt;方法&lt;/h4&gt;提出 ZT-SDN，一个自动化框架，通过学习和强制实施软件定义网络中的网络访问控制。该框架收集网络数据并将通信实体的网络“交易”建模为图。&lt;h4&gt;主要发现&lt;/h4&gt;ZT-SDN 利用新颖的无监督学习方法从网络数据中提取交易模式，生成正确的访问控制规则，并推断其之间的强关联性，以实现主动规则部署。&lt;h4&gt;结论&lt;/h4&gt;ZT-SDN 在检测异常网络访问和滥用允许流量方面表现出色，并展示了在 SDN 环境中的可扩展性和网络性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero Trust (ZT) is a security paradigm aiming to curtail an attacker'slateral movements within a network by implementing least-privilege andper-request access control policies. However, its widespread adoption ishindered by the difficulty of generating proper rules due to the lack ofdetailed knowledge of communication requirements and the characteristicbehaviors of communicating entities under benign conditions. Consequently,manual rule generation becomes cumbersome and error-prone. To address theseproblems, we propose ZT-SDN, an automated framework for learning and enforcingnetwork access control in Software-Defined Networks. ZT-SDN collects data fromthe underlying network and models the network "transactions" performed bycommunicating entities as graphs. The nodes represent entities, while thedirected edges represent transactions identified by different protocol stacksobserved. It uses novel unsupervised learning approaches to extract transactionpatterns directly from the network data, such as the allowed protocol stacksand port numbers and data transmission behavior. Finally, ZT-SDN uses aninnovative approach to generate correct access control rules and infer strongassociations between them, allowing proactive rule deployment in forwardingdevices. We show the framework's efficacy in detecting abnormal networkaccesses and abuses of permitted flows in changing network conditions with realnetwork datasets. Additionally, we showcase ZT-SDN's scalability and thenetwork's performance when applied in an SDN environment.</description>
      <author>example@mail.com (Charalampos Katsis, Elisa Bertino)</author>
      <guid isPermaLink="false">2411.15020v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Deep Loss Convexification for Learning Iterative Models</title>
      <link>http://arxiv.org/abs/2411.10649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 10 figures, accepted paper to Transactions on Pattern
  Analysis and Machine Intelligence. arXiv admin note: text overlap with
  arXiv:2303.11526&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;迭代方法（如迭代最近点ICP）在点云配准中常遭遇局部最优性差的问题，如鞍点，这与非凸优化的特性有关。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一基本挑战，提出一种方法将深度迭代方法在测试时的损失景观局部形成类似凸的形状。&lt;h4&gt;方法&lt;/h4&gt;提出深度损失凸化（DLC），通过对抗训练操控真实预测，而非输入数据，利用神经网络的过参数化特性。&lt;h4&gt;主要发现&lt;/h4&gt;引入星凸性作为几何约束，重塑损失景观，提供额外的新型铰链损失，从而实现近似最优的预测。&lt;h4&gt;结论&lt;/h4&gt;使用DLC在现有网络架构上展示了在训练递归神经网络、3D点云配准和多模型图像对齐任务中的最先进表现。&lt;h4&gt;总结&lt;/h4&gt;深度损失凸化方法有效改善了迭代方法的局部最优性问题，提升了多种任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Iterative methods such as iterative closest point (ICP) for point cloudregistration often suffer from bad local optimality (e.g. saddle points), dueto the nature of nonconvex optimization. To address this fundamental challenge,in this paper we propose learning to form the loss landscape of a deepiterative method w.r.t. predictions at test time into a convex-like shapelocally around each ground truth given data, namely Deep Loss Convexification(DLC), thanks to the overparametrization in neural networks. To this end, weformulate our learning objective based on adversarial training by manipulatingthe ground-truth predictions, rather than input data. In particular, we proposeusing star-convexity, a family of structured nonconvex functions that areunimodal on all lines that pass through a global minimizer, as our geometricconstraint for reshaping loss landscapes, leading to (1) extra novel hingelosses appended to the original loss and (2) near-optimal predictions. Wedemonstrate the state-of-the-art performance using DLC with existing networkarchitectures for the tasks of training recurrent neural networks (RNNs), 3Dpoint cloud registration, and multimodel image alignment.</description>
      <author>example@mail.com (Ziming Zhang, Yuping Shao, Yiqing Zhang, Fangzhou Lin, Haichong Zhang, Elke Rundensteiner)</author>
      <guid isPermaLink="false">2411.10649v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Trans-Glasso: A Transfer Learning Approach to Precision Matrix Estimation</title>
      <link>http://arxiv.org/abs/2411.15624v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;精确度矩阵估计在多个领域中至关重要，但当样本有限时，面临挑战。&lt;h4&gt;目的&lt;/h4&gt;通过迁移学习提高精确度矩阵估计的准确性，利用相关源研究的数据。&lt;h4&gt;方法&lt;/h4&gt;提出Trans-Glasso，一种两步迁移学习方法：首先使用多任务学习目标获取初步估计器，然后通过差分网络估计调整这些估计器以适应目标和源精确矩阵之间的结构差异。&lt;h4&gt;主要发现&lt;/h4&gt;在假设目标精确矩阵的大部分条目与源矩阵共享的前提下，推导出非渐近误差界限，并证明在特定条件下，Trans-Glasso达到了最小最大最优性。大量模拟显示Trans-Glasso在小样本设置中的表现优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;Trans-Glasso在生物学背景下的基因网络和不同癌症亚型的蛋白质网络应用中有效，首次为差分网络估计推导出最小最大最优率。&lt;h4&gt;总结&lt;/h4&gt;Trans-Glasso展现了在有限样本情况下进行精确度矩阵估计的优势，尤其在生物领域具有广泛应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Precision matrix estimation is essential in various fields, yet it ischallenging when samples for the target study are limited. Transfer learningcan enhance estimation accuracy by leveraging data from related source studies.We propose Trans-Glasso, a two-step transfer learning method for precisionmatrix estimation. First, we obtain initial estimators using a multi-tasklearning objective that captures shared and unique features across studies.Then, we refine these estimators through differential network estimation toadjust for structural differences between the target and source precisionmatrices. Under the assumption that most entries of the target precision matrixare shared with source matrices, we derive non-asymptotic error bounds and showthat Trans-Glasso achieves minimax optimality under certain conditions.Extensive simulations demonstrate Trans Glasso's superior performance comparedto baseline methods, particularly in small-sample settings. We further validateTrans-Glasso in applications to gene networks across brain tissues and proteinnetworks for various cancer subtypes, showcasing its effectiveness inbiological contexts. Additionally, we derive the minimax optimal rate fordifferential network estimation, representing the first such guarantee in thisarea.</description>
      <author>example@mail.com (Boxin Zhao, Cong Ma, Mladen Kolar)</author>
      <guid isPermaLink="false">2411.15624v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Solaris: A Foundation Model of the Sun</title>
      <link>http://arxiv.org/abs/2411.16339v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型在多个科学领域取得了显著成功，激励我们探索其在太阳物理学中的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出Solaris，这是第一个用于预测太阳大气的基础模型。&lt;h4&gt;方法&lt;/h4&gt;利用来自太阳动态观测站的13年全盘多波长太阳影像进行预训练，以进行12小时间隔的预测。&lt;h4&gt;主要发现&lt;/h4&gt;Solaris采用了大型3D Swin Transformer架构，拥有1.09亿个参数，能够在低数据环境下通过微调实现优秀的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Solaris有效捕捉太阳大气的复杂动态，能够变革太阳预测。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了Solaris作为基础模型在太阳物理领域的应用潜力，提供了新的预测工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have demonstrated remarkable success across variousscientific domains, motivating our exploration of their potential in solarphysics. In this paper, we present Solaris, the first foundation model forforecasting the Sun's atmosphere. We leverage 13 years of full-disk,multi-wavelength solar imagery from the Solar Dynamics Observatory, spanning acomplete solar cycle, to pre-train Solaris for 12-hour interval forecasting.Solaris is built on a large-scale 3D Swin Transformer architecture with 109million parameters. We demonstrate Solaris' ability to generalize byfine-tuning on a low-data regime using a single wavelength (1700 {\AA}), thatwas not included in pre-training, outperforming models trained from scratch onthis specific wavelength. Our results indicate that Solaris can effectivelycapture the complex dynamics of the solar atmosphere and transform solarforecasting.</description>
      <author>example@mail.com (Harris Abdul Majid, Pietro Sittoni, Francesco Tudisco)</author>
      <guid isPermaLink="false">2411.16339v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MambaDETR: Query-based Temporal Modeling using State Space Model for Multi-View 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.13628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;利用时间信息提升3D检测性能在自动驾驶领域取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法MambaDETR，以提高时间融合的效率。&lt;h4&gt;方法&lt;/h4&gt;在高效状态空间中实现时间融合，并设计运动消除模块以去除相对静态物体。&lt;h4&gt;主要发现&lt;/h4&gt;在标准nuScenes基准测试中，MambaDETR在3D物体检测任务中取得了显著的结果。&lt;h4&gt;结论&lt;/h4&gt;MambaDETR在现有时间融合方法中表现出最先进的性能。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了有效的时间信息利用方法以改进3D检测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Utilizing temporal information to improve the performance of 3D detection hasmade great progress recently in the field of autonomous driving. Traditionaltransformer-based temporal fusion methods suffer from quadratic computationalcost and information decay as the length of the frame sequence increases. Inthis paper, we propose a novel method called MambaDETR, whose main idea is toimplement temporal fusion in the efficient state space. Moreover, we design aMotion Elimination module to remove the relatively static objects for temporalfusion. On the standard nuScenes benchmark, our proposed MambaDETR achievesremarkable result in the 3D object detection task, exhibiting state-of-the-artperformance among existing temporal fusion methods.</description>
      <author>example@mail.com (Tong Ning, Ke Lu, Xirui Jiang, Jian Xue)</author>
      <guid isPermaLink="false">2411.13628v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multi-label Sequential Sentence Classification via Large Language Model</title>
      <link>http://arxiv.org/abs/2411.15623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by EMNLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;科学出版物中的顺序句子分类（SSC）对支持细粒度信息检索和抽取式摘要至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架LLM-SSC，以克服当前SSC方法在模型规模、序列长度和单标签设置方面的限制。&lt;h4&gt;方法&lt;/h4&gt;基于大型语言模型（LLM）的方法，使用设计的提示生成SSC标签，并引入多标签对比学习损失及自动加权方案。&lt;h4&gt;主要发现&lt;/h4&gt;在上下文学习和任务特定调优设置下，LLM-SSC在SSC任务中表现优异。&lt;h4&gt;结论&lt;/h4&gt;研究推出的新数据集biorc800包含生物医学领域的无结构摘要及手动注释，并开源代码。&lt;h4&gt;总结&lt;/h4&gt;LLM-SSC框架有效提升了顺序句子分类的能力，支持单标签和多标签分类任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential sentence classification (SSC) in scientific publications iscrucial for supporting downstream tasks such as fine-grained informationretrieval and extractive summarization. However, current SSC methods areconstrained by model size, sequence length, and single-label setting. Toaddress these limitations, this paper proposes LLM-SSC, a large language model(LLM)-based framework for both single- and multi-label SSC tasks. Unlikeprevious approaches that employ small- or medium-sized language models, theproposed framework utilizes LLMs to generate SSC labels through designedprompts, which enhance task understanding by incorporating demonstrations and aquery to describe the prediction target. We also present a multi-labelcontrastive learning loss with auto-weighting scheme, enabling the multi-labelclassification task. To support our multi-label SSC analysis, we introduce andrelease a new dataset, biorc800, which mainly contains unstructured abstractsin the biomedical domain with manual annotations. Experiments demonstrateLLM-SSC's strong performance in SSC under both in-context learning andtask-specific tuning settings. We release biorc800 and our code at:https://github.com/ScienceNLP-Lab/LLM-SSC.</description>
      <author>example@mail.com (Mengfei Lan, Lecheng Zheng, Shufan Ming, Halil Kilicoglu)</author>
      <guid isPermaLink="false">2411.15623v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>3D Reconstruction by Looking: Instantaneous Blind Spot Detector for Indoor SLAM through Mixed Reality</title>
      <link>http://arxiv.org/abs/2411.12514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 13 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;室内SLAM在重建任务中常面临场景漂移、双墙和盲点等问题，尤其是在传感器（如LiDAR和相机）附近的狭小空间中。&lt;h4&gt;目的&lt;/h4&gt;开发一种系统以提高点云注册的实时可视化，从而减轻上述问题。&lt;h4&gt;方法&lt;/h4&gt;开发LiMRSF（LiDAR-MR-RGB传感器融合）系统，通过混合现实头戴设备让用户实时感知点云注册情况。&lt;h4&gt;主要发现&lt;/h4&gt;盲点检测器的错误检测精度为75.76%，监测的保真度表现良好，具有较高的SSIM、PSNR和较低的MSE。&lt;h4&gt;结论&lt;/h4&gt;该方法确保生成详细、高质量的3D模型数据集，具有在建筑信息建模（BIM）等领域的潜在应用。&lt;h4&gt;总结&lt;/h4&gt;LiMRSF系统通过增强现实技术改善了室内SLAM的重建质量，帮助用户快速识别和纠正盲点及错误。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Indoor SLAM often suffers from issues such as scene drifting, double walls,and blind spots, particularly in confined spaces with objects close to thesensors (e.g. LiDAR and cameras) in reconstruction tasks. Real-timevisualization of point cloud registration during data collection may helpmitigate these issues, but a significant limitation remains in the inability toin-depth compare the scanned data with actual physical environments. Thesechallenges obstruct the quality of reconstruction products, frequentlynecessitating revisit and rescan efforts. For this regard, we developed theLiMRSF (LiDAR-MR-RGB Sensor Fusion) system, allowing users to perceive thein-situ point cloud registration by looking through a Mixed-Reality (MR)headset. This tailored framework visualizes point cloud meshes as holograms,seamlessly matching with the real-time scene on see-through glasses, andautomatically highlights errors detected while they overlap. Such holographicelements are transmitted via a TCP server to an MR headset, where it iscalibrated to align with the world coordinate, the physical location. Thisallows users to view the localized reconstruction product instantaneously,enabling them to quickly identify blind spots and errors, and take promptaction on-site. Our blind spot detector achieves an error detection precisionwith an F1 Score of 75.76% with acceptably high fidelity of monitoring throughthe LiMRSF system (highest SSIM of 0.5619, PSNR of 14.1004, and lowest MSE of0.0389 in the five different sections of the simplified mesh model which usersvisualize through the LiMRSF device see-through glasses). This method ensuresthe creation of detailed, high-quality datasets for 3D models, with potentialapplications in Building Information Modeling (BIM) but not limited.</description>
      <author>example@mail.com (Hanbeom Chang, Jongseong Brad Choi, Chul Min Yeum)</author>
      <guid isPermaLink="false">2411.12514v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Open-Vocabulary Octree-Graph for 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2411.16253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11pages,7figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;开放词汇的3D场景理解对具身智能体至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出Octree-Graph，以提高开放词汇的3D场景理解效率。&lt;h4&gt;方法&lt;/h4&gt;设计了时间组分合并（CGSM）策略和实例特征聚合（IFA）算法来获取3D实例和语义特征，并开发了自适应八叉树结构以存储语义和物体占用信息。&lt;h4&gt;主要发现&lt;/h4&gt;Octree-Graph的每个自适应八叉树作为图节点，边缘描述节点之间的空间关系，经过广泛实验验证了方法的有效性和多功能性。&lt;h4&gt;结论&lt;/h4&gt;该方法在各种任务上表现出色，解决了现有点云表示的局限性。&lt;h4&gt;总结&lt;/h4&gt;Octree-Graph为开放词汇3D场景理解提供了新的表示方式，提升了后续任务的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D scene understanding is indispensable for embodied agents.Recent works leverage pretrained vision-language models (VLMs) for objectsegmentation and project them to point clouds to build 3D maps. Despiteprogress, a point cloud is a set of unordered coordinates that requiressubstantial storage space and does not directly convey occupancy information orspatial relation, making existing methods inefficient for downstream tasks,e.g., path planning and complex text-based object retrieval. To address theseissues, we propose Octree-Graph, a novel scene representation foropen-vocabulary 3D scene understanding. Specifically, a ChronologicalGroup-wise Segment Merging (CGSM) strategy and an Instance Feature Aggregation(IFA) algorithm are first designed to get 3D instances and correspondingsemantic features. Subsequently, an adaptive-octree structure is developed thatstores semantics and depicts the occupancy of an object adjustably according toits shape. Finally, the Octree-Graph is constructed where each adaptive-octreeacts as a graph node, and edges describe the spatial relations among nodes.Extensive experiments on various tasks are conducted on several widely-useddatasets, demonstrating the versatility and effectiveness of our method.</description>
      <author>example@mail.com (Zhigang Wang, Yifei Su, Chenhui Li, Dong Wang, Yan Huang, Bin Zhao, Xuelong Li)</author>
      <guid isPermaLink="false">2411.16253v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Quantum-enhanced unsupervised image segmentation for medical images analysis</title>
      <link>http://arxiv.org/abs/2411.15086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;乳腺癌是全球女性癌症相关死亡的主要原因，需要放射科医生仔细检查乳腺X光片以识别异常病变。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于量子增强的无监督乳腺X光图像分割框架，旨在提高分割精度并降低计算资源需求。&lt;h4&gt;方法&lt;/h4&gt;引入量子启发的图像表示作为分割掩模的初步近似，将分割任务形式化为QUBO问题，以最大化背景与肿瘤区域之间的对比度，并确保分割掩模的连通性最小化。&lt;h4&gt;主要发现&lt;/h4&gt;量子退火和变分量子电路在图像分割中表现出与经典优化技术相当的性能，且量子退火在实验中显示出比经典优化方法快一个数量级。&lt;h4&gt;结论&lt;/h4&gt;该框架的性能与现有最先进的监督方法（包括基于UNet的架构）相当，提供了一种可行的无监督乳腺癌图像分割替代方案。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了量子增强技术在无监督医学图像分割中的潜力，能够平衡分割精度与计算要求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Breast cancer remains the leading cause of cancer-related mortality amongwomen worldwide, necessitating the meticulous examination of mammograms byradiologists to characterize abnormal lesions. This manual process demands highaccuracy and is often time-consuming, costly, and error-prone. Automated imagesegmentation using artificial intelligence offers a promising alternative tostreamline this workflow. However, most existing methods are supervised,requiring large, expertly annotated datasets that are not always available, andthey experience significant generalization issues. Thus, unsupervised learningmodels can be leveraged for image segmentation, but they come at a cost ofreduced accuracy, or require extensive computational resourcess. In this paper,we propose the first end-to-end quantum-enhanced framework for unsupervisedmammography medical images segmentation that balances between performanceaccuracy and computational requirements. We first introduce a quantum-inspiredimage representation that serves as an initial approximation of thesegmentation mask. The segmentation task is then formulated as a QUBO problem,aiming to maximize the contrast between the background and the tumor regionwhile ensuring a cohesive segmentation mask with minimal connected components.We conduct an extensive evaluation of quantum and quantum-inspired methods forimage segmentation, demonstrating that quantum annealing and variationalquantum circuits achieve performance comparable to classical optimizationtechniques. Notably, quantum annealing is shown to be an order of magnitudefaster than the classical optimization method in our experiments. Our findingsdemonstrate that this framework achieves performance comparable tostate-of-the-art supervised methods, including UNet-based architectures,offering a viable unsupervised alternative for breast cancer imagesegmentation.</description>
      <author>example@mail.com (Laia Domingo, Mahdi Chehimi)</author>
      <guid isPermaLink="false">2411.15086v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Interpreting Object-level Foundation Models via Visual Precision Search</title>
      <link>http://arxiv.org/abs/2411.16198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态预训练的进展推动了以对象为基础的模型在视觉定位和对象检测等任务中的应用，但解读这些模型的决策变得越来越困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法以改进对象级任务的可解释性，解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;我们提出了一种视觉精确搜索方法，能够生成更少区域的准确归因图，避免了内部模型参数的干扰，采用稀疏子区域划分和一致性、协作评分来识别关键决策区域。&lt;h4&gt;主要发现&lt;/h4&gt;在RefCOCO、MS COCO和LVIS上的实验表明，我们的方法在Grounding DINO和Florence-2的对象级任务可解释性上超越了现有的最先进技术，取得了显著的信度提升。&lt;h4&gt;结论&lt;/h4&gt;我们的技术不仅提升了解释能力，还能分析视觉定位和对象检测任务中的失败，超越了现有方法。&lt;h4&gt;总结&lt;/h4&gt;我们的方法在多个评估指标上表现优异，代码将在GitHub上发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in multimodal pre-training have propelled object-level foundationmodels, such as Grounding DINO and Florence-2, in tasks like visual groundingand object detection. However, interpreting these models\' decisions has grownincreasingly challenging. Existing interpretable attribution methods forobject-level task interpretation have notable limitations: (1) gradient-basedmethods lack precise localization due to visual-textual fusion in foundationmodels, and (2) perturbation-based methods produce noisy saliency maps,limiting fine-grained interpretability. To address these, we propose a VisualPrecision Search method that generates accurate attribution maps with fewerregions. Our method bypasses internal model parameters to overcome attributionissues from multimodal fusion, dividing inputs into sparse sub-regions andusing consistency and collaboration scores to accurately identify criticaldecision-making regions. We also conducted a theoretical analysis of theboundary guarantees and scope of applicability of our method. Experiments onRefCOCO, MS COCO, and LVIS show our approach enhances object-level taskinterpretability over SOTA for Grounding DINO and Florence-2 across variousevaluation metrics, with faithfulness gains of 23.7\%, 31.6\%, and 20.1\% on MSCOCO, LVIS, and RefCOCO for Grounding DINO, and 102.9\% and 66.9\% on MS COCOand RefCOCO for Florence-2. Additionally, our method can interpret failures invisual grounding and object detection tasks, surpassing existing methods acrossmultiple evaluation metrics. The code will be released at\url{https://github.com/RuoyuChen10/VPS}.</description>
      <author>example@mail.com (Ruoyu Chen, Siyuan Liang, Jingzhi Li, Shiming Liu, Maosen Li, Zheng Huang, Hua Zhang, Xiaochun Cao)</author>
      <guid isPermaLink="false">2411.16198v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations</title>
      <link>http://arxiv.org/abs/2411.13451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 3 figures, an abridged version to appear in NeurIPS 2024
  AFM Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的多模态网络代理依赖于多模态大型语言模型（MLLMs），能够自主执行多种网络任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于人类示范的少样本适应性代理构建方法，以克服现有网络代理在未见网站和领域中的自动化任务的困难。&lt;h4&gt;方法&lt;/h4&gt;引入AdaptAgent框架，使得多模态网络代理能够通过少量人类示范（最多2个）适应新的网站和领域。&lt;h4&gt;主要发现&lt;/h4&gt;在Mind2Web和VisualWebArena两个基准测试中，使用上下文示范或元适应示范的成功率提高了3.36%至7.21%，相对提升21.03%至65.75%。&lt;h4&gt;结论&lt;/h4&gt;研究结果揭示了在大规模预训练和微调之外，开发广泛适用的多模态网络代理的另一条途径，强调了少样本适应性的重要性。&lt;h4&gt;总结&lt;/h4&gt;通过人类示范，AdaptAgent框架有效提升了网络代理在新环境中的表现，推动了多模态网络代理的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State-of-the-art multimodal web agents, powered by Multimodal Large LanguageModels (MLLMs), can autonomously execute many web tasks by processing userinstructions and interacting with graphical user interfaces (GUIs). Currentstrategies for building web agents rely on (i) the generalizability ofunderlying MLLMs and their steerability via prompting, and (ii) large-scalefine-tuning of MLLMs on web-related tasks. However, web agents still struggleto automate tasks on unseen websites and domains, limiting their applicabilityto enterprise-specific and proprietary platforms. Beyond generalization fromlarge-scale pre-training and fine-tuning, we propose building agents forfew-shot adaptability using human demonstrations. We introduce the AdaptAgentframework that enables both proprietary and open-weights multimodal web agentsto adapt to new websites and domains using few human demonstrations (up to 2).Our experiments on two popular benchmarks -- Mind2Web &amp; VisualWebArena -- showthat using in-context demonstrations (for proprietary models) ormeta-adaptation demonstrations (for meta-learned open-weights models) booststask success rate by 3.36% to 7.21% over non-adapted state-of-the-art models,corresponding to a relative increase of 21.03% to 65.75%. Furthermore, ouradditional analyses (a) show the effectiveness of multimodal demonstrationsover text-only ones, (b) shed light on the influence of different dataselection strategies during meta-learning on the generalization of the agent,and (c) demonstrate the effect of number of few-shot examples on the webagent's success rate. Overall, our results unlock a complementary axis fordeveloping widely applicable multimodal web agents beyond large-scalepre-training and fine-tuning, emphasizing few-shot adaptability.</description>
      <author>example@mail.com (Gaurav Verma, Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Tucker Balch, Manuela Veloso)</author>
      <guid isPermaLink="false">2411.13451v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Retrieval Augmented Multi-modal Generation: A Benchmark, Evaluate Metrics and Strong Baselines</title>
      <link>http://arxiv.org/abs/2411.16365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文研究多模态检索增强多模态生成（M$^2$RAG）任务，该任务需要基础模型浏览包含文本和图像的多模态网页，并生成多模态响应以解决用户查询。&lt;h4&gt;目的&lt;/h4&gt;填补M$^2$RAG任务的系统研究和分析的空白。&lt;h4&gt;方法&lt;/h4&gt;构建M$^2$RAG任务基准，配备文本模态和多模态指标，以分析现有基础模型的能力，并提出几种有效的方法帮助基础模型完成该任务。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验结果揭示了一些值得进一步研究的有趣现象。&lt;h4&gt;结论&lt;/h4&gt;通过系统的评估结果，推动了对M$^2$RAG任务的理解和研究。&lt;h4&gt;总结&lt;/h4&gt;本研究为多模态检索和生成领域提供了基准和方法，有助于未来的深入研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates an intriguing task of Multi-modal Retrieval AugmentedMulti-modal Generation (M$^2$RAG). This task requires foundation models tobrowse multi-modal web pages, with mixed text and images, and generatemulti-modal responses for solving user queries, which exhibits betterinformation density and readability. Given the early researching stage ofM$^2$RAG task, there is a lack of systematic studies and analysis. To fill thisgap, we construct a benchmark for M$^2$RAG task, equipped with a suite oftext-modal metrics and multi-modal metrics to analyze the capabilities ofexisting foundation models. Besides, we also propose several effective methodsfor foundation models to accomplish this task, based on the comprehensiveevaluation results on our benchmark. Extensive experimental results revealseveral intriguing phenomena worth further research.</description>
      <author>example@mail.com (Zi-Ao Ma, Tian Lan, Rong-Cheng Tu, Yong Hu, Heyan Huang, Xian-Ling Mao)</author>
      <guid isPermaLink="false">2411.16365v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Granularity Class Prototype Topology Distillation for Class-Incremental Source-Free Unsupervised Domain Adaptation</title>
      <link>http://arxiv.org/abs/2411.16064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文探讨了无监督领域适应中的增量类源无关问题（CI-SFUDA），即在没有标记源实例的情况下，增量获取无标记目标数据。&lt;h4&gt;目的&lt;/h4&gt;解决相似源类知识对目标类表示学习的干扰以及将新目标知识与旧知识的整合问题。&lt;h4&gt;方法&lt;/h4&gt;提出了多粒度类原型拓扑蒸馏（GROTO）算法，通过多粒度类原型自组织模块和原型拓扑蒸馏模块有效传递源知识到无标记的增量目标领域。&lt;h4&gt;主要发现&lt;/h4&gt;通过建模两个累积分布挖掘正类，并通过引入多粒度类原型生成可靠的伪标签，促进正类目标特征自组织，最终实现了源和目标特征空间的拓扑结构构建。&lt;h4&gt;结论&lt;/h4&gt;在三组公共数据集上进行的广泛实验表明，所提方法在性能上达到了最新的最佳水平。&lt;h4&gt;总结&lt;/h4&gt;GROTO算法有效解决了CI-SFUDA中的两个主要挑战，推动了无监督领域适应的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the Class-Incremental Source-Free Unsupervised DomainAdaptation (CI-SFUDA) problem, where the unlabeled target data comeincrementally without access to labeled source instances. This problem posestwo challenges, the disturbances of similar source-class knowledge totarget-class representation learning and the new target knowledge to old ones.To address them, we propose the Multi-Granularity Class Prototype TopologyDistillation (GROTO) algorithm, which effectively transfers the sourceknowledge to the unlabeled class-incremental target domain. Concretely, wedesign the multi-granularity class prototype self-organization module andprototype topology distillation module. Firstly, the positive classes are minedby modeling two accumulation distributions. Then, we generate reliablepseudo-labels by introducing multi-granularity class prototypes, and use themto promote the positive-class target feature self-organization. Secondly, thepositive-class prototypes are leveraged to construct the topological structuresof source and target feature spaces. Then, we perform the topology distillationto continually mitigate the interferences of new target knowledge to old ones.Extensive experiments demonstrate that our proposed method achievesstate-of-the-art performances on three public datasets.</description>
      <author>example@mail.com (Peihua Deng, Jiehua Zhang, Xichun Sheng, Chenggang Yan, Yaoqi Sun, Ying Fu, Liang Li)</author>
      <guid isPermaLink="false">2411.16064v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks-based Parameter Design towards Large-Scale Superconducting Quantum Circuits for Crosstalk Mitigation</title>
      <link>http://arxiv.org/abs/2411.16354v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;为了展示量子计算的优越性，设计和制造越来越大规模的超导量子计算芯片，推动了电子设计自动化的需求，以追求更好的效率和效果。&lt;h4&gt;目的&lt;/h4&gt;提出一种用于大规模超导量子电路的参数设计算法。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络（GNN）的可扩展性，算法基于'三阶梯缩放'机制，包含两个神经网络模型：一个是监督学习的小规模电路评估器，另一个是无监督学习的中规模电路设计器。&lt;h4&gt;主要发现&lt;/h4&gt;算法在减轻量子串扰错误方面表现出色，特别是在处理由超导量子电路的图结构和参数分配引发的错误时。&lt;h4&gt;结论&lt;/h4&gt;经过良好训练的设计器在效率和效果上均具有显著优势，尤其在处理大规模电路时，训练设计器完成频率设计任务所需时间大幅缩短。&lt;h4&gt;总结&lt;/h4&gt;本研究初步展示了将图神经网络应用于量子处理器参数设计的优势，并为电子设计自动化中大型数值模拟面临的挑战提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To demonstrate supremacy of quantum computing, increasingly large-scalesuperconducting quantum computing chips are being designed and fabricated,sparking the demand for electronic design automation in pursuit of betterefficiency and effectiveness. However, the complexity of simulating quantumsystems poses a significant challenge to computer-aided design of quantumchips. Harnessing the scalability of graph neural networks (GNNs), we herepropose a parameter designing algorithm for large-scale superconducting quantumcircuits. The algorithm depends on the so-called 'three-stair scaling'mechanism, which comprises two neural-network models: an evaluator supervisedlytrained on small-scale circuits for applying to medium-scale circuits, and adesigner unsupervisedly trained on medium-scale circuits for applying tolarge-scale ones. We demonstrate our algorithm in mitigating quantum crosstalkerrors, which are commonly present and closely related to the graph structuresand parameter assignments of superconducting quantum circuits. Parameters forboth single- and two-qubit gates are considered simultaneously. Numericalresults indicate that the well-trained designer achieves notable advantages notonly in efficiency but also in effectiveness, especially for large-scalecircuits. For example, in superconducting quantum circuits consisting of around870 qubits, the trained designer requires only 27 seconds to complete thefrequency designing task which necessitates 90 minutes for the traditionalSnake algorithm. More importantly, the crosstalk errors using our algorithm areonly 51% of those produced by the Snake algorithm. Overall, this studyinitially demonstrates the advantages of applying graph neural networks todesign parameters in quantum processors, and provides insights for systemswhere large-scale numerical simulations are challenging in electronic designautomation.</description>
      <author>example@mail.com (Hao Ai, Yu-xi Liu)</author>
      <guid isPermaLink="false">2411.16354v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Privacy-Preserving Federated Foundation Model for Generalist Ultrasound Artificial Intelligence</title>
      <link>http://arxiv.org/abs/2411.16380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;超声成像因其无创性和实时能力而广泛用于临床诊断，但传统超声诊断存在医生专业知识依赖性强和图像质量不佳等限制，导致解读困难和诊断错误的可能性增加。&lt;h4&gt;目的&lt;/h4&gt;探讨人工智能在增强临床诊断中的潜力，特别是在各种生物医学成像模式下检测异常的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种创新的隐私保护超声基础模型UltraFedFM，该模型通过跨越9个国家16个医疗机构的联合学习进行预训练，利用超过100万幅涵盖19个器官和10种超声模式的超声图像数据集。&lt;h4&gt;主要发现&lt;/h4&gt;UltraFedFM在疾病诊断中达到0.927的接收者操作特征曲线下的平均面积，以及0.878的病灶分割dice相似系数，超越中级超声医师的诊断准确性，并与专家级超声医师的表现相当。&lt;h4&gt;结论&lt;/h4&gt;UltraFedFM在增强临床诊断的同时，保护患者隐私，标志着人工智能驱动的超声成像在未来临床应用中的进步。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了AI在超声成像中的应用潜力，解决了数据隐私和模型适用性的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ultrasound imaging is widely used in clinical diagnosis due to itsnon-invasive nature and real-time capabilities. However, conventionalultrasound diagnostics face several limitations, including high dependence onphysician expertise and suboptimal image quality, which complicatesinterpretation and increases the likelihood of diagnostic errors. Artificialintelligence (AI) has emerged as a promising solution to enhance clinicaldiagnosis, particularly in detecting abnormalities across various biomedicalimaging modalities. Nonetheless, current AI models for ultrasound imaging facecritical challenges. First, these models often require large volumes of labeledmedical data, raising concerns over patient privacy breaches. Second, mostexisting models are task-specific, which restricts their broader clinicalutility. To overcome these challenges, we present UltraFedFM, an innovativeprivacy-preserving ultrasound foundation model. UltraFedFM is collaborativelypre-trained using federated learning across 16 distributed medical institutionsin 9 countries, leveraging a dataset of over 1 million ultrasound imagescovering 19 organs and 10 ultrasound modalities. This extensive and diversedata, combined with a secure training framework, enables UltraFedFM to exhibitstrong generalization and diagnostic capabilities. It achieves an average areaunder the receiver operating characteristic curve of 0.927 for diseasediagnosis and a dice similarity coefficient of 0.878 for lesion segmentation.Notably, UltraFedFM surpasses the diagnostic accuracy of mid-levelultrasonographers and matches the performance of expert-level sonographers inthe joint diagnosis of 8 common systemic diseases. These findings indicate thatUltraFedFM can significantly enhance clinical diagnostics while safeguardingpatient privacy, marking an advancement in AI-driven ultrasound imaging forfuture clinical applications.</description>
      <author>example@mail.com (Yuncheng Jiang, Chun-Mei Feng, Jinke Ren, Jun Wei, Zixun Zhang, Yiwen Hu, Yunbi Liu, Rui Sun, Xuemei Tang, Juan Du, Xiang Wan, Yong Xu, Bo Du, Xin Gao, Guangyu Wang, Shaohua Zhou, Shuguang Cui, Rick Siow Mong Goh, Yong Liu, Zhen Li)</author>
      <guid isPermaLink="false">2411.16380v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Material synthesis through simulations guided by machine learning: a position paper</title>
      <link>http://arxiv.org/abs/2411.13953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大理石废料是石材切割过程中产生的富钙残余物，具有再利用潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种可持续的数据收集方法，以优化大理石废料的混合设计。&lt;h4&gt;方法&lt;/h4&gt;采用机器学习模型和元学习作为优化工具，估算用于骨料的切割废料量，以获取特定机械性能的混合设计。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟生成大数据集，节省数据收集时间和成本，并利用机器学习模型优化混合设计，减少人工实验的需求。&lt;h4&gt;结论&lt;/h4&gt;该方法有助于简化大理石废料的再利用过程，促进石材切割行业的可持续性和效率。&lt;h4&gt;总结&lt;/h4&gt;结合集体数据和先进的机器学习技术，推动大理石废料再利用的可持续发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this position paper, we propose an approach for sustainable datacollection in the field of optimal mix design for marble sludge reuse. Marblesludge, a calcium-rich residual from stone-cutting processes, can be repurposedby mixing it with various ingredients. However, determining the optimal mixdesign is challenging due to the variability in sludge composition and thecostly, time-consuming nature of experimental data collection. Also, weinvestigate the possibility of using machine learning models usingmeta-learning as an optimization tool to estimate the correct quantity ofstone-cutting sludge to be used in aggregates to obtain a mix design withspecific mechanical properties that can be used successfully in the buildingindustry. Our approach offers two key advantages: (i) through simulations, alarge dataset can be generated, saving time and money during the datacollection phase, and (ii) Utilizing machine learning models, with performanceenhancement through hyper-parameter optimization via meta-learning, to estimateoptimal mix designs reducing the need for extensive manual experimentation,lowering costs, minimizing environmental impact, and accelerating theprocessing of quarry sludge. Our idea promises to streamline the marble sludgereuse process by leveraging collective data and advanced machine learning,promoting sustainability and efficiency in the stonecutting sector.</description>
      <author>example@mail.com (Usman Syed, Federico Cunico, Uzair Khan, Eros Radicchi, Francesco Setti, Adolfo Speghini, Paolo Marone, Filiberto Semenzin, Marco Cristani)</author>
      <guid isPermaLink="false">2411.13953v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Local Intrinsic Dimensionality for Dynamic Graph Embeddings</title>
      <link>http://arxiv.org/abs/2411.16145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;局部内在维度（LID）在数据挖掘和机器学习领域具有重要的理论意义和实际应用。&lt;h4&gt;目的&lt;/h4&gt;探讨如何将为静态图设计的LID度量NC-LID适应于动态网络。&lt;h4&gt;方法&lt;/h4&gt;分析基于随机游走的动态图嵌入方法dynnode2vec，并研究NC-LID与10个真实动态网络嵌入的内在质量之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;NC-LID可以作为一个良好的指标，用于识别那些嵌入向量不倾向于保持时间图结构的节点。&lt;h4&gt;结论&lt;/h4&gt;本研究的经验发现为基于LID的动态图嵌入方法提供了第一步的基础。&lt;h4&gt;总结&lt;/h4&gt;研究表明，NC-LID在动态网络中的应用具有潜力，可以改善动态图嵌入的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The notion of local intrinsic dimensionality (LID) has important theoreticalimplications and practical applications in the fields of data mining andmachine learning. Recent research efforts indicate that LID measures definedfor graphs can improve graph representational learning methods based on randomwalks. In this paper, we discuss how NC-LID, a LID measure designed for staticgraphs, can be adapted for dynamic networks. Focusing on dynnode2vec as themost representative dynamic graph embedding method based on random walks, weexamine correlations between NC-LID and the intrinsic quality of 10 real-worlddynamic network embeddings. The obtained results show that NC-LID can be usedas a good indicator of nodes whose embedding vectors do not tend to preservetemporal graph structure well. Thus, our empirical findings constitute thefirst step towards LID-aware dynamic graph embedding methods.</description>
      <author>example@mail.com (Dušica Knežević, Miloš Savić, Miloš Radovanović)</author>
      <guid isPermaLink="false">2411.16145v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning for automated multi-scale functional field boundaries extraction using multi-date Sentinel-2 and PlanetScope imagery: Case Study of Netherlands and Pakistan</title>
      <link>http://arxiv.org/abs/2411.15923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  09 pages, To be published&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究探讨了多时相卫星影像在功能性田界划分中的有效性，使用深度学习语义分割架构。&lt;h4&gt;目的&lt;/h4&gt;提升荷兰和巴基斯坦两个不同地理和多尺度农业系统的田界划分精度。&lt;h4&gt;方法&lt;/h4&gt;获取2022年4月、8月和10月的PlanetScope和Sentinel-2多日期影像，并在巴基斯坦选定区域获取2022年11月及2023年2月和3月的影像。荷兰使用基本登记作物地块（BRP）矢量层作为标注训练数据，巴基斯坦则使用自制的田界矢量数据。评估了四种基于UNET架构的深度学习模型，比较不同多日期影像和NDVI堆栈的效果。&lt;h4&gt;主要发现&lt;/h4&gt;多日期NDVI堆栈提供了额外的时间背景，反映了作物在生长季节不同时间的变化，且多尺度地面信息对于开发稳健的、普适的田界划分模型至关重要。&lt;h4&gt;结论&lt;/h4&gt;在小规模农业地区，精细空间分辨率对于提取田界十分重要，研究结果可以推广至多尺度实施，以改善异质农业环境中的自动田界划分。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了多时相影像和深度学习技术结合在精准农业中的潜力，尤其是在不同地理区域间的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores the effectiveness of multi-temporal satellite imagery forbetter functional field boundary delineation using deep learning semanticsegmentation architecture on two distinct geographical and multi-scale farmingsystems of Netherlands and Pakistan. Multidate images of April, August andOctober 2022 were acquired for PlanetScope and Sentinel-2 in sub regions ofNetherlands and November 2022, February and March 2023 for selected area ofDunyapur in Pakistan. For Netherlands, Basic registration crop parcels (BRP)vector layer was used as labeled training data. while self-crafted fieldboundary vector data were utilized for Pakistan. Four deep learning models withUNET architecture were evaluated using different combinations of multi-dateimages and NDVI stacks in the Netherlands subregions. A comparative analysis ofIoU scores assessed the effectiveness of the proposed multi-date NDVI stackapproach. These findings were then applied for transfer learning, usingpre-trained models from the Netherlands on the selected area in Pakistan.Additionally, separate models were trained using self-crafted field boundarydata for Pakistan, and combined models were developed using data from both theNetherlands and Pakistan. Results indicate that multi-date NDVI stacks provideadditional temporal context, reflecting crop growth over different times of theseason. The study underscores the critical role of multi-scale groundinformation from diverse geographical areas in developing robust anduniversally applicable models for field boundary delineation. The results alsohighlight the importance of fine spatial resolution for extraction of fieldboundaries in regions with small scale framing. The findings can be extended tomulti-scale implementations for improved automatic field boundary delineationin heterogeneous agricultural environments.</description>
      <author>example@mail.com (Saba Zahid, Sajid Ghuffar, Obaid-ur-Rehman, Syed Roshaan Ali Shah)</author>
      <guid isPermaLink="false">2411.15923v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>VisionPAD: A Vision-Centric Pre-training Paradigm for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2411.14716v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了一种新的自监督预训练范式VisionPAD，专为自动驾驶中的视觉算法设计。&lt;h4&gt;目的&lt;/h4&gt;旨在通过更高效的方式重建多视图表示，仅利用图像作为监督。&lt;h4&gt;方法&lt;/h4&gt;使用3D高斯点云重建，并提出自监督方法进行体素速度估计，通过扭曲体素到相邻帧来监督渲染输出，学习序列数据中的运动线索。&lt;h4&gt;主要发现&lt;/h4&gt;采用多帧光度一致性方法增强几何感知，通过根据渲染深度和相对姿态将相邻帧投影到当前帧，提升3D几何表示。&lt;h4&gt;结论&lt;/h4&gt;在自动驾驶数据集上的广泛实验表明，VisionPAD在3D目标检测、占用预测和地图分割方面显著提升性能，超过了现有的预训练策略。&lt;h4&gt;总结&lt;/h4&gt;VisionPAD通过纯图像监督实现了更优的3D表现，展示了其在自动驾驶领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces VisionPAD, a novel self-supervised pre-trainingparadigm designed for vision-centric algorithms in autonomous driving. Incontrast to previous approaches that employ neural rendering with explicitdepth supervision, VisionPAD utilizes more efficient 3D Gaussian Splatting toreconstruct multi-view representations using only images as supervision.Specifically, we introduce a self-supervised method for voxel velocityestimation. By warping voxels to adjacent frames and supervising the renderedoutputs, the model effectively learns motion cues in the sequential data.Furthermore, we adopt a multi-frame photometric consistency approach to enhancegeometric perception. It projects adjacent frames to the current frame based onrendered depths and relative poses, boosting the 3D geometric representationthrough pure image supervision. Extensive experiments on autonomous drivingdatasets demonstrate that VisionPAD significantly improves performance in 3Dobject detection, occupancy prediction and map segmentation, surpassingstate-of-the-art pre-training strategies by a considerable margin.</description>
      <author>example@mail.com (Haiming Zhang, Wending Zhou, Yiyao Zhu, Xu Yan, Jiantao Gao, Dongfeng Bai, Yingjie Cai, Bingbing Liu, Shuguang Cui, Zhen Li)</author>
      <guid isPermaLink="false">2411.14716v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Deep Metric Learning with Coreset for Active Learning in 3D Segmentation</title>
      <link>http://arxiv.org/abs/2411.15763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习在机器学习领域取得显著进展，但通常需要大量标注数据。3D语义分割等任务在医学领域的标注需求尤其高，导致成本上升。&lt;h4&gt;目的&lt;/h4&gt;探讨主动学习（AL）在3D医学分割中的应用，以减轻标注负担。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的度量学习方法结合弱监督与主动学习，采用基于切片的主动学习来进行3D医学分割。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在四个数据集的弱标注和全标注上超越了现有的主动学习技术，并在低标注预算下表现优越。&lt;h4&gt;结论&lt;/h4&gt;通过结合对比学习与医学成像中的数据分组，提出的模型在医学成像中显著降低了标注成本。&lt;h4&gt;总结&lt;/h4&gt;本研究为3D医学分割提供了一种创新的主动学习方法，能够有效减少标注需求并提升模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning has seen remarkable advancements in machine learning, yet itoften demands extensive annotated data. Tasks like 3D semantic segmentationimpose a substantial annotation burden, especially in domains like medicine,where expert annotations drive up the cost. Active learning (AL) holds greatpotential to alleviate this annotation burden in 3D medical segmentation. Themajority of existing AL methods, however, are not tailored to the medicaldomain. While weakly-supervised methods have been explored to reduce annotationburden, the fusion of AL with weak supervision remains unexplored, despite itspotential to significantly reduce annotation costs. Additionally, there islittle focus on slice-based AL for 3D segmentation, which can alsosignificantly reduce costs in comparison to conventional volume-based AL. Thispaper introduces a novel metric learning method for Coreset to performslice-based active learning in 3D medical segmentation. By merging contrastivelearning with inherent data groupings in medical imaging, we learn a metricthat emphasizes the relevant differences in samples for training 3D medicalsegmentation models. We perform comprehensive evaluations using both weak andfull annotations across four datasets (medical and non-medical). Our findingsdemonstrate that our approach surpasses existing active learning techniques onboth weak and full annotations and obtains superior performance withlow-annotation budgets which is crucial in medical imaging. Source code forthis project is available in the supplementary materials and on GitHub:https://github.com/arvindmvepa/al-seg.</description>
      <author>example@mail.com (Arvind Murari Vepa, Zukang Yang, Andrew Choi, Jungseock Joo, Fabien Scalzo, Yizhou Sun)</author>
      <guid isPermaLink="false">2411.15763v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Application of Graph Networks to a wide-field Water-Cherenkov-based Gamma-Ray Observatory</title>
      <link>http://arxiv.org/abs/2411.16565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 12 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;水切伦科夫观测站为高能伽马射线天空观测提供了高工作周期和广视场的基础。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络的深度学习应用，用于背景抑制和能量重建。&lt;h4&gt;方法&lt;/h4&gt;将图神经网络与最新的背景抑制和能量重建方法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;图神经网络在背景抑制方面优于手工设计的分类算法，并且在能量分辨率上优于基于模板的方法。&lt;h4&gt;结论&lt;/h4&gt;图神经网络在伽马射线观测中的应用显示出更好的背景抑制能力和能量重建性能。&lt;h4&gt;总结&lt;/h4&gt;深度学习特别是图神经网络在高能伽马射线观测中具有显著的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Water-Cherenkov-based observatories form the high-duty-cycle and wide fieldof view backbone for observations of the gamma-ray sky at very high energies.For gamma-ray observations, precise event reconstruction and highly effectivebackground rejection are crucial and have been continuously improving in recentyears. In this work, we propose a deep learning application based on graphneural networks (GNNs) for background rejection and energy reconstruction andcompare it to state-of-the-art approaches. We find that GNNs outperformhand-designed classification algorithms and observables in background rejectionand find an improved energy resolution compared to template-based methods.</description>
      <author>example@mail.com (Jonas Glombitza, Martin Schneider, Franziska Leitl, Stefan Funk, Christopher van Eldik)</author>
      <guid isPermaLink="false">2411.16565v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency</title>
      <link>http://arxiv.org/abs/2411.16525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究基于变压器的基础模型的提示调优的统计和计算极限。&lt;h4&gt;目的&lt;/h4&gt;探讨单头变压器在提示调优中的普遍性和效率。&lt;h4&gt;方法&lt;/h4&gt;在单头变压器上进行提示调优，分析其自注意力层的性能，并证明其作为序列到序列Lipschitz函数的通用逼近能力。&lt;h4&gt;主要发现&lt;/h4&gt;{'统计发现': '单层单头变压器的提示调优可以作为通用逼近器。', '计算发现': '识别出提示调优效率的相变，受软提示引导的键和值的范数影响。'}&lt;h4&gt;结论&lt;/h4&gt;在确定的标准下，存在几乎线性时间的提示调优推理算法，而超出该标准后，基于SETH的提示调优不存在亚平方（高效）算法。&lt;h4&gt;应用&lt;/h4&gt;这些极限为设计有效和有表现力的提示调优方法提供了必要条件。&lt;h4&gt;总结&lt;/h4&gt;本研究为提示调优的理论基础提供了重要见解，帮助从业者更好地理解和应用提示调优技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the statistical and computational limits of prompt tuning fortransformer-based foundation models. Our key contributions are prompt tuning on\textit{single-head} transformers with only a \textit{single} self-attentionlayer: (i) is universal, and (ii) supports efficient (even almost-linear time)algorithms under the Strong Exponential Time Hypothesis (SETH). Statistically,we prove that prompt tuning on such simplest possible transformers areuniversal approximators for sequence-to-sequence Lipschitz functions. Inaddition, we provide an exponential-in-$dL$ and -in-$(1/\epsilon)$ lower boundon the required soft-prompt tokens for prompt tuning to memorize any datasetwith 1-layer, 1-head transformers. Computationally, we identify a phasetransition in the efficiency of prompt tuning, determined by the norm of the\textit{soft-prompt-induced} keys and queries, and provide an upper boundcriterion. Beyond this criterion, no sub-quadratic (efficient) algorithm forprompt tuning exists under SETH. Within this criterion, we showcase our theoryby proving the existence of almost-linear time prompt tuning inferencealgorithms. These fundamental limits provide important necessary conditions fordesigning expressive and efficient prompt tuning methods for practitioners.</description>
      <author>example@mail.com (Jerry Yao-Chieh Hu, Wei-Po Wang, Ammar Gilani, Chenyang Li, Zhao Song, Han Liu)</author>
      <guid isPermaLink="false">2411.16525v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning for the Digital Typhoon Dataset: Extensions to Multiple Basins and New Developments in Representations and Tasks</title>
      <link>http://arxiv.org/abs/2411.16421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了数字台风数据集V2，这是一个针对40多年台风卫星图像的最新版本，旨在为长期时空数据的机器学习模型提供基准。&lt;h4&gt;目的&lt;/h4&gt;通过新增南半球热带气旋数据，探讨不同海域和半球之间的区域差异，提出新的研究问题。&lt;h4&gt;方法&lt;/h4&gt;引入自监督学习框架进行表示学习，并结合LSTM模型进行强度预测和额外热带转变预测任务。&lt;h4&gt;主要发现&lt;/h4&gt;对象检测模型在强台风的表现上优于其他模型，同时提出了台风中心估计的新任务。&lt;h4&gt;结论&lt;/h4&gt;研究了机器学习模型在不同海域和半球之间的泛化能力，训练模型于北半球数据并在南半球数据上进行测试。&lt;h4&gt;数据集获取&lt;/h4&gt;该数据集可公开获取，链接为 http://agora.ex.nii.ac.jp/digital-typhoon/dataset/ 和 https://github.com/kitamoto-lab/digital-typhoon/。&lt;h4&gt;总结&lt;/h4&gt;数字台风数据集V2为研究台风的时空特征和提升机器学习模型性能提供了重要资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/kitamoto-lab/digital-typhoon&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the Digital Typhoon Dataset V2, a new version of thelongest typhoon satellite image dataset for 40+ years aimed at benchmarkingmachine learning models for long-term spatio-temporal data. The new addition inDataset V2 is tropical cyclone data from the southern hemisphere, in additionto the northern hemisphere data in Dataset V1. Having data from two hemispheresallows us to ask new research questions about regional differences acrossbasins and hemispheres. We also discuss new developments in representations andtasks of the dataset. We first introduce a self-supervised learning frameworkfor representation learning. Combined with the LSTM model, we discussperformance on intensity forecasting and extra-tropical transition forecastingtasks. We then propose new tasks, such as the typhoon center estimation task.We show that an object detection-based model performs better for strongertyphoons. Finally, we study how machine learning models can generalize acrossbasins and hemispheres, by training the model on the northern hemisphere dataand testing it on the southern hemisphere data. The dataset is publiclyavailable at \url{http://agora.ex.nii.ac.jp/digital-typhoon/dataset/} and\url{https://github.com/kitamoto-lab/digital-typhoon/}.</description>
      <author>example@mail.com (Asanobu Kitamoto, Erwan Dzik, Gaspar Faure)</author>
      <guid isPermaLink="false">2411.16421v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>An End-to-End Robust Point Cloud Semantic Segmentation Network with Single-Step Conditional Diffusion Models</title>
      <link>http://arxiv.org/abs/2411.16308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的条件去噪扩散概率模型（DDPMs）在3D场景理解任务中面临挑战，复杂的几何细节使得从语义标签拟合数据分布的梯度变得困难，导致训练和推理时间较长。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于条件噪声框架（CNF）的端到端鲁棒语义分割网络（CDSegNet），旨在提高3D场景的语义理解能力。&lt;h4&gt;方法&lt;/h4&gt;CDSegNet将噪声网络建模为可学习的噪声特征生成器，使得条件网络能够在多级特征扰动下理解3D场景语义。&lt;h4&gt;主要发现&lt;/h4&gt;CDSegNet在实验中表现出强大的噪声和稀疏性鲁棒性，能够在未见场景中增强泛化能力。&lt;h4&gt;结论&lt;/h4&gt;CDSegNet通过避免直接拟合语义标签的分数，能够像非DDPMs一样实现单一步骤推理，并在公共室内和室外基准测试中显著超越现有方法，达到了最新的性能。&lt;h4&gt;总结&lt;/h4&gt;CDSegNet通过创新的条件噪声框架和鲁棒的噪声特征生成，提高了3D场景的语义分割能力，展现了良好的实用性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing conditional Denoising Diffusion Probabilistic Models (DDPMs) with aNoise-Conditional Framework (NCF) remain challenging for 3D scene understandingtasks, as the complex geometric details in scenes increase the difficulty offitting the gradients of the data distribution (the scores) from semanticlabels. This also results in longer training and inference time for DDPMscompared to non-DDPMs. From a different perspective, we delve deeply into themodel paradigm dominated by the Conditional Network. In this paper, we proposean end-to-end robust semantic \textbf{Seg}mentation \textbf{Net}work based on a\textbf{C}onditional-Noise Framework (CNF) of D\textbf{D}PMs, named\textbf{CDSegNet}. Specifically, CDSegNet models the Noise Network (NN) as alearnable noise-feature generator. This enables the Conditional Network (CN) tounderstand 3D scene semantics under multi-level feature perturbations,enhancing the generalization in unseen scenes. Meanwhile, benefiting from thenoise system of DDPMs, CDSegNet exhibits strong noise and sparsity robustnessin experiments. Moreover, thanks to CNF, CDSegNet can generate the semanticlabels in a single-step inference like non-DDPMs, due to avoiding directlyfitting the scores from semantic labels in the dominant network of CDSegNet. Onpublic indoor and outdoor benchmarks, CDSegNet significantly outperformsexisting methods, achieving state-of-the-art performance.</description>
      <author>example@mail.com (Wentao Qu, Jing Wang, YongShun Gong, Xiaoshui Huang, Liang Xiao)</author>
      <guid isPermaLink="false">2411.16308v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Automatic marker-free registration based on similar tetrahedras for single-tree point clouds</title>
      <link>http://arxiv.org/abs/2411.13069v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  remote sensing; terrestrial lidar; multi-scan cloud registration&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，地面激光扫描技术被广泛用于收集树木点云数据，辅助测量胸径、生物量等林业调查数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于相似四面体的无标记自动注册方法，以实现单棵树点云的注册。&lt;h4&gt;方法&lt;/h4&gt;利用来自同一棵树的两次扫描生成树骨架，并构建关键点集；根据相似性原则过滤和匹配四面体，选择匹配四面体的顶点作为匹配点对，完成粗略注册；然后应用ICP方法获取精细注册参数，完成点云的精确注册。&lt;h4&gt;主要发现&lt;/h4&gt;实验使用八棵不同物种和形状的树木的地面激光扫描数据进行评估，结果表明所提方法在注册精度上显著优于传统的ICP和NDT方法，速度分别快593倍和113倍。&lt;h4&gt;结论&lt;/h4&gt;所提方法在单棵树点云注册中表现出良好的鲁棒性，在精度和速度上相比传统方法具有显著优势，显示出良好的实际注册应用前景。&lt;h4&gt;总结&lt;/h4&gt;该研究表明，基于相似四面体的自动注册方法在森林调查中具有重要应用价值，能够有效提升点云注册的效率与精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, terrestrial laser scanning technology has been widely usedto collect tree point cloud data, aiding in measurements of diameter at breastheight, biomass, and other forestry survey data. Since a single scan fromterrestrial laser systems captures data from only one angle, multiple scansmust be registered and fused to obtain complete tree point cloud data. Thispaper proposes a marker-free automatic registration method for single-treepoint clouds based on similar tetrahedras. First, two point clouds from twoscans of the same tree are used to generate tree skeletons, and key point setsare constructed from these skeletons. Tetrahedra are then filtered and matchedaccording to similarity principles, with the vertices of these two matchedtetrahedras selected as matching point pairs, thus completing the coarseregistration of the point clouds from the two scans. Subsequently, the ICPmethod is applied to the coarse-registered leaf point clouds to obtain fineregistration parameters, completing the precise registration of the two treepoint clouds. Experiments were conducted using terrestrial laser scanning datafrom eight trees, each from different species and with varying shapes. Theproposed method was evaluated using RMSE and Hausdorff distance, comparedagainst the traditional ICP and NDT methods. The experimental resultsdemonstrate that the proposed method significantly outperforms both ICP and NDTin registration accuracy, achieving speeds up to 593 times and 113 times fasterthan ICP and NDT, respectively. In summary, the proposed method shows goodrobustness in single-tree point cloud registration, with significant advantagesin accuracy and speed compared to traditional ICP and NDT methods, indicatingexcellent application prospects in practical registration scenarios.</description>
      <author>example@mail.com (Jing Ren, Pei Wang, Hanlong Li, Yuhan Wu, Yuhang Gao, Wenxin Chen, Mingtai Zhang, Lingyun Zhang)</author>
      <guid isPermaLink="false">2411.13069v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning for Motion Classification in Ankle Exoskeletons Using Surface EMG and IMU Signals</title>
      <link>http://arxiv.org/abs/2411.16273v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;脚踝外骨骼在提升移动能力和减少老年人跌倒风险方面受到广泛关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的运动预测框架，以准确实时预测用户的意图动作。&lt;h4&gt;方法&lt;/h4&gt;集成三种惯性测量单元（IMUs）和八个表面肌电图（sEMG）传感器，捕捉运动和肌肉活动数据。&lt;h4&gt;主要发现&lt;/h4&gt;卷积神经网络（CNN）在五个运动任务的数据集上略优于长短期记忆网络（LSTM），分类准确率分别为96.5%和87.5%。&lt;h4&gt;结论&lt;/h4&gt;该系统在迁移学习方面表现出色，仅需十个样本即可准确分类新对象的动作，模型在传感器故障情况下仍能保持可靠性能，证明深度学习算法在增强脚踝外骨骼功能和安全性方面的潜力。&lt;h4&gt;总结&lt;/h4&gt;研究结果强调了深度学习算法在日常生活中提升脚踝外骨骼可用性的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ankle exoskeletons have garnered considerable interest for their potential toenhance mobility and reduce fall risks, particularly among the agingpopulation. The efficacy of these devices relies on accurate real-timeprediction of the user's intended movements through sensor-based inputs. Thispaper presents a novel motion prediction framework that integrates threeInertial Measurement Units (IMUs) and eight surface Electromyography (sEMG)sensors to capture both kinematic and muscular activity data. A comprehensiveset of activities, representative of everyday movements in barrier-freeenvironments, was recorded for the purpose. Our findings reveal thatConvolutional Neural Networks (CNNs) slightly outperform Long Short-Term Memory(LSTM) networks on a dataset of five motion tasks, achieving classificationaccuracies of $96.5 \pm 0.8 \%$ and $87.5 \pm 2.9 \%$, respectively.Furthermore, we demonstrate the system's proficiency in transfer learning,enabling accurate motion classification for new subjects using just ten samplesper class for finetuning. The robustness of the model is demonstrated by itsresilience to sensor failures resulting in absent signals, maintaining reliableperformance in real-world scenarios. These results underscore the potential ofdeep learning algorithms to enhance the functionality and safety of ankleexoskeletons, ultimately improving their usability in daily life.</description>
      <author>example@mail.com (Silas Ruhrberg Estévez, Josée Mallah, Dominika Kazieczko, Chenyu Tang, Luigi G. Occhipinti)</author>
      <guid isPermaLink="false">2411.16273v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>FUN-AD: Fully Unsupervised Learning for Anomaly Detection with Noisy Training Data</title>
      <link>http://arxiv.org/abs/2411.16110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at WACV 2025. Supplementary material included after
  references. 17 pages, 7 figures, 14 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;主流的异常检测研究主要关注单类分类，但实际工业环境中常因标注错误或新旧产品缺乏标签而导致训练数据噪声。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于学习的全无监督异常检测方法，以处理未标记和可能被污染的训练数据。&lt;h4&gt;方法&lt;/h4&gt;基于两个观察提出新方法：一是正常样本之间的成对特征距离通常小于异常样本或异质样本之间的距离；二是相互最接近的特征对可能是同质对。使用迭代重构的记忆库进行伪标记，并引入新损失函数促进同质性。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公共工业异常基准和语义异常示例上的实验结果验证了FUN-AD在不同场景和异常与正常比率下的有效性。&lt;h4&gt;结论&lt;/h4&gt;FUN-AD方法有效应对了工业环境中异常检测的挑战，适用于不同的异常检测场景。&lt;h4&gt;总结&lt;/h4&gt;本文提出的方法为全无监督异常检测提供了一种新的思路，能够处理复杂的训练数据问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hy-vision-lab/funad&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While the mainstream research in anomaly detection has mainly followed theone-class classification, practical industrial environments often incur noisytraining data due to annotation errors or lack of labels for new or refurbishedproducts. To address these issues, we propose a novel learning-based approachfor fully unsupervised anomaly detection with unlabeled and potentiallycontaminated training data. Our method is motivated by two observations, thati) the pairwise feature distances between the normal samples are on averagelikely to be smaller than those between the anomaly samples or heterogeneoussamples and ii) pairs of features mutually closest to each other are likely tobe homogeneous pairs, which hold if the normal data has smaller variance thanthe anomaly data. Building on the first observation that nearest-neighbordistances can distinguish between confident normal samples and anomalies, wepropose a pseudo-labeling strategy using an iteratively reconstructed memorybank (IRMB). The second observation is utilized as a new loss function topromote class-homogeneity between mutually closest pairs thereby reducing theill-posedness of the task. Experimental results on two public industrialanomaly benchmarks and semantic anomaly examples validate the effectiveness ofFUN-AD across different scenarios and anomaly-to-normal ratios. Our code isavailable at https://github.com/HY-Vision-Lab/FUNAD.</description>
      <author>example@mail.com (Jiin Im, Yongho Son, Je Hyeong Hong)</author>
      <guid isPermaLink="false">2411.16110v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MetaCropFollow: Few-Shot Adaptation with Meta-Learning for Under-Canopy Navigation</title>
      <link>http://arxiv.org/abs/2411.14092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主的植被下导航面临比植被上导航更多的挑战，包括作物行间距狭窄、GPS精度下降和环境杂乱。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过元学习克服领域转移问题，以提高在低数据环境下的导航能力。&lt;h4&gt;方法&lt;/h4&gt;使用元学习训练一个基础学习器，使其能够快速适应新的环境条件。&lt;h4&gt;主要发现&lt;/h4&gt;基础学习器能够在变化的农业环境中实现更稳健的导航。&lt;h4&gt;结论&lt;/h4&gt;元学习可以有效地应对农业环境的领域转移，并在数据较少的情况下保持良好的导航性能。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了元学习在农业自主导航中的应用潜力，尤其是在面对环境变化时的适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous under-canopy navigation faces additional challenges compared toover-canopy settings - for example the tight spacing between the crop rows,degraded GPS accuracy and excessive clutter. Keypoint-based visual navigationhas been shown to perform well in these conditions, however the differencesbetween agricultural environments in terms of lighting, season, soil and croptype mean that a domain shift will likely be encountered at some point of therobot deployment. In this paper, we explore the use of Meta-Learning toovercome this domain shift using a minimal amount of data. We train abase-learner that can quickly adapt to new conditions, enabling more robustnavigation in low-data regimes.</description>
      <author>example@mail.com (Thomas Woehrle, Arun N. Sivakumar, Naveen Uppalapati, Girish Chowdhary)</author>
      <guid isPermaLink="false">2411.14092v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>MSSF: A 4D Radar and Camera Fusion Framework With Multi-Stage Sampling for 3D Object Detection in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2411.15016v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;4D毫米波雷达作为新兴的汽车传感器，具有比传统3D雷达更高的分辨率和精确的高度测量能力，但点云仍然稀疏和嘈杂，难以满足自动驾驶的需求。相机作为常用传感器，可以捕捉丰富的语义信息。&lt;h4&gt;目的&lt;/h4&gt;融合4D雷达和相机，提供一种经济且稳健的自动驾驶感知解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一种简单而有效的多阶段采样融合（MSSF）网络，设计了一个融合模块，能够深度交互点云特征和图像特征，并应用于常用的单模态基础网络。融合模块包括简单特征融合（SFF）和多尺度可变形特征融合（MSDFF）两种类型，SFF易于实现，MSDFF具有更强的融合能力。同时，提出了一个语义引导头，通过体素特征重加权对体素进行前景-背景分割，以缓解特征模糊问题。&lt;h4&gt;主要发现&lt;/h4&gt;在View-of-Delft（VoD）和TJ4DRadset数据集上的广泛实验表明，MSSF的有效性。与最先进的方法相比，在VoD和TJ4DRadSet数据集上，MSSF分别提高了3D平均精度7.0%和4.0%。在VoD数据集上甚至超越了经典的基于LiDAR的方法。&lt;h4&gt;结论&lt;/h4&gt;MSSF网络通过深度融合4D雷达和相机的特征，显著提升了自动驾驶感知的性能，解决了特征模糊和信息交互不足的问题。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的MSSF网络为4D毫米波雷达与相机的融合提供了有效的解决方案，展示了其在自动驾驶领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As one of the automotive sensors that have emerged in recent years, 4Dmillimeter-wave radar has a higher resolution than conventional 3D radar andprovides precise elevation measurements. But its point clouds are still sparseand noisy, making it challenging to meet the requirements of autonomousdriving. Camera, as another commonly used sensor, can capture rich semanticinformation. As a result, the fusion of 4D radar and camera can provide anaffordable and robust perception solution for autonomous driving systems.However, previous radar-camera fusion methods have not yet been thoroughlyinvestigated, resulting in a large performance gap compared to LiDAR-basedmethods. Specifically, they ignore the feature-blurring problem and do notdeeply interact with image semantic information. To this end, we present asimple but effective multi-stage sampling fusion (MSSF) network based on 4Dradar and camera. On the one hand, we design a fusion block that can deeplyinteract point cloud features with image features, and can be applied tocommonly used single-modal backbones in a plug-and-play manner. The fusionblock encompasses two types, namely, simple feature fusion (SFF) and multiscaledeformable feature fusion (MSDFF). The SFF is easy to implement, while theMSDFF has stronger fusion abilities. On the other hand, we propose asemantic-guided head to perform foreground-background segmentation on voxelswith voxel feature re-weighting, further alleviating the problem of featureblurring. Extensive experiments on the View-of-Delft (VoD) and TJ4DRadsetdatasets demonstrate the effectiveness of our MSSF. Notably, compared tostate-of-the-art methods, MSSF achieves a 7.0% and 4.0% improvement in 3D meanaverage precision on the VoD and TJ4DRadSet datasets, respectively. It evensurpasses classical LiDAR-based methods on the VoD dataset.</description>
      <author>example@mail.com (Hongsi Liu, Jun Liu, Guangfeng Jiang, Xin Jin)</author>
      <guid isPermaLink="false">2411.15016v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DeDe: Detecting Backdoor Samples for SSL Encoders via Decoders</title>
      <link>http://arxiv.org/abs/2411.16154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督学习（SSL）在使用大量未标记数据训练高质量上游编码器方面被广泛应用，但其容易受到后门攻击，即通过污染少量训练数据来引发攻击。&lt;h4&gt;目的&lt;/h4&gt;研究如何检测和防御自监督学习中的后门攻击，尤其是针对先进的隐蔽后门攻击。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的检测机制DeDe，通过受害编码器和触发输入的共现来检测后门映射的激活。具体来说，DeDe在辅助数据集上训练解码器，以识别误导到目标嵌入的触发输入。&lt;h4&gt;主要发现&lt;/h4&gt;DeDe在对比学习和CLIP模型上进行了实证评估，显示出在上游检测性能和防止后门在下游任务中的能力上优于现有最先进的检测方法。&lt;h4&gt;结论&lt;/h4&gt;DeDe有效提升了自监督学习系统的安全性，能够更好地检测和防御后门攻击。&lt;h4&gt;总结&lt;/h4&gt;自监督学习虽然强大，但其安全性问题不容忽视，DeDe为防御后门攻击提供了一种有效的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) is pervasively exploited in traininghigh-quality upstream encoders with a large amount of unlabeled data. However,it is found to be susceptible to backdoor attacks merely via polluting a smallportion of training data. The victim encoders mismatch triggered inputs withtarget embeddings, e.g., match the triggered cat input to an airplaneembedding, such that the downstream tasks are affected to misbehave when thetrigger is activated. Emerging backdoor attacks have shown great threats indifferent SSL paradigms such as contrastive learning and CLIP, while fewresearch is devoted to defending against such attacks. Besides, the existingones fall short in detecting advanced stealthy backdoors. To address thelimitations, we propose a novel detection mechanism, DeDe, which detects theactivation of the backdoor mapping with the cooccurrence of victim encoder andtrigger inputs. Specifically, DeDe trains a decoder for the SSL encoder on anauxiliary dataset (can be out-of-distribution or even slightly poisoned), suchthat for any triggered input that misleads to the target embedding, the decoderoutputs an image significantly different from the input. We empiricallyevaluate DeDe on both contrastive learning and CLIP models against varioustypes of backdoor attacks, and demonstrate its superior performance over SOTAdetection methods in both upstream detection performance and ability ofpreventing backdoors in downstream tasks.</description>
      <author>example@mail.com (Sizai Hou, Songze Li, Duanyi Yao)</author>
      <guid isPermaLink="false">2411.16154v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Functionality understanding and segmentation in 3D scenes</title>
      <link>http://arxiv.org/abs/2411.16310v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report. 20 pages, 12 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;理解3D场景中的功能性涉及将自然语言描述转化为在3D环境中定位功能性互动对象，如开关和按钮。&lt;h4&gt;目的&lt;/h4&gt;提出Fun3DU，首个专为3D场景功能性理解设计的方法。&lt;h4&gt;方法&lt;/h4&gt;Fun3DU使用语言模型通过链式思维推理解析任务描述，识别感兴趣对象。通过视觉和语言模型对捕获场景的多个视图进行对象分割，利用几何信息将分割结果提升到3D并聚合成点云。&lt;h4&gt;主要发现&lt;/h4&gt;在SceneFun3D数据集上，Fun3DU显著优于现有的开放词汇3D分割方法。&lt;h4&gt;结论&lt;/h4&gt;Fun3DU是一个无训练需求的方法，完全依赖于预训练模型，代码将公开发布。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法来解决3D场景功能性理解的问题，并在相关数据集上取得了显著成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding functionalities in 3D scenes involves interpreting naturallanguage descriptions to locate functional interactive objects, such as handlesand buttons, in a 3D environment. Functionality understanding is highlychallenging, as it requires both world knowledge to interpret language andspatial perception to identify fine-grained objects. For example, given a tasklike 'turn on the ceiling light', an embodied AI agent must infer that it needsto locate the light switch, even though the switch is not explicitly mentionedin the task description. To date, no dedicated methods have been developed forthis problem. In this paper, we introduce Fun3DU, the first approach designedfor functionality understanding in 3D scenes. Fun3DU uses a language model toparse the task description through Chain-of-Thought reasoning in order toidentify the object of interest. The identified object is segmented acrossmultiple views of the captured scene by using a vision and language model. Thesegmentation results from each view are lifted in 3D and aggregated into thepoint cloud using geometric information. Fun3DU is training-free, relyingentirely on pre-trained models. We evaluate Fun3DU on SceneFun3D, the mostrecent and only dataset to benchmark this task, which comprises over 3000 taskdescriptions on 230 scenes. Our method significantly outperformsstate-of-the-art open-vocabulary 3D segmentation approaches. Code will bereleased publicly.</description>
      <author>example@mail.com (Jaime Corsetti, Francesco Giuliari, Alice Fasoli, Davide Boscaini, Fabio Poiesi)</author>
      <guid isPermaLink="false">2411.16310v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SPAC-Net: Rethinking Point Cloud Completion with Structural Prior</title>
      <link>http://arxiv.org/abs/2411.15066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云补全旨在从部分观测中推断出完整形状。许多方法采用纯粹的编码器-解码器范式，但由于特征抽象问题，容易导致细节丢失。&lt;h4&gt;目的&lt;/h4&gt;提出一个新框架SPAC-Net，通过新的结构先验（接口）重新思考补全任务。&lt;h4&gt;方法&lt;/h4&gt;首先通过边际检测器（MAD）模块定位接口，接口定义为已知观测与缺失部分的交集；然后基于接口学习位移，预测粗略形状，并在上采样阶段前引入结构补充（SSP）模块以增强粗略形状的结构细节。&lt;h4&gt;主要发现&lt;/h4&gt;在多个具有挑战性的基准测试中进行的广泛实验表明，SPAC-Net的方法优于现有的最新技术。&lt;h4&gt;结论&lt;/h4&gt;SPAC-Net通过新的结构指导和细节增强模块有效地提高了点云补全的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，解决了传统点云补全方法中的细节丢失问题，取得了显著的效果提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sand2sand/SPAC-Net&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud completion aims to infer a complete shape from its partialobservation. Many approaches utilize a pure encoderdecoder paradigm in whichcomplete shape can be directly predicted by shape priors learned from partialscans, however, these methods suffer from the loss of details inevitably due tothe feature abstraction issues. In this paper, we propose a novelframework,termed SPAC-Net, that aims to rethink the completion task under theguidance of a new structural prior, we call it interface. Specifically, ourmethod first investigates Marginal Detector (MAD) module to localize theinterface, defined as the intersection between the known observation and themissing parts. Based on the interface, our method predicts the coarse shape bylearning the displacement from the points in interface move to theircorresponding position in missing parts. Furthermore, we devise an additionalStructure Supplement(SSP) module before the upsampling stage to enhance thestructural details of the coarse shape, enabling the upsampling module to focusmore on the upsampling task. Extensive experiments have been conducted onseveral challenging benchmarks, and the results demonstrate that our methodoutperforms existing state-of-the-art approaches.</description>
      <author>example@mail.com (Zizhao Wu, Jian Shi, Xuan Deng, Cheng Zhang, Genfu Yang, Ming Zeng, Yunhai Wang)</author>
      <guid isPermaLink="false">2411.15066v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Features for Zero-Shot 6DoF Object Pose Estimation</title>
      <link>http://arxiv.org/abs/2411.16668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;零样本物体姿态估计允许从图像中检索物体姿态，而无需特定于物体的训练。近年来，这一方法通过视觉基础模型（VFM）得以实现，这些模型是经过预训练的有效通用特征提取器。&lt;h4&gt;目的&lt;/h4&gt;评估潜在扩散模型（LDM）骨干网络对零样本姿态估计的影响。&lt;h4&gt;方法&lt;/h4&gt;采用并修改了一种最新方法，提出了一种基于模板的多阶段方法，以零样本方式使用LDM进行姿态估计。&lt;h4&gt;主要发现&lt;/h4&gt;在三个标准数据集上进行的实证评估显示，所提方法在物体特定的6DoF姿态估计中，相比ViT基线，平均召回率提高了多达27%。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在零样本姿态估计中表现出显著的改进，源代码可在GitHub上获取。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了LDM在零样本物体姿态估计中的潜力，并提供了有效的比较方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot object pose estimation enables the retrieval of object poses fromimages without necessitating object-specific training. In recent approachesthis is facilitated by vision foundation models (VFM), which are pre-trainedmodels that are effectively general-purpose feature extractors. Thecharacteristics exhibited by these VFMs vary depending on the training data,network architecture, and training paradigm. The prevailing choice in thisfield are self-supervised Vision Transformers (ViT). This study assesses theinfluence of Latent Diffusion Model (LDM) backbones on zero-shot poseestimation. In order to facilitate a comparison between the two families ofmodels on a common ground we adopt and modify a recent approach. Therefore, atemplate-based multi-staged method for estimating poses in a zero-shot fashionusing LDMs is presented. The efficacy of the proposed approach is empiricallyevaluated on three standard datasets for object-specific 6DoF pose estimation.The experiments demonstrate an Average Recall improvement of up to 27% over theViT baseline. The source code is available at: https://github.com/BvG1993/DZOP.</description>
      <author>example@mail.com (Bernd Von Gimborn, Philipp Ausserlechner, Markus Vincze, Stefan Thalhammer)</author>
      <guid isPermaLink="false">2411.16668v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Limeade: Let integer molecular encoding aid</title>
      <link>http://arxiv.org/abs/2411.16623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;混合整数规划（MIP）是计算机辅助分子设计（CAMD）的一个成熟框架。&lt;h4&gt;目的&lt;/h4&gt;探讨MIP在分子生成中的应用，提出Limeade作为从现实需求到可行分子的端到端工具。&lt;h4&gt;方法&lt;/h4&gt;通过精确编码分子空间和评分函数，将分子设计问题表示为优化问题，并支持SMARTS模式的包含和排除。&lt;h4&gt;主要发现&lt;/h4&gt;传统的MIP方法由于搜索空间大和评分过程复杂，限制了其在小规模问题之外的应用。&lt;h4&gt;结论&lt;/h4&gt;Limeade不仅满足结构可行性基本约束，还能自动化地将化学需求转化为数学约束。&lt;h4&gt;总结&lt;/h4&gt;Limeade为分子设计提供了一种新的解决方案，能够更好地应对实际需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mixed-integer programming (MIP) is a well-established framework forcomputer-aided molecular design (CAMD). By precisely encoding the molecularspace and score functions, e.g., a graph neural network, the molecular designproblem is represented and solved as an optimization problem, the solution ofwhich corresponds to a molecule with optimal score. However, both the extremelylarge search space and complicated scoring process limit the use of MIP-basedCAMD to specific and tiny problems. Moreover, optimal molecule may not bemeaningful in practice if scores are imperfect. Instead of pursuing optimality,this paper exploits the ability of MIP in molecular generation and proposesLimeade as an end-to-end tool from real-world needs to feasible molecules.Beyond the basic constraints for structural feasibility, Limeade supportsinclusion and exclusion of SMARTS patterns, automating the process ofinterpreting and formulating chemical requirements to mathematical constraints.</description>
      <author>example@mail.com (Shiqiang Zhang, Christian W. Feldmann, Frederik Sandfort, Miriam Mathea, Juan S. Campos, Ruth Misener)</author>
      <guid isPermaLink="false">2411.16623v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Factorized Visual Tokenization and Generation</title>
      <link>http://arxiv.org/abs/2411.16681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉标记器是图像生成的基础，将视觉数据转换为离散标记，使基于变换器的模型在图像生成中表现出色。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，解决VQGAN等基于VQ的标记器在词汇大小受限时的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入因子化量化（FQ），将大词汇表分解为多个独立的子词汇表，并采用去冗余正则化和表示学习来提高标记器的有效性和可扩展性。&lt;h4&gt;主要发现&lt;/h4&gt;FQGAN模型显著改善了视觉标记器的重建质量，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该标记器能够有效适应自回归图像生成，提升生成的多样性和表达能力。&lt;h4&gt;总结&lt;/h4&gt;通过因子化量化和引入预训练视觉模型，FQ方法克服了传统VQ标记器的局限，推动了图像生成领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual tokenizers are fundamental to image generation. They convert visualdata into discrete tokens, enabling transformer-based models to excel at imagegeneration. Despite their success, VQ-based tokenizers like VQGAN facesignificant limitations due to constrained vocabulary sizes. Simply expandingthe codebook often leads to training instability and diminishing performancegains, making scalability a critical challenge. In this work, we introduceFactorized Quantization (FQ), a novel approach that revitalizes VQ-basedtokenizers by decomposing a large codebook into multiple independentsub-codebooks. This factorization reduces the lookup complexity of largecodebooks, enabling more efficient and scalable visual tokenization. To ensureeach sub-codebook captures distinct and complementary information, we propose adisentanglement regularization that explicitly reduces redundancy, promotingdiversity across the sub-codebooks. Furthermore, we integrate representationlearning into the training process, leveraging pretrained vision models likeCLIP and DINO to infuse semantic richness into the learned representations.This design ensures our tokenizer captures diverse semantic levels, leading tomore expressive and disentangled representations. Experiments show that theproposed FQGAN model substantially improves the reconstruction quality ofvisual tokenizers, achieving state-of-the-art performance. We furtherdemonstrate that this tokenizer can be effectively adapted into auto-regressiveimage generation. https://showlab.github.io/FQGAN</description>
      <author>example@mail.com (Zechen Bai, Jianxiong Gao, Ziteng Gao, Pichao Wang, Zheng Zhang, Tong He, Mike Zheng Shou)</author>
      <guid isPermaLink="false">2411.16681v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Towards Foundation Models for Critical Care Time Series</title>
      <link>http://arxiv.org/abs/2411.16346v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for Oral Presentation at AIM-FM Workshop at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在医疗领域，通用大语言模型取得了显著进展，但医院内时间序列数据（如生命体征、实验室结果和重症护理中的治疗）的大规模建模仍然不够深入。&lt;h4&gt;目的&lt;/h4&gt;建立基础以训练大规模多变量时间序列模型，并为跨医院的迁移学习提供基准，研究和解决分布转移问题。&lt;h4&gt;方法&lt;/h4&gt;结合现有的小型数据集以增强患者多样性和模型鲁棒性，同时解决因治疗政策差异引起的分布转移，协调不同数据集中的治疗变量。&lt;h4&gt;主要发现&lt;/h4&gt;引入了一种统一的数据集用于序列建模和迁移学习研究，这是首个包含核心治疗变量的大规模数据集。&lt;h4&gt;结论&lt;/h4&gt;未来计划扩展此数据集，以支持迁移学习的进一步发展，并开发可扩展、通用的重症医疗应用模型。&lt;h4&gt;总结&lt;/h4&gt;这项工作为重症护理数据的大规模建模奠定了基础，并为医疗机器学习模型提供了新的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Notable progress has been made in generalist medical large language modelsacross various healthcare areas. However, large-scale modeling of in-hospitaltime series data - such as vital signs, lab results, and treatments in criticalcare - remains underexplored. Existing datasets are relatively small, butcombining them can enhance patient diversity and improve model robustness. Toeffectively utilize these combined datasets for large-scale modeling, it isessential to address the distribution shifts caused by varying treatmentpolicies, necessitating the harmonization of treatment variables across thedifferent datasets. This work aims to establish a foundation for traininglarge-scale multi-variate time series models on critical care data and toprovide a benchmark for machine learning models in transfer learning acrosshospitals to study and address distribution shift challenges. We introduce aharmonized dataset for sequence modeling and transfer learning research,representing the first large-scale collection to include core treatmentvariables. Future plans involve expanding this dataset to support furtheradvancements in transfer learning and the development of scalable,generalizable models for critical healthcare applications.</description>
      <author>example@mail.com (Manuel Burger, Fedor Sergeev, Malte Londschien, Daphné Chopard, Hugo Yèche, Eike Gerdes, Polina Leshetkina, Alexander Morgenroth, Zeynep Babür, Jasmina Bogojeska, Martin Faltys, Rita Kuznetsova, Gunnar Rätsch)</author>
      <guid isPermaLink="false">2411.16346v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Anomaly Detection and RFI Classification with Unsupervised Learning in Narrowband Radio Technosignature Searches</title>
      <link>http://arxiv.org/abs/2411.16556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 14 figures, submitted to AJ&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;寻找无线电技术特征信号是一种异常检测问题，候选信号在无线频率干扰的海洋中如同针尖一般。&lt;h4&gt;目的&lt;/h4&gt;减少在大规模调查中出现的虚假信号，降低手动跟进的需求。&lt;h4&gt;方法&lt;/h4&gt;提出GLOBULAR聚类方法，利用HDBSCAN算法来降低虚假信号率，并将形态相似的干扰信号进行分组。&lt;h4&gt;主要发现&lt;/h4&gt;GLOBULAR聚类结合标准的窄带信号检测和空间过滤流程（如turboSETI），显著改善了虚假信号率，减少了93.1%的虚假命中率和99.3%的虚假事件率。&lt;h4&gt;结论&lt;/h4&gt;GLOBULAR聚类通过去除高频谱占用区域的干扰信号，可能帮助检测到标准流程未能捕捉到的信号，具有显著的潜力。&lt;h4&gt;总结&lt;/h4&gt;此研究展示了GLOBULAR聚类在未来大规模调查中减少手动跟进需求的有效性，同时提升了信号检测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The search for radio technosignatures is an anomaly detection problem:candidate signals represent needles of interest in the proverbial haystack ofradio-frequency interference (RFI). Current search frameworks find an enormityof false-positive signals, especially in large surveys, requiring manualfollow-up to a sometimes prohibitive degree. Unsupervised learning provides analgorithmic way to winnow the most anomalous signals from the chaff, as well asgroup together RFI signals that bear morphological similarities. We presentGLOBULAR (Grouping Low-frequency Observations By Unsupervised Learning AfterReduction) clustering, a signal processing method that uses HDBSCAN to reducethe false-positive rate and isolate outlier signals for further analysis. Whencombined with a standard narrowband signal detection and spatial filteringpipeline, such as turboSETI, GLOBULAR clustering offers significantimprovements in the false-positive rate over the standard pipeline alone,suggesting dramatic potential for the amelioration of manual follow-uprequirements for future large surveys. By removing RFI signals in regions ofhigh spectral occupancy, GLOBULAR clustering may also enable the detection ofsignals missed by the standard pipeline. We benchmark our method against theChoza et al. (2024) turboSETI-only search of 97 nearby galaxies at L-band,demonstrating a false-positive hit reduction rate of 93.1% and a false-positiveevent reduction rate of 99.3%.</description>
      <author>example@mail.com (Ben Jacobson-Bell, Steve Croft, Carmen Choza, Alex Andersson, Daniel Bautista, Vishal Gajjar, Matthew Lebofsky, David H. E. MacMahon, Caleb Painter, Andrew P. V. Siemion)</author>
      <guid isPermaLink="false">2411.16556v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>EADReg: Probabilistic Correspondence Generation with Efficient Autoregressive Diffusion Model for Outdoor Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2411.15271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;扩散模型在点云配准任务中展现出巨大潜力，尤其是在应对挑战性案例时的鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的框架EADReg，以高效且鲁棒的方式注册LiDAR点云。&lt;h4&gt;方法&lt;/h4&gt;EADReg采用粗到细的配准范式，首先通过双向高斯混合模型（BGMM）过滤异常点，获得纯净的点云对，随后将扩散基础的点云配准视为自回归过程生成稳健的点对应关系，并在上层迭代细化。&lt;h4&gt;主要发现&lt;/h4&gt;EADReg在运行速度上与基于卷积的方法相当，尽管扩散方法常被批评推理速度慢。&lt;h4&gt;结论&lt;/h4&gt;在KITTI和NuScenes基准数据集上的广泛实验显示了我们提出的方法具有最先进的性能。&lt;h4&gt;总结&lt;/h4&gt;EADReg为LiDAR点云配准提供了一种有效的解决方案，并将在发表后发布代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models have shown the great potential in the point cloudregistration (PCR) task, especially for enhancing the robustness to challengingcases. However, existing diffusion-based PCR methods primarily focus oninstance-level scenarios and struggle with outdoor LiDAR points, where thesparsity, irregularity, and huge point scale inherent in LiDAR points posechallenges to establishing dense global point-to-point correspondences. Toaddress this issue, we propose a novel framework named EADReg for efficient androbust registration of LiDAR point clouds based on autoregressive diffusionmodels. EADReg follows a coarse-to-fine registration paradigm. In the coarsestage, we employ a Bi-directional Gaussian Mixture Model (BGMM) to rejectoutlier points and obtain purified point cloud pairs. BGMM establishescorrespondences between the Gaussian Mixture Models (GMMs) from the source andtarget frames, enabling reliable coarse registration based on filtered featuresand geometric information. In the fine stage, we treat diffusion-based PCR asan autoregressive process to generate robust point correspondences, which arethen iteratively refined on upper layers. Despite common criticisms ofdiffusion-based methods regarding inference speed, EADReg achieves runtimecomparable to convolutional-based methods. Extensive experiments on the KITTIand NuScenes benchmark datasets highlight the state-of-the-art performance ofour proposed method. Codes will be released upon publication.</description>
      <author>example@mail.com (Linrui Gong, Jiuming Liu, Junyi Ma, Lihao Liu, Yaonan Wang, Hesheng Wang)</author>
      <guid isPermaLink="false">2411.15271v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Robust Hybrid Precoding for Millimeter Wave MU-MISO System Via Meta-Learning</title>
      <link>http://arxiv.org/abs/2411.15762v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;混合模拟-数字架构因其低成本和低功耗，被认为是大规模多输入多输出（MIMO）系统的一个有前景的能效解决方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于梯度引导的元学习（GGML）的交替优化框架，以解决混合预编码中的非凸目标函数和约束问题。&lt;h4&gt;方法&lt;/h4&gt;GGML框架无须训练，采用即插即用的方式，通过将原始梯度信息输入神经网络，利用梯度下降从局部角度交替优化子问题，同时在元学习框架中更新轻量神经网络以从全局角度优化。&lt;h4&gt;主要发现&lt;/h4&gt;GGML显著提高了频谱效率，并且收敛速度比传统方法快8倍，甚至在相同天线数量下超越了全数字加权最小均方误差（WMMSE）预编码。&lt;h4&gt;结论&lt;/h4&gt;GGML方法在处理具有不完美信道状态信息的预编码方面也具备良好的扩展性，显示出其优越的性能。&lt;h4&gt;总结&lt;/h4&gt;GGML为大规模MIMO系统提供了一种高效的混合预编码解决方案，能够在成本及能耗方面优势明显。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Thanks to the low cost and power consumption, hybrid analog-digitalarchitectures are considered as a promising energy-efficient solution formassive multiple-input multiple-output (MIMO) systems. The key idea is toconnect one RF chain to multiple antennas through low-cost phase shifters.However, due to the non-convex objective function and constraints, we propose agradient-guided meta-learning (GGML) based alternating optimization frameworkto solve this challenging problem. The GGML based hybrid precoding framework is\textit{free-of-training} and \textit{plug-and-play}. Specifically, GGML feedsthe raw gradient information into a neural network, leveraging gradient descentto alternately optimize sub-problems from a local perspective, while alightweight neural network embedded within the meta-learning framework isupdated from a global perspective. We also extend the proposed framework toinclude precoding with imperfect channel state information. Simulation resultsdemonstrate that GGML can significantly enhance spectral efficiency, and speedup the convergence by 8 times faster compared to traditional approaches.Moreover, GGML could even outperform fully digital weighted minimum mean squareerror (WMMSE) precoding with the same number of antennas.</description>
      <author>example@mail.com (Yifan Guo)</author>
      <guid isPermaLink="false">2411.15762v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>BelHouse3D: A Benchmark Dataset for Assessing Occlusion Robustness in 3D Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2411.13251v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 6 figures, 3 tables, accepted at ECCV 2024 Workshops&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模的二维数据集在机器学习中发挥了重要作用，但3D视觉任务的进展相对缓慢，这主要是由于3D基准数据集的有限性。&lt;h4&gt;目的&lt;/h4&gt;旨在解决室内场景语义分割中真实点云数据集创建的挑战。&lt;h4&gt;方法&lt;/h4&gt;引入BelHouse3D数据集，这是一个新构建的合成点云数据集，使用比利时32栋房屋的真实世界参考，确保合成数据与真实条件紧密匹配。&lt;h4&gt;主要发现&lt;/h4&gt;数据集中包含了数据遮挡的测试集，以模拟在真实环境中常见的分布外（OOD）场景，评估流行的点基语义分割方法并提供基准。&lt;h4&gt;结论&lt;/h4&gt;BelHouse3D及其OOD设置将推动室内场景的3D点云语义分割研究，为开发更具普适性的模型提供有价值的见解。&lt;h4&gt;总结&lt;/h4&gt;该研究解决了3D语义分割中的数据集限制问题，促进了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale 2D datasets have been instrumental in advancing machine learning;however, progress in 3D vision tasks has been relatively slow. This disparityis largely due to the limited availability of 3D benchmarking datasets. Inparticular, creating real-world point cloud datasets for indoor scene semanticsegmentation presents considerable challenges, including data collection withinconfined spaces and the costly, often inaccurate process of per-point labelingto generate ground truths. While synthetic datasets address some of thesechallenges, they often fail to replicate real-world conditions, particularlythe occlusions that occur in point clouds collected from real environments.Existing 3D benchmarking datasets typically evaluate deep learning models underthe assumption that training and test data are independently and identicallydistributed (IID), which affects the models' usability for real-world pointcloud segmentation. To address these challenges, we introduce the BelHouse3Ddataset, a new synthetic point cloud dataset designed for 3D indoor scenesemantic segmentation. This dataset is constructed using real-world referencesfrom 32 houses in Belgium, ensuring that the synthetic data closely aligns withreal-world conditions. Additionally, we include a test set with data occlusionto simulate out-of-distribution (OOD) scenarios, reflecting the occlusionscommonly encountered in real-world point clouds. We evaluate popularpoint-based semantic segmentation methods using our OOD setting and present abenchmark. We believe that BelHouse3D and its OOD setting will advance researchin 3D point cloud semantic segmentation for indoor scenes, providing valuableinsights for the development of more generalizable models.</description>
      <author>example@mail.com (Umamaheswaran Raman Kumar, Abdur Razzaq Fayjie, Jurgen Hannaert, Patrick Vandewalle)</author>
      <guid isPermaLink="false">2411.13251v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Training an Open-Vocabulary Monocular 3D Object Detection Model without 3D Data</title>
      <link>http://arxiv.org/abs/2411.15657v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;开放词汇3D目标检测在自动驾驶和机器人领域应用广泛，近年来受到关注，旨在有效识别新类别。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的开放词汇单目3D目标检测框架OVM3D-Det，旨在降低部署成本并扩展至公开数据。&lt;h4&gt;方法&lt;/h4&gt;OVM3D-Det仅使用RGB图像进行训练，采用开放词汇2D模型和伪LiDAR自动标记RGB图像中的3D对象，同时引入自适应伪LiDAR侵蚀和基于大语言模型的边界框精细化。&lt;h4&gt;主要发现&lt;/h4&gt;OVM3D-Det在室内和室外场景中相较于基线方法表现出更优越的检测效果。&lt;h4&gt;结论&lt;/h4&gt;OVM3D-Det通过RGB图像训练3D检测器，克服了传统方法对高精度LiDAR的依赖，展现了其有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究为开放词汇3D目标检测提供了新的思路和方法，代码将会公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D object detection has recently attracted considerableattention due to its broad applications in autonomous driving and robotics,which aims to effectively recognize novel classes in previously unseen domains.However, existing point cloud-based open-vocabulary 3D detection models arelimited by their high deployment costs. In this work, we propose a novelopen-vocabulary monocular 3D object detection framework, dubbed OVM3D-Det,which trains detectors using only RGB images, making it both cost-effective andscalable to publicly available data. Unlike traditional methods, OVM3D-Det doesnot require high-precision LiDAR or 3D sensor data for either input orgenerating 3D bounding boxes. Instead, it employs open-vocabulary 2D models andpseudo-LiDAR to automatically label 3D objects in RGB images, fostering thelearning of open-vocabulary monocular 3D detectors. However, training 3D modelswith labels directly derived from pseudo-LiDAR is inadequate due to impreciseboxes estimated from noisy point clouds and severely occluded objects. Toaddress these issues, we introduce two innovative designs: adaptivepseudo-LiDAR erosion and bounding box refinement with prior knowledge fromlarge language models. These techniques effectively calibrate the 3D labels andenable RGB-only training for 3D detectors. Extensive experiments demonstratethe superiority of OVM3D-Det over baselines in both indoor and outdoorscenarios. The code will be released.</description>
      <author>example@mail.com (Rui Huang, Henry Zheng, Yan Wang, Zhuofan Xia, Marco Pavone, Gao Huang)</author>
      <guid isPermaLink="false">2411.15657v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>CutS3D: Cutting Semantics in 3D for 2D Unsupervised Instance Segmentation</title>
      <link>http://arxiv.org/abs/2411.16319v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的算法在2D图像中进行目标实例分割，严重依赖大量人工标注数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的方法来解决对象实例分割的问题。&lt;h4&gt;方法&lt;/h4&gt;通过生成伪掩码并训练无类别检测器，同时利用3D语义掩码和点云表示来提高实例分割的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法能够更好地分离重叠的实例，且在多个无监督实例分割和目标检测的标准基准上表现优于竞争方法。&lt;h4&gt;结论&lt;/h4&gt;通过引入空间重要性函数和空间置信度组件，能够有效隔离干净的学习信号，提升检测性能。&lt;h4&gt;总结&lt;/h4&gt;本研究为无监督实例分割提供了一种新颖的方法，克服了现有方法在处理重叠实例时的不足。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditionally, algorithms that learn to segment object instances in 2D imageshave heavily relied on large amounts of human-annotated data. Only recently,novel approaches have emerged tackling this problem in an unsupervised fashion.Generally, these approaches first generate pseudo-masks and then train aclass-agnostic detector. While such methods deliver the current state of theart, they often fail to correctly separate instances overlapping in 2D imagespace since only semantics are considered. To tackle this issue, we insteadpropose to cut the semantic masks in 3D to obtain the final 2D instances byutilizing a point cloud representation of the scene. Furthermore, we derive aSpatial Importance function, which we use to resharpen the semantics along the3D borders of instances. Nevertheless, these pseudo-masks are still subject tomask ambiguity. To address this issue, we further propose to augment thetraining of a class-agnostic detector with three Spatial Confidence componentsaiming to isolate a clean learning signal. With these contributions, ourapproach outperforms competing methods across multiple standard benchmarks forunsupervised instance segmentation and object detection.</description>
      <author>example@mail.com (Leon Sick, Dominik Engel, Sebastian Hartwig, Pedro Hermosilla, Timo Ropinski)</author>
      <guid isPermaLink="false">2411.16319v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multi-hop Upstream Preemptive Traffic Signal Control with Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2411.07271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 tables, 12 figures. arXiv admin note: text overlap with
  arXiv:2409.00753&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交通信号控制对于管理城市网络中的拥堵至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的信号控制方法，以优化信号时机分配，减少网络延迟。&lt;h4&gt;方法&lt;/h4&gt;基于马尔可夫链理论，提出多跳上游压力的概念，以考虑更广泛的交通情况。&lt;h4&gt;主要发现&lt;/h4&gt;使用多跳上游压力的控制器在模拟中显著减少了整体网络延迟，优化了交通流动。&lt;h4&gt;结论&lt;/h4&gt;通过更广泛的空间意识，信号控制可以更有效地清除当前排队，提升交通管理效率。&lt;h4&gt;总结&lt;/h4&gt;本研究为交通信号控制提供了一种新的视角，强调了考虑上游交通状况的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic signal control is crucial for managing congestion in urban networks.Existing myopic pressure-based control methods focus only on immediate upstreamlinks, leading to suboptimal green time allocation and increased networkdelays. Effective signal control, however, inherently requires a broaderspatial scope, as traffic conditions further upstream can significantly impacttraffic at the current location. This paper introduces a novel concept based onthe Markov chain theory, namely multi-hop upstream pressure, that generalizesthe conventional pressure to account for traffic conditions beyond theimmediate upstream links. This farsighted and compact metric informs the deepreinforcement learning agent to preemptively clear the present queues, guidingthe agent to optimize signal timings with a broader spatial awareness.Simulations on synthetic and realistic (Toronto) scenarios demonstratecontrollers utilizing multi-hop upstream pressure significantly reduce overallnetwork delay by prioritizing traffic movements based on a broaderunderstanding of upstream congestion.</description>
      <author>example@mail.com (Xiaocan Li, Xiaoyu Wang, Ilia Smirnov, Scott Sanner, Baher Abdulhai)</author>
      <guid isPermaLink="false">2411.07271v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>OffLight: An Offline Multi-Agent Reinforcement Learning Framework for Traffic Signal Control</title>
      <link>http://arxiv.org/abs/2411.06601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高效的交通信号控制对现代城市出行至关重要，但传统系统在适应复杂城市交通模式方面常常面临困难。&lt;h4&gt;目的&lt;/h4&gt;探索多智能体强化学习（MARL）在交通信号控制中的应用。&lt;h4&gt;方法&lt;/h4&gt;在线MARL方法需要大量实时交互，但这非常耗时且成本高昂；离线MARL通过使用历史交通数据来解决这些问题。&lt;h4&gt;主要发现&lt;/h4&gt;离线MARL面临来自真实世界数据集中多样化行为策略的挑战，不同控制器使学习变得复杂。&lt;h4&gt;结论&lt;/h4&gt;需要进一步研究如何有效利用历史数据以克服多样化行为策略的影响。&lt;h4&gt;总结&lt;/h4&gt;MARL在交通信号控制中提供了适应性解决方案，但实施过程中存在实际挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient traffic signal control is critical for modern urban mobility, buttraditional systems often struggle to adapt to complex city traffic patterns.Multi-Agent Reinforcement Learning, or MARL, offers adaptive solutions, yetonline MARL methods require extensive real-time interactions, which are costlyand time-intensive. Offline MARL addresses these issues by using historicaltraffic data, but it faces challenges due to the diverse behavior policies inreal-world datasets, where different controllers complicate learning.</description>
      <author>example@mail.com (Rohit Bokade, Xiaoning Jin)</author>
      <guid isPermaLink="false">2411.06601v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Causal-discovery-based root-cause analysis and its application in time-series prediction error diagnosis</title>
      <link>http://arxiv.org/abs/2411.06990v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages with 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习的快速发展提高了预测模型的准确性，但大多数模型仍然是“黑箱”，使得预测错误诊断变得困难，尤其是在存在异常值时。这种透明度的缺乏阻碍了工业应用中的信任和可靠性。&lt;h4&gt;目的&lt;/h4&gt;解决模型缺乏可解释性的问题，提高对预测错误的诊断能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于因果发现的根本原因分析方法（CD-RCA），该方法无需预定义因果图即可估计预测错误与解释变量之间的因果关系。&lt;h4&gt;主要发现&lt;/h4&gt;CD-RCA能够通过Shapley值识别贡献于预测错误异常值的变量， extensive simulation表明其优于现有的启发式归因方法。&lt;h4&gt;结论&lt;/h4&gt;敏感性分析揭示了Shapley值可能误归因错误的新模式，为更准确的错误归因方法铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;CD-RCA方法有效提高了对机器学习模型预测错误的分析能力，能更准确地识别和归因异常值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent rapid advancements of machine learning have greatly enhanced theaccuracy of prediction models, but most models remain "black boxes", makingprediction error diagnosis challenging, especially with outliers. This lack oftransparency hinders trust and reliability in industrial applications.Heuristic attribution methods, while helpful, often fail to capture true causalrelationships, leading to inaccurate error attributions. Various root-causeanalysis methods have been developed using Shapley values, yet they typicallyrequire predefined causal graphs, limiting their applicability for predictionerrors in machine learning models. To address these limitations, we introducethe Causal-Discovery-based Root-Cause Analysis (CD-RCA) method that estimatescausal relationships between the prediction error and the explanatoryvariables, without needing a pre-defined causal graph. By simulating syntheticerror data, CD-RCA can identify variable contributions to outliers inprediction errors by Shapley values. Extensive simulations show CD-RCAoutperforms current heuristic attribution methods, and a sensitivity analysisreveals new patterns where Shapley values may misattribute errors, paving theway for more accurate error attribution methods.</description>
      <author>example@mail.com (Hiroshi Yokoyama, Ryusei Shingaki, Kaneharu Nishino, Shohei Shimizu, Thong Pham)</author>
      <guid isPermaLink="false">2411.06990v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Flight Time Improvement Using Adaptive Model Predictive Control for Unmanned Aerial Vehicles</title>
      <link>http://arxiv.org/abs/2411.06708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Vietnamese language, in the 26th National Conference on
  Electronics, Communications and Information Technology (REV-ECIT 2023),
  Hanoi, Vietnam&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能航空平台，如无人机(UAV)，预计将在交通、交通管理、现场监测、工业生产和农业管理等多个领域引发革命。&lt;h4&gt;目的&lt;/h4&gt;提出一种模型预测控制(MPC)方法，旨在减少飞行时间，同时克服传统MPC控制器的局限性。&lt;h4&gt;方法&lt;/h4&gt;详细介绍MPC方法及其在无人机控制中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的控制器在效率方面优于标准MPC。&lt;h4&gt;结论&lt;/h4&gt;该方法有潜力成为将智能算法集成到基本控制器中的基础。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了在无人机控制中减少飞行时间的重要性，并提出了改进的控制策略，以提高系统性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intelligent aerial platforms such as Unmanned Aerial Vehicles (UAVs) areexpected to revolutionize various fields, including transportation, trafficmanagement, field monitoring, industrial production, and agriculturalmanagement. Among these, precise control is a critical task that determines theperformance and capabilities of UAV systems. However, current researchprimarily focuses on trajectory tracking and minimizing flight errors, withlimited attention to improving flight time. In this paper, we propose a ModelPredictive Control (MPC) approach aimed at minimizing flight time whileaddressing the limitations of the commonly used classical MPC controllers.Furthermore, the MPC method and its application for UAV control are presentedin detail. Finally, the results demonstrate that the proposed controlleroutperforms the standard MPC in terms of efficiency. Moreover, this approachshows potential to become a foundation for integrating intelligent algorithmsinto basic controllers.</description>
      <author>example@mail.com (Huy-Hoang Ngo, Thanh Nguyen Canh, Xiem HoangVan)</author>
      <guid isPermaLink="false">2411.06708v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging LSTM for Predictive Modeling of Satellite Clock Bias</title>
      <link>http://arxiv.org/abs/2411.07015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 Pages, 6 figures (8 sub-figures), 5 Tables Index Terms-LSTM,
  Satellite Navigation, Deep Learning, Clock Bias&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;卫星时钟偏差预测在提高卫星导航系统的精度中至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种利用长短期记忆网络（LSTM）预测卫星时钟偏差的方法。&lt;h4&gt;方法&lt;/h4&gt;从Galileo的PRN 8卫星收集数据，并通过单差序列预处理数据，进行归一化以确保预测的等距和完整性。对不同长度的数据集（7天至31天）进行LSTM模型训练，每次使用两天的数据。&lt;h4&gt;主要发现&lt;/h4&gt;LSTM模型表现出卓越的准确性，均方根误差（RMSE）为2.11×10^-11，显著优于传统方法，准确度比RNN高170倍，比MLP高2.3×10^7倍，比ARIMA高1.9×10^4倍。&lt;h4&gt;结论&lt;/h4&gt;该研究有助于提高各种设备中低功耗接收器的准确性和效率，特别是在需要节能的应用中。&lt;h4&gt;应用前景&lt;/h4&gt;更准确的卫星时钟偏差预测能够提高低功耗接收器的性能，增强卫星导航系统的可靠性和有效性，适用于偏远地区、物联网设备、可穿戴技术等领域。&lt;h4&gt;总结&lt;/h4&gt;本研究为提高卫星导航系统的精度提供了新的思路，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Satellite clock bias prediction plays a crucial role in enhancing theaccuracy of satellite navigation systems. In this paper, we propose an approachutilizing Long Short-Term Memory (LSTM) networks to predict satellite clockbias. We gather data from the PRN 8 satellite of the Galileo and preprocess itto obtain a single difference sequence, crucial for normalizing the data.Normalization allows resampling of the data, ensuring that the predictions areequidistant and complete. Our methodology involves training the LSTM model onvarying lengths of datasets, ranging from 7 days to 31 days. We employ atraining set consisting of two days' worth of data in each case. Our LSTM modelexhibits exceptional accuracy, with a Root Mean Square Error (RMSE) of 2.11$\times$ 10$^{-11}$. Notably, our approach outperforms traditional methods usedfor similar time-series forecasting projects, being 170 times more accuratethan RNN, 2.3 $\times$ 10$^7$ times more accurate than MLP, and 1.9 $\times$10$^4$ times more accurate than ARIMA. This study holds significant potentialin enhancing the accuracy and efficiency of low-power receivers used in variousdevices, particularly those requiring power conservation. By providing moreaccurate predictions of satellite clock bias, the findings of this research canbe integrated into the algorithms of such devices, enabling them to functionwith heightened precision while conserving power. Improved accuracy in clockbias predictions ensures that low-power receivers can maintain optimalperformance levels, thereby enhancing the overall reliability and effectivenessof satellite navigation systems. Consequently, this advancement holds promisefor a wide range of applications, including remote areas, IoT devices, wearabletechnology, and other devices where power efficiency and navigation accuracyare paramount.</description>
      <author>example@mail.com (Ahan Bhatt, Ishaan Mehta, Pravin Patidar)</author>
      <guid isPermaLink="false">2411.07015v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Goal-oriented Semantic Communication for Robot Arm Reconstruction in Digital Twin: Feature and Temporal Selections</title>
      <link>http://arxiv.org/abs/2411.08835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE for potential publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数字双胞胎技术在工业中被认为是一种极具前景的技术，能够实现对现实系统的实时监控和预测分析，但在数字机器人臂重建方面面临通信开销日益增加的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的目标导向语义通信框架，以提取机器人臂重建任务中的信息，旨在在严格和放宽的重建误差限制下最小化通信负载。&lt;h4&gt;方法&lt;/h4&gt;与传统框架不同，本框架采用特征选择算法提取重建消息中的语义信息，并通过基于深度强化学习的时间选择算法选择性地传输这些信息。&lt;h4&gt;主要发现&lt;/h4&gt;在多种机器人任务的仿真结果中，该框架在严格重建误差限制下通信负载减少至少59.5%，在放宽重建误差限制下减少80%；实验结果显示在严格约束情况下减少53%，在放宽约束情况下减少74%。&lt;h4&gt;结论&lt;/h4&gt;所提出的目标导向语义通信框架有效减少了通信负载，提升了数字双胞胎的重建效率。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了新框架在机器人臂重建中的应用潜力，并提供了实际验证的结果，演示视频可在指定链接观看。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As one of the most promising technologies in industry, the Digital Twin (DT)facilitates real-time monitoring and predictive analysis for real-world systemsby precisely reconstructing virtual replicas of physical entities. However,this reconstruction faces unprecedented challenges due to the everincreasingcommunication overhead, especially for digital robot arm reconstruction. Tothis end, we propose a novel goal-oriented semantic communication (GSC)framework to extract the GSC information for the robot arm reconstruction taskin the DT, with the aim of minimising the communication load under the strictand relaxed reconstruction error constraints. Unlike the traditionalreconstruction framework that periodically transmits a reconstruction messagefor real-time DT reconstruction, our framework implements a feature selection(FS) algorithm to extract the semantic information from the reconstructionmessage, and a deep reinforcement learning-based temporal selection algorithmto selectively transmit the semantic information over time. We validate ourproposed GSC framework through both Pybullet simulations and lab experimentsbased on the Franka Research 3 robot arm. For a range of distinct robotictasks, simulation results show that our framework can reduce the communicationload by at least 59.5% under strict reconstruction error constraints and 80%under relaxed reconstruction error constraints, compared with traditionalcommunication framework. Also, experimental results confirm the effectivenessof our framework, where the communication load is reduced by 53% in strictconstraint case and 74% in relaxed constraint case. The demo is available at:https://youtu.be/2OdeHKxcgnk.</description>
      <author>example@mail.com (Shutong Chen, Emmanouil Spyrakos-Papastavridis, Yichao Jin, Yansha Deng)</author>
      <guid isPermaLink="false">2411.08835v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A neural-network based anomaly detection system and a safety protocol to protect vehicular network</title>
      <link>http://arxiv.org/abs/2411.07013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Master's thesis 2023-2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文探讨了合作智能交通系统（CITS）在提高道路安全性和效率方面的重要性，强调了安全和准确数据交换的必要性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于机器学习的失误检测系统（MDS），用于检测和缓解车辆网络中的错误或误导性信息。&lt;h4&gt;方法&lt;/h4&gt;利用长短期记忆（LSTM）网络对VeReMi数据集进行离线训练，并在编队场景中实时测试检测模型。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能够几乎防止由不当行为引发的所有事故，通过触发防御协议来解散编队。然而，系统在标记特定类型的不当行为方面存在困难，特别是在不同交通条件下。&lt;h4&gt;结论&lt;/h4&gt;尽管目前存在挑战，但论文建议，通过更多的数据和进一步的改进，该MDS可以在现实世界的CITS中实施，从而提高合作驾驶网络的安全性。&lt;h4&gt;总结&lt;/h4&gt;本研究为提高道路安全提供了一种新的技术方案，未来有潜力在实际应用中减少合作驾驶中的风险。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This thesis addresses the use of Cooperative Intelligent Transport Systems(CITS) to improve road safety and efficiency by enabling vehicle-to-vehiclecommunication, highlighting the importance of secure and accurate dataexchange. To ensure safety, the thesis proposes a Machine Learning-basedMisbehavior Detection System (MDS) using Long Short-Term Memory (LSTM) networksto detect and mitigate incorrect or misleading messages within vehicularnetworks. Trained offline on the VeReMi dataset, the detection model is testedin real-time within a platooning scenario, demonstrating that it can preventnearly all accidents caused by misbehavior by triggering a defense protocolthat dissolves the platoon if anomalies are detected. The results show thatwhile the system can accurately detect general misbehavior, it struggles tolabel specific types due to varying traffic conditions, implying the difficultyof creating a universally adaptive protocol. However, the thesis suggests thatwith more data and further refinement, this MDS could be implemented inreal-world CITS, enhancing driving safety by mitigating risks from misbehaviorin cooperative driving networks.</description>
      <author>example@mail.com (Marco Franceschini)</author>
      <guid isPermaLink="false">2411.07013v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Reconstruction of neuromorphic dynamics from a single scalar time series using variational autoencoder and neural network map</title>
      <link>http://arxiv.org/abs/2411.07055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 15 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究基于单个标量时间序列重构具有神经形态行为的动力系统。&lt;h4&gt;目的&lt;/h4&gt;探讨如何利用单一时间序列训练神经网络，使其作为离散时间动力系统运作。&lt;h4&gt;方法&lt;/h4&gt;首先构建延迟坐标嵌入向量，并通过变分自编码器降低维度以获得恢复的状态空间向量；然后利用连续时间步的状态空间向量对训练另一个神经网络，使其作为递归映射运作。&lt;h4&gt;主要发现&lt;/h4&gt;在控制参数变化时，所创建的神经网络系统的行为与原始系统非常吻合，尽管在训练过程中并未明确呈现这些行为。&lt;h4&gt;结论&lt;/h4&gt;单一时间序列足以训练出一个有效的神经网络模型，能够重构和模拟原始动力系统。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过时间序列数据重构复杂动力系统的可能性，为神经网络应用提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper examines the reconstruction of a family of dynamical systems withneuromorphic behavior using a single scalar time series. A model of aphysiological neuron based on the Hodgkin-Huxley formalism is considered.Single time series of one of its variables is shown to be enough to train aneural network that can operate as a discrete time dynamical system with onecontrol parameter. The neural network system is created in two steps. First,the delay-coordinate embedding vectors are constructed form the original timeseries and their dimension is reduced with by means of a variationalautoencoder to obtain the recovered state-space vectors. It is shown that anappropriate reduced dimension can be determined by analyzing the autoencodertraining process. Second, pairs of the recovered state-space vectors atconsecutive time steps supplied with a constant value playing the role of acontrol parameter are used to train another neural network to make it operateas a recurrent map. The regimes of thus created neural network system observedwhen its control parameter is varied are in very good accordance with those ofthe original system, though they were not explicitly presented during training.</description>
      <author>example@mail.com (Pavel V. Kuptsov, Nataliya V. Stankevich)</author>
      <guid isPermaLink="false">2411.07055v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Experience-based Subproblem Planning for Multi-Robot Motion Planning</title>
      <link>http://arxiv.org/abs/2411.08851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多机器人系统在制造和监控等多种应用中提高了效率和生产力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法来解决复杂的多机器人运动规划问题。&lt;h4&gt;方法&lt;/h4&gt;利用经验驱动的规划，构建和利用小型子问题的解决方案数据库，聚焦于较少机器人之间的交互。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在可扩展性和规划效率上显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过实验验证，在移动和机械手机器人中，验证了新方法的有效性，处理了多达32个移动机器人和16个机械手机器人。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一个快速构建的低维多机器人运动规划问题数据库及其应用框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-robot systems enhance efficiency and productivity across variousapplications, from manufacturing to surveillance. While single-robot motionplanning has improved by using databases of prior solutions, extending thisapproach to multi-robot motion planning (MRMP) presents challenges due to theincreased complexity and diversity of tasks and configurations. Recent discretemethods have attempted to address this by focusing on relevantlower-dimensional subproblems, but they are inadequate for complex scenarioslike those involving manipulator robots. To overcome this, we propose a novelapproach that %leverages experience-based planning by constructs and utilizesdatabases of solutions for smaller sub-problems. By focusing on interactionsbetween fewer robots, our method reduces the need for exhaustive databasegrowth, allowing for efficient handling of more complex MRMP scenarios. Wevalidate our approach with experiments involving both mobile and manipulatorrobots, demonstrating significant improvements over existing methods inscalability and planning efficiency. Our contributions include a rapidlyconstructed database for low-dimensional MRMP problems, a framework forapplying these solutions to larger problems, and experimental validation withup to 32 mobile and 16 manipulator robots.</description>
      <author>example@mail.com (Irving Solis, James Motes, Mike Qin, Marco Morales, Nancy M. Amato)</author>
      <guid isPermaLink="false">2411.08851v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>FlexiGen: Stochastic Dataset Generator for Electric Vehicle Charging Energy Flexibility</title>
      <link>http://arxiv.org/abs/2411.07040v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures, 9 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;电动汽车（EV）和可再生能源（RES）是可持续能源系统的重要组成部分，但它们的无序整合可能对电网稳定性造成重大挑战，如峰值负荷和能源平衡问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决方案，通过实现电动汽车与电网之间的双向能量流动，优化能量使用，并缓解可再生能源发电的间歇性问题。&lt;h4&gt;方法&lt;/h4&gt;开发了FlexiGen，一个开源随机数据集生成工具，旨在克服电动汽车灵活性数据的限制，生成符合现实的电动汽车使用模式和灵活性场景的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;FlexiGen生成的合成数据集包含了家庭和办公室日常的电动汽车使用模式、行为和灵活性场景，涵盖了充电模式、用户偏好等。&lt;h4&gt;结论&lt;/h4&gt;FlexiGen生成的数据集为电动汽车与电网之间的双向能量流动和需求响应策略提供了重要的数据支持，并公开了相应的代码和示例数据集。&lt;h4&gt;总结&lt;/h4&gt;此研究为电动汽车的灵活性数据收集提供了新的方法，促进了电动汽车与可再生能源的协调集成，推动了可持续能源系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electric vehicles (EVs) and renewable energy sources (RES) are vitalcomponents of sustainable energy systems, yet their uncoordinated integrationcan pose substantial challenges to grid stability, such as unmanaged peak loadsand energy balance issues. Vehicle-to-Grid (V2G), offer a promising solution toaddress these challenges by enabling bidirectional energy flow between EVs andthe grid. As such, EVs can be used in advances Demand Response (DR) strategiesto optimize energy use and mitigate the intermittency of renewable generation.To reach such advantages, optimization algorithms need data on EV energyflexibility, such as charging patterns and usage preferences. However, datacollection remains constrained by challenges such as high costs, userengagement, data privacy concerns, and limited access to open-source datasetson EV energy flexibility. This paper presents FlexiGen an open-sourcestochastic dataset generator tool designed to overcome the data limitations inEV flexibility for V2G and V1G DR applications. FlexiGen generates syntheticdatasets encompassing realist EV usage patterns, behaviours and flexibilityscenarios for household and office routines. To generate these datasets,FlexiGen uses a series of configurable probabilistic variables, such asstochastic user routines, traffic conditions, charger types, car averageelectricity consumption and State of Charge (SoC). The generated datasetsinclude an hourly routine with the EV State of connection, Destination Charger,Estimated Departure Time, Required SOC at Departure, Estimated Arrival Time,and Estimated SOC at Arrival. Accompanying this publication an example datasetis generated for 3 households with 1 EV each, and 1 office building with 3 EVs.The generated dataset is analyzed and discussed on the paper and publishedalongside the open-source code for FlexiGen tool.</description>
      <author>example@mail.com (Bernardo Cabral, Tiago Fonseca, Clarisse Sousa, Luis Lino Ferreira)</author>
      <guid isPermaLink="false">2411.07040v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>ODEStream: A Buffer-Free Online Learning Framework with ODE-based Adaptor for Streaming Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2411.07413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在实际预测建模中，解决流时间序列的不规则性和概念漂移的挑战至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无缓冲持续学习框架ODEStream，以提高对不规则数据流的适应能力。&lt;h4&gt;方法&lt;/h4&gt;引入时间隔离层以整合数据中的时间依赖性，利用神经常微分方程处理不规则序列并生成连续数据表示。&lt;h4&gt;主要发现&lt;/h4&gt;ODEStream在基准真实世界数据集上的评估显示，其性能优于现有的在线学习和流分析基准，能够在较长时间内提供准确的预测。&lt;h4&gt;结论&lt;/h4&gt;ODEStream通过学习序列动态的变化，最小化了性能随时间的下降，能够更好地处理数据流中的动态变化。&lt;h4&gt;总结&lt;/h4&gt;该研究为流时间序列的持续学习提供了一个有效且灵活的解决方案，适用于实际应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Addressing the challenges of irregularity and concept drift in streaming timeseries is crucial in real-world predictive modelling. Previous studies in timeseries continual learning often propose models that require buffering of longsequences, potentially restricting the responsiveness of the inference system.Moreover, these models are typically designed for regularly sampled data, anunrealistic assumption in real-world scenarios. This paper introducesODEStream, a novel buffer-free continual learning framework that incorporates atemporal isolation layer that integrates temporal dependencies within the data.Simultaneously, it leverages the capability of neural ordinary differentialequations to process irregular sequences and generate a continuous datarepresentation, enabling seamless adaptation to changing dynamics in a datastreaming scenario. Our approach focuses on learning how the dynamics anddistribution of historical data change with time, facilitating the directprocessing of streaming sequences. Evaluations on benchmark real-world datasetsdemonstrate that ODEStream outperforms the state-of-the-art online learning andstreaming analysis baselines, providing accurate predictions over extendedperiods while minimising performance degradation over time by learning how thesequence dynamics change.</description>
      <author>example@mail.com (Futoon M. Abushaqra, Hao Xue, Yongli Ren, Flora D. Salim)</author>
      <guid isPermaLink="false">2411.07413v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Learning-Based Control Barrier Function with Provably Safe Guarantees: Reducing Conservatism with Heading-Aware Safety Margin</title>
      <link>http://arxiv.org/abs/2411.08999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的控制屏障函数（CBF）在车类机器人碰撞避让中往往过于保守，主要使用机器人中心之间的欧几里得距离作为安全边界，忽视了机器人的朝向。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于学习的控制屏障函数，以减少在狭窄环境中的保守性，并提高安全区域的估计准确性。&lt;h4&gt;方法&lt;/h4&gt;设计了一种考虑机器人朝向的安全边界，并使用神经网络近似非可微的安全边界函数，以确保其可微性并便于与CBF集成。&lt;h4&gt;主要发现&lt;/h4&gt;与传统方法相比，提出的CBF在超车和绕行场景中减少了33.5%的保守性，同时保持了安全性。&lt;h4&gt;结论&lt;/h4&gt;所提出的CBF是一个高阶CBF，具有相对度数为二的特性，适用于使用非线性运动学自行车模型建模的两机器人系统。&lt;h4&gt;总结&lt;/h4&gt;通过改进的安全边界设计和神经网络近似，显著提高了车类机器人在复杂环境中的安全性和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bassamlab/sigmarl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a learning-based Control Barrier Function (CBF) to reduceconservatism in collision avoidance of car-like robots. Traditional CBFs oftenuse Euclidean distance between robots' centers as safety margin, neglectingheadings and simplifying geometries to circles. While this ensures smooth,differentiable safety functions required by CBFs, it can be overly conservativein tight environments. To address this limitation, we design a heading-awaresafety margin that accounts for the robots' orientations, enabling a lessconservative and more accurate estimation of safe regions. Since the functioncomputing this safety margin is non-differentiable, we approximate it with aneural network to ensure differentiability and facilitate integration withCBFs. We describe how we achieve bounded learning error and incorporate theupper bound into the CBF to provide formal safety guarantees through forwardinvariance. We show that our CBF is a high-order CBF with relative degree twofor a system with two robots whose dynamics are modeled by the nonlinearkinematic bicycle model. Experimental results in overtaking and bypassingscenarios reveal a 33.5 % reduction in conservatism compared to traditionalmethods, while maintaining safety. Code: https://github.com/bassamlab/sigmarl</description>
      <author>example@mail.com (Jianye Xu, Bassam Alrifaee)</author>
      <guid isPermaLink="false">2411.08999v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>FM-TS: Flow Matching for Time Series Generation</title>
      <link>http://arxiv.org/abs/2411.07506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列生成已成为分析各领域时间数据的重要工具，扩散模型在生成高质量时间序列方面受到广泛关注，但计算需求高且依赖复杂的随机过程。&lt;h4&gt;目的&lt;/h4&gt;提出FM-TS，一个基于流匹配的时间序列生成框架，以简化时间序列生成过程。&lt;h4&gt;方法&lt;/h4&gt;FM-TS通过直接优化连续轨迹来避免扩散模型中常见的迭代采样和复杂噪声调度，提升训练和推理的效率，并支持条件和无条件的时间序列生成。&lt;h4&gt;主要发现&lt;/h4&gt;FM-TS在无条件设置下表现优越，能够无缝推广至条件任务，无需重新训练。与现有方法相比，FM-TS在多个数据集上表现更佳。&lt;h4&gt;结论&lt;/h4&gt;FM-TS在太阳能预测和MuJoCo插补任务中表现出色，得益于创新的$t$次幂采样方法。相关代码可在GitHub上找到。&lt;h4&gt;总结&lt;/h4&gt;FM-TS框架在时间序列生成中展现出高效性和灵活性，超越了传统扩散模型的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/unites-lab/fmts&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series generation has emerged as an essential tool for analyzingtemporal data across numerous fields. While diffusion models have recentlygained significant attention in generating high-quality time series, they tendto be computationally demanding and reliant on complex stochastic processes. Toaddress these limitations, we introduce FM-TS, a rectified Flow Matching-basedframework for Time Series generation, which simplifies the time seriesgeneration process by directly optimizing continuous trajectories. Thisapproach avoids the need for iterative sampling or complex noise schedulestypically required in diffusion-based models. FM-TS is more efficient in termsof training and inference. Moreover, FM-TS is highly adaptive, supporting bothconditional and unconditional time series generation. Notably, through ournovel inference design, the model trained in an unconditional setting canseamlessly generalize to conditional tasks without the need for retraining.Extensive benchmarking across both settings demonstrates that FM-TSconsistently delivers superior performance compared to existing approacheswhile being more efficient in terms of training and inference. For instance, interms of discriminative score, FM-TS achieves 0.005, 0.019, 0.011, 0.005,0.053, and 0.106 on the Sines, Stocks, ETTh, MuJoCo, Energy, and fMRIunconditional time series datasets, respectively, significantly outperformingthe second-best method which achieves 0.006, 0.067, 0.061, 0.008, 0.122, and0.167 on the same datasets. We have achieved superior performance in solarforecasting and MuJoCo imputation tasks, significantly enhanced by ourinnovative $t$ power sampling method. The code is available athttps://github.com/UNITES-Lab/FMTS.</description>
      <author>example@mail.com (Yang Hu, Xiao Wang, Lirong Wu, Huatian Zhang, Stan Z. Li, Sheng Wang, Tianlong Chen)</author>
      <guid isPermaLink="false">2411.07506v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Towards Characterizing Cyber Networks with Large Language Models</title>
      <link>http://arxiv.org/abs/2411.07089v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;威胁猎捕分析大量嘈杂的高维数据以发现稀疏的对抗行为。&lt;h4&gt;目的&lt;/h4&gt;利用网络数据的潜在特征发现异常行为。&lt;h4&gt;方法&lt;/h4&gt;采用名为Cyber Log Embeddings Model (CLEM)的原型工具，基于Zeek网络流量日志进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;CLEM通过在滑动窗口上过度训练，能够紧密特征化每个数据窗口，使用调整随机指数(ARI)评估CLEM输出与专家标记的k均值聚类的比较。&lt;h4&gt;结论&lt;/h4&gt;自然语言建模在理解网络数据方面具有潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过CLEM工具在高维空间中识别对抗行为的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Threat hunting analyzes large, noisy, high-dimensional data to find sparseadversarial behavior. We believe adversarial activities, however they aredisguised, are extremely difficult to completely obscure in high dimensionalspace. In this paper, we employ these latent features of cyber data to findanomalies via a prototype tool called Cyber Log Embeddings Model (CLEM). CLEMwas trained on Zeek network traffic logs from both a real-world productionnetwork and an from Internet of Things (IoT) cybersecurity testbed. The modelis deliberately overtrained on a sliding window of data to characterize eachwindow closely. We use the Adjusted Rand Index (ARI) to comparing the k-meansclustering of CLEM output to expert labeling of the embeddings. Our approachdemonstrates that there is promise in using natural language modeling tounderstand cyber data.</description>
      <author>example@mail.com (Alaric Hartsock, Luiz Manella Pereira, Glenn Fink)</author>
      <guid isPermaLink="false">2411.07089v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>DART-LLM: Dependency-Aware Multi-Robot Task Decomposition and Execution using Large Language Models</title>
      <link>http://arxiv.org/abs/2411.09022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to the 2025 IEEE International Conference on Robotics &amp;
  Automation on September 15, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在机器人系统中表现出显著的推理能力，但在多机器人系统中的应用仍然分散，难以处理复杂任务依赖和并行执行。&lt;h4&gt;目的&lt;/h4&gt;本研究提出DART-LLM系统，旨在解决多机器人系统中的任务分解和执行挑战。&lt;h4&gt;方法&lt;/h4&gt;DART-LLM利用LLMs解析自然语言指令，将其分解为具有依赖关系的多个子任务，从而建立复杂的任务序列，提升多机器人系统中的协调和并行执行效率。系统包括问答LLM模块、分解功能模块、执行模块和基于视觉语言模型（VLM）的物体检测模块。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，DART-LLM在处理长时间任务和具有复杂依赖的协作任务方面表现优异，即使使用较小的模型（如Llama 3.1 8B），系统也能取得良好性能，展示了DART-LLM在模型规模方面的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;DART-LLM系统有效增强了多机器人系统的任务处理能力，特别是在复杂任务依赖和并行执行方面。&lt;h4&gt;总结&lt;/h4&gt;DART-LLM为多机器人系统的任务分解和执行提供了新的解决方案，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have demonstrated significant reasoningcapabilities in robotic systems. However, their deployment in multi-robotsystems remains fragmented and struggles to handle complex task dependenciesand parallel execution. This study introduces the DART-LLM (Dependency-AwareMulti-Robot Task Decomposition and Execution using Large Language Models)system, designed to address these challenges. DART-LLM utilizes LLMs to parsenatural language instructions, decomposing them into multiple subtasks withdependencies to establish complex task sequences, thereby enhancing efficientcoordination and parallel execution in multi-robot systems. The system includesthe QA LLM module, Breakdown Function modules, Actuation module, and aVision-Language Model (VLM)-based object detection module, enabling taskdecomposition and execution from natural language instructions to roboticactions. Experimental results demonstrate that DART-LLM excels in handlinglong-horizon tasks and collaborative tasks with complex dependencies. Even whenusing smaller models like Llama 3.1 8B, the system achieves good performance,highlighting DART-LLM's robustness in terms of model size. Please refer to theproject website \url{https://wyd0817.github.io/project-dart-llm/} for videosand code.</description>
      <author>example@mail.com (Yongdong Wang, Runze Xiao, Jun Younes Louhi Kasahara, Ryosuke Yajima, Keiji Nagatani, Atsushi Yamashita, Hajime Asama)</author>
      <guid isPermaLink="false">2411.09022v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Clinical Reasoning through Knowledge-augmented Rationale Generation</title>
      <link>http://arxiv.org/abs/2411.07611v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages. 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;临床推理在准确疾病诊断中起着关键作用，但许多模型主要使用判别方法，忽视生成支持性推理的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出ClinRaGen，一个为疾病诊断优化的多模态推理生成的SLM。&lt;h4&gt;方法&lt;/h4&gt;ClinRaGen结合独特的知识增强注意机制，将领域知识与时间序列电子健康记录（EHR）数据融合，并采用逐步推理蒸馏策略生成文本和时间序列基础的临床推理。&lt;h4&gt;主要发现&lt;/h4&gt;ClinRaGen显著提升了SLM处理多模态EHR数据和生成准确临床推理的能力。&lt;h4&gt;结论&lt;/h4&gt;ClinRaGen支持更可靠的疾病诊断，推动LLM在医疗领域的应用，并缩小LLM与SLM之间的性能差距。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了通过多模态推理生成技术，如何有效整合领域知识以改进疾病诊断的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clinical rationales play a pivotal role in accurate disease diagnosis;however, many models predominantly use discriminative methods and overlook theimportance of generating supportive rationales. Rationale distillation is aprocess that transfers knowledge from large language models (LLMs) to smallerlanguage models (SLMs), thereby enhancing the latter's ability to break downcomplex tasks. Despite its benefits, rationale distillation alone is inadequatefor addressing domain knowledge limitations in tasks requiring specializedexpertise, such as disease diagnosis. Effectively embedding domain knowledge inSLMs poses a significant challenge. While current LLMs are primarily gearedtoward processing textual data, multimodal LLMs that incorporate time seriesdata, especially electronic health records (EHRs), are still evolving. Totackle these limitations, we introduce ClinRaGen, an SLM optimized formultimodal rationale generation in disease diagnosis. ClinRaGen incorporates aunique knowledge-augmented attention mechanism to merge domain knowledge withtime series EHR data, utilizing a stepwise rationale distillation strategy toproduce both textual and time series-based clinical rationales. Our evaluationsshow that ClinRaGen markedly improves the SLM's capability to interpretmultimodal EHR data and generate accurate clinical rationales, supporting morereliable disease diagnosis, advancing LLM applications in healthcare, andnarrowing the performance divide between LLMs and SLMs.</description>
      <author>example@mail.com (Shuai Niu, Jing Ma, Liang Bai, Zhihua Wang, Yida Xu, Yunya Song, Xian Yang)</author>
      <guid isPermaLink="false">2411.07611v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Smartphone Sensors for Enhanced Road Safety: A Comprehensive Dataset and Review</title>
      <link>http://arxiv.org/abs/2411.07315v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 14 Figures, journal paper, submitted into Scientific Data
  Journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;激进驾驶和恶劣道路条件可能导致严重碰撞，强调了有效监测以确保安全的必要性。&lt;h4&gt;目的&lt;/h4&gt;填补缺乏可靠、标准化数据集的空白，以评估道路条件和驾驶模式。&lt;h4&gt;方法&lt;/h4&gt;引入一个综合数据集，利用智能手机传感器，包含加速度计、陀螺仪、磁力计、GPS等多种传感器。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集捕获了广泛的参数，如加速度、重力、旋转速率、磁场强度和车辆速度，提供了对道路状况和驾驶行为的深入了解。&lt;h4&gt;结论&lt;/h4&gt;数据集旨在增强道路安全、基础设施维护、交通管理和城市规划，促进社区合作和进一步研究。&lt;h4&gt;总结&lt;/h4&gt;通过提供该数据集，研究希望推动智能交通系统的创新解决方案发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Severe collisions can result from aggressive driving and poor roadconditions, emphasizing the need for effective monitoring to ensure safety.Smartphones, with their array of built-in sensors, offer a practical andaffordable solution for road-sensing. However, the lack of reliable,standardized datasets has hindered progress in assessing road conditions anddriving patterns. This study addresses this gap by introducing a comprehensivedataset derived from smartphone sensors, which surpasses existing datasets byincorporating a diverse range of sensors including accelerometer, gyroscope,magnetometer, GPS, gravity, orientation, and uncalibrated sensors. Thesesensors capture extensive parameters such as acceleration force, gravitation,rotation rate, magnetic field strength, and vehicle speed, providing a detailedunderstanding of road conditions and driving behaviors. The dataset is designedto enhance road safety, infrastructure maintenance, traffic management, andurban planning. By making this dataset available to the community, the studyaims to foster collaboration, inspire further research, and facilitate thedevelopment of innovative solutions in intelligent transportation systems.</description>
      <author>example@mail.com (Amith Khandakar, David G. Michelson, Mansura Naznine, Abdus Salam, Md. Nahiduzzaman, Khaled M. Khan, Ponnuthurai Nagaratnam Suganthan, Mohamed Arselene Ayari, Hamid Menouar, Julfikar Haider)</author>
      <guid isPermaLink="false">2411.07315v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>ClevrSkills: Compositional Language and Visual Reasoning in Robotics</title>
      <link>http://arxiv.org/abs/2411.09052v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear at NeurIPS 2024 (D&amp;B track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人任务具有高度的组合性，例如清理桌子需要机器人将物体移动、拾起并逐个移走，同时重新评估动态场景。&lt;h4&gt;目的&lt;/h4&gt;探讨大型视觉语言模型（VLMs）在学习低级能力后，是否能以新颖的方式组合这些能力完成高层次任务，比如清理桌子。&lt;h4&gt;方法&lt;/h4&gt;提出ClevrSkills，一个基于ManiSkill2模拟器的基准套件，包含多种机器人任务的轨迹数据集，配有语言和视觉注释及多模态提示。&lt;h4&gt;主要发现&lt;/h4&gt;在ClevrSkills上对多种VLM基准进行评估，发现即使这些模型在大量任务上进行预训练，它们在机器人任务的组合推理上仍然失败。&lt;h4&gt;结论&lt;/h4&gt;VLM在处理组合推理的机器人任务时存在局限性，表明需要进一步研究和改进。&lt;h4&gt;总结&lt;/h4&gt;ClevrSkills为评估和提升机器人组合推理能力提供了一个新的基准和环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotics tasks are highly compositional by nature. For example, to perform ahigh-level task like cleaning the table a robot must employ low-levelcapabilities of moving the effectors to the objects on the table, pick them upand then move them off the table one-by-one, while re-evaluating theconsequently dynamic scenario in the process. Given that large vision languagemodels (VLMs) have shown progress on many tasks that require high level,human-like reasoning, we ask the question: if the models are taught therequisite low-level capabilities, can they compose them in novel ways toachieve interesting high-level tasks like cleaning the table without having tobe explicitly taught so? To this end, we present ClevrSkills - a benchmarksuite for compositional reasoning in robotics. ClevrSkills is an environmentsuite developed on top of the ManiSkill2 simulator and an accompanying dataset.The dataset contains trajectories generated on a range of robotics tasks withlanguage and visual annotations as well as multi-modal prompts as taskspecification. The suite includes a curriculum of tasks with three levels ofcompositional understanding, starting with simple tasks requiring basic motorskills. We benchmark multiple different VLM baselines on ClevrSkills and showthat even after being pre-trained on large numbers of tasks, these models failon compositional reasoning in robotics tasks.</description>
      <author>example@mail.com (Sanjay Haresh, Daniel Dijkman, Apratim Bhattacharyya, Roland Memisevic)</author>
      <guid isPermaLink="false">2411.09052v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Testing LRD in the spectral domain for functional time series in manifolds</title>
      <link>http://arxiv.org/abs/2411.07731v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  No comments&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种用于长程依赖（LRD）功能时间序列的统计假设检验方法，该方法在谱域中进行。&lt;h4&gt;目的&lt;/h4&gt;检验流形支持的功能时间序列中的长程依赖性。&lt;h4&gt;方法&lt;/h4&gt;基于加权周期图算子构建检验统计量，假设谱密度算子族的元素在流形的等距群下是不变的。&lt;h4&gt;主要发现&lt;/h4&gt;在原假设下，提出的检验统计量的渐近分布为高斯分布；在备择假设下，积分经验二阶和四阶累积谱密度算子的偏差在Hilbert-Schmidt算子范数下趋于零。&lt;h4&gt;结论&lt;/h4&gt;通过加权周期图算子的均方误差一致性，证明了检验的一致性。实现检验的方法基于流形上不变的随机Hilbert-Schmidt核的时间频率变化Karhunen-Loève展开。&lt;h4&gt;总结&lt;/h4&gt;模拟研究展示了渐近正态性和一致性的主要结果，以及所提检验方法的经验规模和功效特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A statistical hypothesis test for long range dependence (LRD) inmanifold-supported functional time series is formulated in the spectral domain.The proposed test statistic operator is based on the weighted periodogramoperator. It is assumed that the elements of the spectral density operatorfamily are invariant with respect to the group of isometries of the manifold. ACentral Limit Theorem is derived to obtain the asymptotic Gaussian distributionof the proposed test statistics operator under the null hypothesis. The rate ofconvergence to zero, in the Hilbert--Schmidt operator norm, of the bias of theintegrated empirical second and fourth order cumulant spectral densityoperators is established under the alternative hypothesis. The consistency ofthe test is derived, from the consistency, in the sense of the integrated meansquare error, of the weighted periodogram operator under LRD. Our proposal toimplement, in practice, the testing approach is based on thetemporal-frequency-varying Karhunen-Lo\'eve expansion obtained here forinvariant random Hilbert-Schmidt kernels on manifolds. A simulation studyillustrates the main results regarding asymptotic normality and consistency,and the empirical size and power properties of the proposed testing approach.</description>
      <author>example@mail.com (M. D. Ruiz-Medina, R. M. Crujeiras)</author>
      <guid isPermaLink="false">2411.07731v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>An Attack Traffic Identification Method Based on Temporal Spectrum</title>
      <link>http://arxiv.org/abs/2411.07510v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 7 figures, 7 tables, 8 formulas&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有网络攻击检测与识别模型存在鲁棒性不足、特征不稳定和数据噪声干扰的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于时间谱的攻击流量检测与识别方法。&lt;h4&gt;方法&lt;/h4&gt;首先，通过滑动窗口对流量数据进行分段，构建特征序列和相应标签序列；然后，应用SSPE和COAP方法将标签序列转化为谱标签，将特征序列转化为时间特征；最后，利用构建的时间特征和谱标签训练模型以检测和识别网络攻击行为。&lt;h4&gt;主要发现&lt;/h4&gt;与传统方法相比，使用SSPE或COAP方法训练的模型提高了识别准确率10%，并在噪声环境中表现出强大的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;基于时间谱的方法有效提升了网络攻击检测与识别的准确性和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;研究表明，提出的方法在复杂环境中能够更好地捕捉和表示攻击行为模式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jim-xie-cn/Research-SSPE-COPA&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the issues of insufficient robustness, unstable features, and datanoise interference in existing network attack detection and identificationmodels, this paper proposes an attack traffic detection and identificationmethod based on temporal spectrum. First, traffic data is segmented by asliding window to construct a feature sequence and a corresponding labelsequence for network traffic. Next, the proposed spectral label generationmethods, SSPE and COAP, are applied to transform the label sequence intospectral labels and the feature sequence into temporal features. Spectrallabels and temporal features are used to capture and represent behavioralpatterns of attacks. Finally, the constructed temporal features and spectrallabels are used to train models, which subsequently detects and identifiesnetwork attack behaviors. Experimental results demonstrate that compared totraditional methods, models trained with the SSPE or COAP method improveidentification accuracy by 10%, and exhibit strong robustness, particularly innoisy environments.</description>
      <author>example@mail.com (Wenwei Xie, Jie Yin, Zihao Chen)</author>
      <guid isPermaLink="false">2411.07510v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>A dynamic latent space time series model to assess the spread of mumps in England</title>
      <link>http://arxiv.org/abs/2411.07749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 20 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;该研究基于英格兰九个地区的腮腺炎病例原始数据集，关注时间动态和时间变化的依赖模式建模。&lt;h4&gt;目的&lt;/h4&gt;旨在发现超越地理位置的潜在传播路径，可能由其他不可直接观察的社会经济因素解释。&lt;h4&gt;方法&lt;/h4&gt;通过采用时间变化的潜在距离网络模型，扩展现有计数时间序列网络模型，捕捉跨系列和跨时间的依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;模型参数在多种现实依赖设置下能够准确估计，实际数据应用提供了一些潜在传播路径的详细视图。&lt;h4&gt;结论&lt;/h4&gt;研究结果突显了关键区域在感染动态中的作用，为公共卫生策略的设计提供了有价值的视角。&lt;h4&gt;总结&lt;/h4&gt;该方法允许清晰可解释的可视化复杂关系，并提供潜在风险的度量，帮助理解传播机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work is motivated by an original dataset of reported mumps cases acrossnine regions of England, and focuses on the modeling of temporal dynamics andtime-varying dependency patterns between the observed time series. The goal isto discover the possible presence of latent routes of contagion that go beyondthe geographical locations of the regions, and instead may be explained throughother non directly observable socio-economic factors. We build upon the recentstatistics literature and extend the existing count time series network modelsby adopting a time-varying latent distance network model. This approach canefficiently capture across-series and across-time dependencies, which are bothnot directly observed from the data. We adopt a Bayesian hierarchical frameworkand perform parameter estimation using L-BFGS optimization and HamiltonianMonte Carlo. We demonstrate with several simulation experiments that the modelparameters can be accurately estimated under a variety of realistic dependencysettings. Our real data application on mumps cases leads to a detailed view ofsome possible contagion routes. A critical advantage of our methodology is thatit permits clear and interpretable visualizations of the complex relationsbetween the time series and how these relations may evolve over time. Thegeometric nature of the latent embedding provides useful model based summaries.In particular, we show how to extract a measure of contraction of the inferredlatent space, which can be interpreted as an overall risk for the escalation ofcontagion, at each point in time. Ultimately, the results highlight somepossible critical transmission pathways and the role of key regions in drivinginfection dynamics, offering valuable perspectives that may be considered whendesigning public health strategies.</description>
      <author>example@mail.com (Hardeep Kaur, Riccardo Rastelli)</author>
      <guid isPermaLink="false">2411.07749v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Information-Optimal Multi-Spacecraft Positioning for Interstellar Object Exploration</title>
      <link>http://arxiv.org/abs/2411.09110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Aerospace Conference, Preprint Version, Accepted: November 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;星际物体（ISOs）是指不受太阳引力束缚的天体，能够为我们理解宇宙的形成和组成提供宝贵的机会。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的多航天器框架，以最大化通过ISOs接触获得的信息，并提供形式化的概率保证。&lt;h4&gt;方法&lt;/h4&gt;通过构建一个椭球体围绕航天器终端位置，处理ISOs的大状态不确定性，并优化多个航天器在椭球体周围的终端位置，以最大化信息获取。&lt;h4&gt;主要发现&lt;/h4&gt;数值模拟表明，该方法有效，能够优化航天器的终端状态选择及理想的兴趣点数量。&lt;h4&gt;结论&lt;/h4&gt;该方法有助于在最小化资源利用的同时，增强对这些稀有且短暂的星际访客的研究能力。&lt;h4&gt;总结&lt;/h4&gt;通过多航天器协同工作，能够更有效地收集来自ISOs的视觉数据，推进对宇宙的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interstellar objects (ISOs), astronomical objects not gravitationally boundto the sun, could present valuable opportunities to advance our understandingof the universe's formation and composition. In response to the unpredictablenature of their discoveries that inherently come with large and rapidlychanging uncertainty in their state, this paper proposes a novelmulti-spacecraft framework for locally maximizing information to be gainedthrough ISO encounters with formal probabilistic guarantees. Given someapproximated control and estimation policies for fully autonomous spacecraftoperations, we first construct an ellipsoid around its terminal position, wherethe ISO would be located with a finite probability. The large state uncertaintyof the ISO is formally handled here through the hierarchical property instochastically contracting nonlinear systems. We then propose a method to findthe terminal positions of the multiple spacecraft optimally distributed aroundthe ellipsoid, which locally maximizes the information we can get from all thepoints of interest (POIs). This utilizes a probabilistic information costfunction that accounts for spacecraft positions, camera specifications, and ISOposition uncertainty, where the information is defined as visual data collectedby cameras. Numerical simulations demonstrate the efficacy of this approachusing synthetic ISO candidates generated from quasi-realistic empiricalpopulations. Our method allows each spacecraft to optimally select its terminalstate and determine the ideal number of POIs to investigate, potentiallyenhancing the ability to study these rare and fleeting interstellar visitorswhile minimizing resource utilization.</description>
      <author>example@mail.com (Arna Bhardwaj, Shishir Bhatta, Hiroyasu Tsukamoto)</author>
      <guid isPermaLink="false">2411.09110v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Towards Vision Mixture of Experts for Wildlife Monitoring on the Edge</title>
      <link>http://arxiv.org/abs/2411.07834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物联网传感器的快速增长导致对计算基础设施的需求激增，同时社会逐渐关注可持续计算。&lt;h4&gt;目的&lt;/h4&gt;减少计算基础设施的占用，尤其是深度学习算法在高级洞察生成中的应用。&lt;h4&gt;方法&lt;/h4&gt;TinyML社区提出了保存通信带宽和减少云存储成本的方法，同时降低算法推理延迟并促进数据隐私。&lt;h4&gt;主要发现&lt;/h4&gt;处理多种数据类型（如时间序列、音频、卫星图像和视频）可以改善学习算法的区分能力，尤其是在网络边缘进行处理时。&lt;h4&gt;结论&lt;/h4&gt;基于数据驱动的条件计算已在单一模型中共享参数，减少了多塔多模态网络的计算需求。&lt;h4&gt;总结&lt;/h4&gt;首次探索了针对移动视觉变换器的每个补丁条件计算，评估模型在鸟类物种区分数据集上的表现，相比于MobileViTV2-1.0，参数减少了4倍，准确率仅下降1%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The explosion of IoT sensors in industrial, consumer and remote sensing usecases has come with unprecedented demand for computing infrastructure totransmit and to analyze petabytes of data. Concurrently, the world is slowlyshifting its focus towards more sustainable computing. For these reasons, therehas been a recent effort to reduce the footprint of related computinginfrastructure, especially by deep learning algorithms, for advanced insightgeneration. The `TinyML' community is actively proposing methods to savecommunication bandwidth and excessive cloud storage costs while reducingalgorithm inference latency and promoting data privacy. Such proposedapproaches should ideally process multiple types of data, including timeseries, audio, satellite images, and video, near the network edge as multipledata streams has been shown to improve the discriminative ability of learningalgorithms, especially for generating fine grained results. Incidentally, therehas been recent work on data driven conditional computation of subnetworks thathas shown real progress in using a single model to share parameters among verydifferent types of inputs such as images and text, reducing the computationrequirement of multi-tower multimodal networks. Inspired by such line of work,we explore similar per patch conditional computation for the first time formobile vision transformers (vision only case), that will eventually be used forsingle-tower multimodal edge models. We evaluate the model on Cornell SapSucker Woods 60, a fine grained bird species discrimination dataset. Ourinitial experiments uses $4X$ fewer parameters compared to MobileViTV2-1.0 witha $1$% accuracy drop on the iNaturalist '21 birds test data provided as part ofthe SSW60 dataset.</description>
      <author>example@mail.com (Emmanuel Azuh Mensah, Anderson Lee, Haoran Zhang, Yitong Shan, Kurtis Heimerl)</author>
      <guid isPermaLink="false">2411.07834v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Deep Learning Approach for Real-time Lane-based Arrival Curve Reconstruction at Intersection using License Plate Recognition Data</title>
      <link>http://arxiv.org/abs/2411.07515v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by T-ITS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;实时和准确的交通到达信息对于主动交通控制系统至关重要，尤其是在部分连接的车辆环境中。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在提出一种用于实时车道基础到达曲线重建的贝叶斯深度学习方法。&lt;h4&gt;方法&lt;/h4&gt;该方法通过捕捉部分观察的链路到达与车道到达之间的关系，表征链路到达的车道选择模式和不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;在多个匹配率场景下的实际实验结果表明，车道选择建模在重建到达曲线中具有优越性和必要性。&lt;h4&gt;结论&lt;/h4&gt;通过贝叶斯参数推断技术，最小化到达曲线重建的不确定性，尤其是在低LPR数据匹配率条件下。&lt;h4&gt;总结&lt;/h4&gt;研究强调了车道选择模式及其不确定性在交通到达信息重建中的重要性，推动了交通控制系统的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The acquisition of real-time and accurate traffic arrival information is ofvital importance for proactive traffic control systems, especially in partiallyconnected vehicle environments. License plate recognition (LPR) data thatrecord both vehicle departures and identities are proven to be desirable inreconstructing lane-based arrival curves in previous works. Existing LPRdatabased methods are predominantly designed for reconstructing historicalarrival curves. For real-time reconstruction of multi-lane urban roads, it ispivotal to determine the lane choice of real-time link-based arrivals, whichhas not been exploited in previous studies. In this study, we propose aBayesian deep learning approach for real-time lane-based arrival curvereconstruction, in which the lane choice patterns and uncertainties oflink-based arrivals are both characterized. Specifically, the learning processis designed to effectively capture the relationship between partially observedlink-based arrivals and lane-based arrivals, which can be physicallyinterpreted as lane choice proportion. Moreover, the lane choice uncertaintiesare characterized using Bayesian parameter inference techniques, minimizingarrival curve reconstruction uncertainties, especially in low LPR data matchingrate conditions. Real-world experiment results conducted in multiple matchingrate scenarios demonstrate the superiority and necessity of lane choicemodeling in reconstructing arrival curves.</description>
      <author>example@mail.com (Yang He, Chengchuan An, Jiawei Lu, Yao-Jan Wu, Zhenbo Lu, Jingxin Xia)</author>
      <guid isPermaLink="false">2411.07515v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>UniHOI: Learning Fast, Dense and Generalizable 4D Reconstruction for Egocentric Hand Object Interaction Videos</title>
      <link>http://arxiv.org/abs/2411.09145v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Egocentric Hand Object Interaction (HOI) 视频为人类与物理世界的交互提供了重要洞察，受到计算机视觉和机器人领域的关注。&lt;h4&gt;目的&lt;/h4&gt;实现对HOI场景几何和动态的全面理解，尤其是密集点云序列重建。&lt;h4&gt;方法&lt;/h4&gt;提出UniHOI模型，统一估计密集4D重建所需的所有变量，包括相机内参、相机位姿和视频深度，通过快速的前向传播方式优化这些变量。&lt;h4&gt;主要发现&lt;/h4&gt;UniHOI在点云序列重建和长时间3D场景流恢复方面超越了所有基线，能够在有运动的情况下实现快速、密集且可泛化的单目HOI场景重建。&lt;h4&gt;结论&lt;/h4&gt;UniHOI是第一种能在运动存在下提供快速、密集和可泛化的单目egocentric HOI场景重建的方法，未来将发布代码和训练模型。&lt;h4&gt;总结&lt;/h4&gt;UniHOI模型有效解决了HOI场景重建中的挑战，提升了一系列变量的一致性，并在训练数据稀缺的情况下实现了良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Egocentric Hand Object Interaction (HOI) videos provide valuable insightsinto human interactions with the physical world, attracting growing interestfrom the computer vision and robotics communities. A key task in fullyunderstanding the geometry and dynamics of HOI scenes is dense pointcloudssequence reconstruction. However, the inherent motion of both hands and thecamera makes this challenging. Current methods often rely on time-consumingtest-time optimization, making them impractical for reconstructinginternet-scale videos. To address this, we introduce UniHOI, a model thatunifies the estimation of all variables necessary for dense 4D reconstruction,including camera intrinsic, camera poses, and video depth, for egocentric HOIscene in a fast feed-forward manner. We end-to-end optimize all these variablesto improve their consistency in 3D space. Furthermore, our model could betrained solely on large-scale monocular video dataset, overcoming thelimitation of scarce labeled HOI data. We evaluate UniHOI with both in-domainand zero-shot generalization setting, surpassing all baselines in pointcloudssequence reconstruction and long-term 3D scene flow recovery. UniHOI is thefirst approach to offer fast, dense, and generalizable monocular egocentric HOIscene reconstruction in the presence of motion. Code and trained model will bereleased in the future.</description>
      <author>example@mail.com (Chengbo Yuan, Geng Chen, Li Yi, Yang Gao)</author>
      <guid isPermaLink="false">2411.09145v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>SynapsNet: Enhancing Neuronal Population Dynamics Modeling via Learning Functional Connectivity</title>
      <link>http://arxiv.org/abs/2411.08221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模神经元群体数据集的可用性需要新的方法来建模群体动态并提取可解释的科学见解。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，以更好地理解神经元活动及其相互作用。&lt;h4&gt;方法&lt;/h4&gt;引入SynapsNet，一个生物学上合理的深度学习框架，能够建模神经元之间的功能互动和群体动态。&lt;h4&gt;主要发现&lt;/h4&gt;SynapsNet在预测群体活动方面优于现有模型，并能够准确学习揭示神经元之间预测性互动的功能连接。&lt;h4&gt;结论&lt;/h4&gt;SynapsNet有效地建模了神经元活动，提供了更好的群体动态预测，并对生物机制提供了可解释的信息。&lt;h4&gt;总结&lt;/h4&gt;SynapsNet通过个别神经元的解码和可学习的功能连接，改善了对神经元群体活动的理解和预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The availability of large-scale neuronal population datasets necessitates newmethods to model population dynamics and extract interpretable, scientificallytranslatable insights. Existing deep learning methods often overlook thebiological mechanisms underlying population activity and thus exhibitsuboptimal performance with neuronal data and provide little to nointerpretable information about neurons and their interactions. In response, weintroduce SynapsNet, a novel deep-learning framework that effectively modelspopulation dynamics and functional interactions between neurons. Within thisbiologically realistic framework, each neuron, characterized by a latentembedding, sends and receives currents through directed connections. A shareddecoder uses the input current, previous neuronal activity, neuron embedding,and behavioral data to predict the population activity in the next time step.Unlike common sequential models that treat population activity as amultichannel time series, SynapsNet applies its decoder to each neuron(channel) individually, with the learnable functional connectivity serving asthe sole pathway for information flow between neurons. Our experiments,conducted on mouse cortical activity from publicly available datasets andrecorded using the two most common population recording modalities (Ca imagingand Neuropixels) across three distinct tasks, demonstrate that SynapsNetconsistently outperforms existing models in forecasting population activity.Additionally, our experiments on both real and synthetic data showed thatSynapsNet accurately learns functional connectivity that reveals predictiveinteractions between neurons.</description>
      <author>example@mail.com (Parsa Delavari, Ipek Oruc, Timothy H Murphy)</author>
      <guid isPermaLink="false">2411.08221v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Trust-Aware Sybil Attack Detection for Resilient Vehicular Communication</title>
      <link>http://arxiv.org/abs/2411.07520v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;连接的自动驾驶车辆（车载自组网，VANETs）在安全、隐私和安全性方面存在担忧，尤其是针对Sybil攻击的风险。&lt;h4&gt;目的&lt;/h4&gt;提出一个信任感知的Sybil事件识别框架（TASER），用于评估VANETs中车辆数据的完整性。&lt;h4&gt;方法&lt;/h4&gt;该框架评估局部车辆集群中交换的信息，基于报告的数据完整性维护每辆车的累计信任度，使用定向天线验证可疑实体的GPS位置。&lt;h4&gt;主要发现&lt;/h4&gt;使用OMNeT++离散事件模拟器、SUMO交通模拟器和VEINS接口进行评估，框架在城市场景中将攻击检测时间减少了多达66%，准确率在含有最多30% Sybil节点的模拟中变化不超过3%。&lt;h4&gt;结论&lt;/h4&gt;该方法无需依赖路边基础设施，能够有效提高Sybil攻击检测的效率和准确性。&lt;h4&gt;总结&lt;/h4&gt;TASER框架为VANETs中的车辆数据完整性提供了一种有效的评估方案，增强了安全性并降低了攻击影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Connected autonomous vehicles, or Vehicular Ad hoc Networks (VANETs), holdgreat promise, but concerns persist regarding safety, privacy, and security,particularly in the face of Sybil attacks, where malicious entities falsifyneighboring traffic information. Despite advancements in detection techniques,many approaches suffer from processing delays and reliance on broadarchitecture, posing significant risks in mitigating attack damages. To addressthese concerns, our research proposes a Trust Aware Sybil Event Recognition(TASER) framework for assessing the integrity of vehicle data in VANETs. Thisframework evaluates information exchanged within local vehicle clusters,maintaining a cumulative trust metric for each vehicle based on reported dataintegrity. Suspicious entities failing to meet trust metric thresholds arestatistically evaluated, and their legitimacy is challenged using directionalantennas to verify their reported GPS locations. We evaluate our frameworkusing the OMNeT++ discrete event simulator, SUMO traffic simulator, and VEINSinterface with TraCI API. Our approach reduces attack detection times by up to66% in urban scenarios, with accuracy varying by no more than 3% acrosssimulations containing up to 30% Sybil nodes and operates without reliance onroadside infrastructure.</description>
      <author>example@mail.com (Mortan Thomas, Abinash Borah, Anirudh Paranjothi)</author>
      <guid isPermaLink="false">2411.07520v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>VidMan: Exploiting Implicit Dynamics from Video Diffusion Model for Effective Robot Manipulation</title>
      <link>http://arxiv.org/abs/2411.09153v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，利用大规模视频数据学习视频生成模型的进展显示出理解复杂物理动态的显著潜力。&lt;h4&gt;目的&lt;/h4&gt;提出VidMan框架，利用多样的机器人轨迹数据开发统一的动态感知模型，以提高机器人操作能力。&lt;h4&gt;方法&lt;/h4&gt;采用两阶段训练机制，第一阶段在OpenX-Embodiment数据集上进行预训练，第二阶段引入自注意力适配器，转化为逆动态模型。&lt;h4&gt;主要发现&lt;/h4&gt;VidMan框架在CALVIN基准测试中相较于最先进的基线模型GR-1提升了11.7%的相对性能，在OXE小规模数据集上精度提升超过9%。&lt;h4&gt;结论&lt;/h4&gt;世界模型显著增强了机器人动作预测的精度，提供了强有力的证据支持。&lt;h4&gt;总结&lt;/h4&gt;VidMan框架展示了有效利用视频数据和机器人轨迹数据的潜力，代码和模型将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements utilizing large-scale video data for learning videogeneration models demonstrate significant potential in understanding complexphysical dynamics. It suggests the feasibility of leveraging diverse robottrajectory data to develop a unified, dynamics-aware model to enhance robotmanipulation. However, given the relatively small amount of available robotdata, directly fitting data without considering the relationship between visualobservations and actions could lead to suboptimal data utilization. To thisend, we propose VidMan (Video Diffusion for Robot Manipulation), a novelframework that employs a two-stage training mechanism inspired by dual-processtheory from neuroscience to enhance stability and improve data utilizationefficiency. Specifically, in the first stage, VidMan is pre-trained on the OpenX-Embodiment dataset (OXE) for predicting future visual trajectories in a videodenoising diffusion manner, enabling the model to develop a long horizontalawareness of the environment's dynamics. In the second stage, a flexible yeteffective layer-wise self-attention adapter is introduced to transform VidManinto an efficient inverse dynamics model that predicts action modulated by theimplicit dynamics knowledge via parameter sharing. Our VidMan frameworkoutperforms state-of-the-art baseline model GR-1 on the CALVIN benchmark,achieving a 11.7% relative improvement, and demonstrates over 9% precisiongains on the OXE small-scale dataset. These results provide compelling evidencethat world models can significantly enhance the precision of robot actionprediction. Codes and models will be public.</description>
      <author>example@mail.com (Youpeng Wen, Junfan Lin, Yi Zhu, Jianhua Han, Hang Xu, Shen Zhao, Xiaodan Liang)</author>
      <guid isPermaLink="false">2411.09153v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>New approaches of the DCC-GARCH residual: Application to foreign exchange rates</title>
      <link>http://arxiv.org/abs/2411.08246v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 18 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出两种方法以过滤多元GARCH模型残差中的相关性。&lt;h4&gt;目的&lt;/h4&gt;提高多元GARCH模型的残差独立性。&lt;h4&gt;方法&lt;/h4&gt;第一种方法通过估计相关矩阵作为参数并将联合分布转换为任意相关矩阵；第二种方法基于相关矩阵的特征值分解将时间序列数据转换为无相关残差。&lt;h4&gt;主要发现&lt;/h4&gt;这两种方法在外汇预测任务中的实证表现良好，并与其他方法的样本外似然性进行了比较。&lt;h4&gt;结论&lt;/h4&gt;使用这些方法可以使DCC-GARCH残差几乎独立。&lt;h4&gt;总结&lt;/h4&gt;提出的两种方法有效地改善了多元GARCH模型的残差相关性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Two formulations are proposed to filter out correlations in the residuals ofthe multivariate GARCH model. The first approach is to estimate the correlationmatrix as a parameter and transform any joint distribution to have an arbitrarycorrelation matrix. The second approach transforms time series data into anuncorrelated residual based on the eigenvalue decomposition of a correlationmatrix. The empirical performance of these methods is examined through aprediction task for foreign exchange rates and compared with othermethodologies in terms of the out-of-sample likelihood. By using theseapproaches, the DCC-GARCH residual can be almost independent.</description>
      <author>example@mail.com (Kenichiro Shiraya, Kanji Suzuki, Tomohisa Yamakami)</author>
      <guid isPermaLink="false">2411.08246v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Accident Impact Prediction based on a deep convolutional and recurrent neural network model</title>
      <link>http://arxiv.org/abs/2411.07537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 18 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交通事故对公共安全构成重大威胁，每年导致无数伤亡和经济负担。&lt;h4&gt;目的&lt;/h4&gt;开发能够实时预测事故后影响的模型，以预防不良后果并提高整体安全性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为级联模型的深度神经网络模型，利用洛杉矶县的可用数据预测事故后影响，该模型结合了长短期记忆（LSTM）和卷积神经网络（CNN）。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在预测事故后影响的精确度上优于现有的基线模型，尤其在预测轻微影响和重大影响的准确率方面表现突出。&lt;h4&gt;结论&lt;/h4&gt;通过引入“事故影响”因素，该模型有效量化了事故对周围交通流的影响，证明了混合机器学习方法在事故后影响预测中的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种新的深度学习方法来提高交通事故影响的预测能力，有助于提升交通安全。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mahyaqorbani/accident-impact-prediction-using-deep-convolutional-and-recurrent-neural-networks&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic accidents pose a significant threat to public safety, resulting innumerous fatalities, injuries, and a substantial economic burden each year. Thedevelopment of predictive models capable of real-time forecasting ofpost-accident impact using readily available data can play a crucial role inpreventing adverse outcomes and enhancing overall safety. However, existingaccident predictive models encounter two main challenges: first, reliance oneither costly or non-real-time data, and second the absence of a comprehensivemetric to measure post-accident impact accurately. To address theselimitations, this study proposes a deep neural network model known as thecascade model. It leverages readily available real-world data from Los AngelesCounty to predict post-accident impacts. The model consists of two components:Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN). The LSTMmodel captures temporal patterns, while the CNN extracts patterns from thesparse accident dataset. Furthermore, an external traffic congestion dataset isincorporated to derive a new feature called the "accident impact" factor, whichquantifies the influence of an accident on surrounding traffic flow. Extensiveexperiments were conducted to demonstrate the effectiveness of the proposedhybrid machine learning method in predicting the post-accident impact comparedto state-of-the-art baselines. The results reveal a higher precision inpredicting minimal impacts (i.e., cases with no reported accidents) and ahigher recall in predicting more significant impacts (i.e., cases with reportedaccidents).</description>
      <author>example@mail.com (Pouyan Sajadi, Mahya Qorbani, Sobhan Moosavi, Erfan Hassannayebi)</author>
      <guid isPermaLink="false">2411.07537v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>EMPERROR: A Flexible Generative Perception Error Model for Probing Self-Driving Planners</title>
      <link>http://arxiv.org/abs/2411.07719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://lasnik.github.io/emperror/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动驾驶系统的规划需要处理现实交通中的复杂性，基于数据的学习规划是一个有前景的方向。&lt;h4&gt;目的&lt;/h4&gt;提高规划系统对噪声感知系统引入的错误的鲁棒性，克服当前方法在评估中忽视这一点的问题。&lt;h4&gt;方法&lt;/h4&gt;提出EMPERROR，一种基于变换器的生成性感知错误模型（PEM），用于应对检测失败模式。&lt;h4&gt;主要发现&lt;/h4&gt;EMPERROR能够更真实地模拟现代检测器，并生成增加规划器碰撞率的现实噪声输入，碰撞率最高可提高85%。&lt;h4&gt;结论&lt;/h4&gt;EMPERROR作为一种工具，能够提供更全面的自动驾驶规划的评估。&lt;h4&gt;总结&lt;/h4&gt;通过引入EMPERROR，本文展示了如何有效地评估和提高自动驾驶规划系统在噪声环境下的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To handle the complexities of real-world traffic, learning planners forself-driving from data is a promising direction. While recent approaches haveshown great progress, they typically assume a setting in which the ground-truthworld state is available as input. However, when deployed, planning needs to berobust to the long-tail of errors incurred by a noisy perception system, whichis often neglected in evaluation. To address this, previous work has proposeddrawing adversarial samples from a perception error model (PEM) mimicking thenoise characteristics of a target object detector. However, these methods usesimple PEMs that fail to accurately capture all failure modes of detection. Inthis paper, we present EMPERROR, a novel transformer-based generative PEM,apply it to stress-test an imitation learning (IL)-based planner and show thatit imitates modern detectors more faithfully than previous work. Furthermore,it is able to produce realistic noisy inputs that increase the planner'scollision rate by up to 85%, demonstrating its utility as a valuable tool for amore complete evaluation of self-driving planners.</description>
      <author>example@mail.com (Niklas Hanselmann, Simon Doll, Marius Cordts, Hendrik P. A. Lensch, Andreas Geiger)</author>
      <guid isPermaLink="false">2411.07719v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Rationality based Innate-Values-driven Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2411.09160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2401.05572&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;内在价值描述了代理的内在动机，反映了它们追求目标的固有兴趣和偏好，以及发展多样技能以满足不同需求的驱动。&lt;h4&gt;目的&lt;/h4&gt;提出一种层次复合内在价值强化学习模型（IVRL），以描述AI代理的复杂行为和交互。&lt;h4&gt;方法&lt;/h4&gt;建立了IVRL模型，提出了两种IVRL模型：DQN和A2C，并在VIZDoom的角色扮演游戏强化学习测试平台上与基准算法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;合理组织各种个体需求可以有效地提高性能。&lt;h4&gt;结论&lt;/h4&gt;平衡内部和外部效用以支持AI代理的学习是实现AI与人类社会安全和谐整合的关键问题。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了内在价值驱动的强化学习在AI代理行为建模中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Innate values describe agents' intrinsic motivations, which reflect theirinherent interests and preferences to pursue goals and drive them to developdiverse skills satisfying their various needs. The essence of reinforcementlearning (RL) is learning from interaction based on reward-driven behaviors,much like natural agents. It is an excellent model to describe theinnate-values-driven (IV) behaviors of AI agents. Especially developing theawareness of the AI agent through balancing internal and external utilitiesbased on its needs in different tasks is a crucial problem for individualslearning to support AI agents integrating human society with safety and harmonyin the long term. This paper proposes a hierarchical compound intrinsic valuereinforcement learning model -- innate-values-driven reinforcement learningtermed IVRL to describe the complex behaviors of AI agents' interaction. Weformulated the IVRL model and proposed two IVRL models: DQN and A2C. Bycomparing them with benchmark algorithms such as DQN, DDQN, A2C, and PPO in theRole-Playing Game (RPG) reinforcement learning test platform VIZDoom, wedemonstrated that rationally organizing various individual needs caneffectively achieve better performance.</description>
      <author>example@mail.com (Qin Yang)</author>
      <guid isPermaLink="false">2411.09160v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Traffic Signal Control using High-Dimensional State Representation and Efficient Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2411.07759v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在基于强化学习的交通信号控制中，信号定时决策依赖于交叉口车辆的信息。&lt;h4&gt;目的&lt;/h4&gt;探讨高维状态表示对交通信号控制性能的影响。&lt;h4&gt;方法&lt;/h4&gt;通过实验结果分析高维状态表示与低维状态表示的性能差异。&lt;h4&gt;主要发现&lt;/h4&gt;使用高维状态表示可以提高交通信号控制的性能，平均等待时间可改善达17.9%。&lt;h4&gt;结论&lt;/h4&gt;高维状态表示利用成本效益高的车联网通信（V2I）实现，支持其在交通信号控制中的应用。&lt;h4&gt;补充发现&lt;/h4&gt;由于状态尺寸较大，需开发计算效率高的模型，并探索了通过剪枝进行模型压缩的可能性。&lt;h4&gt;总结&lt;/h4&gt;高维状态表示在交通信号控制中具有重要价值，值得进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In reinforcement learning-based (RL-based) traffic signal control (TSC),decisions on the signal timing are made based on the available information onvehicles at a road intersection. This forms the state representation for the RLenvironment which can either be high-dimensional containing several variablesor a low-dimensional vector. Current studies suggest that using highdimensional state representations does not lead to improved performance on TSC.However, we argue, with experimental results, that the use of high dimensionalstate representations can, in fact, lead to improved TSC performance withimprovements up to 17.9% of the average waiting time. This high-dimensionalrepresentation is obtainable using the cost-effective vehicle-to-infrastructure(V2I) communication, encouraging its adoption for TSC. Additionally, given thelarge size of the state, we identified the need to have computational efficientmodels and explored model compression via pruning.</description>
      <author>example@mail.com (Lawrence Francis, Blessed Guda, Ahmed Biyabani)</author>
      <guid isPermaLink="false">2411.07759v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Risk-aware MPPI for Stochastic Hybrid Systems</title>
      <link>http://arxiv.org/abs/2411.09198v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随机混合系统的路径规划面临预测未来状态分布的独特挑战，受到状态相关动态切换函数的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种变体的模型预测路径积分控制（MPPI），用于规划此类系统的运动路径。&lt;h4&gt;方法&lt;/h4&gt;采用基于无迹变换的方法来捕捉状态中的随机性及状态相关的切换面，与以往仅基于预测状态均值进行切换的方法不同。&lt;h4&gt;主要发现&lt;/h4&gt;在动态移动代理存在的情况下，利用混合人类动态的机器人比不利用时更快地收敛到目标且没有发生碰撞。&lt;h4&gt;结论&lt;/h4&gt;该框架在模拟移动机器人中的应用表明，考虑动态代理的路径规划可以提高效率和安全性。&lt;h4&gt;总结&lt;/h4&gt;本研究为随机混合系统的运动规划提供了一种有效的方法，能够更好地应对状态相关的动态变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Path Planning for stochastic hybrid systems presents a unique challenge ofpredicting distributions of future states subject to a state-dependent dynamicsswitching function. In this work, we propose a variant of Model Predictive PathIntegral Control (MPPI) to plan kinodynamic paths for such systems. Monte Carlomay be inaccurate when few samples are chosen to predict future states understate-dependent disturbances. We employ recently proposed UnscentedTransform-based methods to capture stochasticity in the states as well as thestate-dependent switching surfaces. This is in contrast to previous works thatperform switching based only on the mean of predicted states. We focus ourmotion planning application on the navigation of a mobile robot in the presenceof dynamically moving agents whose responses are based on sensor-constrainedattention zones. We evaluate our framework on a simulated mobile robot and showfaster convergence to a goal without collisions when the robot exploits thehybrid human dynamics versus when it does not.</description>
      <author>example@mail.com (Hardik Parwana, Mitchell Black, Bardh Hoxha, Hideki Okamoto, Georgios Fainekos, Danil Prokhorov, Dimitra Panagou)</author>
      <guid isPermaLink="false">2411.09198v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>TLDR: Traffic Light Detection using Fourier Domain Adaptation in Hostile WeatheR</title>
      <link>http://arxiv.org/abs/2411.07901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review at IEEE Transactions of Artificial Intelligence. 10
  Pages, 7 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交通灯检测和识别领域缺乏全面的数据集，且在恶劣天气条件下，现有模型的性能较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，通过合并LISA和S2TLD两个广泛使用的数据集，解决数据稀缺和模型性能问题。&lt;h4&gt;方法&lt;/h4&gt;合并数据集后，处理类别不平衡问题，添加合成雨和雾以创建目标域，使用傅里叶领域适应（FDA）最小化两个数据集之间的域差距，并探索半监督学习（SSL）技术以更有效地利用可用数据。&lt;h4&gt;主要发现&lt;/h4&gt;经过FDA增强的图像训练模型在多个指标上优于未使用FDA的模型，最佳模型YOLOv8在各项指标上均有显著提升，精度提高5.1860%，召回率提高14.8009%，mAP50提高9.5074%，mAP50-95提高19.5035%。&lt;h4&gt;结论&lt;/h4&gt;所有模型的平均精度、召回率和mAP指标均显著提高，验证了FDA在减轻恶劣天气条件对模型性能影响方面的有效性。&lt;h4&gt;总结&lt;/h4&gt;这些改进为在具有挑战性的环境条件下实现可靠的性能的实际应用铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The scarcity of comprehensive datasets in the traffic light detection andrecognition domain and the poor performance of state-of-the-art models underhostile weather conditions present significant challenges. To address theseissues, this paper proposes a novel approach by merging two widely useddatasets, LISA and S2TLD. The merged dataset is further processed to tackleclass imbalance, a common problem in this domain. This merged dataset becomesour source domain. Synthetic rain and fog are added to the dataset to createour target domain. We employ Fourier Domain Adaptation (FDA) to create a finaldataset with a minimized domain gap between the two datasets, helping the modeltrained on this final dataset adapt to rainy and foggy weather conditions.Additionally, we explore Semi-Supervised Learning (SSL) techniques to leveragethe available data more effectively. Experimental results demonstrate thatmodels trained on FDA-augmented images outperform those trained without FDAacross confidence-dependent and independent metrics, like mAP50, mAP50-95,Precision, and Recall. The best-performing model, YOLOv8, achieved a Precisionincrease of 5.1860%, Recall increase of 14.8009%, mAP50 increase of 9.5074%,and mAP50-95 increase of 19.5035%. On average, percentage increases of 7.6892%in Precision, 19.9069% in Recall, 15.8506% in mAP50, and 23.8099% in mAP50-95were observed across all models, highlighting the effectiveness of FDA inmitigating the impact of adverse weather conditions on model performance. Theseimprovements pave the way for real-world applications where reliableperformance in challenging environmental conditions is critical.</description>
      <author>example@mail.com (Ishaan Gakhar, Aryesh Guha, Aryaman Gupta, Amit Agarwal, Durga Toshniwal, Ujjwal Verma)</author>
      <guid isPermaLink="false">2411.07901v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Quantifying Qualitative Insights: Leveraging LLMs to Market Predict</title>
      <link>http://arxiv.org/abs/2411.08404v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）的进展有潜力通过整合数值和文本数据来转变金融分析。&lt;h4&gt;目的&lt;/h4&gt;解决多模态信息融合时上下文不足及定性输出效用测量困难的问题，以提高金融预测的效果。&lt;h4&gt;方法&lt;/h4&gt;利用证券公司的日报，创建高质量的上下文信息，将文本关键因素与价格等数值数据结合，形成上下文集。通过动态更新少量示例，使上下文集与查询时间紧密相关，并设计提示来为关键因素打分，将定性见解转化为定量结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，LLMs在市场预测中的表现优于时间序列模型，但仍面临可重复性差和可解释性有限等挑战。&lt;h4&gt;结论&lt;/h4&gt;通过改进上下文信息的整合和定量化处理，LLMs能够在金融预测中提供更优的结果。&lt;h4&gt;总结&lt;/h4&gt;研究展示了LLMs在金融领域的应用潜力，并指出了当前的局限性与未来改进方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Large Language Models (LLMs) have the potential totransform financial analytics by integrating numerical and textual data.However, challenges such as insufficient context when fusing multimodalinformation and the difficulty in measuring the utility of qualitative outputs,which LLMs generate as text, have limited their effectiveness in tasks such asfinancial forecasting. This study addresses these challenges by leveragingdaily reports from securities firms to create high-quality contextualinformation. The reports are segmented into text-based key factors and combinedwith numerical data, such as price information, to form context sets. Bydynamically updating few-shot examples based on the query time, the setsincorporate the latest information, forming a highly relevant set closelyaligned with the query point. Additionally, a crafted prompt is designed toassign scores to the key factors, converting qualitative insights intoquantitative results. The derived scores undergo a scaling process,transforming them into real-world values that are used for prediction. Ourexperiments demonstrate that LLMs outperform time-series models in marketforecasting, though challenges such as imperfect reproducibility and limitedexplainability remain.</description>
      <author>example@mail.com (Hoyoung Lee, Youngsoo Choi, Yuhee Kwon)</author>
      <guid isPermaLink="false">2411.08404v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Ghost-Connect Net: A Generalization-Enhanced Guidance For Sparse Deep Networks Under Distribution Shifts</title>
      <link>http://arxiv.org/abs/2411.09199v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 4 figures, 3 subfigures, 42 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;稀疏深度神经网络在机器人和计算机视觉等实际应用中表现优越，但计算需求的减少限制了其可用性。&lt;h4&gt;目的&lt;/h4&gt;提升深度神经网络的效率，尤其是在分布变化下的适应性。&lt;h4&gt;方法&lt;/h4&gt;引入伴随网络Ghost Connect-Net（GC-Net），监测原始网络中的连接，利用其分布泛化优势。&lt;h4&gt;主要发现&lt;/h4&gt;GC-Net的权重表示原始网络连续层之间的连接测量，经过修剪后将修剪位置映射回原始网络，结合了基于幅度和连接性的修剪方法。&lt;h4&gt;结论&lt;/h4&gt;实验结果显示，混合使用GC-Net指导后层和直接修剪前层的方法在CIFAR-10、Fashion MNIST和Tiny ImageNet等常见基准上取得了良好效果。&lt;h4&gt;总结&lt;/h4&gt;GC-Net的方法为在分布变化下提高泛化能力提供了理论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse deep neural networks (DNNs) excel in real-world applications likerobotics and computer vision, by reducing computational demands that hinderusability. However, recent studies aim to boost DNN efficiency by trimmingredundant neurons or filters based on task relevance, but neglect theiradaptability to distribution shifts. We aim to enhance these existingtechniques by introducing a companion network, Ghost Connect-Net (GC-Net), tomonitor the connections in the original network with distributiongeneralization advantage. GC-Net's weights represent connectivity measurementsbetween consecutive layers of the original network. After pruning GC-Net, thepruned locations are mapped back to the original network as pruned connections,allowing for the combination of magnitude and connectivity-based pruningmethods. Experimental results using common DNN benchmarks, such as CIFAR-10,Fashion MNIST, and Tiny ImageNet show promising results for hybridizing themethod, and using GC-Net guidance for later layers of a network and directpruning on earlier layers. We provide theoretical foundations for GC-Net'sapproach to improving generalization under distribution shifts.</description>
      <author>example@mail.com (Mary Isabelle Wisell, Salimeh Yasaei Sekeh)</author>
      <guid isPermaLink="false">2411.09199v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Optimal Constant Climb Airspeed with Variable Cost Index for All-electric Aircraft</title>
      <link>http://arxiv.org/abs/2411.08156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:2410.01045&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文首次提出了一种在爬升阶段最小化全电动飞机直接运营成本（DOC）的方法。&lt;h4&gt;目的&lt;/h4&gt;引入一个时间变化的成本指数（CI），以优化全电动飞机的爬升性能。&lt;h4&gt;方法&lt;/h4&gt;CI被建模为一个由空中交通管制（ATC）指令的动态参数，确保飞机在爬升过程中保持恒定的空速，同时遵循空中交通法规。&lt;h4&gt;主要发现&lt;/h4&gt;研究探讨了时间变化的CI对全电动飞机最佳空速和爬升时间的影响，并提供了计算最佳爬升空速和爬升持续时间的必要方程。&lt;h4&gt;结论&lt;/h4&gt;通过模拟场景验证了所提方法，建立了爬升空速、爬升时间和能耗的最优值，为未来在先进空中出行的全电动交通工具应用该方法奠定了基础。&lt;h4&gt;总结&lt;/h4&gt;本文的方法论为全电动飞机在爬升阶段的运营提供了新的优化策略，具有实际应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents for the first time an approach to minimize directoperational costs (DOC) for all-electric aircraft during the climb phase,introducing a time-varying cost index (CI). The CI is modeled as a dynamicparameter commanded by Air Traffic Control (ATC), allowing the aircraft tomaintain a constant airspeed throughout the climb, while respecting the airtraffic regulations. This paper also explores the implications of atime-varying CI on the determination of optimal airspeed and climbing time forall-electric aircraft. Additionally, it provides the necessary equations tocalculate both the optimal climb airspeed and climb duration. The proposedmethodology has been validated through a simulated scenario that reflectsactual operational procedures. As a result, optimal values for climb airspeed,climbing time, and energy consumption have been established, paving the way forfuture applications of this methodology to advanced air mobility all-electricvehicles.</description>
      <author>example@mail.com (Lucas Souza e Silva, Luis Rodrigues)</author>
      <guid isPermaLink="false">2411.08156v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>BlueME: Robust Underwater Robot-to-Robot Communication Using Compact Magnetoelectric Antennas</title>
      <link>http://arxiv.org/abs/2411.09241v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;BlueME是一种紧凑型磁电（ME）天线阵列系统，旨在支持水下机器人间的通信。&lt;h4&gt;目的&lt;/h4&gt;设计、开发并实验验证BlueME的性能。&lt;h4&gt;方法&lt;/h4&gt;在自主水面车辆（ASV）和遥控水下车辆（ROV）上部署BlueME，进行开放水域的现场试验。&lt;h4&gt;主要发现&lt;/h4&gt;BlueME在超过200米的距离内保持可靠的信号传输，仅消耗1瓦特的功率。系统在浑浊、障碍物和多径干扰等复杂水下条件下有效运作。&lt;h4&gt;结论&lt;/h4&gt;本研究展示了ME天线在实验室外的首次实用水下部署，并实现了迄今为止最大的VLF ME阵列系统。BlueME在海洋机器人和多机器人合作系统、远程传感器网络中具有显著潜力。&lt;h4&gt;总结&lt;/h4&gt;BlueME的成功实施为水下通信和海洋自动化开辟了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present the design, development, and experimental validation of BlueME, acompact magnetoelectric (ME) antenna array system for underwater robot-to-robotcommunication. BlueME employs ME antennas operating at their natural mechanicalresonance frequency to efficiently transmit and receive very-low-frequency(VLF) electromagnetic signals underwater. To evaluate its performance, wedeployed BlueME on an autonomous surface vehicle (ASV) and a remotely operatedvehicle (ROV) in open-water field trials. Our tests demonstrate that BlueMEmaintains reliable signal transmission at distances beyond 200 meters whileconsuming only 1 watt of power. Field trials show that the system operateseffectively in challenging underwater conditions such as turbidity, obstacles,and multipath interference -- that generally affect acoustics and optics. Ouranalysis also examines the impact of complete submersion on system performanceand identifies key deployment considerations. This work represents the firstpractical underwater deployment of ME antennas outside the laboratory andimplements the largest VLF ME array system to date. BlueME demonstratessignificant potential for marine robotics and automation in multi-robotcooperative systems and remote sensor networks.</description>
      <author>example@mail.com (Mehron Talebi, Sultan Mahmud, Adam Khalifa, Md Jahidul Islam)</author>
      <guid isPermaLink="false">2411.09241v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Impact of Covid-19 on Taxi Industry and Travel Behavior: A Case Study on Chicago, IL</title>
      <link>http://arxiv.org/abs/2411.08168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;COVID-19疫情加剧了全球交通运输的危机，出租车行业受到显著影响。&lt;h4&gt;目的&lt;/h4&gt;研究疫情对出租车行业经济和出行行为的影响。&lt;h4&gt;方法&lt;/h4&gt;利用2014年至2020年在芝加哥的逐次出行数据进行空间分析和可视化。&lt;h4&gt;主要发现&lt;/h4&gt;疫情期间，芝加哥市中心和机场地区的出行次数急剧下降，尽管人们倾向于长途旅行，但出行时间显著减少。&lt;h4&gt;结论&lt;/h4&gt;疫情改变了出租车的热门上下车地点，疫情前主要集中在芝加哥市中心和奥黑尔国际机场，疫情期间则扩展至多个区域。&lt;h4&gt;总结&lt;/h4&gt;疫情对出租车行业产生深远影响，出行模式和热门位置发生了显著变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the debate over the future of transportation continues in the midst of theCOVID-19 pandemic as a deepening global crisis, taxi industry seems to be notspared by the quick and disrupting changes that may arise from the pandemic.The impact is relatively higher in major cities because of the high-densitypopulation and transportation congestion. In this study, we used spatialanalysis and visualization to investigate the impact of the pandemic on theeconomics of the taxi industry and travel behavior using trip-by-trip data fromthe year of 2014 to 2020 in Chicago, IL. Results show that there is a drasticdecline in the trips in the central city and airport areas. During thepandemic, people tended to travel longer distances, but travel times wereconsiderably less because of the significant reduction in traffic volumes.Results also showed that the top twenty most popular pick-up and drop-offlocations only included Chicago Downtown and OHare International Airport beforethe pandemic. However, during the pandemic, the top twenty most popular pick-upand drop-off locations is distributed between the Airport, the Downtown, aswell as many other areas along Chicago Eastside.</description>
      <author>example@mail.com (Naga Sireesha Chinthala, Jenell Lewis, Sravan Vuppalapati, Khiran Kumar Chidambaram Sivaraman, Chinmay Vivek Toley, Huthaifa Ashqar)</author>
      <guid isPermaLink="false">2411.08168v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>FluidML: Fast and Memory Efficient Inference Optimization</title>
      <link>http://arxiv.org/abs/2411.09242v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;边缘设备上的机器学习模型已推动了人形机器人、增强现实眼镜和自动驾驶汽车等众多新应用。&lt;h4&gt;目的&lt;/h4&gt;解决边缘设备上计算资源不足的问题，以应对模型参数不断增加的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出FluidML，一个通用的运行时内存管理和优化框架，能够灵活变换模型执行蓝图，以实现更快和更高效的推理。&lt;h4&gt;主要发现&lt;/h4&gt;FluidML在不同平台上的评估显示，能够将流行语言模型的端到端推理延迟减少最多25.38%，并将峰值内存使用降低最多41.47%。&lt;h4&gt;结论&lt;/h4&gt;FluidML拥有约3万行代码，旨在通用使用，并将作为开源推理运行时优化框架发布给社区。&lt;h4&gt;总结&lt;/h4&gt;FluidML显著优化了边缘设备上的机器学习推理性能，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning models deployed on edge devices have enabled numerousexciting new applications, such as humanoid robots, AR glasses, and autonomousvehicles. However, the computing resources available on these edge devices arenot catching up with the ever-growing number of parameters in these models. Asthe models become bigger and more complicated, the novel yet sophisticatedstructure challenges the inference runtime optimization. We present FluidML, ageneric runtime memory management and optimization framework that can flexiblytransform the model execution blueprint to achieve faster and morememory-efficient inference. Evaluations across different platforms show thatFluidML can consistently reduce the end-to-end inference latency by up to25.38% for popular language models and reduce peak memory usage by up to41.47%, compared to state-of-the-art approaches. FluidML is of ~30K line ofcodes, built for general-purpose usage, and will be released as an open-sourceinference runtime optimization framework to the community.</description>
      <author>example@mail.com (Jinjie Liu, Hang Qiu)</author>
      <guid isPermaLink="false">2411.09242v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>When to Localize? A POMDP Approach</title>
      <link>http://arxiv.org/abs/2411.08281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the 2024 IEEE International Symposium on Safety,
  Security, and Rescue Robotics (SSRR). 6 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人通常通过定位来减少导航误差，并促进后续的高层任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，帮助机器人在定位成本高或效率低时，选择性地进行定位。&lt;h4&gt;方法&lt;/h4&gt;将该方法构建为约束部分可观测马尔可夫决策过程，并使用成本约束POMCP求解器规划机器人的行动。&lt;h4&gt;主要发现&lt;/h4&gt;求解器模拟失败概率，以决定机器人是移动到目标还是进行定位以防止失败。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效减少定位行为，并确保不超过失败的概率。&lt;h4&gt;总结&lt;/h4&gt;本研究为资源受限的机器人在复杂环境中提供了一种优化定位决策的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots often localize to lower navigational errors and facilitate downstream,high-level tasks. However, a robot may want to selectively localize whenlocalization is costly (such as with resource-constrained robots) orinefficient (for example, submersibles that need to surface), especially whennavigating in environments with variable numbers of hazards such as obstaclesand shipping lanes. In this study, we propose a method that helps a robotdetermine ``when to localize'' to 1) minimize such actions and 2) not exceedthe probability of failure (such as surfacing within high-traffic shippinglanes). We formulate our method as a Constrained Partially Observable MarkovDecision Process and use the Cost-Constrained POMCP solver to plan the robot'sactions. The solver simulates failure probabilities to decide if a robot movesto its goal or localizes to prevent failure. We performed numerical experimentswith multiple baselines.</description>
      <author>example@mail.com (Troi Williams, Kasra Torshizi, Pratap Tokekar)</author>
      <guid isPermaLink="false">2411.08281v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Learning Hand State Estimation for a Light Exoskeleton</title>
      <link>http://arxiv.org/abs/2411.09294v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种基于机器学习的手部状态估计器，旨在用于康复，配合轻型外骨骼装置。&lt;h4&gt;目的&lt;/h4&gt;开发一种易于使用且适合家庭和频繁治疗的设备。&lt;h4&gt;方法&lt;/h4&gt;采用监督学习方法，利用前臂的肌肉活动信息和外骨骼的运动数据重建手的开合程度和顺应性。&lt;h4&gt;主要发现&lt;/h4&gt;在使用单一用户的数据进行训练并在同一用户的不同会话中进行测试时，系统表现出良好的预测性能。&lt;h4&gt;结论&lt;/h4&gt;该方法的泛化能力使其在实际康复中具有良好的应用前景。&lt;h4&gt;总结&lt;/h4&gt;通过实验验证了轻型外骨骼设备的有效性，为康复治疗提供了新的技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a machine learning-based estimator of the hand state forrehabilitation purposes, using light exoskeletons. These devices are easy touse and useful for delivering domestic and frequent therapies. We build asupervised approach using information from the muscular activity of the forearmand the motion of the exoskeleton to reconstruct the hand's opening degree andcompliance level. Such information can be used to evaluate the therapy progressand develop adaptive control behaviors. Our approach is validated with a reallight exoskeleton. The experiments demonstrate good predictive performance ofour approach when trained on data coming from a single user and tested on thesame user, even across different sessions. This generalization capability makesour system promising for practical use in real rehabilitation.</description>
      <author>example@mail.com (Gabriele Abbate, Alessandro Giusti, Luca Randazzo, Antonio Paolillo)</author>
      <guid isPermaLink="false">2411.09294v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Recovering head and flux distributions at the sediment-water interface for arbitrary, transient bedforms by inversion of photographic time series</title>
      <link>http://arxiv.org/abs/2411.08788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有研究通常假设简化的河床形状和正弦状水头分布，或依赖于昂贵的计算流体动力学模拟，缺乏实验数据来制定水力头和流量分布的预测规则。&lt;h4&gt;目的&lt;/h4&gt;解决在实验室中难以确定自然床形态引起的水力头和流量分布的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种非侵入性技术，通过对染料前沿传播的照片时间序列进行规则化反演，适用于任意形状和一般瞬态的床形。&lt;h4&gt;主要发现&lt;/h4&gt;分析了在不同流动状态下进行的三次台阶规模的水槽实验，提供了新的数字化床形状、相应的水头分布和染料前沿的数据集。&lt;h4&gt;结论&lt;/h4&gt;这是首次针对自然形成的沙床形态整理的此类数据集。&lt;h4&gt;总结&lt;/h4&gt;本研究为水力头和流量分布的预测提供了新的实验数据和方法，填补了现有研究的空白。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing works that predict bedform-induced hyporheic exchange flux (HEF)typically either assume a simplified streambed shape and correspondingsinusoidal head distribution or rely on costly computational fluid dynamicssimulations. Experimental data have been lacking for the formulation of apriori prediction rules for hydraulic head and flux distributions induced byspatiotemporally heterogeneous natural bedforms because it has not previouslybeen feasible to determine these in the laboratory. We address this problem,presenting a noninvasive technique for regularized inversion of photographictime series of dye front propagation in the hyporheic zone, compatible witharbitrarily-shaped, generally transient bedforms. We employ the technique toanalyze three bench-scale flume experiments performed under different flowregimes, presenting a new data set of digitized bed profiles, correspondinghead distributions, and dye fronts. To our knowledge, this is the first suchdata set collated for naturally-formed sand bedforms.</description>
      <author>example@mail.com (Yoni Teitelbaum, Shai Arnon, Aaron Packman, Scott K. Hansen)</author>
      <guid isPermaLink="false">2411.08788v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>EDM: An Ultra-Low Latency Ethernet Fabric for Memory Disaggregation</title>
      <link>http://arxiv.org/abs/2411.08300v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Full version of paper accepted to ASPLOS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在数据中心实现以太网内存分离面临低远程内存访问延迟的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出EDM，以克服远程内存访问的延迟问题。&lt;h4&gt;方法&lt;/h4&gt;EDM在以太网的物理层实现整个网络协议栈，并在物理层内实现集中快速的内存流量调度器。&lt;h4&gt;主要发现&lt;/h4&gt;在未负载的网络中，EDM的远程内存访问延迟约为300纳秒，显著低于现有的以太网解决方案，并且在高网络负载情况下延迟仍在1.3倍之内。&lt;h4&gt;结论&lt;/h4&gt;EDM的设计有效降低了远程内存访问的延迟，提高了带宽利用率。&lt;h4&gt;总结&lt;/h4&gt;EDM通过在物理层实施网络协议和流量调度，显著改善了以太网内存分离的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving low remote memory access latency remains the biggest challenge inrealizing memory disaggregation over Ethernet inside the datacenter. We presentEDM that tries to overcome this challenge using two key ideas. First, while theexisting network protocols for remote memory access over Ethernet, such asTCP/IP and RDMA, are implemented on top of Ethernet's MAC layer, EDM takes arather radical approach of implementing the entire network protocol stack forremote memory access within the Physical layer (PHY) of the Ethernet. Thisovercomes fundamental latency and bandwidth overheads imposed by the MAC layer,especially for small memory messages. Second, EDM implements a centralized,fast, in-network traffic scheduler for memory traffic within the PHY of theEthernet switch. Inspired by the classic Parallel Iterative Matching (PIM)algorithm, the scheduler dynamically reserves bandwidth between compute andmemory nodes by creating virtual circuits in the switch's PHY, thus eliminatingthe queuing delay and layer 2 packet processing delay at the switch for memorytraffic, with high bandwidth utilization. Our FPGA testbed shows that EDM'snetwork fabric incurs a latency of only $\sim$300 ns for remote memory accessin an unloaded network, which is an order of magnitude lower thanstate-of-the-art Ethernet-based solutions such as RoCEv2 and comparable to theemerging PCIe-based solutions such as CXL. Larger-scale network simulationsshow that even at high network loads, EDM's latency is within 1.3$\times$ itsunloaded latency.</description>
      <author>example@mail.com (Weigao Su, Vishal Shrivastav)</author>
      <guid isPermaLink="false">2411.08300v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Hearing the Robot's Mind: Sonification for Explicit Feedback in Human-Robot Interaction</title>
      <link>http://arxiv.org/abs/2411.09299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社交机器人不仅需要理解人类的意图，还要有效地传达自身的意图或内部状态。&lt;h4&gt;目的&lt;/h4&gt;探索使用声显化技术提供明确的听觉反馈，以增强人机交互中的相互理解。&lt;h4&gt;方法&lt;/h4&gt;引入一种新颖的声显化方法，传达机器人的内部状态，与其对附近个体及其互动意图的感知相关。通过两阶段用户研究进行评估，包括26名参与者的在线视频调查和10名参与者的现场实验。&lt;h4&gt;主要发现&lt;/h4&gt;声显化提高了机器人的表达能力和沟通效果，但听觉反馈的设计需要改进以增强用户体验。参与者认为听觉提示有用，但描述声音为无趣和不愉快。&lt;h4&gt;结论&lt;/h4&gt;精心设计的听觉反馈在开发更有效和吸引人的人机交互系统中至关重要。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了声显化在提升社交机器人与用户之间理解的重要性，呼吁对听觉反馈进行进一步优化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social robots are required not only to understand human intentions but alsoto effectively communicate their intentions or own internal states to users.This study explores the use of sonification to provide explicit auditoryfeedback, enhancing mutual understanding in HRI. We introduce a novelsonification approach that conveys the robot's internal state, linked to itsperception of nearby individuals and their interaction intentions. The approachis evaluated through a two-fold user study: an online video-based survey with$26$ participants and live experiments with $10$ participants. Results indicatethat while sonification improves the robot's expressivity and communicationeffectiveness, the design of the auditory feedback needs refinement to enhanceuser experience. Participants found the auditory cues useful but described thesounds as uninteresting and unpleasant. These findings underscore theimportance of carefully designed auditory feedback in developing more effectiveand engaging HRI systems.</description>
      <author>example@mail.com (Simone Arreghini, Antonio Paolillo, Gabriele Abbate, Alessandro Giusti)</author>
      <guid isPermaLink="false">2411.09299v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:53 +0800</pubDate>
    </item>
    <item>
      <title>Locally Private Sampling with Public Data</title>
      <link>http://arxiv.org/abs/2411.08791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;局部差分隐私（LDP）在保护用户数据的机器学习中越来越受到重视，尤其是在与不可信的聚合器共享数据时。&lt;h4&gt;目的&lt;/h4&gt;解决现有LDP方法假设用户仅拥有单一数据记录的局限性，允许用户利用其私有数据集和公共数据集。&lt;h4&gt;方法&lt;/h4&gt;提出一个局部私有采样框架，假设每个用户有两个分布$p$和$q$，分别代表私有数据集和公共数据集。将生成私有样本的目标框架为一个最小极大优化问题，并使用$f$-散度作为效用度量。&lt;h4&gt;主要发现&lt;/h4&gt;全面刻画了在离散分布条件下，针对一般$f$-散度的最小极大最优机制，并证明该机制在所有$f$-散度上都是通用的。&lt;h4&gt;结论&lt;/h4&gt;实验验证了我们提出的最小极大最优采样器相较于现有最先进的局部私有采样器的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究扩展了LDP的应用，允许用户在保护隐私的同时利用更多的数据资源，提高了数据共享的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Local differential privacy (LDP) is increasingly employed inprivacy-preserving machine learning to protect user data before sharing it withan untrusted aggregator. Most LDP methods assume that users possess only asingle data record, which is a significant limitation since users often gatherextensive datasets (e.g., images, text, time-series data) and frequently haveaccess to public datasets. To address this limitation, we propose a locallyprivate sampling framework that leverages both the private and public datasetsof each user. Specifically, we assume each user has two distributions: $p$ and$q$ that represent their private dataset and the public dataset, respectively.The objective is to design a mechanism that generates a private sampleapproximating $p$ while simultaneously preserving $q$. We frame this objectiveas a minimax optimization problem using $f$-divergence as the utility measure.We fully characterize the minimax optimal mechanisms for general$f$-divergences provided that $p$ and $q$ are discrete distributions.Remarkably, we demonstrate that this optimal mechanism is universal across all$f$-divergences. Experiments validate the effectiveness of our minimax optimalsampler compared to the state-of-the-art locally private sampler.</description>
      <author>example@mail.com (Behnoosh Zamanlooy, Mario Diaz, Shahab Asoodeh)</author>
      <guid isPermaLink="false">2411.08791v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>D4W: Dependable Data-Driven Dynamics for Wheeled Robots</title>
      <link>http://arxiv.org/abs/2411.09360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The Fifth International Conference on Distributed Artificial
  Intelligence&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;轮式机器人在制造、物流和服务行业中得到了广泛关注。&lt;h4&gt;目的&lt;/h4&gt;提出D4W框架，以解决轮式机器人动态建模的困难，提升控制算法的开发和测试效率。&lt;h4&gt;方法&lt;/h4&gt;D4W是一个模拟框架，利用数据驱动方法，通过真实传感器数据学习准确的机器人动态模型。&lt;h4&gt;主要发现&lt;/h4&gt;D4W的学习动态模型能够捕捉复杂的机器人行为和与环境的交互，超越了仅适用于简化场景的分析方法。&lt;h4&gt;结论&lt;/h4&gt;D4W在模拟精度上优于传统方法，允许快速迭代轮式机器人算法，减少或无需现实中的精细调试。&lt;h4&gt;总结&lt;/h4&gt;通过与现有模拟器和控制器的集成，验证了D4W框架的可用性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wheeled robots have gained significant attention due to their wide range ofapplications in manufacturing, logistics, and service industries. However, dueto the difficulty of building a highly accurate dynamics model for wheeledrobots, developing and testing control algorithms for them remains challengingand time-consuming, requiring extensive physical experimentation. To addressthis problem, we propose D4W, i.e., Dependable Data-Driven Dynamics for WheeledRobots, a simulation framework incorporating data-driven methods to acceleratethe development and evaluation of algorithms for wheeled robots. The keycontribution of D4W is a solution that utilizes real-world sensor data to learnaccurate models of robot dynamics. The learned dynamics can capture complexrobot behaviors and interactions with the environment throughout simulations,surpassing the limitations of analytical methods, which only work in simplifiedscenarios. Experimental results show that D4W achieves the best simulationaccuracy compared to traditional approaches, allowing for rapid iteration ofwheel robot algorithms with less or no need for fine-tuning in reality. Wefurther verify the usability and practicality of the proposed framework throughintegration with existing simulators and controllers.</description>
      <author>example@mail.com (Yunfeng Lin, Minghuan Liu, Yong Yu)</author>
      <guid isPermaLink="false">2411.09360v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Future-Proofing IoT: Unleashing the Power of AWS Greengrass in Propelling Smart Devices to New Heights</title>
      <link>http://arxiv.org/abs/2411.08914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;边缘计算的出现将彻底改变云计算在各个领域的应用，包括农业和健康等。&lt;h4&gt;目的&lt;/h4&gt;探讨AWS Greengrass在不同领域的影响，分析其所带来的挑战和机遇。&lt;h4&gt;方法&lt;/h4&gt;研究AWS Greengrass如何改善物联网设备之间的数据共享，并评估其在智能家居、农业、健康、车辆云、智慧城市和工业自动化等方面的应用。&lt;h4&gt;主要发现&lt;/h4&gt;AWS Greengrass在提高处理速度、降低延迟和优化带宽使用方面具有显著优势。&lt;h4&gt;结论&lt;/h4&gt;虽然边缘计算带来了诸多好处，但也提出了新的测试和质量保证挑战。&lt;h4&gt;总结&lt;/h4&gt;本文探讨了边缘和云计算在提升效率的同时，如何应对相关的质量和测试问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of edge computing is set to revolutionize cloud computing invarious sectors, including Agriculture, Health, and more. AWS Greengrass CoreDevice plays a pivotal role in this transformative process by bridgingconnections between IoT devices by improving data sharing between them,unlocking new possibilities in Smart Home, Agriculture, Health, VehicularCloud, Smart City, Industry Automation, and beyond. However, these advancementsalso introduce novel challenges for testing and quality assurance in cloudcomputing. This paper explores the impact of AWS Greengrass in differentfields, addressing challenges, opportunities, and potential benefits of edgeand cloud computing in terms of processing speed, latency, and bandwidth usage.</description>
      <author>example@mail.com (Sahasra Kokkula, Ankit Vatsa, Savaridassan P)</author>
      <guid isPermaLink="false">2411.08914v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Confidence intervals for adaptive trial designs I: A methodological review</title>
      <link>http://arxiv.org/abs/2411.08495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在进行适应性临床试验时，监管指导指出在解释构建的置信区间（CIs）时需谨慎。&lt;h4&gt;目的&lt;/h4&gt;探讨适应性试验中置信区间的构建方法，并提出统计师的实施指南。&lt;h4&gt;方法&lt;/h4&gt;全面回顾适应性设计的置信区间构建方法，并通过文献综述对现有方法进行分类和评估。&lt;h4&gt;主要发现&lt;/h4&gt;不同的适应性设计方法在实现名义覆盖率和与假设检验决策一致性等特征方面的表现各异。&lt;h4&gt;结论&lt;/h4&gt;提出了一套评估置信区间特征的交通信号系统，以帮助选择合适的方法。&lt;h4&gt;总结&lt;/h4&gt;本论文是两部分系列中的第一部分，重点讨论适应性试验的置信区间构建方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Regulatory guidance notes the need for caution in the interpretation ofconfidence intervals (CIs) constructed during and after an adaptive clinicaltrial. Conventional CIs of the treatment effects are prone to undercoverage (aswell as other undesirable properties) in many adaptive designs, because they donot take into account the potential and realised trial adaptations. This paperis the first in a two-part series that explores CIs for adaptive trials. Itprovides a comprehensive review of the methods to construct CIs for adaptivedesigns, while the second paper illustrates how to implement these in practiceand proposes a set of guidelines for trial statisticians. We describe severalclasses of techniques for constructing CIs for adaptive clinical trials, beforeproviding a systematic literature review of available methods, classified bythe type of adaptive design. As part of this, we assess, through a proposedtraffic light system, which of several desirable features of CIs (such asachieving nominal coverage and consistency with the hypothesis test decision)each of these methods holds.</description>
      <author>example@mail.com (David S. Robertson, Thomas Burnett, Babak Choodari-Oskooei, Munya Dimairo, Michael Grayling, Philip Pallmann, Thomas Jaki)</author>
      <guid isPermaLink="false">2411.08495v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Robot Tasks with Fuzzy Time Requirements from Natural Language Instructions</title>
      <link>http://arxiv.org/abs/2411.09436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 8 figures, to be published in 2024 IEEE International
  Conference on Robotic Computing (IRC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自然语言使机器人编程对所有人都更易接近，但自然语言的模糊性给传统机器人系统带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;研究具有模糊时间要求的指令，例如“几分钟后开始”。&lt;h4&gt;方法&lt;/h4&gt;引入模糊技能，定义机器人执行的满意度函数，以表示模糊的执行时间要求，并进行用户研究以泛化这些函数。&lt;h4&gt;主要发现&lt;/h4&gt;参与者对不同执行时间的指令满意度进行了评估，结果表明梯形函数最能近似用户的满意度，并且用户对远期执行的宽容度更高。&lt;h4&gt;结论&lt;/h4&gt;模糊技能和满意度函数可以优化机器人调度，使其更好地满足用户的模糊时间要求。&lt;h4&gt;总结&lt;/h4&gt;本研究为机器人编程中的时间模糊性提供了新的解决方案，有助于提升用户体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Natural language allows robot programming to be accessible to everyone.However, the inherent fuzziness in natural language poses challenges forinflexible, traditional robot systems. We focus on instructions with fuzzy timerequirements (e.g., "start in a few minutes"). Building on previous roboticsresearch, we introduce fuzzy skills. These define an execution by the robotwith so-called satisfaction functions representing vague execution timerequirements. Such functions express a user's satisfaction over potentialstarting times for skill execution. When the robot handles multiple fuzzyskills, the satisfaction function provides a temporal tolerance window forexecution, thus, enabling optimal scheduling based on satisfaction. Wegeneralized such functions based on individual user expectations with a userstudy. The participants rated their satisfaction with an instruction'sexecution at various times. Our investigations reveal that trapezoidalfunctions best approximate the users' satisfaction. Additionally, the resultssuggest that users are more lenient if the execution is specified further intothe future.</description>
      <author>example@mail.com (Sascha Sucker, Michael Neubauer, Dominik Henrich)</author>
      <guid isPermaLink="false">2411.09436v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Towards Practical Deep Schedulers for Allocating Cellular Radio Resources</title>
      <link>http://arxiv.org/abs/2411.08529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前无线网络功能的调度方法尚未出现符合3GPP标准的有效调度器，尤其是在5G及以后版本中需要实现公平的用户吞吐量和较低的计算复杂度。&lt;h4&gt;目的&lt;/h4&gt;开发一种深度调度器，以解决无线网络中的调度问题，并提高调度算法的有效性和实用性。&lt;h4&gt;方法&lt;/h4&gt;对已有的深度调度器进行批判性分析，增强现有的深度强化学习算法，特别是提出新的训练技术用于Proximal Policy Optimization (PPO)和Distributional Soft Actor-Critic Discrete (DSACD)算法。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的算法在性能上优于其他测试的变体，且在保持最小的actor网络复杂度的同时，适用于实时计算环境。&lt;h4&gt;结论&lt;/h4&gt;预训练的深度调度器在现实和符合标准的5G系统级仿真中表现优于启发式对手，展示了强大的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了深度强化学习算法在无线网络调度中的潜力，为5G及未来网络提供了更高效的调度解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning methods are often suggested to address wireless networkfunctions, such as radio packet scheduling. However, a feasible 3GPP-compliantscheduler capable of delivering fair throughput across users, while keeping alow computational complexity for 5G and beyond is still missing. To addressthis, we first take a critical look at previous deep scheduler efforts.Secondly, we enhance State-of-the-Art (SoTA) deep Reinforcement Learning (RL)algorithms and adapt them to train our deep scheduler. In particular, wepropose novel training techniques for Proximal Policy Optimization (PPO) and anew Distributional Soft Actor-Critic Discrete (DSACD) algorithm, whichoutperformed other tested variants. These improvements were achieved whilemaintaining minimal actor network complexity, making them suitable forreal-time computing environments. Additionally, the entropy learning in SACDwas fine-tuned to accommodate resource allocation action spaces of varyingsizes. Our proposed deep schedulers exhibited strong generalization acrossdifferent bandwidths, number of MU-MIMO layers, and traffic models. Ultimately,we show that our pre-trained deep schedulers outperform their heuristic rivalsin realistic and standard-compliant 5G system-level simulations.</description>
      <author>example@mail.com (Petteri Kela, Bryan Liu, Alvaro Valcarce)</author>
      <guid isPermaLink="false">2411.08529v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Transformer-based Time-Series Biomarker Discovery for COPD Diagnosis</title>
      <link>http://arxiv.org/abs/2411.09027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as a workshop paper to NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;慢性阻塞性肺病（COPD）是一种不可逆且进展性疾病，具有高度的遗传性。&lt;h4&gt;目的&lt;/h4&gt;展示使用高维原始肺活量图提供比总结指标更丰富的信号。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于变换器的深度学习技术，处理原始肺活量图值和人口统计信息，以预测与COPD相关的临床终点。&lt;h4&gt;主要发现&lt;/h4&gt;该方法比以往的研究表现更好，同时计算效率更高。&lt;h4&gt;结论&lt;/h4&gt;通过模型学习的权重，使框架更具可解释性，识别对模型预测重要的肺活量图部分。&lt;h4&gt;临床意义&lt;/h4&gt;与经过认证的肺病专家合作，提供对肺活量图不同方面的临床见解，模型的解释与医学知识相符。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，利用深度学习技术分析原始肺活量图可以改善COPD的预测和解释能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Chronic Obstructive Pulmonary Disorder (COPD) is an irreversible andprogressive disease which is highly heritable. Clinically, COPD is definedusing the summary measures derived from a spirometry test but these are notalways adequate. Here we show that using the high-dimensional raw spirogram canprovide a richer signal compared to just using the summary measures. We designa transformer-based deep learning technique to process the raw spirogram valuesalong with demographic information and predict clinically-relevant endpointsrelated to COPD. Our method is able to perform better than prior works whilebeing more computationally efficient. Using the weights learned by the model,we make the framework more interpretable by identifying parts of the spirogramthat are important for the model predictions. Pairing up with a board-certifiedpulmonologist, we also provide clinical insights into the different aspects ofthe spirogram and show that the explanations obtained from the model align withunderlying medical knowledge.</description>
      <author>example@mail.com (Soham Gadgil, Joshua Galanter, Mohammadreza Negahdar)</author>
      <guid isPermaLink="false">2411.09027v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>A ROS~2-based Navigation and Simulation Stack for the Robotino</title>
      <link>http://arxiv.org/abs/2411.09441v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at RoboCup 2024: Robot World Cup XXVII, Springer-Verlag,
  2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Robotino是Festo Didactic开发的多功能教育和研究平台，专注于移动机器人任务。&lt;h4&gt;目的&lt;/h4&gt;开发一个支持Robotino平台的ROS2集成，提供定位和导航的预配置设置。&lt;h4&gt;方法&lt;/h4&gt;创建一个Webots仿真环境，并使用LIDAR传感器扩展Robotino平台，利用Nav2套件中的现有ROS包进行定位和导航。&lt;h4&gt;主要发现&lt;/h4&gt;通过与实验室中三台Robotino在物流环境中的真实实验进行比较，验证了仿真设置的有效性。&lt;h4&gt;结论&lt;/h4&gt;结果表明，使用ROS2和Nav2进行Robotino平台的导航任务是可行的，仿真与现实世界性能之间具有高度一致性。&lt;h4&gt;总结&lt;/h4&gt;研究表明，开发的ROS2集成和仿真环境为Robotino在移动机器人任务中的应用提供了有效支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Robotino, developed by Festo Didactic, serves as a versatile platform ineducation and research for mobile robotics tasks. However, there currently isno ROS2 integration for the Robotino available. In this paper, we describe ourwork on a Webots simulation environment for a Robotino platform extended byLIDAR sensors. A ROS2 integration and a pre-configured setup for localizationand navigation using existing ROS packages from the Nav2 suite are provided. Wevalidate our setup by comparing simulations with real-world experimentsconducted by three Robotinos in a logistics environment in our lab.Additionally, we tested the setup using a ROS 2 hardware driver for theRobotino developed by team GRIPS of the RoboCup Logistics League. The resultsdemonstrate the feasibility of using ROS2 and Nav2 for navigation tasks on theRobotino platform showing great consistency between simulation and real-worldperformance.</description>
      <author>example@mail.com (Saurabh Borse, Tarik Viehmann, Alexander Ferrein, Gerhard Lakemeyer)</author>
      <guid isPermaLink="false">2411.09441v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Learning-Guided Fuzzing for Testing Stateful SDN Controllers</title>
      <link>http://arxiv.org/abs/2411.08626v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;软件定义网络（SDN）的控制器是集中式软件组件，负责实现动态流量工程和网络虚拟化等高级网络功能，但这些功能增加了控制器的复杂性，使得彻底测试变得尤为重要。&lt;h4&gt;目的&lt;/h4&gt;提出SeqFuzzSDN，一种学习引导的模糊测试方法，用于测试状态驱动的SDN控制器。&lt;h4&gt;方法&lt;/h4&gt;SeqFuzzSDN旨在高效探索待测SDN控制器的状态空间，生成有效且多样化的测试（即控制消息序列）以发现故障，并推断准确的故障诱导模型，描述导致故障的消息序列。&lt;h4&gt;主要发现&lt;/h4&gt;与三种先进的模糊测试方法相比，SeqFuzzSDN在相同的时间预算内生成了更多多样化的消息序列，并产生了更准确的故障诱导模型，在灵敏度方面显著优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;SeqFuzzSDN有效提高了状态驱动SDN控制器的测试效率和准确性，是一种具有良好应用前景的测试工具。&lt;h4&gt;总结&lt;/h4&gt;SeqFuzzSDN为状态驱动的SDN控制器测试提供了一种新方法，显著提升了故障发现和故障模型推断的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controllers for software-defined networks (SDNs) are centralised softwarecomponents that enable advanced network functionalities, such as dynamictraffic engineering and network virtualisation. However, these functionalitiesincrease the complexity of SDN controllers, making thorough testing crucial.SDN controllers are stateful, interacting with multiple network devices throughsequences of control messages. Identifying stateful failures in an SDNcontroller is challenging due to the infinite possible sequences of controlmessages, which result in an unbounded number of stateful interactions betweenthe controller and network devices. In this article, we propose SeqFuzzSDN, alearning-guided fuzzing method for testing stateful SDN controllers. SeqFuzzSDNaims to (1) efficiently explore the state space of the SDN controller undertest, (2) generate effective and diverse tests (i.e., control messagesequences) to uncover failures, and (3) infer accurate failure-inducing modelsthat characterise the message sequences leading to failures. In addition, wecompare SeqFuzzSDN with three extensions of state-of-the-art (SOTA) methods forfuzzing SDNs. Our findings show that, compared to the extended SOTA methods,SeqFuzzSDN (1) generates more diverse message sequences that lead to failureswithin the same time budget, and (2) produces more accurate failure-inducingmodels, significantly outperforming the other extended SOTA methods in terms ofsensitivity.</description>
      <author>example@mail.com (Raphaël Ollando, Seung Yeob Shin, Lionel C. Briand)</author>
      <guid isPermaLink="false">2411.08626v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>How to quantify interaction strengths? A critical rethinking of the interaction Jacobian and evaluation methods for non-parametric inference in time series analysis</title>
      <link>http://arxiv.org/abs/2411.09030v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 pages, 5 figures and 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;量化动态系统中状态变量之间的相互作用强度对于理解生态网络至关重要。&lt;h4&gt;目的&lt;/h4&gt;重新引入相互作用雅可比矩阵，以解决生物学解释和数值实现中的问题。&lt;h4&gt;方法&lt;/h4&gt;采用经验动态建模方法中的多变量S-map，从时间序列数据推断相互作用雅可比矩阵，并使用微分商重新定义它。&lt;h4&gt;主要发现&lt;/h4&gt;{'问题一': '相互作用雅可比矩阵与其生物学含义之间的不匹配，使得比较种间和种内相互作用变得复杂。', '问题二': '由给定参数模型推导的参数雅可比矩阵未能充分实现相互作用雅可比矩阵，尤其是使用常微分方程时。'}&lt;h4&gt;结论&lt;/h4&gt;{'解决方案一': '通过将相互作用雅可比矩阵的对角元素减去1，解决种间与种内相互作用强度的可比性问题。', '解决方案二': '引入替代参数雅可比矩阵和累积相互作用强度（CIS），提供更严格的基准来评估S-map方法。'}&lt;h4&gt;总结&lt;/h4&gt;这些解决方案为生态时间序列分析中的非参数方法开发提供了更清晰的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantifying interaction strengths between state variables in dynamicalsystems is essential for understanding ecological networks. Within theempirical dynamic modeling approach, multivariate S-map infers the interactionJacobian from time series data without assuming specific dynamical models. Thisapproach enables the non-parametric statistical inference of interspecificinteractions through state space reconstruction. However, deviations in thebiological interpretation and numerical implementation of the interactionJacobian from its mathematical definition pose challenges. We mathematicallyreintroduce the interaction Jacobian using differential quotients, uncoveringtwo problems: (1) the mismatch between the interaction Jacobian and itsbiological meaning complicates comparisons between interspecific andintraspecific interactions; (2) the interaction Jacobian is not fullyimplemented in the parametric Jacobian numerically derived from givenparametric models, especially using ordinary differential equations. As aresult, model-based evaluations of S-map methods become inappropriate. Toaddress these problems, (1) we propose adjusting the diagonal elements of theinteraction Jacobian by subtracting 1 to resolve the comparability problembetween inter- and intraspecific interaction strengths. Simulations ofpopulation dynamics showed that this adjustment prevents overestimation ofintraspecific interaction strengths. (2) We introduce an alternative parametricJacobian and then cumulative interaction strength (CIS), providing a morerigorous benchmark for evaluating S-map methods. Furthermore, we demonstratedthat the numerical gap between CIS and the existing parametric Jacobian issubstantial in realistic scenarios, suggesting CIS as preferred benchmark.These solutions offer a clearer framework for developing non-parametricapproaches in ecological time series analysis.</description>
      <author>example@mail.com (Takeshi Miki, Chun-Wei Chang, Po-Ju Ke, Arndt Telschow, Cheng-Han Tsai, Masayuki Ushio, Chih-hao Hsieh)</author>
      <guid isPermaLink="false">2411.09030v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>DiffRoad: Realistic and Diverse Road Scenario Generation for Autonomous Vehicle Testing</title>
      <link>http://arxiv.org/abs/2411.09451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成真实且多样化的道路场景对自动驾驶车辆的测试和验证至关重要，但由于现实道路环境的复杂性和变异性，创造真实且多样的场景具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出DiffRoad，一种新型扩散模型，旨在生成可控且高保真的3D道路场景。&lt;h4&gt;方法&lt;/h4&gt;DiffRoad利用扩散模型的生成能力，通过逆去噪过程从白噪声合成道路布局，保持现实世界的空间特征；设计Road-UNet架构，以优化主干和跳跃连接之间的平衡，实现高真实感的场景生成；引入道路场景评估模块，使用道路连续性和合理性两个关键指标筛选合适的场景。&lt;h4&gt;主要发现&lt;/h4&gt;在多个真实世界数据集上的实验结果显示，DiffRoad能够生成真实且平滑的道路结构，同时维持原始分布。&lt;h4&gt;结论&lt;/h4&gt;生成的场景可以完全自动化为OpenDRIVE格式，促进广泛的自动驾驶车辆模拟测试，DiffRoad为大规模自动驾驶车辆测试提供了丰富多样的场景库，并为未来更适合自动驾驶车辆的基础设施设计提供了有价值的见解。&lt;h4&gt;总结&lt;/h4&gt;DiffRoad模型展示了在自动驾驶测试中生成高质量道路场景的潜力，并为相关领域的研究和实践提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating realistic and diverse road scenarios is essential for autonomousvehicle testing and validation. Nevertheless, owing to the complexity andvariability of real-world road environments, creating authentic and variedscenarios for intelligent driving testing is challenging. In this paper, wepropose DiffRoad, a novel diffusion model designed to produce controllable andhigh-fidelity 3D road scenarios. DiffRoad leverages the generative capabilitiesof diffusion models to synthesize road layouts from white noise through aninverse denoising process, preserving real-world spatial features. To enhancethe quality of generated scenarios, we design the Road-UNet architecture,optimizing the balance between backbone and skip connections for high-realismscenario generation. Furthermore, we introduce a road scenario evaluationmodule that screens adequate and reasonable scenarios for intelligent drivingtesting using two critical metrics: road continuity and road reasonableness.Experimental results on multiple real-world datasets demonstrate DiffRoad'sability to generate realistic and smooth road structures while maintaining theoriginal distribution. Additionally, the generated scenarios can be fullyautomated into the OpenDRIVE format, facilitating generalized autonomousvehicle simulation testing. DiffRoad provides a rich and diverse scenariolibrary for large-scale autonomous vehicle testing and offers valuable insightsfor future infrastructure designs that are better suited for autonomousvehicles.</description>
      <author>example@mail.com (Junjie Zhou, Lin Wang, Qiang Meng, Xiaofan Wang)</author>
      <guid isPermaLink="false">2411.09451v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Logic-based Knowledge Awareness for Autonomous Agents in Continuous Spaces</title>
      <link>http://arxiv.org/abs/2411.08754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文旨在为自主智能体的控制器设计方法提供一个基于知识意识的步骤，以改善决策能力。&lt;h4&gt;目的&lt;/h4&gt;创建一个信息的有组织的存储库（知识库），以便自主智能体访问并转化为时间规范。&lt;h4&gt;方法&lt;/h4&gt;采用基于抽象的控制器设计（ABCD）方法，开发一个具有正式保证的控制器，满足任务特定目标和知识库规范的结合。&lt;h4&gt;主要发现&lt;/h4&gt;与传统的离线ABCD方法不同，我们的方法在知识库的规范变化时动态更新控制器。&lt;h4&gt;结论&lt;/h4&gt;通过验证三维非线性汽车模型在城市道路场景中的导航，结果显示该方法有效引导自主智能体达到目标，同时遵循知识库和任务特定目标。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了一种新颖的控制器设计方法，能够在动态环境中有效地支持自主决策。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a step towards a formal controller design method forautonomous agents based on knowledge awareness to improve decision-making. Ourapproach is to first create an organized repository of information (a knowledgebase) for autonomous agents which can be accessed and then translated intotemporal specifications. Secondly, to develop a controller with formalguarantees that meets a combination of mission-specific objective and thespecification from the knowledge base, we utilize an abstraction-basedcontroller design (ABCD) approach, capable of managing both nonlinear dynamicsand temporal requirements. Unlike the conventional offline ABCD approach, ourmethod dynamically updates the controller whenever the knowledge base promptschanges in the specifications. A three-dimensional nonlinear car modelnavigating an urban road scenario with traffic signs and obstacles isconsidered for validation. Results show the effectiveness of the method inguiding the autonomous agents to the target while complying with the knowledgebase and the mission-specific objective.</description>
      <author>example@mail.com (Arabinda Ghosh, Mahmoud Salamati, Sadegh Soudjani)</author>
      <guid isPermaLink="false">2411.08754v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Information Need in Metaverse Recordings -- A Field Study</title>
      <link>http://arxiv.org/abs/2411.09053v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 3 Figures, 8 Tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Metaverse Recordings (MVRs) 是多媒体信息检索（MMIR）领域中新兴且未充分探索的媒介类型。&lt;h4&gt;目的&lt;/h4&gt;了解用户在MVR检索中的信息需求和搜索行为。&lt;h4&gt;方法&lt;/h4&gt;通过进行并分析专家访谈，识别应用场景，突出在元宇宙中检索多媒体内容的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;确认了MVR的现有应用场景，并强调了捕获图形渲染过程及相关输入输出设备的时间序列数据的重要性。&lt;h4&gt;结论&lt;/h4&gt;为开发针对MVR的检索系统奠定基础，定义了使用案例、用户特征和MVR检索系统的具体需求。&lt;h4&gt;未来研究方向&lt;/h4&gt;本研究为理解MVR检索中的信息搜索行为提供了更好的视角，并为该领域的未来研究和系统设计铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;本论文的发现有助于更深入理解MVR检索中的用户行为，并推动相关系统的开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Metaverse Recordings (MVRs) represent an emerging and underexplored mediatype within the field of Multimedia Information Retrieval (MMIR). This paperpresents findings from a field study aimed at understanding the usersinformation needs and search behaviors specific to MVR retrieval. By conductingand analyzing expert interviews, the study identifies application scenarios andhighlights challenges in retrieving multimedia content from the metaverse. Theresults reveal existing application scenarios of MVRs and confirm the relevanceof capturing time-series data from the graphical rendering process and relatedinput-output devices, which are also highly relevant to user needs.Furthermore, the study provides a foundation for developing retrieval systemstailored to MVRs by defining use cases, user stereotypes, and specificrequirements for MVR Retrieval systems. The findings contribute to a betterunderstanding of information search behaviors in MVR Retrieval and pave the wayfor future research and system design in this field.</description>
      <author>example@mail.com (Patrick Steinert, Jan Mischkies, Stefan Wagenpfeil, Ingo Frommholz, Matthias L. Hemmje)</author>
      <guid isPermaLink="false">2411.09053v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>DEIO: Deep Event Inertial Odometry</title>
      <link>http://arxiv.org/abs/2411.03928v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;事件相机是一种受生物启发的运动激活传感器，能够在运动模糊和高动态范围等复杂情况中表现出色。&lt;h4&gt;目的&lt;/h4&gt;提升事件基础的同时定位与地图构建(SLAM)方法在实际应用中的性能，特别是在大规模、低纹理或复杂场景中的适用性。&lt;h4&gt;方法&lt;/h4&gt;提出DEIO，这是首个将学习基础方法与传统非线性图优化相结合的单目深度事件惯性测距框架，整合了可训练的事件基础可微束调整与IMU预集成。&lt;h4&gt;主要发现&lt;/h4&gt;在九个公共挑战数据集上的数值实验表明，DEIO的方法在性能上优于基于图像和事件的基准。&lt;h4&gt;结论&lt;/h4&gt;DEIO框架在复杂环境下表现出更好的鲁棒性和适用性，推动了事件基础SLAM的研究进展。&lt;h4&gt;总结&lt;/h4&gt;研究展示了事件相机与IMU结合的潜力，为未来的SLAM研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/arclab-hku/deio&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event cameras are bio-inspired, motion-activated sensors that demonstrateimpressive potential in handling challenging situations, such as motion blurand high-dynamic range. Despite their promise, existing event-basedsimultaneous localization and mapping (SLAM) approaches exhibit limitedperformance in real-world applications. On the other hand, state-of-the-artSLAM approaches that incorporate deep neural networks for better robustness andapplicability. However, these is a lack of research in fusing learning-basedevent SLAM methods with IMU, which could be indispensable to push theevent-based SLAM to large-scale, low-texture or complex scenarios. In thispaper, we propose DEIO, the first monocular deep event-inertial odometryframework that combines learning-based method with traditional nonlineargraph-based optimization. Specifically, we tightly integrate a trainableevent-based differentiable bundle adjustment (e-DBA) with the IMUpre-integration in a factor graph which employs keyframe-based sliding windowoptimization. Numerical Experiments in nine public challenge datasets show thatour method can achieve superior performance compared with the image-based andevent-based benchmarks. The source code is available at:https://github.com/arclab-hku/DEIO.</description>
      <author>example@mail.com (Weipeng Guan, Fuling Lin, Peiyu Chen, Peng Lu)</author>
      <guid isPermaLink="false">2411.03928v3</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Strategic Sacrifice: Self-Organized Robot Swarm Localization for Inspection Productivity</title>
      <link>http://arxiv.org/abs/2411.09493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 10 figures, 17th International Symposium on Distributed
  Autonomous Robotic Systems (DARS'24)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人群体在检查多样化基础设施（如桥梁和空间站）方面具有显著潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的合作定位机制，以提高检查效率并降低计算资源消耗。&lt;h4&gt;方法&lt;/h4&gt;通过自我组织的牺牲，少数代理承担定位计算负担，通过局部交互提升群体的检查生产力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在动态交互和环境设置下，自适应地最大化检查生产力。&lt;h4&gt;结论&lt;/h4&gt;使用均场分析模型、多代理仿真和金属攀爬机器人检查3D圆柱的硬件实验，展示了方法的最优性和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;提出的合作定位机制有效提高了机器人群体的检查效率，具有应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot swarms offer significant potential for inspecting diverseinfrastructure, ranging from bridges to space stations. However, effectiveinspection requires accurate robot localization, which demands substantialcomputational resources and limits productivity. Inspired by biologicalsystems, we introduce a novel cooperative localization mechanism that minimizescollective computation expenditure through self-organized sacrifice. Here, afew agents bear the computational burden of localization; through localinteractions, they improve the inspection productivity of the swarm. Ourapproach adaptively maximizes inspection productivity for unconstrainedtrajectories in dynamic interaction and environmental settings. We demonstratethe optimality and robustness using mean-field analytical models, multi-agentsimulations, and hardware experiments with metal climbing robots inspecting a3D cylinder.</description>
      <author>example@mail.com (Sneha Ramshanker, Hungtang Ko, Radhika Nagpal)</author>
      <guid isPermaLink="false">2411.09493v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Drone Detection using Deep Neural Networks Trained on Pure Synthetic Data</title>
      <link>http://arxiv.org/abs/2411.09077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无人机检测受益于深度神经网络的进步，但准确的训练数据供应不足。&lt;h4&gt;目的&lt;/h4&gt;探索合成数据在无人机检测中的应用，验证其在现实数据上的转移能力。&lt;h4&gt;方法&lt;/h4&gt;训练一个基于合成数据集的Faster-RCNN模型，并在真实数据集MAV-Vid上进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在MAV-Vid数据集上的AP_50达到97.0%，与训练于真实数据的模型（97.8%）相当。&lt;h4&gt;结论&lt;/h4&gt;合成数据在无人机检测中具有降低数据收集成本和改善标注质量的潜力。&lt;h4&gt;应用&lt;/h4&gt;为安全关键应用（如机场无人机检测）生成特定场景的合成数据集，降低数据生成风险。&lt;h4&gt;未来方向&lt;/h4&gt;合成数据可能支持可靠的无人机检测系统，并惠及无人交通管理等其他领域。&lt;h4&gt;总结&lt;/h4&gt;合成数据为无人机检测提供了新的可能性，未来可以进一步开发更复杂的合成数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mazqtpopx/cranfield-synthetic-drone-detection&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drone detection has benefited from improvements in deep neural networks, butlike many other applications, suffers from the availability of accurate datafor training. Synthetic data provides a potential for low-cost data generationand has been shown to improve data availability and quality. However, modelstrained on synthetic datasets need to prove their ability to perform onreal-world data, known as the problem of sim-to-real transferability. Here, wepresent a drone detection Faster-RCNN model trained on a purely syntheticdataset that transfers to real-world data. We found that it achieves an AP_50of 97.0% when evaluated on the MAV-Vid - a real dataset of flying drones -compared with 97.8% for an equivalent model trained on real-world data. Ourresults show that using synthetic data for drone detection has the potential toreduce data collection costs and improve labelling quality. These findingscould be a starting point for more elaborate synthetic drone datasets. Forexample, realistic recreations of specific scenarios could de-risk the datasetgeneration of safety-critical applications such as the detection of drones atairports. Further, synthetic data may enable reliable drone detection systems,which could benefit other areas, such as unmanned traffic management systems.The code is availablehttps://github.com/mazqtpopx/cranfield-synthetic-drone-detection alongside thedatasetshttps://huggingface.co/datasets/mazqtpopx/cranfield-synthetic-drone-detection.</description>
      <author>example@mail.com (Mariusz Wisniewski, Zeeshan A. Rana, Ivan Petrunin, Alan Holt, Stephen Harman)</author>
      <guid isPermaLink="false">2411.09077v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Optimisation Strategies for Ensuring Fairness in Machine Learning: With and Without Demographics</title>
      <link>http://arxiv.org/abs/2411.09056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis. arXiv admin note: text overlap with arXiv:2310.11407&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;公平性已成为人工智能及其相关算法的主要关注点之一，机器学习公平性领域逐渐发展以应对这些问题。&lt;h4&gt;目的&lt;/h4&gt;提供机器学习公平性领域的全面概述，并引入两个正式框架以解决开放性问题。&lt;h4&gt;方法&lt;/h4&gt;第一个框架使用算子值优化和最小-最大目标来解决时间序列问题中的不公平性；第二个框架则针对常用数据集中缺乏敏感属性（如性别和种族）的问题，引入无敏感属性的偏差修复框架。&lt;h4&gt;主要发现&lt;/h4&gt;第一个框架在著名的COMPAS基准数据集上展示了先进的性能；第二个框架通过对成人普查收入数据集的分析，展示了其有效性。&lt;h4&gt;结论&lt;/h4&gt;提供的算法分析和收敛保证确保了所提方法的鲁棒性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;本论文为机器学习公平性问题提供了创新的解决方案，强调了在缺乏敏感属性情况下处理偏差的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/quan-zhou/proper-learning-of-lds&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring fairness has emerged as one of the primary concerns in AI and itsrelated algorithms. Over time, the field of machine learning fairness hasevolved to address these issues. This paper provides an extensive overview ofthis field and introduces two formal frameworks to tackle open questions inmachine learning fairness.  In one framework, operator-valued optimisation and min-max objectives areemployed to address unfairness in time-series problems. This approach showcasesstate-of-the-art performance on the notorious COMPAS benchmark dataset,demonstrating its effectiveness in real-world scenarios.  In the second framework, the challenge of lacking sensitive attributes, suchas gender and race, in commonly used datasets is addressed. This issue isparticularly pressing because existing algorithms in this field predominantlyrely on the availability or estimations of such attributes to assess andmitigate unfairness. Here, a framework for a group-blind bias-repair isintroduced, aiming to mitigate bias without relying on sensitive attributes.The efficacy of this approach is showcased through analyses conducted on theAdult Census Income dataset.  Additionally, detailed algorithmic analyses for both frameworks are provided,accompanied by convergence guarantees, ensuring the robustness and reliabilityof the proposed methodologies.</description>
      <author>example@mail.com (Quan Zhou)</author>
      <guid isPermaLink="false">2411.09056v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>FlowNav: Learning Efficient Navigation Policies via Conditional Flow Matching</title>
      <link>http://arxiv.org/abs/2411.09524v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CoRL 2024 workshop on Learning Effective Abstractions for
  Planning (LEAP) and workshop on Differentiable Optimization Everywhere:
  Simulation, Estimation, Learning, and Control. 7 pages + 2 pages of
  references, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;动态环境中的有效机器人导航是一项具有挑战性的任务，需要高频率生成精确的控制动作。&lt;h4&gt;目的&lt;/h4&gt;探讨使用条件流匹配（CFM）来学习帮助机器人导航的动作策略。&lt;h4&gt;方法&lt;/h4&gt;将导航视为目标条件控制问题，比较现有的扩散策略与CFM在性能上的差异。&lt;h4&gt;主要发现&lt;/h4&gt;CFM能够生成高精度的机器人动作，匹配扩散策略的准确性，并显著提高运行性能。&lt;h4&gt;结论&lt;/h4&gt;CFM为实时机器人导航提供了更具可扩展性和响应性的解决方案，适用于动态和不可预测的环境。&lt;h4&gt;总结&lt;/h4&gt;CFM的应用使得机器人在复杂环境中更有效地避免碰撞，实现平稳操作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective robot navigation in dynamic environments is a challenging task thatdepends on generating precise control actions at high frequencies. Recentadvancements have framed navigation as a goal-conditioned control problem.Current state-of-the-art methods for goal-based navigation, such as diffusionpolicies, either generate sub-goal images or robot control actions to guiderobots. However, despite their high accuracy, these methods incur substantialcomputational costs, which limits their practicality for real-timeapplications. Recently, Conditional Flow Matching(CFM) has emerged as a moreefficient and robust generalization of diffusion. In this work we explore theuse of CFM to learn action policies that help the robot navigate itsenvironment. Our results demonstrate that CFM is able to generate highlyaccurate robot actions. CFM not only matches the accuracy of diffusion policiesbut also significantly improves runtime performance. This makes it particularlyadvantageous for real-time robot navigation, where swift, reliable actiongeneration is vital for collision avoidance and smooth operation. By leveragingCFM, we provide a pathway to more scalable, responsive robot navigation systemscapable of handling the demands of dynamic and unpredictable environments.</description>
      <author>example@mail.com (Samiran Gode, Abhijeet Nayak, Wolfram Burgard)</author>
      <guid isPermaLink="false">2411.09524v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Emergency Communication for Future Smart Cities with Random Forest Model</title>
      <link>http://arxiv.org/abs/2411.06455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究针对延迟容忍网络(DTNs)中的信息传输优化，尤其是在车祸等紧急情况下。&lt;h4&gt;目的&lt;/h4&gt;优化“喷洒等待”协议，提高紧急情况下的信息传输性能。&lt;h4&gt;方法&lt;/h4&gt;使用机器学习方法随机森林来识别“高质量”节点，这些节点具有高消息传递成功率和最佳路径。&lt;h4&gt;主要发现&lt;/h4&gt;通过ONE模拟器过滤高质量节点数据，仿真实验显示加载高质量节点显著提高协议性能，增加信息传输成功率并减少延迟。&lt;h4&gt;结论&lt;/h4&gt;本研究验证了使用先进机器学习技术改善DTN路由协议的可行性，为未来紧急通信网络管理创新奠定基础。&lt;h4&gt;总结&lt;/h4&gt;本研究通过优化节点识别方法，提高了DTN在紧急情况下的信息传输效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study aims to optimise the "spray and wait" protocol in delay tolerantnetworks (DTNs) to improve the performance of information transmission inemergency situations, especially in car accident scenarios. Due to theintermittent connectivity and dynamic environment of DTNs, traditional routingprotocols often do not work effectively. In this study, a machine learningmethod called random forest was used to identify "high-quality" nodes."High-quality" nodes refer to those with high message delivery success ratesand optimal paths. The high-quality node data was filtered according to thenode report of successful transmission generated by the One simulator. The nodecontact report generated by another One simulator was used to calculate thedata of the three feature vectors required for training the model. The featurevectors and the high-quality node data were then fed into the model to trainthe random forest model, which was then able to identify high-quality nodes.The simulation experiment was carried out in the ONE simulator in the Helsinkicity centre, with two categories of weekday and holiday scenarios, each with adifferent number of nodes. Three groups were set up in each category: theoriginal unmodified group, the group with high-quality nodes, and the groupwith random nodes. The results show that this method of loading high-qualitynodes significantly improves the performance of the protocol, increasing thesuccess rate of information transmission and reducing latency. This study notonly confirms the feasibility of using advanced machine learning techniques toimprove DTN routing protocols, but also lays the foundation for futureinnovations in emergency communication network management.</description>
      <author>example@mail.com (Chengkun Ye, Milena Radenkovic)</author>
      <guid isPermaLink="false">2411.06455v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Interdependent scaling exponents in the human brain</title>
      <link>http://arxiv.org/abs/2411.09098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究大规模人群的静息态fMRI脑活动时间序列。&lt;h4&gt;目的&lt;/h4&gt;应用现象学重整化群方法分析脑活动数据的尺度特征。&lt;h4&gt;方法&lt;/h4&gt;通过递归粗粒化数据，计算时间序列方差、静默的对数概率和最大协方差特征值的尺度指数。&lt;h4&gt;主要发现&lt;/h4&gt;这些指数之间存在明显的线性相互依赖关系，并且与灰质体积和认知表现有显著相关性。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，尺度依赖性是脑组织的内在特征，可能在其他复杂系统中也存在。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了脑活动数据的尺度特征及其与脑结构和认知功能的关系，暗示了复杂系统中的普遍规律。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We apply the phenomenological renormalization group to resting-state fMRItime series of brain activity in a large population. By recursivelycoarse-graining the data, we compute scaling exponents for the series variance,log probability of silence, and largest covariance eigenvalue. The exponentsclearly exhibit linear interdependencies, which we derive analytically in amean-field approach. We find a significant correlation of exponent values withthe gray matter volume and cognitive performance. Akin to scaling relationsnear critical points in thermodynamics, our findings suggest scalinginterdependencies are intrinsic to brain organization and may also exist inother complex systems.</description>
      <author>example@mail.com (Daniel M. Castro, Ernesto P. Raposo, Mauro Copelli, Fernando A. N. Santos)</author>
      <guid isPermaLink="false">2411.09098v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Development of an indoor localization and navigation system based on monocular SLAM for mobile robots</title>
      <link>http://arxiv.org/abs/2411.05337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In The 25th National Conference on Electronics, Communications and
  Information Technology (REV-ECIT 2022), Hanoi, Vietnam. in Vietnamese
  language&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;移动机器人中的定位和导航是两个关键问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于单目SLAM的差分驱动机器人定位和导航系统。&lt;h4&gt;方法&lt;/h4&gt;在机器人操作系统（ROS）上实现，使用Jetson Xavier AGX嵌入式计算平台、2D摄像头和LiDAR传感器收集外部环境信息，采用A*算法和动态窗口法（DWA）进行路径规划，应用ORB_SLAM3算法提取环境特征。&lt;h4&gt;主要发现&lt;/h4&gt;系统在Gazebo仿真环境中进行了测试，并通过Rviz进行可视化，展示了系统在室内定位和导航中的效率和潜力。&lt;h4&gt;结论&lt;/h4&gt;该系统有效支持移动机器人的室内定位和导航任务。&lt;h4&gt;总结&lt;/h4&gt;研究表明，结合单目SLAM和适当的路径规划方法能够提高移动机器人的定位和导航能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Localization and navigation are two crucial issues for mobile robots. In thispaper, we propose an approach for localization and navigation systems for adifferential-drive robot based on monocular SLAM. The system is implemented onthe Robot Operating System (ROS). The hardware includes a differential-driverobot with an embedded computing platform (Jetson Xavier AGX), a 2D camera, anda LiDAR sensor for collecting external environmental information. The A*algorithm and Dynamic Window Approach (DWA) are used for path planning based ona 2D grid map. The ORB_SLAM3 algorithm is utilized to extract environmentalfeatures, providing the robot's pose for the localization and navigationprocesses. Finally, the system is tested in the Gazebo simulation environmentand visualized through Rviz, demonstrating the efficiency and potential of thesystem for indoor localization and navigation of mobile robots.</description>
      <author>example@mail.com (Thanh Nguyen Canh, Duc Manh Do, Xiem HoangVan)</author>
      <guid isPermaLink="false">2411.05337v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Vlimb: A Wire-Driven Wearable Robot for Bodily Extension, Balancing Powerfulness and Reachability</title>
      <link>http://arxiv.org/abs/2411.09565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;已有多种可穿戴机器人被开发，满足身体辅助和娱乐需求，分为增强型和扩展型。&lt;h4&gt;目的&lt;/h4&gt;本研究专注于身体扩展型可穿戴机器人，旨在提升其性能。&lt;h4&gt;方法&lt;/h4&gt;开发了一种名为Vlimb的扩展型可穿戴机器人，采用腱驱动机制和线缆引导机制。&lt;h4&gt;主要发现&lt;/h4&gt;Vlimb具有足够的力量以举起人类，并能够进行复杂的操作。&lt;h4&gt;结论&lt;/h4&gt;Vlimb通过引入被动环结构，克服了腱驱动机制的局限，达到了与人类相当的力量和可达性。&lt;h4&gt;总结&lt;/h4&gt;本文概述了Vlimb的设计方法，进行了初步的操作和提升任务，并验证了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Numerous wearable robots have been developed to meet the demands of physicalassistance and entertainment. These wearable robots range from body-enhancingtypes that assist human arms and legs to body-extending types that have extraarms. This study focuses specifically on wearable robots of the lattercategory, aimed at bodily extension. However, they have not yet achieved thelevel of powerfulness and reachability equivalent to that of human limbs,limiting their application to entertainment and manipulation tasks involvinglightweight objects. Therefore, in this study, we develop an body-extendingwearable robot, Vlimb, which has enough powerfulness to lift a human and canperform manipulation. Leveraging the advantages of tendon-driven mechanisms,Vlimb incorporates a wire routing mechanism capable of accommodating bothdelicate manipulations and robust lifting tasks. Moreover, by introducing apassive ring structure to overcome the limited reachability inherent intendon-driven mechanisms, Vlimb achieves both the powerfulness and reachabilitycomparable to that of humans. This paper outlines the design methodology ofVlimb, conducts preliminary manipulation and lifting tasks, and verifies itseffectiveness.</description>
      <author>example@mail.com (Shogo Sawaguchi, Temma Suzuki, Akihiro Miki, Kento Kawaharazuka, Sota Yuzaki, Shunnosuke Yoshimura, Yoshimoto Ribayashi, Kei Okada, Masayuki Inaba)</author>
      <guid isPermaLink="false">2411.09565v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Spatially Constrained Transformer with Efficient Global Relation Modelling for Spatio-Temporal Prediction</title>
      <link>http://arxiv.org/abs/2411.06836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的时空预测对智能城市的可持续发展至关重要，目前的方法常常难以捕捉重要的时空关系，尤其是忽视了远距离城市区域之间的全球关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来有效捕捉局部和全球关系，以克服现有技术的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出ST-SampleNet，一种结合卷积神经网络（CNN）和自注意力机制的变换器架构，同时引入轻量级区域采样策略和空间约束位置嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;ST-SampleNet在三个真实世界数据集上的实验评估显示其有效性，且高效变体在计算成本上减少了40%，性能仅下降约1%。&lt;h4&gt;结论&lt;/h4&gt;ST-SampleNet有效克服了CNN的邻域偏差问题，并通过轻量级策略提高了时空预测的效率和准确性。&lt;h4&gt;总结&lt;/h4&gt;ST-SampleNet结合了先进的技术，提升了智能城市的时空预测能力，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3233/FAIA240813&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ashusao/st-samplenet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate spatio-temporal prediction is crucial for the sustainabledevelopment of smart cities. However, current approaches often struggle tocapture important spatio-temporal relationships, particularly overlookingglobal relations among distant city regions. Most existing techniquespredominantly rely on Convolutional Neural Networks (CNNs) to capture globalrelations. However, CNNs exhibit neighbourhood bias, making them insufficientfor capturing distant relations. To address this limitation, we proposeST-SampleNet, a novel transformer-based architecture that combines CNNs withself-attention mechanisms to capture both local and global relationseffectively. Moreover, as the number of regions increases, the quadraticcomplexity of self-attention becomes a challenge. To tackle this issue, weintroduce a lightweight region sampling strategy that prunes non-essentialregions and enhances the efficiency of our approach. Furthermore, we introducea spatially constrained position embedding that incorporates spatialneighbourhood information into the self-attention mechanism, aiding in semanticinterpretation and improving the performance of ST-SampleNet. Our experimentalevaluation on three real-world datasets demonstrates the effectiveness ofST-SampleNet. Additionally, our efficient variant achieves a 40% reduction incomputational costs with only a marginal compromise in performance,approximately 1%.</description>
      <author>example@mail.com (Ashutosh Sao, Simon Gottschalk)</author>
      <guid isPermaLink="false">2411.06836v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Software Security and Reliability in Cloud Platforms through AI-based Anomaly Detection</title>
      <link>http://arxiv.org/abs/2411.09200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;持续集成/持续部署（CI/CD）是现代软件开发的基础，但在CI/CD流程中，安全问题依然具有挑战性，云环境中发生了多起安全事件。&lt;h4&gt;目的&lt;/h4&gt;通过人工智能支持的异常检测，增强CI/CD管道的安全性，识别管道和云平台中的网络流量模式中的异常行为。&lt;h4&gt;方法&lt;/h4&gt;采用CSE-CIC-IDS2018和CSE-CIC-IDS2017两个网络流量数据集，结合卷积神经网络（CNN）和长短期记忆网络（LSTM）检测异常流量模式。&lt;h4&gt;主要发现&lt;/h4&gt;实现了98.69%和98.30%的准确率，并生成了不同CI/CD管道阶段的日志文件，模拟受到的网络异常。&lt;h4&gt;结论&lt;/h4&gt;本研究为现代DevOps实践中的安全挑战提供了解决方案，促进了软件安全性和可靠性的发展。&lt;h4&gt;总结&lt;/h4&gt;本研究通过网络流量模式分析和AI支持的异常检测，为CI/CD管道的安全性提供了新的视角和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuous Integration/Continuous Deployment (CI/CD) is fundamental foradvanced software development, supporting faster and more efficient delivery ofcode changes into cloud environments. However, security issues in the CI/CDpipeline remain challenging, and incidents (e.g., DDoS, Bot, Log4j, etc.) arehappening over the cloud environments. While plenty of literature discussesstatic security testing and CI/CD practices, only a few deal with networktraffic pattern analysis to detect different cyberattacks. This research aimsto enhance CI/CD pipeline security by implementing anomaly detection through AI(Artificial Intelligence) support. The goal is to identify unusual behaviour orvariations from network traffic patterns in pipeline and cloud platforms. Thesystem shall integrate into the workflow to continuously monitor pipelineactivities and cloud infrastructure. Additionally, it aims to explore adaptiveresponse mechanisms to mitigate the detected anomalies or security threats.This research employed two popular network traffic datasets, CSE-CIC-IDS2018and CSE-CIC-IDS2017. We implemented a combination of Convolution NeuralNetwork(CNN) and Long Short-Term Memory (LSTM) to detect unusual trafficpatterns. We achieved an accuracy of 98.69% and 98.30% and generated log filesin different CI/CD pipeline stages that resemble the network anomalies affectedto address security challenges in modern DevOps practices, contributing toadvancing software security and reliability.</description>
      <author>example@mail.com (Sabbir M. Saleh, Ibrahim Mohammed Sayem, Nazim Madhavji, John Steinbacher)</author>
      <guid isPermaLink="false">2411.09200v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>HomoMatcher: Dense Feature Matching Results with Semi-Dense Efficiency by Homography Estimation</title>
      <link>http://arxiv.org/abs/2411.06700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, conference under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图像对之间的特征匹配是计算机视觉中的基础问题，对许多应用（如SLAM）至关重要。&lt;h4&gt;目的&lt;/h4&gt;提升半稠密匹配框架中的精细匹配模块。&lt;h4&gt;方法&lt;/h4&gt;采用轻量级高效的单应性估计网络生成粗匹配补丁之间的透视映射，通过补丁到补丁的方法实现整体对齐，结合额外约束以提高亚像素精度。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在实现稠密匹配结果时，计算成本低且准确性高，实验表明其准确性优于以往的半稠密匹配器。&lt;h4&gt;结论&lt;/h4&gt;虽然我们的稠密匹配结果与以往稠密匹配器的端点误差精度相似，但仍保持了半稠密的效率。&lt;h4&gt;总结&lt;/h4&gt;本研究通过改进精细匹配模块，成功在半稠密匹配中实现高效且准确的特征匹配。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Feature matching between image pairs is a fundamental problem in computervision that drives many applications, such as SLAM. Recently, semi-densematching approaches have achieved substantial performance enhancements andestablished a widely-accepted coarse-to-fine paradigm. However, the majority ofexisting methods focus on improving coarse feature representation rather thanthe fine-matching module. Prior fine-matching techniques, which rely onpoint-to-patch matching probability expectation or direct regression, oftenlack precision and do not guarantee the continuity of feature points acrosssequential images. To address this limitation, this paper concentrates onenhancing the fine-matching module in the semi-dense matching framework. Weemploy a lightweight and efficient homography estimation network to generatethe perspective mapping between patches obtained from coarse matching. Thispatch-to-patch approach achieves the overall alignment of two patches,resulting in a higher sub-pixel accuracy by incorporating additionalconstraints. By leveraging the homography estimation between patches, we canachieve a dense matching result with low computational cost. Extensiveexperiments demonstrate that our method achieves higher accuracy compared toprevious semi-dense matchers. Meanwhile, our dense matching results exhibitsimilar end-point-error accuracy compared to previous dense matchers whilemaintaining semi-dense efficiency.</description>
      <author>example@mail.com (Xiaolong Wang, Lei Yu, Yingying Zhang, Jiangwei Lao, Lixiang Ru, Liheng Zhong, Jingdong Chen, Yu Zhang, Ming Yang)</author>
      <guid isPermaLink="false">2411.06700v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Probability of constructing prediction model for observable of a dynamical process via time series</title>
      <link>http://arxiv.org/abs/2411.09230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究动态过程中的一个基本问题是如何通过采样时间序列为未知系统构建预测模型，尤其是在大数据时代。&lt;h4&gt;目的&lt;/h4&gt;为物理、化学和生物科学等领域的实验者提供构建复杂系统可观测量的预测模型的途径。&lt;h4&gt;方法&lt;/h4&gt;在离散时间和连续时间线性系统的设置下，采用线性代数方法，通过Lebesgue测度证明可以几乎肯定地构建预测模型。&lt;h4&gt;主要发现&lt;/h4&gt;即使没有关于动态过程和输出函数的任何信息，仍然可以通过观察到的时间序列构建未知系统的预测模型，并以概率1获得未知矩阵的特征多项式。&lt;h4&gt;结论&lt;/h4&gt;在特定条件下，线性代数方法能够有效且可靠地为未知系统的可观测量提供预测模型。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，利用线性代数和时间序列数据可以在复杂系统建模中实现重要的理论和应用进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; One fundamental problem in studying dynamical process is whether it ispossible and how to construct prediction model for an unknown system viasampled time series, especially in the modern big data era. The research inthis area is beneficial to experimentalists in physics, chemistry, especially,in biological science, where it is hard to construct a prediction models byfirst principles. Therefore constructing prediction model for the observable ofa complex system is of great practical significance in various areas of scienceand engineering. In the present paper, we show in terms of Lebesgue measurethat, at least in the linear case, one can almost surely construct by linearalgebra approach the prediction model about observable of unknown systems onlyvia observed time series in the settings of discrete time and continuous timelinear systems, even in the situation that one has no information about theunderlying dynamical process and output function that generates the observedtime series. Interestingly, we can obtain the characteristic polynomial of theunknown matrices for both of discrete time and continuous time linear systemswith probability 1.</description>
      <author>example@mail.com (Xiao-Song Yang)</author>
      <guid isPermaLink="false">2411.09230v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Smart Automation in Luxury Leather Shoe Polishing: A Human Centric Robotic Approach</title>
      <link>http://arxiv.org/abs/2411.09603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;奢侈皮鞋的抛光过程精细且劳动密集，通常由熟练工匠完成。&lt;h4&gt;目的&lt;/h4&gt;鞋类公司旨在自动化部分抛光过程，以提高质量、生产力和操作员的福祉。&lt;h4&gt;方法&lt;/h4&gt;提出了一个协作机器人系统来辅助鞋子的抛光，机器人配备了专门工具并通过力控制执行抛光任务。&lt;h4&gt;主要发现&lt;/h4&gt;分析了轨迹设计、施加力量、抛光速度和抛光量等关键因素，使用CAM软件设计抛光轨迹，并将其转移到机器人控制系统。&lt;h4&gt;结论&lt;/h4&gt;人类操作员负责设计过程、监督机器人并进行最终修整，确保专业知识对实现质量至关重要。广泛的测试表明，各种鞋型的质量和可靠性显著提升，成功在工业生产线上实施。&lt;h4&gt;总结&lt;/h4&gt;该研究为奢侈鞋抛光的自动化提供了一种有效的解决方案，结合了人机协作，提高了生产效率和产品质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1080/0951192X.2024.2421313&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The polishing of luxury leather shoes is a delicate, labor intensive processtraditionally performed by skilled craftsmen. Footwear companies aim toautomate parts of this process to enhance quality, productivity, and operatorwell-being, but the unique nature of luxury shoe production presentschallenges. This paper introduces a solution involving a collaborative roboticcell to assist in shoe polishing. A collaborative robotic manipulator, equippedwith a specialized tool and governed by force control, executes the polishingtasks. Key factors such as trajectory design, applied force, polishing speed,and polish amount were analyzed. Polishing trajectories are designed using CAMsoftware and transferred to the robot control system. Human operators designthe process, supervise the robot, and perform final finishing, ensuring theirexpertise is integral to achieving quality. Extensive testing on various shoemodels showed significant improvements in quality and reliability, leading tosuccessful implementation on an industrial production line.</description>
      <author>example@mail.com (Matteo Forlini, Marianna Ciccarelli, Luca Carbonari, Alessandra Papetti, Giacomo Palmieri)</author>
      <guid isPermaLink="false">2411.09603v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Towards Smart Microfarming in an Urban Computing Continuum</title>
      <link>http://arxiv.org/abs/2408.02992v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is uploaded here for research community, thus it is for
  non-commercial purposes&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;微农场和城市计算已经成为城市生活的两个独立可持续发展支柱。&lt;h4&gt;目的&lt;/h4&gt;将微农场和城市计算两个概念结合，扩展为智能微农场和城市计算连续体的新概念。&lt;h4&gt;方法&lt;/h4&gt;提出一个植物推荐系统架构，利用边缘计算中的机器学习从IoT传感器获取的土壤数据中寻找适合的植物，并集成LoRa通信解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验设置评估数据收集过程的性能和可靠性，以及推荐解决方案的质量。使用协同过滤完成对土壤和植物的不完整信息的补充。&lt;h4&gt;结论&lt;/h4&gt;应用多种机器学习算法识别并推荐适合特定城市微农场的最佳植物方案。&lt;h4&gt;总结&lt;/h4&gt;智能微农场和城市计算的结合，展示了利用AI和IoT技术提升城市农业效率的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-08-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Microfarming and urban computing have evolved as two distinct sustainabilitypillars of urban living today. In this paper, we combine these two concepts,while majorly extending them jointly towards novel concepts of smartmicrofarming and urban computing continuum. Smart microfarming is proposed withapplications of artificial intelligence (AI) in microfarming, while an urbancomputing continuum is proposed as a major extension of the concept towards anefficient Internet of Things (IoT) -edge-cloud continuum. We propose and builda system architecture for a plant recommendation system that uses machinelearning (ML) at the edge to find, from a pool of given plants, the mostsuitable ones for a given microfarm using monitored soil values obtained fromIoT sensor devices. Moreover, we propose to integrate long-distance LongRange(LoRa) communication solution for sending the data from IoT to the edge system,due to its unlicensed nature and potential for open source implementations.Finally, we propose to integrate open source and less constrained applicationprotocol solutions, such as Advanced Message Queuing Protocol (AMQP) andHypertext Transport Protocol (HTTP) protocols, for storing the data in thecloud. An experimental setup is used to evaluate and analyze the performanceand reliability of the data collection procedure and the quality of therecommendation solution. Furthermore, collaborative filtering is used for thecompletion of an incomplete information about soils and plants. Finally,various ML algorithms are applied to identify and recommend the optimal planfor a specific microfarm in an urban area.</description>
      <author>example@mail.com (Marla Grunewald, Mounir Bensalem, Jasenka Dizdarević, Admela Jukan)</author>
      <guid isPermaLink="false">2408.02992v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>The rotation properties of $δ$ Sct and $γ$ Dor stars</title>
      <link>http://arxiv.org/abs/2411.09292v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures, 1 table, APJ accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于LAMOST光谱和TESS时间序列光度数据，研究了δ Scuti和γ Doradus星的主序星样本。&lt;h4&gt;目的&lt;/h4&gt;分析δ Scuti和γ Doradus星的自转速度分布及其与正常星的比较。&lt;h4&gt;方法&lt;/h4&gt;收集1534颗δ Sct星、367颗γ Dor星及其他相关星，并校正投影效应以获得自转速度分布。&lt;h4&gt;主要发现&lt;/h4&gt;δ Sct和γ Dor星的自转速度分布极其相似，峰值自转速度比正常星高约10 km/s，且正常星的自转速度分布更为分散。&lt;h4&gt;结论&lt;/h4&gt;δ Sct星的自转速度与质量之间的关系不如正常星明显，且在主序星演化后期，正常星加速而δ Sct星减速。还可能存在未分类的星体，导致自转速度分布的广泛差异。&lt;h4&gt;总结&lt;/h4&gt;δ Sct星的光度振幅与自转速度有关，高振幅星通常自转较慢，而低振幅星的自转速度分布较广。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Based on the LAMOST spectroscopy and TESS time-series photometry, we haveobtained a main-sequence star sample of $\delta$ Scuti and $\gamma$ Doradusstars. The sample includes 1534 $\delta$ Sct stars, 367 $\gamma$ Dor stars,1703 $\delta$ Sct$| \gamma$ Dor stars, 270 $\gamma$ Dor$| \delta$ Sct stars,along with 105 '$\delta$ Sct candidates' and 32 '$\gamma$ Dor candidates'.After correcting for projection effects, we derived the equatorial rotationalvelocity distribution for $\delta$ Sct and $\gamma$ Dor stars and compared itwith that of normal stars. The rotational velocity distributions of $\delta$Sct and $\gamma$ Dor stars are extremely similar, with the only differencepotentially due to the rotational variable stars that have not been completelyremoved. In contrast, the rotational velocity distribution of normal stars ismore dispersed compared to pulsating stars. Additionally, the peak rotationalvelocity of the pulsating stars is about 10 km s$^{-1}$ higher than that ofnormal stars. Unlike the normal stars, which show a monotonic increase in peakvelocity with mass between 1.8 and 2.5 $M_{\odot}$, the rotational velocitydistribution of $\delta$ Sct stars does not exhibit a strong mass dependence.We also found that normal stars accelerate during the late main-sequenceevolutionary phase, while $\delta$ Sct stars decelerate. Furthermore, there maystill be unclassified stars with diverse rotational properties in the normalstar sample compared to the $\delta$ Sct stars, which is likely to be animportant contributor to the broader dispersion observed in its rotationalvelocity distribution. The photometric amplitude in $\delta$ Sct stars ismodulated with rotational velocity, with high-amplitude stars typicallyrotating slowly and low-amplitude stars showing a broad distribution ofrotational velocities.</description>
      <author>example@mail.com (Jiyu Wang, Xiaodian Chen, Licai Deng, Jianxing Zhang, Weijia Sun)</author>
      <guid isPermaLink="false">2411.09292v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Learning from Feedback: Semantic Enhancement for Object SLAM Using Foundation Models</title>
      <link>http://arxiv.org/abs/2411.06752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;语义同时定位与地图构建（SLAM）系统在密集的室内环境中，难以映射相似的物体，尤其是当这些物体靠近时。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型SLAM系统SEO-SLAM，以增强在复杂环境中物体级别的语义映射。&lt;h4&gt;方法&lt;/h4&gt;['利用多模态大型语言模型（MLLMs）生成更具体和描述性的开放词汇物体标签。', '同时纠正导致错误地标的因素。', '动态更新多类混淆矩阵，以减轻物体检测器的偏差。']&lt;h4&gt;主要发现&lt;/h4&gt;SEO-SLAM在处理多个相似物体的环境中展示了更高的准确性和稳健性。&lt;h4&gt;结论&lt;/h4&gt;SEO-SLAM在地标匹配精度和语义一致性方面优于现有方法，且MLLM的反馈提高了物体中心的语义映射质量。&lt;h4&gt;总结&lt;/h4&gt;我们的数据集已公开，地址为：jungseokhong.com/SEO-SLAM。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic Simultaneous Localization and Mapping (SLAM) systems struggle to mapsemantically similar objects in close proximity, especially in cluttered indoorenvironments. We introduce Semantic Enhancement for Object SLAM (SEO-SLAM), anovel SLAM system that leverages Vision-Language Models (VLMs) and MultimodalLarge Language Models (MLLMs) to enhance object-level semantic mapping in suchenvironments. SEO-SLAM tackles existing challenges by (1) generating morespecific and descriptive open-vocabulary object labels using MLLMs, (2)simultaneously correcting factors causing erroneous landmarks, and (3)dynamically updating a multiclass confusion matrix to mitigate object detectorbiases. Our approach enables more precise distinctions between similar objectsand maintains map coherence by reflecting scene changes through MLLM feedback.We evaluate SEO-SLAM on our challenging dataset, demonstrating enhancedaccuracy and robustness in environments with multiple similar objects. Oursystem outperforms existing approaches in terms of landmark matching accuracyand semantic consistency. Results show the feedback from MLLM improvesobject-centric semantic mapping. Our dataset is publicly available at:jungseokhong.com/SEO-SLAM.</description>
      <author>example@mail.com (Jungseok Hong, Ran Choi, John J. Leonard)</author>
      <guid isPermaLink="false">2411.06752v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Vision-based Manipulation of Transparent Plastic Bags in Industrial Setups</title>
      <link>http://arxiv.org/abs/2411.09623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;该论文探讨了工业环境中基于视觉的透明塑料袋自主切割和拆包的挑战，符合工业4.0的理念。&lt;h4&gt;目的&lt;/h4&gt;提升工业价值链的可达性和可持续性。&lt;h4&gt;方法&lt;/h4&gt;采用先进的机器学习算法，特别是卷积神经网络（CNN），识别不同光照和背景条件下的透明塑料袋，并结合跟踪算法和深度传感技术实现3D空间感知。&lt;h4&gt;主要发现&lt;/h4&gt;系统在抓取和操作中考虑了最佳抓取点、吸附抓取技术的合规控制，以及动态环境中的实时自动化安全交互。&lt;h4&gt;结论&lt;/h4&gt;系统在实验室中与FRANKA机器人手臂成功测试和验证，显示出在工业应用中的广泛潜力，尤其是在8堆散装装载机的自动拆包和切割方面的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究为透明塑料袋的自动处理提供了有效解决方案，推动了工业4.0的实施。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenges of vision-based manipulation forautonomous cutting and unpacking of transparent plastic bags in industrialsetups, aligning with the Industry 4.0 paradigm. Industry 4.0, driven by data,connectivity, analytics, and robotics, promises enhanced accessibility andsustainability throughout the value chain. The integration of autonomoussystems, including collaborative robots (cobots), into industrial processes ispivotal for efficiency and safety. The proposed solution employs advancedMachine Learning algorithms, particularly Convolutional Neural Networks (CNNs),to identify transparent plastic bags under varying lighting and backgroundconditions. Tracking algorithms and depth sensing technologies are utilized for3D spatial awareness during pick and placement. The system addresses challengesin grasping and manipulation, considering optimal points, compliance controlwith vacuum gripping technology, and real-time automation for safe interactionin dynamic environments. The system's successful testing and validation in thelab with the FRANKA robot arm, showcases its potential for widespreadindustrial applications, while demonstrating effectiveness in automating theunpacking and cutting of transparent plastic bags for an 8-stack bulk-loaderbased on specific requirements and rigorous testing.</description>
      <author>example@mail.com (F. Adetunji, A. Karukayil, P. Samant, S. Shabana, F. Varghese, U. Upadhyay, R. A. Yadav, A. Partridge, E. Pendleton, R. Plant, Y. Petillot, M. Koskinopoulou)</author>
      <guid isPermaLink="false">2411.09623v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Everything You Wanted to Know About Consumer Light Management in Smart Energy</title>
      <link>http://arxiv.org/abs/2411.08353v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 pages, 21 Figures excluding authors' biography&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;消费照明在智能城市和智能村庄的发展中发挥重要作用，智能照明解决方案在住宅区越来越普遍。&lt;h4&gt;目的&lt;/h4&gt;探讨如何在消费者照明管理系统中集成先进技术，以实现可持续和智能的照明解决方案。&lt;h4&gt;方法&lt;/h4&gt;对现有消费者照明管理系统的研究进行了全面调查，评审了不同的设计方法和技术。&lt;h4&gt;主要发现&lt;/h4&gt;现有的消费者照明管理系统存在显著的局限性，且对可持续性的需求迫切。&lt;h4&gt;结论&lt;/h4&gt;制造和研究行业需优先考虑可持续措施，以应对IoT设备对环境的负面影响。&lt;h4&gt;未来研究方向&lt;/h4&gt;文章强调了未来研究的可能途径，特别是在可持续计算框架的开发方面。&lt;h4&gt;总结&lt;/h4&gt;文章呼吁全球科学家、研究人员和工业界关注智能能源的整合，以解决消费者照明管理中的当前问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Consumer lighting plays a significant role in the development of smart citiesand smart villages. With the advancement of (IoT) technology, smart lightingsolutions have become more prevalent in residential areas as well. Thesesolutions provide consumers with increased energy efficiency, addedconvenience, and improved security. On the other hand, the growing number ofIoT devices has become a global concern due to the carbon footprint and carbonemissions associated with these devices. The overuse of batteries increasesmaintenance and cost to IoT devices and simultaneously possesses adverseenvironmental effects, ultimately exacerbating the pace of climate change.Therefore, in tandom with the principles of Industry 4.0, it has become crucialfor manufacturing and research industries to prioritize sustainable measuresadhering to smart energy as a prevention to the negative impacts. Consequently,it has undoubtedly garnered global interest from scientists, researchers, andindustrialists to integrate state-of-the-art technologies in order to solve thecurrent issues in consumer light management systems making it a completesustainable, and smart solution for consumer lighting application. Thismanuscript provides a thorough investigation of various methods as well astechniques to design a state-of-the-art IoT-enabled consumer light managementsystem. It critically reviews the existing works done in consumer lightmanagement systems, emphasizing the significant limitations and the need forsustainability. The top-down approach of developing sustainable computingframeworks for IoT-enabled consumer light management has been reviewed based onthe multidisciplinary technologies involved and state-of-the-art works in therespective domains. Lastly, this article concludes by highlighting possibleavenues for future research.</description>
      <author>example@mail.com (Prajnyajit Mohanty, Umesh C. Pati, Kamalakanta Mahapatra, Saraju P. Mohanty)</author>
      <guid isPermaLink="false">2411.08353v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Approximate Probabilistic Inference forTime-Series Data A Robust Latent Gaussian Model With Temporal Awareness</title>
      <link>http://arxiv.org/abs/2411.09312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;开发强大的生成模型以处理高度变化的非平稳时间序列数据是一项复杂而重要的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够捕捉时间信息并对数据错误具有鲁棒性的概率生成模型。&lt;h4&gt;方法&lt;/h4&gt;介绍了时间深度潜变量高斯模型（tDLGM），其架构受到深度潜变量高斯模型（DLGM）的启发，并通过最小化基于负对数损失的损失函数进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;tDLGM能够重构和生成复杂的时间序列数据，并且对噪声和故障数据具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过引入考虑数据趋势的正则化项，tDLGM在处理时间序列数据时表现优越。&lt;h4&gt;总结&lt;/h4&gt;tDLGM为时间序列数据建模提供了一种有效且鲁棒的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of robust generative models for highly varied non-stationarytime series data is a complex yet important problem. Traditional models fortime series data prediction, such as Long Short-Term Memory (LSTM), areinefficient and generalize poorly as they cannot capture complex temporalrelationships. In this paper, we present a probabilistic generative model thatcan be trained to capture temporal information, and that is robust to dataerrors. We call it Time Deep Latent Gaussian Model (tDLGM). Its novelarchitecture is inspired by Deep Latent Gaussian Model (DLGM). Our model istrained to minimize a loss function based on the negative log loss. Onecontributing factor to Time Deep Latent Gaussian Model (tDLGM) robustness isour regularizer, which accounts for data trends. Experiments conducted showthat tDLGM is able to reconstruct and generate complex time series data, andthat it is robust against to noise and faulty data.</description>
      <author>example@mail.com (Anton Johansson, Arunselvan Ramaswamy)</author>
      <guid isPermaLink="false">2411.09312v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Latency Optimization in LEO Satellite Communications with Hybrid Beam Pattern and Interference Control</title>
      <link>http://arxiv.org/abs/2411.09600v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;低地球轨道（LEO）卫星通信系统的快速发展显著增强了全球连接性，提供了关键的高容量、低延迟服务。&lt;h4&gt;目的&lt;/h4&gt;解决LEO星座的密集配置所带来的资源分配优化和干扰管理挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新框架，优化多波束LEO系统中的波束调度和资源分配，使用混合波束模式以提高下行服务质量并减少传输延迟。&lt;h4&gt;主要发现&lt;/h4&gt;通过动态共信道干扰控制机制，减小LEO星座内的波束干扰并限制其他网络对受保护用户的交叉系统干扰。&lt;h4&gt;结论&lt;/h4&gt;将用户-波束-频率分配与功率优化问题建模为混合整数动态规划模型，并采用低复杂度神经网络基础的图生成算法求解，结果表明该方法优于全频复用和单通道传输的基线方法。&lt;h4&gt;总结&lt;/h4&gt;该方法在多用户传输中显示出进一步性能提升的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of low Earth orbit (LEO) satellite communicationsystems has significantly enhanced global connectivity, offering high-capacity,low-latency services crucial for next-generation applications. However, thedense configuration of LEO constellations poses challenges in resourceallocation optimization and interference management, complicating coexistencewith other communication systems. To address these limitations, this paperproposes a novel framework for optimizing the beam scheduling and resourceallocation in multi-beam LEO systems. To satisfy the uneven terrestrial trafficdemand, a hybrid beam pattern is employed to enhance the downlink quality ofservice and minimize the transmission latency from LEO satellites to grounduser terminals. Additionally, a dynamic co-channel interference (CCI) controlmechanism is developed to mitigate inter-beam interference within the LEOconstellation and limit cross-system interference affecting protected usersfrom other networks. The problem of user-beam-frequency allocation with poweroptimization is formulated as a mixed-integer dynamic programming model andsolved using a low-complexity neural network-based graph generation algorithm.Simulation results show that the proposed approach outperforms the baselinemethods of full frequency reuse and single-channel transmission, and highlightsthe potential for further performance improvement with multi-usertransmissions.</description>
      <author>example@mail.com (Qianqian Zhang, Ye Hu, Minchae Jung)</author>
      <guid isPermaLink="false">2411.09600v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Lost in Tracking Translation: A Comprehensive Analysis of Visual SLAM in Human-Centered XR and IoT Ecosystems</title>
      <link>http://arxiv.org/abs/2411.07146v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;跟踪算法的进步推动了多个领域的应用，例如自动驾驶、机器人引导和增强现实体验。&lt;h4&gt;目的&lt;/h4&gt;评估当前先进跟踪方法在不同应用和场景中的性能，揭示其局限性。&lt;h4&gt;方法&lt;/h4&gt;对跟踪算法面临的算法、环境和运动相关挑战进行分类，并使用多个跟踪算法和代表性数据集进行定量评估。&lt;h4&gt;主要发现&lt;/h4&gt;没有任何跟踪算法能够在不同应用和应用内的不同场景中有效工作。&lt;h4&gt;结论&lt;/h4&gt;通过对分析的洞察，提出了改善跟踪性能的多种方法，包括输入数据特征化、中间信息利用和输出评估。&lt;h4&gt;总结&lt;/h4&gt;跟踪算法的应用受到场景和条件的限制，需探索新的改进方法以提升性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advancements in tracking algorithms have empowered nascent applicationsacross various domains, from steering autonomous vehicles to guiding robots toenhancing augmented reality experiences for users. However, these algorithmsare application-specific and do not work across applications with differenttypes of motion; even a tracking algorithm designed for a given applicationdoes not work in scenarios deviating from highly standard conditions. Forexample, a tracking algorithm designed for robot navigation inside a buildingwill not work for tracking the same robot in an outdoor environment. Todemonstrate this problem, we evaluate the performance of the state-of-the-arttracking methods across various applications and scenarios. To inform ouranalysis, we first categorize algorithmic, environmental, andlocomotion-related challenges faced by tracking algorithms. We quantitativelyevaluate the performance using multiple tracking algorithms and representativedatasets for a wide range of Internet of Things (IoT) and Extended Reality (XR)applications, including autonomous vehicles, drones, and humans. Our analysisshows that no tracking algorithm works across different applications andscenarios within applications. Ultimately, using the insights generated fromour analysis, we discuss multiple approaches to improving the trackingperformance using input data characterization, leveraging intermediateinformation, and output evaluation.</description>
      <author>example@mail.com (Yasra Chandio, Khotso Selialia, Joseph DeGol, Luis Garcia, Fatima M. Anwar)</author>
      <guid isPermaLink="false">2411.07146v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>One-Shot Manipulation Strategy Learning by Making Contact Analogies</title>
      <link>http://arxiv.org/abs/2411.09627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CoRL LEAP Workshop, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新方法MAGIC，用于快速且广泛地泛化操作策略。&lt;h4&gt;目的&lt;/h4&gt;实现一次性学习操作策略，并能广泛适应新物体。&lt;h4&gt;方法&lt;/h4&gt;MAGIC通过参考动作轨迹识别类似的接触点和动作序列，基于两阶段接触点匹配过程，结合全局形状匹配和局部曲率分析。&lt;h4&gt;主要发现&lt;/h4&gt;MAGIC在三项任务（铲取、悬挂和钩取物体）中表现优越，相较于现有方法，显著提升了运行速度和对不同物体类别的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MAGIC方法在操作策略的学习和应用中具有很高的效率和适应性。&lt;h4&gt;总结&lt;/h4&gt;MAGIC为操控智能接触提供了一种有效的学习策略，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel approach, MAGIC (manipulation analogies for generalizableintelligent contacts), for one-shot learning of manipulation strategies withfast and extensive generalization to novel objects. By leveraging a referenceaction trajectory, MAGIC effectively identifies similar contact points andsequences of actions on novel objects to replicate a demonstrated strategy,such as using different hooks to retrieve distant objects of different shapesand sizes. Our method is based on a two-stage contact-point matching processthat combines global shape matching using pretrained neural features with localcurvature analysis to ensure precise and physically plausible contact points.We experiment with three tasks including scooping, hanging, and hookingobjects. MAGIC demonstrates superior performance over existing methods,achieving significant improvements in runtime speed and generalization todifferent object categories. Website: https://magic-2024.github.io/ .</description>
      <author>example@mail.com (Yuyao Liu, Jiayuan Mao, Joshua Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling)</author>
      <guid isPermaLink="false">2411.09627v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Modular Fault Diagnosis Framework for Complex Autonomous Driving Systems</title>
      <link>http://arxiv.org/abs/2411.09643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at 2024 IEEE 20th International Conference on Intelligent
  Computer Communication and Processing (ICCP 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;故障诊断对复杂的自主移动系统至关重要，尤其是在现代自主驾驶（AD）中。&lt;h4&gt;目的&lt;/h4&gt;探索针对AD系统的故障诊断方法，以确保系统的整体完整性。&lt;h4&gt;方法&lt;/h4&gt;提出一种模块化故障诊断框架，包括模块化状态监控和诊断元素，以及状态和依赖关系感知的聚合方法。&lt;h4&gt;主要发现&lt;/h4&gt;该分类方案能够对故障诊断模块进行有效分类，且在AD接驳巴士上进行了实现和评估。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架展示了其在故障诊断方面的能力，适用于多种异构组件。&lt;h4&gt;总结&lt;/h4&gt;模块化故障诊断框架为复杂自主驾驶系统的故障管理提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fault diagnosis is crucial for complex autonomous mobile systems, especiallyfor modern-day autonomous driving (AD). Different actors, numerous use cases,and complex heterogeneous components motivate a fault diagnosis of the systemand overall system integrity. AD systems are composed of many heterogeneouscomponents, each with different functionality and possibly using a differentalgorithm (e.g., rule-based vs. AI components). In addition, these componentsare subject to the vehicle's driving state and are highly dependent. Thispaper, therefore, faces this problem by presenting the concept of a modularfault diagnosis framework for AD systems. The concept suggests modular statemonitoring and diagnosis elements, together with a state- and dependency-awareaggregation method. Our proposed classification scheme allows for thecategorization of the fault diagnosis modules. The concept is implemented on ADshuttle buses and evaluated to demonstrate its capabilities.</description>
      <author>example@mail.com (Stefan Orf, Sven Ochs, Jens Doll, Albert Schotschneider, Marc Heinrich, Marc René Zofka, J. Marius Zöllner)</author>
      <guid isPermaLink="false">2411.09643v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Sparse Interval-valued Time Series Modeling with Machine Learning</title>
      <link>http://arxiv.org/abs/2411.09452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  37 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文将区间视为不可分割的集合，研究高维区间值时间序列的稀疏机器学习回归。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的稀疏机器学习回归方法，以改进区间值时间序列的分析和预测。&lt;h4&gt;方法&lt;/h4&gt;采用LASSO或自适应LASSO技术，开发了一个惩罚的最小距离估计方法，涵盖了点估计的特例，并验证了该估计的相合性和Oracle特性。&lt;h4&gt;主要发现&lt;/h4&gt;Monte Carlo模拟表明所提估计具有良好的有限样本特性，并且在实证应用中表现出对比随机森林和多层感知器等竞争方法的鲁棒性和有效性。&lt;h4&gt;结论&lt;/h4&gt;机器学习技术在区间值时间序列分析中具有潜力，为金融预测和投资组合管理提供了新见解。&lt;h4&gt;总结&lt;/h4&gt;本文为区间值数据分析提供了一种有效工具，展示了稀疏回归在金融领域的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; By treating intervals as inseparable sets, this paper proposes sparse machinelearning regressions for high-dimensional interval-valued time series. WithLASSO or adaptive LASSO techniques, we develop a penalized minimum distanceestimation, which covers point-based estimators are special cases. We establishthe consistency and oracle properties of the proposed penalized estimator,regardless of whether the number of predictors is diverging with the samplesize. Monte Carlo simulations demonstrate the favorable finite sampleproperties of the proposed estimation. Empirical applications tointerval-valued crude oil price forecasting and sparse index-tracking portfolioconstruction illustrate the robustness and effectiveness of our method againstcompeting approaches, including random forest and multilayer perceptron forinterval-valued data. Our findings highlight the potential of machine learningtechniques in interval-valued time series analysis, offering new insights forfinancial forecasting and portfolio management.</description>
      <author>example@mail.com (Haowen Bao, Yongmiao Hong, Yuying Sun, Shouyang Wang)</author>
      <guid isPermaLink="false">2411.09452v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization</title>
      <link>http://arxiv.org/abs/2411.08879v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;动态场景的新视图合成在增强现实和虚拟现实等应用中变得越来越重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的4D高斯点云（4DGS）算法，以处理从随意录制的单目视频中获取的动态场景。&lt;h4&gt;方法&lt;/h4&gt;引入不确定性感知正则化，以识别观察较少的不确定区域，并根据扩散模型和深度平滑性选择性地施加额外先验。此外，针对快速移动的动态区域，提出了一种动态区域稠密化方法，以初始化高斯原语。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，所提出的方法提高了从手持单目相机捕获的视频的4DGS重建性能，并在少样本静态场景重建中取得了良好结果。&lt;h4&gt;结论&lt;/h4&gt;该方法有效解决了现有工作中的过拟合问题，并改善了新视图合成的性能和训练图像重建的质量。&lt;h4&gt;总结&lt;/h4&gt;通过引入不确定性正则化和动态区域稠密化，4DGS算法在动态场景合成中显示出显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Novel view synthesis of dynamic scenes is becoming important in variousapplications, including augmented and virtual reality. We propose a novel 4DGaussian Splatting (4DGS) algorithm for dynamic scenes from casually recordedmonocular videos. To overcome the overfitting problem of existing work forthese real-world videos, we introduce an uncertainty-aware regularization thatidentifies uncertain regions with few observations and selectively imposesadditional priors based on diffusion models and depth smoothness on suchregions. This approach improves both the performance of novel view synthesisand the quality of training image reconstruction. We also identify theinitialization problem of 4DGS in fast-moving dynamic regions, where theStructure from Motion (SfM) algorithm fails to provide reliable 3D landmarks.To initialize Gaussian primitives in such regions, we present a dynamic regiondensification method using the estimated depth maps and scene flow. Ourexperiments show that the proposed method improves the performance of 4DGSreconstruction from a video captured by a handheld monocular camera and alsoexhibits promising results in few-shot static scene reconstruction.</description>
      <author>example@mail.com (Mijeong Kim, Jongwoo Lim, Bohyung Han)</author>
      <guid isPermaLink="false">2411.08879v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>MBA-SLAM: Motion Blur Aware Dense Visual SLAM with Radiance Fields Representation</title>
      <link>http://arxiv.org/abs/2411.08279v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新兴的3D场景表示方法（如NeRF和3D Gaussian Splatting）在使用高质量视频序列进行实时定位与地图构建（SLAM）方面表现出色，但在处理运动模糊帧时存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一个密集视觉SLAM管道（MBA-SLAM），以应对严重的运动模糊输入。&lt;h4&gt;方法&lt;/h4&gt;我们的方案结合了高效的运动模糊感知跟踪器与神经辐射场或高斯散点映射器，通过准确建模运动模糊图像的物理成像过程，同时学习3D场景表示并估计摄像机的局部轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;MBA-SLAM在摄像机定位和地图重建方面超越了以前的最先进方法，在多种数据集上表现优越，包括清晰图像和受运动模糊影响的数据集。&lt;h4&gt;结论&lt;/h4&gt;我们的研究展示了MBA-SLAM方法的多样性和鲁棒性，能够有效处理运动模糊问题。&lt;h4&gt;总结&lt;/h4&gt;代码可在https://github.com/WU-CVGL/MBA-SLAM获取，展示了在不同场景下的良好性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wu-cvgl/mba-slam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emerging 3D scene representations, such as Neural Radiance Fields (NeRF) and3D Gaussian Splatting (3DGS), have demonstrated their effectiveness inSimultaneous Localization and Mapping (SLAM) for photo-realistic rendering,particularly when using high-quality video sequences as input. However,existing methods struggle with motion-blurred frames, which are common inreal-world scenarios like low-light or long-exposure conditions. This oftenresults in a significant reduction in both camera localization accuracy and mapreconstruction quality. To address this challenge, we propose a dense visualSLAM pipeline (i.e. MBA-SLAM) to handle severe motion-blurred inputs. Ourapproach integrates an efficient motion blur-aware tracker with either neuralradiance fields or Gaussian Splatting based mapper. By accurately modeling thephysical image formation process of motion-blurred images, our methodsimultaneously learns 3D scene representation and estimates the cameras' localtrajectory during exposure time, enabling proactive compensation for motionblur caused by camera movement. In our experiments, we demonstrate thatMBA-SLAM surpasses previous state-of-the-art methods in both cameralocalization and map reconstruction, showcasing superior performance across arange of datasets, including synthetic and real datasets featuring sharp imagesas well as those affected by motion blur, highlighting the versatility androbustness of our approach. Code is available athttps://github.com/WU-CVGL/MBA-SLAM.</description>
      <author>example@mail.com (Peng Wang, Lingzhe Zhao, Yin Zhang, Shiyu Zhao, Peidong Liu)</author>
      <guid isPermaLink="false">2411.08279v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Spectral decomposition and high-accuracy Greens functions: Overcoming the Nyquist-Shannon limit via complex-time Krylov expansion</title>
      <link>http://arxiv.org/abs/2411.09680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;强相关量子多体系统的低能谱计算是一个长期存在的难题，对数值方法提出了巨大的挑战。&lt;h4&gt;目的&lt;/h4&gt;提高低能谱计算的准确性，克服频率分辨率的限制。&lt;h4&gt;方法&lt;/h4&gt;使用复时间Krylov空间的方法，解决Nyquist-Shannon定理所带来的频率分辨率限制。&lt;h4&gt;主要发现&lt;/h4&gt;在临界S-1/2海森堡模型和二维Su-Schrieffer-Heeger模型的光双极子示例中，展示了使用该方法的显著准确性提升。&lt;h4&gt;结论&lt;/h4&gt;此方法有效克服了现有方法的局限性，能够在更高维度和更复杂的系统中应用。&lt;h4&gt;总结&lt;/h4&gt;通过复时间Krylov空间，显著提高了强相关量子多体系统低能谱计算的准确性，拓宽了应用范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate computation of low-energy spectra of strongly correlated quantummany-body systems, typically accessed via Greens-functions, is a long-standingproblem posing enormous challenges to numerical methods. When the spectraldecomposition is obtained from Fourier transforming a time series, theNyquist-Shannon theorem limits the frequency resolution $\Delta\omega$according to the numerically accessible time domain size $T$ via $\Delta\omega= 2/T$. In tensor network methods, increasing the domain size is exponentiallyhard due to the ubiquitous spread of correlations, limiting the frequencyresolution and thereby restricting this ansatz class mostly to one-dimensionalsystems with small quasi-particle velocities. Here, we show how thisfundamental limitation can be overcome using complex-time Krylov spaces. At theexample of the critical $S-1/2$ Heisenberg model and light bipolarons in thetwo-dimensional Su-Schrieffer-Heeger model, we demonstrate the enormousimprovements in accuracy, which can be achieved using this method.</description>
      <author>example@mail.com (Sebastian Paeckel)</author>
      <guid isPermaLink="false">2411.09680v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Motion Before Action: Diffusing Object Motion as Manipulation Condition</title>
      <link>http://arxiv.org/abs/2411.09658v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从观察中推断物体运动表示可以增强机器人操作任务的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的机器人模仿学习范式，通过推理物体运动生成动作序列。&lt;h4&gt;方法&lt;/h4&gt;引入MBA（Motion Before Action）模块，利用两级扩散过程进行物体运动生成和机器人动作生成。&lt;h4&gt;主要发现&lt;/h4&gt;MBA首先根据观察预测物体的未来姿态序列，然后利用该序列指导机器人动作生成。&lt;h4&gt;结论&lt;/h4&gt;MBA作为可插拔组件，可以灵活集成到现有的机器人操作策略中，显著提高多种操作任务的性能。&lt;h4&gt;实验&lt;/h4&gt;在模拟和真实环境中进行广泛实验，证明了该方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究为机器人模仿学习提供了一种新思路，提升了机器人的操作能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inferring object motion representations from observations enhances theperformance of robotic manipulation tasks. This paper introduces a new paradigmfor robot imitation learning that generates action sequences by reasoning aboutobject motion from visual observations. We propose MBA (Motion Before Action),a novel module that employs two cascaded diffusion processes for object motiongeneration and robot action generation under object motion guidance. MBA firstpredicts the future pose sequence of the object based on observations, thenuses this sequence as a condition to guide robot action generation. Designed asa plug-and-play component, MBA can be flexibly integrated into existing roboticmanipulation policies with diffusion action heads. Extensive experiments inboth simulated and real-world environments demonstrate that our approachsubstantially improves the performance of existing policies across a wide rangeof manipulation tasks.</description>
      <author>example@mail.com (Yup Su, Xinyu Zhan, Hongjie Fang, Yong-Lu Li, Cewu Lu, Lixin Yang)</author>
      <guid isPermaLink="false">2411.09658v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>DG-SLAM: Robust Dynamic Gaussian Splatting SLAM with Hybrid Pose Optimization</title>
      <link>http://arxiv.org/abs/2411.08373v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在动态场景中实现稳健且精确的姿态估计是视觉同时定位与地图构建（SLAM）中的重要研究挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DG-SLAM系统，以解决动态环境下姿态估计的困难。&lt;h4&gt;方法&lt;/h4&gt;引入3D高斯模型，采用运动掩膜生成、适应性高斯点管理和混合相机跟踪算法等策略来提升姿态估计的准确性和稳健性。&lt;h4&gt;主要发现&lt;/h4&gt;DG-SLAM在相机姿态估计、地图重建和新视图合成方面表现出色，超越现有方法并保持实时渲染能力。&lt;h4&gt;结论&lt;/h4&gt;DG-SLAM是首个基于3D高斯的稳健动态视觉SLAM系统，提供精确的相机姿态估计和高保真重建。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了在动态环境中进行高质量重建和姿态估计的有效方法，推动了SLAM技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving robust and precise pose estimation in dynamic scenes is asignificant research challenge in Visual Simultaneous Localization and Mapping(SLAM). Recent advancements integrating Gaussian Splatting into SLAM systemshave proven effective in creating high-quality renderings using explicit 3DGaussian models, significantly improving environmental reconstruction fidelity.However, these approaches depend on a static environment assumption and facechallenges in dynamic environments due to inconsistent observations of geometryand photometry. To address this problem, we propose DG-SLAM, the first robustdynamic visual SLAM system grounded in 3D Gaussians, which provides precisecamera pose estimation alongside high-fidelity reconstructions. Specifically,we propose effective strategies, including motion mask generation, adaptiveGaussian point management, and a hybrid camera tracking algorithm to improvethe accuracy and robustness of pose estimation. Extensive experimentsdemonstrate that DG-SLAM delivers state-of-the-art performance in camera poseestimation, map reconstruction, and novel-view synthesis in dynamic scenes,outperforming existing methods meanwhile preserving real-time renderingability.</description>
      <author>example@mail.com (Yueming Xu, Haochen Jiang, Zhongyang Xiao, Jianfeng Feng, Li Zhang)</author>
      <guid isPermaLink="false">2411.08373v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>CropCraft: Inverse Procedural Modeling for 3D Reconstruction of Crop Plants</title>
      <link>http://arxiv.org/abs/2411.09693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动从图像构建植物的3D数字双胞胎在农业、环境科学、机器人等领域有广泛应用，但现有的3D重建方法无法完整恢复植物形状。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，通过优化植物形态的参数模型，实现农业作物的3D重建。&lt;h4&gt;方法&lt;/h4&gt;首先通过拟合神经辐射场来估计深度图，然后使用贝叶斯优化来估计植物形态参数，以获得一致的深度渲染。&lt;h4&gt;主要发现&lt;/h4&gt;所得到的3D模型完整且生物学上合理。&lt;h4&gt;结论&lt;/h4&gt;在真实农业图像数据集上验证了该方法，重建结果可用于多种监测和模拟应用。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种有效的3D重建方法，解决了植物形状重建中的遮挡和复杂几何问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to automatically build 3D digital twins of plants from images hascountless applications in agriculture, environmental science, robotics, andother fields. However, current 3D reconstruction methods fail to recovercomplete shapes of plants due to heavy occlusion and complex geometries. Inthis work, we present a novel method for 3D reconstruction of agriculturalcrops based on optimizing a parametric model of plant morphology via inverseprocedural modeling. Our method first estimates depth maps by fitting a neuralradiance field and then employs Bayesian optimization to estimate plantmorphological parameters that result in consistent depth renderings. Theresulting 3D model is complete and biologically plausible. We validate ourmethod on a dataset of real images of agricultural fields, and demonstrate thatthe reconstructions can be used for a variety of monitoring and simulationapplications.</description>
      <author>example@mail.com (Albert J. Zhai, Xinlei Wang, Kaiyuan Li, Zhao Jiang, Junxiong Zhou, Sheng Wang, Zhenong Jin, Kaiyu Guan, Shenlong Wang)</author>
      <guid isPermaLink="false">2411.09693v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Tightly-Coupled, Speed-aided Monocular Visual-Inertial Localization in Topological Map</title>
      <link>http://arxiv.org/abs/2411.05497v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的车辆定位方法依赖于昂贵的传感器，如GPS和LiDAR，存在一定的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新算法，通过使用拓扑地图，实现基于单目视觉和惯性传感器的车辆速度辅助定位。&lt;h4&gt;方法&lt;/h4&gt;使用离线生成的LiDAR点云构建拓扑地图，该地图包含深度图、强度图和相应的相机姿态。通过当前相机图像与存储的拓扑图像之间的匹配进行实时定位，采用迭代误差状态卡尔曼滤波器（IESKF）进行优化姿态估计。&lt;h4&gt;主要发现&lt;/h4&gt;在开放数据集和自收集数据的实验中，算法在拓扑地图生成和定位任务中表现优越，尤其在隧道等挑战性场景下。&lt;h4&gt;结论&lt;/h4&gt;所提算法在使用相对廉价的摄像头进行定位方面显示出更高的准确性和可靠性，适用于复杂环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a novel algorithm for vehicle speed-aided monocularvisual-inertial localization using a topological map. The proposed system aimsto address the limitations of existing methods that rely heavily on expensivesensors like GPS and LiDAR by leveraging relatively inexpensive camera-basedpose estimation. The topological map is generated offline from LiDAR pointclouds and includes depth images, intensity images, and corresponding cameraposes. This map is then used for real-time localization through correspondencematching between current camera images and the stored topological images. Thesystem employs an Iterated Error State Kalman Filter (IESKF) for optimized poseestimation, incorporating correspondence among images and vehicle speedmeasurements to enhance accuracy. Experimental results using both open datasetand our collected data in challenging scenario, such as tunnel, demonstrate theproposed algorithm's superior performance in topological map generation andlocalization tasks.</description>
      <author>example@mail.com (Chanuk Yang, Hayeon O, Kunsoo Huh)</author>
      <guid isPermaLink="false">2411.05497v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>PointCG: Self-supervised Point Cloud Learning via Joint Completion and Generation</title>
      <link>http://arxiv.org/abs/2411.06041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督点云学习的核心在于设置合适的预训练任务，以构建能有效感知3D物体的编码器框架。&lt;h4&gt;目的&lt;/h4&gt;整合两种常见的方法——掩码点建模（MPM）和3D到2D生成，作为预训练框架内的预训练任务。&lt;h4&gt;方法&lt;/h4&gt;提出的框架称为PointCG，包含隐点补全（HPC）模块和任意视角图像生成（AIG）模块。&lt;h4&gt;主要发现&lt;/h4&gt;通过空间意识和精确监督解决了模糊监督信号和对几何信息的敏感性问题，实验表明该方法在各种下游任务中优于基线。&lt;h4&gt;结论&lt;/h4&gt;PointCG框架有效提升了点云学习的性能，代码将在论文接受后公开。&lt;h4&gt;总结&lt;/h4&gt;本研究通过结合两种方法，提出了一种新的点云学习框架，显著提高了对3D物体的感知能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The core of self-supervised point cloud learning lies in setting upappropriate pretext tasks, to construct a pre-training framework that enablesthe encoder to perceive 3D objects effectively. In this paper, we integrate twoprevalent methods, masked point modeling (MPM) and 3D-to-2D generation, aspretext tasks within a pre-training framework. We leverage the spatialawareness and precise supervision offered by these two methods to address theirrespective limitations: ambiguous supervision signals and insensitivity togeometric information. Specifically, the proposed framework, abbreviated asPointCG, consists of a Hidden Point Completion (HPC) module and anArbitrary-view Image Generation (AIG) module. We first capture visible pointsfrom arbitrary views as inputs by removing hidden points. Then, HPC extractsrepresentations of the inputs with an encoder and completes the entire shapewith a decoder, while AIG is used to generate rendered images based on thevisible points' representations. Extensive experiments demonstrate thesuperiority of the proposed method over the baselines in various downstreamtasks. Our code will be made available upon acceptance.</description>
      <author>example@mail.com (Yun Liu, Peng Li, Xuefeng Yan, Liangliang Nan, Bing Wang, Honghua Chen, Lina Gong, Wei Zhao, Mingqiang Wei)</author>
      <guid isPermaLink="false">2411.06041v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Linear Spherical Sliced Optimal Transport: A Fast Metric for Comparing Spherical Data</title>
      <link>http://arxiv.org/abs/2411.06055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉、地球科学和医学等领域，高效比较球形概率分布变得越来越重要。&lt;h4&gt;目的&lt;/h4&gt;开发切片最优传输距离方法，以满足对球形概率分布比较的需求。&lt;h4&gt;方法&lt;/h4&gt;提出线性球形切片最优传输（LSSOT）框架，通过切片将球形分布嵌入到L²空间，保持其内在几何特性。&lt;h4&gt;主要发现&lt;/h4&gt;LSSOT方法在计算效率上优于其他方法，并在皮层表面注册、3D点云插值及形状嵌入等应用中表现出色。&lt;h4&gt;结论&lt;/h4&gt;LSSOT显著提高了计算效率和准确性，是处理球形概率度量的有效工具。&lt;h4&gt;总结&lt;/h4&gt;LSSOT框架通过切片技术为球形概率分布提供了一种高效的比较指标，适用于多种实际应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient comparison of spherical probability distributions becomes importantin fields such as computer vision, geosciences, and medicine. Sliced optimaltransport distances, such as spherical and stereographic spherical slicedWasserstein distances, have recently been developed to address this need. Thesemethods reduce the computational burden of optimal transport by slicinghyperspheres into one-dimensional projections, i.e., lines or circles.Concurrently, linear optimal transport has been proposed to embed distributionsinto \( L^2 \) spaces, where the \( L^2 \) distance approximates the optimaltransport distance, thereby simplifying comparisons across multipledistributions. In this work, we introduce the Linear Spherical Sliced OptimalTransport (LSSOT) framework, which utilizes slicing to embed sphericaldistributions into \( L^2 \) spaces while preserving their intrinsic geometry,offering a computationally efficient metric for spherical probability measures.We establish the metricity of LSSOT and demonstrate its superior computationalefficiency in applications such as cortical surface registration, 3D pointcloud interpolation via gradient flow, and shape embedding. Our resultsdemonstrate the significant computational benefits and high accuracy of LSSOTin these applications.</description>
      <author>example@mail.com (Xinran Liu, Yikun Bai, Rocío Díaz Martín, Kaiwen Shi, Ashkan Shahbazi, Bennett A. Landman, Catie Chang, Soheil Kolouri)</author>
      <guid isPermaLink="false">2411.06055v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Constraints and Variables Reduction for Optimal Power Flow Using Hierarchical Graph Neural Networks with Virtual Node-Splitting</title>
      <link>http://arxiv.org/abs/2411.06268v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;电力系统网络通常被建模为同质图，这限制了图神经网络（GNN）捕捉同一节点的个别发电机特征的能力。&lt;h4&gt;目的&lt;/h4&gt;通过引入虚拟节点拆分策略，全方位捕捉发电机级属性，提高GNN的学习能力和预测准确性。&lt;h4&gt;方法&lt;/h4&gt;开发一种新颖的两阶段自适应层次GNN，首先预测可能出现拥堵的关键线路，然后预测将以最大容量运行的基础发电机。&lt;h4&gt;主要发现&lt;/h4&gt;提出的ROPFLG模型在计算时间上显著优于基准的全OPF（FOPF）和其他两种ROP模型，同时可靠地找到最优解。&lt;h4&gt;结论&lt;/h4&gt;通过虚拟节点拆分，ROPFLG模型有效减少了OPF所需的约束和变量，展示了在实时电网操作中的优势。&lt;h4&gt;总结&lt;/h4&gt;该研究通过创新的GNN模型提升了电力系统优化的效率，解决了计算复杂性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Power system networks are often modeled as homogeneous graphs, which limitsthe ability of graph neural network (GNN) to capture individual generatorfeatures at the same nodes. By introducing the proposed virtual node-splittingstrategy, generator-level attributes like costs, limits, and ramp rates can befully captured by GNN models, improving GNN's learning capacity and predictionaccuracy. Optimal power flow (OPF) problem is used for real-time gridoperations. Limited timeframe motivates studies to create size-reduced OPF(ROPF) models to relieve the computational complexity. In this paper, withvirtual node-splitting, a novel two-stage adaptive hierarchical GNN isdeveloped to (i) predict critical lines that would be congested, and then (ii)predict base generators that would operate at the maximum capacity. This willsubstantially reduce the constraints and variables needed for OPF, creating theproposed ROPFLG model with reduced monitor lines and reduced generator-specificvariables and constraints. Two ROPF models, ROPFL and ROPFG, with just reducedlines or generators respectively, are also implemented as additional benchmarkmodels. Case studies show that the proposed ROPFLG consistently outperforms thebenchmark full OPF (FOPF) and the other two ROPF methods, achieving significantcomputational time savings while reliably finding optimal solutions.</description>
      <author>example@mail.com (Thuan Phamh, Xingpeng Li)</author>
      <guid isPermaLink="false">2411.06268v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Reliable-loc: Robust sequential LiDAR global localization in large-scale street scenes based on verifiable cues</title>
      <link>http://arxiv.org/abs/2411.07815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;可穿戴激光扫描系统具有灵活性和便携性，适用于行人导航、协作映射、增强现实和紧急救援等应用。&lt;h4&gt;目的&lt;/h4&gt;解决现有基于LiDAR的全局定位方法在复杂大型户外场景中缺乏鲁棒性的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于LiDAR的可靠全局定位方法（Reliable-loc），利用序列LiDAR数据中的可验证线索，采用基于蒙特卡罗定位（MCL）和状态监测机制。&lt;h4&gt;主要发现&lt;/h4&gt;Reliable-loc在复杂街景中表现出高鲁棒性、准确性和效率，定位精度为1.66米，偏航精度为3.09度，且实现了实时性能。&lt;h4&gt;结论&lt;/h4&gt;所提方法在大型异构点云数据集上经过全面实验验证，显示出有效性。&lt;h4&gt;总结&lt;/h4&gt;Reliable-loc为改善LiDAR定位系统的鲁棒性提供了一种新的解决方案，适用于多种复杂场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zouxianghong/reliable-loc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wearable laser scanning (WLS) system has the advantages of flexibility andportability. It can be used for determining the user's path within a prior map,which is a huge demand for applications in pedestrian navigation, collaborativemapping, augmented reality, and emergency rescue. However, existing LiDAR-basedglobal localization methods suffer from insufficient robustness, especially incomplex large-scale outdoor scenes with insufficient features and incompletecoverage of the prior map. To address such challenges, we propose LiDAR-basedreliable global localization (Reliable-loc) exploiting the verifiable cues inthe sequential LiDAR data. First, we propose a Monte Carlo Localization (MCL)based on spatially verifiable cues, utilizing the rich information embedded inlocal features to adjust the particles' weights hence avoiding the particlesconverging to erroneous regions. Second, we propose a localization statusmonitoring mechanism guided by the sequential pose uncertainties and adaptivelyswitching the localization mode using the temporal verifiable cues to avoid thecrash of the localization system. To validate the proposed Reliable-loc,comprehensive experiments have been conducted on a large-scale heterogeneouspoint cloud dataset consisting of high-precision vehicle-mounted mobile laserscanning (MLS) point clouds and helmet-mounted WLS point clouds, which covervarious street scenes with a length of over 20km. The experimental resultsindicate that Reliable-loc exhibits high robustness, accuracy, and efficiencyin large-scale, complex street scenes, with a position accuracy of 1.66m, yawaccuracy of 3.09 degrees, and achieves real-time performance. For the code anddetailed experimental results, please refer tohttps://github.com/zouxianghong/Reliable-loc.</description>
      <author>example@mail.com (Xianghong Zou, Jianping Li, Weitong Wu, Fuxun Liang, Bisheng Yang, Zhen Dong)</author>
      <guid isPermaLink="false">2411.07815v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>NatureLM-audio: an Audio-Language Foundation Model for Bioacoustics</title>
      <link>http://arxiv.org/abs/2411.07186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Demo page: https://earthspecies.github.io/naturelm-audio-demo/ The
  code will be open-sourced and available shortly&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在语音、音乐和一般音频等各类听觉任务中表现出色，但在生物声学任务中的应用尚未充分展示。&lt;h4&gt;目的&lt;/h4&gt;开发NatureLM-audio，首个专为生物声学设计的音频语言基础模型。&lt;h4&gt;方法&lt;/h4&gt;使用精心策划的训练数据集，包括多种生物声学、语音和音乐数据的文本-音频对，以应对领域内有限注释数据集的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;模型成功实现了从音乐和语音到生物声学的知识迁移，并在多个生物声学任务上（包括未见物种的零样本分类）设定了新的状态。&lt;h4&gt;结论&lt;/h4&gt;NatureLM-audio展示了其在生物声学研究中的潜力，并开源了生成训练和基准数据的代码，以及模型训练的相关代码。&lt;h4&gt;总结&lt;/h4&gt;该研究为保护和生物多样性监测提供了新的工具，并推动了动物行为研究的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) prompted with text and audio represent the stateof the art in various auditory tasks, including speech, music, and generalaudio, showing emergent abilities on unseen tasks. However, these capabilitieshave yet to be fully demonstrated in bioacoustics tasks, such as detectinganimal vocalizations in large recordings, classifying rare and endangeredspecies, and labeling context and behavior - tasks that are crucial forconservation, biodiversity monitoring, and the study of animal behavior. Inthis work, we present NatureLM-audio, the first audio-language foundation modelspecifically designed for bioacoustics. Our carefully curated training datasetcomprises text-audio pairs spanning a diverse range of bioacoustics, speech,and music data, designed to address the challenges posed by limited annotateddatasets in the field. We demonstrate successful transfer of learnedrepresentations from music and speech to bioacoustics, and our model showspromising generalization to unseen taxa and tasks. Importantly, we testNatureLM-audio on a novel benchmark (BEANS-Zero) and it sets the new state ofthe art (SotA) on several bioacoustics tasks, including zero-shotclassification of unseen species. To advance bioacoustics research, we alsoopen-source the code for generating training and benchmark data, as well as fortraining the model.</description>
      <author>example@mail.com (David Robinson, Marius Miron, Masato Hagiwara, Olivier Pietquin)</author>
      <guid isPermaLink="false">2411.07186v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>GSL-PCD: Improving Generalist-Specialist Learning with Point Cloud Feature-based Task Partitioning</title>
      <link>http://arxiv.org/abs/2411.06733v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度强化学习（DRL）在未见环境变化中的泛化能力往往需要在多样化场景中训练，但许多现有算法在处理大量变化时效率较低。&lt;h4&gt;目的&lt;/h4&gt;提出一种改进的通用-专家学习框架，以提升处理环境变化的效率。&lt;h4&gt;方法&lt;/h4&gt;通过对环境变化进行基于点云特征的任务划分，使用贪婪算法将相似变化分配给同一专家，以提高任务划分的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;基于点云特征的划分方法比传统随机划分提高了9.4%的性能，并将计算和样本需求降低了50%。&lt;h4&gt;结论&lt;/h4&gt;GSL-PCD方法在机器人操作任务中表现优越，能够实现较高的性能和更低的计算成本。&lt;h4&gt;总结&lt;/h4&gt;GSL-PCD通过改进任务划分策略，提高了深度强化学习在多变环境中的效率和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalization in Deep Reinforcement Learning (DRL) across unseen environmentvariations often requires training over a diverse set of scenarios. Manyexisting DRL algorithms struggle with efficiency when handling numerousvariations. The Generalist-Specialist Learning (GSL) framework addresses thisby first training a generalist model on all variations, then creatingspecialists from the generalist's weights, each focusing on a subset ofvariations. The generalist then refines its learning with assistance from thespecialists. However, random task partitioning in GSL can impede performance byassigning vastly different variations to the same specialist, often resultingin each specialist focusing on only one variation, which raises computationalcosts. To improve this, we propose Generalist-Specialist Learning with PointCloud Feature-based Task Partitioning (GSL-PCD). Our approach clustersenvironment variations based on features extracted from object point clouds anduses balanced clustering with a greedy algorithm to assign similar variationsto the same specialist. Evaluations on robotic manipulation tasks from theManiSkill benchmark demonstrate that point cloud feature-based partitioningoutperforms vanilla partitioning by 9.4%, with a fixed number of specialists,and reduces computational and sample requirements by 50% to achieve comparableperformance.</description>
      <author>example@mail.com (Xiu Yuan)</author>
      <guid isPermaLink="false">2411.06733v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning Approaches for BSM Physics: Evaluating DNN and GNN Performance in Particle Collision Event Classification</title>
      <link>http://arxiv.org/abs/2411.06487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in APPB&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在高能粒子碰撞中，检测超出标准模型（BSM）的信号面临复杂数据和区分稀有信号事件与标准模型（SM）背景的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究深度学习模型在分类粒子碰撞事件为BSM信号或背景中的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用包含214,000个SM背景和10,755个BSM事件的数据集，采用欠采样方法解决类别不平衡问题，开发并比较了三种模型：一个DNN和两个不同图构建方法的GNN变体。&lt;h4&gt;主要发现&lt;/h4&gt;所有模型表现出高性能，接收者操作特征曲线下的面积（AUC）值超过94%。DNN模型在多项指标上略优于GNN，但两种GNN方法在不同图结构下表现相近。&lt;h4&gt;结论&lt;/h4&gt;GNN能够明确捕捉事件中粒子间的关系，显示出其在BSM信号检测中的潜力。&lt;h4&gt;总结&lt;/h4&gt;深度学习模型在粒子碰撞事件分类中表现出色，尤其是GNN在处理粒子间关系方面具有优势，值得进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting Beyond Standard Model (BSM) signals in high-energy particlecollisions presents significant challenges due to complex data and the need todifferentiate rare signal events from Standard Model (SM) backgrounds. Thisstudy investigates the efficacy of deep learning models, specifically DeepNeural Networks (DNNs) and Graph Neural Networks (GNNs), in classifyingparticle collision events as either BSM signal or background. The researchutilized a dataset comprising 214,000 SM background and 10,755 BSM events. Toaddress class imbalance, an undersampling method was employed, resulting inbalanced classes. Three models were developed and compared: a DNN and two GNNvariants with different graph construction methods. All models demonstratedhigh performance, achieving Area Under the Receiver Operating Characteristiccurve (AUC) values exceeding $94\%$. While the DNN model slightly outperformedGNNs across various metrics, both GNN approaches showed comparable resultsdespite different graph structures. The GNNs' ability to explicitly captureinter-particle relationships within events highlights their potential for BSMsignal detection.</description>
      <author>example@mail.com (Ali Çelik)</author>
      <guid isPermaLink="false">2411.06487v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Post-Hoc Robustness Enhancement in Graph Neural Networks with Conditional Random Fields</title>
      <link>http://arxiv.org/abs/2411.05399v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）是当前图表示学习的基准方法，但对抗攻击使其在实际应用中存在脆弱性。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提高GNNs在推理阶段的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种后处理方法RobustCRF，基于条件随机场的统计关系学习，具有模型无关性，无需了解底层模型架构。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个模型上进行了验证，使用基准节点分类数据集展现了其有效性。&lt;h4&gt;结论&lt;/h4&gt;RobustCRF能够增强GNNs在推理阶段的鲁棒性，为实际应用提供了新的防御策略。&lt;h4&gt;总结&lt;/h4&gt;研究填补了GNNs推理阶段鲁棒性提升的空白，提出的RobustCRF方法有效且通用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs), which are nowadays the benchmark approach ingraph representation learning, have been shown to be vulnerable to adversarialattacks, raising concerns about their real-world applicability. While existingdefense techniques primarily concentrate on the training phase of GNNs,involving adjustments to message passing architectures or pre-processingmethods, there is a noticeable gap in methods focusing on increasing robustnessduring inference. In this context, this study introduces RobustCRF, a post-hocapproach aiming to enhance the robustness of GNNs at the inference stage. Ourproposed method, founded on statistical relational learning using a ConditionalRandom Field, is model-agnostic and does not require prior knowledge about theunderlying model architecture. We validate the efficacy of this approach acrossvarious models, leveraging benchmark node classification datasets.</description>
      <author>example@mail.com (Yassine Abbahaddou, Sofiane Ennadir, Johannes F. Lutzeyer, Fragkiskos D. Malliaros, Michalis Vazirgiannis)</author>
      <guid isPermaLink="false">2411.05399v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Towards Graph Neural Network Surrogates Leveraging Mechanistic Expert Knowledge for Pandemic Response</title>
      <link>http://arxiv.org/abs/2411.06500v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在COVID-19危机期间，机械模型被证明对基于证据的决策至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合复杂机械模型和数据驱动替代模型的方法，以便公共卫生专家能够迅速适应模型。&lt;h4&gt;方法&lt;/h4&gt;构建一个空间和人口统计学分辨率的传染病模型，并为代表疫情早期阶段的数据集训练图神经网络。&lt;h4&gt;主要发现&lt;/h4&gt;训练后的网络执行时间少于一秒，相较于元人口方法显著加速。&lt;h4&gt;结论&lt;/h4&gt;所建议的方法具有即时执行的潜力，因此可以在低门槛网站应用中集成疾病动态模型。&lt;h4&gt;未来工作&lt;/h4&gt;为决策使用，必须考虑更大方差的数据集。&lt;h4&gt;总结&lt;/h4&gt;结合机械模型与数据驱动模型可提高应对疫情动态变化的决策效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; During the COVID-19 crisis, mechanistic models have been proven fundamentalto guide evidence-based decision making. However, time-critical decisions in adynamically changing environment restrict the time available for modelers togather supporting evidence. As infectious disease dynamics are oftenheterogeneous on a spatial or demographic scale, models should be resolvedaccordingly. In addition, with a large number of potential interventions, allscenarios can barely be computed on time, even when using supercomputingfacilities. We suggest to combine complex mechanistic models with data-drivensurrogate models to allow for on-the-fly model adaptations by public healthexperts. We build upon a spatially and demographically resolved infectiousdisease model and train a graph neural network for data sets representing earlyphases of the pandemic. The resulting networks reached an execution time ofless than a second, a significant speedup compared to the metapopulationapproach. The suggested approach yields potential for on-the-fly execution and,thus, integration of disease dynamics models in low-barrier websiteapplications. For the approach to be used with decision-making, datasets withlarger variance will have to be considered.</description>
      <author>example@mail.com (Agatha Schmidt, Henrik Zunker, Alexander Heinlein, Martin J. Kühn)</author>
      <guid isPermaLink="false">2411.06500v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>POC-SLT: Partial Object Completion with SDF Latent Transformers</title>
      <link>http://arxiv.org/abs/2411.05419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D几何形状完成依赖于表示学习和对几何数据的深入理解。&lt;h4&gt;目的&lt;/h4&gt;解决在部分观察下进行3D形状完成的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出一种在表示签名距离场（SDF）的潜在空间上操作的变换器，利用平滑的潜在空间编码，通过变分自编码器（VAE）训练数百万个3D补丁。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的POC-SLT架构在ShapeNet和ABC数据集的部分观察上表现优越，相较于多种基线最先进方法，3D形状完成有显著提升。&lt;h4&gt;结论&lt;/h4&gt;该方法在定性和定量上都显著改善了3D形状完成的效果。&lt;h4&gt;总结&lt;/h4&gt;通过变换器和潜在空间编码的结合，成功提高了对3D形状的补全能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D geometric shape completion hinges on representation learning and a deepunderstanding of geometric data. Without profound insights into thethree-dimensional nature of the data, this task remains unattainable. Our workaddresses this challenge of 3D shape completion given partial observations byproposing a transformer operating on the latent space representing SignedDistance Fields (SDFs). Instead of a monolithic volume, the SDF of an object ispartitioned into smaller high-resolution patches leading to a sequence oflatent codes. The approach relies on a smooth latent space encoding learned viaa variational autoencoder (VAE), trained on millions of 3D patches. We employan efficient masked autoencoder transformer to complete partial sequences intocomprehensive shapes in latent space. Our approach is extensively evaluated onpartial observations from ShapeNet and the ABC dataset where only fractions ofthe objects are given. The proposed POC-SLT architecture compares favorablywith several baseline state-of-the-art methods, demonstrating a significantimprovement in 3D shape completion, both qualitatively and quantitatively.</description>
      <author>example@mail.com (Faezeh Zakeri, Raphael Braun, Lukas Ruppert, Henrik P. A. Lensch)</author>
      <guid isPermaLink="false">2411.05419v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>SIESEF-FusionNet: Spatial Inter-correlation Enhancement and Spatially-Embedded Feature Fusion Network for LiDAR Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2411.06991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云语义分割中不同语义类别边界的模糊性常导致智能感知系统（如自动驾驶）中的错误决策。&lt;h4&gt;目的&lt;/h4&gt;准确划定边界以提高自动驾驶的安全性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的空间互相关增强和空间嵌入特征融合网络（SIESEF-FusionNet），通过结合逆距离加权和角补偿来增强空间互相关，从而提取更多有用的空间信息，避免冗余。同时设计了新的空间自适应池化模块，将增强的空间信息嵌入语义特征中，以增强语义特征的上下文感知能力。&lt;h4&gt;主要发现&lt;/h4&gt;在Toronto3D数据集上，SIESEF-FusionNet达到了83.7%的mIoU和97.8%的OA，性能优于其他基线方法。在semanticKITTI数据集上，mIoU达到了61.1%，显示出分割性能的显著提升。&lt;h4&gt;结论&lt;/h4&gt;通过消融研究进一步验证了所提模块的有效性和即插即用能力。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的网络和模块显著提升了点云语义分割的性能，为自动驾驶系统的安全性提供了支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ambiguity at the boundaries of different semantic classes in point cloudsemantic segmentation often leads to incorrect decisions in intelligentperception systems, such as autonomous driving. Hence, accurate delineation ofthe boundaries is crucial for improving safety in autonomous driving. A novelspatial inter-correlation enhancement and spatially-embedded feature fusionnetwork (SIESEF-FusionNet) is proposed in this paper, enhancing spatialinter-correlation by combining inverse distance weighting and angularcompensation to extract more beneficial spatial information without causingredundancy. Meanwhile, a new spatial adaptive pooling module is also designed,embedding enhanced spatial information into semantic features for strengtheningthe context-awareness of semantic features. Experimental results demonstratethat 83.7% mIoU and 97.8% OA are achieved by SIESEF-FusionNet on the Toronto3Ddataset, with performance superior to other baseline methods. A value of 61.1%mIoU is reached on the semanticKITTI dataset, where a marked improvement insegmentation performance is observed. In addition, the effectiveness andplug-and-play capability of the proposed modules are further verified throughablation studies.</description>
      <author>example@mail.com (Jiale Chen, Fei Xia, Jianliang Mao, Haoping Wang, Chuanlin Zhang)</author>
      <guid isPermaLink="false">2411.06991v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for modelling breast biomechanical compression</title>
      <link>http://arxiv.org/abs/2411.06596v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Deep Breath @ MICCAI 2024 | The code is available at this URL:
  https://github.com/hadiiiil/GNNs-BreastCompression&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;乳房压缩模拟对于从3D模态到X光程序（如乳腺摄影）的准确图像配准至关重要，能够考虑到由于压缩造成的组织形状和位置变化。&lt;h4&gt;目的&lt;/h4&gt;探索基于物理的图神经网络（PhysGNN）在乳房压缩模拟中的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;使用PhysGNN进行数据驱动建模，结合网格结构信息，训练模型以捕捉复杂的乳腺组织几何形状，基于增量有限元分析（FEA）模拟的变形数据进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;PhysGNN在预测乳房压缩过程中的变形表现出优越性，能够与有限元（FE）模拟的节点位移进行比较。&lt;h4&gt;结论&lt;/h4&gt;该深度学习框架展现了快速、准确的乳房变形近似能力，为实际场景提供了更高的计算效率。&lt;h4&gt;总结&lt;/h4&gt;PhysGNN为乳房压缩模拟提供了一种新颖且高效的方法，有助于改善乳腺摄影图像的分析与处理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hadiiiil/gnns-breastcompression&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Breast compression simulation is essential for accurate image registrationfrom 3D modalities to X-ray procedures like mammography. It accounts for tissueshape and position changes due to compression, ensuring precise alignment andimproved analysis. Although Finite Element Analysis (FEA) is reliable forapproximating soft tissue deformation, it struggles with balancing accuracy andcomputational efficiency. Recent studies have used data-driven models trainedon FEA results to speed up tissue deformation predictions. We propose toexplore Physics-based Graph Neural Networks (PhysGNN) for breast compressionsimulation. PhysGNN has been used for data-driven modelling in other domains,and this work presents the first investigation of their potential in predictingbreast deformation during mammographic compression. Unlike conventionaldata-driven models, PhysGNN, which incorporates mesh structural information andenables inductive learning on unstructured grids, is well-suited for capturingcomplex breast tissue geometries. Trained on deformations from incremental FEAsimulations, PhysGNN's performance is evaluated by comparing predicted nodaldisplacements with those from finite element (FE) simulations. This deeplearning (DL) framework shows promise for accurate, rapid breast deformationapproximations, offering enhanced computational efficiency for real-worldscenarios.</description>
      <author>example@mail.com (Hadeel Awwad, Eloy García, Robert Martí)</author>
      <guid isPermaLink="false">2411.06596v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Language</title>
      <link>http://arxiv.org/abs/2411.05172v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;处理隐含语言对于自然语言处理系统实现精确文本理解和促进用户自然交互至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种可量化语言隐含程度的标量度量，填补没有强大度量工具的空白。&lt;h4&gt;方法&lt;/h4&gt;定义隐含性为语义意义与语用解释之间的偏差，提出了一种名为ImpScore的新型无参考度量，通过可解释的回归模型进行公式化，并利用成对对比学习在特制数据集上进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;通过用户研究验证ImpScore的评估与人类评估在数据集外的准确性和强相关性。&lt;h4&gt;结论&lt;/h4&gt;ImpScore在仇恨言论检测数据集中的应用展示了其实用性，并指出当前大型语言模型在理解高度隐含内容方面的显著局限性。&lt;h4&gt;总结&lt;/h4&gt;ImpScore的度量模型及其训练数据可在https://github.com/audreycs/ImpScore获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/audreycs/impscore&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Handling implicit language is essential for natural language processingsystems to achieve precise text understanding and facilitate naturalinteractions with users. Despite its importance, the absence of a robust metricfor accurately measuring the implicitness of language significantly constrainsthe depth of analysis possible in evaluating models' comprehensioncapabilities. This paper addresses this gap by developing a scalar metric thatquantifies the implicitness level of language without relying on externalreferences. Drawing on principles from traditional linguistics, we define''implicitness'' as the divergence between semantic meaning and pragmaticinterpretation. To operationalize this definition, we introduce ImpScore, anovel, reference-free metric formulated through an interpretable regressionmodel. This model is trained using pairwise contrastive learning on a speciallycurated dataset comprising $112,580$ (implicit sentence, explicit sentence)pairs. We validate ImpScore through a user study that compares its assessmentswith human evaluations on out-of-distribution data, demonstrating its accuracyand strong correlation with human judgments. Additionally, we apply ImpScore tohate speech detection datasets, illustrating its utility and highlightingsignificant limitations in current large language models' ability to understandhighly implicit content. The metric model and its training data are availableat https://github.com/audreycs/ImpScore.</description>
      <author>example@mail.com (Yuxin Wang, Xiaomeng Zhu, Weimin Lyu, Saeed Hassanpour, Soroush Vosoughi)</author>
      <guid isPermaLink="false">2411.05172v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Video RWKV:Video Action Recognition Based RWKV</title>
      <link>http://arxiv.org/abs/2411.05636v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有视频理解方法（如CNN和Transformers）面临高计算成本和长距离依赖的问题。&lt;h4&gt;目的&lt;/h4&gt;引入RWKV到视频领域，提出LSTM CrossRWKV (LCR)框架，以进行时空表示学习，解决视频理解任务。&lt;h4&gt;方法&lt;/h4&gt;LCR框架结合了新颖的Cross RWKV门，增强当前帧边缘信息与过去特征的交互，利用增强的LSTM机制存储长时记忆。&lt;h4&gt;主要发现&lt;/h4&gt;LCR有效捕获空间和时间特征，边缘信息作为LSTM的遗忘门，指导长时记忆管理。&lt;h4&gt;结论&lt;/h4&gt;通过Tube masking策略减少冗余信息和过拟合，LSTM CrossRWKV在视频理解领域设定了新基准，为全面视频分析提供了可扩展和高效的解决方案。&lt;h4&gt;总结&lt;/h4&gt;所有代码和模型均已公开，促进了视频理解研究的进一步发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To address the challenges of high computational costs and long-distancedependencies in exist ing video understanding methods, such as CNNs andTransformers, this work introduces RWKV to the video domain in a novel way. Wepropose a LSTM CrossRWKV (LCR) framework, designed for spatiotemporalrepresentation learning to tackle the video understanding task. Specifically,the proposed linear complexity LCR incorporates a novel Cross RWKV gate tofacilitate interaction be tween current frame edge information and pastfeatures, enhancing the focus on the subject through edge features and globallyaggregating inter-frame features over time. LCR stores long-term mem ory forvideo processing through an enhanced LSTM recurrent execution mechanism. Byleveraging the Cross RWKV gate and recurrent execution, LCR effectivelycaptures both spatial and temporal features. Additionally, the edge informationserves as a forgetting gate for LSTM, guiding long-term memory management.Tubemasking strategy reduces redundant information in food and reducesoverfitting.These advantages enable LSTM CrossRWKV to set a new benchmark invideo under standing, offering a scalable and efficient solution forcomprehensive video analysis. All code and models are publicly available.</description>
      <author>example@mail.com (Zhuowen Yin, Chengru Li, Xingbo Dong)</author>
      <guid isPermaLink="false">2411.05636v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>MureObjectStitch: Multi-reference Image Composition</title>
      <link>http://arxiv.org/abs/2411.07462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成图像合成旨在将给定的前景物体再生到背景图像中，以生成逼真的合成图像。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的微调策略，用于生成图像合成模型。&lt;h4&gt;方法&lt;/h4&gt;通过使用包含相同前景物体的一张或多张图像对预训练模型进行微调，并引入多参考策略，允许模型接受多个前景物体的参考图像。&lt;h4&gt;主要发现&lt;/h4&gt;在MureCOM数据集上的实验验证了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提方法提高了生成图像合成的质量。&lt;h4&gt;总结&lt;/h4&gt;本研究实现了生成图像合成中的前景物体再生，并通过有效的微调和多参考策略提升了合成效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bcmi/mureobjectstitch-image-composition&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative image composition aims to regenerate the given foreground objectin the background image to produce a realistic composite image. In this work,we propose an effective finetuning strategy for generative image compositionmodel, in which we finetune a pretrained model using one or more imagescontaining the same foreground object. Moreover, we propose a multi-referencestrategy, which allows the model to take in multiple reference images of theforeground object. The experiments on MureCOM dataset verify the effectivenessof our method.</description>
      <author>example@mail.com (Jiaxuan Chen, Bo Zhang, Li Niu)</author>
      <guid isPermaLink="false">2411.07462v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Inductive Graph Few-shot Class Incremental Learning</title>
      <link>http://arxiv.org/abs/2411.06634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络（GNN）节点分类与图少样本类增量学习（GFSCIL）存在区别，后者涉及随着时间的推移，图节点和类的稀疏增长。&lt;h4&gt;目的&lt;/h4&gt;提出一种归纳式GFSCIL，能够在不访问旧数据的情况下，持续学习新出现的类和节点，同时保持对旧类的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了一种名为拓扑基础类增强和原型校准（TAP）的方法，采用三分支多拓扑类增强以提升模型的泛化能力，并通过迭代原型校准改善类原型的分离性。&lt;h4&gt;主要发现&lt;/h4&gt;在增量学习中，由于新类样本数量有限，采用的多拓扑类增强方法和原型位移方法有效应对了特征分布漂移问题，确保旧类原型的有效性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在四个数据集上展示了良好的性能，解决了传统增量学习中的灾难性遗忘和过拟合问题。&lt;h4&gt;总结&lt;/h4&gt;该研究为图神经网络在增量学习中的应用提供了一种新的思路，能够在不断变化的环境中保持学习性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node classification with Graph Neural Networks (GNN) under a fixed set oflabels is well known in contrast to Graph Few-Shot Class Incremental Learning(GFSCIL), which involves learning a GNN classifier as graph nodes and classesgrowing over time sporadically. We introduce inductive GFSCIL that continuallylearns novel classes with newly emerging nodes while maintaining performance onold classes without accessing previous data. This addresses the practicalconcern of transductive GFSCIL, which requires storing the entire graph withhistorical data. Compared to the transductive GFSCIL, the inductive settingexacerbates catastrophic forgetting due to inaccessible previous data duringincremental training, in addition to overfitting issue caused by labelsparsity. Thus, we propose a novel method, called Topology-based classAugmentation and Prototype calibration (TAP). To be specific, it first createsa triple-branch multi-topology class augmentation method to enhance modelgeneralization ability. As each incremental session receives a disjointsubgraph with nodes of novel classes, the multi-topology class augmentationmethod helps replicate such a setting in the base session to boost backboneversatility. In incremental learning, given the limited number of novel classsamples, we propose an iterative prototype calibration to improve theseparation of class prototypes. Furthermore, as backbone fine-tuning poses thefeature distribution drift, prototypes of old classes start failing over time,we propose the prototype shift method for old classes to compensate for thedrift. We showcase the proposed method on four datasets.</description>
      <author>example@mail.com (Yayong Li, Peyman Moghadam, Can Peng, Nan Ye, Piotr Koniusz)</author>
      <guid isPermaLink="false">2411.06634v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Mesh Generation via Compressive Tokenization</title>
      <link>http://arxiv.org/abs/2411.07025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Homepage: https://whaohan.github.io/bpt , Code:
  https://github.com/whaohan/bpt&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究提出了一种高效的网格表示方法，称为被阻塞和分块标记化（BPT），旨在生成超过8k面的网格。&lt;h4&gt;目的&lt;/h4&gt;通过压缩网格序列，提高网格生成的细节丰富性和生成的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;BPT通过块索引和补丁聚合来压缩网格序列，长度减少约75%。&lt;h4&gt;主要发现&lt;/h4&gt;BPT的应用使得可以处理面数显著更多的网格数据，从而提升了生成的细节和准确性。&lt;h4&gt;结论&lt;/h4&gt;基于BPT构建的网格生成模型能够灵活控制点云和图像，达到最新性能标准，并适合直接产品使用。&lt;h4&gt;总结&lt;/h4&gt;BPT方法为网格生成提供了有效的压缩和高质量生成能力，推动了网格生成技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/whaohan/bpt&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a compressive yet effective mesh representation, Blocked andPatchified Tokenization (BPT), facilitating the generation of meshes exceeding8k faces. BPT compresses mesh sequences by employing block-wise indexing andpatch aggregation, reducing their length by approximately 75\% compared to theoriginal sequences. This compression milestone unlocks the potential to utilizemesh data with significantly more faces, thereby enhancing detail richness andimproving generation robustness. Empowered with the BPT, we have built afoundation mesh generative model training on scaled mesh data to supportflexible control for point clouds and images. Our model demonstrates thecapability to generate meshes with intricate details and accurate topology,achieving SoTA performance on mesh generation and reaching the level for directproduct usage.</description>
      <author>example@mail.com (Haohan Weng, Zibo Zhao, Biwen Lei, Xianghui Yang, Jian Liu, Zeqiang Lai, Zhuo Chen, Yuhong Liu, Jie Jiang, Chunchao Guo, Tong Zhang, Shenghua Gao, C. L. Philip Chen)</author>
      <guid isPermaLink="false">2411.07025v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>MSEG-VCUQ: Multimodal SEGmentation with Enhanced Vision Foundation Models, Convolutional Neural Networks, and Uncertainty Quantification for High-Speed Video Phase Detection Data</title>
      <link>http://arxiv.org/abs/2411.07463v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review in EAAI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高速度视频相位检测分割在核反应堆、化工处理和电子冷却中至关重要，用于检测气体、液体和微层相位。&lt;h4&gt;目的&lt;/h4&gt;提出MSEG-VCUQ，通过引入VideoSAM，提升多模态数据的分割精度与泛化能力。&lt;h4&gt;方法&lt;/h4&gt;VideoSAM结合了U-Net卷积神经网络和Segment Anything Model (SAM)，用于在多种高速度视频相位检测模式下进行高级特征提取和分割，同时包含不确定性量化来评估像素级离散化误差。&lt;h4&gt;主要发现&lt;/h4&gt;VideoSAM在分割精度上优于SAM和特定模态的CNN模型，特别是在复杂相界面、重叠气泡和动态液-气相互作用的环境中表现卓越。&lt;h4&gt;结论&lt;/h4&gt;MSEG-VCUQ通过VideoSAM为高速度视频相位检测分割提供了一个强大的解决方案，解决了之前的局限，支持多模态数据集的可扩展、精确和适应性分割。&lt;h4&gt;总结&lt;/h4&gt;该研究的代码和数据公开可用，促进高速度视频分析和自主实验的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chikap421/mseg_vcuq&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: High-speed video (HSV) phase detection (PD) segmentation is vital innuclear reactors, chemical processing, and electronics cooling for detectingvapor, liquid, and microlayer phases. Traditional segmentation models facepixel-level accuracy and generalization issues in multimodal data. MSEG-VCUQintroduces VideoSAM, a hybrid framework leveraging convolutional neuralnetworks (CNNs) and transformer-based vision models to enhance segmentationaccuracy and generalizability across complex multimodal PD tasks. Methods:VideoSAM combines U-Net CNN and the Segment Anything Model (SAM) for advancedfeature extraction and segmentation across diverse HSV PD modalities, spanningfluids like water, FC-72, nitrogen, and argon under varied heat fluxconditions. The framework also incorporates uncertainty quantification (UQ) toassess pixel-based discretization errors, delivering reliable metrics such ascontact line density and dry area fraction under experimental conditions.Results: VideoSAM outperforms SAM and modality-specific CNN models insegmentation accuracy, excelling in environments with complex phase boundaries,overlapping bubbles, and dynamic liquid-vapor interactions. Its hybridarchitecture supports cross-dataset generalization, adapting effectively tovarying modalities. The UQ module provides accurate error estimates, enhancingthe reliability of segmentation outputs for advanced HSV PD research.Conclusion: MSEG-VCUQ, via VideoSAM, offers a robust solution for HSV PDsegmentation, addressing previous limitations with advanced deep learning andUQ techniques. The open-source datasets and tools introduced enable scalable,precise, and adaptable segmentation for multimodal PD datasets, supportingadvancements in HSV analysis and autonomous experimentation. The codes and dataused for this paper are publicly available at:\url{https://github.com/chikap421/mseg_vcuq}</description>
      <author>example@mail.com (Chika Maduabuchi, Ericmoore Jossou, Matteo Bucci)</author>
      <guid isPermaLink="false">2411.07463v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Speech-Based Estimation of Schizophrenia Severity Using Feature Fusion</title>
      <link>http://arxiv.org/abs/2411.06033v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted for SPADE workshop at ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，基于语音的精神分裂症谱系评估受到广泛研究。&lt;h4&gt;目的&lt;/h4&gt;开发一个深度学习框架，通过融合特征来估计精神分裂症的严重程度评分。&lt;h4&gt;方法&lt;/h4&gt;采用特征融合方法，将发音特征与从预训练音频模型提取的自我监督语音特征结合，并提出基于自编码器的自我监督表示学习框架以提取紧凑的发音嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;与以前结合语音和视频输入的模型相比，使用多头注意力（MHA）的最佳语音融合模型在精神分裂症严重性估计中，平均绝对误差（MAE）减少了9.18%，均方根误差（RMSE）减少了9.36%。&lt;h4&gt;结论&lt;/h4&gt;该研究表明，基于语音的评估模型在精神分裂症严重性估计上具有更高的准确性。&lt;h4&gt;总结&lt;/h4&gt;本研究通过深度学习和特征融合方法，提升了精神分裂症的语音评估效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech-based assessment of the schizophrenia spectrum has been widelyresearched over in the recent past. In this study, we develop a deep learningframework to estimate schizophrenia severity scores from speech using a featurefusion approach that fuses articulatory features with different self-supervisedspeech features extracted from pre-trained audio models. We also propose anauto-encoder-based self-supervised representation learning framework to extractcompact articulatory embeddings from speech. Our top-performing speech-basedfusion model with Multi-Head Attention (MHA) reduces Mean Absolute Error (MAE)by 9.18% and Root Mean Squared Error (RMSE) by 9.36% for schizophrenia severityestimation when compared with the previous models that combined speech andvideo inputs.</description>
      <author>example@mail.com (Gowtham Premananth, Carol Espy-Wilson)</author>
      <guid isPermaLink="false">2411.06033v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Automatic Contact-Based 3D Scanning Using Articulated Robotic Arm</title>
      <link>http://arxiv.org/abs/2411.07047v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文介绍了一种开放式的六自由度机器人系统，用于对象的三维扫描，采用接触式方法。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够进行高效三维扫描的机器人系统。&lt;h4&gt;方法&lt;/h4&gt;使用数字探头检测与物体的接触，采用逆运动学确定关节角度，并实现直线路径规划。&lt;h4&gt;主要发现&lt;/h4&gt;该系统能够进行单点测量和自由形状表面的三维扫描，并根据指定的区域自动执行扫描。&lt;h4&gt;结论&lt;/h4&gt;系统生成的三维扫描结果采用标准三角形语言（STL）格式，确保与常用3D软件的兼容性。&lt;h4&gt;测试&lt;/h4&gt;根据ASME B89.4.22标准进行的测试量化了系统的准确性和重复性，扫描的点云与物体的原始三维模型进行了比较。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种有效的三维扫描解决方案，具有良好的精度和兼容性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an open-loop articulated 6-degree-of-freedom (DoF)robotic system for three-dimensional (3D) scanning of objects by contact-basedmethod. A digitizer probe was used to detect contact with the object. Inversekinematics (IK) was used to determine the joint angles of the robotcorresponding to the probe position and orientation, and straight-linetrajectory planning was implemented for motion. The system can takesingle-point measurements and 3D scans of freeform surfaces. Specifying thescanning area's size, position, and density, the system automatically scans thedesignated volume. The system produces 3D scans in Standard Triangle Language(STL) format, ensuring compatibility with commonly used 3D software. Testsbased on ASME B89.4.22 standards were conducted to quantify accuracy andrepeatability. The point cloud from the scans was compared to the original 3Dmodel of the object.</description>
      <author>example@mail.com (Shadman Tajwar Shahid, Shah Md. Ahasan Siddique, Md. Humayun Kabir Bhuiyan)</author>
      <guid isPermaLink="false">2411.07047v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Learning-based Nonlinear Model Predictive Control of Articulated Soft Robots using Recurrent Neural Networks</title>
      <link>http://arxiv.org/abs/2411.05616v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE Robotics and Automation Letters
  (RA-L) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;软机器人在控制方面存在困难，需要新的策略来有效操控其柔性结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于学习的方法来预测具有五个自由度的关节软机器人的行为。&lt;h4&gt;方法&lt;/h4&gt;使用基于门控递归单元（GRUs）的递归神经网络（RNNs），并与常用的长短期记忆（LSTM）网络进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;GRUs在准确性上优于LSTM，能够捕捉由粘弹性或摩擦引起的滞后效应，这是简单前馈网络无法实现的。&lt;h4&gt;结论&lt;/h4&gt;提出的基于学习的非线性模型预测控制（NMPC）在气动五自由度关节软机器人实验中实现了平均1.2度的轨迹跟踪误差。&lt;h4&gt;总结&lt;/h4&gt;通过数据驱动模型和优化的训练方法，RNN能够在闭环NMPC中有效利用传感器数据进行短期预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2024.3495579&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft robots pose difficulties in terms of control, requiring novel strategiesto effectively manipulate their compliant structures. Model-based approachesface challenges due to the high dimensionality and nonlinearities such ashysteresis effects. In contrast, learning-based approaches provide nonlinearmodels of different soft robots based only on measured data. In this paper,recurrent neural networks (RNNs) predict the behavior of an articulated softrobot (ASR) with five degrees of freedom (DoF). RNNs based on gated recurrentunits (GRUs) are compared to the more commonly used long short-term memory(LSTM) networks and show better accuracy. The recurrence enables the capture ofhysteresis effects that are inherent in soft robots due to viscoelasticity orfriction but cannot be captured by simple feedforward networks. The data-drivenmodel is used within a nonlinear model predictive control (NMPC), whereby thecorrect handling of the RNN's hidden states is focused. A training approach ispresented that allows measured values to be utilized in each control cycle.This enables accurate predictions of short horizons based on sensor data, whichis crucial for closed-loop NMPC. The proposed learning-based NMPC enablestrajectory tracking with an average error of 1.2deg in experiments with thepneumatic five-DoF ASR.</description>
      <author>example@mail.com (Hendrik Schäfke, Tim-Lukas Habich, Christian Muhmann, Simon F. G. Ehlers, Thomas Seel, Moritz Schappler)</author>
      <guid isPermaLink="false">2411.05616v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>LAuReL: Learned Augmented Residual Layer</title>
      <link>http://arxiv.org/abs/2411.07501v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 2nd Efficient Systems for Foundation Models Workshop
  at the International Conference on Machine Learning (ICML) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高效深度学习方法的核心支柱之一是架构改进，如残差/跳跃连接，这显著提升了模型收敛性和质量。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的通用残差连接的扩展，称为学习增强残差层（LAuReL），旨在作为经典残差连接的替代方案，同时在模型质量和参数占用方面超越它。&lt;h4&gt;方法&lt;/h4&gt;通过在视觉和语言模型中使用LAuReL进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;在ResNet-50的ImageNet 1K任务中，LAuReL实现了添加额外层所获得收益的60%，仅增加了0.003%的参数，并且在增加参数数量时可减少2.6倍。&lt;h4&gt;结论&lt;/h4&gt;LAuReL在提升模型性能的同时，显著降低了参数量，证明了其在深度学习中的有效性。&lt;h4&gt;总结&lt;/h4&gt;LAuReL是一种有效的残差连接扩展，在视觉和语言模型任务中表现出色，提供了更优的性能与参数效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; One of the core pillars of efficient deep learning methods is architecturalimprovements such as the residual/skip connection, which has led tosignificantly better model convergence and quality. Since then the residualconnection has become ubiquitous in not just convolutional neural networks butalso transformer-based architectures, the backbone of LLMs.  In this paper we introduce \emph{Learned Augmented Residual Layer} (LAuReL)-- a novel generalization of the canonical residual connection -- with the goalto be an in-situ replacement of the latter while outperforming on both modelquality and footprint metrics. Our experiments show that using \laurel can helpboost performance for both vision and language models. For example, on theResNet-50, ImageNet 1K task, it achieves $60\%$ of the gains from adding anextra layer, while only adding $0.003\%$ more parameters, and matches it whileadding $2.6\times$ fewer parameters.</description>
      <author>example@mail.com (Gaurav Menghani, Ravi Kumar, Sanjiv Kumar)</author>
      <guid isPermaLink="false">2411.07501v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>BreakGPT: Leveraging Large Language Models for Predicting Asset Price Surges</title>
      <link>http://arxiv.org/abs/2411.06076v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍BreakGPT，一种新型的大型语言模型架构，专门用于时间序列预测和资产价格的快速上涨预测。&lt;h4&gt;目的&lt;/h4&gt;评估BreakGPT及其他基于Transformer的模型在应对高度波动的金融市场中的能力。&lt;h4&gt;方法&lt;/h4&gt;结合大型语言模型和基于Transformer的模型，进行时间序列表示学习与LLM预测框架的有效性研究。&lt;h4&gt;主要发现&lt;/h4&gt;BreakGPT展示了在金融预测中的有效性，具有最小的训练需求，并能够捕捉局部和全局时间依赖性。&lt;h4&gt;结论&lt;/h4&gt;BreakGPT是一个有前景的金融预测解决方案，并且在市场中具有竞争力。&lt;h4&gt;总结&lt;/h4&gt;本文证明了将时间序列表示学习与LLM预测框架结合的有效性，推动了金融市场的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces BreakGPT, a novel large language model (LLM)architecture adapted specifically for time series forecasting and theprediction of sharp upward movements in asset prices. By leveraging both thecapabilities of LLMs and Transformer-based models, this study evaluatesBreakGPT and other Transformer-based models for their ability to address theunique challenges posed by highly volatile financial markets. The primarycontribution of this work lies in demonstrating the effectiveness of combiningtime series representation learning with LLM prediction frameworks. We showcaseBreakGPT as a promising solution for financial forecasting with minimaltraining and as a strong competitor for capturing both local and globaltemporal dependencies.</description>
      <author>example@mail.com (Aleksandr Simonyan)</author>
      <guid isPermaLink="false">2411.06076v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Predicting ionic conductivity in solids from the machine-learned potential energy landscape</title>
      <link>http://arxiv.org/abs/2411.06804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;发现新的超离子材料对于推进固态电池至关重要，这些电池相比传统的液态电解质锂离子电池具有更高的能量密度和安全性。&lt;h4&gt;目的&lt;/h4&gt;提出一种快速可靠评估离子导电性的方案。&lt;h4&gt;方法&lt;/h4&gt;采用通用原子间势模型，并结合启发式结构描述符，以最小的泛化能力有效利用底层模型的知识。&lt;h4&gt;主要发现&lt;/h4&gt;在材料项目数据库中对锂含量材料进行排名，前十名中有八种材料在第一性原理计算中确认在室温下为超离子材料。&lt;h4&gt;结论&lt;/h4&gt;该方法相较于基于机器学习势的分子动力学速度提升约50倍，且比第一性原理分子动力学快至少3000倍。&lt;h4&gt;总结&lt;/h4&gt;通过使用通用原子间势和结构描述符，显著提高了离子导电性的评估效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Discovering new superionic materials is essential for advancing solid-statebatteries, which offer improved energy density and safety compared to thetraditional lithium-ion batteries with liquid electrolytes. Conventionalcomputational methods for identifying such materials are resource-intensive andnot easily scalable. Recently, universal interatomic potential models have beendeveloped using equivariant graph neural networks. These models are trained onextensive datasets of first-principles force and energy calculations. One canachieve significant computational advantages by leveraging them as thefoundation for traditional methods of assessing the ionic conductivity, such asmolecular dynamics or nudged elastic band techniques. However, thegeneralization error from model inference on diverse atomic structures arisingin such calculations can compromise the reliability of the results. In thiswork, we propose an approach for the quick and reliable evaluation of ionicconductivity through the analysis of a universal interatomic potential. Ourmethod incorporates a set of heuristic structure descriptors that effectivelyemploy the rich knowledge of the underlying model while requiring minimalgeneralization capabilities. Using our descriptors, we rank lithium-containingmaterials in the Materials Project database according to their expected ionicconductivity. Eight out of the ten highest-ranked materials are confirmed to besuperionic at room temperature in first-principles calculations. Notably, ourmethod achieves a speed-up factor of approximately 50 compared to moleculardynamics driven by a machine-learning potential, and is at least 3,000 timesfaster compared to first-principles molecular dynamics.</description>
      <author>example@mail.com (Artem Maevskiy, Alexandra Carvalho, Emil Sataev, Volha Turchyna, Keian Noori, Aleksandr Rodin, A. H. Castro Neto, Andrey Ustyuzhanin)</author>
      <guid isPermaLink="false">2411.06804v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>No-Reference Point Cloud Quality Assessment via Graph Convolutional Network</title>
      <link>http://arxiv.org/abs/2411.07728v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE Transactions on Multimedia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;三维点云作为一种新兴的视觉媒体格式，越来越受到消费者的青睐，因为它能提供比二维数据更真实的视觉信息。然而，点云在多媒体通信系统中不可避免地会遭受质量下降和信息丢失。&lt;h4&gt;目的&lt;/h4&gt;本研究提出一种新的无参考点云质量评估（PCQA）方法，旨在通过图卷积网络（GCN）来表征多视角二维投影图像内容之间的相互依赖关系。&lt;h4&gt;方法&lt;/h4&gt;所提出的GCN基础PCQA方法包括三个模块：多视角投影、图构建和基于GCN的质量预测。首先，对测试点云进行多视角投影，以获取一组水平和垂直投影图像；然后，基于不同投影图像之间的空间关系构建感知一致图；最后，通过GCN对构建的图进行推理，以表征不同投影图像之间的相互依赖和交互，并聚合多视角投影图像的特征信息以进行最终质量预测。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公开可用的基准数据库上的实验结果表明，所提出的GC-PCQA方法在性能上优于现有的最先进质量评估指标。&lt;h4&gt;结论&lt;/h4&gt;GC-PCQA方法提供了一种有效的自动点云质量评估手段，能更准确地评估三维点云的质量。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了基于图卷积网络的无参考点云质量评估方法的有效性，并提供了相关代码以供进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Three-dimensional (3D) point cloud, as an emerging visual media format, isincreasingly favored by consumers as it can provide more realistic visualinformation than two-dimensional (2D) data. Similar to 2D plane images andvideos, point clouds inevitably suffer from quality degradation and informationloss through multimedia communication systems. Therefore, automatic point cloudquality assessment (PCQA) is of critical importance. In this work, we propose anovel no-reference PCQA method by using a graph convolutional network (GCN) tocharacterize the mutual dependencies of multi-view 2D projected image contents.The proposed GCN-based PCQA (GC-PCQA) method contains three modules, i.e.,multi-view projection, graph construction, and GCN-based quality prediction.First, multi-view projection is performed on the test point cloud to obtain aset of horizontally and vertically projected images. Then, aperception-consistent graph is constructed based on the spatial relations amongdifferent projected images. Finally, reasoning on the constructed graph isperformed by GCN to characterize the mutual dependencies and interactionsbetween different projected images, and aggregate feature information ofmulti-view projected images for final quality prediction. Experimental resultson two publicly available benchmark databases show that our proposed GC-PCQAcan achieve superior performance than state-of-the-art quality assessmentmetrics. The code will be available at: https://github.com/chenwuwq/GC-PCQA.</description>
      <author>example@mail.com (Wu Chen, Qiuping Jiang, Wei Zhou, Feng Shao, Guangtao Zhai, Weisi Lin)</author>
      <guid isPermaLink="false">2411.07728v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Cardiovascular Disease Prediction through Multi-Modal Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2411.05900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to British Machine Vision Conference (BMVC) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确预测心血管疾病对于早期诊断和干预至关重要，因此需要稳健且精确的预测模型。&lt;h4&gt;目的&lt;/h4&gt;通过多模态学习揭示单一模态数据集无法提供的新见解，提升心血管疾病预测的效果。&lt;h4&gt;方法&lt;/h4&gt;结合心脏磁共振图像、心电图信号和现有医疗信息，采用自监督学习技术，构建综合框架以增强心血管疾病预测。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用掩蔽自编码器预训练心电图编码器，提取生心电图数据的相关特征，并利用多模态对比学习将知识从复杂的心脏磁共振图像转移到简单的心电图和医疗信息。&lt;h4&gt;结论&lt;/h4&gt;所提方法通过不同可用模态增强了图像信息，在平衡准确度上比监督方法提高了7.6%。&lt;h4&gt;总结&lt;/h4&gt;本研究通过多模态学习和自监督技术显著提升了心血管疾病的预测能力，特别是在有限标注数据集的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/fragirla/mmssl-for-cvd-pred&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate prediction of cardiovascular diseases remains imperative for earlydiagnosis and intervention, necessitating robust and precise predictive models.Recently, there has been a growing interest in multi-modal learning foruncovering novel insights not available through uni-modal datasets alone. Bycombining cardiac magnetic resonance images, electrocardiogram signals, andavailable medical information, our approach enables the capture of holisticstatus about individuals' cardiovascular health by leveraging sharedinformation across modalities. Integrating information from multiple modalitiesand benefiting from self-supervised learning techniques, our model provides acomprehensive framework for enhancing cardiovascular disease prediction withlimited annotated datasets.  We employ a masked autoencoder to pre-train the electrocardiogram ECGencoder, enabling it to extract relevant features from raw electrocardiogramdata, and an image encoder to extract relevant features from cardiac magneticresonance images. Subsequently, we utilize a multi-modal contrastive learningobjective to transfer knowledge from expensive and complex modality, cardiacmagnetic resonance image, to cheap and simple modalities such aselectrocardiograms and medical information. Finally, we fine-tuned thepre-trained encoders on specific predictive tasks, such as myocardialinfarction. Our proposed method enhanced the image information by leveragingdifferent available modalities and outperformed the supervised approach by 7.6%in balanced accuracy.</description>
      <author>example@mail.com (Francesco Girlanda, Olga Demler, Bjoern Menze, Neda Davoudi)</author>
      <guid isPermaLink="false">2411.05900v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Federated Low-Rank Adaptation with Differential Privacy over Wireless Networks</title>
      <link>http://arxiv.org/abs/2411.07806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, submitted to IEEE ICC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在分布式边缘设备上微调大型预训练基础模型面临计算和隐私挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种带有差分隐私的分割联邦微调框架，以解决隐私和计算负担问题。&lt;h4&gt;方法&lt;/h4&gt;结合低秩适应和联邦学习，利用无线网络中的无线信道噪声实现差分隐私，避免额外噪声的添加。&lt;h4&gt;主要发现&lt;/h4&gt;通过仅更新一个低秩矩阵，可以减轻噪声放大效应，且在严格的隐私预算下，该框架的准确性高于基线方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在保证隐私的同时，提升了模型的准确性，适用于敏感领域如医疗和金融。&lt;h4&gt;总结&lt;/h4&gt;结合低秩适应与差分隐私的分割联邦微调框架有效解决了隐私和计算负担问题，具有较好的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning large pre-trained foundation models (FMs) on distributed edgedevices presents considerable computational and privacy challenges. Federatedfine-tuning (FedFT) mitigates some privacy issues by facilitating collaborativemodel training without the need to share raw data. To lessen the computationalburden on resource-limited devices, combining low-rank adaptation (LoRA) withfederated learning enables parameter-efficient fine-tuning. Additionally, thesplit FedFT architecture partitions an FM between edge devices and a centralserver, reducing the necessity for complete model deployment on individualdevices. However, the risk of privacy eavesdropping attacks in FedFT remains aconcern, particularly in sensitive areas such as healthcare and finance. Inthis paper, we propose a split FedFT framework with differential privacy (DP)over wireless networks, where the inherent wireless channel noise in the uplinktransmission is utilized to achieve DP guarantees without adding an extraartificial noise. We shall investigate the impact of the wireless noise onconvergence performance of the proposed framework. We will also show that byupdating only one of the low-rank matrices in the split FedFT with DP, theproposed method can mitigate the noise amplification effect. Simulation resultswill demonstrate that the proposed framework achieves higher accuracy understrict privacy budgets compared to baseline methods.</description>
      <author>example@mail.com (Tianqu Kang, Zixin Wang, Hengtao He, Jun Zhang, Shenghui Song, Khaled B. Letaief)</author>
      <guid isPermaLink="false">2411.07806v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Unsupervised Domain Adaptation Regression for Spatial-Temporal Air Quality Sensor Fusion</title>
      <link>http://arxiv.org/abs/2411.06917v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，低成本物联网(IoT)传感器在空气污染监测中的应用增加，但在非受控环境中准确校准传感器仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的无监督领域适应(UDA)方法，以解决环境传感器校准中的问题。&lt;h4&gt;方法&lt;/h4&gt;使用图神经网络(GNNs)建模传感器之间的关系，并结合时空图神经网络(STGNNs)来捕捉时空交互，通过Tikhonov正则化最小二乘问题的封闭形式解决方案进行领域适应。&lt;h4&gt;主要发现&lt;/h4&gt;通过对源域和目标域子空间的对齐，使低成本IoT传感器能够从昂贵参考传感器学习校准参数。&lt;h4&gt;结论&lt;/h4&gt;该方法能够在不需要额外昂贵设备的情况下，实现新位置的可靠污染物测量。&lt;h4&gt;总结&lt;/h4&gt;该研究为提高低成本传感器的测量可靠性提供了有效的无监督学习方法，具有重要的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The deployment of affordable Internet of Things (IoT) sensors for airpollution monitoring has increased in recent years due to their scalability andcost-effectiveness. However, accurately calibrating these sensors inuncontrolled environments remains a significant challenge. While expensivereference sensors can provide accurate ground truth data, they are oftendeployed on a limited scale due to high costs, leading to a scarcity of labeleddata. In diverse urban environments, data distributions constantly shift due tovarying factors such as traffic patterns, industrial activities, and weatherconditions, which impact sensor readings. Consequently, traditional machinelearning models -- despite their increasing deployment for environmental sensorcalibration -- often struggle to provide reliable pollutant measurements acrossdifferent locations due to domain shifts. To address these challenges, wepropose a novel unsupervised domain adaptation (UDA) method specificallytailored for regression tasks on graph-structured data. Our approach leveragesGraph Neural Networks (GNNs) to model the relationships between sensors. Toeffectively capture critical spatial-temporal interactions, we incorporatespatial-temporal graph neural networks (STGNNs), which extend GNNs byincorporating temporal dynamics. To handle the resulting larger embeddings, wepropose a domain adaptation method using a closed-form solution inspired by theTikhonov-regularized least-squares problem. This method leverages Choleskydecomposition and power iteration to align the subspaces between source andtarget domains. By aligning these subspaces, our approach allows low-cost IoTsensors to learn calibration parameters from expensive reference sensors. Thisfacilitates reliable pollutant measurements in new locations without the needfor additional costly equipment.</description>
      <author>example@mail.com (Keivan Faghih Niresi, Ismail Nejjar, Olga Fink)</author>
      <guid isPermaLink="false">2411.06917v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>AGE2HIE: Transfer Learning from Brain Age to Predicting Neurocognitive Outcome for Infant Brain Injury</title>
      <link>http://arxiv.org/abs/2411.05188v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ISBI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;缺氧缺血性脑病（HIE）影响每千名新生儿中的1到5名，30%到50%的病例会导致不良的神经认知结果。&lt;h4&gt;目的&lt;/h4&gt;使用深度学习模型早期准确预测HIE相关的神经认知结果，以改善临床决策、指导治疗和评估新疗法。&lt;h4&gt;方法&lt;/h4&gt;建立首个大型公开HIE数据集，包含156个有2年神经认知结果标签的病例，同时收集了8,859个正常脑部黑白磁共振成像（MRI）数据用于脑龄估计，提出AGE2HIE进行知识迁移。&lt;h4&gt;主要发现&lt;/h4&gt;通过迁移学习，从脑龄估计中显著提高了预测准确性（同一地点或多地点提升3%或2%）以及模型在不同地点的泛化能力（跨地点验证提升5%）。&lt;h4&gt;结论&lt;/h4&gt;迁移学习方法在HIE神经认知结果预测中有效，能够改善模型的性能和适应性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了利用深度学习和迁移学习技术在缺氧缺血性脑病神经认知结果预测中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of every 1,000newborns, with 30% to 50% of cases resulting in adverse neurocognitiveoutcomes. However, these outcomes can only be reliably assessed as early as age2. Therefore, early and accurate prediction of HIE-related neurocognitiveoutcomes using deep learning models is critical for improving clinicaldecision-making, guiding treatment decisions and assessing novel therapies.However, a major challenge in developing deep learning models for this purposeis the scarcity of large, annotated HIE datasets. We have assembled the firstand largest public dataset, however it contains only 156 cases with 2-yearneurocognitive outcome labels. In contrast, we have collected 8,859 normalbrain black Magnetic Resonance Imagings (MRIs) with 0-97 years of age that areavailable for brain age estimation using deep learning models. In this paper,we introduce AGE2HIE to transfer knowledge learned by deep learning models fromhealthy controls brain MRIs to a diseased cohort, from structural to diffusionMRIs, from regression of continuous age estimation to prediction of the binaryneurocognitive outcomes, and from lifespan age (0-97 years) to infant (0-2weeks). Compared to training from scratch, transfer learning from brain ageestimation significantly improves not only the prediction accuracy (3% or 2%improvement in same or multi-site), but also the model generalization acrossdifferent sites (5% improvement in cross-site validation).</description>
      <author>example@mail.com (Rina Bao, Sheng He, Ellen Grant, Yangming Ou)</author>
      <guid isPermaLink="false">2411.05188v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Learning From Graph-Structured Data: Addressing Design Issues and Exploring Practical Applications in Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2411.07269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2205.11691,
  arXiv:2304.14621&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图作为描述交互元素系统的基本工具，能够捕捉从分子相互作用到社交网络和知识图谱等多种数据类型。&lt;h4&gt;目的&lt;/h4&gt;对图表示学习和图神经网络（GNNs）的最新进展进行全面回顾。&lt;h4&gt;方法&lt;/h4&gt;介绍一种配备先进高阶池化功能的GNN，旨在捕捉图结构数据中复杂的节点交互，并提出一个以GNN为核心的分子图生成模型。&lt;h4&gt;主要发现&lt;/h4&gt;该GNN在节点和图级任务中的有效性显著提高，分子图生成模型能够同时学习和生成具有原子-键结构和精确原子位置的分子图。&lt;h4&gt;结论&lt;/h4&gt;模型经过全面的实验评估和与现有方法的比较，展示出在处理多样化实际挑战时的优越性能。&lt;h4&gt;总结&lt;/h4&gt;研究表明，GNN及其相关模型在机器学习、数据挖掘、生物医学和医疗等领域具有重要应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs serve as fundamental descriptors for systems composed of interactingelements, capturing a wide array of data types, from molecular interactions tosocial networks and knowledge graphs. In this paper, we present an exhaustivereview of the latest advancements in graph representation learning and GraphNeural Networks (GNNs). GNNs, tailored to handle graph-structured data, excelin deriving insights and predictions from intricate relational information,making them invaluable for tasks involving such data. Graph representationlearning, a pivotal approach in analyzing graph-structured data, facilitatesnumerous downstream tasks and applications across machine learning, datamining, biomedicine, and healthcare.  Our work delves into the capabilities of GNNs, examining their foundationaldesigns and their application in addressing real-world challenges. We introducea GNN equipped with an advanced high-order pooling function, adept at capturingcomplex node interactions within graph-structured data. This pooling functionsignificantly enhances the GNN's efficacy in both node- and graph-level tasks.Additionally, we propose a molecular graph generative model with a GNN as itscore framework. This GNN backbone is proficient in learning invariant andequivariant molecular characteristics. Employing these features, the moleculargraph generative model is capable of simultaneously learning and generatingmolecular graphs with atom-bond structures and precise atom positions. Ourmodels undergo thorough experimental evaluations and comparisons withestablished methods, showcasing their superior performance in addressingdiverse real-world challenges with various datasets.</description>
      <author>example@mail.com (Chenqing Hua)</author>
      <guid isPermaLink="false">2411.07269v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>NL-SLAM for OC-VLN: Natural Language Grounded SLAM for Object-Centric VLN</title>
      <link>http://arxiv.org/abs/2411.07848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有机器人导航方法在地标导航和相对位置导航上存在显著差异。&lt;h4&gt;目的&lt;/h4&gt;评估基于物体的自然语言导航指令，并提出一种新方法。&lt;h4&gt;方法&lt;/h4&gt;引入OC-VLN数据集，提出NL-SLAM方法，将自然语言指令与机器人观察和位置相结合。&lt;h4&gt;主要发现&lt;/h4&gt;NL-SLAM在所有成功指标上超越了基于现有任务的强基线方法。&lt;h4&gt;结论&lt;/h4&gt;NL-SLAM在现实世界中成功实现了导航指令的跟随，展示了其有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法NL-SLAM，结合自然语言理解与机器人导航，展现出优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Landmark-based navigation (e.g. go to the wooden desk) and relativepositional navigation (e.g. move 5 meters forward) are distinct navigationchallenges solved very differently in existing robotics navigation methodology.We present a new dataset, OC-VLN, in order to distinctly evaluate groundingobject-centric natural language navigation instructions in a method forperforming landmark-based navigation. We also propose Natural Language groundedSLAM (NL-SLAM), a method to ground natural language instruction to robotobservations and poses. We actively perform NL-SLAM in order to followobject-centric natural language navigation instructions. Our methods leveragepre-trained vision and language foundation models and require no task-specifictraining. We construct two strong baselines from state-of-the-art methods onrelated tasks, Object Goal Navigation and Vision Language Navigation, and weshow that our approach, NL-SLAM, outperforms these baselines across all ourmetrics of success on OC-VLN. Finally, we successfully demonstrate theeffectiveness of NL-SLAM for performing navigation instruction following in thereal world on a Boston Dynamics Spot robot.</description>
      <author>example@mail.com (Sonia Raychaudhuri, Duy Ta, Katrina Ashton, Angel X. Chang, Jiuguang Wang, Bernadette Bucher)</author>
      <guid isPermaLink="false">2411.07848v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Reducing Distraction in Long-Context Language Models by Focused Learning</title>
      <link>http://arxiv.org/abs/2411.05928v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;最近大规模语言模型（LLMs）的发展显著增强了其处理长文本的能力，但有效利用这些长文本仍然面临挑战。&lt;h4&gt;目的&lt;/h4&gt;解决由于无关信息干扰而导致模型无法聚焦于最相关部分的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的训练方法，结合检索式数据增强和对比学习，提高LLMs识别相关信息的能力。在微调过程中，使用检索器提取最相关的片段作为增强输入，并引入辅助对比学习目标以确保原始上下文的输出与检索的子上下文紧密对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在长单文档和多文档问答基准测试上，广泛实验表明所提方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法显著改善了LLMs在处理长文本时的表现，提升了其对相关信息的关注能力。&lt;h4&gt;总结&lt;/h4&gt;通过创新的训练方法，提升了LLMs处理长文本的能力，解决了信息干扰问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Large Language Models (LLMs) have significantlyenhanced their capacity to process long contexts. However, effectivelyutilizing this long context remains a challenge due to the issue ofdistraction, where irrelevant information dominates lengthy contexts, causingLLMs to lose focus on the most relevant segments. To address this, we propose anovel training method that enhances LLMs' ability to discern relevantinformation through a unique combination of retrieval-based data augmentationand contrastive learning. Specifically, during fine-tuning with long contexts,we employ a retriever to extract the most relevant segments, serving asaugmented inputs. We then introduce an auxiliary contrastive learning objectiveto explicitly ensure that outputs from the original context and the retrievedsub-context are closely aligned. Extensive experiments on long single-documentand multi-document QA benchmarks demonstrate the effectiveness of our proposedmethod.</description>
      <author>example@mail.com (Zijun Wu, Bingyuan Liu, Ran Yan, Lei Chen, Thomas Delteil)</author>
      <guid isPermaLink="false">2411.05928v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>General Geospatial Inference with a Population Dynamics Foundation Model</title>
      <link>http://arxiv.org/abs/2411.07207v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 16 figures, preprint; v2: updated github url&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全球动态人口的健康与福祉需要政府机构、组织和研究人员理解人类行为与地方环境之间的复杂关系，以识别高风险群体并有效分配有限资源。&lt;h4&gt;目的&lt;/h4&gt;引入人口动态基础模型（PDFM），捕捉多样数据模态之间的关系，适用于广泛的地理空间任务。&lt;h4&gt;方法&lt;/h4&gt;构建覆盖美国邮政编码和县的地理索引数据集，整合人类行为与环境因素数据，利用图神经网络对数据进行建模，生成可适应多种下游任务的嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在27个下游任务中，PDFM在健康指标、社会经济因素和环境测量领域的地理空间插值任务上表现达到最先进水平，25个外推和超分辨率任务中也取得优异成绩。&lt;h4&gt;结论&lt;/h4&gt;将PDFM与先进的预测基础模型TimesFM结合，成功预测失业与贫困，超越完全监督预测的表现。&lt;h4&gt;总结&lt;/h4&gt;研究成果及样例代码已公开供研究人员使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Supporting the health and well-being of dynamic populations around the worldrequires governmental agencies, organizations and researchers to understand andreason over complex relationships between human behavior and local contexts inorder to identify high-risk groups and strategically allocate limitedresources. Traditional approaches to these classes of problems often entaildeveloping manually curated, task-specific features and models to representhuman behavior and the natural and built environment, which can be challengingto adapt to new, or even, related tasks. To address this, we introduce aPopulation Dynamics Foundation Model (PDFM) that aims to capture therelationships between diverse data modalities and is applicable to a broadrange of geospatial tasks. We first construct a geo-indexed dataset for postalcodes and counties across the United States, capturing rich aggregatedinformation on human behavior from maps, busyness, and aggregated searchtrends, and environmental factors such as weather and air quality. We thenmodel this data and the complex relationships between locations using a graphneural network, producing embeddings that can be adapted to a wide range ofdownstream tasks using relatively simple models. We evaluate the effectivenessof our approach by benchmarking it on 27 downstream tasks spanning threedistinct domains: health indicators, socioeconomic factors, and environmentalmeasurements. The approach achieves state-of-the-art performance on all 27geospatial interpolation tasks, and on 25 out of the 27 extrapolation andsuper-resolution tasks. We combined the PDFM with a state-of-the-artforecasting foundation model, TimesFM, to predict unemployment and poverty,achieving performance that surpasses fully supervised forecasting. The full setof embeddings and sample code are publicly available for researchers.</description>
      <author>example@mail.com (Mohit Agarwal, Mimi Sun, Chaitanya Kamath, Arbaaz Muslim, Prithul Sarker, Joydeep Paul, Hector Yee, Marcin Sieniek, Kim Jablonski, Yael Mayer, David Fork, Sheila de Guia, Jamie McPike, Adam Boulanger, Tomer Shekel, David Schottlander, Yao Xiao, Manjit Chakravarthy Manukonda, Yun Liu, Neslihan Bulut, Sami Abu-el-haija, Arno Eigenwillig, Parth Kothari, Bryan Perozzi, Monica Bharel, Von Nguyen, Luke Barrington, Niv Efron, Yossi Matias, Greg Corrado, Krish Eswaran, Shruthi Prabhakara, Shravya Shetty, Gautam Prasad)</author>
      <guid isPermaLink="false">2411.07207v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Towards Equitable ASD Diagnostics: A Comparative Study of Machine and Deep Learning Models Using Behavioral and Facial Data</title>
      <link>http://arxiv.org/abs/2411.05880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自闭症谱系障碍（ASD）在女性中常因性别特异的症状差异而被低估诊断。&lt;h4&gt;目的&lt;/h4&gt;评估机器学习模型，尤其是随机森林和卷积神经网络，以增强ASD的诊断。&lt;h4&gt;方法&lt;/h4&gt;通过结构化数据和面部图像分析来提高诊断准确性。&lt;h4&gt;主要发现&lt;/h4&gt;{'随机森林': '在各数据集上实现了100%的验证准确率，能够管理复杂关系并减少假阴性。', '图像分析': 'MobileNet在准确性上优于基线CNN，达到87%的准确率，但存在30%的验证损失，可能需要进一步优化。'}&lt;h4&gt;结论&lt;/h4&gt;未来工作将重点关注超参数调整、正则化和迁移学习，结合行为数据与面部分析可能改善对低诊断群体的诊断。&lt;h4&gt;影响&lt;/h4&gt;随机森林的高准确性和均衡的精确度-召回率指标可增强临床工作流程，MobileNet的轻量结构适合资源有限的环境，促进ASD筛查的可及性。&lt;h4&gt;挑战&lt;/h4&gt;需要解决模型可解释性和临床信任的问题。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，机器学习模型在ASD诊断中具有重要潜力，特别是在女性患者的早期干预和诊断方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autism Spectrum Disorder (ASD) is often underdiagnosed in females due togender-specific symptom differences overlooked by conventional diagnostics.This study evaluates machine learning models, particularly Random Forest andconvolutional neural networks, for enhancing ASD diagnosis through structureddata and facial image analysis. Random Forest achieved 100% validation accuracyacross datasets, highlighting its ability to manage complex relationships andreduce false negatives, which is crucial for early intervention and addressinggender biases. In image-based analysis, MobileNet outperformed the baselineCNN, achieving 87% accuracy, though a 30% validation loss suggests possibleoverfitting, requiring further optimization for robustness in clinicalsettings. Future work will emphasize hyperparameter tuning, regularization, andtransfer learning. Integrating behavioral data with facial analysis couldimprove diagnosis for underdiagnosed groups. These findings suggest RandomForest's high accuracy and balanced precision-recall metrics could enhanceclinical workflows. MobileNet's lightweight structure also shows promise forresource-limited environments, enabling accessible ASD screening. Addressingmodel explainability and clinician trust will be vital.</description>
      <author>example@mail.com (Mohammed Aledhari, Mohamed Rahouti, Ali Alfatemi)</author>
      <guid isPermaLink="false">2411.05880v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing the Evolution of Graphs and Texts</title>
      <link>http://arxiv.org/abs/2411.06295v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD dissertation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着图形和自然语言表示学习算法的进步，现有模型在许多下游任务中达到了人类水平的表现，尤其是在节点和句子分类任务上。&lt;h4&gt;目的&lt;/h4&gt;有效建模图形的动态性（如社交网络和引用图）并理解文本的变化（具体为新闻标题和个人传记）。&lt;h4&gt;方法&lt;/h4&gt;利用著名的个性化PageRank算法创建有效的动态网络嵌入，以应对不断变化的图形。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法显著提高了检测网络异常入侵者和发现实体意义变化的运行时间和准确性。&lt;h4&gt;结论&lt;/h4&gt;分析新闻标题的后发布变化，以理解编辑背后的意图，并讨论标题变化对信息完整性的潜在影响。同时，研究Twitter用户五年来自我呈现的职业身份，量化职业声望和人口统计对职业披露的影响。&lt;h4&gt;总结&lt;/h4&gt;本研究为动态图形和文本变化提供了新的视角，强调了在大规模动态环境中理解和建模变化的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the recent advance of representation learning algorithms on graphs(e.g., DeepWalk/GraphSage) and natural languages (e.g., Word2Vec/BERT) , thestate-of-the art models can even achieve human-level performance over manydownstream tasks, particularly for the task of node and sentenceclassification. However, most algorithms focus on large-scale models for staticgraphs and text corpus without considering the inherent dynamic characteristicsor discovering the reasons behind the changes. This dissertation aims toefficiently model the dynamics in graphs (such as social networks and citationgraphs) and understand the changes in texts (specifically news titles andpersonal biographies). To achieve this goal, we utilize the renownedPersonalized PageRank algorithm to create effective dynamic network embeddingsfor evolving graphs. Our proposed approaches significantly improve the runningtime and accuracy for both detecting network abnormal intruders and discoveringentity meaning shifts over large-scale dynamic graphs. For text changes, weanalyze the post-publication changes in news titles to understand the intentsbehind the edits and discuss the potential impact of titles changes frominformation integrity perspective. Moreover, we investigate self-presentedoccupational identities in Twitter users' biographies over five years,investigating job prestige and demographics effects in how people disclosejobs, quantifying over-represented jobs and their transitions over time.</description>
      <author>example@mail.com (Xingzhi Guo)</author>
      <guid isPermaLink="false">2411.06295v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Personalized News Recommendation System via LLM Embedding and Co-Occurrence Patterns</title>
      <link>http://arxiv.org/abs/2411.06046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在过去两年，大型语言模型（LLMs）快速发展，展现出显著的新兴能力，尤其在推荐系统领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的新闻推荐算法，通过LLM嵌入和共现模式（LECOP）来重塑新闻模型。&lt;h4&gt;方法&lt;/h4&gt;通过对比学习微调LLM，利用大规模数据集对新闻进行编码，探索多种共现模式来挖掘协作信息。&lt;h4&gt;主要发现&lt;/h4&gt;首次通过LLM构建详细的共现模式，以捕获协作信息，实验表明该方法性能优越。&lt;h4&gt;结论&lt;/h4&gt;新提出的方法在新闻推荐系统中表现出色，能够有效识别用户偏好并提升推荐效果。&lt;h4&gt;总结&lt;/h4&gt;本研究成功结合LLM技术与共现模式，为新闻推荐系统的优化提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the past two years, large language models (LLMs) have achieved rapiddevelopment and demonstrated remarkable emerging capabilities. Concurrently,with powerful semantic understanding and reasoning capabilities, LLMs havesignificantly empowered the rapid advancement of the recommendation systemfield. Specifically, in news recommendation (NR), systems must comprehend andprocess a vast amount of clicked news text to infer the probability ofcandidate news clicks. This requirement exceeds the capabilities of traditionalNR models but aligns well with the strengths of LLMs. In this paper, we proposea novel NR algorithm to reshape the news model via LLM Embedding andCo-Occurrence Pattern (LECOP). On one hand, we fintuned LLM by contrastivelearning using large-scale datasets to encode news, which can fully explore thesemantic information of news to thoroughly identify user preferences. On theother hand, we explored multiple co-occurrence patterns to mine collaborativeinformation. Those patterns include news ID co-occurrence, Item-Item keywordsco-occurrence and Intra-Item keywords co-occurrence. The keywords mentionedabove are all generated by LLM. As far as we know, this is the first time thatconstructing such detailed Co-Occurrence Patterns via LLM to capturecollaboration. Extensive experiments demonstrate the superior performance ofour proposed novel method</description>
      <author>example@mail.com (Zheng Li, Kai Zhange)</author>
      <guid isPermaLink="false">2411.06046v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>3D Branch Point Cloud Completion for Robotic Pruning in Apple Orchards</title>
      <link>http://arxiv.org/abs/2404.05953v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人修剪是一个快速发展的研究领域，旨在应对农业劳动力短缺的问题。&lt;h4&gt;目的&lt;/h4&gt;提高机器人修剪过程中对树枝几何和拓扑的感知能力。&lt;h4&gt;方法&lt;/h4&gt;使用基于模拟的深度神经网络，通过Real-to-Simulation（Real2Sim）数据生成管道来提高点云质量，实现点云的补全和骨架化。&lt;h4&gt;主要发现&lt;/h4&gt;通过Sim2Real技术，模型在几何重建和拓扑预测方面表现出色，定量评估显示使用最佳补全数据时，树枝直径和角度估计的平均绝对误差分别减少了75%和8%。&lt;h4&gt;结论&lt;/h4&gt;Real2Sim数据在零-shot泛化设置中有效，提升了树枝特征表征的准确性，提高了机器人修剪的精度和效率。&lt;h4&gt;总结&lt;/h4&gt;研究表明，基于模拟的深度学习方法能够显著改善农业中点云数据的质量，从而提升机器人修剪的实际应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-04-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic branch pruning is a significantly growing research area to cope withthe shortage of labor force in the context of agriculture. One fundamentalrequirement in robotic pruning is the perception of detailed geometry andtopology of branches. However, the point clouds obtained in agriculturalsettings often exhibit incompleteness due to several constraints, therebyrestricting the accuracy of downstream robotic pruning. In this work, weaddressed the issue of point cloud quality through a simulation-based deepneural network, leveraging a Real-to-Simulation (Real2Sim) data generationpipeline that not only eliminates the need for manual parameterization but alsoguarantees the realism of simulated data. The simulation-based neural networkwas applied to jointly perform point cloud completion and skeletonization onreal-world partial branches, without additional real-world training. TheSim2Real qualitative completion and skeletonization results showed the model'sremarkable capability for geometry reconstruction and topology prediction.Additionally, we quantitatively evaluated the Sim2Real performance by comparingbranch-level trait characterization errors using raw incomplete data andcomplete data. The Mean Absolute Error (MAE) reduced by 75% and 8% for branchdiameter and branch angle estimation, respectively, using the best completedata, which indicates the effectiveness of the Real2Sim data in a zero-shotgeneralization setting. The characterization improvements contributed to theprecision and efficacy of robotic branch pruning.</description>
      <author>example@mail.com (Tian Qiu, Alan Zoubi, Nikolai Spine, Lailiang Cheng, Yu Jiang)</author>
      <guid isPermaLink="false">2404.05953v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Machines and Mathematical Mutations: Using GNNs to Characterize Quiver Mutation Classes</title>
      <link>http://arxiv.org/abs/2411.07467v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习在数学中变得越来越重要，能够识别大量示例中的微妙模式。&lt;h4&gt;目的&lt;/h4&gt;使用图神经网络研究quiver变换，这一操作对簇代数理论至关重要。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络和人工智能可解释性技术，探讨quivers的变换等价性。&lt;h4&gt;主要发现&lt;/h4&gt;发现了$	ilde{D}_n$类型quivers的变换等价性标准，并证明了模型能够捕捉到结构。&lt;h4&gt;结论&lt;/h4&gt;现代机器学习模型能够从数学数据中学习抽象和一般规则，即使没有明确训练。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了机器学习在数学领域，特别是在簇代数中的潜力和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning is becoming an increasingly valuable tool in mathematics,enabling one to identify subtle patterns across collections of examples so vastthat they would be impossible for a single researcher to feasibly review andanalyze. In this work, we use graph neural networks to investigate quivermutation -- an operation that transforms one quiver (or directed multigraph)into another -- which is central to the theory of cluster algebras with deepconnections to geometry, topology, and physics. In the study of clusteralgebras, the question of mutation equivalence is of fundamental concern: giventwo quivers, can one efficiently determine if one quiver can be transformedinto the other through a sequence of mutations? Currently, this question hasonly been resolved in specific cases. In this paper, we use graph neuralnetworks and AI explainability techniques to discover mutation equivalencecriteria for the previously unknown case of quivers of type $\tilde{D}_n$.Along the way, we also show that even without explicit training to do so, ourmodel captures structure within its hidden representation that allows us toreconstruct known criteria from type $D_n$, adding to the growing evidence thatmodern machine learning models are capable of learning abstract and generalrules from mathematical data.</description>
      <author>example@mail.com (Jesse He, Helen Jenne, Herman Chau, Davis Brown, Mark Raugas, Sara Billey, Henry Kvinge)</author>
      <guid isPermaLink="false">2411.07467v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Predicting Stroke through Retinal Graphs and Multimodal Self-supervised Learning</title>
      <link>http://arxiv.org/abs/2411.05597v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as oral paper at ML-CDS workshop, MICCAI 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;早期识别中风对于干预至关重要，需要可靠的模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的视网膜图像表示方法，结合临床信息，以全面捕捉心血管健康状况。&lt;h4&gt;方法&lt;/h4&gt;利用大规模多模态数据集，构建一个整合图形和表格数据的对比框架，以视网膜图像衍生的血管图为基础进行有效表示。&lt;h4&gt;主要发现&lt;/h4&gt;结合多模态对比学习显著提高了中风预测的准确性，采用自监督学习技术减少了对大规模注释数据集的依赖，AUROC从监督学习到自监督学习提高了3.78%。&lt;h4&gt;结论&lt;/h4&gt;图级表示方法在性能上优于图像编码器，并显著减少了预训练和微调的时间，表明视网膜图像是一种经济有效的心血管疾病预测方法。&lt;h4&gt;未来方向&lt;/h4&gt;为未来研究视网膜与脑血管的连接以及基于图的视网膜血管表示的应用铺平道路。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种新颖的方法，通过视网膜图像改善心血管疾病预测，并显示出图形表示的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yuqinghuang01/mmcl-tabular-fundus&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early identification of stroke is crucial for intervention, requiringreliable models. We proposed an efficient retinal image representation togetherwith clinical information to capture a comprehensive overview of cardiovascularhealth, leveraging large multimodal datasets for new medical insights. Ourapproach is one of the first contrastive frameworks that integrates graph andtabular data, using vessel graphs derived from retinal images for efficientrepresentation. This method, combined with multimodal contrastive learning,significantly enhances stroke prediction accuracy by integrating data frommultiple sources and using contrastive learning for transfer learning. Theself-supervised learning techniques employed allow the model to learneffectively from unlabeled data, reducing the dependency on large annotateddatasets. Our framework showed an AUROC improvement of 3.78% from supervised toself-supervised approaches. Additionally, the graph-level representationapproach achieved superior performance to image encoders while significantlyreducing pre-training and fine-tuning runtimes. These findings indicate thatretinal images are a cost-effective method for improving cardiovascular diseasepredictions and pave the way for future research into retinal and cerebralvessel connections and the use of graph-based retinal vessel representations.</description>
      <author>example@mail.com (Yuqing Huang, Bastian Wittmann, Olga Demler, Bjoern Menze, Neda Davoudi)</author>
      <guid isPermaLink="false">2411.05597v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Constraint Learning for Parametric Point Cloud</title>
      <link>http://arxiv.org/abs/2411.07747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;参数化点云源自CAD形状，在工业制造中越来越普遍。&lt;h4&gt;目的&lt;/h4&gt;研究现有点云学习方法忽视CAD形状中的约束属性，限制了对CAD形状的理解。&lt;h4&gt;方法&lt;/h4&gt;提出约束特征学习网络（CstNet），分为两个阶段：第一阶段从B-Rep数据或点云中提取约束；第二阶段利用坐标和约束增强对CAD形状的理解。&lt;h4&gt;主要发现&lt;/h4&gt;CstNet在公共和提出的CAD形状数据集上实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;CstNet是首个针对CAD形状分析的基于约束的学习方法。&lt;h4&gt;数据集&lt;/h4&gt;建立了参数化2万多模态数据集，以应对标注B-Rep数据集的稀缺性。&lt;h4&gt;总结&lt;/h4&gt;CstNet通过引入约束特征，显著提升了CAD形状的理解能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parametric point clouds are sampled from CAD shapes, have become increasinglyprevalent in industrial manufacturing. However, most existing point cloudlearning methods focus on the geometric features, such as local and globalfeatures or developing efficient convolution operations, overlooking theimportant attribute of constraints inherent in CAD shapes, which limits thesemethods' ability to fully comprehend CAD shapes. To address this issue, weanalyzed the effect of constraints, and proposed its deep learning-friendlyrepresentation, after that, the Constraint Feature Learning Network (CstNet) isdeveloped to extract and leverage constraints. Our CstNet includes two stages.The Stage 1 extracts constraints from B-Rep data or point cloud. The Stage 2leverages coordinates and constraints to enhance the comprehend of CAD shapes.Additionally, we built up the Parametric 20,000 Multi-modal Dataset for thescarcity of labeled B-Rep datasets. Experiments demonstrate that our CstNetachieved state-of-the-art performance on both public and proposed CAD shapesdatasets. To the best of our knowledge, CstNet is the first constraint-basedlearning method tailored for CAD shapes analysis.</description>
      <author>example@mail.com (Xi Cheng, Ruiqi Lei, Di Huang, Zhichao Liao, Fengyuan Piao, Yan Chen, Pingfa Feng, Long Zeng)</author>
      <guid isPermaLink="false">2411.07747v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>SamRobNODDI: Q-Space Sampling-Augmented Continuous Representation Learning for Robust and Generalized NODDI</title>
      <link>http://arxiv.org/abs/2411.06444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;神经突起方向分散与密度成像（NODDI）通过扩散磁共振成像（dMRI）对神经疾病的发现与治疗具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于q-space采样增强的连续表示学习框架（SamRobNODDI），以实现稳健和通用的NODDI参数估计。&lt;h4&gt;方法&lt;/h4&gt;引入基于q-space采样增强的连续表示学习方法，探索不同梯度方向之间的信息，同时设计采样一致性损失，以约束不同采样方案的输出保持一致性。&lt;h4&gt;主要发现&lt;/h4&gt;SamRobNODDI在18种不同的q-space采样方案中，与7种先进方法比较，表现出更好的性能、稳健性、泛化能力和灵活性。&lt;h4&gt;结论&lt;/h4&gt;SamRobNODDI是一个灵活的框架，可以应用于不同的骨干网络，提升NODDI参数估计的准确性与一致性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的SamRobNODDI方法有效解决了现有深度学习方法在NODDI参数估计中的局限性，具有重要的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neurite Orientation Dispersion and Density Imaging (NODDI) microstructureestimation from diffusion magnetic resonance imaging (dMRI) is of greatsignificance for the discovery and treatment of various neurological diseases.Current deep learning-based methods accelerate the speed of NODDI parameterestimation and improve the accuracy. However, most methods require the numberand coordinates of gradient directions during testing and training to remainstrictly consistent, significantly limiting the generalization and robustnessof these models in NODDI parameter estimation. In this paper, we propose aq-space sampling augmentation-based continuous representation learningframework (SamRobNODDI) to achieve robust and generalized NODDI. Specifically,a continuous representation learning method based on q-space samplingaugmentation is introduced to fully explore the information between differentgradient directions in q-space. Furthermore, we design a sampling consistencyloss to constrain the outputs of different sampling schemes, ensuring that theoutputs remain as consistent as possible, thereby further enhancing performanceand robustness to varying q-space sampling schemes. SamRobNODDI is also aflexible framework that can be applied to different backbone networks. Tovalidate the effectiveness of the proposed method, we compared it with 7state-of-the-art methods across 18 different q-space sampling schemes,demonstrating that the proposed SamRobNODDI has better performance, robustness,generalization, and flexibility.</description>
      <author>example@mail.com (Taohui Xiao, Jian Cheng, Wenxin Fan, Enqing Dong, Hairong Zheng, Shanshan Wang)</author>
      <guid isPermaLink="false">2411.06444v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>GlocalCLIP: Object-agnostic Global-Local Prompt Learning for Zero-shot Anomaly Detection</title>
      <link>http://arxiv.org/abs/2411.06071v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 33 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;零样本异常检测（ZSAD）在目标数据集中检测异常模式至关重要，特别是在目标领域与训练数据存在分布差异或因受限访问导致数据稀缺的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出GlocalCLIP，以解决直接应用于ZSAD的挑战。&lt;h4&gt;方法&lt;/h4&gt;GlocalCLIP独特地分离全局和局部提示，并共同优化，利用深度文本提示调优精细调整文本提示，同时在视觉编码器中应用V-V注意力层捕捉详细的局部图像特征。&lt;h4&gt;主要发现&lt;/h4&gt;GlocalCLIP在15个来自工业和医疗领域的真实数据集上展示了在ZSAD中的泛化性能，表现优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;GlocalCLIP有效检测各种领域中的异常模式，能够捕捉一般的正常和异常模式，而不依赖于图像中特定对象。&lt;h4&gt;总结&lt;/h4&gt;GlocalCLIP为零样本异常检测提供了一种新方法，通过全局与局部对比学习增强了提示的互补学习效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot anomaly detection (ZSAD) is crucial for detecting abnormal patternsin target datasets without using training samples, specifically in scenarioswhere there are distributional differences between the target domain andtraining data or where data scarcity arises because of restricted access.Although recently pretrained vision-language models demonstrate strongzero-shot performance across various visual tasks, they focus on learning classsemantics, which makes their direct application to ZSAD challenging. To addressthis scenario, we propose GlocalCLIP, which uniquely separates global and localprompts and jointly optimizes them. This approach enables the object-agnosticglocal semantic prompt design to effectively capture general normal andanomalous patterns without dependency on specific objects in the image. Werefine the text prompts for more precise adjustments by utilizing deep-textprompt tuning in the text encoder. In the vision encoder, we apply V-Vattention layers to capture detailed local image features. Finally, weintroduce glocal contrastive learning to improve the complementary learning ofglobal and local prompts, effectively detecting abnormal patterns acrossvarious domains. The generalization performance of GlocalCLIP in ZSAD wasdemonstrated on 15 real-world datasets from both the industrial and medicaldomains, achieving superior performance compared to existing methods.</description>
      <author>example@mail.com (Jiyul Ham, Yonggon Jung, Jun-Geol Baek)</author>
      <guid isPermaLink="false">2411.06071v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Retrieval Augmented Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2411.08249v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;检索增强生成（RAG）是现代大型语言模型（LLM）系统的核心组成部分，尤其在需要最新信息的场景中至关重要。&lt;h4&gt;目的&lt;/h4&gt;探讨RAG在时间序列预测中的应用，特别是在时间序列基础模型（TSFM）如Chronos的背景下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为检索增强预测（RAF）的框架，开发高效的时间序列相关示例检索策略并将其纳入预测中。&lt;h4&gt;主要发现&lt;/h4&gt;实验和机制研究表明，RAF在不同时间序列领域提高了预测准确性，且对于较大的TSFM模型，改进更为显著。&lt;h4&gt;结论&lt;/h4&gt;时间序列数据的动态和事件驱动特性使得RAG成为TSFM的重要组成部分，证明了其在时间序列预测中的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了RAG在时间序列预测中的潜力，强调了其对提高预测精度的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/kutaytire/retrieval-augmented-time-series-forecasting&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieval-augmented generation (RAG) is a central component of modern LLMsystems, particularly in scenarios where up-to-date information is crucial foraccurately responding to user queries or when queries exceed the scope of thetraining data. The advent of time-series foundation models (TSFM), such asChronos, and the need for effective zero-shot forecasting performance acrossvarious time-series domains motivates the question: Do benefits of RAGsimilarly carry over to time series forecasting? In this paper, we advocatethat the dynamic and event-driven nature of time-series data makes RAG acrucial component of TSFMs and introduce a principled RAG framework fortime-series forecasting, called Retrieval Augmented Forecasting (RAF). WithinRAF, we develop efficient strategies for retrieving related time-seriesexamples and incorporating them into forecast. Through experiments andmechanistic studies, we demonstrate that RAF indeed improves the forecastingaccuracy across diverse time series domains and the improvement is moresignificant for larger TSFM sizes.</description>
      <author>example@mail.com (Kutay Tire, Ege Onur Taga, Muhammed Emrullah Ildiz, Samet Oymak)</author>
      <guid isPermaLink="false">2411.08249v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling</title>
      <link>http://arxiv.org/abs/2411.07482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;链接预测对于理解复杂网络至关重要，但传统图神经网络（GNN）通常依赖随机负采样，导致性能不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，Fuzzy Graph Attention Networks (FGAT)，以改进负采样和节点特征聚合。&lt;h4&gt;方法&lt;/h4&gt;FGAT结合模糊粗集原理进行动态负采样，使用模糊负采样（FNS）系统选择高质量负边，提升训练效率。&lt;h4&gt;主要发现&lt;/h4&gt;在两个研究合作网络的实验中，FGAT在链接预测准确性上优于最先进的基线方法。&lt;h4&gt;结论&lt;/h4&gt;FGAT通过模糊粗集的力量有效改进负采样和节点特征学习，显著提升链接预测性能。&lt;h4&gt;总结&lt;/h4&gt;FGAT是一种创新的方法，能够提高复杂网络中链接预测的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is crucial for understanding complex networks but traditionalGraph Neural Networks (GNNs) often rely on random negative sampling, leading tosuboptimal performance. This paper introduces Fuzzy Graph Attention Networks(FGAT), a novel approach integrating fuzzy rough sets for dynamic negativesampling and enhanced node feature aggregation. Fuzzy Negative Sampling (FNS)systematically selects high-quality negative edges based on fuzzy similarities,improving training efficiency. FGAT layer incorporates fuzzy rough setprinciples, enabling robust and discriminative node representations.Experiments on two research collaboration networks demonstrate FGAT's superiorlink prediction accuracy, outperforming state-of-the-art baselines byleveraging the power of fuzzy rough sets for effective negative sampling andnode feature learning.</description>
      <author>example@mail.com (Jinming Xing)</author>
      <guid isPermaLink="false">2411.07482v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Predicting band structures for 2D Photonic Crystals via Deep Learning</title>
      <link>http://arxiv.org/abs/2411.06063v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;光子晶体（PhCs）是具有周期性介电结构的材料，展现出独特的电磁特性，如形成禁止电磁波传播的能带间隙。&lt;h4&gt;目的&lt;/h4&gt;准确预测色散关系，以设计创新的光子设备。&lt;h4&gt;方法&lt;/h4&gt;提出一种利用U-Net的监督学习方法，结合迁移学习和超分辨率技术，预测二维光子晶体的色散关系。&lt;h4&gt;主要发现&lt;/h4&gt;模型能够从低分辨率数据中生成高分辨率的能带结构，显著提高计算效率和准确性。&lt;h4&gt;结论&lt;/h4&gt;所提模型在预测二维光子晶体的初始能带函数方面表现出高准确性，同时显著提高了计算效率。&lt;h4&gt;应用&lt;/h4&gt;该方法结合数据驱动和传统数值技术，为光子晶体的设计与优化提供了稳健的框架。&lt;h4&gt;总结&lt;/h4&gt;整合深度学习与传统计算物理方法，有助于解决复杂的多尺度问题，为未来的光子晶体研究和应用设立了新基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Photonic crystals (PhCs) are periodic dielectric structures that exhibitunique electromagnetic properties, such as the creation of band gaps whereelectromagnetic wave propagation is inhibited. Accurately predicting dispersionrelations, which describe the frequency and direction of wave propagation, isvital for designing innovative photonic devices. However, traditional numericalmethods, like the Finite Element Method (FEM), can encounter significantcomputational challenges due to the multiple scales present in photoniccrystals, especially when calculating band structures across the entireBrillouin zone. To address this, we propose a supervised learning approachutilizing U-Net, along with transfer learning and Super-Resolution techniques,to forecast dispersion relations for 2D PhCs. Our model reduces computationalexpenses by producing high-resolution band structures from low-resolution data,eliminating the necessity for fine meshes throughout the Brillouin zone. TheU-Net architecture enables the simultaneous prediction of multiple bandfunctions, enhancing efficiency and accuracy compared to existing methods thathandle each band function independently. Our findings demonstrate that theproposed model achieves high accuracy in predicting the initial band functionsof 2D PhCs, while also significantly enhancing computational efficiency. Thisamalgamation of data-driven and traditional numerical techniques provides arobust framework for expediting the design and optimization of photoniccrystals. The approach underscores the potential of integrating deep learningwith established computational physics methods to tackle intricate multiscaleproblems, establishing a new benchmark for future PhC research andapplications.</description>
      <author>example@mail.com (Yueqi Wang, Richard Craster, Guanglian Li)</author>
      <guid isPermaLink="false">2411.06063v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Horticultural Temporal Fruit Monitoring via 3D Instance Segmentation and Re-Identification using Point Clouds</title>
      <link>http://arxiv.org/abs/2411.07799v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Robotics and Automation Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人水果监测是自动化农业生产系统的关键步骤，能够显著提升植物和水果的监测效果。&lt;h4&gt;目的&lt;/h4&gt;开发一种新方法，以解决传统手动方法的局限性，提高水果监测的精确性和高通量评估。&lt;h4&gt;方法&lt;/h4&gt;采用基于学习的实例分割方法对收集的3D彩色点云进行水果分割，并利用3D稀疏卷积神经网络提取描述符，通过基于注意力的匹配网络将水果与之前的数据集合关联。&lt;h4&gt;主要发现&lt;/h4&gt;在实际草莓数据集上的实验结果表明，所提方法在水果重新识别方面优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;该方法能够在真实和复杂场景中实现精确的时间水果监测。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的一种新的时间水果监测方法，利用3D点云和深度学习技术，克服了传统方法的局限性，推动了农业自动化的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/prbonn/iris3d&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic fruit monitoring is a key step toward automated agriculturalproduction systems. Robots can significantly enhance plant and temporal fruitmonitoring by providing precise, high-throughput assessments that overcome thelimitations of traditional manual methods. Fruit monitoring is a challengingtask due to the significant variation in size, shape, orientation, andocclusion of fruits. Also, fruits may be harvested or newly grown betweenrecording sessions. Most methods are 2D image-based and they lack the 3Dstructure, depth, and spatial information, which represent key aspects of fruitmonitoring. 3D colored point clouds, instead, can offer this information butthey introduce challenges such as their sparsity and irregularity. In thispaper, we present a novel approach for temporal fruit monitoring that addressespoint clouds collected in a greenhouse over time. Our method segments fruitsusing a learning-based instance segmentation approach directly on the pointcloud. Each segmented fruit is processed by a 3D sparse convolutional neuralnetwork to extract descriptors, which are used in an attention-based matchingnetwork to associate fruits with their instances from previous datacollections. Experimental results on a real dataset of strawberries demonstratethat our approach outperforms other methods for fruits re-identification overtime, allowing for precise temporal fruit monitoring in real and complexscenarios.</description>
      <author>example@mail.com (Daniel Fusaro, Federico Magistri, Jens Behley, Alberto Pretto, Cyrill Stachniss)</author>
      <guid isPermaLink="false">2411.07799v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Contrastive Learning of Urban Space Representations from POI Data</title>
      <link>http://arxiv.org/abs/2411.06229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 5 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的从兴趣点（POI）数据学习城市空间表示的方法存在地理划分、空间信息建模不足、POI语义属性未充分利用和计算效率低下等问题。&lt;h4&gt;目的&lt;/h4&gt;提出CaLLiPer（对比语言-位置预训练），旨在直接将连续城市空间嵌入到向量表示中，以捕捉城市环境的空间和语义分布。&lt;h4&gt;方法&lt;/h4&gt;该模型利用多模态对比学习目标，将位置嵌入与文本POI描述对齐，从而避免复杂的训练语料构建和负采样需求。&lt;h4&gt;主要发现&lt;/h4&gt;在英国伦敦应用CaLLiPer进行城市空间表示学习时，其在土地利用分类和社会经济映射任务上的预测性能比最先进的方法提高了5-15%。&lt;h4&gt;结论&lt;/h4&gt;CaLLiPer在捕捉城市语义的空间变化方面具有高准确性和细分辨率，并且训练时间减少，展示了其效率和可扩展性。&lt;h4&gt;总结&lt;/h4&gt;该研究为可扩展、语义丰富的城市空间表示学习提供了有前景的路径，支持地理空间基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/xlwang233/calliper&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing methods for learning urban space representations fromPoint-of-Interest (POI) data face several limitations, including issues withgeographical delineation, inadequate spatial information modelling,underutilisation of POI semantic attributes, and computational inefficiencies.To address these issues, we propose CaLLiPer (Contrastive Language-LocationPre-training), a novel representation learning model that directly embedscontinuous urban spaces into vector representations that can capture thespatial and semantic distribution of urban environment. This model leverages amultimodal contrastive learning objective, aligning location embeddings withtextual POI descriptions, thereby bypassing the need for complex trainingcorpus construction and negative sampling. We validate CaLLiPer's effectivenessby applying it to learning urban space representations in London, UK, where itdemonstrates 5-15% improvement in predictive performance for land useclassification and socioeconomic mapping tasks compared to state-of-the-artmethods. Visualisations of the learned representations further illustrate ourmodel's advantages in capturing spatial variations in urban semantics with highaccuracy and fine resolution. Additionally, CaLLiPer achieves reduced trainingtime, showcasing its efficiency and scalability. This work provides a promisingpathway for scalable, semantically rich urban space representation learningthat can support the development of geospatial foundation models. Theimplementation code is available at https://github.com/xlwang233/CaLLiPer.</description>
      <author>example@mail.com (Xinglei Wang, Tao Cheng, Stephen Law, Zichao Zeng, Lu Yin, Junyuan Liu)</author>
      <guid isPermaLink="false">2411.06229v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Open-World Task and Motion Planning via Vision-Language Model Inferred Constraints</title>
      <link>http://arxiv.org/abs/2411.08253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型在互联网规模数据上训练，如视觉语言模型(VLMs)，在涉及常识的任务中表现出色，例如视觉问答。&lt;h4&gt;目的&lt;/h4&gt;探索如何将VLMs应用于复杂的机器人操作问题，以解决需要精确连续推理的任务。&lt;h4&gt;方法&lt;/h4&gt;提出将VLMs集成到任务与运动规划(TAMP)系统中，通过生成离散和连续的语言参数约束，帮助TAMP系统推理开放世界概念。&lt;h4&gt;主要发现&lt;/h4&gt;通过在两个机器人系统上进行实验，展示了通过语言传达的目标可以有效实施多种操作任务。&lt;h4&gt;结论&lt;/h4&gt;VLMs可以有效增强TAMP系统的能力，使其能够处理新的人类目标，推动机器人操作的进步。&lt;h4&gt;总结&lt;/h4&gt;结合VLMs与TAMP系统能够改善机器人对复杂任务的处理能力，尤其是在基于语言的目标设定方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models trained on internet-scale data, such as Vision-LanguageModels (VLMs), excel at performing tasks involving common sense, such as visualquestion answering. Despite their impressive capabilities, these models cannotcurrently be directly applied to challenging robot manipulation problems thatrequire complex and precise continuous reasoning. Task and Motion Planning(TAMP) systems can control high-dimensional continuous systems over longhorizons through combining traditional primitive robot operations. However,these systems require detailed model of how the robot can impact itsenvironment, preventing them from directly interpreting and addressing novelhuman objectives, for example, an arbitrary natural language goal. We proposedeploying VLMs within TAMP systems by having them generate discrete andcontinuous language-parameterized constraints that enable TAMP to reason aboutopen-world concepts. Specifically, we propose algorithms for VLM partialplanning that constrain a TAMP system's discrete temporal search and VLMcontinuous constraints interpretation to augment the traditional manipulationconstraints that TAMP systems seek to satisfy. We demonstrate our approach ontwo robot embodiments, including a real world robot, across severalmanipulation tasks, where the desired objectives are conveyed solely throughlanguage.</description>
      <author>example@mail.com (Nishanth Kumar, Fabio Ramos, Dieter Fox, Caelan Reed Garrett)</author>
      <guid isPermaLink="false">2411.08253v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Domain Transfer Learning using Attention Latent Features for Multi-Agent Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2411.06087v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the IEEE International Conference on Systems, Man, and
  Cybernetics 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着传感器硬件、交通基础设施和深度学习架构的进步，车辆轨迹预测在智能交通系统中建立了坚实的基础。&lt;h4&gt;目的&lt;/h4&gt;解决现有模型在特定交通网络上训练后，无法有效推广到未见网络的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的时空轨迹预测框架，通过对基于Transformer模型的注意力表示进行跨领域适应，同时集成图卷积网络以构建动态图特征嵌入，准确建模多交通领域中多智能体车辆的复杂时空交互。&lt;h4&gt;主要发现&lt;/h4&gt;在跨城市和跨时间段的案例研究中验证了框架的有效性，实验结果显示该框架在轨迹预测和领域适应性能方面优于现有最先进模型。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架能够有效提升车辆轨迹预测的准确性，并增强模型在不同交通网络间的适应能力。&lt;h4&gt;总结&lt;/h4&gt;该研究为智能交通系统中的轨迹预测提供了新的方法，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advancements of sensor hardware, traffic infrastructure and deeplearning architectures, trajectory prediction of vehicles has established asolid foundation in intelligent transportation systems. However, existingsolutions are often tailored to specific traffic networks at particular timeperiods. Consequently, deep learning models trained on one network may struggleto generalize effectively to unseen networks. To address this, we proposed anovel spatial-temporal trajectory prediction framework that performscross-domain adaption on the attention representation of a Transformer-basedmodel. A graph convolutional network is also integrated to construct dynamicgraph feature embeddings that accurately model the complex spatial-temporalinteractions between the multi-agent vehicles across multiple traffic domains.The proposed framework is validated on two case studies involving thecross-city and cross-period settings. Experimental results show that ourproposed framework achieves superior trajectory prediction and domainadaptation performances over the state-of-the-art models.</description>
      <author>example@mail.com (Jia Quan Loh, Xuewen Luo, Fan Ding, Hwa Hui Tew, Junn Yong Loo, Ze Yang Ding, Susilawati Susilawati, Chee Pin Tan)</author>
      <guid isPermaLink="false">2411.06087v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Quantum Information-Empowered Graph Neural Network for Hyperspectral Change Detection</title>
      <link>http://arxiv.org/abs/2411.07608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted by IEEE Transactions on Geoscience and
  Remote Sensing (TGRS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;变化检测（CD）是识别地表随时间变化的重要遥感技术，超光谱图像（HSI）的优越物质可识别性显著提高了检测准确性，使得超光谱变化检测（HCD）成为一项关键技术。&lt;h4&gt;目的&lt;/h4&gt;通过利用HSI的图结构，进一步提升检测准确性，采用图神经网络（GNN）解决HCD问题。&lt;h4&gt;方法&lt;/h4&gt;首次将量子深度网络（QUEEN）引入HCD，QUEEN与GNN和CNN不同，它提供了基本不同的单位计算特征，采用层次化的图特征学习（GFL）模块和量子特征学习（QFL）模块进行特征提取。&lt;h4&gt;主要发现&lt;/h4&gt;通过单位特征提取程序，QUEEN为判断是否存在变化提供了全新的信息，GFL模块在超像素级别利用HSI的图结构，QFL模块在像素级别学习量子特征，保留了不在超像素中保留的细节空间信息。&lt;h4&gt;结论&lt;/h4&gt;设计了一种量子分类器，与传统的全连接分类器协作，实验表明，提出的基于QUEEN的GNN（QUEEN-G）在真实超光谱数据集上的HCD性能优越。&lt;h4&gt;总结&lt;/h4&gt;QUEEN-G模型通过创新的特征提取和分类方法，显著提升了超光谱变化检测的准确性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Change detection (CD) is a critical remote sensing technique for identifyingchanges in the Earth's surface over time. The outstanding substanceidentifiability of hyperspectral images (HSIs) has significantly enhanced thedetection accuracy, making hyperspectral change detection (HCD) an essentialtechnology. The detection accuracy can be further upgraded by leveraging thegraph structure of HSIs, motivating us to adopt the graph neural networks(GNNs) in solving HCD. For the first time, this work introduces quantum deepnetwork (QUEEN) into HCD. Unlike GNN and CNN, both extracting theaffine-computing features, QUEEN provides fundamentally differentunitary-computing features. We demonstrate that through the unitary featureextraction procedure, QUEEN provides radically new information for decidingwhether there is a change or not. Hierarchically, a graph feature learning(GFL) module exploits the graph structure of the bitemporal HSIs at thesuperpixel level, while a quantum feature learning (QFL) module learns thequantum features at the pixel level, as a complementary to GFL by preservingpixel-level detailed spatial information not retained in the superpixels. Inthe final classification stage, a quantum classifier is designed to cooperatewith a traditional fully connected classifier. The superior HCD performance ofthe proposed QUEEN-empowered GNN (i.e., QUEEN-G) will be experimentallydemonstrated on real hyperspectral datasets.</description>
      <author>example@mail.com (Chia-Hsiang Lin, Tzu-Hsuan Lin, Jocelyn Chanussot)</author>
      <guid isPermaLink="false">2411.07608v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>DG-PPU: Dynamical Graphs based Post-processing of Point Clouds extracted from Knee Ultrasounds</title>
      <link>http://arxiv.org/abs/2411.08926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was submitted to the IEEE International Symposium on
  Biomedical Imaging (ISBI). This is a preprint version and may be subject to
  copyright&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;接受全膝关节置换术的患者常常经历非特异性的前膝疼痛，这种疼痛源于异常的髌股关节不稳定性。&lt;h4&gt;目的&lt;/h4&gt;旨在实现对髌骨追踪和髌股关节运动的准确可视化。&lt;h4&gt;方法&lt;/h4&gt;使用从超声扫描中提取的点云进行3D配准，以不同的关节屈伸运动角度进行分析。&lt;h4&gt;主要发现&lt;/h4&gt;通过动态图基于后处理算法（DG-PPU），成功创建了更平滑的点云，准确表示不同角度下的膝关节骨骼解剖结构。&lt;h4&gt;结论&lt;/h4&gt;DG-PPU算法在检测和消除假阳性及噪声方面表现优越，达到98.2%的精度，超越了人工数据清理。&lt;h4&gt;创新点&lt;/h4&gt;DG-PPU是首个自动化处理从超声扫描中提取的3D点云的算法，助力开发新型的髌骨异常追踪评估系统。&lt;h4&gt;总结&lt;/h4&gt;此研究为超声引导的髌骨追踪评估提供了新的解决方案，填补了当前技术的空白。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patients undergoing total knee arthroplasty (TKA) often experiencenon-specific anterior knee pain, arising from abnormal patellofemoral joint(PFJ) instability. Tracking PFJ motion is challenging since static imagingmodalities like CT and MRI are limited by field of view and metal artefactinterference. Ultrasounds offer an alternative modality for dynamicmusculoskeletal imaging. We aim to achieve accurate visualisation of patellartracking and PFJ motion, using 3D registration of point clouds extracted fromultrasound scans across different angles of joint flexion. Ultrasound imagescontaining soft tissue are often mislabeled as bone during segmentation,resulting in noisy 3D point clouds that hinder accurate registration of thebony joint anatomy. Machine learning the intrinsic geometry of the knee bonemay help us eliminate these false positives. As the intrinsic geometry of theknee does not change during PFJ motion, one may expect this to be robust acrossmultiple angles of joint flexion. Our dynamical graphs-based post-processingalgorithm (DG-PPU) is able to achieve this, creating smoother point clouds thataccurately represent bony knee anatomy across different angles. After invertingthese point clouds back to their original ultrasound images, we evaluated thatDG-PPU outperformed manual data cleaning done by our lab technician, deletingfalse positives and noise with 98.2% precision across three different angles ofjoint flexion. DG-PPU is the first algorithm to automate the post-processing of3D point clouds extracted from ultrasound scans. With DG-PPU, we contributetowards the development of a novel patellar mal-tracking assessment system withultrasound, which currently does not exist.</description>
      <author>example@mail.com (Injune Hwang, Karthik Saravanan, Caterina V Coralli, S Jack Tu, Stephen J Mellon)</author>
      <guid isPermaLink="false">2411.08926v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Causal Representation Learning from Multimodal Biological Observations</title>
      <link>http://arxiv.org/abs/2411.06518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态数据集在生物应用中（如人类表型测量）广泛存在，能够提供对潜在生物机制的有价值见解。&lt;h4&gt;目的&lt;/h4&gt;开发灵活的识别条件和原则性方法，以促进对生物数据集的理解。&lt;h4&gt;方法&lt;/h4&gt;考虑灵活的非参数潜在分布，允许不同模态之间的因果关系，并建立每个潜在成分的可识别性保证。&lt;h4&gt;主要发现&lt;/h4&gt;提出的理论框架在数值和合成数据集上经过广泛实验验证，结果与实际的人类表型数据集一致，支持已建立的医学研究。&lt;h4&gt;结论&lt;/h4&gt;我们的理论和方法框架有效，能够为生物研究提供更详细的机制理解。&lt;h4&gt;总结&lt;/h4&gt;研究克服了现有多模态分布分析中的局限性，推动了因果表示学习在生物应用中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prevalent in biological applications (e.g., human phenotype measurements),multimodal datasets can provide valuable insights into the underlyingbiological mechanisms. However, current machine learning models designed toanalyze such datasets still lack interpretability and theoretical guarantees,which are essential to biological applications. Recent advances in causalrepresentation learning have shown promise in uncovering the interpretablelatent causal variables with formal theoretical certificates. Unfortunately,existing works for multimodal distributions either rely on restrictiveparametric assumptions or provide rather coarse identification results,limiting their applicability to biological research which favors a detailedunderstanding of the mechanisms.  In this work, we aim to develop flexible identification conditions formultimodal data and principled methods to facilitate the understanding ofbiological datasets. Theoretically, we consider a flexible nonparametric latentdistribution (c.f., parametric assumptions in prior work) permitting causalrelationships across potentially different modalities. We establishidentifiability guarantees for each latent component, extending the subspaceidentification results from prior work. Our key theoretical ingredient is thestructural sparsity of the causal connections among distinct modalities, which,as we will discuss, is natural for a large collection of biological systems.Empirically, we propose a practical framework to instantiate our theoreticalinsights. We demonstrate the effectiveness of our approach through extensiveexperiments on both numerical and synthetic datasets. Results on a real-worldhuman phenotype dataset are consistent with established medical research,validating our theoretical and methodological framework.</description>
      <author>example@mail.com (Yuewen Sun, Lingjing Kong, Guangyi Chen, Loka Li, Gongxu Luo, Zijian Li, Yixuan Zhang, Yujia Zheng, Mengyue Yang, Petar Stojanov, Eran Segal, Eric P. Xing, Kun Zhang)</author>
      <guid isPermaLink="false">2411.06518v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Deep Nonparametric Conditional Independence Tests for Images</title>
      <link>http://arxiv.org/abs/2411.06140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  50 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;条件独立性测试（CITs）用于检测随机变量之间的条件依赖性，但现有的CITs在处理复杂的高维变量（如图像）时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;引入深度非参数条件独立性测试（DNCITs），以提升对高维变量的适用性。&lt;h4&gt;方法&lt;/h4&gt;DNCITs结合了嵌入映射（提取高维变量的特征表示）与适用于这些特征表示的非参数CITs，并推导出其参数估计的一般性质。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟研究不同嵌入映射和非参数CITs在不同混淆变量维度和关系下的表现，DNCITs在分析大规模数据集（如UK Biobank）的脑MRI扫描和行为特征上表现出色。&lt;h4&gt;结论&lt;/h4&gt;DNCITs能够确认一些模糊的个性神经科学研究的无效结果，并在混淆变量控制研究中显示出对混淆变量维度的潜在减少，优于现有的控制方法。&lt;h4&gt;总结&lt;/h4&gt;研究提供了一个实现DNCITs的R包，推动了高维变量分析的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/msimnach/dncitpaper&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conditional independence tests (CITs) test for conditional dependence betweenrandom variables. As existing CITs are limited in their applicability tocomplex, high-dimensional variables such as images, we introduce deepnonparametric CITs (DNCITs). The DNCITs combine embedding maps, which extractfeature representations of high-dimensional variables, with nonparametric CITsapplicable to these feature representations. For the embedding maps, we derivegeneral properties on their parameter estimators to obtain valid DNCITs andshow that these properties include embedding maps learned through (conditional)unsupervised or transfer learning. For the nonparametric CITs, appropriatetests are selected and adapted to be applicable to feature representations.Through simulations, we investigate the performance of the DNCITs for differentembedding maps and nonparametric CITs under varying confounder dimensions andconfounder relationships. We apply the DNCITs to brain MRI scans and behavioraltraits, given confounders, of healthy individuals from the UK Biobank (UKB),confirming null results from a number of ambiguous personality neurosciencestudies with a larger data set and with our more powerful tests. In addition,in a confounder control study, we apply the DNCITs to brain MRI scans and aconfounder set to test for sufficient confounder control, leading to apotential reduction in the confounder dimension under improved confoundercontrol compared to existing state-of-the-art confounder control studies forthe UKB. Finally, we provide an R package implementing the DNCITs.</description>
      <author>example@mail.com (Marco Simnacher, Xiangnan Xu, Hani Park, Christoph Lippert, Sonja Greven)</author>
      <guid isPermaLink="false">2411.06140v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>xCG: Explainable Cell Graphs for Survival Prediction in Non-Small Cell Lung Cancer</title>
      <link>http://arxiv.org/abs/2411.07643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Findings paper presented at Machine Learning for Health (ML4H)
  symposium 2024, December 15-16, 2024, Vancouver, Canada, 11 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习模型在预测肿瘤患者风险方面的理解对疾病进展、临床决策和精准医学至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种可解释的细胞图(xCG)方法用于生存预测。&lt;h4&gt;方法&lt;/h4&gt;基于图神经网络的肿瘤微环境空间建模，验证该模型在416例肺腺癌的成像质量细胞数据(IMC)上的有效性，使用网格化的层次相关传播(LRP)方法计算细胞图的风险归因。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，癌症分期和模型集成对提高风险估计质量的重要性。&lt;h4&gt;结论&lt;/h4&gt;xCG方法及IMC数据已公开，以支持进一步研究。&lt;h4&gt;总结&lt;/h4&gt;本研究为肿瘤患者风险预测提供了新的可解释性方法，促进了精准医学的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/marvinsxtr/explainable-cell-graphs&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding how deep learning models predict oncology patient risk canprovide critical insights into disease progression, support clinicaldecision-making, and pave the way for trustworthy and data-driven precisionmedicine. Building on recent advances in the spatial modeling of the tumormicroenvironment using graph neural networks, we present an explainable cellgraph (xCG) approach for survival prediction. We validate our model on a publiccohort of imaging mass cytometry (IMC) data for 416 cases of lungadenocarcinoma. We explain survival predictions in terms of known phenotypes onthe cell level by computing risk attributions over cell graphs, for which wepropose an efficient grid-based layer-wise relevance propagation (LRP) method.Our ablation studies highlight the importance of incorporating the cancer stageand model ensembling to improve the quality of risk estimates. Our xCG method,together with the IMC data, is made publicly available to support furtherresearch.</description>
      <author>example@mail.com (Marvin Sextro, Gabriel Dernbach, Kai Standvoss, Simon Schallenberg, Frederick Klauschen, Klaus-Robert Müller, Maximilian Alber, Lukas Ruff)</author>
      <guid isPermaLink="false">2411.07643v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Rendering-Oriented 3D Point Cloud Attribute Compression using Sparse Tensor-based Transformer</title>
      <link>http://arxiv.org/abs/2411.07899v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D可视化技术的演变彻底改变了我们与数字内容的互动方式，点云技术在这一变化中处于前沿。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的深度学习框架，将点云属性压缩和可微渲染无缝集成，旨在提高渲染多视图图像的质量。&lt;h4&gt;方法&lt;/h4&gt;提出名为RO-PCAC的渲染导向点云属性压缩框架，并引入基于稀疏张量的变换器SP-Trans，通过增强的局部注意机制捕捉点云中的复杂关系。&lt;h4&gt;主要发现&lt;/h4&gt;RO-PCAC在压缩性能方面达到了最先进的水平，相较于现有的重建导向方法（传统方法、基于学习的方法和混合方法）表现更佳。&lt;h4&gt;结论&lt;/h4&gt;通过考虑渲染过程对重建点云的影响，RO-PCAC有效提高了用户感知质量，推动了点云可视化技术的发展。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种创新的框架，提升了点云数据的压缩效果和可视化质量，为未来研究提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The evolution of 3D visualization techniques has fundamentally transformedhow we interact with digital content. At the forefront of this change is pointcloud technology, offering an immersive experience that surpasses traditional2D representations. However, the massive data size of point clouds presentssignificant challenges in data compression. Current methods for lossy pointcloud attribute compression (PCAC) generally focus on reconstructing theoriginal point clouds with minimal error. However, for point cloudvisualization scenarios, the reconstructed point clouds with distortion stillneed to undergo a complex rendering process, which affects the finaluser-perceived quality. In this paper, we propose an end-to-end deep learningframework that seamlessly integrates PCAC with differentiable rendering,denoted as rendering-oriented PCAC (RO-PCAC), directly targeting the quality ofrendered multiview images for viewing. In a differentiable manner, the impactof the rendering process on the reconstructed point clouds is taken intoaccount. Moreover, we characterize point clouds as sparse tensors and propose asparse tensor-based transformer, called SP-Trans. By aligning with the localdensity of the point cloud and utilizing an enhanced local attention mechanism,SP-Trans captures the intricate relationships within the point cloud, furtherimproving feature analysis and synthesis within the framework. Extensiveexperiments demonstrate that the proposed RO-PCAC achieves state-of-the-artcompression performance, compared to existing reconstruction-oriented methods,including traditional, learning-based, and hybrid methods.</description>
      <author>example@mail.com (Xiao Huo, Junhui Ho, Shuai Wan, Fuzheng Yang)</author>
      <guid isPermaLink="false">2411.07899v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Feature Fusion Transferability Aware Transformer for Unsupervised Domain Adaptation</title>
      <link>http://arxiv.org/abs/2411.07794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)
  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无监督领域适应（UDA）旨在利用已标记源域的知识，提升在未标记目标域上的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的特征融合可迁移性意识变换器（FFTAT），以增强视觉变换器（ViT）在UDA任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;引入两个关键创新：1) 使用补丁鉴别器评估补丁的可迁移性，生成可迁移性矩阵，并将其整合到自注意力机制中；2) 提出一种特征融合技术，在潜在空间中融合嵌入，使每个嵌入能够整合其他嵌入的信息。&lt;h4&gt;主要发现&lt;/h4&gt;这两种组件协同作用，显著提升了特征表示学习。&lt;h4&gt;结论&lt;/h4&gt;在广泛使用的基准测试上，实验证明该方法显著提高了UDA性能，达到了最新的研究水平（SOTA）。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了FFTAT在无监督领域适应中的有效性，推动了视觉变换器在此领域的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised domain adaptation (UDA) aims to leverage the knowledge learnedfrom labeled source domains to improve performance on the unlabeled targetdomains. While Convolutional Neural Networks (CNNs) have been dominant inprevious UDA methods, recent research has shown promise in applying VisionTransformers (ViTs) to this task. In this study, we propose a novel FeatureFusion Transferability Aware Transformer (FFTAT) to enhance ViT performance inUDA tasks. Our method introduces two key innovations: First, we introduce apatch discriminator to evaluate the transferability of patches, generating atransferability matrix. We integrate this matrix into self-attention, directingthe model to focus on transferable patches. Second, we propose a feature fusiontechnique to fuse embeddings in the latent space, enabling each embedding toincorporate information from all others, thereby improving generalization.These two components work in synergy to enhance feature representationlearning. Extensive experiments on widely used benchmarks demonstrate that ourmethod significantly improves UDA performance, achieving state-of-the-art(SOTA) results.</description>
      <author>example@mail.com (Xiaowei Yu, Zhe Huang, Zao Zhang)</author>
      <guid isPermaLink="false">2411.07794v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Understanding the Role of Equivariance in Self-supervised Learning</title>
      <link>http://arxiv.org/abs/2411.06508v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习是自监督学习的主流范式，但普遍存在牺牲有用特征（如颜色）的现象，因为其对数据增强不变。&lt;h4&gt;目的&lt;/h4&gt;研究等变自监督学习（E-SSL），以学习对增强敏感的特征，并理解其在下游任务中学习有用特征的机制。&lt;h4&gt;方法&lt;/h4&gt;从信息论的角度分析E-SSL的泛化能力，识别E-SSL中的重要解释性效应，分析数据变换的影响。&lt;h4&gt;主要发现&lt;/h4&gt;E-SSL通过等变任务与分类任务的协同作用，促使模型提取与类相关的特征，从而提高等变预测的效果，进而有利于需要语义特征的下游任务。&lt;h4&gt;结论&lt;/h4&gt;对等变性的理论理解有助于激发更有原则和先进的E-SSL设计，并提供了实践设计的若干原则。&lt;h4&gt;总结&lt;/h4&gt;代码可在https://github.com/kaotty/Understanding-ESSL获取，研究为E-SSL领域的新方向提供了理论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/kaotty/understanding-essl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has been a leading paradigm for self-supervisedlearning, but it is widely observed that it comes at the price of sacrificinguseful features (\eg colors) by being invariant to data augmentations. Giventhis limitation, there has been a surge of interest in equivariantself-supervised learning (E-SSL) that learns features to be augmentation-aware.However, even for the simplest rotation prediction method, there is a lack ofrigorous understanding of why, when, and how E-SSL learns useful features fordownstream tasks. To bridge this gap between practice and theory, we establishan information-theoretic perspective to understand the generalization abilityof E-SSL. In particular, we identify a critical explaining-away effect in E-SSLthat creates a synergy between the equivariant and classification tasks. Thissynergy effect encourages models to extract class-relevant features to improveits equivariant prediction, which, in turn, benefits downstream tasks requiringsemantic features. Based on this perspective, we theoretically analyze theinfluence of data transformations and reveal several principles for practicaldesigns of E-SSL. Our theory not only aligns well with existing E-SSL methodsbut also sheds light on new directions by exploring the benefits of modelequivariance. We believe that a theoretically grounded understanding on therole of equivariance would inspire more principled and advanced designs in thisfield. Code is available at https://github.com/kaotty/Understanding-ESSL.</description>
      <author>example@mail.com (Yifei Wang, Kaiwen Hu, Sharut Gupta, Ziyu Ye, Yisen Wang, Stefanie Jegelka)</author>
      <guid isPermaLink="false">2411.06508v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>A Hybrid Approach for COVID-19 Detection: Combining Wasserstein GAN with Transfer Learning</title>
      <link>http://arxiv.org/abs/2411.06397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;COVID-19传染性极强，早期诊断对于控制疫情至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决COVID-19和病毒性肺炎病例重叠问题的有效方法。&lt;h4&gt;方法&lt;/h4&gt;采用基于GAN的图像合成方法，生成用于深度学习模型训练的胸部X光图像。&lt;h4&gt;主要发现&lt;/h4&gt;使用定制的Wasserstein GAN生成的图像数量比真实图像多19%，并且深度学习模型在扩展数据集上表现出高分类准确率。&lt;h4&gt;结论&lt;/h4&gt;VGG-16模型在所有模型中准确率最高，达到99.17%。其他模型的测试准确率分别为93.9%、94.49%和97.75%。&lt;h4&gt;总结&lt;/h4&gt;提出的模型可以有效应对图像分析领域中数据集稀缺的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; COVID-19 is extremely contagious and its rapid growth has drawn attentiontowards its early diagnosis. Early diagnosis of COVID-19 enables healthcareprofessionals and government authorities to break the chain of transition andflatten the epidemic curve. With the number of cases accelerating across thedeveloped world, COVID-19 induced Viral Pneumonia cases is a big challenge.Overlapping of COVID-19 cases with Viral Pneumonia and other lung infectionswith limited dataset and long training hours is a serious problem to cater.Limited amount of data often results in over-fitting models and due to thisreason, model does not predict generalized results. To fill this gap, weproposed GAN-based approach to synthesize images which later fed into the deeplearning models to classify images of COVID-19, Normal, and Viral Pneumonia.Specifically, customized Wasserstein GAN is proposed to generate 19% more ChestX-ray images as compare to the real images. This expanded dataset is then usedto train four proposed deep learning models: VGG-16, ResNet-50, GoogLeNet andMNAST. The result showed that expanded dataset utilized deep learning models todeliver high classification accuracies. In particular, VGG-16 achieved highestaccuracy of 99.17% among all four proposed schemes. Rest of the models likeResNet-50, GoogLeNet and MNAST delivered 93.9%, 94.49% and 97.75% testingaccuracies respectively. Later, the efficiency of these models is compared withthe state of art models on the basis of accuracy. Further, our proposed modelscan be applied to address the issue of scant datasets for any problem of imageanalysis.</description>
      <author>example@mail.com (Sumera Rounaq, Shahid Munir Shah, Mahmoud Aljawarneh, Sarah Khan, Ghulam Muhammad)</author>
      <guid isPermaLink="false">2411.06397v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Is Graph Convolution Always Beneficial For Every Feature?</title>
      <link>http://arxiv.org/abs/2411.07663v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在处理结构化数据方面表现出色，但传统GNN在图卷积中对各特征维度的处理是相同的。&lt;h4&gt;目的&lt;/h4&gt;探讨图卷积操作是否对每个特征都同样有益，并提出改进的方法。&lt;h4&gt;方法&lt;/h4&gt;引入一种新型指标——拓扑特征信息性（TFI），用于区分GNN偏好的特征和不偏好的特征，并提出图特征选择（GFS）方法来分别处理这些特征。&lt;h4&gt;主要发现&lt;/h4&gt;GFS方法在8种基线和最先进的GNN架构上进行了广泛实验，发现83.75%的GFS增强案例表现出显著的性能提升，且TFI指标优于其他特征选择方法。&lt;h4&gt;结论&lt;/h4&gt;GFS和TFI的有效性得到了理论分析和实证观察的验证，GFS在超参数调优中表现稳健，显示出其作为增强各种GNN架构的通用方法的潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究通过提出新的特征选择方法和指标，推动了GNN在特征处理上的进一步发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated strong capabilities inprocessing structured data. While traditional GNNs typically treat each featuredimension equally during graph convolution, we raise an important question: Isthe graph convolution operation equally beneficial for each feature? If not,the convolution operation on certain feature dimensions can possibly lead toharmful effects, even worse than the convolution-free models. In prior studies,to assess the impacts of graph convolution on features, people proposed metricsbased on feature homophily to measure feature consistency with the graphtopology. However, these metrics have shown unsatisfactory alignment with GNNperformance and have not been effectively employed to guide feature selectionin GNNs. To address these limitations, we introduce a novel metric, TopologicalFeature Informativeness (TFI), to distinguish between GNN-favored andGNN-disfavored features, where its effectiveness is validated through boththeoretical analysis and empirical observations. Based on TFI, we propose asimple yet effective Graph Feature Selection (GFS) method, which processesGNN-favored and GNN-disfavored features separately, using GNNs and non-GNNmodels. Compared to original GNNs, GFS significantly improves the extraction ofuseful topological information from each feature with comparable computationalcosts. Extensive experiments show that after applying GFS to 8 baseline andstate-of-the-art (SOTA) GNN architectures across 10 datasets, 83.75% of theGFS-augmented cases show significant performance boosts. Furthermore, ourproposed TFI metric outperforms other feature selection methods. These resultsvalidate the effectiveness of both GFS and TFI. Additionally, we demonstratethat GFS's improvements are robust to hyperparameter tuning, highlighting itspotential as a universal method for enhancing various GNN architectures.</description>
      <author>example@mail.com (Yilun Zheng, Xiang Li, Sitao Luan, Xiaojiang Peng, Lihui Chen)</author>
      <guid isPermaLink="false">2411.07663v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>PRISM: Privacy-preserving Inter-Site MRI Harmonization via Disentangled Representation Learning</title>
      <link>http://arxiv.org/abs/2411.06513v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to ISBI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多站点MRI研究常受到不同方法、硬件和采集协议导致的站点特异性变化的影响，影响临床AI/ML任务的准确性和可靠性。&lt;h4&gt;目的&lt;/h4&gt;提出PRISM（隐私保护的多站点MRI协调），一种新的深度学习框架，用于在保持数据隐私的情况下协调多个站点的结构性脑MRI。&lt;h4&gt;方法&lt;/h4&gt;PRISM采用双分支自编码器，结合对比学习和变分推断，能够将解剖特征与样式和站点特异性变化分离，实现无配对图像转换。&lt;h4&gt;主要发现&lt;/h4&gt;采用多站点结构性MRI数据，展示了PRISM在下游任务（如脑组织分割）中的有效性，并通过多次实验验证了其协调性能。&lt;h4&gt;结论&lt;/h4&gt;该框架解决了医疗AI/ML中的关键挑战，包括数据隐私、分布变化、模型泛化能力和可解释性。&lt;h4&gt;总结&lt;/h4&gt;PRISM为多站点MRI数据协调提供了一种有效的方法，且可无缝集成新站点，无需重新训练或微调。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/saranggalada/prism&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-site MRI studies often suffer from site-specific variations arisingfrom differences in methodology, hardware, and acquisition protocols, therebycompromising accuracy and reliability in clinical AI/ML tasks. We present PRISM(Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learningframework for harmonizing structural brain MRI across multiple sites whilepreserving data privacy. PRISM employs a dual-branch autoencoder withcontrastive learning and variational inference to disentangle anatomicalfeatures from style and site-specific variations, enabling unpaired imagetranslation without traveling subjects or multiple MRI modalities. Our modulardesign allows harmonization to any target site and seamless integration of newsites without the need for retraining or fine-tuning. Using multi-sitestructural MRI data, we demonstrate PRISM's effectiveness in downstream taskssuch as brain tissue segmentation and validate its harmonization performancethrough multiple experiments. Our framework addresses key challenges in medicalAI/ML, including data privacy, distribution shifts, model generalizability andinterpretability. Code is available at https://github.com/saranggalada/PRISM</description>
      <author>example@mail.com (Sarang Galada, Tanurima Halder, Kunal Deo, Ram P Krish, Kshitij Jadhav)</author>
      <guid isPermaLink="false">2411.06513v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Developing a Foundation Model for Predicting Material Failure</title>
      <link>http://arxiv.org/abs/2411.08354v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024 "Foundation Models for Science: Progress,
  Opportunities, and Challenges" Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;理解材料失效对设计更强和更轻的结构至关重要，能够识别可减轻的弱点。&lt;h4&gt;目的&lt;/h4&gt;提出一种专门设计的基础模型，用于预测材料失效。&lt;h4&gt;方法&lt;/h4&gt;利用大规模数据集和高达30亿的参数显著提高失效预测的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型能够处理不同材料和模拟器的广泛情况，无需针对每种特定情况进行重新训练或调整。&lt;h4&gt;结论&lt;/h4&gt;模型支持多种输入格式，并能生成多样的输出，且随着模型规模的增加，性能显著提升。&lt;h4&gt;总结&lt;/h4&gt;该模型的设计灵活性和高效性，为材料失效预测提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding material failure is critical for designing stronger and lighterstructures by identifying weaknesses that could be mitigated. Existingfull-physics numerical simulation techniques involve trade-offs between speed,accuracy, and the ability to handle complex features like varying boundaryconditions, grid types, resolution, and physical models. We present the firstfoundation model specifically designed for predicting material failure,leveraging large-scale datasets and a high parameter count (up to 3B) tosignificantly improve the accuracy of failure predictions. In addition, a largelanguage model provides rich context embeddings, enabling our model to makepredictions across a diverse range of conditions. Unlike traditional machinelearning models, which are often tailored to specific systems or limited tonarrow simulation conditions, our foundation model is designed to generalizeacross different materials and simulators. This flexibility enables the modelto handle a range of material properties and conditions, providing accuratepredictions without the need for retraining or adjustments for each specificcase. Our model is capable of accommodating diverse input formats, such asimages and varying simulation conditions, and producing a range of outputs,from simulation results to effective properties. It supports both Cartesian andunstructured grids, with design choices that allow for seamless updates andextensions as new data and requirements emerge. Our results show thatincreasing the scale of the model leads to significant performance gains (lossscales as $N^{-1.6}$, compared to language models which often scale as$N^{-0.5}$).</description>
      <author>example@mail.com (Agnese Marcato, Javier E. Santos, Aleksandra Pachalieva, Kai Gao, Ryley Hill, Esteban Rougier, Qinjun Kang, Jeffrey Hyman, Abigail Hunter, Janel Chua, Earl Lawrence, Hari Viswanathan, Daniel O'Malley)</author>
      <guid isPermaLink="false">2411.08354v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Do you want to play a game? Learning to play Tic-Tac-Toe in Hypermedia Environments</title>
      <link>http://arxiv.org/abs/2411.06398v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at The 21st European Conference on Multi-Agent Systems,
  August 26-28th, 2024 Dublin, Ireland&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;展示了将迁移学习整合入超媒体多代理系统的方式。&lt;h4&gt;目的&lt;/h4&gt;利用多代理微服务架构来提高系统的学习效率。&lt;h4&gt;方法&lt;/h4&gt;代理使用RDF知识库进行信息推理，并应用强化学习技术与井字棋API进行交互。&lt;h4&gt;主要发现&lt;/h4&gt;代理通过形成顾问-被顾问关系，加速个体学习，并从网络数据中学习和利用。&lt;h4&gt;结论&lt;/h4&gt;迁移学习和多代理系统的结合能够提升学习效率和交互能力。&lt;h4&gt;总结&lt;/h4&gt;该研究表明，采用迁移学习的多代理系统在复杂任务中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We demonstrate the integration of Transfer Learning into a hypermediaMulti-Agent System using the Multi-Agent MicroServices (MAMS) architecturalstyle. Agents use RDF knowledge stores to reason over information and applyReinforcement Learning techniques to learn how to interact with a Tic-Tac-ToeAPI. Agents form advisor-advisee relationships in order to speed up individuallearning and exploit and learn from data on the Web.</description>
      <author>example@mail.com (Katharine Beaumont, Rem Collier)</author>
      <guid isPermaLink="false">2411.06398v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Structure Learning For Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2411.07672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）性能提升中，图结构学习（GSL）被广泛应用于重建或优化原始图结构，以解决异质性、过度压缩和噪声结构等问题。&lt;h4&gt;目的&lt;/h4&gt;探讨GSL对GNN的实际效用，质疑其是否真的有助于GNN性能提升。&lt;h4&gt;方法&lt;/h4&gt;提出一个新的GSL框架，包括GSL基础构建、新结构构建和视图融合三步，分析不同图结构在节点表示中的互信息差异。&lt;h4&gt;主要发现&lt;/h4&gt;经过图卷积后，使用新构建的图与原始图的GSL基础相比，没有互信息增益；GSL在大多数情况下无法提升GNN性能，提升主要来源于预训练的GSL基础。&lt;h4&gt;结论&lt;/h4&gt;应重新思考GNN设计中的关键组件，如自训练和结构编码，而不是过于依赖GSL。&lt;h4&gt;总结&lt;/h4&gt;GSL的有效性在相同超参数调优下并不总是超越基线GNN，促使对GNN设计的核心要素进行反思。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To improve the performance of Graph Neural Networks (GNNs), Graph StructureLearning (GSL) has been extensively applied to reconstruct or refine originalgraph structures, effectively addressing issues like heterophily,over-squashing, and noisy structures. While GSL is generally thought to improveGNN performance, it often leads to longer training times and morehyperparameter tuning. Besides, the distinctions among current GSL methodsremain ambiguous from the perspective of GNN training, and there is a lack oftheoretical analysis to quantify their effectiveness. Recent studies furthersuggest that, under fair comparisons with the same hyperparameter tuning, GSLdoes not consistently outperform baseline GNNs. This motivates us to ask acritical question: is GSL really useful for GNNs? To address this question,this paper makes two key contributions. First, we propose a new GSL framework,which includes three steps: GSL base (the representation used for GSL)construction, new structure construction, and view fusion, to better understandthe effectiveness of GSL in GNNs. Second, after graph convolution, we analyzethe differences in mutual information (MI) between node representations derivedfrom the original topology and those from the newly constructed topology.Surprisingly, our empirical observations and theoretical analysis show that nomatter which type of graph structure construction methods are used, afterfeeding the same GSL bases to the newly constructed graph, there is no MI gaincompared to the original GSL bases. To fairly reassess the effectiveness ofGSL, we conduct ablation experiments and find that it is the pretrained GSLbases that enhance GNN performance, and in most cases, GSL cannot improve GNNperformance. This finding encourages us to rethink the essential components inGNNs, such as self-training and structural encoding, in GNN design rather thanGSL.</description>
      <author>example@mail.com (Yilun Zheng, Zhuofan Zhang, Ziming Wang, Xiang Li, Sitao Luan, Xiaojiang Peng, Lihui Chen)</author>
      <guid isPermaLink="false">2411.07672v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation</title>
      <link>http://arxiv.org/abs/2411.08033v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project page: https://nirvanalan.github.io/projects/GA/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管3D内容生成技术已取得显著进展，但现有方法仍面临输入格式、潜在空间设计和输出表示等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的3D生成框架，以解决当前面临的挑战，实现可扩展的高质量3D生成。&lt;h4&gt;方法&lt;/h4&gt;该框架采用变分自编码器（VAE），使用多视角RGB-D（深度）-N（法线）渲染作为输入，独特的潜在空间设计保持3D形状信息，并结合级联潜在扩散模型以改善形状-纹理的解耦。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法GaussianAnything支持多模态条件的3D生成，允许输入点云、文本描述和单/多视角图像。新提出的潜在空间自然实现了几何与纹理的解耦，从而支持3D感知编辑。&lt;h4&gt;结论&lt;/h4&gt;实验结果显示，该方法在多个数据集上有效，优于现有的文本和图像条件3D生成方法。&lt;h4&gt;总结&lt;/h4&gt;该研究提出的3D生成框架通过创新的潜在空间设计和多模态输入，推动了3D内容生成技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While 3D content generation has advanced significantly, existing methodsstill face challenges with input formats, latent space design, and outputrepresentations. This paper introduces a novel 3D generation framework thataddresses these challenges, offering scalable, high-quality 3D generation withan interactive Point Cloud-structured Latent space. Our framework employs aVariational Autoencoder (VAE) with multi-view posed RGB-D(epth)-N(ormal)renderings as input, using a unique latent space design that preserves 3D shapeinformation, and incorporates a cascaded latent diffusion model for improvedshape-texture disentanglement. The proposed method, GaussianAnything, supportsmulti-modal conditional 3D generation, allowing for point cloud, caption, andsingle/multi-view image inputs. Notably, the newly proposed latent spacenaturally enables geometry-texture disentanglement, thus allowing 3D-awareediting. Experimental results demonstrate the effectiveness of our approach onmultiple datasets, outperforming existing methods in both text- andimage-conditioned 3D generation.</description>
      <author>example@mail.com (Yushi Lan, Shangchen Zhou, Zhaoyang Lyu, Fangzhou Hong, Shuai Yang, Bo Dai, Xingang Pan, Chen Change Loy)</author>
      <guid isPermaLink="false">2411.08033v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Bridge: A Unified Framework to Knowledge Graph Completion via Language Models and Knowledge Representation</title>
      <link>http://arxiv.org/abs/2411.06660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;知识图谱补全（KGC）任务依赖于推断缺失的三元组，结构性和语义信息对成功的KGC至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架Bridge，旨在联合编码知识图谱的结构和语义信息。&lt;h4&gt;方法&lt;/h4&gt;通过预训练语言模型（PLMs）分别对实体和关系进行编码，同时利用自监督表示学习方法BYOL对PLMs进行微调，以生成三元组的不同视图。&lt;h4&gt;主要发现&lt;/h4&gt;Bridge在三个基准数据集上的表现超过了当前最先进的模型（SOTA）。&lt;h4&gt;结论&lt;/h4&gt;通过结合结构和语义信息，Bridge有效提升了知识图谱补全的性能。&lt;h4&gt;总结&lt;/h4&gt;Bridge框架通过独特的方法解决了现有KGC模型在结构和语义信息使用上的局限，展示了良好的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge graph completion (KGC) is a task of inferring missing triples basedon existing Knowledge Graphs (KGs). Both structural and semantic informationare vital for successful KGC. However, existing methods only use either thestructural knowledge from the KG embeddings or the semantic information frompre-trained language models (PLMs), leading to suboptimal model performance.Moreover, since PLMs are not trained on KGs, directly using PLMs to encodetriples may be inappropriate. To overcome these limitations, we propose a novelframework called Bridge, which jointly encodes structural and semanticinformation of KGs. Specifically, we strategically encode entities andrelations separately by PLMs to better utilize the semantic knowledge of PLMsand enable structured representation learning via a structural learningprinciple. Furthermore, to bridge the gap between KGs and PLMs, we employ aself-supervised representation learning method called BYOL to fine-tune PLMswith two different views of a triple. Unlike BYOL, which uses augmentationmethods to create two semantically similar views of the same image, potentiallyaltering the semantic information. We strategically separate the triple intotwo parts to create different views, thus avoiding semantic alteration.Experiments demonstrate that Bridge outperforms the SOTA models on threebenchmark datasets.</description>
      <author>example@mail.com (Qiao Qiao, Yuepei Li, Qing Wang, Kang Zhou, Qi Li)</author>
      <guid isPermaLink="false">2411.06660v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Model Editing for LLMs4Code: How Far are We?</title>
      <link>http://arxiv.org/abs/2411.06638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICSE2025. The code is available at:
  https://github.com/xpq-tech/code-llmedit.git&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs4Code）在软件工程领域表现突出，尤其在编码任务中表现显著，但仍存在错误或过时的代码知识。&lt;h4&gt;目的&lt;/h4&gt;填补对当前最先进的模型编辑技术在LLMs4Code中的知识适应性能进行全面比较和分析的研究空白。&lt;h4&gt;方法&lt;/h4&gt;进行系统性研究，应用最新的模型编辑方法修复LLMs4Code的知识不准确性，提出了名为CLMEEval的基准，包含两个数据集：CoNaLa-Edit和CodeSearchNet-Edit。&lt;h4&gt;主要发现&lt;/h4&gt;基于外部记忆的GRACE方法在知识编辑效果和特异性方面表现最佳，现有技术在知识推广方面面临普遍挑战。&lt;h4&gt;结论&lt;/h4&gt;基于深入案例分析，提出了增强版GRACE（A-GRACE），通过对比学习更好地捕捉输入的语义。&lt;h4&gt;总结&lt;/h4&gt;本研究为修复LLMs4Code中的知识不准确性提供了新的视角和工具，推动了模型编辑技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/xpq-tech/code-llmedit&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models for Code (LLMs4Code) have been found to exhibitoutstanding performance in the software engineering domain, especially theremarkable performance in coding tasks. However, even the most advancedLLMs4Code can inevitably contain incorrect or outdated code knowledge. Due tothe high cost of training LLMs4Code, it is impractical to re-train the modelsfor fixing these problematic code knowledge. Model editing is a new technicalfield for effectively and efficiently correcting erroneous knowledge in LLMs,where various model editing techniques and benchmarks have been proposedrecently. Despite that, a comprehensive study that thoroughly compares andanalyzes the performance of the state-of-the-art model editing techniques foradapting the knowledge within LLMs4Code across various code-related tasks isnotably absent. To bridge this gap, we perform the first systematic study onapplying state-of-the-art model editing approaches to repair the inaccuracy ofLLMs4Code. To that end, we introduce a benchmark named CLMEEval, which consistsof two datasets, i.e., CoNaLa-Edit (CNLE) with 21K+ code generation samples andCodeSearchNet-Edit (CSNE) with 16K+ code summarization samples. With the helpof CLMEEval, we evaluate six advanced model editing techniques on threeLLMs4Code: CodeLlama (7B), CodeQwen1.5 (7B), and Stable-Code (3B). Our findingsinclude that the external memorization-based GRACE approach achieves the bestknowledge editing effectiveness and specificity (the editing does not influenceuntargeted knowledge), while generalization (whether the editing can generalizeto other semantically-identical inputs) is a universal challenge for existingtechniques. Furthermore, building on in-depth case analysis, we introduce anenhanced version of GRACE called A-GRACE, which incorporates contrastivelearning to better capture the semantics of the inputs.</description>
      <author>example@mail.com (Xiaopeng Li, Shangwen Wang, Shasha Li, Jun Ma, Jie Yu, Xiaodong Liu, Jing Wang, Bin Ji, Weimin Zhang)</author>
      <guid isPermaLink="false">2411.06638v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Federated Graph Learning with Graphless Clients</title>
      <link>http://arxiv.org/abs/2411.08374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Transactions on Machine Learning Research (TMLR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联邦图学习（FGL）旨在为多个客户端训练机器学习模型，例如图神经网络（GNN），每个客户端拥有自己的图数据。&lt;h4&gt;目的&lt;/h4&gt;解决在某些客户端只有节点特征而没有图结构的情况下，如何在分布式图数据上联合训练模型的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新框架FedGLS，针对无图客户端设计了本地图学习器，通过知识迁移学习本地图结构。每个客户端使用GNN模型和特征编码器进行局部训练，并通过知识蒸馏保留局部图结构知识。&lt;h4&gt;主要发现&lt;/h4&gt;FedGLS在与五个基线模型的比较中表现优越。&lt;h4&gt;结论&lt;/h4&gt;FedGLS有效地解决了图无客户端的联邦图学习问题，能够在分布式环境中实现结构知识的迁移和利用。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了FedGLS框架，为解决图无客户端的联合训练问题提供了有效的方法，展示了其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Graph Learning (FGL) is tasked with training machine learningmodels, such as Graph Neural Networks (GNNs), for multiple clients, each withits own graph data. Existing methods usually assume that each client has bothnode features and graph structure of its graph data. In real-world scenarios,however, there exist federated systems where only a part of the clients havesuch data while other clients (i.e. graphless clients) may only have nodefeatures. This naturally leads to a novel problem in FGL: how to jointly traina model over distributed graph data with graphless clients? In this paper, wepropose a novel framework FedGLS to tackle the problem in FGL with graphlessclients. In FedGLS, we devise a local graph learner on each graphless clientwhich learns the local graph structure with the structure knowledge transferredfrom other clients. To enable structure knowledge transfer, we design a GNNmodel and a feature encoder on each client. During local training, the featureencoder retains the local graph structure knowledge together with the GNN modelvia knowledge distillation, and the structure knowledge is transferred amongclients in global update. Our extensive experiments demonstrate the superiorityof the proposed FedGLS over five baselines.</description>
      <author>example@mail.com (Xingbo Fu, Song Wang, Yushun Dong, Binchi Zhang, Chen Chen, Jundong Li)</author>
      <guid isPermaLink="false">2411.08374v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>MBL-CPDP: A Multi-objective Bilevel Method for Cross-Project Defect Prediction via Automated Machine Learning</title>
      <link>http://arxiv.org/abs/2411.06491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  37 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;跨项目缺陷预测（CPDP）利用机器学习技术主动识别软件缺陷，尤其是在项目特定数据稀缺的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种多目标双层优化方法MBL-CPDP，以解决有效利用跨项目信息和优化机器学习管道的挑战。&lt;h4&gt;方法&lt;/h4&gt;MBL-CPDP包括两个嵌套问题：上层是多目标组合优化问题，增强机器学习管道的鲁棒性和效率；下层是聚焦于调优最优超参数的高成本优化问题。&lt;h4&gt;主要发现&lt;/h4&gt;MBL-CPDP在特征选择、迁移学习和分类方面结合了有限且异构的历史数据，提出了一种集成学习方法以捕获跨项目分布的差异，并在20个项目上与五种自动化机器学习工具和50种CPDP技术进行比较。&lt;h4&gt;结论&lt;/h4&gt;MBL-CPDP在适应性和综合性能评估能力上优于比较方法，显示出其卓越的表现。&lt;h4&gt;总结&lt;/h4&gt;MBL-CPDP通过有效的优化策略提升了跨项目缺陷预测的性能，展现了在稀缺数据情况下的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-project defect prediction (CPDP) leverages machine learning (ML)techniques to proactively identify software defects, especially whereproject-specific data is scarce. However, developing a robust ML pipeline withoptimal hyperparameters that effectively use cross-project information andyield satisfactory performance remains challenging. In this paper, we resolvethis bottleneck by formulating CPDP as a multi-objective bilevel optimization(MBLO) method, dubbed MBL-CPDP. It comprises two nested problems: theupper-level, a multi-objective combinatorial optimization problem, enhancesrobustness and efficiency in optimizing ML pipelines, while the lower-levelproblem is an expensive optimization problem that focuses on tuning theiroptimal hyperparameters. Due to the high-dimensional search space characterizedby feature redundancy and inconsistent data distributions, the upper-levelproblem combines feature selection, transfer learning, and classification toleverage limited and heterogeneous historical data. Meanwhile, an ensemblelearning method is proposed to capture differences in cross-projectdistribution and generalize across diverse datasets. Finally, a MBLO algorithmis presented to solve this problem while achieving high adaptabilityeffectively. To evaluate the performance of MBL-CPDP, we compare it with fiveautomated ML tools and $50$ CPDP techniques across $20$ projects. Extensiveempirical results show that MBL-CPDPoutperforms the comparison methods,demonstrating its superior adaptability and comprehensive performanceevaluation capability.</description>
      <author>example@mail.com (Jiaxin Chen, Jinliang Ding, Kay Chen Tan, Jiancheng Qian, Ke Li)</author>
      <guid isPermaLink="false">2411.06491v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Context Analysis for Rehabilitation Grasping Assistance</title>
      <link>http://arxiv.org/abs/2411.08169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;控制手部外骨骼以帮助有障碍的患者进行抓取任务具有挑战性，因为用户意图难以推断。&lt;h4&gt;目的&lt;/h4&gt;提出一种低成本、实时的系统，用于家庭场景的语义图像标记，旨在支持日常生活活动。&lt;h4&gt;方法&lt;/h4&gt;系统由微型深度摄像头、惯性测量单元和微处理器组成，能够实时分析环境几何形状的3D点云。&lt;h4&gt;主要发现&lt;/h4&gt;在处理复杂的3D场景时，系统能够以超过30帧每秒的速度实现85%以上的分类准确率，并在每种模式下检测和定位可抓取物体。&lt;h4&gt;结论&lt;/h4&gt;抓取点的估计平均误差在简单物体几何形状下可控制在1厘米以内，该系统在机器人辅助康复和手动任务辅助方面具有潜在应用。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了一种新型低成本系统，能够有效支持日常生活中的抓取任务，为相关领域的应用提供了可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Controlling hand exoskeletons for assisting impaired patients in graspingtasks is challenging because it is difficult to infer user intent. Wehypothesize that majority of daily grasping tasks fall into a small set ofcategories or modes which can be inferred through real-time analysis ofenvironmental geometry from 3D point clouds. This paper presents a low-cost,real-time system for semantic image labeling of household scenes with theobjective to inform and assist activities of daily living. The system consistsof a miniature depth camera, an inertial measurement unit and a microprocessor.It is able to achieve 85% or higher accuracy at classification of predefinedmodes while processing complex 3D scenes at over 30 frames per second. Withineach mode it can detect and localize graspable objects. Grasping points can becorrectly estimated on average within 1 cm for simple object geometries. Thesystem has potential applications in robotic-assisted rehabilitation as well asmanual task assistance.</description>
      <author>example@mail.com (Jackson M. Steinkamp, Laura J. Brattain, Conor J. Walsh, Robert D. Howe)</author>
      <guid isPermaLink="false">2411.08169v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Shedding Light on Problems with Hyperbolic Graph Learning</title>
      <link>http://arxiv.org/abs/2411.06688v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，图机器学习领域提出了多种超曲率表示学习的方法，并声称在节点分类和链接预测等图任务中表现优越。&lt;h4&gt;目的&lt;/h4&gt;探讨超曲率图表示学习模型的有效性，并与简单的欧几里得模型进行比较。&lt;h4&gt;方法&lt;/h4&gt;仔细分析当前的超曲率图表示学习领域，识别并讨论基线不严谨、建模假设错误和度量不当等问题。&lt;h4&gt;主要发现&lt;/h4&gt;经过合理训练的简单欧几里得模型在大多数情况下表现不逊于或优于所有引入的超曲率图表示学习模型，即使在被认为是最超曲率的图数据集上。&lt;h4&gt;结论&lt;/h4&gt;许多研究未能严谨展示基线，存在错误的建模假设和误导性度量，影响了超曲率图表示学习的评价。&lt;h4&gt;总结&lt;/h4&gt;本文揭示了超曲率图表示学习中的若干问题，并引入了一系列基准数据集以评估（超曲率）图神经网络的适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent papers in the graph machine learning literature have introduced anumber of approaches for hyperbolic representation learning. The assertedbenefits are improved performance on a variety of graph tasks, nodeclassification and link prediction included. Claims have also been made aboutthe geometric suitability of particular hierarchical graph datasets torepresentation in hyperbolic space. Despite these claims, our work makes asurprising discovery: when simple Euclidean models with comparable numbers ofparameters are properly trained in the same environment, in most cases, theyperform as well, if not better, than all introduced hyperbolic graphrepresentation learning models, even on graph datasets previously claimed to bethe most hyperbolic as measured by Gromov $\delta$-hyperbolicity (i.e., perfecttrees). This observation gives rise to a simple question: how can this be? Weanswer this question by taking a careful look at the field of hyperbolic graphrepresentation learning as it stands today, and find that a number of papersfail to diligently present baselines, make faulty modelling assumptions whenconstructing algorithms, and use misleading metrics to quantify geometry ofgraph datasets. We take a closer look at each of these three problems,elucidate the issues, perform an analysis of methods, and introduce aparametric family of benchmark datasets to ascertain the applicability of(hyperbolic) graph neural networks.</description>
      <author>example@mail.com (Isay Katsman, Anna Gilbert)</author>
      <guid isPermaLink="false">2411.06688v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Learning from Different Samples: A Source-free Framework for Semi-supervised Domain Adaptation</title>
      <link>http://arxiv.org/abs/2411.06665v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;半监督领域适应（SSDA）因能够利用少量标记目标数据来提高模型的泛化能力而备受关注。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法只考虑目标样本适应策略，而忽视对不同目标样本进行定制化学习的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的无源框架（SOUF），实现对源预训练模型在目标领域的半监督微调，具体设计了针对未标记、可靠标记和噪声伪标记目标样本的鲁棒学习技术。&lt;h4&gt;主要发现&lt;/h4&gt;通过概率加权对比学习（PWC）、可靠性混合对比学习（RMC）和预测正则化学习（PR），有效挖掘了不同目标样本的潜在知识，显著提升了模型性能。&lt;h4&gt;结论&lt;/h4&gt;在基准数据集上的广泛实验表明，SOUF框架优于现有的最先进方法。&lt;h4&gt;总结&lt;/h4&gt;本文提出的SOUF框架针对复杂目标分布，通过不同策略综合挖掘目标样本的知识，展示了其在SSDA任务中的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semi-supervised domain adaptation (SSDA) has been widely studied due to itsability to utilize a few labeled target data to improve the generalizationability of the model. However, existing methods only consider designing certainstrategies for target samples to adapt, ignoring the exploration of customizedlearning for different target samples. When the model encounters complex targetdistribution, existing methods will perform limited due to the inability toclearly and comprehensively learn the knowledge of multiple types of targetsamples. To fill this gap, this paper focuses on designing a framework to usedifferent strategies for comprehensively mining different target samples. Wepropose a novel source-free framework (SOUF) to achieve semi-supervisedfine-tuning of the source pre-trained model on the target domain. Differentfrom existing SSDA methods, SOUF decouples SSDA from the perspectives ofdifferent target samples, specifically designing robust learning techniques forunlabeled, reliably labeled, and noisy pseudo-labeled target samples. Forunlabeled target samples, probability-based weighted contrastive learning (PWC)helps the model learn more discriminative feature representations. To mine thelatent knowledge of labeled target samples, reliability-based mixup contrastivelearning (RMC) learns complex knowledge from the constructed reliable sampleset. Finally, predictive regularization learning (PR) further mitigates themisleading effect of noisy pseudo-labeled samples on the model. Extensiveexperiments on benchmark datasets demonstrate the superiority of our frameworkover state-of-the-art methods.</description>
      <author>example@mail.com (Xinyang Huang, Chuang Zhu, Bowen Zhang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2411.06665v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Can MLLMs Guide Weakly-Supervised Temporal Action Localization Tasks?</title>
      <link>http://arxiv.org/abs/2411.08466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型（MLLMs）在深度学习领域获得了显著认可，视频基础模型（VFMs）与大型语言模型（LLMs）的融合在构建强大的视频理解系统中发挥了重要作用。&lt;h4&gt;目的&lt;/h4&gt;引入一种新学习范式MLLM4WTAL，以利用MLLM提供时间动作关键语义和完整语义先验，增强传统的弱监督时间动作定位（WTAL）方法。&lt;h4&gt;方法&lt;/h4&gt;MLLM4WTAL通过集成关键语义匹配（KSM）和完整语义重建（CSR）两个模块来提升WTAL，解决常见的不完整和过度完整问题。&lt;h4&gt;主要发现&lt;/h4&gt;通过严格的实验验证了我们提出的方法在提升各种异构WTAL模型性能方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;尽管MLLMs在计算和内存需求上较高，但它们对视频理解任务的增强作用显示了传统模型的重要性。&lt;h4&gt;总结&lt;/h4&gt;本文提出的MLLM4WTAL范式通过有效整合MLLM的优势，推动了WTAL方法的性能提升，展现了未来视频理解研究的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent breakthroughs in Multimodal Large Language Models (MLLMs) have gainedsignificant recognition within the deep learning community, where the fusion ofthe Video Foundation Models (VFMs) and Large Language Models(LLMs) has proveninstrumental in constructing robust video understanding systems, effectivelysurmounting constraints associated with predefined visual tasks. Thesesophisticated MLLMs exhibit remarkable proficiency in comprehending videos,swiftly attaining unprecedented performance levels across diverse benchmarks.However, their operation demands substantial memory and computationalresources, underscoring the continued importance of traditional models in videocomprehension tasks. In this paper, we introduce a novel learning paradigmtermed MLLM4WTAL. This paradigm harnesses the potential of MLLM to offertemporal action key semantics and complete semantic priors for conventionalWeakly-supervised Temporal Action Localization (WTAL) methods. MLLM4WTALfacilitates the enhancement of WTAL by leveraging MLLM guidance. It achievesthis by integrating two distinct modules: Key Semantic Matching (KSM) andComplete Semantic Reconstruction (CSR). These modules work in tandem toeffectively address prevalent issues like incomplete and over-complete outcomescommon in WTAL methods. Rigorous experiments are conducted to validate theefficacy of our proposed approach in augmenting the performance of variousheterogeneous WTAL models.</description>
      <author>example@mail.com (Quan Zhang, Yuxin Qi)</author>
      <guid isPermaLink="false">2411.08466v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>A Heterogeneous Graph Neural Network Fusing Functional and Structural Connectivity for MCI Diagnosis</title>
      <link>http://arxiv.org/abs/2411.08424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;脑连接变化与脑部疾病的关系在静息态功能成像（rs-fMRI）和扩散张量成像（DTI）中得到了广泛报道。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，通过异构图神经网络（HGNN）整合功能和结构连接，以更好地利用双模态图像中的丰富异质性。&lt;h4&gt;方法&lt;/h4&gt;使用rs-fMRI和DTI提供的血氧水平依赖性和白质结构信息，建立同质元路径，并通过结构-功能耦合和脑社区搜索建立异质元路径；引入异质图池化策略，自动平衡同质和异质元路径，防止特征混淆；提出异质图数据增强方法，解决临床诊断中的样本不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;在ADNI-3数据集中对轻度认知障碍（MCI）诊断进行评估，实验结果表明该方法有效且优于其他算法，平均分类准确率达到93.3%。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地利用了异质信息，提供了更准确的脑部疾病诊断。&lt;h4&gt;总结&lt;/h4&gt;提出的异构图神经网络方法在脑连接分析中展示了卓越的性能，解决了双模态信息整合中的关键问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain connectivity alternations associated with brain disorders have beenwidely reported in resting-state functional imaging (rs-fMRI) and diffusiontensor imaging (DTI). While many dual-modal fusion methods based on graphneural networks (GNNs) have been proposed, they generally follow homogenousfusion ways ignoring rich heterogeneity of dual-modal information. To addressthis issue, we propose a novel method that integrates functional and structuralconnectivity based on heterogeneous graph neural networks (HGNNs) to betterleverage the rich heterogeneity in dual-modal images. We firstly use bloodoxygen level dependency and whiter matter structure information provided byrs-fMRI and DTI to establish homo-meta-path, capturing node relationshipswithin the same modality. At the same time, we propose to establishhetero-meta-path based on structure-function coupling and brain communitysearching to capture relations among cross-modal nodes. Secondly, we furtherintroduce a heterogeneous graph pooling strategy that automatically balanceshomo- and hetero-meta-path, effectively leveraging heterogeneous informationand preventing feature confusion after pooling. Thirdly, based on theflexibility of heterogeneous graphs, we propose a heterogeneous graph dataaugmentation approach that can conveniently address the sample imbalance issuecommonly seen in clinical diagnosis. We evaluate our method on ADNI-3 datasetfor mild cognitive impairment (MCI) diagnosis. Experimental results indicatethe proposed method is effective and superior to other algorithms, with a meanclassification accuracy of 93.3%.</description>
      <author>example@mail.com (Feiyu Yin, Yu Lei, Siyuan Dai, Wenwen Zeng, Guoqing Wu, Liang Zhan, Jinhua Yu)</author>
      <guid isPermaLink="false">2411.08424v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Model for Composite Materials and Microstructural Analysis</title>
      <link>http://arxiv.org/abs/2411.06565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习的快速发展为材料科学带来了众多机会，尤其是在加速材料设计和分析方面。然而，高质量材料数据集的稀缺和成本高昂是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;探索基础模型在材料科学中的应用，特别是针对复合材料的设计。&lt;h4&gt;方法&lt;/h4&gt;提出一个专门为短纤维复合材料设计的基础模型，并在相关数据集上进行预训练，以学习稳健的潜在特征。&lt;h4&gt;主要发现&lt;/h4&gt;转移学习过程中，模型MMAE能够准确预测均质化刚度，R²评分高达0.959，在有限数据训练时也能保持超过0.91的表现。&lt;h4&gt;结论&lt;/h4&gt;基础模型在复合材料中的可行性和有效性得到了验证，未来可以扩展到更复杂的三维复合材料和多晶材料。&lt;h4&gt;意义&lt;/h4&gt;该框架即使在实验数据稀缺的情况下也能实现高精度预测，为更高效、成本更低的材料设计和分析铺平道路。&lt;h4&gt;总结&lt;/h4&gt;基础模型的应用为材料科学提供了新的解决方案，能够提升材料设计的效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of machine learning has unlocked numerous opportunitiesfor materials science, particularly in accelerating the design and analysis ofmaterials. However, a significant challenge lies in the scarcity and high costof obtaining high-quality materials datasets. In other fields, such as naturallanguage processing, foundation models pre-trained on large datasets haveachieved exceptional success in transfer learning, effectively leveraginglatent features to achieve high performance on tasks with limited data. Despitethis progress, the concept of foundation models remains underexplored inmaterials science. Here, we present a foundation model specifically designedfor composite materials. Our model is pre-trained on a dataset of short-fibercomposites to learn robust latent features. During transfer learning, the MMAEaccurately predicts homogenized stiffness, with an R2 score reaching as high as0.959 and consistently exceeding 0.91, even when trained on limited data. Thesefindings validate the feasibility and effectiveness of foundation models incomposite materials. We anticipate extending this approach to more complexthree-dimensional composite materials, polycrystalline materials, and beyond.Moreover, this framework enables high-accuracy predictions even whenexperimental data are scarce, paving the way for more efficient andcost-effective materials design and analysis.</description>
      <author>example@mail.com (Ting-Ju Wei, Chuin-Shan, Chen)</author>
      <guid isPermaLink="false">2411.06565v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Subgraph Retrieval Enhanced by Graph-Text Alignment for Commonsense Question Answering</title>
      <link>http://arxiv.org/abs/2411.06866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ECML PKDD 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;常识问答是一个重要任务，需要机器根据常识进行推理。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的框架SEPTA，以解决现有方法中提取子图和知识融合的挑战。&lt;h4&gt;方法&lt;/h4&gt;将知识图转化为子图向量数据库，采用BFS风格的子图采样策略，并引入双向对比学习方法进行图文对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在五个数据集上的广泛实验表明，框架的有效性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;SEPTA能够有效提高子图检索和知识融合的性能，改善常识问答的效果。&lt;h4&gt;总结&lt;/h4&gt;SEPTA框架通过改进子图提取和图文对齐，解决了常识问答中的关键问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-70365-2_3&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Commonsense question answering is a crucial task that requires machines toemploy reasoning according to commonsense. Previous studies predominantlyemploy an extracting-and-modeling paradigm to harness the information in KG,which first extracts relevant subgraphs based on pre-defined rules and thenproceeds to design various strategies aiming to improve the representations andfusion of the extracted structural knowledge. Despite their effectiveness,there are still two challenges. On one hand, subgraphs extracted by rule-basedmethods may have the potential to overlook critical nodes and result inuncontrollable subgraph size. On the other hand, the misalignment between graphand text modalities undermines the effectiveness of knowledge fusion,ultimately impacting the task performance. To deal with the problems above, wepropose a novel framework: \textbf{S}ubgraph R\textbf{E}trieval Enhanced byGra\textbf{P}h-\textbf{T}ext \textbf{A}lignment, named \textbf{SEPTA}. Firstly,we transform the knowledge graph into a database of subgraph vectors andpropose a BFS-style subgraph sampling strategy to avoid information loss,leveraging the analogy between BFS and the message-passing mechanism. Inaddition, we propose a bidirectional contrastive learning approach forgraph-text alignment, which effectively enhances both subgraph retrieval andknowledge fusion. Finally, all the retrieved information is combined forreasoning in the prediction module. Extensive experiments on five datasetsdemonstrate the effectiveness and robustness of our framework.</description>
      <author>example@mail.com (Boci Peng, Yongchao Liu, Xiaohe Bo, Sheng Tian, Baokun Wang, Chuntao Hong, Yan Zhang)</author>
      <guid isPermaLink="false">2411.06866v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Subset Tuning: Expanding the Operational Range of Parameter-Efficient Training for Large Language Models</title>
      <link>http://arxiv.org/abs/2411.08610v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Workshop on Adaptive Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的大型语言模型训练方法存在参数效率低的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的参数高效训练方法（PET），以优化少量模型参数以适应下游任务。&lt;h4&gt;方法&lt;/h4&gt;与传统方法不同，本方法在训练过程中动态选择修改的参数位置，而不是固定不变。&lt;h4&gt;主要发现&lt;/h4&gt;动态参数选择在使用更少参数的情况下，能够获得良好的性能，且可以在模型总大小的任意比例上无缝调整子集大小。&lt;h4&gt;结论&lt;/h4&gt;在多种自然语言处理任务（如机器翻译、问答、GSM8K、SuperGLUE）中，本方法的表现与现有的提示调优和LoRA方法相当或更优。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种灵活且高效的训练方法，推动了大型语言模型的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel parameter-efficient training (PET) method for largelanguage models that adapts models to downstream tasks by optimizing a smallsubset of the existing model parameters. Unlike prior methods, this subset isnot fixed in location but rather which parameters are modified evolves over thecourse of training. This dynamic parameter selection can yield good performancewith many fewer parameters than extant methods. Our method enables a seamlessscaling of the subset size across an arbitrary proportion of the total modelsize, while popular PET approaches like prompt tuning and LoRA cover only asmall part of this spectrum. We match or outperform prompt tuning and LoRA inmost cases on a variety of NLP tasks (MT, QA, GSM8K, SuperGLUE) for a givenparameter budget across different model families and sizes.</description>
      <author>example@mail.com (Felix Stahlberg, Jared Lichtarge, Shankar Kumar)</author>
      <guid isPermaLink="false">2411.08610v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>DeepONet as a Multi-Operator Extrapolation Model: Distributed Pretraining with Physics-Informed Fine-Tuning</title>
      <link>http://arxiv.org/abs/2411.07239v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新颖的微调方法，以实现多操作符学习，通过训练一个分布式神经操作符，并利用多样的函数数据。&lt;h4&gt;目的&lt;/h4&gt;解决操作符学习在新任务中难以推广的问题。&lt;h4&gt;方法&lt;/h4&gt;在预训练模型的基础上进行微调，选择合适的初始化以快速适应新任务，同时结合分布式学习和物理信息损失进行零-shot 微调。&lt;h4&gt;主要发现&lt;/h4&gt;通过标准微调和低秩适应微调方法，成功训练复杂的非线性目标操作符，显著提高了准确性。&lt;h4&gt;结论&lt;/h4&gt;我们的研究为多操作符学习提供了一个稳健的框架，并强调了迁移学习技术在这一领域的潜力。&lt;h4&gt;总结&lt;/h4&gt;该方法在解决PDE及相关问题的操作符学习中展现出显著优势，推动了多操作符学习的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel fine-tuning method to achieve multi-operator learningthrough training a distributed neural operator with diverse function data andthen zero-shot fine-tuning the neural network using physics-informed losses fordownstream tasks. Operator learning effectively approximates solution operatorsfor PDEs and various PDE-related problems, yet it often struggles to generalizeto new tasks. To address this, we investigate fine-tuning a pretrained model,while carefully selecting an initialization that enables rapid adaptation tonew tasks with minimal data. Our approach combines distributed learning tointegrate data from various operators in pre-training, while physics-informedmethods enable zero-shot fine-tuning, minimizing the reliance on downstreamdata. We investigate standard fine-tuning and Low-Rank Adaptation fine-tuning,applying both to train complex nonlinear target operators that are difficult tolearn only using random initialization. Through comprehensive numericalexamples, we demonstrate the advantages of our approach, showcasing significantimprovements in accuracy. Our findings provide a robust framework for advancingmulti-operator learning and highlight the potential of transfer learningtechniques in this domain.</description>
      <author>example@mail.com (Zecheng Zhang, Christian Moya, Lu Lu, Guang Lin, Hayden Schaeffer)</author>
      <guid isPermaLink="false">2411.07239v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>ReMP: Reusable Motion Prior for Multi-domain 3D Human Pose Estimation and Motion Inbetweening</title>
      <link>http://arxiv.org/abs/2411.09435v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 main pages, WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种可重用的运动先验（ReMP），用于准确跟踪各种下游任务中的运动时间演变。&lt;h4&gt;目的&lt;/h4&gt;通过建立一个稳健的时空运动先验，旨在捕捉适用于多种传感器模式的3D动态。&lt;h4&gt;方法&lt;/h4&gt;从完整的人体姿态参数模型序列中学习丰富的运动先验，采用时序注意机制处理缺失帧或噪声测量。&lt;h4&gt;主要发现&lt;/h4&gt;该运动先验能够在严重遮挡情况下估计姿态，并在不完整和具有挑战性的输入测量中提取关键信息，从而显著提高网格序列恢复的训练效率。&lt;h4&gt;结论&lt;/h4&gt;ReMP在各种实际的3D运动数据（包括深度点云、LiDAR扫描和IMU传感器数据）上持续优于基线方法。&lt;h4&gt;总结&lt;/h4&gt;ReMP展示了在多种传感器数据处理中的有效性，提供了一个项目页面以供进一步探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Reusable Motion prior (ReMP), an effective motion prior that canaccurately track the temporal evolution of motion in various downstream tasks.Inspired by the success of foundation models, we argue that a robustspatio-temporal motion prior can encapsulate underlying 3D dynamics applicableto various sensor modalities. We learn the rich motion prior from a sequence ofcomplete parametric models of posed human body shape. Our prior can easilyestimate poses in missing frames or noisy measurements despite significantocclusion by employing a temporal attention mechanism. More interestingly, ourprior can guide the system with incomplete and challenging input measurementsto quickly extract critical information to estimate the sequence of poses,significantly improving the training efficiency for mesh sequence recovery.ReMP consistently outperforms the baseline method on diverse and practical 3Dmotion data, including depth point clouds, LiDAR scans, and IMU sensor data.Project page is available in https://hojunjang17.github.io/ReMP.</description>
      <author>example@mail.com (Hojun Jang, Young Min Kim)</author>
      <guid isPermaLink="false">2411.09435v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>DeepCRF: Deep Learning-Enhanced CSI-Based RF Fingerprinting for Channel-Resilient WiFi Device Identification</title>
      <link>http://arxiv.org/abs/2411.06925v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文提出了DeepCRF框架，利用深度学习从信道状态信息(CSI)测量中提取微小信号，以实现商业现成(WiFi)设备的鲁棒无线频率指纹识别(RFF)。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，克服之前基于信号空间的方法在非视距(NLoS)条件下的局限性。&lt;h4&gt;方法&lt;/h4&gt;DeepCRF结合了经过精心训练的卷积神经网络(CNN)、模型启发的数据增强、监督对比学习和决策融合技术，以提高在未见信道条件下的泛化能力和抗噪声能力。&lt;h4&gt;主要发现&lt;/h4&gt;DeepCRF在不同信道下显著提高了设备识别准确率，平均识别准确率为99.53%。&lt;h4&gt;结论&lt;/h4&gt;DeepCRF的性能超越了信号空间基线和现有最先进的神经网络基准，显示出其在现实世界未见场景中的有效性。&lt;h4&gt;总结&lt;/h4&gt;DeepCRF框架能够在多种信道条件下实现高精度的设备识别，为无线频率指纹技术提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Oriseven/DeepCRF_TIFS&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents DeepCRF, a new framework that harnesses deep learning toextract subtle micro-signals from channel state information (CSI) measurements,enabling robust and resilient radio-frequency fingerprinting (RFF) ofcommercial-off-the-shelf (COTS) WiFi devices across diverse channel conditions.Building on our previous research, which demonstrated that micro-signals inCSI, termed micro-CSI, most likely originate from RF circuitry imperfectionsand can serve as unique RF fingerprints, we develop a new approach to overcomethe limitations of our prior signal space-based method. While the signalspace-based method is effective in strong line-of-sight (LoS) conditions, weshow that it struggles with the complexities of non-line-of-sight (NLoS)scenarios, compromising the robustness of CSI-based RFF. To address thischallenge, DeepCRF incorporates a carefully trained convolutional neuralnetwork (CNN) with model-inspired data augmentation, supervised contrastivelearning, and decision fusion techniques, enhancing its generalizationcapabilities across unseen channel conditions and resilience against noise. Ourevaluations demonstrate that DeepCRF significantly improves deviceidentification accuracy across diverse channels, outperforming both the signalspace-based baseline and state-of-the-art neural network-based benchmarks.Notably, it achieves an average identification accuracy of 99.53% among 19 COTSWiFi network interface cards in real-world unseen scenarios using 4 CSImeasurements per identification procedure.</description>
      <author>example@mail.com (Ruiqi Kong, He Chen)</author>
      <guid isPermaLink="false">2411.06925v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Zero-shot capability of SAM-family models for bone segmentation in CT scans</title>
      <link>http://arxiv.org/abs/2411.08629v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Segment Anything Model (SAM)及类似模型构成了一系列可提示的基础模型，用于图像和视频分割。&lt;h4&gt;目的&lt;/h4&gt;评估这些模型在医学图像分割中的优缺点，特别是在骨骼CT扫描中的表现。&lt;h4&gt;方法&lt;/h4&gt;使用非迭代的'最佳'提示策略，包括边界框、点和组合，测试SAM系列模型在三个不同骨骼区域的零-shot能力。&lt;h4&gt;主要发现&lt;/h4&gt;最佳设置取决于模型类型和大小、数据集特征及优化目标。SAM和SAM2在所有测试设置中，使用边界框结合中心点的提示效果最佳。&lt;h4&gt;结论&lt;/h4&gt;结果受多种因素影响，提供了在2D提示中使用非交互式'最佳'提示的决策指南。&lt;h4&gt;总结&lt;/h4&gt;本研究填补了骨骼CT分割领域的评估空白，强调了不同提示策略的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Segment Anything Model (SAM) and similar models build a family ofpromptable foundation models (FMs) for image and video segmentation. The objectof interest is identified using prompts, such as bounding boxes or points. Withthese FMs becoming part of medical image segmentation, extensive evaluationstudies are required to assess their strengths and weaknesses in clinicalsetting. Since the performance is highly dependent on the chosen promptingstrategy, it is important to investigate different prompting techniques todefine optimal guidelines that ensure effective use in medical imagesegmentation. Currently, no dedicated evaluation studies exist specifically forbone segmentation in CT scans, leaving a gap in understanding the performancefor this task. Thus, we use non-iterative, ``optimal'' prompting strategiescomposed of bounding box, points and combinations to test the zero-shotcapability of SAM-family models for bone CT segmentation on three differentskeletal regions. Our results show that the best settings depend on the modeltype and size, dataset characteristics and objective to optimize. Overall, SAMand SAM2 prompted with a bounding box in combination with the center point forall the components of an object yield the best results across all testedsettings. As the results depend on multiple factors, we provide a guideline forinformed decision-making in 2D prompting with non-interactive, ''optimal''prompts.</description>
      <author>example@mail.com (Caroline Magg, Hoel Kervadec, Clara I. Sánchez)</author>
      <guid isPermaLink="false">2411.08629v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Decoding Visual Experience and Mapping Semantics through Whole-Brain Analysis Using fMRI Foundation Models</title>
      <link>http://arxiv.org/abs/2411.07121v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;神经解码是理解大脑活动与不同刺激之间关系的过程，已成为认知科学的主要目标。&lt;h4&gt;目的&lt;/h4&gt;通过算法增强对视觉过程的理解，涉及整个大脑激活图。&lt;h4&gt;方法&lt;/h4&gt;使用大规模fMRI编码器和在大型公共数据集上预训练的图像生成模型，通过图像-fMRI对比学习进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进的方法相比，预测语义准确性提高了43%。默认模式网络在刺激解码中贡献最大。&lt;h4&gt;结论&lt;/h4&gt;模型能够在不同场景中捕捉语义含义，验证数据集的零-shot想象解码取得了显著结果。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的算法超越了传统的视觉皮层限制，实现了对整个大脑的视觉体验解码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ppwangyc/wave&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural decoding, the process of understanding how brain activity correspondsto different stimuli, has been a primary objective in cognitive sciences. Overthe past three decades, advancements in functional Magnetic Resonance Imagingand machine learning have greatly improved our ability to map visual stimuli tobrain activity, especially in the visual cortex. Concurrently, research hasexpanded into decoding more complex processes like language and memory acrossthe whole brain, utilizing techniques to handle greater variability and improvesignal accuracy. We argue that "seeing" involves more than just mapping visualstimuli onto the visual cortex; it engages the entire brain, as variousemotions and cognitive states can emerge from observing different scenes. Inthis paper, we develop algorithms to enhance our understanding of visualprocesses by incorporating whole-brain activation maps while individuals areexposed to visual stimuli. We utilize large-scale fMRI encoders and Imagegenerative models pre-trained on large public datasets, which are thenfine-tuned through Image-fMRI contrastive learning. Our models hence can decodevisual experience across the entire cerebral cortex, surpassing the traditionalconfines of the visual cortex. We first compare our method withstate-of-the-art approaches to decoding visual processing and show improvedpredictive semantic accuracy by 43%. A network ablation analysis suggests thatbeyond the visual cortex, the default mode network contributes most to decodingstimuli, in line with the proposed role of this network in sense-making andsemantic processing. Additionally, we implemented zero-shot imaginationdecoding on an extra validation dataset, achieving a p-value of 0.0206 formapping the reconstructed images and ground-truth text stimuli, whichsubstantiates the model's capability to capture semantic meanings acrossvarious scenarios.</description>
      <author>example@mail.com (Yanchen Wang, Adam Turnbull, Tiange Xiang, Yunlong Xu, Sa Zhou, Adnan Masoud, Shekoofeh Azizi, Feng Vankee Lin, Ehsan Adeli)</author>
      <guid isPermaLink="false">2411.07121v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Quasi-Static Time Series Simulations with Foundation Models</title>
      <link>http://arxiv.org/abs/2411.08652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Equal contributors: A.P. and F.M.; Lead contact: A.P&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准静态时间序列(QSTS)模拟在评估电网接纳大规模分布式能源资源的能力方面具有巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过新引入的电网基础模型提高神经电力流求解器的经济可行性。&lt;h4&gt;方法&lt;/h4&gt;提出神经电力流求解器作为替代方案，提升电力流计算速度，同时探讨电网基础模型的应用。&lt;h4&gt;主要发现&lt;/h4&gt;神经电力流求解器能够提升计算速度3到4个数量级，但训练成本高。&lt;h4&gt;结论&lt;/h4&gt;通过电网基础模型，可以在减少训练成本的同时，支持电网操作和规划任务。&lt;h4&gt;建议&lt;/h4&gt;呼吁AI与电力电网社区合作，开发和开源这些模型，使所有运营商能受益于AI技术。&lt;h4&gt;总结&lt;/h4&gt;通过合作开发电网基础模型，能够降低神经电力流求解器的使用门槛，帮助资源有限的运营商。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quasi-static time series (QSTS) simulations have great potential forevaluating the grid's ability to accommodate the large-scale integration ofdistributed energy resources. However, as grids expand and operate closer totheir limits, iterative power flow solvers, central to QSTS simulations, becomecomputationally prohibitive and face increasing convergence issues. Neuralpower flow solvers provide a promising alternative, speeding up power flowcomputations by 3 to 4 orders of magnitude, though they are costly to train. Inthis paper, we envision how recently introduced grid foundation models couldimprove the economic viability of neural power flow solvers. Conceptually,these models amortize training costs by serving as a foundation for a range ofgrid operation and planning tasks beyond power flow solving, with only minimalfine-tuning required. We call for collaboration between the AI and power gridcommunities to develop and open-source these models, enabling all operators,even those with limited resources, to benefit from AI without buildingsolutions from scratch.</description>
      <author>example@mail.com (Alban Puech, François Mirallès, Jonas Weiss, Vincent Mai, Alexandre Blondin Massé, Martin de Montigny, Thomas Brunschwiler, Hendrik F. Hamann)</author>
      <guid isPermaLink="false">2411.08652v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>UniHR: Hierarchical Representation Learning for Unified Knowledge Graph Link Prediction</title>
      <link>http://arxiv.org/abs/2411.07019v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;超关系事实、时间事实和嵌套事实等超三元事实表示越来越受到关注。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的层次表示学习框架（UniHR），以实现统一的知识图谱链接预测。&lt;h4&gt;方法&lt;/h4&gt;UniHR框架包括统一的层次数据表示模块（HiDR）和统一的层次结构学习模块（HiSL）作为图编码器，HiDR模块将不同类型的知识图谱统一为基于三元组的表示，HiSL模块则通过信息传递增强事实内的语义信息和事实间的结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;在3种类型的知识图谱的7个数据集上的实验结果表明，UniHR优于为特定类型知识图谱设计的基线模型，显示出HiDR形式的强泛化能力和HiSL模块的有效性。&lt;h4&gt;结论&lt;/h4&gt;UniHR框架在知识图谱链接预测任务中表现出色，具有较强的适应性。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种有效的方法来整合和处理多种类型的知识图谱表示，推动了链接预测领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lza12a/unihr&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Beyond-triple fact representations including hyper-relational facts withauxiliary key-value pairs, temporal facts with additional timestamps, andnested facts implying relationships between facts, are gaining significantattention. However, existing link prediction models are usually designed forone specific type of facts, making it difficult to generalize to other factrepresentations. To overcome this limitation, we propose a Unified HierarchicalRepresentation learning framework (UniHR) for unified knowledge graph linkprediction. It consists of a unified Hierarchical Data Representation (HiDR)module and a unified Hierarchical Structure Learning (HiSL) module as graphencoder. The HiDR module unifies hyper-relational KGs, temporal KGs, and nestedfactual KGs into triple-based representations. Then HiSL incorporatesintra-fact and inter-fact message passing, focusing on enhancing the semanticinformation within individual facts and enriching the structural informationbetween facts. Experimental results across 7 datasets from 3 types of KGsdemonstrate that our UniHR outperforms baselines designed for one specific kindof KG, indicating strong generalization capability of HiDR form and theeffectiveness of HiSL module. Code and data are available athttps://github.com/Lza12a/UniHR.</description>
      <author>example@mail.com (Zhiqiang Liu, Mingyang Chen, Yin Hua, Zhuo Chen, Ziqi Liu, Lei Liang, Huajun Chen, Wen Zhang)</author>
      <guid isPermaLink="false">2411.07019v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks in Supply Chain Analytics and Optimization: Concepts, Perspectives, Dataset and Benchmarks</title>
      <link>http://arxiv.org/abs/2411.08550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 Pages. Extended journal version of SupplyGraph (arXiv:2401.15299).
  In Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在多个领域（如运输、生物信息学、语言和图像处理）获得了广泛关注，但在供应链管理中的应用研究仍然有限。&lt;h4&gt;目的&lt;/h4&gt;探讨供应链与图结构的连接，以有效应用GNN，并提供详细的框架和实例。&lt;h4&gt;方法&lt;/h4&gt;提供数学定义和任务指导，并提出来自孟加拉国领先快速消费品公司的一组多视角真实世界基准数据集，重点关注供应链规划。&lt;h4&gt;主要发现&lt;/h4&gt;GNN模型在回归、分类和检测任务中表现优于传统统计机器学习和其他深度学习模型，改善幅度在10-40%之间。&lt;h4&gt;结论&lt;/h4&gt;本研究为使用GNN解决供应链问题奠定了基础，支持通过概念讨论、方法论见解和全面数据集的提供。&lt;h4&gt;总结&lt;/h4&gt;GNN在供应链管理中的应用前景广阔，研究提供了理论支持和实践指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/CIOL-SUST/SCG&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have recently gained traction in transportation,bioinformatics, language and image processing, but research on theirapplication to supply chain management remains limited. Supply chains areinherently graph-like, making them ideal for GNN methodologies, which canoptimize and solve complex problems. The barriers include a lack of properconceptual foundations, familiarity with graph applications in SCM, andreal-world benchmark datasets for GNN-based supply chain research. To addressthis, we discuss and connect supply chains with graph structures for effectiveGNN application, providing detailed formulations, examples, mathematicaldefinitions, and task guidelines. Additionally, we present a multi-perspectivereal-world benchmark dataset from a leading FMCG company in Bangladesh,focusing on supply chain planning. We discuss various supply chain tasks usingGNNs and benchmark several state-of-the-art models on homogeneous andheterogeneous graphs across six supply chain analytics tasks. Our analysisshows that GNN-based models consistently outperform statistical MachineLearning and other Deep Learning models by around 10-30% in regression, 10-30%in classification and detection tasks, and 15-40% in anomaly detection tasks ondesignated metrics. With this work, we lay the groundwork for solving supplychain problems using GNNs, supported by conceptual discussions, methodologicalinsights, and a comprehensive dataset.</description>
      <author>example@mail.com (Azmine Toushik Wasi, MD Shafikul Islam, Adipto Raihan Akib, Mahathir Mohammad Bappy)</author>
      <guid isPermaLink="false">2411.08550v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>OSMLoc: Single Image-Based Visual Localization in OpenStreetMap with Geometric and Semantic Guidances</title>
      <link>http://arxiv.org/abs/2411.08665v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;OpenStreetMap (OSM) 是一种广泛使用的志愿地理信息源，帮助人类通过匹配附近的视觉观察与矢量地图数据进行自我定位。然而，图像与OSM的匹配和定位对机器人来说仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出OSMLoc方法，以提高无人地面车辆和物流行业中志愿地理信息数据的利用率。&lt;h4&gt;方法&lt;/h4&gt;OSMLoc是一种受人脑启发的单图像视觉定位方法，结合了语义和几何指导。首先，使用视觉基础模型提取强大的图像特征；其次，提出几何引导的深度分布适配器；最后，利用OSM数据的语义嵌入作为辅助指导进行图像与OSM特征匹配。&lt;h4&gt;主要发现&lt;/h4&gt;通过在MGL数据集、CC验证基准和KITTI数据集上的实验，验证了所提出方法的优越性。&lt;h4&gt;结论&lt;/h4&gt;OSMLoc方法在提高定位准确性、鲁棒性和泛化能力方面表现出色。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新颖的视觉定位方法，并通过广泛的实验验证了其有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; OpenStreetMap (OSM), an online and versatile source of volunteered geographicinformation (VGI), is widely used for human self-localization by matchingnearby visual observations with vectorized map data. However, due to thedivergence in modalities and views, image-to-OSM (I2O) matching andlocalization remain challenging for robots, preventing the full utilization ofVGI data in the unmanned ground vehicles and logistic industry. Inspired by thefact that the human brain relies on geometric and semantic understanding ofsensory information for spatial localization tasks, we propose the OSMLoc inthis paper. OSMLoc is a brain-inspired single-image visual localization methodwith semantic and geometric guidance to improve accuracy, robustness, andgeneralization ability. First, we equip the OSMLoc with the visual foundationalmodel to extract powerful image features. Second, a geometry-guided depthdistribution adapter is proposed to bridge the monocular depth estimation andcamera-to-BEV transform. Thirdly, the semantic embeddings from the OSM data areutilized as auxiliary guidance for image-to-OSM feature matching. To validatethe proposed OSMLoc, we collect a worldwide cross-area and cross-condition (CC)benchmark for extensive evaluation. Experiments on the MGL dataset, CCvalidation benchmark, and KITTI dataset have demonstrated the superiority ofour method. Code, pre-trained models, CC validation benchmark, and additionalresults are available on: https://github.com/WHU-USI3DV/OSMLoc</description>
      <author>example@mail.com (Youqi Liao, Xieyuanli Chen, Shuhao Kang, Jianping Li, Zhen Dong, Hongchao Fan, Bisheng Yang)</author>
      <guid isPermaLink="false">2411.08665v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Invar-RAG: Invariant LLM-aligned Retrieval for Better Generation</title>
      <link>http://arxiv.org/abs/2411.07021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;检索增强生成（RAG）在提供可靠答案预测和解决幻觉问题方面表现出色。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的两阶段微调架构Invar-RAG，以解决直接应用LLM到RAG系统中所面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;在检索阶段，构建LLM基础的检索器，结合LoRA基础的表示学习，处理特征局部性问题；开发不变和变异模式，使用不变损失减少LLM方差。在生成阶段，采用精细化的微调方法提高LLM生成答案的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;Invar-RAG在三个开放域问答数据集上显著优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;Invar-RAG有效提高了基于检索信息生成答案的准确性，并提供了代码以便复现。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的Invar-RAG架构通过改进检索和生成阶段的过程，有效解决了LLM在RAG系统中的应用问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieval-augmented generation (RAG) has shown impressive capability inproviding reliable answer predictions and addressing hallucination problems. Atypical RAG implementation uses powerful retrieval models to extract externalinformation and large language models (LLMs) to generate answers. In contrast,recent LLM-based retrieval has gained attention for its substantialimprovements in information retrieval (IR) due to the LLMs' semanticunderstanding capability. However, directly applying LLM to RAG systemspresents challenges. This may cause feature locality problems as massiveparametric knowledge can hinder effective usage of global information acrossthe corpus; for example, an LLM-based retriever often inputs document summariesinstead of full documents. Moreover, various pre-trained tasks in LLMsintroduce variance, further weakening performance as a retriever.  To address these issues, we propose a novel two-stage fine-tuningarchitecture called Invar-RAG. In the retrieval stage, an LLM-based retrieveris constructed by integrating LoRA-based representation learning to tacklefeature locality issues. To enhance retrieval performance, we develop twopatterns (invariant and variant patterns) and an invariance loss to reduce LLMvariance. In the generation stage, a refined fine-tuning method is employed toimprove LLM accuracy in generating answers based on retrieved information.Experimental results show that Invar-RAG significantly outperforms existingbaselines across three open-domain question answering (ODQA) datasets. Code isavailable in the Supplementary Material for reproducibility.</description>
      <author>example@mail.com (Ziwei Liu, Liang Zhang, Qian Li, Jianghua Wu, Guangxu Zhu)</author>
      <guid isPermaLink="false">2411.07021v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>TDGCN-Based Mobile Multiuser Physical-Layer Authentication for EI-Enabled IIoT</title>
      <link>http://arxiv.org/abs/2411.08628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物理层认证（PLA）提供内生安全、轻量级实现和高可靠性，是边缘智能（EI）赋能的工业物联网（IIoT）中上层安全方法的有希望的补充。&lt;h4&gt;目的&lt;/h4&gt;解决基于信道状态信息（CSI）的PLA方案在低信噪比（SNR）环境下识别移动多用户的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出基于时序动态图卷积网络（TDGCN）的PLA方案，利用智能反射表面（IRS）提高CSI指纹精度，并采用图神经网络（GNN）捕获用户移动和IRS部署引起的时空动态。&lt;h4&gt;主要发现&lt;/h4&gt;将分层CSI指纹划分为多元时间序列，动态GNNs捕获其关联性，时序卷积网络（TCNs）处理每个CSI指纹维度的时间依赖性。&lt;h4&gt;结论&lt;/h4&gt;动态图同构网络（GINs）和级联节点聚类池进一步实现高效信息聚合和降低计算复杂度。仿真结果表明，该方案的认证准确性优于七个基线方案。&lt;h4&gt;总结&lt;/h4&gt;提出的TDGCN-based PLA方案有效提升了在复杂环境下的用户认证性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physical-Layer Authentication (PLA) offers endogenous security, lightweightimplementation, and high reliability, making it a promising complement toupper-layer security methods in Edge Intelligence (EI)-empowered IndustrialInternet of Things (IIoT). However, state-of-the-art Channel State Information(CSI)-based PLA schemes face challenges in recognizing mobile multi-users dueto the limited reliability of CSI fingerprints in low Signal-to-Noise Ratio(SNR) environments and the constantly shifting CSI distributions with usermovements. To address these issues, we propose a Temporal Dynamic GraphConvolutional Network (TDGCN)-based PLA scheme. This scheme harnessesIntelligent Reflecting Surfaces (IRSs) to refine CSI fingerprint precision andemploys Graph Neural Networks (GNNs) to capture the spatio-temporal dynamicsinduced by user movements and IRS deployments. Specifically, we partitionhierarchical CSI fingerprints into multivariate time series and utilize dynamicGNNs to capture their associations. Additionally, Temporal ConvolutionalNetworks (TCNs) handle temporal dependencies within each CSI fingerprintdimension. Dynamic Graph Isomorphism Networks (GINs) and cascade nodeclustering pooling further enable efficient information aggregation and reducedcomputational complexity. Simulations demonstrate the proposed scheme'ssuperior authentication accuracy compared to seven baseline schemes.</description>
      <author>example@mail.com (Rui Meng, Hangyu Zhao, Bingxuan Xu, Yining Wang, Xiaodong Xu, Suyu Lv, Xiaofeng Tao, Ping Zhang)</author>
      <guid isPermaLink="false">2411.08628v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-enhanced Network for Hateful Meme Classification</title>
      <link>http://arxiv.org/abs/2411.07527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Proceedings of the Thirty-Third International Joint
  Conference on Artificial Intelligence Main Track. Pages 6397-6405&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社交媒体的快速扩展导致仇恨迷因在媒体平台上的泛滥，迫切需要有效的识别和移除手段。&lt;h4&gt;目的&lt;/h4&gt;开发一种新框架Pen，以提高仇恨迷因的分类效率。&lt;h4&gt;方法&lt;/h4&gt;基于提示学习的方法构建序列，通过语言模型编码，并进行区域信息的全局提取以实现多视角感知，引入提示感知对比学习以增强特征空间的推理能力。&lt;h4&gt;主要发现&lt;/h4&gt;Pen框架在两个公共数据集上的广泛消融实验显示，其在仇恨迷因分类任务中优于传统手动提示方法，具有更好的泛化能力和分类准确性。&lt;h4&gt;结论&lt;/h4&gt;Pen框架显著提高了模型的分类准确性，是仇恨迷因分类的有效工具。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，Pen框架在仇恨迷因分类任务中表现出色，且代码可在GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.24963/ijcai.2024/707&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/juszzi/pen&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The dynamic expansion of social media has led to an inundation of hatefulmemes on media platforms, accentuating the growing need for efficientidentification and removal. Acknowledging the constraints of conventionalmultimodal hateful meme classification, which heavily depends on externalknowledge and poses the risk of including irrelevant or redundant content, wedeveloped Pen -- a prompt-enhanced network framework based on the promptlearning approach. Specifically, after constructing the sequence through theprompt method and encoding it with a language model, we performed regioninformation global extraction on the encoded sequence for multi-viewperception. By capturing global information about inference instances anddemonstrations, Pen facilitates category selection by fully leveraging sequenceinformation. This approach significantly improves model classificationaccuracy. Additionally, to bolster the model's reasoning capabilities in thefeature space, we introduced prompt-aware contrastive learning into theframework to improve the quality of sample feature distributions. Throughextensive ablation experiments on two public datasets, we evaluate theeffectiveness of the Pen framework, concurrently comparing it withstate-of-the-art model baselines. Our research findings highlight that Pensurpasses manual prompt methods, showcasing superior generalization andclassification accuracy in hateful meme classification tasks. Our code isavailable at https://github.com/juszzi/Pen.</description>
      <author>example@mail.com (Junxi Liu, Yanyan Feng, Jiehai Chen, Yun Xue, Fenghuan Li)</author>
      <guid isPermaLink="false">2411.07527v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>High-Fidelity Cellular Network Control-Plane Traffic Generation without Domain Knowledge</title>
      <link>http://arxiv.org/abs/2411.07345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着移动核心网络架构的快速演变，大规模控制平面流量的追踪对网络设计和性能优化至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究开发高保真度的移动核心网络控制平面流量生成器。&lt;h4&gt;方法&lt;/h4&gt;利用生成式机器学习模型，尤其是开发一种基于变换器的模型CPT-GPT，而非GAN。&lt;h4&gt;主要发现&lt;/h4&gt;1. CPT-GPT无需依赖领域知识，能够合成与SMM相当保真度的控制平面流量。2. 与传统的基于GAN的方法相比，CPT-GPT显著减少了违反状态语义的流量比例，缩短了流量停留时间分布的最大y距离，并提高了新小时模型的迁移学习效率。&lt;h4&gt;结论&lt;/h4&gt;CPT-GPT有效捕捉了流量样本之间的复杂依赖关系，克服了高保真度流量合成的主要挑战。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了生成式机器学习在控制平面流量合成中的应用潜力，提供了一个新的方向以优化移动核心网络的设计与性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3646547.3688422&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With rapid evolution of mobile core network (MCN) architectures, large-scalecontrol-plane traffic (CPT) traces are critical to studying MCN design andperformance optimization by the R&amp;D community. The prior-art control-planetraffic generator SMM heavily relies on domain knowledge which requiresre-design as the domain evolves. In this work, we study the feasibility ofdeveloping a high-fidelity MCN control plane traffic generator by leveraginggenerative ML models. We identify key challenges in synthesizing high-fidelityCPT including generic (to data-plane) requirements such as multimodalityfeature relationships and unique requirements such as stateful semantics andlong-term (time-of-day) data variations. We show state-of-the-art, generativeadversarial network (GAN)-based approaches shown to work well for data-planetraffic cannot meet these fidelity requirements of CPT, and develop atransformer-based model, CPT-GPT, that accurately captures complex dependenciesamong the samples in each traffic stream (control events by the same UE)without the need for GAN. Our evaluation of CPT-GPT on a large-scalecontrol-plane traffic trace shows that (1) it does not rely on domain knowledgeyet synthesizes control-plane traffic with comparable fidelity as SMM; (2)compared to the prior-art GAN-based approach, it reduces the fraction ofstreams that violate stateful semantics by two orders of magnitude, the maxy-distance of sojourn time distributions of streams by 16.0%, and the transferlearning time in deriving new hourly models by 3.36x.</description>
      <author>example@mail.com (Z. Jonny Kong, Nathan Hu, Y. Charlie Hu, Jiayi Meng, Yaron Koral)</author>
      <guid isPermaLink="false">2411.07345v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Trajectory Generation in 3D Environments with Multi-Level Map Construction</title>
      <link>http://arxiv.org/abs/2411.08323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在复杂的3D环境中，为地面机器人生成全局轨迹是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一个稳健高效的框架来生成地面机器人的全局轨迹。&lt;h4&gt;方法&lt;/h4&gt;采用点云作为输入，利用三角形块构建多级地图，进行运动路径搜索，并优化轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，所提方法在点云噪声下表现出更高的鲁棒性，生成高质量轨迹且保持高计算效率。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法有效解决了复杂环境中的轨迹生成问题，代码将公开发布。&lt;h4&gt;总结&lt;/h4&gt;该研究为地面机器人在复杂3D环境中的导航提供了一个有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a robust and efficient framework to generate global trajectoriesfor ground robots in complex 3D environments. The proposed method takes pointcloud as input and efficiently constructs a multi-level map using triangularpatches as the basic elements. A kinematic path search is adopted on thepatches, where motion primitives on different patches combine to form theglobal min-time cost initial trajectory. We use a same-level expansion methodto locate the nearest obstacle for each trajectory waypoint and construct anobjective function with curvature, smoothness and obstacle terms foroptimization. We evaluate the method on several complex 3D point cloud maps.Compared to existing methods, our method demonstrates higher robustness topoint cloud noise, enabling the generation of high quality trajectory whilemaintaining high computational efficiency. Our code will be publicly availableat https://github.com/ck-tian/MLMC-planner.</description>
      <author>example@mail.com (Chengkun Tian, Xiaohui Gao, Yongguang Liu)</author>
      <guid isPermaLink="false">2411.08323v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>HeteroSample: Meta-path Guided Sampling for Heterogeneous Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2411.07022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物联网（IoT）的快速扩展导致了捕捉设备、传感器和系统之间复杂交互的广泛异构图。&lt;h4&gt;目的&lt;/h4&gt;高效分析这些图对于在智能城市、工业物联网和智能交通系统等场景中获取见解至关重要。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为HeteroSample的新型采样方法，旨在通过保留结构完整性、节点和边类型分布及语义模式来解决现有方法的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;HeteroSample通过引入顶级领导者选择、平衡邻域扩展和元路径引导采样策略，显著提升了对原始数据的代表性，同时减少了计算开销。&lt;h4&gt;结论&lt;/h4&gt;HeteroSample在链接预测和节点分类等任务中比现有最先进的方法表现更好，F1分数提高了15%，运行时间减少了20%。&lt;h4&gt;总结&lt;/h4&gt;HeteroSample是一个变革性的工具，能够有效分析复杂的IoT系统，推动智能城市、工业物联网等领域的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid expansion of Internet of Things (IoT) has resulted in vast,heterogeneous graphs that capture complex interactions among devices, sensors,and systems. Efficient analysis of these graphs is critical for derivinginsights in IoT scenarios such as smart cities, industrial IoT, and intelligenttransportation systems. However, the scale and diversity of IoT-generated datapresent significant challenges, and existing methods often struggle withpreserving the structural integrity and semantic richness of these complexgraphs. Many current approaches fail to maintain the balance betweencomputational efficiency and the quality of the insights generated, leading topotential loss of critical information necessary for accurate decision-makingin IoT applications. We introduce HeteroSample, a novel sampling methoddesigned to address these challenges by preserving the structural integrity,node and edge type distributions, and semantic patterns of IoT-related graphs.HeteroSample works by incorporating the novel top-leader selection, balancedneighborhood expansion, and meta-path guided sampling strategies. The key ideais to leverage the inherent heterogeneous structure and semantic relationshipsencoded by meta-paths to guide the sampling process. This approach ensures thatthe resulting subgraphs are representative of the original data whilesignificantly reducing computational overhead. Extensive experimentsdemonstrate that HeteroSample outperforms state-of-the-art methods, achievingup to 15% higher F1 scores in tasks such as link prediction and nodeclassification, while reducing runtime by 20%.These advantages makeHeteroSample a transformative tool for scalable and accurate IoT applications,enabling more effective and efficient analysis of complex IoT systems,ultimately driving advancements in smart cities, industrial IoT, and beyond.</description>
      <author>example@mail.com (Ao Liu, Jing Chen, Ruiying Du, Cong Wu, Yebo Feng, Teng Li, Jianfeng Ma)</author>
      <guid isPermaLink="false">2411.07022v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>AstroM$^3$: A self-supervised multimodal model for astronomy</title>
      <link>http://arxiv.org/abs/2411.08842v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习模型已广泛应用于天文学研究，但模型输入通常仅限于主要数据源（如图像或时间序列）及少量元数据。&lt;h4&gt;目的&lt;/h4&gt;构建一个天文多模态数据集，并提出AstroM$^3$，一种自监督预训练方法，使模型能够同时学习多种模态。&lt;h4&gt;方法&lt;/h4&gt;扩展CLIP（对比语言-图像预训练）模型至三模态设置，整合时间序列光度数据、光谱和天体物理元数据。&lt;h4&gt;主要发现&lt;/h4&gt;CLIP预训练提高了时间序列光度分类性能，准确率从84.6%提升至91.5%。在标记数据稀缺的情况下，CLIP的分类准确率最多提高12.6%。&lt;h4&gt;结论&lt;/h4&gt;训练后的模型可用于其他下游任务，如误分类识别、相似性搜索和异常检测，并且首次构建了一个n&gt;2的模态模型，未来可扩展至n&gt;3。&lt;h4&gt;总结&lt;/h4&gt;AstroM$^3$展示了多模态学习在天文学中的潜力，尤其是在数据有限的情况下，通过自监督学习有效利用了未标记数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While machine-learned models are now routinely employed to facilitateastronomical inquiry, model inputs tend to be limited to a primary data source(namely images or time series) and, in the more advanced approaches, somemetadata. Yet with the growing use of wide-field, multiplexed observationalresources, individual sources of interest often have a broad range ofobservational modes available. Here we construct an astronomical multimodaldataset and propose AstroM$^3$, a self-supervised pre-training approach thatenables a model to learn from multiple modalities simultaneously. Specifically,we extend the CLIP (Contrastive Language-Image Pretraining) model to a trimodalsetting, allowing the integration of time-series photometry data, spectra, andastrophysical metadata. In a fine-tuning supervised setting, our resultsdemonstrate that CLIP pre-training improves classification performance fortime-series photometry, where accuracy increases from 84.6% to 91.5%.Furthermore, CLIP boosts classification accuracy by up to 12.6% when theavailability of labeled data is limited, showing the effectiveness ofleveraging larger corpora of unlabeled data. In addition to fine-tunedclassification, we can use the trained model in other downstream tasks that arenot explicitly contemplated during the construction of the self-supervisedmodel. In particular we show the efficacy of using the learned embeddings formisclassifications identification, similarity search, and anomaly detection.One surprising highlight is the "rediscovery" of Mira subtypes and twoRotational variable subclasses using manifold learning and dimension reductionalgorithm. To our knowledge this is the first construction of an $n&gt;2$ modemodel in astronomy. Extensions to $n&gt;3$ modes is naturally anticipated withthis approach.</description>
      <author>example@mail.com (Mariia Rizhko, Joshua S. Bloom)</author>
      <guid isPermaLink="false">2411.08842v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian Mixture Models Based Augmentation Enhances GNN Generalization</title>
      <link>http://arxiv.org/abs/2411.08638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在节点和图分类等任务中表现出色，但在未见或分布外（OOD）数据上的泛化能力较弱。&lt;h4&gt;目的&lt;/h4&gt;解决GNNs在有限大小或多样性训练数据下的泛化问题。&lt;h4&gt;方法&lt;/h4&gt;提出使用Rademacher复杂度的理论框架计算泛化误差的遗憾界限，并探讨数据增强的影响。&lt;h4&gt;主要发现&lt;/h4&gt;设计了GMM-GDA，一种高效的图数据增强算法，利用高斯混合模型（GMMs）近似任何分布。&lt;h4&gt;结论&lt;/h4&gt;该方法在泛化能力上优于现有的数据增强技术，同时改善了时间复杂度，适合实际应用。&lt;h4&gt;总结&lt;/h4&gt;通过理论框架和GMM-GDA算法，提升了GNNs在数据增强方面的表现，解决了泛化能力的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown great promise in tasks like node andgraph classification, but they often struggle to generalize, particularly tounseen or out-of-distribution (OOD) data. These challenges are exacerbated whentraining data is limited in size or diversity. To address these issues, weintroduce a theoretical framework using Rademacher complexity to compute aregret bound on the generalization error and then characterize the effect ofdata augmentation. This framework informs the design of GMM-GDA, an efficientgraph data augmentation (GDA) algorithm leveraging the capability of GaussianMixture Models (GMMs) to approximate any distribution. Our approach not onlyoutperforms existing augmentation techniques in terms of generalization butalso offers improved time complexity, making it highly suitable for real-worldapplications.</description>
      <author>example@mail.com (Yassine Abbahaddou, Fragkiskos D. Malliaros, Johannes F. Lutzeyer, Amine Mohamed Aboussalah, Michalis Vazirgiannis)</author>
      <guid isPermaLink="false">2411.08638v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>AuscultaBase: A Foundational Step Towards AI-Powered Body Sound Diagnostics</title>
      <link>http://arxiv.org/abs/2411.07547v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;内脏声音的听诊对诊断多种健康状况至关重要，但受限于临床医生的专业知识和人耳的声音感知能力，其有效性常常受到限制。&lt;h4&gt;目的&lt;/h4&gt;提出AuscultaBase框架，以通过创新的数据集成和对比学习技术，提升身体声音的诊断能力。&lt;h4&gt;方法&lt;/h4&gt;编制AuscultaBase-Corpus，构建AuscultaBase-Model，并建立AuscultaBase-Bench以评估各种开源声学预训练模型的性能。&lt;h4&gt;主要发现&lt;/h4&gt;我们的模型在16个任务中有12个任务的表现超过所有其他开源模型，证明了我们方法在身体声音分析中的有效性。&lt;h4&gt;结论&lt;/h4&gt;AuscultaBase框架有效提升了身体声音的诊断能力，为临床应用提供了支持。&lt;h4&gt;总结&lt;/h4&gt;通过综合多源数据和对比学习，AuscultaBase为身体声音的诊断提供了新的基础和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Auscultation of internal body sounds is essential for diagnosing a range ofhealth conditions, yet its effectiveness is often limited by clinicians'expertise and the acoustic constraints of human hearing, restricting its useacross various clinical scenarios. To address these challenges, we introduceAuscultaBase, a foundational framework aimed at advancing body sounddiagnostics through innovative data integration and contrastive learningtechniques. Our contributions include the following: First, we compileAuscultaBase-Corpus, a large-scale, multi-source body sound databaseencompassing 11 datasets with 40,317 audio recordings and totaling 322.4 hoursof heart, lung, and bowel sounds. Second, we develop AuscultaBase-Model, afoundational diagnostic model for body sounds, utilizing contrastive learningon the compiled corpus. Third, we establish AuscultaBase-Bench, a comprehensivebenchmark containing 16 sub-tasks, assessing the performance of variousopen-source acoustic pre-trained models. Evaluation results indicate that ourmodel outperforms all other open-source models in 12 out of 16 tasks,demonstrating the efficacy of our approach in advancing diagnostic capabilitiesfor body sound analysis.</description>
      <author>example@mail.com (Pingjie Wang, Zihan Zhao, Liudan Zhao, Miao He, Xin Sun, Ya Zhang, Kun Sun, Yanfeng Wang, Yu Wang)</author>
      <guid isPermaLink="false">2411.07547v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Comprehensive and Comparative Analysis between Transfer Learning and Custom Built VGG and CNN-SVM Models for Wildfire Detection</title>
      <link>http://arxiv.org/abs/2411.08171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proc. of the 2024 IEEE International Conference On Intelligent
  Computing in Data Sciences&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当代人工智能（AI）和机器学习（ML）研究重视迁移学习，展示其在提升模型性能方面的潜力。&lt;h4&gt;目的&lt;/h4&gt;研究迁移学习在野火检测中的效率和有效性。&lt;h4&gt;方法&lt;/h4&gt;比较三种专门构建的模型（VGG-7、VGG-10 和 CNN-SVM）与三种预训练模型（VGG-16、VGG-19 和 ResNet101），使用包含不同光照条件、时间和地形的野火数据集进行训练和评估。&lt;h4&gt;主要发现&lt;/h4&gt;通过评估准确率、精确率、召回率和F1分数，获得对迁移学习在野火检测中的优缺点的全面理解。&lt;h4&gt;结论&lt;/h4&gt;本研究为AI和ML研究的未来方向提供了有价值的见解，促进了对迁移学习的深入讨论。&lt;h4&gt;关键词&lt;/h4&gt;野火预测、深度学习、机器学习、火灾检测&lt;h4&gt;总结&lt;/h4&gt;迁移学习在复杂的野火检测问题中表现出较好的性能，为相关研究提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contemporary Artificial Intelligence (AI) and Machine Learning (ML) researchplaces a significant emphasis on transfer learning, showcasing itstransformative potential in enhancing model performance across diverse domains.This paper examines the efficiency and effectiveness of transfer learning inthe context of wildfire detection. Three purpose-built models -- VisualGeometry Group (VGG)-7, VGG-10, and Convolutional Neural Network (CNN)-SupportVector Machine(SVM) CNN-SVM -- are rigorously compared with three pretrainedmodels -- VGG-16, VGG-19, and Residual Neural Network (ResNet) ResNet101. Wetrained and evaluated these models using a dataset that captures thecomplexities of wildfires, incorporating variables such as varying lightingconditions, time of day, and diverse terrains. The objective is to discern howtransfer learning performs against models trained from scratch in addressingthe intricacies of the wildfire detection problem. By assessing the performancemetrics, including accuracy, precision, recall, and F1 score, a comprehensiveunderstanding of the advantages and disadvantages of transfer learning in thisspecific domain is obtained. This study contributes valuable insights to theongoing discourse, guiding future directions in AI and ML research. Keywords:Wildfire prediction, deep learning, machine learning fire, detection</description>
      <author>example@mail.com (Aditya V. Jonnalagadda, Hashim A. Hashim, Andrew Harris)</author>
      <guid isPermaLink="false">2411.08171v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Fast and Robust Contextual Node Representation Learning over Dynamic Graphs</title>
      <link>http://arxiv.org/abs/2411.07123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;实际图形随着时间的推移快速增长，需要有效地维护动态图中的节点表示。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的动态图学习框架，以提高PPR（个性化PageRank）在动态图中的维护效率。&lt;h4&gt;方法&lt;/h4&gt;基于稀疏节点注意力的方法，将PPR作为明确的ℓ1正则化优化问题进行处理，并采用近端梯度法（ISTA）来提升PPR-based GNN的效率。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型（GoPPE）通过最大化先前用作注意力的PPR，能够在节点属性噪声较大时表现出色，且在性能上与现有基线模型相当或更好。&lt;h4&gt;结论&lt;/h4&gt;GoPPE模型展示了在动态图演化中的有效性和鲁棒性，特别是在节点初始属性噪声较大时，显著优于传统方法。&lt;h4&gt;总结&lt;/h4&gt;本文通过改进PPR的维护效率，提出了一种新的动态图学习方法，推动了GNN在动态环境中的应用和发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world graphs grow rapidly with edge and vertex insertions over time,motivating the problem of efficiently maintaining robust node representationover evolving graphs. Recent efficient GNNs are designed to decouple recursivemessage passing from the learning process, and favor Personalized PageRank(PPR) as the underlying feature propagation mechanism. However, most PPR-basedGNNs are designed for static graphs, and efficient PPR maintenance remains asan open problem. Further, there is surprisingly little theoreticaljustification for the choice of PPR, despite its impressive empiricalperformance.  In this paper, we are inspired by the recent PPR formulation as an explicit$\ell_1$-regularized optimization problem and propose a unified dynamic graphlearning framework based on sparse node-wise attention. We also present a setof desired properties to justify the choice of PPR in STOA GNNs, and serves asthe guideline for future node attention designs. Meanwhile, we take advantageof the PPR-equivalent optimization formulation and employ the proximal gradientmethod (ISTA) to improve the efficiency of PPR-based GNNs upto 6 times.Finally, we instantiate a simple-yet-effective model (\textsc{GoPPE}) withrobust positional encodings by maximizing PPR previously used as attention. Themodel performs comparably to or better than the STOA baselines and greatlyoutperforms when the initial node attributes are noisy during graph evolution,demonstrating the effectiveness and robustness of \textsc{GoPPE}.</description>
      <author>example@mail.com (Xingzhi Guo, Silong Wang, Baojian Zhou, Yanghua Xiao, Steven Skiena)</author>
      <guid isPermaLink="false">2411.07123v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models</title>
      <link>http://arxiv.org/abs/2411.08870v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Extended version of EMNLP 2024 paper arXiv:2411.04118. Includes
  additional results on clinical note QA tasks and supervised fine-tuning
  evaluations&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来有研究致力于开发专门用于医疗应用的基础模型，通过在公开的生物医学语料库上进行持续预训练，调整通用的大型语言模型（LLMs）和视觉语言模型（VLMs）。&lt;h4&gt;目的&lt;/h4&gt;比较十个公共'医疗' LLMs 和两个 VLMs 与其基础模型的表现差异。&lt;h4&gt;方法&lt;/h4&gt;直接将每个医疗模型与其对应的基础模型逐一比较，分别优化每个模型的提示，在零/少样本提示和监督微调阶段进行评估，并考虑比较中的统计不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;所有医疗 VLMs 和几乎所有医疗 LLMs 在医疗问答任务的零/少样本提示和监督微调中未能持续超越基础模型。在3-shot设置中，医疗 LLMs 仅在22.7%的情况下优于基础模型，36.8%的情况下表现相同，40.5%的情况下显著劣于基础模型。&lt;h4&gt;结论&lt;/h4&gt;经过特定问答任务的微调后，医疗 LLMs 可显示出性能改善，但这些好处未能延续到基于临床记录的任务。研究表明，最先进的通用模型可能已具备强大的医疗知识和推理能力，并为未来研究的结论提供改进建议。&lt;h4&gt;总结&lt;/h4&gt;该研究挑战了医疗 LLMs 和 VLMs 在医疗任务上的有效性，指出通用模型可能已足够强大，建议加大对未来研究方法的规范化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Several recent works seek to develop foundation models specifically formedical applications, adapting general-purpose large language models (LLMs) andvision-language models (VLMs) via continued pretraining on publicly availablebiomedical corpora. These works typically claim that such domain-adaptivepretraining (DAPT) improves performance on downstream medical tasks, such asanswering medical licensing exam questions. In this paper, we compare tenpublic "medical" LLMs and two VLMs against their corresponding base models,arriving at a different conclusion: all medical VLMs and nearly all medicalLLMs fail to consistently improve over their base models in the zero-/few-shotprompting and supervised fine-tuning regimes for medical question-answering(QA). For instance, across all tasks and model pairs we consider in the 3-shotsetting, medical LLMs only outperform their base models in 22.7% of cases,reach a (statistical) tie in 36.8% of cases, and are significantly worse thantheir base models in the remaining 40.5% of cases. Our conclusions are based on(i) comparing each medical model head-to-head, directly against thecorresponding base model; (ii) optimizing the prompts for each model separatelyin zero-/few-shot prompting; and (iii) accounting for statistical uncertaintyin comparisons. While these basic practices are not consistently adopted in theliterature, our ablations show that they substantially impact conclusions.Meanwhile, we find that after fine-tuning on specific QA tasks, medical LLMscan show performance improvements, but the benefits do not carry over to tasksbased on clinical notes. Our findings suggest that state-of-the-artgeneral-domain models may already exhibit strong medical knowledge andreasoning capabilities, and offer recommendations to strengthen the conclusionsof future studies.</description>
      <author>example@mail.com (Daniel P. Jeong, Pranav Mani, Saurabh Garg, Zachary C. Lipton, Michael Oberst)</author>
      <guid isPermaLink="false">2411.08870v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>ScaleNet: Scale Invariance Learning in Directed Graphs</title>
      <link>http://arxiv.org/abs/2411.08758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Scale invariance in node classification is demonstrated and applied
  in graph transformation to develop ScaleNet, which achieves state-of-the-art
  performance on both homophilic and heterophilic directed graphs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在关系数据分析方面取得了进展，但缺乏图像分类中常见的不变性学习技术。&lt;h4&gt;目的&lt;/h4&gt;通过类比图像处理，将尺度不变性概念扩展到节点分类。&lt;h4&gt;方法&lt;/h4&gt;提出了“尺度自我图”的概念，用有序的多重定向边替代传统自我图中的无向单边。&lt;h4&gt;主要发现&lt;/h4&gt;在七个基准数据集上进行实证评估，基于尺度不变性的图学习在简单性、速度和准确性上优于源自随机游走的模型。&lt;h4&gt;结论&lt;/h4&gt;尺度不变性解释了源自随机游走的模型在同质图上的成功和在异质图上的局限性，并提出了ScaleNet架构以利用多尺度特征。&lt;h4&gt;应用&lt;/h4&gt;ScaleNet在七个数据集中的五个（四个同质和一个异质）上取得了最先进的结果，展示了其优秀的适用性。&lt;h4&gt;总结&lt;/h4&gt;这项研究在图学习领域代表了重大进展，提供了一个统一框架，增强了不同类型图的节点分类能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/qin87/scalenet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have advanced relational data analysis but lackinvariance learning techniques common in image classification. In nodeclassification with GNNs, it is actually the ego-graph of the center node thatis classified. This research extends the scale invariance concept to nodeclassification by drawing an analogy to image processing: just as scaleinvariance being used in image classification to capture multi-scale features,we propose the concept of ``scaled ego-graphs''. Scaled ego-graphs generalizetraditional ego-graphs by replacing undirected single-edges with``scaled-edges'', which are ordered sequences of multiple directed edges. Weempirically assess the performance of the proposed scale invariance in graphson seven benchmark datasets, across both homophilic and heterophilicstructures. Our scale-invariance-based graph learning outperforms inceptionmodels derived from random walks by being simpler, faster, and more accurate.The scale invariance explains inception models' success on homophilic graphsand limitations on heterophilic graphs. To ensure applicability of inceptionmodel to heterophilic graphs as well, we further present ScaleNet, anarchitecture that leverages multi-scaled features. ScaleNet achievesstate-of-the-art results on five out of seven datasets (four homophilic and oneheterophilic) and matches top performance on the remaining two, demonstratingits excellent applicability. This represents a significant advance in graphlearning, offering a unified framework that enhances node classification acrossvarious graph types. Our code is available athttps://github.com/Qin87/ScaleNet/tree/July25.</description>
      <author>example@mail.com (Qin Jiang, Chengjia Wang, Michael Lones, Wei Pang)</author>
      <guid isPermaLink="false">2411.08758v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Large Wireless Model (LWM): A Foundation Model for Wireless Channels</title>
      <link>http://arxiv.org/abs/2411.08872v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The LWM model and relevant scripts are available on the LWM website:
  https://lwm-wireless.net/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文提出了大型无线模型（LWM），这是全球首个针对无线信道的基础模型。&lt;h4&gt;目的&lt;/h4&gt;LWM旨在生成通用、丰富的上下文化信道嵌入特征，提升无线通信和传感系统中各种下游任务的性能。&lt;h4&gt;方法&lt;/h4&gt;LWM采用基于变换器的架构，在大规模无线信道数据集上以自监督方式进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;使用LWM嵌入相比于原始信道表示，分类和回归任务的一致性改进，尤其在高复杂性机器学习任务和有限训练数据集的场景中。&lt;h4&gt;结论&lt;/h4&gt;LWM能够从大规模无线数据中学习，为智能系统提供了有效适应多样任务的前景，助力解决无线通信和传感系统中的关键挑战。&lt;h4&gt;总结&lt;/h4&gt;LWM的开发为无线信道建模提供了新的方向，展示了其在不同任务中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://huggingface.co/wi-lab/lwm&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the Large Wireless Model (LWM) -- the world's firstfoundation model for wireless channels. Designed as a task-agnostic model, LWMgenerates universal, rich, contextualized channel embeddings (features) thatpotentially enhance performance across a wide range of downstream tasks inwireless communication and sensing systems. Towards this objective, LWM, whichhas a transformer-based architecture, was pre-trained in a self-supervisedmanner on large-scale wireless channel datasets. Our results show consistentimprovements in classification and regression tasks when using the LWMembeddings compared to raw channel representations, especially in scenarioswith high-complexity machine learning tasks and limited training datasets. ThisLWM's ability to learn from large-scale wireless data opens a promisingdirection for intelligent systems that can efficiently adapt to diverse taskswith limited data, paving the way for addressing key challenges in wirelesscommunication and sensing systems.</description>
      <author>example@mail.com (Sadjad Alikhani, Gouranga Charan, Ahmed Alkhateeb)</author>
      <guid isPermaLink="false">2411.08872v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Variational Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2411.07150v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图表示学习（GRL）是机器学习中的一项基本任务，旨在将高维图结构数据编码为低维向量。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的子图高斯嵌入对比（SGEC）方法，以提高图表示学习的效果。&lt;h4&gt;方法&lt;/h4&gt;引入子图高斯嵌入模块，自适应地将子图映射到结构化高斯空间，利用最优传输距离（包括Wasserstein和Gromov-Wasserstein距离）有效测量子图之间的相似性。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准测试中，SGEC方法的表现超过或与最先进的方法具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;研究结果对自监督学习方法在图表示学习中的设计提供了见解，强调了生成对比对的分布的重要性。&lt;h4&gt;总结&lt;/h4&gt;SGEC方法通过保留图特征和控制生成子图的分布，增强了对比学习过程的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shifengxie/sgec&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning (GRL) is a fundamental task in machinelearning, aiming to encode high-dimensional graph-structured data intolow-dimensional vectors. Self-supervised learning (SSL) methods are widely usedin GRL because they can avoid expensive human annotation. In this work, wepropose a novel Subgraph Gaussian Embedding Contrast (SGEC) method. Ourapproach introduces a subgraph Gaussian embedding module, which adaptively mapssubgraphs to a structured Gaussian space, ensuring the preservation of graphcharacteristics while controlling the distribution of generated subgraphs. Weemploy optimal transport distances, including Wasserstein andGromov-Wasserstein distances, to effectively measure the similarity betweensubgraphs, enhancing the robustness of the contrastive learning process.Extensive experiments across multiple benchmarks demonstrate that SGECoutperforms or presents competitive performance against state-of-the-artapproaches. Our findings provide insights into the design of SSL methods forGRL, emphasizing the importance of the distribution of the generatedcontrastive pairs.</description>
      <author>example@mail.com (Shifeng Xie, Jhony H. Giraldo)</author>
      <guid isPermaLink="false">2411.07150v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Flow reconstruction in time-varying geometries using graph neural networks</title>
      <link>http://arxiv.org/abs/2411.08764v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;该论文提出了一种图注意力卷积网络（GACN），用于从非常稀疏的数据中重建流动场，特别是在时间变化的几何形状中。&lt;h4&gt;目的&lt;/h4&gt;旨在处理极其稀疏的输入数据，以有效重建流动场。&lt;h4&gt;方法&lt;/h4&gt;模型结合了一种特征传播算法作为预处理步骤，利用邻近节点的信息初始化缺失特征，并引入一个二元指示符作为有效性掩码，以区分原始数据和传播数据。&lt;h4&gt;主要发现&lt;/h4&gt;GACN在不同分辨率和领域大小上表现稳健，能够有效处理非结构化数据和可变输入大小。&lt;h4&gt;结论&lt;/h4&gt;与传统卷积神经网络（CNN）和三次插值方法相比，GACN在DNS和PIV测试集上 consistently 显示出更低的重建误差和更好的捕捉细微湍流结构的能力，尤其是在训练时未考虑的新DNS数据和PIV实验数据上效果显著。&lt;h4&gt;总结&lt;/h4&gt;GACN能够有效重建比训练时观察到的领域大14倍的流场，且在更大领域中性能优势更为明显。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The paper presents a Graph Attention Convolutional Network (GACN) for flowreconstruction from very sparse data in time-varying geometries. The modelincorporates a feature propagation algorithm as a preprocessing step to handleextremely sparse inputs, leveraging information from neighboring nodes toinitialize missing features. In addition, a binary indicator is introduced as avalidity mask to distinguish between the original and propagated data points,enabling more effective learning from sparse inputs. Trained on a unique dataset of Direct Numerical Simulations (DNS) of a motored engine at a technicallyrelevant operating condition, the GACN shows robust performance acrossdifferent resolutions and domain sizes and can effectively handle unstructureddata and variable input sizes. The model is tested on previously unseen DNSdata as well as on an experimental data set from Particle Image Velocimetry(PIV) measurements that were not considered during training. A comparativeanalysis shows that the GACN consistently outperforms both a conventionalConvolutional Neural Network (CNN) and cubic interpolation methods on the DNSand PIV test sets by achieving lower reconstruction errors and better capturingfine-scale turbulent structures. In particular, the GACN effectivelyreconstructs flow fields from domains up to 14 times larger than those observedduring training, with the performance advantage increasing for larger domains.</description>
      <author>example@mail.com (Bogdan A. Danciu, Vito A. Pagone, Benjamin Böhm, Marius Schmidt, Christos E. Frouzakis)</author>
      <guid isPermaLink="false">2411.08764v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Predictive Visuo-Tactile Interactive Perception Framework for Object Properties Inference</title>
      <link>http://arxiv.org/abs/2411.09020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主机器人系统在复杂环境中操作时，需要探索物体的未知物理属性，如刚度、质量、重心、摩擦系数和形状。&lt;h4&gt;目的&lt;/h4&gt;精确识别物体属性，以便稳定和可控地操纵物体，并预测操作结果。&lt;h4&gt;方法&lt;/h4&gt;使用配备视觉和触觉传感器的机器人系统，提出了一种新颖的预测感知框架，通过非抓握推和抓握拉等多样化探索行为来识别物体属性。&lt;h4&gt;主要发现&lt;/h4&gt;我们的框架在平面物体的真实机器人实验中表现优于现有的基线，且在三大应用中表现突出：物体跟踪、目标驱动任务和环境变化检测。&lt;h4&gt;结论&lt;/h4&gt;创新的双重可微过滤与图神经网络结合，能够学习物体与机器人之间的互动，并有效选择信息量最大的行动以进行学习和推理。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了一种有效的框架，能够在实际应用中提升物体属性识别的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interactive exploration of the unknown physical properties of objects such asstiffness, mass, center of mass, friction coefficient, and shape is crucial forautonomous robotic systems operating continuously in unstructured environments.Precise identification of these properties is essential to manipulate objectsin a stable and controlled way, and is also required to anticipate the outcomesof (prehensile or non-prehensile) manipulation actions such as pushing,pulling, lifting, etc. Our study focuses on autonomously inferring the physicalproperties of a diverse set of various homogeneous, heterogeneous, andarticulated objects utilizing a robotic system equipped with vision and tactilesensors. We propose a novel predictive perception framework for identifyingobject properties of the diverse objects by leveraging versatile exploratoryactions: non-prehensile pushing and prehensile pulling. As part of theframework, we propose a novel active shape perception to seamlessly initiateexploration. Our innovative dual differentiable filtering with Graph NeuralNetworks learns the object-robot interaction and performs consistent inferenceof indirectly observable time-invariant object properties. In addition, weformulate a $N$-step information gain approach to actively select the mostinformative actions for efficient learning and inference. Extensive real-robotexperiments with planar objects show that our predictive perception frameworkresults in better performance than the state-of-the-art baseline anddemonstrate our framework in three major applications for i) object tracking,ii) goal-driven task, and iii) change in environment detection.</description>
      <author>example@mail.com (Anirvan Dutta, Etienne Burdet, Mohsen Kaboli)</author>
      <guid isPermaLink="false">2411.09020v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Aligning Visual Contrastive learning models via Preference Optimization</title>
      <link>http://arxiv.org/abs/2411.08923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习模型在捕捉语义相似性方面表现出色，但其性能受训练数据质量和偏见的限制。&lt;h4&gt;目的&lt;/h4&gt;探索将人类反馈的强化学习和直接偏好优化应用于对比学习，提出一种新方法以优化模型表现。&lt;h4&gt;方法&lt;/h4&gt;引入偏好优化（PO）方法，系统性地将模型行为与期望偏好对齐，以增强模型在特定任务上的性能。&lt;h4&gt;主要发现&lt;/h4&gt;使用PO训练的模型在处理对比学习任务时表现优于标准方法，并能有效应对对抗性挑战。&lt;h4&gt;结论&lt;/h4&gt;PO方法适用于需要公平性、鲁棒性和特定偏好对齐的任务，能够减轻性别偏见并增强模型的性别理解能力。&lt;h4&gt;总结&lt;/h4&gt;实验表明，PO方法在视觉-语言任务中表现出色，特别是在应对排版攻击和性别概念解耦方面，展现了方法的多样性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning models have demonstrated impressive abilities to capturesemantic similarities by aligning representations in the embedding space.However, their performance can be limited by the quality of the training dataand its inherent biases. While Reinforcement Learning from Human Feedback(RLHF) and Direct Preference Optimization (DPO) have been applied to generativemodels to align them with human preferences, their use in contrastive learninghas yet to be explored. This paper introduces a novel method for trainingcontrastive learning models using Preference Optimization (PO) to break downcomplex concepts. Our method systematically aligns model behavior with desiredpreferences, enhancing performance on the targeted task. In particular, wefocus on enhancing model robustness against typographic attacks, commonly seenin contrastive models like CLIP. We further apply our method to disentanglegender understanding and mitigate gender biases, offering a more nuancedcontrol over these sensitive attributes. Our experiments demonstrate thatmodels trained using PO outperform standard contrastive learning techniqueswhile retaining their ability to handle adversarial challenges and maintainaccuracy on other downstream tasks. This makes our method well-suited for tasksrequiring fairness, robustness, and alignment with specific preferences. Weevaluate our method on several vision-language tasks, tackling challenges suchas typographic attacks. Additionally, we explore the model's ability todisentangle gender concepts and mitigate gender bias, showcasing theversatility of our approach.</description>
      <author>example@mail.com (Amirabbas Afzali, Borna Khodabandeh, Ali Rasekh, Mahyar JafariNodeh, Sepehr kazemi, Simon Gottschalk)</author>
      <guid isPermaLink="false">2411.08923v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Integrative Wrapping System for a Dual-Arm Humanoid Robot</title>
      <link>http://arxiv.org/abs/2411.08389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted Humanoids2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;纸张和布料的灵活物体操控是机器人操控中的一个主要研究挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种可以实现灵活材料连续、多步骤操作的类人机器人系统。&lt;h4&gt;方法&lt;/h4&gt;根据所处理物体的特性，整理和编码必要信息；概括硬件配置、操控方法和识别系统以支持类人包装操作；采用接纳控制来处理纸张张力，并使用点云进行状态评估。&lt;h4&gt;主要发现&lt;/h4&gt;提出的系统能够有效地处理不同形状的物体包装，并展示出其通用性和有效性。&lt;h4&gt;结论&lt;/h4&gt;该研究为类人机器人在包装复杂物体方面的应用提供了新的视角和方法。&lt;h4&gt;总结&lt;/h4&gt;本研究为灵活材料的操控提供了一种新的系统框架，展示了在多步骤操作中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Flexible object manipulation of paper and cloth is a major research challengein robot manipulation. Although there have been efforts to develop hardwarethat enables specific actions and to realize a single action of paper foldingusing sim-to-real and learning, there have been few proposals for humanoidrobots and systems that enable continuous, multi-step actions of flexiblematerials. Wrapping an object with paper and tape is more complex and diversethan traditional manipulation research due to the increased number of objectsthat need to be handled, as well as the three-dimensionality of the operation.In this research, necessary information is organized and coded based on thecharacteristics of each object handled in wrapping. We also generalize thehardware configuration, manipulation method, and recognition system that enablehumanoid wrapping operations. The system will include manipulation withadmittance control focusing on paper tension and state evaluation using pointclouds to handle three-dimensional flexible objects. Finally, wrapping objectswith different shapes is experimented with to show the generality andeffectiveness of the proposed system.</description>
      <author>example@mail.com (Yukina Iwata, Shun Hasegawa, Kento Kawaharazuka, Kei Okada, Masayuki Inaba)</author>
      <guid isPermaLink="false">2411.08389v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>DEEGITS: Deep Learning based Framework for Measuring Heterogenous Traffic State in Challenging Traffic Scenarios</title>
      <link>http://arxiv.org/abs/2411.08335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted for presentation at the 103 rd Annual Meeting of
  Transportation Research Board and publication in Transportation Research
  Record: Journal of Transportation Research Board&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究提出了DEEGITS（基于深度学习的异构交通状态测量）框架，旨在利用先进的卷积神经网络（CNN）技术来准确快速地检测车辆和行人，并在复杂场景中（如拥堵、遮挡）测量交通状态。&lt;h4&gt;目的&lt;/h4&gt;通过数据融合增强训练数据集，实现车辆和行人的同时检测。&lt;h4&gt;方法&lt;/h4&gt;进行图像预处理和增强，以提高数据集的质量和数量；对YOLOv8预训练模型应用迁移学习，优化模型识别多种车辆的能力；使用GridSearch算法获得最佳超参数，SGD优化器在这些设置下优于其他优化器。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验和评估，检测框架的准确性显著，模型在验证集上的mAP@0.5为0.794，测试集为0.786，超越了类似数据集的先前基准。&lt;h4&gt;结论&lt;/h4&gt;本研究结合DeepSORT多目标跟踪算法，以跟踪检测到的车辆和行人，并在混合交通条件下测量异构交通状态。在两个不同交通组成和拥堵水平的地点测试，结果表明误差在统计上不显著，异构交通流和速度测量的相关性分别为0.99到0.88和0.91到0.97。&lt;h4&gt;总结&lt;/h4&gt;DEEGITS框架通过数据融合、迁移学习和先进的检测算法，在复杂交通场景中具备了高效的车辆与行人检测及交通状态测量能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents DEEGITS (Deep Learning Based Heterogeneous Traffic StateMeasurement), a comprehensive framework that leverages state-of-the-artconvolutional neural network (CNN) techniques to accurately and rapidly detectvehicles and pedestrians, as well as to measure traffic states in challengingscenarios (i.e., congestion, occlusion). In this study, we enhance the trainingdataset through data fusion, enabling simultaneous detection of vehicles andpedestrians. Image preprocessing and augmentation are subsequently performed toimprove the quality and quantity of the dataset. Transfer learning is appliedon the YOLOv8 pretrained model to increase the model's capability to identify adiverse array of vehicles. Optimal hyperparameters are obtained using the GridSearch algorithm, with the Stochastic Gradient Descent (SGD) optimizeroutperforming other optimizers under these settings. Extensive experimentationand evaluation demonstrate substantial accuracy within the detection framework,with the model achieving 0.794 mAP@0.5 on the validation set and 0.786 mAP@0.5on the test set, surpassing previous benchmarks on similar datasets. TheDeepSORT multi-object tracking algorithm is incorporated to track detectedvehicles and pedestrians in this study. Finally, the framework is tested tomeasure heterogeneous traffic states in mixed traffic conditions. Two locationswith differing traffic compositions and congestion levels are selected: onemotorized-dominant location with moderate density and onenon-motorized-dominant location with higher density. Errors are statisticallyinsignificant for both cases, showing correlations from 0.99 to 0.88 and 0.91to 0.97 for heterogeneous traffic flow and speed measurements, respectively.</description>
      <author>example@mail.com (Muttahirul Islam, Nazmul Haque, Md. Hadiuzzaman)</author>
      <guid isPermaLink="false">2411.08335v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>HMIL: Hierarchical Multi-Instance Learning for Fine-Grained Whole Slide Image Classification</title>
      <link>http://arxiv.org/abs/2411.07660v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;细粒度分类全切片图像（WSIs）在精准肿瘤学中至关重要，有助于精确癌症诊断和个性化治疗策略。&lt;h4&gt;目的&lt;/h4&gt;解决在相同类别中区分细微形态变化的挑战，提高WSIs的分类精度。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的分层多实例学习（HMIL）框架，通过实例和包级别的标签层次关系对齐，增强学习过程的结构性和信息量。&lt;h4&gt;主要发现&lt;/h4&gt;HMIL框架在细粒度分类中表现出色，结合了类注意机制、监督对比学习和动态加权模块，提升了模型的区分能力。&lt;h4&gt;结论&lt;/h4&gt;在大规模宫颈癌细胞学数据集及两个公共组织学数据集上，HMIL框架展现了最先进的分类性能。&lt;h4&gt;总结&lt;/h4&gt;HMIL框架通过引入层次标签关系和先进的学习机制，为细粒度分类提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-grained classification of whole slide images (WSIs) is essential inprecision oncology, enabling precise cancer diagnosis and personalizedtreatment strategies. The core of this task involves distinguishing subtlemorphological variations within the same broad category of gigapixel-resolutionimages, which presents a significant challenge. While the multi-instancelearning (MIL) paradigm alleviates the computational burden of WSIs, existingMIL methods often overlook hierarchical label correlations, treatingfine-grained classification as a flat multi-class classification task. Toovercome these limitations, we introduce a novel hierarchical multi-instancelearning (HMIL) framework. By facilitating on the hierarchical alignment ofinherent relationships between different hierarchy of labels at instance andbag level, our approach provides a more structured and informative learningprocess. Specifically, HMIL incorporates a class-wise attention mechanism thataligns hierarchical information at both the instance and bag levels.Furthermore, we introduce supervised contrastive learning to enhance thediscriminative capability for fine-grained classification and acurriculum-based dynamic weighting module to adaptively balance thehierarchical feature during training. Extensive experiments on our large-scalecytology cervical cancer (CCC) dataset and two public histology datasets, BRACSand PANDA, demonstrate the state-of-the-art class-wise and overall performanceof our HMIL framework. Our source code is available athttps://github.com/ChengJin-git/HMIL.</description>
      <author>example@mail.com (Cheng Jin, Luyang Luo, Huangjing Lin, Jun Hou, Hao Chen)</author>
      <guid isPermaLink="false">2411.07660v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Guided Noise Reduction for Automatic Modulation Classification</title>
      <link>http://arxiv.org/abs/2411.08376v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动调制分类（AMC）成为第六代（6G）通信中认知无线电网络的关键技术。&lt;h4&gt;目的&lt;/h4&gt;研究在动态和变化的信噪比（SNR）条件下的AMC技术。&lt;h4&gt;方法&lt;/h4&gt;提出基于深度学习的噪声减少网络，以减少无线信道和接收设备引入的噪声；并提出转移学习指导的学习框架（TNR-AMC），利用稀缺的标注调制信号，提高低SNR调制信号的分类准确性。&lt;h4&gt;主要发现&lt;/h4&gt;噪声减少网络在低SNR场景中提高了超过20%的准确性，TNR-AMC框架能够改善不稳定SNR下的分类准确性。&lt;h4&gt;结论&lt;/h4&gt;通过新提出的技术，AMC在6G及未来的快速变化物理信道中具有更好的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;研究表明，针对低SNR和动态信号条件的AMC技术能够显著提高分类性能，推动6G通信的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic modulation classification (AMC) has emerged as a key technique incognitive radio networks in sixth-generation (6G) communications. AMC enableseffective data transmission without requiring prior knowledge of modulationschemes. However, the low classification accuracy under the condition of lowsignal-to-noise ratio (SNR) limits the implementation of AMC techniques underthe rapidly changing physical channels in 6G and beyond. This paperinvestigates the AMC technique for the signals with dynamic and varying SNRs,and a deep learning based noise reduction network is proposed to reduce thenoise introduced by the wireless channel and the receiving equipment. Inparticular, a transfer learning guided learning framework (TNR-AMC) is proposedto utilize the scarce annotated modulation signals and improve theclassification accuracy for low SNR modulation signals. The numerical resultsshow that the proposed noise reduction network achieves an accuracy improvementof over 20\% in low SNR scenarios, and the TNR-AMC framework can improve theclassification accuracy under unstable SNRs.</description>
      <author>example@mail.com (Zelin Ji, Shuo Wang, Kuojun Yang, Qinchuan Zhang, Peng Ye)</author>
      <guid isPermaLink="false">2411.08376v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Learning Disentangled Representations for Perceptual Point Cloud Quality Assessment via Mutual Information Minimization</title>
      <link>http://arxiv.org/abs/2411.07936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无参考点云质量评估（NR-PCQA）旨在客观评估点云的人类感知质量，而不依赖于完美质量的参考点云。随着虚拟现实（VR）和增强现实（AR）等沉浸式媒体应用的快速发展，这一评估变得越来越重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，解决当前NR-PCQA模型在内容与失真表示学习上的不足。&lt;h4&gt;方法&lt;/h4&gt;提出DisPA，一个新的解耦表示学习框架。该框架训练一个双分支解耦网络，最小化点云内容与失真表示之间的互信息（MI）。&lt;h4&gt;主要发现&lt;/h4&gt;DisPA在多个PCQA数据集上超越了现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;通过不同的编码策略和互信息估计，DisPA能够实现明确的表示解耦，并且在性能上具有显著优势。&lt;h4&gt;总结&lt;/h4&gt;DisPA框架有效解决了NR-PCQA中的内容与失真表示学习问题，推动了点云质量评估的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; No-Reference Point Cloud Quality Assessment (NR-PCQA) aims to objectivelyassess the human perceptual quality of point clouds without relying onpristine-quality point clouds for reference. It is becoming increasinglysignificant with the rapid advancement of immersive media applications such asvirtual reality (VR) and augmented reality (AR). However, current NR-PCQAmodels attempt to indiscriminately learn point cloud content and distortionrepresentations within a single network, overlooking their distinctcontributions to quality information. To address this issue, we propose DisPA,a novel disentangled representation learning framework for NR-PCQA. Theframework trains a dual-branch disentanglement network to minimize mutualinformation (MI) between representations of point cloud content and distortion.Specifically, to fully disentangle representations, the two branches adoptdifferent philosophies: the content-aware encoder is pretrained by a maskedauto-encoding strategy, which can allow the encoder to capture semanticinformation from rendered images of distorted point clouds; thedistortion-aware encoder takes a mini-patch map as input, which forces theencoder to focus on low-level distortion patterns. Furthermore, we utilize anMI estimator to estimate the tight upper bound of the actual MI and furtherminimize it to achieve explicit representation disentanglement. Extensiveexperimental results demonstrate that DisPA outperforms state-of-the-artmethods on multiple PCQA datasets.</description>
      <author>example@mail.com (Ziyu Shan, Yujie Zhang, Yipeng Liu, Yiling Xu)</author>
      <guid isPermaLink="false">2411.07936v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>SimpleBEV: Improved LiDAR-Camera Fusion Architecture for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2411.05292v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;越来越多的研究将LiDAR和相机信息融合，以提高自动驾驶系统的3D物体检测性能。&lt;h4&gt;目的&lt;/h4&gt;提出一个名为SimpleBEV的LiDAR-相机融合框架，以实现准确的3D物体检测。&lt;h4&gt;方法&lt;/h4&gt;采用基于鸟瞰视图(BEV)的融合框架，改进相机和LiDAR编码器，使用级联网络进行相机深度估计，并用LiDAR点的深度信息进行校正。同时，引入辅助分支，仅使用相机-BEV特征进行3D物体检测训练，并通过融合多尺度稀疏卷积特征改进LiDAR特征提取器。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提方法在nuScenes数据集上取得了77.6%的NDS准确率，展现了在3D物体检测中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;SimpleBEV框架有效提升了3D物体检测的准确性，证明了LiDAR与相机特征融合的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的SimpleBEV方法在3D物体检测中具有显著的性能提升，展示了融合传感器信息的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; More and more research works fuse the LiDAR and camera information to improvethe 3D object detection of the autonomous driving system. Recently, a simpleyet effective fusion framework has achieved an excellent detection performance,fusing the LiDAR and camera features in a unified bird's-eye-view (BEV) space.In this paper, we propose a LiDAR-camera fusion framework, named SimpleBEV, foraccurate 3D object detection, which follows the BEV-based fusion framework andimproves the camera and LiDAR encoders, respectively. Specifically, we performthe camera-based depth estimation using a cascade network and rectify the depthresults with the depth information derived from the LiDAR points. Meanwhile, anauxiliary branch that implements the 3D object detection using only thecamera-BEV features is introduced to exploit the camera information during thetraining phase. Besides, we improve the LiDAR feature extractor by fusing themulti-scaled sparse convolutional features. Experimental results demonstratethe effectiveness of our proposed method. Our method achieves 77.6\% NDSaccuracy on the nuScenes dataset, showcasing superior performance in the 3Dobject detection track.</description>
      <author>example@mail.com (Yun Zhao, Zhan Gong, Peiru Zheng, Hong Zhu, Shaohua Wu)</author>
      <guid isPermaLink="false">2411.05292v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>CLaSP: Learning Concepts for Time-Series Signals from Natural Language Supervision</title>
      <link>http://arxiv.org/abs/2411.08397v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的时间序列信号数据用自然语言表示存在诸多挑战，包括特征设计、量化及同义词字典的创建。&lt;h4&gt;目的&lt;/h4&gt;提出一个名为'CLaSP'的基础模型，使得可以通过描述信号特征的自然语言查询搜索时间序列信号。&lt;h4&gt;方法&lt;/h4&gt;引入基于对比学习的神经网络，使用TRUCE和SUSHI数据集进行训练，这些数据集包含时间序列信号及其对应的自然语言描述。&lt;h4&gt;主要发现&lt;/h4&gt;CLaSP能够实现时间序列信号数据的自然语言搜索，并准确识别信号数据变化的关键点。&lt;h4&gt;结论&lt;/h4&gt;该方法不需要预定义同义词字典，且利用了大规模语言模型中的常识知识。&lt;h4&gt;总结&lt;/h4&gt;CLaSP模型有效解决了自然语言搜索时间序列信号数据的难题，展示了较好的实验结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a foundation model called "CLaSP" that can search timeseries signals using natural language that describes the characteristics of thesignals as queries. Previous efforts to represent time series signal data innatural language have had challenges in designing a conventional class of timeseries signal characteristics, formulating their quantification, and creating adictionary of synonyms. To overcome these limitations, the proposed methodintroduces a neural network based on contrastive learning. This network isfirst trained using the datasets TRUCE and SUSHI, which consist of time seriessignals and their corresponding natural language descriptions. Previous studieshave proposed vocabularies that data analysts use to describe signalcharacteristics, and SUSHI was designed to cover these terms. We believe that aneural network trained on these datasets will enable data analysts to searchusing natural language vocabulary. Furthermore, our method does not require adictionary of predefined synonyms, and it leverages common sense knowledgeembedded in a large-scale language model (LLM). Experimental resultsdemonstrate that CLaSP enables natural language search of time series signaldata and can accurately learn the points at which signal data changes.</description>
      <author>example@mail.com (Aoi Ito, Kota Dohi, Yohei Kawaguchi)</author>
      <guid isPermaLink="false">2411.08397v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Vision Foundation Models for High-Performance, Training-Free Open Vocabulary Segmentation</title>
      <link>http://arxiv.org/abs/2411.09219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比语言-图像预训练（CLIP）在开放词汇预测方面取得了进展，但其在语义分割上的表现仍不理想，主要由于空间不变的语义特征和分辨率受限。&lt;h4&gt;目的&lt;/h4&gt;解决CLIP在语义分割中的分辨率问题，并提升其分割性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种拼接-再分割的范式，结合了Segment-Anything Model（SAM），通过提取高分辨率图像的细粒度语义关联，增强了全局聚合能力。&lt;h4&gt;主要发现&lt;/h4&gt;Trident框架在八个基准测试中，相较于当前的最优方法，mIoU显著提高，从44.4提升至48.6。&lt;h4&gt;结论&lt;/h4&gt;通过将CLIP的粗分割输出转化为SAM的提示，进一步增强了分割性能。&lt;h4&gt;总结&lt;/h4&gt;Trident框架有效解决了CLIP在语义分割中的局限，提供了更好的分割结果，相关代码已公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/YuHengsss/Trident&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While Contrastive Language-Image Pre-training (CLIP) has advancedopen-vocabulary predictions, its performance on semantic segmentation remainssuboptimal. This shortfall primarily stems from its spatial-invariant semanticfeatures and constrained resolution. While previous adaptations addressedspatial invariance semantic by modifying the self-attention in CLIP's imageencoder, the issue of limited resolution remains unexplored. Different fromprevious segment-then-splice methods that segment sub-images via a slidingwindow and splice the results, we introduce a splice-then-segment paradigm thatincorporates Segment-Anything Model (SAM) to tackle the resolution issue sinceSAM excels at extracting fine-grained semantic correlations fromhigh-resolution images. Specifically, we introduce Trident, a training-freeframework that first splices features extracted by CLIP and DINO fromsub-images, then leverages SAM's encoder to create a correlation matrix forglobal aggregation, enabling a broadened receptive field for effectivesegmentation. Besides, we propose a refinement strategy for CLIP's coarsesegmentation outputs by transforming them into prompts for SAM, furtherenhancing the segmentation performance. Trident achieves a significantimprovement in the mIoU across eight benchmarks compared with the current SOTA,increasing from 44.4 to 48.6.Code is available athttps://github.com/YuHengsss/Trident.</description>
      <author>example@mail.com (Yuheng Shi, Minjing Dong, Chang Xu)</author>
      <guid isPermaLink="false">2411.09219v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification</title>
      <link>http://arxiv.org/abs/2411.08703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多组学数据具有独特特征，包括生物层之间的复杂相互作用和疾病的异质性，这促使我们开发新的设计以应对多组学预测中的独特挑战。&lt;h4&gt;目的&lt;/h4&gt;提出多视角知识转移学习框架（MVKTrans），以自适应方式转移组学知识，增强分类性能。&lt;h4&gt;方法&lt;/h4&gt;设计图对比模块，通过无标签数据训练，有效学习和转移组学内部模式。引入自适应双向跨组学蒸馏模块，自动识别更丰富的组学，促进动态知识转移。&lt;h4&gt;主要发现&lt;/h4&gt;MVKTrans在四个真实生物医学数据集上的实验表明，其性能和鲁棒性优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;MVKTrans框架有效解决了多组学数据的异质性问题，并提升了分类的准确性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了MVKTrans在多组学预测中的应用潜力，提供了开源代码和数据以供进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The distinct characteristics of multiomics data, including complexinteractions within and across biological layers and disease heterogeneity(e.g., heterogeneity in etiology and clinical symptoms), drive us to developnovel designs to address unique challenges in multiomics prediction. In thispaper, we propose the multi-view knowledge transfer learning (MVKTrans)framework, which transfers intra- and inter-omics knowledge in an adaptivemanner by reviewing data heterogeneity and suppressing bias transfer, therebyenhancing classification performance. Specifically, we design a graphcontrastive module that is trained on unlabeled data to effectively learn andtransfer the underlying intra-omics patterns to the supervised task. Thisunsupervised pretraining promotes learning general and unbiased representationsfor each modality, regardless of the downstream tasks. In light of the varyingdiscriminative capacities of modalities across different diseases and/orsamples, we introduce an adaptive and bi-directional cross-omics distillationmodule. This module automatically identifies richer modalities and facilitatesdynamic knowledge transfer from more informative to less informative omics,thereby enabling a more robust and generalized integration. Extensiveexperiments on four real biomedical datasets demonstrate the superiorperformance and robustness of MVKTrans compared to the state-of-the-art. Codeand data are available at https://github.com/Yaolab-fantastic/MVKTrans.</description>
      <author>example@mail.com (Shan Cong, Zhiling Sang, Hongwei Liu, Haoran Luo, Xin Wang, Hong Liang, Jie Hao, Xiaohui Yao)</author>
      <guid isPermaLink="false">2411.08703v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Continuous GNN-based Anomaly Detection on Edge using Efficient Adaptive Knowledge Graph Learning</title>
      <link>http://arxiv.org/abs/2411.09072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to DATE 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视频异常检测（VAD）的需求在智能监控、证据调查和暴力检测等应用中日益增长，成为各行业关键任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的方法，以解决传统VAD方法在实时或资源受限环境中的计算成本和实用性问题。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络（GNN）训练固定知识图（KG），该KG源自大型语言模型（LLMs），如GPT-4。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在计算能力和内存使用上表现出显著的效率，但在动态环境中面临KG频繁更新的限制。&lt;h4&gt;结论&lt;/h4&gt;提出一个新框架，支持在边缘设备上直接进行KG的连续适应，克服了对云计算的依赖。&lt;h4&gt;总结&lt;/h4&gt;通过修剪、交替和创建节点的三阶段过程，动态修改KG，从而实时适应不断变化的数据趋势，提高异常检测模型的鲁棒性，使其更适合在动态和资源受限的环境中部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing demand for robust security solutions across various industrieshas made Video Anomaly Detection (VAD) a critical task in applications such asintelligent surveillance, evidence investigation, and violence detection.Traditional approaches to VAD often rely on finetuning large pre-trainedmodels, which can be computationally expensive and impractical for real-time orresource-constrained environments. To address this, MissionGNN introduced amore efficient method by training a graph neural network (GNN) using a fixedknowledge graph (KG) derived from large language models (LLMs) like GPT-4.While this approach demonstrated significant efficiency in computational powerand memory, it faces limitations in dynamic environments where frequent updatesto the KG are necessary due to evolving behavior trends and shifting datapatterns. These updates typically require cloud-based computation, posingchallenges for edge computing applications. In this paper, we propose a novelframework that facilitates continuous KG adaptation directly on edge devices,overcoming the limitations of cloud dependency. Our method dynamically modifiesthe KG through a three-phase process: pruning, alternating, and creating nodes,enabling real-time adaptation to changing data trends. This continuous learningapproach enhances the robustness of anomaly detection models, making them moresuitable for deployment in dynamic and resource-constrained environments.</description>
      <author>example@mail.com (Sanggeon Yun, Ryozo Masukawa, William Youngwoo Chung, Minhyoung Na, Nathaniel Bastian, Mohsen Imani)</author>
      <guid isPermaLink="false">2411.09072v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>ZOPP: A Framework of Zero-shot Offboard Panoptic Perception for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2411.05311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;离线感知旨在为自动驾驶场景自动生成高质量的3D标签，现有方法主要集中于封闭集合的3D物体检测，未能达到人类级别的识别能力。&lt;h4&gt;目的&lt;/h4&gt;探索一种统一框架来实现自动驾驶场景中不同元素的自动标注，以满足快速发展的感知任务的需求。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的多模态零样本离线全景感知（ZOPP）框架，结合了视觉基础模型的零样本识别能力和从点云中提取的3D表示。&lt;h4&gt;主要发现&lt;/h4&gt;ZOPP在多模态全景感知和自动标注领域具有开创性，经过在Waymo开放数据集上的全面实证研究和评估，验证了其在各类感知任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;ZOPP展示了在真实场景中的巨大潜力，并在下游应用中进行了可用性和扩展性的实验。&lt;h4&gt;总结&lt;/h4&gt;本研究为自动驾驶场景的自动标注提供了一种新的方法，具有重要的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Offboard perception aims to automatically generate high-quality 3D labels forautonomous driving (AD) scenes. Existing offboard methods focus on 3D objectdetection with closed-set taxonomy and fail to match human-level recognitioncapability on the rapidly evolving perception tasks. Due to heavy reliance onhuman labels and the prevalence of data imbalance and sparsity, a unifiedframework for offboard auto-labeling various elements in AD scenes that meetsthe distinct needs of perception tasks is not being fully explored. In thispaper, we propose a novel multi-modal Zero-shot Offboard Panoptic Perception(ZOPP) framework for autonomous driving scenes. ZOPP integrates the powerfulzero-shot recognition capabilities of vision foundation models and 3Drepresentations derived from point clouds. To the best of our knowledge, ZOPPrepresents a pioneering effort in the domain of multi-modal panoptic perceptionand auto labeling for autonomous driving scenes. We conduct comprehensiveempirical studies and evaluations on Waymo open dataset to validate theproposed ZOPP on various perception tasks. To further explore the usability andextensibility of our proposed ZOPP, we also conduct experiments in downstreamapplications. The results further demonstrate the great potential of our ZOPPfor real-world scenarios.</description>
      <author>example@mail.com (Tao Ma, Hongbin Zhou, Qiusheng Huang, Xuemeng Yang, Jianfei Guo, Bo Zhang, Min Dou, Yu Qiao, Botian Shi, Hongsheng Li)</author>
      <guid isPermaLink="false">2411.05311v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>LLM2CLIP: Powerful Language Model Unlocks Richer Visual Representation</title>
      <link>http://arxiv.org/abs/2411.04997v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;CLIP是当今最重要的多模态基础模型之一，其能力受到自然语言提供的丰富监督信号的影响。&lt;h4&gt;目的&lt;/h4&gt;探讨是否可以利用大型语言模型（LLMs）进一步提升多模态表征学习的能力。&lt;h4&gt;方法&lt;/h4&gt;提出LLM2CLIP，利用LLMs的力量通过对比学习在标题空间进行微调，以提取其文本能力并改善输出层的文本可辨性。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入LLMs，CLIP能够处理更长更复杂的标题，克服了原版CLIP在文本编码器上的限制。&lt;h4&gt;结论&lt;/h4&gt;实验表明，该方法在跨模态任务中显著改善了性能。&lt;h4&gt;总结&lt;/h4&gt;LLM2CLIP结合了LLMs的强大文本理解能力，提升了CLIP在多模态表征学习中的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/microsoft/LLM2CLIP&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLIP is one of the most important multimodal foundational models today. Whatpowers CLIP's capabilities? The rich supervision signals provided by naturallanguage, the carrier of human knowledge, shape a powerful cross-modalrepresentation space. However, with the rapid advancements in large languagemodels LLMs like GPT-4 and LLaMA, the boundaries of language comprehension andgeneration are continually being pushed. This raises an intriguing question:can the capabilities of LLMs be harnessed to further improve multimodalrepresentation learning? The potential benefits of incorporating LLMs into CLIPare clear. LLMs' strong textual understanding can fundamentally improve CLIP'sability to handle image captions, drastically enhancing its ability to processlong and complex texts, a well-known limitation of vanilla CLIP. Moreover, LLMsare trained on a vast corpus of text, possessing open-world knowledge. Thisallows them to expand on caption information during training, increasing theefficiency of the learning process. In this paper, we propose LLM2CLIP, a novelapproach that embraces the power of LLMs to unlock CLIP's potential. Byfine-tuning the LLM in the caption space with contrastive learning, we extractits textual capabilities into the output embeddings, significantly improvingthe output layer's textual discriminability. We then design an efficienttraining process where the fine-tuned LLM acts as a powerful teacher for CLIP'svisual encoder. Thanks to the LLM's presence, we can now incorporate longer andmore complex captions without being restricted by vanilla CLIP's text encoder'scontext window and ability limitations. Our experiments demonstrate that thisapproach brings substantial improvements in cross-modal tasks.</description>
      <author>example@mail.com (Weiquan Huang, Aoqi Wu, Yifan Yang, Xufang Luo, Yuqing Yang, Liang Hu, Qi Dai, Xiyang Dai, Dongdong Chen, Chong Luo, Lili Qiu)</author>
      <guid isPermaLink="false">2411.04997v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Jailbreak Attacks and Defenses against Multimodal Generative Models: A Survey</title>
      <link>http://arxiv.org/abs/2411.09259v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ongoing work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型的快速发展促进了跨模态理解和生成的显著进步，涵盖文本、图像、音频和视频等多种模态。&lt;h4&gt;目的&lt;/h4&gt;理解监狱攻击及现有防御机制，以确保多模态生成模型在安全敏感应用中的安全部署。&lt;h4&gt;方法&lt;/h4&gt;系统探讨了多模态监狱攻击的生命周期，分析了输入、编码器、生成器和输出四个层面的攻击和防御策略，并提出详细的攻击方法和防御机制分类法。&lt;h4&gt;主要发现&lt;/h4&gt;覆盖了多种输入输出配置，包括Any-to-Text、Any-to-Vision和Any-to-Any的生成系统。&lt;h4&gt;结论&lt;/h4&gt;指出当前研究中的挑战，并提出未来研究的潜在方向。&lt;h4&gt;总结&lt;/h4&gt;为多模态生成模型的监狱攻击和防御提供了全面的见解，强调了确保安全部署的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid evolution of multimodal foundation models has led to significantadvancements in cross-modal understanding and generation across diversemodalities, including text, images, audio, and video. However, these modelsremain susceptible to jailbreak attacks, which can bypass built-in safetymechanisms and induce the production of potentially harmful content.Consequently, understanding the methods of jailbreak attacks and existingdefense mechanisms is essential to ensure the safe deployment of multimodalgenerative models in real-world scenarios, particularly in security-sensitiveapplications. To provide comprehensive insight into this topic, this surveyreviews jailbreak and defense in multimodal generative models. First, given thegeneralized lifecycle of multimodal jailbreak, we systematically exploreattacks and corresponding defense strategies across four levels: input,encoder, generator, and output. Based on this analysis, we present a detailedtaxonomy of attack methods, defense mechanisms, and evaluation frameworksspecific to multimodal generative models. Additionally, we cover a wide rangeof input-output configurations, including modalities such as Any-to-Text,Any-to-Vision, and Any-to-Any within generative systems. Finally, we highlightcurrent research challenges and propose potential directions for futureresearch.The open-source repository corresponding to this work can be found athttps://github.com/liuxuannan/Awesome-Multimodal-Jailbreak.</description>
      <author>example@mail.com (Xuannan Liu, Xing Cui, Peipei Li, Zekun Li, Huaibo Huang, Shuhan Xia, Miaoxuan Zhang, Yueying Zou, Ran He)</author>
      <guid isPermaLink="false">2411.09259v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training</title>
      <link>http://arxiv.org/abs/2411.08785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大多数关于多语言信息提取的研究局限于零-shot跨语言单一传递（one-to-one）设置，主要使用高资源语言作为源训练数据。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在填补这一空白，通过详细分析跨语言多传递性（many-to-many transfer learning），为涵盖多种语言的最新信息提取语料库提供支持。&lt;h4&gt;方法&lt;/h4&gt;首先确定单一传递表现与多种语言学距离之间的相关性，进而开发出一个结合语言距离的度量，该度量在不同任务和模型规模中都表现出较强的相关性和稳健性。&lt;h4&gt;主要发现&lt;/h4&gt;在更一般的零-shot多语言传递设置中，涉及多个语言的训练和评估过程，基于新定义的距离进行语言聚类能为数据选择问题提供最佳成本-性能权衡的方向。&lt;h4&gt;结论&lt;/h4&gt;提出了一种关系传递设置，通过对抗训练进一步结合多语言未标注数据，利用上述语言距离引导的关系。&lt;h4&gt;总结&lt;/h4&gt;本研究为多语言信息提取系统的发展提供了新的视角和方法，能够更好地适应多种语言的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The majority of previous researches addressing multi-lingual IE are limitedto zero-shot cross-lingual single-transfer (one-to-one) setting, withhigh-resource languages predominantly as source training data. As a result,these works provide little understanding and benefit for the realistic goal ofdeveloping a multi-lingual IE system that can generalize to as many languagesas possible. Our study aims to fill this gap by providing a detailed analysison Cross-Lingual Multi-Transferability (many-to-many transfer learning), forthe recent IE corpora that cover a diverse set of languages. Specifically, wefirst determine the correlation between single-transfer performance and a widerange of linguistic-based distances. From the obtained insights, a combinedlanguage distance metric can be developed that is not only highly correlatedbut also robust across different tasks and model scales. Next, we investigatethe more general zero-shot multi-lingual transfer settings where multiplelanguages are involved in the training and evaluation processes. Languageclustering based on the newly defined distance can provide directions forachieving the optimal cost-performance trade-off in data (languages) selectionproblem. Finally, a relational-transfer setting is proposed to furtherincorporate multi-lingual unlabeled data based on adversarial training usingthe relation induced from the above linguistic distance.</description>
      <author>example@mail.com (Nghia Trung Ngo, Thien Huu Nguyen)</author>
      <guid isPermaLink="false">2411.08785v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>KMM: Key Frame Mask Mamba for Extended Motion Generation</title>
      <link>http://arxiv.org/abs/2411.06481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类运动生成是生成计算机视觉领域的前沿研究，应用于视频创作、游戏开发和机器人操作等领域。&lt;h4&gt;目的&lt;/h4&gt;解决Mamba架构在长序列建模中的效率问题，同时应对记忆衰减和多模态融合的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出KMM新架构，采用关键帧掩模建模技术，增强对运动段关键动作的关注，同时设计对比学习范式以改善多模态融合和运动文本对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在BABEL数据集上进行的广泛实验显示，KMM实现了最先进的性能，FID减少超过57%，参数减少70%。&lt;h4&gt;结论&lt;/h4&gt;KMM为解决Mamba架构的记忆衰减和多模态融合问题提供了有效方案，推动了运动生成领域的发展。&lt;h4&gt;总结&lt;/h4&gt;该研究通过创新的方法改善了运动生成的效果和效率，为未来的应用提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human motion generation is a cut-edge area of research in generative computervision, with promising applications in video creation, game development, androbotic manipulation. The recent Mamba architecture shows promising results inefficiently modeling long and complex sequences, yet two significant challengesremain: Firstly, directly applying Mamba to extended motion generation isineffective, as the limited capacity of the implicit memory leads to memorydecay. Secondly, Mamba struggles with multimodal fusion compared toTransformers, and lack alignment with textual queries, often confusingdirections (left or right) or omitting parts of longer text queries. To addressthese challenges, our paper presents three key contributions: Firstly, weintroduce KMM, a novel architecture featuring Key frame Masking Modeling,designed to enhance Mamba's focus on key actions in motion segments. Thisapproach addresses the memory decay problem and represents a pioneering methodin customizing strategic frame-level masking in SSMs. Additionally, we designeda contrastive learning paradigm for addressing the multimodal fusion problem inMamba and improving the motion-text alignment. Finally, we conducted extensiveexperiments on the go-to dataset, BABEL, achieving state-of-the-art performancewith a reduction of more than 57% in FID and 70% parameters compared toprevious state-of-the-art methods. See project website:https://steve-zeyu-zhang.github.io/KMM</description>
      <author>example@mail.com (Zeyu Zhang, Hang Gao, Akide Liu, Qi Chen, Feng Chen, Yiran Wang, Danning Li, Hao Tang)</author>
      <guid isPermaLink="false">2411.06481v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>LSSInst: Improving Geometric Modeling in LSS-Based BEV Perception with Instance Representation</title>
      <link>http://arxiv.org/abs/2411.06173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by 3DV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着仅依靠相机进行的3D物体检测在自动驾驶中的关注度上升，基于鸟瞰图（BEV）表示的方法获得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出LSSInst，一个结合BEV和实例表示的两阶段物体检测器，以弥补压缩BEV表示中缺失的几何细节。&lt;h4&gt;方法&lt;/h4&gt;LSSInst利用细粒度像素级特征，灵活整合到现有的基于LSS的BEV网络中，并设计了实例适配器以实现BEV与实例之间的语义一致性。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验表明，所提出的框架在现代LSS基础的BEV感知方法中具有出色的泛化能力和性能，超越了当前LSS基础的最新研究。&lt;h4&gt;结论&lt;/h4&gt;LSSInst提升了基于LSS的物体检测性能，尤其在大规模nuScenes基准测试中表现优异。&lt;h4&gt;总结&lt;/h4&gt;通过引入LSSInst，可以在保证计算效率的同时，补充BEV表示中的几何细节，提高自动驾驶场景的物体检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/weijiemax/lssinst&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the attention gained by camera-only 3D object detection in autonomousdriving, methods based on Bird-Eye-View (BEV) representation especially derivedfrom the forward view transformation paradigm, i.e., lift-splat-shoot (LSS),have recently seen significant progress. The BEV representation formulated bythe frustum based on depth distribution prediction is ideal for learning theroad structure and scene layout from multi-view images. However, to retaincomputational efficiency, the compressed BEV representation such as inresolution and axis is inevitably weak in retaining the individual geometricdetails, undermining the methodological generality and applicability. With thisin mind, to compensate for the missing details and utilize multi-view geometryconstraints, we propose LSSInst, a two-stage object detector incorporating BEVand instance representations in tandem. The proposed detector exploitsfine-grained pixel-level features that can be flexibly integrated into existingLSS-based BEV networks. Having said that, due to the inherent gap between tworepresentation spaces, we design the instance adaptor for the BEV-to-instancesemantic coherence rather than pass the proposal naively. Extensive experimentsdemonstrated that our proposed framework is of excellent generalization abilityand performance, which boosts the performances of modern LSS-based BEVperception methods without bells and whistles and outperforms current LSS-basedstate-of-the-art works on the large-scale nuScenes benchmark.</description>
      <author>example@mail.com (Weijie Ma, Jingwei Jiang, Yang Yang, Zehui Chen, Hao Chen)</author>
      <guid isPermaLink="false">2411.06173v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>A Brief History of Named Entity Recognition</title>
      <link>http://arxiv.org/abs/2411.05057v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Survey done in 2020&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当今世界大量信息存储在知识库中。&lt;h4&gt;目的&lt;/h4&gt;研究命名实体识别（NER）的技术演变及其应用。&lt;h4&gt;方法&lt;/h4&gt;比较从监督学习到无监督学习方法在NER中的应用与效果。&lt;h4&gt;主要发现&lt;/h4&gt;NER技术在过去三十年中经历了显著的发展与变化。&lt;h4&gt;结论&lt;/h4&gt;NER是信息提取、语义标注、问答系统和本体构建等领域的重要过程。&lt;h4&gt;总结&lt;/h4&gt;本调查回顾了NER技术的演变，强调了其在现代信息处理中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A large amount of information in today's world is now stored in knowledgebases. Named Entity Recognition (NER) is a process of extracting,disambiguation, and linking an entity from raw text to insightful andstructured knowledge bases. More concretely, it is identifying and classifyingentities in the text that are crucial for Information Extraction, SemanticAnnotation, Question Answering, Ontology Population, and so on. The process ofNER has evolved in the last three decades since it first appeared in 1996. Inthis survey, we study the evolution of techniques employed for NER and comparethe results, starting from supervised to the developing unsupervised learningmethods.</description>
      <author>example@mail.com (Monica Munnangi)</author>
      <guid isPermaLink="false">2411.05057v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>ParaLBench: A Large-Scale Benchmark for Computational Paralinguistics over Acoustic Foundation Models</title>
      <link>http://arxiv.org/abs/2411.09349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;计算机旁白语言学（ComParal）旨在开发算法和模型，自动检测、分析和解释语音交流中的非语言信息，如情感、健康状态、年龄和性别。&lt;h4&gt;目的&lt;/h4&gt;解决ComParal模型的异质性和多样性问题，以实现更现实的应用。&lt;h4&gt;方法&lt;/h4&gt;进行大规模基准测试（ParaLBench），标准化不同旁白语言任务的评估过程，涵盖情感识别和情感维度预测等关键方面。&lt;h4&gt;主要发现&lt;/h4&gt;该基准测试包含十个数据集和十三个不同的旁白语言任务，使用14种声学基础模型在统一评估框架下进行比较。&lt;h4&gt;结论&lt;/h4&gt;通过ParaLBench获得的见解指出了未来研究的潜在方向，如跨语料库的泛化能力，以推动ComParal研究进展。&lt;h4&gt;总结&lt;/h4&gt;为促进后续研究的透明性和可复制性，相关代码将被发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computational paralinguistics (ComParal) aims to develop algorithms andmodels to automatically detect, analyze, and interpret non-verbal informationfrom speech communication, e. g., emotion, health state, age, and gender.Despite its rapid progress, it heavily depends on sophisticatedly designedmodels given specific paralinguistic tasks. Thus, the heterogeneity anddiversity of ComParal models largely prevent the realistic implementation ofComParal models. Recently, with the advent of acoustic foundation modelsbecause of self-supervised learning, developing more generic models that canefficiently perceive a plethora of paralinguistic information has become anactive topic in speech processing. However, it lacks a unified evaluationframework for a fair and consistent performance comparison. To bridge this gap,we conduct a large-scale benchmark, namely ParaLBench, which concentrates onstandardizing the evaluation process of diverse paralinguistic tasks, includingcritical aspects of affective computing such as emotion recognition and emotiondimensions prediction, over different acoustic foundation models. Thisbenchmark contains ten datasets with thirteen distinct paralinguistic tasks,covering short-, medium- and long-term characteristics. Each task is carriedout on 14 acoustic foundation models under a unified evaluation framework,which allows for an unbiased methodological comparison and offers a groundedreference for the ComParal community. Based on the insights gained fromParaLBench, we also point out potential research directions, i.e., thecross-corpus generalizability, to propel ComParal research in the future. Thecode associated with this study will be available to foster the transparencyand replicability of this work for succeeding researchers.</description>
      <author>example@mail.com (Zixing Zhang, Weixiang Xu, Zhongren Dong, Kanglin Wang, Yimeng Wu, Jing Peng, Runming Wang, Dong-Yan Huang)</author>
      <guid isPermaLink="false">2411.09349v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Heuristical Comparison of Vision Transformers Against Convolutional Neural Networks for Semantic Segmentation on Remote Sensing Imagery</title>
      <link>http://arxiv.org/abs/2411.09101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉变换器（ViT）在计算机视觉领域引发了一波新的研究，特别是在图像分类和分割方面表现出色。&lt;h4&gt;目的&lt;/h4&gt;比较使用ViT与不使用ViT进行遥感航空影像的语义分割的关键因素。&lt;h4&gt;方法&lt;/h4&gt;实验中使用加权融合损失函数来优化mIoU分数和Dice分数，同时评估Meta的MaskFormer与UNet卷积神经网络的迁移学习效果。&lt;h4&gt;主要发现&lt;/h4&gt;使用新型加权损失函数显著提升了CNN模型的性能，相较于ViT的迁移学习效果更佳。&lt;h4&gt;结论&lt;/h4&gt;在当前的先进分割模型中，ViT的性能未必强于传统的CNN模型，且在某些情况下可能存在损失。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了在语义分割任务中，ViT和CNN的不同性能表现，为后续研究提供了重要参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ashimdahal/vit-vs-cnn-image-segmentation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Transformers (ViT) have recently brought a new wave of research in thefield of computer vision. These models have done particularly well in the fieldof image classification and segmentation. Research on semantic and instancesegmentation has emerged to accelerate with the inception of the newarchitecture, with over 80\% of the top 20 benchmarks for the iSAID datasetbeing either based on the ViT architecture or the attention mechanism behindits success. This paper focuses on the heuristic comparison of three keyfactors of using (or not using) ViT for semantic segmentation of remote sensingaerial images on the iSAID. The experimental results observed during the courseof the research were under the scrutinization of the following objectives: 1.Use of weighted fused loss function for the maximum mean Intersection overUnion (mIoU) score, Dice score, and minimization or conservation of entropy orclass representation, 2. Comparison of transfer learning on Meta's MaskFormer,a ViT-based semantic segmentation model, against generic UNet ConvolutionalNeural Networks (CNNs) judged over mIoU, Dice scores, training efficiency, andinference time, and 3. What do we lose for what we gain? i.e., the comparisonof the two models against current state-of-art segmentation models. We show theuse of the novel combined weighted loss function significantly boosts the CNNmodel's performance capacities as compared to transfer learning the ViT. Thecode for this implementation can be found on\url{https://github.com/ashimdahal/ViT-vs-CNN-ImageSegmentation}.</description>
      <author>example@mail.com (Ashim Dahal, Saydul Akbar Murad, Nick Rahimi)</author>
      <guid isPermaLink="false">2411.09101v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>DiVR: incorporating context from diverse VR scenes for human trajectory prediction</title>
      <link>http://arxiv.org/abs/2411.08409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;虚拟环境为收集人类行为的详细数据提供了丰富且受控的设置，但大多数现有方法忽视了这些环境的潜力，主要集中在静态场景上。&lt;h4&gt;目的&lt;/h4&gt;利用CREATTIVE3D数据集建模虚拟现实（VR）场景中记录的轨迹，考虑用户特定因素。&lt;h4&gt;方法&lt;/h4&gt;提出Diverse Context VR Human Motion Prediction (DiVR)模型，基于Perceiver架构的跨模态变换器，结合异构图卷积网络整合静态和动态场景上下文。&lt;h4&gt;主要发现&lt;/h4&gt;DiVR在与现有架构（如MLP、LSTM和带注视及点云上下文的变换器）的比较中，表现出更高的准确性和适应性。&lt;h4&gt;结论&lt;/h4&gt;使用VR数据集进行上下文感知的人类轨迹建模具有显著优势，对增强元宇宙中的用户体验有潜在应用。&lt;h4&gt;总结&lt;/h4&gt;该研究强调了在动态场景中利用VR环境进行人类行为预测的重要性，并提供了可公开访问的源代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Virtual environments provide a rich and controlled setting for collectingdetailed data on human behavior, offering unique opportunities for predictinghuman trajectories in dynamic scenes. However, most existing approaches haveoverlooked the potential of these environments, focusing instead on staticcontexts without considering userspecific factors. Employing the CREATTIVE3Ddataset, our work models trajectories recorded in virtual reality (VR) scenesfor diverse situations including road-crossing tasks with user interactions andsimulated visual impairments. We propose Diverse Context VR Human MotionPrediction (DiVR), a cross-modal transformer based on the Perceiverarchitecture that integrates both static and dynamic scene context using aheterogeneous graph convolution network. We conduct extensive experimentscomparing DiVR against existing architectures including MLP, LSTM, andtransformers with gaze and point cloud context. Additionally, we also stresstest our model's generalizability across different users, tasks, and scenes.Results show that DiVR achieves higher accuracy and adaptability compared toother models and to static graphs. This work highlights the advantages of usingVR datasets for context-aware human trajectory modeling, with potentialapplications in enhancing user experiences in the metaverse. Our source code ispublicly available at https://gitlab.inria.fr/ffrancog/creattive3d-divr-model.</description>
      <author>example@mail.com (Franz Franco Gallo, Hui-Yin Wu, Lucile Sassatelli)</author>
      <guid isPermaLink="false">2411.08409v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning</title>
      <link>http://arxiv.org/abs/2411.06659v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 6 figures, 38th Conference on Neural Information Processing
  Systems, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;增量图学习因其解决图表示学习中的灾难性遗忘问题而备受关注，但传统方法通常依赖大量标签进行节点分类，这在实际应用中不切实际。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的图形增量学习方法，以应对少样本增量学习的需求。&lt;h4&gt;方法&lt;/h4&gt;引入Mecoin，通过结构化记忆单元缓存学习类别的原型，并利用记忆构建模块通过节点与缓存原型的交互更新这些原型，同时设计了记忆表示适应模块以降低参数微调的需求。&lt;h4&gt;主要发现&lt;/h4&gt;Mecoin在泛化误差方面表现出色，不同蒸馏策略对模型性能的影响通过实验和VC维度分析得到了探讨。&lt;h4&gt;结论&lt;/h4&gt;Mecoin在准确性和遗忘率方面优于其他相关工作，展示了其在图形增量学习中的有效性。&lt;h4&gt;总结&lt;/h4&gt;Mecoin为少样本增量学习提供了一种新的高效方法，减少了内存消耗和遗忘率，且代码公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/arvin0313/mecoin-gfscil&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Incremental graph learning has gained significant attention for its abilityto address the catastrophic forgetting problem in graph representationlearning. However, traditional methods often rely on a large number of labelsfor node classification, which is impractical in real-world applications. Thismakes few-shot incremental learning on graphs a pressing need. Current methodstypically require extensive training samples from meta-learning to build memoryand perform intensive fine-tuning of GNN parameters, leading to high memoryconsumption and potential loss of previously learned knowledge. To tackle thesechallenges, we introduce Mecoin, an efficient method for building andmaintaining memory. Mecoin employs Structured Memory Units to cache prototypesof learned categories, as well as Memory Construction Modules to update theseprototypes for new categories through interactions between the nodes and thecached prototypes. Additionally, we have designed a Memory RepresentationAdaptation Module to store probabilities associated with each class prototype,reducing the need for parameter fine-tuning and lowering the forgetting rate.When a sample matches its corresponding class prototype, the relevantprobabilities are retrieved from the MRaM. Knowledge is then distilled backinto the GNN through a Graph Knowledge Distillation Module, preserving themodel's memory. We analyze the effectiveness of Mecoin in terms ofgeneralization error and explore the impact of different distillationstrategies on model performance through experiments and VC-dimension analysis.Compared to other related works, Mecoin shows superior performance in accuracyand forgetting rate. Our code is publicly available on thehttps://github.com/Arvin0313/Mecoin-GFSCIL.git .</description>
      <author>example@mail.com (Dong Li, Aijia Zhang, Junqi Gao, Biqing Qi)</author>
      <guid isPermaLink="false">2411.06659v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Meteorological Forecasting: AI-based Approach to Synoptic Weather Map Analysis</title>
      <link>http://arxiv.org/abs/2411.05384v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全球变暖导致天气模式复杂化，天气预报的精确性变得愈加重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的预处理方法和卷积自编码器模型，以改善对天气图的解读。&lt;h4&gt;方法&lt;/h4&gt;使用无监督学习模型（如VQ-VQE）和监督学习模型（如VGG16、VGG19、Xception、InceptionV3和ResNet50），并研究新模型如EfficientNet和ConvNeXt。&lt;h4&gt;主要发现&lt;/h4&gt;虽然这些模型在多种环境下表现良好，但在识别相似天气图方面存在一定局限。&lt;h4&gt;结论&lt;/h4&gt;研究发现余弦相似度是最有效的度量标准，能够准确识别相关的历史天气模式。&lt;h4&gt;总结&lt;/h4&gt;本研究强调从数值精确性转向实用应用，确保模型在气象学领域的理论有效性和实践可行性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As global warming increases the complexity of weather patterns; the precisionof weather forecasting becomes increasingly important. Our study proposes anovel preprocessing method and convolutional autoencoder model developed toimprove the interpretation of synoptic weather maps. These are critical formeteorologists seeking a thorough understanding of weather conditions. Thismodel could recognize historical synoptic weather maps that nearly matchcurrent atmospheric conditions, marking a significant step forward in moderntechnology in meteorological forecasting. This comprises unsupervised learningmodels like VQ-VQE, as well as supervised learning models like VGG16, VGG19,Xception, InceptionV3, and ResNet50 trained on the ImageNet dataset, as well asresearch into newer models like EfficientNet and ConvNeXt. Our findings provedthat, while these models perform well in various settings, their ability toidentify comparable synoptic weather maps has certain limits. Our research,motivated by the primary goal of significantly increasing meteorologists'efficiency in labor-intensive tasks, discovered that cosine similarity is themost effective metric, as determined by a combination of quantitative andqualitative assessments to accurately identify relevant historical weatherpatterns. This study broadens our understanding by shifting the emphasis fromnumerical precision to practical application, ensuring that our model iseffective in theory practical, and accessible in the complex and dynamic fieldof meteorology.</description>
      <author>example@mail.com (Yo-Hwan Choi, Seon-Yu Kang, Minjong Cheon)</author>
      <guid isPermaLink="false">2411.05384v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Fusion Balancing Through Game-Theoretic Regularization</title>
      <link>http://arxiv.org/abs/2411.07335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 6 figures, 4 tables, 1 algorithm&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态学习能够通过揭示数据源之间的关键依赖关系来完成信息提取的全貌，当前系统未能充分利用多种模态以达到最佳性能。&lt;h4&gt;目的&lt;/h4&gt;探讨如何确保在多模态训练中所有模态都能得到充分训练，并且从新模态学习始终能提高性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的损失组件——多模态竞争正则化器（MCR），其灵感来源于互信息（MI）分解，旨在防止多模态训练中的竞争不利影响。&lt;h4&gt;主要发现&lt;/h4&gt;引入博弈论原则，使每个模态作为玩家竞争以最大化其对最终结果的影响；精炼每个MI项的上下界，以增强任务相关的独特和共享信息的提取；提出潜在空间排列以进行条件MI估计，显著提高计算效率。&lt;h4&gt;结论&lt;/h4&gt;MCR超越了所有之前建议的训练策略，是首个在多模态学习中一致性地超过集成基线的模型，清楚地表明组合模态在合成和大型真实世界数据集上带来了显著的性能提升。&lt;h4&gt;总结&lt;/h4&gt;MCR方法有效解决了模态竞争问题，促进了多模态学习的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning can complete the picture of information extraction byuncovering key dependencies between data sources. However, current systems failto fully leverage multiple modalities for optimal performance. This has beenattributed to modality competition, where modalities strive for trainingresources, leaving some underoptimized. We show that current balancing methodsstruggle to train multimodal models that surpass even simple baselines, such asensembles. This raises the question: how can we ensure that all modalities inmultimodal training are sufficiently trained, and that learning from newmodalities consistently improves performance? This paper proposes theMultimodal Competition Regularizer (MCR), a new loss component inspired bymutual information (MI) decomposition designed to prevent the adverse effectsof competition in multimodal training. Our key contributions are: 1)Introducing game-theoretic principles in multimodal learning, where eachmodality acts as a player competing to maximize its influence on the finaloutcome, enabling automatic balancing of the MI terms. 2) Refining lower andupper bounds for each MI term to enhance the extraction of task-relevant uniqueand shared information across modalities. 3) Suggesting latent spacepermutations for conditional MI estimation, significantly improvingcomputational efficiency. MCR outperforms all previously suggested trainingstrategies and is the first to consistently improve multimodal learning beyondthe ensemble baseline, clearly demonstrating that combining modalities leads tosignificant performance gains on both synthetic and large real-world datasets.</description>
      <author>example@mail.com (Konstantinos Kontras, Thomas Strypsteen, Christos Chatzichristos, Paul P. Liang, Matthew Blaschko, Maarten De Vos)</author>
      <guid isPermaLink="false">2411.07335v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Scale Contrastive Learning with Selective Attentions for Blind Image Quality Assessment</title>
      <link>http://arxiv.org/abs/2411.09007v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;盲图像质量评估（BIQA）是计算机视觉中的基础任务，但常常无法与人类主观感知一致。&lt;h4&gt;目的&lt;/h4&gt;解决多尺度评估策略在图像质量感知中的有效性问题，特别是不同尺度对感知质量的影响。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的多尺度BIQA框架，称为对比约束尺度聚焦IQA框架（CSFIQA），使用选择性关注机制和尺度级对比学习模块。&lt;h4&gt;主要发现&lt;/h4&gt;CSFIQA在八个基准数据集上表现优异，SRCC值分别达到0.967（CSIQ为0.947）和0.905（LIVEC为0.876）。&lt;h4&gt;结论&lt;/h4&gt;通过探索图像尺度与感知质量之间的内在关系，CSFIQA显著提高了盲图像质量评估的性能。&lt;h4&gt;总结&lt;/h4&gt;CSFIQA框架有效减少信息冗余，突出关键质量相关信息，解决了不同尺度特征组合带来的混淆问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Blind image quality assessment (BIQA) serves as a fundamental task incomputer vision, yet it often fails to consistently align with human subjectiveperception. Recent advances show that multi-scale evaluation strategies arepromising due to their ability to replicate the hierarchical structure of humanvision. However, the effectiveness of these strategies is limited by a lack ofunderstanding of how different image scales influence perceived quality. Thispaper addresses two primary challenges: the significant redundancy ofinformation across different scales, and the confusion caused by combiningfeatures from these scales, which may vary widely in quality. To this end, anew multi-scale BIQA framework is proposed, namely Contrast-ConstrainedScale-Focused IQA Framework (CSFIQA). CSFIQA features a selective focusattention mechanism to minimize information redundancy and highlight criticalquality-related information. Additionally, CSFIQA includes a scale-levelcontrastive learning module equipped with a noise sample matching mechanism toidentify quality discrepancies across the same image content at differentscales. By exploring the intrinsic relationship between image scales and theperceived quality, the proposed CSFIQA achieves leading performance on eightbenchmark datasets, e.g., achieving SRCC values of 0.967 (versus 0.947 in CSIQ)and 0.905 (versus 0.876 in LIVEC).</description>
      <author>example@mail.com (Zihao Huang, Xudong Li, Bohan Fu, Xiaohui Chu, Ke Li, Yunhang Shen, Yan Zhang)</author>
      <guid isPermaLink="false">2411.09007v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Alternative Learning Paradigms for Image Quality Transfer</title>
      <link>http://arxiv.org/abs/2411.05885v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://melba-journal.org/2024:027&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图像质量转移（IQT）旨在提高低质量医学图像的对比度和分辨率，这些图像通常来自低功率设备，且富含高质量图像学习到的信息。&lt;h4&gt;目的&lt;/h4&gt;提出两种新的IQT问题的公式化方法，分别为无监督学习和结合监督与无监督学习的方式。&lt;h4&gt;方法&lt;/h4&gt;第一种方法为无监督学习框架，称为IQT-SRep，使用稀疏表示和字典学习模型；第二种方法为IQT-DDL，结合了监督与无监督学习，基于深度字典学习。&lt;h4&gt;主要发现&lt;/h4&gt;IQT-SRep通过使用低高质量体积对训练两个字典，使用低质量字典的稀疏表示直接恢复高质量块；而IQT-DDL则显式学习高分辨率字典以提升输入体积，同时优化整个网络。&lt;h4&gt;结论&lt;/h4&gt;与现有的监督深度学习IQT方法相比，提出的方法能够避免与监督方法相关的偏差，尤其是在使用与训练数据分布不同的外部数据时。&lt;h4&gt;总结&lt;/h4&gt;这两种新的IQT方法展示了在医学图像质量提升中的潜在优势和应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.59275/j.melba.2024-1656&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image Quality Transfer (IQT) aims to enhance the contrast and resolution oflow-quality medical images, e.g. obtained from low-power devices, with richinformation learned from higher quality images. In contrast to existing IQTmethods which adopt supervised learning frameworks, in this work, we proposetwo novel formulations of the IQT problem. The first approach uses anunsupervised learning framework, whereas the second is a combination of bothsupervised and unsupervised learning. The unsupervised learning approachconsiders a sparse representation (SRep) and dictionary learning model, whichwe call IQT-SRep, whereas the combination of supervised and unsupervisedlearning approach is based on deep dictionary learning (DDL), which we callIQT-DDL. The IQT-SRep approach trains two dictionaries using a SRep model usingpairs of low- and high-quality volumes. Subsequently, the SRep of a low-qualityblock, in terms of the low-quality dictionary, can be directly used to recoverthe corresponding high-quality block using the high-quality dictionary. On theother hand, the IQT-DDL approach explicitly learns a high-resolution dictionaryto upscale the input volume, while the entire network, including highdictionary generator, is simultaneously optimised to take full advantage ofdeep learning methods. The two models are evaluated using a low-field magneticresonance imaging (MRI) application aiming to recover high-quality images akinto those obtained from high-field scanners. Experiments comparing the proposedapproaches against state-of-the-art supervised deep learning IQT method(IQT-DL) identify that the two novel formulations of the IQT problem can avoidbias associated with supervised methods when tested using out-of-distributiondata that differs from the distribution of the data the model was trained on.This highlights the potential benefit of these novel paradigms for IQT.</description>
      <author>example@mail.com (Ahmed Karam Eldaly, Matteo Figini, Daniel C. Alexander)</author>
      <guid isPermaLink="false">2411.05885v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>A survey on Graph Deep Representation Learning for Facial Expression Recognition</title>
      <link>http://arxiv.org/abs/2411.08472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本综述深入探讨了通过图表示学习（GRL）进行面部表情识别（FER）的各种方法。&lt;h4&gt;目的&lt;/h4&gt;介绍FER任务及图表示和GRL的概念。&lt;h4&gt;方法&lt;/h4&gt;讨论一些用于FER的主要和有价值的数据集，探索基于图的FER方法，包括图扩散、时空图和多流体系结构。&lt;h4&gt;主要发现&lt;/h4&gt;识别出图表示在FER中的前景方法，分析其应用潜力。&lt;h4&gt;结论&lt;/h4&gt;确定未来研究机会并提供总结性评论。&lt;h4&gt;总结&lt;/h4&gt;综述强调了图表示学习在面部表情识别领域的重要性和发展方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This comprehensive review delves deeply into the various methodologiesapplied to facial expression recognition (FER) through the lens of graphrepresentation learning (GRL). Initially, we introduce the task of FER and theconcepts of graph representation and GRL. Afterward, we discuss some of themost prevalent and valuable databases for this task. We explore promisingapproaches for graph representation in FER, including graph diffusion,spatio-temporal graphs, and multi-stream architectures. Finally, we identifyfuture research opportunities and provide concluding remarks.</description>
      <author>example@mail.com (Théo Gueuret, Akrem Sellami, Chaabane Djeraba)</author>
      <guid isPermaLink="false">2411.08472v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>SimBase: A Simple Baseline for Temporal Video Grounding</title>
      <link>http://arxiv.org/abs/2411.07945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，时序视频定位技术取得了显著进展，但网络架构变得愈加复杂。&lt;h4&gt;目的&lt;/h4&gt;探讨简化方法在时序视频定位中的有效性。&lt;h4&gt;方法&lt;/h4&gt;设计了SimBase网络，使用轻量级的一维时序卷积层，而非复杂的时序结构；在跨模态交互中，采用元素级乘积，避免复杂的多模态融合。&lt;h4&gt;主要发现&lt;/h4&gt;SimBase在两个大规模数据集上实现了最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;作为一个简单而强大的基准，SimBase有望激发新的想法并简化未来的时序视频定位评估。&lt;h4&gt;总结&lt;/h4&gt;SimBase展示了简化网络架构在时序视频定位中的潜力和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents SimBase, a simple yet effective baseline for temporalvideo grounding. While recent advances in temporal grounding have led toimpressive performance, they have also driven network architectures towardgreater complexity, with a range of methods to (1) capture temporalrelationships and (2) achieve effective multimodal fusion. In contrast, thispaper explores the question: How effective can a simplified approach be? Toinvestigate, we design SimBase, a network that leverages lightweight,one-dimensional temporal convolutional layers instead of complex temporalstructures. For cross-modal interaction, SimBase only employs an element-wiseproduct instead of intricate multimodal fusion. Remarkably, SimBase achievesstate-of-the-art results on two large-scale datasets. As a simple yet powerfulbaseline, we hope SimBase will spark new ideas and streamline futureevaluations in temporal video grounding.</description>
      <author>example@mail.com (Peijun Bao, Alex C. Kot)</author>
      <guid isPermaLink="false">2411.07945v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Multiscale Graph Construction Using Non-local Cluster Features</title>
      <link>http://arxiv.org/abs/2411.08371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有图聚类方法往往忽略信号变化，导致相似特征的节点聚类失败。&lt;h4&gt;目的&lt;/h4&gt;提出一种同时考虑图和节点特征的多尺度聚类方法。&lt;h4&gt;方法&lt;/h4&gt;通过三个步骤进行层次聚类：1) 提取聚类中的特征向量；2) 计算聚类特征之间的相似性；3) 构建可变的 $k$-最近邻图并应用图谱聚类。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法在多尺度图像和点云分割实验中表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够合并空间上分离但特征相似的节点，具有非局部特性。&lt;h4&gt;总结&lt;/h4&gt;这种多尺度图构建方法为图聚类提供了新的视角，提升了聚类的准确性和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/MLSP58920.2024.10734767&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a multiscale graph construction method using both graphand signal features. Multiscale graph is a hierarchical representation of thegraph, where a node at each level indicates a cluster in a finer resolution. Toobtain the hierarchical clusters, existing methods often use graph clustering;however, they may ignore signal variations. As a result, these methods couldfail to detect the clusters having similar features on nodes. In this paper, weconsider graph and node-wise features simultaneously for multiscale clusteringof a graph. With given clusters of the graph, the clusters are mergedhierarchically in three steps: 1) Feature vectors in the clusters areextracted. 2) Similarities among cluster features are calculated using optimaltransport. 3) A variable $k$-nearest neighbor graph (V$k$NNG) is constructedand graph spectral clustering is applied to the V$k$NNG to obtain clusters at acoarser scale. Additionally, the multiscale graph in this paper has\textit{non-local} characteristics: Nodes with similar features are merged evenif they are spatially separated. In experiments on multiscale image and pointcloud segmentation, we demonstrate the effectiveness of the proposed method.</description>
      <author>example@mail.com (Reina Kaneko, Hayate Kojima, Kenta Yanagiya, Junya Hara, Hiroshi Higashi, Yuichi Tanaka)</author>
      <guid isPermaLink="false">2411.08371v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning for Beamforming in Multi-User Continuous Aperture Array (CAPA) Systems</title>
      <link>http://arxiv.org/abs/2411.09104v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 11 figures. arXiv admin note: text overlap with
  arXiv:2408.11230&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一个DeepCAPA框架，用于学习连续孔径阵列（CAPA）系统中的波束形成。&lt;h4&gt;目的&lt;/h4&gt;优化CAPA系统中的波束形成问题。&lt;h4&gt;方法&lt;/h4&gt;首先对波束形成优化问题进行数学公式化，并证明最优波束形成位于用户共轭信道响应所张成的子空间。为解决深度神经网络（DNN）在处理无限维输入输出空间时的挑战，导出了有限维表示。此外，训练了两个额外的DNN，以近似没有闭合形式表达的操作，从而加速梯度反向传播。&lt;h4&gt;主要发现&lt;/h4&gt;DeepCAPA框架在谱效率和推理复杂度方面优于匹配滤波和最先进的基于傅里叶的离散化方法，并且在天线数量趋近于无穷大时，接近了空间离散阵列系统波束形成优化的性能上限。&lt;h4&gt;结论&lt;/h4&gt;DeepCAPA方法有效提升了波束形成的学习性能，同时降低了训练复杂度。&lt;h4&gt;总结&lt;/h4&gt;DeepCAPA框架通过数学证明和图神经网络设计，成功优化了CAPA系统中的波束形成问题，展示了其优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A DeepCAPA (Deep Learning for Continuous Aperture Array (CAPA)) framework isproposed to learn beamforming in CAPA systems. The beamforming optimizationproblem is firstly formulated, and it is mathematically proved that the optimalbeamforming lies in the subspace spanned by users' conjugate channel responses.Two challenges are encountered when directly applying deep neural networks(DNNs) for solving the formulated problem, i) both the input and output spacesare infinite-dimensional, which are not compatible with DNNs. Thefinite-dimensional representations of inputs and outputs are derived to addressthis challenge. ii) A closed-form loss function is unavailable for training theDNN. To tackle this challenge, two additional DNNs are trained to approximatethe operations without closed-form expressions for expediting gradientback-propagation. To improve learning performance and reduce trainingcomplexity, the permutation equivariance properties of the mappings to belearned are mathematically proved. As a further advance, the DNNs are designedas graph neural networks to leverage the properties. Numerical resultsdemonstrate that: i) the proposed DeepCAPA framework achieves higher spectralefficiency and lower inference complexity compared to match-filtering andstate-of-art Fourier-based discretization method, and ii) DeepCAPA approachesthe performance upper bound of optimizing beamforming in the spatially discretearray-based system as the number of antennas in a fixed-sized area tends towardinfinity.</description>
      <author>example@mail.com (Jia Guo, Yuanwei Liu, Hyundong Shin, Arumugam Nallanathan)</author>
      <guid isPermaLink="false">2411.09104v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>LUDO: Low-Latency Understanding of Highly Deformable Objects using Point Cloud Occupancy Functions</title>
      <link>http://arxiv.org/abs/2411.08777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在需要精确定位的医疗任务中，准确确定不可变形物体的内部结构的形状和位置至关重要，例如机器人活检。&lt;h4&gt;目的&lt;/h4&gt;提出LUDO方法，以实现对可变形物体的准确低延迟理解。&lt;h4&gt;方法&lt;/h4&gt;LUDO通过单视角点云观察，使用占用网络在30毫秒内重建物体的变形状态及其内部结构。&lt;h4&gt;主要发现&lt;/h4&gt;LUDO能够自主定位高度可变形物体内部的感兴趣区域（ROI），并提供预测的不确定性估计及可解释性。&lt;h4&gt;结论&lt;/h4&gt;在实际机器人实验中，LUDO对各种高度可变形物体内部的ROI穿刺成功率达到98.9%。&lt;h4&gt;总结&lt;/h4&gt;LUDO展示了在无需变形注册方法的情况下与可变形物体交互的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately determining the shape and location of internal structures withindeformable objects is crucial for medical tasks that require precise targeting,such as robotic biopsies. We introduce LUDO, a method for accurate low-latencyunderstanding of deformable objects. LUDO reconstructs objects in theirdeformed state, including their internal structures, from a single-view pointcloud observation in under 30 ms using occupancy networks. We demonstrateLUDO's abilities for autonomous targeting of internal regions of interest(ROIs) in highly deformable objects. Additionally, LUDO provides uncertaintyestimates and explainability for its predictions, both of which are importantin safety-critical applications such as surgical interventions. We evaluateLUDO in real-world robotic experiments, achieving a success rate of 98.9% forpuncturing various ROIs inside highly deformable objects. LUDO demonstrates thepotential to interact with deformable objects without the need for deformableregistration methods.</description>
      <author>example@mail.com (Pit Henrich, Franziska Mathis-Ullrich, Paul Maria Scheikl)</author>
      <guid isPermaLink="false">2411.08777v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>LLM-assisted Explicit and Implicit Multi-interest Learning Framework for Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2411.09410v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前推荐系统中的多兴趣建模主要基于用户的行为数据，但这些数据隐含且稀疏，难以捕捉用户复杂多样的兴趣。&lt;h4&gt;目的&lt;/h4&gt;提出一种LLM辅助的显性与隐性多兴趣学习框架（EIMF），在行为和语义两个层面建模用户兴趣。&lt;h4&gt;方法&lt;/h4&gt;框架包括隐性行为兴趣模块（IBIM）和显性语义兴趣模块（ESIM），通过聚类算法选择典型样本，并采用LLM的提示策略获取显性语义兴趣。&lt;h4&gt;主要发现&lt;/h4&gt;在训练阶段，典型样本的语义兴趣能够通过多任务学习增强行为兴趣的表示学习。&lt;h4&gt;结论&lt;/h4&gt;在推理阶段，仅依靠用户的行为数据即可实现准确的推荐，EIMF框架有效结合了小模型与LLM，提高了多兴趣建模的准确性。&lt;h4&gt;总结&lt;/h4&gt;EIMF框架通过整合行为数据和语义信息，解决了小模型在捕捉深层兴趣方面的难题，具有良好的效果和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-interest modeling in current recommender systems (RS) is mainly basedon user behavioral data, capturing user interest preferences from multipledimensions. However, since behavioral data is implicit and often highly sparse,it is challenging to understand users' complex and diverse interests. Recentstudies have shown that the rich semantic information in the text caneffectively supplement the deficiencies of behavioral data. Despite this, it isstill difficult for small models to directly extract semantic featuresassociated with users' deep interests. That is, how to effectively alignsemantics with behavioral information to form a more comprehensive and accurateunderstanding of user interests has become a critical research problem.Toaddress this, we propose an LLM-assisted explicit and implicit multi-interestlearning framework (named EIMF) to model user interests on two levels: behaviorand semantics. The framework consists of two parts: Implicit BehavioralInterest Module (IBIM) and Explicit Semantic Interest Module (ESIM). Thetraditional multi-interest RS model in IBIM can learn users' implicitbehavioral interests from interactions with items. In ESIM, we first adopt aclustering algorithm to select typical samples and design a prompting strategyon LLM to obtain explicit semantic interests. Furthermore, in the trainingphase, the semantic interests of typical samples can enhance the representationlearning of behavioral interests based on the multi-task learning on semanticprediction and modality alignment. Therefore, in the inference stage, accuraterecommendations can be achieved with only the user's behavioral data. Extensiveexperiments on real-world datasets demonstrate the effectiveness of theproposed EIMF framework, which effectively and efficiently combines smallmodels with LLM to improve the accuracy of multi-interest modeling.</description>
      <author>example@mail.com (Shutong Qiao, Chen Gao, Yong Li, Hongzhi Yin)</author>
      <guid isPermaLink="false">2411.09410v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Material Property Prediction with Element Attribute Knowledge Graphs and Multimodal Representation Learning</title>
      <link>http://arxiv.org/abs/2411.08414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习已成为预测晶体材料特性的关键工具，但现有方法主要通过构建晶体结构的多边图来表示材料信息，常常忽视元素的化学和物理特性。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法对元素特性考虑不足的问题，以提高材料性能预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;构建元素属性知识图谱，利用嵌入模型编码元素属性，并提出多模态融合框架ESNet，将元素属性特征与晶体结构特征结合以生成联合多模态表示。&lt;h4&gt;主要发现&lt;/h4&gt;在Materials Project基准数据集上，ESNet在带隙预测任务中表现优异，在形成能预测任务上也达到了现有基准水平。&lt;h4&gt;结论&lt;/h4&gt;通过综合考虑微观结构组成和材料的化学特性，ESNet提供了更全面的视角来预测晶体材料的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究通过构建知识图谱和多模态融合框架，显著提升了晶体材料性能预测的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has become a crucial tool for predicting the properties ofcrystalline materials. However, existing methods primarily represent materialinformation by constructing multi-edge graphs of crystal structures, oftenoverlooking the chemical and physical properties of elements (such as atomicradius, electronegativity, melting point, and ionization energy), which have asignificant impact on material performance. To address this limitation, wefirst constructed an element property knowledge graph and utilized an embeddingmodel to encode the element attributes within the knowledge graph. Furthermore,we propose a multimodal fusion framework, ESNet, which integrates elementproperty features with crystal structure features to generate joint multimodalrepresentations. This provides a more comprehensive perspective for predictingthe performance of crystalline materials, enabling the model to consider bothmicrostructural composition and chemical characteristics of the materials. Weconducted experiments on the Materials Project benchmark dataset, which showedleading performance in the bandgap prediction task and achieved results on apar with existing benchmarks in the formation energy prediction task.</description>
      <author>example@mail.com (Chao Huang, Chunyan Chen, Ling Shi, Chen Chen)</author>
      <guid isPermaLink="false">2411.08414v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Neural Graph Simulator for Complex Systems</title>
      <link>http://arxiv.org/abs/2411.09120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数值模拟是研究复杂系统动态的重要工具，但大规模模拟常因计算限制而难以进行。&lt;h4&gt;目的&lt;/h4&gt;介绍神经图模拟器（NGS），用于在图上模拟时间不变的自主系统。&lt;h4&gt;方法&lt;/h4&gt;利用图神经网络，NGS提供了一个统一的框架，可以模拟不同拓扑和规模的动态系统，采用非均匀时间步和自回归方法。&lt;h4&gt;主要发现&lt;/h4&gt;NGS在处理噪声或缺失数据时表现出色，不需要先验的控制方程知识，计算效率相比传统方法提升了超过10^5倍，特别在刚性问题上表现突出。&lt;h4&gt;结论&lt;/h4&gt;NGS在实际交通数据中的应用显示出先进的交通流预测准确性，且其适用性超出所展示的案例，具有多种潜在的增强方向。&lt;h4&gt;总结&lt;/h4&gt;神经图模拟器为复杂系统的动态模拟提供了一种高效且灵活的解决方案，展示出良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Numerical simulation is a predominant tool for studying the dynamics incomplex systems, but large-scale simulations are often intractable due tocomputational limitations. Here, we introduce the Neural Graph Simulator (NGS)for simulating time-invariant autonomous systems on graphs. Utilizing a graphneural network, the NGS provides a unified framework to simulate diversedynamical systems with varying topologies and sizes without constraints onevaluation times through its non-uniform time step and autoregressive approach.The NGS offers significant advantages over numerical solvers by not requiringprior knowledge of governing equations and effectively handling noisy ormissing data with a robust training scheme. It demonstrates superiorcomputational efficiency over conventional methods, improving performance byover $10^5$ times in stiff problems. Furthermore, it is applied to real trafficdata, forecasting traffic flow with state-of-the-art accuracy. The versatilityof the NGS extends beyond the presented cases, offering numerous potentialavenues for enhancement.</description>
      <author>example@mail.com (Hoyun Choi, Sungyeop Lee, B. Kahng, Junghyo Jo)</author>
      <guid isPermaLink="false">2411.09120v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Online Collision Risk Estimation via Monocular Depth-Aware Object Detectors and Fuzzy Inference</title>
      <link>http://arxiv.org/abs/2411.08060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages (IEEE double column format), 5 figures, 3 tables, submitted
  to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文提出了一种监测框架，用于基于自主车辆（AV）对象检测器的性能推断碰撞风险水平，仅使用单目相机图像。&lt;h4&gt;目的&lt;/h4&gt;通过不同算法产生的预测结果之间的不一致性来关联碰撞风险。&lt;h4&gt;方法&lt;/h4&gt;框架使用两组预测：一组来自深度图中的安全关键2.5D对象，另一组来自AV的3D对象检测器，利用模糊推理分析不一致性与碰撞风险的关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过交并比（IoU）和深度差异度量，两组预测之间的不一致性与3D对象检测器的安全相关错误高度相关。&lt;h4&gt;结论&lt;/h4&gt;构建了模糊推理系统，将不一致性度量映射到现有的碰撞风险指标，发现使用粒子群优化学习通用模糊规则的结果最佳。&lt;h4&gt;应用&lt;/h4&gt;验证了监测系统在大规模nuScenes数据集上的风险估计能力，证明其可以在闭环模拟中保护自主车辆。&lt;h4&gt;总结&lt;/h4&gt;该框架为自主车辆的碰撞风险监测提供了一种有效的方法，能够在实际应用中提高安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a monitoring framework that infers the level ofautonomous vehicle (AV) collision risk based on its object detector'sperformance using only monocular camera images. Essentially, the frameworktakes two sets of predictions produced by different algorithms and associatestheir inconsistencies with the collision risk via fuzzy inference. The firstset of predictions is obtained through retrieving safety-critical 2.5D objectsfrom a depth map, and the second set comes from the AV's 3D object detector. Weexperimentally validate that, based on Intersection-over-Union (IoU) and adepth discrepancy measure, the inconsistencies between the two sets ofpredictions strongly correlate to the safety-related error of the 3D objectdetector against ground truths. This correlation allows us to construct a fuzzyinference system and map the inconsistency measures to an existing collisionrisk indicator. In particular, we apply various knowledge- and data-driventechniques and find using particle swarm optimization that learns general fuzzyrules gives the best mapping result. Lastly, we validate our monitor'scapability to produce relevant risk estimates with the large-scale nuScenesdataset and show it can safeguard an AV in closed-loop simulations.</description>
      <author>example@mail.com (Brian Hsuan-Cheng Liao, Yingjie Xu, Chih-Hong Cheng, Hasan Esen, Alois Knoll)</author>
      <guid isPermaLink="false">2411.08060v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>A Centralized-Distributed Transfer Model for Cross-Domain Recommendation Based on Multi-Source Heterogeneous Transfer Learning</title>
      <link>http://arxiv.org/abs/2411.09286v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in: 2022 IEEE International Conference on Data Mining
  (ICDM) (The authors were affiliated Hangzhou NetEase Cloud Music Technology
  Co., Ltd.)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;跨域推荐（CDR）方法被提出以解决点击率（CTR）估计中的稀疏性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种中央-分布式转移模型（CDTM），以应对多源异构转移学习中的问题。&lt;h4&gt;方法&lt;/h4&gt;通过构建双嵌入结构（特定域嵌入DSE和全局共享嵌入GSE）来解决特征维度异构性，并使用转移矩阵和注意力机制自适应地映射和组合DSE与GSE。&lt;h4&gt;主要发现&lt;/h4&gt;大量的离线和在线实验验证了模型的有效性。&lt;h4&gt;结论&lt;/h4&gt;CDTM模型能够更好地处理跨域推荐中的知识转移问题，提高目标域的模型性能。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的方法有效解决了现有CDR方法中存在的异构性和单源转移的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICDM54844.2022.00166&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-domain recommendation (CDR) methods are proposed to tackle the sparsityproblem in click through rate (CTR) estimation. Existing CDR methods directlytransfer knowledge from the source domains to the target domain and ignore theheterogeneities among domains, including feature dimensional heterogeneity andlatent space heterogeneity, which may lead to negative transfer. Besides, mostof the existing methods are based on single-source transfer, which cannotsimultaneously utilize knowledge from multiple source domains to furtherimprove the model performance in the target domain. In this paper, we propose acentralized-distributed transfer model (CDTM) for CDR based on multi-sourceheterogeneous transfer learning. To address the issue of feature dimensionheterogeneity, we build a dual embedding structure: domain specific embedding(DSE) and global shared embedding (GSE) to model the feature representation inthe single domain and the commonalities in the global space,separately. Tosolve the latent space heterogeneity, the transfer matrix and attentionmechanism are used to map and combine DSE and GSE adaptively. Extensive offlineand online experiments demonstrate the effectiveness of our model.</description>
      <author>example@mail.com (Ke Xu, Ziliang Wang, Wei Zheng, Yuhao Ma, Chenglin Wang, Nengxue Jiang, Cai Cao)</author>
      <guid isPermaLink="false">2411.09286v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Time-to-Event Pretraining for 3D Medical Imaging</title>
      <link>http://arxiv.org/abs/2411.09361v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages, 19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着医学基础模型的兴起和影像数据的日益丰富，可扩展的预训练技术提供了一种有前途的方法来识别预测未来疾病风险的影像生物标志物。&lt;h4&gt;目的&lt;/h4&gt;解决当前自监督方法在3D医学影像模型中无法将像素生物标志物与长期健康结果关联的问题。&lt;h4&gt;方法&lt;/h4&gt;引入时间到事件预训练框架，利用配对的纵向电子健康记录（EHRs）中的大规模时间监督进行3D医学影像模型的预训练。&lt;h4&gt;主要发现&lt;/h4&gt;使用18,945个CT扫描（4.2百万2D图像）和数千个EHR衍生任务的时间到事件分布，方法在8个基准任务中实现了23.7%的AUROC平均提升和29.4%的Harrell C指数增益。&lt;h4&gt;结论&lt;/h4&gt;这些提升是在不牺牲诊断分类性能的情况下实现的，为结合纵向EHR和3D影像数据以推动临床风险预测奠定了基础。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了时间到事件预训练在提高3D医学影像模型的临床风险预测能力中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rise of medical foundation models and the growing availability ofimaging data, scalable pretraining techniques offer a promising way to identifyimaging biomarkers predictive of future disease risk. While currentself-supervised methods for 3D medical imaging models capture local structuralfeatures like organ morphology, they fail to link pixel biomarkers withlong-term health outcomes due to a missing context problem. Current approacheslack the temporal context necessary to identify biomarkers correlated withdisease progression, as they rely on supervision derived only from images andconcurrent text descriptions. To address this, we introduce time-to-eventpretraining, a pretraining framework for 3D medical imaging models thatleverages large-scale temporal supervision from paired, longitudinal electronichealth records (EHRs). Using a dataset of 18,945 CT scans (4.2 million 2Dimages) and time-to-event distributions across thousands of EHR-derived tasks,our method improves outcome prediction, achieving an average AUROC increase of23.7% and a 29.4% gain in Harrell's C-index across 8 benchmark tasks.Importantly, these gains are achieved without sacrificing diagnosticclassification performance. This study lays the foundation for integratinglongitudinal EHR and 3D imaging data to advance clinical risk prediction.</description>
      <author>example@mail.com (Zepeng Huo, Jason Alan Fries, Alejandro Lozano, Jeya Maria Jose Valanarasu, Ethan Steinberg, Louis Blankemeier, Akshay S. Chaudhari, Curtis Langlotz, Nigam H. Shah)</author>
      <guid isPermaLink="false">2411.09361v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Cross Space and Time: A Spatio-Temporal Unitized Model for Traffic Flow Forecasting</title>
      <link>http://arxiv.org/abs/2411.09251v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预测时空交通流面临复杂的空间和时间因素之间的相互作用，现有方法往往孤立处理这些维度，忽视了它们的关键相互依赖性。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一框架（STUM），旨在同时捕捉空间和时间依赖性，并处理时空异质性。&lt;h4&gt;方法&lt;/h4&gt;通过分布对齐和特征融合等技术实现STUM，并引入自适应时空单元格（ASTUC）利用低秩矩阵存储、更新和交互空间、时间及其相关性。&lt;h4&gt;主要发现&lt;/h4&gt;STUM在多个真实数据集上实验显示其预测性能显著提升，且计算成本最低。&lt;h4&gt;结论&lt;/h4&gt;STUM提供了更高的预测准确性和计算效率，适合与多种时空图神经网络集成，增强预测结果。&lt;h4&gt;总结&lt;/h4&gt;研究结果通过超参数优化、预训练分析和结果可视化进行了支持，源代码可以在指定链接获取以便复现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting spatio-temporal traffic flow presents significant challenges dueto complex interactions between spatial and temporal factors. Existingapproaches often address these dimensions in isolation, neglecting theircritical interdependencies. In this paper, we introduce the Spatio-TemporalUnitized Model (STUM), a unified framework designed to capture both spatial andtemporal dependencies while addressing spatio-temporal heterogeneity throughtechniques such as distribution alignment and feature fusion. It also ensuresboth predictive accuracy and computational efficiency. Central to STUM is theAdaptive Spatio-temporal Unitized Cell (ASTUC), which utilizes low-rankmatrices to seamlessly store, update, and interact with space, time, as well astheir correlations. Our framework is also modular, allowing it to integratewith various spatio-temporal graph neural networks through components such asbackbone models, feature extractors, residual fusion blocks, and predictivemodules to collectively enhance forecasting outcomes. Experimental resultsacross multiple real-world datasets demonstrate that STUM consistently improvesprediction performance with minimal computational cost. These findings arefurther supported by hyperparameter optimization, pre-training analysis, andresult visualization. We provide our source code for reproducibility athttps://anonymous.4open.science/r/STUM-E4F0.</description>
      <author>example@mail.com (Weilin Ruan, Wenzhuo Wang, Siru Zhong, Wei Chen, Li Liu, Yuxuan Liang)</author>
      <guid isPermaLink="false">2411.09251v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Efficient 3D Perception on Multi-Sweep Point Cloud with Gumbel Spatial Pruning</title>
      <link>http://arxiv.org/abs/2411.07742v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有方法在户外环境中识别远处或被遮挡的物体时存在限制，原因是户外点云稀疏。&lt;h4&gt;目的&lt;/h4&gt;通过积累多个连续的LiDAR扫描来提高点云感知的准确性。&lt;h4&gt;方法&lt;/h4&gt;引入Gumbel Spatial Pruning (GSP)层，动态修剪冗余点，以减少计算负担。&lt;h4&gt;主要发现&lt;/h4&gt;修剪冗余点对感知准确性的影响很小，能够将LiDAR扫描次数从10次提升至40次，显著提高感知性能。&lt;h4&gt;结论&lt;/h4&gt;GSP层可无缝集成到现有点云网络架构中，且在nuScenes 3D物体检测和BEV地图分割任务中，提升了传统基线方法的性能。&lt;h4&gt;总结&lt;/h4&gt;通过动态修剪点云，解决了计算成本与感知准确性之间的矛盾，实现了更高的感知性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper studies point cloud perception within outdoor environments.Existing methods face limitations in recognizing objects located at a distanceor occluded, due to the sparse nature of outdoor point clouds. In this work, weobserve a significant mitigation of this problem by accumulating multipletemporally consecutive LiDAR sweeps, resulting in a remarkable improvement inperception accuracy. However, the computation cost also increases, hinderingprevious approaches from utilizing a large number of LiDAR sweeps. To tacklethis challenge, we find that a considerable portion of points in theaccumulated point cloud is redundant, and discarding these points has minimalimpact on perception accuracy. We introduce a simple yet effective GumbelSpatial Pruning (GSP) layer that dynamically prunes points based on a learnedend-to-end sampling. The GSP layer is decoupled from other network componentsand thus can be seamlessly integrated into existing point cloud networkarchitectures. Without incurring additional computational overhead, we increasethe number of LiDAR sweeps from 10, a common practice, to as many as 40.Consequently, there is a significant enhancement in perception performance. Forinstance, in nuScenes 3D object detection and BEV map segmentation tasks, ourpruning strategy improves the vanilla TransL baseline and other baselinemethods.</description>
      <author>example@mail.com (Jianhao Li, Tianyu Sun, Xueqian Zhang, Zhongdao Wang, Bailan Feng, Hengshuang Zhao)</author>
      <guid isPermaLink="false">2411.07742v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Neuromodulated Meta-Learning</title>
      <link>http://arxiv.org/abs/2411.06746v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类在多样环境中适应感知和行动，依赖于生物神经系统（BNS），不同任务激活不同脑区。&lt;h4&gt;目的&lt;/h4&gt;研究灵活网络结构（FNS）在元学习中的作用。&lt;h4&gt;方法&lt;/h4&gt;进行广泛的实证和理论分析，探讨模型性能与结构之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;模型性能与结构相关，不同任务没有普遍最优的模式，FNS在元学习中至关重要。&lt;h4&gt;结论&lt;/h4&gt;FNS确保元学习为每个任务生成最佳结构，从而最大化性能和学习效率。&lt;h4&gt;未来工作&lt;/h4&gt;定义、测量和建模元学习中的FNS，提出有效的FNS应具备节俭性、可塑性和敏感性。&lt;h4&gt;方法细节&lt;/h4&gt;提出三种测量方法，形成结构约束，并提出神经调制元学习（NeuronML），通过双层优化更新权重和结构。&lt;h4&gt;评估&lt;/h4&gt;广泛的理论和实证评估证明NeuronML在各种任务上的有效性。&lt;h4&gt;代码链接&lt;/h4&gt;代码公开可用，链接为：https://github.com/WangJingyao07/NeuronML&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wangjingyao07/neuronml&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans excel at adapting perceptions and actions to diverse environments,enabling efficient interaction with the external world. This adaptivecapability relies on the biological nervous system (BNS), which activatesdifferent brain regions for distinct tasks. Meta-learning similarly trainsmachines to handle multiple tasks but relies on a fixed network structure, notas flexible as BNS. To investigate the role of flexible network structure (FNS)in meta-learning, we conduct extensive empirical and theoretical analyses,finding that model performance is tied to structure, with no universallyoptimal pattern across tasks. This reveals the crucial role of FNS inmeta-learning, ensuring meta-learning to generate the optimal structure foreach task, thereby maximizing the performance and learning efficiency ofmeta-learning. Motivated by this insight, we propose to define, measure, andmodel FNS in meta-learning. First, we define that an effective FNS shouldpossess frugality, plasticity, and sensitivity. Then, to quantify FNS inpractice, we present three measurements for these properties, collectivelyforming the \emph{structure constraint} with theoretical supports. Building onthis, we finally propose Neuromodulated Meta-Learning (NeuronML) to model FNSin meta-learning. It utilizes bi-level optimization to update both weights andstructure with the structure constraint. Extensive theoretical and empiricalevaluations demonstrate the effectiveness of NeuronML on various tasks. Code ispublicly available at\href{https://github.com/WangJingyao07/NeuronML}{https://github.com/WangJingyao07/NeuronML}.</description>
      <author>example@mail.com (Jingyao Wang, Huijie Guo, Wenwen Qiang, Jiangmeng Li, Changwen Zheng, Hui Xiong, Gang Hua)</author>
      <guid isPermaLink="false">2411.06746v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>A Practical Guide to Fine-tuning Language Models with Limited Data</title>
      <link>http://arxiv.org/abs/2411.09539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预训练的大型语言模型（LLMs）在自然语言处理（NLP）中已成为标准，尽管其对数据的需求巨大。&lt;h4&gt;目的&lt;/h4&gt;调查有限数据下训练LLMs的最新迁移学习方法，以优化下游任务的模型性能。&lt;h4&gt;方法&lt;/h4&gt;讨论初始和持续预训练策略，以更好地利用未见领域和语言中的先前知识，探讨在微调和少量学习中最大化有限数据的效用。&lt;h4&gt;主要发现&lt;/h4&gt;从任务特定的角度审查适用于不同数据稀缺程度的模型和方法。&lt;h4&gt;结论&lt;/h4&gt;为实践者提供克服受限数据挑战的实用指导，并强调未来研究的有前景方向。&lt;h4&gt;总结&lt;/h4&gt;本文综述了在低资源领域和语言中应用迁移学习优化LLMs的方法，为相关研究提供了重要参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Employing pre-trained Large Language Models (LLMs) has become the de factostandard in Natural Language Processing (NLP) despite their extensive datarequirements. Motivated by the recent surge in research focused on trainingLLMs with limited data, particularly in low-resource domains and languages,this paper surveys recent transfer learning approaches to optimize modelperformance in downstream tasks where data is scarce. We first address initialand continued pre-training strategies to better leverage prior knowledge inunseen domains and languages. We then examine how to maximize the utility oflimited data during fine-tuning and few-shot learning. The final section takesa task-specific perspective, reviewing models and methods suited for differentlevels of data scarcity. Our goal is to provide practitioners with practicalguidelines for overcoming the challenges posed by constrained data while alsohighlighting promising directions for future research.</description>
      <author>example@mail.com (Márton Szép, Daniel Rueckert, Rüdiger von Eisenhart-Rothe, Florian Hinterwimmer)</author>
      <guid isPermaLink="false">2411.09539v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Software Performance Engineering for Foundation Model-Powered Software (FMware)</title>
      <link>http://arxiv.org/abs/2411.09580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）如大型语言模型（LLMs）的兴起正在改变软件开发。&lt;h4&gt;目的&lt;/h4&gt;探讨将FMware转化为生产就绪产品所需的复杂工程，特别关注性能工程。&lt;h4&gt;方法&lt;/h4&gt;基于文献调查和开发内部FMware系统的经验，识别FMware中的四个关键挑战。&lt;h4&gt;主要发现&lt;/h4&gt;FMware面临的四个主要挑战包括：认知架构设计、通信协议、调优和优化、以及部署。&lt;h4&gt;结论&lt;/h4&gt;性能工程在FMware中至关重要，避免在部署后进行代价高昂的优化。&lt;h4&gt;总结&lt;/h4&gt;持续的性能工程是防止性能下降的必要措施，强调软件性能工程（SPE）的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of Foundation Models (FMs) like Large Language Models (LLMs) isrevolutionizing software development. Despite the impressive prototypes,transforming FMware into production-ready products demands complex engineeringacross various domains. A critical but overlooked aspect is performanceengineering, which aims at ensuring FMware meets performance goals such asthroughput and latency to avoid user dissatisfaction and financial loss. Often,performance considerations are an afterthought, leading to costly optimizationefforts post-deployment. FMware's high computational resource demands highlightthe need for efficient hardware use. Continuous performance engineering isessential to prevent degradation. This paper highlights the significance ofSoftware Performance Engineering (SPE) in FMware, identifying four keychallenges: cognitive architecture design, communication protocols, tuning andoptimization, and deployment. These challenges are based on literature surveysand experiences from developing an in-house FMware system. We discuss problems,current practices, and innovative paths for the software engineering community.</description>
      <author>example@mail.com (Haoxiang Zhang, Shi Chang, Arthur Leung, Kishanthan Thangarajah, Boyuan Chen, Hanan Lutfiyya, Ahmed E. Hassan)</author>
      <guid isPermaLink="false">2411.09580v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Autoregressive Adaptive Hypergraph Transformer for Skeleton-based Activity Recognition</title>
      <link>http://arxiv.org/abs/2411.05692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;仅使用图卷积网络（GCNs）提取骨骼序列的多尺度上下文信息和高阶相关性不足以进行有效的动作分类。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型以解决现有模型在处理长距离依赖性和上下文特征方面的不足。&lt;h4&gt;方法&lt;/h4&gt;提出了自回归自适应超图变换器（AutoregAd-HGformer）模型，用于生成相位（自回归和离散）和超图（自适应）。&lt;h4&gt;主要发现&lt;/h4&gt;经过实验和消融研究，AutoregAd-HGformer模型在NTU RGB+D、NTU RGB+D 120和NW-UCLA数据集上优于现有的超图架构。&lt;h4&gt;结论&lt;/h4&gt;该模型通过强大的自回归学习先验，生成更稳健且信息丰富的表示，适用于超边形成，并能有效对齐输入的骨骼嵌入。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/rayabhisek123/autoregad-hgformer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extracting multiscale contextual information and higher-order correlationsamong skeleton sequences using Graph Convolutional Networks (GCNs) alone isinadequate for effective action classification. Hypergraph convolutionaddresses the above issues but cannot harness the long-range dependencies.Transformer proves to be effective in capturing these dependencies and makingcomplex contextual features accessible. We propose an Autoregressive AdaptiveHyperGraph Transformer (AutoregAd-HGformer) model for in-phase (autoregressiveand discrete) and out-phase (adaptive) hypergraph generation. The vectorquantized in-phase hypergraph equipped with powerful autoregressive learnedpriors produces a more robust and informative representation suitable forhyperedge formation. The out-phase hypergraph generator provides amodel-agnostic hyperedge learning technique to align the attributes with inputskeleton embedding. The hybrid (supervised and unsupervised) learning inAutoregAd-HGformer explores the action-dependent feature along spatial,temporal, and channel dimensions. The extensive experimental results andablation study indicate the superiority of our model over state-of-the-arthypergraph architectures on NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets.</description>
      <author>example@mail.com (Abhisek Ray, Ayush Raj, Maheshkumar H. Kolekar)</author>
      <guid isPermaLink="false">2411.05692v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Less is More: Unseen Domain Fake News Detection via Causal Propagation Substructures</title>
      <link>http://arxiv.org/abs/2411.09389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社交媒体上的假新闻传播对个人和社会构成重大威胁。&lt;h4&gt;目的&lt;/h4&gt;提出一种模型以应对新兴或未见领域中的假新闻检测问题。&lt;h4&gt;方法&lt;/h4&gt;引入Causal Subgraph-oriented Domain Adaptive Fake News Detection (CSDA)模型，通过提取传播图中的因果子结构，增强零样本假新闻检测能力，并使用图神经网络生成掩码来识别传播图中的关键节点和边。&lt;h4&gt;主要发现&lt;/h4&gt;CSDA模型在处理OOD假新闻检测方面表现优越，相比其他先进模型提升了7%到16%的准确率。&lt;h4&gt;结论&lt;/h4&gt;CSDA模型有效应对了假新闻检测中的OOD数据挑战，并在少量OOD数据的情况下，通过对比学习进一步提升了性能。&lt;h4&gt;总结&lt;/h4&gt;CSDA模型为假新闻检测提供了新的思路，尤其在面对未知领域的假新闻时显示出良好的适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The spread of fake news on social media poses significant threats toindividuals and society. Text-based and graph-based models have been employedfor fake news detection by analysing news content and propagation networks,showing promising results in specific scenarios. However, these data-drivenmodels heavily rely on pre-existing in-distribution data for training, limitingtheir performance when confronted with fake news from emerging or previouslyunseen domains, known as out-of-distribution (OOD) data. Tackling OOD fake newsis a challenging yet critical task. In this paper, we introduce the CausalSubgraph-oriented Domain Adaptive Fake News Detection (CSDA) model, designed toenhance zero-shot fake news detection by extracting causal substructures frompropagation graphs using in-distribution data and generalising this approach toOOD data. The model employs a graph neural network based mask generationprocess to identify dominant nodes and edges within the propagation graph,using these substructures for fake news detection. Additionally, theperformance of CSDA is further improved through contrastive learning infew-shot scenarios, where a limited amount of OOD data is available fortraining. Extensive experiments on public social media datasets demonstratethat CSDA effectively handles OOD fake news detection, achieving a 7 to 16percents accuracy improvement over other state-of-the-art models.</description>
      <author>example@mail.com (Shuzhi Gong, Richard O. Sinnott, Jianzhong Qi, Cecile Paris)</author>
      <guid isPermaLink="false">2411.09389v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Biomass phenotyping of oilseed rape through UAV multi-view oblique imaging with 3DGS and SAM model</title>
      <link>http://arxiv.org/abs/2411.08453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;油菜的生物量估算对优化作物生产力和育种策略至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究整合3D高斯点云（3DGS）和Segment Anything Model（SAM）以进行精确的3D重建和油菜生物量估算。&lt;h4&gt;方法&lt;/h4&gt;使用36个角度的无人机多视角倾斜图像进行3D重建，并利用SAM模块增强点云分割。&lt;h4&gt;主要发现&lt;/h4&gt;3DGS在7k和30k迭代下提供了高精度，峰值信噪比（PSNR）分别为27.43和29.53，训练时间分别为7分钟和49分钟，超越了结构从运动（SfM）和mipmap神经辐射场（Mip-NeRF）。SAM模块的分割准确率高，平均交并比（mIoU）为0.961，F1-score为0.980。&lt;h4&gt;结论&lt;/h4&gt;在生物量提取模型的比较中，点云体积模型最为准确，决定系数（R2）为0.976，均方根误差（RMSE）为2.92 g/plant，平均绝对百分比误差（MAPE）为6.81%，优于其他模型。本研究展示了结合3DGS与多视角无人机成像在生物量表型中的潜力。&lt;h4&gt;总结&lt;/h4&gt;该研究表明，3DGS与多视角无人机成像的结合可以显著提升油菜生物量的表型评估能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Biomass estimation of oilseed rape is crucial for optimizing cropproductivity and breeding strategies. While UAV-based imaging has advancedhigh-throughput phenotyping, current methods often rely on orthophoto images,which struggle with overlapping leaves and incomplete structural information incomplex field environments. This study integrates 3D Gaussian Splatting (3DGS)with the Segment Anything Model (SAM) for precise 3D reconstruction and biomassestimation of oilseed rape. UAV multi-view oblique images from 36 angles wereused to perform 3D reconstruction, with the SAM module enhancing point cloudsegmentation. The segmented point clouds were then converted into point cloudvolumes, which were fitted to ground-measured biomass using linear regression.The results showed that 3DGS (7k and 30k iterations) provided high accuracy,with peak signal-to-noise ratios (PSNR) of 27.43 and 29.53 and training timesof 7 and 49 minutes, respectively. This performance exceeded that of structurefrom motion (SfM) and mipmap Neural Radiance Fields (Mip-NeRF), demonstratingsuperior efficiency. The SAM module achieved high segmentation accuracy, with amean intersection over union (mIoU) of 0.961 and an F1-score of 0.980.Additionally, a comparison of biomass extraction models found the point cloudvolume model to be the most accurate, with an determination coefficient (R2) of0.976, root mean square error (RMSE) of 2.92 g/plant, and mean absolutepercentage error (MAPE) of 6.81%, outperforming both the plot crop volume andindividual crop volume models. This study highlights the potential of combining3DGS with multi-view UAV imaging for improved biomass phenotyping.</description>
      <author>example@mail.com (Yutao Shen, Hongyu Zhou, Xin Yang, Xuqi Lu, Ziyue Guo, Lixi Jiang, Yong He, Haiyan Cen)</author>
      <guid isPermaLink="false">2411.08453v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>PocoLoco: A Point Cloud Diffusion Model of Human Shape in Loose Clothing</title>
      <link>http://arxiv.org/abs/2411.04249v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;建模能够合理变形的人类虚拟角色是一个活跃的研究领域。&lt;h4&gt;目的&lt;/h4&gt;提出PocoLoco，这是第一个无模板、基于点的、姿态条件生成的3D人类模型，专注于宽松衣物的表现。&lt;h4&gt;方法&lt;/h4&gt;将虚拟角色的衣物变形视为在去噪扩散框架中的条件点云生成任务，直接在无序点云上操作，无需参数模型或衣物模板。&lt;h4&gt;主要发现&lt;/h4&gt;该方法消除了对传统建模的依赖，支持点云补全和基于姿态的编辑等多种实际应用。&lt;h4&gt;结论&lt;/h4&gt;通过发布一个包含75K点云的数据集，旨在为宽松衣物建模的挑战提供解决方案，并推动数字人类的进一步创新。&lt;h4&gt;数据集&lt;/h4&gt;发布了两个执行各种姿势的受试者的数据集，包含75K个点云。&lt;h4&gt;总结&lt;/h4&gt;PocoLoco为虚拟人类动画提供了新的方法，促进了宽松衣物的有效建模，并扩展了训练这些模型的数据资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sidsunny/pocoloco&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling a human avatar that can plausibly deform to articulations is anactive area of research. We present PocoLoco -- the first template-free,point-based, pose-conditioned generative model for 3D humans in loose clothing.We motivate our work by noting that most methods require a parametric model ofthe human body to ground pose-dependent deformations. Consequently, they arerestricted to modeling clothing that is topologically similar to the naked bodyand do not extend well to loose clothing. The few methods that attempt to modelloose clothing typically require either canonicalization or aUV-parameterization and need to address the challenging problem of explicitlyestimating correspondences for the deforming clothes. In this work, weformulate avatar clothing deformation as a conditional point-cloud generationtask within the denoising diffusion framework. Crucially, our frameworkoperates directly on unordered point clouds, eliminating the need for aparametric model or a clothing template. This also enables a variety ofpractical applications, such as point-cloud completion and pose-based editing-- important features for virtual human animation. As current datasets forhuman avatars in loose clothing are far too small for training diffusionmodels, we release a dataset of two subjects performing various poses in looseclothing with a total of 75K point clouds. By contributing towards tackling thechallenging task of effectively modeling loose clothing and expanding theavailable data for training these models, we aim to set the stage for furtherinnovation in digital humans. The source code is available athttps://github.com/sidsunny/pocoloco .</description>
      <author>example@mail.com (Siddharth Seth, Rishabh Dabral, Diogo Luvizon, Marc Habermann, Ming-Hsuan Yang, Christian Theobalt, Adam Kortylewski)</author>
      <guid isPermaLink="false">2411.04249v2</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Assessing the Performance of the DINOv2 Self-supervised Learning Vision Transformer Model for the Segmentation of the Left Atrium from MRI Images</title>
      <link>http://arxiv.org/abs/2411.09598v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, SPIE Medical Imaging, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的左心房（LA）分割对于心房颤动的诊断、治疗计划和手术干预至关重要。&lt;h4&gt;目的&lt;/h4&gt;探索DINOv2自监督学习视觉变换器在MRI图像中进行LA分割的能力。&lt;h4&gt;方法&lt;/h4&gt;利用深度学习模型进行医学图像分割，DINOv2在自然图像上训练，通过迁移学习减少对大量手动标注数据的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;DINOv2在复杂解剖结构、薄边界和有限标注数据的情况下，能够提供准确且一致的分割，平均Dice系数为0.871，Jaccard指数为0.792。&lt;h4&gt;结论&lt;/h4&gt;DINOv2在不同数据量和患者数量的少样本学习中，始终优于基线模型，表明其在MRI图像中的有效适应性，展现了作为分割工具的潜力。&lt;h4&gt;总结&lt;/h4&gt;DINOv2在医学成像中的应用前景广阔，值得在更广泛的领域中推广和使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate left atrium (LA) segmentation from pre-operative scans is crucialfor diagnosing atrial fibrillation, treatment planning, and supporting surgicalinterventions. While deep learning models are key in medical imagesegmentation, they often require extensive manually annotated data. Foundationmodels trained on larger datasets have reduced this dependency, enhancinggeneralizability and robustness through transfer learning. We explore DINOv2, aself-supervised learning vision transformer trained on natural images, for LAsegmentation using MRI. The challenges for LA's complex anatomy, thinboundaries, and limited annotated data make accurate segmentation difficultbefore &amp; during the image-guided intervention. We demonstrate DINOv2's abilityto provide accurate &amp; consistent segmentation, achieving a mean Dice score of.871 &amp; a Jaccard Index of .792 for end-to-end fine-tuning. Through few-shotlearning across various data sizes &amp; patient counts, DINOv2 consistentlyoutperforms baseline models. These results suggest that DINOv2 effectivelyadapts to MRI with limited data, highlighting its potential as a competitivetool for segmentation &amp; encouraging broader use in medical imaging.</description>
      <author>example@mail.com (Bipasha Kundu, Bidur Khanal, Richard Simon, Cristian A. Linte)</author>
      <guid isPermaLink="false">2411.09598v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>ASTD Patterns for Integrated Continuous Anomaly Detection In Data Logs</title>
      <link>http://arxiv.org/abs/2411.07272v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文研究ASTD语言在数据日志中的集成异常检测应用。&lt;h4&gt;目的&lt;/h4&gt;探讨在数据流中使用ASTD语言进行有效的异常检测。&lt;h4&gt;方法&lt;/h4&gt;采用滑动窗口技术进行持续学习，并在每个窗口完成后更新学习模型，以保持检测的准确性并与当前数据趋势对齐。&lt;h4&gt;主要发现&lt;/h4&gt;提出了ASTD模式用于组合学习模型，特别是在无监督学习的背景下，常用于数据流。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的ASTD运算符——量化流，能够无缝结合学习模型，同时保持规范简洁。&lt;h4&gt;贡献&lt;/h4&gt;提供了一种规范模式，强调ASTD在抽象和模块化异常检测系统方面的能力。&lt;h4&gt;设计简化&lt;/h4&gt;ASTD语言通过图形化表示语言运算符，简化了开发者的设计任务，让他们专注于定义系统的功能操作。&lt;h4&gt;总结&lt;/h4&gt;ASTD语言为数据流异常检测系统的发展提供了独特的方法，结合过程的方式提升了系统设计的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the use of the ASTD language for ensemble anomalydetection in data logs. It uses a sliding window technique for continuouslearning in data streams, coupled with updating learning models upon thecompletion of each window to maintain accurate detection and align with currentdata trends. It proposes ASTD patterns for combining learning models,especially in the context of unsupervised learning, which is commonly used fordata streams. To facilitate this, a new ASTD operator is proposed, theQuantified Flow, which enables the seamless combination of learning modelswhile ensuring that the specification remains concise. Our contribution is aspecification pattern, highlighting the capacity of ASTDs to abstract andmodularize anomaly detection systems. The ASTD language provides a uniqueapproach to develop data flow anomaly detection systems, grounded in thecombination of processes through the graphical representation of the languageoperators. This simplifies the design task for developers, who can focusprimarily on defining the functional operations that constitute the system.</description>
      <author>example@mail.com (Chaymae El Jabri, Marc Frappier, Pierre-Martin Tardif)</author>
      <guid isPermaLink="false">2411.07272v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Object Detection using Depth and Image Data for Manufacturing Parts</title>
      <link>http://arxiv.org/abs/2411.09062v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;制造业需要可靠的目标检测方法，以精确挑选和处理各种制造零件和组件。&lt;h4&gt;目的&lt;/h4&gt;解决传统目标检测方法在使用2D图像和3D数据时的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出一种多传感器系统，结合RGB摄像头和3D点云传感器，并进行精确校准以对齐多模态数据，开发基于Faster R-CNN的多模态目标检测方法。&lt;h4&gt;主要发现&lt;/h4&gt;多模态模型在目标检测指标上显著优于深度单一和RGB单一基线，mAP提升13%，均值精度提升11.8%；与深度单一基线相比，mAP提升78%，均值精度提升57%。&lt;h4&gt;结论&lt;/h4&gt;该方法为智能制造应用提供了更可靠和更稳健的目标检测能力。&lt;h4&gt;总结&lt;/h4&gt;通过结合RGB和3D数据，提升了制造业中目标检测的性能和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Manufacturing requires reliable object detection methods for precise pickingand handling of diverse types of manufacturing parts and components.Traditional object detection methods utilize either only 2D images from camerasor 3D data from lidars or similar 3D sensors. However, each of these sensorshave weaknesses and limitations. Cameras do not have depth perception and 3Dsensors typically do not carry color information. These weaknesses canundermine the reliability and robustness of industrial manufacturing systems.To address these challenges, this work proposes a multi-sensor system combiningan red-green-blue (RGB) camera and a 3D point cloud sensor. The two sensors arecalibrated for precise alignment of the multimodal data captured from the twohardware devices. A novel multimodal object detection method is developed toprocess both RGB and depth data. This object detector is based on the FasterR-CNN baseline that was originally designed to process only camera images. Theresults show that the multimodal model significantly outperforms the depth-onlyand RGB-only baselines on established object detection metrics. Morespecifically, the multimodal model improves mAP by 13% and raises MeanPrecision by 11.8% in comparison to the RGB-only baseline. Compared to thedepth-only baseline, it improves mAP by 78% and raises Mean Precision by 57%.Hence, this method facilitates more reliable and robust object detection inservice to smart manufacturing applications.</description>
      <author>example@mail.com (Nazanin Mahjourian, Vinh Nguyen)</author>
      <guid isPermaLink="false">2411.09062v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks and Differential Equations: A hybrid approach for data assimilation of fluid flows</title>
      <link>http://arxiv.org/abs/2411.09476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的基于数据的神经网络模型在流体动力学应用中难以保持物理一致性，并且通常需要大量数据才能获得可靠的性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的混合方法，将图神经网络（GNN）与雷诺平均纳维-斯托克斯（RANS）方程结合，以提高均匀流重建的准确性。&lt;h4&gt;方法&lt;/h4&gt;将GNN框架与RANS方程集成，利用伴随方法，在GNN训练过程中使用RANS衍生的梯度作为优化项，以确保学习的模型符合物理规律。&lt;h4&gt;主要发现&lt;/h4&gt;在多个计算流体动力学场景中测试该方法，结果显示与纯数据驱动模型相比，重建的均匀流的准确性显著提高，且使用的训练数据量有限。&lt;h4&gt;结论&lt;/h4&gt;本研究的关键优势在于将物理定律整合到GNN的训练过程中，能够在数据稀缺的情况下实现高精度预测，特别适用于流体动力学应用。&lt;h4&gt;总结&lt;/h4&gt;这种方法在流体动力学中具有重要价值，能有效提高模型性能，同时减少对大量数据的依赖。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study presents a novel hybrid approach that combines Graph NeuralNetworks (GNNs) with Reynolds-Averaged Navier Stokes (RANS) equations toenhance the accuracy of mean flow reconstruction across a range of fluiddynamics applications. Traditional purely data-driven Neural Networks (NNs)models, often struggle maintaining physical consistency. Moreover, theytypically require large datasets to achieve reliable performances. The GNNframework, which naturally handles unstructured data such as complex geometriesin Computational Fluid Dynamics (CFD), is here integrated with RANS equationsas a physical baseline model. The methodology leverages the adjoint method,enabling the use of RANS-derived gradients as optimization terms in the GNNtraining process. This ensures that the learned model adheres to the governingphysics, maintaining physical consistency while improving the predictionaccuracy. We test our approach on multiple CFD scenarios, including casesinvolving generalization with respect to the Reynolds number, sparsemeasurements, denoising and inpainting of missing portions of the mean flow.The results demonstrate significant improvements in the accuracy of thereconstructed mean flow compared to purely data-driven models, using limitedamounts of data in the training dataset. The key strengths of this study arethe integration of physical laws into the training process of the GNN, and theability to achieve high-accuracy predictions with a limited amount of data,making this approach particularly valuable for applications in fluid dynamicswhere data is often scarce.</description>
      <author>example@mail.com (M. Quattromini, M. A. Bucci, S. Cherubini, O. Semeraro)</author>
      <guid isPermaLink="false">2411.09476v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>SmartInv: Multimodal Learning for Smart Contract Invariant Inference</title>
      <link>http://arxiv.org/abs/2411.09217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能合约是支持区块链上各种商业活动的软件程序，但存在新的“机器无法审计”的漏洞。&lt;h4&gt;目的&lt;/h4&gt;自动检测智能合约中的“机器无法审计”漏洞。&lt;h4&gt;方法&lt;/h4&gt;提出SmartInv框架，通过理解和推理多模态信息（如源代码和自然语言）生成不变量，并检测其违反情况。&lt;h4&gt;主要发现&lt;/h4&gt;SmartInv在真实合约上评估，重新发现了过去2.5年导致数百万美元损失的漏洞，生成的关键不变量比现有工具多3.5倍，检测到的关键漏洞比现有工具多4倍，并且所需时间显著减少（150倍）。&lt;h4&gt;结论&lt;/h4&gt;SmartInv从89621个真实合约中发现了119个零日漏洞，其中五个被开发者确认是“高严重性”的关键零日漏洞。&lt;h4&gt;总结&lt;/h4&gt;SmartInv提供了一种高效准确的方式来识别和解决智能合约中的重大安全漏洞。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smart contracts are software programs that enable diverse business activitieson the blockchain. Recent research has identified new classes of "machineun-auditable" bugs that arise from both transactional contexts and source code.Existing detection methods require human understanding of underlyingtransaction logic and manual reasoning across different sources of context(i.e. modalities), such as code, dynamic transaction executions, and naturallanguage specifying the expected transaction behavior.  To automate the detection of ``machine un-auditable'' bugs, we presentSmartInv, an accurate and fast smart contract invariant inference framework.Our key insight is that the expected behavior of smart contracts, as specifiedby invariants, relies on understanding and reasoning across multimodalinformation, such as source code and natural language. We propose a newprompting strategy to foundation models, Tier of Thought (ToT), to reasonacross multiple modalities of smart contracts and ultimately to generateinvariants. By checking the violation of these generated invariants, SmartInvcan identify potential vulnerabilities.  We evaluate SmartInv on real-world contracts and re-discover bugs thatresulted in multi-million dollar losses over the past 2.5 years (from January1, 2021 to May 31, 2023). Our extensive evaluation shows that SmartInvgenerates (3.5X) more bug-critical invariants and detects (4$\times$) morecritical bugs compared to the state-of-the-art tools in significantly (150X)less time. \sys uncovers 119 zero-day vulnerabilities from the 89,621real-world contracts. Among them, five are critical zero-day bugs confirmed bydevelopers as ``high severity.''</description>
      <author>example@mail.com (Sally Junsong Wang, Kexin Pei, Junfeng Yang)</author>
      <guid isPermaLink="false">2411.09217v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>On the Surprising Effectiveness of Attention Transfer for Vision Transformers</title>
      <link>http://arxiv.org/abs/2411.09702v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024. Code:
  https://github.com/alexlioralexli/attention-transfer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统观点认为，预训练视觉变换器（ViT）通过学习有用的表示来提高下游性能。&lt;h4&gt;目的&lt;/h4&gt;探讨预训练是否真的对下游性能至关重要。&lt;h4&gt;方法&lt;/h4&gt;引入一种名为注意力转移的方法，仅使用预训练教师ViT的注意力模式来指导学生模型的学习。&lt;h4&gt;主要发现&lt;/h4&gt;仅凭注意力模式，模型能够从零开始学习高质量特征并实现可比的下游性能。&lt;h4&gt;结论&lt;/h4&gt;注意力转移使学生模型能够学习自身特征，并与微调后的教师模型结合时进一步提高精度。&lt;h4&gt;研究内容&lt;/h4&gt;系统研究了注意力图的充分性，特别是在分布偏移设置下的表现。&lt;h4&gt;总结&lt;/h4&gt;我们的探索提供了对预训练作用的更好理解，并提出了微调的有效替代方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional wisdom suggests that pre-training Vision Transformers (ViT)improves downstream performance by learning useful representations. Is thisactually true? We investigate this question and find that the features andrepresentations learned during pre-training are not essential. Surprisingly,using only the attention patterns from pre-training (i.e., guiding howinformation flows between tokens) is sufficient for models to learn highquality features from scratch and achieve comparable downstream performance. Weshow this by introducing a simple method called attention transfer, where onlythe attention patterns from a pre-trained teacher ViT are transferred to astudent, either by copying or distilling the attention maps. Since attentiontransfer lets the student learn its own features, ensembling it with afine-tuned teacher also further improves accuracy on ImageNet. Wesystematically study various aspects of our findings on the sufficiency ofattention maps, including distribution shift settings where they underperformfine-tuning. We hope our exploration provides a better understanding of whatpre-training accomplishes and leads to a useful alternative to the standardpractice of fine-tuning</description>
      <author>example@mail.com (Alexander C. Li, Yuandong Tian, Beidi Chen, Deepak Pathak, Xinlei Chen)</author>
      <guid isPermaLink="false">2411.09702v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Long-Tailed Object Detection Pre-training: Dynamic Rebalancing Contrastive Learning with Dual Reconstruction</title>
      <link>http://arxiv.org/abs/2411.09453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预训练在各种视觉任务中（如物体识别和检测）起着重要作用，现有的预训练方法在处理长尾分布时效果不佳，尤其是在检测任务中，存在数据不平衡和简单性偏见的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的针对物体检测的预训练框架，称为动态重平衡对比学习与双重重建（2DRCL）。&lt;h4&gt;方法&lt;/h4&gt;该方法基于整体-局部对比学习机制，结合全局语义和局部模式，设计动态重平衡策略以调整预训练过程中对低频实例的采样，同时通过双重重建任务解决简单性偏见问题。&lt;h4&gt;主要发现&lt;/h4&gt;在COCO和LVIS v1.0数据集上的实验表明，该方法在提高低频类的mAP/AP得分方面效果显著。&lt;h4&gt;结论&lt;/h4&gt;动态重平衡对比学习与双重重建方法能有效提高物体检测任务中长尾类的表现，弥补了传统预训练方法的不足。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的2DRCL方法通过动态重平衡和双重重建，解决了长尾数据的不平衡和简单性偏见问题，展示了其在物体检测中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-training plays a vital role in various vision tasks, such as objectrecognition and detection. Commonly used pre-training methods, which typicallyrely on randomized approaches like uniform or Gaussian distributions toinitialize model parameters, often fall short when confronted with long-taileddistributions, especially in detection tasks. This is largely due to extremedata imbalance and the issue of simplicity bias. In this paper, we introduce anovel pre-training framework for object detection, called Dynamic RebalancingContrastive Learning with Dual Reconstruction (2DRCL). Our method builds on aHolistic-Local Contrastive Learning mechanism, which aligns pre-training withobject detection by capturing both global contextual semantics and detailedlocal patterns. To tackle the imbalance inherent in long-tailed data, we designa dynamic rebalancing strategy that adjusts the sampling of underrepresentedinstances throughout the pre-training process, ensuring better representationof tail classes. Moreover, Dual Reconstruction addresses simplicity bias byenforcing a reconstruction task aligned with the self-consistency principle,specifically benefiting underrepresented tail classes. Experiments on COCO andLVIS v1.0 datasets demonstrate the effectiveness of our method, particularly inimproving the mAP/AP scores for tail classes.</description>
      <author>example@mail.com (Chen-Long Duan, Yong Li, Xiu-Shen Wei, Lin Zhao)</author>
      <guid isPermaLink="false">2411.09453v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>3D Focusing-and-Matching Network for Multi-Instance Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2411.07740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多实例点云配准旨在估计模型点云在整个场景中的所有实例的姿态。&lt;h4&gt;目的&lt;/h4&gt;解决由于场景中物体杂乱和遮挡导致的模型点云与场景中所有实例之间难以获得精确对应的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种简单而强大的3D聚焦与匹配网络，通过学习多个成对点云配准来进行多实例点云配准。首先引入3D多对象聚焦模块以定位每个物体的中心并生成物体提案，利用自注意力和交叉注意力关联模型点云与结构相似的物体，回归物体中心以定位潜在匹配实例。接着，提出3D双重掩膜实例匹配模块来估计模型点云与每个物体提案之间的姿态，使用实例掩膜和重叠掩膜精确预测成对对应。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公共基准数据集Scan2CAD和ROBI上的广泛实验表明，该方法在多实例点云配准任务上达到了新的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;该方法有效解决了多实例点云配准中的对应问题，展示了其在复杂场景中的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;提出的3D聚焦与匹配网络为多实例点云配准提供了一种有效的解决方案，具有较好的实验表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-instance point cloud registration aims to estimate the pose of allinstances of a model point cloud in the whole scene. Existing methods all adoptthe strategy of first obtaining the global correspondence and then clusteringto obtain the pose of each instance. However, due to the cluttered and occludedobjects in the scene, it is difficult to obtain an accurate correspondencebetween the model point cloud and all instances in the scene. To this end, wepropose a simple yet powerful 3D focusing-and-matching network formulti-instance point cloud registration by learning the multiple pair-wisepoint cloud registration. Specifically, we first present a 3D multi-objectfocusing module to locate the center of each object and generate objectproposals. By using self-attention and cross-attention to associate the modelpoint cloud with structurally similar objects, we can locate potential matchinginstances by regressing object centers. Then, we propose a 3D dual maskinginstance matching module to estimate the pose between the model point cloud andeach object proposal. It performs instance mask and overlap mask masks toaccurately predict the pair-wise correspondence. Extensive experiments on twopublic benchmarks, Scan2CAD and ROBI, show that our method achieves a newstate-of-the-art performance on the multi-instance point cloud registrationtask. Code is available at https://github.com/zlynpu/3DFMNet.</description>
      <author>example@mail.com (Liyuan Zhang, Le Hui, Qi Liu, Bo Li, Yuchao Dai)</author>
      <guid isPermaLink="false">2411.07740v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>V2X-R: Cooperative LiDAR-4D Radar Fusion for 3D Object Detection with Denoising Diffusion</title>
      <link>http://arxiv.org/abs/2411.08402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的车辆与一切(V2X)系统通过LiDAR和相机数据显著提升了3D物体检测能力，但在恶劣天气条件下性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法应对恶劣天气对3D物体检测的影响。&lt;h4&gt;方法&lt;/h4&gt;推出V2X-R数据集，结合LiDAR、相机和4D雷达，并提出一种新的合作LiDAR-4D雷达融合管道，实施多种融合策略。&lt;h4&gt;主要发现&lt;/h4&gt;在V2X-R数据集中，LiDAR-4D雷达融合管道表现优越，MDD模块在雾天和雪天条件下进一步提升基本融合模型性能。&lt;h4&gt;结论&lt;/h4&gt;MDD模块在不影响正常性能的情况下，分别提高了5.73%和6.70%的检测性能，数据集和代码将公开发布。&lt;h4&gt;总结&lt;/h4&gt;研究表明，结合4D雷达和LiDAR可以有效提升恶劣天气下的3D物体检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ylwhxht/v2x-r&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current Vehicle-to-Everything (V2X) systems have significantly enhanced 3Dobject detection using LiDAR and camera data. However, these methods sufferfrom performance degradation in adverse weather conditions. The weatherrobust4D radar provides Doppler and additional geometric information, raising thepossibility of addressing this challenge. To this end, we present V2X-R, thefirst simulated V2X dataset incorporating LiDAR, camera, and 4D radar. V2X-Rcontains 12,079 scenarios with 37,727 frames of LiDAR and 4D radar pointclouds, 150,908 images, and 170,859 annotated 3D vehicle bounding boxes.Subsequently, we propose a novel cooperative LiDAR-4D radar fusion pipeline for3D object detection and implement it with various fusion strategies. To achieveweather-robust detection, we additionally propose a Multi-modal DenoisingDiffusion (MDD) module in our fusion pipeline. MDD utilizes weather-robust 4Dradar feature as a condition to prompt the diffusion model to denoise noisyLiDAR features. Experiments show that our LiDAR-4D radar fusion pipelinedemonstrates superior performance in the V2X-R dataset. Over and above this,our MDD module further improved the performance of basic fusion model by up to5.73%/6.70% in foggy/snowy conditions with barely disrupting normalperformance. The dataset and code will be publicly available at:https://github.com/ylwhxht/V2X-R.</description>
      <author>example@mail.com (Xun Huang, Jinlong Wang, Qiming Xia, Siheng Chen, Bisheng Yang, Cheng Wang, Chenglu Wen)</author>
      <guid isPermaLink="false">2411.08402v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>T2-Only Prostate Cancer Prediction by Meta-Learning from Bi-Parametric MR Imaging</title>
      <link>http://arxiv.org/abs/2411.07416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/wxyi057/MetaT2&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的前列腺癌影像诊断需要使用MR T2加权和扩散加权成像序列，且使用额外序列可以提高准确性。&lt;h4&gt;目的&lt;/h4&gt;研究仅使用T2加权序列作为输入的机器学习方法在前列腺癌诊断中的潜力。&lt;h4&gt;方法&lt;/h4&gt;探讨T2单独方法的技术可行性，提出一种新的机器学习模型，仅在推理时使用T2序列，而扩散加权序列用于训练元学习模型。&lt;h4&gt;主要发现&lt;/h4&gt;在超过3000名前列腺癌患者的数据集上，使用T2单独模型的定位性能优于或可与使用T2或两种序列作为输入的替代模型相媲美。&lt;h4&gt;结论&lt;/h4&gt;首次展示了不同输入序列模型的真正阳性病例，证明了仅使用T2序列的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，T2加权成像可独立用于前列腺癌的诊断，并且能够达到与传统方法相似的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wxyi057/metat2&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current imaging-based prostate cancer diagnosis requires both MR T2-weighted(T2w) and diffusion-weighted imaging (DWI) sequences, with additional sequencesfor potentially greater accuracy improvement. However, measuring diffusionpatterns in DWI sequences can be time-consuming, prone to artifacts andsensitive to imaging parameters. While machine learning (ML) models havedemonstrated radiologist-level accuracy in detecting prostate cancer from thesetwo sequences, this study investigates the potential of ML-enabled methodsusing only the T2w sequence as input during inference time. We first discussthe technical feasibility of such a T2-only approach, and then propose a novelML formulation, where DWI sequences - readily available for training purposes -are only used to train a meta-learning model, which subsequently only uses T2wsequences at inference. Using multiple datasets from more than 3,000 prostatecancer patients, we report superior or comparable performance in localisingradiologist-identified prostate cancer using our proposed T2-only models,compared with alternative models using T2-only or both sequences as input. Realpatient cases are presented and discussed to demonstrate, for the first time,the exclusively true-positive cases from models with different input sequences.</description>
      <author>example@mail.com (Weixi Yi, Yipei Wang, Natasha Thorley, Alexander Ng, Shonit Punwani, Veeru Kasivisvanathan, Dean C. Barratt, Shaheer Ullah Saeed, Yipeng Hu)</author>
      <guid isPermaLink="false">2411.07416v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Methodology for a Statistical Analysis of Influencing Factors on 3D Object Detection Performance</title>
      <link>http://arxiv.org/abs/2411.08482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶中，物体检测是通过定位和分类物体来感知环境的重要任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，对与物体检测及环境相关的各种因素对检测性能的影响进行统计分析。&lt;h4&gt;方法&lt;/h4&gt;进行单变量分析，比较每个因素与检测误差的关系，同时分析影响因素的依赖性和相互依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;识别影响检测性能的因素有助于发现训练物体检测器的鲁棒性问题。&lt;h4&gt;结论&lt;/h4&gt;了解影响检测性能的因素支持物体检测系统的安全认证。&lt;h4&gt;总结&lt;/h4&gt;通过统计分析，提升了对自动驾驶物体检测系统安全性的理解和保障。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In autonomous driving, object detection is an essential task to perceive theenvironment by localizing and classifying objects. Most object detectionalgorithms rely on deep learning for their superior performance. However, theirblack box nature makes it challenging to ensure safety. In this paper, wepropose a first-of-its-kind methodology for statistical analysis of theinfluence of various factors related to the objects to detect or theenvironment on the detection performance of both LiDAR- and camera-based 3Dobject detectors. We perform a univariate analysis between each of the factorsand the detection error in order to compare the strength of influence. Tobetter identify potential sources of detection errors, we also analyze theperformance in dependency of the influencing factors and examine theinterdependencies between the different influencing factors. Recognizing thefactors that influence detection performance helps identify robustness issuesin the trained object detector and supports the safety approval of objectdetection systems.</description>
      <author>example@mail.com (Anton Kuznietsov, Dirk Schweickard, Steven Peters)</author>
      <guid isPermaLink="false">2411.08482v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Meta-Learning for Robust Deepfake Detection: A Multi-Agent Framework to Data Drift and Model Generalization</title>
      <link>http://arxiv.org/abs/2411.08148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能，尤其是生成式AI的发展，带来了内容创作的重大可能性，但也导致了广泛的虚假信息和错误内容。&lt;h4&gt;目的&lt;/h4&gt;探讨深度伪造技术带来的隐私侵犯和身份盗窃问题，以及其对社会和商业的影响。&lt;h4&gt;方法&lt;/h4&gt;提出一种对抗性元学习算法，结合任务特定的自适应样本合成和一致性正则化，以提高模型的鲁棒性和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;模型在不同数据集上表现一致，优于现有的深度伪造检测模型。&lt;h4&gt;结论&lt;/h4&gt;提出的框架整合了元学习算法与层次多代理检索增强生成工作流，为提高泛化能力、鲁棒性和适应性提供了整体解决方案。&lt;h4&gt;挑战&lt;/h4&gt;深伪检测器面临缺乏对未见场景的泛化能力和对抗鲁棒性等三大挑战。&lt;h4&gt;总结&lt;/h4&gt;本研究为解决深度伪造问题提供了一种新的方法，有助于提升检测器在实际应用中的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pioneering advancements in artificial intelligence, especially in genAI, haveenabled significant possibilities for content creation, but also led towidespread misinformation and false content. The growing sophistication andrealism of deepfakes is raising concerns about privacy invasion, identitytheft, and has societal, business impacts, including reputational damage andfinancial loss. Many deepfake detectors have been developed to tackle thisproblem. Nevertheless, as for every AI model, the deepfake detectors face thewrath of lack of considerable generalization to unseen scenarios andcross-domain deepfakes. Besides, adversarial robustness is another criticalchallenge, as detectors drastically underperform to the slightest imperceptiblechange. Most state-of-the-art detectors are trained on static datasets and lackthe ability to adapt to emerging deepfake attack trends. These three crucialchallenges though hold paramount importance for reliability in practise,particularly in the deepfake domain, are also the problems with any other AIapplication. This paper proposes an adversarial meta-learning algorithm usingtask-specific adaptive sample synthesis and consistency regularization, in arefinement phase. By focussing on the classifier's strengths and weaknesses, itboosts both robustness and generalization of the model. Additionally, the paperintroduces a hierarchical multi-agent retrieval-augmented generation workflowwith a sample synthesis module to dynamically adapt the model to new datatrends by generating custom deepfake samples. The paper further presents aframework integrating the meta-learning algorithm with the hierarchicalmulti-agent workflow, offering a holistic solution for enhancinggeneralization, robustness, and adaptability. Experimental results demonstratethe model's consistent performance across various datasets, outperforming themodels in comparison.</description>
      <author>example@mail.com (Dinesh Srivasthav P, Badri Narayan Subudhi)</author>
      <guid isPermaLink="false">2411.08148v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
    <item>
      <title>DyGASR: Dynamic Generalized Exponential Splatting with Surface Alignment for Accelerated 3D Mesh Reconstruction</title>
      <link>http://arxiv.org/abs/2411.09156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting (3DGS)的最新进展提高了新视图合成和渲染速度，但从大量小型3D高斯点提取网格仍然面临挑战。&lt;h4&gt;目的&lt;/h4&gt;解决由于高斯点数量庞大和低通特性导致的锐利信号表示困难的问题。&lt;h4&gt;方法&lt;/h4&gt;提出DyGASR，使用广义指数函数替代传统3D高斯，以减少粒子数量并动态优化捕获信号的表示，并引入广义表面正则化(GSR)以确保点云法线与表面垂直。&lt;h4&gt;主要发现&lt;/h4&gt;使用广义指数喷涂(GES)重建网格时常常失败，因此需要对其进行调整，GSR方法有效解决了这一问题。动态分辨率调整策略通过余弦调度逐步提高训练阶段的图像分辨率。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个场景数据集上的评估表明，其速度提高了25%，内存使用降低了30%，超越了现有的3DGS基础网格重建方法。&lt;h4&gt;总结&lt;/h4&gt;DyGASR方法有效解决了3D高斯点网格重建中的挑战，显著提升了重建速度和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-11-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in 3D Gaussian Splatting (3DGS), which lead tohigh-quality novel view synthesis and accelerated rendering, have remarkablyimproved the quality of radiance field reconstruction. However, the extractionof mesh from a massive number of minute 3D Gaussian points remains greatchallenge due to the large volume of Gaussians and difficulty of representationof sharp signals caused by their inherent low-pass characteristics. To addressthis issue, we propose DyGASR, which utilizes generalized exponential functioninstead of traditional 3D Gaussian to decrease the number of particles anddynamically optimize the representation of the captured signal. In addition, itis observed that reconstructing mesh with Generalized ExponentialSplatting(GES) without modifications frequently leads to failures since thegeneralized exponential distribution centroids may not precisely align with thescene surface. To overcome this, we adopt Sugar's approach and introduceGeneralized Surface Regularization (GSR), which reduces the smallest scalingvector of each point cloud to zero and ensures normal alignment perpendicularto the surface, facilitating subsequent Poisson surface mesh reconstruction.Additionally, we propose a dynamic resolution adjustment strategy that utilizesa cosine schedule to gradually increase image resolution from low to highduring the training stage, thus avoiding constant full resolution, whichsignificantly boosts the reconstruction speed. Our approach surpasses existing3DGS-based mesh reconstruction methods, as evidenced by extensive evaluationson various scene datasets, demonstrating a 25\% increase in speed, and a 30\%reduction in memory usage.</description>
      <author>example@mail.com (Shengchao Zhao, Yundong Li)</author>
      <guid isPermaLink="false">2411.09156v1</guid>
      <pubDate>Mon, 02 Dec 2024 10:53:52 +0800</pubDate>
    </item>
  </channel>
</rss>