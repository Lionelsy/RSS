<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 08 Nov 2024 23:20:58 +0800</lastBuildDate>
    <item>
      <title>Advanced Cyberattack Detection in Internet of Medical Things (IoMT) Using Convolutional Neural Networks</title>
      <link>http://arxiv.org/abs/2410.23306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 figures, Accepted at Iranian Conference on Intelligent
  Systems (ICIS) 23-24 October, 2024, Sirjan University of Technology, Sirjan,
  Kerman, Iran. \c{opyright} 2024 IEEE. Personal use of this material is
  permitted. The accepted version is shared here. For the final published
  version, refer to the IEEE Xplore Digital Library&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;互联网医疗物联网（IoMT）的日益整合提升了患者护理，但也带来了关键的网络安全挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于卷积神经网络（CNN）的新方法，用于检测IoMT环境中的网络攻击。&lt;h4&gt;方法&lt;/h4&gt;该模型利用CNN的能力，有效分析网络流量数据的时间特征，训练和评估于CICIoMT2024数据集。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的CNN模型在二分类、分类和多分类任务中表现优异，准确率达到99%，超越了传统机器学习模型和更简单的深度神经网络。&lt;h4&gt;结论&lt;/h4&gt;CNN在提升IoMT网络安全性方面具有显著潜力，有助于保护和维护连接的医疗系统的完整性。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了深度学习在网络安全领域的应用前景，为IoMT的保护提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/alirezamohamadiam/Advanced-Cyberattack-Detection-in-IoMT-Using-CNN&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing integration of the Internet of Medical Things (IoMT) intohealthcare systems has significantly enhanced patient care but has alsointroduced critical cybersecurity challenges. This paper presents a novelapproach based on Convolutional Neural Networks (CNNs) for detectingcyberattacks within IoMT environments. Unlike previous studies thatpredominantly utilized traditional machine learning (ML) models or simpler DeepNeural Networks (DNNs), the proposed model leverages the capabilities of CNNsto effectively analyze the temporal characteristics of network traffic data.Trained and evaluated on the CICIoMT2024 dataset, which comprises 18 distincttypes of cyberattacks across a range of IoMT devices, the proposed CNN modeldemonstrates superior performance compared to previous state-of-the-artmethods, achieving a perfect accuracy of 99% in binary, categorical, andmulticlass classification tasks. This performance surpasses that ofconventional ML models such as Logistic Regression, AdaBoost, DNNs, and RandomForests. These findings highlight the potential of CNNs to substantiallyimprove IoMT cybersecurity, thereby ensuring the protection and integrity ofconnected healthcare systems.</description>
      <author>example@mail.com (Alireza Mohammadi, Hosna Ghahramani, Seyyed Amir Asghari, Mehdi Aminian)</author>
      <guid isPermaLink="false">2410.23306v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Tiny Learning-Based MPC for Multirotors: Solver-Aware Learning for Efficient Embedded Predictive Control</title>
      <link>http://arxiv.org/abs/2410.23634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;微型无人机在环境监测和搜索救援等应用中展现出潜力，但由于计算能力有限和动态复杂，控制面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种适用于资源受限的微型多旋翼平台的学习型模型预测控制框架。&lt;h4&gt;方法&lt;/h4&gt;引入Tiny Learning-Based Model Predictive Control (LB MPC)，通过利用多旋翼动力学结构和开发高效求解器，实现100 Hz的高频控制。&lt;h4&gt;主要发现&lt;/h4&gt;在Crazyflie 2.1与Teensy 4.0微控制器上，LB MPC相比现有嵌入式MPC方法，跟踪性能平均提高23%。&lt;h4&gt;结论&lt;/h4&gt;实现了学习型MPC在微型多旋翼上的首次机载实施，重量仅为53克。&lt;h4&gt;总结&lt;/h4&gt;本研究为微型无人机的控制提供了一种高效的解决方案，优化了资源利用和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tiny aerial robots show promise for applications like environmentalmonitoring and search-and-rescue but face challenges in control due to theirlimited computing power and complex dynamics. Model Predictive Control (MPC)can achieve agile trajectory tracking and handle constraints. Although currentlearning-based MPC methods, such as Gaussian Process (GP) MPC, improve controlperformance by learning residual dynamics, they are computationally demanding,limiting their onboard application on tiny robots. This paper introduces TinyLearning-Based Model Predictive Control (LB MPC), a novel framework forresource-constrained micro multirotor platforms. By exploiting multirotordynamics' structure and developing an efficient solver, our approach enableshigh-rate control at 100 Hz on a Crazyflie 2.1 with a Teensy 4.0microcontroller. We demonstrate a 23\% average improvement in trackingperformance over existing embedded MPC methods, achieving the first onboardimplementation of learning-based MPC on a tiny multirotor (53 g).</description>
      <author>example@mail.com (Babak Akbari, Justin Frank, Melissa Greeff)</author>
      <guid isPermaLink="false">2410.23634v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>SuctionPrompt: Visual-assisted Robotic Picking with a Suction Cup Using Vision-Language Models and Facile Hardware Design</title>
      <link>http://arxiv.org/abs/2410.23640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型和视觉语言模型的开发促进了机器人系统在各个领域的应用。&lt;h4&gt;目的&lt;/h4&gt;研究如何有效地将这些模型整合到实际的机器人任务中。&lt;h4&gt;方法&lt;/h4&gt;开发了一种名为SuctionPrompt的多功能机器人系统，结合了VLM的提示技术和3D检测，用于在多变环境中执行产品拣选任务。&lt;h4&gt;主要发现&lt;/h4&gt;系统在验证实验中准确选择吸取点的成功率为75.4%，在拣选常见物品时成功率为65.0%。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了视觉语言模型在机器人操作任务中的有效性，即便是在简单的3D处理情况下。&lt;h4&gt;总结&lt;/h4&gt;通过结合3D空间信息和自适应行动规划，SuctionPrompt系统能够在新环境中有效接近和操控物体。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of large language models and vision-language models (VLMs)has resulted in the increasing use of robotic systems in various fields.However, the effective integration of these models into real-world robotictasks is a key challenge. We developed a versatile robotic system calledSuctionPrompt that utilizes prompting techniques of VLMs combined with 3Ddetections to perform product-picking tasks in diverse and dynamicenvironments. Our method highlights the importance of integrating 3D spatialinformation with adaptive action planning to enable robots to approach andmanipulate objects in novel environments. In the validation experiments, thesystem accurately selected suction points 75.4%, and achieved a 65.0% successrate in picking common items. This study highlights the effectiveness of VLMsin robotic manipulation tasks, even with simple 3D processing.</description>
      <author>example@mail.com (Tomohiro Motoda, Takahide Kitamura, Ryo Hanai, Yukiyasu Domae)</author>
      <guid isPermaLink="false">2410.23640v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>SceneComplete: Open-World 3D Scene Completion in Complex Real World Environments for Robot Manipulation</title>
      <link>http://arxiv.org/abs/2410.23643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在杂乱的日常环境中，机器人操作需要准确理解3D场景，以稳定和可靠地抓取和放置物体，并避免与其他物体的碰撞。&lt;h4&gt;目的&lt;/h4&gt;构建复杂场景的3D解释，基于有限的输入（如单张RGB-D图像）。&lt;h4&gt;方法&lt;/h4&gt;提出SceneComplete系统，从单视图构建完整的分割3D模型，采用新颖的管道组合通用预训练感知模块（视觉语言、分割、图像修复、图像到3D、姿态估计）以获得高精度结果。&lt;h4&gt;主要发现&lt;/h4&gt;在大型基准数据集上验证了系统的准确性与有效性，其精确的整体物体重建支持了稳健的抓取提案生成，适用于灵巧手。&lt;h4&gt;结论&lt;/h4&gt;SceneComplete系统能够有效构建3D场景模型，提升机器人在复杂环境中的操作能力。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了如何利用单视图数据构建高精度的3D场景模型，为机器人操作提供了理论与实践支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Careful robot manipulation in every-day cluttered environments requires anaccurate understanding of the 3D scene, in order to grasp and place objectsstably and reliably and to avoid mistakenly colliding with other objects. Ingeneral, we must construct such a 3D interpretation of a complex scene based onlimited input, such as a single RGB-D image. We describe SceneComplete, asystem for constructing a complete, segmented, 3D model of a scene from asingle view. It provides a novel pipeline for composing general-purposepretrained perception modules (vision-language, segmentation, image-inpainting,image-to-3D, and pose-estimation) to obtain high-accuracy results. Wedemonstrate its accuracy and effectiveness with respect to ground-truth modelsin a large benchmark dataset and show that its accurate whole-objectreconstruction enables robust grasp proposal generation, including for adexterous hand.</description>
      <author>example@mail.com (Aditya Agarwal, Gaurav Singh, Bipasha Sen, Tomás Lozano-Pérez, Leslie Pack Kaelbling)</author>
      <guid isPermaLink="false">2410.23643v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>CubiXMusashi: Fusion of Wire-Driven CubiX and Musculoskeletal Humanoid Musashi toward Unlimited Performance</title>
      <link>http://arxiv.org/abs/2410.23682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted Humanoids2024, website -
  https://shin0805.github.io/cubixmusashi/, YouTube -
  https://youtu.be/IvzP98-r_mo&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人形机器人在关节配置、驱动方式和自由度方面存在很大差异，导致不同类型的人形机器人能够实现不同的运动和任务。&lt;h4&gt;目的&lt;/h4&gt;研究将肌肉骨骼人形机器人Musashi与线驱动机器人CubiX结合，以克服传统肌肉骨骼人形机器人的局限性。&lt;h4&gt;方法&lt;/h4&gt;将Musashi与CubiX结合形成CubiXMusashi，通过线缆连接环境，实现复杂的运动。&lt;h4&gt;主要发现&lt;/h4&gt;CubiXMusashi能够实现如引体向上、从躺姿起身和空中踢腿等运动，这些运动单靠Musashi是不可能完成的。&lt;h4&gt;结论&lt;/h4&gt;通过与环境连接并利用线缆驱动，各种人形机器人（不仅限于肌肉骨骼人形机器人）可以缓解物理限制，获得新能力。&lt;h4&gt;总结&lt;/h4&gt;CubiXMusashi展示了通过环境互动来增强人形机器人的运动能力的潜力，拓宽了人形机器人的应用范围。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoids exhibit a wide variety in terms of joint configuration, actuators,and degrees of freedom, resulting in different achievable movements and tasksfor each type. Particularly, musculoskeletal humanoids are developed to closelyemulate human body structure and movement functions, consisting of a skeletalframework driven by numerous muscle actuators. The redundant arrangement ofmuscles relative to the skeletal degrees of freedom has been used to representthe flexible and complex body movements observed in humans. However, due tothis flexible body and high degrees of freedom, modeling, simulation, andcontrol become extremely challenging, limiting the feasible movements andtasks. In this study, we integrate the musculoskeletal humanoid Musashi withthe wire-driven robot CubiX, capable of connecting to the environment, to formCubiXMusashi. This combination addresses the shortcomings of traditionalmusculoskeletal humanoids and enables movements beyond the capabilities ofother humanoids. CubiXMusashi connects to the environment with wires and drivesby winding them, successfully achieving movements such as pull-up, rising froma lying pose, and mid-air kicking, which are difficult for Musashi alone. Thisconcept demonstrates that various humanoids, not limited to musculoskeletalhumanoids, can mitigate their physical constraints and acquire new abilities byconnecting to the environment and driving through wires.</description>
      <author>example@mail.com (Shintaro Inoue, Kento Kawaharazuka, Temma Suzuki, Sota Yuzaki, Yoshimoto Ribayashi, Yuta Sahara, Kei Okada)</author>
      <guid isPermaLink="false">2410.23682v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>The VIX as Stochastic Volatility for Corporate Bonds</title>
      <link>http://arxiv.org/abs/2410.22498v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 2 figures, 8 graphs. Keywords: stochastic volatility,
  autoregression, kurtosis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;经典的随机波动率模型假设波动率是不可观察的。&lt;h4&gt;目的&lt;/h4&gt;考虑VIX作为可观察的波动率，并应用于企业债券市场。&lt;h4&gt;方法&lt;/h4&gt;使用VIX（标准普尔500波动率指数）来拟合企业债与10年期国债之间的利差时间序列模型。&lt;h4&gt;主要发现&lt;/h4&gt;将残差除以VIX后，残差更接近理想的高斯白噪声。&lt;h4&gt;结论&lt;/h4&gt;这些残差和VIX来自不同的市场领域，表明模型的长期行为值得分析。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了VIX在企业债市场中的应用及其对模型残差的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classic stochastic volatility models assume volatility is unobservable. Weuse the VIX for consider it observable, and use the Volatility Index: S\&amp;P 500VIX. This index was designed to measure volatility of S&amp;P 500. We apply it to adifferent segment: Corporate bond markets. We fit time series models forspreads between corporate and 10-year Treasury bonds. Next, we divide residualsby VIX. Our main idea is such division makes residuals closer to the ideal caseof a Gaussian white noise. This is remarkable, since these residuals and VIXcome from separate market segments. We conclude with the analysis of long-termbehavior of these models.</description>
      <author>example@mail.com (Jihyun Park, Andrey Sarantsev)</author>
      <guid isPermaLink="false">2410.22498v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Features characterizing safe aerial-aquatic robots</title>
      <link>http://arxiv.org/abs/2410.23722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Peer-reviewed and accepted in IEEE Ubiquitous Robots 2024, New York
  City&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;环境监测的重要性，特别是淡水生态系统对生命和全球经济的关键作用。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过新技术提高淡水生态系统的监测能力。&lt;h4&gt;方法&lt;/h4&gt;对现有空中水面机器人进行全面回顾，重点分析水面进入策略及其安全风险。&lt;h4&gt;主要发现&lt;/h4&gt;现有原型的水面进入策略存在安全风险，并提出相关设计需求。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新型的具备垂直起降能力的机器人，能够实现无缝的空中水面过渡。&lt;h4&gt;总结&lt;/h4&gt;研究强调了空中水面机器人在淡水监测中的潜力，并为未来设计提供了指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper underscores the importance of environmental monitoring, andspecifically of freshwater ecosystems, which play a critical role in sustaininglife and global economy. Despite their importance, insufficient dataavailability prevents a comprehensive understanding of these ecosystems,thereby impeding informed decision-making concerning their preservation.Aerial-aquatic robots are identified as effective tools for freshwater sensing,offering rapid deployment and avoiding the need of using ships and mannedteams.  To advance the field of aerial aquatic robots, this paper conducts acomprehensive review of air-water transitions focusing on the water entrystrategy of existing prototypes. This analysis also highlights the safety risksassociated with each transition and proposes a set of design requirementsrelating to robots' tasks, mission objectives, and safety measures. To furtherexplore the proposed design requirements, we present a novel robot with VTOLcapability, enabling seamless air water transitions.</description>
      <author>example@mail.com (Andrea Giordano, Luca Romanello, Diego Perez Gonzalez, Mirko Kovac, Sophie F. Armanini)</author>
      <guid isPermaLink="false">2410.23722v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>A Comprehensive Review of Current Robot- Based Pollinators in Greenhouse Farming</title>
      <link>http://arxiv.org/abs/2410.23747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 21 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;温室中蜜蜂和风力授粉系统的衰退促使寻找替代授粉方法的重要性上升。&lt;h4&gt;目的&lt;/h4&gt;评估当前在温室中使用的机器人授粉系统。&lt;h4&gt;方法&lt;/h4&gt;对机器人授粉技术进行分类，包括气流喷射、水流喷射、线性执行器、超声波和气液喷雾等技术。&lt;h4&gt;主要发现&lt;/h4&gt;现有技术通常针对特定作物，限制了其通用性。&lt;h4&gt;结论&lt;/h4&gt;自动化授粉技术的整合降低了劳动力成本，并促进了现代农业的发展。&lt;h4&gt;挑战&lt;/h4&gt;探讨了授粉器设计中遇到的挑战。&lt;h4&gt;展望&lt;/h4&gt;展望未来的发展，旨在推动该技术的可持续进步。&lt;h4&gt;总结&lt;/h4&gt;机器人授粉系统为应对温室授粉挑战提供了有前景的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The decline of bee and wind-based pollination systems in greenhouses due tocontrolled environments and limited access has boost the importance of findingalternative pollination methods. Robotic based pollination systems have emergedas a promising solution, ensuring adequate crop yield even in challengingpollination scenarios. This paper presents a comprehensive review of thecurrent robotic-based pollinators employed in greenhouses. The reviewcategorizes pollinator technologies into major categories such as air-jet,water-jet, linear actuator, ultrasonic wave, and air-liquid spray, eachsuitable for specific crop pollination requirements. However, thesetechnologies are often tailored to particular crops, limiting theirversatility. The advancement of science and technology has led to theintegration of automated pollination technology, encompassing informationtechnology, automatic perception, detection, control, and operation. Thisintegration not only reduces labor costs but also fosters the ongoing progressof modern agriculture by refining technology, enhancing automation, andpromoting intelligence in agricultural practices. Finally, the challengesencountered in design of pollinator are addressed, and a forward-lookingperspective is taken towards future developments, aiming to contribute to thesustainable advancement of this technology.</description>
      <author>example@mail.com (Rajmeet Singh, lakmal Seneviratne, Irfan Hussain)</author>
      <guid isPermaLink="false">2410.23747v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Analysing the Interplay of Vision and Touch for Dexterous Insertion Tasks</title>
      <link>http://arxiv.org/abs/2410.23860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人插入任务因感知的不确定性和对精确控制的需求而具有挑战性，特别是在非结构化环境中。&lt;h4&gt;目的&lt;/h4&gt;探讨视觉和触觉反馈在灵巧插入任务中的相互作用。&lt;h4&gt;方法&lt;/h4&gt;进行广泛分析，评估触觉感知在复杂插入任务中的作用。&lt;h4&gt;主要发现&lt;/h4&gt;触觉感知显著提高了在紧凑容差和多变孔位方向下的插入成功率，单靠视觉无法解决。&lt;h4&gt;结论&lt;/h4&gt;为设计更有效的多模态机器人控制系统提供了重要见解，强调了触觉反馈在接触丰富的操作任务中的关键作用。&lt;h4&gt;总结&lt;/h4&gt;研究结果有助于改进机器人在复杂环境中的操作能力，促进多模态感知系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic insertion tasks remain challenging due to uncertainties in perceptionand the need for precise control, particularly in unstructured environments.While humans seamlessly combine vision and touch for such tasks, effectivelyintegrating these modalities in robotic systems is still an open problem. Ourwork presents an extensive analysis of the interplay between visual and tactilefeedback during dexterous insertion tasks, showing that tactile sensing cangreatly enhance success rates on challenging insertions with tight tolerancesand varied hole orientations that vision alone cannot solve. These findingsprovide valuable insights for designing more effective multi-modal roboticcontrol systems and highlight the critical role of tactile feedback incontact-rich manipulation tasks.</description>
      <author>example@mail.com (Janis Lenz, Theo Gruner, Daniel Palenicek, Tim Schneider, Jan Peters)</author>
      <guid isPermaLink="false">2410.23860v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>GoRINNs: Godunov-Riemann Informed Neural Networks for Learning Hyperbolic Conservation Laws</title>
      <link>http://arxiv.org/abs/2410.22193v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究非线性守恒定律系统的逆问题。&lt;h4&gt;目的&lt;/h4&gt;提出GoRINNs，旨在改善数值分析与神经网络结合的效果。&lt;h4&gt;方法&lt;/h4&gt;基于高分辨率Godunov方案解决双曲偏微分方程中的黎曼问题，学习物理通量函数。&lt;h4&gt;主要发现&lt;/h4&gt;GoRINNs在光滑和不连续区域都能提供很高的准确性。&lt;h4&gt;结论&lt;/h4&gt;GoRINNs提供了可解释的保守方案，能有效学习近似黎曼求解器的解算子。&lt;h4&gt;应用&lt;/h4&gt;通过四个基准问题（Burgers', Shallow Water, Lighthill-Whitham-Richards, Payne-Whitham交通流模型）评估性能。&lt;h4&gt;总结&lt;/h4&gt;GoRINNs能够高效处理包含冲击波、稀疏波和接触不连续的偏微分方程解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present GoRINNs: numerical analysis-informed neural networks for thesolution of inverse problems of non-linear systems of conservation laws.GoRINNs are based on high-resolution Godunov schemes for the solution of theRiemann problem in hyperbolic Partial Differential Equations (PDEs). Incontrast to other existing machine learning methods that learn the numericalfluxes of conservative Finite Volume methods, GoRINNs learn the physical fluxfunction per se. Due to their structure, GoRINNs provide interpretable,conservative schemes, that learn the solution operator on the basis ofapproximate Riemann solvers that satisfy the Rankine-Hugoniot condition. Theperformance of GoRINNs is assessed via four benchmark problems, namely theBurgers', the Shallow Water, the Lighthill-Whitham-Richards and thePayne-Whitham traffic flow models. The solution profiles of these PDEs exhibitshock waves, rarefactions and/or contact discontinuities at finite times. Wedemonstrate that GoRINNs provide a very high accuracy both in the smooth anddiscontinuous regions.</description>
      <author>example@mail.com (Dimitrios G. Patsatzis, Mario di Bernardo, Lucia Russo, Constantinos Siettos)</author>
      <guid isPermaLink="false">2410.22193v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>From Web Data to Real Fields: Low-Cost Unsupervised Domain Adaptation for Agricultural Robots</title>
      <link>http://arxiv.org/abs/2410.23906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在精准农业中，视觉模型常常在新、未见的田地中遇到困难，作物和杂草的外观因外部因素而不同于已学习的分布。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过无监督领域适应（UDA）以低成本适应特定田地。&lt;h4&gt;方法&lt;/h4&gt;我们探索了一种从多样的大规模互联网数据池到特定位置的机器人收集的小数据集的领域转移，减少了对大量现场数据收集的需求。同时，引入了一种新模块——基于多级注意力的对抗鉴别器（MAAD），可集成在任何检测模型的特征提取器层。&lt;h4&gt;主要发现&lt;/h4&gt;本研究将MAAD与CenterNet结合，能够同时检测叶子、茎和脉实例。在未标记的目标领域中，性能显著提高，物体检测准确率提高了7.5%，关键点检测提高了5.1%。&lt;h4&gt;结论&lt;/h4&gt;引入MAAD模块显著提升了视觉模型在新环境中的适应性和检测性能。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了低成本的无监督领域适应方法在精准农业视觉模型中的有效性，强调了MAAD模块的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In precision agriculture, vision models often struggle with new, unseenfields where crops and weeds have been influenced by external factors,resulting in compositions and appearances that differ from the learneddistribution. This paper aims to adapt to specific fields at low cost usingUnsupervised Domain Adaptation (UDA). We explore a novel domain shift from adiverse, large pool of internet-sourced data to a small set of data collectedby a robot at specific locations, minimizing the need for extensive on-fielddata collection. Additionally, we introduce a novel module -- the Multi-levelAttention-based Adversarial Discriminator (MAAD) -- which can be integrated atthe feature extractor level of any detection model. In this study, weincorporate MAAD with CenterNet to simultaneously detect leaf, stem, and veininstances. Our results show significant performance improvements in theunlabeled target domain compared to baseline models, with a 7.5% increase inobject detection accuracy and a 5.1% improvement in keypoint detection.</description>
      <author>example@mail.com (Vasileios Tzouras, Lazaros Nalpantidis, Ronja Güldenring)</author>
      <guid isPermaLink="false">2410.23906v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Transformer-based Model Predictive Control: Trajectory Optimization via Sequence Modeling</title>
      <link>http://arxiv.org/abs/2410.23916v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures. Datasets, videos and code available at:
  https://transformermpc.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模型预测控制（MPC）已成为约束控制的主要方法，支持机器人在多种现实场景中的自主性。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的框架，将基于优化和基于学习的方法结合起来，以改善MPC的性能。&lt;h4&gt;方法&lt;/h4&gt;在轨迹生成的优化过程中嵌入高容量的基于变换器的神经网络模型，提供近似最优的初始猜测或目标计划。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，相较于纯粹的基于优化的方法，所提方法在轨迹生成性能上提高了最多75%，求解器迭代次数减少了最多45%，整体MPC运行时间提升了7倍且性能没有下降。&lt;h4&gt;结论&lt;/h4&gt;通过结合优化与学习的方法，所提框架显著提升了MPC的收敛性和运行效率。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了基于变换器的神经网络在MPC中的应用潜力，为机器人自主控制提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2024.3466069&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model predictive control (MPC) has established itself as the primarymethodology for constrained control, enabling general-purpose robot autonomy indiverse real-world scenarios. However, for most problems of interest, MPCrelies on the recursive solution of highly non-convex trajectory optimizationproblems, leading to high computational complexity and strong dependency oninitialization. In this work, we present a unified framework to combine themain strengths of optimization-based and learning-based methods for MPC. Ourapproach entails embedding high-capacity, transformer-based neural networkmodels within the optimization process for trajectory generation, whereby thetransformer provides a near-optimal initial guess, or target plan, to anon-convex optimization problem. Our experiments, performed in simulation andthe real world onboard a free flyer platform, demonstrate the capabilities ofour framework to improve MPC convergence and runtime. Compared to purelyoptimization-based approaches, results show that our approach can improvetrajectory generation performance by up to 75%, reduce the number of solveriterations by up to 45%, and improve overall MPC runtime by 7x without loss inperformance.</description>
      <author>example@mail.com (Davide Celestini, Daniele Gammelli, Tommaso Guffanti, Simone D'Amico, Elisa Capello, Marco Pavone)</author>
      <guid isPermaLink="false">2410.23916v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Redundant Observer-Based Tracking Control for Object Extraction Using a Cable Connected UAV</title>
      <link>http://arxiv.org/abs/2410.23929v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文研究了一种新的基于干扰观测器的控制方案，针对受轻型弹性缆绳和垂直干扰同时影响的四旋翼飞行器。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够估计缆绳刚度系数并补偿外部干扰的控制方法。&lt;h4&gt;方法&lt;/h4&gt;采用观测器方法估计缆绳的刚度系数，并利用系统模型更新外部力的估计，以便在控制中进行补偿。&lt;h4&gt;主要发现&lt;/h4&gt;所提干扰观测器利用所有三个通道的冗余测量共同估计缆绳刚度和垂直干扰，且估计过程解耦且稳定。&lt;h4&gt;结论&lt;/h4&gt;与标准干扰观测器相比，所提方法能够快速调整总力估计，适应四旋翼位置或缆绳紧绷度的变化，实验结果显示显著改善。&lt;h4&gt;实验&lt;/h4&gt;进行了两项实验：一是四旋翼在恒定缆绳拉力下的跟踪性能测试，二是模拟提取带有棱角物体的非线性机制的物体提取测试。&lt;h4&gt;总结&lt;/h4&gt;所提方法在两项实验中表现优于标准干扰观测器和扩展状态观测器方法，展示了其有效性和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A new disturbance observer based control scheme is developed for a quadrotorunder the concurrent disturbances from a lightweight elastic tether cable and alumped vertical disturbance. This elastic tether is unusual as it creates adisturbance proportional to the multicopter's translational movement. Thispaper takes an observer-based approach to estimate the stiffness coefficient ofthe cable and uses the system model to update the estimates of the externalforces, which are then compensated in the control action. Given that thetethered cable force affects both horizontal channels of the quadrotor and isalso coupled with the vertical channel, the proposed disturbance observer isconstructed to exploit the redundant measurements across all three channels tojointly estimate the cable stiffness and the vertical disturbance. Apseudo-inverse method is used to determine the observer gain functions, suchthat the estimation of the two quantities is decoupled and stable. Compared tostandard disturbance observers which assume nearly constant disturbances, theproposed approach can quickly adjust its total force estimate as the tetheredquadrotor changes its position or tautness of the tether. This is applied totwo experiments - a tracking performance test where the multicopter moves undera constant tether strain, and an object extraction test. In the second test,the multicopter manipulates a nonlinear mechanism mimicking the extraction of awedged object. In both cases, the proposed approach shows significantimprovement over standard Disturbance Observer and Extended State Observerapproaches. A video summary of the experiments can be found athttps://youtu.be/9gKr13WTj-k.</description>
      <author>example@mail.com (Benjamin J. Marshall, Yunda Yan, James Knowles, Chenguang Yang, Cunjia Liu)</author>
      <guid isPermaLink="false">2410.23929v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Multiview Scene Graph</title>
      <link>http://arxiv.org/abs/2410.11187v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in NeurIPS 2024. Website at
  https://ai4ce.github.io/MSG/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;场景表示在空间智能中至关重要，能够帮助代理有效重建并理解3D场景。&lt;h4&gt;目的&lt;/h4&gt;提出构建多视图场景图（MSG），从未摆姿的图像中表示场景的拓扑结构。&lt;h4&gt;方法&lt;/h4&gt;通过连接场所和物体节点，构建MSG，同时解决视觉场所识别、物体检测和物体关联的问题。&lt;h4&gt;主要发现&lt;/h4&gt;开发了基于公共3D数据集的MSG数据集和注释，提出了一种基于交并比评分的评估指标，实验结果表明该方法优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;提出的基线方法结合了视觉场所识别和物体关联，采用Transformer解码器架构，显示出卓越的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究为从未摆姿的图像构建拓扑场景表示提供了一种有效的方法，并在实验中验证了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ai4ce/MSG&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A proper scene representation is central to the pursuit of spatialintelligence where agents can robustly reconstruct and efficiently understand3D scenes. A scene representation is either metric, such as landmark maps in 3Dreconstruction, 3D bounding boxes in object detection, or voxel grids inoccupancy prediction, or topological, such as pose graphs with loop closures inSLAM or visibility graphs in SfM. In this work, we propose to build MultiviewScene Graphs (MSG) from unposed images, representing a scene topologically withinterconnected place and object nodes. The task of building MSG is challengingfor existing representation learning methods since it needs to jointly addressboth visual place recognition, object detection, and object association fromimages with limited fields of view and potentially large viewpoint changes. Toevaluate any method tackling this task, we developed an MSG dataset andannotation based on a public 3D dataset. We also propose an evaluation metricbased on the intersection-over-union score of MSG edges. Moreover, we develop anovel baseline method built on mainstream pretrained vision models, combiningvisual place recognition and object association into one Transformer decoderarchitecture. Experiments demonstrate that our method has superior performancecompared to existing relevant baselines.</description>
      <author>example@mail.com (Juexiao Zhang, Gao Zhu, Sihang Li, Xinhao Liu, Haorui Song, Xinran Tang, Chen Feng)</author>
      <guid isPermaLink="false">2410.11187v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Exploiting Information Theory for Intuitive Robot Programming of Manual Activities</title>
      <link>http://arxiv.org/abs/2410.23963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;观察学习是一种有前景的方法，可以使没有编程专长的人以用户友好的方式将技能转移到机器人上，因为它反映了人类通过观察他人学习新行为的方式。&lt;h4&gt;目的&lt;/h4&gt;提出一个新框架，使机器人能够更高层次地理解在RGB视频中记录的人类演示的手动任务。&lt;h4&gt;方法&lt;/h4&gt;通过识别任务结构和目标，使机器人能够将观察到的内容推广到未见的场景。使用香农信息理论提取活动场景元素，并量化手与物体之间共享的信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过场景图属性编码提取的交互特征，并将演示分块，从而简化机器人复制的行为树生成。实验验证了信息理论在从单个人类演示自动生成机器人执行计划中的有效性。&lt;h4&gt;结论&lt;/h4&gt;提供了HANDSOME，一个开放的多主体手动技能演示数据集，以促进该领域的进一步研究和评估。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种基于信息理论的框架，通过高层次的任务理解，增强了机器人在不同环境中的技能泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Observational learning is a promising approach to enable people withoutexpertise in programming to transfer skills to robots in a user-friendlymanner, since it mirrors how humans learn new behaviors by observing others.Many existing methods focus on instructing robots to mimic human trajectories,but motion-level strategies often pose challenges in skills generalizationacross diverse environments. This paper proposes a novel framework that allowsrobots to achieve a \textit{higher-level} understanding of human-demonstratedmanual tasks recorded in RGB videos. By recognizing the task structure andgoals, robots generalize what observed to unseen scenarios. We found our taskrepresentation on Shannon's Information Theory (IT), which is applied for thefirst time to manual tasks. IT helps extract the active scene elements andquantify the information shared between hands and objects. We exploit scenegraph properties to encode the extracted interaction features in a compactstructure and segment the demonstration into blocks, streamlining thegeneration of Behavior Trees for robot replicas. Experiments validated theeffectiveness of IT to automatically generate robot execution plans from asingle human demonstration. Additionally, we provide HANDSOME, an open-sourcedataset of HAND Skills demOnstrated by Multi-subjEcts, to promote furtherresearch and evaluation in this field.</description>
      <author>example@mail.com (Elena Merlo, Marta Lagomarsino, Edoardo Lamon, Arash Ajoudani)</author>
      <guid isPermaLink="false">2410.23963v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>EmbodiedRAG: Dynamic 3D Scene Graph Retrieval for Efficient and Scalable Robot Task Planning</title>
      <link>http://arxiv.org/abs/2410.23968v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近期大型语言模型（LLMs）的进展促进了机器人在真实开放世界环境中的规划能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来优化3D场景图（3DSG）供LLM基础的规划器使用，以应对环境规模和场景图信息复杂性增加带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为EmbodiedRAG的3D场景子图检索框架，将其与LLM基础的规划器结合，用于执行自然语言机器人任务。&lt;h4&gt;主要发现&lt;/h4&gt;EmbodiedRAG显著减少了输入标记数量（减少了一个数量级），并降低了规划时间（每个规划步骤的平均时间减少了70%），同时提高了在AI2Thor模拟家庭任务中的成功率。&lt;h4&gt;结论&lt;/h4&gt;EmbodiedRAG在真实环境中的四足机器人部署中展示了性能优势，表明其在机器人任务中的有效性。&lt;h4&gt;总结&lt;/h4&gt;EmbodiedRAG通过动态适应环境变化和任务相关性改善了机器人任务的执行效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Large Language Models (LLMs) have helped facilitateexciting progress for robotic planning in real, open-world environments. 3Dscene graphs (3DSGs) offer a promising environment representation for groundingsuch LLM-based planners as they are compact and semantically rich. However, asthe robot's environment scales (e.g., number of entities tracked) and thecomplexity of scene graph information increases (e.g., maintaining moreattributes), providing the 3DSG as-is to an LLM-based planner quickly becomesinfeasible due to input token count limits and attentional biases present inLLMs. Inspired by the successes of Retrieval-Augmented Generation (RAG) methodsthat retrieve query-relevant document chunks for LLM question and answering, weadapt the paradigm for our embodied domain. Specifically, we propose a 3D scenesubgraph retrieval framework, called EmbodiedRAG, that we augment an LLM-basedplanner with for executing natural language robotic tasks. Notably, ourretrieved subgraphs adapt to changes in the environment as well as changes intask-relevancy as the robot executes its plan. We demonstrate EmbodiedRAG'sability to significantly reduce input token counts (by an order of magnitude)and planning time (up to 70% reduction in average time per planning step) whileimproving success rates on AI2Thor simulated household tasks with a single-arm,mobile manipulator. Additionally, we implement EmbodiedRAG on a quadruped witha manipulator to highlight the performance benefits for robot deployment at theedge in real environments.</description>
      <author>example@mail.com (Meghan Booker, Grayson Byrd, Bethany Kemp, Aurora Schmidt, Corban Rivera)</author>
      <guid isPermaLink="false">2410.23968v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>GAMap: Zero-Shot Object Goal Navigation with Multi-Scale Geometric-Affordance Guidance</title>
      <link>http://arxiv.org/abs/2410.23978v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 8 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;零样本目标导航（ZS-OGN）使机器人或代理能够导航到未见类别的物体，但传统方法依赖于类别语义信息，面临部分观察物体和环境表示不足的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，解决现有方法在物体部分观察和环境功能表示不足时的导航问题。&lt;h4&gt;方法&lt;/h4&gt;提出几何部分和功能特征图（GAMap），结合物体的部分和功能属性作为导航指导，采用多尺度评分方法捕捉不同尺度的几何部分和功能属性。&lt;h4&gt;主要发现&lt;/h4&gt;在HM3D和Gibson基准数据集上的综合实验表明，成功率和按路径长度加权的成功率均有所提升。&lt;h4&gt;结论&lt;/h4&gt;我们的几何部分和功能引导导航方法有效提升了机器人自主性和多样性，无需额外的物体特定训练或调整。&lt;h4&gt;总结&lt;/h4&gt;GAMap方法通过整合几何部分和功能属性，显著改善了零样本目标导航的表现，展示了其在未知物体环境中导航的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-Shot Object Goal Navigation (ZS-OGN) enables robots or agents tonavigate toward objects of unseen categories without object-specific training.Traditional approaches often leverage categorical semantic information fornavigation guidance, which struggles when only objects are partially observedor detailed and functional representations of the environment are lacking. Toresolve the above two issues, we propose \textit{Geometric-part and AffordanceMaps} (GAMap), a novel method that integrates object parts and affordanceattributes as navigation guidance. Our method includes a multi-scale scoringapproach to capture geometric-part and affordance attributes of objects atdifferent scales. Comprehensive experiments conducted on HM3D and Gibsonbenchmark datasets demonstrate improvements in Success Rate and Successweighted by Path Length, underscoring the efficacy of our geometric-part andaffordance-guided navigation approach in enhancing robot autonomy andversatility, without any additional object-specific training or fine-tuningwith the semantics of unseen objects and/or the locomotions of the robot.</description>
      <author>example@mail.com (Shuaihang Yuan, Hao Huang, Yu Hao, Congcong Wen, Anthony Tzes, Yi Fang)</author>
      <guid isPermaLink="false">2410.23978v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>UAV-based detection of landmines using infrared thermography</title>
      <link>http://arxiv.org/abs/2410.23998v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in "Int. J. Computational Vision and
  Robotics"&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;地雷在全球冲突地区依然是一个普遍的威胁，对无辜生命造成重大影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖、高效、安全且成本效益高的方法来探测隐藏的地雷。&lt;h4&gt;方法&lt;/h4&gt;将无人机与热成像摄像机结合，获取地雷区的高分辨率图像，并使用先进的图像处理算法进行地雷识别。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在夜间表现尤为出色，检测准确率接近88%。&lt;h4&gt;结论&lt;/h4&gt;与现有方法相比，该方案在设计限制上展现出更大的潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究为地雷探测提供了一种新的解决方案，具有高效性和安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1504/IJCVR.2024.10066473&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Landmines remain a pervasive threat in conflict-affected regions worldwide,exacting a toll on innocent lives. Shockingly, every 95 minutes, anotherindividual becomes a victim of these lethal explosive devices (LandminesMonitor 2022 2022), with a significant proportion being innocent civilians.Current methods for landmine detection suffer from inefficiency, high costs,and risks to the operator and system integrity. In this paper, we present anovel, efficient, safe, and cost-effective approach to unearth these hiddendangers. Our proposed method integrates an unmanned aerial vehicle (UAV) with athermal camera to capture high-resolution images of minefields. These imagesare subsequently transmitted to a base computer, where a state-of-the-art imageprocessing algorithm is applied to identify the presence of landmines. Notably,our solution performs exceptionally well, particularly during evening hours,achieving an impressive detection accuracy of nearly 88%. These results exhibitgreat promise when compared to existing methods constrained by their designlimitations.</description>
      <author>example@mail.com (Muhammad Umair Akram Butt, Zaighum Naveed, Usama Javed)</author>
      <guid isPermaLink="false">2410.23998v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Gradient-free training of recurrent neural networks</title>
      <link>http://arxiv.org/abs/2410.23467v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;递归神经网络是一种成功的神经架构，广泛应用于时间相关的问题，如时间序列分析、预测和动态系统建模。&lt;h4&gt;目的&lt;/h4&gt;提出一种计算方法，用于构建递归神经网络的所有权重和偏置，而不使用基于梯度的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了随机特征网络和库普曼算子理论，随机采样单个递归块的隐藏参数，并利用扩展动态模式分解构建外部权重。&lt;h4&gt;主要发现&lt;/h4&gt;在时间序列、混沌动态系统预测、控制问题及气象数据的计算实验中，所构建的递归神经网络的训练时间和预测精度优于常用的基于梯度的方法。&lt;h4&gt;结论&lt;/h4&gt;这种方法缓解了与递归网络相关的反向传播问题，并为分析递归神经网络提供了新的视角，利用库普曼算子的研究成果。&lt;h4&gt;总结&lt;/h4&gt;提出了一种新颖的递归神经网络构建方法，具有更好的训练效率和预测性能，推动了相关理论的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recurrent neural networks are a successful neural architecture for manytime-dependent problems, including time series analysis, forecasting, andmodeling of dynamical systems. Training such networks with backpropagationthrough time is a notoriously difficult problem because their loss gradientstend to explode or vanish. In this contribution, we introduce a computationalapproach to construct all weights and biases of a recurrent neural networkwithout using gradient-based methods. The approach is based on a combination ofrandom feature networks and Koopman operator theory for dynamical systems. Thehidden parameters of a single recurrent block are sampled at random, while theouter weights are constructed using extended dynamic mode decomposition. Thisapproach alleviates all problems with backpropagation commonly related torecurrent networks. The connection to Koopman operator theory also allows us tostart using results in this area to analyze recurrent neural networks. Incomputational experiments on time series, forecasting for chaotic dynamicalsystems, and control problems, as well as on weather data, we observe that thetraining time and forecasting accuracy of the recurrent neural networks weconstruct are improved when compared to commonly used gradient-based methods.</description>
      <author>example@mail.com (Erik Lien Bolager, Ana Cukarska, Iryna Burak, Zahra Monfared, Felix Dietrich)</author>
      <guid isPermaLink="false">2410.23467v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data</title>
      <link>http://arxiv.org/abs/2410.22938v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在交通信号控制（TSC）领域，强化学习的应用研究广泛，但大多数研究假设周围交叉口的交通数据可以持续通过传感器获取。&lt;h4&gt;目的&lt;/h4&gt;解决在现实应用中，由于传感器故障或数据丢失导致的TSC中数据缺失的问题。&lt;h4&gt;方法&lt;/h4&gt;提出DiffLight，一种新颖的条件扩散模型，结合交通数据插补和决策制定，使用部分奖励条件扩散（PRCD）模型来避免缺失奖励干扰学习过程。同时，设计了一个空间-时间变换器（STFormer）架构，以有效捕获交叉口之间的空间时间依赖性。&lt;h4&gt;主要发现&lt;/h4&gt;在五个不同数据缺失场景的实验中，DiffLight表现出色，有效解决了缺失数据下的TSC控制问题。&lt;h4&gt;结论&lt;/h4&gt;DiffLight是一个有效的控制器，能够在数据缺失的情况下进行交通信号控制，相关代码已在GitHub上发布。&lt;h4&gt;总结&lt;/h4&gt;该研究为应对交通信号控制中的数据缺失提供了新的思路和方法，具有实际应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lokol5579/DiffLight-release&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The application of reinforcement learning in traffic signal control (TSC) hasbeen extensively researched and yielded notable achievements. However, mostexisting works for TSC assume that traffic data from all surroundingintersections is fully and continuously available through sensors. Inreal-world applications, this assumption often fails due to sensor malfunctionsor data loss, making TSC with missing data a critical challenge. To meet theneeds of practical applications, we introduce DiffLight, a novel conditionaldiffusion model for TSC under data-missing scenarios in the offline setting.Specifically, we integrate two essential sub-tasks, i.e., traffic dataimputation and decision-making, by leveraging a Partial Rewards ConditionedDiffusion (PRCD) model to prevent missing rewards from interfering with thelearning process. Meanwhile, to effectively capture the spatial-temporaldependencies among intersections, we design a Spatial-Temporal transFormer(STFormer) architecture. In addition, we propose a Diffusion CommunicationMechanism (DCM) to promote better communication and control performance underdata-missing scenarios. Extensive experiments on five datasets with variousdata-missing scenarios demonstrate that DiffLight is an effective controller toaddress TSC with missing data. The code of DiffLight is released athttps://github.com/lokol5579/DiffLight-release.</description>
      <author>example@mail.com (Hanyang Chen, Yang Jiang, Shengnan Guo, Xiaowei Mao, Youfang Lin, Huaiyu Wan)</author>
      <guid isPermaLink="false">2410.22938v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Tangent Space Causal Inference: Leveraging Vector Fields for Causal Discovery in Dynamical Systems</title>
      <link>http://arxiv.org/abs/2410.23499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures. Accepted to NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;因果发现与时间序列数据的研究在多个科学领域中越来越重要，但面临诸多挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法——切空间因果推断（TSCI），用于检测动态系统中的因果关系。&lt;h4&gt;方法&lt;/h4&gt;TSCI通过考虑向量场作为系统动态的显式表示，并检查学习到的向量场之间的同步程度，具有模型无关性，可以替代传统的CCM及其推广。&lt;h4&gt;主要发现&lt;/h4&gt;TSCI的基本算法在计算量稍增的情况下，效果优于基本的CCM算法，同时增强版TSCI结合了潜变量模型和深度学习的表达能力。&lt;h4&gt;结论&lt;/h4&gt;通过在标准系统上的理论验证，TSCI在多个基准任务上表现出更好的因果推断性能。&lt;h4&gt;总结&lt;/h4&gt;TSCI方法为动态系统的因果发现提供了一种新的有效工具，克服了传统方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/KurtButler/tangentspaces&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Causal discovery with time series data remains a challenging yet increasinglyimportant task across many scientific domains. Convergent cross mapping (CCM)and related methods have been proposed to study time series that are generatedby dynamical systems, where traditional approaches like Granger causality areunreliable. However, CCM often yields inaccurate results depending upon thequality of the data. We propose the Tangent Space Causal Inference (TSCI)method for detecting causalities in dynamical systems. TSCI works byconsidering vector fields as explicit representations of the systems' dynamicsand checks for the degree of synchronization between the learned vector fields.The TSCI approach is model-agnostic and can be used as a drop-in replacementfor CCM and its generalizations. We first present a basic version of the TSCIalgorithm, which is shown to be more effective than the basic CCM algorithmwith very little additional computation. We additionally present augmentedversions of TSCI that leverage the expressive power of latent variable modelsand deep learning. We validate our theory on standard systems, and wedemonstrate improved causal inference performance across a number of benchmarktasks.</description>
      <author>example@mail.com (Kurt Butler, Daniel Waxman, Petar M. Djurić)</author>
      <guid isPermaLink="false">2410.23499v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Sparsh: Self-supervised touch representations for vision-based tactile sensing</title>
      <link>http://arxiv.org/abs/2410.24090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Conference on Robot Learning (CoRL), 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉基础的触觉传感器日益普及，能显著补充视觉，但现有解决方案往往依赖于特定任务和传感器的手工感知模型。&lt;h4&gt;目的&lt;/h4&gt;介绍通用的触觉表示方法，以解决触觉传感器数据收集和模型训练中的挑战。&lt;h4&gt;方法&lt;/h4&gt;采用自监督学习（SSL），利用460,000+触觉图像进行预训练，通过掩蔽和自蒸馏在像素和潜在空间中进行学习。&lt;h4&gt;主要发现&lt;/h4&gt;自监督学习的触觉表示在TacBench上平均优于任务和传感器特定的端到端训练95.1%，其中Sparsh (DINO)和Sparsh (IJEPA)表现最为出色。&lt;h4&gt;结论&lt;/h4&gt;学习潜在空间的触觉图像具有显著优势，能够减轻对自定义标签的需求。&lt;h4&gt;总结&lt;/h4&gt;本研究通过建立Sparsh SSL模型和TacBench基准测试，推动了视觉基础触觉传感器的应用和发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we introduce general purpose touch representations for theincreasingly accessible class of vision-based tactile sensors. Such sensorshave led to many recent advances in robot manipulation as they markedlycomplement vision, yet solutions today often rely on task and sensor specifichandcrafted perception models. Collecting real data at scale with task centricground truth labels, like contact forces and slip, is a challenge furthercompounded by sensors of various form factor differing in aspects like lightingand gel markings. To tackle this we turn to self-supervised learning (SSL) thathas demonstrated remarkable performance in computer vision. We present Sparsh,a family of SSL models that can support various vision-based tactile sensors,alleviating the need for custom labels through pre-training on 460k+ tactileimages with masking and self-distillation in pixel and latent spaces. We alsobuild TacBench, to facilitate standardized benchmarking across sensors andmodels, comprising of six tasks ranging from comprehending tactile propertiesto enabling physical perception and manipulation planning. In evaluations, wefind that SSL pre-training for touch representation outperforms task andsensor-specific end-to-end training by 95.1% on average over TacBench, andSparsh (DINO) and Sparsh (IJEPA) are the most competitive, indicating themerits of learning in latent space for tactile images. Project page:https://sparsh-ssl.github.io/</description>
      <author>example@mail.com (Carolina Higuera, Akash Sharma, Chaithanya Krishna Bodduluri, Taosha Fan, Patrick Lancaster, Mrinal Kalakrishnan, Michael Kaess, Byron Boots, Mike Lambeta, Tingfan Wu, Mustafa Mukadam)</author>
      <guid isPermaLink="false">2410.24090v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Generative forecasting of brain activity enhances Alzheimer's classification and interpretation</title>
      <link>http://arxiv.org/abs/2410.23515v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;理解认知与内在大脑活动之间的关系是神经科学中的一个重大挑战，rs-fMRI提供了一种无创监测区域神经活动的方法。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过数据驱动的方法，探索多变量时间序列预测在阿尔茨海默病(AD)分类中的应用。&lt;h4&gt;方法&lt;/h4&gt;采用传统的LSTM模型和新颖的基于Transformer的BrainLM模型，对来自rs-fMRI的独立成分网络进行数据增强的时间序列预测。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，生成预测方法能够增强AD分类的性能，同时BrainLM的后续解释揭示了与AD相关的特定大脑网络敏感性。&lt;h4&gt;结论&lt;/h4&gt;深度学习模型在处理复杂的时序数据方面显示出潜力，尽管存在数据集有限的挑战，但在AD分类中仍能取得良好效果。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过多变量时间序列预测提升AD分类性能的可能性，强调了数据驱动方法在神经科学研究中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the relationship between cognition and intrinsic brain activitythrough purely data-driven approaches remains a significant challenge inneuroscience. Resting-state functional magnetic resonance imaging (rs-fMRI)offers a non-invasive method to monitor regional neural activity, providing arich and complex spatiotemporal data structure. Deep learning has shown promisein capturing these intricate representations. However, the limited availabilityof large datasets, especially for disease-specific groups such as Alzheimer'sDisease (AD), constrains the generalizability of deep learning models. In thisstudy, we focus on multivariate time series forecasting of independentcomponent networks derived from rs-fMRI as a form of data augmentation, usingboth a conventional LSTM-based model and the novel Transformer-based BrainLMmodel. We assess their utility in AD classification, demonstrating howgenerative forecasting enhances classification performance. Post-hocinterpretation of BrainLM reveals class-specific brain network sensitivitiesassociated with AD.</description>
      <author>example@mail.com (Yutong Gao, Vince D. Calhoun, Robyn L. Miller)</author>
      <guid isPermaLink="false">2410.23515v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>3D-ViTac: Learning Fine-Grained Manipulation with Visuo-Tactile Sensing</title>
      <link>http://arxiv.org/abs/2410.24091v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Conference on Robot Learning (CoRL) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;触觉和视觉感知对人类与环境的精细交互至关重要，开发类似的多模态感知能力可以显著增强机器人的操作技能。&lt;h4&gt;目的&lt;/h4&gt;介绍3D-ViTac，一个用于灵巧双手操作的多模态感知和学习系统。&lt;h4&gt;方法&lt;/h4&gt;系统配备了低成本且灵活的触觉传感器，这些传感器的密集感应单元覆盖面积为3mm²，通过将触觉和视觉数据融合到统一的3D表示空间中，保留其三维结构和空间关系。&lt;h4&gt;主要发现&lt;/h4&gt;低成本机器人能够进行精确操作，显著超越仅依赖视觉的策略，特别是在安全处理易碎物品和执行涉及手内操作的长时间任务方面。&lt;h4&gt;结论&lt;/h4&gt;3D-ViTac系统展示了多模态感知在机器人操作中的有效性，能够提升机器人在复杂任务中的表现。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，结合触觉和视觉感知的机器人可以在多种操作中实现更高的精确度和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tactile and visual perception are both crucial for humans to performfine-grained interactions with their environment. Developing similarmulti-modal sensing capabilities for robots can significantly enhance andexpand their manipulation skills. This paper introduces \textbf{3D-ViTac}, amulti-modal sensing and learning system designed for dexterous bimanualmanipulation. Our system features tactile sensors equipped with dense sensingunits, each covering an area of 3$mm^2$. These sensors are low-cost andflexible, providing detailed and extensive coverage of physical contacts,effectively complementing visual information. To integrate tactile and visualdata, we fuse them into a unified 3D representation space that preserves their3D structures and spatial relationships. The multi-modal representation canthen be coupled with diffusion policies for imitation learning. Throughconcrete hardware experiments, we demonstrate that even low-cost robots canperform precise manipulations and significantly outperform vision-onlypolicies, particularly in safe interactions with fragile items and executinglong-horizon tasks involving in-hand manipulation. Our project page isavailable at \url{https://binghao-huang.github.io/3D-ViTac/}.</description>
      <author>example@mail.com (Binghao Huang, Yixuan Wang, Xinyi Yang, Yiyue Luo, Yunzhu Li)</author>
      <guid isPermaLink="false">2410.24091v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>EMGBench: Benchmarking Out-of-Distribution Generalization and Adaptation for Electromyography</title>
      <link>http://arxiv.org/abs/2410.23625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了第一个通用化和适应性基准，利用机器学习评估肌电图（EMG）分类算法在分布外性能方面的表现。&lt;h4&gt;目的&lt;/h4&gt;评估EMG分类器在处理不同于训练分布的输入时的能力，以便在实际应用中作为控制接口使用。&lt;h4&gt;方法&lt;/h4&gt;建立一个新的分布外基准，包括两个主要任务：1) 跨个体分类，2) 使用时间序列的训练-测试划分进行适应性。&lt;h4&gt;主要发现&lt;/h4&gt;该基准涵盖九个数据集，是当前最大的EMG数据集集合，并引入了一个新的数据集，包含一种新型、易穿戴的高密度EMG设备进行数据收集。&lt;h4&gt;结论&lt;/h4&gt;由于缺乏开源基准，EMG研究社区在比较准确性结果时面临挑战。该基准为研究人员提供了分析EMG数据集分布外性能的宝贵资源。&lt;h4&gt;总结&lt;/h4&gt;我们的代码和新数据集可在emgbench.github.io找到，推动了EMG研究的进一步发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces the first generalization and adaptation benchmark usingmachine learning for evaluating out-of-distribution performance ofelectromyography (EMG) classification algorithms. The ability of an EMGclassifier to handle inputs drawn from a different distribution than thetraining distribution is critical for real-world deployment as a controlinterface. By predicting the user's intended gesture using EMG signals, we cancreate a wearable solution to control assistive technologies, such ascomputers, prosthetics, and mobile manipulator robots. This newout-of-distribution benchmark consists of two major tasks that have utility forbuilding robust and adaptable control interfaces: 1) intersubjectclassification and 2) adaptation using train-test splits for time-series. Thisbenchmark spans nine datasets--the largest collection of EMG datasets in abenchmark. Among these, a new dataset is introduced, featuring a novel,easy-to-wear high-density EMG wearable for data collection. The lack ofopen-source benchmarks has made comparing accuracy results between paperschallenging for the EMG research community. This new benchmark providesresearchers with a valuable resource for analyzing practical measures ofout-of-distribution performance for EMG datasets. Our code and data from ournew dataset can be found at emgbench.github.io.</description>
      <author>example@mail.com (Jehan Yang, Maxwell Soh, Vivianna Lieu, Douglas J Weber, Zackory Erickson)</author>
      <guid isPermaLink="false">2410.23625v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Two-Phase Switched Reluctance Motors: Optimal Magnet Placement and Drive System for Torque Density and Efficiency Enhancement</title>
      <link>http://arxiv.org/abs/2410.24121v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大多数高维变点检测方法假设误差过程是平稳的，而变点在各维度上同步发生。随着时间序列维度的增加，这些假设越来越可能被违反，可能会显著降低方法的敏感性和准确性。&lt;h4&gt;目的&lt;/h4&gt;提出AJDN（非平稳噪声下的异步跳变检测），以应对高维时间序列中非平稳噪声和异步跳变的问题。&lt;h4&gt;方法&lt;/h4&gt;AJDN是一种高维多尺度跳变检测方法，旨在检测和估计平滑变化的均值函数中的跳变，允许不同维度的跳变不同时发生。&lt;h4&gt;主要发现&lt;/h4&gt;AJDN在渐近意义上能够以规定的概率准确检测跳变数量，并在异步跳变假设下，其跳变位置估计的准确性几乎是最优的。通过模拟研究，表明AJDN在各种平稳和非平稳的高维时间序列中表现出强大的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;AJDN相较于现有的一些高维变点检测方法表现出强劲的性能，并成功应用于地震时间序列，准确检测复杂时间动态中的跳变。&lt;h4&gt;总结&lt;/h4&gt;AJDN为高维非平稳时间序列的变点检测提供了一种有效的方法，尤其是在存在异步跳变时，展示了其应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper focuses on designing new motors with high torque density, which iscrucial for applications ranging from electric vehicles to robotics. We proposea double-teeth C-core switched reluctance motor with hybrid excitation,integrating permanent magnets and a novel drive technique to enhance motortorque density. We explore three magnet placement configurations to maximizetorque. A common challenge with most self-starting methods used in two-phaseSRMs is the generation of negative torque, which reduces the motor's torquedensity. Our adopted self-starting method minimizes negative torque, and weintroduce a new drive strategy to control the switching on and off, effectivelyeliminating negative torque. Additionally, magnetic equivalent circuits aredeveloped for the analytical design and theoretical analysis of allconfigurations. The SRMs under study are prototyped and tested, and theirperformances are evaluated in terms of torque-angle characteristics, current,and voltage. Both experimental and simulation results validate theeffectiveness of the PM-assisted SRMs in enhancing torque density andefficiency.</description>
      <author>example@mail.com (Gholamreza Davarpanah, Sajjad Mohammadi, James L. Kirtley)</author>
      <guid isPermaLink="false">2410.24121v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Asynchronous Jump Testing and Estimation in High Dimensions Under Complex Temporal Dynamics</title>
      <link>http://arxiv.org/abs/2410.23706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大多数高维变点检测方法假设误差过程是平稳的，而变点在各维度上同步发生。随着时间序列维度的增加，这些假设越来越可能被违反，可能会显著降低方法的敏感性和准确性。&lt;h4&gt;目的&lt;/h4&gt;提出AJDN（非平稳噪声下的异步跳变检测），以应对高维时间序列中非平稳噪声和异步跳变的问题。&lt;h4&gt;方法&lt;/h4&gt;AJDN是一种高维多尺度跳变检测方法，旨在检测和估计平滑变化的均值函数中的跳变，允许不同维度的跳变不同时发生。&lt;h4&gt;主要发现&lt;/h4&gt;AJDN在渐近意义上能够以规定的概率准确检测跳变数量，并在异步跳变假设下，其跳变位置估计的准确性几乎是最优的。通过模拟研究，表明AJDN在各种平稳和非平稳的高维时间序列中表现出强大的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;AJDN相较于现有的一些高维变点检测方法表现出强劲的性能，并成功应用于地震时间序列，准确检测复杂时间动态中的跳变。&lt;h4&gt;总结&lt;/h4&gt;AJDN为高维非平稳时间序列的变点检测提供了一种有效的方法，尤其是在存在异步跳变时，展示了其应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most high dimensional changepoint detection methods assume the error processis stationary and changepoints occur synchronously across dimensions. Theviolation of these assumptions, which in applied settings is increasinglylikely as the dimensionality of the time series being analyzed grows, candramatically curtail the sensitivity or the accuracy of these methods. Wepropose AJDN (Asynchronous Jump Detection under Nonstationary noise). AJDN is ahigh dimensional multiscale jump detection method that tests and estimatesjumps in an otherwise smoothly varying mean function for high dimensional timeseries with nonstationary noise where the jumps across dimensions may not occurat the same time. AJDN is correct in the sense that it detects the correctnumber of jumps with a prescribed probability asymptotically and its accuracyin estimating the locations of the jumps is asymptotically nearly optimal underthe asynchronous jump assumption. Through a simulation study we demonstrateAJDN's robustness across a wide variety of stationary and nonstationary highdimensional time series, and we show its strong performance relative to someexisting high dimensional changepoint detection methods. We apply AJDN to aseismic time series to demonstrate its ability to accurately detect jumps inreal-world high dimensional time series with complex temporal dynamics.</description>
      <author>example@mail.com (Weichi Wu, David Veitch, Zhou Zhou)</author>
      <guid isPermaLink="false">2410.23706v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Unlocking Mode Programming with Multi-Plane Light Conversion Using Computer-Generated Hologram Optimisation</title>
      <link>http://arxiv.org/abs/2410.23369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;可编程光学设备提高了空间复用系统的性能和灵活性，能够在多模光纤等空间多样性传输介质中以高阶特征模式传输支路信号。&lt;h4&gt;目的&lt;/h4&gt;通过波前整形实现传输介质的可扩展性，支持通道对角化和准单输入单输出操作。&lt;h4&gt;方法&lt;/h4&gt;采用多平面光转换（MPLC）等可编程模式复用配置，利用空间光调制器（SLM）同时发射任意子集的空间支路信号。&lt;h4&gt;主要发现&lt;/h4&gt;与传统的波前匹配算法（WMA）相比，计算机生成的全息图算法（如直接搜索）能够显著提高性能，平均模式消光比可提高多达15 dB，插入损耗恶化小于3 dB。&lt;h4&gt;结论&lt;/h4&gt;可编程模式复用器具备适应优化传输功能的能力，除了常规的LP模式传输外，还可以应用于施密特模式，这些模式是从测得的传输矩阵中导出的最低串扰空间特征通道。&lt;h4&gt;总结&lt;/h4&gt;这一研究表明，通过改进的算法和可编程设备，可以有效提升空间分复用系统的吞吐量，以应对日益增长的流量需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Programmable optical devices provide performance enhancement and flexibilityto spatial multiplexing systems enabling transmission of tributaries inhigh-order eigenmodes of spatially-diverse transmission media, like multimodefiber (MMF). Wavefront shaping with spatial light modulators (SLMs) facilitatesscalability of the transmission media by allowing for channel diagonalizationand quasi-single-input single-output operation. Programmable mode multiplexingconfigurations like multi-plane light conversion (MPLC) utilise the SLM andoffer the potential to simultaneously launch an arbitrary subset of spatialtributaries in any N-mode MMF. Such programmable optical processor would enablethe throughput of space-division multiplexing (SDM) systems to be progressivelyincreased by addressing a growing number of tributaries over one MMF and inthis way meet a growing traffic demand - similarly to the wavelength-divisionmultiplexing evolution path. Conventionally, MPLC phasemasks are calculatedusing the wavefront matching algorithm (WMA). However, this method does notexploit the full potential of programmable mode multiplexers. We show, thatcomputer-generated hologram algorithms like direct search enable significantimprovement compared to the traditional WMA-approach. Such gains are enabled bytailored cost functions with dynamic constraints concerning insertion loss aswell as mode extinction ratio. We show that average mode extinction ratio canbe greatly improved by as much as 15 dB at the expense of insertion lossdeterioration of &lt; 3 dB. One particular feature of programmable modemultiplexers is the adaptability to optimised transmission functions. Besidesconventional LP modes transmission, we employ our approach on Schmidt modes,which are spatial eigenchannels with minimum crosstalk derived from a measuredtransmission matrix.</description>
      <author>example@mail.com (Stefan Rothe, Fabio Barbosa, Jürgen W. Czarske, Filipe M. Ferreira)</author>
      <guid isPermaLink="false">2410.23369v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Language-Driven Policy Distillation for Cooperative Driving in Multi-Agent Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2410.24152v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;连接与自动驾驶车辆（CAVs）的协作驾驶技术对提高交通系统的效率和安全性至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高合作代理的学习能力，同时确保决策效率和成本效益。&lt;h4&gt;方法&lt;/h4&gt;提出了一种语言驱动的政策蒸馏方法LDPD，通过一个基于大语言模型（LLM）的教师代理训练较小的学生代理，指导多智能体强化学习（MARL）的探索。&lt;h4&gt;主要发现&lt;/h4&gt;学生代理在最小的教师指导下能够快速提高其能力，并最终超越教师的表现。&lt;h4&gt;结论&lt;/h4&gt;与基线方法相比，本方法在性能和学习效率上表现更佳。&lt;h4&gt;总结&lt;/h4&gt;LDPD框架通过复杂的协作决策推理和高质量的教学经验，提升了CAVs的决策能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The cooperative driving technology of Connected and Autonomous Vehicles(CAVs) is crucial for improving the efficiency and safety of transportationsystems. Learning-based methods, such as Multi-Agent Reinforcement Learning(MARL), have demonstrated strong capabilities in cooperative decision-makingtasks. However, existing MARL approaches still face challenges in terms oflearning efficiency and performance. In recent years, Large Language Models(LLMs) have rapidly advanced and shown remarkable abilities in varioussequential decision-making tasks. To enhance the learning capabilities ofcooperative agents while ensuring decision-making efficiency andcost-effectiveness, we propose LDPD, a language-driven policy distillationmethod for guiding MARL exploration. In this framework, a teacher agent basedon LLM trains smaller student agents to achieve cooperative decision-makingthrough its own decision-making demonstrations. The teacher agent enhances theobservation information of CAVs and utilizes LLMs to perform complexcooperative decision-making reasoning, which also leverages carefully designeddecision-making tools to achieve expert-level decisions, providing high-qualityteaching experiences. The student agent then refines the teacher's priorknowledge into its own model through gradient policy updates. The experimentsdemonstrate that the students can rapidly improve their capabilities withminimal guidance from the teacher and eventually surpass the teacher'sperformance. Extensive experiments show that our approach demonstrates betterperformance and learning efficiency compared to baseline methods.</description>
      <author>example@mail.com (Jiaqi Liu, Chengkai Xu, Peng Hang, Jian Sun, Mingyu Ding, Wei Zhan, Masayoshi Tomizuka)</author>
      <guid isPermaLink="false">2410.24152v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>LSEAttention is All You Need for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.23749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages with referencing, 1 figure, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于Transformer的架构在自然语言处理和计算机视觉中取得了显著成功，但在多变量长期预测中表现常常不如简单的线性基线。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法LSEAttention，以提升Transformer在多变量时间序列预测中的性能。&lt;h4&gt;方法&lt;/h4&gt;LSEAttention旨在解决传统注意力机制导致的熵崩溃和训练不稳定的问题。&lt;h4&gt;主要发现&lt;/h4&gt;LSEAttention在多个真实世界的多变量时间序列数据集上验证有效，超越了现有时间序列Transformer模型的表现，并在某些数据集上超过了先进模型。&lt;h4&gt;结论&lt;/h4&gt;LSEAttention能够充分发挥Transformer在多变量时间序列预测中的潜力。&lt;h4&gt;总结&lt;/h4&gt;通过引入LSEAttention，Transformer模型在多变量长期预测任务中表现出更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer-based architectures have achieved remarkable success in naturallanguage processing and computer vision. However, their performance inmultivariate long-term forecasting often lags behind simpler linear baselines.Previous studies have identified the traditional attention mechanism as asignificant factor contributing to this limitation. To unlock the fullpotential of transformers for multivariate time series forecasting, I introduce\textbf{LSEAttention}, an approach designed to address entropy collapse andtraining instability commonly observed in transformer models. I validate theeffectiveness of LSEAttention across various real-world multivariate timeseries datasets, demonstrating that it not only outperforms existing timeseries transformer models but also exceeds the performance of somestate-of-the-art models on specific datasets.</description>
      <author>example@mail.com (Dizhen Liang)</author>
      <guid isPermaLink="false">2410.23749v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling User Satisfaction and Creator Productivity Trade-Offs in Recommendation Platforms</title>
      <link>http://arxiv.org/abs/2410.23683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;用户生成内容（UGC）平台上的推荐算法显著影响创作者的内容生产动机。&lt;h4&gt;目的&lt;/h4&gt;探讨推荐算法如何影响内容池的数量和多样性，从而影响平台的可持续性。&lt;h4&gt;方法&lt;/h4&gt;通过理论和实证研究，分析相关性驱动政策与探索政策的影响。&lt;h4&gt;主要发现&lt;/h4&gt;纯粹的相关性驱动政策虽然能提高短期用户满意度，但会削弱内容池的长期丰富性；而更强的探索政策可能会稍微降低用户满意度，但能促进更高的内容生产量。&lt;h4&gt;结论&lt;/h4&gt;UGC平台上存在即时用户满意度与整体内容生产之间的根本权衡。&lt;h4&gt;应用&lt;/h4&gt;提出了一种高效的优化方法，以识别最佳探索强度，平衡用户和创作者的参与度。&lt;h4&gt;总结&lt;/h4&gt;该模型可作为UGC平台推荐算法部署前的审计工具，有助于将短期目标与可持续的长期目标对齐。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; On User-Generated Content (UGC) platforms, recommendation algorithmssignificantly impact creators' motivation to produce content as they competefor algorithmically allocated user traffic. This phenomenon subtly shapes thevolume and diversity of the content pool, which is crucial for the platform'ssustainability. In this work, we demonstrate, both theoretically andempirically, that a purely relevance-driven policy with low explorationstrength boosts short-term user satisfaction but undermines the long-termrichness of the content pool. In contrast, a more aggressive exploration policymay slightly compromise user satisfaction but promote higher content creationvolume. Our findings reveal a fundamental trade-off between immediate usersatisfaction and overall content production on UGC platforms. Building on thisfinding, we propose an efficient optimization method to identify the optimalexploration strength, balancing user and creator engagement. Our model canserve as a pre-deployment audit tool for recommendation algorithms on UGCplatforms, helping to align their immediate objectives with sustainable,long-term goals.</description>
      <author>example@mail.com (Fan Yao, Yiming Liao, Jingzhou Liu, Shaoliang Nie, Qifan Wang, Haifeng Xu, Hongning Wang)</author>
      <guid isPermaLink="false">2410.23683v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Case ID detection based on time series data -- the mining use case</title>
      <link>http://arxiv.org/abs/2410.23846v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at EdbA'24 - Fifth International Workshop on Event Data and
  Behavioral Analytics, ICPM 2024, Kopenhagen, Denmark&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;过程挖掘在商业流程分析和重工业中越来越受欢迎，需要特定格式的数据，即事件日志，基本结构包括案例标识符、活动名称和时间戳。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于规则的新算法，通过识别选定变量短期均值的显著变化来检测案例标识符。&lt;h4&gt;方法&lt;/h4&gt;使用监控系统提供的低级传感器读取的时间序列数据进行模式识别，并在挖掘用例中展示解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;开发的算法在大多数情况下正确检测数据集中的标识符，F1分数分别达到96.8%和97%；在制造领域的数据集上，F1分数为92.6%。&lt;h4&gt;结论&lt;/h4&gt;算法在处理有异常值和无异常值的数据集时表现良好，显示出其在工业过程中的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种有效的算法，能够从传感器数据中识别出案例标识符，推动了过程挖掘技术在工业应用中的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Process mining gains increasing popularity in business process analysis, alsoin heavy industry. It requires a specific data format called an event log, withthe basic structure including a case identifier (case ID), activity (event)name, and timestamp. In the case of industrial processes, data is very oftenprovided by a monitoring system as time series of low level sensor readings.This data cannot be directly used for process mining since there is no explicitmarking of activities in the event log, and sometimes, case ID is not provided.We propose a novel rule-based algorithm for identification patterns, based onthe identification of significant changes in short-term mean values of selectedvariable to detect case ID. We present our solution on the mining use case. Wecompare computed results (identified patterns) with expert labels of the samedataset. Experiments show that the developed algorithm in the most of the casescorrectly detects IDs in datasets with and without outliers reaching F1 scorevalues: 96.8% and 97% respectively. We also evaluate our algorithm on datasetfrom manufacturing domain reaching value 92.6% for F1 score.</description>
      <author>example@mail.com (Edyta Brzychczy, Tomasz Pełech-Pilichowski, Ziemowit Dworakowski)</author>
      <guid isPermaLink="false">2410.23846v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Physics of collective transport and traffic phenomena in biology: progress in 20 years</title>
      <link>http://arxiv.org/abs/2410.23735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages including 8 figures; to be submitted to "Physics of Life
  Reviews"&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;过去20年在生物学中运输和交通现象方面取得了巨大进展。&lt;h4&gt;目的&lt;/h4&gt;概述这一时期的主要进展。&lt;h4&gt;方法&lt;/h4&gt;比较单个微米级货物的细胞内集体运输与蚂蚁团队运输的相似性和差异，并使用不对称简单排除过程（ASEP）模型进行生物学扩展。&lt;h4&gt;主要发现&lt;/h4&gt;{'货物运输': '细胞内的分子机器（如RNA聚合酶和核糖体）与蚂蚁的运输特征在模型中表现出相似性。', '基因表达': "RNA聚合酶和核糖体的交通对基因表达中的随机和'编程'错误有显著影响。", '蚂蚁行为': '关于掠食性蚂蚁的单车道交通的经验结果以及解决这一难题的尝试。', '军蚁交通': '在军蚁的三车道交通模型中观察到的意外车道变换规则的影响。'}&lt;h4&gt;结论&lt;/h4&gt;蚂蚁在小路上的信息传递（信息素介导的间接沟通）与人类行人交通中的地面场交互之间存在概念相似性。&lt;h4&gt;总结&lt;/h4&gt;提出了与所有类型交通现象相关的重要理论结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enormous progress have been made in the last 20 years since the publicationof our review \cite{csk05polrev} in this journal on transport and trafficphenomena in biology. In this brief article we present a glimpse of the majoradvances during this period. First, we present similarities and differencesbetween collective intracellular transport of a single micron-size cargo bymultiple molecular motors and that of a cargo particle by a team of ants on thebasis of the common principle of load-sharing. Second, we sketch several modelsall of which are biologically motivated extensions of the Asymmetric SimpleExclusion Process (ASEP); some of these models represent the traffic ofmolecular machines, like RNA polymerase (RNAP) and ribosome, that catalyzetemplate-directed polymerization of RNA and proteins, respectively, whereas fewother models capture the key features of the traffic of ants on trails. Morespecifically, using the ASEP-based models we demonstrate the effects of trafficof RNAPs and ribosomes on random and `programmed' errors in gene expression aswell as on some other subcellular processes. We recall a puzzling empiricalresult on the single-lane traffic of predatory ants {\it Leptogenysprocessionalis} as well as recent attempts to account for this puzzle. We alsomention some surprising effects of lane-changing rules observed in a ASEP-basedmodel for 3-lane traffic of army ants. Finally, we explain the conceptualsimilarities between the pheromone-mediated indirect communication, calledstigmergy, between ants on a trail and the floor-field-mediated interactionbetween humans in a pedestrian traffic. For the floor-field model of humanpedestrian traffic we present a major theoretical result that is relevant fromthe perspective of all types of traffic phenomena.</description>
      <author>example@mail.com (Debashish Chowdhury, Andreas Schadschneider, Katsuhiro Nishinari)</author>
      <guid isPermaLink="false">2410.23735v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>DexMimicGen: Automated Data Generation for Bimanual Dexterous Manipulation via Imitation Learning</title>
      <link>http://arxiv.org/abs/2410.24185v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://dexmimicgen.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模仿学习是教机器人操作技能的有效手段，但数据获取是广泛应用的主要瓶颈，涉及高成本和人力投入。&lt;h4&gt;目的&lt;/h4&gt;解决双手灵巧机器人（如类人机器人）在模仿学习中数据收集的挑战。&lt;h4&gt;方法&lt;/h4&gt;介绍DexMimicGen，一个大规模自动数据生成系统，通过少量人类示范合成轨迹，生成双手灵巧操作的模拟环境。&lt;h4&gt;主要发现&lt;/h4&gt;从60个源人类示范生成了21K个演示，研究了多种数据生成和策略学习决策对代理性能的影响。&lt;h4&gt;结论&lt;/h4&gt;提出了一个真实-模拟-真实的管道，并在实际的类人机器人分类任务中进行了部署。&lt;h4&gt;总结&lt;/h4&gt;DexMimicGen为双手灵巧操作的模仿学习提供了一种可扩展的数据生成解决方案，促进了机器人技能的学习和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning from human demonstrations is an effective means to teachrobots manipulation skills. But data acquisition is a major bottleneck inapplying this paradigm more broadly, due to the amount of cost and human effortinvolved. There has been significant interest in imitation learning forbimanual dexterous robots, like humanoids. Unfortunately, data collection iseven more challenging here due to the challenges of simultaneously controllingmultiple arms and multi-fingered hands. Automated data generation in simulationis a compelling, scalable alternative to fuel this need for data. To this end,we introduce DexMimicGen, a large-scale automated data generation system thatsynthesizes trajectories from a handful of human demonstrations for humanoidrobots with dexterous hands. We present a collection of simulation environmentsin the setting of bimanual dexterous manipulation, spanning a range ofmanipulation behaviors and different requirements for coordination among thetwo arms. We generate 21K demos across these tasks from just 60 source humandemos and study the effect of several data generation and policy learningdecisions on agent performance. Finally, we present a real-to-sim-to-realpipeline and deploy it on a real-world humanoid can sorting task. Videos andmore are at https://dexmimicgen.github.io/</description>
      <author>example@mail.com (Zhenyu Jiang, Yuqi Xie, Kevin Lin, Zhenjia Xu, Weikang Wan, Ajay Mandlekar, Linxi Fan, Yuke Zhu)</author>
      <guid isPermaLink="false">2410.24185v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Large Spatial Model: End-to-end Unposed Images to Semantic 3D</title>
      <link>http://arxiv.org/abs/2410.18956v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Website: https://largespatialmodel.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从有限数量的图像重建和理解3D结构是计算机视觉中的一个成熟问题，传统方法通常将其分解为多个子任务，涉及复杂的数据表示转换。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，直接处理未定位的RGB图像，以实现语义辐射场的生成。&lt;h4&gt;方法&lt;/h4&gt;引入大型空间模型（LSM），通过Transformer架构同时估计几何、外观和语义，结合局部上下文聚合和多尺度融合来提高空间属性回归的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;LSM能够直接从未定位的图像统一多个3D视觉任务，实现实时语义3D重建。&lt;h4&gt;结论&lt;/h4&gt;LSM通过高效的解码器实现了监督的端到端学习，克服了标注3D语义数据的稀缺性，支持自然语言驱动的场景操作。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了LSM在多种任务中的广泛应用，标志着实时语义3D重建的新进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing and understanding 3D structures from a limited number ofimages is a well-established problem in computer vision. Traditional methodsusually break this task into multiple subtasks, each requiring complextransformations between different data representations. For instance, densereconstruction through Structure-from-Motion (SfM) involves converting imagesinto key points, optimizing camera parameters, and estimating structures.Afterward, accurate sparse reconstructions are required for further densemodeling, which is subsequently fed into task-specific neural networks. Thismulti-step process results in considerable processing time and increasedengineering complexity.  In this work, we present the Large Spatial Model (LSM), which processesunposed RGB images directly into semantic radiance fields. LSM simultaneouslyestimates geometry, appearance, and semantics in a single feed-forwardoperation, and it can generate versatile label maps by interacting withlanguage at novel viewpoints. Leveraging a Transformer-based architecture, LSMintegrates global geometry through pixel-aligned point maps. To enhance spatialattribute regression, we incorporate local context aggregation with multi-scalefusion, improving the accuracy of fine local details. To tackle the scarcity oflabeled 3D semantic data and enable natural language-driven scene manipulation,we incorporate a pre-trained 2D language-based segmentation model into a3D-consistent semantic feature field. An efficient decoder then parameterizes aset of semantic anisotropic Gaussians, facilitating supervised end-to-endlearning. Extensive experiments across various tasks show that LSM unifiesmultiple 3D vision tasks directly from unposed images, achieving real-timesemantic 3D reconstruction for the first time.</description>
      <author>example@mail.com (Zhiwen Fan, Jian Zhang, Wenyan Cong, Peihao Wang, Renjie Li, Kairun Wen, Shijie Zhou, Achuta Kadambi, Zhangyang Wang, Danfei Xu, Boris Ivanovic, Marco Pavone, Yue Wang)</author>
      <guid isPermaLink="false">2410.18956v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Deneb and the alpha Cygni Variables</title>
      <link>http://arxiv.org/abs/2410.23985v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 18 figures, submitted to Proceedings for the 43rd Annual
  Conference of the Society for Astronomical Sciences SAS-2024 Symposium on
  Telescope Science, eds. John C. Martin, Robert K. Buchheim, Robert M. Gill,
  Wayne Green, and John Menke,
  https://socastrosci.org/wp-content/uploads/2024/08/2024-Proceedings_Ver1.3d.pdf&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Deneb 是原型 alpha Cygni 变量，属于蓝白色超巨星，显示出不规则的亮度和径向速度变化，周期约为 12 天。&lt;h4&gt;目的&lt;/h4&gt;利用 8.6 年的光度数据集更好地表征 Deneb 的变化行为。&lt;h4&gt;方法&lt;/h4&gt;分析 Solar Mass Ejection Imager (SMEI) 的光度数据，并比较 alpha Cyg 变量的其他星体的光度曲线。&lt;h4&gt;主要发现&lt;/h4&gt;Deneb 的脉动恢复间隔并不固定，最常见的间隔在 100 到 120 天之间，有时会跳过一个或多个间隔。&lt;h4&gt;结论&lt;/h4&gt;alpha Cyg 变量可能不是一个同质群体，其变异机制可能各异。尚不清楚它们是否在赫兹sprung-Russell 图的第一次或第二次穿越中。&lt;h4&gt;未来计划&lt;/h4&gt;将考察 BRITE Constellation 的数据，处理其他明亮 alpha Cyg 变量的 SMEI 数据，并比较 AAVSO 和 TESS 的 6 Cas 光度曲线。&lt;h4&gt;总结&lt;/h4&gt;研究揭示了 Deneb 的复杂脉动行为，并为 alpha Cyg 变量的理解提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deneb, the prototype alpha Cygni variable, is a blue-white supergiant thatshows irregular variability with quasi-period around 12 days in brightness andradial velocity. Abt et al. (2023) found that larger amplitude 12-dayvariations appear to resume abruptly and at an arbitrary phase and damp outafter several cycles, with an interval of around 70 days between theseresumptions. Here we make use of an 8.6-year photometric data set for Denebfrom the Solar Mass Ejection Imager (SMEI) to better characterize thisbehavior. We find that the interval between pulsation resumptions is not exact,with the most common intervals between 100 and 120 days. Sometimes one or moreintervals are skipped. We also examine AAVSO and Transiting Exoplanet SurveySatellite (TESS) light curves for alpha Cyg variables Rigel, Saiph, and Alnilamin Orion, Aludra in Canis Major, and 6 Cas to compare with the behavior ofalpha Cyg. Except for 6 Cas, the time series are too short, or the observationstoo infrequent to draw any conclusions about similarities between the behaviorof these stars and alpha Cyg. We also summarize results of evolution andpulsation modeling for Deneb and alpha Cyg variables from the literature. Thealpha Cyg variables may not be a homogenous group with a common mechanism fortheir variability. It has not been determined whether they are on the firstcrossing of the Hertzsprung-Russell diagram toward the red supergiant phase orare on their second crossing after having been red supergiants. Future plansinclude examining BRITE Constellation data for Deneb, processing SMEI data forother bright alpha Cyg variables, and comparing 6 Cas light curves from AAVSOand TESS data taken concurrently.</description>
      <author>example@mail.com (Joyce A. Guzik, Brian Kloppenborg, Jason Jackiewicz)</author>
      <guid isPermaLink="false">2410.23985v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Tracer: A Tool for Race Detection in Software Defined Network Models</title>
      <link>http://arxiv.org/abs/2410.23763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proceedings FROM 2024, arXiv:2410.23020&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;软件定义网络（SDN）是一种新的计算机网络范式，采用解耦架构，将网络分为数据平面和控制平面。&lt;h4&gt;目的&lt;/h4&gt;本文旨在介绍Tracer工具，该工具可以自动检测和解释DyNetKAT SDN模型中的数据竞争问题。&lt;h4&gt;方法&lt;/h4&gt;Tracer工具利用DyNetKAT的公理化，并基于Lamport向量时钟实现SDN中的竞争检测。&lt;h4&gt;主要发现&lt;/h4&gt;DyNetKAT是一个正式框架，用于建模和分析SDN行为，具有强大的操作语义和在Maude中实现的完整公理化。&lt;h4&gt;结论&lt;/h4&gt;Tracer是一个公开可用的工具，能够有效检测SDN中的数据竞争。&lt;h4&gt;总结&lt;/h4&gt;SDN的异步分布特性可能导致控制平面与数据平面之间的消息传递出现数据竞争，Tracer工具为解决此问题提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.4204/EPTCS.410.6&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Software Defined Networking (SDN) has become a new paradigm in computernetworking, introducing a decoupled architecture that separates the networkinto the data plane and the control plane. The control plane acts as thecentralized brain, managing configuration updates and network management tasks,while the data plane handles traffic based on the configurations provided bythe control plane. Given its asynchronous distributed nature, SDN canexperience data races due to message passing between the control and dataplanes. This paper presents Tracer, a tool designed to automatically detect andexplain the occurrence of data races in DyNetKAT SDN models. DyNetKAT is aformal framework for modeling and analyzing SDN behaviors, with robustoperational semantics and a complete axiomatization implemented in Maude. Builton NetKAT, a language leveraging Kleene Algebra with Tests to express dataplane forwarding behavior, DyNetKAT extends these capabilities by addingprimitives for communication between the control and data planes. Tracerexploits the DyNetKAT axiomatization and enables race detection in SDNs basedon Lamport vector clocks. Tracer is a publicly available tool.</description>
      <author>example@mail.com (Georgiana Caltais, Mahboobeh Zangiabady, Ervin Zvirbulis)</author>
      <guid isPermaLink="false">2410.23763v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>A Sagittal Planar Ankle-Foot Prosthesis with Powered Plantarflexion and Socket Alignment</title>
      <link>http://arxiv.org/abs/2410.24196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 8 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;动力足踝假肢通过辅助起步可降低行走能量消耗，但可能忽视慢性疼痛、刺激、压疮发展及最终的关节炎问题。&lt;h4&gt;目的&lt;/h4&gt;设计并验证一种新型的胫骨截肢假肢，以减少用户的努力和假肢插座的交互负载。&lt;h4&gt;方法&lt;/h4&gt;基于预测生物力学仿真，设计了一种具有10厘米运动范围的非仿生前后移动自由度的假肢。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在行走时能够产生高达160 N-m的足底屈曲扭矩和394 N的前后平移力，控制带宽约为7 Hz。&lt;h4&gt;结论&lt;/h4&gt;原型能够复制仿真假肢的动态，展示了使用预测生物力学仿真作为可穿戴机器人设计工具的优势和实践考量。&lt;h4&gt;总结&lt;/h4&gt;本研究为提升假肢设计提供了重要见解，强调了在提供机械工作时兼顾用户舒适和健康的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Powered ankle-foot prostheses can often reduce the energy cost of walking byassisting with push-off. However, focus on providing mechanical work may leadto ignoring or exacerbating common issues with chronic pain, irritation,pressure ulcer development, and eventual osteoarthritis in persons withamputation. This paper presents the design and validation of a noveltranstibial prosthesis informed by predictive biomechanical simulations of gaitwhich minimize a combination of user effort and interaction loading from theprosthesis socket. From these findings, the device was designed with anon-biomimetic anterior-posterior translation degree of freedom with a 10 cmrange of motion which is primarily position-controlled to change the alignmentof the prosthetic foot with the residual limb. The system is both mobile andtethered, with the batteries, actuators, and majority of electronics located ina small backpack. Mechanical loads are transmitted through cables to theprosthesis, minimizing the distal mass carriage required. We measured torqueand force sensing accuracy, open loop actuator performance, closed loop torqueand position control bandwidth, and torque and position tracking error duringwalking. The system is capable of producing up to 160 N-m of plantarflexiontorque and 394 N of AP translation force with a closed loop control bandwidthof about 7 Hz in both degrees of freedom. Torque tracking during walking wasaccurate within about 10 N-m but position tracking was substantially affectedby phase lag, possibly due to cable slack in the bidirectional mechanism. Theprototype was capable of replicating our simulated prosthesis dynamics duringgait and offers useful insights into the advantages and the practicalconsiderations of using predictive biomechanical simulation as a design toolfor wearable robots.</description>
      <author>example@mail.com (Mark A. Price, Frank C. Sup IV)</author>
      <guid isPermaLink="false">2410.24196v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Ada-MSHyper: Adaptive Multi-Scale Hypergraph Transformer for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.23992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS, 21 pages, and 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;虽然基于变压器的方法在多尺度时间模式交互建模中取得了很大成功，但仍面临两个关键挑战。&lt;h4&gt;目的&lt;/h4&gt;提出自适应多尺度超图变压器（Ada-MSHyper）用于时间序列预测。&lt;h4&gt;方法&lt;/h4&gt;设计了自适应超图学习模块以建模组间交互，并引入多尺度交互模块以促进不同尺度下更全面的模式交互。同时，引入节点和超边约束机制以聚类具有相似语义信息的节点，并区分每个尺度内的时间变化。&lt;h4&gt;主要发现&lt;/h4&gt;在11个真实世界数据集上的广泛实验表明，Ada-MSHyper在长程、短程和超长程时间序列预测中分别减少了4.56%、10.38%和4.97%的均方误差，达到最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;Ada-MSHyper有效解决了时间序列预测中的信息利用瓶颈和时间变化问题。&lt;h4&gt;总结&lt;/h4&gt;该研究为时间序列预测提供了一种新的方法，显示了其在减少预测误差方面的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shangzongjiang/Ada-MSHyper&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although transformer-based methods have achieved great success in multi-scaletemporal pattern interaction modeling, two key challenges limit their furtherdevelopment: (1) Individual time points contain less semantic information, andleveraging attention to model pair-wise interactions may cause the informationutilization bottleneck. (2) Multiple inherent temporal variations (e.g.,rising, falling, and fluctuating) entangled in temporal patterns. To this end,we propose Adaptive Multi-Scale Hypergraph Transformer (Ada-MSHyper) for timeseries forecasting. Specifically, an adaptive hypergraph learning module isdesigned to provide foundations for modeling group-wise interactions, then amulti-scale interaction module is introduced to promote more comprehensivepattern interactions at different scales. In addition, a node and hyperedgeconstraint mechanism is introduced to cluster nodes with similar semanticinformation and differentiate the temporal variations within each scales.Extensive experiments on 11 real-world datasets demonstrate that Ada-MSHyperachieves state-of-the-art performance, reducing prediction errors by an averageof 4.56%, 10.38%, and 4.97% in MSE for long-range, short-range, andultra-long-range time series forecasting, respectively. Code is available athttps://github.com/shangzongjiang/Ada-MSHyper.</description>
      <author>example@mail.com (Zongjiang Shang, Ling Chen, Binqing wu, Dongliang Cui)</author>
      <guid isPermaLink="false">2410.23992v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map</title>
      <link>http://arxiv.org/abs/2410.23780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;确保交通标志法规的遵守对于人类和自动驾驶车辆的导航至关重要。&lt;h4&gt;目的&lt;/h4&gt;引入MapDR数据集，以填补当前基准数据集中对交通标志与车道操作整合任务的忽视。&lt;h4&gt;方法&lt;/h4&gt;MapDR是一个新颖的数据集，旨在从交通标志提取驾驶规则，并与向量化的高精度地图关联。&lt;h4&gt;主要发现&lt;/h4&gt;MapDR包含超过10,000个注释视频片段，捕捉交通标志法规与车道之间的复杂关系。&lt;h4&gt;结论&lt;/h4&gt;通过定义两个关键子任务，MapDR为推动自动驾驶技术提供了强有力的基线，填补了交通标志规则整合的关键空白。&lt;h4&gt;总结&lt;/h4&gt;该研究为可靠的自动导航系统的发展做出了重要贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring adherence to traffic sign regulations is essential for both humanand autonomous vehicle navigation. While current benchmark datasets concentrateon lane perception or basic traffic sign recognition, they often overlook theintricate task of integrating these regulations into lane operations.Addressing this gap, we introduce MapDR, a novel dataset designed for theextraction of Driving Rules from traffic signs and their association withvectorized, locally perceived HD Maps. MapDR features over 10,000 annotatedvideo clips that capture the intricate correlation between traffic signregulations and lanes. We define two pivotal sub-tasks: 1) Rule Extraction fromTraffic Sign, which accurately deciphers regulatory instructions, and 2)Rule-Lane Correspondence Reasoning, which aligns these rules with theirrespective lanes. Built upon this benchmark, we provide a multimodal solutionthat offers a strong baseline for advancing autonomous driving technologies. Itfills a critical gap in the integration of traffic sign rules, contributing tothe development of reliable autonomous navigation systems.</description>
      <author>example@mail.com (Xinyuan Chang, Maixuan Xue, Xinran Liu, Zheng Pan, Xing Wei)</author>
      <guid isPermaLink="false">2410.23780v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion</title>
      <link>http://arxiv.org/abs/2410.24203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS2024, Project: https://github.com/zju3dv/DiffPano; Code:
  https://github.com/zju3dv/DiffPano&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;扩散方法在2D图像和3D物体生成方面取得了显著成就，但3D场景和360度图像的生成受到限制。&lt;h4&gt;目的&lt;/h4&gt;解决生成3D场景和360度图像的局限性，特别是由于场景数据集数量有限和3D场景复杂性等问题。&lt;h4&gt;方法&lt;/h4&gt;建立一个大规模的全景视频-文本数据集，并提出DiffPano框架，通过对单视角文本到全景的扩散模型进行微调，设计球面极点感知的多视角扩散模型。&lt;h4&gt;主要发现&lt;/h4&gt;DiffPano能够生成具有规模、一致性和多样性的全景图像，且能处理未见过的文本描述和相机姿态。&lt;h4&gt;结论&lt;/h4&gt;DiffPano展示了在全景场景生成方面的强大潜力，克服了多视角一致性生成的挑战。&lt;h4&gt;总结&lt;/h4&gt;通过DiffPano框架，可以实现更为一致和多样化的全景图像生成，从而推动3D场景生成的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zju3dv/diffpano&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion-based methods have achieved remarkable achievements in 2D image or3D object generation, however, the generation of 3D scenes and even$360^{\circ}$ images remains constrained, due to the limited number of scenedatasets, the complexity of 3D scenes themselves, and the difficulty ofgenerating consistent multi-view images. To address these issues, we firstestablish a large-scale panoramic video-text dataset containing millions ofconsecutive panoramic keyframes with corresponding panoramic depths, cameraposes, and text descriptions. Then, we propose a novel text-driven panoramicgeneration framework, termed DiffPano, to achieve scalable, consistent, anddiverse panoramic scene generation. Specifically, benefiting from the powerfulgenerative capabilities of stable diffusion, we fine-tune a single-viewtext-to-panorama diffusion model with LoRA on the established panoramicvideo-text dataset. We further design a spherical epipolar-aware multi-viewdiffusion model to ensure the multi-view consistency of the generated panoramicimages. Extensive experiments demonstrate that DiffPano can generate scalable,consistent, and diverse panoramic images with given unseen text descriptionsand camera poses.</description>
      <author>example@mail.com (Weicai Ye, Chenhao Ji, Zheng Chen, Junyao Gao, Xiaoshui Huang, Song-Hai Zhang, Wanli Ouyang, Tong He, Cairong Zhao, Guofeng Zhang)</author>
      <guid isPermaLink="false">2410.24203v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>On testing for independence between generalized error models of several time series</title>
      <link>http://arxiv.org/abs/2410.24003v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出新的基于copula的多元时间序列模型，适用于连续、离散或两者混合的分布。&lt;h4&gt;目的&lt;/h4&gt;扩展现有的随机波动模型和状态切换模型，并提供独立性检验的统计方法。&lt;h4&gt;方法&lt;/h4&gt;定义基于滞后广义误差的经验过程族，展示其联合渐进分布为高斯分布，并与各个时间序列的估计参数无关。&lt;h4&gt;主要发现&lt;/h4&gt;使用Moebius变换获得可处理的协方差，并提出基于Cramer-von Mises统计量和依赖测度的多个检验统计量，以及可视化依赖关系的图形方法。&lt;h4&gt;结论&lt;/h4&gt;通过数值实验评估了所提检验的效力，并展示了对金融数据和犯罪数据的应用实例，涵盖了离散和连续情况。&lt;h4&gt;总结&lt;/h4&gt;所有开发的方法论已在CRAN包IndGenErrors中实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose new copula-based models for multivariate time series havingcontinuous or discrete distributions, or a mixture of both. These modelsinclude stochastic volatility models and regime-switching models. We alsopropose statistics for testing independence between the generalized errors ofthese models, extending previous results of Duchesne, Ghoudi and Remillard(2012) obtained for stochastic volatility models. We define families ofempirical processes constructed from lagged generalized errors, and we showthat their joint asymptotic distributions are Gaussian and independent of theestimated parameters of the individual time series. Moebius transformations ofthe empirical processes are used to obtain tractable covariances. Several testsstatistics are then proposed, based on Cramer-von Mises statistics anddependence measures, as well as graphical methods to visualize the dependence.In addition, numerical experiments are performed to assess the power of theproposed tests. Finally, to show the usefulness of our methodologies, examplesof applications for financial data and crime data are given to cover bothdiscrete and continuous cases. ll developed methodologies are implemented inthe CRAN package IndGenErrors.</description>
      <author>example@mail.com (Kilani Ghoudi, Bouchra R. Nasri, Bruno N. Remillard)</author>
      <guid isPermaLink="false">2410.24003v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Zonal RL-RRT: Integrated RL-RRT Path Planning with Collision Probability and Zone Connectivity</title>
      <link>http://arxiv.org/abs/2410.24205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高维空间中的路径规划面临显著挑战，特别是在时间效率和成功率方面。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的路径规划算法ZonalRL-RRT，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;该算法利用kd-tree分区将地图划分为区域，同时处理区域连通性，确保区域间的无缝过渡，并使用Q学习作为高层决策者。&lt;h4&gt;主要发现&lt;/h4&gt;在森林状地图中，该算法在时间效率上比基本采样方法（如RRT和RRT*）提高了3倍；在运行时间上比启发式引导方法（如BIT*和Informed RRT*）提高了1.5倍，同时在2D到6D环境中保持了可靠的成功率。&lt;h4&gt;结论&lt;/h4&gt;相比于基于学习的方法（如NeuralRRT*和MPNetSMP），以及启发式RRT*J，该算法在相同环境中的平均性能提高了1.5倍。&lt;h4&gt;应用&lt;/h4&gt;通过在MuJoCo环境中对UR10e臂操控器的仿真评估了算法的有效性。&lt;h4&gt;总结&lt;/h4&gt;该方法通过区域划分和强化学习实现自适应高层规划，使算法能够在多样化环境中适应灵活政策，成为先进路径规划的多功能工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Path planning in high-dimensional spaces poses significant challenges,particularly in achieving both time efficiency and a fair success rate. Toaddress these issues, we introduce a novel path-planning algorithm, ZonalRL-RRT, that leverages kd-tree partitioning to segment the map into zones whileaddressing zone connectivity, ensuring seamless transitions between zones. Bybreaking down the complex environment into multiple zones and using Q-learningas the high-level decision-maker, our algorithm achieves a 3x improvement intime efficiency compared to basic sampling methods such as RRT and RRT* inforest-like maps. Our approach outperforms heuristic-guided methods like BIT*and Informed RRT* by 1.5x in terms of runtime while maintaining robust andreliable success rates across 2D to 6D environments. Compared to learning-basedmethods like NeuralRRT* and MPNetSMP, as well as the heuristic RRT*J, ouralgorithm demonstrates, on average, 1.5x better performance in the sameenvironments. We also evaluate the effectiveness of our approach throughsimulations of the UR10e arm manipulator in the MuJoCo environment. A keyobservation of our approach lies in its use of zone partitioning andReinforcement Learning (RL) for adaptive high-level planning allowing thealgorithm to accommodate flexible policies across diverse environments, makingit a versatile tool for advanced path planning.</description>
      <author>example@mail.com (AmirMohammad Tahmasbi, MohammadSaleh Faghfoorian, Saeed Khodaygan, Aniket Bera)</author>
      <guid isPermaLink="false">2410.24205v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Approximate attention with MLP: a pruning strategy for attention-based model in multivariate time series forecasting</title>
      <link>http://arxiv.org/abs/2410.24023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于注意力的架构在时间序列预测任务中广泛应用，包括时空（STF）和长期时间序列预测（LTSF）。&lt;h4&gt;目的&lt;/h4&gt;探讨自注意力网络有效性的原因。&lt;h4&gt;方法&lt;/h4&gt;通过实证方法证明编码器中的整个注意力机制可以简化为由前馈、跳跃连接和层归一化操作构成的多层感知机（MLP），用于多变量时间序列预测的时间或空间建模。&lt;h4&gt;主要发现&lt;/h4&gt;可以去除注意力网络中的Q、K、V投影、注意力得分计算、注意力得分与V的点积以及最终投影，而不会显著降低性能。对于时空网络，MLP替代注意力网络在计算量（FLOPS）上减少了62.579%，性能损失小于2.5%；对长期时间序列预测，FLOPS减少了42.233%，性能损失小于2%。&lt;h4&gt;结论&lt;/h4&gt;该研究表明，可以通过简化注意力机制来保持性能，同时显著降低计算复杂性。&lt;h4&gt;总结&lt;/h4&gt;这项工作为理解自注意力网络提供了新的视角，揭示了其在多变量时间序列预测中的有效性和简化潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Attention-based architectures have become ubiquitous in time seriesforecasting tasks, including spatio-temporal (STF) and long-term time seriesforecasting (LTSF). Yet, our understanding of the reasons for theireffectiveness remains limited. This work proposes a new way to understandself-attention networks: we have shown empirically that the entire attentionmechanism in the encoder can be reduced to an MLP formed by feedforward,skip-connection, and layer normalization operations for temporal and/or spatialmodeling in multivariate time series forecasting. Specifically, the Q, K, and Vprojection, the attention score calculation, the dot-product between theattention score and the V, and the final projection can be removed from theattention-based networks without significantly degrading the performance thatthe given network remains the top-tier compared to other SOTA methods. Forspatio-temporal networks, the MLP-replace-attention network achieves areduction in FLOPS of $62.579\%$ with a loss in performance less than $2.5\%$;for LTSF, a reduction in FLOPs of $42.233\%$ with a loss in performance lessthan $2\%$.</description>
      <author>example@mail.com (Suhan Guo, Jiahong Deng, Yi Wei, Hui Dou, Furao Shen, Jian Zhao)</author>
      <guid isPermaLink="false">2410.24023v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use</title>
      <link>http://arxiv.org/abs/2410.24218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  EMNLP 2024 Main. Project website:
  https://github.com/sled-group/Teachable_RL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在现实场景中，具身代理能够利用人类语言获取显性或隐性知识以进行学习任务是理想的。&lt;h4&gt;目的&lt;/h4&gt;研究不同类型的语言输入如何促进强化学习（RL）具身代理的学习。&lt;h4&gt;方法&lt;/h4&gt;考察语言信息量（对过去行为的反馈和对未来的指导）和多样性（语言表达的变化）对代理学习和推理的影响。&lt;h4&gt;主要发现&lt;/h4&gt;经过多样化和信息丰富的语言反馈训练的代理，能够实现更好的泛化能力和快速适应新任务。&lt;h4&gt;结论&lt;/h4&gt;语言的使用在教导具身代理在开放世界中学习新任务方面起着关键作用。&lt;h4&gt;总结&lt;/h4&gt;研究表明，丰富的语言输入对强化学习代理的学习过程至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sled-group/teachable_rl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world scenarios, it is desirable for embodied agents to have theability to leverage human language to gain explicit or implicit knowledge forlearning tasks. Despite recent progress, most previous approaches adopt simplelow-level instructions as language inputs, which may not reflect natural humancommunication. It's not clear how to incorporate rich language use tofacilitate task learning. To address this question, this paper studiesdifferent types of language inputs in facilitating reinforcement learning (RL)embodied agents. More specifically, we examine how different levels of languageinformativeness (i.e., feedback on past behaviors and future guidance) anddiversity (i.e., variation of language expressions) impact agent learning andinference. Our empirical results based on four RL benchmarks demonstrate thatagents trained with diverse and informative language feedback can achieveenhanced generalization and fast adaptation to new tasks. These findingshighlight the pivotal role of language use in teaching embodied agents newtasks in an open world. Project website:https://github.com/sled-group/Teachable_RL</description>
      <author>example@mail.com (Jiajun Xi, Yinong He, Jianing Yang, Yinpei Dai, Joyce Chai)</author>
      <guid isPermaLink="false">2410.24218v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>EgoMimic: Scaling Imitation Learning via Egocentric Video</title>
      <link>http://arxiv.org/abs/2410.24221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模仿学习所需的演示数据的规模和多样性是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出EgoMimic，一个通过人类体现数据扩展操作的全栈框架。&lt;h4&gt;方法&lt;/h4&gt;EgoMimic通过以下方式实现：1) 使用人体工程学的Project Aria眼镜捕获人类体现数据；2) 低成本的双手操控器，最小化与人类数据的运动学差距；3) 跨域数据对齐技术；4) 模仿学习架构，同时训练人类和机器人数据。&lt;h4&gt;主要发现&lt;/h4&gt;EgoMimic在多样化的长时间、单臂和双手操作任务上，相比于现有的最先进模仿学习方法，取得显著改进，并能够推广到全新的场景。&lt;h4&gt;结论&lt;/h4&gt;添加1小时的额外手部数据比添加1小时的额外机器人数据更有价值，显示出EgoMimic良好的扩展趋势。&lt;h4&gt;总结&lt;/h4&gt;EgoMimic将人类与机器人数据视为同等的体现演示数据，从中学习统一策略，推动了模仿学习的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The scale and diversity of demonstration data required for imitation learningis a significant challenge. We present EgoMimic, a full-stack framework whichscales manipulation via human embodiment data, specifically egocentric humanvideos paired with 3D hand tracking. EgoMimic achieves this through: (1) asystem to capture human embodiment data using the ergonomic Project Ariaglasses, (2) a low-cost bimanual manipulator that minimizes the kinematic gapto human data, (3) cross-domain data alignment techniques, and (4) an imitationlearning architecture that co-trains on human and robot data. Compared to priorworks that only extract high-level intent from human videos, our approachtreats human and robot data equally as embodied demonstration data and learns aunified policy from both data sources. EgoMimic achieves significantimprovement on a diverse set of long-horizon, single-arm and bimanualmanipulation tasks over state-of-the-art imitation learning methods and enablesgeneralization to entirely new scenes. Finally, we show a favorable scalingtrend for EgoMimic, where adding 1 hour of additional hand data issignificantly more valuable than 1 hour of additional robot data. Videos andadditional information can be found at https://egomimic.github.io/</description>
      <author>example@mail.com (Simar Kareer, Dhruv Patel, Ryan Punamiya, Pranay Mathur, Shuo Cheng, Chen Wang, Judy Hoffman, Danfei Xu)</author>
      <guid isPermaLink="false">2410.24221v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>AR-Pro: Counterfactual Explanations for Anomaly Repair with Formal Properties</title>
      <link>http://arxiv.org/abs/2410.24178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;异常检测广泛用于识别关键错误和可疑行为，但当前方法缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;引入反事实解释，以提高异常检测的解释性。&lt;h4&gt;方法&lt;/h4&gt;利用现有方法的共同特性和生成模型的最新进展，生成输入的反事实作为基于扩散的修复。&lt;h4&gt;主要发现&lt;/h4&gt;该方法展示了非异常版本应有的样子，提供了一种领域独立的可解释性规范。&lt;h4&gt;结论&lt;/h4&gt;提出的异常解释框架AR-Pro在视觉和时间序列异常数据集上显示了有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究为异常检测提供了统一的解释生成和评估框架，代码可在指定链接访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection is widely used for identifying critical errors andsuspicious behaviors, but current methods lack interpretability. We leveragecommon properties of existing methods and recent advances in generative modelsto introduce counterfactual explanations for anomaly detection. Given an input,we generate its counterfactual as a diffusion-based repair that shows what anon-anomalous version should have looked like. A key advantage of this approachis that it enables a domain-independent formal specification of explainabilitydesiderata, offering a unified framework for generating and evaluatingexplanations. We demonstrate the effectiveness of our anomaly explainabilityframework, AR-Pro, on vision (MVTec, VisA) and time-series (SWaT, WADI, HAI)anomaly datasets. The code used for the experiments is accessible at:https://github.com/xjiae/arpro.</description>
      <author>example@mail.com (Xiayan Ji, Anton Xue, Eric Wong, Oleg Sokolsky, Insup Lee)</author>
      <guid isPermaLink="false">2410.24178v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Tensegrity Robot Proprioceptive State Estimation with Geometric Constraints</title>
      <link>http://arxiv.org/abs/2410.24226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint; 8 pages, 11 figures, 2 tables; Code at
  https://github.com/Jonathan-Twz/tensegrity-robot-state-estimator&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;张力结构机器人由刚性杆和弹性电缆组成，形成抗冲击的稳固结构，但设计带来了运动学和动力学的复杂性，增加了控制和状态估计的难度。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的自我感知状态估计器，用于张力结构机器人。&lt;h4&gt;方法&lt;/h4&gt;利用3杆棱柱张力结构的几何约束，结合IMU和电机编码器测量，重建机器人的形状和方向；采用接触辅助的扩展卡尔曼滤波器与前向运动学相结合，估计机器人的全局位置和方向。&lt;h4&gt;主要发现&lt;/h4&gt;状态估计器在模拟环境和实际应用中与真实数据进行比较，平均漂移率为4.2%，与传统刚性机器人状态估计性能相当。&lt;h4&gt;结论&lt;/h4&gt;该状态估计器提升了张力结构机器人状态估计的前沿技术，并有潜力在实时情况下使用机载传感器，为张力结构机器人在非结构化环境中的完全自主运行铺平道路。&lt;h4&gt;总结&lt;/h4&gt;本研究为张力结构机器人提供了有效的状态估计解决方案，推动了其在复杂环境中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tensegrity robots, characterized by a synergistic assembly of rigid rods andelastic cables, form robust structures that are resistant to impacts. However,this design introduces complexities in kinematics and dynamics, complicatingcontrol and state estimation. This work presents a novel proprioceptive stateestimator for tensegrity robots. The estimator initially uses the geometricconstraints of 3-bar prism tensegrity structures, combined with IMU and motorencoder measurements, to reconstruct the robot's shape and orientation. It thenemploys a contact-aided invariant extended Kalman filter with forwardkinematics to estimate the global position and orientation of the tensegrityrobot. The state estimator's accuracy is assessed against ground truth data inboth simulated environments and real-world tensegrity robot applications. Itachieves an average drift percentage of 4.2%, comparable to the stateestimation performance of traditional rigid robots. This state estimatoradvances the state of the art in tensegrity robot state estimation and has thepotential to run in real-time using onboard sensors, paving the way for fullautonomy of tensegrity robots in unstructured environments.</description>
      <author>example@mail.com (Wenzhe Tong, Tzu-Yuan Lin, Jonathan Mi, Yicheng Jiang, Maani Ghaffari, Xiaonan Huang)</author>
      <guid isPermaLink="false">2410.24226v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>XRDSLAM: A Flexible and Modular Framework for Deep Learning based SLAM</title>
      <link>http://arxiv.org/abs/2410.23690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文提出了一个灵活的SLAM框架XRDSLAM。&lt;h4&gt;目的&lt;/h4&gt;旨在帮助开发者快速构建完整的SLAM系统，灵活组合不同的算法模块，并进行标准化的基准测试。&lt;h4&gt;方法&lt;/h4&gt;采用模块化代码设计和多进程运行机制，提供统一的数据集管理、3D可视化、算法配置和指标评估等基础模块。&lt;h4&gt;主要发现&lt;/h4&gt;集成了几种最先进的SLAM算法，包括基于NeRF和3DGS的SLAM，以及里程计或重建算法，展示了框架的灵活性和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;对集成算法进行了全面比较和评估，分析了各算法的特征，并将所有代码、配置和数据贡献给开源社区。&lt;h4&gt;总结&lt;/h4&gt;该框架旨在促进SLAM技术在开源生态系统中的广泛研究和开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a flexible SLAM framework, XRDSLAM. It adopts amodular code design and a multi-process running mechanism, providing highlyreusable foundational modules such as unified dataset management, 3dvisualization, algorithm configuration, and metrics evaluation. It can helpdevelopers quickly build a complete SLAM system, flexibly combine differentalgorithm modules, and conduct standardized benchmarking for accuracy andefficiency comparison. Within this framework, we integrate severalstate-of-the-art SLAM algorithms with different types, including NeRF and 3DGSbased SLAM, and even odometry or reconstruction algorithms, which demonstratesthe flexibility and extensibility. We also conduct a comprehensive comparisonand evaluation of these integrated algorithms, analyzing the characteristics ofeach. Finally, we contribute all the code, configuration and data to theopen-source community, which aims to promote the widespread research anddevelopment of SLAM technology within the open-source ecosystem.</description>
      <author>example@mail.com (Xiaomeng Wang, Nan Wang, Guofeng Zhang)</author>
      <guid isPermaLink="false">2410.23690v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Augmentation Invariance Pretraining</title>
      <link>http://arxiv.org/abs/2410.22364v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习方法在视觉变换器（ViTs）的预训练中存在计算挑战，训练所需的计算资源较大，限制了其实际应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种加速框架，以缓解对比学习的计算负担，提升ViT的训练效率。&lt;h4&gt;方法&lt;/h4&gt;采用混合序列压缩策略，包括随机化的标记丢弃和灵活的补丁缩放，以降低梯度估计的成本并加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;对多种加速策略的梯度估计误差进行了深入分析，并讨论了这些策略对下游任务的影响，提供了加速与性能之间权衡的见解。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新颖的程序，以识别最佳加速计划，调整序列压缩比，确保有效训练而不牺牲下游性能。&lt;h4&gt;总结&lt;/h4&gt;在大规模数据集上，我们的方法显著降低了自监督学习算法的计算开销。在ImageNet上，MoCo加速4倍，SimCLR加速3.3倍，DINO加速2.5倍，展示了显著的效率提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Our work tackles the computational challenges of contrastive learningmethods, particularly for the pretraining of Vision Transformers (ViTs).Despite the effectiveness of contrastive learning, the substantialcomputational resources required for training often hinder their practicalapplication. To mitigate this issue, we propose an acceleration framework,leveraging ViT's unique ability to generalize across inputs of varying sequencelengths. Our method employs a mix of sequence compression strategies, includingrandomized token dropout and flexible patch scaling, to reduce the cost ofgradient estimation and accelerate convergence. We further provide an in-depthanalysis of the gradient estimation error of various acceleration strategies aswell as their impact on downstream tasks, offering valuable insights into thetrade-offs between acceleration and performance.  We also propose a novel procedure to identify an optimal accelerationschedule to adjust the sequence compression ratios to the training progress,ensuring efficient training without sacrificing downstream performance. Ourapproach significantly reduces computational overhead across variousself-supervised learning algorithms on large-scale datasets. In ImageNet, ourmethod achieves speedups of 4$\times$ in MoCo, 3.3$\times$ in SimCLR, and2.5$\times$ in DINO, demonstrating substantial efficiency gains.</description>
      <author>example@mail.com (Jinhong Lin, Cheng-En Wu, Yibing Wei, Pedro Morgado)</author>
      <guid isPermaLink="false">2410.22364v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>CrossEarth: Geospatial Vision Foundation Model for Domain Generalizable Remote Sensing Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.22629v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The codes and models will be available at
  https://github.com/Cuzyoung/CrossEarth&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;遥感领域泛化（RSDG）成为一个关键的研究前沿，旨在开发能够在多样场景中有效泛化的模型。&lt;h4&gt;目的&lt;/h4&gt;解决遥感图像中的领域差异问题，尤其是在语义分割任务中，提高模型在未知领域的适应性。&lt;h4&gt;方法&lt;/h4&gt;引入CrossEarth作为首个用于RSDG语义分割的视觉基础模型，采用数据级的地球风格注入管道和模型级的多任务训练管道。&lt;h4&gt;主要发现&lt;/h4&gt;CrossEarth在跨领域泛化方面表现出色，相较于现有的最先进方法具有明显优势。&lt;h4&gt;结论&lt;/h4&gt;建立了一个包含28个跨领域设置的RSDG基准，为未来RSDG模型的可泛化性测试提供了全面框架。&lt;h4&gt;总结&lt;/h4&gt;尽管当前的跨领域方法侧重于领域适应，但本研究提出的解决方案有效提升了遥感图像的跨领域泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cuzyoung/crossearth&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The field of Remote Sensing Domain Generalization (RSDG) has emerged as acritical and valuable research frontier, focusing on developing models thatgeneralize effectively across diverse scenarios. Despite the substantial domaingaps in RS images that are characterized by variabilities such as location,wavelength, and sensor type, research in this area remains underexplored: (1)Current cross-domain methods primarily focus on Domain Adaptation (DA), whichadapts models to predefined domains rather than to unseen ones; (2) Few studiestargeting the RSDG issue, especially for semantic segmentation tasks, whereexisting models are developed for specific unknown domains, struggling withissues of underfitting on other unknown scenarios; (3) Existing RS foundationmodels tend to prioritize in-domain performance over cross-domaingeneralization. To this end, we introduce the first vision foundation model forRSDG semantic segmentation, CrossEarth. CrossEarth demonstrates strongcross-domain generalization through a specially designed data-level Earth-StyleInjection pipeline and a model-level Multi-Task Training pipeline. In addition,for the semantic segmentation task, we have curated an RSDG benchmarkcomprising 28 cross-domain settings across various regions, spectral bands,platforms, and climates, providing a comprehensive framework for testing thegeneralizability of future RSDG models. Extensive experiments on this benchmarkdemonstrate the superiority of CrossEarth over existing state-of-the-artmethods.</description>
      <author>example@mail.com (Ziyang Gong, Zhixiang Wei, Di Wang, Xianzheng Ma, Hongruixuan Chen, Yuru Jia, Yupeng Deng, Zhenming Ji, Xiangwei Zhu, Naoto Yokoya, Jing Zhang, Bo Du, Liangpei Zhang)</author>
      <guid isPermaLink="false">2410.22629v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds</title>
      <link>http://arxiv.org/abs/2410.22099v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures, 4 tables. This work has been submitted to the
  IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;脑成像研究表明，扩散MRI轨迹几何形状描述符可以帮助研究大脑白质通路及其与大脑功能的关系。&lt;h4&gt;目的&lt;/h4&gt;探讨利用深度学习模型计算大脑白质连接的形状度量的可能性。&lt;h4&gt;方法&lt;/h4&gt;引入一个新框架TractShapeNet，利用轨迹的点云表示计算五个形状度量：长度、跨度、体积、总表面积和不规则性。&lt;h4&gt;主要发现&lt;/h4&gt;在1065名健康年轻成年人数据集上评估方法性能，TractShapeNet在皮尔逊相关系数和归一化误差指标上超越其他点云基础神经网络模型。&lt;h4&gt;结论&lt;/h4&gt;深度学习方法能够更快、更高效地计算形状度量，并且在两个下游语言认知预测任务中，TractShapeNet的形状度量表现与DSI-Studio计算的结果相似。&lt;h4&gt;总结&lt;/h4&gt;我们的代码将公开在：https://github.com/SlicerDMRI/TractShapeNet。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain imaging studies have demonstrated that diffusion MRI tractographygeometric shape descriptors can inform the study of the brain's white matterpathways and their relationship to brain function. In this work, we investigatethe possibility of utilizing a deep learning model to compute shape measures ofthe brain's white matter connections. We introduce a novel framework,TractShapeNet, that leverages a point cloud representation of tractography tocompute five shape measures: length, span, volume, total surface area, andirregularity. We assess the performance of the method on a large datasetincluding 1065 healthy young adults. Experiments for shape measure computationdemonstrate that our proposed TractShapeNet outperforms other point cloud-basedneural network models in both the Pearson correlation coefficient andnormalized error metrics. We compare the inference runtime results with theconventional shape computation tool DSI-Studio. Our results demonstrate that adeep learning approach enables faster and more efficient shape measurecomputation. We also conduct experiments on two downstream language cognitionprediction tasks, showing that shape measures from TractShapeNet performsimilarly to those computed by DSI-Studio. Our code will be available at:https://github.com/SlicerDMRI/TractShapeNet.</description>
      <author>example@mail.com (Yui Lo, Yuqian Chen, Dongnan Liu, Jon Haitz Legarreta, Leo Zekelman, Fan Zhang, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O'Donnell)</author>
      <guid isPermaLink="false">2410.22099v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Learning and Transferring Sparse Contextual Bigrams with Linear Transformers</title>
      <link>http://arxiv.org/abs/2410.23438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Transformers在自然语言建模中表现优异，其成功部分源于其结合上下文信息和全局知识的能力，但理论基础尚不明确。&lt;h4&gt;目的&lt;/h4&gt;介绍稀疏上下文双元组（SCB）模型，并分析其训练动态和样本复杂性。&lt;h4&gt;方法&lt;/h4&gt;使用一层线性Transformer和基于梯度的算法来学习SCB模型。&lt;h4&gt;主要发现&lt;/h4&gt;训练过程分为样本密集的初始阶段和更高效的后续改进阶段；预训练模型的微调可以绕过初始阶段。算法表现优于传统的SGD。&lt;h4&gt;结论&lt;/h4&gt;在下游任务与预训练任务之间存在非平凡相关性时，微调能够显著提高效率，且我们的算法与常规的softmax-based Transformers存在关系。&lt;h4&gt;总结&lt;/h4&gt;本研究为理解Transformers的训练机制提供了理论支持，并提出了更高效的训练方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers have excelled in natural language modeling and one reason behindthis success is their exceptional ability to combine contextual informal andglobal knowledge. However, the theoretical basis remains unclear. In thispaper, first we introduce the Sparse Contextual Bigram (SCB), a naturalextension of the classical bigram model, where the next token's generationdepends on a sparse set of earlier positions determined by the last token. Wethen analyze the training dynamics and sample complexity of learning SCB usinga one-layer linear transformer with a gradient-based algorithm. We show thatwhen trained from scratch, the training process can be split into an initialsample-intensive stage where the correlation is boosted from zero to anontrivial value, followed by a more sample-efficient stage of furtherimprovement. Additionally, we prove that, provided a nontrivial correlationbetween the downstream and pretraining tasks, finetuning from a pretrainedmodel allows us to bypass the initial sample-intensive stage. We alsoempirically demonstrate that our algorithm can outperform SGD in this settingand discuss its relationship with the usual softmax-based transformers.</description>
      <author>example@mail.com (Yunwei Ren, Zixuan Wang, Jason D. Lee)</author>
      <guid isPermaLink="false">2410.23438v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>NeFF-BioNet: Crop Biomass Prediction from Point Cloud to Drone Imagery</title>
      <link>http://arxiv.org/abs/2410.23901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;作物生物量提供了植物健康和产量的重要信息，对作物科学、农业系统和农业研究至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决当前测量方法的局限性，以便于大规模量化作物生物量。&lt;h4&gt;方法&lt;/h4&gt;提出了一种生物量预测网络（BioNet），适用于多种数据模式，包括点云和无人机图像，采用稀疏3D卷积神经网络和基于变换器的预测模块。&lt;h4&gt;主要发现&lt;/h4&gt;在点云模式下，BioNet在两个公共数据集上表现优越，相对领先技术提高约6.1%；在RGB图像模式下，BioNet与NeFF结合实现7.9%的改进。&lt;h4&gt;结论&lt;/h4&gt;NeFF模块利用廉价、便携的无人机相机，为大规模田间应用提供了一种可扩展的解决方案。&lt;h4&gt;总结&lt;/h4&gt;BioNet结合现代技术，为作物生物量的测量与预测提供了高效、精确的工具，推动农业研究的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Crop biomass offers crucial insights into plant health and yield, making itessential for crop science, farming systems, and agricultural research.However, current measurement methods, which are labor-intensive, destructive,and imprecise, hinder large-scale quantification of this trait. To address thislimitation, we present a biomass prediction network (BioNet), designed foradaptation across different data modalities, including point clouds and droneimagery. Our BioNet, utilizing a sparse 3D convolutional neural network (CNN)and a transformer-based prediction module, processes point clouds and other 3Ddata representations to predict biomass. To further extend BioNet for droneimagery, we integrate a neural feature field (NeFF) module, enabling 3Dstructure reconstruction and the transformation of 2D semantic features fromvision foundation models into the corresponding 3D surfaces. For the pointcloud modality, BioNet demonstrates superior performance on two publicdatasets, with an approximate 6.1% relative improvement (RI) over thestate-of-the-art. In the RGB image modality, the combination of BioNet and NeFFachieves a 7.9% RI. Additionally, the NeFF-based approach utilizes inexpensive,portable drone-mounted cameras, providing a scalable solution for large fieldapplications.</description>
      <author>example@mail.com (Xuesong Li, Zeeshan Hayder, Ali Zia, Connor Cassidy, Shiming Liu, Warwick Stiller, Eric Stone, Warren Conaty, Lars Petersson, Vivien Rolland)</author>
      <guid isPermaLink="false">2410.23901v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Keep on Swimming: Real Attackers Only Need Partial Knowledge of a Multi-Model System</title>
      <link>http://arxiv.org/abs/2410.23483v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，机器学习的研究常常通过多个模型或智能架构组合来解决任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，针对整体多模型系统进行对抗攻击，只需使用最终黑箱模型的代理模型。&lt;h4&gt;方法&lt;/h4&gt;在初始模型的变换可能使对抗扰动无效的情况下，设计了一种新的对抗攻击方法，避免了对每个系统组件训练代理模型的复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法的攻击成功率为80%，显著高于以往方法的25%；同时引入的扰动比以往先进方法小9.4%（均方误差）。&lt;h4&gt;结论&lt;/h4&gt;尽管实验主要集中在监督图像处理上，但我们相信该攻击方法可以推广到其他多模型设置或智能系统中。&lt;h4&gt;总结&lt;/h4&gt;本研究首次针对特定威胁模型设计的对抗攻击方法，在效果上优于现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent approaches in machine learning often solve a task using a compositionof multiple models or agentic architectures. When targeting a composed systemwith adversarial attacks, it might not be computationally or informationallyfeasible to train an end-to-end proxy model or a proxy model for everycomponent of the system. We introduce a method to craft an adversarial attackagainst the overall multi-model system when we only have a proxy model for thefinal black-box model, and when the transformation applied by the initialmodels can make the adversarial perturbations ineffective. Current methodshandle this by applying many copies of the first model/transformation to aninput and then re-use a standard adversarial attack by averaging gradients, orlearning a proxy model for both stages. To our knowledge, this is the firstattack specifically designed for this threat model and our method has asubstantially higher attack success rate (80% vs 25%) and contains 9.4% smallerperturbations (MSE) compared to prior state-of-the-art methods. Our experimentsfocus on a supervised image pipeline, but we are confident the attack willgeneralize to other multi-model settings [e.g. a mix of open/closed sourcefoundation models], or agentic systems</description>
      <author>example@mail.com (Julian Collado, Kevin Stangl)</author>
      <guid isPermaLink="false">2410.23483v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Novel Clinical-Grade Prostate Cancer Detection and Grading Model: Development and Prospective Validation Using Real World Data, with Performance Assessment on IHC Requested Cases</title>
      <link>http://arxiv.org/abs/2410.23642v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能可能帮助医疗系统满足日益增长的病理服务需求，同时保持诊断质量，减少周转时间和成本。&lt;h4&gt;目的&lt;/h4&gt;研究一个机构开发的前列腺癌检测、分级和工作流程优化系统的性能，并与商业替代方案进行对比。&lt;h4&gt;方法&lt;/h4&gt;从2021年8月到2023年3月，扫描了来自1147名阳性活检患者的21396张切片。开发了用于癌症检测、分级和对可疑案例进行IHC订购筛查的模型。&lt;h4&gt;主要发现&lt;/h4&gt;{'检测一致性': {'AUC': 98.5, '敏感性': 95.0, '特异性': 97.8}, 'ISUP分级': {"Cohen's kappa": 0.869}, '较高等级分组': {'AUC': 97.5, '敏感性': 94.9, '特异性': 96.6}, 'IHC订购减少': '可减少44.5%，总体错误率为1.8%（1.4%假阳性，0.4%假阴性）'}&lt;h4&gt;结论&lt;/h4&gt;具备高扫描量和报告抽象能力的学术医疗中心可以开发准确的计算病理模型供内部使用，这些模型有助于质量控制并改善病理实验室的工作流程，以应对前列腺癌诊断的未来挑战。&lt;h4&gt;总结&lt;/h4&gt;该研究表明，机构开发的病理模型在前列腺癌检测中表现优异，具备较高的检测准确性和工作效率，有潜力提升病理服务质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence may assist healthcare systems in meeting increasingdemand for pathology services while maintaining diagnostic quality and reducingturnaround time and costs. We aimed to investigate the performance of aninstitutionally developed system for prostate cancer detection, grading, andworkflow optimization and to contrast this with commercial alternatives. FromAugust 2021 to March 2023, we scanned 21,396 slides from 1,147 patients withpositive biopsies. We developed models for cancer detection, grading, andscreening of equivocal cases for IHC ordering. We compared a task-specificmodel trained using the PANDA dataset of prostate cancer biopsies with onebuilt using features extracted by the general-purpose histology foundationmodel, UNI and compare their performance in an unfiltered prospectivelycollected dataset that reflects our patient population (1737 slides,95patients). We evaluated the contributions of a bespoke model designed toimprove sensitivity in detecting small cancer foci and scoring of broaderpatterns observed at lower resolution. We found high concordance between thedeveloped systems and pathologist reference in detection (AUC 98.5, sensitivity95.0, and specificity 97.8), ISUP grading (quadratic Cohen's kappa 0.869),grade group 3 or higher (AUC 97.5, sensitivity 94.9, specificity 96.6) andcomparable to published data from commercial systems. Screening could reduceIHC ordering for equivocal cases by 44.5% with an overall error rate of 1.8%(1.4% false positive, 0.4% false negative rates). Institutions like academicmedical centers that have high scanning volumes and report abstractioncapabilities can develop accurate computational pathology models for internaluse. These models have the potential to aid in quality control role and toimprove workflow in the pathology lab to help meet future challenges inprostate cancer diagnosis.</description>
      <author>example@mail.com (Ramin Nateghi, Ruoji Zhou, Madeline Saft, Marina Schnauss, Clayton Neill, Ridwan Alam, Nicole Handa, Mitchell Huang, Eric V Li, Jeffery A Goldstein, Edward M Schaeffer, Menatalla Nadim, Fattaneh Pourakpour, Bogdan Isaila, Christopher Felicelli, Vikas Mehta, Behtash G Nezami, Ashley Ross, Ximing Yang, Lee AD Cooper)</author>
      <guid isPermaLink="false">2410.23642v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Current Boundaries: Integrating Deep Learning and AlphaFold for Enhanced Protein Structure Prediction from Low-Resolution Cryo-EM Maps</title>
      <link>http://arxiv.org/abs/2410.23321v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从冷冻电子显微镜（cryo-EM）地图构建原子模型是结构生物学中的一项关键且复杂的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架DeepTracer-LowResEnhance，以改善低分辨率cryo-EM地图下的模型构建效果。&lt;h4&gt;方法&lt;/h4&gt;将深度学习增强的地图精炼技术与AlphaFold的能力相结合，对37个蛋白质的cryo-EM地图进行严格测试，分辨率范围为2.5到8.4Å。&lt;h4&gt;主要发现&lt;/h4&gt;95.5%的低分辨率地图在预测的残基总数上显著增加，尤其是22个分辨率低于4Å的地图。&lt;h4&gt;结论&lt;/h4&gt;DeepTracer-LowResEnhance在生成更详细和精确的原子模型方面优于Phenix的自动锐化功能，推动了当前计算结构生物学方法的边界。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了DeepTracer-LowResEnhance在低分辨率cryo-EM地图原子模型构建中的有效性，具有重要的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Constructing atomic models from cryo-electron microscopy (cryo-EM) maps is acrucial yet intricate task in structural biology. While advancements in deeplearning, such as convolutional neural networks (CNNs) and graph neuralnetworks (GNNs), have spurred the development of sophisticated map-to-modeltools like DeepTracer and ModelAngelo, their efficacy notably diminishes withlow-resolution maps beyond 4 {\AA}. To address this shortfall, our researchintroduces DeepTracer-LowResEnhance, an innovative framework that synergizes adeep learning-enhanced map refinement technique with the power of AlphaFold.This methodology is designed to markedly improve the construction of modelsfrom low-resolution cryo-EM maps. DeepTracer-LowResEnhance was rigorouslytested on a set of 37 protein cryo-EM maps, with resolutions ranging between2.5 to 8.4 {\AA}, including 22 maps with resolutions lower than 4 {\AA}. Theoutcomes were compelling, demonstrating that 95.5\% of the low-resolution mapsexhibited a significant uptick in the count of total predicted residues. Thisdenotes a pronounced improvement in atomic model building for low-resolutionmaps. Additionally, a comparative analysis alongside Phenix's auto-sharpeningfunctionality delineates DeepTracer-LowResEnhance's superior capability inrendering more detailed and precise atomic models, thereby pushing theboundaries of current computational structural biology methodologies.</description>
      <author>example@mail.com (Xin, Ma, Dong Si)</author>
      <guid isPermaLink="false">2410.23321v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI for Accessible and Inclusive Extended Reality</title>
      <link>http://arxiv.org/abs/2410.23803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at the CHI 2024 Workshop "Building a Metaverse for All:
  Opportunities and Challenges for Future Inclusive and Accessible Virtual
  Environments", May 11, 2024, Honolulu, Hawaii&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能生成内容（AIGC）有潜力改变人们构建和互动虚拟环境的方式。&lt;h4&gt;目的&lt;/h4&gt;讨论AIGC在创建包容性和可访问的虚拟环境中的潜在益处与挑战。&lt;h4&gt;方法&lt;/h4&gt;探讨减少对3D建模专业知识的需求、符号输入和多模态输入的优势、3D内容编辑和3D模型可访问性。&lt;h4&gt;主要发现&lt;/h4&gt;AIGC能够降低对专业技能的依赖，同时提升虚拟环境的可编辑性和可达性。&lt;h4&gt;结论&lt;/h4&gt;尽管AIGC带来诸多好处，但也存在与基础模型相关的特定挑战。&lt;h4&gt;总结&lt;/h4&gt;AIGC在虚拟环境的创建中具有重要意义，但需克服一些挑战以实现更广泛的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial Intelligence-Generated Content (AIGC) has the potential totransform how people build and interact with virtual environments. Within thispaper, we discuss potential benefits but also challenges that AIGC has for thecreation of inclusive and accessible virtual environments. Specifically, wetouch upon the decreased need for 3D modeling expertise, benefits ofsymbolic-only as well as multimodal input, 3D content editing, and 3D modelaccessibility as well as foundation model-specific challenges.</description>
      <author>example@mail.com (Jens Grubert, Junlong Chen, Per Ola Kristensson)</author>
      <guid isPermaLink="false">2410.23803v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Aligning Audio-Visual Joint Representations with an Agentic Workflow</title>
      <link>http://arxiv.org/abs/2410.23230v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉内容和伴随的音频信号共同构成联合表示，以改善音视频相关应用。&lt;h4&gt;目的&lt;/h4&gt;提高音视频数据的对齐，从而提升表示质量和应用性能。&lt;h4&gt;方法&lt;/h4&gt;提出一个基于 LLM 的助手 AVAgent，通过多模态 LLM 对音频和视觉数据进行语言描述，判断数据对齐情况，并在必要时编辑音频信号。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用工具、规划和反思的循环步骤，逐步实现音频信号与视觉内容的对齐。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，所提方法在多种下游任务中相较于之前的基线具有显著的性能提升。&lt;h4&gt;总结&lt;/h4&gt;通过一个以数据为中心的工作流程，改进了音视频联合表示的质量，展现了先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual content and accompanied audio signals naturally formulate a jointrepresentation to improve audio-visual (AV) related applications. While studiesdevelop various AV representation learning frameworks, the importance of AVdata alignment is usually undermined for achieving high-quality representation.We observe that an audio signal may contain background noise interference.Also, non-synchronization may appear between audio and video streams. Thesenon-strict data alignment limits representation quality and downgradeapplication performance. In this paper, we propose to improve AV jointrepresentations from a data-centric perspective by aligning audio signals tovisual data. Our alignment is conducted in an agentic workflow controlled by anLLM-based assistant named AVAgent. For each input AV data pair, our AVAgentuses a multi-modal LLM to convert audio and visual data into languagedescriptions separately (i.e., tool use). Then, AVAgent reasons whether thispaired data is aligned well and plans to edit the audio signal if needed (i.e.,planning). The audio editing is executed by predefined actions that filternoise or augment data. Moreover, we use a VLM to evaluate how modified audiosignals match the visual content and provide feedback to AVAgent (i.e.,reflection). The tool use, planning, and reflection steps operate cyclically tobecome an agentic workflow where audio signals are gradually aligned to visualcontent. To this end, existing methods can directly leverage the aligned AVdata via our agentic workflow to improve AV joint representations. Theexperimental results comprehensively demonstrate the state-of-the-artperformance of the proposed approach against previous baselines in diversedownstream tasks.</description>
      <author>example@mail.com (Shentong Mo, Yibing Song)</author>
      <guid isPermaLink="false">2410.23230v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>FRoundation: Are Foundation Models Ready for Face Recognition?</title>
      <link>http://arxiv.org/abs/2410.23831v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型通常在多样化的大规模数据集上以无监督或自监督方式进行训练，广泛适用于各种下游任务。&lt;h4&gt;目的&lt;/h4&gt;首次研究这些模型是否适用于面部识别特定领域。&lt;h4&gt;方法&lt;/h4&gt;对多种基础模型和不同规模的数据集进行广泛实验，探索在不同数据可用性水平下对模型的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;尽管基础模型具有多功能性，但在面部识别任务中的表现不及针对该任务专门训练的相似架构。&lt;h4&gt;结论&lt;/h4&gt;对基础模型进行微调后，结果令人鼓舞，尤其是在训练数据有限时，往往超越从头训练的模型；即使在大规模训练数据集上，微调后的基础模型与从头训练的模型表现相当，但训练计算成本更低，不依赖于大量数据的假设。&lt;h4&gt;偏差分析&lt;/h4&gt;在某些设置中使用基础模型时观察到略高的偏差。&lt;h4&gt;总结&lt;/h4&gt;基础模型在面部识别领域展现出潜力，特别是在数据有限的情况下，微调能够提升性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are predominantly trained in an unsupervised orself-supervised manner on highly diverse and large-scale datasets, making thembroadly applicable to various downstream tasks. In this work, we investigatefor the first time whether such models are suitable for the specific domain offace recognition. We further propose and demonstrate the adaptation of thesemodels for face recognition across different levels of data availability.Extensive experiments are conducted on multiple foundation models and datasetsof varying scales for training and fine-tuning, with evaluation on a wide rangeof benchmarks. Our results indicate that, despite their versatility,pre-trained foundation models underperform in face recognition compared tosimilar architectures trained specifically for this task. However, fine-tuningfoundation models yields promising results, often surpassing models trainedfrom scratch when training data is limited. Even with access to large-scaleface recognition training datasets, fine-tuned foundation models performcomparably to models trained from scratch, but with lower trainingcomputational costs and without relying on the assumption of extensive dataavailability. Our analysis also explores bias in face recognition, withslightly higher bias observed in some settings when using foundation models.</description>
      <author>example@mail.com (Tahar Chettaoui, Naser Damer, Fadi Boutros)</author>
      <guid isPermaLink="false">2410.23831v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning in Vocal Education: Technical Evaluation of Limited Samples Describing Mezzo-soprano</title>
      <link>http://arxiv.org/abs/2410.23325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;音乐领域的声乐教育难以量化，因歌手声音的个体差异和声乐技巧的量化标准不同。&lt;h4&gt;目的&lt;/h4&gt;提升声乐技巧评估的准确性，特别是针对稀有声部如中女高音的评估。&lt;h4&gt;方法&lt;/h4&gt;采用迁移学习，使用在ImageNet和Urbansound8k数据集上预训练的深度学习模型，并构建专用数据集Mezzo-soprano Vocal Set (MVS)。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习使所有模型的整体准确率平均提高了8.3%，最高准确率达到94.2%。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新颖的评估中女高音声乐技巧的方法，并引入了一种新的音乐教育量化评估方法。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了深度学习在音乐教育中的潜力，特别是在处理稀有声部评估时的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vocal education in the music field is difficult to quantify due to theindividual differences in singers' voices and the different quantitativecriteria of singing techniques. Deep learning has great potential to be appliedin music education due to its efficiency to handle complex data and performquantitative analysis. However, accurate evaluations with limited samples overrare vocal types, such as Mezzo-soprano, requires extensive well-annotated datasupport using deep learning models. In order to attain the objective, weperform transfer learning by employing deep learning models pre-trained on theImageNet and Urbansound8k datasets for the improvement on the precision ofvocal technique evaluation. Furthermore, we tackle the problem of the lack ofsamples by constructing a dedicated dataset, the Mezzo-soprano Vocal Set (MVS),for vocal technique assessment. Our experimental results indicate that transferlearning increases the overall accuracy (OAcc) of all models by an average of8.3%, with the highest accuracy at 94.2%. We not only provide a novel approachto evaluating Mezzo-soprano vocal techniques but also introduce a newquantitative assessment method for music education.</description>
      <author>example@mail.com (Zhenyi Hou, Xu Zhao, Kejie Ye, Xinyu Sheng, Shanggerile Jiang, Jiajing Xia, Yitao Zhang, Chenxi Ban, Daijun Luo, Jiaxing Chen, Yan Zou, Yuchao Feng, Guangyu Fan, Xin Yuan)</author>
      <guid isPermaLink="false">2410.23325v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document</title>
      <link>http://arxiv.org/abs/2410.23452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的句子级关系提取模型存在局限性，难以捕捉复杂的关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过结合图神经网络(GNN)和大型语言模型(LLM)进行句子级关系提取。&lt;h4&gt;方法&lt;/h4&gt;利用LLM生成辅助信息，构建文本数据的复杂图表示，然后通过GNN处理，精炼和丰富每个实体的嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在CrossRE数据集上的实验显示，该方法在多个领域的性能显著提升。&lt;h4&gt;结论&lt;/h4&gt;结合GNN和LLM生成的上下文有助于推动关系提取领域的发展。&lt;h4&gt;总结&lt;/h4&gt;该研究通过新的方法提升了句子级关系提取的能力，展示了GNN与LLM结合的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study introduces a novel approach to sentence-level relation extraction(RE) that integrates Graph Neural Networks (GNNs) with Large Language Models(LLMs) to generate contextually enriched support documents. By harnessing thepower of LLMs to generate auxiliary information, our approach crafts anintricate graph representation of textual data. This graph is subsequentlyprocessed through a Graph Neural Network (GNN) to refine and enrich theembeddings associated with each entity ensuring a more nuanced andinterconnected understanding of the data. This methodology addresses thelimitations of traditional sentence-level RE models by incorporating broadercontexts and leveraging inter-entity interactions, thereby improving themodel's ability to capture complex relationships across sentences. Ourexperiments, conducted on the CrossRE dataset, demonstrate the effectiveness ofour approach, with notable improvements in performance across various domains.The results underscore the potential of combining GNNs with LLM-generatedcontext to advance the field of relation extraction.</description>
      <author>example@mail.com (Vicky Dong, Hao Yu, Yao Chen)</author>
      <guid isPermaLink="false">2410.23452v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>PACER: Preference-conditioned All-terrain Costmap Generation</title>
      <link>http://arxiv.org/abs/2410.23488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在自主机器人导航中，地形成本分配通常采用基于语义的范式，首先通过预训练的语义分类器标记地形，然后根据用户定义的标签与成本之间的映射分配成本。&lt;h4&gt;目的&lt;/h4&gt;假设基于机器学习的替代方法能够快速适应在部署时对新地形表达的用户偏好，而无需额外训练。&lt;h4&gt;方法&lt;/h4&gt;引入并研究PACER，这是一种新的成本图生成方法，接收周围区域的鸟瞰图（BEV）图像和用户指定的偏好上下文，并生成与偏好上下文一致的BEV成本图。&lt;h4&gt;主要发现&lt;/h4&gt;PACER能够迅速适应新的用户偏好，并且相比于基于语义和基于表示学习的方法，在对新地形的泛化能力上表现更佳。&lt;h4&gt;结论&lt;/h4&gt;PACER方法在地形成本分配中表现出了更好的适应性和泛化能力，能够满足用户在不同地形上的需求。&lt;h4&gt;总结&lt;/h4&gt;PACER为自主机器人的地形成本适应提供了有效的解决方案，能够在无需额外训练的情况下快速响应用户偏好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In autonomous robot navigation, terrain cost assignment is typicallyperformed using a semantics-based paradigm in which terrain is first labeledusing a pre-trained semantic classifier and costs are then assigned accordingto a user-defined mapping between label and cost. While this approach israpidly adaptable to changing user preferences, only preferences over the typesof terrain that are already known by the semantic classifier can be expressed.In this paper, we hypothesize that a machine-learning-based alternative to thesemantics-based paradigm above will allow for rapid cost assignment adaptationto preferences expressed over new terrains at deployment time without the needfor additional training. To investigate this hypothesis, we introduce and studyPACER, a novel approach to costmap generation that accepts as input a singlebirds-eye view (BEV) image of the surrounding area along with a user-specifiedpreference context and generates a corresponding BEV costmap that aligns withthe preference context. Using both real and synthetic data along with acombination of proposed training tasks, we find that PACER is able to adaptquickly to new user preferences while also exhibiting better generalization tonovel terrains compared to both semantics-based and representation-learningapproaches.</description>
      <author>example@mail.com (Luisa Mao, Garrett Warnell, Peter Stone, Joydeep Biswas)</author>
      <guid isPermaLink="false">2410.23488v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Multi-fidelity Machine Learning for Uncertainty Quantification and Optimization</title>
      <link>http://arxiv.org/abs/2410.23482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在系统分析和设计优化中，通常有多个计算模型可用于表示给定的物理系统，这些模型可分为高保真模型和低保真模型。&lt;h4&gt;目的&lt;/h4&gt;深入概述基于机器学习的多保真方法，特别强调不确定性量化和优化。&lt;h4&gt;方法&lt;/h4&gt;比较多保真图神经网络与多保真多项式混沌展开，用于不确定性量化；在优化方面，强调多保真贝叶斯优化，提出当目标函数为积分或加权和时的应用策略。&lt;h4&gt;主要发现&lt;/h4&gt;提供了多保真先验的统一视角，并指出了当前文献中的关键空白和研究机会。&lt;h4&gt;结论&lt;/h4&gt;强调多保真方法在计算成本和预测准确性之间的平衡，以及在不确定性量化和优化领域的潜在应用。&lt;h4&gt;总结&lt;/h4&gt;多保真方法在机器学习领域的新兴应用，展示了未来发展的重要研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1615/JMachLearnModelComput.2024055786&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In system analysis and design optimization, multiple computational models aretypically available to represent a given physical system. These models can bebroadly classified as high-fidelity models, which provide highly accuratepredictions but require significant computational resources, and low-fidelitymodels, which are computationally efficient but less accurate. Multi-fidelitymethods integrate high- and low-fidelity models to balance computational costand predictive accuracy. This perspective paper provides an in-depth overviewof the emerging field of machine learning-based multi-fidelity methods, with aparticular emphasis on uncertainty quantification and optimization. Foruncertainty quantification, a particular focus is on multi-fidelity graphneural networks, compared with multi-fidelity polynomial chaos expansion. Foroptimization, our emphasis is on multi-fidelity Bayesian optimization, offeringa unified perspective on multi-fidelity priors and proposing an applicationstrategy when the objective function is an integral or a weighted sum. Wehighlight the current state of the art, identify critical gaps in theliterature, and outline key research opportunities in this evolving field.</description>
      <author>example@mail.com (Ruda Zhang, Negin Alemazkoor)</author>
      <guid isPermaLink="false">2410.23482v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning Approaches for Improving Detection of Unseen Speech Deepfakes</title>
      <link>http://arxiv.org/abs/2410.20578v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, accepted to the IEEE Spoken Language Technology Workshop
  (SLT) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的语音深伪检测方法在对抗已知攻击时表现良好，但对未知攻击的泛化能力仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;解决在训练过程中未观察到的攻击的泛化问题，满足社交媒体上语音深伪的检测需求。&lt;h4&gt;方法&lt;/h4&gt;采用元学习的方法，学习攻击不变特征，以适应样本稀缺的未知攻击。&lt;h4&gt;主要发现&lt;/h4&gt;在InTheWild数据集上，使用仅96个未知数据集样本，Equal Error Rate (EER) 从21.67%降低到10.42%。&lt;h4&gt;结论&lt;/h4&gt;持续的少样本适应确保系统保持最新，表明该方法在检测未知攻击方面具有潜力。&lt;h4&gt;总结&lt;/h4&gt;通过元学习方法提高了对未知语音深伪的检测性能，展示了在样本稀缺情况下的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current speech deepfake detection approaches perform satisfactorily againstknown adversaries; however, generalization to unseen attacks remains an openchallenge. The proliferation of speech deepfakes on social media underscoresthe need for systems that can generalize to unseen attacks not observed duringtraining. We address this problem from the perspective of meta-learning, aimingto learn attack-invariant features to adapt to unseen attacks with very fewsamples available. This approach is promising since generating of a high-scaletraining dataset is often expensive or infeasible. Our experiments demonstratedan improvement in the Equal Error Rate (EER) from 21.67% to 10.42% on theInTheWild dataset, using just 96 samples from the unseen dataset. Continuousfew-shot adaptation ensures that the system remains up-to-date.</description>
      <author>example@mail.com (Ivan Kukanov, Janne Laakkonen, Tomi Kinnunen, Ville Hautamäki)</author>
      <guid isPermaLink="false">2410.20578v2</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Chess Reinforcement Learning with Graph Representation</title>
      <link>http://arxiv.org/abs/2410.23753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;掌握游戏是一项困难的任务，游戏的复杂性和结构差异使其挑战性增加。&lt;h4&gt;目的&lt;/h4&gt;探讨使用基于图的表示法来改进棋类游戏的学习算法，尤其是国际象棋。&lt;h4&gt;方法&lt;/h4&gt;引入图神经网络（GNN）架构，并扩展经典的图注意力网络（GAT）层以包含边特征。&lt;h4&gt;主要发现&lt;/h4&gt;新架构在参数数量相似的情况下，表现优于之前的架构，并能更快提高游戏水平。&lt;h4&gt;结论&lt;/h4&gt;模型在较小的5×5国际象棋变体上训练后，可以迅速微调以适应标准的8×8国际象棋，表明该方法具有良好的泛化能力。&lt;h4&gt;代码&lt;/h4&gt;代码可在https://github.com/akulen/AlphaGateau获取。&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图神经网络架构，改善了棋类游戏的学习效率和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/akulen/alphagateau&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mastering games is a hard task, as games can be extremely complex, and stillfundamentally different in structure from one another. While the AlphaZeroalgorithm has demonstrated an impressive ability to learn the rules andstrategy of a large variety of games, ranging from Go and Chess, to Atarigames, its reliance on extensive computational resources and rigidConvolutional Neural Network (CNN) architecture limits its adaptability andscalability. A model trained to play on a $19\times 19$ Go board cannot be usedto play on a smaller $13\times 13$ board, despite the similarity between thetwo Go variants. In this paper, we focus on Chess, and explore using a moregeneric Graph-based Representation of a game state, rather than a grid-basedone, to introduce a more general architecture based on Graph Neural Networks(GNN). We also expand the classical Graph Attention Network (GAT) layer toincorporate edge-features, to naturally provide a generic policy output format.Our experiments, performed on smaller networks than the initial AlphaZeropaper, show that this new architecture outperforms previous architectures witha similar number of parameters, being able to increase playing strength anorder of magnitude faster. We also show that the model, when trained on asmaller $5\times 5$ variant of chess, is able to be quickly fine-tuned to playon regular $8\times 8$ chess, suggesting that this approach yields promisinggeneralization abilities. Our code is available athttps://github.com/akulen/AlphaGateau.</description>
      <author>example@mail.com (Tomas Rigaux, Hisashi Kashima)</author>
      <guid isPermaLink="false">2410.23753v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Language-guided Hierarchical Fine-grained Image Forgery Detection and Localization</title>
      <link>http://arxiv.org/abs/2410.23556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCV2024. arXiv admin note: substantial text overlap with
  arXiv:2303.17111&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成对抗网络（CNN）合成的图像和图像编辑领域的伪造属性差异较大，这使得统一的图像伪造检测和定位（IFDL）变得具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种层次化细粒度的IFDL表示学习方法，以解决伪造图像属性的表示和分类问题。&lt;h4&gt;方法&lt;/h4&gt;构建了HiFi-Net++，包含四个组件：多分支特征提取器、语言引导伪造定位增强器、分类模块和定位模块。通过层次依赖关系进行细粒度分类，并使用对比语言-图像预训练（CLIP）来增强伪造定位。&lt;h4&gt;主要发现&lt;/h4&gt;HiFi-Net++在不同基准测试上展示了在IFDL和伪造属性分类任务中的有效性，能够学习全面特征和不同伪造属性的层次结构。&lt;h4&gt;结论&lt;/h4&gt;通过建立层次化细粒度数据集，进一步验证了方法的有效性，并提供了源代码和数据集以供研究使用。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的方法有效应对图像伪造检测中的复杂性，并在多个任务中取得了良好的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Differences in forgery attributes of images generated in CNN-synthesized andimage-editing domains are large, and such differences make a unified imageforgery detection and localization (IFDL) challenging. To this end, we presenta hierarchical fine-grained formulation for IFDL representation learning.Specifically, we first represent forgery attributes of a manipulated image withmultiple labels at different levels. Then, we perform fine-grainedclassification at these levels using the hierarchical dependency between them.As a result, the algorithm is encouraged to learn both comprehensive featuresand the inherent hierarchical nature of different forgery attributes. In thiswork, we propose a Language-guided Hierarchical Fine-grained IFDL, denoted asHiFi-Net++. Specifically, HiFi-Net++ contains four components: a multi-branchfeature extractor, a language-guided forgery localization enhancer, as well asclassification and localization modules. Each branch of the multi-branchfeature extractor learns to classify forgery attributes at one level, whilelocalization and classification modules segment pixel-level forgery regions anddetect image-level forgery, respectively. Also, the language-guided forgerylocalization enhancer (LFLE), containing image and text encoders learned bycontrastive language-image pre-training (CLIP), is used to further enrich theIFDL representation. LFLE takes specifically designed texts and the given imageas multi-modal inputs and then generates the visual embedding and manipulationscore maps, which are used to further improve HiFi-Net++ manipulationlocalization performance. Lastly, we construct a hierarchical fine-graineddataset to facilitate our study. We demonstrate the effectiveness of our methodon $8$ by using different benchmarks for both tasks of IFDL and forgeryattribute classification. Our source code and dataset are available.</description>
      <author>example@mail.com (Xiao Guo, Xiaohong Liu, Iacopo Masi, Xiaoming Liu)</author>
      <guid isPermaLink="false">2410.23556v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>DiffBatt: A Diffusion Model for Battery Degradation Prediction and Synthesis</title>
      <link>http://arxiv.org/abs/2410.23893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;电池衰退是绿色技术和可持续能源解决方案中的关键挑战，预测电池容量损失的准确性依然困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的电池衰退预测和合成模型，DiffBatt。&lt;h4&gt;方法&lt;/h4&gt;DiffBatt结合了条件和无条件扩散模型、无分类器引导以及变换器架构，具有高表现力和可扩展性。&lt;h4&gt;主要发现&lt;/h4&gt;DiffBatt作为概率模型捕捉衰老行为的不确定性，同时作为生成模型模拟电池衰退，在预测任务中表现优异，并生成合成衰退曲线以增强模型训练。&lt;h4&gt;结论&lt;/h4&gt;在剩余使用寿命预测任务中，DiffBatt提供了准确的结果，所有数据集的平均RMSE为196个周期，超越其他模型，展现出更好的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;该研究为电池衰退的基础模型开发迈出了重要一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Battery degradation remains a critical challenge in the pursuit of greentechnologies and sustainable energy solutions. Despite significant researchefforts, predicting battery capacity loss accurately remains a formidable taskdue to its complex nature, influenced by both aging and cycling behaviors. Toaddress this challenge, we introduce a novel general-purpose model for batterydegradation prediction and synthesis, DiffBatt. Leveraging an innovativecombination of conditional and unconditional diffusion models withclassifier-free guidance and transformer architecture, DiffBatt achieves highexpressivity and scalability. DiffBatt operates as a probabilistic model tocapture uncertainty in aging behaviors and a generative model to simulatebattery degradation. The performance of the model excels in prediction taskswhile also enabling the generation of synthetic degradation curves,facilitating enhanced model training by data augmentation. In the remaininguseful life prediction task, DiffBatt provides accurate results with a meanRMSE of 196 cycles across all datasets, outperforming all other models anddemonstrating superior generalizability. This work represents an important steptowards developing foundational models for battery degradation.</description>
      <author>example@mail.com (Hamidreza Eivazi, André Hebenbrock, Raphael Ginster, Steffen Blömeke, Stefan Wittek, Christoph Hermann, Thomas S. Spengler, Thomas Turek, Andreas Rausch)</author>
      <guid isPermaLink="false">2410.23893v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks Uncover Geometric Neural Representations in Reinforcement-Based Motor Learning</title>
      <link>http://arxiv.org/abs/2410.23812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 7 figures, accepted at the NeurIPS 2024 workshop on
  Symmetry and Geometry in Neural Representations (NeurReps 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）能够捕捉脑电图（EEG）数据中神经表征的几何特性。&lt;h4&gt;目的&lt;/h4&gt;研究基于强化学习的运动学习如何影响运动规划过程中的神经活动模式。&lt;h4&gt;方法&lt;/h4&gt;利用EEG通道的图结构捕捉脑活动的空间关系，并通过任务特定的对称性定义不同的预训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;预训练策略提高了所有参与者组的模型性能，且几何表征的鲁棒性得到了验证。&lt;h4&gt;结论&lt;/h4&gt;基于图结构的可解释性分析揭示了在不同预训练条件下持续存在的组特异性神经特征，表明与运动学习和反馈处理相关的神经表征中存在稳定的几何结构。&lt;h4&gt;总结&lt;/h4&gt;这项研究展示了GNN如何揭示先前结果对运动规划的影响，并为理解复杂任务中大脑活动的基本原则提供了新视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNN) can capture the geometric properties of neuralrepresentations in EEG data. Here we utilise those to study howreinforcement-based motor learning affects neural activity patterns duringmotor planning, leveraging the inherent graph structure of EEG channels tocapture the spatial relationships in brain activity. By exploitingtask-specific symmetries, we define different pretraining strategies that notonly improve model performance across all participant groups but also validatethe robustness of the geometric representations. Explainability analysis basedon the graph structures reveals consistent group-specific neural signaturesthat persist across pretraining conditions, suggesting stable geometricstructures in the neural representations associated with motor learning andfeedback processing. These geometric patterns exhibit partial invariance tocertain task space transformations, indicating symmetries that enablegeneralisation across conditions while maintaining specificity to individuallearning strategies. This work demonstrates how GNNs can uncover the effects ofprevious outcomes on motor planning, in a complex real-world task, providinginsights into the geometric principles governing neural representations. Ourexperimental design bridges the gap between controlled experiments andecologically valid scenarios, offering new insights into the organisation ofneural representations during naturalistic motor learning, which may openavenues for exploring fundamental principles governing brain activity incomplex tasks.</description>
      <author>example@mail.com (Federico Nardi, Jinpei Han, Shlomi Haar, A. Aldo Faisal)</author>
      <guid isPermaLink="false">2410.23812v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Identifiability Guarantees for Causal Disentanglement from Purely Observational Data</title>
      <link>http://arxiv.org/abs/2410.23620v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;因果解耦旨在了解数据背后的潜在因果因素，提升现有表示学习方法的可解释性和外推能力。&lt;h4&gt;目的&lt;/h4&gt;重新审视在仅使用观察数据的情况下，可以学习到哪些因果变量。&lt;h4&gt;方法&lt;/h4&gt;提供了在非线性因果模型中，考虑加性高斯噪声和线性混合的潜在因子的精确特征描述，不依赖于任何干预或图形限制。&lt;h4&gt;主要发现&lt;/h4&gt;因果变量可以在层次变换下被识别，但进一步的解耦是不可能的。&lt;h4&gt;结论&lt;/h4&gt;提出了一种实用算法，通过解决观察数据得分估计的二次规划，能够从纯观察数据中提取有意义的因果表示。&lt;h4&gt;总结&lt;/h4&gt;本研究为因果解耦提供了理论支持和实践算法，展示了在没有干预的情况下，如何有效识别因果关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Causal disentanglement aims to learn about latent causal factors behind data,holding the promise to augment existing representation learning methods interms of interpretability and extrapolation. Recent advances establishidentifiability results assuming that interventions on (single) latent factorsare available; however, it remains debatable whether such assumptions arereasonable due to the inherent nature of intervening on latent variables.Accordingly, we reconsider the fundamentals and ask what can be learned usingjust observational data.  We provide a precise characterization of latent factors that can beidentified in nonlinear causal models with additive Gaussian noise and linearmixing, without any interventions or graphical restrictions. In particular, weshow that the causal variables can be identified up to a layer-wisetransformation and that further disentanglement is not possible. We transformthese theoretical results into a practical algorithm consisting of solving aquadratic program over the score estimation of the observed data. We providesimulation results to support our theoretical guarantees and demonstrate thatour algorithm can derive meaningful causal representations from purelyobservational data.</description>
      <author>example@mail.com (Ryan Welch, Jiaqi Zhang, Caroline Uhler)</author>
      <guid isPermaLink="false">2410.23620v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian-guided Label Mapping for Visual Reprogramming</title>
      <link>http://arxiv.org/abs/2410.24018v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉重编程（VR）利用预训练视觉模型的内在能力，通过调整输入或输出接口来解决下游任务，这些任务的标签可能与预训练模型的标签完全不同。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，解决一对一标签映射方法忽视预训练标签与下游标签之间复杂关系的问题。&lt;h4&gt;方法&lt;/h4&gt;提出贝叶斯引导标签映射（BLM）方法，构建一个迭代更新的概率标签映射矩阵，量化预训练标签与下游标签之间的成对关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过贝叶斯条件概率引导矩阵赋值，考虑下游标签及预训练模型在下游样本上预测的标签的联合分布，BLM在实验中表现优于现有标签映射方法。&lt;h4&gt;结论&lt;/h4&gt;BLM的成功为理解和分析视觉重编程的有效性提供了一种概率视角。&lt;h4&gt;总结&lt;/h4&gt;BLM方法能够更好地处理标签映射问题，并在预训练视觉模型和视觉语言模型上展示了其优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tmlr-group/bayesianlm&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual reprogramming (VR) leverages the intrinsic capabilities of pretrainedvision models by adapting their input or output interfaces to solve downstreamtasks whose labels (i.e., downstream labels) might be totally different fromthe labels associated with the pretrained models (i.e., pretrained labels).When adapting the output interface, label mapping methods transform thepretrained labels to downstream labels by establishing a gradient-freeone-to-one correspondence between the two sets of labels. However, in thispaper, we reveal that one-to-one mappings may overlook the complex relationshipbetween pretrained and downstream labels. Motivated by this observation, wepropose a Bayesian-guided Label Mapping (BLM) method. BLM constructs aniteratively-updated probabilistic label mapping matrix, with each elementquantifying a pairwise relationship between pretrained and downstream labels.The assignment of values to the constructed matrix is guided by Bayesianconditional probability, considering the joint distribution of the downstreamlabels and the labels predicted by the pretrained model on downstream samples.Experiments conducted on both pretrained vision models (e.g., ResNeXt) andvision-language models (e.g., CLIP) demonstrate the superior performance of BLMover existing label mapping methods. The success of BLM also offers aprobabilistic lens through which to understand and analyze the effectiveness ofVR. Our code is available at https://github.com/tmlr-group/BayesianLM.</description>
      <author>example@mail.com (Chengyi Cai, Zesheng Ye, Lei Feng, Jianzhong Qi, Feng Liu)</author>
      <guid isPermaLink="false">2410.24018v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Sequential Order-Robust Mamba for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.23356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS Workshop on Time Series in the Age of Large Models, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Mamba作为一种有前景的替代品，提供了处理时序数据的近线性复杂度。&lt;h4&gt;目的&lt;/h4&gt;提出SOR-Mamba，一种时序预测方法，以解决现有研究中引入的序列顺序偏差问题。&lt;h4&gt;方法&lt;/h4&gt;1) 采用正则化策略，最小化通过反转通道顺序生成的两个嵌入向量之间的差异，以增强对通道顺序的鲁棒性；2) 消除原本用于捕捉序列数据局部信息的1D卷积。&lt;h4&gt;主要发现&lt;/h4&gt;引入通道相关建模（CCM）作为预训练任务，以保持数据空间和潜在空间之间的通道相关性，从而增强捕捉通道依赖性的能力。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的实验验证所提出方法在标准和迁移学习场景中的有效性。&lt;h4&gt;总结&lt;/h4&gt;SOR-Mamba在处理时序数据中表现出色，提供了对通道顺序更强的鲁棒性和更好的通道依赖性捕捉能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mamba has recently emerged as a promising alternative to Transformers,offering near-linear complexity in processing sequential data. However, whilechannels in time series (TS) data have no specific order in general, recentstudies have adopted Mamba to capture channel dependencies (CD) in TS,introducing a sequential order bias. To address this issue, we proposeSOR-Mamba, a TS forecasting method that 1) incorporates a regularizationstrategy to minimize the discrepancy between two embedding vectors generatedfrom data with reversed channel orders, thereby enhancing robustness to channelorder, and 2) eliminates the 1D-convolution originally designed to capturelocal information in sequential data. Furthermore, we introduce channelcorrelation modeling (CCM), a pretraining task aimed at preserving correlationsbetween channels from the data space to the latent space in order to enhancethe ability to capture CD. Extensive experiments demonstrate the efficacy ofthe proposed method across standard and transfer learning scenarios. Code isavailable at https://github.com/seunghan96/SOR-Mamba.</description>
      <author>example@mail.com (Seunghan Lee, Juri Hong, Kibok Lee, Taeyoung Park)</author>
      <guid isPermaLink="false">2410.23356v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Reducing Oversmoothing through Informed Weight Initialization in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.23830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有图神经网络（GNNs）通常使用针对其他神经网络类型的初始化方法，这忽视了图的拓扑结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的初始化方案（G-Init），旨在减少过平滑现象，从而在节点和图分类任务中取得良好效果。&lt;h4&gt;方法&lt;/h4&gt;对卷积GNNs中信号的前向传播和梯度的反向传播的方差进行理论分析，并将分析简化为GCN的情况，提出新的初始化方法。&lt;h4&gt;主要发现&lt;/h4&gt;新方法（G-Init）能有效减少深度GNNs中的过平滑现象，促进其有效使用。&lt;h4&gt;结论&lt;/h4&gt;实验验证支持理论发现，显示深度网络在没有特征信息的无标签节点（即“冷启动”场景）中具有优势。&lt;h4&gt;总结&lt;/h4&gt;G-Init方法为图神经网络提供了新的初始化思路，改善了模型在特定场景下的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we generalize the ideas of Kaiming initialization to GraphNeural Networks (GNNs) and propose a new scheme (G-Init) that reducesoversmoothing, leading to very good results in node and graph classificationtasks. GNNs are commonly initialized using methods designed for other types ofNeural Networks, overlooking the underlying graph topology. We analyzetheoretically the variance of signals flowing forward and gradients flowingbackward in the class of convolutional GNNs. We then simplify our analysis tothe case of the GCN and propose a new initialization method. Our resultsindicate that the new method (G-Init) reduces oversmoothing in deep GNNs,facilitating their effective use. Experimental validation supports ourtheoretical findings, demonstrating the advantages of deep networks inscenarios with no feature information for unlabeled nodes (i.e., ``cold start''scenario).</description>
      <author>example@mail.com (Dimitrios Kelesis, Dimitris Fotakis, Georgios Paliouras)</author>
      <guid isPermaLink="false">2410.23830v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Consistency in Graph Representations:from Graph Kernels to Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.23748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）作为图表示学习的主要方法，常常难以捕捉图之间一致的相似性关系。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在弥合神经网络方法与核方法之间的差距，使GNN能够一致地捕捉其学习表示中的关系结构。&lt;h4&gt;方法&lt;/h4&gt;通过比较和分析Weisfeiler-Lehman子树（WL-subtree）和Weisfeiler-Lehman最优分配（WLOA）核的性质，揭示其在相似性捕捉方面的优劣。&lt;h4&gt;主要发现&lt;/h4&gt;WLOA在不同迭代中捕捉的相似性是一致的，确保相似的图在后续迭代中保持相似，从而在性能上优于WL-subtree核。&lt;h4&gt;结论&lt;/h4&gt;图表示在GNN层间相似性的持续性对于捕捉关系结构和增强图分类性能至关重要，因此提出了一种损失函数以加强不同层间图表示的一致性。&lt;h4&gt;总结&lt;/h4&gt;实证分析验证了这一猜想，并显示所提出的一致性损失在多个数据集上显著提高了不同GNN骨架的图分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as a dominant approach in graphrepresentation learning, yet they often struggle to capture consistentsimilarity relationships among graphs. While graph kernel methods such as theWeisfeiler-Lehman subtree (WL-subtree) and Weisfeiler-Lehman optimal assignment(WLOA) kernels are effective in capturing similarity relationships, they relyheavily on predefined kernels and lack sufficient non-linearity for morecomplex data patterns. Our work aims to bridge the gap between neural networkmethods and kernel approaches by enabling GNNs to consistently capturerelational structures in their learned representations. Given the analogybetween the message-passing process of GNNs and WL algorithms, we thoroughlycompare and analyze the properties of WL-subtree and WLOA kernels. We find thatthe similarities captured by WLOA at different iterations are asymptoticallyconsistent, ensuring that similar graphs remain similar in subsequentiterations, thereby leading to superior performance over the WL-subtree kernel.Inspired by these findings, we conjecture that the consistency in thesimilarities of graph representations across GNN layers is crucial in capturingrelational structures and enhancing graph classification performance. Thus, wepropose a loss to enforce the similarity of graph representations to beconsistent across different layers. Our empirical analysis verifies ourconjecture and shows that our proposed consistency loss can significantlyenhance graph classification performance across several GNN backbones onvarious datasets.</description>
      <author>example@mail.com (Xuyuan Liu, Yinghao Cai, Qihui Yang, Yujun Yan)</author>
      <guid isPermaLink="false">2410.23748v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>SFM-Protein: Integrative Co-evolutionary Pre-training for Advanced Protein Sequence Representation</title>
      <link>http://arxiv.org/abs/2410.24022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;蛋白质是生物系统中必不可少的成分，其功能与三维结构密切相关。&lt;h4&gt;目的&lt;/h4&gt;理解蛋白质结构与氨基酸序列之间的关系，这是蛋白质建模中的核心挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的预训练策略，强调氨基酸残基之间的相互作用，以增强从序列数据中提取短程和长程共演化特征的能力。&lt;h4&gt;主要发现&lt;/h4&gt;在大规模蛋白质序列数据集上训练的模型表现出卓越的泛化能力，超越了包括ESM模型在内的同类基线。&lt;h4&gt;结论&lt;/h4&gt;实验结果证实了模型在整合共演化信息方面的有效性，这标志着蛋白质序列建模的重大进展。&lt;h4&gt;总结&lt;/h4&gt;本研究通过新策略提升了蛋白质建模的准确性和有效性，推动了该领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Proteins, essential to biological systems, perform functions intricatelylinked to their three-dimensional structures. Understanding the relationshipbetween protein structures and their amino acid sequences remains a corechallenge in protein modeling. While traditional protein foundation modelsbenefit from pre-training on vast unlabeled datasets, they often struggle tocapture critical co-evolutionary information, which evolutionary-based methodsexcel at. In this study, we introduce a novel pre-training strategy for proteinfoundation models that emphasizes the interactions among amino acid residues toenhance the extraction of both short-range and long-range co-evolutionaryfeatures from sequence data. Trained on a large-scale protein sequence dataset,our model demonstrates superior generalization ability, outperformingestablished baselines of similar size, including the ESM model, across diversedownstream tasks. Experimental results confirm the model's effectiveness inintegrating co-evolutionary information, marking a significant step forward inprotein sequence-based modeling.</description>
      <author>example@mail.com (Liang He, Peiran Jin, Yaosen Min, Shufang Xie, Lijun Wu, Tao Qin, Xiaozhuan Liang, Kaiyuan Gao, Yuliang Jiang, Tie-Yan Liu)</author>
      <guid isPermaLink="false">2410.24022v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>RAGraph: A General Retrieval-Augmented Graph Learning Framework</title>
      <link>http://arxiv.org/abs/2410.23855v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在多个领域中解释关系数据变得至关重要，但它们常常难以对与训练实例显著不同的未见图数据进行泛化。&lt;h4&gt;目的&lt;/h4&gt;提出一种新框架，称为通用检索增强图学习（RAGraph），以将外部图数据引入通用图基础模型，从而提高模型在未见场景中的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;建立一个玩具图向量库，捕捉关键属性，如特征和任务特定标签信息。在推断过程中，RAGraph 根据下游任务的关键相似性检索相似的玩具图，并通过消息传递提示机制整合检索的数据以丰富学习上下文。&lt;h4&gt;主要发现&lt;/h4&gt;RAGraph 在节点分类、链接预测和图分类等多个任务中显著超越了最先进的图学习方法，适用于动态和静态数据集。&lt;h4&gt;结论&lt;/h4&gt;RAGraph 在不需要特定任务微调的情况下，始终保持高性能，突显了其适应性、鲁棒性和广泛适用性。&lt;h4&gt;总结&lt;/h4&gt;RAGraph 提供了一种有效的方法来增强图神经网络在未见数据上的表现，展示了其在图学习领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become essential in interpreting relationaldata across various domains, yet, they often struggle to generalize to unseengraph data that differs markedly from training instances. In this paper, weintroduce a novel framework called General Retrieval-Augmented Graph Learning(RAGraph), which brings external graph data into the general graph foundationmodel to improve model generalization on unseen scenarios. On the top of ourframework is a toy graph vector library that we established, which captures keyattributes, such as features and task-specific label information. Duringinference, the RAGraph adeptly retrieves similar toy graphs based on keysimilarities in downstream tasks, integrating the retrieved data to enrich thelearning context via the message-passing prompting mechanism. Our extensiveexperimental evaluations demonstrate that RAGraph significantly outperformsstate-of-the-art graph learning methods in multiple tasks such as nodeclassification, link prediction, and graph classification across both dynamicand static datasets. Furthermore, extensive testing confirms that RAGraphconsistently maintains high performance without the need for task-specificfine-tuning, highlighting its adaptability, robustness, and broadapplicability.</description>
      <author>example@mail.com (Xinke Jiang, Rihong Qiu, Yongxin Xu, Wentao Zhang, Yichen Zhu, Ruizhe Zhang, Yuchen Fang, Xu Chu, Junfeng Zhao, Yasha Wang)</author>
      <guid isPermaLink="false">2410.23855v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Disentangling Disentangled Representations: Towards Improved Latent Units via Diffusion Models</title>
      <link>http://arxiv.org/abs/2410.23820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;解耦表示学习（DRL）旨在将观察到的数据分解为核心内在因素，以便更深入地理解数据。&lt;h4&gt;目的&lt;/h4&gt;探索在无监督条件下利用扩散模型（DMs）进行DRL，以克服手动定义和标记因素的困难。&lt;h4&gt;方法&lt;/h4&gt;设计动态高斯锚定（Dynamic Gaussian Anchoring）来强制属性分离的潜在单元，并提出跳过丢弃（Skip Dropout）技术，以优化去噪U-Net，使其更适合DRL。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法在合成和真实数据上展示了最先进的解耦性能，并在下游任务中表现出优势。&lt;h4&gt;结论&lt;/h4&gt;本研究增强了基于DM的解耦表示的实用性，促进了潜在单元的独立性和属性决策边界的明确性。&lt;h4&gt;总结&lt;/h4&gt;通过引入新的方法和技术，本文在无监督DRL领域中取得了重要进展，提升了模型的可解释性和实际应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Disentangled representation learning (DRL) aims to break down observed datainto core intrinsic factors for a profound understanding of the data. Inreal-world scenarios, manually defining and labeling these factors arenon-trivial, making unsupervised methods attractive. Recently, there have beenlimited explorations of utilizing diffusion models (DMs), which are alreadymainstream in generative modeling, for unsupervised DRL. They implement theirown inductive bias to ensure that each latent unit input to the DM expressesonly one distinct factor. In this context, we design Dynamic Gaussian Anchoringto enforce attribute-separated latent units for more interpretable DRL. Thisunconventional inductive bias explicitly delineates the decision boundariesbetween attributes while also promoting the independence among latent units.Additionally, we also propose Skip Dropout technique, which easily modifies thedenoising U-Net to be more DRL-friendly, addressing its uncooperative naturewith the disentangling feature extractor. Our methods, which carefully considerthe latent unit semantics and the distinct DM structure, enhance thepracticality of DM-based disentangled representations, demonstratingstate-of-the-art disentanglement performance on both synthetic and real data,as well as advantages in downstream tasks.</description>
      <author>example@mail.com (Youngjun Jun, Jiwoo Park, Kyobin Choo, Tae Eun Choi, Seong Jae Hwang)</author>
      <guid isPermaLink="false">2410.23820v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>EchoFM: Foundation Model for Generalizable Echocardiogram Analysis</title>
      <link>http://arxiv.org/abs/2410.23413v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型因其在多任务和数据分布上的泛化能力和适应性而受到广泛关注，但在心脏影像学，特别是超声心动图视频方面的解决方案尚未探索。&lt;h4&gt;目的&lt;/h4&gt;介绍EchoFM，一个专门设计用于表示和分析超声心动图视频的基础模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自监督学习框架，通过时空一致的遮罩策略和周期驱动的对比学习来捕捉时空变异模式，从而有效捕捉超声心动图的时空动态，并在无标签的情况下学习代表性的视频特征。&lt;h4&gt;主要发现&lt;/h4&gt;EchoFM在一个包含超过29万段超声心动图视频的广泛数据集上进行了预训练，涵盖了26种扫描视图和多种成像模式，总计可达2000万帧图像。&lt;h4&gt;结论&lt;/h4&gt;预训练的EchoFM能够轻松适应和微调多种下游任务，作为一个强大的基础模型，实验结果显示其在所有下游任务中超越了最先进的方法，包括专业的超声心动图方法、自监督预训练模型和通用预训练基础模型。&lt;h4&gt;总结&lt;/h4&gt;EchoFM展示了在心脏影像学领域的潜力，提供了一种有效的模型来推动超声心动图视频的分析和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have recently gained significant attention because of theirgeneralizability and adaptability across multiple tasks and data distributions.Although medical foundation models have emerged, solutions for cardiac imaging,especially echocardiography videos, are still unexplored. In this paper, weintroduce EchoFM, a foundation model specifically designed to represent andanalyze echocardiography videos. In EchoFM, we propose a self-supervisedlearning framework that captures both spatial and temporal variability patternsthrough a spatio-temporal consistent masking strategy and periodic-drivencontrastive learning. This framework can effectively capture thespatio-temporal dynamics of echocardiography and learn the representative videofeatures without any labels. We pre-train our model on an extensive datasetcomprising over 290,000 echocardiography videos covering 26 scan views acrossdifferent imaging modes, with up to 20 million frames of images. Thepre-trained EchoFM can then be easily adapted and fine-tuned for a variety ofdownstream tasks, serving as a robust backbone model. Our evaluation wassystemically designed for four downstream tasks after the echocardiographyexamination routine. Experiment results show that EchoFM surpassesstate-of-the-art methods, including specialized echocardiography methods,self-supervised pre-training models, and general-purposed pre-trainedfoundation models, across all downstream tasks.</description>
      <author>example@mail.com (Sekeun Kim, Pengfei Jin, Sifan Song, Cheng Chen, Yiwei Li, Hui Ren, Xiang Li, Tianming Liu, Quanzheng Li)</author>
      <guid isPermaLink="false">2410.23413v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>An Information Criterion for Controlled Disentanglement of Multimodal Data</title>
      <link>http://arxiv.org/abs/2410.23996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态表示学习旨在关联和分解多种模态中的信息。&lt;h4&gt;目的&lt;/h4&gt;通过分离特定模态的信息和共享信息，提高可解释性和鲁棒性，并支持生成反事实结果的下游任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的自监督学习方法——分离自监督学习（Disentangled SSL），用于学习分离的表示。&lt;h4&gt;主要发现&lt;/h4&gt;Disentangled SSL 在多个合成和真实世界数据集上成功学习了共享和特定模态的特征，并在各种下游任务上持续超越基线表现。&lt;h4&gt;结论&lt;/h4&gt;Disentangled SSL 能有效处理模态间信息深度纠缠的问题，特别是在最小必要信息点无法实现的情况下。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了分离表示学习的有效性，推动了多模态学习领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal representation learning seeks to relate and decompose informationinherent in multiple modalities. By disentangling modality-specific informationfrom information that is shared across modalities, we can improveinterpretability and robustness and enable downstream tasks such as thegeneration of counterfactual outcomes. Separating the two types of informationis challenging since they are often deeply entangled in many real-worldapplications. We propose Disentangled Self-Supervised Learning(DisentangledSSL), a novel self-supervised approach for learning disentangledrepresentations. We present a comprehensive analysis of the optimality of eachdisentangled representation, particularly focusing on the scenario not coveredin prior work where the so-called Minimum Necessary Information (MNI) point isnot attainable. We demonstrate that DisentangledSSL successfully learns sharedand modality-specific features on multiple synthetic and real-world datasetsand consistently outperforms baselines on various downstream tasks, includingprediction tasks for vision-language data, as well as molecule-phenotyperetrieval tasks for biological data.</description>
      <author>example@mail.com (Chenyu Wang, Sharut Gupta, Xinyi Zhang, Sana Tonekaboni, Stefanie Jegelka, Tommi Jaakkola, Caroline Uhler)</author>
      <guid isPermaLink="false">2410.23996v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Domain-decomposed image classification algorithms using linear discriminant analysis and convolutional neural networks</title>
      <link>http://arxiv.org/abs/2410.23359v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在现代计算机应用中，图像数据的分类扮演着重要角色。&lt;h4&gt;目的&lt;/h4&gt;比较两种不同域分解的卷积神经网络（CNN）模型在图像分类中的表现。&lt;h4&gt;方法&lt;/h4&gt;通过结合转移学习策略，对两种域分解的CNN模型进行实验比较，并提出了一种新的分解线性判别分析（LDA）策略。&lt;h4&gt;主要发现&lt;/h4&gt;与没有转移学习的全局CNN模型相比，所提出的模型显示出更高的分类准确性，并加快了训练过程；新提出的分解LDA策略在分类准确性上也优于全局LDA。&lt;h4&gt;结论&lt;/h4&gt;域分解的CNN和LDA方法在图像分类任务中表现出色，尤其是在处理复杂数据时。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了域分解技术与转移学习结合的有效性，提升了图像分类的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many modern computer application problems, the classification of imagedata plays an important role. Among many different supervised machine learningmodels, convolutional neural networks (CNNs) and linear discriminant analysis(LDA) as well as sophisticated variants thereof are popular techniques. In thiswork, two different domain decomposed CNN models are experimentally comparedfor different image classification problems. Both models are loosely inspiredby domain decomposition methods and in addition, combined with a transferlearning strategy. The resulting models show improved classification accuraciescompared to the corresponding, composed global CNN model without transferlearning and besides, also help to speed up the training process. Moreover, anovel decomposed LDA strategy is proposed which also relies on a localizationapproach and which is combined with a small neural network model. In comparisonwith a global LDA applied to the entire input data, the presented decomposedLDA approach shows increased classification accuracies for the considered testproblems.</description>
      <author>example@mail.com (Axel Klawonn, Martin Lanser, Janine Weber)</author>
      <guid isPermaLink="false">2410.23359v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Towards Cross-Modal Text-Molecule Retrieval with Better Modality Alignment</title>
      <link>http://arxiv.org/abs/2410.23715v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  BIBM 2024 regular paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;跨模态文本-分子检索模型旨在学习文本和分子模态的共享特征空间，以便准确计算相似性，从而加速药物设计中特定属性和活性的分子筛选。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在捕捉模态共享特征和对比学习、对抗训练的不足之处，以提高跨模态对齐的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的跨模态文本-分子检索模型，包含两种特定模态的编码器和一个基于记忆库的特征投影器，以更好地提取模态共享特征。同时在模型训练中计算四种相似性分布，并最小化这些分布之间的距离以增强跨模态对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该模型在跨模态对齐方面表现出色，尤其在性能上达到了SOTA，超越了之前报告的最佳结果6.4%。&lt;h4&gt;结论&lt;/h4&gt;新模型有效提升了跨模态文本与分子检索的准确性，并解决了现有方法的主要缺陷。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种改进的跨模态检索模型，显著提高了文本与分子之间的相似性计算效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/DeepLearnXMU/CMTMR&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cross-modal text-molecule retrieval model aims to learn a shared featurespace of the text and molecule modalities for accurate similarity calculation,which facilitates the rapid screening of molecules with specific properties andactivities in drug design. However, previous works have two main defects.First, they are inadequate in capturing modality-shared features consideringthe significant gap between text sequences and molecule graphs. Second, theymainly rely on contrastive learning and adversarial training for cross-modalityalignment, both of which mainly focus on the first-order similarity, ignoringthe second-order similarity that can capture more structural information in theembedding space. To address these issues, we propose a novel cross-modaltext-molecule retrieval model with two-fold improvements. Specifically, on thetop of two modality-specific encoders, we stack a memory bank based featureprojector that contain learnable memory vectors to extract modality-sharedfeatures better. More importantly, during the model training, we calculate fourkinds of similarity distributions (text-to-text, text-to-molecule,molecule-to-molecule, and molecule-to-text similarity distributions) for eachinstance, and then minimize the distance between these similarity distributions(namely second-order similarity losses) to enhance cross-modal alignment.Experimental results and analysis strongly demonstrate the effectiveness of ourmodel. Particularly, our model achieves SOTA performance, outperforming thepreviously-reported best result by 6.4%.</description>
      <author>example@mail.com (Jia Song, Wanru Zhuang, Yujie Lin, Liang Zhang, Chunyan Li, Jinsong Su, Song He, Xiaochen Bo)</author>
      <guid isPermaLink="false">2410.23715v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>In-Context Fine-Tuning for Time-Series Foundation Models</title>
      <link>http://arxiv.org/abs/2410.24087v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近期时间序列基础模型在零样本预测中的成功激励了本研究。&lt;h4&gt;目的&lt;/h4&gt;提出一种时间序列基础模型的上下文微调方法。&lt;h4&gt;方法&lt;/h4&gt;设计一个预训练的基础模型，能够在推理时通过多个时间序列示例进行预测。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在推理时利用上下文中的多个相关时间序列示例，能显著提升在流行预测基准上的表现。&lt;h4&gt;结论&lt;/h4&gt;这种上下文微调方法的性能甚至可以与专门在目标领域微调的基础模型相媲美。&lt;h4&gt;总结&lt;/h4&gt;提出的模型在时间序列预测中表现优异，超越了多种现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by the recent success of time-series foundation models forzero-shot forecasting, we present a methodology for $\textit{in-contextfine-tuning}$ of a time-series foundation model. In particular, we design apretrained foundation model that can be prompted (at inference time) withmultiple time-series examples, in order to forecast a target time-series intothe future. Our foundation model is specifically trained to utilize examplesfrom multiple related time-series in its context window (in addition to thehistory of the target time-series) to help it adapt to the specificdistribution of the target domain at inference time. We show that such afoundation model that uses in-context examples at inference time can obtainmuch better performance on popular forecasting benchmarks compared tosupervised deep learning methods, statistical models, as well as othertime-series foundation models. Interestingly, our in-context fine-tuningapproach even rivals the performance of a foundation model that is explicitlyfine-tuned on the target domain.</description>
      <author>example@mail.com (Abhimanyu Das, Matthew Faw, Rajat Sen, Yichen Zhou)</author>
      <guid isPermaLink="false">2410.24087v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Mind the Gap: A Generalized Approach for Cross-Modal Embedding Alignment</title>
      <link>http://arxiv.org/abs/2410.23437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;检索增强生成（RAG）系统通过整合外部知识来提高文本生成能力，但在不同文本模态间检索上下文时常遇到语义差距问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种通用的基于投影的方法，以高效弥补不同文本类型之间的语义差距。&lt;h4&gt;方法&lt;/h4&gt;该方法受迁移学习中适配器模块的启发，通过轻量级投影网络将异构文本模态的嵌入对齐到统一空间。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在速度、准确性和数据效率方面表现优异，显著超越传统检索方法（如Okapi BM25）和Dense Passage Retrieval（DPR）模型，接近Sentence Transformers的准确性。&lt;h4&gt;结论&lt;/h4&gt;通过广泛评估，证明了该方法在不同任务中的有效性和可推广性，显示出在实时、资源受限的应用中的潜力。&lt;h4&gt;总结&lt;/h4&gt;提出的方法为解决不同文本模态之间的语义差距提供了有效的解决方案，具有较高的实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieval-Augmented Generation (RAG) systems enhance text generation byincorporating external knowledge but often struggle when retrieving contextacross different text modalities due to semantic gaps. We introduce ageneralized projection-based method, inspired by adapter modules in transferlearning, that efficiently bridges these gaps between various text types, suchas programming code and pseudocode, or English and French sentences. Ourapproach emphasizes speed, accuracy, and data efficiency, requiring minimalresources for training and inference. By aligning embeddings from heterogeneoustext modalities into a unified space through a lightweight projection network,our model significantly outperforms traditional retrieval methods like theOkapi BM25 algorithm and models like Dense Passage Retrieval (DPR), whileapproaching the accuracy of Sentence Transformers. Extensive evaluationsdemonstrate the effectiveness and generalizability of our method acrossdifferent tasks, highlighting its potential for real-time, resource-constrainedapplications.</description>
      <author>example@mail.com (Arihan Yadav, Alan McMillan)</author>
      <guid isPermaLink="false">2410.23437v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Detecting text level intellectual influence with knowledge graph embeddings</title>
      <link>http://arxiv.org/abs/2410.24021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;追踪思想传播和影响力的存在是多个学科的重要问题，包括知识历史、文化分析、计算社会科学和科学研究等领域。&lt;h4&gt;目的&lt;/h4&gt;收集开放获取期刊文章的语料库，通过知识图谱表示来预测样本文章对之间的引用关系。&lt;h4&gt;方法&lt;/h4&gt;使用Gemini LLM生成知识图谱表示，利用先前发布的方法和新颖的基于图神经网络的嵌入模型进行引用预测。&lt;h4&gt;主要发现&lt;/h4&gt;我们的知识图谱嵌入方法在区分有引用和无引用的文章对方面表现优越，训练后运行高效，并可根据特定语料进行微调以满足个别研究者的需求。&lt;h4&gt;结论&lt;/h4&gt;实验表明，知识图谱中编码的关系，特别是特定关系所结合的概念类型，可以揭示知识影响力，进一步分析文档级知识图谱可能提供有价值的见解。&lt;h4&gt;总结&lt;/h4&gt;知识图谱的分析可能揭示潜在结构，为理解知识传播提供新视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Introduction: Tracing the spread of ideas and the presence of influence is aquestion of special importance across a wide range of disciplines, ranging fromintellectual history to cultural analytics, computational social science, andthe science of science.  Method: We collect a corpus of open source journal articles, generateKnowledge Graph representations using the Gemini LLM, and attempt to predictthe existence of citations between sampled pairs of articles using previouslypublished methods and a novel Graph Neural Network based embedding model.  Results: We demonstrate that our knowledge graph embedding method is superiorat distinguishing pairs of articles with and without citation. Once trained, itruns efficiently and can be fine-tuned on specific corpora to suit individualresearcher needs.  Conclusion(s): This experiment demonstrates that the relationships encoded ina knowledge graph, especially the types of concepts brought together byspecific relations can encode information capable of revealing intellectualinfluence. This suggests that further work in analyzing document levelknowledge graphs to understand latent structures could provide valuableinsights.</description>
      <author>example@mail.com (Lucian Li, Eryclis Silva)</author>
      <guid isPermaLink="false">2410.24021v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Open-Set 3D object detection in LiDAR data as an Out-of-Distribution problem</title>
      <link>http://arxiv.org/abs/2410.23767v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在受控环境中，基于LiDAR数据的3D物体检测通过先进的深度学习方法实现了行业级性能，但神经网络模型受限于有限的内类别物体。&lt;h4&gt;目的&lt;/h4&gt;将开放集3D物体检测问题重新定义为分布外（OOD）问题，以检测异常物体。&lt;h4&gt;方法&lt;/h4&gt;建立比较基准，展示两阶段OOD方法（特别是自动标记）在3D OOD物体检测中的良好表现。&lt;h4&gt;主要发现&lt;/h4&gt;通过严格的评估协议，分析超参数评估和生成额外数据的策略，以训练OOD感知的3D物体检测器。&lt;h4&gt;结论&lt;/h4&gt;此综合分析对开发能够在多样化和不可预测的现实场景中可靠运行的强健3D物体检测系统至关重要。&lt;h4&gt;总结&lt;/h4&gt;新方法为传统物体检测提供了额外信息，推动了3D物体检测技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Object Detection from LiDAR data has achieved industry-ready performancein controlled environments through advanced deep learning methods. However,these neural network models are limited by a finite set of inlier objectcategories. Our work redefines the open-set 3D Object Detection problem inLiDAR data as an Out-Of-Distribution (OOD) problem to detect outlier objects.This approach brings additional information in comparison with traditionalobject detection. We establish a comparative benchmark and show that two-stageOOD methods, notably autolabelling, show promising results for 3D OOD ObjectDetection. Our contributions include setting a rigorous evaluation protocol byexamining the evaluation of hyperparameters and evaluating strategies forgenerating additional data to train an OOD-aware 3D object detector. Thiscomprehensive analysis is essential for developing robust 3D object detectionsystems that can perform reliably in diverse and unpredictable real-worldscenarios.</description>
      <author>example@mail.com (Louis Soum-Fontez, Jean-Emmanuel Deschaud, François Goulette)</author>
      <guid isPermaLink="false">2410.23767v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Scaled Inverse Graphics: Efficiently Learning Large Sets of 3D Scenes</title>
      <link>http://arxiv.org/abs/2410.23742v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;逆图形学领域持续增长，目前的技术主要集中于学习单个场景表示。&lt;h4&gt;目的&lt;/h4&gt;解决在NeRF发展中学习大型场景集的瓶颈问题，以降低资源成本。&lt;h4&gt;方法&lt;/h4&gt;提出了一个名为“缩放逆图形学”的框架，通过两个阶段进行：第一阶段在子集场景上训练压缩模型，第二阶段在压缩后的表示上训练NeRF模型。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在缩放逆图形学中显示出最低的训练时间和内存占用，相比于独立处理每个场景的方法。&lt;h4&gt;结论&lt;/h4&gt;通过在潜在空间中学习NeRF以减小图像分辨率，并通过跨场景共享信息，显著降低了NeRF表示的复杂性。&lt;h4&gt;代码&lt;/h4&gt;我们的代码库已作为开源发布，项目页面为 https://scaled-ig.github.io。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种高效学习大规模场景表示的方法，为逆图形学的发展提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While the field of inverse graphics has been witnessing continuous growth,techniques devised thus far predominantly focus on learning individual scenerepresentations. In contrast, learning large sets of scenes has been aconsiderable bottleneck in NeRF developments, as repeatedly applying inversegraphics on a sequence of scenes, though essential for various applications,remains largely prohibitive in terms of resource costs. We introduce aframework termed "scaled inverse graphics", aimed at efficiently learning largesets of scene representations, and propose a novel method to this end. Itoperates in two stages: (i) training a compression model on a subset of scenes,then (ii) training NeRF models on the resulting smaller representations,thereby reducing the optimization space per new scene. In practice, we compactthe representation of scenes by learning NeRFs in a latent space to reduce theimage resolution, and sharing information across scenes to reduce NeRFrepresentation complexity. We experimentally show that our method presents boththe lowest training time and memory footprint in scaled inverse graphicscompared to other methods applied independently on each scene. Our codebase ispublicly available as open-source. Our project page can be found athttps://scaled-ig.github.io .</description>
      <author>example@mail.com (Karim Kassab, Antoine Schnepf, Jean-Yves Franceschi, Laurent Caraffa, Flavian Vasile, Jeremie Mary, Andrew Comport, Valérie Gouet-Brunet)</author>
      <guid isPermaLink="false">2410.23742v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing</title>
      <link>http://arxiv.org/abs/2410.24119v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型和生成性人工智能的出现有望改变科学计算中的生产力，尤其是在代码开发、重构和编程语言之间的转换方面。&lt;h4&gt;目的&lt;/h4&gt;探讨生成性人工智能在代码翻译、语言互操作性和遗留Fortran代码库检查中的应用。&lt;h4&gt;方法&lt;/h4&gt;开发了一个名为CodeScribe的工具，结合提示工程和用户监督，建立高效的代码转换流程。&lt;h4&gt;主要发现&lt;/h4&gt;CodeScribe能够将Fortran代码转换为C++，生成Fortran-C API以整合遗留系统与现代C++库，并为代码组织和算法实现提供开发者支持。&lt;h4&gt;结论&lt;/h4&gt;尽管生成性人工智能的输出无法保证正确性，但通过自动化任务特定工具和正确性验证方法，可以提高科学计算工作流程的生产力。&lt;h4&gt;挑战&lt;/h4&gt;AI驱动的代码翻译面临的挑战，以及其在科学计算中的生产力提升的优势。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了生成性人工智能在科学计算中的潜力，尤其是在提高代码转换效率和支持开发者方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/neucol/llm-conversion-performance&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of foundational models and generative artificial intelligence(GenAI) is poised to transform productivity in scientific computing, especiallyin code development, refactoring, and translating from one programming languageto another. However, because the output of GenAI cannot be guaranteed to becorrect, manual intervention remains necessary. Some of this intervention canbe automated through task-specific tools, alongside additional methodologiesfor correctness verification and effective prompt development. We explored theapplication of GenAI in assisting with code translation, languageinteroperability, and codebase inspection within a legacy Fortran codebase usedto simulate particle interactions at the Large Hadron Collider (LHC). In theprocess, we developed a tool, CodeScribe, which combines prompt engineeringwith user supervision to establish an efficient process for code conversion. Inthis paper, we demonstrate how CodeScribe assists in converting Fortran code toC++, generating Fortran-C APIs for integrating legacy systems with modern C++libraries, and providing developer support for code organization and algorithmimplementation. We also address the challenges of AI-driven code translationand highlight its benefits for enhancing productivity in scientific computingworkflows.</description>
      <author>example@mail.com (Akash Dhruv, Anshu Dubey)</author>
      <guid isPermaLink="false">2410.24119v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Identifying General Mechanism Shifts in Linear Causal Representations</title>
      <link>http://arxiv.org/abs/2410.24059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeuIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;我们考虑线性因果表示学习的设置，其中观察到$d$个未知潜在因素的线性混合，这些因素遵循线性结构因果模型。&lt;h4&gt;目的&lt;/h4&gt;放宽条件，允许不完美的单节点干预，并减少环境的数量，以便处理潜在因素数量$d$可能很大的情况。&lt;h4&gt;方法&lt;/h4&gt;允许小于$d$的环境数量，以及粗糙的干预，这些干预可以粗略地改变潜在因素的整个因果图。&lt;h4&gt;主要发现&lt;/h4&gt;在一些非常温和的标准假设下，可以识别出在一个或多个环境中发生变化的节点集合，并提供了必要和充分的条件来判断某节点是否为变化节点。&lt;h4&gt;结论&lt;/h4&gt;我们的算法适用于样本设置，并且在合成实验和心理测量数据集上验证了结果。&lt;h4&gt;总结&lt;/h4&gt;该研究为线性因果表示学习提供了新的方法，通过松弛干预条件，能够有效识别潜在因果结构中的变化节点。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the linear causal representation learning setting where weobserve a linear mixing of $d$ unknown latent factors, which follow a linearstructural causal model. Recent work has shown that it is possible to recoverthe latent factors as well as the underlying structural causal model over them,up to permutation and scaling, provided that we have at least $d$ environments,each of which corresponds to perfect interventions on a single latent node(factor). After this powerful result, a key open problem faced by the communityhas been to relax these conditions: allow for coarser than perfect single-nodeinterventions, and allow for fewer than $d$ of them, since the number of latentfactors $d$ could be very large. In this work, we consider precisely such asetting, where we allow a smaller than $d$ number of environments, and alsoallow for very coarse interventions that can very coarsely \textit{change theentire causal graph over the latent factors}. On the flip side, we relax whatwe wish to extract to simply the \textit{list of nodes that have shiftedbetween one or more environments}. We provide a surprising identifiabilityresult that it is indeed possible, under some very mild standard assumptions,to identify the set of shifted nodes. Our identifiability proof moreover is aconstructive one: we explicitly provide necessary and sufficient conditions fora node to be a shifted node, and show that we can check these conditions givenobserved data. Our algorithm lends itself very naturally to the sample settingwhere instead of just interventional distributions, we are provided datasets ofsamples from each of these distributions. We corroborate our results on bothsynthetic experiments as well as an interesting psychometric dataset. The codecan be found at https://github.com/TianyuCodings/iLCS.</description>
      <author>example@mail.com (Tianyu Chen, Kevin Bello, Francesco Locatello, Bryon Aragam, Pradeep Ravikumar)</author>
      <guid isPermaLink="false">2410.24059v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty Estimation for 3D Object Detection via Evidential Learning</title>
      <link>http://arxiv.org/abs/2410.23910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D物体检测是自动驾驶和机器人等计算机视觉应用中的关键任务，但模型在评估检测可靠性方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;引入一种框架，通过利用证据学习损失量化3D物体检测中的不确定性。&lt;h4&gt;方法&lt;/h4&gt;基于鸟瞰图表示的方法，在3D检测器中应用不确定性估计，且计算开销较小，适用于不同架构。&lt;h4&gt;主要发现&lt;/h4&gt;不确定性估计在识别分布外场景、定位不准确的物体和缺失检测方面表现出重要性，框架平均提高了10-20%的性能。&lt;h4&gt;结论&lt;/h4&gt;将这一任务套件集成到系统中，使3D物体检测器自动标记驾驶场景，并通过不确定性估计验证标签正确性，结果在mAP上提高了1%，在NDS上提高了1-2%。&lt;h4&gt;总结&lt;/h4&gt;该框架有效提升了3D物体检测的可靠性，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D object detection is an essential task for computer vision applications inautonomous vehicles and robotics. However, models often struggle to quantifydetection reliability, leading to poor performance on unfamiliar scenes. Weintroduce a framework for quantifying uncertainty in 3D object detection byleveraging an evidential learning loss on Bird's Eye View representations inthe 3D detector. These uncertainty estimates require minimal computationaloverhead and are generalizable across different architectures. We demonstrateboth the efficacy and importance of these uncertainty estimates on identifyingout-of-distribution scenes, poorly localized objects, and missing (falsenegative) detections; our framework consistently improves over baselines by10-20% on average. Finally, we integrate this suite of tasks into a systemwhere a 3D object detector auto-labels driving scenes and our uncertaintyestimates verify label correctness before the labels are used to train a secondmodel. Here, our uncertainty-driven verification results in a 1% improvement inmAP and a 1-2% improvement in NDS.</description>
      <author>example@mail.com (Nikita Durasov, Rafid Mahmood, Jiwoong Choi, Marc T. Law, James Lucas, Pascal Fua, Jose M. Alvarez)</author>
      <guid isPermaLink="false">2410.23910v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>JEMA: A Joint Embedding Framework for Scalable Co-Learning with Multimodal Alignment</title>
      <link>http://arxiv.org/abs/2410.23988v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着工业5.0在工业应用中的兴起，激光金属沉积（LMD）过程的有效监控变得愈加重要，但有限的数据和AI的不透明性带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出JEMA（联合嵌入与多模态对齐）框架，以解决LMD中的过程监控问题。&lt;h4&gt;方法&lt;/h4&gt;利用多模态数据（包括多视角图像和过程参数元数据），通过监督对比损失函数进行学习，简化硬件需求和计算负担。&lt;h4&gt;主要发现&lt;/h4&gt;JEMA在LMD过程监控中表现出色，特别是在下游任务如熔池几何预测上，无需大量微调即可实现良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;JEMA的实施展示了高可扩展性和性能，尤其是与Vision Transformer模型结合时，在多模态设置中性能提高了8%，单模态设置中提高了1%。&lt;h4&gt;总结&lt;/h4&gt;该框架为集成多传感器数据和元数据奠定了基础，支持LMD领域及其他领域的多样化下游任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces JEMA (Joint Embedding with Multimodal Alignment), anovel co-learning framework tailored for laser metal deposition (LMD), apivotal process in metal additive manufacturing. As Industry 5.0 gains tractionin industrial applications, efficient process monitoring becomes increasinglycrucial. However, limited data and the opaque nature of AI present challengesfor its application in an industrial setting. JEMA addresses this challenges byleveraging multimodal data, including multi-view images and metadata such asprocess parameters, to learn transferable semantic representations. By applyinga supervised contrastive loss function, JEMA enables robust learning andsubsequent process monitoring using only the primary modality, simplifyinghardware requirements and computational overhead. We investigate theeffectiveness of JEMA in LMD process monitoring, focusing specifically on itsgeneralization to downstream tasks such as melt pool geometry prediction,achieved without extensive fine-tuning. Our empirical evaluation demonstratesthe high scalability and performance of JEMA, particularly when combined withVision Transformer models. We report an 8% increase in performance inmultimodal settings and a 1% improvement in unimodal settings compared tosupervised contrastive learning. Additionally, the learned embeddingrepresentation enables the prediction of metadata, enhancing interpretabilityand making possible the assessment of the added metadata's contributions. Ourframework lays the foundation for integrating multisensor data with metadata,enabling diverse downstream tasks within the LMD domain and beyond.</description>
      <author>example@mail.com (Joao Sousa, Roya Darabi, Armando Sousa, Frank Brueckner, Luís Paulo Reis, Ana Reis)</author>
      <guid isPermaLink="false">2410.23988v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>BioNCERE: Non-Contrastive Enhancement For Relation Extraction In Biomedical Texts</title>
      <link>http://arxiv.org/abs/2410.23583v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 figures, 2 tables, 10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前生物医学领域的关系提取模型通过微调BioBERT进行分类，但可能面临各向异性问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的训练方法BioNCERE，以降低标注成本，进行关系提取。&lt;h4&gt;方法&lt;/h4&gt;BioNCERE结合迁移学习和非对比学习，通过三阶段的方式解决关系提取问题，避免完全或维度崩溃及过拟合。&lt;h4&gt;主要发现&lt;/h4&gt;在SemMedDB上的实验表明，BioNCERE在关系提取任务中表现接近最先进的性能，而不使用命名实体的信息。&lt;h4&gt;结论&lt;/h4&gt;BioNCERE能够有效进行关系提取，避免了对命名实体标签的依赖，并降低了标注成本。&lt;h4&gt;总结&lt;/h4&gt;通过引入非对比学习和迁移学习，BioNCERE为生物医学关系提取提供了一种新的高效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State-of-the-art models for relation extraction (RE) in the biomedical domainconsider finetuning BioBERT using classification, but they may suffer from theanisotropy problem. Contrastive learning methods can reduce this anisotropyphenomena, and also help to avoid class collapse in any classification problem.In the present paper, a new training method called biological non-contrastiverelation extraction (BioNCERE) is introduced for relation extraction withoutusing any named entity labels for training to reduce annotation costs. BioNCEREuses transfer learning and non-contrastive learning to avoid full ordimensional collapse as well as bypass overfitting. It resolves RE in threestages by leveraging transfer learning two times. By freezing the weightslearned in previous stages in the proposed pipeline and by leveragingnon-contrastive learning in the second stage, the model predicts relationswithout any knowledge of named entities. Experiments have been done on SemMedDBthat are almost similar to State-of-the-art performance on RE without using theinformation of named entities.</description>
      <author>example@mail.com (Farshad Noravesh)</author>
      <guid isPermaLink="false">2410.23583v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Get a Grip: Multi-Finger Grasp Evaluation at Scale Enables Robust Sim-to-Real Transfer</title>
      <link>http://arxiv.org/abs/2410.23701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多指抓取算法在实现从仿真到现实的稳健转移方面面临挑战，尤其在硬件部署时大多数方法效果下降。&lt;h4&gt;目的&lt;/h4&gt;探讨通过判别性抓取评估模型来改进多指抓取的选择和精细化过程。&lt;h4&gt;方法&lt;/h4&gt;发布一个包含350万个抓取样本的新开源数据集，涵盖4300个物体，并使用RGB图像、点云和训练的NeRF进行标注。&lt;h4&gt;主要发现&lt;/h4&gt;现有数据集和方法不足以训练多指抓取的判别性模型，训练效果依赖于大量的正负样本和与推理时一致的视觉数据。&lt;h4&gt;结论&lt;/h4&gt;利用新数据集训练的视觉抓取评估器，在模拟和真实世界试验中超越了分析和生成建模的基线，且评估器的质量显著影响性能。&lt;h4&gt;总结&lt;/h4&gt;新数据集的重要性在于其规模和多样性，证明了对多指抓取算法性能的关键影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work explores conditions under which multi-finger grasping algorithmscan attain robust sim-to-real transfer. While numerous large datasetsfacilitate learning generative models for multi-finger grasping at scale,reliable real-world dexterous grasping remains challenging, with most methodsdegrading when deployed on hardware. An alternate strategy is to usediscriminative grasp evaluation models for grasp selection and refinement,conditioned on real-world sensor measurements. This paradigm has producedstate-of-the-art results for vision-based parallel-jaw grasping, but remainsunproven in the multi-finger setting. In this work, we find that existingdatasets and methods have been insufficient for training discriminitive modelsfor multi-finger grasping. To train grasp evaluators at scale, datasets mustprovide on the order of millions of grasps, including both positive andnegative examples, with corresponding visual data resembling measurements atinference time. To that end, we release a new, open-source dataset of 3.5Mgrasps on 4.3K objects annotated with RGB images, point clouds, and trainedNeRFs. Leveraging this dataset, we train vision-based grasp evaluators thatoutperform both analytic and generative modeling-based baselines on extensivesimulated and real-world trials across a diverse range of objects. We show vianumerous ablations that the key factor for performance is indeed the evaluator,and that its quality degrades as the dataset shrinks, demonstrating theimportance of our new dataset. Project website at:https://sites.google.com/view/get-a-grip-dataset.</description>
      <author>example@mail.com (Tyler Ga Wei Lum, Albert H. Li, Preston Culbertson, Krishnan Srinivasan, Aaron D. Ames, Mac Schwager, Jeannette Bohg)</author>
      <guid isPermaLink="false">2410.23701v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Graph Learning for Numeric Planning</title>
      <link>http://arxiv.org/abs/2410.24080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Extended version of NeurIPS 2024 paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图学习适合用于符号对象中心规划，因为它能够利用规划领域中表现出的关系结构，并处理包含任意数量对象的规划实例。&lt;h4&gt;目的&lt;/h4&gt;提出高效且可解释的机器学习模型，以解决数值规划任务。&lt;h4&gt;方法&lt;/h4&gt;构建了一个新的图核，适用于具有连续和分类属性的图，并开发了新的优化方法来学习数值规划的启发式函数。&lt;h4&gt;主要发现&lt;/h4&gt;我们的图核在数值规划中比图神经网络更高效且具有更好的泛化能力，同时与领域无关的数值规划器相比，覆盖性能也具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在数值规划任务中表现优越，代码已公开在GitHub上。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了图学习在数值规划中的应用潜力，尤其在效率和解释性方面的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/DillonZChen/goose&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph learning is naturally well suited for use in symbolic, object-centricplanning due to its ability to exploit relational structures exhibited inplanning domains and to take as input planning instances with arbitrary numbersof objects. Numeric planning is an extension of symbolic planning in whichstates may now also exhibit numeric variables. In this work, we proposedata-efficient and interpretable machine learning models for learning to solvenumeric planning tasks. This involves constructing a new graph kernel forgraphs with both continuous and categorical attributes, as well as newoptimisation methods for learning heuristic functions for numeric planning.Experiments show that our graph kernels are vastly more efficient andgeneralise better than graph neural networks for numeric planning, and alsoyield competitive coverage performance compared to domain-independent numericplanners. Code is available at https://github.com/DillonZChen/goose</description>
      <author>example@mail.com (Dillon Z. Chen, Sylvie Thiébaux)</author>
      <guid isPermaLink="false">2410.24080v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>$π_0$: A Vision-Language-Action Flow Model for General Robot Control</title>
      <link>http://arxiv.org/abs/2410.24164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  See project website for videos:
  https://physicalintelligence.company/blog/pi0&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人学习有潜力解锁灵活、通用和灵巧的机器人系统，并解决人工智能中的一些深层次问题。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过通用机器人策略（即机器人基础模型）来应对数据、泛化和鲁棒性方面的主要挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于预训练视觉-语言模型的创新流匹配架构，以继承互联网规模的语义知识，并在多个灵巧机器人平台上使用大型多样化的数据集进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;模型在零-shot任务执行能力、遵循人类语言指令及高层次视觉-语言模型策略的能力，以及通过微调获取新技能方面表现良好。&lt;h4&gt;结论&lt;/h4&gt;模型展示了在多种任务（如折叠衣物、清洁桌面和组装箱子）上的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究为实现高效的通用机器人策略提供了新的方法和实证支持，推动了机器人学习的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot learning holds tremendous promise to unlock the full potential offlexible, general, and dexterous robot systems, as well as to address some ofthe deepest questions in artificial intelligence. However, bringing robotlearning to the level of generality required for effective real-world systemsfaces major obstacles in terms of data, generalization, and robustness. In thispaper, we discuss how generalist robot policies (i.e., robot foundation models)can address these challenges, and how we can design effective generalist robotpolicies for complex and highly dexterous tasks. We propose a novel flowmatching architecture built on top of a pre-trained vision-language model (VLM)to inherit Internet-scale semantic knowledge. We then discuss how this modelcan be trained on a large and diverse dataset from multiple dexterous robotplatforms, including single-arm robots, dual-arm robots, and mobilemanipulators. We evaluate our model in terms of its ability to perform tasks inzero shot after pre-training, follow language instructions from people and froma high-level VLM policy, and its ability to acquire new skills via fine-tuning.Our results cover a wide variety of tasks, such as laundry folding, tablecleaning, and assembling boxes.</description>
      <author>example@mail.com (Kevin Black, Noah Brown, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Lucy Xiaoyang Shi, James Tanner, Quan Vuong, Anna Walling, Haohuan Wang, Ury Zhilinsky)</author>
      <guid isPermaLink="false">2410.24164v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Inverse Reinforcement Learning: from Data Alignment to Task Alignment</title>
      <link>http://arxiv.org/abs/2410.23680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2306.01731&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多模仿学习算法使用逆强化学习推断与示范一致的奖励函数，但推断出的奖励函数常常无法捕捉到任务的真实目标。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的框架，优先考虑任务对齐而非传统的数据对齐。&lt;h4&gt;方法&lt;/h4&gt;该框架是一种半监督方法，利用专家示范作为弱监督，推导出一组与任务对齐的候选奖励函数，并采用对抗机制训练策略以验证政策完成任务的能力。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在复杂和迁移学习场景中优于传统的模仿学习基线。&lt;h4&gt;结论&lt;/h4&gt;提供了理论见解，缓解任务与奖励之间的不对齐问题，并展示了实际应用。&lt;h4&gt;总结&lt;/h4&gt;该研究为逆强化学习中的模仿学习提供了一种新方法，强调任务目标的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many imitation learning (IL) algorithms use inverse reinforcement learning(IRL) to infer a reward function that aligns with the demonstration. However,the inferred reward functions often fail to capture the underlying taskobjectives. In this paper, we propose a novel framework for IRL-based IL thatprioritizes task alignment over conventional data alignment. Our framework is asemi-supervised approach that leverages expert demonstrations as weaksupervision to derive a set of candidate reward functions that align with thetask rather than only with the data. It then adopts an adversarial mechanism totrain a policy with this set of reward functions to gain a collectivevalidation of the policy's ability to accomplish the task. We providetheoretical insights into this framework's ability to mitigate task-rewardmisalignment and present a practical implementation. Our experimental resultsshow that our framework outperforms conventional IL baselines in complex andtransfer learning scenarios.</description>
      <author>example@mail.com (Weichao Zhou, Wenchao Li)</author>
      <guid isPermaLink="false">2410.23680v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>GaussianMarker: Uncertainty-Aware Copyright Protection of 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2410.23718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting (3DGS) 已成为获取3D资产的重要方法。&lt;h4&gt;目的&lt;/h4&gt;保护这些资产的版权，通过数字水印技术在3DGS模型中嵌入所有权信息。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于不确定性的方法，限制模型参数的扰动，以实现对3DGS的隐形水印。&lt;h4&gt;主要发现&lt;/h4&gt;在消息解码阶段，即使在各种3D和2D失真情况下，版权信息也能从3D高斯和2D渲染图像中可靠提取。&lt;h4&gt;结论&lt;/h4&gt;在Blender、LLFF和MipNeRF-360数据集上进行了广泛实验，验证了所提方法在消息解码准确性和视图合成质量上的先进性。&lt;h4&gt;总结&lt;/h4&gt;该方法有效解决了现有水印技术无法直接应用于3DGS模型的问题，展示了优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has become a crucial method for acquiring 3Dassets. To protect the copyright of these assets, digital watermarkingtechniques can be applied to embed ownership information discreetly within 3DGSmodels. However, existing watermarking methods for meshes, point clouds, andimplicit radiance fields cannot be directly applied to 3DGS models, as 3DGSmodels use explicit 3D Gaussians with distinct structures and do not rely onneural networks. Naively embedding the watermark on a pre-trained 3DGS cancause obvious distortion in rendered images. In our work, we propose anuncertainty-based method that constrains the perturbation of model parametersto achieve invisible watermarking for 3DGS. At the message decoding stage, thecopyright messages can be reliably extracted from both 3D Gaussians and 2Drendered images even under various forms of 3D and 2D distortions. We conductextensive experiments on the Blender, LLFF and MipNeRF-360 datasets to validatethe effectiveness of our proposed method, demonstrating state-of-the-artperformance on both message decoding accuracy and view synthesis quality.</description>
      <author>example@mail.com (Xiufeng Huang, Ruiqi Li, Yiu-ming Cheung, Ka Chun Cheung, Simon See, Renjie Wan)</author>
      <guid isPermaLink="false">2410.23718v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Matchmaker: Self-Improving Large Language Model Programs for Schema Matching</title>
      <link>http://arxiv.org/abs/2410.24105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024, GenAI for Health Workshop and Table
  Representation Learning Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模式匹配是寻找不同数据源中属性匹配的任务，对于创建可互操作的机器学习数据至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决模式匹配问题，以增加可用于机器学习模型训练的数据，尤其在医疗、金融和电子商务等领域具有广泛的应用前景。&lt;h4&gt;方法&lt;/h4&gt;提出Matchmaker，一个由候选生成、精炼和置信评分组成的组合语言模型程序，能够在无标签的情况下自我改进。&lt;h4&gt;主要发现&lt;/h4&gt;Matchmaker在真实世界的医疗模式匹配基准测试中表现优于以前的机器学习方法，展示了其加速数据集成和互操作性的潜力。&lt;h4&gt;结论&lt;/h4&gt;Matchmaker通过一种新颖的优化方法构建合成上下文示例，指导语言模型的推理过程，从而克服了传统方法对大量标注数据的依赖。&lt;h4&gt;总结&lt;/h4&gt;Matchmaker为模式匹配提供了一种高效的解决方案，提升了机器学习数据的可用性和互操作性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Schema matching -- the task of finding matches between attributes acrossdisparate data sources with different tables and hierarchies -- is critical forcreating interoperable machine learning (ML)-ready data. Addressing thisfundamental data-centric problem has wide implications, especially in domainslike healthcare, finance and e-commerce -- but also has the potential tobenefit ML models more generally, by increasing the data available for ML modeltraining. However, schema matching is a challenging ML task due tostructural/hierarchical and semantic heterogeneity between different schemas.Previous ML approaches to automate schema matching have either requiredsignificant labeled data for model training, which is often unrealistic orsuffer from poor zero-shot performance. To this end, we propose Matchmaker - acompositional language model program for schema matching, comprised ofcandidate generation, refinement and confidence scoring. Matchmaker alsoself-improves in a zero-shot manner without the need for labeled demonstrationsvia a novel optimization approach, which constructs synthetic in-contextdemonstrations to guide the language model's reasoning process. Empirically, wedemonstrate on real-world medical schema matching benchmarks that Matchmakeroutperforms previous ML-based approaches, highlighting its potential toaccelerate data integration and interoperability of ML-ready data.</description>
      <author>example@mail.com (Nabeel Seedat, Mihaela van der Schaar)</author>
      <guid isPermaLink="false">2410.24105v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Progressive Safeguards for Safe and Model-Agnostic Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2410.24096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种正式的、模型无关的元学习框架，以实现安全强化学习。&lt;h4&gt;目的&lt;/h4&gt;通过父母如何保护孩子在风险逐渐增加的任务中，传递安全感来设计框架。&lt;h4&gt;方法&lt;/h4&gt;每个任务与一个监控安全并提供奖励信号的保护机制同步，保护机制由有限状态机实现，基于安全规范。&lt;h4&gt;主要发现&lt;/h4&gt;保护机制可以是复杂和非马尔可夫的，增强了训练过程的灵活性和学习策略的可解释性。&lt;h4&gt;结论&lt;/h4&gt;设计的保护机制是手动的，但高层次且模型无关，适用于各种场景，从像素级游戏控制到语言模型微调。&lt;h4&gt;应用&lt;/h4&gt;从给定的安全规范开始，训练模型以适应新的规范，仅需少量训练样本。&lt;h4&gt;技术优势&lt;/h4&gt;通过有效转移任务间的安全偏差，最大限度减少安全违规。&lt;h4&gt;实验结果&lt;/h4&gt;在Minecraft灵感的Gridworld、VizDoom游戏环境和LLM微调应用中评估，训练的代理实现了几乎最小的安全违规，基线表现不佳。&lt;h4&gt;总结&lt;/h4&gt;提出的框架在安全强化学习中展示了强大的应用潜力和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper we propose a formal, model-agnostic meta-learning framework forsafe reinforcement learning. Our framework is inspired by how parents safeguardtheir children across a progression of increasingly riskier tasks, imparting asense of safety that is carried over from task to task. We model this as ameta-learning process where each task is synchronized with a safeguard thatmonitors safety and provides a reward signal to the agent. The safeguard isimplemented as a finite-state machine based on a safety specification; thereward signal is formally shaped around this specification. The safetyspecification and its corresponding safeguard can be arbitrarily complex andnon-Markovian, which adds flexibility to the training process andexplainability to the learned policy. The design of the safeguard is manual butit is high-level and model-agnostic, which gives rise to an end-to-end safelearning approach with wide applicability, from pixel-level game control tolanguage model fine-tuning. Starting from a given set of safety specifications(tasks), we train a model such that it can adapt to new specifications usingonly a small number of training samples. This is made possible by our methodfor efficiently transferring safety bias between tasks, which effectivelyminimizes the number of safety violations. We evaluate our framework in aMinecraft-inspired Gridworld, a VizDoom game environment, and an LLMfine-tuning application. Agents trained with our approach achieve near-minimalsafety violations, while baselines are shown to underperform.</description>
      <author>example@mail.com (Nabil Omi, Hosein Hasanbeig, Hiteshi Sharma, Sriram K. Rajamani, Siddhartha Sen)</author>
      <guid isPermaLink="false">2410.24096v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>State- and context-dependent robotic manipulation and grasping via uncertainty-aware imitation learning</title>
      <link>http://arxiv.org/abs/2410.24035v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成适应环境的操作和抓取动作是机器人学中的一个挑战性问题，传统的规划和控制算法在外部变量（如物体形状）参数化方面往往不够灵活。&lt;h4&gt;目的&lt;/h4&gt;利用学习从示范（LfD）的方法，获取与环境相关的抓取和操作策略。&lt;h4&gt;方法&lt;/h4&gt;将问题视为基于核的函数近似，核输入包括描述任务相关参数（如物体形状）的通用上下文变量，并基于现有的不确定性量化政策融合工作，提出一种状态依赖的方法。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够自动回归于示范，避免不确定行为，并能平滑适应环境变化。&lt;h4&gt;结论&lt;/h4&gt;该方法在LASA手写数据集和真实的7自由度机器人上进行了评估，成功应对了抓取和操作可变形食品时的滑动适应。&lt;h4&gt;总结&lt;/h4&gt;通过LfD方法，可以有效地获得适应环境变化的抓取与操作策略，提升机器人在复杂场景中的灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating context-adaptive manipulation and grasping actions is achallenging problem in robotics. Classical planning and control algorithms tendto be inflexible with regard to parameterization by external variables such asobject shapes. In contrast, Learning from Demonstration (LfD) approaches, dueto their nature as function approximators, allow for introducing externalvariables to modulate policies in response to the environment. In this paper,we utilize this property by introducing an LfD approach to acquirecontext-dependent grasping and manipulation strategies. We treat the problem asa kernel-based function approximation, where the kernel inputs include genericcontext variables describing task-dependent parameters such as the objectshape. We build on existing work on policy fusion with uncertaintyquantification to propose a state-dependent approach that automatically returnsto demonstrations, avoiding unpredictable behavior while smoothly adapting tocontext changes. The approach is evaluated against the LASA handwriting datasetand on a real 7-DoF robot in two scenarios: adaptation to slippage whilegrasping and manipulating a deformable food item.</description>
      <author>example@mail.com (Tim R. Winter, Ashok M. Sundaram, Werner Friedl, Maximo A. Roa, Freek Stulp, João Silvério)</author>
      <guid isPermaLink="false">2410.24035v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Attention is All You Need to Optimize Wind Farm Operations and Maintenance</title>
      <link>http://arxiv.org/abs/2410.24052v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;风能系统的运营与维护(O&amp;M)是一个基础性问题，影响可靠性和盈利能力。&lt;h4&gt;目的&lt;/h4&gt;优化O&amp;M问题，平衡涡轮机故障风险、运营收入和维护人员物流。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的决策框架，基于多头注意力模型(MHA)，旨在解决大规模混合整数规划(MIP)模型带来的计算挑战。&lt;h4&gt;主要发现&lt;/h4&gt;{'解决时间': '将解决时间从小时减少到秒级。', '可行性': '保证在复杂约束条件下解决方案的可行性。', '解决质量': '相较于传统MIP模型，解决质量显著提高。', '迁移学习': '在不同问题设置中展现出显著的迁移学习能力。'}&lt;h4&gt;结论&lt;/h4&gt;提出的MHA框架在风电场O&amp;M中具有明显优势，能有效提升决策效率与质量。&lt;h4&gt;总结&lt;/h4&gt;该研究为风能系统的运营与维护提供了一种创新的解决方案，促进了人工智能在复杂决策问题中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Operations and maintenance (O&amp;M) is a fundamental problem in wind energysystems with far reaching implications for reliability and profitability.Optimizing O&amp;M is a multi-faceted decision optimization problem that requires acareful balancing act across turbine level failure risks, operational revenues,and maintenance crew logistics. The resulting O&amp;M problems are typically solvedusing large-scale mixed integer programming (MIP) models, which yieldcomputationally challenging problems that require either long-solution times,or heuristics to reach a solution. To address this problem, we introduce anovel decision-making framework for wind farm O&amp;M that builds on a multi-headattention (MHA) models, an emerging artificial intelligence methods that arespecifically designed to learn in rich and complex problem settings. Thedevelopment of proposed MHA framework incorporates a number of modelinginnovations that allows explicit embedding of MIP models within an MHAstructure. The proposed MHA model (i) significantly reduces the solution timefrom hours to seconds, (ii) guarantees feasibility of the proposed solutionsconsidering complex constraints that are omnipresent in wind farm O&amp;M, (iii)results in significant solution quality compared to the conventional MIPformulations, and (iv) exhibits significant transfer learning capability acrossdifferent problem settings.</description>
      <author>example@mail.com (Iman Kazemian, Murat Yildirim, Paritosh Ramanan)</author>
      <guid isPermaLink="false">2410.24052v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>Data-Driven Learning of Two-Stage Beamformers in Passive IRS-Assisted Systems with Inexact Oracles</title>
      <link>http://arxiv.org/abs/2410.24154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种高效的数据驱动和无模型的无监督学习算法，用于在无线通信网络中实现全被动智能反射面（IRS）辅助的最佳短期/长期波束成形。&lt;h4&gt;目的&lt;/h4&gt;解决具有连续不确定性和未知项的两阶段随机非凸优化问题。&lt;h4&gt;方法&lt;/h4&gt;基于零阶随机梯度上升方法，利用不精确评估oracle处理目标函数中的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;算法在现实和一般假设下运行，并且收敛率接近相关两阶段问题的某个静态点，尤其是在第二阶段波束成形问题使用任意不精确oracle解决时。&lt;h4&gt;结论&lt;/h4&gt;该算法适用于多种IRS辅助的最佳波束成形设置，无需依赖（级联）信道模型假设或信道统计知识，且不需要IRS的主动感知能力。&lt;h4&gt;实验结果&lt;/h4&gt;在多输入单输出（MISO）下行模型的多项实验中，算法表现出色，包括需要物理IRS调节的场景，即使在大规模情况下也有效。&lt;h4&gt;总结&lt;/h4&gt;该算法在多种条件下证明了其有效性，为IRS辅助的无线通信系统提供了一种新的优化方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We develop an efficient data-driven and model-free unsupervised learningalgorithm for achieving fully passive intelligent reflective surface(IRS)-assisted optimal short/long-term beamforming in wireless communicationnetworks. The proposed algorithm is based on a zeroth-order stochastic gradientascent methodology, suitable for tackling two-stage stochastic nonconvexoptimization problems with continuous uncertainty and unknown (or "black-box")terms present in the objective function, via the utilization of inexactevaluation oracles. We showcase that the algorithm can operate under realisticand general assumptions, and establish its convergence rate close to somestationary point of the associated two-stage (i.e., short/long-term) problem,particularly in cases where the second-stage (i.e., short-term) beamformingproblem (e.g., transmit precoding) is solved inexactly using an arbitrary(inexact) oracle. The proposed algorithm is applicable on a wide variety ofIRS-assisted optimal beamforming settings, while also being able to operatewithout (cascaded) channel model assumptions or knowledge of channelstatistics, and over arbitrary IRS physical configurations; thus, no activesensing capability at the IRS(s) is needed. Our algorithm is numericallydemonstrated to be very effective in a range of experiments pertaining to awell-studied MISO downlink model, including scenarios demanding physical IRStuning (e.g., directly through varactor capacitances), even in large-scaleregimes.</description>
      <author>example@mail.com (Spyridon Pougkakiotis, Hassaan Hashmi, Dionysis Kalogerias)</author>
      <guid isPermaLink="false">2410.24154v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>The Importance of Being Scalable: Improving the Speed and Accuracy of Neural Network Interatomic Potentials Across Chemical Domains</title>
      <link>http://arxiv.org/abs/2410.24169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模型性能和泛化能力的提升在机器学习中至关重要，涉及模型大小或输入数据增加时性能的变化和计算资源的高效利用。&lt;h4&gt;目的&lt;/h4&gt;研究神经网络相互作用势（NNIPs）在缩放方面的表现，解决其在规模增长时的性能瓶颈。&lt;h4&gt;方法&lt;/h4&gt;系统地研究NNIP缩放策略，采用注意力机制来提高模型的表现力。&lt;h4&gt;主要发现&lt;/h4&gt;通过注意力机制缩放模型是高效的，能够显著提高模型的表现力。开发了名为高效缩放注意力相互作用势（EScAIP）的新架构。&lt;h4&gt;结论&lt;/h4&gt;EScAIP使用图神经网络中的多头自注意力形式，显著提高了推理速度和内存使用效率，且在多种数据集上表现优异。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种理念，而非具体模型，展示了开发通用NNIPs的可能性，以便在增加计算资源和训练数据的同时，持续提升表现力和缩放效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scaling has been critical in improving model performance and generalizationin machine learning. It involves how a model's performance changes withincreases in model size or input data, as well as how efficiently computationalresources are utilized to support this growth. Despite successes in otherareas, the study of scaling in Neural Network Interatomic Potentials (NNIPs)remains limited. NNIPs act as surrogate models for ab initio quantum mechanicalcalculations. The dominant paradigm here is to incorporate many physical domainconstraints into the model, such as rotational equivariance. We contend thatthese complex constraints inhibit the scaling ability of NNIPs, and are likelyto lead to performance plateaus in the long run. In this work, we take analternative approach and start by systematically studying NNIP scalingstrategies. Our findings indicate that scaling the model through attentionmechanisms is efficient and improves model expressivity. These insightsmotivate us to develop an NNIP architecture designed for scalability: theEfficiently Scaled Attention Interatomic Potential (EScAIP). EScAIP leverages amulti-head self-attention formulation within graph neural networks, applyingattention at the neighbor-level representations. Implemented withhighly-optimized attention GPU kernels, EScAIP achieves substantial gains inefficiency--at least 10x faster inference, 5x less memory usage--compared toexisting NNIPs. EScAIP also achieves state-of-the-art performance on a widerange of datasets including catalysts (OC20 and OC22), molecules (SPICE), andmaterials (MPTrj). We emphasize that our approach should be thought of as aphilosophy rather than a specific model, representing a proof-of-concept fordeveloping general-purpose NNIPs that achieve better expressivity throughscaling, and continue to scale efficiently with increased computationalresources and training data.</description>
      <author>example@mail.com (Eric Qu, Aditi S. Krishnapriyan)</author>
      <guid isPermaLink="false">2410.24169v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>URAvatar: Universal Relightable Gaussian Codec Avatars</title>
      <link>http://arxiv.org/abs/2410.24223v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SIGGRAPH Asia 2024. Website:
  https://junxuan-li.github.io/urgca-website/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种从手机扫描生成真实感可重光照的头像的新方法。&lt;h4&gt;目的&lt;/h4&gt;实现实时动画和重光照的头像，适应不同环境的全局光照。&lt;h4&gt;方法&lt;/h4&gt;直接建模可学习的辐射传输，利用高质量的多视角人类扫描和3D高斯模型进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在精度和泛化能力上超过现有方法，且保持实时渲染能力。&lt;h4&gt;结论&lt;/h4&gt;通过逆向渲染微调预训练模型，可以获得个性化的可重光照头像。&lt;h4&gt;总结&lt;/h4&gt;该方法有效解决了手机扫描在多环境下头像重光照的挑战，展示了较好的实时渲染效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a new approach to creating photorealistic and relightable headavatars from a phone scan with unknown illumination. The reconstructed avatarscan be animated and relit in real time with the global illumination of diverseenvironments. Unlike existing approaches that estimate parametric reflectanceparameters via inverse rendering, our approach directly models learnableradiance transfer that incorporates global light transport in an efficientmanner for real-time rendering. However, learning such a complex lighttransport that can generalize across identities is non-trivial. A phone scan ina single environment lacks sufficient information to infer how the head wouldappear in general environments. To address this, we build a universalrelightable avatar model represented by 3D Gaussians. We train on hundreds ofhigh-quality multi-view human scans with controllable point lights.High-resolution geometric guidance further enhances the reconstruction accuracyand generalization. Once trained, we finetune the pretrained model on a phonescan using inverse rendering to obtain a personalized relightable avatar. Ourexperiments establish the efficacy of our design, outperforming existingapproaches while retaining real-time rendering capability.</description>
      <author>example@mail.com (Junxuan Li, Chen Cao, Gabriel Schwartz, Rawal Khirodkar, Christian Richardt, Tomas Simon, Yaser Sheikh, Shunsuke Saito)</author>
      <guid isPermaLink="false">2410.24223v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>ImOV3D: Learning Open-Vocabulary Point Clouds 3D Object Detection from Only 2D Images</title>
      <link>http://arxiv.org/abs/2410.24001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024. Code link
  https://github.com/yangtiming/ImOV3D&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;开放词汇3D物体检测（OV-3Det）旨在超越训练阶段标记的有限基础类别，但Annotated 3D数据稀缺。&lt;h4&gt;目的&lt;/h4&gt;探讨仅利用2D图像学习OV-3Det，以缓解数据稀缺问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型框架ImOV3D，利用伪多模态表示结合2D图像和点云，弥合训练图像和测试点云之间的模态差距。&lt;h4&gt;主要发现&lt;/h4&gt;ImOV3D在两个基准数据集（SUNRGBD和ScanNet）上表现显著优于现有方法，即使在没有真实3D训练数据的情况下。&lt;h4&gt;结论&lt;/h4&gt;通过少量真实3D数据进行微调后，ImOV3D的性能也显著超越了之前的最先进技术。&lt;h4&gt;代码链接&lt;/h4&gt;代码和预训练模型发布在 https://github.com/yangtiming/ImOV3D。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了如何有效利用2D图像来提升3D物体检测的性能，尤其是在数据稀缺的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-31&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yangtiming/imov3d&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary 3D object detection (OV-3Det) aims to generalize beyond thelimited number of base categories labeled during the training phase. Thebiggest bottleneck is the scarcity of annotated 3D data, whereas 2D imagedatasets are abundant and richly annotated. Consequently, it is intuitive toleverage the wealth of annotations in 2D images to alleviate the inherent datascarcity in OV-3Det. In this paper, we push the task setup to its limits byexploring the potential of using solely 2D images to learn OV-3Det. The majorchallenges for this setup is the modality gap between training images andtesting point clouds, which prevents effective integration of 2D knowledge intoOV-3Det. To address this challenge, we propose a novel framework ImOV3D toleverage pseudo multimodal representation containing both images and pointclouds (PC) to close the modality gap. The key of ImOV3D lies in flexiblemodality conversion where 2D images can be lifted into 3D using monocular depthestimation and can also be derived from 3D scenes through rendering. Thisallows unifying both training images and testing point clouds into a commonimage-PC representation, encompassing a wealth of 2D semantic information andalso incorporating the depth and structural characteristics of 3D spatial data.We carefully conduct such conversion to minimize the domain gap betweentraining and test cases. Extensive experiments on two benchmark datasets,SUNRGBD and ScanNet, show that ImOV3D significantly outperforms existingmethods, even in the absence of ground truth 3D training data. With theinclusion of a minimal amount of real 3D data for fine-tuning, the performancealso significantly surpasses previous state-of-the-art. Codes and pre-trainedmodels are released on the https://github.com/yangtiming/ImOV3D.</description>
      <author>example@mail.com (Timing Yang, Yuanliang Ju, Li Yi)</author>
      <guid isPermaLink="false">2410.24001v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
    <item>
      <title>FilMBot: A High-Speed Soft Parallel Robotic Micromanipulator</title>
      <link>http://arxiv.org/abs/2410.23059v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;软机器人操作器通常速度较慢，但具有良好的适应性、韧性和柔性，这种限制也影响了当前的软机器人微操作器。&lt;h4&gt;目的&lt;/h4&gt;介绍FilMBot，一种基于薄膜的电磁驱动软机器人微操作器。&lt;h4&gt;方法&lt;/h4&gt;FilMBot具有3个自由度，使用4厘米针头末端执行器，能够实现高达2117度/秒和2456度/秒的角速度。&lt;h4&gt;主要发现&lt;/h4&gt;FilMBot在路径跟随任务中最高速度可达~1.50 m/s，操作频率可达30 Hz，功能保持到50 Hz，且在小型路径跟随任务中精度高达~6.3微米（约0.05%工作空间）。&lt;h4&gt;结论&lt;/h4&gt;FilMBot的新型低刚度软运动结构与强电磁驱动的结合为软机器人开辟了新的应用途径，其简单构造和廉价、易获取的组件可能扩大微操作器的应用范围。&lt;h4&gt;总结&lt;/h4&gt;FilMBot的设计和性能展示了软机器人在速度和精度上的潜力，可能推动其在学术和专业领域以外的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft robotic manipulators are generally slow despite their greatadaptability, resilience, and compliance. This limitation also extends tocurrent soft robotic micromanipulators. Here, we introduce FilMBot, a 3-DOFfilm-based, electromagnetically actuated, soft kinematic roboticmicromanipulator achieving speeds up to 2117 $\deg$/s and 2456 $\deg$/s in$\alpha$ and $\beta$ angular motions, with corresponding linear velocities of1.61 m/s and 1.92 m/s using a 4-cm needle end-effector, and 1.57 m/s along theZ axis. The robot can reach ~1.50 m/s in path-following tasks, operates atfrequencies up to 30 Hz, and remains functional up to 50 Hz. It demonstrateshigh precision (~6.3 $\mu$m, or ~0.05% of its workspace) in smallpath-following tasks. The novel combination of the low-stiffness soft kinematicfilm structure and strong electromagnetic actuation in FilMBot opens newavenues for soft robotics. Furthermore, its simple construction andinexpensive, readily accessible components could broaden the application ofmicromanipulators beyond current academic and professional users.</description>
      <author>example@mail.com (Jiangkun Yu, Houari Bettahar, Hakan Kandemir, Quan Zhou)</author>
      <guid isPermaLink="false">2410.23059v1</guid>
      <pubDate>Fri, 08 Nov 2024 23:20:58 +0800</pubDate>
    </item>
  </channel>
</rss>
