<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 02 Nov 2024 08:43:59 +0800</lastBuildDate>
    <item>
      <title>Analyzing Neural Network Robustness Using Graph Curvature</title>
      <link>http://arxiv.org/abs/2410.19607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文从图论分析的角度探讨神经网络的鲁棒性问题，特别是图曲率。&lt;h4&gt;目的&lt;/h4&gt;定义神经Ricci曲率，以识别在神经网络中用于“传输数据”的瓶颈边。&lt;h4&gt;方法&lt;/h4&gt;通过对MNIST数据集的评估，分析瓶颈边在神经网络中的出现频率。&lt;h4&gt;主要发现&lt;/h4&gt;在神经网络鲁棒性较差的输入情况下，瓶颈边的出现频率更高。&lt;h4&gt;结论&lt;/h4&gt;这些结果为通过最小化瓶颈边数量提供了一种替代的鲁棒训练方法。&lt;h4&gt;总结&lt;/h4&gt;研究表明，图曲率分析能够有效识别神经网络中的瓶颈，进而提升鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a new look at the neural network (NN) robustness problem,from the point of view of graph theory analysis, specifically graph curvature.Graph curvature (e.g., Ricci curvature) has been used to analyze systemdynamics and identify bottlenecks in many domains, including road trafficanalysis and internet routing. We define the notion of neural Ricci curvatureand use it to identify bottleneck NN edges that are heavily used to ``transportdata" to the NN outputs. We provide an evaluation on MNIST that illustratesthat such edges indeed occur more frequently for inputs where NNs are lessrobust. These results will serve as the basis for an alternative method ofrobust training, by minimizing the number of bottleneck edges.</description>
      <author>example@mail.com (Shuhang Tan, Jayson Sia, Paul Bogdan, Radoslav Ivanov)</author>
      <guid isPermaLink="false">2410.19607v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.19639v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CoRL Workshop Leap 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主驾驶技术取得了显著进展，但现有模型无法充分捕捉多智能体环境的复杂性，动态智能体之间的交互至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出规划集成预测模型（PIFM），以改善多智能体环境下的预测精度和可解释性。&lt;h4&gt;方法&lt;/h4&gt;PIFM灵感来源于大脑中决策和多智能体协调的神经机制，利用丰富的上下文信息，集成道路结构、交通规则和周围车辆的行为，采用基于扩散的架构进行预测。&lt;h4&gt;主要发现&lt;/h4&gt;PIFM能够预测场景中所有智能体的未来轨迹，增强了模型的透明度，与大脑基于外部刺激和其他智能体行为动态调整预测的方法相似。&lt;h4&gt;结论&lt;/h4&gt;大量实验证明，PIFM提供了可解释的、基于神经科学的解决方案，能够实现更安全和高效的自主驾驶系统，并且参数数量极少。&lt;h4&gt;总结&lt;/h4&gt;PIFM是一个创新框架，旨在通过整合多方面信息，提升自主驾驶中的预测能力和透明度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving technology has seen significant advancements, but existingmodels often fail to fully capture the complexity of multi-agent environments,where interactions between dynamic agents are critical. To address this, wepropose the Planning-Integrated Forecasting Model (PIFM), a novel frameworkinspired by neural mechanisms governing decision-making and multi-agentcoordination in the brain. PIFM leverages rich contextual information,integrating road structures, traffic rules, and the behavior of surroundingvehicles to improve both the accuracy and interpretability of predictions. Byadopting a diffusion-based architecture, akin to neural diffusion processesinvolved in predicting and planning, PIFM is able to forecast futuretrajectories of all agents within a scenario. This architecture enhances modeltransparency, as it parallels the brain's method of dynamically adjustingpredictions based on external stimuli and other agents'behaviors. Extensiveexperiments validate PIFM's capacity to provide interpretable,neuroscience-driven solutions for safer and more efficient autonomous drivingsystems, with an extremely low number of parameters.</description>
      <author>example@mail.com (Liu Yunhao, Ding Hong, Zhang Ziming, Wang Huixin, Liu Jinzhao, Xi Suyang)</author>
      <guid isPermaLink="false">2410.19639v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery</title>
      <link>http://arxiv.org/abs/2410.19701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统入侵检测系统（IDS）通常依赖于网络流量或进程数据，单一来源的方法可能无法捕捉到跨多个层次的复杂攻击模式。&lt;h4&gt;目的&lt;/h4&gt;研究结合网络和进程数据是否能提高工业控制系统（ICS）环境中的攻击检测能力。&lt;h4&gt;方法&lt;/h4&gt;利用SWaT数据集，评估多种机器学习模型对单一和组合数据源的表现。&lt;h4&gt;主要发现&lt;/h4&gt;整合网络流量和操作过程数据可以增强检测能力，提升网络攻击分类的召回率。&lt;h4&gt;结论&lt;/h4&gt;在有限的测试环境中，这项研究证明了通过多源数据方法推进ICS入侵检测的可行性。&lt;h4&gt;未来工作&lt;/h4&gt;尽管结果令人鼓舞，但仍需在不同数据集和改进方法论的基础上进行进一步研究。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了多源数据在提高ICS入侵检测中的潜力，但结果仍处于初步阶段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the inclusion of microservices architecture in thedevelopment of scalable and reliable airline reservation systems. Most of thetraditional reservation systems are very rigid and centralized which makes themprone to bottlenecks and a single point of failure. As such, systems do notmeet the requirements of modern airlines which are dynamic. Microservices offerbetter resiliency and scalability because the services do not depend on oneanother and can be deployed independently. The approach is grounded on theCircuit Breaker Pattern to maintain fault tolerance while consuming foreignresources such as flight APIs and payment systems. This avoided the failurepropagation to the systems by 60% enabling the systems to function underexternal failures. Traffic rerouting also bolstered this with a guarantee ofabove 99.95% uptime in systems where high availability was demanded. To addressthis, load balancing was used, particularly the Round-Robin method whichmanaged to enhance performance by 35% through the equal distribution of userrequests among the service instances. Health checks, as well as monitoring inreal-time, helped as well with failure management as they helped to containfailures before the users of the system were affected. The results suggest thatthe use of microservices led to a 40% increase in system scalability, a 50%decrease in downtime and a support for 30% more concurrent users than the useof monolithic architectures. These findings affirm the capability ofmicroservices in the development of robust and flexible airline ticket bookingsystems that are responsive to change and recover from external systemunavailability.</description>
      <author>example@mail.com (Biman Barua, M. Shamim Kaiser)</author>
      <guid isPermaLink="false">2410.19701v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Anomaly Detection in Industrial Control Systems aided by Machine Learning</title>
      <link>http://arxiv.org/abs/2410.19717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, Norwegian Information Security Conference, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统入侵检测系统（IDS）通常依赖于网络流量或进程数据，单一来源的方法可能无法捕捉到跨多个层次的复杂攻击模式。&lt;h4&gt;目的&lt;/h4&gt;研究结合网络和进程数据是否能提高工业控制系统（ICS）环境中的攻击检测能力。&lt;h4&gt;方法&lt;/h4&gt;利用SWaT数据集，评估多种机器学习模型对单一和组合数据源的表现。&lt;h4&gt;主要发现&lt;/h4&gt;整合网络流量和操作过程数据可以增强检测能力，提升网络攻击分类的召回率。&lt;h4&gt;结论&lt;/h4&gt;在有限的测试环境中，这项研究证明了通过多源数据方法推进ICS入侵检测的可行性。&lt;h4&gt;未来工作&lt;/h4&gt;尽管结果令人鼓舞，但仍需在不同数据集和改进方法论的基础上进行进一步研究。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了多源数据在提高ICS入侵检测中的潜力，但结果仍处于初步阶段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional intrusion detection systems (IDSs) often rely on either networktraffic or process data, but this single-source approach may miss complexattack patterns that span multiple layers within industrial control systems(ICSs) or persistent threats that target different layers of operationaltechnology systems. This study investigates whether combining both network andprocess data can improve attack detection in ICSs environments. Leveraging theSWaT dataset, we evaluate various machine learning models on individual andcombined data sources. Our findings suggest that integrating network trafficwith operational process data can enhance detection capabilities, evidenced byimproved recall rates for cyber attack classification. Serving as aproof-of-concept within a limited testing environment, this research exploresthe feasibility of advancing intrusion detection through a multi-source dataapproach in ICSs. Although the results are promising, they are preliminary andhighlight the need for further studies across diverse datasets and refinedmethodologies.</description>
      <author>example@mail.com (Vegard Berge, Chunlei Li)</author>
      <guid isPermaLink="false">2410.19717v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Deep Recurrent Stochastic Configuration Networks for Modelling Nonlinear Dynamic Systems</title>
      <link>http://arxiv.org/abs/2410.20904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习技术在多个领域应用中展现出潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的深度水库计算框架，称为深度递归随机配置网络（DeepRSCN），用于建模非线性动态系统。&lt;h4&gt;方法&lt;/h4&gt;DeepRSCN逐步构建，所有水库节点直接连接到最终输出。随机参数根据监督机制分配，以确保模型的通用逼近特性。使用投影算法在线更新输出权重，以应对未知动态。&lt;h4&gt;主要发现&lt;/h4&gt;通过一组训练样本，DeepRSCN能够快速生成学习表示，这些表示由随机基函数和级联输入及读取权重组成。实验结果显示，DeepRSCN在时间序列预测、非线性系统识别和工业数据预测分析中，在建模效率、学习能力和泛化性能上优于单层网络。&lt;h4&gt;结论&lt;/h4&gt;DeepRSCN在多个应用场景中表现优越，有望提升非线性动态系统的建模效率和预测能力。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的DeepRSCN框架是对深度学习技术在动态系统建模中的一种有效补充。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning techniques have shown promise in many domain applications. Thispaper proposes a novel deep reservoir computing framework, termed deeprecurrent stochastic configuration network (DeepRSCN) for modelling nonlineardynamic systems. DeepRSCNs are incrementally constructed, with all reservoirnodes directly linked to the final output. The random parameters are assignedin the light of a supervisory mechanism, ensuring the universal approximationproperty of the built model. The output weights are updated online using theprojection algorithm to handle the unknown dynamics. Given a set of trainingsamples, DeepRSCNs can quickly generate learning representations, which consistof random basis functions with cascaded input and readout weights. Experimentalresults over a time series prediction, a nonlinear system identificationproblem, and two industrial data predictive analyses demonstrate that theproposed DeepRSCN outperforms the single-layer network in terms of modellingefficiency, learning capability, and generalization performance.</description>
      <author>example@mail.com (Gang Dang, Dianhui Wang)</author>
      <guid isPermaLink="false">2410.20904v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Urban Mobility: AI, ODE-Based Modeling, and Scenario Planning</title>
      <link>http://arxiv.org/abs/2410.19915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;城市化和技术进步正在重新塑造城市交通的未来，带来了挑战和机遇。&lt;h4&gt;目的&lt;/h4&gt;探讨人工智能驱动的技术如何改变交通系统。&lt;h4&gt;方法&lt;/h4&gt;结合前瞻性研究、情景规划和使用常微分方程（ODE）进行数学建模。&lt;h4&gt;主要发现&lt;/h4&gt;通过Python模拟的ODE模型量化了AI创新（如自动驾驶车辆和智能交通管理）在不同监管条件下对缓解交通拥堵的影响。&lt;h4&gt;结论&lt;/h4&gt;ODE模型揭示了AI采纳率与交通拥堵之间的动态关系，为未来情景提供了定量见解。&lt;h4&gt;应用&lt;/h4&gt;通过行业合作和案例研究，为企业和政策制定者提供在这一不断变化的环境中导航的战略指导。&lt;h4&gt;总结&lt;/h4&gt;本研究有助于理解如何通过AI采纳促进更加高效、可持续和宜居城市的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urbanization and technological advancements are reshaping the future of urbanmobility, presenting both challenges and opportunities. This paper combinesforesight and scenario planning with mathematical modeling using OrdinaryDifferential Equations (ODEs) to explore how Artificial Intelligence(AI)-driven technologies can transform transportation systems. By simulatingODE-based models in Python, we quantify the impact of AI innovations, such asautonomous vehicles and intelligent traffic management, on reducing trafficcongestion under different regulatory conditions.  Our ODE models capture the dynamic relationship between AI adoption rates andtraffic congestion, providing quantitative insights into how future scenariosmight unfold. By incorporating industry collaborations and case studies, weoffer strategic guidance for businesses and policymakers navigating thisevolving landscape. This study contributes to understanding how foresight,scenario planning, and ODE modeling can inform strategies for creating moreefficient, sustainable, and livable cities through AI adoption.</description>
      <author>example@mail.com (Katsiaryna Bahamazava)</author>
      <guid isPermaLink="false">2410.19915v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Less is More: Efficient Time Series Dataset Condensation via Two-fold Modal Matching--Extended Version</title>
      <link>http://arxiv.org/abs/2410.20905v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by PVLDB 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社会各个领域中传感器的扩展使得时间序列数据大量增加，这为交通基础设施和电网等重要应用提供了可能。&lt;h4&gt;目的&lt;/h4&gt;减少从时间序列数据中提取价值所需的计算和存储成本。&lt;h4&gt;方法&lt;/h4&gt;提出了一种时间序列数据集压缩框架TimeDC，采用双重模式匹配，包括频率匹配和训练轨迹匹配。&lt;h4&gt;主要发现&lt;/h4&gt;TimeDC通过特征提取和分解驱动的频率匹配，保留了压缩时间序列中的复杂时间依赖性。&lt;h4&gt;结论&lt;/h4&gt;TimeDC通过课程训练轨迹匹配确保了有效和通用的时间序列数据集压缩，并通过专家缓冲区避免内存溢出。&lt;h4&gt;总结&lt;/h4&gt;对真实数据的广泛实验展示了所提解决方案的有效性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The expanding instrumentation of processes throughout society with sensorsyields a proliferation of time series data that may in turn enable importantapplications, e.g., related to transportation infrastructures or power grids.Machine-learning based methods are increasingly being used to extract valuefrom such data. We provide means of reducing the resulting considerablecomputational and data storage costs. We achieve this by providing means ofcondensing large time series datasets such that models trained on the condenseddata achieve performance comparable to those trained on the original, largedata. Specifically, we propose a time series dataset condensation framework,TimeDC, that employs two-fold modal matching, encompassing frequency matchingand training trajectory matching. Thus, TimeDC performs time series featureextraction and decomposition-driven frequency matching to preserve complextemporal dependencies in the reduced time series. Further, TimeDC employscurriculum training trajectory matching to ensure effective and generalizedtime series dataset condensation. To avoid memory overflow and to reduce thecost of dataset condensation, the framework includes an expert buffer storingpre-computed expert trajectories. Extensive experiments on real data offerinsight into the effectiveness and efficiency of the proposed solutions.</description>
      <author>example@mail.com (Hao Miao, Ziqiao Liu, Yan Zhao, Chenjuan Guo, Bin Yang, Kai Zheng, Christian S. Jensen)</author>
      <guid isPermaLink="false">2410.20905v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SFTrack: A Robust Scale and Motion Adaptive Algorithm for Tracking Small and Fast Moving Objects</title>
      <link>http://arxiv.org/abs/2410.20079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IROS 2024 selected Oral&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文讨论了无人机视频中的多目标跟踪问题，该问题在交通监控和实时嫌疑人追踪等无人机应用中至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单但更有效的方法来克服无人机跟踪中的挑战。&lt;h4&gt;方法&lt;/h4&gt;引入新的跟踪策略，从低置信度检测开始跟踪目标，并改进传统基于外观的匹配算法以提高低置信度检测的关联性。&lt;h4&gt;主要发现&lt;/h4&gt;在两个无人机特定数据集（VisDrone2019、UAVDT）和一个通用目标跟踪数据集（MOT17）上进行基准评估，结果表明该方法优于现有的先进技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在多种跟踪环境中展现了较高的鲁棒性和适应性。&lt;h4&gt;数据集改进&lt;/h4&gt;改善了UAVDT数据集的标注，修正了原始标注中的错误和遗漏，并将提供改进后的数据集以促进更好的基准测试。&lt;h4&gt;总结&lt;/h4&gt;本文提出的多目标跟踪方法在无人机监控应用中表现优异，为相关领域的研究提供了新的数据支持和参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the problem of multi-object tracking in Unmanned AerialVehicle (UAV) footage. It plays a critical role in various UAV applications,including traffic monitoring systems and real-time suspect tracking by thepolice. However, this task is highly challenging due to the fast motion ofUAVs, as well as the small size of target objects in the videos caused by thehigh-altitude and wide angle views of drones. In this study, we thus introducea simple yet more effective method compared to previous work to overcome thesechallenges. Our approach involves a new tracking strategy, which initiates thetracking of target objects from low-confidence detections commonly encounteredin UAV application scenarios. Additionally, we propose revisiting traditionalappearance-based matching algorithms to improve the association oflow-confidence detections. To evaluate the effectiveness of our method, weconducted benchmark evaluations on two UAV-specific datasets (VisDrone2019,UAVDT) and one general object tracking dataset (MOT17). The results demonstratethat our approach surpasses current state-of-the art methodologies,highlighting its robustness and adaptability in diverse tracking environments.Furthermore, we have improved the annotation of the UAVDT dataset by rectifyingseveral errors and addressing omissions found in the original annotations. Wewill provide this refined version of the dataset to facilitate betterbenchmarking in the field.</description>
      <author>example@mail.com (InPyo Song, Jangwon Lee)</author>
      <guid isPermaLink="false">2410.20079v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FACTS: A Factored State-Space Framework For World Modelling</title>
      <link>http://arxiv.org/abs/2410.20922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code released in https://github.com/NanboLi/FACTS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;世界建模对于理解和预测复杂系统的动态至关重要，需要学习空间和时间的依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的递归框架FACTS模型，以解决现有框架在高维序列建模中的局限性。&lt;h4&gt;方法&lt;/h4&gt;FACTS模型构建了一个图结构的记忆，通过路由机制学习可排列的记忆表示，并通过选择性状态空间传播进行适应。&lt;h4&gt;主要发现&lt;/h4&gt;FACTS在多元时间序列预测和以对象为中心的世界建模等多种任务中表现优异，始终超越或匹配专用的最先进模型。&lt;h4&gt;结论&lt;/h4&gt;尽管FACTS是一个通用的世界建模设计，但其性能在多样化任务中表现出色。&lt;h4&gt;总结&lt;/h4&gt;FACTS模型有效解决了长时间高维序列建模的挑战，展示了其在复杂系统建模中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nanboli/facts&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; World modelling is essential for understanding and predicting the dynamics ofcomplex systems by learning both spatial and temporal dependencies. However,current frameworks, such as Transformers and selective state-space models likeMambas, exhibit limitations in efficiently encoding spatial and temporalstructures, particularly in scenarios requiring long-term high-dimensionalsequence modelling. To address these issues, we propose a novel recurrentframework, the \textbf{FACT}ored \textbf{S}tate-space (\textbf{FACTS}) model,for spatial-temporal world modelling. The FACTS framework constructs agraph-structured memory with a routing mechanism that learns permutable memoryrepresentations, ensuring invariance to input permutations while adaptingthrough selective state-space propagation. Furthermore, FACTS supports parallelcomputation of high-dimensional sequences. We empirically evaluate FACTS acrossdiverse tasks, including multivariate time series forecasting andobject-centric world modelling, demonstrating that it consistently outperformsor matches specialised state-of-the-art models, despite its general-purposeworld modelling design.</description>
      <author>example@mail.com (Li Nanbo, Firas Laakom, Yucheng Xu, Wenyi Wang, Jürgen Schmidhuber)</author>
      <guid isPermaLink="false">2410.20922v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SmartX Intelligent Sec: A Security Framework Based on Machine Learning and eBPF/XDP</title>
      <link>http://arxiv.org/abs/2410.20244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;信息与通信技术基础设施日益复杂，面临众多挑战，尤其是在支持最新网络范式方面。&lt;h4&gt;目的&lt;/h4&gt;提出一种创新的智能安全框架SmartX Intelligent Sec，以应对当前网络安全挑战。&lt;h4&gt;方法&lt;/h4&gt;SmartX Intelligent Sec结合轻量级扩展伯克利数据包过滤器/eXpress DataPath (eBPF/XDP)进行高效的网络数据包捕获和恶意网络流量过滤，并使用双向长短期记忆（BiLSTM）分类器进行网络威胁检测。&lt;h4&gt;主要发现&lt;/h4&gt;实时原型展示了SmartX Intelligent Sec的全面自动化特性，能够持续捕获网络数据包，有效检测网络威胁，并高效过滤恶意网络流量。&lt;h4&gt;结论&lt;/h4&gt;该框架确保了现代信息与通信技术基础设施的安全性和操作效率。&lt;h4&gt;总结&lt;/h4&gt;SmartX Intelligent Sec是一个创新的智能安全解决方案，能够提升网络安全和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Information and Communication Technologies (ICT) infrastructures are becomingincreasingly complex day by day, facing numerous challenges to support thelatest networking paradigms. Security is undeniably a critical component forthe effective functioning of these advanced ICT infrastructures. By consideringthe current network security challenges, we propose SmartX Intelligent Sec, aninnovative intelligent security framework. SmartX Intelligent Sec leverages acombination of the lightweight extended Berkeley Packet Filter/eXpress DataPath (eBPF/XDP) for efficient network packet capturing and filtering maliciousnetwork traffic, and a Bidirectional Long Short-Term Memory (BiLSTM) classifierfor network threat detection. Our real-time prototype demonstrates that SmartXIntelligent Sec offers comprehensive automation features, enabling continuousnetwork packet capturing, effective network threat detection, and efficientfiltering of malicious network traffic. This framework ensures enhancedsecurity and operational efficiency for modern ICT infrastructures.</description>
      <author>example@mail.com (Talaya Farasat, JongWon Kim, Joachim Posegga)</author>
      <guid isPermaLink="false">2410.20244v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SoftCTRL: Soft conservative KL-control of Transformer Reinforcement Learning for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.22752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to IEEE Open Journal of Intelligent Transportation Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，城市自驾车的运动规划成为一个热门问题，涉及道路组件的复杂交互。&lt;h4&gt;目的&lt;/h4&gt;解决运动规划中的安全性和可靠性问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种结合模仿学习（IL）和强化学习（RL）的方法，通过隐式熵-KL控制来减少IL的过度保守特性。&lt;h4&gt;主要发现&lt;/h4&gt;在未见数据集的不同挑战性城市模拟场景中，虽然IL在模仿任务中表现良好，但提出的方法显著提高了鲁棒性（失败率减少超过17%）并生成了类人驾驶行为。&lt;h4&gt;结论&lt;/h4&gt;结合IL与RL的方法有效改善了自驾车的运动规划能力，提升了安全性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种有效的运动规划解决方案，克服了纯IL方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, motion planning for urban self-driving cars (SDV) has becomea popular problem due to its complex interaction of road components. To tacklethis, many methods have relied on large-scale, human-sampled data processedthrough Imitation learning (IL). Although effective, IL alone cannot adequatelyhandle safety and reliability concerns. Combining IL with Reinforcementlearning (RL) by adding KL divergence between RL and IL policy to the RL losscan alleviate IL's weakness but suffer from over-conservation caused bycovariate shift of IL. To address this limitation, we introduce a method thatcombines IL with RL using an implicit entropy-KL control that offers a simpleway to reduce the over-conservation characteristic. In particular, we validatedifferent challenging simulated urban scenarios from the unseen dataset,indicating that although IL can perform well in imitation tasks, our proposedmethod significantly improves robustness (over 17\% reduction in failures) andgenerates human-like driving behavior.</description>
      <author>example@mail.com (Minh Tri Huynh, Duc Dung Nguyen)</author>
      <guid isPermaLink="false">2410.22752v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Federated Time Series Generation on Feature and Temporally Misaligned Data</title>
      <link>http://arxiv.org/abs/2410.21072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;分布式时间序列数据在联邦学习中面临挑战，因客户端特征集不同且时间步对齐不一致。&lt;h4&gt;目的&lt;/h4&gt;提出FedTDD，一种新颖的联邦时间序列扩散模型，旨在跨客户端联合学习合成器。&lt;h4&gt;方法&lt;/h4&gt;FedTDD采用新型数据蒸馏与聚合框架，通过填补不对齐的时间步和特征来调和客户端之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;FedTDD通过交换本地合成输出而非模型参数来学习客户端时间序列之间的相关性，实验结果显示其在五个数据集上的有效性。&lt;h4&gt;结论&lt;/h4&gt;FedTDD在Context-FID和相关性分数上相较于本地训练分别提高了79.4%和62.8%的性能。&lt;h4&gt;总结&lt;/h4&gt;FedTDD有效地通过共享合成输出实现了本地时间序列知识的转移，提升了客户端的本地数据填补质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed time series data presents a challenge for federated learning, asclients often possess different feature sets and have misaligned time steps.Existing federated time series models are limited by the assumption of perfecttemporal or feature alignment across clients. In this paper, we propose FedTDD,a novel federated time series diffusion model that jointly learns a synthesizeracross clients. At the core of FedTDD is a novel data distillation andaggregation framework that reconciles the differences between clients byimputing the misaligned timesteps and features. In contrast to traditionalfederated learning, FedTDD learns the correlation across clients' time seriesthrough the exchange of local synthetic outputs instead of model parameters. Acoordinator iteratively improves a global distiller network by leveragingshared knowledge from clients through the exchange of synthetic data. As thedistiller becomes more refined over time, it subsequently enhances the qualityof the clients' local feature estimates, allowing each client to then improveits local imputations for missing data using the latest, more accuratedistiller. Experimental results on five datasets demonstrate FedTDD'seffectiveness compared to centralized training, and the effectiveness ofsharing synthetic outputs to transfer knowledge of local time series. Notably,FedTDD achieves 79.4% and 62.8% improvement over local training in Context-FIDand Correlational scores.</description>
      <author>example@mail.com (Chenrui Fan, Zhi Wen Soi, Aditya Shankar, Abele Mălan, Lydia Y. Chen)</author>
      <guid isPermaLink="false">2410.21072v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Who is Responsible? Explaining Safety Violations in Multi-Agent Cyber-Physical Systems</title>
      <link>http://arxiv.org/abs/2410.20288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多智能体网络物理系统在多种应用中存在，智能体决策可能因不确定的动态操作环境或错误行为受到影响。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化程序，以原则性方式将安全违规的责任分配给单个智能体的行为。&lt;h4&gt;方法&lt;/h4&gt;基于道路安全中的安全违规推理，使用反事实推理创建替代场景，介绍每个智能体的责任度（DoR）指标，并利用Shapley值量化各智能体对安全违规的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;责任度（DoR）提高了决策的可解释性和智能体行为及其后果的问责性。&lt;h4&gt;结论&lt;/h4&gt;自动化责任分配策略显著减少了人力劳动和认知负担，并在智能体数量增加时通过启发式技术和方法提高了可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自动化方法来评估智能体在安全违规中的责任，能够有效提升决策的透明度和责任感。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent cyber-physical systems are present in a variety of applications.Agent decision-making can be affected due to errors induced by uncertain,dynamic operating environments or due to incorrect actions taken by an agent.When an erroneous decision that leads to a violation of safety is identified,assigning responsibility to individual agents is a key step toward preventingfuture accidents. Current approaches to carrying out such investigationsrequire human labor or high degree of familiarity with operating environments.Automated strategies to assign responsibility can achieve a significantreduction in human effort and associated cognitive burden. In this paper, wedevelop an automated procedure to assign responsibility for safety violationsto actions of any single agent in a principled manner. We base our approach onreasoning about safety violations in road safety. Given a safety violation, weuse counterfactual reasoning to create alternative scenarios, showing howdifferent outcomes could have occurred if certain actions had been replaced byothers. We introduce the degree of responsibility (DoR) metric for each agent.The DoR, using the Shapley value, quantifies each agent's contribution to thesafety violation, providing a basis to explain and justify decisions. We alsodevelop heuristic techniques and methods based on agent interaction structuresto improve scalability as agent numbers grow. We examine three safety violationcases from the National Highway Traffic Safety Administration (NHTSA). We runexperiments using CARLA urban driving simulator. Results show the DoR improvesthe explainability of decisions and accountability for agent actions and theirconsequences.</description>
      <author>example@mail.com (Luyao Niu, Hongchao Zhang, Dinuka Sahabandu, Bhaskar Ramasubramanian, Andrew Clark, Radha Poovendran)</author>
      <guid isPermaLink="false">2410.20288v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Tool Manipulation of An Aerial Vehicle with A Dynamically Displacing Center-of-Mass</title>
      <link>http://arxiv.org/abs/2410.22816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2404.01110&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着航空机器人在工业应用中的普及，增强其物理交互能力的需求日益增加。&lt;h4&gt;目的&lt;/h4&gt;提高航空机器人在推动任务中的力生成能力，以支持更复杂的工业应用。&lt;h4&gt;方法&lt;/h4&gt;基于之前的工作，提出了一种优化重心位置的创新方法，以增强交互过程中的力生成。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟验证了所提方法的有效性，显示该系统在实际环境中进行高级航空操作的潜力。&lt;h4&gt;结论&lt;/h4&gt;该系统的设计能够支持更高自由度的操作，并有效执行工具基础的任务。&lt;h4&gt;总结&lt;/h4&gt;优化重心位置的策略为航空操控提供了新的可能性，适用于工业领域的多种复杂任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As aerial robots gain traction in industrial applications, there is growinginterest in enhancing their physical interaction capabilities. Pushing tasksperformed by aerial manipulators have been successfully demonstrated incontact-based inspections. However, more complex industrial applicationsrequire these systems to support higher-DoF (Degree of Freedom) manipulatorsand generate larger forces while pushing (e.g., drilling, grinding). This paperbuilds on our previous work, where we introduced an aerial vehicle with adynamically displacing CoM (Center of Mass) to improve force exertion duringinteractions. We propose a novel approach to further enhance this system'sforce generation by optimizing its CoM location during interactions.Additionally, we study the case of this aerial vehicle equipped with a 2-DoFmanipulation arm to extend the system's functionality in tool-based tasks. Theeffectiveness of the proposed methods is validated through simulations,demonstrating the potential of this system for advanced aerial manipulation inpractical settings.</description>
      <author>example@mail.com (Tong Hui, Matteo Fumagalli)</author>
      <guid isPermaLink="false">2410.22816v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Trajectory Flow Matching with Applications to Clinical Time Series Modeling</title>
      <link>http://arxiv.org/abs/2410.21154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Spotlight&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;建模随机和不规则采样的时间序列是一项具有挑战性的任务，广泛应用于医学等领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来训练神经随机微分方程（Neural SDEs），以解决当前算法的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出轨迹流匹配（Trajectory Flow Matching，TFM）方法，以无模拟的方式训练Neural SDE，避免通过动态回传。&lt;h4&gt;主要发现&lt;/h4&gt;TFM能够有效学习时间序列数据，并通过重参数化技巧提高训练稳定性，在临床时间序列设置中表现出色。&lt;h4&gt;结论&lt;/h4&gt;TFM在三个临床时间序列数据集上显示了改进的性能和不确定性预测能力。&lt;h4&gt;总结&lt;/h4&gt;TFM为处理随机和不规则采样的时间序列提供了一种新的有效方法，具有重要的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nzhangx/trajectoryflowmatching&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling stochastic and irregularly sampled time series is a challengingproblem found in a wide range of applications, especially in medicine. Neuralstochastic differential equations (Neural SDEs) are an attractive modelingtechnique for this problem, which parameterize the drift and diffusion terms ofan SDE with neural networks. However, current algorithms for training NeuralSDEs require backpropagation through the SDE dynamics, greatly limiting theirscalability and stability. To address this, we propose Trajectory Flow Matching(TFM), which trains a Neural SDE in a simulation-free manner, bypassingbackpropagation through the dynamics. TFM leverages the flow matching techniquefrom generative modeling to model time series. In this work we first establishnecessary conditions for TFM to learn time series data. Next, we present areparameterization trick which improves training stability. Finally, we adaptTFM to the clinical time series setting, demonstrating improved performance onthree clinical time series datasets both in terms of absolute performance anduncertainty prediction.</description>
      <author>example@mail.com (Xi Zhang, Yuan Pu, Yuki Kawamura, Andrew Loza, Yoshua Bengio, Dennis L. Shung, Alexander Tong)</author>
      <guid isPermaLink="false">2410.21154v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Sebica: Lightweight Spatial and Efficient Bidirectional Channel Attention Super Resolution Network</title>
      <link>http://arxiv.org/abs/2410.20546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures, 26 conferences&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;单幅图像超分辨率(SISR)是提高低分辨率图像视觉质量的重要技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种轻量级网络Sebica，以解决资源有限或时间敏感环境下的计算挑战。&lt;h4&gt;方法&lt;/h4&gt;Sebica结合空间和高效的双向通道注意机制，旨在降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;Sebica在Div2K和Flickr2K数据集上的PSNR/SSIM分别为28.29/0.7976和30.18/0.8330，超越大多数基线轻量级模型，且与最高性能模型相当，但参数和GFLOPs分别仅为17%和15%。&lt;h4&gt;结论&lt;/h4&gt;Sebica的小版本仅有7.9K参数和0.41 GFLOPS，分别为最高性能模型参数和GFLOPs的3%，在Flickr2K数据集上仍能达到28.12/0.7931和0.3009/0.8317的PSNR和SSIM指标。&lt;h4&gt;应用&lt;/h4&gt;Sebica在实际应用中显示了显著改进，特别是在交通视频场景的目标检测任务中，提高了检测准确性。&lt;h4&gt;总结&lt;/h4&gt;Sebica是一种高效的超分辨率网络，适合于计算资源有限的环境，同时在多个指标上表现优异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/idiosyncracies/Sebica&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single Image Super-Resolution (SISR) is a vital technique for improving thevisual quality of low-resolution images. While recent deep learning models havemade significant advancements in SISR, they often encounter computationalchallenges that hinder their deployment in resource-limited or time-sensitiveenvironments. To overcome these issues, we present Sebica, a lightweightnetwork that incorporates spatial and efficient bidirectional channel attentionmechanisms. Sebica significantly reduces computational costs while maintaininghigh reconstruction quality, achieving PSNR/SSIM scores of 28.29/0.7976 and30.18/0.8330 on the Div2K and Flickr2K datasets, respectively. These resultssurpass most baseline lightweight models and are comparable to thehighest-performing model, but with only 17% and 15% of the parameters andGFLOPs. Additionally, our small version of Sebica has only 7.9K parameters and0.41 GFLOPS, representing just 3% of the parameters and GFLOPs of thehighest-performing model, while still achieving PSNR and SSIM metrics of28.12/0.7931 and 0.3009/0.8317, on the Flickr2K dataset respectively. Inaddition, Sebica demonstrates significant improvements in real-worldapplications, specifically in object detection tasks, where it enhancesdetection accuracy in traffic video scenarios.</description>
      <author>example@mail.com (Chongxiao Liu)</author>
      <guid isPermaLink="false">2410.20546v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Grasping Force Estimation for Markerless Visuotactile Sensors</title>
      <link>http://arxiv.org/abs/2410.22825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;触觉传感器在力估计方面的应用日益增多，尤其是基于视觉的触觉传感器（VBTS），因其高空间分辨率和低成本而成为新趋势。&lt;h4&gt;目的&lt;/h4&gt;设计和实施多种方法，通过不同的无标记视觉触觉表现来估计正常抓取力。&lt;h4&gt;方法&lt;/h4&gt;通过对比分析在机器人抓取任务中的性能，确定最合适的视觉触觉表现。使用了DIGIT传感器和GelSight Mini传感器生成的数据集进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;RGB视觉触觉表现比深度图像或两者组合更适合估计正常抓取力。RGBmod在10个未见过的日常物体上测试表现良好，平均相对误差为0.125 ± 0.153。&lt;h4&gt;结论&lt;/h4&gt;我们的方案在使用RGB和深度信息进行相同任务的文献中表现优越。&lt;h4&gt;总结&lt;/h4&gt;本研究显示RGB视觉触觉表现的优势，以及RGBmod在实际场景中的良好泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/JSEN.2024.3489052&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tactile sensors have been used for force estimation in the past, especiallyVision-Based Tactile Sensors (VBTS) have recently become a new trend due totheir high spatial resolution and low cost. In this work, we have designed andimplemented several approaches to estimate the normal grasping force usingdifferent types of markerless visuotactile representations obtained from VBTS.Our main goal is to determine the most appropriate visuotactile representation,based on a performance analysis during robotic grasping tasks. Our proposal hasbeen tested on the dataset generated with our DIGIT sensors and another oneobtained using GelSight Mini sensors from another state-of-the-art work. Wehave also tested the generalization capabilities of our best approach, calledRGBmod. The results led to two main conclusions. First, the RGB visuotactilerepresentation is a better input option than the depth image or a combinationof the two for estimating normal grasping forces. Second, RGBmod achieved agood performance when tested on 10 unseen everyday objects in real-worldscenarios, achieving an average relative error of 0.125 +- 0.153. Furthermore,we show that our proposal outperforms other works in the literature that useRGB and depth information for the same task.</description>
      <author>example@mail.com (Julio Castaño-Amoros, Pablo Gil)</author>
      <guid isPermaLink="false">2410.22825v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SeriesGAN: Time Series Generation via Adversarial and Autoregressive Learning</title>
      <link>http://arxiv.org/abs/2410.21203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted at BigData 2024 on October 26, 2024, as a
  regular paper for oral presentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前基于生成对抗网络（GAN）的时间序列生成方法面临收敛不佳、嵌入空间信息损失和不稳定性等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种先进框架，以克服上述挑战，结合自编码器生成的嵌入空间优势和GAN的对抗训练动态。&lt;h4&gt;方法&lt;/h4&gt;该方法采用两个判别器，一个专门指导生成器，另一个用于优化自编码器和生成器的输出。同时，引入了一种新型自编码器基础损失函数和教师强制监督网络，捕捉数据的逐步条件分布。&lt;h4&gt;主要发现&lt;/h4&gt;生成器在潜在空间中操作，而两个判别器分别在潜在和特征空间中工作，提供关键反馈，最小化嵌入空间的信息损失。&lt;h4&gt;结论&lt;/h4&gt;通过联合训练，该框架在生成高保真时间序列数据方面表现出色，在多种真实和合成的多变量时间序列数据集上，定性和定量地超越现有的最先进基准。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的框架有效解决了GAN在时间序列生成中的主要问题，显著提升了生成数据的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/samresume/seriesgan&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current Generative Adversarial Network (GAN)-based approaches for time seriesgeneration face challenges such as suboptimal convergence, information loss inembedding spaces, and instability. To overcome these challenges, we introducean advanced framework that integrates the advantages of anautoencoder-generated embedding space with the adversarial training dynamics ofGANs. This method employs two discriminators: one to specifically guide thegenerator and another to refine both the autoencoder's and generator's output.Additionally, our framework incorporates a novel autoencoder-based lossfunction and supervision from a teacher-forcing supervisor network, whichcaptures the stepwise conditional distributions of the data. The generatoroperates within the latent space, while the two discriminators work on latentand feature spaces separately, providing crucial feedback to both the generatorand the autoencoder. By leveraging this dual-discriminator approach, weminimize information loss in the embedding space. Through joint training, ourframework excels at generating high-fidelity time series data, consistentlyoutperforming existing state-of-the-art benchmarks both qualitatively andquantitatively across a range of real and synthetic multivariate time seriesdatasets.</description>
      <author>example@mail.com (MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi)</author>
      <guid isPermaLink="false">2410.21203v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Non-contact Dexterous Micromanipulation with Multiple Optoelectronic Robots</title>
      <link>http://arxiv.org/abs/2410.22848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;微操控系统利用自动化和机器人技术提高微观任务的精度、重复性和效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的非接触微操控方法，以克服当前方法在特定对象或任务上的局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法基于光电技术，利用光电场中产生的排斥性介电泳力驱动微型机器人，实现目标物体的非接触操控。&lt;h4&gt;主要发现&lt;/h4&gt;非接触特性降低了潜在损害、污染或粘附的风险，同时显著提高了操控的灵活性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法为多种微观对象和任务提供了一种通用且灵活的解决方案，减少了对专用工具的需求。&lt;h4&gt;实验&lt;/h4&gt;进行了非接触轨迹跟踪、避障以及多微型机器人间相互避让的模拟和实验证明该方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种创新的微操控技术，具有广泛应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Micromanipulation systems leverage automation and robotic technologies toimprove the precision, repeatability, and efficiency of various tasks at themicroscale. However, current approaches are typically limited to specificobjects or tasks, which necessitates the use of custom tools and specializedgrasping methods. This paper proposes a novel non-contact micromanipulationmethod based on optoelectronic technologies. The proposed method utilizesrepulsive dielectrophoretic forces generated in the optoelectronic field todrive a microrobot, enabling the microrobot to push the target object in acluttered environment without physical contact. The non-contact feature canminimize the risks of potential damage, contamination, or adhesion whilelargely improving the flexibility of manipulation. The feature enables the useof a general tool for indirect object manipulation, eliminating the need forspecialized tools. A series of simulation studies and real-world experiments --including non-contact trajectory tracking, obstacle avoidance, and reciprocalavoidance between multiple microrobots -- are conducted to validate theperformance of the proposed method. The proposed formulation provides a generaland dexterous solution for a range of objects and tasks at the micro scale.</description>
      <author>example@mail.com (Yongyi Jia, Shu Miao, Ao Wang, Caiding Ni, Lin Feng, Xiaowo Wang, Xiang Li)</author>
      <guid isPermaLink="false">2410.22848v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Neural Operators for Adaptive Control of Freeway Traffic</title>
      <link>http://arxiv.org/abs/2410.20708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类驾驶行为中的不确定性和反应延迟导致高速公路上的停走交通拥堵。&lt;h4&gt;目的&lt;/h4&gt;提出基于神经算子的自适应边界控制设计，以解决具有不确定空间变化系数和边界参数的耦合2x2双曲系统的自适应交通控制问题。&lt;h4&gt;方法&lt;/h4&gt;采用DeepONet进行算子学习，学习系统参数与核函数之间的映射，从而克服传统PDE自适应控制中在线求解反步核的高计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;DeepONet在生成核函数方面比传统PDE求解器快近两个数量级，同时保持损失在$10^{-3}$的数量级。&lt;h4&gt;结论&lt;/h4&gt;DeepONet在近似PDE反步设计中表现出强大的潜力，能够有效提高计算效率。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了使用DeepONet进行高速公路交通控制的有效性，为解决交通拥堵问题提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Uncertainty and delayed reactions in human driving behavior lead tostop-and-go traffic congestion on freeways. The freeway traffic dynamics aregoverned by the Aw-Rascle-Zhang (ARZ) traffic Partial Differential Equation(PDE) models with unknown relaxation time. Motivated by the adaptive trafficcontrol problem, this paper presents a neural operator (NO) based adaptiveboundary control design for the coupled 2$\times$2 hyperbolic systems withuncertain spatially varying in-domain coefficients and boundary parameter. Intraditional adaptive control for PDEs, solving backstepping kernel online iscomputationally intensive, as it requires significant resources at each timestep to update the estimation of coefficients. To address this challenge, weuse operator learning, i.e. DeepONet, to learn the mapping from systemparameters to the kernels functions. DeepONet, a class of deep neural networksdesigned for approximating operators, has shown strong potential forapproximating PDE backstepping designs in recent studies. Unlike previous worksthat focus on approximating single kernel equation associated with the scalarPDE system, we extend this framework to approximate PDE kernels for a class ofthe first-order coupled 2$\times$2 hyperbolic kernel equations. Our approachdemonstrates that DeepONet is nearly two orders of magnitude faster thantraditional PDE solvers for generating kernel functions, while maintaining aloss on the order of $10^{-3}$.</description>
      <author>example@mail.com (Kaijing Lv, Junmin Wang, Yihuai Zhang, Huan Yu)</author>
      <guid isPermaLink="false">2410.20708v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Reconstructing dynamics from sparse observations with no training on target system</title>
      <link>http://arxiv.org/abs/2410.21222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 21 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;系统可能面临前所未有的情况，仅能进行稀疏观察。&lt;h4&gt;目的&lt;/h4&gt;探讨如何在没有训练数据的情况下，从有限的观察中重建系统的动态。&lt;h4&gt;方法&lt;/h4&gt;开发了一种混合变换器和水库计算的机器学习方案，利用已知混沌系统的合成数据训练变换器。&lt;h4&gt;主要发现&lt;/h4&gt;即使可用数据仅为所需的20%，也能高精度重建复杂和非线性动态。&lt;h4&gt;结论&lt;/h4&gt;提出的混合机器学习框架为在缺乏训练数据和稀疏观察的极端情况下重建复杂动态提供了新思路。&lt;h4&gt;总结&lt;/h4&gt;该方法有效应对传统非线性时间序列分析及机器学习方法无法解决的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In applications, an anticipated situation is where the system of interest hasnever been encountered before and sparse observations can be made only once.Can the dynamics be faithfully reconstructed from the limited observationswithout any training data? This problem defies any known traditional methods ofnonlinear time-series analysis as well as existing machine-learning methodsthat typically require extensive data from the target system for training. Weaddress this challenge by developing a hybrid transformer andreservoir-computing machine-learning scheme. The key idea is that, for acomplex and nonlinear target system, the training of the transformer can beconducted not using any data from the target system, but with essentiallyunlimited synthetic data from known chaotic systems. The trained transformer isthen tested with the sparse data from the target system. The output of thetransformer is further fed into a reservoir computer for predicting thelong-term dynamics or the attractor of the target system. The power of theproposed hybrid machine-learning framework is demonstrated using a large numberof prototypical nonlinear dynamical systems, with high reconstruction accuracyeven when the available data is only 20% of that required to faithfullyrepresent the dynamical behavior of the underlying system. The frameworkprovides a paradigm of reconstructing complex and nonlinear dynamics in theextreme situation where training data does not exist and the observations arerandom and sparse.</description>
      <author>example@mail.com (Zheng-Meng Zhai, Jun-Yin Huang, Benjamin D. Stern, Ying-Cheng Lai)</author>
      <guid isPermaLink="false">2410.21222v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Human-inspired Grasping Strategies of Fresh Fruits and Vegetables Applied to Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2410.22893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  *Authors contributed equally&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新鲜水果和蔬菜的机器人操作，尤其是抓取多个松散物品，具有较强的工业需求，但仍然是一个具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;本文旨在概述人类在挑选松散水果和蔬菜时使用的独特操作策略，以更好地将其应用于机器人对多种物品的操作。&lt;h4&gt;方法&lt;/h4&gt;提出了一种首个版本的机器人系统，旨在抓取不同的单个或多个新鲜物品，配备多指顺应性机器人抓手。&lt;h4&gt;主要发现&lt;/h4&gt;从工业关键绩效指标（KPIs）的角度分析了人类抓取策略，并使用相同的KPIs对机器人系统进行了验证，考虑了人类的表现和策略。&lt;h4&gt;结论&lt;/h4&gt;本文为未来新鲜水果和蔬菜智能操作的机器人演示器的发展奠定了基础，并指出了处理任务复杂性所需的通用方法。&lt;h4&gt;总结&lt;/h4&gt;人类的抓取策略和机器人系统的设计相结合，为提高机器人操作效率提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic manipulation of fresh fruits and vegetables, including the graspingof multiple loose items, has a strong industrial need but it still is achallenging task for robotic manipulation. This paper outlines the distinctivemanipulation strategies used by humans to pick loose fruits and vegetables withthe aim to better adopt them for robotic manipulation of diverse items. In thiswork we present a first version of a robotic setup designed to pick differentsingle or multiple fresh items, featuring multi-fingered compliant roboticgripper. We analyse human grasping strategies from the perspective ofindustrial Key Performance Indicators (KPIs) used in the logistic sector. Therobotic system was validated using the same KPIs, as well as taking intoaccount human performance and strategies. This paper lays the foundation forfuture development of the robotic demonstrator for fresh fruit and vegetableintelligent manipulation, and outlines the need for generic approaches tohandle the complexity of the task.</description>
      <author>example@mail.com (Romeo Orsolino, Mykhaylo Marfeychuk, Mariana de Paula Assis Fonseca, Mario Baggetta, Wesley Wimshurst, Francesco Porta, Morgan Clarke, Giovanni Berselli, Jelizaveta Konstantinova)</author>
      <guid isPermaLink="false">2410.22893v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Interaction Modeling With Reduced Accumulated Error for Multi-Agent Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2410.21342v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, accepted by IEEE TNNLS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;动态复杂系统由交互的异质代理组成，广泛存在于城市交通系统和社交网络中。&lt;h4&gt;目的&lt;/h4&gt;理解和预测复杂系统的动态，特别是城市中交通参与者的轨迹预测。&lt;h4&gt;方法&lt;/h4&gt;提出了异质交互建模，旨在减少多代理轨迹预测中的累积误差。基于历史轨迹，推断代理之间的动态交互图，并定义异质注意机制来聚合来自异质邻居的影响。&lt;h4&gt;主要发现&lt;/h4&gt;通过分析空间和时间角度的误差来源，引入图熵和混合训练策略分别减少两种误差。&lt;h4&gt;结论&lt;/h4&gt;在三个包含异质代理的真实数据集上进行实验，结果验证了该方法的优越性。&lt;h4&gt;总结&lt;/h4&gt;该研究为复杂系统中的异质交互建模提供了新的方法，改善了轨迹预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TNNLS.2022.3224007&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamical complex systems composed of interactive heterogeneous agents areprevalent in the world, including urban traffic systems and social networks.Modeling the interactions among agents is the key to understanding andpredicting the dynamics of the complex system, e.g., predicting thetrajectories of traffic participants in the city. Compared with interactionmodeling in homogeneous systems such as pedestrians in a crowded scene,heterogeneous interaction modeling is less explored. Worse still, the erroraccumulation problem becomes more severe since the interactions are morecomplex. To tackle the two problems, this paper proposes heterogeneousinteraction modeling with reduced accumulated error for multi-agent trajectoryprediction. Based on the historical trajectories, our method infers the dynamicinteraction graphs among agents, featured by directed interacting relations andinteracting effects. A heterogeneous attention mechanism is defined on theinteraction graphs for aggregating the influence from heterogeneous neighborsto the target agent. To alleviate the error accumulation problem, this paperanalyzes the error sources from the spatial and temporal perspectives, andproposes to introduce the graph entropy and the mixup training strategy forreducing the two types of errors respectively. Our method is examined on threereal-world datasets containing heterogeneous agents, and the experimentalresults validate the superiority of our method.</description>
      <author>example@mail.com (Siyuan Chen, Jiahai Wang)</author>
      <guid isPermaLink="false">2410.21342v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>An Efficient Representation of Whole-body Model Predictive Control for Online Compliant Dual-arm Mobile Manipulation</title>
      <link>http://arxiv.org/abs/2410.22910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review for IEEE Transactions on Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;双臂移动操控器能够使用简单的末端执行器运输和操控大型物体，需在动态环境中满足严格的安全性和合规性要求。&lt;h4&gt;目的&lt;/h4&gt;解决在高度冗余的移动操控器中，在线实现满足各种硬约束的全身运动规划的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种高效的全身运动轨迹表示方式，结合双层模型预测控制（MPC）框架，利用Bézier曲线参数化表示优化的无碰撞轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在首次MPC中快速实现面向对象的长时间运动规划，并在第二次MPC中生成全身运动，满足硬约束。&lt;h4&gt;结论&lt;/h4&gt;该表示方法使两个MPC具备连续性，避免了现有MPC中不准确的模型状态转变和密集的决策变量设置，提高了高维空间中双层MPC框架的在线执行能力。&lt;h4&gt;应用&lt;/h4&gt;通过在多种场景下的模拟比较和实际实验，验证了该方法在静态和动态障碍物避免及与操控物体和外部干扰的合规交互控制中的效率和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;该研究为双臂移动操控器在复杂环境中的安全高效操作提供了新方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dual-arm mobile manipulators can transport and manipulate large-size objectswith simple end-effectors. To interact with dynamic environments with strictsafety and compliance requirements, achieving whole-body motion planning onlinewhile meeting various hard constraints for such highly redundant mobilemanipulators poses a significant challenge. We tackle this challenge bypresenting an efficient representation of whole-body motion trajectories withinour bilevel model-based predictive control (MPC) framework. We utilizeB\'ezier-curve parameterization to represent the optimized collision-freetrajectories of two collaborating end-effectors in the first MPC, facilitatingfast long-horizon object-oriented motion planning in SE(3) while consideringapproximated feasibility constraints. This approach is further applied toparameterize whole-body trajectories in the second MPC for whole-body motiongeneration with predictive admittance control in a relatively short horizonwhile satisfying whole-body hard constraints. This representation enables twoMPCs with continuous properties, thereby avoiding inaccurate model-statetransition and dense decision-variable settings in existing MPCs using thediscretization method. It strengthens the online execution of the bilevel MPCframework in high-dimensional space and facilitates the generation ofconsistent commands for our hybrid position/velocity-controlled robot. Thesimulation comparisons and real-world experiments demonstrate the efficiencyand robustness of this approach in various scenarios for static and dynamicobstacle avoidance, and compliant interaction control with the manipulatedobject and external disturbances.</description>
      <author>example@mail.com (Wenqian Du, Ran Long, João Moura, Jiayi Wang, Saeid Samadi, Sethu Vijayakumar)</author>
      <guid isPermaLink="false">2410.22910v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Strada-LLM: Graph LLM for traffic prediction</title>
      <link>http://arxiv.org/abs/2410.20856v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交通预测是智能交通系统的重要组成部分，需要在时空维度上推理交通模式以提供准确的预测。&lt;h4&gt;目的&lt;/h4&gt;解决不同交通条件下数据分布多样性带来的挑战，提升交通预测的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;提出一种图感知的LLM（大语言模型）进行交通预测，考虑邻近节点的交通信息作为协变量，并采用轻量级方法进行高效的领域适应。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在处理新数据分布时表现优越，超越了传统的时间序列LLM和GNN（图神经网络）监督方法。&lt;h4&gt;结论&lt;/h4&gt;Strada-LLM能够轻松适应不同的LLM骨干网络，且性能下降不明显，显示出其广泛的适用性。&lt;h4&gt;总结&lt;/h4&gt;通过提出一种新的图感知LLM，能够有效应对交通预测中的数据分布挑战，提升预测效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic prediction is a vital component of intelligent transportationsystems. By reasoning about traffic patterns in both the spatial and temporaldimensions, accurate and interpretable predictions can be provided. Aconsiderable challenge in traffic prediction lies in handling the diverse datadistributions caused by vastly different traffic conditions occurring atdifferent locations. LLMs have been a dominant solution due to their remarkablecapacity to adapt to new datasets with very few labeled data samples, i.e.,few-shot adaptability. However, existing forecasting techniques mainly focus onextracting local graph information and forming a text-like prompt, leaving LLM-based traffic prediction an open problem. This work presents a probabilisticLLM for traffic forecasting with three highlights. We propose a graph-aware LLMfor traffic prediction that considers proximal traffic information.Specifically, by considering the traffic of neighboring nodes as covariates,our model outperforms the corresponding time-series LLM. Furthermore, we adopta lightweight approach for efficient domain adaptation when facing new datadistributions in few-shot fashion. The comparative experiment demonstrates theproposed method outperforms the state-of-the-art LLM-based methods and thetraditional GNN- based supervised approaches. Furthermore, Strada-LLM can beeasily adapted to different LLM backbones without a noticeable performancedrop.</description>
      <author>example@mail.com (Seyed Mohamad Moghadas, Yangxintong Lyu, Bruno Cornelis, Alexandre Alahi, Adrian Munteanu)</author>
      <guid isPermaLink="false">2410.20856v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Temporal Linear Network for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.21448v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近期研究质疑了复杂深度学习架构在时间序列预测中的必要性，表明简单线性模型往往优于复杂方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种新架构——时间线性网络（TLN），扩展线性模型的能力，同时保持可解释性和计算效率。&lt;h4&gt;方法&lt;/h4&gt;TLN设计用于有效捕捉多变量时间序列数据中的时间依赖性和特征依赖性，其为TSMixer的变体，保持严格线性结构。&lt;h4&gt;主要发现&lt;/h4&gt;TLN通过去除激活函数、引入专门的内核初始化和稀疏卷积处理不同时间尺度，同时保留模型的线性特性。&lt;h4&gt;结论&lt;/h4&gt;TLN显式保留和利用输入数据的时间结构，能够计算等效线性模型，提供更高的可解释性，便于在TLN模型和线性等效模型间无缝转换。&lt;h4&gt;总结&lt;/h4&gt;TLN架构结合了线性模型的优势和复杂模型的灵活性，为时间序列预测提供了一种高效且可解释的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/remigenet/TLN&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has challenged the necessity of complex deep learningarchitectures for time series forecasting, demonstrating that simple linearmodels can often outperform sophisticated approaches. Building upon thisinsight, we introduce a novel architecture the Temporal Linear Net (TLN), thatextends the capabilities of linear models while maintaining interpretabilityand computational efficiency. TLN is designed to effectively capture bothtemporal and feature-wise dependencies in multivariate time series data. Ourapproach is a variant of TSMixer that maintains strict linearity throughout itsarchitecture. TSMixer removes activation functions, introduces specializedkernel initializations, and incorporates dilated convolutions to handle varioustime scales, while preserving the linear nature of the model. Unliketransformer-based models that may lose temporal information due to theirpermutation-invariant nature, TLN explicitly preserves and leverages thetemporal structure of the input data. A key innovation of TLN is its ability tocompute an equivalent linear model, offering a level of interpretability notfound in more complex architectures such as TSMixer. This feature allows forseamless conversion between the full TLN model and its linear equivalent,facilitating both training flexibility and inference optimization.</description>
      <author>example@mail.com (Remi Genet, Hugo Inzirillo)</author>
      <guid isPermaLink="false">2410.21448v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>GPTR: Gaussian Process Trajectory Representation for Continuous-Time Motion Estimation</title>
      <link>http://arxiv.org/abs/2410.22931v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The source code has been released. All feedbacks are welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;连续时间轨迹表示在近年来变得越来越受欢迎，能够融合更多传感器和感知方式，克服传统离散时间框架的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种高斯过程轨迹表示（GPTR）框架，用于连续时间运动估计（CTME）任务，以促进连续时间范式的采用。&lt;h4&gt;方法&lt;/h4&gt;采用三阶随机抖动模型，提供旋转和平移状态导数的闭式表达式，以实现平滑的连续轨迹表示。&lt;h4&gt;主要发现&lt;/h4&gt;GP基础的轨迹表示在多种运动估计任务中显示出有效性和效率，提供了优化示例，包括LiDAR、相机、IMU、UWB因子及闭式解析雅可比。&lt;h4&gt;结论&lt;/h4&gt;GPTR可以帮助研究人员快速开发未来应用，如批量优化、校准、传感器融合和轨迹规划等。&lt;h4&gt;资源&lt;/h4&gt;GPTR源代码作为轻量级头文件库可用，易于集成，无需大量代码修改。&lt;h4&gt;总结&lt;/h4&gt;该项目旨在支持更广泛的机器人和计算机视觉社区，提升连续时间轨迹表示的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuous-time trajectory representation has gained significant popularityin recent years, as it offers an elegant formulation that allows the fusion ofa larger number of sensors and sensing modalities, overcoming limitations oftraditional discrete-time frameworks. To bolster the adoption of thecontinuous-time paradigm, we propose a so-called Gaussian Process TrajectoryRepresentation (GPTR) framework for continuous-time motion estimation (CTME)tasks. Our approach stands out by employing a third-order random jerk model,featuring closed-form expressions for both rotational and translational statederivatives. This model provides smooth, continuous trajectory representationsthat are crucial for precise estimation of complex motion. To support the widerrobotics and computer vision communities, we have made the source code for GPTRavailable as a light-weight header-only library. This format was chosen for itsease of integration, allowing developers to incorporate GPTR into existingsystems without needing extensive code modifications. Moreover, we also providea set of optimization examples with LiDAR, camera, IMU, UWB factors, andclosed-form analytical Jacobians under the proposed GP framework. Ourexperiments demonstrate the efficacy and efficiency of GP-based trajectoryrepresentation in various motion estimation tasks, and the examples can serveas the prototype to help researchers quickly develop future applications suchas batch optimization, calibration, sensor fusion, trajectory planning, etc.,with continuous-time trajectory representation. Our project is accessible athttps://github.com/brytsknguyen/gptr .</description>
      <author>example@mail.com (Thien-Minh Nguyen, Ziyu Cao, Kailai Li, Shenghai Yuan, Lihua Xie)</author>
      <guid isPermaLink="false">2410.22931v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fakeium: A Dynamic Execution Environment for JavaScript Program Analysis</title>
      <link>http://arxiv.org/abs/2410.20862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;JavaScript作为一种简单的Web脚本语言，现已广泛应用于桌面、移动和服务器应用程序，增加了被恶意行为者利用的风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的动态分析工具，以检测JavaScript程序中的恶意模式。&lt;h4&gt;方法&lt;/h4&gt;提出Fakeium，一个基于V8引擎的开源轻量级执行环境，支持大规模动态分析。&lt;h4&gt;主要发现&lt;/h4&gt;Fakeium在执行开销极小的情况下，能够检测到隐藏的API调用，特别是在混淆代码中。&lt;h4&gt;结论&lt;/h4&gt;Fakeium为安全分析师提供了一种有效工具，可以在不依赖资源密集型浏览器或合成用户输入的情况下，识别JavaScript中的恶意行为。&lt;h4&gt;总结&lt;/h4&gt;Fakeium的灵活性和高度可定制性使其成为动态分析JavaScript程序的有价值工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The JavaScript programming language, which began as a simple scriptinglanguage for the Web, has become ubiquitous, spanning desktop, mobile, andserver applications. This increase in usage has made JavaScript an attractivetarget for nefarious actors, resulting in the proliferation of maliciousbrowser extensions that steal user information and supply chain attacks thattarget the official Node.js package registry. To combat these threats,researchers have developed specialized tools and frameworks for analyzing thebehavior of JavaScript programs to detect malicious patterns. Static analysistools typically struggle with the highly dynamic nature of the language andfail to process obfuscated sources, while dynamic analysis pipelines takeseveral minutes to run and require more resources per program, making themunfeasible for large-scale analyses. In this paper, we present Fakeium, anovel, open source, and lightweight execution environment designed forefficient, large-scale dynamic analysis of JavaScript programs. Built on top ofthe popular V8 engine, Fakeium complements traditional static analysis byproviding additional API calls and string literals that would otherwise gounnoticed without the need for resource-intensive instrumented browsers orsynthetic user input. Besides its negligible execution overhead, our tool ishighly customizable and supports hooks for advanced analysis scenarios such asnetwork traffic emulation. Fakeium's flexibility and ability to detect hiddenAPI calls, especially in obfuscated sources, highlights its potential as avaluable tool for security analysts to detect malicious behavior.</description>
      <author>example@mail.com (José Miguel Moreno, Narseo Vallina-Rodriguez, Juan Tapiador)</author>
      <guid isPermaLink="false">2410.20862v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Quantum Phase Estimation without Controlled Unitaries</title>
      <link>http://arxiv.org/abs/2410.21517v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究展示了如何使用适应的经典相位恢复算法进行无控制的量子相位估计。&lt;h4&gt;目的&lt;/h4&gt;消除常规方法中成本高昂的控制时间演化和Hadamard测试，以获取重建光谱所需的复杂时间序列。&lt;h4&gt;方法&lt;/h4&gt;通过扩展待解决的问题至具有更大输入信号集的形式，同时利用信号和/或光谱的自然约束，采用经典信号处理中的算法，具体使用了向量相位恢复和二维相位恢复两种互补方法。&lt;h4&gt;主要发现&lt;/h4&gt;数值研究表明这两种方法在估计费米-哈伯模型的光谱方面的可行性，并讨论了它们对固有统计噪声的韧性。&lt;h4&gt;结论&lt;/h4&gt;显著减少了所需的相干控制操作数量，降低了电路深度，简化了在近期期设备中实施统计量子相位估计的复杂性。&lt;h4&gt;总结&lt;/h4&gt;本研究为无控制的量子相位估计提供了一种新的方法，展示了经典算法在量子计算中的潜在应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work we demonstrate the use of adapted classical phase retrievalalgorithms to perform control-free quantum phase estimation. We eliminate thecostly controlled time evolution and Hadamard test commonly required to accessthe complex time-series needed to reconstruct the spectrum. This significantreduction of the number of coherent controlled-operations lowers the circuitdepth and considerably simplifies the implementation of statistical quantumphase estimation in near-term devices. This seemingly impossible task can beachieved by extending the problem that one wishes to solve to one with a largerset of input signals while exploiting natural constraints on the signal and/orthe spectrum. We leverage well-established algorithms that are widely used inthe context of classical signal processing, demonstrating two complementarymethods to do this, vectorial phase retrieval and two-dimensional phaseretrieval. We numerically investigate the feasibility of both approaches forestimating the spectrum of the Fermi-Hubbard model and discuss their resilienceto inherent statistical noise.</description>
      <author>example@mail.com (Laura Clinton, Toby S. Cubitt, Raul Garcia-Patron, Ashley Montanaro, Stasja Stanisic, Maarten Stroeks)</author>
      <guid isPermaLink="false">2410.21517v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>From 5G to 6G: A Survey on Security, Privacy, and Standardization Pathways</title>
      <link>http://arxiv.org/abs/2410.21986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;6G的愿景是提升网络能力，提供更快的数据传输速率、近乎零延迟和更高的容量。&lt;h4&gt;目的&lt;/h4&gt;支持更多连接设备，并在智能数字生态系统中实现无缝体验，人工智能在网络管理和数据分析中发挥关键作用。&lt;h4&gt;方法&lt;/h4&gt;对6G协议进行全面概述，重点关注安全和隐私，识别风险并提出缓解策略。&lt;h4&gt;主要发现&lt;/h4&gt;6G的扩展引发了严重的安全和隐私问题，包括未经授权的访问和数据泄露。&lt;h4&gt;结论&lt;/h4&gt;需要定制的6G解决方案，以应对物联网设备、边缘计算和AI驱动分析的集成带来的挑战。&lt;h4&gt;行业展望&lt;/h4&gt;讨论行业愿景、政府项目及标准化努力，以平衡技术创新与安全隐私措施。&lt;h4&gt;总结&lt;/h4&gt;本论文强调了在推进6G技术的同时，必须加强安全和隐私的保障。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The vision for 6G aims to enhance network capabilities with faster datarates, near-zero latency, and higher capacity, supporting more connecteddevices and seamless experiences within an intelligent digital ecosystem whereartificial intelligence (AI) plays a crucial role in network management anddata analysis. This advancement seeks to enable immersive mixed-realityexperiences, holographic communications, and smart city infrastructures.However, the expansion of 6G raises critical security and privacy concerns,such as unauthorized access and data breaches. This is due to the increasedintegration of IoT devices, edge computing, and AI-driven analytics. This paperprovides a comprehensive overview of 6G protocols, focusing on security andprivacy, identifying risks, and presenting mitigation strategies. The surveyexamines current risk assessment frameworks and advocates for tailored 6Gsolutions. We further discuss industry visions, government projects, andstandardization efforts to balance technological innovation with robustsecurity and privacy measures.</description>
      <author>example@mail.com (Mengmeng Yang, Youyang Qu, Thilina Ranbaduge, Chandra Thapa, Nazatul Sultan, Ming Ding, Hajime Suzuki, Wei Ni, Sharif Abuadbba, David Smith, Paul Tyler, Josef Pieprzyk, Thierry Rakotoarivelo, Xinlong Guan, Sirine M'rabet)</author>
      <guid isPermaLink="false">2410.21986v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>VISTA-SSM: Varying and Irregular Sampling Time-series Analysis via State Space Models</title>
      <link>http://arxiv.org/abs/2410.21527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种用于多变量和不规则采样时间序列的聚类方法，称为VISTA，基于参数状态空间混合模型。&lt;h4&gt;目的&lt;/h4&gt;旨在无监督地识别来自医疗和心理学数据集中的群体，这些数据集常常存在采样问题。&lt;h4&gt;方法&lt;/h4&gt;采用线性高斯状态空间模型（LGSSMs）构建灵活的参数框架，以适应多种时间序列动态，并假设人群可以表示为给定数量的LGSSMs混合。使用显式推导的对数似然函数，开发期望最大化方案来拟合模型参数。&lt;h4&gt;主要发现&lt;/h4&gt;VISTA能够处理具有大幅度采样率变化和不规则采样的多变量时间序列，其在模拟和真实数据集上的评估显示其在多种应用场景中的表现优于大多数标准时间序列聚类方法。&lt;h4&gt;结论&lt;/h4&gt;VISTA提供了一个开源的Python实现，证明了其在处理不规则时间序列数据方面的有效性和准确性。&lt;h4&gt;总结&lt;/h4&gt;VISTA是一种创新的聚类方法，适用于医疗和心理学领域中的复杂时间序列数据，展示了其优越的性能和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce VISTA, a clustering approach for multivariate and irregularlysampled time series based on a parametric state space mixture model. VISTA isspecifically designed for the unsupervised identification of groups in datasetsoriginating from healthcare and psychology where such sampling issues arecommonplace. Our approach adapts linear Gaussian state space models (LGSSMs) toprovide a flexible parametric framework for fitting a wide range of time seriesdynamics. The clustering approach itself is based on the assumption that thepopulation can be represented as a mixture of a given number of LGSSMs. VISTA'smodel formulation allows for an explicit derivation of the log-likelihoodfunction, from which we develop an expectation-maximization scheme for fittingmodel parameters to the observed data samples. Our algorithmic implementationis designed to handle populations of multivariate time series that can exhibitlarge changes in sampling rate as well as irregular sampling. We evaluate theversatility and accuracy of our approach on simulated and real-world datasets,including demographic trends, wearable sensor data, epidemiological timeseries, and ecological momentary assessments. Our results indicate that VISTAoutperforms most comparable standard times series clustering methods. Weprovide an open-source implementation of VISTA in Python.</description>
      <author>example@mail.com (Benjamin Brindle, Thomas Derrick Hull, Matteo Malgaroli, Nicolas Charon)</author>
      <guid isPermaLink="false">2410.21527v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PDSR: Efficient UAV Deployment for Swift and Accurate Post-Disaster Search and Rescue</title>
      <link>http://arxiv.org/abs/2410.22982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is currently under review at IEEE IoT Magazine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了一种全面的灾后搜索与救援（PDSR）框架，旨在利用无人机优化搜索和救援操作。&lt;h4&gt;目的&lt;/h4&gt;提高在各种灾害场景下的传感能力的精确性和可用性。&lt;h4&gt;方法&lt;/h4&gt;快速部署装备有多种传感、通信和智能能力的无人机群，作为集成系统，结合多种技术与方法进行高效检测。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够显著快于传统方法实现对受损区域的全面覆盖。&lt;h4&gt;结论&lt;/h4&gt;通过与机器学习结合的多模态传感数据融合，可以提高检测准确性，确保精确识别幸存者。&lt;h4&gt;挑战&lt;/h4&gt;提出了架构解决方案并解决了相关挑战，以确保在实际灾害场景中的最佳性能。&lt;h4&gt;总结&lt;/h4&gt;该框架通过多层次无人机群架构与数据融合技术，优化了灾后搜索与救援效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a comprehensive framework for Post-Disaster Search andRescue (PDSR), aiming to optimize search and rescue operations leveragingUnmanned Aerial Vehicles (UAVs). The primary goal is to improve the precisionand availability of sensing capabilities, particularly in various catastrophicscenarios. Central to this concept is the rapid deployment of UAV swarmsequipped with diverse sensing, communication, and intelligence capabilities,functioning as an integrated system that incorporates multiple technologies andapproaches for efficient detection of individuals buried beneath rubble ordebris following a disaster. Within this framework, we propose architecturalsolution and address associated challenges to ensure optimal performance inreal-world disaster scenarios. The proposed framework aims to achieve completecoverage of damaged areas significantly faster than traditional methods using amulti-tier swarm architecture. Furthermore, integrating multi-modal sensingdata with machine learning for data fusion could enhance detection accuracy,ensuring precise identification of survivors.</description>
      <author>example@mail.com (Alaa Awad Abdellatif, Ali Elmancy, Amr Mohamed, Ahmed Massoud, Wadha Lebda, Khalid K. Naji)</author>
      <guid isPermaLink="false">2410.22982v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FairStream: Fair Multimedia Streaming Benchmark for Reinforcement Learning Agents</title>
      <link>http://arxiv.org/abs/2410.21029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多媒体流媒体占据了当前互联网流量的大部分。&lt;h4&gt;目的&lt;/h4&gt;探讨如何在波动的网络条件下优化多媒体流的比特率，以提升播放流畅性和用户体验（QoE）。&lt;h4&gt;方法&lt;/h4&gt;研究者训练了强化学习（RL）代理，考虑了多种挑战，如部分可观测性、多目标、代理异质性和异步性，提出了一种新的多代理环境。&lt;h4&gt;主要发现&lt;/h4&gt;通过对五种不同流量类别的基线方法进行分析，发现常用的近端策略优化（PPO）算法不如简单的贪婪启发式方法表现优越。&lt;h4&gt;结论&lt;/h4&gt;未来的工作将包括多代理RL算法的适应以及环境的进一步扩展。&lt;h4&gt;总结&lt;/h4&gt;本研究为多媒体流的公平性及其在复杂环境中的表现提供了新的见解，强调了算法选择的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jw3il/fairstream&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimedia streaming accounts for the majority of traffic in today'sinternet. Mechanisms like adaptive bitrate streaming control the bitrate of astream based on the estimated bandwidth, ideally resulting in smooth playbackand a good Quality of Experience (QoE). However, selecting the optimal bitrateis challenging under volatile network conditions. This motivated researchers totrain Reinforcement Learning (RL) agents for multimedia streaming. Theconsidered training environments are often simplified, leading to promisingresults with limited applicability. Additionally, the QoE fairness acrossmultiple streams is seldom considered by recent RL approaches. With this work,we propose a novel multi-agent environment that comprises multiple challengesof fair multimedia streaming: partial observability, multiple objectives, agentheterogeneity and asynchronicity. We provide and analyze baseline approachesacross five different traffic classes to gain detailed insights into thebehavior of the considered agents, and show that the commonly used ProximalPolicy Optimization (PPO) algorithm is outperformed by a simple greedyheuristic. Future work includes the adaptation of multi-agent RL algorithms andfurther expansions of the environment.</description>
      <author>example@mail.com (Jannis Weil, Jonas Ringsdorf, Julian Barthel, Yi-Ping Phoebe Chen, Tobias Meuser)</author>
      <guid isPermaLink="false">2410.21029v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Reconstructing East Asian Temperatures from 1368 to 1911 Using Historical Documents, Climate Models, and Data Assimilation</title>
      <link>http://arxiv.org/abs/2410.21790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 15 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在1368年至1911年间，东亚缺乏仪器数据，导致理解过去气候条件面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;重建东亚的年度温度，利用重建的东亚气候历史编码系列(REACHES)。&lt;h4&gt;方法&lt;/h4&gt;采用三层统计框架，包括克里金插值法、定量映射和贝叶斯数据同化方法，整合历史文献和现代气候模型。&lt;h4&gt;主要发现&lt;/h4&gt;克里金法处理缺失信息，定量映射将REACHES数据校准至摄氏温度，贝叶斯方法提高重建精度。&lt;h4&gt;结论&lt;/h4&gt;通过综合历史文献、现代气候模型和先进统计方法，显著改善了历史温度重建的准确性，成为未来环境和气候研究的重要资源。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种有效的历史温度重建方法，填补了东亚地区气候数据的空白，为相关研究提供了重要基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel approach for reconstructing annual temperatures in EastAsia from 1368 to 1911, leveraging the Reconstructed East Asian ClimateHistorical Encoded Series (REACHES). The lack of instrumental data during thisperiod poses significant challenges to understanding past climate conditions.REACHES digitizes historical documents from the Ming and Qing dynasties ofChina, converting qualitative descriptions into a four-level ordinaltemperature scale. However, these index-based data are biased toward abnormalor extreme weather phenomena, leading to data gaps that likely correspond tonormal conditions. To address this bias and reconstruct historical temperaturesat any point within East Asia, including locations without direct historicaldata, we employ a three-tiered statistical framework. First, we perform krigingto interpolate temperature data across East Asia, adopting a zero-meanassumption to handle missing information. Next, we utilize the Last MillenniumEnsemble (LME) reanalysis data and apply quantile mapping to calibrate thekriged REACHES data to Celsius temperature scales. Finally, we introduce anovel Bayesian data assimilation method that integrates the kriged Celsius datawith LME simulations to enhance reconstruction accuracy. We model the LME dataat each geographic location using a flexible nonstationary autoregressive timeseries model and employ regularized maximum likelihood estimation with a fusedlasso penalty. The resulting dynamic distribution serves as a prior, which isrefined via Kalman filtering by incorporating the kriged Celsius REACHES datato yield posterior temperature estimates. This comprehensive integration ofhistorical documentation, contemporary climate models, and advanced statisticalmethods improves the accuracy of historical temperature reconstructions andprovides a crucial resource for future environmental and climate studies.</description>
      <author>example@mail.com (Eric Sun, Kuan-hui Elaine Lin, Wan-Ling Tseng, Pao K. Wang, Hsin-Cheng Huang)</author>
      <guid isPermaLink="false">2410.21790v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics</title>
      <link>http://arxiv.org/abs/2410.22997v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, 2 tables, to be published in the 2024 IEEE-RAS
  International Conference on Humanoid Robots, We make our code, including all
  prompts, available at https://github.com/AIS-Bonn/Prompt_Engineering&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;最近大型语言模型（LLM）的进展在自主机器人控制和人机交互中发挥了重要作用，利用其广泛的知识和理解能力。&lt;h4&gt;目的&lt;/h4&gt;比较不同的提示工程技术及其组合在服务机器人高层任务规划和执行中的应用。&lt;h4&gt;方法&lt;/h4&gt;定义一组多样化的任务和简单的功能集，在仿真环境中测量多个先进模型的任务完成准确性和执行时间。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比不同的提示工程技术，评估它们在任务规划和执行中的表现。&lt;h4&gt;结论&lt;/h4&gt;提示工程技术的有效性对服务机器人在高层任务执行中的性能有显著影响。&lt;h4&gt;总结&lt;/h4&gt;本研究为提升服务机器人的任务执行能力提供了实证依据，并为未来的研究方向指明了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ais-bonn/prompt_engineering&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in LLM have been instrumental in autonomous robot control andhuman-robot interaction by leveraging their vast general knowledge andcapabilities to understand and reason across a wide range of tasks andscenarios. Previous works have investigated various prompt engineeringtechniques for improving the performance of \glspl{LLM} to accomplish tasks,while others have proposed methods that utilize LLMs to plan and execute tasksbased on the available functionalities of a given robot platform. In this work,we consider both lines of research by comparing prompt engineering techniquesand combinations thereof within the application of high-level task planning andexecution in service robotics. We define a diverse set of tasks and a simpleset of functionalities in simulation, and measure task completion accuracy andexecution time for several state-of-the-art models.</description>
      <author>example@mail.com (Jonas Bode, Bastian Pätzold, Raphael Memmesheimer, Sven Behnke)</author>
      <guid isPermaLink="false">2410.22997v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.21086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全球交通安全面临重大挑战，交通事故每年导致约135万人死亡，主要原因是人为错误。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的驾驶员监测系统（DMS），以评估SAE 2/3级自动驾驶环境中的认知负荷和困倦。&lt;h4&gt;方法&lt;/h4&gt;提出一种新型的多任务DMS，称为VDMoE，利用RGB视频输入非侵入性地监测驾驶员状态，结合远程光电容积描记法（rPPG）获取生理信息。&lt;h4&gt;主要发现&lt;/h4&gt;VDMoE在监测驾驶员状态方面有效，提高了检测准确性并保持了效率，且优化了专家混合框架以处理多模态输入。&lt;h4&gt;结论&lt;/h4&gt;VDMoE为提高自动驾驶系统的安全性做出了贡献，代码和数据将在后续发布。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过先进的监测系统提高驾驶安全性的潜力，尤其是在驾驶员可能分心或疲劳的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Road safety remains a critical challenge worldwide, with approximately 1.35million fatalities annually attributed to traffic accidents, often due to humanerrors. As we advance towards higher levels of vehicle automation, challengesstill exist, as driving with automation can cognitively over-demand drivers ifthey engage in non-driving-related tasks (NDRTs), or lead to drowsiness ifdriving was the sole task. This calls for the urgent need for an effectiveDriver Monitoring System (DMS) that can evaluate cognitive load and drowsinessin SAE Level-2/3 autonomous driving contexts. In this study, we propose a novelmulti-task DMS, termed VDMoE, which leverages RGB video input to monitor driverstates non-invasively. By utilizing key facial features to minimizecomputational load and integrating remote Photoplethysmography (rPPG) forphysiological insights, our approach enhances detection accuracy whilemaintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE)framework to accommodate multi-modal inputs and improve performance acrossdifferent tasks. A novel prior-inclusive regularization method is introduced toalign model outputs with statistical priors, thus accelerating convergence andmitigating overfitting risks. We validate our method with the creation of a newdataset (MCDD), which comprises RGB video and physiological indicators from 42participants, and two public datasets. Our findings demonstrate theeffectiveness of VDMoE in monitoring driver states, contributing to saferautonomous driving systems. The code and data will be released.</description>
      <author>example@mail.com (Jiyao Wang, Xiao Yang, Zhenyu Wang, Ximeng Wei, Ange Wang, Dengbo He, Kaishun Wu)</author>
      <guid isPermaLink="false">2410.21086v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fingerprinting Browsers in Encrypted Communications</title>
      <link>http://arxiv.org/abs/2410.21101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;浏览器指纹识别是通过捕获浏览器与服务器之间通信的网络流量来识别浏览器。&lt;h4&gt;目的&lt;/h4&gt;讨论基于TLS 1.3协议的HTTPS下的浏览器指纹识别方法。&lt;h4&gt;方法&lt;/h4&gt;建立一个使用UTM虚拟机管理程序的网络，设置一个虚拟机作为服务器，另一个虚拟机使用不同的浏览器进行通信。&lt;h4&gt;主要发现&lt;/h4&gt;不同浏览器与服务器通信时使用的消息数量不同，消息长度也存在差异。&lt;h4&gt;结论&lt;/h4&gt;不同浏览器的行为存在30%-35%的不相似性。&lt;h4&gt;总结&lt;/h4&gt;浏览器指纹识别可以通过分析HTTPS协议传输中的消息特征来实现，具有显著的浏览器间差异性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Browser fingerprinting is the identification of a browser through the networktraffic captured during communication between the browser and server. This canbe done using the HTTP protocol, browser extensions, and other methods. Thispaper discusses browser fingerprinting using the HTTPS over TLS 1.3 protocol.The study observed that different browsers use a different number of messagesto communicate with the server, and the length of messages also varies. Toconduct the study, a network was set up using a UTM hypervisor with one virtualmachine as the server and another as a VM with a different browser. Thecommunication was captured, and it was found that there was a 30\%-35\%dissimilarity in the behavior of different browsers.</description>
      <author>example@mail.com (Sandhya Aneja, Nagender Aneja)</author>
      <guid isPermaLink="false">2410.21101v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DexGraspNet 2.0: Learning Generative Dexterous Grasping in Large-scale Synthetic Cluttered Scenes</title>
      <link>http://arxiv.org/abs/2410.23004v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在杂乱场景中，灵巧手的抓取仍然非常具有挑战性，因为数据稀缺。&lt;h4&gt;目的&lt;/h4&gt;提出一个大规模的合成基准，解决抓取数据不足的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的两阶段抓取方法，利用条件在局部几何上的扩散模型高效学习数据。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的生成方法在模拟实验中优于所有基线。&lt;h4&gt;结论&lt;/h4&gt;通过测试时深度恢复，方法实现了零样本的模拟到真实转移，在杂乱场景中达到了90.7%的真实世界灵巧抓取成功率。&lt;h4&gt;总结&lt;/h4&gt;通过创新的基准和方法，显著提升了灵巧手在复杂环境中的抓取能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping in cluttered scenes remains highly challenging for dexterous handsdue to the scarcity of data. To address this problem, we present a large-scalesynthetic benchmark, encompassing 1319 objects, 8270 scenes, and 427 milliongrasps. Beyond benchmarking, we also propose a novel two-stage grasping methodthat learns efficiently from data by using a diffusion model that conditions onlocal geometry. Our proposed generative method outperforms all baselines insimulation experiments. Furthermore, with the aid of test-time-depthrestoration, our method demonstrates zero-shot sim-to-real transfer, attaining90.7% real-world dexterous grasping success rate in cluttered scenes.</description>
      <author>example@mail.com (Jialiang Zhang, Haoran Liu, Danshi Li, Xinqiang Yu, Haoran Geng, Yufei Ding, Jiayi Chen, He Wang)</author>
      <guid isPermaLink="false">2410.23004v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Individualised recovery trajectories of patients with impeded mobility, using distance between probability distributions of learnt graphs</title>
      <link>http://arxiv.org/abs/2410.21983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;患者在进行身体康复时，依赖于可靠评估其累计表现的反馈。&lt;h4&gt;目的&lt;/h4&gt;提供一种方法，以学习患者在身体治疗中恢复运动能力的轨迹。&lt;h4&gt;方法&lt;/h4&gt;使用时间序列数据记录20个关节位置，通过贝叶斯学习的随机图计算运动恢复评分（MRS），并绘制恢复轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;患者在进行相同运动时的MRS差异可以通过统计距离/发散度来描述。&lt;h4&gt;结论&lt;/h4&gt;基于恢复学习结果，提出针对不同运动损伤程度患者的最佳运动方案建议。&lt;h4&gt;总结&lt;/h4&gt;本研究为身体康复提供了一种基于数据驱动的方法，帮助优化患者的恢复过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.artmed.2024.103005.&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patients who are undergoing physical rehabilitation, benefit from feedbackthat follows from reliable assessment of their cumulative performance attainedat a given time. In this paper, we provide a method for the learning of therecovery trajectory of an individual patient, as they undertake exercises aspart of their physical therapy towards recovery of their loss of movementability, following a critical illness. The difference between the MovementRecovery Scores (MRSs) attained by a patient, when undertaking a given exerciseroutine on successive instances, is given by a statistical distance/divergencebetween the (posterior) probabilities of random graphs that are Bayesianlylearnt using time series data on locations of 20 of the patient's joints,recorded on an e-platform as the patient exercises. This allows for thecomputation of the MRS on every occasion the patient undertakes this exercise,using which, the recovery trajectory is drawn. We learn each graph as a RandomGeometric Graph drawn in a probabilistic metric space, and identify theclosed-form marginal posterior of any edge of the graph, given the correlationstructure of the multivariate time series data on joint locations. On the basisof our recovery learning, we offer recommendations on the optimal exerciseroutines for patients with given level of mobility impairment.</description>
      <author>example@mail.com (Chuqiao Zhang, Crina Grosan, Dalia Chakrabarty)</author>
      <guid isPermaLink="false">2410.21983v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Host-SSD Collaborative Write Accelerator for LSM-Tree-Based Key-Value Stores</title>
      <link>http://arxiv.org/abs/2410.21760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Log-Structured Merge (LSM)树基于的键值存储（KVS）在写密集型环境中表现出色，但在压缩过程中常出现写停滞，导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出KVACCEL，一个新颖的硬件-软件协同设计框架，消除写停滞。&lt;h4&gt;方法&lt;/h4&gt;利用双接口SSD分配逻辑NAND闪存空间，支持块接口和键值接口，在写停滞期间使用键值接口作为临时写缓冲区。&lt;h4&gt;主要发现&lt;/h4&gt;KVACCEL在写密集型工作负载中，吞吐量比ADOC提高了最高1.17倍，性能与CPU利用效率优化显著。&lt;h4&gt;结论&lt;/h4&gt;对于混合读写工作负载，KVACCEL与ADOC表现相当。&lt;h4&gt;总结&lt;/h4&gt;KVACCEL通过优化资源使用和确保主机与设备之间的一致性，有效减少了写停滞现象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Log-Structured Merge (LSM) tree-based Key-Value Stores (KVSs) are widelyadopted for their high performance in write-intensive environments, but theyoften face performance degradation due to write stalls during compaction. Priorsolutions, such as regulating I/O traffic or using multiple compaction threads,can cause unexpected drops in throughput or increase host CPU usage, whilehardware-based approaches using FPGA, GPU, and DPU aimed at reducing compactionduration introduce additional hardware costs. In this study, we proposeKVACCEL, a novel hardware-software co-design framework that eliminates writestalls by leveraging a dual-interface SSD. KVACCEL allocates logical NAND flashspace to support both block and key-value interfaces, using the key-valueinterface as a temporary write buffer during write stalls. This strategysignificantly reduces write stalls, optimizes resource usage, and ensuresconsistency between the host and device by implementing an in-device LSM-basedwrite buffer with an iterator-based range scan mechanism. Our extensiveevaluation shows that for write-intensive workloads, KVACCEL outperforms ADOCby up to 1.17x in terms of throughput and performance-to-CPU-utilizationefficiency. For mixed read-write workloads, both demonstrate comparableperformance.</description>
      <author>example@mail.com (KiHwan Kim, Hyunsun Chung, Seonghoon Ahn, Junhyeok Park, Safdar Jamil, Hongsu Byun, Myungcheol Lee, Jinchun Choi, Youngjae Kim)</author>
      <guid isPermaLink="false">2410.21760v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback</title>
      <link>http://arxiv.org/abs/2410.23022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动从自然语言描述中合成密集奖励是一种有前景的强化学习范式，适用于稀疏奖励问题、开放式探索和层次技能设计。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法的限制，提升强化学习中的奖励合成能力。&lt;h4&gt;方法&lt;/h4&gt;提出ONI分布式架构，同时学习强化学习策略和内在奖励函数，利用大型语言模型（LLM）反馈，通过异步LLM服务器标注代理的经验，进而提炼成内在奖励模型。&lt;h4&gt;主要发现&lt;/h4&gt;探索了多种奖励建模的算法选择，包括哈希、分类和排序模型，并研究了它们的相对权衡。&lt;h4&gt;结论&lt;/h4&gt;该方法在NetHack学习环境中的一系列挑战性稀疏奖励任务上实现了最先进的性能，完全依赖于代理收集的经验，无需外部数据集或源代码。&lt;h4&gt;总结&lt;/h4&gt;研究展示了利用LLM反馈来改进强化学习奖励合成的潜力，提供了一种统一的简单过程来处理稀疏奖励问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatically synthesizing dense rewards from natural language descriptionsis a promising paradigm in reinforcement learning (RL), with applications tosparse reward problems, open-ended exploration, and hierarchical skill design.Recent works have made promising steps by exploiting the prior knowledge oflarge language models (LLMs). However, these approaches suffer from importantlimitations: they are either not scalable to problems requiring billions ofenvironment samples; or are limited to reward functions expressible by compactcode, which may require source code and have difficulty capturing nuancedsemantics; or require a diverse offline dataset, which may not exist or beimpossible to collect. In this work, we address these limitations through acombination of algorithmic and systems-level contributions. We propose ONI, adistributed architecture that simultaneously learns an RL policy and anintrinsic reward function using LLM feedback. Our approach annotates theagent's collected experience via an asynchronous LLM server, which is thendistilled into an intrinsic reward model. We explore a range of algorithmicchoices for reward modeling with varying complexity, including hashing,classification, and ranking models. By studying their relative tradeoffs, weshed light on questions regarding intrinsic reward design for sparse rewardproblems. Our approach achieves state-of-the-art performance across a range ofchallenging, sparse reward tasks from the NetHack Learning Environment in asimple unified process, solely using the agent's gathered experience, withoutrequiring external datasets nor source code. We make our code available at\url{URL} (coming soon).</description>
      <author>example@mail.com (Qinqing Zheng, Mikael Henaff, Amy Zhang, Aditya Grover, Brandon Amos)</author>
      <guid isPermaLink="false">2410.23022v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Infrared photometry with InGaAs detectors: First light with SPECULOOS</title>
      <link>http://arxiv.org/abs/2410.22140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SPIE Astronomical Telescopes + Instrumentation 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了SPIRIT的光度性能，该仪器是一种基于InGaAs CMOS的地面近红外设备，具有1280x1024像素和12微米的像素间距。&lt;h4&gt;目的&lt;/h4&gt;SPIRIT旨在优化对晚期M型和L型恒星的时间序列光度精度。&lt;h4&gt;方法&lt;/h4&gt;使用定制的宽通滤光器（0.81 - 1.33微米，zYJ），以减少大气可降水水汽（PWV）变动对差分光度的影响，并且设计为免维护，无需液氮冷却。&lt;h4&gt;主要发现&lt;/h4&gt;SPIRIT在观察L型及更冷恒星时表现出比传统CCD仪器（2048x2048像素，I+z'滤光器）更好的光度噪声性能。定制滤光器显著减少了由PWV变动引入的红噪声。&lt;h4&gt;结论&lt;/h4&gt;在SPIRIT的观测中，探测器的读出噪声是主要限制因素，但在某些情况下，缺乏比较恒星也限制了性能。&lt;h4&gt;总结&lt;/h4&gt;SPIRIT展现了优越的光度性能，尤其是在对晚期恒星的观测中，表明其在天文观测中的潜在应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1117/12.3018320&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present the photometric performance of SPIRIT, a ground-basednear-infrared InGaAs CMOS-based instrument (1280 by 1024 pixels, 12 micronpitch), using on-sky results from the SPECULOOS-Southern Observatory during2022 - 2023. SPIRIT was specifically designed to optimise time-seriesphotometric precision for observing late M and L type stars. To achieve this, acustom wide-pass filter (0.81 - 1.33 microns, zYJ ) was used, which was alsodesigned to minimise the effects of atmospheric precipitable water vapour (PWV)variability on differential photometry. Additionally, SPIRIT was designed to bemaintenance-free by eliminating the need for liquid nitrogen for cooling. Wecompared SPIRIT's performance with a deeply-depleted (2048 by 2048 pixels, 13.5micron pitch) CCD-based instrument (using an I+z' filter, 0.7 - 1.1 microns)through simultaneous observations. For L type stars and cooler, SPIRITexhibited better photometric noise performance compared to the CCD-basedinstrument. The custom filter also significantly minimised red noise in theobserved light curves typically introduced by atmospheric PWV variability. InSPIRIT observations, the detector's read noise was the dominant limitation,although in some cases, we were limited by the lack of comparison stars.</description>
      <author>example@mail.com (Peter P. Pedersen, Didier Queloz, Lionel Garcia, Yannick Schacke, Laetitia Delrez, Brice-Olivier Demory, Elsa Ducrot, Georgina Dransfield, Michael Gillon, Matthew J. Hooton, Clàudia Janó-Muñoz, Emmanuël Jehin, Daniel Sebastian, Mathilde Timmermans, Samantha Thompson, Amaury H. M. J. Triaud, Julien de Wit, Sebastián Zúñiga-Fernández)</author>
      <guid isPermaLink="false">2410.22140v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Data streaming platform for crowd-sourced vehicle dataset generation</title>
      <link>http://arxiv.org/abs/2410.21934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages. To be published in IEEE Transactions on Intelligent
  Vehicles&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;车辆是复杂的机器，配备了传感器以提供实时数据用于驾驶辅助系统。由于交通、道路和天气条件的多样性，系统的持续增强至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一个边缘-云数据平台，以连接汽车数据生产者与多种异构服务，解决数据空间中的关键挑战。&lt;h4&gt;方法&lt;/h4&gt;评估数据平台在文本、图像和视频数据工作负载下的性能限制，考察连接技术的影响，并评估延迟。&lt;h4&gt;主要发现&lt;/h4&gt;使用5G连接时，数据传输到边缘托管的应用程序的延迟降至33毫秒，而跨越边缘和云处理基础设施时约为77毫秒。&lt;h4&gt;结论&lt;/h4&gt;结果为避免汽车数据平台中的瓶颈提供了必要的处理资产指导。&lt;h4&gt;总结&lt;/h4&gt;该研究促进了数据驱动的互联和创新数据经济的发展，强调了边缘和云基础设施的协同作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TIV.2024.3486926&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicles are sophisticated machines equipped with sensors that providereal-time data for onboard driving assistance systems. Due to the wide varietyof traffic, road, and weather conditions, continuous system enhancements areessential. Connectivity allows vehicles to transmit previously unknown data,expanding datasets and accelerating the development of new data models. Thisenables faster identification and integration of novel data, improving systemreliability and reducing time to market. Data Spaces aim to create adata-driven, interconnected, and innovative data economy, where edge and cloudinfrastructures support a virtualised IoT platform that connects data sourcesand development servers. This paper proposes an edge-cloud data platform toconnect car data producers with multiple and heterogeneous services, addressingkey challenges in Data Spaces, such as data sovereignty, governance,interoperability, and privacy. The paper also evaluates the data platform'sperformance limits for text, image, and video data workloads, examines theimpact of connectivity technologies, and assesses latencies. The results showthat latencies drop to 33ms with 5G connectivity when pipelining data toconsuming applications hosted at the edge, compared to around 77ms whencrossing both edge and cloud processing infrastructures. The results offerguidance on the necessary processing assets to avoid bottlenecks in car dataplatforms.</description>
      <author>example@mail.com (Felipe Mogollon, Zaloa Fernandez, Angel Martin, Juan Diego Ortega, Gorka Velez)</author>
      <guid isPermaLink="false">2410.21934v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Camber-changing flapping hydrofoils for efficient and environmental-safe water propulsion system</title>
      <link>http://arxiv.org/abs/2410.23032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Peer-reviewed and accepted in Ubiquitous Robots 2024, New York City&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究介绍了一种新型的基于水翼的推进框架，灵感来源于某些水生物种的波动运动。&lt;h4&gt;目的&lt;/h4&gt;提高无人水下机器人在水中的推进效率。&lt;h4&gt;方法&lt;/h4&gt;采用动态仿真验证了调节弯度的水翼与对称水翼的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;调节弯度的水翼在水平推力方面显著优于对称设计，显示了弯度调节方法的潜力。&lt;h4&gt;结论&lt;/h4&gt;所提出的原型设计能够有效提供水上推进，并在水上飞机起飞时产生垂直力。&lt;h4&gt;应用&lt;/h4&gt;设计旨在利用波浪能，推动替代能源的探索。&lt;h4&gt;意义&lt;/h4&gt;该研究推进了水下机器人的仿生振荡原理的理解，为未来环保且灵活的水下探测发展奠定基础。&lt;h4&gt;总结&lt;/h4&gt;本研究为无人水下机器人的推进效率提升提供了新的思路和设计基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research introduces a novel hydrofoil-based propulsion framework forunmanned aquatic robots, inspired by the undulating locomotion observed inselect aquatic species. The proposed system incorporates a camber-modulatingmechanism to enhance hydrofoil propulsive force generation and eventuallyefficiency. Through dynamic simulations, we validate the effectiveness of thecamber-adjusting hydrofoil compared to a symmetric counterpart. The resultsdemonstrate a significant improvement in horizontal thrust, emphasizing thepotential of the cambering approach to enhance propulsive performance.Additionally, a prototype flipper design is presented, featuring individualcontrol of heave and pitch motions, as well as a camber-adjustment mechanism.The integrated system not only provides efficient water-based propulsion butalso offers the capacity for generating vertical forces during take-offmaneuvers for seaplanes. The design is tailored to harness wave energy,contributing to the exploration of alternative energy resources. This workadvances the understanding of bionic oscillatory principles for aquatic robotsand provides a foundation for future developments in environmentally safe andagile underwater exploration.</description>
      <author>example@mail.com (Luca Romanello, Leonard Hohaus, David-Marian Schmitt, Mirko Kovac, Sophie F. Armanini)</author>
      <guid isPermaLink="false">2410.23032v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Pulsar timing methods for evaluating dispersion measure time series</title>
      <link>http://arxiv.org/abs/2410.22170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;射电脉冲星研究电离星际介质及其色散效应，这对利用脉冲星进行引力波搜索的噪声源有重要影响。&lt;h4&gt;目的&lt;/h4&gt;比较三种常用方案在测量脉冲星定时数据中星际传播效应的时间变化方面的功能和可靠性。&lt;h4&gt;方法&lt;/h4&gt;在低观察频率（100-200 MHz）下进行广泛模拟，注入长期相关噪声过程及白噪声，评估三种去噪方法：逐epoch（EW）测量星际色散、DMX方法的分段拟合、以及通过贝叶斯分析的DMGP模型。&lt;h4&gt;主要发现&lt;/h4&gt;所有方法在建模色散时表现良好，DMGP方法精度最高，其次是DMX和EW；EW方法最准确，其次是DMX和DMGP。&lt;h4&gt;结论&lt;/h4&gt;EW被认为是研究银河系电离介质的最可靠方法，未来的研究应通过更现实的模拟来确认这一结果。&lt;h4&gt;其他发现&lt;/h4&gt;DMGP和DMX在去除长期相关噪声方面表现优异，适合引力波研究，但需进行完整的脉冲星定时阵列实验模拟以支持该解释。&lt;h4&gt;总结&lt;/h4&gt;研究表明，EW方法在可靠性上优于其他方法，而DMGP和DMX在噪声去除方面表现突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radio pulsars allow the study of the ionised interstellar medium and itsdispersive effects, a major noise source in gravitational wave searches usingpulsars. In this paper, we compare the functionality and reliability of threecommonly used schemes to measure temporal variations in interstellarpropagation effects in pulsar-timing data. We carry out extensive simulationsat low observing frequencies (100-200 MHz) by injecting long-term correlatednoise processes with power-law spectra and white noise, to evaluate therobustness, accuracy and precision of the following three mitigation methods:epoch-wise (EW) measurements of interstellar dispersion; the DMX method ofsimultaneous, piece-wise fits to interstellar dispersion; and DMGP, whichmodels dispersion variations through Gaussian processes using a Bayesiananalysis method. We then evaluate how reliably the input signals arereconstructed and how the various methods react to the presence of achromaticlong-period noise. All the methods perform well, provided the achromaticlong-period noise is modeled for DMX and DMGP. The most precise method is DMGP,followed by DMX and EW, while the most accurate is EW, followed by DMX andDMGP. We also test different scenarios including simulations of L-band ToAs andrealistic DM injection, with no significant variation in the obtained results.Given the nature of our simulations and our scope, we deem that EW is the mostreliable method to study the Galactic ionized media. Future works should beconducted to confirm this result via more realistic simulations. We note thatDM GP and DMX seem to be the most performing techniques in removing long-termcorrelated noise, and hence for gravitational wave studies. However, fullsimulations of pulsar timing array experiments are needed to support thisinterpretation.</description>
      <author>example@mail.com (F. Iraci, A. Chalumeau, C. Tiburzi, J. P. W. Verbiest, A. Possenti, G. M. Shaifullah, S. C. Susarla, M. A. Krishnakumar, M. T. Lam, H. T. Cromartie, M. Kerr, Jean-Mathias Grießmeier)</author>
      <guid isPermaLink="false">2410.22170v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>GRINNs: Godunov-Riemann Informed Neural Networks for Learning Hyperbolic Conservation Laws</title>
      <link>http://arxiv.org/abs/2410.22193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出GRINNs：一种基于数值分析的神经网络，旨在解决非线性守恒定律系统的反问题。&lt;h4&gt;目的&lt;/h4&gt;开发高分辨率的神经网络方法，以提高对超波动偏微分方程的求解能力。&lt;h4&gt;方法&lt;/h4&gt;GRINNs基于高分辨率的Godunov方案解决黎曼问题，学习物理通量函数而非数值通量。&lt;h4&gt;主要发现&lt;/h4&gt;在四个基准问题（Burgers'、浅水、Lighthill-Whitham-Richards及Payne-Whitham交通流模型）中，GRINNs在光滑和不连续区域均表现出极高的准确性。&lt;h4&gt;结论&lt;/h4&gt;GRINNs提供了一种可解释的守恒方案，能够有效学习满足Rankine-Hugoniot条件的解算子。&lt;h4&gt;总结&lt;/h4&gt;GRINNs是一种创新的神经网络方法，能够高效解决涉及冲击波和稀疏区域的复杂问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present GRINNs: numerical analysis-informed neural networks for thesolution of inverse problems of non-linear systems of conservation laws. GRINNsare based on high-resolution Godunov schemes for the solution of the Riemannproblem in hyperbolic Partial Differential Equations (PDEs). In contrast toother existing machine learning methods that learn the numerical fluxes ofconservative Finite Volume methods, GRINNs learn the physical flux function perse. Due to their structure, GRINNs provide interpretable, conservative schemes,that learn the solution operator on the basis of approximate Riemann solversthat satisfy the Rankine-Hugoniot condition. The performance of GRINNs isassessed via four benchmark problems, namely the Burgers', the Shallow Water,the Lighthill-Whitham-Richards and the Payne-Whitham traffic flow models. Thesolution profiles of these PDEs exhibit shock waves, rarefactions and/orcontact discontinuities at finite times. We demonstrate that GRINNs provide avery high accuracy both in the smooth and discontinuous regions.</description>
      <author>example@mail.com (Dimitrios G. Patsatzis, Mario di Bernardo, Lucia Russo, Constantinos Siettos)</author>
      <guid isPermaLink="false">2410.22193v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Potential of Multi-modal Sensing Framework for Forest Ecology</title>
      <link>http://arxiv.org/abs/2410.23033v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Peer-reviewed and accepted in IEEE ICRA 2024 Workshop RUNE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;森林为人类提供重要资源和服务，但保护和恢复森林面临挑战，特别是在难以到达的区域，如森林树冠，缺乏可操作的数据。&lt;h4&gt;目的&lt;/h4&gt;探讨使用机器人技术改善森林数据收集，特别是通过无人机和其他方法获取树冠数据。&lt;h4&gt;方法&lt;/h4&gt;利用无人机群体展示自主导航，通过树冠灵活操控，避免树木碰撞，以进行区域映射和数据收集。&lt;h4&gt;主要发现&lt;/h4&gt;单靠自由飞行的无人机不足以满足数据收集需求，飞行过程中产生的噪音扰动动物，可能会影响数据的准确性。商业无人机在需要灵活操作的任务中自主性有限，进一步复杂化数据采集工作。&lt;h4&gt;结论&lt;/h4&gt;虽然生物滑翔机和传感器发射等方法在下层树冠的数据收集中表现有效，但在数据和传感器的回收上仍面临挑战，通常需要人工干预。&lt;h4&gt;总结&lt;/h4&gt;综合来看，森林数据收集领域亟需更有效的技术手段，以减少对生物学家的干扰和提高数据采集的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forests offer essential resources and services to humanity, yet preservingand restoring them presents challenges, particularly due to the limitedavailability of actionable data, especially in hard-to-reach areas like forestcanopies. Accessibility continues to pose a challenge for biologists collectingdata in forest environments, often requiring them to invest significant timeand energy in climbing trees to place sensors. This operation not only consumesresources but also exposes them to danger. Efforts in robotics have beendirected towards accessing the tree canopy using robots. A swarm of drones hasshowcased autonomous navigation through the canopy, maneuvering with agilityand evading tree collisions, all aimed at mapping the area and collecting data.However, relying solely on free-flying drones has proven insufficient for datacollection. Flying drones within the canopy generates loud noise, disturbinganimals and potentially corrupting the data. Additionally, commercial dronesoften have limited autonomy for dexterous tasks where aerial physicalinteraction could be required, further complicating data acquisition efforts.Aerial deployed sensor placement methods such as bio-gliders and sensorshooting have proven effective for data collection within the lower canopy.However, these methods face challenges related to retrieving the data andsensors, often necessitating human intervention.</description>
      <author>example@mail.com (Luca Romanello, Tian Lan, Mirko Kovac, Sophie F. Armanini, Basaran Bahadir Kocer)</author>
      <guid isPermaLink="false">2410.23033v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Hypergraph-based multi-scale spatio-temporal graph convolution network for Time-Series anomaly detection</title>
      <link>http://arxiv.org/abs/2410.22256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列异常检测技术在航空航天、水处理、云服务等多个领域中发挥重要作用。&lt;h4&gt;目的&lt;/h4&gt;提高工作效率，避免重大经济损失。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于超图的时空图卷积神经网络模型STGCN_Hyper，通过超图动态图结构学习模块捕获多个变量之间的高阶、多跳相关性，并利用多尺度TCN扩张卷积模块捕获时间维度上不同尺度的特征依赖。&lt;h4&gt;主要发现&lt;/h4&gt;STGCN_Hyper模型能够灵活学习多尺度时间序列特征及特征间的依赖关系，且在异常检测任务中在精确度、召回率和F1-score等指标上优于大多数现有基线模型。&lt;h4&gt;结论&lt;/h4&gt;本模型有效地实现了无监督的异常检测，并在多个时间序列数据集上取得了良好的实验结果。&lt;h4&gt;总结&lt;/h4&gt;STGCN_Hyper模型通过先进的技术手段提升了高维复杂数据集中的异常检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series anomaly detection technology plays an important rolein many fields including aerospace, water treatment, cloud service providers,etc. Excellent anomaly detection models can greatly improve work efficiency andavoid major economic losses. However, with the development of technology, theincreasing size and complexity of data, and the lack of labels for relevantabnormal data, it is becoming increasingly challenging to perform effective andaccurate anomaly detection in high-dimensional and complex data sets. In thispaper, we propose a hypergraph based spatiotemporal graph convolutional neuralnetwork model STGCN_Hyper, which explicitly captures high-order, multi-hopcorrelations between multiple variables through a hypergraph based dynamicgraph structure learning module. On this basis, we further use the hypergraphbased spatiotemporal graph convolutional network to utilize the learnedhypergraph structure to effectively propagate and aggregate one-hop andmulti-hop related node information in the convolutional network, therebyobtaining rich spatial information. Furthermore, through the multi-scale TCNdilated convolution module, the STGCN_hyper model can also capture thedependencies of features at different scales in the temporal dimension. Anunsupervised anomaly detector based on PCA and GMM is also integrated into theSTGCN_hyper model. Through the anomaly score of the detector, the model candetect the anomalies in an unsupervised way. Experimental results on multipletime series datasets show that our model can flexibly learn the multi-scaletime series features in the data and the dependencies between features, andoutperforms most existing baseline models in terms of precision, recall,F1-score on anomaly detection tasks. Our code is available on:https://git.ecdf.ed.ac.uk/msc-23-24/s2044819</description>
      <author>example@mail.com (Hongyi Xu)</author>
      <guid isPermaLink="false">2410.22256v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Cora: Accelerating Stateful Network Applications with SmartNICs</title>
      <link>http://arxiv.org/abs/2410.22229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着网络应用性能要求的提高，越来越多的状态ful网络应用被转移到SmartNICs，以提升性能并降低总体拥有成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的方法来卸载状态ful网络应用，以应对状态操作复杂性和资源消耗问题。&lt;h4&gt;方法&lt;/h4&gt;提出Cora编译器和运行时，Cora编译器为每个SmartNIC引入准确的性能模型，并使用高效的编译算法搜索卸载计划，Cora运行时监控流量动态并进行适应性调整。&lt;h4&gt;主要发现&lt;/h4&gt;Cora可以在相同的吞吐量目标下，提出节省高达94.0% CPU核心的分区方案，相比基线方案提升1.9倍；在相同资源约束下，Cora能够加速网络功能44.9%-82.3%。&lt;h4&gt;结论&lt;/h4&gt;Cora运行时能够适应流量变化，保持较低的CPU使用率。&lt;h4&gt;总结&lt;/h4&gt;Cora是一种有效的解决方案，能够显著提高状态ful网络应用的性能并降低资源使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing performance requirements on networked applications, there isa new trend of offloading stateful network applications to SmartNICs to improveperformance and reduce the total cost of ownership. However, offloadingstateful network applications is non-trivial due to state operation complexity,state resource consumption, and the complicated relationship between trafficand state. Naively partitioning the program by state or traffic can result in asuboptimal partition plan with higher CPU usage or even packet drops. In thispaper, we propose Cora, a compiler and runtime that offloads stateful networkapplications to SmartNIC-accelerated hosts. Cora compiler introduces anaccurate performance model for each SmartNIC and employs an efficient compilingalgorithm to search the offloading plan. Cora runtime can monitor trafficdynamics and adapt to minimize CPU usage. Cora is built atop Netronome Agilioand BlueField 2 SmartNICs. Our evaluation shows that for the same throughputtarget, Cora can propose partition plans saving up to 94.0% CPU cores, 1.9times more than baseline solutions. Under the same resource constraint, Coracan accelerate network functions by 44.9%-82.3%. Cora runtime can adapt totraffic changes and keep CPU usage low.</description>
      <author>example@mail.com (Shaoke Xi, Jiaqi Gao, Mengqi Liu, Jiamin Cao, Fuliang Li, Kai Bu, Kui Ren, Minlan Yu, Dennis Cai, Ennan Zhai)</author>
      <guid isPermaLink="false">2410.22229v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Neural Attention Field: Emerging Point Relevance in 3D Scenes for One-Shot Dexterous Grasping</title>
      <link>http://arxiv.org/abs/2410.23039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在具有物体和上下文变化的新场景中，一次性转移灵巧抓取一直是一个具有挑战性的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种神经注意力场，以表示3D空间中语义感知的密集特征场。&lt;h4&gt;方法&lt;/h4&gt;使用变压器解码器计算任意3D查询点与所有场景点之间的跨注意力，并提供基于注意力的聚合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过鼓励末端效应器关注任务相关的场景区域，显著提高了真实机器人上的成功率。&lt;h4&gt;结论&lt;/h4&gt;与基于特征场的方法相比，所提出的方法在优化效果上表现更好。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了如何通过自监督框架在少量3D点云上训练变压器解码器，从而实现一次性演示下的语义感知灵巧抓取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; One-shot transfer of dexterous grasps to novel scenes with object and contextvariations has been a challenging problem. While distilled feature fields fromlarge vision models have enabled semantic correspondences across 3D scenes,their features are point-based and restricted to object surfaces, limitingtheir capability of modeling complex semantic feature distributions forhand-object interactions. In this work, we propose the \textit{neural attentionfield} for representing semantic-aware dense feature fields in the 3D space bymodeling inter-point relevance instead of individual point features. Core to itis a transformer decoder that computes the cross-attention between any 3D querypoint with all the scene points, and provides the query point feature with anattention-based aggregation. We further propose a self-supervised framework fortraining the transformer decoder from only a few 3D pointclouds without handdemonstrations. Post-training, the attention field can be applied to novelscenes for semantics-aware dexterous grasping from one-shot demonstration.Experiments show that our method provides better optimization landscapes byencouraging the end-effector to focus on task-relevant scene regions, resultingin significant improvements in success rates on real robots compared with thefeature-field-based methods.</description>
      <author>example@mail.com (Qianxu Wang, Congyue Deng, Tyler Ga Wei Lum, Yuanpei Chen, Yaodong Yang, Jeannette Bohg, Yixin Zhu, Leonidas Guibas)</author>
      <guid isPermaLink="false">2410.23039v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Stochastic Flow Matching for Resolving Small-Scale Physics</title>
      <link>http://arxiv.org/abs/2410.19814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;条件扩散和流模型在自然图像中对于超分辨小尺度细节效果显著，但在物理科学（如天气）中面临挑战。&lt;h4&gt;目的&lt;/h4&gt;解决小尺度细节超分辨问题，尤其是在天气数据处理中。&lt;h4&gt;方法&lt;/h4&gt;通过将输入编码为更接近目标分布的潜在基础分布，随后进行流匹配生成小尺度物理细节。编码器捕捉确定性成分，流匹配则添加随机小尺度细节。&lt;h4&gt;主要发现&lt;/h4&gt;提出的随机流匹配（SFM）框架在实际CWA天气数据集和基于PDE的Kolmogorov数据集上的实验结果显示，优于现有的条件扩散和流方法。&lt;h4&gt;结论&lt;/h4&gt;SFM框架在超分辨天气变量（从25公里到2公里尺度）任务中表现卓越，显著提高了小尺度细节的模拟精度。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，成功应对了天气数据处理中小尺度细节超分辨的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conditioning diffusion and flow models have proven effective forsuper-resolving small-scale details in natural images.However, in physicalsciences such as weather, super-resolving small-scale details poses significantchallenges due to: (i) misalignment between input and output distributions(i.e., solutions to distinct partial differential equations (PDEs) followdifferent trajectories), (ii) multi-scale dynamics, deterministic dynamics atlarge scales vs. stochastic at small scales, and (iii) limited data, increasingthe risk of overfitting. To address these challenges, we propose encoding theinputs to a latent base distribution that is closer to the target distribution,followed by flow matching to generate small-scale physics. The encoder capturesthe deterministic components, while flow matching adds stochastic small-scaledetails. To account for uncertainty in the deterministic part, we inject noiseinto the encoder output using an adaptive noise scaling mechanism, which isdynamically adjusted based on maximum-likelihood estimates of the encoderpredictions. We conduct extensive experiments on both the real-world CWAweather dataset and the PDE-based Kolmogorov dataset, with the CWA taskinvolving super-resolving the weather variables for the region of Taiwan from25 km to 2 km scales. Our results show that the proposed stochastic flowmatching (SFM) framework significantly outperforms existing methods such asconditional diffusion and flows.</description>
      <author>example@mail.com (Stathi Fotiadis, Noah Brenowitz, Tomas Geffner, Yair Cohen, Michael Pritchard, Arash Vahdat, Morteza Mardani)</author>
      <guid isPermaLink="false">2410.19814v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Pedestrian crash causation analysis near bus stops: Insights from random parameters NB-Lindley models</title>
      <link>http://arxiv.org/abs/2410.22253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;公交车站附近的行人安全日益受到关注，伤害和死亡人数上升，强调了降低事故风险和鼓励城市交通中的公共交通的必要性。&lt;h4&gt;目的&lt;/h4&gt;填补现有研究中对暴露特征和公交车站设计元素对行人-车辆碰撞影响的忽视，开发数据驱动的干预措施。&lt;h4&gt;方法&lt;/h4&gt;使用随机参数负二项-林德利模型（RPNB-L）量化德克萨斯州沃斯堡市各种特征（如公交车站设计、交通、乘客活动和道路环境等）与行人-车辆碰撞之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;分析覆盖596个公交车站点，结果显示RPNB-L模型在捕捉各站点变异性方面优于传统的负二项（NB）和固定系数NB-L模型。影响行人KABCO碰撞频率的显著预测因素包括平均年度日交通量（AADT）、公交乘客上下车率、位于交叉口近侧的车站、混合用途区域以及缺乏中央分隔带、人行道或斑马线。另外，照明差、高中数量多和较低的速度限制（如35 mph）也增加了碰撞频率。&lt;h4&gt;结论&lt;/h4&gt;研究应用安全改善潜力（PSI）指标识别高风险地点，并优先考虑关键走廊进行干预。&lt;h4&gt;总结&lt;/h4&gt;本研究通过量化公交车站设计与行人安全之间的关系，为公共交通安全干预措施提供了重要数据支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pedestrian safety near bus stops is a growing concern due to rising injuriesand fatalities, underscoring the need to mitigate crash risks and encourageactive travel through public transportation in urban corridors. However,existing research has often overlooked the effects of exposure characteristicsand bus stop design elements on pedestrian-vehicle crashes, limiting thedevelopment of data-driven interventions. This study aims to fill that gap byquantifying the relationship between various features (e.g., bus stop design,traffic, and passenger activity, roadway environment, etc.) andvehicle-pedestrian crashes in Fort Worth, Texas, using the Random ParametersNegative Binomial-Lindley (RPNB-L) model to address the unobservedheterogeneity. By accounting for site-specific variability, the RPNB-L modeloffers a more nuanced understanding of the factors influencing crash frequency.The analysis covers 596 bus stop sites, integrating crash data from 2018 to2022 with roadway network and stop design characteristics. Results show thatthe RPNB-L model outperforms traditional Negative Binomial (NB) andfixed-coefficient NB-L models in capturing variability across sites.Significant predictors of higher pedestrian KABCO crash frequencies includeaverage annual daily traffic (AADT), bus passenger boarding rates, stopslocated near-side of intersections, mixed-use areas, and the absence ofmedians, sidewalks, or crosswalks. Additional factors, such as poor lighting,high school numbers, and lower speed limits (e.g., 35 mph), also increase crashfrequency. The study applies the Potential for Safety Improvement (PSI) metricto identify high-risk sites and prioritize key corridors for intervention.</description>
      <author>example@mail.com (Mohammad Anis, Srinivas R. Geedipally, Dominique Lord)</author>
      <guid isPermaLink="false">2410.22253v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>TumblerBots: Tumbling Robotic sensors for Minimally-invasive Benthic Monitoring</title>
      <link>http://arxiv.org/abs/2410.23049v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Robosoft 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人系统在水环境监测应用中具有重要潜力，包括水质监测、污染映射和生物多样性数据收集。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖框架，以减少对脆弱生态系统的干扰，并准确收集水下数据。&lt;h4&gt;方法&lt;/h4&gt;采用轻量化的翻转器系统，通过无人机部署，翻转器在水面上释放感应单元以进行非侵入性数据收集。&lt;h4&gt;主要发现&lt;/h4&gt;翻转器以0.8到2.5米每秒的低速率下降，减少了对生态系统的干扰，且在户外测试中表现出良好的抗风能力。&lt;h4&gt;结论&lt;/h4&gt;该系统在中到强风条件下表现稳健，验证了整体框架的有效性。&lt;h4&gt;总结&lt;/h4&gt;新的框架和设计理念能够在保护生态环境的同时，实现高效的水环境监测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic systems show significant promise for water environmental sensingapplications such as water quality monitoring, pollution mapping andbiodiversity data collection.  Conventional deployment methods often disrupt fragile ecosystems, preventingdepiction of the undisturbed environmental condition. In response to thischallenge, we propose a novel framework utilizing a lightweight tumbler systemequipped with a sensing unit, deployed via a drone. This design minimizesdisruption to the water habitat by maintaining a slow descent. The sensing unitis detached once on the water surface, enabling precise and non-invasive datacollection from the benthic zone.  The tumbler is designed to be lightweight and compact, enabling deploymentvia a drone. The sensing pod, which detaches from the tumbler and descends tothe bottom of the water body, is equipped with temperature and pressuresensors, as well as a buoyancy system. The later, activated upon taskcompletion, utilizes a silicon membrane inflated via a chemical reaction. Thereaction generates a pressure of 70 kPa, causing the silicon membrane to expandby 30\%, which exceeds the 5.7\% volume increase required for positivebuoyancy. The tumblers, made from ecofriendly materials to minimizeenvironmental impact when lost during the mission, were tested for theirgliding ratio and descent rate. They exhibit a low descent rate, in the rangeof 0.8 to 2.5 meters per seconds, which minimizes disturbance to the ecosystemupon water landing. Additionally, the system demonstrated robustness inmoderate to strong wind conditions during outdoor tests, validating the overallframework.</description>
      <author>example@mail.com (L. Romanello, A. Teboul, F. Wiesemuller, P. H. Nguyen, M. Kovac, S. F. Armanini)</author>
      <guid isPermaLink="false">2410.23049v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Log Heston Model for Monthly Average VIX</title>
      <link>http://arxiv.org/abs/2410.22471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures, 17 graphs. Keywords: autoregression, volatility,
  Hill estimator, variance-gamma distribution, stationary Markov chain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;我们对VIX（每月平均）和每月股指收益率的时间序列进行建模。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过模型化VIX与股指收益率的关系来提高收益率分布的独立性。&lt;h4&gt;方法&lt;/h4&gt;使用对数Heston模型，将VIX的对数建模为一阶自回归。&lt;h4&gt;主要发现&lt;/h4&gt;标准化的每月股指收益率（除以VIX）更接近独立同分布的高斯分布。&lt;h4&gt;结论&lt;/h4&gt;所得到的模型是均值回归型，创新项为非高斯分布，适用于小型和大型股指，并能捕捉真实股市收益的帕累托型尾部特性。&lt;h4&gt;总结&lt;/h4&gt;结合随机波动模型表现良好，适用于价格和总收益的分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We model time series of VIX (monthly average) and monthly stock indexreturns. We use log-Heston model: logarithm of VIX is modeled as anautoregression of order 1. Our main insight is that normalizing monthly stockindex returns (dividing them by VIX) makes them much closer to independentidentically distributed Gaussian. The resulting model is mean-reverting, andthe innovations are non-Gaussian. The combined stochastic volatility model fitswell, and captures Pareto-like tails of real-world stock market returns. Thisworks for small and large stock indices, for both price and total returns.</description>
      <author>example@mail.com (Jihyun Park, Andrey Sarantsev)</author>
      <guid isPermaLink="false">2410.22471v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Communication Characterization of AI Workloads for Large-scale Multi-chiplet Accelerators</title>
      <link>http://arxiv.org/abs/2410.22262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 Pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;下一代人工智能（AI）工作负载在执行时间方面面临可扩展性和鲁棒性的挑战，主要由于其数据密集型特性。&lt;h4&gt;目的&lt;/h4&gt;分析AI工作负载在由多个芯片组成的扩展加速器架构中，由数据传输特性引起的潜在瓶颈。&lt;h4&gt;方法&lt;/h4&gt;捕捉一组AI工作负载的单播和多播通信流量，评估通信所花费的时间和多播消息的数量，随所用芯片数量的变化。&lt;h4&gt;主要发现&lt;/h4&gt;某些AI工作负载可能受到通信，尤其是多播流量的主导影响，这可能成为性能瓶颈并限制其可扩展性。&lt;h4&gt;结论&lt;/h4&gt;工作负载分析建议在芯片级别架构灵活的互连解决方案，以提高下一代AI加速器的性能、效率和可扩展性。&lt;h4&gt;总结&lt;/h4&gt;研究强调了在设计AI加速器时考虑数据传输特性的重要性，以优化性能和扩展能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next-generation artificial intelligence (AI) workloads are posing challengesof scalability and robustness in terms of execution time due to their intrinsicevolving data-intensive characteristics. In this paper, we aim to analyse thepotential bottlenecks caused due to data movement characteristics of AIworkloads on scale-out accelerator architectures composed of multiple chiplets.Our methodology captures the unicast and multicast communication traffic of aset of AI workloads and assesses aspects such as the time spent in suchcommunications and the amount of multicast messages as a function of the numberof employed chiplets. Our studies reveal that some AI workloads are potentiallyvulnerable to the dominant effects of communication, especially multicasttraffic, which can become a performance bottleneck and limit their scalability.Workload profiling insights suggest to architect a flexible interconnectsolution at chiplet level in order to improve the performance, efficiency andscalability of next-generation AI accelerators.</description>
      <author>example@mail.com (Mariam Musavi, Emmanuel Irabor, Abhijit Das, Eduard Alarcon, Sergi Abadal)</author>
      <guid isPermaLink="false">2410.22262v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>The VIX as Stochastic Volatility for Corporate Bonds</title>
      <link>http://arxiv.org/abs/2410.22498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures, 8 graphs. Keywords: stochastic volatility,
  autoregression, kurtosis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;经典的随机波动率模型假设波动率是不可观察的。&lt;h4&gt;目的&lt;/h4&gt;将VIX视为可观察的波动率，并将其应用于企业债券市场。&lt;h4&gt;方法&lt;/h4&gt;对企业债券与10年期国债之间的利差进行时间序列模型拟合，并用VIX对残差进行除法处理。&lt;h4&gt;主要发现&lt;/h4&gt;这种除法处理使得残差更接近理想的高斯白噪声，尽管残差和VIX来自不同市场领域。&lt;h4&gt;结论&lt;/h4&gt;分析了这些模型的长期行为。&lt;h4&gt;总结&lt;/h4&gt;研究表明，将可观察的波动率引入企业债券市场可以改善模型的残差特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classic stochastic volatility models assume volatility is unobservable. Weuse the VIX for consider it observable, and use the Volatility Index: S\&amp;P 500VIX. This index was designed to measure volatility of S\&amp;P 500. We apply it toa different segment: Corporate bond markets. We fit time series models forspreads between corporate and 10-year Treasury bonds. Next, we divide residualsby VIX. Our main idea is such division makes residuals closer to the ideal caseof a Gaussian white noise. This is remarkable, since these residuals and VIXcome from separate market segments. We conclude with the analysis of long-termbehavior of these models.</description>
      <author>example@mail.com (Jihyun Park, Andrey Sarantsev)</author>
      <guid isPermaLink="false">2410.22498v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Structure Preservation Learning</title>
      <link>http://arxiv.org/abs/2410.22520v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在构建机器学习模型时，数据选择的可用性、获取成本和区分能力等因素至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过结合不同数据模态的结构，增强数据的实用性。&lt;h4&gt;方法&lt;/h4&gt;提出多模态结构保持学习（MSPL），利用一种数据模态提供的聚类结构来提升另一种模态的数据实用性。&lt;h4&gt;主要发现&lt;/h4&gt;MSPL在合成时间序列数据中揭示潜在结构，并从全基因组测序和抗菌药物抗性数据中恢复聚类。&lt;h4&gt;结论&lt;/h4&gt;MSPL能够将学习到的特征与外部结构结合，促进不同数据模态之间的协同效应。&lt;h4&gt;总结&lt;/h4&gt;MSPL是一种有效的方法，可以改善多模态数据在流行病学应用中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When selecting data to build machine learning models in practicalapplications, factors such as availability, acquisition cost, anddiscriminatory power are crucial considerations. Different data modalitiesoften capture unique aspects of the underlying phenomenon, making theirutilities complementary. On the other hand, some sources of data hoststructural information that is key to their value. Hence, the utility of onedata type can sometimes be enhanced by matching the structure of another. Wepropose Multimodal Structure Preservation Learning (MSPL) as a novel method oflearning data representations that leverages the clustering structure providedby one data modality to enhance the utility of data from another modality. Wedemonstrate the effectiveness of MSPL in uncovering latent structures insynthetic time series data and recovering clusters from whole genome sequencingand antimicrobial resistance data using mass spectrometry data in support ofepidemiology applications. The results show that MSPL can imbue the learnedfeatures with external structures and help reap the beneficial synergiesoccurring across disparate data modalities.</description>
      <author>example@mail.com (Chang Liu, Jieshi Chen, Lee H. Harrison, Artur Dubrawski)</author>
      <guid isPermaLink="false">2410.22520v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Analysis of Classifier Training on Synthetic Data for Cross-Domain Datasets</title>
      <link>http://arxiv.org/abs/2410.22748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习的主要挑战之一是需要收集大量的训练数据，缺乏足够大的数据集常常会限制其应用。&lt;h4&gt;目的&lt;/h4&gt;探讨合成数据驱动的训练在智能交通系统中的潜力，尤其是在基于摄像头的交通标志识别应用中。&lt;h4&gt;方法&lt;/h4&gt;提出一种合成数据集的增强流程，包括结构化阴影和高斯镜面高光等新颖的增强过程，并使用半监督错误引导方法生成合成图像。&lt;h4&gt;主要发现&lt;/h4&gt;在跨域测试数据集上，合成图像驱动的训练方法在大多数情况下优于真实图像训练方法，例如在GTSRB数据集上提高了10%的精度。&lt;h4&gt;结论&lt;/h4&gt;合成图像训练能够提高模型的泛化能力，降低获取图像的成本。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，合成数据结合真实数据能够有效提升深度学习模型在智能交通系统中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TITS.2020.3009186&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A major challenges of deep learning (DL) is the necessity to collect hugeamounts of training data. Often, the lack of a sufficiently large datasetdiscourages the use of DL in certain applications. Typically, acquiring therequired amounts of data costs considerable time, material and effort. Tomitigate this problem, the use of synthetic images combined with real data is apopular approach, widely adopted in the scientific community to effectivelytrain various detectors. In this study, we examined the potential of syntheticdata-based training in the field of intelligent transportation systems. Ourfocus is on camera-based traffic sign recognition applications for advanceddriver assistance systems and autonomous driving. The proposed augmentationpipeline of synthetic datasets includes novel augmentation processes such asstructured shadows and gaussian specular highlights. A well-known DL model wastrained with different datasets to compare the performance of synthetic andreal image-based trained models. Additionally, a new, detailed method toobjectively compare these models is proposed. Synthetic images are generatedusing a semi-supervised errors-guide method which is also described. Ourexperiments showed that a synthetic image-based approach outperforms in mostcases real image-based training when applied to cross-domain test datasets(+10% precision for GTSRB dataset) and consequently, the generalization of themodel is improved decreasing the cost of acquiring images.</description>
      <author>example@mail.com (Andoni Cortés, Clemente Rodríguez, Gorka Velez, Javier Barandiarán, Marcos Nieto)</author>
      <guid isPermaLink="false">2410.22748v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Inference for Relational Graph in a Causal Vector Autoregressive Time Series</title>
      <link>http://arxiv.org/abs/2410.22617v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在高维向量自回归过程（VAR）中，同时估计图结构和自相关结构是一个重要问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来同时估计因果高维VAR过程的图结构和自相关结构。&lt;h4&gt;方法&lt;/h4&gt;使用贝叶斯框架估计平稳精度矩阵，引入一种新参数化方法，便于联合估计精度矩阵和自协方差矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;该方法保持过程的因果性，并提供了一种快速计算高维高斯VAR的降秩似然的方法。&lt;h4&gt;结论&lt;/h4&gt;在新参数化下，利用稀疏先验和似然函数获得图形参数和时间参数的后验分布，并开发了高效的马尔可夫链蒙特卡洛（MCMC）算法用于后验计算。&lt;h4&gt;理论结果&lt;/h4&gt;建立了高维后验的一致性性质。&lt;h4&gt;应用效果&lt;/h4&gt;该方法在模拟和实际数据应用中表现出色。&lt;h4&gt;总结&lt;/h4&gt;提出的估计方法在理论和实践中均显示出优越性，适用于高维VAR模型的分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a method for simultaneously estimating a contemporaneous graphstructure and autocorrelation structure for a causal high-dimensional vectorautoregressive process (VAR). The graph is estimated by estimating thestationary precision matrix using a Bayesian framework. We introduce a novelparameterization that is convenient for jointly estimating the precision matrixand the autocovariance matrices. The methodology based on the newparameterization has several desirable properties. A key feature of theproposed methodology is that it maintains causality of the process in itsestimates and also provides a fast feasible way for computing the reduced ranklikelihood for a high-dimensional Gaussian VAR. We use sparse priors along withthe likelihood under the new parameterization to obtain the posterior of thegraphical parameters as well as that of the temporal parameters. An efficientMarkov Chain Monte Carlo (MCMC) algorithm is developed for posteriorcomputation. We also establish theoretical consistency properties for thehigh-dimensional posterior. The proposed methodology shows excellentperformance in simulations and real data applications.</description>
      <author>example@mail.com (Arkaprava Roy, Anindya Roy, Subhashis Ghosal)</author>
      <guid isPermaLink="false">2410.22617v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Modelling vehicle and pedestrian collective dynamics: Challenges and advancements</title>
      <link>http://arxiv.org/abs/2410.22896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在城市化社会中，交通和行人流动的管理与调节对公共安全、经济发展和环境保护具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;审视经典建模方法在集体行为中的适用性和局限性。&lt;h4&gt;方法&lt;/h4&gt;通过四个集体行为的案例进行回顾：交通流中的停走波、车道形成、长期回避行为和行人动态中的负载平衡。&lt;h4&gt;主要发现&lt;/h4&gt;停走动态和车道形成可以通过基本的反应模型处理，而后两者需要群体层面的预判和协调。&lt;h4&gt;结论&lt;/h4&gt;经典基于力的模型存在局限性，需要长远的预判机制和多尺度建模方法。&lt;h4&gt;总结&lt;/h4&gt;评估新发展和建模概念以应对交通和行人流的复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In our urbanised societies, the management and regulation of traffic andpedestrian flows is of considerable interest for public safety, economicdevelopment, and the conservation of the environment. However, modelling andcontrolling the collective dynamics of vehicles and pedestrians raises severalchallenges. Not only are the individual entities self-propelled and hard todescribe, but their complex nonlinear physical and social interactions makesthe multi-agent problem of crowd and traffic flow even more involved. In thischapter, we purport to review the suitability and limitations of classicalmodelling approaches through four examples of collective behaviour: stop-and-gowaves in traffic flow, lane formation, long-term avoidance behaviour, and loadbalancing in pedestrian dynamics. While stop-and-go dynamics and lane formationcan both be addressed by basic reactive models (at least to some extent), thelatter two require anticipation and/or coordination at the level of the group.The results highlight the limitations of classical force-based models, but alsothe need for long-term anticipation mechanisms and multiscale modellingapproaches. In response, we review new developments and modelling concepts.</description>
      <author>example@mail.com (Cécile Appert-Rolland, Alexandre Nicolas, Armin Seyfried, Antoine Tordeux, Denis Ullmo)</author>
      <guid isPermaLink="false">2410.22896v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>When Circular Economy Meets the Smart City Ecosystem: Defining the Smart and Circular City</title>
      <link>http://arxiv.org/abs/2410.22012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint submitted to the 10th IEEE International Smart Cities
  Conference 2024 (ISC2 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能城市在过去20年中成为活跃的研究领域，适应技术进步，关注可持续性和气候变化。&lt;h4&gt;目的&lt;/h4&gt;扩展智能城市的定义，将循环经济作为核心支柱，提出“智能与循环城市”的概念。&lt;h4&gt;方法&lt;/h4&gt;讨论智能与循环城市如何在可持续性和智能性方面相互融合，同时促进新商业活动和模式。&lt;h4&gt;主要发现&lt;/h4&gt;智能与循环城市有助于将公民置于智能城市的核心，推动更广泛的循环经济活动。&lt;h4&gt;结论&lt;/h4&gt;以前的智能城市和技术研究为在城市中实施循环经济活动提供了基础，超越传统方法。&lt;h4&gt;挑战&lt;/h4&gt;概述当前在这一领域的开放挑战和仍需解决的研究问题。&lt;h4&gt;总结&lt;/h4&gt;智能与循环城市的概念促进了可持续性和智能发展的结合，并为未来的研究提供了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smart cities have been a very active research area in the past 20 years,while continuously adapting to new technological advancements and keeping upwith the times regarding sustainability and climate change. In this context,there have been numerous proposals to expand the scope of smart cities,focusing on resilience and sustainability, among other aspects, resulting interms like smart sustainable cities. At the same time, there is an ongoingdiscussion regarding the degree in which smart cities put people at theircentre. In this work, we argue toward expanding the current smart citydefinition by integrating the circular economy as one of its central pillarsand adopting the term smart (and) circular city. We discuss the ways a smartand circular city encompasses both sustainability and smartness in an integralmanner, while also being well-positioned to foster novel business activity andmodels and helping to place citizens at the heart of the smart city. In thissense, we also argue that previous research in smart cities and technologies,such as those related to Industry 4.0, can serve as a cornerstone to implementcircular economy activities within cities, at a scale that exceeds currentactivities that are based on more conventional approaches. We also outlinecurrent open challenges in this domain and research questions that still needto be addressed.</description>
      <author>example@mail.com (Georgios Mylonas, Athanasios Kalogeras, Sobah Abbas Petersen, Luis Muñoz, Ioannis Chatzigiannakis)</author>
      <guid isPermaLink="false">2410.22012v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Leader-Follower 3D Formation for Underwater Robots</title>
      <link>http://arxiv.org/abs/2410.23128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at DARS 2024 (The 17th International Symposium on
  Distributed Autonomous Robotic Systems)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;鱼群的行为被假设为能带来多种生存优势，包括觅食成功、躲避掠食者的安全性，以及通过水动力相互作用节省能量。&lt;h4&gt;目的&lt;/h4&gt;探讨水下机器人集体如何通过形成控制实现类似的生存优势，特别是在环境监测中的有效空间采样。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于领导者-跟随者策略的水下形成控制方法，仅依靠视觉感知和低计算量的反应控制算法，实现复杂的3D队形。&lt;h4&gt;主要发现&lt;/h4&gt;首次通过物理平台BlueSwarm成功演示了直线、并排和错列游泳的3D队形，同时在物理基础模拟器中研究了更复杂的队形，提供了关于水下惯性/阻力条件下队形收敛性和稳定性的新的见解。&lt;h4&gt;结论&lt;/h4&gt;研究为未来水下机器人群体在水域环境中进行最小通信的应用奠定了基础。&lt;h4&gt;总结&lt;/h4&gt;通过水下机器人集体的形成控制，能够有效模拟鱼群行为，以提高环境监测的效率和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The schooling behavior of fish is hypothesized to confer many survivalbenefits, including foraging success, safety from predators, and energy savingsthrough hydrodynamic interactions when swimming in formation. Underwater robotcollectives may be able to achieve similar benefits in future applications,e.g. using formation control to achieve efficient spatial sampling forenvironmental monitoring. Although many theoretical algorithms exist formulti-robot formation control, they have not been tested in the underwaterdomain due to the fundamental challenges in underwater communication. Here weintroduce a leader-follower strategy for underwater formation control thatallows us to realize complex 3D formations, using purely vision-basedperception and a reactive control algorithm that is low computation. We use aphysical platform, BlueSwarm, to demonstrate for the first time an experimentalrealization of inline, side-by-side, and staggered swimming 3D formations. Morecomplex formations are studied in a physics-based simulator, providing newinsights into the convergence and stability of formations given underwaterinertial/drag conditions. Our findings lay the groundwork for futureapplications of underwater robot swarms in aquatic environments with minimalcommunication.</description>
      <author>example@mail.com (Di Ni, Hungtang Ko, Radhika Nagpal)</author>
      <guid isPermaLink="false">2410.23128v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>WaveRoRA: Wavelet Rotary Route Attention for Multivariate Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.22649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is coming soon! For sure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，基于Transformer的模型在多变量时间序列预测中取得了显著成功，但以往的研究主要集中在时间域或频率域提取特征，无法充分捕捉趋势和周期特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种小波学习框架，以建模时间序列数据的复杂时间依赖性。&lt;h4&gt;方法&lt;/h4&gt;小波域集成时间和频率信息，分析信号在不同尺度上的局部特征。同时，提出了一种新颖的注意力机制：旋转路由注意力（RoRA），具有线性复杂度，解决了传统Softmax注意力的高计算成本问题。&lt;h4&gt;主要发现&lt;/h4&gt;WaveRoRA在小波域中捕捉时间序列间的依赖性，并在八个真实世界数据集上进行了广泛实验，结果表明其在性能上优于现有的最先进模型，同时保持了较低的计算成本。&lt;h4&gt;结论&lt;/h4&gt;WaveRoRA模型有效地解决了多变量时间序列预测中的长期依赖性问题，展现出更好的性能和效率。&lt;h4&gt;总结&lt;/h4&gt;该研究提出的新方法在多变量时间序列预测中显示出优越性，为未来的研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Transformer-based models (Transformers) have achievedsignificant success in multivariate time series forecasting (MTSF). However,previous works focus on extracting features either from the time domain or thefrequency domain, which inadequately captures the trends and periodiccharacteristics. To address this issue, we propose a wavelet learning frameworkto model complex temporal dependencies of the time series data. The waveletdomain integrates both time and frequency information, allowing for theanalysis of local characteristics of signals at different scales. Additionally,the Softmax self-attention mechanism used by Transformers has quadraticcomplexity, which leads to excessive computational costs when capturinglong-term dependencies. Therefore, we propose a novel attention mechanism:Rotary Route Attention (RoRA). Unlike Softmax attention, RoRA utilizes rotaryposition embeddings to inject relative positional information to sequencetokens and introduces a small number of routing tokens $r$ to aggregateinformation from the $KV$ matrices and redistribute it to the $Q$ matrix,offering linear complexity. We further propose WaveRoRA, which leverages RoRAto capture inter-series dependencies in the wavelet domain. We conductextensive experiments on eight real-world datasets. The results indicate thatWaveRoRA outperforms existing state-of-the-art models while maintaining lowercomputational costs.</description>
      <author>example@mail.com (Aobo Liang, Yan Sun)</author>
      <guid isPermaLink="false">2410.22649v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Resilient-By-Design: A Resiliency Framework for Future Wireless Networks</title>
      <link>http://arxiv.org/abs/2410.23203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Communications Magazine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;未来社会将越来越数字化、超连接和全球数据驱动，6G及后续无线网络预计将连接数字世界与物理世界。&lt;h4&gt;目的&lt;/h4&gt;为了给不同行业（如工业、智慧城市、电子健康和自主交通）提供无线连接作为服务，增强社会对无线网络的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出一个以韧性为设计理念的框架，概述干扰环境，详细阐述主要特征，并描述预测、预防、保护和进步四个关键步骤。&lt;h4&gt;主要发现&lt;/h4&gt;通过初步的模拟结果展示了该框架在应对网络中断时的潜在优势和效率。&lt;h4&gt;结论&lt;/h4&gt;6G及后续网络不仅要提供近乎即时和几乎无限的连接，还要具备抵御内部和外部干扰的能力。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种综合的方法来应对未来无线网络的挑战，确保其在各种干扰情况下的韧性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Our future society will be increasingly digitalised, hyper-connected andglobally data driven. The sixth generation (6G) and beyond 6G wireless networksare expected to bridge the digital and physical worlds by providing wirelessconnectivity as a service to different vertical sectors, including industries,smart cities, eHealth and autonomous transportation. Such far reachingintegration will render the society increasingly reliant on wireless networks.While this has the potential to greatly enhance our quality and ease of life,any disruption to these networks would also have significant impact withoverreaching consequences. Disruptions can happen due to a variety of reasons,including planned outages, failures due to the nature of wireless propagation,natural disasters, and deliberate cybersecurity attacks. Hence, 6G and beyond6G networks should not only provide near instant and virtually unlimitedconnectivity, but also be resilient against internal and external disruptions.This paper proposes a resilient-by-design framework towards this end. First, weprovide an overview of the disruption landscape. Thereafter, we comprehensivelyoutline the main features of the proposed concept. Finally, we detail the fourkey steps of the framework, namely predict, preempt, protect and progress. Asimple but illustrative preliminary simulation result is also presented tohighlight the potential advantages and efficiency of the proposed approach inaddressing outages.</description>
      <author>example@mail.com (Nurul Huda Mahmood, Sumudu Samarakoon, Pawani Porambage, Mehdi Bennis, Matti Latva-aho)</author>
      <guid isPermaLink="false">2410.23203v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>YOLOv11 for Vehicle Detection: Advancements, Performance, and Applications in Intelligent Transportation Systems</title>
      <link>http://arxiv.org/abs/2410.22898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的车辆检测对于智能交通系统、自动驾驶和交通监测的发展至关重要。&lt;h4&gt;目的&lt;/h4&gt;分析YOLO11在车辆检测任务中的最新进展。&lt;h4&gt;方法&lt;/h4&gt;基于多种车辆类型的综合数据集，评估YOLO11的表现，使用精度、召回率、F1分数和平均平均精度（mAP）等指标。&lt;h4&gt;主要发现&lt;/h4&gt;YOLO11在检测较小和被遮挡车辆方面超越了YOLOv8和YOLOv10，同时保持竞争力的推理时间。&lt;h4&gt;结论&lt;/h4&gt;YOLO11在复杂环境中展示了更高的检测速度、准确性和鲁棒性，适合实时应用。&lt;h4&gt;应用价值&lt;/h4&gt;YOLO11有潜力提升自动驾驶性能和交通监测系统，提供未来发展的思路。&lt;h4&gt;总结&lt;/h4&gt;YOLO11的架构改进进一步推动了高效、可扩展的车辆检测系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate vehicle detection is essential for the development of intelligenttransportation systems, autonomous driving, and traffic monitoring. This paperpresents a detailed analysis of YOLO11, the latest advancement in the YOLOseries of deep learning models, focusing exclusively on vehicle detectiontasks. Building upon the success of its predecessors, YOLO11 introducesarchitectural improvements designed to enhance detection speed, accuracy, androbustness in complex environments. Using a comprehensive dataset comprisingmultiple vehicle types-cars, trucks, buses, motorcycles, and bicycles weevaluate YOLO11's performance using metrics such as precision, recall, F1score, and mean average precision (mAP). Our findings demonstrate that YOLO11surpasses previous versions (YOLOv8 and YOLOv10) in detecting smaller and moreoccluded vehicles while maintaining a competitive inference time, making itwell-suited for real-time applications. Comparative analysis shows significantimprovements in the detection of complex vehicle geometries, furthercontributing to the development of efficient and scalable vehicle detectionsystems. This research highlights YOLO11's potential to enhance autonomousvehicle performance and traffic monitoring systems, offering insights forfuture developments in the field.</description>
      <author>example@mail.com (Mujadded Al Rabbani Alif)</author>
      <guid isPermaLink="false">2410.22898v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Robust and Efficient Visual-Inertial Initialization with Probabilistic Normal Epipolar Constraint</title>
      <link>http://arxiv.org/abs/2410.19473v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确且稳健的初始化对于视觉惯性里程计（VIO）至关重要，差的初始化会严重影响位姿精度。&lt;h4&gt;目的&lt;/h4&gt;估计加速度计偏置、陀螺仪偏置、初始速度和重力等参数。&lt;h4&gt;方法&lt;/h4&gt;扩展旋转-位移-解耦框架，加入新的不确定性参数和优化模块；采用概率正常极线约束的陀螺仪偏置优化器；融合IMU和视觉测量以高效求解速度、重力和尺度；设计附加的精细化模块以减少重力和尺度误差。&lt;h4&gt;主要发现&lt;/h4&gt;在EuRoC数据集上进行的广泛初始化测试表明，该方法将陀螺仪偏置和旋转估计误差平均减少了16%和4%；重力误差平均减少了29%。&lt;h4&gt;结论&lt;/h4&gt;该方法显著提高了VIO的初始化精度，尤其是在快速运动或退化场景下。&lt;h4&gt;总结&lt;/h4&gt;通过改进的初始化方法，显著提升了视觉惯性里程计的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and robust initialization is essential for Visual-Inertial Odometry(VIO), as poor initialization can severely degrade pose accuracy. Duringinitialization, it is crucial to estimate parameters such as accelerometerbias, gyroscope bias, initial velocity, and gravity, etc. The IMU sensorrequires precise estimation of gyroscope bias because gyroscope bias affectsrotation, velocity and position. Most existing VIO initialization methods adoptStructure from Motion (SfM) to solve for gyroscope bias. However, SfM is notstable and efficient enough in fast motion or degenerate scenes. To overcomethese limitations, we extended the rotation-translation-decoupling framework byadding new uncertainty parameters and optimization modules. First, we adopt agyroscope bias optimizer that incorporates probabilistic normal epipolarconstraints. Second, we fuse IMU and visual measurements to solve for velocity,gravity, and scale efficiently. Finally, we design an additional refinementmodule that effectively diminishes gravity and scale errors. Extensiveinitialization tests on the EuRoC dataset show that our method reduces thegyroscope bias and rotation estimation error by an average of 16% and 4%respectively. It also significantly reduces the gravity error, with an averagereduction of 29%.</description>
      <author>example@mail.com (Changshi Mu, Daquan Feng, Qi Zheng, Yuan Zhuang)</author>
      <guid isPermaLink="false">2410.19473v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Persistent Homology for MCI Classification: A Comparative Analysis between Graph and Vietoris-Rips Filtrations</title>
      <link>http://arxiv.org/abs/2410.22681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;轻度认知障碍（MCI）通常与早期神经退行性变有关，表现为细微的认知下降和大脑连接性中断。&lt;h4&gt;目的&lt;/h4&gt;分析与MCI相关的拓扑变化，重点研究早期MCI和晚期MCI两种亚型。&lt;h4&gt;方法&lt;/h4&gt;使用来自两个人群的fMRI时间序列数据，分别为公开的ADNI数据集（西方队列）和内部TLSA数据集（印度城市队列）。采用持久同调这一拓扑数据分析方法，使用Vietoris-Rips和图过滤两种不同的过滤技术进行MCI亚型分类。&lt;h4&gt;主要发现&lt;/h4&gt;Vietoris-Rips过滤方法在捕捉大脑连接性微小变化方面显著优于图过滤，分类准确率为85.7%，而图过滤的最高准确率为71.4%。&lt;h4&gt;结论&lt;/h4&gt;持久同调方法，特别是结合Wasserstein距离，显示出在早期诊断和精确分类认知障碍方面的潜力，为MCI的大脑连接性变化提供了重要见解。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了Vietoris-Rips过滤在检测与神经退行性变相关的复杂拓扑特征方面的敏感性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mild cognitive impairment (MCI), often linked to early neurodegeneration, ischaracterized by subtle cognitive declines and disruptions in brainconnectivity. The present study offers a detailed analysis of topologicalchanges associated with MCI, focusing on two subtypes: Early MCI and Late MCI.This analysis utilizes fMRI time series data from two distinct populations: thepublicly available ADNI dataset (Western cohort) and the in-house TLSA dataset(Indian Urban cohort). Persistent Homology, a topological data analysis method,is employed with two distinct filtration techniques - Vietoris-Rips and graphfiltration-for classifying MCI subtypes. For Vietoris-Rips filtration,inter-ROI Wasserstein distance matrices between persistent diagrams are usedfor classification, while graph filtration relies on the top ten mostpersistent homology features. Comparative analysis shows that the Vietoris-Ripsfiltration significantly outperforms graph filtration, capturing subtlevariations in brain connectivity with greater accuracy. The Vietoris-Ripsfiltration method achieved the highest classification accuracy of 85.7\% fordistinguishing between age and gender matched healthy controls and MCI, whereasgraph filtration reached a maximum accuracy of 71.4\% for the same task. Thissuperior performance highlights the sensitivity of Vietoris-Rips filtration indetecting intricate topological features associated with neurodegeneration. Thefindings underscore the potential of persistent homology, particularly whencombined with the Wasserstein distance, as a powerful tool for early diagnosisand precise classification of cognitive impairments, offering valuable insightsinto brain connectivity changes in MCI.</description>
      <author>example@mail.com (Debanjali Bhattacharya, Rajneet Kaur, Ninad Aithal, Neelam Sinha, Thomas Gregor Issac)</author>
      <guid isPermaLink="false">2410.22681v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning</title>
      <link>http://arxiv.org/abs/2410.23156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;广泛智能体应形成任务特定的抽象，选择性地暴露任务的基本元素，同时抽象掉原始传感器运动空间的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合符号和神经知识表示优势的首次抽象语言——神经符号谓词。&lt;h4&gt;方法&lt;/h4&gt;概述了一种在线算法，用于发明这些谓词并学习抽象世界模型。&lt;h4&gt;主要发现&lt;/h4&gt;与层次强化学习、视觉-语言模型规划和符号谓词发明方法相比，本方法在五个模拟机器人领域的任务中表现出更好的样本复杂度、更强的跨分布泛化能力和更好的可解释性。&lt;h4&gt;结论&lt;/h4&gt;我们的研究表明，神经符号谓词方法在多个方面优于现有技术。&lt;h4&gt;总结&lt;/h4&gt;该研究为智能体的任务抽象提供了新的视角和方法，有助于提升其在复杂环境中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Broadly intelligent agents should form task-specific abstractions thatselectively expose the essential elements of a task, while abstracting away thecomplexity of the raw sensorimotor space. In this work, we presentNeuro-Symbolic Predicates, a first-order abstraction language that combines thestrengths of symbolic and neural knowledge representations. We outline anonline algorithm for inventing such predicates and learning abstract worldmodels. We compare our approach to hierarchical reinforcement learning,vision-language model planning, and symbolic predicate invention approaches, onboth in- and out-of-distribution tasks across five simulated robotic domains.Results show that our approach offers better sample complexity, strongerout-of-distribution generalization, and improved interpretability.</description>
      <author>example@mail.com (Yichao Liang, Nishanth Kumar, Hao Tang, Adrian Weller, Joshua B. Tenenbaum, Tom Silver, João F. Henriques, Kevin Ellis)</author>
      <guid isPermaLink="false">2410.23156v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Context-Based Visual-Language Place Recognition</title>
      <link>http://arxiv.org/abs/2410.19341v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉基础的机器人定位和SLAM中，视觉地点识别（VPR）至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决给定查询图像对应位置的准确识别问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的VPR方法，通过零样本、语言驱动的语义分割模型提取像素级嵌入，构建语义图像描述符，无需额外训练。&lt;h4&gt;主要发现&lt;/h4&gt;在挑战性地点识别场景中，所提出的方法优于非学习的图像表示技术和现成的卷积神经网络（CNN）描述符。&lt;h4&gt;结论&lt;/h4&gt;该方法在场景变化中保持稳健性，且不需要大量标记数据进行训练。&lt;h4&gt;代码链接&lt;/h4&gt;我们的代码可在 https://github.com/woo-soojin/context-based-vlpr 获取。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，能够有效应对视觉地点识别中的外观变化问题，提升了识别准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/woo-soojin/context-based-vlpr&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In vision-based robot localization and SLAM, Visual Place Recognition (VPR)is essential. This paper addresses the problem of VPR, which involvesaccurately recognizing the location corresponding to a given query image. Apopular approach to vision-based place recognition relies on low-level visualfeatures. Despite significant progress in recent years, place recognition basedon low-level visual features is challenging when there are changes in sceneappearance. To address this, end-to-end training approaches have been proposedto overcome the limitations of hand-crafted features. However, these approachesstill fail under drastic changes and require large amounts of labeled data totrain models, presenting a significant limitation. Methods that leveragehigh-level semantic information, such as objects or categories, have beenproposed to handle variations in appearance. In this paper, we introduce anovel VPR approach that remains robust to scene changes and does not requireadditional training. Our method constructs semantic image descriptors byextracting pixel-level embeddings using a zero-shot, language-driven semanticsegmentation model. We validate our approach in challenging place recognitionscenarios using real-world public dataset. The experiments demonstrate that ourmethod outperforms non-learned image representation techniques andoff-the-shelf convolutional neural network (CNN) descriptors. Our code isavailable at https: //github.com/woo-soojin/context-based-vlpr.</description>
      <author>example@mail.com (Soojin Woo, Seong-Woo Kim)</author>
      <guid isPermaLink="false">2410.19341v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data</title>
      <link>http://arxiv.org/abs/2410.22938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;强化学习在交通信号控制（TSC）中的应用已被广泛研究，取得了显著成就。然而，大多数现有研究假设所有周边交叉口的交通数据通过传感器完全持续可用。&lt;h4&gt;目的&lt;/h4&gt;针对现实应用中由于传感器故障或数据丢失导致的交通信号控制中的数据缺失问题，提出DiffLight模型。&lt;h4&gt;方法&lt;/h4&gt;引入条件扩散模型DiffLight，结合交通数据插补和决策制定，采用部分奖励条件扩散（PRCD）模型来防止缺失奖励干扰学习过程，同时设计空间-时间变换器（STFormer）架构以捕捉交叉口间的空间-时间依赖性，并提出扩散通信机制（DCM）以提升在数据缺失情境下的通信与控制性能。&lt;h4&gt;主要发现&lt;/h4&gt;在五个不同数据缺失情境下的广泛实验表明，DiffLight有效地解决了缺失数据下的交通信号控制问题。&lt;h4&gt;结论&lt;/h4&gt;DiffLight是一种有效的控制器，能够应对交通信号控制中的数据缺失挑战，其代码已在GitHub上发布。&lt;h4&gt;总结&lt;/h4&gt;DiffLight模型通过创新的方法应对交通信号控制中的数据缺失问题，显示出其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lokol5579/DiffLight-release&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The application of reinforcement learning in traffic signal control (TSC) hasbeen extensively researched and yielded notable achievements. However, mostexisting works for TSC assume that traffic data from all surroundingintersections is fully and continuously available through sensors. Inreal-world applications, this assumption often fails due to sensor malfunctionsor data loss, making TSC with missing data a critical challenge. To meet theneeds of practical applications, we introduce DiffLight, a novel conditionaldiffusion model for TSC under data-missing scenarios in the offline setting.Specifically, we integrate two essential sub-tasks, i.e., traffic dataimputation and decision-making, by leveraging a Partial Rewards ConditionedDiffusion (PRCD) model to prevent missing rewards from interfering with thelearning process. Meanwhile, to effectively capture the spatial-temporaldependencies among intersections, we design a Spatial-Temporal transFormer(STFormer) architecture. In addition, we propose a Diffusion CommunicationMechanism (DCM) to promote better communication and control performance underdata-missing scenarios. Extensive experiments on five datasets with variousdata-missing scenarios demonstrate that DiffLight is an effective controller toaddress TSC with missing data. The code of DiffLight is released athttps://github.com/lokol5579/DiffLight-release.</description>
      <author>example@mail.com (Hanyang Chen, Yang Jiang, Shengnan Guo, Xiaowei Mao, Youfang Lin, Huaiyu Wan)</author>
      <guid isPermaLink="false">2410.22938v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Community search signatures as foundation features for human-centered geospatial modeling</title>
      <link>http://arxiv.org/abs/2410.22721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures, presented at the DMLR workshop at ICML 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;聚合的相对搜索频率提供了反映人们习惯、关注点、兴趣、意图和一般信息需求的独特信号，这些信号在其他现成数据集中无法找到。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，以生成聚合和匿名的搜索兴趣表示，作为社区级别地理空间建模的基础特征。&lt;h4&gt;方法&lt;/h4&gt;使用跨多个领域的空间数据集对这些特征进行基准测试，并在覆盖95%以上美国大陆人口的邮政编码中进行建模。&lt;h4&gt;主要发现&lt;/h4&gt;在3000人以上的邮政编码中，针对20%保留县的缺失值预测模型在21个健康变量上平均$R^2$得分为0.74，在6个人口和环境变量上为0.80。&lt;h4&gt;结论&lt;/h4&gt;这些搜索特征可以用于空间预测而无需严格的时间对齐，且所得到的模型优于空间插值和使用卫星图像特征的先进方法。&lt;h4&gt;总结&lt;/h4&gt;研究表明，聚合搜索数据在地理空间建模中具有重要应用潜力，能够提升预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Aggregated relative search frequencies offer a unique composite signalreflecting people's habits, concerns, interests, intents, and generalinformation needs, which are not found in other readily available datasets.Temporal search trends have been successfully used in time series modelingacross a variety of domains such as infectious diseases, unemployment rates,and retail sales. However, most existing applications require curatingspecialized datasets of individual keywords, queries, or query clusters, andthe search data need to be temporally aligned with the outcome variable ofinterest. We propose a novel approach for generating an aggregated andanonymized representation of search interest as foundation features at thecommunity level for geospatial modeling. We benchmark these features usingspatial datasets across multiple domains. In zip codes with a populationgreater than 3000 that cover over 95% of the contiguous US population, ourmodels for predicting missing values in a 20% set of holdout counties achievean average $R^2$ score of 0.74 across 21 health variables, and 0.80 across 6demographic and environmental variables. Our results demonstrate that thesesearch features can be used for spatial predictions without strict temporalalignment, and that the resulting models outperform spatial interpolation andstate of the art methods using satellite imagery features.</description>
      <author>example@mail.com (Mimi Sun, Chaitanya Kamath, Mohit Agarwal, Arbaaz Muslim, Hector Yee, David Schottlander, Shailesh Bavadekar, Niv Efron, Shravya Shetty, Gautam Prasad)</author>
      <guid isPermaLink="false">2410.22721v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>V2X-Assisted Distributed Computing and Control Framework for Connected and Automated Vehicles under Ramp Merging Scenario</title>
      <link>http://arxiv.org/abs/2410.22987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been submitted to IEEE Journal. The source code has
  been released at:
  https://github.com/qiongwu86/V2X-Assisted-Distributed-Computing-and-Control-Framework-for-Connected-and-Automated-Vehicles.git&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究连接与自动化车辆（CAVs）在匝道合并场景下的分布式计算与协作控制。&lt;h4&gt;目的&lt;/h4&gt;制定集中式协作轨迹规划问题，优化车辆轨迹以满足安全约束和交通性能。&lt;h4&gt;方法&lt;/h4&gt;提出通过车联网（V2X）通信实现的分布式解决方案，减少对中央控制器的依赖并降低计算时间。&lt;h4&gt;主要发现&lt;/h4&gt;提出的分布式合作迭代模型预测控制（DCIMPC）方法能有效分解高维、集中且非凸的问题，利用车辆的计算资源快速求解。&lt;h4&gt;结论&lt;/h4&gt;该框架在收敛性、安全性和求解速度方面表现良好，DCIMPC显著提高了计算速度而不损害系统性能。&lt;h4&gt;总结&lt;/h4&gt;本研究为V2X辅助的分布式计算与控制提供了系统框架，验证了其有效性和优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/qiongwu86/v2x-assisted-distributed-computing-and-control-framework-for-connected-and-automated-vehicles&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates distributed computing and cooperative control ofconnected and automated vehicles (CAVs) in ramp merging scenario undertransportation cyber-physical system. Firstly, a centralized cooperativetrajectory planning problem is formulated subject to the safely constraints andtraffic performance in ramp merging scenario, where the trajectories of allvehicles are jointly optimized. To get rid of the reliance on a centralcontroller and reduce computation time, a distributed solution to this problemimplemented among CAVs through Vehicles-to-Everything (V2X) communication isproposed. Unlike existing method, our method can distribute the computationaltask among CAVs and carry out parallel solving through V2X communication. Then,a multi-vehicles model predictive control (MPC) problem aimed at maximizingsystem stability and minimizing control input is formulated based on thesolution of the first problem subject to strict safety constants and inputlimits. Due to these complex constraints, this problem becomeshigh-dimensional, centralized, and non-convex. To solve it in a short time, adecomposition and convex reformulation method, namely distributed cooperativeiterative model predictive control (DCIMPC), is proposed. This method leveragesthe communication capability of CAVs to decompose the problem, making full useof the computational resources on vehicles to achieve fast solutions anddistributed control. The two above problems with their corresponding solvingmethods form the systemic framework of the V2X assisted distributed computingand control. Simulations have been conducted to evaluate the framework'sconvergence, safety, and solving speed. Additionally, extra experiments areconducted to validate the performance of DCIMPC. The results show that ourmethod can greatly improve computation speed without sacrificing systemperformance.</description>
      <author>example@mail.com (Qiong Wu, Jiahou Chu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief)</author>
      <guid isPermaLink="false">2410.22987v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>RopeTP: Global Human Motion Recovery via Integrating Robust Pose Estimation with Diffusion Trajectory Prior</title>
      <link>http://arxiv.org/abs/2410.20358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WACV 2025 (Round 1)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了RopeTP框架，结合了稳健的姿态估计和扩散轨迹先验，用于从视频中重建全球人类运动。&lt;h4&gt;目的&lt;/h4&gt;重建精确、稳定的全球人类运动轨迹，特别是在遮挡情况下。&lt;h4&gt;方法&lt;/h4&gt;采用分层注意机制，提高上下文感知，利用可见解剖结构的关系改善局部姿态估计的准确性，并通过扩散轨迹模型从局部姿态序列预测现实的人类运动。&lt;h4&gt;主要发现&lt;/h4&gt;RopeTP在两个基准数据集上超越了现有方法，尤其在遮挡场景中表现优异，且比依赖SLAM的初始相机估计和优化的方法更准确。&lt;h4&gt;结论&lt;/h4&gt;RopeTP提供了更准确和现实的轨迹重建，确保生成的轨迹与观察到的局部动作一致，并自然展开。&lt;h4&gt;总结&lt;/h4&gt;RopeTP是一个新颖的框架，通过改进局部姿态估计和引入扩散模型，实现了高效的3D人类运动重建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present RopeTP, a novel framework that combines Robust pose estimationwith a diffusion Trajectory Prior to reconstruct global human motion fromvideos. At the heart of RopeTP is a hierarchical attention mechanism thatsignificantly improves context awareness, which is essential for accuratelyinferring the posture of occluded body parts. This is achieved by exploitingthe relationships with visible anatomical structures, enhancing the accuracy oflocal pose estimations. The improved robustness of these local estimationsallows for the reconstruction of precise and stable global trajectories.Additionally, RopeTP incorporates a diffusion trajectory model that predictsrealistic human motion from local pose sequences. This model ensures that thegenerated trajectories are not only consistent with observed local actions butalso unfold naturally over time, thereby improving the realism and stability of3D human motion reconstruction. Extensive experimental validation shows thatRopeTP surpasses current methods on two benchmark datasets, particularlyexcelling in scenarios with occlusions. It also outperforms methods that relyon SLAM for initial camera estimates and extensive optimization, deliveringmore accurate and realistic trajectories.</description>
      <author>example@mail.com (Mingjiang Liang, Yongkang Cheng, Hualin Liang, Shaoli Huang, Wei Liu)</author>
      <guid isPermaLink="false">2410.20358v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks</title>
      <link>http://arxiv.org/abs/2410.23208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two authors contributed equally. Project page located at:
  https://kinetix-env.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型模型在离线数据集上通过自监督学习取得了出色的文本和图像处理能力，但在顺序决策问题中的应用仍然是一个开放性挑战。&lt;h4&gt;目的&lt;/h4&gt;通过生成大量基于物理的2D任务，训练一个通用的强化学习（RL）代理，以提高其在物理控制方面的能力。&lt;h4&gt;方法&lt;/h4&gt;引入Kinetix，一个开放的物理基础RL环境空间，涵盖从机器人运动和抓取到视频游戏和经典RL环境的任务，并使用新型硬件加速物理引擎Jax2D进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;训练后的代理展现出强大的物理推理能力，能够零-shot解决未见过的人类设计的环境。对感兴趣任务进行微调的代理性能显著优于从头开始训练的RL代理。&lt;h4&gt;结论&lt;/h4&gt;这一研究表明大规模、混合质量的预训练对于在线RL是可行的，Kinetix有望成为进一步研究的有用框架。&lt;h4&gt;总结&lt;/h4&gt;Kinetix为物理控制的强化学习提供了新的训练环境，展示了在复杂任务中提升代理能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While large models trained with self-supervised learning on offline datasetshave shown remarkable capabilities in text and image domains, achieving thesame generalisation for agents that act in sequential decision problems remainsan open challenge. In this work, we take a step towards this goal byprocedurally generating tens of millions of 2D physics-based tasks and usingthese to train a general reinforcement learning (RL) agent for physicalcontrol. To this end, we introduce Kinetix: an open-ended space ofphysics-based RL environments that can represent tasks ranging from roboticlocomotion and grasping to video games and classic RL environments, all withina unified framework. Kinetix makes use of our novel hardware-acceleratedphysics engine Jax2D that allows us to cheaply simulate billions of environmentsteps during training. Our trained agent exhibits strong physical reasoningcapabilities, being able to zero-shot solve unseen human-designed environments.Furthermore, fine-tuning this general agent on tasks of interest showssignificantly stronger performance than training an RL agent *tabula rasa*.This includes solving some environments that standard RL training completelyfails at. We believe this demonstrates the feasibility of large scale,mixed-quality pre-training for online RL and we hope that Kinetix will serve asa useful framework to investigate this further.</description>
      <author>example@mail.com (Michael Matthews, Michael Beukman, Chris Lu, Jakob Foerster)</author>
      <guid isPermaLink="false">2410.23208v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Cascade Approach for APT Campaign Attribution in System Event Logs: Technique Hunting and Subgraph Matching</title>
      <link>http://arxiv.org/abs/2410.22602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着高级持续性威胁（APTs）日益复杂，对有效检测方法的需求不断增加。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过系统事件日志识别APT攻击活动。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为SFM的级联方法，结合了技术猎捕和APT活动归属。&lt;h4&gt;主要发现&lt;/h4&gt;在五个真实APT活动的评估中，所提方法表现出可靠的性能。&lt;h4&gt;结论&lt;/h4&gt;通过将检测到的技术与已知攻击序列对齐，可以更准确地确定最可能的APT活动。&lt;h4&gt;总结&lt;/h4&gt;本研究为识别APT攻击提供了一种有效的检测方法，具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As Advanced Persistent Threats (APTs) grow increasingly sophisticated, thedemand for effective detection methods has intensified. This study addressesthe challenge of identifying APT campaign attacks through system event logs. Acascading approach, name SFM, combines Technique hunting and APT campaignattribution. Our approach assumes that real-world system event logs contain avast majority of normal events interspersed with few suspiciously maliciousones and that these logs are annotated with Techniques of MITRE ATT&amp;CKframework for attack pattern recognition. Then, we attribute APT campaignattacks by aligning detected Techniques with known attack sequences todetermine the most likely APT campaign. Evaluations on five real-world APTcampaigns indicate that the proposed approach demonstrates reliableperformance.</description>
      <author>example@mail.com (Yi-Ting Huang, Ying-Ren Guo, Guo-Wei Wong, Meng Chang Chen)</author>
      <guid isPermaLink="false">2410.22602v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MIXAD: Memory-Induced Explainable Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2410.22735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICPR 2024 (oral paper)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代工业应用中，准确检测和诊断多变量时间序列数据中的异常至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种可解释的异常检测模型，弥补现有方法在解释性与检测性能之间的短板。&lt;h4&gt;方法&lt;/h4&gt;MIXAD（基于记忆的可解释时间序列异常检测）结合记忆网络和时空处理单元，理解传感器关系中的复杂动态和拓扑结构。&lt;h4&gt;主要发现&lt;/h4&gt;提出的新异常评分方法能够检测到记忆激活模式中的显著变化，并在可解释性指标上超越现有最佳基准34.30%和34.51%。&lt;h4&gt;结论&lt;/h4&gt;MIXAD不仅确保了良好的检测性能，同时提升了模型的可解释性。&lt;h4&gt;总结&lt;/h4&gt;MIXAD为多变量时间序列数据的异常检测提供了一种有效且可解释的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For modern industrial applications, accurately detecting and diagnosinganomalies in multivariate time series data is essential. Despite such need,most state-of-the-art methods often prioritize detection performance over modelinterpretability. Addressing this gap, we introduce MIXAD (Memory-InducedExplainable Time Series Anomaly Detection), a model designed for interpretableanomaly detection. MIXAD leverages a memory network alongside spatiotemporalprocessing units to understand the intricate dynamics and topologicalstructures inherent in sensor relationships. We also introduce a novel anomalyscoring method that detects significant shifts in memory activation patternsduring anomalies. Our approach not only ensures decent detection performancebut also outperforms state-of-the-art baselines by 34.30% and 34.51% ininterpretability metrics.</description>
      <author>example@mail.com (Minha Kim, Kishor Kumar Bhaumik, Amin Ahsan Ali, Simon S. Woo)</author>
      <guid isPermaLink="false">2410.22735v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Levels of explanation -- implementation and evaluation of what and when for different time-sensitive tasks</title>
      <link>http://arxiv.org/abs/2410.23215v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究集中于人机交互中的解释级别构建与评估。&lt;h4&gt;目的&lt;/h4&gt;确定机器人应向用户传达何种信息，以及何时传达这些信息。&lt;h4&gt;方法&lt;/h4&gt;定义了两个术语：详细程度（高、低）和解释模式（动态、静态），并基于这些参数构建了三种不同的解释级别（高、中、低），在用户研究中进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;在没有时间限制的条件下，高解释级别在解释充分性、碰撞数、错误移动数和澄清次数上表现最佳。高和中解释级别在完成时间、流畅性和对机器人的信任上没有显著差异。在有时间限制的条件下，高和中解释级别的任务表现更好，并在多个指标上优于低解释级别。&lt;h4&gt;结论&lt;/h4&gt;高和中解释级别在时间敏感的任务中更受欢迎，未来将讨论提升解释级别的方向。&lt;h4&gt;总结&lt;/h4&gt;研究表明，解释级别的构建与评估对提高人机交互的有效性至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we focused on constructing and evaluating levels ofexplanation(LOE) that address two basic aspect of HRI: 1. What informationshould be communicated to the user by the robot? 2. When should the robotcommunicate this information? For constructing the LOE, we defined two terms,verbosity and explanation patterns, each with two levels (verbosity -- high andlow, explanation patterns -- dynamic and static). Based on these parameters,three different LOE (high, medium, and low) were constructed and evaluated in auser study with a telepresence robot. The user study was conducted for asimulated telerobotic healthcare task with two different conditions related totime sensitivity, as evaluated by two different user groups -- one thatperformed the task within a time limit and the other with no time limit. Wefound that the high LOE was preferred in terms of adequacy of explanation,number of collisions, number of incorrect movements, and number ofclarifications when users performed the experiment in the without time limitcondition. We also found that both high and medium LOE did not have significantdifferences in completion time, the fluency of HRI, and trust in the robot.When users performed the experiment in the with time limit condition, high andmedium LOE had better task performances and were preferred to the low LOE interms of completion time, fluency, adequacy of explanation, trust, number ofcollisions, number of incorrect movements and number of clarifications. Futuredirections for advancing LOE are discussed.</description>
      <author>example@mail.com (Shikhar Kumar, Omer Keidar, Yael Edan)</author>
      <guid isPermaLink="false">2410.23215v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>coVoxSLAM: GPU Accelerated Globally Consistent Dense SLAM</title>
      <link>http://arxiv.org/abs/2410.21149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;密集SLAM系统对移动机器人至关重要，提供定位、导航、路径规划、障碍物规避和决策能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的GPU加速体积SLAM系统，利用GPU的并行处理能力在大规模环境中构建全球一致的地图。&lt;h4&gt;方法&lt;/h4&gt;开发coVoxSLAM系统，并在不同平台（离散和嵌入式GPU）上进行部署与比较。&lt;h4&gt;主要发现&lt;/h4&gt;使用公共数据集的结果表明，coVoxSLAM在执行时间上显著提升，同时保持准确的定位。&lt;h4&gt;结论&lt;/h4&gt;该系统作为开源项目可在GitHub上获取，推动了密集SLAM技术的发展。&lt;h4&gt;总结&lt;/h4&gt;coVoxSLAM利用GPU加速，提升了密集SLAM的性能，是移动机器人领域的一个重要进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A dense SLAM system is essential for mobile robots, as it provideslocalization and allows navigation, path planning, obstacle avoidance, anddecision-making in unstructured environments. Due to increasing computationaldemands the use of GPUs in dense SLAM is expanding. In this work, we presentcoVoxSLAM, a novel GPU-accelerated volumetric SLAM system that takes fulladvantage of the parallel processing power of the GPU to build globallyconsistent maps even in large-scale environments. It was deployed on differentplatforms (discrete and embedded GPU) and compared with the state of the art.The results obtained using public datasets show that coVoxSLAM delivers asignificant performance improvement considering execution times whilemaintaining accurate localization. The presented system is available asopen-source on GitHub https://github.com/lrse-uba/coVoxSLAM.</description>
      <author>example@mail.com (Emiliano Höss, Pablo De Cristóforis)</author>
      <guid isPermaLink="false">2410.21149v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DisenTS: Disentangled Channel Evolving Pattern Modeling for Multivariate Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.22981v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列预测在各种实际应用中起着至关重要的作用，现有方法通常使用单一模型来捕捉通道间的复杂依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提出DisenTS框架，以解耦的方式建模多变量时间序列中的通道演变模式。&lt;h4&gt;方法&lt;/h4&gt;框架采用多个独立的预测模型，每个模型负责揭示独特的演变模式，并引入Forecaster Aware Gate (FAG)模块生成自适应路由信号。&lt;h4&gt;主要发现&lt;/h4&gt;利用线性权重近似（LWA）策略量化深度神经网络，并通过相似性约束（SC）来引导模型专注于潜在模式。&lt;h4&gt;结论&lt;/h4&gt;DisenTS框架通过解耦建模方式，能更好地捕捉多变量时间序列中各通道的动态变化，提升预测准确性。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新颖的方法，通过多个专门的模型和自适应机制，优化了多变量时间序列预测的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series forecasting plays a crucial role in variousreal-world applications. Significant efforts have been made to integrateadvanced network architectures and training strategies that enhance the captureof temporal dependencies, thereby improving forecasting accuracy. On the otherhand, mainstream approaches typically utilize a single unified model withsimplistic channel-mixing embedding or cross-channel attention operations toaccount for the critical intricate inter-channel dependencies. Moreover, somemethods even trade capacity for robust prediction based on thechannel-independent assumption. Nonetheless, as time series data may displaydistinct evolving patterns due to the unique characteristics of each channel(including multiple strong seasonalities and trend changes), the unifiedmodeling methods could yield suboptimal results. To this end, we proposeDisenTS, a tailored framework for modeling disentangled channel evolvingpatterns in general multivariate time series forecasting. The central idea ofDisenTS is to model the potential diverse patterns within the multivariate timeseries data in a decoupled manner. Technically, the framework employs multipledistinct forecasting models, each tasked with uncovering a unique evolvingpattern. To guide the learning process without supervision of patternpartition, we introduce a novel Forecaster Aware Gate (FAG) module thatgenerates the routing signals adaptively according to both the forecasters'states and input series' characteristics. The forecasters' states are derivedfrom the Linear Weight Approximation (LWA) strategy, which quantizes thecomplex deep neural networks into compact matrices. Additionally, theSimilarity Constraint (SC) is further proposed to guide each model tospecialize in an underlying pattern by minimizing the mutual informationbetween the representations.</description>
      <author>example@mail.com (Zhiding Liu, Jiqian Yang, Qingyang Mao, Yuze Zhao, Mingyue Cheng, Zhi Li, Qi Liu, Enhong Chen)</author>
      <guid isPermaLink="false">2410.22981v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning</title>
      <link>http://arxiv.org/abs/2410.23234v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;该论文介绍了一个名为EMOTION的框架，旨在为类人机器人生成表达情感的动作序列，增强其进行人类非语言交流的能力。&lt;h4&gt;目的&lt;/h4&gt;提升机器人在非语言交流中的能力，特别是面部表情、手势和身体动作等关键非语言线索。&lt;h4&gt;方法&lt;/h4&gt;利用大型语言模型（LLMs）的上下文学习能力，动态生成适合人类-机器人互动的社交手势动作序列，并与人类反馈版本EMOTION++进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;通过在线用户研究，结果显示EMOTION生成的动作在自然性和可理解性方面与人类表现相当，甚至在某些情况下超过人类表现。&lt;h4&gt;结论&lt;/h4&gt;该方法在生成可理解和自然的机器人动作方面具有潜力，并为未来研究提供了设计启示，考虑生成表达性机器人手势时的多种变量。&lt;h4&gt;总结&lt;/h4&gt;EMOTION框架在提升机器人非语言交流能力方面具有显著优势，建议进一步研究以优化手势生成的多样性与细腻度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a framework, called EMOTION, for generating expressivemotion sequences in humanoid robots, enhancing their ability to engage inhumanlike non-verbal communication. Non-verbal cues such as facial expressions,gestures, and body movements play a crucial role in effective interpersonalinteractions. Despite the advancements in robotic behaviors, existing methodsoften fall short in mimicking the diversity and subtlety of human non-verbalcommunication. To address this gap, our approach leverages the in-contextlearning capability of large language models (LLMs) to dynamically generatesocially appropriate gesture motion sequences for human-robot interaction. Weuse this framework to generate 10 different expressive gestures and conductonline user studies comparing the naturalness and understandability of themotions generated by EMOTION and its human-feedback version, EMOTION++, againstthose by human operators. The results demonstrate that our approach eithermatches or surpasses human performance in generating understandable and naturalrobot motions under certain scenarios. We also provide design implications forfuture research to consider a set of variables when generating expressiverobotic gestures.</description>
      <author>example@mail.com (Peide Huang, Yuhan Hu, Nataliya Nechyporenko, Daehwa Kim, Walter Talbott, Jian Zhang)</author>
      <guid isPermaLink="false">2410.23234v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense</title>
      <link>http://arxiv.org/abs/2410.23091v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管持续努力保护神经分类器免受对抗攻击，但它们仍然易受攻击，尤其是对未见过的攻击。&lt;h4&gt;目的&lt;/h4&gt;模拟标签生成，通过识别标签的因果因素和非因果因素来辅助数据生成。&lt;h4&gt;方法&lt;/h4&gt;提出了一种因果扩散模型（CausalDiff），适应扩散模型用于条件数据生成，并通过学习新颖的因果信息瓶颈目标来解耦两种因果因素。&lt;h4&gt;主要发现&lt;/h4&gt;CausalDiff在各种未见攻击上显著优于最先进的防御方法，CIFAR-10的平均鲁棒性为86.39%（+4.01%），CIFAR-100为56.25%（+3.13%），GTSRB为82.62%（+4.93%）。&lt;h4&gt;结论&lt;/h4&gt;CausalDiff有效提高了神经分类器对抗未见攻击的鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;本研究通过因果模型提升了神经网络的防御能力，为对抗攻击的防御提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite ongoing efforts to defend neural classifiers from adversarialattacks, they remain vulnerable, especially to unseen attacks. In contrast,humans are difficult to be cheated by subtle manipulations, since we makejudgments only based on essential factors. Inspired by this observation, weattempt to model label generation with essential label-causative factors andincorporate label-non-causative factors to assist data generation. For anadversarial example, we aim to discriminate the perturbations as non-causativefactors and make predictions only based on the label-causative factors.Concretely, we propose a casual diffusion model (CausalDiff) that adaptsdiffusion models for conditional data generation and disentangles the two typesof casual factors by learning towards a novel casual information bottleneckobjective. Empirically, CausalDiff has significantly outperformedstate-of-the-art defense methods on various unseen attacks, achieving anaverage robustness of 86.39% (+4.01%) on CIFAR-10, 56.25% (+3.13%) onCIFAR-100, and 82.62% (+4.93%) on GTSRB (German Traffic Sign RecognitionBenchmark).</description>
      <author>example@mail.com (Mingkun Zhang, Keping Bi, Wei Chen, Quanrun Chen, Jiafeng Guo, Xueqi Cheng)</author>
      <guid isPermaLink="false">2410.23091v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>NYC-Event-VPR: A Large-Scale High-Resolution Event-Based Visual Place Recognition Dataset in Dense Urban Environments</title>
      <link>http://arxiv.org/abs/2410.21615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉场所识别（VPR）使自主机器人能够识别之前访问过的位置，对同时定位与地图构建（SLAM）任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;介绍NYC-Event-VPR数据集，以填补基于事件的VPR数据缺口。&lt;h4&gt;方法&lt;/h4&gt;使用Prophesee IMX636 HD事件传感器与RGB摄像头和GPS模块结合，收集数据。&lt;h4&gt;主要发现&lt;/h4&gt;数据集包含超过13小时的地理标记事件数据，覆盖260公里的纽约市，涵盖多种光照和天气条件，昼夜场景，以及多次访问不同位置。&lt;h4&gt;结论&lt;/h4&gt;事件相机具有高时间分辨率、超低延迟和高动态范围，适用于解决VPR面临的挑战，但数据集稀缺限制了应用。&lt;h4&gt;总结&lt;/h4&gt;通过三种框架进行泛化性能评估，推动事件基础VPR的创新及其在机器人应用中的整合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual place recognition (VPR) enables autonomous robots to identifypreviously visited locations, which contributes to tasks like simultaneouslocalization and mapping (SLAM). VPR faces challenges such as accurate imageneighbor retrieval and appearance change in scenery. Event cameras, also knownas dynamic vision sensors, are a new sensor modality for VPR and offer apromising solution to the challenges with their unique attributes: hightemporal resolution (1MHz clock), ultra-low latency (in {\mu}s), and highdynamic range (&gt;120dB). These attributes make event cameras less susceptible tomotion blur and more robust in variable lighting conditions, making themsuitable for addressing VPR challenges. However, the scarcity of event-basedVPR datasets, partly due to the novelty and cost of event cameras, hamperstheir adoption. To fill this data gap, our paper introduces the NYC-Event-VPRdataset to the robotics and computer vision communities, featuring theProphesee IMX636 HD event sensor (1280x720 resolution), combined with RGBcamera and GPS module. It encompasses over 13 hours of geotagged event data,spanning 260 kilometers across New York City, covering diverse lighting andweather conditions, day/night scenarios, and multiple visits to variouslocations. Furthermore, our paper employs three frameworks to conductgeneralization performance assessments, promoting innovation in event-based VPRand its integration into robotics applications.</description>
      <author>example@mail.com (Taiyi Pan, Junyang He, Chao Chen, Yiming Li, Chen Feng)</author>
      <guid isPermaLink="false">2410.21615v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Keypoint Abstraction using Large Models for Object-Relative Imitation Learning</title>
      <link>http://arxiv.org/abs/2410.23254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CoRL LangRob Workshop, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在机器人技术中，适应新物体配置和实例的能力是一个重要挑战。基于关键点的表示方法在捕捉物体特征和行动预测中有效，但手动设计和依赖额外人类标签限制了其扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出KALM框架，以利用大型预训练的视觉-语言模型自动生成任务相关和跨实例一致的关键点。&lt;h4&gt;方法&lt;/h4&gt;KALM通过使用语言模型生成提案，提炼出在不同视角和物体之间稳健一致的关键点，并通过小规模机器人演示数据验证这些关键点。&lt;h4&gt;主要发现&lt;/h4&gt;基于生成的关键点，我们可以训练关键点条件的策略模型，预测在关键点中心帧中的动作，使机器人能够有效地在不同物体姿势、相机视角和相似功能形状的物体实例间进行泛化。&lt;h4&gt;结论&lt;/h4&gt;该方法在现实世界中表现出色，能够从少量演示中适应不同任务和环境，无需额外标签。&lt;h4&gt;总结&lt;/h4&gt;KALM框架通过自动生成关键点，提升了机器人在各种任务和环境中的适应性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalization to novel object configurations and instances across diversetasks and environments is a critical challenge in robotics. Keypoint-basedrepresentations have been proven effective as a succinct representation forcapturing essential object features, and for establishing a reference frame inaction prediction, enabling data-efficient learning of robot skills. However,their manual design nature and reliance on additional human labels limit theirscalability. In this paper, we propose KALM, a framework that leverages largepre-trained vision-language models (LMs) to automatically generatetask-relevant and cross-instance consistent keypoints. KALM distills robust andconsistent keypoints across views and objects by generating proposals using LMsand verifies them against a small set of robot demonstration data. Based on thegenerated keypoints, we can train keypoint-conditioned policy models thatpredict actions in keypoint-centric frames, enabling robots to generalizeeffectively across varying object poses, camera views, and object instanceswith similar functional shapes. Our method demonstrates strong performance inthe real world, adapting to different tasks and environments from only ahandful of demonstrations while requiring no additional labels. Website:https://kalm-il.github.io/</description>
      <author>example@mail.com (Xiaolin Fang, Bo-Ruei Huang, Jiayuan Mao, Jasmine Shone, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling)</author>
      <guid isPermaLink="false">2410.23254v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>EnvoDat: A Large-Scale Multisensory Dataset for Robotic Spatial Awareness and Semantic Reasoning in Heterogeneous Environments</title>
      <link>http://arxiv.org/abs/2410.22200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;为了确保机器人在多样化真实世界条件下的自主效率，需要高质量的异构数据集来评估操作算法的性能和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;填补当前基准测试在城市地形上的不足，特别是针对地下隧道、自然田野和现代室内空间等环境的代表性。&lt;h4&gt;方法&lt;/h4&gt;引入EnvoDat，这是一个在多种环境和条件下收集的大规模多模态数据集，包括高亮度、雾、雨和零能见度等不同时间的情况。&lt;h4&gt;主要发现&lt;/h4&gt;EnvoDat包含来自13个场景的26个序列，10种传感模态，超过1.9TB的数据，以及超过89K个针对82个对象和地形类别的细粒度多边形注释。&lt;h4&gt;结论&lt;/h4&gt;通过不同格式的后处理，EnvoDat支持SLAM基准测试和监督学习算法的评估，以及多模态视觉模型的微调。&lt;h4&gt;总结&lt;/h4&gt;EnvoDat为在极具挑战性的环境中实现环境适应性机器人自主提供了重要的贡献，数据集和其他相关资源可通过指定链接访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To ensure the efficiency of robot autonomy under diverse real-worldconditions, a high-quality heterogeneous dataset is essential to benchmark theoperating algorithms' performance and robustness. Current benchmarkspredominantly focus on urban terrains, specifically for on-road autonomousdriving, leaving multi-degraded, densely vegetated, dynamic and feature-sparseenvironments, such as underground tunnels, natural fields, and modern indoorspaces underrepresented. To fill this gap, we introduce EnvoDat, a large-scale,multi-modal dataset collected in diverse environments and conditions, includinghigh illumination, fog, rain, and zero visibility at different times of theday. Overall, EnvoDat contains 26 sequences from 13 scenes, 10 sensingmodalities, over 1.9TB of data, and over 89K fine-grained polygon-basedannotations for more than 82 object and terrain classes. We post-processedEnvoDat in different formats that support benchmarking SLAM and supervisedlearning algorithms, and fine-tuning multimodal vision models. With EnvoDat, wecontribute to environment-resilient robotic autonomy in areas where theconditions are extremely challenging. The datasets and other relevant resourcescan be accessed through https://linusnep.github.io/EnvoDat/.</description>
      <author>example@mail.com (Linus Nwankwo, Bjoern Ellensohn, Vedant Dave, Peter Hofer, Jan Forstner, Marlene Villneuve, Robert Galler, Elmar Rueckert)</author>
      <guid isPermaLink="false">2410.22200v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SCRREAM : SCan, Register, REnder And Map:A Framework for Annotating Accurate and Dense 3D Indoor Scenes with a Benchmark</title>
      <link>http://arxiv.org/abs/2410.22715v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的3D室内数据集通常优先考虑规模而非真实准确性，这导致在进行深度渲染等密集几何任务时出现问题。&lt;h4&gt;目的&lt;/h4&gt;提出SCRREAM数据集注释框架，以便对场景中的物体进行完全密集网格的注释，并在真实图像序列上注册相机姿态，从而提供准确的真实值。&lt;h4&gt;方法&lt;/h4&gt;展示数据集注释流程，并展示从该框架中获得的四种可能的数据集变体，包括室内重建、SLAM、场景编辑与物体移除、人类重建和6D姿态估计。&lt;h4&gt;主要发现&lt;/h4&gt;与之前的室内数据集相比，SCRREAM设计允许在11个样本场景上评估密集几何任务，并与准确渲染的真实深度图进行比较。&lt;h4&gt;结论&lt;/h4&gt;SCRREAM为密集几何任务提供了新的基准，能够有效解决传统数据集在真实值评估中的不足。&lt;h4&gt;总结&lt;/h4&gt;SCRREAM框架通过提供准确的注释和真实值，推动了室内重建和SLAM等领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditionally, 3d indoor datasets have generally prioritized scale overground-truth accuracy in order to obtain improved generalization. However,using these datasets to evaluate dense geometry tasks, such as depth rendering,can be problematic as the meshes of the dataset are often incomplete and mayproduce wrong ground truth to evaluate the details. In this paper, we proposeSCRREAM, a dataset annotation framework that allows annotation of fully densemeshes of objects in the scene and registers camera poses on the real imagesequence, which can produce accurate ground truth for both sparse 3D as well asdense 3D tasks. We show the details of the dataset annotation pipeline andshowcase four possible variants of datasets that can be obtained from ourframework with example scenes, such as indoor reconstruction and SLAM, sceneediting &amp; object removal, human reconstruction and 6d pose estimation. Recentpipelines for indoor reconstruction and SLAM serve as new benchmarks. Incontrast to previous indoor dataset, our design allows to evaluate densegeometry tasks on eleven sample scenes against accurately rendered ground truthdepth maps.</description>
      <author>example@mail.com (HyunJun Jung, Weihang Li, Shun-Cheng Wu, William Bittner, Nikolas Brasch, Jifei Song, Eduardo Pérez-Pellitero, Zhensong Zhang, Arthur Moreau, Nassir Navab, Benjamin Busam)</author>
      <guid isPermaLink="false">2410.22715v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation</title>
      <link>http://arxiv.org/abs/2410.23277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类具备互补的学习系统，结合了对世界动态的慢学习与对新经验的快速存储。&lt;h4&gt;目的&lt;/h4&gt;提出SlowFast-VGen，一种用于动作驱动的长视频生成的双速学习系统。&lt;h4&gt;方法&lt;/h4&gt;结合掩码条件视频扩散模型进行世界动态的慢学习，并在推理时采用基于时间的LoRA模块进行快速学习。&lt;h4&gt;主要发现&lt;/h4&gt;SlowFast-VGen在各种指标上超越基线，生成的长视频保持一致性，FVD评分为514，场景切换平均为0.37。&lt;h4&gt;结论&lt;/h4&gt;慢-快学习循环算法显著提升了长时间规划任务的表现。&lt;h4&gt;总结&lt;/h4&gt;通过收集20万段带语言动作注释的视频数据，支持慢学习的世界模型，有效提升了动作驱动视频生成的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human beings are endowed with a complementary learning system, which bridgesthe slow learning of general world dynamics with fast storage of episodicmemory from a new experience. Previous video generation models, however,primarily focus on slow learning by pre-training on vast amounts of data,overlooking the fast learning phase crucial for episodic memory storage. Thisoversight leads to inconsistencies across temporally distant frames whengenerating longer videos, as these frames fall beyond the model's contextwindow. To this end, we introduce SlowFast-VGen, a novel dual-speed learningsystem for action-driven long video generation. Our approach incorporates amasked conditional video diffusion model for the slow learning of worlddynamics, alongside an inference-time fast learning strategy based on atemporal LoRA module. Specifically, the fast learning process updates itstemporal LoRA parameters based on local inputs and outputs, thereby efficientlystoring episodic memory in its parameters. We further propose a slow-fastlearning loop algorithm that seamlessly integrates the inner fast learning loopinto the outer slow learning loop, enabling the recall of prior multi-episodeexperiences for context-aware skill learning. To facilitate the slow learningof an approximate world model, we collect a large-scale dataset of 200k videoswith language action annotations, covering a wide range of scenarios. Extensiveexperiments show that SlowFast-VGen outperforms baselines across variousmetrics for action-driven video generation, achieving an FVD score of 514compared to 782, and maintaining consistency in longer videos, with an averageof 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithmsignificantly enhances performances on long-horizon planning tasks as well.Project Website: https://slowfast-vgen.github.io</description>
      <author>example@mail.com (Yining Hong, Beide Liu, Maxine Wu, Yuanhao Zhai, Kai-Wei Chang, Lingjie Li, Kevin Lin, Chung-Ching Lin, Jianfeng Wang, Zhengyuan Yang, Yingnian Wu, Lijuan Wang)</author>
      <guid isPermaLink="false">2410.23277v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DisCo: Distributed Contact-Rich Trajectory Optimization for Forceful Multi-Robot Collaboration</title>
      <link>http://arxiv.org/abs/2410.23283v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了DisCo，一种用于接触丰富的多机器人任务的分布式算法。&lt;h4&gt;目的&lt;/h4&gt;优化机器人在多个任务中的接触力和轨迹，以实现协作操作、团队运动和模块化机器人运动。&lt;h4&gt;方法&lt;/h4&gt;基于交替方向乘子法(ADMM)的变体，每个机器人独立计算接触力，通过无线网与其他机器人协作，确保一致性约束。&lt;h4&gt;主要发现&lt;/h4&gt;DisCo在协作操作、多机器人团队运动和模块化机器人运动中表现出色，成功率提高3倍，计算速度提升2.5到5倍。&lt;h4&gt;结论&lt;/h4&gt;分布式方法提高了计算效率并保护了机器人的隐私，同时在硬件实验中证明了有效性。&lt;h4&gt;总结&lt;/h4&gt;DisCo算法通过分布式优化实现机器人之间的高效协作，适用于多种复杂任务场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present DisCo, a distributed algorithm for contact-rich, multi-robottasks. DisCo is a distributed contact-implicit trajectory optimizationalgorithm, which allows a group of robots to optimize a time sequence of forcesto objects and to their environment to accomplish tasks such as collaborativemanipulation, robot team sports, and modular robot locomotion. We build ouralgorithm on a variant of the Alternating Direction Method of Multipliers(ADMM), where each robot computes its own contact forces and contact-switchingevents from a smaller single-robot, contact-implicit trajectory optimizationproblem, while cooperating with other robots through dual variables, enforcingconstraints between robots. Each robot iterates between solving its localproblem, and communicating over a wireless mesh network to enforce theseconsistency constraints with its neighbors, ultimately converging to acoordinated plan for the group. The local problems solved by each robot aresignificantly less challenging than a centralized problem with all robots'contact forces and switching events, improving the computational efficiency,while also preserving the privacy of some aspects of each robot's operation. Wedemonstrate the effectiveness of our algorithm in simulations of collaborativemanipulation, multi-robot team sports scenarios, and in modular robotlocomotion, where DisCo achieves $3$x higher success rates with a 2.5x to 5xfaster computation time. Further, we provide results of hardware experiments ona modular truss robot, with three collaborating truss nodes planningindividually while working together to produce a punctuated rolling-gate motionof the composite structure. Videos are available on the project page:https://disco-opt.github.io.</description>
      <author>example@mail.com (Ola Shorinwa, Matthew Devlin, Elliot W. Hawkes, Mac Schwager)</author>
      <guid isPermaLink="false">2410.23283v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ISAC Prototype System for Multi-Domain Cooperative Communication Networks</title>
      <link>http://arxiv.org/abs/2410.22956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures, accepted by IEEE Wireless Communications Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;未来无线网络将转变为集成感知与通信（ISAC）网络，开启数字双胞胎等创新服务。&lt;h4&gt;目的&lt;/h4&gt;验证ISAC网络的感知能力及其在提升通信中的作用。&lt;h4&gt;方法&lt;/h4&gt;开发了一种先进的ISAC原型系统，支持单静态、双静态和网络感知模式，进行多模态数据收集与同步。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在感知辅助波束追踪和实时高清晰度视频传输方面表现出色，提供精确的角度和距离测量，以及实时成像和基于无线的同时定位与地图构建（SLAM）。&lt;h4&gt;结论&lt;/h4&gt;原型系统符合5G新无线标准，支持最多16个用户设备（UE）上行传输和10个下行传输，实际测试显示角度估计的均方根误差为2.3度，距离估计为0.3米，实时无线SLAM的多模态辅助估计误差为0.25米和0.8米。&lt;h4&gt;总结&lt;/h4&gt;该ISAC原型系统展示了在感知与通信领域的高精度和高效能，具有重要的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Future wireless networks are poised to transform into integrated sensing andcommunication (ISAC) networks, unlocking groundbreaking services such asdigital twinning. To harness the full potential of ISAC networks, it isessential to experimentally validate their sensing capabilities and the role ofsensing in boosting communication. However, current prototype systems fallshort in supporting multiple sensing functions or validating sensing-assistedcommunication. In response, we have developed an advanced ISAC prototype systemthat incorporates monostatic, bistatic, and network sensing modes. This systemsupports multimodal data collection and synchronization, ensuring comprehensiveexperimental validation. On the communication front, it excels in sensing-aidedbeam tracking and real-time high-definition video transmission. For sensingapplications, it provides precise angle and range measurements, real-timeangle-range imaging, and radio-based simultaneous localization and mapping(SLAM). Our prototype aligns with the 5G New Radio standard, offeringscalability for up to 16 user equipments (UEs) in uplink transmission and 10UEs in downlink transmission. Real-world tests showcase the system's superioraccuracy, with root mean square errors of 2.3 degrees for angle estimation and0.3 meters (m) for range estimation. Additionally, the estimation errors formultimodal-aided real-time radio SLAM localization and mapping are 0.25 m and0.8 m, respectively.</description>
      <author>example@mail.com (Jie Yang, Hang Que, Tao Du, Le Liang, Xiao Li, Chao-Kai Wen, Shi Jin)</author>
      <guid isPermaLink="false">2410.22956v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards</title>
      <link>http://arxiv.org/abs/2410.23289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;直接从人类视频训练机器人是在机器人技术和计算机视觉领域的新兴方向。&lt;h4&gt;目的&lt;/h4&gt;解决多指机器人手自主任务学习的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出HuDOR技术，通过直接从人类视频计算奖励进行在线微调，使用基于对象的轨迹构建奖励函数。&lt;h4&gt;主要发现&lt;/h4&gt;HuDOR能够在视觉和形态差异的情况下，提供有意义的学习信号，四指Allegro手在仅有一小时在线交互的情况下学习任务。&lt;h4&gt;结论&lt;/h4&gt;HuDOR在四个任务上的实验中表现出比基线高出4倍的改进。&lt;h4&gt;总结&lt;/h4&gt;代码和视频可在我们的网站上找到，展示了HuDOR的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training robots directly from human videos is an emerging area in roboticsand computer vision. While there has been notable progress with two-fingeredgrippers, learning autonomous tasks for multi-fingered robot hands in this wayremains challenging. A key reason for this difficulty is that a policy trainedon human hands may not directly transfer to a robot hand due to morphologydifferences. In this work, we present HuDOR, a technique that enables onlinefine-tuning of policies by directly computing rewards from human videos.Importantly, this reward function is built using object-oriented trajectoriesderived from off-the-shelf point trackers, providing meaningful learningsignals despite the morphology gap and visual differences between human androbot hands. Given a single video of a human solving a task, such as gentlyopening a music box, HuDOR enables our four-fingered Allegro hand to learn thetask with just an hour of online interaction. Our experiments across four tasksshow that HuDOR achieves a 4x improvement over baselines. Code and videos areavailable on our website, https://object-rewards.github.io.</description>
      <author>example@mail.com (Irmak Guzey, Yinlong Dai, Georgy Savva, Raunaq Bhirangi, Lerrel Pinto)</author>
      <guid isPermaLink="false">2410.23289v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>LGU-SLAM: Learnable Gaussian Uncertainty Matching with Deformable Correlation Sampling for Deep Visual SLAM</title>
      <link>http://arxiv.org/abs/2410.23231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度视觉同步定位与地图构建(SLAM)技术如DROID，通过深度视觉里程计和密集光流场取得了显著进展，但依赖全局视觉相似性匹配。&lt;h4&gt;目的&lt;/h4&gt;解决不确定区域中的模糊相似性干扰导致的噪声问题，从而提高SLAM的几何建模准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种可学习的高斯不确定性(LGU)匹配，设计了一个学习型的2D高斯不确定性模型，用于匹配帧对的关联，同时采用多尺度可变形相关采样策略和KAN偏差GRU组件。&lt;h4&gt;主要发现&lt;/h4&gt;通过对真实和合成数据集的广泛实验验证了该方法的有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;所提方法在精确对应构建和时空建模方面表现出色，能够有效减少噪声干扰，提高SLAM性能。&lt;h4&gt;总结&lt;/h4&gt;该研究通过引入可学习的高斯不确定性和改进的采样策略，显著提升了深度视觉SLAM的准确性和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/uestc-nnlab/lgu-slam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep visual Simultaneous Localization and Mapping (SLAM) techniques, e.g.,DROID, have made significant advancements by leveraging deep visual odometry ondense flow fields. In general, they heavily rely on global visual similaritymatching. However, the ambiguous similarity interference in uncertain regionscould often lead to excessive noise in correspondences, ultimately misleadingSLAM in geometric modeling. To address this issue, we propose a LearnableGaussian Uncertainty (LGU) matching. It mainly focuses on precisecorrespondence construction. In our scheme, a learnable 2D Gaussian uncertaintymodel is designed to associate matching-frame pairs. It could generateinput-dependent Gaussian distributions for each correspondence map.Additionally, a multi-scale deformable correlation sampling strategy is devisedto adaptively fine-tune the sampling of each direction by a priori look-upranges, enabling reliable correlation construction. Furthermore, a KAN-bias GRUcomponent is adopted to improve a temporal iterative enhancement foraccomplishing sophisticated spatio-temporal modeling with limited parameters.The extensive experiments on real-world and synthetic datasets are conducted tovalidate the effectiveness and superiority of our method.</description>
      <author>example@mail.com (Yucheng Huang, Luping Ji, Hudong Liu, Mao Ye)</author>
      <guid isPermaLink="false">2410.23231v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>CLAP. I. Resolving miscalibration for deep learning-based galaxy photometric redshift estimation</title>
      <link>http://arxiv.org/abs/2410.19390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 + 6 pages, 9 + 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;获取未进行光谱测量的星系的光度红移概率密度仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新方法，称为对比学习和自适应KNN用于光度红移（CLAP），以解决模型输出与真实红移分布之间的误校准问题。&lt;h4&gt;方法&lt;/h4&gt;结合监督对比学习（SCL）和K近邻（KNN）构建和校准原始概率密度估计，并实施重拟合程序以准备大规模成像数据的最终估计。&lt;h4&gt;主要发现&lt;/h4&gt;CLAP利用深度学习和KNN的优势，在概率密度估计的校准上优于基准方法，同时保持高准确性和计算效率。&lt;h4&gt;结论&lt;/h4&gt;误校准对方法引起的数据实例之间的过度相关性特别敏感，常规深度学习方法难以消除这种误校准，而CLAP则能够克服此问题。&lt;h4&gt;总结&lt;/h4&gt;CLAP在获取天文学和宇宙学应用所需的光度红移概率密度方面表现出色。这是关于CLAP系列的第一篇论文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1051/0004-6361/202449113&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/QiufanLin/CLAP-I&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Obtaining well-calibrated photometric redshift probability densities forgalaxies without a spectroscopic measurement remains a challenge. Deep learningdiscriminative models, typically fed with multi-band galaxy images, can produceoutputs that mimic probability densities and achieve state-of-the-art accuracy.However, such models may be affected by miscalibration that would result indiscrepancies between the model outputs and the actual distributions of trueredshifts. Our work develops a novel method called the Contrastive Learning andAdaptive KNN for Photometric Redshift (CLAP) that resolves this issue. Itleverages supervised contrastive learning (SCL) and k-nearest neighbours (KNN)to construct and calibrate raw probability density estimates, and implements arefitting procedure to resume end-to-end discriminative models ready to producefinal estimates for large-scale imaging data. The harmonic mean is adopted tocombine an ensemble of estimates from multiple realisations for improvingaccuracy. Our experiments demonstrate that CLAP takes advantage of both deeplearning and KNN, outperforming benchmark methods on the calibration ofprobability density estimates and retaining high accuracy and computationalefficiency. With reference to CLAP, we point out that miscalibration isparticularly sensitive to the method-induced excessive correlations among datainstances in addition to the unaccounted-for epistemic uncertainties. Reducingthe uncertainties may not guarantee the removal of miscalibration due to thepresence of such excessive correlations, yet this is a problem for conventionaldeep learning methods rather than CLAP. These discussions underscore therobustness of CLAP for obtaining photometric redshift probability densitiesrequired by astrophysical and cosmological applications. This is the firstpaper in our series on CLAP.</description>
      <author>example@mail.com (Qiufan Lin, Hengxin Ruan, Dominique Fouchez, Shupei Chen, Rui Li, Paulo Montero-Camacho, Nicola R. Napolitano, Yuan-Sen Ting, Wei Zhang)</author>
      <guid isPermaLink="false">2410.19390v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework</title>
      <link>http://arxiv.org/abs/2410.19453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管利用多语言数据微调大型语言模型（LLMs）可以迅速提升其多语言能力，但在主导语言（如英语）与非主导语言之间仍存在性能差距，原因在于训练数据的不平衡。&lt;h4&gt;目的&lt;/h4&gt;进一步提升非主导语言的性能。&lt;h4&gt;方法&lt;/h4&gt;提出ShifCon，一种基于Shift的对比框架，将非主导语言的表示对齐到主导语言，允许访问模型参数中相对丰富的信息，并在生成前将表示移回原语言子空间。&lt;h4&gt;主要发现&lt;/h4&gt;ShifCon框架显著提升了非主导语言的性能，尤其是资源稀缺的语言。&lt;h4&gt;结论&lt;/h4&gt;进一步分析提供了额外的见解，以验证ShifCon的有效性并推动未来的研究。&lt;h4&gt;总结&lt;/h4&gt;ShifCon通过有效的表示对齐和多语言对比学习，显著改善了非主导语言的表现，为低资源语言提供了新的提升方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/rattlesnakey/ShifCon&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although fine-tuning Large Language Models (LLMs) with multilingual data canrapidly enhance the multilingual capabilities of LLMs, they still exhibit aperformance gap between the dominant language (e.g., English) and non-dominantones due to the imbalance of training data across languages. To further enhancethe performance of non-dominant languages, we propose ShifCon, a Shift-basedContrastive framework that aligns the internal forward process of otherlanguages toward that of the dominant one. Specifically, it shifts therepresentations of non-dominant languages into the dominant language subspace,allowing them to access relatively rich information encoded in the modelparameters. The enriched representations are then shifted back into theiroriginal language subspace before generation. Moreover, we introduce a subspacedistance metric to pinpoint the optimal layer area for shifting representationsand employ multilingual contrastive learning to further enhance the alignmentof representations within this area. Experiments demonstrate that our ShifConframework significantly enhances the performance of non-dominant languages,particularly for low-resource ones. Further analysis offers extra insights toverify the effectiveness of ShifCon and propel future research</description>
      <author>example@mail.com (Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei)</author>
      <guid isPermaLink="false">2410.19453v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Bio2Token: All-atom tokenization of any biomolecular structure with Mamba</title>
      <link>http://arxiv.org/abs/2410.19110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高保真度的大型3D分子结构的有效编码和表示对生物分子设计应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发能够学习完整蛋白质、RNA和小分子结构的原子级标记的量化自编码器。&lt;h4&gt;方法&lt;/h4&gt;使用Mamba状态空间模型架构，以较少的训练数据和参数，实现接近1埃的重构精度。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够高效地扩展至近100,000个原子的系统，且训练效率高。&lt;h4&gt;结论&lt;/h4&gt;学习到的生物结构标记可作为未来全原子语言模型的输入。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，解决了大规模生物分子表示学习中的精度和效率问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient encoding and representation of large 3D molecular structures withhigh fidelity is critical for biomolecular design applications. Despite this,many representation learning approaches restrict themselves to modeling smallersystems or use coarse-grained approximations of the systems, for examplemodeling proteins at the resolution of amino acid residues rather than at thelevel of individual atoms. To address this, we develop quantized auto-encodersthat learn atom-level tokenizations of complete proteins, RNA and smallmolecule structures with reconstruction accuracies below and around 1 Angstrom.We demonstrate that the Mamba state space model architecture employed iscomparatively efficient, requiring a fraction of the training data, parametersand compute needed to reach competitive accuracies and can scale to systemswith almost 100,000 atoms. The learned structure tokens of bio2token may serveas the input for all-atom language models in the future.</description>
      <author>example@mail.com (Andrew Liu, Axel Elaldi, Nathan Russell, Olivia Viessmann)</author>
      <guid isPermaLink="false">2410.19110v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MatExpert: Decomposing Materials Discovery by Mimicking Human Experts</title>
      <link>http://arxiv.org/abs/2410.21317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;材料发现是一个关键的研究领域，对多个行业有深远的影响。&lt;h4&gt;目的&lt;/h4&gt;介绍MatExpert框架，以加速新固态材料的发现与设计。&lt;h4&gt;方法&lt;/h4&gt;MatExpert结合大型语言模型和对比学习，模拟人类材料设计专家的工作流程，分为检索、过渡和生成三个阶段。&lt;h4&gt;主要发现&lt;/h4&gt;MatExpert在材料生成任务中优于现有最先进的方法，在有效性、分布性和稳定性等多个指标上表现出色。&lt;h4&gt;结论&lt;/h4&gt;MatExpert在基于语言的生成模型中代表了计算材料发现的重大进展。&lt;h4&gt;总结&lt;/h4&gt;MatExpert框架通过三个关键阶段提高了新材料的发现效率，推动了材料科学的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Material discovery is a critical research area with profound implications forvarious industries. In this work, we introduce MatExpert, a novel frameworkthat leverages Large Language Models (LLMs) and contrastive learning toaccelerate the discovery and design of new solid-state materials. Inspired bythe workflow of human materials design experts, our approach integrates threekey stages: retrieval, transition, and generation. First, in the retrievalstage, MatExpert identifies an existing material that closely matches thedesired criteria. Second, in the transition stage, MatExpert outlines thenecessary modifications to transform this material formulation to meet specificrequirements outlined by the initial user query. Third, in the generationstate, MatExpert performs detailed computations and structural generation tocreate new materials based on the provided information. Our experimentalresults demonstrate that MatExpert outperforms state-of-the-art methods inmaterial generation tasks, achieving superior performance across variousmetrics including validity, distribution, and stability. As such, MatExpertrepresents a meaningful advancement in computational material discovery usinglangauge-based generative models.</description>
      <author>example@mail.com (Qianggang Ding, Santiago Miret, Bang Liu)</author>
      <guid isPermaLink="false">2410.21317v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Indication Finding: a novel use case for representation learning</title>
      <link>http://arxiv.org/abs/2410.19174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多疗法在治疗多种疾病方面有效。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，利用自然语言处理和真实世界数据来优先考虑潜在的新适应症。&lt;h4&gt;方法&lt;/h4&gt;使用表示学习生成适应症的嵌入，并根据其与已知适应症的接近度进行优先排序。&lt;h4&gt;主要发现&lt;/h4&gt;成功应用该方法于抗IL-17A，并使用SPPMI生成的嵌入进行评估。&lt;h4&gt;结论&lt;/h4&gt;展示了一个评估框架，用于确定适应症发现结果和生成的嵌入的质量。&lt;h4&gt;总结&lt;/h4&gt;该方法为优先考虑新适应症提供了一种有效的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many therapies are effective in treating multiple diseases. We present anapproach that leverages methods developed in natural language processing andreal-world data to prioritize potential, new indications for a mechanism ofaction (MoA). We specifically use representation learning to generateembeddings of indications and prioritize them based on their proximity to theindications with the strongest available evidence for the MoA. We demonstratethe successful deployment of our approach for anti-IL-17A using embeddingsgenerated with SPPMI and present an evaluation framework to determine thequality of indication finding results and the derived embeddings.</description>
      <author>example@mail.com (Maren Eckhoff, Valmir Selimi, Alexander Aranovitch, Ian Lyons, Emily Briggs, Jennifer Hou, Alex Devereson, Matej Macak, David Champagne, Chris Anagnostopoulos)</author>
      <guid isPermaLink="false">2410.19174v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Human-Object Interaction Detection Collaborated with Large Relation-driven Diffusion Models</title>
      <link>http://arxiv.org/abs/2410.20155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类-物体交互检测方法通常依赖大规模视觉-语言模型来识别涉及人类和物体的事件。&lt;h4&gt;目的&lt;/h4&gt;提出DIFFUSIONHOI，一种新的人类-物体交互检测器，利用文本到图像的扩散模型。&lt;h4&gt;方法&lt;/h4&gt;采用基于反演的策略学习人类与物体之间关系模式的表达，将学习到的关系嵌入作为文本提示，引导扩散模型生成特定交互的图像，并从中提取相关线索。&lt;h4&gt;主要发现&lt;/h4&gt;DIFFUSIONHOI在三种数据集上，在常规和零样本设置下都达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;扩散模型在识别中/低级视觉概念和处理新概念的组合性方面表现优越，能够有效提取人类-物体交互的相关信息。&lt;h4&gt;总结&lt;/h4&gt;DIFFUSIONHOI为人类-物体交互检测提供了一种新的思路，改善了传统模型的局限性，取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prevalent human-object interaction (HOI) detection approaches typicallyleverage large-scale visual-linguistic models to help recognize eventsinvolving humans and objects. Though promising, models trained via contrastivelearning on text-image pairs often neglect mid/low-level visual cues andstruggle at compositional reasoning. In response, we introduce DIFFUSIONHOI, anew HOI detector shedding light on text-to-image diffusion models. Unlike theaforementioned models, diffusion models excel in discerning mid/low-levelvisual concepts as generative models, and possess strong compositionality tohandle novel concepts expressed in text inputs. Considering diffusion modelsusually emphasize instance objects, we first devise an inversion-based strategyto learn the expression of relation patterns between humans and objects inembedding space. These learned relation embeddings then serve as textualprompts, to steer diffusion models generate images that depict specificinteractions, and extract HOI-relevant cues from images without heavyfine-tuning. Benefited from above, DIFFUSIONHOI achieves SOTA performance onthree datasets under both regular and zero-shot setups.</description>
      <author>example@mail.com (Liulei Li, Wenguan Wang, Yi Yang)</author>
      <guid isPermaLink="false">2410.20155v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Reliability of Foundation Model-Based Frontier Selection in Zero-Shot Object Goal Navigation</title>
      <link>http://arxiv.org/abs/2410.21037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了一种新的方法，用于在零样本目标导航（ZS-OGN）中进行可靠的边界选择，旨在增强机器人导航系统的常识推理能力。&lt;h4&gt;目的&lt;/h4&gt;提高室内环境中机器人导航系统的性能，解决基础模型中常见的无意义或不相关推理问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多专家决策框架，包括两个关键组件：多样化专家边界分析（DEFA）和共识决策（CDM）。DEFA利用三种专家模型：家具布局、房间类型分析和视觉场景推理；CDM则聚合这些模型的输出，优先考虑一致或多数共识。&lt;h4&gt;主要发现&lt;/h4&gt;在RoboTHOR和HM3D数据集上表现出色，能够有效导航至未训练的物体或目标，超越了多种基线方法，显示出在动态现实条件下的适应性和卓越的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法展示了在零样本目标导航中提升机器人导航性能的潜力，强调了多专家系统在复杂环境中的重要性。&lt;h4&gt;总结&lt;/h4&gt;通过引入多专家决策框架，本文的方法在室内导航中实现了更高的可靠性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a novel method for reliable frontier selection inZero-Shot Object Goal Navigation (ZS-OGN), enhancing robotic navigation systemswith foundation models to improve commonsense reasoning in indoor environments.Our approach introduces a multi-expert decision framework to address thenonsensical or irrelevant reasoning often seen in foundation model-basedsystems. The method comprises two key components: Diversified Expert FrontierAnalysis (DEFA) and Consensus Decision Making (CDM). DEFA utilizes three expertmodels: furniture arrangement, room type analysis, and visual scene reasoning,while CDM aggregates their outputs, prioritizing unanimous or majorityconsensus for more reliable decisions. Demonstrating state-of-the-artperformance on the RoboTHOR and HM3D datasets, our method excels at navigatingtowards untrained objects or goals and outperforms various baselines,showcasing its adaptability to dynamic real-world conditions and superiorgeneralization capabilities.</description>
      <author>example@mail.com (Shuaihang Yuan, Halil Utku Unlu, Hao Huang, Congcong Wen, Anthony Tzes, Yi Fang)</author>
      <guid isPermaLink="false">2410.21037v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Perturbation-based Graph Active Learning for Weakly-Supervised Belief Representation Learning</title>
      <link>http://arxiv.org/abs/2410.19176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;该论文解决了在社交网络中优化标签资源分配的问题，尤其是在半监督信念表示学习方面。&lt;h4&gt;目的&lt;/h4&gt;旨在在有限预算内，战略性地识别社交媒体图中值得标记的有价值信息，从而最大化任务性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于图数据增强的扰动主动学习策略（PerbALGraph），根据自动估计器逐步选择待标记信息，无需人工指导。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提策略在信念表示学习任务中表现出色，能够有效提升性能。&lt;h4&gt;结论&lt;/h4&gt;通过对网络中对结构特征敏感的信息进行识别，该方法显著提高了半监督过程的有效性。&lt;h4&gt;总结&lt;/h4&gt;在标签资源有限的情况下，优化标签分配是关键研究问题，所提出的方法提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the problem of optimizing the allocation of labelingresources for semi-supervised belief representation learning in socialnetworks. The objective is to strategically identify valuable messages onsocial media graphs that are worth labeling within a constrained budget,ultimately maximizing the task's performance. Despite the progress inunsupervised or semi-supervised methods in advancing belief and ideologyrepresentation learning on social networks and the remarkable efficacy of graphlearning techniques, the availability of high-quality curated labeled socialdata can greatly benefit and further improve performances. Consequently,allocating labeling efforts is a critical research problem in scenarios wherelabeling resources are limited. This paper proposes a graph dataaugmentation-inspired perturbation-based active learning strategy (PerbALGraph)that progressively selects messages for labeling according to an automaticestimator, obviating human guidance. This estimator is based on the principlethat messages in the network that exhibit heightened sensitivity to structuralfeatures of the observational data indicate landmark quality that significantlyinfluences semi-supervision processes. We design the estimator to be theprediction variance under a set of designed graph perturbations, which ismodel-agnostic and application-independent. Extensive experiment resultsdemonstrate the effectiveness of the proposed strategy for beliefrepresentation learning tasks.</description>
      <author>example@mail.com (Dachun Sun, Ruijie Wang, Jinning Li, Ruipeng Han, Xinyi Liu, You Lyu, Tarek Abdelzaher)</author>
      <guid isPermaLink="false">2410.19176v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media</title>
      <link>http://arxiv.org/abs/2410.19193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社交媒体上的虚假信息带来了社会和技术方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究将文本特征融入图神经网络(GNNs)以提高假新闻检测的效果。&lt;h4&gt;方法&lt;/h4&gt;通过实验探讨使用基于Transformer的语言模型生成高质量的上下文文本表示。&lt;h4&gt;主要发现&lt;/h4&gt;上下文表示在Macro F1上比静态表示提高了9.3%，比没有文本特征的GNNs提高了33.8%。&lt;h4&gt;结论&lt;/h4&gt;噪声数据增强会降低性能并增加不稳定性，期望该方法能为进一步研究开辟新的方向。&lt;h4&gt;总结&lt;/h4&gt;所有代码已公开，以供进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Disinformation on social media poses both societal and technical challenges.While previous studies have integrated textual information into propagationnetworks, they have yet to fully leverage the advancements in Transformer-basedlanguage models for high-quality contextual text representations. This workinvestigates the impact of incorporating textual features into Graph NeuralNetworks (GNNs) for fake news detection. Our experiments demonstrate thatcontextual representations improve performance by 9.3% in Macro F1 over staticones and 33.8% over GNNs without textual features. However, noisy dataaugmentation degrades performance and increases instability. We expect ourmethodology to open avenues for further research, and all code is made publiclyavailable.</description>
      <author>example@mail.com (Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes)</author>
      <guid isPermaLink="false">2410.19193v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision</title>
      <link>http://arxiv.org/abs/2410.19115v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://wangrc.site/MoGePage/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出MoGe模型，用于从单目开放域图像中恢复3D几何结构。&lt;h4&gt;目的&lt;/h4&gt;直接预测捕获场景的3D点图，使用与仿射不变的表示，避免真实全局尺度和位移的影响。&lt;h4&gt;方法&lt;/h4&gt;新表示方法消除了训练中的歧义监督，并促进了有效的几何学习。提出了一系列新的全局和局部几何监督，增强模型学习高质量几何的能力。&lt;h4&gt;主要发现&lt;/h4&gt;包括一个稳健、优化和高效的点云对齐求解器，用于准确的全局形状学习，以及促进精确局部几何监督的多尺度局部几何损失。&lt;h4&gt;结论&lt;/h4&gt;在大型混合数据集上训练模型，展示出强大的泛化能力和高准确性。&lt;h4&gt;总结&lt;/h4&gt;在对多样的未见数据集的全面评估中，模型在所有任务上显著优于最先进的方法，包括单目3D点图、深度图和相机视场的估计。代码和模型将在项目页面发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present MoGe, a powerful model for recovering 3D geometry from monocularopen-domain images. Given a single image, our model directly predicts a 3Dpoint map of the captured scene with an affine-invariant representation, whichis agnostic to true global scale and shift. This new representation precludesambiguous supervision in training and facilitate effective geometry learning.Furthermore, we propose a set of novel global and local geometry supervisionsthat empower the model to learn high-quality geometry. These include a robust,optimal, and efficient point cloud alignment solver for accurate global shapelearning, and a multi-scale local geometry loss promoting precise localgeometry supervision. We train our model on a large, mixed dataset anddemonstrate its strong generalizability and high accuracy. In our comprehensiveevaluation on diverse unseen datasets, our model significantly outperformsstate-of-the-art methods across all tasks, including monocular estimation of 3Dpoint map, depth map, and camera field of view. Code and models will bereleased on our project page.</description>
      <author>example@mail.com (Ruicheng Wang, Sicheng Xu, Cassie Dai, Jianfeng Xiang, Yu Deng, Xin Tong, Jiaolong Yang)</author>
      <guid isPermaLink="false">2410.19115v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery</title>
      <link>http://arxiv.org/abs/2410.20219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by EMNLP 2024 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新意图发现对任务导向对话系统至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种统一的意图发现方法以提高知识传递效果。&lt;h4&gt;方法&lt;/h4&gt;提出伪标签增强的原型对比学习（PLPCL）模型，通过迭代利用伪标签探索潜在的正负样本，并设计整合IND和OOD样本的监督和伪信号的原型学习方法。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在发现新意图的两种不同设置中证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;在三个基准数据集和两种任务设置上的实验结果表明，我们的方法有效。&lt;h4&gt;总结&lt;/h4&gt;PLPCL模型通过结合伪标签和原型学习，缩小了意图表示与聚类过程之间的差距，提升了意图发现的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/dymanne123/PLPCL&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; New intent discovery is a crucial capability for task-oriented dialoguesystems. Existing methods focus on transferring in-domain (IND) prior knowledgeto out-of-domain (OOD) data through pre-training and clustering stages. Theyeither handle the two processes in a pipeline manner, which exhibits a gapbetween intent representation and clustering process or use typical contrastiveclustering that overlooks the potential supervised signals from the whole data.Besides, they often individually deal with open intent discovery or OODsettings. To this end, we propose a Pseudo-Label enhanced PrototypicalContrastive Learning (PLPCL) model for uniformed intent discovery. Weiteratively utilize pseudo-labels to explore potential positive/negativesamples for contrastive learning and bridge the gap between representation andclustering. To enable better knowledge transfer, we design a prototype learningmethod integrating the supervised and pseudo signals from IND and OOD samples.In addition, our method has been proven effective in two different settings ofdiscovering new intents. Experiments on three benchmark datasets and two tasksettings demonstrate the effectiveness of our approach.</description>
      <author>example@mail.com (Yimin Deng, Yuxia Wu, Guoshuai Zhao, Li Zhu, Xueming Qian)</author>
      <guid isPermaLink="false">2410.20219v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>KA$^2$ER: Knowledge Adaptive Amalgamation of ExpeRts for Medical Images Segmentation</title>
      <link>http://arxiv.org/abs/2410.21085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted to MICCAI2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近期发布了多种用于医学图像分析的基础模型，如MedSAM和SwinUNETR，这些模型在多个任务中证明了其有效性。&lt;h4&gt;目的&lt;/h4&gt;针对现实世界医学数据的异质性和非均匀性，提出一种自适应融合知识框架，以提高模型在特定医学图像分割任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;首先为每个任务训练基于nnUNet的专家模型，并重用预训练的SwinUNETR作为目标基础模型。接着将输入数据编码到基础模型和专家模型中，并将其主干特征共同投影到自适应融合层。&lt;h4&gt;主要发现&lt;/h4&gt;通过设计层次注意机制，实现目标模型与所有专家的隐藏层特征知识的自适应融合，有效减少了因任务间差异引起的领域转移。&lt;h4&gt;结论&lt;/h4&gt;在多个挑战性任务上进行的广泛实验表明，该基础模型在现实世界医学图像分割中具有良好的有效性和适应性。&lt;h4&gt;总结&lt;/h4&gt;提出的自适应融合知识框架能够有效应对医学图像分割中的领域转移问题，提升模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, many foundation models for medical image analysis such as MedSAM,SwinUNETR have been released and proven to be useful in multiple tasks.However, considering the inherent heterogeneity and inhomogeneity of real-worldmedical data, directly applying these models to specific medical imagesegmentation tasks often leads to negative domain shift effects, which canseverely weaken the model's segmentation capabilities. To this end, we proposean adaptive amalgamation knowledge framework that aims to train a versatilefoundation model to handle the joint goals of multiple expert models, eachspecialized for a distinct task. Specifically, we first train an nnUNet-basedexpert model for each task, and reuse the pre-trained SwinUNTER as the targetfoundation model. Then, the input data for all challenging tasks are encoded inthe foundation model and the expert models, respectively, and their backbonefeatures are jointly projected into the adaptive amalgamation layer. Within thehidden layer, the hierarchical attention mechanisms are designed to achieveadaptive merging of the target model to the hidden layer feature knowledge ofall experts, which significantly reduces the domain shift arising from theinter-task differences. Finally, the gold amalgamated features and the promptfeatures are fed into the mask decoder to obtain the segmentation results.Extensive experiments conducted in these challenging tasks demonstrate theeffectiveness and adaptability of our foundation model for real-world medicalimage segmentation.</description>
      <author>example@mail.com (Shangde Gao, Yichao Fu, Ke Liu, Hongxia Xu, Jian Wu)</author>
      <guid isPermaLink="false">2410.21085v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Can Self Supervision Rejuvenate Similarity-Based Link Prediction?</title>
      <link>http://arxiv.org/abs/2410.19183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管基于端到端学习的链接预测方法取得了显著进展，但在没有已知链接标签的无监督场景中，传统的基于相似性的链接预测方法仍然重要。&lt;h4&gt;目的&lt;/h4&gt;解决在基于相似性的链接预测中选择节点特征的挑战，以提高性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新方法：自监督相似性链接预测（3SLP），该方法结合了自监督图学习技术，适用于无监督条件下的相似性链接预测。&lt;h4&gt;主要发现&lt;/h4&gt;3SLP引入了双视图对比节点表示学习（DCNRL），通过数据增强和节点表示学习开发更具信息量的节点表示，实验结果表明3SLP在基准数据集上表现优异，AUC比传统方法提高了最多21.2%。&lt;h4&gt;结论&lt;/h4&gt;3SLP在无监督情况下显著提升了基于相似性的链接预测性能，验证了自监督学习在此领域的有效性。&lt;h4&gt;总结&lt;/h4&gt;自监督相似性链接预测方法（3SLP）通过改进节点表示学习，克服了传统方法的局限性，展现出更好的链接预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although recent advancements in end-to-end learning-based link prediction(LP) methods have shown remarkable capabilities, the significance oftraditional similarity-based LP methods persists in unsupervised scenarioswhere there are no known link labels. However, the selection of node featuresfor similarity computation in similarity-based LP can be challenging. Lessinformative node features can result in suboptimal LP performance. To addressthese challenges, we integrate self-supervised graph learning techniques intosimilarity-based LP and propose a novel method: Self-SupervisedSimilarity-based LP (3SLP). 3SLP is suitable for the unsupervised condition ofsimilarity-based LP without the assistance of known link labels. Specifically,3SLP introduces a dual-view contrastive node representation learning (DCNRL)with crafted data augmentation and node representation learning. DCNRL isdedicated to developing more informative node representations, replacing thenode attributes as inputs in the similarity-based LP backbone. Extensiveexperiments over benchmark datasets demonstrate the salient improvement of3SLP, outperforming the baseline of traditional similarity-based LP by up to21.2% (AUC).</description>
      <author>example@mail.com (Chenhan Zhang, Weiqi Wang, Zhiyi Tian, James Jianqiao Yu, Mohamed Ali Kaafar, An Liu, Shui Yu)</author>
      <guid isPermaLink="false">2410.19183v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Double Difference Earthquake Location with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.19323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;双差地震重定位是许多地震目录开发工作流程中的重要组成部分。该技术通过最小化来自附近源波到达时间的差异测量，实现事件之间的高分辨率相对重定位，提升了对断层的解析度和地震活动的解读。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于图神经网络的双差重定位框架，旨在最小化目录的双差残差以定位地震。&lt;h4&gt;方法&lt;/h4&gt;采用Graph Neural Network (GNN) 处理地震数据，通过批处理和采样方法，使其能够扩展到任意大的目录。架构使用一个图表示站点，另一个图表示源，并创建两个图之间的笛卡尔积图，以捕捉站点和源之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;在北加州、土耳其和北智利的多种测试案例中获得了高分辨率的重定位结果，显示出模型对多种损失函数和定位目标的适应性，包括学习站点修正和映射到不同目录的参考框架。&lt;h4&gt;结论&lt;/h4&gt;GNN方法在双差重定位方面展现出良好的前景，能够扩展到非常大的目录，并为重定位问题提供新的见解。&lt;h4&gt;总结&lt;/h4&gt;GraphDD框架通过图神经网络实现了高效的双差重定位，具备良好的扩展性和适应性，为地震研究提供了新的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Double difference earthquake relocation is an essential component of manyearthquake catalog development workflows. This technique produceshigh-resolution relative relocations between events by minimizing differentialmeasurements of the arrival times of waves from nearby sources, whichhighlights the resolution of faults and improves interpretation of seismicactivity. The inverse problem is typically solved iteratively usingconjugate-gradient minimization, however the cost scales significantly with thetotal number of sources and stations considered. Here we propose a Graph NeuralNetwork (GNN) based earthquake double-difference relocation framework, GraphDouble Difference (GraphDD), that is trained to minimize the double-differenceresiduals of a catalog to locate earthquakes. Through batching and sampling themethod can scale to arbitrarily large catalogs. Our architecture uses one graphto represent the stations, a second graph to represent the sources, and createsthe Cartesian product graph between the two graphs to capture the relationshipsbetween the stations and sources (e.g., the residuals and travel time partialderivatives). This key feature allows a natural architecture that can be usedto minimize the double-difference residuals. We implement our model on severaldistinct test cases including seismicity from northern California, Turkiye, andnorthern Chile, which have highly variable data quality, and station and sourcedistributions. We obtain high resolution relocations in these tests, and ourmodel shows adaptability to variable types of loss functions and locationobjectives, including learning station corrections and mapping into thereference frame of a different catalog. Our results suggest that a GNN approachto double-difference relocation is a promising direction for scaling to verylarge catalogs and gaining new insights into the relocation problem.</description>
      <author>example@mail.com (Ian W. McBrearty, Gregory C. Beroza)</author>
      <guid isPermaLink="false">2410.19323v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fusion-then-Distillation: Toward Cross-modal Positive Distillation for Domain Adaptive 3D Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.19446v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在跨模态无监督领域适应中，模型在源领域数据（如合成数据）上训练，并适应目标领域数据（如真实世界数据），而不访问目标注释。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的融合-再蒸馏（FtD++）方法，以探索源领域和目标领域的跨模态正向蒸馏，用于3D语义分割。&lt;h4&gt;方法&lt;/h4&gt;FtD++实现了输出分布的一致性，不仅在2D图像和3D点云之间，也在源领域和增强领域之间。该方法包括三个关键成分：1) 模型无关的特征融合模块，用于生成交叉模态融合表示；2) 跨模态正向蒸馏，结合源领域的语义内容和目标领域的风格；3) 跨模态去偏伪标签，通过自我训练方式建模伪标签的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验报告了在无监督和半监督设置下的多个领域适应场景中的最先进结果。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了新的FtD++方法在跨模态无监督领域适应中的有效性，促进了源领域与目标领域之间的对齐。&lt;h4&gt;总结&lt;/h4&gt;通过融合和蒸馏策略，FtD++在3D语义分割任务中展现了优越的表现，推动了跨模态学习的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/barcaaaa/ftd-plusplus&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In cross-modal unsupervised domain adaptation, a model trained onsource-domain data (e.g., synthetic) is adapted to target-domain data (e.g.,real-world) without access to target annotation. Previous methods seek tomutually mimic cross-modal outputs in each domain, which enforces a classprobability distribution that is agreeable in different domains. However, theyoverlook the complementarity brought by the heterogeneous fusion in cross-modallearning. In light of this, we propose a novel fusion-then-distillation (FtD++)method to explore cross-modal positive distillation of the source and targetdomains for 3D semantic segmentation. FtD++ realizes distribution consistencybetween outputs not only for 2D images and 3D point clouds but also forsource-domain and augment-domain. Specially, our method contains three keyingredients. First, we present a model-agnostic feature fusion module togenerate the cross-modal fusion representation for establishing a latent space.In this space, two modalities are enforced maximum correlation andcomplementarity. Second, the proposed cross-modal positive distillationpreserves the complete information of multi-modal input and combines thesemantic content of the source domain with the style of the target domain,thereby achieving domain-modality alignment. Finally, cross-modal debiasedpseudo-labeling is devised to model the uncertainty of pseudo-labels via aself-training manner. Extensive experiments report state-of-the-art results onseveral domain adaptive scenarios under unsupervised and semi-supervisedsettings. Code is available at https://github.com/Barcaaaa/FtD-PlusPlus.</description>
      <author>example@mail.com (Yao Wu, Mingwei Xing, Yachao Zhang, Yuan Xie, Yanyun Qu)</author>
      <guid isPermaLink="false">2410.19446v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ANOMIX: A Simple yet Effective Hard Negative Generation via Mixing for Graph Anomaly Detection</title>
      <link>http://arxiv.org/abs/2410.20310v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）通常需要大量样本。&lt;h4&gt;目的&lt;/h4&gt;提出一种减少样本数量的方法，利用困难负样本（如Mixup）来改善图异常检测（GAD）。&lt;h4&gt;方法&lt;/h4&gt;提出ANOMIX框架，包含新颖的图混合方法ANOMIX-M和多层次对比，用于GAD。&lt;h4&gt;主要发现&lt;/h4&gt;ANOMIX-M能够有效混合输入图中的异常和正常数据，生成对GCL有重要作用的困难负样本。&lt;h4&gt;结论&lt;/h4&gt;ANOMIX是首个尝试通过图混合生成GAD任务的困难负样本的方法，且在准确性和效率上表现优异。具体表现为AUC提高最多5.49%，速度提升1.76%；同时样本数量减少近80%。&lt;h4&gt;总结&lt;/h4&gt;ANOMIX框架通过创新的方法显著提升了图异常检测的性能，代码可在指定链接获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/missinghwan/anomix&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph contrastive learning (GCL) generally requires a large number ofsamples. The one of the effective ways to reduce the number of samples is usinghard negatives (e.g., Mixup). Designing mixing-based approach for GAD can bedifficult due to imbalanced data or limited number of anomalies. We proposeANOMIX, a framework that consists of a novel graph mixing approach, ANOMIX-M,and multi-level contrasts for GAD. ANOMIX-M can effectively mix abnormality andnormality from input graph to generate hard negatives, which are important forefficient GCL. ANOMIX is (a) A first mixing approach: firstly attempting graphmixing to generate hard negatives for GAD task and node- and subgraph-levelcontrasts to distinguish underlying anomalies. (b) Accurate: winning thehighest AUC, up to 5.49% higher and 1.76% faster. (c) Effective: reducing thenumber of samples nearly 80% in GCL. Code is available athttps://github.com/missinghwan/ANOMIX.</description>
      <author>example@mail.com (Hwan Kim, Junghoon Kim, Sungsu Lim)</author>
      <guid isPermaLink="false">2410.20310v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal AI for comprehensive breast cancer prognostication</title>
      <link>http://arxiv.org/abs/2410.21256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;乳腺癌的治疗选择受分子亚型和临床特征的指导，复发风险评估对个性化治疗至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于数字病理和临床特征的乳腺癌患者分层测试，以提高治疗选择的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用基于视觉变换器的全癌症基础模型，结合自监督学习，从数字化的H&amp;E染色切片中提取特征，并与临床数据整合，形成多模态AI测试。&lt;h4&gt;主要发现&lt;/h4&gt;该测试在来自七个国家的8,161名乳腺癌患者的数据中开发和评估，主要终点（无病生存期）的预测C-index为0.71，AI测试在准确性上优于标准的Oncotype DX检测。&lt;h4&gt;结论&lt;/h4&gt;该AI测试在所有主要乳腺癌亚型中表现出稳健的准确性，尤其是在目前临床指南未推荐的TNBC中，表明其可以改善准确性，扩大适用范围，并增强治疗选择工具的可及性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了AI测试在乳腺癌治疗选择中的潜力，尤其是在提高复发预测准确性方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Treatment selection in breast cancer is guided by molecular subtypes andclinical characteristics. Recurrence risk assessment plays a crucial role inpersonalizing treatment. Current methods, including genomic assays, havelimited accuracy and clinical utility, leading to suboptimal decisions for manypatients. We developed a test for breast cancer patient stratification based ondigital pathology and clinical characteristics using novel AI methods.Specifically, we utilized a vision transformer-based pan-cancer foundationmodel trained with self-supervised learning to extract features from digitizedH&amp;E-stained slides. These features were integrated with clinical data to form amulti-modal AI test predicting cancer recurrence and death. The test wasdeveloped and evaluated using data from a total of 8,161 breast cancer patientsacross 15 cohorts originating from seven countries. Of these, 3,502 patientsfrom five cohorts were used exclusively for evaluation, while the remainingpatients were used for training. Our test accurately predicted our primaryendpoint, disease-free interval, in the five external cohorts (C-index: 0.71[0.68-0.75], HR: 3.63 [3.02-4.37, p&lt;0.01]). In a direct comparison (N=858), theAI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay,with a C-index of 0.67 [0.61-0.74] versus 0.61 [0.49-0.73], respectively.Additionally, the AI test added independent information to Oncotype DX in amultivariate analysis (HR: 3.11 [1.91-5.09, p&lt;0.01)]). The test demonstratedrobust accuracy across all major breast cancer subtypes, including TNBC(C-index: 0.71 [0.62-0.81], HR: 3.81 [2.35-6.17, p=0.02]), where no diagnostictools are currently recommended by clinical guidelines. These results suggestthat our AI test can improve accuracy, extend applicability to a wider range ofpatients, and enhance access to treatment selection tools.</description>
      <author>example@mail.com (Jan Witowski, Ken Zeng, Joseph Cappadona, Jailan Elayoubi, Elena Diana Chiru, Nancy Chan, Young-Joon Kang, Frederick Howard, Irina Ostrovnaya, Carlos Fernandez-Granda, Freya Schnabel, Ugur Ozerdem, Kangning Liu, Zoe Steinsnyder, Nitya Thakore, Mohammad Sadic, Frank Yeung, Elisa Liu, Theodore Hill, Benjamin Swett, Danielle Rigau, Andrew Clayburn, Valerie Speirs, Marcus Vetter, Lina Sojak, Simone Muenst Soysal, Daniel Baumhoer, Khalil Choucair, Yu Zong, Lina Daoud, Anas Saad, Waleed Abdulsattar, Rafic Beydoun, Jia-Wern Pan, Haslina Makmur, Soo-Hwang Teo, Linda Ma Pak, Victor Angel, Dovile Zilenaite-Petrulaitiene, Arvydas Laurinavicius, Natalie Klar, Brian D. Piening, Carlo Bifulco, Sun-Young Jun, Jae Pak Yi, Su Hyun Lim, Adam Brufsky, Francisco J. Esteva, Lajos Pusztai, Yann LeCun, Krzysztof J. Geras)</author>
      <guid isPermaLink="false">2410.21256v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ST-NeRP: Spatial-Temporal Neural Representation Learning with Prior Embedding for Patient-specific Imaging Study</title>
      <link>http://arxiv.org/abs/2410.19283v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages with 10 figures and 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在治疗过程中，影像学常用于监测疾病进展和评估治疗反应，但可靠捕捉和预测患者特定图像序列的时空解剖变化是一项重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个计算框架，以满足多种实际应用的需求。&lt;h4&gt;方法&lt;/h4&gt;提出了一种空间-时间神经表示学习的策略（ST-NeRP），利用隐式神经表示网络（INR）将参考时间点的图像编码为先验嵌入，并学习一个时空连续变形函数。&lt;h4&gt;主要发现&lt;/h4&gt;ST-NeRP模型在多种序列图像系列（如4D CT和纵向CT数据集）中的应用显示出良好的效果。&lt;h4&gt;结论&lt;/h4&gt;ST-NeRP模型在监测患者治疗过程中的解剖变化方面具有显著潜力。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种新的方法来提高患者特定成像研究的准确性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; During and after a course of therapy, imaging is routinely used to monitorthe disease progression and assess the treatment responses. Despite of itssignificance, reliably capturing and predicting the spatial-temporal anatomicchanges from a sequence of patient-specific image series presents aconsiderable challenge. Thus, the development of a computational frameworkbecomes highly desirable for a multitude of practical applications. In thiscontext, we propose a strategy of Spatial-Temporal Neural Representationlearning with Prior embedding (ST-NeRP) for patient-specific imaging study. Ourstrategy involves leveraging an Implicit Neural Representation (INR) network toencode the image at the reference time point into a prior embedding.Subsequently, a spatial-temporally continuous deformation function is learnedthrough another INR network. This network is trained using the wholepatient-specific image sequence, enabling the prediction of deformation fieldsat various target time points. The efficacy of the ST-NeRP model isdemonstrated through its application to diverse sequential image series,including 4D CT and longitudinal CT datasets within thoracic and abdominalimaging. The proposed ST-NeRP model exhibits substantial potential in enablingthe monitoring of anatomical changes within a patient throughout thetherapeutic journey.</description>
      <author>example@mail.com (Liang Qiu, Liyue Shen, Lianli Liu, Junyan Liu, Yizheng Chen, Lei Xing)</author>
      <guid isPermaLink="false">2410.19283v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>An Enhanced Hierarchical Planning Framework for Multi-Robot Autonomous Exploration</title>
      <link>http://arxiv.org/abs/2410.19373v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多机器人系统的自主环境探索在救援任务、探索活动等方面具有广泛应用。&lt;h4&gt;目的&lt;/h4&gt;解决当前方法在短视性、忽视长期影响及高维学习空间收敛困难等方面的局限。&lt;h4&gt;方法&lt;/h4&gt;提出一种创新的集成策略，将基于边界的方法的低维动作空间效率与基于深度强化学习（DRL）的方法的长远性和最优性相结合，构建三层规划框架。&lt;h4&gt;主要发现&lt;/h4&gt;与基线方法相比，该框架在环境探索中所需时间步骤更少，数据传输减少超过30%。&lt;h4&gt;结论&lt;/h4&gt;所提方法在效率和性能方面优于传统方法，能够有效提升多机器人系统的环境探索能力。&lt;h4&gt;总结&lt;/h4&gt;通过综合利用边界识别、图神经网络和局部路径规划，显著提高了多机器人系统的探索效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The autonomous exploration of environments by multi-robot systems is acritical task with broad applications in rescue missions, explorationendeavors, and beyond. Current approaches often rely on either greedy frontierselection or end-to-end deep reinforcement learning (DRL) methods, yet thesemethods are frequently hampered by limitations such as short-sightedness,overlooking long-term implications, and convergence difficulties stemming fromthe intricate high-dimensional learning space. To address these challenges,this paper introduces an innovative integration strategy that combines thelow-dimensional action space efficiency of frontier-based methods with thefar-sightedness and optimality of DRL-based approaches. We propose athree-tiered planning framework that first identifies frontiers in free space,creating a sparse map representation that lightens data transmission burdensand reduces the DRL action space's dimensionality. Subsequently, we develop amulti-graph neural network (mGNN) that incorporates states of potential targetsand robots, leveraging policy-based reinforcement learning to computeaffinities, thereby superseding traditional heuristic utility values. Lastly,we implement local routing planning through subsequence search, which avoidsexhaustive sequence traversal. Extensive validation across diverse scenariosand comprehensive simulation results demonstrate the effectiveness of ourproposed method. Compared to baseline approaches, our framework achievesenvironmental exploration with fewer time steps and a notable reduction of over30% in data transmission, showcasing its superiority in terms of efficiency andperformance.</description>
      <author>example@mail.com (Gengyuan Cai, Luosong Guo, Xiangmao Chang)</author>
      <guid isPermaLink="false">2410.19373v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FastPCI: Motion-Structure Guided Fast Point Cloud Frame Interpolation</title>
      <link>http://arxiv.org/abs/2410.19573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in ECCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云帧插值是一项挑战性任务，涉及准确的场景流估计和几何结构的保持。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法以提高点云帧插值的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;引入Pyramid Convolution-Transformer架构，通过混合卷积-变换器改善局部和长程特征学习，并采用金字塔网络以提供多层次特征，减少计算量。同时提出双向运动结构块以提高场景流估计的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;FastPCI在KITTI数据集中相较于现有技术PointINet和NeuralPCI显著提高了插值精度（例如，Chamfer距离分别减少26.6%和18.3%），并且速度提升超过10倍和600倍。&lt;h4&gt;结论&lt;/h4&gt;FastPCI在点云帧插值任务中表现出色，具有高效率和高准确性，代码可在GitHub上获取。&lt;h4&gt;总结&lt;/h4&gt;FastPCI通过创新的架构和方法，显著提升了点云帧插值的性能，解决了传统方法的不足。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/genuszty/fastpci&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud frame interpolation is a challenging task that involves accuratescene flow estimation across frames and maintaining the geometry structure.Prevailing techniques often rely on pre-trained motion estimators or intensivetesting-time optimization, resulting in compromised interpolation accuracy orprolonged inference. This work presents FastPCI that introduces PyramidConvolution-Transformer architecture for point cloud frame interpolation. Ourhybrid Convolution-Transformer improves the local and long-range featurelearning, while the pyramid network offers multilevel features and reduces thecomputation. In addition, FastPCI proposes a unique Dual-DirectionMotion-Structure block for more accurate scene flow estimation. Our design ismotivated by two facts: (1) accurate scene flow preserves 3D structure, and (2)point cloud at the previous timestep should be reconstructable using reversemotion from future timestep. Extensive experiments show that FastPCIsignificantly outperforms the state-of-the-art PointINet and NeuralPCI withnotable gains (e.g. 26.6% and 18.3% reduction in Chamfer Distance in KITTI),while being more than 10x and 600x faster, respectively. Code is available athttps://github.com/genuszty/FastPCI</description>
      <author>example@mail.com (Tianyu Zhang, Guocheng Qian, Jin Xie, Jian Yang)</author>
      <guid isPermaLink="false">2410.19573v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference</title>
      <link>http://arxiv.org/abs/2410.21262v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模基础模型在语言和视觉任务中表现优异，但其密集的矩阵-向量运算在推理过程中面临显著的计算挑战。&lt;h4&gt;目的&lt;/h4&gt;提出Block-Level Adaptive Structured (BLAST)矩阵，以学习和利用深度学习模型线性层权重矩阵中的高效结构。&lt;h4&gt;方法&lt;/h4&gt;BLAST矩阵相比于现有的结构化矩阵提供了更大的灵活性，可以表示从数据中学习或从已有权重矩阵计算出的各种结构。&lt;h4&gt;主要发现&lt;/h4&gt;{'中型模型': {'模型名': ['ViT', 'GPT-2'], '性能提升': '训练使用BLAST权重后，复杂度分别降低70%和40%。'}, '大型模型': {'模型名': ['Llama-7B', 'DiT-XL'], '压缩效果': '实现2倍压缩，且性能下降幅度在所有测试的结构化矩阵中最低。'}}&lt;h4&gt;结论&lt;/h4&gt;BLAST矩阵在语言和视觉任务的压缩中展现了显著的效率与灵活性。&lt;h4&gt;总结&lt;/h4&gt;BLAST矩阵为深度学习模型提供了一种高效的结构化权重表示方式，有助于在性能与计算复杂度之间取得良好平衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/changwoolee/blast&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale foundation models have demonstrated exceptional performance inlanguage and vision tasks. However, the numerous dense matrix-vector operationsinvolved in these large networks pose significant computational challengesduring inference. To address these challenges, we introduce the Block-LevelAdaptive STructured (BLAST) matrix, designed to learn and leverage efficientstructures prevalent in the weight matrices of linear layers within deeplearning models. Compared to existing structured matrices, the BLAST matrixoffers substantial flexibility, as it can represent various types of structuresthat are either learned from data or computed from pre-existing weightmatrices. We demonstrate the efficiency of using the BLAST matrix forcompressing both language and vision tasks, showing that (i) for medium-sizedmodels such as ViT and GPT-2, training with BLAST weights boosts performancewhile reducing complexity by 70% and 40%, respectively; and (ii) for largefoundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2xcompression while exhibiting the lowest performance degradation among alltested structured matrices. Our code is available athttps://github.com/changwoolee/BLAST.</description>
      <author>example@mail.com (Changwoo Lee, Soo Min Kwon, Qing Qu, Hun-Seok Kim)</author>
      <guid isPermaLink="false">2410.21262v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Balancing the Scales: Enhancing Fairness in Facial Expression Recognition with Latent Alignment</title>
      <link>http://arxiv.org/abs/2410.19444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动识别情感意图的面部表情已在计算机视觉领域得到深入研究。&lt;h4&gt;目的&lt;/h4&gt;探讨如何减轻面部表情识别系统中的偏见，提高模型的公平性和准确性。&lt;h4&gt;方法&lt;/h4&gt;利用基于潜在空间的表示学习来缓解面部表情识别中的偏见。&lt;h4&gt;主要发现&lt;/h4&gt;现有数据集大多采用人工标注，容易引入个体人口统计偏见，且缺乏对各种社会文化人口群体的公平代表。&lt;h4&gt;结论&lt;/h4&gt;在面部表情识别领域，偏见分析和缓解是相对较少探索的领域，但本研究通过新方法提升了模型的表现。&lt;h4&gt;总结&lt;/h4&gt;本研究强调对面部表情识别数据集中的偏见进行深入分析和解决，以促进公平性和准确性的提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatically recognizing emotional intent using facial expression has been athoroughly investigated topic in the realm of computer vision. FacialExpression Recognition (FER), being a supervised learning task, relies heavilyon substantially large data exemplifying various socio-cultural demographicattributes. Over the past decade, several real-world in-the-wild FER datasetsthat have been proposed were collected through crowd-sourcing or web-scraping.However, most of these practically used datasets employ a manual annotationmethodology for labeling emotional intent, which inherently propagatesindividual demographic biases. Moreover, these datasets also lack an equitablerepresentation of various socio-cultural demographic groups, thereby inducing aclass imbalance. Bias analysis and its mitigation have been investigated acrossmultiple domains and problem settings, however, in the FER domain, this is arelatively lesser explored area. This work leverages representation learningbased on latent spaces to mitigate bias in facial expression recognitionsystems, thereby enhancing a deep learning model's fairness and overallaccuracy.</description>
      <author>example@mail.com (Syed Sameen Ahmad Rizvi, Aryan Seth, Pratik Narang)</author>
      <guid isPermaLink="false">2410.19444v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DeMuVGN: Effective Software Defect Prediction Model by Learning Multi-view Software Dependency via Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.19550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;软件缺陷预测(SDP)旨在识别软件开发中的高风险缺陷模块，以优化资源分配。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的缺陷预测模型，以更好地捕捉与缺陷相关的信息，尤其是开发者因素。&lt;h4&gt;方法&lt;/h4&gt;提出DeMuVGN模型，通过图神经网络学习多视图软件依赖关系，使用综合数据、调用和开发者依赖的多视图软件依赖图(MSDG)，并采用SMOTE技术解决类别不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;在对八个开源项目的案例研究中，DeMuVGN显示出显著改进：i) 多视图图模型的F1分数比单视图模型提高11.1%到12.1%；ii) DeMuVGN在项目内上下文中的F1分数提高17.4%到45.8%，在跨项目上下文中提高17.9%到41.0%。&lt;h4&gt;结论&lt;/h4&gt;DeMuVGN在软件演化方面表现出色，后期软件版本的改进更为显著，其在不同项目中的强大表现突显了其通用性。&lt;h4&gt;未来建议&lt;/h4&gt;建议未来研究关注多视图依赖图在成熟及新开发项目中的缺陷预测应用。&lt;h4&gt;总结&lt;/h4&gt;DeMuVGN模型通过综合依赖关系和先进的样本平衡技术，在缺陷预测中展示了较好的性能和广泛适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Software defect prediction (SDP) aims to identify high-risk defect modules insoftware development, optimizing resource allocation. While previous studiesshow that dependency network metrics improve defect prediction, most methodsfocus on code-based dependency graphs, overlooking developer factors. Currentmetrics, based on handcrafted features like ego and global network metrics,fail to fully capture defect-related information. To address this, we proposeDeMuVGN, a defect prediction model that learns multi-view software dependencyvia graph neural networks. We introduce a Multi-view Software Dependency Graph(MSDG) that integrates data, call, and developer dependencies. DeMuVGN alsoleverages the Synthetic Minority Oversampling Technique (SMOTE) to addressclass imbalance and enhance defect module identification. In a case study ofeight open-source projects across 20 versions, DeMuVGN demonstrates significantimprovements: i) models based on multi-view graphs improve F1 scores by 11.1%to 12.1% over single-view models; ii) DeMuVGN improves F1 scores by 17.4% to45.8% in within-project contexts and by 17.9% to 41.0% in cross-projectcontexts. Additionally, DeMuVGN excels in software evolution, showing moreimprovement in later-stage software versions. Its strong performance acrossdifferent projects highlights its generalizability. We recommend futureresearch focus on multi-view dependency graphs for defect prediction in bothmature and newly developed projects.</description>
      <author>example@mail.com (Yu Qiao, Lina Gong, Yu Zhao, Yongwei Wang, Mingqiang Wei)</author>
      <guid isPermaLink="false">2410.19550v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors</title>
      <link>http://arxiv.org/abs/2410.19680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurlPS 2024. Project page:
  https://chenchao15.github.io/LocalN2NM/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在许多计算机视觉应用中，从点云中准确估计有符号距离函数（SDF）非常重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，结合数据驱动和过拟合方法的优点，以提高神经SDF学习的泛化能力、推理速度和准确性。&lt;h4&gt;方法&lt;/h4&gt;引入一种新颖的统计推理算法，能够在局部区域内微调基于数据驱动的先验，而无需有符号距离监督、干净的点云或点法线。&lt;h4&gt;主要发现&lt;/h4&gt;与最新方法的数值和视觉比较显示，在表面重建和点云去噪方面，该方法优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法能够更快地收敛，并在初始化阶段提供良好的起始点，适用于高噪声点云等挑战性场景。&lt;h4&gt;代码&lt;/h4&gt;代码可在https://github.com/chenchao15/LocalN2NM获取。&lt;h4&gt;总结&lt;/h4&gt;本研究通过新算法的引入，解决了现有方法在泛化能力和推理速度上的局限，展示了在多个基准测试上的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; It is important to estimate an accurate signed distance function (SDF) from apoint cloud in many computer vision applications. The latest methods learnneural SDFs using either a data-driven based or an overfitting-based strategy.However, these two kinds of methods are with either poor generalization or slowconvergence, which limits their capability under challenging scenarios likehighly noisy point clouds. To resolve this issue, we propose a method topromote pros of both data-driven based and overfitting-based methods for bettergeneralization, faster inference, and higher accuracy in learning neural SDFs.We introduce a novel statistical reasoning algorithm in local regions which isable to finetune data-driven based priors without signed distance supervision,clean point cloud, or point normals. This helps our method start with a goodinitialization, and converge to a minimum in a much faster way. Our numericaland visual comparisons with the state-of-the-art methods show our superiorityover these methods in surface reconstruction and point cloud denoising onwidely used shape and scene benchmarks. The code is available athttps://github.com/chenchao15/LocalN2NM.</description>
      <author>example@mail.com (Chao Chen, Yu-Shen Liu, Zhizhong Han)</author>
      <guid isPermaLink="false">2410.19680v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization</title>
      <link>http://arxiv.org/abs/2410.21411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024. Project page:
  https://mengzibin.github.io/SocialGPT.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社会关系推理旨在从图像中识别朋友、配偶和同事等关系类别。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在可推广性和可解释性方面的局限。&lt;h4&gt;方法&lt;/h4&gt;提出一个名为{name}的框架，结合视觉基础模型（VFM）和大型语言模型（LLM）的能力，通过模块化框架实现社会关系识别。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在两个数据库上实现了具有竞争力的零样本结果，并能生成可解释的回答，LLM能够提供基于语言的解释。&lt;h4&gt;结论&lt;/h4&gt;提出的贪婪段落提示优化（GSPO）方法显著提升了性能，并且该方法能够适应不同的图像风格。&lt;h4&gt;总结&lt;/h4&gt;该研究通过将视觉分类任务转化为LLM的生成任务，引入了系统设计原则，推动了社会关系识别的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mengzibin/socialgpt&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social relation reasoning aims to identify relation categories such asfriends, spouses, and colleagues from images. While current methods adopt theparadigm of training a dedicated network end-to-end using labeled image data,they are limited in terms of generalizability and interpretability. To addressthese issues, we first present a simple yet well-crafted framework named{\name}, which combines the perception capability of Vision Foundation Models(VFMs) and the reasoning capability of Large Language Models (LLMs) within amodular framework, providing a strong baseline for social relation recognition.Specifically, we instruct VFMs to translate image content into a textual socialstory, and then utilize LLMs for text-based reasoning. {\name} introducessystematic design principles to adapt VFMs and LLMs separately and bridge theirgaps. Without additional model training, it achieves competitive zero-shotresults on two databases while offering interpretable answers, as LLMs cangenerate language-based explanations for the decisions. The manual promptdesign process for LLMs at the reasoning phase is tedious and an automatedprompt optimization method is desired. As we essentially convert a visualclassification task into a generative task of LLMs, automatic promptoptimization encounters a unique long prompt optimization issue. To addressthis issue, we further propose the Greedy Segment Prompt Optimization (GSPO),which performs a greedy search by utilizing gradient information at the segmentlevel. Experimental results show that GSPO significantly improves performance,and our method also generalizes to different image styles. The code isavailable at https://github.com/Mengzibin/SocialGPT.</description>
      <author>example@mail.com (Wanhua Li, Zibin Meng, Jiawei Zhou, Donglai Wei, Chuang Gan, Hanspeter Pfister)</author>
      <guid isPermaLink="false">2410.21411v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning</title>
      <link>http://arxiv.org/abs/2410.19560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在无监督视觉表示学习的最新进展中，联合嵌入预测架构（JEPA）成为了一种重要的方法，通过创新的掩码策略从未标记的图像中提取视觉特征。&lt;h4&gt;目的&lt;/h4&gt;解决JEPA存在的两个主要限制：I-JEPA的指数移动平均（EMA）无法有效防止整体崩溃，以及I-JEPA预测不准确地学习补丁表示的均值。&lt;h4&gt;方法&lt;/h4&gt;本研究提出了一种新框架，即对比JEPA（C-JEPA），将基于图像的联合嵌入预测架构与方差-不变性-协方差正则化（VICReg）策略结合，旨在有效学习方差/协方差，防止整体崩溃并确保增强视图均值的不变性。&lt;h4&gt;主要发现&lt;/h4&gt;通过实证和理论评估，C-JEPA显著提升了视觉表示学习的稳定性和质量。&lt;h4&gt;结论&lt;/h4&gt;在ImageNet-1K数据集上进行预训练时，C-JEPA在线性探测和微调性能指标上表现出快速和显著的收敛。&lt;h4&gt;总结&lt;/h4&gt;C-JEPA通过整合新策略，克服了JEPA的局限性，提升了无监督视觉表示学习的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent advancements in unsupervised visual representation learning, theJoint-Embedding Predictive Architecture (JEPA) has emerged as a significantmethod for extracting visual features from unlabeled imagery through aninnovative masking strategy. Despite its success, two primary limitations havebeen identified: the inefficacy of Exponential Moving Average (EMA) from I-JEPAin preventing entire collapse and the inadequacy of I-JEPA prediction inaccurately learning the mean of patch representations. Addressing thesechallenges, this study introduces a novel framework, namely C-JEPA(Contrastive-JEPA), which integrates the Image-based Joint-Embedding PredictiveArchitecture with the Variance-Invariance-Covariance Regularization (VICReg)strategy. This integration is designed to effectively learn thevariance/covariance for preventing entire collapse and ensuring invariance inthe mean of augmented views, thereby overcoming the identified limitations.Through empirical and theoretical evaluations, our work demonstrates thatC-JEPA significantly enhances the stability and quality of visualrepresentation learning. When pre-trained on the ImageNet-1K dataset, C-JEPAexhibits rapid and improved convergence in both linear probing and fine-tuningperformance metrics.</description>
      <author>example@mail.com (Shentong Mo, Shengbang Tong)</author>
      <guid isPermaLink="false">2410.19560v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Convolution-based Hybrid Model Approach with Representation Learning for Real-Time Acoustic Anomaly Detection</title>
      <link>http://arxiv.org/abs/2410.19722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 10 figures, ICMLC2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;早期检测工业机械组件的潜在故障对于确保操作的可靠性和安全性至关重要，从而维护机器状态监测（MCM）。&lt;h4&gt;目的&lt;/h4&gt;引入一种创新的方法来进行实时声学异常检测。&lt;h4&gt;方法&lt;/h4&gt;结合半监督时间卷积、表征学习和时间卷积网络（TCN）的混合模型策略，有效处理声学数据中的各种复杂异常模式。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在性能上优于该领域的已建立研究，并通过定量证据和可视化表示（如t-SNE图）进一步验证其有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法展示了在声学异常检测中的有效性，证明了其在工业应用中的潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种有效的声学异常检测方法，能够提升工业机械的故障检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3651671.3651693&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The early detection of potential failures in industrial machinery componentsis paramount for ensuring the reliability and safety of operations, therebypreserving Machine Condition Monitoring (MCM). This research addresses thisimperative by introducing an innovative approach to Real-Time Acoustic AnomalyDetection. Our method combines semi-supervised temporal convolution withrepresentation learning and a hybrid model strategy with Temporal ConvolutionalNetworks (TCN) to handle various intricate anomaly patterns found in acousticdata effectively. The proposed model demonstrates superior performance comparedto established research in the field, underscoring the effectiveness of thisapproach. Not only do we present quantitative evidence of its superiority, butwe also employ visual representations, such as t-SNE plots, to furthersubstantiate the model's efficacy.</description>
      <author>example@mail.com (Sahan Dissanayaka, Manjusri Wickramasinghe, Pasindu Marasinghe)</author>
      <guid isPermaLink="false">2410.19722v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Foundation Model for Chemical Design and Property Prediction</title>
      <link>http://arxiv.org/abs/2410.21422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能在计算化学研究中取得了显著进展，但传统AI方法通常依赖于特定任务的模型设计和训练，限制了模型规模的可扩展性和跨任务的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;介绍ChemFM，一个专门为化学开发的大规模基础模型。&lt;h4&gt;方法&lt;/h4&gt;ChemFM包含多达30亿个参数，在1.78亿个分子上进行自监督因果语言建模的预训练，以提取可泛化的分子表示。可以通过全参数和参数高效的微调方法适应不同的化学应用。&lt;h4&gt;主要发现&lt;/h4&gt;ChemFM在多个化学任务中始终优于最先进的方法。在34个属性预测基准中提升了67.48%的性能，在条件分子生成任务中减少了33.31%的生成分子条件属性与实际属性之间的平均绝对偏差，在4个反应预测数据集中提高了3.7%的Top-1准确率。&lt;h4&gt;结论&lt;/h4&gt;ChemFM在预测抗生素活性和细胞毒性方面表现出色，显示出其在新型抗生素发现中的潜力。预计ChemFM将通过提供一个能够有效泛化到广泛任务的基础模型，显著推动化学研究。&lt;h4&gt;总结&lt;/h4&gt;ChemFM是为化学领域开发的强大基础模型，具有广泛的应用潜力和良好的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has significantly advanced computationalchemistry research. However, traditional AI methods often rely on task-specificmodel designs and training, which constrain both the scalability of model sizeand generalization across different tasks. Here, we introduce ChemFM, alarge-scale foundation model specifically developed for chemistry, comprisingup to 3 billion parameters. ChemFM is pre-trained on 178 million moleculesusing self-supervised causal language modeling to extract generalizablemolecular representations. This model can be adapted to diverse downstreamchemical applications using both full-parameter and parameter-efficientfine-tuning methods. ChemFM consistently outperforms state-of-the-artapproaches across multiple chemical tasks. Notably, it achieves up to 67.48%performance improvement across 34 property prediction benchmarks, up to 33.31%reduction in mean average deviation between conditioned and actual propertiesof generated molecules in conditional molecular generation tasks, and up to3.7% top-1 accuracy improvement across 4 reaction prediction datasets.Moreover, ChemFM demonstrates superior performance in predicting antibioticactivity and cytotoxicity, highlighting its potential to advance the discoveryof novel antibiotics. We anticipate that ChemFM will significantly advancechemistry research by providing a foundation model capable of effectivelygeneralizing across a broad range of tasks with minimal additional training.</description>
      <author>example@mail.com (Feiyang Cai, Tianyu Zhu, Tzuen-Rong Tzeng, Yongping Duan, Ling Liu, Srikanth Pilla, Gang Li, Feng Luo)</author>
      <guid isPermaLink="false">2410.21422v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Image and Radio Frequency Fusion for Optimizing Vehicle Positioning</title>
      <link>http://arxiv.org/abs/2410.19788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文设计了一个多模态车辆定位框架，结合信道状态信息（CSI）和图像进行车辆定位。&lt;h4&gt;目的&lt;/h4&gt;在户外场景中，考虑每辆车只能与一个基站（BS）通信，并上传其估计的CSI。&lt;h4&gt;方法&lt;/h4&gt;使用元学习的硬期望最大化（EM）算法，处理标记和未标记的CSI数据及相应的图像。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入加权损失函数，减少标签噪声，提高模型收敛性。&lt;h4&gt;结论&lt;/h4&gt;与仅使用CSI指纹的基线方法相比，提出的方法可以将定位误差减少多达61%。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的多模态车辆定位方法，显著提升了定位精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, a multi-modal vehicle positioning framework that jointlylocalizes vehicles with channel state information (CSI) and images is designed.In particular, we consider an outdoor scenario where each vehicle cancommunicate with only one BS, and hence, it can upload its estimated CSI toonly its associated BS. Each BS is equipped with a set of cameras, such that itcan collect a small number of labeled CSI, a large number of unlabeled CSI, andthe images taken by cameras. To exploit the unlabeled CSI data and positionlabels obtained from images, we design an meta-learning based hardexpectation-maximization (EM) algorithm. Specifically, since we do not know thecorresponding relationship between unlabeled CSI and the multiple vehiclelocations in images, we formulate the calculation of the training objective asa minimum matching problem. To reduce the impact of label noises caused byincorrect matching between unlabeled CSI and vehicle locations obtained fromimages and achieve better convergence, we introduce a weighted loss function onthe unlabeled datasets, and study the use of a meta-learning algorithm forcomputing the weighted loss. Subsequently, the model parameters are updatedaccording to the weighted loss function of unlabeled CSI samples and theirmatched position labels obtained from images. Simulation results show that theproposed method can reduce the positioning error by up to 61% compared to abaseline that does not use images and uses only CSI fingerprint for vehiclepositioning.</description>
      <author>example@mail.com (Ouwen Huan, Tao Luo, Mingzhe Chen)</author>
      <guid isPermaLink="false">2410.19788v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Global Graph Counterfactual Explanation: A Subgraph Mapping Approach</title>
      <link>http://arxiv.org/abs/2410.19978v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在各种实际应用中得到了广泛部署，但大多数GNNs是黑箱模型，缺乏解释。&lt;h4&gt;目的&lt;/h4&gt;通过对抗性解释来揭示GNN的决策过程，寻找输入图的最小扰动以改变GNN的预测。&lt;h4&gt;方法&lt;/h4&gt;提出GlobalGCE，一种新的全局级图对抗性解释方法，旨在识别一组子图映射规则作为目标GNN的对抗性解释。&lt;h4&gt;主要发现&lt;/h4&gt;通过这些规则，用某些重要子图替换其对抗性子图可以在大多数图上改变GNN预测至所需类别，达到最大覆盖。&lt;h4&gt;结论&lt;/h4&gt;GlobalGCE在现有基准之上表现优越，能够有效生成子图和规则。&lt;h4&gt;总结&lt;/h4&gt;GlobalGCE提供了一种新的思路来解释GNN模型，解决了信息过载和跨图关系不足的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have been widely deployed in various real-worldapplications. However, most GNNs are black-box models that lack explanations.One strategy to explain GNNs is through counterfactual explanation, which aimsto find minimum perturbations on input graphs that change the GNN predictions.Existing works on GNN counterfactual explanations primarily concentrate on thelocal-level perspective (i.e., generating counterfactuals for each individualgraph), which suffers from information overload and lacks insights into thebroader cross-graph relationships. To address such issues, we proposeGlobalGCE, a novel global-level graph counterfactual explanation method.GlobalGCE aims to identify a collection of subgraph mapping rules ascounterfactual explanations for the target GNN. According to these rules,substituting certain significant subgraphs with their counterfactual subgraphswill change the GNN prediction to the desired class for most graphs (i.e.,maximum coverage). Methodologically, we design a significant subgraph generatorand a counterfactual subgraph autoencoder in our GlobalGCE, where the subgraphsand the rules can be effectively generated. Extensive experiments demonstratethe superiority of our GlobalGCE compared to existing baselines. Our code canbe found at https://anonymous.4open.science/r/GlobalGCE-92E8.</description>
      <author>example@mail.com (Yinhan He, Wendy Zheng, Yaochen Zhu, Jing Ma, Saumitra Mishra, Natraj Raman, Ninghao Liu, Jundong Li)</author>
      <guid isPermaLink="false">2410.19978v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>LLMs Can Evolve Continually on Modality for X-Modal Reasoning</title>
      <link>http://arxiv.org/abs/2410.20178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态大语言模型（MLLMs）因其在多模态理解方面的出色能力而受到广泛关注，但现有方法在扩展新模态时面临计算负担。&lt;h4&gt;目的&lt;/h4&gt;提出PathWeave，一个灵活且可扩展的框架，支持模态切换和扩展，促进MLLMs在多模态推理方面的持续发展。&lt;h4&gt;方法&lt;/h4&gt;采用持续学习的概念，开发增量训练策略，基于预训练的MLLMs扩展新模态，利用单模态数据，无需执行联合模态预训练。引入新颖的Adapter-in-Adapter（AnA）框架，实现单模态和跨模态适配器的无缝整合，并在两种适配器之间应用MoE基础的门控模块，增强多模态交互。&lt;h4&gt;主要发现&lt;/h4&gt;通过建立名为持续学习模态（MCL）的基准，展示提出的AnA框架在学习灵活性和记忆稳定性方面的有效性。PathWeave在性能上与最先进的MLLMs相当，同时将参数训练负担减少了98.73%。&lt;h4&gt;结论&lt;/h4&gt;PathWeave为MLLMs的模态扩展和持续学习提供了高效的解决方案，降低了计算复杂度。&lt;h4&gt;总结&lt;/h4&gt;本文提出的PathWeave框架在多模态理解中具有显著优势，有助于未来多模态模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jiazuoyu/pathweave&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have gained significant attentiondue to their impressive capabilities in multimodal understanding. However,existing methods rely heavily on extensive modal-specific pretraining andjoint-modal tuning, leading to significant computational burdens when expandingto new modalities. In this paper, we propose PathWeave, a flexible and scalableframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMsto continually EVolve on modalities for $\mathbb{X}$-modal reasoning. Weleverage the concept of Continual Learning and develop an incremental trainingstrategy atop pre-trained MLLMs, enabling their expansion to new modalitiesusing uni-modal data, without executing joint-modal pretraining. In detail, anovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal andcross-modal adapters are seamlessly integrated to facilitate efficient modalityalignment and collaboration. Additionally, an MoE-based gating module isapplied between two types of adapters to further enhance the multimodalinteraction. To investigate the proposed method, we establish a challengingbenchmark called Continual Learning of Modality (MCL), which consists ofhigh-quality QA data from five distinct modalities: image, video, audio, depthand point cloud. Extensive experiments demonstrate the effectiveness of theproposed AnA framework on learning plasticity and memory stability duringcontinual learning. Furthermore, PathWeave performs comparably tostate-of-the-art MLLMs while concurrently reducing parameter training burdensby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave</description>
      <author>example@mail.com (Jiazuo Yu, Haomiao Xiong, Lu Zhang, Haiwen Diao, Yunzhi Zhuge, Lanqing Hong, Dong Wang, Huchuan Lu, You He, Long Chen)</author>
      <guid isPermaLink="false">2410.20178v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Transferring Knowledge from High-Quality to Low-Quality MRI for Adult Glioma Diagnosis</title>
      <link>http://arxiv.org/abs/2410.18698v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report, MICCAI 2024 BraTS-SSA Challenge Runner Up&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;胶质瘤是一种常见且致命的脑肿瘤，需要早期诊断以改善预后，但撒哈拉以南非洲的低质量磁共振成像技术阻碍了准确诊断。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过BraTS挑战赛，提升撒哈拉以南非洲成人胶质瘤的诊断能力。&lt;h4&gt;方法&lt;/h4&gt;采用BraTS-GLI 2021获胜解决方案的模型，使用三种训练策略：1）在BraTS-GLI 2021数据集上初始训练，并在BraTS-Africa数据集上微调；2）仅在BraTS-Africa数据集上训练；3）仅在BraTS-Africa数据集上进行2倍超分辨率增强的训练。&lt;h4&gt;主要发现&lt;/h4&gt;初始在BraTS-GLI 2021数据集训练后，微调BraTS-Africa数据集的策略效果最佳。模型在验证阶段的Dice分数分别为0.882、0.840和0.926，Hausdorff距离（95%）分数为15.324、37.518和13.971，针对增强肿瘤、肿瘤核心和整个肿瘤。&lt;h4&gt;结论&lt;/h4&gt;在比赛的最终阶段，我们的做法成功获得第二名，反映了模型和训练策略的强大和有效性。该研究为改善撒哈拉以南非洲胶质瘤的诊断提供了见解，展示了深度学习在资源有限环境中的潜力以及从高质量数据集中迁移学习的重要性。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了高质量数据集在训练中的先验知识的重要性，并展示了深度学习在低资源环境下改善胶质瘤诊断的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Glioma, a common and deadly brain tumor, requires early diagnosis forimproved prognosis. However, low-quality Magnetic Resonance Imaging (MRI)technology in Sub-Saharan Africa (SSA) hinders accurate diagnosis. This paperpresents our work in the BraTS Challenge on SSA Adult Glioma. We adopt themodel from the BraTS-GLI 2021 winning solution and utilize it with threetraining strategies: (1) initially training on the BraTS-GLI 2021 dataset withfine-tuning on the BraTS-Africa dataset, (2) training solely on theBraTS-Africa dataset, and (3) training solely on the BraTS-Africa dataset with2x super-resolution enhancement. Results show that initial training on theBraTS-GLI 2021 dataset followed by fine-tuning on the BraTS-Africa dataset hasyielded the best results. This suggests the importance of high-quality datasetsin providing prior knowledge during training. Our top-performing model achievesDice scores of 0.882, 0.840, and 0.926, and Hausdorff Distance (95%) scores of15.324, 37.518, and 13.971 for enhancing tumor, tumor core, and whole tumor,respectively, in the validation phase. In the final phase of the competition,our approach successfully secured second place overall, reflecting the strengthand effectiveness of our model and training strategies. Our approach providesinsights into improving glioma diagnosis in SSA, showing the potential of deeplearning in resource-limited settings and the importance of transfer learningfrom high-quality datasets.</description>
      <author>example@mail.com (Yanguang Zhao, Long Bai, Zhaoxi Zhang, Yanan Wu, Mobarakol Islam, Hongliang Ren)</author>
      <guid isPermaLink="false">2410.18698v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Prototypical Extreme Multi-label Classification with a Dynamic Margin Loss</title>
      <link>http://arxiv.org/abs/2410.20401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;极端多标签分类(XMC)方法在极大的标签空间中预测相关标签。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且性能卓越的XMC方法，克服计算开销和高效解决方案之间的权衡。&lt;h4&gt;方法&lt;/h4&gt;提出PRIME方法，采用原型对比学习技术，将XMC视为数据到原型的预测任务，使用浅层变换器编码器和标签原型网络来增强标签表示。&lt;h4&gt;主要发现&lt;/h4&gt;PRIME在多个公共基准测试中取得了最先进的结果，同时保持模型的高效性。&lt;h4&gt;结论&lt;/h4&gt;PRIME方法有效地改善了极端标签空间中的分类性能，并在效率和性能之间达到了良好的平衡。&lt;h4&gt;总结&lt;/h4&gt;PRIME方法通过对比学习和标签原型网络提高了极端多标签分类的效率和表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extreme Multi-label Classification (XMC) methods predict relevant labels fora given query in an extremely large label space. Recent works in XMC addressthis problem using deep encoders that project text descriptions to an embeddingspace suitable for recovering the closest labels. However, learning deep modelscan be computationally expensive in large output spaces, resulting in atrade-off between high performing brute-force approaches and efficientsolutions. In this paper, we propose PRIME, a XMC method that employs a novelprototypical contrastive learning technique to reconcile efficiency andperformance surpassing brute-force approaches. We frame XMC as adata-to-prototype prediction task where label prototypes aggregate informationfrom related queries. More precisely, we use a shallow transformer encoder thatwe coin as Label Prototype Network, which enriches label representations byaggregating text-based embeddings, label centroids and learnable free vectors.We jointly train a deep encoder and the Label Prototype Network using anadaptive triplet loss objective that better adapts to the high granularity andambiguity of extreme label spaces. PRIME achieves state-of-the-art results inseveral public benchmarks of different sizes and domains, while keeping themodel efficient.</description>
      <author>example@mail.com (Kunal Dahiya, Diego Ortego, David Jiménez)</author>
      <guid isPermaLink="false">2410.20401v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Sparse Decomposition of Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.19723v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在图表示学习中表现优越，但推理成本较高，主要由于聚合操作需要为大量节点进行内存提取，这成为在线预测应用的主要障碍。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，减少聚合过程中包含的节点数量，以应对动态节点特征的在线预测需求。&lt;h4&gt;方法&lt;/h4&gt;通过稀疏分解，学习使用经过线性变换的特征的加权和来近似节点表示，从而选择扩展邻域中的特定子集节点，达到线性复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法计算稀疏分解的最佳参数，确保对原始GNN模型的准确近似，并通过有效策略减少训练时间，提高学习过程。&lt;h4&gt;结论&lt;/h4&gt;通过大量实验表明，该方法在推理加速方面优于其他基线模型，在节点分类和时空预测任务中实现了显著的准确性提升，同时推理时间相当。&lt;h4&gt;总结&lt;/h4&gt;该研究为图神经网络的在线预测提供了有效的解决方案，能够在保证准确性的基础上显著降低推理成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNN) exhibit superior performance in graphrepresentation learning, but their inference cost can be high, due to anaggregation operation that can require a memory fetch for a very large numberof nodes. This inference cost is the major obstacle to deploying GNN modelswith \emph{online prediction} to reflect the potentially dynamic node features.To address this, we propose an approach to reduce the number of nodes that areincluded during aggregation. We achieve this through a sparse decomposition,learning to approximate node representations using a weighted sum of linearlytransformed features of a carefully selected subset of nodes within theextended neighbourhood. The approach achieves linear complexity with respect tothe average node degree and the number of layers in the graph neural network.We introduce an algorithm to compute the optimal parameters for the sparsedecomposition, ensuring an accurate approximation of the original GNN model,and present effective strategies to reduce the training time and improve thelearning process. We demonstrate via extensive experiments that our methodoutperforms other baselines designed for inference speedup, achievingsignificant accuracy gains with comparable inference times for both nodeclassification and spatio-temporal forecasting tasks.</description>
      <author>example@mail.com (Yaochen Hu, Mai Zeng, Ge Zhang, Pavel Rumiantsev, Liheng Ma, Yingxue Zhang, Mark Coates)</author>
      <guid isPermaLink="false">2410.19723v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>UFT: Unifying Fine-Tuning of SFT and RLHF/DPO/UNA through a Generalized Implicit Reward Function</title>
      <link>http://arxiv.org/abs/2410.21438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;通过对数万亿个标记进行预训练，LLM获得了文本生成的能力。&lt;h4&gt;目的&lt;/h4&gt;为了增强模型的实用性并减少潜在的危害，依次应用SFT和对齐。&lt;h4&gt;方法&lt;/h4&gt;引入统一微调（UFT），将SFT和对齐整合为一个训练阶段，使用相同的目标和损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;UFT在仅使用指令调优数据时优于SFT，并且在结合指令调优数据和对齐数据时有效防止了灾难性遗忘。&lt;h4&gt;结论&lt;/h4&gt;UFT在指令跟随的ifeval任务和事实性truthful-qa任务中表现出明显改善，建立了有效的预训练-UFT范式。&lt;h4&gt;总结&lt;/h4&gt;UFT提供了一种有效且高效的微调框架，提升了LLM训练的整体效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; By pretraining on trillions of tokens, an LLM gains the capability of textgeneration. However, to enhance its utility and reduce potential harm, SFT andalignment are applied sequentially to the pretrained model. Due to thediffering nature and objective functions of SFT and alignment, catastrophicforgetting has become a significant issue. To address this, we introduceUnified Fine-Tuning (UFT), which integrates SFT and alignment into a singletraining stage using the same objective and loss functions through an implicitreward function. Our experimental results demonstrate that UFT outperforms SFTon instruction-tuning data alone. Moreover, when combining instruction-tuningdata with alignment data, UFT effectively prevents catastrophic forgettingacross these two stages and shows a clear advantage over sequentially applyingSFT and alignment. This is evident in the significant improvements observed inthe \textbf{ifeval} task for instruction-following and the \textbf{truthful-qa}task for factuality. The proposed general fine-tuning framework UFT establishesan effective and efficient pretraining-UFT paradigm for LLM training.</description>
      <author>example@mail.com (Zhichao Wang, Bin Bi, Zixu Zhu, Xiangbo Mao, Jun Wang, Shiyu Wang)</author>
      <guid isPermaLink="false">2410.21438v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>GraphLSS: Integrating Lexical, Structural, and Semantic Features for Long Document Extractive Summarization</title>
      <link>http://arxiv.org/abs/2410.21315v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Short paper submitted to ACL ARR November cycle&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;异构图神经网络在长文档摘要中受到关注，将提取建模为节点分类任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的异构图构建方法GraphLSS，用于长文档的抽取式摘要。&lt;h4&gt;方法&lt;/h4&gt;GraphLSS结合词汇、结构和语义特征，定义两个信息层次（词和句子）以及四种边类型（句子语义相似度、句子出现顺序、句子中的词和词语义相似度），不需要辅助学习模型。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准数据集上的实验表明，GraphLSS与顶尖图基方法具有竞争力，且优于近期的非图模型。&lt;h4&gt;结论&lt;/h4&gt;GraphLSS提供了一种更简单、直观的长文档摘要解决方案。&lt;h4&gt;总结&lt;/h4&gt;我们在GitHub上发布了代码，推动该领域的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous graph neural networks have recently gained attention for longdocument summarization, modeling the extraction as a node classification task.Although effective, these models often require external tools or additionalmachine learning models to define graph components, producing highly complexand less intuitive structures. We present GraphLSS, a heterogeneous graphconstruction for long document extractive summarization, incorporating Lexical,Structural, and Semantic features. It defines two levels of information (wordsand sentences) and four types of edges (sentence semantic similarity, sentenceoccurrence order, word in sentence, and word semantic similarity) without anyneed for auxiliary learning models. Experiments on two benchmark datasets showthat GraphLSS is competitive with top-performing graph-based methods,outperforming recent non-graph models. We release our code on GitHub.</description>
      <author>example@mail.com (Margarita Bugueño, Hazem Abou Hamdan, Gerard de Melo)</author>
      <guid isPermaLink="false">2410.21315v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Point-PRC: A Prompt Learning Based Regulation Framework for Generalizable Point Cloud Analysis</title>
      <link>http://arxiv.org/abs/2410.20406v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;最近的研究表明，通过参数高效的提示调优可以显著提升3D点云识别性能，但在下游任务上实现的提升伴随着3D领域泛化能力的严重下降。&lt;h4&gt;目的&lt;/h4&gt;解决大规模3D模型在3D领域泛化能力下降的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一个综合调节框架，允许可学习提示与大型3D模型中已学习的通用知识进行积极互动，保持良好的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的框架通过最大化任务特定预测与任务无关知识之间的相互一致性，对提示学习轨迹施加多个显式约束，能够持续提升泛化能力，并在各种3DDG基准上增强任务特定的3D识别性能。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅提高了泛化能力，还在多个3DDG基准上以明显的幅度增强了任务特定的3D识别性能。&lt;h4&gt;新贡献&lt;/h4&gt;创建了三个新的基准（基础到新、跨数据集和少样本泛化基准）以丰富该领域并激励未来研究。&lt;h4&gt;总结&lt;/h4&gt;代码和基准可在指定链接获取，旨在促进3D领域泛化能力的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/auniquesun/point-prc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the 3D domain generalization (3DDG) ability of large3D models based on prevalent prompt learning. Recent works demonstrate theperformances of 3D point cloud recognition can be boosted remarkably byparameter-efficient prompt tuning. However, we observe that the improvement ondownstream tasks comes at the expense of a severe drop in 3D domaingeneralization. To resolve this challenge, we present a comprehensiveregulation framework that allows the learnable prompts to actively interactwith the well-learned general knowledge in large 3D models to maintain goodgeneralization. Specifically, the proposed framework imposes multiple explicitconstraints on the prompt learning trajectory by maximizing the mutualagreement between task-specific predictions and task-agnostic knowledge. Wedesign the regulation framework as a plug-and-play module to embed intoexisting representative large 3D models. Surprisingly, our method not onlyrealizes consistently increasing generalization ability but also enhancestask-specific 3D recognition performances across various 3DDG benchmarks by aclear margin. Considering the lack of study and evaluation on 3DDG, we alsocreate three new benchmarks, namely base-to-new, cross-dataset and few-shotgeneralization benchmarks, to enrich the field and inspire future research.Code and benchmarks are available at\url{https://github.com/auniquesun/Point-PRC}.</description>
      <author>example@mail.com (Hongyu Sun, Qiuhong Ke, Yongcai Wang, Wang Chen, Kang Yang, Deying Li, Jianfei Cai)</author>
      <guid isPermaLink="false">2410.20406v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Learning the Regularization Strength for Deep Fine-Tuning via a Data-Emphasized Variational Objective</title>
      <link>http://arxiv.org/abs/2410.19675v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多流行的迁移学习方法依赖于网格搜索来选择控制过拟合的正则化超参数。&lt;h4&gt;目的&lt;/h4&gt;提出一种替代网格搜索的方法，以直接学习正则化超参数。&lt;h4&gt;方法&lt;/h4&gt;通过基于变分方法的证据下界（ELBo）目标，使用模型选择技术在完整训练集上学习正则化超参数。&lt;h4&gt;主要发现&lt;/h4&gt;修改后的ELBo在深度神经网络中增强了数据似然相对于先验的影响，同时仍然有效用于贝叶斯模型选择。&lt;h4&gt;结论&lt;/h4&gt;所提技术克服了网格搜索的三个主要缺点，并在多个数据集的图像分类任务中表现出有效性，计算时间显著减少。&lt;h4&gt;总结&lt;/h4&gt;所提出的方法在保持准确性的同时，显著提高了计算效率，是对传统网格搜索的有效替代。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tufts-ml/data-emphasized-ELBo&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A number of popular transfer learning methods rely on grid search to selectregularization hyperparameters that control over-fitting. This grid searchrequirement has several key disadvantages: the search is computationallyexpensive, requires carving out a validation set that reduces the size ofavailable data for model training, and requires practitioners to specifycandidate values. In this paper, we propose an alternative to grid search:directly learning regularization hyperparameters on the full training set viamodel selection techniques based on the evidence lower bound ("ELBo") objectivefrom variational methods. For deep neural networks with millions of parameters,we specifically recommend a modified ELBo that upweights the influence of thedata likelihood relative to the prior while remaining a valid bound on theevidence for Bayesian model selection. Our proposed technique overcomes allthree disadvantages of grid search. We demonstrate effectiveness on imageclassification tasks on several datasets, yielding heldout accuracy comparableto existing approaches with far less compute time.</description>
      <author>example@mail.com (Ethan Harvey, Mikhail Petrov, Michael C. Hughes)</author>
      <guid isPermaLink="false">2410.19675v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Language Agents Meet Causality -- Bridging LLMs and Causal World Models</title>
      <link>http://arxiv.org/abs/2410.19923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://j0hngou.github.io/LLMCWM/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在规划和推理应用中显示出良好前景，但这些任务需要强大的系统，要求对环境有因果理解。&lt;h4&gt;目的&lt;/h4&gt;提出一个将因果表示学习（CRL）与LLMs整合的框架，以实现因果意识的推理和规划。&lt;h4&gt;方法&lt;/h4&gt;该框架学习一个因果世界模型，将因果变量与自然语言表达关联，为LLMs提供灵活的接口，以文本形式处理和生成动作及状态描述。&lt;h4&gt;主要发现&lt;/h4&gt;在时间尺度和环境复杂性不同的因果推断和规划任务中，该方法的效果优于基于LLM的推理器，特别是在较长规划周期中表现更佳。&lt;h4&gt;结论&lt;/h4&gt;整合CRL与LLMs的框架有效提升了因果意识的推理和规划能力，展示了该方法的优势。&lt;h4&gt;总结&lt;/h4&gt;通过因果世界模型，LLMs能够更好地理解和描述环境中的因果关系，增强其在复杂任务中的应用能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/j0hngou/LLMCWM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have recently shown great promise in planningand reasoning applications. These tasks demand robust systems, which arguablyrequire a causal understanding of the environment. While LLMs can acquire andreflect common sense causal knowledge from their pretraining data, thisinformation is often incomplete, incorrect, or inapplicable to a specificenvironment. In contrast, causal representation learning (CRL) focuses onidentifying the underlying causal structure within a given environment. Wepropose a framework that integrates CRLs with LLMs to enable causally-awarereasoning and planning. This framework learns a causal world model, with causalvariables linked to natural language expressions. This mapping provides LLMswith a flexible interface to process and generate descriptions of actions andstates in text form. Effectively, the causal world model acts as a simulatorthat the LLM can query and interact with. We evaluate the framework on causalinference and planning tasks across temporal scales and environmentalcomplexities. Our experiments demonstrate the effectiveness of the approach,with the causally-aware method outperforming LLM-based reasoners, especiallyfor longer planning horizons.</description>
      <author>example@mail.com (John Gkountouras, Matthias Lindemann, Phillip Lippe, Efstratios Gavves, Ivan Titov)</author>
      <guid isPermaLink="false">2410.19923v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FedSSP: Federated Graph Learning with Spectral Knowledge and Personalized Preference</title>
      <link>http://arxiv.org/abs/2410.20105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;个性化联邦图学习（pFGL）在不妨碍隐私的情况下，促进了图神经网络（GNN）的去中心化训练，满足非独立同分布（non-IID）参与者的个性化需求。&lt;h4&gt;目的&lt;/h4&gt;解决跨域场景中结构异质性对pFGL的重大挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了FedSSP框架，通过共享通用谱知识，克服领域结构变化，同时引入个性化偏好模块。&lt;h4&gt;主要发现&lt;/h4&gt;谱特性能有效反映固有的领域结构变化，且传统的pFGL方法在共享非通用知识方面存在问题。&lt;h4&gt;结论&lt;/h4&gt;FedSSP框架在跨数据集和跨领域设置下表现优越，展示了其在个性化联邦图学习中的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究通过创新方法提升了pFGL的性能，提供了可在GitHub上获取的代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/oakleytan/fedssp&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized Federated Graph Learning (pFGL) facilitates the decentralizedtraining of Graph Neural Networks (GNNs) without compromising privacy whileaccommodating personalized requirements for non-IID participants. Incross-domain scenarios, structural heterogeneity poses significant challengesfor pFGL. Nevertheless, previous pFGL methods incorrectly share non-genericknowledge globally and fail to tailor personalized solutions locally underdomain structural shift. We innovatively reveal that the spectral nature ofgraphs can well reflect inherent domain structural shifts. Correspondingly, ourmethod overcomes it by sharing generic spectral knowledge. Moreover, weindicate the biased message-passing schemes for graph structures and proposethe personalized preference module. Combining both strategies, we propose ourpFGL framework FedSSP which Shares generic Spectral knowledge while satisfyinggraph Preferences. Furthermore, We perform extensive experiments oncross-dataset and cross-domain settings to demonstrate the superiority of ourframework. The code is available at https://github.com/OakleyTan/FedSSP.</description>
      <author>example@mail.com (Zihan Tan, Guancheng Wan, Wenke Huang, Mang Ye)</author>
      <guid isPermaLink="false">2410.20105v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MAMMAL -- Molecular Aligned Multi-Modal Architecture and Language</title>
      <link>http://arxiv.org/abs/2410.22367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;药物发现通常包括多个步骤，如识别与疾病病因相关的靶蛋白、验证与该靶点的相互作用能否防止症状或治愈疾病等。&lt;h4&gt;目的&lt;/h4&gt;提出MAMMAL（分子对齐多模态架构和语言），用于处理药物发现中的多任务学习。&lt;h4&gt;方法&lt;/h4&gt;MAMMAL方法应用于创建一个多功能基础模型，利用大规模生物数据集（20亿样本），支持多种分类、回归和生成任务。&lt;h4&gt;主要发现&lt;/h4&gt;模型在11个不同下游任务的评估中，9个任务达到新的最先进水平（SOTA），2个任务表现与最先进水平相当。&lt;h4&gt;结论&lt;/h4&gt;该模型在所有任务中使用统一架构，与传统的针对特定任务的架构相比，性能表现更佳。&lt;h4&gt;模型可用性&lt;/h4&gt;模型代码和预训练权重公开可用，链接为https://github.com/BiomedSciAI/biomed-multi-alignment和https://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m。&lt;h4&gt;总结&lt;/h4&gt;MAMMAL提供了一种新的方法，通过多模态学习优化药物发现过程，展示了广泛的应用潜力和优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/biomedsciai/biomed-multi-alignment&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug discovery typically consists of multiple steps, including identifying atarget protein key to a disease's etiology, validating that interacting withthis target could prevent symptoms or cure the disease, discovering a smallmolecule or biologic therapeutic to interact with it, and optimizing thecandidate molecule through a complex landscape of required properties. Drugdiscovery related tasks often involve prediction and generation whileconsidering multiple entities that potentially interact, which poses achallenge for typical AI models. For this purpose we present MAMMAL - MolecularAligned Multi-Modal Architecture and Language - a method that we applied tocreate a versatile multi-task foundation modelibm/biomed.omics.bl.sm.ma-ted-458m that learns from large-scale biologicaldatasets (2 billion samples) across diverse modalities, including proteins,small molecules, and genes. We introduce a prompt syntax that supports a widerange of classification, regression, and generation tasks. It allows combiningdifferent modalities and entity types as inputs and/or outputs. Our modelhandles combinations of tokens and scalars and enables the generation of smallmolecules and proteins, property prediction, and transcriptomic lab testpredictions. We evaluated the model on 11 diverse downstream tasks spanningdifferent steps within a typical drug discovery pipeline, where it reaches newSOTA in 9 tasks and is comparable to SOTA in 2 tasks. This performance isachieved while using a unified architecture serving all tasks, in contrast tothe original SOTA performance achieved using tailored architectures.  The model code and pretrained weights are publicly available athttps://github.com/BiomedSciAI/biomed-multi-alignment andhttps://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m.</description>
      <author>example@mail.com (Yoel Shoshan, Moshiko Raboh, Michal Ozery-Flato, Vadim Ratner, Alex Golts, Jeffrey K. Weber, Ella Barkan, Simona Rabinovici-Cohen, Sagi Polaczek, Ido Amos, Ben Shapira, Liam Hazan, Matan Ninio, Sivan Ravid, Michael M. Danziger, Joseph A. Morrone, Parthasarathy Suryanarayanan, Michal Rosen-Zvi, Efrat Hexter)</author>
      <guid isPermaLink="false">2410.22367v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Augmentation Invariance Pretraining</title>
      <link>http://arxiv.org/abs/2410.22364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习方法在视觉变换器（ViTs）预训练中的计算挑战。&lt;h4&gt;目的&lt;/h4&gt;解决对比学习训练中所需的高计算资源问题，以促进其实际应用。&lt;h4&gt;方法&lt;/h4&gt;提出加速框架，利用ViT对不同序列长度输入的泛化能力，采用随机 token 随机丢弃和灵活的补丁缩放等序列压缩策略以减少梯度估计成本并加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;对不同加速策略的梯度估计误差及其对下游任务的影响进行了深入分析，提供了加速与性能之间的权衡见解。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的优化加速调度程序，根据训练进度调整序列压缩比，以确保高效训练而不牺牲下游性能。&lt;h4&gt;总结&lt;/h4&gt;在大规模数据集上，显著降低了各种自监督学习算法的计算开销。在ImageNet上，MoCo速度提高4倍，SimCLR提高3.3倍，DINO提高2.5倍，显示出显著的效率提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Our work tackles the computational challenges of contrastive learningmethods, particularly for the pretraining of Vision Transformers (ViTs).Despite the effectiveness of contrastive learning, the substantialcomputational resources required for training often hinder their practicalapplication. To mitigate this issue, we propose an acceleration framework,leveraging ViT's unique ability to generalize across inputs of varying sequencelengths. Our method employs a mix of sequence compression strategies, includingrandomized token dropout and flexible patch scaling, to reduce the cost ofgradient estimation and accelerate convergence. We further provide an in-depthanalysis of the gradient estimation error of various acceleration strategies aswell as their impact on downstream tasks, offering valuable insights into thetrade-offs between acceleration and performance.  We also propose a novel procedure to identify an optimal accelerationschedule to adjust the sequence compression ratios to the training progress,ensuring efficient training without sacrificing downstream performance. Ourapproach significantly reduces computational overhead across variousself-supervised learning algorithms on large-scale datasets. In ImageNet, ourmethod achieves speedups of 4$\times$ in MoCo, 3.3$\times$ in SimCLR, and2.5$\times$ in DINO, demonstrating substantial efficiency gains.</description>
      <author>example@mail.com (Jinhong Lin, Cheng-En Wu, Yibing Wei, Pedro Morgado)</author>
      <guid isPermaLink="false">2410.22364v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Deep Concept Identification for Generative Design</title>
      <link>http://arxiv.org/abs/2410.20061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于拓扑优化的生成设计提供了多样化的替代方案，但设计师在选择最合适方案时面临认知负担增加的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于深度学习的概念识别框架，以帮助结构化生成的设计替代方案。&lt;h4&gt;方法&lt;/h4&gt;利用深度学习技术进行深度概念识别，自动学习几何属性与结构性能之间的映射关系。&lt;h4&gt;主要发现&lt;/h4&gt;框架通过生成设计技术生成多样化替代方案，利用深度学习对其进行聚类，并通过分类模型进行排序以供设计实践使用。&lt;h4&gt;结论&lt;/h4&gt;实施变分深嵌入和逻辑回归模型验证了框架的基本能力，尽管设计师需设定概念数量，但框架能以决策树形式展示识别的概念及其关系。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种有效的方法，通过深度学习支持的概念识别和分类，减轻设计师的认知负担，并提高生成设计的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A generative design based on topology optimization provides diversealternatives as entities in a computational model with a high design degree.However, as the diversity of the generated alternatives increases, thecognitive burden on designers to select the most appropriate alternatives alsoincreases. Whereas the concept identification approach, which finds variouscategories of entities, is an effective means to structure alternatives,evaluation of their similarities is challenging due to shape diversity. Toaddress this challenge, this study proposes a concept identification frameworkfor generative design using deep learning (DL) techniques. One of the keyabilities of DL is the automatic learning of different representations of aspecific task. Deep concept identification finds various categories thatprovide insights into the mapping relationships between geometric propertiesand structural performance through representation learning using DL. Theproposed framework generates diverse alternatives using a generative designtechnique, clusters the alternatives into several categories using a DLtechnique, and arranges these categories for design practice using aclassification model. This study demonstrates its fundamental capabilities byimplementing variational deep embedding, a generative and clustering modelbased on the DL paradigm, and logistic regression as a classification model. Asimplified design problem of a two-dimensional bridge structure is applied as acase study to validate the proposed framework. Although designers are requiredto determine the viewing aspect level by setting the number of concepts, thisimplementation presents the identified concepts and their relationships in theform of a decision tree based on a specified level.</description>
      <author>example@mail.com (Ryo Tsumoto, Kentaro Yaji, Yutaka Nomaguchi, Kikuo Fujita)</author>
      <guid isPermaLink="false">2410.20061v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Going Beyond H&amp;E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?</title>
      <link>http://arxiv.org/abs/2410.21560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Workshop on Advancements In Medical Foundation Models
  (NeurIPS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究评估了最先进的组织病理学基础模型在多染色自身免疫免疫组化数据集上的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;比较13种特征提取模型在类风湿性关节炎亚型划分和干燥综合症检测任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;使用简单的基于注意力的多实例学习分类器，评估从癌症H&amp;E图像到自身免疫IHC图像的学习表示的可转移性。&lt;h4&gt;主要发现&lt;/h4&gt;组织病理学预训练模型的表现没有显著优于ImageNet预训练模型，且存在自身免疫特征误解和特征重要性偏差的证据。&lt;h4&gt;结论&lt;/h4&gt;从癌症到自身免疫组织病理学知识的转移面临挑战，需要对AI模型在不同组织病理学任务上的表现进行仔细评估。&lt;h4&gt;代码&lt;/h4&gt;基准测试的代码可在https://github.com/AmayaGS/ImmunoHistoBench找到。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了在自身免疫病理学领域应用AI模型时需谨慎评估其适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/amayags/immunohistobench&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study evaluates the generalisation capabilities of state-of-the-arthistopathology foundation models on out-of-distribution multi-stain autoimmuneImmunohistochemistry datasets. We compare 13 feature extractor models,including ImageNet-pretrained networks, and histopathology foundation modelstrained on both public and proprietary data, on Rheumatoid Arthritis subtypingand Sjogren's Disease detection tasks. Using a simple Attention-Based MultipleInstance Learning classifier, we assess the transferability of learnedrepresentations from cancer H&amp;E images to autoimmune IHC images. Contrary toexpectations, histopathology-pretrained models did not significantly outperformImageNet-pretrained models. Furthermore, there was evidence of both autoimmunefeature misinterpretation and biased feature importance. Our findings highlightthe challenges in transferring knowledge from cancer to autoimmunehistopathology and emphasise the need for careful evaluation of AI modelsacross diverse histopathological tasks. The code to run this benchmark isavailable at https://github.com/AmayaGS/ImmunoHistoBench.</description>
      <author>example@mail.com (Amaya Gallagher-Syed, Elena Pontarini, Myles J. Lewis, Michael R. Barnes, Gregory Slabaugh)</author>
      <guid isPermaLink="false">2410.21560v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Transformer-Based Tooth Alignment Prediction With Occlusion And Collision Constraints</title>
      <link>http://arxiv.org/abs/2410.20806v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  add key words and email information&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数字正畸治疗规划需要牙齿对齐，这一过程耗时耗力且依赖临床经验。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Swin-transformer的轻量化牙齿对齐神经网络。&lt;h4&gt;方法&lt;/h4&gt;重组3D点云，基于虚拟弓线转换为有序多通道纹理；设计两种新的咬合损失函数，定量评估上下颌关系；收集包含591个临床案例的大型数字正畸数据集，并提出两种新的数据集增强方法。&lt;h4&gt;主要发现&lt;/h4&gt;在使用新咬合损失函数后，预测准确性显著提高。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在高预测准确性方面表现优异，并且数据集的发布将对社区产生积极影响。&lt;h4&gt;总结&lt;/h4&gt;研究为数字正畸治疗提供了一种高效的工具，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The planning of digital orthodontic treatment requires providing toothalignment, which not only consumes a lot of time and labor to determinemanually but also relays clinical experiences heavily. In this work, weproposed a lightweight tooth alignment neural network based onSwin-transformer. We first re-organized 3D point clouds based on virtual archlines and converted them into order-sorted multi-channel textures, whichimproves the accuracy and efficiency simultaneously. We then designed two newocclusal loss functions that quantitatively evaluate the occlusal relationshipbetween the upper and lower jaws. They are important clinical constraints,first introduced to the best of our knowledge, and lead to cutting-edgeprediction accuracy. To train our network, we collected a large digitalorthodontic dataset that has 591 clinical cases, including various complexclinical cases. This dataset will benefit the community after its release sincethere is no open dataset so far. Furthermore, we also proposed two neworthodontic dataset augmentation methods considering tooth spatial distributionand occlusion. We evaluated our method with this dataset and extensiveexperiments, including comparisons with STAT methods and ablation studies, anddemonstrate the high prediction accuracy of our method.</description>
      <author>example@mail.com (ZhenXing Dong, JiaZhou Chen, YangHui Xu)</author>
      <guid isPermaLink="false">2410.20806v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PepDoRA: A Unified Peptide Language Model via Weight-Decomposed Low-Rank Adaptation</title>
      <link>http://arxiv.org/abs/2410.20667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;肽类治疗药物，包括大环肽、肽抑制剂和生物活性线性肽，由于其独特的物理化学性质，在治疗开发中发挥着关键作用。预测这些性质仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出PepDoRA，一个统一的肽表示模型，以弥补现有模型在肽的预测能力上的不足。&lt;h4&gt;方法&lt;/h4&gt;利用Weight-Decomposed Low-Rank Adaptation (DoRA)，PepDoRA对ChemBERTa-77M-MLM进行高效微调，通过掩蔽语言模型目标生成优化的嵌入，适用于修改和未修改肽的性质预测任务。&lt;h4&gt;主要发现&lt;/h4&gt;通过在100,000个修改后的生物活性和结合肽上进行调优，PepDoRA嵌入能够捕捉输入肽的功能特性，准确预测膜渗透性、抗污染性和溶血倾向，以及通过对比学习实现靶蛋白特异性结合。&lt;h4&gt;结论&lt;/h4&gt;PepDoRA为化学和生物多样性的肽提供了统一的表示，成为功能和活性预测的多用途工具，推动肽类治疗药物的广泛应用。&lt;h4&gt;总结&lt;/h4&gt;PepDoRA模型在肽的性质预测中显示出良好的适应性，有助于肽类药物的开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Peptide therapeutics, including macrocycles, peptide inhibitors, andbioactive linear peptides, play a crucial role in therapeutic development dueto their unique physicochemical properties. However, predicting theseproperties remains challenging. While structure-based models primarily focus onlocal interactions, language models are capable of capturing global therapeuticproperties of both modified and linear peptides. Protein language models likeESM-2, though effective for natural peptides, cannot however encode chemicalmodifications. Conversely, pre-trained chemical language models excel inrepresenting small molecule properties but are not optimized for peptides. Tobridge this gap, we introduce PepDoRA, a unified peptide representation model.Leveraging Weight-Decomposed Low-Rank Adaptation (DoRA), PepDoRA efficientlyfine-tunes the ChemBERTa-77M-MLM on a masked language model objective togenerate optimized embeddings for downstream property prediction tasksinvolving both modified and unmodified peptides. By tuning on a diverse andexperimentally valid set of 100,000 modified, bioactive, and binding peptides,we show that PepDoRA embeddings capture functional properties of inputpeptides, enabling the accurate prediction of membrane permeability,non-fouling and hemolysis propensity, and via contrastive learning, targetprotein-specific binding. Overall, by providing a unified representation forchemically and biologically diverse peptides, PepDoRA serves as a versatiletool for function and activity prediction, facilitating the development ofpeptide therapeutics across a broad spectrum of applications.</description>
      <author>example@mail.com (Leyao Wang, Rishab Pulugurta, Pranay Vure, Yinuo Zhang, Aastha Pal, Pranam Chatterjee)</author>
      <guid isPermaLink="false">2410.20667v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Discovering Robotic Interaction Modes with Discrete Representation Learning</title>
      <link>http://arxiv.org/abs/2410.20258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类操作关节物体的行为可以被分类为不同的交互模式，但传统机器人学习方法缺乏对这些模式的离散表示。&lt;h4&gt;目的&lt;/h4&gt;提出ActAIM2，学习机器人操作交互模式的离散表示，采用无监督方式，不依赖专家标签或模拟器信息。&lt;h4&gt;方法&lt;/h4&gt;使用新颖的数据收集方法，包括模拟器回放，ActAIM2包含交互模式选择器和低级动作预测器，前者生成潜在交互模式的离散表示，后者输出相应的动作轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;通过操作关节物体的成功率和从离散表示中采样有意义动作的鲁棒性验证了该方法。&lt;h4&gt;结论&lt;/h4&gt;ActAIM2在提高可操控性和泛化能力方面显著优于基线和消融研究。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了无监督学习在机器人操作中的潜力，并提供了有效的交互模式学习方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human actions manipulating articulated objects, such as opening and closing adrawer, can be categorized into multiple modalities we define as interactionmodes. Traditional robot learning approaches lack discrete representations ofthese modes, which are crucial for empirical sampling and grounding. In thispaper, we present ActAIM2, which learns a discrete representation of robotmanipulation interaction modes in a purely unsupervised fashion, without theuse of expert labels or simulator-based privileged information. Utilizing noveldata collection methods involving simulator rollouts, ActAIM2 consists of aninteraction mode selector and a low-level action predictor. The selectorgenerates discrete representations of potential interaction modes withself-supervision, while the predictor outputs corresponding actiontrajectories. Our method is validated through its success rate in manipulatingarticulated objects and its robustness in sampling meaningful actions from thediscrete representation. Extensive experiments demonstrate ActAIM2'seffectiveness in enhancing manipulability and generalizability over baselinesand ablation studies. For videos and additional results, see our website:https://actaim2.github.io/.</description>
      <author>example@mail.com (Liquan Wang, Ankit Goyal, Haoping Xu, Animesh Garg)</author>
      <guid isPermaLink="false">2410.20258v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Just Propagate: Unifying Matrix Factorization, Network Embedding, and LightGCN for Link Prediction</title>
      <link>http://arxiv.org/abs/2410.21325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;链接预测是图分析中的一个基础任务。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的框架，以涵盖矩阵分解、网络嵌入和图神经网络方法进行链接预测。&lt;h4&gt;方法&lt;/h4&gt;分析不同模型的设计因素，并进行初步的方法论和实证分析。&lt;h4&gt;主要发现&lt;/h4&gt;基于统一框架揭示了几个关键的设计因素。&lt;h4&gt;结论&lt;/h4&gt;研究结果有助于加深对链接预测的理解，并激发新的链接预测方法的设计。&lt;h4&gt;总结&lt;/h4&gt;提出的统一框架为链接预测提供了新的视角和方法论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a fundamental task in graph analysis. Despite the successof various graph-based machine learning models for link prediction, there lacksa general understanding of different models. In this paper, we propose aunified framework for link prediction that covers matrix factorization andrepresentative network embedding and graph neural network methods. Ourpreliminary methodological and empirical analyses further reveal several keydesign factors based on our unified framework. We believe our results coulddeepen our understanding and inspire novel designs for link prediction methods.</description>
      <author>example@mail.com (Haoxin Liu)</author>
      <guid isPermaLink="false">2410.21325v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ImageNet-RIB Benchmark: Large Pre-Training Datasets Don't Guarantee Robustness after Fine-Tuning</title>
      <link>http://arxiv.org/abs/2410.21582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型预训练模型在学习专业任务方面提供了有价值的基础，通过微调模型以适应特定任务。&lt;h4&gt;目的&lt;/h4&gt;在保持模型鲁棒性的同时，实现针对目标任务的专业化。&lt;h4&gt;方法&lt;/h4&gt;引入新的鲁棒性微调基准，ImageNet-RIB，包括一组相关但不同的专门任务，评估微调后模型对离散样本的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;持续学习方法EWC和LwF在微调后保持鲁棒性，但微调通常降低了模型在相关下游任务上的性能。预训练在大型丰富数据集上的模型初始鲁棒性较高，但在微调过程中表现出明显退化。预训练和下游数据集之间的距离可预测性能退化。&lt;h4&gt;结论&lt;/h4&gt;微调后模型的鲁棒性在预训练数据集最丰富和多样化时最差，表明以最强基础模型开始并不一定是专业任务性能的最佳方法。&lt;h4&gt;总结&lt;/h4&gt;该基准为开发更具韧性的微调策略和构建鲁棒的机器学习模型提供了关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Highly performant large-scale pre-trained models promise to also provide avaluable foundation for learning specialized tasks, by fine-tuning the model tothe desired task. By starting from a good general-purpose model, the goal is toachieve both specialization in the target task and maintain robustness. Toassess the robustness of models to out-of-distribution samples afterfine-tuning on downstream datasets, we introduce a new robust fine-tuningbenchmark, ImageNet-RIB (Robustness Inheritance Benchmark). The benchmarkconsists of a set of related but distinct specialized (downstream) tasks;pre-trained models are fine-tuned on one task in the set and their robustnessis assessed on the rest, iterating across all tasks for fine-tuning andassessment. We find that the continual learning methods, EWC and LwF maintainrobustness after fine-tuning though fine-tuning generally does reduceperformance on generalization to related downstream tasks across models. Notsurprisingly, models pre-trained on large and rich datasets exhibit higherinitial robustness across datasets and suffer more pronounced degradationduring fine-tuning. The distance between the pre-training and downstreamdatasets, measured by optimal transport, predicts this performance degradationon the pre-training dataset. However, counterintuitively, model robustnessafter fine-tuning on related downstream tasks is the worst when thepre-training dataset is the richest and the most diverse. This suggests thatstarting with the strongest foundation model is not necessarily the bestapproach for performance on specialist tasks. The benchmark thus offers keyinsights for developing more resilient fine-tuning strategies and buildingrobust machine learning models. https://jd730.github.io/projects/ImageNet-RIB</description>
      <author>example@mail.com (Jaedong Hwang, Brian Cheung, Zhang-Wei Hong, Akhilan Boopathy, Pulkit Agrawal, Ila Fiete)</author>
      <guid isPermaLink="false">2410.21582v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Relation-based Counterfactual Data Augmentation and Contrastive Learning for Robustifying Natural Language Inference Models</title>
      <link>http://arxiv.org/abs/2410.20710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at INTERSPEECH 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预训练语言模型在各种自然语言处理任务中表现良好，但往往依赖非因果特征和模式来决定结果。&lt;h4&gt;目的&lt;/h4&gt;提高自然语言推理任务中模型对反事实修订数据的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;采用基于标记和基于句子的增强方法生成反事实句子对，并应用对比学习帮助模型识别不同类别的句子对之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;在经过反事实修订的数据集和一般NLI数据集上的评估结果显示，所提方法能够提高NLI模型的性能和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习和数据增强，模型在自然语言推理任务中的表现得到了显著改善。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的方法有效提升了自然语言推理模型在面临反事实数据时的学习能力和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although pre-trained language models show good performance on various naturallanguage processing tasks, they often rely on non-causal features and patternsto determine the outcome. For natural language inference tasks, previousresults have shown that even a model trained on a large number of data fails toperform well on counterfactually revised data, indicating that the model is notrobustly learning the semantics of the classes. In this paper, we propose amethod in which we use token-based and sentence-based augmentation methods togenerate counterfactual sentence pairs that belong to each class, and applycontrastive learning to help the model learn the difference between sentencepairs of different classes with similar contexts. Evaluation results withcounterfactually-revised dataset and general NLI datasets show that theproposed method can improve the performance and robustness of the NLI model.</description>
      <author>example@mail.com (Heerin Yang, Sseung-won Hwang, Jungmin So)</author>
      <guid isPermaLink="false">2410.20710v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>UTSRMorph: A Unified Transformer and Superresolution Network for Unsupervised Medical Image Registration</title>
      <link>http://arxiv.org/abs/2410.20348v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13pages,10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;复杂的图像配准是医学图像分析中的关键问题，基于深度学习的方法比传统方法取得了更好的结果。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督图像配准方法，称为统一变换器和超分辨率网络（UTSRMorph），以增强特征表示学习和生成详细的位移场。&lt;h4&gt;方法&lt;/h4&gt;提出了融合注意力块，将基于卷积网络的通道注意力模块与多头自注意力模块相结合，并使用重叠窗口的交叉注意力方法，以获得丰富的配对图像相关信息。&lt;h4&gt;主要发现&lt;/h4&gt;UTSRMorph在3D脑部MR（OASIS, IXI）和MR-CT数据集上的性能优于最新的注册方法，定性和定量结果显示其相对更好的表现。&lt;h4&gt;结论&lt;/h4&gt;UTSRMorph有效克服了卷积网络和变换器在图像配准中的局限性，提供了更好的特征表示和位移场生成。&lt;h4&gt;代码和数据集&lt;/h4&gt;代码和数据集公开可用，链接为：https://github.com/Runshi-Zhang/UTSRMorph。&lt;h4&gt;总结&lt;/h4&gt;UTSRMorph通过结合卷积网络和变换器的优势，提出了一种新的无监督图像配准方法，显著提升了医学图像分析的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMI.2024.3467919&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/runshi-zhang/utsrmorph&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complicated image registration is a key issue in medical image analysis, anddeep learning-based methods have achieved better results than traditionalmethods. The methods include ConvNet-based and Transformer-based methods.Although ConvNets can effectively utilize local information to reduceredundancy via small neighborhood convolution, the limited receptive fieldresults in the inability to capture global dependencies. Transformers canestablish long-distance dependencies via a self-attention mechanism; however,the intense calculation of the relationships among all tokens leads to highredundancy. We propose a novel unsupervised image registration method named theunified Transformer and superresolution (UTSRMorph) network, which can enhancefeature representation learning in the encoder and generate detaileddisplacement fields in the decoder to overcome these problems. We first proposea fusion attention block to integrate the advantages of ConvNets andTransformers, which inserts a ConvNet-based channel attention module into amultihead self-attention module. The overlapping attention block, a novelcross-attention method, uses overlapping windows to obtain abundantcorrelations with match information of a pair of images. Then, the blocks areflexibly stacked into a new powerful encoder. The decoder generation process ofa high-resolution deformation displacement field from low-resolution featuresis considered as a superresolution process. Specifically, the superresolutionmodule was employed to replace interpolation upsampling, which can overcomefeature degradation. UTSRMorph was compared to state-of-the-art registrationmethods in the 3D brain MR (OASIS, IXI) and MR-CT datasets. The qualitative andquantitative results indicate that UTSRMorph achieves relatively betterperformance. The code and datasets are publicly available athttps://github.com/Runshi-Zhang/UTSRMorph.</description>
      <author>example@mail.com (Runshi Zhang, Hao Mo, Junchen Wang, Bimeng Jie, Yang He, Nenghao Jin, Liang Zhu)</author>
      <guid isPermaLink="false">2410.20348v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DeCaf: A Causal Decoupling Framework for OOD Generalization on Node Classification</title>
      <link>http://arxiv.org/abs/2410.20295v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）容易受到分布变化的影响，这在关键领域中造成了脆弱性和安全问题。&lt;h4&gt;目的&lt;/h4&gt;迫切需要增强GNNs在分布外（OOD）测试数据上的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入了更现实的图数据生成模型，使用结构因果模型（SCMs），重新定义分布变化并确定其起源。提出了一个因果解耦框架DeCaf，独立学习无偏特征-标签和结构-标签映射。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细的理论框架，展示了该方法如何有效减轻各种分布变化的影响。&lt;h4&gt;结论&lt;/h4&gt;在不同模式变化的真实和合成数据集上评估DeCaf，验证了其增强GNNs泛化能力的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种新的方法来应对GNNs在分布变化中的挑战，推动了其在实际应用中的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are susceptible to distribution shifts, creatingvulnerability and security issues in critical domains. There is a pressing needto enhance the generalizability of GNNs on out-of-distribution (OOD) test data.Existing methods that target learning an invariant (feature, structure)-labelmapping often depend on oversimplified assumptions about the data generationprocess, which do not adequately reflect the actual dynamics of distributionshifts in graphs. In this paper, we introduce a more realistic graph datageneration model using Structural Causal Models (SCMs), allowing us to redefinedistribution shifts by pinpointing their origins within the generation process.Building on this, we propose a casual decoupling framework, DeCaf, thatindependently learns unbiased feature-label and structure-label mappings. Weprovide a detailed theoretical framework that shows how our approach caneffectively mitigate the impact of various distribution shifts. We evaluateDeCaf across both real-world and synthetic datasets that demonstrate differentpatterns of shifts, confirming its efficacy in enhancing the generalizabilityof GNNs.</description>
      <author>example@mail.com (Xiaoxue Han, Huzefa Rangwala, Yue Ning)</author>
      <guid isPermaLink="false">2410.20295v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection</title>
      <link>http://arxiv.org/abs/2410.19898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文回顾了深度学习在非侵入性认知障碍检测中的最新进展。&lt;h4&gt;目的&lt;/h4&gt;探讨非侵入性认知衰退的各种指标，包括语言、面部和运动能力。&lt;h4&gt;方法&lt;/h4&gt;分析相关数据集、特征提取技术和应用于该领域的深度学习架构。&lt;h4&gt;主要发现&lt;/h4&gt;基于语言和语音的方法通常具备最高的检测性能，结合声学和语言特征的方法优于单一模态的研究，面部分析方法在视觉模态上显示出潜力，但研究相对较少。&lt;h4&gt;结论&lt;/h4&gt;大多数研究集中于二分类问题，针对多分类或回归任务的研究较少。转移学习和预训练语言模型在语言分析中表现出色，但仍面临数据标准化、模型可解释性等挑战。&lt;h4&gt;未来研究方向&lt;/h4&gt;建议研究语言无关的语音分析方法、开发多模态诊断系统，并关注AI辅助医疗中的伦理问题。&lt;h4&gt;总结&lt;/h4&gt;通过总结当前趋势和识别关键障碍，本文旨在指导深度学习基础的认知障碍检测系统的发展，以改善早期诊断和患者结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This review paper explores recent advances in deep learning approaches fornon-invasive cognitive impairment detection. We examine various non-invasiveindicators of cognitive decline, including speech and language, facial, andmotoric mobility. The paper provides an overview of relevant datasets,feature-extracting techniques, and deep-learning architectures applied to thisdomain. We have analyzed the performance of different methods across modalitiesand observed that speech and language-based methods generally achieved thehighest detection performance. Studies combining acoustic and linguisticfeatures tended to outperform those using a single modality. Facial analysismethods showed promise for visual modalities but were less extensively studied.Most papers focused on binary classification (impaired vs. non-impaired), withfewer addressing multi-class or regression tasks. Transfer learning andpre-trained language models emerged as popular and effective techniques,especially for linguistic analysis. Despite significant progress, severalchallenges remain, including data standardization and accessibility, modelexplainability, longitudinal analysis limitations, and clinical adaptation.Lastly, we propose future research directions, such as investigatinglanguage-agnostic speech analysis methods, developing multi-modal diagnosticsystems, and addressing ethical considerations in AI-assisted healthcare. Bysynthesizing current trends and identifying key obstacles, this review aims toguide further development of deep learning-based cognitive impairment detectionsystems to improve early diagnosis and ultimately patient outcomes.</description>
      <author>example@mail.com (Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor)</author>
      <guid isPermaLink="false">2410.19898v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>AdaptGCD: Multi-Expert Adapter Tuning for Generalized Category Discovery</title>
      <link>http://arxiv.org/abs/2410.21705v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的半监督学习受限于封闭世界假设，而广义类别发现（GCD）认为无标签数据集中包含未出现在标签集中的新类别。&lt;h4&gt;目的&lt;/h4&gt;不仅对旧类别进行分类，还要在无标签数据中发现新类别。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的基于适配器调优的方法AdaptGCD，首次将适配器调优引入GCD任务，并设计了多专家适配器结构，以便将旧类和新类的数据分组处理。&lt;h4&gt;主要发现&lt;/h4&gt;在7个广泛使用的数据集上进行了大量实验，显著提高了性能，证明了所提方案的有效性。&lt;h4&gt;结论&lt;/h4&gt;AdaptGCD方法在GCD任务中实现了预训练模型的通用知识与任务适应性的良好平衡，对未来研究具有启示意义。&lt;h4&gt;总结&lt;/h4&gt;本研究为广义类别发现提供了新的视角和方法，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Different from the traditional semi-supervised learning paradigm that isconstrained by the close-world assumption, Generalized Category Discovery (GCD)presumes that the unlabeled dataset contains new categories not appearing inthe labeled set, and aims to not only classify old categories but also discovernew categories in the unlabeled data. Existing studies on GCD typically devoteto transferring the general knowledge from the self-supervised pretrained modelto the target GCD task via some fine-tuning strategies, such as partial tuningand prompt learning. Nevertheless, these fine-tuning methods fail to make asound balance between the generalization capacity of pretrained backbone andthe adaptability to the GCD task. To fill this gap, in this paper, we propose anovel adapter-tuning-based method named AdaptGCD, which is the first work tointroduce the adapter tuning into the GCD task and provides some key insightsexpected to enlighten future research. Furthermore, considering the discrepancyof supervision information between the old and new classes, a multi-expertadapter structure equipped with a route assignment constraint is elaboratelydevised, such that the data from old and new classes are separated intodifferent expert groups. Extensive experiments are conducted on 7 widely-useddatasets. The remarkable improvements in performance highlight theeffectiveness of our proposals.</description>
      <author>example@mail.com (Yuxun Qu, Yongqiang Tang, Chenyang Zhang, Wensheng Zhang)</author>
      <guid isPermaLink="false">2410.21705v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Positive History: Re-ranking with List-level Hybrid Feedback</title>
      <link>http://arxiv.org/abs/2410.20778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;重排序作为推荐系统的最后阶段，旨在生成符合用户偏好的重新排序列表。以往的研究主要关注于项目级的正反馈，忽视了用户在整个列表上提供的正负反馈。&lt;h4&gt;目的&lt;/h4&gt;探索列表级混合反馈如何揭示用户的整体偏好及其在列表中的比较行为模式，从而改进重排序。&lt;h4&gt;方法&lt;/h4&gt;提出了名为RELIFE的重排序方法，采用三个模块：去耦兴趣挖掘器、序列偏好混合器和比较感知模式提取器，以捕捉用户的偏好和行为模式。&lt;h4&gt;主要发现&lt;/h4&gt;RELIFE在整合用户偏好和行为模式方面显著优于现有的重排序基线模型。&lt;h4&gt;结论&lt;/h4&gt;通过对候选列表和历史列表的行为模式进行对比学习，RELIFE有效提升了重排序的性能。&lt;h4&gt;总结&lt;/h4&gt;RELIFE方法通过利用列表级混合反馈，显著改善了推荐系统的重排序效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the last stage of recommender systems, re-ranking generates a re-orderedlist that aligns with the user's preference. However, previous works generallyfocus on item-level positive feedback as history (e.g., only clicked items) andignore that users provide positive or negative feedback on items in the entirelist. This list-level hybrid feedback can reveal users' holistic preferencesand reflect users' comparison behavior patterns manifesting within a list. Suchpatterns could predict user behaviors on candidate lists, thus aiding betterre-ranking. Despite appealing benefits, extracting and integrating preferencesand behavior patterns from list-level hybrid feedback into re-ranking multipleitems remains challenging. To this end, we propose Re-ranking with List-levelHybrid Feedback (dubbed RELIFE). It captures user's preferences and behaviorpatterns with three modules: a Disentangled Interest Miner to disentangle theuser's preferences into interests and disinterests, a Sequential PreferenceMixer to learn users' entangled preferences considering the context offeedback, and a Comparison-aware Pattern Extractor to capture user's behaviorpatterns within each list. Moreover, for better integration of patterns,contrastive learning is adopted to align the behavior patterns of candidate andhistorical lists. Extensive experiments show that RELIFE significantlyoutperforms SOTA re-ranking baselines.</description>
      <author>example@mail.com (Muyan Weng, Yunjia Xi, Weiwen Liu, Bo Chen, Jianghao Lin, Ruiming Tang, Weinan Zhang, Yong Yu)</author>
      <guid isPermaLink="false">2410.20778v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Idempotent Unsupervised Representation Learning for Skeleton-Based Action Recognition</title>
      <link>http://arxiv.org/abs/2410.20349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成模型作为一种强大的生成技术，逐渐成为识别任务的重要工具。然而，现有的预训练生成方法在骨架动作识别中获得的特征包含与识别无关的冗余信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于骨架的幂等生成模型（IGM），用于无监督表示学习，以解决现有方法的不足。&lt;h4&gt;方法&lt;/h4&gt;首先理论上证明生成模型与最大熵编码之间的等价性，通过引入对比学习使生成模型的特征更加紧凑。同时，引入幂等性约束，在特征空间中形成更强的一致性正则化，只保留动作语义的关键信息。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集NTU RGB+D和PKUMMD上的广泛实验表明，所提方法的有效性。在NTU 60x子数据集上，性能从84.6%提升到86.2%。&lt;h4&gt;结论&lt;/h4&gt;在零-shot适应场景中，模型在之前无法识别的情况下表现出显著的有效性，取得了良好的结果。&lt;h4&gt;总结&lt;/h4&gt;本项目的代码可在GitHub上找到，链接为：https://github.com/LanglandsLin/IGM。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative models, as a powerful technique for generation, also graduallybecome a critical tool for recognition tasks. However, in skeleton-based actionrecognition, the features obtained from existing pre-trained generative methodscontain redundant information unrelated to recognition, which contradicts thenature of the skeleton's spatially sparse and temporally consistent properties,leading to undesirable performance. To address this challenge, we make effortsto bridge the gap in theory and methodology and propose a novel skeleton-basedidempotent generative model (IGM) for unsupervised representation learning.More specifically, we first theoretically demonstrate the equivalence betweengenerative models and maximum entropy coding, which demonstrates a potentialroute that makes the features of generative models more compact by introducingcontrastive learning. To this end, we introduce the idempotency constraint toform a stronger consistency regularization in the feature space, to push thefeatures only to maintain the critical information of motion semantics for therecognition task. Our extensive experiments on benchmark datasets, NTU RGB+Dand PKUMMD, demonstrate the effectiveness of our proposed method. On the NTU 60xsub dataset, we observe a performance improvement from 84.6$\%$ to 86.2$\%$.Furthermore, in zero-shot adaptation scenarios, our model demonstratessignificant efficacy by achieving promising results in cases that werepreviously unrecognizable. Our project is available at\url{https://github.com/LanglandsLin/IGM}.</description>
      <author>example@mail.com (Lilang Lin, Lehong Wu, Jiahang Zhang, Jiaying Liu)</author>
      <guid isPermaLink="false">2410.20349v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>The Galaxy Zoo Catalogs for the Galaxy And Mass Assembly (GAMA) Survey</title>
      <link>http://arxiv.org/abs/2410.19985v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 22 figures, 8 tables, accepted for publication in PASA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "Galaxy Zoo是一个在线项目，用于通过公众投票对额外星系成像调查的形态特征进行分类。",
    "目的": "比较在不同调查（DESI成像调查和部分KiDS调查）中进行的分类，以进行交叉验证。",
    "方法": "对比不同成像质量和深度下的分类结果，分析投票一致性。",
    "主要发现": "整体投票结果一致，但个别星系存在显著差异。DESI+\rev{{\sc zoobot}}分类中，'平滑'星系的投票比例较高，主要是由于成像深度的差异。",
    "结论": "DESI成像比KiDS更浅且分辨率略低，导致Galaxy Zoo图像未显示出盘面特征。与专家视觉分类进行对比后，KiDS基础的Galaxy Zoo投票结果一致性良好。经过红移校正后，DESI和KiDS的Galaxy Zoo分类在种群属性上也表现出良好一致性。",
    "总结": "zoobot的交叉验证增强了其补充Galaxy Zoo分类及跨调查转移学习的能力的信心。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Galaxy Zoo is an online project to classify morphological features inextra-galactic imaging surveys with public voting. In this paper, we comparethe classifications made for two different surveys, the Dark EnergySpectroscopic Instrument (DESI) imaging survey and a part of the Kilo-DegreeSurvey (KiDS), in the equatorial fields of the Galaxy And Mass Assembly (GAMA)survey. Our aim is to cross-validate and compare the classifications based ondifferent imaging quality and depth.  We find that generally the voting agrees globally but with substantialscatter i.e. substantial differences for individual galaxies. There is anotable higher voting fraction in favor of ``smooth'' galaxies in theDESI+\rev{{\sc zoobot}} classifications, most likely due to the differencebetween imaging depth. DESI imaging is shallower and slightly lower resolutionthan KiDS and the Galaxy Zoo images do not reveal details such as disk features\rev{and thus are missed in the {\sc zoobot} training sample}. \rev{We checkagainst expert visual classifications and find good agreement with KiDS-basedGalaxy Zoo voting.}  We reproduce the results from Porter-Temple+ (2022), on the dependence ofstellar mass, star-formation, and specific star-formation on the number ofspiral arms. This shows that once corrected for redshift, the DESI Galaxy Zooand KiDS Galaxy Zoo classifications agree well on population properties. Thezoobot cross-validation increases confidence in its ability to complimentGalaxy Zoo classifications and its ability for transfer learning acrosssurveys.</description>
      <author>example@mail.com (Benne W. Holwerda, Clayton Robertson, Kyle Cook, Kevin A. Pimbblet, Sarah Casura, Anne E. Sansom, Divya Patel, Trevor Butrum, David H. W. Glass, Lee Kelvin, Ivan K. Baldry, Roberto De Propris, Steven Bamford, Karen Masters, Maria Stone, Tim Hardin, Mike Walmsley, Jochen Liske, S M Rafee Adnan)</author>
      <guid isPermaLink="false">2410.19985v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Quality Analysis of the Coding Bitrate Tradeoff Between Geometry and Attributes for Colored Point Clouds</title>
      <link>http://arxiv.org/abs/2410.21613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云编码通常对几何信息和属性（如RGB颜色组件）分配相似的比特率。&lt;h4&gt;目的&lt;/h4&gt;研究几何和属性编码之间不同比特率权衡对点云质量的影响。&lt;h4&gt;方法&lt;/h4&gt;使用MPEG标准的几何点云压缩（G-PCC）编码五种不同特征和类型的点云，采用八叉树编码几何信息，使用区域自适应层次变换和预测提升变换编码属性。同时测试JPEG Pleno点云验证模型。&lt;h4&gt;主要发现&lt;/h4&gt;考虑了五种不同的属性/几何比特率权衡，结果显示属性编码的比特率分配较高时通常效果更好。&lt;h4&gt;结论&lt;/h4&gt;较高的属性编码比特率分配通常会带来稍微更好的重建结果。&lt;h4&gt;总结&lt;/h4&gt;该研究为点云编码提供了不同比特率权衡的质量评估，指出属性编码的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Typically, point cloud encoders allocate a similar bitrate for geometry andattributes (usually RGB color components) information coding. This paperreports a quality study considering different coding bitrate tradeoff betweengeometry and attributes. A set of five point clouds, representing differentcharacteristics and types of content was encoded with the MPEG standardGeometry Point Cloud Compression (G-PCC), using octree to encode geometryinformation, and both the Region Adaptive Hierarchical Transform and thePrediction Lifting transform for attributes. Furthermore, the JPEG Pleno PointCloud Verification Model was also tested. Five different attributes/geometrybitrate tradeoffs were considered, notably 70%/30%, 60%/40%, 50%/50%, 40%/60%,30%/70%. Three point cloud objective metrics were selected to assess thequality of the reconstructed point clouds, notably the PSNR YUV, the PointCloud Quality Metric, and GraphSIM. Furthermore, for each encoder, theBjonteegaard Deltas were computed for each tradeoff, using the 50%/50% tradeoffas a reference. The reported results indicate that using a higher bitrateallocation for attribute encoding usually yields slightly better results.</description>
      <author>example@mail.com (Joao Prazeres, Rafael Rodrigues, Manuela Pereira, Antonio M. G. Pinheiro)</author>
      <guid isPermaLink="false">2410.21613v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Improving In-Context Learning with Small Language Model Ensembles</title>
      <link>http://arxiv.org/abs/2410.21868v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024 Workshop on Adaptive Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在多种任务中表现出色，但在特定领域任务上的表现仍有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，提升ICL在特定领域任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;提出Ensemble SuperICL，通过利用多个微调的小型语言模型（SLMs）的专业知识来增强ICL。&lt;h4&gt;主要发现&lt;/h4&gt;Ensemble SuperICL在多个自然语言理解基准上达到了最先进的结果，并在医学领域的标注任务中表现优异。&lt;h4&gt;结论&lt;/h4&gt;Ensemble SuperICL为LLMs提供了一种成本低效高的领域专业化方法，适合实际应用。&lt;h4&gt;总结&lt;/h4&gt;本研究满足了对高效领域专业化方法的需求，为从业者提供了一种经济有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mehdimojarradi/Ensemble-SuperICL&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have shown impressive capabilities acrossvarious tasks, but their performance on domain-specific tasks remains limited.While methods like retrieval augmented generation and fine-tuning can help toaddress this, they require significant resources. In-context learning (ICL) isa cheap and efficient alternative but cannot match the accuracies of advancedmethods. We present Ensemble SuperICL, a novel approach that enhances ICL byleveraging the expertise of multiple fine-tuned small language models (SLMs).Ensemble SuperICL achieves state of the art (SoTA) results on several naturallanguage understanding benchmarks. Additionally, we test it on a medical-domainlabelling task and showcase its practicality by using off-the-shelf SLMsfine-tuned on a general language task, achieving superior accuracy inlarge-scale data labelling compared to all baselines. Finally, we conduct anablation study and sensitivity analyses to elucidate the underlying mechanismof Ensemble SuperICL. Our research contributes to the growing demand forefficient domain specialisation methods in LLMs, offering a cheap and effectivemethod for practitioners.</description>
      <author>example@mail.com (M. Mehdi Mojarradi, Lingyi Yang, Robert McCraith, Adam Mahdi)</author>
      <guid isPermaLink="false">2410.21868v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fidelity-Imposed Displacement Editing for the Learn2Reg 2024 SHG-BF Challenge</title>
      <link>http://arxiv.org/abs/2410.20812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;二次谐波生成(SHG)与明场(BF)显微镜的联合检查可以区分组织成分和胶原纤维，帮助分析人类乳腺癌和胰腺癌组织。&lt;h4&gt;目的&lt;/h4&gt;解决SHG和BF图像之间的大差异，以提高当前基于学习的注册模型在对齐SHG与BF图像时的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型的多模态注册框架，采用忠实性强加位移编辑，结合批量对比学习、特征预对齐和实例级优化。&lt;h4&gt;主要发现&lt;/h4&gt;在Learn2Reg COMULISglobe SHG-BF挑战赛中，实验结果验证了该方法的有效性，并在在线排行榜上获得第一名。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架有效解决了SHG和BF图像对齐的问题，显示出在多模态图像注册中的潜力。&lt;h4&gt;总结&lt;/h4&gt;通过创新的方法提高了二次谐波生成与明场显微镜图像的注册精度，推动了癌症组织分析的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Co-examination of second-harmonic generation (SHG) and bright-field (BF)microscopy enables the differentiation of tissue components and collagenfibers, aiding the analysis of human breast and pancreatic cancer tissues.However, large discrepancies between SHG and BF images pose challenges forcurrent learning-based registration models in aligning SHG to BF. In thispaper, we propose a novel multi-modal registration framework that employsfidelity-imposed displacement editing to address these challenges. Theframework integrates batch-wise contrastive learning, feature-basedpre-alignment, and instance-level optimization. Experimental results from theLearn2Reg COMULISglobe SHG-BF Challenge validate the effectiveness of ourmethod, securing the 1st place on the online leaderboard.</description>
      <author>example@mail.com (Jiacheng Wang, Xiang Chen, Renjiu Hu, Rongguang Wang, Min Liu, Yaonan Wang, Jiazheng Wang, Hao Li, Hang Zhang)</author>
      <guid isPermaLink="false">2410.20812v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PaPaGei: Open Foundation Models for Optical Physiological Signals</title>
      <link>http://arxiv.org/abs/2410.20542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and models:
  https://github.com/nokia-bell-labs/papagei-foundation-model&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;光电容积描记法（PPG）是监测生物信号和心血管健康最广泛使用的非侵入性技术，应用于临床和可穿戴设备的消费者健康。&lt;h4&gt;目的&lt;/h4&gt;提出PaPaGei，这是第一个针对PPG信号的开放基础模型，以解决现有模型缺乏通用性的问题。&lt;h4&gt;方法&lt;/h4&gt;PaPaGei在超过57,000小时的2000万个未标记PPG信号段上进行预训练，使用公开数据集，并在20个任务和10个多样化数据集上进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;PaPaGei在至少14个任务中相比其他竞争时间序列基础模型的分类和回归性能分别提高了6.3%和2.9%。&lt;h4&gt;结论&lt;/h4&gt;PaPaGei比其他基础模型或方法更有效，能够在不同肤色下保持稳健性，为未来模型的偏差评估建立了基准。&lt;h4&gt;应用&lt;/h4&gt;PaPaGei可以作为特征提取器和其他多模态模型的编码器，开辟了多模态健康监测的新机会。&lt;h4&gt;总结&lt;/h4&gt;PaPaGei模型展示了在PPG信号处理中的创新与优势，推动了生物信号监测技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nokia-bell-labs/papagei-foundation-model&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Photoplethysmography (PPG) is the most widely used non-invasive technique formonitoring biosignals and cardiovascular health, with applications in bothclinical settings and consumer health through wearable devices. Current machinelearning models trained on PPG signals are mostly task-specific and lackgeneralizability. Previous works often used single-device datasets, did notexplore out-of-domain generalization, or did not release their models,hindering reproducibility and further research. We introduce PaPaGei, the firstopen foundation model for PPG signals. PaPaGei is pre-trained on more than57,000 hours of 20 million unlabeled segments of PPG signals using publiclyavailable datasets exclusively. We evaluate against popular time-seriesfoundation models and other benchmarks on 20 tasks of 10 diverse datasetsspanning cardiovascular health, sleep disorders, pregnancy monitoring, andwellbeing assessment. Our architecture incorporates novel representationlearning approaches that leverage differences in PPG signal morphology acrossindividuals, enabling it to capture richer representations than traditionalcontrastive learning methods. Across 20 tasks, PaPaGei improves classificationand regression performance by an average of 6.3% and 2.9%, respectively,compared to other competitive time-series foundation models in at least 14tasks. PaPaGei is more data- and parameter-efficient than other foundationmodels or methods, as it outperforms 70x larger models. Beyond accuracy, wealso investigate robustness against different skin tones, establishing abenchmark for bias evaluations of future models. Notably, PaPaGei can be usedout of the box as both a feature extractor and an encoder for other multimodalmodels, opening up new opportunities for multimodal health monitoring</description>
      <author>example@mail.com (Arvind Pillai, Dimitris Spathis, Fahim Kawsar, Mohammad Malekzadeh)</author>
      <guid isPermaLink="false">2410.20542v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks on Discriminative Graphs of Words</title>
      <link>http://arxiv.org/abs/2410.20469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在复杂数据结构推断中的成功促使许多研究将其应用于文本分类任务。&lt;h4&gt;目的&lt;/h4&gt;探索一种新的判别图词图神经网络（DGoW-GNN）方法，用于文本分类。&lt;h4&gt;方法&lt;/h4&gt;构建仅包含词节点的图，不使用文档节点，根据标签将训练语料分成不相连的子图，边的权重由表示词的点互信息决定。将文本分类任务重新表述为游走分类任务，并提出结合GNN和序列模型的新模型。&lt;h4&gt;主要发现&lt;/h4&gt;在七个基准数据集上的评估中，DGoW-GNN的表现不及多个最先进的基线模型。&lt;h4&gt;结论&lt;/h4&gt;分析了性能差异的原因，并假设在何种条件下DGoW-GNN的表现可能改善。&lt;h4&gt;总结&lt;/h4&gt;DGoW-GNN提供了一种新的视角来处理文本分类，但仍需改进以提升其性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/abbahaddou/DGOW&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In light of the recent success of Graph Neural Networks (GNNs) and theirability to perform inference on complex data structures, many studies applyGNNs to the task of text classification. In most previous methods, aheterogeneous graph, containing both word and document nodes, is constructedusing the entire corpus and a GNN is used to classify document nodes. In thiswork, we explore a new Discriminative Graph of Words Graph Neural Network(DGoW-GNN) approach encapsulating both a novel discriminative graphconstruction and model to classify text. In our graph construction, containingonly word nodes and no document nodes, we split the training corpus intodisconnected subgraphs according to their labels and weight edges by thepointwise mutual information of the represented words. Our graph construction,for which we provide theoretical motivation, allows us to reformulate the taskof text classification as the task of walk classification. We also propose anew model for the graph-based classification of text, which combines a GNN anda sequence model. We evaluate our approach on seven benchmark datasets and findthat it is outperformed by several state-of-the-art baseline models. We analysereasons for this performance difference and hypothesise under which conditionsit is likely to change.</description>
      <author>example@mail.com (Yassine Abbahaddou, Johannes F. Lutzeyer, Michalis Vazirgiannis)</author>
      <guid isPermaLink="false">2410.20469v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models</title>
      <link>http://arxiv.org/abs/2410.20008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to EMNLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;微调预训练的大型语言模型（LLMs）已成为解决各种自然语言处理（NLP）任务的常用方法。&lt;h4&gt;目的&lt;/h4&gt;研究预训练LLMs中编码的任务特定信息及指令微调对其表示的影响。&lt;h4&gt;方法&lt;/h4&gt;使用矩阵分析工具，比较预训练和指令微调的LLMs在存储任务特定信息方面的差异。&lt;h4&gt;主要发现&lt;/h4&gt;部分任务已在预训练LLMs中编码，而另一些任务则从指令微调中获益显著。&lt;h4&gt;结论&lt;/h4&gt;确定了模型从高层次通用表示转向更任务导向表示的层次，这加深了对LLMs工作机制的理解，并有助于未来在高效迁移学习和多任务学习领域的研究。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了LLMs在不同任务中的表现差异及其潜在改进方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning pre-trained large language models (LLMs) on a diverse array oftasks has become a common approach for building models that can solve variousnatural language processing (NLP) tasks. However, where and to what extentthese models retain task-specific knowledge remains largely unexplored. Thisstudy investigates the task-specific information encoded in pre-trained LLMsand the effects of instruction tuning on their representations across a diverseset of over 60 NLP tasks. We use a set of matrix analysis tools to examine thedifferences between the way pre-trained and instruction-tuned LLMs storetask-specific information. Our findings reveal that while some tasks arealready encoded within the pre-trained LLMs, others greatly benefit frominstruction tuning. Additionally, we pinpointed the layers in which the modeltransitions from high-level general representations to more task-orientedrepresentations. This finding extends our understanding of the governingmechanisms of LLMs and facilitates future research in the fields ofparameter-efficient transfer learning and multi-task learning.</description>
      <author>example@mail.com (Zheng Zhao, Yftah Ziser, Shay B. Cohen)</author>
      <guid isPermaLink="false">2410.20008v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Standardization Trends on Safety and Trustworthiness Technology for Advanced AI</title>
      <link>http://arxiv.org/abs/2410.22151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 2 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能（AI）在过去十年迅速发展，特别是在语言理解、图像和视频识别、编程和科学推理等领域。&lt;h4&gt;目的&lt;/h4&gt;分析先进人工智能的安全性和可信性标准化的国际趋势，支持安全和可信的AI发展。&lt;h4&gt;方法&lt;/h4&gt;识别标准化的关键领域，提出未来的方向和策略，并讨论政策影响。&lt;h4&gt;主要发现&lt;/h4&gt;基于大型语言模型和基础模型的AI技术正在接近或超越人工通用智能，表现出在复杂问题解决和多领域任务中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;尽管AI的进步可能变革科学、工业、医疗和教育等领域，但也引发了关于其安全性和可信性的担忧。&lt;h4&gt;风险&lt;/h4&gt;包括不受控性、伦理冲突、长期社会经济影响和安全保障等相关风险。&lt;h4&gt;标准化努力&lt;/h4&gt;正在制定国际公认的标准，以确保AI的安全性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;有效的标准化有助于提升国际竞争力，促进先进AI的安全和可信发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.22648/ETRI.2024.J.390511&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial Intelligence (AI) has rapidly evolved over the past decade and hasadvanced in areas such as language comprehension, image and video recognition,programming, and scientific reasoning. Recent AI technologies based on largelanguage models and foundation models are approaching or surpassing artificialgeneral intelligence. These systems demonstrate superior performance in complexproblem solving, natural language processing, and multi-domain tasks, and canpotentially transform fields such as science, industry, healthcare, andeducation. However, these advancements have raised concerns regarding thesafety and trustworthiness of advanced AI, including risks related touncontrollability, ethical conflicts, long-term socioeconomic impacts, andsafety assurance. Efforts are being expended to develop internationallyagreed-upon standards to ensure the safety and reliability of AI. This studyanalyzes international trends in safety and trustworthiness standardization foradvanced AI, identifies key areas for standardization, proposes futuredirections and strategies, and draws policy implications. The goal is tosupport the safe and trustworthy development of advanced AI and enhanceinternational competitiveness through effective standardization.</description>
      <author>example@mail.com (Jonghong Jeon)</author>
      <guid isPermaLink="false">2410.22151v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.20964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in NeurIPS 2024. Code is available at
  https://github.com/heyongxin233/DeTeCtive&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前检测AI生成文本的技术主要依赖手动特征提取和监督二分类方法，这些方法在性能上存在瓶颈，且通用性不佳。&lt;h4&gt;目的&lt;/h4&gt;重新审视AI生成文本检测任务，强调区分不同作者的写作风格，而不仅仅是将文本分类为人类写作或AI生成。&lt;h4&gt;方法&lt;/h4&gt;提出DeTeCtive，一个多任务辅助、多层次对比学习框架，以促进学习不同的写作风格，并结合密集信息检索管道进行AI生成文本检测。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验，证明该方法提升了各种文本编码器在多个基准测试中检测AI生成文本的能力，并在OOD零-shot评估中大幅超越现有方法。该方法还具备对OOD数据的训练无关增量适应（TFIA）能力，进一步增强了其在OOD检测场景中的有效性。&lt;h4&gt;结论&lt;/h4&gt;希望通过开源代码和模型，激发AI生成文本检测领域的新思路，确保大型语言模型的安全应用并增强合规性。&lt;h4&gt;总结&lt;/h4&gt;DeTeCtive框架在AI生成文本检测方面表现优异，为未来的研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current techniques for detecting AI-generated text are largely confined tomanual feature crafting and supervised binary classification paradigms. Thesemethodologies typically lead to performance bottlenecks and unsatisfactorygeneralizability. Consequently, these methods are often inapplicable forout-of-distribution (OOD) data and newly emerged large language models (LLMs).In this paper, we revisit the task of AI-generated text detection. We arguethat the key to accomplishing this task lies in distinguishing writing stylesof different authors, rather than simply classifying the text intohuman-written or AI-generated text. To this end, we propose DeTeCtive, amulti-task auxiliary, multi-level contrastive learning framework. DeTeCtive isdesigned to facilitate the learning of distinct writing styles, combined with adense information retrieval pipeline for AI-generated text detection. Ourmethod is compatible with a range of text encoders. Extensive experimentsdemonstrate that our method enhances the ability of various text encoders indetecting AI-generated text across multiple benchmarks and achievesstate-of-the-art results. Notably, in OOD zero-shot evaluation, our methodoutperforms existing approaches by a large margin. Moreover, we find our methodboasts a Training-Free Incremental Adaptation (TFIA) capability towards OODdata, further enhancing its efficacy in OOD detection scenarios. We willopen-source our code and models in hopes that our work will spark new thoughtsin the field of AI-generated text detection, ensuring safe application of LLMsand enhancing compliance. Our code is available athttps://github.com/heyongxin233/DeTeCtive.</description>
      <author>example@mail.com (Xun Guo, Shan Zhang, Yongxin He, Ting Zhang, Wanquan Feng, Haibin Huang, Chongyang Ma)</author>
      <guid isPermaLink="false">2410.20964v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DHPrep: Deep Hawkes Process based Dynamic Network Representation</title>
      <link>http://arxiv.org/abs/2410.20627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;网络表示旨在将顶点编码到低维空间，同时保留原始网络结构和属性。大多数现有方法集中在静态网络结构上，未考虑时间动态性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够捕捉动态网络时间动态的算法，特别用于预测动态网络行为。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于深度霍克斯过程的动态网络表示算法（DHPrep），结合结构信息和时间动态来学习顶点表示。&lt;h4&gt;主要发现&lt;/h4&gt;DHPrep算法在多项任务（包括链接预测和顶点推荐）中，表现优于现有的最先进基准方法。&lt;h4&gt;结论&lt;/h4&gt;DHPrep有效捕捉动态网络的时间动态，确保表示随时间平滑演变。&lt;h4&gt;总结&lt;/h4&gt;本研究通过实验验证了DHPrep在动态网络表示学习中的优势，强调了时间动态在网络表示中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Networks representation aims to encode vertices into a low-dimensional space,while preserving the original network structures and properties. Most existingmethods focus on static network structure without considering temporaldynamics. However, in real world, most networks (e.g., social and biologicalnetworks) are dynamic in nature and are constantly evolving over time. Suchtemporal dynamics are critical in representations learning, especially forpredicting dynamic networks behaviors. To this end, a Deep Hawkes Process basedDynamic Networks Representation algorithm (DHPrep) is proposed in this paper,which is capable of capturing temporal dynamics of dynamic networks.Specifically, DHPrep incorporates both structural information and temporaldynamics to learn vertices representations that can model the edge formationprocess for a vertex pair, where the structural information is used to capturethe historical impact from their neighborhood, and the temporal dynamicsutilize this historical information and apply Hawkes point process to model theedges formation process. Moreover, a temporal smoother is further imposed toensure the representations evolve smoothly over time. To evaluate theeffectiveness of DHPrep, extensive experiments are carried out using fourreal-world datasets. Experimental results reveal that our DHPrep algorithmoutperforms state-of-the-art baseline methods in various tasks including linkprediction and vertices recommendation.</description>
      <author>example@mail.com (Ruixuan Han, Hongxiang Li, Bin Xie)</author>
      <guid isPermaLink="false">2410.20627v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Cosmic-Scale Benchmark for Symmetry-Preserving Data Processing</title>
      <link>http://arxiv.org/abs/2410.20516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 3 figures; To appear at the NeurReps Workshop @ NeurIPS
  2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高效处理结构化点云数据并保留多尺度信息是各领域面临的关键挑战。&lt;h4&gt;目的&lt;/h4&gt;基准测试图神经网络在捕捉局部聚类环境和长距离关联能力方面的表现。&lt;h4&gt;方法&lt;/h4&gt;使用模拟星系位置和属性的数据集，评估$E(3)$-等变图神经网络的性能。&lt;h4&gt;主要发现&lt;/h4&gt;对称性强的宇宙数据中，$E(3)$-等变网络在下游性能和模拟效率上优于非等变网络及特定领域信息提取技术。&lt;h4&gt;结论&lt;/h4&gt;当前架构在捕捉长距离关联信息方面不如领域特定基线，未来需要优化架构以更好地提取长距离信息。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了图神经网络在处理对称性数据中的潜力，同时指出了改进提取长距离信息的必要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently processing structured point cloud data while preservingmultiscale information is a key challenge across domains, from graphics toatomistic modeling. Using a curated dataset of simulated galaxy positions andproperties, represented as point clouds, we benchmark the ability of graphneural networks to simultaneously capture local clustering environments andlong-range correlations. Given the homogeneous and isotropic nature of theUniverse, the data exhibits a high degree of symmetry. We therefore focus onevaluating the performance of Euclidean symmetry-preserving($E(3)$-equivariant) graph neural networks, showing that they can outperformnon-equivariant counterparts and domain-specific information extractiontechniques in downstream performance as well as simulation-efficiency. However,we find that current architectures fail to capture information from long-rangecorrelations as effectively as domain-specific baselines, motivating futurework on architectures better suited for extracting long-range information.</description>
      <author>example@mail.com (Julia Balla, Siddharth Mishra-Sharma, Carolina Cuesta-Lazaro, Tommi Jaakkola, Tess Smidt)</author>
      <guid isPermaLink="false">2410.20516v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DOFS: A Real-world 3D Deformable Object Dataset with Full Spatial Information for Dynamics Model Learning</title>
      <link>http://arxiv.org/abs/2410.21758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 6 figures, 2024 CoRL Workshop on Learning Robot Fine and
  Dexterous Manipulation: Perception and Control&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一个名为DOFS的3D可变形物体（DOs）数据集，包含完整的空间信息。&lt;h4&gt;目的&lt;/h4&gt;利用新颖且低成本的数据收集平台，获取3D可变形物体的多视角信息。&lt;h4&gt;方法&lt;/h4&gt;使用透明操作平面，结合捏合策略和双指夹具进行主动操作，收集RGB-D图像、点云和3D变形网格等数据。&lt;h4&gt;主要发现&lt;/h4&gt;数据集中包含多视角的RGB-D图像、注册良好的点云、3D占用信息及其语义。&lt;h4&gt;结论&lt;/h4&gt;训练了一个神经网络，以低分辨率的3D占用和动作作为输入，建模弹塑性物体的动态特性。&lt;h4&gt;未来工作&lt;/h4&gt;数据集及数据收集系统的所有CAD将很快在我们的网站上发布。&lt;h4&gt;总结&lt;/h4&gt;DOFS数据集为研究3D可变形物体的动态提供了重要的基础数据和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes DOFS, a pilot dataset of 3D deformable objects (DOs)(e.g., elasto-plastic objects) with full spatial information (i.e., top, side,and bottom information) using a novel and low-cost data collection platformwith a transparent operating plane. The dataset consists of active manipulationaction, multi-view RGB-D images, well-registered point clouds, 3D deformedmesh, and 3D occupancy with semantics, using a pinching strategy with atwo-parallel-finger gripper. In addition, we trained a neural network with thedown-sampled 3D occupancy and action as input to model the dynamics of anelasto-plastic object. Our dataset and all CADs of the data collection systemwill be released soon on our website.</description>
      <author>example@mail.com (Zhen Zhang, Xiangyu Chu, Yunxi Tang, K. W. Samuel Au)</author>
      <guid isPermaLink="false">2410.21758v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Towards Unifying Understanding and Generation in the Era of Vision Foundation Models: A Survey from the Autoregression Perspective</title>
      <link>http://arxiv.org/abs/2410.22217v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 1 table, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自回归在大型语言模型中展现了良好的可扩展性，将所有语言任务统一为下一个标记预测的范式。&lt;h4&gt;目的&lt;/h4&gt;探讨将自回归模型的成功扩展到视觉基础模型的可能性。&lt;h4&gt;方法&lt;/h4&gt;回顾近期的进展，分析现有视觉基础模型的局限性，并提出自回归的正式定义及其优势。&lt;h4&gt;主要发现&lt;/h4&gt;展示了下一代视觉基础模型的趋势，即将理解和生成统一于视觉任务中，并对自回归视觉基础模型进行分类。&lt;h4&gt;结论&lt;/h4&gt;这是首次全面总结自回归视觉基础模型在理解与生成统一趋势下的研究。&lt;h4&gt;挑战&lt;/h4&gt;讨论了多个有前景的研究挑战和方向。&lt;h4&gt;资源&lt;/h4&gt;提供了相关资源链接，供进一步研究使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autoregression in large language models (LLMs) has shown impressivescalability by unifying all language tasks into the next token predictionparadigm. Recently, there is a growing interest in extending this success tovision foundation models. In this survey, we review the recent advances anddiscuss future directions for autoregressive vision foundation models. First,we present the trend for next generation of vision foundation models, i.e.,unifying both understanding and generation in vision tasks. We then analyze thelimitations of existing vision foundation models, and present a formaldefinition of autoregression with its advantages. Later, we categorizeautoregressive vision foundation models from their vision tokenizers andautoregression backbones. Finally, we discuss several promising researchchallenges and directions. To the best of our knowledge, this is the firstsurvey to comprehensively summarize autoregressive vision foundation modelsunder the trend of unifying understanding and generation. A collection ofrelated resources is available at https://github.com/EmmaSRH/ARVFM.</description>
      <author>example@mail.com (Shenghao Xie, Wenqiang Zu, Mingyang Zhao, Duo Su, Shilong Liu, Ruohua Shi, Guoqi Li, Shanghang Zhang, Lei Ma)</author>
      <guid isPermaLink="false">2410.22217v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Sensor2Text: Enabling Natural Language Interactions for Daily Activity Tracking Using Wearable Sensors</title>
      <link>http://arxiv.org/abs/2410.20034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉问答技术可以根据图像和自然语言问题生成文本响应，已在日常活动跟踪和医疗监测中取得显著进展，尤其对老年患者和记忆障碍者至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出Sensor2Text模型，以利用可穿戴传感器追踪日常活动并进行对话。&lt;h4&gt;方法&lt;/h4&gt;通过转移学习和师生网络克服可穿戴传感器数据的信息密度低、单一传感器识别活动的不足，以及模型在问答和互动对话中的能力限制，设计了一个编码-解码神经网络模型来联合处理语言和传感器数据。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够识别人体活动，并利用不同的可穿戴传感器进行问答对话，在字幕生成和对话任务上表现与现有视觉语言模型相当或更好。&lt;h4&gt;结论&lt;/h4&gt;这是首个能够就可穿戴传感器数据进行对话的模型，提供了一种创新的方法来跟踪日常活动，解决了当前基于视觉解决方案的隐私和视野限制问题。&lt;h4&gt;总结&lt;/h4&gt;Sensor2Text模型为日常活动监测提供了一种新颖的解决方案，兼顾隐私和信息获取的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Question-Answering, a technology that generates textual responses froman image and natural language question, has progressed significantly. Notably,it can aid in tracking and inquiring about daily activities, crucial inhealthcare monitoring, especially for elderly patients or those with memorydisabilities. However, video poses privacy concerns and has a limited field ofview. This paper presents Sensor2Text, a model proficient in tracking dailyactivities and engaging in conversations using wearable sensors. The approachoutlined here tackles several challenges, including low information density inwearable sensor data, insufficiency of single wearable sensors in humanactivities recognition, and model's limited capacity for Question-Answering andinteractive conversations. To resolve these obstacles, transfer learning andstudent-teacher networks are utilized to leverage knowledge fromvisual-language models. Additionally, an encoder-decoder neural network modelis devised to jointly process language and sensor data for conversationalpurposes. Furthermore, Large Language Models are also utilized to enableinteractive capabilities. The model showcases the ability to identify humanactivities and engage in Q\&amp;A dialogues using various wearable sensormodalities. It performs comparably to or better than existing visual-languagemodels in both captioning and conversational tasks. To our knowledge, thisrepresents the first model capable of conversing about wearable sensor data,offering an innovative approach to daily activity tracking that addressesprivacy and field-of-view limitations associated with current vision-basedsolutions.</description>
      <author>example@mail.com (Wenqiang Chen, Jiaxuan Cheng, Leyao Wang, Wei Zhao, Wojciech Matusik)</author>
      <guid isPermaLink="false">2410.20034v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>BEVPose: Unveiling Scene Semantics through Pose-Guided Multi-Modal BEV Alignment</title>
      <link>http://arxiv.org/abs/2410.20969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS), 2024. Project page:
  https://m80hz.github.io/bevpose/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶和移动机器人领域，鸟瞰视图（BEV）表示方法发生了显著变化，主要使用变换器和融合来自不同视觉传感器（如激光雷达和相机）的测量数据。&lt;h4&gt;目的&lt;/h4&gt;提出BEVPose框架，集成来自相机和激光雷达的数据的BEV表示，减少对大量标注数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;通过利用传感器姿态作为指导信号，对多模态传感器输入进行对齐和融合，以学习捕捉环境几何和语义特征的潜在BEV嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;预训练方法在BEV地图分割任务中表现出色，超越了完全监督的最新方法，仅需极少量标注数据。&lt;h4&gt;结论&lt;/h4&gt;该研究不仅解决了BEV表示学习中数据效率的问题，还拓宽了这些技术在各种领域（包括越野和室内环境）的潜力。&lt;h4&gt;总结&lt;/h4&gt;BEVPose框架通过有效利用传感器姿态信息，在实现高效学习的同时，降低了对标注数据的需求，展示了在多种环境中应用的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of autonomous driving and mobile robotics, there has been asignificant shift in the methods used to create Bird's Eye View (BEV)representations. This shift is characterised by using transformers and learningto fuse measurements from disparate vision sensors, mainly lidar and cameras,into a 2D planar ground-based representation. However, these learning-basedmethods for creating such maps often rely heavily on extensive annotated data,presenting notable challenges, particularly in diverse or non-urbanenvironments where large-scale datasets are scarce. In this work, we presentBEVPose, a framework that integrates BEV representations from camera and lidardata, using sensor pose as a guiding supervisory signal. This method notablyreduces the dependence on costly annotated data. By leveraging poseinformation, we align and fuse multi-modal sensory inputs, facilitating thelearning of latent BEV embeddings that capture both geometric and semanticaspects of the environment. Our pretraining approach demonstrates promisingperformance in BEV map segmentation tasks, outperforming fully-supervisedstate-of-the-art methods, while necessitating only a minimal amount ofannotated data. This development not only confronts the challenge of dataefficiency in BEV representation learning but also broadens the potential forsuch techniques in a variety of domains, including off-road and indoorenvironments.</description>
      <author>example@mail.com (Mehdi Hosseinzadeh, Ian Reid)</author>
      <guid isPermaLink="false">2410.20969v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SEG:Seeds-Enhanced Iterative Refinement Graph Neural Network for Entity Alignment</title>
      <link>http://arxiv.org/abs/2410.20733v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;实体对齐对于合并知识图谱至关重要，因为它匹配具有相同语义的实体。&lt;h4&gt;目的&lt;/h4&gt;解决由于多样化数据源导致的非同构邻域结构所带来的对齐困难，特别是对于不常见和稀疏连接的实体。&lt;h4&gt;方法&lt;/h4&gt;提出了一种软标签传播框架，整合多源数据和迭代种子增强，处理大规模数据集的可扩展性挑战。&lt;h4&gt;主要发现&lt;/h4&gt;该框架使用种子进行锚定，选择最佳关系对，创建富含邻域特征和语义关系数据的软标签。&lt;h4&gt;结论&lt;/h4&gt;实现了双向加权联合损失函数，缩小正样本之间的距离，并差异化处理负样本，考虑非同构邻域结构。&lt;h4&gt;总结&lt;/h4&gt;我们的方法在多个数据集上优于现有的半监督方法，显著提高了实体对齐的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Entity alignment is crucial for merging knowledge across knowledge graphs, asit matches entities with identical semantics. The standard method matches theseentities based on their embedding similarities using semi-supervised learning.However, diverse data sources lead to non-isomorphic neighborhood structuresfor aligned entities, complicating alignment, especially for less common andsparsely connected entities. This paper presents a soft label propagationframework that integrates multi-source data and iterative seed enhancement,addressing scalability challenges in handling extensive datasets where scalecomputing excels. The framework uses seeds for anchoring and selects optimalrelationship pairs to create soft labels rich in neighborhood features andsemantic relationship data. A bidirectional weighted joint loss function isimplemented, which reduces the distance between positive samples anddifferentially processes negative samples, taking into account thenon-isomorphic neighborhood structures. Our method outperforms existingsemi-supervised approaches, as evidenced by superior results on multipledatasets, significantly improving the quality of entity alignment.</description>
      <author>example@mail.com (Wei Ai, Yinghui Gao, Jianbin Li, Jiayi Du, Tao Meng, Yuntao Shou, Keqin Li)</author>
      <guid isPermaLink="false">2410.20733v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Detection-Guided Deep Learning-Based Model with Spatial Regularization for Lung Nodule Segmentation</title>
      <link>http://arxiv.org/abs/2410.20154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;肺癌是全球癌症诊断的主要原因，也是癌症相关死亡的首要原因。早期检测肺结节对改善患者预后至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高肺结节的分割精度，以帮助医生区分恶性和良性病变。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型模型，利用深度学习框架将分割和分类过程整合，采用特征组合块以促进信息共享，并结合空间正则化技术提升精度。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在捕捉目标结节的准确性上优于其他常用模型，通过迁移学习进一步提升性能，敏感性得分为0.885，Dice得分为0.814。&lt;h4&gt;结论&lt;/h4&gt;新模型在CT图像中对肺结节的分割性能显著提升，为肺癌早期诊断提供了有效工具。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了深度学习在医疗影像分析中的潜力，尤其是在肺癌的早期检测和治疗中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lung cancer ranks as one of the leading causes of cancer diagnosis and is theforemost cause of cancer-related mortality worldwide. The early detection oflung nodules plays a pivotal role in improving outcomes for patients, as itenables timely and effective treatment interventions. The segmentation of lungnodules plays a critical role in aiding physicians in distinguishing betweenmalignant and benign lesions. However, this task remains challenging due to thesubstantial variation in the shapes and sizes of lung nodules, and theirfrequent proximity to lung tissues, which complicates clear delineation. Inthis study, we introduce a novel model for segmenting lung nodules in computedtomography (CT) images, leveraging a deep learning framework that integratessegmentation and classification processes. This model is distinguished by itsuse of feature combination blocks, which facilitate the sharing of informationbetween the segmentation and classification components. Additionally, we employthe classification outcomes as priors to refine the size estimation of thepredicted nodules, integrating these with a spatial regularization technique toenhance precision. Furthermore, recognizing the challenges posed by limitedtraining datasets, we have developed an optimal transfer learning strategy thatfreezes certain layers to further improve performance. The results show thatour proposed model can capture the target nodules more accurately compared toother commonly used models. By applying transfer learning, the performance canbe further improved, achieving a sensitivity score of 0.885 and a Dice score of0.814.</description>
      <author>example@mail.com (Jiasen Zhang, Mingrui Yang, Weihong Guo, Brian A. Xavier, Michael Bolen, Xiaojuan Li)</author>
      <guid isPermaLink="false">2410.20154v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Disentangled and Self-Explainable Node Representation Learning</title>
      <link>http://arxiv.org/abs/2410.21043v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;节点表示或嵌入是捕捉节点属性的低维向量，通常通过无监督结构相似性目标或监督任务进行学习，但无监督节点嵌入的可解释性研究较少。&lt;h4&gt;目的&lt;/h4&gt;提出DiSeNE框架，生成自解释的节点嵌入，填补无监督节点嵌入可解释性研究的空白。&lt;h4&gt;方法&lt;/h4&gt;采用解耦表示学习，生成维度可解释的嵌入，每个维度与图的不同拓扑结构对齐，同时优化可解释性和解耦性的新目标函数。&lt;h4&gt;主要发现&lt;/h4&gt;通过多个基准数据集的广泛实验，验证了所提出方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;DiSeNE框架有效地实现了自解释的节点嵌入，为无监督学习提供了新的视角和方法。&lt;h4&gt;总结&lt;/h4&gt;该研究推动了节点嵌入的可解释性研究，提出了新的评估指标，丰富了图模型的理解和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node representations, or embeddings, are low-dimensional vectors that capturenode properties, typically learned through unsupervised structural similarityobjectives or supervised tasks. While recent efforts have focused on explaininggraph model decisions, the interpretability of unsupervised node embeddingsremains underexplored. To bridge this gap, we introduce DiSeNE (Disentangledand Self-Explainable Node Embedding), a framework that generatesself-explainable embeddings in an unsupervised manner. Our method employsdisentangled representation learning to produce dimension-wise interpretableembeddings, where each dimension is aligned with distinct topological structureof the graph. We formalize novel desiderata for disentangled and interpretableembeddings, which drive our new objective functions, optimizing simultaneouslyfor both interpretability and disentanglement. Additionally, we propose severalnew metrics to evaluate representation quality and human interpretability.Extensive experiments across multiple benchmark datasets demonstrate theeffectiveness of our approach.</description>
      <author>example@mail.com (Simone Piaggesi, André Panisson, Megha Khosla)</author>
      <guid isPermaLink="false">2410.21043v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Review of Graph-Powered Data Quality Applications for IoT Monitoring Sensor Networks</title>
      <link>http://arxiv.org/abs/2410.21006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper submitted to Journal of Network and Computer Applications&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物联网技术的发展促使监测网络在智能城市、环境监测和精密农业等多种应用中得到广泛采用。&lt;h4&gt;目的&lt;/h4&gt;研究基于图的技术，以提高传感器网络数据的质量，这对于决策过程、数字双胞胎等应用至关重要。&lt;h4&gt;方法&lt;/h4&gt;强调机器学习和信号处理技术在图上的应用，利用图拓扑结构的优势。&lt;h4&gt;主要发现&lt;/h4&gt;图信号处理（GSP）和图神经网络（GNN）等技术被广泛应用于数据质量增强任务。&lt;h4&gt;结论&lt;/h4&gt;重点讨论监测传感器网络中数据质量控制的图模型，并探讨缺失值填补、异常值检测和虚拟传感等技术细节。&lt;h4&gt;未来趋势&lt;/h4&gt;识别未来的趋势和挑战，如数字双胞胎的图模型或模型的可迁移性和泛化能力。&lt;h4&gt;总结&lt;/h4&gt;基于图的解决方案在传感器网络的数据质量任务中具有重要应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of Internet of Things (IoT) technologies has led to thewidespread adoption of monitoring networks for a wide variety of applications,such as smart cities, environmental monitoring, and precision agriculture. Amajor research focus in recent years has been the development of graph-basedtechniques to improve the quality of data from sensor networks, a key aspectfor the use of sensed data in decision-making processes, digital twins, andother applications. Emphasis has been placed on the development of machinelearning and signal processing techniques over graphs, taking advantage of thebenefits provided by the use of structured data through a graph topology. Manytechnologies such as the graph signal processing (GSP) or the successful graphneural networks (GNNs) have been used for data quality enhancement tasks. Inthis survey, we focus on graph-based models for data quality control inmonitoring sensor networks. Furthermore, we delve into the technical detailsthat are commonly leveraged for providing powerful graph-based solutions fordata quality tasks in sensor networks, including missing value imputation,outlier detection, or virtual sensing. To conclude, we have identified futuretrends and challenges such as graph-based models for digital twins or modeltransferability and generalization.</description>
      <author>example@mail.com (Pau Ferrer-Cid, Jose M. Barcelo-Ordinas, Jorge Garcia-Vidal)</author>
      <guid isPermaLink="false">2410.21006v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Uncovering Capabilities of Model Pruning in Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.20356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MM' 24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图对比学习在无真实标签的情况下成功地预训练了图神经网络，但现有方法依赖于随机生成的增强视图，可能导致语义改变。&lt;h4&gt;目的&lt;/h4&gt;通过不同模型版本的对比，而非依赖增强视图，重新构建图对比学习问题。&lt;h4&gt;方法&lt;/h4&gt;理论上揭示模型剪枝在对比学习中的优势；实际中使用原始图作为输入，动态生成一个经过剪枝的图编码器与原始编码器对比。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法在处理困难负样本时，通过局部对比损失提高了节点嵌入的完整性。&lt;h4&gt;结论&lt;/h4&gt;在多种图分类基准上进行广泛验证，该方法在无监督和迁移学习中相较于最先进的工作表现更佳。&lt;h4&gt;总结&lt;/h4&gt;该研究通过模型剪枝改进了图对比学习，增强了性能和一般化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph contrastive learning has achieved great success in pre-training graphneural networks without ground-truth labels. Leading graph contrastive learningfollows the classical scheme of contrastive learning, forcing model to identifythe essential information from augmented views. However, general augmentedviews are produced via random corruption or learning, which inevitably leads tosemantics alteration. Although domain knowledge guided augmentations alleviatethis issue, the generated views are domain specific and undermine thegeneralization. In this work, motivated by the firm representation ability ofsparse model from pruning, we reformulate the problem of graph contrastivelearning via contrasting different model versions rather than augmented views.We first theoretically reveal the superiority of model pruning in contrast todata augmentations. In practice, we take original graph as input anddynamically generate a perturbed graph encoder to contrast with the originalencoder by pruning its transformation weights. Furthermore, considering theintegrity of node embedding in our method, we are capable of developing a localcontrastive loss to tackle the hard negative samples that disturb the modeltraining. We extensively validate our method on various benchmarks regardinggraph classification via unsupervised and transfer learning. Compared to thestate-of-the-art (SOTA) works, better performance can always be obtained by theproposed method.</description>
      <author>example@mail.com (Wu Junran, Chen Xueyuan, Li Shangzhe)</author>
      <guid isPermaLink="false">2410.20356v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Quantum Circuits, Feature Maps, and Expanded Pseudo-Entropy: A Categorical Theoretic Analysis of Encoding Real-World Data into a Quantum Computer</title>
      <link>http://arxiv.org/abs/2410.22084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，量子机器学习的发展促进了将机器学习转化为量子电路的研究，尤其关注如何在编码真实世界数据时不丢失信息和避免噪声。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的数值方法，以确定编码方案在将真实世界数据映射到量子电路中的有效性。&lt;h4&gt;方法&lt;/h4&gt;通过计算点云数据中每个数据点的香农熵，并在嵌入流形上进行采样，计算应用于各自量子算子的扩展伪熵概念，而非密度算符。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的伪熵方法能够推广现有的表达性和表达能力方法，并且可以推广对称量子特征图。&lt;h4&gt;结论&lt;/h4&gt;该方法为理解量子特征图之间的联系提供了合理依据，但仍需更深入的数学分析来支持这些论点。&lt;h4&gt;总结&lt;/h4&gt;新方法为量子机器学习中的数据编码问题提供了新的视角，具有潜在的推广能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This manuscripts proposes a new and novel numerical method to the determinethe efficacy of an encoding scheme to map real-world data into a quantumcircuit. The method calculates the Shannon entropy of each of the data pointsfrom a point-cloud, hence, samples from an embedded manifold, and calculatesthe expanded concept of pseudo-entropy applied to each respective quantumoperator that comes from a given quantum feature map, and not the densityoperator. In the recent decade, there has been a continuous advancement oftranslating machine learning into a quantum circuit with many promisingresults. For quantum machine learning, a major underlying question is how toencode real-world data into a quantum circuit without losing information andadding noise. A few notable methods derived are expressibility, where thedistribution of the output of states from the circuit are compared against theHaar probability measure with information theoretic techniques, andexpressivity, a method that maps the expectation of a quantum circuit to thespace of complex functions via a partial Fourier series, noting that moreintricate the function the more expressive, and using the symmetry embeddedwithin the data to derive a quantum feature map. The proposed pseudo-entropymethod is discussed to and empirically shown to generalize these methods.Furthermore, this method is argued to also generalize symmetric quantum featuremaps. The discussions and arguments are a reasonable basis for understandingthe connections but require deeper mathematical analysis.</description>
      <author>example@mail.com (Andrew Vlasic)</author>
      <guid isPermaLink="false">2410.22084v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fourier Head: Helping Large Language Models Learn Complex Probability Distributions</title>
      <link>http://arxiv.org/abs/2410.22269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page and code are at https://nategillman.com/fourier-head&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型的质量提升引发了对其在非语言标记建模中的应用兴趣，例如将决策转换器用于建模离散动作空间。&lt;h4&gt;目的&lt;/h4&gt;探讨在非语言领域中，softmax是否能捕捉标记的连续结构和复杂分布，以提高标记生成质量。&lt;h4&gt;方法&lt;/h4&gt;引入基于傅里叶级数构建的神经网络层，可替代任意线性层，以实现更连续的输出结构，并在合成数据集和实际决策、时间序列预测任务中进行广泛分析。&lt;h4&gt;主要发现&lt;/h4&gt;该傅里叶头在具有自然连续结构的数据分布场景下表现出色，提升了决策转换器在Atari Seaquest游戏中的回报46%，并在20个未见基准上提高了时间序列预测模型的性能3.5%。&lt;h4&gt;结论&lt;/h4&gt;傅里叶头能够更好地学习数据中的信号，同时忽略高频噪声，支持其在复杂数据分布场景中的有效性。&lt;h4&gt;总结&lt;/h4&gt;引入傅里叶级数的神经网络层提升了非语言标记建模的效果，特别是在决策和时间序列任务中表现显著。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the quality of large language models has improved, there has beenincreased interest in using them to model non-linguistic tokens. For example,the Decision Transformer recasts agentic decision making as a sequence modelingproblem, using a decoder-only LLM to model the distribution over the discreteaction space for an Atari agent. However, when adapting LLMs to non-linguisticdomains, it remains unclear if softmax over discrete bins captures thecontinuous structure of the tokens and the potentially complex distributionsneeded for high quality token generation. We introduce a neural network layer,constructed using Fourier series, which we can easily substitute for any linearlayer if we want the outputs to have a more continuous structure. We performextensive analysis on synthetic datasets, as well as on large-scale decisionmaking and time series forecasting tasks. We also provide theoretical evidencethat this layer can better learn signal from data while ignoring high-frequencynoise. All of our results support the effectiveness of our proposed Fourierhead in scenarios where the underlying data distribution has a naturalcontinuous structure. For example, the Fourier head improves a DecisionTransformer agent's returns by 46% on the Atari Seaquest game, and increases astate-of-the-art times series foundation model's forecasting performance by3.5% across 20 benchmarks unseen during training.</description>
      <author>example@mail.com (Nate Gillman, Daksh Aggarwal, Michael Freeman, Saurabh Singh, Chen Sun)</author>
      <guid isPermaLink="false">2410.22269v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SandboxAQ's submission to MRL 2024 Shared Task on Multi-lingual Multi-task Information Retrieval</title>
      <link>http://arxiv.org/abs/2410.21501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MRL 2024 Shared Task on Multi-lingual Multi-task Information
  Retrieval; 4th Multilingual Representation Learning (MRL) Workshop; EMNLP
  2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文探讨了五种不同语言中的问答（QA）和命名实体识别（NER）问题。&lt;h4&gt;目的&lt;/h4&gt;评估五种大型语言模型在不同提示方法下的表现。&lt;h4&gt;方法&lt;/h4&gt;使用零-shot、链式推理和翻译技术对模型进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;部分模型在某些任务上表现优于其他模型，但其有效性在任务和语言间差异显著。&lt;h4&gt;结论&lt;/h4&gt;高级提示技术通常提高了QA的表现，但对NER的效果则不一而足；不同任务之间的语言难度模式存在差异。&lt;h4&gt;建议&lt;/h4&gt;强调在多语言自然语言处理中的任务特定方法的必要性，现有模型可能在不同任务中发展出不同的语言能力。&lt;h4&gt;总结&lt;/h4&gt;研究结果揭示了多语言NLP中任务特定方法的重要性，并指出模型在不同任务上可能具备不同的语言能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the problems of Question Answering (QA) and Named EntityRecognition (NER) in five diverse languages. We tested five Large LanguageModels with various prompting methods, including zero-shot, chain-of-thoughtreasoning, and translation techniques. Our results show that while some modelsconsistently outperform others, their effectiveness varies significantly acrosstasks and languages. We saw that advanced prompting techniques generallyimproved QA performance but had mixed results for NER; and we observed thatlanguage difficulty patterns differed between tasks. Our findings highlight theneed for task-specific approaches in multilingual NLP and suggest that currentmodels may develop different linguistic competencies for different tasks.</description>
      <author>example@mail.com (Isidora Chara Tourni, Sayontan Ghosh, Brenda Miao, Constantijn van der Poel)</author>
      <guid isPermaLink="false">2410.21501v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Graph Based Traffic Analysis and Delay Prediction</title>
      <link>http://arxiv.org/abs/2410.21028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;马耳他是欧盟人口最密集的国家，人口密度约为每平方公里1672人。该地区车辆增长迅速，6个月内增加约11,000辆。&lt;h4&gt;目的&lt;/h4&gt;研究交通拥堵问题，并提供准确全面的数据收集方法以应对马耳他波动的交通状况。&lt;h4&gt;方法&lt;/h4&gt;构建了一个名为MalTra的全面交通数据集，包含公众在200天内的真实出行数据，并采用ARIMA模型和两种图神经网络（STGCN和DCRNN）进行分析和比较。&lt;h4&gt;主要发现&lt;/h4&gt;DCRNN模型的表现优于STGCN，MAE为3.98（STGCN为6.65），RMSE为7.78（STGCN为12.73）。&lt;h4&gt;结论&lt;/h4&gt;DCRNN模型在交通数据分析中更为有效，能够更好地应对马耳他交通拥堵问题。&lt;h4&gt;总结&lt;/h4&gt;本研究通过构建全面的数据集和有效的分析模型，为马耳他的交通管理提供了重要的数据支持和理论依据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research is focused on traffic congestion in the small island of Maltawhich is the most densely populated country in the EU with about 1,672inhabitants per square kilometre (4,331 inhabitants/sq mi). Furthermore, Maltahas a rapid vehicle growth. Based on our research, the number of vehiclesincreased by around 11,000 in a little more than 6 months, which shows howimportant it is to have an accurate and comprehensive means of collecting datato tackle the issue of fluctuating traffic in Malta. In this paper, we firstpresent the newly built comprehensive traffic dataset, called MalTra. Thisdataset includes realistic trips made by members of the public across theisland over a period of 200 days. We then describe the methodology we adoptedto generate syntactic data to complete our data set as much as possible. In ourresearch, we consider both MalTra and the Q-Traffic dataset, which has beenused in several other research studies. The statistical ARIMA model and twograph neural networks, the spatial temporal graph convolutional network (STGCN)and the diffusion convolutional recurrent network (DCRNN) were used to analyseand compare the results with existing research. From the evaluation, we foundthat the DCRNN model outperforms the STGCN with the former resulting in MAE of3.98 (6.65 in the case of the latter) and a RMSE of 7.78 (against 12.73 of thelatter).</description>
      <author>example@mail.com (Gabriele Borg, Charlie Abela)</author>
      <guid isPermaLink="false">2410.21028v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Causal Modeling in Multi-Context Systems: Distinguishing Multiple Context-Specific Causal Graphs which Account for Observational Support</title>
      <link>http://arxiv.org/abs/2410.20405v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多上下文数据的因果结构学习面临机遇与挑战。机遇来自共享与特定上下文的因果图，使得因果知识可以在不同上下文中推广和转移。&lt;h4&gt;目的&lt;/h4&gt;研究不同观察支持对因果图可识别性的影响，这是文献中当前尚未深入探讨的挑战。&lt;h4&gt;方法&lt;/h4&gt;详细研究新引入的因果图对象，这些对象捕捉因果机制和数据支持，允许分析更大类的上下文特定变化，更精确地表征分布变化。&lt;h4&gt;主要发现&lt;/h4&gt;扩展了对上下文特定因果结构可识别性的结果，提出了一种在结构因果模型中建模上下文特定独立性（CSI）的框架，可以探索这些图对象不同的情形。&lt;h4&gt;结论&lt;/h4&gt;该框架有助于解释异常现象或极端事件，其中因果机制在不同条件下变化或似乎变化。研究结果为理解多上下文系统中的因果关系提供了理论基础，对推广、迁移学习和异常检测具有重要意义。&lt;h4&gt;总结&lt;/h4&gt;未来的工作可能将这种方法扩展到更复杂的数据类型，如时间序列。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Causal structure learning with data from multiple contexts carries bothopportunities and challenges. Opportunities arise from considering shared andcontext-specific causal graphs enabling to generalize and transfer causalknowledge across contexts. However, a challenge that is currently understudiedin the literature is the impact of differing observational support betweencontexts on the identifiability of causal graphs. Here we study in detailrecently introduced [6] causal graph objects that capture both causalmechanisms and data support, allowing for the analysis of a larger class ofcontext-specific changes, characterizing distribution shifts more precisely. Wethereby extend results on the identifiability of context-specific causalstructures and propose a framework to model context-specific independence (CSI)within structural causal models (SCMs) in a refined way that allows to explorescenarios where these graph objects differ. We demonstrate how this frameworkcan help explaining phenomena like anomalies or extreme events, where causalmechanisms change or appear to change under different conditions. Our resultscontribute to the theoretical foundations for understanding causal relations inmulti-context systems, with implications for generalization, transfer learning,and anomaly detection. Future work may extend this approach to more complexdata types, such as time-series.</description>
      <author>example@mail.com (Martin Rabel, Wiebke Günther, Jakob Runge, Andreas Gerhardus)</author>
      <guid isPermaLink="false">2410.20405v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Local Policies Enable Zero-shot Long-horizon Manipulation</title>
      <link>http://arxiv.org/abs/2410.22332v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main paper 7 pages, 3 tables, 3 figures. Appendix 6 pages, 2 figures,
  6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在机器人操作中，sim2real（从模拟到现实）的转移面临复杂接触模拟和生成现实任务分布的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出ManipGen以解决生成现实任务分布的问题。&lt;h4&gt;方法&lt;/h4&gt;引入局部策略（local policies），结合视觉、语言和运动规划的基础模型，实现sim2real转移。&lt;h4&gt;主要发现&lt;/h4&gt;在Robosuite基准任务中，ManipGen在模拟中的零-shot性能达到97%。局部策略能够解决未见过的长时域操作任务，表现出显著的姿态、物体和场景配置变化。&lt;h4&gt;结论&lt;/h4&gt;ManipGen在50个现实操作任务中优于现有最先进的方法，分别提升36%、76%、62%和60%。&lt;h4&gt;总结&lt;/h4&gt;ManipGen通过局部策略实现了更有效的机器人操作，从模拟到现实的转移效果显著。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sim2real for robotic manipulation is difficult due to the challenges ofsimulating complex contacts and generating realistic task distributions. Totackle the latter problem, we introduce ManipGen, which leverages a new classof policies for sim2real transfer: local policies. Locality enables a varietyof appealing properties including invariances to absolute robot and objectpose, skill ordering, and global scene configuration. We combine these policieswith foundation models for vision, language and motion planning and demonstrateSOTA zero-shot performance of our method to Robosuite benchmark tasks insimulation (97%). We transfer our local policies from simulation to reality andobserve they can solve unseen long-horizon manipulation tasks with up to 8stages with significant pose, object and scene configuration variation.ManipGen outperforms SOTA approaches such as SayCan, OpenVLA, LLMTrajGen andVoxPoser across 50 real-world manipulation tasks by 36%, 76%, 62% and 60%respectively. Video results at https://mihdalal.github.io/manipgen/</description>
      <author>example@mail.com (Murtaza Dalal, Min Liu, Walter Talbott, Chen Chen, Deepak Pathak, Jian Zhang, Ruslan Salakhutdinov)</author>
      <guid isPermaLink="false">2410.22332v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds</title>
      <link>http://arxiv.org/abs/2410.22099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures, 4 tables. This work has been submitted to the
  IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;脑成像研究表明，扩散MRI轨迹几何形状描述符可以帮助研究大脑白质通路及其与大脑功能的关系。&lt;h4&gt;目的&lt;/h4&gt;探讨利用深度学习模型计算大脑白质连接的形状度量的可能性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新框架TractShapeNet，利用点云表示法计算五个形状度量：长度、跨度、体积、总表面积和不规则性。&lt;h4&gt;主要发现&lt;/h4&gt;在1065名健康年轻成年人的大型数据集中，TractShapeNet在皮尔逊相关系数和标准化误差指标上优于其他基于点云的神经网络模型。&lt;h4&gt;结论&lt;/h4&gt;深度学习方法能够更快、更高效地计算形状度量，其在两个下游语言认知预测任务中的表现与DSI-Studio计算的形状度量相似。&lt;h4&gt;总结&lt;/h4&gt;我们的代码将公开在：https://github.com/SlicerDMRI/TractShapeNet&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain imaging studies have demonstrated that diffusion MRI tractographygeometric shape descriptors can inform the study of the brain's white matterpathways and their relationship to brain function. In this work, we investigatethe possibility of utilizing a deep learning model to compute shape measures ofthe brain's white matter connections. We introduce a novel framework,TractShapeNet, that leverages a point cloud representation of tractography tocompute five shape measures: length, span, volume, total surface area, andirregularity. We assess the performance of the method on a large datasetincluding 1065 healthy young adults. Experiments for shape measure computationdemonstrate that our proposed TractShapeNet outperforms other point cloud-basedneural network models in both the Pearson correlation coefficient andnormalized error metrics. We compare the inference runtime results with theconventional shape computation tool DSI-Studio. Our results demonstrate that adeep learning approach enables faster and more efficient shape measurecomputation. We also conduct experiments on two downstream language cognitionprediction tasks, showing that shape measures from TractShapeNet performsimilarly to those computed by DSI-Studio. Our code will be available at:https://github.com/SlicerDMRI/TractShapeNet.</description>
      <author>example@mail.com (Yui Lo, Yuqian Chen, Dongnan Liu, Jon Haitz Legarreta, Leo Zekelman, Fan Zhang, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O'Donnell)</author>
      <guid isPermaLink="false">2410.22099v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing CTR Prediction in Recommendation Domain with Search Query Representation</title>
      <link>http://arxiv.org/abs/2410.21487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CIKM 2024 Full Research Track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多平台（如电子商务网站）同时提供搜索和推荐服务，以更好地满足用户的多样化需求。&lt;h4&gt;目的&lt;/h4&gt;通过利用搜索领域提取的用户偏好，增强推荐领域的推荐服务。&lt;h4&gt;方法&lt;/h4&gt;提出一个框架，从用户搜索查询嵌入中学习，预测用户在推荐领域的点击项目，采用对比学习探讨查询与项目的关系，并结合扩散模型解决数据稀疏问题。&lt;h4&gt;主要发现&lt;/h4&gt;我们的模型在推荐领域的性能优于现有的最先进模型。&lt;h4&gt;结论&lt;/h4&gt;通过有效提取用户搜索信息，并将其整合入点击率预测中，可以显著提升推荐系统的效果。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的方法通过学习用户搜索行为，改善了推荐系统的准确性，显示出潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3627673.3679849&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many platforms, such as e-commerce websites, offer both search andrecommendation services simultaneously to better meet users' diverse needs.Recommendation services suggest items based on user preferences, while searchservices allow users to search for items before providing recommendations.Since users and items are often shared between the search and recommendationdomains, there is a valuable opportunity to enhance the recommendation domainby leveraging user preferences extracted from the search domain. Existingapproaches either overlook the shift in user intention between these domains orfail to capture the significant impact of learning from users' search querieson understanding their interests.  In this paper, we propose a framework that learns from user search queryembeddings within the context of user preferences in the recommendation domain.Specifically, user search query sequences from the search domain are used topredict the items users will click at the next time point in the recommendationdomain. Additionally, the relationship between queries and items is exploredthrough contrastive learning. To address issues of data sparsity, the diffusionmodel is incorporated to infer positive items the user will select aftersearching with certain queries in a denoising manner, which is particularlyeffective in preventing false positives. Effectively extracting thisinformation, the queries are integrated into click-through rate prediction inthe recommendation domain. Experimental analysis demonstrates that our modeloutperforms state-of-the-art models in the recommendation domain.</description>
      <author>example@mail.com (Yuening Wang, Man Chen, Yaochen Hu, Wei Guo, Yingxue Zhang, Huifeng Guo, Yong Liu, Mark Coates)</author>
      <guid isPermaLink="false">2410.21487v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Graph Sparsification for Enhanced Conformal Prediction in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.21618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Conformal Prediction 是一个可靠的框架，确保机器学习任务中的可靠覆盖。&lt;h4&gt;目的&lt;/h4&gt;探讨在训练阶段改进 conformal prediction 的方法。&lt;h4&gt;方法&lt;/h4&gt;提出 SparGCP，通过引入图稀疏化和 conformal prediction 特定目标，改善图神经网络的训练。&lt;h4&gt;主要发现&lt;/h4&gt;SparGCP 通过参数化图稀疏化模块过滤无关边缘，显著提高了 conformal prediction 的效率。&lt;h4&gt;结论&lt;/h4&gt;SparGCP 在真实世界的图数据集上表现优越，平均减少了 32% 的预测集大小，并能无缝扩展到大型网络。&lt;h4&gt;总结&lt;/h4&gt;本研究通过 SparGCP 方法有效提升了图神经网络训练阶段的 conformal prediction 效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conformal Prediction is a robust framework that ensures reliable coverageacross machine learning tasks. Although recent studies have applied conformalprediction to graph neural networks, they have largely emphasized post-hocprediction set generation. Improving conformal prediction during the trainingstage remains unaddressed. In this work, we tackle this challenge from adenoising perspective by introducing SparGCP, which incorporates graphsparsification and a conformal prediction-specific objective into GNN training.SparGCP employs a parameterized graph sparsification module to filter outtask-irrelevant edges, thereby improving conformal prediction efficiency.Extensive experiments on real-world graph datasets demonstrate that SparGCPoutperforms existing methods, reducing prediction set sizes by an average of32\% and scaling seamlessly to large networks on commodity GPUs.</description>
      <author>example@mail.com (Yuntian He, Pranav Maneriker, Anutam Srinivasan, Aditya T. Vadlamani, Srinivasan Parthasarathy)</author>
      <guid isPermaLink="false">2410.21618v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>KANsformer for Scalable Beamforming</title>
      <link>http://arxiv.org/abs/2410.20690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着移动通信系统的发展，需要提高能量效率的波束成形技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督深度学习方法，整合变换器和Kolmogorov-Arnold网络，以实现可扩展的波束成形。&lt;h4&gt;方法&lt;/h4&gt;KANsformer通过多头自注意力机制提取隐含特征，并利用KAN进行波束成形设计。&lt;h4&gt;主要发现&lt;/h4&gt;KANsformer在泛化性能、迁移学习和消融实验中表现优越。&lt;h4&gt;结论&lt;/h4&gt;KANsformer优于现有的基准深度学习方法，能够适应移动用户数量的变化，实现实时和近似最优的推理。&lt;h4&gt;总结&lt;/h4&gt;该研究为移动通信系统的波束成形提供了一种新颖的深度学习解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an unsupervised deep-learning (DL) approach byintegrating transformer and Kolmogorov-Arnold networks (KAN) termed KANsformerto realize scalable beamforming for mobile communication systems. Specifically,we consider a classic multi-input-single-output energy efficiency maximizationproblem subject to the total power budget. The proposed KANsformer firstextracts hidden features via a multi-head self-attention mechanism and thenreads out the desired beamforming design via KAN. Numerical results areprovided to evaluate the KANsformer in terms of generalization performance,transfer learning and ablation experiment. Overall, the KANsformer outperformsexisting benchmark DL approaches, and is adaptable to the change in the numberof mobile users with real-time and near-optimal inference.</description>
      <author>example@mail.com (Xinke Xie, Yang Lu, Chong-Yung Chi, Wei Chen, Bo Ai, Dusit Niyato)</author>
      <guid isPermaLink="false">2410.20690v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SimSiam Naming Game: A Unified Approach for Representation Learning and Emergent Communication</title>
      <link>http://arxiv.org/abs/2410.21803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新兴通信由生成模型驱动，使智能体能通过交互发展出共同语言来描述对同一对象的不同看法。&lt;h4&gt;目的&lt;/h4&gt;提出SimSiam+VAE，作为统一的表征学习和新兴通信的方法。&lt;h4&gt;方法&lt;/h4&gt;在SimSiam网络的预测器中集成变分自编码器（VAE），以增强表征学习并捕捉不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;SimSiam+VAE的实验结果优于SimSiam和VI-SimSiam。&lt;h4&gt;结论&lt;/h4&gt;SSNG展示了与参考游戏相当的性能，并稍微优于Metropolis-Hastings命名游戏。&lt;h4&gt;总结&lt;/h4&gt;通过将生成和贝叶斯方法结合，SSNG促进了智能体之间的相互理解，表明其在动态角色交替中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emergent communication, driven by generative models, enables agents todevelop a shared language for describing their individual views of the sameobjects through interactions. Meanwhile, self-supervised learning (SSL),particularly SimSiam, uses discriminative representation learning to makerepresentations of augmented views of the same data point closer in therepresentation space. Building on the prior work of VI-SimSiam, whichincorporates a generative and Bayesian perspective into the SimSiam frameworkvia variational inference (VI) interpretation, we propose SimSiam+VAE, aunified approach for both representation learning and emergent communication.SimSiam+VAE integrates a variational autoencoder (VAE) into the predictor ofthe SimSiam network to enhance representation learning and capture uncertainty.Experimental results show that SimSiam+VAE outperforms both SimSiam andVI-SimSiam. We further extend this model into a communication framework calledthe SimSiam Naming Game (SSNG), which applies the generative and Bayesianapproach based on VI to develop internal representations and emergent language,while utilizing the discriminative process of SimSiam to facilitate mutualunderstanding between agents. In experiments with established models, despitethe dynamic alternation of agent roles during interactions, SSNG demonstratescomparable performance to the referential game and slightly outperforms theMetropolis-Hastings naming game.</description>
      <author>example@mail.com (Nguyen Le Hoang, Tadahiro Taniguchi, Fang Tianwei, Akira Taniguchi)</author>
      <guid isPermaLink="false">2410.21803v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Surface reconstruction from point cloud using a semi-Lagrangian scheme with local interpolator</title>
      <link>http://arxiv.org/abs/2410.22205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种水平集方法，用于从点云重建未知表面，而不假设点之间的连接已知。&lt;h4&gt;目的&lt;/h4&gt;通过变分公式和曲率约束，最小化表面面积，权衡表面与点云之间的距离。&lt;h4&gt;方法&lt;/h4&gt;解决一个等效的对流-扩散方程，描述由水平集函数隐式定义的初始表面演化。采用半拉格朗日方案，并与局部插值器耦合以降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;使用多线性插值器和加权本质非振荡插值器提高重建的准确性，且方法具有局部化特性和快速并行算法，显著加快重建速度。&lt;h4&gt;结论&lt;/h4&gt;提出了一种点云数据的预处理方法，以设置算法参数，并通过二维和三维的数值测试评估近似解的质量和算法的计算效率。&lt;h4&gt;总结&lt;/h4&gt;该方法有效地重建未知表面，提供了高效且准确的解决方案，适用于各种计算场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a level set method to reconstruct unknown surfaces from pointclouds, without assuming that the connections between points are known. Weconsider a variational formulation with a curvature constraint that minimizesthe surface area weighted by the distance of the surface from the point cloud.More precisely we solve an equivalent advection-diffusion equation that governsthe evolution of an initial surface described implicitly by a level setfunction. Among all the possible representations, we aim to compute the signeddistance function at least in the vicinity of the reconstructed surface. Thenumerical method for the approximation of the solution is based on asemi-Lagrangian scheme whose main novelty consists in its coupling with a localinterpolator instead of a global one, with the aim of saving computationalcosts. In particular, we resort to a multi-linear interpolator and to aWeighted Essentially Non-oscillatory one, to improve the accuracy of thereconstruction. Special attention has been paid to the localization of themethod and to the development of fast algorithms that run in parallel,resulting in faster reconstruction and thus the opportunity to easily improvethe resolution. A preprocessing of the point cloud data is also proposed to setthe parameters of the method. Numerical tests in two and three dimensions arepresented to evaluate the quality of the approximated solution and theefficiency of the algorithm in terms of computational time.</description>
      <author>example@mail.com (Silvia Preda, Matteo Semplice)</author>
      <guid isPermaLink="false">2410.22205v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Multi-Granularity Representation via Group Contrastive Learning for Unsupervised Vehicle Re-identification</title>
      <link>http://arxiv.org/abs/2410.21667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;车辆重识别（Vehicle ReID）旨在从不同监控摄像头视角中检索车辆图像。&lt;h4&gt;目的&lt;/h4&gt;解决现有模型在大规模真实场景中由于源数据集与目标之间显著领域差异而导致的性能下降问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种无监督车辆重识别框架（MGR-GCL），结合多粒度CNN表示和对比学习模块，以实现高效的领域适应。&lt;h4&gt;主要发现&lt;/h4&gt;通过在标记源数据集上训练的多粒度表示（MGR），生成目标数据集的伪标签，促进领域适应过程，实验结果显示该方法优于现有的最先进技术。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架有效提升了车辆重识别的性能，解决了领域不匹配带来的挑战。&lt;h4&gt;总结&lt;/h4&gt;MGR-GCL框架通过无监督学习策略，实现了车辆重识别的领域适应，展现出良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicle re-identification (Vehicle ReID) aims at retrieving vehicle imagesacross disjoint surveillance camera views. The majority of vehicle ReIDresearch is heavily reliant upon supervisory labels from specifichuman-collected datasets for training. When applied to the large-scalereal-world scenario, these models will experience dreadful performance declinesdue to the notable domain discrepancy between the source dataset and thetarget. To address this challenge, in this paper, we propose an unsupervisedvehicle ReID framework (MGR-GCL). It integrates a multi-granularity CNNrepresentation for learning discriminative transferable features and acontrastive learning module responsible for efficient domain adaptation in theunlabeled target domain. Specifically, after training the proposedMulti-Granularity Representation (MGR) on the labeled source dataset, wepropose a group contrastive learning module (GCL) to generate pseudo labels forthe target dataset, facilitating the domain adaptation process. We conductedextensive experiments and the results demonstrated our superiority againstexisting state-of-the-art methods.</description>
      <author>example@mail.com (Zhigang Chang, Shibao Zheng)</author>
      <guid isPermaLink="false">2410.21667v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Breccia and basalt classification of thin sections of Apollo rocks with deep learning</title>
      <link>http://arxiv.org/abs/2410.21024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类预计将在下一个十年内重新探索月球，这是自阿波罗计划以来的首次活动。&lt;h4&gt;目的&lt;/h4&gt;重返月球的主要目标之一是继续采集地质样本，特别是高质量标本，以最大化科学回报。&lt;h4&gt;方法&lt;/h4&gt;提出了一种分类月球岩石薄片的框架，利用阿波罗任务的岩石薄片图像，应用对比学习方法分析这些图像并提取有意义的特征。&lt;h4&gt;主要发现&lt;/h4&gt;经过对预训练的Inception-Resnet-v2网络进行微调，能够有效提取阿波罗岩石薄片图像的基本特征，训练的二分类器在分离破碎岩和玄武岩时达到了98.44%的准确率。&lt;h4&gt;结论&lt;/h4&gt;开发的岩石分类工具可以帮助宇航员更好地分析月球岩石样本，从而提高未来月球任务的科学价值。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了机器学习在月球样本分析中的应用潜力，为未来的月球探索提供了重要的技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human exploration of the moon is expected to resume in the next decade,following the last such activities in the Apollo programme time. One of themajor objectives of returning to the Moon is to continue retrieving geologicalsamples, with a focus on collecting high-quality specimens to maximizescientific return. Tools that assist astronauts in making informed decisionsabout sample collection activities can maximize the scientific value of futurelunar missions. A lunar rock classifier is a tool that can potentially providethe necessary information for astronauts to analyze lunar rock samples,allowing them to augment in-situ value identification of samples. Towardsdemonstrating the value of such a tool, in this paper, we introduce a frameworkfor classifying rock types in thin sections of lunar rocks. We leverage thevast collection of petrographic thin-section images from the Apollo missions,captured under plane-polarized light (PPL), cross-polarised light (XPL), andreflected light at varying magnifications. Advanced machine learning methods,including contrastive learning, are applied to analyze these images and extractmeaningful features. The contrastive learning approach fine-tunes a pre-trainedInception-Resnet-v2 network with the SimCLR loss function. The fine-tunedInception-Resnet-v2 network can then extract essential features effectivelyfrom the thin-section images of Apollo rocks. A simple binary classifier istrained using transfer learning from the fine-tuned Inception-ResNet-v2 to98.44\% ($\pm$1.47) accuracy in separating breccias from basalts.</description>
      <author>example@mail.com (Freja Thoresen, Aidan Cowley, Romeo Haak, Jonas Lewe, Clara Moriceau, Piotr Knapczyk, Victoria S. Engelschiøn)</author>
      <guid isPermaLink="false">2410.21024v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhance Hyperbolic Representation Learning via Second-order Pooling</title>
      <link>http://arxiv.org/abs/2410.22026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;超曲率表示学习因其捕捉层次信息的能力而广为人知，但不同层次类别之间的样本距离往往需要较大。&lt;h4&gt;目的&lt;/h4&gt;解决超曲率判别目标导致的Lipschitz常数增大问题，以充分利用主干网络的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入二阶池化到超曲率表示学习中，自然增加样本间距离而不影响输入特征的泛化能力，并提出核近似正则化以解决低维双线性特征在超曲率表示学习中的应用问题。&lt;h4&gt;主要发现&lt;/h4&gt;二阶池化能够有效增加样本间距离，同时保持主干网络的泛化能力，而核近似正则化有助于低维特征良好近似核函数。&lt;h4&gt;结论&lt;/h4&gt;所提方法在图结构数据集上的广泛实验表明其有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，通过二阶池化和核近似正则化，改善超曲率表示学习的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperbolic representation learning is well known for its ability to capturehierarchical information. However, the distance between samples from differentlevels of hierarchical classes can be required large. We reveal that thehyperbolic discriminant objective forces the backbone to capture thishierarchical information, which may inevitably increase the Lipschitz constantof the backbone. This can hinder the full utilization of the backbone'sgeneralization ability. To address this issue, we introduce second-orderpooling into hyperbolic representation learning, as it naturally increases thedistance between samples without compromising the generalization ability of theinput features. In this way, the Lipschitz constant of the backbone does notnecessarily need to be large. However, current off-the-shelf low-dimensionalbilinear pooling methods cannot be directly employed in hyperbolicrepresentation learning because they inevitably reduce the distance expansioncapability. To solve this problem, we propose a kernel approximationregularization, which enables the low-dimensional bilinear features toapproximate the kernel function well in low-dimensional space. Finally, weconduct extensive experiments on graph-structured datasets to demonstrate theeffectiveness of the proposed method.</description>
      <author>example@mail.com (Kun Song, Ruben Solozabal, Li hao, Lu Ren, Moloud Abdar, Qing Li, Fakhri Karray, Martin Takac)</author>
      <guid isPermaLink="false">2410.22026v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>LiVisSfM: Accurate and Robust Structure-from-Motion with LiDAR and Visual Cues</title>
      <link>http://arxiv.org/abs/2410.22213v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 9 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种名为LiVisSfM的准确且稳健的运动结构重建系统，结合了激光雷达（LiDAR）和视觉线索。&lt;h4&gt;目的&lt;/h4&gt;开发一种不依赖于惯性测量单元（IMU）的LiDAR-视觉SfM方法，以实现准确的LiDAR位姿估计。&lt;h4&gt;方法&lt;/h4&gt;采用激光雷达帧注册到LiDAR体素地图，使用点到高斯残差度量，并结合LiDAR-视觉的束优化和显式回环闭合。&lt;h4&gt;主要发现&lt;/h4&gt;LiVisSfM框架在LiDAR位姿恢复和稠密点云重建方面，表现优于现有的LiDAR惯性里程计（LIO）和LiDAR-视觉里程计（LIVO）方法。&lt;h4&gt;结论&lt;/h4&gt;LiVisSfM在KITTI基准和多种自采集数据集上的实验结果显示出其更高的准确性和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;LiVisSfM通过创新的框架和方法，提升了LiDAR和视觉信息结合的效率和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an accurate and robust Structure-from-Motion (SfM)pipeline named LiVisSfM, which is an SfM-based reconstruction system that fullycombines LiDAR and visual cues. Unlike most existing LiDAR-inertial odometry(LIO) and LiDAR-inertial-visual odometry (LIVO) methods relying heavily onLiDAR registration coupled with Inertial Measurement Unit (IMU), we propose aLiDAR-visual SfM method which innovatively carries out LiDAR frame registrationto LiDAR voxel map in a Point-to-Gaussian residual metrics, combined with aLiDAR-visual BA and explicit loop closure in a bundle optimization way toachieve accurate and robust LiDAR pose estimation without dependence on IMUincorporation. Besides, we propose an incremental voxel updating strategy forefficient voxel map updating during the process of LiDAR frame registration andLiDAR-visual BA optimization. Experiments demonstrate the superioreffectiveness of our LiVisSfM framework over state-of-the-art LIO and LIVOworks on more accurate and robust LiDAR pose recovery and dense point cloudreconstruction of both public KITTI benchmark and a variety of self-captureddataset.</description>
      <author>example@mail.com (Hanqing Jiang, Liyang Zhou, Zhuang Zhang, Yihao Yu, Guofeng Zhang)</author>
      <guid isPermaLink="false">2410.22213v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>UnCLe: Unsupervised Continual Learning of Depth Completion</title>
      <link>http://arxiv.org/abs/2410.18074v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度补全任务旨在从同步的RGB图像和稀疏深度图推断出密集深度图。现有方法通常在静态数据集上训练，但在适应新的非静态分布时，容易出现'灾难性遗忘'。&lt;h4&gt;目的&lt;/h4&gt;提出UnCLe，一个标准化基准，用于无监督持续学习的多模态深度估计任务。&lt;h4&gt;方法&lt;/h4&gt;通过适应深度补全模型于包含来自不同域的多样场景的数据集序列，模拟非静态分布，采用持续学习范式中的代表性方法以实现无监督持续学习。&lt;h4&gt;主要发现&lt;/h4&gt;通过标准定量指标评估模型在室内和室外场景的表现，发现无监督持续学习的深度补全仍是一个开放问题。&lt;h4&gt;结论&lt;/h4&gt;引入模型反演质量作为额外的遗忘度量，邀请研究人员利用UnCLe作为开发平台。&lt;h4&gt;总结&lt;/h4&gt;UnCLe为发展无监督持续学习的深度补全提供了一个重要的基准和研究平台。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose UnCLe, a standardized benchmark for Unsupervised ContinualLearning of a multimodal depth estimation task: Depth completion aims to infera dense depth map from a pair of synchronized RGB image and sparse depth map.We benchmark depth completion models under the practical scenario ofunsupervised learning over continuous streams of data. Existing methods aretypically trained on a static, or stationary, dataset. However, when adaptingto novel non-stationary distributions, they "catastrophically forget"previously learned information. UnCLe simulates these non-stationarydistributions by adapting depth completion models to sequences of datasetscontaining diverse scenes captured from distinct domains using different visualand range sensors. We adopt representative methods from continual learningparadigms and translate them to enable unsupervised continual learning of depthcompletion. We benchmark these models for indoor and outdoor and investigatethe degree of catastrophic forgetting through standard quantitative metrics.Furthermore, we introduce model inversion quality as an additional measure offorgetting. We find that unsupervised continual learning of depth completion isan open problem, and we invite researchers to leverage UnCLe as a developmentplatform.</description>
      <author>example@mail.com (Suchisrit Gangopadhyay, Xien Chen, Michael Chu, Patrick Rim, Hyoungseob Park, Alex Wong)</author>
      <guid isPermaLink="false">2410.18074v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Fresh Look at Generalized Category Discovery through Non-negative Matrix Factorization</title>
      <link>http://arxiv.org/abs/2410.21807v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;一般化类别发现（GCD）旨在使用标记的基础数据对基础和新颖图像进行分类，目前的方法未能充分优化基于余弦相似度的共现矩阵。&lt;h4&gt;目的&lt;/h4&gt;解决当前方法在基础-新颖区域的零化和基础与新颖领域的稀疏性不足问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种非负一般化类别发现（NN-GCD）框架，使用对称非负矩阵分解（SNMF）证明最优K-means与最优SNMF的等价性，并将优化问题重新构建为非负对比学习（NCL）优化问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，NN-GCD在GCD基准测试中表现优于现有的最先进方法，在语义转移基准上平均准确率达到66.1%，比之前的方法提高了4.7%。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效解决了GCD中的稀疏性和优化问题，为进一步研究提供了新的思路和方法。&lt;h4&gt;总结&lt;/h4&gt;NN-GCD框架通过理论等价和新的激活函数与损失函数，显著提升了GCD模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized Category Discovery (GCD) aims to classify both base and novelimages using labeled base data. However, current approaches inadequatelyaddress the intrinsic optimization of the co-occurrence matrix $\bar{A}$ basedon cosine similarity, failing to achieve zero base-novel regions and adequatesparsity in base and novel domains. To address these deficiencies, we propose aNon-Negative Generalized Category Discovery (NN-GCD) framework. It employsSymmetric Non-negative Matrix Factorization (SNMF) as a mathematical medium toprove the equivalence of optimal K-means with optimal SNMF, and the equivalenceof SNMF solver with non-negative contrastive learning (NCL) optimization.Utilizing these theoretical equivalences, it reframes the optimization of$\bar{A}$ and K-means clustering as an NCL optimization problem. Moreover, tosatisfy the non-negative constraints and make a GCD model converge to anear-optimal region, we propose a GELU activation function and an NMF NCE loss.To transition $\bar{A}$ from a suboptimal state to the desired $\bar{A}^*$, weintroduce a hybrid sparse regularization approach to impose sparsityconstraints. Experimental results show NN-GCD outperforms state-of-the-artmethods on GCD benchmarks, achieving an average accuracy of 66.1\% on theSemantic Shift Benchmark, surpassing prior counterparts by 4.7\%.</description>
      <author>example@mail.com (Zhong Ji, Shuo Yang, Jingren Liu, Yanwei Pang, Jungong Han)</author>
      <guid isPermaLink="false">2410.21807v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Transfer Clustering: A Unified Framework</title>
      <link>http://arxiv.org/abs/2410.21263v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  52 pages, 8 figures; typos corrected, table edited&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一个用于聚类的通用迁移学习框架，涉及主要数据集和辅助数据集，这两个数据集可能反映出相似但不同的潜在分组结构。&lt;h4&gt;目的&lt;/h4&gt;设计一种自适应迁移聚类（ATC）算法，以在未知差异存在的情况下自动利用数据的共性。&lt;h4&gt;方法&lt;/h4&gt;通过优化估计的偏差-方差分解来实现迁移聚类，适用于包括高斯混合模型、随机块模型和潜在类别模型在内的广泛统计模型。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析证明了ATC在高斯混合模型下的最优性，并明确量化了迁移的好处。&lt;h4&gt;结论&lt;/h4&gt;通过大量仿真和真实数据实验，验证了该方法在各种场景下的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究为聚类问题提供了新的迁移学习视角，并展示了ATC算法的实用性和优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhongyuanlyu/atc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a general transfer learning framework for clustering given a maindataset and an auxiliary one about the same subjects. The two datasets mayreflect similar but different latent grouping structures of the subjects. Wepropose an adaptive transfer clustering (ATC) algorithm that automaticallyleverages the commonality in the presence of unknown discrepancy, by optimizingan estimated bias-variance decomposition. It applies to a broad class ofstatistical models including Gaussian mixture models, stochastic block models,and latent class models. A theoretical analysis proves the optimality of ATCunder the Gaussian mixture model and explicitly quantifies the benefit oftransfer. Extensive simulations and real data experiments confirm our method'seffectiveness in various scenarios.</description>
      <author>example@mail.com (Yuqi Gu, Zhongyuan Lyu, Kaizheng Wang)</author>
      <guid isPermaLink="false">2410.21263v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Orb: A Fast, Scalable Neural Network Potential</title>
      <link>http://arxiv.org/abs/2410.22570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了Orb，一种用于材料原子级建模的通用原子间势。&lt;h4&gt;目的&lt;/h4&gt;开发一种比现有通用势更快、更稳定的模型。&lt;h4&gt;方法&lt;/h4&gt;评估Orb在几何优化、Monte Carlo和分子动力学模拟中的表现，并探索材料基础模型开发的多个方面，重点关注扩散预训练。&lt;h4&gt;主要发现&lt;/h4&gt;Orb模型的速度比现有通用势快3-6倍，并在多种非分布材料的模拟中保持稳定。&lt;h4&gt;结论&lt;/h4&gt;Orb在Matbench Discovery基准测试中，错误率比其他方法减少了31%。&lt;h4&gt;总结&lt;/h4&gt;Orb提供了一种新的高效且准确的材料建模方法，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Orb, a family of universal interatomic potentials for atomisticmodelling of materials. Orb models are 3-6 times faster than existing universalpotentials, stable under simulation for a range of out of distributionmaterials and, upon release, represented a 31% reduction in error over othermethods on the Matbench Discovery benchmark. We explore several aspects offoundation model development for materials, with a focus on diffusionpretraining. We evaluate Orb as a model for geometry optimization, Monte Carloand molecular dynamics simulations.</description>
      <author>example@mail.com (Mark Neumann, James Gin, Benjamin Rhodes, Steven Bennett, Zhiyi Li, Hitarth Choubisa, Arthur Hussey, Jonathan Godwin)</author>
      <guid isPermaLink="false">2410.22570v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Hypergraph Neural Networks Reveal Spatial Domains from Single-cell Transcriptomics Data</title>
      <link>http://arxiv.org/abs/2410.19868v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;空间转录组数据的聚类任务至关重要，能够将组织样本分类为多种细胞亚群，进而分析聚类的生物功能、组织重建和细胞间相互作用。&lt;h4&gt;目的&lt;/h4&gt;提高空间转录组数据的聚类准确性，克服传统图神经网络(GNN)在捕捉细胞间隐含连接方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;使用超图神经网络(HGNN)，通过超边连接多个节点，捕捉更丰富的结构信息，同时利用自编码器进行无监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在iLISI评分上取得了1.843的最高分，显示出识别细胞类型的多样性。此外，在下游聚类中，模型的ARI值为0.51，Leiden评分为0.60，均优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;HGNN模型在空间转录组数据的聚类中展示了卓越的性能，能够更好地识别细胞亚群和其多样性。&lt;h4&gt;总结&lt;/h4&gt;HGNN通过捕捉细胞间复杂的连接关系，显著提升了空间转录组数据的聚类效果，具有重要的研究和应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The task of spatial clustering of transcriptomics data is of paramountimportance. It enables the classification of tissue samples into diversesubpopulations of cells, which, in turn, facilitates the analysis of thebiological functions of clusters, tissue reconstruction, and cell-cellinteractions. Many approaches leverage gene expressions, spatial locations, andhistological images to detect spatial domains; however, Graph Neural Networks(GNNs) as state of the art models suffer from a limitation in the assumption ofpairwise connections between nodes. In the case of domain detection in spatialtranscriptomics, some cells are found to be not directly related. Still, theyare grouped as the same domain, which shows the incapability of GNNs forcapturing implicit connections among the cells.  While graph edges connect only two nodes, hyperedges connect an arbitrarynumber of nodes along their edges, which lets Hypergraph Neural Networks(HGNNs) capture and utilize richer and more complex structural information thantraditional GNNs. We use autoencoders to address the limitation of not havingthe actual labels, which are well-suited for unsupervised learning. Our modelhas demonstrated exceptional performance, achieving the highest iLISI score of1.843 compared to other methods. This score indicates the greatest diversity ofcell types identified by our method. Furthermore, our model outperforms othermethods in downstream clustering, achieving the highest ARI values of 0.51 andLeiden score of 0.60.</description>
      <author>example@mail.com (Mehrad Soltani, Luis Rueda)</author>
      <guid isPermaLink="false">2410.19868v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Domain Transfer Learning Method for Thermal Adaptive Behavior Recognition with WiFi</title>
      <link>http://arxiv.org/abs/2410.21827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;可靠的舒适模型对于提高居住者满意度和减少建筑能耗至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过精确识别穿衣和脱衣两种常见的热适应行为，提高热舒适预测的支持效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种跨域迁移学习方法，利用WiFi信号识别人类穿衣和脱衣的适应性行为。首先通过计算去噪WiFi信号的滑动方差确定活动区间，然后进行短时傅里叶变换和离散小波变换以提取时频分析的动作信息，最后集成高效的预训练1D CNN模型与SVM算法作为混合模型以增强在新场景下的识别鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;基于迁移学习的混合模型在适应性行为的识别中表现更为准确，在两个案例中分别达到了96.9%和94.9%的准确率。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了对目标对象适应性行为的预测准确性。&lt;h4&gt;总结&lt;/h4&gt;本研究为热舒适预测提供了一种新的解决方案，利用WiFi信号和迁移学习技术克服了传统活动识别的隐私、成本和性能问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A reliable comfort model is essential to improve occupant satisfaction andreduce building energy consumption. As two types of the most common andintuitive thermal adaptive behaviors, precise recognition of dressing andundressing can effectively support thermal comfort prediction. However,traditional activity recognition suffers from shortcomings in privacy, cost,and performance. To address the above issues, this study proposes across-domain transfer learning method for human dressing and undressingadaptive behavior recognition with WiFi. First, we determine the activityinterval by calculating the sliding variance for denoised WiFi signals.Subsequently, short-time Fourier transform and discrete wavelet transform areperformed to extract action information on the basis of time-frequencyanalysis. Ultimately, an efficient 1D CNN pre-trained model is integrated withthe SVM algorithm as a hybrid model to enhance the identification robustness innew scenarios. Experiment results show that the hybrid model based on transferlearning provides a more accurate prediction for the adaptative behavior oftarget subjects, achieving 96.9% and 94.9% accuracy in two cases, respectively.</description>
      <author>example@mail.com (Zhaohe Lv, Guoliang Zhao, Zhanbo Xu, Jiang Wu, Yadong Zhou, Kun Liu)</author>
      <guid isPermaLink="false">2410.21827v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>CrossEarth: Geospatial Vision Foundation Model for Domain Generalizable Remote Sensing Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.22629v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The codes and models will be available at
  https://github.com/Cuzyoung/CrossEarth&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;遥感领域的领域泛化（RSDG）研究尚处于初期，关注于在不同场景中有效泛化的模型。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的遥感语义分割的视觉基础模型CrossEarth，旨在克服当前模型在未知领域中的表现不足。&lt;h4&gt;方法&lt;/h4&gt;CrossEarth采用了数据层面的Earth-Style Injection管道和模型层面的多任务训练管道，增强跨领域泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;CrossEarth在28个跨领域设置的基准测试中显示出优于现有最先进方法的表现。&lt;h4&gt;结论&lt;/h4&gt;CrossEarth为未来的RSDG模型提供了一个全面的测试框架，展示了其在遥感领域的广泛适用性。&lt;h4&gt;总结&lt;/h4&gt;本研究填补了RSDG领域的研究空白，推动了语义分割任务的进展，并为相关研究提供了基准和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cuzyoung/crossearth&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The field of Remote Sensing Domain Generalization (RSDG) has emerged as acritical and valuable research frontier, focusing on developing models thatgeneralize effectively across diverse scenarios. Despite the substantial domaingaps in RS images that are characterized by variabilities such as location,wavelength, and sensor type, research in this area remains underexplored: (1)Current cross-domain methods primarily focus on Domain Adaptation (DA), whichadapts models to predefined domains rather than to unseen ones; (2) Few studiestargeting the RSDG issue, especially for semantic segmentation tasks, whereexisting models are developed for specific unknown domains, struggling withissues of underfitting on other unknown scenarios; (3) Existing RS foundationmodels tend to prioritize in-domain performance over cross-domaingeneralization. To this end, we introduce the first vision foundation model forRSDG semantic segmentation, CrossEarth. CrossEarth demonstrates strongcross-domain generalization through a specially designed data-level Earth-StyleInjection pipeline and a model-level Multi-Task Training pipeline. In addition,for the semantic segmentation task, we have curated an RSDG benchmarkcomprising 28 cross-domain settings across various regions, spectral bands,platforms, and climates, providing a comprehensive framework for testing thegeneralizability of future RSDG models. Extensive experiments on this benchmarkdemonstrate the superiority of CrossEarth over existing state-of-the-artmethods.</description>
      <author>example@mail.com (Ziyang Gong, Zhixiang Wei, Di Wang, Xianzheng Ma, Hongruixuan Chen, Yuru Jia, Yupeng Deng, Zhenming Ji, Xiangwei Zhu, Naoto Yokoya, Jing Zhang, Bo Du, Liangpei Zhang)</author>
      <guid isPermaLink="false">2410.22629v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation</title>
      <link>http://arxiv.org/abs/2410.22658v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;持续模仿学习（CiL）旨在从多个阶段和任务的演示中提取和积累任务知识，以实现多任务策略。&lt;h4&gt;目的&lt;/h4&gt;解决现有适配器基础的CiL方法在知识共享方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出IsCiL框架，通过逐步学习不同演示中的可共享技能，支持在非平稳CiL环境中进行样本高效的任务适应。&lt;h4&gt;主要发现&lt;/h4&gt;在Franka-Kitchen和Meta-World的复杂任务实验中，IsCiL在任务适应性和样本效率上表现出色。&lt;h4&gt;结论&lt;/h4&gt;IsCiL不仅能有效适应任务，还可以扩展至任务遗忘场景。&lt;h4&gt;总结&lt;/h4&gt;IsCiL通过增强知识共享能力，提升了持续模仿学习的性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual Imitation Learning (CiL) involves extracting and accumulating taskknowledge from demonstrations across multiple stages and tasks to achieve amulti-task policy. With recent advancements in foundation models, there hasbeen a growing interest in adapter-based CiL approaches, where adapters areestablished parameter-efficiently for tasks newly demonstrated. While theseapproaches isolate parameters for specific tasks and tend to mitigatecatastrophic forgetting, they limit knowledge sharing among differentdemonstrations. We introduce IsCiL, an adapter-based CiL framework thataddresses this limitation of knowledge sharing by incrementally learningshareable skills from different demonstrations, thus enabling sample-efficienttask adaptation using the skills particularly in non-stationary CiLenvironments. In IsCiL, demonstrations are mapped into the state embeddingspace, where proper skills can be retrieved upon input states throughprototype-based memory. These retrievable skills are incrementally learned ontheir corresponding adapters. Our CiL experiments with complex tasks inFranka-Kitchen and Meta-World demonstrate robust performance of IsCiL in bothtask adaptation and sample-efficiency. We also show a simple extension of IsCiLfor task unlearning scenarios.</description>
      <author>example@mail.com (Daehee Lee, Minjong Yoo, Woo Kyung Kim, Wonje Choi, Honguk Woo)</author>
      <guid isPermaLink="false">2410.22658v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Systematic Literature Review of Spatio-Temporal Graph Neural Network Models for Time Series Forecasting and Classification</title>
      <link>http://arxiv.org/abs/2410.22377v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，时空图神经网络（GNNs）在时间序列分析领域受到广泛关注，因其能捕捉变量之间及时间点之间的依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提供GNNs在时间序列分类和预测中的建模方法和应用领域的全面概述。&lt;h4&gt;方法&lt;/h4&gt;进行了数据库搜索，选择了150多篇期刊论文，对该领域的现状进行了详细审查。&lt;h4&gt;主要发现&lt;/h4&gt;提供了各种模型的汇总、相关源代码链接、可用数据集、基准模型和拟合结果。&lt;h4&gt;结论&lt;/h4&gt;希望这些信息能为研究人员的未来研究提供帮助，这是首个系统性文献综述，详细比较了不同领域中当前时空GNN模型的结果。&lt;h4&gt;挑战&lt;/h4&gt;讨论了时空GNNs应用中的当前限制和挑战，如可比性、可重复性、可解释性、信息容量不足和可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本综述为研究人员提供了一个全面的模型和应用参考，同时指出了未来研究中需要克服的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, spatio-temporal graph neural networks (GNNs) have attractedconsiderable interest in the field of time series analysis, due to theirability to capture dependencies among variables and across time points. Theobjective of the presented systematic literature review is hence to provide acomprehensive overview of the various modeling approaches and applicationdomains of GNNs for time series classification and forecasting. A databasesearch was conducted, and over 150 journal papers were selected for a detailedexamination of the current state-of-the-art in the field. This examination isintended to offer to the reader a comprehensive collection of proposed models,links to related source code, available datasets, benchmark models, and fittingresults. All this information is hoped to assist researchers in future studies.To the best of our knowledge, this is the first systematic literature reviewpresenting a detailed comparison of the results of current spatio-temporal GNNmodels in different domains. In addition, in its final part this reviewdiscusses current limitations and challenges in the application ofspatio-temporal GNNs, such as comparability, reproducibility, explainability,poor information capacity, and scalability.</description>
      <author>example@mail.com (Flavio Corradini, Marco Gori, Carlo Lucheroni, Marco Piangerelli, Martina Zannotti)</author>
      <guid isPermaLink="false">2410.22377v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Graph-Based Model for Vehicle-Centric Data Sharing Ecosystem</title>
      <link>http://arxiv.org/abs/2410.22897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was accepted and presented at 2024 IEEE 27th International
  Conference on Intelligent Transportation Systems (ITSC 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;技术的发展促使汽车行业发生范式转变，越来越关注连接服务和自动驾驶能力。&lt;h4&gt;目的&lt;/h4&gt;理解现代汽车数据收集和共享的生态系统。&lt;h4&gt;方法&lt;/h4&gt;采用本体论101方法，结合隐私政策分析、文献综述和现有本体，开发高层概念图模型。&lt;h4&gt;主要发现&lt;/h4&gt;现代汽车在数据交换中处理不同方之间的信息，提供隐私相关的数据共享见解。&lt;h4&gt;结论&lt;/h4&gt;提出了基础模型，具备灵活性和可扩展性，以进一步分析不同背景下的数据共享实践。&lt;h4&gt;未来研究方向&lt;/h4&gt;探索高级本体语言进行推理任务，支持拓扑分析以发现数据隐私风险，开发比较分析工具。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了汽车数据共享生态系统的复杂性，并建议进一步研究以增强对隐私问题的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of technologies has prompted a paradigm shift in theautomotive industry, with an increasing focus on connected services andautonomous driving capabilities. This transformation allows vehicles to collectand share vast amounts of vehicle-specific and personal data. While thesetechnological advancements offer enhanced user experiences, they also raiseprivacy concerns. To understand the ecosystem of data collection and sharing inmodern vehicles, we adopted the ontology 101 methodology to incorporateinformation extracted from different sources, including analysis of privacypolicies using GPT-4, a small-scale systematic literature review, and anexisting ontology, to develop a high-level conceptual graph-based model, aimingto get insights into how modern vehicles handle data exchange among differentparties. This serves as a foundational model with the flexibility andscalability to further expand for modelling and analysing data sharingpractices across diverse contexts. Two realistic examples were developed todemonstrate the usefulness and effectiveness of discovering insights intoprivacy regarding vehicle-related data sharing. We also recommend severalfuture research directions, such as exploring advanced ontology languages forreasoning tasks, supporting topological analysis for discovering data privacyrisks/concerns, and developing useful tools for comparative analysis, tostrengthen the understanding of the vehicle-centric data sharing ecosystem.</description>
      <author>example@mail.com (Haiyue Yuan, Ali Raza, Nikolay Matyunin, Jibesh Patra, Shujun Li)</author>
      <guid isPermaLink="false">2410.22897v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Robots Pre-train Robots: Manipulation-Centric Robotic Representation from Large-Scale Robot Datasets</title>
      <link>http://arxiv.org/abs/2410.22325v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉表示的预训练提高了机器人学习的效率，但缺乏大规模的领域内机器人数据集。&lt;h4&gt;目的&lt;/h4&gt;利用人类视频进行机器人视觉表示的预训练，克服数据不足的问题。&lt;h4&gt;方法&lt;/h4&gt;评估各种预训练表示与下游机器人操作任务的相关性；提出操作中心表示（MCR）框架，捕捉视觉特征和动态信息。&lt;h4&gt;主要发现&lt;/h4&gt;发现操作中心性是下游任务成功率的强指标，MCR在四个仿真领域的20个任务中超越最强基线方法14.8%。&lt;h4&gt;结论&lt;/h4&gt;MCR在现实世界的三项任务中提升了数据高效学习的性能76.9%。&lt;h4&gt;总结&lt;/h4&gt;MCR通过对视觉观察与机器人状态-动作动态进行对齐，显著提升了机器人操作的效率与效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The pre-training of visual representations has enhanced the efficiency ofrobot learning. Due to the lack of large-scale in-domain robotic datasets,prior works utilize in-the-wild human videos to pre-train robotic visualrepresentation. Despite their promising results, representations from humanvideos are inevitably subject to distribution shifts and lack the dynamicsinformation crucial for task completion. We first evaluate various pre-trainedrepresentations in terms of their correlation to the downstream roboticmanipulation tasks (i.e., manipulation centricity). Interestingly, we find thatthe "manipulation centricity" is a strong indicator of success rates whenapplied to downstream tasks. Drawing from these findings, we proposeManipulation Centric Representation (MCR), a foundation representation learningframework capturing both visual features and the dynamics information such asactions and proprioceptions of manipulation tasks to improve manipulationcentricity. Specifically, we pre-train a visual encoder on the DROID roboticdataset and leverage motion-relevant data such as robot proprioceptive statesand actions. We introduce a novel contrastive loss that aligns visualobservations with the robot's proprioceptive state-action dynamics, combinedwith a behavior cloning (BC)-like actor loss to predict actions duringpre-training, along with a time contrastive loss. Empirical results across 4simulation domains with 20 tasks verify that MCR outperforms the strongestbaseline method by 14.8%. Moreover, MCR boosts the performance ofdata-efficient learning with a UR5e arm on 3 real-world tasks by 76.9%. Projectwebsite: https://robots-pretrain-robots.github.io/.</description>
      <author>example@mail.com (Guangqi Jiang, Yifei Sun, Tao Huang, Huanyu Li, Yongyuan Liang, Huazhe Xu)</author>
      <guid isPermaLink="false">2410.22325v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Object 3D Grounding with Dynamic Modules and Language-Informed Spatial Attention</title>
      <link>http://arxiv.org/abs/2410.22306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多目标3D定位涉及根据点云中的查询短语定位3D框，是一项具有挑战性和重要性的任务，广泛应用于视觉理解、人机交互和机器人技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决多目标3D定位挑战的方法。&lt;h4&gt;方法&lt;/h4&gt;引入D-LISA，两阶段方法，包含三个创新：1）动态视觉模块，允许可变和可学习数量的框提议；2）动态相机定位，为每个提议提取特征；3）语言知情的空间注意模块，更好地对提议进行推理，输出最终预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，D-LISA在多目标3D定位任务上比现有最先进的方法提高了12.8%的绝对精度，并且在单目标3D定位上也表现出竞争力。&lt;h4&gt;结论&lt;/h4&gt;D-LISA方法在多目标和单目标3D定位任务中均表现出色，验证了其有效性。&lt;h4&gt;总结&lt;/h4&gt;D-LISA通过创新模块显著提升了多目标3D定位的性能，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-object 3D Grounding involves locating 3D boxes based on a given queryphrase from a point cloud. It is a challenging and significant task withnumerous applications in visual understanding, human-computer interaction, androbotics. To tackle this challenge, we introduce D-LISA, a two-stage approachincorporating three innovations. First, a dynamic vision module that enables avariable and learnable number of box proposals. Second, a dynamic camerapositioning that extracts features for each proposal. Third, alanguage-informed spatial attention module that better reasons over theproposals to output the final prediction. Empirically, experiments show thatour method outperforms the state-of-the-art methods on multi-object 3Dgrounding by 12.8% (absolute) and is competitive in single-object 3D grounding.</description>
      <author>example@mail.com (Haomeng Zhang, Chiao-An Yang, Raymond A. Yeh)</author>
      <guid isPermaLink="false">2410.22306v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Emotion-Guided Image to Music Generation</title>
      <link>http://arxiv.org/abs/2410.22299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2024 6th Asian Digital Image Processing Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从图像生成音乐可以提升多种应用，包括照片幻灯片的背景音乐、社交媒体体验和视频创作。&lt;h4&gt;目的&lt;/h4&gt;提出一种情感引导的图像到音乐生成框架，使生成的音乐与给定图像的情感基调相一致。&lt;h4&gt;方法&lt;/h4&gt;采用基于情感的Valence-Arousal (VA)空间，直接整合VA损失函数以实现准确的情感对齐，模型使用CNN-Transformer架构。&lt;h4&gt;主要发现&lt;/h4&gt;在新创建的情感配对图像-MIDI数据集上的实验结果表明，所提出模型在多音率、音高熵、节奏一致性和损失收敛等指标上表现优越。&lt;h4&gt;结论&lt;/h4&gt;该模型能够生成在音乐和情感上都具有一致性的MIDI序列，超越了以往依赖对比学习的模型。&lt;h4&gt;总结&lt;/h4&gt;论文展示了一种新的图像到音乐生成方法，强调情感一致性，具有良好的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating music from images can enhance various applications, includingbackground music for photo slideshows, social media experiences, and videocreation. This paper presents an emotion-guided image-to-music generationframework that leverages the Valence-Arousal (VA) emotional space to producemusic that aligns with the emotional tone of a given image. Unlike previousmodels that rely on contrastive learning for emotional consistency, theproposed approach directly integrates a VA loss function to enable accurateemotional alignment. The model employs a CNN-Transformer architecture,featuring pre-trained CNN image feature extractors and three Transformerencoders to capture complex, high-level emotional features from MIDI music.Three Transformer decoders refine these features to generate musically andemotionally consistent MIDI sequences. Experimental results on a newly curatedemotionally paired image-MIDI dataset demonstrate the proposed model's superiorperformance across metrics such as Polyphony Rate, Pitch Entropy, GrooveConsistency, and loss convergence.</description>
      <author>example@mail.com (Souraja Kundu, Saket Singh, Yuji Iwahori)</author>
      <guid isPermaLink="false">2410.22299v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>LogSHIELD: A Graph-based Real-time Anomaly Detection Framework using Frequency Analysis</title>
      <link>http://arxiv.org/abs/2410.21936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于异常的网络威胁检测在深度学习领域日益受到关注，旨在检测新型网络攻击和取证。&lt;h4&gt;目的&lt;/h4&gt;提出一个高效、实时的威胁检测模型，以满足大规模企业网络中的高准确率和高通量需求。&lt;h4&gt;方法&lt;/h4&gt;提出LogSHIELD模型，采用基于图的异常检测，利用来源图的频域分析进行实时威胁检测。&lt;h4&gt;主要发现&lt;/h4&gt;LogSHIELD能够提取日志之间的上下文和因果关系，有效检测隐秘和复杂的攻击，平均AUC和F1分数超过98%。&lt;h4&gt;结论&lt;/h4&gt;LogSHIELD显著提高了检测吞吐量，平均检测延迟为0.13秒，检测时间优于现有模型。&lt;h4&gt;总结&lt;/h4&gt;LogSHIELD是一种先进的图基异常检测模型，适用于实时网络威胁监测，具备高效的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly-based cyber threat detection using deep learning is on a constantgrowth in popularity for novel cyber-attack detection and forensics. A robust,efficient, and real-time threat detector in a large-scale operationalenterprise network requires high accuracy, high fidelity, and a high throughputmodel to detect malicious activities. Traditional anomaly-based detectionmodels, however, suffer from high computational overhead and low detectionaccuracy, making them unsuitable for real-time threat detection. In this work,we propose LogSHIELD, a highly effective graph-based anomaly detection model inhost data. We present a real-time threat detection approach usingfrequency-domain analysis of provenance graphs. To demonstrate the significanceof graph-based frequency analysis we proposed two approaches. Approach-I uses aGraph Neural Network (GNN) LogGNN and approach-II performs frequency domainanalysis on graph node samples for graph embedding. Both approaches use astatistical clustering algorithm for anomaly detection. The proposed models areevaluated using a large host log dataset consisting of 774M benign logs and375K malware logs. LogSHIELD explores the provenance graph to extractcontextual and causal relationships among logs, exposing abnormal activities.It can detect stealthy and sophisticated attacks with over 98% average AUC andF1 scores. It significantly improves throughput, achieves an average detectionlatency of 0.13 seconds, and outperforms state-of-the-art models in detectiontime.</description>
      <author>example@mail.com (Krishna Chandra Roy, Qian Chen)</author>
      <guid isPermaLink="false">2410.21936v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>HelloMeme: Integrating Spatial Knitting Attentions to Embed High-Level and Fidelity-Rich Conditions in Diffusion Models</title>
      <link>http://arxiv.org/abs/2410.22901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出一种有效的方法，在文本到图像的基础模型中插入适配器。&lt;h4&gt;目的&lt;/h4&gt;执行复杂的下游任务，同时保持基础模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;优化与2D特征图相关的注意力机制，以增强适配器的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在生成表情视频的任务中验证了该方法，并取得了显著成果。&lt;h4&gt;结论&lt;/h4&gt;该方法为大型文本到图像模型的后训练任务提供了见解，并与SD1.5衍生模型兼容，具备开源社区的价值。&lt;h4&gt;总结&lt;/h4&gt;相关代码将被发布，为进一步研究提供支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/HelloVision/HelloMeme&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose an effective method for inserting adapters into text-to-imagefoundation models, which enables the execution of complex downstream taskswhile preserving the generalization ability of the base model. The core idea ofthis method is to optimize the attention mechanism related to 2D feature maps,which enhances the performance of the adapter. This approach was validated onthe task of meme video generation and achieved significant results. We hopethis work can provide insights for post-training tasks of large text-to-imagemodels. Additionally, as this method demonstrates good compatibility with SD1.5derivative models, it holds certain value for the open-source community.Therefore, we will release the related code(\url{https://songkey.github.io/hellomeme}).</description>
      <author>example@mail.com (Shengkai Zhang, Nianhong Jiao, Tian Li, Chaojie Yang, Chenhui Xue, Boya Niu, Jun Gao)</author>
      <guid isPermaLink="false">2410.22901v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Point cloud-based diffusion models for the Electron-Ion Collider</title>
      <link>http://arxiv.org/abs/2410.22421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高能对撞机实验中，生成模型可用于快速探测器模拟、反折叠、超越标准模型的物理搜索及推断任务。&lt;h4&gt;目的&lt;/h4&gt;扩展先前的生成模型，生成包括所有粒子种类及完整动力学信息的整体对撞事件。&lt;h4&gt;方法&lt;/h4&gt;使用点云和结合图边创建的变换器模块的新的架构，称为点边变换器。还调整基础模型OmniLearn以生成完整的对撞事件。&lt;h4&gt;主要发现&lt;/h4&gt;模型能够很好地学习事件整体约束，如动量守恒和离散量子数，并且在未来的电子-离子对撞机事件中表现良好。&lt;h4&gt;结论&lt;/h4&gt;这种方法可能表明向适应和微调基础模型以满足下游任务的转变，而不是从头开始训练新的模型。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了生成模型在高能对撞机实验中的潜力，尤其是在提高样本生成的精度和效率方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; At high-energy collider experiments, generative models can be used for a widerange of tasks, including fast detector simulations, unfolding, searches ofphysics beyond the Standard Model, and inference tasks. In particular, it hasbeen demonstrated that score-based diffusion models can generate high-fidelityand accurate samples of jets or collider events. This work expands on previousgenerative models in three distinct ways. First, our model is trained togenerate entire collider events, including all particle species with completekinematic information. We quantify how well the model learns event-wideconstraints such as the conservation of momentum and discrete quantum numbers.We focus on the events at the future Electron-Ion Collider, but we expect thatour results can be extended to proton-proton and heavy-ion collisions. Second,previous generative models often relied on image-based techniques. The sparsityof the data can negatively affect the fidelity and sampling time of the model.We address these issues using point clouds and a novel architecture combiningedge creation with transformer modules called Point Edge Transformers. Third,we adapt the foundation model OmniLearn, to generate full collider events. Thisapproach may indicate a transition toward adapting and fine-tuning foundationmodels for downstream tasks instead of training new models from scratch.</description>
      <author>example@mail.com (Jack Y. Araz, Vinicius Mikuni, Felix Ringer, Nobuo Sato, Fernando Torales Acosta, Richard Whitehill)</author>
      <guid isPermaLink="false">2410.22421v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DECRL: A Deep Evolutionary Clustering Jointed Temporal Knowledge Graph Representation Learning Approach</title>
      <link>http://arxiv.org/abs/2410.22631v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024, 17 pages, and 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间知识图谱（TKG）表示学习旨在将随时间演变的实体和关系映射到连续低维向量空间中的嵌入表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种深度演化聚类联合时间知识图谱表示学习的方法（DECRL），以捕捉TKG中高阶相关性的时间演变。&lt;h4&gt;方法&lt;/h4&gt;引入深度演化聚类模块来捕捉实体之间的高阶相关性；采用聚类感知的无监督对齐机制，确保跨时间戳的软重叠聚类的精确一对一对齐；引入隐式相关编码器，捕捉在全局图引导下任意两组聚类之间的潜在相关性。&lt;h4&gt;主要发现&lt;/h4&gt;在七个真实世界数据集上的广泛实验表明，DECRL在平均上在MRR、Hits@1、Hits@3和Hits@10方面比最佳基线分别提高了9.53%、12.98%、10.42%和14.68%。&lt;h4&gt;结论&lt;/h4&gt;DECRL在时间知识图谱表示学习中实现了最先进的性能，有效捕捉了高阶相关性的时间演变。&lt;h4&gt;总结&lt;/h4&gt;DECRL方法在处理TKG的时间演变方面具有显著优势，展示了其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Knowledge Graph (TKG) representation learning aims to map temporalevolving entities and relations to embedded representations in a continuouslow-dimensional vector space. However, existing approaches cannot capture thetemporal evolution of high-order correlations in TKGs. To this end, we proposea Deep Evolutionary Clustering jointed temporal knowledge graph RepresentationLearning approach (DECRL). Specifically, a deep evolutionary clustering moduleis proposed to capture the temporal evolution of high-order correlations amongentities. Furthermore, a cluster-aware unsupervised alignment mechanism isintroduced to ensure the precise one-to-one alignment of soft overlappingclusters across timestamps, thereby maintaining the temporal smoothness ofclusters. In addition, an implicit correlation encoder is introduced to capturelatent correlations between any pair of clusters under the guidance of a globalgraph. Extensive experiments on seven real-world datasets demonstrate thatDECRL achieves the state-of-the-art performances, outperforming the bestbaseline by an average of 9.53%, 12.98%, 10.42%, and 14.68% in MRR, Hits@1,Hits@3, and Hits@10, respectively.</description>
      <author>example@mail.com (Qian Chen, Ling Chen)</author>
      <guid isPermaLink="false">2410.22631v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning</title>
      <link>http://arxiv.org/abs/2410.21872v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;早期准确诊断脑肿瘤对提高患者生存率至关重要，但由于脑肿瘤类型多样和形态特征复杂，检测与分类具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究预训练模型在脑肿瘤分类中的应用，特别关注Mamba模型的部署。&lt;h4&gt;方法&lt;/h4&gt;微调多个主流迁移学习模型，并将其应用于脑肿瘤的多类分类，与从头训练的模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;Vim模型在独立测试集上实现了100%的分类准确率，展示了迁移学习在医学影像领域的显著优势。&lt;h4&gt;结论&lt;/h4&gt;Vim模型相比现有的先进模型更轻量、高效且准确，为临床应用提供了新视角，且所提出的框架可广泛应用于其他医学影像分类问题。&lt;h4&gt;总结&lt;/h4&gt;本研究强调迁移学习在脑肿瘤分类中的有效性，展示了新模型的潜力和广泛适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early and accurate diagnosis of brain tumors is crucial for improving patientsurvival rates. However, the detection and classification of brain tumors arechallenging due to their diverse types and complex morphologicalcharacteristics. This study investigates the application of pre-trained modelsfor brain tumor classification, with a particular focus on deploying the Mambamodel. We fine-tuned several mainstream transfer learning models and appliedthem to the multi-class classification of brain tumors. By comparing thesemodels to those trained from scratch, we demonstrated the significantadvantages of transfer learning, especially in the medical imaging field, whereannotated data is often limited. Notably, we introduced the Vision Mamba (Vim),a novel network architecture, and applied it for the first time in brain tumorclassification, achieving exceptional classification accuracy. Experimentalresults indicate that the Vim model achieved 100% classification accuracy on anindependent test set, emphasizing its potential for tumor classification tasks.These findings underscore the effectiveness of transfer learning in brain tumorclassification and reveal that, compared to existing state-of-the-art models,the Vim model is lightweight, efficient, and highly accurate, offering a newperspective for clinical applications. Furthermore, the framework proposed inthis study for brain tumor classification, based on transfer learning and theVision Mamba model, is broadly applicable to other medical imagingclassification problems.</description>
      <author>example@mail.com (Yinyi Lai, Anbo Cao, Yuan Gao, Jiaqi Shang, Zongyu Li, Jia Guo)</author>
      <guid isPermaLink="false">2410.21872v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ERGO-ML: A continuous organization of the X-ray galaxy cluster population in TNG-Cluster with contrastive learning</title>
      <link>http://arxiv.org/abs/2410.22416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Please see more results from TNG-Cluster on astro-ph this week from
  Rohr+ and Prunier+&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;星系团的物理特性反映了潜在引力场、合并及与其它光晕和卫星星系的强相互作用，以及来自超新星和超大质量黑洞的星系反馈。&lt;h4&gt;目的&lt;/h4&gt;考虑ICM的X射线发射图像中的全部信息内容，而不仅仅是传统的总结统计。&lt;h4&gt;方法&lt;/h4&gt;使用最近邻对比学习(NNCLR)识别并填充低维表示空间，以352个星系团的理想化X射线图像为基础，生成约8000幅图像。&lt;h4&gt;主要发现&lt;/h4&gt;表示空间形成了从放松到合并物体的连续分布，并显示出与红移、光晕质量、气体质量、恒星质量和超大质量黑洞质量等的明显趋势。&lt;h4&gt;结论&lt;/h4&gt;8维表示可以用于预测星系团的多种属性、寻找类比并识别物理属性之间的相关性，暗示因果关系。&lt;h4&gt;总结&lt;/h4&gt;对比学习是一个强大的工具，能够仅凭图像特征表征星系团，并推导出它们的物理特性和形成历史的约束。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The physical properties of the intracluster medium (ICM) reflect signaturesof the underlying gravitational potential, mergers and strong interactions withother halos and satellite galaxies, as well as galactic feedback fromsupernovae and supermassive black holes (SMBHs). Traditionally, clusters havebeen characterized in terms of summary statistics, such as halo mass, X-rayluminosity, cool-core state, luminosity of AGN, and number of mergingcomponents. In this paper of the Extracting Reality from Galaxy Observableswith Machine Learning series (ERGO-ML), we instead consider the fullinformation content available in maps of X-ray emission from the ICM. We employNearest Neighbour Contrastive Learning (NNCLR) to identify and populate alow-dimensional representation space of such images. Using idealized X-ray mapsof the 352 clusters of the TNG-Cluster cosmological magnetohydrodynamicalsimulation suite, we take three orthogonal projections of each cluster at eightsnapshots within the redshift range $0\leq z&lt;1$, resulting in a dataset of$\sim$8,000 images. Our findings reveal that this representation space forms acontinuous distribution from relaxed to merging objects, and fromcentrally-peaked to flat emission profiles. The representation also exhibitsclear trends with redshift, with halo, gas, stellar, and SMBH mass, with timesince a last major merger, and with indicators of dynamical state. We show thatan 8-dimensional representation can be used to predict a variety of clusterproperties, find analogs, and identify correlations between physicalproperties, thereby suggesting causal relationships. Our analysis demonstratesthat contrastive learning is a powerful tool for characterizing galaxy clustersfrom their images alone, allowing us to derive constraints on their physicalproperties and formation histories using cosmological hydrodynamical galaxysimulations.</description>
      <author>example@mail.com (Urmila Chadayammuri, Lukas Eisert, Annalisa Pillepich, Katrin Lehle, Mohammadreza Ayromlou, Dylan Nelson)</author>
      <guid isPermaLink="false">2410.22416v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>CopRA: A Progressive LoRA Training Strategy</title>
      <link>http://arxiv.org/abs/2410.22911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in UniReps Workshop (Extended Abstract Track), NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;低秩适应（LoRA）是一种高效的参数微调基础模型的技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的渐进训练策略，以解决LoRA在合并和剪枝任务中的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入随机层丢弃的训练策略，并优化每层LoRA参数的Shapley值，将每层视为合作游戏中的参与者，称之为合作LoRA（CopRA）。&lt;h4&gt;主要发现&lt;/h4&gt;使用CopRA训练的参数展现出线性模式连接性，支持高效的模型合并。&lt;h4&gt;结论&lt;/h4&gt;CopRA为联邦学习和多任务学习开辟了新途径，同时在剪枝任务中表现优越。&lt;h4&gt;总结&lt;/h4&gt;CopRA通过优化模型训练过程，改善了LoRA在特定任务中的表现，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) is a parameter-efficient technique for rapidlyfine-tuning foundation models. In standard LoRA training dynamics, models tendto quickly converge to a local optimum near the initialization. However, thislocal optimum may not be ideal for out-of-distribution data or tasks such asmerging and pruning. In this work, we propose a novel progressive trainingstrategy for LoRA with random layer dropping. This strategy also optimizes theShapley value of LoRA parameters in each layer, treating each layer as a playerin a cooperative game. We refer to this method as Cooperative LoRA (CopRA). Ourexperimental results demonstrate that parameters trained with CopRA exhibitlinear mode connectivity, which enables efficient model merging. This alsopaves the way for federated learning and multi-task learning via LoRA merging.Additionally, by optimizing the Shapley value, CopRA shows superior performancein pruning tasks.</description>
      <author>example@mail.com (Zhan Zhuang, Xiequn Wang, Yulong Zhang, Wei Li, Yu Zhang, Ying Wei)</author>
      <guid isPermaLink="false">2410.22911v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Feature distribution Adaptation Network for Speech Emotion Recognition</title>
      <link>http://arxiv.org/abs/2410.22023v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态语音情感识别问题具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的深度归纳迁移学习框架，称为特征分布适应网络，以提升语音情感识别的表现。&lt;h4&gt;方法&lt;/h4&gt;利用预训练的ResNet-34进行面部表情图像和声学梅尔谱特征提取，采用交叉注意力机制建模多模态特征的内在相似性，并通过前馈网络高效执行多模态特征分布适应，扩展使用局部最大均值差损失。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准数据集上的实验结果表明，该模型相比现有方法具有优秀的性能。&lt;h4&gt;结论&lt;/h4&gt;所提方法有效改善了多模态语音情感识别的效果。&lt;h4&gt;总结&lt;/h4&gt;通过深度迁移学习策略，成功对齐视觉和音频特征分布，实现情感的一致性表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shaokai1209/fdan&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel deep inductive transfer learning framework,named feature distribution adaptation network, to tackle the challengingmulti-modal speech emotion recognition problem. Our method aims to use deeptransfer learning strategies to align visual and audio feature distributions toobtain consistent representation of emotion, thereby improving the performanceof speech emotion recognition. In our model, the pre-trained ResNet-34 isutilized for feature extraction for facial expression images and acoustic Melspectrograms, respectively. Then, the cross-attention mechanism is introducedto model the intrinsic similarity relationships of multi-modal features.Finally, the multi-modal feature distribution adaptation is performedefficiently with feed-forward network, which is extended using the localmaximum mean discrepancy loss. Experiments are carried out on two benchmarkdatasets, and the results demonstrate that our model can achieve excellentperformance compared with existing ones.</description>
      <author>example@mail.com (Shaokai Li, Yixuan Ji, Peng Song, Haoqin Sun, Wenming Zheng)</author>
      <guid isPermaLink="false">2410.22023v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Few-shot Open Relation Extraction with Gaussian Prototype and Adaptive Margin</title>
      <link>http://arxiv.org/abs/2410.20320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Few-shot relation extraction with none-of-the-above (FsRE with NOTA) 旨在处理未知类别的少样本场景，这比传统的少样本关系提取任务更具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，解决少样本过拟合和NOTA边界混淆问题，提高分类准确性。&lt;h4&gt;方法&lt;/h4&gt;提出基于高斯原型和自适应边距的GPAM框架，包含三个模块：半真实表示、GMM原型度量学习和决策边界学习。&lt;h4&gt;主要发现&lt;/h4&gt;GPAM通过去偏信息增强和高斯空间距离测量，获得了更好的表示，并通过自适应边距和负采样学习了更准确的分类边界。&lt;h4&gt;结论&lt;/h4&gt;GPAM在FewRel数据集上的实验结果表明，超越了之前的原型方法，实现了最先进的性能。&lt;h4&gt;总结&lt;/h4&gt;GPAM框架有效解决了FsRE with NOTA中的挑战，展示了其在少样本关系提取中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot relation extraction with none-of-the-above (FsRE with NOTA) aims atpredicting labels in few-shot scenarios with unknown classes. FsRE with NOTA ismore challenging than the conventional few-shot relation extraction task, sincethe boundaries of unknown classes are complex and difficult to learn.Meta-learning based methods, especially prototype-based methods, are themainstream solutions to this task. They obtain the classification boundary bylearning the sample distribution of each class. However, their performance islimited because few-shot overfitting and NOTA boundary confusion lead tomisclassification between known and unknown classes. To this end, we propose anovel framework based on Gaussian prototype and adaptive margin named GPAM forFsRE with NOTA, which includes three modules, semi-factual representation,GMM-prototype metric learning and decision boundary learning. The first twomodules obtain better representations to solve the few-shot problem throughdebiased information enhancement and Gaussian space distance measurement. Thethird module learns more accurate classification boundaries and prototypesthrough adaptive margin and negative sampling. In the training procedure ofGPAM, we use contrastive learning loss to comprehensively consider the effectsof range and margin on the classification of known and unknown classes toensure the model's stability and robustness. Sufficient experiments andablations on the FewRel dataset show that GPAM surpasses previous prototypemethods and achieves state-of-the-art performance.</description>
      <author>example@mail.com (Tianlin Guo, Lingling Zhang, Jiaxin Wang, Yuokuo Lei, Yifei Li, Haofen Wang, Jun Liu)</author>
      <guid isPermaLink="false">2410.20320v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms</title>
      <link>http://arxiv.org/abs/2410.23144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://source.plus/pd12m&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;PD12M是一个包含1240万张高质量公共领域和CC0许可图像的数据集。&lt;h4&gt;目的&lt;/h4&gt;旨在为文本到图像模型的训练提供足够的数据。&lt;h4&gt;方法&lt;/h4&gt;通过Source.Plus平台引入社区驱动的数据集治理机制。&lt;h4&gt;主要发现&lt;/h4&gt;PD12M是迄今为止最大的公共领域图像文本数据集，能够有效训练基础模型，同时减少版权问题。&lt;h4&gt;结论&lt;/h4&gt;这种数据集的设计有助于长期支持可重复性和减少潜在伤害。&lt;h4&gt;总结&lt;/h4&gt;PD12M为文本到图像模型的研究提供了重要资源，并促进了数据集的治理和可持续发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Public Domain 12M (PD12M), a dataset of 12.4 million high-qualitypublic domain and CC0-licensed images with synthetic captions, designed fortraining text-to-image models. PD12M is the largest public domain image-textdataset to date, with sufficient size to train foundation models whileminimizing copyright concerns. Through the Source.Plus platform, we alsointroduce novel, community-driven dataset governance mechanisms that reduceharm and support reproducibility over time.</description>
      <author>example@mail.com (Jordan Meyer, Nick Padgett, Cullen Miller, Laura Exline)</author>
      <guid isPermaLink="false">2410.23144v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>The PV-ALE Dataset: Enhancing Apple Leaf Disease Classification Through Transfer Learning with Convolutional Neural Networks</title>
      <link>http://arxiv.org/abs/2410.22490v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in th Sixth International Conference on Soft Computing and
  its Engineering Applications (icSoftComp2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全球食品安全形势不断变化，准确可靠的作物疾病诊断需求日益迫切。&lt;h4&gt;目的&lt;/h4&gt;扩展广泛使用的PlantVillage数据集，增加苹果叶病害类别，以增强多样性和复杂性。&lt;h4&gt;方法&lt;/h4&gt;在原始和扩展数据集上进行实验评估，检验现有模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;现有模型在新增加的类别上表现不佳，凸显了对更强大和可推广的计算机视觉模型的需求。&lt;h4&gt;结论&lt;/h4&gt;在原始和扩展数据集上分别获得了99.63%和97.87%的测试F1分数，提供了更具挑战性和多样化的基准。&lt;h4&gt;总结&lt;/h4&gt;扩展数据集可用于未来研究，推动准确可靠的苹果叶病害识别模型的发展，数据集可在Kaggle上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the global food security landscape continues to evolve, the need foraccurate and reliable crop disease diagnosis has never been more pressing. Toaddress global food security concerns, we extend the widely used PlantVillagedataset with additional apple leaf disease classes, enhancing diversity andcomplexity. Experimental evaluations on both original and extended datasetsreveal that existing models struggle with the new additions, highlighting theneed for more robust and generalizable computer vision models. Test F1 scoresof 99.63% and 97.87% were obtained on the original and extended datasets,respectively. Our study provides a more challenging and diverse benchmark,paving the way for the development of accurate and reliable models foridentifying apple leaf diseases under varying imaging conditions. The expandeddataset is available athttps://www.kaggle.com/datasets/akinyemijoseph/apple-leaf-disease-dataset-6-classes-v2enabling future research to build upon our findings.</description>
      <author>example@mail.com (Joseph Damilola Akinyemi, Kolawole John Adebayo)</author>
      <guid isPermaLink="false">2410.22490v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FISC: Federated Domain Generalization via Interpolative Style Transfer and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.22622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联邦学习（FL）在保护隐私和促进协作学习方面显示出潜力，但大多数现有解决方案仅关注来自单一领域的私有数据。&lt;h4&gt;目的&lt;/h4&gt;解决客户端数据来自不同领域（领域转移）时导致的性能下降问题。&lt;h4&gt;方法&lt;/h4&gt;引入FISC，一种新的FL领域泛化范式，通过提取局部风格的插值风格并采用对比学习，处理更复杂的领域分布。&lt;h4&gt;主要发现&lt;/h4&gt;FISC在多个数据集（包括PACS、Office-Home和IWildCam）上的实验结果显示，其性能超越了现有的最先进方法，未见领域的准确率提高范围为3.64%至57.22%。&lt;h4&gt;结论&lt;/h4&gt;FISC能够有效处理领域异质性和客户端采样问题，提供多领域表示和无偏收敛目标。&lt;h4&gt;总结&lt;/h4&gt;FISC是一种创新的方法，提升了联邦学习在不同领域数据上的性能，代码可在指定链接获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) shows promise in preserving privacy and enablingcollaborative learning. However, most current solutions focus on private datacollected from a single domain. A significant challenge arises when client datacomes from diverse domains (i.e., domain shift), leading to poor performance onunseen domains. Existing Federated Domain Generalization approaches addressthis problem but assume each client holds data for an entire domain, limitingtheir practicality in real-world scenarios with domain-based heterogeneity andclient sampling.  To overcome this, we introduce FISC, a novel FL domain generalizationparadigm that handles more complex domain distributions across clients. FISCenables learning across domains by extracting an interpolative style from localstyles and employing contrastive learning. This strategy gives clientsmulti-domain representations and unbiased convergent targets. Empirical resultson multiple datasets, including PACS, Office-Home, and IWildCam, show FISCoutperforms state-of-the-art (SOTA) methods. Our method achieves accuracyimprovements ranging from 3.64% to 57.22% on unseen domains. Our code isavailable at https://anonymous.4open.science/r/FISC-AAAI-16107.</description>
      <author>example@mail.com (Dung Thuy Nguyen, Taylor T. Johnson, Kevin Leach)</author>
      <guid isPermaLink="false">2410.22622v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Machine Learning for Detecting and Locating Human-Made Objects in 3D Point Cloud</title>
      <link>http://arxiv.org/abs/2410.20006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D点云是由航空LiDAR系统收集的非结构化、稀疏和不规则的数据集，包含每个点的经度、纬度和高程信息。&lt;h4&gt;目的&lt;/h4&gt;检测和识别自然树木结构中的人造物体。&lt;h4&gt;方法&lt;/h4&gt;研究分为三个阶段：地面过滤、局部信息提取（LIE）和聚类。地面过滤使用一种称为单侧回归（OSR）的统计方法，LIE阶段采用基于Hessian矩阵的核方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的地面过滤方法优于先前的技术，LIE方法成功区分树木和人造物体的点。&lt;h4&gt;结论&lt;/h4&gt;Hessian矩阵有效捕捉了树木和人造物体之间的区别，LiDAR点的三维分布与人造物体的二维分布相对应。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的方法来提高在复杂地形中对点云数据中人造物体的检测和识别能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A 3D point cloud is an unstructured, sparse, and irregular dataset, typicallycollected by airborne LiDAR systems over a geological region. Laser pulsesemitted from these systems reflect off objects both on and above the ground,resulting in a dataset containing the longitude, latitude, and elevation ofeach point, as well as information about the corresponding laser pulsestrengths. A widely studied research problem, addressed in many previous works,is ground filtering, which involves partitioning the points into ground andnon-ground subsets. This research introduces a novel task: detecting andidentifying human-made objects amidst natural tree structures. This task isperformed on the subset of non-ground points derived from the ground filteringstage. Marked Point Fields (MPFs) are used as models well-suited to thesetasks. The proposed methodology consists of three stages: ground filtering,local information extraction (LIE), and clustering. In the ground filteringstage, a statistical method called One-Sided Regression (OSR) is introduced,addressing the limitations of prior ground filtering methods on uneventerrains. In the LIE stage, unsupervised learning methods are lacking. Tomitigate this, a kernel-based method for the Hessian matrix of the MPF isdeveloped. In the clustering stage, the Gaussian Mixture Model (GMM) is appliedto the results of the LIE stage to partition the non-ground points into treesand human-made objects. The underlying assumption is that LiDAR points fromtrees exhibit a three-dimensional distribution, while those from human-madeobjects follow a two-dimensional distribution. The Hessian matrix of the MPFeffectively captures this distinction. Experimental results demonstrate thatthe proposed ground filtering method outperforms previous techniques, and theLIE method successfully distinguishes between points representing trees andhuman-made objects.</description>
      <author>example@mail.com (Hong Zhao, Huyunting Huang, Tonglin Zhang, Baijian Yang, Jin Wei-Kocsis, Songlin Fei)</author>
      <guid isPermaLink="false">2410.20006v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Vision Paper: Designing Graph Neural Networks in Compliance with the European Artificial Intelligence Act</title>
      <link>http://arxiv.org/abs/2410.22120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;欧盟人工智能法案为人工智能和机器学习系统的发展与监管提供了全面的指导，尤其对图神经网络（GNNs）有重大影响。&lt;h4&gt;目的&lt;/h4&gt;探讨人工智能法案对图神经网络所带来的独特挑战，并提出相应的应对策略。&lt;h4&gt;方法&lt;/h4&gt;分析法案对数据管理、数据治理、鲁棒性、人类监督和隐私的要求，并研究这些要求对GNN训练的影响。&lt;h4&gt;主要发现&lt;/h4&gt;强调了在GNN中公平采样策略和有效可解释性技术的重要性，分析了偏见、鲁棒性、可解释性和隐私的相关问题。&lt;h4&gt;结论&lt;/h4&gt;为GNN在新立法框架下提供了具体指导，填补了研究空白，并识别了未来研究的开放问题。&lt;h4&gt;总结&lt;/h4&gt;本研究为GNN的合规性提出了方法，并指出了在新的法律要求下的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The European Union's Artificial Intelligence Act (AI Act) introducescomprehensive guidelines for the development and oversight of ArtificialIntelligence (AI) and Machine Learning (ML) systems, with significantimplications for Graph Neural Networks (GNNs). This paper addresses the uniquechallenges posed by the AI Act for GNNs, which operate on complexgraph-structured data. The legislation's requirements for data management, datagovernance, robustness, human oversight, and privacy necessitate tailoredstrategies for GNNs. Our study explores the impact of these requirements on GNNtraining and proposes methods to ensure compliance. We provide an in-depthanalysis of bias, robustness, explainability, and privacy in the context ofGNNs, highlighting the need for fair sampling strategies and effectiveinterpretability techniques. Our contributions fill the research gap byoffering specific guidance for GNNs under the new legislative framework andidentifying open questions and future research directions.</description>
      <author>example@mail.com (Barbara Hoffmann, Jana Vatter, Ruben Mayer)</author>
      <guid isPermaLink="false">2410.22120v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Auxiliary Task Relevance for Enhanced Industrial Fault Diagnosis through Curriculum Meta-learning</title>
      <link>http://arxiv.org/abs/2410.20351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器故障的准确诊断对智能制造的操作安全至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决深度学习在设备故障实例中标注训练数据稀缺的问题，从而提升故障诊断的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种相关任务意识课程元学习（RT-ACM）框架，灵感来源于人类认知学习过程，考虑辅助工作条件的相关性，并采用“先易后难”的课程采样原则。&lt;h4&gt;主要发现&lt;/h4&gt;RT-ACM框架在两个真实数据集上的实验结果表明其优越性。&lt;h4&gt;结论&lt;/h4&gt;RT-ACM框架显著改善了故障诊断模型的收敛状态，有助于克服现有方法在变动工作条件下的不足。&lt;h4&gt;总结&lt;/h4&gt;通过引入RT-ACM框架，可以更有效地进行机器故障诊断，提升智能制造的安全性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate diagnosis of machine breakdowns is crucial for maintainingoperational safety in smart manufacturing. Despite the promise shown by deeplearning in automating fault identification, the scarcity of labeled trainingdata, particularly for equipment failure instances, poses a significantchallenge. This limitation hampers the development of robust classificationmodels. Existing methods like model-agnostic meta-learning (MAML) do notadequately address variable working conditions, affecting knowledge transfer.To address these challenges, a Related Task Aware Curriculum Meta-learning(RT-ACM) enhanced fault diagnosis framework is proposed in this paper, inspiredby human cognitive learning processes. RT-ACM improves training by consideringthe relevance of auxiliary working conditions, adhering to the principle of``paying more attention to more relevant knowledge", and focusing on ``easierfirst, harder later" curriculum sampling. This approach aids the meta-learnerin achieving a superior convergence state. Extensive experiments on tworeal-world datasets demonstrate the superiority of RT-ACM framework.</description>
      <author>example@mail.com (Jinze Wang, Tiehua Zhang, Boon Xian Chai, Adriano Di Pietro, Dimitrios Georgakopoulos, Jiong Jin)</author>
      <guid isPermaLink="false">2410.20351v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DECADE: Towards Designing Efficient-yet-Accurate Distance Estimation Modules for Collision Avoidance in Mobile Advanced Driver Assistance Systems</title>
      <link>http://arxiv.org/abs/2410.19336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 17 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能手机和移动设备的普及为每个人提供了使用低成本机器学习/深度学习模型的高级驾驶辅助系统（ADAS）应用的机会，以增强道路安全。&lt;h4&gt;目的&lt;/h4&gt;针对移动ADAS中的碰撞避免的关键功能，提出一种轻量级的距离估计模型DECADE。&lt;h4&gt;方法&lt;/h4&gt;DECADE处理每个检测器输出，而不是构建逐像素的深度/视差图，并提出一个姿态估计DNN来估计检测的自我中心方向，以辅助距离估计DNN进行预测。&lt;h4&gt;主要发现&lt;/h4&gt;与YOLO目标检测器结合并在KITTI 3D目标检测数据集上进行微调后，提出的模块在距离范围0-150米内实现了1.38米的平均绝对误差和7.3%的平均相对误差，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该评估方案不仅评估了类别性能，还特别在0-70米的关键范围内评估了距离准确性。&lt;h4&gt;总结&lt;/h4&gt;DECADE模型通过快速距离估计扩展了对象检测的能力，提高了移动ADAS的实时应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of smartphones and other mobile devices provides a uniqueopportunity to make Advanced Driver Assistance Systems (ADAS) accessible toeveryone in the form of an application empowered by low-cost Machine/DeepLearning (ML/DL) models to enhance road safety. For the critical feature ofCollision Avoidance in Mobile ADAS, lightweight Deep Neural Networks (DNN) forobject detection exist, but conventional pixel-wise depth/distance estimationDNNs are vastly more computationally expensive making them unsuitable for areal-time application on resource-constrained devices. In this paper, wepresent a distance estimation model, DECADE, that processes each detectoroutput instead of constructing pixel-wise depth/disparity maps. In it, wepropose a pose estimation DNN to estimate allocentric orientation of detectionsto supplement the distance estimation DNN in its prediction of distance usingbounding box features. We demonstrate that these modules can be attached to anydetector to extend object detection with fast distance estimation. Evaluationof the proposed modules with attachment to and fine-tuning on the outputs ofthe YOLO object detector on the KITTI 3D Object Detection dataset achievesstate-of-the-art performance with 1.38 meters in Mean Absolute Error and 7.3%in Mean Relative Error in the distance range of 0-150 meters. Our extensiveevaluation scheme not only evaluates class-wise performance, but also evaluatesrange-wise accuracy especially in the critical range of 0-70m.</description>
      <author>example@mail.com (Muhammad Zaeem Shahzad, Muhammad Abdullah Hanif, Muhammad Shafique)</author>
      <guid isPermaLink="false">2410.19336v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Towards Neural-Network-based optical temperature sensing of Semiconductor Membrane External Cavity Laser</title>
      <link>http://arxiv.org/abs/2410.22528v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种基于机器学习的非接触方法，用于通过激光发射确定激光增益介质的温度。&lt;h4&gt;目的&lt;/h4&gt;利用训练好的少层神经网络模型预测激光设备的特性，仅依赖光谱数据。&lt;h4&gt;方法&lt;/h4&gt;采用前馈神经网络训练，通过可见光/近红外光微型光谱仪记录的数据进行预测，并使用光纤光谱仪获取大量标记的强度数据。&lt;h4&gt;主要发现&lt;/h4&gt;预训练的深度神经网络实现了快速、可靠且简单的激光系统温度推断，且不需要额外的光学诊断或温度传感器。&lt;h4&gt;结论&lt;/h4&gt;通过微型移动光谱仪和远程检测能力，温度推断能力可以通过迁移学习方法适用于各种激光二极管，同时在不同应用场景下通过减少网络深度来节省计算成本。&lt;h4&gt;总结&lt;/h4&gt;该方法达到了亚百分比精度的温度推断，同时在准确性与计算成本之间取得了平衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A machine-learning non-contact method to determine the temperature of a lasergain medium via its laser emission with a trained few-layer neural net model ispresented. The training of the feed-forward Neural Network (NN) enables theprediction of the device's properties solely from spectral data, here recordedby visible-/nearinfrared-light compact micro-spectrometers for both a diodepump laser and optically-pumped gain membrane of a semiconductor disk laser.Fiber spectrometers are used for the acquisition of large quantities oflabelled intensity data, which can afterwards be used for the predictionprocess. Such pretrained deep NNs enable a fast, reliable and easy way to inferthe temperature of a laser system such as our Membrane External Cavity Laser,at a later monitoring stage without the need of additional optical diagnosticsor read-out temperature sensors. With the miniature mobile spectrometer and theremote detection ability, the temperature inference capability can be adaptedfor various laser diodes using transfer learning methods with pretrainedmodels. Here, mean-square-error values for the temperature inferencecorresponding to sub-percent accuracy of our sensor scheme are reached, whilecomputational cost can be saved by reducing the network depth at the heredisplayed cost of accuracy, as appropriate for different application scenarios.</description>
      <author>example@mail.com (Jakob Mannstadt, Arash Rahimi-Iman)</author>
      <guid isPermaLink="false">2410.22528v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning and Adversarial Disentanglement for Privacy-Preserving Task-Oriented Semantic Communications</title>
      <link>http://arxiv.org/abs/2410.22784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to EEE Journal on Selected Areas in Communications (JSAC):
  Intelligent Communications for Real-Time Computer Vision (Comm4CV)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;任务导向的语义通信系统在高效智能数据传输方面表现出色，但现有方法难以完全区分任务相关和无关的信息，导致隐私问题和性能不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种信息瓶颈方法CLAD，以提高任务相关信息的传输效率。&lt;h4&gt;方法&lt;/h4&gt;CLAD结合对比学习来捕捉任务相关特征，并采用对抗解耦来丢弃任务无关信息。同时，引入信息保留指数（IRI）来评估编码特征的最小性和信息量。&lt;h4&gt;主要发现&lt;/h4&gt;CLAD在任务表现、隐私保护和IRI方面优于现有最先进的方法，预测性能提高约2.5-3%，IRI减少77-90%，对抗准确率降低57-76%。&lt;h4&gt;结论&lt;/h4&gt;CLAD有效提升了任务导向语义通信系统的性能，同时增强了隐私保护。&lt;h4&gt;总结&lt;/h4&gt;CLAD方法通过有效解耦和对比学习，在任务相关信息传输中取得了显著进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/omarerak/clad&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Task-oriented semantic communication systems have emerged as a promisingapproach to achieving efficient and intelligent data transmission, where onlyinformation relevant to a specific task is communicated. However, existingmethods struggle to fully disentangle task-relevant and task-irrelevantinformation, leading to privacy concerns and subpar performance. To addressthis, we propose an information-bottleneck method, named CLAD (contrastivelearning and adversarial disentanglement). CLAD leverages contrastive learningto effectively capture task-relevant features while employing adversarialdisentanglement to discard task-irrelevant information. Additionally, due tothe lack of reliable and reproducible methods to gain insight into theinformativeness and minimality of the encoded feature vectors, we introduce anew technique to compute the information retention index (IRI), a comparativemetric used as a proxy for the mutual information between the encoded featuresand the input, reflecting the minimality of the encoded features. The IRIquantifies the minimality and informativeness of the encoded feature vectorsacross different task-oriented communication techniques. Our extensiveexperiments demonstrate that CLAD outperforms state-of-the-art baselines interms of task performance, privacy preservation, and IRI. CLAD achieves apredictive performance improvement of around 2.5-3%, along with a 77-90%reduction in IRI and a 57-76% decrease in adversarial accuracy.</description>
      <author>example@mail.com (Omar Erak, Omar Alhussein, Wen Tong)</author>
      <guid isPermaLink="false">2410.22784v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning Approaches for Improving Detection of Unseen Speech Deepfakes</title>
      <link>http://arxiv.org/abs/2410.20578v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, accepted to the IEEE Spoken Language Technology Workshop
  (SLT) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的语音深伪检测方法对已知攻击表现良好，但对未见攻击的泛化仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发能够对未见攻击进行泛化的系统，以应对社交媒体上语音深伪的日益增长。&lt;h4&gt;方法&lt;/h4&gt;采用元学习的视角，旨在学习攻击不变特征，以适应仅有少量样本的未见攻击。&lt;h4&gt;主要发现&lt;/h4&gt;在InTheWild数据集上，使用仅96个未见样本，EER从21.67%改善至10.42%。&lt;h4&gt;结论&lt;/h4&gt;持续的少量样本适应确保系统保持最新状态。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了元学习在语音深伪检测中的应用潜力，尤其是在面对未见攻击时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current speech deepfake detection approaches perform satisfactorily againstknown adversaries; however, generalization to unseen attacks remains an openchallenge. The proliferation of speech deepfakes on social media underscoresthe need for systems that can generalize to unseen attacks not observed duringtraining. We address this problem from the perspective of meta-learning, aimingto learn attack-invariant features to adapt to unseen attacks with very fewsamples available. This approach is promising since generating of a high-scaletraining dataset is often expensive or infeasible. Our experiments demonstratedan improvement in the Equal Error Rate (EER) from 21.67% to 10.42% on theInTheWild dataset, using just 96 samples from the unseen dataset. Continuousfew-shot adaptation ensures that the system remains up-to-date.</description>
      <author>example@mail.com (Ivan Kukanov, Janne Laakkonen, Tomi Kinnunen, Ville Hautamäki)</author>
      <guid isPermaLink="false">2410.20578v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Age of Information-Oriented Probabilistic Link Scheduling for Device-to-Device Networks</title>
      <link>http://arxiv.org/abs/2410.20196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures, accepted by IEEE WiOpt24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;论文关注于通过年龄感知的链路调度优化设备间（D2D）网络中的信息长期平均年龄（AoI）。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来应对所有D2D链路的AoI动态交织问题，寻找最佳调度策略。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于年龄感知的静态随机策略，通过链路的AoI和信道状态信息计算每个时间槽的调度概率，并采用Lyapunov优化框架来最小化每个时间槽的Lyapunov漂移。&lt;h4&gt;主要发现&lt;/h4&gt;针对每个时间槽的最小化问题由于链路间干扰是非凸的，使用消息传递神经网络（MPNN）来优化该问题，并展示了该方法的优越性能。&lt;h4&gt;结论&lt;/h4&gt;提出的年龄感知静态随机策略在仿真中表现优于基准方法，验证了该方法的可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本论文通过新颖的策略和优化方法，提升了D2D网络中信息更新的效率，为未来的研究提供了参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper focuses on optimizing the long-term average age of information(AoI) in device-to-device (D2D) networks through age-aware link scheduling. Theproblem is naturally formulated as a Markov decision process (MDP). However,finding the optimal policy for the formulated MDP in its original form ischallenging due to the intertwined AoI dynamics of all D2D links. To addressthis, we propose an age-aware stationary randomized policy that determines theprobability of scheduling each link in each time slot based on the AoI of alllinks and the statistical channel state information among all transceivers. Byemploying the Lyapunov optimization framework, our policy aims to minimize theLyapunov drift in every time slot. Nonetheless, this per-slot minimizationproblem is nonconvex due to cross-link interference in D2D networks, posingsignificant challenges for real-time decision-making. After analyzing thepermutation equivariance property of the optimal solutions to the per-slotproblem, we apply a message passing neural network (MPNN), a type of graphneural network that also exhibits permutation equivariance, to optimize theper-slot problem in an unsupervised learning manner. Simulation resultsdemonstrate the superior performance of the proposed age-aware stationaryrandomized policy over baselines and validate the scalability of our method.</description>
      <author>example@mail.com (Lixin Wang, Qian Wang, He, Chen, Shidong Zhou)</author>
      <guid isPermaLink="false">2410.20196v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Subgraph Aggregation for Out-of-Distribution Generalization on Graphs</title>
      <link>http://arxiv.org/abs/2410.22228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）中的分布外（OOD）泛化受到了广泛关注，因为它在现实世界的基于图的预测中至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决依赖单一因果子图所带来的脆弱性问题，并学习图数据背后的不变模式。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新框架——子图聚合（SuGAr），旨在学习对OOD泛化至关重要的多样化子图。该框架使用定制的子图采样器和多样性正则化器来提取不变子图，并通过平均其表示进行聚合。&lt;h4&gt;主要发现&lt;/h4&gt;SuGAr显著丰富了子图信号，提高了潜在因果结构的覆盖，从而提高了OOD泛化能力。&lt;h4&gt;结论&lt;/h4&gt;在合成和真实数据集上的广泛实验表明，SuGAr在图的OOD泛化上相较于现有最先进的方法提高了最多24%。这是首次通过学习多个不变子图来研究图的OOD泛化。&lt;h4&gt;总结&lt;/h4&gt;SuGAr框架为图神经网络的OOD泛化提供了新的思路，强调了多样化子图的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) generalization in Graph Neural Networks (GNNs) hasgained significant attention due to its critical importance in graph-basedpredictions in real-world scenarios. Existing methods primarily focus onextracting a single causal subgraph from the input graph to achievegeneralizable predictions. However, relying on a single subgraph can lead tosusceptibility to spurious correlations and is insufficient for learninginvariant patterns behind graph data. Moreover, in many real-worldapplications, such as molecular property prediction, multiple criticalsubgraphs may influence the target label property. To address these challenges,we propose a novel framework, SubGraph Aggregation (SuGAr), designed to learn adiverse set of subgraphs that are crucial for OOD generalization on graphs.Specifically, SuGAr employs a tailored subgraph sampler and diversityregularizer to extract a diverse set of invariant subgraphs. These invariantsubgraphs are then aggregated by averaging their representations, whichenriches the subgraph signals and enhances coverage of the underlying causalstructures, thereby improving OOD generalization. Extensive experiments on bothsynthetic and real-world datasets demonstrate that \ours outperformsstate-of-the-art methods, achieving up to a 24% improvement in OODgeneralization on graphs. To the best of our knowledge, this is the first workto study graph OOD generalization by learning multiple invariant subgraphs.</description>
      <author>example@mail.com (Bowen Liu, Haoyang Li, Shuning Wang, Shuo Nie, Shanghang Zhang)</author>
      <guid isPermaLink="false">2410.22228v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2410.22790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;顺序推荐系统(SRS)旨在通过全面建模用户在用户-项目交互序列中的复杂偏好，预测用户可能感兴趣的后续项目。&lt;h4&gt;目的&lt;/h4&gt;提出现有SRS模型忽视高层次偏好及丰富的项目间语义关系的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的层次偏好建模框架，使用双变换器模块和双对比学习方案，强化低层次和高层次偏好的学习，并设计语义增强的上下文嵌入模块以改善推荐性能。&lt;h4&gt;主要发现&lt;/h4&gt;在六个真实数据集上的广泛实验表明，所提出的方法在性能上优于现有的最先进方法，并且设计合理。&lt;h4&gt;结论&lt;/h4&gt;通过综合考虑低层次和高层次偏好动态，显著提高了顺序推荐的准确性。&lt;h4&gt;总结&lt;/h4&gt;该框架有效整合了用户的多维偏好信息，推动了顺序推荐系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential recommender systems (SRSs) aim to predict the subsequent itemswhich may interest users via comprehensively modeling users' complex preferenceembedded in the sequence of user-item interactions. However, most of existingSRSs often model users' single low-level preference based on item IDinformation while ignoring the high-level preference revealed by item attributeinformation, such as item category. Furthermore, they often utilize limitedsequence context information to predict the next item while overlooking richerinter-item semantic relations. To this end, in this paper, we proposed a novelhierarchical preference modeling framework to substantially model the complexlow- and high-level preference dynamics for accurate sequential recommendation.Specifically, in the framework, a novel dual-transformer module and a noveldual contrastive learning scheme have been designed to discriminatively learnusers' low- and high-level preference and to effectively enhance both low- andhigh-level preference learning respectively. In addition, a novelsemantics-enhanced context embedding module has been devised to generate moreinformative context embedding for further improving the recommendationperformance. Extensive experiments on six real-world datasets have demonstratedboth the superiority of our proposed method over the state-of-the-art ones andthe rationality of our design.</description>
      <author>example@mail.com (Chengkai Huang, Shoujin Wang, Xianzhi Wang, Lina Yao)</author>
      <guid isPermaLink="false">2410.22790v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization</title>
      <link>http://arxiv.org/abs/2410.22707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Humanoids2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种重叠区域采样方法，以降低内存使用同时保持准确性。&lt;h4&gt;方法&lt;/h4&gt;通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。&lt;h4&gt;主要发现&lt;/h4&gt;在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。&lt;h4&gt;结论&lt;/h4&gt;对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。&lt;h4&gt;总结&lt;/h4&gt;该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State recognition of the environment and objects, such as the open/closedstate of doors and the on/off of lights, is indispensable for robots thatperform daily life support and security tasks. Until now, state recognitionmethods have been based on training neural networks from manual annotations,preparing special sensors for the recognition, or manually programming toextract features from point clouds or raw images. In contrast, we propose arobotic state recognition method using a pre-trained vision-language model,which is capable of Image-to-Text Retrieval (ITR) tasks. We prepare severalkinds of language prompts in advance, calculate the similarity between theseprompts and the current image by ITR, and perform state recognition. Byapplying the optimal weighting to each prompt using black-box optimization,state recognition can be performed with higher accuracy. Experiments show thatthis theory enables a variety of state recognitions by simply preparingmultiple prompts without retraining neural networks or manual programming. Inaddition, since only prompts and their weights need to be prepared for eachrecognizer, there is no need to prepare multiple models, which facilitatesresource management. It is possible to recognize the open/closed state oftransparent doors, the state of whether water is running or not from a faucet,and even the qualitative state of whether a kitchen is clean or not, which havebeen challenging so far, through language.</description>
      <author>example@mail.com (Kento Kawaharazuka, Yoshiki Obinata, Naoaki Kanazawa, Kei Okada, Masayuki Inaba)</author>
      <guid isPermaLink="false">2410.22707v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PV-VTT: A Privacy-Centric Dataset for Mission-Specific Anomaly Detection and Natural Language Interpretation</title>
      <link>http://arxiv.org/abs/2410.22623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视频犯罪检测是计算机视觉和人工智能的重要应用，但现有数据集主要关注严重犯罪，忽视了可能预防这些犯罪的前兆活动（如隐私侵犯）。&lt;h4&gt;目的&lt;/h4&gt;提出PV-VTT（隐私侵犯视频到文本），一个独特的多模态数据集，旨在识别隐私侵犯行为集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。&lt;h4&gt;主要发现&lt;/h4&gt;在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。&lt;h4&gt;结论&lt;/h4&gt;对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。&lt;h4&gt;总结&lt;/h4&gt;该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video crime detection is a significant application of computer vision andartificial intelligence. However, existing datasets primarily focus ondetecting severe crimes by analyzing entire video clips, often neglecting theprecursor activities (i.e., privacy violations) that could potentially preventthese crimes. To address this limitation, we present PV-VTT (Privacy ViolationVideo To Text), a unique multimodal dataset aimed at identifying privacyviolations. PV-VTT provides detailed annotations for both video and text inscenarios. To ensure the privacy of individuals in the videos, we only providevideo feature vectors, avoiding the release of any raw video data. Thisprivacy-focused approach allows researchers to use the dataset while protectingparticipant confidentiality. Recognizing that privacy violations are oftenambiguous and context-dependent, we propose a Graph Neural Network (GNN)-basedvideo description model. Our model generates a GNN-based prompt with image forLarge Language Model (LLM), which deliver cost-effective and high-quality videodescriptions. By leveraging a single video frame along with relevant text, ourmethod reduces the number of input tokens required, maintaining descriptivequality while optimizing LLM API-usage. Extensive experiments validate theeffectiveness and interpretability of our approach in video description tasksand flexibility of our PV-VTT dataset.</description>
      <author>example@mail.com (Ryozo Masukawa, Sanggeon Yun, Yoshiki Yamaguchi, Mohsen Imani)</author>
      <guid isPermaLink="false">2410.22623v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments</title>
      <link>http://arxiv.org/abs/2410.21340v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模模型（如大语言模型和复杂图像生成系统）的部署需要大量计算资源，导致高成本。&lt;h4&gt;目的&lt;/h4&gt;降低成本，解决可扩展性和数据安全性相关的挑战，推动向去中心化系统的转变。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于元学习的框架，自动选择去中心化系统中的最佳加速方法，通过历史性能数据学习不同任务上各种加速技术的表现。&lt;h4&gt;主要发现&lt;/h4&gt;该元学习框架系统地识别每个任务的最佳加速策略，显著提高了决策效率和系统性能，超越了传统方法。&lt;h4&gt;结论&lt;/h4&gt;元学习有潜力革命性地改变去中心化人工智能系统中的推理加速，提供更加民主和经济可行的人工智能解决方案。&lt;h4&gt;总结&lt;/h4&gt;通过自动化选择最佳加速方法，本文为去中心化AI系统的推理效率提升提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The deployment of large-scale models, such as large language models (LLMs)and sophisticated image generation systems, incurs substantial costs due totheir computational demands. To mitigate these costs and address challengesrelated to scalability and data security, there is a growing shift towardsdecentralized systems for deploying such models. In these decentralizedenvironments, efficient inference acceleration becomes crucial to managecomputational resources effectively and enhance system responsiveness. In thiswork, we address the challenge of selecting optimal acceleration methods indecentralized systems by introducing a meta-learning-based framework. Thisframework automates the selection process by learning from historicalperformance data of various acceleration techniques across different tasks.Unlike traditional methods that rely on random selection or expert intuition,our approach systematically identifies the best acceleration strategies basedon the specific characteristics of each task. We demonstrate that ourmeta-learning framework not only streamlines the decision-making process butalso consistently outperforms conventional methods in terms of efficiency andperformance. Our results highlight the potential of meta-learning torevolutionize inference acceleration in decentralized AI systems, offering apath towards more democratic and economically feasible artificial intelligencesolutions.</description>
      <author>example@mail.com (Yuzhe Yang, Yipeng Du, Ahmad Farhan, Claudio Angione, Yue Zhao, Harry Yang, Fielding Johnston, James Buban, Patrick Colangelo)</author>
      <guid isPermaLink="false">2410.21340v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Feature Selection Algorithm Based on Dual Manifold Re-ranking</title>
      <link>http://arxiv.org/abs/2410.20388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  in Chinese language&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。```json
{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。"
```json
{
    "背景": "高维数据在许多数据分析任务中常见，特征选择技术旨在从原始高维数据中识别最具代表性的特征。",
    "目的": "提出一种基于双流形重排序（DMRR）的无监督特征选择算法，以解决无。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。"
}
征之间的流形结构，通过变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。"
}
进行流形重排序。",
    "主要发现": "DMRR与三种原始无监督特征选择算法和两种无监督特征选择后处理算法的比较实验结果表明，样本的重要性信息及样本与特征之间的双重关系对更好的特征选择有益。",
    "结论": "考虑样本的重要性和样本与特征之间的相互关系可以显著改善无监督特征选择的效果。",
    "总结": "DMRR算法有效捕捉了数据的内部结构，提供了改进无监督特征选择的新方法。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.11896/jsjkx.221000143&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-dimensional data is commonly encountered in numerous data analysistasks. Feature selection techniques aim to identify the most representativefeatures from the original high-dimensional data. Due to the absence of classlabel information, it is significantly more challenging to select appropriatefeatures in unsupervised learning scenarios compared to supervised ones.Traditional unsupervised feature selection methods typically score the featuresof samples based on certain criteria, treating samples indiscriminately.However, these approaches fail to fully capture the internal structure of thedata. The importance of different samples should vary, and there is a dualrelationship between the weight of samples and features that will influenceeach other. Therefore, an unsupervised feature selection algorithm based ondual manifold re-ranking (DMRR) is proposed in this paper. Different similaritymatrices are constructed to depict the manifold structures among samples,between samples and features, and among features themselves. Then, manifoldre-ranking is performed by combining the initial scores of samples andfeatures. By comparing DMRR with three original unsupervised feature selectionalgorithms and two unsupervised feature selection post-processing algorithms,experimental results confirm that the importance information of differentsamples and the dual relationship between sample and feature are beneficial forachieving better feature selection.</description>
      <author>example@mail.com (Yunhui Liang, Jianwen Gan, Yan Chen, Peng Zhou, Liang Du)</author>
      <guid isPermaLink="false">2410.20388v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities</title>
      <link>http://arxiv.org/abs/2410.23160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "近年来，针对多领域时间序列预测的基础模型开发受到广泛关注。",
    "目的": "提出FlexTSF，一个通用的时间序列预测模型，以处理区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时    "方法": "FlexTSF以自回归方式生成预测，包含三种新设计：VT-Norm用于消除数据领域障碍，IVP Patcher用于学习灵活结构的时间序列表示，LED attention用于整合这两者并在预测中考虑领域和时间信息。",
    "主要发现": "在12个数据集上的实验表明，FlexTSF在常规和不规则时间序列预测上均优于现有最先进模型。",
    "结论": "经过自监督预训练后，FlexTSF在零样本和少样本设置下均展现出卓越的时间序列预测性能。",
方法能够在资源受限的环境中高效进行大规模点云配准，同时保持TSF模型有效应对了时间序列数据中的缺失值、不数据中的缺失值、不等序列长度和不规则时间间隔等问题，具有更好的泛化能力。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing a foundation model for time series forecasting across diversedomains has attracted significant attention in recent years. Existing workstypically assume regularly sampled, well-structured data, limiting theirapplicability to more generalized scenarios where time series often containmissing values, unequal sequence lengths, and irregular time intervals betweenmeasurements. To cover diverse domains and handle variable regularities, wepropose FlexTSF, a universal time series forecasting model that possessesbetter generalization and natively support both regular and irregular timeseries. FlexTSF produces forecasts in an autoregressive manner and incorporatesthree novel designs: VT-Norm, a normalization strategy to ablate data domainbarriers, IVP Patcher, a patching module to learn representations from flexiblystructured time series, and LED attention, an attention mechanism to seamlesslyintegrate these two and propagate forecasts with awareness of domain and timeinformation. Experiments on 12 datasets show that FlexTSF outperformsstate-of-the-art forecasting models respectively designed for regular andirregular time series. Furthermore, after self-supervised pre-training, FlexTSFshows exceptional performance in both zero-shot and few-show settings for timeseries forecasting.</description>
      <author>example@mail.com (Jingge Xiao, Yile Chen, Gao Cong, Wolfgang Nejdl, Simon Gottschalk)</author>
      <guid isPermaLink="false">2410.23160v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MassiveGNN: Efficient Training via Prefetching for Massively Connected Distributed Graphs</title>
      <link>http://arxiv.org/abs/2410.22697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proc. of the IEEE International Conference on Cluster Computing
  (CLUSTER), 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在图结构数据学习中不可或缺，但在大规模连接图上，其计算成本不断上升，导致执行性能面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;解决在大规模图上执行GNN时的计算成本和性能问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于参数化的连续预取和驱逐方案，结合最新的Amazon DistDGL分布式GNN框架，以改善分布式图上的采样和通信开销。&lt;h4&gt;主要发现&lt;/h4&gt;在NERSC的Perlmutter超级计算机上，对各种OGB数据集的端到端训练性能提升了约15%到40%。&lt;h4&gt;结论&lt;/h4&gt;通过优化采样和通信策略，能够有效提升分布式GNN的训练性能。&lt;h4&gt;总结&lt;/h4&gt;本文提供了一种有效的解决方案，旨在克服大规模图数据学习中的性能瓶颈。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNN) are indispensable in learning fromgraph-structured data, yet their rising computational costs, especially onmassively connected graphs, pose significant challenges in terms of executionperformance. To tackle this, distributed-memory solutions such as partitioningthe graph to concurrently train multiple replicas of GNNs are in practice.However, approaches requiring a partitioned graph usually suffer fromcommunication overhead and load imbalance, even under optimal partitioning andcommunication strategies due to irregularities in the neighborhood minibatchsampling.  This paper proposes practical trade-offs for improving the sampling andcommunication overheads for representation learning on distributed graphs(using popular GraphSAGE architecture) by developing a parameterized continuousprefetch and eviction scheme on top of the state-of-the-art Amazon DistDGLdistributed GNN framework, demonstrating about 15-40% improvement in end-to-endtraining performance on the National Energy Research Scientific ComputingCenter's (NERSC) Perlmutter supercomputer for various OGB datasets.</description>
      <author>example@mail.com (Aishwarya Sarkar, Sayan Ghosh, Nathan R. Tallent, Ali Jannesari)</author>
      <guid isPermaLink="false">2410.22697v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Real birational implicitization for statistical models</title>
      <link>http://arxiv.org/abs/2410.23102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法{
    "背景": "研究半代数集在非理想映射下的隐式描述，前提是映射的分母在集合上为正。",
    "目的": "为全球理性可识别的统计模型提供模型定义约束，以促进模型成员测试、表示学习和模型等价性性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够    "方法": "通过推导隐式方程，展示其在样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在其他相关框架中的适用性。",
    "主要发现": "隐式方程恢复了经典图模型的马尔可夫性质以及如Verma约束等其他知名方程，并扩展到彩色或干预图模型、分阶段树和Lyapunov模型等一般化框架。",
    "结论": "在进一步的温和假设下，隐式方程生成模型的消失理想，推广了Geiger等人的先前结果。",
    "总结": "本研究为统计模型的理论提供了重要的约束和工具，促进了模型的理解与应用。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We derive an implicit description of the image of a semialgebraic set under abirational map, provided that the denominators of the map are positive on theset. For statistical models which are globally rationally identifiable, thisyields model-defining constraints which facilitate model membership testing,representation learning, and model equivalence tests. Many examples illustratethe applicability of our results. The implicit equations recover well-knownMarkov properties of classical graphical models, as well as other well-studiedequations such as the Verma constraint. They also provide Markov properties forgeneralizations of these frameworks, such as colored or interventionalgraphical models, staged trees, and the recently introduced Lyapunov models.Under a further mild assumption, we show that our implicit equations generatethe vanishing ideal of the model up to a saturation, generalizing previousresults of Geiger, Meek and Sturmfels, Duarte and G\"orgen, Sullivant, andothers.</description>
      <author>example@mail.com (Tobias Boege, Liam Solus)</author>
      <guid isPermaLink="false">2410.23102v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling and Zero-Shot Transfer</title>
      <link>http://arxiv.org/abs/2410.21683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures, supporting information appended&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "构建可转移的描述符用于分子和生物系统的构象表示，在药物发现、基于学习的分子动力学和蛋白质机制分析中有广泛应用。",
    "目的": "探索域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出几何图神经网络（Geom-GNNs）作为可转移和高效的几何描述符，以改善域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLo    "方法": "研究Geom-GNNs在自监督预训练、监督和无监督学习设置下的表现能力，分析不同架构的可表达能力以及其在预训练任务上的缩放行为。",
    "主要发现": "Geom-GNNs在预训练任务上不遵循幂律缩放，且在重要的量子化学标签监督任务上缺乏可预测的缩放行为。不同架构在预训练任务上的表现能力存在差异。",
    "结论": "全原子图嵌入可以与其他神经网络架构有机结合，以增强表达能力，同时低维潜在空间的投影与传统几何描述符有良好的一致性。",
    "总结": "研究显示预训练的Geom-GNNs在提高分子建模泛化能力方面具有潜力，且与其他模型结合能够提升其表现。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Constructing transferable descriptors for conformation representation ofmolecular and biological systems finds numerous applications in drug discovery,learning-based molecular dynamics, and protein mechanism analysis. Geometricgraph neural networks (Geom-GNNs) with all-atom information have transformedatomistic simulations by serving as a general learnable geometric descriptorsfor downstream tasks including prediction of interatomic potential andmolecular properties. However, common practices involve supervising Geom-GNNson specific downstream tasks, which suffer from the lack of high-quality dataand inaccurate labels leading to poor generalization and performancedegradation on out-of-distribution (OOD) scenarios. In this work, we exploredthe possibility of using pre-trained Geom-GNNs as transferable and highlyeffective geometric descriptors for improved generalization. To explore theirrepresentation power, we studied the scaling behaviors of Geom-GNNs underself-supervised pre-training, supervised and unsupervised learning setups. Wefind that the expressive power of different architectures can differ on thepre-training task. Interestingly, Geom-GNNs do not follow the power-law scalingon the pre-training task, and universally lack predictable scaling behavior onthe supervised tasks with quantum chemical labels important for screening anddesign of novel molecules. More importantly, we demonstrate how all-atom graphembedding can be organically combined with other neural architectures toenhance the expressive power. Meanwhile, the low-dimensional projection of thelatent space shows excellent agreement with conventional geometricaldescriptors.</description>
      <author>example@mail.com (Zihan Pengmei, Zhengyuan Shen, Zichen Wang, Marcus Collins, Huzefa Rangwala)</author>
      <guid isPermaLink="false">2410.21683v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning-Driven Microstructure Characterization and Vickers Hardness Prediction of Mg-Gd Alloys</title>
      <link>http://arxiv.org/abs/2410.20402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内```json
{
    "背景": "材料科学领域长期以来关注成分、微观结构与性能之间的关系。",
    "目的": "分析和预测Gd含量、树枝状结构及二次相对固溶Mg-Gd合金机械性能的影响。",
    "方法": "提出基于图像处理和深度学习技术的多模态融合学习框架，结合元素成分和微观结构特征，准确预测Vickers硬度。",
    "主要发现": "Transformer模型在预测准确性方面表现最佳，R²值达到0.9；SHAP分析识别出四个影响Vickers硬度的关键特征值。",
    "结论": "这些发现 "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用金性能的理解，还为未来材料设计和优化提供了理论支持。",
    "总结": "本研究为Mg-Gd合金的性能预测提供了新的方法和思路，"本研究为Mg-Gd合金的性能预测提供了新的方法和思路，促进了材料科学的发展。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of materials science, exploring the relationship betweencomposition, microstructure, and properties has long been a critical researchfocus. The mechanical performance of solid-solution Mg-Gd alloys issignificantly influenced by Gd content, dendritic structures, and the presenceof secondary phases. To better analyze and predict the impact of these factors,this study proposes a multimodal fusion learning framework based on imageprocessing and deep learning techniques. This framework integrates bothelemental composition and microstructural features to accurately predict theVickers hardness of solid-solution Mg-Gd alloys. Initially, deep learningmethods were employed to extract microstructural information from a variety ofsolid-solution Mg-Gd alloy images obtained from literature and experiments.This provided precise grain size and secondary phase microstructural featuresfor performance prediction tasks. Subsequently, these quantitative analysisresults were combined with Gd content information to construct a performanceprediction dataset. Finally, a regression model based on the Transformerarchitecture was used to predict the Vickers hardness of Mg-Gd alloys. Theexperimental results indicate that the Transformer model performs best in termsof prediction accuracy, achieving an R^2 value of 0.9. Additionally, SHAPanalysis identified critical values for four key features affecting the Vickershardness of Mg-Gd alloys, providing valuable guidance for alloy design. Thesefindings not only enhance the understanding of alloy performance but also offertheoretical support for future material design and optimization.</description>
      <author>example@mail.com (Lu Wang, Hongchan Chen, Bing Wang, Qian Li, Qun Luo, Yuexing Han)</author>
      <guid isPermaLink="false">2410.20402v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors</title>
      <link>http://arxiv.org/abs/2410.19590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Transformer的单目3D物体检测方法MonoDGP，以解决现有方法中深度误差对边界框高度表示的影响。&lt;h4&gt;方法&lt;/h4&gt;采用透视不变几何误差来修改投影公式，讨论几何误差的机制和效果，同时解耦深度引导解码器，并构建仅依赖视觉特征的估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。&lt;h4&gt;主要发现&lt;/h4&gt;MonoDGP通过引入区域分割头（RSH），生成增强特征和分割嵌入，优化和微调Transformer解码器的输入令牌。&lt;h4&gt;结论&lt;/h4&gt;在不增加额外数据的情况下，MonoDGP在KITTI基准测试上表现出最先进的性能。&lt;h4&gt;代码链接&lt;/h4&gt;https://github.com/PuFanqi23/MonoDGP&lt;h4&gt;总结&lt;/h4&gt;MonoDGP提供了一种简单有效的替代多深度预测的方法，在单目3D物体检测中展示了优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perspective projection has been extensively utilized in monocular 3D objectdetection methods. It introduces geometric priors from 2D bounding boxes and 3Dobject dimensions to reduce the uncertainty of depth estimation. However, dueto depth errors originating from the object's visual surface, the height of thebounding box often fails to represent the actual projected central height,which undermines the effectiveness of geometric depth. Direct prediction forthe projected height unavoidably results in a loss of 2D priors, whilemulti-depth prediction with complex branches does not fully leverage geometricdepth. This paper presents a Transformer-based monocular 3D object detectionmethod called MonoDGP, which adopts perspective-invariant geometry errors tomodify the projection formula. We also try to systematically discuss andexplain the mechanisms and efficacy behind geometry errors, which serve as asimple but effective alternative to multi-depth prediction. Additionally,MonoDGP decouples the depth-guided decoder and constructs a 2D decoder onlydependent on visual features, providing 2D priors and initializing objectqueries without the disturbance of 3D detection. To further optimize andfine-tune input tokens of the transformer decoder, we also introduce a RegionSegment Head (RSH) that generates enhanced features and segment embeddings. Ourmonocular method demonstrates state-of-the-art performance on the KITTIbenchmark without extra data. Code is available athttps://github.com/PuFanqi23/MonoDGP.</description>
      <author>example@mail.com (Fanqi Pu, Yifan Wang, Jiru Deng, Wenming Yang)</author>
      <guid isPermaLink="false">2410.19590v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Efficient End-to-End 6-Dof Grasp Detection Framework for Edge Devices with Hierarchical Heatmaps and Feature Propagation</title>
      <link>http://arxiv.org/abs/2410.22980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平```json
{
    "背景": "6-DoF抓取检测对智能嵌入式系统的发展至关重要，因为它为物体抓取提供可行的机器人姿态。",
    "目的": "提出一种高效的6-DoF抓取检测网络，以便在复杂环境中实现抓取。",
    "方法": "采用层次热图表示的域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下网络（E3GNet），从RGBD或点云数据中提取3D几何特征。",
    "主要发现": "E3GNet能够在杂乱的真实环境中有效识别高质量和多样化的抓取方式，且在模型推理效率上超过了以往的方法。",
    "结论": "通过我们的端到端方法和高效网络设计，E3GNet实现了在边缘设备上的实时6-DoF抓取检测，并在真实世界实验中达到了94%的物体抓取成功率。",
    "总结": "E3GNet为移动机器人平台上的6-DoF抓取检测提供了一种高效且有效的解决方案。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 6-DoF grasp detection is critically important for the advancement ofintelligent embodied systems, as it provides feasible robot poses for objectgrasping. Various methods have been proposed to detect 6-DoF grasps through theextraction of 3D geometric features from RGBD or point cloud data. However,most of these approaches encounter challenges during real robot deployment dueto their significant computational demands, which can be particularlyproblematic for mobile robot platforms, especially those reliant on edgecomputing devices. This paper presents an Efficient End-to-End Grasp DetectionNetwork (E3GNet) for 6-DoF grasp detection utilizing hierarchical heatmaprepresentations. E3GNet effectively identifies high-quality and diverse graspsin cluttered real-world environments. Benefiting from our end-to-endmethodology and efficient network design, our approach surpasses previousmethods in model inference efficiency and achieves real-time 6-Dof graspdetection on edge devices. Furthermore, real-world experiments validate theeffectiveness of our method, achieving a satisfactory 94% object graspingsuccess rate.</description>
      <author>example@mail.com (Kaiqin Yang. Yixiang Dai, Guijin Wang, Siang Chen)</author>
      <guid isPermaLink="false">2410.22980v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Dual-Optimized Adaptive Graph Reconstruction for Multi-View Graph Clustering</title>
      <link>http://arxiv.org/abs/2410.22983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM MM 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上```json
{
    "背景": "多视角聚类是针对多媒体数据的重要机器学习任务，涉及图像、视频和文本等多个领域。随着图数据的日益丰富，多视角    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优MVGC）的重要性愈加明显。",
    "目的": "提出一种新的多视角图聚类方法，旨在解决异质图问题，同时保留传统图神经网络（GNN）的优点。",
    "方法": "提出了基于双重优化自适应图重构的多视
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他方法DOAGC，首先开发了一种考虑节点关联和原始结构信息的自适应图重构机制，并设计了双重优化策略。",
,
    "主要发现": "通过大量实验，DOAG   "主要发现": "通过大量实验，DOAGC有效缓解了异质图问题，展示了优化策略的可行性。",
    "结论": "DOAGC在保持传统GNN简洁性、可解释性和效率的同时，成功应对了异质图的挑战。",
    "总结": "本研究提出的DOAGC方法为处理异质图提供了新的思路，并在实验中验证了  "主要发现": "通过大量实验，DOAGC有效缓解了异质图问题，展示了优化策略的可行性。",
    "结论": "DOAGC在保持传统GNN简洁性、可解释性和效率的同时，成功应对了异质图的挑战。",
    "总结": "本研究提出的DOAGC方法为处理异质图提供了新的思路，并在实验中验证了其有效性。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3664647.3680677&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view clustering is an important machine learning task for multi-mediadata, encompassing various domains such as images, videos, and texts. Moreover,with the growing abundance of graph data, the significance of multi-view graphclustering (MVGC) has become evident. Most existing methods focus on graphneural networks (GNNs) to extract information from both graph structure andfeature data to learn distinguishable node representations. However,traditional GNNs are designed with the assumption of homophilous graphs, makingthem unsuitable for widely prevalent heterophilous graphs. Several techniqueshave been introduced to enhance GNNs for heterophilous graphs. While thesemethods partially mitigate the heterophilous graph issue, they often neglectthe advantages of traditional GNNs, such as their simplicity, interpretability,and efficiency. In this paper, we propose a novel multi-view graph clusteringmethod based on dual-optimized adaptive graph reconstruction, named DOAGC. Itmainly aims to reconstruct the graph structure adapted to traditional GNNs todeal with heterophilous graph issues while maintaining the advantages oftraditional GNNs. Specifically, we first develop an adaptive graphreconstruction mechanism that accounts for node correlation and originalstructural information. To further optimize the reconstruction graph, we designa dual optimization strategy and demonstrate the feasibility of ouroptimization strategy through mutual information theory. Numerous experimentsdemonstrate that DOAGC effectively mitigates the heterophilous graph problem.</description>
      <author>example@mail.com (Zichen Wen, Tianyi Wu, Yazhou Ren, Yawen Ling, Chenhang Cui, Xiaorong Pu, Lifang He)</author>
      <guid isPermaLink="false">2410.22983v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Self-Driving Car Racing: Application of Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2410.22766v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch```json
{
    "背景": "本研究探讨深度强化学习在自主驾驶赛车领域的应用，受到AI驱动的移动性和自主赛车赛事的推动。",
    "目的": "开发一个能够在OpenAI Gymnasium CarRacing环境中高效驾驶模拟汽车的AI代理。",
    "方法": "研究多k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集DQN）、近端策略优化（PPO），以及结合迁移学习和递归神经网络（RNN）的新适应算法。",
    "主要发现": "DQN为策略学习提供了强有力的基线，而集成ResNet和LSTM模型显著提升了代理捕捉复杂空间和时间动态的能力。PPO在连续行动空间中表现出色，但仍面临策略崩溃等挑战。",
    "结论": "比较了不同方法的性能，并提出未来研究方向，集中于提高计算效率和 "DQN为策略学习提供了强有力的基线，而集成ResNet和LSTM模型显著提升了代理捕捉复杂空间和时间动态的能力。PPO在连续行动空间中表现出色，但仍面临策略崩溃等挑战。",
    "结论": "比较了不同方法的性能，并提出未来研究方向，集中于提高计算效率和解决模型稳定性问题。研究成果对自主驾驶和相关控制任务的AI系统发展作出贡献。",
    "总结": "本论文为深度强化学习在自主驾驶领域的应用提供"DQN为策略学习提供了强有力的基线，而集成ResNet和LSTM模型显著提升了代理捕捉复杂空间和时间动态的能力。PPO在连续行动空间中表现出色，但仍面临策略崩溃等挑战。",
    "结论": "比较了不同方法的性能，并提出未来研究方向，集中于提高计算效率和解决模型稳定性问题。研究成果对自主驾驶和相关控制任务的AI系统发展作出贡献。",
    "总结": "本论文为深度强化学习在自主驾驶领域的应用提供了新的见解和研究方向。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the application of deep reinforcement learning (RL)techniques in the domain of autonomous self-driving car racing. Motivated bythe rise of AI-driven mobility and autonomous racing events, the project aimsto develop an AI agent that efficiently drives a simulated car in the OpenAIGymnasium CarRacing environment. We investigate various RL algorithms,including Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and noveladaptations that incorporate transfer learning and recurrent neural networks(RNNs) for enhanced performance. The project demonstrates that while DQNprovides a strong baseline for policy learning, integrating ResNet and LSTMmodels significantly improves the agent's ability to capture complex spatialand temporal dynamics. PPO, particularly in continuous action spaces, showspromising results for fine control, although challenges such as policy collapseremain. We compare the performance of these approaches and outline futureresearch directions focused on improving computational efficiency andaddressing model stability. Our findings contribute to the ongoing developmentof AI systems in autonomous driving and related control tasks.</description>
      <author>example@mail.com (Florentiana Yuwono, Gan Pang Yen, Jason Christopher)</author>
      <guid isPermaLink="false">2410.22766v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>IndraEye: Infrared Electro-Optical UAV-based Perception Dataset for Robust Downstream Tasks</title>
      <link>http://arxiv.org/abs/2410.20953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。&lt;h4&gt;目的&lt;/h4&gt;提高声音事件检测的性能，尤其是在标注数据不足的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。&lt;h4&gt;主要发现&lt;/h4&gt;在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。&lt;h4&gt;结论&lt;/h4&gt;通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。&lt;h4&gt;总结&lt;/h4&gt;本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) have shown exceptional performance when trainedon well-illuminated images captured by Electro-Optical (EO) cameras, whichprovide rich texture details. However, in critical applications like aerialperception, it is essential for DNNs to maintain consistent reliability acrossall conditions, including low-light scenarios where EO cameras often struggleto capture sufficient detail. Additionally, UAV-based aerial object detectionfaces significant challenges due to scale variability from varying altitudesand slant angles, adding another layer of complexity. Existing methodstypically address only illumination changes or style variations as domainshifts, but in aerial perception, correlation shifts also impact DNNperformance. In this paper, we introduce the IndraEye dataset, a multi-sensor(EO-IR) dataset designed for various tasks. It includes 5,612 images with145,666 instances, encompassing multiple viewing angles, altitudes, sevenbackgrounds, and different times of the day across the Indian subcontinent. Thedataset opens up several research opportunities, such as multimodal learning,domain adaptation for object detection and segmentation, and exploration ofsensor-specific strengths and weaknesses. IndraEye aims to advance the field bysupporting the development of more robust and accurate aerial perceptionsystems, particularly in challenging conditions. IndraEye dataset isbenchmarked with object detection and semantic segmentation tasks. Dataset andsource codes are available at https://bit.ly/indraeye.</description>
      <author>example@mail.com (Manjunath D, Prajwal Gurunath, Sumanth Udupa, Aditya Gandhamal, Shrikar Madhu, Aniruddh Sikdar, Suresh Sundaram)</author>
      <guid isPermaLink="false">2410.20953v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Memory-Efficient Point Cloud Registration via Overlapping Region Sampling</title>
      <link>http://arxiv.org/abs/2410.21753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted for IEEE International Conference on Visual Communications
  and Image Processing 2024 (VCIP2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接 "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在D使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE202用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，的进展OA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音性捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频同时增加频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD使用件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.ELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9D）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结   "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论":",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习: "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法"提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其方法其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注内存据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下保持准确",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
,
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "  "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结    "": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结":":提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法计重叠自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。"
NN)的音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。"
压缩机制，结合多同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。"
}
```感知器(MLP)和变换器器架构。",
。",
    "音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in deep learning have improved 3D point cloud registrationbut increased graphics processing unit (GPU) memory usage, often requiringpreliminary sampling that reduces accuracy. We propose an overlapping regionsampling method to reduce memory usage while maintaining accuracy. Our approachestimates the overlapping region and intensively samples from it, using ak-nearest-neighbor (kNN) based point compression mechanism with multi layerperceptron (MLP) and transformer architectures. Evaluations on 3DMatch and3DLoMatch datasets show our method outperforms other sampling methods inregistration recall, especially at lower GPU memory levels. For 3DMatch, weachieve 94% recall with 33% reduced memory usage, with greater advantages in3DLoMatch. Our method enables efficient large-scale point cloud registration inresource-constrained environments, maintaining high accuracy whilesignificantly reducing memory requirements.</description>
      <author>example@mail.com (Tomoyasu Shimada, Kazuhiko Murasaki, Shogo Sato, Toshihiko Nishimura, Taiga Yoshida, Ryuichi Tanida)</author>
      <guid isPermaLink="false">2410.21753v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>NASM: Neural Anisotropic Surface Meshing</title>
      <link>http://arxiv.org/abs/2410.23109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SIGGRAPH Asia 2024 (Conference Track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获了一种基于学习的新学（FOA）麦克风捕获的性表面网格化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几面网格化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘网格化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征格化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验,
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验": "在Thingi10K数据集上的大量表面模型上进行评估，并在Multi-Garment Network数据集和FAUST人类数据集上进行了广泛的未见3D形状测试。",
    "总结": "新方法在各向异性表面网    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验": "在Thingi10K数据集上的大量表面模型上进行评估，并在Multi-Garment Network数据集和FAUST人类数据集上进行了广泛的未见3D形状测试。",
    "总结": "新方法在各向异性表面网格化领域表现出优越性，具有良好的  "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验": "在Thingi10K数据集上的大量表面模型上进行评估，并在Multi-Garment Network数据集和FAUST人类数据集上进行了广泛的未见3D形状测试。",
    "总结": "新方法在各向异性表面网格化领域表现出优越性，具有良好的可扩展性和对几何特征的保留能力。"
}
```和目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验": "在Thingi10K数据集上的大量表面模型上进行评估，并在Multi-Garment Network数据集和FAUST人类数据集上进行了广泛的未见3D形状测试。",
    "总结": "新方法在各向异性表面网格化领域表现出优越性，具有良好的可扩展性和对几何特征的保留能力。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3680528.3687700&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a new learning-based method, NASM, for anisotropicsurface meshing. Our key idea is to propose a graph neural network to embed aninput mesh into a high-dimensional (high-d) Euclidean embedding space topreserve curvature-based anisotropic metric by using a dot product loss betweenhigh-d edge vectors. This can dramatically reduce the computational time andincrease the scalability. Then, we propose a novel feature-sensitive remeshingon the generated high-d embedding to automatically capture sharp geometricfeatures. We define a high-d normal metric, and then derive an automaticdifferentiation on a high-d centroidal Voronoi tessellation (CVT) optimizationwith the normal metric to simultaneously preserve geometric features andcurvature anisotropy that exhibit in the original 3D shapes. To our knowledge,this is the first time that a deep learning framework and a large dataset areproposed to construct a high-d Euclidean embedding space for 3D anisotropicsurface meshing. Experimental results are evaluated and compared with thestate-of-the-art in anisotropic surface meshing on a large number of surfacemodels from Thingi10K dataset as well as tested on extensive unseen 3D shapesfrom Multi-Garment Network dataset and FAUST human dataset.</description>
      <author>example@mail.com (Hongbo Li, Haikuan Zhu, Sikai Zhong, Ningna Wang, Cheng Lin, Xiaohu Guo, Shiqing Xin, Wenping Wang, Jing Hua, Zichun Zhong)</author>
      <guid isPermaLink="false">2410.23109v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MutaPLM: Protein Language Modeling for Mutation Explanation and Engineering</title>
      <link>http://arxiv.org/abs/2410.22949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 poster&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景```json
{
    "背景": "研究蛋白质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "研究蛋白质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "目的": "提出MutaPLM框架，以更好地解释和导航蛋白质突变。",
    "方法": "MutaPLM引入了蛋白质增量网络，捕获突变的明确表示，并使用链式思维的迁移学习策略，从生物医学文本中提取突变知识。同时构建了首个大规模蛋白质突变数据集MutaDescribe，提供丰富的文本注释。",
    "主要蛋白质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "目的": "提出MutaPLM框架，以更好地解释和导航蛋白质突变。",
    "方法": "MutaPLM引入了蛋白质增量网络，捕获突变的明确表示，并使用链式思维的迁移学习策略，从生物医学文本中提取突变知识。同时构建了首个大规模蛋白质突变数据集MutaDescribe，提供丰富的文本注释。",
    "主要发现": "MutaPLM能够提供易于理解的突变效应解释，并优先考虑具有良好特性的新的突变。",
    "结论": "MutaPLM在突变解释和优先级排序方面表现优异，所有代码、模型和数据已在GitHub上开源。",
    "总结": "MutaPLM为蛋白质突变的研究提供了一种统一的解释框架，增强质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "目的": "提出MutaPLM框架，以更好地解释和导航蛋白质突变。",
    "方法": "MutaPLM引入了蛋白质增量网络，捕获突变的明确表示，并使用链式思维的迁移学习策略，从生物医学文本中提取突变知识。同时构建了首个大规模蛋白质突变数据集MutaDescribe，提供丰富的文本注释。",
    "主要发现": "MutaPLM能够提供易于理解的突变效应解释，并优先考虑具有良好特性的新的突变。",
    "结论": "MutaPLM在突变解释和优先级排序方面表现优异，所有代码、模型和数据已在GitHub上开源。",
    "总结": "MutaPLM为蛋白质突变的研究提供了一种统一的解释框架，增强了蛋白质语言模型在实际应用中的可解释质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "目的": "提出MutaPLM框架，以更好地解释和导航蛋白质突变。",
    "方法": "MutaPLM引入了蛋白质增量网络，捕获突变的明确表示，并使用链式思维的迁移学习策略，从生物医学文本中提取突变知识。同时构建了首个大规模蛋白质突变数据集MutaDescribe，提供丰富的文本注释。",
    "主要发现": "MutaPLM能够提供易于理解的突变效应解释，并优先考虑具有良好特性的新的突变。",
    "结论": "MutaPLM在突变解释和优先级排序方面表现优异，所有代码、模型和数据已在GitHub上开源。",
    "总结": "MutaPLM为蛋白质突变的研究提供了一种统一的解释框架，增强了蛋白质语言模型在实际应用中的可解释性和工程化能力。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Studying protein mutations within amino acid sequences holds tremendoussignificance in life sciences. Protein language models (PLMs) have demonstratedstrong capabilities in broad biological applications. However, due toarchitectural design and lack of supervision, PLMs model mutations implicitlywith evolutionary plausibility, which is not satisfactory to serve asexplainable and engineerable tools in real-world studies. To address theseissues, we present MutaPLM, a unified framework for interpreting and navigatingprotein mutations with protein language models. MutaPLM introduces a proteindelta network that captures explicit protein mutation representations within aunified feature space, and a transfer learning pipeline with a chain-of-thought(CoT) strategy to harvest protein mutation knowledge from biomedical texts. Wealso construct MutaDescribe, the first large-scale protein mutation datasetwith rich textual annotations, which provides cross-modal supervision signals.Through comprehensive experiments, we demonstrate that MutaPLM excels atproviding human-understandable explanations for mutational effects andprioritizing novel mutations with desirable properties. Our code, model, anddata are open-sourced at https://github.com/PharMolix/MutaPLM.</description>
      <author>example@mail.com (Yizhen Luo, Zikun Nie, Massimo Hong, Suyuan Zhao, Hao Zhou, Zaiqing Nie)</author>
      <guid isPermaLink="false">2410.22949v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DOA-Aware Audio-Visual Self-Supervised Learning for Sound Event Localization and Detection</title>
      <link>http://arxiv.org/abs/2410.22803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to APSIPA2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云分割是3D理解中的一个重要主题，传统上使用CNN或Transformer进行处理。&lt;h4&gt;目的&lt;/h4&gt;解决Mamba在点云分割中未能超越最佳CNN和Transformer方法的性能问题。&lt;h4&gt;方法&lt;/h4&gt;识别有效和高效的点云分割架构的关键组成部分，并增强标准Mamba以适应点云分割。&lt;h4&gt;主要发现&lt;/h4&gt;{'空间局部性和稳健的上下文理解': '对强性能至关重要。', 'Mamba的线性计算复杂度': '提供了比Transformer更优的数据和推理效率，同时保持强大的上下文理解能力。', 'Mamba的缺点': ['强制因果性不适合处理无依赖的点云。', '单向扫描策略导致方向性偏差，限制了捕捉无序点云的全部上下文能力。']}&lt;h4&gt;改进措施&lt;/h4&gt;去除因果卷积，引入新的双向跨步SSM，以增强模型捕捉空间关系的能力。&lt;h4&gt;结论&lt;/h4&gt;开发了名为MEEPO的新架构，有效整合CNN和Mamba的优势，显著超越之前的最佳方法PTv3，提升了性能和效率。&lt;h4&gt;性能提升&lt;/h4&gt;MEEPO在多个关键基准数据集上比PTv3提高了最多0.8 mIoU，同时速度提高了42.1%，内存效率提高了5.53倍。&lt;h4&gt;总结&lt;/h4&gt;通过综合不同模型的优势，MEEPO在点云分割领域实现了显著的性能突破。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes sound event localization and detection (SELD) forspatial audio recordings captured by firstorder ambisonics (FOA) microphones.In this task, one may train a deep neural network (DNN) using FOA dataannotated with the classes and directions of arrival (DOAs) of sound events.However, the performance of this approach is severely bounded by the amount ofannotated data. To overcome this limitation, we propose a novel method ofpretraining the feature extraction part of the DNN in a self-supervised manner.We use spatial audio-visual recordings abundantly available as virtual realitycontents. Assuming that sound objects are concurrently observed by the FOAmicrophones and the omni-directional camera, we jointly train audio and visualencoders with contrastive learning such that the audio and visual embeddings ofthe same recording and DOA are made close. A key feature of our method is thatthe DOA-wise audio embeddings are jointly extracted from the raw audio data,while the DOA-wise visual embeddings are separately extracted from the localvisual crops centered on the corresponding DOA. This encourages the latentfeatures of the audio encoder to represent both the classes and DOAs of soundevents. The experiment using the DCASE2022 Task 3 dataset of 20 hours showsnon-annotated audio-visual recordings of 100 hours reduced the error score ofSELD from 36.4 pts to 34.9 pts.</description>
      <author>example@mail.com (Yoto Fujita, Yoshiaki Bando, Keisuke Imoto, Masaki Onishi, Kazuyoshi Yoshii)</author>
      <guid isPermaLink="false">2410.22803v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Exploring contextual modeling with linear complexity for point cloud segmentation</title>
      <link>http://arxiv.org/abs/2410.21211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）的强大在于其能够学习高度表达性的表示，适用于广泛的任务，但预训练模型需要多阶段微调才能有效应用于下游任务。&lt;h4&gt;目的&lt;/h4&gt;引入一个带有参数高效微调（PEFT）方案的元学习框架，以解决模型重训练和微调阶段独立性带来的性能问题。&lt;h4&gt;方法&lt;/h4&gt;在中间重训练阶段，使用元学习框架和低秩适应方法对线性模型进行理论分析，以学习易于适应未见任务的模型。&lt;h4&gt;主要发现&lt;/h4&gt;标准重训练在寻找可适应参数集方面存在次优性，而我们的方法能够恢复最佳可适应参数。&lt;h4&gt;结论&lt;/h4&gt;在ConvAI2数据集中对RoBERTa模型进行重训练时，使用提议的元学习方案相较于传统方法观察到显著的性能提升。&lt;h4&gt;总结&lt;/h4&gt;通过元学习框架优化重训练过程，可以提高基础模型的适应性和性能，尤其在低资源下游任务中表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud segmentation is an important topic in 3D understanding that hastraditionally has been tackled using either the CNN or Transformer. Recently,Mamba has emerged as a promising alternative, offering efficient long-rangecontextual modeling capabilities without the quadratic complexity associatedwith Transformer's attention mechanisms. However, despite Mamba's potential,early efforts have all failed to achieve better performance than the bestCNN-based and Transformer-based methods. In this work, we address thischallenge by identifying the key components of an effective and efficient pointcloud segmentation architecture. Specifically, we show that: 1) Spatiallocality and robust contextual understanding are critical for strongperformance, and 2) Mamba features linear computational complexity, offeringsuperior data and inference efficiency compared to Transformers, while stillbeing capable of delivering strong contextual understanding. Additionally, wefurther enhance the standard Mamba specifically for point cloud segmentation byidentifying its two key shortcomings. First, the enforced causality in theoriginal Mamba is unsuitable for processing point clouds that have no suchdependencies. Second, its unidirectional scanning strategy imposes adirectional bias, hampering its ability to capture the full context ofunordered point clouds in a single pass. To address these issues, we carefullyremove the causal convolutions and introduce a novel Strided Bidirectional SSMto enhance the model's capability to capture spatial relationships. Our effortsculminate in the development of a novel architecture named MEEPO, whicheffectively integrates the strengths of CNN and Mamba. MEEPO surpasses theprevious state-of-the-art method, PTv3, by up to +0.8 mIoU on multiple keybenchmark datasets, while being 42.1% faster and 5.53x more memory efficient.</description>
      <author>example@mail.com (Yong Xien Chng, Xuchong Qiu, Yizeng Han, Yifan Pu, Jiewei Cao, Gao Huang)</author>
      <guid isPermaLink="false">2410.21211v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning Adaptable Foundation Models</title>
      <link>http://arxiv.org/abs/2410.22264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）的强大在于其能够学习高度表达性的表示，适用于广泛的任务，但预训练模型需要多阶段微调才能有效应用于下游任务。&lt;h4&gt;目的&lt;/h4&gt;引入一个带有参数高效微调（PEFT）方案的元学习框架，以解决模型重训练和微调阶段独立性带来的性能问题。&lt;h4&gt;方法&lt;/h4&gt;在中间重训练阶段，使用元学习框架和低秩适应方法对线性模型进行理论分析，以学习易于适应未见任务的模型。&lt;h4&gt;主要发现&lt;/h4&gt;标准重训练在寻找可适应参数集方面存在次优性，而我们的方法能够恢复最佳可适应参数。&lt;h4&gt;结论&lt;/h4&gt;在ConvAI2数据集中对RoBERTa模型进行重训练时，使用提议的元学习方案相较于传统方法观察到显著的性能提升。&lt;h4&gt;总结&lt;/h4&gt;通过元学习框架优化重训练过程，可以提高基础模型的适应性和性能，尤其在低资源下游任务中表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The power of foundation models (FMs) lies in their capacity to learn highlyexpressive representations that can be adapted to a broad spectrum of tasks.However, these pretrained models require multiple stages of fine-tuning tobecome effective for downstream applications. Conventionally, the model isfirst retrained on the aggregate of a diverse set of tasks of interest and thenadapted to specific low-resource downstream tasks by utilizing aparameter-efficient fine-tuning (PEFT) scheme. While this two-phase procedureseems reasonable, the independence of the retraining and fine-tuning phasescauses a major issue, as there is no guarantee the retrained model will achievegood performance post-fine-tuning. To explicitly address this issue, weintroduce a meta-learning framework infused with PEFT in this intermediateretraining stage to learn a model that can be easily adapted to unseen tasks.For our theoretical results, we focus on linear models using low-rankadaptations. In this setting, we demonstrate the suboptimality of standardretraining for finding an adaptable set of parameters. Further, we prove thatour method recovers the optimally adaptable parameters. We then apply thesetheoretical insights to retraining the RoBERTa model to predict thecontinuation of conversations between different personas within the ConvAI2dataset. Empirically, we observe significant performance benefits using ourproposed meta-learning scheme during retraining relative to the conventionalapproach.</description>
      <author>example@mail.com (Jacob L. Block, Sundararajan Srinivasan, Liam Collins, Aryan Mokhtari, Sanjay Shakkottai)</author>
      <guid isPermaLink="false">2410.22264v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters</title>
      <link>http://arxiv.org/abs/2410.23168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Transformers已成为基础模型的主要架构，因其在多个领域表现优异，但大规模扩展的成本仍然是一个重要问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的架构，解决模型扩展过程中的高计算成本。&lt;h4&gt;方法&lt;/h4&gt;引入TokenFormer架构，利用注意力机制处理输入token与模型参数之间的交互，增强架构灵活性。&lt;h4&gt;主要发现&lt;/h4&gt;通过将模型参数视为token，替代传统的线性投影，实现逐步高效的扩展，避免从头开始重新训练。&lt;h4&gt;结论&lt;/h4&gt;TokenFormer模型在参数从124M扩展到1.4B时，性能与从头训练的Transformers相当，同时大幅降低了训练成本。&lt;h4&gt;总结&lt;/h4&gt;TokenFormer提供了一种新方法，允许在不重训的情况下高效扩展Transformers，具有良好的性能和较低的计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/haiyang-w/tokenformer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers have become the predominant architecture in foundation modelsdue to their excellent performance across various domains. However, thesubstantial cost of scaling these models remains a significant concern. Thisproblem arises primarily from their dependence on a fixed number of parameterswithin linear projections. When architectural modifications (e.g., channeldimensions) are introduced, the entire model typically requires retraining fromscratch. As model sizes continue growing, this strategy results in increasinglyhigh computational costs and becomes unsustainable. To overcome this problem,we introduce TokenFormer, a natively scalable architecture that leverages theattention mechanism not only for computations among input tokens but also forinteractions between tokens and model parameters, thereby enhancingarchitectural flexibility. By treating model parameters as tokens, we replaceall the linear projections in Transformers with our token-parameter attentionlayer, where input tokens act as queries and model parameters as keys andvalues. This reformulation allows for progressive and efficient scaling withoutnecessitating retraining from scratch. Our model scales from 124M to 1.4Bparameters by incrementally adding new key-value parameter pairs, achievingperformance comparable to Transformers trained from scratch while greatlyreducing training costs. Code and models are available at\url{https://github.com/Haiyang-W/TokenFormer}.</description>
      <author>example@mail.com (Haiyang Wang, Yue Fan, Muhammad Ferjad Naeem, Yongqin Xian, Jan Eric Lenssen, Liwei Wang, Federico Tombari, Bernt Schiele)</author>
      <guid isPermaLink="false">2410.23168v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification</title>
      <link>http://arxiv.org/abs/2410.23066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的极端多标签文本分类（XMTC）模型依赖多标签注意力层来关注输入文本中的关键标记，但获取最佳注意力权重具有挑战性且资源密集。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的迁移学习策略PLANT（预训练和利用的注意力），以优化XMTC解码器的微调。&lt;h4&gt;方法&lt;/h4&gt;PLANT通过利用预训练的学习排名模型作为植入的注意力层，结合互信息增益增强注意力，引入无注意力机制，并实施状态解码器以保持上下文。&lt;h4&gt;主要发现&lt;/h4&gt;PLANT在多个数据集（mimicfull, mimicfifty, mimicfour, eurlex, wikiten）上超越了现有的最先进方法，尤其在小样本场景中表现优异，F1分数在mimicrare和mimicfew上分别提高超过50和36个百分点。&lt;h4&gt;结论&lt;/h4&gt;PLANT在处理稀有代码方面展现出卓越能力，并在小样本场景中以显著更少的数据实现与传统模型相当的精度。&lt;h4&gt;总结&lt;/h4&gt;通过关键技术创新，PLANT不仅提高了模型性能，还在小样本情况下展现出显著的数据效率，综合消融研究验证了这些贡献的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State-of-the-art Extreme Multi-Label Text Classification (XMTC) models relyheavily on multi-label attention layers to focus on key tokens in input text,but obtaining optimal attention weights is challenging and resource-intensive.To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- anovel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpassesexisting state-of-the-art methods across all metrics on mimicfull, mimicfifty,mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shotscenarios, outperforming previous models specifically designed for few-shotscenarios by over 50 percentage points in F1 scores on mimicrare and by over 36percentage points on mimicfew, demonstrating its superior capability inhandling rare codes. PLANT also shows remarkable data efficiency in few-shotscenarios, achieving precision comparable to traditional models withsignificantly less data. These results are achieved through key technicalinnovations: leveraging a pretrained Learning-to-Rank model as the plantedattention layer, integrating mutual-information gain to enhance attention,introducing an inattention mechanism, and implementing a stateful-decoder tomaintain context. Comprehensive ablation studies validate the importance ofthese contributions in realizing the performance gains.</description>
      <author>example@mail.com (Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu)</author>
      <guid isPermaLink="false">2410.23066v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multimodality Helps Few-Shot 3D Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.22489v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;少样本3D点云分割（FS-PCS）旨在以最少的标注支持样本对新类别进行模型泛化。&lt;h4&gt;目的&lt;/h4&gt;解决现有FS-PCS方法主要集中于单模态点云输入，忽视了利用多模态信息的潜在好处。&lt;h4&gt;方法&lt;/h4&gt;提出了一种无成本的多模态FS-PCS设置，使用文本标签和可用的2D图像模态，开发了MultiModal Few-Shot SegNet (MM-FSS)模型。&lt;h4&gt;主要发现&lt;/h4&gt;MM-FSS通过共享骨干网络提取跨模态和单模态视觉特征，采用预训练文本编码器生成文本嵌入。引入多模态关联融合（MCF）模块和多模态语义融合（MSF）模块以优化多模态信息利用，并提出了测试时自适应跨模态校准（TACC）技术来减轻训练偏差。&lt;h4&gt;结论&lt;/h4&gt;在S3DIS和ScanNet数据集上的实验结果显示，该方法显著提高了性能，表明利用常被忽视的自由模态对FS-PCS的益处，为未来研究提供了宝贵的见解。&lt;h4&gt;总结&lt;/h4&gt;代码可在https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot 3D point cloud segmentation (FS-PCS) aims at generalizing models tosegment novel categories with minimal annotated support samples. While existingFS-PCS methods have shown promise, they primarily focus on unimodal point cloudinputs, overlooking the potential benefits of leveraging multimodalinformation. In this paper, we address this gap by introducing a cost-freemultimodal FS-PCS setup, utilizing textual labels and the potentially available2D image modality. Under this easy-to-achieve setup, we present the MultiModalFew-Shot SegNet (MM-FSS), a model effectively harnessing complementaryinformation from multiple modalities. MM-FSS employs a shared backbone with twoheads to extract intermodal and unimodal visual features, and a pretrained textencoder to generate text embeddings. To fully exploit the multimodalinformation, we propose a Multimodal Correlation Fusion (MCF) module togenerate multimodal correlations, and a Multimodal Semantic Fusion (MSF) moduleto refine the correlations using text-aware semantic guidance. Additionally, wepropose a simple yet effective Test-time Adaptive Cross-modal Calibration(TACC) technique to mitigate training bias, further improving generalization.Experimental results on S3DIS and ScanNet datasets demonstrate significantperformance improvements achieved by our method. The efficacy of our approachindicates the benefits of leveraging commonly-ignored free modalities forFS-PCS, providing valuable insights for future research. The code is availableat https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot .</description>
      <author>example@mail.com (Zhaochong An, Guolei Sun, Yun Liu, Runjia Li, Min Wu, Ming-Ming Cheng, Ender Konukoglu, Serge Belongie)</author>
      <guid isPermaLink="false">2410.22489v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Representational learning for an anomalous sound detection system with source separation model</title>
      <link>http://arxiv.org/abs/2410.21797v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  DCASE 2024 workshop published&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;检测机械操作中的异常声音面临显著挑战，主要由于难以概括异常声学模式。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的训练方法，以改善异常声音检测系统的性能。&lt;h4&gt;方法&lt;/h4&gt;基于源分离模型（CMGAN）的方法，旨在从目标和非目标声学信号的混合中分离出非目标机器声音。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在性能上优于传统的自编码器训练方法和专注于隔离目标机器信号的源分离技术。&lt;h4&gt;结论&lt;/h4&gt;随着非目标数据量的增加，该方法展示了增强表征学习的潜力，同时保持目标类数据的恒定数量。&lt;h4&gt;总结&lt;/h4&gt;通过有效利用多样化的机器声音，CMGAN方法可以在样本量有限的情况下训练复杂的神经网络架构，提高异常声音检测的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The detection of anomalous sounds in machinery operation presents asignificant challenge due to the difficulty in generalizing anomalous acousticpatterns. This task is typically approached as an unsupervised learning ornovelty detection problem, given the complexities associated with theacquisition of comprehensive anomalous acoustic data. Conventionalmethodologies for training anomalous sound detection systems primarily employauto-encoder architectures or representational learning with auxiliary tasks.However, both approaches have inherent limitations. Auto-encoder structures areconstrained to utilizing only the target machine's operational sounds, whiletraining with auxiliary tasks, although capable of incorporating diverseacoustic inputs, may yield representations that lack correlation with thecharacteristic acoustic signatures of anomalous conditions. We propose atraining method based on the source separation model (CMGAN) that aims toisolate non-target machine sounds from a mixture of target and non-target classacoustic signals. This approach enables the effective utilization of diversemachine sounds and facilitates the training of complex neural networkarchitectures with limited sample sizes. Our experimental results demonstratethat the proposed method yields better performance compared to bothconventional auto-encoder training approaches and source separation techniquesthat focus on isolating target machine signals. Moreover, our experimentalresults demonstrate that the proposed method exhibits the potential forenhanced representation learning as the quantity of non-target data increases,even while maintaining a constant volume of target class data.</description>
      <author>example@mail.com (Seunghyeon Shin, Seokjin Lee)</author>
      <guid isPermaLink="false">2410.21797v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes</title>
      <link>http://arxiv.org/abs/2410.23126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究现代Hopfield模型和核化Hopfield模型(KHMs)的最佳记忆容量。&lt;h4&gt;目的&lt;/h4&gt;分析KHMs的记忆配置与信息论中的球形码之间的关系。&lt;h4&gt;方法&lt;/h4&gt;将KHMs的记忆问题视为超球面上的点排列问题，通过建立球形码的专门化。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': 'KHMs的最佳容量发生在特征空间允许记忆形成最佳球形码时。', '2': '提出了分析KHMs如何实现最佳记忆容量，并识别相应的必要条件。', '3': '建立了一个匹配文献中已知指数下界的上限容量界限。', '4': '开发了一个子线性时间算法U-Hop+以达到KHMs的最佳容量。', '5': '分析了所需特征维度相对于存储记忆数量的扩展行为。'}&lt;h4&gt;结论&lt;/h4&gt;这些发现改善了KHMs的检索能力和相应变换器的表示学习。&lt;h4&gt;实验结果&lt;/h4&gt;通过详尽的数值结果支持理论发现。&lt;h4&gt;总结&lt;/h4&gt;研究为现代Hopfield模型提供了首个紧凑且最佳的渐近记忆容量分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the optimal memorization capacity of modern Hopfield models andKernelized Hopfield Models (KHMs), a transformer-compatible class of DenseAssociative Memories. We present a tight analysis by establishing a connectionbetween the memory configuration of KHMs and spherical codes from informationtheory. Specifically, we treat the stored memory set as a specialized sphericalcode. This enables us to cast the memorization problem in KHMs into a pointarrangement problem on a hypersphere. We show that the optimal capacity of KHMsoccurs when the feature space allows memories to form an optimal sphericalcode. This unique perspective leads to: (i) An analysis of how KHMs achieveoptimal memory capacity, and identify corresponding necessary conditions.Importantly, we establish an upper capacity bound that matches the well-knownexponential lower bound in the literature. This provides the first tight andoptimal asymptotic memory capacity for modern Hopfield models. (ii) Asub-linear time algorithm $\mathtt{U}\text{-}\mathtt{Hop}$+ to reach KHMs'optimal capacity. (iii) An analysis of the scaling behavior of the requiredfeature dimension relative to the number of stored memories. These effortsimprove both the retrieval capability of KHMs and the representation learningof corresponding transformers. Experimentally, we provide thorough numericalresults to back up theoretical findings.</description>
      <author>example@mail.com (Jerry Yao-Chieh Hu, Dennis Wu, Han Liu)</author>
      <guid isPermaLink="false">2410.23126v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MVSDet: Multi-View Indoor 3D Object Detection via Efficient Plane Sweeps</title>
      <link>http://arxiv.org/abs/2410.21566v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多视角室内3D物体检测的关键挑战是从图像中推断准确的几何信息以实现精确的3D检测。&lt;h4&gt;目的&lt;/h4&gt;提出MVSDet，利用平面扫描进行几何感知的3D物体检测。&lt;h4&gt;方法&lt;/h4&gt;设计了一种概率采样和软加权机制，以决定像素特征在3D体积中的放置，选择概率体中得分最高的多个位置，并用概率分数表示置信度。&lt;h4&gt;主要发现&lt;/h4&gt;通过应用像素对齐的高斯溅射技术来规范化深度预测，并在计算开销较小的情况下提高检测性能。&lt;h4&gt;结论&lt;/h4&gt;在ScanNet和ARKIT Scenes数据集上的广泛实验显示了模型的优越性。&lt;h4&gt;代码&lt;/h4&gt;我们的代码可在https://github.com/Pixie8888/MVSDet获取。&lt;h4&gt;总结&lt;/h4&gt;MVSDet通过新的方法改善了多视角3D物体检测的性能，解决了以往方法中几何信息不准确的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/pixie8888/mvsdet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The key challenge of multi-view indoor 3D object detection is to inferaccurate geometry information from images for precise 3D detection. Previousmethod relies on NeRF for geometry reasoning. However, the geometry extractedfrom NeRF is generally inaccurate, which leads to sub-optimal detectionperformance. In this paper, we propose MVSDet which utilizes plane sweep forgeometry-aware 3D object detection. To circumvent the requirement for a largenumber of depth planes for accurate depth prediction, we design a probabilisticsampling and soft weighting mechanism to decide the placement of pixel featureson the 3D volume. We select multiple locations that score top in theprobability volume for each pixel and use their probability score to indicatethe confidence. We further apply recent pixel-aligned Gaussian Splatting toregularize depth prediction and improve detection performance with littlecomputation overhead. Extensive experiments on ScanNet and ARKitScenes datasetsare conducted to show the superiority of our model. Our code is available athttps://github.com/Pixie8888/MVSDet.</description>
      <author>example@mail.com (Yating Xu, Chen Li, Gim Hee Lee)</author>
      <guid isPermaLink="false">2410.21566v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Aligning Audio-Visual Joint Representations with an Agentic Workflow</title>
      <link>http://arxiv.org/abs/2410.23230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉内容与伴随音频信号自然形成联合表示，以改善音视频相关应用。&lt;h4&gt;目的&lt;/h4&gt;提高音视频联合表示的质量，强调音频与视频数据的对齐重要性。&lt;h4&gt;方法&lt;/h4&gt;提出一种由名为AVAgent的基于大语言模型的助手控制的工作流程，通过将音频信号对齐到视觉数据来改善联合表示。&lt;h4&gt;主要发现&lt;/h4&gt;AVAgent利用多模态大语言模型将音频和视觉数据分别转换为语言描述，并评估其对齐情况，必要时编辑音频信号。&lt;h4&gt;结论&lt;/h4&gt;通过工具使用、规划和反思的循环步骤，音频信号逐渐与视觉内容对齐，现有方法可以直接利用对齐的音视频数据以改善联合表示。&lt;h4&gt;总结&lt;/h4&gt;实验结果全面展示了所提出方法在多种下游任务中优于以往基线的最新性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual content and accompanied audio signals naturally formulate a jointrepresentation to improve audio-visual (AV) related applications. While studiesdevelop various AV representation learning frameworks, the importance of AVdata alignment is usually undermined for achieving high-quality representation.We observe that an audio signal may contain background noise interference.Also, non-synchronization may appear between audio and video streams. Thesenon-strict data alignment limits representation quality and downgradeapplication performance. In this paper, we propose to improve AV jointrepresentations from a data-centric perspective by aligning audio signals tovisual data. Our alignment is conducted in an agentic workflow controlled by anLLM-based assistant named AVAgent. For each input AV data pair, our AVAgentuses a multi-modal LLM to convert audio and visual data into languagedescriptions separately (i.e., tool use). Then, AVAgent reasons whether thispaired data is aligned well and plans to edit the audio signal if needed (i.e.,planning). The audio editing is executed by predefined actions that filternoise or augment data. Moreover, we use a VLM to evaluate how modified audiosignals match the visual content and provide feedback to AVAgent (i.e.,reflection). The tool use, planning, and reflection steps operate cyclically tobecome an agentic workflow where audio signals are gradually aligned to visualcontent. To this end, existing methods can directly leverage the aligned AVdata via our agentic workflow to improve AV joint representations. Theexperimental results comprehensively demonstrate the state-of-the-artperformance of the proposed approach against previous baselines in diversedownstream tasks.</description>
      <author>example@mail.com (Shentong Mo, Yibing Song)</author>
      <guid isPermaLink="false">2410.23230v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Multimodal Fusion of In-process Sensor Data for Advanced Manufacturing Process Monitoring</title>
      <link>http://arxiv.org/abs/2410.22558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;有效监控制造过程对保持产品质量和运营效率至关重要，现代制造环境生成大量多模态数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的多模态传感器数据融合方法，以应对高维数据的解读挑战，尤其是在缺乏标签数据的情况下。&lt;h4&gt;方法&lt;/h4&gt;采用对比学习技术，关联不同数据模态，开发了五种独特模态的编码器，包括视觉图像、音频信号、激光位置和激光功率测量。&lt;h4&gt;主要发现&lt;/h4&gt;通过将高维数据集压缩为低维表示空间，该方法提高了流程控制、异常检测和质量保证等下游任务的效率。&lt;h4&gt;结论&lt;/h4&gt;研究展示了该方法在先进制造系统中增强过程监控能力的潜力，并为智能制造提供了灵活、可扩展的多模态数据融合框架。&lt;h4&gt;总结&lt;/h4&gt;本研究为适应多样化的制造环境和传感器配置提供了有效的解决方案，推动了智能制造的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective monitoring of manufacturing processes is crucial for maintainingproduct quality and operational efficiency. Modern manufacturing environmentsgenerate vast amounts of multimodal data, including visual imagery from variousperspectives and resolutions, hyperspectral data, and machine health monitoringinformation such as actuator positions, accelerometer readings, and temperaturemeasurements. However, interpreting this complex, high-dimensional datapresents significant challenges, particularly when labeled datasets areunavailable. This paper presents a novel approach to multimodal sensor datafusion in manufacturing processes, inspired by the Contrastive Language-ImagePre-training (CLIP) model. We leverage contrastive learning techniques tocorrelate different data modalities without the need for labeled data,developing encoders for five distinct modalities: visual imagery, audiosignals, laser position (x and y coordinates), and laser power measurements. Bycompressing these high-dimensional datasets into low-dimensionalrepresentational spaces, our approach facilitates downstream tasks such asprocess control, anomaly detection, and quality assurance. We evaluate theeffectiveness of our approach through experiments, demonstrating its potentialto enhance process monitoring capabilities in advanced manufacturing systems.This research contributes to smart manufacturing by providing a flexible,scalable framework for multimodal data fusion that can adapt to diversemanufacturing environments and sensor configurations.</description>
      <author>example@mail.com (Matthew McKinney, Anthony Garland, Dale Cillessen, Jesse Adamczyk, Dan Bolintineanu, Michael Heiden, Elliott Fowler, Brad L. Boyce)</author>
      <guid isPermaLink="false">2410.22558v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Unified Domain Generalization and Adaptation for Multi-View 3D Object Detection</title>
      <link>http://arxiv.org/abs/2410.22461v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D物体检测在多视角摄像头的应用中取得了进展，但监督学习方法在面对未见和未标记的数据集时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出统一领域泛化与适应（UDGA）方法，以解决3D物体检测中的几何失配和标注资源不足的问题。&lt;h4&gt;方法&lt;/h4&gt;提出多视角重叠深度约束，利用多视角之间的强关联性，减少因视角变化带来的几何差距；同时引入标签高效的领域适应方法，使用极少的标签进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;UDGA框架在源域和目标域中均能实现稳定的检测性能，有效弥合领域差距，并减少对标注的需求。&lt;h4&gt;结论&lt;/h4&gt;UDGA在大规模基准测试（如nuScenes、Lyft和Waymo）中展示了其鲁棒性，优于现有的最先进方法。&lt;h4&gt;总结&lt;/h4&gt;UDGA方法通过创新的约束和适应策略，提升了3D物体检测的有效性和效率，尤其在资源有限的情况下表现突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in 3D object detection leveraging multi-view cameras havedemonstrated their practical and economical value in various challenging visiontasks. However, typical supervised learning approaches face challenges inachieving satisfactory adaptation toward unseen and unlabeled target datasets(\ie, direct transfer) due to the inevitable geometric misalignment between thesource and target domains. In practice, we also encounter constraints onresources for training models and collecting annotations for the successfuldeployment of 3D object detectors. In this paper, we propose Unified DomainGeneralization and Adaptation (UDGA), a practical solution to mitigate thosedrawbacks. We first propose Multi-view Overlap Depth Constraint that leveragesthe strong association between multi-view, significantly alleviating geometricgaps due to perspective view changes. Then, we present a Label-Efficient DomainAdaptation approach to handle unfamiliar targets with significantly feweramounts of labels (\ie, 1$\%$ and 5$\%)$, while preserving well-defined sourceknowledge for training efficiency. Overall, UDGA framework enables stabledetection performance in both source and target domains, effectively bridginginevitable domain gaps, while demanding fewer annotations. We demonstrate therobustness of UDGA with large-scale benchmarks: nuScenes, Lyft, and Waymo,where our framework outperforms the current state-of-the-art methods.</description>
      <author>example@mail.com (Gyusam Chang, Jiwon Lee, Donghyun Kim, Jinkyu Kim, Dongwook Lee, Daehyun Ji, Sujin Jang, Sangpil Kim)</author>
      <guid isPermaLink="false">2410.22461v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Conditional Forecasting of Margin Calls using Dynamic Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.23275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新颖的动态图神经网络（DGNN）架构，用于解决时间金融网络中的条件性m步预测问题。&lt;h4&gt;目的&lt;/h4&gt;验证DGNN在模拟数据上的有效性，特别是在利率互换（IRS）交易网络中的应用。&lt;h4&gt;方法&lt;/h4&gt;使用从时间金融网络模型中模拟的数据，捕捉利率互换交易网络的典型特征。&lt;h4&gt;主要发现&lt;/h4&gt;DGNN能够在预定的压力测试场景下，准确预测净变动保证金，时间跨度可达21天。&lt;h4&gt;结论&lt;/h4&gt;网络动态可以成功融入压力测试实践，为监管者和决策者提供重要的系统性风险监测工具。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了DGNN在金融网络预测中的潜力，尤其是在动态环境下的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel Dynamic Graph Neural Network (DGNN) architecture forsolving conditional $m$-steps ahead forecasting problems in temporal financialnetworks. The proposed DGNN is validated on simulated data from a temporalfinancial network model capturing stylized features of Interest Rate Swaps(IRSs) transaction networks, where financial entities trade swap contractsdynamically and the network topology evolves conditionally on a reference rate.The proposed model is able to produce accurate conditional forecasts of netvariation margins up to a $21$-day horizon by leveraging conditionalinformation under pre-determined stress test scenarios. Our work shows that thenetwork dynamics can be successfully incorporated into stress-testingpractices, thus providing regulators and policymakers with a crucial tool forsystemic risk monitoring.</description>
      <author>example@mail.com (Matteo Citterio, Marco D'Errico, Gabriele Visentin)</author>
      <guid isPermaLink="false">2410.23275v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Method of Moments for Estimation of Noisy Curves</title>
      <link>http://arxiv.org/abs/2410.23220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "研究从高噪声的高斯点云中恢复高维分段线性曲线的问题。",
    "目的": "确定恢复曲线所需的样本复杂度，以及提出有效的恢复方法。",
    "方法": "基于第三阶矩张量的拟合，采用精确的初始化策略进行曲线恢复。",
    "主要发现": "恢复曲线所需的样本复杂度至少与噪声的六次方成正比，且$O(\sigma^6)$的样本量是足够的。",
    "结论": "所提出的方法能有效地从高噪声数据中恢复出分段线性曲线，相关代码已公开于GitHub。",
    "总结": "本文提供了从高噪声点云中恢复高维分段线性曲线的理论基础和实践方法，并验证了其有效性。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we study the problem of recovering a ground truth highdimensional piecewise linear curve $C^*(t):[0, 1]\to\mathbb{R}^d$ from a highnoise Gaussian point cloud with covariance $\sigma^2I$ centered around thecurve. We establish that the sample complexity of recovering $C^*$ from datascales with order at least $\sigma^6$. We then show that recovery of apiecewise linear curve from the third moment is locally well-posed, and hence$O(\sigma^6)$ samples is also sufficient for recovery. We propose methods torecover a curve from data based on a fitting to the third moment tensor with acareful initialization strategy and conduct some numerical experimentsverifying the ability of our methods to recover curves. All code for ournumerical experiments is publicly available on GitHub.</description>
      <author>example@mail.com (Phillip Lo, Yuehaw Khoo)</author>
      <guid isPermaLink="false">2410.23220v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Micro-Structures Graph-Based Point Cloud Registration for Balancing Efficiency and Accuracy</title>
      <link>http://arxiv.org/abs/2410.21857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云配准（PCR）是摄影测量和遥感中的一个基本且重要的问题，旨在寻找点集之间的最佳刚性变换。&lt;h4&gt;目的&lt;/h4&gt;实现高效且精确的点云配准面临着重大挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的基于微结构图的全局点云配准方法，包括两个阶段：1) 粗配准（CR）：通过图形整合微结构，采用高效的图形层次策略去除异常值以获得最大共识集，并提出了基于Lie代数空间的鲁棒GNC-Welsch估计器进行优化；2) 精细配准（FR）：使用八叉树方法自适应搜索微结构中的平面特征，通过最小化点到平面的距离获得更精确的局部对齐，并将其视为平面调整算法结合安德森加速优化（PA-AA）。&lt;h4&gt;主要发现&lt;/h4&gt;在真实数据上的广泛实验表明，所提出的方法在3DMatch和ETH数据集上表现良好，相比于最先进的方法，具有更高的精度指标，并且时间成本减少至少三分之一。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在点云配准任务中表现出色，能够有效提高配准的准确性和效率。&lt;h4&gt;总结&lt;/h4&gt;本研究为点云配准提供了一种新的方法论，具有重要的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TGRS.2024.3488502&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point Cloud Registration (PCR) is a fundamental and significant issue inphotogrammetry and remote sensing, aiming to seek the optimal rigidtransformation between sets of points. Achieving efficient and precise PCRposes a considerable challenge. We propose a novel micro-structures graph-basedglobal point cloud registration method. The overall method is comprised of twostages. 1) Coarse registration (CR): We develop a graph incorporatingmicro-structures, employing an efficient graph-based hierarchical strategy toremove outliers for obtaining the maximal consensus set. We propose a robustGNC-Welsch estimator for optimization derived from a robust estimator to theoutlier process in the Lie algebra space, achieving fast and robust alignment.2) Fine registration (FR): To refine local alignment further, we use the octreeapproach to adaptive search plane features in the micro-structures. Byminimizing the distance from the point-to-plane, we can obtain a more preciselocal alignment, and the process will also be addressed effectively by beingtreated as a planar adjustment algorithm combined with Anderson acceleratedoptimization (PA-AA). After extensive experiments on real data, our proposedmethod performs well on the 3DMatch and ETH datasets compared to the mostadvanced methods, achieving higher accuracy metrics and reducing the time costby at least one-third.</description>
      <author>example@mail.com (Rongling Zhang, Li Yan, Pengcheng Wei, Hong Xie, Pinzhuo Wang, Binbing Wang)</author>
      <guid isPermaLink="false">2410.21857v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Paradigm Synergy: Can a Cross-Paradigm Objective Enhance Long-Tailed Learning?</title>
      <link>http://arxiv.org/abs/2410.22883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督学习(SSL)在多个计算机视觉任务中取得了显著成果，但在长尾分布的真实数据集上的表现较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来弥补自监督学习在处理类不平衡时的不足。&lt;h4&gt;方法&lt;/h4&gt;引入自适应范式协同(APS)，重新审视对比学习，从空间结构的角度动态调整潜在空间结构的均匀性，并结合监督学习的重加权策略。&lt;h4&gt;主要发现&lt;/h4&gt;在常用的长尾数据集上进行的广泛实验表明，APS有效且高效地提升了性能。&lt;h4&gt;结论&lt;/h4&gt;发现监督学习与自监督学习之间可以更深入地整合，为处理真实世界类不平衡问题提供了可能的解决方案。&lt;h4&gt;总结&lt;/h4&gt;APS方法展示了自监督学习与监督学习结合的潜力，有助于构建更强大的模型以应对类不平衡挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has achieved impressive results across severalcomputer vision tasks, even rivaling supervised methods. However, itsperformance degrades on real-world datasets with long-tailed distributions dueto difficulties in capturing inherent class imbalances. Although supervisedlong-tailed learning offers significant insights, the absence of labels in SSLprevents direct transfer of these strategies.To bridge this gap, we introduceAdaptive Paradigm Synergy (APS), a cross-paradigm objective that seeks to unifythe strengths of both paradigms. Our approach reexamines contrastive learningfrom a spatial structure perspective, dynamically adjusting the uniformity oflatent space structure through adaptive temperature tuning. Furthermore, wedraw on a re-weighting strategy from supervised learning to compensate for theshortcomings of temperature adjustment in explicit quantityperception.Extensive experiments on commonly used long-tailed datasetsdemonstrate that APS improves performance effectively and efficiently. Ourfindings reveal the potential for deeper integration between supervised andself-supervised learning, paving the way for robust models that handlereal-world class imbalance.</description>
      <author>example@mail.com (Haowen Xiao, Guanghui Liu, Xinyi Gao, Yang Li, Fengmao Lv, Jielei Chu)</author>
      <guid isPermaLink="false">2410.22883v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>S3PT: Scene Semantics and Structure Guided Clustering to Boost Self-Supervised Pre-Training for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.23085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，自监督聚类预训练技术如DINO和Cribo在下游检测和分割任务中表现出色，但在实际应用中（如自动驾驶）面临物体类别和尺寸分布不平衡以及复杂场景几何形状的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出S3PT，一种新颖的场景语义与结构引导聚类方法，以提供更一致的自监督训练目标。&lt;h4&gt;方法&lt;/h4&gt;三方面贡献：1. 引入语义分布一致的聚类，提升稀有类别（如摩托车和动物）的表示；2. 采用物体多样性一致的空间聚类，处理不平衡和多样的物体尺寸；3. 提出基于深度的空间聚类，以几何信息正则化学习，进一步细化特征层面的区域分离。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes、nuImages和Cityscapes数据集上，所学表示显著提升了下游语义分割和3D物体检测任务的性能，并展示了良好的领域迁移特性。&lt;h4&gt;结论&lt;/h4&gt;S3PT方法通过场景一致的目标和几何信息的引导，改善了自监督学习的效果，尤其对不平衡和稀有类别的处理具有积极影响。&lt;h4&gt;总结&lt;/h4&gt;本研究通过S3PT方法应对现实应用中的挑战，显著提升了物体检测和分割的表现，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent self-supervised clustering-based pre-training techniques like DINO andCribo have shown impressive results for downstream detection and segmentationtasks. However, real-world applications such as autonomous driving facechallenges with imbalanced object class and size distributions and complexscene geometries. In this paper, we propose S3PT a novel scene semantics andstructure guided clustering to provide more scene-consistent objectives forself-supervised training. Specifically, our contributions are threefold: First,we incorporate semantic distribution consistent clustering to encourage betterrepresentation of rare classes such as motorcycles or animals. Second, weintroduce object diversity consistent spatial clustering, to handle imbalancedand diverse object sizes, ranging from large background areas to small objectssuch as pedestrians and traffic signs. Third, we propose a depth-guided spatialclustering to regularize learning based on geometric information of the scene,thus further refining region separation on the feature level. Our learnedrepresentations significantly improve performance in downstream semanticsegmentation and 3D object detection tasks on the nuScenes, nuImages, andCityscapes datasets and show promising domain translation properties.</description>
      <author>example@mail.com (Maciej K. Wozniak, Hariprasath Govindarajan, Marvin Klingner, Camille Maurice, Ravi Kiran, Senthil Yogamani)</author>
      <guid isPermaLink="false">2410.23085v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Theoretical Investigations and Practical Enhancements on Tail Task Risk Minimization in Meta Learning</title>
      <link>http://arxiv.org/abs/2410.22788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;元学习在大型模型和任务分布鲁棒性时代中变得越来越重要，现实场景中任务分布鲁棒性是不可或缺的考虑因素。&lt;h4&gt;目的&lt;/h4&gt;探讨尾部任务风险最小化在快速适应鲁棒性提升中的有效性，并进行理论和实践方面的改进。&lt;h4&gt;方法&lt;/h4&gt;将分布鲁棒策略简化为一个最大-最小优化问题，构建斯塔克尔堡均衡作为解决方案概念，并估计收敛速度。&lt;h4&gt;主要发现&lt;/h4&gt;在存在尾部风险的情况下，推导出泛化界限，建立与估计分位数的联系，并在实践中改进所研究的策略。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的评估，证明了该提案的意义及其在促进多模态大型模型鲁棒性方面的可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本研究为元学习领域提供了理论支持和实践改进，强调了尾部风险管理在任务适应性中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Meta learning is a promising paradigm in the era of large models and taskdistributional robustness has become an indispensable consideration inreal-world scenarios. Recent advances have examined the effectiveness of tailtask risk minimization in fast adaptation robustness improvement\citep{wang2023simple}. This work contributes to more theoreticalinvestigations and practical enhancements in the field. Specifically, we reducethe distributionally robust strategy to a max-min optimization problem,constitute the Stackelberg equilibrium as the solution concept, and estimatethe convergence rate. In the presence of tail risk, we further derive thegeneralization bound, establish connections with estimated quantiles, andpractically improve the studied strategy. Accordingly, extensive evaluationsdemonstrate the significance of our proposal and its scalability to multimodallarge models in boosting robustness.</description>
      <author>example@mail.com (Yiqin Lv, Qi Wang, Dong Liang, Zheng Xie)</author>
      <guid isPermaLink="false">2410.22788v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Partial Channel Dependence with Channel Masks for Time Series Foundation Models</title>
      <link>http://arxiv.org/abs/2410.23222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS Workshop on Time Series in the Age of Large Models, 2024.
  Oral presentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型在时间序列领域的应用随着大规模时间序列数据集的出现而取得了成功，但之前的研究主要关注模型架构的设计，忽视了通道间的隐性异质性。&lt;h4&gt;目的&lt;/h4&gt;引入部分通道依赖（PCD）概念，以更复杂地调整基于数据集特定信息的通道依赖性。&lt;h4&gt;方法&lt;/h4&gt;提出一种通道掩码，通过两个关键组件实现PCD：1) 编码通道间相对依赖关系的相关矩阵，2) 学习每个数据集特定的绝对依赖关系的领域参数，进而优化相关矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;在包括预测、分类、填补和异常检测等四个时间序列任务中，验证了PCD的有效性，适用于少样本和零样本场景，适用于基础时间序列模型和单任务模型。&lt;h4&gt;结论&lt;/h4&gt;部分通道依赖的引入显著提升了时间序列任务的处理效果。&lt;h4&gt;总结&lt;/h4&gt;本研究为时间序列模型设计提供了新的思路，强调了通道间隐性依赖的处理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in foundation models have been successfully extended tothe time series (TS) domain, facilitated by the emergence of large-scale TSdatasets. However, previous efforts have primarily focused on designing modelarchitectures to address explicit heterogeneity among datasets such as variousnumbers of channels, while often overlooking implicit heterogeneity such asvarying dependencies between channels. In this work, we introduce the conceptof partial channel dependence (PCD), which enables a more sophisticatedadjustment of channel dependencies based on dataset-specific information. Toachieve PCD, we propose a channel mask that captures the relationships betweenchannels within a dataset using two key components: 1) a correlation matrixthat encodes relative dependencies between channels, and 2) domain parametersthat learn the absolute dependencies specific to each dataset, refining thecorrelation matrix. We validate the effectiveness of PCD across four tasks inTS including forecasting, classification, imputation, and anomaly detection,under diverse settings, including few-shot and zero-shot scenarios with both TSfoundation models and single-task models. Code is available athttps://github.com/seunghan96/CM.</description>
      <author>example@mail.com (Seunghan Lee, Taeyoung Park, Kibok Lee)</author>
      <guid isPermaLink="false">2410.23222v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Nested ResNet: A Vision-Based Method for Detecting the Sensing Area of a Drop-in Gamma Probe</title>
      <link>http://arxiv.org/abs/2410.23154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;目前，临床上广泛使用的滴入伽马探头在机器人辅助手术中用于淋巴结检测，但仅提供音频反馈，缺乏必要的视觉反馈。&lt;h4&gt;目的&lt;/h4&gt;改进基于深度学习的回归方法，以提高探头感应区域的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;引入三分支深度学习框架，主要分支使用立体腹腔镜图像作为输入，采用Nested ResNet架构，并通过迁移学习进行深度估计，同时通过探头轴采样提供方向指导，结合各分支特征以提高预测准确性。&lt;h4&gt;主要发现&lt;/h4&gt;在公开数据集上评估后，方法表现优于以往，2D均值误差减少了22.10%，3D均值误差减少了41.67%。定性比较也进一步证明了方法的精度提升。&lt;h4&gt;结论&lt;/h4&gt;经过广泛评估，解决方案显著提高了感应区域预测的准确性和可靠性，为外科手术中滴入伽马探头的使用提供了更准确的视觉反馈。&lt;h4&gt;总结&lt;/h4&gt;该研究的进展为外科医生提供了更加准确和可靠的定位，提升了手术的安全性和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Drop-in gamma probes are widely used in robotic-assisted minimallyinvasive surgery (RAMIS) for lymph node detection. However, these devices onlyprovide audio feedback on signal intensity, lacking the visual feedbacknecessary for precise localisation. Previous work attempted to predict thesensing area location using laparoscopic images, but the prediction accuracywas unsatisfactory. Improvements are needed in the deep learning-basedregression approach.  Methods: We introduce a three-branch deep learning framework to predict thesensing area of the probe. Specifically, we utilise the stereo laparoscopicimages as input for the main branch and develop a Nested ResNet architecture.The framework also incorporates depth estimation via transfer learning andorientation guidance through probe axis sampling. The combined features fromeach branch enhanced the accuracy of the prediction.  Results: Our approach has been evaluated on a publicly available dataset,demonstrating superior performance over previous methods. In particular, ourmethod resulted in a 22.10\% decrease in 2D mean error and a 41.67\% reductionin 3D mean error. Additionally, qualitative comparisons further demonstratedthe improved precision of our approach.  Conclusion: With extensive evaluation, our solution significantly enhancesthe accuracy and reliability of sensing area predictions. This advancementenables visual feedback during the use of the drop-in gamma probe in surgery,providing surgeons with more accurate and reliable localisation.}</description>
      <author>example@mail.com (Songyu Xu, Yicheng Hu, Jionglong Su, Daniel Elson, Baoru Huang)</author>
      <guid isPermaLink="false">2410.23154v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Automated Image-Based Identification and Consistent Classification of Fire Patterns with Quantitative Shape Analysis and Spatial Location Identification</title>
      <link>http://arxiv.org/abs/2410.23105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;火灾模式通常通过调查者的视觉观察进行分类，这导致了主观解释。&lt;h4&gt;目的&lt;/h4&gt;提出一个量化的火灾模式分类框架，以支持火灾调查员，实现一致性和准确性。&lt;h4&gt;方法&lt;/h4&gt;该框架整合了四个组件，包括人机交互提取火灾模式、基于长宽比的随机森林模型分类、火灾现场点云分割以及火灾模式与室内元素的空间关系分析。&lt;h4&gt;主要发现&lt;/h4&gt;该框架的分类结果在合成数据上达到93%的精确度，在真实火灾模式上达到83%。&lt;h4&gt;结论&lt;/h4&gt;该框架综合了定性和定量数据，为火灾模式分析提供了一种新方法。&lt;h4&gt;总结&lt;/h4&gt;该研究为火灾调查提供了一种更为客观和准确的分析工具，有助于提高调查结果的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fire patterns, consisting of fire effects that offer insights into firebehavior and origin, are traditionally classified based on investigators'visual observations, leading to subjective interpretations. This study proposesa framework for quantitative fire pattern classification to support fireinvestigators, aiming for consistency and accuracy. The framework integratesfour components. First, it leverages human-computer interaction to extract firepatterns from surfaces, combining investigator expertise with computationalanalysis. Second, it employs an aspect ratio-based random forest model toclassify fire pattern shapes. Third, fire scene point cloud segmentationenables precise identification of fire-affected areas and the mapping of 2Dfire patterns to 3D scenes. Lastly, spatial relationships between fire patternsand indoor elements support an interpretation of the fire scene. Thesecomponents provide a method for fire pattern analysis that synthesizesqualitative and quantitative data. The framework's classification resultsachieve 93% precision on synthetic data and 83% on real fire patterns.</description>
      <author>example@mail.com (Pengkun Liu, Shuna Ni, Stanislav I. Stoliarov, Pingbo Tang)</author>
      <guid isPermaLink="false">2410.23105v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>EMMA: End-to-End Multimodal Model for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.23262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Blog post: https://waymo.com/blog/2024/10/introducing-emma/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出EMMA，一个用于自动驾驶的端到端多模态模型。&lt;h4&gt;目的&lt;/h4&gt;将原始相机传感器数据直接映射到多种驾驶特定输出。&lt;h4&gt;方法&lt;/h4&gt;基于多模态大语言模型，使用自然语言文本表示所有非传感器输入和输出。&lt;h4&gt;主要发现&lt;/h4&gt;EMMA在nuScenes的运动规划上表现出色，并在Waymo Open Motion Dataset和Waymo Open Dataset上取得竞争性结果。&lt;h4&gt;结论&lt;/h4&gt;联合训练EMMA的规划轨迹、物体检测和道路图任务在所有三个领域均有所提升，表明其作为通用模型的潜力。&lt;h4&gt;局限性&lt;/h4&gt;处理的图像帧数量有限，不支持准确的3D传感器（如LiDAR或雷达），且计算成本高。&lt;h4&gt;总结&lt;/h4&gt;希望我们的研究结果能激励进一步研究，以缓解这些问题并推动自动驾驶模型架构的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.Built on a multi-modal large language model foundation, EMMA directly maps rawcamera sensor data into various driving-specific outputs, including plannertrajectories, perception objects, and road graph elements. EMMA maximizes theutility of world knowledge from the pre-trained large language models, byrepresenting all non-sensor inputs (e.g. navigation instructions and egovehicle status) and outputs (e.g. trajectories and 3D locations) as naturallanguage text. This approach allows EMMA to jointly process various drivingtasks in a unified language space, and generate the outputs for each task usingtask-specific prompts. Empirically, we demonstrate EMMA's effectiveness byachieving state-of-the-art performance in motion planning on nuScenes as wellas competitive results on the Waymo Open Motion Dataset (WOMD). EMMA alsoyields competitive results for camera-primary 3D object detection on the WaymoOpen Dataset (WOD). We show that co-training EMMA with planner trajectories,object detection, and road graph tasks yields improvements across all threedomains, highlighting EMMA's potential as a generalist model for autonomousdriving applications. However, EMMA also exhibits certain limitations: it canprocess only a small amount of image frames, does not incorporate accurate 3Dsensing modalities like LiDAR or radar and is computationally expensive. Wehope that our results will inspire further research to mitigate these issuesand to further evolve the state of the art in autonomous driving modelarchitectures.</description>
      <author>example@mail.com (Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, James Guo, Dragomir Anguelov, Mingxing Tan)</author>
      <guid isPermaLink="false">2410.23262v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Threshold-based Two-layer Online Unsupervised Anomaly Detector</title>
      <link>http://arxiv.org/abs/2410.22967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物联网（IoT）的普及增加了网络威胁的脆弱性，迫切需要开发能够适应新型攻击的异常检测系统（ADSs）。&lt;h4&gt;目的&lt;/h4&gt;提出一种综合框架，增强和解释安全领域中的在线无监督异常检测。&lt;h4&gt;方法&lt;/h4&gt;引入可解释的双层异常检测方法，生成可靠的高置信度伪标签，并结合在线学习机制，通过创新的阈值调整方法更新Adaptive NAD以应对新威胁。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Adaptive NAD在CIC-Darknet2020和CIC-DoHBrw-2020数据集上分别提高了超过5.4%和23.0%的SPAUC，超越了现有的最先进解决方案。&lt;h4&gt;结论&lt;/h4&gt;Adaptive NAD提供了一种有效的异常检测解决方案，具备更好的适应性和可解释性，适合实际应用。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了Adaptive NAD在应对网络安全威胁中的潜力，并且其代码公开可用，促进了研究界的进一步探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mylearncodespace/adaptive-nad&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of the Internet of Things (IoT) has heightened thevulnerability to cyber threats, making it imperative to develop AnomalyDetection Systems (ADSs) capable of adapting to emerging or novel attacks.Prior research has predominantly concentrated on offline unsupervised learningtechniques to protect ADSs, which are impractical for real-world applications.Furthermore, these studies often rely heavily on the assumption of knownlegitimate behaviors and fall short of meeting the interpretabilityrequirements in security contexts, thereby hindering their practical adoption.In response, this paper introduces Adaptive NAD, a comprehensive frameworkaimed at enhancing and interpreting online unsupervised anomaly detectionwithin security domains. We propose an interpretable two-layer anomalydetection approach that generates dependable, high-confidence pseudo-labels.Subsequently, we incorporate an online learning mechanism that updates AdaptiveNAD using an innovative threshold adjustment method to accommodate new threats.Experimental findings reveal that Adaptive NAD surpasses state-of-the-artsolutions by achieving improvements of over 5.4% and 23.0% in SPAUC on theCIC-Darknet2020 and CIC-DoHBrw-2020 datasets, respectively. The code forAdaptive NAD is publicly available athttps://github.com/MyLearnCodeSpace/Adaptive-NAD.</description>
      <author>example@mail.com (Yachao Yuan, Yu Huang, Yali Yuan, Jin Wang)</author>
      <guid isPermaLink="false">2410.22967v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Hyperparameter Optimization in Machine Learning</title>
      <link>http://arxiv.org/abs/2410.22854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;超参数是控制机器学习算法行为的配置变量，广泛应用于机器学习和人工智能中。&lt;h4&gt;目的&lt;/h4&gt;探讨超参数优化的统一处理方法，提供最新的例子和见解。&lt;h4&gt;方法&lt;/h4&gt;涵盖随机搜索、准随机搜索、基于带子的、模型的和梯度的超参数搜索技术。&lt;h4&gt;主要发现&lt;/h4&gt;自动化超参数搜索可以减轻研究人员和从业者通过试错法寻找合适超参数的负担。&lt;h4&gt;结论&lt;/h4&gt;讨论了在线、约束和多目标形式的扩展，及其与元学习和神经架构搜索等其他领域的联系。&lt;h4&gt;未来研究&lt;/h4&gt;提出了未解决的问题和未来的研究方向。&lt;h4&gt;总结&lt;/h4&gt;自动化超参数优化是实现机器学习自动化的重要步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperparameters are configuration variables controlling the behavior ofmachine learning algorithms. They are ubiquitous in machine learning andartificial intelligence and the choice of their values determine theeffectiveness of systems based on these technologies. Manual hyperparametersearch is often unsatisfactory and becomes unfeasible when the number ofhyperparameters is large. Automating the search is an important step towardsautomating machine learning, freeing researchers and practitioners alike fromthe burden of finding a good set of hyperparameters by trial and error. In thissurvey, we present a unified treatment of hyperparameter optimization,providing the reader with examples and insights into the state-of-the-art. Wecover the main families of techniques to automate hyperparameter search, oftenreferred to as hyperparameter optimization or tuning, including random andquasi-random search, bandit-, model- and gradient- based approaches. We furtherdiscuss extensions, including online, constrained, and multi-objectiveformulations, touch upon connections with other fields such as meta-learningand neural architecture search, and conclude with open questions and futureresearch directions.</description>
      <author>example@mail.com (Luca Franceschi, Michele Donini, Valerio Perrone, Aaron Klein, Cédric Archambeau, Matthias Seeger, Massimiliano Pontil, Paolo Frasconi)</author>
      <guid isPermaLink="false">2410.22854v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ReferEverything: Towards Segmenting Everything We Can Speak of in Videos</title>
      <link>http://arxiv.org/abs/2410.23287v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page at
  https://miccooper9.github.io/projects/ReferEverything/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出REM框架，用于通过自然语言对视频中的各种概念进行分割。&lt;h4&gt;目的&lt;/h4&gt;实现对稀有和未见对象的准确分割与跟踪。&lt;h4&gt;方法&lt;/h4&gt;利用在互联网规模数据集上学习的视觉语言表示，通过微调在特定领域的对象分割数据集上进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;REM可以准确分割和跟踪稀有对象，并能够推广到非对象动态概念，如海浪。&lt;h4&gt;结论&lt;/h4&gt;在Ref-DAVIS等领域数据集上，REM的表现与先进方法相当，并在外域数据上的区域相似度方面超越它们。&lt;h4&gt;总结&lt;/h4&gt;REM利用互联网规模的预训练，展现了优越的分割能力，适用于广泛的概念和动态场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present REM, a framework for segmenting a wide range of concepts in videothat can be described through natural language. Our method capitalizes onvisual-language representations learned by video diffusion models onInternet-scale datasets. A key insight of our approach is preserving as much ofthe generative model's original representation as possible, while fine-tuningit on narrow-domain Referral Object Segmentation datasets. As a result, ourframework can accurately segment and track rare and unseen objects, despitebeing trained on object masks from a limited set of categories. Additionally,it can generalize to non-object dynamic concepts, such as waves crashing in theocean, as demonstrated in our newly introduced benchmark for Referral VideoProcess Segmentation (Ref-VPS). Our experiments show that REM performs on parwith state-of-the-art approaches on in-domain datasets, like Ref-DAVIS, whileoutperforming them by up to twelve points in terms of region similarity onout-of-domain data, leveraging the power of Internet-scale pre-training.</description>
      <author>example@mail.com (Anurag Bagchi, Zhipeng Bao, Yu-Xiong Wang, Pavel Tokmakov, Martial Hebert)</author>
      <guid isPermaLink="false">2410.23287v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PointRecon: Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching</title>
      <link>http://arxiv.org/abs/2410.23245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新颖的在线点基3D重建方法，从姿态单目RGB视频中进行重建。&lt;h4&gt;目的&lt;/h4&gt;旨在持续更新场景的全局点云表示，随着新图像的观察更新点的特征和三维位置。&lt;h4&gt;方法&lt;/h4&gt;通过新颖的基于光线的2D-3D特征匹配技术，实现点云更新和新点的深度预测，该方法对之前点位置预测中的错误具有鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够扩展点云，添加新检测到的点，同时谨慎地去除冗余点，且处理无限长度的序列，提供实时更新。&lt;h4&gt;结论&lt;/h4&gt;与离线方法相比，该方法不受预定义分辨率或场景大小限制，其统一的全局表示确保了视角间的一致性。&lt;h4&gt;实验结果&lt;/h4&gt;在ScanNet数据集上的实验表明，该方法在在线多视图立体视觉（MVS）方法中达到了最先进的质量。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种有效的在线3D重建技术，具有实时更新和高质量重建的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel online, point-based 3D reconstruction method from posedmonocular RGB videos. Our model maintains a global point cloud representationof the scene, continuously updating the features and 3D locations of points asnew images are observed. It expands the point cloud with newly detected pointswhile carefully removing redundancies. The point cloud updates and depthpredictions for new points are achieved through a novel ray-based 2D-3D featurematching technique, which is robust against errors in previous point positionpredictions. In contrast to offline methods, our approach processesinfinite-length sequences and provides real-time updates. Additionally, thepoint cloud imposes no pre-defined resolution or scene size constraints, andits unified global representation ensures view consistency across perspectives.Experiments on the ScanNet dataset show that our method achievesstate-of-the-art quality among online MVS approaches. Project page:https://arthurhero.github.io/projects/pointrecon</description>
      <author>example@mail.com (Chen Ziwen, Zexiang Xu, Li Fuxin)</author>
      <guid isPermaLink="false">2410.23245v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Higher-order Cross-structural Embedding Model for Time Series Analysis</title>
      <link>http://arxiv.org/abs/2410.22984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列分析在医疗、金融和传感网络等多个领域受到广泛关注，因其重要应用。&lt;h4&gt;目的&lt;/h4&gt;解决当前方法在建模时间序列高阶交互方面的不足，提升下游任务性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架High-TS，结合多尺度Transformer和拓扑深度学习(TDL)同时建模时间和空间视角，并利用对比学习整合这两种结构。&lt;h4&gt;主要发现&lt;/h4&gt;High-TS在多种时间序列任务中超越了现有的最先进方法，强调了高阶交叉结构信息在提升模型性能中的重要性。&lt;h4&gt;结论&lt;/h4&gt;高阶交叉结构信息对时间序列分析的模型性能提升具有显著影响。&lt;h4&gt;总结&lt;/h4&gt;High-TS框架通过整合多种学习方法，提供了一种有效的解决方案，促进了时间序列分析的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series analysis has gained significant attention due to its criticalapplications in diverse fields such as healthcare, finance, and sensornetworks. The complexity and non-stationarity of time series make itchallenging to capture the interaction patterns across different timestamps.Current approaches struggle to model higher-order interactions within timeseries, and focus on learning temporal or spatial dependencies separately,which limits performance in downstream tasks. To address these gaps, we proposeHigher-order Cross-structural Embedding Model for Time Series (High-TS), anovel framework that jointly models both temporal and spatial perspectives bycombining multiscale Transformer with Topological Deep Learning (TDL).Meanwhile, High-TS utilizes contrastive learning to integrate these twostructures for generating robust and discriminative representations. Extensiveexperiments show that High-TS outperforms state-of-the-art methods in varioustime series tasks and demonstrate the importance of higher-ordercross-structural information in improving model performance.</description>
      <author>example@mail.com (Guancen Lin, Cong Shen, Aijing Lin)</author>
      <guid isPermaLink="false">2410.22984v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>UniRiT: Towards Few-Shot Non-Rigid Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2410.22909v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 14 figures, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;非刚性点云配准是3D场景理解中的一个关键挑战，尤其在外科导航中尤为重要。现有方法在训练于大规模高质量数据集时表现优秀，但这些数据集收集和标注成本高昂，特别是在真实医疗场景中。&lt;h4&gt;目的&lt;/h4&gt;解决少量样本的非刚性点云配准问题。&lt;h4&gt;方法&lt;/h4&gt;提出UniRiT框架，通过将复杂的非刚性变换模式分解为刚性和小的非刚性变换，采用两步配准策略，首先对齐源点云和目标点云的质心，然后通过非刚性变换进行精细化配准，以降低问题复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;引入新的数据集MedMatch3D，包含真实人类器官并展现高样本分布变异性。UniRiT在MedMatch3D上表现出色，相较于现有最佳方法提升了94.22%。&lt;h4&gt;结论&lt;/h4&gt;UniRiT在少样本非刚性点云配准任务中具有先进的表现，展示了该框架的有效性和潜力。&lt;h4&gt;总结&lt;/h4&gt;通过创新的方法和新数据集，UniRiT显著改善了非刚性点云配准的性能，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-rigid point cloud registration is a critical challenge in 3D sceneunderstanding, particularly in surgical navigation. Although existing methodsachieve excellent performance when trained on large-scale, high-qualitydatasets, these datasets are prohibitively expensive to collect and annotate,e.g., organ data in authentic medical scenarios. With insufficient trainingsamples and data noise, existing methods degrade significantly since non-rigidpatterns are more flexible and complicated than rigid ones, and thedistributions across samples are more distinct, leading to higher difficulty inrepresentation learning with few data. In this work, we aim to deal with thischallenging few-shot non-rigid point cloud registration problem. Based on theobservation that complex non-rigid transformation patterns can be decomposedinto rigid and small non-rigid transformations, we propose a novel andeffective framework, UniRiT. UniRiT adopts a two-step registration strategythat first aligns the centroids of the source and target point clouds and thenrefines the registration with non-rigid transformations, thereby significantlyreducing the problem complexity. To validate the performance of UniRiT onreal-world datasets, we introduce a new dataset, MedMatch3D, which consists ofreal human organs and exhibits high variability in sample distribution. Wefurther establish a new challenging benchmark for few-shot non-rigidregistration. Extensive empirical results demonstrate that UniRiT achievesstate-of-the-art performance on MedMatch3D, improving the existing bestapproach by 94.22%.</description>
      <author>example@mail.com (Geng Li, Haozhi Cao, Mingyang Liu, Chenxi Jiang, Jianfei Yang)</author>
      <guid isPermaLink="false">2410.22909v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models</title>
      <link>http://arxiv.org/abs/2410.23266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有基准测试强调了多模态基础模型（MFM）在利用时间上下文进行视频理解方面的杰出表现，但模型在视觉时间推理方面的真实表现如何尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;系统性检查当前视觉时间推理任务，提出评估MFMs时间推理能力的新标准。&lt;h4&gt;方法&lt;/h4&gt;提出三个原则及相应指标：多帧增益、帧顺序敏感性和帧信息差异，并引入新的基准TOMATO，包含1484个经过人工标注的问题，涵盖六个任务，应用于1417个视频。&lt;h4&gt;主要发现&lt;/h4&gt;评估显示最佳模型与人类之间存在57.3%的性能差距，分析揭示MFMs在连续序列解释方面存在根本性局限。&lt;h4&gt;结论&lt;/h4&gt;虽然MFMs能够准确识别孤立帧中的事件，但无法将这些帧作为连续序列进行解释，TOMATO将成为评估下一代MFMs的关键测试平台，并呼吁社区开发能够理解视频中人类世界动态的AI系统。&lt;h4&gt;总结&lt;/h4&gt;当前MFMs在视觉时间推理方面的能力被高估了，需要进一步研究和改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yale-nlp/TOMATO&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing benchmarks often highlight the remarkable performance achieved bystate-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporalcontext for video understanding. However, how well do the models truly performvisual temporal reasoning? Our study of existing benchmarks shows that thiscapability of MFMs is likely overestimated as many questions can be solved byusing a single, few, or out-of-order frames. To systematically examine currentvisual temporal reasoning tasks, we propose three principles with correspondingmetrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) FrameInformation Disparity. Following these principles, we introduce TOMATO,Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted torigorously assess MFMs' temporal reasoning capabilities in video understanding.TOMATO comprises 1,484 carefully curated, human-annotated questions spanningsix tasks (i.e., action count, direction, rotation, shape &amp; trend, velocity &amp;frequency, and visual cues), applied to 1,417 videos, including 805self-recorded and -generated videos, that encompass human-centric, real-world,and simulated scenarios. Our comprehensive evaluation reveals a human-modelperformance gap of 57.3% with the best-performing model. Moreover, our in-depthanalysis uncovers more fundamental limitations beyond this gap in current MFMs.While they can accurately recognize events in isolated frames, they fail tointerpret these frames as a continuous sequence. We believe TOMATO will serveas a crucial testbed for evaluating the next-generation MFMs and as a call tothe community to develop AI systems capable of comprehending human worlddynamics through the video modality.</description>
      <author>example@mail.com (Ziyao Shangguan, Chuhan Li, Yuxuan Ding, Yanan Zheng, Yilun Zhao, Tesca Fitzgerald, Arman Cohan)</author>
      <guid isPermaLink="false">2410.23266v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating the Robustness of LiDAR Point Cloud Tracking Against Adversarial Attack</title>
      <link>http://arxiv.org/abs/2410.20893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究探讨基于神经网络的LiDAR点云跟踪模型在对抗攻击下的鲁棒性，这是一个常被忽视但至关重要的方面。&lt;h4&gt;目的&lt;/h4&gt;关注跟踪模型在对抗攻击威胁下的鲁棒性，填补性能增强与鲁棒性之间的空白。&lt;h4&gt;方法&lt;/h4&gt;建立统一框架进行3D物体跟踪中的对抗攻击，详细研究白盒和黑盒攻击策略；针对白盒攻击，定制特定损失函数并扩展现有方法如FGSM、C&amp;W和PGD；针对黑盒攻击，引入新颖的目标感知扰动生成(TAPG)算法。&lt;h4&gt;主要发现&lt;/h4&gt;高级跟踪方法在白盒和黑盒攻击下表现出显著脆弱性，强调在LiDAR点云跟踪模型设计中融入对抗攻击鲁棒性的必要性。&lt;h4&gt;结论&lt;/h4&gt;TAPG方法在攻击效果和扰动隐蔽性之间达成最佳平衡，相较于现有方法表现更佳。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了对抗攻击对LiDAR点云跟踪模型的影响，并提出了增强鲁棒性的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we delve into the robustness of neural network-based LiDARpoint cloud tracking models under adversarial attacks, a critical aspect oftenoverlooked in favor of performance enhancement. These models, despiteincorporating advanced architectures like Transformer or Bird's Eye View (BEV),tend to neglect robustness in the face of challenges such as adversarialattacks, domain shifts, or data corruption. We instead focus on the robustnessof the tracking models under the threat of adversarial attacks. We begin byestablishing a unified framework for conducting adversarial attacks within thecontext of 3D object tracking, which allows us to thoroughly investigate bothwhite-box and black-box attack strategies. For white-box attacks, we tailorspecific loss functions to accommodate various tracking paradigms and extendexisting methods such as FGSM, C\&amp;W, and PGD to the point cloud domain. Inaddressing black-box attack scenarios, we introduce a novel transfer-basedapproach, the Target-aware Perturbation Generation (TAPG) algorithm, with thedual objectives of achieving high attack performance and maintaining lowperceptibility. This method employs a heuristic strategy to enforce sparseattack constraints and utilizes random sub-vector factorization to bolstertransferability. Our experimental findings reveal a significant vulnerabilityin advanced tracking methods when subjected to both black-box and white-boxattacks, underscoring the necessity for incorporating robustness againstadversarial attacks into the design of LiDAR point cloud tracking models.Notably, compared to existing methods, the TAPG also strikes an optimal balancebetween the effectiveness of the attack and the concealment of theperturbations.</description>
      <author>example@mail.com (Shengjing Tian, Yinan Han, Xiantong Zhao, Bin Liu, Xiuping Liu)</author>
      <guid isPermaLink="false">2410.20893v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
  </channel>
</rss>
