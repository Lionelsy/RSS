<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Mon, 30 Sep 2024 21:12:10 +0800</lastBuildDate>
    <item>
      <title>CROSS-GAiT: Cross-Attention-Based Multimodal Representation Fusion for Parametric Gait Adaptation in Complex Terrains</title>
      <link>http://arxiv.org/abs/2409.17262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究目标**:   - 提出CROSS-GAiT算法，旨在为四足机器人使用跨注意力机制融合来自视觉和时间序列输入的地形表示。2. **输入数据**:   - 包括线性加速度、角速度和关节力等时间序列数据，以及视觉输入。3. **地形表示生成**:   - 通过掩蔽的视觉变换器（ViT）编码器处理视觉输入，使用扩张因果卷积编码器处理时间序列数据。4. **跨注意力机制**:   - 此机制选择和整合每种模态中最相关的特征，将地形特征与机器人动态结合，以实现更好的步态调整。5. **自适应步态调整**:   - CROSS-GAiT利用融合的表示动态调整步态参数，以应对变化和不可预测的地形条件。6. **训练数据**:   - 在多种地形上进行训练，包括沥青、混凝土、砖铺路面、草地、密集植被、卵石、碎石和沙子。7. **算法的泛化能力**:   - 该算法能够很好地适应未见过的环境条件，提升实时导航性能。8. **实验实施**:   - 在Ghost Robotics Vision 60机器人上实施，并在复杂地形（如高植被密度、不平稳表面、沙丘和可变形基底）中进行了广泛测试。9. **性能改进**:   - IMU能量密度减少至少7.04%，总关节努力减少27.3%，这直接关联于稳定性提高和能量使用减少。   10. **成功率与效率**:    - 成功率提高至少64.5%，到达目标的时间减少4.91%（在四个复杂场景中）。11. **地形分类任务**:    - 学习的表示在地形分类任务中比最先进的方法提高4.48%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present CROSS-GAiT, a novel algorithm for quadruped robots that uses CrossAttention to fuse terrain representations derived from visual and time-seriesinputs, including linear accelerations, angular velocities, and joint efforts.These fused representations are used to adjust the robot's step height and hipsplay, enabling adaptive gaits that respond dynamically to varying terrainconditions. We generate these terrain representations by processing visualinputs through a masked Vision Transformer (ViT) encoder and time-series datathrough a dilated causal convolutional encoder. The cross-attention mechanismthen selects and integrates the most relevant features from each modality,combining terrain characteristics with robot dynamics for better-informed gaitadjustments. CROSS-GAiT uses the combined representation to dynamically adjustgait parameters in response to varying and unpredictable terrains. We trainCROSS-GAiT on data from diverse terrains, including asphalt, concrete, brickpavements, grass, dense vegetation, pebbles, gravel, and sand. Our algorithmgeneralizes well and adapts to unseen environmental conditions, enhancingreal-time navigation performance. CROSS-GAiT was implemented on a GhostRobotics Vision 60 robot and extensively tested in complex terrains with highvegetation density, uneven/unstable surfaces, sand banks, deformablesubstrates, etc. We observe at least a 7.04% reduction in IMU energy densityand a 27.3% reduction in total joint effort, which directly correlates withincreased stability and reduced energy usage when compared to state-of-the-artmethods. Furthermore, CROSS-GAiT demonstrates at least a 64.5% increase insuccess rate and a 4.91% reduction in time to reach the goal in four complexscenarios. Additionally, the learned representations perform 4.48% better thanthe state-of-the-art on a terrain classification task.</description>
      <author>example@mail.com (Gershom Seneviratne, Kasun Weerakoon, Mohamed Elnoor, Vignesh Rajgopal, Harshavarthan Varatharajan, Mohamed Khalid M Jaffar, Jason Pusey, Dinesh Manocha)</author>
      <guid isPermaLink="false">2409.17262v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Real-Time Pedestrian Detection on IoT Edge Devices: A Lightweight Deep Learning Approach</title>
      <link>http://arxiv.org/abs/2409.15740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 tables, 12 figures, article submitted to IEEE for
  possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 人工智能（AI）在我们日常生活中变得不可或缺，计算机视觉技术已足够成熟，能够在智能交通系统中承担检测路口行人的安全关键角色，从而警告车辆潜在的碰撞风险。2. **现有挑战**:   - 现有的集中计算方法分析摄像头视频并生成警报，但在实时应用中面临挑战，包括延迟、数据传输速度有限和生命风险。3. **边缘计算的解决方案**:   - 边缘服务器为实时应用提供了潜在解决方案，具备本地计算和存储资源，响应时间更短，但处理能力有限。4. **轻量级深度学习技术**:   - 轻量级深度学习（DL）技术使边缘服务器能够利用压缩的深度神经网络（DNN）模型提升性能。5. **研究目标**:   - 本研究探讨在人工智能物联网（AIoT）边缘设备上实现轻量级深度学习模型。6. **模型部署**:   - 部署了基于优化的YOLO深度学习模型用于实时行人检测，检测事件通过消息队列遥测传输（MQTT）协议发送至边缘服务器。7. **实验结果**:   - 模拟结果显示，优化后的YOLO模型能够实现实时行人检测，推理速度为147毫秒，帧率为2.3帧每秒，准确率达到78%，在基准模型上有显著提升。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has become integral to our everyday lives.Computer vision has advanced to the point where it can play the safety criticalrole of detecting pedestrians at road intersections in intelligenttransportation systems and alert vehicular traffic as to potential collisions.Centralized computing analyzes camera feeds and generates alerts for nearbyvehicles. However, real-time applications face challenges such as latency,limited data transfer speeds, and the risk of life loss. Edge servers offer apotential solution for real-time applications, providing localized computingand storage resources and lower response times. Unfortunately, edge servershave limited processing power. Lightweight deep learning (DL) techniques enableedge servers to utilize compressed deep neural network (DNN) models.  The research explores implementing a lightweight DL model on ArtificialIntelligence of Things (AIoT) edge devices. An optimized You Only Look Once(YOLO) based DL model is deployed for real-time pedestrian detection, withdetection events transmitted to the edge server using the Message QueuingTelemetry Transport (MQTT) protocol. The simulation results demonstrate thatthe optimized YOLO model can achieve real-time pedestrian detection, with afast inference speed of 147 milliseconds, a frame rate of 2.3 frames persecond, and an accuracy of 78%, representing significant improvements overbaseline models.</description>
      <author>example@mail.com (Muhammad Dany Alfikri, Rafael Kaliski)</author>
      <guid isPermaLink="false">2409.15740v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Models for Intelligent Transportation Systems: A Survey</title>
      <link>http://arxiv.org/abs/2409.15816v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 智能交通系统（ITS）在现代交通管理和优化中至关重要，显著提升了交通效率和安全性。2. **研究目的**:   - 本文提供了关于ITS中扩散模型的全面调查，涵盖理论和实践两个方面。3. **理论基础**:   - 介绍扩散模型的理论基础及其主要变体，包括条件扩散模型和潜在扩散模型，强调它们在建模复杂的多模态交通数据和可控生成方面的适用性。4. **面临的挑战**:   - 概述ITS中的主要挑战及扩散模型的相应优势，帮助读者深入理解ITS与扩散模型之间的交集。5. **应用实例**:   - 从多个角度探讨扩散模型在ITS领域的当前应用，包括：     - 自动驾驶     - 交通仿真     - 轨迹预测     - 交通安全6. **技术讨论**:   - 讨论最先进的扩散模型技术，并强调值得进一步研究的关键ITS研究方向。7. **研究贡献**:   - 通过结构化的概述，旨在为研究人员提供对ITS中扩散模型的全面理解，推动其在交通领域的未来应用。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intelligent Transportation Systems (ITS) are vital in modern trafficmanagement and optimization, significantly enhancing traffic efficiency andsafety. Recently, diffusion models have emerged as transformative tools foraddressing complex challenges within ITS. In this paper, we present acomprehensive survey of diffusion models for ITS, covering both theoretical andpractical aspects. First, we introduce the theoretical foundations of diffusionmodels and their key variants, including conditional diffusion models andlatent diffusion models, highlighting their suitability for modeling complex,multi-modal traffic data and enabling controllable generation. Second, weoutline the primary challenges in ITS and the corresponding advantages ofdiffusion models, providing readers with a deeper understanding of theintersection between ITS and diffusion models. Third, we offer amulti-perspective investigation of current applications of diffusion models inITS domains, including autonomous driving, traffic simulation, trajectoryprediction, and traffic safety. Finally, we discuss state-of-the-art diffusionmodel techniques and highlight key ITS research directions that warrant furtherinvestigation. Through this structured overview, we aim to provide researcherswith a comprehensive understanding of diffusion models for ITS, therebyadvancing their future applications in the transportation domain.</description>
      <author>example@mail.com (Mingxing Peng, Kehua Chen, Xusen Guo, Qiming Zhang, Hongliang Lu, Hui Zhong, Di Chen, Meixin Zhu, Hai Yang)</author>
      <guid isPermaLink="false">2409.15816v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Sparsity, Regularization and Causality in Agricultural Yield: The Case of Paddy Rice in Peru</title>
      <link>http://arxiv.org/abs/2409.17298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究目的**:   - 本研究提出一种新方法，将农业普查数据与遥感时间序列结合，开发针对秘鲁不同地区稻米产量的精确预测模型。2. **方法论**:   - 使用稀疏回归和Elastic-Net正则化技术，识别关键遥感变量（如NDVI、降水量和温度）与农业产量之间的因果关系。3. **预测精度提升**:   - 应用这些变量的一阶和二阶动态变换（速度和加速度），以捕捉非线性模式和对产量的延迟影响，从而进一步提高预测准确性。4. **研究发现**:   - 结合正则化技术与气候和地理空间变量时，预测性能显著改善，使得产量变异的预测更加精确。5. **因果关系确认**:   - 研究结果确认了Granger意义上的因果关系，强调该方法在战略农业管理中的价值。6. **实际贡献**:   - 该研究有助于提高稻米种植的生产效率和可持续性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study introduces a novel approach that integrates agricultural censusdata with remotely sensed time series to develop precise predictive models forpaddy rice yield across various regions of Peru. By utilizing sparse regressionand Elastic-Net regularization techniques, the study identifies causalrelationships between key remotely sensed variables-such as NDVI,precipitation, and temperature-and agricultural yield. To further enhanceprediction accuracy, the first- and second-order dynamic transformations(velocity and acceleration) of these variables are applied, capturingnon-linear patterns and delayed effects on yield. The findings highlight theimproved predictive performance when combining regularization techniques withclimatic and geospatial variables, enabling more precise forecasts of yieldvariability. The results confirm the existence of causal relationships in theGranger sense, emphasizing the value of this methodology for strategicagricultural management. This contributes to more efficient and sustainableproduction in paddy rice cultivation.</description>
      <author>example@mail.com (Rita Rocio Guzman-Lopez, Luis Huamanchumo, Kevin Fernandez, Oscar Cutipa-Luque, Yhon Tiahuallpa, Helder Rojas)</author>
      <guid isPermaLink="false">2409.17298v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Intention-based and Risk-Aware Trajectory Prediction for Autonomous Driving in Complex Traffic Scenarios</title>
      <link>http://arxiv.org/abs/2409.15821v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 准确预测周围车辆的轨迹是自动驾驶面临的关键挑战。2. **主要问题**:   - 当前自动驾驶系统存在两大显著问题：     - 预测的认知不确定性。     - 缺乏风险意识。   - 这些问题限制了自动驾驶技术的进一步发展。3. **研究目标**:   - 本文提出一种新颖的轨迹预测模型，结合驾驶行为、伦理决策和风险评估的洞见和原则。4. **模型组成**:   - 模型基于联合预测，包括三个模块：     - **交互模块**：捕捉车辆间动态交互。     - **意图模块**：根据交互信息考虑车辆的主要意图，增强轨迹生成的多样性。     - **风险评估模块**：优化预测轨迹，遵循先进的风险意识决策原则。5. **实验结果**:   - 在DeepAccident数据集上进行评估，模型在正常和事故场景中的预测性能显著优于最先进的算法，分别提高了28.9%和26.5%。6. **研究贡献**:   - 提出的模型提升了复杂交通场景中轨迹预测的熟练度和适应性。7. **代码分享**:   - 该模型的代码可在指定网站上获取，促进更多研究和应用。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting the trajectory of surrounding vehicles is a criticalchallenge for autonomous vehicles. In complex traffic scenarios, there are twosignificant issues with the current autonomous driving system: the cognitiveuncertainty of prediction and the lack of risk awareness, which limit thefurther development of autonomous driving. To address this challenge, weintroduce a novel trajectory prediction model that incorporates insights andprinciples from driving behavior, ethical decision-making, and risk assessment.Based on joint prediction, our model consists of interaction, intention, andrisk assessment modules. The dynamic variation of interaction between vehiclescan be comprehensively captured at each timestamp in the interaction module.Based on interaction information, our model considers primary intentions forvehicles to enhance the diversity of trajectory generation. The optimization ofpredicted trajectories follows the advanced risk-aware decision-makingprinciples. Experimental results are evaluated on the DeepAccident dataset; ourapproach shows its remarkable prediction performance on normal and accidentscenarios and outperforms the state-of-the-art algorithms by at least 28.9\%and 26.5\%, respectively. The proposed model improves the proficiency andadaptability of trajectory prediction in complex traffic scenarios. The codefor the proposed model is available athttps://sites.google.com/view/ir-prediction.</description>
      <author>example@mail.com (Wen Wei, Jiankun Wang)</author>
      <guid isPermaLink="false">2409.15821v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Pre-Finetuning with Impact Duration Awareness for Stock Movement Prediction</title>
      <link>http://arxiv.org/abs/2409.17419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NTCIR-18 FinArg-2 Dataset&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 理解新闻事件对股市影响的持续时间对有效的时间序列预测至关重要，但这一方面在当前研究中被大多忽视。2. **研究目标**:   - 本文旨在填补这一研究空白，介绍一种新数据集——影响持续时间估计数据集（IDED），专门用于基于投资者意见估计影响持续时间。3. **方法论**:   - 研究表明，使用IDED对语言模型进行预微调，可以提高基于文本的股票走势预测性能。4. **比较分析**:   - 将所提的预微调任务与情感分析预微调进行对比，进一步确认学习影响持续时间的重要性。5. **研究发现**:   - 结果突显了这一新研究方向在股票走势预测中的潜力，为金融预测提供了一条新途径。6. **数据公开**:   - 提供IDED和预微调语言模型，依据CC BY-NC-SA 4.0许可证供学术使用，以促进该领域的进一步探索。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the duration of news events' impact on the stock market iscrucial for effective time-series forecasting, yet this facet is largelyoverlooked in current research. This paper addresses this research gap byintroducing a novel dataset, the Impact Duration Estimation Dataset (IDED),specifically designed to estimate impact duration based on investor opinions.Our research establishes that pre-finetuning language models with IDED canenhance performance in text-based stock movement predictions. In addition, wejuxtapose our proposed pre-finetuning task with sentiment analysispre-finetuning, further affirming the significance of learning impact duration.Our findings highlight the promise of this novel research direction in stockmovement prediction, offering a new avenue for financial forecasting. We alsoprovide the IDED and pre-finetuned language models under the CC BY-NC-SA 4.0license for academic use, fostering further exploration in this field.</description>
      <author>example@mail.com (Chr-Jr Chiu, Chung-Chi Chen, Hen-Hsen Huang, Hsin-Hsi Chen)</author>
      <guid isPermaLink="false">2409.17419v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>FSF-Net: Enhance 4D Occupancy Forecasting with Coarse BEV Scene Flow for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2409.15841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 4D占用预测是自动驾驶中的重要技术，能够避免复杂交通场景中的潜在风险。2. **场景流的重要性**:   - 场景流是描述4D占用图趋势的关键要素，但在真实场景中准确预测场景流非常困难。3. **发现**:   - 研究发现，鸟瞰视角（BEV）场景流在大多数交通场景中可以近似表示3D场景流，且粗糙的BEV场景流易于生成。4. **方法提出**:   - 提出基于粗糙BEV场景流的4D占用预测方法FSF-Net。5. **模型架构**:   - 首先开发一个基于粗糙BEV场景流的一般占用预测架构。6. **特征表示增强**:   - 提出基于向量量化的Mamba（VQ-Mamba）网络，以挖掘时空结构场景特征，从而增强4D占用特征表示能力。7. **特征融合**:   - 设计基于U-Net的质量融合（UQF）网络，以有效融合从BEV场景流和潜在特征预测的粗糙占用图，生成细粒度的预测结果。8. **实验验证**:   - 在公共Occ3D数据集上进行大量实验，FSF-Net的IoU和mIoU分别比最先进的方法提高了9.56%和10.87%。9. **研究贡献**:   - 认为提出的FSF-Net有助于提高自动驾驶的安全性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 4D occupancy forecasting is one of the important techniques for autonomousdriving, which can avoid potential risk in the complex traffic scenes. Sceneflow is a crucial element to describe 4D occupancy map tendency. However, anaccurate scene flow is difficult to predict in the real scene. In this paper,we find that BEV scene flow can approximately represent 3D scene flow in mosttraffic scenes. And coarse BEV scene flow is easy to generate. Under thisthought, we propose 4D occupancy forecasting method FSF-Net based on coarse BEVscene flow. At first, we develop a general occupancy forecasting architecturebased on coarse BEV scene flow. Then, to further enhance 4D occupancy featurerepresentation ability, we propose a vector quantized based Mamba (VQ-Mamba)network to mine spatial-temporal structural scene feature. After that, toeffectively fuse coarse occupancy maps forecasted from BEV scene flow andlatent features, we design a U-Net based quality fusion (UQF) network togenerate the fine-grained forecasting result. Extensive experiments areconducted on public Occ3D dataset. FSF-Net has achieved IoU and mIoU 9.56% and10.87% higher than state-of-the-art method. Hence, we believe that proposedFSF-Net benefits to the safety of autonomous driving.</description>
      <author>example@mail.com (Erxin Guo, Pei An, You Yang, Qiong Liu, An-An Liu)</author>
      <guid isPermaLink="false">2409.15841v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Solar Active Regions Emergence Prediction Using Long Short-Term Memory Networks</title>
      <link>http://arxiv.org/abs/2409.17421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 8 figures, 5 tables, under review at the AAS Astrophysical
  Journal&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究目的**:   - 开发长短期记忆（LSTM）模型，以预测太阳表面活跃区域（ARs）的形成。2. **数据来源**:   - 使用来自太阳动态观测台（SDO）声波成像仪（HMI）的多种观测数据，包括多普勒位移速度、连续强度和磁场观测。3. **数据集构建**:   - 创建声学功率和磁通的时间序列数据集，用于训练LSTM模型，以预测连续强度，提前12小时。4. **模型能力**:   - 这些新型机器学习（ML）模型能够捕捉与即将出现的磁通涌现和连续强度下降相关的声学功率密度变化。5. **模型测试**:   - 在5个未见过的活跃区域数据上测试模型性能。6. **最佳模型**:   - 模型8为表现最佳的模型，能够成功预测所有测试活跃区域的出现，在实验环境中和三种操作环境中均有效。7. **具体预测结果**:   - 该模型分别提前10小时、29小时和5小时预测了AR11726、AR13165和AR13179的出现。8. **性能评估**:   - 该模型在太阳盘的活跃区和安静区的平均均方根误差（RMSE）值为0.11。9. **研究贡献**:   - 本研究为机器学习辅助的太阳活跃区域预测奠定了基础。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We developed Long Short-Term Memory (LSTM) models to predict the formation ofactive regions (ARs) on the solar surface. Using the Doppler shift velocity,the continuum intensity, and the magnetic field observations from the SolarDynamics Observatory (SDO) Helioseismic and Magnetic Imager (HMI), we havecreated time-series datasets of acoustic power and magnetic flux, which areused to train LSTM models on predicting continuum intensity, 12 hours inadvance. These novel machine learning (ML) models are able to capturevariations of the acoustic power density associated with upcoming magnetic fluxemergence and continuum intensity decrease. Testing of the models' performancewas done on data for 5 ARs, unseen from the models during training. Model 8,the best performing model trained, was able to make a successful prediction ofemergence for all testing active regions in an experimental setting and threeof them in an operational. The model predicted the emergence of AR11726,AR13165, and AR13179 respectively 10, 29, and 5 hours in advance, andvariations of this model achieved average RMSE values of 0.11 for both activeand quiet areas on the solar disc. This work sets the foundations for ML-aidedprediction of solar ARs.</description>
      <author>example@mail.com (Spiridon Kasapis, Irina N. Kitiashvili, Alexander G. Kosovichev, John T. Stefan)</author>
      <guid isPermaLink="false">2409.17421v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Robo-CSK-Organizer: Commonsense Knowledge to Organize Detected Objects for Multipurpose Robots</title>
      <link>http://arxiv.org/abs/2409.18385v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **系统介绍**:   - 本文提出一个名为Robo-CSK-Organizer的系统，通过注入经典知识库的常识知识，增强机器人对环境的识别能力，帮助以任务相关的方式组织检测到的物体。2. **应用领域**:   - 特别适用于多用途机器人，提升其在不同任务中的灵活性。3. **与现有系统的对比**:   - 与仅依赖深度学习工具（如ChatGPT）的系统相比，Robo-CSK-Organizer在多个方面表现突出：     - 有效解决模糊性问题。     - 维护物体放置的一致性。     - 适应多样化的任务分类。4. **可解释性AI的贡献**:   - 该系统有助于可解释性AI，增强信任度和人机协作。5. **实验验证**:   - 在模拟家庭机器人环境中进行的控制实验表明，Robo-CSK-Organizer在将物体放置在上下文相关的位置方面表现优越。6. **决策能力**:   - 强调AI系统在常识引导下进行决策的能力，使其更接近人类认知的阈值。7. **积极影响**:   - Robo-CSK-Organizer对AI和机器人领域产生积极影响。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a system called Robo-CSK-Organizer that infusescommonsense knowledge from a classical knowledge based to enhance the contextrecognition capabilities of robots so as to facilitate the organization ofdetected objects by classifying them in a task-relevant manner. It isparticularly useful in multipurpose robotics. Unlike systems relying solely ondeep learning tools such as ChatGPT, the Robo-CSK-Organizer system stands outin multiple avenues as follows. It resolves ambiguities well, and maintainsconsistency in object placement. Moreover, it adapts to diverse task-basedclassifications. Furthermore, it contributes to explainable AI, hence helpingto improve trust and human-robot collaboration. Controlled experimentsperformed in our work, simulating domestic robotics settings, makeRobo-CSK-Organizer demonstrate superior performance while placing objects incontextually relevant locations. This work highlights the capacity of anAI-based system to conduct commonsense-guided decision-making in roboticscloser to the thresholds of human cognition. Hence, Robo-CSK-Organizer makespositive impacts on AI and robotics.</description>
      <author>example@mail.com (Rafael Hidalgo, Jesse Parron, Aparna S. Varde, Weitian Wang)</author>
      <guid isPermaLink="false">2409.18385v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Potential Field as Scene Affordance for Behavior Change-Based Visual Risk Object Identification</title>
      <link>http://arxiv.org/abs/2409.15846v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究主题**:   - 研究基于行为变化的视觉风险对象识别（Visual-ROI），这是一个用于检测智能驾驶系统潜在危险的关键框架。2. **现有方法的局限性**:   - 当前方法在空间准确性和时间一致性方面存在显著局限，主要源于对场景可用性的理解不完整。   - 例如，现有方法经常错误地将与自车无关的车辆识别为风险对象。3. **效率问题**:   - 现有基于行为变化的方法在图像空间中实现因果推断，效率较低。4. **新框架提出**:   - 提出一种新的框架，采用鸟瞰图（BEV）表示法，以克服上述挑战。5. **潜在场作为场景可用性**:   - 利用潜在场作为场景可用性，涉及来自道路基础设施和交通参与者的排斥力，以及来自目标目的地的吸引力。6. **能量计算**:   - 通过根据BEV语义分割获得的语义标签分配不同的能量水平来计算潜在场。7. **实验与对比**:   - 进行全面的实验和消融研究，将所提方法与多种先进算法在合成和真实世界数据集上进行比较。8. **结果总结**:   - 在RiskBench数据集上，空间和时间一致性分别提高了20.3%和11.6%。   - 计算效率提高了88%。   - 在nuScenes数据集上，空间准确性提高了5.4%，时间一致性提高了7.2%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study behavior change-based visual risk object identification(Visual-ROI), a critical framework designed to detect potential hazards forintelligent driving systems. Existing methods often show significantlimitations in spatial accuracy and temporal consistency, stemming from anincomplete understanding of scene affordance. For example, these methodsfrequently misidentify vehicles that do not impact the ego vehicle as riskobjects. Furthermore, existing behavior change-based methods are inefficientbecause they implement causal inference in the perspective image space. Wepropose a new framework with a Bird's Eye View (BEV) representation to overcomethe above challenges. Specifically, we utilize potential fields as sceneaffordance, involving repulsive forces derived from road infrastructure andtraffic participants, along with attractive forces sourced from targetdestinations. In this work, we compute potential fields by assigning differentenergy levels according to the semantic labels obtained from BEV semanticsegmentation. We conduct thorough experiments and ablation studies, comparingthe proposed method with various state-of-the-art algorithms on both syntheticand real-world datasets. Our results show a notable increase in spatial andtemporal consistency, with enhancements of 20.3% and 11.6% on the RiskBenchdataset, respectively. Additionally, we can improve computational efficiency by88%. We achieve improvements of 5.4% in spatial accuracy and 7.2% in temporalconsistency on the nuScenes dataset.</description>
      <author>example@mail.com (Pang-Yuan Pao, Shu-Wei Lu, Ze-Yan Lu, Yi-Ting Chen)</author>
      <guid isPermaLink="false">2409.15846v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Speech to Reality: On-Demand Production using Natural Language, 3D Generative AI, and Discrete Robotic Assembly</title>
      <link>http://arxiv.org/abs/2409.18390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible. An updated version will replace this version&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **系统介绍**:   - 本文提出一个系统，将语音转换为物理对象，结合3D生成人工智能与机器人组装技术。2. **自然语言输入**:   - 该系统利用自然语言输入，使设计和制造变得更加可及，允许没有3D建模或机器人编程专业知识的个人创建物理对象。3. **离散机器人组装**:   - 提出利用基于晶格的体素组件的离散机器人组装，解决使用生成AI输出进行物理生产时面临的挑战，如设计变异、制造速度、结构完整性和材料浪费。4. **工作流程**:   - 系统将语音转换为3D对象，离散化为体素组件，计算优化的组装顺序，并生成机器人工具路径。5. **实验结果**:   - 通过组装各种物体（如椅子和架子）展示结果，这些物体通过语音提示，在5分钟内使用6轴机器人手臂实现。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a system that transforms speech into physical objects by combining3D generative Artificial Intelligence with robotic assembly. The systemleverages natural language input to make design and manufacturing moreaccessible, enabling individuals without expertise in 3D modeling or roboticprogramming to create physical objects. We propose utilizing discrete roboticassembly of lattice-based voxel components to address the challenges of usinggenerative AI outputs in physical production, such as design variability,fabrication speed, structural integrity, and material waste. The systeminterprets speech to generate 3D objects, discretizes them into voxelcomponents, computes an optimized assembly sequence, and generates a robotictoolpath. The results are demonstrated through the assembly of various objects,ranging from chairs to shelves, which are prompted via speech and realizedwithin 5 minutes using a 6-axis robotic arm.</description>
      <author>example@mail.com (Alexander Htet Kyaw, Se Hwan Jeon, Miana Smith, Neil Gershenfeld)</author>
      <guid isPermaLink="false">2409.18390v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Toward Scalable and Efficient Visual Data Transmission in 6G Networks</title>
      <link>http://arxiv.org/abs/2409.15961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **6G网络背景**:   - 6G网络技术将在视觉数据传输主导全球移动流量的环境中出现，预计将持续增长，受到基于AI的计算机视觉应用需求增加的推动。2. **视觉数据传输挑战**:   - 随着需求增加，视觉数据传输的任务变得更加困难。3. **技术回顾**:   - 评审有效的视觉数据传输技术，如内容压缩和自适应视频流，强调这些技术的优点和局限性。4. **云服务的可扩展性与成本问题**:   - 考虑到云基础和设备上的AI服务的可扩展性和成本问题，探讨分布式网络计算架构（如雾计算）作为6G网络的一个方向。5. **技术属性研究**:   - 调查实现视觉数据及时传输所需的技术属性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 6G network technology will emerge in a landscape where visual datatransmissions dominate global mobile traffic and are expected to growcontinuously, driven by the increasing demand for AI-based computer visionapplications. This will make already challenging task of visual datatransmission even more difficult. In this work, we review effective techniquesfor visual data transmission, such as content compression and adaptive videostreaming, highlighting their advantages and limitations. Further, consideringthe scalability and cost issues of cloud-based and on-device AI services, weexplore distributed in-network computing architecture like fog-computing as adirection of 6G networks, and investigate the necessary technical propertiesfor the timely delivery of visual data.</description>
      <author>example@mail.com (Junhao Cai, Taegun An, Changhee Joo)</author>
      <guid isPermaLink="false">2409.15961v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>From News to Forecast: Integrating Event Analysis in LLM-Based Time Series Forecasting with Reflection</title>
      <link>http://arxiv.org/abs/2409.17515v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究目的**:   - 提出一种新方法，通过大型语言模型（LLMs）和生成代理增强时间序列预测。2. **方法概述**:   - 采用语言作为媒介，动态整合各种社会事件到预测模型中，将新闻内容与时间序列波动对齐，以获取更丰富的洞察。3. **LLM代理应用**:   - 利用基于LLM的代理，迭代过滤无关新闻，并进行类人推理和反思，以评估预测结果。4. **复杂事件分析**:   - 模型能够分析复杂事件，如意外事件和社会行为变化，并持续优化新闻选择逻辑及代理输出的稳健性。5. **模型微调**:   - 将选定的新闻与时间序列数据结合，微调预训练的LLaMa2模型。6. **实验结果**:   - 结果显示预测准确性显著提高，表明通过有效利用非结构化新闻数据，可能在时间序列预测领域带来范式转变。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel approach to enhance time series forecastingusing Large Language Models (LLMs) and Generative Agents. With language as amedium, our method adaptively integrates various social events into forecastingmodels, aligning news content with time series fluctuations for enrichedinsights. Specifically, we utilize LLM-based agents to iteratively filter outirrelevant news and employ human-like reasoning and reflection to evaluatepredictions. This enables our model to analyze complex events, such asunexpected incidents and shifts in social behavior, and continuously refine theselection logic of news and the robustness of the agent's output. By compilingselected news with time series data, we fine-tune the LLaMa2 pre-trained model.The results demonstrate significant improvements in forecasting accuracy andsuggest a potential paradigm shift in time series forecasting by effectivelyharnessing unstructured news data.</description>
      <author>example@mail.com (Xinlei Wang, Maike Feng, Jing Qiu, Jinjin Gu, Junhua Zhao)</author>
      <guid isPermaLink="false">2409.17515v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>An Augmented Reality Interface for Teleoperating Robot Manipulators: Reducing Demonstrator Task Load through Digital Twin Control</title>
      <link>http://arxiv.org/abs/2409.18394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 高质量示范数据对数据驱动方法（如模仿学习）的成功至关重要。2. **现有平台问题**:   - 现有提供操作任务示范的平台通常对演示者有较高的身体和心理要求，需额外硬件或专业领域知识。3. **新接口介绍**:   - 本文提出了一种新型增强现实（AR）接口，用于远程操作机器人 manipulator，关注演示者的体验，特别是在执行需要精确度和准确性的复杂任务时。4. **技术实现**:   - 该接口专为Microsoft HoloLens 2设计，利用混合现实的适应性，使用户通过数字双胞胎代理控制物理机器人。5. **实验评估**:   - 在三个复杂操作任务中评估该方法的有效性，并与OPEN TEACH（一种最新的虚拟现实（VR）远程操作系统）以及两种传统控制方法（动觉教学和3D SpaceMouse）进行比较。6. **结果总结**:   - 研究结果表明，该AR方法与VR方法的表现相当，并展示了AR在数据收集中的潜力。7. **用户体验评估**:   - 进行了一项初步研究，以评估每种方法的可用性和任务负荷。结果显示，AR系统的可用性评分高于VR基准，显著降低了用户的心理需求、身体努力和挫败感。8. **附加资源**:   - 相关视频可在YouTube上查看，链接为 [https://youtu.be/w-M58ohPgrA](https://youtu.be/w-M58ohPgrA)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Acquiring high-quality demonstration data is essential for the success ofdata-driven methods, such as imitation learning. Existing platforms forproviding demonstrations for manipulation tasks often impose significantphysical and mental demands on the demonstrator, require additional hardwaresystems, or necessitate specialized domain knowledge. In this work, we presenta novel augmented reality (AR) interface for teleoperating roboticmanipulators, emphasizing the demonstrator's experience, particularly in thecontext of performing complex tasks that require precision and accuracy. Thisinterface, designed for the Microsoft HoloLens 2, leverages the adaptablenature of mixed reality (MR), enabling users to control a physical robotthrough digital twin surrogates. We assess the effectiveness of our approachacross three complex manipulation tasks and compare its performance againstOPEN TEACH, a recent virtual reality (VR) teleoperation system, as well as twotraditional control methods: kinesthetic teaching and a 3D SpaceMouse forend-effector control. Our findings show that our method performs comparably tothe VR approach and demonstrates the potential for AR in data collection.Additionally, we conduct a pilot study to evaluate the usability and task loadassociated with each method. Results indicate that our AR-based system achieveshigher usability scores than the VR benchmark and significantly reduces mentaldemand, physical effort, and frustration experienced by users. An accompanyingvideo can be found at https://youtu.be/w-M58ohPgrA.</description>
      <author>example@mail.com (Aliyah Smith, Monroe Kennedy III)</author>
      <guid isPermaLink="false">2409.18394v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Motion Prediction: A Lightweight &amp; Accurate Trajectory Prediction Model With Fast Training and Inference Speed</title>
      <link>http://arxiv.org/abs/2409.16154v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 高效且安全的自动驾驶要求自主车辆能够预测其他交通参与者的运动。2. **现有模型问题**:   - 当前的运动预测模型虽然准确性高，但在训练资源需求和嵌入式硬件部署方面存在显著挑战。3. **新模型提出**:   - 本文提出了一种新的高效运动预测模型，能够在短短几小时内在单个GPU上训练，并达到竞争力的基准结果。4. **架构特点**:   - 采用轻量级架构，重点减少训练资源需求，使模型能够轻松应用于自定义数据集。5. **推理延迟优势**:   - 该模型具有低推理延迟，特别适合在计算资源有限的自主应用中部署。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For efficient and safe autonomous driving, it is essential that autonomousvehicles can predict the motion of other traffic agents. While highly accurate,current motion prediction models often impose significant challenges in termsof training resource requirements and deployment on embedded hardware. Wepropose a new efficient motion prediction model, which achieves highlycompetitive benchmark results while training only a few hours on a single GPU.Due to our lightweight architectural choices and the focus on reducing therequired training resources, our model can easily be applied to customdatasets. Furthermore, its low inference latency makes it particularly suitablefor deployment in autonomous applications with limited computing resources.</description>
      <author>example@mail.com (Alexander Prutsch, Horst Bischof, Horst Possegger)</author>
      <guid isPermaLink="false">2409.16154v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>TOI-2458 b: A mini-Neptune consistent with in situ hot Jupiter formation</title>
      <link>http://arxiv.org/abs/2409.17532v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 17 figures, submitted to Astronomy &amp; Astrophysics&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **发现与确认**:   - 报告了TOI-2458 b的发现及其光谱确认，这是一颗围绕F型星的过境迷你海王星。2. **宿主星特征**:   - TOI-2458的质量为$M_\star=1.05 \pm 0.03$ M$_{\odot}$，半径为$R_\star=1.31 \pm 0.03$ R$_{\odot}$，有效温度为$T_{\rm eff}=6005 \pm 50$ K，金属丰度为$-0.10 \pm 0.05$ dex。3. **行星参数**:   - 结合TESS光度观测与HARPS光谱数据，发现该行星的公转周期约为3.74天，质量为$M_p=13.31 \pm 0.99$ M$_{\oplus}$，半径为$R_p=2.83 \pm 0.20$ R$_{\oplus}$。4. **星体活动周期**:   - TOI-2458显示出约54天的短期活动周期，该周期在HARPS S指数时间序列中得以揭示。5. **比较研究**:   - 研究了其他F型星，其活动周期与TOI-2458相似，发现这些星的自转周期比根据陀螺年代学预测的要短。6. **星体倾角**:   - 确定TOI-2458的倾角为$i_\star = 10.6_{-10.6}^{+13.3}$度。7. **现象解释**:   - 讨论了快速自转和行星轨道倾斜现象，推测可能由TOI-2458 b内部形成的热木星影响，认为该热木星可能近期被宿主星吞没。8. **其他行星发现**:   - HARPS光谱分析还发现另一颗行星，周期为$P = 16.55 \pm 0.06$天，最小质量为$M_p \sin i = 10.22 \pm 1.90$ M$_{\oplus}$。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We report on the discovery and spectroscopic confirmation of TOI-2458 b, atransiting mini-Neptune around an F-type star leaving the main-sequence with amass of $M_\star=1.05 \pm 0.03$ M$_{\odot}$, a radius of $R_\star=1.31 \pm0.03$ R$_{\odot}$, an effective temperature of $T_{\rm eff}=6005\pm50$ K, and ametallicity of $-0.10\pm0.05$ dex. By combining TESS photometry withhigh-resolution spectra acquired with the HARPS spectrograph, we found that thetransiting planet has an orbital period of $\sim$3.74 days, a mass of$M_p=13.31\pm0.99$ M$_{\oplus}$ and a radius of $R_p=2.83\pm0.20$ R$_{\oplus}$.The host star TOI-2458 shows a short activity cycle of $\sim$54 days revealedin the HARPS S-index time series. We took the opportunity to investigate otherF stars showing activity cycle periods comparable to that of TOI-2458 and foundthat they have shorter rotation periods than would be expected based on thegyrochronology predictions. In addition, we determined TOI-2458's stellarinclination angle to be $i_\star\,=\,10.6_{-10.6}^{+13.3}$ degrees. We discussthat both phenomena (fast stellar rotation and planet orbit inclination) couldbe explained by in situ formation of a hot Jupiter interior to TOI-2458 b. Itis plausible that this hot Jupiter was recently engulfed by the star. Analysisof HARPS spectra has identified the presence of another planet with a period of$P\,=\,16.55\pm0.06$ days and a minimum mass of $M_p \sin i=10.22\pm1.90$M$_{\oplus}$.</description>
      <author>example@mail.com (Ján Šubjak, Davide Gandolfi, Elisa Goffo, David Rapetti, Grzegorz Nowak, Toshiyuki Mizuki, Fei Dai, Luisa M. Serrano, Thomas G. Wilson, Dawid Jankowski, Krzysztof Goździewski, Jon M. Jenkins, Joseph D. Twicken, Joshua N. Winn, Allyson Bieryla, William D. Cochran, Karen A. Collins, Hans J. Deeg, Rafael A. García, Eike W. Guenther, Artie P. Hatzes, Petr Kabáth, Judith Korth, David W. Latham, John H. Livingston, Savita Mathur, Norio Narita, Jaume Orell-Miquel, Enric Pallé, Carina M. Persson, Seth Redfield, Richard P. Schwarz, David Watanabe, Carl Ziegler)</author>
      <guid isPermaLink="false">2409.17532v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Word2Wave: Language Driven Mission Programming for Efficient Subsea Deployments of Marine Robots</title>
      <link>http://arxiv.org/abs/2409.18405v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究目标**:   - 探索为自主水下车辆（AUVs）设计和开发基于语言的动态任务编程接口。2. **框架介绍**:   - 提出的“Word2Wave”（W2W）框架用于远程水下任务的交互式编程和参数配置。3. **W2W框架组成**:   - (i) 一套新颖的语言规则和命令结构，实现高效的语言到任务的映射。   - (ii) 基于GPT的提示工程模块，用于生成训练数据。   - (iii) 基于小型语言模型（SLM）的序列到序列学习管道，从人类语音或文本生成任务命令。   - (iv) 新颖的用户界面，用于2D任务地图可视化和人机交互。4. **学习管道**:   - 使用名为T5-Small的SLM，能够有效地从处理过的语言数据中学习语言到任务的映射，提供稳健且高效的性能。5. **评估方法**:   - 除了与最先进的技术进行基准评估外，还进行用户交互研究，以展示W2W相较于商业AUV编程接口的有效性。6. **实证结果**:   - 参与者使用W2W编程的时间少于传统接口的10%，被认为是更简单、更自然的水下任务编程范式，用户可用性评分为76.25。7. **未来研究机会**:   - W2W为无手动AUV任务编程提供了有前景的未来研究机会，以提高水下部署的效率。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the design and development of a language-based interfacefor dynamic mission programming of autonomous underwater vehicles (AUVs). Theproposed 'Word2Wave' (W2W) framework enables interactive programming andparameter configuration of AUVs for remote subsea missions. The W2W frameworkincludes: (i) a set of novel language rules and command structures forefficient language-to-mission mapping; (ii) a GPT-based prompt engineeringmodule for training data generation; (iii) a small language model (SLM)-basedsequence-to-sequence learning pipeline for mission command generation fromhuman speech or text; and (iv) a novel user interface for 2D mission mapvisualization and human-machine interfacing. The proposed learning pipelineadapts an SLM named T5-Small that can learn language-to-mission mapping fromprocessed language data effectively, providing robust and efficientperformance. In addition to a benchmark evaluation with state-of-the-art, weconduct a user interaction study to demonstrate the effectiveness of W2W overcommercial AUV programming interfaces. Across participants, W2W-basedprogramming required less than 10% time for mission programming compared totraditional interfaces; it is deemed to be a simpler and more natural paradigmfor subsea mission programming with a usability score of 76.25. W2W opens uppromising future research opportunities on hands-free AUV mission programmingfor efficient subsea deployments.</description>
      <author>example@mail.com (Ruo Chen, David Blow, Adnan Abdullah, Md Jahidul Islam)</author>
      <guid isPermaLink="false">2409.18405v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>A Universal Multi-Vehicle Cooperative Decision-Making Approach in Structured Roads by Mixed-Integer Potential Game</title>
      <link>http://arxiv.org/abs/2409.16190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 由于现实世界道路拓扑的复杂性和自动驾驶车辆的固有复杂性，多个联网自动驾驶车辆（CAVs）的协同决策仍然是一个重大挑战。2. **现有方法局限**:   - 目前大多数方法针对特定场景，现有的优化和学习方法在不同场景下的效率受到建模复杂性和数据依赖性的限制，影响其在实际中的应用。3. **研究目标**:   - 本文提出一种基于博弈理论的通用多车辆协同决策方法，适用于结构化道路。4. **决策问题转化**:   - 将决策问题转化为在路点图框架内的图路径搜索问题。5. **问题形式化**:   - 首先将问题形式化为混合整数线性规划问题（MILP），然后转化为混合整数潜在博弈（MIPG），从而缩小问题范围，确保各参与者不需为整体成本妥协。6. **求解算法**:   - 提出了两种高斯-赛德尔算法用于协同决策，以解决MIPG问题并获得纳什均衡解。7. **算法特性**:   - 特别地，序列高斯-赛德尔算法考虑了CAV交互的不同程度和调整策略的灵活性，以确定优化优先级，从而减少无效优化的频率。8. **实验评估**:   - 在不同拓扑结构的城市交通场景中进行的实验评估表明，所提方法在有效性和效率上优于MILP。9. **效率验证**:   - 不同优化序列的比较验证了序列高斯-赛德尔算法在协同决策中的效率。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the intricate of real-world road topologies and the inherentcomplexity of autonomous vehicles, cooperative decision-making for multipleconnected autonomous vehicles (CAVs) remains a significant challenge.Currently, most methods are tailored to specific scenarios, and the efficiencyof existing optimization and learning methods applicable to diverse scenariosis hindered by the complexity of modeling and data dependency, which limittheir real-world applicability. To address these issues, this paper proposes auniversal multi-vehicle cooperative decision-making method in structured roadswith game theory. We transform the decision-making problem into a graph pathsearching problem within a way-point graph framework. The problem is formulatedas a mixed-integer linear programming problem (MILP) first and transformed intoa mixed-integer potential game (MIPG), which reduces the scope of problem andensures that no player needs to sacrifice for the overall cost. TwoGauss-Seidel algorithms for cooperative decision-making are presented to solvethe MIPG problem and obtain the Nash equilibrium solutions. Specifically, thesequential Gauss-Seidel algorithm for cooperative decision-making considers thevarying degrees of CAV interactions and flexibility in adjustment strategies todetermine optimization priorities, which reduces the frequency of ineffectiveoptimizations. Experimental evaluations across various urban traffic scenarioswith different topological structures demonstrate the effectiveness andefficiency of the proposed method compared with MILP and comparisons ofdifferent optimization sequences validate the efficiency of the sequentialGauss-Seidel algorithm for cooperative decision-making.</description>
      <author>example@mail.com (Chengzhen Meng, Zhenmin Huang, Jun Ma)</author>
      <guid isPermaLink="false">2409.16190v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>A novel application of Shapley values for large multidimensional time-series data: Applying explainable AI to a DNA profile classification neural network</title>
      <link>http://arxiv.org/abs/2409.18156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 在高维时间序列数据上应用Shapley值计算具有计算挑战性，尤其是对于$N$个输入，问题的复杂度为$2^N$。2. **图像处理中的方法**:   - 在图像处理中，通过使用像素聚类（称为超像素）来简化计算。3. **研究目标**:   - 本研究提出了一种高效解决方案，将超像素的概念应用于时间序列数据的Shapley值计算。4. **应用实例**:   - 以法医DNA分类为例，展示该方法在多变量时间序列数据上的应用，这些特征已通过卷积神经网络（CNN）进行分类。5. **DNA处理中的挑战**:   - 在DNA处理过程中，需要从提取和处理过程中产生的背景噪声中识别等位基因。6. **数据规模**:   - 单个DNA分析包含$31,200$个扫描点，分类决策需要在法律上具有可辩性，通常由人工读取，耗时巨大。7. **CNN的应用优势**:   - 使用CNN与快速计算有意义的Shapley值，为分类提供了一种潜在的替代方案。8. **研究成果**:   - 本研究展示了对这一庞大任务的Shapley值进行现实、准确和快速计算的可行性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The application of Shapley values to high-dimensional, time-series-like datais computationally challenging - and sometimes impossible. For $N$ inputs theproblem is $2^N$ hard. In image processing, clusters of pixels, referred to assuperpixels, are used to streamline computations. This research presents anefficient solution for time-seres-like data that adapts the idea of superpixelsfor Shapley value computation. Motivated by a forensic DNA classificationexample, the method is applied to multivariate time-series-like data whosefeatures have been classified by a convolutional neural network (CNN). In DNAprocessing, it is important to identify alleles from the background noisecreated by DNA extraction and processing. A single DNA profile has $31,200$scan points to classify, and the classification decisions must be defensible ina court of law. This means that classification is routinely performed by humanreaders - a monumental and time consuming process. The application of a CNNwith fast computation of meaningful Shapley values provides a potentialalternative to the classification. This research demonstrates the realistic,accurate and fast computation of Shapley values for this massive task</description>
      <author>example@mail.com (Lauren Elborough, Duncan Taylor, Melissa Humphries)</author>
      <guid isPermaLink="false">2409.18156v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>BoT-Drive: Hierarchical Behavior and Trajectory Planning for Autonomous Driving using POMDPs</title>
      <link>http://arxiv.org/abs/2409.18411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 动态道路环境中的不确定性对自动驾驶中的行为和轨迹规划构成了重大挑战。2. **引入算法**:   - 本文介绍了BoT-Drive，一种规划算法，旨在在部分可观察的马尔可夫决策过程（POMDP）框架内解决不确定性问题。3. **驾驶员模型应用**:   - BoT-Drive利用驾驶员模型来表征未知的行为意图，并利用其模型参数推断隐藏的驾驶风格。4. **决策机制**:   - 将驾驶员模型视为自动驾驶车辆的决策行动，BoT-Drive有效应对POMDP中的指数复杂性。5. **安全性与鲁棒性增强**:   - 规划器进一步应用重要性采样，基于规划的高层行为优化驾驶轨迹，以提高安全性和鲁棒性。6. **性能评估**:   - 在真实世界数据上的评估显示，BoT-Drive在常规和复杂城市驾驶场景中，始终优于现有的规划方法和基于学习的方法。7. **改进效果**:   - BoT-Drive在驾驶安全性和可靠性方面表现出显著的改善。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Uncertainties in dynamic road environments pose significant challenges forbehavior and trajectory planning in autonomous driving. This paper introducesBoT-Drive, a planning algorithm that addresses uncertainties at both behaviorand trajectory levels within a Partially Observable Markov Decision Process(POMDP) framework. BoT-Drive employs driver models to characterize unknownbehavioral intentions and utilizes their model parameters to infer hiddendriving styles. By also treating driver models as decision-making actions forthe autonomous vehicle, BoT-Drive effectively tackles the exponentialcomplexity inherent in POMDPs. To enhance safety and robustness, the plannerfurther applies importance sampling to refine the driving trajectoryconditioned on the planned high-level behavior. Evaluation on real-world datashows that BoT-Drive consistently outperforms both existing planning methodsand learning-based methods in regular and complex urban driving scenes,demonstrating significant improvements in driving safety and reliability.</description>
      <author>example@mail.com (Xuanjin Jin, Chendong Zeng, Shengfa Zhu, Chunxiao Liu, Panpan Cai)</author>
      <guid isPermaLink="false">2409.18411v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Twinning Commercial Network Traces on Experimental Open RAN Platforms</title>
      <link>http://arxiv.org/abs/2409.16217v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 10 figures, 4 tables. Accepted for publication in the
  Proceedings of 18th ACM Workshop on Wireless Network Testbeds, Experimental
  Evaluation &amp; Characterization (WiNTECH '24)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 大型数据集的可用性推动了计算机视觉和自然语言处理等领域的发展，但在移动网络领域却面临数据不足的问题。2. **数据可用性问题**:   - 移动流量数据常因隐私或法规问题而不可得，这在开放无线接入网络（Open RAN）中尤为突出。3. **人工智能在RAN中的应用**:   - 尽管人工智能有潜力优化和控制RAN，但因缺乏训练数据集，其应用仍滞后。4. **现有工作局限**:   - 尽管已有大量工作致力于开发准确反映生产环境的测试平台，但在模拟网络流量方面的努力不足。5. **研究目的**:   - 本文旨在设计一种方法，以在实验性的Open RAN测试平台中模拟真实世界的蜂窝流量轨迹。6. **方法展示**:   - 在Colosseum Open RAN数字双胞胎上演示所提方法，并公开发布一个大型数据集（超过500小时，450 GB），包括物理层（PHY）、媒介接入层（MAC）和应用层（App）关键性能测量（KPMs）及协议栈日志。7. **数据集的应用**:   - 我们的分析表明，该数据集可用于开发和评估多个Open RAN用例，特别是那些对延迟要求严格的场景。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3636534.3697320&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While the availability of large datasets has been instrumental to advancefields like computer vision and natural language processing, this has not beenthe case in mobile networking. Indeed, mobile traffic data is often unavailabledue to privacy or regulatory concerns. This problem becomes especially relevantin Open Radio Access Network (RAN), where artificial intelligence canpotentially drive optimization and control of the RAN, but still lags behinddue to the lack of training datasets. While substantial work has focused ondeveloping testbeds that can accurately reflect production environments, thesame level of effort has not been put into twinning the traffic that traversesuch networks. To fill this gap, in this paper, we design a methodology to twinreal-world cellular traffic traces in experimental Open RAN testbeds. Wedemonstrate our approach on the Colosseum Open RAN digital twin, and publiclyrelease a large dataset (more than 500 hours and 450 GB) with PHY-, MAC-, andApp-layer Key Performance Measurements (KPMs), and protocol stack logs. Ouranalysis shows that our dataset can be used to develop and evaluate a number ofOpen RAN use cases, including those with strict latency requirements.</description>
      <author>example@mail.com (Leonardo Bonati, Ravis Shirkhani, Claudio Fiandrino, Stefano Maxenti, Salvatore D'Oro, Michele Polese, Tommaso Melodia)</author>
      <guid isPermaLink="false">2409.16217v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>PGN: The RNN's New Successor is Effective for Long-Range Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2409.17703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 循环神经网络（RNN）的递归结构导致信息传播路径长，限制了其捕捉长期依赖能力，并引发梯度爆炸/消失问题，且顺序执行效率低下。2. **新提出的模型**:   - 提出了“并行门控网络”（PGN），作为RNN的新继任者，旨在克服上述限制。3. **PGN的设计**:   - PGN通过设计的历史信息提取（HIE）层直接从前一个时间步骤捕捉信息，并利用门控机制选择和融合当前时间步骤的信息。4. **信息传播路径优化**:   - 将信息传播路径减少到$\mathcal{O}(1)$，有效解决了RNN的局限性。5. **增强性能的框架**:   - 提出了“时间PGN”（TPGN）作为PGN的时间建模框架，包含两个分支以全面捕捉时间序列的语义信息。6. **两个分支功能**:   - 一个分支利用PGN捕捉长期周期模式并保留其局部特征；另一个分支通过补丁捕捉短期信息并聚合全球表示。7. **复杂性和效率**:   - TPGN实现了理论复杂性为$\mathcal{O}(\sqrt{L})$，确保操作的高效性。8. **实验结果**:   - 在五个基准数据集上的实验结果证明了TPGN的最新性能和高效率，进一步确认了PGN作为RNN的有效继任者在长期时间序列预测中的有效性。9. **代码可用性**:   - 相关代码可在GitHub仓库中获取：[TPGN代码仓库](https://github.com/Water2sea/TPGN)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/water2sea/tpgn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to the recurrent structure of RNN, the long information propagation pathposes limitations in capturing long-term dependencies, gradientexplosion/vanishing issues, and inefficient sequential execution. Based onthis, we propose a novel paradigm called Parallel Gated Network (PGN) as thenew successor to RNN. PGN directly captures information from previous timesteps through the designed Historical Information Extraction (HIE) layer andleverages gated mechanisms to select and fuse it with the current time stepinformation. This reduces the information propagation path to $\mathcal{O}(1)$,effectively addressing the limitations of RNN. To enhance PGN's performance inlong-range time series forecasting tasks, we propose a novel temporal modelingframework called Temporal PGN (TPGN). TPGN incorporates two branches tocomprehensively capture the semantic information of time series. One branchutilizes PGN to capture long-term periodic patterns while preserving theirlocal characteristics. The other branch employs patches to capture short-terminformation and aggregate the global representation of the series. TPGNachieves a theoretical complexity of $\mathcal{O}(\sqrt{L})$, ensuringefficiency in its operations. Experimental results on five benchmark datasetsdemonstrate the state-of-the-art (SOTA) performance and high efficiency ofTPGN, further confirming the effectiveness of PGN as the new successor to RNNin long-range time series forecasting. The code is available in thisrepository: \url{https://github.com/Water2sea/TPGN}.</description>
      <author>example@mail.com (Yuxin Jia, Youfang Lin, Jing Yu, Shuo Wang, Tianhao Liu, Huaiyu Wan)</author>
      <guid isPermaLink="false">2409.17703v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Get It For Free: Radar Segmentation without Expert Labels and Its Application in Odometry and Localization</title>
      <link>http://arxiv.org/abs/2409.18434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究目标**:   - 本文提出了一种新颖的弱监督语义分割方法，用于雷达分割。2. **方法概述**:   - 利用现有的LiDAR语义分割模型生成语义标签，这些标签作为训练雷达语义分割模型的监督信号。3. **性能比较**:   - 得到的雷达语义分割模型在所有天气条件下表现优于基于LiDAR的模型，尤其在雪、雨和雾等恶劣天气中提供更一致和稳健的分割结果。4. **错误修正方案**:   - 为了减轻LiDAR语义标签可能出现的错误，设计了专门的修正方案，基于结构特征和分布模式修正错误标签。5. **下游任务应用**:   - 雷达分割模型生成的语义信息用于两个下游任务，显著提升了性能。6. **定位任务**:   - 在基于雷达的大规模定位中，相较于之前的方法，定位误差减少了20.55%。7. **里程计任务**:   - 在里程计任务中，与第二好的方法相比，翻译精度提高了16.4%，并在2024年ICRA的雷达机器人研讨会上获得雷达里程计竞赛第一名。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a novel weakly supervised semantic segmentation methodfor radar segmentation, where the existing LiDAR semantic segmentation modelsare employed to generate semantic labels, which then serve as supervisionsignals for training a radar semantic segmentation model. The obtained radarsemantic segmentation model outperforms LiDAR-based models, providing moreconsistent and robust segmentation under all-weather conditions, particularlyin the snow, rain and fog. To mitigate potential errors in LiDAR semanticlabels, we design a dedicated refinement scheme that corrects erroneous labelsbased on structural features and distribution patterns. The semanticinformation generated by our radar segmentation model is used in two downstreamtasks, achieving significant performance improvements. In large-scaleradar-based localization using OpenStreetMap, it leads to localization errorreduction by 20.55\% over prior methods. For the odometry task, it improvestranslation accuracy by 16.4\% compared to the second-best method, securing thefirst place in the radar odometry competition at the Radar in Robotics workshopof ICRA 2024, Japan</description>
      <author>example@mail.com (Siru Li, Ziyang Hong, Yushuai Chen, Liang Hu, Jiahu Qin)</author>
      <guid isPermaLink="false">2409.18434v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Bound-preserving OEDG schemes for Aw-Rascle-Zhang traffic models on networks</title>
      <link>http://arxiv.org/abs/2409.16269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 物理解必须满足正密度和速度$v$及其他Riemann不变量的最小和最大原则，这对于广泛使用的Aw-Rascle-Zhang（ARZ）交通模型及其改进的压力（AP）ARZ模型至关重要。2. **现有问题**:   - 许多数值方案因违反这些界限而导致不稳定，目前唯一的界限保持（BP）数值方案（针对ARZ模型）是随机的，仅为一阶精度且不严格保守。3. **研究贡献**:   - 本文引入了任意高阶的可证明BP的DG（动态有限元）方案，能够保持上述所有界限，除了速度$v$的最大原则，后者与数值方案的一致性和保守性相冲突。4. **替代约束**:   - 尽管未直接强制执行$v$的最大原则，严格保持的另一个Riemann不变量$w$的最大原则实际上为$v$提供了替代上界。5. **BP属性分析**:   - 分析和严格证明BP特性是一个特别复杂的任务：Lax-Friedrichs（LF）分裂属性通常适用于双曲守恒定律，但在这两种模型中并不适用。6. **解决方案**:   - 为了克服这一挑战，提出了LF分裂属性的广义版本，并通过几何准线性化（GQL）方法进行证明。7. **抑制振荡**:   - 为了抑制DG解中的虚假振荡，采用了最近提出的振荡消除（OE）技术，该技术基于新型阻尼方程的解算子。8. **数值示例**:   - 包含多个数值示例，以展示所提出方案的有效性、准确性和BP特性，并应用于道路网络的交通模拟。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Physical solutions to the widely used Aw-Rascle-Zhang (ARZ) traffic model andthe adapted pressure (AP) ARZ model should satisfy the positivity of density,the minimum and maximum principles with respect to the velocity $v$ and otherRiemann invariants. Many numerical schemes suffer from instabilities caused byviolating these bounds, and the only existing bound-preserving (BP) numericalscheme (for ARZ model) is random, only first-order accurate, and not strictlyconservative. This paper introduces arbitrarily high-order provably BP DGschemes for these two models, preserving all the aforementioned bounds exceptthe maximum principle of $v$, which has been rigorously proven to conflict withthe consistency and conservation of numerical schemes. Although the maximumprinciple of $v$ is not directly enforced, we find that the strictly preservedmaximum principle of another Riemann invariant $w$ actually enforces analternative upper bound on $v$. At the core of this work, analyzing andrigorously proving the BP property is a particularly nontrivial task: theLax-Friedrichs (LF) splitting property, usually expected for hyperbolicconservation laws and employed to construct BP schemes, does not hold for thesetwo models. To overcome this challenge, we formulate a generalized version ofthe LF splitting property, and prove it via the geometric quasilinearization(GQL) approach [Kailiang Wu and Chi-Wang Shu, SIAM Review, 65: 1031-1073,2023]. To suppress spurious oscillations in the DG solutions, we employ theoscillation-eliminating (OE) technique, recently proposed in [Manting Peng,Zheng Sun, and Kailiang Wu, Mathematics of Computation, in press], which isbased on the solution operator of a novel damping equation. Several numericalexamples are included to demonstrate the effectiveness, accuracy, and BPproperties of our schemes, with applications to traffic simulations on roadnetworks.</description>
      <author>example@mail.com (Wei Chen, Shumo Cui, Kailiang Wu, Tao Xiong)</author>
      <guid isPermaLink="false">2409.16269v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Stationarity of Manifold Time Series</title>
      <link>http://arxiv.org/abs/2409.17706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 随着现代跨学科研究的发展，多维时间序列数据受到越来越多的关注。2. **关键问题**:   - 分析此类数据时，一个重要问题是“平稳性”，它反映了潜在的动态行为，对细胞生物学、神经科学和实证金融等多个领域至关重要。3. **研究缺口**:   - 目前缺乏针对多维时间序列的正式平稳性定义。4. **研究贡献**:   - 本文提出了多维时间序列的首个**一阶平稳性**和**二阶平稳性**定义，填补了这一空白。5. **统计方法开发**:   - 开发了新的统计程序以检验多维时间序列的平稳性，并研究其渐近性质。6. **方法优势**:   - 这些方法考虑了流形的曲率特性，使分析比在欧几里得空间中更为复杂。7. **效果评估**:   - 通过数值模拟评估方法的有效性，并通过分析一项来自《Cell》的细胞类型比例时间序列数据集展示其实用价值。8. **结果一致性**:   - 一阶平稳性检验结果与该论文的生物学发现一致，而二阶平稳性检验则为其中一个关键假设提供了数值支持。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In modern interdisciplinary research, manifold time series data have beengarnering more attention. A critical question in analyzing such data is``stationarity'', which reflects the underlying dynamic behavior and is crucialacross various fields like cell biology, neuroscience and empirical finance.Yet, there has been an absence of a formal definition of stationarity that istailored to manifold time series. This work bridges this gap by proposing thefirst definitions of first-order and second-order stationarity for manifoldtime series. Additionally, we develop novel statistical procedures to test thestationarity of manifold time series and study their asymptotic properties. Ourmethods account for the curved nature of manifolds, leading to a more intricateanalysis than that in Euclidean space. The effectiveness of our methods isevaluated through numerical simulations and their practical merits aredemonstrated through analyzing a cell-type proportion time series dataset froma paper recently published in Cell. The first-order stationarity test resultaligns with the biological findings of this paper, while the second-orderstationarity test provides numerical support for a critical assumption madetherein.</description>
      <author>example@mail.com (Junhao Zhu, Dehan Kong, Zhaolei Zhang, Zhenhua Lin)</author>
      <guid isPermaLink="false">2409.17706v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Exploiting Physical Human-Robot Interaction to Provide a Unique Rolling Experience with a Riding Ballbot</title>
      <link>http://arxiv.org/abs/2409.18452v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 本研究介绍了为骑乘球形机器人（ballbot）开发的免手控制方案，旨在允许骑乘者（包括手动轮椅用户）通过身体倾斜和扭转来控制其运动。2. **硬件平台**:   - 使用的硬件平台为个人独特滚动体验（PURE），该平台采用球形机器人驱动系统，能够提供全向机动性。3. **控制方案适应性**:   - 为了适应不同身体运动功能的用户，免手控制方案需根据骑乘者的身体功能和个人偏好进行调整。4. **控制概念**:   - 整合了（a）阻抗控制和（b）导纳控制的概念进控制方案中。5. **优化框架**:   - 使用双代理优化框架评估骑乘者与球形机器人系统在安全关键任务（如以1.4 m/s的速度制动）的效率。6. **实验证明**:   - 将候选控制方案实施到物理机器人硬件中，并与两名经验丰富的用户进行验证，展示了免手导纳控制方案（HACS）的效率和鲁棒性。7. **性能改进**:   - HACS接口通过物理人机交互（pHRI）作为输入，导致更低的制动努力和更短的制动距离及时间。8. **新用户测试**:   - 招募12名新用户（包括六名健全用户和六名手动轮椅用户），评估HACS的制动性能，涵盖不同的身体运动能力。9. **导航能力展示**:   - 在模拟狭窄走廊、急转弯和静态及动态障碍物的课程中，进一步展示了PURE的室内导航能力。10. **研究意义**:    - 利用pHRI，提出的导纳风格控制方案有效地通过身体动作控制球形机器人，为手动轮椅用户提供安全灵活的室内导航，带来个人独特的滚动体验。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study introduces the development of hands-free control schemes for ariding ballbot, designed to allow riders including manual wheelchair users tocontrol its movement through torso leaning and twisting. The hardware platform,Personal Unique Rolling Experience (PURE), utilizes a ballbot drivetrain, adynamically stable mobile robot that uses a ball as its wheel to provideomnidirectional maneuverability. To accommodate users with varying torso motionfunctions, the hanads-free control scheme should be adjustable based on therider's torso function and personal preferences. Therefore, concepts of (a)impedance control and (b) admittance control were integrated into the controlscheme. A duo-agent optimization framework was utilized to assess theefficiency of this rider-ballbot system for a safety-critical task: brakingfrom 1.4 m/s. The candidate control schemes were further implemented in thephysical robot hardware and validated with two experienced users, demonstratingthe efficiency and robustness of the hands-free admittance control scheme(HACS). This interface, which utilized physical human-robot interaction (pHRI)as the input, resulted in lower braking effort and shorter braking distance andtime. Subsequently, 12 novice participants (six able-bodied users and sixmanual wheelchair users) with different levels of torso motion capability werethen recruited to benchmark the braking performance with HACS. The indoornavigation capability of PURE was further demonstrated with these participantsin courses simulating narrow hallways, tight turns, and navigation throughstatic and dynamic obstacles. By exploiting pHRI, the proposed admittance-stylecontrol scheme provided effective control of the ballbot via torso motions.This interface enables PURE to provide a personal unique rolling experience tomanual wheelchair users for safe and agile indoor navigation.</description>
      <author>example@mail.com (Chenzhang Xiao, Seung Yun Song, Yu Chen, Mahshid Mansouri, João Ramos, Adam W. Bleakney, William R. Norris, Elizabeth T. Hsiao-Wecksler)</author>
      <guid isPermaLink="false">2409.18452v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Granger Causality for Mixed Time Series Generalized Linear Models: A Case Study on Multimodal Brain Connectivity</title>
      <link>http://arxiv.org/abs/2409.17751v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper submitted for publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究动机**:   - 本研究源于神经科学实验，旨在理解脑网络中节点之间的相互作用，采用不同类型的数据模态捕捉脑活动的不同方面。2. **Granger因果关系评估**:   - 引入一个灵活的框架，通过一类通用模型，适应混合类型的数据（包括二元、计数、连续和正分量），以广义线性模型（GLM）的形式进行建模。3. **统计推断方法**:   - 基于频率主义和贝叶斯方法进行因果关系的统计推断，重点关注后者。4. **推断程序开发**:   - 开发了一种通过提出的贝叶斯混合时间序列模型进行推断的程序，采用尖峰和板条先验处理模型中的某些参数。5. **因果顺序选择**:   - 该推断方法指导因果顺序选择，并提供恰当的不确定性量化。6. **应用实例**:   - 方法用于研究在嗅觉工作记忆任务中记录的老鼠尖峰列和局部场电位（LFP）数据。7. **关键发现**:   - 提供了老鼠尖峰活动与LFP谱功率之间因果关系的重要见解，特别是LFP β波段的功率可预测300毫秒后的尖峰活动。8. **研究意义**:   - 提供了一种新颖的分析工具，展示了其在神经科学新兴研究领域的实用性和灵活性，并在因果关系研究中具有广泛应用潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper is motivated by studies in neuroscience experiments to understandinteractions between nodes in a brain network using different types of datamodalities that capture different distinct facets of brain activity. To assessGranger-causality, we introduce a flexible framework through a general class ofmodels that accommodates mixed types of data (binary, count, continuous, andpositive components) formulated in a generalized linear model (GLM) fashion.Statistical inference for causality is performed based on both frequentist andBayesian approaches, with a focus on the latter. Here, we develop a procedurefor conducting inference through the proposed Bayesian mixed time series model.By introducing spike and slab priors for some parameters in the model, ourinferential approach guides causality order selection and provides properuncertainty quantification. The proposed methods are then utilized to study therat spike train and local field potentials (LFP) data recorded during theolfaction working memory task. The proposed methodology provides criticalinsights into the causal relationship between the rat spiking activity and LFPspectral power. Specifically, power in the LFP beta band is predictive ofspiking activity 300 milliseconds later, providing a novel analytical tool forthis area of emerging interest in neuroscience and demonstrating its usefulnessand flexibility in the study of causality in general.</description>
      <author>example@mail.com (Luiza S. C. Piancastelli, Wagner Barreto-Souza, Norbert J. Fortin, Keiland W. Cooper, Hernando Ombao)</author>
      <guid isPermaLink="false">2409.17751v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Entropic selection of magnetization in a frustrated 2D magnetic model</title>
      <link>http://arxiv.org/abs/2409.17793v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures, submitted to Phys Rev B Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究主题**:   - 讨论了一种受挫的二维经典海森堡模型，该模型涉及相互作用的六角形自旋簇的磁性基态及其性质。2. **能量计算**:   - 精确计算了任意值的$J_1$（簇内耦合）和$J_2$（簇间耦合）下基态的能量。3. **主要结果**:   - 在相图的受挫区域，基态的集合具有比全局旋转对称性导致的更大的简并性。4. **磁化特性**:   - 基态的多样性并没有固定的总磁化值，而是存在一系列允许的值。5. **有限温度效应**:   - 通过蒙特卡洛模拟显示，熵选择了总磁化的最可能值，同时蒙特卡洛时间序列的直方图呈现非平凡的特征。6. **研究意义**:   - 该模型是对由耦合自旋簇组成的一类受挫磁性结构特性建模的第一步。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We discuss the magnetic ground state and properties of a frustratedtwo-dimensional classical Heisenberg model of interacting hexagonal clusters ofspins. The energy of the ground states is found exactly for arbitrary values of$J_1$ (intra-cluster couplings) and $J_2$ (inter-cluster couplings). Our mainresults concern a frustrated region of the phase diagram, where we show thatthe set of ground states has a degeneracy larger than that due to globalrotation symmetry. Furthermore, the ground state manifold does not have a fixedtotal magnetization~: there is a range of allowed values. At finitetemperature, our Monte-Carlo simulations show that the entropy selects the mostprobable value of the total magnetization, while the histogram of theMonte-Carlo time series is non-trivial. This model is a first step towardsmodelling properties of a class of frustrated magnetic structures composed ofcoupled spin clusters.</description>
      <author>example@mail.com (Anuradha Jagannathan, Thierry Jolicoeur)</author>
      <guid isPermaLink="false">2409.17793v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Generative Pre-trained Ranking Model with Over-parameterization at Web-Scale (Extended Abstract)</title>
      <link>http://arxiv.org/abs/2409.16594v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 学习排序（LTR）广泛应用于网页搜索中，以根据输入查询优先显示相关网页。2. **主要挑战**:   - 传统LTR模型面临两个主要障碍：     1. 缺乏良好注释的查询-网页对及其覆盖多样搜索查询流行度的排名分数，影响了模型对不同流行度查询的处理能力。     2. 模型训练不足，无法产生广泛的LTR表示，导致过拟合。3. **提出的新模型**:   - 为了解决这些挑战，提出了**生成式半监督预训练（GS2P）LTR模型**。4. **实验验证**:   - 在一个公开可用的数据集和一个从大型搜索引擎收集的真实数据集上进行了广泛的离线实验。5. **实际应用**:   - 将GS2P部署在一个大型网页搜索引擎中，处理现实流量，观察到显著的改进效果。6. **成果总结**:   - 研究表明GS2P模型在实际应用中有效提升了LTR性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning to rank (LTR) is widely employed in web searches to prioritizepertinent webpages from retrieved content based on input queries. However,traditional LTR models encounter two principal obstacles that lead tosuboptimal performance: (1) the lack of well-annotated query-webpage pairs withranking scores covering a diverse range of search query popularities, whichhampers their ability to address queries across the popularity spectrum, and(2) inadequately trained models that fail to induce generalized representationsfor LTR, resulting in overfitting. To address these challenges, we propose a\emph{\uline{G}enerative \uline{S}emi-\uline{S}upervised \uline{P}re-trained}(GS2P) LTR model. We conduct extensive offline experiments on both a publiclyavailable dataset and a real-world dataset collected from a large-scale searchengine. Furthermore, we deploy GS2P in a large-scale web search engine withrealistic traffic, where we observe significant improvements in the real-worldapplication.</description>
      <author>example@mail.com (Yuchen Li, Haoyi Xiong, Linghe Kong, Jiang Bian, Shuaiqiang Wang, Guihai Chen, Dawei Yin)</author>
      <guid isPermaLink="false">2409.16594v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>DynaWeightPnP: Toward global real-time 3D-2D solver in PnP without correspondences</title>
      <link>http://arxiv.org/abs/2409.18457v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究主题**:   - 本文探讨一种特殊的视角-n-点（PnP）问题：在没有对应关系的情况下实时估计3D和2D形状的最佳姿态，称为无对应PnP。2. **研究挑战**:   - 尽管已有许多研究关注3D和2D形状配准，实现实时和高准确性的性能仍然具有挑战性。3. **目标任务**:   - 本研究专门针对3D-2D几何形状配准任务，应用最近开发的再生核希尔伯特空间（RKHS）来解决“大到小”的问题。4. **解决方法**:   - 采用迭代重加权最小二乘法有效地解决基于RKHS的公式。5. **观测性问题**:   - 识别出无对应PnP中的一个独特观测性问题：旋转和位移之间的数值模糊性。6. **新方法提出**:   - 提出了DynaWeightPnP，引入动态加权子问题和替代搜索算法，以增强姿态估计和对齐精度。7. **实验背景**:   - 在典型案例中进行实验，即在内血管图像引导干预（EIGIs）中进行3D-2D血管中心线配准任务。8. **实验结果**:   - 结果表明，提出的算法在现代单核CPU上实现了60 Hz（无后期优化）和31 Hz（有后期优化）的注册处理速率，且准确性与现有方法相当。9. **应用前景**:   - 这些结果强调了DynaWeightPnP在未来机器人导航任务（如EIGIs）中的适用性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses a special Perspective-n-Point (PnP) problem: estimatingthe optimal pose to align 3D and 2D shapes in real-time withoutcorrespondences, termed as correspondence-free PnP. While several studies havefocused on 3D and 2D shape registration, achieving both real-time and accurateperformance remains challenging. This study specifically targets the 3D-2Dgeometric shape registration tasks, applying the recently developed ReproducingKernel Hilbert Space (RKHS) to address the "big-to-small" issue. An iterativereweighted least squares method is employed to solve the RKHS-based formulationefficiently. Moreover, our work identifies a unique and interestingobservability issue in correspondence-free PnP: the numerical ambiguity betweenrotation and translation. To address this, we proposed DynaWeightPnP,introducing a dynamic weighting sub-problem and an alternative searchingalgorithm designed to enhance pose estimation and alignment accuracy.Experiments were conducted on a typical case, that is, a 3D-2D vascularcenterline registration task within Endovascular Image-Guided Interventions(EIGIs). Results demonstrated that the proposed algorithm achieves registrationprocessing rates of 60 Hz (without post-refinement) and 31 Hz (withpost-refinement) on modern single-core CPUs, with competitive accuracycomparable to existing methods. These results underscore the suitability ofDynaWeightPnP for future robot navigation tasks like EIGIs.</description>
      <author>example@mail.com (Jingwei Song, Maani Ghaffari)</author>
      <guid isPermaLink="false">2409.18457v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Examining the Rat in the Tunnel: Interpretable Multi-Label Classification of Tor-based Malware</title>
      <link>http://arxiv.org/abs/2409.16639v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 尽管Tor是最受欢迎的隐私增强网络，但网络犯罪分子越来越多地使用Tor来掩盖恶意流量，妨碍识别受感染设备与指挥控制（C&amp;C）服务器之间的恶意通信。2. **问题重要性**:   - 恶意流量会导致网络拥堵，降低Tor的性能，并促使网络管理员阻止Tor流量。3. **现有研究局限性**:   - 尽管已有研究显示了准确分类捕获的Tor流量为恶意或良性的潜力，但现有方法的微平均精度和召回率值仅约为70%，性能有限。4. **分类必要性**:   - 准确分类特定恶意软件类别对于有效的攻击预防和缓解至关重要，同时理解不同恶意软件类别的独特模式和攻击向量有助于开发强大且可适应的防御机制。5. **新方法介绍**:   - 采用基于消息传递神经网络的多标签分类技术，证明其优于之前的方法（如二元相关、分类器链和标签幂集），微平均精度（MAP）和召回率（MAR）均超过90%。6. **性能提升**:   - 与之前的研究相比，在MAP、MAR和汉明损失方面分别提高了19.98%、10.15%和59.21%的性能。7. **可解释性研究**:   - 采用可解释人工智能（XAI）技术解释模型的决策过程。8. **鲁棒性评估**:   - 通过制造对抗扰动评估所有技术的鲁棒性，这些扰动能够操纵分类器预测，并生成假阳性和假阴性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite being the most popular privacy-enhancing network, Tor is increasinglyadopted by cybercriminals to obfuscate malicious traffic, hindering theidentification of malware-related communications between compromised devicesand Command and Control (C&amp;C) servers. This malicious traffic can inducecongestion and reduce Tor's performance, while encouraging networkadministrators to block Tor traffic. Recent research, however, demonstrates thepotential for accurately classifying captured Tor traffic as malicious orbenign. While existing efforts have addressed malware class identification,their performance remains limited, with micro-average precision and recallvalues around 70%. Accurately classifying specific malware classes is crucialfor effective attack prevention and mitigation. Furthermore, understanding theunique patterns and attack vectors employed by different malware classes helpsthe development of robust and adaptable defence mechanisms.  We utilise a multi-label classification technique based on Message-PassingNeural Networks, demonstrating its superiority over previous approaches such asBinary Relevance, Classifier Chains, and Label Powerset, by achievingmicro-average precision (MAP) and recall (MAR) exceeding 90%. Compared toprevious work, we significantly improve performance by 19.98%, 10.15%, and59.21% in MAP, MAR, and Hamming Loss, respectively. Next, we employ ExplainableArtificial Intelligence (XAI) techniques to interpret the decision-makingprocess within these models. Finally, we assess the robustness of alltechniques by crafting adversarial perturbations capable of manipulatingclassifier predictions and generating false positives and negatives.</description>
      <author>example@mail.com (Ishan Karunanayake, Mashael AlSabah, Nadeem Ahmed, Sanjay Jha)</author>
      <guid isPermaLink="false">2409.16639v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Enriched Functional Tree-Based Classifiers: A Novel Approach Leveraging Derivatives and Geometric Features</title>
      <link>http://arxiv.org/abs/2409.17804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究领域**:   - 本研究属于标量与函数分类文献，广泛应用于统计学、数学和计算机科学等领域。2. **研究目标**:   - 介绍了一种先进的监督分类方法，通过将功能数据分析（FDA）与基于树的集成技术结合，来分类高维时间序列。3. **提出的方法**:   - 提出的框架称为“丰富的功能树基分类器”（EFTCs），利用导数和几何特征，借助集成方法的多样性来增强预测性能并降低方差。4. **应用范围**:   - 方法已在丰富的功能分类树（FCTs）、功能K-NN（FKNN）、功能随机森林（FRF）、功能XGBoost（FXGB）和功能LightGBM（FLGBM）上进行了测试，并可扩展到其他基于树和非基于树的分类器。5. **实验验证**:   - 通过对七个现实世界数据集和六个模拟场景的广泛实验评估，展示了该方案相较于传统方法的显著改进。6. **新见解**:   - 提供了对功能数据分析在复杂高维学习问题中的应用的新见解。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The positioning of this research falls within the scalar-on-functionclassification literature, a field of significant interest across variousdomains, particularly in statistics, mathematics, and computer science. Thisstudy introduces an advanced methodology for supervised classification byintegrating Functional Data Analysis (FDA) with tree-based ensemble techniquesfor classifying high-dimensional time series. The proposed framework, EnrichedFunctional Tree-Based Classifiers (EFTCs), leverages derivative and geometricfeatures, benefiting from the diversity inherent in ensemble methods to furtherenhance predictive performance and reduce variance. While our approach has beentested on the enrichment of Functional Classification Trees (FCTs), FunctionalK-NN (FKNN), Functional Random Forest (FRF), Functional XGBoost (FXGB), andFunctional LightGBM (FLGBM), it could be extended to other tree-based andnon-tree-based classifiers, with appropriate considerations emerging from thisinvestigation. Through extensive experimental evaluations on seven real-worlddatasets and six simulated scenarios, this proposal demonstrates fascinatingimprovements over traditional approaches, providing new insights into theapplication of FDA in complex, high-dimensional learning problems.</description>
      <author>example@mail.com (Fabrizio Maturo, Annamaria Porreca)</author>
      <guid isPermaLink="false">2409.17804v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>An Epistemic Human-Aware Task Planner which Anticipates Human Beliefs and Decisions</title>
      <link>http://arxiv.org/abs/2409.18545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 提出了一个扩展的人机任务规划框架，旨在处理人类与机器人之间的间歇性共享执行经历及显著的信念差异。2. **研究目标**:   - 目标是构建一个考虑不可控人类行为的机器人策略，使机器人能够预测在执行非共享任务时可能取得的进展。3. **人类视角**:   - 这种预测是从人类的角度进行的，他们能够访问对机器人的估计模型。4. **新规划框架**:   - 提出了一个新的规划框架，并基于AND-OR搜索构建了求解器，集成了知识推理和视角评估。5. **动态建模**:   - 方法动态建模和管理潜在进展的扩展和收缩，同时精确跟踪代理何时共享任务执行经验。6. **情境评估**:   - 规划器系统地评估情境，并忽略那些被认为对人类不可能的世界。7. **信念估计**:   - 新求解器可以沿着潜在行动路径估计人类与机器人的不同信念，从而合成机器人选择合适时机进行沟通的计划。8. **沟通时机**:   - 机器人能够选择适当的时机进行信息传达、回应询问或推迟具体行动，直到执行经验可以共享。9. **实验验证**:   - 在两个领域（一个新领域和一个改编领域）进行了初步实验，展示了该框架的有效性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a substantial extension of our Human-Aware Task Planningframework, tailored for scenarios with intermittent shared executionexperiences and significant belief divergence between humans and robots,particularly due to the uncontrollable nature of humans. Our objective is tobuild a robot policy that accounts for uncontrollable human behaviors, thusenabling the anticipation of possible advancements achieved by the robot whenthe execution is not shared, e.g. when humans are briefly absent from theshared environment to complete a subtask. But, this anticipation is consideredfrom the perspective of humans who have access to an estimated model for therobot. To this end, we propose a novel planning framework and build a solverbased on AND-OR search, which integrates knowledge reasoning, includingsituation assessment by perspective taking. Our approach dynamically models andmanages the expansion and contraction of potential advances while preciselykeeping track of when (and when not) agents share the task executionexperience. The planner systematically assesses the situation and ignoresworlds that it has reason to think are impossible for humans. Overall, our newsolver can estimate the distinct beliefs of the human and the robot alongpotential courses of action, enabling the synthesis of plans where the robotselects the right moment for communication, i.e. informing, or replying to aninquiry, or defers ontic actions until the execution experiences can be shared.Preliminary experiments in two domains, one novel and one adapted, demonstratethe effectiveness of the framework.</description>
      <author>example@mail.com (Shashank Shekhar, Anthony Favier, Rachid Alami)</author>
      <guid isPermaLink="false">2409.18545v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Automating Traffic Model Enhancement with AI Research Agent</title>
      <link>http://arxiv.org/abs/2409.16876v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 开发高效的交通模型对于优化运输系统至关重要，但现有方法耗时且容易因手动过程引入错误。2. **传统工作流程**:   - 传统流程包括详尽的文献回顾、公式优化和迭代测试，导致研究效率低下。3. **新方法介绍**:   - 本文提出了交通研究代理（TR-Agent），一个基于AI的系统，旨在通过迭代闭环过程自主开发和优化交通模型。4. **研究流程分阶段**:   - 将研究流程分为四个关键阶段：创意生成、理论制定、理论评估和迭代优化。5. **模块构建**:   - TR-Agent由四个相应模块构成：创意生成器、代码生成器、评估器和分析器。各模块协同工作，检索外部知识，生成新创意，实现和调试模型，并在评估数据集上进行评估。6. **模型持续优化**:   - 系统基于迭代反馈不断优化模型，提高研究效率和模型性能。7. **实验结果**:   - 实验结果表明，TR-Agent在多个交通模型上实现了显著的性能提升，包括智能驾驶模型（IDM）、MOBIL变道模型和Lighthill-Whitham-Richards（LWR）交通流模型。8. **优化解释**:   - TR-Agent为其优化提供详细解释，便于研究人员验证和在其基础上进行改进。9. **开源支持**:   - 为了支持研究和合作，研究团队已开源实验中使用的代码和数据，促进更广泛的访问和领域内的持续进展。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing efficient traffic models is essential for optimizingtransportation systems, yet current approaches remain time-intensive andsusceptible to human errors due to their reliance on manual processes.Traditional workflows involve exhaustive literature reviews, formulaoptimization, and iterative testing, leading to inefficiencies in research. Inresponse, we introduce the Traffic Research Agent (TR-Agent), an AI-drivensystem designed to autonomously develop and refine traffic models through aniterative, closed-loop process. Specifically, we divide the research pipelineinto four key stages: idea generation, theory formulation, theory evaluation,and iterative optimization; and construct TR-Agent with four correspondingmodules: Idea Generator, Code Generator, Evaluator, and Analyzer. Working insynergy, these modules retrieve knowledge from external resources, generatenovel ideas, implement and debug models, and finally assess them on theevaluation datasets. Furthermore, the system continuously refines these modelsbased on iterative feedback, enhancing research efficiency and modelperformance. Experimental results demonstrate that TR-Agent achievessignificant performance improvements across multiple traffic models, includingthe Intelligent Driver Model (IDM) for car following, the MOBIL lane-changingmodel, and the Lighthill-Whitham-Richards (LWR) traffic flow model.Additionally, TR-Agent provides detailed explanations for its optimizations,allowing researchers to verify and build upon its improvements easily. Thisflexibility makes the framework a powerful tool for researchers intransportation and beyond. To further support research and collaboration, wehave open-sourced both the code and data used in our experiments, facilitatingbroader access and enabling continued advancements in the field.</description>
      <author>example@mail.com (Xusen Guo, Xinxi Yang, Mingxing Peng, Hongliang Lu, Meixin Zhu, Hai Yang)</author>
      <guid isPermaLink="false">2409.16876v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Uncertainty-Aware Visual-Inertial SLAM with Volumetric Occupancy Mapping</title>
      <link>http://arxiv.org/abs/2409.12051v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 figures, 5 tables, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究主题**:   - 提出了视觉-惯性同步定位与地图构建（SLAM）方法，紧密结合稀疏重投影误差、惯性测量单元预积分和相对位姿因子与密集体积占用映射。2. **深度预测融合**:   - 采用深度神经网络的深度预测以完全概率的方式进行融合。3. **不确定性意识**:   - 方法严格考虑不确定性：首先，不仅使用机器人立体设备的深度和不确定性预测，还通过运动立体概率融合提供跨基线的深度信息，从而显著提高映射精度。4. **不确定性传播**:   - 预测和融合的深度不确定性不仅传播到占用概率，还传播到生成的密集子图之间的对齐因子，进入概率非线性最小二乘估计器。5. **全球一致性**:   - 这种子图表示在规模上提供全球一致的几何结构。6. **性能评估**:   - 在两个基准数据集上进行了全面评估，结果显示定位和映射精度超过了当前最先进的技术。7. **实际应用**:   - 同时提供了可直接用于实时机器人规划和控制的体积占用信息。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose visual-inertial simultaneous localization and mapping that tightlycouples sparse reprojection errors, inertial measurement unit pre-integrals,and relative pose factors with dense volumetric occupancy mapping. Hereby depthpredictions from a deep neural network are fused in a fully probabilisticmanner. Specifically, our method is rigorously uncertainty-aware: first, we usedepth and uncertainty predictions from a deep network not only from the robot'sstereo rig, but we further probabilistically fuse motion stereo that providesdepth information across a range of baselines, therefore drastically increasingmapping accuracy. Next, predicted and fused depth uncertainty propagates notonly into occupancy probabilities but also into alignment factors betweengenerated dense submaps that enter the probabilistic nonlinear least squaresestimator. This submap representation offers globally consistent geometry atscale. Our method is thoroughly evaluated in two benchmark datasets, resultingin localization and mapping accuracy that exceeds the state of the art, whilesimultaneously offering volumetric occupancy directly usable for downstreamrobotic planning and control in real-time.</description>
      <author>example@mail.com (Jaehyung Jung, Simon Boche, Sebastián Barbas Laina, Stefan Leutenegger)</author>
      <guid isPermaLink="false">2409.12051v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning-based vs Deep Learning-based Anomaly Detection in Multivariate Time Series for Spacecraft Attitude Sensors</title>
      <link>http://arxiv.org/abs/2409.17841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for the ESA SPAICE Conference 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 在航天器的故障检测、隔离与恢复（FDIR）框架中，新的基于AI的方法正在出现，以克服传统阈值检查的局限性。2. **研究目标**:   - 本研究旨在表征针对航天器姿态传感器中多变量时间序列的卡值检测问题的两种不同方法。3. **性能分析**:   - 分析揭示了这两种方法在性能上的差异。4. **可解释性与推广性**:   - 讨论了两种方法的可解释性及其在不同场景中的推广能力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the framework of Failure Detection, Isolation and Recovery (FDIR) onspacecraft, new AI-based approaches are emerging in the state of the art toovercome the limitations commonly imposed by traditional threshold checking.  The present research aims at characterizing two different approaches to theproblem of stuck values detection in multivariate time series coming fromspacecraft attitude sensors. The analysis reveals the performance differencesin the two approaches, while commenting on their interpretability andgeneralization to different scenarios.</description>
      <author>example@mail.com (R. Gallon, F. Schiemenz, A. Krstova, A. Menicucci, E. Gill)</author>
      <guid isPermaLink="false">2409.17841v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Unscented Transform-based Pure Pursuit Path-Tracking Algorithm under Uncertainty</title>
      <link>http://arxiv.org/abs/2409.18585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to the 21st International Conference on Informatics in
  Control, Automation and Robotics (ICINCO 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 自动驾驶越来越受欢迎，因其有潜力通过接管人类驾驶任务来消除道路事故。2. **面临的挑战**:   - 仍然面临的挑战是自主跟踪规划路径，尤其是在自我定位或理解周围环境的不确定性可能影响决策时。3. **决策影响**:   - 不确定性会影响自动驾驶车辆计算所需转向的程度，以最小化跟踪误差。4. **提出的方法**:   - 本文提出了一种修改后的几何纯追踪路径跟踪算法，利用无味变换考虑这些不确定性。5. **测试方法**:   - 该算法通过模拟进行测试，针对典型的道路几何形状，如直线和圆形路径。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated driving has become more and more popular due to its potential toeliminate road accidents by taking over driving tasks from humans. One of theremaining challenges is to follow a planned path autonomously, especially whenuncertainties in self-localizing or understanding the surroundings caninfluence the decisions made by autonomous vehicles, such as calculating howmuch they need to steer to minimize tracking errors. In this paper, a modifiedgeometric pure pursuit path-tracking algorithm is proposed, taking intoconsideration such uncertainties using the unscented transform. The algorithmis tested through simulations for typical road geometries, such as straight andcircular lines.</description>
      <author>example@mail.com (Chinnawut Nantabut)</author>
      <guid isPermaLink="false">2409.18585v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Performance assessment of ADAS in a representative subset of critical traffic situations</title>
      <link>http://arxiv.org/abs/2409.16942v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 随着各种自动化碰撞预防系统在个人车辆中的普遍应用，评估和区分汽车模型的自动安全性能变得愈加重要。2. **测试活动启动**:   - 2023年，Swiss Re及其合作伙伴启动了一项为期八个月的车辆测试活动，在德国的认可UNECE类型批准机构和Euro NCAP认证的试验场进行。3. **测试车辆**:   - 测试涉及十二款量产车辆和一款原型车，这些车辆均配备了碰撞预防系统。4. **测试场景**:   - 选取了一系列与美国和欧盟事故形势相关的安全关键交通场景进行测试。5. **安全性能评估**:   - 本文比较和评估了这十三种碰撞预防系统（包括硬件和软件堆栈）的相对安全性能。6. **评分系统**:   - 引入了一个新的评分系统，表示测试系统对现实世界碰撞频率和碰撞冲击能量减少的预测影响，权重基于测试场景的现实相关性。7. **协议现实性度量**:   - 提出了一个新颖的度量标准，用于量化测试协议的现实性，并确认该协议合理地代表了现实驾驶情境。8. **原型系统表现**:   - 发现原型系统在预发布状态下，在大多数测试场景中优于量产（消费后发布）车辆。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a variety of automated collision prevention systems gain presence withinpersonal vehicles, rating and differentiating the automated safety performanceof car models has become increasingly important for consumers, manufacturers,and insurers. In 2023, Swiss Re and partners initiated an eight-month longvehicle testing campaign conducted on a recognized UNECE type approvalauthority and Euro NCAP accredited proving ground in Germany. The campaignexposed twelve mass-produced vehicle models and one prototype vehicle fittedwith collision prevention systems to a selection of safety-critical trafficscenarios representative of United States and European Union accidentlandscape. In this paper, we compare and evaluate the relative safetyperformance of these thirteen collision prevention systems (hardware andsoftware stack) as demonstrated by this testing campaign. We first introduce anew scoring system which represents a test system's predicted impact on overallreal-world collision frequency and reduction of collision impact energy,weighted based on the real-world relevance of the test scenario. Next, weintroduce a novel metric that quantifies the realism of the protocol andconfirm that our test protocol is a plausible representation of real-worlddriving. Finally, we find that the prototype system in its pre-release stateoutperforms the mass-produced (post-consumer-release) vehicles in the majorityof the tested scenarios on the test track.</description>
      <author>example@mail.com (Luigi Di Lillo, Andrea Triscari, Xilin Zhou, Robert Dyro, Ruolin Li, Marco Pavone)</author>
      <guid isPermaLink="false">2409.16942v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>A multi-source data power load forecasting method using attention mechanism-based parallel cnn-gru</title>
      <link>http://arxiv.org/abs/2409.17889v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 准确的电力负荷预测对提高能效和确保电力供应质量至关重要。2. **问题复杂性**:   - 电力负荷预测涉及动态因素（如历史负荷变化）和静态因素（如特定时期内的气候条件）。3. **研究方法**:   - 本文从模型无关的角度提出了一种并行结构网络，以提取动态和静态数据中的重要信息。4. **理论基础**:   - 基于复杂性学习理论，证明了通过并行结构集成的模型相比于单一基学习器具有更强的泛化能力。5. **独立性影响**:   - 基学习器之间的独立性越高，并行结构模型的泛化能力越强，这表明机器学习模型的结构本身包含重要信息。6. **模型设计**:   - 在此理论基础上，采用并行卷积神经网络（CNN）-门控递归单元（GRU）注意力模型（PCGA）来解决电力负荷预测问题，旨在有效整合动态和静态特征的影响。7. **模块功能**:   - CNN模块负责从静态数据中捕获空间特征，GRU模块则捕获动态时间序列数据中的长期依赖关系。8. **注意力机制**:   - 注意力层设计用来关注从并行CNN-GRU提取的时空特征中的关键信息。9. **实验验证**:   - 为证明并行结构模型在提取和整合多源信息方面的优势，进行了系列实验。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate power load forecasting is crucial for improving energy efficiencyand ensuring power supply quality. Considering the power load forecastingproblem involves not only dynamic factors like historical load variations butalso static factors such as climate conditions that remain constant overspecific periods. From the model-agnostic perspective, this paper proposes aparallel structure network to extract important information from both dynamicand static data. Firstly, based on complexity learning theory, it isdemonstrated that models integrated through parallel structures exhibitsuperior generalization abilities compared to individual base learners.Additionally, the higher the independence between base learners, the strongerthe generalization ability of the parallel structure model. This suggests thatthe structure of machine learning models inherently contains significantinformation. Building on this theoretical foundation, a parallel convolutionalneural network (CNN)-gate recurrent unit (GRU) attention model (PCGA) isemployed to address the power load forecasting issue, aiming to effectivelyintegrate the influences of dynamic and static features. The CNN module isresponsible for capturing spatial characteristics from static data, while theGRU module captures long-term dependencies in dynamic time series data. Theattention layer is designed to focus on key information from thespatial-temporal features extracted by the parallel CNN-GRU. To substantiatethe advantages of the parallel structure model in extracting and integratingmulti-source information, a series of experiments are conducted.</description>
      <author>example@mail.com (Chao Min, Yijia Wang, Bo Zhang, Xin Ma, Junyi Cui)</author>
      <guid isPermaLink="false">2409.17889v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Geometry-aware Feature Matching for Large-Scale Structure from Motion</title>
      <link>http://arxiv.org/abs/2409.02310v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 在多图像的结构从运动（SfM）系统中，建立一致且密集的对应关系至关重要。2. **挑战**:   - 重大视图变化（例如空中到地面的视图重叠极少）对对应关系求解器构成更大挑战。3. **提出的方法**:   - 本研究提出了一种基于优化的新方法，通过引入几何线索来显著增强现有的特征匹配方法，除了颜色线索外。4. **方法优势**:   - 该方法在大规模场景中帮助填补重叠较少时的空白。5. **几何验证**:   - 将几何验证形式化为一个优化问题，指导无检测器方法中的特征匹配，并使用基于检测器的方法中的稀疏对应关系作为锚点。6. **几何约束**:   - 通过采用Sampson距离强制执行几何约束，确保无检测器方法中的密集对应关系在几何上是一致且更准确的。7. **混合策略成果**:   - 这种混合策略显著提高了对应关系的密度和准确性，缓解了多视图不一致性，显著提高了相机姿态准确性和点云密度。8. **性能评估**:   - 在基准数据集上表现优于最先进的特征匹配方法，并能够在极具挑战性的超大规模环境中实现特征匹配。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Establishing consistent and dense correspondences across multiple images iscrucial for Structure from Motion (SfM) systems. Significant view changes, suchas air-to-ground with very sparse view overlap, pose an even greater challengeto the correspondence solvers. We present a novel optimization-based approachthat significantly enhances existing feature matching methods by introducinggeometry cues in addition to color cues. This helps fill gaps when there isless overlap in large-scale scenarios. Our method formulates geometricverification as an optimization problem, guiding feature matching withindetector-free methods and using sparse correspondences from detector-basedmethods as anchor points. By enforcing geometric constraints via the SampsonDistance, our approach ensures that the denser correspondences fromdetector-free methods are geometrically consistent and more accurate. Thishybrid strategy significantly improves correspondence density and accuracy,mitigates multi-view inconsistencies, and leads to notable advancements incamera pose accuracy and point cloud density. It outperforms state-of-the-artfeature matching methods on benchmark datasets and enables feature matching inchallenging extreme large-scale settings.</description>
      <author>example@mail.com (Gonglin Chen, Jinsen Wu, Haiwei Chen, Wenbin Teng, Zhiyuan Gao, Andrew Feng, Rongjun Qin, Yajie Zhao)</author>
      <guid isPermaLink="false">2409.02310v3</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Analysis of Truncated Singular Value Decomposition for Koopman Operator-Based Lane Change Model</title>
      <link>http://arxiv.org/abs/2409.18586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to the 21st International Conference on Informatics in
  Control, Automation and Robotics (ICINCO 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 理解和建模复杂动态系统对于提升车辆性能和安全性至关重要，尤其是在自动驾驶的背景下。2. **方法介绍**:   - 最近，Koopman算子及其近似方法（如扩展动态模式分解EDMD）因其在将强非线性系统行为转换为线性表示方面的有效性而受到关注。3. **集成优势**:   - 这种转换使得这些方法能够与传统线性控制器集成。4. **技术细节**:   - 为了实现这一点，采用奇异值分解（SVD），特别是截断SVD，用于从大型数据集中高效地近似Koopman算子。5. **研究目标**:   - 本研究评估了EDMD中使用的不同基函数，并对截断SVD在表示车道变换行为模型中的效果进行排名，旨在平衡计算效率与信息损失。6. **研究发现**:   - 结果表明，截断SVD技术并不一定能显著减少计算训练时间，并且会导致显著的信息损失。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and modeling complex dynamic systems is crucial for enhancingvehicle performance and safety, especially in the context of autonomousdriving. Recently, popular methods such as Koopman operators and theirapproximators, known as Extended Dynamic Mode Decomposition (EDMD), haveemerged for their effectiveness in transforming strongly nonlinear systembehavior into linear representations. This allows them to be integrated withconventional linear controllers. To achieve this, Singular Value Decomposition(SVD), specifically truncated SVD, is employed to approximate Koopman operatorsfrom extensive datasets efficiently. This study evaluates different basisfunctions used in EDMD and ranks for truncated SVD for representing lane changebehavior models, aiming to balance computational efficiency with informationloss. The findings, however, suggest that the technique of truncated SVD doesnot necessarily achieve substantial reductions in computational training timeand results in significant information loss.</description>
      <author>example@mail.com (Chinnawut Nantabut)</author>
      <guid isPermaLink="false">2409.18586v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Hi-SLAM: Scaling-up Semantics in SLAM with a Hierarchically Categorical Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2409.12518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究目标**:   - 提出了Hi-SLAM，一种语义3D高斯点云SLAM方法，具有新颖的分层分类表示。2. **功能特性**:   - Hi-SLAM能够实现准确的全球3D语义映射、可扩展性和明确的语义标签预测。3. **环境复杂性挑战**:   - 随着环境复杂性的增加，语义SLAM系统中的参数使用显著增加，导致场景理解变得更加困难和成本高昂。4. **创新方法**:   - 引入了一种新颖的分层表示，将语义信息以紧凑形式编码到3D高斯点云中，利用大型语言模型（LLMs）的能力。5. **优化策略**:   - 提出了新型语义损失，旨在通过层间和层内优化来优化分层语义信息。6. **系统增强**:   - 加强了整个SLAM系统，提升了跟踪和映射性能。7. **性能优势**:   - Hi-SLAM在映射和跟踪精度方面超越了现有的稠密SLAM方法，同时实现了2倍的操作速度提升。8. **渲染性能**:   - 在小型合成场景中，语义分割的渲染表现竞争力强，显著减少了存储和训练时间需求。9. **渲染帧率**:   - 渲染帧率在包含语义信息时达到2000 FPS，不含时达到3000 FPS。10. **复杂场景处理能力**:    - 显示出处理复杂现实场景的能力，支持超过500个语义类别，突出其宝贵的扩展能力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Hi-SLAM, a semantic 3D Gaussian Splatting SLAM method featuring anovel hierarchical categorical representation, which enables accurate global 3Dsemantic mapping, scaling-up capability, and explicit semantic label predictionin the 3D world. The parameter usage in semantic SLAM systems increasessignificantly with the growing complexity of the environment, making itparticularly challenging and costly for scene understanding. To address thisproblem, we introduce a novel hierarchical representation that encodes semanticinformation in a compact form into 3D Gaussian Splatting, leveraging thecapabilities of large language models (LLMs). We further introduce a novelsemantic loss designed to optimize hierarchical semantic information throughboth inter-level and cross-level optimization. Furthermore, we enhance thewhole SLAM system, resulting in improved tracking and mapping performance. OurHi-SLAM outperforms existing dense SLAM methods in both mapping and trackingaccuracy, while achieving a 2x operation speed-up. Additionally, it exhibitscompetitive performance in rendering semantic segmentation in small syntheticscenes, with significantly reduced storage and training time requirements.Rendering FPS impressively reaches 2,000 with semantic information and 3,000without it. Most notably, it showcases the capability of handling the complexreal-world scene with more than 500 semantic classes, highlighting its valuablescaling-up capability.</description>
      <author>example@mail.com (Boying Li, Zhixi Cai, Yuan-Fang Li, Ian Reid, Hamid Rezatofighi)</author>
      <guid isPermaLink="false">2409.12518v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>A Hybrid Quantum-Classical AI-Based Detection Strategy for Generative Adversarial Network-Based Deepfake Attacks on an Autonomous Vehicle Traffic Sign Classification System</title>
      <link>http://arxiv.org/abs/2409.17311v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 自动驾驶汽车（AVs）的感知模块依赖深度学习模型来检测和识别周围环境中的各种物体。2. **重要性**:   - 交通标志分类系统是感知模块的重要组成部分，帮助AVs识别道路交通标志。3. **安全隐患**:   - 对抗性攻击（如修改交通标志图像）可能导致AVs误识别交通标志，进而造成危险后果。4. **深伪技术**:   - 深伪（Deepfake）技术被提出作为一种对抗性攻击手段，通过用深伪交通标志替换真实交通标志图像，从而欺骗AV的交通标志分类系统。5. **研究目标**:   - 本研究展示如何利用基于生成对抗网络（GAN）的深伪攻击来愚弄AV交通标志分类系统。6. **检测策略**:   - 开发了一种深伪交通标志图像检测策略，采用混合量子-经典神经网络（NNs）。7. **混合方法**:   - 该混合方法使用幅度编码将输入交通标志图像的特征表示为量子态，相较于经典方法显著降低了内存需求。8. **评估方法**:   - 评估了该混合深伪检测方法及若干基线经典卷积神经网络在真实和深伪交通标志图像上的表现。9. **实验结果**:   - 结果表明，在大多数情况下，混合量子-经典神经网络在深伪检测方面的表现与基线经典卷积神经网络相当或更高，同时内存需求不足经典卷积NN的三分之一。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The perception module in autonomous vehicles (AVs) relies heavily on deeplearning-based models to detect and identify various objects in theirsurrounding environment. An AV traffic sign classification system is integralto this module, which helps AVs recognize roadway traffic signs. However,adversarial attacks, in which an attacker modifies or alters the image capturedfor traffic sign recognition, could lead an AV to misrecognize the trafficsigns and cause hazardous consequences. Deepfake presents itself as a promisingtechnology to be used for such adversarial attacks, in which a deepfake trafficsign would replace a real-world traffic sign image before the image is fed tothe AV traffic sign classification system. In this study, the authors presenthow a generative adversarial network-based deepfake attack can be crafted tofool the AV traffic sign classification systems. The authors developed adeepfake traffic sign image detection strategy leveraging hybridquantum-classical neural networks (NNs). This hybrid approach utilizesamplitude encoding to represent the features of an input traffic sign imageusing quantum states, which substantially reduces the memory requirementcompared to its classical counterparts. The authors evaluated this hybriddeepfake detection approach along with several baseline classical convolutionalNNs on real-world and deepfake traffic sign images. The results indicate thatthe hybrid quantum-classical NNs for deepfake detection could achieve similaror higher performance than the baseline classical convolutional NNs in mostcases while requiring less than one-third of the memory required by theshallowest classical convolutional NN considered in this study.</description>
      <author>example@mail.com (M Sabbir Salek, Shaozhi Li, Mashrur Chowdhury)</author>
      <guid isPermaLink="false">2409.17311v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Incorporating sparse labels into biologging studies using hidden Markov models with weighted likelihoods</title>
      <link>http://arxiv.org/abs/2409.18091v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 生态学家常使用隐马尔可夫模型（HMM）解码潜在过程，例如动物行为序列，从观察到的生物记录时间序列中提取信息。2. **技术进步**:   - 现代技术设备（如录像机和无人机）使研究人员能够直接观察动物行为。3. **标签的作用**:   - 将这些观察作为潜在过程的标签可以提高隐马尔可夫模型在解码潜在过程时的准确性。4. **观察频率问题**:   - 许多野生动物的观察频率较低，稀有标签的包含对参数估计的影响微乎其微，因此并未显著提升解码准确性。5. **提出方法**:   - 本文引入了一种加权似然方法，增强标记观察的相对影响力。6. **应用实例**:   - 采用此方法开发了两种隐马尔可夫模型，用于解码不列颠哥伦比亚省沿海虎鲸（Orcinus orca）的觅食行为。7. **评估方法**:   - 使用交叉验证评估指标，展示了加权似然方法相比现有方法具有更高的解码准确性和可理解性。8. **研究贡献**:   - 因此，本文方法有效利用稀疏标签，增强了研究人员在多个领域准确解码隐含过程的能力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ecologists often use a hidden Markov model to decode a latent process, suchas a sequence of an animal's behaviours, from an observed biologging timeseries. Modern technological devices such as video recorders and drones nowallow researchers to directly observe an animal's behaviour. Using theseobservations as labels of the latent process can improve a hidden Markovmodel's accuracy when decoding the latent process. However, many wild animalsare observed infrequently. Including such rare labels often has a negligibleinfluence on parameter estimates, which in turn does not meaningfully improvethe accuracy of the decoded latent process. We introduce a weighted likelihoodapproach that increases the relative influence of labelled observations. We usethis approach to develop two hidden Markov models to decode the foragingbehaviour of killer whales (Orcinus orca) off the coast of British Columbia,Canada. Using cross-validated evaluation metrics, we show that our weightedlikelihood approach produces more accurate and understandable decoded latentprocesses compared to existing methods. Thus, our method effectively leveragessparse labels to enhance researchers' ability to accurately decode hiddenprocesses across various fields.</description>
      <author>example@mail.com (Evan Sidrow, Nancy Heckman, Tess M. McRae, Beth L. Volpov, Andrew W. Trites, Sarah M. E. Fortune, Marie Auger-Méthé)</author>
      <guid isPermaLink="false">2409.18091v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Towards Event-Triggered NMPC for Efficient 6G Communications: Experimental Results and Open Problems</title>
      <link>http://arxiv.org/abs/2409.18589v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 网络控制系统实现了对分布式系统的实时控制与协调，利用5G及未来6G网络提供的低延迟、高可靠性和大规模连接性。2. **应用领域**:   - 该技术的应用包括自动驾驶车辆、机器人、工业自动化和智能电网。3. **稳定性保证**:   - 尽管网络控制算法在存在延迟和数据包丢失的情况下具有名义稳定性保证，但其实际性能仍然高度依赖于底层网络的具体特性和条件。4. **控制与通信的协同设计**:   - 为了实现所需的性能并高效使用通信资源，控制与通信的协同设计至关重要。5. **周期性方案的局限**:   - 尽管周期性方案（固定的通信时机）能够提供可靠的控制性能，但在不需要更新时的多余传输会导致网络资源的低效使用。6. **研究目标**:   - 本文探讨了模型预测控制与网络通信的协同设计潜力。7. **实施方案**:   - 设计并实现了一种事件触发的非线性模型预测控制器，用于稳定Furuta摆，采用定制的开放无线接入网络6G研究平台进行通信。8. **性能分析**:   - 分析了在不同信道条件和事件触发标准下的控制性能和网络利用率。9. **实验结果**:   - 结果表明，事件触发控制方案在减少通信需求的同时，能够实现与周期控制相似的性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Networked control systems enable real-time control and coordination ofdistributed systems, leveraging the low latency, high reliability, and massiveconnectivity offered by 5G and future 6G networks. Applications includeautonomous vehicles, robotics, industrial automation, and smart grids. Despitenetworked control algorithms admitting nominal stability guarantees even in thepresence of delays and packet dropouts, their practical performance stillheavily depends on the specific characteristics and conditions of theunderlying network. To achieve the desired performance while efficiently usingcommunication resources, co-design of control and communication is pivotal.Although periodic schemes, where communication instances are fixed, can providereliable control performance, unnecessary transmissions, when updates are notneeded, result in inefficient usage of network resources. In this paper, weinvestigate the potential for co-design of model predictive control and networkcommunication. To this end, we design and implement an event-triggerednonlinear model predictive controller for stabilizing a Furuta pendulumcommunicating over a tailored open radio access network 6G research platform.We analyze the control performance as well as network utilization under varyingchannel conditions and event-triggering criteria. Our results show that theevent-triggered control scheme achieves similar performance to periodic controlwith reduced communication demand.</description>
      <author>example@mail.com (Jens Püttschneider, Julian Golembiewski, Niklas A. Wagner, Christian Wietfeld, Timm Faulwasser)</author>
      <guid isPermaLink="false">2409.18589v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MGSO: Monocular Real-time Photometric SLAM with Efficient 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2409.13055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper Contribution to the ICRA 2025 Conference. Currently being
  reviewed&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 实时SLAM（同步定位与地图构建）与稠密3D映射在计算上具有挑战性，尤其是在资源有限的设备上。2. **新技术介绍**:   - 最近开发的**3D高斯点云**（3D Gaussian Splatting, 3DGS）为实时稠密3D重建提供了有前景的方法。3. **现有系统的局限**:   - 当前的3DGS基础SLAM系统在硬件简单性、速度和地图质量之间难以取得平衡。大多数系统在一到两个方面表现出色，但很少能兼顾所有。4. **主要问题**:   - 同时进行SLAM和初始化3D高斯点云的困难是一个关键问题。5. **提出的解决方案**:   - 本文提出了一种新型实时SLAM系统——**单目GSO**（Monocular GSO, MGSO），将光度SLAM与3DGS集成。6. **光度SLAM的作用**:   - 光度SLAM为3DGS的初始化提供稠密的结构化点云，加速优化过程，并以更少的高斯点生成更高效的地图。7. **实验结果**:   - 实验表明，MGSO系统在质量、内存效率和速度之间实现了良好的平衡，超越了当前的最先进技术。8. **输入要求**:   - 系统仅使用RGB输入即可完成所有结果。9. **数据集评估**:   - 在Replica、TUM-RGBD和EuRoC数据集上评估，与现有的实时稠密重建系统进行比较。10. **应用前景**:    - 不仅超过了当代系统，实验还表明，该系统在笔记本硬件上保持性能，使其成为机器人、增强现实等实时应用的实用解决方案。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-time SLAM with dense 3D mapping is computationally challenging,especially on resource-limited devices. The recent development of 3D GaussianSplatting (3DGS) offers a promising approach for real-time dense 3Dreconstruction. However, existing 3DGS-based SLAM systems struggle to balancehardware simplicity, speed, and map quality. Most systems excel in one or twoof the aforementioned aspects but rarely achieve all. A key issue is thedifficulty of initializing 3D Gaussians while concurrently conducting SLAM. Toaddress these challenges, we present Monocular GSO (MGSO), a novel real-timeSLAM system that integrates photometric SLAM with 3DGS. Photometric SLAMprovides dense structured point clouds for 3DGS initialization, acceleratingoptimization and producing more efficient maps with fewer Gaussians. As aresult, experiments show that our system generates reconstructions with abalance of quality, memory efficiency, and speed that outperforms thestate-of-the-art. Furthermore, our system achieves all results using RGBinputs. We evaluate the Replica, TUM-RGBD, and EuRoC datasets against currentlive dense reconstruction systems. Not only do we surpass contemporary systems,but experiments also show that we maintain our performance on laptop hardware,making it a practical solution for robotics, A/R, and other real-timeapplications.</description>
      <author>example@mail.com (Yan Song Hu, Nicolas Abboud, Muhammad Qasim Ali, Adam Srebrnjak Yang, Imad Elhajj, Daniel Asmar, Yuhao Chen, John S. Zelek)</author>
      <guid isPermaLink="false">2409.13055v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Data-efficient Trajectory Prediction via Coreset Selection</title>
      <link>http://arxiv.org/abs/2409.17385v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 现代车辆配备多种信息收集设备（如传感器和摄像头），持续生成大量原始数据。2. **预测重要性**:   - 准确预测邻近车辆的轨迹是理解复杂驾驶环境的重要组成部分。3. **模型训练挑战**:   - 训练轨迹预测模型面临两大挑战：     - **计算密集**：处理大规模数据需要大量计算资源。     - **数据不均衡**：简单和中等驾驶场景在数据集中占主导地位，而复杂场景（如密集交通）则被低估。4. **数据示例**:   - 在Argoverse运动预测数据集中，具有50个或更多代理的场景实例非常少，而10至20个代理的场景则更为常见。5. **研究目的**:   - 本文旨在减少过代表场景中的数据冗余，并减少复杂场景中数据稀缺带来的偏见。6. **提出方法**:   - 提出了一种基于**核心集选择**的新型数据高效训练方法，战略性地选择一个小而具有代表性的数据子集，同时平衡不同场景难度的比例。7. **创新性**:   - 据我们所知，这是首个能够有效压缩大规模轨迹数据集的方法，同时实现了最先进的压缩比。8. **性能结果**:   - 值得注意的是，即使仅使用50%的Argoverse数据集，模型训练性能几乎没有下降。9. **泛化能力**:   - 选定的核心集保持了优秀的泛化能力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern vehicles are equipped with multiple information-collection devicessuch as sensors and cameras, continuously generating a large volume of rawdata. Accurately predicting the trajectories of neighboring vehicles is a vitalcomponent in understanding the complex driving environment. Yet, trainingtrajectory prediction models is challenging in two ways. Processing thelarge-scale data is computation-intensive. Moreover, easy-medium drivingscenarios often overwhelmingly dominate the dataset, leaving challengingdriving scenarios such as dense traffic under-represented. For example, in theArgoverse motion prediction dataset, there are very few instances with $\ge 50$agents, while scenarios with $10 \thicksim 20$ agents are far more common. Inthis paper, to mitigate data redundancy in the over-represented drivingscenarios and to reduce the bias rooted in the data scarcity of complex ones,we propose a novel data-efficient training method based on coreset selection.This method strategically selects a small but representative subset of datawhile balancing the proportions of different scenario difficulties. To the bestof our knowledge, we are the first to introduce a method capable of effectivelycondensing large-scale trajectory dataset, while achieving a state-of-the-artcompression ratio. Notably, even when using only 50% of the Argoverse dataset,the model can be trained with little to no decline in performance. Moreover,the selected coreset maintains excellent generalization ability.</description>
      <author>example@mail.com (Ruining Yang, Lili Su)</author>
      <guid isPermaLink="false">2409.17385v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Using dynamic loss weighting to boost improvements in forecast stability</title>
      <link>http://arxiv.org/abs/2409.18267v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究主题**:   - 滚动原点. **研究主题**:   - 滚动原点预测不稳定性指的是在新数据点可用时更新预测所引起的特定时期内预测的变化性。2. **现有模型扩展**:   - 最近对N-BEATS模型进行了扩展，旨在为单变量时间序列点预测引入预测稳定性作为额外的优化目标，除了准确性之外。3. **稳定性与准确性**:   - 研究表明，通过最小化包含预测误差和预测不稳定性成分的复合损失函数，可以在不损害准确性的情况下获得更稳定的预测，并通过静态超参数控制稳定性的影响。4. **研究目标**:   - 本文实证研究是否可以通过应用动态损失加权算法在不妨碍准确性的情况下进一步提高稳定性，这些算法在训练过程中改变损失权重。5. **实验结果**:   - 发现一些现有的动态损失加权方法能够实现这一目标。6. **最佳方法**:   - 然而，作者提出的随机加权方法扩展——**任务感知随机加权**，表现出最佳性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rolling origin forecast instability refers to variability in forecasts for aspecific period induced by updating the forecast when new data points becomeavailable. Recently, an extension to the N-BEATS model for univariate timeseries point forecasting was proposed to include forecast stability as anadditional optimization objective, next to accuracy. It was shown that morestable forecasts can be obtained without harming accuracy by minimizing acomposite loss function that contains both a forecast error and a forecastinstability component, with a static hyperparameter to control the impact ofstability. In this paper, we empirically investigate whether furtherimprovements in stability can be obtained without compromising accuracy byapplying dynamic loss weighting algorithms, which change the loss weightsduring training. We show that some existing dynamic loss weighting methodsachieve this objective. However, our proposed extension to the Random Weightingapproach -- Task-Aware Random Weighting -- shows the best performance.</description>
      <author>example@mail.com (Daan Caljon, Jeff Vercauteren, Simon De Vos, Wouter Verbeke, Jente Van Belle)</author>
      <guid isPermaLink="false">2409.18267v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>From One to the Power of Many: Augmentations for Invariance to Multi-LiDAR Perception from Single-Sensor Datasets</title>
      <link>http://arxiv.org/abs/2409.18592v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 最近，基于深度神经网络的LiDAR感知方法在自动驾驶车辆的经典基准测试（如nuScenes和SemanticKITTI）中表现出显著性能提升。2. **问题陈述**:   - 训练于单一传感器设置的模型在现代多传感器车辆部署时，性能仍存在较大差距。3. **研究目标**:   - 本文探讨缺乏不变性是否是造成这些性能差距的原因，并提出初步解决方案。4. **解决方案**:   - 通过应用特定的数据增强技术，旨在改善模型在多传感器LiDAR设置中的迁移能力。5. **实验验证**:   - 提供实验证据表明，所提增强方法提高了LiDAR传感器设置的普适性。6. **不变性分析**:   - 研究这些数据增强如何影响模型在不同LiDAR传感器设置下的不变性特性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, LiDAR perception methods for autonomous vehicles, powered by deepneural networks have experienced steep growth in performance on classicbenchmarks, such as nuScenes and SemanticKITTI. However, there are still largegaps in performance when deploying models trained on such single-sensor setupsto modern multi-sensor vehicles. In this work, we investigate if a lack ofinvariance may be responsible for these performance gaps, and propose someinitial solutions in the form of application-specific data augmentations, whichcan facilitate better transfer to multi-sensor LiDAR setups. We provideexperimental evidence that our proposed augmentations improve generalizationacross LiDAR sensor setups, and investigate how these augmentations affect themodels' invariance properties on simulations of different LiDAR sensor setups.</description>
      <author>example@mail.com (Marc Uecker, J. Marius Zöllner)</author>
      <guid isPermaLink="false">2409.18592v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>HMD$^2$: Environment-aware Motion Generation from Single Egocentric Head-Mounted Device</title>
      <link>http://arxiv.org/abs/2409.13426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究主题**:   - 本文研究了使用单个头戴设备（配备外向色彩相机和视觉SLAM能力）在线生成逼真的全身人类动作。2. **系统介绍**:   - 介绍了一种新颖的系统**HMD²**，旨在平衡动作重建与生成之间的关系。3. **重建目标**:   - 从重建的角度，系统最大限度地利用相机流，生成包括头部运动、SLAM点云和图像嵌入等分析和学习特征。4. **生成方法**:   - HMD²采用多模态条件运动扩散模型，结合时间序列骨干网络，以保持生成动作的时间一致性。5. **在线推断**:   - 通过自回归填充技术，实现在线动作推断，具有最小延迟（0.17秒）。6. **实验数据**:   - 系统经过验证，能够高效且稳健地扩展到超过200小时的广泛数据集，这些数据集涵盖了复杂的室内和室外环境，使用了公开可用的智能眼镜。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the online generation of realistic full-body humanmotion using a single head-mounted device with an outward-facing color cameraand the ability to perform visual SLAM. Given the inherent ambiguity of thissetup, we introduce a novel system, HMD$^2$, designed to balance between motionreconstruction and generation. From a reconstruction standpoint, our systemaims to maximally utilize the camera streams to produce both analytical andlearned features, including head motion, SLAM point cloud, and imageembeddings. On the generative front, HMD$^2$ employs a multi-modal conditionalmotion Diffusion model, incorporating a time-series backbone to maintaintemporal coherence in generated motions, and utilizes autoregressivein-painting to facilitate online motion inference with minimal latency (0.17seconds). Collectively, we demonstrate that our system offers a highlyeffective and robust solution capable of scaling to an extensive dataset ofover 200 hours collected in a wide range of complex indoor and outdoorenvironments using publicly available smart glasses.</description>
      <author>example@mail.com (Vladimir Guzov, Yifeng Jiang, Fangzhou Hong, Gerard Pons-Moll, Richard Newcombe, C. Karen Liu, Yuting Ye, Lingni Ma)</author>
      <guid isPermaLink="false">2409.13426v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Real-World Data Inspired Interactive Connected Traffic Scenario Generation</title>
      <link>http://arxiv.org/abs/2409.17429v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 模拟是确保连接和自动驾驶车辆（CAVs）测试与验证准确性、效率和真实性的关键步骤。2. **趋势与重要性**:   - 随着CAV的快速普及，将真实世界数据集成到模拟环境中变得愈加重要。3. **V2X通信的角色**:   - 在CAV技术中，**车与万物（V2X）**通信在确保CAV、基础设施和其他道路用户之间信息无缝传输中扮演重要角色。4. **现有研究的局限**:   - 现有研究主要集中于开发和测试V2X中的通信协议、资源分配策略及数据传播技术，缺乏将真实V2X数据集成到模拟中的研究。5. **研究目标**:   - 本文旨在填补这一研究空白，利用来自路边单元（RSUs）的真实信号相位和计时（SPaT）数据来提升CAV模拟的真实感。6. **动态响应算法**:   - 开发了一种算法，使自动驾驶车辆（AVs）能够动态响应实时交通信号数据，模拟真实的V2X通信场景。7. **高保真模拟环境**:   - 这种高保真模拟环境能够生成多模态数据，包括轨迹数据、语义摄像头、深度摄像头和鸟瞰视图数据，以适应各种交通场景。8. **研究贡献**:   - 生成的场景和数据为AV与交通基础设施及其他道路用户的交互提供了宝贵的见解。9. **研究目标**:   - 本研究旨在弥合理论研究与CAV实际部署之间的差距，促进更智能和更安全的交通系统的发展。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation is a crucial step in ensuring accurate, efficient, and realisticConnected and Autonomous Vehicles (CAVs) testing and validation. As theadoption of CAV accelerates, the integration of real-world data into simulationenvironments becomes increasingly critical. Among various technologies utilizedby CAVs, Vehicle-to-Everything (V2X) communication plays a crucial role inensuring a seamless transmission of information between CAVs, infrastructure,and other road users. However, most existing studies have focused on developingand testing communication protocols, resource allocation strategies, and datadissemination techniques in V2X. There is a gap where real-world V2X data isintegrated into simulations to generate diverse and high-fidelity trafficscenarios. To fulfill this research gap, we leverage real-world Signal Phaseand Timing (SPaT) data from Roadside Units (RSUs) to enhance the fidelity ofCAV simulations. Moreover, we developed an algorithm that enables AutonomousVehicles (AVs) to respond dynamically to real-time traffic signal data,simulating realistic V2X communication scenarios. Such high-fidelity simulationenvironments can generate multimodal data, including trajectory, semanticcamera, depth camera, and bird's eye view data for various traffic scenarios.The generated scenarios and data provide invaluable insights into AVs'interactions with traffic infrastructure and other road users. This work aimsto bridge the gap between theoretical research and practical deployment ofCAVs, facilitating the development of smarter and safer transportation systems.</description>
      <author>example@mail.com (Junwei You, Pei Li, Yang Cheng, Keshu Wu, Rui Gan, Steven T. Parker, Bin Ran)</author>
      <guid isPermaLink="false">2409.17429v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Pseudo-kinematic trajectory control of tracked vehicles</title>
      <link>http://arxiv.org/abs/2409.18641v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 追踪车辆在复杂场景中使用，运动规划和导航过程可能非常复杂。2. **复杂性问题**:   - 车辆具有复杂的动态特性，存在许多难以识别的参数，并且这些参数会根据操作条件显著变化。3. **模型提出**:   - 本文提出了一种简单的**伪运动学模型**，该模型通过一小组依赖速度的参数来捕捉车辆运动的复杂动态效应。4. **控制器设计**:   - 该选择使得能够开发出基于**Lyapunov**的轨迹控制器，确保性能并减少计算时间。5. **验证方法**:   - 通过模拟和实验数据验证了所提方法的正确性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tracked vehicles are used in complex scenarios, where motion planning andnavigation can be very complex. They have complex dynamics, with manyparameters that are difficult to identify and that change significantly basedon the operating conditions. We propose a simple pseudo-kinematic model, wherethe intricate dynamic effects underlying the vehicle's motion are captured in asmall set of velocity-dependent parameters. This choice enables the developmentof a Lyapunov-based trajectory controller with guaranteed performance and smallcomputation time. We demonstrate the correctness of our approach with bothsimulation and experimental data.</description>
      <author>example@mail.com (Michele Focchi, Daniele Fontanelli, Luigi Palopoli)</author>
      <guid isPermaLink="false">2409.18641v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>A Time Series is Worth Five Experts: Heterogeneous Mixture of Experts for Traffic Flow Prediction</title>
      <link>http://arxiv.org/abs/2409.17440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 准确的交通预测面临重大挑战，需要深入理解时间和空间线索及其复杂的交互作用。2. **现有问题**:   - 现有的交通预测系统主要依赖复杂的序列模型，但往往在每个时间步嵌入多个变量和空间关系，可能会妨碍有效的变量中心学习，从而导致传统交通预测任务性能下降。3. **解决方案**:   - 本文提出了**变量中心**和**先验知识中心**的建模技术，以克服现有方法的局限性。4. **模型介绍**:   - 提出了**异质专家混合模型（TITAN）**，用于交通流预测。TITAN最初包含三个专注于序列建模的专家。5. **建模方法**:   - 设计了一种低秩自适应方法，使TITAN能够同时实现变量中心建模。 6. **监督过程**:   - 使用先验知识中心的建模策略来监督门控过程，确保准确的路由。7. **实验结果**:   - 在两个公共交通网络数据集（METR-LA和PEMS-BAY）上的实验表明，TITAN有效捕捉了变量中心的依赖关系，同时确保了准确的路由。8. **性能提升**:   - 相较于之前的最先进模型，TITAN在所有评估指标上实现了约4.37%到11.53%的提升。9. **代码可用性**:   - 代码已开源，链接为：[TITAN GitHub](https://github.com/sqlcow/TITAN)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sqlcow/TITAN&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate traffic prediction faces significant challenges, necessitating adeep understanding of both temporal and spatial cues and their complexinteractions across multiple variables. Recent advancements in trafficprediction systems are primarily due to the development of complexsequence-centric models. However, existing approaches often embed multiplevariables and spatial relationships at each time step, which may hindereffective variable-centric learning, ultimately leading to performancedegradation in traditional traffic prediction tasks. To overcome theselimitations, we introduce variable-centric and prior knowledge-centric modelingtechniques. Specifically, we propose a Heterogeneous Mixture of Experts (TITAN)model for traffic flow prediction. TITAN initially consists of three expertsfocused on sequence-centric modeling. Then, designed a low-rank adaptivemethod, TITAN simultaneously enables variable-centric modeling. Furthermore, wesupervise the gating process using a prior knowledge-centric modeling strategyto ensure accurate routing. Experiments on two public traffic network datasets,METR-LA and PEMS-BAY, demonstrate that TITAN effectively capturesvariable-centric dependencies while ensuring accurate routing. Consequently, itachieves improvements in all evaluation metrics, ranging from approximately4.37\% to 11.53\%, compared to previous state-of-the-art (SOTA) models. Thecode is open at\href{https://github.com/sqlcow/TITAN}{https://github.com/sqlcow/TITAN}.</description>
      <author>example@mail.com (Guangyu Wang, Yujie Chen, Ming Gao, Zhiqiao Wu, Jiafu Tang, Jiabi Zhao)</author>
      <guid isPermaLink="false">2409.17440v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>CycleNet: Enhancing Time Series Forecasting through Modeling Periodic Patterns</title>
      <link>http://arxiv.org/abs/2409.18479v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的分点解读：1. **研究背景**:   - 稳定的周期模式是进行长期预测的基础。2. **研究创新**:   - 本文首次探索了显式建模周期性对提高长期时间序列预测（LTSF）模型性能的作用。3. **技术介绍**:   - 引入了**残差周期预测（RCF）**技术，利用可学习的递归周期来建模序列中的固有周期模式，并对模型周期的残差部分进行预测。4. **模型构建**:   - 将RCF与线性层或浅层多层感知机（MLP）结合，形成了名为**CycleNet**的简单而强大的方法。5. **性能优势**:   - CycleNet在电力、天气和能源等多个领域实现了**最先进的预测准确性**，并通过减少90%以上的参数数量显著提高了效率。6. **插件能力**:   - RCF作为一种新颖的即插即用技术，能够显著提升现有模型（如PatchTST和iTransformer）的预测准确性。7. **代码可用性**:   - 源代码已发布在GitHub上，链接为：[CycleNet GitHub](https://github.com/ACAT-SCUT/CycleNet)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ACAT-SCUT/CycleNet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The stable periodic patterns present in time series data serve as thefoundation for conducting long-horizon forecasts. In this paper, we pioneer theexploration of explicitly modeling this periodicity to enhance the performanceof models in long-term time series forecasting (LTSF) tasks. Specifically, weintroduce the Residual Cycle Forecasting (RCF) technique, which utilizeslearnable recurrent cycles to model the inherent periodic patterns withinsequences, and then performs predictions on the residual components of themodeled cycles. Combining RCF with a Linear layer or a shallow MLP forms thesimple yet powerful method proposed in this paper, called CycleNet. CycleNetachieves state-of-the-art prediction accuracy in multiple domains includingelectricity, weather, and energy, while offering significant efficiencyadvantages by reducing over 90% of the required parameter quantity.Furthermore, as a novel plug-and-play technique, the RCF can also significantlyimprove the prediction accuracy of existing models, including PatchTST andiTransformer. The source code is available at:https://github.com/ACAT-SCUT/CycleNet.</description>
      <author>example@mail.com (Shengsheng Lin, Weiwei Lin, Xinyi Hu, Wentai Wu, Ruichao Mo, Haocheng Zhong)</author>
      <guid isPermaLink="false">2409.18479v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Automatic Gain Tuning for Humanoid Robots Walking Architectures Using Gradient-Free Optimization Techniques</title>
      <link>http://arxiv.org/abs/2409.18649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 复杂控制架构的开发使得机器人，尤其是类人机器人，具备了多种能力。&lt;h4&gt;2. 挑战&lt;/h4&gt;   - 调整这些控制架构仍然是一项具有挑战性且耗时的任务，通常需要专家介入。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本文提出了一种方法论，以自动调整行走类人机器人的分层控制架构的增益。&lt;h4&gt;4. 优化方法&lt;/h4&gt;   - 使用不同的无梯度优化方法进行测试，包括：     - 遗传算法（GA）     - 协方差矩阵自适应进化策略（CMA-ES）     - 进化策略（ES）     - 微分进化（DE）&lt;h4&gt;5. 验证过程&lt;/h4&gt;   - 在仿真和真实的ergoCub类人机器人上验证了所找到的参数。&lt;h4&gt;6. 结果&lt;/h4&gt;   - 遗传算法（GA）实现了最快的收敛速度（10,000次函数评估，相比之下其他算法需要25,000次）。   - 在仿真和转移到真实机器人平台时，GA的任务完成成功率为100%。&lt;h4&gt;7. 研究意义&lt;/h4&gt;   - 研究结果强调了所提出方法的潜力，能够自动化调优过程，从而减少手动干预的需求。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing sophisticated control architectures has endowed robots,particularly humanoid robots, with numerous capabilities. However, tuning thesearchitectures remains a challenging and time-consuming task that requiresexpert intervention. In this work, we propose a methodology to automaticallytune the gains of all layers of a hierarchical control architecture for walkinghumanoids. We tested our methodology by employing different gradient-freeoptimization methods: Genetic Algorithm (GA), Covariance Matrix AdaptationEvolution Strategy (CMA-ES), Evolution Strategy (ES), and DifferentialEvolution (DE). We validated the parameter found both in simulation and on thereal ergoCub humanoid robot. Our results show that GA achieves the fastestconvergence (10 x 10^3 function evaluations vs 25 x 10^3 needed by the otheralgorithms) and 100% success rate in completing the task both in simulation andwhen transferred on the real robotic platform. These findings highlight thepotential of our proposed method to automate the tuning process, reducing theneed for manual intervention.</description>
      <author>example@mail.com (Carlotta Sartore, Marco Rando, Giulio Romualdi, Cesare Molinari, Lorenzo Rosasco, Daniele Pucci)</author>
      <guid isPermaLink="false">2409.18649v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>SPAQ-DL-SLAM: Towards Optimizing Deep Learning-based SLAM for Resource-Constrained Embedded Platforms</title>
      <link>http://arxiv.org/abs/2409.14515v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear at the 18th International Conference on Control,
  Automation, Robotics and Vision (ICARCV), December 2024, Dubai, UAE&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 优化基于深度学习的同时定位与地图构建（DL-SLAM）算法对于在资源受限的嵌入式平台上实现高效计算至关重要，这使得自主移动机器人能够进行实时计算。&lt;h4&gt;2. 提出的框架&lt;/h4&gt;   - 本文提出了**SPAQ-DL-SLAM**框架，策略性地将结构化剪枝和量化（SPAQ）应用于一种先进的DL-SLAM算法——DROID-SLAM，以提高资源和能效。&lt;h4&gt;3. 优化方法&lt;/h4&gt;   - 采用基于层级敏感性分析的精细调优进行结构化剪枝，随后对DROID-SLAM中的深度学习模块进行8位后训练静态量化（PTQ）。&lt;h4&gt;4. 优化结果&lt;/h4&gt;   - SPAQ-DROID-SLAM模型通过20%的结构化剪枝和8位PTQ优化，较DROID-SLAM模型实现了18.9%的FLOPs减少和79.8%的模型大小减少。&lt;h4&gt;5. 性能评估&lt;/h4&gt;   - 在TUM-RGBD基准上的评估结果显示，SPAQ-DROID-SLAM模型在绝对轨迹误差（ATE）指标上平均超越DROID-SLAM模型10.5%。&lt;h4&gt;6. 泛化能力&lt;/h4&gt;   - 在ETH3D SLAM训练基准上，SPAQ-DROID-SLAM模型展现出更强的泛化能力，其面积曲线（AUC）得分更高，并在两个额外的数据序列中表现出成功。&lt;h4&gt;7. 性能变化&lt;/h4&gt;   - 尽管有这些改进，模型在EuRoC数据集的Vicon Room序列中的性能存在波动，特别是在高角速度下捕获的场景。&lt;h4&gt;8. 设计建议&lt;/h4&gt;   - 研究表明，在设计DL-SLAM算法时考虑操作环境和任务需求可以实现最佳性能和资源效率，适用于资源受限的嵌入式平台部署。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimizing Deep Learning-based Simultaneous Localization and Mapping(DL-SLAM) algorithms is essential for efficient implementation onresource-constrained embedded platforms, enabling real-time on-boardcomputation in autonomous mobile robots. This paper presents SPAQ-DL-SLAM, aframework that strategically applies Structured Pruning and Quantization (SPAQ)to the architecture of one of the state-ofthe-art DL-SLAM algorithms,DROID-SLAM, for resource and energy-efficiency. Specifically, we performstructured pruning with fine-tuning based on layer-wise sensitivity analysisfollowed by 8-bit post-training static quantization (PTQ) on the deep learningmodules within DROID-SLAM. Our SPAQ-DROIDSLAM model, optimized version ofDROID-SLAM model using our SPAQ-DL-SLAM framework with 20% structured pruningand 8-bit PTQ, achieves an 18.9% reduction in FLOPs and a 79.8% reduction inoverall model size compared to the DROID-SLAM model. Our evaluations on theTUM-RGBD benchmark shows that SPAQ-DROID-SLAM model surpasses the DROID-SLAMmodel by an average of 10.5% on absolute trajectory error (ATE) metric.Additionally, our results on the ETH3D SLAM training benchmark demonstrateenhanced generalization capabilities of the SPAQ-DROID-SLAM model, seen by ahigher Area Under the Curve (AUC) score and success in 2 additional datasequences compared to the DROIDSLAM model. Despite these improvements, themodel exhibits performance variance on the distinct Vicon Room sequences fromthe EuRoC dataset, which are captured at high angular velocities. This varyingperformance at some distinct scenarios suggests that designing DL-SLAMalgorithms taking operating environments and tasks in consideration can achieveoptimal performance and resource efficiency for deployment inresource-constrained embedded platforms.</description>
      <author>example@mail.com (Niraj Pudasaini, Muhammad Abdullah Hanif, Muhammad Shafique)</author>
      <guid isPermaLink="false">2409.14515v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Long or Short or Both? An Exploration on Lookback Time Windows of Behavioral Features in Product Search Ranking</title>
      <link>http://arxiv.org/abs/2409.17456v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in ACM SIGIR Workshop on eCommerce 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 客户购物行为特征是电子商务中产品搜索排名模型的核心。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 本文探讨了在历史数据中聚合这些特征时，回顾时间窗口的影响。&lt;h4&gt;3. 时间窗口的对比&lt;/h4&gt;   - 研究了使用长时间窗口和短时间窗口的优缺点。&lt;h4&gt;4. 提出的新方法&lt;/h4&gt;   - 提出了一种新颖的方法，整合来自不同时间窗口的历史行为特征。&lt;h4&gt;5. 查询级信号的重要性&lt;/h4&gt;   - 强调在排名模型中使用查询级垂直信号的关键性，以有效聚合来自不同行为特征的信息。&lt;h4&gt;6. 实证支持&lt;/h4&gt;   - 提供了基于Walmart.com实时产品搜索流量的案例证据，支持所提方法的有效性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Customer shopping behavioral features are core to product search rankingmodels in eCommerce. In this paper, we investigate the effect of lookback timewindows when aggregating these features at the (query, product) level overhistory. By studying the pros and cons of using long and short time windows, wepropose a novel approach to integrating these historical behavioral features ofdifferent time windows. In particular, we address the criticality of usingquery-level vertical signals in ranking models to effectively aggregate allinformation from different behavioral features. Anecdotal evidence for theproposed approach is also provided using live product search traffic onWalmart.com.</description>
      <author>example@mail.com (Qi Liu, Atul Singh, Jingbo Liu, Cun Mu, Zheng Yan, Jan Pedersen)</author>
      <guid isPermaLink="false">2409.17456v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Discrete Policy: Learning Disentangled Action Space for Multi-Task Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2409.18707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 学习视觉运动策略以实现多任务机器人操控一直是机器人领域的一个长期挑战。&lt;h4&gt;2. 挑战所在&lt;/h4&gt;   - 动作空间的多样性使得同一任务可以通过多种方式完成，导致单个任务的多模态动作分布。   - 随着任务数量的增加，动作分布的复杂性加剧。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 本文提出了**离散策略**（Discrete Policy），一种用于训练通用代理以实现多任务操控技能的机器人学习方法。&lt;h4&gt;4. 技术细节&lt;/h4&gt;   - 离散策略使用向量量化将动作序列映射到离散潜在空间，促进任务特定代码的学习。   - 这些代码在观察和语言指令的条件下被重建为动作空间。&lt;h4&gt;5. 实验评估&lt;/h4&gt;   - 在仿真和多个现实世界的实施中评估该方法，包括单臂和双臂机器人设置。&lt;h4&gt;6. 性能对比&lt;/h4&gt;   - 离散策略在多个基准测试中优于已建立的扩散策略（Diffusion Policy）和多种最先进的方法，如ACT、Octo和OpenVLA。   - 在一个包含五个任务的现实世界多任务训练设置中，离散策略的平均成功率比扩散策略高出26%，比OpenVLA高出15%。&lt;h4&gt;7. 任务数量的影响&lt;/h4&gt;   - 当任务数量增加到12时，离散策略与扩散策略之间的性能差距扩大至32.5%，进一步展示了该方法的优势。&lt;h4&gt;8. 研究意义&lt;/h4&gt;   - 本研究实证表明，在潜在空间中学习多任务策略是实现通用代理的重要一步。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning visuomotor policy for multi-task robotic manipulation has been along-standing challenge for the robotics community. The difficulty lies in thediversity of action space: typically, a goal can be accomplished in multipleways, resulting in a multimodal action distribution for a single task. Thecomplexity of action distribution escalates as the number of tasks increases.In this work, we propose \textbf{Discrete Policy}, a robot learning method fortraining universal agents capable of multi-task manipulation skills. DiscretePolicy employs vector quantization to map action sequences into a discretelatent space, facilitating the learning of task-specific codes. These codes arethen reconstructed into the action space conditioned on observations andlanguage instruction. We evaluate our method on both simulation and multiplereal-world embodiments, including both single-arm and bimanual robot settings.We demonstrate that our proposed Discrete Policy outperforms a well-establishedDiffusion Policy baseline and many state-of-the-art approaches, including ACT,Octo, and OpenVLA. For example, in a real-world multi-task training settingwith five tasks, Discrete Policy achieves an average success rate that is 26\%higher than Diffusion Policy and 15\% higher than OpenVLA. As the number oftasks increases to 12, the performance gap between Discrete Policy andDiffusion Policy widens to 32.5\%, further showcasing the advantages of ourapproach. Our work empirically demonstrates that learning multi-task policieswithin the latent space is a vital step toward achieving general-purposeagents.</description>
      <author>example@mail.com (Kun Wu, Yichen Zhu, Jinming Li, Junjie Wen, Ning Liu, Zhiyuan Xu, Qinru Qiu, Jian Tang)</author>
      <guid isPermaLink="false">2409.18707v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Discontinuous Reception with Adjustable Inactivity Timer for IIoT</title>
      <link>http://arxiv.org/abs/2409.17881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE Transactions on Industrial Informatics (2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 不连续接收（DRX）是降低工业物联网（IIoT）设备能耗的关键技术。&lt;h4&gt;2. DRX功能&lt;/h4&gt;   - DRX允许设备在没有计划数据接收时进入低功耗模式，其有效性依赖于DRX参数的正确配置。&lt;h4&gt;3. 建模方法&lt;/h4&gt;   - 本文通过半马尔可夫链建模对DRX过程进行表征。&lt;h4&gt;4. 参数设置方法&lt;/h4&gt;   - 详细介绍了两种设置DRX参数的方法，以最小化设备功耗并满足平均延迟约束：     - **第一种方法**：进行全面搜索以找到最佳配置。     - **第二种方法**：使用低复杂度的元启发式算法寻找次优配置，考虑理想和实际的DRX配置。&lt;h4&gt;5. 非活动计时器（IT）&lt;/h4&gt;   - IT是一个警戒时间，指定设备在最后一次信息交换后保持活动的时长。   - 传统方式是设备在每次数据接收后重启IT，这可能会不必要地延长活动时间。&lt;h4&gt;6. 提出的新方法&lt;/h4&gt;   - 提出了更高效的方法，基站（BS）通过控制信道在适当时明确指示重启计时器。   - 该决策基于基站对其缓冲区状态的了解。&lt;h4&gt;7. 流量模型&lt;/h4&gt;   - 考虑了在IIoT设置中典型的泊松流量和突发流量模型。&lt;h4&gt;8. 仿真验证&lt;/h4&gt;   - 通过广泛的数值仿真验证了该提案在降低设备能耗和保持通信延迟方面的适用性。&lt;h4&gt;9. 能效提升&lt;/h4&gt;   - 在任何到达率和延迟约束下，能量节省可达30%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TII.2024.3455010&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Discontinuous reception (DRX) is a key technology for reducing the energyconsumption of industrial Internet of Things (IIoT) devices. Specifically, DRXallows the devices to operate in a low-power mode when no data reception isscheduled, and its effectiveness depends on the proper configuration of the DRXparameters. In this paper, we characterize the DRX process departing from asemi-Markov chain modeling. We detail two ways to set DRX parameters tominimize the device power consumption while meeting a mean delay constraint.The first method exhaustively searches for the optimal configuration. Incontrast, the second method uses a low-complexity metaheuristic to find asub-optimal configuration, thus considering ideal and practical DRXconfigurations. Notably, within the DRX parameters, the inactivity timer (IT)is a caution time that specifies how long a device remains active after thelast information exchange. Traditionally, a device implementing DRX willrestart the IT after each data reception as a precedent to a low-power mode.The usual approach lies in restarting the IT whenever new data is receivedduring this cautious period, which might sometimes needlessly extend the activetime. Herein, we propose a more efficient method in which the transmit basestation (BS) explicitly indicates restarting the timer through the controlchannel only when appropriate. The decision is taken based on the BS'sknowledge about its buffer status. We consider Poisson and bursty trafficmodels, which are typical in IIoT setups, and verify the suitability of ourproposal for reducing the energy consumption of the devices withoutsignificantly compromising the communication latency through extensivenumerical simulations. Specifically, energy-saving gains of up to 30% can beobtained regardless of the arrival rate and delay constraints.</description>
      <author>example@mail.com (David E. Ruíz-Guirola, Carlos A. Rodríguez-López, Onel L. A. López, Samuel Montejo-Sánchez, Vitalio Alfonso Reguera, Matti Latva-aho)</author>
      <guid isPermaLink="false">2409.17881v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Treating Brain-inspired Memories as Priors for Diffusion Model to Forecast Multivariate Time Series</title>
      <link>http://arxiv.org/abs/2409.18491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 多变量时间序列（MTS）预测在多个应用领域面临重大挑战，尤其是在建模时间模式时。&lt;h4&gt;2. 主要挑战&lt;/h4&gt;   - 输入的有限长度使得建模周期性和突发性事件变得困难，这些事件在不同通道中会重复出现。&lt;h4&gt;3. 灵感来源&lt;/h4&gt;   - 受到人类记忆机制的启发，提出了一种通道共享的、基于大脑的记忆模块，用于更好地捕捉时间模式。&lt;h4&gt;4. 记忆模块构成&lt;/h4&gt;   - 该记忆模块包含：     - **语义记忆**：用于捕捉一般模式，如周期性事件。     - **情景记忆**：用于捕捉特殊模式，如突发事件。&lt;h4&gt;5. 机制设计&lt;/h4&gt;   - 设计了相应的回忆和更新机制，以更有效地利用这些时间模式。&lt;h4&gt;6. 模型创新&lt;/h4&gt;   - 提出了一种基于大脑的记忆增强扩散模型，利用记忆作为先验信息。&lt;h4&gt;7. 记忆检索&lt;/h4&gt;   - 该模型能够为不同通道检索相关记忆，并将其作为MTS预测的独特先验。&lt;h4&gt;8. 效果提升&lt;/h4&gt;   - 这种记忆的融入显著提高了预测的准确性和鲁棒性。&lt;h4&gt;9. 实验验证&lt;/h4&gt;   - 在八个数据集上的实验结果一致验证了该方法在捕捉和利用不同通道的多样化重复时间模式方面的优越性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting Multivariate Time Series (MTS) involves significant challenges invarious application domains. One immediate challenge is modeling temporalpatterns with the finite length of the input. These temporal patterns usuallyinvolve periodic and sudden events that recur across different channels. Tobetter capture temporal patterns, we get inspiration from humans' memorymechanisms and propose a channel-shared, brain-inspired memory module for MTS.Specifically, brain-inspired memory comprises semantic and episodic memory,where the former is used to capture general patterns, such as periodic events,and the latter is employed to capture special patterns, such as sudden events,respectively. Meanwhile, we design corresponding recall and update mechanismsto better utilize these patterns. Furthermore, acknowledging the capacity ofdiffusion models to leverage memory as a prior, we present a brain-inspiredmemory-augmented diffusion model. This innovative model retrieves relevantmemories for different channels, utilizing them as distinct priors for MTSpredictions. This incorporation significantly enhances the accuracy androbustness of predictions. Experimental results on eight datasets consistentlyvalidate the superiority of our approach in capturing and leveraging diverserecurrent temporal patterns across different channels.</description>
      <author>example@mail.com (Muyao Wang, Wenchao Chen, Zhibin Duan, Bo Chen)</author>
      <guid isPermaLink="false">2409.18491v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Electro-Mechanical Contact Interactions Between Human Finger and Touchscreen Under Electroadhesion</title>
      <link>http://arxiv.org/abs/2409.18725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 电粘附（EA）在机器人、自动化、太空任务、纺织品和触觉显示等领域具有潜在应用，但其物理机制尚未深入探讨，模型和实验数据有限。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 本论文开发了一个电机械模型，以估计人手指与触摸屏之间的静电力，并与实验测得的摩擦力进行比较。&lt;h4&gt;3. 模型结果&lt;/h4&gt;   - 模型与实验数据吻合良好，表明静电力的变化主要受以下因素影响：     - 250 Hz以下频率的角质层电荷泄漏。     - 250 Hz以上的电气特性。&lt;h4&gt;4. 新方法&lt;/h4&gt;   - 采用电阻抗测量的新方法，通过从总阻抗中减去皮肤和触摸屏的阻抗来估计静电力。这是首次实验性估计手指与电压诱导电容触摸屏之间的平均空气间隙。&lt;h4&gt;5. 电极极化阻抗研究&lt;/h4&gt;   - 研究了电极极化阻抗，特别是在低频率下，揭示了其在电荷泄漏现象中的作用。&lt;h4&gt;6. 触觉感知实验&lt;/h4&gt;   - 使用直流（DC）和交流（AC）电压信号在触摸屏上进行触觉感知实验，参与者包括10名不同手指湿度水平的人。   - 结果显示，AC电压的检测阈值显著低于DC电压，原因在于低频率下的电荷泄漏。&lt;h4&gt;7. 湿度影响&lt;/h4&gt;   - 湿润手指的参与者表现出更高的阈值水平，实验结果由阻抗测量支持。&lt;h4&gt;8. 涂层对触觉感知的影响&lt;/h4&gt;   - 研究了触摸屏顶层涂层如何影响触觉感知，聚焦于无EA的交互。   - 心理物理实验和物理测量表明，涂层材料显著影响触觉感知，可能是由于分子间相互作用。&lt;h4&gt;9. 研究意义&lt;/h4&gt;   - 这些发现为理解电粘附下的手指与触摸屏交互提供了见解，并在设计基于此技术的机器人系统和触觉界面中具有潜在应用价值。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electroadhesion (EA) has potential in robotics, automation, space missions,textiles, and tactile displays, but its physics remains underexplored due tolimited models and experimental data. This thesis develops anelectro-mechanical model to estimate electrostatic forces between human fingerand touchscreen under EA and compares it to experimentally measured frictionforces. The model aligns well with the data, showing that the electrostaticforce changes mainly due to charge leakage from the Stratum Corneum atfrequencies below 250 Hz and its electrical properties above 250 Hz.Additionally, a novel approach using electrical impedance measurementsestimates electrostatic forces by subtracting skin and touchscreen impedancesfrom the total impedance. This method is the first to experimentally estimatethe average air gap between finger and voltage-induced capacitive touchscreen.The effect of electrode polarization impedance, particularly at lowfrequencies, was also studied, revealing its role in the charge leakagephenomenon. Tactile perception via EA was investigated using DC and AC voltagesignals on a touchscreen with 10 participants of varying finger moisturelevels. Results showed that AC voltage detection thresholds were significantlylower than for DC, explained by charge leakage at lower frequencies.Participants with moist fingers exhibited higher threshold levels, supported byimpedance measurements. The thesis also investigated how touchscreen topcoatings influence tactile perception, focusing on EA-free interactions.Psychophysical experiments and physical measurements demonstrated that coatingmaterials significantly affect tactile perception, likely due to molecularinteractions. These findings offer insights into finger-touchscreeninteractions under EA and have potential applications in designing roboticsystems and haptic interfaces using this technology.</description>
      <author>example@mail.com (Easa AliAbbasi)</author>
      <guid isPermaLink="false">2409.18725v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Spectral Graph Theoretic Methods for Enhancing Network Robustness in Robot Localization</title>
      <link>http://arxiv.org/abs/2409.15506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  63rd IEEE Conference on Decision and Control (CDC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文关注通过最大化代数连通性来优化边加权网络，以增强网络的鲁棒性。&lt;h4&gt;2. 研究动机&lt;/h4&gt;   - 研究动机源于在协作定位中的精确机器人位置估计和在同时定位与地图构建（SLAM）中的姿态图稀疏化需求。&lt;h4&gt;3. 问题表述&lt;/h4&gt;   - 将代数连通性最大化问题形式化为混合整数半正定规划（MISDP），该问题属于NP-hard类。&lt;h4&gt;4. 方法论&lt;/h4&gt;   - 利用谱图理论方法，特别是切格尔不等式，引入了新颖的“切格尔切割”以增强和高效解决中等规模的MISDP。&lt;h4&gt;5. 新模型开发&lt;/h4&gt;   - 开发了一种新的混合整数线性规划（MILP），用于高效计算切格尔切割，并在外部逼近算法中实现，以解决MISDP。&lt;h4&gt;6. 启发式算法&lt;/h4&gt;   - 提出了贪心k-opt启发式算法，生成高质量解，作为切格尔切割的有效下界。&lt;h4&gt;7. 性能评估&lt;/h4&gt;   - 综合数值分析表明，通过在合成和现实机器人定位数据集上增强切割，显著提高了运行时间的效率。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the optimization of edge-weighted networks by maximizingalgebraic connectivity to enhance network robustness. Motivated by the need forprecise robot position estimation in cooperative localization and pose-graphsparsification in Simultaneous Localization and Mapping (SLAM), the algebraicconnectivity maximization problem is formulated as a Mixed IntegerSemi-Definite Program (MISDP), which is NP-hard. Leveraging spectral graphtheoretic methods, specifically Cheeger's inequality, this work introducesnovel "Cheeger cuts" to strengthen and efficiently solve medium-scale MISDPs.Further, a new Mixed Integer Linear Program (MILP) is developed for efficientlycomputing Cheeger cuts, implemented within an outer-approximation algorithm forsolving the MISDP. A greedy k-opt heuristic is also presented, producinghigh-quality solutions that serve as valid lower bounds for Cheeger cuts.Comprehensive numerical analyses demonstrate the efficacy of strengthened cutsvia substantial improvements in run times on synthetic and realistic robotlocalization datasets.</description>
      <author>example@mail.com (Neelkamal Somisetty, Harsha Nagarajan, Swaroop Darbha)</author>
      <guid isPermaLink="false">2409.15506v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Are Music Foundation Models Better at Singing Voice Deepfake Detection? Far-Better Fuse them with Speech Foundation Models</title>
      <link>http://arxiv.org/abs/2409.14131v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 本研究首次深入探讨音乐基础模型（MFMs）和语音基础模型（SFMs）在歌声深度伪造检测（SVDD）中的效果。&lt;h4&gt;2. 研究目的&lt;/h4&gt;   - 进行全面的比较研究，以确定哪种模型在SVDD中表现更佳。&lt;h4&gt;3. 比较对象&lt;/h4&gt;   - 比较最新的MFMs（如MERT变体和music2vec）与预训练的SFMs（用于一般语音表示学习和说话人识别）。&lt;h4&gt;4. 主要发现&lt;/h4&gt;   - 说话人识别的SFM表示在所有基础模型中表现最佳，主要由于其在捕捉音高、音调、强度等歌声特征方面的高效性。&lt;h4&gt;5. 模型融合探索&lt;/h4&gt;   - 研究还探讨了模型融合，以利用它们的互补特性来提高SVDD的效果。&lt;h4&gt;6. 提出的新框架&lt;/h4&gt;   - 提出了一个新框架FIONA，通过同步x-vector（说话人识别SFM）和MERT-v1-330M（MFM）进行融合。&lt;h4&gt;7. 性能结果&lt;/h4&gt;   - 使用FIONA框架，报告了最低的等错误率（EER）为13.74%，超过了所有单一基础模型和基线模型融合，达到了最新的研究成果（SOTA）。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, for the first time, we extensively investigate whether musicfoundation models (MFMs) or speech foundation models (SFMs) work better forsinging voice deepfake detection (SVDD), which has recently attracted attentionin the research community. For this, we perform a comprehensive comparativestudy of state-of-the-art (SOTA) MFMs (MERT variants and music2vec) and SFMs(pre-trained for general speech representation learning as well as speakerrecognition). We show that speaker recognition SFM representations perform thebest amongst all the foundation models (FMs), and this performance can beattributed to its higher efficacy in capturing the pitch, tone, intensity, etc,characteristics present in singing voices. To our end, we also explore thefusion of FMs for exploiting their complementary behavior for improved SVDD,and we propose a novel framework, FIONA for the same. With FIONA, through thesynchronization of x-vector (speaker recognition SFM) and MERT-v1-330M (MFM),we report the best performance with the lowest Equal Error Rate (EER) of 13.74%, beating all the individual FMs as well as baseline FM fusions and achievingSOTA results.</description>
      <author>example@mail.com (Orchid Chetia Phukan, Sarthak Jain, Swarup Ranjan Behera, Arun Balaji Buduru, Rajesh Sharma, S. R Mahadeva Prasanna)</author>
      <guid isPermaLink="false">2409.14131v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Modular Autonomous Vehicle in Heterogeneous Traffic Flow: Modeling, Simulation, and Implication</title>
      <link>http://arxiv.org/abs/2409.17945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 模块化自主车辆（MAVs）作为一种创新概念，将模块化设计引入自主车辆的发展中。&lt;h4&gt;2. 设计特点&lt;/h4&gt;   - 该设计允许多个模块无缝连接并协同运作，改变了交通流的特性。&lt;h4&gt;3. 研究目的&lt;/h4&gt;   - 旨在理解涉及这些车辆及其集体操作的交通流特征。&lt;h4&gt;4. 建模框架&lt;/h4&gt;   - 建立了一个模拟框架，以模拟MAV在交通流中的行为。&lt;h4&gt;5. 流量模型&lt;/h4&gt;   - 研究了包含各种模块大小随意组合的混合交通流。&lt;h4&gt;6. 仿真条件&lt;/h4&gt;   - 在不同的交通需求和渗透率水平下进行模拟，以考察这些车辆对交通流的影响。&lt;h4&gt;7. 分析内容&lt;/h4&gt;   - 分析了微观轨迹、MAV列车组成以及混合交通流的宏观基本图。&lt;h4&gt;8. 主要发现&lt;/h4&gt;   - 集成MAV及其集体操作显著提高了交通容量，提升幅度取决于混合交通流中的渗透率。&lt;h4&gt;9. 渗透率影响&lt;/h4&gt;   - 当渗透率超过75%时，交通容量几乎翻倍。&lt;h4&gt;10. 自由流速调节&lt;/h4&gt;    - MAV的存在显著影响并调节混合交通的自由流速，尤其在MAV与背景交通的操作速度限值存在差异时，混合交通会调整到这些车辆的运行速度。&lt;h4&gt;11. 未来展望&lt;/h4&gt;    - 本研究为未来可能的交通流系统提供了见解，特别是将现代MAV技术纳入其中。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modular autonomous vehicles (MAVs) represent a groundbreaking concept thatintegrates modularity into the ongoing development of autonomous vehicles. Thisinnovative design introduces unique features to traffic flow, allowing multiplemodules to seamlessly join together and operate collectively. To understand thetraffic flow characteristics involving these vehicles and their collectiveoperations, this study established a modeling framework specifically designedto simulate their behavior within traffic flow. The mixed traffic flow,incorporating arbitrarily formed trains of various modular sizes, is modeledand studied. Simulations are conducted under varying levels of traffic demandand penetration rates to examine the traffic flow dynamics in the presence ofthese vehicles and their operations. The microscopic trajectories, MAV traincompositions, and macroscopic fundamental diagrams of the mixed traffic floware analyzed. The simulation findings indicate that integrating MAVs and theircollective operations can substantially enhance capacity, with the extent ofimprovement depending on the penetration rate in mixed traffic flow. Notably,the capacity nearly doubles when the penetration rate exceeds 75%. Furthermore,their presence significantly influences and regulates the free-flow speed ofthe mixed traffic. Particularly, when variations in operational speed limitsexist between the MAVs and the background traffic, the mixed traffic adjusts tothe operating velocity of these vehicles. This study provides insights intopotential future traffic flow systems incorporating emerging MAV technologies.</description>
      <author>example@mail.com (Lanhang Ye, Toshiyuki Yamamoto)</author>
      <guid isPermaLink="false">2409.17945v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Prompt-Driven Temporal Domain Adaptation for Nighttime UAV Tracking</title>
      <link>http://arxiv.org/abs/2409.18533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IROS2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 在低光照条件下，夜间无人机（UAV）跟踪通过领域适应（DA）取得了显著进展。&lt;h4&gt;2. 问题识别&lt;/h4&gt;   - 现有的基于DA的训练方法在缩小无人机跟踪器的时间上下文差异方面存在不足。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 提出了一种基于提示的时间领域适应训练框架（TDA），旨在充分利用时间上下文以应对夜间无人机跟踪的挑战。&lt;h4&gt;4. 框架细节&lt;/h4&gt;   - 框架通过训练时间特征生成器与判别器来对齐白天和夜间领域的时间上下文分布。&lt;h4&gt;5. 判别器功能&lt;/h4&gt;   - 时间一致的判别器逐步提取共享的领域特征，以生成时间序列中的一致领域区分结果。&lt;h4&gt;6. 高质量样本获取&lt;/h4&gt;   - 使用提示驱动的对象挖掘器，精确定位未标注夜间视频中的对象，以获取高质量的训练样本。&lt;h4&gt;7. 基准构建&lt;/h4&gt;   - 构建了一个新的长期夜间无人机跟踪基准。&lt;h4&gt;8. 性能评估&lt;/h4&gt;   - 在公共和自构建的夜间基准上进行了全面评估，结果显示TDA框架训练的跟踪器（TDA-Track）表现出色。&lt;h4&gt;9. 实际应用&lt;/h4&gt;   - 实际夜间测试表明该方法的可行性。&lt;h4&gt;10. 资源链接&lt;/h4&gt;    - 相关代码和演示视频可在GitHub上获得：[TDA-Track](https://github.com/vision4robotics/TDA-Track)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vision4robotics/tda-track&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nighttime UAV tracking under low-illuminated scenarios has achieved greatprogress by domain adaptation (DA). However, previous DA training-based worksare deficient in narrowing the discrepancy of temporal contexts for UAVtrackers. To address the issue, this work proposes a prompt-driven temporaldomain adaptation training framework to fully utilize temporal contexts forchallenging nighttime UAV tracking, i.e., TDA. Specifically, the proposedframework aligns the distribution of temporal contexts from daytime andnighttime domains by training the temporal feature generator against thediscriminator. The temporal-consistent discriminator progressively extractsshared domain-specific features to generate coherent domain discriminationresults in the time series. Additionally, to obtain high-quality trainingsamples, a prompt-driven object miner is employed to precisely locate objectsin unannotated nighttime videos. Moreover, a new benchmark for long-termnighttime UAV tracking is constructed. Exhaustive evaluations on both publicand self-constructed nighttime benchmarks demonstrate the remarkableperformance of the tracker trained in TDA framework, i.e., TDA-Track.Real-world tests at nighttime also show its practicality. The code and demovideos are available at https://github.com/vision4robotics/TDA-Track.</description>
      <author>example@mail.com (Changhong Fu, Yiheng Wang, Liangliang Yao, Guangze Zheng, Haobo Zuo, Jia Pan)</author>
      <guid isPermaLink="false">2409.18533v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Optimum Configuration for Hovering n-Quadrotors carrying a Slung Payload</title>
      <link>http://arxiv.org/abs/2409.18741v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted for publication at AIAA SCITECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目的&lt;/h4&gt;   - 提出了一种策略，用于在负载周围组织四旋翼无人机，以实现无需外部刺激的悬停。&lt;h4&gt;2. 软件开发&lt;/h4&gt;   - 开发了一款MATLAB软件，用于模拟四旋翼-负载系统的动力学。&lt;h4&gt;3. 设计基础&lt;/h4&gt;   - 基于几何概念，确保负载与系统的质心对齐。&lt;h4&gt;4. 悬停测试&lt;/h4&gt;   - 成功的悬停测试验证了该方法的有效性。&lt;h4&gt;5. 算法改进&lt;/h4&gt;   - 改进算法以考虑推力能力和螺旋桨距离，计算实现悬停所需的最小四旋翼数量。&lt;h4&gt;6. 算法效果示例&lt;/h4&gt;   - 通过数值示例展示算法的有效性，结果表明较大的四旋翼可能需要较少的单位，而较小的四旋翼则提供更大的灵活性。&lt;h4&gt;7. 代码链接&lt;/h4&gt;   - 相关代码可在GitHub上找到：[Swarm-Slung-Payload](https://github.com/Hosnooo/Swarm-Slung-Payload)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes a strategy for organising quadrotors around a payload toenable hovering without external stimuli, together with a MATLAB software formodelling the dynamics of a quadrotor-payload system. Based on geometricconcepts, the proposed design keeps the payload and system centre of massaligned. Hovering tests that are successful confirm the method's efficiency.Moreover, the algorithm is improved to take thrust capacities and propellerdistances into account, calculating the minimum number of quadrotors needed forhovering. The algorithm's effectiveness is demonstrated by numerical examples,which reveal that larger quadrotors may require fewer units while smaller onesgive greater flexibility. Our code can be found at:\href{https://github.com/Hosnooo/Swarm-Slung-Payload}{https://github.com/Hosnooo/Swarm-Slung-Payload}</description>
      <author>example@mail.com (Mohssen E. Elshaar, Pansie A. khodary, Meral L. Badr, Mohamad A. Sayegh, Zeyad M. Manaa, Ayman M. Abdallah)</author>
      <guid isPermaLink="false">2409.18741v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>SoMaSLAM: 2D Graph SLAM for Sparse Range Sensing with Soft Manhattan World Constraints</title>
      <link>http://arxiv.org/abs/2409.15736v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages including references, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 提出了一种用于稀疏范围感知的图SLAM算法，结合了软曼哈顿世界（soft Manhattan world）和地标间约束。&lt;h4&gt;2. 稀疏范围感知的必要性&lt;/h4&gt;   - 对于小型机器人而言，使用重型和昂贵传感器不切实际，因此需要稀疏范围感知。&lt;h4&gt;3. 现有SLAM方法的局限性&lt;/h4&gt;   - 现有处理稀疏范围感知的SLAM方法在准确性上存在不足，且由于数据点获取有限，随着时间的推移会累积漂移误差。&lt;h4&gt;4. 结构性规则的缺陷&lt;/h4&gt;   - 使用结构性规则（如曼哈顿世界）来弥补这些缺陷的方法在映射与规则不符的真实世界环境时存在问题。&lt;h4&gt;5. SoMaSLAM的设计&lt;/h4&gt;   - SoMaSLAM是专为稀疏范围感知的小型机器人设计的2D图SLAM，能够有效映射稀疏数据而不强制执行严格的结构规则，并保持自适应图。&lt;h4&gt;6. 软约束的实现&lt;/h4&gt;   - 将曼哈顿世界假设作为软约束实现，称之为软曼哈顿世界。&lt;h4&gt;7. 新型约束的提出&lt;/h4&gt;   - 提出了新颖的软地标间约束，以将软曼哈顿世界融入图SLAM中。&lt;h4&gt;8. 实验验证&lt;/h4&gt;   - 通过广泛评估，证明SoMaSLAM在不同数据集上提高了定位精度，并且足够灵活以应用于真实世界。&lt;h4&gt;9. 源码和数据集发布&lt;/h4&gt;   - 研究团队在其网站上发布了源代码和稀疏范围数据集，便于其他研究者使用。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a graph SLAM algorithm for sparse range sensing that incorporatesa soft Manhattan world utilizing landmark-landmark constraints. Sparse rangesensing is necessary for tiny robots that do not have the luxury of using heavyand expensive sensors. Existing SLAM methods dealing with sparse range sensinglack accuracy and accumulate drift error over time due to limited access todata points. Algorithms that cover this flaw using structural regularities,such as the Manhattan world (MW), have shortcomings when mapping real-worldenvironments that do not coincide with the rules. We propose SoMaSLAM, a 2Dgraph SLAM designed for tiny robots with sparse range sensing. Our approacheffectively maps sparse range data without enforcing strict structuralregularities and maintains an adaptive graph. We implement the MW assumption assoft constraints, which we refer to as a soft Manhattan world. We propose novelsoft landmark-landmark constraints to incorporate the soft MW into graph SLAM.Through extensive evaluation, we demonstrate that our proposed SoMaSLAM methodimproves localization accuracy on diverse datasets and is flexible enough to beused in the real world. We release our source code and sparse range datasets athttps://SoMaSLAM.github.io/.</description>
      <author>example@mail.com (Jeahn Han, Zichao Hu, Seonmo Yang, Minji Kim, Pyojin Kim)</author>
      <guid isPermaLink="false">2409.15736v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>EFA-YOLO: An Efficient Feature Attention Model for Fire and Flame Detection</title>
      <link>http://arxiv.org/abs/2409.12635v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 火灾作为一种突发性强、破坏性大的自然灾害，长期以来对人类社会和生态环境构成了重大威胁。&lt;h4&gt;2. 技术进展&lt;/h4&gt;   - 随着智能城市和物联网（IoT）技术的快速发展，基于深度学习的火灾检测系统逐渐成为应对火灾隐患的关键手段。&lt;h4&gt;3. 现有挑战&lt;/h4&gt;   - 现有的火灾检测模型在复杂环境中的检测准确性和实时性能仍然面临许多挑战。&lt;h4&gt;4. 提出的解决方案&lt;/h4&gt;   - 提出了两个关键模块：EAConv（高效注意力卷积）和EADown（高效注意力下采样）。&lt;h4&gt;5. EAConv模块&lt;/h4&gt;   - 结合高效注意力机制与深度可分离卷积，显著提高特征提取效率。&lt;h4&gt;6. EADown模块&lt;/h4&gt;   - 利用空间和通道注意力机制结合池化操作，增强特征下采样的准确性和效率。&lt;h4&gt;7. 模型设计&lt;/h4&gt;   - 基于上述两个模块，设计了一个高效轻量的火焰检测模型EFA-YOLO（高效特征注意力YOLO）。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - EFA-YOLO的模型参数量仅为1.4M，GFLOPs为4.6，CPU每张图像的推理时间仅为22.19毫秒。&lt;h4&gt;9. 性能比较&lt;/h4&gt;   - 与现有主流模型（如YOLOv5、YOLOv8、YOLOv9和YOLOv10）相比，EFA-YOLO在检测准确性（mAP）和推理速度上显著提升，模型参数量减少94.6%，推理速度提升88倍。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a natural disaster with high suddenness and great destructiveness, firehas long posed a major threat to human society and ecological environment. Inrecent years, with the rapid development of smart city and Internet of Things(IoT) technologies, fire detection systems based on deep learning havegradually become a key means to cope with fire hazards. However, existing firedetection models still have many challenges in terms of detection accuracy andreal-time performance in complex contexts. To address these issues, we proposetwo key modules: EAConv (Efficient Attention Convolution) and EADown (EfficientAttention Downsampling). The EAConv module significantly improves the featureextraction efficiency by combining an efficient attention mechanism withdepth-separable convolution, while the EADown module enhances the accuracy andefficiency of feature downsampling by utilizing spatial and channel attentionmechanisms in combination with pooling operations. Based on these two modules,we design an efficient and lightweight flame detection model, EFA-YOLO(Efficient Feature Attention YOLO). Experimental results show that EFA-YOLO hasa model parameter quantity of only 1.4M, GFLOPs of 4.6, and the inference timeper image on the CPU is only 22.19 ms. Compared with existing mainstream models(e.g., YOLOv5, YOLOv8, YOLOv9, and YOLOv10), EFA-YOLO exhibits a significantenhancement in detection accuracy (mAP) and inference speed, with modelparameter amount is reduced by 94.6 and the inference speed is improved by 88times.</description>
      <author>example@mail.com (Weichao Pan, Xu Wang, Wenqing Huan)</author>
      <guid isPermaLink="false">2409.12635v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating Robot Influence on Pedestrian Behavior Models for Crowd Simulation and Benchmarking</title>
      <link>http://arxiv.org/abs/2409.14844v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 机器人在人行道上的存在会导致行人轨迹偏离。&lt;h4&gt;2. 现有方法的局限性&lt;/h4&gt;   - 现有方法无法客观测量行人在未见情况下的轨迹偏差。&lt;h4&gt;3. 解决方案&lt;/h4&gt;   - 引入一个模拟框架，反复测量和基准测试行人因不同导航算法驱动的机器人而产生的轨迹偏差。&lt;h4&gt;4. 模型设计&lt;/h4&gt;   - 使用增强的社会力模型（SFM），通过增加机器人力组件，形成社会机器人力模型（SRFM），以模拟行人偏差行为。&lt;h4&gt;5. 参数学习&lt;/h4&gt;   - 模型参数通过JRDB数据集中的行人轨迹进行学习。&lt;h4&gt;6. 实验设置&lt;/h4&gt;   - 在有无机器人力组件的情况下，使用SRFM模拟行人，并在五种不同场景中客观测量机器人造成的轨迹偏差。&lt;h4&gt;7. 研究成果&lt;/h4&gt;   - 本文证明了客观测量行人对机器人的反应是可能的。&lt;h4&gt;8. 后续应用&lt;/h4&gt;   - 利用模拟结果训练两种不同的强化学习（RL）策略，并将其与传统导航模型进行评估。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The presence of robots amongst pedestrians affects them causing deviation totheir trajectories. Existing methods suffer from the limitation of not beingable to objectively measure this deviation in unseen cases. In order to solvethis issue, we introduce a simulation framework that repetitively measures andbenchmarks the deviation in trajectory of pedestrians due to robots driven bydifferent navigation algorithms. We simulate the deviation behavior of thepedestrians using an enhanced Social Force Model (SFM) with a robot forcecomponent that accounts for the influence of robots on pedestrian behavior,resulting in the Social Robot Force Model (SRFM). Parameters for this model arelearned using the pedestrian trajectories from the JRDB dataset. Pedestriansare then simulated using the SRFM with and without the robot force component toobjectively measure the deviation to their trajectory caused by the robot in 5different scenarios. Our work in this paper is a proof of concept that showsobjectively measuring the pedestrian reaction to robot is possible. We use oursimulation to train two different RL policies and evaluate them againsttraditional navigation models.</description>
      <author>example@mail.com (Subham Agrawal, Nils Dengler, Maren Bennewitz)</author>
      <guid isPermaLink="false">2409.14844v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Drive via Asymmetric Self-Play</title>
      <link>http://arxiv.org/abs/2409.18218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 重要性&lt;/h4&gt;   - 大规模数据对于学习现实且有效的驾驶策略至关重要。&lt;h4&gt;2. 问题&lt;/h4&gt;   - 仅依赖真实数据扩展数据集是不切实际的，因为大多数驾驶数据都不够有趣。   - 收集新的长尾场景费用高且不安全。&lt;h4&gt;3. 解决方案&lt;/h4&gt;   - 提出了"不对称自我对弈"的方法，以超越真实数据，生成具有挑战性、可解决且现实的合成场景。&lt;h4&gt;4. 方法概述&lt;/h4&gt;   - 该方法包括一位教师（生成可解决场景）和一位学生（学习解决这些场景），两者相互配合。&lt;h4&gt;5. 应用效果&lt;/h4&gt;   - 在交通模拟中，学习到的策略在名义场景和长尾场景中显著减少碰撞。&lt;h4&gt;6. 零-shot迁移&lt;/h4&gt;   - 学习到的策略能够零-shot迁移，为端到端自主驾驶生成训练数据，效果显著优于现有的对抗性方法或仅使用真实数据的方式。&lt;h4&gt;7. 结论&lt;/h4&gt;   - 提出的方法展现了在合成场景生成和解决方面的有效性，为未来的自主驾驶研究提供了新的方向。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale data is crucial for learning realistic and capable drivingpolicies. However, it can be impractical to rely on scaling datasets with realdata alone. The majority of driving data is uninteresting, and deliberatelycollecting new long-tail scenarios is expensive and unsafe. We proposeasymmetric self-play to scale beyond real data with additional challenging,solvable, and realistic synthetic scenarios. Our approach pairs a teacher thatlearns to generate scenarios it can solve but the student cannot, with astudent that learns to solve them. When applied to traffic simulation, we learnrealistic policies with significantly fewer collisions in both nominal andlong-tail scenarios. Our policies further zero-shot transfer to generatetraining data for end-to-end autonomy, significantly outperformingstate-of-the-art adversarial approaches, or using real data alone. For moreinformation, visit https://waabi.ai/selfplay .</description>
      <author>example@mail.com (Chris Zhang, Sourav Biswas, Kelvin Wong, Kion Fallah, Lunjun Zhang, Dian Chen, Sergio Casas, Raquel Urtasun)</author>
      <guid isPermaLink="false">2409.18218v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Iterative Trace Minimization for the Reconciliation of Very Short Hierarchical Time Series</title>
      <link>http://arxiv.org/abs/2409.18550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 时间序列通常呈现出加性层次结构。在这种情况下，高层次的时间序列是其下属时间序列的总和。&lt;h4&gt;2. 问题描述&lt;/h4&gt;   - 这种层次结构对预测提出了自然约束，而单变量预测技术无法保证预测结果的一致性。&lt;h4&gt;3. 解决方案&lt;/h4&gt;   - 一种明显的解决方案是仅对底层时间序列进行预测，并通过聚合获得高层次的预测，这种方法称为自下而上的方法。&lt;h4&gt;4. 前人研究&lt;/h4&gt;   - \citep{Wickramasuriya2019}提出了一种名为MinT的最优调和方法，旨在最小化所有预测错误的协方差矩阵的迹。&lt;h4&gt;5. MinT的优势&lt;/h4&gt;   - MinT算法在性能上优于自下而上的方法及其他方法，因而受到广泛欢迎。&lt;h4&gt;6. 研究目的&lt;/h4&gt;   - 本文提供了一项模拟研究，考察MinT在非常短的时间序列和较大层次结构中的表现。&lt;h4&gt;7. 挑战&lt;/h4&gt;   - 在这种情况下，MinT所需的协方差估计变得困难。&lt;h4&gt;8. 新方法&lt;/h4&gt;   - 本文引入了一种新颖的迭代方法，显著减少了需要估计的参数数量，从而进一步提高预测准确性。&lt;h4&gt;9. 案例研究&lt;/h4&gt;   - 通过基于世界半导体贸易统计（WSTS）提供的半导体数据集的案例研究，展示了MinTit的应用。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series often appear in an additive hierarchical structure. In suchcases, time series on higher levels are the sums of their subordinate timeseries. This hierarchical structure places a natural constraint on forecasts.However, univariate forecasting techniques are incapable of ensuring thisforecast coherence. An obvious solution is to forecast only bottom time seriesand obtain higher level forecasts through aggregation. This approach is alsoknown as the bottom-up approach. In their seminal paper,\citep{Wickramasuriya2019} propose an optimal reconciliation approach namedMinT. It tries to minimize the trace of the underlying covariance matrix of allforecast errors. The MinT algorithm has demonstrated superior performance tothe bottom-up and other approaches and enjoys great popularity. This paperprovides a simulation study examining the performance of MinT for very shorttime series and larger hierarchical structures. This scenario makes thecovariance estimation required by MinT difficult. A novel iterative approach isintroduced which significantly reduces the number of estimated parameters. Thisapproach is capable of improving forecast accuracy further. The application ofMinTit is also demonstrated with a case study at the hand of a semiconductordataset based on data provided by the World Semiconductor Trade Statistics(WSTS), a premier provider of semiconductor market data.</description>
      <author>example@mail.com (Louis Steinmeister, Markus Pauly)</author>
      <guid isPermaLink="false">2409.18550v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>OpenObject-NAV: Open-Vocabulary Object-Oriented Navigation Based on Dynamic Carrier-Relationship Scene Graph</title>
      <link>http://arxiv.org/abs/2409.18743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://openobject-nav.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 日常生活中，常用物品（如杯子）的位置往往不固定，并且同一类别中有多个实例，携带者也频繁变化，这使得机器人有效导航到特定实例变得困难。&lt;h4&gt;2. 挑战描述&lt;/h4&gt;   - 机器人需要持续捕捉和更新场景变化和计划，但当前的物体导航方法主要集中在语义层面，缺乏动态更新场景表示的能力。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本文旨在捕捉常用物品与其静态携带者之间的关系。&lt;h4&gt;4. 方法论&lt;/h4&gt;   - 构建了一个开放词汇的携带者关系场景图（CRSG），并在机器人导航过程中更新携带状态，以反映场景的动态变化。&lt;h4&gt;5. 导航策略&lt;/h4&gt;   - 基于CRSG，提出了一种实例导航策略，将导航过程建模为马尔可夫决策过程（MDP）。&lt;h4&gt;6. 决策过程&lt;/h4&gt;   - 在每一步，决策受到大型语言模型的常识知识和视觉语言特征相似性的影响。&lt;h4&gt;7. 实验设计&lt;/h4&gt;   - 在Habitat模拟器中设计了一系列针对常用日常物品的长序列导航任务。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 结果表明，通过更新CRSG，机器人可以有效地导航到移动的目标。&lt;h4&gt;9. 实际应用&lt;/h4&gt;   - 该算法还在真实机器人上进行了部署，验证了其实际有效性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In everyday life, frequently used objects like cups often have unfixedpositions and multiple instances within the same category, and their carriersfrequently change as well. As a result, it becomes challenging for a robot toefficiently navigate to a specific instance. To tackle this challenge, therobot must capture and update scene changes and plans continuously. However,current object navigation approaches primarily focus on semantic-level and lackthe ability to dynamically update scene representation. This paper captures therelationships between frequently used objects and their static carriers. Itconstructs an open-vocabulary Carrier-Relationship Scene Graph (CRSG) andupdates the carrying status during robot navigation to reflect the dynamicchanges of the scene. Based on the CRSG, we further propose an instancenavigation strategy that models the navigation process as a Markov DecisionProcess. At each step, decisions are informed by Large Language Model'scommonsense knowledge and visual-language feature similarity. We designed aseries of long-sequence navigation tasks for frequently used everyday items inthe Habitat simulator. The results demonstrate that by updating the CRSG, therobot can efficiently navigate to moved targets. Additionally, we deployed ouralgorithm on a real robot and validated its practical effectiveness.</description>
      <author>example@mail.com (Yujie Tang, Meiling Wang, Yinan Deng, Zibo Zheng, Jiagui Zhong, Yufeng Yue)</author>
      <guid isPermaLink="false">2409.18743v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Task-driven SLAM Benchmarking</title>
      <link>http://arxiv.org/abs/2409.16573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 7 figures, 1 table. Submitted to ICRA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 对于辅助机器人来说，SLAM（同步定位与地图构建）的一个关键应用是支持其在环境中导航并完成任务。&lt;h4&gt;2. 现有问题&lt;/h4&gt;   - 当前的SLAM基准测试未考虑基于任务的部署，其中重复性（精度）比准确性更为重要。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本文提出了一种任务驱动的基准测试框架，用于评估SLAM方法。&lt;h4&gt;4. 框架特点&lt;/h4&gt;   - 该框架考虑SLAM的映射能力，以精度作为关键指标，并且实施资源需求低。&lt;h4&gt;5. 实验设计&lt;/h4&gt;   - 在模拟和真实场景中测试最先进的SLAM方法，以提供对现代SLAM解决方案性能特性的见解。&lt;h4&gt;6. 关键发现&lt;/h4&gt;   - 结果表明，在典型室内环境中，主动立体SLAM的精度与基于LiDAR的SLAM相当。&lt;h4&gt;7. 意义&lt;/h4&gt;   - 该基准测试方法为任务驱动应用中的SLAM性能提供了更相关和准确的评估。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For assistive robots, one critical use case of SLAM is to supportlocalization as they navigate through an environment completing tasks. CurrentSLAM benchmarks do not consider task-based deployments where repeatability(precision) is more critical than accuracy. To address this gap, we propose atask-driven benchmarking framework for evaluating SLAM methods. The frameworkaccounts for SLAM's mapping capabilities, employs precision as a key metric,and has low resource requirements to implement. Testing of state-of-the-artSLAM methods in both simulated and real-world scenarios provides insights intothe performance properties of modern SLAM solutions. In particular, it showsthat passive stereo SLAM operates at a level of precision comparable toLiDAR-based SLAM in typical indoor environments. The benchmarking approachoffers a more relevant and accurate assessment of SLAM performance intask-driven applications.</description>
      <author>example@mail.com (Yanwei Du, Shiyu Feng, Carlton G. Cort, Patricio A. Vela)</author>
      <guid isPermaLink="false">2409.16573v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Revolutionizing Payload Inspection: A Self-Supervised Journey to Precision with Few Shots</title>
      <link>http://arxiv.org/abs/2409.18219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着网络的不断扩展和互联性增强，开发新颖的恶意软件检测方法的需求愈加明显。&lt;h4&gt;2. 问题陈述&lt;/h4&gt;   - 传统安全措施逐渐无法应对现代网络攻击的复杂性，深度包检测（DPI）在增强网络安全方面至关重要。&lt;h4&gt;3. DPI的优势&lt;/h4&gt;   - DPI能够深入分析网络流量，不仅检查网络包的元数据，还分析包负载中的实际内容，提供全面的数据视图。&lt;h4&gt;4. 深度学习的应用&lt;/h4&gt;   - 将先进的深度学习技术与DPI结合，提出了现代恶意软件检测方法。&lt;h4&gt;5. 现有挑战&lt;/h4&gt;   - 最先进的监督学习方法在处理未见攻击时存在局限，难以准确检测新攻击，并从之前攻击中迁移知识到新攻击，尤其是当标记样本数量较少时。&lt;h4&gt;6. 研究创新&lt;/h4&gt;   - 本文利用自监督学习和小样本学习的最新进展，提出了一种自监督的方法，通过遮蔽部分负载训练变换器，从大量未标记数据集中学习负载的嵌入表示。&lt;h4&gt;7. 方法流程&lt;/h4&gt;   - 提取的表示用于训练恶意软件检测算法，并采用小样本学习方法将检测器适应于新型攻击。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 在多个数据集上的实验结果显示，所提出的方法在新场景下具有良好的成功率和泛化能力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As networks continue to expand and become more interconnected, the need fornovel malware detection methods becomes more pronounced. Traditional securitymeasures are increasingly inadequate against the sophistication of modern cyberattacks. Deep Packet Inspection (DPI) has been pivotal in enhancing networksecurity, offering an in-depth analysis of network traffic that surpassesconventional monitoring techniques. DPI not only examines the metadata ofnetwork packets, but also dives into the actual content being carried withinthe packet payloads, providing a comprehensive view of the data flowing throughnetworks. The integration of advanced deep learning techniques with DPI hasintroduced modern methodologies into malware detection. However, the challengewith the state-of-the-art supervised learning approaches is that they preventthe generalization to unseen attacks embedded in the payloads, prohibiting themfrom accurately detecting new attacks and transferring knowledge learned fromprevious attacks to the new attacks with small labeled sample sizes. This paperleverages the recent advancements in self-supervised learning and few-shotlearning. Our proposed self-supervised approach trains a transformer to learnthe embedding of the payloads from a vast amount of unlabeled datasets bymasking portions of payloads, leading to a learnt representation that wellgeneralizes to various downstream tasks. Once the representation is extractedfrom payloads, they are used to train a malware detection algorithm. Therepresentation obtained from the transformer is then used to adapt the malwaredetector to novel types of attacks using few-shot learning approaches. Ourexperimental results across several datasets show the great success andgeneralization of the proposed approach to novel scenarios.</description>
      <author>example@mail.com (Kyle Stein, Arash Mahyari, Guillermo Francia III, Eman El-Sheikh)</author>
      <guid isPermaLink="false">2409.18219v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Causal Reinforcement Learning for Optimisation of Robot Dynamics in Unknown Environments</title>
      <link>http://arxiv.org/abs/2409.13423v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 12 figures, 3 tables. To be presented in 10th IEEE
  International Smart Cities Conference (ISC2-2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 机器人在未知环境中的自主操作面临挑战，主要由于缺乏对交互动态的知识，例如物体的可移动性。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 本文提出了一种新颖的因果强化学习（Causal Reinforcement Learning）方法，以增强机器人操作能力，并应用于城市搜索与救援（SAR）场景。&lt;h4&gt;3. 方法论&lt;/h4&gt;   - 该机器学习架构使机器人能够学习物体的视觉特征（如纹理和形状）与物体在交互时动态（如可移动性）之间的因果关系，从而显著改善决策过程。&lt;h4&gt;4. 实验设计&lt;/h4&gt;   - 进行了因果发现和强化学习实验，以验证因果强化学习的优越性能。&lt;h4&gt;5. 结果表现&lt;/h4&gt;   - 实验结果显示，在复杂情况下，与非因果模型相比，因果强化学习显著减少了学习时间，缩短幅度超过24.5%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous operations of robots in unknown environments are challenging dueto the lack of knowledge of the dynamics of the interactions, such as theobjects' movability. This work introduces a novel Causal Reinforcement Learningapproach to enhancing robotics operations and applies it to an urban search andrescue (SAR) scenario. Our proposed machine learning architecture enablesrobots to learn the causal relationships between the visual characteristics ofthe objects, such as texture and shape, and the objects' dynamics uponinteraction, such as their movability, significantly improving theirdecision-making processes. We conducted causal discovery and RL experimentsdemonstrating the Causal RL's superior performance, showing a notable reductionin learning times by over 24.5% in complex situations, compared to non-causalmodels.</description>
      <author>example@mail.com (Julian Gerald Dcruz, Sam Mahoney, Jia Yun Chua, Adoundeth Soukhabandith, John Mugabe, Weisi Guo, Miguel Arana-Catania)</author>
      <guid isPermaLink="false">2409.13423v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>TemporalPaD: a reinforcement-learning framework for temporal feature representation and dimension reduction</title>
      <link>http://arxiv.org/abs/2409.18597v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 最近在特征表示和维度减少方面的进展显示了它们对提高预测建模效率的重要性。&lt;h4&gt;2. 框架介绍&lt;/h4&gt;   - 本文提出了TemporalPaD，一个新颖的端到端深度学习框架，专为时间模式数据集设计。&lt;h4&gt;3. 集成方法&lt;/h4&gt;   - TemporalPaD结合了强化学习（RL）与神经网络，实现特征表示与特征减少的并行处理。&lt;h4&gt;4. 模块结构&lt;/h4&gt;   - 框架由三个协作模块组成：     - **策略模块（Policy Module）**：作为演员，负责通过RL进行维度减少。     - **表示模块（Representation Module）**：负责特征提取。     - **分类模块（Classification Module）**：与表示模块共同作为评论者。&lt;h4&gt;5. 评估方法&lt;/h4&gt;   - 使用29个UCI数据集对TemporalPaD进行全面评估，这些数据集是验证特征减少算法的公认基准，采用10次独立测试和10折交叉验证。&lt;h4&gt;6. 应用实例&lt;/h4&gt;   - TemporalPaD特别设计用于时间序列数据，已应用于真实世界的DNA分类问题，涉及增强子类别和增强子强度。&lt;h4&gt;7. 结果表现&lt;/h4&gt;   - 结果显示，TemporalPaD是一个高效且有效的框架，适用于结构化数据和序列数据集的特征减少。&lt;h4&gt;8. 源代码获取&lt;/h4&gt;   - 提出的TemporalPaD的源代码作为补充材料免费提供，访问地址为 [Health Informatics Lab](http://www.healthinformaticslab.org/supp/)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in feature representation and dimension reduction havehighlighted their crucial role in enhancing the efficacy of predictivemodeling. This work introduces TemporalPaD, a novel end-to-end deep learningframework designed for temporal pattern datasets. TemporalPaD integratesreinforcement learning (RL) with neural networks to achieve concurrent featurerepresentation and feature reduction. The framework consists of threecooperative modules: a Policy Module, a Representation Module, and aClassification Module, structured based on the Actor-Critic (AC) framework. ThePolicy Module, responsible for dimensionality reduction through RL, functionsas the actor, while the Representation Module for feature extraction and theClassification Module collectively serve as the critic. We comprehensivelyevaluate TemporalPaD using 29 UCI datasets, a well-known benchmark forvalidating feature reduction algorithms, through 10 independent tests and10-fold cross-validation. Additionally, given that TemporalPaD is specificallydesigned for time series data, we apply it to a real-world DNA classificationproblem involving enhancer category and enhancer strength. The resultsdemonstrate that TemporalPaD is an efficient and effective framework forachieving feature reduction, applicable to both structured data and sequencedatasets. The source code of the proposed TemporalPaD is freely available assupplementary material to this article and athttp://www.healthinformaticslab.org/supp/.</description>
      <author>example@mail.com (Xuechen Mu, Zhenyu Huang, Kewei Li, Haotian Zhang, Xiuli Wang, Yusi Fan, Kai Zhang, Fengfeng Zhou)</author>
      <guid isPermaLink="false">2409.18597v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Assessment of Submillimeter Precision via Structure from Motion Technique in Close-Range Capture Environments</title>
      <link>http://arxiv.org/abs/2409.15602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This study comprises 23 pages, 15 figures, and 5 tables. It is part
  of an ongoing PhD thesis currently under development&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文探讨了通过运动结构法（SfM）创建3D模型的潜力，作为一种高效、经济的结构监测策略。&lt;h4&gt;2. 应用领域&lt;/h4&gt;   - SfM技术广泛应用于多个工程领域，尤其适用于从数十米外拍摄的照片创建大型结构模型。&lt;h4&gt;3. 研究空白&lt;/h4&gt;   - 目前对于SfM在实验室分析（如结构测试）中的可用性和操作程序讨论较少。&lt;h4&gt;4. 实验目的&lt;/h4&gt;   - 本研究旨在利用SfM方法在短距离拍摄下创建亚毫米质量的模型，以用于结构测试。&lt;h4&gt;5. 实验设计&lt;/h4&gt;   - 进行了系列实验，在1米距离拍摄，采用不同的质量设置，包括相机校准模型、尺度条分布、重叠率和垂直与倾斜图像的使用。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 使用校准模型、适当分布的尺度条、80%的重叠率以及垂直和倾斜图像的结合，获得了约0.1毫米的均方根误差（RMSE）值。&lt;h4&gt;7. 技术潜力&lt;/h4&gt;   - 结果表明，该技术在实验室环境中满足结构测试所需的亚毫米定位质量，展示了其在3D建模中的应用潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Creating 3D models through the Structure from Motion technique is arecognized, efficient, cost-effective structural monitoring strategy. Thistechnique is applied in several engineering fields, particularly for creatingmodels of large structures from photographs taken a few tens of meters away.However, discussions about its usability and the procedures for conductinglaboratory analysis, such as structural tests, are rarely addressed. This studyinvestigates the potential of the SfM method to create submillimeter-qualitymodels for structural tests, with short-distance captures. A series ofexperiments was carried out, with photographic captures at a 1-meter distance,using different quality settings: camera calibration model, Scale Barsdispersion, overlapping rates, and the use of vertical and oblique images.Employing a calibration model with images taken over a test board and a set ofScale Bars (SB) appropriately distributed over the test area, an overlap rateof 80 percent, and the integration of vertical and oblique images, RMSE valuesof approximately 0.1 mm were obtained. This result indicates the potentialapplication of the technique for 3D modeling with submillimeter positionalquality, as required for structural tests in laboratory environments.</description>
      <author>example@mail.com (Francisco Roza de Moraes, Irineu da Silva)</author>
      <guid isPermaLink="false">2409.15602v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>A study on the effects of mixed explicit and implicit communications in human-virtual-agent interactions</title>
      <link>http://arxiv.org/abs/2409.18745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 12 figures, 4 tables. Under review for International
  Journal of Social Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文探讨了人类与机器人（或虚拟代理）之间的沟通，强调这种沟通对互动的重要性，并受到人类沟通方式的启发。&lt;h4&gt;2. 沟通方式&lt;/h4&gt;   - 研究涉及显式（如手势、鼠标和键盘输入、声音以及屏幕信息）和隐式（如视线方向、位置、面部表情和眉毛上扬）沟通方式的互动实验。&lt;h4&gt;3. 实验目的&lt;/h4&gt;   - 评估混合显式和隐式沟通对比纯显式沟通的效果。&lt;h4&gt;4. 结果分析&lt;/h4&gt;   - 使用贝叶斯参数估计法得出的结果表明，混合沟通方式下的错误数量和任务执行时间没有显著变化，交互的感知效率也未受影响。&lt;h4&gt;5. 主观评价提升&lt;/h4&gt;   - 在使用混合沟通方式时，虚拟代理的接受度、社交性和透明度显著提高，分别达到88.3%、92%和92.9%的效果大小后验分布超出实际等效区域的上限。&lt;h4&gt;6. 任务相关度量&lt;/h4&gt;   - 任务相关的度量（如时间、错误数量和交互的感知效率）在本实验中未受沟通类型的影响。&lt;h4&gt;7. 人类接受度&lt;/h4&gt;   - 主观评价的改善表明，人类对混合显式和隐式沟通方式的接受度更高，表明这种沟通方式可能更有效。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Communication between humans and robots (or virtual agents) is essential forinteraction and often inspired by human communication, which uses gestures,facial expressions, gaze direction, and other explicit and implicit means. Thiswork presents an interaction experiment where humans and virtual agentsinteract through explicit (gestures, manual entries using mouse and keyboard,voice, sound, and information on screen) and implicit (gaze direction,location, facial expressions, and raise of eyebrows) communication to evaluatethe effect of mixed explicit-implicit communication against purely explicitcommunication. Results obtained using Bayesian parameter estimation show thatthe number of errors and task execution time did not significantly change whenmixed explicit and implicit communications were used, and neither the perceivedefficiency of the interaction. In contrast, acceptance, sociability, andtransparency of the virtual agent increased when using mixed communicationmodalities (88.3%, 92%, and 92.9% of the effect size posterior distribution ofeach variable, respectively, were above the upper limit of the region ofpractical equivalence). This suggests that task-related measures, such as time,number of errors, and perceived efficiency of the interaction, have not beeninfluenced by the communication type in our particular experiment. However, theimprovement of subjective measures related to the virtual agent, such asacceptance, sociability, and transparency, suggests that humans are morereceptive to mixed explicit and implicit communications.</description>
      <author>example@mail.com (Ana Christina Almada Campos, Bruno Vilhena Adorno)</author>
      <guid isPermaLink="false">2409.18745v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>HGSLoc: 3DGS-based Heuristic Camera Pose Refinement</title>
      <link>http://arxiv.org/abs/2409.10925v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 视觉定位是指在已知场景表示中确定相机姿态和方向的过程，但受到照明变化和视角变动等因素的影响。&lt;h4&gt;2. 提出的框架&lt;/h4&gt;   - 本文提出了HGSLoc，一种新颖的轻量级即插即用姿态优化框架，将3D重建与启发式优化策略结合，以提高姿态估计精度。&lt;h4&gt;3. 几何地图引入&lt;/h4&gt;   - 引入显式几何地图用于3D表示和高保真渲染，从而生成高质量合成视图以支持准确的视觉定位。&lt;h4&gt;4. 速度与精度提升&lt;/h4&gt;   - 与基于NeRF的神经渲染定位方法相比，HGSLoc展示了更快的渲染速度和更高的定位精度。&lt;h4&gt;5. 启发式优化策略&lt;/h4&gt;   - 采用启发式优化策略，能够快速定位目标节点，并通过设定步级优化步长来增强小误差场景下的姿态精度。&lt;h4&gt;6. 优化能力&lt;/h4&gt;   - 通过精心设计的启发式函数，提供高效的优化能力，能够在粗略定位估计中快速减少误差。&lt;h4&gt;7. 模型复杂性降低&lt;/h4&gt;   - 该方法减少了对复杂神经网络模型的依赖，同时在噪声和挑战性环境中展示了更强的鲁棒性和更高的定位精度。&lt;h4&gt;8. 基准测试表现&lt;/h4&gt;   - 提出的优化框架在多个基准数据集（如7Scenes和DB数据集）上表现出色，展示了3D重建与启发式优化策略结合的优势。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization refers to the process of determining camera poses andorientation within a known scene representation. This task is often complicatedby factors such as illumination changes and variations in viewing angles. Inthis paper, we propose HGSLoc, a novel lightweight, plug and-play poseoptimization framework, which integrates 3D reconstruction with a heuristicrefinement strategy to achieve higher pose estimation accuracy. Specifically,we introduce an explicit geometric map for 3D representation and high-fidelityrendering, allowing the generation of high-quality synthesized views to supportaccurate visual localization. Our method demonstrates a faster rendering speedand higher localization accuracy compared to NeRF-based neural renderinglocalization approaches. We introduce a heuristic refinement strategy, itsefficient optimization capability can quickly locate the target node, while weset the step-level optimization step to enhance the pose accuracy in thescenarios with small errors. With carefully designed heuristic functions, itoffers efficient optimization capabilities, enabling rapid error reduction inrough localization estimations. Our method mitigates the dependence on complexneural network models while demonstrating improved robustness against noise andhigher localization accuracy in challenging environments, as compared to neuralnetwork joint optimization strategies. The optimization framework proposed inthis paper introduces novel approaches to visual localization by integratingthe advantages of 3D reconstruction and heuristic refinement strategy, whichdemonstrates strong performance across multiple benchmark datasets, including7Scenes and DB dataset.</description>
      <author>example@mail.com (Zhongyan Niu, Zhen Tan, Jinpu Zhang, Xueliang Yang, Dewen Hu)</author>
      <guid isPermaLink="false">2409.10925v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Robo-Platform: A Robotic System for Recording Sensors and Controlling Robots</title>
      <link>http://arxiv.org/abs/2409.16595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project repository: https://github.com/m-dayani/robo-platform Youtube
  Video: https://youtu.be/BTQ4yLB1bak Dataset:
  https://drive.google.com/drive/folders/1OZqdA1xa-SyJ64qL_TibqhtwhR1fWWrx?usp=sharing&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文探讨了移动智能手机在机器人项目中的应用，特别是其集成的传感器（如相机、IMU、GNSS）和通信渠道。&lt;h4&gt;2. 手机优势&lt;/h4&gt;   - 移动智能手机经济实惠、便于携带且可编程，适合用于测试、数据采集和控制移动机器人等多种机器人应用。&lt;h4&gt;3. 机器人系统构建&lt;/h4&gt;   - 提出了一个机器人系统，包括一部Android手机、一块通过USB连接的微控制器板和一个远程无线控制站。&lt;h4&gt;4. 数据采集模式&lt;/h4&gt;   - 在数据采集模式下，Android设备能够记录多种配置的相机、IMU、GNSS单元和外部USB ADC通道的数据集，适用于姿态估计和场景重建等应用。&lt;h4&gt;5. 机器人控制模式&lt;/h4&gt;   - 在机器人控制模式下，Android手机、微控制器板和其他外设构成了移动或固定的机器人系统，通过Wi-Fi或蓝牙与远程服务器连接进行控制。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实验证明，尽管SLAM和增强现实（AR）应用可以利用采集的数据，但所提出的系统能够为处理这些噪声和间歇性测量的高级算法奠定基础。&lt;h4&gt;7. 通信媒体特性&lt;/h4&gt;   - 研究了通信媒体的特性，并包含了两个示例机器人项目，涉及控制玩具车和四旋翼飞行器。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile smartphones compactly provide sensors such as cameras, IMUs, GNSSmeasurement units, and wireless and wired communication channels required forrobotics projects. They are affordable, portable, and programmable, which makesthem ideal for testing, data acquisition, controlling mobile robots, and manyother robotic applications. A robotic system is proposed in this paper,consisting of an Android phone, a microcontroller board attached to the phonevia USB, and a remote wireless controller station. In the data acquisitionmode, the Android device can record a dataset of a diverse configuration ofmultiple cameras, IMUs, GNSS units, and external USB ADC channels in the rawestformat used for, but not limited to, pose estimation and scene reconstructionapplications. In robot control mode, the Android phone, a microcontrollerboard, and other peripherals constitute the mobile or stationary roboticsystem. This system is controlled using a remote server connected over Wi-Fi orBluetooth. Experiments show that although the SLAM and AR applications canutilize the acquired data, the proposed system can pave the way for moreadvanced algorithms for processing these noisy and sporadic measurements.Moreover, the characteristics of the communication media are studied, and twoexample robotic projects, which involve controlling a toy car and a quadcopter,are included.</description>
      <author>example@mail.com (Masoud Dayani Najafabadi)</author>
      <guid isPermaLink="false">2409.16595v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Multi-platoon car-following models with flexible platoon sizes and communication levels</title>
      <link>http://arxiv.org/abs/2409.18304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint for IEEE&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文将单车队跟车模型扩展至多车队跟车模型，针对连接和自主车辆（CAV）设置灵活的车队规模和通信水平。&lt;h4&gt;2. 通信方法&lt;/h4&gt;   - 具体考虑了车队之间的前向和后向通信方式，并考虑了通信延迟。&lt;h4&gt;3. 稳定性分析&lt;/h4&gt;   - 数学证明了一些线性稳定性的一般结果，并进行了数值模拟，以展示车队规模和通信水平的影响。&lt;h4&gt;4. 混合交通条件&lt;/h4&gt;   - 模拟结果表明，在混合交通条件下，CAV车队能够稳定一定比例的人驱动车辆（HDV）。&lt;h4&gt;5. 一致性验证&lt;/h4&gt;   - 模拟结果与理论分析一致，特别是在环形道路场景中，证明了CAV车队的稳定性。&lt;h4&gt;6. 应用建议&lt;/h4&gt;   - 本文为自主车辆（AV）的通信系统设计和CAV与HDV混合交通流管理提供了建议。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we extend a single platoon car-following (CF) model to somemulti-platoon CF models for connected and autonomous vehicles (CAVs) withflexible platoon size and communication level. Specifically, we considerforward and backward communication methods between platoons with delays. Somegeneral results of linear stability are mathematically proven, and numericalsimulations are performed to illustrate the effects of platoon sizes andcommunication levels, as well as to demonstrate the potential for stabilizinghuman-driven vehicles (HDVs) in mixed traffic conditions. The simulationresults are consistent with theoretical analysis, and demonstrate that in thering road scenario, CAV platoons can stabilize certain percentage of HDVs. Thispaper can provide suggestions for the design of communication system ofautonomous vehicles (AVs), and management of mixed traffic flow of CAVs andHDVs.</description>
      <author>example@mail.com (Shouwei Hui, Michael Zhang)</author>
      <guid isPermaLink="false">2409.18304v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MACeIP: A Multimodal Ambient Context-enriched Intelligence Platform in Smart Cities</title>
      <link>http://arxiv.org/abs/2409.15243v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 6 figures, IEEE/IEIE ICCE-Asia 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文介绍了一种多模态环境上下文增强智能平台（MACeIP），旨在提升智慧城市的城市管理和公民参与。&lt;h4&gt;2. 平台整合技术&lt;/h4&gt;   - 平台集成了先进技术，包括物联网（IoT）传感器、边缘计算和云计算，以及多模态人工智能，以创建一个响应迅速的智能城市生态系统。&lt;h4&gt;3. 关键组成部分&lt;/h4&gt;   - 包括公民互动的互动中心、广泛的物联网传感器网络、智能公共资产管理、行人监测系统、城市规划门户和云计算系统。&lt;h4&gt;4. 原型展示&lt;/h4&gt;   - 在多个城市展示了MACeIP的原型，重点聚焦于新不伦瑞克省的弗雷德里克顿。&lt;h4&gt;5. 创新贡献&lt;/h4&gt;   - 该研究通过提供一种可扩展、高效且以用户为中心的城市智能与管理方法，为创新城市发展做出了贡献。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a Multimodal Ambient Context-enriched IntelligencePlatform (MACeIP) for Smart Cities, a comprehensive system designed to enhanceurban management and citizen engagement. Our platform integrates advancedtechnologies, including Internet of Things (IoT) sensors, edge and cloudcomputing, and Multimodal AI, to create a responsive and intelligent urbanecosystem. Key components include Interactive Hubs for citizen interaction, anextensive IoT sensor network, intelligent public asset management, a pedestrianmonitoring system, a City Planning Portal, and a Cloud Computing System. Wedemonstrate the prototype of MACeIP in several cities, focusing on Fredericton,New Brunswick. This work contributes to innovative city development by offeringa scalable, efficient, and user-centric approach to urban intelligence andmanagement.</description>
      <author>example@mail.com (Truong Thanh Hung Nguyen, Phuc Truong Loc Nguyen, Monica Wachowicz, Hung Cao)</author>
      <guid isPermaLink="false">2409.15243v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Tail Risk Analysis for Financial Time Series</title>
      <link>http://arxiv.org/abs/2409.18643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Book chapter to appear in the Handbook on Statistics of Extremes
  (Chapman &amp; Hall / CRC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本书章节阐述了如何将极值统计应用于金融时间序列数据。&lt;h4&gt;2. 数据特性&lt;/h4&gt;   - 金融时间序列数据通常表现出强烈的序列依赖性，这使得尾部风险的评估变得复杂。&lt;h4&gt;3. 尾部风险估计方法&lt;/h4&gt;   - 讨论了两种主要的尾部风险估计方法：无条件和有条件分位数预测。&lt;h4&gt;4. 案例研究&lt;/h4&gt;   - 以标准普尔500指数为案例，评估序列（极值）依赖性，进行无条件和有条件的风险分析，并应用回测方法。&lt;h4&gt;5. 多变量尾部依赖性&lt;/h4&gt;   - 探讨序列依赖性对多变量尾部依赖性的影响。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This book chapter illustrates how to apply extreme value statistics tofinancial time series data. Such data often exhibits strong serial dependence,which complicates assessment of tail risks. We discuss the two main approchesto tail risk estimation, unconditional and conditional quantile forecasting. Weuse the S&amp;P 500 index as a case study to assess serial (extremal) dependence,perform an unconditional and conditional risk analysis, and apply backtestingmethods. Additionally, the chapter explores the impact of serial dependence onmultivariate tail dependence.</description>
      <author>example@mail.com (Anna Kiriliouk, Chen Zhou)</author>
      <guid isPermaLink="false">2409.18643v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the potential of collaborative UAV 3D mapping in Kenyan savanna for wildlife research</title>
      <link>http://arxiv.org/abs/2409.15914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at IMAV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文探讨了基于无人机（UAV）的生物多样性保护应用，为研究人员提供了许多数据获取优势。&lt;h4&gt;2. 无人机平台功能&lt;/h4&gt;   - 配备数据处理硬件的无人机平台能够支持保护挑战，包括3D栖息地绘图、监视和监控解决方案。&lt;h4&gt;3. 实时重建与定位&lt;/h4&gt;   - 高质量的实时场景重建和无人机定位可以优化单个或协作任务的探索与利用平衡。&lt;h4&gt;4. 研究框架&lt;/h4&gt;   - 本文探索了两种协作框架的潜力：视觉同时定位与地图构建（V-SLAM）和运动构造（SfM），用于3D绘图目的。&lt;h4&gt;5. 结果比较&lt;/h4&gt;   - 将这两种协作框架的结果与标准的离线方法进行比较，以评估其性能和效果。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; UAV-based biodiversity conservation applications have exhibited many dataacquisition advantages for researchers. UAV platforms with embedded dataprocessing hardware can support conservation challenges through 3D habitatmapping, surveillance and monitoring solutions. High-quality real-time scenereconstruction as well as real-time UAV localization can optimize theexploration vs exploitation balance of single or collaborative mission. In thiswork, we explore the potential of two collaborative frameworks - VisualSimultaneous Localization and Mapping (V-SLAM) and Structure-from-Motion (SfM)for 3D mapping purposes and compare results with standard offline approaches.</description>
      <author>example@mail.com (Vandita Shukla, Luca Morelli, Pawel Trybala, Fabio Remondino, Wentian Gan, Yifei Yu, Xin Wang)</author>
      <guid isPermaLink="false">2409.15914v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Topological SLAM in colonoscopies leveraging deep features and topological priors</title>
      <link>http://arxiv.org/abs/2409.16806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 介绍了ColonSLAM系统，该系统结合了经典的多地图度量SLAM与深度特征和拓扑先验，以创建整个结肠的拓扑地图。&lt;h4&gt;2. SLAM管道功能&lt;/h4&gt;   - SLAM管道能够生成表示结肠短视频片段位置的独立度量子地图，但由于形变和SIFT描述符在医疗领域的性能有限，无法合并可见子地图。&lt;h4&gt;3. 拓扑先验的引导&lt;/h4&gt;   - ColonSLAM通过拓扑先验进行引导，结合了一个深度定位网络，该网络经过训练以区分两幅图像是否来自同一地点。&lt;h4&gt;4. 匹配网络&lt;/h4&gt;   - 使用基于变换器的软验证匹配网络，能够在探索过程中关联时间上相距较远的子地图，将它们归类为同一结肠位置的节点。&lt;h4&gt;5. 地图构建能力&lt;/h4&gt;   - 该方法能够构建比文献中任何其他方法更复杂的地图。&lt;h4&gt;6. 实验验证&lt;/h4&gt;   - 在Endomapper数据集上展示了该方法的有效性，表明其在实际人类探索中生成整个结肠地图的潜力。&lt;h4&gt;7. 代码和模型提供&lt;/h4&gt;   - 提供了代码和模型，链接地址为：[GitHub - ColonSLAM](https://github.com/endomapper/ColonSLAM)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce ColonSLAM, a system that combines classical multiple-map metricSLAM with deep features and topological priors to create topological maps ofthe whole colon. The SLAM pipeline by itself is able to create disconnectedindividual metric submaps representing locations from short video subsectionsof the colon, but is not able to merge covisible submaps due to deformationsand the limited performance of the SIFT descriptor in the medical domain.ColonSLAM is guided by topological priors and combines a deep localizationnetwork trained to distinguish if two images come from the same place or notand the soft verification of a transformer-based matching network, being ableto relate far-in-time submaps during an exploration, grouping them in nodesimaging the same colon place, building more complex maps than any otherapproach in the literature. We demonstrate our approach in the Endomapperdataset, showing its potential for producing maps of the whole colon in realhuman explorations. Code and models are available at:https://github.com/endomapper/ColonSLAM.</description>
      <author>example@mail.com (Javier Morlana, Juan D. Tardós, José M. M. Montiel)</author>
      <guid isPermaLink="false">2409.16806v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>GephiForR: An R package for creating Gephi-style network visualizations</title>
      <link>http://arxiv.org/abs/2409.18646v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文介绍了GephiForR，这是一个R包，旨在在R中复现基于Java的Gephi的关键绘图工具。&lt;h4&gt;2. 目标用户&lt;/h4&gt;   - 该包对具有最低R经验的用户友好，特别实现了ForceAtlas2，这是由Jacomy等人（2014）为Gephi开发的关键布局功能。&lt;h4&gt;3. 主要创新&lt;/h4&gt;   - 最大的进展是能够将先前的位置作为基线传递给ForceAtlas2，这对绘制时间序列数据的网络布局演变尤为有用。&lt;h4&gt;4. 适用范围&lt;/h4&gt;   - GephiForR特别适合处理少于1000个节点的网络，因R依赖单线程计算，较大的网络计算时间较长，但该包也能够处理更大的网络。&lt;h4&gt;5. 性能验证&lt;/h4&gt;   - 通过各种示例和与现有工具及Gephi本身的比较，展示了该包的能力，并评估了其性能和速度。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces GephiForR, an R package designed to replicateJava-based Gephi's key plotting tools in R. The package is accessible to thosewith minimal R experience and, in particular, implements ForceAtlas2, the keylayout feature developed for Gephi by Jacomy et al. (2014). The mostsignificant advancement is the ability to pass previous positions intoForceAtlas2 as baselines, a particularly useful feature for plotting theevolution of network layouts for time series data. GephiForR is especiallysuited for networks of less than 1000 nodes, simply because R's dependence onsingle-thread computation means that larger networks take longer to compute,but the package can handle these larger networks as well. I demonstrate thepackage's capabilities through various examples and comparisons with existingtools and Gephi itself, assessing performance and speed.</description>
      <author>example@mail.com (Julia Manso)</author>
      <guid isPermaLink="false">2409.18646v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Peer-to-Peer Learning Dynamics of Wide Neural Networks</title>
      <link>http://arxiv.org/abs/2409.15267v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 论文探讨了点对点学习这一日益流行的框架，使得超越5G的分布式边缘设备能够以隐私保护的方式协作训练深度神经网络，而无需中央服务器的支持。&lt;h4&gt;2. 设计挑战&lt;/h4&gt;   - 在新兴环境（如智能城市）中，神经网络训练算法面临许多设计考虑因素（如网络架构和超参数），这些在实际部署中难以调优。&lt;h4&gt;3. 研究需求&lt;/h4&gt;   - 亟需对用于训练高度非凸神经网络的分布式优化算法的训练动态进行表征，尤其是在点对点学习环境中。&lt;h4&gt;4. 研究方法&lt;/h4&gt;   - 本文提供了使用流行的分布式梯度下降（DGD）算法训练宽神经网络的学习动态的显式非渐近特征描述。&lt;h4&gt;5. 理论基础&lt;/h4&gt;   - 研究结果结合了神经切线核（NTK）理论的最新进展以及之前在分布式学习和共识方面的广泛工作。&lt;h4&gt;6. 结果验证&lt;/h4&gt;   - 通过准确预测用于分类任务的宽神经网络的参数和误差动态，验证了我们的分析结果。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Peer-to-peer learning is an increasingly popular framework that enablesbeyond-5G distributed edge devices to collaboratively train deep neuralnetworks in a privacy-preserving manner without the aid of a central server.Neural network training algorithms for emerging environments, e.g., smartcities, have many design considerations that are difficult to tune indeployment settings -- such as neural network architectures andhyperparameters. This presents a critical need for characterizing the trainingdynamics of distributed optimization algorithms used to train highly nonconvexneural networks in peer-to-peer learning environments. In this work, we providean explicit, non-asymptotic characterization of the learning dynamics of wideneural networks trained using popular distributed gradient descent (DGD)algorithms. Our results leverage both recent advancements in neural tangentkernel (NTK) theory and extensive previous work on distributed learning andconsensus. We validate our analytical results by accurately predicting theparameter and error dynamics of wide neural networks trained for classificationtasks.</description>
      <author>example@mail.com (Shreyas Chaudhari, Srinivasa Pranav, Emile Anand, José M. F. Moura)</author>
      <guid isPermaLink="false">2409.15267v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Improving Agent Behaviors with RL Fine-tuning for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2409.18343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 在自主车辆研究中，建模代理行为是一个主要挑战，具有重要应用，包括构建现实可靠的离线评估模拟和预测交通代理的运动以进行在线规划。&lt;h4&gt;2. 现有方法的局限&lt;/h4&gt;   - 尽管监督学习在多个领域建模代理方面取得了成功，但这些模型在测试时可能遭遇分布转移的问题。&lt;h4&gt;3. 研究方法&lt;/h4&gt;   - 本文通过闭环微调行为模型，结合强化学习，提高代理行为的可靠性。&lt;h4&gt;4. 性能提升&lt;/h4&gt;   - 我们的方法在整体性能上有所改善，同时在特定指标（如碰撞率）上也表现出明显的提升，特别是在Waymo Open Sim Agents挑战中。&lt;h4&gt;5. 新基准提出&lt;/h4&gt;   - 提出了一个新的策略评估基准，用于直接评估模拟代理的能力，以衡量自主车辆规划者的质量。&lt;h4&gt;6. 有效性验证&lt;/h4&gt;   - 在该新基准上展示了我们方法的有效性，证明其在评估和提升代理行为方面的潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A major challenge in autonomous vehicle research is modeling agent behaviors,which has critical applications including constructing realistic and reliablesimulations for off-board evaluation and forecasting traffic agents motion foronboard planning. While supervised learning has shown success in modelingagents across various domains, these models can suffer from distribution shiftwhen deployed at test-time. In this work, we improve the reliability of agentbehaviors by closed-loop fine-tuning of behavior models with reinforcementlearning. Our method demonstrates improved overall performance, as well asimproved targeted metrics such as collision rate, on the Waymo Open Sim Agentschallenge. Additionally, we present a novel policy evaluation benchmark todirectly assess the ability of simulated agents to measure the quality ofautonomous vehicle planners and demonstrate the effectiveness of our approachon this new benchmark.</description>
      <author>example@mail.com (Zhenghao Peng, Wenjie Luo, Yiren Lu, Tianyi Shen, Cole Gulino, Ari Seff, Justin Fu)</author>
      <guid isPermaLink="false">2409.18343v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Transparency evaluation for the Kinematic Design of the Harnesses through Human-Exoskeleton Interaction Modeling</title>
      <link>http://arxiv.org/abs/2409.18755v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 下肢外骨骼（LLEs）是可穿戴机器人，旨在为用户提供机械动力。&lt;h4&gt;2. 用户与外骨骼的连接&lt;/h4&gt;   - 人-外骨骼连接必须保持用户的自然行为，避免不必要的力的产生，因此，许多研究专注于这些力的最小化。&lt;h4&gt;3. 建模的重要性&lt;/h4&gt;   - 鉴于反复原型制作和实验测试的复杂性，对外骨骼及其与用户的物理交互进行建模是一种有价值的方法，用于评估设计效果。&lt;h4&gt;4. 提出的方法&lt;/h4&gt;   - 本文提出了一种新方法，通过灵活的仿真工具比较不同的外骨骼配置。   - 该方法考虑了设备动态的仿真，包括与穿戴者的交互，以评估多种连接机制设计以及LLE的运动学和驱动。&lt;h4&gt;5. 优化过程&lt;/h4&gt;   - 评估基于通过优化过程最小化交互扭矩，优化变量包括接口的阻抗参数及LLE关节变量轨迹与穿戴者关节运动的相似性。&lt;h4&gt;6. 实验验证&lt;/h4&gt;   - 使用可穿戴步态外骨骼（Wearable Walker LLE）进行不同配置的探索性测试，并测量交互力。&lt;h4&gt;7. 结果比较&lt;/h4&gt;   - 实验数据与优化结果进行了比较，证明所提方法提供的接触扭矩估计与收集的测量数据及文献中的先前结果一致。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lower Limb Exoskeletons (LLEs) are wearable robots that provide mechanicalpower to the user. Human-exoskeleton (HE) connections must preserve the user'snatural behavior during the interaction, avoiding undesired forces. Therefore,numerous works focus on their minimization. Given the inherent complications ofrepeatedly prototyping and experimentally testing a device, modeling theexoskeleton and its physical interaction with the user emerges as a valuableapproach for assessing the design effects. This paper proposes a novel methodto compare different exoskeleton configurations with a flexible simulationtool. This approach contemplates simulating the dynamics of the device,including its interaction with the wearer, to evaluate multiple connectionmechanism designs along with the kinematics and actuation of the LLE. Thisevaluation is based on the minimization of the interaction wrenches through anoptimization process that includes the impedance parameters at the interfacesas optimization variables and the similarity of the LLE's joint variablestrajectories with the motion of the wearer's articulations. Exploratory testsare conducted using the Wearable Walker LLE in different configurations andmeasuring the interaction forces. Experimental data are then compared to theoptimization outcomes, proving that the proposed method provides contact wrenchestimations consistent with the collected measurements and previous outcomesfrom the literature. Copyright 2024 IEEE. Personal use of this material ispermitted. Permission from IEEE must be obtained for all other uses, in anycurrent or future media, including reprinting/republishing this material foradvertising or promotional purposes, creating new collective works, for resaleor redistribution to servers or lists, or reuse of any copyrighted component ofthis work in other works.</description>
      <author>example@mail.com (Riccardo Bezzini, Carlo Alberto Avizzano, Francesco Porcini, Alessandro Filippeschi)</author>
      <guid isPermaLink="false">2409.18755v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Initialization of Monocular Visual Navigation for Autonomous Agents Using Modified Structure from Small Motion</title>
      <link>http://arxiv.org/abs/2409.16465v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 1 page for references, 6 figures, 1 table, IEEEtran format
  This work has been submitted to the IEEE for possible publication. Copyright
  may be transferred without notice, after which this version may no longer be
  accessible&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 提出了一个独立的单目视觉同步定位与地图构建（vSLAM）初始化流程，专为太空中的自主机器人设计。&lt;h4&gt;2. 方法论&lt;/h4&gt;   - 采用了一种最先进的因子图优化流程，增强了经典的小运动结构（SfSM）方法，以稳健地初始化单目代理在弱透视投影场景中的定位。&lt;h4&gt;3. 挑战应对&lt;/h4&gt;   - 解决了航天器检查轨迹带来的视觉估计挑战，包括：     - **中心指向运动**：加剧了浮雕模糊性。     - **场景中存在主导平面**：导致经典运动结构（SfM）中的运动估计退化。&lt;h4&gt;4. 实验验证&lt;/h4&gt;   - 在具有弱透视投影的模拟卫星检查图像上验证了该方法的有效性。&lt;h4&gt;5. 性能比较&lt;/h4&gt;   - 证明了所提方法的有效性，并与其他单目初始化程序相比，展现了改进的性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a standalone monocular visual Simultaneous Localization andMapping (vSLAM) initialization pipeline for autonomous robots in space. Ourmethod, a state-of-the-art factor graph optimization pipeline, enhancesclassical Structure from Small Motion (SfSM) to robustly initialize a monocularagent in weak-perspective projection scenes. Furthermore, it overcomes visualestimation challenges introduced by spacecraft inspection trajectories, suchas: center-pointing motion, which exacerbates the bas-relief ambiguity, and thepresence of a dominant plane in the scene, which causes motion estimationdegeneracies in classical Structure from Motion (SfM). We validate our methodon realistic, simulated satellite inspection images exhibiting weak-perspectiveprojection, and we demonstrate its effectiveness and improved performancecompared to other monocular initialization procedures.</description>
      <author>example@mail.com (Juan-Diego Florez, Mehregan Dor, Panagiotis Tsiotras)</author>
      <guid isPermaLink="false">2409.16465v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Inline Photometrically Calibrated Hybrid Visual SLAM</title>
      <link>http://arxiv.org/abs/2409.16810v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 本文提出了一种集成的视觉SLAM方法，结合了在线序列光度校准与混合直接-间接视觉SLAM（H-SLAM）。&lt;h4&gt;2. 光度校准的作用&lt;/h4&gt;   - 光度校准有助于在不同照明条件下规范化像素强度值，从而改善H-SLAM的直接组件。&lt;h4&gt;3. 间接组件的益处&lt;/h4&gt;   - 由于在可变光照条件下检测的特征更加稳定，光度校准对H-SLAM的间接组件也带来了额外的好处。&lt;h4&gt;4. 实验验证&lt;/h4&gt;   - 所提出的光度校准H-SLAM在多个数据集上进行了测试，包括TUM monoVO和我们创建的数据集。&lt;h4&gt;5. 性能比较&lt;/h4&gt;   - 校准后的H-SLAM在所有实验中超越了其他最先进的直接、间接和混合视觉SLAM系统。&lt;h4&gt;6. 现场测试结果&lt;/h4&gt;   - 在我们现场测试的在线SLAM中，校准H-SLAM也显著优于其他SLAM系统。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an integrated approach to Visual SLAM, merging onlinesequential photometric calibration within a Hybrid direct-indirect visual SLAM(H-SLAM). Photometric calibration helps normalize pixel intensity values underdifferent lighting conditions, and thereby improves the direct component of ourH-SLAM. A tangential benefit also results to the indirect component of H-SLAMgiven that the detected features are more stable across variable lightingconditions. Our proposed photometrically calibrated H-SLAM is tested on severaldatasets, including the TUM monoVO as well as on a dataset we created.Calibrated H-SLAM outperforms other state of the art direct, indirect, andhybrid Visual SLAM systems in all the experiments. Furthermore, in online SLAMtested at our site, it also significantly outperformed the other SLAM Systems.</description>
      <author>example@mail.com (Nicolas Abboud, Malak Sayour, Imad H. Elhajj, John Zelek, Daniel Asmar)</author>
      <guid isPermaLink="false">2409.16810v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking the Power of Timestamps for Robust Time Series Forecasting: A Global-Local Fusion Perspective</title>
      <link>http://arxiv.org/abs/2409.18696v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 时间序列预测在金融、交通、能源、医疗和气候等多个行业中发挥着重要作用。&lt;h4&gt;2. 时间戳的重要性&lt;/h4&gt;   - 时间戳包含丰富的季节性信息，能够为预测技术提供强有力的全球指导。&lt;h4&gt;3. 现有问题&lt;/h4&gt;   - 现有研究主要关注局部观察，时间戳常被视为可选补充，利用不足。   - 当现实世界数据受到污染时，缺乏全球信息会损害算法的预测能力。&lt;h4&gt;4. 提出的解决方案&lt;/h4&gt;   - 本文提出了一种新框架，命名为GLAFF。   - 在GLAFF框架中，时间戳被单独建模，以捕捉全球依赖关系。&lt;h4&gt;5. 功能特点&lt;/h4&gt;   - GLAFF作为插件，能够自适应调整全球和局部信息的组合权重，实现无缝协作，与任何时间序列预测基础模型兼容。&lt;h4&gt;6. 实验验证&lt;/h4&gt;   - 在九个真实世界数据集上进行的广泛实验表明，GLAFF显著提升了广泛使用的主流预测模型的平均性能，提升幅度达到12.5%。&lt;h4&gt;7. 性能对比&lt;/h4&gt;   - GLAFF超越了之前的最先进方法，提升了5.5%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting has played a pivotal role across various industries,including finance, transportation, energy, healthcare, and climate. Due to theabundant seasonal information they contain, timestamps possess the potential tooffer robust global guidance for forecasting techniques. However, existingworks primarily focus on local observations, with timestamps being treatedmerely as an optional supplement that remains underutilized. When data gatheredfrom the real world is polluted, the absence of global information will damagethe robust prediction capability of these algorithms. To address theseproblems, we propose a novel framework named GLAFF. Within this framework, thetimestamps are modeled individually to capture the global dependencies. Workingas a plugin, GLAFF adaptively adjusts the combined weights for global and localinformation, enabling seamless collaboration with any time series forecastingbackbone. Extensive experiments conducted on nine real-world datasetsdemonstrate that GLAFF significantly enhances the average performance of widelyused mainstream forecasting models by 12.5%, surpassing the previousstate-of-the-art method by 5.5%.</description>
      <author>example@mail.com (Chengsen Wang, Qi Qi, Jingyu Wang, Haifeng Sun, Zirui Zhuang, Jinming Wu, Jianxin Liao)</author>
      <guid isPermaLink="false">2409.18696v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Artificial Intelligence for Secured Information Systems in Smart Cities: Collaborative IoT Computing with Deep Reinforcement Learning and Blockchain</title>
      <link>http://arxiv.org/abs/2409.16444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 物联网（IoT）的快速扩展带来了隐私、安全和数据完整性等关键挑战，特别是在智能城市和智能制造等基础设施中。&lt;h4&gt;2. 技术解决方案&lt;/h4&gt;   - 区块链技术提供不可变、可扩展和去中心化的解决方案，能够应对上述挑战。   - 深度强化学习（DRL）在物联网环境中的整合，增强了适应性和决策能力。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本文探讨区块链和DRL的结合，以优化物联网辅助智能城市中的移动传输和安全数据交换。&lt;h4&gt;4. 方法论&lt;/h4&gt;   - 通过对物联网应用系统的聚类和分类，展示DRL与区块链结合如何提升物联网网络的性能，同时维护隐私和安全。&lt;h4&gt;5. 文献回顾&lt;/h4&gt;   - 基于对2015年至2024年间发布文献的回顾，分类了所呈现的方法，并提供了实用的分类法，为研究人员提供重要视角，突出未来探索和研究的潜在领域。&lt;h4&gt;6. 研究发现&lt;/h4&gt;   - 结合区块链的去中心化框架与DRL能够解决隐私和安全问题，提高移动传输效率，并确保强大且保护隐私的物联网系统。&lt;h4&gt;7. 应用探讨&lt;/h4&gt;   - 探索了区块链与DRL的集成，并概述了DRL技术的显著应用。&lt;h4&gt;8. 研究贡献&lt;/h4&gt;   - 通过解决机器学习与区块链集成的挑战，本研究为研究人员提出了新颖的视角，并从跨学科的角度提供了基础性探索。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accelerated expansion of the Internet of Things (IoT) has raised criticalchallenges associated with privacy, security, and data integrity, specificallyin infrastructures such as smart cities or smart manufacturing. Blockchaintechnology provides immutable, scalable, and decentralized solutions to addressthese challenges, and integrating deep reinforcement learning (DRL) into theIoT environment offers enhanced adaptability and decision-making. This paperinvestigates the integration of blockchain and DRL to optimize mobiletransmission and secure data exchange in IoT-assisted smart cities. Through theclustering and categorization of IoT application systems, the combination ofDRL and blockchain is shown to enhance the performance of IoT networks bymaintaining privacy and security. Based on the review of papers publishedbetween 2015 and 2024, we have classified the presented approaches and offeredpractical taxonomies, which provide researchers with critical perspectives andhighlight potential areas for future exploration and research. Ourinvestigation shows how combining blockchain's decentralized framework with DRLcan address privacy and security issues, improve mobile transmissionefficiency, and guarantee robust, privacy-preserving IoT systems. Additionally,we explore blockchain integration for DRL and outline the notable applicationsof DRL technology. By addressing the challenges of machine learning andblockchain integration, this study proposes novel perspectives for researchersand serves as a foundational exploration from an interdisciplinary standpoint.</description>
      <author>example@mail.com (Amin Zakaie Far, Mohammad Zakaie Far, Sonia Gharibzadeh, Shiva Zangeneh, Leila Amini, Morteza Rahimi)</author>
      <guid isPermaLink="false">2409.16444v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Neural Collaborative Filtering to Detect Anomalies in Human Semantic Trajectories</title>
      <link>http://arxiv.org/abs/2409.18427v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in the 1st ACM SIGSPATIAL International
  Workshop on Geospatial Anomaly Detection (GeoAnomalies'24)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 人类轨迹异常检测在安全监控和公共卫生等多个领域变得越来越重要。&lt;h4&gt;2. 现有问题&lt;/h4&gt;   - 现有的轨迹异常检测方法主要集中在车辆交通，而针对人类轨迹的异常检测仍然未被充分探索。&lt;h4&gt;3. 数据挑战&lt;/h4&gt;   - 人类轨迹数据通常非常稀疏，因此机器学习方法成为识别复杂模式的首选。&lt;h4&gt;4. 模型透明性需求&lt;/h4&gt;   - 对于潜在偏见和模型鲁棒性的担忧增加了对更透明和可解释替代方案的需求。&lt;h4&gt;5. 研究目标&lt;/h4&gt;   - 本研究旨在开发一种轻量级异常检测模型，专门用于检测人类轨迹中的异常。&lt;h4&gt;6. 方法论&lt;/h4&gt;   - 提出了一个神经协同过滤方法，用于建模和预测正常的移动模式。   - 该方法在没有先验知识的情况下建模用户的日常生活模式，增强了在数据稀疏或不完整场景（如冷启动情况）下的性能。&lt;h4&gt;7. 算法结构&lt;/h4&gt;   - 算法由两个主要模块组成：     - **协同过滤模块**：应用协同过滤来建模个体人类在感兴趣地点的正常移动。     - **神经模块**：负责解释人类轨迹数据中固有的复杂时空关系。&lt;h4&gt;8. 实验验证&lt;/h4&gt;   - 为验证所提方法，进行了广泛的实验，使用了模拟和真实世界数据集，并与多种最先进的轨迹异常检测方法进行了比较。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human trajectory anomaly detection has become increasingly important across awide range of applications, including security surveillance and public health.However, existing trajectory anomaly detection methods are primarily focused onvehicle-level traffic, while human-level trajectory anomaly detection remainsunder-explored. Since human trajectory data is often very sparse, machinelearning methods have become the preferred approach for identifying complexpatterns. However, concerns regarding potential biases and the robustness ofthese models have intensified the demand for more transparent and explainablealternatives. In response to these challenges, our research focuses ondeveloping a lightweight anomaly detection model specifically designed todetect anomalies in human trajectories. We propose a Neural CollaborativeFiltering approach to model and predict normal mobility. Our method is designedto model users' daily patterns of life without requiring prior knowledge,thereby enhancing performance in scenarios where data is sparse or incomplete,such as in cold start situations. Our algorithm consists of two main modules.The first is the collaborative filtering module, which applies collaborativefiltering to model normal mobility of individual humans to places of interest.The second is the neural module, responsible for interpreting the complexspatio-temporal relationships inherent in human trajectory data. To validateour approach, we conducted extensive experiments using simulated and real-worlddatasets comparing to numerous state-of-the-art trajectory anomaly detectionapproaches.</description>
      <author>example@mail.com (Yueyang Liu, Lance Kennedy, Hossein Amiri, Andreas Züfle)</author>
      <guid isPermaLink="false">2409.18427v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>SplatLoc: 3D Gaussian Splatting-based Visual Localization for Augmented Reality</title>
      <link>http://arxiv.org/abs/2409.14067v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 可视定位在增强现实（AR）应用中至关重要，帮助AR设备获取其在预构建地图中的6自由度（6-DoF）姿态，以便在现实场景中渲染虚拟内容。&lt;h4&gt;2. 现有问题&lt;/h4&gt;   - 现有方法无法进行新视图渲染，并且需要较大的存储容量来保存地图。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 本文提出了一种高效的可视定位方法，能够以更少的参数实现高质量渲染。&lt;h4&gt;4. 技术细节&lt;/h4&gt;   - 该方法利用3D高斯原语作为场景表示。   - 为确保精确的2D-3D对应关系进行姿态估计，开发了一个无偏的3D场景特定描述符解码器，从构建的特征体积中提取信息。&lt;h4&gt;5. 关键技术&lt;/h4&gt;   - 引入了一种显著3D地标选择算法，根据显著性评分选择适合的原语子集进行定位。   - 对关键高斯原语进行正则化，以防止各向异性效应，进一步提高定位性能。&lt;h4&gt;6. 实验验证&lt;/h4&gt;   - 在两个广泛使用的数据集上进行的广泛实验表明，所提方法在渲染和定位性能上优于或可与最先进的隐式可视定位方法相媲美。&lt;h4&gt;7. 项目链接&lt;/h4&gt;   - 项目页面可访问：[SplatLoc](https://zju3dv.github.io/splatloc)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization plays an important role in the applications of AugmentedReality (AR), which enable AR devices to obtain their 6-DoF pose in thepre-build map in order to render virtual content in real scenes. However, mostexisting approaches can not perform novel view rendering and require largestorage capacities for maps. To overcome these limitations, we propose anefficient visual localization method capable of high-quality rendering withfewer parameters. Specifically, our approach leverages 3D Gaussian primitivesas the scene representation. To ensure precise 2D-3D correspondences for poseestimation, we develop an unbiased 3D scene-specific descriptor decoder forGaussian primitives, distilled from a constructed feature volume. Additionally,we introduce a salient 3D landmark selection algorithm that selects a suitableprimitive subset based on the saliency score for localization. We furtherregularize key Gaussian primitives to prevent anisotropic effects, which alsoimproves localization performance. Extensive experiments on two widely useddatasets demonstrate that our method achieves superior or comparable renderingand localization performance to state-of-the-art implicit-based visuallocalization approaches. Project page:\href{https://zju3dv.github.io/splatloc}{https://zju3dv.github.io/splatloc}.</description>
      <author>example@mail.com (Hongjia Zhai, Xiyu Zhang, Boming Zhao, Hai Li, Yijia He, Zhaopeng Cui, Hujun Bao, Guofeng Zhang)</author>
      <guid isPermaLink="false">2409.14067v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Frequency-based View Selection in Gaussian Splatting Reconstruction</title>
      <link>http://arxiv.org/abs/2409.16470v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 三维重建是机器人感知中的一个基础问题。&lt;h4&gt;2. 问题聚焦&lt;/h4&gt;   - 本文探讨主动视图选择问题，以尽可能少的输入图像执行3D高斯斑点重建。&lt;h4&gt;3. 现有技术进展&lt;/h4&gt;   - 尽管3D高斯斑点技术在图像渲染和3D重建方面取得了显著进展，但重建质量受到2D图像选择和通过运动结构（SfM）算法估计相机姿态的强烈影响。&lt;h4&gt;4. 当前方法的不足&lt;/h4&gt;   - 现有的视图选择方法依赖于遮挡、不确定深度或神经网络预测，但这些方法不足以有效处理问题，并且在新场景中难以推广。&lt;h4&gt;5. 新方法的提出&lt;/h4&gt;   - 通过在频域中对潜在视图进行排名，我们能够在没有真实数据的情况下有效估计新视点的潜在信息增益。&lt;h4&gt;6. 方法优势&lt;/h4&gt;   - 该方法克服了当前模型架构和效率的限制，实现了视图选择的最先进结果，展示了其在基于图像的3D重建中的潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Three-dimensional reconstruction is a fundamental problem in roboticsperception. We examine the problem of active view selection to perform 3DGaussian Splatting reconstructions with as few input images as possible.Although 3D Gaussian Splatting has made significant progress in image renderingand 3D reconstruction, the quality of the reconstruction is strongly impactedby the selection of 2D images and the estimation of camera poses throughStructure-from-Motion (SfM) algorithms. Current methods to select views thatrely on uncertainties from occlusions, depth ambiguities, or neural networkpredictions directly are insufficient to handle the issue and struggle togeneralize to new scenes. By ranking the potential views in the frequencydomain, we are able to effectively estimate the potential information gain ofnew viewpoints without ground truth data. By overcoming current constraints onmodel architecture and efficacy, our method achieves state-of-the-art resultsin view selection, demonstrating its potential for efficient image-based 3Dreconstruction.</description>
      <author>example@mail.com (Monica M. Q. Li, Pierre-Yves Lajoie, Giovanni Beltrame)</author>
      <guid isPermaLink="false">2409.16470v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning from Demonstration with Implicit Nonlinear Dynamics Models</title>
      <link>http://arxiv.org/abs/2409.18768v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 学习示范（LfD）是一种用于训练解决复杂运动任务的策略的有效范式。&lt;h4&gt;2. 面临的挑战&lt;/h4&gt;   - LfD在实际应用中需要克服策略执行过程中的错误累积问题，即由于错误随时间叠加而导致的漂移问题和随之而来的分布外行为。&lt;h4&gt;3. 现有解决方案&lt;/h4&gt;   - 现有研究通过以下方法解决这一问题：     - 扩大数据收集     - 通过人机协作修正策略错误     - 进行时间上集成的策略预测     - 学习动力学系统模型的参数&lt;h4&gt;4. 提出的新方法&lt;/h4&gt;   - 本文提出并验证了一种替代方法，受到水库计算的启发，开发了一种新型神经网络层，包含具有可调动态特性的固定非线性动力学系统。&lt;h4&gt;5. 验证方法&lt;/h4&gt;   - 在再现人类书写运动的任务中，使用LASA人类书写数据集验证了该神经网络层的有效性。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实证实验表明，将该层集成到现有神经网络架构中可以解决LfD中的错误累积问题。&lt;h4&gt;7. 比较评估&lt;/h4&gt;   - 本文还与现有方法进行比较，包括时间集成的策略预测和回声状态网络（ESNs）实现。   - 结果显示，所提出的方法在书写任务上表现出更高的策略精度和鲁棒性，同时能够推广到多种动态状态，并保持竞争性的延迟性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning from Demonstration (LfD) is a useful paradigm for training policiesthat solve tasks involving complex motions. In practice, the successfulapplication of LfD requires overcoming error accumulation during policyexecution, i.e. the problem of drift due to errors compounding over time andthe consequent out-of-distribution behaviours. Existing works seek to addressthis problem through scaling data collection, correcting policy errors with ahuman-in-the-loop, temporally ensembling policy predictions or through learningthe parameters of a dynamical system model. In this work, we propose andvalidate an alternative approach to overcoming this issue. Inspired byreservoir computing, we develop a novel neural network layer that includes afixed nonlinear dynamical system with tunable dynamical properties. We validatethe efficacy of our neural network layer on the task of reproducing humanhandwriting motions using the LASA Human Handwriting Dataset. Through empiricalexperiments we demonstrate that incorporating our layer into existing neuralnetwork architectures addresses the issue of compounding errors in LfD.Furthermore, we perform a comparative evaluation against existing approachesincluding a temporal ensemble of policy predictions and an Echo State Networks(ESNs) implementation. We find that our approach yields greater policyprecision and robustness on the handwriting task while also generalising tomultiple dynamics regimes and maintaining competitive latency scores.</description>
      <author>example@mail.com (Peter David Fagan, Subramanian Ramamoorthy)</author>
      <guid isPermaLink="false">2409.18768v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Go-SLAM: Grounded Object Segmentation and Localization with Gaussian Splatting SLAM</title>
      <link>http://arxiv.org/abs/2409.16944v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文介绍了Go-SLAM，一个新颖的框架，利用3D高斯斑点SLAM技术重建动态环境，并在场景表示中嵌入对象级信息。&lt;h4&gt;2. 对象分割技术&lt;/h4&gt;   - 该框架采用先进的对象分割技术，为每个高斯斑点分配一个唯一标识符，以对应其所代表的对象。&lt;h4&gt;3. 开放词汇查询&lt;/h4&gt;   - 系统支持开放词汇查询，用户可以使用自然语言描述来定位对象。&lt;h4&gt;4. 路径生成模块&lt;/h4&gt;   - 框架包含一个优化路径生成模块，能够为机器人计算高效的导航路径，考虑障碍物和环境的不确定性。&lt;h4&gt;5. 综合评估&lt;/h4&gt;   - 在多种场景设置下进行的全面评估展示了该方法在以下方面的有效性：     - 高保真场景重建     - 精确的对象分割     - 灵活的对象查询     - 高效的机器人路径规划&lt;h4&gt;6. 研究贡献&lt;/h4&gt;   - 该工作在3D场景重建、语义对象理解和实时环境交互之间架起了一座桥梁，代表了该领域的进一步进展。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Go-SLAM, a novel framework that utilizes 3D Gaussian SplattingSLAM to reconstruct dynamic environments while embedding object-levelinformation within the scene representations. This framework employs advancedobject segmentation techniques, assigning a unique identifier to each Gaussiansplat that corresponds to the object it represents. Consequently, our systemfacilitates open-vocabulary querying, allowing users to locate objects usingnatural language descriptions. Furthermore, the framework features an optimalpath generation module that calculates efficient navigation paths for robotstoward queried objects, considering obstacles and environmental uncertainties.Comprehensive evaluations in various scene settings demonstrate theeffectiveness of our approach in delivering high-fidelity scenereconstructions, precise object segmentation, flexible object querying, andefficient robot path planning. This work represents an additional step forwardin bridging the gap between 3D scene reconstruction, semantic objectunderstanding, and real-time environment interactions.</description>
      <author>example@mail.com (Phu Pham, Dipam Patel, Damon Conover, Aniket Bera)</author>
      <guid isPermaLink="false">2409.16944v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Forecasting Macroeconomic Dynamics using a Calibrated Data-Driven Agent-based Model</title>
      <link>http://arxiv.org/abs/2409.18760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 近年来，经济主体基于模型的研究从定性模型转向定量模型，尤其在时间序列预测方面取得了进展。&lt;h4&gt;2. 模型性能&lt;/h4&gt;   - 一些新模型的预测性能与标准模型相当，甚至更优（如Poledna等（2023a）、Hommes等（2022）、Pichler等（2022）所示）。&lt;h4&gt;3. 研究创新&lt;/h4&gt;   - 本文在Poledna等的模型基础上进行了扩展，新增了多个特征：     - 住房市场     - 具备收入、财富和消费异质性的真实合成个体人口     - 改进的行为规则和市场机制     - 增强的信贷市场&lt;h4&gt;4. 模型校准&lt;/h4&gt;   - 模型针对所有38个OECD成员国进行了校准，采用了最先进的近似贝叶斯推断方法。&lt;h4&gt;5. 预测测试&lt;/h4&gt;   - 通过进行样本外预测测试，模型表现优于Poledna模型和AR(1)时间序列模型，且具有高度统计显著性。&lt;h4&gt;6. 研究平台&lt;/h4&gt;   - 本文所建模型在一个开发的平台上构建，便于构建、运行和评估替代模型，旨在促进未来相关领域的研究。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the last few years, economic agent-based models have made the transitionfrom qualitative models calibrated to match stylised facts to quantitativemodels for time series forecasting, and in some cases, their predictions haveperformed as well or better than those of standard models (see, e.g. Poledna etal. (2023a); Hommes et al. (2022); Pichler et al. (2022)). Here, we build onthe model of Poledna et al., adding several new features such as housingmarkets, realistic synthetic populations of individuals with income, wealth andconsumption heterogeneity, enhanced behavioural rules and market mechanisms,and an enhanced credit market. We calibrate our model for all 38 OECD membercountries using state-of-the-art approximate Bayesian inference methods andtest it by making out-of-sample forecasts. It outperforms both the Poledna andAR(1) time series models by a highly statistically significant margin. Ourmodel is built within a platform we have developed, making it easy to build,run, and evaluate alternative models, which we hope will encourage future workin this area.</description>
      <author>example@mail.com (Samuel Wiese, Jagoda Kaszowska-Mojsa, Joel Dyer, Jose Moran, Marco Pangallo, Francois Lafond, John Muellbauer, Anisoara Calinescu, J. Doyne Farmer)</author>
      <guid isPermaLink="false">2409.18760v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Adversarial Challenges in Network Intrusion Detection Systems: Research Insights and Future Prospects</title>
      <link>http://arxiv.org/abs/2409.18736v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 机器学习在网络安全领域取得了显著进展，尤其是在入侵检测系统（NIDS）方面。&lt;h4&gt;2. 机器学习的优势&lt;/h4&gt;   - 机器学习算法能够识别数据特征之间的复杂关系，并对未见样本进行良好的泛化，推动了检测性能的提升。   - 深度神经网络特别促进了这一进展，使得分析大量训练数据成为可能。&lt;h4&gt;3. 脆弱性问题&lt;/h4&gt;   - 然而，机器学习模型易受到对抗性攻击的影响，即对输入数据的操控旨在误导模型做出错误预测。&lt;h4&gt;4. 对抗性攻击的研究现状&lt;/h4&gt;   - 尽管对无结构数据（如文本和图像）的对抗威胁有很多关注，但在结构化数据（如网络流量）中的有效性尚未得到充分探讨。&lt;h4&gt;5. 研究目的&lt;/h4&gt;   - 本文旨在填补这一空白，对基于机器学习的NIDS进行关键性回顾，并深入分析其对对抗性攻击的脆弱性。&lt;h4&gt;6. 文献回顾&lt;/h4&gt;   - 评估现有NIDS研究，突出关键趋势、优势和局限性，并识别需要进一步探索的理解空白。&lt;h4&gt;7. 挑战与展望&lt;/h4&gt;   - 讨论新出现的挑战，并提供开发更强大和更具抗干扰能力的NIDS模型的见解。&lt;h4&gt;8. 总结目标&lt;/h4&gt;   - 本文旨在增强对NIDS中对抗性攻击和防御的理解，并指导未来研究以改善网络安全应用中机器学习模型的鲁棒性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning has brought significant advances in cybersecurity,particularly in the area of intrusion detection systems. This improvements canbe mostly attributed to the ability of machine learning algorithms to identifycomplex relations between features in the data and to generalize well to unseensamples. Deep neural networks in particular contributed to this progress byenabling the analysis of large amounts of training data, significantlyenhancing detection performance. However, machine learning models arevulnerable to adversarial attacks: manipulations of input data designed tomislead the models into making incorrect predictions. While much attention hasbeen given to adversarial threats in unstructured data such as text and images,their effectiveness in structured data such as network traffic has not been asthoroughly explored.  This survey seeks to fill this gap by providing an critical review of machinelearning-based Network Intrusion Detection Systems (NIDS) and a thoroughanalysis of their vulnerability to adversarial attacks. We critically reviewexisting NIDS research, highlighting key trends, strengths, and limitations,and we identify gaps in understanding that require further exploration. Wefurther discuss emerging challenges and offer insights for developing morerobust and resilient NIDS models. In summary, this paper aims to enhanceunderstanding of adversarial attacks and defenses in NIDS and guide futureresearch in improving the robustness of machine learning models incybersecurity applications.</description>
      <author>example@mail.com (Sabrine Ennaji, Fabio De Gaspari, Dorjan Hitaj, Alicia K/Bidi, Luigi V. Mancini)</author>
      <guid isPermaLink="false">2409.18736v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>AutoSTF: Decoupled Neural Architecture Search for Cost-Effective Automated Spatio-Temporal Forecasting</title>
      <link>http://arxiv.org/abs/2409.16586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 时空预测是各种智能城市应用中的关键组成部分，如交通优化、能源管理和社会经济分析。&lt;h4&gt;2. 现有方法的局限性&lt;/h4&gt;   - 近期提出了多种自动时空预测方法，旨在自动搜索最佳神经网络架构以捕捉复杂的时空依赖关系。   - 现有的自动化方法面临着高昂的神经架构搜索开销，限制了其实际应用及对多样化时空运算符的深入探索。&lt;h4&gt;3. 提出的框架&lt;/h4&gt;   - 本文提出了AutoSTF，一个解耦的自动神经架构搜索框架，旨在实现成本有效的自动时空预测。&lt;h4&gt;4. 效率提升&lt;/h4&gt;   - 从效率角度出发，首先将混合搜索空间解耦为时间空间和空间空间，并分别设计表示压缩和参数共享方案，以降低参数爆炸。&lt;h4&gt;5. 优化过程加速&lt;/h4&gt;   - 解耦的时空搜索不仅加速了模型优化过程，还为更有效的时空依赖建模提供了新的空间。&lt;h4&gt;6. 有效性提升&lt;/h4&gt;   - 从有效性角度出发，提出了多补丁转移模块，以共同捕捉多粒度的时间依赖，并扩展空间搜索空间以实现更细粒度的逐层空间依赖搜索。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 在八个数据集上的广泛实验表明，AutoSTF在准确性和效率方面具有优越性。&lt;h4&gt;8. 性能对比&lt;/h4&gt;   - 提出的框架与最先进的自动时空预测方法相比，实现了高达13.48倍的速度提升，同时保持了最佳的预测准确性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-temporal forecasting is a critical component of various smart cityapplications, such as transportation optimization, energy management, andsocio-economic analysis. Recently, several automated spatio-temporalforecasting methods have been proposed to automatically search the optimalneural network architecture for capturing complex spatio-temporal dependencies.However, the existing automated approaches suffer from expensive neuralarchitecture search overhead, which hinders their practical use and the furtherexploration of diverse spatio-temporal operators in a finer granularity. Inthis paper, we propose AutoSTF, a decoupled automatic neural architecturesearch framework for cost-effective automated spatio-temporal forecasting. Fromthe efficiency perspective, we first decouple the mixed search space intotemporal space and spatial space and respectively devise representationcompression and parameter-sharing schemes to mitigate the parameter explosion.The decoupled spatio-temporal search not only expedites the model optimizationprocess but also leaves new room for more effective spatio-temporal dependencymodeling. From the effectiveness perspective, we propose a multi-patch transfermodule to jointly capture multi-granularity temporal dependencies and extendthe spatial search space to enable finer-grained layer-wise spatial dependencysearch. Extensive experiments on eight datasets demonstrate the superiority ofAutoSTF in terms of both accuracy and efficiency. Specifically, our proposedmethod achieves up to 13.48x speed-up compared to state-of-the-art automaticspatio-temporal forecasting methods while maintaining the best forecastingaccuracy.</description>
      <author>example@mail.com (Tengfei Lyu, Weijia Zhang, Jinliang Deng, Hao Liu)</author>
      <guid isPermaLink="false">2409.16586v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Combining Absolute and Semi-Generalized Relative Poses for Visual Localization</title>
      <link>http://arxiv.org/abs/2409.14269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 可视化定位是估计给定查询图像在已知场景中的相机姿态的问题。&lt;h4&gt;2. 现有方法的局限性&lt;/h4&gt;   - 大多数先进的定位方法采用基于结构的范式，通过在查询图像中的像素和场景中的3D点之间进行2D-3D匹配来进行姿态估计。   - 这些方法假设场景的3D模型是准确的，但在仅有少量图像可用以计算场景表示时，这种假设可能不成立。&lt;h4&gt;3. 结构无关方法&lt;/h4&gt;   - 结构无关的方法依赖于2D-2D匹配，不需要任何3D场景模型，但其准确性通常低于基于结构的方法。&lt;h4&gt;4. 先前工作的局限性&lt;/h4&gt;   - 尽管有研究提出结合基于结构和无结构的姿态估计策略，但其实际相关性尚未得到验证。&lt;h4&gt;5. 研究分析&lt;/h4&gt;   - 本文分析了结合基于结构和无结构策略的方法，同时探索如何选择来自2D-2D和2D-3D匹配的姿态。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 结果表明，结合这两种策略在多个实际相关场景中提升了定位性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization is the problem of estimating the camera pose of a givenquery image within a known scene. Most state-of-the-art localization approachesfollow the structure-based paradigm and use 2D-3D matches between pixels in aquery image and 3D points in the scene for pose estimation. These approachesassume an accurate 3D model of the scene, which might not always be available,especially if only a few images are available to compute the scenerepresentation. In contrast, structure-less methods rely on 2D-2D matches anddo not require any 3D scene model. However, they are also less accurate thanstructure-based methods. Although one prior work proposed to combinestructure-based and structure-less pose estimation strategies, its practicalrelevance has not been shown. We analyze combining structure-based andstructure-less strategies while exploring how to select between poses obtainedfrom 2D-2D and 2D-3D matches, respectively. We show that combining bothstrategies improves localization performance in multiple practically relevantscenarios.</description>
      <author>example@mail.com (Vojtech Panek, Torsten Sattler, Zuzana Kukelova)</author>
      <guid isPermaLink="false">2409.14269v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>A POMDP-based hierarchical planning framework for manipulation under pose uncertainty</title>
      <link>http://arxiv.org/abs/2409.18775v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review (2025 IEEE International Conference on Robotics &amp;
  Automation)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 机器人在家庭环境中面临挑战，特别是在视觉反馈无效的情况下，如在遮挡物后取物或在黑暗中寻找开关。&lt;h4&gt;2. 利用接触进行定位&lt;/h4&gt;   - 在这些情况下，利用接触信号来定位目标物体可能是有效的。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 提出了一种使用二进制接触信号进行操作任务的在线规划框架，该框架处理姿态不确定性，并将其形式化为部分可观测马尔可夫决策过程（POMDP）。&lt;h4&gt;4. 粒子集表示的不适用性&lt;/h4&gt;   - 直接将信念表示为粒子集在家庭环境中不可行，因为需要在大量粒子中展开展行动序列，计算时间显著。&lt;h4&gt;5. 分层信念表示&lt;/h4&gt;   - 为了解决这个问题，提出了一种分层信念表示。初步在3D体积空间中粗略表示不确定性。&lt;h4&gt;6. 策略计算与执行&lt;/h4&gt;   - 计算并执行在体积空间中细化不确定性的策略，直到不确定性降低到足够程度，然后再转换回粒子空间进行进一步细化。&lt;h4&gt;7. 闭环规划与执行框架&lt;/h4&gt;   - 使用闭环规划和执行框架，结合基于启发式搜索的任意时间求解器，在有限时间预算内计算部分策略。&lt;h4&gt;8. 性能展示&lt;/h4&gt;   - 在现实世界和仿真中展示框架的性能，特别是在使用UR10e操纵器进行插头插入任务时，解决了高达50厘米的位置信息不确定性和接近$2\pi$的角度不确定性。&lt;h4&gt;9. 实验结果&lt;/h4&gt;   - 实验结果表明，该框架的有效性，在现实世界中成功率达到93%，且相较于贪婪基线在解的质量上提高超过50%，显著加快了规划速度，并实现了复杂问题的实时解决。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots often face challenges in domestic environments where visual feedbackis ineffective, such as retrieving objects obstructed by occlusions or findinga light switch in the dark. In these cases, utilizing contacts to localize thetarget object can be effective. We propose an online planning framework usingbinary contact signals for manipulation tasks with pose uncertainty, formulatedas a Partially Observable Markov Decision Process (POMDP). Naively representingthe belief as a particle set makes planning infeasible due to the largeuncertainties in domestic settings, as identifying the best sequence of actionsrequires rolling out thousands of actions across millions of particles, takingsignificant compute time. To address this, we propose a hierarchical beliefrepresentation. Initially, we represent the uncertainty coarsely in a 3Dvolumetric space. Policies that refine uncertainty in this space are computedand executed, and once uncertainty is sufficiently reduced, the problem istranslated back into the particle space for further refinement before taskcompletion. We utilize a closed-loop planning and execution framework with aheuristic-search-based anytime solver that computes partial policies within alimited time budget. The performance of the framework is demonstrated both inreal world and in simulation on the high-precision task of inserting a pluginto a port using a UR10e manipulator, resolving positional uncertainties up to50 centimeters and angular uncertainties close to $2\pi$. Experimental resultshighlight the framework's effectiveness, achieving a 93\% success rate in thereal world and over 50\% improvement in solution quality compared to greedybaselines, significantly accelerating planning and enabling real-time solutionsfor complex problems.</description>
      <author>example@mail.com (Muhammad Suhail Saleem, Rishi Veerapaneni, Maxim Likhachev)</author>
      <guid isPermaLink="false">2409.18775v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Submap-based Autonomous MAV Exploration using Visual-Inertial SLAM Configurable for LiDARs or Depth Cameras</title>
      <link>http://arxiv.org/abs/2409.16972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 8 figures, for the accompanying video see
  https://youtu.be/Uf5fwmYcuq4&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 自主探索未知空间是移动机器人在现实世界中部署的关键组成部分。&lt;h4&gt;2. 安全导航的重要性&lt;/h4&gt;   - 安全导航对于所有机器人应用至关重要，要求对机器人周围环境有准确且一致的地图。&lt;h4&gt;3. 自主性与状态估计&lt;/h4&gt;   - 为实现完全自主，机器人必须依赖车载状态估计，但这种估计随时间可能会出现漂移。&lt;h4&gt;4. 提出的框架&lt;/h4&gt;   - 提出了一种基于局部子地图的微型空中车辆（MAV）探索框架，通过对相对子地图姿态应用闭环校正，保持全局一致性。&lt;h4&gt;5. 大规模探索方法&lt;/h4&gt;   - 该框架高效计算全局环境前沿，并利用基于采样的下一个最佳视图探索规划器，实现大规模探索。&lt;h4&gt;6. 传感器适应性&lt;/h4&gt;   - 方法支持使用LiDAR传感器或深度相机，适用于不同类型的MAV平台。&lt;h4&gt;7. 比较评估&lt;/h4&gt;   - 在仿真中与先进的基于子地图的探索框架进行了比较评估，展示了本方法的效率和重建质量。&lt;h4&gt;8. 实际应用展示&lt;/h4&gt;   - 最后，展示了该方法在实际MAV上的适用性，包括一个配备LiDAR的MAV和一个配备深度相机的MAV。&lt;h4&gt;9. 视频链接&lt;/h4&gt;   - 相关视频可在 [YouTube](https://youtu.be/Uf5fwmYcuq4) 上查看。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous exploration of unknown space is an essential component for thedeployment of mobile robots in the real world. Safe navigation is crucial forall robotics applications and requires accurate and consistent maps of therobot's surroundings. To achieve full autonomy and allow deployment in a widevariety of environments, the robot must rely on on-board state estimation whichis prone to drift over time. We propose a Micro Aerial Vehicle (MAV)exploration framework based on local submaps to allow retaining globalconsistency by applying loop-closure corrections to the relative submap poses.To enable large-scale exploration we efficiently compute global,environment-wide frontiers from the local submap frontiers and use asampling-based next-best-view exploration planner. Our method seamlesslysupports using either a LiDAR sensor or a depth camera, making it suitable fordifferent kinds of MAV platforms. We perform comparative evaluations insimulation against a state-of-the-art submap-based exploration framework toshowcase the efficiency and reconstruction quality of our approach. Finally, wedemonstrate the applicability of our method to real-world MAVs, one equippedwith a LiDAR and the other with a depth camera. Video available athttps://youtu.be/Uf5fwmYcuq4 .</description>
      <author>example@mail.com (Sotiris Papatheodorou, Simon Boche, Sebastián Barbas Laina, Stefan Leutenegger)</author>
      <guid isPermaLink="false">2409.16972v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Classification and regression of trajectories rendered as images via 2D Convolutional Neural Networks</title>
      <link>http://arxiv.org/abs/2409.18832v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 轨迹可以视为坐标的时间序列，通常来源于运动物体。&lt;h4&gt;2. 轨迹分类的重要性&lt;/h4&gt;   - 轨迹分类方法对检测不同的运动模式至关重要，而回归方法则用于计算运动指标和预测。&lt;h4&gt;3. 计算机视觉的进展&lt;/h4&gt;   - 最近的计算机视觉进展促进了通过人工神经网络（CNN）处理将轨迹呈现为图像的方法，尤其是使用2D卷积层。&lt;h4&gt;4. CNN的优势&lt;/h4&gt;   - 这种方法利用CNN学习图像中的空间特征层次，能够识别复杂形状，并克服其他机器学习方法对输入轨迹点数固定的限制。&lt;h4&gt;5. 图像呈现的局限性&lt;/h4&gt;   - 将轨迹渲染为图像可能引入一些未充分研究的伪影，如由于坐标绘制在离散网格上而导致的信息丢失，以及由于线条厚度和混叠而导致的光谱变化。&lt;h4&gt;6. 研究目标&lt;/h4&gt;   - 本研究调查了CNN在处理合成轨迹（已使用不同方式渲染为图像）中的分类和回归问题的有效性。&lt;h4&gt;7. 考虑的参数&lt;/h4&gt;   - 研究所考虑的参数包括线条厚度、图像分辨率、运动历史（时间组件的颜色编码）和抗混叠处理。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 结果强调了根据模型深度和运动历史选择合适图像分辨率的重要性，尤其在运动方向至关重要的应用中。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectories can be regarded as time-series of coordinates, typically arisingfrom motile objects. Methods for trajectory classification are particularlyimportant to detect different movement patterns, while methods for regressionto compute motility metrics and forecasting. Recent advances in computer visionhave facilitated the processing of trajectories rendered as images viaartificial neural networks with 2d convolutional layers (CNNs). This approachleverages the capability of CNNs to learn spatial hierarchies of features fromimages, necessary to recognize complex shapes. Moreover, it overcomes thelimitation of other machine learning methods that require input trajectorieswith a fixed number of points. However, rendering trajectories as images canintroduce poorly investigated artifacts such as information loss due to theplotting of coordinates on a discrete grid, and spectral changes due to linethickness and aliasing. In this study, we investigate the effectiveness of CNNsfor solving classification and regression problems from synthetic trajectoriesthat have been rendered as images using different modalities. The parametersconsidered in this study include line thickness, image resolution, usage ofmotion history (color-coding of the temporal component) and anti-aliasing.Results highlight the importance of choosing an appropriate image resolutionaccording to model depth and motion history in applications where movementdirection is critical.</description>
      <author>example@mail.com (Mariaclaudia Nicolai, Raffaella Fiamma Cabini, Diego Ulisse Pizzagalli)</author>
      <guid isPermaLink="false">2409.18832v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>LKA-ReID:Vehicle Re-Identification with Large Kernel Attention</title>
      <link>http://arxiv.org/abs/2409.17908v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper is under consideration at 2025 IEEE International
  Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着智能交通系统的快速发展和智慧城市基础设施的普及，车辆重识别（Vehicle Re-ID）技术已成为重要的研究领域。&lt;h4&gt;2. 面临的挑战&lt;/h4&gt;   - 车辆重识别任务面临的主要挑战是不同车辆之间的高度相似性。&lt;h4&gt;3. 现有方法的局限性&lt;/h4&gt;   - 现有方法通常依赖额外的检测或分割模型来提取差异化的局部特征，但这些方法要么需要额外的标注，要么显著增加计算成本。&lt;h4&gt;4. 注意力机制的应用&lt;/h4&gt;   - 使用注意力机制捕捉全局和局部特征是解决车辆重识别任务中类别之间高度相似性的重要手段。&lt;h4&gt;5. 提出的模型 - LKA-ReID&lt;/h4&gt;   - 本文提出了一种名为LKA-ReID的大核注意力模型（Large Kernel Attention）。&lt;h4&gt;6. 大核注意力的优势&lt;/h4&gt;   - LKA结合了自注意力的优点，并受益于卷积的优势，能够更全面地提取车辆的全局和局部特征。&lt;h4&gt;7. 引入的混合通道注意力&lt;/h4&gt;   - 引入混合通道注意力（Hybrid Channel Attention，HCA），将通道注意力与空间信息结合，使模型更好地关注通道和特征区域，忽略背景及其他干扰信息。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 在VeRi-776数据集上的实验表明，LKA-ReID的有效性，mAP达到了86.65%，Rank-1达到了98.03%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of intelligent transportation systems and thepopularity of smart city infrastructure, Vehicle Re-ID technology has become animportant research field. The vehicle Re-ID task faces an important challenge,which is the high similarity between different vehicles. Existing methods useadditional detection or segmentation models to extract differentiated localfeatures. However, these methods either rely on additional annotations orgreatly increase the computational cost. Using attention mechanism to captureglobal and local features is crucial to solve the challenge of high similaritybetween classes in vehicle Re-ID tasks. In this paper, we propose LKA-ReID withlarge kernel attention. Specifically, the large kernel attention (LKA) utilizesthe advantages of self-attention and also benefits from the advantages ofconvolution, which can extract the global and local features of the vehiclemore comprehensively. We also introduce hybrid channel attention (HCA) combineschannel attention with spatial information, so that the model can better focuson channels and feature regions, and ignore background and other disturbinginformation. Experiments on VeRi-776 dataset demonstrated the effectiveness ofLKA-ReID, with mAP reaches 86.65% and Rank-1 reaches 98.03%.</description>
      <author>example@mail.com (Xuezhi Xiang, Zhushan Ma, Lei Zhang, Denis Ombati, Himaloy Himu, Xiantong Zhen)</author>
      <guid isPermaLink="false">2409.17908v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>CamLoPA: A Hidden Wireless Camera Localization Framework via Signal Propagation Path Analysis</title>
      <link>http://arxiv.org/abs/2409.15169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 隐蔽无线摄像头的隐私威胁&lt;/h4&gt;   - 隐藏的无线摄像头对隐私构成重大威胁，因此需要有效的检测和定位方法。&lt;h4&gt;2. 现有解决方案的局限性&lt;/h4&gt;   - 现有方法通常需要宽敞的活动区域、高成本的专用设备或预先收集的训练数据，这限制了它们的实际应用。&lt;h4&gt;3. 提出的解决方案 - CamLoPA&lt;/h4&gt;   - 本文介绍了CamLoPA，一个无需训练的无线摄像头检测和定位框架，能够在活动空间限制较小的情况下使用低成本的商用现货设备（COTS）。&lt;h4&gt;4. 检测和定位能力&lt;/h4&gt;   - CamLoPA能够在用户活动的45秒内完成检测和定位，使用Raspberry Pi板进行操作。&lt;h4&gt;5. 工作原理&lt;/h4&gt;   - 在这段短时间内，CamLoPA分析无线流量与用户移动之间的因果关系，以检测窃听摄像头的存在。&lt;h4&gt;6. 定位模型&lt;/h4&gt;   - CamLoPA采用了一种基于无线信号传播路径分析的新型方位定位模型，利用用户路径穿越第一弗雷涅区（FFZ）的时间比率来确定摄像头的方位角。&lt;h4&gt;7. 细化定位&lt;/h4&gt;   - 通过识别摄像头的象限，进一步细化定位结果。&lt;h4&gt;8. 性能评估&lt;/h4&gt;   - 在不同设备和环境中的评估表明，CamLoPA实现了95.37%的窃听摄像头检测准确率和平均17.23的定位误差，同时大幅降低了活动空间的要求。&lt;h4&gt;9. 演示链接&lt;/h4&gt;   - 演示视频可在 [YouTube](https://www.youtube.com/watch?v=GKam04FzeM4) 上查看。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hidden wireless cameras pose significant privacy threats, necessitatingeffective detection and localization methods. However, existing solutions oftenrequire spacious activity areas, expensive specialized devices, orpre-collected training data, limiting their practical deployment. To addressthese limitations, we introduce CamLoPA, a training-free wireless cameradetection and localization framework that operates with minimal activity spaceconstraints using low-cost commercial-off-the-shelf (COTS) devices. CamLoPA canachieve detection and localization in just 45 seconds of user activities with aRaspberry Pi board. During this short period, it analyzes the causalrelationship between the wireless traffic and user movement to detect thepresence of a snooping camera. Upon detection, CamLoPA employs a novel azimuthlocation model based on wireless signal propagation path analysis.Specifically, this model leverages the time ratio of user paths crossing theFirst Fresnel Zone (FFZ) to determine the azimuth angle of the camera. ThenCamLoPA refines the localization by identifying the camera's quadrant. Weevaluate CamLoPA across various devices and environments, demonstrating that itachieves 95.37% snooping camera detection accuracy and an average localizationerror of 17.23, under the significantly reduced activity space requirements.Our demo are available at https://www.youtube.com/watch?v=GKam04FzeM4.</description>
      <author>example@mail.com (Xiang Zhang, Jie Zhang, Zehua Ma, Jinyang Huang, Meng Li, Huan Yan, Peng Zhao, Zijian Zhang, Qing Guo, Tianwei Zhang, Bin Liu, Nenghai Yu)</author>
      <guid isPermaLink="false">2409.15169v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Excavating in the Wild: The GOOSE-Ex Dataset for Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2409.18788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE for review&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 深度学习技术在自主系统中的成功部署依赖于在特定部署环境中可用的数据。&lt;h4&gt;2. 数据集的稀缺性&lt;/h4&gt;   - 尤其是在非结构化户外环境中，现有的数据集非常有限，适用的机器人平台和场景更少。&lt;h4&gt;3. 先前工作&lt;/h4&gt;   - 之前的研究中，提出了德国户外和越野数据集（GOOSE）框架，并提供了来自越野车辆的10,000个多模态帧，旨在增强在非结构化环境中的感知能力。&lt;h4&gt;4. 新研究的重点&lt;/h4&gt;   - 本文关注GOOSE框架的可推广性，并通过开源GOOSE-Ex数据集来解决该问题。&lt;h4&gt;5. 新数据集的特征&lt;/h4&gt;   - GOOSE-Ex数据集包含来自不同环境的5,000个标记多模态帧，这些帧是在机器人挖掘机和四足平台上记录的。&lt;h4&gt;6. 性能分析&lt;/h4&gt;   - 对不同平台和传感器模态在未见环境中的语义分割性能进行了全面分析。&lt;h4&gt;7. 数据集的应用展示&lt;/h4&gt;   - 演示了如何将组合数据集用于不同的下游应用或竞赛，如越野导航、物体操作和场景完成。&lt;h4&gt;8. 资源共享&lt;/h4&gt;   - 数据集、平台文档以及用于越野感知的预训练最先进模型将可在 [https://goose-dataset.de/](https://goose-dataset.de/) 上获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The successful deployment of deep learning-based techniques for autonomoussystems is highly dependent on the data availability for the respective systemin its deployment environment. Especially for unstructured outdoorenvironments, very few datasets exist for even fewer robotic platforms andscenarios. In an earlier work, we presented the German Outdoor and OffroadDataset (GOOSE) framework along with 10000 multimodal frames from an offroadvehicle to enhance the perception capabilities in unstructured environments. Inthis work, we address the generalizability of the GOOSE framework. Toaccomplish this, we open-source the GOOSE-Ex dataset, which contains additional5000 labeled multimodal frames from various completely different environments,recorded on a robotic excavator and a quadruped platform. We perform acomprehensive analysis of the semantic segmentation performance on differentplatforms and sensor modalities in unseen environments. In addition, wedemonstrate how the combined datasets can be utilized for different downstreamapplications or competitions such as offroad navigation, object manipulation orscene completion. The dataset, its platform documentation and pre-trainedstate-of-the-art models for offroad perception will be made available onhttps://goose-dataset.de/.  \</description>
      <author>example@mail.com (Raphael Hagmanns, Peter Mortimer, Miguel Granero, Thorsten Luettel, Janko Petereit)</author>
      <guid isPermaLink="false">2409.18788v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Event-based Stereo Depth Estimation: A Survey</title>
      <link>http://arxiv.org/abs/2409.17680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 20 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 立体视觉在机器人领域具有广泛的吸引力，因为它是生物体感知深度以导航三维世界的主要方式。&lt;h4&gt;2. 事件相机的特点&lt;/h4&gt;   - 事件相机是一种新型生物启发传感器，能够异步检测每个像素的亮度变化，具有极高的时间分辨率和动态范围，适用于高速运动和广泛的照明条件下的机器感知。&lt;h4&gt;3. 深度估计的重要性&lt;/h4&gt;   - 高时间精度有利于立体匹配，使得视差（深度）估计成为事件相机研究的热门领域。&lt;h4&gt;4. 领域发展历程&lt;/h4&gt;   - 过去30年，该领域快速发展，从低延迟、低功耗电路设计演变到现在由计算机视觉社区推动的深度学习（DL）方法。&lt;h4&gt;5. 文献导航的挑战&lt;/h4&gt;   - 由于该领域的高度跨学科性质，文献庞杂，非专家难以导航。&lt;h4&gt;6. 现有调查的不足&lt;/h4&gt;   - 以往的调查仅关注应用或特定技术类别，忽视了立体数据集。&lt;h4&gt;7. 本调查的贡献&lt;/h4&gt;   - 本文提供全面的概述，涵盖瞬时立体和适用于同时定位与地图构建（SLAM）的长期方法，以及理论和实证比较。&lt;h4&gt;8. 深度学习方法及数据集的评审&lt;/h4&gt;   - 本文首次全面评审深度学习方法和立体数据集，并提供创建新基准的实用建议，以推动该领域发展。&lt;h4&gt;9. 优点与挑战&lt;/h4&gt;   - 讨论了基于事件的立体深度估计面临的主要优点和挑战，尽管取得了显著进展，但在准确性和效率方面仍存在问题。&lt;h4&gt;10. 未来研究方向&lt;/h4&gt;    - 确定了若干研究空白并建议未来的研究方向，旨在激励该领域的后续研究。&lt;h4&gt;11. 目标受众&lt;/h4&gt;    - 希望该调查为新手提供可及的入门点，同时为社区内经验丰富的研究人员提供实用指南。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stereopsis has widespread appeal in robotics as it is the predominant way bywhich living beings perceive depth to navigate our 3D world. Event cameras arenovel bio-inspired sensors that detect per-pixel brightness changesasynchronously, with very high temporal resolution and high dynamic range,enabling machine perception in high-speed motion and broad illuminationconditions. The high temporal precision also benefits stereo matching, makingdisparity (depth) estimation a popular research area for event cameras eversince its inception. Over the last 30 years, the field has evolved rapidly,from low-latency, low-power circuit design to current deep learning (DL)approaches driven by the computer vision community. The bibliography is vastand difficult to navigate for non-experts due its highly interdisciplinarynature. Past surveys have addressed distinct aspects of this topic, in thecontext of applications, or focusing only on a specific class of techniques,but have overlooked stereo datasets. This survey provides a comprehensiveoverview, covering both instantaneous stereo and long-term methods suitable forsimultaneous localization and mapping (SLAM), along with theoretical andempirical comparisons. It is the first to extensively review DL methods as wellas stereo datasets, even providing practical suggestions for creating newbenchmarks to advance the field. The main advantages and challenges faced byevent-based stereo depth estimation are also discussed. Despite significantprogress, challenges remain in achieving optimal performance in not onlyaccuracy but also efficiency, a cornerstone of event-based computing. Weidentify several gaps and propose future research directions. We hope thissurvey inspires future research in this area, by serving as an accessible entrypoint for newcomers, as well as a practical guide for seasoned researchers inthe community.</description>
      <author>example@mail.com (Suman Ghosh, Guillermo Gallego)</author>
      <guid isPermaLink="false">2409.17680v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization</title>
      <link>http://arxiv.org/abs/2409.16502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website at https://gsplatloc.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 虽然存在多种视觉定位方法，如场景坐标和姿态回归，但这些方法通常面临高内存消耗或大量优化需求的挑战。&lt;h4&gt;2. 提出的解决方案&lt;/h4&gt;   - 本文利用新颖视图合成的最新进展，特别是3D高斯点云（3D Gaussian Splatting, 3DGS），来增强定位能力。&lt;h4&gt;3. 3DGS的优势&lt;/h4&gt;   - 3DGS能够紧凑地编码3D几何形状和场景外观，通过其空间特征提供有效的表示。&lt;h4&gt;4. 密集描述图的使用&lt;/h4&gt;   - 我们的方法利用XFeat的轻量级关键点检测和描述模型生成的密集描述图。&lt;h4&gt;5. 关键点描述符的提炼&lt;/h4&gt;   - 提出将这些密集关键点描述符蒸馏到3DGS中，以改善模型的空间理解，从而通过2D-3D对应关系实现更准确的相机姿态预测。&lt;h4&gt;6. 姿态估计与优化&lt;/h4&gt;   - 在初步估计姿态后，使用光度扭曲损失进行优化和精炼。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 在流行的室内和室外数据集上的基准测试表明，我们的方法超越了现有的最先进的神经渲染姿态（Neural Render Pose, NRP）方法，包括NeRFMatch和PNeRFLoc。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/haksorus/gsplatloc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although various visual localization approaches exist, such as scenecoordinate and pose regression, these methods often struggle with high memoryconsumption or extensive optimization requirements. To address thesechallenges, we utilize recent advancements in novel view synthesis,particularly 3D Gaussian Splatting (3DGS), to enhance localization. 3DGS allowsfor the compact encoding of both 3D geometry and scene appearance with itsspatial features. Our method leverages the dense description maps produced byXFeat's lightweight keypoint detection and description model. We proposedistilling these dense keypoint descriptors into 3DGS to improve the model'sspatial understanding, leading to more accurate camera pose predictions through2D-3D correspondences. After estimating an initial pose, we refine it using aphotometric warping loss. Benchmarking on popular indoor and outdoor datasetsshows that our approach surpasses state-of-the-art Neural Render Pose (NRP)methods, including NeRFMatch and PNeRFLoc.</description>
      <author>example@mail.com (Gennady Sidorov, Malik Mohrat, Ksenia Lebedeva, Ruslan Rakhimov, Sergey Kolyubin)</author>
      <guid isPermaLink="false">2409.16502v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Open-Nav: Exploring Zero-Shot Vision-and-Language Navigation in Continuous Environment with Open-Source LLMs</title>
      <link>http://arxiv.org/abs/2409.18794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 视觉与语言导航（VLN）任务要求智能体根据文本指令在3D环境中导航。&lt;h4&gt;2. 传统方法的局限性&lt;/h4&gt;   - 传统方法依赖于监督学习，严重依赖于特定领域的数据集来训练VLN模型。&lt;h4&gt;3. 新兴方法的挑战&lt;/h4&gt;   - 最近的方法尝试利用闭源的大型语言模型（LLMs），如GPT-4，以零-shot方式解决VLN任务，但面临高昂的令牌成本和潜在的数据泄露问题。&lt;h4&gt;4. 提出的新方法&lt;/h4&gt;   - 本文介绍了Open-Nav，一项新研究，探索开源LLMs在连续环境中的零-shot VLN。&lt;h4&gt;5. 方法论&lt;/h4&gt;   - Open-Nav采用时空链式思维（CoT）推理方法，将任务分解为指令理解、进度估计和决策制定。&lt;h4&gt;6. 增强场景感知&lt;/h4&gt;   - 通过细致的对象和空间知识增强场景感知，以改善LLM在导航中的推理能力。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 在模拟和真实环境中的广泛实验表明，Open-Nav的性能与使用闭源LLM的结果相当，具有竞争力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-and-Language Navigation (VLN) tasks require an agent to follow textualinstructions to navigate through 3D environments. Traditional approaches usesupervised learning methods, relying heavily on domain-specific datasets totrain VLN models. Recent methods try to utilize closed-source large languagemodels (LLMs) like GPT-4 to solve VLN tasks in zero-shot manners, but facechallenges related to expensive token costs and potential data breaches inreal-world applications. In this work, we introduce Open-Nav, a novel studythat explores open-source LLMs for zero-shot VLN in the continuous environment.Open-Nav employs a spatial-temporal chain-of-thought (CoT) reasoning approachto break down tasks into instruction comprehension, progress estimation, anddecision-making. It enhances scene perceptions with fine-grained object andspatial knowledge to improve LLM's reasoning in navigation. Our extensiveexperiments in both simulated and real-world environments demonstrate thatOpen-Nav achieves competitive performance compared to using closed-source LLMs.</description>
      <author>example@mail.com (Yanyuan Qiao, Wenqi Lyu, Hui Wang, Zixu Wang, Zerui Li, Yuan Zhang, Mingkui Tan, Qi Wu)</author>
      <guid isPermaLink="false">2409.18794v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>SurfaceAI: Automated creation of cohesive road surface quality datasets based on open street-level imagery</title>
      <link>http://arxiv.org/abs/2409.18922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 2 figures; accepted at 2nd ACM SIGSPATIAL International
  Workshop on Advances in Urban-AI&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 本文介绍了SurfaceAI，一个旨在从公开可用的街景图像生成全面地理参考数据集的管道，专注于道路表面类型和质量。&lt;h4&gt;2. 研究动机&lt;/h4&gt;   - 道路不平整对交通参与者的安全和舒适性有显著影响，尤其是对脆弱道路用户，因此对基础设施建模和分析中需要详细的道路表面数据。&lt;h4&gt;3. 方法创新&lt;/h4&gt;   - SurfaceAI通过利用众包的Mapillary数据来训练模型，预测街景图像中可见的道路表面类型和质量。&lt;h4&gt;4. 数据整合&lt;/h4&gt;   - 预测结果被汇总，以提供有关整个道路段状况的统一信息。&lt;h4&gt;5. 研究贡献&lt;/h4&gt;   - 该方法填补了道路表面数据的缺口，为基础设施分析提供了重要的支持。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces SurfaceAI, a pipeline designed to generatecomprehensive georeferenced datasets on road surface type and quality fromopenly available street-level imagery. The motivation stems from thesignificant impact of road unevenness on the safety and comfort of trafficparticipants, especially vulnerable road users, emphasizing the need fordetailed road surface data in infrastructure modeling and analysis. SurfaceAIaddresses this gap by leveraging crowdsourced Mapillary data to train modelsthat predict the type and quality of road surfaces visible in street-levelimages, which are then aggregated to provide cohesive information on entireroad segment conditions.</description>
      <author>example@mail.com (Alexandra Kapp, Edith Hoffmann, Esther Weigmann, Helena Mihaljević)</author>
      <guid isPermaLink="false">2409.18922v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>CESNET-TimeSeries24: Time Series Dataset for Network Traffic Anomaly Detection and Forecasting</title>
      <link>http://arxiv.org/abs/2409.18874v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 网络流量中的异常检测对维护计算机网络安全和识别恶意活动至关重要。&lt;h4&gt;2. 现有方法的局限性&lt;/h4&gt;   - 预测方法是异常检测的主要方法之一，但缺乏广泛的真实世界网络数据集可能导致对异常检测算法性能的高估。&lt;h4&gt;3. 研究目的&lt;/h4&gt;   - 本文旨在填补这一空白，介绍一个新数据集，包含从CESNET3网络收集的网络实体行为的时间序列数据。&lt;h4&gt;4. 数据集描述&lt;/h4&gt;   - 数据集基于275,000个活跃IP地址的40周网络流量创建，提供丰富的时间序列数据。&lt;h4&gt;5. 数据来源及其重要性&lt;/h4&gt;   - 数据的ISP来源确保了网络实体之间的高度变异性，这为预测和异常检测模型提供了独特而真实的挑战。&lt;h4&gt;6. 实际应用价值&lt;/h4&gt;   - 该数据集为基于预测的异常检测方法的实际部署提供了宝贵的见解。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection in network traffic is crucial for maintaining the securityof computer networks and identifying malicious activities. One of the primaryapproaches to anomaly detection are methods based on forecasting. Nevertheless,extensive real-world network datasets for forecasting and anomaly detectiontechniques are missing, potentially causing performance overestimation ofanomaly detection algorithms. This manuscript addresses this gap by introducinga dataset comprising time series data of network entities' behavior, collectedfrom the CESNET3 network. The dataset was created from 40 weeks of networktraffic of 275 thousand active IP addresses. The ISP origin of the presenteddata ensures a high level of variability among network entities, which forms aunique and authentic challenge for forecasting and anomaly detection models. Itprovides valuable insights into the practical deployment of forecast-basedanomaly detection approaches.</description>
      <author>example@mail.com (Josef Koumar, Karel Hynek, Tomáš Čejka, Pavel Šiška)</author>
      <guid isPermaLink="false">2409.18874v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Neural Implicit Representation for Highly Dynamic LiDAR Mapping and Odometry</title>
      <link>http://arxiv.org/abs/2409.17729v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 最近在同时定位与地图构建（SLAM）领域的进展显示了基于LiDAR技术的鲁棒性。&lt;h4&gt;2. 新技术的引入&lt;/h4&gt;   - 神经辐射场（NeRF）为3D场景重建提供了新的可能性，尤其是在SLAM系统中，NeRF-LOAM表现出色。&lt;h4&gt;3. 现有系统的局限性&lt;/h4&gt;   - 尽管NeRF-LOAM具有优势，但其在动态户外环境中由于固有的静态假设，常面临困难。&lt;h4&gt;4. 提出的新方法&lt;/h4&gt;   - 本文提出了一种新方法，旨在改善高度动态户外场景中的重建效果。&lt;h4&gt;5. 方法的主要组成部分&lt;/h4&gt;   - **场景分离**：首先将场景分为静态背景和动态前景，识别并排除动态元素，从而创建仅准确表示静态背景的密集3D地图。   - **多分辨率表示**：扩展八叉树结构以支持多分辨率表示，提升重建质量并帮助去除第一模块识别的动态物体。&lt;h4&gt;6. 高频信息捕捉&lt;/h4&gt;   - 应用傅里叶特征编码于采样点，捕捉高频信息，从而实现更完整的重建结果。&lt;h4&gt;7. 实验评估&lt;/h4&gt;   - 在多个数据集上的评估表明，该方法在性能上优于当前最先进的技术。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Simultaneous Localization and Mapping (SLAM) haveincreasingly highlighted the robustness of LiDAR-based techniques. At the sametime, Neural Radiance Fields (NeRF) have introduced new possibilities for 3Dscene reconstruction, exemplified by SLAM systems. Among these, NeRF-LOAM hasshown notable performance in NeRF-based SLAM applications. However, despite itsstrengths, these systems often encounter difficulties in dynamic outdoorenvironments due to their inherent static assumptions. To address theselimitations, this paper proposes a novel method designed to improvereconstruction in highly dynamic outdoor scenes. Based on NeRF-LOAM, theproposed approach consists of two primary components. First, we separate thescene into static background and dynamic foreground. By identifying andexcluding dynamic elements from the mapping process, this segmentation enablesthe creation of a dense 3D map that accurately represents the static backgroundonly. The second component extends the octree structure to supportmulti-resolution representation. This extension not only enhancesreconstruction quality but also aids in the removal of dynamic objectsidentified by the first module. Additionally, Fourier feature encoding isapplied to the sampled points, capturing high-frequency information and leadingto more complete reconstruction results. Evaluations on various datasetsdemonstrate that our method achieves more competitive results compared tocurrent state-of-the-art approaches.</description>
      <author>example@mail.com (Qi Zhang, He Wang, Ru Li, Wenbin Li)</author>
      <guid isPermaLink="false">2409.17729v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Exploiting Motion Prior for Accurate Pose Estimation of Dashboard Cameras</title>
      <link>http://arxiv.org/abs/2409.18673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 行车记录仪（dashcams）每天录制数百万段驾驶视频，为多种应用（如驾驶地图制作和更新）提供了宝贵的数据源。&lt;h4&gt;2. 挑战&lt;/h4&gt;   - 使用这些行车记录仪数据的必要步骤是估计相机姿态。然而，由于图像质量低，存在运动模糊和动态物体，现有的图像匹配方法在准确估计相机姿态方面面临挑战。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 本研究提出了一种针对行车记录仪图像的精确姿态估计方法，利用固有的相机运动先验。&lt;h4&gt;4. 运动先验的利用&lt;/h4&gt;   - 行车记录仪捕获的图像序列通常表现出明显的运动先验，例如向前移动或横向转弯，这些都是进行对应估计的重要线索。&lt;h4&gt;5. 姿态回归模块&lt;/h4&gt;   - 基于上述观察，我们设计了一个姿态回归模块，旨在学习相机的运动先验，并将这些先验整合到对应关系和姿态估计过程中。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实验表明，在真实的行车记录仪数据集中，我们的方法在AUC 5°的姿态估计上比基线提高了22%，并且在结构光从运动（SfM）中，对于19%更多的图像估计姿态时的重投影误差更小。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dashboard cameras (dashcams) record millions of driving videos daily,offering a valuable potential data source for various applications, includingdriving map production and updates. A necessary step for utilizing thesedashcam data involves the estimation of camera poses. However, the low-qualityimages captured by dashcams, characterized by motion blurs and dynamic objects,pose challenges for existing image-matching methods in accurately estimatingcamera poses. In this study, we propose a precise pose estimation method fordashcam images, leveraging the inherent camera motion prior. Typically, imagesequences captured by dash cameras exhibit pronounced motion prior, such asforward movement or lateral turns, which serve as essential cues forcorrespondence estimation. Building upon this observation, we devise a poseregression module aimed at learning camera motion prior, subsequentlyintegrating these prior into both correspondences and pose estimationprocesses. The experiment shows that, in real dashcams dataset, our method is22% better than the baseline for pose estimation in AUC5\textdegree, and it canestimate poses for 19% more images with less reprojection error in Structurefrom Motion (SfM).</description>
      <author>example@mail.com (Yipeng Lu, Yifan Zhao, Haiping Wang, Zhiwei Ruan, Yuan Liu, Zhen Dong, Bisheng Yang)</author>
      <guid isPermaLink="false">2409.18673v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>BlinkTrack: Feature Tracking over 100 FPS via Events and Images</title>
      <link>http://arxiv.org/abs/2409.17981v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 特征跟踪对于运动结构（SFM）、同时定位与地图构建（SLAM）、物体跟踪以及各种计算机视觉任务至关重要。&lt;h4&gt;2. 事件相机的优势与局限&lt;/h4&gt;   - 事件相机以其高时间分辨率和捕捉异步变化的能力而受到关注，但缺乏传统相机提供的细致纹理信息，导致跟踪中的误差累积。&lt;h4&gt;3. 提出的新框架&lt;/h4&gt;   - 本文提出了一个新框架BlinkTrack，集成事件数据和RGB图像进行高频特征跟踪。&lt;h4&gt;4. 方法创新&lt;/h4&gt;   - 将传统的卡尔曼滤波器扩展为基于学习的框架，在事件和图像分支中利用可微分的卡尔曼滤波器，提高单模态跟踪性能，解决模糊性，并支持异步数据融合。&lt;h4&gt;5. 数据集贡献&lt;/h4&gt;   - 引入新的合成和增强数据集，以更好地评估模型性能。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实验结果表明，BlinkTrack显著优于现有的基于事件的方法，处理预处理事件数据时超过100 FPS，使用多模态数据时达到80 FPS。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Feature tracking is crucial for, structure from motion (SFM), simultaneouslocalization and mapping (SLAM), object tracking and various computer visiontasks. Event cameras, known for their high temporal resolution and ability tocapture asynchronous changes, have gained significant attention for theirpotential in feature tracking, especially in challenging conditions. However,event cameras lack the fine-grained texture information that conventionalcameras provide, leading to error accumulation in tracking. To address this, wepropose a novel framework, BlinkTrack, which integrates event data with RGBimages for high-frequency feature tracking. Our method extends the traditionalKalman filter into a learning-based framework, utilizing differentiable Kalmanfilters in both event and image branches. This approach improvessingle-modality tracking, resolves ambiguities, and supports asynchronous datafusion. We also introduce new synthetic and augmented datasets to betterevaluate our model. Experimental results indicate that BlinkTrack significantlyoutperforms existing event-based methods, exceeding 100 FPS with preprocessedevent data and 80 FPS with multi-modality data.</description>
      <author>example@mail.com (Yichen Shen, Yijin Li, Shuo Chen, Guanglin Li, Zhaoyang Huang, Hujun Bao, Zhaopeng Cui, Guofeng Zhang)</author>
      <guid isPermaLink="false">2409.17981v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Safe Decentralized Multi-Agent Control using Black-Box Predictors, Conformal Decision Policies, and Control Barrier Functions</title>
      <link>http://arxiv.org/abs/2409.18862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 1 figure, submitted for ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 本文针对去中心化多智能体机器人环境中的安全控制挑战，特别是在使用不确定黑箱模型预测其他智能体轨迹时。&lt;h4&gt;2. 方法论&lt;/h4&gt;   - 采用最近提出的符合决策理论，通过根据观察到的预测误差调整基于控制障碍函数的安全约束的限制性。&lt;h4&gt;3. 控制器合成&lt;/h4&gt;   - 利用这些安全约束合成控制器，平衡安全性和任务完成之间的目标，尽管存在预测误差。&lt;h4&gt;4. 理论贡献&lt;/h4&gt;   - 提供了关于基于预测轨迹的安全约束与基于真实轨迹的约束之间差异的单调函数平均值的上界。&lt;h4&gt;5. 实验验证&lt;/h4&gt;   - 通过实验结果验证了理论，展示了在斯坦福无人机数据集中导航机器人的控制器性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the challenge of safe control in decentralized multi-agent roboticsettings, where agents use uncertain black-box models to predict other agents'trajectories. We use the recently proposed conformal decision theory to adaptthe restrictiveness of control barrier functions-based safety constraints basedon observed prediction errors. We use these constraints to synthesizecontrollers that balance between the objectives of safety and taskaccomplishment, despite the prediction errors. We provide an upper bound on theaverage over time of the value of a monotonic function of the differencebetween the safety constraint based on the predicted trajectories and theconstraint based on the ground truth ones. We validate our theory throughexperimental results showing the performance of our controllers when navigatinga robot in the multi-agent scenes in the Stanford Drone Dataset.</description>
      <author>example@mail.com (Sacha Huriot, Hussein Sibai)</author>
      <guid isPermaLink="false">2409.18862v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Royal Reveals: LiDAR Mapping of Kronborg Castle, Echoes of Hamlet's Halls</title>
      <link>http://arxiv.org/abs/2409.18752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 4 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 本文介绍了一个大型数据集，基于对丹麦埃尔西诺尔著名的文艺复兴堡垒——克伦堡城堡的细致360度LiDAR扫描。&lt;h4&gt;2. 设备和技术&lt;/h4&gt;   - 使用了垂直安装的、云台稳定的16通道360度Velodyne VLP-16 LiDAR扫描仪，配合Intel RealSense L515深度相机。&lt;h4&gt;3. 数据集特点&lt;/h4&gt;   - 该研究提供了城堡复杂建筑细节和结构特征的无与伦比的数字表示。&lt;h4&gt;4. 应用潜力&lt;/h4&gt;   - 数据集使研究人员能够进行实验，利用数据进行同时定位与地图构建（SLAM）以及平面图生成。&lt;h4&gt;5. 研究贡献&lt;/h4&gt;   - 该数据集为相关领域的研究提供了重要资源，促进了对历史建筑的深入理解和技术应用。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a large scale dataset from a meticulous 360-degree LiDAR(Light Detection and Ranging) scan conducted on Kronborg Castle, a renownedRenaissance fortress located in Elsinore (Helsing{\o}r), Denmark, famouslyassociated with Shakespeare's "Hamlet." Utilising a vertical mounted, gimbalstabilised, 16 channel, 360-degree Velodyne VLP-16 LiDAR scanner, paired withan Intel RealSense L515 depth camera. This research offers an unparalleleddigital representation of the castle's intricate architectural details andstructural nuances, enabling fellow researchers to conduct experimentsutilising the data for SLAM (Simultaneous Localisation and Mapping) as well asfloorplan generation.</description>
      <author>example@mail.com (Leon Davies, Simon Sølvsten)</author>
      <guid isPermaLink="false">2409.18752v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Towards Super-Nominal Payload Handling: Inverse Dynamics Analysis for Multi-Skill Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2409.18939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted as an extended abstract to ICRA@40&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 对于关节机器人（articulated robots）的运动规划，传统上使用在制造商定义的有效载荷限制内的算法。&lt;h4&gt;2. 实证分析&lt;/h4&gt;   - 对Franka Emika Panda机器人的实证分析表明，传统方法不必要地限制了机器人的动态可达任务空间。&lt;h4&gt;3. 研究发现&lt;/h4&gt;   - 研究结果建立了更大的操作范围，表明该机器人能够处理超过其额定容量两倍的有效载荷。&lt;h4&gt;4. 初步结果&lt;/h4&gt;   - 初步发现表明，将非抓取运动原语与基于抓取的操作结合，可能会进一步提高涉及超出正常限制的有效载荷的操作任务的成功率。&lt;h4&gt;5. 研究贡献&lt;/h4&gt;   - 该研究为优化关节机器人在更高有效载荷下的操作能力提供了新的视角，可能会推动机器人应用的边界。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion planning for articulated robots has traditionally been governed byalgorithms that operate within manufacturer-defined payload limits. Ourempirical analysis of the Franka Emika Panda robot demonstrates that thisapproach unnecessarily restricts the robot's dynamically-reachable task space.These results establish an expanded operational envelope for such robots,showing that they can handle payloads of more than twice their rated capacity.Additionally, our preliminary findings indicate that integrating non-prehensilemotion primitives with grasping-based manipulation has the potential to furtherincrease the success rates of manipulation tasks involving payloads exceedingnominal limits.</description>
      <author>example@mail.com (Anuj Pasricha, Alessandro Roncone)</author>
      <guid isPermaLink="false">2409.18939v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Mean-Field Control Barrier Functions: A Framework for Real-Time Swarm Control</title>
      <link>http://arxiv.org/abs/2409.18945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 控制障碍函数（CBFs）是一种有效的方法，确保在实时控制应用中（如电力系统、资源分配、自动驾驶、机器人等）的安全性和性能。&lt;h4&gt;2. 安全性独立性&lt;/h4&gt;   - CBFs能够确保安全性，与可能在离线预先规划的高层任务无关。例如，CBFs可以保证车辆保持在车道内。&lt;h4&gt;3. 多代理问题&lt;/h4&gt;   - 当代理数量较大时，CBFs的计算在多代理设置中可能会受到维度诅咒的影响，从而导致性能下降。&lt;h4&gt;4. 提出的新方法&lt;/h4&gt;   - 本文提出了均值场控制障碍函数（MF-CBFs），将CBF框架扩展到均值场（或群体控制）环境。&lt;h4&gt;5. 核心思想&lt;/h4&gt;   - 将一组代理建模为状态空间中的概率测度，并构建相应的控制障碍函数。&lt;h4&gt;6. 安全约束推导&lt;/h4&gt;   - 类似于传统CBFs，MF-CBFs推导了（分布式）控制的安全约束，但现在依赖于概率测度空间中的微积分。&lt;h4&gt;7. 研究贡献&lt;/h4&gt;   - 该工作为处理大规模代理系统中的安全性问题提供了一种新方法，有助于提高多代理控制的可行性和效率。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Control Barrier Functions (CBFs) are an effective methodology to ensuresafety and performative efficacy in real-time control applications such aspower systems, resource allocation, autonomous vehicles, robotics, etc. Thisapproach ensures safety independently of the high-level tasks that may havebeen pre-planned offline. For example, CBFs can be used to guarantee that avehicle will remain in its lane. However, when the number of agents is large,computation of CBFs can suffer from the curse of dimensionality in themulti-agent setting. In this work, we present Mean-field Control BarrierFunctions (MF-CBFs), which extends the CBF framework to the mean-field (orswarm control) setting. The core idea is to model a population of agents asprobability measures in the state space and build corresponding control barrierfunctions. Similar to traditional CBFs, we derive safety constraints on the(distributed) controls but now relying on the differential calculus in thespace of probability measures.</description>
      <author>example@mail.com (Samy Wu Fung, Levon Nurbekyan)</author>
      <guid isPermaLink="false">2409.18945v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>UniCal: Unified Neural Sensor Calibration</title>
      <link>http://arxiv.org/abs/2409.18953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024. Project page: https://waabi.ai/unical/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 自驾车辆（SDVs）需要准确校准激光雷达（LiDAR）和摄像头，以便准确融合传感器数据以实现自主驾驶。&lt;h4&gt;2. 传统校准方法的局限&lt;/h4&gt;   - 传统的校准方法通常依赖于在受控和结构化场景中捕获的基准物，并计算对应关系进行优化。   - 这些方法成本高，且需要大量基础设施和操作，难以在车辆队伍中规模化应用。&lt;h4&gt;3. 提出的新方法&lt;/h4&gt;   - 本文提出了UniCal，一个统一框架，旨在轻松校准配备多个LiDAR和摄像头的自驾车辆。   - 该方法基于可微分场景表示，能够渲染在几何和光度上相一致的多视角传感器观测。&lt;h4&gt;4. 联合学习机制&lt;/h4&gt;   - 通过可微分体积渲染，联合学习传感器校准和基础场景表示，利用户外传感器数据，无需特定的校准基准物。&lt;h4&gt;5. “驱动与校准”方法&lt;/h4&gt;   - 这种"驱动与校准"的方法相比现有校准系统显著降低了成本和操作开销，使得大规模SDV车队的有效校准成为可能。&lt;h4&gt;6. 几何一致性保证&lt;/h4&gt;   - 为确保来自不同传感器的观测之间的几何一致性，提出了一种新颖的表面对齐损失，结合了基于特征的配准和神经渲染。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 在多个数据集上的综合评估表明，UniCal的准确性超过或匹配现有校准方法，同时在效率上更具优势，展示了UniCal在可扩展校准中的价值。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-driving vehicles (SDVs) require accurate calibration of LiDARs andcameras to fuse sensor data accurately for autonomy. Traditional calibrationmethods typically leverage fiducials captured in a controlled and structuredscene and compute correspondences to optimize over. These approaches are costlyand require substantial infrastructure and operations, making it challenging toscale for vehicle fleets. In this work, we propose UniCal, a unified frameworkfor effortlessly calibrating SDVs equipped with multiple LiDARs and cameras.Our approach is built upon a differentiable scene representation capable ofrendering multi-view geometrically and photometrically consistent sensorobservations. We jointly learn the sensor calibration and the underlying scenerepresentation through differentiable volume rendering, utilizing outdoorsensor data without the need for specific calibration fiducials. This"drive-and-calibrate" approach significantly reduces costs and operationaloverhead compared to existing calibration systems, enabling efficientcalibration for large SDV fleets at scale. To ensure geometric consistencyacross observations from different sensors, we introduce a novel surfacealignment loss that combines feature-based registration with neural rendering.Comprehensive evaluations on multiple datasets demonstrate that UniCaloutperforms or matches the accuracy of existing calibration approaches whilebeing more efficient, demonstrating the value of UniCal for scalablecalibration.</description>
      <author>example@mail.com (Ze Yang, George Chen, Haowei Zhang, Kevin Ta, Ioan Andrei Bârsan, Daniel Murphy, Sivabalan Manivasagam, Raquel Urtasun)</author>
      <guid isPermaLink="false">2409.18953v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>GSIFN: A Graph-Structured and Interlaced-Masked Multimodal Transformer-based Fusion Network for Multimodal Sentiment Analysis</title>
      <link>http://arxiv.org/abs/2408.14809v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 多模态情感分析（MSA）利用多种数据模态来分析人类情感。&lt;h4&gt;2. 现有模型问题&lt;/h4&gt;   - 现有的MSA模型通常采用先进的多模态融合和表示学习方法，但面临以下两个主要挑战：     - (i) 多模态融合方法中，模态组合的解耦和大量参数冗余导致融合性能和效率不足。     - (ii) 在单模态特征提取器和编码器中，表示能力与计算开销之间存在困难的权衡。&lt;h4&gt;3. 提出的新方法&lt;/h4&gt;   - 本文提出的GSIFN包含两个主要组件：     - (i) **图结构与交织掩蔽的多模态Transformer**：       - 采用交织掩蔽机制构建稳健的多模态图嵌入，实现全模态一体的基于Transformer的融合，显著降低计算开销。     - (ii) **自监督学习框架**：       - 具有低计算开销和高性能，利用并行化的LSTM与矩阵记忆增强非语言模态特征，以生成单模态标签。&lt;h4&gt;4. 实验验证&lt;/h4&gt;   - 在CMU-MOSI、CMU-MOSEI和CH-SIMS等MSA数据集上评估，GSIFN显示出显著优越的性能，同时计算开销显著低于之前的先进模型。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-08-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Sentiment Analysis (MSA) leverages multiple data modals to analyzehuman sentiment. Existing MSA models generally employ cutting-edge multimodalfusion and representation learning-based methods to promote MSA capability.However, there are two key challenges: (i) in existing multimodal fusionmethods, the decoupling of modal combinations and tremendous parameterredundancy, lead to insufficient fusion performance and efficiency; (ii) achallenging trade-off exists between representation capability andcomputational overhead in unimodal feature extractors and encoders. Ourproposed GSIFN incorporates two main components to solve these problems: (i) agraph-structured and interlaced-masked multimodal Transformer. It adopts theInterlaced Mask mechanism to construct robust multimodal graph embedding,achieve all-modal-in-one Transformer-based fusion, and greatly reduce thecomputational overhead; (ii) a self-supervised learning framework with lowcomputational overhead and high performance, which utilizes a parallelized LSTMwith matrix memory to enhance non-verbal modal features for unimodal labelgeneration. Evaluated on the MSA datasets CMU-MOSI, CMU-MOSEI, and CH-SIMS,GSIFN demonstrates superior performance with significantly lower computationaloverhead compared with previous state-of-the-art models.</description>
      <author>example@mail.com (Yijie Jin)</author>
      <guid isPermaLink="false">2408.14809v3</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>PixelBytes: Catching Unified Embedding for Multimodal Generation</title>
      <link>http://arxiv.org/abs/2409.15512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 本报告介绍了一种名为PixelBytes Embedding的新方法，旨在实现统一的多模态表示学习。&lt;h4&gt;2. 方法特点&lt;/h4&gt;   - 该方法能够将多种输入整合为单一的、连贯的表示，从而促进多模态序列生成，尤其针对文本和像素图像。&lt;h4&gt;3. 灵感来源&lt;/h4&gt;   - 受先进序列模型（如Image Transformers、PixelCNN和Mamba-Bytes）的启发，PixelBytes旨在解决不同数据类型整合的挑战。&lt;h4&gt;4. 模型架构探索&lt;/h4&gt;   - 探讨了多种模型架构，包括递归神经网络（RNNs）、状态空间模型（SSMs）和基于注意力的模型，特别关注双向处理和创新的PxBy嵌入技术。&lt;h4&gt;5. 实验验证&lt;/h4&gt;   - 在一个专门的PixelBytes宝可梦数据集上进行实验，结果表明，结合PxBy嵌入和卷积层的双向序列模型能够生成连贯的多模态序列。&lt;h4&gt;6. 研究贡献&lt;/h4&gt;   - 本研究为能够理解和生成统一多模态数据的集成AI模型的发展做出了贡献。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This report introduces PixelBytes Embedding, a novel approach for unifiedmultimodal representation learning. Our method captures diverse inputs in asingle, cohesive representation, enabling emergent properties for multimodalsequence generation, particularly for text and pixelated images. Inspired bystate-of-the-art sequence models such as Image Transformers, PixelCNN, andMamba-Bytes, PixelBytes aims to address the challenges of integrating differentdata types. We explore various model architectures, including Recurrent NeuralNetworks (RNNs), State Space Models (SSMs), and Attention-based models,focusing on bidirectional processing and our innovative PxBy embeddingtechnique. Our experiments, conducted on a specialized PixelBytes Pok{\'e}mondataset, demonstrate that bidirectional sequence models with PxBy embedding andconvolutional layers can generate coherent multimodal sequences. This workcontributes to the advancement of integrated AI models capable of understandingand generating multimodal data in a unified manner.</description>
      <author>example@mail.com (Fabien Furfaro)</author>
      <guid isPermaLink="false">2409.15512v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised Multimodal Speech Representations for the Assessment of Schizophrenia Symptoms</title>
      <link>http://arxiv.org/abs/2409.09733v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 多模态精神分裂症评估系统近年来获得了广泛关注。&lt;h4&gt;2. 研究目的&lt;/h4&gt;   - 本文提出一个精神分裂症评估系统，用于区分精神分裂症的主要症状类别，并预测整体严重程度评分。&lt;h4&gt;3. 模型开发&lt;/h4&gt;   - 开发了一个基于向量量化变分自编码器（VQ-VAE）的多模态表示学习（MRL）模型，旨在从声道变量（TVs）和面部动作单元（FAUs）中生成与任务无关的语音表示。&lt;h4&gt;4. 下游预测模型&lt;/h4&gt;   - 这些表示随后被用于基于多任务学习（MTL）的下游预测模型，以获取分类标签和整体严重程度评分。&lt;h4&gt;5. 性能提升&lt;/h4&gt;   - 提出的框架在多类分类任务中超越了之前的研究，在所有评估指标（加权F1分数、AUC-ROC分数和加权准确率）上表现更佳。&lt;h4&gt;6. 新任务的解决&lt;/h4&gt;   - 此外，该系统能够估计精神分裂症的严重程度评分，这是早期方法未能解决的任务。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal schizophrenia assessment systems have gained traction over thelast few years. This work introduces a schizophrenia assessment system todiscern between prominent symptom classes of schizophrenia and predict anoverall schizophrenia severity score. We develop a Vector Quantized VariationalAuto-Encoder (VQ-VAE) based Multimodal Representation Learning (MRL) model toproduce task-agnostic speech representations from vocal Tract Variables (TVs)and Facial Action Units (FAUs). These representations are then used in aMulti-Task Learning (MTL) based downstream prediction model to obtain classlabels and an overall severity score. The proposed framework outperforms theprevious works on the multi-class classification task across all evaluationmetrics (Weighted F1 score, AUC-ROC score, and Weighted Accuracy).Additionally, it estimates the schizophrenia severity score, a task notaddressed by earlier approaches.</description>
      <author>example@mail.com (Gowtham Premananth, Carol Espy-Wilson)</author>
      <guid isPermaLink="false">2409.09733v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Structural Similarity-based Underwater Sonar Loop Detection</title>
      <link>http://arxiv.org/abs/2409.14020v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目的&lt;/h4&gt;   - 实现水下环境的自主导航，需要提前使用同时定位与地图构建（SLAM）算法创建地图，利用声纳等传感器。&lt;h4&gt;2. 环路闭合的重要性&lt;/h4&gt;   - 在SLAM过程中，使用环路闭合技术以减少累积的姿态误差。&lt;h4&gt;3. 现有方法的局限性&lt;/h4&gt;   - 以往研究通过将3D点云投影到2D来进行环路检测，但这一过程会因图像分辨率导致数据丢失。   - 在单调的水下环境（如河流或湖泊）中，提取关键点变得困难。   - 使用神经网络或基于词袋模型（BoW）的方法需要额外的预处理任务，例如提前训练模型或预创建词汇。&lt;h4&gt;4. 提出的新方法&lt;/h4&gt;   - 本文直接利用声纳数据获得的点云，避免因投影造成的性能下降。   - 通过数学公式计算点云的逐点结构特征图，并比较点云之间的相似性，消除了对关键点提取的需求。&lt;h4&gt;5. 算法的适应性&lt;/h4&gt;   - 该算法能够在新环境中运行，无需额外的学习或处理任务。&lt;h4&gt;6. 实验验证&lt;/h4&gt;   - 使用来自深水的南极数据集和来自河流与湖泊的Seaward数据集验证了所提方法的性能。   - 实验结果表明，该方法在两个数据集上均实现了最佳的环路检测性能。&lt;h4&gt;7. 代码获取&lt;/h4&gt;   - 相关代码可在 [GitHub](https://github.com/donghwijung/point_cloud_structural_similarity_based_underwater_sonar_loop_detection) 上获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In order to enable autonomous navigation in underwater environments, a mapneeds to be created in advance using a Simultaneous Localization and Mapping(SLAM) algorithm that utilizes sensors like a sonar. At this time, loop closureis employed to reduce the pose error accumulated during the SLAM process. Inthe case of loop detection using a sonar, some previous studies have used amethod of projecting the 3D point cloud into 2D, then extracting keypoints andmatching them. However, during the 2D projection process, data loss occurs dueto image resolution, and in monotonous underwater environments such as riversor lakes, it is difficult to extract keypoints. Additionally, methods that useneural networks or are based on Bag of Words (BoW) have the disadvantage ofrequiring additional preprocessing tasks, such as training the model in advanceor pre-creating a vocabulary. To address these issues, in this paper, weutilize the point cloud obtained from sonar data without any projection toprevent performance degradation due to data loss. Additionally, by calculatingthe point-wise structural feature map of the point cloud using mathematicalformulas and comparing the similarity between point clouds, we eliminate theneed for keypoint extraction and ensure that the algorithm can operate in newenvironments without additional learning or tasks. To evaluate the method, wevalidated the performance of the proposed algorithm using the Antarcticadataset obtained from deep underwater and the Seaward dataset collected fromrivers and lakes. Experimental results show that our proposed method achievesthe best loop detection performance in both datasets. Our code is available athttps://github.com/donghwijung/point_cloud_structural_similarity_based_underwater_sonar_loop_detection.</description>
      <author>example@mail.com (Donghwi Jung, Andres Pulido, Jane Shin, Seong-Woo Kim)</author>
      <guid isPermaLink="false">2409.14020v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>GND: Global Navigation Dataset with Multi-Modal Perception and Multi-Category Traversability in Outdoor Campus Environments</title>
      <link>http://arxiv.org/abs/2409.14262v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 在大型户外环境中导航需要对几何结构、环境语义和地形特征进行复杂推理，这些通常通过LiDAR和相机等传感器捕捉。&lt;h4&gt;2. 现有技术的局限&lt;/h4&gt;   - 当前的移动机器人依赖于基于手工规则和高精度地图进行导航，但缺乏人类在未知户外空间中具备的常识推理能力。&lt;h4&gt;3. 数据集介绍&lt;/h4&gt;   - 提出了全球导航数据集（Global Navigation Dataset, GND），这是一个大型数据集，集成了多模态传感器数据，包括3D LiDAR点云、RGB图像和360度图像。&lt;h4&gt;4. 数据集内容&lt;/h4&gt;   - 包含多类别可通行性地图（如行人步道、车辆道路、楼梯、越野地形和障碍物），数据来源于十个大学校园。   - 环境类型多样，包括公园、城市设置、高程变化和不同规模的校园布局。&lt;h4&gt;5. 数据集规模&lt;/h4&gt;   - 数据集覆盖约2.7平方公里，总计包含至少350座建筑。&lt;h4&gt;6. 应用展示&lt;/h4&gt;   - 提供了一系列GND的新应用案例，展示其在全球机器人导航中的实用性，包括基于地图的全球导航、无地图导航和全球位置识别等。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Navigating large-scale outdoor environments requires complex reasoning interms of geometric structures, environmental semantics, and terraincharacteristics, which are typically captured by onboard sensors such as LiDARand cameras. While current mobile robots can navigate such environments usingpre-defined, high-precision maps based on hand-crafted rules catered for thespecific environment, they lack commonsense reasoning capabilities that mosthumans possess when navigating unknown outdoor spaces. To address this gap, weintroduce the Global Navigation Dataset (GND), a large-scale dataset thatintegrates multi-modal sensory data, including 3D LiDAR point clouds and RGBand 360-degree images, as well as multi-category traversability maps(pedestrian walkways, vehicle roadways, stairs, off-road terrain, andobstacles) from ten university campuses. These environments encompass a varietyof parks, urban settings, elevation changes, and campus layouts of differentscales. The dataset covers approximately 2.7km2 and includes at least 350buildings in total. We also present a set of novel applications of GND toshowcase its utility to enable global robot navigation, such as map-basedglobal navigation, mapless navigation, and global place recognition.</description>
      <author>example@mail.com (Jing Liang, Dibyendu Das, Daeun Song, Md Nahid Hasan Shuvo, Mohammad Durrani, Karthik Taranath, Ivan Penskiy, Dinesh Manocha, Xuesu Xiao)</author>
      <guid isPermaLink="false">2409.14262v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>DepMamba: Progressive Fusion Mamba for Multimodal Depression Detection</title>
      <link>http://arxiv.org/abs/2409.15936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 抑郁症是一种影响全球数百万人的常见心理疾病。&lt;h4&gt;2. 现有方法的局限性&lt;/h4&gt;   - 当前的多模态方法依赖于对齐或聚合的多模态融合，存在两个主要问题：     - **长距离时间建模效率低**。     - **多模态融合效果不佳**，包括跨模态融合和单模态处理之间的协同。&lt;h4&gt;3. 提出的模型&lt;/h4&gt;   - 本文提出了一种音频-视觉渐进融合模型，称为DepMamba，用于多模态抑郁检测。&lt;h4&gt;4. 核心设计&lt;/h4&gt;   - **分层上下文建模**：     - 结合卷积神经网络和Mamba，从局部到全局提取特征，适用于长距离序列。   - **渐进多模态融合**：     - 首先使用多模态协作状态空间模型（SSM）提取每种模态的跨模态和单模态信息。     - 其次，利用增强的多模态SSM来增强模态之间的凝聚力。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 在两个大规模抑郁症数据集上的广泛实验结果显示，DepMamba在性能上优于现有的最新方法。&lt;h4&gt;6. 代码获取&lt;/h4&gt;   - 相关代码可在 [GitHub](https://github.com/Jiaxin-Ye/DepMamba) 上获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Jiaxin-Ye/DepMamba&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Depression is a common mental disorder that affects millions of peopleworldwide. Although promising, current multimodal methods hinge on aligned oraggregated multimodal fusion, suffering two significant limitations: (i)inefficient long-range temporal modeling, and (ii) sub-optimal multimodalfusion between intermodal fusion and intramodal processing. In this paper, wepropose an audio-visual progressive fusion Mamba for multimodal depressiondetection, termed DepMamba. DepMamba features two core designs: hierarchicalcontextual modeling and progressive multimodal fusion. On the one hand,hierarchical modeling introduces convolution neural networks and Mamba toextract the local-to-global features within long-range sequences. On the otherhand, the progressive fusion first presents a multimodal collaborative StateSpace Model (SSM) extracting intermodal and intramodal information for eachmodality, and then utilizes a multimodal enhanced SSM for modality cohesion.Extensive experimental results on two large-scale depression datasetsdemonstrate the superior performance of our DepMamba over existingstate-of-the-art methods. Code is available athttps://github.com/Jiaxin-Ye/DepMamba.</description>
      <author>example@mail.com (Jiaxin Ye, Junping Zhang, Hongming Shan)</author>
      <guid isPermaLink="false">2409.15936v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Semantic Leakage in Cross-lingual Embeddings via Orthogonality Constraint</title>
      <link>http://arxiv.org/abs/2409.15664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 16 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 准确对齐跨语言句子嵌入中的上下文表示对有效的并行数据挖掘至关重要。&lt;h4&gt;2. 常见策略&lt;/h4&gt;   - 一种常见策略是从多语言预训练模型中获取的句子嵌入中将语义和语言分开。&lt;h4&gt;3. 现有方法的不足&lt;/h4&gt;   - 目前的解开表示学习方法存在“语义泄漏”问题，即大量特定语言的信息不小心泄漏到语义表示中。&lt;h4&gt;4. 影响&lt;/h4&gt;   - 这种泄漏阻碍了语义和语言表示的有效解开，使得难以检索到能清晰表示句子意义的嵌入。&lt;h4&gt;5. 提出的新方法&lt;/h4&gt;   - 为了解决这一挑战，提出了一种新训练目标，称为正交约束学习（ORACLE），旨在强制语义嵌入和语言嵌入之间的正交性。&lt;h4&gt;6. 关键组成部分&lt;/h4&gt;   - ORACLE基于两个组成部分：类内聚类和类间分离。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 通过在跨语言检索和语义文本相似性任务上的实验，证明了使用ORACLE目标进行训练有效减少了语义泄漏，并增强了嵌入空间内的语义对齐。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/dayeonki/oracle&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately aligning contextual representations in cross-lingual sentenceembeddings is key for effective parallel data mining. A common strategy forachieving this alignment involves disentangling semantics and language insentence embeddings derived from multilingual pre-trained models. However, wediscover that current disentangled representation learning methods suffer fromsemantic leakage - a term we introduce to describe when a substantial amount oflanguage-specific information is unintentionally leaked into semanticrepresentations. This hinders the effective disentanglement of semantic andlanguage representations, making it difficult to retrieve embeddings thatdistinctively represent the meaning of the sentence. To address this challenge,we propose a novel training objective, ORthogonAlity Constraint LEarning(ORACLE), tailored to enforce orthogonality between semantic and languageembeddings. ORACLE builds upon two components: intra-class clustering andinter-class separation. Through experiments on cross-lingual retrieval andsemantic textual similarity tasks, we demonstrate that training with the ORACLEobjective effectively reduces semantic leakage and enhances semantic alignmentwithin the embedding space.</description>
      <author>example@mail.com (Dayeon Ki, Cheonbok Park, Hyunjoong Kim)</author>
      <guid isPermaLink="false">2409.15664v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Deep Transfer Hashing for Adaptive Learning on Federated Streaming Data</title>
      <link>http://arxiv.org/abs/2409.12575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at ECML2024: 8th Intl. Worksh. and Tutorial on Interactive
  Adaptive Learning, Sep. 9th, 2024, Vilnius, Lithuania&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文探讨了将联邦学习与深度迁移哈希结合，用于分布式预测任务，强调资源高效的客户端训练。&lt;h4&gt;2. 联邦学习的优势&lt;/h4&gt;   - 联邦学习允许多个客户端协同训练共享模型，同时保护数据隐私。&lt;h4&gt;3. 深度迁移哈希的作用&lt;/h4&gt;   - 通过引入深度迁移哈希，可以将高维数据转换为紧凑的哈希码，减少数据传输量和网络负载。&lt;h4&gt;4. 框架设计&lt;/h4&gt;   - 提出的框架利用迁移学习，在中央服务器上预训练深度神经网络，然后在客户端进行微调，以提高模型的准确性和适应性。&lt;h4&gt;5. 隐私保护机制&lt;/h4&gt;   - 采用选择性哈希码共享机制，使用隐私保护的全局记忆库，进一步支持客户端的微调。&lt;h4&gt;6. 解决研究挑战&lt;/h4&gt;   - 该方法通过提高计算效率和可扩展性解决了之前研究中的挑战。&lt;h4&gt;7. 实际应用场景&lt;/h4&gt;   - 实际应用包括Car2X事件预测，通过共同训练的模型识别交通模式，辅助交通密度评估和事故检测等任务。&lt;h4&gt;8. 研究目标&lt;/h4&gt;   - 旨在开发一个结合联邦学习、深度迁移哈希和迁移学习的强大框架，以实现高效和安全的下游任务执行。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This extended abstract explores the integration of federated learning withdeep transfer hashing for distributed prediction tasks, emphasizingresource-efficient client training from evolving data streams. Federatedlearning allows multiple clients to collaboratively train a shared model whilemaintaining data privacy - by incorporating deep transfer hashing,high-dimensional data can be converted into compact hash codes, reducing datatransmission size and network loads. The proposed framework utilizes transferlearning, pre-training deep neural networks on a central server, andfine-tuning on clients to enhance model accuracy and adaptability. A selectivehash code sharing mechanism using a privacy-preserving global memory bankfurther supports client fine-tuning. This approach addresses challenges inprevious research by improving computational efficiency and scalability.Practical applications include Car2X event predictions, where a shared model iscollectively trained to recognize traffic patterns, aiding in tasks such astraffic density assessment and accident detection. The research aims to developa robust framework that combines federated learning, deep transfer hashing andtransfer learning for efficient and secure downstream task execution.</description>
      <author>example@mail.com (Manuel Röder, Frank-Michael Schleif)</author>
      <guid isPermaLink="false">2409.12575v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning from Contrastive Prompts: Automated Optimization and Adaptation</title>
      <link>http://arxiv.org/abs/2409.15199v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着大型语言模型（LLMs）的发展，手动编写提示的工作量显著增加。&lt;h4&gt;2. 现有方法的局限&lt;/h4&gt;   - 现有的提示优化方法虽然实现了自动化，但仅依赖于从错误样本中学习，导致性能不理想。&lt;h4&gt;3. 未探讨的挑战&lt;/h4&gt;   - 文献中未探讨的一个问题是，适用于旧模型的提示在新版本或不同语言上可能效果不佳。&lt;h4&gt;4. 提出的新框架&lt;/h4&gt;   - 本文提出了“对比提示学习”（LCP）框架，旨在解决这些问题，提升提示优化和适应性。&lt;h4&gt;5. 方法论&lt;/h4&gt;   - LCP采用对比学习，通过分析有效和无效提示示例中的模式，生成有效的提示。&lt;h4&gt;6. 实验评估&lt;/h4&gt;   - 在Big-Bench Hard数据集上的评估显示，LCP在提示优化方面的胜率超过76%，优于现有方法。&lt;h4&gt;7. 适应性强&lt;/h4&gt;   - LCP在不同模型版本、模型家族和语言之间表现出强大的适应性。&lt;h4&gt;8. 贡献与意义&lt;/h4&gt;   - LCP提供了一种系统化的提示工程方法，减少在不同上下文中部署LLMs所需的手动工作。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As LLMs evolve, significant effort is spent on manually crafting prompts.While existing prompt optimization methods automate this process, they relysolely on learning from incorrect samples, leading to a sub-optimalperformance. Additionally, an unexplored challenge in the literature is promptseffective for prior models may not perform well on newer versions or differentlanguages. We propose the Learning from Contrastive Prompts (LCP) framework toaddress these gaps, enhancing both prompt optimization and adaptation. LCPemploys contrastive learning to generate effective prompts by analyzingpatterns in good and bad prompt examples. Our evaluation on the Big-Bench Harddataset shows that LCP has a win rate of over 76% over existing methods inprompt optimization and demonstrates strong adaptability across different modelversions, families, and languages. LCP offers a systematic approach to promptengineering, reducing manual effort in deploying LLMs across varied contexts.</description>
      <author>example@mail.com (Mingqi Li, Karan Aggarwal, Yong Xie, Aitzaz Ahmad, Stephen Lau)</author>
      <guid isPermaLink="false">2409.15199v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios</title>
      <link>http://arxiv.org/abs/2409.17864v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at 18th ACM Conference on Recommender Systems (RecSys '24)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 大多数推荐系统采用协同过滤（CF），根据过去的集体互动提供推荐。&lt;h4&gt;2. 问题陈述&lt;/h4&gt;   - 当可用的互动很少或没有时，CF算法的性能会下降，这种情况被称为冷启动问题。&lt;h4&gt;3. 解决方案概述&lt;/h4&gt;   - 以前的研究依赖于利用用户或物品的协同数据和侧面信息的模型。&lt;h4&gt;4. 方法创新&lt;/h4&gt;   - 本文提出了一种新的多模态推荐技术，称为多模态单支路嵌入网络（SiBraR）。&lt;h4&gt;5. 模型设计&lt;/h4&gt;   - SiBraR通过权重共享，使用同一个单支路嵌入网络对不同模态的互动数据和多模态侧面信息进行编码。&lt;h4&gt;6. 模型优势&lt;/h4&gt;   - SiBraR在缺失模态的情况下（如冷启动）表现出色。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 在来自三个不同推荐领域（音乐、电影和电子商务）的规模较大的推荐数据集上进行的广泛实验表明，SiBraR在冷启动情境下显著优于CF和最先进的基于内容的推荐系统。&lt;h4&gt;8. 推荐准确性&lt;/h4&gt;   - SiBraR在缺失模态场景中推荐的准确性高，并且能够将不同模态映射到共享嵌入空间的相同区域，从而减少模态间的差距。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3640457.3688009&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most recommender systems adopt collaborative filtering (CF) and providerecommendations based on past collective interactions. Therefore, theperformance of CF algorithms degrades when few or no interactions areavailable, a scenario referred to as cold-start. To address this issue,previous work relies on models leveraging both collaborative data and sideinformation on the users or items. Similar to multimodal learning, these modelsaim at combining collaborative and content representations in a sharedembedding space. In this work we propose a novel technique for multimodalrecommendation, relying on a multimodal Single-Branch embedding network forRecommendation (SiBraR). Leveraging weight-sharing, SiBraR encodes interactiondata as well as multimodal side information using the same single-branchembedding network on different modalities. This makes SiBraR effective inscenarios of missing modality, including cold start. Our extensive experimentson large-scale recommendation datasets from three different recommendationdomains (music, movie, and e-commerce) and providing multimodal contentinformation (audio, text, image, labels, and interactions) show that SiBraRsignificantly outperforms CF as well as state-of-the-art content-based RSs incold-start scenarios, and is competitive in warm scenarios. We show thatSiBraR's recommendations are accurate in missing modality scenarios, and thatthe model is able to map different modalities to the same region of the sharedembedding space, hence reducing the modality gap.</description>
      <author>example@mail.com (Christian Ganhör, Marta Moscati, Anna Hausberger, Shah Nawaz, Markus Schedl)</author>
      <guid isPermaLink="false">2409.17864v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Exploring bat song syllable representations in self-supervised audio encoders</title>
      <link>http://arxiv.org/abs/2409.12634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at VIHAR-2024; see https://vihar-2024.vihar.org/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究问题&lt;/h4&gt;   - 本文探讨深度学习模型在识别其他物种的声乐类型方面的表现，特别是针对人类生成声音训练的模型。&lt;h4&gt;2. 研究焦点&lt;/h4&gt;   - 分析了多个自监督音频编码器对蝙蝠歌曲音节的编码能力。&lt;h4&gt;3. 主要发现&lt;/h4&gt;   - 发现经过人类语音预训练的模型生成了不同音节类型最具辨别性的表示。&lt;h4&gt;4. 研究意义&lt;/h4&gt;   - 这些发现为在蝙蝠生物声学中应用跨物种迁移学习奠定了基础。&lt;h4&gt;5. 信号处理理解&lt;/h4&gt;   - 研究还提升了对音频编码模型在处理分布外信号时的理解。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; How well can deep learning models trained on human-generated soundsdistinguish between another species' vocalization types? We analyze theencoding of bat song syllables in several self-supervised audio encoders, andfind that models pre-trained on human speech generate the most distinctiverepresentations of different syllable types. These findings form first stepstowards the application of cross-species transfer learning in bat bioacoustics,as well as an improved understanding of out-of-distribution signal processingin audio encoder models.</description>
      <author>example@mail.com (Marianne de Heer Kloots, Mirjam Knörnschild)</author>
      <guid isPermaLink="false">2409.12634v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>3D-JEPA: A Joint Embedding Predictive Architecture for 3D Self-Supervised Representation Learning</title>
      <link>http://arxiv.org/abs/2409.15803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 不变性基础和生成方法在3D自监督表示学习（SSRL）中表现突出，但存在一些问题。&lt;h4&gt;2. 问题陈述&lt;/h4&gt;   - 不变性方法依赖手工设计的数据增强，这可能引入对所有下游任务不适用的偏差。   - 生成方法则不加区分地重建被遮挡区域，导致表示空间中保存了无关的细节。&lt;h4&gt;3. 提出的新方法&lt;/h4&gt;   - 本文介绍了3D-JEPA，这是一个新颖的非生成性3D自监督表示学习框架。&lt;h4&gt;4. 多块采样策略&lt;/h4&gt;   - 提出了多块采样策略，生成足够的信息上下文块和多个代表性目标块。&lt;h4&gt;5. 上下文感知解码器&lt;/h4&gt;   - 采用上下文感知解码器增强目标块的重建效果，持续将上下文信息输入解码器，帮助编码器学习语义建模，而非仅仅记忆与目标块相关的上下文信息。&lt;h4&gt;6. 表示预测机制&lt;/h4&gt;   - 3D-JEPA通过编码器和上下文感知解码器架构，从上下文块预测目标块的表示。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 在不同数据集上的多项下游任务中证明了3D-JEPA的有效性和高效性，预训练周期较少的情况下实现了更高的准确率。&lt;h4&gt;8. 具体结果&lt;/h4&gt;   - 例如，在PB_T50_RS数据集上，经过150个预训练周期后达到了88.65%的准确率。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Invariance-based and generative methods have shown a conspicuous performancefor 3D self-supervised representation learning (SSRL). However, the formerrelies on hand-crafted data augmentations that introduce bias not universallyapplicable to all downstream tasks, and the latter indiscriminatelyreconstructs masked regions, resulting in irrelevant details being saved in therepresentation space. To solve the problem above, we introduce 3D-JEPA, a novelnon-generative 3D SSRL framework. Specifically, we propose a multi-blocksampling strategy that produces a sufficiently informative context block andseveral representative target blocks. We present the context-aware decoder toenhance the reconstruction of the target blocks. Concretely, the contextinformation is fed to the decoder continuously, facilitating the encoder inlearning semantic modeling rather than memorizing the context informationrelated to target blocks. Overall, 3D-JEPA predicts the representation oftarget blocks from a context block using the encoder and context-aware decoderarchitecture. Various downstream tasks on different datasets demonstrate3D-JEPA's effectiveness and efficiency, achieving higher accuracy with fewerpretraining epochs, e.g., 88.65% accuracy on PB_T50_RS with 150 pretrainingepochs.</description>
      <author>example@mail.com (Naiwen Hu, Haozhe Cheng, Yifan Xie, Shiqi Li, Jihua Zhu)</author>
      <guid isPermaLink="false">2409.15803v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Pix2Next: Leveraging Vision Foundation Models for RGB to NIR Image Translation</title>
      <link>http://arxiv.org/abs/2409.16706v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages,12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 本文提出了Pix2Next，这是一个新颖的图像到图像转换框架，旨在解决从RGB输入生成高质量近红外（NIR）图像的挑战。&lt;h4&gt;2. 方法论&lt;/h4&gt;   - 该方法利用最先进的视觉基础模型（VFM），采用编码器-解码器架构，结合跨注意力机制以增强特征集成。&lt;h4&gt;3. 特征捕捉&lt;/h4&gt;   - 设计旨在捕获详细的全局表示并保留重要的光谱特征，将RGB到NIR的转换视为一个复杂的问题，而不仅仅是简单的领域转换。&lt;h4&gt;4. 生成对抗网络&lt;/h4&gt;   - 使用多尺度PatchGAN判别器，确保在不同细节层次上生成逼真的图像。&lt;h4&gt;5. 损失函数设计&lt;/h4&gt;   - 精心设计的损失函数将全局上下文理解与局部特征保留相结合，以提高图像生成的质量。&lt;h4&gt;6. 实验验证&lt;/h4&gt;   - 在RANUS数据集上进行实验，结果表明Pix2Next在定量指标和视觉质量上具有优势，FID分数比现有方法提高了34.81%。&lt;h4&gt;7. 实际应用&lt;/h4&gt;   - 展示了Pix2Next的实际效用，通过生成的NIR数据增强有限真实NIR数据集，提升下游目标检测任务的性能。&lt;h4&gt;8. 数据集扩展&lt;/h4&gt;   - 该方法使得在无需额外数据采集或标注工作的情况下扩大NIR数据集成为可能，潜在地加速NIR基础计算机视觉应用的发展。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes Pix2Next, a novel image-to-image translation frameworkdesigned to address the challenge of generating high-quality Near-Infrared(NIR) images from RGB inputs. Our approach leverages a state-of-the-art VisionFoundation Model (VFM) within an encoder-decoder architecture, incorporatingcross-attention mechanisms to enhance feature integration. This design capturesdetailed global representations and preserves essential spectralcharacteristics, treating RGB-to-NIR translation as more than a simple domaintransfer problem. A multi-scale PatchGAN discriminator ensures realistic imagegeneration at various detail levels, while carefully designed loss functionscouple global context understanding with local feature preservation. Weperformed experiments on the RANUS dataset to demonstrate Pix2Next's advantagesin quantitative metrics and visual quality, improving the FID score by 34.81%compared to existing methods. Furthermore, we demonstrate the practical utilityof Pix2Next by showing improved performance on a downstream object detectiontask using generated NIR data to augment limited real NIR datasets. Theproposed approach enables the scaling up of NIR datasets without additionaldata acquisition or annotation efforts, potentially accelerating advancementsin NIR-based computer vision applications.</description>
      <author>example@mail.com (Youngwan Jin, Incheol Park, Hanbin Song, Hyeongjin Ju, Yagiz Nalcakan, Shiho Kim)</author>
      <guid isPermaLink="false">2409.16706v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>ViKL: A Mammography Interpretation Framework via Multimodal Aggregation of Visual-knowledge-linguistic Features</title>
      <link>http://arxiv.org/abs/2409.15744v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 乳腺摄影是乳腺癌诊断的主要成像工具。尽管在深度学习应用于乳腺摄影图像解读方面取得了重要进展，但以视觉特征为主的努力在跨数据集的泛化上往往存在困难。&lt;h4&gt;2. 研究假设&lt;/h4&gt;   - 我们假设，整合放射科实践中的其他模态，特别是报告的语言特征和体现放射学见解的表现特征，可以提供更强大、更可解释且更具泛化能力的表示。&lt;h4&gt;3. 提出的数据集&lt;/h4&gt;   - 本文宣布了MVKL，这是第一个包含多视角图像、详细表现和报告的多模态乳腺摄影数据集。&lt;h4&gt;4. 研究目标&lt;/h4&gt;   - 基于该数据集，集中研究无监督预训练的挑战任务，并提出了ViKL框架，旨在协同整合视觉、知识和语言特征。&lt;h4&gt;5. 框架特点&lt;/h4&gt;   - ViKL框架仅依赖配对信息，无需获得通常难以获取的病理标签。&lt;h4&gt;6. 学习方法&lt;/h4&gt;   - ViKL采用三重对比学习方法，将语言和知识基础的见解与视觉数据结合，实现了跨模态和同模态特征的增强。&lt;h4&gt;7. 研究发现&lt;/h4&gt;   - 1) 整合报告和表现与无监督视觉预训练显著提升病理分类性能，并促进多模态交互。   - 2) 表现可以引入一种新的困难负样本选择机制。   - 3) 多模态特征在不同数据集之间表现出可迁移性。   - 4) 多模态预训练方法减少了误校准，并构建了高质量的表示空间。&lt;h4&gt;8. 资源共享&lt;/h4&gt;   - MVKL数据集和ViKL代码公开可用，支持广泛的未来研究，链接为 [GitHub - ViKL](https://github.com/wxwxwwxxx/ViKL)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wxwxwwxxx/vikl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mammography is the primary imaging tool for breast cancer diagnosis. Despitesignificant strides in applying deep learning to interpret mammography images,efforts that focus predominantly on visual features often struggle withgeneralization across datasets. We hypothesize that integrating additionalmodalities in the radiology practice, notably the linguistic features ofreports and manifestation features embodying radiological insights, offers amore powerful, interpretable and generalizable representation. In this paper,we announce MVKL, the first multimodal mammography dataset encompassingmulti-view images, detailed manifestations and reports. Based on this dataset,we focus on the challanging task of unsupervised pretraining and propose ViKL,a innovative framework that synergizes Visual, Knowledge, and Linguisticfeatures. This framework relies solely on pairing information without thenecessity for pathology labels, which are often challanging to acquire. ViKLemploys a triple contrastive learning approach to merge linguistic andknowledge-based insights with visual data, enabling both inter-modality andintra-modality feature enhancement. Our research yields significant findings:1) Integrating reports and manifestations with unsupervised visual pretraining,ViKL substantially enhances the pathological classification and fostersmultimodal interactions. 2) Manifestations can introduce a novel hard negativesample selection mechanism. 3) The multimodal features demonstratetransferability across different datasets. 4) The multimodal pretrainingapproach curbs miscalibrations and crafts a high-quality representation space.The MVKL dataset and ViKL code are publicly available athttps://github.com/wxwxwwxxx/ViKL to support a broad spectrum of futureresearch.</description>
      <author>example@mail.com (Xin Wei, Yaling Tao, Changde Du, Gangming Zhao, Yizhou Yu, Jinpeng Li)</author>
      <guid isPermaLink="false">2409.15744v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Boolean Product Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2409.14001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2407.10688&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 图神经网络（GNNs）最近取得了显著成功，关键操作是聚合邻居节点的信息。&lt;h4&gt;2. 邻居定义问题&lt;/h4&gt;   - 目前研究主要基于观察到的邻接矩阵来定义邻居进行信息聚合。然而，显式给定的图通常包含噪声，这在消息传递过程中可能被放大。&lt;h4&gt;3. 转向潜在图推断&lt;/h4&gt;   - 由于上述问题，许多研究者开始关注潜在图推断，具体是学习参数化图。&lt;h4&gt;4. 提出的新方法&lt;/h4&gt;   - 本文提出了一种基于布尔乘积的图残差连接，旨在将潜在图与原始图连接，以减轻潜在图结构学习中的波动。&lt;h4&gt;5. 布尔乘积的计算&lt;/h4&gt;   - 在每一层中计算潜在图与原始图之间的布尔乘积，以纠正学习过程。&lt;h4&gt;6. 三角形检测的等价性&lt;/h4&gt;   - 两个邻接矩阵之间的布尔乘积等价于三角形检测。&lt;h4&gt;7. 方法解释&lt;/h4&gt;   - 提出的布尔乘积图神经网络可以被解释为从原始图和潜在图中发现三角形团。&lt;h4&gt;8. 实验验证&lt;/h4&gt;   - 在基准数据集上验证了该方法，结果表明其能够提高图神经网络的性能和鲁棒性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have recently achieved significant success, witha key operation involving the aggregation of information from neighboringnodes. Substantial researchers have focused on defining neighbors foraggregation, predominantly based on observed adjacency matrices. However, inmany scenarios, the explicitly given graphs contain noise, which can beamplified during the messages-passing process. Therefore, many researchers haveturned their attention to latent graph inference, specifically learning aparametric graph. To mitigate fluctuations in latent graph structure learning,this paper proposes a novel Boolean product-based graph residual connection inGNNs to link the latent graph and the original graph. It computes the Booleanproduct between the latent graph and the original graph at each layer tocorrect the learning process. The Boolean product between two adjacencymatrices is equivalent to triangle detection. Accordingly, the proposed Booleanproduct graph neural networks can be interpreted as discovering triangularcliques from the original and the latent graph. We validate the proposed methodin benchmark datasets and demonstrate its ability to enhance the performanceand robustness of GNNs.</description>
      <author>example@mail.com (Ziyan Wang, Bin Liu, Ling Xiang)</author>
      <guid isPermaLink="false">2409.14001v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>ERPoT: Effective and Reliable Pose Tracking for Mobile Robots Based on Lightweight and Compact Polygon Maps</title>
      <link>http://arxiv.org/abs/2409.14723v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目的&lt;/h4&gt;   - 本文提出了一种有效且可靠的移动机器人位姿跟踪解决方案，称为ERPoT，专为大规模户外环境设计。&lt;h4&gt;2. 创新点&lt;/h4&gt;   - 提出了一种由多个多边形组成的先验多边形地图，以应对环境扩展导致的地图大小增加问题。&lt;h4&gt;3. 地图优势&lt;/h4&gt;   - 先验多边形地图通过简洁、准确地描绘环境占用，实现了长期可靠的位姿跟踪，同时保持了紧凑的形式。&lt;h4&gt;4. 数据处理&lt;/h4&gt;   - 位姿跟踪在纯LiDAR模式下进行，密集的3D点云通过地面去除和障碍物选择转化为稀疏的2D扫描。&lt;h4&gt;5. 新成本函数&lt;/h4&gt;   - 引入了一种新的成本函数用于通过点-多边形匹配进行位姿估计，包含两种约束形式：点到顶点和点到边缘。&lt;h4&gt;6. 研究重点&lt;/h4&gt;   - 主要关注两个方面：轻量化和紧凑的先验地图构建，以及有效可靠的机器人位姿跟踪。&lt;h4&gt;7. 应用前景&lt;/h4&gt;   - 这两个方面为未来在不同环境中配备不同LiDAR传感器的移动平台导航奠定了基础。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 通过对公开数据集和自记录数据集的比较实验，评估结果显示ERPoT在可靠性、先验地图大小、位姿估计误差和运行时间方面优于其他五种方法。&lt;h4&gt;9. 资源链接&lt;/h4&gt;   - 相关代码可在GitHub上访问：[GitHub - ERPoT](https://github.com/ghm0819/ERPoT)。   - 相关补充视频可在YouTube观看：[视频链接](https://youtu.be/cseml5FrW1Q)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an effective and reliable pose tracking solution termedERPoT for mobile robots operating in large-scale outdoor environments,underpinned by an innovative prior polygon map. Especially, to overcome thechallenge that arises as the map size grows with the expansion of theenvironment, the novel form of a prior map composed of multiple polygons isproposed. Benefiting from the use of polygons to concisely and accuratelydepict environmental occupancy, the prior polygon map achieves long-termreliable pose tracking while ensuring a compact form. More importantly, posetracking is carried out under pure LiDAR mode, and the dense 3D point cloud istransformed into a sparse 2D scan through ground removal and obstacleselection. On this basis, a novel cost function for pose estimation throughpoint-polygon matching is introduced, encompassing two distinct constraintforms: point-to-vertex and point-to-edge. In this study, our primary focus lieson two crucial aspects: lightweight and compact prior map construction, as wellas effective and reliable robot pose tracking. Both aspects serve as thefoundational pillars for future navigation across different mobile platformsequipped with different LiDAR sensors in different environments. Comparativeexperiments based on the publicly available datasets and our self-recordeddatasets are conducted, and evaluation results show the superior performance ofERPoT on reliability, prior map size, pose estimation error, and runtime overthe other five approaches. The corresponding code can be accessed athttps://github.com/ghm0819/ERPoT, and the supplementary video is athttps://youtu.be/cseml5FrW1Q.</description>
      <author>example@mail.com (Haiming Gao, Qibo Qiu, Hongyan Liu, Dingkun Liang, Chaoqun Wang, Xuebo Zhang)</author>
      <guid isPermaLink="false">2409.14723v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Rapid aerodynamic prediction of swept wings via physics-embedded transfer learning</title>
      <link>http://arxiv.org/abs/2409.12711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 基于机器学习的模型在快速获取跨声速扫掠翼流场方面具有潜力，但建立训练数据集的计算成本较高。&lt;h4&gt;2. 提出的方法&lt;/h4&gt;   - 提出一种物理嵌入的迁移学习框架，以高效训练模型。&lt;h4&gt;3. 核心思想&lt;/h4&gt;   - 利用三维翼周围流场与二维截面气动翼流场之间的分析关系。&lt;h4&gt;4. 预训练模型&lt;/h4&gt;   - 使用气动翼样本预训练气动预测模型。&lt;h4&gt;5. 迁移模型&lt;/h4&gt;   - 将气动翼到翼的迁移模型通过少量翼样本进行微调，从而基于每个跨段的二维结果预测三维流场。&lt;h4&gt;6. 理论嵌入&lt;/h4&gt;   - 在确定对应气动翼几何形状和操作条件时嵌入扫掠理论。&lt;h4&gt;7. 操作条件计算&lt;/h4&gt;   - 提出并评估低保真度涡格方法与数据驱动方法，以获取截面气动翼升力系数作为操作条件之一。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 与非迁移模型相比，引入预训练模型使误差减少30%。   - 引入扫掠理论进一步减少误差9%。&lt;h4&gt;9. 数据集规模影响&lt;/h4&gt;   - 减少数据集规模时，使用的翼训练样本少于一半即可达到与非迁移框架相同的误差水平，显著简化模型建立过程。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning-based models provide a promising way to rapidly acquiretransonic swept wing flow fields but suffer from large computational costs inestablishing training datasets. Here, we propose a physics-embedded transferlearning framework to efficiently train the model by leveraging the idea that athree-dimensional flow field around wings can be analyzed with two-dimensionalflow fields around cross-sectional airfoils. An airfoil aerodynamics predictionmodel is pretrained with airfoil samples. Then, an airfoil-to-wing transfermodel is fine-tuned with a few wing samples to predict three-dimensional flowfields based on two-dimensional results on each spanwise cross section. Sweeptheory is embedded when determining the corresponding airfoil geometry andoperating conditions, and to obtain the sectional airfoil lift coefficient,which is one of the operating conditions, the low-fidelity vortex latticemethod and data-driven methods are proposed and evaluated. Compared to anontransfer model, introducing the pretrained model reduces the error by 30%,while introducing sweep theory further reduces the error by 9%. When reducingthe dataset size, less than half of the wing training samples are need to reachthe same error level as the nontransfer framework, which makes establishing themodel much easier.</description>
      <author>example@mail.com (Yunjia Yang, Runze Li, Yufei Zhang, Lu Lu, Haixin Chen)</author>
      <guid isPermaLink="false">2409.12711v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Robust Scene Change Detection Using Visual Foundation Models and Cross-Attention Mechanisms</title>
      <link>http://arxiv.org/abs/2409.16850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 提出一种新颖的场景变化检测方法，旨在有效应对关键挑战，如光照变化、季节性变化和视角差异。&lt;h4&gt;2. 核心技术&lt;/h4&gt;   - 利用视觉基础模型DINOv2的强大特征提取能力。   - 集成全图交叉注意力机制（full-image cross-attention）。&lt;h4&gt;3. 方法论&lt;/h4&gt;   - 为有效学习图像对之间的对应和不对应关系：     - **冻结主干网络**：保持密集基础特征的通用性。     - **采用全图交叉注意力**：更好地处理图像对之间的视角变化。&lt;h4&gt;4. 评估数据集&lt;/h4&gt;   - 在两个基准数据集（VL-CMU-CD和PSCD）及其视角变化版本上进行评估。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 实验结果显示F1-score显著提高，尤其在涉及几何变化的图像对场景中。   - 方法展现出比现有最先进方法更优越的泛化能力，表现出对光度和几何变化的鲁棒性。&lt;h4&gt;6. 适应性&lt;/h4&gt;   - 方法在微调以适应新环境时，展现出更好的整体泛化能力。&lt;h4&gt;7. 消融研究&lt;/h4&gt;   - 详细的消融研究进一步验证了架构中各组件的贡献。&lt;h4&gt;8. 开放源代码&lt;/h4&gt;   - 在论文接受后，将公开源代码，供研究者使用。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel method for scene change detection that leverages therobust feature extraction capabilities of a visual foundational model, DINOv2,and integrates full-image cross-attention to address key challenges such asvarying lighting, seasonal variations, and viewpoint differences. In order toeffectively learn correspondences and mis-correspondences between an image pairfor the change detection task, we propose to a) ``freeze'' the backbone inorder to retain the generality of dense foundation features, and b) employ``full-image'' cross-attention to better tackle the viewpoint variationsbetween the image pair. We evaluate our approach on two benchmark datasets,VL-CMU-CD and PSCD, along with their viewpoint-varied versions. Our experimentsdemonstrate significant improvements in F1-score, particularly in scenariosinvolving geometric changes between image pairs. The results indicate ourmethod's superior generalization capabilities over existing state-of-the-artapproaches, showing robustness against photometric and geometric variations aswell as better overall generalization when fine-tuned to adapt to newenvironments. Detailed ablation studies further validate the contributions ofeach component in our architecture. Source code will be made publicly availableupon acceptance.</description>
      <author>example@mail.com (Chun-Jung Lin, Sourav Garg, Tat-Jun Chin, Feras Dayoub)</author>
      <guid isPermaLink="false">2409.16850v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>ManiNeg: Manifestation-guided Multimodal Pretraining for Mammography Classification</title>
      <link>http://arxiv.org/abs/2409.15745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 乳腺癌对人类健康构成重大威胁。   - 对比学习（contrastive learning）成为从乳腺X光图像中提取关键病变特征的有效方法，为乳腺癌筛查和分析提供了强有力的工具。&lt;h4&gt;2. 对比学习中的关键问题&lt;/h4&gt;   - 负采样（negative sampling）是对比学习的重要方面，选择适当的困难负样本对于保留病变的详细信息至关重要。   - 通常假设提取的特征能够充分捕捉语义内容，每个小批量中自然包含理想的困难负样本。&lt;h4&gt;3. 挑战&lt;/h4&gt;   - 乳腺肿块的特性挑战了这些假设，导致传统方法可能不足以有效选择负样本。&lt;h4&gt;4. 提出的解决方案&lt;/h4&gt;   - 引入ManiNeg，一种新颖的方法，利用“表现”（manifestations）作为代理来挖掘困难负样本。   - “表现”指的是疾病的可观察症状或迹象，为选择困难负样本提供知识驱动的坚实基础。&lt;h4&gt;5. 优势&lt;/h4&gt;   - 该方法具有对模型优化的不变性，促进了高效的采样过程。&lt;h4&gt;6. 数据集开发&lt;/h4&gt;   - 为支持ManiNeg及未来研究，开发了MVKL数据集，包含多视角乳腺X光图像、相关报告、精细标注的表现及病理确认的良恶性结果。&lt;h4&gt;7. 评估结果&lt;/h4&gt;   - 在良性和恶性分类任务中评估ManiNeg，结果表明该方法不仅在单模态和多模态上下文中改善了表征，还展示了跨数据集的泛化能力。&lt;h4&gt;8. 开放资源&lt;/h4&gt;   - MVKL数据集和代码已公开，供社区进一步研究使用，链接为 [ManiNeg GitHub](https://github.com/wxwxwwxxx/ManiNeg)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wxwxwwxxx/manineg&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Breast cancer is a significant threat to human health. Contrastive learninghas emerged as an effective method to extract critical lesion features frommammograms, thereby offering a potent tool for breast cancer screening andanalysis. A crucial aspect of contrastive learning involves negative sampling,where the selection of appropriate hard negative samples is essential fordriving representations to retain detailed information about lesions. Incontrastive learning, it is often assumed that features can sufficientlycapture semantic content, and that each minibatch inherently includes idealhard negative samples. However, the characteristics of breast lumps challengethese assumptions. In response, we introduce ManiNeg, a novel approach thatleverages manifestations as proxies to mine hard negative samples.Manifestations, which refer to the observable symptoms or signs of a disease,provide a knowledge-driven and robust basis for choosing hard negative samples.This approach benefits from its invariance to model optimization, facilitatingefficient sampling. To support ManiNeg and future research endeavors, wedeveloped the MVKL dataset, which includes multi-view mammograms, correspondingreports, meticulously annotated manifestations, and pathologically confirmedbenign-malignant outcomes. We evaluate ManiNeg on the benign and malignantclassification task. Our results demonstrate that ManiNeg not only improvesrepresentation in both unimodal and multimodal contexts but also showsgeneralization across datasets. The MVKL dataset and our codes are publiclyavailable at https://github.com/wxwxwwxxx/ManiNeg.</description>
      <author>example@mail.com (Xujun Li, Xin Wei, Jing Jiang, Danxiang Chen, Wei Zhang, Jinpeng Li)</author>
      <guid isPermaLink="false">2409.15745v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>IPF-HMGNN: A novel integrative prediction framework for metro passenger flow</title>
      <link>http://arxiv.org/abs/2409.14104v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 城市地铁系统的运营和管理依赖于对未来客流的准确预测。   - 尽管利用所有可用信息可能提高预测准确性，但对乘客进出站所收集票种与客流之间的层级关系关注较少。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 提出一种新颖的集成预测框架，名为层级消息传递图神经网络（IPF-HMGNN）。&lt;h4&gt;3. 框架组成&lt;/h4&gt;   - 该框架包含三个模块：     - 初始预测模块     - 任务判断模块     - 层级协调模块&lt;h4&gt;4. 研究方法&lt;/h4&gt;   - 以中国无锡地铁网络为例，研究两种预测方法：     1. **传统预测方法**：模型直接预测车站的客流量。     2. **层级预测方法**：同时考虑票种和车站客流的预测，遵循层级约束（即每种票种的预测客流总和等于车站总客流）。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 在传统预测方法中，IPF-HMGNN显著降低了图神经网络（GNN）预测模型的平均绝对误差（MAE）和均方根误差（RMSE），分别减少49.56%和53.88%。   - 在层级预测方法中，IPF-HMGNN在满足层级约束的同时，实现了MAE和RMSE最大分别降低35.32%和36.18%。&lt;h4&gt;6. 研究意义&lt;/h4&gt;   - 研究结果表明，IPF-HMGNN在客流预测中具有显著优势，能够有效利用票种信息，提高预测准确性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The operation and management of the metro system in urban areas rely onaccurate predictions of future passenger flow. While using all the availableinformation can potentially improve on the accuracy of the flow prediction,there has been little attention to the hierarchical relationship between thetype of tickets collected from the passengers entering/exiting a station andits resulting passenger flow. To this end, we propose a novel IntegrativePrediction Framework with the Hierarchical Message-Passing Graph Neural Network(IPF-HMGNN). The proposed framework consists of three components: initialprediction, task judgment and hierarchical coordination modules. Using theWuxi, China metro network as an example, we study two prediction approaches (i)traditional prediction approach where the model directly predicts passengerflow at the station, and (ii) hierarchical prediction approach where theprediction of ticket type and station passenger flow are performedsimultaneously considering the hierarchical constraints (i.e., the sum ofpredicted passenger flow per ticket type equals the predicted stationaggregated passenger flow). Experimental results indicate that in thetraditional prediction approach, our IPF-HMGNN can significantly reduce themean absolute error (MAE) and root mean square error (RMSE) of the GNNprediction model by 49.56% and 53.88%, respectively. In the hierarchicalprediction approach, IPF-HMGNN can achieve a maximum reduction of 35.32% in MAEand 36.18% in RMSE, while satisfying the hierarchical constraint.</description>
      <author>example@mail.com (Wenbo Lu, Yong Zhang, Hai L. Vu, Jinhua Xu, Peikun Li)</author>
      <guid isPermaLink="false">2409.14104v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Recognition of Harmful Phytoplankton from Microscopic Images using Deep Learning</title>
      <link>http://arxiv.org/abs/2409.12900v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 监测浮游植物分布，尤其是有害的浮游植物，对保护水生生态系统、调节全球气候和环境保护至关重要。&lt;h4&gt;2. 传统方法的局限性&lt;/h4&gt;   - 传统监测方法通常耗时、成本高、易出错，并且不适合大规模应用，突显了需要准确高效的自动化系统。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本研究评估了几种先进的卷积神经网络（CNN）模型，包括ResNet、ResNeXt、DenseNet和EfficientNet，旨在从显微图像中分类十一种有害浮游植物属。&lt;h4&gt;4. 方法&lt;/h4&gt;   - 使用三种迁移学习方法进行分类：线性探测（linear probing）、微调（fine-tuning）和组合方法。&lt;h4&gt;5. 主要发现&lt;/h4&gt;   - ResNet-50在微调方法下表现最佳，准确率达到96.97%。   - 结果显示，模型在区分四种具有相似形态特征的有害浮游植物类型时遇到了困难。&lt;h4&gt;6. 研究意义&lt;/h4&gt;   - 研究结果为开发更高效的自动化监测系统提供了基础，特别是在识别有害浮游植物方面的应用潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monitoring plankton distribution, particularly harmful phytoplankton, isvital for preserving aquatic ecosystems, regulating the global climate, andensuring environmental protection. Traditional methods for monitoring are oftentime-consuming, expensive, error-prone, and unsuitable for large-scaleapplications, highlighting the need for accurate and efficient automatedsystems. In this study, we evaluate several state-of-the-art CNN models,including ResNet, ResNeXt, DenseNet, and EfficientNet, using three transferlearning approaches: linear probing, fine-tuning, and a combined approach, toclassify eleven harmful phytoplankton genera from microscopic images. The bestperformance was achieved by ResNet-50 using the fine-tuning approach, with anaccuracy of 96.97%. The results also revealed that the models struggled todifferentiate between four harmful phytoplankton types with similarmorphological features.</description>
      <author>example@mail.com (Aymane Khaldi, Rohaifa Khaldi)</author>
      <guid isPermaLink="false">2409.12900v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Towards Underwater Camouflaged Object Tracking: An Experimental Evaluation of SAM and SAM 2</title>
      <link>http://arxiv.org/abs/2409.16902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint. Work in Progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 过去十年，视觉目标跟踪取得了显著进展，主要得益于大型训练数据集的可用性。   - 现有的跟踪数据集主要集中在开放空气场景，限制了水下环境目标跟踪的发展。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 提出第一款大规模水下伪装目标跟踪数据集，命名为UW-COT，旨在填补这一空白。&lt;h4&gt;3. 方法与评估&lt;/h4&gt;   - 基于UW-COT数据集，进行多种先进视觉目标跟踪方法和最新图像与视频分割技术的实验评估。   - 特别比较了Segment Anything Model (SAM)及其更新版本SAM 2在困难水下环境中的表现。&lt;h4&gt;4. 主要发现&lt;/h4&gt;   - 研究结果显示，SAM 2在处理水下伪装目标的复杂性方面相比于SAM有显著提升。   - 最新的视频分割基础模型SAM 2相较于当前先进的视觉目标跟踪方法，展现了显著的优势。&lt;h4&gt;5. 研究意义&lt;/h4&gt;   - 这些发现为水下场景更有效的跟踪技术开发提供了宝贵的见解。&lt;h4&gt;6. 数据集获取&lt;/h4&gt;   - UW-COT数据集将在指定链接上提供访问。通过这些要点，可以清晰地理解研究的背景、目标、方法、主要发现及其重要性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/983632847/awesome-multimodal-object-tracking&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over the past decade, significant progress has been made in visual objecttracking, largely due to the availability of large-scale training datasets.However, existing tracking datasets are primarily focused on open-airscenarios, which greatly limits the development of object tracking inunderwater environments. To address this issue, we take a step forward byproposing the first large-scale underwater camouflaged object tracking dataset,namely UW-COT. Based on the proposed dataset, this paper presents anexperimental evaluation of several advanced visual object tracking methods andthe latest advancements in image and video segmentation. Specifically, wecompare the performance of the Segment Anything Model (SAM) and its updatedversion, SAM 2, in challenging underwater environments. Our findings highlightthe improvements in SAM 2 over SAM, demonstrating its enhanced capability tohandle the complexities of underwater camouflaged objects. Compared to currentadvanced visual object tracking methods, the latest video segmentationfoundation model SAM 2 also exhibits significant advantages, providing valuableinsights into the development of more effective tracking technologies forunderwater scenarios. The dataset will be accessible at\color{magenta}{https://github.com/983632847/Awesome-Multimodal-Object-Tracking}.</description>
      <author>example@mail.com (Chunhui Zhang, Li Liu, Guanjie Huang, Hao Wen, Xi Zhou, Yanfeng Wang)</author>
      <guid isPermaLink="false">2409.16902v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>BranchPoseNet: Characterizing tree branching with a deep learning-based pose estimation approach</title>
      <link>http://arxiv.org/abs/2409.14755v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目的&lt;/h4&gt;   - 本文提出了一种自动化流程，用于检测激光扫描数据中的树轮。&lt;h4&gt;2. 重要性&lt;/h4&gt;   - 准确的树轮检测能提供树木生长模式、木材质量的宝贵见解，并有潜力作为生物识别标记，跟踪树木在林业价值链中的信息。&lt;h4&gt;3. 工作流程&lt;/h4&gt;   - 该流程处理点云数据，生成截面图像，随后用于识别树轮和树干沿线的关键点。&lt;h4&gt;4. 测试数据&lt;/h4&gt;   - 方法在一组破坏性采样的单棵树的数据集上进行测试，这些树的树轮位于已砍伐树木的树干上。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 结果显示出强大的潜力，成功地识别了树轮，并准确计算了关键结构指标，从单棵树的点云中揭示了新的见解和更深层次的信息。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/stefp/whorl_pose_detector&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an automated pipeline for detecting tree whorls inproximally laser scanning data using a pose-estimation deep learning model.Accurate whorl detection provides valuable insights into tree growth patterns,wood quality, and offers potential for use as a biometric marker to track treesthroughout the forestry value chain. The workflow processes point cloud data tocreate sectional images, which are subsequently used to identify keypointsrepresenting tree whorls and branches along the stem. The method was tested ona dataset of destructively sampled individual trees, where the whorls werelocated along the stems of felled trees. The results demonstrated strongpotential, with accurate identification of tree whorls and precise calculationof key structural metrics, unlocking new insights and deeper levels ofinformation from individual tree point clouds.</description>
      <author>example@mail.com (Stefano Puliti, Carolin Fischer, Rasmus Astrup)</author>
      <guid isPermaLink="false">2409.14755v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification</title>
      <link>http://arxiv.org/abs/2409.15974v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Interspeech 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 跨年龄说话人验证（CASV）引起了越来越多的研究兴趣，但现有的说话人验证系统在CASV中表现不佳，主要由于年龄导致的声音个体差异。&lt;h4&gt;2. 提出的方法&lt;/h4&gt;   - 本文提出了一种基于互信息（MI）最小化的解耦表示学习框架，用于CASV。&lt;h4&gt;3. 模型训练&lt;/h4&gt;   - 训练一个主干模型，以将与身份和年龄相关的嵌入从说话人信息中解耦出来。&lt;h4&gt;4. 互信息估计&lt;/h4&gt;   - 训练一个MI估计器，通过MI最小化来减少与年龄和身份相关的嵌入之间的相关性，从而生成年龄不变的说话人嵌入。&lt;h4&gt;5. 年龄感知损失函数&lt;/h4&gt;   - 利用正负样本之间的年龄差距，提出一种年龄感知的MI最小化损失函数，使主干模型更加关注具有较大年龄差异的声音变化。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实验结果表明，所提出的方法在Vox-CA的多个跨年龄测试集上优于其他方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; There has been an increasing research interest in cross-age speakerverification~(CASV). However, existing speaker verification systems performpoorly in CASV due to the great individual differences in voice caused byaging. In this paper, we propose a disentangled representation learningframework for CASV based on mutual information~(MI) minimization. In ourmethod, a backbone model is trained to disentangle the identity- andage-related embeddings from speaker information, and an MI estimator is trainedto minimize the correlation between age- and identity-related embeddings via MIminimization, resulting in age-invariant speaker embeddings. Furthermore, byusing the age gaps between positive and negative samples, we propose anaging-aware MI minimization loss function that allows the backbone model tofocus more on the vocal changes with large age gaps. Experimental results showthat the proposed method outperforms other methods on multiple Cross-Age testsets of Vox-CA.</description>
      <author>example@mail.com (Fengrun Zhang, Wangjin Zhou, Yiming Liu, Wang Geng, Yahui Shan, Chen Zhang)</author>
      <guid isPermaLink="false">2409.15974v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>TabGraphs: A Benchmark and Strong Baselines for Learning on Graphs with Tabular Node Features</title>
      <link>http://arxiv.org/abs/2409.14500v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 表格机器学习在工业和科学领域中非常重要，通常将表格的行作为独立的数据样本处理。&lt;h4&gt;2. 额外信息的利用&lt;/h4&gt;   - 有时可利用行之间的关系信息来提升预测性能，这种信息可以自然地用图来建模。&lt;h4&gt;3. 模型评估问题&lt;/h4&gt;   - 现有的图机器学习模型通常在具有同质节点特征的数据集上进行评估，而与表格数据中的异质数值和分类特征相去甚远。&lt;h4&gt;4. 数据差异&lt;/h4&gt;   - 表格和图机器学习研究中使用的数据存在关键差异，这使得难以理解图模型如何成功转移到表格数据上。&lt;h4&gt;5. 新基准的提出&lt;/h4&gt;   - 提出了一个包含异质表格节点特征和现实预测任务的多样图的新基准，以填补这一空白。&lt;h4&gt;6. 模型评估&lt;/h4&gt;   - 通过这个基准评估了一系列模型，包括文献中之前被忽视的简单方法。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 实验表明，图神经网络（GNNs）在表格数据上通常能提高预测性能，但标准的表格模型也可以通过简单的特征预处理适应图数据，有时能与GNNs竞争甚至超越它们。&lt;h4&gt;8. 研究启示&lt;/h4&gt;   - 基于实证研究，向表格和图机器学习领域的研究人员和从业者提供了见解。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yandex-research/tabgraphs&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular machine learning is an important field for industry and science. Inthis field, table rows are usually treated as independent data samples, butadditional information about relations between them is sometimes available andcan be used to improve predictive performance. Such information can benaturally modeled with a graph, thus tabular machine learning may benefit fromgraph machine learning methods. However, graph machine learning models aretypically evaluated on datasets with homogeneous node features, which havelittle in common with heterogeneous mixtures of numerical and categoricalfeatures present in tabular datasets. Thus, there is a critical differencebetween the data used in tabular and graph machine learning studies, which doesnot allow one to understand how successfully graph models can be transferred totabular data. To bridge this gap, we propose a new benchmark of diverse graphswith heterogeneous tabular node features and realistic prediction tasks. We usethis benchmark to evaluate a vast set of models, including simple methodspreviously overlooked in the literature. Our experiments show that graph neuralnetworks (GNNs) can indeed often bring gains in predictive performance fortabular data, but standard tabular models also can be adapted to work withgraph data by using simple feature preprocessing, which sometimes enables themto compete with and even outperform GNNs. Based on our empirical study, weprovide insights for researchers and practitioners in both tabular and graphmachine learning fields.</description>
      <author>example@mail.com (Gleb Bazhenov, Oleg Platonov, Liudmila Prokhorenkova)</author>
      <guid isPermaLink="false">2409.14500v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Spatial-Temporal Mixture-of-Graph-Experts for Multi-Type Crime Prediction</title>
      <link>http://arxiv.org/abs/2409.15764v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着各种犯罪类型继续威胁公共安全和经济发展，预测多种犯罪的发生变得愈发重要，以便有效预防。&lt;h4&gt;2. 现有问题&lt;/h4&gt;   - 现有研究大多忽视不同犯罪类别的异质性，并未解决空间分布不平衡的问题。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 提出了一种空间-时间混合图专家框架（ST-MoGE），用于集体多类型犯罪预测。&lt;h4&gt;4. 模型增强&lt;/h4&gt;   - 引入注意力门控混合图专家模块（MGE），以捕捉各犯罪类别的独特和共享模式，从而提高识别多样空间-时间依赖的能力。&lt;h4&gt;5. 对比学习&lt;/h4&gt;   - 提出交叉专家对比学习（CECL）以更新MGEs，强制每个专家专注于特定模式建模，减少混合和冗余。&lt;h4&gt;6. 解决不平衡问题&lt;/h4&gt;   - 采用分层自适应损失重加权（HALR）方法，消除数据稀缺区域的偏见和学习不足。&lt;h4&gt;7. 实验评估&lt;/h4&gt;   - 在两个真实世界的犯罪数据集上进行全面实验，并与十二个先进基线进行比较。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 实验结果显示，所提出的方法在效果上优于现有方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As various types of crime continue to threaten public safety and economicdevelopment, predicting the occurrence of multiple types of crimes becomesincreasingly vital for effective prevention measures. Although extensiveefforts have been made, most of them overlook the heterogeneity of differentcrime categories and fail to address the issue of imbalanced spatialdistribution. In this work, we propose a Spatial-TemporalMixture-of-Graph-Experts (ST-MoGE) framework for collective multiple-type crimeprediction. To enhance the model's ability to identify diverse spatial-temporaldependencies and mitigate potential conflicts caused by spatial-temporalheterogeneity of different crime categories, we introduce an attentive-gatedMixture-of-Graph-Experts (MGEs) module to capture the distinctive and sharedcrime patterns of each crime category. Then, we propose Cross-ExpertContrastive Learning(CECL) to update the MGEs and force each expert to focus onspecific pattern modeling, thereby reducing blending and redundancy.Furthermore, to address the issue of imbalanced spatial distribution, wepropose a Hierarchical Adaptive Loss Re-weighting (HALR) approach to eliminatebiases and insufficient learning of data-scarce regions. To evaluate theeffectiveness of our methods, we conduct comprehensive experiments on tworeal-world crime datasets and compare our results with twelve advancedbaselines. The experimental results demonstrate the superiority of our methods.</description>
      <author>example@mail.com (Ziyang Wu, Fan Liu, Jindong Han, Yuxuan Liang, Hao Liu)</author>
      <guid isPermaLink="false">2409.15764v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Bilateral Sharpness-Aware Minimization for Flatter Minima</title>
      <link>http://arxiv.org/abs/2409.13173v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - Sharpness-Aware Minimization (SAM) 通过减少最大锐度（Max-Sharpness, MaxS）来增强模型的泛化能力。&lt;h4&gt;2. 现有问题&lt;/h4&gt;   - 实证研究发现，SAM在增强泛化能力时面临“平坦性指标问题”（Flatness Indicator Problem, FIP），只考虑梯度上升方向的平坦性，导致下一个最小化区域不够平坦。&lt;h4&gt;3. 改进建议&lt;/h4&gt;   - 引入一个更好的平坦性指标（Flatness Indicator, FI），以提高神经网络的泛化能力。   - 利用当前权重周围邻域内训练损失与最小损失之间的差异，定义为最小锐度（Min-Sharpness, MinS）。&lt;h4&gt;4. 新方法&lt;/h4&gt;   - 通过将MaxS和MinS结合，创建了一个改进的FI，以指示优化过程中更平坦的方向。&lt;h4&gt;5. 提出的算法&lt;/h4&gt;   - 将改进的FI与SAM结合，提出了双边SAM（Bilateral SAM, BSAM），旨在找到比SAM更平坦的最小值。&lt;h4&gt;6. 理论分析&lt;/h4&gt;   - 理论分析证明，BSAM能够收敛到局部最小值。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 大量实验表明，BSAM在多种任务（如分类、迁移学习、人类姿态估计和网络量化）中，相较于传统SAM表现出更优越的泛化性能和鲁棒性。&lt;h4&gt;8. 代码可用性&lt;/h4&gt;   - 相关代码已公开，访问链接为：[BSAM GitHub Repository](https://github.com/ajiaaa/BSAM)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sharpness-Aware Minimization (SAM) enhances generalization by reducing aMax-Sharpness (MaxS). Despite the practical success, we empirically found thatthe MAxS behind SAM's generalization enhancements face the "Flatness IndicatorProblem" (FIP), where SAM only considers the flatness in the direction ofgradient ascent, resulting in a next minimization region that is notsufficiently flat. A better Flatness Indicator (FI) would bring a bettergeneralization of neural networks. Because SAM is a greedy search method innature. In this paper, we propose to utilize the difference between thetraining loss and the minimum loss over the neighborhood surrounding thecurrent weight, which we denote as Min-Sharpness (MinS). By merging MaxS andMinS, we created a better FI that indicates a flatter direction during theoptimization. Specially, we combine this FI with SAM into the proposedBilateral SAM (BSAM) which finds a more flatter minimum than that of SAM. Thetheoretical analysis proves that BSAM converges to local minima. Extensiveexperiments demonstrate that BSAM offers superior generalization performanceand robustness compared to vanilla SAM across various tasks, i.e.,classification, transfer learning, human pose estimation, and networkquantization. Code is publicly available at: https://github.com/ajiaaa/BSAM.</description>
      <author>example@mail.com (Jiaxin Deng, Junbiao Pang, Baochang Zhang, Qingming Huang)</author>
      <guid isPermaLink="false">2409.13173v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Wavelet Scattering Network for image inpainting detection</title>
      <link>http://arxiv.org/abs/2409.17023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 图像修复工具的快速发展，特别是去除伪影的工具，使得数字图像操控变得异常容易。&lt;h4&gt;2. 研究目的&lt;/h4&gt;   - 提出多种创新方法，基于低级噪声分析检测图像修复伪造。&lt;h4&gt;3. 方法概述&lt;/h4&gt;   - 将双树复小波变换（DT-CWT）用于特征提取，与卷积神经网络（CNN）结合，进行伪造区域的检测与定位。   - 采用创新的纹理分割与噪声方差估计的结合。&lt;h4&gt;4. DT-CWT的优势&lt;/h4&gt;   - 提供移位不变性，增强对细微操控的鲁棒性。   - 方向选择性强，能够在特定频率带和方向上检测到修复过程中引入的细微伪影。&lt;h4&gt;5. 网络架构评估&lt;/h4&gt;   - 评估并提出多种神经网络架构以提高检测效果。&lt;h4&gt;6. 融合检测模块&lt;/h4&gt;   - 提出一个融合检测模块，将纹理分析与噪声方差估计结合，以识别伪造区域。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 与最先进的方法进行基准测试，显示出在所有引用的替代方法中具有优越的性能。&lt;h4&gt;8. 可用资源&lt;/h4&gt;   - 训练代码（包括预训练模型权重）及数据集将可在GitHub上获取：[GitHub Repository](https://github.com/jmaba/Deep-dual-tree-complex-neural-network-for-image-inpainting-detection)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of image inpainting tools, especially those aimed atremoving artifacts, has made digital image manipulation alarmingly accessible.This paper proposes several innovative ideas for detecting inpainting forgeriesbased on low level noise analysis by combining Dual-Tree Complex WaveletTransform (DT-CWT) for feature extraction with convolutional neural networks(CNN) for forged area detection and localization, and lastly by employing aninnovative combination of texture segmentation with noise variance estimations.The DT-CWT offers significant advantages due to its shift-invariance, enhancingits robustness against subtle manipulations during the inpainting process.Furthermore, its directional selectivity allows for the detection of subtleartifacts introduced by inpainting within specific frequency bands andorientations. Various neural network architectures were evaluated and proposed.Lastly, we propose a fusion detection module that combines texture analysiswith noise variance estimation to give the forged area. Our approach wasbenchmarked against state-of-the-art methods and demonstrated superiorperformance over all cited alternatives. The training code (with pretrainedmodel weights) as long as the dataset will be available athttps://github.com/jmaba/Deep-dual-tree-complex-neural-network-for-image-inpainting-detection</description>
      <author>example@mail.com (Barglazan Adrian-Alin, Brad Remus)</author>
      <guid isPermaLink="false">2409.17023v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Improving Adversarial Robustness for 3D Point Cloud Recognition at Test-Time through Purified Self-Training</title>
      <link>http://arxiv.org/abs/2409.14940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 3D点云识别在许多现实应用中具有重要作用，但3D点云深度学习模型容易受到对抗性攻击的影响。&lt;h4&gt;2. 现有问题&lt;/h4&gt;   - 尽管对抗性训练已被广泛应用于提高模型的鲁棒性，但其对新出现的攻击可能效果不佳。   - 采用对抗性净化的方法，可以利用生成模型减轻对抗性攻击的影响。&lt;h4&gt;3. 挑战&lt;/h4&gt;   - 净化方法需要对净化后的样本重新训练分类器，这会增加计算开销。   - 在更现实的场景中，测试样本是以流式方式到达的，对抗样本与干净样本混合存在，这使得处理更加复杂。&lt;h4&gt;4. 研究目标&lt;/h4&gt;   - 探索在观察到测试样本后动态更新模型的可能性，以应对这些挑战。&lt;h4&gt;5. 提出的方法&lt;/h4&gt;   - 提出了一种测试时净化自我训练策略，旨在实现动态更新。   - 引入自适应阈值和特征分布对齐，以提高自我训练的鲁棒性。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 在不同对抗性攻击下的广泛实验结果表明，所提方法与基于净化的方法相辅相成，有助于处理不断变化的对抗性攻击，尤其是在测试数据流中。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recognizing 3D point cloud plays a pivotal role in many real-worldapplications. However, deploying 3D point cloud deep learning model isvulnerable to adversarial attacks. Despite many efforts into developing robustmodel by adversarial training, they may become less effective against emergingattacks. This limitation motivates the development of adversarial purificationwhich employs generative model to mitigate the impact of adversarial attacks.In this work, we highlight the remaining challenges from two perspectives.First, the purification based method requires retraining the classifier onpurified samples which introduces additional computation overhead. Moreover, ina more realistic scenario, testing samples arrives in a streaming fashion andadversarial samples are not isolated from clean samples. These challengesmotivates us to explore dynamically update model upon observing testingsamples. We proposed a test-time purified self-training strategy to achievethis objective. Adaptive thresholding and feature distribution alignment areintroduced to improve the robustness of self-training. Extensive results ondifferent adversarial attacks suggest the proposed method is complementary topurification based method in handling continually changing adversarial attackson the testing data stream.</description>
      <author>example@mail.com (Jinpeng Lin, Xulei Yang, Tianrui Li, Xun Xu)</author>
      <guid isPermaLink="false">2409.14940v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Representation Learning with Augmentations of Continuous Training Data Improves the Feel and Performance of Myoelectric Control</title>
      <link>http://arxiv.org/abs/2409.16015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Neural Systems and Rehabilitation
  Engineering&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 传统的基于模式识别的肌电控制通常使用静态或斜坡收缩进行训练，但这种方法无法捕捉现实世界运动的动态特性。&lt;h4&gt;2. 研究目的&lt;/h4&gt;   - 研究动态数据训练分类器的好处，特别是涵盖不同运动类别之间过渡的连续动态数据。&lt;h4&gt;3. 方法&lt;/h4&gt;   - 使用传统分类器（线性判别分析，LDA）和深度学习分类器（长短期记忆网络，LSTM），比较它们在不同数据集上的表现：     - 使用斜坡数据训练     - 使用连续动态数据训练     - 使用自监督学习技术（VICReg）增强的连续动态数据训练&lt;h4&gt;4. 实验评估&lt;/h4&gt;   - 通过在线Fitts’ Law测试，评估20名参与者对每个分类器的可用性和有效性。&lt;h4&gt;5. 主要结果&lt;/h4&gt;   - 时间模型，尤其是使用连续动态数据训练的LSTM，显著优于传统方法。   - VICReg预训练进一步提升了在线性能和用户体验。&lt;h4&gt;6. 用户反馈&lt;/h4&gt;   - 用户反馈强调了平滑、无抖动的控制以及在不同运动类别中一致性能的重要性。&lt;h4&gt;7. 研究意义&lt;/h4&gt;   - 研究结果突显了连续动态数据和自监督学习在提升基于表面肌电信号的肌电控制中的潜力，为开发更直观和用户友好的假肢设备奠定了基础。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pattern recognition-based myoelectric control is traditionally trained withstatic or ramp contractions, but this fails to capture the dynamic nature ofreal-world movements. This study investigated the benefits of trainingclassifiers with continuous dynamic data, encompassing transitions betweenvarious movement classes. We employed both conventional (LDA) and deep learning(LSTM) classifiers, comparing their performance when trained with ramp data,continuous dynamic data, and continuous dynamic data augmented with aself-supervised learning technique (VICReg). An online Fitts' Law test with$20$ participants evaluated the usability and effectiveness of each classifier.Results demonstrate that temporal models, particularly LSTMs trained withcontinuous dynamic data, significantly outperformed traditional approaches.Furthermore, VICReg pre-training led to additional improvements in onlineperformance and user experience. Qualitative feedback highlighted theimportance of smooth, jitter-free control and consistent performance acrossmovement classes. These findings underscore the potential of continuous dynamicdata and self-supervised learning for advancing sEMG-PR-based myoelectriccontrol, paving the way for more intuitive and user-friendly prostheticdevices.</description>
      <author>example@mail.com (Shriram Tallam Puranam Raghu, Dawn MacIsaac, Erik Scheme)</author>
      <guid isPermaLink="false">2409.16015v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>FastGL: A GPU-Efficient Framework for Accelerating Sampling-Based GNN Training at Large Scale</title>
      <link>http://arxiv.org/abs/2409.14939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ASPLOS 2024 fall cycle after major revision&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 图神经网络（GNNs）在非欧几里得图数据上表现优越，已在各种图相关任务中取得突破性成果。&lt;h4&gt;2. 现有问题&lt;/h4&gt;   - 现有的基于采样的训练框架在处理包含数十亿节点和边的大型图时，效率仍然有限。   - 主要瓶颈存在于采样训练的三个阶段：子图采样、内存输入输出（IO）和计算。&lt;h4&gt;3. 提出的解决方案&lt;/h4&gt;   - 提出FastGL，一个GPU高效框架，旨在通过同时优化上述三个阶段来加速大规模GNN的采样训练。&lt;h4&gt;4. 优化策略&lt;/h4&gt;   - **Match-Reorder策略**：利用图结构的内在重叠性，减少数据流量，加速内存IO，而不增加GPU内存开销。   - **Memory-Aware计算方法**：利用GPU内存的层次特性，降低计算过程中的不规则数据访问。   - **Fused-Map方法**：减少采样过程中的同步开销。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 实验表明，FastGL在速度上相较于现有最先进框架（PyG、DGL和GNNLab）分别实现了11.8倍、2.2倍和1.5倍的加速。&lt;h4&gt;6. 代码可用性&lt;/h4&gt;   - 相关代码可在GitHub上获取：[FastGL GitHub Repository](https://github.com/a1bc2def6g/fastgl-ae)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3622781.3674167&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/a1bc2def6g/fastgl-ae&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown great superiority on non-Euclideangraph data, achieving ground-breaking performance on various graph-relatedtasks. As a practical solution to train GNN on large graphs with billions ofnodes and edges, the sampling-based training is widely adopted by existingtraining frameworks. However, through an in-depth analysis, we observe that theefficiency of existing sampling-based training frameworks is still limited dueto the key bottlenecks lying in all three phases of sampling-based training,i.e., subgraph sample, memory IO, and computation. To this end, we proposeFastGL, a GPU-efficient Framework for accelerating sampling-based training ofGNN at Large scale by simultaneously optimizing all above three phases, takinginto account both GPU characteristics and graph structure. Specifically, byexploiting the inherent overlap within graph structures, FastGL develops theMatch-Reorder strategy to reduce the data traffic, which accelerates the memoryIO without incurring any GPU memory overhead. Additionally, FastGL leverages aMemory-Aware computation method, harnessing the GPU memory's hierarchicalnature to mitigate irregular data access during computation. FastGL furtherincorporates the Fused-Map approach aimed at diminishing the synchronizationoverhead during sampling. Extensive experiments demonstrate that FastGL canachieve an average speedup of 11.8x, 2.2x and 1.5x over the state-of-the-artframeworks PyG, DGL, and GNNLab, respectively.Our code is available athttps://github.com/a1bc2def6g/fastgl-ae.</description>
      <author>example@mail.com (Zeyu Zhu, Peisong Wang, Qinghao Hu, Gang Li, Xiaoyao Liang, Jian Cheng)</author>
      <guid isPermaLink="false">2409.14939v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Towards Universal Large-Scale Foundational Model for Natural Gas Demand Forecasting</title>
      <link>http://arxiv.org/abs/2409.15794v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 在全球能源战略中，准确的天然气需求预测对有效资源配置和运营规划至关重要。&lt;h4&gt;2. 传统方法局限&lt;/h4&gt;   - 传统预测方法难以应对多样化行业和商业领域中日益复杂和变化的天然气消费模式。&lt;h4&gt;3. 新模型提出&lt;/h4&gt;   - 提出第一个专门针对天然气需求预测的基础模型（foundation model），旨在克服传统方法的局限性。&lt;h4&gt;4. 基础模型优势&lt;/h4&gt;   - 基础模型能够跨任务和数据集进行泛化，避免了需要为不同客户群体建立单独模型的问题。&lt;h4&gt;5. 对比学习应用&lt;/h4&gt;   - 利用对比学习提高预测准确性，特别是解决历史消费数据中的噪声问题和相似数据样本的潜在误分类。&lt;h4&gt;6. 噪声过滤技术&lt;/h4&gt;   - 在对比学习框架中集成高级噪声过滤技术，以提升学习表示的质量，从而提高预测的准确性。&lt;h4&gt;7. 行业特定微调&lt;/h4&gt;   - 模型在预训练期间进行行业特定的微调，更好地捕捉各行业天然气消费的独特特征。&lt;h4&gt;8. 实验验证&lt;/h4&gt;   - 使用来自ENN Group的大规模数据集进行广泛实验，数据涵盖超过10,000个工业、商业和福利相关客户的多个地区。&lt;h4&gt;9. 结果表现&lt;/h4&gt;   - 模型在现有最先进方法中表现优越，相较于最佳可用模型，均方误差（MSE）提升3.68%，平均绝对缩放误差（MASE）提升6.15%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the context of global energy strategy, accurate natural gas demandforecasting is crucial for ensuring efficient resource allocation andoperational planning. Traditional forecasting methods struggle to cope with thegrowing complexity and variability of gas consumption patterns across diverseindustries and commercial sectors. To address these challenges, we propose thefirst foundation model specifically tailored for natural gas demandforecasting. Foundation models, known for their ability to generalize acrosstasks and datasets, offer a robust solution to the limitations of traditionalmethods, such as the need for separate models for different customer segmentsand their limited generalization capabilities. Our approach leveragescontrastive learning to improve prediction accuracy in real-world scenarios,particularly by tackling issues such as noise in historical consumption dataand the potential misclassification of similar data samples, which can lead todegradation in the quaility of the representation and thus the accuracy ofdownstream forecasting tasks. By integrating advanced noise filteringtechniques within the contrastive learning framework, our model enhances thequality of learned representations, leading to more accurate predictions.Furthermore, the model undergoes industry-specific fine-tuning duringpretraining, enabling it to better capture the unique characteristics of gasconsumption across various sectors. We conducted extensive experiments using alarge-scale dataset from ENN Group, which includes data from over 10,000industrial, commercial, and welfare-related customers across multiple regions.Our model outperformed existing state-of-the-art methods, demonstrating arelative improvement in MSE by 3.68\% and in MASE by 6.15\% compared to thebest available model.</description>
      <author>example@mail.com (Xinxing Zhou, Jiaqi Ye, Shubao Zhao, Ming Jin, Zhaoxiang Hou, Chengyi Yang, Zengxiang Li, Yanlong Wen, Xiaojie Yuan)</author>
      <guid isPermaLink="false">2409.15794v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Overcoming Data Limitations in Internet Traffic Forecasting: LSTM Models with Transfer Learning and Wavelet Augmentation</title>
      <link>http://arxiv.org/abs/2409.13181v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 Figures, Submitted to Elsevier Journal of Computer
  Communication&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 小型互联网服务提供商（ISP）网络中的有效流量预测面临数据可用性有限的挑战。&lt;h4&gt;2. 研究方法&lt;/h4&gt;   - 采用迁移学习和数据增强技术，使用两种基于LSTM的模型：LSTMSeq2Seq和LSTMSeq2SeqAtn。   - 模型最初在Juniper Networks提供的全面数据集上训练，随后应用于较小的数据集。&lt;h4&gt;3. 数据集特点&lt;/h4&gt;   - 数据集代表真实的互联网流量遥测，提供不同网络领域的多样化流量模式见解。&lt;h4&gt;4. 模型表现&lt;/h4&gt;   - 单步预测效果良好，但多步预测特别是在长期准确性上面临挑战。   - 在较小的数据集中，LSTMSeq2Seq通常优于LSTMSeq2SeqAtn，表明更高的模型复杂性不一定带来更好的性能。&lt;h4&gt;5. 领域差异&lt;/h4&gt;   - 模型的有效性在不同网络领域之间有所不同，反映出独特流量特征的影响。&lt;h4&gt;6. 数据增强&lt;/h4&gt;   - 使用离散小波变换进行数据增强，显著提高了模型性能，尤其是在短期预测中。&lt;h4&gt;7. 模型一致性分析&lt;/h4&gt;   - 分析了模型的变异性和一致性，发现LSTMSeq2SeqAtn的注意力机制在短期预测中提供了更好的一致性，但在长期预测中变异性更大。&lt;h4&gt;8. 研究结论&lt;/h4&gt;   - 结果强调了不同建模方法在流量预测中的优缺点。   - 总体而言，研究强调了迁移学习和数据增强在提升小型ISP网络流量预测模型准确性方面的重要性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective internet traffic prediction in smaller ISP networks is challengedby limited data availability. This paper explores this issue using transferlearning and data augmentation techniques with two LSTM-based models,LSTMSeq2Seq and LSTMSeq2SeqAtn, initially trained on a comprehensive datasetprovided by Juniper Networks and subsequently applied to smaller datasets. Thedatasets represent real internet traffic telemetry, offering insights intodiverse traffic patterns across different network domains. Our study revealedthat while both models performed well in single-step predictions, multi-stepforecasts were challenging, particularly in terms of long-term accuracy. Insmaller datasets, LSTMSeq2Seq generally outperformed LSTMSeq2SeqAtn, indicatingthat higher model complexity does not necessarily translate to betterperformance. The models' effectiveness varied across different network domains,reflecting the influence of distinct traffic characteristics. To address datascarcity, Discrete Wavelet Transform was used for data augmentation, leading tosignificant improvements in model performance, especially in shorter-termforecasts. Our analysis showed that data augmentation is crucial in scenarioswith limited data. Additionally, the study included an analysis of the models'variability and consistency, with attention mechanisms in LSTMSeq2SeqAtnproviding better short-term forecasting consistency but greater variability inlonger forecasts. The results highlight the benefits and limitations ofdifferent modeling approaches in traffic prediction. Overall, this researchunderscores the importance of transfer learning and data augmentation inenhancing the accuracy of traffic prediction models, particularly in smallerISP networks with limited data availability.</description>
      <author>example@mail.com (Sajal Saha, Anwar Haque, Greg Sidebottom)</author>
      <guid isPermaLink="false">2409.13181v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not</title>
      <link>http://arxiv.org/abs/2409.17044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 大型语言模型（LLM）的卓越性能促使研究人员探索其在各种任务和输入模态中的应用。&lt;h4&gt;2. S2T任务现状&lt;/h4&gt;   - 在语音转文本（S2T）任务中，新的解决方案是通过适配模块将语音基础模型（SFM）编码器的输出投影到LLM嵌入空间。&lt;h4&gt;3. 研究空白&lt;/h4&gt;   - 目前尚未研究下游任务性能如何依赖于各个组件（SFM、适配器、LLM），以及适配器的最佳设计是否取决于所选的SFM和LLM。&lt;h4&gt;4. 实验设计&lt;/h4&gt;   - 评估5个适配模块、2个LLM（Mistral和Llama）以及2个SFM（Whisper和SeamlessM4T）在两个常见的S2T任务上的组合：自动语音识别和语音翻译。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 结果显示，SFM在下游性能中起着关键作用，而适配器的选择具有中等影响，并依赖于所用的SFM和LLM。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The remarkable performance achieved by Large Language Models (LLM) has drivenresearch efforts to leverage them for a wide range of tasks and inputmodalities. In speech-to-text (S2T) tasks, the emerging solution consists ofprojecting the output of the encoder of a Speech Foundational Model (SFM) intothe LLM embedding space through an adapter module. However, no work has yetinvestigated how much the downstream-task performance depends on each component(SFM, adapter, LLM) nor whether the best design of the adapter depends on thechosen SFM and LLM. To fill this gap, we evaluate the combination of 5 adaptermodules, 2 LLMs (Mistral and Llama), and 2 SFMs (Whisper and SeamlessM4T) ontwo widespread S2T tasks, namely Automatic Speech Recognition and SpeechTranslation. Our results demonstrate that the SFM plays a pivotal role indownstream performance, while the adapter choice has moderate impact anddepends on the SFM and LLM.</description>
      <author>example@mail.com (Francesco Verdini, Pierfrancesco Melucci, Stefano Perna, Francesco Cariaggi, Marco Gaido, Sara Papi, Szymon Mazurek, Marek Kasztelnik, Luisa Bentivogli, Sébastien Bratières, Paolo Merialdo, Simone Scardapane)</author>
      <guid isPermaLink="false">2409.17044v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Open-World Object Detection with Instance Representation Learning</title>
      <link>http://arxiv.org/abs/2409.16073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Our project website can be found at
  https://sunohlee.github.io/OWODRep/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 人类能够自然识别新物体及其关系，而基于深度学习的目标检测器在检测训练中未观察到的物体时表现不佳。&lt;h4&gt;2. 问题提出&lt;/h4&gt;   - 开放世界物体检测（OWOD）旨在使模型能够在开放世界场景中检测未知物体，但现有OWOD方法未能捕捉检测物体之间的细微关系，影响全面场景理解。&lt;h4&gt;3. 方法创新&lt;/h4&gt;   - 提出一种新方法，利用视觉基础模型（VFM）的知识，训练能够检测新物体并提取语义丰富特征的目标检测器。&lt;h4&gt;4. 监督机制&lt;/h4&gt;   - 使用Segment Anything Model生成的语义掩膜来监督未知物体的框回归，确保准确定位。&lt;h4&gt;5. 特征学习&lt;/h4&gt;   - 通过将VFM特征获得的实例级相似性转移到检测器的实例嵌入，学习语义丰富的特征空间。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 大量实验表明，该方法学习到的特征空间具有鲁棒性和泛化能力，优于其他基于OWOD的特征提取方法。&lt;h4&gt;7. 应用扩展&lt;/h4&gt;   - 通过增强特征，该模型提高了检测器在开放世界跟踪等任务中的适用性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While humans naturally identify novel objects and understand theirrelationships, deep learning-based object detectors struggle to detect andrelate objects that are not observed during training. To overcome this issue,Open World Object Detection(OWOD) has been introduced to enable models todetect unknown objects in open-world scenarios. However, OWOD methods fail tocapture the fine-grained relationships between detected objects, which arecrucial for comprehensive scene understanding and applications such as classdiscovery and tracking. In this paper, we propose a method to train an objectdetector that can both detect novel objects and extract semantically richfeatures in open-world conditions by leveraging the knowledge of VisionFoundation Models(VFM). We first utilize the semantic masks from the SegmentAnything Model to supervise the box regression of unknown objects, ensuringaccurate localization. By transferring the instance-wise similarities obtainedfrom the VFM features to the detector's instance embeddings, our method thenlearns a semantically rich feature space of these embeddings. Extensiveexperiments show that our method learns a robust and generalizable featurespace, outperforming other OWOD-based feature extraction methods. Additionally,we demonstrate that the enhanced feature from our model increases thedetector's applicability to tasks such as open-world tracking.</description>
      <author>example@mail.com (Sunoh Lee, Minsik Jeon, Jihong Min, Junwon Seo)</author>
      <guid isPermaLink="false">2409.16073v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>DIAL: Dense Image-text ALignment for Weakly Supervised Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2409.15801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by the European Conference on Computer Vision (ECCV), 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 弱监督语义分割（WSSS）方法通常依赖类激活图（CAM）生成初始种子，但由于仅使用图像级标签，往往无法捕捉全局上下文。&lt;h4&gt;2. 方法提出&lt;/h4&gt;   - 引入DALNet（Dense Alignment Learning Network），利用文本嵌入增强对目标的全面理解和精确定位。&lt;h4&gt;3. 核心思想&lt;/h4&gt;   - 采用双重对齐策略：     - **全局隐式对齐（GIA）**：通过最大化类标记与对应文本嵌入之间的相似性，同时最小化与背景嵌入的相似性，以捕捉全局语义。     - **局部显式对齐（LEA）**：利用来自补丁标记的空间信息改善目标定位。&lt;h4&gt;4. 学习方法&lt;/h4&gt;   - 提出交叉对比学习方法，旨在对齐图像和文本模态之间的前景特征，同时将其与背景区分开，鼓励在缺失区域激活并抑制干扰。&lt;h4&gt;5. 实验验证&lt;/h4&gt;   - 在PASCAL VOC和MS COCO数据集上进行广泛实验，结果显示DALNet显著优于当前最先进的WSSS方法。&lt;h4&gt;6. 方法优势&lt;/h4&gt;   - DALNet作为单阶段方法，实现更高效的端到端处理过程。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Weakly supervised semantic segmentation (WSSS) approaches typically rely onclass activation maps (CAMs) for initial seed generation, which often fail tocapture global context due to limited supervision from image-level labels. Toaddress this issue, we introduce DALNet, Dense Alignment Learning Network thatleverages text embeddings to enhance the comprehensive understanding andprecise localization of objects across different levels of granularity. Our keyinsight is to employ a dual-level alignment strategy: (1) Global ImplicitAlignment (GIA) to capture global semantics by maximizing the similaritybetween the class token and the corresponding text embeddings while minimizingthe similarity with background embeddings, and (2) Local Explicit Alignment(LEA) to improve object localization by utilizing spatial information frompatch tokens. Moreover, we propose a cross-contrastive learning approach thataligns foreground features between image and text modalities while separatingthem from the background, encouraging activation in missing regions andsuppressing distractions. Through extensive experiments on the PASCAL VOC andMS COCO datasets, we demonstrate that DALNet significantly outperformsstate-of-the-art WSSS methods. Our approach, in particular, allows for moreefficient end-to-end process as a single-stage method.</description>
      <author>example@mail.com (Soojin Jang, Jungmin Yun, Junehyoung Kwon, Eunju Lee, Youngbin Kim)</author>
      <guid isPermaLink="false">2409.15801v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning and Machine Learning, Advancing Big Data Analytics and Management: Tensorflow Pretrained Models</title>
      <link>http://arxiv.org/abs/2409.13566v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This book contains 148 pages and 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 书籍主题&lt;/h4&gt;   - 专注于TensorFlow预训练模型在深度学习中的应用。&lt;h4&gt;2. 应用领域&lt;/h4&gt;   - 提供任务指导，如图像分类和目标检测。&lt;h4&gt;3. 现代架构介绍&lt;/h4&gt;   - 涵盖ResNet、MobileNet和EfficientNet等现代架构的实际实现。&lt;h4&gt;4. 迁移学习&lt;/h4&gt;   - 通过真实示例和实验展示迁移学习的强大能力。&lt;h4&gt;5. 方法比较&lt;/h4&gt;   - 比较线性探测与模型微调，分析不同方法的效果。&lt;h4&gt;6. 可视化技术&lt;/h4&gt;   - 使用PCA、t-SNE和UMAP等技术进行可视化，帮助读者直观理解不同方法的影响。&lt;h4&gt;7. 适用对象&lt;/h4&gt;   - 设计适合初学者到高级用户的内容。&lt;h4&gt;8. 代码和指导&lt;/h4&gt;   - 包含完整示例代码和逐步说明，帮助读者快速掌握如何利用预训练模型改善性能。&lt;h4&gt;9. 理论与实践结合&lt;/h4&gt;   - 将理论见解与实践相结合，帮助读者自信地应对各种深度学习挑战。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This book focuses on the application of TensorFlow pre-trained models in deeplearning, providing detailed guidance on effectively using these models fortasks such as image classification and object detection. It covers practicalimplementations of modern architectures like ResNet, MobileNet, andEfficientNet, demonstrating the power of transfer learning through real-worldexamples and experiments. The book compares linear probing and modelfine-tuning, offering visualizations using techniques such as PCA, t-SNE, andUMAP to help readers intuitively understand the impact of different approaches.Designed for beginners to advanced users, this book includes complete examplecode and step-by-step instructions, enabling readers to quickly master how toleverage pre-trained models to improve performance in practical scenarios. Byblending theoretical insights with hands-on practice, this book equips readerswith the knowledge to confidently tackle various deep learning challenges.</description>
      <author>example@mail.com (Keyu Chen, Ziqian Bi, Qian Niu, Junyu Liu, Benji Peng, Sen Zhang, Ming Liu, Ming Li, Xuanhe Pan, Jiawei Xu, Jinlang Wang, Pohsun Feng)</author>
      <guid isPermaLink="false">2409.13566v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>GeoBiked: A Dataset with Geometric Features and Automated Labeling Techniques to Enable Deep Generative Models in Engineering Design</title>
      <link>http://arxiv.org/abs/2409.17045v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 提供一个数据集以支持深度生成模型（DGM）在工程设计中的应用。&lt;h4&gt;2. 数据集介绍&lt;/h4&gt;   - **GeoBiked**：包含4,355张自行车图像，标注了结构和技术特征。&lt;h4&gt;3. 自动标注技术&lt;/h4&gt;   - 研究两种自动标注技术：     - 使用图像生成模型的整合潜在特征（Hyperfeatures）来检测结构图像中的几何对应关系（如轮中心位置）。     - 生成结构图像的多样化文本描述。&lt;h4&gt;4. GPT-4o模型应用&lt;/h4&gt;   - 这个视觉-语言模型（VLM）分析图像并生成与系统提示对齐的多样描述。&lt;h4&gt;5. 技术实现&lt;/h4&gt;   - 将技术图像表示为扩散超特征（Diffusion-Hyperfeatures），使几何对应关系的绘制成为可能。   - 通过提供多个标注的源图像，提高对未见样本中几何点的检测准确性。&lt;h4&gt;6. 描述生成能力&lt;/h4&gt;   - GPT-4o能够生成准确的技术图像描述。   - 仅基于图像的生成导致多样性，但可能出现幻觉；仅基于分类标签则限制了多样性。&lt;h4&gt;7. 输入平衡&lt;/h4&gt;   - 同时使用图像和分类标签作为输入，可以在创造性与准确性之间取得平衡。&lt;h4&gt;8. 应用潜力&lt;/h4&gt;   - 成功使用超特征进行几何对应关系检测，表明该方法可用于技术图像中的一般点检测和注释任务。&lt;h4&gt;9. 模型依赖性&lt;/h4&gt;   - 使用VLM对图像进行文本描述标注是可行的，但依赖于模型的检测能力、精心设计的提示和输入信息的选择。&lt;h4&gt;10. 研究目标&lt;/h4&gt;    - 探索在工程设计领域应用基础模型的潜力，旨在填补这一领域的空白，通过数据集探索训练、微调和条件化DGM的方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We provide a dataset for enabling Deep Generative Models (DGMs) inengineering design and propose methods to automate data labeling by utilizinglarge-scale foundation models. GeoBiked is curated to contain 4 355 bicycleimages, annotated with structural and technical features and is used toinvestigate two automated labeling techniques: The utilization of consolidatedlatent features (Hyperfeatures) from image-generation models to detectgeometric correspondences (e.g. the position of the wheel center) in structuralimages and the generation of diverse text descriptions for structural images.GPT-4o, a vision-language-model (VLM), is instructed to analyze images andproduce diverse descriptions aligned with the system-prompt. By representingtechnical images as Diffusion-Hyperfeatures, drawing geometric correspondencesbetween them is possible. The detection accuracy of geometric points in unseensamples is improved by presenting multiple annotated source images. GPT-4o hassufficient capabilities to generate accurate descriptions of technical images.Grounding the generation only on images leads to diverse descriptions butcauses hallucinations, while grounding it on categorical labels restricts thediversity. Using both as input balances creativity and accuracy. Successfullyusing Hyperfeatures for geometric correspondence suggests that this approachcan be used for general point-detection and annotation tasks in technicalimages. Labeling such images with text descriptions using VLMs is possible, butdependent on the models detection capabilities, careful prompt-engineering andthe selection of input information. Applying foundation models in engineeringdesign is largely unexplored. We aim to bridge this gap with a dataset toexplore training, finetuning and conditioning DGMs in this field and suggestingapproaches to bootstrap foundation models to process technical images.</description>
      <author>example@mail.com (Phillip Mueller, Sebastian Mueller, Lars Mikelsons)</author>
      <guid isPermaLink="false">2409.17045v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Nearest Neighbor Search Using Dynamic Programming</title>
      <link>http://arxiv.org/abs/2409.15023v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 在处理分布在3D空间的流形表面的点云时，传统最近邻搜索算法（如KD树和R树）的效率可能下降，尤其是当查询点远离数据时。&lt;h4&gt;2. 效率问题&lt;/h4&gt;   - 在极端情况下，查询的复杂度可能接近O(n)，导致性能下降。&lt;h4&gt;3. 方法提出&lt;/h4&gt;   - 提出了一个新颖的动态规划技术，预计算有向无环图（DAG），以实现更高效的最近邻查询，特别是针对2D流形数据。&lt;h4&gt;4. 方法优势&lt;/h4&gt;   - 利用这种结构，只需进行少量的点对距离比较，即可准确识别最近邻。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 大量实验结果表明，所提方法的查询速度比传统方法快1倍到10倍。&lt;h4&gt;6. 比较性能&lt;/h4&gt;   - 在均匀分布的点云上，算法的查询效率与KD树相当。&lt;h4&gt;7. 扩展功能&lt;/h4&gt;   - 支持前k个点的最近邻查询，并且能与低复杂度的最远点采样算法结合实现。&lt;h4&gt;8. 适用性&lt;/h4&gt;   - 该方法有潜力支持不同类型的原始数据和距离度量的最近邻查询。&lt;h4&gt;9. 贡献与展望&lt;/h4&gt;   - 提出的算法被认为是当前最简洁、直接的确切最近邻搜索算法，预计将对该领域的进展产生重大影响。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When dealing with point clouds distributed on manifold surfaces in 3D space,or when the query point is far from the data, the efficiency of traditionalnearest neighbor search algorithms (e.g., KD Tree and R Tree) may degrade. Inextreme cases, the complexity of the query can approach O(n). In this paper, wepropose a novel dynamic programming technique that precomputes a DirectedAcyclic Graph (DAG) to enable more efficient nearest neighbor queries for 2Dmanifold data. By leveraging this structure, only a small number of distancecomparisons between point pairs are required to accurately identify the nearestneighbor. Extensive experimental results demonstrate that our method achievesquery speeds that are 1x-10x faster than traditional methods. Moreover, ouralgorithm exhibits significant potential. It achieves query efficiencycomparable to KD-trees on uniformly distributed point clouds. Additionally, ouralgorithm supports nearest neighbor queries among the first k points. Coupledwith our algorithm, a farthest point sampling algorithm with lower complexitycan also be implemented. Furthermore, our method has the potential to supportnearest neighbor queries with different types of primitives and distancemetrics. We believe that the method proposed in this paper represents the mostconcise and straightforward exact nearest neighbor search algorithm currentlyavailable, and it will contribute significantly to advancements in the field.</description>
      <author>example@mail.com (Pengfei Wang, Jiantao Song, Shiqing Xin, Shuangmin Chen, Changhe Tu, Wenping Wang, Jiaye Wang)</author>
      <guid isPermaLink="false">2409.15023v3</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Towards Representation Learning for Weighting Problems in Design-Based Causal Inference</title>
      <link>http://arxiv.org/abs/2409.16407v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  UAI 2024, typos in UAI version fixed&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 重新加权分布以最小化与目标分布的距离是一种强大且灵活的策略，用于估计广泛的因果效应。&lt;h4&gt;2. 实践挑战&lt;/h4&gt;   - 在实践中，这种方法可能具有挑战性，因为最优权重通常依赖于对潜在数据生成过程的了解。&lt;h4&gt;3. 研究重点&lt;/h4&gt;   - 本文关注于设计基础权重，这些权重不包含结果信息，典型示例包括前瞻性队列研究、调查加权以及增强加权估计器的加权部分。&lt;h4&gt;4. 表示学习的重要性&lt;/h4&gt;   - 探讨表示学习在寻找有效权重中的核心作用。&lt;h4&gt;5. 方法论创新&lt;/h4&gt;   - 不同于假设良好指定表示的常见方法，强调选择表示时可能导致的误差。   - 提出了一个通用框架，用于找到适合的表示，以最小化这种误差。&lt;h4&gt;6. 新估计程序&lt;/h4&gt;   - 基于最新的研究，结合平衡权重与神经网络，提出了一种端到端的估计程序，能够学习灵活的表示，同时保留有希望的理论性质。&lt;h4&gt;7. 实验成果&lt;/h4&gt;   - 该方法在多种常见的因果推断任务中表现出竞争力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reweighting a distribution to minimize a distance to a target distribution isa powerful and flexible strategy for estimating a wide range of causal effects,but can be challenging in practice because optimal weights typically depend onknowledge of the underlying data generating process. In this paper, we focus ondesign-based weights, which do not incorporate outcome information; prominentexamples include prospective cohort studies, survey weighting, and theweighting portion of augmented weighting estimators. In such applications, weexplore the central role of representation learning in finding desirableweights in practice. Unlike the common approach of assuming a well-specifiedrepresentation, we highlight the error due to the choice of a representationand outline a general framework for finding suitable representations thatminimize this error. Building on recent work that combines balancing weightsand neural networks, we propose an end-to-end estimation procedure that learnsa flexible representation, while retaining promising theoretical properties. Weshow that this approach is competitive in a range of common causal inferencetasks.</description>
      <author>example@mail.com (Oscar Clivio, Avi Feller, Chris Holmes)</author>
      <guid isPermaLink="false">2409.16407v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MotifDisco: Motif Causal Discovery For Time Series Motifs</title>
      <link>http://arxiv.org/abs/2409.15219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 许多时间序列，特别是健康数据流，可以理解为一系列现象或事件，这些称为“动机”（motifs）。   - 时间序列动机是一个短的轨迹片段，可能隐含地捕捉到时间序列中的基本现象。&lt;h4&gt;2. 研究重点&lt;/h4&gt;   - 本文专注于从连续血糖监测仪（CGMs）收集的血糖轨迹，这些轨迹本质上包含了代表人类行为（如饮食和运动）的动机。&lt;h4&gt;3. 研究目的&lt;/h4&gt;   - 识别和量化动机之间的因果关系可以帮助更好地理解和表示这些模式，有助于改进深度学习和生成模型，并推动个性化辅导和人工胰岛素输送系统等先进技术的发展。&lt;h4&gt;4. 研究缺口&lt;/h4&gt;   - 之前的研究没有开发出针对时间序列动机的因果发现方法。&lt;h4&gt;5. 提出的方法&lt;/h4&gt;   - 开发了MotifDisco（动机因果发现），这是一个新的因果发现框架，用于从时间序列轨迹中学习动机之间的因果关系。   - 形式化了“动机因果性”（Motif Causality, MC）的概念，灵感来自Granger因果性和传递熵。&lt;h4&gt;6. 技术实现&lt;/h4&gt;   - 创建了一个基于图神经网络的框架，通过解决无监督链接预测问题，学习动机之间的因果关系。&lt;h4&gt;7. 应用案例&lt;/h4&gt;   - 将MC与三种模型使用案例集成：预测、异常检测和聚类，展示MC作为其他下游任务的构建块的应用。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 评估框架后发现，动机因果性在所有使用案例中提供了显著的性能提升。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many time series, particularly health data streams, can be best understood asa sequence of phenomenon or events, which we call motifs. A time series motifis a short trace segment which may implicitly capture an underlying phenomenonwithin the time series. Specifically, we focus on glucose traces collected fromcontinuous glucose monitors (CGMs), which inherently contain motifsrepresenting underlying human behaviors such as eating and exercise. Theability to identify and quantify causal relationships amongst motifs canprovide a mechanism to better understand and represent these patterns, usefulfor improving deep learning and generative models and for advanced technologydevelopment (e.g., personalized coaching and artificial insulin deliverysystems). However, no previous work has developed causal discovery methods fortime series motifs. Therefore, in this paper we develop MotifDisco (motifdisco-very of causality), a novel causal discovery framework to learn causalrelations amongst motifs from time series traces. We formalize a notion ofMotif Causality (MC), inspired from Granger Causality and Transfer Entropy, anddevelop a Graph Neural Network-based framework that learns causality betweenmotifs by solving an unsupervised link prediction problem. We also integrate MCwith three model use cases of forecasting, anomaly detection and clustering, toshowcase the use of MC as a building block for other downstream tasks. Finally,we evaluate our framework and find that Motif Causality provides a significantperformance improvement in all use cases.</description>
      <author>example@mail.com (Josephine Lamp, Mark Derdzinski, Christopher Hannemann, Sam Hatfield, Joost van der Linden)</author>
      <guid isPermaLink="false">2409.15219v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>CLSP: High-Fidelity Contrastive Language-State Pre-training for Agent State Representation</title>
      <link>http://arxiv.org/abs/2409.15806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着人工智能的快速发展，多模态学习已成为重要的研究领域。   - 对于智能代理而言，状态是一种关键模态，能够传达精确信息，与图像、视频和语言等常见模态并行。&lt;h4&gt;2. 现状问题&lt;/h4&gt;   - 状态模态的表示仍然滞后于其他模态的发展。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 提出一种高保真对比语言-状态预训练（CLSP）方法，旨在将状态信息准确编码为适用于强化学习和多模态大型语言模型的通用表示。&lt;h4&gt;4. 方法步骤&lt;/h4&gt;   - **预训练任务设计**：基于分类设计预训练任务，以训练一个带有粗粒度信息的编码器。   - **数据对构建**：构建状态与语言描述的数据对，利用预训练的编码器初始化CLSP编码器。   - **对比学习**：采用对比学习训练CLSP编码器，以有效表示精确的状态信息。&lt;h4&gt;5. 增强表示能力&lt;/h4&gt;   - 使用随机傅里叶特征（RFF）方法增强数据信息的表示，实现高保真映射。&lt;h4&gt;6. 实验验证&lt;/h4&gt;   - 大量实验表明，该方法在文本-状态检索、强化学习导航任务和多模态大型语言模型理解方面，表现出优越的精度和泛化能力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of artificial intelligence, multimodal learninghas become an important research area. For intelligent agents, the state is acrucial modality to convey precise information alongside common modalities likeimages, videos, and language. This becomes especially clear with the broadadoption of reinforcement learning and multimodal large language models.Nevertheless, the representation of state modality still lags in development.To this end, we propose a High-Fidelity Contrastive Language-State Pre-training(CLSP) method, which can accurately encode state information into generalrepresentations for both reinforcement learning and multimodal large languagemodels. Specifically, we first design a pre-training task based on theclassification to train an encoder with coarse-grained information. Next, weconstruct data pairs of states and language descriptions, utilizing thepre-trained encoder to initialize the CLSP encoder. Then, we deploy contrastivelearning to train the CLSP encoder to effectively represent precise stateinformation. Additionally, we enhance the representation of numericalinformation using the Random Fourier Features (RFF) method for high-fidelitymapping. Extensive experiments demonstrate the superior precision andgeneralization capabilities of our representation, achieving outstandingresults in text-state retrieval, reinforcement learning navigation tasks, andmultimodal large language model understanding.</description>
      <author>example@mail.com (Fuxian Huang, Qi Zhang, Shaopeng Zhai, Jie Wang, Tianyi Zhang, Haoran Zhang, Ming Zhou, Yu Liu, Yu Qiao)</author>
      <guid isPermaLink="false">2409.15806v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension</title>
      <link>http://arxiv.org/abs/2409.13609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  EMNLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - **引用表达理解（REC）**：旨在通过自然语言定位局部视觉区域，任务依赖于多模态对齐。&lt;h4&gt;2. 现有方法问题&lt;/h4&gt;   - 大多数方法使用强大的预训练模型进行全量微调，然而这不仅破坏了预训练中嵌入的丰富知识，还导致显著的计算成本。&lt;h4&gt;3. 研究动机&lt;/h4&gt;   - 受到参数高效迁移学习（PETL）方法的启发，研究目标是以有效且高效的方式解决REC任务。&lt;h4&gt;4. 方法局限性&lt;/h4&gt;   - 直接将PETL方法应用于REC任务不合适，因为这些方法缺乏精确的局部视觉感知和视觉-语言对齐的特定领域能力。&lt;h4&gt;5. 提出的新框架&lt;/h4&gt;   - **MaPPER（多模态先验引导的参数高效调优）**：     - 包含动态先验适配器，受对齐先验指导。     - 包括局部卷积适配器，以提取精确的局部语义，增强视觉感知。&lt;h4&gt;6. 模块创新&lt;/h4&gt;   - 提出了先验引导文本模块，以进一步利用先验促进跨模态对齐。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 在三个广泛使用的基准测试上，MaPPER相比于全量微调和其他PETL方法表现出最佳准确性，仅需调整1.41%的可调骨干参数。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Referring Expression Comprehension (REC), which aims to ground a local visualregion via natural language, is a task that heavily relies on multimodalalignment. Most existing methods utilize powerful pre-trained models totransfer visual/linguistic knowledge by full fine-tuning. However, fullfine-tuning the entire backbone not only breaks the rich prior knowledgeembedded in the pre-training, but also incurs significant computational costs.Motivated by the recent emergence of Parameter-Efficient Transfer Learning(PETL) methods, we aim to solve the REC task in an effective and efficientmanner. Directly applying these PETL methods to the REC task is inappropriate,as they lack the specific-domain abilities for precise local visual perceptionand visual-language alignment. Therefore, we propose a novel framework ofMultimodal Prior-guided Parameter Efficient Tuning, namely MaPPER.Specifically, MaPPER comprises Dynamic Prior Adapters guided by a alignedprior, and Local Convolution Adapters to extract precise local semantics forbetter visual perception. Moreover, the Prior-Guided Text module is proposed tofurther utilize the prior for facilitating the cross-modal alignment.Experimental results on three widely-used benchmarks demonstrate that MaPPERachieves the best accuracy compared to the full fine-tuning and other PETLmethods with only 1.41% tunable backbone parameters.</description>
      <author>example@mail.com (Ting Liu, Zunnan Xu, Yue Hu, Liangtao Shi, Zhiqiang Wang, Quanjun Yin)</author>
      <guid isPermaLink="false">2409.13609v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>SpikeGS: Learning 3D Gaussian Fields from Continuous Spike Stream</title>
      <link>http://arxiv.org/abs/2409.15176v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACCV 2024. Project page: https://github.com/520jz/SpikeGS&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - Spike相机是一种高速度视觉传感器，相较于传统帧相机具有高时间分辨率和高动态范围，这使其在许多计算机视觉任务中具有显著优势。&lt;h4&gt;2. 现有挑战&lt;/h4&gt;   - 3D重建和新视图合成任务基于Spike相机的研究仍然不足。   - 虽然已有方法用于从Spike流学习神经辐射场，但在极端噪声和低光照条件下缺乏鲁棒性，且使用深度全连接神经网络和光线行进渲染策略导致计算复杂度高，难以恢复细微纹理细节。&lt;h4&gt;3. 新方法的提出&lt;/h4&gt;   - 引入SpikeGS，这是首个仅从Spike流学习3D高斯场的方法。   - 设计了一个基于3DGS的可微分Spike流渲染框架，结合噪声嵌入和脉冲神经元。&lt;h4&gt;4. 技术创新&lt;/h4&gt;   - 利用3DGS的多视图一致性和基于瓦片的多线程并行渲染机制，实现了高质量的实时渲染结果。   - 引入了一种在不同光照条件下都能泛化的Spike渲染损失函数。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 方法能够从移动Spike相机捕获的连续Spike流中重建具有细腻纹理细节的视图合成结果，在极端噪声低光场景下表现出高鲁棒性。   - 在真实和合成数据集上的实验结果表明，该方法在渲染质量和速度方面超过了现有方法。&lt;h4&gt;6. 代码发布&lt;/h4&gt;   - 相关代码将发布在GitHub上：[https://github.com/520jz/SpikeGS](https://github.com/520jz/SpikeGS)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/520jz/spikegs&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A spike camera is a specialized high-speed visual sensor that offersadvantages such as high temporal resolution and high dynamic range compared toconventional frame cameras. These features provide the camera with significantadvantages in many computer vision tasks. However, the tasks of 3Dreconstruction and novel view synthesis based on spike cameras remainunderdeveloped. Although there are existing methods for learning neuralradiance fields from spike stream, they either lack robustness in extremelynoisy, low-quality lighting conditions or suffer from high computationalcomplexity due to the deep fully connected neural networks and ray marchingrendering strategies used in neural radiance fields, making it difficult torecover fine texture details. In contrast, the latest advancements in 3DGS haveachieved high-quality real-time rendering by optimizing the point cloudrepresentation into Gaussian ellipsoids. Building on this, we introduceSpikeGS, the first method to learn 3D Gaussian fields solely from spike stream.We designed a differentiable spike stream rendering framework based on 3DGS,incorporating noise embedding and spiking neurons. By leveraging the multi-viewconsistency of 3DGS and the tile-based multi-threaded parallel renderingmechanism, we achieved high-quality real-time rendering results. Additionally,we introduced a spike rendering loss function that generalizes under varyingillumination conditions. Our method can reconstruct view synthesis results withfine texture details from a continuous spike stream captured by a moving spikecamera, while demonstrating high robustness in extremely noisy low-lightscenarios. Experimental results on both real and synthetic datasets demonstratethat our method surpasses existing approaches in terms of rendering quality andspeed. Our code will be available at https://github.com/520jz/SpikeGS.</description>
      <author>example@mail.com (Jinze Yu, Xi Peng, Zhengda Lu, Laurent Kneip, Yiqun Wang)</author>
      <guid isPermaLink="false">2409.15176v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Text Representation Learning via Instruction-Tuning for Zero-Shot Dense Retrieval</title>
      <link>http://arxiv.org/abs/2409.16497v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at DCAI24 workshop@CIKM2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 密集检索系统广泛用于信息检索（IR），依赖于通过编码器学习文本表示，通常需要基于标签数据的监督建模，而获得这些数据可能成本高昂或根本不可用。&lt;h4&gt;2. 创新方法&lt;/h4&gt;   - 本研究提出了一种新颖的无监督文本表示学习技术，通过对预训练的编码器-解码器大型语言模型（LLM）进行指令调优，采用双编码器检索框架。&lt;h4&gt;3. 数据增强&lt;/h4&gt;   - 证明了通过基于Rao-Blackwell定理生成的相关合成查询的表示，可以增强语料库的表示。&lt;h4&gt;4. 查询与语料对齐&lt;/h4&gt;   - 使用自我指令调优有效对齐查询和语料文本表示。&lt;h4&gt;5. 具体实施步骤&lt;/h4&gt;   - 首先，提示一个开放式预训练LLM按照定义的指令（如问题生成和关键词总结）生成合成查询。   - 其次，使用定义的指令和通过质量检查的生成查询对预训练LLM进行微调。   - 最后，为每个语料生成合成查询，并通过加权平均合成查询和原始语料嵌入来表示每个语料。&lt;h4&gt;6. 实验评估&lt;/h4&gt;   - 在低资源设置下，评估了所提方法在三个英语和一个德语检索数据集上的表现，衡量指标包括NDCG@10、MRR@100和Recall@100。&lt;h4&gt;7. 结果表现&lt;/h4&gt;   - 在所有指标上显著提高了平均零-shot检索性能，FLAN-T5模型变体绝对增加了[3.34%, 3.50%]，并且超过了三个竞争密集检索模型（如mDPR、T-Systems、mBART-Large），这些模型的大小至少小38%。   - 在NDCG@10上，绝对提高了1.96%、4.62%、9.52%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense retrieval systems are commonly used for information retrieval (IR).They rely on learning text representations through an encoder and usuallyrequire supervised modeling via labelled data which can be costly to obtain orsimply unavailable. In this study, we introduce a novel unsupervised textrepresentation learning technique via instruction-tuning the pre-trainedencoder-decoder large language models (LLM) under the dual-encoder retrievalframework. We demonstrate the corpus representation can be augmented by therepresentations of relevant synthetic queries generated by the instruct-tunedLLM founded on the Rao-Blackwell theorem. Furthermore, we effectively align thequery and corpus text representation with self-instructed-tuning. Specifically,we first prompt an open-box pre-trained LLM to follow defined instructions(i.e. question generation and keyword summarization) to generate syntheticqueries. Next, we fine-tune the pre-trained LLM with defined instructions andthe generated queries that passed quality check. Finally, we generate syntheticqueries with the instruction-tuned LLM for each corpora and represent eachcorpora by weighted averaging the synthetic queries and original corporaembeddings. We evaluate our proposed method under low-resource settings onthree English and one German retrieval datasets measuring NDCG@10, MRR@100,Recall@100. We significantly improve the average zero-shot retrievalperformance on all metrics, increasing open-box FLAN-T5 model variations by[3.34%, 3.50%] in absolute and exceeding three competitive dense retrievers(i.e. mDPR, T-Systems, mBART-Large), with model of size at least 38% smaller,by 1.96%, 4.62%, 9.52% absolute on NDCG@10.</description>
      <author>example@mail.com (Qiuhai Zeng, Zimeng Qiu, Dae Yon Hwang, Xin He, William M. Campbell)</author>
      <guid isPermaLink="false">2409.16497v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling the Potential of Graph Neural Networks in SME Credit Risk Assessment</title>
      <link>http://arxiv.org/abs/2409.17909v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究框架&lt;/h4&gt;   - 论文以图神经网络为技术框架，整合企业财务指标之间的内在联系，提出了企业信用风险评估模型。&lt;h4&gt;2. 研究内容&lt;/h4&gt;   - **选择指标**：基于前人的经验，选择了29个企业财务数据指标，将每个指标抽象为一个顶点。   - **关系分析**：深入分析指标之间的关系，构建指标的相似性矩阵，并使用最大生成树算法实现企业的图结构映射。&lt;h4&gt;3. 表示学习&lt;/h4&gt;   - 在映射图的表示学习阶段，构建了一个图神经网络模型以获取嵌入表示。   - 每个节点的特征向量扩展为32维，进行了三次GraphSAGE操作，并使用Pool操作对结果进行汇聚，最终输出三个特征向量的平均值作为图的嵌入表示。&lt;h4&gt;4. 分类器构建&lt;/h4&gt;   - 使用两层全连接网络构建分类器，完成预测任务。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 在真实企业数据上的实验结果表明，所提模型能够有效完成企业的多级信用等级评估。   - 树状图映射深刻描绘了公司各指标数据的内在联系。&lt;h4&gt;6. 模型评估&lt;/h4&gt;   - 根据ROC等评价标准，模型的分类效果显著，表现出良好的“鲁棒性”。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper takes the graph neural network as the technical framework,integrates the intrinsic connections between enterprise financial indicators,and proposes a model for enterprise credit risk assessment. The main researchwork includes: Firstly, based on the experience of predecessors, we selected 29enterprise financial data indicators, abstracted each indicator as a vertex,deeply analyzed the relationships between the indicators, constructed asimilarity matrix of indicators, and used the maximum spanning tree algorithmto achieve the graph structure mapping of enterprises; secondly, in therepresentation learning phase of the mapped graph, a graph neural network modelwas built to obtain its embedded representation. The feature vector of eachnode was expanded to 32 dimensions, and three GraphSAGE operations wereperformed on the graph, with the results pooled using the Pool operation, andthe final output of three feature vectors was averaged to obtain the graph'sembedded representation; finally, a classifier was constructed using atwo-layer fully connected network to complete the prediction task. Experimentalresults on real enterprise data show that the model proposed in this paper canwell complete the multi-level credit level estimation of enterprises.Furthermore, the tree-structured graph mapping deeply portrays the intrinsicconnections of various indicator data of the company, and according to the ROCand other evaluation criteria, the model's classification effect is significantand has good "robustness".</description>
      <author>example@mail.com (Bingyao Liu, Iris Li, Jianhua Yao, Yuan Chen, Guanming Huang, Jiajing Wang)</author>
      <guid isPermaLink="false">2409.17909v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning and Double U-Net Empowered Wave Propagation Model in Complex Indoor Environment</title>
      <link>http://arxiv.org/abs/2409.13833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 应用基于迁移学习和变压器网络的机器学习（ML）网络于复杂室内环境的波传播模型。&lt;h4&gt;2. 模型目的&lt;/h4&gt;   - 该网络旨在预测信号在各种物体环境中的传播，模拟典型室内空间中的多样化家具。&lt;h4&gt;3. 模型架构&lt;/h4&gt;   - 提出了以**Attention U-Net**和**高效网络**为基础的模型，用于处理编码了室内环境基本信息的图像。&lt;h4&gt;4. 环境定义&lt;/h4&gt;   - 室内环境由其基本结构定义，包括墙壁、窗户和门口的排列，以及家具放置的不同配置。&lt;h4&gt;5. 创新算法&lt;/h4&gt;   - 引入了一种新算法，将2D平面图生成3D环境，这对于高效收集训练数据至关重要。&lt;h4&gt;6. 模型评估&lt;/h4&gt;   - 通过将预测的信号覆盖图与光线追踪（RT）模拟进行比较来评估模型。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 预测结果显示，在所有测试场景中，均方根误差（RMSE）低于6 dB。&lt;h4&gt;8. 模型改进&lt;/h4&gt;   - 使用双U-Net结构相比于单U-Net模型观察到显著的性能提升。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A Machine Learning (ML) network based on transfer learning and transformernetworks is applied to wave propagation models for complex indoor settings.This network is designed to predict signal propagation in environments with avariety of objects, effectively simulating the diverse range of furnituretypically found in indoor spaces. We propose Attention U-Net with EfficientNetworks as the backbone, to process images encoded with the essentialinformation of the indoor environment. The indoor environment is defined by itsfundamental structure, such as the arrangement of walls, windows, and doorways,alongside varying configurations of furniture placement. An innovativealgorithm is introduced to generate a 3D environment from a 2D floorplan, whichis crucial for efficient collection of data for training. The model isevaluated by comparing the predicted signal coverage map with ray tracing (RT)simulations. The prediction results show a root mean square error of less than6 dB across all tested scenarios, with significant improvements observed whenusing a Double U-Net structure compared to a single U-Net model.</description>
      <author>example@mail.com (Ziheng Fu, Swagato Mukherjee, Michael T. Lanagan, Prasenjit Mitra, Tarun Chawla, Ram M. Narayanan)</author>
      <guid isPermaLink="false">2409.13833v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Domain Generalization Algorithms in Computational Pathology</title>
      <link>http://arxiv.org/abs/2409.17063v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 深度学习模型在计算病理学（CPath）任务中展现出巨大潜力，但在未见数据上应用时，性能往往受到领域转移的影响。&lt;h4&gt;2. 问题识别&lt;/h4&gt;   - 解决领域转移问题需要领域泛化（DG）算法，但在CPath背景下，缺乏系统性评估。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本研究旨在基准测试30种DG算法在3个不同难度的CPath任务上的有效性，进行了7,560次交叉验证。&lt;h4&gt;4. 评估方法&lt;/h4&gt;   - 使用统一且稳健的平台评估这些算法，结合了特定模态的技术和最新进展，如预训练基础模型。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 大规模交叉验证实验提供了各种DG策略相对性能的洞察。   - 自监督学习和染色增强方法始终优于其他方法，强调了预训练模型和数据增强的潜力。&lt;h4&gt;6. 新数据集介绍&lt;/h4&gt;   - 引入了一个新的全癌症肿瘤检测数据集（HISTOPANTUM），作为未来研究的基准。&lt;h4&gt;7. 研究贡献&lt;/h4&gt;   - 本研究为研究人员在选择适当的DG方法应用于CPath任务提供了有价值的指导。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models have shown immense promise in computational pathology(CPath) tasks, but their performance often suffers when applied to unseen datadue to domain shifts. Addressing this requires domain generalization (DG)algorithms. However, a systematic evaluation of DG algorithms in the CPathcontext is lacking. This study aims to benchmark the effectiveness of 30 DGalgorithms on 3 CPath tasks of varying difficulty through 7,560cross-validation runs. We evaluate these algorithms using a unified and robustplatform, incorporating modality-specific techniques and recent advances likepretrained foundation models. Our extensive cross-validation experimentsprovide insights into the relative performance of various DG strategies. Weobserve that self-supervised learning and stain augmentation consistentlyoutperform other methods, highlighting the potential of pretrained models anddata augmentation. Furthermore, we introduce a new pan-cancer tumor detectiondataset (HISTOPANTUM) as a benchmark for future research. This study offersvaluable guidance to researchers in selecting appropriate DG approaches forCPath tasks.</description>
      <author>example@mail.com (Neda Zamanitajeddin, Mostafa Jahanifar, Kesi Xu, Fouzia Siraj, Nasir Rajpoot)</author>
      <guid isPermaLink="false">2409.17063v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Train Once, Deploy Anywhere: Matryoshka Representation Learning for Multimodal Recommendation</title>
      <link>http://arxiv.org/abs/2409.16627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to EMNLP 2024 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 尽管语言和视觉建模已有显著进展，将丰富的多模态知识集成到推荐系统中仍然面临重大挑战。&lt;h4&gt;2. 主要问题&lt;/h4&gt;   - 推荐系统需要高效的推荐，这要求适应性和交互性的响应。&lt;h4&gt;3. 研究重点&lt;/h4&gt;   - 本研究聚焦于序列推荐，提出了一种轻量级框架：**全尺度马特里约什卡表示学习用于多模态推荐**（fMRLRec）。&lt;h4&gt;4. 框架功能&lt;/h4&gt;   - fMRLRec捕捉不同粒度的项目特征，学习信息丰富的表示，以实现跨多个维度的高效推荐。&lt;h4&gt;5. 多模态特征整合&lt;/h4&gt;   - 采用简单映射将多模态项目特征投影到对齐的特征空间，以整合来自不同模态的特征。&lt;h4&gt;6. 线性变换设计&lt;/h4&gt;   - 设计了一种高效的线性变换，将较小的特征嵌入到较大的特征中，显著减少了在推荐数据上的大规模训练所需的内存。&lt;h4&gt;7. 扩展性&lt;/h4&gt;   - 结合改进的状态空间建模技术，fMRLRec能够扩展到不同的维度，并且只需一次训练即可生成多个适应不同粒度的模型。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 在多个基准数据集上的实验表明，fMRLRec的有效性和高效性， consistently outperforming state-of-the-art baseline methods。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advancements in language and vision modeling, integrating richmultimodal knowledge into recommender systems continues to pose significantchallenges. This is primarily due to the need for efficient recommendation,which requires adaptive and interactive responses. In this study, we focus onsequential recommendation and introduce a lightweight framework calledfull-scale Matryoshka representation learning for multimodal recommendation(fMRLRec). Our fMRLRec captures item features at different granularities,learning informative representations for efficient recommendation acrossmultiple dimensions. To integrate item features from diverse modalities,fMRLRec employs a simple mapping to project multimodal item features into analigned feature space. Additionally, we design an efficient lineartransformation that embeds smaller features into larger ones, substantiallyreducing memory requirements for large-scale training on recommendation data.Combined with improved state space modeling techniques, fMRLRec scales todifferent dimensions and only requires one-time training to produce multiplemodels tailored to various granularities. We demonstrate the effectiveness andefficiency of fMRLRec on multiple benchmark datasets, which consistentlyachieves superior performance over state-of-the-art baseline methods.</description>
      <author>example@mail.com (Yueqi Wang, Zhenrui Yue, Huimin Zeng, Dong Wang, Julian McAuley)</author>
      <guid isPermaLink="false">2409.16627v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Skeletal Data Matching and Merging from Multiple RGB-D Sensors for Room-Scale Human Behaviour Tracking</title>
      <link>http://arxiv.org/abs/2409.15242v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This preprint has not undergone peer review (when applicable) or any
  post-submission improvements or corrections. The Version of Record of this
  contribution is published in the proceedings of the 2024 edition of the
  Cooperative Design, Visualization, and Engineering conference, and is
  available online at https://doi.org/10.1007/978-3-031-71315-6_30&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 使用普通的RGB-D传感器（如Kinect系列）提供房间规模的人体行为追踪是一种流行且经济的选择。&lt;h4&gt;2. 应用场景&lt;/h4&gt;   - 这种传感器适用于娱乐系统等应用，能够在电视前进行人体追踪。&lt;h4&gt;3. 问题识别&lt;/h4&gt;   - RGB-D传感器对遮挡（如物体或其他人）的敏感性在更复杂的房间设置中可能导致追踪问题。&lt;h4&gt;4. 解决方案概述&lt;/h4&gt;   - 为了缓解遮挡问题、扩展追踪范围并提高准确性，可以依赖多个RGB-D传感器进行数据融合。&lt;h4&gt;5. 数据融合挑战&lt;/h4&gt;   - 传感器之间的校准问题，确保提供共同的参考框架。   - 在实际合并数据时，涉及骨架匹配和合并的挑战。&lt;h4&gt;6. 方法介绍&lt;/h4&gt;   - 本文讨论了应对这些挑战的方法，并展示了通过对齐的点云和合并的骨架列表所取得的结果。&lt;h4&gt;7. 实验成果&lt;/h4&gt;   - 研究结果成功实现了无干扰和抗遮挡的人体行为追踪，适用于房间规模的应用。&lt;h4&gt;8. 潜在应用&lt;/h4&gt;   - 该技术可作为互动应用和（可能的远程）协作系统的输入。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-71315-6_30&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A popular and affordable option to provide room-scale human behaviourtracking is to rely on commodity RGB-D sensors %todo: such as the Kinect familyof devices? as such devices offer body tracking capabilities at a reasonableprice point. While their capabilities may be sufficient for applications suchas entertainment systems where a person plays in front of a television, RGB-Dsensors are sensitive to occlusions from objects or other persons that might bein the way in more complex room-scale setups. To alleviate the occlusion issuebut also in order to extend the tracking range and strengthen its accuracy, itis possible to rely on multiple RGB-D sensors and perform data fusion.Unfortunately, fusing the data in a meaningful manner raises additionalchallenges related to the calibration of the sensors relative to each other toprovide a common frame of reference, but also regarding skeleton matching andmerging when actually combining the data. In this paper, we discuss ourapproach to tackle these challenges and present the results we achieved,through aligned point clouds and combined skeleton lists. These resultssuccessfully enable unobtrusive and occlusion-resilient human behaviourtracking at room scale, that may be used as input for interactive applicationsas well as (possibly remote) collaborative systems.</description>
      <author>example@mail.com (Adrien Coppens, Valérie Maquil)</author>
      <guid isPermaLink="false">2409.15242v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Double-Path Adaptive-correlation Spatial-Temporal Inverted Transformer for Stock Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2409.15662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 空间-时间图神经网络（STGNNs）在多种时间序列预测任务中取得了显著成功。&lt;h4&gt;2. 问题识别&lt;/h4&gt;   - 在股票预测任务中，由于缺乏明确且固定的空间关系，许多STGNNs在该领域的表现不佳。&lt;h4&gt;3. 现有方法的局限&lt;/h4&gt;   - 一些STGNNs尝试从时间序列中学习空间关系，但往往缺乏全面性。&lt;h4&gt;4. 研究发现&lt;/h4&gt;   - 研究表明，使用特征变化作为标记进行时间序列建模，与使用时间步作为标记相比，可以揭示完全不同的信息。&lt;h4&gt;5. 提出的新模型&lt;/h4&gt;   - 为了更全面地提取股票数据中的动态空间信息，提出了**双路径自适应相关空间-时间反转变换器**（DPA-STIFormer）。&lt;h4&gt;6. 模型设计&lt;/h4&gt;   - DPA-STIFormer通过特征的连续变化将每个节点建模为标记。   - 引入**双向自适应融合机制**，将节点编码分解为时间和特征表示。&lt;h4&gt;7. 空间相关性提取&lt;/h4&gt;   - 同时从双路径方法中提取不同的空间相关性，并提出双路径门控机制来融合这两种相关信息。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 在四个股票市场数据集上进行的实验显示出最先进的结果，验证了该模型在揭示潜在时间相关模式方面的优越能力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial-temporal graph neural networks (STGNNs) have achieved significantsuccess in various time series forecasting tasks. However, due to the lack ofexplicit and fixed spatial relationships in stock prediction tasks, many STGNNsfail to perform effectively in this domain. While some STGNNs learn spatialrelationships from time series, they often lack comprehensiveness. Researchindicates that modeling time series using feature changes as tokens revealsentirely different information compared to using time steps as tokens. To morecomprehensively extract dynamic spatial information from stock data, we proposea Double-Path Adaptive-correlation Spatial-Temporal Inverted Transformer(DPA-STIFormer). DPA-STIFormer models each node via continuous changes infeatures as tokens and introduces a Double Direction Self-adaptation Fusionmechanism. This mechanism decomposes node encoding into temporal and featurerepresentations, simultaneously extracting different spatial correlations froma double path approach, and proposes a Double-path gating mechanism to fusethese two types of correlation information. Experiments conducted on four stockmarket datasets demonstrate state-of-the-art results, validating the model'ssuperior capability in uncovering latent temporal-correlation patterns.</description>
      <author>example@mail.com (Wenbo Yan, Ying Tan)</author>
      <guid isPermaLink="false">2409.15662v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Passive Sonar Classification using Pre-trained Audio and ImageNet Models</title>
      <link>http://arxiv.org/abs/2409.13878v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 6 figures, This work has been submitted to the IEEE for
  possible publication. Copyright may be transferred without notice, after
  which this version may no longer be accessible&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 研究转移学习，利用大型预训练模型并进行微调以适应下游任务。&lt;h4&gt;2. 预训练模型背景&lt;/h4&gt;   - 最常用的预训练模型最初是在ImageNet上训练的。&lt;h4&gt;3. 问题识别&lt;/h4&gt;   - 不同数据模态下，这些模型的泛化能力可能有所不同。&lt;h4&gt;4. 研究比较&lt;/h4&gt;   - 本研究比较了预训练的音频神经网络（PANNs）与ImageNet预训练模型在水下声学目标识别（UATR）中的表现。&lt;h4&gt;5. 性能观察&lt;/h4&gt;   - 发现ImageNet预训练模型在被动声纳分类中略微优于预训练的音频模型。&lt;h4&gt;6. 音频采样率分析&lt;/h4&gt;   - 研究分析了音频采样率对模型预训练和微调的影响。&lt;h4&gt;7. 研究贡献&lt;/h4&gt;   - 本研究为UATR的转移学习应用提供了贡献，展示了预训练模型在解决UATR领域中标注数据稀缺问题的潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is commonly employed to leverage large, pre-trained modelsand perform fine-tuning for downstream tasks. The most prevalent pre-trainedmodels are initially trained using ImageNet. However, their ability togeneralize can vary across different data modalities. This study comparespre-trained Audio Neural Networks (PANNs) and ImageNet pre-trained modelswithin the context of underwater acoustic target recognition (UATR). It wasobserved that the ImageNet pre-trained models slightly out-perform pre-trainedaudio models in passive sonar classification. We also analyzed the impact ofaudio sampling rates for model pre-training and fine-tuning. This studycontributes to transfer learning applications of UATR, illustrating thepotential of pre-trained models to address limitations caused by scarce,labeled data in the UATR domain.</description>
      <author>example@mail.com (Amirmohammad Mohammadi, Tejashri Kelhe, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples)</author>
      <guid isPermaLink="false">2409.13878v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Ontological Commitment in Multi-Modal Foundation Models</title>
      <link>http://arxiv.org/abs/2409.17109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Qualitative Reasoning Workshop 2024 (QR2024) colocated with ECAI2024,
  camera-ready submission; first two authors contributed equally; 10 pages, 4
  figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 本研究主题&lt;/h4&gt;   - 本文探讨本体承诺（即使用的概念、关系和假设）在定性推理（QR）模型中的重要性。&lt;h4&gt;2. 现状概述&lt;/h4&gt;   - 当前处理原始输入的主流方法是深度神经网络（DNN），通常基于多模态基础模型，这些模型能够自动学习丰富的概念表示和相应的推理能力。&lt;h4&gt;3. 问题识别&lt;/h4&gt;   - 学习到的定性知识缺乏透明性，难以进行检查、验证或与现有的QR模型进行适配。&lt;h4&gt;4. 现有方法的限制&lt;/h4&gt;   - 目前可以将预定义概念与DNN的潜在表示关联，但可提取的关系主要限于语义相似性。&lt;h4&gt;5. 研究贡献&lt;/h4&gt;   - 本文提出了一种方法，从多模态DNN中提取学习到的超类层次结构，针对一组叶子概念。&lt;h4&gt;6. 方法步骤&lt;/h4&gt;   - **步骤1**：使用DNN的文本输入模态获取叶子概念的嵌入表示。   - **步骤2**：对这些嵌入应用层次聚类，利用DNN通过向量距离编码的语义相似性。   - **步骤3**：通过在可用的QR本体中搜索，为获得的父概念标记。&lt;h4&gt;7. 初步评估结果&lt;/h4&gt;   - 初步评估显示，可以从最先进的基础模型中提取出有意义的本体类层次结构。&lt;h4&gt;8. 验证与验证能力&lt;/h4&gt;   - 论文展示了如何根据给定本体验证和验证DNN学习到的表示。&lt;h4&gt;9. 未来应用展望&lt;/h4&gt;   - 最后，讨论了在定性推理背景下的潜在未来应用。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ontological commitment, i.e., used concepts, relations, and assumptions, area corner stone of qualitative reasoning (QR) models. The state-of-the-art forprocessing raw inputs, though, are deep neural networks (DNNs), nowadays oftenbased off from multimodal foundation models. These automatically learn richrepresentations of concepts and respective reasoning. Unfortunately, thelearned qualitative knowledge is opaque, preventing easy inspection,validation, or adaptation against available QR models. So far, it is possibleto associate pre-defined concepts with latent representations of DNNs, butextractable relations are mostly limited to semantic similarity. As a next steptowards QR for validation and verification of DNNs: Concretely, we propose amethod that extracts the learned superclass hierarchy from a multimodal DNN fora given set of leaf concepts. Under the hood we (1) obtain leaf conceptembeddings using the DNN's textual input modality; (2) apply hierarchicalclustering to them, using that DNNs encode semantic similarities via vectordistances; and (3) label the such-obtained parent concepts using search inavailable ontologies from QR. An initial evaluation study shows that meaningfulontological class hierarchies can be extracted from state-of-the-art foundationmodels. Furthermore, we demonstrate how to validate and verify a DNN's learnedrepresentations against given ontologies. Lastly, we discuss potential futureapplications in the context of QR.</description>
      <author>example@mail.com (Mert Keser, Gesina Schwalbe, Niki Amini-Naieni, Matthias Rottmann, Alois Knoll)</author>
      <guid isPermaLink="false">2409.17109v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Matérn Kernels for Tunable Implicit Surface Reconstruction</title>
      <link>http://arxiv.org/abs/2409.15466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 提出使用Matérn核族进行可调的隐式表面重建，基于近期在定向点云3D重建中的成功应用。&lt;h4&gt;2. 方法优势&lt;/h4&gt;   - 从理论和实践角度看，Matérn核具备一些优越特性，使其在表面重建中表现出色。   - 相比于基于弧余弦核的先进方法，Matérn核更易于实现、计算速度更快且可扩展性更好。&lt;h4&gt;3. 频谱调节&lt;/h4&gt;   - 由于Matérn核是平稳的，证明其频谱可以像傅里叶特征映射一样调节，以帮助基于坐标的多层感知机（MLPs）克服谱偏差。&lt;h4&gt;4. 理论分析&lt;/h4&gt;   - 理论上分析了Matérn核与SIREN网络的联系，以及其与之前使用的弧余弦核的关系。&lt;h4&gt;5. 数据依赖性核&lt;/h4&gt;   - 基于近期引入的神经核场，提出了数据依赖的Matérn核。&lt;h4&gt;6. 性能比较&lt;/h4&gt;   - 特别是Laplace核（作为Matérn核的一部分）在无噪声情况下表现极具竞争力，性能几乎与最先进的方法相当，同时训练时间缩短超过五倍。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mweiherer/matern-surface-reconstruction&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose to use the family of Mat\'ern kernels for tunable implicit surfacereconstruction, building upon the recent success of kernel methods for 3Dreconstruction of oriented point clouds. As we show, both, from a theoreticaland practical perspective, Mat\'ern kernels have some appealing propertieswhich make them particularly well suited for surface reconstruction --outperforming state-of-the-art methods based on the arc-cosine kernel whilebeing significantly easier to implement, faster to compute, and scaleable.Being stationary, we demonstrate that the Mat\'ern kernels' spectrum can betuned in the same fashion as Fourier feature mappings help coordinate-basedMLPs to overcome spectral bias. Moreover, we theoretically analyze Mat\'ernkernel's connection to SIREN networks as well as its relation to previouslyemployed arc-cosine kernels. Finally, based on recently introduced NeuralKernel Fields, we present data-dependent Mat\'ern kernels and conclude thatespecially the Laplace kernel (being part of the Mat\'ern family) is extremelycompetitive, performing almost on par with state-of-the-art methods in thenoise-free case while having a more than five times shorter training time.</description>
      <author>example@mail.com (Maximilian Weiherer, Bernhard Egger)</author>
      <guid isPermaLink="false">2409.15466v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Progressive Representation Learning for Real-Time UAV Tracking</title>
      <link>http://arxiv.org/abs/2409.16652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by the 2024 IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 视觉目标跟踪在无人机（UAV）自主应用中具有重要意义。   - 在复杂动态环境中，学习稳健的目标表示面临挑战，尤其是当遇到纵横比变化和遮挡时。&lt;h4&gt;2. 问题描述&lt;/h4&gt;   - 这些挑战严重影响了目标的原始信息。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 本文提出了一个新颖的渐进表示学习框架，称为**PRL-Track**。&lt;h4&gt;4. 方法结构&lt;/h4&gt;   - **粗表示学习**：     - 设计了两个创新的调节器，分别依赖于外观信息和语义信息，以减轻外观干扰并捕获语义信息。   - **细表示学习**：     - 开发了一个新的层次建模生成器，以交织粗目标表示。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 通过严格实验，PRL-Track在三个权威的无人机跟踪基准测试中显示出卓越的性能。&lt;h4&gt;6. 实际应用&lt;/h4&gt;   - 实际测试表明，PRL-Track在配备边缘智能相机的典型无人机平台上实现了每秒42.6帧的优越跟踪性能。&lt;h4&gt;7. 资源可用性&lt;/h4&gt;   - 代码、模型和演示视频可在GitHub上获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vision4robotics/prl-track&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual object tracking has significantly promoted autonomous applications forunmanned aerial vehicles (UAVs). However, learning robust objectrepresentations for UAV tracking is especially challenging in complex dynamicenvironments, when confronted with aspect ratio change and occlusion. Thesechallenges severely alter the original information of the object. To handle theabove issues, this work proposes a novel progressive representation learningframework for UAV tracking, i.e., PRL-Track. Specifically, PRL-Track is dividedinto coarse representation learning and fine representation learning. Forcoarse representation learning, two innovative regulators, which rely onappearance and semantic information, are designed to mitigate appearanceinterference and capture semantic information. Furthermore, for finerepresentation learning, a new hierarchical modeling generator is developed tointertwine coarse object representations. Exhaustive experiments demonstratethat the proposed PRL-Track delivers exceptional performance on threeauthoritative UAV tracking benchmarks. Real-world tests indicate that theproposed PRL-Track realizes superior tracking performance with 42.6 frames persecond on the typical UAV platform equipped with an edge smart camera. Thecode, model, and demo videos are available at\url{https://github.com/vision4robotics/PRL-Track}.</description>
      <author>example@mail.com (Changhong Fu, Xiang Lei, Haobo Zuo, Liangliang Yao, Guangze Zheng, Jia Pan)</author>
      <guid isPermaLink="false">2409.16652v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>GraphGI:A GNN Explanation Method using Game Interaction</title>
      <link>http://arxiv.org/abs/2409.15698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 图神经网络（GNNs）受到广泛关注，并在多个领域得到广泛应用。   - 然而，GNNs常被视为黑箱模型，使得其预测机制难以解释。&lt;h4&gt;2. 当前挑战&lt;/h4&gt;   - 现有的图解释技术主要集中在识别关键节点或边，归因于驱动模型预测的关键数据特征。   - 这些特征并不独立影响模型结果，而是相互作用，共同影响预测。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 本文提出了一种新颖的解释方法**GraphGI**，旨在识别具有最高互动强度的特征集合，并将其呈现为解释子图。&lt;h4&gt;4. 方法流程&lt;/h4&gt;   - 在给定训练好的模型和输入图的情况下，逐步将重要边纳入选定的子图，以解释预测。   - 利用博弈论的互动值评估在边添加后互动强度，确保新添加的边为解释子图提供最大互动强度。&lt;h4&gt;5. 计算效率&lt;/h4&gt;   - 为提高计算效率，采用有效的近似技术来计算Shapley值和博弈论互动值。&lt;h4&gt;6. 实验评估&lt;/h4&gt;   - 实证评估表明，该方法在保真性和稀疏性方面表现优越，保持了解释结果的可理解性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have garnered significant attention and havebeen extensively utilized across various domains. However, similar to otherdeep learning models, GNNs are often viewed as black-box models, making itchallenging to interpret their prediction mechanisms. Current graph explanationtechniques focus on identifying key nodes or edges, attributing the criticaldata features that drive model predictions. Nevertheless, these features do notindependently influence the model's outcomes; rather, they interact with oneanother to collectively affect predictions. In this work, we propose a novelexplanatory method GraphGI, which identifies the coalition with the highestinteraction strength and presents it as an explanatory subgraph. Given atrained model and an input graph, our method explains predictions by graduallyincorporating significant edges into the selected subgraph. We utilizegame-theoretic interaction values to assess the interaction strength after edgeadditions, ensuring that the newly added edges confer maximum interactionstrength to the explanatory subgraph. To enhance computational efficiency, weadopt effective approximation techniques for calculating Shapley values andgame-theoretic interaction values. Empirical evaluations demonstrate that ourmethod achieves superior fidelity and sparsity, maintaining theinterpretability of the results at a comprehensible level.</description>
      <author>example@mail.com (Xingping Xian, Jianlu Liu, Tao Wu, Lin Yuan, Chao Wang, Baiyun Chen)</author>
      <guid isPermaLink="false">2409.15698v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Unsupervised Image-to-Image Translation Using Contrastive Learning and Histogram of Oriented Gradients</title>
      <link>http://arxiv.org/abs/2409.16042v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Critical Errors in Data or Analysis&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究领域&lt;/h4&gt;   - 图像到图像的转换是计算机视觉中的一个重要领域，旨在将图像从一个视觉域转换到另一个，同时保持其核心内容和结构。&lt;h4&gt;2. 主要挑战&lt;/h4&gt;   - **数据对不齐**：两个域的数据通常是未配对的，这使得有效训练生成对抗网络（GAN）变得困难。   - **生成质量问题**：现有方法在图像生成过程中往往会产生伪影或幻觉，导致图像质量下降。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 本文提出了一种增强的无监督图像到图像翻译方法，基于对比无配对翻译（CUT）模型，结合了方向梯度直方图（HOG）特征。&lt;h4&gt;4. 方法优势&lt;/h4&gt;   - 通过最小化输入图像与生成图像的HOG特征之间的损失，即使在没有语义标签的情况下，也能确保图像语义结构的保留。&lt;h4&gt;5. 实验测试&lt;/h4&gt;   - 在将GTA5数据集中合成的游戏环境转换为城市景观数据集中真实城市场景的实验中，展示了显著降低幻觉并提升图像质量的效果。&lt;h4&gt;6. 研究意义&lt;/h4&gt;   - 提出的改进方法在解决未配对数据问题和提高生成图像质量方面具有重要意义，对图像翻译领域的发展贡献良多。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-to-Image Translation is a vital area of computer vision that focuses ontransforming images from one visual domain to another while preserving theircore content and structure. However, this field faces two major challenges:first, the data from the two domains are often unpaired, making it difficult totrain generative adversarial networks effectively; second, existing methodstend to produce artifacts or hallucinations during image generation, leading toa decline in image quality. To address these issues, this paper proposes anenhanced unsupervised image-to-image translation method based on theContrastive Unpaired Translation (CUT) model, incorporating Histogram ofOriented Gradients (HOG) features. This novel approach ensures the preservationof the semantic structure of images, even without semantic labels, byminimizing the loss between the HOG features of input and generated images. Themethod was tested on translating synthetic game environments from GTA5 datasetto realistic urban scenes in cityscapes dataset, demonstrating significantimprovements in reducing hallucinations and enhancing image quality.</description>
      <author>example@mail.com (Wanchen Zhao)</author>
      <guid isPermaLink="false">2409.16042v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning with Clinical Concept Embeddings from Large Language Models</title>
      <link>http://arxiv.org/abs/2409.13893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 知识共享在医疗保健中至关重要，尤其是在利用多个临床站点的数据以应对数据稀缺、降低成本和实现及时干预时。&lt;h4&gt;2. 转移学习的作用&lt;/h4&gt;   - 转移学习可以促进跨站点的知识转移，但不同站点之间临床概念的异质性是一个主要挑战。&lt;h4&gt;3. 大型语言模型（LLMs）的潜力&lt;/h4&gt;   - LLMs在捕捉临床概念的语义意义和减少异质性方面展现出显著潜力。&lt;h4&gt;4. 研究方法&lt;/h4&gt;   - 分析了来自两个大型医疗系统的电子健康记录，以评估LLMs的语义嵌入对本地、共享和转移学习模型的影响。&lt;h4&gt;5. 研究结果&lt;/h4&gt;   - 特定领域的LLMs（如Med-BERT）在本地和直接转移场景中表现出色。   - 通用模型（如OpenAI嵌入）需要进行微调以达到最佳性能。&lt;h4&gt;6. 微调的平衡&lt;/h4&gt;   - 过度微调使用生物医学嵌入的模型可能会降低其有效性，强调了微调平衡的重要性。&lt;h4&gt;7. 研究意义&lt;/h4&gt;   - 本研究强调了领域特定嵌入和谨慎模型微调在医疗保健知识转移中的重要性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge sharing is crucial in healthcare, especially when leveraging datafrom multiple clinical sites to address data scarcity, reduce costs, and enabletimely interventions. Transfer learning can facilitate cross-site knowledgetransfer, but a major challenge is heterogeneity in clinical concepts acrossdifferent sites. Large Language Models (LLMs) show significant potential ofcapturing the semantic meaning of clinical concepts and reducing heterogeneity.This study analyzed electronic health records from two large healthcare systemsto assess the impact of semantic embeddings from LLMs on local, shared, andtransfer learning models. Results indicate that domain-specific LLMs, such asMed-BERT, consistently outperform in local and direct transfer scenarios, whilegeneric models like OpenAI embeddings require fine-tuning for optimalperformance. However, excessive tuning of models with biomedical embeddings mayreduce effectiveness, emphasizing the need for balance. This study highlightsthe importance of domain-specific embeddings and careful model tuning foreffective knowledge transfer in healthcare.</description>
      <author>example@mail.com (Yuhe Gao, Runxue Bao, Yuelyu Ji, Yiming Sun, Chenxi Song, Jeffrey P. Ferraro, Ye Ye)</author>
      <guid isPermaLink="false">2409.13893v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Block Expanded DINORET: Adapting Natural Domain Foundation Models for Retinal Imaging Without Catastrophic Forgetting</title>
      <link>http://arxiv.org/abs/2409.17332v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  J.Zoellin, C. Merk and M. Buob contributed equally as shared-first
  authors. D. Cabrera DeBuc, M. D. Becker and G. M. Somfai contributed equally
  as senior authors for this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 将深度学习融入医学影像有望极大提升诊断方法，但面临通用性挑战。&lt;h4&gt;2. 基础模型的优势&lt;/h4&gt;   - 基于自监督学习的基础模型旨在解决这些问题，提高数据效率。   - 自然领域的基础模型在医学影像中显示出良好前景，但系统性研究，尤其是在领域适应和参数高效微调方面仍然不足。&lt;h4&gt;3. 遗忘问题&lt;/h4&gt;   - 目前对基础模型微调过程中灾难性遗忘的问题研究较少。&lt;h4&gt;4. 模型适应&lt;/h4&gt;   - 适应了DINOv2视觉变换器用于视网膜影像分类任务，采用自监督学习生成了两个新基础模型，称为DINORET和BE DINORET。&lt;h4&gt;5. 数据来源&lt;/h4&gt;   - 使用公开的彩色眼底照片进行模型开发，并随后进行微调以进行糖尿病视网膜病变分期和青光眼检测。&lt;h4&gt;6. 新策略&lt;/h4&gt;   - 引入了块扩展作为一种新颖的领域适应策略，并评估模型在灾难性遗忘方面的表现。&lt;h4&gt;7. 性能评估&lt;/h4&gt;   - 模型与眼科领域的最先进基础模型RETFound进行基准比较。   - DINORET和BE DINORET在视网膜影像任务上展现出竞争力，块扩展模型在大多数数据集上取得最高分。&lt;h4&gt;8. 数据效率&lt;/h4&gt;   - 块扩展有效缓解了灾难性遗忘。   - 进行的少样本学习研究表明，DINORET和BE DINORET在数据效率上优于RETFound。&lt;h4&gt;9. 研究意义&lt;/h4&gt;   - 本研究强调了将自然领域视觉模型适应于视网膜影像的潜力，利用自监督学习和块扩展。   - BE DINORET在不牺牲先前能力的情况下提供了强健的性能。   - 研究结果表明，这些方法能够帮助医疗机构为其患者群体开发定制的视觉模型，增强全球医疗的包容性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating deep learning into medical imaging is poised to greatly advancediagnostic methods but it faces challenges with generalizability. Foundationmodels, based on self-supervised learning, address these issues and improvedata efficiency. Natural domain foundation models show promise for medicalimaging, but systematic research evaluating domain adaptation, especially usingself-supervised learning and parameter-efficient fine-tuning, remainsunderexplored. Additionally, little research addresses the issue ofcatastrophic forgetting during fine-tuning of foundation models. We adapted theDINOv2 vision transformer for retinal imaging classification tasks usingself-supervised learning and generated two novel foundation models termedDINORET and BE DINORET. Publicly available color fundus photographs wereemployed for model development and subsequent fine-tuning for diabeticretinopathy staging and glaucoma detection. We introduced block expansion as anovel domain adaptation strategy and assessed the models for catastrophicforgetting. Models were benchmarked to RETFound, a state-of-the-art foundationmodel in ophthalmology. DINORET and BE DINORET demonstrated competitiveperformance on retinal imaging tasks, with the block expanded model achievingthe highest scores on most datasets. Block expansion successfully mitigatedcatastrophic forgetting. Our few-shot learning studies indicated that DINORETand BE DINORET outperform RETFound in terms of data-efficiency. This studyhighlights the potential of adapting natural domain vision models to retinalimaging using self-supervised learning and block expansion. BE DINORET offersrobust performance without sacrificing previously acquired capabilities. Ourfindings suggest that these methods could enable healthcare institutions todevelop tailored vision models for their patient populations, enhancing globalhealthcare inclusivity.</description>
      <author>example@mail.com (Jay Zoellin, Colin Merk, Mischa Buob, Amr Saad, Samuel Giesser, Tahm Spitznagel, Ferhat Turgut, Rui Santos, Yukun Zhou, Sigfried Wagner, Pearse A. Keane, Yih Chung Tham, Delia Cabrera DeBuc, Matthias D. Becker, Gabor M. Somfai)</author>
      <guid isPermaLink="false">2409.17332v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>A Prompting-Based Representation Learning Method for Recommendation with Large Language Models</title>
      <link>http://arxiv.org/abs/2409.16674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Risks: The 1st International Workshop on Risks, Opportunities, and
  Evaluation of Generative Models in Recommendation&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 最近几年，推荐系统（RS）因大型语言模型（LLMs）的出现而经历了转型，特别是在自然语言处理（NLP）领域。&lt;h4&gt;2. LLMs的能力&lt;/h4&gt;   - 像GPT-3.5/4和Llama等模型展示了理解和生成类人文本的前所未有的能力。   - 这些LLMs的广泛预训练信息使其能够捕捉用户和物品的不同上下文信息，从而获得更深层次的语义表示。&lt;h4&gt;3. 面临挑战&lt;/h4&gt;   - 尽管LLMs潜力巨大，但如何利用上下文信息中的用户-物品偏好，以及如何使其与推荐系统的改进相一致，仍然是一个挑战。&lt;h4&gt;4. 研究动机&lt;/h4&gt;   - 认为更好地理解用户或物品本身是提升推荐性能的关键因素，研究生成信息丰富的个人资料。&lt;h4&gt;5. 提出方法&lt;/h4&gt;   - 引入**基于提示的表示学习方法（P4R）**，旨在提升LLMs在推荐系统中的语言能力。   - 在P4R框架中，利用LLM的提示策略创建个性化物品资料。&lt;h4&gt;6. 技术实现&lt;/h4&gt;   - 将这些资料转化为语义表示空间，使用预训练的BERT模型进行文本嵌入。   - 结合图卷积网络（GCN）进行协同过滤表示。&lt;h4&gt;7. 框架目标&lt;/h4&gt;   - P4R框架对这两个嵌入空间进行对齐，以解决一般推荐任务。&lt;h4&gt;8. 实验评估&lt;/h4&gt;   - 在评估中，将P4R与最先进的推荐模型进行比较，评估基于提示的个人资料生成质量。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Recommender Systems (RS) have witnessed a transformativeshift with the advent of Large Language Models (LLMs) in the field of NaturalLanguage Processing (NLP). Models such as GPT-3.5/4, Llama, have demonstratedunprecedented capabilities in understanding and generating human-like text. Theextensive information pre-trained by these LLMs allows for the potential tocapture a more profound semantic representation from different contextualinformation of users and items.  While the great potential lies behind the thriving of LLMs, the challenge ofleveraging user-item preferences from contextual information and its alignmentwith the improvement of Recommender Systems needs to be addressed. Believingthat a better understanding of the user or item itself can be the key factor inimproving recommendation performance, we conduct research on generatinginformative profiles using state-of-the-art LLMs.  To boost the linguistic abilities of LLMs in Recommender Systems, weintroduce the Prompting-Based Representation Learning Method for Recommendation(P4R). In our P4R framework, we utilize the LLM prompting strategy to createpersonalized item profiles. These profiles are then transformed into semanticrepresentation spaces using a pre-trained BERT model for text embedding.Furthermore, we incorporate a Graph Convolution Network (GCN) for collaborativefiltering representation. The P4R framework aligns these two embedding spacesin order to address the general recommendation tasks. In our evaluation, wecompare P4R with state-of-the-art Recommender models and assess the quality ofprompt-based profile generation.</description>
      <author>example@mail.com (Junyi Chen, Toyotaro Suzumura)</author>
      <guid isPermaLink="false">2409.16674v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MGNN: Moment Graph Neural Network for Universal Molecular Potentials</title>
      <link>http://arxiv.org/abs/2409.15800v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 高效且稳健的深度学习模型在分子系统表示中的重要性日益增加，尤其是在科学探索中。&lt;h4&gt;2. 技术进展&lt;/h4&gt;   - 消息传递神经网络的出现标志着图学习的变革，特别是在预测化学性质和加速分子动力学研究方面。&lt;h4&gt;3. 提出方法&lt;/h4&gt;   - 介绍了**Moment Graph Neural Network (MGNN)**，这是一种旋转不变的消息传递神经网络架构。   - MGNN利用三维分子图的时刻表示学习，能够捕捉三维分子结构中固有的微妙空间关系。&lt;h4&gt;4. 性能表现&lt;/h4&gt;   - MGNN在基准数据集（如QM9和修订版MD17）上表现出新一流的性能，超越了现有的相关方法。&lt;h4&gt;5. 动态模拟能力&lt;/h4&gt;   - MGNN在动态模拟中表现出色，能够准确预测复杂系统（如非晶电解质）的结构和动力学性质，其结果与从头算模拟结果高度一致。&lt;h4&gt;6. 应用前景&lt;/h4&gt;   - MGNN在分子光谱模拟中的应用展示了其显著提升计算工作流程的潜力，为传统电子结构方法提供了一种有前景的替代方案。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The quest for efficient and robust deep learning models for molecular systemsrepresentation is increasingly critical in scientific exploration. The adventof message passing neural networks has marked a transformative era ingraph-based learning, particularly in the realm of predicting chemicalproperties and expediting molecular dynamics studies. We present the MomentGraph Neural Network (MGNN), a rotation-invariant message passing neuralnetwork architecture that capitalizes on the moment representation learning of3D molecular graphs, is adept at capturing the nuanced spatial relationshipsinherent in three-dimensional molecular structures. MGNN demonstrates newstate-of-the-art performance over contemporary methods on benchmark datasetssuch as QM9 and the revised MD17. The prowess of MGNN also extends to dynamicsimulations, accurately predicting the structural and kinetic properties ofcomplex systems such as amorphous electrolytes, with results that closely alignwith those from ab-initio simulations. The application of MGNN to thesimulation of molecular spectra exemplifies its potential to significantlyenhance the computational workflow, offering a promising alternative totraditional electronic structure methods</description>
      <author>example@mail.com (Jian Chang, Shuze Zhu)</author>
      <guid isPermaLink="false">2409.15800v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Any-Point Tracking by Contrastive Random Walks</title>
      <link>http://arxiv.org/abs/2409.16288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024. Project link: https://ayshrv.com/gmrw . Code:
  https://github.com/ayshrv/gmrw/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 提出一种简单的自监督方法来解决“任何点跟踪”（TAP）问题。&lt;h4&gt;2. 方法概述&lt;/h4&gt;   - 训练一个全局匹配变换器，通过对比随机游走找到视频中的循环一致轨迹。   - 利用变换器的注意力机制进行全局匹配，定义在时空图上的随机游走转移矩阵。&lt;h4&gt;3. 技术优势&lt;/h4&gt;   - 能够进行“全对”比较，使模型获得高空间精度和强对比学习信号，避免了许多复杂的现有方法（如粗到细匹配）。&lt;h4&gt;4. 设计决策&lt;/h4&gt;   - 提出了多个设计决策，使得全局匹配架构能够通过循环一致性进行自我监督训练。   - 识别到基于变换器的方法对捷径解决方案敏感，因此提出了一种数据增强方案以应对这一问题。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 在TapVid基准测试上取得了强劲的表现，超越了之前的自监督跟踪方法（如DIFT），并与多种监督方法具有竞争力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ayshrv/gmrw&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a simple, self-supervised approach to the Tracking Any Point (TAP)problem. We train a global matching transformer to find cycle consistent tracksthrough video via contrastive random walks, using the transformer'sattention-based global matching to define the transition matrices for a randomwalk on a space-time graph. The ability to perform "all pairs" comparisonsbetween points allows the model to obtain high spatial precision and to obtaina strong contrastive learning signal, while avoiding many of the complexitiesof recent approaches (such as coarse-to-fine matching). To do this, we proposea number of design decisions that allow global matching architectures to betrained through self-supervision using cycle consistency. For example, weidentify that transformer-based methods are sensitive to shortcut solutions,and propose a data augmentation scheme to address them. Our method achievesstrong performance on the TapVid benchmarks, outperforming previousself-supervised tracking methods, such as DIFT, and is competitive with severalsupervised methods.</description>
      <author>example@mail.com (Ayush Shrivastava, Andrew Owens)</author>
      <guid isPermaLink="false">2409.16288v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Multiple-Exit Tuning: Towards Inference-Efficient Adaptation for Vision Transformer</title>
      <link>http://arxiv.org/abs/2409.13999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages,13 figures,6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 参数高效的迁移学习（PETL）在将预训练的视觉变换器（ViT）适应于各种下游任务方面展现出巨大潜力。&lt;h4&gt;2. 现有问题&lt;/h4&gt;   - 现有研究主要集中在最小化可学习参数的数量，这虽然节省存储，但在简单样本上分配了过多的计算资源，导致推理效率低下。&lt;h4&gt;3. 提出方法&lt;/h4&gt;   - 引入了一种名为多出口调优（MET）的推理高效调优方法。   - MET在预训练的ViT主干网络中集成了多个出口，每个出口配备一个线性预测头。&lt;h4&gt;4. 推理机制&lt;/h4&gt;   - 在推理阶段，简单样本会在早期出口退出，只有足够困难的样本才会流向最后的出口，从而节省简单样本的计算成本。&lt;h4&gt;5. 组成部分&lt;/h4&gt;   - **出口特定适配器（E-adapters）**：设计用于提取适合不同出口的表示。   - 为确保参数效率，所有E-adapters共享相同的下投影和上投影矩阵。&lt;h4&gt;6. 图正则化&lt;/h4&gt;   - 由于线性分类器的性能受样本之间关系的影响，采用图正则化来改善输入到早期出口分类器的表示。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 进行了大量实验以验证MET的性能，结果显示MET在准确性和推理效率方面明显优于最先进的方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient transfer learning (PETL) has shown great potential inadapting a vision transformer (ViT) pre-trained on large-scale datasets tovarious downstream tasks. Existing studies primarily focus on minimizing thenumber of learnable parameters. Although these methods are storage-efficient,they allocate excessive computational resources to easy samples, leading toinefficient inference. To address this issue, we introduce aninference-efficient tuning method termed multiple-exit tuning (MET). METintegrates multiple exits into the pre-trained ViT backbone. Since thepredictions in ViT are made by a linear classifier, each exit is equipped witha linear prediction head. In inference stage, easy samples will exit at earlyexits and only hard enough samples will flow to the last exit, thus saving thecomputational cost for easy samples. MET consists of exit-specific adapters(E-adapters) and graph regularization. E-adapters are designed to extractsuitable representations for different exits. To ensure parameter efficiency,all E-adapters share the same down-projection and up-projection matrices. Asthe performances of linear classifiers are influenced by the relationship amongsamples, we employ graph regularization to improve the representations fed intothe classifiers at early exits. Finally, we conduct extensive experiments toverify the performance of MET. Experimental results show that MET has anobvious advantage over the state-of-the-art methods in terms of both accuracyand inference efficiency.</description>
      <author>example@mail.com (Zheng Liu, Jinchao Zhu, Nannan Li, Gao Huang)</author>
      <guid isPermaLink="false">2409.13999v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>CadVLM: Bridging Language and Vision in the Generation of Parametric CAD Sketches</title>
      <link>http://arxiv.org/abs/2409.17457v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 参数化计算机辅助设计（CAD）在现代机械设计中至关重要。   - 当前面临在精确参数化草图建模方面的挑战，并且缺乏适合机械设计的实用评估指标。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 利用预训练基础模型的能力，这些模型在自然语言处理和计算机视觉中表现优异，开发专门用于CAD的生成模型。&lt;h4&gt;3. 技术创新&lt;/h4&gt;   - 提出了CadVLM，一种端到端的视觉语言模型，用于CAD生成。   - 该方法将预训练基础模型进行适应，以有效处理工程草图，整合草图原始序列和草图图像。&lt;h4&gt;4. 实验结果&lt;/h4&gt;   - 通过广泛实验，展示了在多个CAD草图生成任务上的优越表现，包括：     - CAD自动补全     - CAD自动约束     - 图像条件生成&lt;h4&gt;5. 研究贡献&lt;/h4&gt;   - 这是首次将多模态大型语言模型成功应用于参数化CAD生成，标志着计算机辅助机械设计领域的开创性进展。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parametric Computer-Aided Design (CAD) is central to contemporary mechanicaldesign. However, it encounters challenges in achieving precise parametricsketch modeling and lacks practical evaluation metrics suitable for mechanicaldesign. We harness the capabilities of pre-trained foundation models, renownedfor their successes in natural language processing and computer vision, todevelop generative models specifically for CAD. These models are adept atunderstanding complex geometries and design reasoning, a crucial advancement inCAD technology. In this paper, we propose CadVLM, an end-to-end vision languagemodel for CAD generation. Our approach involves adapting pre-trained foundationmodels to manipulate engineering sketches effectively, integrating both sketchprimitive sequences and sketch images. Extensive experiments demonstratesuperior performance on multiple CAD sketch generation tasks such as CADautocompletion, CAD autoconstraint, and image conditional generation. To ourknowledge, this is the first instance of a multimodal Large Language Model(LLM) being successfully applied to parametric CAD generation, representing apioneering step in the field of computer-aided mechanical design.</description>
      <author>example@mail.com (Sifan Wu, Amir Khasahmadi, Mor Katz, Pradeep Kumar Jayaraman, Yewen Pu, Karl Willis, Bang Liu)</author>
      <guid isPermaLink="false">2409.17457v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Using Random Codebooks for Audio Neural AutoEncoders</title>
      <link>http://arxiv.org/abs/2409.16677v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的要点解读：1. **研究背景**：潜在表示学习在多个应用领域已成为活跃的研究领域，持续了数十年。2. **灵感来源**：研究受到自然语言处理中的标记化方法的启发，并致力于寻找简单的数据表示。3. **方法创新**：提出了一种新颖的策略，通过随机代码本构建神经离散表示。   - 这些代码本是通过随机抽样一个大型预定义固定代码本获得的。4. **实验验证**：通过实验展示了该方法在音频压缩和重建任务中的优点和潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Latent representation learning has been an active field of study for decadesin numerous applications. Inspired among others by the tokenization fromNatural Language Processing and motivated by the research of a simple datarepresentation, recent works have introduced a quantization step into thefeature extraction. In this work, we propose a novel strategy to build theneural discrete representation by means of random codebooks. These codebooksare obtained by randomly sampling a large, predefined fixed codebook. Weexperimentally show the merits and potential of our approach in a task of audiocompression and reconstruction.</description>
      <author>example@mail.com (Benoît Giniès, Xiaoyu Bie, Olivier Fercoq, Gaël Richard)</author>
      <guid isPermaLink="false">2409.16677v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Symmetries and Expressive Requirements for Learning General Policies</title>
      <link>http://arxiv.org/abs/2409.15892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 21st International Conference on Principles of
  Knowledge Representation and Reasoning (KR2024) in the Reasoning, Learning,
  and Decision Making track&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;5. 方法论&lt;/h4&gt;   - 将规划状态映射为普通图。   - 使用现成算法确定两个状态是否在目标上同构。   - 使用着色算法判断通过逻辑计算或GNN计算的C₂特征是否能够区分非同构状态。&lt;h4&gt;6. 研究结果&lt;/h4&gt;   - 对称性检测能够提高学习效果。   - 未能检测到非对称性可能导致某些领域无法学习广义策略。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State symmetries play an important role in planning and generalized planning.In the first case, state symmetries can be used to reduce the size of thesearch; in the second, to reduce the size of the training set. In the case ofgeneral planning, however, it is also critical to distinguish non-symmetricstates, i.e., states that represent non-isomorphic relational structures.However, while the language of first-order logic distinguishes non-symmetricstates, the languages and architectures used to represent and learn generalpolicies do not. In particular, recent approaches for learning general policiesuse state features derived from description logics or learned via graph neuralnetworks (GNNs) that are known to be limited by the expressive power of C_2,first-order logic with two variables and counting. In this work, we address theproblem of detecting symmetries in planning and generalized planning and usethe results to assess the expressive requirements for learning general policiesover various planning domains. For this, we map planning states to plaingraphs, run off-the-shelf algorithms to determine whether two states areisomorphic with respect to the goal, and run coloring algorithms to determineif C_2 features computed logically or via GNNs distinguish non-isomorphicstates. Symmetry detection results in more effective learning, while thefailure to detect non-symmetries prevents general policies from being learnedat all in certain domains.</description>
      <author>example@mail.com (Dominik Drexler, Simon Ståhlberg, Blai Bonet, Hector Geffner)</author>
      <guid isPermaLink="false">2409.15892v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Patch-Based Contrastive Learning and Memory Consolidation for Online Unsupervised Continual Learning</title>
      <link>http://arxiv.org/abs/2409.16391v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in Conference on Lifelong Learning Agents (COLLAS) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的要点解读：1. **研究主题**：关注一种相对未被广泛研究的学习范式——在线无监督持续学习（O-UCL），其中特征为代理接收非静态、无标签的数据流，并逐渐学习识别越来越多的类别。2. **应用背景**：此范式旨在模拟现实世界应用，特别是遇到新奇事物的场景，例如探索具有多个未知和随时间变化实体的地形。3. **创新性**：O-UCL将无监督学习、持续学习和在线学习三者结合，形成一个既具挑战性又现实的学习范式。4. **评估机制**：在该环境中，代理需频繁评估，并努力在数据流的每个时刻保持最佳表示，而不是仅在预先指定的离线任务结束时。5. **提出方法**：提出了一种名为**PCMC**（基于补丁的对比学习与记忆巩固）的方法，通过识别和聚类补丁级特征来构建数据的组合理解。6. **特征提取**：使用通过补丁对比学习训练的编码器提取这些补丁级特征的嵌入。7. **避免灾难性遗忘**：PCMC在将新数据纳入其分布时能有效避免灾难性遗忘，并在“睡眠”期间巩固记忆示例。8. **实验评估**：在从ImageNet和Places365数据集创建的数据流上评估PCMC的性能，并探索PCMC算法的不同版本，比较其与现有方法和简单基线的性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We focus on a relatively unexplored learning paradigm known as {\em OnlineUnsupervised Continual Learning} (O-UCL), where an agent receives anon-stationary, unlabeled data stream and progressively learns to identify anincreasing number of classes. This paradigm is designed to model real-worldapplications where encountering novelty is the norm, such as exploring aterrain with several unknown and time-varying entities. Unlike prior work inunsupervised, continual, or online learning, O-UCL combines all three areasinto a single challenging and realistic learning paradigm. In this setting,agents are frequently evaluated and must aim to maintain the best possiblerepresentation at any point of the data stream, rather than at the end ofpre-specified offline tasks. The proposed approach, called \textbf{P}atch-based\textbf{C}ontrastive learning and \textbf{M}emory \textbf{C}onsolidation(PCMC), builds a compositional understanding of data by identifying andclustering patch-level features. Embeddings for these patch-level features areextracted with an encoder trained via patch-based contrastive learning. PCMCincorporates new data into its distribution while avoiding catastrophicforgetting, and it consolidates memory examples during ``sleep" periods. Weevaluate PCMC's performance on streams created from the ImageNet and Places365datasets. Additionally, we explore various versions of the PCMC algorithm andcompare its performance against several existing methods and simple baselines.</description>
      <author>example@mail.com (Cameron Taylor, Vassilis Vassiliades, Constantine Dovrolis)</author>
      <guid isPermaLink="false">2409.16391v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Generalization in birdsong classification: impact of transfer learning methods and dataset characteristics</title>
      <link>http://arxiv.org/abs/2409.15383v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;3. 实验结果&lt;/h4&gt;   - **微调与知识蒸馏**：实验表明，两者均能取得良好表现，尤其是交叉蒸馏在提高Xeno-canto数据集中的领域内表现方面特别有效。   - **浅层微调**：在推广到声景时，浅层微调的表现优于知识蒸馏，显示出其鲁棒性和约束性。4. **多物种标签的研究**：进一步研究如何在存在不完整的多物种标签的情况下进行处理。5. **建议改进**：倡导动物声音社区采取更全面的标注实践，包括标注背景物种和提供时间细节，以增强鲁棒鸟类声音分类器的训练。6. **研究贡献**：这些发现为优化预训练模型的重用提供了见解，以推动自动生物声学识别的发展。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Animal sounds can be recognised automatically by machine learning, and thishas an important role to play in biodiversity monitoring. Yet despiteincreasingly impressive capabilities, bioacoustic species classifiers stillexhibit imbalanced performance across species and habitats, especially incomplex soundscapes. In this study, we explore the effectiveness of transferlearning in large-scale bird sound classification across various conditions,including single- and multi-label scenarios, and across different modelarchitectures such as CNNs and Transformers. Our experiments demonstrate thatboth fine-tuning and knowledge distillation yield strong performance, withcross-distillation proving particularly effective in improving in-domainperformance on Xeno-canto data. However, when generalizing to soundscapes,shallow fine-tuning exhibits superior performance compared to knowledgedistillation, highlighting its robustness and constrained nature. Our studyfurther investigates how to use multi-species labels, in cases where these arepresent but incomplete. We advocate for more comprehensive labeling practiceswithin the animal sound community, including annotating background species andproviding temporal details, to enhance the training of robust bird soundclassifiers. These findings provide insights into the optimal reuse ofpretrained models for advancing automatic bioacoustic recognition.</description>
      <author>example@mail.com (Burooj Ghani, Vincent J. Kalkman, Bob Planqué, Willem-Pier Vellinga, Lisa Gill, Dan Stowell)</author>
      <guid isPermaLink="false">2409.15383v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Uni-Med: A Unified Medical Generalist Foundation Model For Multi-Task Learning Via Connector-MoE</title>
      <link>http://arxiv.org/abs/2409.17508v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;4. CMoE模块的优势&lt;/h4&gt;   - 通过精心设计的路由器和混合投影专家，CMoE有效解决了“拉锯战”问题。5. **应用任务**：Uni-Med能够执行六项不同的医疗任务，包括：   - 问答   - 视觉问答   - 报告生成   - 指称表达理解   - 指称表达生成   - 图像分类6. **创新性**：Uni-Med是首个在连接器层面解决多任务干扰的努力。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 大规模消融实验验证了在任意配置下引入CMoE的有效性，平均性能提升达8%。8. **分析视角**：提供了从梯度优化和参数统计的角度分析“拉锯战”问题的解释。9. **评估表现**：与之前最先进的医疗MLLM相比，Uni-Med在多项任务上实现了竞争力或优越的评估指标。10. **资源可用性**：相关代码、数据和模型将在GitHub上发布。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal large language models (MLLMs) have shown impressive capabilitiesas a general-purpose interface for various visual and linguistic tasks.However, building a unified MLLM for multi-task learning in the medical fieldremains a thorny challenge. To mitigate the tug-of-war problem of multi-modalmulti-task optimization, recent advances primarily focus on improving the LLMcomponents, while neglecting the connector that bridges the gap betweenmodalities. In this paper, we introduce Uni-Med, a novel medical generalistfoundation model which consists of a universal visual feature extractionmodule, a connector mixture-of-experts (CMoE) module, and an LLM. Benefitingfrom the proposed CMoE that leverages a well-designed router with a mixture ofprojection experts at the connector, Uni-Med achieves efficient solution to thetug-of-war problem and can perform six different medical tasks includingquestion answering, visual question answering, report generation, referringexpression comprehension, referring expression generation and imageclassification. To the best of our knowledge, Uni-Med is the first effort totackle multi-task interference at the connector. Extensive ablation experimentsvalidate the effectiveness of introducing CMoE under any configuration, with upto an average 8% performance gains. We further provide interpretation analysisof the tug-of-war problem from the perspective of gradient optimization andparameter statistics. Compared to previous state-of-the-art medical MLLMs,Uni-Med achieves competitive or superior evaluation metrics on diverse tasks.Code, data and model will be soon available at GitHub.</description>
      <author>example@mail.com (Xun Zhu, Ying Hu, Fanbin Mo, Miao Li, Ji Wu)</author>
      <guid isPermaLink="false">2409.17508v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Hyperbolic Image-and-Pointcloud Contrastive Learning for 3D Classification</title>
      <link>http://arxiv.org/abs/2409.15810v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at IROS2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;3. 方法论&lt;/h4&gt;   - **模态内部分支**：利用点云的内在几何结构探索其在超曲面空间中的嵌入表示，以捕捉不变特征。   - **跨模态分支**：利用图像指导点云建立强语义层次关联。&lt;h4&gt;4. 实验结果&lt;/h4&gt;   - 实证实验表明，HyperIPC在分类性能上表现优秀，特别是在ScanObjectNN数据集上，相比基线模型，物体分类结果提升了2.8%，少样本分类结果提升了5.9%。&lt;h4&gt;5. 验证与分析&lt;/h4&gt;   - 进行的消融研究和确认测试验证了HyperIPC参数设置的合理性及其子模块的有效性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D contrastive representation learning has exhibited remarkable efficacyacross various downstream tasks. However, existing contrastive learningparadigms based on cosine similarity fail to deeply explore the potentialintra-modal hierarchical and cross-modal semantic correlations aboutmulti-modal data in Euclidean space. In response, we seek solutions inhyperbolic space and propose a hyperbolic image-and-pointcloud contrastivelearning method (HyperIPC). For the intra-modal branch, we rely on theintrinsic geometric structure to explore the hyperbolic embeddingrepresentation of point cloud to capture invariant features. For thecross-modal branch, we leverage images to guide the point cloud in establishingstrong semantic hierarchical correlations. Empirical experiments underscore theoutstanding classification performance of HyperIPC. Notably, HyperIPC enhancesobject classification results by 2.8% and few-shot classification outcomes by5.9% on ScanObjectNN compared to the baseline. Furthermore, ablation studiesand confirmatory testing validate the rationality of HyperIPC's parametersettings and the effectiveness of its submodules.</description>
      <author>example@mail.com (Naiwen Hu, Haozhe Cheng, Yifan Xie, Pengcheng Shi, Jihua Zhu)</author>
      <guid isPermaLink="false">2409.15810v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Demo2Vec: Learning Region Embedding with Demographic Information</title>
      <link>http://arxiv.org/abs/2409.16837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;3. 方法论&lt;/h4&gt;   - 发现现有基于KL散度的预训练方法可能对流动性信息存在偏见。   - 提议使用Jenson-Shannon散度作为多视图表示学习的更合适的损失函数。&lt;h4&gt;4. 实验结果&lt;/h4&gt;   - 来自纽约和芝加哥的实验结果表明，流动性数据和收入数据的组合是最佳的预训练数据组合，提供比现有模型高出10.22%的预测性能。&lt;h4&gt;5. 建议&lt;/h4&gt;   - 考虑到在许多发展中国家流动性大数据难以获取，建议使用地理距离加收入作为一种简单但有效的区域嵌入预训练数据组合。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Demographic data, such as income, education level, and employment rate,contain valuable information of urban regions, yet few studies have integrateddemographic information to generate region embedding. In this study, we showhow the simple and easy-to-access demographic data can improve the quality ofstate-of-the-art region embedding and provide better predictive performances inurban areas across three common urban tasks, namely check-in prediction, crimerate prediction, and house price prediction. We find that existing pre-trainmethods based on KL divergence are potentially biased towards mobilityinformation and propose to use Jenson-Shannon divergence as a more appropriateloss function for multi-view representation learning. Experimental results fromboth New York and Chicago show that mobility + income is the best pre-traindata combination, providing up to 10.22\% better predictive performances thanexisting models. Considering that mobility big data can be hardly accessible inmany developing cities, we suggest geographic proximity + income to be a simplebut effective data combination for region embedding pre-training.</description>
      <author>example@mail.com (Ya Wen, Yulun Zhou)</author>
      <guid isPermaLink="false">2409.16837v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>AUGUR, A flexible and efficient optimization algorithm for identification of optimal adsorption sites</title>
      <link>http://arxiv.org/abs/2409.16204v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;2. 模型构成&lt;/h4&gt;   - **结合技术**：模型结合图神经网络和高斯过程，创建一个灵活、高效的预测器。   - **特性**：该预测器具有内置的不确定性量化，能够意识到对称性，具备平移和旋转不变性。3. **优化策略**：该预测器作为数据高效的贝叶斯优化方案的替代，旨在确定最佳吸附位置。&lt;h4&gt;4. 性能优势&lt;/h4&gt;   - 相较于当前最先进的方法，AUGUR能够用更少的迭代次数确定复杂集群的最佳位置。   - 不依赖手工特征，能够无缝应用于任何分子，无需进行修改。5. **模型适应性**：图的池化特性使得同一模型能够处理不同大小的分子，从而实现对计算要求高的系统的能量预测，这些系统是通过在相对较小且成本低的系统上训练的模型来实现的。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel flexible optimization pipeline fordetermining the optimal adsorption sites, named AUGUR (Aware of UncertaintyGraph Unit Regression). Our model combines graph neural networks and Gaussianprocesses to create a flexible, efficient, symmetry-aware, translation, androtation-invariant predictor with inbuilt uncertainty quantification. Thispredictor is then used as a surrogate for a data-efficient BayesianOptimization scheme to determine the optimal adsorption positions. Thispipeline determines the optimal position of large and complicated clusters withfar fewer iterations than current state-of-the-art approaches. Further, it doesnot rely on hand-crafted features and can be seamlessly employed on anymolecule without any alterations. Additionally, the pooling properties ofgraphs allow for the processing of molecules of different sizes by the samemodel. This allows the energy prediction of computationally demanding systemsby a model trained on comparatively smaller and less expensive ones</description>
      <author>example@mail.com (Ioannis Kouroudis, Poonam, Neel Misciaci, Felix Mayr, Leon Müller, Zhaosu Gu, Alessio Gagliardi)</author>
      <guid isPermaLink="false">2409.16204v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Selection of Prompt Engineering Techniques for Code Generation through Predicting Code Complexity</title>
      <link>http://arxiv.org/abs/2409.16416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages + reference&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;3. 选择挑战&lt;/h4&gt;   - **交互提示技术**：可能无法始终如预期般提供好处，尤其是在处理简单查询时。   - **自动化提示工程方法**：缺乏适应性，未能充分利用多阶段响应。4. **提出的解决方案**：提出PET-Select，这是一种与PET无关的选择模型，利用代码复杂性作为代理来分类查询并选择最合适的PET。&lt;h4&gt;5. 方法论&lt;/h4&gt;   - 结合对比学习，PET-Select有效区分简单和复杂问题，从而选择最适合每个查询复杂性级别的PET。&lt;h4&gt;6. 实验评估&lt;/h4&gt;   - 在MBPP和HumanEval基准上使用GPT-3.5 Turbo和GPT-4o进行评估，显示出高达1.9%的pass@1准确性提升，以及74.8%的令牌使用减少。7. **结果展示**：提供定量和定性的结果，展示PET-Select如何有效选择最合适的技术来处理每个代码生成查询，进一步强调其在优化PET选择方面的效率。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have demonstrated impressive performance insoftware engineering tasks. However, improving their accuracy in generatingcorrect and reliable code remains challenging. Numerous prompt engineeringtechniques (PETs) have been developed to address this, but no single approachis universally optimal. Selecting the right PET for each query is difficult fortwo primary reasons: (1) interactive prompting techniques may not consistentlydeliver the expected benefits, especially for simpler queries, and (2) currentautomated prompt engineering methods lack adaptability and fail to fullyutilize multi-stage responses. To overcome these challenges, we proposePET-Select, a PET-agnostic selection model that uses code complexity as a proxyto classify queries and select the most appropriate PET. By incorporatingcontrastive learning, PET-Select effectively distinguishes between simple andcomplex problems, allowing it to choose PETs that are best suited for eachquery's complexity level. Our evaluations on the MBPP and HumanEval benchmarksusing GPT-3.5 Turbo and GPT-4o show up to a 1.9% improvement in pass@1accuracy, along with a 74.8% reduction in token usage. Additionally, we provideboth quantitative and qualitative results to demonstrate how PET-Selecteffectively selects the most appropriate techniques for each code generationquery, further showcasing its efficiency in optimizing PET selection.</description>
      <author>example@mail.com (Chung-Yu Wang, Alireza DaghighFarsoodeh, Hung Viet Pham)</author>
      <guid isPermaLink="false">2409.16416v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>From Lazy to Rich: Exact Learning Dynamics in Deep Linear Networks</title>
      <link>http://arxiv.org/abs/2409.14623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;4. 方法论&lt;/h4&gt;   - 推导出lambda平衡初始化的精确解，这种初始化由各层权重的相对规模定义。&lt;h4&gt;5. 研究发现&lt;/h4&gt;   - 这些解能够捕捉表征的演变及神经切线核在丰富和懒惰状态之间的变化。6. **理论贡献**：研究加深了对权重初始化对学习状态影响的理论理解。7. **实际应用**：这些发现对持续学习、逆向学习和迁移学习具有重要意义，适用于神经科学和实际应用。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Biological and artificial neural networks develop internal representationsthat enable them to perform complex tasks. In artificial networks, theeffectiveness of these models relies on their ability to build task specificrepresentation, a process influenced by interactions among datasets,architectures, initialization strategies, and optimization algorithms. Priorstudies highlight that different initializations can place networks in either alazy regime, where representations remain static, or a rich/feature learningregime, where representations evolve dynamically. Here, we examine howinitialization influences learning dynamics in deep linear neural networks,deriving exact solutions for lambda-balanced initializations-defined by therelative scale of weights across layers. These solutions capture the evolutionof representations and the Neural Tangent Kernel across the spectrum from therich to the lazy regimes. Our findings deepen the theoretical understanding ofthe impact of weight initialization on learning regimes, with implications forcontinual learning, reversal learning, and transfer learning, relevant to bothneuroscience and practical applications.</description>
      <author>example@mail.com (Clémentine C. J. Dominé, Nicolas Anguita, Alexandra M. Proca, Lukas Braun, Daniel Kunin, Pedro A. M. Mediano, Andrew M. Saxe)</author>
      <guid isPermaLink="false">2409.14623v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>RmGPT: Rotating Machinery Generative Pretrained Model</title>
      <link>http://arxiv.org/abs/2409.17604v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;3. 新框架&lt;/h4&gt;   - **标记基础框架**：RmGPT引入了一种新颖的基于标记的框架，包含信号标记、提示标记、时频任务标记和故障标记，以便在统一的模型架构中处理异构数据。&lt;h4&gt;4. 学习策略&lt;/h4&gt;   - 利用自监督学习进行稳健特征提取。   - 引入下一信号标记预测的预训练策略，以及高效的提示学习以适应特定任务。5. **实验验证**：大量实验表明，RmGPT显著超越了现有的最先进算法，在诊断任务中实现近乎完美的准确率，在预测任务中表现出极低的错误率。6. **少样本学习优势**：RmGPT在少样本学习场景中表现优异，在16类一次性实验中达到92%的准确率，突显了其适应性和鲁棒性。7. **贡献与前景**：该工作将RmGPT建立为旋转机械的强大PHM基础模型，推动PHM解决方案的可扩展性和通用性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In industry, the reliability of rotating machinery is critical for productionefficiency and safety. Current methods of Prognostics and Health Management(PHM) often rely on task-specific models, which face significant challenges inhandling diverse datasets with varying signal characteristics, fault modes andoperating conditions. Inspired by advancements in generative pretrained models,we propose RmGPT, a unified model for diagnosis and prognosis tasks. RmGPTintroduces a novel token-based framework, incorporating Signal Tokens, PromptTokens, Time-Frequency Task Tokens and Fault Tokens to handle heterogeneousdata within a unified model architecture. We leverage self-supervised learningfor robust feature extraction and introduce a next signal token predictionpretraining strategy, alongside efficient prompt learning for task-specificadaptation. Extensive experiments demonstrate that RmGPT significantlyoutperforms state-of-the-art algorithms, achieving near-perfect accuracy indiagnosis tasks and exceptionally low errors in prognosis tasks. Notably, RmGPTexcels in few-shot learning scenarios, achieving 92% accuracy in 16-classone-shot experiments, highlighting its adaptability and robustness. This workestablishes RmGPT as a powerful PHM foundation model for rotating machinery,advancing the scalability and generalizability of PHM solutions.</description>
      <author>example@mail.com (Yilin Wang, Yifei Yu, Kong Sun, Peixuan Lei, Yuxuan Zhang, Enrico Zio, Aiguo Xia, Yuanxiang Li)</author>
      <guid isPermaLink="false">2409.17604v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>PseudoNeg-MAE: Self-Supervised Point Cloud Learning using Conditional Pseudo-Negative Embeddings</title>
      <link>http://arxiv.org/abs/2409.15832v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICRA2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;3. 新方法的创新&lt;/h4&gt;   - **关系建模**：PseudoNeg-MAE通过一个参数网络COPE显式建模原始数据点与变换数据点之间的关系，学习潜在空间中由变换引起的局部位移。   - **解决训练问题**：联合训练COPE与MAE可能导致不理想的平凡解，使COPE输出退化为恒等映射。4. **新损失函数**：引入新型损失函数，结合伪负样本，有效惩罚这些平凡的不变解，促进嵌入的变换敏感性。5. **实验验证**：在形状分类和相对姿态估计任务中验证PseudoNeg-MAE的有效性。&lt;h4&gt;6. 性能表现&lt;/h4&gt;   - 在ModelNet40和ScanObjectNN数据集上，PseudoNeg-MAE在具有挑战性的评估协议下实现了最先进的性能。   - 在相对姿态估计中显示出更高的准确性。7. **结论**：结果表明，PseudoNeg-MAE在学习具有辨别性和变换敏感性的表示方面具有有效性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose PseudoNeg-MAE, a novel self-supervised learning framework thatenhances global feature representation of point cloud mask autoencoder bymaking them both discriminative and sensitive to transformations. Traditionalcontrastive learning methods focus on achieving invariance, which can lead tothe loss of valuable transformation-related information. In contrast,PseudoNeg-MAE explicitly models the relationship between original andtransformed data points using a parametric network COPE, which learns thelocalized displacements caused by transformations within the latent space.However, jointly training COPE with the MAE leads to undesirable trivialsolutions where COPE outputs collapse to an identity. To address this, weintroduce a novel loss function incorporating pseudo-negatives, whicheffectively penalizes these trivial invariant solutions and promotestransformation sensitivity in the embeddings. We validate PseudoNeg-MAE onshape classification and relative pose estimation tasks, where PseudoNeg-MAEachieves state-of-the-art performance on the ModelNet40 and ScanObjectNNdatasets under challenging evaluation protocols and demonstrates superioraccuracy in estimating relative poses. These results show the effectiveness ofPseudoNeg-MAE in learning discriminative and transformation-sensitiverepresentations.</description>
      <author>example@mail.com (Sutharsan Mahendren, Saimunur Rahman, Piotr Koniusz, Tharindu Fernando, Sridha Sridharan, Clinton Fookes, Peyman Moghadam)</author>
      <guid isPermaLink="false">2409.15832v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Context-Conditioned Spatio-Temporal Predictive Learning for Reliable V2V Channel Prediction</title>
      <link>http://arxiv.org/abs/2409.09978v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;4. 提出的方法&lt;/h4&gt;   - **上下文条件的时空预测学习方法**：利用因果卷积长短期记忆网络（CA-ConvLSTM）有效捕捉4D CSI数据中的依赖性。   - **上下文条件的注意机制**：增强时空记忆更新的效率。5. **创新点**：引入适用于递归网络的自适应元学习方案，以减轻累积预测误差的问题。6. **实验验证**：通过在三种不同几何配置和移动场景中进行实证研究来验证所提出的方法。&lt;h4&gt;7. 结果展示&lt;/h4&gt;   - 该方法在各几何形状上优于现有的最先进预测模型。   - 元学习框架显著提升了递归预测模型在高度挑战的跨几何设置中的性能，彰显了其稳健性和适应性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Achieving reliable multidimensional Vehicle-to-Vehicle (V2V) channel stateinformation (CSI) prediction is both challenging and crucial for optimizingdownstream tasks that depend on instantaneous CSI. This work extendstraditional prediction approaches by focusing on four-dimensional (4D) CSI,which includes predictions over time, bandwidth, and antenna (TX and RX) space.Such a comprehensive framework is essential for addressing the dynamic natureof mobility environments within intelligent transportation systems,necessitating the capture of both temporal and spatial dependencies acrossdiverse domains. To address this complexity, we propose a novelcontext-conditioned spatiotemporal predictive learning method. This methodleverages causal convolutional long short-term memory (CA-ConvLSTM) toeffectively capture dependencies within 4D CSI data, and incorporatescontext-conditioned attention mechanisms to enhance the efficiency ofspatiotemporal memory updates. Additionally, we introduce an adaptivemeta-learning scheme tailored for recurrent networks to mitigate the issue ofaccumulative prediction errors. We validate the proposed method throughempirical studies conducted across three different geometric configurations andmobility scenarios. Our results demonstrate that the proposed approachoutperforms existing state-of-the-art predictive models, achieving superiorperformance across various geometries. Moreover, we show that the meta-learningframework significantly enhances the performance of recurrent-based predictivemodels in highly challenging cross-geometry settings, thus highlighting itsrobustness and adaptability.</description>
      <author>example@mail.com (Lei Chu, Daoud Burghal, Rui Wang, Michael Neuman, Andreas F. Molisch)</author>
      <guid isPermaLink="false">2409.09978v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Pre-trained Graphformer-based Ranking at Web-scale Search (Extended Abstract)</title>
      <link>http://arxiv.org/abs/2409.16590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的要点解读：1. **研究背景**：Transformer和图神经网络（GNN）在学习排序（LTR）领域得到应用，但这两种方法遵循不同的、互补的问题表述：   - **Transformer**：基于查询-网页对进行排名分数回归。   - **GNN**：在查询-网页二分图中进行链接预测。2. **现有挑战**：尽管可以在源数据集上预训练GNN或Transformer，并在稀疏标注的LTR数据集上进行微调，但由于配对和二分图领域之间的分布转变，整合这些异构模型到统一的LTR框架中存在显著挑战。3. **提出的解决方案**：引入了新颖的MPGraf模型，采用模块化和胶囊式的预训练策略，旨在将Transformer的回归能力与GNN的链接预测优势有效结合。4. **实验验证**：进行了广泛的离线和在线实验，以严格评估MPGraf的性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Both Transformer and Graph Neural Networks (GNNs) have been employed in thedomain of learning to rank (LTR). However, these approaches adhere to twodistinct yet complementary problem formulations: ranking score regression basedon query-webpage pairs, and link prediction within query-webpage bipartitegraphs, respectively. While it is possible to pre-train GNNs or Transformers onsource datasets and subsequently fine-tune them on sparsely annotated LTRdatasets, the distributional shifts between the pair-based and bipartite graphdomains present significant challenges in integrating these heterogeneousmodels into a unified LTR framework at web scale. To address this, we introducethe novel MPGraf model, which leverages a modular and capsule-basedpre-training strategy, aiming to cohesively integrate the regressioncapabilities of Transformers with the link prediction strengths of GNNs. Weconduct extensive offline and online experiments to rigorously evaluate theperformance of MPGraf.</description>
      <author>example@mail.com (Yuchen Li, Haoyi Xiong, Linghe Kong, Zeyi Sun, Hongyang Chen, Shuaiqiang Wang, Dawei Yin)</author>
      <guid isPermaLink="false">2409.16590v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Semi-LLIE: Semi-supervised Contrastive Learning with Mamba-based Low-light Image Enhancement</title>
      <link>http://arxiv.org/abs/2409.16604v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;4. 解决方案&lt;/h4&gt;   - 引入语义感知对比损失，以准确转移光照分布，增强图像的自然色彩。   - 设计基于Mamba的低光照图像增强骨干网络，通过多尺度特征学习方案，增强局部区域像素关系的表示能力，从而生成丰富纹理细节的图像。   - 提出基于大规模视觉-语言识别模型（RAM）的新型感知损失，帮助生成具有更丰富文本细节的增强图像。5. **实验结果**：实验结果表明，Semi-LLIE在定量和定性指标上均超过现有方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the impressive advancements made in recent low-light imageenhancement techniques, the scarcity of paired data has emerged as asignificant obstacle to further advancements. This work proposes amean-teacher-based semi-supervised low-light enhancement (Semi-LLIE) frameworkthat integrates the unpaired data into model training. The mean-teachertechnique is a prominent semi-supervised learning method, successfully adoptedfor addressing high-level and low-level vision tasks. However, two primaryissues hinder the naive mean-teacher method from attaining optimal performancein low-light image enhancement. Firstly, pixel-wise consistency loss isinsufficient for transferring realistic illumination distribution from theteacher to the student model, which results in color cast in the enhancedimages. Secondly, cutting-edge image enhancement approaches fail to effectivelycooperate with the mean-teacher framework to restore detailed information indark areas due to their tendency to overlook modeling structured informationwithin local regions. To mitigate the above issues, we first introduce asemantic-aware contrastive loss to faithfully transfer the illuminationdistribution, contributing to enhancing images with natural colors. Then, wedesign a Mamba-based low-light image enhancement backbone to effectivelyenhance Mamba's local region pixel relationship representation ability with amulti-scale feature learning scheme, facilitating the generation of images withrich textural details. Further, we propose novel perceptive loss based on thelarge-scale vision-language Recognize Anything Model (RAM) to help generateenhanced images with richer textual details. The experimental results indicatethat our Semi-LLIE surpasses existing methods in both quantitative andqualitative metrics.</description>
      <author>example@mail.com (Guanlin Li, Ke Zhang, Ting Wang, Ming Li, Bin Zhao, Xuelong Li)</author>
      <guid isPermaLink="false">2409.16604v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Cross-lingual Human-Preference Alignment for Neural Machine Translation with Direct Quality Optimization</title>
      <link>http://arxiv.org/abs/2409.17673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的要点解读：1. **研究背景**：强化学习与人类反馈（RLHF）及其衍生技术（如直接偏好优化DPO）是用于将通用基础模型调整为特定任务的算法。2. **研究问题**：在神经机器翻译（NMT）中，存在任务与数据的不匹配问题。3. **研究贡献**：将任务对齐应用于NMT，能够改善多语言模型在所有语言上的表现，即使任务对齐仅应用于部分语言。4. **新方法**：引入直接质量优化（DQO），这是DPO的一种变体，利用预训练的翻译质量评估模型作为人类偏好的代理。5. **验证方法**：通过自动化指标和人工评估验证了所提出方法的改进效果。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning from Human Feedback (RLHF) and derivative techniqueslike Direct Preference Optimization (DPO) are task-alignment algorithms used torepurpose general, foundational models for specific tasks. We show thatapplying task-alignment to neural machine translation (NMT) addresses anexisting task--data mismatch in NMT, leading to improvements across alllanguages of a multilingual model, even when task-alignment is only applied toa subset of those languages. We do so by introducing Direct QualityOptimization (DQO), a variant of DPO leveraging a pre-trained translationquality estimation model as a proxy for human preferences, and verify theimprovements with both automatic metrics and human evaluation.</description>
      <author>example@mail.com (Kaden Uhlig, Joern Wuebker, Raphael Reinauer, John DeNero)</author>
      <guid isPermaLink="false">2409.17673v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Articulated Object Manipulation using Online Axis Estimation with SAM2-Based Tracking</title>
      <link>http://arxiv.org/abs/2409.16287v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page:
  https://hytidel.github.io/video-tracking-for-axis-estimation/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;4. 方法细节&lt;/h4&gt;   - **交互感知基础**：利用任意交互感知技术，通过轻微物体移动生成动态场景的点云帧。   - **点云分割**：使用Segment Anything Model 2（SAM2）对这些点云进行分割，遮罩移动部分以实现准确的在线轴线估计。5. **成果**：该方法显著提升了涉及关节物体操控任务的精确性和效率。6. **实验验证**：在模拟环境中的实验表明，该方法在需要精确轴线控制的任务中优于基线方法。 7. **项目页面**：[项目页面](https://hytidel.github.io/video-tracking-for-axis-estimation/) 提供了更多相关信息。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Articulated object manipulation requires precise object interaction, wherethe object's axis must be carefully considered. Previous research employedinteractive perception for manipulating articulated objects, but typically,open-loop approaches often suffer from overlooking the interaction dynamics. Toaddress this limitation, we present a closed-loop pipeline integratinginteractive perception with online axis estimation from segmented 3D pointclouds. Our method leverages any interactive perception technique as afoundation for interactive perception, inducing slight object movement togenerate point cloud frames of the evolving dynamic scene. These point cloudsare then segmented using Segment Anything Model 2 (SAM2), after which themoving part of the object is masked for accurate motion online axis estimation,guiding subsequent robotic actions. Our approach significantly enhances theprecision and efficiency of manipulation tasks involving articulated objects.Experiments in simulated environments demonstrate that our method outperformsbaseline approaches, especially in tasks that demand precise axis-basedcontrol. Project Page:https://hytidel.github.io/video-tracking-for-axis-estimation/.</description>
      <author>example@mail.com (Xi Wang, Tianxing Chen, Qiaojun Yu, Tianling Xu, Zanxin Chen, Yiting Fu, Cewu Lu, Yao Mu, Ping Luo)</author>
      <guid isPermaLink="false">2409.16287v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>3D Unsupervised Learning by Distilling 2D Open-Vocabulary Segmentation Models for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2405.15286v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures, codes are available at
  https://github.com/sbysbysbys/UOV&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的要点解读：1. **研究背景**：点云数据标注在自动驾驶中被认为是一项耗时且昂贵的任务，而无监督学习可以通过从未标注的数据中学习点云表示来避免这一问题。2. **提出的方法**：本文提出了一种名为 UOV 的新颖3D无监督框架，该框架借助2D开放词汇分割模型进行辅助。3. **框架结构**：UOV框架分为两个阶段：   - **第一阶段**：创新性地整合高质量的文本和图像特征，提出三模态对比预训练（Tri-Modal contrastive Pre-training，TMP）。   - **第二阶段**：利用点云和图像之间的空间映射生成伪标签，实现跨模态知识蒸馏。4. **技术细节**：引入近似平面交互（Approximate Flat Interaction，AFI）方法，以解决对齐过程中的噪声和标签混淆问题。5. **实验验证**：在多个相关数据集上进行了广泛实验，以验证UOV的优越性。6. **性能结果**：在nuScenes数据集的无标注点云分割任务中，UOV达到了创纪录的47.73% mIoU，超越了之前最佳模型10.70% mIoU。7. **微调表现**：在nuScenes和SemanticKITTI数据集上，使用1%数据的微调性能分别达到了51.75% mIoU和48.14% mIoU，超越了所有之前的预训练模型。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-05-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sbysbysbys/uov&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud data labeling is considered a time-consuming and expensive taskin autonomous driving, whereas unsupervised learning can avoid it by learningpoint cloud representations from unannotated data. In this paper, we proposeUOV, a novel 3D Unsupervised framework assisted by 2D Open-Vocabularysegmentation models. It consists of two stages: In the first stage, weinnovatively integrate high-quality textual and image features of 2Dopen-vocabulary models and propose the Tri-Modal contrastive Pre-training(TMP). In the second stage, spatial mapping between point clouds and images isutilized to generate pseudo-labels, enabling cross-modal knowledgedistillation. Besides, we introduce the Approximate Flat Interaction (AFI) toaddress the noise during alignment and label confusion. To validate thesuperiority of UOV, extensive experiments are conducted on multiple relateddatasets. We achieved a record-breaking 47.73% mIoU on the annotation-freepoint cloud segmentation task in nuScenes, surpassing the previous best modelby 10.70% mIoU. Meanwhile, the performance of fine-tuning with 1% data onnuScenes and SemanticKITTI reached a remarkable 51.75% mIoU and 48.14% mIoU,outperforming all previous pre-trained models.</description>
      <author>example@mail.com (Boyi Sun, Yuhang Liu, Xingxia Wang, Bin Tian, Long Chen, Fei-Yue Wang)</author>
      <guid isPermaLink="false">2405.15286v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Domain-Independent Automatic Generation of Descriptive Texts for Time-Series Data</title>
      <link>http://arxiv.org/abs/2409.16647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的要点解读：1. **研究背景**：由于缺乏带有描述性文本的时间序列数据，训练生成描述性文本的模型面临挑战。2. **研究目标**：本研究提出了一种系统生成与时间序列数据无关的描述性文本的方法。3. **方法论**：识别出两种创建时间序列数据与描述性文本对的方法：   - **前向方法**：从时间序列数据生成描述文本。   - **后向方法**：通过描述文本生成时间序列数据。4. **数据集构建**：实施了新颖的后向方法，创建了“观察的时间自动标题”（TACO）数据集。5. **实验结果**：实验结果表明，基于对比学习的模型在使用TACO数据集训练后，能够为新领域的时间序列数据生成描述性文本。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to scarcity of time-series data annotated with descriptive texts,training a model to generate descriptive texts for time-series data ischallenging. In this study, we propose a method to systematically generatedomain-independent descriptive texts from time-series data. We identify twodistinct approaches for creating pairs of time-series data and descriptivetexts: the forward approach and the backward approach. By implementing thenovel backward approach, we create the Temporal Automated Captions forObservations (TACO) dataset. Experimental results demonstrate that acontrastive learning based model trained using the TACO dataset is capable ofgenerating descriptive texts for time-series data in novel domains.</description>
      <author>example@mail.com (Kota Dohi, Aoi Ito, Harsh Purohit, Tomoya Nishida, Takashi Endo, Yohei Kawaguchi)</author>
      <guid isPermaLink="false">2409.16647v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning</title>
      <link>http://arxiv.org/abs/2409.16684v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的要点解读：1. **研究背景**：图学习中的图去学习（Graph unlearning）旨在消除特定节点、边或属性对训练的图神经网络（GNN）的影响，尤其在隐私、偏见或数据过时等应用中至关重要。2. **现有问题**：现有的图去学习技术通常需要在剩余数据上进行额外训练，导致在大规模图上出现显著的计算成本。3. **提出的方法**：我们提出了一种两阶段的无训练方法，称为“删除然后修正”（Erase then Rectify, ETR），旨在高效且可扩展地进行图去学习，同时保持模型的有效性。4. **理论基础**：首先建立理论基础，表明掩蔽对未学习样本关键的模型参数能够实现有效的去学习。5. **“删除”阶段**：该阶段通过策略性地编辑模型参数，消除未学习样本及其对相关节点的传播影响。6. **“修正”阶段**：为确保GNN的有效性，设计了一种梯度近似方法，以估计模型在剩余数据集上的梯度，并用于增强模型性能。7. **优势**：ETR实现了图去学习，无需额外训练或完全访问训练数据，显著减少计算开销，同时保护数据隐私。8. **实验结果**：在七个公共数据集上的广泛实验表明，ETR在模型有效性、去学习效率和去学习效果上具有一致的优势，确立其作为现实世界图去学习挑战的有前景的解决方案。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph unlearning, which aims to eliminate the influence of specific nodes,edges, or attributes from a trained Graph Neural Network (GNN), is essential inapplications where privacy, bias, or data obsolescence is a concern. However,existing graph unlearning techniques often necessitate additional training onthe remaining data, leading to significant computational costs, particularlywith large-scale graphs. To address these challenges, we propose a two-stagetraining-free approach, Erase then Rectify (ETR), designed for efficient andscalable graph unlearning while preserving the model utility. Specifically, wefirst build a theoretical foundation showing that masking parameters criticalfor unlearned samples enables effective unlearning. Building on this insight,the Erase stage strategically edits model parameters to eliminate the impact ofunlearned samples and their propagated influence on intercorrelated nodes. Tofurther ensure the GNN's utility, the Rectify stage devises a gradientapproximation method to estimate the model's gradient on the remaining dataset,which is then used to enhance model performance. Overall, ETR achieves graphunlearning without additional training or full training data access,significantly reducing computational overhead and preserving data privacy.Extensive experiments on seven public datasets demonstrate the consistentsuperiority of ETR in model utility, unlearning efficiency, and unlearningeffectiveness, establishing it as a promising solution for real-world graphunlearning challenges.</description>
      <author>example@mail.com (Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu)</author>
      <guid isPermaLink="false">2409.16684v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Instance Segmentation of Reinforced Concrete Bridges with Synthetic Point Clouds</title>
      <link>http://arxiv.org/abs/2409.16381v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 12 figures, Submitted to "Automation in Construction"&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 国家桥梁检查标准要求进行详细的元素级桥梁检查。传统上，检查员通过评估结构组件的损伤来手动分配状态评级，这一过程劳动密集且耗时。&lt;h4&gt;2. 自动化的必要性&lt;/h4&gt;   - 自动化元素级桥梁检查过程可以促进更全面的状态文档记录，从而改善整体桥梁管理。&lt;h4&gt;3. 现有研究的局限&lt;/h4&gt;   - 尽管桥梁点云的语义分割已有研究，但桥梁元素的实例分割研究有限，部分原因是缺乏标注数据集，以及训练模型的泛化难度。&lt;h4&gt;4. 提出的解决方案&lt;/h4&gt;   - 本文提出了一种新颖的方法，通过三种不同的方法生成合成数据，以解决上述问题。&lt;h4&gt;5. 框架和模型&lt;/h4&gt;   - 我们的框架利用Mask3D变换器模型，并通过超参数调整和新颖的遮挡技术进行优化。&lt;h4&gt;6. 性能验证&lt;/h4&gt;   - 模型在真实的LiDAR和摄影测量桥梁点云上实现了最先进的性能，展示了该框架在自动化元素级桥梁检查中的潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The National Bridge Inspection Standards require detailed element-levelbridge inspections. Traditionally, inspectors manually assign condition ratingsby rating structural components based on damage, but this process islabor-intensive and time-consuming. Automating the element-level bridgeinspection process can facilitate more comprehensive condition documentation toimprove overall bridge management. While semantic segmentation of bridge pointclouds has been studied, research on instance segmentation of bridge elementsis limited, partly due to the lack of annotated datasets, and the difficulty ingeneralizing trained models. To address this, we propose a novel approach forgenerating synthetic data using three distinct methods. Our framework leveragesthe Mask3D transformer model, optimized with hyperparameter tuning and a novelocclusion technique. The model achieves state-of-the-art performance on realLiDAR and photogrammetry bridge point clouds, respectively, demonstrating thepotential of the framework for automating element-level bridge inspections.</description>
      <author>example@mail.com (Asad Ur Rahman, Vedhus Hoskere)</author>
      <guid isPermaLink="false">2409.16381v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Towards General Text-guided Image Synthesis for Customized Multimodal Brain MRI Generation</title>
      <link>http://arxiv.org/abs/2409.16818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的要点解读：1. **研究背景**：多模态脑部磁共振成像（MRI）在神经科学和神经病学中至关重要，但由于MRI扫描仪的可获取性和长时间的采集时间，这类图像并不常见。2. **现有问题**：当前的MRI图像合成方法通常在独立数据集上训练，针对特定任务，导致在新数据集和任务上表现不佳。3. **提出的方法**：我们提出了 TUMSyn，一个文本引导的通用MRI图像合成模型，能够根据文本提示灵活生成具有所需成像元数据的脑部MRI图像。4. **数据集构建**：为确保TUMSyn的图像合成精度、多样性和通用性，我们构建了一个包含31,407个3D图像和7种MRI模态的脑部MRI数据库，数据来自13个中心。5. **模型训练**：我们使用对比学习预训练了一个特定于MRI的文本编码器，以有效控制基于文本提示的MRI图像合成。6. **实验结果**：在多样化的数据集和医生评估中，TUMSyn能够在监督和零样本场景下生成具有临床意义的MRI图像。7. **应用前景**：因此，TUMSyn可以与已获取的MRI扫描结合使用，促进大规模基于MRI的脑部疾病筛查和诊断。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Wangyulin-user/TUMSyn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal brain magnetic resonance (MR) imaging is indispensable inneuroscience and neurology. However, due to the accessibility of MRI scannersand their lengthy acquisition time, multimodal MR images are not commonlyavailable. Current MR image synthesis approaches are typically trained onindependent datasets for specific tasks, leading to suboptimal performance whenapplied to novel datasets and tasks. Here, we present TUMSyn, a Text-guidedUniversal MR image Synthesis generalist model, which can flexibly generatebrain MR images with demanded imaging metadata from routinely acquired scansguided by text prompts. To ensure TUMSyn's image synthesis precision,versatility, and generalizability, we first construct a brain MR databasecomprising 31,407 3D images with 7 MRI modalities from 13 centers. We thenpre-train an MRI-specific text encoder using contrastive learning toeffectively control MR image synthesis based on text prompts. Extensiveexperiments on diverse datasets and physician assessments indicate that TUMSyncan generate clinically meaningful MR images with specified imaging metadata insupervised and zero-shot scenarios. Therefore, TUMSyn can be utilized alongwith acquired MR scan(s) to facilitate large-scale MRI-based screening anddiagnosis of brain diseases.</description>
      <author>example@mail.com (Yulin Wang, Honglin Xiong, Kaicong Sun, Shuwei Bai, Ling Dai, Zhongxiang Ding, Jiameng Liu, Qian Wang, Qian Liu, Dinggang Shen)</author>
      <guid isPermaLink="false">2409.16818v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>2024 BRAVO Challenge Track 1 1st Place Report: Evaluating Robustness of Vision Foundation Models for Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2409.17208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: substantial text overlap with arXiv:2409.15107&lt;h3&gt;GPT 摘要:&lt;/h3&gt; 以下是对论文摘要的要点解读：1. **报告主题**：本报告介绍了我们在2024 BRAVO挑战赛第一赛道中的解决方案。2. **数据集**：模型在 Cityscapes 数据集上进行训练，并在多个分布外数据集上评估其鲁棒性。3. **方法**：利用视觉基础模型学习的强大表示，向 DINOv2 附加一个简单的分割解码器，并对整个模型进行微调。4. **效果**：该方法优于现有更复杂的方案，并在挑战中取得第一名。5. **代码公开**：我们的代码已公开可用，链接为 [GitHub - tue-mps/benchmark-vfm-ss](https://github.com/tue-mps/benchmark-vfm-ss)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tue-mps/benchmark-vfm-ss&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this report, we present our solution for Track 1 of the 2024 BRAVOChallenge, where a model is trained on Cityscapes and its robustness isevaluated on several out-of-distribution datasets. Our solution leverages thepowerful representations learned by vision foundation models, by attaching asimple segmentation decoder to DINOv2 and fine-tuning the entire model. Thisapproach outperforms more complex existing approaches, and achieves 1st placein the challenge. Our code is publicly available athttps://github.com/tue-mps/benchmark-vfm-ss.</description>
      <author>example@mail.com (Tommie Kerssies, Daan de Geus, Gijs Dubbelman)</author>
      <guid isPermaLink="false">2409.17208v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Counterfactual Explanations for Clustering Models</title>
      <link>http://arxiv.org/abs/2409.12632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 聚类算法依赖复杂的优化过程，这些过程可能难以理解，尤其是对于缺乏技术专长的个人。&lt;h4&gt;2. 现有问题&lt;/h4&gt;   - 尽管存在许多可解释的人工智能技术用于监督学习，但对于无监督学习，尤其是聚类，相关研究相对较少。   - 定义“真实”聚类本身具有挑战性，这进一步增加了无监督学习及其可解释性的复杂性。&lt;h4&gt;3. 信任与采纳&lt;/h4&gt;   - 这些无监督学习的特点使得人们难以建立对这些方法的信任，从而限制了其广泛应用。&lt;h4&gt;4. 研究目标&lt;/h4&gt;   - 为了解决这些挑战，提出了一种新的模型无关的技术，通过反事实陈述来解释聚类算法。&lt;h4&gt;5. 方法论&lt;/h4&gt;   - 该方法依赖一种新颖的软评分方法，捕捉聚类模型所利用的空间信息。   - 该方法在监督学习的最先进贝叶斯反事实生成器基础上构建，以提供高质量的解释。&lt;h4&gt;6. 性能评估&lt;/h4&gt;   - 在五个数据集和两种聚类算法上评估了该方法的性能，结果表明，引入软评分来指导反事实搜索显著改善了结果。&lt;h4&gt;7. 研究贡献&lt;/h4&gt;   - 该研究为聚类算法的可解释性提供了新的思路，可能促进无监督学习方法的信任和采用。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clustering algorithms rely on complex optimisation processes that may bedifficult to comprehend, especially for individuals who lack technicalexpertise. While many explainable artificial intelligence techniques exist forsupervised machine learning, unsupervised learning -- and clustering inparticular -- has been largely neglected. To complicate matters further, thenotion of a ``true'' cluster is inherently challenging to define. These facetsof unsupervised learning and its explainability make it difficult to fostertrust in such methods and curtail their adoption. To address these challenges,we propose a new, model-agnostic technique for explaining clustering algorithmswith counterfactual statements. Our approach relies on a novel soft-scoringmethod that captures the spatial information utilised by clustering models. Itbuilds upon a state-of-the-art Bayesian counterfactual generator for supervisedlearning to deliver high-quality explanations. We evaluate its performance onfive datasets and two clustering algorithms, and demonstrate that introducingsoft scores to guide counterfactual search significantly improves the results.</description>
      <author>example@mail.com (Aurora Spagnol, Kacper Sokol, Pietro Barbiero, Marc Langheinrich, Martin Gjoreski)</author>
      <guid isPermaLink="false">2409.12632v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Machine Translation Advancements of Low-Resource Indian Languages by Transfer Learning</title>
      <link>http://arxiv.org/abs/2409.15879v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, wmt24. arXiv admin note: substantial text overlap with
  arXiv:2409.14800&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 本文介绍了华为翻译中心（HW-TSC）在WMT24印度语言机器翻译共享任务中的提交，旨在为低资源的印度语言开发可靠的机器翻译系统。&lt;h4&gt;2. 知识转移策略&lt;/h4&gt;   - 采用了两种不同的知识转移策略，考虑了语言书写系统的特点以及现有开源模型对印度语言的支持。&lt;h4&gt;3. 模型优化&lt;/h4&gt;   - 对于阿萨姆语（as）和曼尼普尔语（mn），对现有的IndicTrans2开源模型进行了微调，以实现英语与这两种语言之间的双向翻译。&lt;h4&gt;4. 多语言模型训练&lt;/h4&gt;   - 对于卡西语（kh）和米佐语（mz），使用这四种语言对的双语数据训练了一个多语言模型作为基线，并添加了约8千字的英语-孟加拉语双语数据，所有数据共享某些语言特征。&lt;h4&gt;5. 微调过程&lt;/h4&gt;   - 经过微调，实现了英语与卡西语及米佐语之间的双向翻译。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 转移学习实验产生了显著结果：阿萨姆语到英语（en-as）得分23.5 BLEU，曼尼普尔语到英语（en-mn）得分31.8 BLEU，英语到阿萨姆语（as-en）得分36.2 BLEU，英语到曼尼普尔语（mn-en）得分47.9 BLEU。&lt;h4&gt;7. 多语言模型的表现&lt;/h4&gt;   - 多语言模型的转移学习实验也取得了良好成绩：英语到卡西语（en-kh）得分19.7 BLEU，英语到米佐语（en-mz）得分32.8 BLEU，卡西语到英语（kh-en）得分16.1 BLEU，米佐语到英语（mz-en）得分33.9 BLEU。&lt;h4&gt;8. 研究贡献&lt;/h4&gt;   - 这些结果不仅强调了转移学习技术对低资源语言的有效性，也推动了低资源印度语言的机器翻译能力的发展。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces the submission by Huawei Translation Center (HW-TSC) tothe WMT24 Indian Languages Machine Translation (MT) Shared Task. To develop areliable machine translation system for low-resource Indian languages, weemployed two distinct knowledge transfer strategies, taking into account thecharacteristics of the language scripts and the support available from existingopen-source models for Indian languages. For Assamese(as) and Manipuri(mn), wefine-tuned the existing IndicTrans2 open-source model to enable bidirectionaltranslation between English and these languages. For Khasi (kh) and Mizo (mz),We trained a multilingual model as a baseline using bilingual data from thesefour language pairs, along with an additional about 8kw English-Bengalibilingual data, all of which share certain linguistic features. This wasfollowed by fine-tuning to achieve bidirectional translation between Englishand Khasi, as well as English and Mizo. Our transfer learning experimentsproduced impressive results: 23.5 BLEU for en-as, 31.8 BLEU for en-mn, 36.2BLEU for as-en, and 47.9 BLEU for mn-en on their respective test sets.Similarly, the multilingual model transfer learning experiments yieldedimpressive outcomes, achieving 19.7 BLEU for en-kh, 32.8 BLEU for en-mz, 16.1BLEU for kh-en, and 33.9 BLEU for mz-en on their respective test sets. Theseresults not only highlight the effectiveness of transfer learning techniquesfor low-resource languages but also contribute to advancing machine translationcapabilities for low-resource Indian languages.</description>
      <author>example@mail.com (Bin Wei, Jiawei Zhen, Zongyao Li, Zhanglin Wu, Daimeng Wei, Jiaxin Guo, Zhiqiang Rao, Shaojun Li, Yuanchang Luo, Hengchao Shang, Jinlong Yang, Yuhao Xie, Hao Yang)</author>
      <guid isPermaLink="false">2409.15879v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Predictive Covert Communication Against Multi-UAV Surveillance Using Graph Koopman Autoencoder</title>
      <link>http://arxiv.org/abs/2409.17048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 低探测概率（LPD）通信旨在隐藏无线电频率（RF）信号的存在，以避免监控，尤其是在无人机（UAV）移动监控的背景下。&lt;h4&gt;2. 挑战&lt;/h4&gt;   - 在移动监控中，由于无人机快速且连续的运动具备未知的非线性动态，因此实现LPD通信面临重大挑战。&lt;h4&gt;3. 关键需求&lt;/h4&gt;   - 准确预测无人机的未来位置对于实现实时的LPD通信至关重要。&lt;h4&gt;4. 新框架&lt;/h4&gt;   - 论文提出了一种新框架，称为“预测隐蔽通信”，旨在最小化在多无人机监控下的地面自组网中的可探测性。&lt;h4&gt;5. 数据驱动方法&lt;/h4&gt;   - 该方法结合了图神经网络（GNN）和Koopman理论，以建模多无人机网络中的复杂交互，并通过线性化动态实现长期预测，即使在历史数据有限的情况下。&lt;h4&gt;6. 实验验证&lt;/h4&gt;   - 大量仿真结果表明，使用该方法预测的轨迹相比于知名的最先进基准方法，探测概率降低了63%-75%，显示出在实际场景中实现低延迟隐蔽操作的潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low Probability of Detection (LPD) communication aims to obscure the presenceof radio frequency (RF) signals to evade surveillance. In the context of mobilesurveillance utilizing unmanned aerial vehicles (UAVs), achieving LPDcommunication presents significant challenges due to the UAVs' rapid andcontinuous movements, which are characterized by unknown nonlinear dynamics.Therefore, accurately predicting future locations of UAVs is essential forenabling real-time LPD communication. In this paper, we introduce a novelframework termed predictive covert communication, aimed at minimizingdetectability in terrestrial ad-hoc networks under multi-UAV surveillance. Ourdata-driven method synergistically integrates graph neural networks (GNN) withKoopman theory to model the complex interactions within a multi-UAV network andfacilitating long-term predictions by linearizing the dynamics, even withlimited historical data. Extensive simulation results substantiate that thepredicted trajectories using our method result in at least 63%-75% lowerprobability of detection when compared to well-known state-of-the-art baselineapproaches, showing promise in enabling low-latency covert operations inpractical scenarios.</description>
      <author>example@mail.com (Sivaram Krishnan, Jihong Park, Gregory Sherman, Benjamin Campbell, Jinho Choi)</author>
      <guid isPermaLink="false">2409.17048v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Game4Loc: A UAV Geo-Localization Benchmark from Game Data</title>
      <link>http://arxiv.org/abs/2409.16925v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://yux1angji.github.io/game4loc/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 介绍了基于视觉的无人机（UAV）地理定位技术，作为全球导航卫星系统（GNSS）GPS信息的辅助来源，能够在无GPS环境中独立工作。&lt;h4&gt;2. 深度学习方法&lt;/h4&gt;   - 最近的深度学习方法将这一技术视为图像匹配和检索的任务，通过在地理标记的卫星图像数据库中检索无人机视角图像来获取大致的定位信息。&lt;h4&gt;3. 数据获取挑战&lt;/h4&gt;   - 由于高成本和隐私问题，通常难以从连续区域获取大量的无人机视角图像，而现有的无人机视角数据集大多由小规模的航空摄影组成，假设每个查询都有一个完美的一对一对齐参考图像，这与实际定位场景存在显著差距。&lt;h4&gt;4. 新数据集构建&lt;/h4&gt;   - 本研究构建了一个名为GTA-UAV的大范围连续区域无人机地理定位数据集，涵盖多种飞行高度、姿态、场景和目标，利用现代计算机游戏生成数据。&lt;h4&gt;5. 现实任务扩展&lt;/h4&gt;   - 引入了更实际的无人机地理定位任务，包括跨视角配对数据的部分匹配，并将图像级检索扩展到实际的定位（以米为单位）。&lt;h4&gt;6. 学习方法&lt;/h4&gt;   - 在构建无人机视角和卫星视角配对时，采用了基于权重的对比学习方法，能够有效学习并避免额外的后处理匹配步骤。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 实验结果表明，所构建的数据集和训练方法在无人机地理定位方面的有效性，以及在实际场景中的泛化能力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Yux1angJi/GTA-UAV&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The vision-based geo-localization technology for UAV, serving as a secondarysource of GPS information in addition to the global navigation satellitesystems (GNSS), can still operate independently in the GPS-denied environment.Recent deep learning based methods attribute this as the task of image matchingand retrieval. By retrieving drone-view images in geo-tagged satellite imagedatabase, approximate localization information can be obtained. However, due tohigh costs and privacy concerns, it is usually difficult to obtain largequantities of drone-view images from a continuous area. Existing drone-viewdatasets are mostly composed of small-scale aerial photography with a strongassumption that there exists a perfect one-to-one aligned reference image forany query, leaving a significant gap from the practical localization scenario.In this work, we construct a large-range contiguous area UAV geo-localizationdataset named GTA-UAV, featuring multiple flight altitudes, attitudes, scenes,and targets using modern computer games. Based on this dataset, we introduce amore practical UAV geo-localization task including partial matches ofcross-view paired data, and expand the image-level retrieval to the actuallocalization in terms of distance (meters). For the construction of drone-viewand satellite-view pairs, we adopt a weight-based contrastive learningapproach, which allows for effective learning while avoiding additionalpost-processing matching steps. Experiments demonstrate the effectiveness ofour data and training method for UAV geo-localization, as well as thegeneralization capabilities to real-world scenarios.</description>
      <author>example@mail.com (Yuxiang Ji, Boyong He, Zhuoyue Tan, Liaoni Wu)</author>
      <guid isPermaLink="false">2409.16925v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Redefining Data Pairing for Motion Retargeting Leveraging a Human Body Prior</title>
      <link>http://arxiv.org/abs/2409.13208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 Figures, Accepted at IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 提出了MR.HuBo（利用人类身体先验进行运动重定向），旨在收集高质量的上半身机器人与人类配对姿态数据，支持数据驱动的运动重定向方法。&lt;h4&gt;2. 方法创新&lt;/h4&gt;   - 与现有方法不同，现有方法通过将人类运动捕捉（MoCap）姿态转换为机器人姿态来收集数据，而MR.HuBo则反向操作：首先随机采样机器人姿态，然后将其转换为人类姿态。&lt;h4&gt;3. 极端姿态处理&lt;/h4&gt;   - 随机机器人姿态可能导致极端和不可行的人类姿态，因此提出了一种额外技术，通过利用训练自大量人类姿态数据的人体先验来筛选极端姿态。&lt;h4&gt;4. 适用范围&lt;/h4&gt;   - 该数据收集方法可用于任何类人机器人，只需设计或优化系统的超参数，如大小比例因子和采样的关节角度范围。&lt;h4&gt;5. 神经网络架构&lt;/h4&gt;   - 提出了一个两阶段的运动重定向神经网络，能够在大量配对数据上通过监督学习进行训练。&lt;h4&gt;6. 性能比较&lt;/h4&gt;   - 与通过无监督学习训练的其他学习方法相比，使用大量高质量配对数据训练的深度神经网络表现出显著的性能。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 实验表明，数据过滤方法的效果优于使用原始和噪声数据训练模型的结果。&lt;h4&gt;8. 资源共享&lt;/h4&gt;   - 代码和视频结果可在指定网站上获取，提供了额外的研究资源。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose MR.HuBo (Motion Retargeting leveraging a HUman BOdy prior), acost-effective and convenient method to collect high-quality upper body paired$\langle \text{robot, human} \rangle$ pose data, which is essential fordata-driven motion retargeting methods. Unlike existing approaches whichcollect $\langle \text{robot, human} \rangle$ pose data by converting humanMoCap poses into robot poses, our method goes in reverse. We first samplediverse random robot poses, and then convert them into human poses. However,since random robot poses can result in extreme and infeasible human poses, wepropose an additional technique to sort out extreme poses by exploiting a humanbody prior trained from a large amount of human pose data. Our data collectionmethod can be used for any humanoid robots, if one designs or optimizes thesystem's hyperparameters which include a size scale factor and the joint angleranges for sampling. In addition to this data collection method, we alsopresent a two-stage motion retargeting neural network that can be trained viasupervised learning on a large amount of paired data. Compared to otherlearning-based methods trained via unsupervised learning, we found that ourdeep neural network trained with ample high-quality paired data achievednotable performance. Our experiments also show that our data filtering methodyields better retargeting results than training the model with raw and noisydata. Our code and video results are available onhttps://sites.google.com/view/mr-hubo/</description>
      <author>example@mail.com (Xiyana Figuera, Soogeun Park, Hyemin Ahn)</author>
      <guid isPermaLink="false">2409.13208v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MIO: A Foundation Model on Multimodal Tokens</title>
      <link>http://arxiv.org/abs/2409.17692v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report. Codes and models will be available soon&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究引入&lt;/h4&gt;   - 本文介绍了MIO，一种新型基础模型，基于多模态令牌，能够以端到端、自回归的方式理解和生成语音、文本、图像和视频。&lt;h4&gt;2. 现有模型的局限性&lt;/h4&gt;   - 尽管大型语言模型（LLMs）和多模态大型语言模型（MM-LLMs）推动了人工通用智能的发展，但它们在真正的任何对任何理解和生成方面仍存在不足。&lt;h4&gt;3. GPT-4o的潜力&lt;/h4&gt;   - 最近发布的GPT-4o展示了任何对任何LLMs在复杂现实任务中的显著潜力，支持图像、语音和文本的全方位输入和输出，但其为闭源且不支持生成多模态交错序列。&lt;h4&gt;4. MIO的创新&lt;/h4&gt;   - 为填补这一空白，MIO通过因果多模态建模，训练于四种模态的离散令牌的混合。&lt;h4&gt;5. 训练过程&lt;/h4&gt;   - MIO经历四个阶段的训练过程：     1. 对齐预训练     2. 交错预训练     3. 增强语音的预训练     4. 在多样的文本、视觉和语音任务上进行全面的监督微调。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实验结果表明，MIO在性能上与之前的双模态基准、任何对任何模型基准，甚至特定模态基准相比，具有竞争力，某些情况下表现更优。&lt;h4&gt;7. 高级能力&lt;/h4&gt;   - MIO展现了其任何对任何特性所固有的高级能力，如交错视频-文本生成、视觉思维链推理、视觉指导生成、指令性图像编辑等。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce MIO, a novel foundation model built on multimodaltokens, capable of understanding and generating speech, text, images, andvideos in an end-to-end, autoregressive manner. While the emergence of largelanguage models (LLMs) and multimodal large language models (MM-LLMs) propelsadvancements in artificial general intelligence through their versatilecapabilities, they still lack true any-to-any understanding and generation.Recently, the release of GPT-4o has showcased the remarkable potential ofany-to-any LLMs for complex real-world tasks, enabling omnidirectional inputand output across images, speech, and text. However, it is closed-source anddoes not support the generation of multimodal interleaved sequences. To addressthis gap, we present MIO, which is trained on a mixture of discrete tokensacross four modalities using causal multimodal modeling. MIO undergoes afour-stage training process: (1) alignment pre-training, (2) interleavedpre-training, (3) speech-enhanced pre-training, and (4) comprehensivesupervised fine-tuning on diverse textual, visual, and speech tasks. Ourexperimental results indicate that MIO exhibits competitive, and in some casessuperior, performance compared to previous dual-modal baselines, any-to-anymodel baselines, and even modality-specific baselines. Moreover, MIOdemonstrates advanced capabilities inherent to its any-to-any feature, such asinterleaved video-text generation, chain-of-visual-thought reasoning, visualguideline generation, instructional image editing, etc.</description>
      <author>example@mail.com (Zekun Wang, King Zhu, Chunpu Xu, Wangchunshu Zhou, Jiaheng Liu, Yibo Zhang, Jiashuo Wang, Ning Shi, Siyu Li, Yizhi Li, Haoran Que, Zhaoxiang Zhang, Yuanxing Zhang, Ge Zhang, Ke Xu, Jie Fu, Wenhao Huang)</author>
      <guid isPermaLink="false">2409.17692v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>On the Impact of Feature Heterophily on Link Prediction with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2409.17475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 异质性定义&lt;/h4&gt;   - 异质性（Heterophily）是指网络中连接节点倾向于具有不同的类别标签或特征，这对许多图神经网络（GNN）模型构成挑战。&lt;h4&gt;2. 异质性对GNN的影响&lt;/h4&gt;   - 尽管在节点分类任务中，强异质性对GNN的挑战已经得到充分理解，但异质性在其他重要图学习任务（如链接预测）中的影响尚不明确。&lt;h4&gt;3. 研究重点&lt;/h4&gt;   - 本研究聚焦于链接预测任务，系统分析节点特征的异质性如何影响GNN的性能。&lt;h4&gt;4. 理论框架&lt;/h4&gt;   - 首先，提出了同质性和异质性的链接预测任务的正式定义，并展示了针对各自任务所需的不同优化的理论框架。&lt;h4&gt;5. 编码器和解码器分析&lt;/h4&gt;   - 分析不同的链接预测编码器和解码器如何适应不同程度的特征同质性，并提出改进性能的设计。&lt;h4&gt;6. 实证分析&lt;/h4&gt;   - 在多种合成和真实世界数据集上的实证分析验证了理论见解，并强调了在链接预测任务中采用可学习解码器和具有自我及邻居嵌入分离的GNN编码器的重要性。&lt;h4&gt;7. 超越同质性的应用&lt;/h4&gt;   - 研究结果表明，针对异质性特征的设计在链接预测任务中比仅考虑同质性更为有效。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterophily, or the tendency of connected nodes in networks to have differentclass labels or dissimilar features, has been identified as challenging formany Graph Neural Network (GNN) models. While the challenges of applying GNNsfor node classification when class labels display strong heterophily are wellunderstood, it is unclear how heterophily affects GNN performance in otherimportant graph learning tasks where class labels are not available. In thiswork, we focus on the link prediction task and systematically analyze theimpact of heterophily in node features on GNN performance. Theoretically, wefirst introduce formal definitions of homophilic and heterophilic linkprediction tasks, and present a theoretical framework that highlights thedifferent optimizations needed for the respective tasks. We then analyze howdifferent link prediction encoders and decoders adapt to varying levels offeature homophily and introduce designs for improved performance. Our empiricalanalysis on a variety of synthetic and real-world datasets confirms ourtheoretical insights and highlights the importance of adopting learnabledecoders and GNN encoders with ego- and neighbor-embedding separation inmessage passing for link prediction tasks beyond homophily.</description>
      <author>example@mail.com (Jiong Zhu, Gaotang Li, Yao-An Yang, Jing Zhu, Xuehao Cui, Danai Koutra)</author>
      <guid isPermaLink="false">2409.17475v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>DRIM: Learning Disentangled Representations from Incomplete Multimodal Healthcare Data</title>
      <link>http://arxiv.org/abs/2409.17055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 实际医疗数据通常是多模态和不完整的，这增加了对先进深度学习模型的需求，以有效整合这些数据。&lt;h4&gt;2. 多模态数据的优势&lt;/h4&gt;   - 使用包括组织病理切片、MRI和基因数据等多种模态，提供了改善预后预测和揭示新治疗途径的前所未有的机会。&lt;h4&gt;3. 对比学习的局限性&lt;/h4&gt;   - 传统对比学习方法假设不同视图包含相同的任务相关信息，仅利用共享信息，这在处理医疗数据时显得过于限制。&lt;h4&gt;4. DRIM方法介绍&lt;/h4&gt;   - 提出了DRIM，一种新型多模态方法，旨在捕捉共享和独特的表示，尽管数据稀疏依然有效。&lt;h4&gt;5. 表示编码&lt;/h4&gt;   - 针对一组模态，DRIM旨在为每个模态编码一个表示，该表示分为两部分：一部分 encapsulating 患者相关的跨模态信息，另一部分 encapsulating 模态特定的细节。&lt;h4&gt;6. 信息共享与独特性&lt;/h4&gt;   - 通过增加不同患者模态间的共享信息，同时最小化每个模态中共享与独特成分的重叠，实现信息的有效编码。&lt;h4&gt;7. 性能表现&lt;/h4&gt;   - 在胶质瘤患者生存预测任务中，DRIM方法的表现超过了现有的最先进算法，并且在面对缺失模态时显示出鲁棒性。&lt;h4&gt;8. 可重复性&lt;/h4&gt;   - 为促进研究的可重复性，相关代码已公开发布在GitHub上。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lucas-rbnt/drim&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-life medical data is often multimodal and incomplete, fueling thegrowing need for advanced deep learning models capable of integrating themefficiently. The use of diverse modalities, including histopathology slides,MRI, and genetic data, offers unprecedented opportunities to improve prognosisprediction and to unveil new treatment pathways. Contrastive learning, widelyused for deriving representations from paired data in multimodal tasks, assumesthat different views contain the same task-relevant information and leveragesonly shared information. This assumption becomes restrictive when handlingmedical data since each modality also harbors specific knowledge relevant todownstream tasks. We introduce DRIM, a new multimodal method for capturingthese shared and unique representations, despite data sparsity. Morespecifically, given a set of modalities, we aim to encode a representation foreach one that can be divided into two components: one encapsulatingpatient-related information common across modalities and the other,encapsulating modality-specific details. This is achieved by increasing theshared information among different patient modalities while minimizing theoverlap between shared and unique components within each modality. Our methodoutperforms state-of-the-art algorithms on glioma patients survival predictiontasks, while being robust to missing modalities. To promote reproducibility,the code is made publicly available at https://github.com/Lucas-rbnt/DRIM</description>
      <author>example@mail.com (Lucas Robinet, Ahmad Berjaoui, Ziad Kheil, Elizabeth Cohen-Jonathan Moyal)</author>
      <guid isPermaLink="false">2409.17055v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Stain Separation Improves Cross-Scanner Adenocarcinoma Segmentation with Joint Multi-Task Learning</title>
      <link>http://arxiv.org/abs/2409.13246v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 数字病理学在肿瘤诊断和分割方面取得了显著进展，但由于器官、组织制备和图像获取的差异（称为域偏移），当前算法的有效性受到限制。&lt;h4&gt;2. 挑战目标&lt;/h4&gt;   - COSAS（跨器官和跨扫描仪腺癌分割）挑战旨在提高分割算法对域偏移的鲁棒性，任务2专注于使用来自六个扫描仪的多样化数据集进行腺癌分割，推动临床诊断的边界。&lt;h4&gt;3. 研究方法&lt;/h4&gt;   - 我们的方法采用无监督学习，通过在多任务学习框架中进行染色分离，使用多解码器自编码器模型。&lt;h4&gt;4. 染色分离&lt;/h4&gt;   - 该模型能够隔离染色矩阵和染色密度，从而处理颜色变化，提高不同扫描仪之间的泛化能力。&lt;h4&gt;5. 模型增强&lt;/h4&gt;   - 通过混合染色增强技术进一步增强模型的鲁棒性，并使用U-net架构进行分割。&lt;h4&gt;6. 方法创新&lt;/h4&gt;   - 我们的方法的新颖之处在于在多任务学习框架中使用染色分离，有效地将组织结构与颜色变化解耦。&lt;h4&gt;7. 研究成果&lt;/h4&gt;   - 该方法显示出提高分割准确性和在不同组织病理染色间的泛化能力的潜力，为数字病理学中的更可靠诊断工具铺平了道路。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Digital pathology has made significant advances in tumor diagnosis andsegmentation, but image variability due to differences in organs, tissuepreparation, and acquisition - known as domain shift - limits the effectivenessof current algorithms. The COSAS (Cross-Organ and Cross-Scanner AdenocarcinomaSegmentation) challenge addresses this issue by improving the resilience ofsegmentation algorithms to domain shift, with Task 2 focusing on adenocarcinomasegmentation using a diverse dataset from six scanners, pushing the boundariesof clinical diagnostics. Our approach employs unsupervised learning throughstain separation within a multi-task learning framework using a multi-decoderautoencoder. This model isolates stain matrix and stain density, allowing it tohandle color variation and improve generalization across scanners. We furtherenhanced the robustness of the model with a mixture of stain augmentationtechniques and used a U-net architecture for segmentation. The novelty of ourmethod lies in the use of stain separation within a multi-task learningframework, which effectively disentangles histological structures from colorvariations. This approach shows promise for improving segmentation accuracy andgeneralization across different histopathological stains, paving the way formore reliable diagnostic tools in digital pathology.</description>
      <author>example@mail.com (Ho Heon Kim, Won Chan Jeong, Young Shin Ko, Young Jin Park)</author>
      <guid isPermaLink="false">2409.13246v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience</title>
      <link>http://arxiv.org/abs/2409.17702v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code, data and demo videos at https://hierarchical-emv.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 机器人的经验口头表达（即总结和回答关于机器人过去的问题）是改善人机交互的关键能力。&lt;h4&gt;2. 现有方法的局限&lt;/h4&gt;   - 之前的研究多采用基于规则的系统或微调的深度模型，主要针对短时间（几分钟）的情节数据进行口头表达，限制了模型的泛化和迁移能力。&lt;h4&gt;3. 研究创新&lt;/h4&gt;   - 本文采用大型预训练模型，以零或少量示例来处理机器人的经验口头表达，特别关注终身经验的表达。&lt;h4&gt;4. 数据结构&lt;/h4&gt;   - 从情节记忆（EM）中推导出树状数据结构，底层表示原始感知和本体感觉数据，上层抽象为自然语言概念的事件。&lt;h4&gt;5. 层次化表示&lt;/h4&gt;   - 基于经验流构建的层次化表示用于交互式地搜索情节记忆，针对用户查询动态展开（初始压缩的）树节点，以找到相关信息。&lt;h4&gt;6. 计算效率&lt;/h4&gt;   - 该方法在扩展到数月的机器人经验数据时，仍保持低计算成本。&lt;h4&gt;7. 实验评估&lt;/h4&gt;   - 在模拟家庭机器人数据、人类自我中心视频和真实世界机器人录音上评估了该方法，展示了其灵活性和可扩展性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Verbalization of robot experience, i.e., summarization of and questionanswering about a robot's past, is a crucial ability for improving human-robotinteraction. Previous works applied rule-based systems or fine-tuned deepmodels to verbalize short (several-minute-long) streams of episodic data,limiting generalization and transferability. In our work, we apply largepretrained models to tackle this task with zero or few examples, andspecifically focus on verbalizing life-long experiences. For this, we derive atree-like data structure from episodic memory (EM), with lower levelsrepresenting raw perception and proprioception data, and higher levelsabstracting events to natural language concepts. Given such a hierarchicalrepresentation built from the experience stream, we apply a large languagemodel as an agent to interactively search the EM given a user's query,dynamically expanding (initially collapsed) tree nodes to find the relevantinformation. The approach keeps computational costs low even when scaling tomonths of robot experience data. We evaluate our method on simulated householdrobot data, human egocentric videos, and real-world robot recordings,demonstrating its flexibility and scalability.</description>
      <author>example@mail.com (Leonard Bärmann, Chad DeChant, Joana Plewnia, Fabian Peller-Konrad, Daniel Bauer, Tamim Asfour, Alex Waibel)</author>
      <guid isPermaLink="false">2409.17702v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Redundancy: Information-aware Unsupervised Multiplex Graph Structure Learning</title>
      <link>http://arxiv.org/abs/2409.17386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appear in NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 无监督多重图学习（UMGL）旨在在不同边类型下学习节点表示，无需手动标注。&lt;h4&gt;2. 现有研究的不足&lt;/h4&gt;   - 现有研究忽视了图结构的可靠性，现实数据通常复杂且包含大量与任务无关的噪声，严重影响UMGL的性能。&lt;h4&gt;3. 方法局限&lt;/h4&gt;   - 现有方法主要依赖对比学习来最大化不同图之间的互信息，限制了它们在多重图冗余场景中的应用，未能捕捉到视图唯一的任务相关信息。&lt;h4&gt;4. 研究创新&lt;/h4&gt;   - 本文聚焦于一个更现实且具有挑战性的任务：无监督地从多个图中学习融合图，保留足够的任务相关信息，同时去除任务无关的噪声。&lt;h4&gt;5. 提出的方法&lt;/h4&gt;   - 提出的信息感知无监督多重图融合框架（InfoMGF）通过图结构精炼消除无关噪声，并同时最大化视图共享和视图独特的任务相关信息，从而解决非冗余多重图的前沿问题。&lt;h4&gt;6. 理论支持&lt;/h4&gt;   - 理论分析进一步保证了InfoMGF的有效性。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 在不同下游任务上，与各种基线方法的全面实验展示了其卓越的性能和鲁棒性。   - 出乎意料的是，本文的无监督方法甚至超越了复杂的监督方法。&lt;h4&gt;8. 代码和数据集&lt;/h4&gt;   - 相关的源代码和数据集可在 [GitHub - zxlearningdeep/InfoMGF](https://github.com/zxlearningdeep/InfoMGF) 获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zxlearningdeep/infomgf&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised Multiplex Graph Learning (UMGL) aims to learn noderepresentations on various edge types without manual labeling. However,existing research overlooks a key factor: the reliability of the graphstructure. Real-world data often exhibit a complex nature and contain abundanttask-irrelevant noise, severely compromising UMGL's performance. Moreover,existing methods primarily rely on contrastive learning to maximize mutualinformation across different graphs, limiting them to multiplex graph redundantscenarios and failing to capture view-unique task-relevant information. In thispaper, we focus on a more realistic and challenging task: to unsupervisedlylearn a fused graph from multiple graphs that preserve sufficient task-relevantinformation while removing task-irrelevant noise. Specifically, our proposedInformation-aware Unsupervised Multiplex Graph Fusion framework (InfoMGF) usesgraph structure refinement to eliminate irrelevant noise and simultaneouslymaximizes view-shared and view-unique task-relevant information, therebytackling the frontier of non-redundant multiplex graph. Theoretical analysesfurther guarantee the effectiveness of InfoMGF. Comprehensive experimentsagainst various baselines on different downstream tasks demonstrate itssuperior performance and robustness. Surprisingly, our unsupervised method evenbeats the sophisticated supervised approaches. The source code and datasets areavailable at https://github.com/zxlearningdeep/InfoMGF.</description>
      <author>example@mail.com (Zhixiang Shen, Shuo Wang, Zhao Kang)</author>
      <guid isPermaLink="false">2409.17386v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>The Effect of Perceptual Metrics on Music Representation Learning for Genre Classification</title>
      <link>http://arxiv.org/abs/2409.17069v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2312.03455&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 自然信号的主观质量可以通过客观感知度量进行近似。&lt;h4&gt;2. 感知度量的目的&lt;/h4&gt;   - 感知度量旨在近似人类观察者的感知行为，通常反映自然信号中的结构和神经通路。&lt;h4&gt;3. 模型训练&lt;/h4&gt;   - 使用感知度量作为损失函数训练的模型能够捕捉到这些度量中蕴含的感知上有意义的特征。&lt;h4&gt;4. 研究发现&lt;/h4&gt;   - 通过使用从训练有感知损失的自编码器提取的特征，能够在音乐理解任务（如流派分类）中提高性能。   - 相比直接使用这些度量作为距离来学习分类器，这种方法表现更佳。&lt;h4&gt;5. 推广能力&lt;/h4&gt;   - 这一结果表明，在表示学习中使用感知度量作为损失函数时，能够提高对新信号的泛化能力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The subjective quality of natural signals can be approximated with objectiveperceptual metrics. Designed to approximate the perceptual behaviour of humanobservers, perceptual metrics often reflect structures found in natural signalsand neurological pathways. Models trained with perceptual metrics as lossfunctions can capture perceptually meaningful features from the structures heldwithin these metrics. We demonstrate that using features extracted fromautoencoders trained with perceptual losses can improve performance on musicunderstanding tasks, i.e. genre classification, over using these metricsdirectly as distances when learning a classifier. This result suggests improvedgeneralisation to novel signals when using perceptual metrics as loss functionsfor representation learning.</description>
      <author>example@mail.com (Tashi Namgyal, Alexander Hepburn, Raul Santos-Rodriguez, Valero Laparra, Jesus Malo)</author>
      <guid isPermaLink="false">2409.17069v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Taming Diffusion Prior for Image Super-Resolution with Domain Shift SDEs</title>
      <link>http://arxiv.org/abs/2409.17778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 基于扩散的图像超分辨率（SR）模型因其强大的图像恢复能力而受到广泛关注。&lt;h4&gt;2. 现有模型的挑战&lt;/h4&gt;   - 现有的扩散模型在效率与性能之间难以找到最佳平衡。   - 通常，这些模型未能充分利用现有的预训练模型，限制了其生成能力。   - 另外，许多模型需要从随机噪声开始进行多次前向传递，影响推理效率。&lt;h4&gt;3. 提出的方法（DoSSR）&lt;/h4&gt;   - 本文提出了一个名为DoSSR的基于领域转移的扩散超分辨率模型。   - 该模型利用预训练扩散模型的生成能力，同时通过使用低分辨率（LR）图像启动扩散过程，显著提高了效率。&lt;h4&gt;4. 核心创新&lt;/h4&gt;   - 采用领域转移方程，与现有扩散模型无缝集成。   - 这种集成不仅改善了扩散先验的使用，还提升了推理效率。&lt;h4&gt;5. 方法改进&lt;/h4&gt;   - 将离散转移过程转变为连续形式，称为DoS-SDEs。   - 该改进使得快速定制求解器得以实现，进一步提高了采样效率。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实证结果显示，所提出的方法在合成与真实世界数据集上达到了最先进的性能。   - 该方法显著减少了采样步骤，仅需5个采样步骤。&lt;h4&gt;7. 效率提升&lt;/h4&gt;   - 与之前基于扩散先验的方法相比，DoSSR在速度上实现了5-7倍的显著提升，展示了其卓越的效率。&lt;h4&gt;8. 代码可用性&lt;/h4&gt;   - 相关代码已公开，访问地址为 [GitHub - QinpengCui/DoSSR](https://github.com/QinpengCui/DoSSR)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/qinpengcui/dossr&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion-based image super-resolution (SR) models have attracted substantialinterest due to their powerful image restoration capabilities. However,prevailing diffusion models often struggle to strike an optimal balance betweenefficiency and performance. Typically, they either neglect to exploit thepotential of existing extensive pretrained models, limiting their generativecapacity, or they necessitate a dozens of forward passes starting from randomnoises, compromising inference efficiency. In this paper, we present DoSSR, aDomain Shift diffusion-based SR model that capitalizes on the generative powersof pretrained diffusion models while significantly enhancing efficiency byinitiating the diffusion process with low-resolution (LR) images. At the coreof our approach is a domain shift equation that integrates seamlessly withexisting diffusion models. This integration not only improves the use ofdiffusion prior but also boosts inference efficiency. Moreover, we advance ourmethod by transitioning the discrete shift process to a continuous formulation,termed as DoS-SDEs. This advancement leads to the fast and customized solversthat further enhance sampling efficiency. Empirical results demonstrate thatour proposed method achieves state-of-the-art performance on synthetic andreal-world datasets, while notably requiring only 5 sampling steps. Compared toprevious diffusion prior based methods, our approach achieves a remarkablespeedup of 5-7 times, demonstrating its superior efficiency. Code:https://github.com/QinpengCui/DoSSR.</description>
      <author>example@mail.com (Qinpeng Cui, Yixuan Liu, Xinyi Zhang, Qiqi Bao, Zhongdao Wang, Qingmin Liao, Li Wang, Tian Lu, Emad Barsoum)</author>
      <guid isPermaLink="false">2409.17778v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Low Latency Point Cloud Rendering with Learned Splatting</title>
      <link>http://arxiv.org/abs/2409.16504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at CVPR 2024 Workshop on AIS: Vision, Graphics and AI for
  Streaming (https://ai4streaming-workshop.github.io/)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 点云是重要的三维表示形式，广泛应用于新兴领域。   - 由于点的稀疏性和不规则性，高质量点云渲染存在挑战，常需复杂计算以恢复连续的表面表示。&lt;h4&gt;2. 运动延迟要求&lt;/h4&gt;   - 为避免视觉不适，运动到光子的延迟必须非常短，低于10毫秒。&lt;h4&gt;3. 现有解决方案的不足&lt;/h4&gt;   - 现有的渲染解决方案在质量或速度上均存在不足。&lt;h4&gt;4. 提出的框架&lt;/h4&gt;   - 本研究提出一个框架，实现交互式、自由视角和高保真度的点云渲染。   - 通过训练通用神经网络，从任意点云估计三维椭圆高斯，并使用可微分的表面喷洒技术渲染平滑的纹理和表面法线。&lt;h4&gt;5. 优化特点&lt;/h4&gt;   - 方法不需要针对每个场景进行优化，能够实时渲染动态点云。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实验结果显示，该解决方案在视觉质量和速度上优于现有方法，且具有良好的场景内容通用性和对压缩伪影的鲁棒性。&lt;h4&gt;7. 代码可用性&lt;/h4&gt;   - 相关代码已公开，访问地址为 [GitHub - huzi96/gaussian-pcloud-render](https://github.com/huzi96/gaussian-pcloud-render)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/huzi96/gaussian-pcloud-render&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud is a critical 3D representation with many emerging applications.Because of the point sparsity and irregularity, high-quality rendering of pointclouds is challenging and often requires complex computations to recover thecontinuous surface representation. On the other hand, to avoid visualdiscomfort, the motion-to-photon latency has to be very short, under 10 ms.Existing rendering solutions lack in either quality or speed. To tackle thesechallenges, we present a framework that unlocks interactive, free-viewing andhigh-fidelity point cloud rendering. We train a generic neural network toestimate 3D elliptical Gaussians from arbitrary point clouds and usedifferentiable surface splatting to render smooth texture and surface normalfor arbitrary views. Our approach does not require per-scene optimization, andenable real-time rendering of dynamic point cloud. Experimental resultsdemonstrate the proposed solution enjoys superior visual quality and speed, aswell as generalizability to different scene content and robustness tocompression artifacts. The code is available athttps://github.com/huzi96/gaussian-pcloud-render .</description>
      <author>example@mail.com (Yueyu Hu, Ran Gong, Qi Sun, Yao Wang)</author>
      <guid isPermaLink="false">2409.16504v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Potential of Synthetic Images: A Study on Histopathology Image Classification</title>
      <link>http://arxiv.org/abs/2409.16002v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ECCV 2024 - BioImage Computing Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 组织病理图像分类对疾病的准确识别和诊断至关重要，但需要大型多样的数据集。&lt;h4&gt;2. 数据集获取的挑战&lt;/h4&gt;   - 获取这些数据集通常成本高昂且耗时，原因在于需要专家注释和伦理约束。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本研究探讨不同生成模型和图像选择方法在基于类别标签创建真实合成组织病理图像补丁的适用性。&lt;h4&gt;4. 生成模型的重要性&lt;/h4&gt;   - 研究发现选择合适的生成模型类型和架构对提升性能至关重要。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 在PCam数据集上的实验表明，扩散模型在迁移学习中效果显著，而GAN生成的样本更适合于数据增强。&lt;h4&gt;6. 模型对比&lt;/h4&gt;   - 基于变换器的生成模型不需要图像过滤，而卷积神经网络（CNN）生成的模型则需基于现实评分的选择。&lt;h4&gt;7. 结论&lt;/h4&gt;   - 结果表明，合成图像能够有效增强现有数据集，最终提高下游组织病理图像分类任务的性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/leirebv/synthetic_histopathology_dataset&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Histopathology image classification is crucial for the accurateidentification and diagnosis of various diseases but requires large and diversedatasets. Obtaining such datasets, however, is often costly and time-consumingdue to the need for expert annotations and ethical constraints. To addressthis, we examine the suitability of different generative models and imageselection approaches to create realistic synthetic histopathology image patchesconditioned on class labels. Our findings highlight the importance of selectingan appropriate generative model type and architecture to enhance performance.Our experiments over the PCam dataset show that diffusion models are effectivefor transfer learning, while GAN-generated samples are better suited foraugmentation. Additionally, transformer-based generative models do not requireimage filtering, in contrast to those derived from Convolutional NeuralNetworks (CNNs), which benefit from realism score-based selection. Therefore,we show that synthetic images can effectively augment existing datasets,ultimately improving the performance of the downstream histopathology imageclassification task.</description>
      <author>example@mail.com (Leire Benito-Del-Valle, Aitor Alvarez-Gila, Itziar Eguskiza, Cristina L. Saratxaga)</author>
      <guid isPermaLink="false">2409.16002v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>BeanCounter: A low-toxicity, large-scale, and open dataset of business-oriented text</title>
      <link>http://arxiv.org/abs/2409.17827v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 最近的语言模型突破主要来源于将相同模型架构有效扩展到更大数据集。&lt;h4&gt;2. 数据集的重要性&lt;/h4&gt;   - 研究表明，增大训练数据集的大小和质量能带来显著的性能提升，因此需要新的大规模数据集来源。&lt;h4&gt;3. 新数据集的介绍&lt;/h4&gt;   - 本研究推出了BeanCounter，一个公共数据集，包含超过1590亿个标记，数据来源于企业披露的信息。&lt;h4&gt;4. 数据的新颖性&lt;/h4&gt;   - BeanCounter的数据新颖性体现在其与Common Crawl基础数据集的重叠率低于0.1%，且规模比依赖类似来源的数据集大一个数量级。&lt;h4&gt;5. 数据的质量假设&lt;/h4&gt;   - 由于数据的来源，假设BeanCounter相较于基于网络的数据集更加真实且毒性更低。&lt;h4&gt;6. 假设验证&lt;/h4&gt;   - 探索这一假设时发现，BeanCounter中许多群体身份的出现频率相似，但相较于其他数据集，其上下文的毒性显著较低。&lt;h4&gt;7. 实用性评估&lt;/h4&gt;   - 评估并比较了两个持续在BeanCounter上预训练的语言模型与其基础模型，发现持续预训练模型的毒性生成减少了18%-33%，并在金融领域表现改善。&lt;h4&gt;8. 研究结论&lt;/h4&gt;   - 总体而言，研究表明BeanCounter是一个低毒性、高质量且足够规模的特定领域数据源，适合用于训练数十亿参数的语言模型。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many of the recent breakthroughs in language modeling have resulted fromscaling effectively the same model architecture to larger datasets. In thisvein, recent work has highlighted performance gains from increasing trainingdataset size and quality, suggesting a need for novel sources of large-scaledatasets. In this work, we introduce BeanCounter, a public dataset consistingof more than 159B tokens extracted from businesses' disclosures. We show thatthis data is indeed novel: less than 0.1% of BeanCounter appears in CommonCrawl-based datasets and it is an order of magnitude larger than datasetsrelying on similar sources. Given the data's provenance, we hypothesize thatBeanCounter is comparatively more factual and less toxic than web-baseddatasets. Exploring this hypothesis, we find that many demographic identitiesoccur with similar prevalence in BeanCounter but with significantly less toxiccontext relative to other datasets. To demonstrate the utility of BeanCounter,we evaluate and compare two LLMs continually pre-trained on BeanCounter withtheir base models. We find an 18-33% reduction in toxic generation and improvedperformance within the finance domain for the continually pretrained models.Collectively, our work suggests that BeanCounter is a novel source oflow-toxicity and high-quality domain-specific data with sufficient scale totrain multi-billion parameter LLMs.</description>
      <author>example@mail.com (Siyan Wang, Bradford Levy)</author>
      <guid isPermaLink="false">2409.17827v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>TA-Cleaner: A Fine-grained Text Alignment Backdoor Defense Strategy for Multimodal Contrastive Learning</title>
      <link>http://arxiv.org/abs/2409.17601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 预训练的大型多模态对比学习模型（如CLIP）在业界被广泛认可，但对数据污染的后门攻击非常敏感，这对下游模型训练构成重大风险。&lt;h4&gt;2. 防御策略&lt;/h4&gt;   - 针对潜在威胁，微调比用增强数据重新训练大型模型提供了更简单有效的防御选择。在监督学习领域，微调防御策略表现优异。&lt;h4&gt;3. 未监督及半监督领域的挑战&lt;/h4&gt;   - 在未监督和半监督领域，当CLIP面对一些复杂攻击技术时，现有微调防御策略CleanCLIP的防御性能存在局限。&lt;h4&gt;4. CleanCLIP的不足&lt;/h4&gt;   - CleanCLIP的文本增强中的同义词替换不足以增强文本特征空间。&lt;h4&gt;5. 改进方案&lt;/h4&gt;   - 提出细粒度的文本对齐清理器（TA-Cleaner），通过切断后门触发器的特征连接来弥补CleanCLIP的不足。&lt;h4&gt;6. 操作方法&lt;/h4&gt;   - 在CleanCLIP的每个训练周期随机选择少量样本生成正负子文本，并将子文本与图像对齐，以增强文本自我监督。&lt;h4&gt;7. 实验评估&lt;/h4&gt;   - 针对六种攻击算法评估TA-Cleaner的有效性，并在ImageNet1K上进行全面的零-shot分类测试。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 实验结果表明，TA-Cleaner在基于微调的防御技术中实现了最先进的防御效果，面对新颖的攻击技术BadCLIP时，TA-Cleaner在Top-1和Top-10的ASR分别降低了52.02%和63.88%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pre-trained large models for multimodal contrastive learning, such as CLIP,have been widely recognized in the industry as highly susceptible todata-poisoned backdoor attacks. This poses significant risks to downstreammodel training. In response to such potential threats, finetuning offers asimpler and more efficient defense choice compared to retraining large modelswith augmented data. In the supervised learning domain, fine-tuning defensestrategies can achieve excellent defense performance. However, in theunsupervised and semi-supervised domain, we find that when CLIP faces somecomplex attack techniques, the existing fine-tuning defense strategy,CleanCLIP, has some limitations on defense performance. The synonymsubstitution of its text-augmentation is insufficient to enhance the textfeature space. To compensate for this weakness, we improve it by proposing afine-grained \textbf{T}ext \textbf{A}lignment \textbf{C}leaner (TA-Cleaner) tocut off feature connections of backdoor triggers. We randomly select a fewsamples for positive and negative subtext generation at each epoch ofCleanCLIP, and align the subtexts to the images to strengthen the textself-supervision. We evaluate the effectiveness of our TA-Cleaner against sixattack algorithms and conduct comprehensive zero-shot classification tests onImageNet1K. Our experimental results demonstrate that TA-Cleaner achievesstate-of-the-art defensiveness among finetuning-based defense techniques. Evenwhen faced with the novel attack technique BadCLIP, our TA-Cleaner outperformsCleanCLIP by reducing the ASR of Top-1 and Top-10 by 52.02\% and 63.88\%,respectively.</description>
      <author>example@mail.com (Yuan Xun, Siyuan Liang, Xiaojun Jia, Xinwei Liu, Xiaochun Cao)</author>
      <guid isPermaLink="false">2409.17601v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Generalize Unseen Domains via Multi-Source Meta Learning for Text Classification</title>
      <link>http://arxiv.org/abs/2409.13787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着深度学习方法的快速发展，文本分类领域取得了许多突破，相关模型已显示出高精度。&lt;h4&gt;2. 现有模型的局限性&lt;/h4&gt;   - 大多数模型在已知领域的标注数据上训练，难以在新的、具有挑战性的未知领域中保持高精度，这与模型的泛化能力直接相关。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本文研究文本分类的多源领域泛化，并提出一个框架，利用多个已知领域训练模型，以在未知领域实现高精度。&lt;h4&gt;4. 提出的新框架&lt;/h4&gt;   - 提出了一个多源元学习领域泛化框架，模拟模型向未知领域的泛化过程，提取足够的领域相关特征。&lt;h4&gt;5. 记忆机制引入&lt;/h4&gt;   - 引入记忆机制以存储领域特定特征，与元学习框架协调工作。&lt;h4&gt;6. 新颖的“陪审团”机制&lt;/h4&gt;   - 采用新颖的“陪审团”机制，使模型学习足够的领域不变特征。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 实验表明，所提出的元学习框架有效增强了模型在未知领域的泛化能力，并在多源文本分类数据集上优于现有的最先进方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid development of deep learning methods, there have been manybreakthroughs in the field of text classification. Models developed for thistask have been shown to achieve high accuracy. However, most of these modelsare trained using labeled data from seen domains. It is difficult for thesemodels to maintain high accuracy in a new challenging unseen domain, which isdirectly related to the generalization of the model. In this paper, we studythe multi-source Domain Generalization of text classification and propose aframework to use multiple seen domains to train a model that can achieve highaccuracy in an unseen domain. Specifically, we propose a multi-sourcemeta-learning Domain Generalization framework to simulate the process of modelgeneralization to an unseen domain, so as to extract sufficient domain-relatedfeatures. We introduced a memory mechanism to store domain-specific features,which coordinate with the meta-learning framework. Besides, we adopt the novel"jury" mechanism that enables the model to learn sufficient domain-invariantfeatures. Experiments demonstrate that our meta-learning framework caneffectively enhance the ability of the model to generalize to an unseen domainand can outperform the state-of-the-art methods on multi-source textclassification datasets.</description>
      <author>example@mail.com (Yuxuan Hu, Chenwei Zhang, Min Yang, Xiaodan Liang, Chengming Li, Xiping Hu)</author>
      <guid isPermaLink="false">2409.13787v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>DeformStream: Deformation-based Adaptive Volumetric Video Streaming</title>
      <link>http://arxiv.org/abs/2409.16615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 体积视频流媒体提供沉浸式3D体验，但在实时传输详细内容时面临高带宽需求和延迟问题。&lt;h4&gt;2. 传统方法的局限&lt;/h4&gt;   - 传统的点云流媒体在放大时会妥协视觉质量，而神经渲染技术在实时应用中计算负担过重。&lt;h4&gt;3. 网格流媒体的优势&lt;/h4&gt;   - 网格基础流媒体通过保留表面细节和连接性，为3D内容提供更精细的表示，但传统网格流媒体方法通常按帧传输数据，未能充分利用帧间的时间冗余。&lt;h4&gt;4. 带来的问题&lt;/h4&gt;   - 这种按帧传输导致带宽使用效率低下，且对网络波动适应性差。&lt;h4&gt;5. 新方法的提出&lt;/h4&gt;   - 引入基于变形的自适应体积视频流媒体（Deformation-based Adaptive Volumetric Video Streaming），利用网格表示的固有变形性来增强流媒体性能。&lt;h4&gt;6. 核心技术&lt;/h4&gt;   - DeformStream通过嵌入变形来重构后续帧，基于帧间运动显著减少带宽使用，同时确保帧间视觉一致性。&lt;h4&gt;7. QoE模型与算法&lt;/h4&gt;   - 为解决帧重构开销和网络适应性，提出新的用户体验（QoE）模型，考虑客户端的变形延迟，并设计动态规划算法来优化视觉质量和带宽消耗之间的权衡。&lt;h4&gt;8. 评估结果&lt;/h4&gt;   - 评估结果表明，基于变形的自适应体积视频流媒体在带宽效率和视觉质量上优于现有的网格流媒体系统，为实时体积视频应用提供了一种稳健的解决方案。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Volumetric video streaming offers immersive 3D experiences but facessignificant challenges due to high bandwidth requirements and latency issues intransmitting detailed content in real time. Traditional methods like pointcloud streaming compromise visual quality when zoomed in, and neural renderingtechniques are too computationally intensive for real-time use. Thoughmesh-based streaming stands out by preserving surface detail and connectivity,offering a more refined representation for 3D content, traditional meshstreaming methods typically transmit data on a per-frame basis, failing to takefull advantage of temporal redundancies across frames. This results ininefficient bandwidth usage and poor adaptability to fluctuating networkconditions. We introduce Deformation-based Adaptive Volumetric Video Streaming,a novel framework that enhances volumetric video streaming performance byleveraging the inherent deformability of mesh-based representations.DeformStream uses embedded deformation to reconstruct subsequent frames frominter-frame motion, significantly reducing bandwidth usage while ensuringvisual coherence between frames. To address frame reconstruction overhead andnetwork adaptability, we formulate a new QoE model that accounts forclient-side deformation latency and design a dynamic programming algorithm tooptimize the trade-off between visual quality and bandwidth consumption undervarying network conditions. Our evaluation demonstrates that Deformation-basedAdaptive Volumetric Video Streaming outperforms existing mesh-based streamingsystems in both bandwidth efficiency and visual quality, offering a robustsolution for real-time volumetric video applications.</description>
      <author>example@mail.com (Boyan Li, Yongting Chen, Dayou Zhang, Fangxin Wang)</author>
      <guid isPermaLink="false">2409.16615v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Stable Survival Extrapolation via Transfer Learning</title>
      <link>http://arxiv.org/abs/2409.16044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 6 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 平均生存期是多个应用（如健康经济评估）决策过程中的关键要素，定义为完整生存曲线下的面积，需要对观察数据进行外推。&lt;h4&gt;2. 研究方法&lt;/h4&gt;   - 本文采用贝叶斯死亡率模型，并将其预测结果转移，以构建作为生存模型锚定的基线人群。这可以视为在未见数据中的隐含偏倚-方差权衡。&lt;h4&gt;3. 外推方法&lt;/h4&gt;   - 提出基于灵活的参数多风险模型的外推方法，能够自然适应多样的形状，包括非比例风险和交叉生存曲线，同时通常保持自然解释性。&lt;h4&gt;4. 应用案例&lt;/h4&gt;   - 在三个案例中估计平均生存期及相关估计量：乳腺癌、心脏心律失常和晚期黑色素瘤。&lt;h4&gt;5. 具体评估&lt;/h4&gt;   - 评估三阴性乳腺癌病例的生存劣势，结合免疫疗法与mRNA癌症治疗对晚期黑色素瘤的疗效，以及植入型心脏去颤器对心脏心律失常的适用性。&lt;h4&gt;6. 竞争风险分析&lt;/h4&gt;   - 在竞争风险背景下进行心脏心律失常的评估，展示仅关注特定原因风险如何最小化潜在不稳定性。&lt;h4&gt;7. 研究结论&lt;/h4&gt;   - 结果表明，所提方法在生存外推时提供了灵活、可解释且稳健的解决方案。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The mean survival is the key ingredient of the decision process in severalapplications, including health economic evaluations. It is defined as the areaunder the complete survival curve thus necessitating extrapolation of theobserved data. In this article we employ a Bayesian mortality model andtransfer its projections in order to construct the baseline population thatacts as an anchor of the survival model. This can be seen as an implicitbias-variance trade-off in unseen data. We then propose extrapolation methodsbased on flexible parametric polyhazard models which can naturally accommodatediverse shapes, including non-proportional hazards and crossing survival curveswhile typically maintaining a natural interpretation. We estimate the meansurvival and related estimands in three cases, namely breast cancer, cardiacarrhythmia and advanced melanoma. Specifically, we evaluate the survivaldisadvantage of triple negative breast cancer cases, the efficacy of combiningimmunotherapy with mRNA cancer therapeutic for advanced melanoma treatment andthe suitability of implantable cardioverter defibrilators for cardiacarrhythmia. The latter is conducted in a competing risks context illustratinghow working on the cause-specific hazard alone minimizes potential instability.The results suggest that the proposed approach offers a flexible, interpretableand robust approach when survival extrapolation is required.</description>
      <author>example@mail.com (Anastasios Apsemidis, Nikolaos Demiris)</author>
      <guid isPermaLink="false">2409.16044v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Recent Advancement of Emotion Cognition in Large Language Models</title>
      <link>http://arxiv.org/abs/2409.13354v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 大型语言模型（LLMs）中的情感认知对于提升在社交媒体、人机交互和心理健康评估等多种应用中的表现至关重要。&lt;h4&gt;2. 现有研究现状&lt;/h4&gt;   - 当前研究主要集中在情感分类、情感丰富的响应生成和心智理论评估上，同时也承认存在一些挑战，如对注释数据的依赖和情感处理的复杂性。&lt;h4&gt;3. 论文目的&lt;/h4&gt;   - 本文提供了关于LLMs在情感认知领域的最新进展的详细综述。&lt;h4&gt;4. 研究内容&lt;/h4&gt;   - 探讨关键研究、方法论、研究结果和资源，并将这些内容与Ulric Neisser的认知阶段进行对齐。&lt;h4&gt;5. 未来研究方向&lt;/h4&gt;   - 概述了这一不断发展的领域的潜在未来研究方向，包括无监督学习方法和开发更复杂、可解释的情感认知LLMs。&lt;h4&gt;6. 先进方法讨论&lt;/h4&gt;   - 讨论了提高LLMs情感认知能力的先进方法，如对比学习。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emotion cognition in large language models (LLMs) is crucial for enhancingperformance across various applications, such as social media, human-computerinteraction, and mental health assessment. We explore the current landscape ofresearch, which primarily revolves around emotion classification, emotionallyrich response generation, and Theory of Mind assessments, while acknowledge thechallenges like dependency on annotated data and complexity in emotionprocessing. In this paper, we present a detailed survey of recent progress inLLMs for emotion cognition. We explore key research studies, methodologies,outcomes, and resources, aligning them with Ulric Neisser's cognitive stages.Additionally, we outline potential future directions for research in thisevolving field, including unsupervised learning approaches and the developmentof more complex and interpretable emotion cognition LLMs. We also discussadvanced methods such as contrastive learning used to improve LLMs' emotioncognition capabilities.</description>
      <author>example@mail.com (Yuyan Chen, Yanghua Xiao)</author>
      <guid isPermaLink="false">2409.13354v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions</title>
      <link>http://arxiv.org/abs/2409.18042v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://emova-ollm.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - GPT-4o是一个全模态模型，能够进行具有多种情感和语调的语音对话，标志着全模态基础模型的一个里程碑。&lt;h4&gt;2. 现有挑战&lt;/h4&gt;   - 使大型语言模型具备端到端处理图像、文本和语音的能力仍然是开源社区面临的挑战。现有的视觉-语言模型依赖外部工具进行语音处理，而语音-语言模型则在视觉理解能力上存在不足。&lt;h4&gt;3. 提出的新模型&lt;/h4&gt;   - 本文提出了EMOVA（情感全在语音助手），旨在为大型语言模型提供端到端的语音能力，同时保持卓越的视觉-语言性能。&lt;h4&gt;4. 技术创新&lt;/h4&gt;   - 采用了语义-声学解耦的语音分词器，发现全模态对齐可以显著增强视觉-语言和语音能力，相较于相应的双模态对齐模型。&lt;h4&gt;5. 灵活性增强&lt;/h4&gt;   - 提出了一个轻量级风格模块，支持灵活的语音风格控制（如情感和音调）。&lt;h4&gt;6. 性能评估&lt;/h4&gt;   - EMOVA首次在视觉-语言和语音基准测试中实现了最先进的性能，同时支持生动情感的全模态口语对话。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; GPT-4o, an omni-modal model that enables vocal conversations with diverseemotions and tones, marks a milestone for omni-modal foundation models.However, empowering Large Language Models to perceive and generate images,texts, and speeches end-to-end with publicly available data remains challengingin the open-source community. Existing vision-language models rely on externaltools for the speech processing, while speech-language models still suffer fromlimited or even without vision-understanding abilities. To address this gap, wepropose EMOVA (EMotionally Omni-present Voice Assistant), to enable LargeLanguage Models with end-to-end speech capabilities while maintaining theleading vision-language performance. With a semantic-acoustic disentangledspeech tokenizer, we notice surprisingly that omni-modal alignment can furtherenhance vision-language and speech abilities compared with the correspondingbi-modal aligned counterparts. Moreover, a lightweight style module is proposedfor flexible speech style controls (e.g., emotions and pitches). For the firsttime, EMOVA achieves state-of-the-art performance on both the vision-languageand speech benchmarks, and meanwhile, supporting omni-modal spoken dialoguewith vivid emotions.</description>
      <author>example@mail.com (Kai Chen, Yunhao Gou, Runhui Huang, Zhili Liu, Daxin Tan, Jing Xu, Chunwei Wang, Yi Zhu, Yihan Zeng, Kuo Yang, Dingdong Wang, Kun Xiang, Haoyuan Li, Haoli Bai, Jianhua Han, Xiaohui Li, Weike Jin, Nian Xie, Yu Zhang, James T. Kwok, Hengshuang Zhao, Xiaodan Liang, Dit-Yan Yeung, Xiao Chen, Zhenguo Li, Wei Zhang, Qun Liu, Lanqing Hong, Lu Hou, Hang Xu)</author>
      <guid isPermaLink="false">2409.18042v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Robotic-CLIP: Fine-tuning CLIP on Action Data for Robotic Applications</title>
      <link>http://arxiv.org/abs/2409.17727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 视觉语言模型在提取有意义特征方面对各种机器人应用发挥了关键作用，尤其是对需要视觉和自然语言理解的任务。&lt;h4&gt;2. 现有模型的局限性&lt;/h4&gt;   - 对比语言-图像预训练（CLIP）模型仅在静态图像与文本提示的配对上进行训练，尚未完全适应涉及动态动作的机器人任务。&lt;h4&gt;3. 新方法的提出&lt;/h4&gt;   - 本文提出了Robotic-CLIP，以增强机器人感知能力。&lt;h4&gt;4. 数据收集与标注&lt;/h4&gt;   - 首先收集并标注了大规模的动作数据，以支持模型的训练。&lt;h4&gt;5. 模型构建&lt;/h4&gt;   - 通过在309,433个动作视频（约740万帧）上使用对比学习微调CLIP，构建了Robotic-CLIP。&lt;h4&gt;6. 性能提升&lt;/h4&gt;   - Robotic-CLIP继承了CLIP在图像处理方面的强大性能，同时获得了理解机器人上下文中动作的能力。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 大规模实验表明，Robotic-CLIP在各种语言驱动的机器人任务中优于其他基于CLIP的模型。&lt;h4&gt;8. 实际应用效果&lt;/h4&gt;   - 进一步展示了Robotic-CLIP在现实世界抓取应用中的实际有效性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision language models have played a key role in extracting meaningfulfeatures for various robotic applications. Among these, ContrastiveLanguage-Image Pretraining (CLIP) is widely used in robotic tasks that requireboth vision and natural language understanding. However, CLIP was trainedsolely on static images paired with text prompts and has not yet been fullyadapted for robotic tasks involving dynamic actions. In this paper, weintroduce Robotic-CLIP to enhance robotic perception capabilities. We firstgather and label large-scale action data, and then build our Robotic-CLIP byfine-tuning CLIP on 309,433 videos (~7.4 million frames) of action data usingcontrastive learning. By leveraging action data, Robotic-CLIP inherits CLIP'sstrong image performance while gaining the ability to understand actions inrobotic contexts. Intensive experiments show that our Robotic-CLIP outperformsother CLIP-based models across various language-driven robotic tasks.Additionally, we demonstrate the practical effectiveness of Robotic-CLIP inreal-world grasping applications.</description>
      <author>example@mail.com (Nghia Nguyen, Minh Nhat Vu, Tung D. Ta, Baoru Huang, Thieu Vo, Ngan Le, Anh Nguyen)</author>
      <guid isPermaLink="false">2409.17727v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>ReFine: Boosting Time Series Prediction of Extreme Events by Reweighting and Fine-tuning</title>
      <link>http://arxiv.org/abs/2409.14232v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 极端事件在气候和天气中非常重要，例如重大风暴、洪水、极端热浪或寒潮等，通常代表着具有显著影响的事件。&lt;h4&gt;2. 挑战&lt;/h4&gt;   - 极端事件通常位于数据分布的尾部，因此预测这些事件具有挑战性，主要因为它们的稀有性和不规则性。&lt;h4&gt;3. OOD问题&lt;/h4&gt;   - 先前研究提到的“分布外（OOD）问题”指的是测试数据的分布与训练数据存在显著差异。&lt;h4&gt;4. 提出的策略&lt;/h4&gt;   - 本文提出了两种策略来应对这一挑战：重加权（reweighting）和微调（fine-tuning）。&lt;h4&gt;5. 重加权策略&lt;/h4&gt;   - 重加权策略通过加权损失函数，使机器学习模型更加关注极端事件，赋予极端样本的预测错误更大的惩罚。&lt;h4&gt;6. 优化方法&lt;/h4&gt;   - 与以往基于简单启发式的重加权方法不同，本文采用元学习（meta-learning）动态优化这些惩罚权重。&lt;h4&gt;7. 微调策略&lt;/h4&gt;   - 在重加权模型的基础上，仅使用稀有的极端样本进行微调，以进一步提高极端样本的性能。&lt;h4&gt;8. 实验验证&lt;/h4&gt;   - 通过对多个数据集的广泛实验，实证验证了元学习基础的重加权方法优于现有的启发式方法，而微调策略能够进一步提升模型性能。&lt;h4&gt;9. 模型通用性&lt;/h4&gt;   - 这两种策略是模型无关的，可以在任何类型的神经网络上实现，用于时间序列预测。&lt;h4&gt;10. 开源代码&lt;/h4&gt;    - 提供了开源代码，网址为 [GitHub](https://github.com/JimengShi/ReFine)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extreme events are of great importance since they often represent impactiveoccurrences. For instance, in terms of climate and weather, extreme eventsmight be major storms, floods, extreme heat or cold waves, and more. However,they are often located at the tail of the data distribution. Consequently,accurately predicting these extreme events is challenging due to their rarityand irregularity. Prior studies have also referred to this as theout-of-distribution (OOD) problem, which occurs when the distribution of thetest data is substantially different from that used for training. In this work,we propose two strategies, reweighting and fine-tuning, to tackle thechallenge. Reweighting is a strategy used to force machine learning models tofocus on extreme events, which is achieved by a weighted loss function thatassigns greater penalties to the prediction errors for the extreme samplesrelative to those on the remainder of the data. Unlike previous intuitivereweighting methods based on simple heuristics of data distribution, we employmeta-learning to dynamically optimize these penalty weights. To further boostthe performance on extreme samples, we start from the reweighted models andfine-tune them using only rare extreme samples. Through extensive experimentson multiple data sets, we empirically validate that our meta-learning-basedreweighting outperforms existing heuristic ones, and the fine-tuning strategycan further increase the model performance. More importantly, these twostrategies are model-agnostic, which can be implemented on any type of neuralnetwork for time series forecasting. The open-sourced code is available at\url{https://github.com/JimengShi/ReFine}.</description>
      <author>example@mail.com (Jimeng Shi, Azam Shirali, Giri Narasimhan)</author>
      <guid isPermaLink="false">2409.14232v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>CREVE: An Acceleration-based Constraint Approach for Robust Radar Ego-Velocity Estimation</title>
      <link>http://arxiv.org/abs/2409.16847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 从毫米波频调连续波（mmWave FMCW）雷达的点云测量中估计自我速度（ego-velocity）已成为雷达惯性里程计（RIO）系统的重要组成部分。&lt;h4&gt;2. 现有方法的局限性&lt;/h4&gt;   - 传统方法在点云异常值数量超过正常值时，表现较差。&lt;h4&gt;3. 提出的新方法&lt;/h4&gt;   - 本文提出了CREVE，这是一种基于加速度的非平等约束滤波器，利用惯性测量单元（IMU）的额外测量数据来实现稳健的自我速度估计。&lt;h4&gt;4. 增强准确性与鲁棒性&lt;/h4&gt;   - 为了进一步提高准确性和对传感器误差的鲁棒性，提出了一种实用的加速度计偏差估计方法和参数适应规则。&lt;h4&gt;5. 方法评估&lt;/h4&gt;   - 通过使用五个开源无人机数据集来评估所提出方法的有效性。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实验结果表明，该算法显著优于三种现有的最先进方法，绝对轨迹误差分别减少约53%、84%和35%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ego-velocity estimation from point cloud measurements of a millimeter-wavefrequency-modulated continuous wave (mmWave FMCW) radar has become a crucialcomponent of radar-inertial odometry (RIO) systems. Conventional approachesoften perform poorly when the number of point cloud outliers exceeds that ofinliers. In this paper, we propose CREVE, an acceleration-based inequalityconstraints filter that leverages additional measurements from an inertialmeasurement unit (IMU) to achieve robust ego-velocity estimations. To furtherenhance accuracy and robustness against sensor errors, we introduce a practicalaccelerometer bias estimation method and a parameter adaptation rule. Theeffectiveness of the proposed method is evaluated using five open-source dronedatasets. Experimental results demonstrate that our algorithm significantlyoutperforms three existing state-of-the-art methods, achieving reductions inabsolute trajectory error of approximately 53%, 84%, and 35% compared to them.</description>
      <author>example@mail.com (Hoang Viet Do, Bo Sung Ko, Jin Woo Song)</author>
      <guid isPermaLink="false">2409.16847v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Neural P$^3$M: A Long-Range Interaction Modeling Enhancer for Geometric GNNs</title>
      <link>http://arxiv.org/abs/2409.17622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 几何图神经网络（GNNs）成为建模分子几何结构的强大工具，但在捕捉大型分子系统中的长程相互作用时存在局限性。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 为了克服这一挑战，本文引入了Neural P³M，这是一个通用的几何GNN增强器，旨在扩展其能力。&lt;h4&gt;3. 方法创新&lt;/h4&gt;   - Neural P³M通过引入网格点与原子结合，并以可训练的方式重新设计传统数学操作，以提升模型的表现。&lt;h4&gt;4. 灵活性与性能&lt;/h4&gt;   - 该方法在多种分子系统中展示了灵活性，并在预测能量和力方面表现出色。&lt;h4&gt;5. 性能评估&lt;/h4&gt;   - Neural P³M在MD22基准测试上优于其他方法，并在OE62数据集上实现了平均22%的性能提升。&lt;h4&gt;6. 架构兼容性&lt;/h4&gt;   - 此方法能够与多种架构集成，进一步增强其应用范围和效果。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometric graph neural networks (GNNs) have emerged as powerful tools formodeling molecular geometry. However, they encounter limitations in effectivelycapturing long-range interactions in large molecular systems. To address thischallenge, we introduce Neural P$^3$M, a versatile enhancer of geometric GNNsto expand the scope of their capabilities by incorporating mesh pointsalongside atoms and reimaging traditional mathematical operations in atrainable manner. Neural P$^3$M exhibits flexibility across a wide range ofmolecular systems and demonstrates remarkable accuracy in predicting energiesand forces, outperforming on benchmarks such as the MD22 dataset. It alsoachieves an average improvement of 22% on the OE62 dataset while integratingwith various architectures.</description>
      <author>example@mail.com (Yusong Wang, Chaoran Cheng, Shaoning Li, Yuxuan Ren, Bin Shao, Ge Liu, Pheng-Ann Heng, Nanning Zheng)</author>
      <guid isPermaLink="false">2409.17622v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Lessons Learned from a Unifying Empirical Study of Parameter-Efficient Transfer Learning (PETL) in Visual Recognition</title>
      <link>http://arxiv.org/abs/2409.16434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code is available at https://github.com/OSU-MLB/PETL_Vision&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 参数高效的迁移学习（PETL）近年来受到广泛关注，因预训练模型规模不断扩大，需要进行微调（FT）以提高下游任务的性能。&lt;h4&gt;2. 研究动机&lt;/h4&gt;   - 尽管PETL方法层出不穷，但缺乏系统性研究以理解其性能及适用场景，未解答何时应用PETL及使用哪种方法的问题。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本文进行了一项统一的实证研究，聚焦于视觉变换器中的代表性PETL方法。&lt;h4&gt;4. 方法与比较&lt;/h4&gt;   - 系统调优超参数，公平比较不同PETL方法在下游任务上的准确性。&lt;h4&gt;5. 研究发现&lt;/h4&gt;   - **相似准确性**：经过仔细调优，不同PETL方法在低样本基准VTAB-1K上可获得相似的准确性，包括一些简单的方法（如仅微调偏置项）。   - **错误模式与高置信度预测**：尽管准确性相似，PETL方法在错误和高置信度预测上存在差异，可能由于不同的归纳偏置。这种不一致性为集成方法提供了机会，研究者进行了初步尝试。   - **多样本场景中的有效性**：PETL在多样本任务中也有效，使用更少的可学习参数时，其准确性与完全微调相当，甚至更好。   - **对分布变化的鲁棒性**：研究PETL在维持预训练模型对分布变化的鲁棒性方面的能力，发现PETL方法优于仅进行完全微调的模型。&lt;h4&gt;6. 未来研究方向&lt;/h4&gt;   - 尽管PETL方法表现良好，但借助权重空间集成，完全微调模型在下游任务和分布外性能之间能取得更好的平衡，提示未来PETL的研究方向。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient transfer learning (PETL) has attracted significantattention lately, due to the increasing size of pre-trained models and the needto fine-tune (FT) them for superior downstream performance. This community-wideenthusiasm has sparked a plethora of new methods. Nevertheless, a systematicstudy to understand their performance and suitable application scenarios islacking, leaving questions like when to apply PETL and which method to uselargely unanswered. In this paper, we conduct a unifying empirical study ofrepresentative PETL methods in the context of Vision Transformers. Wesystematically tune their hyper-parameters to fairly compare their accuracy ondownstream tasks. Our study not only offers a valuable user guide but alsounveils several new insights. First, if tuned carefully, different PETL methodscan obtain quite similar accuracy in the low-shot benchmark VTAB-1K. Thisincludes simple methods like FT the bias terms that were reported inferior.Second, though with similar accuracy, we find that PETL methods make differentmistakes and high-confidence predictions, likely due to their differentinductive biases. Such an inconsistency (or complementariness) opens up theopportunity for ensemble methods, and we make preliminary attempts at this.Third, going beyond the commonly used low-shot tasks, we find that PETL is alsouseful in many-shot regimes -- it achieves comparable and sometimes betteraccuracy than full FT, using much fewer learnable parameters. Last but notleast, we investigate PETL's ability to preserve a pre-trained model'srobustness to distribution shifts (e.g., a CLIP backbone). Perhaps notsurprisingly, PETL methods outperform full FT alone. However, with weight-spaceensembles, the fully FT model can achieve a better balance between downstreamand out-of-distribution performance, suggesting a future research direction forPETL.</description>
      <author>example@mail.com (Zheda Mai, Ping Zhang, Cheng-Hao Tu, Hong-You Chen, Li Zhang, Wei-Lun Chao)</author>
      <guid isPermaLink="false">2409.16434v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Learning of Multi-modal Affine Registration for PET/CT</title>
      <link>http://arxiv.org/abs/2409.13863v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE NSS/MIC/RTSD'24 ((c) IEEE). Code available at
  https://github.com/junyuchen245/Correlation_Ratio&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 仿射配准在PET/CT成像中发挥着关键作用，因PET与CT图像的功能表示和解剖表示不同，导致对齐困难。&lt;h4&gt;2. 深度学习的潜力&lt;/h4&gt;   - 尽管深度学习（DL）方法在各种医学成像应用中显示出巨大潜力，但在多模态PET/CT仿射配准中的应用仍相对未被探索。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本研究探讨了一种基于深度学习的PET/CT仿射配准方法。&lt;h4&gt;4. 新方法的介绍&lt;/h4&gt;   - 提出了一种使用Parzen窗口近似相关比的创新方法，该比率作为训练深度神经网络（DNN）进行多模态配准的图像相似性度量。&lt;h4&gt;5. 优化方案&lt;/h4&gt;   - 提出了一个多尺度、实例特定的优化方案，能够在多个图像分辨率上迭代细化DNN生成的仿射参数。&lt;h4&gt;6. 方法评估&lt;/h4&gt;   - 使用公共FDG-PET/CT数据集和合成仿射变换，对比广泛使用的互信息度量和ANTs软件包中的流行优化技术。&lt;h4&gt;7. 研究结果&lt;/h4&gt;   - 本方法在多模态PET/CT图像配准中取得了平均Dice相似系数（DSC）为0.870，优于比较方法，证明了其有效性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Affine registration plays a crucial role in PET/CT imaging, where aligningPET with CT images is challenging due to their respective functional andanatomical representations. Despite the significant promise shown by recentdeep learning (DL)-based methods in various medical imaging applications, theirapplication to multi-modal PET/CT affine registration remains relativelyunexplored. This study investigates a DL-based approach for PET/CT affineregistration. We introduce a novel method using Parzen windowing to approximatethe correlation ratio, which acts as the image similarity measure for trainingDNNs in multi-modal registration. Additionally, we propose a multi-scale,instance-specific optimization scheme that iteratively refines theDNN-generated affine parameters across multiple image resolutions. Our methodwas evaluated against the widely used mutual information metric and a popularoptimization-based technique from the ANTs package, using a large publicFDG-PET/CT dataset with synthetic affine transformations. Our approach achieveda mean Dice Similarity Coefficient (DSC) of 0.870, outperforming the comparedmethods and demonstrating its effectiveness in multi-modal PET/CT imageregistration.</description>
      <author>example@mail.com (Junyu Chen, Yihao Liu, Shuwen Wei, Aaron Carass, Yong Du)</author>
      <guid isPermaLink="false">2409.13863v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MALPOLON: A Framework for Deep Species Distribution Modeling</title>
      <link>http://arxiv.org/abs/2409.18102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文描述了一个深度物种分布模型框架，称为MALPOLON。&lt;h4&gt;2. 技术基础&lt;/h4&gt;   - 该框架用Python编写，基于PyTorch库，旨在便于深度物种分布模型（deep-SDM）的训练和推理。&lt;h4&gt;3. 目标用户&lt;/h4&gt;   - 主要面向具有一般Python语言技能的用户（如建模生态学家），帮助他们测试深度学习方法以构建新的物种分布模型。&lt;h4&gt;4. 高级用户的优势&lt;/h4&gt;   - 更高级的用户可以利用框架的模块性，通过重写现有类来进行更具体的实验，同时利用一键示例在自定义或提供的原始和预处理数据集上训练神经网络进行多分类任务。&lt;h4&gt;5. 开源与文档&lt;/h4&gt;   - MALPOLON在GitHub和PyPi上开源，提供了丰富的文档和多种使用场景的示例。&lt;h4&gt;6. 功能特点&lt;/h4&gt;   - 该框架提供简单的安装过程、基于YAML的配置、并行计算、多GPU利用、基准测试的基础模型，以及广泛的教程和文档。&lt;h4&gt;7. 目标与贡献&lt;/h4&gt;   - MALPOLON旨在提高生态学家和研究人员的可访问性和性能可扩展性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes a deep-SDM framework, MALPOLON. Written in Python andbuilt upon the PyTorch library, this framework aims to facilitate training andinferences of deep species distribution models (deep-SDM) and sharing for userswith only general Python language skills (e.g., modeling ecologists) who areinterested in testing deep learning approaches to build new SDMs. More advancedusers can also benefit from the framework's modularity to run more specificexperiments by overriding existing classes while taking advantage ofpress-button examples to train neural networks on multiple classification tasksusing custom or provided raw and pre-processed datasets. The framework isopen-sourced on GitHub and PyPi along with extensive documentation and examplesof use in various scenarios. MALPOLON offers straightforward installation,YAML-based configuration, parallel computing, multi-GPU utilization, baselineand foundational models for benchmarking, and extensivetutorials/documentation, aiming to enhance accessibility and performancescalability for ecologists and researchers.</description>
      <author>example@mail.com (Theo Larcher, Lukas Picek, Benjamin Deneu, Titouan Lorieul, Maximilien Servajean, Alexis Joly)</author>
      <guid isPermaLink="false">2409.18102v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Trading through Earnings Seasons using Self-Supervised Contrastive Representation Learning</title>
      <link>http://arxiv.org/abs/2409.17392v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 盈利公告是金融市场中的一个关键经济事件，对预测股票走势至关重要。盈利数据提供了公司财务状况的洞察，并暗示股票未来走势。&lt;h4&gt;2. 发布周期的挑战&lt;/h4&gt;   - 盈利公告的发布周期不规律，使得在中频算法交易模型中整合此数据变得困难。此外，数据发布后其有效性迅速下降，导致模型随时间保持准确性的挑战。&lt;h4&gt;3. 提出的新模型&lt;/h4&gt;   - 为了解决这一挑战，本文引入了对比收益变换器（CET）模型，这是一种基于对比预测编码（CPC）的自监督学习方法，旨在优化盈利数据的利用。&lt;h4&gt;4. 有效性评估&lt;/h4&gt;   - 我们对CET模型与各行业基准模型进行比较研究，以验证其有效性。&lt;h4&gt;5. 深入分析&lt;/h4&gt;   - 研究深入探讨了股票数据的复杂性，评估不同模型（尤其是CET）如何处理盈利数据随时间变化的相关性。&lt;h4&gt;6. 研究成果&lt;/h4&gt;   - 研究结果显示，CET在提取盈利数据的内在价值方面具有明显优势。基于CPC的设计使其能够更细致地理解盈利数据，从而即便在数据老化后也能保持一致的股票预测。&lt;h4&gt;7. 新方法的意义&lt;/h4&gt;   - CET的发现为在算法交易中更好地利用盈利数据预测股票价格趋势提供了一种新方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Earnings release is a key economic event in the financial markets and crucialfor predicting stock movements. Earnings data gives a glimpse into how acompany is doing financially and can hint at where its stock might go next.However, the irregularity of its release cycle makes it a challenge toincorporate this data in a medium-frequency algorithmic trading model and theusefulness of this data fades fast after it is released, making it tough formodels to stay accurate over time. Addressing this challenge, we introduce theContrastive Earnings Transformer (CET) model, a self-supervised learningapproach rooted in Contrastive Predictive Coding (CPC), aiming to optimise theutilisation of earnings data. To ascertain its effectiveness, we conduct acomparative study of CET against benchmark models across diverse sectors. Ourresearch delves deep into the intricacies of stock data, evaluating how variousmodels, and notably CET, handle the rapidly changing relevance of earnings dataover time and over different sectors. The research outcomes shed light on CET'sdistinct advantage in extrapolating the inherent value of earnings data overtime. Its foundation on CPC allows for a nuanced understanding, facilitatingconsistent stock predictions even as the earnings data ages. This finding aboutCET presents a fresh approach to better use earnings data in algorithmictrading for predicting stock price trends.</description>
      <author>example@mail.com (Zhengxin Joseph Ye, Bjoern Schuller)</author>
      <guid isPermaLink="false">2409.17392v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Bi-Filtration and Stability of TDA Mapper for Point Cloud Data</title>
      <link>http://arxiv.org/abs/2409.17360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - Carlsson、Singh和Memoli的TDA mapper将点云数据集转换为依赖于多个参数选择的图。&lt;h4&gt;2. 多尺度映射器的发展&lt;/h4&gt;   - Dey、Memoli和Wang开发了多尺度映射器，用于抽象拓扑空间，以便通过持久同调分析参数选择。&lt;h4&gt;3. 实际数据的挑战&lt;/h4&gt;   - 在应用于实际数据时，并不总能获得mapper图的滤波。&lt;h4&gt;4. DBSCAN算法的参数&lt;/h4&gt;   - DBSCAN是TDA mapper软件中常用的聚类算法，具有两个参数：\(\epsilon\)和MinPts。   - 当MinPts = 1时，DBSCAN等同于单连接聚类，切割高度为\(\epsilon\)。&lt;h4&gt;5. 聚类的影响&lt;/h4&gt;   - 如果使用MinPts &gt; 2进行DBSCAN聚类，除非没有自由边界点，否则可能不会存在mapper图的滤波。&lt;h4&gt;6. 聚类参数的影响&lt;/h4&gt;   - 使用MinPts = 1或2时，随着覆盖大小\(\epsilon\)的增加和/或MinPts的减少，存在mapper图的滤波。&lt;h4&gt;7. 滤波的不稳定性&lt;/h4&gt;   - 1维滤波不稳定；如果数据集中添加噪声，使每个数据点最大偏移\(\delta\)，则扰动数据集的mapper图的持久同调可能与原始数据集显著不同。&lt;h4&gt;8. 稳定性的获得&lt;/h4&gt;   - 通过同时增加覆盖大小和\(\epsilon\)，可以获得稳定性。&lt;h4&gt;9. 同调群的双滤波&lt;/h4&gt;   - 特别地，展示了这两个数据集的同调群关于覆盖大小和\(\epsilon\)的双滤波是2\(\delta\)-交错的。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Carlsson, Singh and Memoli's TDA mapper takes a point cloud dataset andoutputs a graph that depends on several parameter choices. Dey, Memoli, andWang developed Multiscale Mapper for abstract topological spaces so thatparameter choices can be analyzed via persistent homology. However, whenapplied to actual data, one does not always obtain filtrations of mappergraphs. DBSCAN, one of the most common clustering algorithms used in the TDAmapper software, has two parameters, \textbf{$\epsilon$} and \textbf{MinPts}.If \textbf{MinPts = 1} then DBSCAN is equivalent to single linkage clusteringwith cutting height \textbf{$\epsilon$}. We show that if DBSCAN clustering isused with \textbf{MinPts $&gt;$ 2}, a filtration of mapper graphs may not existexcept in the absence of free-border points; but such filtrations exist ifDBSCAN clustering is used with \textbf{MinPts = 1} or \textbf{2} as the coversize increases, \textbf{$\epsilon$} increases, and/or \textbf{MinPts}decreases. However, the 1-dimensional filtration is unstable. If one adds noiseto a data set so that each data point has been perturbed by a distance at most\textbf{$\delta$}, the persistent homology of the mapper graph of the perturbeddata set can be significantly different from that of the original data set. Weshow that we can obtain stability by increasing both the cover size and\textbf{$\epsilon$} at the same time. In particular, we show that thebi-filtrations of the homology groups with respect to cover size and $\epsilon$between these two datasets are \textbf{2$\delta$}-interleaved.</description>
      <author>example@mail.com (Wako Bungula, Isabel Darcy)</author>
      <guid isPermaLink="false">2409.17360v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Convolutional Signal Propagation: A Simple Scalable Algorithm for Hypergraphs</title>
      <link>http://arxiv.org/abs/2409.17628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 过去十年，图学习方法，特别是图神经网络（GNNs），得到了广泛发展。&lt;h4&gt;2. 现有方法的局限性&lt;/h4&gt;   - 这些方法通常无法直接应用于更复杂的结构，如双边图（相当于超图），这类图表示两种实体类型之间的交互（例如，用户喜欢某部电影）。&lt;h4&gt;3. 提出的新方法&lt;/h4&gt;   - 本文提出了一种名为卷积信号传播（CSP）的方法，这是一种无参数、简单且可扩展的方法，能够原生操作双边图（超图），并且实现代码量极少。&lt;h4&gt;4. CSP的定义与关系&lt;/h4&gt;   - 在定义CSP后，展示了它与成熟方法（如标签传播、朴素贝叶斯和超图卷积网络）的关系。&lt;h4&gt;5. 评估与比较&lt;/h4&gt;   - 在多个领域的真实数据集上评估CSP，与多种参考方法进行比较，重点关注检索和分类任务。&lt;h4&gt;6. 性能结果&lt;/h4&gt;   - 结果表明，CSP在保持低计算复杂度的同时，提供了竞争力的性能，成为超图节点分类和检索的理想基线选择。&lt;h4&gt;7. 广泛适用性&lt;/h4&gt;   - 尽管CSP在超图上操作，但在通常不与超图相关的任务（如自然语言处理）上也取得了良好的结果。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Last decade has seen the emergence of numerous methods for learning ongraphs, particularly Graph Neural Networks (GNNs). These methods, however, areoften not directly applicable to more complex structures like bipartite graphs(equivalent to hypergraphs), which represent interactions among two entitytypes (e.g. a user liking a movie). This paper proposes Convolutional SignalPropagation (CSP), a non-parametric simple and scalable method that nativelyoperates on bipartite graphs (hypergraphs) and can be implemented with just afew lines of code. After defining CSP, we demonstrate its relationship withwell-established methods like label propagation, Naive Bayes, and HypergraphConvolutional Networks. We evaluate CSP against several reference methods onreal-world datasets from multiple domains, focusing on retrieval andclassification tasks. Our results show that CSP offers competitive performancewhile maintaining low computational complexity, making it an ideal first choiceas a baseline for hypergraph node classification and retrieval. Moreover,despite operating on hypergraphs, CSP achieves good results in tasks typicallynot associated with hypergraphs, such as natural language processing.</description>
      <author>example@mail.com (Pavel Procházka, Marek Dědič, Lukáš Bajer)</author>
      <guid isPermaLink="false">2409.17628v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Transfer learning for financial data predictions: a systematic review</title>
      <link>http://arxiv.org/abs/2409.17183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  43 pages, 5 tables, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 文献指出，金融时间序列数据在准确预测股票价格方面面临重大挑战，这些数据特征包括噪声和对新闻的敏感性。&lt;h4&gt;2. 传统方法的局限性&lt;/h4&gt;   - 传统统计方法假设数据具有线性和正态性，这不适合金融时间序列的非线性特征。&lt;h4&gt;3. 机器学习的优势&lt;/h4&gt;   - 机器学习方法能够捕捉数据中的非线性关系，因此被认为是预测金融价格的主要工具。&lt;h4&gt;4. 神经网络的主导地位&lt;/h4&gt;   - 当前，神经网络被视为主要的机器学习工具，用于金融价格预测。&lt;h4&gt;5. 迁移学习的潜力&lt;/h4&gt;   - 迁移学习是一种旨在将知识从源任务转移到目标任务的方法，可能为改善金融预测能力提供重要的工具。&lt;h4&gt;6. 文献回顾的不足&lt;/h4&gt;   - 目前对金融预测的文献回顾主要集中在神经网络架构上，鲜有对迁移学习方法的重视。&lt;h4&gt;7. 研究目标&lt;/h4&gt;   - 本文旨在深入探讨迁移学习在金融市场预测中的应用，以及迁移学习方法在股票市场预测中的挑战和未来潜在方向。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Literature highlighted that financial time series data pose significantchallenges for accurate stock price prediction, because these data arecharacterized by noise and susceptibility to news; traditional statisticalmethodologies made assumptions, such as linearity and normality, which are notsuitable for the non-linear nature of financial time series; on the other hand,machine learning methodologies are able to capture non linear relationship inthe data. To date, neural network is considered the main machine learning toolfor the financial prices prediction. Transfer Learning, as a method aimed attransferring knowledge from source tasks to target tasks, can represent a veryuseful methodological tool for getting better financial prediction capability.Current reviews on the above body of knowledge are mainly focused on neuralnetwork architectures, for financial prediction, with very little emphasis onthe transfer learning methodology; thus, this paper is aimed at going deeper onthis topic by developing a systematic review with respect to application ofTransfer Learning for financial market predictions and to challenges/potentialfuture directions of the transfer learning methodologies for stock marketpredictions.</description>
      <author>example@mail.com (V. Lanzetta)</author>
      <guid isPermaLink="false">2409.17183v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Brain-Cognition Fingerprinting via Graph-GCCA with Contrastive Learning</title>
      <link>http://arxiv.org/abs/2409.13887v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 许多纵向神经影像学研究旨在通过研究大脑功能与认知之间的动态互动，改善对大脑老化和疾病的理解。&lt;h4&gt;2. 研究需求&lt;/h4&gt;   - 需要准确编码大脑功能与认知之间的多维关系，同时考虑个体随时间的变化。&lt;h4&gt;3. 提出的新模型&lt;/h4&gt;   - 本文提出了一种无监督学习模型，称为对比学习基础的图泛化典型相关分析（CoGraCa）。&lt;h4&gt;4. 模型功能&lt;/h4&gt;   - CoGraCa通过图注意网络和广义典型相关分析编码大脑与认知之间的关系。&lt;h4&gt;5. 个性化指纹创建&lt;/h4&gt;   - 模型依赖个性化和多模态对比学习来创建反映每个人独特神经和认知表型的“大脑-认知指纹”。&lt;h4&gt;6. 数据集应用&lt;/h4&gt;   - 将CoGraCa应用于健康个体的纵向数据集，包括多次访谈中获取的静息态功能MRI和认知测量。&lt;h4&gt;7. 指纹效果&lt;/h4&gt;   - 生成的指纹有效捕捉显著的个体差异，并在识别性别和年龄方面超越现有的单模态和基于CCA的多模态模型。&lt;h4&gt;8. 可解释性&lt;/h4&gt;   - 更重要的是，模型编码提供了这两种模态之间的可解释交互。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many longitudinal neuroimaging studies aim to improve the understanding ofbrain aging and diseases by studying the dynamic interactions between brainfunction and cognition. Doing so requires accurate encoding of theirmultidimensional relationship while accounting for individual variability overtime. For this purpose, we propose an unsupervised learning model (called\underline{\textbf{Co}}ntrastive Learning-based \underline{\textbf{Gra}}phGeneralized \underline{\textbf{Ca}}nonical Correlation Analysis (CoGraCa)) thatencodes their relationship via Graph Attention Networks and generalizedCanonical Correlational Analysis. To create brain-cognition fingerprintsreflecting unique neural and cognitive phenotype of each person, the model alsorelies on individualized and multimodal contrastive learning. We apply CoGraCato longitudinal dataset of healthy individuals consisting of resting-statefunctional MRI and cognitive measures acquired at multiple visits for eachparticipant. The generated fingerprints effectively capture significantindividual differences and outperform current single-modal and CCA-basedmultimodal models in identifying sex and age. More importantly, our encodingprovides interpretable interactions between those two modalities.</description>
      <author>example@mail.com (Yixin Wang, Wei Peng, Yu Zhang, Ehsan Adeli, Qingyu Zhao, Kilian M. Pohl)</author>
      <guid isPermaLink="false">2409.13887v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Semi-Supervised 3D Object Detection with Channel Augmentation using Transformation Equivariance</title>
      <link>http://arxiv.org/abs/2409.06583v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to 2024 IEEE International Conference on Image Processing
  (ICIP)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 准确的3D物体检测对自主车辆和机器人安全有效地导航和与环境互动至关重要。&lt;h4&gt;2. 性能依赖于数据&lt;/h4&gt;   - 3D检测器的性能依赖于数据规模和注释，这些注释成本高昂。&lt;h4&gt;3. 需求增长&lt;/h4&gt;   - 对于使用有限标注数据进行训练的需求日益增长。&lt;h4&gt;4. 提出的新框架&lt;/h4&gt;   - 本研究探讨了一种新颖的教师-学生框架，采用通道增强技术进行3D半监督物体检测。&lt;h4&gt;5. 教师-学生自监督学习&lt;/h4&gt;   - 教师-学生自监督学习（SSL）通常对教师应用弱增强，对学生应用强增强。&lt;h4&gt;6. 多通道增强的应用&lt;/h4&gt;   - 本研究对两个网络都应用了多通道增强，使用变换等变性检测器（TED）。&lt;h4&gt;7. TED的优势&lt;/h4&gt;   - TED允许我们探索点云上的不同增强组合，并有效聚合多通道的变换等变性特征。&lt;h4&gt;8. 固定增强的益处&lt;/h4&gt;   - 通过为教师网络采用固定的通道增强，学生可以在可靠的伪标签上稳定训练。&lt;h4&gt;9. 增强数据多样性&lt;/h4&gt;   - 采用强通道增强可以丰富数据的多样性，提高对变换的鲁棒性，并增强学生网络的泛化性能。&lt;h4&gt;10. 基线和一致性&lt;/h4&gt;    - 我们使用最先进的分层监督作为基线，并将其双阈值适配到TED，称为通道IoU一致性。&lt;h4&gt;11. 实验评估&lt;/h4&gt;    - 我们在KITTI数据集上评估了我们的方法，取得了显著的性能提升，超越了最先进的3D半监督物体检测模型。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate 3D object detection is crucial for autonomous vehicles and robots tonavigate and interact with the environment safely and effectively. Meanwhile,the performance of 3D detector relies on the data size and annotation which isexpensive. Consequently, the demand of training with limited labeled data isgrowing. We explore a novel teacher-student framework employing channelaugmentation for 3D semi-supervised object detection. The teacher-student SSLtypically adopts a weak augmentation and strong augmentation to teacher andstudent, respectively. In this work, we apply multiple channel augmentations toboth networks using the transformation equivariance detector (TED). The TEDallows us to explore different combinations of augmentation on point clouds andefficiently aggregates multi-channel transformation equivariance features. Inprinciple, by adopting fixed channel augmentations for the teacher network, thestudent can train stably on reliable pseudo-labels. Adopting strong channelaugmentations can enrich the diversity of data, fostering robustness totransformations and enhancing generalization performance of the studentnetwork. We use SOTA hierarchical supervision as a baseline and adapt itsdual-threshold to TED, which is called channel IoU consistency. We evaluate ourmethod with KITTI dataset, and achieved a significant performance leap,surpassing SOTA 3D semi-supervised object detection models.</description>
      <author>example@mail.com (Minju Kang, Taehun Kong, Tae-Kyun Kim)</author>
      <guid isPermaLink="false">2409.06583v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Lotus: Diffusion-based Visual Foundation Model for High-quality Dense Prediction</title>
      <link>http://arxiv.org/abs/2409.18124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://lotus3d.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 利用预训练的文本到图像扩散模型的视觉先验，提供了一种增强零-shot泛化在密集预测任务中的有效解决方案。&lt;h4&gt;2. 现有方法的局限性&lt;/h4&gt;   - 现有方法通常不加批判地使用原始扩散公式，这在密集预测和图像生成之间存在根本性差异时可能不是最优的。&lt;h4&gt;3. 系统分析&lt;/h4&gt;   - 本文对密集预测的扩散公式进行了系统分析，关注质量和效率两个方面。&lt;h4&gt;4. 发现的问题&lt;/h4&gt;   - 原始的图像生成参数化类型（学习预测噪声）对密集预测有害。   - 多步骤的加噪/去噪扩散过程也是不必要的，且优化难度大。&lt;h4&gt;5. 提出的新模型&lt;/h4&gt;   - 基于这些见解，提出了Lotus，一个基于扩散的视觉基础模型，具有简单有效的适配协议用于密集预测。&lt;h4&gt;6. 模型训练方式&lt;/h4&gt;   - Lotus直接预测注释而不是噪声，从而避免有害的方差。&lt;h4&gt;7. 简化扩散过程&lt;/h4&gt;   - 将扩散过程重新公式化为单步骤程序，简化了优化过程并显著提高了推理速度。&lt;h4&gt;8. 新调优策略&lt;/h4&gt;   - 引入了一种新调优策略，称为“细节保护器”，能够实现更准确和细致的预测。&lt;h4&gt;9. 性能表现&lt;/h4&gt;   - 在不扩大训练数据或模型容量的情况下，Lotus在多个数据集上实现了零-shot深度和法线估计的最先进（SoTA）性能。&lt;h4&gt;10. 效率提升&lt;/h4&gt;    - Lotus显著提高了效率，比大多数现有的基于扩散的方法快数百倍。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging the visual priors of pre-trained text-to-image diffusion modelsoffers a promising solution to enhance zero-shot generalization in denseprediction tasks. However, existing methods often uncritically use the originaldiffusion formulation, which may not be optimal due to the fundamentaldifferences between dense prediction and image generation. In this paper, weprovide a systemic analysis of the diffusion formulation for the denseprediction, focusing on both quality and efficiency. And we find that theoriginal parameterization type for image generation, which learns to predictnoise, is harmful for dense prediction; the multi-step noising/denoisingdiffusion process is also unnecessary and challenging to optimize. Based onthese insights, we introduce Lotus, a diffusion-based visual foundation modelwith a simple yet effective adaptation protocol for dense prediction.Specifically, Lotus is trained to directly predict annotations instead ofnoise, thereby avoiding harmful variance. We also reformulate the diffusionprocess into a single-step procedure, simplifying optimization andsignificantly boosting inference speed. Additionally, we introduce a noveltuning strategy called detail preserver, which achieves more accurate andfine-grained predictions. Without scaling up the training data or modelcapacity, Lotus achieves SoTA performance in zero-shot depth and normalestimation across various datasets. It also significantly enhances efficiency,being hundreds of times faster than most existing diffusion-based methods.</description>
      <author>example@mail.com (Jing He, Haodong Li, Wei Yin, Yixun Liang, Leheng Li, Kaiqiang Zhou, Hongbo Liu, Bingbing Liu, Ying-Cong Chen)</author>
      <guid isPermaLink="false">2409.18124v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Hyper-Graph Neural Networks for Context-aware Human Activity Recognition</title>
      <link>http://arxiv.org/abs/2409.17483v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PerCom 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 上下文感知的人体活动识别（CHAR）面临挑战，需从受手机放置和用户表现风格等上下文因素显著变化的信号中识别用户的当前活动。&lt;h4&gt;2. 研究主张&lt;/h4&gt;   - 我们认为，上下文感知的活动访问模式可以视为一种通用的图表示学习任务。&lt;h4&gt;3. 图模式的利用&lt;/h4&gt;   - 利用CHAR数据中的潜在图模式可以提高识别任务的性能和表示学习效果。&lt;h4&gt;4. 关注的活动&lt;/h4&gt;   - 我们专注于识别&lt;活动, 手机放置&gt;元组，基于某些活动通常在特定手机位置下执行的直觉。&lt;h4&gt;5. 图结构&lt;/h4&gt;   - CHAR数据具有潜在的图结构，可以视为一种异构超图，包含多种类型的节点和超边（连接多个节点的边）。&lt;h4&gt;6. 任务转化&lt;/h4&gt;   - 将学习&lt;活动, 手机放置&gt;表示转化为图节点表示学习问题。&lt;h4&gt;7. 提出的新架构&lt;/h4&gt;   - 本文提出了一种新颖的异构超图神经网络架构（HHGNN-CHAR），包括三种类型的异构节点（用户、手机放置和活动），所有节点之间的连接通过超边表示。&lt;h4&gt;8. 评估结果&lt;/h4&gt;   - 在未脚本化的实际CHAR数据集上，经过严格评估，我们的框架显著超越了现有的最先进基线，包括未利用图的CHAR模型和未结合异构节点或超边的GNN变体，整体提升14.04%在马修斯相关系数（MCC）和7.01%在宏F1分数上。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/PerComWorkshops56833.2023.10150328&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Context-aware Human Activity Recognition (CHAR) is challenging due to theneed to recognize the user's current activity from signals that varysignificantly with contextual factors such as phone placements and the variedstyles with which different users perform the same activity. In this paper, weargue that context-aware activity visit patterns in realistic in-the-wild datacan equivocally be considered as a general graph representation learning task.We posit that exploiting underlying graphical patterns in CHAR data can improveCHAR task performance and representation learning. Building on the intuitionthat certain activities are frequently performed with the phone placed incertain positions, we focus on the context-aware human activity problem ofrecognizing the &lt;Activity, Phone Placement&gt; tuple. We demonstrate that CHARdata has an underlying graph structure that can be viewed as a heterogenoushypergraph that has multiple types of nodes and hyperedges (an edge connectingmore than two nodes). Subsequently, learning &lt;Activity, Phone Placement&gt;representations becomes a graph node representation learning problem. Aftertask transformation, we further propose a novel Heterogeneous HyperGraph NeuralNetwork architecture for Context-aware Human Activity Recognition (HHGNN-CHAR),with three types of heterogeneous nodes (user, phone placement, and activity).Connections between all types of nodes are represented by hyperedges. Rigorousevaluation demonstrated that on an unscripted, in-the-wild CHAR dataset, ourproposed framework significantly outperforms state-of-the-art (SOTA) baselinesincluding CHAR models that do not exploit graphs, and GNN variants that do notincorporate heterogeneous nodes or hyperedges with overall improvements 14.04%on Matthews Correlation Coefficient (MCC) and 7.01% on Macro F1 scores.</description>
      <author>example@mail.com (Wen Ge, Guanyi Mou, Emmanuel O. Agu, Kyumin Lee)</author>
      <guid isPermaLink="false">2409.17483v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Hand-object reconstruction via interaction-aware graph attention mechanism</title>
      <link>http://arxiv.org/abs/2409.17629v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, Accepted by ICIP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着对高级视觉计算需求的增长，估计手部和物体的姿态已成为一个重要研究领域。&lt;h4&gt;2. 主要挑战&lt;/h4&gt;   - 主要挑战在于理解和重建手与物体之间的交互，如接触和物理合理性。&lt;h4&gt;3. 现有方法的局限性&lt;/h4&gt;   - 现有方法通常采用图神经网络来整合手和物体网格的空间信息，但未充分利用图的潜力，尤其是在手图和物体图之间的边缘修改方面。&lt;h4&gt;4. 提出的新方法&lt;/h4&gt;   - 我们提出了一种基于图的细化方法，结合了交互感知的图注意机制，以考虑手-物体交互。&lt;h4&gt;5. 边缘的连接&lt;/h4&gt;   - 通过边缘建立紧密相关节点之间的连接，既包括单一图内的节点，也包括不同图之间的节点。&lt;h4&gt;6. 实验验证&lt;/h4&gt;   - 实验结果展示了我们提出的方法的有效性，在物理合理性方面显著改善。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating the poses of both a hand and an object has become an importantarea of research due to the growing need for advanced vision computing. Theprimary challenge involves understanding and reconstructing how hands andobjects interact, such as contact and physical plausibility. Existingapproaches often adopt a graph neural network to incorporate spatialinformation of hand and object meshes. However, these approaches have not fullyexploited the potential of graphs without modification of edges within andbetween hand- and object-graphs. We propose a graph-based refinement methodthat incorporates an interaction-aware graph-attention mechanism to account forhand-object interactions. Using edges, we establish connections among closelycorrelated nodes, both within individual graphs and across different graphs.Experiments demonstrate the effectiveness of our proposed method with notableimprovements in the realm of physical plausibility.</description>
      <author>example@mail.com (Taeyun Woo, Tae-Kyun Kim, Jinah Park)</author>
      <guid isPermaLink="false">2409.17629v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Graph Pruning Based Spatial and Temporal Graph Convolutional Network with Transfer Learning for Traffic Prediction</title>
      <link>http://arxiv.org/abs/2409.16532v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, accepted by ICIAAI2023, withdrawn from proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 城市化与交通拥堵问题&lt;/h4&gt;   - 随着城市化进程和人口快速增长，交通拥堵问题变得越来越严重。&lt;h4&gt;2. 智能交通系统的需求&lt;/h4&gt;   - 智能交通系统依赖实时、准确的预测算法来解决交通拥堵问题。&lt;h4&gt;3. 深度学习方法的局限性&lt;/h4&gt;   - 尽管递归神经网络（RNN）和图卷积网络（GCN）在数据充足时能高效预测道路状况，但在数据有限的情况下，预测道路网络仍然是一个挑战。&lt;h4&gt;4. 提出的新方法&lt;/h4&gt;   - 本研究提出了一种基于图剪枝和迁移学习框架的新型时空卷积网络（TL-GPSTGN）来应对这一问题。&lt;h4&gt;5. 图结构的分析&lt;/h4&gt;   - 首先，通过分析道路网络结构和特征数据的相关性及信息熵，提取图的基本结构和信息。&lt;h4&gt;6. 图剪枝技术的应用&lt;/h4&gt;   - 利用图剪枝技术处理图的邻接矩阵和输入特征数据，从而显著提高模型的迁移性能。&lt;h4&gt;7. 时空关系的捕获&lt;/h4&gt;   - 将处理后的数据输入时空图卷积网络，以捕捉时空关系并预测道路状况。&lt;h4&gt;8. 测试与验证&lt;/h4&gt;   - 本研究在真实数据集上对TL-GPSTGN方法进行了全面测试和验证，并与其他常用模型在相同条件下的预测性能进行了比较。&lt;h4&gt;9. 结果表现&lt;/h4&gt;   - 实验结果表明，TL-GPSTGN在单一数据集上的预测准确性卓越，并且在不同数据集上展现出强大的迁移性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the process of urbanization and the rapid growth of population, theissue of traffic congestion has become an increasingly critical concern.Intelligent transportation systems heavily rely on real-time and preciseprediction algorithms to address this problem. While Recurrent Neural Network(RNN) and Graph Convolutional Network (GCN) methods in deep learning havedemonstrated high accuracy in predicting road conditions when sufficient datais available, forecasting in road networks with limited data remains achallenging task. This study proposed a novel Spatial-temporal ConvolutionalNetwork (TL-GPSTGN) based on graph pruning and transfer learning framework totackle this issue. Firstly, the essential structure and information of thegraph are extracted by analyzing the correlation and information entropy of theroad network structure and feature data. By utilizing graph pruning techniques,the adjacency matrix of the graph and the input feature data are processed,resulting in a significant improvement in the model's migration performance.Subsequently, the well-characterized data are inputted into thespatial-temporal graph convolutional network to capture the spatial-temporalrelationships and make predictions regarding the road conditions. Furthermore,this study conducts comprehensive testing and validation of the TL-GPSTGNmethod on real datasets, comparing its prediction performance against othercommonly used models under identical conditions. The results demonstrate theexceptional predictive accuracy of TL-GPSTGN on a single dataset, as well asits robust migration performance across different datasets.</description>
      <author>example@mail.com (Zihao Jing)</author>
      <guid isPermaLink="false">2409.16532v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Vision-Language Models Assisted Unsupervised Video Anomaly Detection</title>
      <link>http://arxiv.org/abs/2409.14109v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 视频异常检测的重要性&lt;/h4&gt;   - 视频异常检测在工业和学术领域受到广泛关注，因为它在计算机视觉应用中扮演着关键角色。&lt;h4&gt;2. 面临的挑战&lt;/h4&gt;   - 异常的不可预测性和异常样本的稀缺性对无监督学习方法构成了重大挑战。&lt;h4&gt;3. 提出的新方法&lt;/h4&gt;   - 为克服无监督学习的局限性（缺乏全面的异常知识），我们提出了VLAVAD（视频-语言模型辅助异常检测）。&lt;h4&gt;4. 方法的核心技术&lt;/h4&gt;   - 该方法采用跨模态的预训练模型，结合大型语言模型（LLMs）的推理能力。   - 引入选择性提示适配器（SPA）来选择语义空间。&lt;h4&gt;5. 时间一致性检测&lt;/h4&gt;   - 引入序列状态空间模块（S3M），用于检测语义特征中的时间不一致性。&lt;h4&gt;6. 特征映射与可解释性&lt;/h4&gt;   - 通过将高维视觉特征映射到低维语义特征，我们的方法显著增强了无监督异常检测的可解释性。&lt;h4&gt;7. 性能表现&lt;/h4&gt;   - 所提出的方法有效应对了检测难以识别的异常的挑战，在挑战性的上海科技数据集上达到了最先进的性能（SOTA）。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video anomaly detection is a subject of great interest across industrial andacademic domains due to its crucial role in computer vision applications.However, the inherent unpredictability of anomalies and the scarcity of anomalysamples present significant challenges for unsupervised learning methods. Toovercome the limitations of unsupervised learning, which stem from a lack ofcomprehensive prior knowledge about anomalies, we propose VLAVAD(Video-Language Models Assisted Anomaly Detection). Our method employs across-modal pre-trained model that leverages the inferential capabilities oflarge language models (LLMs) in conjunction with a Selective-Prompt Adapter(SPA) for selecting semantic space. Additionally, we introduce a Sequence StateSpace Module (S3M) that detects temporal inconsistencies in semantic features.By mapping high-dimensional visual features to low-dimensional semantic ones,our method significantly enhance the interpretability of unsupervised anomalydetection. Our proposed approach effectively tackles the challenge of detectingelusive anomalies that are hard to discern over periods, achieving SOTA on thechallenging ShanghaiTech dataset.</description>
      <author>example@mail.com (Yalong Jiang, Liquan Mao)</author>
      <guid isPermaLink="false">2409.14109v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Evaluation of Security of ML-based Watermarking: Copy and Removal Attacks</title>
      <link>http://arxiv.org/abs/2409.18211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 数字内容的需求&lt;/h4&gt;   - 随着从现实世界和AI生成的媒体中捕获的大量数字内容，迫切需要保护版权、追踪内容和验证数据来源的方法。&lt;h4&gt;2. 数字水印的重要性&lt;/h4&gt;   - 数字水印是一种关键方法，用以应对上述挑战，确保内容的合法性和可追溯性。&lt;h4&gt;3. 数字水印的发展历程&lt;/h4&gt;   - 水印技术经历了三个发展阶段：     - 手工制作的方法     - 基于自编码器的方案     - 基于基础模型的方法&lt;h4&gt;4. 安全性研究的不足&lt;/h4&gt;   - 尽管这些水印系统的鲁棒性得到了充分记录，但对抗性攻击下的安全性仍然未被充分探讨。&lt;h4&gt;5. 研究目标&lt;/h4&gt;   - 本文评估了基础模型的潜在空间数字水印系统，这些系统利用对抗嵌入技术。&lt;h4&gt;6. 实验内容&lt;/h4&gt;   - 一系列实验调查了在复制和移除攻击下的安全性维度，为这些系统的脆弱性提供了实证洞见。&lt;h4&gt;7. 数据可获得性&lt;/h4&gt;   - 所有实验代码和结果可在指定的GitHub仓库中获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vkinakh/ssl-watermarking-attacks&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The vast amounts of digital content captured from the real world orAI-generated media necessitate methods for copyright protection, traceability,or data provenance verification. Digital watermarking serves as a crucialapproach to address these challenges. Its evolution spans three generations:handcrafted, autoencoder-based, and foundation model based methods. %Itsevolution spans three generations: handcrafted methods, autoencoder-basedschemes, and methods based on foundation models. While the robustness of thesesystems is well-documented, the security against adversarial attacks remainsunderexplored. This paper evaluates the security of foundation models' latentspace digital watermarking systems that utilize adversarial embeddingtechniques. A series of experiments investigate the security dimensions undercopy and removal attacks, providing empirical insights into these systems'vulnerabilities. All experimental codes and results are available athttps://github.com/vkinakh/ssl-watermarking-attacks}{repository</description>
      <author>example@mail.com (Vitaliy Kinakh, Brian Pulfer, Yury Belousov, Pierre Fernandez, Teddy Furon, Slava Voloshynovskiy)</author>
      <guid isPermaLink="false">2409.18211v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>FracGM: A Fast Fractional Programming Technique for Geman-McClure Robust Estimator</title>
      <link>http://arxiv.org/abs/2409.13978v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 在计算机视觉、机器人技术和导航领域，稳健估计至关重要，旨在减少离群值测量对准确性的影响。&lt;h4&gt;2. 提出的方法&lt;/h4&gt;   - 本文提出了一种快速算法，命名为**FracGM**，用于Geman-McClure稳健估计，利用分数规划技术。&lt;h4&gt;3. 算法原理&lt;/h4&gt;   - FracGM通过将原始的非凸分数问题重构为一个凸对偶问题和一个线性方程系统，采用交替优化模式进行迭代求解。&lt;h4&gt;4. 优势对比&lt;/h4&gt;   - 相比于逐步非凸性方法，FracGM展现出更快的收敛速度和更好的离群值拒绝能力。&lt;h4&gt;5. 全局最优性&lt;/h4&gt;   - 在特定条件下，可以保证所提求解器的全局最优性。&lt;h4&gt;6. 应用示例&lt;/h4&gt;   - 通过**Wahba旋转问题**和**3D点云配准**展示了FracGM求解器的有效性，同时结合了放松预处理和投影后处理。&lt;h4&gt;7. 性能评估&lt;/h4&gt;   - 随着离群值比例从20%增加到80%，FracGM在旋转和位移增量方面分别降低了53%和88%。&lt;h4&gt;8. 实际应用结果&lt;/h4&gt;   - 在现实场景中，FracGM在18个结果中有13个表现更好，并且计算时间改善了19.43%。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/StephLin/FracGM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust estimation is essential in computer vision, robotics, and navigation,aiming to minimize the impact of outlier measurements for improved accuracy. Wepresent a fast algorithm for Geman-McClure robust estimation, FracGM,leveraging fractional programming techniques. This solver reformulates theoriginal non-convex fractional problem to a convex dual problem and a linearequation system, iteratively solving them in an alternating optimizationpattern. Compared to graduated non-convexity approaches, this strategy exhibitsa faster convergence rate and better outlier rejection capability. In addition,the global optimality of the proposed solver can be guaranteed under givenconditions. We demonstrate the proposed FracGM solver with Wahba's rotationproblem and 3-D point-cloud registration along with relaxation pre-processingand projection post-processing. Compared to state-of-the-art algorithms, whenthe outlier rates increase from 20% to 80%, FracGM shows 53% and 88% lowerrotation and translation increases. In real-world scenarios, FracGM achievesbetter results in 13 out of 18 outcomes, while having a 19.43% improvement inthe computation time.</description>
      <author>example@mail.com (Bang-Shien Chen, Yu-Kai Lin, Jian-Yu Chen, Chih-Wei Huang, Jann-Long Chern, Ching-Cherng Sun)</author>
      <guid isPermaLink="false">2409.13978v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>NeuroPath: A Neural Pathway Transformer for Joining the Dots of Human Connectomes</title>
      <link>http://arxiv.org/abs/2409.17510v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 现代成像技术使得我们能够实时研究两个不同脑区之间的连接性，但对解剖结构如何支持大脑功能及自发功能波动如何促进认知的深入理解仍然难以实现。&lt;h4&gt;2. 现有挑战&lt;/h4&gt;   - 尽管在机器学习领域已经投入大量精力以建立神经影像数据与表型特征之间的非线性映射，但缺乏神经科学的见解使得理解瞬时神经活动与认知行为之间的关系面临重大挑战。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本文聚焦于结构连接（SC）与功能连接（FC）之间的耦合机制，将这一网络神经科学问题表述为高阶拓扑的图表示学习问题。&lt;h4&gt;4. 关键概念&lt;/h4&gt;   - 引入“拓扑绕道”这一概念，以表征一种普遍存在的功能连接（直接连接）如何通过神经通路（绕道）由结构连接物理支持，形成一个结构与功能互动的循环环路。&lt;h4&gt;5. 方法论&lt;/h4&gt;   - 在机器学习的背景下，多跳绕道路径支持SC与FC的耦合，使得我们能够在Transformer中设计一种新颖的多头自注意力机制，以捕捉从SC和FC配对图中提取的多模态特征表示。&lt;h4&gt;6. 模型提出&lt;/h4&gt;   - 提出了一个生物启发的深度模型，命名为**NeuroPath**，旨在从大量神经影像中找到假定的连接组特征表示，并可应用于各种下游任务，如任务识别和疾病诊断。&lt;h4&gt;7. 实验评估&lt;/h4&gt;   - 在大型公共数据集（HCP和UK Biobank）上对NeuroPath进行了评估，涵盖监督学习和零样本学习。&lt;h4&gt;8. 性能结果&lt;/h4&gt;   - NeuroPath表现出最先进的性能，显示出在网络神经科学领域的巨大潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although modern imaging technologies allow us to study connectivity betweentwo distinct brain regions in-vivo, an in-depth understanding of how anatomicalstructure supports brain function and how spontaneous functional fluctuationsemerge remarkable cognition is still elusive. Meanwhile, tremendous effortshave been made in the realm of machine learning to establish the nonlinearmapping between neuroimaging data and phenotypic traits. However, the absenceof neuroscience insight in the current approaches poses significant challengesin understanding cognitive behavior from transient neural activities. Toaddress this challenge, we put the spotlight on the coupling mechanism ofstructural connectivity (SC) and functional connectivity (FC) by formulatingsuch network neuroscience question into an expressive graph representationlearning problem for high-order topology. Specifically, we introduce theconcept of topological detour to characterize how a ubiquitous instance of FC(direct link) is supported by neural pathways (detour) physically wired by SC,which forms a cyclic loop interacted by brain structure and function. In theclich\'e of machine learning, the multi-hop detour pathway underlying SC-FCcoupling allows us to devise a novel multi-head self-attention mechanism withinTransformer to capture multi-modal feature representation from paired graphs ofSC and FC. Taken together, we propose a biological-inspired deep model, coinedas NeuroPath, to find putative connectomic feature representations from theunprecedented amount of neuroimages, which can be plugged into variousdownstream applications such as task recognition and disease diagnosis. We haveevaluated NeuroPath on large-scale public datasets including HCP and UK Biobankunder supervised and zero-shot learning, where the state-of-the-art performanceby our NeuroPath indicates great potential in network neuroscience.</description>
      <author>example@mail.com (Ziquan Wei, Tingting Dan, Jiaqi Ding, Paul J Laurienti, Guorong Wu)</author>
      <guid isPermaLink="false">2409.17510v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Modeling the Popularity of Events on Web by Sparsity and Mutual-Excitation Guided Graph Neural Network</title>
      <link>http://arxiv.org/abs/2409.17678v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 网页内容中描述的事件反映了现实社会的观点、价值观和趋势。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 将网络事件映射到受欢迎程度分数，对于感知网络空间的社会趋势至关重要。&lt;h4&gt;3. 挑战&lt;/h4&gt;   - 文本与图像之间的复杂语义对应关系，以及隐含的文本-图像-受欢迎度映射机制，给这一任务带来了显著挑战。&lt;h4&gt;4. 研究方法&lt;/h4&gt;   - 本文从理解可解释的映射机制出发，提出了一种新方法。&lt;h4&gt;5. 关键词组织&lt;/h4&gt;   - 将不同事件的关键词组织成一个统一图，以便于通过两级映射建模事件的受欢迎程度。&lt;h4&gt;6. 映射机制&lt;/h4&gt;   - **自激励**：每个关键词形成其受欢迎程度。   - **互激励**：两个关键词相互影响，决定事件的受欢迎程度。&lt;h4&gt;7. 技术实现&lt;/h4&gt;   - 采用图神经网络（GNN）作为基础模型，综合建模自激励、互激励和图像上下文，形成稀疏深度因子模型。&lt;h4&gt;8. 数据集发布&lt;/h4&gt;   - 本研究发布了一个挑战性网页事件数据集，用于受欢迎度预测任务。&lt;h4&gt;9. 实验结果&lt;/h4&gt;   - 在三个公共数据集上的实验结果表明，所提方法显著提高了性能，超越了当前最先进的方法。&lt;h4&gt;10. 数据集获取&lt;/h4&gt;    - 数据集可公开获取，链接为：[Hot-events-dataset](https://github.com/pangjunbiao/Hot-events-dataset)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The content of a webpage described or posted an event in the cyberspaceinevitably reflects viewpoints, values and trends of the physical society.Mapping an event on web to the popularity score plays a pivot role to sense thesocial trends from the cyberspace. However, the complex semantic correspondencebetween texts and images, as well as the implicit text-image-popularity mappingmechanics pose a significant challenge to this non-trivial task. In this paper,we address this problem from a viewpoint of understanding the interpretablemapping mechanics. Concretely, we organize the keywords from different eventsinto an unified graph. The unified graph facilitates to model the popularity ofevents via two-level mappings, i.e., the self excitation and the mutualexcitation. The self-excitation assumes that each keyword forms the popularitywhile the mutual-excitation models that two keywords would excite each other todetermine the popularity of an event. Specifically, we use Graph Neural Network(GNN) as the backbone to model the self-excitation, the mutual excitation andthe context of images into a sparse and deep factor model. Besides, to our bestknowledge, we release a challenge web event dataset for the popularityprediction task. The experimental results on three public datasets demonstratethat our method achieves significant improvements and outperforms thestate-of-the-art methods. Dataset is publicly available at:https://github.com/pangjunbiao/Hot-events-dataset.</description>
      <author>example@mail.com (Jiaxin Deng, Linlin Jia, Junbiao Pang, Qingming Huang)</author>
      <guid isPermaLink="false">2409.17678v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>GraphLoRA: Structure-Aware Contrastive Low-Rank Adaptation for Cross-Graph Transfer Learning</title>
      <link>http://arxiv.org/abs/2409.16670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 图神经网络（GNNs）在电子商务和社交网络等多个领域的图分析任务中表现出色。&lt;h4&gt;2. 主要挑战&lt;/h4&gt;   - 尽管GNN的多功能性，其在迁移能力方面面临显著挑战，限制了其在实际应用中的效用。&lt;h4&gt;3. 现有研究的局限&lt;/h4&gt;   - 现有的GNN迁移学习研究忽视了不同图数据集之间的分布差异，在跨不同分布时遇到困难。&lt;h4&gt;4. 研究问题&lt;/h4&gt;   - 如何有效地将经过良好训练的GNN应用于特征和结构分布各异的新图仍然是一个未被充分探索的问题。&lt;h4&gt;5. 提出的方法&lt;/h4&gt;   - 本文提出**GraphLoRA**，一种有效且参数高效的方法，用于将经过良好训练的GNN迁移到多样化的图域。&lt;h4&gt;6. 关键技术&lt;/h4&gt;   - 首先，提出了一种结构感知的最大均值差异（SMMD）方法，用于对齐源图和目标图之间不同的节点特征分布。   - 引入低秩适应，通过在预训练GNN旁边注入一个小型可训练GNN，有效弥补结构分布差距，减轻灾难性遗忘。&lt;h4&gt;7. 正则化目标&lt;/h4&gt;   - 提出了结构感知的正则化目标，以增强预训练GNN对目标图在稀缺监督标签情况下的适应性。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 在六个真实世界的数据集上进行的广泛实验表明，GraphLoRA在调整仅20%参数的情况下，优于11个基线方法，即使在不同的图域之间也表现出色。&lt;h4&gt;9. 代码可用性&lt;/h4&gt;   - 相关代码可在 [此链接](https://anonymous.4open.science/r/GraphLoRA) 获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated remarkable proficiency inhandling a range of graph analytical tasks across various domains, such ase-commerce and social networks. Despite their versatility, GNNs facesignificant challenges in transferability, limiting their utility in real-worldapplications. Existing research in GNN transfer learning overlooksdiscrepancies in distribution among various graph datasets, facing challengeswhen transferring across different distributions. How to effectively adopt awell-trained GNN to new graphs with varying feature and structuraldistributions remains an under-explored problem. Taking inspiration from thesuccess of Low-Rank Adaptation (LoRA) in adapting large language models tovarious domains, we propose GraphLoRA, an effective and parameter-efficientmethod for transferring well-trained GNNs to diverse graph domains.Specifically, we first propose a Structure-aware Maximum Mean Discrepancy(SMMD) to align divergent node feature distributions across source and targetgraphs. Moreover, we introduce low-rank adaptation by injecting a smalltrainable GNN alongside the pre-trained one, effectively bridging structuraldistribution gaps while mitigating the catastrophic forgetting. Additionally, astructure-aware regularization objective is proposed to enhance theadaptability of the pre-trained GNN to target graph with scarce supervisionlabels. Extensive experiments on six real-world datasets demonstrate theeffectiveness of GraphLoRA against eleven baselines by tuning only 20% ofparameters, even across disparate graph domains. The code is available athttps://anonymous.4open.science/r/GraphLoRA.</description>
      <author>example@mail.com (Zhe-Rui Yang, Jindong Han, Chang-Dong Wang, Hao Liu)</author>
      <guid isPermaLink="false">2409.16670v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification</title>
      <link>http://arxiv.org/abs/2409.17777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  RK and RS contributed equally to this work, 20 Pages, 8 Figures, 9
  Tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 深度多模态学习通过对比学习成功捕捉了模态之间的显式一对一关系，但现实数据常常表现出超越简单成对关联的共享关系。&lt;h4&gt;2. 提出的方法&lt;/h4&gt;   - 本文提出了**M3CoL**（Multimodal Mixup Contrastive Learning）方法，以捕捉多模态数据中固有的细微共享关系。&lt;h4&gt;3. 关键贡献&lt;/h4&gt;   - 关键贡献是基于Mixup的对比损失，通过将一个模态的混合样本与其他模态的相应样本对齐，从而学习稳健的表示并捕捉它们之间的共享关系。&lt;h4&gt;4. 框架设计&lt;/h4&gt;   - 对于多模态分类任务，提出了一个框架，集成了融合模块和单模态预测模块，以在训练期间提供辅助监督，并结合所提出的基于Mixup的对比损失。&lt;h4&gt;5. 实验验证&lt;/h4&gt;   - 在多个数据集（N24News、ROSMAP、BRCA和Food-101）上进行了广泛实验，结果表明M3CoL有效捕捉共享多模态关系，并具有跨领域的泛化能力。&lt;h4&gt;6. 性能比较&lt;/h4&gt;   - 在N24News、ROSMAP和BRCA数据集上，M3CoL的表现超过了最先进的方法，而在Food-101上则表现相当。&lt;h4&gt;7. 研究意义&lt;/h4&gt;   - 本研究强调了学习共享关系对于稳健多模态学习的重要性，为未来的研究开辟了有希望的方向。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep multimodal learning has shown remarkable success by leveragingcontrastive learning to capture explicit one-to-one relations acrossmodalities. However, real-world data often exhibits shared relations beyondsimple pairwise associations. We propose M3CoL, a Multimodal Mixup ContrastiveLearning approach to capture nuanced shared relations inherent in multimodaldata. Our key contribution is a Mixup-based contrastive loss that learns robustrepresentations by aligning mixed samples from one modality with theircorresponding samples from other modalities thereby capturing shared relationsbetween them. For multimodal classification tasks, we introduce a frameworkthat integrates a fusion module with unimodal prediction modules for auxiliarysupervision during training, complemented by our proposed Mixup-basedcontrastive loss. Through extensive experiments on diverse datasets (N24News,ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively capturesshared multimodal relations and generalizes across domains. It outperformsstate-of-the-art methods on N24News, ROSMAP, and BRCA, while achievingcomparable performance on Food-101. Our work highlights the significance oflearning shared relations for robust multimodal learning, opening up promisingavenues for future research.</description>
      <author>example@mail.com (Raja Kumar, Raghav Singhal, Pranamya Kulkarni, Deval Mehta, Kshitij Jadhav)</author>
      <guid isPermaLink="false">2409.17777v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Research on Dynamic Data Flow Anomaly Detection based on Machine Learning</title>
      <link>http://arxiv.org/abs/2409.14796v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 现代网络攻击的复杂性和多样性使得使用代理、网关、防火墙和加密隧道等单一防御策略不再有效。&lt;h4&gt;2. 研究重点&lt;/h4&gt;   - 主动识别数据异常已成为数据安全领域的重要研究方向。&lt;h4&gt;3. 现有研究的局限&lt;/h4&gt;   - 大多数现有研究集中于样本平衡数据，导致在不平衡数据情况下的检测效果不理想。&lt;h4&gt;4. 研究方法&lt;/h4&gt;   - 本研究采用无监督学习方法识别动态数据流中的异常。&lt;h4&gt;5. 特征提取&lt;/h4&gt;   - 首先，从实时数据中提取多维特征，利用聚类算法分析数据模式。&lt;h4&gt;6. 异常识别&lt;/h4&gt;   - 通过聚类相似数据，模型能够自动识别出显著偏离正常流量的数据行为，无需标记数据。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 实验结果表明，所提方法在多种场景中表现出高准确率，能够有效检测异常。&lt;h4&gt;8. 性能特点&lt;/h4&gt;   - 方法在不平衡数据情况下表现出稳健和适应性强的性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The sophistication and diversity of contemporary cyberattacks have renderedthe use of proxies, gateways, firewalls, and encrypted tunnels as a standalonedefensive strategy inadequate. Consequently, the proactive identification ofdata anomalies has emerged as a prominent area of research within the field ofdata security. The majority of extant studies concentrate on sample equilibriumdata, with the consequence that the detection effect is not optimal in thecontext of unbalanced data. In this study, the unsupervised learning method isemployed to identify anomalies in dynamic data flows. Initially,multi-dimensional features are extracted from real-time data, and a clusteringalgorithm is utilised to analyse the patterns of the data. This enables thepotential outliers to be automatically identified. By clustering similar data,the model is able to detect data behaviour that deviates significantly fromnormal traffic without the need for labelled data. The results of theexperiments demonstrate that the proposed method exhibits high accuracy in thedetection of anomalies across a range of scenarios. Notably, it demonstratesrobust and adaptable performance, particularly in the context of unbalanceddata.</description>
      <author>example@mail.com (Liyang Wang, Yu Cheng, Hao Gong, Jiacheng Hu, Xirui Tang, Iris Li)</author>
      <guid isPermaLink="false">2409.14796v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Hyper-parameter Optimization for Wireless Network Traffic Prediction Models with A Novel Meta-Learning Framework</title>
      <link>http://arxiv.org/abs/2409.14535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 提出一种基于元学习的超参数优化框架，用于无线网络流量预测模型。&lt;h4&gt;2. 预测模型&lt;/h4&gt;   - 采用基于注意力机制的深度神经网络（ADNN）作为每个无线网络流量预测任务的预测模型，称为基学习器（base-learner）。&lt;h4&gt;3. 元学习器的角色&lt;/h4&gt;   - 使用元学习器自动生成针对特定基学习器的最佳超参数，这些超参数基于对应基任务的内在特征（元特征）。&lt;h4&gt;4. 观察与假设&lt;/h4&gt;   - 通过对真实流量记录的观察发现，具有相似元特征的基任务往往倾向于使用相似的超参数。&lt;h4&gt;5. 超参数选择方法&lt;/h4&gt;   - 元学习器利用K近邻（KNN）学习方法获取一组候选超参数选择策略，适用于新的基学习器。&lt;h4&gt;6. 优化算法&lt;/h4&gt;   - 使用先进的遗传算法结合智能染色体筛选，最终获取最佳超参数选择策略。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 大量实验表明，所提框架中的基学习器在无线网络流量预测任务中具有高潜力的预测能力。&lt;h4&gt;8. 性能提升&lt;/h4&gt;   - 元学习器通过提供最佳超参数显著提升了基学习器的性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel meta-learning based hyper-parameteroptimization framework for wireless network traffic prediction models. Anattention-based deep neural network (ADNN) is adopted as the prediction model,i.e., base-learner, for each wireless network traffic prediction task, namelybase-task, and a meta-learner is employed to automatically generate the optimalhyper-parameters for a given base-learner according to the correspondingbase-task's intrinsic characteristics or properties, i.e., meta-features. Basedon our observation from real-world traffic records that base-tasks possessingsimilar meta-features tend to favour similar hyper-parameters for theirbase-learners, the meta-learner exploits a K-nearest neighbor (KNN) learningmethod to obtain a set of candidate hyper-parameter selection strategies for anew base-learner, which are then utilized by an advanced genetic algorithm withintelligent chromosome screening to finally acquire the best hyper-parameterselection strategy. Extensive experiments demonstrate that base-learners in theproposed framework have high potential prediction ability for wireless networktraffic prediction task, and the meta-learner can enormously elevate thebase-learners' performance by providing them the optimal hyper-parameters.</description>
      <author>example@mail.com (Liangzhi Wang, Jie Zhang, Yuan Gao, Jiliang Zhang, Guiyi Wei, Haibo Zhou, Bin Zhuge, Zitian Zhang)</author>
      <guid isPermaLink="false">2409.14535v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Embodied-RAG: General non-parametric Embodied Memory for Retrieval and Generation</title>
      <link>http://arxiv.org/abs/2409.18313v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Web: https://quanting-xie.github.io/Embodied-RAG-web/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 机器人在探索和学习方面没有限制，但所有知识必须是可搜索和可操作的。   - 在语言研究中，增强检索生成（RAG）已成为大规模非参数知识的主要工具。&lt;h4&gt;2. 现有技术的局限&lt;/h4&gt;   - 现有的RAG技术无法直接应用于具身领域，该领域是多模态的，数据高度相关，感知需要抽象处理。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 本文提出了**Embodied-RAG**框架，增强具身代理的基础模型，结合非参数记忆系统，能够自主构建层次知识以支持导航和语言生成。&lt;h4&gt;4. 功能特点&lt;/h4&gt;   - Embodied-RAG处理多种空间和语义分辨率，适用于不同环境和查询类型，包括特定对象和整体氛围描述。&lt;h4&gt;5. 记忆结构&lt;/h4&gt;   - 其核心记忆结构为**语义森林**，以不同细节层次存储语言描述。该层次化组织使系统能够高效生成上下文敏感的输出。&lt;h4&gt;6. 应用效果&lt;/h4&gt;   - 实验表明，Embodied-RAG有效地将RAG与机器人领域相结合，成功处理了来自19个环境的200多个解释和导航查询。&lt;h4&gt;7. 研究意义&lt;/h4&gt;   - 强调了Embodied-RAG作为具身代理的通用非参数系统的潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; There is no limit to how much a robot might explore and learn, but all ofthat knowledge needs to be searchable and actionable. Within language research,retrieval augmented generation (RAG) has become the workhouse of large-scalenon-parametric knowledge, however existing techniques do not directly transferto the embodied domain, which is multimodal, data is highly correlated, andperception requires abstraction.  To address these challenges, we introduce Embodied-RAG, a framework thatenhances the foundational model of an embodied agent with a non-parametricmemory system capable of autonomously constructing hierarchical knowledge forboth navigation and language generation. Embodied-RAG handles a full range ofspatial and semantic resolutions across diverse environments and query types,whether for a specific object or a holistic description of ambiance. At itscore, Embodied-RAG's memory is structured as a semantic forest, storinglanguage descriptions at varying levels of detail. This hierarchicalorganization allows the system to efficiently generate context-sensitiveoutputs across different robotic platforms. We demonstrate that Embodied-RAGeffectively bridges RAG to the robotics domain, successfully handling over 200explanation and navigation queries across 19 environments, highlighting itspromise for general-purpose non-parametric system for embodied agents.</description>
      <author>example@mail.com (Quanting Xie, So Yeon Min, Tianyi Zhang, Aarav Bajaj, Ruslan Salakhutdinov, Matthew Johnson-Roberson, Yonatan Bisk)</author>
      <guid isPermaLink="false">2409.18313v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MUSE: Integrating Multi-Knowledge for Knowledge Graph Completion</title>
      <link>http://arxiv.org/abs/2409.17536v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2408.05283&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 知识图谱补全（KGC）旨在预测缺失的关系部分，形式为（头实体）-[关系]-&gt;（尾实体）三元组。&lt;h4&gt;2. 现有方法的局限&lt;/h4&gt;   - 大多数现有KGC方法专注于单一特征（如关系类型）或子图聚合，未充分探索知识图谱的所有特征，也忽视了外部语义知识的指导。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 本文提出了一种知识感知推理模型 **MUSE**，设计了新颖的多知识表示学习机制用于缺失关系预测。&lt;h4&gt;4. 模型组件&lt;/h4&gt;   - MUSE通过三个并行组件构建定制的嵌入空间：     1. **先验知识学习**：通过微调BERT增强三元组的语义表示。     2. **上下文信息传递**：增强知识图谱的上下文信息。     3. **关系路径聚合**：增强从头实体到尾实体的路径表示。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 实验结果表明，MUSE在四个公共数据集上显著优于其他基线方法，在NELL995数据集上实现了超过5.50%的H@1改进和4.20%的MRR改进。&lt;h4&gt;6. 代码和数据集&lt;/h4&gt;   - 相关代码和数据集将通过 [GitHub](https://github.com/SUSTech-TP/ADMA2024-MUSE.git) 发布。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge Graph Completion (KGC) aims to predict the missing [relation] partof (head entity)--[relation]-&gt;(tail entity) triplet. Most existing KGC methodsfocus on single features (e.g., relation types) or sub-graph aggregation.However, they do not fully explore the Knowledge Graph (KG) features andneglect the guidance of external semantic knowledge. To address theseshortcomings, we propose a knowledge-aware reasoning model (MUSE), whichdesigns a novel multi-knowledge representation learning mechanism for missingrelation prediction. Our model develops a tailored embedding space throughthree parallel components: 1) Prior Knowledge Learning for enhancing thetriplets' semantic representation by fine-tuning BERT; 2) Context MessagePassing for enhancing the context messages of KG; 3) Relational PathAggregation for enhancing the path representation from the head entity to thetail entity. The experimental results show that MUSE significantly outperformsother baselines on four public datasets, achieving over 5.50% H@1 improvementand 4.20% MRR improvement on the NELL995 dataset. The code and datasets will bereleased via https://github.com/SUSTech-TP/ADMA2024-MUSE.git.</description>
      <author>example@mail.com (Pengjie Liu)</author>
      <guid isPermaLink="false">2409.17536v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Cross-lingual Speech Emotion Recognition: Humans vs. Self-Supervised Models</title>
      <link>http://arxiv.org/abs/2409.16920v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 自监督学习（SSL）模型在语音情感识别（SER）中表现有效，但在跨语言场景下的研究较少。&lt;h4&gt;2. 研究目的&lt;/h4&gt;   - 本研究进行了一项比较分析，评估人类表现与SSL模型在SER任务中的差异。&lt;h4&gt;3. 方法论&lt;/h4&gt;   - 开展层级分析以及在单语、跨语和迁移学习背景下探索参数高效的微调策略。&lt;h4&gt;4. 比较层次&lt;/h4&gt;   - 在话语级和段落级别上比较模型和人类的SER能力。&lt;h4&gt;5. 方言影响&lt;/h4&gt;   - 通过人类评估调查方言对跨语言SER的影响。&lt;h4&gt;6. 主要发现&lt;/h4&gt;   - 适当的知识迁移使得模型能够适应目标语言，达到与母语者相当的表现。&lt;h4&gt;7. 方言的显著影响&lt;/h4&gt;   - 对于没有语言和副语言背景的个体，方言对SER产生显著影响。&lt;h4&gt;8. 情感表现的差异&lt;/h4&gt;   - 人类和模型在不同情感上的表现行为存在明显差异。&lt;h4&gt;9. 研究意义&lt;/h4&gt;   - 结果为SSL模型在跨语言SER能力提供了新见解，强调了它们与人类情感感知的相似性和差异。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhan7721/crosslingual_ser&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Utilizing Self-Supervised Learning (SSL) models for Speech EmotionRecognition (SER) has proven effective, yet limited research has exploredcross-lingual scenarios. This study presents a comparative analysis betweenhuman performance and SSL models, beginning with a layer-wise analysis and anexploration of parameter-efficient fine-tuning strategies in monolingual,cross-lingual, and transfer learning contexts. We further compare the SERability of models and humans at both utterance- and segment-levels.Additionally, we investigate the impact of dialect on cross-lingual SER throughhuman evaluation. Our findings reveal that models, with appropriate knowledgetransfer, can adapt to the target language and achieve performance comparableto native speakers. We also demonstrate the significant effect of dialect onSER for individuals without prior linguistic and paralinguistic background.Moreover, both humans and models exhibit distinct behaviors across differentemotions. These results offer new insights into the cross-lingual SERcapabilities of SSL models, underscoring both their similarities to anddifferences from human emotion perception.</description>
      <author>example@mail.com (Zhichen Han, Tianqi Geng, Hui Feng, Jiahong Yuan, Korin Richmond, Yuanchao Li)</author>
      <guid isPermaLink="false">2409.16920v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>LoopSR: Looping Sim-and-Real for Lifelong Policy Adaptation of Legged Robots</title>
      <link>http://arxiv.org/abs/2409.17992v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 背景介绍&lt;/h4&gt;   - 强化学习（RL）在腿部运动中展现了显著且具普遍性的能力，尤其在模拟到现实的转移中。&lt;h4&gt;2. 适应性方法的局限&lt;/h4&gt;   - 尽管像领域随机化这样的适应性方法旨在增强策略对多样环境的鲁棒性，但根据“无免费午餐定理”，这种全面性可能会导致策略在特定环境中的性能下降，导致在现实世界中部署后出现次优解。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 本文提出了一个名为 **LoopSR** 的终身策略适应框架，利用基于变换器的编码器将现实世界的轨迹投影到潜在空间，并相应地在模拟中重建现实世界环境以进行进一步改进。&lt;h4&gt;4. 技术架构&lt;/h4&gt;   - 采用自编码器架构和对比学习方法，以更好地提取现实世界动态的特征。&lt;h4&gt;5. 持续训练的参数&lt;/h4&gt;   - 持续训练所需的模拟参数通过将解码器预测的参数与模拟轨迹数据集中检索的参数结合而得出。&lt;h4&gt;6. 数据效率的提升&lt;/h4&gt;   - 通过利用持续训练，LoopSR 在数据效率上优于强基线，仅需有限的数据即可在模拟到模拟和模拟到现实的实验中取得显著表现。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement Learning (RL) has shown its remarkable and generalizablecapability in legged locomotion through sim-to-real transfer. However, whileadaptive methods like domain randomization are expected to make policy morerobust to diverse environments, such comprehensiveness potentially detractsfrom the policy's performance in any specific environment according to the NoFree Lunch theorem, leading to a suboptimal solution once deployed in the realworld. To address this issue, we propose a lifelong policy adaptation frameworknamed LoopSR, which utilizes a transformer-based encoder to project real-worldtrajectories into a latent space, and accordingly reconstruct the real-worldenvironments back in simulation for further improvement. Autoencoderarchitecture and contrastive learning methods are adopted to better extract thecharacteristics of real-world dynamics. The simulation parameters for continualtraining are derived by combining predicted parameters from the decoder withretrieved parameters from the simulation trajectory dataset. By leveraging thecontinual training, LoopSR achieves superior data efficiency compared withstrong baselines, with only a limited amount of data to yield eminentperformance in both sim-to-sim and sim-to-real experiments.</description>
      <author>example@mail.com (Peilin Wu, Weiji Xie, Jiahang Cao, Hang Lai, Weinan Zhang)</author>
      <guid isPermaLink="false">2409.17992v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Triple Point Masking</title>
      <link>http://arxiv.org/abs/2409.17547v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 现有方法的限制&lt;/h4&gt;   - 现有的3D掩码学习方法在数据有限的情况下表现出性能瓶颈，研究目标是克服这一限制。&lt;h4&gt;2. 提出的方法&lt;/h4&gt;   - 引入了一种名为 **TPM（Triple Point Masking）** 的三点掩码方案，作为一个可扩展的框架，用于掩码自编码器的预训练，实现3D点云的多掩码学习。&lt;h4&gt;3. 掩码选择&lt;/h4&gt;   - 在基线方法的基础上，增加了两种额外的掩码选择（中等掩码和低掩码），核心思想是物体的恢复过程可以以多种方式表现。&lt;h4&gt;4. 高掩码方案的不足&lt;/h4&gt;   - 之前的高掩码方案专注于捕捉全局表示，但缺乏细粒度的恢复能力，导致生成的预训练权重在微调过程中的作用有限。&lt;h4&gt;5. TPM的优势&lt;/h4&gt;   - 通过TPM，现有方法能够展现更灵活和准确的补全能力，使得在预训练阶段的自编码器能够考虑单个3D物体的多种表示。&lt;h4&gt;6. 权重选择模块&lt;/h4&gt;   - 提出了一个**基于支持向量机（SVM）的权重选择模块**，在微调阶段为下游网络填充最佳权重，最大化线性准确性，并促进新物体复杂表示的获取。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 大量实验表明，四个基线方法配备TPM后，在各种下游任务上取得了全面的性能提升。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing 3D mask learning methods encounter performance bottlenecks underlimited data, and our objective is to overcome this limitation. In this paper,we introduce a triple point masking scheme, named TPM, which serves as ascalable framework for pre-training of masked autoencoders to achievemulti-mask learning for 3D point clouds. Specifically, we augment the baselineswith two additional mask choices (i.e., medium mask and low mask) as our coreinsight is that the recovery process of an object can manifest in diverse ways.Previous high-masking schemes focus on capturing the global representation butlack the fine-grained recovery capability, so that the generated pre-trainedweights tend to play a limited role in the fine-tuning process. With thesupport of the proposed TPM, available methods can exhibit more flexible andaccurate completion capabilities, enabling the potential autoencoder in thepre-training stage to consider multiple representations of a single 3D object.In addition, an SVM-guided weight selection module is proposed to fill theencoder parameters for downstream networks with the optimal weight during thefine-tuning stage, maximizing linear accuracy and facilitating the acquisitionof intricate representations for new objects. Extensive experiments show thatthe four baselines equipped with the proposed TPM achieve comprehensiveperformance improvements on various downstream tasks.</description>
      <author>example@mail.com (Jiaming Liu, Linghe Kong, Yue Wu, Maoguo Gong, Hao Li, Qiguang Miao, Wenping Ma, Can Qin)</author>
      <guid isPermaLink="false">2409.17547v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical end-to-end autonomous navigation through few-shot waypoint detection</title>
      <link>http://arxiv.org/abs/2409.14633v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appeared at the 40th Anniversary of the IEEE International Conference
  on Robotics and Automation (ICRA@40), 23-26 September, 2024, Rotterdam, The
  Netherlands. 9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 人类导航能力&lt;/h4&gt;   - 人类通过将动作与地标关联来促进导航，能够识别环境中的显著特征。&lt;h4&gt;2. 简洁的导航指令&lt;/h4&gt;   - 人类的导航指令通常非常简洁，例如短语描述，表明对记忆的要求较低且不依赖复杂的导航工具。&lt;h4&gt;3. 当前自主导航的不足&lt;/h4&gt;   - 现有的自主导航系统依赖于精确的定位设备和算法，以及大量的环境传感数据。&lt;h4&gt;4. 研究动机&lt;/h4&gt;   - 本研究受到人类导航能力的启发，旨在填补技术差距。&lt;h4&gt;5. 提出的方法&lt;/h4&gt;   - 提出了一种**分层的端到端元学习方案**，使移动机器人能在未知环境中导航，只需提供少量地标图像及其对应的高层导航动作。&lt;h4&gt;6. 简化方式寻找过程&lt;/h4&gt;   - 该方法极大简化了路径规划过程，便于在新环境中的适应。&lt;h4&gt;7. 少样本检测技术&lt;/h4&gt;   - 对于少样本的测点检测，使用基于度量的少样本学习技术，通过分布嵌入实现。&lt;h4&gt;8. 多任务控制模块&lt;/h4&gt;   - 测点检测触发多任务低层操作控制模块，执行相应的高层导航动作。&lt;h4&gt;9. 实验验证&lt;/h4&gt;   - 使用小规模自主车辆在多个未见过的室内环境中进行新的导航任务，展示了该方案的有效性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2024.3365294&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human navigation is facilitated through the association of actions withlandmarks, tapping into our ability to recognize salient features in ourenvironment. Consequently, navigational instructions for humans can beextremely concise, such as short verbal descriptions, indicating a small memoryrequirement and no reliance on complex and overly accurate navigation tools.Conversely, current autonomous navigation schemes rely on accurate positioningdevices and algorithms as well as extensive streams of sensory data collectedfrom the environment. Inspired by this human capability and motivated by theassociated technological gap, in this work we propose a hierarchical end-to-endmeta-learning scheme that enables a mobile robot to navigate in a previouslyunknown environment upon presentation of only a few sample images of a set oflandmarks along with their corresponding high-level navigation actions. Thisdramatically simplifies the wayfinding process and enables easy adoption to newenvironments. For few-shot waypoint detection, we implement a metric-basedfew-shot learning technique through distribution embedding. Waypoint detectiontriggers the multi-task low-level maneuver controller module to execute thecorresponding high-level navigation action. We demonstrate the effectiveness ofthe scheme using a small-scale autonomous vehicle on novel indoor navigationtasks in several previously unseen environments.</description>
      <author>example@mail.com (Amin Ghafourian, Zhongying CuiZhu, Debo Shi, Ian Chuang, Francois Charette, Rithik Sachdeva, Iman Soltani)</author>
      <guid isPermaLink="false">2409.14633v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Fairness-Performance Pareto Front Computation</title>
      <link>http://arxiv.org/abs/2409.17643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 背景介绍&lt;/h4&gt;   - 存在一个公认的内在权衡，即表示的公平性与基于该表示的分类器性能之间的关系。&lt;h4&gt;2. 优化复杂性问题&lt;/h4&gt;   - 现代表示学习方法中的优化算法复杂，使得判断某种方法获得的公平性-性能曲线是否接近真实的帕累托前沿变得困难。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本文提出了一种新方法来计算最优的帕累托前沿，不需要训练复杂的表示模型。&lt;h4&gt;4. 方法优势&lt;/h4&gt;   - 最优的公平表示具有多种有用的结构特性，这些特性使得计算帕累托前沿的问题简化为一个紧凑的离散问题。&lt;h4&gt;5. 求解方法&lt;/h4&gt;   - 这些紧凑的近似问题可以通过现有的凹凸编程方法高效求解。&lt;h4&gt;6. 通用性&lt;/h4&gt;   - 由于该方法独立于特定的表示模型，可以作为表示学习算法的基准进行比较。&lt;h4&gt;7. 实验评估&lt;/h4&gt;   - 在多个真实世界基准数据集上对该方法进行了实验评估。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; There is a well known intrinsic trade-off between the fairness of arepresentation and the performance of classifiers derived from therepresentation. Due to the complexity of optimisation algorithms in most modernrepresentation learning approaches, for a given method it may be non-trivial todecide whether the obtained fairness-performance curve of the method isoptimal, i.e., whether it is close to the true Pareto front for thesequantities for the underlying data distribution.  In this paper we propose a new method to compute the optimal Pareto front,which does not require the training of complex representation models. We showthat optimal fair representations possess several useful structural properties,and that these properties enable a reduction of the computation of the ParetoFront to a compact discrete problem. We then also show that these compactapproximating problems can be efficiently solved via off-the shelfconcave-convex programming methods.  Since our approach is independent of the specific model of representations,it may be used as the benchmark to which representation learning algorithms maybe compared. We experimentally evaluate the approach on a number of real worldbenchmark datasets.</description>
      <author>example@mail.com (Mark Kozdoba, Binyamin Perets, Shie Mannor)</author>
      <guid isPermaLink="false">2409.17643v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models</title>
      <link>http://arxiv.org/abs/2409.17481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Spotlight&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 背景介绍&lt;/h4&gt;   - 大型语言模型（LLMs）具有庞大的参数数量，通常导致显著的冗余。   &lt;h4&gt;2. 方法概述&lt;/h4&gt;   - 本研究提出了一种名为 **MaskLLM** 的可学习剪枝方法，旨在在 LLM 中建立 **半结构化（N:M）稀疏性**，以减少推理过程中的计算开销。&lt;h4&gt;3. 创新点&lt;/h4&gt;   - MaskLLM 通过 **Gumbel Softmax 采样** 明确建模 N:M 结构模式，避免了开发新的重要性标准。&lt;h4&gt;4. 优势&lt;/h4&gt;   - **高质量的掩码**：该方法能够有效扩展到大规模数据集，并学习准确的掩码。   - **可迁移性**：掩码分布的概率建模使得稀疏性可以跨域或跨任务进行迁移学习。&lt;h4&gt;5. 实验评估&lt;/h4&gt;   - 在多个 LLM（如 LLaMA-2、Nemotron-4 和 GPT-3）上评估 MaskLLM，模型参数范围从 843M 到 15B。   - 实验结果表明，与最先进的方法相比，MaskLLM 显著提高了性能。例如，传统方法在 Wikitext 上的困惑度（PPL）通常达到 10 或更高，而密集模型的 PPL 为 5.12，MaskLLM 通过学习掩码获得了 6.72 的 PPL，且权重保持冻结状态。&lt;h4&gt;6. 应用潜力&lt;/h4&gt;   - MaskLLM 的可学习特性允许为下游任务或领域定制掩码，从而实现 2:4 稀疏性的无损应用。&lt;h4&gt;7. 代码获取&lt;/h4&gt;   - 相关代码可在 [GitHub](https://github.com/NVlabs/MaskLLM) 上获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nvlabs/maskllm&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) are distinguished by their massive parametercounts, which typically result in significant redundancy. This work introducesMaskLLM, a learnable pruning method that establishes Semi-structured (or``N:M'') Sparsity in LLMs, aimed at reducing computational overhead duringinference. Instead of developing a new importance criterion, MaskLLM explicitlymodels N:M patterns as a learnable distribution through Gumbel Softmaxsampling. This approach facilitates end-to-end training on large-scale datasetsand offers two notable advantages: 1) High-quality Masks - our methodeffectively scales to large datasets and learns accurate masks; 2)Transferability - the probabilistic modeling of mask distribution enables thetransfer learning of sparsity across domains or tasks. We assessed MaskLLMusing 2:4 sparsity on various LLMs, including LLaMA-2, Nemotron-4, and GPT-3,with sizes ranging from 843M to 15B parameters, and our empirical results showsubstantial improvements over state-of-the-art methods. For instance, leadingapproaches achieve a perplexity (PPL) of 10 or greater on Wikitext compared tothe dense model's 5.12 PPL, but MaskLLM achieves a significantly lower 6.72 PPLsolely by learning the masks with frozen weights. Furthermore, MaskLLM'slearnable nature allows customized masks for lossless application of 2:4sparsity to downstream tasks or domains. Code is available at\url{https://github.com/NVlabs/MaskLLM}.</description>
      <author>example@mail.com (Gongfan Fang, Hongxu Yin, Saurav Muralidharan, Greg Heinrich, Jeff Pool, Jan Kautz, Pavlo Molchanov, Xinchao Wang)</author>
      <guid isPermaLink="false">2409.17481v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised Pretraining for Cardiovascular Magnetic Resonance Cine Segmentation</title>
      <link>http://arxiv.org/abs/2409.18100v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Data Engineering in Medical Imaging (DEMI) Workshop at
  MICCAI 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 自监督预训练（SSP）在从大型无标签数据集中学习方面显示出良好效果，可能对自动化心血管磁共振（CMR）短轴cine分割有用。&lt;h4&gt;2. 研究问题&lt;/h4&gt;   - SSP在分割任务中的效益报告不一致，导致其应用于CMR时遇到困难。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本研究旨在评估不同SSP方法在CMR cine分割中的有效性。&lt;h4&gt;4. 数据集与方法&lt;/h4&gt;   - 使用296个受试者的短轴cine堆栈（共90618个2D切片）进行无标签预训练，采用四种SSP方法：SimCLR、位置对比学习、DINO和掩膜图像建模（MIM）。   - 针对不同数量的受试者子集进行监督微调，并从头训练一个2D基线模型。&lt;h4&gt;5. 性能比较&lt;/h4&gt;   - 将微调后的模型与基线模型进行比较，使用140个受试者的测试数据集计算3D Dice相似系数（DSC）。   - SSP方法在最大监督微调子集上未能超越基线（DSC = 0.89）。&lt;h4&gt;6. 微调效果&lt;/h4&gt;   - 当仅有10个受试者（231个2D切片）用于监督训练时，使用MIM的SSP方法（DSC = 0.86）相较于从头训练（DSC = 0.82）有所提升。&lt;h4&gt;7. 研究结论&lt;/h4&gt;   - SSP在标注数据稀缺时对CMR cine分割有价值，但在充足标注数据情况下对最先进的深度学习方法没有帮助。   - SSP方法的选择对结果影响显著。&lt;h4&gt;8. 代码获取&lt;/h4&gt;   - 相关代码已公开，链接为：[GitHub - q-cardIA/ssp-cmr-cine-segmentation](https://github.com/q-cardIA/ssp-cmr-cine-segmentation)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/q-cardia/ssp-cmr-cine-segmentation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised pretraining (SSP) has shown promising results in learningfrom large unlabeled datasets and, thus, could be useful for automatedcardiovascular magnetic resonance (CMR) short-axis cine segmentation. However,inconsistent reports of the benefits of SSP for segmentation have made itdifficult to apply SSP to CMR. Therefore, this study aimed to evaluate SSPmethods for CMR cine segmentation.  To this end, short-axis cine stacks of 296 subjects (90618 2D slices) wereused for unlabeled pretraining with four SSP methods; SimCLR, positionalcontrastive learning, DINO, and masked image modeling (MIM). Subsets of varyingnumbers of subjects were used for supervised fine-tuning of 2D models for eachSSP method, as well as to train a 2D baseline model from scratch. Thefine-tuned models were compared to the baseline using the 3D Dice similaritycoefficient (DSC) in a test dataset of 140 subjects.  The SSP methods showed no performance gains with the largest supervisedfine-tuning subset compared to the baseline (DSC = 0.89). When only 10 subjects(231 2D slices) are available for supervised training, SSP using MIM (DSC =0.86) improves over training from scratch (DSC = 0.82).  This study found that SSP is valuable for CMR cine segmentation when labeledtraining data is scarce, but does not aid state-of-the-art deep learningmethods when ample labeled data is available. Moreover, the choice of SSPmethod is important. The code is publicly available at:https://github.com/q-cardIA/ssp-cmr-cine-segmentation</description>
      <author>example@mail.com (Rob A. J. de Mooij, Josien P. W. Pluim, Cian M. Scannell)</author>
      <guid isPermaLink="false">2409.18100v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Online Adaptation of Learned Vehicle Dynamics Model with Meta-Learning Approach</title>
      <link>http://arxiv.org/abs/2409.14950v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 Pages, 6 Figures, IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本研究提出了一种用于接近操控极限的自动驾驶车辆动力学模型，采用多层神经网络表示。&lt;h4&gt;2. 在线适应需求&lt;/h4&gt;   - 为了应对未见环境，模型需要实现在线适应，但必须在适应新环境的同时不遗忘之前遇到的环境。&lt;h4&gt;3. 方法应用&lt;/h4&gt;   - 本研究应用了Continual-MAML方法，以解决上述问题。该方法通过从优化的初始参数开始更新，使模型能够快速高效地适应之前遇到的环境。&lt;h4&gt;4. 评估方法&lt;/h4&gt;   - 研究评估了在线模型适应对推理性能和模型预测路径积分（MPPI）控制性能的影响，使用TRIKart平台进行实验。&lt;h4&gt;5. 预训练过程&lt;/h4&gt;   - 神经网络使用在测试环境中收集的驾驶数据进行预训练，并在未包含于训练数据的多种不同道路条件下执行在线适应实验。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 实证结果表明，使用Continual-MAML的方法在测试集损失和MPPI的在线跟踪性能上优于固定模型和使用梯度下降的模型。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We represent a vehicle dynamics model for autonomous driving near the limitsof handling via a multi-layer neural network. Online adaptation is desirable inorder to address unseen environments. However, the model needs to adapt to newenvironments without forgetting previously encountered ones. In this study, weapply Continual-MAML to overcome this difficulty. It enables the model to adaptto the previously encountered environments quickly and efficiently by startingupdates from optimized initial parameters. We evaluate the impact of onlinemodel adaptation with respect to inference performance and impact on controlperformance of a model predictive path integral (MPPI) controller using theTRIKart platform. The neural network was pre-trained using driving datacollected in our test environment, and experiments for online adaptation wereexecuted on multiple different road conditions not contained in the trainingdata. Empirical results show that the model using Continual-MAML outperformsthe fixed model and the model using gradient descent in test set loss andonline tracking performance of MPPI.</description>
      <author>example@mail.com (Yuki Tsuchiya, Thomas Balch, Paul Drews, Guy Rosman)</author>
      <guid isPermaLink="false">2409.14950v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>When SAM2 Meets Video Camouflaged Object Segmentation: A Comprehensive Evaluation and Adaptation</title>
      <link>http://arxiv.org/abs/2409.18653v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本研究调查了Segment Anything Model 2（SAM2）在视频伪装物体分割（VCOS）任务中的应用和表现。&lt;h4&gt;2. VCOS挑战&lt;/h4&gt;   - VCOS涉及检测与周围环境无缝融合的物体，这些物体因颜色、纹理相似或光照条件差而难以识别。&lt;h4&gt;3. SAM2的潜力&lt;/h4&gt;   - SAM2作为一种视频基础模型，在多种任务中表现出潜力，但在动态伪装场景中的有效性尚未充分探索。&lt;h4&gt;4. 研究方法&lt;/h4&gt;   - 本研究对SAM2在VCOS中的能力进行了全面评估，主要包括：     - 在伪装视频数据集上评估SAM2的表现，使用不同的模型和提示（点击、框选和掩膜）。     - 探索SAM2与现有多模态大型语言模型（MLLMs）和VCOS方法的结合。     - 通过在视频伪装数据集上进行微调，特别调整SAM2。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 综合实验表明，SAM2在视频中检测伪装物体的零-shot能力优秀。   - 进一步调整SAM2的参数可进一步提升其在VCOS中的表现。&lt;h4&gt;6. 代码获取&lt;/h4&gt;   - 相关代码将会发布在GitHub上，链接为：[SAM2-VCOS](https://github.com/zhoustan/SAM2-VCOS)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhoustan/sam2-vcos&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates the application and performance of the SegmentAnything Model 2 (SAM2) in the challenging task of video camouflaged objectsegmentation (VCOS). VCOS involves detecting objects that blend seamlessly inthe surroundings for videos, due to similar colors and textures, poor lightconditions, etc. Compared to the objects in normal scenes, camouflaged objectsare much more difficult to detect. SAM2, a video foundation model, has shownpotential in various tasks. But its effectiveness in dynamic camouflagedscenarios remains under-explored. This study presents a comprehensive study onSAM2's ability in VCOS. First, we assess SAM2's performance on camouflagedvideo datasets using different models and prompts (click, box, and mask).Second, we explore the integration of SAM2 with existing multimodal largelanguage models (MLLMs) and VCOS methods. Third, we specifically adapt SAM2 byfine-tuning it on the video camouflaged dataset. Our comprehensive experimentsdemonstrate that SAM2 has excellent zero-shot ability of detecting camouflagedobjects in videos. We also show that this ability could be further improved byspecifically adjusting SAM2's parameters for VCOS. The code will be availableat https://github.com/zhoustan/SAM2-VCOS</description>
      <author>example@mail.com (Yuli Zhou, Guolei Sun, Yawei Li, Luca Benini, Ender Konukoglu)</author>
      <guid isPermaLink="false">2409.18653v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>DiffSSC: Semantic LiDAR Scan Completion using Denoising Diffusion Probabilistic Models</title>
      <link>http://arxiv.org/abs/2409.18092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 感知系统在自动驾驶中至关重要，涉及多个传感器和对应的计算机视觉算法。&lt;h4&gt;2. 3D LiDAR传感器&lt;/h4&gt;   - 3D LiDAR传感器广泛用于捕捉车辆周围的稀疏点云。&lt;h4&gt;3. 现有挑战&lt;/h4&gt;   - 由于点云的稀疏性和缺乏语义，这些系统在感知被遮挡区域和场景中的空隙方面存在困难。&lt;h4&gt;4. 解决方案&lt;/h4&gt;   - 语义场景补全（SSC）旨在根据原始LiDAR测量共同预测未观察到的几何形状和语义，以实现更完整的场景表示。&lt;h4&gt;5. 方法创新&lt;/h4&gt;   - 基于扩散模型在图像生成和超分辨率任务中的良好结果，本文提出将其扩展到SSC，通过分别在点和语义空间中实现加噪和去噪的扩散过程。&lt;h4&gt;6. 生成控制&lt;/h4&gt;   - 采用语义LiDAR点云作为条件输入，设计局部和全局正则化损失来稳定去噪过程。&lt;h4&gt;7. 实验评估&lt;/h4&gt;   - 在自动驾驶数据集上评估了我们的方法，结果显示其在SSC任务上超越了最先进的技术。 &lt;h4&gt;8. 结果意义&lt;/h4&gt;   - 该方法的成功表明其在自动驾驶感知系统中的潜力和应用价值。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perception systems play a crucial role in autonomous driving, incorporatingmultiple sensors and corresponding computer vision algorithms. 3D LiDAR sensorsare widely used to capture sparse point clouds of the vehicle's surroundings.However, such systems struggle to perceive occluded areas and gaps in the scenedue to the sparsity of these point clouds and their lack of semantics. Toaddress these challenges, Semantic Scene Completion (SSC) jointly predictsunobserved geometry and semantics in the scene given raw LiDAR measurements,aiming for a more complete scene representation. Building on promising resultsof diffusion models in image generation and super-resolution tasks, we proposetheir extension to SSC by implementing the noising and denoising diffusionprocesses in the point and semantic spaces individually. To control thegeneration, we employ semantic LiDAR point clouds as conditional input anddesign local and global regularization losses to stabilize the denoisingprocess. We evaluate our approach on autonomous driving datasets and ourapproach outperforms the state-of-the-art for SSC.</description>
      <author>example@mail.com (Helin Cao, Sven Behnke)</author>
      <guid isPermaLink="false">2409.18092v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Prototype based Masked Audio Model for Self-Supervised Learning of Sound Event Detection</title>
      <link>http://arxiv.org/abs/2409.17656v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICASSP2025; The code for this paper will be available at
  https://github.com/cai525/Transformer4SED after the paper is accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 声音事件检测（SED）面临一个重大挑战，即如何有效利用未标记的数据，因为标记数据的可用性受限于高昂的注释成本。&lt;h4&gt;2. 现有方法局限&lt;/h4&gt;   - 半监督算法依赖于标记数据来学习未标记数据，性能受到标记数据质量和数量的限制。&lt;h4&gt;3. 新算法介绍&lt;/h4&gt;   - 本文提出了一种新的算法——基于原型的掩蔽音频模型（PMAM），用于SED中的自监督表示学习，以更好地利用未标记数据。&lt;h4&gt;4. 伪标签构建&lt;/h4&gt;   - 利用高斯混合模型（GMM）构建语义丰富的帧级伪标签，这些伪标签用于监督Transformer基础的掩蔽音频模型的学习。&lt;h4&gt;5. 损失函数选择&lt;/h4&gt;   - 采用二元交叉熵损失而非广泛使用的InfoNCE损失，以提供来自不同原型的独立损失贡献，这在多标签的无监督数据帧中尤为重要。&lt;h4&gt;6. 微调阶段&lt;/h4&gt;   - 最后通过少量标记数据进行微调，获得高性能的SED模型。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 在DESED任务的对比测试中，所提方法实现了62.5%的PSDS1得分，超过了当前的最先进模型。&lt;h4&gt;8. 技术优势&lt;/h4&gt;   - 结果表明，所提技术的优越性，展示了在声事件检测任务中的潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cai525/transformer4sed&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A significant challenge in sound event detection (SED) is the effectiveutilization of unlabeled data, given the limited availability of labeled datadue to high annotation costs. Semi-supervised algorithms rely on labeled datato learn from unlabeled data, and the performance is constrained by the qualityand size of the former. In this paper, we introduce the Prototype based MaskedAudio Model~(PMAM) algorithm for self-supervised representation learning inSED, to better exploit unlabeled data. Specifically, semantically richframe-level pseudo labels are constructed from a Gaussian mixture model (GMM)based prototypical distribution modeling. These pseudo labels supervise thelearning of a Transformer-based masked audio model, in which binarycross-entropy loss is employed instead of the widely used InfoNCE loss, toprovide independent loss contributions from different prototypes, which isimportant in real scenarios in which multiple labels may apply to unsuperviseddata frames. A final stage of fine-tuning with just a small amount of labeleddata yields a very high performing SED model. On like-for-like tests using theDESED task, our method achieves a PSDS1 score of 62.5\%, surpassing currentstate-of-the-art models and demonstrating the superiority of the proposedtechnique.</description>
      <author>example@mail.com (Pengfei Cai, Yan Song, Nan Jiang, Qing Gu, Ian McLoughlin)</author>
      <guid isPermaLink="false">2409.17656v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>T3: A Novel Zero-shot Transfer Learning Framework Iteratively Training on an Assistant Task for a Target Task</title>
      <link>http://arxiv.org/abs/2409.17640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 长文本摘要在高效处理大量信息中变得越来越重要，但对大型语言模型（LLMs）如GPT和LLaMA系列仍然具有挑战性。&lt;h4&gt;2. 挑战因素&lt;/h4&gt;   - 主要挑战包括缺乏足够的开源训练数据集以及对上下文细节处理的高要求。&lt;h4&gt;3. 解决方案&lt;/h4&gt;   - 本文设计了一种新颖的零-shot迁移学习框架，简称为T3，旨在通过迭代训练基线LLM在辅助任务上以提升目标任务的表现。&lt;h4&gt;4. 框架设计&lt;/h4&gt;   - T3的思路是选择一个数据资源更丰富且在结构或语义上与目标任务相似的辅助任务。&lt;h4&gt;5. 应用实例&lt;/h4&gt;   - 在实际应用中，T3通过利用问答任务作为辅助任务来处理长文本摘要。&lt;h4&gt;6. 有效性验证&lt;/h4&gt;   - 在多个数据集（如BBC摘要、NarraSum、FairytaleQA和NLQuAD）上验证了T3的有效性。&lt;h4&gt;7. 性能提升&lt;/h4&gt;   - 相较于三种基线LLM，T3在ROUGE上提升近14%、在BLEU上提升35%、在Factscore上提升16%。&lt;h4&gt;8. 未来展望&lt;/h4&gt;   - 结果表明，T3框架在更多辅助任务与目标任务组合中的潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long text summarization, gradually being essential for efficiently processinglarge volumes of information, stays challenging for Large Language Models(LLMs) such as GPT and LLaMA families because of the insufficient open-sourcedtraining datasets and the high requirement of contextual details dealing. Toaddress the issue, we design a novel zero-shot transfer learning framework,abbreviated as T3, to iteratively training a baseline LLM on an assistant taskfor the target task, where the former should own richer data resources andshare structural or semantic similarity with the latter. In practice, T3 isapproached to deal with the long text summarization task by utilizing questionanswering as the assistant task, and further validated its effectiveness on theBBC summary, NarraSum, FairytaleQA, and NLQuAD datasets, with up to nearly 14%improvement in ROUGE, 35% improvement in BLEU, and 16% improvement in Factscorecompared to three baseline LLMs, demonstrating its potential for moreassistant-target task combinations.</description>
      <author>example@mail.com (Xindi Tong, Yujin Zhu, Shijian Fan, Liang Xu)</author>
      <guid isPermaLink="false">2409.17640v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>SynBench: A Synthetic Benchmark for Non-rigid 3D Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2409.14474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 非刚性点云配准在计算机视觉中是一项关键任务。&lt;h4&gt;2. 评估需求&lt;/h4&gt;   - 评估非刚性点云配准方法需要一个包含多种挑战的数据集，如大变形水平、噪声、离群点和不完整性。&lt;h4&gt;3. 现有问题&lt;/h4&gt;   - 尽管已有多个用于变形点云配准的数据集，但缺乏一个综合基准，导致不同方法之间的公平评估困难。&lt;h4&gt;4. 新数据集的介绍&lt;/h4&gt;   - 本文介绍了SynBench，这是一个使用SimTool创建的新非刚性点云配准数据集，SimTool用于柔体模拟，基于Flex和Unreal Engine。&lt;h4&gt;5. 数据集特点&lt;/h4&gt;   - SynBench提供两个点集之间对应点的真实值，并涵盖关键的注册挑战，包括不同程度的变形、噪声、离群点和不完整性。&lt;h4&gt;6. 独特贡献&lt;/h4&gt;   - SynBench具有三个显著特点：     1. 是第一个提供多种非刚性点云配准挑战的基准。     2. 包含不同难度级别的挑战。     3. 提供变形前后对应点的真实值。&lt;h4&gt;7. 未来展望&lt;/h4&gt;   - 作者相信，SynBench将使未来的非刚性点云配准方法能够进行公平的成果比较。&lt;h4&gt;8. 获取信息&lt;/h4&gt;   - SynBench数据集可公开访问，链接为：[SynBench 数据集](https://doi.org/10.11588/data/R9IKCF)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-rigid point cloud registration is a crucial task in computer vision.Evaluating a non-rigid point cloud registration method requires a dataset withchallenges such as large deformation levels, noise, outliers, andincompleteness. Despite the existence of several datasets for deformable pointcloud registration, the absence of a comprehensive benchmark with allchallenges makes it difficult to achieve fair evaluations among differentmethods. This paper introduces SynBench, a new non-rigid point cloudregistration dataset created using SimTool, a toolset for soft body simulationin Flex and Unreal Engine. SynBench provides the ground truth of correspondingpoints between two point sets and encompasses key registration challenges,including varying levels of deformation, noise, outliers, and incompleteness.To the best of the authors' knowledge, compared to existing datasets, SynBenchpossesses three particular characteristics: (1) it is the first benchmark thatprovides various challenges for non-rigid point cloud registration, (2)SynBench encompasses challenges of varying difficulty levels, and (3) itincludes ground truth corresponding points both before and after deformation.The authors believe that SynBench enables future non-rigid point cloudregistration methods to present a fair comparison of their achievements.SynBench is publicly available at: https://doi.org/10.11588/data/R9IKCF.</description>
      <author>example@mail.com (Sara Monji-Azad, Marvin Kinz, Claudia Scherl, David Männle, Jürgen Hesser, Nikolas Löw)</author>
      <guid isPermaLink="false">2409.14474v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>You Only Speak Once to See</title>
      <link>http://arxiv.org/abs/2409.18372v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 figures, submitted to ICASSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 使用视觉线索对图像中的物体进行定位是计算机视觉中的一种成熟方法，但音频在物体识别和定位中的潜力仍未被充分探索。&lt;h4&gt;2. 新方法的提出&lt;/h4&gt;   - 我们介绍了YOSS（"You Only Speak Once to See"），旨在利用音频进行视觉场景中的物体定位，称为音频定位（Audio Grounding）。&lt;h4&gt;3. 方法机制&lt;/h4&gt;   - 通过将预训练的音频模型与视觉模型结合，采用对比学习和多模态对齐，捕捉语音指令或描述，并将其直接映射到图像中的对应物体。&lt;h4&gt;4. 实验结果&lt;/h4&gt;   - 实验结果表明，音频指导可以有效应用于物体定位，建议将音频指导纳入现有物体定位方法中，以提高精度和鲁棒性。&lt;h4&gt;5. 应用前景&lt;/h4&gt;   - 这一发现为高级物体识别、场景理解以及更直观和更强大的机器人系统的发展开辟了新可能性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grounding objects in images using visual cues is a well-established approachin computer vision, yet the potential of audio as a modality for objectrecognition and grounding remains underexplored. We introduce YOSS, "You OnlySpeak Once to See," to leverage audio for grounding objects in visual scenes,termed Audio Grounding. By integrating pre-trained audio models with visualmodels using contrastive learning and multi-modal alignment, our approachcaptures speech commands or descriptions and maps them directly tocorresponding objects within images. Experimental results indicate that audioguidance can be effectively applied to object grounding, suggesting thatincorporating audio guidance may enhance the precision and robustness ofcurrent object grounding methods and improve the performance of robotic systemsand computer vision applications. This finding opens new possibilities foradvanced object recognition, scene understanding, and the development of moreintuitive and capable robotic systems.</description>
      <author>example@mail.com (Wenhao Yang, Jianguo Wei, Wenhuan Lu, Lei Li)</author>
      <guid isPermaLink="false">2409.18372v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MSARS: A Meta-Learning and Reinforcement Learning Framework for SLO Resource Allocation and Adaptive Scaling for Microservices</title>
      <link>http://arxiv.org/abs/2409.14953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 6 figures, IEEE ISPA 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 服务水平目标（SLOs）&lt;/h4&gt;   - SLO旨在为云服务的服务时间设定阈值，以确保服务质量（QoS）和用户满意度。&lt;h4&gt;2. 现状&lt;/h4&gt;   - 当前许多研究将SLO视为需要分配的系统资源，以确保QoS符合SLO要求。&lt;h4&gt;3. 现有框架的局限性&lt;/h4&gt;   - 现有的微服务自动扩展框架依赖SLO资源，通常使用复杂且计算密集型的模型，需要大量时间和资源来确定适当的资源分配。&lt;h4&gt;4. 研究目标&lt;/h4&gt;   - 本文旨在快速分配SLO资源，减少资源成本，同时确保应用QoS满足SLO要求，适应动态变化的微服务环境。&lt;h4&gt;5. 提出的框架&lt;/h4&gt;   - 提出了MSARS框架，利用元学习快速推导SLO资源分配策略，并采用强化学习进行微服务资源的自适应扩展。&lt;h4&gt;6. 创新组件&lt;/h4&gt;   - **第一**：MSARS使用图卷积网络（GCN）预测当前环境中最适合的SLO资源分配方案。   - **第二**：利用元学习使图神经网络能够快速适应环境变化，确保在高度动态的微服务环境中具备适应性。   - **第三**：基于改进的双延迟深度确定性策略梯度（TD3）模型生成每个微服务的自动扩展策略。&lt;h4&gt;7. 自适应自动扩展政策&lt;/h4&gt;   - 自适应自动扩展政策将SLO资源分配策略整合进调度算法中，以满足SLO要求。&lt;h4&gt;8. 性能比较&lt;/h4&gt;   - 与利用神经网络和强化学习的最先进资源自动扩展算法相比，MSARS在适应新环境时减少了40%的时间，减少了38%的SLO违规次数，并降低了8%的资源成本。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Service Level Objectives (SLOs) aim to set threshold for service time incloud services to ensure acceptable quality of service (QoS) and usersatisfaction. Currently, many studies consider SLOs as a system resource to beallocated, ensuring QoS meets the SLOs. Existing microservice auto-scalingframeworks that rely on SLO resources often utilize complex and computationallyintensive models, requiring significant time and resources to determineappropriate resource allocation. This paper aims to rapidly allocate SLOresources and minimize resource costs while ensuring application QoS meets theSLO requirements in a dynamically changing microservice environment. We proposeMSARS, a framework that leverages meta-learning to quickly derive SLO resourceallocation strategies and employs reinforcement learning for adaptive scalingof microservice resources. It features three innovative components: First,MSARS uses graph convolutional networks to predict the most suitable SLOresource allocation scheme for the current environment. Second, MSARS utilizesmeta-learning to enable the graph neural network to quickly adapt toenvironmental changes ensuring adaptability in highly dynamic microserviceenvironments. Third, MSARS generates auto-scaling policies for eachmicroservice based on an improved Twin Delayed Deep Deterministic PolicyGradient (TD3) model. The adaptive auto-scaling policy integrates the SLOresource allocation strategy into the scheduling algorithm to satisfy SLOs.Finally, we compare MSARS with state-of-the-art resource auto-scalingalgorithms that utilize neural networks and reinforcement learning, MSARS takes40% less time to adapt to new environments, 38% reduction of SLO violations,and 8% less resources cost.</description>
      <author>example@mail.com (Kan Hu, Linfeng Wen, Minxian Xu, Kejiang Ye)</author>
      <guid isPermaLink="false">2409.14953v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Supra-Laplacian Encoding for Transformer on Dynamic Graphs</title>
      <link>http://arxiv.org/abs/2409.17986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 背景&lt;/h4&gt;   - 完全连接的图变换器（Graph Transformers, GT）在静态图社区中迅速崛起，作为消息传递模型的替代方案，后者存在表达能力不足、过度压缩和欠覆盖等问题。&lt;h4&gt;2. 动态上下文中的挑战&lt;/h4&gt;   - 在动态情况下，通过自注意力机制连接多个快照中的所有节点，GT丧失了结构和时间信息。&lt;h4&gt;3. 新方法的提出&lt;/h4&gt;   - 本文介绍了超拉普拉斯编码（Supra-Laplacian encoding）用于时空变换器（SLATE），这是一种新的时空编码方法，旨在利用GT架构，同时保持时空信息。&lt;h4&gt;4. 具体实现&lt;/h4&gt;   - 将离散时间动态图转换为多层图，并利用其关联超拉普拉斯矩阵的谱特性。&lt;h4&gt;5. 配对关系建模&lt;/h4&gt;   - 通过交叉注意力机制显式建模节点之间的配对关系，为动态链接预测提供准确的边表示。&lt;h4&gt;6. 性能比较&lt;/h4&gt;   - SLATE在9个数据集上超越了许多基于消息传递图神经网络与递归模型（如LSTM）结合的最先进方法，以及动态图变换器。&lt;h4&gt;7. 代码发布&lt;/h4&gt;   - 将开放源代码和重现结果的说明，以促进研究的进一步发展。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fully connected Graph Transformers (GT) have rapidly become prominent in thestatic graph community as an alternative to Message-Passing models, whichsuffer from a lack of expressivity, oversquashing, and under-reaching. However,in a dynamic context, by interconnecting all nodes at multiple snapshots withself-attention, GT loose both structural and temporal information. In thiswork, we introduce Supra-LAplacian encoding for spatio-temporal TransformErs(SLATE), a new spatio-temporal encoding to leverage the GT architecture whilekeeping spatio-temporal information. Specifically, we transform Discrete TimeDynamic Graphs into multi-layer graphs and take advantage of the spectralproperties of their associated supra-Laplacian matrix. Our second contributionexplicitly model nodes' pairwise relationships with a cross-attentionmechanism, providing an accurate edge representation for dynamic linkprediction. SLATE outperforms numerous state-of-the-art methods based onMessage-Passing Graph Neural Networks combined with recurrent models (e.gLSTM), and Dynamic Graph Transformers, on 9 datasets. Code and instructions toreproduce our results will be open-sourced.</description>
      <author>example@mail.com (Yannis Karmim, Marc Lafon, Raphaël Fournier S'niehotta, Nicolas Thome)</author>
      <guid isPermaLink="false">2409.17986v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>How green is continual learning, really? Analyzing the energy consumption in continual training of vision foundation models</title>
      <link>http://arxiv.org/abs/2409.18664v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript has been accepted at the Green FOundation MOdels
  (GreenFOMO) ECCV 2024 Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着人工智能（AI）应用的不断增加，其对环境的影响逐渐显著。尽管持续学习（continual learning）具有促进绿色AI的潜力，但其环境可持续性仍然相对未被探索。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 本研究旨在系统地理解持续学习算法的能效。&lt;h4&gt;3. 实验设计&lt;/h4&gt;   - 进行了广泛的实证实验，比较了最近的表示、提示和示例基础的持续学习算法与两种标准基线（微调和联合训练）在持续适应预训练ViT-B/16基础模型时的能耗。&lt;h4&gt;4. 数据集&lt;/h4&gt;   - 实验在三个标准数据集上进行：CIFAR-100、ImageNet-R和DomainNet。&lt;h4&gt;5. 新指标的提出&lt;/h4&gt;   - 提出了一个新颖的指标——能量净得分（Energy NetScore），用于衡量算法在能源和准确性之间的权衡效率。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 通过对学习步骤的数量和大小进行不同评估，实验表明不同类型的持续学习算法在训练和推理阶段对能量消耗的影响差异很大。&lt;h4&gt;7. 推理阶段的重要性&lt;/h4&gt;   - 尽管在持续学习文献中常被忽视，研究发现推理阶段消耗的能量对于评估持续学习模型的环境可持续性至关重要。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the ever-growing adoption of AI, its impact on the environment is nolonger negligible. Despite the potential that continual learning could havetowards Green AI, its environmental sustainability remains relativelyuncharted. In this work we aim to gain a systematic understanding of the energyefficiency of continual learning algorithms. To that end, we conducted anextensive set of empirical experiments comparing the energy consumption ofrecent representation-, prompt-, and exemplar-based continual learningalgorithms and two standard baseline (fine tuning and joint training) when usedto continually adapt a pre-trained ViT-B/16 foundation model. We performed ourexperiments on three standard datasets: CIFAR-100, ImageNet-R, and DomainNet.Additionally, we propose a novel metric, the Energy NetScore, which we usemeasure the algorithm efficiency in terms of energy-accuracy trade-off. Throughnumerous evaluations varying the number and size of the incremental learningsteps, our experiments demonstrate that different types of continual learningalgorithms have very different impacts on energy consumption during bothtraining and inference. Although often overlooked in the continual learningliterature, we found that the energy consumed during the inference phase iscrucial for evaluating the environmental sustainability of continual learningmodels.</description>
      <author>example@mail.com (Tomaso Trinci, Simone Magistri, Roberto Verdecchia, Andrew D. Bagdanov)</author>
      <guid isPermaLink="false">2409.18664v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>EdgeRunner: Auto-regressive Auto-encoder for Artistic Mesh Generation</title>
      <link>http://arxiv.org/abs/2409.18114v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://research.nvidia.com/labs/dir/edgerunner/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 当前方法的问题&lt;/h4&gt;   - 现有的自回归网格生成方法存在不完整、细节不足和泛化能力差等问题。&lt;h4&gt;2. 新模型的提出&lt;/h4&gt;   - 本文提出了一种自回归自编码器（ArAE）模型，能够生成高质量的3D网格，最多可达到4,000个面，空间分辨率为 $512^3$。&lt;h4&gt;3. 网格标记化算法&lt;/h4&gt;   - 引入了一种新颖的网格标记化算法，将三角网格高效压缩为一维标记序列，显著提高训练效率。&lt;h4&gt;4. 固定长度潜在空间&lt;/h4&gt;   - 模型将可变长度的三角网格压缩为固定长度的潜在空间，从而使训练潜在扩散模型成为可能，以提高泛化能力。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 大量实验表明，在点云和图像条件下的网格生成任务中，该模型在质量、多样性和泛化能力上表现优越。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current auto-regressive mesh generation methods suffer from issues such asincompleteness, insufficient detail, and poor generalization. In this paper, wepropose an Auto-regressive Auto-encoder (ArAE) model capable of generatinghigh-quality 3D meshes with up to 4,000 faces at a spatial resolution of$512^3$. We introduce a novel mesh tokenization algorithm that efficientlycompresses triangular meshes into 1D token sequences, significantly enhancingtraining efficiency. Furthermore, our model compresses variable-lengthtriangular meshes into a fixed-length latent space, enabling training latentdiffusion models for better generalization. Extensive experiments demonstratethe superior quality, diversity, and generalization capabilities of our modelin both point cloud and image-conditioned mesh generation tasks.</description>
      <author>example@mail.com (Jiaxiang Tang, Zhaoshuo Li, Zekun Hao, Xian Liu, Gang Zeng, Ming-Yu Liu, Qinsheng Zhang)</author>
      <guid isPermaLink="false">2409.18114v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>From Text to Treatment Effects: A Meta-Learning Approach to Handling Text-Based Confounding</title>
      <link>http://arxiv.org/abs/2409.15503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目标&lt;/h4&gt;   - 研究因果机器学习的核心目标之一是从观察数据中准确估计异质性处理效应（Heterogeneous Treatment Effects）。&lt;h4&gt;2. Meta-learning 的兴起&lt;/h4&gt;   - 近年来，元学习（meta-learning）作为一种灵活的、模型无关的范式，开始用于估计条件平均处理效应（CATE），可以使用任何监督模型。&lt;h4&gt;3. 研究重点&lt;/h4&gt;   - 本文重点考察当混杂变量嵌入文本中时，元学习者的表现。&lt;h4&gt;4. 实验方法&lt;/h4&gt;   - 通过合成数据实验，展示使用预训练文本表示的混杂变量与表格背景变量结合时，学习者的 CATE 估计效果优于仅依赖表格变量的模型，尤其是在数据充足时。&lt;h4&gt;5. 模型性能限制&lt;/h4&gt;   - 由于文本嵌入的复杂性，这些模型的性能仍未能完全匹配具有完美混杂变量知识的元学习者的表现。&lt;h4&gt;6. 研究发现的意义&lt;/h4&gt;   - 研究结果突显了预训练文本表示在因果推断中的潜力和局限性，并为未来研究开辟了有趣的方向。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; One of the central goals of causal machine learning is the accurateestimation of heterogeneous treatment effects from observational data. Inrecent years, meta-learning has emerged as a flexible, model-agnostic paradigmfor estimating conditional average treatment effects (CATE) using anysupervised model. This paper examines the performance of meta-learners when theconfounding variables are embedded in text. Through synthetic data experiments,we show that learners using pre-trained text representations of confounders, inaddition to tabular background variables, achieve improved CATE estimatescompare to those relying solely on the tabular variables, particularly whensufficient data is available. However, due to the entangled nature of the textembeddings, these models do not fully match the performance of meta-learnerswith perfect confounder knowledge. These findings highlight both the potentialand the limitations of pre-trained text representations for causal inferenceand open up interesting avenues for future research.</description>
      <author>example@mail.com (Henri Arno, Paloma Rabaey, Thomas Demeester)</author>
      <guid isPermaLink="false">2409.15503v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Unsupervised Learning for Cost-Effective Visual Anomaly Detection</title>
      <link>http://arxiv.org/abs/2409.15980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 传统系统的局限性&lt;/h4&gt;   - 传统基于机器学习的视觉检测系统需要大量数据收集和重复模型训练以提高准确性。   - 这些系统通常需要昂贵的相机、计算设备和显著的机器学习专业知识，给中小企业带来负担。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 本研究探索利用无监督学习方法、预训练模型和低成本硬件，以创建一种经济高效的视觉异常检测系统。&lt;h4&gt;3. 低成本解决方案&lt;/h4&gt;   - 旨在开发一种低成本的视觉异常检测方案，使用最少的数据进行模型训练，同时保持模型的泛化能力和可扩展性。&lt;h4&gt;4. 系统架构&lt;/h4&gt;   - 系统利用来自 Anomalib 的无监督学习模型，并通过 openVINO 部署在经济实惠的 Raspberry Pi 硬件上。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 结果显示，该经济高效的系统可以在 Raspberry Pi 上完成异常检测训练和推断，仅需 90 秒，且只使用 10 张正常产品图像。&lt;h4&gt;6. 性能指标&lt;/h4&gt;   - 系统在性能上表现良好，F1 宏得分超过 0.95。&lt;h4&gt;7. 环境敏感性&lt;/h4&gt;   - 虽然系统对环境变化（如光照、产品定位或背景）略显敏感，但仍然是中小制造商进行工厂自动化检测的快速且经济的方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional machine learning-based visual inspection systems requireextensive data collection and repetitive model training to improve accuracy.These systems typically require expensive camera, computing equipment andsignificant machine learning expertise, which can substantially burden smalland medium-sized enterprises. This study explores leveraging unsupervisedlearning methods with pre-trained models and low-cost hardware to create acost-effective visual anomaly detection system. The research aims to develop alow-cost visual anomaly detection solution that uses minimal data for modeltraining while maintaining generalizability and scalability. The systemutilises unsupervised learning models from Anomalib and is deployed onaffordable Raspberry Pi hardware through openVINO. The results show that thiscost-effective system can complete anomaly defection training and inference ona Raspberry Pi in just 90 seconds using only 10 normal product images,achieving an F1 macro score exceeding 0.95. While the system is slightlysensitive to environmental changes like lighting, product positioning, orbackground, it remains a swift and economical method for factory automationinspection for small and medium-sized manufacturers</description>
      <author>example@mail.com (Yunbo Long, Zhengyang Ling, Sam Brook, Duncan McFarlane, Alexandra Brintrup)</author>
      <guid isPermaLink="false">2409.15980v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Embed and Emulate: Contrastive representations for simulation-based inference</title>
      <link>http://arxiv.org/abs/2409.18402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 科学建模和工程应用严重依赖参数估计方法，以适应物理模型并使用真实世界的测量数据校准数值仿真。&lt;h4&gt;2. 现代仿真基础推断（SBI）方法&lt;/h4&gt;   - 在缺乏可处理的解析统计模型和可行的似然函数的情况下，现代SBI方法首先使用数值模拟器生成参数和模拟输出的数据集。&lt;h4&gt;3. 数据集的应用&lt;/h4&gt;   - 该数据集用于近似似然函数，并在给定观测数据的情况下估计系统参数。&lt;h4&gt;4. 机器学习的角色&lt;/h4&gt;   - 一些SBI方法采用机器学习模拟器来加速数据生成和参数估计。&lt;h4&gt;5. 高维系统的挑战&lt;/h4&gt;   - 将这些方法应用于高维物理系统仍然具有挑战性，主要由于训练高维模拟器的成本和复杂性。&lt;h4&gt;6. 新方法的提出&lt;/h4&gt;   - 本文提出了一种新的SBI方法，称为嵌入与模拟（E&amp;E），基于对比学习，能够有效处理高维数据和复杂的多模态参数后验。&lt;h4&gt;7. 低维潜在嵌入学习&lt;/h4&gt;   - E&amp;E学习数据的低维潜在嵌入（即摘要统计量）及其在潜在空间中的快速模拟器，从而在推断过程中消除了运行昂贵的仿真或高维模拟器的需要。&lt;h4&gt;8. 理论属性及实验验证&lt;/h4&gt;   - 通过合成实验展示学习的潜在空间的理论属性，并在高维混沌Lorenz 96系统的现实非可识别参数估计任务中展示了优越的性能，相较于现有方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scientific modeling and engineering applications rely heavily on parameterestimation methods to fit physical models and calibrate numerical simulationsusing real-world measurements. In the absence of analytic statistical modelswith tractable likelihoods, modern simulation-based inference (SBI) methodsfirst use a numerical simulator to generate a dataset of parameters andsimulated outputs. This dataset is then used to approximate the likelihood andestimate the system parameters given observation data. Several SBI methodsemploy machine learning emulators to accelerate data generation and parameterestimation. However, applying these approaches to high-dimensional physicalsystems remains challenging due to the cost and complexity of traininghigh-dimensional emulators. This paper introduces Embed and Emulate (E&amp;E): anew SBI method based on contrastive learning that efficiently handleshigh-dimensional data and complex, multimodal parameter posteriors. E&amp;E learnsa low-dimensional latent embedding of the data (i.e., a summary statistic) anda corresponding fast emulator in the latent space, eliminating the need to runexpensive simulations or a high dimensional emulator during inference. Weillustrate the theoretical properties of the learned latent space through asynthetic experiment and demonstrate superior performance over existing methodsin a realistic, non-identifiable parameter estimation task using thehigh-dimensional, chaotic Lorenz 96 system.</description>
      <author>example@mail.com (Ruoxi Jiang, Peter Y. Lu, Rebecca Willett)</author>
      <guid isPermaLink="false">2409.18402v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Spatiotemporal Learning on Cell-embedded Graphs</title>
      <link>http://arxiv.org/abs/2409.18013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 数据驱动的物理系统仿真最近引起了广泛关注，许多神经模型相继被开发。&lt;h4&gt;2. 图神经网络的潜力&lt;/h4&gt;   - 尤其是基于网格的图神经网络（GNN）在预测任意几何域的时空动态方面展示了显著潜力。&lt;h4&gt;3. 现有方法的局限性&lt;/h4&gt;   - 现有的节点-边消息传递机制限制了模型的表示学习能力。&lt;h4&gt;4. 新模型的提出&lt;/h4&gt;   - 本文提出了一种细胞嵌入的图神经网络模型（CeGNN），用于学习时空动态，性能提升显著。&lt;h4&gt;5. 可学习的细胞属性&lt;/h4&gt;   - 在消息传递过程中引入可学习的细胞属性，更好地捕捉区域特征的空间依赖性。&lt;h4&gt;6. 局部聚合机制的升级&lt;/h4&gt;   - 该策略将局部聚合方案从一阶（如从边到节点）升级到更高阶（如从体积到边，再到节点），充分利用体积信息。&lt;h4&gt;7. 新颖的特征增强模块&lt;/h4&gt;   - 设计了一种新的特征增强模块，进一步提高了 CeGNN 的性能，并缓解了过平滑问题，通过将潜在特征视为基函数。&lt;h4&gt;8. 实验验证&lt;/h4&gt;   - 在多个偏微分方程（PDE）系统和一个真实世界数据集上进行了广泛实验，结果表明 CeGNN 相较于其他基线模型具有优越性能，特别是在多个 PDE 系统上将预测误差降低了一个数量级。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data-driven simulation of physical systems has recently kindled significantattention, where many neural models have been developed. In particular,mesh-based graph neural networks (GNNs) have demonstrated significant potentialin predicting spatiotemporal dynamics across arbitrary geometric domains.However, the existing node-edge message passing mechanism in GNNs limits themodel's representation learning ability. In this paper, we proposed acell-embedded GNN model (aka CeGNN) to learn spatiotemporal dynamics withlifted performance. Specifically, we introduce a learnable cell attribution tothe node-edge message passing process, which better captures the spatialdependency of regional features. Such a strategy essentially upgrades the localaggregation scheme from the first order (e.g., from edge to node) to a higherorder (e.g., from volume to edge and then to node), which takes advantage ofvolumetric information in message passing. Meanwhile, a novel feature-enhancedblock is designed to further improve the performance of CeGNN and relieve theover-smoothness problem, via treating the latent features as basis functions.The extensive experiments on various PDE systems and one real-world datasetdemonstrate that CeGNN achieves superior performance compared with otherbaseline models, particularly reducing the prediction error with up to 1 ordersof magnitude on several PDE systems.</description>
      <author>example@mail.com (Yuan Mi, Hao Sun)</author>
      <guid isPermaLink="false">2409.18013v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>HM3: Hierarchical Multi-Objective Model Merging for Pretrained Models</title>
      <link>http://arxiv.org/abs/2409.18893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 模型合并的定义&lt;/h4&gt;   - 模型合并是一种技术，旨在将多个大型预训练模型合并为一个具有更强性能和更广泛任务适应性的单一模型。&lt;h4&gt;2. 技术的流行原因&lt;/h4&gt;   - 该技术因其能够绕过原始训练数据和进一步训练过程而在大型预训练模型开发中日益流行。&lt;h4&gt;3. 现有方法的局限&lt;/h4&gt;   - 大多数现有模型合并方法主要集中在探索参数空间，合并具有相同架构的模型。&lt;h4&gt;4. 架构空间合并的挑战&lt;/h4&gt;   - 在架构空间内进行合并尽管潜力巨大，但由于搜索空间庞大和层兼容性挑战，仍处于早期阶段。&lt;h4&gt;5. 新方法的提出&lt;/h4&gt;   - 本文通过将架构空间合并过程建模为强化学习任务，标志着向更灵活和全面的模型合并技术迈出了重要一步。&lt;h4&gt;6. 训练网络的方式&lt;/h4&gt;   - 通过对权重向量的离线采样训练策略网络和价值网络，随后用于合并策略的在线优化。&lt;h4&gt;7. 多目标优化框架&lt;/h4&gt;   - 引入多目标优化范式，以适应用户多样的任务偏好，学习最优模型的帕累托前沿，提供定制的合并建议。&lt;h4&gt;8. 实验验证&lt;/h4&gt;   - 在多个任务（如文本翻译、数学推理和代码生成）上的实验结果验证了所提框架在模型合并中的有效性和优越性。&lt;h4&gt;9. 代码共享&lt;/h4&gt;   - 研究代码将在审稿过程后公开发布。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model merging is a technique that combines multiple large pretrained modelsinto a single model with enhanced performance and broader task adaptability. Ithas gained popularity in large pretrained model development due to its abilityto bypass the need for original training data and further training processes.However, most existing model merging approaches focus solely on exploring theparameter space, merging models with identical architectures. Merging withinthe architecture space, despite its potential, remains in its early stages dueto the vast search space and the challenges of layer compatibility. This papermarks a significant advance toward more flexible and comprehensive modelmerging techniques by modeling the architecture-space merging process as areinforcement learning task. We train policy and value networks using offlinesampling of weight vectors, which are then employed for the online optimizationof merging strategies. Moreover, a multi-objective optimization paradigm isintroduced to accommodate users' diverse task preferences, learning the Paretofront of optimal models to offer customized merging suggestions. Experimentalresults across multiple tasks, including text translation, mathematicalreasoning, and code generation, validate the effectiveness and superiority ofthe proposed framework in model merging. The code will be made publiclyavailable after the review process.</description>
      <author>example@mail.com (Yu Zhou, Xingyu Wu, Jibin Wu, Liang Feng, Kay Chen Tan)</author>
      <guid isPermaLink="false">2409.18893v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Spatial Visibility and Temporal Dynamics: Revolutionizing Field of View Prediction in Adaptive Point Cloud Video Streaming</title>
      <link>http://arxiv.org/abs/2409.18236v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 视场（FoV）自适应流媒体显著减少了沉浸式点云视频（PCV）的带宽需求，仅传输观众视场内的可见点。&lt;h4&gt;2. 传统方法的局限&lt;/h4&gt;   - 传统方法通常专注于基于轨迹的 6 自由度（6DoF）FoV 预测，利用预测的 FoV 计算点的可见性。   - 这些方法未明确考虑视频内容对观众注意力的影响，且从 FoV 到点可见性的转换常常容易出错且耗时。&lt;h4&gt;3. 新方法的提出&lt;/h4&gt;   - 本文从单元可见性的角度重新构建 PCV FoV 预测问题，基于预测的可见性分布做出精确的 3D 数据传输决策。&lt;h4&gt;4. 模型开发&lt;/h4&gt;   - 开发了一种新颖的空间可见性和对象感知图模型，利用历史 3D 可见性数据，同时结合空间感知、邻近单元相关性和遮挡信息来预测未来的单元可见性。&lt;h4&gt;5. 性能提升&lt;/h4&gt;   - 该模型显著改善了长期单元可见性预测，与最先进模型相比，预测均方误差（MSE）损失降低了多达 50%。&lt;h4&gt;6. 实时性能&lt;/h4&gt;   - 模型在处理超过 100 万个点的点云视频时，仍保持实时性能（超过 30fps）。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Field-of-View (FoV) adaptive streaming significantly reduces bandwidthrequirement of immersive point cloud video (PCV) by only transmitting visiblepoints in a viewer's FoV. The traditional approaches often focus ontrajectory-based 6 degree-of-freedom (6DoF) FoV predictions. The predicted FoVis then used to calculate point visibility. Such approaches do not explicitlyconsider video content's impact on viewer attention, and the conversion fromFoV to point visibility is often error-prone and time-consuming. We reformulatethe PCV FoV prediction problem from the cell visibility perspective, allowingfor precise decision-making regarding the transmission of 3D data at the celllevel based on the predicted visibility distribution. We develop a novelspatial visibility and object-aware graph model that leverages the historical3D visibility data and incorporates spatial perception, neighboring cellcorrelation, and occlusion information to predict the cell visibility in thefuture. Our model significantly improves the long-term cell visibilityprediction, reducing the prediction MSE loss by up to 50% compared to thestate-of-the-art models while maintaining real-time performance (more than30fps) for point cloud videos with over 1 million points.</description>
      <author>example@mail.com (Chen Li, Tongyu Zong, Yueyu Hu, Yao Wang, Yong Liu)</author>
      <guid isPermaLink="false">2409.18236v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Transferring disentangled representations: bridging the gap between synthetic and real images</title>
      <link>http://arxiv.org/abs/2409.18017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究重要性&lt;/h4&gt;   - 在表示学习中，开发有意义且高效的表示，能够分离数据生成机制的基本结构，是至关重要的。&lt;h4&gt;2. 现有挑战&lt;/h4&gt;   - 目前，解缠表示学习在真实图像上的潜力尚未充分展现，主要原因包括生成因素之间的相关性、分辨率问题以及对真实标签的有限访问。&lt;h4&gt;3. 合成数据的利用&lt;/h4&gt;   - 本文探讨利用合成数据学习通用的解缠表示，以便应用于真实数据，并讨论微调的效果及其转移后保留的解缠特性。&lt;h4&gt;4. 实证研究&lt;/h4&gt;   - 提供了广泛的实证研究，以解决上述问题。&lt;h4&gt;5. 新度量标准&lt;/h4&gt;   - 提出了一种新的可解释的基于干预的度量标准，以衡量表示中因素编码的质量。&lt;h4&gt;6. 研究结果&lt;/h4&gt;   - 结果表明，从合成数据到真实数据的表示转移能实现某种程度的解缠，并且是有效的。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing meaningful and efficient representations that separate thefundamental structure of the data generation mechanism is crucial inrepresentation learning. However, Disentangled Representation Learning has notfully shown its potential on real images, because of correlated generativefactors, their resolution and limited access to ground truth labels.Specifically on the latter, we investigate the possibility of leveragingsynthetic data to learn general-purpose disentangled representations applicableto real data, discussing the effect of fine-tuning and what properties ofdisentanglement are preserved after the transfer. We provide an extensiveempirical study to address these issues. In addition, we propose a newinterpretable intervention-based metric, to measure the quality of factorsencoding in the representation. Our results indicate that some level ofdisentanglement, transferring a representation from synthetic to real data, ispossible and effective.</description>
      <author>example@mail.com (Jacopo Dapueto, Nicoletta Noceti, Francesca Odone)</author>
      <guid isPermaLink="false">2409.18017v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Learning Based Multi-Scale Exposure Fusion</title>
      <link>http://arxiv.org/abs/2409.17830v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 提出了无监督学习基础的多尺度曝光融合（ULMEF），用于将不同曝光的低动态范围（LDR）图像融合为高质量的 LDR 图像，以表示高动态范围（HDR）场景。&lt;h4&gt;2. 无监督学习的特点&lt;/h4&gt;   - 在 ULMEF 中，损失函数起着关键作用，与监督学习不同。&lt;h4&gt;3. 新型损失函数&lt;/h4&gt;   - 本文提出了新型损失函数，这些损失函数使用待融合的所有图像及来自同一 HDR 场景的其他不同曝光图像来定义。&lt;h4&gt;4. 损失函数的优势&lt;/h4&gt;   - 新的损失函数能够引导 ULMEF 从 HDR 场景中学习更可靠的信息，相比仅使用待融合图像集的现有损失函数，显著提升了融合图像的质量。&lt;h4&gt;5. 多尺度策略&lt;/h4&gt;   - ULMEF 采用了多尺度策略，包括多尺度注意模块，有效保留了融合图像中的场景深度和局部对比度。&lt;h4&gt;6. 扩展应用&lt;/h4&gt;   - ULMEF 还可以用于曝光插值和曝光外推。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 大量实验表明，所提出的 ULMEF 算法在性能上优于最先进的曝光融合算法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised learning based multi-scale exposure fusion (ULMEF) is efficientfor fusing differently exposed low dynamic range (LDR) images into a higherquality LDR image for a high dynamic range (HDR) scene. Unlike supervisedlearning, loss functions play a crucial role in the ULMEF. In this paper, novelloss functions are proposed for the ULMEF and they are defined by using all theimages to be fused and other differently exposed images from the same HDRscene. The proposed loss functions can guide the proposed ULMEF to learn morereliable information from the HDR scene than existing loss functions which aredefined by only using the set of images to be fused. As such, the quality ofthe fused image is significantly improved. The proposed ULMEF also adopts amulti-scale strategy that includes a multi-scale attention module toeffectively preserve the scene depth and local contrast in the fused image.Meanwhile, the proposed ULMEF can be adopted to achieve exposure interpolationand exposure extrapolation. Extensive experiments show that the proposed ULMEFalgorithm outperforms state-of-the-art exposure fusion algorithms.</description>
      <author>example@mail.com (Chaobing Zheng, Shiqian Wu, Zhenggguo Li)</author>
      <guid isPermaLink="false">2409.17830v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>UniBEVFusion: Unified Radar-Vision BEVFusion for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2409.14751v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 4 figues, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 技术背景&lt;/h4&gt;   - 4D 毫米波（MMW）雷达提供高度信息和密集的点云数据，逐渐在 3D 物体检测中变得流行。&lt;h4&gt;2. 雷达与视觉融合&lt;/h4&gt;   - 最近，雷达-视觉融合模型的性能接近基于 LiDAR 的模型，具备更低的硬件成本和在极端条件下更好的适应性。&lt;h4&gt;3. 现有模型的问题&lt;/h4&gt;   - 许多雷达-视觉融合模型将雷达视为稀疏的 LiDAR，未充分利用雷达特有的信息。   - 这些多模态网络对单一模态（尤其是视觉）的失败非常敏感。&lt;h4&gt;4. 提出的解决方案&lt;/h4&gt;   - 提出了雷达深度提升-分裂-发射（RDL）模块，将雷达特定数据整合到深度预测过程中，以增强视觉鸟瞰图（BEV）特征的质量。&lt;h4&gt;5. 统一特征融合方法&lt;/h4&gt;   - 引入统一特征融合（UFF）方法，使用共享模块提取不同模态的 BEV 特征。&lt;h4&gt;6. 鲁棒性评估&lt;/h4&gt;   - 开发了新颖的失败测试（FT）消融实验，通过注入高斯噪声模拟视觉模态的失败，以评估多模态模型的鲁棒性。&lt;h4&gt;7. 实验与结果&lt;/h4&gt;   - 在 View-of-Delft (VoD) 和 TJ4D 数据集上进行了广泛实验。   - 结果表明，提出的统一 BEV 融合（UniBEVFusion）网络在 TJ4D 数据集上的 3D 和 BEV 物体检测准确率分别提高了 1.44 和 1.72，显著优于最先进模型。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 4D millimeter-wave (MMW) radar, which provides both height information anddense point cloud data over 3D MMW radar, has become increasingly popular in 3Dobject detection. In recent years, radar-vision fusion models have demonstratedperformance close to that of LiDAR-based models, offering advantages in termsof lower hardware costs and better resilience in extreme conditions. However,many radar-vision fusion models treat radar as a sparse LiDAR, underutilizingradar-specific information. Additionally, these multi-modal networks are oftensensitive to the failure of a single modality, particularly vision. To addressthese challenges, we propose the Radar Depth Lift-Splat-Shoot (RDL) module,which integrates radar-specific data into the depth prediction process,enhancing the quality of visual Bird-Eye View (BEV) features. We furtherintroduce a Unified Feature Fusion (UFF) approach that extracts BEV featuresacross different modalities using shared module. To assess the robustness ofmulti-modal models, we develop a novel Failure Test (FT) ablation experiment,which simulates vision modality failure by injecting Gaussian noise. We conductextensive experiments on the View-of-Delft (VoD) and TJ4D datasets. The resultsdemonstrate that our proposed Unified BEVFusion (UniBEVFusion) networksignificantly outperforms state-of-the-art models on the TJ4D dataset, withimprovements of 1.44 in 3D and 1.72 in BEV object detection accuracy.</description>
      <author>example@mail.com (Haocheng Zhao, Runwei Guan, Taoyu Wu, Ka Lok Man, Limin Yu, Yutao Yue)</author>
      <guid isPermaLink="false">2409.14751v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Flat'n'Fold: A Diverse Multi-Modal Dataset for Garment Perception and Manipulation</title>
      <link>http://arxiv.org/abs/2409.18297v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 数据集介绍&lt;/h4&gt;   - 提出了 Flat'n'Fold，这是一个新颖的大规模服装操作数据集，旨在填补现有数据集中的关键空白。&lt;h4&gt;2. 数据集规模&lt;/h4&gt;   - 包含 1,212 个由人类示范和 887 个由机器人示范的平整和折叠 44 种独特服装的操作，涵盖 8 个类别。&lt;h4&gt;3. 数据集优势&lt;/h4&gt;   - Flat'n'Fold 在规模、范围和多样性上超过了先前的数据集。&lt;h4&gt;4. 数据捕获&lt;/h4&gt;   - 数据集独特地捕捉了从皱褶到折叠状态的整个操作过程，提供同步的多视角 RGB-D 图像、点云和操作数据，包括手或夹具的位置与旋转信息。&lt;h4&gt;5. 多样性和复杂性分析&lt;/h4&gt;   - 对比现有基准，量化了数据集的多样性和复杂性，显示出自然且多样的真实世界人类和机器人操作演示。&lt;h4&gt;6. 基准建立&lt;/h4&gt;   - 建立了抓取点预测和子任务分解的新基准，以展示 Flat'n'Fold 的实用性。&lt;h4&gt;7. 模型评估&lt;/h4&gt;   - 对现有最先进模型在这些任务上的评估显示出显著的改进空间，强调了 Flat'n'Fold 在可变形物体的机器人感知和操作中的潜力。&lt;h4&gt;8. 数据集获取&lt;/h4&gt;   - 数据集可在 [Flat'n'Fold 官网](https://cvas-ug.github.io/flat-n-fold) 下载。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Flat'n'Fold, a novel large-scale dataset for garment manipulationthat addresses critical gaps in existing datasets. Comprising 1,212 human and887 robot demonstrations of flattening and folding 44 unique garments across 8categories, Flat'n'Fold surpasses prior datasets in size, scope, and diversity.Our dataset uniquely captures the entire manipulation process from crumpled tofolded states, providing synchronized multi-view RGB-D images, point clouds,and action data, including hand or gripper positions and rotations. We quantifythe dataset's diversity and complexity compared to existing benchmarks and showthat our dataset features natural and diverse manipulations of real-worlddemonstrations of human and robot demonstrations in terms of visual and actioninformation. To showcase Flat'n'Fold's utility, we establish new benchmarks forgrasping point prediction and subtask decomposition. Our evaluation ofstate-of-the-art models on these tasks reveals significant room forimprovement. This underscores Flat'n'Fold's potential to drive advances inrobotic perception and manipulation of deformable objects. Our dataset can bedownloaded at https://cvas-ug.github.io/flat-n-fold</description>
      <author>example@mail.com (Lipeng Zhuang, Shiyu Fan, Yingdong Ru, Florent Audonnet, Paul Henderson, Gerardo Aragon-Camarasa)</author>
      <guid isPermaLink="false">2409.18297v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>LangSAMP: Language-Script Aware Multilingual Pretraining</title>
      <link>http://arxiv.org/abs/2409.18199v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 最近的多语言预训练语言模型（mPLMs）通常不使用语言嵌入，即分配给不同语言的可学习向量。&lt;h4&gt;2. 不使用语言嵌入的原因&lt;/h4&gt;   - **统一参数集**：mPLMs 期望在所有语言中使用单一统一的参数集。   - **无语言 ID 输入**：它们需要作为通用文本编码器正常工作，而不需要语言 ID 作为输入。&lt;h4&gt;3. 潜在问题&lt;/h4&gt;   - 移除语言嵌入增加了 token 嵌入编码所有语言特定信息的负担，可能会妨碍模型生成更具语言中立性的表示。&lt;h4&gt;4. 提出的方法&lt;/h4&gt;   - 提出了“语言-脚本感知多语言预训练”（LangSAMP），旨在通过引入语言和脚本嵌入来增强表示学习，同时保持简单的架构。&lt;h4&gt;5. 方法实现&lt;/h4&gt;   - 在将最终表示传递给语言建模头进行预测之前，将这些嵌入集成到变换器块的输出中。&lt;h4&gt;6. 应用与实验&lt;/h4&gt;   - 将 LangSAMP 应用于对 XLM-R 的持续预训练，使用覆盖超过 500 种语言的高度多语言语料库。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 得到的模型在性能上始终优于基线模型。&lt;h4&gt;8. 分析结果&lt;/h4&gt;   - 广泛分析表明，语言/脚本嵌入能够编码语言/脚本特定的信息，从而改善跨语言转移的源语言选择。&lt;h4&gt;9. 资源共享&lt;/h4&gt;   - 代码和模型已公开发布，链接为 [LangSAMP GitHub](https://github.com/cisnlp/LangSAMP)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent multilingual pretrained language models (mPLMs) often avoid usinglanguage embeddings -- learnable vectors assigned to different languages. Theseembeddings are discarded for two main reasons: (1) mPLMs are expected to have asingle, unified parameter set across all languages, and (2) they need tofunction seamlessly as universal text encoders without requiring language IDsas input. However, this removal increases the burden on token embeddings toencode all language-specific information, which may hinder the model's abilityto produce more language-neutral representations. To address this challenge, wepropose Language-Script Aware Multilingual Pretraining (LangSAMP), a methodthat incorporates both language and script embeddings to enhance representationlearning while maintaining a simple architecture. Specifically, we integratethese embeddings into the output of the transformer blocks before passing thefinal representations to the language modeling head for prediction. We applyLangSAMP to the continual pretraining of XLM-R on a highly multilingual corpuscovering more than 500 languages. The resulting model consistently outperformsthe baseline. Extensive analysis further shows that language/script embeddingsencode language/script-specific information, which improves the selection ofsource languages for crosslingual transfer. We make our code and modelspublicly available at \url{https://github.com/cisnlp/LangSAMP}.</description>
      <author>example@mail.com (Yihong Liu, Haotian Ye, Chunlan Ma, Mingyang Wang, Hinrich Schütze)</author>
      <guid isPermaLink="false">2409.18199v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Improved Approximation Algorithms for Relational Clustering</title>
      <link>http://arxiv.org/abs/2409.18498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 聚类在计算机科学中起着关键作用，促进了多个领域的数据分析和问题解决。&lt;h4&gt;2. 聚类的意义&lt;/h4&gt;   - 通过将大数据集划分为有意义的组，聚类揭示了数据中的隐藏结构和关系，帮助进行无监督学习、分类、异常检测和推荐系统等任务。&lt;h4&gt;3. 关系数据库中的挑战&lt;/h4&gt;   - 在关系数据库中，由于数据分布在多个表中，高效的聚类非常重要，但由于表连接的计算复杂性，这一过程充满挑战。&lt;h4&gt;4. 研究目的&lt;/h4&gt;   - 本文提出高效的算法，针对关系数据中的 $k$-中位数和 $k$-均值聚类，且不需要预先计算连接查询结果。&lt;h4&gt;5. 主要贡献&lt;/h4&gt;   - 对于关系 $k$-中位数聚类，提出了第一个高效的相对近似算法。   - 对于关系 $k$-均值聚类，提出的算法显著改善了已知算法的近似因子和运行时间，解决了较大的常数近似因子和高昂运行时间的问题。&lt;h4&gt;6. 算法复杂度&lt;/h4&gt;   - 针对给定的连接查询 $Q$ 和包含 $O(N)$ 元组的数据库实例 $D$，提出了随机化的 $(1+\varepsilon)\gamma$-近似算法，运行时间约为 $O(k^2N^{\mathsf{fhw}})+T_\gamma(k^2)$。&lt;h4&gt;7. 参数说明&lt;/h4&gt;   - 其中，$\varepsilon \in (0,1)$ 是用户决定的常数参数，$\mathsf{fhw}$ 是查询 $Q$ 的分数超树宽度，$\gamma$ 和 $T_\gamma(x)$ 分别是传统聚类算法在标准计算设置下的近似因子和运行时间。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Clustering plays a crucial role in computer science, facilitating dataanalysis and problem-solving across numerous fields. By partitioning largedatasets into meaningful groups, clustering reveals hidden structures andrelationships within the data, aiding tasks such as unsupervised learning,classification, anomaly detection, and recommendation systems. Particularly inrelational databases, where data is distributed across multiple tables,efficient clustering is essential yet challenging due to the computationalcomplexity of joining tables. This paper addresses this challenge byintroducing efficient algorithms for $k$-median and $k$-means clustering onrelational data without the need for pre-computing the join query results. Forthe relational $k$-median clustering, we propose the first efficient relativeapproximation algorithm. For the relational $k$-means clustering, our algorithmsignificantly improves both the approximation factor and the running time ofthe known relational $k$-means clustering algorithms, which suffer either fromlarge constant approximation factors, or expensive running time. Given a joinquery $Q$ and a database instance $D$ of $O(N)$ tuples, for both $k$-median and$k$-means clustering on the results of $Q$ on $D$, we propose randomized$(1+\varepsilon)\gamma$-approximation algorithms that run in roughly$O(k^2N^{\mathsf{fhw}})+T_\gamma(k^2)$ time, where $\varepsilon\in (0,1)$ is aconstant parameter decided by the user, $\mathsf{fhw}$ is the fractionalhyper-tree width of $Q$, while $\gamma$ and $T_\gamma(x)$ are respectively theapproximation factor and the running time of a traditional clustering algorithmin the standard computational setting over $x$ points.</description>
      <author>example@mail.com (Aryan Esmailpour, Stavros Sintos)</author>
      <guid isPermaLink="false">2409.18498v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>MATCH POLICY: A Simple Pipeline from Point Cloud Registration to Manipulation Policies</title>
      <link>http://arxiv.org/abs/2409.15517v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  project url: https://haojhuang.github.io/match_page/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 许多操控任务要求机器人根据对象之间的位置关系重新排列物体，这些任务可以通过一组刚体部件之间的相对姿态序列来描述。&lt;h4&gt;2. 提出的方法&lt;/h4&gt;   - 提出了 MATCH POLICY，这是一种简单但新颖的高精度拾取和放置任务解决方案。&lt;h4&gt;3. 方法原理&lt;/h4&gt;   - 该方法不是直接预测动作，而是将拾取和放置目标与存储的演示进行配准，将动作推断转化为点云配准任务。&lt;h4&gt;4. 无培训的实现&lt;/h4&gt;   - 这种方法使得在没有任何训练的情况下，实现复杂的操控策略成为可能。&lt;h4&gt;5. 任务设定&lt;/h4&gt;   - MATCH POLICY 针对高精度任务进行了关键帧设置设计。&lt;h4&gt;6. 样本效率与泛化性&lt;/h4&gt;   - 通过利用几何交互和任务对称性，MATCH POLICY 实现了极高的样本效率和对未见配置的良好泛化能力。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 在 RLBench 基准测试中，MATCH POLICY 在多个任务上表现出最先进的性能，并与多种强基线进行比较，同时在真实机器人上测试了六个任务。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many manipulation tasks require the robot to rearrange objects relative toone another. Such tasks can be described as a sequence of relative posesbetween parts of a set of rigid bodies. In this work, we propose MATCH POLICY,a simple but novel pipeline for solving high-precision pick and place tasks.Instead of predicting actions directly, our method registers the pick and placetargets to the stored demonstrations. This transfers action inference into apoint cloud registration task and enables us to realize nontrivial manipulationpolicies without any training. MATCH POLICY is designed to solve high-precisiontasks with a key-frame setting. By leveraging the geometric interaction and thesymmetries of the task, it achieves extremely high sample efficiency andgeneralizability to unseen configurations. We demonstrate its state-of-the-artperformance across various tasks on RLBench benchmark compared with severalstrong baselines and test it on a real robot with six tasks.</description>
      <author>example@mail.com (Haojie Huang, Haotian Liu, Dian Wang, Robin Walters, Robert Platt)</author>
      <guid isPermaLink="false">2409.15517v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning in $\ell_1$ Regularized Regression: Hyperparameter Selection Strategy based on Sharp Asymptotic Analysis</title>
      <link>http://arxiv.org/abs/2409.17704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 转移学习技术旨在利用多个相关数据集的信息，以提高针对目标数据集的预测质量。&lt;h4&gt;2. 应用领域&lt;/h4&gt;   - 这些方法已在高维稀疏回归的背景下得到应用，出现了一些基于 Lasso 的算法，例如 Trans-Lasso 和 Pretraining Lasso。&lt;h4&gt;3. 超参数选择问题&lt;/h4&gt;   - 这些算法需要统计学家选择控制来自相关数据集的信息转移程度和类型的超参数，但关于这些超参数选择策略及其对算法性能的影响尚未得到充分研究。&lt;h4&gt;4. 研究目的&lt;/h4&gt;   - 为了解决这一问题，本文通过使用复制方法进行渐近分析，深入研究了在高维设置下的算法行为。&lt;h4&gt;5. 主要发现&lt;/h4&gt;   - 研究表明，忽略转移到微调阶段的两种信息类型之一对泛化性能影响较小，表明超参数选择的工作可以显著减少。&lt;h4&gt;6. 理论与实证支持&lt;/h4&gt;   - 这些理论发现通过在 IMDb 数据集上的实际应用得到了实证支持。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning techniques aim to leverage information from multiplerelated datasets to enhance prediction quality against a target dataset. Suchmethods have been adopted in the context of high-dimensional sparse regression,and some Lasso-based algorithms have been invented: Trans-Lasso and PretrainingLasso are such examples. These algorithms require the statistician to selecthyperparameters that control the extent and type of information transfer fromrelated datasets. However, selection strategies for these hyperparameters, aswell as the impact of these choices on the algorithm's performance, have beenlargely unexplored. To address this, we conduct a thorough, precise study ofthe algorithm in a high-dimensional setting via an asymptotic analysis usingthe replica method. Our approach reveals a surprisingly simple behavior of thealgorithm: Ignoring one of the two types of information transferred to thefine-tuning stage has little effect on generalization performance, implyingthat efforts for hyperparameter selection can be significantly reduced. Ourtheoretical findings are also empirically supported by real-world applicationson the IMDb dataset.</description>
      <author>example@mail.com (Koki Okajima, Tomoyuki Obuchi)</author>
      <guid isPermaLink="false">2409.17704v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images</title>
      <link>http://arxiv.org/abs/2409.18364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 7 figures, accepted NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 在由于人类与物体或人类之间的交互造成严重遮挡的情况下，3D 人体形状重建是一个具有挑战性的问题。&lt;h4&gt;2. 现有模型的局限性&lt;/h4&gt;   - 参数模型（如 SMPL(-X)）能够表示整体人体形状，但仅限于穿着较少的情况。   - 基于隐式函数的方法从参数模型中提取特征，利用人体先验知识，能够捕捉几何细节（如衣物和头发），但在处理不对齐的参数模型和给定单个 RGB 图像时难以填补遮挡区域。&lt;h4&gt;3. 提出的新方法&lt;/h4&gt;   - 提出了一个新颖的管道，MHCDIFF（多假设条件点云扩散），它基于概率分布的点云扩散，旨在在遮挡情况下进行像素对齐的详细 3D 人体重建。&lt;h4&gt;4. 方法优势&lt;/h4&gt;   - 与之前的隐式函数方法相比，点云扩散模型能够捕捉全局一致的特征，以生成遮挡区域，并通过去噪过程纠正不对齐的 SMPL 网格。&lt;h4&gt;5. 核心机制&lt;/h4&gt;   - MHCDIFF 的核心在于从多个假设的 SMPL(-X) 网格中提取局部特征，并聚合这些特征以条件化扩散模型。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 在 CAPE 和 MultiHuman 数据集上的实验表明，所提方法在合成和真实遮挡情况下，优于基于 SMPL、隐式函数、点云扩散及其组合的各种最新技术（SOTA）方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D human shape reconstruction under severe occlusion due to human-object orhuman-human interaction is a challenging problem. Parametric models i.e.,SMPL(-X), which are based on the statistics across human shapes, can representwhole human body shapes but are limited to minimally-clothed human shapes.Implicit-function-based methods extract features from the parametric models toemploy prior knowledge of human bodies and can capture geometric details suchas clothing and hair. However, they often struggle to handle misalignedparametric models and inpaint occluded regions given a single RGB image. Inthis work, we propose a novel pipeline, MHCDIFF, Multi-hypotheses ConditionedPoint Cloud Diffusion, composed of point cloud diffusion conditioned onprobabilistic distributions for pixel-aligned detailed 3D human reconstructionunder occlusion. Compared to previous implicit-function-based methods, thepoint cloud diffusion model can capture the global consistent features togenerate the occluded regions, and the denoising process corrects themisaligned SMPL meshes. The core of MHCDIFF is extracting local features frommultiple hypothesized SMPL(-X) meshes and aggregating the set of features tocondition the diffusion model. In the experiments on CAPE and MultiHumandatasets, the proposed method outperforms various SOTA methods based on SMPL,implicit functions, point cloud diffusion, and their combined, under syntheticand real occlusions.</description>
      <author>example@mail.com (Donghwan Kim, Tae-Kyun Kim)</author>
      <guid isPermaLink="false">2409.18364v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Analysis of Spatial augmentation in Self-supervised models in the purview of training and test distributions</title>
      <link>http://arxiv.org/abs/2409.18228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in ECCV 2024 Workshop on Out-of-distribution generalization
  in computer vision (OOD-CV)&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究主题&lt;/h4&gt;   - 本文对自监督表示学习方法中常用的空间增强技术（包括对比和非对比方法）进行了实证研究，主要集中在随机裁剪和 cutout 技术。&lt;h4&gt;2. 贡献一&lt;/h4&gt;   - 将随机裁剪分解为两种独立的增强方式：重叠（overlap）和补丁（patch），并详细分析了重叠区域和补丁大小对下游任务准确性的影响。&lt;h4&gt;3. 贡献二&lt;/h4&gt;   - 针对 cutout 增强未能有效学习良好表示的原因提供了见解，与早期文献的报道相符。&lt;h4&gt;4. 贡献三&lt;/h4&gt;   - 基于上述分析，提出了一种基于距离的边距方法，用于不变性损失，旨在学习面向场景的表示，针对物体中心分布的下游任务。&lt;h4&gt;5. 方法效果&lt;/h4&gt;   - 证明了简单的边距设置（与场景中心图像中两个空间视图之间的像素距离成比例）能够改善学习到的表示。&lt;h4&gt;6. 研究意义&lt;/h4&gt;   - 本研究增进了对空间增强技术的理解，并探讨了训练增强与测试分布之间的领域差距对表现的影响。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present an empirical study of typical spatial augmentationtechniques used in self-supervised representation learning methods (bothcontrastive and non-contrastive), namely random crop and cutout. Ourcontributions are: (a) we dissociate random cropping into two separateaugmentations, overlap and patch, and provide a detailed analysis on the effectof area of overlap and patch size to the accuracy on down stream tasks. (b) Weoffer an insight into why cutout augmentation does not learn goodrepresentation, as reported in earlier literature. Finally, based on theseanalysis, (c) we propose a distance-based margin to the invariance loss forlearning scene-centric representations for the downstream task onobject-centric distribution, showing that as simple as a margin proportional tothe pixel distance between the two spatial views in the scence-centric imagescan improve the learned representation. Our study furthers the understanding ofthe spatial augmentations, and the effect of the domain-gap between thetraining augmentations and the test distribution.</description>
      <author>example@mail.com (Abhishek Jha, Tinne Tuytelaars)</author>
      <guid isPermaLink="false">2409.18228v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>VLMine: Long-Tail Data Mining with Vision Language Models</title>
      <link>http://arxiv.org/abs/2409.15486v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 确保在长尾样本上的稳健性能对于许多机器学习的实际应用（如自动驾驶）是一个重要问题。&lt;h4&gt;2. 研究重点&lt;/h4&gt;   - 关注在未标记数据中识别稀有样本的问题。&lt;h4&gt;3. 提出的方法&lt;/h4&gt;   - 提出了一种简单且可扩展的数据挖掘方法，利用大型视觉语言模型（VLM）中的知识。&lt;h4&gt;4. 方法细节&lt;/h4&gt;   - 使用 VLM 将图像内容总结为一组关键词，并根据关键词频率识别稀有样本。&lt;h4&gt;5. 比较分析&lt;/h4&gt;   - VLM 提供了与传统基于模型不确定性的方法不同的信号，以识别长尾样本。&lt;h4&gt;6. 信号整合&lt;/h4&gt;   - 提出了一个简单且通用的方法，整合来自多种挖掘算法的信号。&lt;h4&gt;7. 评估任务&lt;/h4&gt;   - 在两个不同的任务上评估了该方法：2D 图像分类（以类间变化为主要数据多样性来源）和 3D 目标检测（以类内变化为主要关注点）。&lt;h4&gt;8. 知识迁移&lt;/h4&gt;   - 通过检测任务，展示了从 2D 图像提取的知识可以迁移至 3D 领域。&lt;h4&gt;9. 实验结果&lt;/h4&gt;   - 实验结果表明，在多个代表性基准（如 ImageNet-LT、Places-LT 和 Waymo Open Dataset）上，与基线技术相比，性能提升显著（提升幅度在 10% 到 50% 之间）。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring robust performance on long-tail examples is an important problem formany real-world applications of machine learning, such as autonomous driving.This work focuses on the problem of identifying rare examples within a corpusof unlabeled data. We propose a simple and scalable data mining approach thatleverages the knowledge contained within a large vision language model (VLM).Our approach utilizes a VLM to summarize the content of an image into a set ofkeywords, and we identify rare examples based on keyword frequency. We findthat the VLM offers a distinct signal for identifying long-tail examples whencompared to conventional methods based on model uncertainty. Therefore, wepropose a simple and general approach for integrating signals from multiplemining algorithms. We evaluate the proposed method on two diverse tasks: 2Dimage classification, in which inter-class variation is the primary source ofdata diversity, and on 3D object detection, where intra-class variation is themain concern. Furthermore, through the detection task, we demonstrate that theknowledge extracted from 2D images is transferable to the 3D domain. Ourexperiments consistently show large improvements (between 10\% and 50\%) overthe baseline techniques on several representative benchmarks: ImageNet-LT,Places-LT, and the Waymo Open Dataset.</description>
      <author>example@mail.com (Mao Ye, Gregory P. Meyer, Zaiwei Zhang, Dennis Park, Siva Karthik Mustikovela, Yuning Chai, Eric M Wolff)</author>
      <guid isPermaLink="false">2409.15486v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Best Practices for Fitting Machine Learning Interatomic Potentials for Molten Salts: A Case Study Using NaCl-MgCl2</title>
      <link>http://arxiv.org/abs/2409.17869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 Pages, 9 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究目的&lt;/h4&gt;   - 开发了一种可组合传递的机器学习原子间势，用于研究 (NaCl)₁₋ₓ(MgCl₂)ₓ 熔融盐。&lt;h4&gt;2. 方法论&lt;/h4&gt;   - 使用原子簇扩展势（ACE）和 PBE-D3 方法，展示了通过仅使用 x={0, 1/3, 2/3, 1} 的数据来拟合一个稳健的势。&lt;h4&gt;3. 性能评估&lt;/h4&gt;   - 评估了多种密度泛函理论（DFT）方法的性能，包括 PBE-D3、PBE-D4、R2SCAN-D4 和 R2SCAN-rVV10，在单一的 NaCl 和 MgCl₂ 盐上进行测试。&lt;h4&gt;4. 结果分析&lt;/h4&gt;   - R2SCAN-D4 方法在计算 NaCl 和 MgCl₂ 的热物理性质时，相较于其他三种方法表现出整体上适度更好的准确性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.commatsci.2024.113409&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we developed a compositionally transferable machine learninginteratomic potential using atomic cluster expansion potential and PBE-D3method for (NaCl)1-x(MgCl2)x molten salt and we showed that it is possible tofit a robust potential for this pseudo-binary system by only including datafrom x={0, 1/3, 2/3, 1}. We also assessed the performance of several DFTmethods including PBE-D3, PBE-D4, R2SCAN-D4, and R2SCAN-rVV10 on unary NaCl andMgCl2 salts. Our results show that the R2SCAN-D4 method calculates thethermophysical properties of NaCl and MgCl2 with an overall modestly betteraccuracy compared to the other three methods.</description>
      <author>example@mail.com (Siamak Attarian, Chen Shen, Dane Morgan, Izabela Szlufarska)</author>
      <guid isPermaLink="false">2409.17869v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Reducing Semantic Ambiguity In Domain Adaptive Semantic Segmentation Via Probabilistic Prototypical Pixel Contrast</title>
      <link>http://arxiv.org/abs/2409.18543v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  revise&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 领域适应旨在减少源域与目标域之间的领域转移导致的模型性能下降。&lt;h4&gt;2. 现有方法的局限&lt;/h4&gt;   - 尽管通过结合认知学习与自我训练范式取得了良好表现，但在确定性嵌入部署时，因尺度、光照或重叠等因素导致的模糊场景仍然存在问题。&lt;h4&gt;3. 新方法提出&lt;/h4&gt;   - 提出了概率原型像素对比（PPPC），一个通用的适应框架，将每个像素嵌入建模为多元高斯分布的概率，以充分利用嵌入的不确定性，从而提高模型的表示质量。&lt;h4&gt;4. 原型推导&lt;/h4&gt;   - 从概率估计的后验概率中推导原型，帮助将决策边界推离模糊点。&lt;h4&gt;5. 计算方法优化&lt;/h4&gt;   - 采用高效的方法计算分布之间的相似性，消除采样和重参数化的需要，显著降低计算开销。&lt;h4&gt;6. 动态选择模糊区域&lt;/h4&gt;   - 在图像级别动态选择模糊区域，以扩大对比学习中涉及的边界点数量，有利于为每个类别建立精确的分布。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 大量实验表明，PPPC不仅在像素级别解决了模糊问题，产生了具有区分性的表示，还在合成到真实和昼夜适应任务中取得显著进展。&lt;h4&gt;8. 性能提升&lt;/h4&gt;   - 在最具挑战性的昼间到夜间适应场景中，PPPC超越了之前的最新技术（SOTA），提高了5.2%的mIoU，并在其他未见数据集上展现出更强的泛化能力。&lt;h4&gt;9. 代码与模型&lt;/h4&gt;   - 相关代码和模型可在 [GitHub](https://github.com/DarlingInTheSV/Probabilistic-Prototypical-Pixel-Contrast) 获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/darlinginthesv/probabilistic-prototypical-pixel-contrast&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain adaptation aims to reduce the model degradation on the target domaincaused by the domain shift between the source and target domains. Althoughencouraging performance has been achieved by combining cognitive learning withthe self-training paradigm, they suffer from ambiguous scenarios caused byscale, illumination, or overlapping when deploying deterministic embedding. Toaddress these issues, we propose probabilistic proto-typical pixel contrast(PPPC), a universal adaptation framework that models each pixel embedding as aprobability via multivariate Gaussian distribution to fully exploit theuncertainty within them, eventually improving the representation quality of themodel. In addition, we derive prototypes from probability estimation posteriorprobability estimation which helps to push the decision boundary away from theambiguity points. Moreover, we employ an efficient method to compute similaritybetween distributions, eliminating the need for sampling andreparameterization, thereby significantly reducing computational overhead.Further, we dynamically select the ambiguous crops at the image level toenlarge the number of boundary points involved in contrastive learning, whichbenefits the establishment of precise distributions for each category.Extensive experimentation demonstrates that PPPC not only helps to addressambiguity at the pixel level, yielding discriminative representations but alsoachieves significant improvements in both synthetic-to-real and day-to-nightadaptation tasks. It surpasses the previous state-of-the-art (SOTA) by +5.2%mIoU in the most challenging daytime-to-nighttime adaptation scenario,exhibiting stronger generalization on other unseen datasets. The code andmodels are available athttps://github.com/DarlingInTheSV/Probabilistic-Prototypical-Pixel-Contrast.</description>
      <author>example@mail.com (Xiaoke Hao, Shiyu Liu, Chuanbo Feng, Ye Zhu)</author>
      <guid isPermaLink="false">2409.18543v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>EvoFA: Evolvable Fast Adaptation for EEG Emotion Recognition</title>
      <link>http://arxiv.org/abs/2409.15733v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 基于脑电图（EEG）的情感识别因其准确性和客观性而受到广泛关注。&lt;h4&gt;2. 问题陈述&lt;/h4&gt;   - EEG信号的非平稳性导致信号分布随时间漂移，重用模型时会严重降低性能。&lt;h4&gt;3. 现有解决方案的局限&lt;/h4&gt;   - 虽然近年来提出了许多领域适应（DA）方法，但这些方法依赖大量目标数据进行校准，限制了其在离线场景中的应用，不适合实时应用。&lt;h4&gt;4. 新方法提出&lt;/h4&gt;   - 本文提出了可进化快速适应框架（EvoFA），这是一个专为EEG数据设计的在线适应框架。&lt;h4&gt;5. 方法整合&lt;/h4&gt;   - EvoFA有机整合了少样本学习（FSL）的快速适应性和领域适应（DA）的分布匹配，通过两阶段的泛化过程实现。&lt;h4&gt;6. 训练阶段&lt;/h4&gt;   - 在训练阶段，构建一个强泛化能力的基础元学习模型。&lt;h4&gt;7. 测试阶段&lt;/h4&gt;   - 在测试阶段，设计了一个可进化的元适应模块，迭代地将目标（测试）数据的边际分布与不断演变的源（训练）数据对齐。&lt;h4&gt;8. 在线性能提升&lt;/h4&gt;   - 该方法使模型能够学习测试数据相对于训练数据的演变趋势，从而提高在线测试性能。&lt;h4&gt;9. 实验结果&lt;/h4&gt;   - 实验结果表明，EvoFA在基本FSL方法和之前的在线方法上取得了显著改进。&lt;h4&gt;10. 应用前景&lt;/h4&gt;    - EvoFA的引入为EEG基础的情感识别在现实应用中的更广泛采用铺平了道路。&lt;h4&gt;11. 代码发布&lt;/h4&gt;    - 代码将在发表后发布。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electroencephalography (EEG)-based emotion recognition has gained significanttraction due to its accuracy and objectivity. However, the non-stationarynature of EEG signals leads to distribution drift over time, causing severeperformance degradation when the model is reused. While numerous domainadaptation (DA) approaches have been proposed in recent years to address thisissue, their reliance on large amounts of target data for calibration restrictsthem to offline scenarios, rendering them unsuitable for real-timeapplications. To address this challenge, this paper proposes Evolvable FastAdaptation (EvoFA), an online adaptive framework tailored for EEG data. EvoFAorganically integrates the rapid adaptation of Few-Shot Learning (FSL) and thedistribution matching of Domain Adaptation (DA) through a two-stagegeneralization process. During the training phase, a robust base meta-learningmodel is constructed for strong generalization. In the testing phase, adesigned evolvable meta-adaptation module iteratively aligns the marginaldistribution of target (testing) data with the evolving source (training) datawithin a model-agnostic meta-learning framework, enabling the model to learnthe evolving trends of testing data relative to training data and improvingonline testing performance. Experimental results demonstrate that EvoFAachieves significant improvements compared to the basic FSL method and previousonline methods. The introduction of EvoFA paves the way for broader adoption ofEEG-based emotion recognition in real-world applications. Our code will bereleased upon publication.</description>
      <author>example@mail.com (Ming Jin, Danni Zhang, Gangming Zhao, Changde Du, Jinpeng Li)</author>
      <guid isPermaLink="false">2409.15733v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Learning Beamforming in Cell-Free Massive MIMO ISAC Systems</title>
      <link>http://arxiv.org/abs/2409.18237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IEEE SPAWC 2024. Code files will be available on the
  Wireless Intelligence Lab website: https://www.wi-lab.net/research/&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 波束形成设计对集成感知与通信（ISAC）MIMO系统的高效运行至关重要。&lt;h4&gt;2. 挑战&lt;/h4&gt;   - 与集中式MIMO系统相比，细胞无处不在的大规模MIMO系统的ISAC波束形成设计更具挑战性，原因在于分布式大量接入点（AP）的额外复杂性。&lt;h4&gt;3. 方法论&lt;/h4&gt;   - 本文首先表明图神经网络（GNN）是一种适合的机器学习框架，用于解决上述问题。&lt;h4&gt;4. 模型开发&lt;/h4&gt;   - 开发了一种新型的异构GNN模型，灵感来源于细胞无处不在的ISAC MIMO系统的特定特征。&lt;h4&gt;5. 低复杂度扩展&lt;/h4&gt;   - 该模型支持细胞无处不在ISAC系统的低复杂度扩展，且在添加或移除接入点时不需要完全重新训练。&lt;h4&gt;6. 性能结果&lt;/h4&gt;   - 结果表明，所提出的架构能够实现近似最优的性能，并且适用于各种网络结构。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Beamforming design is critical for the efficient operation of integratedsensing and communication (ISAC) MIMO systems. ISAC beamforming design incell-free massive MIMO systems, compared to colocated MIMO systems, is morechallenging due to the additional complexity of the distributed large number ofaccess points (APs). To address this problem, this paper first shows that graphneural networks (GNNs) are a suitable machine learning framework. Then, itdevelops a novel heterogeneous GNN model inspired by the specificcharacteristics of the cell-free ISAC MIMO systems. This model enables thelow-complexity scaling of the cell-free ISAC system and does not require fullretraining when additional APs are added or removed. Our results show that theproposed architecture can achieve near-optimal performance, and applies well tovarious network structures.</description>
      <author>example@mail.com (Umut Demirhan, Ahmed Alkhateeb)</author>
      <guid isPermaLink="false">2409.18237v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Improving Visual Object Tracking through Visual Prompting</title>
      <link>http://arxiv.org/abs/2409.18901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted and to appear in IEEE Transactions on Multimedia&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 学习区分目标与周围干扰物的判别模型对于通用视觉目标跟踪至关重要。&lt;h4&gt;2. 挑战&lt;/h4&gt;   - 由于现有跟踪器的有限判别能力，动态目标表示适应干扰物变得困难。&lt;h4&gt;3. 方法介绍&lt;/h4&gt;   - 提出了用于通用视觉目标跟踪的新机制——视觉提示机制（PiVOT），旨在解决上述问题。&lt;h4&gt;4. 提示生成网络&lt;/h4&gt;   - PiVOT利用预训练的基础模型CLIP自动生成和优化视觉提示，从而实现基础模型知识向跟踪的转移。&lt;h4&gt;5. CLIP的优势&lt;/h4&gt;   - CLIP提供了广泛的类别级知识，而跟踪器则在特定实例数据上训练，能更好地识别独特的对象实例。&lt;h4&gt;6. 视觉提示编制&lt;/h4&gt;   - PiVOT首先编制一个视觉提示，突出潜在目标位置。&lt;h4&gt;7. 知识转移&lt;/h4&gt;   - PiVOT利用CLIP根据候选对象与参考模板之间的相似性来优化视觉提示。&lt;h4&gt;8. 优化效果&lt;/h4&gt;   - 一旦视觉提示被优化，它能更好地显示潜在目标位置，从而减少不相关的提示信息。&lt;h4&gt;9. 实例感知特征图&lt;/h4&gt;   - 通过视觉提示的指导，跟踪器可以生成改进的实例感知特征图，从而有效减少干扰物。&lt;h4&gt;10. 训练复杂性&lt;/h4&gt;    - 该方法在训练过程中不涉及CLIP，保持相同的训练复杂性，并保留预训练基础模型的泛化能力。&lt;h4&gt;11. 实验结果&lt;/h4&gt;    - 在多个基准测试中，PiVOT通过提出的提示方法能够抑制干扰对象并增强跟踪器性能。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning a discriminative model to distinguish a target from its surroundingdistractors is essential to generic visual object tracking. Dynamic targetrepresentation adaptation against distractors is challenging due to the limiteddiscriminative capabilities of prevailing trackers. We present a new visualPrompting mechanism for generic Visual Object Tracking (PiVOT) to address thisissue. PiVOT proposes a prompt generation network with the pre-trainedfoundation model CLIP to automatically generate and refine visual prompts,enabling the transfer of foundation model knowledge for tracking. While CLIPoffers broad category-level knowledge, the tracker, trained oninstance-specific data, excels at recognizing unique object instances. Thus,PiVOT first compiles a visual prompt highlighting potential target locations.To transfer the knowledge of CLIP to the tracker, PiVOT leverages CLIP torefine the visual prompt based on the similarities between candidate objectsand the reference templates across potential targets. Once the visual prompt isrefined, it can better highlight potential target locations, thereby reducingirrelevant prompt information. With the proposed prompting mechanism, thetracker can generate improved instance-aware feature maps through the guidanceof the visual prompt, thus effectively reducing distractors. The proposedmethod does not involve CLIP during training, thereby keeping the same trainingcomplexity and preserving the generalization capability of the pretrainedfoundation model. Extensive experiments across multiple benchmarks indicatethat PiVOT, using the proposed prompting method can suppress distractingobjects and enhance the tracker.</description>
      <author>example@mail.com (Shih-Fang Chen, Jun-Cheng Chen, I-Hong Jhuo, Yen-Yu Lin)</author>
      <guid isPermaLink="false">2409.18901v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Lidar Panoptic Segmentation in an Open World</title>
      <link>http://arxiv.org/abs/2409.14273v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Pre-print. Accepted in the International Journal of Computer Vision,
  19 Sept 2024. Code available at
  https://github.com/g-meghana-reddy/open-world-panoptic-segmentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 激光雷达全景分割（LPS）对安全部署自动驾驶车辆至关重要。&lt;h4&gt;2. LPS的目标&lt;/h4&gt;   - 识别和分割激光雷达点，基于预定义的语义类别词汇，包括可计数的物体类别（如行人和车辆）和无形区域类别（如植被和道路）。   - 需要对每个个体物体实例（如每一辆车）进行分割。&lt;h4&gt;3. 现实挑战&lt;/h4&gt;   - 当前LPS方法假设语义类别词汇在真实世界中是固定的，但实际上，类别本体通常会随着机器人遇到新的类实例而演变。&lt;h4&gt;4. 新研究方向&lt;/h4&gt;   - 本文研究“开放世界中的LPS”（LiPSOW），训练模型在具有预定义语义类别词汇的数据集上，并研究其在包含新实例的大型数据集上的泛化能力。&lt;h4&gt;5. 实验结论&lt;/h4&gt;   - 以往的方法专注于特定类别的实例分割，并在已知类别上取得了最先进的结果。   - 基于类别无关的自下而上分组的方法在未知类别上表现良好，但在已知类别上不如完全数据驱动的方法。&lt;h4&gt;6. 提出的新方法&lt;/h4&gt;   - 在类无关的点聚类基础上，采用分层方式对输入点云进行过分割，随后进行二元点段分类，类似于区域提议网络（Region Proposal Network）。   - 最终通过计算点段的加权层次树中的切割，获得点云分割，独立于语义分类。&lt;h4&gt;7. 研究成果&lt;/h4&gt;   - 该统一方法在已知和未知类别上均表现出色，提供了一种折中的解决方案。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s11263-024-02166-9&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/g-meghana-reddy/open-world-panoptic-segmentation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Addressing Lidar Panoptic Segmentation (LPS ) is crucial for safe deploymentof autonomous vehicles. LPS aims to recognize and segment lidar points w.r.t. apre-defined vocabulary of semantic classes, including thing classes ofcountable objects (e.g., pedestrians and vehicles) and stuff classes ofamorphous regions (e.g., vegetation and road). Importantly, LPS requiressegmenting individual thing instances (e.g., every single vehicle). Current LPSmethods make an unrealistic assumption that the semantic class vocabulary isfixed in the real open world, but in fact, class ontologies usually evolve overtime as robots encounter instances of novel classes that are considered to beunknowns w.r.t. the pre-defined class vocabulary. To address this unrealisticassumption, we study LPS in the Open World (LiPSOW): we train models on adataset with a pre-defined semantic class vocabulary and study theirgeneralization to a larger dataset where novel instances of thing and stuffclasses can appear. This experimental setting leads to interesting conclusions.While prior art train class-specific instance segmentation methods and obtainstate-of-the-art results on known classes, methods based on class-agnosticbottom-up grouping perform favorably on classes outside of the initial classvocabulary (i.e., unknown classes). Unfortunately, these methods do not performon-par with fully data-driven methods on known classes. Our work suggests amiddle ground: we perform class-agnostic point clustering and over-segment theinput cloud in a hierarchical fashion, followed by binary point segmentclassification, akin to Region Proposal Network [1]. We obtain the final pointcloud segmentation by computing a cut in the weighted hierarchical tree ofpoint segments, independently of semantic classification. Remarkably, thisunified approach leads to strong performance on both known and unknown classes.</description>
      <author>example@mail.com (Anirudh S Chakravarthy, Meghana Reddy Ganesina, Peiyun Hu, Laura Leal-Taixe, Shu Kong, Deva Ramanan, Aljosa Osep)</author>
      <guid isPermaLink="false">2409.14273v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>DMC-VB: A Benchmark for Representation Learning for Control with Visual Distractors</title>
      <link>http://arxiv.org/abs/2409.18330v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Datasets and Benchmarks Track. Dataset available at:
  https://github.com/google-deepmind/dmc_vision_benchmark&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 行为克隆和离线强化学习（RL）是构建通用智能体的有效方法，能够减少昂贵的在线学习需求。&lt;h4&gt;2. 问题陈述&lt;/h4&gt;   - 尽管在某些方面具备强大的泛化能力，智能体对背景或相机视角等控制无关因素的轻微视觉变化表现出脆弱性。&lt;h4&gt;3. 数据集介绍&lt;/h4&gt;   - 提出了DeepMind Control Visual Benchmark (DMC-VB)数据集，旨在评估离线RL智能体在视觉输入下解决连续控制任务的鲁棒性，尤其是在存在视觉干扰的情况下。&lt;h4&gt;4. 数据集特点&lt;/h4&gt;   - 结合了不同难度的运动和导航任务。   - 包含静态和动态的视觉变化。   - 考虑了不同技能水平策略生成的数据。   - 系统地返回状态和像素观察的配对。   - 数据集规模大约是以往工作的十倍。   - 包含隐藏目标的任务。&lt;h4&gt;5. 基准测试&lt;/h4&gt;   - 提出了三项基准测试，用于评估预训练的表示学习方法，并对几种新提出的方法进行了实验。&lt;h4&gt;6. 主要发现&lt;/h4&gt;   - 预训练的表示对DMC-VB上的策略学习没有帮助，且存在从像素观察学习到的策略与从状态学习到的策略之间的显著表示差距。   - 当专家数据有限时，策略学习可以从在（a）次优数据和（b）具有随机隐藏目标的任务上预训练的表示中受益。&lt;h4&gt;7. 资源提供&lt;/h4&gt;   - 数据集和基准代码可在GitHub上获取：[DMC Vision Benchmark](https://github.com/google-deepmind/dmc_vision_benchmark)。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/google-deepmind/dmc_vision_benchmark&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning from previously collected data via behavioral cloning or offlinereinforcement learning (RL) is a powerful recipe for scaling generalist agentsby avoiding the need for expensive online learning. Despite stronggeneralization in some respects, agents are often remarkably brittle to minorvisual variations in control-irrelevant factors such as the background orcamera viewpoint. In this paper, we present theDeepMind Control VisualBenchmark (DMC-VB), a dataset collected in the DeepMind Control Suite toevaluate the robustness of offline RL agents for solving continuous controltasks from visual input in the presence of visual distractors. In contrast toprior works, our dataset (a) combines locomotion and navigation tasks ofvarying difficulties, (b) includes static and dynamic visual variations, (c)considers data generated by policies with different skill levels, (d)systematically returns pairs of state and pixel observation, (e) is an order ofmagnitude larger, and (f) includes tasks with hidden goals. Accompanying ourdataset, we propose three benchmarks to evaluate representation learningmethods for pretraining, and carry out experiments on several recently proposedmethods. First, we find that pretrained representations do not help policylearning on DMC-VB, and we highlight a large representation gap betweenpolicies learned on pixel observations and on states. Second, we demonstratewhen expert data is limited, policy learning can benefit from representationspretrained on (a) suboptimal data, and (b) tasks with stochastic hidden goals.Our dataset and benchmark code to train and evaluate agents are available at:https://github.com/google-deepmind/dmc_vision_benchmark.</description>
      <author>example@mail.com (Joseph Ortiz, Antoine Dedieu, Wolfgang Lehrach, Swaroop Guntupalli, Carter Wendelken, Ahmad Humayun, Guangyao Zhou, Sivaramakrishnan Swaminathan, Miguel Lázaro-Gredilla, Kevin Murphy)</author>
      <guid isPermaLink="false">2409.18330v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Jump Diffusion-Informed Neural Networks with Transfer Learning for Accurate American Option Pricing under Data Scarcity</title>
      <link>http://arxiv.org/abs/2409.18168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 期权定价模型在金融数学和风险管理中至关重要，近年来通过人工智能方法得到了广泛研究和进展。&lt;h4&gt;2. 研究挑战&lt;/h4&gt;   - 美式期权定价面临挑战，主要由于确定最佳行使时间和建模由随机路径导致的非线性收益的复杂性。&lt;h4&gt;3. 现有问题&lt;/h4&gt;   - 目前广泛使用的布莱克-肖尔斯公式在混合模型中的应用无法准确捕捉价格过程中的不连续性，限制了模型性能，特别是在数据稀缺的情况下。&lt;h4&gt;4. 研究目标&lt;/h4&gt;   - 本研究提出一个全面的美式期权定价框架，由六个相互关联的模块组成，结合非线性优化算法、分析和数值模型以及神经网络，以提高定价性能。&lt;h4&gt;5. 数据稀缺处理&lt;/h4&gt;   - 为了应对数据稀缺的挑战，框架集成了通过数值数据增强的迁移学习以及一个受物理约束的跳跃扩散过程信息的神经网络，以捕捉对数收益分布的尖峰厚尾特性（leptokurtosis）。&lt;h4&gt;6. 训练效率提升&lt;/h4&gt;   - 设计了一个使用贝叶斯优化的预热期，以提供最佳的数据损失和物理损失系数，从而提高训练效率。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 六个案例研究的实验结果表明，该框架在准确性、收敛性、物理有效性和泛化能力方面表现良好。&lt;h4&gt;8. 模型优势&lt;/h4&gt;   - 提出的模型在定价深度虚值期权方面表现优越。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Option pricing models, essential in financial mathematics and riskmanagement, have been extensively studied and recently advanced by AImethodologies. However, American option pricing remains challenging due to thecomplexity of determining optimal exercise times and modeling non-linearpayoffs resulting from stochastic paths. Moreover, the prevalent use of theBlack-Scholes formula in hybrid models fails to accurately capture thediscontinuity in the price process, limiting model performance, especiallyunder scarce data conditions. To address these issues, this study presents acomprehensive framework for American option pricing consisting of sixinterrelated modules, which combine nonlinear optimization algorithms,analytical and numerical models, and neural networks to improve pricingperformance. Additionally, to handle the scarce data challenge, this frameworkintegrates the transfer learning through numerical data augmentation and aphysically constrained, jump diffusion process-informed neural network tocapture the leptokurtosis of the log return distribution. To increase trainingefficiency, a warm-up period using Bayesian optimization is designed to provideoptimal data loss and physical loss coefficients. Experimental results of sixcase studies demonstrate the accuracy, convergence, physical effectiveness, andgeneralization of the framework. Moreover, the proposed model shows superiorperformance in pricing deep out-of-the-money options.</description>
      <author>example@mail.com (Qiguo Sun, Hanyue Huang, XiBei Yang, Yuwei Zhang)</author>
      <guid isPermaLink="false">2409.18168v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Understanding the Benefits of SimCLR Pre-Training in Two-Layer Convolutional Neural Networks</title>
      <link>http://arxiv.org/abs/2409.18685v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  65 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - SimCLR 是一种广泛使用的对比学习方法，主要用于视觉任务。&lt;h4&gt;2. 方法概述&lt;/h4&gt;   - SimCLR 在大量未标记数据上预训练深度神经网络，通过教模型区分正负增强图像对。&lt;h4&gt;3. 预训练效果&lt;/h4&gt;   - 该方法旨在使深度神经网络学习高效表示，从而提升未来监督微调的性能。&lt;h4&gt;4. 理论理解不足&lt;/h4&gt;   - 尽管 SimCLR 有效，但对其底层机制的理论理解仍然有限。&lt;h4&gt;5. 研究目标&lt;/h4&gt;   - 本文通过案例研究的方式，理论性地介绍 SimCLR 方法。&lt;h4&gt;6. 实验设置&lt;/h4&gt;   - 考虑训练一个两层卷积神经网络（CNN），以学习一个玩具图像数据模型。&lt;h4&gt;7. 主要发现&lt;/h4&gt;   - 在标记数据数量满足特定条件下，SimCLR 预训练结合监督微调能够实现几乎最优的测试损失。&lt;h4&gt;8. 标签复杂性&lt;/h4&gt;   - 与直接在监督数据上训练相比，SimCLR 预训练所需的标签复杂性明显较低。&lt;h4&gt;9. 研究贡献&lt;/h4&gt;   - 本分析揭示了 SimCLR 在使用更少标签进行学习时的优势。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; SimCLR is one of the most popular contrastive learning methods for visiontasks. It pre-trains deep neural networks based on a large amount of unlabeleddata by teaching the model to distinguish between positive and negative pairsof augmented images. It is believed that SimCLR can pre-train a deep neuralnetwork to learn efficient representations that can lead to a betterperformance of future supervised fine-tuning. Despite its effectiveness, ourtheoretical understanding of the underlying mechanisms of SimCLR is stilllimited. In this paper, we theoretically introduce a case study of the SimCLRmethod. Specifically, we consider training a two-layer convolutional neuralnetwork (CNN) to learn a toy image data model. We show that, under certainconditions on the number of labeled data, SimCLR pre-training combined withsupervised fine-tuning achieves almost optimal test loss. Notably, the labelcomplexity for SimCLR pre-training is far less demanding compared to directtraining on supervised data. Our analysis sheds light on the benefits of SimCLRin learning with fewer labels.</description>
      <author>example@mail.com (Han Zhang, Yuan Cao)</author>
      <guid isPermaLink="false">2409.18685v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Causality-based Subject and Task Fingerprints using fMRI Time-series Data</title>
      <link>http://arxiv.org/abs/2409.18298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 最近，系统神经科学因其揭示多尺度脑网络复杂关系的能力而重新引起关注。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 验证基于因果关系的方法在fMRI指纹识别中的可行性和有效性。&lt;h4&gt;3. 方法论&lt;/h4&gt;   - 提出一种创新的方法，利用脑的因果动态活动识别个体的独特认知模式（如个体指纹）和fMRI任务（如任务指纹）。&lt;h4&gt;4. 关键创新&lt;/h4&gt;   - 发展了一个双时间尺度线性状态空间模型，从个体的fMRI时间序列数据中提取“时空”（即因果）特征。&lt;h4&gt;5. 概念引入&lt;/h4&gt;   - 在本文中，首次提出并量化了“因果指纹”这一概念，与其他指纹研究不同，该方法从因果关系角度量化指纹。&lt;h4&gt;6. 技术实现&lt;/h4&gt;   - 结合模态分解和投影方法进行个体识别，并使用基于图神经网络（GNN）模型进行任务识别。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 实验结果及与非因果方法的比较证明了所提方法的有效性。&lt;h4&gt;8. 可视化与生物相关性&lt;/h4&gt;   - 可视化得到的因果特征，并讨论其在现有脑功能理解中的生物学相关性。&lt;h4&gt;9. 未来研究方向&lt;/h4&gt;   - 本研究为因果指纹的进一步研究铺平了道路，潜在应用于健康对照和神经退行性疾病。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, there has been a revived interest in system neuroscience causationmodels due to their unique capability to unravel complex relationships inmulti-scale brain networks. In this paper, our goal is to verify thefeasibility and effectiveness of using a causality-based approach for fMRIfingerprinting. Specifically, we propose an innovative method that utilizes thecausal dynamics activities of the brain to identify the unique cognitivepatterns of individuals (e.g., subject fingerprint) and fMRI tasks (e.g., taskfingerprint). The key novelty of our approach stems from the development of atwo-timescale linear state-space model to extract 'spatio-temporal' (akacausal) signatures from an individual's fMRI time series data. To the best ofour knowledge, we pioneer and subsequently quantify, in this paper, the conceptof 'causal fingerprint.' Our method is well-separated from other fingerprintstudies as we quantify fingerprints from a cause-and-effect perspective, whichare then incorporated with a modal decomposition and projection method toperform subject identification and a GNN-based (Graph Neural Network) model toperform task identification. Finally, we show that the experimental results andcomparisons with non-causality-based methods demonstrate the effectiveness ofthe proposed methods. We visualize the obtained causal signatures and discusstheir biological relevance in light of the existing understanding of brainfunctionalities. Collectively, our work paves the way for further studies oncausal fingerprints with potential applications in both healthy controls andneurodegenerative diseases.</description>
      <author>example@mail.com (Dachuan Song, Li Shen, Duy Duong-Tran, Xuan Wang)</author>
      <guid isPermaLink="false">2409.18298v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Cognition</title>
      <link>http://arxiv.org/abs/2409.18624v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 无监督学习方法受到认知模型的启发，主要集中在数学空间中对样本进行聚类。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 提出一种基于原始特征的无监督学习方法，旨在用于决策制定，并受到新型认知模型的启发。&lt;h4&gt;3. 方法论&lt;/h4&gt;   - 该方法采用以表示为中心的方式，构建输入空间，形成一种分布式的层次结构，且对输入类型不敏感。&lt;h4&gt;4. 比较分析&lt;/h4&gt;   - 将该方法与当前无监督学习分类的最先进技术以及癌症类型分类的最先进技术进行了比较。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 实验结果显示，该方法在性能上优于之前的最先进技术。&lt;h4&gt;6. 认知特性评估&lt;/h4&gt;   - 评估了该方法的一些类认知特性，发现其不仅超越了比较算法（包括监督学习算法），还展示了更具认知特征的行为。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised learning methods have a soft inspiration in cognition models. Tothis day, the most successful unsupervised learning methods revolve aroundclustering samples in a mathematical space. In this paper we propose astate-of-the-art primitive-based unsupervised learning approach fordecision-making inspired by novel cognition models. This representation-centricapproach models the input space constructively as a distributed hierarchicalstructure in an input-agnostic way. We compared our approach with currentstate-of-the-art in unsupervised learning classification, and with currentstate-of-the-art in cancer type classification. We show how our proposaloutperforms previous state-of-the-art. We also evaluate some cognition-likeproperties of our proposal where it not only outperforms the comparedalgorithms (even supervised learning ones), but it also shows a different, morecognition-like, behaviour.</description>
      <author>example@mail.com (Alfredo Ibias, Hector Antona, Guillem Ramirez-Miranda, Enric Guinovart, Eduard Alarcon)</author>
      <guid isPermaLink="false">2409.18624v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>KISS-Matcher: Fast and Robust Point Cloud Registration Revisited</title>
      <link>http://arxiv.org/abs/2409.15615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 全球点云注册系统在各个方面已取得显著进展，但许多研究集中于特定组件，如特征提取、图论剪枝或位姿求解器。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 本文提供了一种整体视角，开发了一个开源且多功能的C++库，用于点云注册，称为**KISS-Matcher**。&lt;h4&gt;3. 创新方法&lt;/h4&gt;   - 引入了一种新颖的特征检测器**Faster-PFH**，改进了经典的快速点特征直方图（FPFH）。   - 采用基于$k$-core的图论剪枝技术，以降低拒绝离群点对应关系的时间复杂度。&lt;h4&gt;4. 系统集成&lt;/h4&gt;   - 将这些模块整合成一个完整、用户友好且即用的处理流程。&lt;h4&gt;5. 实验验证&lt;/h4&gt;   - 通过广泛的实验验证，KISS-Matcher展现出卓越的可扩展性和广泛的适用性。   - 相比于最先进的抗离群点注册流程，KISS-Matcher在保持准确性的同时实现了显著的速度提升。&lt;h4&gt;6. 资源共享&lt;/h4&gt;   - 代码将公开在[GitHub](https://github.com/MIT-SPARK/KISS-Matcher)上。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mit-spark/kiss-matcher&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While global point cloud registration systems have advanced significantly inall aspects, many studies have focused on specific components, such as featureextraction, graph-theoretic pruning, or pose solvers. In this paper, we take aholistic view on the registration problem and develop an open-source andversatile C++ library for point cloud registration, called\textit{KISS-Matcher}. KISS-Matcher combines a novel feature detector,\textit{Faster-PFH}, that improves over the classical fast point featurehistogram (FPFH). Moreover, it adopts a $k$-core-based graph-theoretic pruningto reduce the time complexity of rejecting outlier correspondences. Finally, itcombines these modules in a complete, user-friendly, and ready-to-use pipeline.As verified by extensive experiments, KISS-Matcher has superior scalability andbroad applicability, achieving a substantial speed-up compared tostate-of-the-art outlier-robust registration pipelines while preservingaccuracy. Our code will be available at\href{https://github.com/MIT-SPARK/KISS-Matcher}{\texttt{https://github.com/MIT-SPARK/KISS-Matcher}}.</description>
      <author>example@mail.com (Hyungtae Lim, Daebeom Kim, Gunhee Shin, Jingnan Shi, Ignacio Vizzo, Hyun Myung, Jaesik Park, and Luca Carlone)</author>
      <guid isPermaLink="false">2409.15615v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Review of Digital Asset Development with Graph Neural Network Unlearning</title>
      <link>http://arxiv.org/abs/2409.18455v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着数字资产快速发展的环境，数据隐私和合规性需求日益增强。&lt;h4&gt;2. 研究目的&lt;/h4&gt;   - 本文探讨图神经网络（GNNs）在数字资产管理中的关键作用，并引入专门针对GNN架构的创新去学习技术。&lt;h4&gt;3. 去学习策略分类&lt;/h4&gt;   - 将去学习策略分为两大类：     - **数据驱动近似**：通过操控图结构隔离并移除特定节点的影响。     - **模型驱动近似**：修改GNN的内部参数和架构。&lt;h4&gt;4. 应用场景&lt;/h4&gt;   - 讨论了这些去学习方法在多个应用中的适用性，包括：     - 欺诈检测     - 风险评估     - 代币关系预测     - 去中心化治理&lt;h4&gt;5. 挑战分析&lt;/h4&gt;   - 讨论了在实时金融应用中，平衡模型性能与数据去学习要求的挑战。&lt;h4&gt;6. 提出的混合方法&lt;/h4&gt;   - 提出了结合两种去学习策略优点的混合方法，以提升GNN在数字资产生态系统中的效率和有效性。&lt;h4&gt;7. 研究贡献&lt;/h4&gt;   - 本文旨在提供一个全面的框架，以理解和实施GNN去学习技术，为数字资产领域中机器学习的安全和合规部署铺平道路。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the rapidly evolving landscape of digital assets, the imperative forrobust data privacy and compliance with regulatory frameworks has intensified.This paper investigates the critical role of Graph Neural Networks (GNNs) inthe management of digital assets and introduces innovative unlearningtechniques specifically tailored to GNN architectures. We categorize unlearningstrategies into two primary classes: data-driven approximation, whichmanipulates the graph structure to isolate and remove the influence of specificnodes, and model-driven approximation, which modifies the internal parametersand architecture of the GNN itself. By examining recent advancements in theseunlearning methodologies, we highlight their applicability in various usecases, including fraud detection, risk assessment, token relationshipprediction, and decentralized governance. We discuss the challenges inherent inbalancing model performance with the requirements for data unlearning,particularly in the context of real-time financial applications. Furthermore,we propose a hybrid approach that combines the strengths of both unlearningstrategies to enhance the efficiency and effectiveness of GNNs in digital assetecosystems. Ultimately, this paper aims to provide a comprehensive frameworkfor understanding and implementing GNN unlearning techniques, paving the wayfor secure and compliant deployment of machine learning in the digital assetdomain.</description>
      <author>example@mail.com (Zara Lisbon)</author>
      <guid isPermaLink="false">2409.18455v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Reducing and Exploiting Data Augmentation Noise through Meta Reweighting Contrastive Learning for Text Classification</title>
      <link>http://arxiv.org/abs/2409.17474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE BigData 2021&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 数据增强在解决数据稀缺问题和提高模型泛化能力方面表现出色，但增强数据的质量可能存在差异，尤其是与原始数据相比。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 旨在提升深度学习模型在文本分类任务中使用增强数据样本的性能。&lt;h4&gt;3. 框架简介&lt;/h4&gt;   - 提出了一个新颖的框架，结合了元学习和对比学习技术，以重新加权增强样本并根据其质量优化特征表示。&lt;h4&gt;4. 算法设计&lt;/h4&gt;   - 框架中提出了新的权重依赖的入队和出队算法，有效利用增强样本的权重/质量信息。&lt;h4&gt;5. 实验设置&lt;/h4&gt;   - 通过实验验证了该框架与现有深度学习模型（如RoBERTa-base和Text-CNN）及增强技术（如Wordnet和Easydata）的合理合作。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 在七个GLUE基准数据集上，该框架在Text-CNN编码器上实现了平均1.6%、最高4.3%的绝对改进；在RoBERTa-base编码器上实现了平均1.4%、最高4.4%的绝对改进，相较于最佳基线。&lt;h4&gt;7. 分析与贡献&lt;/h4&gt;   - 进行了框架设计的深入分析，揭示了网络组件的非平凡贡献。&lt;h4&gt;8. 可复现性&lt;/h4&gt;   - 提供了公开代码，以便于更好的研究复现。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/BigData52589.2021.9671510&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data augmentation has shown its effectiveness in resolving the data-hungryproblem and improving model's generalization ability. However, the quality ofaugmented data can be varied, especially compared with the raw/original data.To boost deep learning models' performance given augmented data/samples in textclassification tasks, we propose a novel framework, which leverages both metalearning and contrastive learning techniques as parts of our design forreweighting the augmented samples and refining their feature representationsbased on their quality. As part of the framework, we propose novelweight-dependent enqueue and dequeue algorithms to utilize augmented samples'weight/quality information effectively. Through experiments, we show that ourframework can reasonably cooperate with existing deep learning models (e.g.,RoBERTa-base and Text-CNN) and augmentation techniques (e.g., Wordnet andEasydata) for specific supervised learning tasks. Experiment results show thatour framework achieves an average of 1.6%, up to 4.3% absolute improvement onText-CNN encoders and an average of 1.4%, up to 4.4% absolute improvement onRoBERTa-base encoders on seven GLUE benchmark datasets compared with the bestbaseline. We present an indepth analysis of our framework design, revealing thenon-trivial contributions of our network components. Our code is publiclyavailable for better reproducibility.</description>
      <author>example@mail.com (Guanyi Mou, Yichuan Li, Kyumin Lee)</author>
      <guid isPermaLink="false">2409.17474v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Underground Mapping and Localization Based on Ground-Penetrating Radar</title>
      <link>http://arxiv.org/abs/2409.16446v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 基于深度神经网络的3D物体重建近年来受到越来越多的关注，但地下物体的3D重建仍然面临挑战。&lt;h4&gt;2. 工具介绍&lt;/h4&gt;   - 地面穿透雷达（GPR）是检测和定位地下物体（如植物根系和管道）的一种强大且广泛使用的工具，具有成本效益和不断发展的技术。&lt;h4&gt;3. 方法概述&lt;/h4&gt;   - 本文提出了一种基于深度卷积神经网络的抛物线信号检测网络，利用来自GPR传感器的B扫描图像。&lt;h4&gt;4. 关键点检测&lt;/h4&gt;   - 检测到的关键点有助于准确拟合抛物线曲线，用于将原始GPR B扫描图像解释为物体模型的横截面。&lt;h4&gt;5. 多任务点云网络&lt;/h4&gt;   - 设计了一个多任务点云网络，能够同时执行点云分割和补全，从而填补稀疏的点云图。&lt;h4&gt;6. 未知位置处理&lt;/h4&gt;   - 对于未知位置，可以使用GPR A扫描数据与构建的地图中的对应A扫描数据进行匹配，以确定位置，验证模型构建地图的准确性。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 实验结果展示了该方法的有效性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D object reconstruction based on deep neural networks has gained increasingattention in recent years. However, 3D reconstruction of underground objects togenerate point cloud maps remains a challenge. Ground Penetrating Radar (GPR)is one of the most powerful and extensively used tools for detecting andlocating underground objects such as plant root systems and pipelines, with itscost-effectiveness and continuously evolving technology. This paper introducesa parabolic signal detection network based on deep convolutional neuralnetworks, utilizing B-scan images from GPR sensors. The detected keypoints canaid in accurately fitting parabolic curves used to interpret the original GPRB-scan images as cross-sections of the object model. Additionally, a multi-taskpoint cloud network was designed to perform both point cloud segmentation andcompletion simultaneously, filling in sparse point cloud maps. For unknownlocations, GPR A-scan data can be used to match corresponding A-scan data inthe constructed map, pinpointing the position to verify the accuracy of the mapconstruction by the model. Experimental results demonstrate the effectivenessof our method.</description>
      <author>example@mail.com (Jinchang Zhang, Guoyu Lu)</author>
      <guid isPermaLink="false">2409.16446v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>DRL-STNet: Unsupervised Domain Adaptation for Cross-modality Medical Image Segmentation via Disentangled Representation Learning</title>
      <link>http://arxiv.org/abs/2409.18340v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2024 Challenge, FLARE Challenge, Unsupervised domain
  adaptation, Organ segmentation, Feature disentanglement, Self-training&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 无监督领域适应（UDA）在医学图像分割中至关重要，尤其是在跨模态数据场景中。&lt;h4&gt;2. 研究目的&lt;/h4&gt;   - UDA旨在将知识从标记的源域转移到未标记的目标域，从而减少对大量人工标注的依赖。&lt;h4&gt;3. 提出的框架&lt;/h4&gt;   - 本文提出了DRL-STNet，这是一种新颖的跨模态医学图像分割框架，结合了生成对抗网络（GANs）、解耦表示学习（DRL）和自我训练（ST）。&lt;h4&gt;4. 方法论&lt;/h4&gt;   - 该方法在GAN中利用DRL将源域图像转换为目标模态的图像。   - 初始阶段使用这些转换后的图像和相应的源标签训练分割模型，然后通过合成图像和真实图像的组合进行迭代微调，使用伪标签和真实标签。&lt;h4&gt;5. 实验结果&lt;/h4&gt;   - 在FLARE挑战数据集上，所提出的框架在腹部器官分割任务中表现优异。   - 在Dice相似系数上比现有最先进的方法提高了11.4%，在归一化表面Dice指标上提高了13.1%，分别达到74.21%和80.69%的得分。&lt;h4&gt;6. 性能指标&lt;/h4&gt;   - 平均运行时间为41秒，GPU内存-时间曲线下的面积为11,292 MB。&lt;h4&gt;7. 结论&lt;/h4&gt;   - 这些结果表明DRL-STNet在增强跨模态医学图像分割任务方面具有潜力。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised domain adaptation (UDA) is essential for medical imagesegmentation, especially in cross-modality data scenarios. UDA aims to transferknowledge from a labeled source domain to an unlabeled target domain, therebyreducing the dependency on extensive manual annotations. This paper presentsDRL-STNet, a novel framework for cross-modality medical image segmentation thatleverages generative adversarial networks (GANs), disentangled representationlearning (DRL), and self-training (ST). Our method leverages DRL within a GANto translate images from the source to the target modality. Then, thesegmentation model is initially trained with these translated images andcorresponding source labels and then fine-tuned iteratively using a combinationof synthetic and real images with pseudo-labels and real labels. The proposedframework exhibits superior performance in abdominal organ segmentation on theFLARE challenge dataset, surpassing state-of-the-art methods by 11.4% in theDice similarity coefficient and by 13.1% in the Normalized Surface Dice metric,achieving scores of 74.21% and 80.69%, respectively. The average running timeis 41 seconds, and the area under the GPU memory-time curve is 11,292 MB. Theseresults indicate the potential of DRL-STNet for enhancing cross-modalitymedical image segmentation tasks.</description>
      <author>example@mail.com (Hui Lin, Florian Schiffers, Santiago López-Tapia, Neda Tavakoli, Daniel Kim, Aggelos K. Katsaggelos)</author>
      <guid isPermaLink="false">2409.18340v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Social Media Bot Policies: Evaluating Passive and Active Enforcement</title>
      <link>http://arxiv.org/abs/2409.18931v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 多模态基础模型（MFM）的出现为社交媒体平台的变革带来了重大潜力，同时也引发了安全和伦理方面的担忧。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 本文旨在评估主要社交媒体平台的安全协议在减轻MFM机器人部署方面的有效性。&lt;h4&gt;3. 研究对象&lt;/h4&gt;   - 检查了八个流行社交媒体平台的机器人和内容政策，包括X（前身为Twitter）、Instagram、Facebook、Threads、TikTok、Mastodon、Reddit和LinkedIn。&lt;h4&gt;4. 方法论&lt;/h4&gt;   - 使用Selenium开发了一个网络机器人，测试这些平台的机器人部署和AI生成内容的政策及其执行机制。&lt;h4&gt;5. 研究发现&lt;/h4&gt;   - 结果显示，这些平台当前的执行机制存在显著漏洞。&lt;h4&gt;6. 政策执行问题&lt;/h4&gt;   - 尽管所有平台都有明确的反机器人活动政策，但未能检测和阻止MFM机器人的操作。&lt;h4&gt;7. 安全隐患&lt;/h4&gt;   - 这一发现揭示了社交媒体平台在安全措施方面的关键缺口，表明恶意行为者可能利用这些弱点传播虚假信息、实施诈骗或操纵用户。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of Multimodal Foundation Models (MFMs) holds significantpromise for transforming social media platforms. However, this advancement alsointroduces substantial security and ethical concerns, as it may facilitatemalicious actors in the exploitation of online users. We aim to evaluate thestrength of security protocols on prominent social media platforms inmitigating the deployment of MFM bots. We examined the bot and content policiesof eight popular social media platforms: X (formerly Twitter), Instagram,Facebook, Threads, TikTok, Mastodon, Reddit, and LinkedIn. Using Selenium, wedeveloped a web bot to test bot deployment and AI-generated content policiesand their enforcement mechanisms. Our findings indicate significantvulnerabilities within the current enforcement mechanisms of these platforms.Despite having explicit policies against bot activity, all platforms failed todetect and prevent the operation of our MFM bots. This finding reveals acritical gap in the security measures employed by these social media platforms,underscoring the potential for malicious actors to exploit these weaknesses todisseminate misinformation, commit fraud, or manipulate users.</description>
      <author>example@mail.com (Kristina Radivojevic, Christopher McAleer, Catrell Conley, Cormac Kennedy, Paul Brenner)</author>
      <guid isPermaLink="false">2409.18931v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Automated Segmentation and Analysis of Microscopy Images of Laser Powder Bed Fusion Melt Tracks</title>
      <link>http://arxiv.org/abs/2409.18326v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 随着金属增材制造（AM）应用的增加，研究人员和从业者开始采用数据驱动的方法来优化打印条件。&lt;h4&gt;2. 数据的重要性&lt;/h4&gt;   - 融化轨迹的横截面图像提供了调节工艺参数、开发参数缩放数据和识别缺陷的重要信息。&lt;h4&gt;3. 研究目标&lt;/h4&gt;   - 本文提出了一种图像分割神经网络，能够自动识别和测量横截面图像中的融化轨迹尺寸。&lt;h4&gt;4. 方法论&lt;/h4&gt;   - 使用U-Net架构，基于62张来自不同实验室、机器和材料的预标记图像的数据集进行训练，并结合图像增强技术。&lt;h4&gt;5. 模型性能&lt;/h4&gt;   - 经过合适调优的神经网络超参数（如批量大小和学习率）后，模型在分类任务中的准确率超过99%，F1分数超过90%。&lt;h4&gt;6. 鲁棒性&lt;/h4&gt;   - 神经网络在不同用户拍摄的图像、不同机器打印的图像及采用不同显微镜获取的图像上表现出良好的鲁棒性。&lt;h4&gt;7. 后处理模块&lt;/h4&gt;   - 该研究还包含一个后处理模块，用于提取融化池的高度、宽度以及润湿角。&lt;h4&gt;8. 未来方向&lt;/h4&gt;   - 讨论了提高模型性能的机会和转移学习的途径，例如扩展到其他增材制造工艺（如定向能量沉积）。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing adoption of metal additive manufacturing (AM),researchers and practitioners are turning to data-driven approaches to optimiseprinting conditions. Cross-sectional images of melt tracks provide valuableinformation for tuning process parameters, developing parameter scaling data,and identifying defects. Here we present an image segmentation neural networkthat automatically identifies and measures melt track dimensions from across-section image. We use a U-Net architecture to train on a data set of 62pre-labelled images obtained from different labs, machines, and materialscoupled with image augmentation. When neural network hyperparameters such asbatch size and learning rate are properly tuned, the learned model shows anaccuracy for classification of over 99% and an F1 score over 90%. The neuralnetwork exhibits robustness when tested on images captured by various users,printed on different machines, and acquired using different microscopes. Apost-processing module extracts the height and width of the melt pool, and thewetting angles. We discuss opportunities to improve model performance andavenues for transfer learning, such as extension to other AM processes such asdirected energy deposition.</description>
      <author>example@mail.com (Aagam Shah, Reimar Weissbach, David A. Griggs, A. John Hart, Elif Ertekin, Sameh Tawfick)</author>
      <guid isPermaLink="false">2409.18326v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Open-Set Domain Generalization Using Evidential Bi-Level Hardest Domain Scheduler</title>
      <link>http://arxiv.org/abs/2409.17555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024. The source code will be available at
  https://github.com/KPeng9510/EBiL-HaDS&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 在开放集领域泛化（OSDG）中，模型需要处理新的数据外观变异（领域）以及开放集条件，测试时同时存在已知和新类别。&lt;h4&gt;2. 任务挑战&lt;/h4&gt;   - OSDG面临的挑战包括在不同领域之间进行广泛的泛化和准确量化类别的新颖性，这对动态环境中的应用至关重要。&lt;h4&gt;3. 近年来的进展&lt;/h4&gt;   - 最近，元学习技术在OSDG中表现出色，通过多样化的随机类别和预定义的领域划分策略有效协调元训练和测试任务。&lt;h4&gt;4. 训练策略的重要性&lt;/h4&gt;   - 这些方法更注重精心设计的训练计划，而非传统方法主要关注数据增强和特征学习的提升。&lt;h4&gt;5. 现有模型的局限&lt;/h4&gt;   - 当前的元学习模型通常使用预定义的顺序领域调度器来组织数据分区，但领域调度策略在训练中的影响尚未充分研究。&lt;h4&gt;6. 研究发现&lt;/h4&gt;   - 本文观察到，与固定的顺序和随机领域调度器相比，自适应领域调度器在OSDG中表现更佳。&lt;h4&gt;7. 提出的新方法&lt;/h4&gt;   - 提出了证据双层最难领域调度器（EBiL-HaDS），实现自适应领域调度，通过评估领域可靠性来战略性地排序领域。&lt;h4&gt;8. 方法细节&lt;/h4&gt;   - 该方法利用一个使用证据学习的信心得分训练的跟随网络，结合最大重偏差差异进行正则化，并以双层方式优化。&lt;h4&gt;9. 实验结果&lt;/h4&gt;   - 结果表明，所提方法显著提高了OSDG的性能，为已见和未见类别提供了更具区分性的嵌入表示。&lt;h4&gt;10. 源代码&lt;/h4&gt;    - 源代码将可在 https://github.com/KPeng9510/EBiL-HaDS 获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/kpeng9510/ebil-hads&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In Open-Set Domain Generalization (OSDG), the model is exposed to both newvariations of data appearance (domains) and open-set conditions, where bothknown and novel categories are present at test time. The challenges of thistask arise from the dual need to generalize across diverse domains andaccurately quantify category novelty, which is critical for applications indynamic environments. Recently, meta-learning techniques have demonstratedsuperior results in OSDG, effectively orchestrating the meta-train and -testtasks by employing varied random categories and predefined domain partitionstrategies. These approaches prioritize a well-designed training schedule overtraditional methods that focus primarily on data augmentation and theenhancement of discriminative feature learning. The prevailing meta-learningmodels in OSDG typically utilize a predefined sequential domain scheduler tostructure data partitions. However, a crucial aspect that remains inadequatelyexplored is the influence brought by strategies of domain schedulers duringtraining. In this paper, we observe that an adaptive domain scheduler benefitsmore in OSDG compared with prefixed sequential and random domain schedulers. Wepropose the Evidential Bi-Level Hardest Domain Scheduler (EBiL-HaDS) to achievean adaptive domain scheduler. This method strategically sequences domains byassessing their reliabilities in utilizing a follower network, trained withconfidence scores learned in an evidential manner, regularized by max rebiasingdiscrepancy, and optimized in a bi-level manner. The results show that ourmethod substantially improves OSDG performance and achieves more discriminativeembeddings for both the seen and unseen categories. The source code will beavailable at https://github.com/KPeng9510/EBiL-HaDS.</description>
      <author>example@mail.com (Kunyu Peng, Di Wen, Kailun Yang, Ao Luo, Yufan Chen, Jia Fu, M. Saquib Sarfraz, Alina Roitberg, Rainer Stiefelhagen)</author>
      <guid isPermaLink="false">2409.17555v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception</title>
      <link>http://arxiv.org/abs/2409.18877v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to TIP&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 视觉情感分析在计算机视觉和心理学领域具有重要的研究价值。&lt;h4&gt;2. 现有方法的局限&lt;/h4&gt;   - 现有的视觉情感分析方法由于情感感知的模糊性和数据场景的多样性，普遍存在有限的泛化能力。&lt;h4&gt;3. 提出的新框架&lt;/h4&gt;   - 本文介绍了UniEmoX，一个跨模态的语义引导大规模预训练框架。&lt;h4&gt;4. 理论基础&lt;/h4&gt;   - UniEmoX受心理学研究的启发，强调情感探索过程与个体与环境之间互动的不可分割性。&lt;h4&gt;5. 结构信息整合&lt;/h4&gt;   - 该框架整合了以场景为中心和以人物为中心的低级图像空间结构信息，旨在获取更细腻和可区分的情感表示。&lt;h4&gt;6. 语义知识提取&lt;/h4&gt;   - 通过利用成对和非成对的图像-文本样本之间的相似性，UniEmoX从CLIP模型中提炼丰富的语义知识，以更有效地增强情感嵌入表示。&lt;h4&gt;7. 创新性&lt;/h4&gt;   - 据我们所知，这是第一个将心理学理论与现代对比学习和掩蔽图像建模技术结合的情感分析大规模预训练框架，适用于多样场景。&lt;h4&gt;8. 数据集开发&lt;/h4&gt;   - 开发了名为Emo8的视觉情感数据集，涵盖卡通、自然、现实、科幻和广告封面风格，几乎涵盖所有常见情感场景。&lt;h4&gt;9. 实验验证&lt;/h4&gt;   - 在六个基准数据集上进行的全面实验，针对两个下游任务验证了UniEmoX的有效性。&lt;h4&gt;10. 源代码&lt;/h4&gt;    - 源代码可在https://github.com/chincharles/u-emo获取。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual emotion analysis holds significant research value in both computervision and psychology. However, existing methods for visual emotion analysissuffer from limited generalizability due to the ambiguity of emotion perceptionand the diversity of data scenarios. To tackle this issue, we introduceUniEmoX, a cross-modal semantic-guided large-scale pretraining framework.Inspired by psychological research emphasizing the inseparability of theemotional exploration process from the interaction between individuals andtheir environment, UniEmoX integrates scene-centric and person-centriclow-level image spatial structural information, aiming to derive more nuancedand discriminative emotional representations. By exploiting the similaritybetween paired and unpaired image-text samples, UniEmoX distills rich semanticknowledge from the CLIP model to enhance emotional embedding representationsmore effectively. To the best of our knowledge, this is the first large-scalepretraining framework that integrates psychological theories with contemporarycontrastive learning and masked image modeling techniques for emotion analysisacross diverse scenarios. Additionally, we develop a visual emotional datasettitled Emo8. Emo8 samples cover a range of domains, including cartoon, natural,realistic, science fiction and advertising cover styles, covering nearly allcommon emotional scenes. Comprehensive experiments conducted on six benchmarkdatasets across two downstream tasks validate the effectiveness of UniEmoX. Thesource code is available at https://github.com/chincharles/u-emo.</description>
      <author>example@mail.com (Chuang Chen, Xiao Sun, Zhi Liu)</author>
      <guid isPermaLink="false">2409.18877v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>How Effective is Pre-training of Large Masked Autoencoders for Downstream Earth Observation Tasks?</title>
      <link>http://arxiv.org/abs/2409.18536v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 自监督预训练在许多计算机视觉任务中表现出色，尤其是在标记数据稀缺的情况下。&lt;h4&gt;2. 地球观测领域的应用&lt;/h4&gt;   - 在地球观测（EO）中，基础模型和多种基于视觉变压器（ViT）的方法已成功应用于迁移学习，以支持下游任务。&lt;h4&gt;3. 研究问题&lt;/h4&gt;   - 目前尚不清楚在何种条件下，预训练模型相较于从头开始训练能提供显著优势。&lt;h4&gt;4. 研究目的&lt;/h4&gt;   - 本研究调查了基于ViT的掩蔽自编码器（MAE）在下游EO任务中的有效性，重点关注重建、分割和分类任务。&lt;h4&gt;5. 模型选择&lt;/h4&gt;   - 考虑了两个大型基于ViT的MAE预训练模型：基础模型Prithvi和SatMAE。&lt;h4&gt;6. 评估方法&lt;/h4&gt;   - 对Prithvi模型在重建和分割下游任务中的表现进行评估；对SatMAE在分类下游任务中的表现进行评估。&lt;h4&gt;7. 研究发现&lt;/h4&gt;   - 预训练在细调任务与预训练任务高度相似（如重建）时特别有利。   - 对于分割或分类等任务，经过特定超参数调整的从头训练同样或更有效。&lt;h4&gt;8. 结论&lt;/h4&gt;   - 研究结果提示在选择预训练与从头训练的策略时，应考虑任务的具体特点。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised pre-training has proven highly effective for many computervision tasks, particularly when labelled data are scarce. In the context ofEarth Observation (EO), foundation models and various other Vision Transformer(ViT)-based approaches have been successfully applied for transfer learning todownstream tasks. However, it remains unclear under which conditionspre-trained models offer significant advantages over training from scratch. Inthis study, we investigate the effectiveness of pre-training ViT-based MaskedAutoencoders (MAE) for downstream EO tasks, focusing on reconstruction,segmentation, and classification. We consider two large ViT-based MAEpre-trained models: a foundation model (Prithvi) and SatMAE. We evaluatePrithvi on reconstruction and segmentation-based downstream tasks, and forSatMAE we assess its performance on a classification downstream task. Ourfindings suggest that pre-training is particularly beneficial when thefine-tuning task closely resembles the pre-training task, e.g. reconstruction.In contrast, for tasks such as segmentation or classification, training fromscratch with specific hyperparameter adjustments proved to be equally or moreeffective.</description>
      <author>example@mail.com (Jose Sosa, Mohamed Aloulou, Danila Rukhovich, Rim Sleimi, Boonyarit Changaival, Anis Kacem, Djamila Aouada)</author>
      <guid isPermaLink="false">2409.18536v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Seeing the Invisible through Speckle Images</title>
      <link>http://arxiv.org/abs/2409.18815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 散射现象通过产生斑点图案遮蔽了波所携带的信息，这在显微镜和天文学等多个领域构成了常见挑战。&lt;h4&gt;2. 传统方法的局限&lt;/h4&gt;   - 传统的斑点信息提取方法通常依赖于显著的物理假设、复杂设备或复杂算法。&lt;h4&gt;3. 机器学习的兴起&lt;/h4&gt;   - 最近，机器学习作为一种可扩展且广泛采用的工具，出现用于解释斑点图案。&lt;h4&gt;4. 监督学习的挑战&lt;/h4&gt;   - 目前大多数机器学习技术严重依赖于大量标记数据进行监督训练，而在缺乏标签的情况下，这种方法存在问题。&lt;h4&gt;5. 提出的新策略&lt;/h4&gt;   - 本文提出了一种基于无监督学习的策略，用于斑点识别和评估，能够直接从斑点中捕捉高层次信息（如物体类别），无需标记数据。&lt;h4&gt;6. 方法特点&lt;/h4&gt;   - 通过从斑点中推导不变特征，该方法支持斑点分类，并促进图像传感的多种应用。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 通过两个重要应用实验验证了该策略：     - 一个非侵入式的葡萄糖监测系统，能够区分时序葡萄糖浓度。     - 一个高通量通信系统，利用多模光纤在动态环境中工作。&lt;h4&gt;8. 潜在应用&lt;/h4&gt;   - 该方法的多功能性为包括生物医学诊断、量子网络解耦和遥感等广泛应用提供了前景。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scattering obscures information carried by wave by producing a specklepattern, posing a common challenge across various fields, including microscopyand astronomy. Traditional methods for extracting information from specklesoften rely on significant physical assumptions, complex devices, or intricatealgorithms. Recently, machine learning has emerged as a scalable and widelyadopted tool for interpreting speckle patterns. However, most current machinelearning techniques depend heavily on supervised training with extensivelabeled datasets, which is problematic when labels are unavailable. To addressthis, we propose a strategy based on unsupervised learning for specklerecognition and evaluation, enabling to capture high-level information, such asobject classes, directly from speckles without labeled data. By derivinginvariant features from speckles, this method allows for the classification ofspeckles and facilitates diverse applications in image sensing. Weexperimentally validated our strategy through two significant applications: anoninvasive glucose monitoring system capable of differentiating time-lapseglucose concentrations, and a high-throughput communication system utilizingmultimode fibers in dynamic environments. The versatility of this method holdspromise for a broad range of far-reaching applications, including biomedicaldiagnostics, quantum network decoupling, and remote sensing.</description>
      <author>example@mail.com (Weiru Fan, Xiaobin Tang, Xingqi Xu, Huizhu Hu, Vladislav V. Yakovlev, Shi-Yao Zhu, Da-Wei Wang, Delong Zhang)</author>
      <guid isPermaLink="false">2409.18815v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Geometric deep learning for galaxy-halo connection: a case study for galaxy intrinsic alignments</title>
      <link>http://arxiv.org/abs/2409.18761v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures. submitted to MNRAS&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 即将开展的宇宙学影像调查（如Rubin Observatory LSST）需要大规模模拟，涵盖现实的星系群体，以支持各种科学应用。&lt;h4&gt;2. 内在对齐现象&lt;/h4&gt;   - 内在对齐（IA）现象是指星系朝向过密度区域的方向排列，如果未得到妥善建模，可能在弱引力透镜分析中引入显著的系统性偏差。&lt;h4&gt;3. 计算限制&lt;/h4&gt;   - 由于计算资源的限制，在广泛体积中模拟与IA相关的星系形成和演化的复杂细节是不切实际的。&lt;h4&gt;4. 新方法的提出&lt;/h4&gt;   - 本文提出了一种深度生成模型，基于IllustrisTNG-100模拟，采样三维星系形状和方向，以准确再现内在对齐及相关标量特征。&lt;h4&gt;5. 宇宙网络建模&lt;/h4&gt;   - 将宇宙网络建模为一系列图，每个图代表一个光晕，节点代表子光晕/星系。&lt;h4&gt;6. 模型架构&lt;/h4&gt;   - 采用SO(3) × ℝⁿ扩散生成模型来处理星系方向和n个标量，使用E(3)等变图神经网络，明确尊重宇宙的欧几里得对称性。&lt;h4&gt;7. 学习能力&lt;/h4&gt;   - 模型能够学习和预测与参考模拟在统计上相一致的星系方向等特征。&lt;h4&gt;8. 联合建模能力&lt;/h4&gt;   - 模型展示了联合建模欧几里得标量（如星系大小、形状和颜色）与非欧几里得SO(3)量（如星系方向）的能力，这些都受到非线性尺度下复杂星系物理的影响。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forthcoming cosmological imaging surveys, such as the Rubin Observatory LSST,require large-scale simulations encompassing realistic galaxy populations for avariety of scientific applications. Of particular concern is the phenomenon ofintrinsic alignments (IA), whereby galaxies orient themselves towardsoverdensities, potentially introducing significant systematic biases in weakgravitational lensing analyses if they are not properly modeled. Due tocomputational constraints, simulating the intricate details of galaxy formationand evolution relevant to IA across vast volumes is impractical. As analternative, we propose a Deep Generative Model trained on the IllustrisTNG-100simulation to sample 3D galaxy shapes and orientations to accurately reproduceintrinsic alignments along with correlated scalar features. We model the cosmicweb as a set of graphs, each graph representing a halo with nodes representingthe subhalos/galaxies. The architecture consists of a SO(3) $\times$$\mathbb{R}^n$ diffusion generative model, for galaxy orientations and $n$scalars, implemented with E(3) equivariant Graph Neural Networks thatexplicitly respect the Euclidean symmetries of our Universe. The model is ableto learn and predict features such as galaxy orientations that arestatistically consistent with the reference simulation. Notably, our modeldemonstrates the ability to jointly model Euclidean-valued scalars (galaxysizes, shapes, and colors) along with non-Euclidean valued SO(3) quantities(galaxy orientations) that are governed by highly complex galactic physics atnon-linear scales.</description>
      <author>example@mail.com (Yesukhei Jagvaral, Francois Lanusse, Rachel Mandelbaum)</author>
      <guid isPermaLink="false">2409.18761v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Localized Gaussians as Self-Attention Weights for Point Clouds Correspondence</title>
      <link>http://arxiv.org/abs/2409.13291v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 当前基于数据的方法用于点云匹配时，需要大量的训练时间和计算资源，这对模型的部署和应用构成了重大挑战。&lt;h4&gt;2. 技术进展&lt;/h4&gt;   - 最近，使用仅包含编码器的Transformer架构在点云匹配任务中取得了进展，注意力头中出现了语义上有意义的模式，这些模式特别类似于以输入形状每个点为中心的高斯函数。&lt;h4&gt;3. 研究目的&lt;/h4&gt;   - 本研究进一步探讨这一现象，通过将这些模式作为固定的注意力权重集成到Transformer架构的注意力头中。&lt;h4&gt;4. 方法变体&lt;/h4&gt;   - 评估了两种变体：一种使用预先确定的高斯方差值，另一种将方差值视为可学习参数。&lt;h4&gt;5. 噪声数据分析&lt;/h4&gt;   - 分析在噪声数据上的表现，并探索提高对噪声的鲁棒性的方法。&lt;h4&gt;6. 研究发现&lt;/h4&gt;   - 固定注意力权重不仅加速了训练过程，还增强了优化的稳定性。&lt;h4&gt;7. 消融研究&lt;/h4&gt;   - 进行了消融研究，以识别注入信息最有影响力的特定层，并理解网络对这些信息的依赖程度。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current data-driven methodologies for point cloud matching demand extensivetraining time and computational resources, presenting significant challengesfor model deployment and application. In the point cloud matching task, recentadvancements with an encoder-only Transformer architecture have revealed theemergence of semantically meaningful patterns in the attention heads,particularly resembling Gaussian functions centered on each point of the inputshape. In this work, we further investigate this phenomenon by integratingthese patterns as fixed attention weights within the attention heads of theTransformer architecture. We evaluate two variants: one utilizing predeterminedvariance values for the Gaussians, and another where the variance values aretreated as learnable parameters. Additionally we analyze the performances onnoisy data and explore a possible way to improve robustness to noise. Ourfindings demonstrate that fixing the attention weights not only accelerates thetraining process but also enhances the stability of the optimization.Furthermore, we conducted an ablation study to identify the specific layerswhere the infused information is most impactful and to understand the relianceof the network on this information.</description>
      <author>example@mail.com (Alessandro Riva, Alessandro Raganato, Simone Melzi)</author>
      <guid isPermaLink="false">2409.13291v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Latent Representation Learning for Multimodal Brain Activity Translation</title>
      <link>http://arxiv.org/abs/2409.18462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 神经科学使用多种神经影像技术，各自提供对大脑活动的独特见解，例如高时间分辨率的脑电图（EEG）和高空间精度的功能性磁共振成像（fMRI）。&lt;h4&gt;2. 研究挑战&lt;/h4&gt;   - 整合这些异构数据源是一个挑战，限制了对大脑功能的全面理解。&lt;h4&gt;3. 提出的框架&lt;/h4&gt;   - 本文提出了多模态大脑活动的时空对齐框架（SAMBA），旨在通过学习一个统一的潜在空间来弥合模态间的空间和时间分辨率差距，消除模态特定的偏差。&lt;h4&gt;4. 新技术的引入&lt;/h4&gt;   - SAMBA引入了一种新颖的基于注意力的波形分解方法，用于对电生理记录进行频谱过滤。   - 使用图注意力网络建模功能脑单元之间的功能连接。   - 采用递归层捕捉脑信号中的时间自相关性。&lt;h4&gt;5. 训练效果&lt;/h4&gt;   - SAMBA的训练不仅实现了模态间的转换，还学习了丰富的大脑信息处理表示。&lt;h4&gt;6. 应用展示&lt;/h4&gt;   - 通过SAMBA的隐藏层学习到的表示，展示了如何分类驱动大脑活动的外部刺激。&lt;h4&gt;7. 潜在影响&lt;/h4&gt;   - 本研究为神经科学研究和临床应用的广泛后续应用铺平了道路。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neuroscience employs diverse neuroimaging techniques, each offering distinctinsights into brain activity, from electrophysiological recordings such as EEG,which have high temporal resolution, to hemodynamic modalities such as fMRI,which have increased spatial precision. However, integrating theseheterogeneous data sources remains a challenge, which limits a comprehensiveunderstanding of brain function. We present the Spatiotemporal Alignment ofMultimodal Brain Activity (SAMBA) framework, which bridges the spatial andtemporal resolution gaps across modalities by learning a unified latent spacefree of modality-specific biases. SAMBA introduces a novel attention-basedwavelet decomposition for spectral filtering of electrophysiologicalrecordings, graph attention networks to model functional connectivity betweenfunctional brain units, and recurrent layers to capture temporalautocorrelations in brain signal. We show that the training of SAMBA, asidefrom achieving translation, also learns a rich representation of braininformation processing. We showcase this classify external stimuli drivingbrain activity from the representation learned in hidden layers of SAMBA,paving the way for broad downstream applications in neuroscience research andclinical contexts.</description>
      <author>example@mail.com (Arman Afrasiyabi, Dhananjay Bhaskar, Erica L. Busch, Laurent Caplette, Rahul Singh, Guillaume Lajoie, Nicholas B. Turk-Browne, Smita Krishnaswamy)</author>
      <guid isPermaLink="false">2409.18462v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Token Pruning in Vision State Space Models</title>
      <link>http://arxiv.org/abs/2409.18962v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS'24&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 状态空间模型（SSMs）在计算复杂度上保持线性，相较于变压器中的注意力模块，具有优势，并已应用于视觉任务，成为一种强大的视觉基础模型。&lt;h4&gt;2. 研究动机&lt;/h4&gt;   - 观察到视觉变压器（ViTs）中的最终预测仅基于最信息丰富的部分标记，促使我们通过基于标记的修剪提高SSM基础视觉模型的效率。&lt;h4&gt;3. 现有技术的局限&lt;/h4&gt;   - 现有针对ViTs设计的标记修剪技术直接应用于SSMs时，未能提供良好的性能，即便经过广泛的微调。&lt;h4&gt;4. 问题分析&lt;/h4&gt;   - 重新审视SSMs的独特计算特性，发现简单应用修剪会破坏序列标记位置。&lt;h4&gt;5. 新方法的提出&lt;/h4&gt;   - 设计了一种专门针对SSM基础视觉模型的新型通用标记修剪方法。&lt;h4&gt;6. 修剪方法的细节&lt;/h4&gt;   - 首先引入了一种修剪感知的隐藏状态对齐方法，以稳定剩余标记的邻域，从而增强性能。   - 提出了适用于SSM模型的标记重要性评估方法，以指导标记修剪。&lt;h4&gt;7. 实现与加速&lt;/h4&gt;   - 通过高效的实现和实际加速方法，所提方法实现了实际的加速效果。&lt;h4&gt;8. 实验结果&lt;/h4&gt;   - 大量实验表明，该方法在不同任务中能够显著减少计算量，且对性能的影响最小。   - 在ImageNet上，修剪后的PlainMamba-L3模型达到了81.7%的准确率，同时FLOPs减少了41.6%。&lt;h4&gt;9. 研究贡献&lt;/h4&gt;   - 本研究为未来研究提供了对SSM基础视觉模型行为的更深刻理解。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State Space Models (SSMs) have the advantage of keeping linear computationalcomplexity compared to attention modules in transformers, and have been appliedto vision tasks as a new type of powerful vision foundation model. Inspired bythe observations that the final prediction in vision transformers (ViTs) isonly based on a subset of most informative tokens, we take the novel step ofenhancing the efficiency of SSM-based vision models through token-basedpruning. However, direct applications of existing token pruning techniquesdesigned for ViTs fail to deliver good performance, even with extensivefine-tuning. To address this issue, we revisit the unique computationalcharacteristics of SSMs and discover that naive application disrupts thesequential token positions. This insight motivates us to design a novel andgeneral token pruning method specifically for SSM-based vision models. We firstintroduce a pruning-aware hidden state alignment method to stabilize theneighborhood of remaining tokens for performance enhancement. Besides, based onour detailed analysis, we propose a token importance evaluation method adaptedfor SSM models, to guide the token pruning. With efficient implementation andpractical acceleration methods, our method brings actual speedup. Extensiveexperiments demonstrate that our approach can achieve significant computationreduction with minimal impact on performance across different tasks. Notably,we achieve 81.7\% accuracy on ImageNet with a 41.6\% reduction in the FLOPs forpruned PlainMamba-L3. Furthermore, our work provides deeper insights intounderstanding the behavior of SSM-based vision models for future research.</description>
      <author>example@mail.com (Zheng Zhan, Zhenglun Kong, Yifan Gong, Yushu Wu, Zichong Meng, Hangyu Zheng, Xuan Shen, Stratis Ioannidis, Wei Niu, Pu Zhao, Yanzhi Wang)</author>
      <guid isPermaLink="false">2409.18962v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech</title>
      <link>http://arxiv.org/abs/2409.18622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  EMNLP 2024 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 获取丰富且高质量的数据在多语言环境中尤其困难，这引发了对低资源场景的关注。&lt;h4&gt;2. 现有文献的局限&lt;/h4&gt;   - 当前文献依赖于语言ID的固定表达，导致语言表示学习不足，并无法生成未见语言的语音。&lt;h4&gt;3. 提出的新方法&lt;/h4&gt;   - 本文提出了一种新颖的方法，直接从音频输入中提取语言特征，同时有效过滤杂音信息，包括说话者特征如音色。&lt;h4&gt;4. 评估方法&lt;/h4&gt;   - 进行了主观和客观评估，以确认该方法在多语言文本到语音转换中的有效性。&lt;h4&gt;5. 低资源迁移学习的优势&lt;/h4&gt;   - 结果显示，该方法在低资源迁移学习中，对于以前未见语言表现出优越性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The difficulty of acquiring abundant, high-quality data, especially inmulti-lingual contexts, has sparked interest in addressing low-resourcescenarios. Moreover, current literature rely on fixed expressions from languageIDs, which results in the inadequate learning of language representations, andthe failure to generate speech in unseen languages. To address thesechallenges, we propose a novel method that directly extracts linguisticfeatures from audio input while effectively filtering out miscellaneousacoustic information including speaker-specific attributes like timbre.Subjective and objective evaluations affirm the effectiveness of our approachfor multi-lingual text-to-speech, and highlight its superiority in low-resourcetransfer learning for previously unseen language.</description>
      <author>example@mail.com (Youngjae Kim, Yejin Jeon, Gary Geunbae Lee)</author>
      <guid isPermaLink="false">2409.18622v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>HardCore Generation: Generating Hard UNSAT Problems for Data Augmentation</title>
      <link>http://arxiv.org/abs/2409.18778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 有效确定布尔方程的可满足性（SAT问题）在各种工业问题中至关重要。&lt;h4&gt;2. 深度学习的潜力&lt;/h4&gt;   - 最近，深度学习方法的出现为SAT求解的增强带来了重大潜力。&lt;h4&gt;3. 数据集的短缺&lt;/h4&gt;   - 当前大多数公共数据集要么是随机生成的，要么极其有限，仅包含少量来自不相关问题家族的示例，这些数据集不足以进行深度学习方法的有效训练。&lt;h4&gt;4. 生成技术的探索&lt;/h4&gt;   - 鉴于数据集短缺，研究者开始探索生成技术，以创建更准确反映实际SAT问题的数据。&lt;h4&gt;5. 现有方法的不足&lt;/h4&gt;   - 现有生成方法要么无法产生具有挑战性的SAT问题，要么面临时间可扩展性障碍。&lt;h4&gt;6. 核心概念的引入&lt;/h4&gt;   - 本文通过识别和操控影响问题“难度”的关键因素（称为核心）来解决上述问题。&lt;h4&gt;7. 核心检测的挑战&lt;/h4&gt;   - 尽管一些先前的研究已涉及核心，但传统启发式核心检测技术的时间成本过高。&lt;h4&gt;8. 新方法的提出&lt;/h4&gt;   - 本文引入了一种快速的核心检测程序，利用图神经网络（GNN）来提高效率。&lt;h4&gt;9. 实验结果&lt;/h4&gt;   - 实证结果表明，所提出的方法能够高效生成仍然难以解决的问题，并保留原始示例问题的关键属性。&lt;h4&gt;10. 应用场景&lt;/h4&gt;    - 实验还表明，生成的合成SAT问题可以用于数据增强，改善求解器运行时间的预测。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently determining the satisfiability of a boolean equation -- known asthe SAT problem for brevity -- is crucial in various industrial problems.Recently, the advent of deep learning methods has introduced significantpotential for enhancing SAT solving. However, a major barrier to theadvancement of this field has been the scarcity of large, realistic datasets.The majority of current public datasets are either randomly generated orextremely limited, containing only a few examples from unrelated problemfamilies. These datasets are inadequate for meaningful training of deeplearning methods. In light of this, researchers have started exploringgenerative techniques to create data that more accurately reflect SAT problemsencountered in practical situations. These methods have so far suffered fromeither the inability to produce challenging SAT problems or time-scalabilityobstacles. In this paper we address both by identifying and manipulating thekey contributors to a problem's ``hardness'', known as cores. Although someprevious work has addressed cores, the time costs are unacceptably high due tothe expense of traditional heuristic core detection techniques. We introduce afast core detection procedure that uses a graph neural network. Our empiricalresults demonstrate that we can efficiently generate problems that remain hardto solve and retain key attributes of the original example problems. We showvia experiment that the generated synthetic SAT problems can be used in a dataaugmentation setting to provide improved prediction of solver runtimes.</description>
      <author>example@mail.com (Joseph Cotnareanu, Zhanguang Zhang, Hui-Ling Zhen, Yingxue Zhang, Mark Coates)</author>
      <guid isPermaLink="false">2409.18778v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Positional Encoder Graph Quantile Neural Networks for Geographic Data</title>
      <link>http://arxiv.org/abs/2409.18865v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 main text pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - Positional Encoder Graph Neural Networks (PE-GNNs) 是建模连续空间数据的主要方法，但在生成校准的预测分布方面存在不足，限制了它们在不确定性量化中的有效性。&lt;h4&gt;2. 新方法的提出&lt;/h4&gt;   - 引入了Positional Encoder Graph Quantile Neural Network (PE-GQNN)，这是一种新颖的方法，结合了PE-GNN、量化神经网络和重校准技术，形成一个完全非参数化的框架，对预测分布的假设要求较少。&lt;h4&gt;3. 网络架构&lt;/h4&gt;   - 提出了新的网络架构，配合基于量化的损失函数，能够在不增加计算复杂度的情况下，生成准确且可靠的概率模型。&lt;h4&gt;4. 应用范围&lt;/h4&gt;   - 该方法提供了一个灵活且稳健的框架用于条件密度估计，适用于超越空间数据的上下文。&lt;h4&gt;5. KNN预测器的整合&lt;/h4&gt;   - 提出了结构化的方法，将K近邻（KNN）预测器纳入模型，同时避免通过GNN层操作导致的数据泄漏。&lt;h4&gt;6. 实验结果&lt;/h4&gt;   - 在基准数据集上的实验表明，PE-GQNN在预测准确性和不确定性量化方面显著优于现有的最先进方法。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Positional Encoder Graph Neural Networks (PE-GNNs) are a leading approach formodeling continuous spatial data. However, they often fail to producecalibrated predictive distributions, limiting their effectiveness foruncertainty quantification. We introduce the Positional Encoder Graph QuantileNeural Network (PE-GQNN), a novel method that integrates PE-GNNs, QuantileNeural Networks, and recalibration techniques in a fully nonparametricframework, requiring minimal assumptions about the predictive distributions. Wepropose a new network architecture that, when combined with a quantile-basedloss function, yields accurate and reliable probabilistic models withoutincreasing computational complexity. Our approach provides a flexible, robustframework for conditional density estimation, applicable beyond spatial datacontexts. We further introduce a structured method for incorporating a KNNpredictor into the model while avoiding data leakage through the GNN layeroperation. Experiments on benchmark datasets demonstrate that PE-GQNNsignificantly outperforms existing state-of-the-art methods in both predictiveaccuracy and uncertainty quantification.</description>
      <author>example@mail.com (William E. R. de Amorim, Scott A. Sisson, T. Rodrigues, David J. Nott, Guilherme S. Rodrigues)</author>
      <guid isPermaLink="false">2409.18865v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>HSTFL: A Heterogeneous Federated Learning Framework for Misaligned Spatiotemporal Forecasting</title>
      <link>http://arxiv.org/abs/2409.18482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 时空预测已成为智能城市应用（如智能交通和智能能源管理）的重要基础。&lt;h4&gt;2. 现有方法的优点&lt;/h4&gt;   - 通过整合来自不同领域的地理分布时间序列数据，时空预测的性能显著提高，例如，通过人类流动数据增强房地产评估，联合预测出租车和自行车需求。&lt;h4&gt;3. 现有方法的局限性&lt;/h4&gt;   - 现有方法假设集中式数据收集和利用环境，忽视了不同方数据所带来的隐私和商业利益问题。&lt;h4&gt;4. 研究目的&lt;/h4&gt;   - 本文研究在没有直接访问多源私有数据的情况下进行多方协作的时空预测。&lt;h4&gt;5. 面临的挑战&lt;/h4&gt;   - 1) 跨域特征异质性；2) 跨客户端地理异质性，使得标准的水平或垂直联邦学习方法不适用。&lt;h4&gt;6. 提出的框架&lt;/h4&gt;   - 提出了异质时空联邦学习（HSTFL）框架，使多个客户端能够在保护隐私的同时，协同利用来自不同领域的地理分布时间序列数据。&lt;h4&gt;7. 实现细节&lt;/h4&gt;   - 首先设计了垂直联邦时空表示学习，以在各参与者之间局部保留时空依赖，并生成异质数据的有效表示。   - 然后提出了跨客户端虚拟节点对齐模块，通过多层次知识融合方案整合跨客户端的时空依赖。&lt;h4&gt;8. 实验验证&lt;/h4&gt;   - 通过广泛的隐私分析和实验评估，证明HSTFL不仅有效抵抗推断攻击，还显著改善了与多种基线方法的比较结果。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatiotemporal forecasting has emerged as an indispensable building block ofdiverse smart city applications, such as intelligent transportation and smartenergy management. Recent advancements have uncovered that the performance ofspatiotemporal forecasting can be significantly improved by integratingknowledge in geo-distributed time series data from different domains, \egenhancing real-estate appraisal with human mobility data; joint taxi and bikedemand predictions. While effective, existing approaches assume a centralizeddata collection and exploitation environment, overlooking the privacy andcommercial interest concerns associated with data owned by different parties.In this paper, we investigate multi-party collaborative spatiotemporalforecasting without direct access to multi-source private data. However, thistask is challenging due to 1) cross-domain feature heterogeneity and 2)cross-client geographical heterogeneity, where standard horizontal or verticalfederated learning is inapplicable. To this end, we propose a HeterogeneousSpatioTemporal Federated Learning (HSTFL) framework to enable multiple clientsto collaboratively harness geo-distributed time series data from differentdomains while preserving privacy. Specifically, we first devise verticalfederated spatiotemporal representation learning to locally preservespatiotemporal dependencies among individual participants and generateeffective representations for heterogeneous data. Then we propose across-client virtual node alignment block to incorporate cross-clientspatiotemporal dependencies via a multi-level knowledge fusion scheme.Extensive privacy analysis and experimental evaluations demonstrate that HSTFLnot only effectively resists inference attacks but also provides a significantimprovement against various baselines.</description>
      <author>example@mail.com (Shuowei Cai, Hao Liu)</author>
      <guid isPermaLink="false">2409.18482v1</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Sparse-to-Dense LiDAR Point Generation by LiDAR-Camera Fusion for 3D Object Detection</title>
      <link>http://arxiv.org/abs/2409.14985v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 在3D对象检测中，仅依靠LiDAR传感器在远距离准确检测对象仍然是一个重大挑战，主要由于数据稀疏的固有限制。&lt;h4&gt;2. 提出的解决方案&lt;/h4&gt;   - 本文提出了LiDAR-Camera Augmentation Network (LCANet)，这是一种新颖的框架，通过融合2D图像特征重建LiDAR点云数据，从而生成额外点以提高检测准确性。&lt;h4&gt;3. 数据融合&lt;/h4&gt;   - LCANet通过将图像特征投影到3D空间中，将LiDAR传感器和相机的数据融合，整合语义信息进入点云数据中。&lt;h4&gt;4. 特征编码&lt;/h4&gt;   - 融合后的数据被编码以生成包含语义和空间信息的3D特征，然后进一步精炼以重建最终的点，最后进行边界框预测。&lt;h4&gt;5. 优势&lt;/h4&gt;   - 这种数据融合有效补偿了LiDAR在远距离对象检测中的弱点，因为这些对象通常由稀疏点表示。&lt;h4&gt;6. 点云补全网络&lt;/h4&gt;   - 由于原始数据集中许多对象的稀疏性使得点生成的有效监督变得困难，因此采用了点云补全网络，创建完整的点云数据集以监督网络中密集点云的生成。&lt;h4&gt;7. 实验验证&lt;/h4&gt;   - 在KITTI和Waymo数据集上进行的大量实验表明，LCANet显著优于现有模型，特别是在检测稀疏和远距离对象方面表现突出。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately detecting objects at long distances remains a critical challengein 3D object detection when relying solely on LiDAR sensors due to the inherentlimitations of data sparsity. To address this issue, we propose theLiDAR-Camera Augmentation Network (LCANet), a novel framework that reconstructsLiDAR point cloud data by fusing 2D image features, which contain rich semanticinformation, generating additional points to improve detection accuracy. LCANetfuses data from LiDAR sensors and cameras by projecting image features into the3D space, integrating semantic information into the point cloud data. Thisfused data is then encoded to produce 3D features that contain both semanticand spatial information, which are further refined to reconstruct final pointsbefore bounding box prediction. This fusion effectively compensates for LiDAR'sweakness in detecting objects at long distances, which are often represented bysparse points. Additionally, due to the sparsity of many objects in theoriginal dataset, which makes effective supervision for point generationchallenging, we employ a point cloud completion network to create a completepoint cloud dataset that supervises the generation of dense point clouds in ournetwork. Extensive experiments on the KITTI and Waymo datasets demonstrate thatLCANet significantly outperforms existing models, particularly in detectingsparse and distant objects.</description>
      <author>example@mail.com (Minseung Lee, Seokha Moon, Seung Joon Lee, Jinkyu Kim)</author>
      <guid isPermaLink="false">2409.14985v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Domain-Invariant Representation Learning of Bird Sounds</title>
      <link>http://arxiv.org/abs/2409.08589v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 被动声学监测（PAM）对生物声学研究至关重要，它允许非侵入性物种跟踪和生物多样性监测。&lt;h4&gt;2. 公民科学平台的作用&lt;/h4&gt;   - 像Xeno-Canto这样的公民科学平台提供了大量标注数据集，这些数据集来自于意图录制目标物种的记录。&lt;h4&gt;3. 领域转移问题&lt;/h4&gt;   - PAM需要在被动声景中进行监测，这导致了焦点录音与被动录音之间的领域转移，给基于焦点录音训练的深度学习模型带来了挑战。&lt;h4&gt;4. 解决方案&lt;/h4&gt;   - 采用监督对比学习（supervised contrastive learning）来提高鸟类声音分类的领域泛化能力，强化来自不同领域的同类样本之间的领域不变性。&lt;h4&gt;5. 新方法ProtoCLR&lt;/h4&gt;   - 提出了一种原型对比学习（ProtoCLR），通过将样本与类原型进行比较，而不是成对比较，降低了SupCon损失的计算复杂性。&lt;h4&gt;6. 新基准测试&lt;/h4&gt;   - 提出了一个基于BirdSet的大规模鸟类声音数据集的新少量样本分类基准，展示了该方法的有效性。&lt;h4&gt;7. 性能表现&lt;/h4&gt;   - 实验结果表明，所提方法在实现强大的迁移性能方面表现良好。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Passive acoustic monitoring (PAM) is crucial for bioacoustic research,enabling non-invasive species tracking and biodiversity monitoring. Citizenscience platforms like Xeno-Canto provide large annotated datasets from focalrecordings, where the target species is intentionally recorded. However, PAMrequires monitoring in passive soundscapes, creating a domain shift betweenfocal and passive recordings, which challenges deep learning models trained onfocal recordings. To address this, we leverage supervised contrastive learningto improve domain generalization in bird sound classification, enforcing domaininvariance across same-class examples from different domains. We also proposeProtoCLR (Prototypical Contrastive Learning of Representations), which reducesthe computational complexity of the SupCon loss by comparing examples to classprototypes instead of pairwise comparisons. Additionally, we present a newfew-shot classification benchmark based on BirdSet, a large-scale bird sounddataset, and demonstrate the effectiveness of our approach in achieving strongtransfer performance.</description>
      <author>example@mail.com (Ilyass Moummad, Romain Serizel, Emmanouil Benetos, Nicolas Farrugia)</author>
      <guid isPermaLink="false">2409.08589v3</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Prompt Obfuscation for Large Language Models</title>
      <link>http://arxiv.org/abs/2409.11026v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 系统提示包含详细说明，用于描述基础大型语言模型（LLM）执行的任务，可以轻松将基础模型转化为工具和服务，且开销极小。&lt;h4&gt;2. 知识产权问题&lt;/h4&gt;   - 由于系统提示对实用性的重要影响，它们通常被视为知识产权，类似于软件产品的代码。&lt;h4&gt;3. 安全隐患&lt;/h4&gt;   - 通过提示注入（prompt injection）可以轻易提取系统提示，目前尚无有效的防护措施能够防止此类信息被窃取。&lt;h4&gt;4. 现有防护的不足&lt;/h4&gt;   - 所有保护措施可能被精心设计的提示注入绕过，导致防护无效。&lt;h4&gt;5. 提出的新方法&lt;/h4&gt;   - 本文提出了一种替代传统系统提示的方法——提示混淆（prompt obfuscation），旨在防止系统提示被提取，同时保持系统的实用性，开销极小。&lt;h4&gt;6. 核心理念&lt;/h4&gt;   - 找到一个与原始系统提示具有相同功能的表示形式，使得混淆后的系统提示不包含可以推导出原始提示的信息。&lt;h4&gt;7. 实现方法&lt;/h4&gt;   - 实现了一种基于优化的方法，寻找混淆提示的表示，同时保持其功能。&lt;h4&gt;8. 评估方法&lt;/h4&gt;   - 采用八种不同的指标比较使用原始和混淆系统提示的系统性能，结果显示混淆版本的性能与原始版本相当。&lt;h4&gt;9. 攻击测试&lt;/h4&gt;   - 进行了三种不同的去混淆攻击，结果表明，尽管可以访问混淆提示和LLM，但无法一致地提取出有意义的信息。&lt;h4&gt;10. 结论&lt;/h4&gt;    - 总体来看，提示混淆被证明是一种有效的方法，可以在保护知识产权的同时，保持与原始系统提示相同的实用性。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; System prompts that include detailed instructions to describe the taskperformed by the underlying large language model (LLM) can easily transformfoundation models into tools and services with minimal overhead. Because oftheir crucial impact on the utility, they are often considered intellectualproperty, similar to the code of a software product. However, extracting systemprompts is easily possible by using prompt injection. As of today, there is noeffective countermeasure to prevent the stealing of system prompts and allsafeguarding efforts could be evaded with carefully crafted prompt injectionsthat bypass all protection mechanisms. In this work, we propose an alternativeto conventional system prompts. We introduce prompt obfuscation to prevent theextraction of the system prompt while maintaining the utility of the systemitself with only little overhead. The core idea is to find a representation ofthe original system prompt that leads to the same functionality, while theobfuscated system prompt does not contain any information that allowsconclusions to be drawn about the original system prompt. We implement anoptimization-based method to find an obfuscated prompt representation whilemaintaining the functionality. To evaluate our approach, we investigate eightdifferent metrics to compare the performance of a system using the original andthe obfuscated system prompts, and we show that the obfuscated version isconstantly on par with the original one. We further perform three differentdeobfuscation attacks and show that with access to the obfuscated prompt andthe LLM itself, we are not able to consistently extract meaningful information.Overall, we showed that prompt obfuscation can be an effective method toprotect intellectual property while maintaining the same utility as theoriginal system prompt.</description>
      <author>example@mail.com (David Pape, Thorsten Eisenhofer, Lea Schönherr)</author>
      <guid isPermaLink="false">2409.11026v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Dual-Level Cross-Modal Contrastive Clustering</title>
      <link>http://arxiv.org/abs/2409.04561v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  We have found that our paper has many imperfections and incorrect
  formulas and derivations, and we insist on retracting the manuscript in order
  to avoid misleading readers.&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 图像聚类是无监督学习中的关键任务，涉及将图像分组到不同的聚类中，而无需标签。&lt;h4&gt;2. 现有方法的局限性&lt;/h4&gt;   - 以往的深度聚类方法虽然取得了显著成果，但仅探索图像自身的内在信息，忽视了外部监督知识对图像语义理解的提升。&lt;h4&gt;3. 新兴技术的应用&lt;/h4&gt;   - 最近，基于大规模数据集的视觉-语言预训练模型在各种下游任务中表现出色，但在视觉表示学习和文本语义学习之间仍存在差距。&lt;h4&gt;4. 挑战&lt;/h4&gt;   - 如何有效利用这两种不同模态的表示进行聚类仍然是一个重大挑战。&lt;h4&gt;5. 提出的框架&lt;/h4&gt;   - 本文提出了一种新颖的图像聚类框架，称为双层交叉模态对比聚类（DXMC）。&lt;h4&gt;6. 方法步骤&lt;/h4&gt;   - **引入外部文本信息**：构建一个语义空间，以生成图像-文本对。   - **编码处理**：将图像-文本对分别送入预训练的图像和文本编码器，获取图像和文本嵌入。   - **网络设计**：将嵌入分别输入四个精心设计的网络进行处理。   - **对比学习**：在不同模态和不同层次的区分表示之间进行双层交叉模态对比学习。&lt;h4&gt;7. 实验结果&lt;/h4&gt;   - 在五个基准数据集上的大量实验结果表明，所提出的方法在性能上具有优势。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Regan-Zhang/DXMC&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image clustering, which involves grouping images into different clusterswithout labels, is a key task in unsupervised learning. Although previous deepclustering methods have achieved remarkable results, they only explore theintrinsic information of the image itself but overlook external supervisionknowledge to improve the semantic understanding of images. Recently,visual-language pre-trained model on large-scale datasets have been used invarious downstream tasks and have achieved great results. However, there is agap between visual representation learning and textual semantic learning, andhow to properly utilize the representation of two different modalities forclustering is still a big challenge. To tackle the challenges, we propose anovel image clustering framwork, named Dual-level Cross-Modal ContrastiveClustering (DXMC). Firstly, external textual information is introduced forconstructing a semantic space which is adopted to generate image-text pairs.Secondly, the image-text pairs are respectively sent to pre-trained image andtext encoder to obtain image and text embeddings which subsquently are fed intofour well-designed networks. Thirdly, dual-level cross-modal contrastivelearning is conducted between discriminative representations of differentmodalities and distinct level. Extensive experimental results on five benchmarkdatasets demonstrate the superiority of our proposed method.</description>
      <author>example@mail.com (Haixin Zhang, Yongjun Li, Dong Huang)</author>
      <guid isPermaLink="false">2409.04561v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning for Analyzing Atomic Force Microscopy (AFM) Images Generated from Polymer Blends</title>
      <link>http://arxiv.org/abs/2409.11438v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  39 pages, 13 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt; &lt;h4&gt;1. 研究背景&lt;/h4&gt;   - 本文提出了一种新的机器学习工作流程，使用无监督学习技术识别来自聚合物薄膜的原子力显微镜（AFM）图像中的域。&lt;h4&gt;2. 研究目标&lt;/h4&gt;   - 工作流程旨在识别两种聚合物域的空间位置，尽量减少人工干预，并计算域大小分布，以帮助判断材料的相分离状态（宏相或微相有序或无序域）。&lt;h4&gt;3. 相关领域综述&lt;/h4&gt;   - 简要回顾了计算机视觉和信号处理领域中适用于上述任务的现有方法，这些方法在聚合物科学和工程领域中经常使用。&lt;h4&gt;4. 方法测试&lt;/h4&gt;   - 测试了来自计算机视觉和信号处理的多种方法在AFM图像数据集上的效果，识别每种方法的优缺点。&lt;h4&gt;5. 域分割任务&lt;/h4&gt;   - 在域分割任务中，使用离散傅里叶变换（DFT）或离散余弦变换（DCT）结合方差统计作为特征的工作流程表现最佳。   - 相比之下，计算机视觉领域流行的ResNet50深度学习方法在AFM图像的域分割任务中表现较差。&lt;h4&gt;6. 域大小分布计算&lt;/h4&gt;   - 对于第二个任务，使用现有的PoreSpy Python包，从DFT工作流程的输出中计算144个输入AFM图像的域大小分布。&lt;h4&gt;7. 研究贡献&lt;/h4&gt;   - 本文分享的信息和开源代码可为聚合物和软材料领域的研究人员提供指导，帮助其进行聚合物样本AFM图像的自动化分析，特别是针对可能具有结晶或非结晶域、域之间界面锋利或粗糙、以及微相或宏相分离域的情况。&lt;br&gt;&lt;br&gt;&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/arthijayaraman-lab/automated-atomic-force-microscopy-image-analysis&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper we present a new machine learning workflow with unsupervisedlearning techniques to identify domains within atomic force microscopy imagesobtained from polymer films. The goal of the workflow is to identify thespatial location of the two types of polymer domains with little to no manualintervention and calculate the domain size distributions which in turn can helpqualify the phase separated state of the material as macrophase or microphaseordered or disordered domains. We briefly review existing approaches used inother fields, computer vision and signal processing that can be applicable forthe above tasks that happen frequently in the field of polymer science andengineering. We then test these approaches from computer vision and signalprocessing on the AFM image dataset to identify the strengths and limitationsof each of these approaches for our first task. For our first domainsegmentation task, we found that the workflow using discrete Fourier transformor discrete cosine transform with variance statistics as the feature works thebest. The popular ResNet50 deep learning approach from computer vision fieldexhibited relatively poorer performance in the domain segmentation task for ourAFM images as compared to the DFT and DCT based workflows. For the second task,for each of 144 input AFM images, we then used an existing porespy pythonpackage to calculate the domain size distribution from the output of that imagefrom DFT based workflow. The information and open source codes we share in thispaper can serve as a guide for researchers in the polymer and soft materialsfields who need ML modeling and workflows for automated analyses of AFM imagesfrom polymer samples that may have crystalline or amorphous domains, sharp orrough interfaces between domains, or micro or macrophase separated domains.</description>
      <author>example@mail.com (Aanish Paruchuri, Yunfei Wang, Xiaodan Gu, Arthi Jayaraman)</author>
      <guid isPermaLink="false">2409.11438v2</guid>
      <pubDate>Mon, 30 Sep 2024 21:12:10 +0800</pubDate>
    </item>
  </channel>
</rss>
