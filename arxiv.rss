<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 18 Oct 2024 23:02:27 +0800</lastBuildDate>
    <item>
      <title>WT-CFormer: High-Performance Web Traffic Anomaly Detection Using CNN and Transformer Networks</title>
      <link>http://arxiv.org/abs/2410.10327v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Web流量（WT）是捕捉用户访问网站时与web服务器之间传输数据量的时间序列数据，异常流量信号表明数据的异常波动，因此检测异常至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究快速准确的Web流量异常检测方法，以提高分类效果和速度。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的异常检测模型WT-CFormer，利用Transformer高效提取Web流量的时间特征，结合CNN提取空间特征，以改善异常检测性能。&lt;h4&gt;主要发现&lt;/h4&gt;WT-CFormer在评估实验中表现最佳，召回率为96.79%，精确率为97.35%，F1分数为97.07%，准确率为99.43%，相较于当前最先进的方法有显著提升。&lt;h4&gt;结论&lt;/h4&gt;WT-CFormer在仅用50个训练周期时的分类性能优于C-LSTM在500个训练周期的表现，显著提升了收敛性能，同时通过消融实验证明了WT-CFormer各组成部分的必要性。&lt;h4&gt;总结&lt;/h4&gt;WT-CFormer是一种高效且准确的Web流量异常检测模型，具有良好的分类性能和快速收敛能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Web traffic (WT) refers to time-series data that captures the volume of datatransmitted to and from a web server during a user's visit to a website.Anomalies in web traffic signal unusual fluctuations in this data, making theirdetection crucial for ensuring network security. Deep neural network approachesfor web traffic anomaly detection have achieved cutting-edge classificationperformance. However, since these methods are still insufficient in terms ofclassification effectiveness and speed, researching fast and accurate anomalydetection methods is a challenging problem. In this paper, we propose a novelanomaly detection model (WT-CFormer) specifically designed for web traffic,which innovatively use the Transformer to efficiently and accurately extractthe temporal features of web traffic and deeply integrates the CNN to extractthe spatial features of web traffic to improve the anomaly detectionperformance. In addition, we conduct a large number of experiments to prove theeffectiveness and superiority of WT-CFormer for web traffic anomaly detection.In evaluation experiments, WT-CFormer has the highest performance, obtaining arecall as high as 96.79%, a precision of 97.35%, an F1 score of 97.07%, and anaccuracy of 99.43%, which is 7.09%,1.15%, 4.77%, and 0.83% better than thestate-of-the-art method, followed by C-LSTM, CTGA, random forest, and KNNalgorithms. In addition, we find that the classification performance ofWT-CFormer with only 50 training epochs outperforms C-LSTM with 500 trainingepochs, which greatly improves the convergence performance. Finally, we performablation experiments to demonstrate the necessity of each component withinWT-CFormer.</description>
      <author>example@mail.com (Yundi He, Runhua Shi)</author>
      <guid isPermaLink="false">2410.10327v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Learning Sub-Second Routing Optimization in Computer Networks requires Packet-Level Dynamics</title>
      <link>http://arxiv.org/abs/2410.10377v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Transactions of Machine Learning Research (TMLR) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在计算机网络中，为数据包寻找高效路由是一个重要任务，最佳路由受网络拓扑、状态和流量需求影响，并可能在毫秒内变化。&lt;h4&gt;目的&lt;/h4&gt;利用强化学习学习网络表示，为可能的新情况提供路由决策。&lt;h4&gt;方法&lt;/h4&gt;研究流体网络模型在毫秒级适应中的适宜性，提出了第一个基于数据包的强化学习环境PackeRL。&lt;h4&gt;主要发现&lt;/h4&gt;基于流体环境训练的学习策略在更现实但更具挑战性的环境中表现不佳，需要数据包级网络模型以捕捉真实动态，特别是在TCP流量存在的情况下。&lt;h4&gt;结论&lt;/h4&gt;引入M-Slim和FieldLines两种新算法，前者在高流量下表现优异但难以扩展，后者能在毫秒内重新优化任意网络拓扑的路由，无需重训练。&lt;h4&gt;性能比较&lt;/h4&gt;这两种算法在高流量场景中优于当前的学习型方法和常用的静态基线协议。&lt;h4&gt;实验验证&lt;/h4&gt;所有发现均通过在现实网络条件下的广泛实验进行验证，使用快速且多功能的训练和评估框架。&lt;h4&gt;总结&lt;/h4&gt;研究表明，数据包级模型及新算法在动态路由优化中具有显著优势，推动了网络路由策略的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Finding efficient routes for data packets is an essential task in computernetworking. The optimal routes depend greatly on the current network topology,state and traffic demand, and they can change within milliseconds.Reinforcement Learning can help to learn network representations that providerouting decisions for possibly novel situations. So far, this has commonly beendone using fluid network models. We investigate their suitability formillisecond-scale adaptations with a range of traffic mixes and find thatpacket-level network models are necessary to capture true dynamics, inparticular in the presence of TCP traffic. To this end, we present$\textit{PackeRL}$, the first packet-level Reinforcement Learning environmentfor routing in generic network topologies. Our experiments confirm thatlearning-based strategies that have been trained in fluid environments do notgeneralize well to this more realistic, but more challenging setup. Hence, wealso introduce two new algorithms for learning sub-second Routing Optimization.We present $\textit{M-Slim}$, a dynamic shortest-path algorithm that excels athigh traffic volumes but is computationally hard to scale to large networktopologies, and $\textit{FieldLines}$, a novel next-hop policy design thatre-optimizes routing for any network topology within milliseconds withoutrequiring any re-training. Both algorithms outperform current learning-basedapproaches as well as commonly used static baseline protocols in scenarios withhigh-traffic volumes. All findings are backed by extensive experiments inrealistic network conditions in our fast and versatile training and evaluationframework.</description>
      <author>example@mail.com (Andreas Boltres, Niklas Freymuth, Patrick Jahnke, Holger Karl, Gerhard Neumann)</author>
      <guid isPermaLink="false">2410.10377v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Spatial-Temporal Bearing Fault Detection Using Graph Attention Networks and LSTM</title>
      <link>http://arxiv.org/abs/2410.11923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;工业机械中的轴承故障诊断面临挑战，需要提高准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合图注意力网络（GAT）和长短期记忆网络（LSTM）的方法，以增强轴承故障诊断。&lt;h4&gt;方法&lt;/h4&gt;将时间序列传感器数据转换为图表示，GAT捕捉组件间的空间关系，LSTM建模时间模式。使用Case Western Reserve University（CWRU）轴承数据集进行验证，并与多种传统方法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;模型在各种测试条件下的准确率、召回率和F1分数均达到100%。能够准确识别故障，并在不同操作场景中有效泛化，优于传统方法。&lt;h4&gt;结论&lt;/h4&gt;研究展示了GAT与LSTM结合在故障检测中的独特性，克服了传统时间序列方法的局限性，具有显著的工业预测维护潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究为轴承故障检测提供了一种创新方法，具有高准确性和广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: This paper aims to enhance bearing fault diagnosis in industrialmachinery by introducing a novel method that combines Graph Attention Network(GAT) and Long Short-Term Memory (LSTM) networks. This approach captures bothspatial and temporal dependencies within sensor data, improving the accuracy ofbearing fault detection under various conditions. Methodology: The proposedmethod converts time series sensor data into graph representations. GATcaptures spatial relationships between components, while LSTM models temporalpatterns. The model is validated using the Case Western Reserve University(CWRU) Bearing Dataset, which includes data under different horsepower levelsand both normal and faulty conditions. Its performance is compared with methodssuch as K-Nearest Neighbors (KNN), Local Outlier Factor (LOF), Isolation Forest(IForest) and GNN-based method for bearing fault detection (GNNBFD). Findings:The model achieved outstanding results, with precision, recall, and F1-scoresreaching 100\% across various testing conditions. It not only identifies faultsaccurately but also generalizes effectively across different operationalscenarios, outperforming traditional methods. Originality: This researchpresents a unique combination of GAT and LSTM for fault detection, overcomingthe limitations of traditional time series methods by capturing complexspatial-temporal dependencies. Its superior performance demonstratessignificant potential for predictive maintenance in industrial applications.</description>
      <author>example@mail.com (Moirangthem Tiken Singh, Rabinder Kumar Prasad, Gurumayum Robert Michael, N. Hemarjit Singh, N. K. Kaphungkui)</author>
      <guid isPermaLink="false">2410.11923v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Cooperative nonlinear distributed model predictive control with dissimilar control horizons</title>
      <link>http://arxiv.org/abs/2410.10428v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列预测仍然是一个具有挑战性的任务，尤其是在复杂的多尺度时间模式下。&lt;h4&gt;目的&lt;/h4&gt;提出LLM-Mixer框架，以提高预测准确性。&lt;h4&gt;方法&lt;/h4&gt;通过多尺度时间序列分解与预训练大语言模型（LLMs）相结合，处理短期波动和长期趋势。&lt;h4&gt;主要发现&lt;/h4&gt;在多变量和单变量数据集上的广泛实验表明，LLM-Mixer的性能具有竞争力，超越了最近的先进模型。&lt;h4&gt;结论&lt;/h4&gt;结合多尺度分析和LLMs在有效和可扩展的时间序列预测中具有潜力。&lt;h4&gt;总结&lt;/h4&gt;LLM-Mixer框架通过创新性的方法提升了时间序列预测的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a nonlinear distributed model predictive control(DMPC) algorithm, which allows for dissimilar and time-varying control horizonsamong agents, thereby addressing a common limitation in current DMPC schemes.We consider cooperative agents with varying computational capabilities andoperational objectives, each willing to manage varying numbers of optimizationvariables at each time step. Recursive feasibility and a non-increasingevolution of the optimal cost are proven for the proposed algorithm. Throughnumerical simulations on systems with three agents, we show that our approacheffectively approximates the performance of traditional DMPC, while reducingthe number of variables to be optimized. This advancement paves the way for amore decentralized yet coordinated control strategy in various applications,including power systems and traffic management.</description>
      <author>example@mail.com (Paula Chanfreut, José M. Maestre, Quanyan Zhu, W. P. M. H. Heemels)</author>
      <guid isPermaLink="false">2410.10428v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.11674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Time series forecasting using LLMs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在许多现实世界的路由问题中，决策者需要优化稀疏图，如不满足三角不等式的交通网络。&lt;h4&gt;目的&lt;/h4&gt;研究在稀疏图上具有非度量成本的奖赏收集旅行商问题（Pc-TSP），以寻找最小化跑步者空气污染暴露的长跑路线。&lt;h4&gt;方法&lt;/h4&gt;引入针对具有非度量成本函数的稀疏图的启发式方法，以及开发一种新的分支与切割算法，称为不相交路径成本覆盖（DPCC）切割。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的启发式方法能够提供比文献中最先进的启发式方法更低成本的可行解；在非度量成本函数的数据集上，DPCC切割算法的解决能力优于基线切割算法。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在处理稀疏图和非度量成本的情况下，能够有效提高解决方案的质量和效率。&lt;h4&gt;总结&lt;/h4&gt;本研究为优化稀疏图上的奖赏收集旅行商问题提供了新的方法和见解，具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Kowsher/LLMMixer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting remains a challenging task, particularly in thecontext of complex multiscale temporal patterns. This study presents LLM-Mixer,a framework that improves forecasting accuracy through the combination ofmultiscale time-series decomposition with pre-trained LLMs (Large LanguageModels). LLM-Mixer captures both short-term fluctuations and long-term trendsby decomposing the data into multiple temporal resolutions and processing themwith a frozen LLM, guided by a textual prompt specifically designed fortime-series data. Extensive experiments conducted on multivariate andunivariate datasets demonstrate that LLM-Mixer achieves competitiveperformance, outperforming recent state-of-the-art models across variousforecasting horizons. This work highlights the potential of combiningmultiscale analysis and LLMs for effective and scalable time-seriesforecasting.</description>
      <author>example@mail.com (Md Kowsher, Md. Shohanur Islam Sobuj, Nusrat Jahan Prottasha, E. Alejandro Alanis, Ozlem Ozmen Garibay, Niloofar Yousefi)</author>
      <guid isPermaLink="false">2410.11674v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Routing on Sparse Graphs with Non-metric Costs for the Prize-collecting Travelling Salesperson Problem</title>
      <link>http://arxiv.org/abs/2410.10440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ATT'24: Workshop Agents in Traffic and Transportation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "本研究首次探讨了时间序列基础模型在VaR估计中的应用。",
    "目的": "比较Google的TimesFM模型与传统参数和非参数模型在VaR估计中的表现。",
    "方法": "使用S&amp;P 100指数及其成分股的19年每日收益数据进行回测，比较TimesFM与GARCH、GAS及经验分位数估计。",
    "主要发现": "经过微调的TimesFM模型在实际与预期比率方面始终优于传统方法，其在分位数损失函数上的表现与最佳计量经济学方法GAS模型相当。",
    "结论": "基础模型在0.01、0.025、0.05和0.1 VaR水平的预测中表现最佳或居于前列，微调显著提高了结果，不应在零-shot设置中使用。",
    "挑战": "尽管基础模型提供了与传统计量经济学方法完全不同的替代方法，但仍面临一些挑战。",
    "总结": "基础模型在VaR预测中展现出优越性，值得进一步探索其应用潜力。```json
{
    "背景": "本研究首次探讨了时间序列基础模型在VaR估计中的应用。",
    "目的": "比较Google的TimesFM模型与传统参数和非参数模型在VaR估计中的表现。",
    "方法": "使用S&amp;P 100指数及其成分股的19年每日收益数据进行回测，比较TimesFM与GARCH、GAS及经验分位数估计。",
    "主要发现": "经过微调的TimesFM模型在实际与预期比率方面始终优于传统方法，其在分位数损失函数上的表现与最佳计量经济学方法GAS模型相当。",
    "结论": "基础模型在0.01、0.025、0.05和0.1 VaR水平的预测中表现最佳或居于前列，微调显著提高了结果，不应在零-shot设置中使用。",
    "挑战": "尽管基础模型提供了与传统计量经济学方法完全不同的替代方法，但仍面临一些挑战。",
    "总结": "基础模型在VaR预测中展现出优越性，值得进一步探索其应用潜力。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many real-world routing problems, decision makers must optimise oversparse graphs such as transportation networks with non-metric costs on theedges that do not obey the triangle inequality. Motivated by finding asufficiently long running route in a city that minimises the air pollutionexposure of the runner, we study the Prize-collecting Travelling SalespersonProblem (Pc-TSP) on sparse graphs with non-metric costs. Given an undirectedgraph with a cost function on the edges and a prize function on the vertices,the goal of Pc-TSP is to find a tour rooted at the origin that minimises thetotal cost such that the total prize is at least some quota. First, weintroduce heuristics designed for sparse graphs with non-metric cost functionswhere previous work dealt with either a complete graph or a metric costfunction. Next, we develop a branch &amp; cut algorithm that employs a new cut wecall the disjoint-paths cost-cover (DPCC) cut. Empirical experiments on twodatasets show that our heuristics can produce a feasible solution with lesscost than a state-of-the-art heuristic from the literature. On datasets withnon-metric cost functions, DPCC is found to solve more instances to optimalitythan the baseline cutting algorithm we compare against.</description>
      <author>example@mail.com (Patrick O'Hara, M. S. Ramanujan, Theodoros Damoulas)</author>
      <guid isPermaLink="false">2410.10440v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Time-Series Foundation Model for Value-at-Risk</title>
      <link>http://arxiv.org/abs/2410.11773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列预测（TSF）在金融、天气服务和能源管理等多个领域中具有重要功能，现有方法普遍存在对特定领域数据要求高和在新领域上泛化性能差的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的基准FoundTS，以便对新兴的TSF基础模型进行全面、公正的评估和比较。&lt;h4&gt;方法&lt;/h4&gt;FoundTS涵盖多种TSF基础模型，支持零-shot、少-shot和全-shot等不同预测策略，并提供标准化的评估流程，包括数据集拆分、加载、归一化和少-shot采样。&lt;h4&gt;主要发现&lt;/h4&gt;对广泛数据集进行的评估揭示了现有基础模型的优缺点及其固有限制，并指出未来模型设计的方向。&lt;h4&gt;结论&lt;/h4&gt;FoundTS为不同领域和统计特征的数据集提供了一个评估平台，促进了对TSF基础模型的公正评估。&lt;h4&gt;总结&lt;/h4&gt;我们将代码和数据集公开，以支持研究社区对TSF模型的进一步探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/anubha0812/timesfm-for-value-at-risk&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study is the first to explore the application of a time-seriesfoundation model for VaR estimation. Foundation models, pre-trained on vast andvaried datasets, can be used in a zero-shot setting with relatively minimaldata or further improved through finetuning. We compare the performance ofGoogle's model, called TimesFM, against conventional parametric andnon-parametric models, including GARCH, Generalized Autoregressive Score (GAS),and empirical quantile estimates, using daily returns from the S\&amp;P 100 indexand its constituents over 19 years. Our backtesting results indicate that, interms of the actual-over-expected ratio, the fine-tuned TimesFM modelconsistently outperforms traditional methods. Regarding the quantile score lossfunction, it achieves performance comparable to the best econometric approach,the GAS model. Overall, the foundation model is either the best or among thetop performers in forecasting VaR across the 0.01, 0.025, 0.05, and 0.1 VaRlevels. We also found that fine-tuning significantly improves the results, andthe model should not be used in zero-shot settings. Overall, foundation modelscan provide completely alternative approaches to traditional econometricmethods, yet there are challenges to be tackled.</description>
      <author>example@mail.com (Anubha Goel, Puneet Pasricha, Juho Kanniainen)</author>
      <guid isPermaLink="false">2410.11773v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.11802v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代人工智能的发展促进了自动化、计算机视觉、欺诈检测等多个领域的进步。&lt;h4&gt;目的&lt;/h4&gt;提出一个利用人工智能改善交通流量的自主智能交通管理系统。&lt;h4&gt;方法&lt;/h4&gt;系统采用YOLO V5卷积神经网络检测交通管理图像中的车辆，并使用长短期记忆的递归神经网络(RNN-LSTM)预测未来12小时的车辆数量。&lt;h4&gt;主要发现&lt;/h4&gt;{'预测结果': {'均方误差': 4.521, '均方根误差': 2.232}, '仿真结果': {'有STM的交通管理拥堵流量': '每分钟21辆，较无STM时高出50%', '有STM的车辆通行延迟': '每辆车5秒，较无STM时降低70%'}}&lt;h4&gt;结论&lt;/h4&gt;使用人工智能的自主智能交通管理系统能够提高交通流量50%并减少车辆通行延迟70%。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了AI在交通管理中的有效应用，能够显著改善交通效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time Series Forecasting (TSF) is key functionality in numerous fields,including in finance, weather services, and energy management. While TSFmethods are emerging these days, many of them require domain-specific datacollection and model training and struggle with poor generalization performanceon new domains. Foundation models aim to overcome this limitation. Pre-trainedon large-scale language or time series data, they exhibit promising inferencingcapabilities in new or unseen data. This has spurred a surge in new TSFfoundation models. We propose a new benchmark, FoundTS, to enable thorough andfair evaluation and comparison of such models. FoundTS covers a variety of TSFfoundation models, including those based on large language models and thosepretrained on time series. Next, FoundTS supports different forecastingstrategies, including zero-shot, few-shot, and full-shot, thereby facilitatingmore thorough evaluations. Finally, FoundTS offers a pipeline that standardizesevaluation processes such as dataset splitting, loading, normalization, andfew-shot sampling, thereby facilitating fair evaluations. Building on this, wereport on an extensive evaluation of TSF foundation models on a broad range ofdatasets from diverse domains and with different statistical characteristics.Specifically, we identify pros and cons and inherent limitations of existingfoundation models, and we identify directions for future model design. We makeour code and datasets available athttps://anonymous.4open.science/r/FoundTS-C2B0.</description>
      <author>example@mail.com (Zhe Li, Xiangfei Qiu, Peng Chen, Yihang Wang, Hanyin Cheng, Yang Shu, Jilin Hu, Chenjuan Guo, Aoying Zhou, Qingsong Wen, Christian S. Jensen, Bin Yang)</author>
      <guid isPermaLink="false">2410.11802v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ASTM :Autonomous Smart Traffic Management System Using Artificial Intelligence CNN and LSTM</title>
      <link>http://arxiv.org/abs/2410.10929v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In process to IEEE Intelligent Vehicle Symposium 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代人工智能的发展促进了自动化、计算机视觉、欺诈检测等多个领域的进步。&lt;h4&gt;目的&lt;/h4&gt;提出一个利用人工智能改善交通流量的自主智能交通管理系统。&lt;h4&gt;方法&lt;/h4&gt;ExoTST利用注意力机制的优势，并引入了一种新的跨时间模态融合模块，使模型能够共同学习过去和当前的外生序列，将其视为不同的模态。&lt;h4&gt;主要发现&lt;/h4&gt;ExoTST在处理历史与当前外生变量之间的分布变化不确定性方面提供了更强的鲁棒性和灵活性，并在真实世界的碳通量数据集和时间序列基准测试中表现优越，预测准确率提高了10%。&lt;h4&gt;结论&lt;/h4&gt;ExoTST在面对缺失值和外生驱动噪声时表现出良好的鲁棒性，能够在实际情境中保持一致的性能，适应常见的不完美情况。&lt;h4&gt;总结&lt;/h4&gt;ExoTST是一种有效的时间序列预测工具，通过创新的方法提升了预测准确性和鲁棒性，适应了多种实际应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the modern world, the development of Artificial Intelligence (AI) hascontributed to improvements in various areas, including automation, computervision, fraud detection, and more. AI can be leveraged to enhance theefficiency of Autonomous Smart Traffic Management (ASTM) systems and reducetraffic congestion rates. This paper presents an Autonomous Smart TrafficManagement (STM) system that uses AI to improve traffic flow rates. The systememploys the YOLO V5 Convolutional Neural Network to detect vehicles in trafficmanagement images. Additionally, it predicts the number of vehicles for thenext 12 hours using a Recurrent Neural Network with Long Short-Term Memory(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages thetraffic cycle length based on these vehicle predictions, aided by AI. From theresults of the RNN-LSTM model for predicting vehicle numbers over the next 12hours, we observe that the model predicts traffic with a Mean Squared Error(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.After simulating the STM system in the CARLA simulation environment, we foundthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles perminute) is 50\% higher than the rate without STM (around 15 vehicles perminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5seconds per vehicle) is 70\% lower than without STM (around 12 seconds pervehicle). These results demonstrate that the STM system using AI can increasetraffic flow by 50\% and reduce vehicle pass delays by 70\%.</description>
      <author>example@mail.com (Christofel Rio Goenawan)</author>
      <guid isPermaLink="false">2410.10929v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ExoTST: Exogenous-Aware Temporal Sequence Transformer for Time Series Prediction</title>
      <link>http://arxiv.org/abs/2410.12184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICDM 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的长期预测是许多机器学习应用和决策过程的基础。传统的时间序列预测方法通常只关注自回归建模或仅考虑当前外生变量。&lt;h4&gt;目的&lt;/h4&gt;提出ExoTST，一种新型基于变换器的框架，旨在有效整合当前外生变量与过去的内生和外生变量，以提高时间序列预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;ExoTST利用注意力机制的优势，并引入了一种新的跨时间模态融合模块，使模型能够共同学习过去和当前的外生序列，将其视为不同的模态。&lt;h4&gt;主要发现&lt;/h4&gt;ExoTST在处理历史与当前外生变量之间的分布变化不确定性方面提供了更强的鲁棒性和灵活性，并在真实世界的碳通量数据集和时间序列基准测试中表现优越，预测准确率提高了10%。&lt;h4&gt;结论&lt;/h4&gt;ExoTST在面对缺失值和外生驱动噪声时表现出良好的鲁棒性，能够在实际情境中保持一致的性能，适应常见的不完美情况。&lt;h4&gt;总结&lt;/h4&gt;ExoTST是一种有效的时间序列预测工具，通过创新的方法提升了预测准确性和鲁棒性，适应了多种实际应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate long-term predictions are the foundations for many machine learningapplications and decision-making processes. Traditional time series approachesfor prediction often focus on either autoregressive modeling, which reliessolely on past observations of the target ``endogenous variables'', or forwardmodeling, which considers only current covariate drivers ``exogenousvariables''. However, effectively integrating past endogenous and pastexogenous with current exogenous variables remains a significant challenge. Inthis paper, we propose ExoTST, a novel transformer-based framework thateffectively incorporates current exogenous variables alongside past context forimproved time series prediction. To integrate exogenous informationefficiently, ExoTST leverages the strengths of attention mechanisms andintroduces a novel cross-temporal modality fusion module. This module enablesthe model to jointly learn from both past and current exogenous series,treating them as distinct modalities. By considering these series separately,ExoTST provides robustness and flexibility in handling data uncertainties thatarise from the inherent distribution shift between historical and currentexogenous variables. Extensive experiments on real-world carbon flux datasetsand time series benchmarks demonstrate ExoTST's superior performance comparedto state-of-the-art baselines, with improvements of up to 10\% in predictionaccuracy. Moreover, ExoTST exhibits strong robustness against missing valuesand noise in exogenous drivers, maintaining consistent performance inreal-world situations where these imperfections are common.</description>
      <author>example@mail.com (Kshitij Tayal, Arvind Renganathan, Xiaowei Jia, Vipin Kumar, Dan Lu)</author>
      <guid isPermaLink="false">2410.12184v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Anisotropic Stiffness and Programmable Actuation for Soft Robots Enabled by an Inflated Rotational Joint</title>
      <link>http://arxiv.org/abs/2410.13003v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;软体机器人因其适应性强而受到关注，具有分布式、非均匀的刚度和致动特性。&lt;h4&gt;目的&lt;/h4&gt;研究如何制造具有可调性能的稳健且易于制造的软性弯曲关节。&lt;h4&gt;方法&lt;/h4&gt;提出了一种可膨胀的致动模块，通过强制部分皱褶来定义弯曲平面，从而降低结构在弯曲方向的刚度。&lt;h4&gt;主要发现&lt;/h4&gt;通过皱褶和未皱褶区域的比例，可以轻松设计最终的刚度，且模块在多种载荷条件下能够保持运动约束。&lt;h4&gt;结论&lt;/h4&gt;该模块显示了在软连续机器人中实现复杂致动的潜力，并能够将致动力和效率与负载能力解耦。&lt;h4&gt;总结&lt;/h4&gt;该模块为软气动机器人嵌入智能致动提供了一种新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft robots are known for their ability to perform tasks with greatadaptability, enabled by their distributed, non-uniform stiffness andactuation. Bending is the most fundamental motion for soft robot design, butcreating robust, and easy-to-fabricate soft bending joint with tunableproperties remains an active problem of research. In this work, we demonstratean inflatable actuation module for soft robots with a defined bending planeenabled by forced partial wrinkling. This lowers the structural stiffness inthe bending direction, with the final stiffness easily designed by the ratio ofwrinkled and unwrinkled regions. We present models and experimentalcharacterization showing the stiffness properties of the actuation module, aswell as its ability to maintain the kinematic constraint over a large range ofloading conditions. We demonstrate the potential for complex actuation in asoft continuum robot and for decoupling actuation force and efficiency fromload capacity. The module provides a novel method for embedding intelligentactuation into soft pneumatic robots.</description>
      <author>example@mail.com (Sicheng Wang, Eugenio Frias-Miranda, Antonio Alvarez Valdivia, Laura H. Blumenschein)</author>
      <guid isPermaLink="false">2410.13003v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>V2I-Calib++: A Multi-terminal Spatial Calibration Approach in Urban Intersections for Collaborative Perception</title>
      <link>http://arxiv.org/abs/2410.11008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;城市交叉口因行人和车辆密集以及高楼大厦导致的GPS信号遮挡，成为城市交通系统中最具挑战性的区域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多端LiDAR系统校准方法，以解决传统方法在城市峡谷中面临的GPS信号不稳定问题。&lt;h4&gt;方法&lt;/h4&gt;新方法不依赖于定位先验来确定初始外部参数，结合全球一致性搜索算法和最优运输理论，引入了一种新的整体距离度量（oDist）来测量感知对象之间的空间关联。&lt;h4&gt;主要发现&lt;/h4&gt;通过对V2X-Sim和DAIR-V2X真实数据集进行的广泛比较和消融实验，验证了该方法的有效性和效率。&lt;h4&gt;结论&lt;/h4&gt;所提出的多端LiDAR系统校准方法能够满足实时要求，并有效提取共观察目标以进行外部参数计算和优化。&lt;h4&gt;代码链接&lt;/h4&gt;https://github.com/MassimoQu/v2i-calib&lt;h4&gt;总结&lt;/h4&gt;该研究为城市交通系统中的多端感知提供了一种新颖的校准解决方案，克服了GPS信号不稳定带来的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/massimoqu/v2i-calib&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban intersections, dense with pedestrian and vehicular traffic andcompounded by GPS signal obstructions from high-rise buildings, are among themost challenging areas in urban traffic systems. Traditional single-vehicleintelligence systems often perform poorly in such environments due to a lack ofglobal traffic flow information and the ability to respond to unexpectedevents. Vehicle-to-Everything (V2X) technology, through real-time communicationbetween vehicles (V2V) and vehicles to infrastructure (V2I), offers a robustsolution. However, practical applications still face numerous challenges.Calibration among heterogeneous vehicle and infrastructure endpoints inmulti-end LiDAR systems is crucial for ensuring the accuracy and consistency ofperception system data. Most existing multi-end calibration methods rely oninitial calibration values provided by positioning systems, but the instabilityof GPS signals due to high buildings in urban canyons poses severe challengesto these methods. To address this issue, this paper proposes a novel multi-endLiDAR system calibration method that does not require positioning priors todetermine initial external parameters and meets real-time requirements. Ourmethod introduces an innovative multi-end perception object associationtechnique, utilizing a new Overall Distance metric (oDist) to measure thespatial association between perception objects, and effectively combines globalconsistency search algorithms with optimal transport theory. By this means, wecan extract co-observed targets from object association results for furtherexternal parameter computation and optimization. Extensive comparative andablation experiments conducted on the simulated dataset V2X-Sim and the realdataset DAIR-V2X confirm the effectiveness and efficiency of our method. Thecode for this method can be accessed at:\url{https://github.com/MassimoQu/v2i-calib}.</description>
      <author>example@mail.com (Qianxin Qu, Xinyu Zhang, Yijin Xiong, Shichun Guo, Ziqiang Song, Jun Li)</author>
      <guid isPermaLink="false">2410.11008v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Abnormality Forecasting: Time Series Anomaly Prediction via Future Context Modeling</title>
      <link>http://arxiv.org/abs/2410.12206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 5 figures, submitted to KDD conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列数据中的异常检测对于基础设施安全、智能运营维护和太空探索等多个领域至关重要。目前的研究主要集中在异常发生后进行检测，这可能导致重大财务或声誉损失及基础设施损坏。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在探讨时间序列异常预测问题，提供在异常事件发生之前的早期预警。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新颖的原则性方法，即未来上下文建模（FCM），通过分析观察窗口与正常数据之间的细微差异来准确预测目标窗口中的未来异常事件。&lt;h4&gt;主要发现&lt;/h4&gt;FCM利用长期预测模型生成具有辨别性的未来上下文，并通过建模观察数据与预测未来上下文的正常性关联，增强了异常性预测的能力。实验结果显示，FCM在多个数据集上获得了超过70%的良好召回率，并在F1分数上显著优于所有基线。&lt;h4&gt;结论&lt;/h4&gt;FCM提供了一种有效的时间序列异常预测方法，能够在多个数据集上实现优异的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的FCM方法为时间序列异常预测提供了新的视角和有效的解决方案，具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Identifying anomalies from time series data plays an important role invarious fields such as infrastructure security, intelligent operation andmaintenance, and space exploration. Current research focuses on detecting theanomalies after they occur, which can lead to significant financial/reputationloss or infrastructure damage. In this work we instead study a more practicalyet very challenging problem, time series anomaly prediction, aiming atproviding early warnings for abnormal events before their occurrence. To tacklethis problem, we introduce a novel principled approach, namely future contextmodeling (FCM). Its key insight is that the future abnormal events in a targetwindow can be accurately predicted if their preceding observation windowexhibits any subtle difference to normal data. To effectively capture suchdifferences, FCM first leverages long-term forecasting models to generate adiscriminative future context based on the observation data, aiming to amplifythose subtle but unusual difference. It then models a normality correlation ofthe observation data with the forecasting future context to complement thenormality modeling of the observation data in foreseeing possible abnormalityin the target window. A joint variate-time attention learning is alsointroduced in FCM to leverage both temporal signals and features of the timeseries data for more discriminative normality modeling in the aforementionedtwo views. Comprehensive experiments on five datasets demonstrate that FCMgains good recall rate (70\%+) on multiple datasets and significantlyoutperforms all baselines in F1 score. Code is available athttps://github.com/mala-lab/FCM.</description>
      <author>example@mail.com (Sinong Zhao, Wenrui Wang, Hongzuo Xu, Zhaoyang Yu, Qingsong Wen, Gang Wang, xiaoguang Liu, Guansong Pang)</author>
      <guid isPermaLink="false">2410.12206v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>GyroCopter: Differential Bearing Measuring Trajectory Planner for Tracking and Localizing Radio Frequency Sources</title>
      <link>http://arxiv.org/abs/2410.13081v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  For a demonstration video, see https://youtu.be/OkmmQjD74Us&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主航空器可以有效解决无线电频率（RF）源追踪和定位问题，应用范围包括野生动物保护和搜救行动。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法GyroCopter，旨在提高RF源追踪的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;规划多旋翼无人机的飞行轨迹，利用飞行动态执行恒定旋转运动以获得“伪方位”测量。&lt;h4&gt;主要发现&lt;/h4&gt;旋转基础的伪方位方法显著减少了与现场旋转方位测量相关的限制，同时利用简单、低成本和轻量级的信号强度测量硬件来估算方位。&lt;h4&gt;结论&lt;/h4&gt;该方法通过消除额外硬件需求，保持了简洁、轻便和成本效益，经过广泛的模拟和实地测试验证了其有效性。&lt;h4&gt;总结&lt;/h4&gt;GyroCopter展示了作为一种快速和实用的RF源定位解决方案的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous aerial vehicles can provide efficient and effective solutions forradio frequency (RF) source tracking and localizing problems with applicationsranging from wildlife conservation to search and rescue operations. Existinglightweight, low-cost, bearing measurements-based methods with a singleantenna-receiver sensor system configurations necessitate in situ rotations,leading to substantial measurement acquisition times restricting searchableareas and number of measurements. We propose a GyroCopter for the task. Ourapproach plans the trajectory of a multi-rotor unmanned aerial vehicle (UAV)whilst utilizing UAV flight dynamics to execute a constant gyration motion toderive "pseudo-bearing" measurements to track RF sources. The gyration-basedpseudo-bearing approach: i) significantly reduces the limitations associatedwith in situ rotation bearing; while ii) capitalizing on the simplicity,affordability, and lightweight nature of signal strength measurementacquisition hardware to estimate bearings. This method distinguishes itselffrom other pseudo-bearing approaches by eliminating the need for additionalhardware to maintain simplicity, lightweightness and cost-effectiveness. Tovalidate our approach, we derived the optimal rotation speed and conductedextensive simulations and field missions with our GyroCopter to track andlocalize multiple RF sources. The results confirm the effectiveness of ourmethod, highlighting its potential as a practical and rapid solution for RFsource localization tasks.</description>
      <author>example@mail.com (Fei Chen, S. Hamid Rezatofighi, Damith C. Ranasinghe)</author>
      <guid isPermaLink="false">2410.13081v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Routing and Scheduling Optimization for Urban Air Mobility Fleet Management using Quantum Annealing</title>
      <link>http://arxiv.org/abs/2410.11231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;城市空中出行（UAM）在城市交通和配送中的整合日益加速，主要由于交通拥堵及其环境和经济影响。&lt;h4&gt;目的&lt;/h4&gt;高效管理城市中预期的高密度空中交通，以确保安全和有效的运营。&lt;h4&gt;方法&lt;/h4&gt;提出一个路由和调度框架，使用数学优化技术为大型UAM车辆队伍规划高效且无冲突的路线。&lt;h4&gt;主要发现&lt;/h4&gt;将路线规划公式化为最大加权独立集问题，利用各种算法和专业优化硬件（如量子退火器）进行优化。&lt;h4&gt;结论&lt;/h4&gt;通过在新加坡的空域交通管理模拟器中验证方法，增强了空域利用率，并促进了地区交通的分布。&lt;h4&gt;总结&lt;/h4&gt;本研究拓宽了优化技术在UAM交通管理中的潜在应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing integration of urban air mobility (UAM) for urban transportationand delivery has accelerated due to increasing traffic congestion and itsenvironmental and economic repercussions. Efficiently managing the anticipatedhigh-density air traffic in cities is critical to ensure safe and effectiveoperations. In this study, we propose a routing and scheduling framework toaddress the needs of a large fleet of UAM vehicles operating in urban areas.Using mathematical optimization techniques, we plan efficient and deconflictedroutes for a fleet of vehicles. Formulating route planning as a maximumweighted independent set problem enables us to utilize various algorithms andspecialized optimization hardware, such as quantum annealers, which has seensubstantial progress in recent years. Our method is validated using a trafficmanagement simulator tailored for the airspace in Singapore. Our approachenhances airspace utilization by distributing traffic throughout a region. Thisstudy broadens the potential applications of optimization techniques in UAMtraffic management.</description>
      <author>example@mail.com (Renichiro Haba, Takuya Mano, Ryosuke Ueda, Genichiro Ebe, Kohei Takeda, Masayoshi Terabe, Masayuki Ohzeki)</author>
      <guid isPermaLink="false">2410.11231v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Irregularity-Informed Time Series Analysis: Adaptive Modelling of Spatial and Temporal Dynamics</title>
      <link>http://arxiv.org/abs/2410.12257v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;不规则时间序列数据（IRTS）在实际应用中越来越普遍，分为自然不规则时间序列（NIRTS）和意外不规则时间序列（AIRTS）。&lt;h4&gt;目的&lt;/h4&gt;提出一个新型的基于变换器的框架，充分利用IRTS数据的潜力。&lt;h4&gt;方法&lt;/h4&gt;从局部性、时间、空间和不规则性四个视角处理IRTS，并设计不规则性门控机制以自适应选择与任务相关的信息。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在三个缺失比率高的数据集上表现出强大的抗性，并通过消融研究验证了不规则性信息对NIRTS和AIRTS的重要性。&lt;h4&gt;结论&lt;/h4&gt;该方法提高了对各种IRTS数据的泛化能力，并有效利用了不规则性信息。&lt;h4&gt;总结&lt;/h4&gt;我们在GitHub上发布了实现，促进了不规则时间序列数据的研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Irregular Time Series Data (IRTS) has shown increasing prevalence inreal-world applications. We observed that IRTS can be divided into twospecialized types: Natural Irregular Time Series (NIRTS) and AccidentalIrregular Time Series (AIRTS). Various existing methods either ignore theimpacts of irregular patterns or statically learn the irregular dynamics ofNIRTS and AIRTS data and suffer from limited data availability due to thesparsity of IRTS. We proposed a novel transformer-based framework for generalirregular time series data that treats IRTS from four views: Locality, Time,Spatio and Irregularity to motivate the data usage to the highest potential.Moreover, we design a sophisticated irregularity-gate mechanism to adaptivelyselect task-relevant information from irregularity, which improves thegeneralization ability to various IRTS data. We implement extensive experimentsto demonstrate the resistance of our work to three highly missing ratiodatasets (88.4\%, 94.9\%, 60\% missing value) and investigate the significanceof the irregularity information for both NIRTS and AIRTS by additional ablationstudy. We release our implementation inhttps://github.com/IcurasLW/MTSFormer-Irregular_Time_Series.git</description>
      <author>example@mail.com (Liangwei Nathan Zheng, Zhengyang Li, Chang George Dong, Wei Emma Zhang, Lin Yue, Miao Xu, Olaf Maennel, Weitong Chen)</author>
      <guid isPermaLink="false">2410.12257v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Modelling advection on distance-weighted directed networks</title>
      <link>http://arxiv.org/abs/2410.11352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究描述在距离加权有向图上的对流动态。&lt;h4&gt;目的&lt;/h4&gt;提出一个模型来描述对流的动力学特征。&lt;h4&gt;方法&lt;/h4&gt;建立一组离散对流算子应满足的关键性质或公理，并证明存在一个基本唯一的算子满足这些性质。&lt;h4&gt;主要发现&lt;/h4&gt;考虑了无限和有限网络，以及可能的变体和扩展。&lt;h4&gt;结论&lt;/h4&gt;通过分析和数值示例展示了所提模型，并描述了其在交通网络模拟中的应用。&lt;h4&gt;总结&lt;/h4&gt;该研究为对流动态的理解提供了新的模型和应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper we propose a model for describing advection dynamics ondistance-weighted directed graphs. To this end we establish a set of keyproperties, or axioms, that a discrete advection operator should satisfy, andprove that there exists an essentially unique operator satisfying all suchproperties. Both infinite and finite networks are considered, as well aspossible variants and extensions. We illustrate the proposed model throughexamples, both analytical and numerical, and we describe an application to thesimulation of a traffic network.</description>
      <author>example@mail.com (Michele Benzi, Fabio Durastante, Francesco Zigliotto)</author>
      <guid isPermaLink="false">2410.11352v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CATCH: Channel-Aware multivariate Time Series Anomaly Detection via Frequency Patching</title>
      <link>http://arxiv.org/abs/2410.12261v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列中的异常检测面临挑战，尤其是异构子序列异常的出现。&lt;h4&gt;目的&lt;/h4&gt;提出CATCH框架，以克服现有重构方法在细粒度频率特征和通道相关性捕获方面的不足。&lt;h4&gt;方法&lt;/h4&gt;CATCH框架基于频率补丁，通过将频率域分割为频率带来增强细粒度频率特征的捕获。同时，引入通道融合模块（CFM），利用补丁掩码生成器和掩码注意机制，迭代发现合适的补丁级通道相关性。&lt;h4&gt;主要发现&lt;/h4&gt;在9个真实世界数据集和12个合成数据集上的大量实验表明，CATCH实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;CATCH框架有效提升了多变量时间序列异常检测的能力，特别是在捕获频率特征和通道相关性方面。&lt;h4&gt;总结&lt;/h4&gt;CATCH通过频率补丁和通道融合模块，显著改善了多变量时间序列中的异常检测效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection in multivariate time series is challenging as heterogeneoussubsequence anomalies may occur. Reconstruction-based methods, which focus onlearning nomral patterns in the frequency domain to detect diverse abnormalsubsequences, achieve promising resutls, while still falling short on capturingfine-grained frequency characteristics and channel correlations. To contendwith the limitations, we introduce CATCH, a framework based on frequencypatching. We propose to patchify the frequency domain into frequency bands,which enhances its ability to capture fine-grained frequency characteristics.To perceive appropriate channel correlations, we propose a Channel FusionModule (CFM), which features a patch-wise mask generator and a masked-attentionmechanism. Driven by a bi-level multi-objective optimization algorithm, the CFMis encouraged to iteratively discover appropriate patch-wise channelcorrelations, and to cluster relevant channels while isolating adverse effectsfrom irrelevant channels. Extensive experiments on 9 real-world datasets and 12synthetic datasets demonstrate that CATCH achieves state-of-the-artperformance.</description>
      <author>example@mail.com (Xingjian Wu, Xiangfei Qiu, Zhengyu Li, Yihang Wang, Jilin Hu, Chenjuan Guo, Hui Xiong, Bin Yang)</author>
      <guid isPermaLink="false">2410.12261v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ALOHA Unleashed: A Simple Recipe for Robot Dexterity</title>
      <link>http://arxiv.org/abs/2410.13126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近期的研究表明，通过模仿学习可以有效学习端到端的机器人策略。&lt;h4&gt;目的&lt;/h4&gt;探讨模仿学习在复杂灵巧操作任务中的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;在ALOHA2平台上进行大规模数据收集，结合Diffusion Policies等表达性模型。&lt;h4&gt;主要发现&lt;/h4&gt;在处理可变形物体和复杂接触动态的双手操作任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;该方法在5个真实世界和3个模拟任务上超越了现有的最先进基准。&lt;h4&gt;项目链接&lt;/h4&gt;项目网站和视频可以访问 aloha-unleashed.github.io。&lt;h4&gt;总结&lt;/h4&gt;通过大规模数据和先进模型，模仿学习在复杂操作中表现出显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work has shown promising results for learning end-to-end robotpolicies using imitation learning. In this work we address the question of howfar can we push imitation learning for challenging dexterous manipulationtasks. We show that a simple recipe of large scale data collection on the ALOHA2 platform, combined with expressive models such as Diffusion Policies, can beeffective in learning challenging bimanual manipulation tasks involvingdeformable objects and complex contact rich dynamics. We demonstrate our recipeon 5 challenging real-world and 3 simulated tasks and demonstrate improvedperformance over state-of-the-art baselines. The project website and videos canbe found at aloha-unleashed.github.io.</description>
      <author>example@mail.com (Tony Z. Zhao, Jonathan Tompson, Danny Driess, Pete Florence, Kamyar Ghasemipour, Chelsea Finn, Ayzaan Wahid)</author>
      <guid isPermaLink="false">2410.13126v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Before &amp; After: The Effect of EU's 2022 Code of Practice on Disinformation</title>
      <link>http://arxiv.org/abs/2410.11369v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，欧洲委员会采取了重要措施以减少网络空间中的虚假信息，包括推出2022年《加强版虚假信息行为准则》。&lt;h4&gt;目的&lt;/h4&gt;探讨《行为准则》的影响，特别是广告网络在虚假信息网站上的广告投放情况。&lt;h4&gt;方法&lt;/h4&gt;进行历史分析，以评估广告网络与虚假信息网站之间的广告关系。&lt;h4&gt;主要发现&lt;/h4&gt;尽管表面上看情况有所改善，但虚假信息网站与主要广告网络之间的广告关系没有显著减少。广告网络主要撤出访问量少的虚假信息网站，但仍与流量较大的不可靠网站保持关系。&lt;h4&gt;结论&lt;/h4&gt;广告网络仍然在几乎400个虚假信息网站上投放合法公司的广告，表明现有措施未能有效遏制虚假信息广告的传播。&lt;h4&gt;总结&lt;/h4&gt;整体来看，广告网络与虚假信息网站的关系依然存在，且对公众信息环境的影响未得到有效控制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over the past few years, the European Commission has made significant stepsto reduce disinformation in cyberspace. One of those steps has been theintroduction of the 2022 "Strengthened Code of Practice on Disinformation".Signed by leading online platforms, this Strengthened Code of Practice onDisinformation is an attempt to combat disinformation on the Web. The Code ofPractice includes a variety of measures including the demonetization ofdisinformation, urging, for example, advertisers "to avoid the placement ofadvertising next to Disinformation content".  In this work, we set out to explore what was the impact of the Code ofPractice and especially to explore to what extent ad networks continue toadvertise on dis-/mis-information sites. We perform a historical analysis andfind that, although at a hasty glance things may seem to be improving, there isreally no significant reduction in the amount of advertising relationshipsamong popular misinformation websites and major ad networks. In fact, we showthat ad networks have withdrawn mostly from unpopular misinformation websiteswith very few visitors, but still form relationships with highly unreliablewebsites that account for the majority of misinformation traffic. To makematters worse, we show that ad networks continue to place advertisements oflegitimate companies next to misinformation content. In fact, major ad networksplace ads in almost 400 misinformation websites of our dataset.</description>
      <author>example@mail.com (Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Nicolas Kourtellis, Evangelos P. Markatos)</author>
      <guid isPermaLink="false">2410.11369v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Discovering Leitmotifs in Multidimensional Time Series</title>
      <link>http://arxiv.org/abs/2410.12293v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;乐句是文学、电影或音乐中反复出现的主题，具有象征意义。针对多维时间序列（MDTS）数据中的乐句发现问题属于无监督的复杂模式发现问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖、高效且有效的乐句发现算法LAMA，用于多维时间序列数据的分析。&lt;h4&gt;方法&lt;/h4&gt;LAMA基于两个核心原则：一是乐句在未知数量的子维度中显现，二是子维度与最佳模式之间存在依赖关系，需联合处理这两个问题。&lt;h4&gt;主要发现&lt;/h4&gt;在14个不同的真实数据集上进行的实验评估显示，LAMA在检测有意义的模式时表现优于四个先进的基准方法，并且没有增加计算复杂性。&lt;h4&gt;结论&lt;/h4&gt;LAMA能够有效且高效地发现多维时间序列数据中的乐句，解决了传统方法中的独立选择维度和乐句的问题。&lt;h4&gt;总结&lt;/h4&gt;LAMA算法为多维时间序列中的模式发现提供了新的解决方案，展现出优越的性能和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A leitmotif is a recurring theme in literature, movies or music that carriessymbolic significance for the piece it is contained in. When this piece can berepresented as a multi-dimensional time series (MDTS), such as acoustic orvisual observations, finding a leitmotif is equivalent to the pattern discoveryproblem, which is an unsupervised and complex problem in time series analytics.Compared to the univariate case, it carries additional complexity becausepatterns typically do not occur in all dimensions but only in a few - whichare, however, unknown and must be detected by the method itself. In this paper,we present the novel, efficient and highly effective leitmotif discoveryalgorithm LAMA for MDTS. LAMA rests on two core principals: (a) a leitmotifmanifests solely given a yet unknown number of sub-dimensions - neither toofew, nor too many, and (b) the set of sub-dimensions are not independent fromthe best pattern found therein, necessitating both problems to be approached ina joint manner. In contrast to most previous methods, LAMA tackles bothproblems jointly - instead of independently selecting dimensions (orleitmotifs) and finding the best leitmotifs (or dimensions). Our experimentalevaluation on a novel ground-truth annotated benchmark of 14 distinct real-lifedata sets shows that LAMA, when compared to four state-of-the-art baselines,shows superior performance in detecting meaningful patterns without increasedcomputational complexity.</description>
      <author>example@mail.com (Patrick Schäfer, Ulf Leser)</author>
      <guid isPermaLink="false">2410.12293v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Power in Numbers: Primitive Algorithm for Swarm Robot Navigation in Unknown Environments</title>
      <link>http://arxiv.org/abs/2410.13149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 22 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;移动机器人在未知环境中的导航已成为重要研究课题，主要依赖实时环境映射、自动定位和路径生成。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单的导航算法，以利用群体机器人在未知环境中移动。&lt;h4&gt;方法&lt;/h4&gt;算法假设机器人仅需感知目标方向和周围机器人的相对位置，机器人通过朝向目标前进并绕过周围机器人来导航。&lt;h4&gt;主要发现&lt;/h4&gt;所提算法无需感知环境、判断是否卡住或进行复杂的机器人间通信。&lt;h4&gt;结论&lt;/h4&gt;通过数学验证、基于潜在场方法的数值模拟以及声场导航的实验演示，验证了算法的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究为移动机器人在动态未知环境中的导航提供了一种简化方法，具有实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, the navigation of mobile robots in unknown environments has becomea particularly significant research topic. Previous studies have primarilyemployed real-time environmental mapping using cameras and LiDAR, along withself-localization and path generation based on those maps. Additionally, thereis research on Sim-to-Real transfer, where robots acquire behaviors throughpre-trained reinforcement learning and apply these learned actions inreal-world navigation. However, strictly the observe action and modelling ofunknown environments that change unpredictably over time with accuracy andprecision is an extremely complex endeavor. This study proposes a simplenavigation algorithm for traversing unknown environments by utilizes the numberof swarm robots. The proposed algorithm assumes that the robot has only thesimple function of sensing the direction of the goal and the relative positionsof the surrounding robots. The robots can navigate an unknown environment bysimply continuing towards the goal while bypassing surrounding robots. Themethod does not need to sense the environment, determine whether they or otherrobots are stuck, or do the complicated inter-robot communication. Wemathematically validate the proposed navigation algorithm, present numericalsimulations based on the potential field method, and conduct experimentaldemonstrations using developed robots based on the sound fields for navigation.</description>
      <author>example@mail.com (Yusuke Tsunoda, Shoken Otsuka, Kazuki Ito, Runze Xiao, Keisuke Naniwa, Yuichiro Sueoka, Koichi Osuka)</author>
      <guid isPermaLink="false">2410.13149v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>RSSI-Assisted CSI-Based Passenger Counting with Multiple Wi-Fi Receivers</title>
      <link>http://arxiv.org/abs/2410.11400v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 9 figures, this article was submitted to IEEE for possible
  publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;乘客计数对于公共交通车辆调度和交通容量评估至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的基于边缘计算的乘客计数系统。&lt;h4&gt;方法&lt;/h4&gt;系统由多个Wi-Fi接收器和一个边缘服务器组成，利用信道状态信息（CSI）和接收信号强度指示（RSSI）实现接收器之间的协作。&lt;h4&gt;主要发现&lt;/h4&gt;系统在香港双层巴士的实际数据集中，最高可计数20名乘客，平均准确率和F1分数超过94%，比其他合作感知基线高出至少2.27%的准确率和2.34%的F1分数。&lt;h4&gt;结论&lt;/h4&gt;所提出的系统在乘客计数方面表现优异，具有较高的准确性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;本文提出的基于边缘计算的乘客计数系统有效利用Wi-Fi信号，实现了高精度的乘客计数。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Passenger counting is crucial for public transport vehicle scheduling andtraffic capacity evaluation. However, most existing methods are either costlyor with low counting accuracy, leading to the recent use of Wi-Fi signals forthis purpose. In this paper, we develop an efficient edge computing-basedpassenger counting system consists of multiple Wi-Fi receivers and an edgeserver. It leverages channel state information (CSI) and received signalstrength indicator (RSSI) to facilitate the collaboration among multiplereceivers. Specifically, we design a novel CSI feature fusion module calledAdaptive RSSI-weighted CSI Feature Concatenation, which integrates locallyextracted CSI and RSSI features from multiple receivers for information fusionat the edge server. Performance of our proposed system is evaluated using areal-world dataset collected from a double-decker bus in Hong Kong, with up to20 passengers. The experimental results reveal that our system achieves anaverage accuracy and F1-score of over 94%, surpassing other cooperative sensingbaselines by at least 2.27% in accuracy and 2.34% in F1-score.</description>
      <author>example@mail.com (Jingtao Guo, Wenhao Zhuang, Yuyi Mao, Ivan Wang-Hei Ho)</author>
      <guid isPermaLink="false">2410.11400v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Revisited Large Language Model for Time Series Analysis through Modality Alignment</title>
      <link>http://arxiv.org/abs/2410.12326v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在传感器数据分析等关键网络应用中表现出色，但并未专门为时间序列任务设计。&lt;h4&gt;目的&lt;/h4&gt;评估大型语言模型在时间序列任务（如预测、分类、插值和异常检测）中的有效性。&lt;h4&gt;方法&lt;/h4&gt;通过广泛实验比较大型语言模型与简单基线模型（如单层线性模型和随机初始化的LLMs）的性能。&lt;h4&gt;主要发现&lt;/h4&gt;大型语言模型在核心时间序列任务中优势微乎其微，且可能扭曲数据的时间结构；相反，简单模型表现更佳且参数需求更少。&lt;h4&gt;结论&lt;/h4&gt;大型语言模型在时间序列任务的表现源自时间序列数据的内在特征和结构，而非与语言模型架构的有效对齐。&lt;h4&gt;总结&lt;/h4&gt;简单模型在时间序列任务中优于大型语言模型，且现有重编程技术未能有效对齐时间序列数据与语言模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models have demonstrated impressive performance in manypivotal web applications such as sensor data analysis. However, since LLMs arenot designed for time series tasks, simpler models like linear regressions canoften achieve comparable performance with far less complexity. In this study,we perform extensive experiments to assess the effectiveness of applying LLMsto key time series tasks, including forecasting, classification, imputation,and anomaly detection. We compare the performance of LLMs against simplerbaseline models, such as single-layer linear models and randomly initializedLLMs. Our results reveal that LLMs offer minimal advantages for these core timeseries tasks and may even distort the temporal structure of the data. Incontrast, simpler models consistently outperform LLMs while requiring far fewerparameters. Furthermore, we analyze existing reprogramming techniques and show,through data manifold analysis, that these methods fail to effectively aligntime series data with language and display pseudo-alignment behaviour inembedding space. Our findings suggest that the performance of LLM-based methodsin time series tasks arises from the intrinsic characteristics and structure oftime series data, rather than any meaningful alignment with the language modelarchitecture.</description>
      <author>example@mail.com (Liangwei Nathan Zheng, Chang George Dong, Wei Emma Zhang, Lin Yue, Miao Xu, Olaf Maennel, Weitong Chen)</author>
      <guid isPermaLink="false">2410.12326v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Line Spectral Analysis Using the G-Filter: An Atomic Norm Minimization Approach</title>
      <link>http://arxiv.org/abs/2410.12358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 8 figures. Submitted to Automatica&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;谱分析领域传统上将连续谱（谱密度）与线谱（Dirac脉冲）区分开，前者对应于完全非确定性过程，后者代表正弦波。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的线谱估计方法，结合Georgiou的滤波器组（G-filter）和原子范数最小化（ANM）理论。&lt;h4&gt;方法&lt;/h4&gt;利用滤波器输出的协方差矩阵进行Carathéodory–Fejér型分解，利用半正定规划高效解决ANM问题。&lt;h4&gt;主要发现&lt;/h4&gt;提出的优化理论是标准ANM在线谱估计上的重要推广，且与G-filter结合的ANM方法在多个方面优于子空间方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在只需一个输出向量且无需先验知识的情况下，能够有效工作，适应不同信噪比的信号。&lt;h4&gt;总结&lt;/h4&gt;模拟结果表明，适当设计的G-filter使得该方法在不同信噪比下表现良好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The area of spectral analysis has a traditional dichotomy between continuousspectra (spectral densities) which correspond to purely nondeterministicprocesses, and line spectra (Dirac impulses) which represent sinusoids. Whilethe former case is important in the identification of discrete-time linearstochastic systems, the latter case is essential for the analysis and modelingof time series with notable applications in radar systems. In this paper, wedevelop a novel approach for line spectral estimation which combines ideas ofGeorgiou's filter banks (G-filters) and atomic norm minimization (ANM), amainstream method for line spectral analysis in the last decade following thetheory of compressed sensing. Such a combination is only possible because aCarath\'{e}odory--Fej\'{e}r-type decomposition is available for the covariancematrix of the filter output. The ANM problem can be characterized viasemidefinite programming which can be solved efficiently. As a consequence, ouroptimization theory can be seen as a substantial generalization of the standardANM for line spectral estimation. Moreover, our ANM approach with a G-filterhas significant advantages over subspace methods because it can work with justone output vector and without \emph{a priori} knowledge about the number ofsinusoids in the input. Simulation results show that our approach performsreasonably well under different signal-to-noise ratios when the G-filter issuitably designed.</description>
      <author>example@mail.com (Bin Zhu)</author>
      <guid isPermaLink="false">2410.12358v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Numerical computation of generalized Wasserstein distances with applications to traffic model analysis</title>
      <link>http://arxiv.org/abs/2410.11441v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;广义Wasserstein距离可以定量比较具有相同或不同总质量的两种连续或离散质量分布。&lt;h4&gt;目的&lt;/h4&gt;提出四种数值方法，用于近似最近几年引入的三种不同的广义Wasserstein距离，并探讨其物理意义。&lt;h4&gt;方法&lt;/h4&gt;开发数值方法并计算不同输入（包括不同边界条件）对应的数值解之间的广义Wasserstein距离。&lt;h4&gt;主要发现&lt;/h4&gt;这些广义Wasserstein距离在交通流的微分模型敏感性分析中具有重要应用。&lt;h4&gt;结论&lt;/h4&gt;模型敏感性可以通过计算不同输入下的数值解之间的广义Wasserstein距离来量化。&lt;h4&gt;总结&lt;/h4&gt;广义Wasserstein距离为比较和分析复杂模型提供了有效的工具，促进了交通流模型的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized Wasserstein distances allow to quantitatively compare twocontinuous or atomic mass distributions with equal or different total mass. Inthis paper, we propose four numerical methods for the approximation of threedifferent generalized Wasserstein distances introduced in the last years,giving some insights about their physical meaning. After that, we explore theirusage in the context of the sensitivity analysis of differential models fortraffic flow. The quantification of models sensitivity is obtained by computingthe generalized Wasserstein distances between two (numerical) solutionscorresponding to different inputs, including different boundary conditions.</description>
      <author>example@mail.com (Maya Briani, Emiliano Cristiani, Giovanni Franzina, Francesca L. Ignoto)</author>
      <guid isPermaLink="false">2410.11441v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Towards Neural Scaling Laws for Time Series Foundation Models</title>
      <link>http://arxiv.org/abs/2410.12360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;缩放规律为时间序列基础模型（TSFM）的设计提供了重要见解，但以往研究主要关注于ID数据的缩放规律，OOD数据的缩放行为及模型架构的影响尚未得到充分探讨。&lt;h4&gt;目的&lt;/h4&gt;研究两种常见的TSFM架构，即仅编码器和仅解码器的Transformer，考察它们在ID和OOD数据上的缩放行为。&lt;h4&gt;方法&lt;/h4&gt;对不同参数数量、计算预算和数据集大小下的模型进行训练和评估。&lt;h4&gt;主要发现&lt;/h4&gt;TSFM的对数似然损失在OOD和ID设置中表现出相似的缩放行为。不同架构的缩放特性存在显著差异，编码器仅Transformer的可扩展性优于解码器仅Transformer。&lt;h4&gt;结论&lt;/h4&gt;尽管扩大TSFM规模有望推动性能突破，但对TSFM缩放规律缺乏全面理解限制了模型缩放的框架发展。本文通过综合研究成果，提供了设计和扩展更大TSFM的实用指导。&lt;h4&gt;总结&lt;/h4&gt;研究填补了TSFM缩放规律理解的空白，为提升模型能力提供了可行的设计和缩放建议。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scaling laws offer valuable insights into the design of time seriesfoundation models (TSFMs). However, previous research has largely focused onthe scaling laws of TSFMs for in-distribution (ID) data, leaving theirout-of-distribution (OOD) scaling behavior and the influence of modelarchitectures less explored. In this work, we examine two common TSFMarchitectures, encoder-only and decoder-only Transformers, and investigatetheir scaling behavior on both ID and OOD data. These models are trained andevaluated across varying parameter counts, compute budgets, and dataset sizes.Our experiments reveal that the log-likelihood loss of TSFMs exhibits similarscaling behavior in both OOD and ID settings. We further compare the scalingproperties across different architectures, incorporating two state-of-the-artTSFMs as case studies, showing that model architecture plays a significant rolein scaling. The encoder-only Transformers demonstrate better scalability thanthe decoder-only Transformers, while the architectural enhancements in the twoadvanced TSFMs primarily improve ID performance but reduce OOD scalability.While scaling up TSFMs is expected to drive performance breakthroughs, the lackof a comprehensive understanding of TSFM scaling laws has hindered thedevelopment of a robust framework to guide model scaling. We fill this gap inthis work by synthesizing our findings and providing practical guidelines fordesigning and scaling larger TSFMs with enhanced model capabilities.</description>
      <author>example@mail.com (Qingren Yao, Chao-Han Huck Yang, Renhe Jiang, Yuxuan Liang, Ming Jin, Shirui Pan)</author>
      <guid isPermaLink="false">2410.12360v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Minimizing emissions through ride pooling incentives</title>
      <link>http://arxiv.org/abs/2410.11629v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;面对气候紧急情况和日益增长的污染与交通拥堵挑战，共享拼车被提出作为解决城市交通低碳化和空间效率的潜在方案。&lt;h4&gt;目的&lt;/h4&gt;探讨哪些系统配置能够实现共享拼车的经济可行性。&lt;h4&gt;方法&lt;/h4&gt;开发简化模型，分析特定用户数量、街道网络拓扑和其他系统参数下的拼车系统的切换潜力和CO2排放。&lt;h4&gt;主要发现&lt;/h4&gt;根据假设的切换率函数，地方交通的CO2排放可以减少39%到45%，其他系统参数的影响仅为几个百分点。&lt;h4&gt;结论&lt;/h4&gt;呼吁进行实证分析，将模型转化为大城市低碳和智能准公共交通的情景。&lt;h4&gt;总结&lt;/h4&gt;共享拼车在降低城市交通碳排放方面具有显著潜力，需进一步研究其经济可行性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In face of the climate emergency and growing challenges ranging frompollution to traffic jams, ride pooling has been floated as a potentialsolution for less congested, low-carbon and more space-efficient urbantransport. However, it is unclear which system configurations enable aneconomically viable case for shared pooled mobility. To gain a betterunderstanding of mechanisms behind this, we develop a simplified model toanalyze the switching potential and CO2 emissions of ride pooling systems for agiven number of transport users, street network topology and other systemparameter values with different hypothetical switch rate functions. We findthat CO2 emissions of local transport can be reduced by 39 to 45 % depending onthe assumed switch rate function with other system parameters only having asecondary effect of a few percentage points. We call for empirically gaugedanalyses that translate our model into scenarios for metropolitan low-carbonand smart para-transit.</description>
      <author>example@mail.com (Milli Keil, Felix Creutzig, Nora Molkenthin)</author>
      <guid isPermaLink="false">2410.11629v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Arc-Length-Based Warping for Robot Skill Synthesis from Multiple Demonstrations</title>
      <link>http://arxiv.org/abs/2410.13322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在机器人领域，示范学习（LfD）旨在通过多次示范同一任务将技能转移给机器人。&lt;h4&gt;目的&lt;/h4&gt;提出一种新算法，名为空间采样（SS），用于机器人轨迹的时间独立对齐。&lt;h4&gt;方法&lt;/h4&gt;通过提供信号的弧长参数化来实现轨迹的对齐，消除对时间对齐的需求。&lt;h4&gt;主要发现&lt;/h4&gt;大时间偏移的示范轨迹会引入合成最终轨迹的不确定性，而在弧长域中的对齐可以显著减少这种不确定性。&lt;h4&gt;结论&lt;/h4&gt;相较于各种先进的基于时间的信号对齐算法，空间采样方法在准确性和鲁棒性上表现更佳。&lt;h4&gt;数据集&lt;/h4&gt;构建了一个公开的自定义机器人录音数据集以测试真实世界的轨迹。&lt;h4&gt;总结&lt;/h4&gt;空间采样算法通过消除时间对齐的需求，提高了机器人技能表示的准确性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In robotics, Learning from Demonstration (LfD) aims to transfer skills torobots by using multiple demonstrations of the same task. These demonstrationsare recorded and processed to extract a consistent skill representation. Thisprocess typically requires temporal alignment through techniques such asDynamic Time Warping (DTW). In this paper, we introduce a novel algorithm,named Spatial Sampling (SS), specifically designed for robot trajectories, thatenables time-independent alignment of the trajectories by providing anarc-length parametrization of the signals. This approach eliminates the needfor temporal alignment, enhancing the accuracy and robustness of skillrepresentation. Specifically, we show that large time shifts in thedemonstrated trajectories can introduce uncertainties in the synthesis of thefinal trajectory, which alignment in the arc-length domain can drasticallyreduce, in comparison with various state-of-the-art time-based signal alignmentalgorithms. To this end, we built a custom publicly available dataset of robotrecordings to test real-world trajectories.</description>
      <author>example@mail.com (Giovanni Braglia, Davide Tebaldi, André Eugenio Lazzaretti, Luigi Biagiotti)</author>
      <guid isPermaLink="false">2410.13322v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>GeoCalib: Learning Single-image Calibration with Geometric Optimization</title>
      <link>http://arxiv.org/abs/2409.06704v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at ECCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从单张图像中，视觉线索可以帮助推导相机参数，如焦距和重力方向。&lt;h4&gt;目的&lt;/h4&gt;研究单图像标定在图像编辑和三维映射等下游应用中的益处。&lt;h4&gt;方法&lt;/h4&gt;提出GeoCalib，一个利用3D几何普遍规律的深度神经网络，通过优化过程进行端到端训练，以估计相机参数并从数据中学习有用的视觉线索。&lt;h4&gt;主要发现&lt;/h4&gt;GeoCalib在各种基准测试中表现出比现有的经典和学习方法更强的鲁棒性和更高的准确性。&lt;h4&gt;结论&lt;/h4&gt;GeoCalib的内部优化能够估计不确定性，有助于标记失败案例，并对视觉定位等下游应用带来益处。&lt;h4&gt;总结&lt;/h4&gt;GeoCalib代码和训练模型已公开，提供了对单图像标定的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cvg/geocalib&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; From a single image, visual cues can help deduce intrinsic and extrinsiccamera parameters like the focal length and the gravity direction. Thissingle-image calibration can benefit various downstream applications like imageediting and 3D mapping. Current approaches to this problem are based on eitherclassical geometry with lines and vanishing points or on deep neural networkstrained end-to-end. The learned approaches are more robust but struggle togeneralize to new environments and are less accurate than their classicalcounterparts. We hypothesize that they lack the constraints that 3D geometryprovides. In this work, we introduce GeoCalib, a deep neural network thatleverages universal rules of 3D geometry through an optimization process.GeoCalib is trained end-to-end to estimate camera parameters and learns to finduseful visual cues from the data. Experiments on various benchmarks show thatGeoCalib is more robust and more accurate than existing classical and learnedapproaches. Its internal optimization estimates uncertainties, which help flagfailure cases and benefit downstream applications like visual localization. Thecode and trained models are publicly available athttps://github.com/cvg/GeoCalib.</description>
      <author>example@mail.com (Alexander Veicht, Paul-Edouard Sarlin, Philipp Lindenberger, Marc Pollefeys)</author>
      <guid isPermaLink="false">2409.06704v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Bias correction of quadratic spectral estimators</title>
      <link>http://arxiv.org/abs/2410.12386v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Biometrika, Miscelanea&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;存在三种主要的非参数估计器用于时间序列的功率谱密度估计：滞后窗口、多个锤和Welch估计器，但在有限样本中，这些估计器可能会产生不可忽视的偏差。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以显著减少Welch估计器在有限样本中的偏差，并扩展到更广泛的二次估计器家族。&lt;h4&gt;方法&lt;/h4&gt;Astfalck等人（2024）的方法可以与任何旨在减少偏差的锤和滞后序列结合使用，提供滞后窗口和多个锤估计器的偏差修正理论。&lt;h4&gt;主要发现&lt;/h4&gt;该理论得到了模拟研究的支持，并比较了不同的二次估计器变体。&lt;h4&gt;结论&lt;/h4&gt;尽管计算复杂度超过O(n log n)，但在实际应用中并不难以处理，该方法应视为对相关领域工作的扩展，而非替代性方法。&lt;h4&gt;总结&lt;/h4&gt;本文提供了对多种二次估计器的偏差修正方法，为功率谱密度估计提供了新的理论基础和实用工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The three cardinal, statistically consistent, families of non-parametricestimators to the power spectral density of a time series are lag-window,multitaper and Welch estimators. However, when estimating power spectraldensities from a finite sample each can be subject to non-ignorable bias.Astfalck et al. (2024) developed a method that offers significant biasreduction for finite samples for Welch's estimator, which this article extendsto the larger family of quadratic estimators, thus offering similar theory forbias correction of lag-window and multitaper estimators as well as combinationsthereof. Importantly, this theory may be used in conjunction with any and alltapers and lag-sequences designed for bias reduction, and so should be seen asan extension to valuable work in these fields, rather than a supplantingmethodology. The order of computation is larger than O(n log n) typical inspectral analyses, but not insurmountable in practice. Simulation studiessupport the theory with comparisons across variations of quadratic estimators.</description>
      <author>example@mail.com (Lachlan Astfalck, Adam Sykulski, Edward Cripps)</author>
      <guid isPermaLink="false">2410.12386v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>On the potential of Optimal Transport in Geospatial Data Science</title>
      <link>http://arxiv.org/abs/2410.11709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;地理信息科学和交通领域的预测问题主要旨在提升运营效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种空间评估指标和损失函数，即最优运输（OT），以评估空间预测模型的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用最优运输指标来评估因预测错误造成的重新定位成本，并在真实和合成数据上进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;['预测错误的空间分布在许多应用中是相关的，并且可以转化为现实世界的成本。', '与其他指标相比，OT能够反映这些空间成本。', 'OT指标可以提高跨空间和时间尺度的可比性。']&lt;h4&gt;结论&lt;/h4&gt;建议在神经网络中利用OT作为损失函数，以提高预测的空间正确性，并与GeoAI的运营考虑保持一致。&lt;h4&gt;总结&lt;/h4&gt;通过提供代码和教程，促进OT在地理信息系统中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mie-lab/geospatialot&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prediction problems in geographic information science and transportation arefrequently motivated by the possibility to enhance operational efficiency.Examples range from predicting car sharing demand for optimizing relocation toforecasting traffic congestion for navigation purposes. However, conventionalaccuracy metrics do not account for the spatial distribution of predictionserrors, despite its relevance for operations. We put forward Optimal Transport(OT) as a spatial evaluation metric and loss function. The proposed OT metricassesses the utility of spatial prediction models in terms of the relocationcosts caused by prediction errors. In experiments on real and synthetic data,we demonstrate that 1) the spatial distribution of the prediction errors isrelevant in many applications and can be translated to real-world costs, 2) incontrast to other metrics, OT reflects these spatial costs, and 3) OT metricsimprove comparability across spatial and temporal scales. Finally, we advocatefor leveraging OT as a loss function in neural networks to improve the spatialcorrectness of predictions. This approach not only aligns evaluation in GeoAIwith operational considerations, but also signifies a step forward in refiningpredictions within geospatial applications. To facilitate the adoption of OT inGIS, we provide code and tutorials at https://github.com/mie-lab/geospatialOT.</description>
      <author>example@mail.com (Nina Wiedemann, Théo Uscidda, Martin Raubal)</author>
      <guid isPermaLink="false">2410.11709v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Accurate Checkerboard Corner Detection under Defoucs</title>
      <link>http://arxiv.org/abs/2410.13371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;相机标定是3D视觉中的一个关键过程，影响自主驾驶、机器人技术、建筑等应用。&lt;h4&gt;目的&lt;/h4&gt;增强棋盘角点检测的特征提取，这是标定中的一个关键步骤。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于对称性的亚像素精细化方法，分析现有方法的局限性，并引入简化的目标函数以降低计算时间和过拟合风险。&lt;h4&gt;主要发现&lt;/h4&gt;新方法显著提高了可见光相机的准确性，特别是在处理图像中的突变和散焦效应时。&lt;h4&gt;结论&lt;/h4&gt;该方法在可见光相机标定中表现优越，相比现有技术有显著的准确性提升。&lt;h4&gt;代码链接&lt;/h4&gt;https://github.com/spdfghi/Accurate-Checkerboard-Corner-Detection-under-Defoucs.git&lt;h4&gt;总结&lt;/h4&gt;本文提出的对称性基础的亚像素精细化方法为相机标定提供了新的思路，能够有效应对图像中的复杂变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Camera calibration is a critical process in 3D vision, im pactingapplications in autonomous driving, robotics, ar chitecture, and so on. Thispaper focuses on enhancing feature extraction for chessboard corner detection,a key step in calibration. We analyze existing methods, high lighting theirlimitations and propose a novel sub-pixel refinement approach based onsymmetry, which signifi cantly improves accuracy for visible light cameras. Unlike prior symmetry based method that assume a contin uous physical pattern,our approach accounts for abrupt changes in visible light camera images anddefocus ef fects. We introduce a simplified objective function that reducescomputation time and mitigates overfitting risks. Furthermore, we derive anexplicit expression for the pixel value of a blurred edge, providing insightsinto the relationship between pixel value and center intensity. Our methoddemonstrates superior performance, achiev ing substantial accuracy improvementsover existing tech niques, particularly in the context of visible light cam eracalibration. Our code is available from https://github.com/spdfghi/Accurate-Checkerboard Corner-Detection-under-Defoucs.git.</description>
      <author>example@mail.com (Zezhun Shi)</author>
      <guid isPermaLink="false">2410.13371v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>BestMan: A Modular Mobile Manipulator Platform for Embodied AI with Unified Simulation-Hardware APIs</title>
      <link>http://arxiv.org/abs/2410.13407v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;具身人工智能（Embodied AI）强调代理在物理环境中的感知、理解和行动能力。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的模拟平台BestMan，以解决现有平台面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;BestMan基于PyBullet，设计了一个集成的多级技能链、模块化架构、统一接口和硬件无关的方法。&lt;h4&gt;主要发现&lt;/h4&gt;BestMan能够实现感知、规划和控制之间的无缝协调，并简化开发过程。&lt;h4&gt;结论&lt;/h4&gt;BestMan是一个有价值的工具，可用于推进具身人工智能的研究，增强平台的扩展性。&lt;h4&gt;总结&lt;/h4&gt;通过解决技术集成复杂性、模块化不足、接口异质性和硬件适应性等问题，BestMan为具身AI研究提供了强大的支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Embodied Artificial Intelligence (Embodied AI) emphasizes agents' ability toperceive, understand, and act in physical environments. Simulation platformsplay a crucial role in advancing this field by enabling the validation andoptimization of algorithms. However, existing platforms face challenges such asmultilevel technical integration complexity, insufficient modularity, interfaceheterogeneity, and adaptation to diverse hardware. We present BestMan, asimulation platform based on PyBullet, designed to address these issues.BestMan introduces an integrated multilevel skill chain for seamlesscoordination across perception, planning, and control; a highly modulararchitecture for flexible algorithm integration; unified interfaces for smoothsimulation-to-reality transfer; and a hardware-agnostic approach for adaptingto various mobile manipulator configurations. These features collectivelysimplify development and enhance platform expandability, making BestMan avaluable tool for Embodied AI research.</description>
      <author>example@mail.com (Kui Yang, Nieqing Cao, Yan Ding, Chao Chen)</author>
      <guid isPermaLink="false">2410.13407v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Augmented Intelligence in Smart Intersections: Local Digital Twins-Assisted Hybrid Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.12163v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;车辆与道路协作是一种提升自动驾驶安全性和效率的有前景的方法，通过将车载系统的智能扩展到智能道路基础设施。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的本地数字双胞胎（LDT）辅助混合自动驾驶系统，以提高交通交叉口的安全性和效率。&lt;h4&gt;方法&lt;/h4&gt;利用配备传感器和计算能力的路边单元（RSUs），该系统持续监测交通，提取人类驾驶知识，并通过离线强化学习框架生成特定于交叉口的本地驾驶代理。&lt;h4&gt;主要发现&lt;/h4&gt;与传统车载系统相比，LDT辅助的混合系统能够将安全措施提高10%，旅行时间减少15%。此外，峰值延迟为8.51毫秒（CP）和146毫秒（本地代理下载），符合3GPP的V2X和模型传输要求。&lt;h4&gt;结论&lt;/h4&gt;实现的原型展示了可靠的实时性能，满足了所提出系统设计的目标。&lt;h4&gt;总结&lt;/h4&gt;该系统通过增强信息交换和提取人类驾驶知识，展示了在智能交通交叉口中提高安全性和效率的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicle-road collaboration is a promising approach for enhancing the safetyand efficiency of autonomous driving by extending the intelligence of onboardsystems to smart roadside infrastructures. The introduction of digital twins(DTs), particularly local DTs (LDTs) at the edge, in smart mobility presents anew embodiment of augmented intelligence, which could enhance informationexchange and extract human driving expertise to improve onboard intelligence.This paper presents a novel LDT-assisted hybrid autonomous driving system forimproving safety and efficiency in traffic intersections. By leveragingroadside units (RSUs) equipped with sensory and computing capabilities, theproposed system continuously monitors traffic, extracts human drivingknowledge, and generates intersection-specific local driving agents through anoffline reinforcement learning (RL) framework. When connected and automatedvehicles (CAVs) pass through RSU-equipped intersections, RSUs can provide localagents to support safe and efficient driving in local areas. Meanwhile, theyprovide real-time cooperative perception (CP) to broaden onboard sensoryhorizons. The proposed LDT-assisted hybrid system is implemented withstate-of-the-art products, e.g., CAVs and RSUs, and technologies, e.g.,millimeter-wave (mmWave) communications. Hardware-in-the-loop (HiL) simulationsand proof-of-concept (PoC) tests validate system performance from twostandpoints: (i) The peak latency for CP and local agent downloading are 8.51ms and 146 ms, respectively, aligning with 3GPP requirements forvehicle-to-everything (V2X) and model transfer use cases. Moreover, (ii) localdriving agents can improve safety measures by 10% and reduce travel time by 15%compared with conventional onboard systems. The implemented prototype alsodemonstrates reliable real-time performance, fulfilling the targets of theproposed system design.</description>
      <author>example@mail.com (Kui Wang, Kazuma Nonomura, Zongdian Li, Tao Yu, Kei Sakaguchi, Omar Hashash, Walid Saad, Changyang She, Yonghui Li)</author>
      <guid isPermaLink="false">2410.12163v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>RAMPA: Robotic Augmented Reality for Machine Programming and Automation</title>
      <link>http://arxiv.org/abs/2410.13412v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人技术逐渐应用于传统工业以外的各个领域，急需直观的机器人培训和交互系统。&lt;h4&gt;目的&lt;/h4&gt;介绍一种名为RAMPA的系统，利用增强现实技术促进机器人示范编程。&lt;h4&gt;方法&lt;/h4&gt;使用最新的商业化AR头戴设备（如Meta Quest 3）来实现工业机器人（如Universal Robots UR10）的示范编程。&lt;h4&gt;主要发现&lt;/h4&gt;RAMPA系统在安全性、编程障碍和实际硬件演示收集的效率上解决了关键挑战，并通过定量指标评估了教学效果。&lt;h4&gt;结论&lt;/h4&gt;该系统显著提高了机器人任务的教学和优化方式，改善了操作安全性、效率和用户参与度。&lt;h4&gt;总结&lt;/h4&gt;RAMPA系统展示了增强现实技术在机器人编程中的应用潜力，为未来的机器人培训提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/dogadogan/rampa&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As robotics continue to enter various sectors beyond traditional industrialapplications, the need for intuitive robot training and interaction systemsbecomes increasingly more important. This paper introduces Robotic AugmentedReality for Machine Programming (RAMPA), a system that utilizes thecapabilities of state-of-the-art and commercially available AR headsets, e.g.,Meta Quest 3, to facilitate the application of Programming from Demonstration(PfD) approaches on industrial robotic arms, such as Universal Robots UR10. Ourapproach enables in-situ data recording, visualization, and fine-tuning ofskill demonstrations directly within the user's physical environment. RAMPAaddresses critical challenges of PfD, such as safety concerns, programmingbarriers, and the inefficiency of collecting demonstrations on the actualhardware. The performance of our system is evaluated against the traditionalmethod of kinesthetic control in teaching three different robotic manipulationtasks and analyzed with quantitative metrics, measuring task performance andcompletion time, trajectory smoothness, system usability, user experience, andtask load using standardized surveys. Our findings indicate a substantialadvancement in how robotic tasks are taught and refined, promising improvementsin operational safety, efficiency, and user engagement in robotic programming.</description>
      <author>example@mail.com (Fatih Dogangun, Serdar Bahar, Yigit Yildirim, Bora Toprak Temir, Emre Ugur, Mustafa Doga Dogan)</author>
      <guid isPermaLink="false">2410.13412v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Characterizing Behavioral Differences and Adaptations of Automated Vehicles and Human Drivers at Unsignalized Intersections: Insights from Waymo and Lyft Open Datasets</title>
      <link>http://arxiv.org/abs/2410.12538v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to Transportation Research Record for
  potential publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主驾驶车辆（AVs）融入交通系统为提高道路安全性和效率提供了前所未有的机会，但AV与人工驾驶车辆（HVs）在交叉口的互动仍是一个未解的研究问题。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过研究AV和HV在无信号交叉口的行为差异和适应性来填补这一空白。&lt;h4&gt;方法&lt;/h4&gt;利用Waymo和Lyft的两个全面的AV数据集，采用系统的方法识别和分析合并和交叉冲突，计算关键的安全和效率指标，包括碰撞时间（TTC）、后侵入时间（PET）、最大所需减速度（MRD）、时间优势（TA）以及速度和加速度特征。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在混合交通流中，尽管AV保持较大的安全边际，但其保守的行为可能导致人类驾驶员面临意外情况，从而可能造成不安全的条件。同时，人类驾驶员在与AV互动时表现出更一致的行为，表明AV可能有助于协调交通流模式。&lt;h4&gt;结论&lt;/h4&gt;Waymo和Lyft车辆之间观察到了显著差异，这强调了在交通建模和管理策略中考虑制造商特定AV行为的重要性，以确保AV的安全整合。&lt;h4&gt;总结&lt;/h4&gt;本研究处理的数据集已公开发布，以促进对AV与HV互动的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/SaeedRahmani/Unsignalized_AV_HV&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of autonomous vehicles (AVs) into transportation systemspresents an unprecedented opportunity to enhance road safety and efficiency.However, understanding the interactions between AVs and human-driven vehicles(HVs) at intersections remains an open research question. This study aims tobridge this gap by examining behavioral differences and adaptations of AVs andHVs at unsignalized intersections by utilizing two comprehensive AV datasetsfrom Waymo and Lyft. Using a systematic methodology, the research identifiesand analyzes merging and crossing conflicts by calculating key safety andefficiency metrics, including time to collision (TTC), post-encroachment time(PET), maximum required deceleration (MRD), time advantage (TA), and speed andacceleration profiles. The findings reveal a paradox in mixed traffic flow:while AVs maintain larger safety margins, their conservative behavior can leadto unexpected situations for human drivers, potentially causing unsafeconditions. From a performance point of view, human drivers exhibit moreconsistent behavior when interacting with AVs versus other HVs, suggesting AVsmay contribute to harmonizing traffic flow patterns. Moreover, notabledifferences were observed between Waymo and Lyft vehicles, which highlights theimportance of considering manufacturer-specific AV behaviors in trafficmodeling and management strategies for the safe integration of AVs. Theprocessed dataset utilized in this study is openly published to foster theresearch on AV-HV interactions.</description>
      <author>example@mail.com (Saeed Rahmani, Zhenlin, Xu, Simeon C. Calvert, Bart van Arem)</author>
      <guid isPermaLink="false">2410.12538v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera</title>
      <link>http://arxiv.org/abs/2410.08107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code Page: https://github.com/wu-cvgl/IncEventGS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;隐式神经表示和显式3D高斯点云在新视角合成方面取得了显著进展，但大多数研究集中在基于帧的相机上。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的增量3D高斯点云重建算法IncEventGS，专门针对事件相机。&lt;h4&gt;方法&lt;/h4&gt;利用传统SLAM管道的跟踪和映射范式，逐步恢复3D场景表示，首先估计相机运动，然后联合优化3D场景表示和相机运动。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，IncEventGS的性能优于之前的NeRF方法和其他相关基线，特别是在没有真实相机姿态的情况下。&lt;h4&gt;结论&lt;/h4&gt;该方法在相机运动估计方面也优于现有的事件视觉里程计方法，且代码已公开可用。&lt;h4&gt;总结&lt;/h4&gt;IncEventGS为事件相机的3D重建提供了有效的解决方案，展示了良好的性能和广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wu-cvgl/inceventgs&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit neural representation and explicit 3D Gaussian Splatting (3D-GS) fornovel view synthesis have achieved remarkable progress with frame-based camera(e.g. RGB and RGB-D cameras) recently. Compared to frame-based camera, a noveltype of bio-inspired visual sensor, i.e. event camera, has demonstratedadvantages in high temporal resolution, high dynamic range, low powerconsumption and low latency. Due to its unique asynchronous and irregular datacapturing process, limited work has been proposed to apply neuralrepresentation or 3D Gaussian splatting for an event camera. In this work, wepresent IncEventGS, an incremental 3D Gaussian Splatting reconstructionalgorithm with a single event camera. To recover the 3D scene representationincrementally, we exploit the tracking and mapping paradigm of conventionalSLAM pipelines for IncEventGS. Given the incoming event stream, the trackerfirstly estimates an initial camera motion based on prior reconstructed 3D-GSscene representation. The mapper then jointly refines both the 3D scenerepresentation and camera motion based on the previously estimated motiontrajectory from the tracker. The experimental results demonstrate thatIncEventGS delivers superior performance compared to prior NeRF-based methodsand other related baselines, even we do not have the ground-truth camera poses.Furthermore, our method can also deliver better performance compared tostate-of-the-art event visual odometry methods in terms of camera motionestimation. Code is publicly available at:https://github.com/wu-cvgl/IncEventGS.</description>
      <author>example@mail.com (Jian Huang, Chengrui Dong, Peidong Liu)</author>
      <guid isPermaLink="false">2410.08107v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Interactive Navigation with Adaptive Non-prehensile Mobile Manipulation</title>
      <link>http://arxiv.org/abs/2410.13418v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文介绍了一种通过自适应非抓握移动操控进行互动导航的框架。&lt;h4&gt;目的&lt;/h4&gt;解决处理具有未知动态的物体的挑战，这些物体难以通过视觉观察推断其动态特性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种针对常见可移动室内物体的自适应动态模型，利用学习的SE(2)动态表示，并将其整合到模型预测路径积分（MPPI）控制中指导机器人的交互。&lt;h4&gt;主要发现&lt;/h4&gt;所学习的动态模型有助于在导航不可操控物体时进行决策，并在仿真和实际场景中验证了其准确性和有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法成功应用于动态平衡移动机器人Shmoobot的可移动物体导航任务，展示了其在物体动态表示和操控方面的能力。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一个有效的框架，提升了机器人在复杂环境中与可移动物体的互动能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a framework for interactive navigation through adaptivenon-prehensile mobile manipulation. A key challenge in this process is handlingobjects with unknown dynamics, which are difficult to infer from visualobservation. To address this, we propose an adaptive dynamics model for commonmovable indoor objects via learned SE(2) dynamics representations. This modelis integrated into Model Predictive Path Integral (MPPI) control to guide therobot's interactions. Additionally, the learned dynamics help informdecision-making when navigating around objects that cannot be manipulated.Ourapproach is validated in both simulation and real-world scenarios,demonstrating its ability to accurately represent object dynamics andeffectively manipulate various objects. We further highlight its success in theNavigation Among Movable Objects (NAMO) task by deploying the proposedframework on a dynamically balancing mobile robot, Shmoobot. Project website:https://cmushmoobot.github.io/AdaptivePushing/.</description>
      <author>example@mail.com (Cunxi Dai, Xiaohan Liu, Koushil Sreenath, Zhongyu Li, Ralph Hollis)</author>
      <guid isPermaLink="false">2410.13418v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ROMAN: Open-Set Object Map Alignment for Robust View-Invariant Global Localization</title>
      <link>http://arxiv.org/abs/2410.08262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全球定位是长期且无漂移机器人导航所需的基本能力，但当前方法在面对显著不同的视角时无法重新定位。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为ROMAN的全球定位方法，能够在具有挑战性和多样化的环境中进行定位。&lt;h4&gt;方法&lt;/h4&gt;ROMAN通过创建和对齐开放集和视图不变对象的地图，解决特征稀疏或感知混淆环境中的定位难题，采用统一的图论全局数据关联方法，同时考虑对象形状、语义相似性和重力方向的先验。&lt;h4&gt;主要发现&lt;/h4&gt;在一系列大型多机器人或多会话SLAM实验中，ROMAN的最大召回率比其他基于对象的地图对齐方法高36%，绝对轨迹误差比使用视觉特征进行回环检测低37%。&lt;h4&gt;结论&lt;/h4&gt;ROMAN在室内、城市和非结构化/森林环境中的表现优于现有方法，展示了其在复杂环境中的有效性。&lt;h4&gt;总结&lt;/h4&gt;ROMAN是一种强大的全局定位方法，能够克服传统方法在多样化环境中的局限性，提供更高的定位精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Global localization is a fundamental capability required for long-term anddrift-free robot navigation. However, current methods fail to relocalize whenfaced with significantly different viewpoints. We present ROMAN (Robust ObjectMap Alignment Anywhere), a robust global localization method capable oflocalizing in challenging and diverse environments based on creating andaligning maps of open-set and view-invariant objects. To address localizationdifficulties caused by feature-sparse or perceptually aliased environments,ROMAN formulates and solves a registration problem between object submaps usinga unified graph-theoretic global data association approach that simultaneouslyaccounts for object shape and semantic similarities and a prior on gravitydirection. Through a set of challenging large-scale multi-robot ormulti-session SLAM experiments in indoor, urban and unstructured/forestedenvironments, we demonstrate that ROMAN achieves a maximum recall 36% higherthan other object-based map alignment methods and an absolute trajectory errorthat is 37% lower than using visual features for loop closures. Our projectpage can be found at https://acl.mit.edu/ROMAN/.</description>
      <author>example@mail.com (Mason B. Peterson, Yi Xuan Jia, Yulun Tian, Annika Thomas, Jonathan P. How)</author>
      <guid isPermaLink="false">2410.08262v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Constrained Posterior Sampling: Time Series Generation with Hard Constraints</title>
      <link>http://arxiv.org/abs/2410.12652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成现实的时间序列样本对压力测试模型和保护用户隐私非常重要，尤其是在工程和安全关键应用中。&lt;h4&gt;目的&lt;/h4&gt;生成符合特定领域约束的时间序列样本，以应对电力需求模式等实际问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为约束后验采样（CPS）的扩散采样算法，旨在每次去噪更新后将后验均值投影到约束集内。&lt;h4&gt;主要发现&lt;/h4&gt;CPS能够在不需要额外训练的情况下，扩展到大约100个约束，并在样本质量和与真实时间序列的相似性方面超越现有方法，分别提高约10%和42%。&lt;h4&gt;结论&lt;/h4&gt;CPS在处理约束时间序列生成方面具有显著优势，能够更好地满足实际应用需求。&lt;h4&gt;总结&lt;/h4&gt;CPS是一种有效的算法，能够在保持样本质量的同时满足大量约束，适用于各种实际数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating realistic time series samples is crucial for stress-testing modelsand protecting user privacy by using synthetic data. In engineering andsafety-critical applications, these samples must meet certain hard constraintsthat are domain-specific or naturally imposed by physics or nature. Consider,for example, generating electricity demand patterns with constraints on peakdemand times. This can be used to stress-test the functioning of power gridsduring adverse weather conditions. Existing approaches for generatingconstrained time series are either not scalable or degrade sample quality. Toaddress these challenges, we introduce Constrained Posterior Sampling (CPS), adiffusion-based sampling algorithm that aims to project the posterior meanestimate into the constraint set after each denoising update. Notably, CPSscales to a large number of constraints (~100) without requiring additionaltraining. We provide theoretical justifications highlighting the impact of ourprojection step on sampling. Empirically, CPS outperforms state-of-the-artmethods in sample quality and similarity to real time series by around 10% and42%, respectively, on real-world stocks, traffic, and air quality datasets.</description>
      <author>example@mail.com (Sai Shankar Narasimhan, Shubhankar Agarwal, Litu Rout, Sanjay Shakkottai, Sandeep P. Chinchali)</author>
      <guid isPermaLink="false">2410.12652v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Novelty-based Sample Reuse for Continuous Robotics Control</title>
      <link>http://arxiv.org/abs/2410.13490v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;强化学习中的智能体通过与环境的互动收集状态信息和奖励，这对策略优化至关重要，但这一过程非常耗时，尤其在复杂的机器人仿真和现实应用中。&lt;h4&gt;目的&lt;/h4&gt;解决传统算法在处理样本后重新与环境交互导致的历史数据利用不充分的问题。&lt;h4&gt;方法&lt;/h4&gt;提出新颖性引导的样本重用（NSR）方法，为不常见的新状态提供额外更新，而对频繁状态跳过额外更新，以最大化样本利用率。&lt;h4&gt;主要发现&lt;/h4&gt;NSR方法提高了算法的收敛速度和成功率，同时并未显著增加时间消耗。&lt;h4&gt;结论&lt;/h4&gt;NSR有效改善了样本利用效率，适用于强化学习中的复杂任务。&lt;h4&gt;总结&lt;/h4&gt;通过NSR方法，可以更有效地利用样本，加快学习过程，提升智能体在强化学习中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ppksigs/nsr_ddpg_her_for_manipulation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In reinforcement learning, agents collect state information and rewardsthrough environmental interactions, essential for policy refinement. Thisprocess is notably time-consuming, especially in complex robotic simulationsand real-world applications. Traditional algorithms usually re-engage with theenvironment after processing a single batch of samples, thereby failing tofully capitalize on historical data. However, frequently observed states, withreliable value estimates, require minimal updates; in contrast, rare observedstates necessitate more intensive updates for achieving accurate valueestimations. To address uneven sample utilization, we propose Novelty-guidedSample Reuse (NSR). NSR provides extra updates for infrequent, novel states andskips additional updates for frequent states, maximizing sample use beforeinteracting with the environment again. Our experiments show that NSR improvesthe convergence rate and success rate of algorithms without significantlyincreasing time consumption. Our code is publicly available athttps://github.com/ppksigs/NSR-DDPG-HER.</description>
      <author>example@mail.com (Ke Duan, Kai Yang, Houde Liu, Xueqian Wang)</author>
      <guid isPermaLink="false">2410.13490v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing NeRF-based SLAM with Trajectory Smoothness Constraints</title>
      <link>http://arxiv.org/abs/2410.08780v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;NeRF和摄像机轨迹的联合优化在SLAM任务中因其卓越的密集映射质量和一致性而得到广泛应用。&lt;h4&gt;目的&lt;/h4&gt;解决当前NeRF基础SLAM中的摄像机运动不平滑和不现实的问题。&lt;h4&gt;方法&lt;/h4&gt;提出TS-SLAM，通过均匀的三次B样条表示摄像机轨迹，引入平滑性约束，以确保摄像机运动的平滑性。&lt;h4&gt;主要发现&lt;/h4&gt;TS-SLAM在轨迹准确性和映射质量上优于未采用平滑约束的NeRF基础SLAM。&lt;h4&gt;结论&lt;/h4&gt;通过利用B样条的可微性和局部控制特性，TS-SLAM能够增量学习控制点，从而提高SLAM的整体性能。&lt;h4&gt;总结&lt;/h4&gt;TS-SLAM有效改善了摄像机轨迹的平滑性，提升了SLAM的映射质量和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The joint optimization of Neural Radiance Fields (NeRF) and cameratrajectories has been widely applied in SLAM tasks due to its superior densemapping quality and consistency. NeRF-based SLAM learns camera poses usingconstraints by implicit map representation. A widely observed phenomenon thatresults from the constraints of this form is jerky and physically unrealisticestimated camera motion, which in turn affects the map quality. To address thisdeficiency of current NeRF-based SLAM, we propose in this paper TS-SLAM (TS forTrajectory Smoothness). It introduces smoothness constraints on cameratrajectories by representing them with uniform cubic B-splines with continuousacceleration that guarantees smooth camera motion. Benefiting from thedifferentiability and local control properties of B-splines, TS-SLAM canincrementally learn the control points end-to-end using a sliding windowparadigm. Additionally, we regularize camera trajectories by exploiting thedynamics prior to further smooth trajectories. Experimental results demonstratethat TS-SLAM achieves superior trajectory accuracy and improves mapping qualityversus NeRF-based SLAM that does not employ the above smoothness constraints.</description>
      <author>example@mail.com (Yicheng He, Guangcheng Chen, Hong Zhang)</author>
      <guid isPermaLink="false">2410.08780v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Context Matters: Leveraging Contextual Features for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.12672v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列预测通常受外部上下文特征的影响，尤其是在金融领域，无法仅凭历史数据准确预测股价。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法ContextFormer，以有效整合多模态上下文信息，提升现有预测模型的性能。&lt;h4&gt;方法&lt;/h4&gt;ContextFormer能够从丰富的多模态上下文中提取与预测相关的信息，包括分类、连续、时变和事件文本信息。&lt;h4&gt;主要发现&lt;/h4&gt;ContextFormer在多个现实世界数据集上，较现有最先进的预测模型提高了最多30%的性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入多模态上下文信息，ContextFormer显著增强了传统时间序列预测模型的效果。&lt;h4&gt;总结&lt;/h4&gt;ContextFormer是一种新颖的可插拔方法，能够有效提升时间序列预测的准确性，尤其是在考虑外部信息时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasts are often influenced by exogenous contextual featuresin addition to their corresponding history. For example, in financial settings,it is hard to accurately predict a stock price without considering publicsentiments and policy decisions in the form of news articles, tweets, etc.Though this is common knowledge, the current state-of-the-art (SOTA)forecasting models fail to incorporate such contextual information, owing toits heterogeneity and multimodal nature. To address this, we introduceContextFormer, a novel plug-and-play method to surgically integrate multimodalcontextual information into existing pre-trained forecasting models.ContextFormer effectively distills forecast-specific information from richmultimodal contexts, including categorical, continuous, time-varying, and eventextual information, to significantly enhance the performance of existing baseforecasters. ContextFormer outperforms SOTA forecasting models by up to 30% ona range of real-world datasets spanning energy, traffic, environmental, andfinancial domains.</description>
      <author>example@mail.com (Sameep Chattopadhyay, Pulkit Paliwal, Sai Shankar Narasimhan, Shubhankar Agarwal, Sandeep P. Chinchali)</author>
      <guid isPermaLink="false">2410.12672v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>State Estimation Transformers for Agile Legged Locomotion</title>
      <link>http://arxiv.org/abs/2410.13496v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IROS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种状态估计方法，旨在提高四足机器人在执行高级技能（如跳跃）时的表现。&lt;h4&gt;目的&lt;/h4&gt;推测机器人的特权状态，以推动四足机器人在复杂环境中的能力。&lt;h4&gt;方法&lt;/h4&gt;引入状态估计变换器（SET），将状态估计问题视为条件序列建模，通过因果掩码的变换器输出难以直接获得的机器人状态。&lt;h4&gt;主要发现&lt;/h4&gt;SET在动态运动中能够准确预测机器人状态，且在三个任务（奔跑、跳跃、后空翻）中表现优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;SET在估计准确性和转移性方面表现出色，尤其是在真实世界中的跳跃成功率和激活恢复控制器方面，显示出变换器基础的状态估计器在动态运动任务中的优势。&lt;h4&gt;总结&lt;/h4&gt;SET方法为四足机器人提供了一种有效的状态估计手段，能够在复杂环境中实现高级技能的执行。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a state estimation method that can accurately predict the robot'sprivileged states to push the limits of quadruped robots in executing advancedskills such as jumping in the wild. In particular, we present the StateEstimation Transformers (SET), an architecture that casts the state estimationproblem as conditional sequence modeling. SET outputs the robot states that arehard to obtain directly in the real world, such as the body height andvelocities, by leveraging a causally masked Transformer. By conditioning anautoregressive model on the robot's past states, our SET model can predictthese privileged observations accurately even in highly dynamic locomotions. Weevaluate our methods on three tasks -- running jumping, running backflipping,and running sideslipping -- on a low-cost quadruped robot, Cyberdog2. Resultsshow that SET can outperform other methods in estimation accuracy andtransferability in the simulation as well as success rates of jumping andtriggering a recovery controller in the real world, suggesting the superiorityof such a Transformer-based explicit state estimator in highly dynamiclocomotion tasks.</description>
      <author>example@mail.com (Chen Yu, Yichu Yang, Tianlin Liu, Yangwei You, Mingliang Zhou, Diyun Xiang)</author>
      <guid isPermaLink="false">2410.13496v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>A Gaussian process model for stellar activity in 2-D line profile time-series</title>
      <link>http://arxiv.org/abs/2410.12698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in MNRAS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;恒星活动区域如黑子和耀斑会扭曲光谱线的形状，导致径向速度的变化，这种变化通常远大于地球类行星的信号。&lt;h4&gt;目的&lt;/h4&gt;提出一种物理驱动的高斯过程框架，以直接建模光谱线轮廓或交叉相关函数中的活动信号。&lt;h4&gt;方法&lt;/h4&gt;该方法利用光谱线轮廓变化中速度（波长）区间之间的时间相关性，基于一个简化但物理上合理的模型。&lt;h4&gt;主要发现&lt;/h4&gt;在信噪比低至约100的合成和真实数据集上，该方法能够有效区分行星信号和活动信号，即使它们的周期相同。&lt;h4&gt;结论&lt;/h4&gt;通过对两年的HARPS-N太阳数据进行注入/恢复测试，证明该方法能准确恢复1.5个地球质量的行星信号，半幅值为0.3 m/s，周期为33天，尤其是在高太阳活动期间。&lt;h4&gt;总结&lt;/h4&gt;提出的高斯过程框架为从恒星活动中提取行星信号提供了一种有效的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stellar active regions like spots and faculae can distort the shapes ofspectral lines, inducing variations in the radial velocities that are oftenorders of magnitude larger than the signals from Earth-like planets. Efforts tomitigate these activity signals have hitherto focused on either the time or thevelocity (wavelength) domains. We present a physics-driven Gaussian process(GP) framework to model activity signals directly in time series of lineprofiles or Cross-Correlation Functions (CCFs). Unlike existing methods whichcorrect activity signals in line profile time series, our approach exploits thetime correlation between velocity (wavelength) bins in the line profilevariations, and is based on a simplified but physically motivated model for theorigin of these variations. When tested on both synthetic and real data setswith signal-to-noise ratios down to $\sim$ 100, our method was able to separatethe planetary signal from the activity signal, even when their periods wereidentical. We also conducted injection/recovery tests using two years ofrealistically sampled HARPS-N solar data, demonstrating the ability of themethod to accurately recover a signal induced by a 1.5-Earth mass planet with asemi-amplitude of 0.3 m/s and a period of 33 days during high solar activity.</description>
      <author>example@mail.com (Haochuan Yu, Suzanne Aigrain, Baptiste Klein, Michael Cretignier, Florian Lienhard, Stephen J. Roberts)</author>
      <guid isPermaLink="false">2410.12698v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Voxel-SLAM: A Complete, Accurate, and Versatile LiDAR-Inertial SLAM System</title>
      <link>http://arxiv.org/abs/2410.08935v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究提出了Voxel-SLAM，一个完整、准确且多功能的LiDAR-惯性SLAM系统。&lt;h4&gt;目的&lt;/h4&gt;实现实时估计和高精度地图构建，充分利用短期、中期、长期和多地图数据关联。&lt;h4&gt;方法&lt;/h4&gt;系统由初始化、里程计、局部映射、回环闭合和全局映射五个模块组成，使用自适应体素地图作为统一的地图表示。&lt;h4&gt;主要发现&lt;/h4&gt;在30个序列的基准比较中，与其他先进方法相比，Voxel-SLAM在狭窄室内、大型野外和城市环境下表现出色，显示出初始化的鲁棒性和效率。&lt;h4&gt;结论&lt;/h4&gt;该系统能够处理多个会话并在退化环境中进行重新定位，展示了其高效性和适应性。&lt;h4&gt;总结&lt;/h4&gt;Voxel-SLAM系统通过多种数据关联技术，实现了高效的实时估计和高精度映射，是一种先进的SLAM解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we present Voxel-SLAM: a complete, accurate, and versatileLiDAR-inertial SLAM system that fully utilizes short-term, mid-term, long-term,and multi-map data associations to achieve real-time estimation and highprecision mapping. The system consists of five modules: initialization,odometry, local mapping, loop closure, and global mapping, all employing thesame map representation, an adaptive voxel map. The initialization provides anaccurate initial state estimation and a consistent local map for subsequentmodules, enabling the system to start with a highly dynamic initial state. Theodometry, exploiting the short-term data association, rapidly estimates currentstates and detects potential system divergence. The local mapping, exploitingthe mid-term data association, employs a local LiDAR-inertial bundle adjustment(BA) to refine the states (and the local map) within a sliding window of recentLiDAR scans. The loop closure detects previously visited places in the currentand all previous sessions. The global mapping refines the global map with anefficient hierarchical global BA. The loop closure and global mapping bothexploit long-term and multi-map data associations. We conducted a comprehensivebenchmark comparison with other state-of-the-art methods across 30 sequencesfrom three representative scenes, including narrow indoor environments usinghand-held equipment, large-scale wilderness environments with aerial robots,and urban environments on vehicle platforms. Other experiments demonstrate therobustness and efficiency of the initialization, the capacity to work inmultiple sessions, and relocalization in degenerated environments.</description>
      <author>example@mail.com (Zheng Liu, Haotian Li, Chongjian Yuan, Xiyuan Liu, Jiarong Lin, Rundong Li, Chunran Zheng, Bingyang Zhou, Wenyi Liu, Fu Zhang)</author>
      <guid isPermaLink="false">2410.08935v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Photometric detection of internal gravity waves in upper main-sequence stars. IV. Comparable SLF variability in SMC, LMC and Galactic massive stars</title>
      <link>http://arxiv.org/abs/2410.12726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Re-submitted to A&amp;A after a positive first referee report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大质量主序星具有对流核心和辐射包层，以及表面下对流区，其特性强烈依赖于星体的光学性质和金属丰度。&lt;h4&gt;目的&lt;/h4&gt;研究不同金属丰度的巨大星体在表面下对流稳定性窗口内外的SLF变异性是否表现出相似特性。&lt;h4&gt;方法&lt;/h4&gt;使用TESS任务提取定制的光变曲线，并采用有效点扩散函数(ePSF)方法和高斯过程(GP)回归方法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;在从银河系到SMC星系的金属丰度范围内，巨大星体的SLF变异性特性是一致的，无论是否在表面下稳定窗口内。&lt;h4&gt;结论&lt;/h4&gt;非旋转的一维星体结构模型无法独立解释巨大星体光变曲线中的SLF变异性机制。SLF变异性在不同金属丰度下表现出的相似特性支持了由年轻星体向更演化星体过渡的主导机制变化。&lt;h4&gt;总结&lt;/h4&gt;年轻星体主要依赖于核心激发的内部重力波，而最重和演化较久的星体则更倾向于具有表面下对流区。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Massive main-sequence stars have convective cores and radiative envelopes,and sub-surface convection zones. However, their properties strongly depend ona star's opacity and metallicity. Non-rotating 1D evolution models ofmain-sequence stars between $7 \leq M \leq 40$ M$_{\odot}$ and metallicity ofthe SMC suggest tenuous sub-surface convection zones when using the Rayleighnumber as a criterion for convection. We test if massive stars of differentmetallicities inside and outside of stability windows for sub-surfaceconvection exhibit similar properties in their observed SLF variability. Weextract customised light curves from the ongoing TESS mission for a sample ofmassive stars using an effective point spread function (ePSF) method, andcompare them using a Gaussian process (GP) regression methodology. Wedemonstrate that the properties of SLF variability observed in time-seriesphotometry of massive stars are consistent across the metallicity range fromthe Milky Way down to the SMC galaxy, for stars both inside and outside of thesub-surface stability windows. We conclude that non-rotating 1D stellarstructure models of sub-surface convection cannot alone be used to explain themechanism giving rise to SLF variability in light curves of massive stars.Additionally, the similar properties of SLF variability across a large range inmetallicity, which follow the same trends in mass and age in theHertzsprung-Russell (HR) diagram at both high and low metallicity, support atransition in the dominant mechanism causing SLF variability from younger tomore evolved stars. Specifically, core-excited internal gravity waves (IGWs)are more favourable for younger stars that lack substantial sub-surfaceconvection zones, especially at low-metallicity, and sub-surface convectionzones are more favourable for the most massive and evolved stars. (abstractabridged for arxiv submission)</description>
      <author>example@mail.com (Dominic M. Bowman, Pieterjan Van Daele, Mathias Michielsen, Timothy Van Reeth)</author>
      <guid isPermaLink="false">2410.12726v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ESVO2: Direct Visual-Inertial Odometry with Stereo Event Cameras</title>
      <link>http://arxiv.org/abs/2410.09374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;事件驱动视觉里程计是视觉同时定位与地图构建（SLAM）技术的一种特定分支，旨在利用神经形态摄像头的工作原理并行解决跟踪和地图构建问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于事件的立体视觉惯性里程计系统，以解决现有直接方法在计算复杂性和相机姿态跟踪方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;通过根据事件的局部动态有效采样轮廓点，加速地图构建操作；通过合并时间立体和静态立体结果，提高地图构建的结构完整性和局部平滑性；引入IMU测量作为运动先验，解决相机姿态跟踪中的退化问题。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的系统在现代高分辨率事件摄像机上表现良好，能够提高大规模户外环境中的全局定位精度。&lt;h4&gt;结论&lt;/h4&gt;通过在五个公开数据集上的广泛评估，证明了所提出系统相较于五种最先进方法的优越性能。&lt;h4&gt;总结&lt;/h4&gt;该研究为事件驱动视觉里程计的发展提供了有效的解决方案，尤其在处理复杂运动和提高地图质量方面具有显著的贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nail-hnu/esvo2&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Event-based visual odometry is a specific branch of visual SimultaneousLocalization and Mapping (SLAM) techniques, which aims at solving tracking andmapping sub-problems in parallel by exploiting the special working principlesof neuromorphic (ie, event-based) cameras. Due to the motion-dependent natureof event data, explicit data association ie, feature matching underlarge-baseline view-point changes is hardly established, making direct methodsa more rational choice. However, state-of-the-art direct methods are limited bythe high computational complexity of the mapping sub-problem and the degeneracyof camera pose tracking in certain degrees of freedom (DoF) in rotation. Inthis paper, we resolve these issues by building an event-based stereovisual-inertial odometry system on top of our previous direct pipelineEvent-based Stereo Visual Odometry. Specifically, to speed up the mappingoperation, we propose an efficient strategy for sampling contour pointsaccording to the local dynamics of events. The mapping performance is alsoimproved in terms of structure completeness and local smoothness by merging thetemporal stereo and static stereo results. To circumvent the degeneracy ofcamera pose tracking in recovering the pitch and yaw components of generalsix-DoF motion, we introduce IMU measurements as motion priors viapre-integration. To this end, a compact back-end is proposed for continuouslyupdating the IMU bias and predicting the linear velocity, enabling an accuratemotion prediction for camera pose tracking. The resulting system scales wellwith modern high-resolution event cameras and leads to better globalpositioning accuracy in large-scale outdoor environments. Extensive evaluationson five publicly available datasets featuring different resolutions andscenarios justify the superior performance of the proposed system against fivestate-of-the-art methods.</description>
      <author>example@mail.com (Junkai Niu, Sheng Zhong, Xiuyuan Lu, Shaojie Shen, Guillermo Gallego, Yi Zhou)</author>
      <guid isPermaLink="false">2410.09374v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Latency-Aware Inter-domain Routing</title>
      <link>http://arxiv.org/abs/2410.13019v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管云服务和内容提供商已努力降低延迟以满足当前和未来的服务需求，但仍有改进空间。&lt;h4&gt;目的&lt;/h4&gt;提出改进方案，以降低互联网中的延迟。&lt;h4&gt;方法&lt;/h4&gt;提出两项实现修改，使边界网关协议（BGP）能够感知延迟，从而减少延迟的膨胀。&lt;h4&gt;主要发现&lt;/h4&gt;延迟比例的自治系统（AS）前置和本地偏好中立化的提案显示出传播抽象延迟信息的潜力，同时增加的路由开销合理。&lt;h4&gt;结论&lt;/h4&gt;通过以上提案，可以有效降低互联网服务中的延迟问题。&lt;h4&gt;总结&lt;/h4&gt;本研究为改善BGP的延迟感知能力提供了新的思路，旨在提升网络性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite efforts from cloud and content providers to lower latency toacceptable levels for current and future services (e.g., augmented reality orcloud gaming), there are still opportunities for improvement. A major reasonthat traffic engineering efforts are challenged to lower latency is that theInternet's inter-domain routing protocol, the Border Gateway Protocol, isoblivious to any performance metric, and circuitous routing is still pervasive.  In this work, we propose two implementation modifications that networks canleverage to make BGP latency-aware and reduce excessive latency inflation.These proposals, latency-proportional AS prepending and local preferenceneutralization, show promise towards providing a method for propagatingabstract latency information with a reasonable increase in routing overhead.</description>
      <author>example@mail.com (Shihan Lin, Yi Zhou, Xiao Zhang, Todd Arnold, Ramesh Govindan, Xiaowei Yang)</author>
      <guid isPermaLink="false">2410.13019v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SSET: Swapping-Sliding Explanation for Time Series Classifiers in Affect Detection</title>
      <link>http://arxiv.org/abs/2410.12996v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器学习模型的局部解释受到广泛关注，特别是在图像数据的可解释性上，但多变量时间序列数据的研究较少。&lt;h4&gt;目的&lt;/h4&gt;提出一种针对多变量时间序列分类器的决策解释方法，称为SSET，以改善时间序列数据的可解释性。&lt;h4&gt;方法&lt;/h4&gt;SSET包括交换和滑动两个阶段，通过检测重要变量并在每个时间步长上滑动窗口，呈现影响预测结果的显著子序列。&lt;h4&gt;主要发现&lt;/h4&gt;在情感检测领域，SSET在两个真实生理时间序列数据集（WESAD和MAHNOB-HCI）上的评估表明，其性能优于之前的模型。&lt;h4&gt;结论&lt;/h4&gt;SSET提供了一种有效的时间序列数据解释方法，克服了传统方法的限制，为实际应用提供了有效的解释。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的SSET方法在多变量时间序列数据的可解释性方面具有重要意义，特别是在情感状态检测中表现良好。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Local explanation of machine learning (ML) models has recently receivedsignificant attention due to its ability to reduce ambiguities about why themodels make specific decisions. Extensive efforts have been invested to addressexplainability for different data types, particularly images. However, the workon multivariate time series data is limited. A possible reason is that theconflation of time and other variables in time series data can cause thegenerated explanations to be incomprehensible to humans. In addition, someefforts on time series fall short of providing accurate explanations as theyeither ignore a context in the time domain or impose differentiabilityrequirements on the ML models. Such restrictions impede their ability toprovide valid explanations in real-world applications and non-differentiable MLsettings. In this paper, we propose a swapping--sliding decision explanationfor multivariate time series classifiers, called SSET. The proposal consists ofswapping and sliding stages, by which salient sub-sequences causing significantdrops in the prediction score are presented as explanations. In the formerstage, the important variables are detected by swapping the series of interestwith close train data from target classes. In the latter stage, the salientobservations of these variables are explored by sliding a window over each timestep. Additionally, the model measures the importance of different variablesover time in a novel way characterized by multiple factors. We leverage SSET onaffect detection domain where evaluations are performed on two real-worldphysiological time series datasets, WESAD and MAHNOB-HCI, and a deepconvolutional classifier, CN-Waterfall. This classifier has shown superiorperformance to prior models to detect human affective states. Comparing SSETwith several benchmarks, including LIME, integrated gradients, and Dynamask, wefound..</description>
      <author>example@mail.com (Nazanin Fouladgar, Marjan Alirezaie, Kary Främling)</author>
      <guid isPermaLink="false">2410.12996v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>An Expeditious Spatial Mean Radiant Temperature Mapping Framework using Visual SLAM and Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.09443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by 2024 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;确保热舒适对建筑环境中个体的福祉和生产力至关重要，而平均辐射温度（MRT）是测量中非常具有挑战性的指标。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的MRT测量框架，以解决传统测量方法耗时且不易用的问题。&lt;h4&gt;方法&lt;/h4&gt;该框架结合视觉同时定位与地图构建（SLAM）和语义分割技术，基于传统MRT计算方法的经验法则，使用表面温度和视因子，创建包含丰富表面温度信息的3D热点云。&lt;h4&gt;主要发现&lt;/h4&gt;通过使用Grounded SAM这一新型目标检测和分割工具，提取具有不同温度特征的建筑表面特征，详细分割热特征减少了MRT计算中的潜在误差，并有效重建室内环境中的空间MRT分布。&lt;h4&gt;结论&lt;/h4&gt;该数据驱动框架提供比传统方法更快、更高效的MRT测量和空间映射，能够直接让研究人员和从业者参与MRT测量，并有助于热舒适及辐射冷却和加热系统的研究。&lt;h4&gt;总结&lt;/h4&gt;该研究为提升热舒适度的测量方法提供了新的思路和工具，具有重要的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring thermal comfort is essential for the well-being and productivity ofindividuals in built environments. Of the various thermal comfort indicators,the mean radiant temperature (MRT) is very challenging to measure. Most commonmeasurement methodologies are time-consuming and not user-friendly. To addressthis issue, this paper proposes a novel MRT measurement framework that usesvisual simultaneous localization and mapping (SLAM) and semantic segmentationtechniques. The proposed approach follows the rule of thumb of the traditionalMRT calculation method using surface temperature and view factors. However, itemploys visual SLAM and creates a 3D thermal point cloud with enriched surfacetemperature information. The framework then implements Grounded SAM, a newobject detection and segmentation tool to extract features with distincttemperature profiles on building surfaces. The detailed segmentation of thermalfeatures not only reduces potential errors in the calculation of the MRT butalso provides an efficient reconstruction of the spatial MRT distribution inthe indoor environment. We also validate the calculation results with thereference measurement methodology. This data-driven framework offers faster andmore efficient MRT measurements and spatial mapping than conventional methods.It can enable the direct engagement of researchers and practitioners in MRTmeasurements and contribute to research on thermal comfort and radiant coolingand heating systems.</description>
      <author>example@mail.com (Wei Liang, Yiting Zhang, Ji Zhang, Erica Cochran Hameen)</author>
      <guid isPermaLink="false">2410.09443v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Design of an Efficient Fan-Shaped Clustered Trust-Based Routing Model with QoS &amp; Security-Aware Side-Chaining for IoV Deployments</title>
      <link>http://arxiv.org/abs/2410.12798v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://ijisae.org/index.php/IJISAE/article/view/3770&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物联网车辆（IoV）快速扩展导致需要高效且安全的路由模型，以管理由互联设备和车辆产生的大量数据流量。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的扇形信任基础路由模型，结合服务质量（QoS）和安全意识的侧链管理。&lt;h4&gt;方法&lt;/h4&gt;使用延迟、吞吐量、数据包交付率（PDR）和能耗等时间层次指标来确定最佳路由路径，确保高效的数据传输；采用细菌觅食优化器（BFO）算法动态调整侧链配置；利用扇形聚类方法将节点分组以提高通信效率和资源利用率。&lt;h4&gt;主要发现&lt;/h4&gt;与替代方法相比，模型在延迟、吞吐量、PDR和能耗方面分别实现了9.5%、10.5%、2.9%和4.5%的改进；模型在面对Sybil、伪装和洪水攻击等安全威胁时，仍能保持较高的QoS水平。&lt;h4&gt;结论&lt;/h4&gt;提出的路由模型和侧链管理方法在智能城市、工业自动化、医疗系统、交通网络和环境监测等领域具有广泛应用。&lt;h4&gt;总结&lt;/h4&gt;该研究显著提升了现有区块链安全模型的性能，并提供了可靠的数据传输保障。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-09-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid expansion of Internet of Vehicles (IoV) deployments hasnecessitated the creation of efficient and secure routing models to manage themassive data traffic generated by interconnected devices &amp; vehicles. For IoVdeployments, we propose a novel fan-shaped trust-based routing model withQuality of Service (QoS) and security-aware side-chaining. Our method employstemporal levels of delay, throughput, Packet Delivery Ratio (PDR), and energyconsumption to determine optimal routing paths, thereby ensuring efficient datatransmissions. We employ the Bacterial Foraging Optimizer (BFO) algorithm tomanage side-chains within the network, which dynamically adjusts side-chainconfigurations to optimize system performance. The technique of fan-shapedclustering is used to group nodes into efficient clusters, allowing for moreefficient communication and resource utilization sets. Extensiveexperimentation and performance analysis are utilized to evaluate the proposedmodel. Existing blockchain-based security models have been significantlyimproved by our findings. Our model achieves a remarkable 9.5% reduction indelay, a 10.5% improvement in throughput, a 2.9% improvement in PDR, and a 4.5%reduction in energy consumption compared to alternative approaches. Inaddition, we evaluate the model's resistance to Sybil, Masquerading, andFlooding attacks, which are prevalent security threats for IoV deployments.Even under these attack scenarios, our model provides consistently higher QoSlevels compared to existing solutions, ensuring uninterrupted and reliable datatransmissions. In IoV deployments, the proposed routing model and side-chainingmanagement approach have numerous applications and use-cases like Smart cities,industrial automation, healthcare systems, transportation networks, andenvironmental monitoring.</description>
      <author>example@mail.com (Sadaf Ravindra Suryawanshi, Praveen Gupta)</author>
      <guid isPermaLink="false">2410.12798v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Design and Feasibility of a Community Motorcycle Ambulance System in the Philippines</title>
      <link>http://arxiv.org/abs/2410.13026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究调查在菲律宾马尼拉大都会和伊洛伊洛市部署摩托车救护车（motorlance）的潜力，以改善高交通量、服务不足地区的紧急医疗服务。&lt;h4&gt;目的&lt;/h4&gt;旨在提供快速、经济的替代方案，以应对传统救护车在拥挤城市和偏远农村地区的不足。&lt;h4&gt;方法&lt;/h4&gt;通过现场访问、司机访谈和用户调查，评估公众对摩托车救护车概念的信任和接受度，同时进行成本分析以验证其财务可行性。&lt;h4&gt;主要发现&lt;/h4&gt;在马拉维、泰国和伊朗的试点项目显示，摩托车救护车系统显著改善了响应时间和成本效率。&lt;h4&gt;结论&lt;/h4&gt;摩托车救护车在马尼拉和伊洛伊洛市的实施具有可行性，未来工作将集中在马丹劳永的实际试点实施上，并根据该试点的成功扩展服务至类似地区。&lt;h4&gt;总结&lt;/h4&gt;摩托车救护车系统能够有效提升菲律宾紧急医疗服务的质量，尤其是在交通繁忙和资源不足的地区。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates the potential for motorcycle ambulance (motorlance)deployment in Metro Manila and Iloilo City to improve emergency medical care inhigh-traffic, underserved regions of the Philippines. VSee, a humanitariantechnology company, has organized numerous free clinics in the Philippines andidentified a critical need for improved emergency services. Motorlances offer afast, affordable alternative to traditional ambulances, particularly incongested urban settings and remote rural locations. Pilot programs in Malawi,Thailand, and Iran have demonstrated significant improvements in response timesand cost-efficiency with motorlance systems. This study presents a frameworkfor motorlance operation and identifies three potential pilot locations:Mandaluyong, Smokey Mountain, and Iloilo City. Site visits, driver interviews,and user surveys indicate public trust in the motorlance concept and positivereception to potential motorlance deployment. Cost analysis verifies thefinancial feasibility of motorlance systems. Future work will focus onimplementing a physical pilot in Mandaluyong, with the aim of expanding serviceto similar regions contingent on the Mandaluyong pilot's success.</description>
      <author>example@mail.com (Aaron Rodriguez, Aidan Chen, Ryan Rodriguez)</author>
      <guid isPermaLink="false">2410.13026v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SPF-EMPC Planner: A real-time multi-robot trajectory planner for complex environments with uncertainties</title>
      <link>http://arxiv.org/abs/2410.13573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在实际应用中，障碍物的不确定运动和机器人状态观测的不精确性给机器人群体带来了显著的不确定性，特别是在集群环境中。&lt;h4&gt;目的&lt;/h4&gt;解决复杂动态不确定环境中的多机器人导航问题。&lt;h4&gt;方法&lt;/h4&gt;引入扩展状态模型预测控制规划器，结合安全概率场，生成安全轨迹并考虑机器人模型约束和状态不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;仿真实验显示成功率比最先进算法高出四倍，物理实验验证了方法的实时操作能力。&lt;h4&gt;结论&lt;/h4&gt;该方法能够确保多机器人在不确定环境中的安全导航。&lt;h4&gt;总结&lt;/h4&gt;提出的规划器有效应对动态障碍物和环境复杂性，为多机器人安全导航提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In practical applications, the unpredictable movement of obstacles and theimprecise state observation of robots introduce significant uncertainties forthe swarm of robots, especially in cluster environments. However, existingmethods are difficult to realize safe navigation, considering uncertainties,complex environmental structures, and robot swarms. This paper introduces anextended state model predictive control planner with a safe probability fieldto address the multi-robot navigation problem in complex, dynamic, anduncertain environments. Initially, the safe probability field offers aninnovative approach to model the uncertainty of external dynamic obstacles,combining it with an unconstrained optimization method to generate safetrajectories for multi-robot online. Subsequently, the extended state modelpredictive controller can accurately track these generated trajectories whileconsidering the robots' inherent model constraints and state uncertainty, thusensuring the practical feasibility of the planned trajectories. Simulationexperiments show a success rate four times higher than that of state-of-the-artalgorithms. Physical experiments demonstrate the method's ability to operate inreal-time, enabling safe navigation for multi-robot in uncertain environments.</description>
      <author>example@mail.com (Peng Liu, Pengming Zhu, Zhiwen Zeng, Xuekai Qiu, Yu Wang, Huimin Lu)</author>
      <guid isPermaLink="false">2410.13573v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Online conformal inference for multi-step time series forecasting</title>
      <link>http://arxiv.org/abs/2410.13115v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;考虑构建无分布预测区间的问题，重点关注多步预测误差的时间依赖性。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来有效地处理多步预测的自相关性，以提高预测区间的统计效率。&lt;h4&gt;方法&lt;/h4&gt;提出自相关多步符合预测（AcMCP）方法，利用自相关性质来构建多步预测区间，并扩展现有的单步符合预测方法以适应多步场景。&lt;h4&gt;主要发现&lt;/h4&gt;AcMCP方法在局部窗口内的覆盖率接近目标，同时提供适应性预测区间，能有效应对变化条件。&lt;h4&gt;结论&lt;/h4&gt;虽然在有限样本情况下，增加预测时间范围可能会加剧与目标覆盖的偏差，但该方法仍保证了理论上的长期覆盖保障。&lt;h4&gt;总结&lt;/h4&gt;AcMCP方法为多步时间序列预测提供了一种有效的解决方案，确保了预测区间的可靠性和统计效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of constructing distribution-free predictionintervals for multi-step time series forecasting, with a focus on the temporaldependencies inherent in multi-step forecast errors. We establish that theoptimal $h$-step-ahead forecast errors exhibit serial correlation up to lag$(h-1)$ under a general non-stationary autoregressive data generating process.To leverage these properties, we propose the Autocorrelated Multi-stepConformal Prediction (AcMCP) method, which effectively incorporatesautocorrelations in multi-step forecast errors, resulting in more statisticallyefficient prediction intervals. This method ensures theoretical long-runcoverage guarantees for multi-step prediction intervals, though we note thatincreased forecasting horizons may exacerbate deviations from the targetcoverage, particularly in the context of limited sample sizes. Additionally, weextend several easy-to-implement conformal prediction methods, originallydesigned for single-step forecasting, to accommodate multi-step scenarios.Through empirical evaluations, including simulations and applications to data,we demonstrate that AcMCP achieves coverage that closely aligns with the targetwithin local windows, while providing adaptive prediction intervals thateffectively respond to varying conditions.</description>
      <author>example@mail.com (Xiaoqian Wang, Rob J Hyndman)</author>
      <guid isPermaLink="false">2410.13115v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SLAM-AAC: Enhancing Audio Captioning with Paraphrasing Augmentation and CLAP-Refine through LLMs</title>
      <link>http://arxiv.org/abs/2410.09503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动音频字幕生成（AAC）旨在为输入音频信号生成自然的文本描述。近期音频预训练模型和大型语言模型的进展显著提升了音频理解和文本推理能力，促进了AAC的改进。&lt;h4&gt;目的&lt;/h4&gt;提出SLAM-AAC，通过重述增强和CLAP-Refine进一步增强AAC。&lt;h4&gt;方法&lt;/h4&gt;使用自监督的EAT模型提取细粒度音频表示，并通过轻量级线性层与文本嵌入对齐。使用LoRA适配器高效微调生成字幕的LLM。借鉴机器翻译中的回译方法，实现重述增强，以扩展Clotho数据集。&lt;h4&gt;主要发现&lt;/h4&gt;SLAM-AAC在Clotho V2和AudioCaps数据集上实现了最先进的性能，超越了之前的主流模型。&lt;h4&gt;结论&lt;/h4&gt;SLAM-AAC通过引入多种解码输出的CLAP-Refine策略，充分利用音频与文本之间的相似性，生成更符合输入音频的文本描述。&lt;h4&gt;总结&lt;/h4&gt;SLAM-AAC通过创新的方法和策略，显著提升了音频字幕生成的效果，展示了先进的音频理解能力和文本生成能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated Audio Captioning (AAC) aims to generate natural textualdescriptions for input audio signals. Recent progress in audio pre-trainedmodels and large language models (LLMs) has significantly enhanced audiounderstanding and textual reasoning capabilities, making improvements in AACpossible. In this paper, we propose SLAM-AAC to further enhance AAC withparaphrasing augmentation and CLAP-Refine through LLMs. Our approach uses theself-supervised EAT model to extract fine-grained audio representations, whichare then aligned with textual embeddings via lightweight linear layers. Thecaption generation LLM is efficiently fine-tuned using the LoRA adapter.Drawing inspiration from the back-translation method in machine translation, weimplement paraphrasing augmentation to expand the Clotho dataset duringpre-training. This strategy helps alleviate the limitation of scarce audio-textpairs and generates more diverse captions from a small set of audio clips.During inference, we introduce the plug-and-play CLAP-Refine strategy to fullyexploit multiple decoding outputs, akin to the n-best rescoring strategy inspeech recognition. Using the CLAP model for audio-text similarity calculation,we could select the textual descriptions generated by multiple searching beamsthat best match the input audio. Experimental results show that SLAM-AACachieves state-of-the-art performance on Clotho V2 and AudioCaps, surpassingprevious mainstream models.</description>
      <author>example@mail.com (Wenxi Chen, Ziyang Ma, Xiquan Li, Xuenan Xu, Yuzhe Liang, Zhisheng Zheng, Kai Yu, Xie Chen)</author>
      <guid isPermaLink="false">2410.09503v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>STGformer: Efficient Spatiotemporal Graph Transformer for Traffic Forecasting</title>
      <link>http://arxiv.org/abs/2410.00385v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交通预测是智慧城市管理的基石，有助于资源分配和交通规划。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的时空图变换器（STGformer）架构，以解决现有方法在大规模时空交互中的计算需求问题。&lt;h4&gt;方法&lt;/h4&gt;STGformer结合了图神经网络和变换器的优点，通过单层STG注意力块捕捉高阶时空交互，从而降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;STGformer在加利福尼亚的8600个传感器的路网图上进行批量推理时，实现了100倍的速度提升和99.8%的GPU内存使用减少。&lt;h4&gt;结论&lt;/h4&gt;STGformer在LargeST基准测试中优于现有的基于变换器的方法，如PDFormer和STAEformer，显示出其在克服计算和内存限制方面的潜力。&lt;h4&gt;总结&lt;/h4&gt;STGformer为未来的时空建模任务奠定了有前景的基础，有望彻底改变交通预测领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/dreamzz5/stgformer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic forecasting is a cornerstone of smart city management, enablingefficient resource allocation and transportation planning. Deep learning, withits ability to capture complex nonlinear patterns in spatiotemporal (ST) data,has emerged as a powerful tool for traffic forecasting. While graph neuralnetworks (GCNs) and transformer-based models have shown promise, theircomputational demands often hinder their application to real-world roadnetworks, particularly those with large-scale spatiotemporal interactions. Toaddress these challenges, we propose a novel spatiotemporal graph transformer(STGformer) architecture. STGformer effectively balances the strengths of GCNsand Transformers, enabling efficient modeling of both global and local trafficpatterns while maintaining a manageable computational footprint. Unliketraditional approaches that require multiple attention layers, STG attentionblock captures high-order spatiotemporal interactions in a single layer,significantly reducing computational cost. In particular, STGformer achieves a100x speedup and a 99.8\% reduction in GPU memory usage compared to STAEformerduring batch inference on a California road graph with 8,600 sensors. Weevaluate STGformer on the LargeST benchmark and demonstrate its superiorityover state-of-the-art Transformer-based methods such as PDFormer andSTAEformer, which underline STGformer's potential to revolutionize trafficforecasting by overcoming the computational and memory limitations of existingapproaches, making it a promising foundation for future spatiotemporal modelingtasks.</description>
      <author>example@mail.com (Hongjun Wang, Jiyuan Chen, Tong Pan, Zheng Dong, Lingyu Zhang, Renhe Jiang, Xuan Song)</author>
      <guid isPermaLink="false">2410.00385v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Surgical Depth Anything: Depth Estimation for Surgical Scenes using Foundation Models</title>
      <link>http://arxiv.org/abs/2410.07434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;单目深度估计在追踪和重建算法中至关重要，尤其是在外科视频中。然而，手术过程中直接获取真实深度图的困难使得监督学习方法不切实际。&lt;h4&gt;目的&lt;/h4&gt;提出一种针对外科领域的Depth Anything模型微调方法，以提供更准确的逐像素深度图。&lt;h4&gt;方法&lt;/h4&gt;基于当前最先进的深度估计模型Depth Anything，进行特定于外科领域的微调，旨在克服在手术场景中应用时出现的模糊、渗漏和反射等问题。&lt;h4&gt;主要发现&lt;/h4&gt;微调后的模型在外科场景中的表现显著提高，减少了与模糊和反射相关的错误，并实现了更可靠和精确的深度估计。&lt;h4&gt;结论&lt;/h4&gt;通过针对外科环境的微调，Depth Anything模型能够更好地满足手术领域的独特需求和挑战。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了如何通过微调提高深度估计模型在手术视频中的适用性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular depth estimation is crucial for tracking and reconstructionalgorithms, particularly in the context of surgical videos. However, theinherent challenges in directly obtaining ground truth depth maps duringsurgery render supervised learning approaches impractical. While manyself-supervised methods based on Structure from Motion (SfM) have shownpromising results, they rely heavily on high-quality camera motion and requireoptimization on a per-patient basis. These limitations can be mitigated byleveraging the current state-of-the-art foundational model for depthestimation, Depth Anything. However, when directly applied to surgical scenes,Depth Anything struggles with issues such as blurring, bleeding, andreflections, resulting in suboptimal performance. This paper presents afine-tuning of the Depth Anything model specifically for the surgical domain,aiming to deliver more accurate pixel-wise depth maps tailored to the uniquerequirements and challenges of surgical environments. Our fine-tuning approachsignificantly improves the model's performance in surgical scenes, reducingerrors related to blurring and reflections, and achieving a more reliable andprecise depth estimation.</description>
      <author>example@mail.com (Ange Lou, Yamin Li, Yike Zhang, Jack Noble)</author>
      <guid isPermaLink="false">2410.07434v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Head Effect in Live Streaming Platforms: A Two-Sided Market and Welfare Analysis</title>
      <link>http://arxiv.org/abs/2410.13090v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文探讨直播平台作为连接主播和观众的双边市场，关注“头部效应”，即少数顶尖主播因网络效应和平台政策吸引大部分观众。&lt;h4&gt;目的&lt;/h4&gt;分析直播平台中的流量集中现象及其对社会福利的影响。&lt;h4&gt;方法&lt;/h4&gt;使用静态和动态模型研究流量集中及赢家通吃的情形。&lt;h4&gt;主要发现&lt;/h4&gt;流量集中可能短期内提升消费者效用，但长期来看会降低内容多样性和整体社会福利。&lt;h4&gt;结论&lt;/h4&gt;建议政策干预以调整流量分配，促进观众在主播之间的更公平分配。&lt;h4&gt;政策建议&lt;/h4&gt;通过模拟结果展示，多种政策结合可以显著降低市场集中度，并提升社会福利。&lt;h4&gt;总结&lt;/h4&gt;论文强调了政策干预在促进直播平台公平性和社会福利方面的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper develops a theoretical framework to analyze live streamingplatforms as two-sided markets connecting streamers and viewers, focusing onthe "head effect" where a few top streamers attract most viewers due to strongnetwork effects and platform policies like commission rates and trafficallocation algorithms. Using static and dynamic models, it examines how thesefactors lead to traffic concentration and winner-takes-all scenarios. Thewelfare implications are assessed, revealing that while such concentration mayenhance consumer utility short-term, it can reduce content diversity andoverall social welfare in the long run. The paper proposes policy interventionsto adjust traffic allocation, promoting a more equitable distribution ofviewers across streamers, and demonstrates through simulations that combiningmultiple policies can significantly reduce market concentration and enhancesocial welfare</description>
      <author>example@mail.com (Yukun Zhang)</author>
      <guid isPermaLink="false">2410.13090v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Preference Aligned Diffusion Planner for Quadrupedal Locomotion Control</title>
      <link>http://arxiv.org/abs/2410.13586v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;扩散模型在捕捉复杂分布方面表现优越，适用于四足运动控制，但离线策略对分布外（OOD）状态敏感。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合离线学习和在线偏好对齐的两阶段学习框架，以改善四足运动控制。&lt;h4&gt;方法&lt;/h4&gt;离线阶段，扩散规划器从专家数据集中学习状态-动作序列的联合分布，无需使用奖励标签；在线阶段在仿真环境中进行互动，解决OOD问题并提高鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;提出了一种新型的弱偏好标记方法，无需真实奖励或人类偏好，展现了在缓慢和高速场景下的优越稳定性和速度跟踪准确性，能够实现零-shot迁移到Unitree Go1机器人。&lt;h4&gt;结论&lt;/h4&gt;该方法在各种步态（如慢跑、快跑、跳跃）中表现良好，展示了其在实际应用中的潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种有效的四足运动控制方案，利用扩散模型提升了运动的稳定性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Diffusion models demonstrate superior performance in capturing complexdistributions from large-scale datasets, providing a promising solution forquadrupedal locomotion control. However, offline policy is sensitive toOut-of-Distribution (OOD) states due to the limited state coverage in thedatasets. In this work, we propose a two-stage learning framework combiningoffline learning and online preference alignment for legged locomotion control.Through the offline stage, the diffusion planner learns the joint distributionof state-action sequences from expert datasets without using reward labels.Subsequently, we perform the online interaction in the simulation environmentbased on the trained offline planer, which significantly addresses the OODissues and improves the robustness. Specifically, we propose a novel weakpreference labeling method without the ground-truth reward or humanpreferences. The proposed method exhibits superior stability and velocitytracking accuracy in pacing, trotting, and bounding gait under both slow- andhigh-speed scenarios and can perform zero-shot transfer to the real Unitree Go1robots. The project website for this paper is athttps://shangjaven.github.io/preference-aligned-diffusion-legged/.</description>
      <author>example@mail.com (Xinyi Yuan, Zhiwei Shang, Zifan Wang, Chenkai Wang, Zhao Shan, Zhenchao Qi, Meixin Zhu, Chenjia Bai, Xuelong Li)</author>
      <guid isPermaLink="false">2410.13586v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>FDF: Flexible Decoupled Framework for Time Series Forecasting with Conditional Denoising and Polynomial Modeling</title>
      <link>http://arxiv.org/abs/2410.13253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列预测在众多网络应用中至关重要，影响着各行业的决策。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的灵活解耦框架（FDF），以提高时间序列预测性能。&lt;h4&gt;方法&lt;/h4&gt;将时间序列分解为趋势和季节性成分，分别建模以实现解耦分析。引入条件去噪季节模块（CDSM）和多项式趋势模块（PTM）来捕捉复杂的季节性和光滑的趋势成分。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提框架在性能上优于现有方法，具有较高的灵活性。&lt;h4&gt;结论&lt;/h4&gt;希望本研究为时间序列预测提供新的视角，并计划将代码公开作为开源项目。&lt;h4&gt;总结&lt;/h4&gt;本文提出的FDF框架通过解耦时间序列的趋势和季节性成分，提高了预测的准确性和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting is vital in numerous web applications, influencingcritical decision-making across industries. While diffusion models haverecently gained increasing popularity for this task, we argue they suffer froma significant drawback: indiscriminate noise addition to the original timeseries followed by denoising, which can obscure underlying dynamic evolvingtrend and complicate forecasting. To address this limitation, we propose anovel flexible decoupled framework (FDF) that learns high-quality time seriesrepresentations for enhanced forecasting performance. A key characteristic ofour approach leverages the inherent inductive bias of time series data bydecomposing it into trend and seasonal components, each modeled separately toenable decoupled analysis and modeling. Specifically, we propose an innovativeConditional Denoising Seasonal Module (CDSM) within the diffusion model, whichleverages statistical information from the historical window to conditionallymodel the complex seasonal component. Notably, we incorporate a PolynomialTrend Module (PTM) to effectively capture the smooth trend component, therebyenhancing the model's ability to represent temporal dependencies. Extensiveexperiments validate the effectiveness of our framework, demonstrating superiorperformance over existing methods and higlighting its flexibility in timeseries forecasting. We hope our work can bring a new perspective for timeseries forecasting. We intend to make our code publicly available asopen-source in the future.</description>
      <author>example@mail.com (Jintao Zhang, Mingyue Cheng, Xiaoyu Tao, Zhiding Liu, Daoyu Wang)</author>
      <guid isPermaLink="false">2410.13253v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>The Influence of Generative AI on Content Platforms: Supply, Demand, and Welfare Impacts in Two-Sided Markets</title>
      <link>http://arxiv.org/abs/2410.13101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;探讨生成性人工智能如何影响人类创作者和AI共同生成内容的在线平台。&lt;h4&gt;目的&lt;/h4&gt;开发模型理解生成性AI如何改变供需关系、影响流量分配和社会福利。&lt;h4&gt;方法&lt;/h4&gt;通过分析和模拟实验评估政策建议，以减少负面影响并改善社会福利。&lt;h4&gt;主要发现&lt;/h4&gt;{'内容供应': 'AI低成本导致内容供应大幅增加，可能造成过剩。', '内容多样性': 'AI提升内容多样性，但可能引发信息过载，降低用户满意度。', '流量集中': "AI增加顶级创作者的流量集中，形成'赢家通吃'效应，同时扩大小众内容的机会，形成'长尾'效应。"}&lt;h4&gt;结论&lt;/h4&gt;总体影响取决于AI生成内容的质量和信息过载的程度，需谨慎管理AI在在线内容平台中的角色。&lt;h4&gt;总结&lt;/h4&gt;研究强调了维持在线内容平台健康平衡的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores how generative artificial intelligence (AI) affectsonline platforms where both human creators and AI generate content. We developa model to understand how generative AI changes supply and demand, impactstraffic distribution, and influences social welfare. Our analysis shows that AIcan lead to a huge increase in content supply due to its low cost, which couldcause oversupply. While AI boosts content variety, it can also createinformation overload, lowering user satisfaction and disrupting the market. AIalso increases traffic concentration among top creators (the "winner-takes-all"effect) while expanding opportunities for niche content (the "long-tail"effect). We assess how these changes affect consumer and producer benefits,finding that the overall impact depends on the quality of AI-generated contentand the level of information overload. Through simulation experiments, we testpolicy ideas, such as adjusting platform fees and recommendations, to reducenegative effects and improve social welfare. The results highlight the need forcareful management of AI's role in online content platforms to maintain ahealthy balance</description>
      <author>example@mail.com (Yukun Zhang)</author>
      <guid isPermaLink="false">2410.13101v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Semantic Environment Atlas for Object-Goal Navigation</title>
      <link>http://arxiv.org/abs/2410.09081v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了一种新颖的映射方法，旨在增强具身智能体的视觉导航能力。&lt;h4&gt;目的&lt;/h4&gt;提出语义环境地图（SEA），丰富导航上下文。&lt;h4&gt;方法&lt;/h4&gt;使用语义图地图，细致描绘地点与物体之间的关系，利用图像观测构建地图，并将视觉地标作为稀疏编码节点。&lt;h4&gt;主要发现&lt;/h4&gt;SEA整合了来自不同环境的多个语义地图，保留了地点-物体关系的记忆，显著提升了视觉定位和导航任务的表现。&lt;h4&gt;结论&lt;/h4&gt;基于SEA的定位框架在视觉定位和目标导航任务中表现优异，成功率达到39.0%，较现有方法提高了12.4%，并在嘈杂的测距和驱动条件下保持鲁棒性，同时计算成本低。&lt;h4&gt;总结&lt;/h4&gt;SEA方法有效提升了具身智能体的导航能力，展示了其在复杂环境中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-05&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.knosys.2024.112446&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce the Semantic Environment Atlas (SEA), a novelmapping approach designed to enhance visual navigation capabilities of embodiedagents. The SEA utilizes semantic graph maps that intricately delineate therelationships between places and objects, thereby enriching the navigationalcontext. These maps are constructed from image observations and capture visuallandmarks as sparsely encoded nodes within the environment. The SEA integratesmultiple semantic maps from various environments, retaining a memory ofplace-object relationships, which proves invaluable for tasks such as visuallocalization and navigation. We developed navigation frameworks thateffectively leverage the SEA, and we evaluated these frameworks through visuallocalization and object-goal navigation tasks. Our SEA-based localizationframework significantly outperforms existing methods, accurately identifyinglocations from single query images. Experimental results in Habitat scenariosshow that our method not only achieves a success rate of 39.0%, an improvementof 12.4% over the current state-of-the-art, but also maintains robustness undernoisy odometry and actuation conditions, all while keeping computational costslow.</description>
      <author>example@mail.com (Nuri Kim, Jeongho Park, Mineui Hong, Songhwai Oh)</author>
      <guid isPermaLink="false">2410.09081v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Novel Bayesian algorithms for ARFIMA long-memory processes: a comparison between MCMC and ABC approaches</title>
      <link>http://arxiv.org/abs/2410.13261v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;ARFIMA模型广泛用于捕捉时间序列数据中的长记忆特性。&lt;h4&gt;目的&lt;/h4&gt;比较两种贝叶斯方法（MCMC和ABC）在估计ARFIMA模型参数方面的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型MCMC算法，过滤时间序列为长记忆和ARMA成分，并提出了一种新的ABC方法，使用三种不同的总结统计量进行后验估计。&lt;h4&gt;主要发现&lt;/h4&gt;新提出的MCMC在各项指标上表现优越，贝叶斯方法有效估计了长记忆和短记忆参数。&lt;h4&gt;结论&lt;/h4&gt;该研究增强了我们对ARFIMA建模中贝叶斯技术的理解，提供了其在复杂时间序列数据中应用的优缺点的见解。&lt;h4&gt;总结&lt;/h4&gt;通过广泛的模拟研究和对实际金融数据的应用，验证了所提方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a comparative study of two Bayesian approaches - MarkovChain Monte Carlo (MCMC) and Approximate Bayesian Computation (ABC) - forestimating the parameters of autoregressive fractionally-integrated movingaverage (ARFIMA) models, which are widely used to capture long-memory in timeseries data. We propose a novel MCMC algorithm that filters the time seriesinto distinct long-memory and ARMA components, and benchmarked it againststandard approaches. Additionally, a new ABC method is proposed, using threedifferent summary statistics used for posterior estimation. The methods areimplemented and evaluated through an extensive simulation study, as well asapplied to a real-world financial dataset, specifically the quarterly U.S.Gross National Product (GNP) series. The results demonstrate the effectivenessof the Bayesian methods in estimating long-memory and short-memory parameters,with the filtered MCMC showing superior performance in various metrics. Thisstudy enhances our understanding of Bayesian techniques in ARFIMA modeling,providing insights into their advantages and limitations when applied tocomplex time series data.</description>
      <author>example@mail.com (James Cohen Gabor, Clara Grazian)</author>
      <guid isPermaLink="false">2410.13261v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>MLP-SLAM: Multilayer Perceptron-Based Simultaneous Localization and Mapping With a Dynamic and Static Object Discriminator</title>
      <link>http://arxiv.org/abs/2410.10669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Dynamic SLAM&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;V-SLAM系统在动态物体较少的环境中表现出高精度，但在动态物体较多的环境中性能显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于多层感知器（MLP）的实时立体SLAM系统，以解决动态物体干扰的问题。&lt;h4&gt;方法&lt;/h4&gt;利用完整的几何信息，避免信息丢失，并创建了一个包含50,000多个特征点的公开数据集。&lt;h4&gt;主要发现&lt;/h4&gt;MLP基于的动态和静态特征点分类器在性能上优于其他方法，且在KITTI跟踪数据集上表现出最高的平均精度和最快的速度。&lt;h4&gt;结论&lt;/h4&gt;该MLP基于的实时立体SLAM系统在动态SLAM系统中表现突出，代码和数据集已公开在GitHub上。&lt;h4&gt;总结&lt;/h4&gt;本文提出的系统有效克服了动态环境下的SLAM挑战，并提供了可供评估的新数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Visual Simultaneous Localization and Mapping (V-SLAM) system has seensignificant development in recent years, demonstrating high precision inenvironments with limited dynamic objects. However, their performancesignificantly deteriorates when deployed in settings with a higher presence ofmovable objects, such as environments with pedestrians, cars, and buses, whichare common in outdoor scenes. To address this issue, we propose a MultilayerPerceptron (MLP)-based real-time stereo SLAM system that leverages completegeometry information to avoid information loss. Moreover, there is currently nopublicly available dataset for directly evaluating the effectiveness of dynamicand static feature classification methods, and to bridge this gap, we havecreated a publicly available dataset containing over 50,000 feature points.Experimental results demonstrate that our MLP-based dynamic and static featurepoint discriminator has achieved superior performance compared to other methodson this dataset. Furthermore, the MLP-based real-time stereo SLAM system hasshown the highest average precision and fastest speed on the outdoor KITTItracking datasets compared to other dynamic SLAM systems.The open-source codeand datasets are available at https://github.com/TaozheLi/MLP-SLAM.</description>
      <author>example@mail.com (Taozhe Li, Wei Sun)</author>
      <guid isPermaLink="false">2410.10669v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Jailbreaking LLM-Controlled Robots</title>
      <link>http://arxiv.org/abs/2410.13691v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）的引入改变了机器人技术，提升了上下文推理和人机交互能力。&lt;h4&gt;目的&lt;/h4&gt;评估在机器人领域部署LLMs的风险，特别是它们在面临恶意攻击时的脆弱性。&lt;h4&gt;方法&lt;/h4&gt;提出RoboPAIR算法，专门设计用于攻击LLM控制的机器人，进行白盒、灰盒和黑盒三种场景的实验。&lt;h4&gt;主要发现&lt;/h4&gt;RoboPAIR能够快速有效地找到攻击漏洞，在三个新数据集中显示出100%的攻击成功率，且成功在商业机器人系统中实施了攻击。&lt;h4&gt;结论&lt;/h4&gt;被攻击的LLMs风险不仅限于文本生成，可能导致真实世界中的物理损害，因此需要解决这一新出现的脆弱性。&lt;h4&gt;总结&lt;/h4&gt;确保LLMs在机器人中的安全部署至关重要，RoboPAIR的研究揭示了潜在的重大安全隐患。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent introduction of large language models (LLMs) has revolutionizedthe field of robotics by enabling contextual reasoning and intuitivehuman-robot interaction in domains as varied as manipulation, locomotion, andself-driving vehicles. When viewed as a stand-alone technology, LLMs are knownto be vulnerable to jailbreaking attacks, wherein malicious prompters elicitharmful text by bypassing LLM safety guardrails. To assess the risks ofdeploying LLMs in robotics, in this paper, we introduce RoboPAIR, the firstalgorithm designed to jailbreak LLM-controlled robots. Unlike existing, textualattacks on LLM chatbots, RoboPAIR elicits harmful physical actions fromLLM-controlled robots, a phenomenon we experimentally demonstrate in threescenarios: (i) a white-box setting, wherein the attacker has full access to theNVIDIA Dolphins self-driving LLM, (ii) a gray-box setting, wherein the attackerhas partial access to a Clearpath Robotics Jackal UGV robot equipped with aGPT-4o planner, and (iii) a black-box setting, wherein the attacker has onlyquery access to the GPT-3.5-integrated Unitree Robotics Go2 robot dog. In eachscenario and across three new datasets of harmful robotic actions, wedemonstrate that RoboPAIR, as well as several static baselines, findsjailbreaks quickly and effectively, often achieving 100% attack success rates.Our results reveal, for the first time, that the risks of jailbroken LLMsextend far beyond text generation, given the distinct possibility thatjailbroken robots could cause physical damage in the real world. Indeed, ourresults on the Unitree Go2 represent the first successful jailbreak of adeployed commercial robotic system. Addressing this emerging vulnerability iscritical for ensuring the safe deployment of LLMs in robotics. Additional mediais available at: https://robopair.org</description>
      <author>example@mail.com (Alexander Robey, Zachary Ravichandran, Vijay Kumar, Hamed Hassani, George J. Pappas)</author>
      <guid isPermaLink="false">2410.13691v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Cyber Attacks Prevention Towards Prosumer-based EV Charging Stations: An Edge-assisted Federated Prototype Knowledge Distillation Approach</title>
      <link>http://arxiv.org/abs/2410.13260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究针对基于用户的电动车充电站（EVCSs）进行网络攻击预防，涵盖网络流量数据的检测和干预。&lt;h4&gt;目的&lt;/h4&gt;建立有效的网络攻击预防机制。&lt;h4&gt;方法&lt;/h4&gt;提出了一种边缘辅助的联邦原型知识蒸馏（E-FPKD）方法，利用局部边缘服务器进行联邦学习，并采用Pearson相关系数进行特征选择。&lt;h4&gt;主要发现&lt;/h4&gt;E-FPKD方法在NSL-KDD、UNSW-NB15和IoTID20数据集上实现了最大的整体检测正确率（ODC），在多类分类中相较于基线方法表现更优。&lt;h4&gt;结论&lt;/h4&gt;E-FPKD方法在检测与干预网络攻击方面表现良好，能够有效处理非独立同分布数据的挑战。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种创新的方法来提升电动车充电站的网络安全性，显示了在复杂环境下的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, cyber-attack prevention for the prosumer-based electricvehicle (EV) charging stations (EVCSs) is investigated, which covers twoaspects: 1) cyber-attack detection on prosumers' network traffic (NT) data, and2) cyber-attack intervention. To establish an effective prevention mechanism,several challenges need to be tackled, for instance, the NT data per prosumermay be non-independent and identically distributed (non-IID), and the boundarybetween benign and malicious traffic becomes blurred. To this end, we proposean edge-assisted federated prototype knowledge distillation (E-FPKD) approach,where each client is deployed on a dedicated local edge server (DLES) and canreport its availability for joining the federated learning (FL) process. Priorto the E-FPKD approach, to enhance accuracy, the Pearson CorrelationCoefficient is adopted for feature selection. Regarding the proposed E-FPKDapproach, we integrate the knowledge distillation and prototype aggregationtechnique into FL to deal with the non-IID challenge. To address the boundaryissue, instead of directly calculating the distance between benign andmalicious traffic, we consider maximizing the overall detection correctness ofall prosumers (ODC), which can mitigate the computational cost compared withthe former way. After detection, a rule-based method will be triggered at eachDLES for cyber-attack intervention. Experimental analysis demonstrates that theproposed E-FPKD can achieve the largest ODC on NSL-KDD, UNSW-NB15, and IoTID20datasets in both binary and multi-class classification, compared withbaselines. For instance, the ODC for IoTID20 obtained via the proposed methodis separately 0.3782% and 4.4471% greater than FedProto and FedAU inmulti-class classification.</description>
      <author>example@mail.com (Luyao Zou, Quang Hieu Vo, Kitae Kim, Huy Q. Le, Chu Myaet Thwal, Chaoning Zhang, Choong Seon Hong)</author>
      <guid isPermaLink="false">2410.13260v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbone</title>
      <link>http://arxiv.org/abs/2410.13338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;概率时间序列填补在实际场景中得到广泛应用，能够估计填补结果的不确定性。&lt;h4&gt;目的&lt;/h4&gt;探讨去噪扩散概率模型（DDPMs）在概率时间序列填补任务中的应用及挑战。&lt;h4&gt;方法&lt;/h4&gt;将计算高效的状态空间模型Mamba集成至DDPMs作为去噪模块，并设计多个基于状态空间模型的块以实现双向建模和变量间关系理解。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在多个数据集和不同缺失场景及缺失比例下实现了最先进的时间序列填补结果。&lt;h4&gt;结论&lt;/h4&gt;通过改进的去噪模块和双向建模方法，有效提升了时间序列填补的性能。&lt;h4&gt;总结&lt;/h4&gt;本文提出的DDPMs改进方法在处理时间序列填补问题中具有显著优势，成功应对了现有方法面临的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Probabilistic time series imputation has been widely applied in real-worldscenarios due to its ability to estimate uncertainty of imputation results.Meanwhile, denoising diffusion probabilistic models (DDPMs) have achieved greatsuccess in probabilistic time series imputation tasks with its power to modelcomplex distributions. However, current DDPM-based probabilistic time seriesimputation methodologies are confronted with two types of challenges:1)~\textit{~The backbone modules of the denoising parts are not capable ofachieving sequence modeling with low time complexity.} 2)~\textit{Thearchitecture of denoising modules can not handle the inter-variable andbidirectional dependencies in the time series imputation problem effectively.}To address the first challenge, we integrate the computational efficient statespace model, namely Mamba, as the backbone denosing module for DDPMs. To tacklethe second challenge, we carefully devise several SSM-based blocks forbidirectional modeling and inter-variable relation understanding. Experimentalresults demonstrate that our approach can achieve state-of-the-art time seriesimputation results on multiple datasets, different missing scenarios andmissing ratios.</description>
      <author>example@mail.com (Hongfan Gao, Wangmeng Shen, Xiangfei Qiu, Ronghui Xu, Jilin Hu, Bin Yang)</author>
      <guid isPermaLink="false">2410.13338v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Interacting humans and robots can improve sensory prediction by adapting their viscoelasticity</title>
      <link>http://arxiv.org/abs/2410.13755v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类和机器人在互动中交换能量和触觉信息，但触觉信息的交换尚未被充分理解。&lt;h4&gt;目的&lt;/h4&gt;开发一个计算模型，以研究代理之间的机械和感知互动，调节其粘弹性以优化触觉信息交换。&lt;h4&gt;方法&lt;/h4&gt;构建了一个随机最优信息与努力（SOIE）控制器，考虑感知和运动噪声，进行机器人间的追踪任务实验。&lt;h4&gt;主要发现&lt;/h4&gt;SOIE控制器在机器人-机器人实验中表现出优越的性能，相较于刚性或柔性控制，能够改善触觉信息的交换和性能。&lt;h4&gt;结论&lt;/h4&gt;该控制器预测人类如何调整肌肉激活以增强触觉交流，且在与机器人互动时，通过调整粘弹性来应对噪声特征，提高了追踪性能和触觉通信效果。&lt;h4&gt;总结&lt;/h4&gt;SOIE控制器有望提升人类与机器人之间的触觉交流和协作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To manipulate objects or dance together, humans and robots exchange energyand haptic information. While the exchange of energy in human-robot interactionhas been extensively investigated, the underlying exchange of hapticinformation is not well understood. Here, we develop a computational model ofthe mechanical and sensory interactions between agents that can tune theirviscoelasticity while considering their sensory and motor noise. The resultingstochastic-optimal-information-and-effort (SOIE) controller predicts how theexchange of haptic information and the performance can be improved by adjustingviscoelasticity. This controller was first implemented on a robot-robotexperiment with a tracking task which showed its superior performance whencompared to either stiff or compliant control. Importantly, the optimalcontroller also predicts how connected humans alter their muscle activation toimprove haptic communication, with differentiated viscoelasticity adjustment totheir own sensing noise and haptic perturbations. A human-robot experiment thenillustrated the applicability of this optimal control strategy for robots,yielding improved tracking performance and effective haptic communication asthe robot adjusted its viscoelasticity according to its own and the user'snoise characteristics. The proposed SOIE controller may thus be used to improvehaptic communication and collaboration of humans and robots.</description>
      <author>example@mail.com (Xiaoxiao Cheng, Jonathan Eden, Bastien Berret, Atsushi Takagi, Etienne Burdet)</author>
      <guid isPermaLink="false">2410.13755v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Inadequate contrast ratio of road markings as an indicator for ADAS failure</title>
      <link>http://arxiv.org/abs/2410.13320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IRF World Congress 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;道路标线是重要的交通安全特征，对人类驾驶员和机器视觉技术（如高级驾驶辅助系统ADAS）都至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究不同可见条件下ADAS对道路标线的依赖性及其对轨迹规划的影响。&lt;h4&gt;方法&lt;/h4&gt;在多种可见条件（白天、夜晚、下雨、眩光）下测试开源摄像头ADAS，并分析道路标线的对比度。&lt;h4&gt;主要发现&lt;/h4&gt;在可见度差的情况下，类型II的道路标线（结构化标线）相比类型I（平面标线）提供了更好的ADAS可靠性。夜间在无干扰因素下，类型II标线的对比度显著高于类型I；白天时类型I的对比度略高，但在潮湿条件下类型II的对比度明显优于类型I。&lt;h4&gt;结论&lt;/h4&gt;道路标线的可见性对ADAS的车道识别能力至关重要，低对比度会导致ADAS识别不充分。目前未能找到具体的最低对比度值，因ADAS算法复杂性所致。&lt;h4&gt;总结&lt;/h4&gt;研究结果强调了提高道路标线可见性的重要性，以提升ADAS在各种天气条件下的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Road markings were reported as critical road safety features, equally neededfor both human drivers and for machine vision technologies utilised by advanceddriver assistance systems (ADAS) and in driving automation. Visibility of roadmarkings is achieved because of their colour contrasting with the roadwaysurface. During recent testing of an open-source camera-based ADAS underseveral visibility conditions (day, night, rain, glare), significant failuresin trajectory planning were recorded and quantified. Consistently, better ADASreliability under poor visibility conditions was achieved with Type II roadmarkings (i.e. structured markings, facilitating moisture drainage) as comparedto Type I road marking (i.e. flat lines). To further understand these failures,analysis of contrast ratio of road markings, which the tested ADAS wasdetecting for traffic lane recognition, was performed. The highest contrastratio (greater than 0.5, calculated per Michelson equation) was measured atnight in the absence of confounding factors, with statistically significantdifference of 0.1 in favour of Type II road markings over Type I. Underdaylight conditions, contrast ratio was reduced, with slightly higher valuesmeasured with Type I. The presence of rain or wet roads caused thedeterioration of the contrast ratio, with Type II road markings exhibitingsignificantly higher contrast ratio than Type I, even though the values werelow (less than 0.1). These findings matched the output of the ADAS related totraffic lane detection and underlined the importance of road markingvisibility. Inadequate lane recognition by ADAS was associated with very lowcontrast ratio of road markings indeed. Importantly, specific minimum contrastratio value could not be found, which was due to the complexity of ADASalgorithms...</description>
      <author>example@mail.com (Novel Certad, Cristina Olaverri-Monreal, Friedrich Wiesinger, Tomasz E. Burghardt)</author>
      <guid isPermaLink="false">2410.13320v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Statistical testing on generative AI anomaly detection tools in Alzheimer's Disease diagnosis</title>
      <link>http://arxiv.org/abs/2410.13363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;阿尔茨海默病由于机制理解有限和患者异质性大，诊断具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一种可靠的生成性人工智能方法，用于阿尔茨海默病的预测。&lt;h4&gt;方法&lt;/h4&gt;采用选择性推断解决假设检验中的双重抽样问题，比较传统统计方法与选择性推断的效果。&lt;h4&gt;主要发现&lt;/h4&gt;选择性推断能够在控制假阳性率的同时保留统计检验的功效，且p值的膨胀问题得到改善。&lt;h4&gt;结论&lt;/h4&gt;该方法可帮助临床医生在阿尔茨海默病的诊断和早期干预中提供支持。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了生成性人工智能在医疗影像异常检测中的潜力，并提出了有效的统计方法以提高诊断的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Alzheimer's Disease is challenging to diagnose due to our limitedunderstanding of its mechanism and large heterogeneity among patients.Neurodegeneration is studied widely as a biomarker for clinical diagnosis,which can be measured from time series MRI progression. On the other hand,generative AI has shown promise in anomaly detection in medical imaging andused for tasks including tumor detection. However, testing the reliability ofsuch data-driven methods is non-trivial due to the issue of double-dipping inhypothesis testing. In this work, we propose to solve this issue with selectiveinference and develop a reliable generative AI method for Alzheimer'sprediction. We show that compared to traditional statistical methods withhighly inflated p-values, selective inference successfully controls the falsediscovery rate under the desired alpha level while retaining statistical power.In practice, our pipeline could assist clinicians in Alzheimer's diagnosis andearly intervention.</description>
      <author>example@mail.com (Rosemary He, Ichiro Takeuchi)</author>
      <guid isPermaLink="false">2410.13363v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>GSORB-SLAM: Gaussian Splatting SLAM benefits from ORB features and Transmittance information</title>
      <link>http://arxiv.org/abs/2410.11356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D高斯喷溅技术（3DGS）的出现引发了密集视觉SLAM研究的新热潮，但现有方法存在对伪影和噪声敏感、训练视点选择不佳以及缺乏全局光照优化等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一个将3DGS与ORB特征紧密结合的密集SLAM系统。&lt;h4&gt;方法&lt;/h4&gt;设计了一种联合优化方法，以实现稳健跟踪并有效减少噪声和伪影的影响，结合从累积透射率中得出的新几何观测和从像素数据中提取的ORB特征。同时，提出了一种自适应高斯扩展和正则化方法，使高斯原语能够紧凑地表示场景，并采用基于混合图的视点选择策略以减轻过拟合效应和提高收敛质量。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了紧凑且高质量的场景表示和准确定位，GSORB-SLAM在不同数据集上的评估显示出卓越的性能。&lt;h4&gt;结论&lt;/h4&gt;所提出的系统在密集SLAM任务中表现出色，代码将会公开提供。&lt;h4&gt;总结&lt;/h4&gt;本研究有效解决了传统SLAM方法中的多个挑战，提供了一种新的解决方案，推动了SLAM技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of 3D Gaussian Splatting (3DGS) has recently sparked a renewedwave of dense visual SLAM research. However, current methods face challengessuch as sensitivity to artifacts and noise, sub-optimal selection of trainingviewpoints, and a lack of light global optimization. In this paper, we proposea dense SLAM system that tightly couples 3DGS with ORB features. We design ajoint optimization approach for robust tracking and effectively reducing theimpact of noise and artifacts. This involves combining novel geometricobservations, derived from accumulated transmittance, with ORB featuresextracted from pixel data. Furthermore, to improve mapping quality, we proposean adaptive Gaussian expansion and regularization method that enables Gaussianprimitives to represent the scene compactly. This is coupled with a viewpointselection strategy based on the hybrid graph to mitigate over-fitting effectsand enhance convergence quality. Finally, our approach achieves compact andhigh-quality scene representations and accurate localization. GSORB-SLAM hasbeen evaluated on different datasets, demonstrating outstanding performance.The code will be available.</description>
      <author>example@mail.com (Wancai Zheng, Xinyi Yu, Jintao Rong, Linlin Ou, Yan Wei, Libo Zhou)</author>
      <guid isPermaLink="false">2410.11356v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SplatPose+: Real-time Image-Based Pose-Agnostic 3D Anomaly Detection</title>
      <link>http://arxiv.org/abs/2410.12080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于图像的姿态无关3D异常检测在工业质量控制中越来越重要，旨在从测试对象的查询图像中发现异常。&lt;h4&gt;目的&lt;/h4&gt;寻找在查询视图不可知的情况下，如何识别与参考图像（无异常对象）之间的差异。&lt;h4&gt;方法&lt;/h4&gt;提出SplatPose+方法，结合结构从运动(SfM)模型用于定位和3D高斯点云(3DGS)模型用于新视图合成。&lt;h4&gt;主要发现&lt;/h4&gt;SplatPose+实现了实时推断速度和比SplatPose更快的训练，同时在Pose-agnostic异常检测基准上达到了新的SOTA。&lt;h4&gt;结论&lt;/h4&gt;尽管需要额外计算SfM模型，SplatPose+在工业生产中的应用具有显著优势。&lt;h4&gt;总结&lt;/h4&gt;SplatPose+有效解决了实时异常检测的问题，并在多个姿态的异常检测数据集上表现优异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-based Pose-Agnostic 3D Anomaly Detection is an important task that hasemerged in industrial quality control. This task seeks to find anomalies fromquery images of a tested object given a set of reference images of ananomaly-free object. The challenge is that the query views (a.k.a poses) areunknown and can be different from the reference views. Currently, new methodssuch as OmniposeAD and SplatPose have emerged to bridge the gap by synthesizingpseudo reference images at the query views for pixel-to-pixel comparison.However, none of these methods can infer in real-time, which is critical inindustrial quality control for massive production. For this reason, we proposeSplatPose+, which employs a hybrid representation consisting of a Structurefrom Motion (SfM) model for localization and a 3D Gaussian Splatting (3DGS)model for Novel View Synthesis. Although our proposed pipeline requires thecomputation of an additional SfM model, it offers real-time inference speedsand faster training compared to SplatPose. Quality-wise, we achieved a new SOTAon the Pose-agnostic Anomaly Detection benchmark with the Multi-Pose AnomalyDetection (MAD-SIM) dataset.</description>
      <author>example@mail.com (Yizhe Liu, Yan Song Hu, Yuhao Chen, John Zelek)</author>
      <guid isPermaLink="false">2410.12080v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>lightcurver: A Python Pipeline for Precise Photometry of Multiple-Epoch Wide-Field Images</title>
      <link>http://arxiv.org/abs/2410.13625v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;lightcurver是一个用于时间序列天文成像数据的光度处理管道，旨在半自动提取小型混合目标的精确光曲线。&lt;h4&gt;目的&lt;/h4&gt;支持对被混合目标（如透镜类类星体、超新星或拥挤场中的变星）的光度分析。&lt;h4&gt;方法&lt;/h4&gt;利用STARRED生成每幅图像的先进经验点扩散函数（PSF）模型，并通过结合视场内多个恒星的PSF光度流量来确定各个时刻之间的相对零点。&lt;h4&gt;主要发现&lt;/h4&gt;该方法生成了点源的光曲线和感兴趣区域的高分辨率图像模型，累计了所有时刻的信号。&lt;h4&gt;结论&lt;/h4&gt;lightcurver旨在保持可维护性、快速性和增量处理，能够支持即将到来的鲁宾天文台的空间和时间遗产调查中大量混合目标的日常光度分析。&lt;h4&gt;总结&lt;/h4&gt;该管道为天文光度分析提供了高效且精确的工具，适应未来大规模观测项目的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.21105/joss.06775&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; lightcurver is a photometric pipeline for time series astronomical imagingdata, designed for the semi-automatic extraction of precise light curves fromsmall, blended targets. Such targets include, but are not limited to, lensedquasars, supernovae, or Cepheids in crowded fields. lightcurver leveragesSTARRED (Michalewicz et al., 2023; Millon et al., 2024) to generatestate-of-the-art empirical point spread function (PSF) models for each image.It then determines the relative zeropoints between epochs by combining thePSF-photometry fluxes of several stars in the field of view. Subsequently,STARRED is used again to simultaneously model the calibrated pixels of theregion of interest across all epochs. This process yields light curves of thepoint sources and a high-resolution image model of the region of interest,cumulating the signal from all epochs. lightcurver aims to be maintainable,fast, and incremental in its processing approach. As such, it can enable thedaily photometric analysis of a large number of blended targets in the contextof the upcoming Rubin Observatory Legacy Survey of Space and Time.</description>
      <author>example@mail.com (Frédéric Dux)</author>
      <guid isPermaLink="false">2410.13625v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>V3D-SLAM: Robust RGB-D SLAM in Dynamic Environments with 3D Semantic Geometry Voting</title>
      <link>http://arxiv.org/abs/2410.12068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在高度动态环境中进行同时定位与地图构建（SLAM）面临挑战，因移动物体与相机姿态之间的相关复杂性。&lt;h4&gt;目的&lt;/h4&gt;为了提高SLAM性能，需要最小化移动物体的干扰事件，并理解物体的3D形状和动态特性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为V3D-SLAM的鲁棒方法，通过两个轻量级的再评估阶段去除移动物体，包括使用空间推理的霍夫投票机制识别潜在的移动和静态物体，以及通过使用Chamfer距离作为相似性度量检测由物体内部运动引起的动态噪声来细化静态物体。&lt;h4&gt;主要发现&lt;/h4&gt;在动态序列和真实相机轨迹的TUM RGB-D基准实验中，V3D-SLAM方法的表现优于最新的先进SLAM方法。&lt;h4&gt;结论&lt;/h4&gt;V3D-SLAM通过对动态环境的有效处理，提升了SLAM的性能，源代码可在GitHub上获取。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，解决了动态环境中SLAM的挑战，具有较好的实用性和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous localization and mapping (SLAM) in highly dynamic environmentsis challenging due to the correlation complexity between moving objects and thecamera pose. Many methods have been proposed to deal with this problem;however, the moving properties of dynamic objects with a moving camera remainunclear. Therefore, to improve SLAM's performance, minimizing disruptive eventsof moving objects with a physical understanding of 3D shapes and dynamics ofobjects is needed. In this paper, we propose a robust method, V3D-SLAM, toremove moving objects via two lightweight re-evaluation stages, includingidentifying potentially moving and static objects using a spatial-reasonedHough voting mechanism and refining static objects by detecting dynamic noisecaused by intra-object motions using Chamfer distances as similaritymeasurements. Our experiment on the TUM RGB-D benchmark on dynamic sequenceswith ground-truth camera trajectories showed that our methods outperform themost recent state-of-the-art SLAM methods. Our source code is available athttps://github.com/tuantdang/v3d-slam.</description>
      <author>example@mail.com (Tuan Dang, Khang Nguyen, Mandfred Huber)</author>
      <guid isPermaLink="false">2410.12068v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Speech and More: Investigating the Emergent Ability of Speech Foundation Models for Classifying Physiological Time-Series Signals</title>
      <link>http://arxiv.org/abs/2410.12645v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管仅在语音数据上训练，语音基础模型（SFM）如Whisper在非语音任务（如音频分类）上表现出色，部分原因是语音与音频共享一些共同特征。&lt;h4&gt;目的&lt;/h4&gt;评估SFM在更具挑战性的超域（OOD）任务中的表现，即对生理时间序列信号的分类。&lt;h4&gt;方法&lt;/h4&gt;测试两个关键假设：一是SFM能够通过捕捉共享的时间模式来推广到生理信号；二是多语言SFM由于在预训练期间接触到更大的变异性，将优于其他模型。&lt;h4&gt;主要发现&lt;/h4&gt;在使用心电图（ECG）、肌电图（EMG）和皮肤电反应（EDA）信号进行压力识别的实验中，基于SFM派生表示的模型优于基于原始生理信号的模型。多语言SFM的准确率最高，支持了我们的假设。&lt;h4&gt;结论&lt;/h4&gt;这项研究将SFM定位为超越语音的新领域中的有前景工具。&lt;h4&gt;总结&lt;/h4&gt;SFM在处理生理信号时展示了良好的泛化能力，尤其是多语言模型在OOD任务中的表现更为优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite being trained exclusively on speech data, speech foundation models(SFMs) like Whisper have shown impressive performance in non-speech tasks suchas audio classification. This is partly because speech shares some commontraits with audio, enabling SFMs to transfer effectively. In this study, wepush the boundaries by evaluating SFMs on a more challenging out-of-domain(OOD) task: classifying physiological time-series signals. We test two keyhypotheses: first, that SFMs can generalize to physiological signals bycapturing shared temporal patterns; second, that multilingual SFMs willoutperform others due to their exposure to greater variability duringpre-training, leading to more robust, generalized representations. Ourexperiments, conducted for stress recognition using ECG (Electrocardiogram),EMG (Electromyography), and EDA (Electrodermal Activity) signals, reveal thatmodels trained on SFM-derived representations outperform those trained on rawphysiological signals. Among all models, multilingual SFMs achieve the highestaccuracy, supporting our hypothesis and demonstrating their OOD capabilities.This work positions SFMs as promising tools for new uncharted domains beyondspeech.</description>
      <author>example@mail.com (Orchid Chetia Phukan, Swarup Ranjan Behera, Girish, Mohd Mujtaba Akhtar, Arun Balaji Buduru, Rajesh Sharma)</author>
      <guid isPermaLink="false">2410.12645v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene Representation</title>
      <link>http://arxiv.org/abs/2410.13571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  https://drivedreamer4d.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;闭环仿真对推进端到端的自主驾驶系统至关重要。现有的传感器仿真方法主要依赖于与训练数据分布紧密对齐的条件，限制在前行驾驶场景中。&lt;h4&gt;目的&lt;/h4&gt;介绍DriveDreamer4D，提升4D驾驶场景表示，利用世界模型进行视频生成。&lt;h4&gt;方法&lt;/h4&gt;利用世界模型作为数据机器，根据真实驾驶数据合成新颖的轨迹视频，控制前景和背景元素的时空一致性，以遵循交通约束。&lt;h4&gt;主要发现&lt;/h4&gt;DriveDreamer4D在新轨迹视角下显著提升生成质量，相比PVG、S3 Gaussian和Deformable-GS，FID相对改善分别为24.5%、39.0%和10.5%；同时在NTA-IoU指标上增加了20.3%、42.0%和13.7%。&lt;h4&gt;结论&lt;/h4&gt;DriveDreamer4D是首个利用视频生成模型来改善驾驶场景中4D重建的方法，显著增强了驾驶代理的时空一致性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了DriveDreamer4D在自主驾驶仿真中的创新，推动了动态驾驶环境的复杂场景生成。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Closed-loop simulation is essential for advancing end-to-end autonomousdriving systems. Contemporary sensor simulation methods, such as NeRF and 3DGS,rely predominantly on conditions closely aligned with training datadistributions, which are largely confined to forward-driving scenarios.Consequently, these methods face limitations when rendering complex maneuvers(e.g., lane change, acceleration, deceleration). Recent advancements inautonomous-driving world models have demonstrated the potential to generatediverse driving videos. However, these approaches remain constrained to 2Dvideo generation, inherently lacking the spatiotemporal coherence required tocapture intricacies of dynamic driving environments. In this paper, weintroduce \textit{DriveDreamer4D}, which enhances 4D driving scenerepresentation leveraging world model priors. Specifically, we utilize theworld model as a data machine to synthesize novel trajectory videos based onreal-world driving data. Notably, we explicitly leverage structured conditionsto control the spatial-temporal consistency of foreground and backgroundelements, thus the generated data adheres closely to traffic constraints. Toour knowledge, \textit{DriveDreamer4D} is the first to utilize video generationmodels for improving 4D reconstruction in driving scenarios. Experimentalresults reveal that \textit{DriveDreamer4D} significantly enhances generationquality under novel trajectory views, achieving a relative improvement in FIDby 24.5\%, 39.0\%, and 10.5\% compared to PVG, $\text{S}^3$Gaussian, andDeformable-GS. Moreover, \textit{DriveDreamer4D} markedly enhances thespatiotemporal coherence of driving agents, which is verified by acomprehensive user study and the relative increases of 20.3\%, 42.0\%, and13.7\% in the NTA-IoU metric.</description>
      <author>example@mail.com (Guosheng Zhao, Chaojun Ni, Xiaofeng Wang, Zheng Zhu, Guan Huang, Xinze Chen, Boyuan Wang, Youyi Zhang, Wenjun Mei, Xingang Wang)</author>
      <guid isPermaLink="false">2410.13571v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ABBA-VSM: Time Series Classification using Symbolic Representation on the Edge</title>
      <link>http://arxiv.org/abs/2410.10285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages with references, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，边缘人工智能（Edge AI）在多个行业中变得越来越普遍，应用于环境监测和智能城市管理等领域。&lt;h4&gt;目的&lt;/h4&gt;解决现有时间序列分类（TSC）算法在边缘环境中因资源受限而难以有效部署的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种自适应布朗桥符号聚合向量空间模型（ABBA-VSM），通过将原始时间序列自适应压缩为符号表示，直接在这些符号上训练分类模型。&lt;h4&gt;主要发现&lt;/h4&gt;ABBA-VSM在IoT与边缘设备之间减少了通信数据和计算周期。在UCR时间序列分类存档的数据集上，ABBA-VSM达到了最高80%的压缩比和90-100%的二分类准确率，非二分类的平均压缩比为60%，准确率在60-80%之间。&lt;h4&gt;结论&lt;/h4&gt;ABBA-VSM为边缘环境中的资源高效TSC服务提供了有效解决方案。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的ABBA-VSM模型在保证分类准确率的同时，实现了数据的高效压缩，适合资源受限的边缘计算环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Edge AI has become more prevalent with applications acrossvarious industries, from environmental monitoring to smart city management.Edge AI facilitates the processing of Internet of Things (IoT) data andprovides privacy-enabled and latency-sensitive services to application usersusing Machine Learning (ML) algorithms, e.g., Time Series Classification (TSC).However, existing TSC algorithms require access to full raw data and demandsubstantial computing resources to train and use them effectively in runtime.This makes them impractical for deployment in resource-constrained Edgeenvironments. To address this, in this paper, we propose an Adaptive BrownianBridge-based Symbolic Aggregation Vector Space Model (ABBA-VSM). It is a newTSC model designed for classification services on Edge. Here, we firstadaptively compress the raw time series into symbolic representations, thuscapturing the changing trends of data. Subsequently, we train theclassification model directly on these symbols. ABBA-VSM reduces communicationdata between IoT and Edge devices, as well as computation cycles, in thedevelopment of resource-efficient TSC services on Edge. We evaluate oursolution with extensive experiments using datasets from the UCR time seriesclassification archive. The results demonstrate that the ABBA-VSM achieves upto 80% compression ratio and 90-100% accuracy for binary classification.Whereas, for non-binary classification, it achieves an average compressionratio of 60% and accuracy ranging from 60-80%.</description>
      <author>example@mail.com (Meerzhan Kanatbekova, Shashikant Ilager, Ivona Brandic)</author>
      <guid isPermaLink="false">2410.10285v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>A Subsequence Approach to Topological Data Analysis for Irregularly-Spaced Time Series</title>
      <link>http://arxiv.org/abs/2410.13723v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间延迟嵌入（TDE）基于Takens定理，为时间序列数据的内在动态提供了表示和分析机制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的子序列嵌入方法，以处理不规则间隔的时间序列数据。&lt;h4&gt;方法&lt;/h4&gt;该方法通过持久性同调的视角，结合拓扑数据分析（TDA）来研究时间序列表示。&lt;h4&gt;主要发现&lt;/h4&gt;新方法保留了原始状态空间的拓扑结构，同时减少了虚假同调特征。&lt;h4&gt;结论&lt;/h4&gt;在噪声和时间序列间隔不规则性的不同程度下，提出的方法具有理论稳定性和收敛性。&lt;h4&gt;应用&lt;/h4&gt;数值研究和对真实数据的应用证明了提出方法的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究为不规则间隔的时间序列数据提供了一种有效的分析方法，增强了对其动态特征的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A time-delay embedding (TDE), grounded in the framework of Takens's Theorem,provides a mechanism to represent and analyze the inherent dynamics oftime-series data. Recently, topological data analysis (TDA) methods have beenapplied to study this time series representation mainly through the lens ofpersistent homology. Current literature on the fusion of TDE and TDA are adeptat analyzing uniformly-spaced time series observations. This work introduces anovel {\em subsequence} embedding method for irregularly-spaced time-seriesdata. We show that this method preserves the original state space topologywhile reducing spurious homological features. Theoretical stability results andconvergence properties of the proposed method in the presence of noise andvarying levels of irregularity in the spacing of the time series areestablished. Numerical studies and an application to real data illustrates theperformance of the proposed method.</description>
      <author>example@mail.com (Sixtus Dakurah, Jessi Cisewski-Kehe)</author>
      <guid isPermaLink="false">2410.13723v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Towards Autonomous Indoor Parking: A Globally Consistent Semantic SLAM System and A Semantic Localization Subsystem</title>
      <link>http://arxiv.org/abs/2410.12169v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种全球一致的语义SLAM系统(GCSLAM)和语义融合定位子系统(SF-Loc)，旨在复杂停车场中实现准确的语义映射和稳健的定位。&lt;h4&gt;目的&lt;/h4&gt;提高在复杂环境中的定位和映射精度。&lt;h4&gt;方法&lt;/h4&gt;使用前视和环视视觉相机、IMU和轮编码器作为输入传感器配置。GCSLAM引入了一种新型因子图来优化姿态和语义地图，结合多传感器数据和鸟瞰视角的语义信息，以及一个全局槽管理模块来存储和管理停车位观测。SF-Loc利用GCSLAM构建的语义地图进行基于地图的定位。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界的数据集上表现出优于现有SLAM系统的性能，展示了在稳健的全局定位和精确的语义映射方面的卓越能力。&lt;h4&gt;结论&lt;/h4&gt;GCSLAM和SF-Loc结合提供了一种有效的解决方案，能够在复杂的停车场环境中实现高效的语义映射和定位。&lt;h4&gt;总结&lt;/h4&gt;该研究为复杂环境中的SLAM技术发展提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a globally consistent semantic SLAM system (GCSLAM) and asemantic-fusion localization subsystem (SF-Loc), which achieves accuratesemantic mapping and robust localization in complex parking lots. Visualcameras (front-view and surround-view), IMU, and wheel encoder form the inputsensor configuration of our system. The first part of our work is GCSLAM.GCSLAM introduces a novel factor graph for the optimization of poses andsemantic map, which incorporates innovative error terms based on multi-sensordata and BEV (bird's-eye view) semantic information. Additionally, GCSLAMintegrates a Global Slot Management module that stores and manages parking slotobservations. SF-Loc is the second part of our work, which leverages thesemantic map built by GCSLAM to conduct map-based localization. SF-Locintegrates registration results and odometry poses with a novel factor graph.Our system demonstrates superior performance over existing SLAM on tworeal-world datasets, showing excellent capabilities in robust globallocalization and precise semantic mapping.</description>
      <author>example@mail.com (Yichen Sha, Siting Zhu, Hekui Guo, Zhong Wang, Hesheng Wang)</author>
      <guid isPermaLink="false">2410.12169v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Gravity-aligned Rotation Averaging with Circular Regression</title>
      <link>http://arxiv.org/abs/2410.12763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at ECCV2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "从无序图像重建3D场景在计算机视觉和机器人技术中至关重要，具有众包地图等广泛应用。",
    "目的": "提出一种整合重力方向的全局结构光束法(SfM)方法，以提高相机方向精度并减少自由度。",
    "方法": "将重力方向信息融入全局管道的旋转平均阶段，基于圆形回归算法，支持部分相机已知重力的场景。",
    "主要发现": "在四个大规模数据集上达到了最先进的精度，相较于SfM基线平均提高了13个AUC@$1^\circ$点，同时速度提升了八倍。",
    "结论": "该方法在准确性上优于标准平面姿态图优化技术，提升了23个AUC@$1^\circ$点。代码可在GitHub上获取。",
    "总结": "此方法利用可用的重力信息有效提升了3D重建的准确性和效率，适用于现代消费设备。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing a 3D scene from unordered images is pivotal in computer visionand robotics, with applications spanning crowd-sourced mapping and beyond.While global Structure-from-Motion (SfM) techniques are scalable and fast, theyoften compromise on accuracy. To address this, we introduce a principledapproach that integrates gravity direction into the rotation averaging phase ofglobal pipelines, enhancing camera orientation accuracy and reducing thedegrees of freedom. This additional information is commonly available in recentconsumer devices, such as smartphones, mixed-reality devices and drones, makingthe proposed method readily accessible. Rooted in circular regression, ouralgorithm has similar convergence guarantees as linear regression. It alsosupports scenarios where only a subset of cameras have known gravity.Additionally, we propose a mechanism to refine error-prone gravity. We achievestate-of-the-art accuracy on four large-scale datasets. Particularly, theproposed method improves upon the SfM baseline by 13 AUC@$1^\circ$ points, onaverage, while running eight times faster. It also outperforms the standardplanar pose graph optimization technique by 23 AUC@$1^\circ$ points. The codeis at https://github.com/colmap/glomap.</description>
      <author>example@mail.com (Linfei Pan, Marc Pollefeys, Dániel Baráth)</author>
      <guid isPermaLink="false">2410.12763v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring</title>
      <link>http://arxiv.org/abs/2410.13616v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究提出了通过无人机摄像头进行多类别车辆检测的进展，涉及时空物体检测模型的开发。&lt;h4&gt;目的&lt;/h4&gt;构建一个用于全面训练和评估算法的时空车辆检测数据集。&lt;h4&gt;方法&lt;/h4&gt;引入了一个包含6600张标注序列帧图像的时空车辆检测数据集，并增强了基于YOLO的物体检测算法以纳入时间动态。&lt;h4&gt;主要发现&lt;/h4&gt;最佳的时空模型相较于单帧模型提高了16.22%的性能，注意力机制进一步提升了模型的性能。&lt;h4&gt;结论&lt;/h4&gt;集成注意力机制的时空模型显示出额外的性能增益潜力，并验证了显著的进步。&lt;h4&gt;总结&lt;/h4&gt;本研究在无人机多类别车辆检测领域推动了时空感知的算法发展，展示了数据集和模型改进的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TAI.2024.3454566&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents advancements in multi-class vehicle detection using UAVcameras through the development of spatiotemporal object detection models. Thestudy introduces a Spatio-Temporal Vehicle Detection Dataset (STVD) containing6, 600 annotated sequential frame images captured by UAVs, enablingcomprehensive training and evaluation of algorithms for holistic spatiotemporalperception. A YOLO-based object detection algorithm is enhanced to incorporatetemporal dynamics, resulting in improved performance over single frame models.The integration of attention mechanisms into spatiotemporal models is shown tofurther enhance performance. Experimental validation demonstrates significantprogress, with the best spatiotemporal model exhibiting a 16.22% improvementover single frame models, while it is demonstrated that attention mechanismshold the potential for additional performance gains.</description>
      <author>example@mail.com (Kristina Telegraph, Christos Kyrkou)</author>
      <guid isPermaLink="false">2410.13616v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation</title>
      <link>http://arxiv.org/abs/2410.13817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  J. P. Sleiman and M. Mittal contributed equally. Accepted for CoRL
  2024 (Oral). Project website:
  https://leggedrobotics.github.io/guided-rl-locoma/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;强化学习通常需要针对每个任务精心设计马尔可夫决策过程（MDP）。&lt;h4&gt;目的&lt;/h4&gt;提出一种系统化的方法来合成行为和控制多接触的运动操作任务。&lt;h4&gt;方法&lt;/h4&gt;定义一个任务无关的MDP，通过基于模型的轨迹优化器生成每个任务的单个示范来训练RL策略，并采用自适应相位动态公式来有效追踪示范。&lt;h4&gt;主要发现&lt;/h4&gt;与之前的运动模仿RL方法相比，所学策略在所有考虑的任务中成功率更高，能够学习到示范中没有的恢复操作。&lt;h4&gt;结论&lt;/h4&gt;成功将这些策略转移到真实机器人上，证明了该方法的实际可行性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种有效的RL策略训练方法，能处理动态不确定性和外部干扰，适用于复杂的运动操作任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning (RL) often necessitates a meticulous Markov DecisionProcess (MDP) design tailored to each task. This work aims to address thischallenge by proposing a systematic approach to behavior synthesis and controlfor multi-contact loco-manipulation tasks, such as navigating spring-loadeddoors and manipulating heavy dishwashers. We define a task-independent MDP totrain RL policies using only a single demonstration per task generated from amodel-based trajectory optimizer. Our approach incorporates an adaptive phasedynamics formulation to robustly track the demonstrations while accommodatingdynamic uncertainties and external disturbances. We compare our method againstprior motion imitation RL works and show that the learned policies achievehigher success rates across all considered tasks. These policies learn recoverymaneuvers that are not present in the demonstration, such as re-graspingobjects during execution or dealing with slippages. Finally, we successfullytransfer the policies to a real robot, demonstrating the practical viability ofour approach.</description>
      <author>example@mail.com (Jean-Pierre Sleiman, Mayank Mittal, Marco Hutter)</author>
      <guid isPermaLink="false">2410.13817v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Semantic Cues from Foundation Vision Models for Enhanced Local Feature Correspondence</title>
      <link>http://arxiv.org/abs/2410.09533v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in ACCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉对应是计算机视觉任务中的关键步骤，包括相机定位、图像配准和运动结构重建。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，通过引入语义推理来增强局部特征匹配。&lt;h4&gt;方法&lt;/h4&gt;使用基础视觉模型特征（如DINOv2）的语义线索，改进现有描述符，使得在推理时不需要图像对。&lt;h4&gt;主要发现&lt;/h4&gt;六种现有描述符的适应版本在相机定位中平均性能提高了29%，与现有匹配器如LightGlue和LoFTR在两个基准测试中的准确性相当。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法通过特征缓存和快速相似性搜索实现了高效匹配，代码和训练模型可在指定网址获取。&lt;h4&gt;总结&lt;/h4&gt;该研究通过引入语义推理显著提升了特征匹配的性能，减少了对图像对的依赖。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual correspondence is a crucial step in key computer vision tasks,including camera localization, image registration, and structure from motion.The most effective techniques for matching keypoints currently involve usinglearned sparse or dense matchers, which need pairs of images. These neuralnetworks have a good general understanding of features from both images, butthey often struggle to match points from different semantic areas. This paperpresents a new method that uses semantic cues from foundation vision modelfeatures (like DINOv2) to enhance local feature matching by incorporatingsemantic reasoning into existing descriptors. Therefore, the learneddescriptors do not require image pairs at inference time, allowing featurecaching and fast matching using similarity search, unlike learned matchers. Wepresent adapted versions of six existing descriptors, with an average increasein performance of 29% in camera localization, with comparable accuracy toexisting matchers as LightGlue and LoFTR in two existing benchmarks. Both codeand trained models are available athttps://www.verlab.dcc.ufmg.br/descriptors/reasoning_accv24</description>
      <author>example@mail.com (Felipe Cadar, Guilherme Potje, Renato Martins, Cédric Demonceaux, Erickson R. Nascimento)</author>
      <guid isPermaLink="false">2410.09533v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Assessing the Optimistic Bias in the Natural Inflow Forecasts: A Call for Model Monitoring in Brazil</title>
      <link>http://arxiv.org/abs/2410.13763v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;到2023年，巴西水电占总发电量的约66%，有效应对了风能和太阳能的间歇性问题。&lt;h4&gt;目的&lt;/h4&gt;预测自然流入能量（NIE）时间序列，以评估水资源的价值并进行长期水电热计划。&lt;h4&gt;方法&lt;/h4&gt;通过滚动窗口的样本外测试，分析官方NIE预测与实际观察之间的偏差。&lt;h4&gt;主要发现&lt;/h4&gt;在过去12年中，官方NIE预测值在东南和东北两个主要子系统中，持续高于实际观察值，显示出乐观偏差。&lt;h4&gt;结论&lt;/h4&gt;东南子系统的统计偏差分别为6%、13%、18%和23%，而东北子系统为19%、57%、80%和108%。&lt;h4&gt;总结&lt;/h4&gt;监测NIE预测中的乐观偏差对于避免过于乐观的未来系统条件评估及风险较高的储存政策至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hydroelectricity accounted for roughly 66% of the total generation in Brazilin 2023 and addressed most of the intermittency of wind and solar generation.Thus, one of the most important steps in the operation planning of this countryis the forecast of the natural inflow energy (NIE) time series, anapproximation of the energetic value of the water inflows. To manage waterresources over time, the Brazilian system operator performs long-term forecastsfor the NIE to assess the water values through long-term hydrothermal planningmodels, which are then used to define the short-term merit order in day-aheadscheduling. Therefore, monitoring optimistic bias in NIE forecasts is crucialto prevent an optimistic view of future system conditions and subsequentriskier storage policies. In this article, we investigate and showcase strongevidence of an optimistic bias in the official NIE forecasts, with predictedvalues consistently exceeding the observations over the past 12 years in thetwo main subsystems (Southeast and Northeast). Rolling window out-of-sampletests conducted with real data demonstrate that the official forecast modelexhibits a statistically significant bias of 6%, 13%, 18%, and 23% for 1, 6,12, and 24 steps ahead in the Southeast subsystem, and 19%, 57%, 80%, and 108%in the Northeast.</description>
      <author>example@mail.com (Arthur Brigatto, Alexandre Street, Cristiano Fernandes, Davi Valladao, Guilherme Bodin, Joaquim Dias Garcia)</author>
      <guid isPermaLink="false">2410.13763v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CitySolution: A complaining task distributive mobile application for smart city corporation using deep learning</title>
      <link>http://arxiv.org/abs/2410.12882v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;缺乏自动化在线平台来报告市民投诉，城市公司在管理投诉方面面临重大挑战，资源有限。&lt;h4&gt;目的&lt;/h4&gt;开发两个Android应用程序，并使用深度学习模型自动分类投诉。&lt;h4&gt;方法&lt;/h4&gt;使用Teachable Machine创建深度学习模型，开发市民和管理者两种版本的应用程序。&lt;h4&gt;主要发现&lt;/h4&gt;市民可以通过拍照轻松报告市政问题，管理者能够获取分类的投诉信息及其位置和状态。&lt;h4&gt;结论&lt;/h4&gt;高层管理者可以监测市政进展，提高透明度和效率，促进全国范围内的智慧城市发展。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种有效的投诉管理解决方案，通过技术提升市民和政府之间的互动。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The lack of an automated online platform for reporting citizens' complaints,coupled with the city corporations' struggles in managing them, presentssignificant challenges. Furthermore, the availability of resources is verylimited to higher authorities for monitoring progress. The primary objective ofthis paper is to develop two Android applications and to categorize complaintsautomatically using a deep learning model created on the Teachable Machine.With the citizen-oriented application, individuals can easily report complaintsby capturing pictures of their municipal issues. The authority version of theapplication provides categorized complaints, along with location and statusdetails. Higher authorities can monitor the municipal progress, therebyenhancing transparency, and efficiency and promoting smart city development ona nationwide scale.</description>
      <author>example@mail.com (Farhatun Shama, Abdul Aziz, Lamisa Bintee Mizan Deya)</author>
      <guid isPermaLink="false">2410.12882v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>PAPL-SLAM: Principal Axis-Anchored Monocular Point-Line SLAM</title>
      <link>http://arxiv.org/abs/2410.12324v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在点线SLAM系统中，线结构信息的利用和线的优化是两个重要问题。&lt;h4&gt;目的&lt;/h4&gt;同时解决线结构信息的约束和优化问题，以提高映射和跟踪的准确性。&lt;h4&gt;方法&lt;/h4&gt;通过将方向相似的线锚定到主轴，并使用$n+2$个参数对$n$条线进行优化，考虑场景结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法显著减少了需要优化的线参数数量，并能够快速准确地进行映射和跟踪。&lt;h4&gt;结论&lt;/h4&gt;通过建模线轴概率数据关联和提供轴的创建、更新及优化算法，增强了系统的鲁棒性，避免了不匹配。&lt;h4&gt;额外信息&lt;/h4&gt;基于垂直先验和消失点的结构线检测策略适用于大多数现实场景符合亚特兰大世界假设。&lt;h4&gt;总结&lt;/h4&gt;在各种室内外数据集上的实验结果和消融研究证明了该系统的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In point-line SLAM systems, the utilization of line structural informationand the optimization of lines are two significant problems. The former isusually addressed through structural regularities, while the latter typicallyinvolves using minimal parameter representations of lines in optimization.However, separating these two steps leads to the loss of constraint informationto each other. We anchor lines with similar directions to a principal axis andoptimize them with $n+2$ parameters for $n$ lines, solving both problemstogether. Our method considers scene structural information, which can beeasily extended to different world hypotheses while significantly reducing thenumber of line parameters to be optimized, enabling rapid and accurate mappingand tracking. To further enhance the system's robustness and avoid mismatch, wehave modeled the line-axis probabilistic data association and provided thealgorithm for axis creation, updating, and optimization. Additionally,considering that most real-world scenes conform to the Atlanta Worldhypothesis, we provide a structural line detection strategy based on verticalpriors and vanishing points. Experimental results and ablation studies onvarious indoor and outdoor datasets demonstrate the effectiveness of oursystem.</description>
      <author>example@mail.com (Guanghao Li, Yu Cao, Qi Chen, Yifan Yang, Jian Pu)</author>
      <guid isPermaLink="false">2410.12324v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Towards a Factor Graph-Based Method using Angular Rates for Full Magnetometer Calibration and Gyroscope Bias Estimation</title>
      <link>http://arxiv.org/abs/2410.13827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 figures, submitted to 2024 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;MEMS姿态参考系统广泛应用于确定系统的姿态，但传感器测量偏差限制了其准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的基于因子图的方法，称为磁力计和陀螺仪校准（MAGYC）。&lt;h4&gt;方法&lt;/h4&gt;MAGYC利用三轴角速率测量来增强批处理和在线校准，减少对仪器运动的严格要求，且不需要了解局部磁场或仪器姿态，便于与平滑和映射框架中的因子图算法集成。&lt;h4&gt;主要发现&lt;/h4&gt;通过数值仿真和在水下车辆上的实地实验评估，提出的方法将水下车辆的航向误差标准偏差从6.21度降低至0.57度。&lt;h4&gt;结论&lt;/h4&gt;MAGYC方法显著提高了水下车辆的航向测量精度，适用于标准海底测绘调查。&lt;h4&gt;总结&lt;/h4&gt;MAGYC方法在校准过程中提供了更灵活的条件，显著改善了传感器的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; MEMS Attitude Heading Reference Systems are widely employed to determine asystem's attitude, but sensor measurement biases limit their accuracy. Thispaper introduces a novel factor graph-based method called MAgnetometer andGYroscope Calibration (MAGYC). MAGYC leverages three-axis angular ratemeasurements from an angular rate gyroscope to enhance calibration for batchand online applications. Our approach imposes less restrictive conditions forinstrument movements required for calibration, eliminates the need forknowledge of the local magnetic field or instrument attitude, and facilitatesintegration into factor graph algorithms within Smoothing and Mappingframeworks. We evaluate the proposed methods through numerical simulations andin-field experimental assessments using a sensor installed on an underwatervehicle. Ultimately, our proposed methods reduced the underwater vehicle'sheading error standard deviation from 6.21 to 0.57 degrees for a standardseafloor mapping survey.</description>
      <author>example@mail.com (Sebastián Rodríguez-Martínez, Giancarlo Troni)</author>
      <guid isPermaLink="false">2410.13827v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>LoGS: Visual Localization via Gaussian Splatting with Fewer Training Images</title>
      <link>http://arxiv.org/abs/2410.11505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉定位涉及估计查询图像的6自由度相机姿态，是计算机视觉和机器人任务中的基本组件。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于视觉的定位流程LoGS，利用3D高斯散点（GS）技术进行场景表示。&lt;h4&gt;方法&lt;/h4&gt;在映射阶段，首先应用运动重建（SfM），然后生成GS地图。在定位过程中，通过图像检索获得初始位置，结合局部特征匹配和PnP求解器，最后通过对GS地图的分析-合成方法实现高精度姿态。&lt;h4&gt;主要发现&lt;/h4&gt;在四个大规模数据集上的实验结果表明，该方法在相机姿态估计方面达到了最先进的准确性，并且在挑战性的少量样本条件下表现出良好的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;LoGS方法提供了一种有效的视觉定位解决方案，具有高质量的新视图合成能力。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了通过3D高斯散点技术实现精确视觉定位的潜力，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization involves estimating a query image's 6-DoF (degrees offreedom) camera pose, which is a fundamental component in various computervision and robotic tasks. This paper presents LoGS, a vision-based localizationpipeline utilizing the 3D Gaussian Splatting (GS) technique as scenerepresentation. This novel representation allows high-quality novel viewsynthesis. During the mapping phase, structure-from-motion (SfM) is appliedfirst, followed by the generation of a GS map. During localization, the initialposition is obtained through image retrieval, local feature matching coupledwith a PnP solver, and then a high-precision pose is achieved through theanalysis-by-synthesis manner on the GS map. Experimental results on fourlarge-scale datasets demonstrate the proposed approach's SoTA accuracy inestimating camera poses and robustness under challenging few-shot conditions.</description>
      <author>example@mail.com (Yuzhou Cheng, Jianhao Jiao, Yue Wang, Dimitrios Kanoulas)</author>
      <guid isPermaLink="false">2410.11505v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Enabling a multifunctional telecommunications fiber optic network: Ultrastable optical frequency transfer and attosecond timing in deployed multicore fiber</title>
      <link>http://arxiv.org/abs/2410.13801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;电信行业部署了数十亿公里的光纤，形成了一个庞大的全球网络，可用于环境传感、量子网络和国际时间比较等附加应用。&lt;h4&gt;目的&lt;/h4&gt;解决电信光纤网络因单向性而无法适应重要应用的问题。&lt;h4&gt;方法&lt;/h4&gt;提出并演示通过多芯光纤准确传输超稳定光信号，兼容长途光纤系统的单向性。&lt;h4&gt;主要发现&lt;/h4&gt;在10,000秒时，展示了3x10^-19的分数频率不稳定性。&lt;h4&gt;结论&lt;/h4&gt;这一成果为跨洲光钟比较提供了可能，具有基础物理学和重新定义秒的应用前景。&lt;h4&gt;总结&lt;/h4&gt;多芯光纤的应用为电信网络的多功能性提供了新的机遇，推动了更广泛的科学应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The telecommunications industry's deployment of billions of kilometers ofoptical fiber has created a vast global network that can be exploited foradditional applications such as environmental sensing, quantum networking andinternational clock comparisons. However, for reasons such as theunidirectionality of long-haul fiber links, telecom fiber networks cannotalways be adapted for important applications beyond data transmission.Fortunately, new multicore optical fibers create the opportunity forapplication coexistence with data traffic, creating expansive multifunctionalnetworks. Towards that end, we propose and demonstrate the faithful transfer ofultrastable optical signals through multicore fiber in a way that is compatiblewith the unidirectionality of long-haul fiber optic systems, demonstrating afractional frequency instability of 3x10-19 at 10,000 seconds. This opens thedoor towards intercontinental optical clock comparisons, with applications infundamental physics and the redefinition of the second.</description>
      <author>example@mail.com (Nazanin Hoghooghi, Mikael Mazur, Nicolas Fontaine, Yifan Liu, Dahyeon Lee, Charles McLemore, Takuma Nakamura, Tetsuya Hayashi, Giammarco Di Sciullo, Divya Shaji, Antonio Mecozzi, Cristian Antonelli, Franklyn Quinlan)</author>
      <guid isPermaLink="false">2410.13801v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing Deep Transformer Models for Time Series Forecasting via Manifold Learning</title>
      <link>http://arxiv.org/abs/2410.13792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to TMLR 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Transformer 模型在自然语言处理和计算机视觉等多个领域取得了显著成果，但对这些模型的全面理解仍然不足，尤其是在深度时间序列预测方法方面。&lt;h4&gt;目的&lt;/h4&gt;分析时间序列预测模型的几何特征，以提高对 Transformer 模型的理解。&lt;h4&gt;方法&lt;/h4&gt;从流形学习的角度出发，假设时间序列预测模型的潜在表示位于低维流形上，重点分析这些潜在数据流形的内在维度和主曲率。&lt;h4&gt;主要发现&lt;/h4&gt;深度 Transformer 模型在各层之间表现出相似的几何行为，这些几何特征与模型性能相关。此外，未训练模型的结构最初有所不同，但在训练过程中迅速收敛。&lt;h4&gt;结论&lt;/h4&gt;通过几何分析和可微分工具，可以设计出新的改进型深度预测神经网络，这为现有分析研究提供了补充，并有助于更好地理解 Transformer 模型在时间序列预测中的表现。&lt;h4&gt;总结&lt;/h4&gt;本研究为时间序列预测中的 Transformer 模型提供了几何分析的新视角，可能推动相关领域的进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformer models have consistently achieved remarkable results in variousdomains such as natural language processing and computer vision. However,despite ongoing research efforts to better understand these models, the fieldstill lacks a comprehensive understanding. This is particularly true for deeptime series forecasting methods, where analysis and understanding work isrelatively limited. Time series data, unlike image and text information, can bemore challenging to interpret and analyze. To address this, we approach theproblem from a manifold learning perspective, assuming that the latentrepresentations of time series forecasting models lie next to a low-dimensionalmanifold. In our study, we focus on analyzing the geometric features of theselatent data manifolds, including intrinsic dimension and principal curvatures.Our findings reveal that deep transformer models exhibit similar geometricbehavior across layers, and these geometric features are correlated with modelperformance. Additionally, we observe that untrained models initially havedifferent structures, but they rapidly converge during training. By leveragingour geometric analysis and differentiable tools, we can potentially design newand improved deep forecasting neural networks. This approach complementsexisting analysis studies and contributes to a better understanding oftransformer models in the context of time series forecasting. Code is releasedat https://github.com/azencot-group/GATLM.</description>
      <author>example@mail.com (Ilya Kaufman, Omri Azencot)</author>
      <guid isPermaLink="false">2410.13792v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Sparse Prototype Network for Explainable Pedestrian Behavior Prediction</title>
      <link>http://arxiv.org/abs/2410.12195v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预测行人行为对自动驾驶和智慧城市等应用至关重要，但现有深度学习模型在准确预测方面表现出色，却无法解释其内部工作原理。&lt;h4&gt;目的&lt;/h4&gt;提出一种可解释的方法Sparse Prototype Network (SPN)，旨在同时预测行人的未来动作、轨迹和姿态。&lt;h4&gt;方法&lt;/h4&gt;SPN利用中间原型瓶颈层提供基于样本的解释，原型是模态无关的，可以对应输入的任意模态，并通过单语义性和聚类约束进行正则化。&lt;h4&gt;主要发现&lt;/h4&gt;原型学习到一致且易于人类理解的特征，在TITAN和PIE数据集上实现了动作、轨迹和姿态预测的最先进性能。&lt;h4&gt;结论&lt;/h4&gt;提出了一种名为Top-K Mono-semanticity Scale的度量，以定量评估可解释性，定性结果显示稀疏性与可解释性之间存在正相关。&lt;h4&gt;总结&lt;/h4&gt;SPN为行人行为预测提供了一种新的解释性框架，增强了预测结果的可理解性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting pedestrian behavior is challenging yet crucial for applicationssuch as autonomous driving and smart city. Recent deep learning models haveachieved remarkable performance in making accurate predictions, but they failto provide explanations of their inner workings. One reason for this problem isthe multi-modal inputs. To bridge this gap, we present Sparse Prototype Network(SPN), an explainable method designed to simultaneously predict a pedestrian'sfuture action, trajectory, and pose. SPN leverages an intermediate prototypebottleneck layer to provide sample-based explanations for its predictions. Theprototypes are modality-independent, meaning that they can correspond to anymodality from the input. Therefore, SPN can extend to arbitrary combinations ofmodalities. Regularized by mono-semanticity and clustering constraints, theprototypes learn consistent and human-understandable features and achievestate-of-the-art performance on action, trajectory and pose prediction on TITANand PIE. Finally, we propose a metric named Top-K Mono-semanticity Scale toquantitatively evaluate the explainability. Qualitative results show thepositive correlation between sparsity and explainability. Code available athttps://github.com/Equinoxxxxx/SPN.</description>
      <author>example@mail.com (Yan Feng, Alexander Carballo, Kazuya Takeda)</author>
      <guid isPermaLink="false">2410.12195v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>QueensCAMP: an RGB-D dataset for robust Visual SLAM</title>
      <link>http://arxiv.org/abs/2410.12520v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉同时定位与地图构建（VSLAM）是机器人应用的基础技术，尽管研究取得了显著进展，但在恶劣环境下的鲁棒性仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的RGB-D数据集，用于评估VSLAM系统的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;数据集包含真实室内场景，具有动态物体、运动模糊和不同照明条件，并模拟了相机故障，包括镜头污垢、冷凝、曝光不足和过度曝光。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，传统的VSLAM算法ORB-SLAM2和基于深度学习的视觉里程计算法TartanVO在这些困难条件下性能下降。&lt;h4&gt;结论&lt;/h4&gt;该数据集和相机故障的开源工具为开发更鲁棒的VSLAM系统提供了宝贵的资源，以应对现实世界的挑战。&lt;h4&gt;总结&lt;/h4&gt;研究为VSLAM技术在复杂环境中的应用提供了新的评估工具，推动了相关领域的进一步发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Simultaneous Localization and Mapping (VSLAM) is a fundamentaltechnology for robotics applications. While VSLAM research has achievedsignificant advancements, its robustness under challenging situations, such aspoor lighting, dynamic environments, motion blur, and sensor failures, remainsa challenging issue. To address these challenges, we introduce a novel RGB-Ddataset designed for evaluating the robustness of VSLAM systems. The datasetcomprises real-world indoor scenes with dynamic objects, motion blur, andvarying illumination, as well as emulated camera failures, including lens dirt,condensation, underexposure, and overexposure. Additionally, we offeropen-source scripts for injecting camera failures into any images, enablingfurther customization by the research community. Our experiments demonstratethat ORB-SLAM2, a traditional VSLAM algorithm, and TartanVO, a DeepLearning-based VO algorithm, can experience performance degradation under thesechallenging conditions. Therefore, this dataset and the camera failureopen-source tools provide a valuable resource for developing more robust VSLAMsystems capable of handling real-world challenges.</description>
      <author>example@mail.com (Hudson M. S. Bruno, Esther L. Colombini, Sidney N. Givigi Jr)</author>
      <guid isPermaLink="false">2410.12520v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Spatial Attention and Edge Context for Optimized Feature Selection in Visual Localization</title>
      <link>http://arxiv.org/abs/2410.12240v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究探讨神经网络与经典机器人算法的交集，通过神经算法推理(NAR)框架，使神经网络能够有效地像经典机器人算法一样进行推理。&lt;h4&gt;目的&lt;/h4&gt;旨在通过学习执行经典算法，提升神经网络在机器人及安全关键应用中的可预测性和一致性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于图神经网络(GNN)的学习框架NAR-*ICP，学习经典ICP点云配准算法的中间算法步骤，并扩展了CLRS算法推理基准，加入经典机器人感知算法。&lt;h4&gt;主要发现&lt;/h4&gt;在多样化的数据集上进行评估，从真实世界到合成数据，展示了该方法在处理复杂和嘈杂输入时的灵活性。&lt;h4&gt;结论&lt;/h4&gt;该方法在所有基准和数据集上实现了优越的性能，持续超越其训练的算法，进一步证明了其超越传统算法能力的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;NAR-*ICP框架结合了神经网络的适应性和经典算法的可靠性，展现了在机器人领域的广泛应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual localization determines an agent's precise position and orientationwithin an environment using visual data. It has become a critical task in thefield of robotics, particularly in applications such as autonomous navigation.This is due to the ability to determine an agent's pose using cost-effectivesensors such as RGB cameras. Recent methods in visual localization employ scenecoordinate regression to determine the agent's pose. However, these methodsface challenges as they attempt to regress 2D-3D correspondences across theentire image region, despite not all regions providing useful information. Toaddress this issue, we introduce an attention network that selectively targetsinformative regions of the image. Using this network, we identify thehighest-scoring features to improve the feature selection process and combinethe result with edge detection. This integration ensures that the featureschosen for the training buffer are located within robust regions, therebyimproving 2D-3D correspondence and overall localization performance. Ourapproach was tested on the outdoor benchmark dataset, demonstrating superiorresults compared to previous methods.</description>
      <author>example@mail.com (Nanda Febri Istighfarin, HyungGi Jo)</author>
      <guid isPermaLink="false">2410.12240v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>NAR-*ICP: Neural Execution of Classical ICP-based Pointcloud Registration Algorithms</title>
      <link>http://arxiv.org/abs/2410.11031v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;奖励塑形是强化学习中的一个关键组成部分，尤其在稀疏奖励可能妨碍学习的复杂任务中。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来选择有效的奖励塑形函数，解决传统方法在选择时的挑战和计算开销。&lt;h4&gt;方法&lt;/h4&gt;引入在线奖励选择和策略优化（ORSO），将奖励塑形选择框架化为在线模型选择问题，采用原则性探索策略自动识别有前景的奖励塑形函数。&lt;h4&gt;主要发现&lt;/h4&gt;ORSO在各种连续控制任务中表现出色，显著提高了样本效率，减少了计算时间，并始终识别出与领域专家手工设计奖励生成的策略相当的高质量奖励函数。&lt;h4&gt;结论&lt;/h4&gt;ORSO方法在奖励塑形选择中展示了优越性，能够在无人工干预的情况下有效识别奖励函数。&lt;h4&gt;总结&lt;/h4&gt;ORSO通过平衡探索与利用，提供了可证明的遗憾保证，推动了强化学习领域的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study explores the intersection of neural networks and classicalrobotics algorithms through the Neural Algorithmic Reasoning (NAR) framework,allowing to train neural networks to effectively reason like classical roboticsalgorithms by learning to execute them. Algorithms are integral to robotics andsafety-critical applications due to their predictable and consistentperformance through logical and mathematical principles. In contrast, whileneural networks are highly adaptable, handling complex, high-dimensional dataand generalising across tasks, they often lack interpretability andtransparency in their internal computations. We propose a Graph Neural Network(GNN)-based learning framework, NAR-*ICP, which learns the intermediatealgorithmic steps of classical ICP-based pointcloud registration algorithms,and extend the CLRS Algorithmic Reasoning Benchmark with classical roboticsperception algorithms. We evaluate our approach across diverse datasets, fromreal-world to synthetic, demonstrating its flexibility in handling complex andnoisy inputs, along with its potential to be used as part of a larger learningsystem. Our results indicate that our method achieves superior performanceacross all benchmarks and datasets, consistently surpassing even the algorithmsit has been trained on, further demonstrating its ability to generalise beyondthe capabilities of traditional algorithms.</description>
      <author>example@mail.com (Efimia Panagiotaki, Daniele De Martini, Lars Kunze, Petar Veličković)</author>
      <guid isPermaLink="false">2410.11031v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization</title>
      <link>http://arxiv.org/abs/2410.13837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  preprint, 35 pages, 23 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高速度触觉阵列对于非结构化环境中的实时机器人控制至关重要，但高像素数量限制了大多数触觉阵列的读出速率，通常低于100Hz。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法ACTS，以提高触觉矩阵的采样效率和交互重建能力。&lt;h4&gt;方法&lt;/h4&gt;ACTS采用自适应压缩触觉子采样，通过稀疏恢复和学习的触觉字典进行交互重建。&lt;h4&gt;主要发现&lt;/h4&gt;在1024像素传感器阵列（32x32）上测试，ACTS相比光栅扫描提高了18倍的帧率，误差极小。&lt;h4&gt;结论&lt;/h4&gt;首次在大面积触觉皮肤中实现了快速物体分类（接触后20毫秒内）、高速飞行物检测、反弹角度估计和变形跟踪，增强了时空分辨率。&lt;h4&gt;应用&lt;/h4&gt;该方法可以在固件中实现，将现有的低成本、灵活且坚固的触觉阵列升级为高分辨率系统，适用于大面积时空触觉感知。&lt;h4&gt;总结&lt;/h4&gt;ACTS为触觉感知技术提供了一种有效的解决方案，显著提升了性能和应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/calvincbzhang/orso&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reward shaping is a critical component in reinforcement learning (RL),particularly for complex tasks where sparse rewards can hinder learning. Whileshaping rewards have been introduced to provide additional guidance, selectingeffective shaping functions remains challenging and computationally expensive.This paper introduces Online Reward Selection and Policy Optimization (ORSO), anovel approach that frames shaping reward selection as an online modelselection problem. ORSO employs principled exploration strategies toautomatically identify promising shaping reward functions without humanintervention, balancing exploration and exploitation with provable regretguarantees. We demonstrate ORSO's effectiveness across various continuouscontrol tasks using the Isaac Gym simulator. Compared to traditional methodsthat fully evaluate each shaping reward function, ORSO significantly improvessample efficiency, reduces computational time, and consistently identifieshigh-quality reward functions that produce policies comparable to thosegenerated by domain experts through hand-engineered rewards.</description>
      <author>example@mail.com (Chen Bo Calvin Zhang, Zhang-Wei Hong, Aldo Pacchiano, Pulkit Agrawal)</author>
      <guid isPermaLink="false">2410.13837v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Subsampling and Learned Model Improve Spatiotemporal Resolution of Tactile Skin</title>
      <link>http://arxiv.org/abs/2410.13847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 pages, 8 main figures, 12 supplemental figures, Videos can be
  accessed at https://tinyurl.com/TactileSubsampling&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的定位算法依赖复杂的3D表示，限制了无人机的定位能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法LoD-Loc，用于空中视觉定位。&lt;h4&gt;方法&lt;/h4&gt;LoD-Loc利用细节等级（LoD）3D地图，通过将LoD投影模型的线框与神经网络预测的线框对齐，来估计无人机的姿态。&lt;h4&gt;主要发现&lt;/h4&gt;LoD-Loc通过构建成本体积并选择最大概率姿态，展示了出色的性能，超越了当前使用纹理3D模型的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;LoD-Loc在无公共数据集的情况下，从头收集了两个数据集，并展示了其在定位任务中的有效性。&lt;h4&gt;总结&lt;/h4&gt;LoD-Loc是一种新颖的定位方法，具有较高的准确性和效率，适用于无人机的视觉定位。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-speed tactile arrays are essential for real-time robotic control inunstructured environments, but high pixel counts limit readout rates of mostlarge tactile arrays to below 100Hz. We introduce ACTS - adaptive compressivetactile subsampling - a method that efficiently samples tactile matrices andreconstructs interactions using sparse recovery and a learned tactiledictionary. Tested on a 1024-pixel sensor array (32x32), ACTS increased framerates by 18X compared to raster scanning, with minimal error. For the firsttime in large-area tactile skin, we demonstrate rapid object classificationwithin 20ms of contact, high-speed projectile detection, ricochet angleestimation, and deformation tracking through enhanced spatiotemporalresolution. Our method can be implemented in firmware, upgrading existinglow-cost, flexible, and robust tactile arrays into high-resolution systems forlarge-area spatiotemporal touch sensing.</description>
      <author>example@mail.com (Ariel Slepyan, Dian Li, Aidan Aug, Sriramana Sankar, Trac Tran, Nitish Thakor)</author>
      <guid isPermaLink="false">2410.13847v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>LoD-Loc: Aerial Visual Localization using LoD 3D Map with Neural Wireframe Alignment</title>
      <link>http://arxiv.org/abs/2410.12269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024; for Project page, see
  https://victorzoo.github.io/LoD-Loc.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Graph Transformer (GT)是一种特殊的图神经网络（GNN），利用多头注意力机制进行高阶消息传递，但在节点分类应用中存在一些局限性。&lt;h4&gt;目的&lt;/h4&gt;探索GT架构在节点分类任务中的适应性，并提出改进方案。&lt;h4&gt;方法&lt;/h4&gt;通过大量观察性实验，分析当前GT中多头自注意力模块的可替换性，以及前馈神经网络模块的价值，进而解耦GNN的传播（P）和变换（T），提出GNNFormer架构。&lt;h4&gt;主要发现&lt;/h4&gt;GT中的多头自注意力模块可以完全替换，而前馈神经网络模块具有重要价值。GNNFormer在同质和异质场景下均能有效适应节点分类任务。&lt;h4&gt;结论&lt;/h4&gt;GNNFormer架构在12个基准数据集上的实验表明，它能有效适应节点分类任务，不受全局噪声和计算效率的限制。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的GNNFormer架构克服了GT在节点分类中的局限性，展示了良好的适应性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a new method named LoD-Loc for visual localization in the air.Unlike existing localization algorithms, LoD-Loc does not rely on complex 3Drepresentations and can estimate the pose of an Unmanned Aerial Vehicle (UAV)using a Level-of-Detail (LoD) 3D map. LoD-Loc mainly achieves this goal byaligning the wireframe derived from the LoD projected model with that predictedby the neural network. Specifically, given a coarse pose provided by the UAVsensor, LoD-Loc hierarchically builds a cost volume for uniformly sampled posehypotheses to describe pose probability distribution and select a pose withmaximum probability. Each cost within this volume measures the degree of linealignment between projected and predicted wireframes. LoD-Loc also devises a6-DoF pose optimization algorithm to refine the previous result with adifferentiable Gaussian-Newton method. As no public dataset exists for thestudied problem, we collect two datasets with map levels of LoD3.0 and LoD2.0,along with real RGB queries and ground-truth pose annotations. We benchmark ourmethod and demonstrate that LoD-Loc achieves excellent performance, evensurpassing current state-of-the-art methods that use textured 3D models forlocalization. The code and dataset are available athttps://victorzoo.github.io/LoD-Loc.github.io/.</description>
      <author>example@mail.com (Juelin Zhu, Shen Yan, Long Wang, Shengyue Zhang, Yu Liu, Maojun Zhang)</author>
      <guid isPermaLink="false">2410.12269v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Graph Transformer Architecture Design for Node Classification</title>
      <link>http://arxiv.org/abs/2410.11189v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联邦图神经网络（FedGNN）是一种结合了联邦学习和图神经网络的隐私保护机器学习技术，旨在使用孤立的图数据进行训练。&lt;h4&gt;目的&lt;/h4&gt;探讨垂直联邦图神经网络（VFGNN）在后门攻击方面的脆弱性，并提出相应的攻击方法。&lt;h4&gt;方法&lt;/h4&gt;提出了BVG，这是第一个针对VFGNN的后门攻击方法，采用多跳触发器，仅需四个目标类节点即可有效实施攻击。&lt;h4&gt;主要发现&lt;/h4&gt;BVG在三个数据集和三种不同的GNN模型上取得了高攻击成功率（ASR），对主要任务准确性（MTA）的影响最小。&lt;h4&gt;结论&lt;/h4&gt;评估了几种防御方法，进一步验证了BVG的稳健性和有效性，强调了在实际VFGNN应用中需要更先进的防御机制来应对复杂的后门攻击。&lt;h4&gt;总结&lt;/h4&gt;该研究揭示了VFGNN在安全性方面的潜在风险，并提出了有效的攻击策略，呼吁对防御措施的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Transformer (GT), as a special type of Graph Neural Networks (GNNs),utilizes multi-head attention to facilitate high-order message passing.However, this also imposes several limitations in node classificationapplications: 1) nodes are susceptible to global noise; 2) self-attentioncomputation cannot scale well to large graphs. In this work, we conductextensive observational experiments to explore the adaptability of the GTarchitecture in node classification tasks and draw several conclusions: thecurrent multi-head self-attention module in GT can be completely replaceable,while the feed-forward neural network module proves to be valuable. Based onthis, we decouple the propagation (P) and transformation (T) of GNNs andexplore a powerful GT architecture, named GNNFormer, which is based on the P/Tcombination message passing and adapted for node classification in bothhomophilous and heterophilous scenarios. Extensive experiments on 12 benchmarkdatasets demonstrate that our proposed GT architecture can effectively adapt tonode classification tasks without being affected by global noise andcomputational efficiency limitations.</description>
      <author>example@mail.com (Jiajun Zhou, Xuanze Chen, Chenxuan Xie, Yu Shanqing, Qi Xuan, Xiaoniu Yang)</author>
      <guid isPermaLink="false">2410.11189v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Backdoor Attack on Vertical Federated Graph Neural Network Learning</title>
      <link>http://arxiv.org/abs/2410.11290v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联邦图神经网络（FedGNN）是一种结合了联邦学习和图神经网络的隐私保护机器学习技术，旨在使用孤立的图数据进行训练。&lt;h4&gt;目的&lt;/h4&gt;探讨垂直联邦图神经网络（VFGNN）在后门攻击方面的脆弱性，并提出相应的攻击方法。&lt;h4&gt;方法&lt;/h4&gt;提出了BVG，这是第一个针对VFGNN的后门攻击方法，采用多跳触发器，仅需四个目标类节点即可有效实施攻击。&lt;h4&gt;主要发现&lt;/h4&gt;BVG在三个数据集和三种不同的GNN模型上取得了高攻击成功率（ASR），对主要任务准确性（MTA）的影响最小。&lt;h4&gt;结论&lt;/h4&gt;评估了几种防御方法，进一步验证了BVG的稳健性和有效性，强调了在实际VFGNN应用中需要更先进的防御机制来应对复杂的后门攻击。&lt;h4&gt;总结&lt;/h4&gt;该研究揭示了VFGNN在安全性方面的潜在风险，并提出了有效的攻击策略，呼吁对防御措施的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Graph Neural Network (FedGNN) is a privacy-preserving machinelearning technology that combines federated learning (FL) and graph neuralnetworks (GNNs). It offers a privacy-preserving solution for training GNNsusing isolated graph data. Vertical Federated Graph Neural Network (VFGNN) isan important branch of FedGNN, where data features and labels are distributedamong participants, and each participant has the same sample space. Due to thedifficulty of accessing and modifying distributed data and labels, thevulnerability of VFGNN to backdoor attacks remains largely unexplored. In thiscontext, we propose BVG, the first method for backdoor attacks in VFGNN.Without accessing or modifying labels, BVG uses multi-hop triggers and requiresonly four target class nodes for an effective backdoor attack. Experiments showthat BVG achieves high attack success rates (ASR) across three datasets andthree different GNN models, with minimal impact on main task accuracy (MTA). Wealso evaluate several defense methods, further validating the robustness andeffectiveness of BVG. This finding also highlights the need for advanceddefense mechanisms to counter sophisticated backdoor attacks in practical VFGNNapplications.</description>
      <author>example@mail.com (Jirui Yang, Peng Chen, Zhihui Lu, Ruijun Deng, Qiang Duan, Jianping Zeng)</author>
      <guid isPermaLink="false">2410.11290v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Automatic Navigation and Voice Cloning Technology Deployment on a Humanoid Robot</title>
      <link>http://arxiv.org/abs/2410.13612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;超声心动图是最广泛使用的心脏影像学方式，通过捕捉超声视频数据评估心脏结构和功能。&lt;h4&gt;目的&lt;/h4&gt;引入EchoPrime，一个多视图、视图知情的视频基础模型，以提高超声心动图的性能和应用范围。&lt;h4&gt;方法&lt;/h4&gt;EchoPrime在超过1200万对视频和报告的基础上进行训练，利用对比学习构建统一嵌入模型，并结合视图分类和解剖注意力模型。&lt;h4&gt;主要发现&lt;/h4&gt;EchoPrime在两个独立医疗系统的数据集上，在23个多样的心脏形态和功能基准测试中表现出色，超越了任务特定的方法和先前的基础模型。&lt;h4&gt;结论&lt;/h4&gt;经过严格的临床评估，EchoPrime能帮助医生自动化初步评估全面的超声心动图。&lt;h4&gt;总结&lt;/h4&gt;EchoPrime通过整合多视图信息，显著提升了超声心动图的解读精度和效率，有助于临床应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robots have shown immense potential and are expected to be widely usedin the service industry. The importance of automatic navigation and voicecloning cannot be overstated as they enable functional robots to providehigh-quality services. The objective of this work is to develop a controlalgorithm for the automatic navigation of a humanoid mobile robot called Cruzr,which is a service robot manufactured by Ubtech. Initially, a virtualenvironment is constructed in the simulation software Gazebo using SimultaneousLocalization And Mapping (SLAM), and global path planning is carried out bymeans of local path tracking. The two-wheel differential chassis kinematicsmodel is employed to ensure autonomous dynamic obstacle avoidance for the robotchassis. Furthermore, the mapping and trajectory generation algorithmsdeveloped in the simulation environment are successfully implemented on thereal robot Cruzr. The performance of automatic navigation is compared betweenthe Dynamic Window Approach (DWA) and Model Predictive Control (MPC)algorithms. Additionally, a mobile application for voice cloning is createdbased on a Hidden Markov Model, and the proposed Chatbot is also tested anddeployed on Cruzr.</description>
      <author>example@mail.com (Dongkun Han, Boyuan Shao)</author>
      <guid isPermaLink="false">2410.13612v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>EchoPrime: A Multi-Video View-Informed Vision-Language Model for Comprehensive Echocardiography Interpretation</title>
      <link>http://arxiv.org/abs/2410.09704v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 3 tables, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;超声心动图是最广泛使用的心脏影像学方式，通过捕捉超声视频数据评估心脏结构和功能。&lt;h4&gt;目的&lt;/h4&gt;引入EchoPrime，一个多视图、视图知情的视频基础模型，以提高超声心动图的性能和应用范围。&lt;h4&gt;方法&lt;/h4&gt;EchoPrime在超过1200万对视频和报告的基础上进行训练，利用对比学习构建统一嵌入模型，并结合视图分类和解剖注意力模型。&lt;h4&gt;主要发现&lt;/h4&gt;EchoPrime在两个独立医疗系统的数据集上，在23个多样的心脏形态和功能基准测试中表现出色，超越了任务特定的方法和先前的基础模型。&lt;h4&gt;结论&lt;/h4&gt;经过严格的临床评估，EchoPrime能帮助医生自动化初步评估全面的超声心动图。&lt;h4&gt;总结&lt;/h4&gt;EchoPrime通过整合多视图信息，显著提升了超声心动图的解读精度和效率，有助于临床应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/echonet/echoprime&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Echocardiography is the most widely used cardiac imaging modality, capturingultrasound video data to assess cardiac structure and function. Artificialintelligence (AI) in echocardiography has the potential to streamline manualtasks and improve reproducibility and precision. However, most echocardiographyAI models are single-view, single-task systems that do not synthesizecomplementary information from multiple views captured during a full exam, andthus lead to limited performance and scope of applications. To address thisproblem, we introduce EchoPrime, a multi-view, view-informed, video-basedvision-language foundation model trained on over 12 million video-report pairs.EchoPrime uses contrastive learning to train a unified embedding model for allstandard views in a comprehensive echocardiogram study with representation ofboth rare and common diseases and diagnoses. EchoPrime then utilizesview-classification and a view-informed anatomic attention model to weightvideo-specific interpretations that accurately maps the relationship betweenechocardiographic views and anatomical structures. With retrieval-augmentedinterpretation, EchoPrime integrates information from all echocardiogram videosin a comprehensive study and performs holistic comprehensive clinicalechocardiography interpretation. In datasets from two independent healthcaresystems, EchoPrime achieves state-of-the art performance on 23 diversebenchmarks of cardiac form and function, surpassing the performance of bothtask-specific approaches and prior foundation models. Following rigorousclinical evaluation, EchoPrime can assist physicians in the automatedpreliminary assessment of comprehensive echocardiography.</description>
      <author>example@mail.com (Milos Vukadinovic, Xiu Tang, Neal Yuan, Paul Cheng, Debiao Li, Susan Cheng, Bryan He, David Ouyang)</author>
      <guid isPermaLink="false">2410.09704v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>KA-GNN: Kolmogorov-Arnold Graph Neural Networks for Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2410.11323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;分子属性预测是人工智能驱动药物发现（AIDD）中的关键任务。&lt;h4&gt;目的&lt;/h4&gt;开发超越传统非神经网络方法的模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型图神经网络模型-Kolmogorov-Arnold网络（KAN）基础上的图神经网络（KA-GNN），结合傅里叶级数，专为分子属性预测设计。&lt;h4&gt;主要发现&lt;/h4&gt;KA-GNN在七个公共数据集上的测试和验证显示，其在属性预测方面显著优于现有的最先进基准。&lt;h4&gt;结论&lt;/h4&gt;KA-GNN具有KAN方法的高可解释性，并在计算资源使用上极为高效，适合在资源受限的环境中部署。&lt;h4&gt;总结&lt;/h4&gt;KA-GNN为分子属性预测提供了一种有效且可解释的解决方案，推动了药物发现领域的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular property prediction is a crucial task in the process of ArtificialIntelligence-Driven Drug Discovery (AIDD). The challenge of developing modelsthat surpass traditional non-neural network methods continues to be a vibrantarea of research. This paper presents a novel graph neural network model-theKolmogorov-Arnold Network (KAN)-based Graph Neural Network (KA-GNN), whichincorporates Fourier series, specifically designed for molecular propertyprediction. This model maintains the high interpretability characteristic ofKAN methods while being extremely efficient in computational resource usage,making it an ideal choice for deployment in resource-constrained environments.Tested and validated on seven public datasets, KA-GNN has shown significantimprovements in property predictions over the existing state-of-the-art (SOTA)benchmarks.</description>
      <author>example@mail.com (Longlong Li, Yipeng Zhang, Guanghui Wang, Kelin Xia)</author>
      <guid isPermaLink="false">2410.11323v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>t-READi: Transformer-Powered Robust and Efficient Multimodal Inference for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.09747v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 16 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着自主车辆广泛采用多模态传感器（如相机、激光雷达、雷达），融合其输出以实现稳健的感知变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出t-READi，一种自适应推理系统，以适应多模态传感器数据的变化，从而实现稳健和高效的感知。&lt;h4&gt;方法&lt;/h4&gt;t-READi识别对变化敏感但结构特定的模型参数，仅适应这些参数，同时保持其余参数不变，并利用跨模态对比学习方法弥补缺失模态造成的损失。&lt;h4&gt;主要发现&lt;/h4&gt;t-READi相较于现有方法，平均推理准确率提高超过6%，推理延迟减少近15倍，且在最坏情况下仅增加5%的内存开销。&lt;h4&gt;结论&lt;/h4&gt;t-READi能够有效应对多模态传感器数据的变化，提高感知性能，且兼容现有的多模态深度融合方法。&lt;h4&gt;总结&lt;/h4&gt;t-READi为自主车辆中的多模态感知提供了一种新颖的解决方案，能够显著提升准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given the wide adoption of multimodal sensors (e.g., camera, lidar, radar) byautonomous vehicles (AVs), deep analytics to fuse their outputs for a robustperception become imperative. However, existing fusion methods often make twoassumptions rarely holding in practice: i) similar data distributions for allinputs and ii) constant availability for all sensors. Because, for example,lidars have various resolutions and failures of radars may occur, suchvariability often results in significant performance degradation in fusion. Tothis end, we present tREADi, an adaptive inference system that accommodates thevariability of multimodal sensory data and thus enables robust and efficientperception. t-READi identifies variation-sensitive yet structure-specific modelparameters; it then adapts only these parameters while keeping the rest intact.t-READi also leverages a cross-modality contrastive learning method tocompensate for the loss from missing modalities. Both functions are implementedto maintain compatibility with existing multimodal deep fusion methods. Theextensive experiments evidently demonstrate that compared with the status quoapproaches, t-READi not only improves the average inference accuracy by morethan 6% but also reduces the inference latency by almost 15x with the cost ofonly 5% extra memory overhead in the worst case under realistic data and modalvariations.</description>
      <author>example@mail.com (Pengfei Hu, Yuhang Qian, Tianyue Zheng, Ang Li, Zhe Chen, Yue Gao, Xiuzhen Cheng, Jun Luo)</author>
      <guid isPermaLink="false">2410.09747v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Are High-Degree Representations Really Unnecessary in Equivariant Graph Neural Networks?</title>
      <link>http://arxiv.org/abs/2410.11443v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;引入了具有E(3)对称性的等变图神经网络（GNNs），在多个科学应用中取得了显著成功。&lt;h4&gt;目的&lt;/h4&gt;探讨等变GNN在对称结构上的表现力，质疑高阶表示的必要性。&lt;h4&gt;方法&lt;/h4&gt;通过理论证明，展示当输出表示的阶数固定为1或其他特定值时，等变GNN会退化为零函数；提出HEGNN，结合高阶可转动向量，保持EGNN的效率。&lt;h4&gt;主要发现&lt;/h4&gt;HEGNN在玩具数据集和复杂数据集（如N-body和MD17）上均表现出显著的改进，支持理论分析。&lt;h4&gt;结论&lt;/h4&gt;理论发现和实证结果为等变GNN的研究开辟了新的可能性。&lt;h4&gt;总结&lt;/h4&gt;研究表明高阶表示在等变GNN中是必要的，并提出了有效的HEGNN模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Equivariant Graph Neural Networks (GNNs) that incorporate E(3) symmetry haveachieved significant success in various scientific applications. As one of themost successful models, EGNN leverages a simple scalarization technique toperform equivariant message passing over only Cartesian vectors (i.e.,1st-degree steerable vectors), enjoying greater efficiency and efficacycompared to equivariant GNNs using higher-degree steerable vectors. Thissuccess suggests that higher-degree representations might be unnecessary. Inthis paper, we disprove this hypothesis by exploring the expressivity ofequivariant GNNs on symmetric structures, including $k$-fold rotations andregular polyhedra. We theoretically demonstrate that equivariant GNNs willalways degenerate to a zero function if the degree of the outputrepresentations is fixed to 1 or other specific values. Based on thistheoretical insight, we propose HEGNN, a high-degree version of EGNN toincrease the expressivity by incorporating high-degree steerable vectors whilemaintaining EGNN's efficiency through the scalarization trick. Our extensiveexperiments demonstrate that HEGNN not only aligns with our theoreticalanalyses on toy datasets consisting of symmetric structures, but also showssubstantial improvements on more complicated datasets such as $N$-body andMD17. Our theoretical findings and empirical results potentially open up newpossibilities for the research of equivariant GNNs.</description>
      <author>example@mail.com (Jiacheng Cen, Anyi Li, Ning Lin, Yuxiang Ren, Zihe Wang, Wenbing Huang)</author>
      <guid isPermaLink="false">2410.11443v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CoActionGraphRec: Sequential Multi-Interest Recommendations Using Co-Action Graphs</title>
      <link>http://arxiv.org/abs/2410.11464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;eBay等电商平台在开发商品推荐系统时面临独特的挑战，包括数据稀疏和用户兴趣多样性。&lt;h4&gt;目的&lt;/h4&gt;提出CoActionGraphRec (CAGR)模型，以应对数据稀疏性问题。&lt;h4&gt;方法&lt;/h4&gt;使用基于文本的双塔深度学习模型，包含商品塔和用户塔，利用共同行动图层来增强用户和商品的表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过图神经网络组件充分利用共同行动图，捕捉协同信号，并通过全连接图构建用户行为序列。&lt;h4&gt;结论&lt;/h4&gt;通过明确的交互模块学习行为交互的表示，实验结果显示该方法在关键指标上表现优于现有最先进方法。&lt;h4&gt;总结&lt;/h4&gt;CAGR模型有效地改善了eBay商品推荐系统的性能，克服了数据稀疏性带来的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; There are unique challenges to developing item recommender systems fore-commerce platforms like eBay due to sparse data and diverse user interests.While rich user-item interactions are important, eBay's data sparsity exceedsother e-commerce sites by an order of magnitude. To address this challenge, wepropose CoActionGraphRec (CAGR), a text based two-tower deep learning model(Item Tower and User Tower) utilizing co-action graph layers. In order toenhance user and item representations, a graph-based solution tailored toeBay's environment is utilized. For the Item Tower, we represent each itemusing its co-action items to capture collaborative signals in a co-action graphthat is fully leveraged by the graph neural network component. For the UserTower, we build a fully connected graph of each user's behavior sequence, withedges encoding pairwise relationships. Furthermore, an explicit interactionmodule learns representations capturing behavior interactions. Extensiveoffline and online A/B test experiments demonstrate the effectiveness of ourproposed approach and results show improved performance over state-of-the-artmethods on key metrics.</description>
      <author>example@mail.com (Yi Sun, Yuri M. Brovman)</author>
      <guid isPermaLink="false">2410.11464v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ViFi-ReID: A Two-Stream Vision-WiFi Multimodal Approach for Person Re-identification</title>
      <link>http://arxiv.org/abs/2410.09875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;行人重识别（ReID）是安全领域的重要技术，涉及安全检查、人员计数等应用。&lt;h4&gt;目的&lt;/h4&gt;解决当前ReID方法在服装变化和遮挡等客观条件下的局限性。&lt;h4&gt;方法&lt;/h4&gt;利用普遍可用的路由器，通过WiFi信号中的通道状态信息（CSI）捕捉行人的步态信息，构建多模态数据集，并采用双流网络分别处理视频理解和信号分析任务，进行多模态融合和对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;在真实场景中的广泛实验表明，所提方法有效揭示了异构数据之间的关联，弥补了视觉和信号模态之间的差距，显著扩展了感知范围，提高了多传感器下的ReID准确性。&lt;h4&gt;结论&lt;/h4&gt;结合WiFi信号和视频数据的方法在行人重识别中表现出色，提升了准确性和应用范围。&lt;h4&gt;总结&lt;/h4&gt;该研究为行人重识别提供了一种新的思路，通过多模态数据融合改善了现有技术的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Person re-identification(ReID), as a crucial technology in the field ofsecurity, plays a vital role in safety inspections, personnel counting, andmore. Most current ReID approaches primarily extract features from images,which are easily affected by objective conditions such as clothing changes andocclusions. In addition to cameras, we leverage widely available routers assensing devices by capturing gait information from pedestrians through theChannel State Information (CSI) in WiFi signals and contribute a multimodaldataset. We employ a two-stream network to separately process videounderstanding and signal analysis tasks, and conduct multi-modal fusion andcontrastive learning on pedestrian video and WiFi data. Extensive experimentsin real-world scenarios demonstrate that our method effectively uncovers thecorrelations between heterogeneous data, bridges the gap between visual andsignal modalities, significantly expands the sensing range, and improves ReIDaccuracy across multiple sensors.</description>
      <author>example@mail.com (Chen Mao, Chong Tan, Jingqi Hu, Min Zheng)</author>
      <guid isPermaLink="false">2410.09875v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Large-Scale 3D Medical Image Pre-training with Geometric Context Priors</title>
      <link>http://arxiv.org/abs/2410.09890v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CVPR 2024 Extension&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;医学图像分析中的标注稀缺性是一个重大挑战，尽管大规模预训练提供了一种有效的无标签解决方案，但在医学图像领域的应用仍然不足。&lt;h4&gt;目的&lt;/h4&gt;利用大规模无标签数据，学习高层语义，克服医学图像分析中的标注不足问题。&lt;h4&gt;方法&lt;/h4&gt;提出Volume Contrast (VoCo)框架，通过提取不同区域的基础裁剪，构建正负对进行对比学习，预测随机裁剪的上下文位置。&lt;h4&gt;主要发现&lt;/h4&gt;VoCo能够将固有的几何上下文编码到模型表示中，从而促进上下文编码到模型表示中，从而促进无标注条件下的高层语义学习。&lt;h4&gt;结论&lt;/h4&gt;引入了最大的医学预训练数据集PreCT-160K，探讨了模型规模的扩展规律，并建立了涵盖48个医学任务的基准，实验结果显示VoCo的优越性。&lt;h4&gt;总结&lt;/h4&gt;VoCo框架为医学图像分析提供了一种有效的无标注学习方法，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/luffy03/large-scale-medical&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The scarcity of annotations poses a significant challenge in medical imageanalysis. Large-scale pre-training has emerged as a promising label-efficientsolution, owing to the utilization of large-scale data, large models, andadvanced pre-training techniques. However, its development in medical imagesremains underexplored. The primary challenge lies in harnessing large-scaleunlabeled data and learning high-level semantics without annotations. Weobserve that 3D medical images exhibit consistent geometric context, i.e.,consistent geometric relations between different organs, which leads to apromising way for learning consistent representations. Motivated by this, weintroduce a simple-yet-effective Volume Contrast (VoCo) framework to leveragegeometric context priors for self-supervision. Given an input volume, weextract base crops from different regions to construct positive and negativepairs for contrastive learning. Then we predict the contextual position of arandom crop by contrasting its similarity to the base crops. In this way, VoCoencodes the inherent geometric context into model representations, facilitatinghigh-level semantic learning without annotations. Specifically, we (1)introduce the largest medical pre-training dataset PreCT-160K; (2) investigatescaling laws and propose guidelines for tailoring different model sizes tovarious medical tasks; (3) build a benchmark encompassing 48 medical tasks.Extensive experiments highlight the superiority of VoCo. Codes athttps://github.com/Luffy03/Large-Scale-Medical.</description>
      <author>example@mail.com (Linshan Wu, Jiaxin Zhuang, Hao Chen)</author>
      <guid isPermaLink="false">2410.09890v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Physics-informed neural networks for multi-field visualization with single-color laser induced fluorescence</title>
      <link>http://arxiv.org/abs/2410.07568v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从稀疏观测数据中重建场是一个不适定问题，广泛应用于工程和科学领域。&lt;h4&gt;目的&lt;/h4&gt;研究使用物理信息神经网络（PINNs）从稀疏且噪声较大的实验温度数据中重建完整的温度、速度和压力场。&lt;h4&gt;方法&lt;/h4&gt;在层流混合对流系统中应用PINNs，并探索迁移学习（TL）以显著减少场重建所需的时间。&lt;h4&gt;主要发现&lt;/h4&gt;PINNs有效消除不符合物理规律的大多数实验噪声。TL方法的误差在5%以内，同时计算时间减少了9.9倍。&lt;h4&gt;结论&lt;/h4&gt;使用非同时粒子图像测速（PIV）和有限体积法（FVM）验证PINN重建结果，重建的速度场与PIV结果相匹配，温度误差低于1%，压力和速度误差低于10%。&lt;h4&gt;总结&lt;/h4&gt;这项研究提供了使用PINNs解决不适定问题的可行性，并强调了TL在实现近实时场重建中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing fields from sparsely observed data is an ill-posed problemthat arises in many engineering and science applications. Here, we investigatethe use of physics-informed neural networks (PINNs) to reconstruct completetemperature, velocity and pressure fields from sparse and noisy experimentaltemperature data obtained through single-color laser-induced fluorescence(LIF). The PINNs are applied to the laminar mixed convection system, a complexbut fundamentally important phenomenon characterized by the simultaneouspresence of transient forced and natural convection behaviors. To enhancecomputation efficiency, this study also explores transfer learning (TL) as amean of significantly reducing the time required for field reconstruction. Ourfindings demonstrate that PINNs are effective, capable of eliminating mostexperimental noise that does not conform to governing physics laws.Additionally, we show that the TL method achieves errors within 5% compared tothe regular training scheme while reducing computation time by a factor of 9.9.We validate the PINN reconstruction results using non-simultaneous particleimage velocimetry (PIV) and finite volume method (FVM) simulations. Thereconstructed velocity fields from the PINN closely match those obtained fromPIV. When using FVM data as a reference, the average temperature errors arebelow 1%, while the pressure and velocity errors are below 10%. This researchprovides insights into the feasibility of using PINNs for solving ill-posedproblems with experimental data and highlights the potential of TL to enablenear real-time field reconstruction.</description>
      <author>example@mail.com (Nagahiro Ohashi, Leslie K. Hwang, Beomjin Kwon)</author>
      <guid isPermaLink="false">2410.07568v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ECGN: A Cluster-Aware Approach to Graph Neural Networks for Imbalanced Classification</title>
      <link>http://arxiv.org/abs/2410.11765v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图中节点分类是一个常见的问题，理想的分类器必须适应类分布的不平衡，并利用实际图的聚类结构的信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，解决现有图神经网络（GNN）未同时处理类不平衡和聚类结构的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了增强聚类感知图网络（ECGN），通过集成特定聚类的训练和合成节点生成，学习不同聚类的节点聚合。&lt;h4&gt;主要发现&lt;/h4&gt;ECGN通过生成新的少数类节点，帮助清晰化类间决策边界，结合聚类感知嵌入与全局集成步骤，提高节点嵌入质量。&lt;h4&gt;结论&lt;/h4&gt;ECGN在一些广泛研究的基准数据集上，表现超越最接近的竞争者，提升幅度可达11%。&lt;h4&gt;总结&lt;/h4&gt;ECGN是一种灵活的方法，适用于任何基础GNN和聚类生成技术，显著改善节点分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/anonymous753341/ecgn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classifying nodes in a graph is a common problem. The ideal classifier mustadapt to any imbalances in the class distribution. It must also use informationin the clustering structure of real-world graphs. Existing Graph NeuralNetworks (GNNs) have not addressed both problems together. We propose theEnhanced Cluster-aware Graph Network (ECGN), a novel method that addressesthese issues by integrating cluster-specific training with synthetic nodegeneration. Unlike traditional GNNs that apply the same node update process forall nodes, ECGN learns different aggregations for different clusters. We alsouse the clusters to generate new minority-class nodes in a way that helpsclarify the inter-class decision boundary. By combining cluster-awareembeddings with a global integration step, ECGN enhances the quality of theresulting node embeddings. Our method works with any underlying GNN and anycluster generation technique. Experimental results show that ECGN consistentlyoutperforms its closest competitors by up to 11% on some widely studiedbenchmark datasets.</description>
      <author>example@mail.com (Bishal Thapaliya, Anh Nguyen, Yao Lu, Tian Xie, Igor Grudetskyi, Fudong Lin, Antonios Valkanas, Jingyu Liu, Deepayan Chakraborty, Bilel Fehri)</author>
      <guid isPermaLink="false">2410.11765v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Robustness and Security Enhancement of Radio Frequency Fingerprint Identification in Time-Varying Channels</title>
      <link>http://arxiv.org/abs/2410.07591v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无线设备由于制造过程中的微小差异，具有独特的无线频率指纹（RFF），这使得无线频率指纹识别（RFFI）在物联网等受限功耗的应用中越来越受欢迎。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的抗干扰的无线频率指纹，并利用迁移学习技术来增强在时变信道中的RFFI效果。&lt;h4&gt;方法&lt;/h4&gt;通过实验验证提出的RFFI系统在室内和室外环境中的分类准确性，并分析其安全性及防范冒充攻击的措施。&lt;h4&gt;主要发现&lt;/h4&gt;该RFFI系统在室内环境中平均分类准确性提高了33.3%，在室外环境中提高了34.5%。&lt;h4&gt;结论&lt;/h4&gt;提出的无钥匙防御措施有效提升了攻击检测率，室内和室外环境中的接收者操作特征曲线（AUC）平均提高了0.3，攻击检测率提高了40.0%。&lt;h4&gt;安全性分析&lt;/h4&gt;分析了RFFI系统在非受控环境中可能遭遇的安全漏洞，尤其是冒充攻击的风险。&lt;h4&gt;总结&lt;/h4&gt;通过结合新的RFF和迁移学习，本文提出了一种有效的RFFI系统，并提出了相应的安全防护措施，具有良好的实际应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radio frequency fingerprint identification (RFFI) is becoming increasinglypopular, especially in applications with constrained power, such as theInternet of Things (IoT). Due to subtle manufacturing variations, wirelessdevices have unique radio frequency fingerprints (RFFs). These RFFs can be usedwith pattern recognition algorithms to classify wireless devices. However,Implementing reliable RFFI in time-varying channels is challenging because RFFsare often distorted by channel effects, reducing the classification accuracy.This paper introduces a new channel-robust RFF, and leverages transfer learningto enhance RFFI in the time-varying channels. Experimental results show thatthe proposed RFFI system achieved an average classification accuracyimprovement of 33.3 % in indoor environments and 34.5 % in outdoorenvironments. This paper also analyzes the security of the proposed RFFI systemto address the security flaw in formalized impersonation attacks. Since RFFcollection is being carried out in uncontrolled deployment environments, RFFIsystems can be targeted with false RFFs sent by rogue devices. The resultingclassifiers may classify the rogue devices as legitimate, effectively replacingtheir true identities. To defend against impersonation attacks, a novel keylesscountermeasure is proposed, which exploits the intrinsic output of the softmaxfunction after classifier training without sacrificing the lightweight natureof RFFI. Experimental results demonstrate an average increase of 0.3 in thearea under the receiver operating characteristic curve (AUC), with a 40.0 %improvement in attack detection rate in indoor and outdoor environments.</description>
      <author>example@mail.com (Lu Yang, Seyit Camtepe, Yansong Gao, Vicky Liu, Dhammika Jayalath)</author>
      <guid isPermaLink="false">2410.07591v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>StatioCL: Contrastive Learning for Time Series via Non-Stationary and Temporal Contrast</title>
      <link>http://arxiv.org/abs/2410.10048v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CIKM24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习（CL）在时间序列数据的表示学习中逐渐成为一种有前景的方法，通过将相似对紧密嵌入并使不相似对距离远离。&lt;h4&gt;目的&lt;/h4&gt;解决现有CL方法中引入的假负对（FNPs）问题，这些问题源于忽视内在特征和随机选择不同段作为不相似对，从而导致表示学习错误、模型性能降低和整体效率低下。&lt;h4&gt;方法&lt;/h4&gt;首次系统性地定义和分类时间序列中的FNPs，包括语义假负对和时间假负对。提出了StatioCL，一个新颖的CL框架，用于捕捉非平稳性和时间依赖性，以减轻FNPs并纠正学习表示的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;StatioCL通过解释和区分非平稳状态，有效捕捉语义特征并消除语义FNPs。同时，它基于时间依赖性建立细粒度相似性水平，以捕捉段之间的时间接近性，并减轻时间FNPs。&lt;h4&gt;结论&lt;/h4&gt;在真实世界基准时间序列分类数据集上的评估显示，StatioCL相较于现有最先进的CL方法有显著提升，实现了2.9%的召回率提高和19.2%的FNPs减少。此外，StatioCL在数据效率和对标签稀缺性的鲁棒性方面也表现更佳。&lt;h4&gt;总结&lt;/h4&gt;StatioCL为提高时间序列表示学习的效果提供了新的解决方案，展示了在处理假负对和提高模型性能方面的显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yvonneywu/statiocl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) has emerged as a promising approach forrepresentation learning in time series data by embedding similar pairs closelywhile distancing dissimilar ones. However, existing CL methods often introducefalse negative pairs (FNPs) by neglecting inherent characteristics and thenrandomly selecting distinct segments as dissimilar pairs, leading to erroneousrepresentation learning, reduced model performance, and overall inefficiency.To address these issues, we systematically define and categorize FNPs in timeseries into semantic false negative pairs and temporal false negative pairs forthe first time: the former arising from overlooking similarities in labelcategories, which correlates with similarities in non-stationarity and thelatter from neglecting temporal proximity. Moreover, we introduce StatioCL, anovel CL framework that captures non-stationarity and temporal dependency tomitigate both FNPs and rectify the inaccuracies in learned representations. Byinterpreting and differentiating non-stationary states, which reflect thecorrelation between trends or temporal dynamics with underlying data patterns,StatioCL effectively captures the semantic characteristics and eliminatessemantic FNPs. Simultaneously, StatioCL establishes fine-grained similaritylevels based on temporal dependencies to capture varying temporal proximitybetween segments and to mitigate temporal FNPs. Evaluated on real-worldbenchmark time series classification datasets, StatioCL demonstrates asubstantial improvement over state-of-the-art CL methods, achieving a 2.9%increase in Recall and a 19.2% reduction in FNPs. Most importantly, StatioCLalso shows enhanced data efficiency and robustness against label scarcity.</description>
      <author>example@mail.com (Yu Wu, Ting Dang, Dimitris Spathis, Hong Jia, Cecilia Mascolo)</author>
      <guid isPermaLink="false">2410.10048v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Towards Zero-Shot Camera Trap Image Categorization</title>
      <link>http://arxiv.org/abs/2410.12769v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文探讨相机捕捉图像的自动分类替代方法。&lt;h4&gt;目的&lt;/h4&gt;评估现有分类器的性能，并提出新的方法以减少特定位置的过拟合。&lt;h4&gt;方法&lt;/h4&gt;首先基准测试尖端分类器，随后结合MegaDetector与多个分类器及Segment Anything，最后测试基于大型语言模型的两种方法。&lt;h4&gt;主要发现&lt;/h4&gt;结合MegaDetector与两个独立分类器的组合在准确性上表现最佳，单一BEiTV2分类器的相对误差降低了约42%到75%。&lt;h4&gt;结论&lt;/h4&gt;在新的位置上，去除背景后准确度误差减半。基于DINOv2和FAISS的零-shot方法在图像分类中也取得了竞争性结果。&lt;h4&gt;总结&lt;/h4&gt;提出的零-shot管道显示了在相机捕捉图像分类中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes the search for an alternative approach to the automaticcategorization of camera trap images. First, we benchmark state-of-the-artclassifiers using a single model for all images. Next, we evaluate methodscombining MegaDetector with one or more classifiers and Segment Anything toassess their impact on reducing location-specific overfitting. Last, we proposeand test two approaches using large language and foundational models, such asDINOv2, BioCLIP, BLIP, and ChatGPT, in a zero-shot scenario. Evaluation carriedout on two publicly available datasets (WCT from New Zealand, CCT20 from theSouthwestern US) and a private dataset (CEF from Central Europe) revealed thatcombining MegaDetector with two separate classifiers achieves the highestaccuracy. This approach reduced the relative error of a single BEiTV2classifier by approximately 42\% on CCT20, 48\% on CEF, and 75\% on WCT.Besides, as the background is removed, the error in terms of accuracy in newlocations is reduced to half. The proposed zero-shot pipeline based on DINOv2and FAISS achieved competitive results (1.0\% and 4.7\% smaller on CCT20, andCEF, respectively), which highlights the potential of zero-shot approaches forcamera trap image categorization.</description>
      <author>example@mail.com (Jiří Vyskočil, Lukas Picek)</author>
      <guid isPermaLink="false">2410.12769v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Slide-based Graph Collaborative Training for Histopathology Whole Slide Image Analysis</title>
      <link>http://arxiv.org/abs/2410.10260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;计算病理学的发展认为肿瘤的病理特征对于癌症诊断具有重要指导意义。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的WSI（全切片图像）分析管道SlideGCD，以引入切片间的相关性，改善WSI建模。&lt;h4&gt;方法&lt;/h4&gt;SlideGCD可以适应现有的多实例学习（MIL）框架，通过引入癌症发展先验知识来改进切片表示的初始化和细化。&lt;h4&gt;主要发现&lt;/h4&gt;在四个不同任务（癌症亚型、癌症分期、生存预测和基因突变预测）中，与七个典型的SOTA WSI分析框架进行广泛比较和实验，验证了所提管道的有效性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;切片间的相关性引入能够增强WSI表示学习的效果，提升癌症诊断的准确性。&lt;h4&gt;总结&lt;/h4&gt;SlideGCD为WSI分析提供了新的思路，通过考虑切片间的相互关系，推动了计算病理学的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of computational pathology lies in the consensus thatpathological characteristics of tumors are significant guidance for cancerdiagnostics. Most existing research focuses on the inner-contextual informationwithin each WSI yet ignores the possible inter-correlations between slides. Asthe development of tumors is a continuous process involving a series ofhistological, morphological, and genetic changes that accumulate over time, thesimilarities and differences between WSIs across various stages, grades,locations and patients should potentially contribute to the representation ofWSIs and deserve to be taken into account in WSI modeling. To verify theadvancement of introducing the slide inter-correlations into the representationlearning of WSIs, we proposed a generic WSI analysis pipeline SlideGCD that canbe adapted to any existing Multiple Instance Learning (MIL) frameworks andimprove their performance. With the new paradigm, the prior knowledge of cancerdevelopment can participate in the end-to-end workflow, which concurrentlyinitializes and refines the slide representation, as a guide for messagepassing in the slide-based graph. Extensive comparisons and experiments areconducted to validate the effectiveness and robustness of the proposed pipelineacross 4 different tasks, including cancer subtyping, cancer staging, survivalprediction, and gene mutation prediction, with 7 representative SOTA WSIanalysis frameworks as backbones.</description>
      <author>example@mail.com (Jun Shi, Tong Shu, Zhiguo Jiang, Wei Wang, Haibo Wu, Yushan Zheng)</author>
      <guid isPermaLink="false">2410.10260v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.11782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型（LLM）基础的智能体在集体智能方面取得了显著进展，显示出集体智能的能力远超个体智能。&lt;h4&gt;目的&lt;/h4&gt;为了解决在选择最有效的多智能体通信拓扑时的困惑，提出G-Designer，旨在动态设计任务感知的定制通信拓扑。&lt;h4&gt;方法&lt;/h4&gt;G-Designer将多智能体系统建模为多智能体网络，利用变分图自编码器对智能体节点和任务特定虚拟节点进行编码，并解码出适应任务的高性能通信拓扑。&lt;h4&gt;主要发现&lt;/h4&gt;{'高性能': '在MMLU上取得84.50%的准确率，在HumanEval上以89.90%的通过率表现优异。', '任务适应性': '针对任务难度量身定制通信协议，在HumanEval上将令牌消耗减少了多达95.33%。', '对抗鲁棒性': '在面对智能体对抗攻击时，仅有0.3%的准确率下降。'}&lt;h4&gt;结论&lt;/h4&gt;G-Designer提供了一种自适应、高效且稳健的多智能体部署方案，能够显著提升任务执行效率。&lt;h4&gt;总结&lt;/h4&gt;G-Designer通过动态设计定制通信拓扑，有效解决了多智能体系统中的通信效率问题，展示了其在多个方面的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in large language model (LLM)-based agents havedemonstrated that collective intelligence can significantly surpass thecapabilities of individual agents, primarily due to well-crafted inter-agentcommunication topologies. Despite the diverse and high-performing designsavailable, practitioners often face confusion when selecting the most effectivepipeline for their specific task: \textit{Which topology is the best choice formy task, avoiding unnecessary communication token overhead while ensuringhigh-quality solution?} In response to this dilemma, we introduce G-Designer,an adaptive, efficient, and robust solution for multi-agent deployment, whichdynamically designs task-aware, customized communication topologies.Specifically, G-Designer models the multi-agent system as a multi-agentnetwork, leveraging a variational graph auto-encoder to encode both the nodes(agents) and a task-specific virtual node, and decodes a task-adaptive andhigh-performing communication topology. Extensive experiments on six benchmarksshowcase that G-Designer is: \textbf{(1) high-performing}, achieving superiorresults on MMLU with accuracy at $84.50\%$ and on HumanEval with pass@1 at$89.90\%$; \textbf{(2) task-adaptive}, architecting communication protocolstailored to task difficulty, reducing token consumption by up to $95.33\%$ onHumanEval; and \textbf{(3) adversarially robust}, defending against agentadversarial attacks with merely $0.3\%$ accuracy drop.</description>
      <author>example@mail.com (Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, Junfeng Fang, Kun Wang, Dawei Cheng)</author>
      <guid isPermaLink="false">2410.11782v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Data Validation Methods for Efficient Model Training</title>
      <link>http://arxiv.org/abs/2410.07880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前自然语言处理、语音合成、语音识别和视觉语言模型等先进模型依赖于大量数据，但低资源语言的数据通常无法获得。&lt;h4&gt;目的&lt;/h4&gt;研究改进低资源语言机器学习系统的挑战与潜在解决方案。&lt;h4&gt;方法&lt;/h4&gt;探讨“质量数据”的定义，开发适当数据生成方法，提高模型训练的可获取性，并对现有方法进行全面审查，包括数据增强、多语种迁移学习、合成数据生成和数据选择技术。&lt;h4&gt;主要发现&lt;/h4&gt;现有方法的进展与局限性，以及多个开放的研究问题，为未来研究提供了框架。&lt;h4&gt;结论&lt;/h4&gt;通过解决这些挑战，本文旨在使先进的机器学习模型对低资源语言更为可及，从而提高其在各个领域的实用性与影响力。&lt;h4&gt;总结&lt;/h4&gt;本文为低资源语言的机器学习模型优化提供了研究基础，强调了数据利用效率和模型性能的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the challenges and potential solutions for improvingmachine learning systems for low-resource languages. State-of-the-art models innatural language processing (NLP), text-to-speech (TTS), speech-to-text (STT),and vision-language models (VLM) rely heavily on large datasets, which areoften unavailable for low-resource languages. This research explores key areassuch as defining "quality data," developing methods for generating appropriatedata and enhancing accessibility to model training. A comprehensive review ofcurrent methodologies, including data augmentation, multilingual transferlearning, synthetic data generation, and data selection techniques, highlightsboth advancements and limitations. Several open research questions areidentified, providing a framework for future studies aimed at optimizing datautilization, reducing the required data quantity, and maintaining high-qualitymodel performance. By addressing these challenges, the paper aims to makeadvanced machine learning models more accessible for low-resource languages,enhancing their utility and impact across various sectors.</description>
      <author>example@mail.com (Yurii Paniv)</author>
      <guid isPermaLink="false">2410.07880v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Unified Representation of Genomic and Biomedical Concepts through Multi-Task, Multi-Source Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.10144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 2 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了一种名为GENomic Encoding REpresentation with Language Model (GENEREL)的框架，旨在连接遗传和生物医学知识库。&lt;h4&gt;目的&lt;/h4&gt;通过微调语言模型，融入与临床概念（如疾病和药物）相关的生物知识。&lt;h4&gt;方法&lt;/h4&gt;构建统一的嵌入空间，结合患者数据、生物医学知识图谱和GWAS摘要，以多任务对比学习对SNP和临床概念的嵌入进行对齐。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GENEREL能够有效捕捉SNP与临床概念之间的复杂关系，并识别相关性程度。&lt;h4&gt;结论&lt;/h4&gt;这一创新方法增强了对SNP和生物医学概念的统一嵌入系统的构建，提升了生物医学研究中的数据整合和发现潜力。&lt;h4&gt;总结&lt;/h4&gt;GENEREL为生物医学研究提供了一种新的视角，通过整合遗传和临床数据，推动了相关概念的识别与应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce GENomic Encoding REpresentation with Language Model (GENEREL), aframework designed to bridge genetic and biomedical knowledge bases. What setsGENEREL apart is its ability to fine-tune language models to infuse biologicalknowledge behind clinical concepts such as diseases and medications. Thisfine-tuning enables the model to capture complex biomedical relationships moreeffectively, enriching the understanding of how genomic data connects toclinical outcomes. By constructing a unified embedding space for biomedicalconcepts and a wide range of common SNPs from sources such as patient-leveldata, biomedical knowledge graphs, and GWAS summaries, GENEREL aligns theembeddings of SNPs and clinical concepts through multi-task contrastivelearning. This allows the model to adapt to diverse natural languagerepresentations of biomedical concepts while bypassing the limitations oftraditional code mapping systems across different data sources. Our experimentsdemonstrate GENEREL's ability to effectively capture the nuanced relationshipsbetween SNPs and clinical concepts. GENEREL also emerges to discern the degreeof relatedness, potentially allowing for a more refined identification ofconcepts. This pioneering approach in constructing a unified embedding systemfor both SNPs and biomedical concepts enhances the potential for dataintegration and discovery in biomedical research.</description>
      <author>example@mail.com (Hongyi Yuan, Suqi Liu, Kelly Cho, Katherine Liao, Alexandre Pereira, Tianxi Cai)</author>
      <guid isPermaLink="false">2410.10144v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>DEeR: Deviation Eliminating and Noise Regulating for Privacy-preserving Federated Low-rank Adaptation</title>
      <link>http://arxiv.org/abs/2410.12926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;低秩适应（LoRA）与联邦学习（FL）的结合在医学任务中受到广泛关注，旨在通过隐私保护的分散训练来适应预训练的基础模型（FMs）。&lt;h4&gt;目的&lt;/h4&gt;解决LoRA与FL直接结合产生的聚合偏差和差分隐私噪声放大效应问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的隐私保护联邦微调框架，称为DEeR。通过理论证明消除聚合偏差的必要条件是确保客户端的LoRA参数等价，并设计了一个偏差消除器利用交替最小化算法优化LoRA参数矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;分析噪声放大效应，发现该问题主要由差分隐私噪声与LoRA参数之间的线性关系引起。提出了噪声调节器，通过两个调节因子解耦DP与LoRA之间的关系。&lt;h4&gt;结论&lt;/h4&gt;DEeR在公共医学数据集上显示出优于现有先进方法的性能，提供了强大的隐私保护和出色的微调性能。&lt;h4&gt;总结&lt;/h4&gt;DEeR框架有效解决了聚合偏差和噪声放大问题，推动了LoRA与FL结合在医学领域的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cuhk-aim-group/deer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating low-rank adaptation (LoRA) with federated learning (FL) hasreceived widespread attention recently, aiming to adapt pretrained foundationmodels (FMs) to downstream medical tasks via privacy-preserving decentralizedtraining. However, owing to the direct combination of LoRA and FL, currentmethods generally undergo two problems, i.e., aggregation deviation, anddifferential privacy (DP) noise amplification effect. To address theseproblems, we propose a novel privacy-preserving federated finetuning frameworkcalled \underline{D}eviation \underline{E}liminating and Nois\underline{e}\underline{R}egulating (DEeR). Specifically, we firstly theoretically provethat the necessary condition to eliminate aggregation deviation is guaranteingthe equivalence between LoRA parameters of clients. Based on the theoreticalinsight, a deviation eliminator is designed to utilize alternating minimizationalgorithm to iteratively optimize the zero-initialized and non-zero-initializedparameter matrices of LoRA, ensuring that aggregation deviation always be zerosduring training. Furthermore, we also conduct an in-depth analysis of the noiseamplification effect and find that this problem is mainly caused by the``linear relationship'' between DP noise and LoRA parameters. To suppress thenoise amplification effect, we propose a noise regulator that exploits tworegulator factors to decouple relationship between DP and LoRA, therebyachieving robust privacy protection and excellent finetuning performance.Additionally, we perform comprehensive ablated experiments to verify theeffectiveness of the deviation eliminator and noise regulator. DEeR showsbetter performance on public medical datasets in comparison withstate-of-the-art approaches. The code is available athttps://github.com/CUHK-AIM-Group/DEeR.</description>
      <author>example@mail.com (Meilu Zhu, Axiu Mao, Jun Liu, Yixuan Yuan)</author>
      <guid isPermaLink="false">2410.12926v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>DiRW: Path-Aware Digraph Learning for Heterophily</title>
      <link>http://arxiv.org/abs/2410.10320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）作为强大的图结构数据表示学习工具，主要针对无向图，但忽略了有向图中的丰富信息。&lt;h4&gt;目的&lt;/h4&gt;解决有向图在实际应用中的挑战，尤其是拓扑异质性问题。&lt;h4&gt;方法&lt;/h4&gt;提出了有向随机游走（DiRW）策略，作为一种新型神经架构，优化了路径采样和节点特征聚合。&lt;h4&gt;主要发现&lt;/h4&gt;DiRW作为插件策略增强了大多数基于空间的方法，并在有向图学习中达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;DiRW提供了一种有效的学习范式，克服了现有方法的局限性。&lt;h4&gt;总结&lt;/h4&gt;通过实验证明，DiRW提升了有向图处理的效率和稳定性，适用于多个数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, graph neural network (GNN) has emerged as a powerful representationlearning tool for graph-structured data. However, most approaches are tailoredfor undirected graphs, neglecting the abundant information embedded in theedges of directed graphs (digraphs). In fact, digraphs are widely applied inthe real world (e.g., social networks and recommendations) and are alsoconfirmed to offer a new perspective for addressing topological heterophilychallenges (i.e., connected nodes have complex patterns of feature distributionor labels). Despite recent significant advancements in DiGNNs, existingspatial- and spectral-based methods have inherent limitations due to thecomplex learning mechanisms and reliance on high-quality topology, leading tolow efficiency and unstable performance. To address these issues, we proposeDirected Random Walk (DiRW), which can be viewed as a plug-and-play strategy oran innovative neural architecture that provides a guidance or new learningparadigm for most spatial-based methods or digraphs. Specifically, DiRWincorporates a direction-aware path sampler optimized from the perspectives ofwalk probability, length, and number in a weight-free manner by consideringnode profiles and topological structure. Building upon this, DiRW utilizes anode-wise learnable path aggregator for generalized messages obtained by ourproposed adaptive walkers to represent the current node. Extensive experimentson 9 datasets demonstrate that DiRW: (1) enhances most spatial-based methods asa plug-and-play strategy; (2) achieves SOTA performance as a new digraphlearning paradigm.</description>
      <author>example@mail.com (Daohan Su, Xunkai Li, Zhenjun Li, Yinping Liao, Rong-Hua Li, Guoren Wang)</author>
      <guid isPermaLink="false">2410.10320v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Regional Ocean Forecasting with Hierarchical Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.11807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 35 figures. Accepted to the Tackling Climate Change with
  Machine Learning workshop at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的海洋预报系统对理解海洋动态至关重要，这对环境管理和气候适应策略有重要影响。&lt;h4&gt;目的&lt;/h4&gt;介绍SeaCast，一个用于高分辨率、中期海洋预报的神经网络。&lt;h4&gt;方法&lt;/h4&gt;SeaCast采用基于图形的框架来处理复杂的海洋网格几何，并整合区域海洋背景下的外部强迫数据。&lt;h4&gt;主要发现&lt;/h4&gt;通过与地中海的操作数值模型和气象强迫数据的实验验证，证明了该方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;机器学习的进步为海洋预报提供了快速且节能的替代方案，SeaCast展示了其在中期海洋预报中的潜力。&lt;h4&gt;总结&lt;/h4&gt;SeaCast为海洋预报领域提供了创新的方法，并为环境管理和气候适应提供支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate ocean forecasting systems are vital for understanding marinedynamics, which play a crucial role in environmental management and climateadaptation strategies. Traditional numerical solvers, while effective, arecomputationally expensive and time-consuming. Recent advancements in machinelearning have revolutionized weather forecasting, offering fast andenergy-efficient alternatives. Building on these advancements, we introduceSeaCast, a neural network designed for high-resolution, medium-range oceanforecasting. SeaCast employs a graph-based framework to effectively handle thecomplex geometry of ocean grids and integrates external forcing data tailoredto the regional ocean context. Our approach is validated through experiments ata high spatial resolution using the operational numerical model of theMediterranean Sea provided by the Copernicus Marine Service, along with bothnumerical and data-driven atmospheric forcings.</description>
      <author>example@mail.com (Daniel Holmberg, Emanuela Clementi, Teemu Roos)</author>
      <guid isPermaLink="false">2410.11807v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CL3: A Collaborative Learning Framework for the Medical Data Ensuring Data Privacy in the Hyperconnected Environment</title>
      <link>http://arxiv.org/abs/2410.07900v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在超连接环境中，医疗机构在共享和传输敏感患者信息时，尤其关注数据隐私，以防数据泄露和恶意行为者的干扰。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过提出的协作学习框架CL3，检测COVID-19的胸部X光图像。&lt;h4&gt;方法&lt;/h4&gt;采用迁移学习作为起始全局模型，整合来自不同医疗机构的本地模型，并构建新的全局模型以适应本地模型中的数据漂移，同时考虑增量学习以便于对新医疗数据的持续适应。&lt;h4&gt;主要发现&lt;/h4&gt;CL3框架在经过六轮联邦通信后，使用Xception模型和批量大小为16时，达到了89.99%的全球准确率。&lt;h4&gt;结论&lt;/h4&gt;CL3框架有效地生成了高效、安全和可扩展的模型，同时维护了患者数据隐私，并确保了模型的及时更新。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了在保护数据隐私的前提下，通过协作学习提高COVID-19检测准确性的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zavidparvez/CL3-Collaborative-Approach&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In a hyperconnected environment, medical institutions are particularlyconcerned with data privacy when sharing and transmitting sensitive patientinformation due to the risk of data breaches, where malicious actors couldintercept sensitive information. A collaborative learning framework, includingtransfer, federated, and incremental learning, can generate efficient, secure,and scalable models while requiring less computation, maintaining patient dataprivacy, and ensuring an up-to-date model. This study aims to address thedetection of COVID-19 using chest X-ray images through a proposed collaborativelearning framework called CL3. Initially, transfer learning is employed,leveraging knowledge from a pre-trained model as the starting global model.Local models from different medical institutes are then integrated, and a newglobal model is constructed to adapt to any data drift observed in the localmodels. Additionally, incremental learning is considered, allowing continuousadaptation to new medical data without forgetting previously learnedinformation. Experimental results demonstrate that the CL3 framework achieved aglobal accuracy of 89.99% when using Xception with a batch size of 16 afterbeing trained for six federated communication rounds. A demo of the CL3framework is available athttps://github.com/zavidparvez/CL3-Collaborative-Approach to ensurereproducibility.</description>
      <author>example@mail.com (Mohamamd Zavid Parvez, Rafiqul Islam, Md Zahidul Islam)</author>
      <guid isPermaLink="false">2410.07900v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Eliminating the Language Bias for Visual Question Answering with fine-grained Causal Intervention</title>
      <link>http://arxiv.org/abs/2410.10184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管视觉问答（VQA）取得了显著进展，但文本信息引入的语言偏见问题仍未解决。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的因果干预训练方案CIBi，从更细粒度的角度消除语言偏见。&lt;h4&gt;方法&lt;/h4&gt;将语言偏见分为上下文偏见和关键词偏见，采用因果干预和对比学习消除上下文偏见，同时设计基于反事实生成的问答分支以消除关键词偏见。&lt;h4&gt;主要发现&lt;/h4&gt;CIBi适用于多种VQA模型，表现出竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;CIBi有效地从细粒度的视角解决了语言偏见问题，改善了多模态表示。&lt;h4&gt;总结&lt;/h4&gt;通过细化语言偏见的处理方法，CIBi为VQA领域提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/ICME57554.2024.10688155&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the remarkable advancements in Visual Question Answering (VQA), thechallenge of mitigating the language bias introduced by textual informationremains unresolved. Previous approaches capture language bias from acoarse-grained perspective. However, the finer-grained information within asentence, such as context and keywords, can result in different biases. Due tothe ignorance of fine-grained information, most existing methods fail tosufficiently capture language bias. In this paper, we propose a novel causalintervention training scheme named CIBi to eliminate language bias from afiner-grained perspective. Specifically, we divide the language bias intocontext bias and keyword bias. We employ causal intervention and contrastivelearning to eliminate context bias and improve the multi-modal representation.Additionally, we design a new question-only branch based on counterfactualgeneration to distill and eliminate keyword bias. Experimental resultsillustrate that CIBi is applicable to various VQA models, yielding competitiveperformance.</description>
      <author>example@mail.com (Ying Liu, Ge Bai, Chenji Lu, Shilong Li, Zhang Zhang, Ruifang Liu, Wenbin Guo)</author>
      <guid isPermaLink="false">2410.10184v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Multi-View Multi-Task Modeling with Speech Foundation Models for Speech Forensic Tasks</title>
      <link>http://arxiv.org/abs/2410.12947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;语音鉴定任务（SFTs）包括自动说话人识别、语音情感识别、性别识别和年龄估计，广泛应用于安全和生物特征识别领域。&lt;h4&gt;目的&lt;/h4&gt;解决当前为每个任务单独建模所带来的计算资源需求高、成本增加、时间消耗和维护挑战。&lt;h4&gt;方法&lt;/h4&gt;采用多任务学习策略，探索先进的语音基础模型（SFM），分析其在不同SFT任务中的表现，并提出多视角学习（MVL）和新框架TANGO。&lt;h4&gt;主要发现&lt;/h4&gt;在多任务学习框架中，将SFT建模在一起时，相较于单一任务模型表现有所下降，但通过MVL整合不同SFM的多样表示，可以提升共享学习过程的效果。&lt;h4&gt;结论&lt;/h4&gt;TANGO框架在基准数据集（如CREMA-D、emo-DB和BAVED）上表现优于单一SFM表示和基线融合技术。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了基于多任务学习和多视角学习的TANGO框架，有效提升了多个语音鉴定任务的整体性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech forensic tasks (SFTs), such as automatic speaker recognition (ASR),speech emotion recognition (SER), gender recognition (GR), and age estimation(AE), find use in different security and biometric applications. Previous workshave applied various techniques, with recent studies focusing on applyingspeech foundation models (SFMs) for improved performance. However, most priorefforts have centered on building individual models for each task separately,despite the inherent similarities among these tasks. This isolated approachresults in higher computational resource requirements, increased costs, timeconsumption, and maintenance challenges. In this study, we address thesechallenges by employing a multi-task learning strategy. Firstly, we explore thevarious state-of-the-art (SOTA) SFMs by extracting their representations forlearning these SFTs and investigating their effectiveness at each taskspecifically. Secondly, we analyze the performance of the extractedrepresentations on the SFTs in a multi-task learning framework. We observe adecline in performance when SFTs are modeled together compared to individualtask-specific models, and as a remedy, we propose multi-view learning (MVL).Views are representations from different SFMs transformed into distinctabstract spaces by characteristics unique to each SFM. By leveraging MVL, weintegrate these diverse representations to capture complementary informationacross tasks, enhancing the shared learning process. We introduce a newframework called TANGO (Task Alignment with iNter-view Gated Optimal transport)to implement this approach. With TANGO, we achieve the topmost performance incomparison to individual SFM representations as well as baseline fusiontechniques across benchmark datasets such as CREMA-D, emo-DB, and BAVED.</description>
      <author>example@mail.com (Orchid Chetia Phukan, Devyani Koshal, Swarup Ranjan Behera, Arun Balaji Buduru, Rajesh Sharma)</author>
      <guid isPermaLink="false">2410.12947v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>V2M: Visual 2-Dimensional Mamba for Image Representation Learning</title>
      <link>http://arxiv.org/abs/2410.10382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Mamba因其灵活设计和高效硬件性能而受到广泛关注，主要用于处理基于状态空间模型(SSM)的1D序列。&lt;h4&gt;目的&lt;/h4&gt;将Mamba应用于视觉领域，通过将2D图像展平为补丁并视为1D序列，解决原始图像的2D结构信息损失问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种视觉二维Mamba(V2M)模型，直接在2D空间处理图像标记，首先将SSM推广到二维空间，考虑两个相邻维度的状态。&lt;h4&gt;主要发现&lt;/h4&gt;V2M有效结合了2D局部性信息，同时继承了Mamba的高效性和依赖输入的可扩展性。&lt;h4&gt;结论&lt;/h4&gt;在ImageNet分类及COCO上的目标检测、实例分割和ADE20K的语义分割等下游视觉任务中，V2M相比其他视觉骨干网络表现出色。&lt;h4&gt;总结&lt;/h4&gt;V2M模型提供了一种完整的解决方案，改进了现有方法在处理2D图像时的信息损失问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wangck20/v2m&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mamba has garnered widespread attention due to its flexible design andefficient hardware performance to process 1D sequences based on the state spacemodel (SSM). Recent studies have attempted to apply Mamba to the visual domainby flattening 2D images into patches and then regarding them as a 1D sequence.To compensate for the 2D structure information loss (e.g., local similarity) ofthe original image, most existing methods focus on designing different ordersto sequentially process the tokens, which could only alleviate this issue tosome extent. In this paper, we propose a Visual 2-Dimensional Mamba (V2M) modelas a complete solution, which directly processes image tokens in the 2D space.We first generalize SSM to the 2-dimensional space which generates the nextstate considering two adjacent states on both dimensions (e.g., columns androws). We then construct our V2M based on the 2-dimensional SSM formulation andincorporate Mamba to achieve hardware-efficient parallel processing. Theproposed V2M effectively incorporates the 2D locality prior yet inherits theefficiency and input-dependent scalability of Mamba. Extensive experimentalresults on ImageNet classification and downstream visual tasks including objectdetection and instance segmentation on COCO and semantic segmentation on ADE20Kdemonstrate the effectiveness of our V2M compared with other visual backbones.</description>
      <author>example@mail.com (Chengkun Wang, Wenzhao Zheng, Yuanhui Huang, Jie Zhou, Jiwen Lu)</author>
      <guid isPermaLink="false">2410.10382v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting and Benchmarking Graph Autoencoders: A Contrastive Learning Perspective</title>
      <link>http://arxiv.org/abs/2410.10241v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图自编码器（GAEs）是一种自监督学习模型，能够通过从低维潜在空间重建输入图来学习图结构数据的有意义表示。&lt;h4&gt;目的&lt;/h4&gt;研究GAEs与对比学习之间的联系，推动图自监督学习的研究。&lt;h4&gt;方法&lt;/h4&gt;回顾之前研究中的GAEs，并展示如何将对比学习原则应用于GAEs。&lt;h4&gt;主要发现&lt;/h4&gt;引入了lrGAE（左-右GAE）框架，该框架利用对比学习原则，有效学习有意义的表示。&lt;h4&gt;结论&lt;/h4&gt;lrGAE不仅加深了对GAEs的理解，还在多种基于图的学习任务中设定了新的基准。&lt;h4&gt;代码链接&lt;/h4&gt;源代码及基线和结果复现代码可在https://github.com/EdisonLeeeee/lrGAE获得。&lt;h4&gt;总结&lt;/h4&gt;本研究建立了GAEs与对比学习之间的联系，并提出了一个新的GAE框架，为图自监督学习提供了新的视角和基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/edisonleeeee/lrgae&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph autoencoders (GAEs) are self-supervised learning models that can learnmeaningful representations of graph-structured data by reconstructing the inputgraph from a low-dimensional latent space. Over the past few years, GAEs havegained significant attention in academia and industry. In particular, therecent advent of GAEs with masked autoencoding schemes marks a significantadvancement in graph self-supervised learning research. While numerous GAEshave been proposed, the underlying mechanisms of GAEs are not well understood,and a comprehensive benchmark for GAEs is still lacking. In this work, webridge the gap between GAEs and contrastive learning by establishing conceptualand methodological connections. We revisit the GAEs studied in previous worksand demonstrate how contrastive learning principles can be applied to GAEs.Motivated by these insights, we introduce lrGAE (left-right GAE), a general andpowerful GAE framework that leverages contrastive learning principles to learnmeaningful representations. Our proposed lrGAE not only facilitates a deeperunderstanding of GAEs but also sets a new benchmark for GAEs across diversegraph-based learning tasks. The source code for lrGAE, including the baselinesand all the code for reproducing the results, is publicly available athttps://github.com/EdisonLeeeee/lrGAE.</description>
      <author>example@mail.com (Jintang Li, Ruofan Wu, Yuchang Zhu, Huizhe Zhang, Xinzhou Jin, Guibin Zhang, Zulun Zhu, Zibin Zheng, Liang Chen)</author>
      <guid isPermaLink="false">2410.10241v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Robust 3D Point Clouds Classification based on Declarative Defenders</title>
      <link>http://arxiv.org/abs/2410.09691v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预训练深度神经网络（DNN）被广泛认为是重要的知识产权，存在知识产权侵犯的风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以防止在未经授权的迁移学习场景中滥用学习知识。&lt;h4&gt;方法&lt;/h4&gt;提出非可转移修剪（NTP），通过模型修剪控制预训练DNN对未经授权数据域的转移性，并使用交替方向乘子法（ADMM）优化模型稀疏性和非可转移学习损失。&lt;h4&gt;主要发现&lt;/h4&gt;NTP在多种源和目标域对比中表现优异，平均样本学习曲线下的面积（SLC-AUC）为-0.54，表明使用NTP训练的模型不适合迁移学习到未经授权的目标域。&lt;h4&gt;结论&lt;/h4&gt;NTP在监督学习和自监督学习的背景下均得到验证，确认其在实际应用中的有效性。&lt;h4&gt;总结&lt;/h4&gt;NTP是一种创新的方法，通过控制模型的可转移性来保护知识产权，显著提升了非可转移学习的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/KaidongLi/pytorch-LatticePointClassifier&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud classification requires distinct models from 2D imageclassification due to the divergent characteristics of the respective inputdata. While 3D point clouds are unstructured and sparse, 2D images arestructured and dense. Bridging the domain gap between these two data types is anon-trivial challenge to enable model interchangeability. Recent research usingLattice Point Classifier (LPC) highlights the feasibility of cross-domainapplicability. However, the lattice projection operation in LPC generates 2Dimages with disconnected projected pixels. In this paper, we explore threedistinct algorithms for mapping 3D point clouds into 2D images. Throughextensive experiments, we thoroughly examine and analyze their performance anddefense mechanisms. Leveraging current large foundation models, we scrutinizethe feature disparities between regular 2D images and projected 2D images. Theproposed approaches demonstrate superior accuracy and robustness againstadversarial attacks. The generative model-based mapping algorithms yieldregular 2D images, further minimizing the domain gap from regular 2Dclassification tasks. The source code is available athttps://github.com/KaidongLi/pytorch-LatticePointClassifier.git.</description>
      <author>example@mail.com (Kaidong Li, Tianxiao Zhang, Chuncong Zhong, Ziming Zhang, Guanghui Wang)</author>
      <guid isPermaLink="false">2410.09691v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Non-transferable Pruning</title>
      <link>http://arxiv.org/abs/2410.08015v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in ECCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预训练深度神经网络（DNN）被广泛认为是重要的知识产权，存在知识产权侵犯的风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以防止在未经授权的迁移学习场景中滥用学习知识。&lt;h4&gt;方法&lt;/h4&gt;提出非可转移修剪（NTP），通过模型修剪控制预训练DNN对未经授权数据域的转移性，并使用交替方向乘子法（ADMM）优化模型稀疏性和非可转移学习损失。&lt;h4&gt;主要发现&lt;/h4&gt;NTP在多种源和目标域对比中表现优异，平均样本学习曲线下的面积（SLC-AUC）为-0.54，表明使用NTP训练的模型不适合迁移学习到未经授权的目标域。&lt;h4&gt;结论&lt;/h4&gt;NTP在监督学习和自监督学习的背景下均得到验证，确认其在实际应用中的有效性。&lt;h4&gt;总结&lt;/h4&gt;NTP是一种创新的方法，通过控制模型的可转移性来保护知识产权，显著提升了非可转移学习的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretrained Deep Neural Networks (DNNs), developed from extensive datasets tointegrate multifaceted knowledge, are increasingly recognized as valuableintellectual property (IP). To safeguard these models against IP infringement,strategies for ownership verification and usage authorization have emerged.Unlike most existing IP protection strategies that concentrate on restrictingdirect access to the model, our study addresses an extended DNN IP issue:applicability authorization, aiming to prevent the misuse of learned knowledge,particularly in unauthorized transfer learning scenarios. We proposeNon-Transferable Pruning (NTP), a novel IP protection method that leveragesmodel pruning to control a pretrained DNN's transferability to unauthorizeddata domains. Selective pruning can deliberately diminish a model's suitabilityon unauthorized domains, even with full fine-tuning. Specifically, ourframework employs the alternating direction method of multipliers (ADMM) foroptimizing both the model sparsity and an innovative non-transferable learningloss, augmented with Fisher space discriminative regularization, to constrainthe model's generalizability to the target dataset. We also propose a noveleffective metric to measure the model non-transferability: Area Under theSample-wise Learning Curve (SLC-AUC). This metric facilitates consideration offull fine-tuning across various sample sizes. Experimental results demonstratethat NTP significantly surpasses the state-of-the-art non-transferable learningmethods, with an average SLC-AUC at $-0.54$ across diverse pairs of source andtarget domains, indicating that models trained with NTP do not suit fortransfer learning to unauthorized target domains. The efficacy of NTP isvalidated in both supervised and self-supervised learning contexts, confirmingits applicability in real-world scenarios.</description>
      <author>example@mail.com (Ruyi Ding, Lili Su, Aidong Adam Ding, Yunsi Fei)</author>
      <guid isPermaLink="false">2410.08015v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Information propagation dynamics in Deep Graph Networks</title>
      <link>http://arxiv.org/abs/2410.10464v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图是一种高度表达的抽象，用于建模实体及其关系，如分子结构、社交网络和交通网络。&lt;h4&gt;目的&lt;/h4&gt;研究深图网络（DGN）中信息传播的动态性，解决静态和动态图中的有效信息传播模式学习问题。&lt;h4&gt;方法&lt;/h4&gt;将深图网络视为动态系统，提供理论和实证证据，展示所提架构在节点间传播和保留长期依赖关系的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的架构能够从不规则和稀疏采样的动态图中学习复杂的时空模式。&lt;h4&gt;结论&lt;/h4&gt;本论文全面探讨图、深度学习和动态系统之间的交叉，为图表示学习领域提供了洞察和进展，推动了更有效和多样化的基于图的学习模型的发展。&lt;h4&gt;总结&lt;/h4&gt;论文探讨了深图网络在静态和动态图中信息传播的动态性，强调了在图表示学习中的重要性和应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are a highly expressive abstraction for modeling entities and theirrelations, such as molecular structures, social networks, and traffic networks.Deep Graph Networks (DGNs) have emerged as a family of deep learning modelsthat can effectively process and learn such structured information. However,learning effective information propagation patterns within DGNs remains acritical challenge that heavily influences the model capabilities, both in thestatic domain and in the temporal domain (where features and/or topologyevolve). Given this challenge, this thesis investigates the dynamics ofinformation propagation within DGNs for static and dynamic graphs, focusing ontheir design as dynamical systems. Throughout this work, we provide theoreticaland empirical evidence to demonstrate the effectiveness of our proposedarchitectures in propagating and preserving long-term dependencies betweennodes, and in learning complex spatio-temporal patterns from irregular andsparsely sampled dynamic graphs. In summary, this thesis provides acomprehensive exploration of the intersection between graphs, deep learning,and dynamical systems, offering insights and advancements for the field ofgraph representation learning and paving the way for more effective andversatile graph-based learning models.</description>
      <author>example@mail.com (Alessio Gravina)</author>
      <guid isPermaLink="false">2410.10464v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>What Do Speech Foundation Models Not Learn About Speech?</title>
      <link>http://arxiv.org/abs/2410.12948v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 Pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;理解语音基础模型如何捕捉非语言线索对提高其可解释性和适应性至关重要。&lt;h4&gt;目的&lt;/h4&gt;分析多个知名模型（如Whisper、Seamless、Wav2Vec、HuBERT和Qwen2-Audio）在动态SUPERB基准测试中对语言和非语言任务的学习表现。&lt;h4&gt;方法&lt;/h4&gt;评估模型在零样本情境下的表现，并对从这些模型中提取的层级特征进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;一些模型在零样本设置中表现良好，且零样本性能与更好的学习表示相关。层级特征分析表明，某些模型的学习表示的可分离性与模型深度之间存在凸关系，不同层捕获特定任务的特征。&lt;h4&gt;结论&lt;/h4&gt;这些模型在多种任务上表现出色，即使未经过专门训练，且它们的表示可以有效适应下游任务。&lt;h4&gt;总结&lt;/h4&gt;研究揭示了模型的泛化能力、层级表示特征及适应下游任务所需的转变程度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding how speech foundation models capture non-verbal cues is crucialfor improving their interpretability and adaptability across diverse tasks. Inour work, we analyze several prominent models such as Whisper, Seamless,Wav2Vec, HuBERT, and Qwen2-Audio focusing on their learned representations inboth paralinguistic and non-paralinguistic tasks from the Dynamic-SUPERBbenchmark. Our study addresses three key questions: (1) What non-verbal cues(e.g., speaker intent, emotion, environmental context) are captured? (2) Howare these cues represented across different layers of the models? and (3) Towhat extent can these representations be effectively adapted to downstreamtasks? To answer these questions, we first evaluate the models in a zero-shotsetting, followed by fine-tuning on layer-wise features extracted from thesemodels. Our results provide insights into the models' capacity forgeneralization, the characteristics of their layer-wise representations, andthe degree of transformation required for downstream task adaptation. Ourfindings suggest that some of these models perform well on various tasks inzero-shot settings, despite not being explicitly trained for those tasks. Wealso observe that zero-shot performance correlates with better-learnedrepresentations. The analysis of layer-wise features demonstrates that somemodels exhibit a convex relationship between the separability of the learnedrepresentations and model depth, with different layers capturing task-specificfeatures.</description>
      <author>example@mail.com (Abdul Waheed, Hanin Atwany, Bhiksha Raj, Rita Singh)</author>
      <guid isPermaLink="false">2410.12948v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Model Predictive Control for Optimal Motion Planning of Unmanned Aerial Vehicles</title>
      <link>http://arxiv.org/abs/2410.09799v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In proceedings of 2024, the 7th International Conference on Control,
  Robotics and Informatics (ICCRI 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无人机（UAV）导航需要适应障碍物和不同的操作环境结构。&lt;h4&gt;目的&lt;/h4&gt;提出一种在未知复杂环境中操作的无人机的最优运动规划器。&lt;h4&gt;方法&lt;/h4&gt;运动规划器接收来自局部范围传感器的点云数据，并将其转换为表示周围环境的体素网格，根据体素网格生成引导无人机到达目标的局部轨迹，并使用模型预测控制（MPC）进行进一步优化。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进的方法进行比较，结果显示本方法提供了更短、更平滑的轨迹，更快且更稳定的速度轮廓。&lt;h4&gt;结论&lt;/h4&gt;该方法在能量效率方面表现良好，适合各种无人机应用。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的运动规划器能够有效提升无人机在复杂环境中的导航能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motion planning is an essential process for the navigation of unmanned aerialvehicles (UAVs) where they need to adapt to obstacles and different structuresof their operating environment to reach the goal. This paper presents anoptimal motion planner for UAVs operating in unknown complex environments. Themotion planner receives point cloud data from a local range sensor and thenconverts it into a voxel grid representing the surrounding environment. A localtrajectory guiding the UAV to the goal is then generated based on the voxelgrid. This trajectory is further optimized using model predictive control (MPC)to enhance the safety, speed, and smoothness of UAV operation. The optimizationis carried out via the definition of several cost functions and constraints,taking into account the UAV's dynamics and requirements. A number ofsimulations and comparisons with a state-of-the-art method have been conductedin a complex environment with many obstacles to evaluate the performance of ourmethod. The results show that our method provides not only shorter and smoothertrajectories but also faster and more stable speed profiles. It is also energyefficient making it suitable for various UAV applications.</description>
      <author>example@mail.com (Duy-Nam Bui, Thu Hang Khuat, Manh Duong Phung, Thuan-Hoang Tran, Dong LT Tran)</author>
      <guid isPermaLink="false">2410.09799v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Features are fate: a theory of transfer learning in high-dimensional regression</title>
      <link>http://arxiv.org/abs/2410.08194v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着大规模预训练神经网络的出现，适应数据有限的下游任务的方法变得非常必要。&lt;h4&gt;目的&lt;/h4&gt;探讨任务相似性对迁移学习成功的影响，并建立理论理解。&lt;h4&gt;方法&lt;/h4&gt;采用特征中心的观点，研究深度线性网络作为迁移学习的最小模型，分析目标数据集大小和特征空间重叠的影响。&lt;h4&gt;主要发现&lt;/h4&gt;当目标任务的特征空间与源任务重叠足够强时，线性迁移和微调都能显著提高性能，尤其是在数据有限的情况下。&lt;h4&gt;结论&lt;/h4&gt;特征学习动态的深入理解表明，线性结果也适用于非线性网络，强调了特征空间重叠的重要性。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了迁移学习中任务相似性的新理论视角，强调特征空间重叠对性能提升的关键作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the emergence of large-scale pre-trained neural networks, methods toadapt such "foundation" models to data-limited downstream tasks have become anecessity. Fine-tuning, preference optimization, and transfer learning have allbeen successfully employed for these purposes when the target task closelyresembles the source task, but a precise theoretical understanding of "tasksimilarity" is still lacking. While conventional wisdom suggests that simplemeasures of similarity between source and target distributions, such as$\phi$-divergences or integral probability metrics, can directly predict thesuccess of transfer, we prove the surprising fact that, in general, this is notthe case. We adopt, instead, a feature-centric viewpoint on transfer learningand establish a number of theoretical results that demonstrate that when thetarget task is well represented by the feature space of the pre-trained model,transfer learning outperforms training from scratch. We study deep linearnetworks as a minimal model of transfer learning in which we can analyticallycharacterize the transferability phase diagram as a function of the targetdataset size and the feature space overlap. For this model, we establishrigorously that when the feature space overlap between the source and targettasks is sufficiently strong, both linear transfer and fine-tuning improveperformance, especially in the low data limit. These results build on anemerging understanding of feature learning dynamics in deep linear networks,and we demonstrate numerically that the rigorous results we derive for thelinear case also apply to nonlinear networks.</description>
      <author>example@mail.com (Javan Tahir, Surya Ganguli, Grant M. Rotskoff)</author>
      <guid isPermaLink="false">2410.08194v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Long-Tailed Backdoor Attack Using Dynamic Data Augmentation Operations</title>
      <link>http://arxiv.org/abs/2410.12955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;后门攻击已成为深度神经网络日益严重的安全威胁，吸引了研究人员的关注。&lt;h4&gt;目的&lt;/h4&gt;探讨在长尾分布数据集上的后门攻击。&lt;h4&gt;方法&lt;/h4&gt;分析数据不平衡对后门攻击的影响，并提出一种名为动态数据增强操作（D$^2$AO）的有效后门攻击方法。&lt;h4&gt;主要发现&lt;/h4&gt;D$^2$AO选择器根据类别、样本类型（干净样本与后门样本）和样本特征共同选择操作，同时开发触发器生成器生成样本特定的触发器。&lt;h4&gt;结论&lt;/h4&gt;通过对后门模型和触发器生成器的联合优化，利用动态数据增强操作选择器，显著提高了攻击性能，同时保持了干净样本的准确性。&lt;h4&gt;总结&lt;/h4&gt;该研究首次探讨了长尾分布数据集上的后门攻击，提出的D$^2$AO方法在攻击性能和准确性方面均取得了显著进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, backdoor attack has become an increasing security threat to deepneural networks and drawn the attention of researchers. Backdoor attacksexploit vulnerabilities in third-party pretrained models during the trainingphase, enabling them to behave normally for clean samples and mispredict forsamples with specific triggers. Existing backdoor attacks mainly focus onbalanced datasets. However, real-world datasets often follow long-taileddistributions. In this paper, for the first time, we explore backdoor attack onsuch datasets. Specifically, we first analyze the influence of data imbalanceon backdoor attack. Based on our analysis, we propose an effective backdoorattack named Dynamic Data Augmentation Operation (D$^2$AO). We design D$^2$AOselectors to select operations depending jointly on the class, sample type(clean vs. backdoored) and sample features. Meanwhile, we develop a triggergenerator to generate sample-specific triggers. Through simultaneousoptimization of the backdoored model and trigger generator, guided by dynamicdata augmentation operation selectors, we achieve significant advancements.Extensive experiments demonstrate that our method can achieve thestate-of-the-art attack performance while preserving the clean accuracy.</description>
      <author>example@mail.com (Lu Pang, Tao Sun, Weimin Lyu, Haibin Ling, Chao Chen)</author>
      <guid isPermaLink="false">2410.12955v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Affinity-Graph-Guided Contractive Learning for Pretext-Free Medical Image Segmentation with Minimal Annotation</title>
      <link>http://arxiv.org/abs/2410.10366v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  BIBM 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;半监督学习和对比学习在医疗图像分割中取得了一定成功，但常常依赖于缺乏特定性的前置任务，并面临由于标注不足而导致的过拟合问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种亲和图引导的半监督对比学习框架（Semi-AGCL），以在最小标注下实现医疗图像分割，无需前置任务。&lt;h4&gt;方法&lt;/h4&gt;设计了一种基于平均补丁熵的补丁间采样方法，提供稳健的初始特征空间，并设计了亲和图引导的损失函数，利用数据的固有结构来提高学习表示的质量和模型的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在仅使用10%完整标注集的情况下，模型的准确性接近完全标注基线，偏差仅为2.52%；在仅使用5%标注时，性能显著提升，超过第二最佳基线23.09%，在CRAG和ACDC数据集上改善26.57%。&lt;h4&gt;结论&lt;/h4&gt;该框架有效降低了对标注的依赖，提高了医疗图像分割的准确性，展示了其在标注极少情况下的强大性能。&lt;h4&gt;总结&lt;/h4&gt;通过引入亲和图和创新的采样及损失函数，Semi-AGCL框架在医疗图像分割中取得了显著成果，表明其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The combination of semi-supervised learning (SemiSL) and contrastive learning(CL) has been successful in medical image segmentation with limitedannotations. However, these works often rely on pretext tasks that lack thespecificity required for pixel-level segmentation, and still face overfittingissues due to insufficient supervision signals resulting from too fewannotations. Therefore, this paper proposes an affinity-graph-guidedsemi-supervised contrastive learning framework (Semi-AGCL) by establishingadditional affinity-graph-based supervision signals between the student andteacher network, to achieve medical image segmentation with minimal annotationswithout pretext. The framework first designs an average-patch-entropy-driveninter-patch sampling method, which can provide a robust initial feature spacewithout relying on pretext tasks. Furthermore, the framework designs anaffinity-graph-guided loss function, which can improve the quality of thelearned representation and the model generalization ability by exploiting theinherent structure of the data, thus mitigating overfitting. Our experimentsindicate that with merely 10% of the complete annotation set, our modelapproaches the accuracy of the fully annotated baseline, manifesting a marginaldeviation of only 2.52%. Under the stringent conditions where only 5% of theannotations are employed, our model exhibits a significant enhancement inperformance surpassing the second best baseline by 23.09% on the dice metricand achieving an improvement of 26.57% on the notably arduous CRAG and ACDCdatasets.</description>
      <author>example@mail.com (Zehua Cheng, Di Yuan, Thomas Lukasiewicz)</author>
      <guid isPermaLink="false">2410.10366v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Novelty Detection Based on Latent Representations of a General Feature Extractor</title>
      <link>http://arxiv.org/abs/2410.09861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种有效的无监督3D点云新颖性检测方法。&lt;h4&gt;目的&lt;/h4&gt;利用通用的点云特征提取器和一类分类器进行新颖性检测。&lt;h4&gt;方法&lt;/h4&gt;通用特征提取器由图形自编码器构成，首次在与正常/异常类别无关的点云数据集上训练。将输入点云转换为潜在向量后，进行一类分类。&lt;h4&gt;主要发现&lt;/h4&gt;相较于现有方法测量3D坐标空间的重建误差，本方法利用浓缩形状信息的潜在表示，允许更直接有效的新颖性检测。&lt;h4&gt;结论&lt;/h4&gt;通用特征提取器能够提取未见类别的形状特征，避免了自编码器的重新训练，降低了计算负担。&lt;h4&gt;实验验证&lt;/h4&gt;通过在多个ShapeNet数据集子集上的实验验证了方法的性能，结果显示基于潜在表示的方法优于现有方法。&lt;h4&gt;总结&lt;/h4&gt;提出的方法在无监督3D点云新颖性检测中表现良好，具有较低的计算复杂度和更高的检测效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose an effective unsupervised 3D point cloud novelty detectionapproach, leveraging a general point cloud feature extractor and a one-classclassifier. The general feature extractor consists of a graph-based autoencoderand is trained once on a point cloud dataset such as a mathematically generatedfractal 3D point cloud dataset that is independent of normal/abnormalcategories. The input point clouds are first converted into latent vectors bythe general feature extractor, and then one-class classification is performedon the latent vectors. Compared to existing methods measuring thereconstruction error in 3D coordinate space, our approach utilizes latentrepresentations where the shape information is condensed, which allows moredirect and effective novelty detection. We confirm that our general featureextractor can extract shape features of unseen categories, eliminating the needfor autoencoder re-training and reducing the computational burden. We validatethe performance of our method through experiments on several subsets of theShapeNet dataset and demonstrate that our latent-based approach outperforms theexisting methods.</description>
      <author>example@mail.com (Shizuka Akahori, Satoshi Iizuka, Ken Mawatari, Kazuhiro Fukui)</author>
      <guid isPermaLink="false">2410.09861v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Transfer Learning Empowered Temporal Graph Networks for Cross-City Real Estate Appraisal</title>
      <link>http://arxiv.org/abs/2410.08947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;房地产评估对房地产交易、投资分析和房地产税收等活动至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出Meta-Transfer学习增强的时间图网络（MetaTransfer），以从数据丰富的大城市向数据稀缺的小城市转移知识，提升评估性能。&lt;h4&gt;方法&lt;/h4&gt;通过将日益增长的房地产交易与相关住宅社区建模为时间事件异构图，设计事件触发的时间图网络，模拟不断变化的房地产交易之间的不规则时空关系。将城市范围内的房地产评估视为多任务动态图链接标签预测问题，提出基于超网络的多任务学习模块以促进社区之间的知识共享。&lt;h4&gt;主要发现&lt;/h4&gt;基于五个真实世界数据集的广泛实验表明，MetaTransfer在性能上显著优于十一种基线算法。&lt;h4&gt;结论&lt;/h4&gt;MetaTransfer通过自适应重加权来自多个源城市的训练交易实例，有效缓解负迁移，提高跨城市知识转移的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新颖的框架，利用深度学习技术改善数据稀缺城市的房地产评估，显示出良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real estate appraisal is important for a variety of endeavors such as realestate deals, investment analysis, and real property taxation. Recently, deeplearning has shown great promise for real estate appraisal by harnessingsubstantial online transaction data from web platforms. Nonetheless, deeplearning is data-hungry, and thus it may not be trivially applicable toenormous small cities with limited data. To this end, we propose Meta-TransferLearning Empowered Temporal Graph Networks (MetaTransfer) to transfer valuableknowledge from multiple data-rich metropolises to the data-scarce city toimprove valuation performance. Specifically, by modeling the ever-growing realestate transactions with associated residential communities as a temporal eventheterogeneous graph, we first design an Event-Triggered Temporal Graph Networkto model the irregular spatiotemporal correlations between evolving real estatetransactions. Besides, we formulate the city-wide real estate appraisal as amulti-task dynamic graph link label prediction problem, where the valuation ofeach community in a city is regarded as an individual task. AHypernetwork-Based Multi-Task Learning module is proposed to simultaneouslyfacilitate intra-city knowledge sharing between multiple communities andtask-specific parameters generation to accommodate the community-wise realestate price distribution. Furthermore, we propose a Tri-Level OptimizationBased Meta- Learning framework to adaptively re-weight training transactioninstances from multiple source cities to mitigate negative transfer, and thusimprove the cross-city knowledge transfer effectiveness. Finally, extensiveexperiments based on five real-world datasets demonstrate the significantsuperiority of MetaTransfer compared with eleven baseline algorithms.</description>
      <author>example@mail.com (Weijia Zhang, Jindong Han, Hao Liu, Wei Fan, Hao Wang, Hui Xiong)</author>
      <guid isPermaLink="false">2410.08947v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Configurable Embodied Data Generation for Class-Agnostic RGB-D Video Segmentation</title>
      <link>http://arxiv.org/abs/2410.12995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in IEEE Robotics and Automation Letters October 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;该论文探讨了如何生成大规模数据集，以改善跨不同形态机器人的类无关视频分割。&lt;h4&gt;目的&lt;/h4&gt;研究视频分割模型是否在考虑机器人实体特征的情况下，从通用分割数据中获得更好的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一条管道，利用3D重建（例如HM3DSem）生成可配置的分割视频，依据机器人的实体特征（如传感器类型、放置和光照源）进行定制。&lt;h4&gt;主要发现&lt;/h4&gt;引入了一个大规模的RGB-D视频全景分割数据集（MVPd），用于基础和视频分割模型的广泛基准测试，并支持针对实体特征的视频分割研究。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，使用MVPd进行微调可以改善将基础模型迁移到某些机器人实体（如特定摄像机位置）的性能，同时使用3D模态（深度图像和摄像机姿态）也能提升视频分割的准确性和一致性。&lt;h4&gt;总结&lt;/h4&gt;通过考虑机器人实体特征，生成定制数据集能够有效提升视频分割模型的性能，尤其是在特定机器人平台上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a method for generating large-scale datasets to improveclass-agnostic video segmentation across robots with different form factors.Specifically, we consider the question of whether video segmentation modelstrained on generic segmentation data could be more effective for particularrobot platforms if robot embodiment is factored into the data generationprocess. To answer this question, a pipeline is formulated for using 3Dreconstructions (e.g. from HM3DSem) to generate segmented videos that areconfigurable based on a robot's embodiment (e.g. sensor type, sensor placement,and illumination source). A resulting massive RGB-D video panoptic segmentationdataset (MVPd) is introduced for extensive benchmarking with foundation andvideo segmentation models, as well as to support embodiment-focused research invideo segmentation. Our experimental findings demonstrate that using MVPd forfinetuning can lead to performance improvements when transferring foundationmodels to certain robot embodiments, such as specific camera placements. Theseexperiments also show that using 3D modalities (depth images and camera pose)can lead to improvements in video segmentation accuracy and consistency. Theproject webpage is available at https://topipari.com/projects/MVPd</description>
      <author>example@mail.com (Anthony Opipari, Aravindhan K Krishnan, Shreekant Gayaka, Min Sun, Cheng-Hao Kuo, Arnie Sen, Odest Chadwicke Jenkins)</author>
      <guid isPermaLink="false">2410.12995v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing JEPAs with Spatial Conditioning: Robust and Efficient Representation Learning</title>
      <link>http://arxiv.org/abs/2410.10773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Workshop on Self-Supervised Learning - Theory and
  Practice. Comments welcome!&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;IJEPA（基于图像的联合嵌入预测架构）为使用掩码图像建模框架的表示学习提供了一种吸引人的替代方案。&lt;h4&gt;目的&lt;/h4&gt;通过在潜在空间中进行预测，捕捉有用的语义信息，以提高表示能力。&lt;h4&gt;方法&lt;/h4&gt;通过对上下文和目标窗口的位置进行条件化，改进IJEPA的编码器模块，以避免表示崩溃。&lt;h4&gt;主要发现&lt;/h4&gt;条件编码器在多个图像分类基准数据集上表现出性能提升，并在上下文窗口大小和预训练样本效率上表现出更强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;引入条件编码器有效改善了IJEPA的表现，提升了模型在不同情况中的预测能力。&lt;h4&gt;总结&lt;/h4&gt;IJEPA通过空间信息的条件化处理，显著提高了图像表示学习的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image-based Joint-Embedding Predictive Architecture (IJEPA) offers anattractive alternative to Masked Autoencoder (MAE) for representation learningusing the Masked Image Modeling framework. IJEPA drives representations tocapture useful semantic information by predicting in latent rather than inputspace. However, IJEPA relies on carefully designed context and target windowsto avoid representational collapse. The encoder modules in IJEPA cannotadaptively modulate the type of predicted and/or target features based on thefeasibility of the masked prediction task as they are not given sufficientinformation of both context and targets. Based on the intuition that in naturalimages, information has a strong spatial bias with spatially local regionsbeing highly predictive of one another compared to distant ones. We conditionthe target encoder and context encoder modules in IJEPA with positions ofcontext and target windows respectively. Our "conditional" encoders showperformance gains on several image classification benchmark datasets, improvedrobustness to context window size and sample-efficiency during pretraining.</description>
      <author>example@mail.com (Etai Littwin, Vimal Thilak, Anand Gopalakrishnan)</author>
      <guid isPermaLink="false">2410.10773v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Hey AI Can You Grade My Essay?: Automatic Essay Grading</title>
      <link>http://arxiv.org/abs/2410.09319v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in ICAAAIML (4th International Conference on Advances and
  Applications of Artificial Intelligence and Machine Learning) 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动作文评分（AEG）因其在教育应用中的重要性而受到NLP社区的关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型，以提高自动作文评分的效果。&lt;h4&gt;方法&lt;/h4&gt;采用协作学习和迁移学习的概念，使用两个网络分别检查作文的语法和结构特征，以及评分整体思想。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在AEG领域中表现优于现有的最先进模型，准确率达到85.50%。&lt;h4&gt;结论&lt;/h4&gt;新模型有效提升了自动评分的准确性，解决了单一网络无法学习人类写作特征的问题。&lt;h4&gt;总结&lt;/h4&gt;通过引入多个网络协同工作，显著改善了自动作文评分的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic essay grading (AEG) has attracted the the attention of the NLPcommunity because of its applications to several educational applications, suchas scoring essays, short answers, etc. AEG systems can save significant timeand money when grading essays. In the existing works, the essays are gradedwhere a single network is responsible for the whole process, which may beineffective because a single network may not be able to learn all the featuresof a human-written essay. In this work, we have introduced a new model thatoutperforms the state-of-the-art models in the field of AEG. We have used theconcept of collaborative and transfer learning, where one network will beresponsible for checking the grammatical and structural features of thesentences of an essay while another network is responsible for scoring theoverall idea present in the essay. These learnings are transferred to anothernetwork to score the essay. We also compared the performances of the differentmodels mentioned in our work, and our proposed model has shown the highestaccuracy of 85.50%.</description>
      <author>example@mail.com (Maisha Maliha, Vishal Pramanik)</author>
      <guid isPermaLink="false">2410.09319v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Towards Reproducible Learning-based Compression</title>
      <link>http://arxiv.org/abs/2410.09872v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at MMSP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习系统通常面临可重复性不足的问题，这部分源于硬件或软件实现的细节。&lt;h4&gt;目的&lt;/h4&gt;分析深度学习在压缩系统中的可重复性问题，尤其是在不同制造商设备上进行编码和解码时的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出一种保护机制，以确保在有限资源下的可重复性，前提是限制不匹配的范围。&lt;h4&gt;主要发现&lt;/h4&gt;对于学习型压缩系统，解码过程可能因单个比特差异而崩溃，尤其是在基于学习的熵编码器中。&lt;h4&gt;结论&lt;/h4&gt;提出的方法可以在重构级别或选定的解码级别上应用，且在压制误差范围时，可降低保护所带来的开销。&lt;h4&gt;总结&lt;/h4&gt;实验结果表明，所提方法在图像压缩和点云压缩等学习型压缩系统中有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A deep learning system typically suffers from a lack of reproducibility thatis partially rooted in hardware or software implementation details. Theirreproducibility leads to skepticism in deep learning technologies and it canhinder them from being deployed in many applications. In this work, theirreproducibility issue is analyzed where deep learning is employed incompression systems while the encoding and decoding may be run on devices fromdifferent manufacturers. The decoding process can even crash due to a singlebit difference, e.g., in a learning-based entropy coder. For a given deeplearning-based module with limited resources for protection, we first suggestthat reproducibility can only be assured when the mismatches are bounded. Thena safeguarding mechanism is proposed to tackle the challenges. The proposedmethod may be applied for different levels of protection either at thereconstruction level or at a selected decoding level. Furthermore, the overheadintroduced for the protection can be scaled down accordingly when the errorbound is being suppressed. Experiments demonstrate the effectiveness of theproposed approach for learning-based compression systems, e.g., in imagecompression and point cloud compression.</description>
      <author>example@mail.com (Jiahao Pang, Muhammad Asad Lodhi, Junghyun Ahn, Yuning Huang, Dong Tian)</author>
      <guid isPermaLink="false">2410.09872v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>JOOCI: a Framework for Learning Comprehensive Speech Representations</title>
      <link>http://arxiv.org/abs/2410.11086v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;语音中的信息可以分为两类：所说内容（内容）和表达方式（其他）。&lt;h4&gt;目的&lt;/h4&gt;提出一种联合优化语音中的其他信息和内容信息的框架（JOOCI）。&lt;h4&gt;方法&lt;/h4&gt;JOOCI使用可学习的独立参数，分别建模其他信息和内容信息，解决优化挑战。&lt;h4&gt;主要发现&lt;/h4&gt;JOOCI在SUPERB基准测试中的多项语音下游任务评估中，显著优于其他相似规模（1亿参数）和相同预训练数据（960小时）的SOTA模型。&lt;h4&gt;结论&lt;/h4&gt;JOOCI有效提升了模型在复杂层次特征构建上的能力。&lt;h4&gt;总结&lt;/h4&gt;JOOCI框架通过独立建模实现了语音信息的优化，表现优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Information in speech can be divided into two categories: what is being said(content) and how it is expressed (other). Current state-of-the-art (SOTA)techniques model speech at fixed segments, usually 10-25 ms, using a singleembedding. Given the orthogonal nature of other and content information,attempting to optimize both within a single embedding results in suboptimalsolutions. This approach divides the models capacity, limiting its ability tobuild complex hierarchical features effectively. In this work, we present anend-to-end speech representation learning framework designed to jointlyoptimize the other and content information (JOOCI) in speech. By using separatelearnable parameters, JOOCI addresses this optimization challenge by modelingother and content information independently. Our results show that JOOCIconsistently outperforms other SOTA models of similar size (100 millionparameters) and pre-training data used (960 hours) by a significant margin whenevaluated on a range of speech downstream tasks in the SUPERB benchmark, asshown in Table 1.</description>
      <author>example@mail.com (Hemant Yadav, Rajiv Ratn Shah, Sunayana Sitaram)</author>
      <guid isPermaLink="false">2410.11086v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>"Let's Argue Both Sides": Argument Generation Can Force Small Models to Utilize Previously Inaccessible Reasoning Capabilities</title>
      <link>http://arxiv.org/abs/2410.12997v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to Workshop on Customizable NLP: Progress and Challenges in
  Customizing NLP for a Domain, Application, Group, or Individual at EMNLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在多个评估任务中取得了最先进的结果，但在需要严格逻辑推理的情况下表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出论证生成（Argument Generation）作为一种方法，以促使模型利用其推理能力。&lt;h4&gt;方法&lt;/h4&gt;生成每个可能推断结果的论据，并要求最终模型对生成的论据进行排序。&lt;h4&gt;主要发现&lt;/h4&gt;论证生成可以替代零-shot 提示技术，而无需增加复杂性。该方法在较小的语言模型中带来了更大的提升。&lt;h4&gt;结论&lt;/h4&gt;知识探测技术如链式推理和论证生成在需要进一步推理时才有用，作为更常见的零-shot 方法的辅助。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了模型规模与提示方法之间的复杂关系，论证生成在推理不足的情况下能够有效提升模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs), despite achieving state-of-the-art results in anumber of evaluation tasks, struggle to maintain their performance when logicalreasoning is strictly required to correctly infer a prediction. In this work,we propose Argument Generation as a method of forcing models to utilize theirreasoning capabilities when other approaches such as chain-of-thought reasoningprove insufficient. Our method involves the generation of arguments for eachpossible inference result, and asking the end model to rank the generatedarguments. We show that Argument Generation can serve as an appropriatesubstitute for zero-shot prompting techniques without the requirement to addlayers of complexity. Furthermore, we argue that knowledge-probing techniquessuch as chain-of-thought reasoning and Argument Generation are only useful whenfurther reasoning is required to infer a prediction, making them auxiliary tomore common zero-shot approaches. Finally, we demonstrate that our approachforces larger gains in smaller language models, showcasing a complexrelationship between model size and prompting methods in foundation models.</description>
      <author>example@mail.com (Kaveh Eskandari Miandoab, Vasanth Sarathy)</author>
      <guid isPermaLink="false">2410.12997v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Learning to learn ecosystems from limited data -- a meta-learning approach</title>
      <link>http://arxiv.org/abs/2410.07368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在开发数据驱动的生态系统方法中，观测数据的稀缺是一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;通过合成数据开发一种元学习框架，以预测生态系统的长期行为。&lt;h4&gt;方法&lt;/h4&gt;利用时间延迟前馈神经网络，结合典型的非生态动态系统生成合成数据。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够在数据有限的情况下准确重建生态系统的“动态气候”。&lt;h4&gt;结论&lt;/h4&gt;相比仅用生态系统数据训练的机器学习方法，该框架在训练数据量减少五到七倍的情况下，提高了预测的准确性和稳健性。&lt;h4&gt;问题&lt;/h4&gt;讨论了影响预测性能的若干问题。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了元学习框架在生态系统预测中的潜力，尤其是在数据稀缺的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A fundamental challenge in developing data-driven approaches to ecologicalsystems for tasks such as state estimation and prediction is the paucity of theobservational or measurement data. For example, modern machine-learningtechniques such as deep learning or reservoir computing typically require alarge quantity of data. Leveraging synthetic data from paradigmatic nonlinearbut non-ecological dynamical systems, we develop a meta-learning framework withtime-delayed feedforward neural networks to predict the long-term behaviors ofecological systems as characterized by their attractors. We show that theframework is capable of accurately reconstructing the ``dynamical climate'' ofthe ecological system with limited data. Three benchmark population models inecology, namely the Hastings-Powell model, a three-species food chain, and theLotka-Volterra system, are used to demonstrate the performance of themeta-learning based prediction framework. In all cases, enhanced accuracy androbustness are achieved using five to seven times less training data ascompared with the corresponding machine-learning method trained solely from theecosystem data. A number of issues affecting the prediction performance areaddressed.</description>
      <author>example@mail.com (Zheng-Meng Zhai, Bryan Glaz, Mulugeta Haile, Ying-Cheng Lai)</author>
      <guid isPermaLink="false">2410.07368v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Block-to-Scene Pre-training for Point Cloud Hybrid-Domain Masked Autoencoders</title>
      <link>http://arxiv.org/abs/2410.09886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云作为3D数据的主要表示形式，可以分为场景域点云和物体域点云，基于建模内容进行分类。现有的基于MAE的方法具有领域特定性，限制了模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种通用的点云混合域遮罩自编码器（PointHDMAE），通过块到场景的预训练策略进行预训练。&lt;h4&gt;方法&lt;/h4&gt;构建一个混合域的遮罩自编码器，包含场景域和物体域的编码器和解码器。采用块到场景的策略，随机选择场景中的点块，进行变换以将点块坐标从场景空间转换到物体空间，使用物体级遮罩和重建流程恢复被遮罩的点，并引入场景级块位置回归流程。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验，验证了混合域模型的泛化能力和优越性。&lt;h4&gt;结论&lt;/h4&gt;提出的PointHDMAE模型在不同数据集和任务中表现出色，显示了其在点云自监督学习中的潜力。&lt;h4&gt;总结&lt;/h4&gt;本文研究表明，混合域的预训练策略能有效提升点云模型的泛化能力，推动了自监督学习的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point clouds, as a primary representation of 3D data, can be categorized intoscene domain point clouds and object domain point clouds based on the modeledcontent. Masked autoencoders (MAE) have become the mainstream paradigm in pointclouds self-supervised learning. However, existing MAE-based methods aredomain-specific, limiting the model's generalization. In this paper, we proposeto pre-train a general Point cloud Hybrid-Domain Masked AutoEncoder(PointHDMAE) via a block-to-scene pre-training strategy. We first propose ahybrid-domain masked autoencoder consisting of an encoder and decoder belongingto the scene domain and object domain, respectively. The object domain encoderspecializes in handling object point clouds and multiple shared object encodersassist the scene domain encoder in analyzing the scene point clouds.Furthermore, we propose a block-to-scene strategy to pre-train ourhybrid-domain model. Specifically, we first randomly select point blocks withina scene and apply a set of transformations to convert each point blockcoordinates from the scene space to the object space. Then, we employ anobject-level mask and reconstruction pipeline to recover the masked points ofeach block, enabling the object encoder to learn a universal objectrepresentation. Finally, we introduce a scene-level block position regressionpipeline, which utilizes the blocks' features in the object space to regressthese blocks' initial positions within the scene space, facilitating thelearning of scene representations. Extensive experiments across differentdatasets and tasks demonstrate the generalization and superiority of ourhybrid-domain model.</description>
      <author>example@mail.com (Yaohua Zha, Tao Dai, Yanzi Wang, Hang Guo, Taolin Zhang, Zhihao Ouyang, Chunlin Fan, Bin Chen, Ke Chen, Shu-Tao Xia)</author>
      <guid isPermaLink="false">2410.09886v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Deep Transfer Learning: Model Framework and Error Analysis</title>
      <link>http://arxiv.org/abs/2410.09383v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文提出一个深度迁移学习框架，旨在利用多领域上游数据的信息来提升单领域下游任务的性能。&lt;h4&gt;目的&lt;/h4&gt;提升在样本数量较少的下游任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;框架允许多领域数据中存在共享和特定特征，并提供自动识别的机制，以精确转移和利用信息。&lt;h4&gt;主要发现&lt;/h4&gt;模型框架明确指出对下游任务有贡献的上游特征，增强了解释性；迁移学习显著提高了下游任务的收敛速度。&lt;h4&gt;结论&lt;/h4&gt;通过迁移，收敛速度从未迁移的O(m^{-1/2(d+2)} + n^{-1/2(d+2)})降低到部分迁移的O(m^{-1/2(d*+3)} + n^{-1/2(d+2)})，甚至完全迁移的O(m^{-1/2} + n^{-1/2(d+2)})，其中d*远小于d。&lt;h4&gt;实验验证&lt;/h4&gt;理论结果通过在图像分类和回归数据集上的实证实验得到验证。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一个有效的框架，展示了深度迁移学习在小样本下游任务中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a framework for deep transfer learning, which aims toleverage information from multi-domain upstream data with a large number ofsamples $n$ to a single-domain downstream task with a considerably smallernumber of samples $m$, where $m \ll n$, in order to enhance performance ondownstream task. Our framework has several intriguing features. First, itallows the existence of both shared and specific features among multi-domaindata and provides a framework for automatic identification, achieving precisetransfer and utilization of information. Second, our model framework explicitlyindicates the upstream features that contribute to downstream tasks,establishing a relationship between upstream domains and downstream tasks,thereby enhancing interpretability. Error analysis demonstrates that thetransfer under our framework can significantly improve the convergence rate forlearning Lipschitz functions in downstream supervised tasks, reducing it from$\tilde{O}(m^{-\frac{1}{2(d+2)}}+n^{-\frac{1}{2(d+2)}})$ ("no transfer") to$\tilde{O}(m^{-\frac{1}{2(d^*+3)}} + n^{-\frac{1}{2(d+2)}})$ ("partialtransfer"), and even to $\tilde{O}(m^{-1/2}+n^{-\frac{1}{2(d+2)}})$ ("completetransfer"), where $d^* \ll d$ and $d$ is the dimension of the observed data.Our theoretical findings are substantiated by empirical experiments conductedon image classification datasets, along with a regression dataset.</description>
      <author>example@mail.com (Yuling Jiao, Huazhen Lin, Yuchen Luo, Jerry Zhijian Yang)</author>
      <guid isPermaLink="false">2410.09383v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Multiview Scene Graph</title>
      <link>http://arxiv.org/abs/2410.11187v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To be published in NeurIPS 2024. Website at
  https://ai4ce.github.io/MSG/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;场景表示在空间智能中至关重要，能够有效地重建和理解三维场景。&lt;h4&gt;目的&lt;/h4&gt;提出一种从未标定图像构建多视角场景图（MSG），以拓扑方式表示场景。&lt;h4&gt;方法&lt;/h4&gt;通过结合视觉地点识别、物体检测和物体关联，开发基于主流预训练视觉模型的Transformer解码器架构。&lt;h4&gt;主要发现&lt;/h4&gt;提出的MSG方法相较于现有基准方法展现了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;开发的MSG数据集和评估指标为评估场景表示方法提供了基础。&lt;h4&gt;总结&lt;/h4&gt;本研究在复杂条件下有效整合了多种视觉任务，推动了三维场景理解的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A proper scene representation is central to the pursuit of spatialintelligence where agents can robustly reconstruct and efficiently understand3D scenes. A scene representation is either metric, such as landmark maps in 3Dreconstruction, 3D bounding boxes in object detection, or voxel grids inoccupancy prediction, or topological, such as pose graphs with loop closures inSLAM or visibility graphs in SfM. In this work, we propose to build MultiviewScene Graphs (MSG) from unposed images, representing a scene topologically withinterconnected place and object nodes. The task of building MSG is challengingfor existing representation learning methods since it needs to jointly addressboth visual place recognition, object detection, and object association fromimages with limited fields of view and potentially large viewpoint changes. Toevaluate any method tackling this task, we developed an MSG dataset andannotation based on a public 3D dataset. We also propose an evaluation metricbased on the intersection-over-union score of MSG edges. Moreover, we develop anovel baseline method built on mainstream pretrained vision models, combiningvisual place recognition and object association into one Transformer decoderarchitecture. Experiments demonstrate our method has superior performancecompared to existing relevant baselines.</description>
      <author>example@mail.com (Juexiao Zhang, Gao Zhu, Sihang Li, Xinhao Liu, Haorui Song, Xinran Tang, Chen Feng)</author>
      <guid isPermaLink="false">2410.11187v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Flex: End-to-End Text-Instructed Visual Navigation with Foundation Models</title>
      <link>http://arxiv.org/abs/2410.13002v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;元学习近年来在少样本学习和强化学习等领域广泛应用，但在少样本分类中，尚不清楚其为何及何时优于其他算法。&lt;h4&gt;目的&lt;/h4&gt;探索元学习在少样本分类中的表现及其优越性。&lt;h4&gt;方法&lt;/h4&gt;通过调整标签噪声比例和任务异质性，进行预实验，使用奇异向量典范相关分析量化神经网络的表示稳定性，以比较元学习与经典学习算法的行为。&lt;h4&gt;主要发现&lt;/h4&gt;得益于双层优化策略，元学习算法对标签噪声和异质任务具有更好的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;元学习在无监督领域有着良好的发展前景，提出了DHM-UHT，一个动态头元学习算法，进行无监督异质任务构建。&lt;h4&gt;实现&lt;/h4&gt;DHM-UHT利用DBSCAN和动态头实现异质任务构建，并对无监督异质任务构建的整个过程进行元学习。&lt;h4&gt;性能&lt;/h4&gt;在多个无监督零样本和少样本数据集上，DHM-UHT取得了最先进的性能。&lt;h4&gt;代码&lt;/h4&gt;代码已发布在https://github.com/tuantuange/DHM-UHT。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了元学习在处理无监督异质任务中的潜力，并提供了新的算法及其实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; End-to-end learning directly maps sensory inputs to actions, creating highlyintegrated and efficient policies for complex robotics tasks. However, suchmodels are tricky to efficiently train and often struggle to generalize beyondtheir training scenarios, limiting adaptability to new environments, tasks, andconcepts. In this work, we investigate the minimal data requirements andarchitectural adaptations necessary to achieve robust closed-loop performancewith vision-based control policies under unseen text instructions and visualdistribution shifts. To this end, we design datasets with various levels ofdata representation richness, refine feature extraction protocols by leveragingmulti-modal foundation model encoders, and assess the suitability of differentpolicy network heads. Our findings are synthesized in Flex (Fly-lexically), aframework that uses pre-trained Vision Language Models (VLMs) as frozenpatch-wise feature extractors, generating spatially aware embeddings thatintegrate semantic and visual information. These rich features form the basisfor training highly robust downstream policies capable of generalizing acrossplatforms, environments, and text-specified tasks. We demonstrate theeffectiveness of this approach on quadrotor fly-to-target tasks, where agentstrained via behavior cloning on a small simulated dataset successfullygeneralize to real-world scenes, handling diverse novel goals and commandformulations.</description>
      <author>example@mail.com (Makram Chahine, Alex Quach, Alaa Maalouf, Tsun-Hsuan Wang, Daniela Rus)</author>
      <guid isPermaLink="false">2410.13002v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Meta-Learning via Dynamic Head and Heterogeneous Task Construction for Few-Shot Classification</title>
      <link>http://arxiv.org/abs/2410.02267v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;构建人工智能地理空间系统需要快速提供大规模空间数据分析，且尽量减少人工干预。&lt;h4&gt;目的&lt;/h4&gt;研究数据分析中的模型评估和不确定性量化。&lt;h4&gt;方法&lt;/h4&gt;提出迁移学习框架，将大数据集分割为小数据集，流入分析框架以促进学习和推断。&lt;h4&gt;主要发现&lt;/h4&gt;引入贝叶斯预测堆叠法，能够快速分析多元空间数据，并在合理时间内进行推断。&lt;h4&gt;结论&lt;/h4&gt;该方法在气候科学中的海表温度和植被指数的大规模数据集分析中表现出有效性。&lt;h4&gt;总结&lt;/h4&gt;通过广泛的模拟实验验证了该方法的有效性，使得在不高要求硬件条件下，能够实现高效的数据分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tuantuange/dhm-uht&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Meta-learning has been widely used in recent years in areas such as few-shotlearning and reinforcement learning. However, the questions of why and when itis better than other algorithms in few-shot classification remain to beexplored. In this paper, we perform pre-experiments by adjusting the proportionof label noise and the degree of task heterogeneity in the dataset. We use themetric of Singular Vector Canonical Correlation Analysis to quantify therepresentation stability of the neural network and thus to compare the behaviorof meta-learning and classical learning algorithms. We find that benefitingfrom the bi-level optimization strategy, the meta-learning algorithm has betterrobustness to label noise and heterogeneous tasks. Based on the aboveconclusion, we argue a promising future for meta-learning in the unsupervisedarea, and thus propose DHM-UHT, a dynamic head meta-learning algorithm withunsupervised heterogeneous task construction. The core idea of DHM-UHT is touse DBSCAN and dynamic head to achieve heterogeneous task construction andmeta-learn the whole process of unsupervised heterogeneous task construction.On several unsupervised zero-shot and few-shot datasets, DHM-UHT obtainsstate-of-the-art performance. The code is released athttps://github.com/tuantuange/DHM-UHT.</description>
      <author>example@mail.com (Yunchuan Guan, Yu Liu, Ketong Liu, Ke Zhou, Zhiqi Shen)</author>
      <guid isPermaLink="false">2410.02267v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Transfer Learning for Artificially Intelligent Geospatial Systems: A Predictive Stacking Approach</title>
      <link>http://arxiv.org/abs/2410.09504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;用户希望获取详细的森林地图，从林地到树冠的各个层面。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够自动生成联合的地面和空中森林重建的流程。&lt;h4&gt;方法&lt;/h4&gt;提出一种无标记的配准流程，通过相对变换约束估计，结合地面SLAM扫描过程中的空间约束，精确对齐不同的点云。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够生成大规模自然环境的精细重建，支持多平台数据捕获。&lt;h4&gt;结论&lt;/h4&gt;我们的方案无需外部基础设施，即可实现精准的森林数据重建。&lt;h4&gt;总结&lt;/h4&gt;提出的自动化流程有效整合了地面和空中激光扫描数据，满足了林业应用的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lucapresicce/Bayesian-Transfer-Learning-for-GeoAI&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building artificially intelligent geospatial systems require rapid deliveryof spatial data analysis at massive scales with minimal human intervention.Depending upon their intended use, data analysis may also entail modelassessment and uncertainty quantification. This article devises transferlearning frameworks for deployment in artificially intelligent systems, where amassive data set is split into smaller data sets that stream into theanalytical framework to propagate learning and assimilate inference for theentire data set. Specifically, we introduce Bayesian predictive stacking formultivariate spatial data and demonstrate its effectiveness in rapidlyanalyzing massive data sets. Furthermore, we make inference feasible in areasonable amount of time, and without excessively demanding hardware settings.We illustrate the effectiveness of this approach in extensive simulationexperiments and subsequently analyze massive data sets in climate science onsea surface temperatures and on vegetation index.</description>
      <author>example@mail.com (Luca Presicce, Sudipto Banerjee)</author>
      <guid isPermaLink="false">2410.09504v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Markerless Aerial-Terrestrial Co-Registration of Forest Point Clouds using a Deformable Pose Graph</title>
      <link>http://arxiv.org/abs/2410.09896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;心血管疾病（CVD）是全球主要的死亡和早逝原因，职业环境显著影响CVD风险，强调了有效心脏监测和预警系统的必要性。&lt;h4&gt;目的&lt;/h4&gt;提出MERIT，一个基于多模态的可穿戴系统，旨在无运动限制地精确监测心电图（ECG）波形。&lt;h4&gt;方法&lt;/h4&gt;MERIT通过引入深度独立成分分析（Deep-ICA）模块和多模态融合模块，减轻运动影响并增强ECG信号重建。&lt;h4&gt;主要发现&lt;/h4&gt;与商业可穿戴设备和现有方法相比，MERIT在不同的办公活动中能够准确重建ECG波形。&lt;h4&gt;结论&lt;/h4&gt;MERIT为动态环境中的精细心脏监测提供了可靠的解决方案。&lt;h4&gt;总结&lt;/h4&gt;MERIT系统通过创新的方法有效解决了日常活动中对心电图监测的挑战，提升了动态环境下的心脏健康监测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For biodiversity and forestry applications, end-users desire maps of foreststhat are fully detailed, from the forest floor to the canopy. Terrestrial laserscanning and aerial laser scanning are accurate and increasingly mature methodsfor scanning the forest. However, individually they are not able to estimateattributes such as tree height, trunk diameter and canopy density due to theinherent differences in their field-of-view and mapping processes. In thiswork, we present a pipeline that can automatically generate a single jointterrestrial and aerial forest reconstruction. The novelty of the approach is amarker-free registration pipeline, which estimates a set of relativetransformation constraints between the aerial cloud and terrestrial sub-cloudswithout requiring any co-registration reflective markers to be physicallyplaced in the scene. Our method then uses these constraints in a pose graphformulation, which enables us to finely align the respective clouds whilerespecting spatial constraints introduced by the terrestrial SLAM scanningprocess. We demonstrate that our approach can produce a fine-grained andcomplete reconstruction of large-scale natural environments, enablingmulti-platform data capture for forestry applications without requiringexternal infrastructure.</description>
      <author>example@mail.com (Benoit Casseau, Nived Chebrolu, Matias Mattamala, Leonard Freissmuth, Maurice Fallon)</author>
      <guid isPermaLink="false">2410.09896v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>MERIT: Multimodal Wearable Vital Sign Waveform Monitoring</title>
      <link>http://arxiv.org/abs/2410.00392v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管端到端多通道脑电图（EEG）学习方法显示出显著前景，但在神经诊断中，特别是在颅内EEG资源方面，其适用性常受到限制。&lt;h4&gt;目的&lt;/h4&gt;研究如何在单通道EEG条件下学习稳健的多通道表征，并能在不同任务中扩展应用，例如癫痫预测。&lt;h4&gt;方法&lt;/h4&gt;提出SplitSEE框架，通过自监督学习和深度聚类任务，独立学习时间和频率域的表征，并引入新颖的聚类损失来测量信息相似性。&lt;h4&gt;主要发现&lt;/h4&gt;SplitSEE仅通过单通道EEG学习的表征超越了多通道基线，显示出在不同通道间的适应能力，且在临床数据集上表现出色。&lt;h4&gt;结论&lt;/h4&gt;SplitSEE证明了在单通道EEG学习中，能够实现有效、鲁棒和可扩展的表现。&lt;h4&gt;总结&lt;/h4&gt;该研究为单通道EEG表征学习提供了一种新的方法，具有显著的临床应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cardiovascular disease (CVD) is the leading cause of death and prematuremortality worldwide, with occupational environments significantly influencingCVD risk, underscoring the need for effective cardiac monitoring and earlywarning systems. Existing methods of monitoring vital signs require subjects toremain stationary, which is impractical for daily monitoring as individuals areoften in motion. To address this limitation, we propose MERIT, amultimodality-based wearable system designed for precise ECG waveformmonitoring without movement restrictions. Daily activities, involving frequentarm movements, can significantly affect sensor data and complicate thereconstruction of accurate ECG signals. To mitigate motion impact and enhanceECG signal reconstruction, we introduce a deep independent component analysis(Deep-ICA) module and a multimodal fusion module. We conducted experiments with15 subjects. Our results, compared with commercial wearable devices andexisting methods, demonstrate that MERIT accurately reconstructs ECG waveformsduring various office activities, offering a reliable solution for fine-grainedcardiac monitoring in dynamic environments.</description>
      <author>example@mail.com (Yongyang Tang, Zhe Chen, Ang Li, Tianyue Zheng, Zheng Lin, Jia Xu, Pin Lv, Zhe Sun, Yue Gao)</author>
      <guid isPermaLink="false">2410.00392v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning</title>
      <link>http://arxiv.org/abs/2410.11200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted by ICDM2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人学习端到端策略时，轨迹通常包含末端执行器和夹持器的位置、工作空间图像和语言信息。&lt;h4&gt;目的&lt;/h4&gt;研究用于精细抓取的策略，解决现有策略不适合于需要紧密耦合的夹持器力和位置的问题。&lt;h4&gt;方法&lt;/h4&gt;收集并公开130条成功抓取的轨迹，包含30种独特物体的力反馈；采用一种不依赖于特定夹持器且无需额外硬件的力感知方法。&lt;h4&gt;主要发现&lt;/h4&gt;使用力反馈训练的策略在精细抓取上优于仅依靠位置的策略，且能够对未见过的精细物体进行泛化，同时将抓取策略延迟降低近4倍。&lt;h4&gt;结论&lt;/h4&gt;希望鼓励他人考虑在新数据集中收集力和触觉信息，以支持未来机器人基础模型的稳健且接触丰富的操作。&lt;h4&gt;总结&lt;/h4&gt;本研究结果表明，力反馈在精细抓取中的重要性，并提供了数据、代码和模型等资源，供未来研究使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While end-to-end multi-channel electroencephalography (EEG) learningapproaches have shown significant promise, their applicability is oftenconstrained in neurological diagnostics, such as intracranial EEG resources.When provided with a single-channel EEG, how can we learn representations thatare robust to multi-channels and scalable across varied tasks, such as seizureprediction? In this paper, we present SplitSEE, a structurally splittableframework designed for effective temporal-frequency representation learning insingle-channel EEG. The key concept of SplitSEE is a self-supervised frameworkincorporating a deep clustering task. Given an EEG, we argue that the time andfrequency domains are two distinct perspectives, and hence, learnedrepresentations should share the same cluster assignment. To this end, we firstpropose two domain-specific modules that independently learn domain-specificrepresentation and address the temporal-frequency tradeoff issue inconventional spectrogram-based methods. Then, we introduce a novel clusteringloss to measure the information similarity. This encourages representationsfrom both domains to coherently describe the same input by assigning them aconsistent cluster. SplitSEE leverages a pre-training-to-fine-tuning frameworkwithin a splittable architecture and has following properties: (a)Effectiveness: it learns representations solely from single-channel EEG but haseven outperformed multi-channel baselines. (b) Robustness: it shows thecapacity to adapt across different channels with low performance variance.Superior performance is also achieved with our collected clinical dataset. (c)Scalability: With just one fine-tuning epoch, SplitSEE achieves high and stableperformance using partial model layers.</description>
      <author>example@mail.com (Rikuto Kotoge, Zheng Chen, Tasuku Kimura, Yasuko Matsubara, Takufumi Yanagisawa, Haruhiko Kishima, Yasushi Sakurai)</author>
      <guid isPermaLink="false">2410.11200v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Just Add Force for Contact-Rich Robot Policies</title>
      <link>http://arxiv.org/abs/2410.13124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人学习端到端策略时，轨迹通常包含末端执行器和夹持器的位置、工作空间图像和语言信息。&lt;h4&gt;目的&lt;/h4&gt;研究用于精细抓取的策略，解决现有策略不适合于需要紧，并优化图嵌入表示。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的谱图对比学习框架SpeGCL，利用傅里叶变换提取节点特征的高频和低频信息，并在傅里叶空间中构建对比学习机制。&lt;h4&gt;主要发现&lt;/h4&gt;高频信息在增强图中的差异大于低频信息，现有GCL方法主要关注时域（低频信息），未能有效利用高频信息以加快模型收敛。&lt;h4&gt;结论&lt;/h4&gt;SpeGCL在仅依赖负样本优化图嵌入表示方面表现优越，理论分析证明了其有效性，实验结果显示SpeGCL优于现有最先进的GCL方法。&lt;h4&gt;总结&lt;/h4&gt;SpeGCL框架通过专注于高频信息和负样本，显著提升了图对比学习的表现，适用于无监督学习、迁移学习和半监督学习等场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robot trajectories used for learning end-to-end robot policies typicallycontain end-effector and gripper position, workspace images, and language.Policies learned from such trajectories are unsuitable for delicate grasping,which require tightly coupled and precise gripper force and gripper position.We collect and make publically available 130 trajectories with force feedbackof successful grasps on 30 unique objects. Our current-based method for sensingforce, albeit noisy, is gripper-agnostic and requires no additional hardware.We train and evaluate two diffusion policies: one with (forceful) the collectedforce feedback and one without (position-only). We find that forceful policiesare superior to position-only policies for delicate grasping and are able togeneralize to unseen delicate objects, while reducing grasp policy latency bynear 4x, relative to LLM-based methods. With our promising results on limiteddata, we hope to signal to others to consider investing in collecting force andother such tactile information in new datasets, enabling more robust,contact-rich manipulation in future robot foundation models. Our data, code,models, and videos are viewable at https://justaddforce.github.io/.</description>
      <author>example@mail.com (William Xie, Stefan Caldararu, Nikolaus Correll)</author>
      <guid isPermaLink="false">2410.13124v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SpeGCL: Self-supervised Graph Spectrum Contrastive Learning without Positive Samples</title>
      <link>http://arxiv.org/abs/2410.10365v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了一种用于3D点云分类和分割任务的神经网络PointNet-KAN。&lt;h4&gt;目的&lt;/h4&gt;探索将Kolmogorov-Arnold Networks (KANs)作为传统多层感知器(MLPs)的替代方案。&lt;h4&gt;方法&lt;/h4&gt;使用共享KAN层和对称函数进行全局特征提取，确保相对于输入特征的置换不变性，并利用Jacobi多项式构建KAN层。&lt;h4&gt;主要发现&lt;/h4&gt;在各种多项式度数和特殊类型（如Lagrange、Chebyshev和Gegenbauer多项式）下，PointNet-KAN在3D物体分类和分割的基准数据集上表现出与采用MLPs的PointNet相竞争的性能。&lt;h4&gt;结论&lt;/h4&gt;尽管网络架构更浅且更简单，PointNet-KAN仍然能取得良好效果，期望为将KANs整合进更先进的点云处理架构提供基础和指导。&lt;h4&gt;总结&lt;/h4&gt;PointNet-KAN展示了KANs在3D点云处理中的潜在优势，为未来研究指明了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning (GCL) excels at managing noise and fluctuations ininput data, making it popular in various fields (e.g., social networks, andknowledge graphs). Our study finds that the difference in high-frequencyinformation between augmented graphs is greater than that in low-frequencyinformation. However, most existing GCL methods focus mainly on the time domain(low-frequency information) for node feature representations and cannot makegood use of high-frequency information to speed up model convergence.Furthermore, existing GCL paradigms optimize graph embedding representations bypulling the distance between positive sample pairs closer and pushing thedistance between positive and negative sample pairs farther away, but ourtheoretical analysis shows that graph contrastive learning benefits frompushing negative pairs farther away rather than pulling positive pairs closer.To solve the above-mentioned problems, we propose a novel spectral GCLframework without positive samples, named SpeGCL. Specifically, to solve theproblem that existing GCL methods cannot utilize high-frequency information,SpeGCL uses a Fourier transform to extract high-frequency and low-frequencyinformation of node features, and constructs a contrastive learning mechanismin a Fourier space to obtain better node feature representation. Furthermore,SpeGCL relies entirely on negative samples to refine the graph embedding. Wealso provide a theoretical justification for the efficacy of using onlynegative samples in SpeGCL. Extensive experiments on un-supervised learning,transfer learning, and semi-supervised learning have validated the superiorityof our SpeGCL framework over the state-of-the-art GCL methods.</description>
      <author>example@mail.com (Yuntao Shou, Xiangyong Cao, Deyu Meng)</author>
      <guid isPermaLink="false">2410.10365v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>PointNet with KAN versus PointNet with MLP for 3D Classification and Segmentation of Point Sets</title>
      <link>http://arxiv.org/abs/2410.10084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "现代机器学习的广泛应用源于提取多来源数据中的有意义特征的能力，但许多实际领域的数据在来源上并非同分布，并且在其来源内存在统计依赖，这违反了现有理论研究的重要假设。",
    "目的": "针对上述问题，建立从多个数据来源学习一般非线性表示的统计保证，适应不同输入分布和可能依赖的数据。",
    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}```json
{
    "背景": "介绍了一种用于3D点云分类和分割任务的神经网络PointNet-KAN。",
    "目的": "探索将Kolmogorov-Arnold Networks (KANs)作为传统多层感 "针对上述问题，建立从多个数据来源学习一般非线性表示的统计保证，适应不同输入分布和可能依赖的数据。",
    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\math针对上述问题，建立从多个数据来源学习一般非线性表示的统计保证，适应不同输入分布和可能依赖的数据。",
    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\述问题，建立从多个数据来源学习一般非线性表示的统计保证，适应不同输入分布和可能依赖的数据。",
    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超个数据来源学习一般非线性表示的统计保证，适应不同输入分布和可能依赖的数据。",
    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm性表示的统计保证，适应不同输入分布和可能依赖的数据。",
    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}同输入分布和可能依赖的数据。",
    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N依赖的数据。",
    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N T} \big)$ 下降，依赖性仅影响样本需求，风险界限据。",
    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N T} \big)$ 下降，依赖性仅影响样本需求，风险界限与独立同分布情形匹配。",
    "结论": "随着任务数量    "方法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N T} \big)$ 下降，依赖性仅影响样本需求，风险界限与独立同分布情形匹配。",
    "结论": "随着任务数量 $T$ 的增加，样本需求和风险界限收敛到 $r$ 维回归的情况，仿佛 $g_\star$ 已法": "研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N T} \big)$ 下降，依赖性仅影响样本需求，风险界限与独立同分布情形匹配。",
    "结论": "随着任务数量 $T$ 的增加，样本需求和风险界限收敛到 $r$ 维回归的情况，仿佛 $g_\star$ 已经给定。",
    "总结": "研究为多来源数据"研究从函数类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N T} \big)$ 下降，依赖性仅影响样本需求，风险界限与独立同分布情形匹配。",
    "结论": "随着任务数量 $T$ 的增加，样本需求和风险界限收敛到 $r$ 维回归的情况，仿佛 $g_\star$ 已经给定。",
    "总结": "研究为多来源数据的非线性表示学习提供了理论支持，揭类中学习 $T+1$ 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N T} \big)$ 下降，依赖性仅影响样本需求，风险界限与独立同分布情形匹配。",
    "结论": "随着任务数量 $T$ 的增加，样本需求和风险界限收敛到 $r$ 维回归的情况，仿佛 $g_\star$ 已经给定。",
    "总结": "研究为多来源数据的非线性表示学习提供了理论支持，揭示了任务多样性和数据依赖性对样本需求和 个函数 $f_\star^{(t)} \circ g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N T} \big)$ 下降，依赖性仅影响样本需求，风险界限与独立同分布情形匹配。",
    "结论": "随着任务数量 $T$ 的增加，样本需求和风险界限收敛到 $r$ 维回归的情况，仿佛 $g_\star$ 已经给定。",
    "总结": "研究为多来源数据的非线性表示学习提供了理论支持，揭示了任务多样性和数据依赖性对样本需求和风险的影响。"
}
```主要发现": "在各种 g_\star$ 的样本复杂度，其中 $f_\star^{(t)}$ 是任务特定的线性函数，$g_\star$ 是共享的非线性表示。",
    "主要发现": "当样本量 $N$ 满足 $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$ 时，目标任务上 $\hat f^{(0)} \circ \hat g$ 的超额风险随着 $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcal F)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N T} \big)$ 下降，依赖性仅影响样本需求，风险界限与独立同分布情形匹配。",
    "结论": "随着任务数量 $T$ 的增加，样本需求和风险界限收敛到 $r$ 维回归的情况，仿佛 $g_\star$ 已经给定。",
    "总结": "研究为多来源数据的非线性表示学习提供了理论支持，揭示了任务多样性和数据依赖性对样本需求和风险的影响。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce PointNet-KAN, a neural network for 3D point cloud classificationand segmentation tasks, built upon two key components. First, it employsKolmogorov-Arnold Networks (KANs) instead of traditional Multilayer Perceptrons(MLPs). Second, it retains the core principle of PointNet by using shared KANlayers and applying symmetric functions for global feature extraction, ensuringpermutation invariance with respect to the input features. In traditional MLPs,the goal is to train the weights and biases with fixed activation functions;however, in KANs, the goal is to train the activation functions themselves. Weuse Jacobi polynomials to construct the KAN layers. We extensively evaluatePointNet-KAN across various polynomial degrees and special types such as theLagrange, Chebyshev, and Gegenbauer polynomials. Our results show thatPointNet-KAN achieves competitive performance compared to PointNet with MLPs onbenchmark datasets for 3D object classification and segmentation, despiteemploying a shallower and simpler network architecture. We hope this workserves as a foundation and provides guidance for integrating KANs, as analternative to MLPs, into more advanced point cloud processing architectures.</description>
      <author>example@mail.com (Ali Kashefi)</author>
      <guid isPermaLink="false">2410.10084v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Guarantees for Nonlinear Representation Learning: Non-identical Covariates, Dependent Data, Fewer Samples</title>
      <link>http://arxiv.org/abs/2410.11227v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Appeared at ICML 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代基础模型的成本不断上升，传统方法通过手动规则删除特定上下文部分以降低成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服性能与效率之间的权衡。&lt;h4&gt;方法&lt;/h4&gt;引入神经注意力记忆模型（NAMMs），通过学习的网络实现内存管理，提升变换器的性能和效率。&lt;h4&gt;主要发现&lt;/h4&gt;在多个长上下文基准测试中，NAMMs显著提高了性能，同时将模型输入上下文缩减至原始大小的一小部分。&lt;h4&gt;结论&lt;/h4&gt;NAMMs具有广泛适用性，能够在不同的变换器架构和输入模态下实现零样本迁移，其优势也适用于视觉和强化学习领域。&lt;h4&gt;总结&lt;/h4&gt;NAMMs通过关注最相关的信息，提升了变换器的性能和效率，为处理现代基础模型的挑战提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A driving force behind the diverse applicability of modern machine learningis the ability to extract meaningful features across many sources. However,many practical domains involve data that are non-identically distributed acrosssources, and statistically dependent within its source, violating vitalassumptions in existing theoretical studies. Toward addressing these issues, weestablish statistical guarantees for learning general $\textit{nonlinear}$representations from multiple data sources that admit different inputdistributions and possibly dependent data. Specifically, we study thesample-complexity of learning $T+1$ functions $f_\star^{(t)} \circ g_\star$from a function class $\mathcal F \times \mathcal G$, where $f_\star^{(t)}$ aretask specific linear functions and $g_\star$ is a shared nonlinearrepresentation. A representation $\hat g$ is estimated using $N$ samples fromeach of $T$ source tasks, and a fine-tuning function $\hat f^{(0)}$ is fitusing $N'$ samples from a target task passed through $\hat g$. We show thatwhen $N \gtrsim C_{\mathrm{dep}} (\mathrm{dim}(\mathcal F) +\mathrm{C}(\mathcal G)/T)$, the excess risk of $\hat f^{(0)} \circ \hat g$ onthe target task decays as $\nu_{\mathrm{div}} \big(\frac{\mathrm{dim}(\mathcalF)}{N'} + \frac{\mathrm{C}(\mathcal G)}{N T} \big)$, where $C_{\mathrm{dep}}$denotes the effect of data dependency, $\nu_{\mathrm{div}}$ denotes an(estimatable) measure of $\textit{task-diversity}$ between the source andtarget tasks, and $\mathrm C(\mathcal G)$ denotes the complexity of therepresentation class $\mathcal G$. In particular, our analysis reveals: as thenumber of tasks $T$ increases, both the sample requirement and risk boundconverge to that of $r$-dimensional regression as if $g_\star$ had been given,and the effect of dependency only enters the sample requirement, leaving therisk bound matching the iid setting.</description>
      <author>example@mail.com (Thomas T. Zhang, Bruce D. Lee, Ingvar Ziemann, George J. Pappas, Nikolai Matni)</author>
      <guid isPermaLink="false">2410.11227v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>An Evolved Universal Transformer Memory</title>
      <link>http://arxiv.org/abs/2410.13166v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 14 figures. Preprint, under submission. Source code is
  available at https://github.com/SakanaAI/evo-memory&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来自动驾驶汽车的关注度不断上升，激发了大量研究。&lt;h4&gt;目的&lt;/h4&gt;确保自动驾驶汽车的安全、舒适和效率，特别是控制器模块的研究。&lt;h4&gt;方法&lt;/h4&gt;使用异构图和图神经网络在线学习车辆模型和横向控制器，处理车辆的当前状态和输入。&lt;h4&gt;主要发现&lt;/h4&gt;提出的自学习模型的横向控制器在CARLA开源自动驾驶平台上的表现令人满意。&lt;h4&gt;结论&lt;/h4&gt;需要适应变化环境的控制器，以满足自动驾驶的需求。&lt;h4&gt;总结&lt;/h4&gt;本文介绍了通过图神经网络在线学习车辆模型和控制策略的创新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sakanaai/evo-memory&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prior methods propose to offset the escalating costs of modern foundationmodels by dropping specific parts of their contexts with hand-designed rules,while attempting to preserve their original performance. We overcome thistrade-off with Neural Attention Memory Models (NAMMs), introducing a learnednetwork for memory management that improves both the performance and efficiencyof transformers. We evolve NAMMs atop pre-trained transformers to providedifferent latent contexts focusing on the most relevant information forindividual layers and attention heads.NAMMs are universally applicable to anymodel using self-attention as they condition exclusively on the values in theproduced attention matrices. Learning NAMMs on a small set of problems, weachieve substantial performance improvements across multiple long-contextbenchmarks while cutting the model's input contexts up to a fraction of theoriginal sizes. We show the generality of our conditioning enables zero-shottransfer of NAMMs trained only on language to entirely new transformerarchitectures even across input modalities, with their benefits carrying overto vision and reinforcement learning.</description>
      <author>example@mail.com (Edoardo Cetin, Qi Sun, Tianyu Zhao, Yujin Tang)</author>
      <guid isPermaLink="false">2410.13166v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>An Online Self-learning Graph-based Lateral Controller for Self-Driving Cars</title>
      <link>http://arxiv.org/abs/2410.11979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The article has been published in the early access area on IEEE
  Xplore for the IEEE Transactions on Intelligent Vehicles (2024). This is the
  accepted version. Number of pages: 12 pages, Number of figures: 10&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来自动驾驶汽车的关注度不断上升，激发了大量研究。&lt;h4&gt;目的&lt;/h4&gt;确保自动驾驶汽车的安全、舒适和效率，特别是控制器模块的研究。&lt;h4&gt;方法&lt;/h4&gt;使用异构图和图神经网络在线学习车辆模型和横向控制器，处理车辆的当前状态和输入。&lt;h4&gt;主要发现&lt;/h4&gt;提出的自学习模型的横向控制器在CARLA开源自动驾驶平台上的表现令人满意。&lt;h4&gt;结论&lt;/h4&gt;需要适应变化环境的控制器，以满足自动驾驶的需求。&lt;h4&gt;总结&lt;/h4&gt;本文介绍了通过图神经网络在线学习车辆模型和控制策略的创新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TIV.2024.3478052&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The hype around self-driving cars has been growing over the past years andhas sparked much research. Several modules in self-driving cars are thoroughlyinvestigated to ensure safety, comfort, and efficiency, among which thecontroller is crucial. The controller module can be categorized intolongitudinal and lateral controllers in which the task of the former is tofollow the reference velocity, and the latter is to reduce the lateraldisplacement error from the reference path. Generally, a tuned controller isnot sufficient to perform in all environments. Thus, a controller that canadapt to changing conditions is necessary for autonomous driving. Furthermore,these controllers often depend on vehicle models that also need to adapt overtime due to varying environments. This paper uses graphs to present noveltechniques to learn the vehicle model and the lateral controller online. First,a heterogeneous graph is presented depicting the current states of and inputsto the vehicle. The vehicle model is then learned online using known physicalconstraints in conjunction with the processing of the graph through a GraphNeural Network structure. Next, another heterogeneous graph - depicting thetransition from current to desired states - is processed through another GraphNeural Network structure to generate the steering command on the fly. Finally,the performance of this self-learning model-based lateral controller isevaluated and shown to be satisfactory on an open-source autonomous drivingplatform called CARLA.</description>
      <author>example@mail.com (Jilan Samiuddin, Benoit Boulet, Di Wu)</author>
      <guid isPermaLink="false">2410.11979v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modal Few-Shot Learning: a Generative Transfer Learning Framework</title>
      <link>http://arxiv.org/abs/2410.10663v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的少样本学习研究主要集中在单模态设置上，限制了其在实际应用中的效果。&lt;h4&gt;目的&lt;/h4&gt;引入跨模态少样本学习（CFSL）任务，以识别来自多个模态的实例，尤其是在只有少量标记样本的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种生成转移学习（GTL）框架，包括两个阶段：第一阶段在丰富的单模态数据上训练，第二阶段进行转移学习以适应新数据。&lt;h4&gt;主要发现&lt;/h4&gt;GTL框架在四个不同的多模态数据集（Sketchy、TU-Berlin、Mask1K和SKSF-A）上表现优于最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;该模型能够从大量单模态数据中估计潜在概念，并利用有限样本将这些概念推广到未见模态，类似于人类的认知过程。&lt;h4&gt;总结&lt;/h4&gt;CFSL任务和GTL框架为处理多模态数据中的少样本学习提供了新的视角和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Most existing studies on few-shot learning focus on unimodal settings, wheremodels are trained to generalize on unseen data using only a small number oflabeled examples from the same modality. However, real-world data areinherently multi-modal, and unimodal approaches limit the practicalapplications of few-shot learning. To address this gap, this paper introducesthe Cross-modal Few-Shot Learning (CFSL) task, which aims to recognizeinstances from multiple modalities when only a few labeled examples areavailable. This task presents additional challenges compared to classicalfew-shot learning due to the distinct visual characteristics and structuralproperties unique to each modality. To tackle these challenges, we propose aGenerative Transfer Learning (GTL) framework consisting of two stages: thefirst stage involves training on abundant unimodal data, and the second stagefocuses on transfer learning to adapt to novel data. Our GTL framework jointlyestimates the latent shared concept across modalities and in-modalitydisturbance in both stages, while freezing the generative module during thetransfer phase to maintain the stability of the learned representations andprevent overfitting to the limited multi-modal samples. Our finds demonstratethat GTL has superior performance compared to state-of-the-art methods acrossfour distinct multi-modal datasets: Sketchy, TU-Berlin, Mask1K, and SKSF-A.Additionally, the results suggest that the model can estimate latent conceptsfrom vast unimodal data and generalize these concepts to unseen modalitiesusing only a limited number of available samples, much like human cognitiveprocesses.</description>
      <author>example@mail.com (Zhengwei Yang, Yuke Li, Qiang Sun, Basura Fernando, Heng Huang, Zheng Wang)</author>
      <guid isPermaLink="false">2410.10663v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>FedCCRL: Federated Domain Generalization with Cross-Client Representation Learning</title>
      <link>http://arxiv.org/abs/2410.11267v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;领域泛化（DG）旨在训练能够有效泛化到未见领域的模型。在联邦学习（FL）环境中，客户共同训练模型但不直接共享数据，现有的DG算法因隐私限制及每个客户的数据量和领域多样性有限而不适用。&lt;h4&gt;目的&lt;/h4&gt;提出FedCCRL，一种新颖的联邦领域泛化方法，以提高模型在未见领域的泛化能力，同时保护隐私并降低计算和通信成本。&lt;h4&gt;方法&lt;/h4&gt;将MixStyle适应于联邦设置，以转移领域特定特征，同时使用AugMix来扰动领域不变特征。此外，利用有监督对比损失进行表示对齐，并使用Jensen-Shannon散度确保原始样本和增强样本之间的一致性预测。&lt;h4&gt;主要发现&lt;/h4&gt;在PACS、OfficeHome和miniDomainNet等数据集上，FedCCRL在不同客户数量下达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;FedCCRL有效地解决了在联邦学习环境中进行领域泛化的挑战，保持了隐私性并优化了计算效率。&lt;h4&gt;总结&lt;/h4&gt;FedCCRL是一种创新的方法，提升了模型在未见领域中的泛化能力，适用于隐私敏感的联邦学习场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sanphouwang/fedccrl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain Generalization (DG) aims to train models that can effectivelygeneralize to unseen domains. However, in the context of Federated Learning(FL), where clients collaboratively train a model without directly sharingtheir data, most existing DG algorithms are not directly applicable to the FLsetting due to privacy constraints, as well as the limited data quantity anddomain diversity at each client. To tackle these challenges, we proposeFedCCRL, a novel federated domain generalization method that significantlyimproves the model's ability to generalize to unseen domains withoutcompromising privacy or incurring excessive computational and communicationcosts. Specifically, we adapt MixStyle to the federated setting to transferdomain-specific features while AugMix is employed to perturb domain-invariantfeatures. Furthermore, we leverage supervised contrastive loss forrepresentation alignment and utilize Jensen-Shannon divergence to ensureconsistent predictions between original and augmented samples. Extensiveexperimental results demonstrate that FedCCRL achieves the state-of-the-artperformances on the PACS, OfficeHome and miniDomainNet datasets across varyingnumbers of clients. Code is available athttps://github.com/SanphouWang/FedCCRL.</description>
      <author>example@mail.com (Xinpeng Wang, Xiaoying Tang)</author>
      <guid isPermaLink="false">2410.11267v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Drift Monitoring in Medical Imaging AI</title>
      <link>http://arxiv.org/abs/2410.13174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能（AI）在医疗影像中的应用推动了临床诊断的发展，但管理模型漂移和确保长期可靠性面临挑战。&lt;h4&gt;目的&lt;/h4&gt;开发MMC+框架，以实现可扩展的漂移监测，提升医疗影像AI模型的监测能力。&lt;h4&gt;方法&lt;/h4&gt;基于CheXstray框架，MMC+引入实时漂移检测，利用多模态数据一致性，扩展原有方法，提供更具可扩展性和适应性的解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;MMC+在麻省总医院的真实数据验证中有效检测到显著的数据变化，并与模型性能变化相关联。&lt;h4&gt;结论&lt;/h4&gt;MMC+作为早期预警系统，能够指示AI系统可能偏离可接受的性能范围，并促使及时干预，强调监测多样化数据流和评估数据变化的重要性。&lt;h4&gt;总结&lt;/h4&gt;本研究为AI解决方案在临床环境中的更广泛采用和整合做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of artificial intelligence (AI) into medical imaging hasadvanced clinical diagnostics but poses challenges in managing model drift andensuring long-term reliability. To address these challenges, we develop MMC+,an enhanced framework for scalable drift monitoring, building upon theCheXstray framework that introduced real-time drift detection for medicalimaging AI models using multi-modal data concordance. This work extends theoriginal framework's methodologies, providing a more scalable and adaptablesolution for real-world healthcare settings and offers a reliable andcost-effective alternative to continuous performance monitoring addressinglimitations of both continuous and periodic monitoring methods. MMC+ introducescritical improvements to the original framework, including more robust handlingof diverse data streams, improved scalability with the integration offoundation models like MedImageInsight for high-dimensional image embeddingswithout site-specific training, and the introduction of uncertainty bounds tobetter capture drift in dynamic clinical environments. Validated withreal-world data from Massachusetts General Hospital during the COVID-19pandemic, MMC+ effectively detects significant data shifts and correlates themwith model performance changes. While not directly predicting performancedegradation, MMC+ serves as an early warning system, indicating when AI systemsmay deviate from acceptable performance bounds and enabling timelyinterventions. By emphasizing the importance of monitoring diverse data streamsand evaluating data shifts alongside model performance, this work contributesto the broader adoption and integration of AI solutions in clinical settings.</description>
      <author>example@mail.com (Jameson Merkow, Felix J. Dorfner, Xiyu Yang, Alexander Ersoy, Giridhar Dasegowda, Mannudeep Kalra, Matthew P. Lungren, Christopher P. Bridge, Ivan Tarapov)</author>
      <guid isPermaLink="false">2410.13174v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>BrainMVP: Multi-modal Vision Pre-training for Brain Image Analysis using Multi-parametric MRI</title>
      <link>http://arxiv.org/abs/2410.10604v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;主成分分析（PCA）在目标数据样本过少时受到显著限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于迁移学习的主成分分析方法（TL-PCA），利用相关源任务的知识来补充目标任务的稀缺数据。&lt;h4&gt;方法&lt;/h4&gt;TL-PCA有两个版本：一个使用源任务的预训练PCA解决方案，另一个使用源数据。通过在优化目标中增加对目标子空间与源子空间接近度的惩罚，解决特征值分解问题。&lt;h4&gt;主要发现&lt;/h4&gt;在图像数据集上，TL-PCA提高了测试数据的表示，适用于降维，且学习的子空间维度可以低于或高于目标数据样本数量。&lt;h4&gt;结论&lt;/h4&gt;TL-PCA克服了标准PCA在样本不足情况下的性能限制，提供了更好的降维效果。&lt;h4&gt;总结&lt;/h4&gt;TL-PCA通过迁移学习增强了PCA的能力，尤其在样本数量有限的情况下表现优越。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate diagnosis of brain abnormalities is greatly enhanced by theinclusion of complementary multi-parametric MRI imaging data. There issignificant potential to develop a universal pre-training model that can bequickly adapted for image modalities and various clinical scenarios. However,current models often rely on uni-modal image data, neglecting the cross-modalcorrelations among different image modalities or struggling to scale uppre-training in the presence of missing modality data. In this paper, wepropose BrainMVP, a multi-modal vision pre-training framework for brain imageanalysis using multi-parametric MRI scans. First, we collect 16,022 brain MRIscans (over 2.4 million images), encompassing eight MRI modalities sourced froma diverse range of centers and devices. Then, a novel pre-training paradigm isproposed for the multi-modal MRI data, addressing the issue of missingmodalities and achieving multi-modal information fusion. Cross-modalreconstruction is explored to learn distinctive brain image embeddings andefficient modality fusion capabilities. A modality-wise data distillationmodule is proposed to extract the essence representation of each MR imagemodality for both the pre-training and downstream application purposes.Furthermore, we introduce a modality-aware contrastive learning module toenhance the cross-modality association within a study. Extensive experiments ondownstream tasks demonstrate superior performance compared to state-of-the-artpre-training methods in the medical domain, with Dice Score improvement of0.28%-14.47% across six segmentation benchmarks and a consistent accuracyimprovement of 0.65%-18.07% in four individual classification tasks.</description>
      <author>example@mail.com (Shaohao Rui, Lingzhi Chen, Zhenyu Tang, Lilong Wang, Mianxin Liu, Shaoting Zhang, Xiaosong Wang)</author>
      <guid isPermaLink="false">2410.10604v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>TL-PCA: Transfer Learning of Principal Component Analysis</title>
      <link>http://arxiv.org/abs/2410.10805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在科学研究和复杂代码的工程领域，人工判断往往不可靠或昂贵，需采用可扩展的监督研究方法来训练和评估AI系统。&lt;h4&gt;目的&lt;/h4&gt;探讨在生成微调数据时，数量与质量之间的权衡对二元NLP分类任务的影响。&lt;h4&gt;方法&lt;/h4&gt;研究了三种从预训练模型中获取分类知识的监督微调策略：数量主导、质量主导和混合策略，并探索了样本高效的提取方法。&lt;h4&gt;主要发现&lt;/h4&gt;发现混合策略结合低质量和高质量数据，可以在更低成本下实现更高的准确性。确立了可扩展提取方法的帕累托前沿，优化了标注成本和分类器性能的权衡。&lt;h4&gt;结论&lt;/h4&gt;大规模预训练与对不完美人类标签进行微调的组合方法，可能是可扩展监督的良好基线。&lt;h4&gt;总结&lt;/h4&gt;在实际应用中，标签质量不固定，实践者需平衡数量与质量，以优化AI系统的性能和成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Principal component analysis (PCA) can be significantly limited when there istoo few examples of the target data of interest. We propose a transfer learningapproach to PCA (TL-PCA) where knowledge from a related source task is used inaddition to the scarce data of a target task. Our TL-PCA has two versions, onethat uses a pretrained PCA solution of the source task, and another that usesthe source data. Our proposed approach extends the PCA optimization objectivewith a penalty on the proximity of the target subspace and the source subspaceas given by the pretrained source model or the source data. This optimizationis solved by eigendecomposition for which the number of data-dependenteigenvectors (i.e., principal directions of TL-PCA) is not limited to thenumber of target data examples, which is a root cause that limits the standardPCA performance. Accordingly, our results for image datasets show that therepresentation of test data is improved by TL-PCA for dimensionality reductionwhere the learned subspace dimension is lower or higher than the number oftarget data examples.</description>
      <author>example@mail.com (Sharon Hendy, Yehuda Dar)</author>
      <guid isPermaLink="false">2410.10805v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Balancing Label Quantity and Quality for Scalable Elicitation</title>
      <link>http://arxiv.org/abs/2410.13215v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在科学研究和复杂代码的工程领域，人工判断往往不可靠或昂贵，需采用可扩展的监督研究方法来训练和评估AI系统。&lt;h4&gt;目的&lt;/h4&gt;探讨在生成微调数据时，数量与质量之间的权衡对二元NLP分类任务的影响。&lt;h4&gt;方法&lt;/h4&gt;研究了三种从预训练模型中获取分类知识的监督微调策略：数量主导、质量主导和混合策略，并探索了样本高效的提取方法。&lt;h4&gt;主要发现&lt;/h4&gt;发现混合策略结合低质量和高质量数据，可以在更低成本下实现更高的准确性。确立了可扩展提取方法的帕累托前沿，优化了标注成本和分类器性能的权衡。&lt;h4&gt;结论&lt;/h4&gt;大规模预训练与对不完美人类标签进行微调的组合方法，可能是可扩展监督的良好基线。&lt;h4&gt;总结&lt;/h4&gt;在实际应用中，标签质量不固定，实践者需平衡数量与质量，以优化AI系统的性能和成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/eleutherai/scalable-elicitation&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scalable oversight studies methods of training and evaluating AI systems indomains where human judgement is unreliable or expensive, such as scientificresearch and software engineering in complex codebases. Recent work in thisarea by Burns et al. (2023) suggests that Language Models (LMs) pretrained oninternet-scale corpora exhibit an inductive bias toward producing correctanswers, even when finetuned on error-prone labels produced by a smallerlanguage model. This suggests that massive pretraining combined with finetuningon imperfect human labels may be a solid baseline method for scalableoversight. In the real world, however, label quality is not fixed:practitioners face a quantity-quality tradeoff when generating finetuning data.In this paper, we explore the microeconomics of the quantity-quality tradeoffon binary NLP classification tasks used in Burns et al. (2023). We find thatthere are three regimes of eliciting classification knowledge from pretrainedmodels using supervised finetuning: quantity-dominant, quality-dominant, and amixed regime involving the use of low- and high-quality data together to attainhigher accuracy at a lower cost than using either alone. We exploresample-efficient elicitation methods that make use of two datasets of differingqualities, and establish a Pareto frontier of scalable elicitation methods thatoptimally trade off labeling cost and classifier performance.</description>
      <author>example@mail.com (Alex Mallen, Nora Belrose)</author>
      <guid isPermaLink="false">2410.13215v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Meta-DT: Offline Meta-RL as Conditional Sequence Modeling with World Model Disentanglement</title>
      <link>http://arxiv.org/abs/2410.11448v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工通用智能的目标是开发出能够从多样经验中学习并推广到未见任务的高能力通用模型。语言和视觉领域在这一趋势上取得了显著进展，但强化学习（RL）代理在此框架下的泛化能力仍然较差。&lt;h4&gt;目的&lt;/h4&gt;提出MetaDecision Transformer (Meta-DT)来解决强化学习的泛化能力不足的问题。&lt;h4&gt;方法&lt;/h4&gt;Meta-DT利用变换器架构的序列建模能力和通过世界模型解耦进行的稳健任务表示学习，进行离线元强化学习的高效泛化。首先预训练一个上下文感知的世界模型以学习紧凑的任务表示，并将其作为上下文条件注入因果变换器中以指导任务导向的序列生成。同时，利用元策略生成的历史轨迹作为自我引导的提示，选择预测误差最大的轨迹片段构建提示，最大限度地编码与世界模型互补的任务特定信息。&lt;h4&gt;主要发现&lt;/h4&gt;在MuJoCo和Meta-World基准测试中，Meta-DT在少样本和零样本泛化能力上表现优于强基线，同时在实际应用中具有更少的前提条件。&lt;h4&gt;结论&lt;/h4&gt;所提框架在测试时不需要任何专家演示或领域知识，展现了较强的泛化能力和实际应用价值。&lt;h4&gt;总结&lt;/h4&gt;Meta-DT通过创新的模型设计和有效的任务表示学习，提升了强化学习在复杂任务中的泛化能力，为人工通用智能的发展提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nju-rl/meta-dt&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A longstanding goal of artificial general intelligence is highly capablegeneralists that can learn from diverse experiences and generalize to unseentasks. The language and vision communities have seen remarkable progress towardthis trend by scaling up transformer-based models trained on massive datasets,while reinforcement learning (RL) agents still suffer from poor generalizationcapacity under such paradigms. To tackle this challenge, we propose MetaDecision Transformer (Meta-DT), which leverages the sequential modeling abilityof the transformer architecture and robust task representation learning viaworld model disentanglement to achieve efficient generalization in offlinemeta-RL. We pretrain a context-aware world model to learn a compact taskrepresentation, and inject it as a contextual condition to the causaltransformer to guide task-oriented sequence generation. Then, we subtly utilizehistory trajectories generated by the meta-policy as a self-guided prompt toexploit the architectural inductive bias. We select the trajectory segment thatyields the largest prediction error on the pretrained world model to constructthe prompt, aiming to encode task-specific information complementary to theworld model maximally. Notably, the proposed framework eliminates therequirement of any expert demonstration or domain knowledge at test time.Experimental results on MuJoCo and Meta-World benchmarks across various datasettypes show that Meta-DT exhibits superior few and zero-shot generalizationcapacity compared to strong baselines while being more practical with fewerprerequisites. Our code is available at https://github.com/NJU-RL/Meta-DT.</description>
      <author>example@mail.com (Zhi Wang, Li Zhang, Wenhao Wu, Yuanheng Zhu, Dongbin Zhao, Chunlin Chen)</author>
      <guid isPermaLink="false">2410.11448v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>QueST: Querying Functional and Structural Niches on Spatial Transcriptomics Data via Contrastive Subgraph Embedding</title>
      <link>http://arxiv.org/abs/2410.10652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;组织内的功能或结构空间区域被称为空间生态位，是多细胞生物空间背景的重要元素。&lt;h4&gt;目的&lt;/h4&gt;开发一种模型以查询不同组织间共享的生态位，以全面理解细胞群体的组织和表型。&lt;h4&gt;方法&lt;/h4&gt;提出QueST，一种新颖的生态位表示学习模型，采用子图对比学习方法捕捉生态位特征，并结合对抗训练以减轻批次效应。&lt;h4&gt;主要发现&lt;/h4&gt;在使用人类和小鼠数据集的基准测试中，QueST在准确的生态位查询方面优于现有的图表示学习方法。&lt;h4&gt;结论&lt;/h4&gt;QueST为空间生态位查询提供了专门模型，为深入理解细胞空间组织的模式和机制铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;QueST展示了在多样本中有效查询空间生态位的潜力，促进了对细胞空间组织的深入研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cmhimself/quest&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The functional or structural spatial regions within tissues, referred to asspatial niches, are elements for illustrating the spatial contexts ofmulticellular organisms. A key challenge is querying shared niches acrossdiverse tissues, which is crucial for achieving a comprehensive understandingof the organization and phenotypes of cell populations. However, current dataanalysis methods predominantly focus on creating spatial-aware embeddings forcells, neglecting the development of niche-level representations for effectivequerying. To address this gap, we introduce QueST, a novel niche representationlearning model designed for querying spatial niches across multiple samples.QueST utilizes a novel subgraph contrastive learning approach to explicitlycapture niche-level characteristics and incorporates adversarial training tomitigate batch effects. We evaluate QueST on established benchmarks using humanand mouse datasets, demonstrating its superiority over state-of-the-art graphrepresentation learning methods in accurate niche queries. Overall, QueSToffers a specialized model for spatial niche queries, paving the way for deeperinsights into the patterns and mechanisms of cell spatial organization acrosstissues. Source code can be found at https://github.com/cmhimself/QueST.</description>
      <author>example@mail.com (Mo Chen, Minsheng Hao, Xuegong Zhang, Lei Wei)</author>
      <guid isPermaLink="false">2410.10652v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>FragNet: A Graph Neural Network for Molecular Property Prediction with Four Layers of Interpretability</title>
      <link>http://arxiv.org/abs/2410.12156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;分子性质预测在药物发现和能源存储材料设计等现代科学应用中至关重要。&lt;h4&gt;目的&lt;/h4&gt;引入一种既能提供高准确性又能解释预测结果的模型。&lt;h4&gt;方法&lt;/h4&gt;提出FragNet架构，这是一种图神经网络。&lt;h4&gt;主要发现&lt;/h4&gt;FragNet的预测准确性可与当前最先进的模型相媲美，同时能够在四个层面上提供分子子结构的洞见。&lt;h4&gt;结论&lt;/h4&gt;FragNet能够解释在预测分子性质时，关键的原子、键、分子片段和分子片段连接的作用，特别是对于那些没有常规共价键连接的子结构。&lt;h4&gt;总结&lt;/h4&gt;FragNet的可解释性有助于从模型学习到的分子结构与性质之间的模式中获得科学洞见。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular property prediction is a crucial step in many modern-day scientificapplications including drug discovery and energy storage material design.Despite the availability of numerous machine learning models for this task, weare lacking in models that provide both high accuracies and interpretability ofthe predictions. We introduce the FragNet architecture, a graph neural networknot only capable of achieving prediction accuracies comparable to the currentstate-of-the-art models, but also able to provide insight on four levels ofmolecular substructures. This model enables understanding of which atoms,bonds, molecular fragments, and molecular fragment connections are critical inthe prediction of a given molecular property. The ability to interpret theimportance of connections between fragments is of particular interest formolecules which have substructures that are not connected with regular covalentbonds. The interpretable capabilities of FragNet are key to gaining scientificinsights from the model's learned patterns between molecular structure andmolecular properties.</description>
      <author>example@mail.com (Gihan Panapitiya, Peiyuan Gao, C Mark Maupin, Emily G Saldanha)</author>
      <guid isPermaLink="false">2410.12156v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Improving Bias in Facial Attribute Classification: A Combined Impact of KL Divergence induced Loss Function and Dual Attention</title>
      <link>http://arxiv.org/abs/2410.11176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 9 figures, 5 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;AI人脸识别系统的公平性至关重要，早期系统常表现出人口统计偏见，特别是在性别和种族分类上，女性和肤色较深的个体准确率较低。&lt;h4&gt;目的&lt;/h4&gt;解决人脸识别中的偏见问题，促进系统在各人口群体之间的公平性。&lt;h4&gt;方法&lt;/h4&gt;采用双重注意机制，结合预训练的Inception-ResNet V1模型，并通过KL散度正则化和交叉熵损失函数进行增强。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在减少偏见的同时，提高了准确性和计算效率，实验结果显示公平性和分类准确性均有显著改善。&lt;h4&gt;结论&lt;/h4&gt;该研究提供了有效的解决方案，增强了人脸识别系统的可靠性，推动了偏见问题的解决。&lt;h4&gt;总结&lt;/h4&gt;本论文提出的方法为改善人脸识别系统的公平性和准确性提供了新的思路，具有重要的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring that AI-based facial recognition systems produce fair predictionsand work equally well across all demographic groups is crucial. Earlier systemsoften exhibited demographic bias, particularly in gender and racialclassification, with lower accuracy for women and individuals with darker skintones. To tackle this issue and promote fairness in facial recognition,researchers have introduced several bias-mitigation techniques for genderclassification and related algorithms. However, many challenges remain, such asdata diversity, balancing fairness with accuracy, disparity, and biasmeasurement. This paper presents a method using a dual attention mechanism witha pre-trained Inception-ResNet V1 model, enhanced by KL-divergenceregularization and a cross-entropy loss function. This approach reduces biaswhile improving accuracy and computational efficiency through transferlearning. The experimental results show significant improvements in bothfairness and classification accuracy, providing promising advances inaddressing bias and enhancing the reliability of facial recognition systems.</description>
      <author>example@mail.com (Shweta Patel, Dakshina Ranjan Kisku)</author>
      <guid isPermaLink="false">2410.11176v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Parameterize Structure with Differentiable Template for 3D Shape Generation</title>
      <link>http://arxiv.org/abs/2410.10399v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;结构表示对重建和生成具有部件语义的可编辑3D形状至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以参数化同一类别中共享结构，关注部件内部细节。&lt;h4&gt;方法&lt;/h4&gt;使用可微模板和固定长度参数来表示形状，特定参数计算表示具体形状的立方体，并利用三视图绘图的边界描述内部细节。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够有效重建或生成具有复杂细节的多样形状，并实现平滑插值。&lt;h4&gt;结论&lt;/h4&gt;通过固定长度参数和三视图细节，所提出的网络在点云重建、生成和插值方面表现优越。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种简单有效的网络结构，提升了3D形状生成与重建的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Structural representation is crucial for reconstructing and generatingeditable 3D shapes with part semantics. Recent 3D shape generation works employcomplicated networks and structure definitions relying on hierarchicalannotations and pay less attention to the details inside parts. In this paper,we propose the method that parameterizes the shared structure in the samecategory using a differentiable template and corresponding fixed-lengthparameters. Specific parameters are fed into the template to calculate cuboidsthat indicate a concrete shape. We utilize the boundaries of three-viewdrawings of each cuboid to further describe the inside details. Shapes arerepresented with the parameters and three-view details inside cuboids, fromwhich the SDF can be calculated to recover the object. Benefiting from ourfixed-length parameters and three-view details, our networks for reconstructionand generation are simple and effective to learn the latent space. Our methodcan reconstruct or generate diverse shapes with complicated details, andinterpolate them smoothly. Extensive evaluations demonstrate the superiority ofour method on reconstruction from point cloud, generation, and interpolation.</description>
      <author>example@mail.com (Changfeng Ma, Pengxiao Guo, Shuangyu Yang, Yinuo Chen, Jie Guo, Chongjun Wang, Yanwen Guo, Wenping Wang)</author>
      <guid isPermaLink="false">2410.10399v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Towards Fair Graph Representation Learning in Social Networks</title>
      <link>http://arxiv.org/abs/2410.11493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在网络数据的表示学习中广泛应用，近年来对GNN模型的公平性引起了广泛关注。&lt;h4&gt;目的&lt;/h4&gt;确保节点表示能够被准确分类，但不易与特定群体关联。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为公平意识图神经网络（EAGNN）的方法，通过引入基于充分性、独立性和分离性的约束来实现公平表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;GNN在社交网络学习中的不公平性源于社交同质性，即同一群体的用户更倾向于聚集，导致模型预测与敏感属性建立虚假的关联。&lt;h4&gt;结论&lt;/h4&gt;EAGNN方法能够有效实现群体公平性，在三个不同社交同质性水平的数据集上，EAGNN在两项公平性指标上达到了最先进的性能，并且效果具有竞争力。&lt;h4&gt;总结&lt;/h4&gt;本研究通过EAGNN方法提升了GNN在公平表示学习中的表现，有助于解决社交网络中的公平性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the widespread use of Graph Neural Networks (GNNs) for representationlearning from network data, the fairness of GNN models has raised greatattention lately. Fair GNNs aim to ensure that node representations can beaccurately classified, but not easily associated with a specific group.Existing advanced approaches essentially enhance the generalisation of noderepresentation in combination with data augmentation strategy, and do notdirectly impose constraints on the fairness of GNNs. In this work, we identifythat a fundamental reason for the unfairness of GNNs in social network learningis the phenomenon of social homophily, i.e., users in the same group are moreinclined to congregate. The message-passing mechanism of GNNs can cause usersin the same group to have similar representations due to social homophily,leading model predictions to establish spurious correlations with sensitiveattributes. Inspired by this reason, we propose a method called Equity-AwareGNN (EAGNN) towards fair graph representation learning. Specifically, to ensurethat model predictions are independent of sensitive attributes whilemaintaining prediction performance, we introduce constraints for fairrepresentation learning based on three principles: sufficiency, independence,and separation. We theoretically demonstrate that our EAGNN method caneffectively achieve group fairness. Extensive experiments on three datasetswith varying levels of social homophily illustrate that our EAGNN methodachieves the state-of-the-art performance across two fairness metrics andoffers competitive effectiveness.</description>
      <author>example@mail.com (Guixian Zhang, Guan Yuan, Debo Cheng, Lin Liu, Jiuyong Li, Shichao Zhang)</author>
      <guid isPermaLink="false">2410.11493v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Fundus to Fluorescein Angiography Video Generation as a Retinal Generative Foundation Model</title>
      <link>http://arxiv.org/abs/2410.13242v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;眼底荧光素血管造影（FFA）对诊断和监测视网膜血管问题至关重要，但其侵入性和可及性有限，相比于彩色眼底（CF）成像。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，将CF图像转换为动态FFA视频，以克服现有静态图像生成方法的局限。&lt;h4&gt;方法&lt;/h4&gt;引入Fundus2Video，一个自回归生成对抗网络（GAN）模型，从单一CF图像生成动态FFA视频。&lt;h4&gt;主要发现&lt;/h4&gt;Fundus2Video在视频生成方面表现卓越，FVD为1497.12，PSNR为11.77。临床专家验证了生成视频的真实性。&lt;h4&gt;结论&lt;/h4&gt;该模型的生成器在十个外部公共数据集上展现出显著的下游迁移能力，包括血管分割、视网膜疾病诊断、系统性疾病预测和多模态检索，表现出出色的零样本和少量样本能力。&lt;h4&gt;总结&lt;/h4&gt;Fundus2Video作为FFA检查的强大非侵入性替代方案，是一个多功能的视网膜生成基础模型，能够捕捉静态和时间维度的视网膜特征，表现出复杂的跨模态关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fundus fluorescein angiography (FFA) is crucial for diagnosing and monitoringretinal vascular issues but is limited by its invasive nature and restrictedaccessibility compared to color fundus (CF) imaging. Existing methods thatconvert CF images to FFA are confined to static image generation, missing thedynamic lesional changes. We introduce Fundus2Video, an autoregressivegenerative adversarial network (GAN) model that generates dynamic FFA videosfrom single CF images. Fundus2Video excels in video generation, achieving anFVD of 1497.12 and a PSNR of 11.77. Clinical experts have validated thefidelity of the generated videos. Additionally, the model's generatordemonstrates remarkable downstream transferability across ten external publicdatasets, including blood vessel segmentation, retinal disease diagnosis,systemic disease prediction, and multimodal retrieval, showcasing impressivezero-shot and few-shot capabilities. These findings position Fundus2Video as apowerful, non-invasive alternative to FFA exams and a versatile retinalgenerative foundation model that captures both static and temporal retinalfeatures, enabling the representation of complex inter-modality relationships.</description>
      <author>example@mail.com (Weiyi Zhang, Jiancheng Yang, Ruoyu Chen, Siyu Huang, Pusheng Xu, Xiaolan Chen, Shanfu Lu, Hongyu Cao, Mingguang He, Danli Shi)</author>
      <guid isPermaLink="false">2410.13242v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Power of LLMs as Multi-Modal Encoders for Text and Graph-Structured Data</title>
      <link>http://arxiv.org/abs/2410.11235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在多标签情感分类中，尤其是对于阿拉伯语等资源匮乏语言，类不平衡和标签相关性的问题影响了模型性能，尤其是在准确预测小众情感方面。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，结合堆叠嵌入、元学习和混合损失函数，以增强阿拉伯语的多标签情感分类。&lt;h4&gt;方法&lt;/h4&gt;从三个微调的语言模型（ArabicBERT、MarBERT和AraBERT）中提取上下文嵌入，然后将其堆叠形成丰富的嵌入。通过元学习器在这些堆叠嵌入上进行训练，最终将连接的表示输入到Bi-LSTM模型，并通过全连接神经网络进行多标签分类。此外，引入混合损失函数，结合类加权、标签相关矩阵和对比学习，有效解决类不平衡和标签相关性的问题。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验验证了所提模型在精确度、召回率、F1分数、Jaccard准确率和汉明损失等关键指标上的表现。类级性能分析表明，混合损失函数显著减少了多数类和少数类之间的差异，实现了更平衡的情感分类。&lt;h4&gt;结论&lt;/h4&gt;本研究不仅推进了阿拉伯语的多标签情感分类，还提供了一个可适应其他语言和领域的通用框架，为解决资源匮乏情感分类任务的挑战迈出了重要一步。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的方法有效改善了阿拉伯语情感分类的性能，展示了在处理低资源语言情感分类任务中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph-structured information offers rich contextual information that canenhance language models by providing structured relationships and hierarchies,leading to more expressive embeddings for various applications such asretrieval, question answering, and classification. However, existing methodsfor integrating graph and text embeddings, often based on Multi-layerPerceptrons (MLPs) or shallow transformers, are limited in their ability tofully exploit the heterogeneous nature of these modalities. To overcome this,we propose Janus, a simple yet effective framework that leverages LargeLanguage Models (LLMs) to jointly encode text and graph data. Specifically,Janus employs an MLP adapter to project graph embeddings into the same space astext embeddings, allowing the LLM to process both modalities jointly. Unlikeprior work, we also introduce contrastive learning to align the graph and textspaces more effectively, thereby improving the quality of learned jointembeddings. Empirical results across six datasets spanning three tasks,knowledge graph-contextualized question answering, graph-text pairclassification, and retrieval, demonstrate that Janus consistently outperformsexisting baselines, achieving significant improvements across multipledatasets, with gains of up to 11.4% in QA tasks. These results highlightJanus's effectiveness in integrating graph and text data. Ablation studiesfurther validate the effectiveness of our method.</description>
      <author>example@mail.com (Jiacheng Lin, Kun Qian, Haoyu Han, Nurendra Choudhary, Tianxin Wei, Zhongruo Wang, Sahika Genc, Edward W Huang, Sheng Wang, Karthik Subbian, Danai Koutra, Jimeng Sun)</author>
      <guid isPermaLink="false">2410.11235v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Improving Arabic Multi-Label Emotion Classification using Stacked Embeddings and Hybrid Loss Function</title>
      <link>http://arxiv.org/abs/2410.03979v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper is withdrawn due to an authorship dispute. Contributors who
  were part of the project but lacked significant contributions were not
  included as authors. The authorship details may be revised, and a replacement
  submitted after resolving the dispute. Content changes may follow, which will
  be reflected in the revised version. Thank you for your understanding&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;张力完整性机器人由刚性支柱和柔性电缆组成，是一种新兴的混合刚柔机器人系统，适用于多种应用，从运动到组装。&lt;h4&gt;目的&lt;/h4&gt;解决张力完整性机器人在控制和建模方面的困难，特别是由于其柔性和高自由度带来的问题。&lt;h4&gt;方法&lt;/h4&gt;提出使用图神经网络对张力完整性机器人的接触动态进行建模，利用其在刚性杆端帽之间的自然图状电缆连接。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的学习模拟器能够在模拟到模拟的实验中准确模拟3杆和6杆张力完整性机器人动态，且在现实3杆张力完整性机器人上表现出更高的准确性。&lt;h4&gt;结论&lt;/h4&gt;该方法在训练和推理时计算效率更高，同时比最近的基于网格的图神经网络模拟器更具准确性。&lt;h4&gt;代码和数据&lt;/h4&gt;可在https://github.com/nchen9191/tensegrity_gnn_simulator_public 获取。&lt;h4&gt;总结&lt;/h4&gt;本研究通过图神经网络提供了一种新方法来高效建模张力完整性机器人的动态，克服了传统方法的限制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In multi-label emotion classification, particularly for low-resourcelanguages like Arabic, the challenges of class imbalance and label correlationhinder model performance, especially in accurately predicting minorityemotions. To address these issues, this study proposes a novel approach thatcombines stacked embeddings, meta-learning, and a hybrid loss function toenhance multi-label emotion classification for the Arabic language. The studyextracts contextual embeddings from three fine-tuned languagemodels-ArabicBERT, MarBERT, and AraBERT-which are then stacked to form enrichedembeddings. A meta-learner is trained on these stacked embeddings, and theresulting concatenated representations are provided as input to a Bi-LSTMmodel, followed by a fully connected neural network for multi-labelclassification. To further improve performance, a hybrid loss function isintroduced, incorporating class weighting, label correlation matrix, andcontrastive learning, effectively addressing class imbalances and improving thehandling of label correlations. Extensive experiments validate the proposedmodel's performance across key metrics such as Precision, Recall, F1-Score,Jaccard Accuracy, and Hamming Loss. The class-wise performance analysisdemonstrates the hybrid loss function's ability to significantly reducedisparities between majority and minority classes, resulting in a more balancedemotion classification. An ablation study highlights the contribution of eachcomponent, showing the superiority of the model compared to baseline approachesand other loss functions. This study not only advances multi-label emotionclassification for Arabic but also presents a generalizable framework that canbe adapted to other languages and domains, providing a significant step forwardin addressing the challenges of low-resource emotion classification tasks.</description>
      <author>example@mail.com (Nisar Ahmed, Muhammad Imran Zaman)</author>
      <guid isPermaLink="false">2410.03979v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Learning Differentiable Tensegrity Dynamics using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.12216v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;引力波的探测为观察宇宙提供了前所未有的机会，特别是在黑洞螺旋的研究中。这些事件为在极端能量条件下探索物理法则提供了独特实验室。&lt;h4&gt;目的&lt;/h4&gt;解决引力波数据中噪声对信号识别的重大挑战。&lt;h4&gt;方法&lt;/h4&gt;采用简化的AI架构，开发了一种新颖的训练方法，以准确检测复杂噪声中的引力波。&lt;h4&gt;主要发现&lt;/h4&gt;模型在非白噪声场景下的准确率超过99%，并展示了对变化的噪声功率谱密度（PSD）条件的显著适应性。&lt;h4&gt;结论&lt;/h4&gt;通过迁移学习原理，模型能够在少量微调后快速适应新的噪声特征，实现动态变化噪声环境中的实时应用。&lt;h4&gt;总结&lt;/h4&gt;该研究为引力波信号检测提供了一种有效的AI解决方案，克服了传统噪声抑制方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tensegrity robots are composed of rigid struts and flexible cables. Theyconstitute an emerging class of hybrid rigid-soft robotic systems and arepromising systems for a wide array of applications, ranging from locomotion toassembly. They are difficult to control and model accurately, however, due totheir compliance and high number of degrees of freedom. To address this issue,prior work has introduced a differentiable physics engine designed fortensegrity robots based on first principles. In contrast, this work proposesthe use of graph neural networks to model contact dynamics over a graphrepresentation of tensegrity robots, which leverages their natural graph-likecable connectivity between end caps of rigid rods. This learned simulator canaccurately model 3-bar and 6-bar tensegrity robot dynamics insimulation-to-simulation experiments where MuJoCo is used as the ground truth.It can also achieve higher accuracy than the previous differentiable engine fora real 3-bar tensegrity robot, for which the robot state is only partiallyobservable. When compared against direct applications of recent mesh-basedgraph neural network simulators, the proposed approach is computationally moreefficient, both for training and inference, while achieving higher accuracy.Code and data are available athttps://github.com/nchen9191/tensegrity_gnn_simulator_public</description>
      <author>example@mail.com (Nelson Chen, Kun Wang, William R. Johnson III, Rebecca Kramer-Bottiglio, Kostas Bekris, Mridul Aanjaneya)</author>
      <guid isPermaLink="false">2410.12216v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning Adapts to Changing PSD in Gravitational Wave Data</title>
      <link>http://arxiv.org/abs/2410.11911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;引力波的探测为观察宇宙Ns）的分析一直是计算神经科学的重点研究方向。&lt;h4&gt;目的&lt;/h4&gt;解决BNN分析中神经元与突触动态、连接模式及学习过程之间的关系。&lt;h4&gt;方法&lt;/h4&gt;引入一种基于网络表示学习（NRL）的新型BNN分析框架，利用注意力分数揭示网络组件及其特征之间的复杂关系。&lt;h4&gt;主要发现&lt;/h4&gt;框架集成了基于计算图（CG）的BNN表示、一个生物启发的图注意力网络（BGAN），支持多尺度的相关性分析，并构建了一个广泛的BNN数据集。&lt;h4&gt;结论&lt;/h4&gt;该研究首次将NRL方法应用于BNNs的全面分析，揭示了神经元的组成结构及信息流。&lt;h4&gt;总结&lt;/h4&gt;本研究通过创新的方法深化了对生物物理神经网络的理解，为未来的研究提供了新的工具和数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The detection of gravitational waves has opened unparalleled opportunitiesfor observing the universe, particularly through the study of black holeinspirals. These events serve as unique laboratories to explore the laws ofphysics under conditions of extreme energies. However, significant noise ingravitational wave (GW) data from observatories such as Advanced LIGO and Virgoposes major challenges in signal identification. Traditional noise suppressionmethods often fall short in fully addressing the non-Gaussian effects in thedata, including the fluctuations in noise power spectral density (PSD) overshort time intervals. These challenges have led to the exploration of an AIapproach that, while overcoming previous obstacles, introduced its ownchallenges, such as scalability, reliability issues, and the vanishing gradientproblem. Our approach addresses these issues through a simplified architecture.To compensate for the potential limitations of a simpler model, we havedeveloped a novel training methodology that enables it to accurately detectgravitational waves amidst highly complex noise. Employing this strategy, ourmodel achieves over 99% accuracy in non-white noise scenarios and showsremarkable adaptability to changing noise PSD conditions. By leveraging theprinciples of transfer learning, our model quickly adapts to new noise profileswith just a few epochs of fine-tuning, facilitating real-time applications indynamically changing noise environments.</description>
      <author>example@mail.com (Beka Modrekiladze)</author>
      <guid isPermaLink="false">2410.11911v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Network Representation Learning for Biophysical Neural Network Analysis</title>
      <link>http://arxiv.org/abs/2410.11503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, Work-In-Progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云的语义分割是自动驾驶和机器人领域理解环境的重要任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来处理小数据集下的语义分割问题，同时兼顾实时性和准确性。&lt;h4&gt;方法&lt;/h4&gt;利用三维表示捕捉局部特征，引入范围图像表示以整合额外信息并加速计算，使用基于GPU的KDTree进行快速构建和查询。&lt;h4&gt;主要发现&lt;/h4&gt;在SemanticKITTI和nuScenes数据集上的广泛实验表明，所提出的方法在小数据集和传统设置下均表现良好。&lt;h4&gt;结论&lt;/h4&gt;我们的方法的简化版本在与全尺度最先进模型的竞争中表现出色，且能够实时运行，适用于实际应用场景。&lt;h4&gt;总结&lt;/h4&gt;通过结合三维表示和范围图像表示，我们的模型在语义分割任务中实现了高效性和高准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The analysis of biophysical neural networks (BNNs) has been a longstandingfocus in computational neuroscience. A central yet unresolved challenge in BNNanalysis lies in deciphering the correlations between neuronal and synapticdynamics, their connectivity patterns, and learning process. To address this,we introduce a novel BNN analysis framework grounded in network representationlearning (NRL), which leverages attention scores to uncover intricatecorrelations between network components and their features. Our frameworkintegrates a new computational graph (CG)-based BNN representation, abio-inspired graph attention network (BGAN) that enables multiscale correlationanalysis across BNN representations, and an extensive BNN dataset. The CG-basedrepresentation captures key computational features, information flow, andstructural relationships underlying neuronal and synaptic dynamics, while BGANreflects the compositional structure of neurons, including dendrites, somas,and axons, as well as bidirectional information flows between BNN components.The dataset comprises publicly available models from ModelDB, reconstructedusing the Python and standardized in NeuroML format, and is augmented with dataderived from canonical neuron and synapse models. To our knowledge, this studyis the first to apply an NRL-based approach to the full spectrum of BNNs andtheir analysis.</description>
      <author>example@mail.com (Youngmok Ha, Yongjoo Kim, Hyun Jae Jang, Seungyeon Lee, Eunji Pak)</author>
      <guid isPermaLink="false">2410.11503v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Exploiting Local Features and Range Images for Small Data Real-Time Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.10510v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for publication at the 2024 IEEE/RSJ
  International Conference on Intelligent Robots and Systems (IROS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）的成功促使对语音和音频数据的整合努力，旨在创建能够处理文本和非文本输入的通用基础模型。&lt;h4&gt;目的&lt;/h4&gt;指导语音LLMs的发展，提出一个五级路线图，从基本的自动语音识别（ASR）到能够将非语义信息与抽象声学知识整合的超人类模型。&lt;h4&gt;方法&lt;/h4&gt;设计了SAGI基准，标准化各个任务在五个层级中的关键方面，以揭示使用抽象声学知识和能力完整性方面的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;发现处理副语言线索和抽象声学知识方面存在差距。&lt;h4&gt;结论&lt;/h4&gt;本文概述了推进语音LLMs的路线图，介绍了评估基准，并提供了对其当前局限性和潜力的关键见解。&lt;h4&gt;总结&lt;/h4&gt;研究为语音LLMs的发展提供了方向，强调了现有技术的不足及未来改进的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bender97/waffleandrange&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation of point clouds is an essential task for understandingthe environment in autonomous driving and robotics. Recent range-based worksachieve real-time efficiency, while point- and voxel-based methods producebetter results but are affected by high computational complexity. Moreover,highly complex deep learning models are often not suited to efficiently learnfrom small datasets. Their generalization capabilities can easily be driven bythe abundance of data rather than the architecture design. In this paper, weharness the information from the three-dimensional representation toproficiently capture local features, while introducing the range imagerepresentation to incorporate additional information and facilitate fastcomputation. A GPU-based KDTree allows for rapid building, querying, andenhancing projection with straightforward operations. Extensive experiments onSemanticKITTI and nuScenes datasets demonstrate the benefits of ourmodification in a ``small data'' setup, in which only one sequence of thedataset is used to train the models, but also in the conventional setup, whereall sequences except one are used for training. We show that a reduced versionof our model not only demonstrates strong competitiveness against full-scalestate-of-the-art models but also operates in real-time, making it a viablechoice for real-world case applications. The code of our method is available athttps://github.com/Bender97/WaffleAndRange.</description>
      <author>example@mail.com (Daniel Fusaro, Simone Mosco, Emanuele Menegatti, Alberto Pretto)</author>
      <guid isPermaLink="false">2410.10510v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Roadmap towards Superhuman Speech Understanding using Large Language Models</title>
      <link>http://arxiv.org/abs/2410.13268v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）在无标签图中学习表示的能力强，因此在社区检测任务中表现优异。&lt;h4&gt;目的&lt;/h4&gt;考虑社区结构的语义，以提出一种有效的图对比学习框架（GCLS²）用于检测社区。&lt;h4&gt;方法&lt;/h4&gt;结合社区的内部密集和外部稀疏特性，利用经典社区结构提取高层次结构视图，并设计结构语义表达模块来增强原始特征表示，同时制定结构对比损失以优化节点的特征表示。&lt;h4&gt;主要发现&lt;/h4&gt;在各种真实世界的图数据集上进行的广泛实验表明，GCLS²在检测社区的准确性和模块性方面优于八种最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;GCLS²能够更好地捕捉社区的拓扑结构，从而提高社区检测的效果。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的GCLS²框架有效结合了社区结构的语义特征，显著提升了社区检测的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The success of large language models (LLMs) has prompted efforts to integratespeech and audio data, aiming to create general foundation models capable ofprocessing both textual and non-textual inputs. Recent advances, such asGPT-4o, highlight the potential for end-to-end speech LLMs, which preservesnon-semantic information and world knowledge for deeper speech understanding.To guide the development of speech LLMs, we propose a five-level roadmap,ranging from basic automatic speech recognition (ASR) to advanced superhumanmodels capable of integrating non-semantic information with abstract acousticknowledge for complex tasks. Moreover, we design a benchmark, SAGI Bechmark,that standardizes critical aspects across various tasks in these five levels,uncovering challenges in using abstract acoustic knowledge and completeness ofcapability. Our findings reveal gaps in handling paralinguistic cues andabstract acoustic knowledge, and we offer future directions. This paperoutlines a roadmap for advancing speech LLMs, introduces a benchmark forevaluation, and provides key insights into their current limitations andpotential.</description>
      <author>example@mail.com (Fan Bu, Yuhao Zhang, Xidong Wang, Benyou Wang, Qun Liu, Haizhou Li)</author>
      <guid isPermaLink="false">2410.13268v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>GCLS$^2$: Towards Efficient Community Detection using Graph Contrastive Learning with Structure Semantics</title>
      <link>http://arxiv.org/abs/2410.11273v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高计算能力和大量数据的可用性支持了基础模型的发展，这是一种广泛用于生成人工智能的新兴技术。&lt;h4&gt;目的&lt;/h4&gt;提出LLIAM模型，即Llama Lora-集成自回归模型，旨在提升模型在多样时间序列数据集上的知识。&lt;h4&gt;方法&lt;/h4&gt;使用低秩适应（Low-Rank Adaptations）来增强模型的知识，并进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;进行了两组实验，获得了良好且有前景的结果，训练时间低于其他深度学习方法。&lt;h4&gt;结论&lt;/h4&gt;鼓励利用可用资源（如预训练模型）来避免不必要和昂贵的训练，缩小传统人工智能与绿色人工智能目标之间的差距。&lt;h4&gt;总结&lt;/h4&gt;基础模型的可扩展性和适应性为多种任务提供了坚实基础，促进了深度学习领域的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to powerful ability to learn representations from unlabeled graphs, graphcontrastive learning (GCL) has shown excellent performance in communitydetection tasks. Existing GCL-based methods on the community detection usuallyfocused on learning attribute representations of individual nodes, which,however, ignores structure semantics of communities (e.g., nodes in the samecommunity should be close to each other). Therefore, in this paper, we willconsider the semantics of community structures for the community detection, andpropose an effective framework of graph contrastive learning under structuresemantics (GCLS$^2$) for detecting communities. To seamlessly integrateinterior dense and exterior sparse characteristics of communities with ourcontrastive learning strategy, we employ classic community structures toextract high-level structural views and design a structure semantic expressionmodule to augment the original structural feature representation. Moreover, weformulate the structure contrastive loss to optimize the feature representationof nodes, which can better capture the topology of communities. Extensiveexperiments have been conducted on various real-world graph datasets andconfirmed that GCLS$^2$ outperforms eight state-of-the-art methods, in terms ofthe accuracy and modularity of the detected communities.</description>
      <author>example@mail.com (Qi Wen, Yiyang Zhang, Yutong Ye, Yingbo Zhou, Nan Zhang, Xiang Lian, Mingsong Chen)</author>
      <guid isPermaLink="false">2410.11273v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning with Foundational Models for Time Series Forecasting using Low-Rank Adaptations</title>
      <link>http://arxiv.org/abs/2410.11539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，3D视觉已成为计算机视觉的重要领域，应用于自动驾驶、机器人、增强现实和医学成像等多个领域。&lt;h4&gt;目的&lt;/h4&gt;探讨使用扩散模型在3D视觉任务中的应用潜力和效果。&lt;h4&gt;方法&lt;/h4&gt;回顾利用扩散模型的最先进方法，包括3D物体生成、形状补全、点云重建和场景理解。&lt;h4&gt;主要发现&lt;/h4&gt;扩散模型能够更灵活、以概率的方式捕捉现实世界3D数据中的变异性和不确定性，但传统方法在效率和可扩展性方面存在挑战。&lt;h4&gt;结论&lt;/h4&gt;讨论了扩散模型在3D视觉中的关键挑战及潜在解决方案，包括计算效率的提高、多模态融合的增强和大规模预训练的探索。&lt;h4&gt;总结&lt;/h4&gt;本文为3D视觉领域的未来探索与发展奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High computational power and the availability of large datasets havesupported the development of Foundational Models. They are a new emergingtechnique widely used in Generative Artificial Intelligence, characterized bytheir scalability and their use in Transfer Learning. The enormous andheterogeneous amounts of data used in their initial training phase, known aspre-training, give them a higher generalization capacity than any otherspecific model, constituting a solid base that can be adapted or adjusted to awide range of tasks, increasing their applicability. This study proposes LLIAM,the Llama Lora-Integrated Autorregresive Model. Low-Rank Adaptations are usedto enhance the knowledge of the model with diverse time series datasets, knownas the fine-tuning phase. To illustrate the capabilities of our proposal, twosets of experiments have been carried out that obtained favorable and promisingresults with lower training times than other Deep Learning approaches. Withthis work, we also encourage the use of available resources (such as thesepre-trained models) to avoid unnecessary and costly training, narrowing the gapbetween the goals of traditional Artificial Intelligence and those specified bythe definition of Green Artificial Intelligence.</description>
      <author>example@mail.com (M. Germán-Morales, A. J. Rivera-Rivas, M. J. del Jesus Díaz, C. J. Carmona)</author>
      <guid isPermaLink="false">2410.11539v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion Models in 3D Vision: A Survey</title>
      <link>http://arxiv.org/abs/2410.04738v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;表示学习在下游任务中变得越来越重要，特别是在强大的模型转向学习潜在表示后进行微调时。这种方法在利用脑解剖结构中的结构信息方面尤为有价值。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，通过强制在三维空间中进行等变性（SO(3)-等变性），以改善对脑结构的详细解剖信息的学习。&lt;h4&gt;方法&lt;/h4&gt;开发了一种编码3D MRI的新方法，显式建模几何等变性，确保对输入图像空间应用的旋转操作在嵌入表示空间中也能反映出来。&lt;h4&gt;主要发现&lt;/h4&gt;SOE模型在两个公共数据集上进行预训练，并在预测年龄和诊断阿尔茨海默病的任务中表现优于其他方法，并且对不同轴的旋转具有较强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过该方法，脑的结构和解剖信息的捕获更加有效，证明了几何知识的引入能显著提高表示学习的性能。&lt;h4&gt;总结&lt;/h4&gt;该研究表明，利用几何变换知识可以提升MRI表示学习的效果，提供了一种新的思路和方法来改进脑部影像分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, 3D vision has become a crucial field within computer vision,powering a wide range of applications such as autonomous driving, robotics,augmented reality (AR), and medical imaging. This field relies on the accurateperception, understanding, and reconstruction of 3D scenes from 2D data sourceslike images and videos. Diffusion models, originally designed for 2D generativetasks, offer the potential for more flexible, probabilistic approaches that canbetter capture the variability and uncertainty present in real-world 3D data.However, traditional methods often struggle with efficiency and scalability. Inthis paper, we review the state-of-the-art approaches that leverage diffusionmodels for 3D visual tasks, including but not limited to 3D object generation,shape completion, point cloud reconstruction, and scene understanding. Weprovide an in-depth discussion of the underlying mathematical principles ofdiffusion models, outlining their forward and reverse processes, as well as thevarious architectural advancements that enable these models to work with 3Ddatasets. We also discuss the key challenges in applying diffusion models to 3Dvision, such as handling occlusions and varying point densities, and thecomputational demands of high-dimensional data. Finally, we discuss potentialsolutions, including improving computational efficiency, enhancing multimodalfusion, and exploring the use of large-scale pretraining for bettergeneralization across 3D tasks. This paper serves as a foundation for futureexploration and development in this rapidly evolving field.</description>
      <author>example@mail.com (Zhen Wang, Dongyuan Li, Renhe Jiang)</author>
      <guid isPermaLink="false">2410.04738v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SOE: SO(3)-Equivariant 3D MRI Encoding</title>
      <link>http://arxiv.org/abs/2410.12053v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;表示学习在下游任务中变得越来越重要，特别是在强大的模型转向学习潜在表示后进行微调时。这种方法在利用脑解剖结构中的结构信息方面尤为有价值。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，通过强制在三维空间中进行等变性（SO(3)-等变性），以改善对脑结构的详细解剖信息的学习。&lt;h4&gt;方法&lt;/h4&gt;开发了一种编码3D MRI的新方法，显式建模几何等变性，确保对输入图像空间应用的旋转操作在嵌入表示空间中也能反映出来。&lt;h4&gt;主要发现&lt;/h4&gt;SOE模型在两个公共数据集上进行预训练，并在预测年龄和诊断阿尔茨海默病的任务中表现优于其他方法，并且对不同轴的旋转具有较强的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过该方法，脑的结构和解剖信息的捕获更加有效，证明了几何知识的引入能显著提高表示学习的性能。&lt;h4&gt;总结&lt;/h4&gt;该研究表明，利用几何变换知识可以提升MRI表示学习的效果，提供了一种新的思路和方法来改进脑部影像分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning has become increasingly important, especially aspowerful models have shifted towards learning latent representations beforefine-tuning for downstream tasks. This approach is particularly valuable inleveraging the structural information within brain anatomy. However, a commonlimitation of recent models developed for MRIs is their tendency to ignore orremove geometric information, such as translation and rotation, therebycreating invariance with respect to geometric operations. We contend thatincorporating knowledge about these geometric transformations into the modelcan significantly enhance its ability to learn more detailed anatomicalinformation within brain structures. As a result, we propose a novel method forencoding 3D MRIs that enforces equivariance with respect to all rotations in 3Dspace, in other words, SO(3)-equivariance (SOE). By explicitly modeling thisgeometric equivariance in the representation space, we ensure that anyrotational operation applied to the input image space is also reflected in theembedding representation space. This approach requires moving beyondtraditional representation learning methods, as we need a representation vectorspace that allows for the application of the same SO(3) operation in thatspace. To facilitate this, we leverage the concept of vector neurons. Therepresentation space formed by our method captures the brain's structural andanatomical information more effectively. We evaluate SOE pretrained on thestructural MRIs of two public data sets with respect to the downstream task ofpredicting age and diagnosing Alzheimer's Disease from T1-weighted brain scansof the ADNI data set. We demonstrate that our approach not only outperformsother methods but is also robust against various degrees of rotation alongdifferent axes. The code is available athttps://github.com/shizhehe/SOE-representation-learning.</description>
      <author>example@mail.com (Shizhe He, Magdalini Paschali, Jiahong Ouyang, Adnan Masood, Akshay Chaudhari, Ehsan Adeli)</author>
      <guid isPermaLink="false">2410.12053v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Cultural Heritage 3D Reconstruction with Diffusion Networks</title>
      <link>http://arxiv.org/abs/2410.10927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by the workshop VISART for ECCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;文章探讨了使用新近的生成AI算法修复文化遗产物品。&lt;h4&gt;目的&lt;/h4&gt;利用一种条件扩散模型有效重建3D点云。&lt;h4&gt;方法&lt;/h4&gt;评估模型在一般和文化遗产特定环境中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;该扩散模型能够准确重现文化遗产几何形状，但存在数据多样性和离群值敏感性等挑战。&lt;h4&gt;结论&lt;/h4&gt;模型在文物修复研究中显示出显著潜力，为利用AI技术推进古代文物修复方法奠定基础。&lt;h4&gt;总结&lt;/h4&gt;本研究为文化遗产修复提供了新的方法论，说明了生成AI在这一领域的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/PJaramilloV/pcdiff-method&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This article explores the use of recent generative AI algorithms forrepairing cultural heritage objects, leveraging a conditional diffusion modeldesigned to reconstruct 3D point clouds effectively. Our study evaluates themodel's performance across general and cultural heritage-specific settings.Results indicate that, with considerations for object variability, thediffusion model can accurately reproduce cultural heritage geometries. Despiteencountering challenges like data diversity and outlier sensitivity, the modeldemonstrates significant potential in artifact restoration research. This worklays groundwork for advancing restoration methodologies for ancient artifactsusing AI technologies.</description>
      <author>example@mail.com (Pablo Jaramillo, Ivan Sipiran)</author>
      <guid isPermaLink="false">2410.10927v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive learning of cell state dynamics in response to perturbations</title>
      <link>http://arxiv.org/abs/2410.11281v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 6 figures, 3 appendix figures, 4 videos (ancillary files)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;细胞和细胞器的活细胞成像被广泛用于分析细胞对扰动的反应，但人工标注动态细胞状态既耗时又容易产生偏见。&lt;h4&gt;目的&lt;/h4&gt;提出DynaCLR，一个自监督框架，通过对时间序列数据集的对比学习来建模细胞动态。&lt;h4&gt;方法&lt;/h4&gt;DynaCLR整合单细胞追踪与时间感知对比学习，将相邻时间点的细胞图像映射到相邻的嵌入空间，从而实现更定量和高效的注释、分类、聚类或解释细胞状态。&lt;h4&gt;主要发现&lt;/h4&gt;使用DynaCLR训练的模型在感染状态分类上 consistently 达到超过95%的准确率，能够检测瞬态细胞状态，并可靠地嵌入未见的实验。&lt;h4&gt;结论&lt;/h4&gt;DynaCLR为由于扰动（如感染、基因敲除和药物）造成的细胞状态动态的比较分析提供了灵活的框架。&lt;h4&gt;应用&lt;/h4&gt;展示了DynaCLR在分析病毒感染动力学、检测细胞分裂引起的瞬态形态变化以及映射由于病毒感染导致的细胞器动态等方面的应用。&lt;h4&gt;工具&lt;/h4&gt;提供了基于PyTorch的模型训练和推理管道的实现，以及用于可视化和注释细胞轨迹的用户界面。&lt;h4&gt;总结&lt;/h4&gt;DynaCLR通过对比学习提升了细胞动态分析的效率和准确性，为生命科学研究提供了新的工具和思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mehta-lab/viscy&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce DynaCLR, a self-supervised framework for modeling cell dynamicsvia contrastive learning of representations of time-lapse datasets. Live cellimaging of cells and organelles is widely used to analyze cellular responses toperturbations. Human annotation of dynamic cell states captured by time-lapseperturbation datasets is laborious and prone to bias. DynaCLR integratessingle-cell tracking with time-aware contrastive learning to map images ofcells at neighboring time points to neighboring embeddings. Mapping themorphological dynamics of cells to a temporally regularized embedding spacemakes the annotation, classification, clustering, or interpretation of the cellstates more quantitative and efficient. We illustrate the features andapplications of DynaCLR with the following experiments: analyzing the kineticsof viral infection in human cells, detecting transient changes in cellmorphology due to cell division, and mapping the dynamics of organelles due toviral infection. Models trained with DynaCLR consistently achieve $&gt;95\%$accuracy for infection state classification, enable the detection of transientcell states and reliably embed unseen experiments. DynaCLR provides a flexibleframework for comparative analysis of cell state dynamics due to perturbations,such as infection, gene knockouts, and drugs. We provide PyTorch-basedimplementations of the model training and inference pipeline(https://github.com/mehta-lab/viscy) and a user interface(https://github.com/czbiohub-sf/napari-iohub) for the visualization andannotation of trajectories of cells in the real space and the embedding space.</description>
      <author>example@mail.com (Soorya Pradeep, Alishba Imran, Ziwen Liu, Taylla Milena Theodoro, Eduardo Hirata-Miyasaki, Ivan Ivanov, Madhura Bhave, Sudip Khadka, Hunter Woosley, Carolina Arias, Shalin B. Mehta)</author>
      <guid isPermaLink="false">2410.11281v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning</title>
      <link>http://arxiv.org/abs/2410.12096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Graph structure learning, Graph representation learning, Large
  language models, Graph neural networks&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图表示学习在实际应用中至关重要，但常常面临普遍噪声问题。&lt;h4&gt;目的&lt;/h4&gt;提出LangGSL框架，结合预训练语言模型和图结构学习模型的优势，提升节点特征和图结构学习。&lt;h4&gt;方法&lt;/h4&gt;通过LLMs过滤原始数据中的噪声，提取有价值的信息，并在互学习阶段利用小型语言模型生成伪标签和节点嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;LangGSL通过增强全局上下文，提升了整体性能，同时GSLM利用LM的输出不断优化图结构。&lt;h4&gt;结论&lt;/h4&gt;LM与GSLM协同工作，互补各自优势，在变分信息最大化框架中实现了节点特征的增强和更强的图结构。&lt;h4&gt;实验结果&lt;/h4&gt;在不同规模和任务场景的多样化图数据集上进行的广泛实验展示了该方法的可扩展性和有效性。&lt;h4&gt;总结&lt;/h4&gt;LangGSL框架有效地提升了图表示学习的性能，解决了噪声问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning, involving both node features and graphstructures, is crucial for real-world applications but often encounterspervasive noise. State-of-the-art methods typically address noise by focusingseparately on node features with large language models (LLMs) and on graphstructures with graph structure learning models (GSLMs). In this paper, weintroduce LangGSL, a robust framework that integrates the complementarystrengths of pre-trained language models and GSLMs to jointly enhance both nodefeature and graph structure learning. In LangGSL, we first leverage LLMs tofilter noise in the raw data and extract valuable cleaned information asfeatures, enhancing the synergy of downstream models. During the mutuallearning phase in LangGSL, the core idea is to leverage the relatively smalllanguage model (LM) to process local attributes and generate reliablepseudo-labels and informative node embeddings, which are then integrated intothe GSLM's prediction phase. This approach enriches the global context andenhances overall performance. Meanwhile, GSLM refines the evolving graphstructure constructed from the LM's output, offering updated labels back to theLM as additional guidance, thus facilitating a more effective mutual learningprocess. The LM and GSLM work synergistically, complementing each other'sstrengths and offsetting weaknesses within a variational information-maximizingframework, resulting in enhanced node features and a more robust graphstructure. Extensive experiments on diverse graph datasets of varying scalesand across different task scenarios demonstrate the scalability andeffectiveness of the proposed approach.</description>
      <author>example@mail.com (Guangxin Su, Yifan Zhu, Wenjie Zhang, Hanchen Wang, Ying Zhang)</author>
      <guid isPermaLink="false">2410.12096v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CONSULT: Contrastive Self-Supervised Learning for Few-shot Tumor Detection</title>
      <link>http://arxiv.org/abs/2410.11307v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能在脑肿瘤检测中通过MRI扫描提高准确性并减轻医务人员的工作负担，但在极少医学图像的情况下，传统深度学习方法常常失败。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的两阶段异常检测算法CONSULT，以应对极少样本条件下的肿瘤检测问题。&lt;h4&gt;方法&lt;/h4&gt;CONSULT的第一阶段针对MRI脑部图像微调预训练特征提取器，使用合成数据生成管道创造肿瘤样本，并结合上下文感知对比学习和自监督特征对抗学习来改善特征提取效果。&lt;h4&gt;主要发现&lt;/h4&gt;CONSULT在少样本脑肿瘤检测中表现优越，相比PatchCore在2、4、6、8个样本下分别提高了9.4%、12.9%、10.2%和6.0%。&lt;h4&gt;结论&lt;/h4&gt;CONSULT通过自监督训练方案和独特的对比损失函数Tritanh Loss提升了模型性能和数据可靠性。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了在健康图像上训练的情况下，CONSULT有效地提高了异常检测的准确性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence aids in brain tumor detection via MRI scans,enhancing the accuracy and reducing the workload of medical professionals.However, in scenarios with extremely limited medical images, traditional deeplearning approaches tend to fail due to the absence of anomalous images.Anomaly detection also suffers from ineffective feature extraction due to vaguetraining process. Our work introduces a novel two-stage anomaly detectionalgorithm called CONSULT (CONtrastive Self-sUpervised Learning for few-shotTumor detection). The first stage of CONSULT fine-tunes a pre-trained featureextractor specifically for MRI brain images, using a synthetic data generationpipeline to create tumor-like data. This process overcomes the lack of anomalysamples and enables the integration of attention mechanisms to focus onanomalous image segments. The first stage is to overcome the shortcomings ofcurrent anomaly detection in extracting features in high-variation data byincorporating Context-Aware Contrastive Learning and Self-supervised FeatureAdversarial Learning. The second stage of CONSULT uses PatchCore forconventional feature extraction via the fine-tuned weights from the firststage. To summarize, we propose a self-supervised training scheme for anomalydetection, enhancing model performance and data reliability. Furthermore, ourproposed contrastive loss, Tritanh Loss, stabilizes learning by offering aunique solution all while enhancing gradient flow. Finally, CONSULT achievessuperior performance in few-shot brain tumor detection, demonstratingsignificant improvements over PatchCore by 9.4%, 12.9%, 10.2%, and 6.0% for 2,4, 6, and 8 shots, respectively, while training exclusively on healthy images.</description>
      <author>example@mail.com (Sin Chee Chin, Xuan Zhang, Lee Yeong Khang, Wenming Yang)</author>
      <guid isPermaLink="false">2410.11307v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Federated Temporal Graph Clustering</title>
      <link>http://arxiv.org/abs/2410.12343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间图聚类是一项复杂任务，涉及在动态图中发现有意义的结构，这些图中的关系和实体随时间变化。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的联邦时间图聚类（FTGC）框架，以实现图神经网络在多个客户端上的去中心化训练，确保数据隐私。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了时间聚合机制，有效捕捉图结构随时间的演变，并采用联邦优化策略以协作学习高质量的聚类表示。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在保持数据隐私和减少通信开销的同时，在时间图数据集上实现了竞争性的性能。&lt;h4&gt;结论&lt;/h4&gt;FTGC框架为涉及动态数据的隐私敏感的现实应用提供了一个有前景的解决方案。&lt;h4&gt;总结&lt;/h4&gt;总的来说，FTGC框架有效解决了时间图聚类中的隐私和通信挑战，适用于动态数据的实际应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal graph clustering is a complex task that involves discoveringmeaningful structures in dynamic graphs where relationships and entities changeover time. Existing methods typically require centralized data collection,which poses significant privacy and communication challenges. In this work, weintroduce a novel Federated Temporal Graph Clustering (FTGC) framework thatenables decentralized training of graph neural networks (GNNs) across multipleclients, ensuring data privacy throughout the process. Our approachincorporates a temporal aggregation mechanism to effectively capture theevolution of graph structures over time and a federated optimization strategyto collaboratively learn high-quality clustering representations. By preservingdata privacy and reducing communication overhead, our framework achievescompetitive performance on temporal graph datasets, making it a promisingsolution for privacy-sensitive, real-world applications involving dynamic data.</description>
      <author>example@mail.com (Yang Liu, Zihao Zhou, Xianghong Xu, Qian Li)</author>
      <guid isPermaLink="false">2410.12343v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>All models are wrong, some are useful: Model Selection with Limited Labels</title>
      <link>http://arxiv.org/abs/2410.13609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着大规模监督学习和自监督学习的发展，预训练模型的种类日益增多，选择合适的模型在机器学习生命周期中变得越来越重要。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架MODEL SELECTOR，以实现高效的预训练分类器选择，减少标注数据的需求。&lt;h4&gt;方法&lt;/h4&gt;MODEL SELECTOR从未标记的目标数据集中抽取一小部分高信息量的样本进行标注，从而高效识别最佳的预训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MODEL SELECTOR显著减少了对标注数据的需求，并且能够一致地选择表现最佳或接近最佳的模型。&lt;h4&gt;结论&lt;/h4&gt;在16个不同数据集上的18个模型集合中，MODEL SELECTOR在识别最佳模型时将标注成本减少了高达94.15%。当选择接近最佳模型（准确率仅比最佳模型低1%）时，标注成本也降低了72.41%。&lt;h4&gt;总结&lt;/h4&gt;MODEL SELECTOR是一个强大的工具，能够有效减少预训练模型选择过程中的标注成本，提升模型选择的效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/robustml-lab/model-selector&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the multitude of pretrained models available thanks to the advancementsin large-scale supervised and self-supervised learning, choosing the rightmodel is becoming increasingly pivotal in the machine learning lifecycle.However, much like the training process, choosing the best pretrainedoff-the-shelf model for raw, unlabeled data is a labor-intensive task. Toovercome this, we introduce MODEL SELECTOR, a framework for label-efficientselection of pretrained classifiers. Given a pool of unlabeled target data,MODEL SELECTOR samples a small subset of highly informative examples forlabeling, in order to efficiently identify the best pretrained model fordeployment on this target dataset. Through extensive experiments, wedemonstrate that MODEL SELECTOR drastically reduces the need for labeled datawhile consistently picking the best or near-best performing model. Across 18model collections on 16 different datasets, comprising over 1,500 pretrainedmodels, MODEL SELECTOR reduces the labeling cost by up to 94.15% to identifythe best model compared to the cost of the strongest baseline. Our resultsfurther highlight the robustness of MODEL SELECTOR in model selection, as itreduces the labeling cost by up to 72.41% when selecting a near-best model,whose accuracy is only within 1% of the best model.</description>
      <author>example@mail.com (Patrik Okanovic, Andreas Kirsch, Jannes Kasper, Torsten Hoefler, Andreas Krause, Nezihe Merve Gürel)</author>
      <guid isPermaLink="false">2410.13609v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Few-shot Novel View Synthesis using Depth Aware 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2410.11080v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented in ECCV 2024 workshop S3DSGR&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian splatting在新视角合成中已超越神经辐射场方法，实现了更低的计算成本和实时高质量渲染，但在输入视角较少时性能显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于深度感知的Gaussian splatting方法，以应对少量视角的新视角合成问题。&lt;h4&gt;方法&lt;/h4&gt;利用单目深度预测作为先验，结合尺度不变深度损失，对3D形状进行约束，同时使用低阶球谐函数建模颜色，避免过拟合。此外，保持所有不透明度较低的点以提高重建质量。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在峰值信噪比、结构相似性指数和感知相似性方面分别提高了10.5%、6%和14.1%。&lt;h4&gt;结论&lt;/h4&gt;验证了所提出方法的有效性，并显示其超越传统的3D Gaussian splatting方法。&lt;h4&gt;总结&lt;/h4&gt;提出的深度感知Gaussian splatting方法在输入视角较少的情况下，显著提升了新视角合成的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/raja-kumar/depth-aware-3dgs&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian splatting has surpassed neural radiance field methods in novelview synthesis by achieving lower computational costs and real-timehigh-quality rendering. Although it produces a high-quality rendering with alot of input views, its performance drops significantly when only a few viewsare available. In this work, we address this by proposing a depth-awareGaussian splatting method for few-shot novel view synthesis. We use monoculardepth prediction as a prior, along with a scale-invariant depth loss, toconstrain the 3D shape under just a few input views. We also model color usinglower-order spherical harmonics to avoid overfitting. Further, we observe thatremoving splats with lower opacity periodically, as performed in the originalwork, leads to a very sparse point cloud and, hence, a lower-quality rendering.To mitigate this, we retain all the splats, leading to a better reconstructionin a few view settings. Experimental results show that our method outperformsthe traditional 3D Gaussian splatting methods by achieving improvements of10.5% in peak signal-to-noise ratio, 6% in structural similarity index, and14.1% in perceptual similarity, thereby validating the effectiveness of ourapproach. The code will be made available at:https://github.com/raja-kumar/depth-aware-3DGS</description>
      <author>example@mail.com (Raja Kumar, Vanshika Vats)</author>
      <guid isPermaLink="false">2410.11080v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Toward a Well-Calibrated Discrimination via Survival Outcome-Aware Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.11340v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;以往的深度学习生存分析方法主要依赖于排序损失来提高区分性能，但这往往牺牲了校准性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的对比学习方法，旨在提高区分性能而不牺牲校准性能。&lt;h4&gt;方法&lt;/h4&gt;该方法在对比学习框架内采用加权采样，为具有相似生存结果的样本分配较低的惩罚。&lt;h4&gt;主要发现&lt;/h4&gt;当与常用的负对数似然损失结合时，该方法显著提高了区分性能，而不直接操控模型输出，从而实现更好的校准。&lt;h4&gt;结论&lt;/h4&gt;在多个真实世界临床数据集上的实验表明，我们的方法在区分和校准方面优于最先进的深度生存模型。&lt;h4&gt;总结&lt;/h4&gt;通过全面的消融研究，我们进一步通过定量和定性分析验证了该方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Previous deep learning approaches for survival analysis have primarily reliedon ranking losses to improve discrimination performance, which often comes atthe expense of calibration performance. To address such an issue, we propose anovel contrastive learning approach specifically designed to enhancediscrimination \textit{without} sacrificing calibration. Our method employsweighted sampling within a contrastive learning framework, assigning lowerpenalties to samples with similar survival outcomes. This aligns well with theassumption that patients with similar event times share similar clinicalstatuses. Consequently, when augmented with the commonly used negativelog-likelihood loss, our approach significantly improves discriminationperformance without directly manipulating the model outputs, thereby achievingbetter calibration. Experiments on multiple real-world clinical datasetsdemonstrate that our method outperforms state-of-the-art deep survival modelsin both discrimination and calibration. Through comprehensive ablation studies,we further validate the effectiveness of our approach through quantitative andqualitative analyses.</description>
      <author>example@mail.com (Dongjoon Lee, Hyeryn Park, Changhee Lee)</author>
      <guid isPermaLink="false">2410.11340v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Perseus: Leveraging Common Data Patterns with Curriculum Learning for More Robust Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.12425v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在处理图数据方面表现优异，但易受对抗攻击的影响。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的对抗防御方法，以提升GNNs在对抗攻击下的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;采用基于课程学习的Perseus方法，通过评估边的难度和调整学习顺序，指导模型学习完整的图结构，并聚焦于常见数据模式。&lt;h4&gt;主要发现&lt;/h4&gt;使用Perseus训练的模型在对抗攻击下表现优越，显著提高了鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;Perseus方法有效减缓了对抗干扰的影响，提升了模型性能。&lt;h4&gt;总结&lt;/h4&gt;Perseus是一个创新的防御方法，能够在不预处理的情况下直接在受对抗扰动影响的图数据上进行训练，解决了现有方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) excel at handling graph data but remainvulnerable to adversarial attacks. Existing defense methods typically rely onassumptions like graph sparsity and homophily to either preprocess the graph orguide structure learning. However, preprocessing methods often struggle toaccurately distinguish between normal edges and adversarial perturbations,leading to suboptimal results due to the loss of valuable edge information.Robust graph neural network models train directly on graph data affected byadversarial perturbations, without preprocessing. This can cause the model toget stuck in poor local optima, negatively affecting its performance. Toaddress these challenges, we propose Perseus, a novel adversarial defensemethod based on curriculum learning. Perseus assesses edge difficulty usingglobal homophily and applies a curriculum learning strategy to adjust thelearning order, guiding the model to learn the full graph structure whileadaptively focusing on common data patterns. This approach mitigates the impactof adversarial perturbations. Experiments show that models trained with Perseusachieve superior performance and are significantly more robust to adversarialattacks.</description>
      <author>example@mail.com (Kaiwen Xia, Huijun Wu, Duanyu Li, Min Xie, Ruibo Wang, Wenzhe Zhang)</author>
      <guid isPermaLink="false">2410.12425v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Prompt-leveraged Weakly Supervised Cancer Segmentation based on Segment Anything</title>
      <link>http://arxiv.org/abs/2410.13621v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的病理诊断依赖于医生和病理学家的形态特征评估，但标注数据的不足限制了有效的图像分析。&lt;h4&gt;目的&lt;/h4&gt;提出一种超越监督学习的新方法，解决病理图像分析中的有限标注数据问题。&lt;h4&gt;方法&lt;/h4&gt;结合类激活图和基于Segment Anything Model (SAM) 的伪标注，构建弱监督语义分割（WSSS）模型，并采用预训练的SAM基础模型进行有效预训练。&lt;h4&gt;主要发现&lt;/h4&gt;在三种组织病理学乳腺癌数据集上的实验表明，该方法优于其他WSSS方法，仅需12GB GPU内存即可完成训练。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在有效性和效率上均表现出色，为解决病理图像分析中的标注数据问题提供了新的思路。&lt;h4&gt;总结&lt;/h4&gt;通过将增强的注意力丢弃层知识转移到SAM，生成伪标注，展示了该方法的潜力和应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/qi-nemosong/eplc-sam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes a novel approach beyond supervised learning for effectivepathological image analysis, addressing the challenge of limited robust labeleddata. Pathological diagnosis of diseases like cancer has conventionally reliedon the evaluation of morphological features by physicians and pathologists.However, recent advancements in compute-aided diagnosis (CAD) systems aregaining significant attention as diagnostic support tools. Although theadvancement of deep learning has improved CAD significantly, segmentationmodels typically require large pixel-level annotated dataset, and such labelingis expensive. Existing studies not based on supervised approaches stillstruggle with limited generalization, and no practical approach has emergedyet. To address this issue, we present a weakly supervised semanticsegmentation (WSSS) model by combining class activation map and SegmentAnything Model (SAM)-based pseudo-labeling. For effective pretraining, we adoptthe SAM-a foundation model that is pretrained on large datasets and operates inzero-shot configurations using only coarse prompts. The proposed approachtransfer enhanced Attention Dropout Layer's knowledge to SAM, therebygenerating pseudo-labels. To demonstrate the superiority of the proposedmethod, experimental studies are conducted on histopathological breast cancerdatasets. The proposed method outperformed other WSSS methods across threedatasets, demonstrating its efficiency by achieving this with only 12GB of GPUmemory during training. Our code is available at :https://github.com/QI-NemoSong/EPLC-SAM</description>
      <author>example@mail.com (Joonhyeon Song, Seohwan Yun, Seongho Yoon, Joohyeok Kim, Sangmin Lee)</author>
      <guid isPermaLink="false">2410.13621v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Visual Manipulation with Legs</title>
      <link>http://arxiv.org/abs/2410.11345v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  More details can be found on our project page:
  https://legged-manipulation.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;动物利用四肢进行运动和操作。&lt;h4&gt;目的&lt;/h4&gt;为四足机器人赋予类似的多功能性。&lt;h4&gt;方法&lt;/h4&gt;系统包括视觉操作策略模块和运动操作模块，使用强化学习和点云观测进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;系统在物体姿态对齐任务中展示了比以往更灵活的物体操作能力。&lt;h4&gt;结论&lt;/h4&gt;机器人能够通过单腿操作和基于评价图选择左右腿，将物体移动至远处目标。&lt;h4&gt;实验&lt;/h4&gt;在模拟和现实环境中评估系统性能。&lt;h4&gt;总结&lt;/h4&gt;该系统显著提升了四足机器人使用腿进行操作的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Animals use limbs for both locomotion and manipulation. We aim to equipquadruped robots with similar versatility. This work introduces a system thatenables quadruped robots to interact with objects using their legs, inspired bynon-prehensile manipulation. The system has two main components: a visualmanipulation policy module and a loco-manipulator module. The visualmanipulation policy, trained with reinforcement learning (RL) using point cloudobservations and object-centric actions, decides how the leg should interactwith the object. The loco-manipulator controller manages leg movements and bodypose adjustments, based on impedance control and Model Predictive Control(MPC). Besides manipulating objects with a single leg, the system can selectfrom the left or right leg based on critic maps and move objects to distantgoals through base adjustment. Experiments evaluate the system on object posealignment tasks in both simulation and the real world, demonstrating moreversatile object manipulation skills with legs than previous work. Videos canbe found at https://legged-manipulation.github.io/</description>
      <author>example@mail.com (Xialin He, Chengjing Yuan, Wenxuan Zhou, Ruihan Yang, David Held, Xiaolong Wang)</author>
      <guid isPermaLink="false">2410.11345v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SeaDATE: Remedy Dual-Attention Transformer with Semantic Alignment via Contrast Learning for Multimodal Object Detection</title>
      <link>http://arxiv.org/abs/2410.11358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态目标检测利用多种模态信息来提高检测器的准确性和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为SeaDATE的高效准确的目标检测方法。&lt;h4&gt;方法&lt;/h4&gt;引入一种新颖的双重注意力特征融合模块(DTF)，通过双重注意力机制在Transformer's指导下整合局部和全局信息。&lt;h4&gt;主要发现&lt;/h4&gt;Transformer引导的融合方法在提取浅层特征的细节信息方面表现优于深层语义信息。&lt;h4&gt;结论&lt;/h4&gt;设计了对比学习模块(CL)，旨在改善Transformer引导融合在提取深层语义特征方面的不足，有效利用跨模态信息。&lt;h4&gt;实验结果&lt;/h4&gt;在FLIR、LLVIP和M3FD数据集上进行了广泛的实验和消融研究，证明了该方法的有效性，达到了最先进的检测性能。&lt;h4&gt;总结&lt;/h4&gt;SeaDATE方法通过创新的特征融合和对比学习技术，显著提升了多模态目标检测的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal object detection leverages diverse modal information to enhancethe accuracy and robustness of detectors. By learning long-term dependencies,Transformer can effectively integrate multimodal features in the featureextraction stage, which greatly improves the performance of multimodal objectdetection. However, current methods merely stack Transformer-guided fusiontechniques without exploring their capability to extract features at variousdepth layers of network, thus limiting the improvements in detectionperformance. In this paper, we introduce an accurate and efficient objectdetection method named SeaDATE. Initially, we propose a novel dual attentionFeature Fusion (DTF) module that, under Transformer's guidance, integrateslocal and global information through a dual attention mechanism, strengtheningthe fusion of modal features from orthogonal perspectives using spatial andchannel tokens. Meanwhile, our theoretical analysis and empirical validationdemonstrate that the Transformer-guided fusion method, treating images assequences of pixels for fusion, performs better on shallow features' detailinformation compared to deep semantic information. To address this, we designeda contrastive learning (CL) module aimed at learning features of multimodalsamples, remedying the shortcomings of Transformer-guided fusion in extractingdeep semantic features, and effectively utilizing cross-modal information.Extensive experiments and ablation studies on the FLIR, LLVIP, and M3FDdatasets have proven our method to be effective, achieving state-of-the-artdetection performance.</description>
      <author>example@mail.com (Shuhan Dong, Yunsong Li, Weiying Xie, Jiaqing Zhang, Jiayuan Tian, Danian Yang, Jie Lei)</author>
      <guid isPermaLink="false">2410.11358v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting</title>
      <link>http://arxiv.org/abs/2410.12593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;感知设备的广泛部署导致时空预测应用（如交通流、空气质量和风能）数据激增。&lt;h4&gt;目的&lt;/h4&gt;解决流媒体场景中的时空预测面临的双重挑战：新数据模型重训练效率低下和长期历史的灾难性遗忘。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于提示调优的连续预测方法，通过扩展和压缩的调优原则，利用存储的提示与基础时空图神经网络联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;在多个真实世界数据集上的广泛实验结果显示，该方法在有效性、效率和普适性等方面优于现有最先进的基线。&lt;h4&gt;结论&lt;/h4&gt;该方法确保模型能够从时空数据流中顺序学习，以完成相应时期的任务。&lt;h4&gt;总结&lt;/h4&gt;新方法有效解决了流媒体时空预测中的挑战，并展示了其多方面的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread deployment of sensing devices leads to a surge in data forspatio-temporal forecasting applications such as traffic flow, air quality, andwind energy. Although spatio-temporal graph neural networks have achievedsuccess in modeling various static spatio-temporal forecasting scenarios,real-world spatio-temporal data are typically received in a streaming manner,and the network continuously expands with the installation of new sensors.Thus, spatio-temporal forecasting in streaming scenarios faces dual challenges:the inefficiency of retraining models over newly arrived data and thedetrimental effects of catastrophic forgetting over long-term history. Toaddress these challenges, we propose a novel prompt tuning-based continuousforecasting method, following two fundamental tuning principles guided byempirical and theoretical analysis: expand and compress, which effectivelyresolve the aforementioned problems with lightweight tuning parameters.Specifically, we integrate the base spatio-temporal graph neural network with acontinuous prompt pool, utilizing stored prompts (i.e., few learnableparameters) in memory, and jointly optimize them with the base spatio-temporalgraph neural network. This method ensures that the model sequentially learnsfrom the spatio-temporal data stream to accomplish tasks for correspondingperiods. Extensive experimental results on multiple real-world datasetsdemonstrate the multi-faceted superiority of our method over thestate-of-the-art baselines, including effectiveness, efficiency, universality,etc.</description>
      <author>example@mail.com (Wei Chen, Yuxuan Liang)</author>
      <guid isPermaLink="false">2410.12593v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Wearable Foundation Models</title>
      <link>http://arxiv.org/abs/2410.13638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;可穿戴传感器因其健康追踪功能而变得普及，产生大量的连续和长期测量数据。&lt;h4&gt;目的&lt;/h4&gt;研究传感器基础模型在计算、数据和模型规模上的扩展特性。&lt;h4&gt;方法&lt;/h4&gt;使用来自16.5万人、长达4000万小时的实时心率、心率变异性、皮肤电活动、加速度、皮肤温度和高度计的每分钟数据，构建了一个多模态基础模型LSM。&lt;h4&gt;主要发现&lt;/h4&gt;建立了LSM在时间和传感器模态上的插补、插值和外推等任务的扩展规律，展示了LSM在下游学习任务（如运动和活动识别）中的高效样本学习能力。&lt;h4&gt;结论&lt;/h4&gt;LSM是迄今为止基于最广泛的传感器模态数据集构建的多模态基础模型，为科学和可操作的见解提供了新的可能性。&lt;h4&gt;总结&lt;/h4&gt;通过LSM模型的研究，可以更有效地分析和利用可穿戴传感器的数据，推动健康监测和活动识别的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wearable sensors have become ubiquitous thanks to a variety of healthtracking features. The resulting continuous and longitudinal measurements fromeveryday life generate large volumes of data; however, making sense of theseobservations for scientific and actionable insights is non-trivial. Inspired bythe empirical success of generative modeling, where large neural networks learnpowerful representations from vast amounts of text, image, video, or audiodata, we investigate the scaling properties of sensor foundation models acrosscompute, data, and model size. Using a dataset of up to 40 million hours ofin-situ heart rate, heart rate variability, electrodermal activity,accelerometer, skin temperature, and altimeter per-minute data from over165,000 people, we create LSM, a multimodal foundation model built on thelargest wearable-signals dataset with the most extensive range of sensormodalities to date. Our results establish the scaling laws of LSM for taskssuch as imputation, interpolation and extrapolation, both across time andsensor modalities. Moreover, we highlight how LSM enables sample-efficientdownstream learning for tasks like exercise and activity recognition.</description>
      <author>example@mail.com (Girish Narayanswamy, Xin Liu, Kumar Ayush, Yuzhe Yang, Xuhai Xu, Shun Liao, Jake Garrison, Shyam Tailor, Jake Sunshine, Yun Liu, Tim Althoff, Shrikanth Narayanan, Pushmeet Kohli, Jiening Zhan, Mark Malhotra, Shwetak Patel, Samy Abdel-Ghaffar, Daniel McDuff)</author>
      <guid isPermaLink="false">2410.13638v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Just-In-Time Software Defect Prediction via Bi-modal Change Representation Learning</title>
      <link>http://arxiv.org/abs/2410.12107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by JSS (The Journal of Systems &amp; Software)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究者提出了即时缺陷预测（JIT-DP）方法，旨在早期识别代码提交中的潜在缺陷。&lt;h4&gt;目的&lt;/h4&gt;解决现有模型仅学习源代码变更，未考虑变更背后的自然语言意图的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一种新型的双模态变更预训练模型BiCC-BERT，并设计了替换消息识别（RMI）作为预训练目标，以学习提交消息与代码变更之间的语义关联。&lt;h4&gt;主要发现&lt;/h4&gt;JIT-BiCC在使用27,391个代码变更训练后，与8种最先进的JIT-DP方法比较，F1分数提高了10.8%。&lt;h4&gt;结论&lt;/h4&gt;JIT-BiCC在学习双模态语义方面表现出色，优于所有基线模型。&lt;h4&gt;总结&lt;/h4&gt;通过双模态表示，JIT-BiCC有效提升了即时缺陷预测的性能，捕获了更深层次的变化语义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.jss.2024.112253&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jyz-1201/jit-bicc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For predicting software defects at an early stage, researchers have proposedjust-in-time defect prediction (JIT-DP) to identify potential defects in codecommits. The prevailing approaches train models to represent code changes inhistory commits and utilize the learned representations to predict the presenceof defects in the latest commit. However, existing models merely learn editionsin source code, without considering the natural language intentions behind thechanges. This limitation hinders their ability to capture deeper semantics. Toaddress this, we introduce a novel bi-modal change pre-training model calledBiCC-BERT. BiCC-BERT is pre-trained on a code change corpus to learn bi-modalsemantic representations. To incorporate commit messages from the corpus, wedesign a novel pre-training objective called Replaced Message Identification(RMI), which learns the semantic association between commit messages and codechanges. Subsequently, we integrate BiCC-BERT into JIT-DP and propose a newdefect prediction approach -- JIT-BiCC. By leveraging the bi-modalrepresentations from BiCC-BERT, JIT-BiCC captures more profound changesemantics. We train JIT-BiCC using 27,391 code changes and compare itsperformance with 8 state-of-the-art JIT-DP approaches. The results demonstratethat JIT-BiCC outperforms all baselines, achieving a 10.8% improvement inF1-score. This highlights its effectiveness in learning the bi-modal semanticsfor JIT-DP.</description>
      <author>example@mail.com (Yuze Jiang, Beijun Shen, Xiaodong Gu)</author>
      <guid isPermaLink="false">2410.12107v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>MCGS: Multiview Consistency Enhancement for Sparse-View 3D Gaussian Radiance Fields</title>
      <link>http://arxiv.org/abs/2410.11394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D高斯表示的辐射场在新视图合成方面表现优异，具有高训练效率和快速渲染能力。然而，稀疏输入视图缺乏多视图一致性约束，导致点云初始化不佳和优化及稠密化的启发式不可靠，从而影响性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于3D高斯溅射的视图合成框架MCGS，以实现从稀疏输入视图中重建逼真的场景。&lt;h4&gt;方法&lt;/h4&gt;MCGS通过引入稀疏匹配器和随机填充策略的新初始化方法，以及多视图一致性引导的渐进修剪策略，来增强多视图一致性。&lt;h4&gt;主要发现&lt;/h4&gt;新初始化方法产生了紧凑而足够的初始点集，提升了初始几何先验；渐进修剪策略通过加强一致性和消除低贡献高斯，精炼了高斯场。&lt;h4&gt;结论&lt;/h4&gt;这些模块化、即插即用的策略提高了对稀疏输入视图的鲁棒性，加快了渲染速度，减少了内存消耗，使MCGS成为一个实用且高效的3D高斯溅射框架。&lt;h4&gt;总结&lt;/h4&gt;MCGS有效解决了稀疏输入视图带来的挑战，提升了多视图一致性，为3D场景重建提供了一种高效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radiance fields represented by 3D Gaussians excel at synthesizing novelviews, offering both high training efficiency and fast rendering. However, withsparse input views, the lack of multi-view consistency constraints results inpoorly initialized point clouds and unreliable heuristics for optimization anddensification, leading to suboptimal performance. Existing methods oftenincorporate depth priors from dense estimation networks but overlook theinherent multi-view consistency in input images. Additionally, they rely onmulti-view stereo (MVS)-based initialization, which limits the efficiency ofscene representation. To overcome these challenges, we propose a view synthesisframework based on 3D Gaussian Splatting, named MCGS, enabling photorealisticscene reconstruction from sparse input views. The key innovations of MCGS inenhancing multi-view consistency are as follows: i) We introduce aninitialization method by leveraging a sparse matcher combined with a randomfilling strategy, yielding a compact yet sufficient set of initial points. Thisapproach enhances the initial geometry prior, promoting efficient scenerepresentation. ii) We develop a multi-view consistency-guided progressivepruning strategy to refine the Gaussian field by strengthening consistency andeliminating low-contribution Gaussians. These modular, plug-and-play strategiesenhance robustness to sparse input views, accelerate rendering, and reducememory consumption, making MCGS a practical and efficient framework for 3DGaussian Splatting.</description>
      <author>example@mail.com (Yuru Xiao, Deming Zhai, Wenbo Zhao, Kui Jiang, Junjun Jiang, Xianming Liu)</author>
      <guid isPermaLink="false">2410.11394v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Touch-to-Touch Pretraining</title>
      <link>http://arxiv.org/abs/2410.11834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的触觉传感器设计多样，导致开发通用的触觉信号处理方法面临挑战。&lt;h4&gt;目的&lt;/h4&gt;学习一种统一的表示，捕捉不同触觉传感器之间的共享信息。&lt;h4&gt;方法&lt;/h4&gt;利用对比学习将来自两个不同传感器的触觉信号整合到一个共享的嵌入空间中，使用包含多个传感器探测相同物体的数据集。&lt;h4&gt;主要发现&lt;/h4&gt;所学习的特征为下游的姿态估计和分类任务提供了强大的预训练支持；同时，使用一种传感器训练的模型可以在另一种传感器上部署，而无需额外训练。&lt;h4&gt;结论&lt;/h4&gt;通过这种方法，可以有效地提高触觉信号处理的通用性和灵活性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了对比学习在触觉信号处理中的应用潜力，为不同传感器之间的知识迁移提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Today's tactile sensors have a variety of different designs, making itchallenging to develop general-purpose methods for processing touch signals. Inthis paper, we learn a unified representation that captures the sharedinformation between different tactile sensors. Unlike current approaches thatfocus on reconstruction or task-specific supervision, we leverage contrastivelearning to integrate tactile signals from two different sensors into a sharedembedding space, using a dataset in which the same objects are probed withmultiple sensors. We apply this approach to paired touch signals from GelSlimand Soft Bubble sensors. We show that our learned features provide strongpretraining for downstream pose estimation and classification tasks. We alsoshow that our embedding enables models trained using one touch sensor to bedeployed using another without additional training. Project details can befound at https://www.mmintlab.com/research/cttp/.</description>
      <author>example@mail.com (Samanta Rodriguez, Yiming Dou, William van den Bogert, Miquel Oller, Kevin So, Andrew Owens, Nima Fazeli)</author>
      <guid isPermaLink="false">2410.11834v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Movie Gen: A Cast of Media Foundation Models</title>
      <link>http://arxiv.org/abs/2410.13720v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出一种名为Movie Gen的基础模型，用于生成高质量的1080p高清影片。&lt;h4&gt;目的&lt;/h4&gt;展示模型在视频生成、编辑和个性化方面的能力。&lt;h4&gt;方法&lt;/h4&gt;使用具有30B参数的变换器模型，最大上下文长度为73K视频标记，生成16秒、16帧每秒的视频。&lt;h4&gt;主要发现&lt;/h4&gt;在文本到视频合成、视频个性化、视频编辑、视频到音频生成和文本到音频生成等多项任务上设立了新的先进标准。&lt;h4&gt;结论&lt;/h4&gt;通过架构、潜在空间、训练目标、数据整理等技术创新，实现了大规模媒体生成模型的训练与优化。&lt;h4&gt;总结&lt;/h4&gt;希望本论文能帮助研究社区加速媒体生成模型的进展与创新，所有视频可在指定网址获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Movie Gen, a cast of foundation models that generateshigh-quality, 1080p HD videos with different aspect ratios and synchronizedaudio. We also show additional capabilities such as precise instruction-basedvideo editing and generation of personalized videos based on a user's image.Our models set a new state-of-the-art on multiple tasks: text-to-videosynthesis, video personalization, video editing, video-to-audio generation, andtext-to-audio generation. Our largest video generation model is a 30B parametertransformer trained with a maximum context length of 73K video tokens,corresponding to a generated video of 16 seconds at 16 frames-per-second. Weshow multiple technical innovations and simplifications on the architecture,latent spaces, training objectives and recipes, data curation, evaluationprotocols, parallelization techniques, and inference optimizations that allowus to reap the benefits of scaling pre-training data, model size, and trainingcompute for training large scale media generation models. We hope this paperhelps the research community to accelerate progress and innovation in mediageneration models. All videos from this paper are available athttps://go.fb.me/MovieGenResearchVideos.</description>
      <author>example@mail.com (Adam Polyak, Amit Zohar, Andrew Brown, Andros Tjandra, Animesh Sinha, Ann Lee, Apoorv Vyas, Bowen Shi, Chih-Yao Ma, Ching-Yao Chuang, David Yan, Dhruv Choudhary, Dingkang Wang, Geet Sethi, Guan Pang, Haoyu Ma, Ishan Misra, Ji Hou, Jialiang Wang, Kiran Jagadeesh, Kunpeng Li, Luxin Zhang, Mannat Singh, Mary Williamson, Matt Le, Matthew Yu, Mitesh Kumar Singh, Peizhao Zhang, Peter Vajda, Quentin Duval, Rohit Girdhar, Roshan Sumbaly, Sai Saketh Rambhatla, Sam Tsai, Samaneh Azadi, Samyak Datta, Sanyuan Chen, Sean Bell, Sharadh Ramaswamy, Shelly Sheynin, Siddharth Bhattacharya, Simran Motwani, Tao Xu, Tianhe Li, Tingbo Hou, Wei-Ning Hsu, Xi Yin, Xiaoliang Dai, Yaniv Taigman, Yaqiao Luo, Yen-Cheng Liu, Yi-Chiao Wu, Yue Zhao, Yuval Kirstain, Zecheng He, Zijian He, Albert Pumarola, Ali Thabet, Artsiom Sanakoyeu, Arun Mallya, Baishan Guo, Boris Araya, Breena Kerr, Carleigh Wood, Ce Liu, Cen Peng, Dimitry Vengertsev, Edgar Schonfeld, Elliot Blanchard, Felix Juefei-Xu, Fraylie Nord, Jeff Liang, John Hoffman, Jonas Kohler, Kaolin Fire, Karthik Sivakumar, Lawrence Chen, Licheng Yu, Luya Gao, Markos Georgopoulos, Rashel Moritz, Sara K. Sampson, Shikai Li, Simone Parmeggiani, Steve Fine, Tara Fowler, Vladan Petrovic, Yuming Du)</author>
      <guid isPermaLink="false">2410.13720v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Just Ramp-up: Unleash the Potential of Regression-based Estimator for A/B Tests under Network Interference</title>
      <link>http://arxiv.org/abs/2410.12740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在网络干扰下的因果推断研究中，现有方法通常依赖单次实验，面临性能瓶颈和处理多样干扰结构的限制。&lt;h4&gt;目的&lt;/h4&gt;提出利用多次实验来克服传统方法的局限性，特别是在统计上合并多个实验数据的优势。&lt;h4&gt;方法&lt;/h4&gt;分析线性回归估计器在一般线性网络干扰下的偏差和方差，通过合并顺序进行的实验数据来估计全球平均处理效应。&lt;h4&gt;主要发现&lt;/h4&gt;偏差在偏差-方差权衡中占主导地位，通过合并不同处理比例的实验数据可以显著降低偏差。在一般线性干扰下，合并更多实验步骤并不必要，但在非线性干扰下则可能有利。&lt;h4&gt;结论&lt;/h4&gt;基于图神经网络的更高级估计器在利用合并实验数据进行训练时表现优异，显示出卓越的统计性能。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了在因果推断中通过合并多次实验数据来提高估计精度的重要性，特别是在面对复杂的干扰结构时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research in causal inference under network interference has exploredvarious experimental designs and estimation techniques to address this issue.However, existing methods, which typically rely on single experiments, oftenreach a performance bottleneck and face limitations in handling diverseinterference structures. In contrast, we propose leveraging multipleexperiments to overcome these limitations. In industry, the use of sequentialexperiments, often known as the ramp-up process, where traffic to the treatmentgradually increases, is common due to operational needs like risk managementand cost control. Our approach shifts the focus from operational aspects to thestatistical advantages of merging data from multiple experiments. By combiningdata from sequentially conducted experiments, we aim to estimate the globalaverage treatment effect more effectively. In this paper, we begin by analyzingthe bias and variance of the linear regression estimator for GATE under generallinear network interference. We demonstrate that bias plays a dominant role inthe bias-variance tradeoff and highlight the intrinsic bias reduction achievedby merging data from experiments with strictly different treatment proportions.Herein the improvement introduced by merging two steps of experimental data isessential. In addition, we show that merging more steps of experimental data isunnecessary under general linear interference, while it can become beneficialwhen nonlinear interference occurs. Furthermore, we look into a more advancedestimator based on graph neural networks. Through extensive simulation studies,we show that the regression-based estimator benefits remarkably from trainingon merged experiment data, achieving outstanding statistical performance.</description>
      <author>example@mail.com (Qianyi Chen, Bo Li)</author>
      <guid isPermaLink="false">2410.12740v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Parametric Graph Representations in the Era of Foundation Models: A Survey and Position</title>
      <link>http://arxiv.org/abs/2410.12126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, 15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图在大数据和人工智能领域被广泛应用于建模复杂的关系数据。&lt;h4&gt;目的&lt;/h4&gt;识别有意义的图规律，以提升图生成和链接预测等应用的有效性。&lt;h4&gt;方法&lt;/h4&gt;从多个视角回顾图规律的研究，包括宏观和微观视角、低阶和高阶图、静态和动态图、不同观察空间及新提出的图参数。&lt;h4&gt;主要发现&lt;/h4&gt;图规律的研究揭示了新的研究潜力，尤其是在图神经表示学习和解决不同图数据之间的领域不一致性方面。&lt;h4&gt;结论&lt;/h4&gt;通过图规律指导的实际应用展示了其重要性，文末讨论了当前挑战和未来研究方向。&lt;h4&gt;总结&lt;/h4&gt;图规律的研究为多模态信息提供了支持，并推动了大规模基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs have been widely used in the past decades of big data and AI to modelcomprehensive relational data. When analyzing a graph's statistical properties,graph laws serve as essential tools for parameterizing its structure.Identifying meaningful graph laws can significantly enhance the effectivenessof various applications, such as graph generation and link prediction. Facingthe large-scale foundation model developments nowadays, the study of graph lawsreveals new research potential, e.g., providing multi-modal information forgraph neural representation learning and breaking the domain inconsistency ofdifferent graph data. In this survey, we first review the previous study ofgraph laws from multiple perspectives, i.e., macroscope and microscope ofgraphs, low-order and high-order graphs, static and dynamic graphs, differentobservation spaces, and newly proposed graph parameters. After we reviewvarious real-world applications benefiting from the guidance of graph laws, weconclude the paper with current challenges and future research directions.</description>
      <author>example@mail.com (Dongqi Fu, Liri Fang, Zihao Li, Hanghang Tong, Vetle I. Torvik, Jingrui He)</author>
      <guid isPermaLink="false">2410.12126v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>NavTopo: Leveraging Topological Maps For Autonomous Navigation Of a Mobile Robot</title>
      <link>http://arxiv.org/abs/2410.11492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is published in proceedings of the 9th International
  Conference "Interactive Collaborative Robotics" (ICR 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文遵循基于注意力的跟踪范式，提出了一种以物体为中心的基于变换器的3D跟踪框架。&lt;h4&gt;目的&lt;/h4&gt;旨在改进传统模型驱动的跟踪方法，考虑物体和自我运动之间的几何效应。&lt;h4&gt;方法&lt;/h4&gt;提出S.T.A.R.-Track，使用新颖的潜在运动模型（LMM）来调整对象查询，以直接在潜在空间中应对视角和光照变化，同时明确建模几何运动。&lt;h4&gt;主要发现&lt;/h4&gt;与新颖的可学习轨迹嵌入结合使用后，形成了一个通用的跟踪框架，可与任何基于查询的检测器集成。&lt;h4&gt;结论&lt;/h4&gt;在nuScenes基准测试中的广泛实验表明，所提方法在DETR3D基础的跟踪器中表现出色，同时显著减少了轨迹的身份切换数量。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种创新的跟踪框架，提升了3D跟踪的准确性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-71360-6_11&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous navigation of a mobile robot is a challenging task which requiresability of mapping, localization, path planning and path following.Conventional mapping methods build a dense metric map like an occupancy grid,which is affected by odometry error accumulation and consumes a lot of memoryand computations in large environments. Another approach to mapping is theusage of topological properties, e.g. adjacency of locations in theenvironment. Topological maps are less prone to odometry error accumulation andhigh resources consumption, and also enable fast path planning because of thegraph sparsity. Based on this idea, we proposed NavTopo - a full navigationpipeline based on topological map and two-level path planning. The pipelinelocalizes in the graph by matching neural network descriptors and 2Dprojections of the input point clouds, which significantly reduces memoryconsumption compared to metric and topological point cloud-based approaches. Wetest our approach in a large indoor photo-relaistic simulated environment andcompare it to a metric map-based approach based on popular metric mappingmethod RTAB-MAP. The experimental results show that our topological approachsignificantly outperforms the metric one in terms of performance, keepingproper navigational efficiency.</description>
      <author>example@mail.com (Kirill Muravyev, Konstantin Yakovlev)</author>
      <guid isPermaLink="false">2410.11492v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>S.T.A.R.-Track: Latent Motion Models for End-to-End 3D Object Tracking with Adaptive Spatio-Temporal Appearance Representations</title>
      <link>http://arxiv.org/abs/2306.17602v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  \c{opyright} 2023 IEEE. Personal use of this material is permitted.
  Permission from IEEE must be obtained for all other uses, in any current or
  future media, including reprinting/republishing this material for advertising
  or promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态学习在各个领域越来越重要，能够整合来自不同来源的数据，如图像、文本和个性化记录，尤其在医疗领域中常见。&lt;h4&gt;目的&lt;/h4&gt;提出Flex-MoE框架，灵活地整合任意模态组合，同时对缺失数据保持稳健性。&lt;h4&gt;方法&lt;/h4&gt;Flex-MoE通过新的缺失模态库处理缺失模态，结合观察到的模态组合与对应的缺失模态；同时设计稀疏MoE框架以提高效率。&lt;h4&gt;主要发现&lt;/h4&gt;在ADNI和MIMIC-IV数据集上的评估结果表明，Flex-MoE能够有效建模多样的缺失模态场景中的任意模态组合。&lt;h4&gt;结论&lt;/h4&gt;Flex-MoE展示了其在多模态学习中的有效性，尤其是在缺失模态情况下的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;Flex-MoE框架为多模态学习提供了一种新的解决方案，克服了现有框架对模态组合的限制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2023-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2023.3342552&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Following the tracking-by-attention paradigm, this paper introduces anobject-centric, transformer-based framework for tracking in 3D. Traditionalmodel-based tracking approaches incorporate the geometric effect of object- andego motion between frames with a geometric motion model. Inspired by this, wepropose S.T.A.R.-Track, which uses a novel latent motion model (LMM) toadditionally adjust object queries to account for changes in viewing directionand lighting conditions directly in the latent space, while still modeling thegeometric motion explicitly. Combined with a novel learnable track embeddingthat aids in modeling the existence probability of tracks, this results in ageneric tracking framework that can be integrated with any query-baseddetector. Extensive experiments on the nuScenes benchmark demonstrate thebenefits of our approach, showing state-of-the-art performance for DETR3D-basedtrackers while drastically reducing the number of identity switches of tracksat the same time.</description>
      <author>example@mail.com (Simon Doll, Niklas Hanselmann, Lukas Schneider, Richard Schulz, Markus Enzweiler, Hendrik P. A. Lensch)</author>
      <guid isPermaLink="false">2306.17602v3</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts</title>
      <link>http://arxiv.org/abs/2410.08245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Spotlight&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自然材料通常是无序的，其整体性质难以从结构中预测，因为缺乏基础的晶体轴。&lt;h4&gt;目的&lt;/h4&gt;开发一个数字化流程，从算法生成的可调无序配置到3D打印材料，以帮助研究这些材料，使用电阻作为测试案例。&lt;h4&gt;方法&lt;/h4&gt;材料设计始于随机点云，通过Lloyd算法迭代演变以接近均匀性，点通过Delaunay三角剖分连接形成无序网络超材料。&lt;h4&gt;主要发现&lt;/h4&gt;使用不锈钢17-4 PH和钛合金Ti-6Al-4V进行激光粉末床熔融增材制造，实验测量了无序网络的整体电阻率，发现图拉普拉斯算子准确预测了结构的有效电阻，但对各向异性和全局网络拓扑高度敏感。&lt;h4&gt;结论&lt;/h4&gt;单一网络统计或无序表征无法预测全局电阻率。&lt;h4&gt;总结&lt;/h4&gt;该研究为无序材料的电阻特性提供了新的理解和预测工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/unites-lab/flex-moe&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning has gained increasing importance across various fields,offering the ability to integrate data from diverse sources such as images,text, and personalized records, which are frequently observed in medicaldomains. However, in scenarios where some modalities are missing, many existingframeworks struggle to accommodate arbitrary modality combinations, oftenrelying heavily on a single modality or complete data. This oversight ofpotential modality combinations limits their applicability in real-worldsituations. To address this challenge, we propose Flex-MoE (FlexibleMixture-of-Experts), a new framework designed to flexibly incorporate arbitrarymodality combinations while maintaining robustness to missing data. The coreidea of Flex-MoE is to first address missing modalities using a new missingmodality bank that integrates observed modality combinations with thecorresponding missing ones. This is followed by a uniquely designed Sparse MoEframework. Specifically, Flex-MoE first trains experts using samples with allmodalities to inject generalized knowledge through the generalized router($\mathcal{G}$-Router). The $\mathcal{S}$-Router then specializes in handlingfewer modality combinations by assigning the top-1 gate to the expertcorresponding to the observed modality combination. We evaluate Flex-MoE on theADNI dataset, which encompasses four modalities in the Alzheimer's Diseasedomain, as well as on the MIMIC-IV dataset. The results demonstrate theeffectiveness of Flex-MoE highlighting its ability to model arbitrary modalitycombinations in diverse missing modality scenarios. Code is available athttps://github.com/UNITES-Lab/flex-moe.</description>
      <author>example@mail.com (Sukwon Yun, Inyoung Choi, Jie Peng, Yangfan Wu, Jingxuan Bao, Qiyiwen Zhang, Jiayi Xin, Qi Long, Tianlong Chen)</author>
      <guid isPermaLink="false">2410.08245v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Electrical Transport in Tunably-Disordered Metamaterials</title>
      <link>http://arxiv.org/abs/2410.11525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自然材料通常是无序的，其整体性质难以从结构中预测，因为缺乏基础的晶体轴。&lt;h4&gt;目的&lt;/h4&gt;开发一个数字化流程，从算法生成的可调无序配置到3D打印材料，以帮助研究这些材料，使用电阻作为测试案例。&lt;h4&gt;方法&lt;/h4&gt;材料设计始于随机点云，通过Lloyd算法迭代演变以接近均匀性，点通过Delaunay三角剖分连接形成无序网络超材料。&lt;h4&gt;主要发现&lt;/h4&gt;使用不锈钢17-4 PH和钛合金Ti-6Al-4V进行激光粉末床熔融增材制造，实验测量了无序网络的整体电阻率，发现图拉普拉斯算子准确预测了结构的有效电阻，但对各向异性和全局网络拓扑高度敏感。&lt;h4&gt;结论&lt;/h4&gt;单一网络统计或无序表征无法预测全局电阻率。&lt;h4&gt;总结&lt;/h4&gt;该研究为无序材料的电阻特性提供了新的理解和预测工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Naturally occurring materials are often disordered, with their bulkproperties being challenging to predict from the structure, due to the lack ofunderlying crystalline axes. In this paper, we develop a digital pipeline fromalgorithmically-created configurations with tunable disorder to 3D printedmaterials, as a tool to aid in the study of such materials, using electricalresistance as a test case. The designed material begins with a random pointcloud that is iteratively evolved using Lloyd's algorithm to approachuniformity, with the points being connected via a Delaunay triangulation toform a disordered network metamaterial. Utilizing laser powder bed fusionadditive manufacturing with stainless steel 17-4 PH and titanium alloyTi-6Al-4V, we are able to experimentally measure the bulk electricalresistivity of the disordered network. We found that the graph Laplacianaccurately predicts the effective resistance of the structure, but is highlysensitive to anisotropy and global network topology, preventing a singlenetwork statistic or disorder characterization from predicting globalresistivity.</description>
      <author>example@mail.com (Caitlyn Obrero, Mastawal Tirfe, Carmen Lee, Sourabh Saptarshi, Christopher Rock, Karen E. Daniels, Katherine A. Newhall)</author>
      <guid isPermaLink="false">2410.11525v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal graph neural networks for localized off-grid weather forecasting</title>
      <link>http://arxiv.org/abs/2410.12938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;紧急应用如野火管理和可再生能源发电需要精确的地表附近天气预报。&lt;h4&gt;目的&lt;/h4&gt;通过训练异构图神经网络（GNN）来将网格化的天气预报降尺度到感兴趣的非网格位置。&lt;h4&gt;方法&lt;/h4&gt;使用多模态GNN，利用当地历史天气观测（如风速、温度）来修正不同时间段的网格天气预报，并通过信息传递聚合邻近节点的信息。&lt;h4&gt;主要发现&lt;/h4&gt;在美国东北部的天气站实验中，我们的模型优于多种数据驱动和非数据驱动的非网格预报方法。&lt;h4&gt;结论&lt;/h4&gt;我们的方法展示了如何弥合全球大型天气模型与局部准确预测之间的差距，以支持局部决策制定。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种有效的天气预报降尺度方法，能够提高紧急应用中的天气预报精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/earth-intelligence-lab/localizedweathergnn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urgent applications like wildfire management and renewable energy generationrequire precise, localized weather forecasts near the Earth's surface. However,weather forecast products from machine learning or numerical weather models arecurrently generated on a global regular grid, on which a naive interpolationcannot accurately reflect fine-grained weather patterns close to the ground. Inthis work, we train a heterogeneous graph neural network (GNN) end-to-end todownscale gridded forecasts to off-grid locations of interest. This multi-modalGNN takes advantage of local historical weather observations (e.g., wind,temperature) to correct the gridded weather forecast at different lead timestowards locally accurate forecasts. Each data modality is modeled as adifferent type of node in the graph. Using message passing, the node at theprediction location aggregates information from its heterogeneous neighbornodes. Experiments using weather stations across the Northeastern United Statesshow that our model outperforms a range of data-driven and non-data-drivenoff-grid forecasting methods. Our approach demonstrates how the gap betweenglobal large-scale weather models and locally accurate predictions can bebridged to inform localized decision-making.</description>
      <author>example@mail.com (Qidong Yang, Jonathan Giezendanner, Daniel Salles Civitarese, Johannes Jakubik, Eric Schmitt, Anirban Chandra, Jeremy Vila, Detlef Hohl, Chris Hill, Campbell Watson, Sherrie Wang)</author>
      <guid isPermaLink="false">2410.12938v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Fusion based Q-distribution Prediction for Controlled Nuclear Fusion</title>
      <link>http://arxiv.org/abs/2410.08879v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Q分布预测是受控核聚变中的重要研究方向，深度学习成为解决预测挑战的关键方法。&lt;h4&gt;目的&lt;/h4&gt;利用深度学习技术应对Q分布预测的复杂性。&lt;h4&gt;方法&lt;/h4&gt;探索计算机视觉中的多模态融合方法，将2D线图像数据与原始1D数据结合形成双模输入，并采用Transformer的注意力机制进行特征提取和双模信息的交互融合。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验验证了我们方法的有效性，显著减少了Q分布的预测误差。&lt;h4&gt;结论&lt;/h4&gt;我们的研究表明，深度学习技术在Q分布预测中具有重要应用潜力。&lt;h4&gt;总结&lt;/h4&gt;该论文展示了深度学习在控制核聚变研究中，特别是在Q分布预测方面的创新应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Q-distribution prediction is a crucial research direction in controllednuclear fusion, with deep learning emerging as a key approach to solvingprediction challenges. In this paper, we leverage deep learning techniques totackle the complexities of Q-distribution prediction. Specifically, we exploremultimodal fusion methods in computer vision, integrating 2D line image datawith the original 1D data to form a bimodal input. Additionally, we employ theTransformer's attention mechanism for feature extraction and the interactivefusion of bimodal information. Extensive experiments validate the effectivenessof our approach, significantly reducing prediction errors in Q-distribution.</description>
      <author>example@mail.com (Shiao Wang, Yifeng Wang, Qingchuan Ma, Xiao Wang, Ning Yan, Qingquan Yang, Guosheng Xu, Jin Tang)</author>
      <guid isPermaLink="false">2410.08879v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>PAVLM: Advancing Point Cloud based Affordance Understanding Via Vision-Language Model</title>
      <link>http://arxiv.org/abs/2410.11564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;了解可供性是识别3D物体上可操作区域的任务，对于机器人系统在物理世界中的互动至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出PAVLM框架，以增强点云的3D可供性理解。&lt;h4&gt;方法&lt;/h4&gt;PAVLM结合几何引导传播模块与大语言模型的隐藏嵌入，丰富视觉语义，同时利用Llama-3.1模型生成上下文感知的文本。&lt;h4&gt;主要发现&lt;/h4&gt;在3D-AffordanceNet基准测试中，PAVLM在完整和部分点云任务上均超过了基线方法，特别是在新颖的开放世界可供性任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;PAVLM有效提高了3D物体的可供性理解能力，展示了其在人机互动中的潜力。&lt;h4&gt;总结&lt;/h4&gt;PAVLM通过整合多模态知识和上下文感知生成，显著提升了机器人操作的理解和表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Affordance understanding, the task of identifying actionable regions on 3Dobjects, plays a vital role in allowing robotic systems to engage with andoperate within the physical world. Although Visual Language Models (VLMs) haveexcelled in high-level reasoning and long-horizon planning for roboticmanipulation, they still fall short in grasping the nuanced physical propertiesrequired for effective human-robot interaction. In this paper, we introducePAVLM (Point cloud Affordance Vision-Language Model), an innovative frameworkthat utilizes the extensive multimodal knowledge embedded in pre-trainedlanguage models to enhance 3D affordance understanding of point cloud. PAVLMintegrates a geometric-guided propagation module with hidden embeddings fromlarge language models (LLMs) to enrich visual semantics. On the language side,we prompt Llama-3.1 models to generate refined context-aware text, augmentingthe instructional input with deeper semantic cues. Experimental results on the3D-AffordanceNet benchmark demonstrate that PAVLM outperforms baseline methodsfor both full and partial point clouds, particularly excelling in itsgeneralization to novel open-world affordance tasks of 3D objects. For moreinformation, visit our project site: pavlm-source.github.io.</description>
      <author>example@mail.com (Shang-Ching Liu, Van Nhiem Tran, Wenkai Chen, Wei-Lun Cheng, Yen-Lin Huang, I-Bin Liao, Yung-Hui Li, Jianwei Zhang)</author>
      <guid isPermaLink="false">2410.11564v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Learning Representations for Reasoning: Generalizing Across Diverse Structures</title>
      <link>http://arxiv.org/abs/2410.13018v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;推荐系统广泛应用于各个领域，以预测用户偏好，提供个性化体验，增强用户参与度和满意度。然而，传统推荐系统受到混淆偏差的影响，尤其是在潜在混淆因素存在时，这些因素同时影响项目曝光和用户反馈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的去偏差方法，结合工具变量（IV）方法和可识别变分自编码器（iVAE），实现推荐系统中的去偏差表示学习，称为IViDR。&lt;h4&gt;方法&lt;/h4&gt;IViDR利用用户特征的嵌入作为工具变量，处理潜在混淆因素造成的偏差，并重构项目的嵌入，以获得去偏差的交互数据。同时，使用iVAE推断项目曝光与用户反馈之间潜在混淆因素的可识别表示。&lt;h4&gt;主要发现&lt;/h4&gt;IViDR在合成和真实世界数据集上的大量实验表明，其在减少偏差和提供可靠推荐方面，优于现有的最先进模型。&lt;h4&gt;结论&lt;/h4&gt;IViDR有效地解决了潜在混淆因素造成的偏差问题，提供了更可靠的推荐结果。&lt;h4&gt;总结&lt;/h4&gt;IViDR结合了理论分析与实证实验，证明了工具变量的有效性及潜在表示的可识别性，为推荐系统的去偏差提供了新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning, the ability to logically draw conclusions from existing knowledge,is a hallmark of human. Together with perception, they constitute the two majorthemes of artificial intelligence. While deep learning has pushed the limit ofperception beyond human-level performance, the progress in reasoning domains isway behind. One fundamental reason is that reasoning problems usually haveflexible structures for both knowledge and queries, and many existing modelsonly perform well on structures seen during training. Here we aim to push theboundary of reasoning models by devising algorithms that generalize acrossknowledge and query structures, as well as systems that accelerate developmenton structured data. This thesis consists of three parts. In Part I, we studymodels that can inductively generalize to unseen knowledge graphs with newentity and relation vocabularies. For new entities, we propose a framework thatlearns neural operators in a dynamic programming algorithm computing pathrepresentations. For relations, we construct a relation graph to capture theinteractions between relations, thereby converting new relations into newentities. In Part II, we propose two solutions for generalizing acrossmulti-step queries on knowledge graphs and text respectively. For knowledgegraphs, we show that multi-step queries can be solved by multiple calls ofgraph neural networks and fuzzy logic operations. For text, we devise analgorithm to learn explicit knowledge as textual rules to improve largelanguage models on multi-step queries. In Part III, we propose two systems tofacilitate machine learning development on structured data. Our library treatsstructured data as first-class citizens and removes the barrier for developingalgorithms on structured data. Our node embedding system solves the GPU memorybottleneck of embedding matrices and scales to graphs with billion nodes.</description>
      <author>example@mail.com (Zhaocheng Zhu)</author>
      <guid isPermaLink="false">2410.13018v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Dual Latent Confounding Biases in Recommender Systems</title>
      <link>http://arxiv.org/abs/2410.12451v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模仿学习在机器人操控领域取得了一定进展，但在处理复杂的长时间可变物体任务时仍面临挑战，如高维状态空间、复杂动态和多模态动作分布。&lt;h4&gt;目的&lt;/h4&gt;提出一个数据高效的通用学习框架DeformPAM，旨在解决传统模仿学习方法中数据需求大、分布偏移和累积错误的问题。&lt;h4&gt;方法&lt;/h4&gt;DeformPAM将长时间任务分解为多个动作原语，利用3D点云输入和扩散模型来建模动作分布，并使用人类偏好数据训练隐式奖励模型。&lt;h4&gt;主要发现&lt;/h4&gt;在推理阶段，奖励模型对多个候选动作进行评分，选择最佳执行动作，从而减少异常动作的发生，提高任务完成质量。&lt;h4&gt;结论&lt;/h4&gt;在三个具有挑战性的真实世界长时间可变物体操控任务上的实验表明，DeformPAM相比基线方法在任务完成质量和效率上都有显著改善，即使在数据有限的情况下。&lt;h4&gt;总结&lt;/h4&gt;DeformPAM有效解决了长时间可变物体操控中的关键问题，提升了模仿学习的应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recommender systems are extensively utilised across various areas to predictuser preferences for personalised experiences and enhanced user engagement andsatisfaction. Traditional recommender systems, however, are complicated byconfounding bias, particularly in the presence of latent confounders thataffect both item exposure and user feedback. Existing debiasing methods oftenfail to capture the complex interactions caused by latent confounders ininteraction data, especially when dual latent confounders affect both the userand item sides. To address this, we propose a novel debiasing method thatjointly integrates the Instrumental Variables (IV) approach and identifiableVariational Auto-Encoder (iVAE) for Debiased representation learning inRecommendation systems, referred to as IViDR. Specifically, IViDR leverages theembeddings of user features as IVs to address confounding bias caused by latentconfounders between items and user feedback, and reconstructs the embedding ofitems to obtain debiased interaction data. Moreover, IViDR employs anIdentifiable Variational Auto-Encoder (iVAE) to infer identifiablerepresentations of latent confounders between item exposure and user feedbackfrom both the original and debiased interaction data. Additionally, we providetheoretical analyses of the soundness of using IV and the identifiability ofthe latent representations. Extensive experiments on both synthetic andreal-world datasets demonstrate that IViDR outperforms state-of-the-art modelsin reducing bias and providing reliable recommendations.</description>
      <author>example@mail.com (Jianfeng Deng, Qingfeng Chen, Debo Cheng, Jiuyong Li, Lin Liu, Xiaojing Du)</author>
      <guid isPermaLink="false">2410.12451v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignment</title>
      <link>http://arxiv.org/abs/2410.11584v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模仿学习在机器人操控领域取得了一定进展，但在处理复杂的长时间可变物体任务时仍面临挑战，如高维状态空间、复杂动态和多模态动作分布。&lt;h4&gt;目的&lt;/h4&gt;提出一个数据高效的通用学习框架DeformPAM，旨在解决传统模仿学习方法中数据需求大、分布偏移和累积错误的问题。&lt;h4&gt;方法&lt;/h4&gt;DeformPAM将长时间任务分解为多个动作原语，利用3D点云输入和扩散模型来建模动作分布，并使用人类偏好数据训练隐式奖励模型。&lt;h4&gt;主要发现&lt;/h4&gt;在推理阶段，奖励模型对多个候选动作进行评分，选择最佳执行动作，从而减少异常动作的发生，提高任务完成质量。&lt;h4&gt;结论&lt;/h4&gt;在三个具有挑战性的真实世界长时间可变物体操控任务上的实验表明，DeformPAM相比基线方法在任务完成质量和效率上都有显著改善，即使在数据有限的情况下。&lt;h4&gt;总结&lt;/h4&gt;DeformPAM有效解决了长时间可变物体操控中的关键问题，提升了模仿学习的应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, imitation learning has made progress in the field of roboticmanipulation. However, it still faces challenges when dealing with complexlong-horizon deformable object tasks, such as high-dimensional state spaces,complex dynamics, and multimodal action distributions. Traditional imitationlearning methods often require a large amount of data and encounterdistributional shifts and accumulative errors in these tasks. To address theseissues, we propose a data-efficient general learning framework (DeformPAM)based on preference learning and reward-guided action selection. DeformPAMdecomposes long-horizon tasks into multiple action primitives, utilizes 3Dpoint cloud inputs and diffusion models to model action distributions, andtrains an implicit reward model using human preference data. During theinference phase, the reward model scores multiple candidate actions, selectingthe optimal action for execution, thereby reducing the occurrence of anomalousactions and improving task completion quality. Experiments conducted on threechallenging real-world long-horizon deformable object manipulation tasksdemonstrate the effectiveness of this method. Results show that DeformPAMimproves both task completion quality and efficiency compared to baselinemethods even with limited data. Code and data will be available athttps://deform-pam.robotflow.ai.</description>
      <author>example@mail.com (Wendi Chen, Han Xue, Fangyuan Zhou, Yuan Fang, Cewu Lu)</author>
      <guid isPermaLink="false">2410.11584v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>AuD-Former: A Hierarchical Transformer Network for Multimodal Audio-Based Disease Prediction</title>
      <link>http://arxiv.org/abs/2410.09289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于音频的疾病预测逐渐成为传统医学诊断方法的有力补充，能够实现早期、方便和无创的疾病检测与预防。&lt;h4&gt;目的&lt;/h4&gt;提出AuD-Former，一种针对多模态音频疾病预测的分层变换网络。&lt;h4&gt;方法&lt;/h4&gt;在分层方式中无缝整合了内模态与跨模态融合，同时有效编码内模态和跨模态的互补相关性。&lt;h4&gt;主要发现&lt;/h4&gt;AuD-Former在预测三种疾病（COVID-19、帕金森病、病理性构音障碍）方面表现出最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;AuD-Former在音频疾病预测任务中展现出广泛的潜力，且各主要组件的显著益处通过广泛的消融研究和定性分析得到了验证。&lt;h4&gt;总结&lt;/h4&gt;该研究填补了现有方法中的不足，通过综合利用多模态数据的互补性，提升了疾病预测的准确性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-based disease prediction is emerging as a promising supplement totraditional medical diagnosis methods, facilitating early, convenient, andnon-invasive disease detection and prevention. Multimodal fusion, whichintegrates features from various domains within or across bio-acousticmodalities, has proven effective in enhancing diagnostic performance. However,most existing methods in the field employ unilateral fusion strategies thatfocus solely on either intra-modal or inter-modal fusion. This approach limitsthe full exploitation of the complementary nature of diverse acoustic featuredomains and bio-acoustic modalities. Additionally, the inadequate and isolatedexploration of latent dependencies within modality-specific and modality-sharedspaces curtails their capacity to manage the inherent heterogeneity inmultimodal data. To fill these gaps, we propose AuD-Former, a hierarchicaltransformer network designed for general multimodal audio-based diseaseprediction. Specifically, we seamlessly integrate intra-modal and inter-modalfusion in a hierarchical manner and proficiently encode the necessaryintra-modal and inter-modal complementary correlations, respectively.Comprehensive experiments demonstrate that AuD-Former achieves state-of-the-artperformance in predicting three diseases: COVID-19, Parkinson's disease, andpathological dysarthria, showcasing its promising potential in a broad contextof audio-based disease prediction tasks. Additionally, extensive ablationstudies and qualitative analyses highlight the significant benefits of eachmain component within our model.</description>
      <author>example@mail.com (Jinjin Cai, Ruiqi Wang, Dezhong Zhao, Ziqin Yuan, Victoria McKenna, Aaron Friedman, Rachel Foot, Susan Storey, Ryan Boente, Sudip Vhaduri, Byung-Cheol Min)</author>
      <guid isPermaLink="false">2410.09289v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Exploring transfer learning for Deep NLP systems on rarely annotated languages</title>
      <link>http://arxiv.org/abs/2410.12879v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自然语言处理(NLP)随着深度学习的兴起迅速发展，显著超越了传统规则基础的方法。&lt;h4&gt;目的&lt;/h4&gt;研究在印地语和尼泊尔语之间应用迁移学习进行词性标注的效果。&lt;h4&gt;方法&lt;/h4&gt;使用BLSTM-CNN-CRF模型进行训练，探索联合训练和多任务学习对词性标注准确性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;联合训练的印地语-尼泊尔语词嵌入在所有模型中相较于单语和向量映射嵌入显著提高了性能。&lt;h4&gt;结论&lt;/h4&gt;通过共同训练和多任务学习可以有效提升词性标注的准确性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了深度学习在少数语言的NLP任务中的潜力，尤其是利用语言之间的相似性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Natural language processing (NLP) has experienced rapid advancements with therise of deep learning, significantly outperforming traditional rule-basedmethods. By capturing hidden patterns and underlying structures within data,deep learning has improved performance across various NLP tasks, overcoming thelimitations of rule-based systems. However, most research and development inNLP has been concentrated on a select few languages, primarily those with largenumbers of speakers or financial significance, leaving many othersunderexplored. This lack of research is often attributed to the scarcity ofadequately annotated datasets essential for training deep learning models.Despite this challenge, there is potential in leveraging the linguisticsimilarities between unexplored and well-studied languages, particularly thosein close geographic and linguistic proximity. This thesis investigates theapplication of transfer learning for Part-of-Speech (POS) tagging between Hindiand Nepali, two highly similar languages belonging to the Indo-Aryan languagefamily. Specifically, the work explores whether joint training of a POS taggingmodel for both languages enhances performance. Additionally, we assess whethermultitask learning in Hindi, with auxiliary tasks such as gender andsingular/plural tagging, can contribute to improved POS tagging accuracy. Thedeep learning architecture employed is the BLSTM-CNN-CRF model, trained underdifferent conditions: monolingual word embeddings, vector-mapped embeddings,and jointly trained Hindi-Nepali word embeddings. Varying dropout rates (0.25to 0.5) and optimizers (ADAM and AdaDelta) are also evaluated. Results indicatethat jointly trained Hindi-Nepali word embeddings improve performance acrossall models compared to monolingual and vector-mapped embeddings.</description>
      <author>example@mail.com (Dipendra Yadav, Tobias Strauß, Kristina Yordanova)</author>
      <guid isPermaLink="false">2410.12879v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Iter-AHMCL: Alleviate Hallucination for Large Language Model via Iterative Model-level Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.12130v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大语言模型（LLMs）的发展推动了商业和科学研究中的多种AI应用，但在推理过程中存在高风险的幻觉问题。&lt;h4&gt;目的&lt;/h4&gt;开发有效的方法以减少幻觉，同时保持LLM的原有能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新方法，称为迭代模型级对比学习（Iter-AHMCL），通过对比训练有幻觉和无幻觉的数据模型，修改预训练LLM的表示层。&lt;h4&gt;主要发现&lt;/h4&gt;在四个预训练基础LLM（LLaMA2、Alpaca、LLaMA3和Qwen）上进行的实验表明，该方法在TruthfulQA基准上平均提高了10.1分。&lt;h4&gt;结论&lt;/h4&gt;Iter-AHMCL在减少幻觉的同时，保持了LLM的一般能力，证明了其有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的Iter-AHMCL方法为解决LLM的幻觉问题提供了新思路，具有重要的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of Large Language Models (LLMs) has significantly advancedvarious AI applications in commercial and scientific research fields, such asscientific literature summarization, writing assistance, and knowledge graphconstruction. However, a significant challenge is the high risk ofhallucination during LLM inference, which can lead to security concerns likefactual inaccuracies, inconsistent information, and fabricated content. Totackle this issue, it is essential to develop effective methods for reducinghallucination while maintaining the original capabilities of the LLM. Thispaper introduces a novel approach called Iterative Model-level ContrastiveLearning (Iter-AHMCL) to address hallucination. This method modifies therepresentation layers of pre-trained LLMs by using contrastive `positive' and`negative' models, trained on data with and without hallucinations. Byleveraging the differences between these two models, we create a morestraightforward pathway to eliminate hallucinations, and the iterative natureof contrastive learning further enhances performance. Experimental validationon four pre-trained foundation LLMs (LLaMA2, Alpaca, LLaMA3, and Qwen)finetuning with a specially designed dataset shows that our approach achievesan average improvement of 10.1 points on the TruthfulQA benchmark.Comprehensive experiments demonstrate the effectiveness of Iter-AHMCL inreducing hallucination while maintaining the general capabilities of LLMs.</description>
      <author>example@mail.com (Huiwen Wu, Xiaohan Li, Xiaogang Xu, Jiafei Wu, Deyi Zhang, Zhe Liu)</author>
      <guid isPermaLink="false">2410.12130v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Simultaneous Diffusion Sampling for Conditional LiDAR Generation</title>
      <link>http://arxiv.org/abs/2410.11628v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;LiDAR作为自主系统的主要传感器，可以捕捉反映环境几何形状的3D点云。&lt;h4&gt;目的&lt;/h4&gt;在LiDAR扫描稀疏、被障碍物遮挡或范围过小的情况下，增强点云扫描以支持后续任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的同时扩散采样方法，基于场景的3D结构从多个视角生成点云，利用多视角几何约束和互信息提高结果质量。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够生成准确且几何一致的点云增强，显著优于现有方法，适用于多种基准测试。&lt;h4&gt;结论&lt;/h4&gt;通过重新构建输入扫描到多个新视角，生成合成LiDAR扫描，结合输入和合成扫描的条件生成，能够有效提升点云扫描的质量。&lt;h4&gt;总结&lt;/h4&gt;提出的生成方法在点云扫描增强上取得了显著进展，展示了生成性方法在计算机视觉中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; By enabling capturing of 3D point clouds that reflect the geometry of theimmediate environment, LiDAR has emerged as a primary sensor for autonomoussystems. If a LiDAR scan is too sparse, occluded by obstacles, or too small inrange, enhancing the point cloud scan by while respecting the geometry of thescene is useful for downstream tasks. Motivated by the explosive growth ofinterest in generative methods in vision, conditional LiDAR generation isstarting to take off. This paper proposes a novel simultaneous diffusionsampling methodology to generate point clouds conditioned on the 3D structureof the scene as seen from multiple views. The key idea is to impose multi-viewgeometric constraints on the generation process, exploiting mutual informationfor enhanced results. Our method begins by recasting the input scan to multiplenew viewpoints around the scan, thus creating multiple synthetic LiDAR scans.Then, the synthetic and input LiDAR scans simultaneously undergo conditionalgeneration according to our methodology. Results show that our method canproduce accurate and geometrically consistent enhancements to point cloudscans, allowing it to outperform existing methods by a large margin in avariety of benchmarks.</description>
      <author>example@mail.com (Ryan Faulkner, Luke Haub, Simon Ratcliffe, Anh-Dzung Doan, Ian Reid, Tat-Jun Chin)</author>
      <guid isPermaLink="false">2410.11628v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Improving Colorectal Cancer Screening and Risk Assessment through Predictive Modeling on Medical Images and Records</title>
      <link>http://arxiv.org/abs/2410.09880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;结肠镜筛查是发现和去除结肠息肉以防止其发展为结直肠癌（CRC）的一种有效方法。&lt;h4&gt;目的&lt;/h4&gt;探讨在CRC风险评估中结合额外的医疗记录信息和自动处理病理切片的计算机视觉技术的潜在好处。&lt;h4&gt;方法&lt;/h4&gt;利用新罕布什尔州结肠镜注册中心的大型数据集，适应一种基于变换器的模型进行病理图像分析，以预测5年内的CRC风险，并研究多模态融合技术。&lt;h4&gt;主要发现&lt;/h4&gt;训练变换器模型以预测中间临床变量可以提升5年CRC风险预测性能，AUC为0.630。同时，融合影像和非影像特征的预测能力优于仅依赖结肠镜程序和显微镜发现提取的变量。&lt;h4&gt;结论&lt;/h4&gt;本研究表明，整合多种数据源和先进计算技术有助于提高未来CRC风险评估的准确性和有效性。&lt;h4&gt;总结&lt;/h4&gt;研究强调了数字病理学和深度学习技术在结直肠癌风险评估中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Colonoscopy screening is an effective method to find and remove colon polypsbefore they can develop into colorectal cancer (CRC). Current follow-uprecommendations, as outlined by the U.S. Multi-Society Task Force forindividuals found to have polyps, primarily rely on histopathologicalcharacteristics, neglecting other significant CRC risk factors. Moreover, theconsiderable variability in colorectal polyp characterization amongpathologists poses challenges in effective colonoscopy follow-up orsurveillance. The evolution of digital pathology and recent advancements indeep learning provide a unique opportunity to investigate the added benefits ofincluding the additional medical record information and automatic processing ofpathology slides using computer vision techniques in the calculation of futureCRC risk. Leveraging the New Hampshire Colonoscopy Registry's extensivedataset, many with longitudinal colonoscopy follow-up information, we adaptedour recently developed transformer-based model for histopathology imageanalysis in 5-year CRC risk prediction. Additionally, we investigated variousmultimodal fusion techniques, combining medical record information with deeplearning derived risk estimates. Our findings reveal that training atransformer model to predict intermediate clinical variables contributes toenhancing 5-year CRC risk prediction performance, with an AUC of 0.630comparing to direct prediction. Furthermore, the fusion of imaging andnon-imaging features, while not requiring manual inspection of microscopyimages, demonstrates improved predictive capabilities for 5-year CRC riskcomparing to variables extracted from colonoscopy procedure and microscopyfindings. This study signifies the potential of integrating diverse datasources and advanced computational techniques in transforming the accuracy andeffectiveness of future CRC risk assessments.</description>
      <author>example@mail.com (Shuai Jiang, Christina Robinson, Joseph Anderson, William Hisey, Lynn Butterly, Arief Suriawinata, Saeed Hassanpour)</author>
      <guid isPermaLink="false">2410.09880v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>YOLO-ELA: Efficient Local Attention Modeling for High-Performance Real-Time Insulator Defect Detection</title>
      <link>http://arxiv.org/abs/2410.11727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督对比学习依赖于数据增强带来的视图变化，以学习视图不变的预训练表示。&lt;h4&gt;目的&lt;/h4&gt;提高训练数据的多样性，以增强预训练模型的泛化能力和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出统一框架进行特征空间的数据增强，称为特征增强，增强与原始特征相似的特征，改善数据多样性。&lt;h4&gt;主要发现&lt;/h4&gt;系统研究不同的特征增强架构、梯度流技巧，以及特征增强与传统数据增强之间的关系，揭示特征增强在自对比学习中的一些实用原则。&lt;h4&gt;结论&lt;/h4&gt;通过在实例区分或实例相似性范式中整合特征增强，持续改善预训练特征学习的表现，并在下游图像分类和目标检测任务中获得更好的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;特征增强为自监督学习提供了一种有效的方法，提升了模型在多个任务中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing detection methods for insulator defect identification from unmannedaerial vehicles (UAV) struggle with complex background scenes and smallobjects, leading to suboptimal accuracy and a high number of false positivesdetection. Using the concept of local attention modeling, this paper proposes anew attention-based foundation architecture, YOLO-ELA, to address this issue.The Efficient Local Attention (ELA) blocks were added into the neck part of theone-stage YOLOv8 architecture to shift the model's attention from backgroundfeatures towards features of insulators with defects. The SCYLLAIntersection-Over-Union (SIoU) criterion function was used to reduce detectionloss, accelerate model convergence, and increase the model's sensitivitytowards small insulator defects, yielding higher true positive outcomes. Due toa limited dataset, data augmentation techniques were utilized to increase thediversity of the dataset. In addition, we leveraged the transfer learningstrategy to improve the model's performance. Experimental results onhigh-resolution UAV images show that our method achieved a state-of-the-artperformance of 96.9% mAP0.5 and a real-time detection speed of 74.63 frames persecond, outperforming the baseline model. This further demonstrates theeffectiveness of attention-based convolutional neural networks (CNN) in objectdetection tasks.</description>
      <author>example@mail.com (Olalekan Akindele, Joshua Atolagbe)</author>
      <guid isPermaLink="false">2410.11727v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Feature Augmentation for Self-supervised Contrastive Learning: A Closer Look</title>
      <link>http://arxiv.org/abs/2410.12396v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IJCNN 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自适应控制的一个关键目标是使机器人能够快速适应动态环境。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习基础自适应控制框架，以提高对动态环境的适应能力。&lt;h4&gt;方法&lt;/h4&gt;采用自监督元学习（SSML）对深度神经网络（DNN）进行预训练，并通过复合适应在线调整完整的DNN。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的框架在面对大风干扰的真实四旋翼跟踪问题中，相比经典和基于学习的自适应控制基线显著提升了19-39%的性能。&lt;h4&gt;结论&lt;/h4&gt;该框架能够有效利用离线轨迹数据，提升自适应控制的稳定性和响应能力。&lt;h4&gt;总结&lt;/h4&gt;通过引入新的自适应控制框架，显著增强了在动态环境中机器人的适应能力，充分发挥了DNN的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised contrastive learning heavily relies on the view variancebrought by data augmentation, so that it can learn a view-invariant pre-trainedrepresentation. Beyond increasing the view variance for contrast, this workfocuses on improving the diversity of training data, to improve thegeneralization and robustness of the pre-trained models. To this end, wepropose a unified framework to conduct data augmentation in the feature space,known as feature augmentation. This strategy is domain-agnostic, which augmentssimilar features to the original ones and thus improves the data diversity. Weperform a systematic investigation of various feature augmentationarchitectures, the gradient-flow skill, and the relationship between featureaugmentation and traditional data augmentation. Our study reveals somepractical principles for feature augmentation in self-contrastive learning. Byintegrating feature augmentation on the instance discrimination or the instancesimilarity paradigm, we consistently improve the performance of pre-trainedfeature learning and gain better generalization over the downstream imageclassification and object detection task.</description>
      <author>example@mail.com (Yong Zhang, Rui Zhu, Shifeng Zhang, Xu Zhou, Shifeng Chen, Xiaofan Chen)</author>
      <guid isPermaLink="false">2410.12396v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Meta-Learning for All-Layer DNN-Based Adaptive Control with Stability Guarantees</title>
      <link>http://arxiv.org/abs/2410.07575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交错的多模态理解与生成在多模态学习中成为重要领域，但现有评估不足。&lt;h4&gt;目的&lt;/h4&gt;提出MMIE，一个大型知识密集型基准，用于评估大型视觉语言模型（LVLMs）的交错多模态理解与生成能力。&lt;h4&gt;方法&lt;/h4&gt;MMIE包含2万个精心策划的多模态查询，涵盖3个类别、12个领域和102个子领域，支持交错输入和输出，提供多项选择和开放式问题格式。&lt;h4&gt;主要发现&lt;/h4&gt;对八个LVLMs进行评估，发现即便是最佳模型也有显著改进空间，大多数模型仅达到中等结果。&lt;h4&gt;结论&lt;/h4&gt;MMIE将推动交错LVLMs的发展，基准和代码已公开发布。&lt;h4&gt;总结&lt;/h4&gt;MMIE为交错多模态理解与生成提供了全面的评估工具，旨在提高评估的准确性和减少偏见。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A critical goal of adaptive control is enabling robots to rapidly adapt indynamic environments. Recent studies have developed a meta-learning-basedadaptive control scheme, which uses meta-learning to extract nonlinear features(represented by Deep Neural Networks (DNNs)) from offline data, and usesadaptive control to update linear coefficients online. However, such a schemeis fundamentally limited by the linear parameterization of uncertainties anddoes not fully unleash the capability of DNNs. This paper introduces a novellearning-based adaptive control framework that pretrains a DNN viaself-supervised meta-learning (SSML) from offline trajectories and onlineadapts the full DNN via composite adaptation. In particular, the offline SSMLstage leverages the time consistency in trajectory data to train the DNN topredict future disturbances from history, in a self-supervised manner withoutenvironment condition labels. The online stage carefully designs a control lawand an adaptation law to update the full DNN with stability guarantees.Empirically, the proposed framework significantly outperforms (19-39%) variousclassic and learning-based adaptive control baselines, in challengingreal-world quadrotor tracking problems under large dynamic wind disturbance.</description>
      <author>example@mail.com (Guanqi He, Yogita Choudhary, Guanya Shi)</author>
      <guid isPermaLink="false">2410.07575v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models</title>
      <link>http://arxiv.org/abs/2410.10139v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度隐写术中，模型大小通常与底层网格分辨率相关，需要训练一个单独的神经网络作为消息提取器。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于点云表示的生成图像隐写术。&lt;h4&gt;方法&lt;/h4&gt;将图像数据表示为点云，学习点云数据的分布，并以连续函数的形式表示，突破图像分辨率的限制。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以根据实际需要生成任意分辨率的图像，避免了对显式数据的需求。&lt;h4&gt;结论&lt;/h4&gt;使用固定的点云提取器将网络训练转移到点云数据上，节省训练时间，并降低了因消息提取器传输而暴露隐写行为的风险。&lt;h4&gt;实验结果&lt;/h4&gt;实验表明，该方案生成的隐写图像具有非常高的图像质量，消息提取的准确率超过99%。&lt;h4&gt;总结&lt;/h4&gt;提出的点云表示方法有效提升了隐写术的灵活性和安全性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Lillianwei-h/MMIE&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interleaved multimodal comprehension and generation, enabling models toproduce and interpret both images and text in arbitrary sequences, have becomea pivotal area in multimodal learning. Despite significant advancements, theevaluation of this capability remains insufficient. Existing benchmarks sufferfrom limitations in data scale, scope, and evaluation depth, while currentevaluation metrics are often costly or biased, lacking in reliability forpractical applications. To address these challenges, we introduce MMIE, alarge-scale knowledge-intensive benchmark for evaluating interleaved multimodalcomprehension and generation in Large Vision-Language Models (LVLMs). MMIEcomprises 20K meticulously curated multimodal queries, spanning 3 categories,12 fields, and 102 subfields, including mathematics, coding, physics,literature, health, and arts. It supports both interleaved inputs and outputs,offering a mix of multiple-choice and open-ended question formats to evaluatediverse competencies. Moreover, we propose a reliable automated evaluationmetric, leveraging a scoring model fine-tuned with human-annotated data andsystematic evaluation criteria, aimed at reducing bias and improving evaluationaccuracy. Extensive experiments demonstrate the effectiveness of our benchmarkand metrics in providing a comprehensive evaluation of interleaved LVLMs.Specifically, we evaluate eight LVLMs, revealing that even the best models showsignificant room for improvement, with most achieving only moderate results. Webelieve MMIE will drive further advancements in the development of interleavedLVLMs. We publicly release our benchmark and code inhttps://mmie-bench.github.io/.</description>
      <author>example@mail.com (Peng Xia, Siwei Han, Shi Qiu, Yiyang Zhou, Zhaoyang Wang, Wenhao Zheng, Zhaorun Chen, Chenhang Cui, Mingyu Ding, Linjie Li, Lijuan Wang, Huaxiu Yao)</author>
      <guid isPermaLink="false">2410.10139v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Generative Image Steganography Based on Point Cloud</title>
      <link>http://arxiv.org/abs/2410.11673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11pages,13figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列数据在医疗和工业等领域信息丰富，但由于高维度和缺乏标签，处理起来具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出TimeDRL框架，以解决多变量时间序列表示学习中的解缠嵌入和归纳偏差问题。&lt;h4&gt;方法&lt;/h4&gt;TimeDRL采用双层解缠嵌入，使用[CLS]标记策略生成时间戳级和实例级嵌入，并通过时间戳预测和实例对比任务进行表示学习，同时避免使用增强方法以消除归纳偏差。&lt;h4&gt;主要发现&lt;/h4&gt;在预测和分类数据集上的实验表明，TimeDRL优于现有方法，并在半监督设置下验证了其在有限标签数据下的有效性。&lt;h4&gt;结论&lt;/h4&gt;TimeDRL能够有效地学习多变量时间序列的表示，解决了现有方法的限制。&lt;h4&gt;总结&lt;/h4&gt;TimeDRL框架通过双层解缠嵌入和特定任务设计，提升了多变量时间序列数据的表示学习效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In deep steganography, the model size is usually related to the underlyingmesh resolution, and a separate neural network needs to be trained as a messageextractor. In this paper, we propose a generative image steganography based onpoint cloud representation, which represents image data as a point cloud,learns the distribution of the point cloud data, and represents it in the formof a continuous function. This method breaks through the limitation of theimage resolution, and can generate images with arbitrary resolution accordingto the actual need, and omits the need for explicit data for imagesteganography. At the same time, using a fixed point cloud extractor transfersthe training of the network to the point cloud data, which saves the trainingtime and avoids the risk of exposing the steganography behavior caused by thetransmission of the message extractor. Experiments prove that thesteganographic images generated by the scheme have very high image quality andthe accuracy of message extraction reaches more than 99%.</description>
      <author>example@mail.com (Zhong Yangjie, Liu Jia, Liu Meiqi, Ke Yan)</author>
      <guid isPermaLink="false">2410.11673v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning of Disentangled Representations for Multivariate Time-Series</title>
      <link>http://arxiv.org/abs/2410.12606v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Workshop: Self-Supervised Learning - Theory and Practice&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列数据在医疗和工业等领域信息丰富，但由于高维度和缺乏标签，处理起来具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出TimeDRL框架，以解决多变量时间序列表示学习中的解缠嵌入和归纳偏差问题。&lt;h4&gt;方法&lt;/h4&gt;TimeDRL采用双层解缠嵌入，使用[CLS]标记策略生成时间戳级和实例级嵌入，并通过时间戳预测和实例对比任务进行表示学习，同时避免使用增强方法以消除归纳偏差。&lt;h4&gt;主要发现&lt;/h4&gt;在预测和分类数据集上的实验表明，TimeDRL优于现有方法，并在半监督设置下验证了其在有限标签数据下的有效性。&lt;h4&gt;结论&lt;/h4&gt;TimeDRL能够有效地学习多变量时间序列的表示，解决了现有方法的限制。&lt;h4&gt;总结&lt;/h4&gt;TimeDRL框架通过双层解缠嵌入和特定任务设计，提升了多变量时间序列数据的表示学习效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time-series data in fields like healthcare and industry areinformative but challenging due to high dimensionality and lack of labels.Recent self-supervised learning methods excel in learning rich representationswithout labels but struggle with disentangled embeddings and inductive biasissues like transformation-invariance. To address these challenges, weintroduce TimeDRL, a framework for multivariate time-series representationlearning with dual-level disentangled embeddings. TimeDRL features: (i)disentangled timestamp-level and instance-level embeddings using a [CLS] tokenstrategy; (ii) timestamp-predictive and instance-contrastive tasks forrepresentation learning; and (iii) avoidance of augmentation methods toeliminate inductive biases. Experiments on forecasting and classificationdatasets show TimeDRL outperforms existing methods, with further validation insemi-supervised settings with limited labeled data.</description>
      <author>example@mail.com (Ching Chang, Chiao-Tung Chan, Wei-Yao Wang, Wen-Chih Peng, Tien-Fu Chen)</author>
      <guid isPermaLink="false">2410.12606v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CMAL: A Novel Cross-Modal Associative Learning Framework for Vision-Language Pre-Training</title>
      <link>http://arxiv.org/abs/2410.12595v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  vision-language pre-training, contrastive learning, cross-modal,
  associative learning, associative mapping classification&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社交媒体平台的兴起使得视觉-语言预训练(VLP)受到了广泛关注，并取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出CMAL框架，以解决当前研究中忽视不同模态之间自然不对称性的问题，并减少对大规模图像-文本语料库的依赖。&lt;h4&gt;方法&lt;/h4&gt;首先将视觉对象和文本标记分别嵌入到超球体空间中学习隐特征，然后设计跨模态联想提示层进行锚点掩蔽和特征填充，最后利用统一语义编码器学习跨模态交互特征，并设计联想映射分类层来学习锚点之间的潜在联想映射。&lt;h4&gt;主要发现&lt;/h4&gt;CMAL在四个常见的视觉与语言任务中，与之前的CMCL方法相比，表现出竞争力，且所需语料显著更少。&lt;h4&gt;结论&lt;/h4&gt;CMAL在SNLI-VE和REC (testA)任务上取得了新的最先进结果，验证了其有效性。&lt;h4&gt;总结&lt;/h4&gt;CMAL通过跨模态联想学习，有效提升了视觉-语言预训练的性能，展现了较少依赖于大规模数据的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the flourishing of social media platforms, vision-language pre-training(VLP) recently has received great attention and many remarkable progresses havebeen achieved. The success of VLP largely benefits from the informationcomplementation and enhancement between different modalities. However, most ofrecent studies focus on cross-modal contrastive learning (CMCL) to promoteimage-text alignment by pulling embeddings of positive sample pairs togetherwhile pushing those of negative pairs apart, which ignores the naturalasymmetry property between different modalities and requires large-scaleimage-text corpus to achieve arduous progress. To mitigate this predicament, wepropose CMAL, a Cross-Modal Associative Learning framework with anchor pointsdetection and cross-modal associative learning for VLP. Specifically, we firstrespectively embed visual objects and textual tokens into separate hyperspherespaces to learn intra-modal hidden features, and then design a cross-modalassociative prompt layer to perform anchor point masking and swap featurefilling for constructing a hybrid cross-modal associative prompt. Afterwards,we exploit a unified semantic encoder to learn their cross-modal interactivefeatures for context adaptation. Finally, we design an associative mappingclassification layer to learn potential associative mappings between modalitiesat anchor points, within which we develop a fresh self-supervised associativemapping classification task to boost CMAL's performance. Experimental resultsverify the effectiveness of CMAL, showing that it achieves competitiveperformance against previous CMCL-based methods on four common downstreamvision-and-language tasks, with significantly fewer corpus. Especially, CMALobtains new state-of-the-art results on SNLI-VE and REC (testA).</description>
      <author>example@mail.com (Zhiyuan Ma, Jianjun Li, Guohui Li, Kaiyan Huang)</author>
      <guid isPermaLink="false">2410.12595v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Tracing Human Stress from Physiological Signals using UWB Radar</title>
      <link>http://arxiv.org/abs/2410.10155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;压力追踪是一个重要的研究领域，支持健康护理和压力管理等多种应用，相关工作主要源于压力检测。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的深度压力追踪方法DST，旨在解决现有压力检测面临的两个主要挑战。&lt;h4&gt;方法&lt;/h4&gt;DST基于非接触式超宽带雷达收集生理信号，设计了信号提取模块和多模态融合模块，以提取和有效利用多模态生理信号。&lt;h4&gt;主要发现&lt;/h4&gt;在三组真实数据集上进行的广泛实验表明，DST在追踪人类压力状态方面显著优于所有基线，平均检测准确率提高了6.31%。&lt;h4&gt;结论&lt;/h4&gt;DST方法在用户体验和检测效果上表现出色，为压力检测提供了新的思路。&lt;h4&gt;总结&lt;/h4&gt;本文强调了压力追踪的连续性，提出的DST方法在生理信号收集和处理上具有创新性，显著提升了压力状态的检测准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stress tracing is an important research domain that supports manyapplications, such as health care and stress management; and its closestrelated works are derived from stress detection. However, these existing workscannot well address two important challenges facing stress detection. First,most of these studies involve asking users to wear physiological sensors todetect their stress states, which has a negative impact on the user experience.Second, these studies have failed to effectively utilize multimodalphysiological signals, which results in less satisfactory detection results.This paper formally defines the stress tracing problem, which emphasizes thecontinuous detection of human stress states. A novel deep stress tracingmethod, named DST, is presented. Note that DST proposes tracing human stressbased on physiological signals collected by a noncontact ultrawideband radar,which is more friendly to users when collecting their physiological signals. InDST, a signal extraction module is carefully designed at first to robustlyextract multimodal physiological signals from the raw RF data of the radar,even in the presence of body movement. Afterward, a multimodal fusion module isproposed in DST to ensure that the extracted multimodal physiological signalscan be effectively fused and utilized. Extensive experiments are conducted onthree real-world datasets, including one self-collected dataset and twopublicity datasets. Experimental results show that the proposed DST methodsignificantly outperforms all the baselines in terms of tracing human stressstates. On average, DST averagely provides a 6.31% increase in detectionaccuracy on all datasets, compared with the best baselines.</description>
      <author>example@mail.com (Jia Xu, Teng Xiao, Pin Lv, Zhe Chen, Chao Cai, Yang Zhang, Zehui Xiong)</author>
      <guid isPermaLink="false">2410.10155v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning from Learning Curves for Budget-Limited Algorithm Selection</title>
      <link>http://arxiv.org/abs/2410.07696v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "训练大量机器学习算法至收敛以选择最佳算法的过程计算资源浪费，尤其在预算有限的情况下。",
    "目的": "在预算限制下，优化算法选择和训练资源分配，以提高性能。",
    "方法": "将问题建模为马尔可夫决策过程，提出一种框架，代理在学习过程中选择最有前途的算法，而不必等到其完全训练。",
    "主要发现":。",
    "主要发现": "通过元学习和学习曲线的进展，增强了算法选择过程，且我们的DDQN基线优于启发式基线和随机搜索。",
    "结论": "我们的成本效益基线在学习曲线不频繁交叉时能表现良好，证明了元学习的有效性。",
    "总结": "本研究通过元学习与学习曲线结合，优化了在预算限制下的算法选择过程。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training a large set of machine learning algorithms to convergence in orderto select the best-performing algorithm for a dataset is computationallywasteful. Moreover, in a budget-limited scenario, it is crucial to carefullyselect an algorithm candidate and allocate a budget for training it, ensuringthat the limited budget is optimally distributed to favor the most promisingcandidates. Casting this problem as a Markov Decision Process, we propose anovel framework in which an agent must select in the process of learning themost promising algorithm without waiting until it is fully trained. At eachtime step, given an observation of partial learning curves of algorithms, theagent must decide whether to allocate resources to further train the mostpromising algorithm (exploitation), to wake up another algorithm previously putto sleep, or to start training a new algorithm (exploration). In addition, ourframework allows the agent to meta-learn from learning curves on past datasetsalong with dataset meta-features and algorithm hyperparameters. Byincorporating meta-learning, we aim to avoid myopic decisions based solely onpremature learning curves on the dataset at hand. We introduce two benchmarksof learning curves that served in international competitions at WCCI'22 andAutoML-conf'22, of which we analyze the results. Our findings show that bothmeta-learning and the progression of learning curves enhance the algorithmselection process, as evidenced by methods of winning teams and our DDQNbaseline, compared to heuristic baselines or a random search. Interestingly,our cost-effective baseline, which selects the best-performing algorithm w.r.t.a small budget, can perform decently when learning curves do not intersectfrequently.</description>
      <author>example@mail.com (Manh Hung Nguyen, Lisheng Sun-Hosoya, Isabelle Guyon)</author>
      <guid isPermaLink="false">2410.07696v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Generalized local polynomial reproductions</title>
      <link>http://arxiv.org/abs/2410.12973v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  32 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "本文提出了一个一般框架，处理黎曼流形中的Lipschitz域，提供了保证存在规范集和广义局部多项式重现的条件。",
    "目的": "旨在分析各种无网格方法，并提供一种无网格方法。",
    "方法": "通过证明在具有Lipschitz边界的$\mathbb{R}^n$代数流形的紧子集上存在光滑的局部多项式重现。",
    "主要发现": "在代数流形上直接操作点云的坐标无关移动最小二乘逼近方法的形状函数在存在性、稳定性、正则性、局部性和逼近性质上获得了新发现。",
    "结论": "研究结果为形状函数的性质提供了新的理解，特别是在无需切平面近似的情况下。",
    "总结": "该框架和结果为无网格方法的分析和应用提供了重要的理论基础。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a general framework, treating Lipschitz domains in Riemannianmanifolds, that provides conditions guaranteeing the existence of norming setsand generalized local polynomial reproduction - a powerful tool used in theanalysis of various mesh-free methods and a mesh-free method in its own right.As a key application, we prove the existence of smooth local polynomialreproductions on compact subsets of algebraic manifolds in $\mathbb{R}^n$ withLipschitz boundary. These results are then applied to derive new findings onthe existence, stability, regularity, locality, and approximation properties ofshape functions for a coordinate-free moving least squares approximation methodon algebraic manifolds, which operates directly on point clouds withoutrequiring tangent plane approximations.</description>
      <author>example@mail.com (Thomas Hangelbroek, Christian Rieger, Grady B. Wright)</author>
      <guid isPermaLink="false">2410.12973v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building</title>
      <link>http://arxiv.org/abs/2410.13756v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能和可靠的任务规划是通用机器人技术的核心能力，需具备足够描述场景中所有对象和状态信息的领域表示。&lt;h4&gt;目的&lt;/h4&gt;提出CLIMB，一个持续学习框架，用于机器人任务规划。&lt;h4&gt;方法&lt;/h4&gt;CLIMB利用基础模型和执行反馈来指导领域模型的构建，能够从自然语言描述中构建模型，并在解决任务的过程中学习非显而易见的谓词，存储该信息以便未来问题使用。&lt;h4&gt;主要发现&lt;/h4&gt;CLIMB在常见规划环境中相比基线方法提高了性能。&lt;h4&gt;结论&lt;/h4&gt;开发了BlocksWorld++领域，这是一个模拟环境，并提供了一个易于使用的实际对应物，以及逐步增加难度的任务课程，用于评估持续学习。&lt;h4&gt;总结&lt;/h4&gt;CLIMB框架展示了在机器人任务规划中的有效性，并且提供了可用于未来研究和应用的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intelligent and reliable task planning is a core capability for generalizedrobotics, requiring a descriptive domain representation that sufficientlymodels all object and state information for the scene. We present CLIMB, acontinual learning framework for robot task planning that leverages foundationmodels and execution feedback to guide domain model construction. CLIMB canbuild a model from a natural language description, learn non-obvious predicateswhile solving tasks, and store that information for future problems. Wedemonstrate the ability of CLIMB to improve performance in common planningenvironments compared to baseline methods. We also develop the BlocksWorld++domain, a simulated environment with an easily usable real counterpart,together with a curriculum of tasks with progressing difficulty for evaluatingcontinual learning. Additional details and demonstrations for this system canbe found at https://plan-with-climb.github.io/ .</description>
      <author>example@mail.com (Walker Byrnes, Miroslav Bogdanovic, Avi Balakirsky, Stephen Balakirsky, Animesh Garg)</author>
      <guid isPermaLink="false">2410.13756v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Explanation-Preserving Augmentation for Semi-Supervised Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2410.12657v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图表示学习（GRL）通过图增强方法在节点分类和图分类等广泛任务中取得了性能提升。&lt;h4&gt;目的&lt;/h4&gt;在自监督GRL中，目标是为同一图的增强生成相似表示，而为不同图的增强生成可区分的表示。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新方法——解释保持增强（EPA），利用图解释技术生成增强图，以实现语义保持与数据扰动的平衡。&lt;h4&gt;主要发现&lt;/h4&gt;EPA通过训练图解释器推断与图语义最相关的子结构（解释），并生成保持语义的增强，以实现自监督GRL，即EPA-GRL。实验证明，EPA-GRL在各种基准数据集上优于现有的最先进GRL方法。&lt;h4&gt;结论&lt;/h4&gt;EPA-GRL在语义保持和数据扰动之间架起了桥梁，推动了图表示学习的发展。&lt;h4&gt;总结&lt;/h4&gt;EPA-GRL方法展示了在自监督图表示学习中，如何有效结合语义保持与数据扰动，取得显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning (GRL), enhanced by graph augmentation methods,has emerged as an effective technique achieving performance improvements inwide tasks such as node classification and graph classification. Inself-supervised GRL, paired graph augmentations are generated from each graph.Its objective is to infer similar representations for augmentations of the samegraph, but maximally distinguishable representations for augmentations ofdifferent graphs. Analogous to image and language domains, the desiderata of anideal augmentation method include both (1) semantics-preservation; and (2)data-perturbation; i.e., an augmented graph should preserve the semantics ofits original graph while carrying sufficient variance. However, most existing(un-)/self-supervised GRL methods focus on data perturbation but largelyneglect semantics preservation. To address this challenge, in this paper, wepropose a novel method, Explanation-Preserving Augmentation (EPA), thatleverages graph explanation techniques for generating augmented graphs that canbridge the gap between semantics-preservation and data-perturbation. EPA firstuses a small number of labels to train a graph explainer to infer thesub-structures (explanations) that are most relevant to a graph's semantics.These explanations are then used to generate semantics-preserving augmentationsfor self-supervised GRL, namely EPA-GRL. We demonstrate theoretically, using ananalytical example, and through extensive experiments on a variety of benchmarkdatasets that EPA-GRL outperforms the state-of-the-art (SOTA) GRL methods,which are built upon semantics-agnostic data augmentations.</description>
      <author>example@mail.com (Zhuomin Chen, Jingchao Ni, Hojat Allah Salehi, Xu Zheng, Esteban Schafir, Farhad Shirani, Dongsheng Luo)</author>
      <guid isPermaLink="false">2410.12657v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>StyleDistance: Stronger Content-Independent Style Embeddings with Synthetic Parallel Examples</title>
      <link>http://arxiv.org/abs/2410.12757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;风格表示的目的是将具有相似写作风格的文本紧密嵌入，而将不同风格的文本远离，但训练中使用的对比三元组可能在风格和内容上都存在差异。&lt;h4&gt;目的&lt;/h4&gt;引入StyleDistance，一种训练更强的与内容无关的风格嵌入的方法。&lt;h4&gt;方法&lt;/h4&gt;利用大型语言模型创建具有控制风格变异的近似释义合成数据集，并在40个不同的风格特征上生成正负样本以进行精准的对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;通过人类和自动评估评估合成数据和嵌入的质量，StyleDistance增强了风格嵌入的内容独立性。&lt;h4&gt;结论&lt;/h4&gt;该模型在实际基准测试中表现良好，在下游应用中超越了领先的风格表示。&lt;h4&gt;总结&lt;/h4&gt;StyleDistance为内容无关的风格嵌入提供了一种新方法，提升了风格表示的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Style representations aim to embed texts with similar writing styles closelyand texts with different styles far apart, regardless of content. However, thecontrastive triplets often used for training these representations may vary inboth style and content, leading to potential content leakage in therepresentations. We introduce StyleDistance, a novel approach to trainingstronger content-independent style embeddings. We use a large language model tocreate a synthetic dataset of near-exact paraphrases with controlled stylevariations, and produce positive and negative examples across 40 distinct stylefeatures for precise contrastive learning. We assess the quality of oursynthetic data and embeddings through human and automatic evaluations.StyleDistance enhances the content-independence of style embeddings, whichgeneralize to real-world benchmarks and outperform leading stylerepresentations in downstream applications. Our model can be found athttps://huggingface.co/StyleDistance/styledistance .</description>
      <author>example@mail.com (Ajay Patel, Jiacheng Zhu, Justin Qiu, Zachary Horvitz, Marianna Apidianaki, Kathleen McKeown, Chris Callison-Burch)</author>
      <guid isPermaLink="false">2410.12757v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ConML: A Universal Meta-Learning Framework with Task-Level Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.05975v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;元学习使学习系统能够快速适应新任务，类似于人类的学习方式。&lt;h4&gt;目的&lt;/h4&gt;提出ConML，一个通用的元学习框架，能够应用于各种元学习算法，而无需依赖特定的模型架构或目标模型。&lt;h4&gt;方法&lt;/h4&gt;ConML的核心是任务级对比学习，扩展了对比学习的应用，从无监督学习的表示空间到元学习的模型空间。通过在元训练过程中利用任务身份作为额外的监督信号，比较元学习者在模型空间的输出，最小化同一任务内的模型距离，并最大化不同任务间的模型距离。&lt;h4&gt;主要发现&lt;/h4&gt;ConML能够与基于优化、基于度量和基于摊销的元学习算法无缝集成，并且在上下文学习中表现出色，提升了在各种少样本学习任务中的性能。&lt;h4&gt;结论&lt;/h4&gt;ConML展示了在多种元学习任务中，快速学习和性能提升的有效性。&lt;h4&gt;总结&lt;/h4&gt;ConML提供了一种新颖的方式，通过任务级对比学习，改进了元学习算法的适用性和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Meta-learning enables learning systems to adapt quickly to new tasks, similarto humans. To emulate this human-like rapid learning and enhance alignment anddiscrimination abilities, we propose ConML, a universal meta-learning frameworkthat can be applied to various meta-learning algorithms without relying onspecific model architectures nor target models. The core of ConML is task-levelcontrastive learning, which extends contrastive learning from therepresentation space in unsupervised learning to the model space inmeta-learning. By leveraging task identity as an additional supervision signalduring meta-training, we contrast the outputs of the meta-learner in the modelspace, minimizing inner-task distance (between models trained on differentsubsets of the same task) and maximizing inter-task distance (between modelsfrom different tasks). We demonstrate that ConML integrates seamlessly withoptimization-based, metric-based, and amortization-based meta-learningalgorithms, as well as in-context learning, resulting in performanceimprovements across diverse few-shot learning tasks.</description>
      <author>example@mail.com (Shiguang Wu, Yaqing Wang, Yatao Bian, Quanming Yao)</author>
      <guid isPermaLink="false">2410.05975v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>MMCFND: Multimodal Multilingual Caption-aware Fake News Detection for Low-resource Indic Languages</title>
      <link>http://arxiv.org/abs/2410.10407v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;虚假信息的广泛传播威胁到可靠信息源的完整性，尤其是在低资源的印度语言中，假新闻检测主要依赖文本分析。&lt;h4&gt;目的&lt;/h4&gt;引入一个专门针对印度假新闻检测的多模态多语言数据集，并提出相应的检测框架。&lt;h4&gt;方法&lt;/h4&gt;创建了包含28,085个实例的MMIFND数据集，涵盖了多种印度语言，并提出了MMCFND框架，利用预训练的单模态编码器和配对编码器，提取新闻文章的视觉和文本深度表示。&lt;h4&gt;主要发现&lt;/h4&gt;MMCFND框架在特征提取方面优于现有方法，能够更有效地识别假新闻。&lt;h4&gt;结论&lt;/h4&gt;该数据集和框架有助于加速低资源环境下的研究与发展，并提供了一种新的假新闻检测方法。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了多模态假新闻检测在低资源语言中的重要性，并展示了新方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread dissemination of false information through manipulativetactics that combine deceptive text and images threatens the integrity ofreliable sources of information. While there has been research on detectingfake news in high resource languages using multimodal approaches, methods forlow resource Indic languages primarily rely on textual analysis. Thisdifference highlights the need for robust methods that specifically addressmultimodal fake news in Indic languages, where the lack of extensive datasetsand tools presents a significant obstacle to progress. To this end, weintroduce the Multimodal Multilingual dataset for Indic Fake News Detection(MMIFND). This meticulously curated dataset consists of 28,085 instancesdistributed across Hindi, Bengali, Marathi, Malayalam, Tamil, Gujarati andPunjabi. We further propose the Multimodal Multilingual Caption-aware frameworkfor Fake News Detection (MMCFND). MMCFND utilizes pre-trained unimodal encodersand pairwise encoders from a foundational model that aligns vision andlanguage, allowing for extracting deep representations from visual and textualcomponents of news articles. The multimodal fusion encoder in the foundationalmodel integrates text and image representations derived from its pairwiseencoders to generate a comprehensive cross modal representation. Furthermore,we generate descriptive image captions that provide additional context todetect inconsistencies and manipulations. The retrieved features are then fusedand fed into a classifier to determine the authenticity of news articles. Thecurated dataset can potentially accelerate research and development in lowresource environments significantly. Thorough experimentation on MMIFNDdemonstrates that our proposed framework outperforms established methods forextracting relevant fake news detection features.</description>
      <author>example@mail.com (Shubhi Bansal, Nishit Sushil Singh, Shahid Shafi Dar, Nagendra Kumar)</author>
      <guid isPermaLink="false">2410.10407v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Addressing Heterogeneity and Heterophily in Graphs: A Heterogeneous Heterophilic Spectral Graph Neural Network</title>
      <link>http://arxiv.org/abs/2410.13373v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在建模图结构方面获得了显著的学术关注，但仍面临异质性和异质亲和性两个主要挑战。&lt;h4&gt;目的&lt;/h4&gt;研究异质异质亲和图的应用，填补现有研究在此领域的空白。&lt;h4&gt;方法&lt;/h4&gt;提出一种异质异质亲和谱图神经网络（H2SGNN），采用双模块方法：局部独立过滤和全局混合过滤。&lt;h4&gt;主要发现&lt;/h4&gt;H2SGNN在四个真实世界数据集上的实证评估显示其优于现有最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;H2SGNN有效应对异质性和异质亲和性问题，展现出良好的性能。&lt;h4&gt;总结&lt;/h4&gt;该研究为异质异质亲和图的建模提供了新方法，推动了图神经网络的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have garnered significant scholarly attentionfor their powerful capabilities in modeling graph structures. Despite this, twoprimary challenges persist: heterogeneity and heterophily. Existing studiesoften address heterogeneous and heterophilic graphs separately, leaving aresearch gap in the understanding of heterogeneous heterophilic graphs-thosethat feature diverse node or relation types with dissimilar connected nodes. Toaddress this gap, we investigate the application of spectral graph filterswithin heterogeneous graphs. Specifically, we propose a HeterogeneousHeterophilic Spectral Graph Neural Network (H2SGNN), which employs adual-module approach: local independent filtering and global hybrid filtering.The local independent filtering module applies polynomial filters to eachsubgraph independently to adapt to different homophily, while the global hybridfiltering module captures interactions across different subgraphs. Extensiveempirical evaluations on four real-world datasets demonstrate the superiorityof H2SGNN compared to state-of-the-art methods.</description>
      <author>example@mail.com (Kangkang Lu, Yanhua Yu, Zhiyong Huang, Jia Li, Yuling Wang, Meiyu Liang, Xiting Qin, Yimeng Ren, Tat-Seng Chua, Xidian Wang)</author>
      <guid isPermaLink="false">2410.13373v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>System-2 Reasoning via Generality and Adaptation</title>
      <link>http://arxiv.org/abs/2410.07866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024 Workshop on System 2 Reasoning At Scale&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前模型在特定任务应用上取得了显著进展，但在深度推理、普遍性和适应性方面存在困难，这些都是实现人工通用智能（AGI）所需的关键组成部分。&lt;h4&gt;目的&lt;/h4&gt;探讨现有方法在实现高级系统2推理方面的局限性，并强调普遍性和适应性对AGI的重要性。&lt;h4&gt;方法&lt;/h4&gt;提出四个关键研究方向：1) 从行动序列中学习人类意图，2) 结合符号模型和神经模型，3) 针对不熟悉环境的元学习，4) 强化学习以实现多步推理。&lt;h4&gt;主要发现&lt;/h4&gt;现有方法往往无法超越训练数据进行泛化，适应新任务的能力受到限制，影响人类类似推理的能力。&lt;h4&gt;结论&lt;/h4&gt;通过所提出的研究方向，旨在提升模型的泛化和适应能力，使计算模型更接近AGI所需的推理能力。&lt;h4&gt;总结&lt;/h4&gt;文章强调了在实现AGI过程中克服当前模型局限性的重要性，并提出了可行的研究路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While significant progress has been made in task-specific applications,current models struggle with deep reasoning, generality, and adaptation -- keycomponents of System-2 reasoning that are crucial for achieving ArtificialGeneral Intelligence (AGI). Despite the promise of approaches such as programsynthesis, language models, and transformers, these methods often fail togeneralize beyond their training data and to adapt to novel tasks, limitingtheir ability to perform human-like reasoning. This paper explores thelimitations of existing approaches in achieving advanced System-2 reasoning andhighlights the importance of generality and adaptation for AGI. Moreover, wepropose four key research directions to address these gaps: (1) learning humanintentions from action sequences, (2) combining symbolic and neural models, (3)meta-learning for unfamiliar environments, and (4) reinforcement learning toreason multi-step. Through these directions, we aim to advance the ability togeneralize and adapt, bringing computational models closer to the reasoningcapabilities required for AGI.</description>
      <author>example@mail.com (Sejin Kim, Sundong Kim)</author>
      <guid isPermaLink="false">2410.07866v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Representing Model Weights with Language using Tree Experts</title>
      <link>http://arxiv.org/abs/2410.13569v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;公共模型的可用性增加，引发了能否训练使用其他网络作为输入的神经网络的思考。&lt;h4&gt;目的&lt;/h4&gt;学习在一个联合空间中表示模型，嵌入模型权重和语言。&lt;h4&gt;方法&lt;/h4&gt;识别真实世界模型的关键特性，提出ProbeX方法作为轻量级探测技术。&lt;h4&gt;主要发现&lt;/h4&gt;大多数公共模型属于一个小的模型树，每个树内的模型之间的干扰变异较少；ProbeX能够有效地将大型模型的权重映射到共享的权重-语言嵌入空间。&lt;h4&gt;结论&lt;/h4&gt;ProbeX在零-shot模型分类和检索中表现出色，展示了其优秀的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;本研究通过有效的模型表示和探测方法，推动了对公共模型的理解和利用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing availability of public models begs the question: can we trainneural networks that use other networks as input? This paper learns torepresent models within a joint space that embeds both model weights andlanguage. However, machine learning on model weights is challenging as modelweights often exhibit significant variation unrelated to the models' semanticproperties (nuisance variation). We identify a key property of real-worldmodels: most public models belong to a small set of Model Trees, where allmodels within a tree are fine-tuned from a common ancestor (e.g., a foundationmodel). Importantly, we find that within each tree there is less nuisancevariation between models. For example, while classifying models according totheir training dataset generally requires complex architectures, in our case,even a linear classifier trained on a single layer is often effective. Whileeffective, linear layers are computationally expensive as model weights arevery high dimensional. To address this, we introduce Probing Experts (ProbeX),a theoretically motivated, lightweight probing method. Notably, ProbeX is thefirst probing method designed to learn from the weights of just a single modellayer. We also construct and release a dataset that simulates the structure ofpublic model repositories. Our results show that ProbeX can effectively map theweights of large models into a shared weight-language embedding space.Furthermore, we demonstrate the impressive generalization of our method,achieving zero-shot model classification and retrieval.</description>
      <author>example@mail.com (Eliahu Horwitz, Bar Cavia, Jonathan Kahana, Yedid Hoshen)</author>
      <guid isPermaLink="false">2410.13569v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>MSc-SQL: Multi-Sample Critiquing Small Language Models For Text-To-SQL Translation</title>
      <link>http://arxiv.org/abs/2410.12916v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3rd Table Representation Learning Workshop at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;文本到SQL生成使非专业人士能够通过自然语言与数据库交互。&lt;h4&gt;目的&lt;/h4&gt;解决大型闭源模型在可访问性、隐私和延迟方面的挑战。&lt;h4&gt;方法&lt;/h4&gt;开发小型、高效且开源的文本到SQL模型，提出MSc-SQL方法，通过关联元数据对多个候选SQL生成进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;我们的样本评估模型能够同时评估多个输出，达到领先的性能。&lt;h4&gt;结论&lt;/h4&gt;该模型在保持竞争力的同时，成本显著低于大型模型。&lt;h4&gt;代码链接&lt;/h4&gt;完整代码可在github.com/layer6ai-labs/msc-sql找到。&lt;h4&gt;总结&lt;/h4&gt;MSc-SQL提供了一种有效的解决方案，促进了文本到SQL生成的普及和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Text-to-SQL generation enables non-experts to interact with databases vianatural language. Recent advances rely on large closed-source models like GPT-4that present challenges in accessibility, privacy, and latency. To addressthese issues, we focus on developing small, efficient, and open-sourcetext-to-SQL models. We demonstrate the benefits of sampling multiple candidateSQL generations and propose our method, MSc-SQL, to critique them usingassociated metadata. Our sample critiquing model evaluates multiple outputssimultaneously, achieving state-of-the-art performance compared to otheropen-source models while remaining competitive with larger models at a muchlower cost. Full code can be found at github.com/layer6ai-labs/msc-sql.</description>
      <author>example@mail.com (Satya Krishna Gorti, Ilan Gofman, Zhaoyan Liu, Jiapeng Wu, Noël Vouitsis, Guangwei Yu, Jesse C. Cresswell, Rasa Hosseinzadeh)</author>
      <guid isPermaLink="false">2410.12916v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>FAMSeC: A Few-shot-sample-based General AI-generated Image Detection Method</title>
      <link>http://arxiv.org/abs/2410.13156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成性人工智能的快速增长导致互联网上充斥着AI生成的图像，这引发了安全隐患，并增加了对可靠检测方法的需求。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在有限样本下进行有效检测的通用AI生成图像检测方法。&lt;h4&gt;方法&lt;/h4&gt;提出FAMSeC，基于LoRA的伪造意识模块和语义特征引导的对比学习策略，以应对有限样本的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;FAMSeC在分类准确度上提升了14.55%，仅使用了0.56%的训练样本，表现优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;通过结合伪造意识模块和语义特征引导的对比学习，FAMSeC能够有效学习有限样本，增强检测的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;FAMSeC为现代检测机制提供了一种新的思路，能够在闭源模型和样本有限的情况下实现高效的生成图像检测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The explosive growth of generative AI has saturated the internet withAI-generated images, raising security concerns and increasing the need forreliable detection methods. The primary requirement for such detection isgeneralizability, typically achieved by training on numerous fake images fromvarious models. However, practical limitations, such as closed-source modelsand restricted access, often result in limited training samples. Therefore,training a general detector with few-shot samples is essential for moderndetection mechanisms. To address this challenge, we propose FAMSeC, a generalAI-generated image detection method based on LoRA-based Forgery AwarenessModule and Semantic feature-guided Contrastive learning strategy. Toeffectively learn from limited samples and prevent overfitting, we developed aForgery Awareness Module (FAM) based on LoRA, maintaining the generalization ofpre-trained features. Additionally, to cooperate with FAM, we designed aSemantic feature-guided Contrastive learning strategy (SeC), making the FAMfocus more on the differences between real/fake image than on the features ofthe samples themselves. Experiments show that FAMSeC outperformsstate-of-the-art method, enhancing classification accuracy by 14.55% with just0.56% of the training samples.</description>
      <author>example@mail.com (Juncong Xu, Yang Yang, Han Fang, Honggu Liu, Weiming Zhang)</author>
      <guid isPermaLink="false">2410.13156v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>TRLO: An Efficient LiDAR Odometry with 3D Dynamic Object Tracking and Removal</title>
      <link>http://arxiv.org/abs/2410.13240v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8pages, 5figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;动态城市环境中，移动机器人需要同时进行状态估计和地图构建，但现有SLAM解决方案通常假设环境为静态。&lt;h4&gt;目的&lt;/h4&gt;提出TRLO，旨在提高状态估计的准确性，并生成更清晰的点云地图。&lt;h4&gt;方法&lt;/h4&gt;采用深度学习方法检测动态物体，设计基于无味卡尔曼滤波器（UKF）和最近邻策略的3D多物体跟踪器，使用快速的两阶段迭代最近点求解器进行状态估计，并提出新颖的哈希关键帧数据库管理方式。&lt;h4&gt;主要发现&lt;/h4&gt;通过对KITTI和UrbanLoco数据集的广泛评估，TRLO在状态估计准确性和地图清晰度上优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;TRLO有效解决了动态环境下的状态估计和地图构建问题，提升了准确性和地图质量。&lt;h4&gt;总结&lt;/h4&gt;TRLO通过深度学习和先进的跟踪与估计方法，改善了移动机器人在动态环境中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous state estimation and mapping is an essential capability formobile robots working in dynamic urban environment. The majority of existingSLAM solutions heavily rely on a primarily static assumption. However, due tothe presence of moving vehicles and pedestrians, this assumption does notalways hold, leading to localization accuracy decreased and maps distorted. Toaddress this challenge, we propose TRLO, a dynamic LiDAR odometry thatefficiently improves the accuracy of state estimation and generates a cleanerpoint cloud map. To efficiently detect dynamic objects in the surroundingenvironment, a deep learning-based method is applied, generating detectionbounding boxes. We then design a 3D multi-object tracker based on UnscentedKalman Filter (UKF) and nearest neighbor (NN) strategy to reliably identify andremove dynamic objects. Subsequently, a fast two-stage iterative nearest pointsolver is employed to solve the state estimation using cleaned static pointcloud. Note that a novel hash-based keyframe database management is proposedfor fast access to search keyframes. Furthermore, all the detected objectbounding boxes are leveraged to impose posture consistency constraint tofurther refine the final state estimation. Extensive evaluations and ablationstudies conducted on the KITTI and UrbanLoco datasets demonstrate that ourapproach not only achieves more accurate state estimation but also generatescleaner maps, compared with baselines.</description>
      <author>example@mail.com (Yanpeng Jia, Ting Wang, Xieyuanli Chen, Shiliang Shao)</author>
      <guid isPermaLink="false">2410.13240v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>A phase transition in sampling from Restricted Boltzmann Machines</title>
      <link>http://arxiv.org/abs/2410.08423v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  43 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "限制玻尔兹曼机是一类无向图模型，在深度学习和无监督学习中发挥着重要作用。",
    "目的": "证明一参数限制玻尔兹曼机的Gibbs采样器混合时间的相变现象。",
    "方法": "分析Gibbs采样器与动态系统之间的联系，以量化前者的行为。",
    "主要发现": "混合时间与顶点数量的关系呈对数、幂次和指数变化，具体取决于参数$c$相对于临界值$c_\star\approx-5.87$的位置。",
    "结论": "在临界情况下$c=c_\star$，我们为采样器的平稳分布发展了新的等周不等式，表明该分布近似对数凹。",
    "总结": "本研究揭示了限制玻尔兹曼机中Gibbs采样器混合时间的相变特性及其与动态系统的关系。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Restricted Boltzmann Machines are a class of undirected graphical models thatplay a key role in deep learning and unsupervised learning. In this study, weprove a phase transition phenomenon in the mixing time of the Gibbs sampler fora one-parameter Restricted Boltzmann Machine. Specifically, the mixing timevaries logarithmically, polynomially, and exponentially with the number ofvertices depending on whether the parameter $c$ is above, equal to, or below acritical value $c_\star\approx-5.87$. A key insight from our analysis is thelink between the Gibbs sampler and a dynamical system, which we utilize toquantify the former based on the behavior of the latter. To study the criticalcase $c= c_\star$, we develop a new isoperimetric inequality for the sampler'sstationary distribution by showing that the distribution is nearly log-concave.</description>
      <author>example@mail.com (Youngwoo Kwon, Qian Qin, Guanyang Wang, Yuchen Wei)</author>
      <guid isPermaLink="false">2410.08423v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Condition-Aware Multimodal Fusion for Robust Semantic Perception of Driving Scenes</title>
      <link>http://arxiv.org/abs/2410.10791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶中，利用多种传感器对于稳健的语义感知至关重要，因为每种传感器类型都有互补的优缺点。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的、条件感知的多模态融合方法，以提高驾驶场景的语义感知能力。&lt;h4&gt;方法&lt;/h4&gt;CAFuser方法使用RGB摄像头输入来分类环境条件，并生成一个条件令牌（ConditionToken），指导多传感器模态的融合。同时，引入模态特定的特征适配器，将不同的传感器输入对齐到共享的潜在空间，从而高效整合。&lt;h4&gt;主要发现&lt;/h4&gt;通过基于实际条件动态调整传感器融合，模型在恶劣条件下显著提高了稳健性和准确性。&lt;h4&gt;结论&lt;/h4&gt;CAFuser在MUSES数据集上设置了新的最先进水平，在多模态全景分割中达到59.7 PQ，在语义分割中达到78.2 mIoU，在公开基准中排名第一。&lt;h4&gt;总结&lt;/h4&gt;CAFuser通过条件感知的融合方法显著提升了自动驾驶的语义感知性能，尤其在复杂环境下表现优异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging multiple sensors is crucial for robust semantic perception inautonomous driving, as each sensor type has complementary strengths andweaknesses. However, existing sensor fusion methods often treat sensorsuniformly across all conditions, leading to suboptimal performance. Bycontrast, we propose a novel, condition-aware multimodal fusion approach forrobust semantic perception of driving scenes. Our method, CAFuser uses an RGBcamera input to classify environmental conditions and generate a ConditionToken that guides the fusion of multiple sensor modalities. We further newlyintroduce modality-specific feature adapters to align diverse sensor inputsinto a shared latent space, enabling efficient integration with a single andshared pre-trained backbone. By dynamically adapting sensor fusion based on theactual condition, our model significantly improves robustness and accuracy,especially in adverse-condition scenarios. We set the new state of the art withCAFuser on the MUSES dataset with 59.7 PQ for multimodal panoptic segmentationand 78.2 mIoU for semantic segmentation, ranking first on the publicbenchmarks.</description>
      <author>example@mail.com (Tim Broedermann, Christos Sakaridis, Yuqian Fu, Luc Van Gool)</author>
      <guid isPermaLink="false">2410.10791v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Multi-frame Detection via Graph Neural Networks: A Link Prediction Approach</title>
      <link>http://arxiv.org/abs/2410.13436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多帧检测算法可以有效利用连续回波之间的相关性，以提高弱目标的检测性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多帧检测方法，通过图神经网络改进目标跟踪的精度和效率。&lt;h4&gt;方法&lt;/h4&gt;将多帧检测问题重新表述为图中的链接预测任务，构建观察关联图，并设计一个多特征链接预测网络，整合回波结构、速率信息和时空耦合特征。&lt;h4&gt;主要发现&lt;/h4&gt;与传统的单帧和多帧检测算法相比，所提算法在检测弱目标的性能上有所提高，并有效抑制了误报。&lt;h4&gt;结论&lt;/h4&gt;所设计的网络能够有效整合所用特征，实现目标与误报之间的准确关联。&lt;h4&gt;总结&lt;/h4&gt;通过将多帧检测流程简化为一步，通过链接预测的方式，减少了性能损失，并直接输出目标轨迹。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-frame detection algorithms can effectively utilize the correlationbetween consecutive echoes to improve the detection performance of weaktargets. Existing efficient multi-frame detection algorithms are typicallybased on three sequential steps: plot extraction via a relative low primarythreshold, track search and track detection. However, these three-stageprocessing algorithms may result in a notable loss of detection performance anddo not fully leverage the available echo information across frames. As toapplying graph neural networks in multi-frame detection, the algorithms areprimarily based on node classification tasks, which cannot directly outputtarget tracks. In this paper, we reformulate the multi-frame detection problemas a link prediction task in graphs. First, we perform a rough association ofmulti-frame observations that exceed the low threshold to construct observationassociation graphs. Subsequently, a multi-feature link prediction network isdesigned based on graph neural networks, which integrates multi-dimensionalinformation, including echo structure, Doppler information, and spatio-temporalcoupling of plots. By leveraging the principle of link prediction, we unifiesthe processes of track search and track detection into one step to reduceperformance loss and directly output target tracks. Experimental results showthat, compared with traditional single-frame and multi-frame detectionalgorithms, the proposed algorithm improves the detection performance of weaktargets while suppressing false alarms. Additionally, interpretable analysisindicates that the designed network effectively integrates the utilizedfeatures, allowing for accurate associations between targets and false alarms.</description>
      <author>example@mail.com (Zhihao Lin, Chang Gao, Junkun Yan, Qingfu Zhang, Hongwei Liu)</author>
      <guid isPermaLink="false">2410.13436v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Deep Tabular Learning</title>
      <link>http://arxiv.org/abs/2410.12034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  43 pages, 18 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;表格数据在医疗、金融和交通等行业广泛使用，但由于其异构特性和缺乏空间结构，给深度学习带来了独特挑战。&lt;h4&gt;目的&lt;/h4&gt;回顾深度学习模型在表格数据处理中的演变，从早期的全连接网络到先进的架构。&lt;h4&gt;方法&lt;/h4&gt;综述了多种模型，包括TabNet、SAINT、TabTranSELU和MambaNet，探讨了注意力机制、特征嵌入和混合架构的应用。&lt;h4&gt;主要发现&lt;/h4&gt;TabNet通过实例级特征选择提高可解释性，而SAINT结合自注意力和样本间注意力捕捉特征和数据点之间的复杂交互。&lt;h4&gt;结论&lt;/h4&gt;混合架构如TabTransformer和FT-Transformer有效处理分类和数值数据，图基模型如GNN4TDL和GANDALF增强特征表示并减少小数据集的过拟合。&lt;h4&gt;未来方向&lt;/h4&gt;研究将继续平衡大数据集的性能和效率，关注可扩展性、泛化能力和可解释性。&lt;h4&gt;总结&lt;/h4&gt;本综述强调了表格数据深度学习模型的关键进展，并指出未来研究的潜在方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular data, widely used in industries like healthcare, finance, andtransportation, presents unique challenges for deep learning due to itsheterogeneous nature and lack of spatial structure. This survey reviews theevolution of deep learning models for tabular data, from early fully connectednetworks (FCNs) to advanced architectures like TabNet, SAINT, TabTranSELU, andMambaNet. These models incorporate attention mechanisms, feature embeddings,and hybrid architectures to address tabular data complexities. TabNet usessequential attention for instance-wise feature selection, improvinginterpretability, while SAINT combines self-attention and intersample attentionto capture complex interactions across features and data points, both advancingscalability and reducing computational overhead. Hybrid architectures such asTabTransformer and FT-Transformer integrate attention mechanisms withmulti-layer perceptrons (MLPs) to handle categorical and numerical data, withFT-Transformer adapting transformers for tabular datasets. Research continuesto balance performance and efficiency for large datasets. Graph-based modelslike GNN4TDL and GANDALF combine neural networks with decision trees or graphstructures, enhancing feature representation and mitigating overfitting insmall datasets through advanced regularization techniques. Diffusion-basedmodels like the Tabular Denoising Diffusion Probabilistic Model (TabDDPM)generate synthetic data to address data scarcity, improving model robustness.Similarly, models like TabPFN and Ptab leverage pre-trained language models,incorporating transfer learning and self-supervised techniques into tabulartasks. This survey highlights key advancements and outlines future researchdirections on scalability, generalization, and interpretability in diversetabular data applications.</description>
      <author>example@mail.com (Shriyank Somvanshi, Subasish Das, Syed Aaqib Javed, Gian Antariksa, Ahmed Hossain)</author>
      <guid isPermaLink="false">2410.12034v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning Integration in Hierarchical Reinforcement Learning for Advanced Task Complexity</title>
      <link>http://arxiv.org/abs/2410.07921v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;分层强化学习（HRL）通过将复杂任务分解为结构化策略，有效地处理复杂任务，但面临高效探索和快速适应的挑战。&lt;h4&gt;目的&lt;/h4&gt;将元学习整合到HRL中，以增强智能体快速学习和适应分层策略的能力。&lt;h4&gt;方法&lt;/h4&gt;采用元学习进行快速任务适应，同时通过内在动机机制激励高效探索，奖励新状态的访问。智能体使用高层策略在自定义网格环境中选择多个低层策略，利用基于梯度的元学习和可微分的内循环更新，在越来越困难的任务课程中进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，元学习分层智能体显著优于传统的无元学习和内在动机的HRL智能体，表现出加速学习、更高的累积奖励和在复杂网格环境中的成功率提高。&lt;h4&gt;结论&lt;/h4&gt;将元学习与HRL结合，以及课程学习和内在动机的整合，显著增强了智能体处理复杂任务的能力。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的整合方法有效提升了智能体在复杂任务中的表现，展示了元学习在HRL中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Arashkhajooei/Meta-Learning-Integration-in-Hierarchical-Reinforcement-Learning-for-Advanced-Task-Complexity&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hierarchical Reinforcement Learning (HRL) effectively tackles complex tasksby decomposing them into structured policies. However, HRL agents often facechallenges with efficient exploration and rapid adaptation. To address this, weintegrate meta-learning into HRL to enhance the agent's ability to learn andadapt hierarchical policies swiftly. Our approach employs meta-learning forrapid task adaptation based on prior experience, while intrinsic motivationmechanisms encourage efficient exploration by rewarding novel state visits.Specifically, our agent uses a high-level policy to select among multiplelow-level policies operating within custom grid environments. We utilizegradient-based meta-learning with differentiable inner-loop updates, enablingoptimization across a curriculum of increasingly difficult tasks. Experimentalresults demonstrate that our meta-learned hierarchical agent significantlyoutperforms traditional HRL agents without meta-learning and intrinsicmotivation. The agent exhibits accelerated learning, higher cumulative rewards,and improved success rates in complex grid environments. These findings suggestthat integrating meta-learning with HRL, alongside curriculum learning andintrinsic motivation, substantially enhances the agent's capability to handlecomplex tasks.</description>
      <author>example@mail.com (Arash Khajooeinejad, Masoumeh Chapariniya)</author>
      <guid isPermaLink="false">2410.07921v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation</title>
      <link>http://arxiv.org/abs/2410.13178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review as a conference paper at ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从知识数据库中检索基因功能网络面临挑战，主要由于疾病网络与亚型特异性变化之间的不匹配。&lt;h4&gt;目的&lt;/h4&gt;提出GeSubNet，学习统一表示以预测基因交互，同时区分不同疾病亚型。&lt;h4&gt;方法&lt;/h4&gt;GeSubNet是一个多步骤表示学习框架，包括三个模块：1) 深度生成模型从患者基因表达谱中学习独特疾病亚型；2) 图神经网络捕捉来自知识数据库的先前基因网络表示；3) 通过推理损失整合这两种表示，提升亚型特异性信息。&lt;h4&gt;主要发现&lt;/h4&gt;GeSubNet在四个图评估指标上的平均改进分别为30.6%、21.0%、20.1%和56.6%，并在四个癌症数据集上表现优越。&lt;h4&gt;结论&lt;/h4&gt;通过生物模拟实验，生成的网络能够识别亚型特异性基因，具有83%的可能性影响患者分布变化。&lt;h4&gt;资源&lt;/h4&gt;GeSubNet资源可在：https://anonymous.4open.science/r/GeSubNet/ 获取。&lt;h4&gt;总结&lt;/h4&gt;GeSubNet有效整合基因交互知识，提升了对亚型特异性网络的理解与预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Retrieving gene functional networks from knowledge databases presents achallenge due to the mismatch between disease networks and subtype-specificvariations. Current solutions, including statistical and deep learning methods,often fail to effectively integrate gene interaction knowledge from databasesor explicitly learn subtype-specific interactions. To address this mismatch, wepropose GeSubNet, which learns a unified representation capable of predictinggene interactions while distinguishing between different disease subtypes.Graphs generated by such representations can be considered subtype-specificnetworks. GeSubNet is a multi-step representation learning framework with threemodules: First, a deep generative model learns distinct disease subtypes frompatient gene expression profiles. Second, a graph neural network capturesrepresentations of prior gene networks from knowledge databases, ensuringaccurate physical gene interactions. Finally, we integrate these tworepresentations using an inference loss that leverages graph generationcapabilities, conditioned on the patient separation loss, to refinesubtype-specific information in the learned representation. GeSubNetconsistently outperforms traditional methods, with average improvements of30.6%, 21.0%, 20.1%, and 56.6% across four graph evaluation metrics, averagedover four cancer datasets. Particularly, we conduct a biological simulationexperiment to assess how the behavior of selected genes from over 11,000candidates affects subtypes or patient distributions. The results show that thegenerated network has the potential to identify subtype-specific genes with an83% likelihood of impacting patient distribution shifts. The GeSubNet resourceis available: https://anonymous.4open.science/r/GeSubNet/</description>
      <author>example@mail.com (Ziwei Yang, Zheng Chen, Xin Liu, Rikuto Kotoge, Peng Chen, Yasuko Matsubara, Yasushi Sakurai, Jimeng Sun)</author>
      <guid isPermaLink="false">2410.13178v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>DPLM-2: A Multimodal Diffusion Protein Language Model</title>
      <link>http://arxiv.org/abs/2410.13782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;蛋白质是由氨基酸序列定义的重要大分子，其序列决定了三维结构和功能。&lt;h4&gt;目的&lt;/h4&gt;提出一种多模态蛋白质基础模型，DPLM-2，以同时建模、理解和生成序列与结构。&lt;h4&gt;方法&lt;/h4&gt;DPLM-2扩展了离散扩散蛋白语言模型，通过查找无量化的分词器将3D坐标转换为离散标记，并在实验数据和高质量合成结构上进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;DPLM-2能够同时生成高度兼容的氨基酸序列及其对应的3D结构，避免了两阶段生成的方法。&lt;h4&gt;结论&lt;/h4&gt;DPLM-2在多种条件生成任务中表现出竞争力，包括折叠、逆折叠和支架生成，并为预测任务提供结构感知的表示。&lt;h4&gt;总结&lt;/h4&gt;DPLM-2通过联合建模序列和结构，提升了蛋白质生成的效率和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Proteins are essential macromolecules defined by their amino acid sequences,which determine their three-dimensional structures and, consequently, theirfunctions in all living organisms. Therefore, generative protein modelingnecessitates a multimodal approach to simultaneously model, understand, andgenerate both sequences and structures. However, existing methods typically useseparate models for each modality, limiting their ability to capture theintricate relationships between sequence and structure. This results insuboptimal performance in tasks that requires joint understanding andgeneration of both modalities. In this paper, we introduce DPLM-2, a multimodalprotein foundation model that extends discrete diffusion protein language model(DPLM) to accommodate both sequences and structures. To enable structurallearning with the language model, 3D coordinates are converted to discretetokens using a lookup-free quantization-based tokenizer. By training on bothexperimental and high-quality synthetic structures, DPLM-2 learns the jointdistribution of sequence and structure, as well as their marginals andconditionals. We also implement an efficient warm-up strategy to exploit theconnection between large-scale evolutionary data and structural inductivebiases from pre-trained sequence-based protein language models. Empiricalevaluation shows that DPLM-2 can simultaneously generate highly compatibleamino acid sequences and their corresponding 3D structures eliminating the needfor a two-stage generation approach. Moreover, DPLM-2 demonstrates competitiveperformance in various conditional generation tasks, including folding, inversefolding, and scaffolding with multimodal motif inputs, as well as providingstructure-aware representations for predictive tasks.</description>
      <author>example@mail.com (Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, Quanquan Gu)</author>
      <guid isPermaLink="false">2410.13782v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Progressive Multi-Modal Fusion for Robust 3D Object Detection</title>
      <link>http://arxiv.org/abs/2410.07475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多传感器融合对于自动驾驶中准确的3D物体检测至关重要，常用的传感器包括摄像头和激光雷达（LiDAR）。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在单一视图中进行传感器融合时，造成的高度和几何比例等互补信息的损失。&lt;h4&gt;方法&lt;/h4&gt;提出ProFusion3D，一个逐步融合框架，在中间和物体查询层次同时结合BEV和PV中的特征。架构分层融合局部和全局特征，增强3D物体检测的鲁棒性。同时引入自监督掩膜建模预训练策略，通过三个新目标提高多模态表示学习和数据效率。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes和Argoverse2数据集上的广泛实验显示ProFusion3D的有效性。&lt;h4&gt;结论&lt;/h4&gt;ProFusion3D对传感器故障具有鲁棒性，在仅有一种模态可用时仍表现出色。&lt;h4&gt;总结&lt;/h4&gt;ProFusion3D通过改进的特征融合和预训练策略，显著提升了3D物体检测的性能与效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-sensor fusion is crucial for accurate 3D object detection in autonomousdriving, with cameras and LiDAR being the most commonly used sensors. However,existing methods perform sensor fusion in a single view by projecting featuresfrom both modalities either in Bird's Eye View (BEV) or Perspective View (PV),thus sacrificing complementary information such as height or geometricproportions. To address this limitation, we propose ProFusion3D, a progressivefusion framework that combines features in both BEV and PV at both intermediateand object query levels. Our architecture hierarchically fuses local and globalfeatures, enhancing the robustness of 3D object detection. Additionally, weintroduce a self-supervised mask modeling pre-training strategy to improvemulti-modal representation learning and data efficiency through three novelobjectives. Extensive experiments on nuScenes and Argoverse2 datasetsconclusively demonstrate the efficacy of ProFusion3D. Moreover, ProFusion3D isrobust to sensor failure, demonstrating strong performance when only onemodality is available.</description>
      <author>example@mail.com (Rohit Mohan, Daniele Cattaneo, Florian Drews, Abhinav Valada)</author>
      <guid isPermaLink="false">2410.07475v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Data-Driven Discovery of the Origins of UV Absorption in Alpha-3C Protein</title>
      <link>http://arxiv.org/abs/2410.08624v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在过去十年中，越来越多的实验工作表明，缺乏芳香族和共轭基团的蛋白质能够在近紫外区（超过300 nm）吸收光并发出可见光。&lt;h4&gt;目的&lt;/h4&gt;理解这一现象的起源，以设计非侵入性的光谱探针，用于生物系统中的局部相互作用研究。&lt;h4&gt;方法&lt;/h4&gt;使用数据驱动的方法，结合分子动力学和激发态模拟，采用无监督学习方法对蛋白质环境进行编码，自动检测相关的结构特征。&lt;h4&gt;主要发现&lt;/h4&gt;识别出三种主要结构特征，分别对应不同的氢键模式，并利用量子力学/分子力学（QM/MM）模拟，研究整个蛋白质和溶剂的相互作用。&lt;h4&gt;结论&lt;/h4&gt;涉及精氨酸和羧酸根的氢键结构最容易发生近紫外吸收，并且这些特征对QM区域的大小及显式溶剂的包含高度敏感，强调了使用气相团簇模型的局限性。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了蛋白质在近紫外区的光吸收机制，为未来的生物探针设计提供了重要的理论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Over the last decade, there has been a growing body of experimental workshowing that proteins devoid of aromatic and conjugated groups can absorb lightin the near-UV beyond 300 nm and emit visible light. Understanding the originsof this phenomena offers the possibility of designing non-invasivespectroscopic probes for local interactions in biological systems. It wasrecently found that the synthetic protein {\alpha}3C displays UV-vis absorptionbetween 250-800 nm which was shown to arise from charge-transfer excitationsbetween charged amino acids. In this work, we use data-driven discovery torevisit the origins of these features using molecular dynamics andexcited-state simulations. Specifically, an unsupervised learning approachbeginning with encoding protein environments with local atomic descriptors, isemployed to automatically detect relevant structural motifs. We identify threemain motifs corresponding to different hydrogen-bonding patterns that aresubsequently used to perform QM/MM simulations including the entire protein andsolvent bath with the density-functional tight-binding (DFTB) approach.Hydrogen-bonding structures involving arginine and carboxylate groups appear tobe the most prone to near-UV absorption. We show that these features are highlysensitive to the size of the QM region employed as well as to the inclusion ofexplicit solvation underscoring the limitations of using gas-phase clustermodels.</description>
      <author>example@mail.com (Germaine Neza Hozana, Gonzalo Díaz Mirón, Ali Hassanali)</author>
      <guid isPermaLink="false">2410.08624v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Learning to rumble: Automated elephant call classification, detection and endpointing using deep architectures</title>
      <link>http://arxiv.org/abs/2410.12082v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动识别和分类大象叫声可以帮助保护工作和环境管理策略。&lt;h4&gt;目的&lt;/h4&gt;检测、隔离和分类持续录音中的大象叫声。&lt;h4&gt;方法&lt;/h4&gt;在帧级别进行叫声检测，使用两个注释数据集（亚洲和非洲大象的声音），评估多种浅层和深层分类模型，采用音频谱图变换器（AST）并进行迁移学习。&lt;h4&gt;主要发现&lt;/h4&gt;使用AST和迁移学习显著提高了计算复杂性和性能，最佳分类器在帧级二分类上平均精度为0.962，5类和7类分类的ROC曲线下面积分别为0.957和0.979。&lt;h4&gt;结论&lt;/h4&gt;完全自动化的大象叫声检测和子叫声分类系统即将实现，为保护和管理提供重要信息。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，利用新型神经网络架构和迁移学习可以有效提高大象叫声的自动识别和分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider the problem of detecting, isolating and classifying elephantcalls in continuously recorded audio. Such automatic call characterisation canassist conservation efforts and inform environmental management strategies. Incontrast to previous work in which call detection was performed at a segmentlevel, we perform call detection at a frame level which implicitly also allowscall endpointing, the isolation of a call in a longer recording. Forexperimentation, we employ two annotated datasets, one containing Asian and theother African elephant vocalisations. We evaluate several shallow and deepclassifier models, and show that the current best performance can be improvedby using an audio spectrogram transformer (AST), a neural architecture whichhas not been used for this purpose before, and which we have configured in anovel sequence-to-sequence manner. We also show that using transfer learning bypre-training leads to further improvements both in terms of computationalcomplexity and performance. Finally, we consider sub-call classification usingan accepted taxonomy of call types, a task which has not previously beenconsidered. We show that also in this case the transformer architecturesprovide the best performance. Our best classifiers achieve an average precision(AP) of 0.962 for framewise binary call classification, and an area under thereceiver operating characteristic (AUC) of 0.957 and 0.979 for callclassification with 5 classes and sub-call classification with 7 classesrespectively. All of these represent either new benchmarks (sub-callclassifications) or improvements on previously best systems. We conclude that afully-automated elephant call detection and subcall classification system iswithin reach. Such a system would provide valuable information on the behaviourand state of elephant herds for the purposes of conservation and management.</description>
      <author>example@mail.com (Christiaan M. Geldenhuys, Thomas R. Niesler)</author>
      <guid isPermaLink="false">2410.12082v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning-Driven Adaptive Codebook Design for Near-Field Communications</title>
      <link>http://arxiv.org/abs/2410.08318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态遥感数据通过多种传感器收集，提供地球表面的全面和综合视角。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的多模态适配器网络（MANet），用于多模态遥感语义分割。&lt;h4&gt;方法&lt;/h4&gt;基于最近的视觉基础模型进展，特别是Segment Anything Model (SAM)，引入多模态适配器（MMAdapter）来微调SAM的图像编码器，并结合金字塔深度融合模块（DFM）以整合不同尺度的高层地理特征。&lt;h4&gt;主要发现&lt;/h4&gt;在两个高分辨率的多模态遥感数据集ISPRS Vaihingen和ISPRS Potsdam上的实验结果表明，提出的MANet显著超越了现有模型在多模态语义分割任务中的表现。&lt;h4&gt;结论&lt;/h4&gt;该研究不仅引入了一种新的多模态融合网络，也首次展示了SAM在数字表面模型（DSM）数据上的强大泛化能力。&lt;h4&gt;总结&lt;/h4&gt;该工作将源码发布于GitHub，以供进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extremely large-scale arrays (XL-arrays) and ultra-high frequencies are twokey technologies for sixth-generation (6G) networks, offering higher systemcapacity and expanded bandwidth resources. To effectively combine thesetechnologies, it is necessary to consider the near-field spherical-wavepropagation model, rather than the traditional far-field planar-wave model. Inthis paper, we explore a near-field communication system comprising a basestation (BS) with hybrid analog-digital beamforming and multiple mobile users.Our goal is to maximize the system's sum-rate by optimizing the near-fieldcodebook design for hybrid precoding. To enable fast adaptation to varying userdistributions, we propose a meta-learning-based framework that integrates themodel-agnostic meta-learning (MAML) algorithm with a codebook learning network.Specifically, we first design a deep neural network (DNN) to learn thenear-field codebook. Then, we combine the MAML algorithm with the DNN to allowrapid adaptation to different channel conditions by leveraging awell-initialized model from the outer network. Simulation results demonstratethat our proposed framework outperforms conventional algorithms, offeringimproved generalization and better overall performance.</description>
      <author>example@mail.com (Mianyi Zhang, Yunlong Cai, Jiaqi Xu, A. Lee Swindlehurst)</author>
      <guid isPermaLink="false">2410.08318v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>MANet: Fine-Tuning Segment Anything Model for Multimodal Remote Sensing Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.11160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态遥感数据通过多种传感器收集，提供地球表面的全面和综合视角。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的多模态适配器网络（MANet），用于多模态遥感语义分割。&lt;h4&gt;方法&lt;/h4&gt;基于最近的视觉基础模型进展，特别是Segment Anything Model (SAM)，引入多模态适配器（MMAdapter）来微调SAM的图像编码器，并结合金字塔深度融合模块（DFM）以整合不同尺度的高层地理特征。&lt;h4&gt;主要发现&lt;/h4&gt;在两个高分辨率的多模态遥感数据集ISPRS Vaihingen和ISPRS Potsdam上的实验结果表明，提出的MANet显著超越了现有模型在多模态语义分割任务中的表现。&lt;h4&gt;结论&lt;/h4&gt;该研究不仅引入了一种新的多模态融合网络，也首次展示了SAM在数字表面模型（DSM）数据上的强大泛化能力。&lt;h4&gt;总结&lt;/h4&gt;该工作将源码发布于GitHub，以供进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sstary/ssrs&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal remote sensing data, collected from a variety of sensors, providea comprehensive and integrated perspective of the Earth's surface. By employingmultimodal fusion techniques, semantic segmentation offers more detailedinsights into geographic scenes compared to single-modality approaches.Building upon recent advancements in vision foundation models, particularly theSegment Anything Model (SAM), this study introduces a novel MultimodalAdapter-based Network (MANet) for multimodal remote sensing semanticsegmentation. At the core of this approach is the development of a MultimodalAdapter (MMAdapter), which fine-tunes SAM's image encoder to effectivelyleverage the model's general knowledge for multimodal data. In addition, apyramid-based Deep Fusion Module (DFM) is incorporated to further integratehigh-level geographic features across multiple scales before decoding. Thiswork not only introduces a novel network for multimodal fusion, but alsodemonstrates, for the first time, SAM's powerful generalization capabilitieswith Digital Surface Model (DSM) data. Experimental results on twowell-established fine-resolution multimodal remote sensing datasets, ISPRSVaihingen and ISPRS Potsdam, confirm that the proposed MANet significantlysurpasses current models in the task of multimodal semantic segmentation. Thesource code for this work will be accessible at https://github.com/sstary/SSRS.</description>
      <author>example@mail.com (Xianping Ma, Xiaokang Zhang, Man-On Pun, Bo Huang)</author>
      <guid isPermaLink="false">2410.11160v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Interpreting Temporal Graph Neural Networks with Koopman Theory</title>
      <link>http://arxiv.org/abs/2410.13469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时空图神经网络（STGNNs）在许多领域（如预测和流行病学）中显示出良好的效果，但理解这些模型学习的动态和解释其行为比静态数据模型复杂得多。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Koopman理论的可解释性方法，用于分析时序图的决策过程。&lt;h4&gt;方法&lt;/h4&gt;介绍了两种方法来解释STGNN的决策过程：第一种基于动态模式分解（DMD），第二种基于稀疏非线性动态识别（SINDy）。&lt;h4&gt;主要发现&lt;/h4&gt;方法能够正确识别可解释的特征，如传播过程中的感染时间和感染节点。&lt;h4&gt;结论&lt;/h4&gt;所提出的可解释性方法为理解STGNN的决策过程提供了新的视角，能够有效识别输入中的重要时空模式。&lt;h4&gt;总结&lt;/h4&gt;本研究为时空图神经网络的可解释性提供了新的方法，增强了对复杂动态系统的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatiotemporal graph neural networks (STGNNs) have shown promising results inmany domains, from forecasting to epidemiology. However, understanding thedynamics learned by these models and explaining their behaviour issignificantly more complex than for models dealing with static data. Inspiredby Koopman theory, which allows a simpler description of intricate, nonlineardynamical systems, we introduce an explainability approach for temporal graphs.We present two methods to interpret the STGNN's decision process and identifythe most relevant spatial and temporal patterns in the input for the task athand. The first relies on dynamic mode decomposition (DMD), a Koopman-inspireddimensionality reduction method. The second relies on sparse identification ofnonlinear dynamics (SINDy), a popular method for discovering governingequations, which we use for the first time as a general tool forexplainability. We show how our methods can correctly identify interpretablefeatures such as infection times and infected nodes in the context ofdissemination processes.</description>
      <author>example@mail.com (Michele Guerra, Simone Scardapane, Filippo Maria Bianchi)</author>
      <guid isPermaLink="false">2410.13469v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning</title>
      <link>http://arxiv.org/abs/2410.13179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的语音表示学习方法通常使用随机掩蔽方案进行掩蔽声学建模(MAM)。&lt;h4&gt;目的&lt;/h4&gt;提出EH-MAM（Easy-to-Hard自适应掩蔽声学建模），一种新的自监督学习方法，以改善语音表示学习。&lt;h4&gt;方法&lt;/h4&gt;引入选择性和自适应的掩蔽策略，在自监督学习训练过程中逐渐引入更难的区域进行重构。使用教师模型预测帧损失并决定掩蔽的帧。&lt;h4&gt;主要发现&lt;/h4&gt;EH-MAM在各种低资源语音识别和SUPERB基准测试中，比多项最先进的基线提高了5%-10%。&lt;h4&gt;结论&lt;/h4&gt;EH-MAM有效捕捉语音帧之间有用的上下文，从而提高了模型的表现和对语音的理解。&lt;h4&gt;总结&lt;/h4&gt;EH-MAM通过自适应选择难度区域，促进了更有效的语音表示学习，展示了其在语音处理任务中的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cs20s030/ehmam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present EH-MAM (Easy-to-Hard adaptive Masked AcousticModeling), a novel self-supervised learning approach for speech representationlearning. In contrast to the prior methods that use random masking schemes forMasked Acoustic Modeling (MAM), we introduce a novel selective and adaptivemasking strategy. Specifically, during SSL training, we progressively introduceharder regions to the model for reconstruction. Our approach automaticallyselects hard regions and is built on the observation that the reconstructionloss of individual frames in MAM can provide natural signals to judge thedifficulty of solving the MAM pre-text task for that frame. To identify thesehard regions, we employ a teacher model that first predicts the frame-wiselosses and then decides which frames to mask. By learning to create challengingproblems, such as identifying harder frames and solving them simultaneously,the model is able to learn more effective representations and thereby acquire amore comprehensive understanding of the speech. Quantitatively, EH-MAMoutperforms several state-of-the-art baselines across various low-resourcespeech recognition and SUPERB benchmarks by 5%-10%. Additionally, we conduct athorough analysis to show that the regions masked by EH-MAM effectively captureuseful context across speech frames.</description>
      <author>example@mail.com (Ashish Seth, Ramaneswaran Selvakumar, S Sakshi, Sonal Kumar, Sreyan Ghosh, Dinesh Manocha)</author>
      <guid isPermaLink="false">2410.13179v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>MotionBank: A Large-scale Video Motion Benchmark with Disentangled Rule-based Annotations</title>
      <link>http://arxiv.org/abs/2410.13790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的大规模运动模型（LMM）在小规模运动数据和昂贵文本描述方面受限，且现有基准主要关注纯身体动作，忽略了人类与人、物体和场景的互动。&lt;h4&gt;目的&lt;/h4&gt;构建和基准化一个大型运动模型，服务于多种运动相关任务，如人类运动生成，强调可解释性和普适性。&lt;h4&gt;方法&lt;/h4&gt;整合大规模视频动作数据集，构建MotionBank，包括13个视频动作数据集、124万条运动序列和1.329亿帧自然多样的人类动作；同时开发运动字幕生成算法，自动生成基于运动特征的文本描述。&lt;h4&gt;主要发现&lt;/h4&gt;MotionBank对人类运动生成、上下文中的运动生成和运动理解等一般运动相关任务有显著帮助。&lt;h4&gt;结论&lt;/h4&gt;视频动作和基于规则的文本注释为更大规模的运动模型提供了有效的替代方案，数据集、代码和基准将公开发布。&lt;h4&gt;总结&lt;/h4&gt;本研究通过构建MotionBank解决了现有LMM在数据和基准方面的不足，为运动相关任务提供了新的资源和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we tackle the problem of how to build and benchmark a largemotion model (LMM). The ultimate goal of LMM is to serve as a foundation modelfor versatile motion-related tasks, e.g., human motion generation, withinterpretability and generalizability. Though advanced, recent LMM-relatedworks are still limited by small-scale motion data and costly textdescriptions. Besides, previous motion benchmarks primarily focus on pure bodymovements, neglecting the ubiquitous motions in context, i.e., humansinteracting with humans, objects, and scenes. To address these limitations, weconsolidate large-scale video action datasets as knowledge banks to buildMotionBank, which comprises 13 video action datasets, 1.24M motion sequences,and 132.9M frames of natural and diverse human motions. Different fromlaboratory-captured motions, in-the-wild human-centric videos contain abundantmotions in context. To facilitate better motion text alignment, we alsometiculously devise a motion caption generation algorithm to automaticallyproduce rule-based, unbiased, and disentangled text descriptions via thekinematic characteristics for each motion. Extensive experiments show that ourMotionBank is beneficial for general motion-related tasks of human motiongeneration, motion in-context generation, and motion understanding. Videomotions together with the rule-based text annotations could serve as anefficient alternative for larger LMMs. Our dataset, codes, and benchmark willbe publicly available at https://github.com/liangxuy/MotionBank.</description>
      <author>example@mail.com (Liang Xu, Shaoyang Hua, Zili Lin, Yifan Liu, Feipeng Ma, Yichao Yan, Xin Jin, Xiaokang Yang, Wenjun Zeng)</author>
      <guid isPermaLink="false">2410.13790v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>HeightFormer: A Semantic Alignment Monocular 3D Object Detection Method from Roadside Perspective</title>
      <link>http://arxiv.org/abs/2410.07758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;车载3D物体检测技术在自动驾驶中受到广泛关注，但针对路边传感器在3D交通物体检测中的应用研究较少。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的3D物体检测框架，提升基于高度估计的2D到3D投影效果。&lt;h4&gt;方法&lt;/h4&gt;集成了Spatial Former和Voxel Pooling Former，以增强高度估计的2D到3D投影。&lt;h4&gt;主要发现&lt;/h4&gt;在Rope3D和DAIR-V2X-I数据集上进行的广泛实验表明，所提算法在检测车辆和骑行者方面表现优越。&lt;h4&gt;结论&lt;/h4&gt;提高路边3D物体检测的准确性有助于构建安全可靠的智能交通系统，推动自动驾驶的广泛应用。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种有效的3D物体检测方法，并计划在指定网站发布代码和预训练模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The on-board 3D object detection technology has received extensive attentionas a critical technology for autonomous driving, while few studies have focusedon applying roadside sensors in 3D traffic object detection. Existing studiesachieve the projection of 2D image features to 3D features through heightestimation based on the frustum. However, they did not consider the heightalignment and the extraction efficiency of bird's-eye-view features. We proposea novel 3D object detection framework integrating Spatial Former and VoxelPooling Former to enhance 2D-to-3D projection based on height estimation.Extensive experiments were conducted using the Rope3D and DAIR-V2X-I dataset,and the results demonstrated the outperformance of the proposed algorithm inthe detection of both vehicles and cyclists. These results indicate that thealgorithm is robust and generalized under various detection scenarios.Improving the accuracy of 3D object detection on the roadside is conducive tobuilding a safe and trustworthy intelligent transportation system ofvehicle-road coordination and promoting the large-scale application ofautonomous driving. The code and pre-trained models will be released onhttps://anonymous.4open.science/r/HeightFormer.</description>
      <author>example@mail.com (Pei Liu, Zihao Zhang, Haipeng Liu, Nanfang Zheng, Meixin Zhu, Ziyuan Pu)</author>
      <guid isPermaLink="false">2410.07758v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Learning of Spatio-Temporal Patterns in Spiking Neuronal Networks</title>
      <link>http://arxiv.org/abs/2410.08637v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published at the Proceedings of the International Conference on
  Neuromorphic Systems 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预测未来事件或模式的能力在交通控制、天气预报和供应链管理等多个应用中至关重要。&lt;h4&gt;目的&lt;/h4&gt;扩展已有的生物学合理的序列学习模型，以检测和学习多种时空模式的序列。&lt;h4&gt;方法&lt;/h4&gt;在原有模型基础上，结合输入突触中的可塑性连接，采用脉冲神经网络和无监督的局部学习规则。&lt;h4&gt;主要发现&lt;/h4&gt;模型能够学习和预测高阶序列，并且在不同输入设置和参数下表现出鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;改进后的模型有效地扩展了序列学习的能力，能够处理更复杂的时空模式。&lt;h4&gt;总结&lt;/h4&gt;本研究为序列学习提供了一种新的生物学启发的方法，具有较强的实用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ffeiler/unsupervised_sequence_learning_stp_snn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to predict future events or patterns based on previous experienceis crucial for many applications such as traffic control, weather forecasting,or supply chain management. While modern supervised Machine Learning approachesexcel at such sequential tasks, they are computationally expensive and requirelarge training data. A previous work presented a biologically plausiblesequence learning model, developed through a bottom-up approach, consisting ofa spiking neural network and unsupervised local learning rules. The model inits original formulation identifies only a specific type of sequence elementscomposed of synchronous spikes by activating a subset of neurons with identicalstimulus preference. In this work, we extend the model to detect and learnsequences of various spatio-temporal patterns (STPs) by incorporating plasticconnections in the input synapses. We showcase that the model is able to learnand predict high-order sequences. We further study the robustness of the modelagainst different input settings and parameters.</description>
      <author>example@mail.com (Florian Feiler, Emre Neftci, Younes Bouhadjar)</author>
      <guid isPermaLink="false">2410.08637v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>On-the-fly Modulation for Balanced Multimodal Learning</title>
      <link>http://arxiv.org/abs/2410.11582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by T-PAMI 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态学习通过整合不同模态的信息来提升模型性能，但其潜力未得到充分利用。&lt;h4&gt;目的&lt;/h4&gt;解决目前联合训练策略下模态之间不平衡和未优化的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了在优化过程中监测模态间的判别差异的On-the-fly Prediction Modulation (OPM)和On-the-fly Gradient Modulation (OGM)策略，以调整每个模态的优化。&lt;h4&gt;主要发现&lt;/h4&gt;OPM通过动态概率降低主导模态的影响，OGM则在反向传播阶段减小其梯度，显著改善了多模态任务的性能。&lt;h4&gt;结论&lt;/h4&gt;这些简单有效的策略不仅提升了基础和任务导向的多模态模型性能，还在更复杂的多模态任务中展示了其有效性和灵活性。&lt;h4&gt;总结&lt;/h4&gt;研究提供了新的方法来增强多模态学习的效果，源代码可在指定网址获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/gewu-lab/bml_tpami2024&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal learning is expected to boost model performance by integratinginformation from different modalities. However, its potential is not fullyexploited because the widely-used joint training strategy, which has a uniformobjective for all modalities, leads to imbalanced and under-optimized uni-modalrepresentations. Specifically, we point out that there often exists modalitywith more discriminative information, e.g., vision of playing football andsound of blowing wind. They could dominate the joint training process,resulting in other modalities being significantly under-optimized. To alleviatethis problem, we first analyze the under-optimized phenomenon from both thefeed-forward and the back-propagation stages during optimization. Then,On-the-fly Prediction Modulation (OPM) and On-the-fly Gradient Modulation (OGM)strategies are proposed to modulate the optimization of each modality, bymonitoring the discriminative discrepancy between modalities during training.Concretely, OPM weakens the influence of the dominant modality by dropping itsfeature with dynamical probability in the feed-forward stage, while OGMmitigates its gradient in the back-propagation stage. In experiments, ourmethods demonstrate considerable improvement across a variety of multimodaltasks. These simple yet effective strategies not only enhance performance invanilla and task-oriented multimodal models, but also in more complexmultimodal tasks, showcasing their effectiveness and flexibility. The sourcecode is available at \url{https://github.com/GeWu-Lab/BML_TPAMI2024}.</description>
      <author>example@mail.com (Yake Wei, Di Hu, Henghui Du, Ji-Rong Wen)</author>
      <guid isPermaLink="false">2410.11582v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>TransAgent: Transfer Vision-Language Foundation Models with Heterogeneous Agent Collaboration</title>
      <link>http://arxiv.org/abs/2410.12183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉语言基础模型（如 CLIP）在迁移学习中表现出色，得益于大规模图像-文本预训练。&lt;h4&gt;目的&lt;/h4&gt;解决目标领域数据与预训练阶段差异大的问题，以提高模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种通用的 TransAgent 框架，通过统一方式传输孤立代理的知识，有效指导 CLIP 进行多源知识蒸馏。&lt;h4&gt;主要发现&lt;/h4&gt;TransAgent 能够与 11 个异构代理灵活协作，提升视觉语言基础模型的性能。&lt;h4&gt;结论&lt;/h4&gt;TransAgent 在 11 个视觉识别数据集上达到了最先进的性能，平均比 CoOp 提高了约 10%，在包含大领域转移的 EuroSAT 数据集上提高了 20%。&lt;h4&gt;总结&lt;/h4&gt;TransAgent 框架有效整合了多种知识源，增强了模型的泛化能力，并在多项任务中取得了显著成果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language foundation models (such as CLIP) have recently shown theirpower in transfer learning, owing to large-scale image-text pre-training.However, target domain data in the downstream tasks can be highly differentfrom the pre-training phase, which makes it hard for such a single model togeneralize well. Alternatively, there exists a wide range of expert models thatcontain diversified vision and/or language knowledge pre-trained on differentmodalities, tasks, networks, and datasets. Unfortunately, these models are"isolated agents" with heterogeneous structures, and how to integrate theirknowledge for generalizing CLIP-like models has not been fully explored. Tobridge this gap, we propose a general and concise TransAgent framework, whichtransports the knowledge of the isolated agents in a unified manner, andeffectively guides CLIP to generalize with multi-source knowledge distillation.With such a distinct framework, we flexibly collaborate with 11 heterogeneousagents to empower vision-language foundation models, without further cost inthe inference phase. Finally, our TransAgent achieves state-of-the-artperformance on 11 visual recognition datasets. Under the same low-shot setting,it outperforms the popular CoOp with around 10% on average, and 20% on EuroSATwhich contains large domain shifts.</description>
      <author>example@mail.com (Yiwei Guo, Shaobin Zhuang, Kunchang Li, Yu Qiao, Yali Wang)</author>
      <guid isPermaLink="false">2410.12183v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CERES: Critical-Event Reconstruction via Temporal Scene Graph Completion</title>
      <link>http://arxiv.org/abs/2410.13514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;评估自主车辆（AVs）在安全关键和常规场景中的行为对于其在现实世界中的部署至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于真实世界数据的按需场景生成方法，以提高测试集的可信性和有效性。&lt;h4&gt;方法&lt;/h4&gt;采用时间场景图捕捉真实世界数据中场景实体之间不断变化的时空关系，并通过图神经网络（GNNs）生成动态场景。使用用户定义的行动和关键性条件确保灵活的定制场景创建。&lt;h4&gt;主要发现&lt;/h4&gt;我们的模型在准确预测与请求场景对应的链接方面显著优于基准。&lt;h4&gt;结论&lt;/h4&gt;进一步评估生成场景在现成模拟器中的有效性和兼容性。&lt;h4&gt;总结&lt;/h4&gt;该研究为自主车辆的场景生成提供了一种新的方法，增强了模拟测试的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes a method for on-demand scenario generation in simulation,grounded on real-world data. Evaluating the behaviour of Autonomous Vehicles(AVs) in both safety-critical and regular scenarios is essential for assessingtheir robustness before real-world deployment. By integrating scenarios derivedfrom real-world datasets into the simulation, we enhance the plausibility andvalidity of testing sets. This work introduces a novel approach that employstemporal scene graphs to capture evolving spatiotemporal relationships amongscene entities from a real-world dataset, enabling the generation of dynamicscenarios in simulation through Graph Neural Networks (GNNs). User-definedaction and criticality conditioning are used to ensure flexible, tailoredscenario creation. Our model significantly outperforms the benchmarks inaccurately predicting links corresponding to the requested scenarios. Wefurther evaluate the validity and compatibility of our generated scenarios inan off-the-shelf simulator.</description>
      <author>example@mail.com (Efimia Panagiotaki, Georgi Pramatarov, Lars Kunze, Daniele De Martini)</author>
      <guid isPermaLink="false">2410.13514v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Metalic: Meta-Learning In-Context with Protein Language Models</title>
      <link>http://arxiv.org/abs/2410.08355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;使用通用密集表示建模轨迹数据已成为各种下游应用的普遍范式，例如轨迹分类、旅行时间估计和相似性计算。&lt;h4&gt;目的&lt;/h4&gt;提出MVTraj，一种新颖的多视角建模方法，以学习轨迹表示。&lt;h4&gt;方法&lt;/h4&gt;MVTraj整合来自GPS、道路网络和兴趣点的多样上下文知识，通过自监督预训练任务捕捉和区分不同空间视图的运动模式，并利用层次交互模块融合不同视图的表示。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界数据集上的大量实验表明，MVTraj在与不同空间视图相关的任务中显著优于现有基线，验证了其有效性和实用性。&lt;h4&gt;结论&lt;/h4&gt;MVTraj为轨迹数据建模提供了更全面的理解，能够更好地捕捉不同地理背景下的运动模式。&lt;h4&gt;总结&lt;/h4&gt;MVTraj方法通过多视角整合和层次交互，提升了轨迹表示学习的效果，具有重要的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting the biophysical and functional properties of proteins is essentialfor in silico protein design. Machine learning has emerged as a promisingtechnique for such prediction tasks. However, the relative scarcity of in vitroannotations means that these models often have little, or no, specific data onthe desired fitness prediction task. As a result of limited data, proteinlanguage models (PLMs) are typically trained on general protein sequencemodeling tasks, and then fine-tuned, or applied zero-shot, to protein fitnessprediction. When no task data is available, the models make strong assumptionsabout the correlation between the protein sequence likelihood and fitnessscores. In contrast, we propose meta-learning over a distribution of standardfitness prediction tasks, and demonstrate positive transfer to unseen fitnessprediction tasks. Our method, called Metalic (Meta-Learning In-Context), usesin-context learning and fine-tuning, when data is available, to adapt to newtasks. Crucially, fine-tuning enables considerable generalization, even thoughit is not accounted for during meta-training. Our fine-tuned models achievestrong results with 18 times fewer parameters than state-of-the-art models.Moreover, our method sets a new state-of-the-art in low-data settings onProteinGym, an established fitness-prediction benchmark. Due to data scarcity,we believe meta-learning will play a pivotal role in advancing proteinengineering.</description>
      <author>example@mail.com (Jacob Beck, Shikha Surana, Manus McAuliffe, Oliver Bent, Thomas D. Barrett, Juan Jose Garau Luis, Paul Duckworth)</author>
      <guid isPermaLink="false">2410.08355v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Context-Enhanced Multi-View Trajectory Representation Learning: Bridging the Gap through Self-Supervised Models</title>
      <link>http://arxiv.org/abs/2410.13196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于视觉的鸟瞰图（BEV）3D物体检测在自动驾驶中变得越来越流行，但现有方法对与背景高度相似的物体检测效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法ROA-BEV，以提高BEV基础的3D物体检测性能。&lt;h4&gt;方法&lt;/h4&gt;采用2D区域导向注意力机制，使网络更加关注可能存在物体的特征学习，并通过多尺度结构增强信息内容。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes数据集上的实验表明，ROA-BEV在BEVDet和BEVDepth的基础上提升了检测性能。&lt;h4&gt;结论&lt;/h4&gt;ROA-BEV为3D物体检测提供了更有效的解决方案，相关代码将很快发布。&lt;h4&gt;总结&lt;/h4&gt;本文提出的ROA-BEV方法通过区域导向注意力和多尺度结构，显著提高了基于BEV的3D物体检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling trajectory data with generic-purpose dense representations hasbecome a prevalent paradigm for various downstream applications, such astrajectory classification, travel time estimation and similarity computation.However, existing methods typically rely on trajectories from a single spatialview, limiting their ability to capture the rich contextual information that iscrucial for gaining deeper insights into movement patterns across differentgeospatial contexts. To this end, we propose MVTraj, a novel multi-viewmodeling method for trajectory representation learning. MVTraj integratesdiverse contextual knowledge, from GPS to road network and points-of-interestto provide a more comprehensive understanding of trajectory data. To align thelearning process across multiple views, we utilize GPS trajectories as a bridgeand employ self-supervised pretext tasks to capture and distinguish movementpatterns across different spatial views. Following this, we treat trajectoriesfrom different views as distinct modalities and apply a hierarchicalcross-modal interaction module to fuse the representations, thereby enrichingthe knowledge derived from multiple sources. Extensive experiments onreal-world datasets demonstrate that MVTraj significantly outperforms existingbaselines in tasks associated with various spatial views, validating itseffectiveness and practical utility in spatio-temporal modeling.</description>
      <author>example@mail.com (Tangwen Qian, Junhe Li, Yile Chen, Gao Cong, Tao Sun, Fei Wang, Yongjun Xu)</author>
      <guid isPermaLink="false">2410.13196v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>ROA-BEV: 2D Region-Oriented Attention for BEV-based 3D Object</title>
      <link>http://arxiv.org/abs/2410.10298v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于视觉的鸟瞰图（BEV）3D物体检测在自动驾驶中变得越来越流行，但现有方法对与背景高度相似的物体检测效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法ROA-BEV，以提高BEV基础的3D物体检测性能。&lt;h4&gt;方法&lt;/h4&gt;采用2D区域导向注意力机制，使网络更加关注可能存在物体的特征学习，并通过多尺度结构增强信息内容。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes数据集上的实验表明，ROA-BEV在BEVDet和BEVDepth的基础上提升了检测性能。&lt;h4&gt;结论&lt;/h4&gt;ROA-BEV为3D物体检测提供了更有效的解决方案，相关代码将很快发布。&lt;h4&gt;总结&lt;/h4&gt;本文提出的ROA-BEV方法通过区域导向注意力和多尺度结构，显著提高了基于BEV的3D物体检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-based BEV (Bird-Eye-View) 3D object detection has recently becomepopular in autonomous driving. However, objects with a high similarity to thebackground from a camera perspective cannot be detected well by existingmethods. In this paper, we propose 2D Region-oriented Attention for a BEV-based3D Object Detection Network (ROA-BEV), which can make the backbone focus moreon feature learning in areas where objects may exist. Moreover, our methodincreases the information content of ROA through a multi-scale structure. Inaddition, every block of ROA utilizes a large kernel to ensure that thereceptive field is large enough to catch large objects' information.Experiments on nuScenes show that ROA-BEV improves the performance based onBEVDet and BEVDepth. The code will be released soon.</description>
      <author>example@mail.com (Jiwei Chen, Laiyan Ding, Chi Zhang, Feifei Li, Rui Huang)</author>
      <guid isPermaLink="false">2410.10298v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Interdependency Matters: Graph Alignment for Multivariate Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2410.08877v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列（MTS）中的异常检测对于数据挖掘和工业应用至关重要。当前工业方法通常将异常检测视为无监督学习任务，旨在通过估计噪声和无标签数据集中的正常分布来识别偏差。&lt;h4&gt;目的&lt;/h4&gt;探讨MTS通道之间的相互依赖性在异常检测中的重要性，并提出一种新的方法来利用这种相互依赖性进行异常检测。&lt;h4&gt;方法&lt;/h4&gt;提出MADGA（通过图对齐的MTS异常检测），将异常检测重新定义为图对齐问题，动态将子序列转换为图，捕捉不断变化的相互依赖性，并通过优化对齐计划来进行图对齐。&lt;h4&gt;主要发现&lt;/h4&gt;相互依赖性从正常到异常数据的变化显著，异常可以通过这些相互依赖性图序列的变化来检测。MADGA在各种真实世界数据集上的广泛实验验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;MADGA在检测异常和区分相互依赖性方面展现出出色的能力，始终在各种场景中达到最先进的水平。&lt;h4&gt;总结&lt;/h4&gt;MADGA是首个明确利用相互依赖性进行MTS异常检测的图对齐应用，具有创新性和实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wyy-code/MADGA&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection in multivariate time series (MTS) is crucial for variousapplications in data mining and industry. Current industrial methods typicallyapproach anomaly detection as an unsupervised learning task, aiming to identifydeviations by estimating the normal distribution in noisy, label-free datasets.These methods increasingly incorporate interdependencies between channelsthrough graph structures to enhance accuracy. However, the role ofinterdependencies is more critical than previously understood, as shifts ininterdependencies between MTS channels from normal to anomalous data aresignificant. This observation suggests that \textit{anomalies could be detectedby changes in these interdependency graph series}. To capitalize on thisinsight, we introduce MADGA (MTS Anomaly Detection via Graph Alignment), whichredefines anomaly detection as a graph alignment (GA) problem that explicitlyutilizes interdependencies for anomaly detection. MADGA dynamically transformssubsequences into graphs to capture the evolving interdependencies, and Graphalignment is performed between these graphs, optimizing an alignment plan thatminimizes cost, effectively minimizing the distance for normal data andmaximizing it for anomalous data. Uniquely, our GA approach involves explicitalignment of both nodes and edges, employing Wasserstein distance for nodes andGromov-Wasserstein distance for edges. To our knowledge, this is the firstapplication of GA to MTS anomaly detection that explicitly leveragesinterdependency for this purpose. Extensive experiments on diverse real-worlddatasets validate the effectiveness of MADGA, demonstrating its capability todetect anomalies and differentiate interdependencies, consistently achievingstate-of-the-art across various scenarios.</description>
      <author>example@mail.com (Yuanyi Wang, Haifeng Sun, Chengsen Wang, Mengde Zhu, Jingyu Wang, Wei Tang, Qi Qi, Zirui Zhuang, Jianxin Liao)</author>
      <guid isPermaLink="false">2410.08877v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>A Simplifying and Learnable Graph Convolutional Attention Network for Unsupervised Knowledge Graphs Alignment</title>
      <link>http://arxiv.org/abs/2410.13263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的实体对齐任务依赖于标记数据提供的监督信息，但标记数据的成本较高，导致大多数监督方法在实际场景中难以应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种简化且可学习的图卷积注意网络用于无监督知识图谱对齐的方法，以解决缺乏标记数据所导致的性能瓶颈。&lt;h4&gt;方法&lt;/h4&gt;引入LCAT作为骨干网络建模两个知识图谱的图结构，并设计基于潜在匹配关系的关系结构重建方法，以有效过滤对齐实体的无效邻域信息。&lt;h4&gt;主要发现&lt;/h4&gt;基于一致性的相似性函数被提出，以更好地衡量候选实体对的相似性。SLU在不同大小和类型的三个数据集上进行了广泛实验，验证了其优越性。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，SLU显著提高了对齐准确性，超过了25种监督或无监督方法，在最佳情况下，Hits@1提高了6.4%。&lt;h4&gt;总结&lt;/h4&gt;SLU方法有效解决了无监督实体对齐中的建模复杂性和效果与实用性平衡的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The success of current Entity Alignment (EA) task depends largely on thesupervision information provided by labeled data. Considering the cost oflabeled data, most supervised methods are difficult to apply in practicalscenarios. Therefore, more and more works based on contrastive learning, activelearning or other deep learning techniques have been developed, to solve theperformance bottleneck caused by the lack of labeled data. However, theexisting unsupervised EA methods still have some limitations, either theirmodeling complexity is high or they cannot balance the effectiveness andpracticality of alignment. To overcome these issues, we propose a Simplifyingand Learnable graph convolutional attention network for Unsupervised KnowledgeGraphs alignment method (SLU). Specifically, we first introduce LCAT, a new andsimple framework as the backbone network to model the graph structure of twoKGs. Then we design a reconstruction method of relation structure based onpotential matching relations for efficiently filtering invalid neighborhoodinformation of aligned entities, to improve the usability and scalability ofSLU. Impressively, a similarity function based on consistency is proposed tobetter measure the similarity of candidate entity pairs. Finally, we conductextensive experiments on three datasets of different sizes (15K and 100K) anddifferent types (cross-lingual and monolingual) to verify the superiority ofSLU. Experimental results show that SLU significantly improves alignmentaccuracy, outperforming 25 supervised or unsupervised methods, and improving6.4% in Hits@1 over the best baseline in the best case.</description>
      <author>example@mail.com (Weishan Cai, Wenjun Ma, Yuncheng Jiang)</author>
      <guid isPermaLink="false">2410.13263v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning on Multi-Dimensional Data: A Novel Approach to Neural Network-Based Surrogate Modeling</title>
      <link>http://arxiv.org/abs/2410.12241v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Referring 3D Segmentation是一项视觉语言任务，旨在从3D点云中根据查询句子分割指定对象的所有点。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的Referring 3D Segmentation流程，旨在提高标签效率并简化流程。&lt;h4&gt;方法&lt;/h4&gt;提出了Label-Efficient and Single-Stage（LESS）框架，采用高效的二进制掩膜监督；设计了Point-Word Cross-Modal Alignment模块以对齐点的细粒度特征和文本嵌入。此外，引入了QueryMask Predictor和Query-Sentence Alignment模块进行掩膜与查询的粗粒度对齐。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验，在ScanRefer数据集上实现了先进的性能，mIoU比之前的方法提高了约3.7%，仅使用二进制标签。&lt;h4&gt;结论&lt;/h4&gt;LESS方法有效减少了对人工标注和时间的依赖，提升了3D分割的效率和准确性。&lt;h4&gt;总结&lt;/h4&gt;LESS为Referring 3D Segmentation任务提供了一种新的高效解决方案，展示了在仅使用二进制标签的情况下超越现有方法的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of efficient surrogates of partial differential equations(PDEs) is a critical step towards scalable modeling of complex, multiscalesystems-of-systems. Convolutional neural networks (CNNs) have gained popularityas the basis for such surrogate models due to their success in capturinghigh-dimensional input-output mappings and the negligible cost of a forwardpass. However, the high cost of generating training data -- typically viaclassical numerical solvers -- raises the question of whether these models areworth pursuing over more straightforward alternatives with well-establishedtheoretical foundations, such as Monte Carlo methods. To reduce the cost ofdata generation, we propose training a CNN surrogate model on a mixture ofnumerical solutions to both the $d$-dimensional problem and its($d-1$)-dimensional approximation, taking advantage of the efficiency savingsguaranteed by the curse of dimensionality. We demonstrate our approach on amultiphase flow test problem, using transfer learning to train a densefully-convolutional encoder-decoder CNN on the two classes of data. Numericalresults from a sample uncertainty quantification task demonstrate that oursurrogate model outperforms Monte Carlo with several times the data generationbudget.</description>
      <author>example@mail.com (Adrienne M. Propp, Daniel M. Tartakovsky)</author>
      <guid isPermaLink="false">2410.12241v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>LESS: Label-Efficient and Single-Stage Referring 3D Segmentation</title>
      <link>http://arxiv.org/abs/2410.13294v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Referring 3D Segmentation是一项视觉语言任务，旨在从3D点云中根据查询句子分割指定对象的所有点。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的Referring 3D Segmentation流程，旨在提高标签效率并简化流程。&lt;h4&gt;方法&lt;/h4&gt;提出了Label-Efficient and Single-Stage（LESS）框架，采用高效的二进制掩膜监督；设计了Point-Word Cross-Modal Alignment模块以对齐点的细粒度特征和文本嵌入。此外，引入了QueryMask Predictor和Query-Sentence Alignment模块进行掩膜与查询的粗粒度对齐。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验，在ScanRefer数据集上实现了先进的性能，mIoU比之前的方法提高了约3.7%，仅使用二进制标签。&lt;h4&gt;结论&lt;/h4&gt;LESS方法有效减少了对人工标注和时间的依赖，提升了3D分割的效率和准确性。&lt;h4&gt;总结&lt;/h4&gt;LESS为Referring 3D Segmentation任务提供了一种新的高效解决方案，展示了在仅使用二进制标签的情况下超越现有方法的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Referring 3D Segmentation is a visual-language task that segments all pointsof the specified object from a 3D point cloud described by a sentence of query.Previous works perform a two-stage paradigm, first conducting language-agnosticinstance segmentation then matching with given text query. However, thesemantic concepts from text query and visual cues are separately interactedduring the training, and both instance and semantic labels for each object arerequired, which is time consuming and human-labor intensive. To mitigate theseissues, we propose a novel Referring 3D Segmentation pipeline, Label-Efficientand Single-Stage, dubbed LESS, which is only under the supervision of efficientbinary mask. Specifically, we design a Point-Word Cross-Modal Alignment modulefor aligning the fine-grained features of points and textual embedding. QueryMask Predictor module and Query-Sentence Alignment module are introduced forcoarse-grained alignment between masks and query. Furthermore, we propose anarea regularization loss, which coarsely reduces irrelevant backgroundpredictions on a large scale. Besides, a point-to-point contrastive loss isproposed concentrating on distinguishing points with subtly similar features.Through extensive experiments, we achieve state-of-the-art performance onScanRefer dataset by surpassing the previous methods about 3.7% mIoU using onlybinary labels.</description>
      <author>example@mail.com (Xuexun Liu, Xiaoxu Xu, Jinlong Li, Qiudan Zhang, Xu Wang, Nicu Sebe, Lin Ma)</author>
      <guid isPermaLink="false">2410.13294v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Observation of a rare beta decay of the charmed baryon with a Graph Neural Network</title>
      <link>http://arxiv.org/abs/2410.13515v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  28 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究魅夸克重子β衰变为强相互作用和电弱相互作用的基本机制提供了独特的见解。&lt;h4&gt;目的&lt;/h4&gt;利用轻est魅夸克重子Λ_c^+的衰变研究非微扰效应和约束CKM矩阵的基本参数。&lt;h4&gt;方法&lt;/h4&gt;基于BESIII探测器收集的4.5 fb^-1电子-正电子湮灭数据，首次观察到Cabibbo抑制的Λ_c^+ β衰变至中子，采用图神经网络分离信号和背景。&lt;h4&gt;主要发现&lt;/h4&gt;Λ_c^+衰变至n e^+ ν_e的绝对分支比为(3.57±0.34_{stat}±0.14_{syst})×10^{-3}，CKM矩阵元素|V_{cd}|被测量为0.208±0.011_{exp.}±0.007_{LQCD}±0.001_{τ_{Λ_c^+}}。&lt;h4&gt;结论&lt;/h4&gt;该研究为理解魅夸克重子领域的基本相互作用提供了新探针，展示了现代机器学习技术在高能物理研究中的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;通过先进的机器学习技术，该研究提升了实验能力，并为基础物理学提供了新的理解途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The study of beta decay of the charmed baryon provides unique insights intothe fundamental mechanism of the strong and electro-weak interactions. The$\Lambda_c^+$, being the lightest charmed baryon, undergoes disintegrationsolely through the charm quark weak decay. Its beta decay provides an ideallaboratory for investigating non-perturbative effects in quantum chromodynamicsand for constraining the fundamental parameters of theCabibbo-Kobayashi-Maskawa matrix in weak interaction theory. This articlepresents the first observation of the Cabibbo-suppressed $\Lambda_c^+$ betadecay into a neutron $\Lambda_c^+ \rightarrow n e^+ \nu_{e}$, based on$4.5~\mathrm{fb}^{-1}$ of electron-positron annihilation data collected withthe BESIII detector in the energy region above the$\Lambda^+_c\bar{\Lambda}^-_c$ threshold. A novel machine learning technique,leveraging Graph Neural Networks, has been utilized to effectively separatesignals from dominant backgrounds, particularly $\Lambda_c^+ \rightarrow\Lambda e^+ \nu_{e}$. This approach has yielded a statistical significance ofmore than $10\sigma$. The absolute branching fraction of $\Lambda_c^+\rightarrow n e^+ \nu_{e}$ is measured to be$(3.57\pm0.34_{\mathrm{stat}}\pm0.14_{\mathrm{syst}})\times 10^{-3}$. For thefirst time, the CKM matrix element $\left|V_{cd}\right|$ is extracted via acharmed baryon decay to be $0.208\pm0.011_{\rm exp.}\pm0.007_{\rmLQCD}\pm0.001_{\tau_{\Lambda_c^+}}$. This study provides a new probe to furtherunderstand fundamental interactions in the charmed baryon sector, anddemonstrates the power of modern machine learning techniques in enhancingexperimental capability in high energy physics research.</description>
      <author>example@mail.com (BESIII Collaboration, M. Ablikim, M. N. Achasov, P. Adlarson, O. Afedulidis, X. C. Ai, R. Aliberti, A. Amoroso, Q. An, Y. Bai, O. Bakina, I. Balossino, Y. Ban, H. -R. Bao, V. Batozskaya, K. Begzsuren, N. Berger, M. Berlowski, M. Bertani, D. Bettoni, F. Bianchi, E. Bianco, A. Bortone, I. Boyko, R. A. Briere, A. Brueggemann, H. Cai, X. Cai, A. Calcaterra, G. F. Cao, N. Cao, S. A. Cetin, J. F. Chang, G. R. Che, G. Chelkov, C. Chen, C. H. Chen, Chao Chen, G. Chen, H. S. Chen, H. Y. Chen, M. L. Chen, S. J. Chen, S. L. Chen, S. M. Chen, T. Chen, X. R. Chen, X. T. Chen, Y. B. Chen, Y. Q. Chen, Z. J. Chen, Z. Y. Chen, S. K. Choi, G. Cibinetto, F. Cossio, J. J. Cui, H. L. Dai, J. P. Dai, A. Dbeyssi, R. E. de Boer, D. Dedovich, C. Q. Deng, Z. Y. Deng, A. Denig, I. Denysenko, M. Destefanis, F. De Mori, B. Ding, X. X. Ding, Y. Ding, Y. Ding, J. Dong, L. Y. Dong, M. Y. Dong, X. Dong, M. C. Du, S. X. Du, Y. Y. Duan, Z. H. Duan, P. Egorov, Y. H. Fan, J. Fang, J. Fang, S. S. Fang, W. X. Fang, Y. Fang, Y. Q. Fang, R. Farinelli, L. Fava, F. Feldbauer, G. Felici, C. Q. Feng, J. H. Feng, Y. T. Feng, M. Fritsch, C. D. Fu, J. L. Fu, Y. W. Fu, H. Gao, X. B. Gao, Y. N. Gao, Yang Gao, S. Garbolino, I. Garzia, L. Ge, P. T. Ge, Z. W. Ge, C. Geng, E. M. Gersabeck, A. Gilman, K. Goetzen, L. Gong, W. X. Gong, W. Gradl, S. Gramigna, M. Greco, M. H. Gu, Y. T. Gu, C. Y. Guan, A. Q. Guo, L. B. Guo, M. J. Guo, R. P. Guo, Y. P. Guo, A. Guskov, J. Gutierrez, K. L. Han, T. T. Han, F. Hanisch, X. Q. Hao, F. A. Harris, K. K. He, K. L. He, F. H. Heinsius, C. H. Heinz, Y. K. Heng, C. Herold, T. Holtmann, P. C. Hong, G. Y. Hou, X. T. Hou, Y. R. Hou, Z. L. Hou, B. Y. Hu, H. M. Hu, J. F. Hu, S. L. Hu, T. Hu, Y. Hu, G. S. Huang, K. X. Huang, L. Q. Huang, X. T. Huang, Y. P. Huang, T. Hussain, F. Hölzken, N. Hüsken, N. in der Wiesche, J. Jackson, S. Janchiv, J. H. Jeong, Q. Ji, Q. P. Ji, W. Ji, X. B. Ji, X. L. Ji, Y. Y. Ji, X. Q. Jia, Z. K. Jia, D. Jiang, H. B. Jiang, P. C. Jiang, S. S. Jiang, T. J. Jiang, X. S. Jiang, Y. Jiang, J. B. Jiao, J. K. Jiao, Z. Jiao, S. Jin, Y. Jin, M. Q. Jing, X. M. Jing, T. Johansson, S. Kabana, N. Kalantar-Nayestanaki, X. L. Kang, X. S. Kang, M. Kavatsyuk, B. C. Ke, V. Khachatryan, A. Khoukaz, R. Kiuchi, O. B. Kolcu, B. Kopf, M. Kuessner, X. Kui, N. Kumar, A. Kupsc, W. Kühn, J. J. Lane, P. Larin, L. Lavezzi, T. T. Lei, Z. H. Lei, M. Lellmann, T. Lenz, C. Li, C. Li, C. H. Li, Cheng Li, D. M. Li, F. Li, G. Li, H. B. Li, H. J. Li, H. N. Li, Hui Li, J. R. Li, J. S. Li, K. Li, L. J. Li, L. K. Li, Lei Li, M. H. Li, P. R. Li, Q. M. Li, Q. X. Li, R. Li, S. X. Li, T. Li, W. D. Li, W. G. Li, X. Li, X. H. Li, X. L. Li, X. Y. Li, X. Z. Li, Y. G. Li, Z. J. Li, Z. Y. Li, C. Liang, H. Liang, H. Liang, Y. F. Liang, Y. T. Liang, G. R. Liao, L. Z. Liao, Y. P. Liao, J. Libby, A. Limphirat, C. C. Lin, D. X. Lin, T. Lin, B. J. Liu, B. X. Liu, C. Liu, C. X. Liu, F. Liu, F. H. Liu, Feng Liu, G. M. Liu, H. Liu, H. B. Liu, H. H. Liu, H. M. Liu, Huihui Liu, J. B. Liu, J. Y. Liu, K. Liu, K. Y. Liu, Ke Liu, L. Liu, L. C. Liu, Lu Liu, M. H. Liu, P. L. Liu, Q. Liu, S. B. Liu, T. Liu, W. K. Liu, W. M. Liu, X. Liu, X. Liu, Y. Liu, Y. Liu, Y. B. Liu, Z. A. Liu, Z. D. Liu, Z. Q. Liu, X. C. Lou, F. X. Lu, H. J. Lu, J. G. Lu, X. L. Lu, Y. Lu, Y. P. Lu, Z. H. Lu, C. L. Luo, J. R. Luo, M. X. Luo, T. Luo, X. L. Luo, X. R. Lyu, Y. F. Lyu, F. C. Ma, H. Ma, H. L. Ma, J. L. Ma, L. L. Ma, M. M. Ma, Q. M. Ma, R. Q. Ma, T. Ma, X. T. Ma, X. Y. Ma, Y. Ma, Y. M. Ma, F. E. Maas, M. Maggiora, S. Malde, Y. J. Mao, Z. P. Mao, S. Marcello, Z. X. Meng, J. G. Messchendorp, G. Mezzadri, H. Miao, T. J. Min, R. E. Mitchell, X. H. Mo, B. Moses, N. Yu. Muchnoi, J. Muskalla, Y. Nefedov, F. Nerling, L. S. Nie, I. B. Nikolaev, Z. Ning, S. Nisar, Q. L. Niu, W. D. Niu, Y. Niu, S. L. Olsen, Q. Ouyang, S. Pacetti, X. Pan, Y. Pan, A. Pathak, P. Patteri, Y. P. Pei, M. Pelizaeus, H. P. Peng, Y. Y. Peng, K. Peters, J. L. Ping, R. G. Ping, S. Plura, V. Prasad, F. Z. Qi, H. Qi, H. R. Qi, M. Qi, T. Y. Qi, S. Qian, W. B. Qian, C. F. Qiao, X. K. Qiao, J. J. Qin, L. Q. Qin, L. Y. Qin, X. S. Qin, Z. H. Qin, J. F. Qiu, Z. H. Qu, C. F. Redmer, K. J. Ren, A. Rivetti, M. Rolo, G. Rong, Ch. Rosner, S. N. Ruan, N. Salone, A. Sarantsev, Y. Schelhaas, K. Schoenning, M. Scodeggio, K. Y. Shan, W. Shan, X. Y. Shan, Z. J. Shang, J. F. Shangguan, L. G. Shao, M. Shao, C. P. Shen, H. F. Shen, W. H. Shen, X. Y. Shen, B. A. Shi, H. Shi, H. C. Shi, J. L. Shi, J. Y. Shi, Q. Q. Shi, S. Y. Shi, X. Shi, J. J. Song, T. Z. Song, W. M. Song, Y. J. Song, Y. X. Song, S. Sosio, S. Spataro, F. Stieler, Y. J. Su, G. B. Sun, G. X. Sun, H. Sun, H. K. Sun, J. F. Sun, K. Sun, L. Sun, S. S. Sun, T. Sun, W. Y. Sun, Y. Sun, Y. J. Sun, Y. Z. Sun, Z. Q. Sun, Z. T. Sun, C. J. Tang, G. Y. Tang, J. Tang, M. Tang, Y. A. Tang, L. Y. Tao, Q. T. Tao, M. Tat, J. X. Teng, V. Thoren, W. H. Tian, Y. Tian, Z. F. Tian, I. Uman, Y. Wan, S. J. Wang, B. Wang, B. L. Wang, Bo Wang, D. Y. Wang, F. Wang, H. J. Wang, J. J. Wang, J. P. Wang, K. Wang, L. L. Wang, M. Wang, N. Y. Wang, S. Wang, S. Wang, T. Wang, T. J. Wang, W. Wang, W. Wang, W. P. Wang, X. Wang, X. F. Wang, X. J. Wang, X. L. Wang, X. N. Wang, Y. Wang, Y. D. Wang, Y. F. Wang, Y. L. Wang, Y. N. Wang, Y. Q. Wang, Yaqian Wang, Yi Wang, Z. Wang, Z. L. Wang, Z. Y. Wang, Ziyi Wang, D. H. Wei, F. Weidner, S. P. Wen, Y. R. Wen, U. Wiedner, G. Wilkinson, M. Wolke, L. Wollenberg, C. Wu, J. F. Wu, L. H. Wu, L. J. Wu, X. Wu, X. H. Wu, Y. Wu, Y. H. Wu, Y. J. Wu, Z. Wu, L. Xia, X. M. Xian, B. H. Xiang, T. Xiang, D. Xiao, G. Y. Xiao, S. Y. Xiao, Y. L. Xiao, Z. J. Xiao, C. Xie, X. H. Xie, Y. Xie, Y. G. Xie, Y. H. Xie, Z. P. Xie, T. Y. Xing, C. F. Xu, C. J. Xu, G. F. Xu, H. Y. Xu, M. Xu, Q. J. Xu, Q. N. Xu, W. Xu, W. L. Xu, X. P. Xu, Y. C. Xu, Z. P. Xu, Z. S. Xu, F. Yan, L. Yan, W. B. Yan, W. C. Yan, X. Q. Yan, H. J. Yang, H. L. Yang, H. X. Yang, T. Yang, Y. Yang, Y. F. Yang, Y. F. Yang, Y. X. Yang, Z. W. Yang, Z. P. Yao, M. Ye, M. H. Ye, J. H. Yin, Z. Y. You, B. X. Yu, C. X. Yu, G. Yu, J. S. Yu, T. Yu, X. D. Yu, Y. C. Yu, C. Z. Yuan, J. Yuan, J. Yuan, L. Yuan, S. C. Yuan, Y. Yuan, Z. Y. Yuan, C. X. Yue, A. A. Zafar, F. R. Zeng, S. H. Zeng, X. Zeng, Y. Zeng, Y. J. Zeng, Y. J. Zeng, X. Y. Zhai, Y. C. Zhai, Y. H. Zhan, A. Q. Zhang, B. L. Zhang, B. X. Zhang, D. H. Zhang, G. Y. Zhang, H. Zhang, H. Zhang, H. C. Zhang, H. H. Zhang, H. H. Zhang, H. Q. Zhang, H. R. Zhang, H. Y. Zhang, J. Zhang, J. Zhang, J. J. Zhang, J. L. Zhang, J. Q. Zhang, J. S. Zhang, J. W. Zhang, J. X. Zhang, J. Y. Zhang, J. Z. Zhang, Jianyu Zhang, L. M. Zhang, Lei Zhang, P. Zhang, Q. Y. Zhang, R. Y. Zhang, S. H. Zhang, Shulei Zhang, X. D. Zhang, X. M. Zhang, X. Y. Zhang, Y. Zhang, Y. Zhang, Y. T. Zhang, Y. H. Zhang, Y. M. Zhang, Yan Zhang, Z. D. Zhang, Z. H. Zhang, Z. L. Zhang, Z. Y. Zhang, Z. Y. Zhang, Z. Z. Zhang, G. Zhao, J. Y. Zhao, J. Z. Zhao, L. Zhao, Lei Zhao, M. G. Zhao, N. Zhao, R. P. Zhao, S. J. Zhao, Y. B. Zhao, Y. X. Zhao, Z. G. Zhao, A. Zhemchugov, B. Zheng, B. M. Zheng, J. P. Zheng, W. J. Zheng, Y. H. Zheng, B. Zhong, X. Zhong, H. Zhou, J. Y. Zhou, L. P. Zhou, S. Zhou, X. Zhou, X. K. Zhou, X. R. Zhou, X. Y. Zhou, Y. Z. Zhou, J. Zhu, K. Zhu, K. J. Zhu, K. S. Zhu, L. Zhu, L. X. Zhu, S. H. Zhu, S. Q. Zhu, T. J. Zhu, W. D. Zhu, Y. C. Zhu, Z. A. Zhu, J. H. Zou, J. Zu)</author>
      <guid isPermaLink="false">2410.13515v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Context-Aware Adapter Tuning for Few-Shot Relation Learning in Knowledge Graphs</title>
      <link>http://arxiv.org/abs/2410.09123v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by EMNLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;知识图谱（KGs）在各种现实世界应用中非常重要，但由于缺失关系，常常存在不完整性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，以预测具有有限训练样本的新关系。&lt;h4&gt;方法&lt;/h4&gt;引入RelAdapter，一个为少样本关系学习设计的上下文感知适配器，增强元学习中的适应过程。&lt;h4&gt;主要发现&lt;/h4&gt;RelAdapter通过轻量级适配器模块实现关系特定的可调适应，且整合了目标关系的上下文信息，从而提高了适应性。&lt;h4&gt;结论&lt;/h4&gt;在三个基准KGs上的广泛实验验证了RelAdapter相较于最先进方法的优越性。&lt;h4&gt;总结&lt;/h4&gt;RelAdapter有效解决了少样本关系学习中的独立同分布假设问题，提升了知识图谱的关系预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/liuran998/RelAdapter&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Knowledge graphs (KGs) are instrumental in various real-world applications,yet they often suffer from incompleteness due to missing relations. To predictinstances for novel relations with limited training examples, few-shot relationlearning approaches have emerged, utilizing techniques such as meta-learning.However, the assumption is that novel relations in meta-testing and baserelations in meta-training are independently and identically distributed, whichmay not hold in practice. To address the limitation, we propose RelAdapter, acontext-aware adapter for few-shot relation learning in KGs designed to enhancethe adaptation process in meta-learning. First, RelAdapter is equipped with alightweight adapter module that facilitates relation-specific, tunableadaptation of meta-knowledge in a parameter-efficient manner. Second,RelAdapter is enriched with contextual information about the target relation,enabling enhanced adaptation to each distinct relation. Extensive experimentson three benchmark KGs validate the superiority of RelAdapter overstate-of-the-art methods.</description>
      <author>example@mail.com (Ran Liu, Zhongzhou Liu, Xiaoli Li, Yuan Fang)</author>
      <guid isPermaLink="false">2410.09123v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Generalizable Spacecraft Trajectory Generation via Multimodal Learning with Transformers</title>
      <link>http://arxiv.org/abs/2410.11723v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures, submitted to 2025 American Control Conference
  (ACC)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;有效的轨迹生成对可靠的航天器自主控制至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的轨迹生成框架，以应对频繁重新配置场景的挑战。&lt;h4&gt;方法&lt;/h4&gt;利用高容量变换器神经网络，结合多模态数据源，编码场景和轨迹约束信息。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在非凸优化问题中生成近似最优初始猜测，显著提高收敛速度和性能。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的仿真和实际实验，该方法相比传统方法实现了最高30%的成本改善和80%的不可行案例减少。&lt;h4&gt;总结&lt;/h4&gt;该框架展示了在多种场景变化下的强健泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective trajectory generation is essential for reliable on-board spacecraftautonomy. Among other approaches, learning-based warm-starting represents anappealing paradigm for solving the trajectory generation problem, effectivelycombining the benefits of optimization- and data-driven methods. Currentapproaches for learning-based trajectory generation often focus on fixed,single-scenario environments, where key scene characteristics, such as obstaclepositions or final-time requirements, remain constant across problem instances.However, practical trajectory generation requires the scenario to be frequentlyreconfigured, making the single-scenario approach a potentially impracticalsolution. To address this challenge, we present a novel trajectory generationframework that generalizes across diverse problem configurations, by leveraginghigh-capacity transformer neural networks capable of learning from multimodaldata sources. Specifically, our approach integrates transformer-based neuralnetwork models into the trajectory optimization process, encoding bothscene-level information (e.g., obstacle locations, initial and goal states) andtrajectory-level constraints (e.g., time bounds, fuel consumption targets) viamultimodal representations. The transformer network then generates near-optimalinitial guesses for non-convex optimization problems, significantly enhancingconvergence speed and performance. The framework is validated through extensivesimulations and real-world experiments on a free-flyer platform, achieving upto 30% cost improvement and 80% reduction in infeasible cases with respect totraditional approaches, and demonstrating robust generalization across diversescenario variations.</description>
      <author>example@mail.com (Davide Celestini, Amirhossein Afsharrad, Daniele Gammelli, Tommaso Guffanti, Gioele Zardini, Sanjay Lall, Elisa Capello, Simone D'Amico, Marco Pavone)</author>
      <guid isPermaLink="false">2410.11723v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>UAV3D: A Large-scale 3D Perception Benchmark for Unmanned Aerial Vehicles</title>
      <link>http://arxiv.org/abs/2410.11125v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无人机（UAV）配备摄像头，广泛应用于航空摄影、监视和农业等领域。有效的目标检测和跟踪对无人机的部署至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出UAV3D基准，以促进无人机在3D感知和协作3D感知任务的研究。&lt;h4&gt;方法&lt;/h4&gt;UAV3D包含1000个场景，每个场景有20帧，配有完全标注的3D边界框，涵盖单无人机和协作无人机的3D目标检测与跟踪任务。&lt;h4&gt;主要发现&lt;/h4&gt;现有无人机应用基准主要针对传统的2D感知任务，限制了对环境的3D理解，并且单一无人机的视角限制了其在远距离或遮挡区域的感知能力。&lt;h4&gt;结论&lt;/h4&gt;UAV3D基准为多种3D感知任务提供了支持，促进了无人机技术在复杂环境下的应用。&lt;h4&gt;总结&lt;/h4&gt;UAV3D数据集和代码可在指定网址获取，推动无人机技术的进一步发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unmanned Aerial Vehicles (UAVs), equipped with cameras, are employed innumerous applications, including aerial photography, surveillance, andagriculture. In these applications, robust object detection and tracking areessential for the effective deployment of UAVs. However, existing benchmarksfor UAV applications are mainly designed for traditional 2D perception tasks,restricting the development of real-world applications that require a 3Dunderstanding of the environment. Furthermore, despite recent advancements insingle-UAV perception, limited views of a single UAV platform significantlyconstrain its perception capabilities over long distances or in occluded areas.To address these challenges, we introduce UAV3D, a benchmark designed toadvance research in both 3D and collaborative 3D perception tasks with UAVs.UAV3D comprises 1,000 scenes, each of which has 20 frames with fully annotated3D bounding boxes on vehicles. We provide the benchmark for four 3D perceptiontasks: single-UAV 3D object detection, single-UAV object tracking,collaborative-UAV 3D object detection, and collaborative-UAV object tracking.Our dataset and code are available athttps://huiyegit.github.io/UAV3D_Benchmark/.</description>
      <author>example@mail.com (Hui Ye, Rajshekhar Sunderraman, Shihao Ji)</author>
      <guid isPermaLink="false">2410.11125v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Affinity Propagation for Improved Public Sentiment Insights</title>
      <link>http://arxiv.org/abs/2410.12862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;每天生成大量数据，公众情绪在市场营销、政治和社会研究等领域中是关键因素。&lt;h4&gt;目的&lt;/h4&gt;了解不同主题的公众情绪以提供有价值的见解。&lt;h4&gt;方法&lt;/h4&gt;引入无监督学习技术，特别是Affinity Propagation (AP) 聚类，分析情感，比较AP与K-means聚类，使用TF-IDF向量化和主成分分析(PCA)进行降维。&lt;h4&gt;主要发现&lt;/h4&gt;AP与聚合层次聚类结合后，显著优于K-means聚类，能够更有效地捕捉全球和局部情感结构。&lt;h4&gt;结论&lt;/h4&gt;研究提出了一个可扩展且高效的无监督学习框架，用于情感分析，强调先进AI技术在分析公众情绪方面的重要社会影响，无需大量标记数据。&lt;h4&gt;总结&lt;/h4&gt;此研究为自然语言处理领域贡献了有效的情感分析方法，降低了对标记数据的依赖。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the large amount of data generated every day, public sentiment is a keyfactor for various fields, including marketing, politics, and social research.Understanding the public sentiment about different topics can provide valuableinsights. However, most traditional approaches for sentiment analysis oftendepend on supervised learning, which requires a significant amount of labeleddata. This makes it both expensive and time-consuming to implement. Thisproject introduces an approach using unsupervised learning techniques,particularly Affinity Propagation (AP) clustering, to analyze sentiment. APclustering groups text data based on natural patterns, without needingpredefined cluster numbers. The paper compares AP with K-means clustering,using TF-IDF Vectorization for text representation and Principal ComponentAnalysis (PCA) for dimensionality reduction. To enhance performance, AP iscombined with Agglomerative Hierarchical Clustering. This hybrid method refinesclusters further, capturing both global and local sentiment structures moreeffectively. The effectiveness of these methods is evaluated using theSilhouette Score, Calinski-Harabasz Score, and Davies-Bouldin Index. Resultsshow that AP with Agglomerative Hierarchical Clustering significantlyoutperforms K-means. This research contributes to Natural Language Processing(NLP) by proposing a scalable and efficient unsupervised learning framework forsentiment analysis, highlighting the significant societal impact of advanced AItechniques in analyzing public sentiment without the need for extensive labeleddata.</description>
      <author>example@mail.com (Mayimunah Nagayi, Clement Nyirenda)</author>
      <guid isPermaLink="false">2410.12862v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Scene Flow Estimation with Point-Voxel Fusion and Surface Representation</title>
      <link>http://arxiv.org/abs/2410.13355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper is under consideration at 2025 IEEE International
  Conference on Acoustics, Speech, and Signal Processing (ICASSP 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;场景流估计旨在生成连续两帧点云之间的3D运动场，广泛应用于多个领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服现有点基方法和体素基方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出一种点-体素融合方法，通过稀疏网格注意力和移动窗口策略捕捉长范围依赖，同时利用点分支捕捉细粒度特征。此外，通过伞形表面特征提取模块显式编码点云的局部表面信息。&lt;h4&gt;主要发现&lt;/h4&gt;在Flyingthings3D和KITTI数据集上进行实验，验证方法的有效性，结果显示本方法优于所有自监督方法，并与完全监督方法相比具有高度竞争力。&lt;h4&gt;结论&lt;/h4&gt;在所有评估指标上均有提升，特别是在KITTI数据集上，EPE分别减少了8.51%和10.52%。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的点-体素融合方法有效提升了场景流估计的性能，展示了良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scene flow estimation aims to generate the 3D motion field of points betweentwo consecutive frames of point clouds, which has wide applications in variousfields. Existing point-based methods ignore the irregularity of point cloudsand have difficulty capturing long-range dependencies due to the inefficiencyof point-level computation. Voxel-based methods suffer from the loss of detailinformation. In this paper, we propose a point-voxel fusion method, where weutilize a voxel branch based on sparse grid attention and the shifted windowstrategy to capture long-range dependencies and a point branch to capturefine-grained features to compensate for the information loss in the voxelbranch. In addition, since xyz coordinates are difficult to describe thegeometric structure of complex 3D objects in the scene, we explicitly encodethe local surface information of the point cloud through the umbrella surfacefeature extraction (USFE) module. We verify the effectiveness of our method byconducting experiments on the Flyingthings3D and KITTI datasets. Our methodoutperforms all other self-supervised methods and achieves highly competitiveresults compared to fully supervised methods. We achieve improvements in allmetrics, especially EPE, which is reduced by 8.51% and 10.52% on the KITTIo andKITTIs datasets, respectively.</description>
      <author>example@mail.com (Xuezhi Xiang, Xi Wang, Lei Zhang, Denis Ombati, Himaloy Himu, Xiantong Zhen)</author>
      <guid isPermaLink="false">2410.13355v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>pyhgf: A neural network library for predictive coding</title>
      <link>http://arxiv.org/abs/2410.09206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;贝叶斯认知模型在计算神经科学和精神病学中获得了广泛关注，预计其应用将迅速扩展至人工智能领域。&lt;h4&gt;目的&lt;/h4&gt;提供支持具身、适应性强且能效高的自主智能体的普遍推理框架。&lt;h4&gt;方法&lt;/h4&gt;介绍了	exttt{pyhgf}，一个基于JAX和Rust的Python包，用于创建、操作和采样动态网络以进行预测编码。&lt;h4&gt;主要发现&lt;/h4&gt;通过将网络组件封装为透明、模块化和可塑的变量，改善了其他框架的局限性，能够实现任意计算复杂度的信念传播。&lt;h4&gt;结论&lt;/h4&gt;核心变量的透明性可以转化为推理过程，利用自我组织原则，表达结构学习、元学习或因果发现，作为网络结构对意外输入适应的结果。&lt;h4&gt;总结&lt;/h4&gt;代码、教程和文档可在https://github.com/ilabcode/pyhgf获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ilabcode/pyhgf&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bayesian models of cognition have gained considerable traction incomputational neuroscience and psychiatry. Their scopes are now expected toexpand rapidly to artificial intelligence, providing general inferenceframeworks to support embodied, adaptable, and energy-efficient autonomousagents. A central theory in this domain is predictive coding, which posits thatlearning and behaviour are driven by hierarchical probabilistic inferencesabout the causes of sensory inputs. Biological realism constrains thesenetworks to rely on simple local computations in the form of precision-weightedpredictions and prediction errors. This can make this framework highlyefficient, but its implementation comes with unique challenges on the softwaredevelopment side. Embedding such models in standard neural network librariesoften becomes limiting, as these libraries' compilation and differentiationbackends can force a conceptual separation between optimization algorithms andthe systems being optimized. This critically departs from other biologicalprinciples such as self-monitoring, self-organisation, cellular growth andfunctional plasticity. In this paper, we introduce \texttt{pyhgf}: a Pythonpackage backed by JAX and Rust for creating, manipulating and sampling dynamicnetworks for predictive coding. We improve over other frameworks by enclosingthe network components as transparent, modular and malleable variables in themessage-passing steps. The resulting graphs can implement arbitrarycomputational complexities as beliefs propagation. But the transparency of corevariables can also translate into inference processes that leverageself-organisation principles, and express structure learning, meta-learning orcausal discovery as the consequence of network structural adaptation tosurprising inputs. The code, tutorials and documentation are hosted at:https://github.com/ilabcode/pyhgf.</description>
      <author>example@mail.com (Nicolas Legrand, Lilian Weber, Peter Thestrup Waade, Anna Hedvig Møller Daugaard, Mojtaba Khodadadi, Nace Mikuš, Chris Mathys)</author>
      <guid isPermaLink="false">2410.09206v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CVCP-Fusion: On Implicit Depth Estimation for 3D Bounding Box Prediction</title>
      <link>http://arxiv.org/abs/2410.11211v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:2205.02833 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;LiDAR和相机数据结合已成为3D物体检测的常见方法，但以点级别结合丢失了相机特征的语义信息。&lt;h4&gt;目的&lt;/h4&gt;提出Cross-View Center Point-Fusion模型，通过在BEV空间中结合相机和LiDAR特征，保留相机流的语义密度。&lt;h4&gt;方法&lt;/h4&gt;该架构结合了Cross-View Transformers和CenterPoint的特点，平行运行其骨干网络，实现高效的实时处理。&lt;h4&gt;主要发现&lt;/h4&gt;在2D地图视图表示中，隐式计算的深度估计可能足够准确，但在3D世界视图空间中，精确的边界框预测需要显式计算的几何和空间信息。&lt;h4&gt;结论&lt;/h4&gt;Cross-View Center Point-Fusion模型有效整合了相机与LiDAR数据，提升了3D物体检测的准确性和实时性。&lt;h4&gt;总结&lt;/h4&gt;本研究为3D物体检测提供了一种新方法，通过融合多种数据源，增强了检测精度和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/safetylab24/FusionCVCP&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Combining LiDAR and Camera-view data has become a common approach for 3DObject Detection. However, previous approaches combine the two input streams ata point-level, throwing away semantic information derived from camera features.In this paper we propose Cross-View Center Point-Fusion, a state-of-the-artmodel to perform 3D object detection by combining camera and LiDAR-derivedfeatures in the BEV space to preserve semantic density from the camera streamwhile incorporating spacial data from the LiDAR stream. Our architectureutilizes aspects from previously established algorithms, Cross-ViewTransformers and CenterPoint, and runs their backbones in parallel, allowingefficient computation for real-time processing and application. In this paperwe find that while an implicitly calculated depth-estimate may be sufficientlyaccurate in a 2D map-view representation, explicitly calculated geometric andspacial information is needed for precise bounding box prediction in the 3Dworld-view space.</description>
      <author>example@mail.com (Pranav Gupta, Rishabh Rengarajan, Viren Bankapur, Vedansh Mannem, Lakshit Ahuja, Surya Vijay, Kevin Wang)</author>
      <guid isPermaLink="false">2410.11211v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Railway LiDAR semantic segmentation based on intelligent semi-automated data annotation</title>
      <link>http://arxiv.org/abs/2410.13383v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This article has been accepted for publication in the IEEE VTC Fall
  2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动化车辆依赖于对环境的准确和稳健的感知，自动化列车同样需要环境感知。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于2DPass网络架构的点状3D语义分割方法，解决目前铁路环境缺乏公共数据集和相关方法的问题。&lt;h4&gt;方法&lt;/h4&gt;使用扫描和图像联合进行点状3D语义分割，采用半自动智能数据标注方法高效准确地标注德国铁路轨道上的数据。同时应用主动学习方法智能选择训练数据集的扫描数据。&lt;h4&gt;主要发现&lt;/h4&gt;完成了铁路数据的标注，包括来自铁路环境的相机和LiDAR数据，并通过图像分割网络转移标注原始LiDAR点云。&lt;h4&gt;结论&lt;/h4&gt;训练的3D LiDAR语义分割网络在9个类别上实现了良好的分割结果，平均IoU达71.48%。&lt;h4&gt;总结&lt;/h4&gt;本研究为自动化列车的环境感知提供了有效的方法和数据支持，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated vehicles rely on an accurate and robust perception of theenvironment. Similarly to automated cars, highly automated trains require anenvironmental perception. Although there is a lot of research based on eithercamera or LiDAR sensors in the automotive domain, very few contributions forthis task exist yet for automated trains. Additionally, no public dataset ordescribed approach for a 3D LiDAR semantic segmentation in the railwayenvironment exists yet. Thus, we propose an approach for a point-wise 3Dsemantic segmentation based on the 2DPass network architecture using scans andimages jointly. In addition, we present a semi-automated intelligent dataannotation approach, which we use to efficiently and accurately label therequired dataset recorded on a railway track in Germany. To improve performancedespite a still small number of labeled scans, we apply an active learningapproach to intelligently select scans for the training dataset. Ourcontributions are threefold: We annotate rail data including camera and LiDARdata from the railway environment, transfer label the raw LiDAR point cloudsusing an image segmentation network, and train a state-of-the-art 3D LiDARsemantic segmentation network efficiently leveraging active learning. Thetrained network achieves good segmentation results with a mean IoU of 71.48% of9 classes.</description>
      <author>example@mail.com (Florian Wulff, Bernd Schaeufele, Julian Pfeifer, Ilja Radusch)</author>
      <guid isPermaLink="false">2410.13383v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning for Hybrid Precoding in Millimeter Wave MIMO System</title>
      <link>http://arxiv.org/abs/2410.09427v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5pages, 6figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;混合模拟/数字架构通过相位移器将有限数量的射频链路连接到多个天线，有效解决了大规模多输入多输出（MIMO）系统中的能耗问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决混合预编码中模拟和数字预编码器耦合及恒模约束的有效方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种即插即用、无需预训练的解决方案，利用梯度引导的元学习（GGML）框架，通过混合预编码最大化MIMO系统的谱效率。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在系统参数变化时表现出强大的鲁棒性，且在相同天线数量下，其性能甚至超过了全数字加权最小均方误差（WMMSE）预编码。&lt;h4&gt;结论&lt;/h4&gt;该方法优于现有方法，显示出更高的性能和可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本研究为大规模MIMO系统的混合预编码提供了一种新的高效解决方案，具有良好的性能和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The hybrid analog/digital architecture that connects a limited number of RFchains to multiple antennas through phase shifters could effectively addressthe energy consumption issues in massive multiple-input multiple-output (MIMO)systems. However, the main challenges in hybrid precoding lie in the couplingbetween analog and digital precoders and the constant modulus constraint.Generally, traditional optimization algorithms for this problem typicallysuffer from high computational complexity or suboptimal performance, while deeplearning based solutions exhibit poor scalability and robustness. This paperproposes a plug and play, free of pre-training solution that leverages gradientguided meta learning (GGML) framework to maximize the spectral efficiency ofMIMO systems through hybrid precoding. Specifically, GGML utilizes gradientinformation as network input to facilitate the sharing of gradient informationflow. We retain the iterative process of traditional algorithms and leveragemeta learning to alternately optimize the precoder. Simulation results showthat this method outperforms existing methods, demonstrates robustness tovariations in system parameters, and can even exceed the performance of fullydigital weighted minimum mean square error (WMMSE) precoding with the samenumber of antennas.</description>
      <author>example@mail.com (Yifan Guo)</author>
      <guid isPermaLink="false">2410.09427v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>TEOcc: Radar-camera Multi-modal Occupancy Prediction via Temporal Enhancement</title>
      <link>http://arxiv.org/abs/2410.11228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ECAI2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;语义占用作为一种新颖的3D场景表示方法，在自动驾驶中受到广泛关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种雷达-相机多模态时序增强占用预测网络TEOcc。&lt;h4&gt;方法&lt;/h4&gt;引入时序增强分支，分别使用长短期解码器学习时序占用预测，并设计3D卷积层以降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;TEOcc在nuScenes基准测试中实现了最先进的占用预测效果。&lt;h4&gt;结论&lt;/h4&gt;时序增强分支可以作为插件模块，轻松集成到现有占用预测方法中以提升性能。&lt;h4&gt;代码与模型&lt;/h4&gt;代码与模型将发布在https://github.com/VDIGPKU/TEOcc。&lt;h4&gt;总结&lt;/h4&gt;本研究充分利用时序信息，提出的TEOcc网络在占用预测领域具有显著优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vdigpku/teocc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As a novel 3D scene representation, semantic occupancy has gained muchattention in autonomous driving. However, existing occupancy prediction methodsmainly focus on designing better occupancy representations, such astri-perspective view or neural radiance fields, while ignoring the advantagesof using long-temporal information. In this paper, we propose a radar-cameramulti-modal temporal enhanced occupancy prediction network, dubbed TEOcc. Ourmethod is inspired by the success of utilizing temporal information in 3Dobject detection. Specifically, we introduce a temporal enhancement branch tolearn temporal occupancy prediction. In this branch, we randomly discard thet-k input frame of the multi-view camera and predict its 3D occupancy bylong-term and short-term temporal decoders separately with the information fromother adjacent frames and multi-modal inputs. Besides, to reduce computationalcosts and incorporate multi-modal inputs, we specially designed 3Dconvolutional layers for long-term and short-term temporal decoders.Furthermore, since the lightweight occupancy prediction head is a denseclassification head, we propose to use a shared occupancy prediction head forthe temporal enhancement and main branches. It is worth noting that thetemporal enhancement branch is only performed during training and is discardedduring inference. Experiment results demonstrate that TEOcc achievesstate-of-the-art occupancy prediction on nuScenes benchmarks. In addition, theproposed temporal enhancement branch is a plug-and-play module that can beeasily integrated into existing occupancy prediction methods to improve theperformance of occupancy prediction. The code and models will be released athttps://github.com/VDIGPKU/TEOcc.</description>
      <author>example@mail.com (Zhiwei Lin, Hongbo Jin, Yongtao Wang, Yufei Wei, Nan Dong)</author>
      <guid isPermaLink="false">2410.11228v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Generative Adversarial Synthesis of Radar Point Cloud Scenes</title>
      <link>http://arxiv.org/abs/2410.13526v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICMIM 2024; 7th IEEE MTT Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;汽车雷达的验证和确认需要真实交通场景的数据集，这些数据集的获取非常繁琐。&lt;h4&gt;目的&lt;/h4&gt;提出一种使用GAN生成雷达场景合成的方法，替代真实数据集的获取和基于仿真的方法。&lt;h4&gt;方法&lt;/h4&gt;训练一个基于PointNet++的GAN模型生成逼真的雷达点云场景，并使用二分类器评估生成场景与真实场景的性能。&lt;h4&gt;主要发现&lt;/h4&gt;我们的GAN模型在生成场景的性能上达到了与真实场景测试集相似的表现（约87%）。&lt;h4&gt;结论&lt;/h4&gt;使用GAN生成的雷达场景可以有效替代真实场景数据集，且性能相近。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了GAN在汽车雷达场景合成中的潜力，为数据获取提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For the validation and verification of automotive radars, datasets ofrealistic traffic scenarios are required, which, how ever, are laborious toacquire. In this paper, we introduce radar scene synthesis using GANs as analternative to the real dataset acquisition and simulation-based approaches. Wetrain a PointNet++ based GAN model to generate realistic radar point cloudscenes and use a binary classifier to evaluate the performance of scenesgenerated using this model against a test set of real scenes. We demonstratethat our GAN model achieves similar performance (~87%) to the real scenes testset.</description>
      <author>example@mail.com (Muhammad Saad Nawaz, Thomas Dallmann, Torsten Schoen, Dirk Heberling)</author>
      <guid isPermaLink="false">2410.13526v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Steering Your Generalists: Improving Robotic Foundation Models via Value Guidance</title>
      <link>http://arxiv.org/abs/2410.13816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Conference on Robot Learning (CoRL) 2024. Project Page:
  https://nakamotoo.github.io/V-GPS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型通用机器人策略在多样化的演示数据集上训练，能够有效控制多种机器人并获得广泛的操作技能。&lt;h4&gt;目的&lt;/h4&gt;提出一种普遍适用的方法，通过重排名机器人策略的动作以提高其在部署时的性能。&lt;h4&gt;方法&lt;/h4&gt;采用名为价值引导策略引导（V-GPS）的方法，根据离线强化学习学习的价值函数重新排名动作，无需微调策略权重。&lt;h4&gt;主要发现&lt;/h4&gt;相同的价值函数能够提升五种不同架构的最先进策略的性能，尽管它们是在不同数据集上训练的，在多个机器人平台上的12项任务中实现了一致的性能提升。&lt;h4&gt;结论&lt;/h4&gt;V-GPS方法兼容多种通用策略，能够在不修改原有策略的情况下显著提高机器人性能。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了如何利用价值函数改善机器人策略的有效性，为未来的机器人控制提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large, general-purpose robotic policies trained on diverse demonstrationdatasets have been shown to be remarkably effective both for controlling avariety of robots in a range of different scenes, and for acquiring broadrepertoires of manipulation skills. However, the data that such policies aretrained on is generally of mixed quality -- not only are human-collecteddemonstrations unlikely to perform the task perfectly, but the larger thedataset is, the harder it is to curate only the highest quality examples. Italso remains unclear how optimal data from one embodiment is for training onanother embodiment. In this paper, we present a general and broadly applicableapproach that enhances the performance of such generalist robot policies atdeployment time by re-ranking their actions according to a value functionlearned via offline RL. This approach, which we call Value-Guided PolicySteering (V-GPS), is compatible with a wide range of different generalistpolicies, without needing to fine-tune or even access the weights of thepolicy. We show that the same value function can improve the performance offive different state-of-the-art policies with different architectures, eventhough they were trained on distinct datasets, attaining consistent performanceimprovement on multiple robotic platforms across a total of 12 tasks. Code andvideos can be found at: https://nakamotoo.github.io/V-GPS</description>
      <author>example@mail.com (Mitsuhiko Nakamoto, Oier Mees, Aviral Kumar, Sergey Levine)</author>
      <guid isPermaLink="false">2410.13816v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Representation Learning of Structured Data for Medical Foundation Models</title>
      <link>http://arxiv.org/abs/2410.13351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Workshop on Unifying Representations in Neural Models
  (UniReps 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在多个领域表现出色，包括医疗保健，但在有效处理结构化非文本数据（如ICD-10或SNOMED-CT医疗代码）方面能力有限。&lt;h4&gt;目的&lt;/h4&gt;探讨LLMs在处理医疗代码时面临的挑战，并提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;引入UniStruct架构，设计一个结合非结构化文本和结构化数据的多模态医疗基础模型，采用专门针对结构化医疗代码的子词分词技术。&lt;h4&gt;主要发现&lt;/h4&gt;在内部医疗数据库上经过预训练后，该模型在评估指标上提高了最多23%，其中约2%的提升归因于提出的分词方法；在EHRSHOT公共基准测试中，UniStruct模型在超过42%的下游任务中表现改善。&lt;h4&gt;结论&lt;/h4&gt;该方法增强了以患者为中心模型的表示和泛化能力，填补了表示学习模型在处理复杂结构化医疗数据与非结构化文本之间的关键空白。&lt;h4&gt;总结&lt;/h4&gt;UniStruct架构有效解决了LLMs在医疗领域处理结构化数据的不足，为未来的医疗记录处理提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have demonstrated remarkable performance acrossvarious domains, including healthcare. However, their ability to effectivelyrepresent structured non-textual data, such as the alphanumeric medical codesused in records like ICD-10 or SNOMED-CT, is limited and has been particularlyexposed in recent research. This paper examines the challenges LLMs face inprocessing medical codes due to the shortcomings of current tokenizationmethods. As a result, we introduce the UniStruct architecture to design amultimodal medical foundation model of unstructured text and structured data,which addresses these challenges by adapting subword tokenization techniquesspecifically for the structured medical codes. Our approach is validatedthrough model pre-training on both an extensive internal medical database and apublic repository of structured medical records. Trained on over 1 billiontokens on the internal medical database, the proposed model achieves up to a23% improvement in evaluation metrics, with around 2% gain attributed to ourproposed tokenization. Additionally, when evaluated on the EHRSHOT publicbenchmark with a 1/1000 fraction of the pre-training data, the UniStruct modelimproves performance on over 42% of the downstream tasks. Our approach not onlyenhances the representation and generalization capabilities of patient-centricmodels but also bridges a critical gap in representation learning models'ability to handle complex structured medical data, alongside unstructured text.</description>
      <author>example@mail.com (Vijay Prakash Dwivedi, Viktor Schlegel, Andy T. Liu, Thanh-Tung Nguyen, Abhinav Ramesh Kashyap, Jeng Wei, Wei-Hsian Yin, Stefan Winkler, Robby T. Tan)</author>
      <guid isPermaLink="false">2410.13351v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning</title>
      <link>http://arxiv.org/abs/2410.13761v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;PAC-Bayes学习为研究学习算法的泛化能力提供了综合框架，并通过优化泛化界限来推导新的学习算法。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的迭代学习算法构建策略，以优化一系列替代训练目标，从而提高计算效率。&lt;h4&gt;方法&lt;/h4&gt;通过将泛化界限中的经验风险替换为可构建的低维函数空间的投影，来实现更高效的查询。&lt;h4&gt;主要发现&lt;/h4&gt;迭代优化替代目标可以导致原始泛化界限的优化，并在元学习框架中引入了一个元目标，提供了元梯度的闭式表达。&lt;h4&gt;结论&lt;/h4&gt;该方法在工业生化问题的数值实验中得到了验证，展示了其有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的PAC-Bayes学习方法，通过优化替代目标，提高了学习算法的效率和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ins1stenc3/gder&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training high-quality deep models necessitates vast amounts of data,resulting in overwhelming computational and memory demands. Recently, datapruning, distillation, and coreset selection have been developed to streamlinedata volume by retaining, synthesizing, or selecting a small yet informativesubset from the full set. Among these methods, data pruning incurs the leastadditional training cost and offers the most practical acceleration benefits.However, it is the most vulnerable, often suffering significant performancedegradation with imbalanced or biased data schema, thus raising concerns aboutits accuracy and reliability in on-device deployment. Therefore, there is alooming need for a new data pruning paradigm that maintains the efficiency ofprevious practices while ensuring balance and robustness. Unlike the fields ofcomputer vision and natural language processing, where mature solutions havebeen developed to address these issues, graph neural networks (GNNs) continueto struggle with increasingly large-scale, imbalanced, and noisy datasets,lacking a unified dataset pruning solution. To achieve this, we introduce anovel dynamic soft-pruning method, GDeR, designed to update the training``basket'' during the process using trainable prototypes. GDeR first constructsa well-modeled graph embedding hypersphere and then samples\textit{representative, balanced, and unbiased subsets} from this embeddingspace, which achieves the goal we called Graph Training Debugging. Extensiveexperiments on five datasets across three GNN backbones, demonstrate that GDeR(I) achieves or surpasses the performance of the full dataset with 30%~50%fewer training samples, (II) attains up to a 2.81x lossless training speedup,and (III) outperforms state-of-the-art pruning methods in imbalanced trainingand noisy training scenarios by 0.3%~4.3% and 3.6%~7.8%, respectively.</description>
      <author>example@mail.com (Guibin Zhang, Haonan Dong, Yuchen Zhang, Zhixun Li, Dingshuo Chen, Kai Wang, Tianlong Chen, Yuxuan Liang, Dawei Cheng, Kun Wang)</author>
      <guid isPermaLink="false">2410.13761v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Learning via Surrogate PAC-Bayes</title>
      <link>http://arxiv.org/abs/2410.10230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;PAC-Bayes学习为研究学习算法的泛化能力提供了综合框架，并通过优化泛化界限来推导新的学习算法。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的迭代学习算法构建策略，以优化一系列替代训练目标，从而提高计算效率。&lt;h4&gt;方法&lt;/h4&gt;通过将泛化界限中的经验风险替换为可构建的低维函数空间的投影，来实现更高效的查询。&lt;h4&gt;主要发现&lt;/h4&gt;迭代优化替代目标可以导致原始泛化界限的优化，并在元学习框架中引入了一个元目标，提供了元梯度的闭式表达。&lt;h4&gt;结论&lt;/h4&gt;该方法在工业生化问题的数值实验中得到了验证，展示了其有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的PAC-Bayes学习方法，通过优化替代目标，提高了学习算法的效率和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; PAC-Bayes learning is a comprehensive setting for (i) studying thegeneralisation ability of learning algorithms and (ii) deriving new learningalgorithms by optimising a generalisation bound. However, optimisinggeneralisation bounds might not always be viable for tractable or computationalreasons, or both. For example, iteratively querying the empirical risk mightprove computationally expensive. In response, we introduce a novel principledstrategy for building an iterative learning algorithm via the optimisation of asequence of surrogate training objectives, inherited from PAC-Bayesgeneralisation bounds. The key argument is to replace the empirical risk (seenas a function of hypotheses) in the generalisation bound by its projection ontoa constructible low dimensional functional space: these projections can bequeried much more efficiently than the initial risk. On top of providing thatgeneric recipe for learning via surrogate PAC-Bayes bounds, we (i) contributetheoretical results establishing that iteratively optimising our surrogatesimplies the optimisation of the original generalisation bounds, (ii)instantiate this strategy to the framework of meta-learning, introducing ameta-objective offering a closed form expression for meta-gradient, (iii)illustrate our approach with numerical experiments inspired by an industrialbiochemical problem.</description>
      <author>example@mail.com (Antoine Picard-Weibel, Roman Moscoviz, Benjamin Guedj)</author>
      <guid isPermaLink="false">2410.10230v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CLaMP 2: Multimodal Music Information Retrieval Across 101 Languages Using Large Language Models</title>
      <link>http://arxiv.org/abs/2410.13267v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 10 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的音乐信息检索系统面临语言多样性管理和多种音乐模式整合的挑战，这些限制降低了其在全球多模态音乐环境中的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出CLaMP 2系统，以支持101种语言，并兼容ABC记谱法和MIDI，用于音乐信息检索。&lt;h4&gt;方法&lt;/h4&gt;CLaMP 2在150万个ABC-MIDI文本三元组上进行了预训练，包含多语言文本编码器和通过对比学习对齐的多模态音乐编码器。&lt;h4&gt;主要发现&lt;/h4&gt;CLaMP 2在多语言语义搜索和跨模态音乐分类中取得了业界领先的结果。&lt;h4&gt;结论&lt;/h4&gt;CLaMP 2为包容性和全球音乐信息检索建立了新的标准，显著减少了文本噪声，平衡了语言分布。&lt;h4&gt;总结&lt;/h4&gt;CLaMP 2系统通过先进的技术解决了音乐信息检索中的多语言和多模态问题，提升了系统的整体效能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/sanderwood/clamp2&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Challenges in managing linguistic diversity and integrating various musicalmodalities are faced by current music information retrieval systems. Theselimitations reduce their effectiveness in a global, multimodal musicenvironment. To address these issues, we introduce CLaMP 2, a system compatiblewith 101 languages that supports both ABC notation (a text-based musicalnotation format) and MIDI (Musical Instrument Digital Interface) for musicinformation retrieval. CLaMP 2, pre-trained on 1.5 million ABC-MIDI-texttriplets, includes a multilingual text encoder and a multimodal music encoderaligned via contrastive learning. By leveraging large language models, weobtain refined and consistent multilingual descriptions at scale, significantlyreducing textual noise and balancing language distribution. Our experimentsshow that CLaMP 2 achieves state-of-the-art results in both multilingualsemantic search and music classification across modalities, thus establishing anew standard for inclusive and global music information retrieval.</description>
      <author>example@mail.com (Shangda Wu, Yashan Wang, Ruibin Yuan, Zhancheng Guo, Xu Tan, Ge Zhang, Monan Zhou, Jing Chen, Xuefeng Mu, Yuejie Gao, Yuanliang Dong, Jiafeng Liu, Xiaobing Li, Feng Yu, Maosong Sun)</author>
      <guid isPermaLink="false">2410.13267v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SAM-Guided Masked Token Prediction for 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2410.12158v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型显著提升了2D任务的表现，Bridge3D等近期工作成功应用这些模型改善3D场景理解。&lt;h4&gt;目的&lt;/h4&gt;解决2D到3D知识蒸馏中的2D与3D表现不一致和3D数据集中的长尾分布问题。&lt;h4&gt;方法&lt;/h4&gt;引入一种新的SAM引导的标记化方法，替代传统的KNN标记化技术；实施群体平衡的重加权策略以应对长尾问题；框架采用两阶段的掩蔽标记预测过程，学生模型同时预测全局嵌入和局部嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;在SUN RGB-D、ScanNet和S3DIS等多个数据集上进行验证，结果显示在3D目标检测和语义分割任务上显著提升。&lt;h4&gt;结论&lt;/h4&gt;该方法在自监督学习领域建立了新的基准，超越了当前最先进的方法。&lt;h4&gt;总结&lt;/h4&gt;通过创新的标记化方法和重加权策略，显著提高了3D场景理解的性能，推动了相关研究的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have significantly enhanced 2D task performance, and recentworks like Bridge3D have successfully applied these models to improve 3D sceneunderstanding through knowledge distillation, marking considerableadvancements. Nonetheless, challenges such as the misalignment between 2D and3D representations and the persistent long-tail distribution in 3D datasetsstill restrict the effectiveness of knowledge distillation from 2D to 3D usingfoundation models. To tackle these issues, we introduce a novel SAM-guidedtokenization method that seamlessly aligns 3D transformer structures withregion-level knowledge distillation, replacing the traditional KNN-basedtokenization techniques. Additionally, we implement a group-balancedre-weighting strategy to effectively address the long-tail problem in knowledgedistillation. Furthermore, inspired by the recent success of masked featureprediction, our framework incorporates a two-stage masked token predictionprocess in which the student model predicts both the global embeddings and thetoken-wise local embeddings derived from the teacher models trained in thefirst stage. Our methodology has been validated across multiple datasets,including SUN RGB-D, ScanNet, and S3DIS, for tasks like 3D object detection andsemantic segmentation. The results demonstrate significant improvements overcurrent State-of-the-art self-supervised methods, establishing new benchmarksin this field.</description>
      <author>example@mail.com (Zhimin Chen, Liang Yang, Yingwei Li, Longlong Jing, Bing Li)</author>
      <guid isPermaLink="false">2410.12158v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>iFuzzyTL: Interpretable Fuzzy Transfer Learning for SSVEP BCI System</title>
      <link>http://arxiv.org/abs/2410.12267v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预训练的强大视觉或多模态基础模型（如CLIP）依赖于大规模数据集，这些数据集可能存在噪声、潜在的错位以及长尾分布。&lt;h4&gt;目的&lt;/h4&gt;设计一个可控的图像-文本合成管道CtrlSynth，以实现数据高效和强健的多模态学习。&lt;h4&gt;方法&lt;/h4&gt;通过将图像的视觉语义分解为基本元素，应用用户指定的控制策略（如删除、添加或替换操作），然后重新组合这些元素以合成图像或文本。&lt;h4&gt;主要发现&lt;/h4&gt;CtrlSynth允许用户通过定义自定义控制策略，以细粒度的方式控制数据合成，进而自然且多样化地生成合成样本。&lt;h4&gt;结论&lt;/h4&gt;在31个涵盖不同视觉和视觉-语言任务的数据集上的广泛实验表明，CtrlSynth显著改善了CLIP模型的零-shot分类、图像-文本检索和组合推理性能。&lt;h4&gt;总结&lt;/h4&gt;CtrlSynth是一个闭环、无训练和模块化的框架，易于支持不同的预训练模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid evolution of Brain-Computer Interfaces (BCIs) has significantlyinfluenced the domain of human-computer interaction, with Steady-State VisualEvoked Potentials (SSVEP) emerging as a notably robust paradigm. This studyexplores advanced classification techniques leveraging interpretable fuzzytransfer learning (iFuzzyTL) to enhance the adaptability and performance ofSSVEP-based systems. Recent efforts have strengthened to reduce calibrationrequirements through innovative transfer learning approaches, which refinecross-subject generalizability and minimize calibration through strategicapplication of domain adaptation and few-shot learning strategies. Pioneeringdevelopments in deep learning also offer promising enhancements, facilitatingrobust domain adaptation and significantly improving system responsiveness andaccuracy in SSVEP classification. However, these methods often require complextuning and extensive data, limiting immediate applicability. iFuzzyTLintroduces an adaptive framework that combines fuzzy logic principles withneural network architectures, focusing on efficient knowledge transfer anddomain adaptation. iFuzzyTL refines input signal processing and classificationin a human-interpretable format by integrating fuzzy inference systems andattention mechanisms. This approach bolsters the model's precision and alignswith real-world operational demands by effectively managing the inherentvariability and uncertainty of EEG data. The model's efficacy is demonstratedacross three datasets: 12JFPM (89.70% accuracy for 1s with an informationtransfer rate (ITR) of 149.58), Benchmark (85.81% accuracy for 1s with an ITRof 213.99), and eldBETA (76.50% accuracy for 1s with an ITR of 94.63),achieving state-of-the-art results and setting new benchmarks for SSVEP BCIperformance.</description>
      <author>example@mail.com (Xiaowei Jiang, Beining Cao, Liang Ou, Yu-Cheng Chang, Thomas Do, Chin-Teng Lin)</author>
      <guid isPermaLink="false">2410.12267v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning</title>
      <link>http://arxiv.org/abs/2410.11963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着模型能力的提升，评估变得更加复杂，需要在一个基准测试中同时测试多个技能。&lt;h4&gt;目的&lt;/h4&gt;提出一种自动化的方法，通过分析模型生成的推理，恢复与评估实例相关的底层技能。&lt;h4&gt;方法&lt;/h4&gt;验证推理解析的技能相关性，并在12个基准上对46000个实例推断技能。&lt;h4&gt;主要发现&lt;/h4&gt;发现多个技能在不同基准上是普遍存在的，从而整理出数百个技能片段（即测试共同技能的实例集）。&lt;h4&gt;结论&lt;/h4&gt;通过技能片段分析得到的见解可以推广到未见过的实例，实现了3%的准确率提升，并开启了模型评估的新途径。&lt;h4&gt;总结&lt;/h4&gt;研究通过技能特定分析，提供了对模型能力更细致和可操作的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretraining robust vision or multimodal foundation models (e.g., CLIP) relieson large-scale datasets that may be noisy, potentially misaligned, and havelong-tail distributions. Previous works have shown promising results inaugmenting datasets by generating synthetic samples. However, they only supportdomain-specific ad hoc use cases (e.g., either image or text only, but notboth), and are limited in data diversity due to a lack of fine-grained controlover the synthesis process. In this paper, we design a \emph{controllable}image-text synthesis pipeline, CtrlSynth, for data-efficient and robustmultimodal learning. The key idea is to decompose the visual semantics of animage into basic elements, apply user-specified control policies (e.g., remove,add, or replace operations), and recompose them to synthesize images or texts.The decompose and recompose feature in CtrlSynth allows users to control datasynthesis in a fine-grained manner by defining customized control policies tomanipulate the basic elements. CtrlSynth leverages the capabilities ofpretrained foundation models such as large language models or diffusion modelsto reason and recompose basic elements such that synthetic samples are naturaland composed in diverse ways. CtrlSynth is a closed-loop, training-free, andmodular framework, making it easy to support different pretrained models. Withextensive experiments on 31 datasets spanning different vision andvision-language tasks, we show that CtrlSynth substantially improves zero-shotclassification, image-text retrieval, and compositional reasoning performanceof CLIP models.</description>
      <author>example@mail.com (Qingqing Cao, Mahyar Najibi, Sachin Mehta)</author>
      <guid isPermaLink="false">2410.11963v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models</title>
      <link>http://arxiv.org/abs/2410.13826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code at: github.com/microsoft/skill-slice-insights&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模通用领域预训练后进行特定下游任务微调已成为机器学习的主要范式，但预训练与目标领域之间的差异可能导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;强调任务自适应继续预训练（TAP）的必要性，以提高模型在特定任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;提出TapWeight框架，自动确定各预训练目标的重要性，通过多层次优化问题进行重新加权。&lt;h4&gt;主要发现&lt;/h4&gt;在分子属性预测和自然语言理解任务中，TapWeight显著超越了基线方法。&lt;h4&gt;结论&lt;/h4&gt;实验结果验证了TapWeight的有效性和通用性。&lt;h4&gt;总结&lt;/h4&gt;TapWeight通过自动优化预训练目标的重要性，提升了模型在特定任务上的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With models getting stronger, evaluations have grown more complex, testingmultiple skills in one benchmark and even in the same instance at once.However, skill-wise performance is obscured when inspecting aggregate accuracy,under-utilizing the rich signal modern benchmarks contain. We propose anautomatic approach to recover the underlying skills relevant for any evaluationinstance, by way of inspecting model-generated rationales. After validating therelevance of rationale-parsed skills and inferring skills for $46$k instancesover $12$ benchmarks, we observe many skills to be common across benchmarks,resulting in the curation of hundreds of skill-slices (i.e. sets of instancestesting a common skill). Inspecting accuracy over these slices yields novelinsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,on average, Gemini 1.5 Pro is $18\%$ more accurate in "computing molar mass",but $19\%$ less accurate in "applying constitutional law", despite the overallaccuracies of the three models differing by a mere $0.4\%$. Furthermore, wedemonstrate the practical utility of our approach by showing that insightsderived from skill slice analysis can generalize to held-out instances: whenrouting each instance to the model strongest on the relevant skills, we see a$3\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices andframework open a new avenue in model evaluation, leveraging skill-specificanalyses to unlock a more granular and actionable understanding of modelcapabilities.</description>
      <author>example@mail.com (Mazda Moayeri, Vidhisha Balachandran, Varun Chandrasekaran, Safoora Yousefi, Thomas Fel, Soheil Feizi, Besmira Nushi, Neel Joshi, Vibhav Vineet)</author>
      <guid isPermaLink="false">2410.13826v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>TapWeight: Reweighting Pretraining Objectives for Task-Adaptive Pretraining</title>
      <link>http://arxiv.org/abs/2410.10006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模通用领域预训练后进行特定下游任务微调已成为机器学习的主要范式，但预训练与目标领域之间的差异可能导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;强调任务自适应继续预训练（TAP）的必要性，以提高模型在特定任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;提出TapWeight框架，自动确定各预训练目标的重要性，通过多层次优化问题进行重新加权。&lt;h4&gt;主要发现&lt;/h4&gt;在分子属性预测和自然语言理解任务中，TapWeight显著超越了基线方法。&lt;h4&gt;结论&lt;/h4&gt;实验结果验证了TapWeight的有效性和通用性。&lt;h4&gt;总结&lt;/h4&gt;TapWeight通过自动优化预训练目标的重要性，提升了模型在特定任务上的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale general domain pretraining followed by downstream-specificfinetuning has become a predominant paradigm in machine learning. However,discrepancies between the pretraining and target domains can still lead toperformance degradation in certain cases, underscoring the need fortask-adaptive continued pretraining (TAP). TAP methods typically involvecontinued pretraining on task-specific unlabeled datasets or introducingadditional unsupervised learning objectives to enhance model capabilities.While many TAP methods perform continued pretraining with multiple pretrainingobjectives, they often determine the tradeoff parameters between objectivesmanually, resulting in suboptimal outcomes and higher computational costs. Inthis paper, we propose TapWeight, a task-adaptive pretraining framework whichautomatically determines the optimal importance of each pretraining objectivebased on downstream feedback. TapWeight reweights each pretraining objective bysolving a multi-level optimization problem. We applied TapWeight to bothmolecular property prediction and natural language understanding tasks,significantly surpassing baseline methods. Experimental results validate theeffectiveness and generalizability of TapWeight.</description>
      <author>example@mail.com (Ruiyi Zhang, Sai Ashish Somayajula, Pengtao Xie)</author>
      <guid isPermaLink="false">2410.10006v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>A Stochastic Approach to Bi-Level Optimization for Hyperparameter Optimization and Meta Learning</title>
      <link>http://arxiv.org/abs/2410.10417v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代深度学习中普遍存在的一般可微元学习问题，包括超参数优化、损失函数学习、少样本学习和不变性学习等，通常被形式化为双层优化（BLO）。&lt;h4&gt;目的&lt;/h4&gt;提出一种新视角，将给定的BLO问题转化为随机优化问题。&lt;h4&gt;方法&lt;/h4&gt;将内损失函数视为平滑的概率分布，外损失则为内分布的期望损失。采用随机梯度Langevin动力学（SGLD）MCMC来采样内部分布，并提出递归算法计算MC估计的超梯度。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在处理大模型时采用新的一阶近似，无需存储庞大的雅可比矩阵，能够考虑不确定性，使方法对次优内优化或由于过参数化导致的非唯一内最小值具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;与现有方法相比，本方法在实践中表现出更可靠的解决方案，能够有效应对不稳定行为和超参数敏感性，并在各种元学习问题上取得了良好结果，能够轻松扩展到学习8700万超参数的视觉变换器。&lt;h4&gt;总结&lt;/h4&gt;提出的随机优化方法在元学习中具有重要的应用潜力，尤其在处理复杂模型和大规模超参数时表现优异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We tackle the general differentiable meta learning problem that is ubiquitousin modern deep learning, including hyperparameter optimization, loss functionlearning, few-shot learning, invariance learning and more. These problems areoften formalized as Bi-Level optimizations (BLO). We introduce a novelperspective by turning a given BLO problem into a stochastic optimization,where the inner loss function becomes a smooth probability distribution, andthe outer loss becomes an expected loss over the inner distribution. To solvethis stochastic optimization, we adopt Stochastic Gradient Langevin Dynamics(SGLD) MCMC to sample inner distribution, and propose a recurrent algorithm tocompute the MC-estimated hypergradient. Our derivation is similar toforward-mode differentiation, but we introduce a new first-order approximationthat makes it feasible for large models without needing to store huge Jacobianmatrices. The main benefits are two-fold: i) Our stochastic formulation takesinto account uncertainty, which makes the method robust to suboptimal inneroptimization or non-unique multiple inner minima due to overparametrization;ii) Compared to existing methods that often exhibit unstable behavior andhyperparameter sensitivity in practice, our method leads to considerably morereliable solutions. We demonstrate that the new approach achieves promisingresults on diverse meta learning problems and easily scales to learning 87Mhyperparameters in the case of Vision Transformers.</description>
      <author>example@mail.com (Minyoung Kim, Timothy M. Hospedales)</author>
      <guid isPermaLink="false">2410.10417v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>LiPO: LiDAR Inertial Odometry for ICP Comparison</title>
      <link>http://arxiv.org/abs/2410.08097v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;引入了一种名为LiPO的LiDAR惯性里程计框架，用于直接比较不同的迭代最近点（ICP）点云配准方法。&lt;h4&gt;目的&lt;/h4&gt;量化P2P-ICP和P2F-ICP之间的权衡，以帮助决定何时使用每种方法。&lt;h4&gt;方法&lt;/h4&gt;使用LiPO框架直接比较ICP方法，并在相关基准数据集及自定义无人地面车辆（UGV）上进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;P2F-ICP在激烈运动和复杂环境中相比于P2P-ICP有较少的漂移和更高的映射精度，但P2F-ICP需要更多手动调整的超参数。&lt;h4&gt;结论&lt;/h4&gt;在真实的机器人应用中，尽管P2P-ICP漂移较大，但由于其在不同环境和运动中的一致性，可能更受欢迎。&lt;h4&gt;总结&lt;/h4&gt;P2F-ICP虽有优势，但在实际应用中P2P-ICP的普遍适用性使其更具吸引力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a LiDAR inertial odometry (LIO) framework, called LiPO, thatenables direct comparisons of different iterative closest point (ICP) pointcloud registration methods. The two common ICP methods we compare arepoint-to-point (P2P) and point-to-feature (P2F). In our experience, within thecontext of LIO, P2F-ICP results in less drift and improved mapping accuracywhen robots move aggressively through challenging environments when compared toP2P-ICP. However, P2F-ICP methods require more hand-tuned hyper-parameters thatmake P2F-ICP less general across all environments and motions. In real-worldfield robotics applications where robots are used across differentenvironments, more general P2P-ICP methods may be preferred despite increaseddrift. In this paper, we seek to better quantify the trade-off between P2P-ICPand P2F-ICP to help inform when each method should be used. To explore thistrade-off, we use LiPO to directly compare ICP methods and test on relevantbenchmark datasets as well as on our custom unpiloted ground vehicle (UGV). Wefind that overall, P2F-ICP has reduced drift and improved mapping accuracy,but, P2P-ICP is more consistent across all environments and motions withminimal drift increase.</description>
      <author>example@mail.com (Darwin Mick, Taylor Pool, Madankumar Sathenahally Nagaraju, Michael Kaess, Howie Choset, Matt Travers)</author>
      <guid isPermaLink="false">2410.08097v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Tracking Universal Features Through Fine-Tuning and Model Merging</title>
      <link>http://arxiv.org/abs/2410.12391v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究特征在不同文本领域的模型中如何出现、消失和持续。&lt;h4&gt;目的&lt;/h4&gt;提供对小规模模型和稀疏自编码器在典型迁移学习场景中的特征稳定性和转变的深入理解。&lt;h4&gt;方法&lt;/h4&gt;从一个基于BabyLM语料库和Python代码集合的单层Transformer语言模型开始，适应TinyStories和Lua编程语言两个新领域，并通过球面线性插值合并这两个模型。&lt;h4&gt;主要发现&lt;/h4&gt;特征的稳定性和转变在不同领域的模型中表现出不同的特征。&lt;h4&gt;结论&lt;/h4&gt;迁移学习场景中，小规模模型的特征表现出复杂的动态变化。&lt;h4&gt;总结&lt;/h4&gt;本研究深入探讨了特征在不同文本领域模型中的演变，揭示了特征在迁移学习中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study how features emerge, disappear, and persist across models fine-tunedon different domains of text. More specifically, we start from a base one-layerTransformer language model that is trained on a combination of the BabyLMcorpus, and a collection of Python code from The Stack. This base model isadapted to two new domains of text: TinyStories, and the Lua programminglanguage, respectively; and then these two models are merged using these twomodels using spherical linear interpolation. Our exploration aims to providedeeper insights into the stability and transformation of features acrosstypical transfer-learning scenarios using small-scale models and sparseauto-encoders.</description>
      <author>example@mail.com (Niels Horn, Desmond Elliott)</author>
      <guid isPermaLink="false">2410.12391v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Fusion with Relational Learning for Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2410.12128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于图的分子表示学习在药物发现和材料科学中对准确预测分子属性至关重要，但面临复杂的分子关系和有限的化学知识的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一个新框架MMFRL，以克服现有方法的局限性，提升分子属性预测的效果。&lt;h4&gt;方法&lt;/h4&gt;通过多模态预训练和关系学习增强嵌入初始化，并系统性研究在不同阶段（早期、中期和晚期）进行模态融合的影响。&lt;h4&gt;主要发现&lt;/h4&gt;MMFRL在MoleculeNet基准测试中显著优于现有方法，并支持针对特定任务的优化。&lt;h4&gt;结论&lt;/h4&gt;MMFRL的可解释性提供了有价值的化学见解，强调了其在实际药物发现应用中的潜力。&lt;h4&gt;总结&lt;/h4&gt;MMFRL为分子属性预测提供了一种新方法，解决了多模态融合和复杂分子关系的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph based molecular representation learning is essential for accuratelypredicting molecular properties in drug discovery and materials science;however, it faces significant challenges due to the intricate relationshipsamong molecules and the limited chemical knowledge utilized during training.While contrastive learning is often employed to handle molecular relationships,its reliance on binary metrics is insufficient for capturing the complexity ofthese interactions. Multimodal fusion has gained attention for propertyreasoning, but previous work has explored only a limited range of modalities,and the optimal stages for fusing different modalities in molecular propertytasks remain underexplored. In this paper, we introduce MMFRL (MultimodalFusion with Relational Learning for Molecular Property Prediction), a novelframework designed to overcome these limitations. Our method enhances embeddinginitialization through multimodal pretraining using relational learning. Wealso conduct a systematic investigation into the impact of modality fusion atdifferent stages such as early, intermediate, and late, highlighting theiradvantages and shortcomings. Extensive experiments on MoleculeNet benchmarksdemonstrate that MMFRL significantly outperforms existing methods. Furthermore,MMFRL enables task-specific optimizations. Additionally, the explainability ofMMFRL provides valuable chemical insights, emphasizing its potential to enhancereal-world drug discovery applications.</description>
      <author>example@mail.com (Zhengyang Zhou, Hao Xu, Pengyu Hong)</author>
      <guid isPermaLink="false">2410.12128v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>D-FINE: Redefine Regression Task in DETRs as Fine-grained Distribution Refinement</title>
      <link>http://arxiv.org/abs/2410.13842v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;D-FINE是一种强大的实时物体检测器，旨在提高定位精度，改进DETR模型中的边界框回归任务。&lt;h4&gt;目的&lt;/h4&gt;通过重新定义边界框回归任务，提高物体检测的准确性和速度。&lt;h4&gt;方法&lt;/h4&gt;D-FINE包含两个关键组件：细粒度分布优化(FDR)和全局最优定位自蒸馏(GO-LSD)。FDR通过迭代优化概率分布来提高定位准确性，而GO-LSD则通过自蒸馏从精细化分布中转移知识。&lt;h4&gt;主要发现&lt;/h4&gt;D-FINE-L / X在COCO数据集上分别以124 / 78 FPS达到了54.0% / 55.8%的AP，预训练于Objects365时达到了57.1% / 59.3%的AP，超越了所有现有的实时检测器。&lt;h4&gt;结论&lt;/h4&gt;D-FINE显著提高了多种DETR模型的性能，AP提升可达5.3%，且几乎没有额外的参数和训练成本。&lt;h4&gt;总结&lt;/h4&gt;D-FINE通过创新的方法在物体检测中实现了速度与精度的良好平衡，展示了其在实时检测领域的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Peterande/D-FINE&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce D-FINE, a powerful real-time object detector that achievesoutstanding localization precision by redefining the bounding box regressiontask in DETR models. D-FINE comprises two key components: Fine-grainedDistribution Refinement (FDR) and Global Optimal Localization Self-Distillation(GO-LSD). FDR transforms the regression process from predicting fixedcoordinates to iteratively refining probability distributions, providing afine-grained intermediate representation that significantly enhanceslocalization accuracy. GO-LSD is a bidirectional optimization strategy thattransfers localization knowledge from refined distributions to shallower layersthrough self-distillation, while also simplifying the residual prediction tasksfor deeper layers. Additionally, D-FINE incorporates lightweight optimizationsin computationally intensive modules and operations, achieving a better balancebetween speed and accuracy. Specifically, D-FINE-L / X achieves 54.0% / 55.8%AP on the COCO dataset at 124 / 78 FPS on an NVIDIA T4 GPU. When pretrained onObjects365, D-FINE-L / X attains 57.1% / 59.3% AP, surpassing all existingreal-time detectors. Furthermore, our method significantly enhances theperformance of a wide range of DETR models by up to 5.3% AP with negligibleextra parameters and training costs. Our code and pretrained models:https://github.com/Peterande/D-FINE.</description>
      <author>example@mail.com (Yansong Peng, Hebei Li, Peixi Wu, Yueyi Zhang, Xiaoyan Sun, Feng Wu)</author>
      <guid isPermaLink="false">2410.13842v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks</title>
      <link>http://arxiv.org/abs/2410.10454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by EMNLP 2024 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;元学习已成为少样本文本分类的突出技术，并取得了良好的性能。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在从支持集样本中提取准确类别原型时遇到的困难。&lt;h4&gt;方法&lt;/h4&gt;利用标签信息构建任务自适应的度量空间，减少类内差异并放大类间差异，同时使用最优传输技术估计类别原型。&lt;h4&gt;主要发现&lt;/h4&gt;在八个基准数据集上的广泛实验中，所提方法在所有任务上均明显优于最新的模型。&lt;h4&gt;结论&lt;/h4&gt;通过充分利用任务内部的信息，提出了一种有效的解决方案，克服了现有方法的局限性。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种新的方法来改善少样本文本分类的性能，所有数据集和代码均可在指定网址获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yvogao/laqda&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Meta-learning has emerged as a prominent technology for few-shot textclassification and has achieved promising performance. However, existingmethods often encounter difficulties in drawing accurate class prototypes fromsupport set samples, primarily due to probable large intra-class differencesand small inter-class differences within the task. Recent approaches attempt toincorporate external knowledge or pre-trained language models to augment data,but this requires additional resources and thus does not suit many few-shotscenarios. In this paper, we propose a novel solution to address this issue byadequately leveraging the information within the task itself. Specifically, weutilize label information to construct a task-adaptive metric space, therebyadaptively reducing the intra-class differences and magnifying the inter-classdifferences. We further employ the optimal transport technique to estimateclass prototypes with query set samples together, mitigating the problem ofinaccurate and ambiguous support set samples caused by large intra-classdifferences. We conduct extensive experiments on eight benchmark datasets, andour approach shows obvious advantages over state-of-the-art models across allthe tasks on all the datasets. For reproducibility, all the datasets and codesare available at https://github.com/YvoGao/LAQDA.</description>
      <author>example@mail.com (Xinyue Liu, Yunlong Gao, Linlin Zong, Bo Xu)</author>
      <guid isPermaLink="false">2410.10454v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Point Cloud Completion through Unbalanced Optimal Transport</title>
      <link>http://arxiv.org/abs/2410.02671v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;未配对点云补全研究探索如何从未配对的不完整和完整点云数据中学习补全映射。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的未配对点云补全方法，称为未平衡最优运输映射（UOT-UPC）。&lt;h4&gt;方法&lt;/h4&gt;将未配对点云补全自然解释为最优运输（OT）问题，并引入未平衡最优运输（UOT）方法以解决未配对点云补全数据集中普遍存在的类别不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;分析适用于未配对补全任务的成本函数，表明InfoCD成本函数特别适合此任务。&lt;h4&gt;结论&lt;/h4&gt;我们的模型首次利用UOT进行未配对点云补全，在单类别和多类别数据集上取得了竞争力或优越的结果，尤其在类别不平衡的场景中表现出色。&lt;h4&gt;总结&lt;/h4&gt;UOT-UPC模型有效解决了未配对点云补全中的类别不平衡问题，展示了其在各类数据集上的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unpaired point cloud completion explores methods for learning a completionmap from unpaired incomplete and complete point cloud data. In this paper, wepropose a novel approach for unpaired point cloud completion using theunbalanced optimal transport map, called Unbalanced Optimal Transport Map forUnpaired Point Cloud Completion (UOT-UPC). We demonstrate that the unpairedpoint cloud completion can be naturally interpreted as the Optimal Transport(OT) problem and introduce the Unbalanced Optimal Transport (UOT) approach toaddress the class imbalance problem, which is prevalent in unpaired point cloudcompletion datasets. Moreover, we analyze the appropriate cost function forunpaired completion tasks. This analysis shows that the InfoCD cost function isparticularly well-suited for this task. Our model is the first attempt toleverage UOT for unpaired point cloud completion, achieving competitive orsuperior results on both single-category and multi-category datasets. Inparticular, our model is especially effective in scenarios with classimbalance, where the proportions of categories are different between theincomplete and complete point cloud datasets.</description>
      <author>example@mail.com (Taekyung Lee, Jaemoo Choi, Myungjoo Kang, Jaewoong Choi)</author>
      <guid isPermaLink="false">2410.02671v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>DualQuat-LOAM: LiDAR Odometry and Mapping parametrized on Dual Quaternions</title>
      <link>http://arxiv.org/abs/2410.13541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在使用基于梯度的深度强化学习模型中，优化器的选择和学习率对性能至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种动态学习率方法，以改善深度强化学习的表现。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于元学习的动态学习率（LRRL），通过多臂老虎机算法选择学习率，依据训练过程中的代理表现进行调整。&lt;h4&gt;主要发现&lt;/h4&gt;LRRL显著提高了深度强化学习算法的性能。&lt;h4&gt;结论&lt;/h4&gt;动态学习率方法有效应对了学习率选择中的挑战，优化了模型训练过程。&lt;h4&gt;总结&lt;/h4&gt;LRRL通过灵活调整学习率，改善了深度强化学习的训练效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper reports on a novel method for LiDAR odometry estimation, whichcompletely parameterizes the system with dual quaternions. To accomplish this,the features derived from the point cloud, including edges, surfaces, andStable Triangle Descriptor (STD), along with the optimization problem, areexpressed in the dual quaternion set. This approach enables the directcombination of translation and orientation errors via dual quaternionoperations, greatly enhancing pose estimation, as demonstrated in comparativeexperiments against other state-of-the-art methods. Our approach reduced drifterror compared to other LiDAR-only-odometry methods, especially in scenarioswith sharp curves and aggressive movements with large angular displacement.DualQuat-LOAM is benchmarked against several public datasets. In the KITTIdataset it has a translation and rotation error of 0.79% and 0.0039{\deg}/m,with an average run time of 53 ms.</description>
      <author>example@mail.com (Edison P. Velasco-Sánchez, Luis F. Recalde, Guanrui Li, Francisco A. Candelas-Herias, Santiago T. Puente-Mendez, Fernando Torres-Medina)</author>
      <guid isPermaLink="false">2410.13541v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Learning Rate for Deep Reinforcement Learning: A Bandit Approach</title>
      <link>http://arxiv.org/abs/2410.12598v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;使用多智能体AI模型自动发现新金属合金，整合多模态数据和外部知识，包括物理学的见解。&lt;h4&gt;目的&lt;/h4&gt;自动化探索多组分金属合金的设计空间，特别关注NbMoTa系列体心立方合金。&lt;h4&gt;方法&lt;/h4&gt;系统由三个关键组件组成：一组负责推理和规划的LLM，一组具有不同角色和专业的AI代理，以及一个用于快速获取关键物理属性的新型图神经网络（GNN）模型。&lt;h4&gt;主要发现&lt;/h4&gt;GNN模型准确预测原子级属性，如Peierls能垒和溶质/螺旋位错相互作用能，为多智能体系统提供了快速替代昂贵的计算方法。&lt;h4&gt;结论&lt;/h4&gt;该AI系统通过减少对人类专业知识的依赖，克服了直接全原子模拟的限制，显著加速了先进合金的发现，具有在其他复杂系统中广泛应用的潜力。&lt;h4&gt;总结&lt;/h4&gt;该方法结合了GNN的预测能力和基于LLM的代理的动态协作，自动导航合金设计空间，识别原子级材料属性的趋势并预测宏观机械强度，标志着自动化材料设计的重要进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In Deep Reinforcement Learning models trained using gradient-basedtechniques, the choice of optimizer and its learning rate are crucial toachieving good performance: higher learning rates can prevent the model fromlearning effectively, while lower ones might slow convergence. Additionally,due to the non-stationarity of the objective function, the best-performinglearning rate can change over the training steps. To adapt the learning rate, astandard technique consists of using decay schedulers. However, theseschedulers assume that the model is progressively approaching convergence,which may not always be true, leading to delayed or premature adjustments. Inthis work, we propose dynamic Learning Rate for deep Reinforcement Learning(LRRL), a meta-learning approach that selects the learning rate based on theagent's performance during training. LRRL is based on a multi-armed banditalgorithm, where each arm represents a different learning rate, and the banditfeedback is provided by the cumulative returns of the RL policy to update thearms' probability distribution. Our empirical results demonstrate that LRRL cansubstantially improve the performance of deep RL algorithms.</description>
      <author>example@mail.com (Henrique Donâncio, Antoine Barrier, Leah F. South, Florence Forbes)</author>
      <guid isPermaLink="false">2410.12598v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems</title>
      <link>http://arxiv.org/abs/2410.13768v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "半监督学习（SSL）在医学图像分割中是一项具有挑战性但非常实用的任务，通过利用未标记样本减少对大规模标记数据集的依赖。",
    "目的": "提出一种新颖的基于FixMatch的半监督框架SemSim，以解决现有方法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以```json
{
    "背景": "半监督学习（SSL）在医学图像分割中是一项具有挑战性但非常实用的任务，通过利用未标记样本减少对大规模标记数据集的依赖。",
    "目的": "提出一种新颖的基于FixMatch的半监督框架SemSim，以解决现有方法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共```json
{
    "背景": "半监督学习（SSL）在医学图像分割中是一项具有挑战性但非常实用的任务，通过利用未标记样本减少对大规模标记数据集的依赖。",
    "目的": "提出一种新颖的基于FixMatch的半监督框架SemSim，以解决现有方法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上    "背景": "半监督学习（SSL）在医学图像分割中是一项具有挑战性但非常实用的任务，通过利用未标记样本减少对大规模标记数据集的依赖。",
    "目的": "提出一种新颖的基于FixMatch的半监督框架SemSim，以解决现有方法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法半监督学习（SSL）在医学图像分割中是一项具有挑战性但非常实用的任务，通过利用未标记样本减少对大规模标记数据集的依赖。",
    "目的": "提出一种新颖的基于FixMatch的半监督框架SemSim，以解决现有方法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升项具有挑战性但非常实用的任务，通过利用未标记样本减少对大规模标记数据集的依赖。",
    "目的": "提出一种新颖的基于FixMatch的半监督框架SemSim，以解决现有方法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结有挑战性但非常实用的任务，通过利用未标记样本减少对大规模标记数据集的依赖。",
    "目的": "提出一种新颖的基于FixMatch的半监督框架SemSim，以解决现有方法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论":态数据和外部知识，包括物理学的见解。",
    "目的": "自动化探索多组分金属合目的": "提出一种新颖的基于FixMatch的半监督框架SemSim，以解决现有方法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框MoTa系列体心立h的半监督框架SemSim，以解决现有方法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法方法": "系统法的两个主要局限性。",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性",
    "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学  "方法": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割": "SemSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割的性能mSim通过两个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割的性能。",
    "总结个设计来增强语义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割的性能。",
    "总结": "本研究义相似性：1) 通过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割的性能。",
    "总结": "本研究提出的SemSim过推理图像内的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割的性能。",
    "总结": "本研究提出的SemSim框架通过增强的像素对亲和图来修正像素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割的性能。",
    "总结": "本研究提出的SemSim框架通过增强语义相似性和上下文依赖，显著改善了医学素级预测，明确整合上下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割的性能。",
    "总结": "本研究提出的SemSim框架通过增强语义相似性和上下文依赖，显著改善了医学图像分割的效果。"
下文依赖；2) 通过特征查询机制将标记和未标记数据连接，充分考虑跨图像的解剖相似性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割的性能。",
    "总结": "本研究提出的SemSim框架通过增强语义相似性和上下文依赖，显著改善了医学图像分割的效果。"
}
```ierls能垒和溶性。此外，引入空间感知融合模块（SFM）以探索多尺度的独特信息。",
    "主要发现": "SemSim在三个公共分割基准上显示出相较于最先进方法的一致性提升。",
    "结论": "SemSim框架有效克服了现有方法的局限性，提升了医学图像分割的性能。",
    "总结": "本研究提出的SemSim框架通过增强语义相似性和上下文依赖，显著改善了医学图像分割的效果。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A multi-agent AI model is used to automate the discovery of new metallicalloys, integrating multimodal data and external knowledge including insightsfrom physics via atomistic simulations. Our multi-agent system features threekey components: (a) a suite of LLMs responsible for tasks such as reasoning andplanning, (b) a group of AI agents with distinct roles and expertise thatdynamically collaborate, and (c) a newly developed graph neural network (GNN)model for rapid retrieval of key physical properties. A set of LLM-driven AIagents collaborate to automate the exploration of the vast design space ofMPEAs, guided by predictions from the GNN. We focus on the NbMoTa family ofbody-centered cubic (bcc) alloys, modeled using an ML-based interatomicpotential, and target two key properties: the Peierls barrier and solute/screwdislocation interaction energy. Our GNN model accurately predicts theseatomic-scale properties, providing a faster alternative to costly brute-forcecalculations and reducing the computational burden on multi-agent systems forphysics retrieval. This AI system revolutionizes materials discovery byreducing reliance on human expertise and overcoming the limitations of directall-atom simulations. By synergizing the predictive power of GNNs with thedynamic collaboration of LLM-based agents, the system autonomously navigatesvast alloy design spaces, identifying trends in atomic-scale materialproperties and predicting macro-scale mechanical strength, as demonstrated byseveral computational experiments. This approach accelerates the discovery ofadvanced alloys and holds promise for broader applications in other complexsystems, marking a significant step forward in automated materials design.</description>
      <author>example@mail.com (Alireza Ghafarollahi, Markus J. Buehler)</author>
      <guid isPermaLink="false">2410.13768v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SemSim: Revisiting Weak-to-Strong Consistency from a Semantic Similarity Perspective for Semi-supervised Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2410.13486v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;CT扫描中的颅骨分割已被认为是一个已解决的问题，但在MRI中，由于软组织的存在，这一任务复杂性显著增加。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的方法来进行MRI图像中的颅骨分割。&lt;h4&gt;方法&lt;/h4&gt;通过MR到CT的转换生成合成CT数据，然后在合成CT上进行分割，而不是直接在MRI图像上进行分割。&lt;h4&gt;主要发现&lt;/h4&gt;该方法解决了无监督颅骨分割中的多项问题，包括MR和CT数据集的不配对性、低分辨率和图像质量差，以及模型的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究对需要从MRI体积中进行颅骨分割的后续任务（如颅骨切除术或手术规划）具有重要价值，是合成数据在医学成像中应用的重要一步。&lt;h4&gt;总结&lt;/h4&gt;提出的无监督方法为MRI中的颅骨分割提供了新的思路，克服了传统方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semi-supervised learning (SSL) for medical image segmentation is achallenging yet highly practical task, which reduces reliance on large-scalelabeled dataset by leveraging unlabeled samples. Among SSL techniques, theweak-to-strong consistency framework, popularized by FixMatch, has emerged as astate-of-the-art method in classification tasks. Notably, such a simplepipeline has also shown competitive performance in medical image segmentation.However, two key limitations still persist, impeding its efficient adaptation:(1) the neglect of contextual dependencies results in inconsistent predictionsfor similar semantic features, leading to incomplete object segmentation; (2)the lack of exploitation of semantic similarity between labeled and unlabeleddata induces considerable class-distribution discrepancy. To address theselimitations, we propose a novel semi-supervised framework based on FixMatch,named SemSim, powered by two appealing designs from semantic similarityperspective: (1) rectifying pixel-wise prediction by reasoning about theintra-image pair-wise affinity map, thus integrating contextual dependenciesexplicitly into the final prediction; (2) bridging labeled and unlabeled datavia a feature querying mechanism for compact class representation learning,which fully considers cross-image anatomical similarities. As the reliablesemantic similarity extraction depends on robust features, we further introducean effective spatial-aware fusion module (SFM) to explore distinctiveinformation from multiple scales. Extensive experiments show that SemSim yieldsconsistent improvements over the state-of-the-art methods across three publicsegmentation benchmarks.</description>
      <author>example@mail.com (Shiao Xie, Hongyi Wang, Ziwei Niu, Hao Sun, Shuyi Ouyang, Yen-Wei Chen, Lanfen Lin)</author>
      <guid isPermaLink="false">2410.13486v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Skull Segmentation via Contrastive MR-to-CT Modality Translation</title>
      <link>http://arxiv.org/abs/2410.13427v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 5 figures, ACCV 2024 - GAISynMeD Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;CT扫描中的颅骨分割已被认为是一个已解决的问题，但在MRI中，由于软组织的存在，这一任务复杂性显著增加。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的方法来进行MRI图像中的颅骨分割。&lt;h4&gt;方法&lt;/h4&gt;通过MR到CT的转换生成合成CT数据，然后在合成CT上进行分割，而不是直接在MRI图像上进行分割。&lt;h4&gt;主要发现&lt;/h4&gt;该方法解决了无监督颅骨分割中的多项问题，包括MR和CT数据集的不配对性、低分辨率和图像质量差，以及模型的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究对需要从MRI体积中进行颅骨分割的后续任务（如颅骨切除术或手术规划）具有重要价值，是合成数据在医学成像中应用的重要一步。&lt;h4&gt;总结&lt;/h4&gt;提出的无监督方法为MRI中的颅骨分割提供了新的思路，克服了传统方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The skull segmentation from CT scans can be seen as an already solvedproblem. However, in MR this task has a significantly greater complexity due tothe presence of soft tissues rather than bones. Capturing the bone structuresfrom MR images of the head, where the main visualization objective is thebrain, is very demanding. The attempts that make use of skull stripping seem tonot be well suited for this task and fail to work in many cases. On the otherhand, supervised approaches require costly and time-consuming skullannotations. To overcome the difficulties we propose a fully unsupervisedapproach, where we do not perform the segmentation directly on MR images, butwe rather perform a synthetic CT data generation via MR-to-CT translation andperform the segmentation there. We address many issues associated withunsupervised skull segmentation including the unpaired nature of MR and CTdatasets (contrastive learning), low resolution and poor quality(super-resolution), and generalization capabilities. The research has asignificant value for downstream tasks requiring skull segmentation from MRvolumes such as craniectomy or surgery planning and can be seen as an importantstep towards the utilization of synthetic data in medical imaging.</description>
      <author>example@mail.com (Kamil Kwarciak, Mateusz Daniol, Daria Hemmerling, Marek Wodzinski)</author>
      <guid isPermaLink="false">2410.13427v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Real-time Stereo-based 3D Object Detection for Streaming Perception</title>
      <link>http://arxiv.org/abs/2410.12394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Streaming Perception, 3D Object Detection, NeurIPS2024 poster&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;快速响应环境变化对自动驾驶的感知系统至关重要，最近提出了一种新任务——流媒体感知。&lt;h4&gt;目的&lt;/h4&gt;评估视频在线感知的延迟和准确性，并提出一种新的框架来提升实时3D目标检测的性能。&lt;h4&gt;方法&lt;/h4&gt;引入StreamDSGN，这是第一个基于立体视觉的实时3D目标检测框架，采用历史信息预测下一个时刻的3D属性。&lt;h4&gt;主要发现&lt;/h4&gt;StreamDSGN通过三种策略显著提升了感知准确性，并在KITTI Tracking数据集上相较于强基线提升了流媒体平均精度达4.33%。&lt;h4&gt;结论&lt;/h4&gt;StreamDSGN有效地缓解了流媒体感知的准确性下降问题，提供了更好的目标检测性能。&lt;h4&gt;总结&lt;/h4&gt;本文提出的StreamDSGN框架为流媒体感知任务提供了一种有效的解决方案，代码可在GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to promptly respond to environmental changes is crucial for theperception system of autonomous driving. Recently, a new task called streamingperception was proposed. It jointly evaluate the latency and accuracy into asingle metric for video online perception. In this work, we introduceStreamDSGN, the first real-time stereo-based 3D object detection frameworkdesigned for streaming perception. StreamDSGN is an end-to-end framework thatdirectly predicts the 3D properties of objects in the next moment by leveraginghistorical information, thereby alleviating the accuracy degradation ofstreaming perception. Further, StreamDSGN applies three strategies to enhancethe perception accuracy: (1) A feature-flow-based fusion method, whichgenerates a pseudo-next feature at the current moment to address themisalignment issue between feature and ground truth. (2) An extra regressionloss for explicit supervision of object motion consistency in consecutiveframes. (3) A large kernel backbone with a large receptive field foreffectively capturing long-range spatial contextual features caused by changesin object positions. Experiments on the KITTI Tracking dataset show that,compared with the strong baseline, StreamDSGN significantly improves thestreaming average precision by up to 4.33%. Our code is available athttps://github.com/weiyangdaren/streamDSGN-pytorch.</description>
      <author>example@mail.com (Changcai Li, Zonghua Gu, Gang Chen, Libo Huang, Wei Zhang, Huihui Zhou)</author>
      <guid isPermaLink="false">2410.12394v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Performance of Point Cloud Completion Networks with Consistency Loss</title>
      <link>http://arxiv.org/abs/2410.07298v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  First version of Paper "Enhancing Performance of Point Cloud
  Completion Networks with Consistency Loss" by Kevin Tirta Wijaya and
  Christofel Rio Goenawan. In process submission to Neurocomputing Journal 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云补全网络通常训练以最小化补全点云与真实点云之间的差异，但在孤立观察时，不完整的物体级点云可能存在多个有效的补全解决方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的补全一致性损失，以缓解一对多映射问题。&lt;h4&gt;方法&lt;/h4&gt;通过改进常规学习目标，引入一致性损失，确保来自相同源点云的不完整物体生成一致的补全解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;在多个已建立的数据集和基准测试中，提出的一致性损失显著提升了多种现有网络的补全性能，而无需修改网络设计。&lt;h4&gt;结论&lt;/h4&gt;使用一致性损失训练的先进点云补全网络在具有挑战性的MVP数据集上达到了最先进的准确性。&lt;h4&gt;总结&lt;/h4&gt;该方法在不影响推理速度的情况下，提高了点云补全的准确性，相关代码和实验结果可在指定GitHub链接获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-09&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud completion networks are conventionally trained to minimize thedisparities between the completed point cloud and the ground-truth counterpart.However, an incomplete object-level point cloud can have multiple validcompletion solutions when it is examined in isolation. This one-to-many mappingissue can cause contradictory supervision signals to the network because theloss function may produce different values for identical input-output pairs ofthe network. In many cases, this issue could adversely affect the networkoptimization process. In this work, we propose to enhance the conventionallearning objective using a novel completion consistency loss to mitigate theone-to-many mapping problem. Specifically, the proposed consistency loss ensurethat a point cloud completion network generates a coherent completion solutionfor incomplete objects originating from the same source point cloud.Experimental results across multiple well-established datasets and benchmarksdemonstrated the proposed completion consistency loss have excellent capabilityto enhance the completion performance of various existing networks without anymodification to the design of the networks. The proposed consistency lossenhances the performance of the point completion network without affecting theinference speed, thereby increasing the accuracy of point cloud completion.Notably, a state-of-the-art point completion network trained with the proposedconsistency loss can achieve state-of-the-art accuracy on the challenging newMVP dataset. The code and result of experiment various point completion modelsusing proposed consistency loss will be available at:https://github.com/kaist-avelab/ConsistencyLoss .</description>
      <author>example@mail.com (Christofel Rio Goenawan, Kevin Tirta Wijaya, Seung-Hyun Kong)</author>
      <guid isPermaLink="false">2410.07298v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Task Consistent Prototype Learning for Incremental Few-shot Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.13094v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;增量少样本语义分割(iFSS)任务要求模型在仅有少量标注样本的情况下，不断扩展对新类别的分割能力。&lt;h4&gt;目的&lt;/h4&gt;解决基础训练阶段与增量学习阶段目标不一致所导致的性能下降问题。&lt;h4&gt;方法&lt;/h4&gt;引入基于元学习的原型方法，通过在基础训练阶段模拟增量评估协议，采用伪增量任务序列进行训练，并应用元目标实现快速适应而不遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;通过原型空间重分配学习，动态更新类别原型，建立最佳的类间原型边界，提高类原型之间的区分度。&lt;h4&gt;结论&lt;/h4&gt;在PASCAL和COCO基准上的广泛实验表明，所提方法在iFSS挑战中表现优越，提供了宝贵的见解。&lt;h4&gt;总结&lt;/h4&gt;本研究为增量少样本语义分割提供了一种有效的方法，促进模型快速适应新类别的同时保持先前知识。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Incremental Few-Shot Semantic Segmentation (iFSS) tackles a task thatrequires a model to continually expand its segmentation capability on novelclasses using only a few annotated examples. Typical incremental approachesencounter a challenge that the objective of the base training phase (fittingbase classes with sufficient instances) does not align with the incrementallearning phase (rapidly adapting to new classes with less forgetting). Thisdisconnect can result in suboptimal performance in the incremental setting.This study introduces a meta-learning-based prototype approach that encouragesthe model to learn how to adapt quickly while preserving previous knowledge.Concretely, we mimic the incremental evaluation protocol during the basetraining session by sampling a sequence of pseudo-incremental tasks. Each taskin the simulated sequence is trained using a meta-objective to enable rapidadaptation without forgetting. To enhance discrimination among classprototypes, we introduce prototype space redistribution learning, whichdynamically updates class prototypes to establish optimal inter-prototypeboundaries within the prototype space. Extensive experiments on iFSS datasetsbuilt upon PASCAL and COCO benchmarks show the advanced performance of theproposed approach, offering valuable insights for addressing iFSS challenges.</description>
      <author>example@mail.com (Wenbo Xu, Yanan Wu, Haoran Jiang, Yang Wang, Qiang Wu, Jian Zhang)</author>
      <guid isPermaLink="false">2410.13094v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>TopoFR: A Closer Look at Topology Alignment on Face Recognition</title>
      <link>http://arxiv.org/abs/2410.10587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督学习在表格数据上的应用旨在借鉴自然语言和图像领域的进展，但现有技术在整合多域数据方面存在困难，并需进行数据清理或满足特定结构要求，限制了预训练数据集的可扩展性。&lt;h4&gt;目的&lt;/h4&gt;介绍PORTAL框架，旨在处理各种数据模态，无需清理或预处理。&lt;h4&gt;方法&lt;/h4&gt;PORTAL采用逐行预训练的方法，能够在在线收集的数据集上有效预训练，并进行微调以匹配复杂分类和回归任务上的先进方法。&lt;h4&gt;主要发现&lt;/h4&gt;PORTAL框架在处理多种数据模态时表现出色，克服了数据清理和结构要求的限制。&lt;h4&gt;结论&lt;/h4&gt;该研究为大规模表格数据的自监督学习提供了实用的进展。&lt;h4&gt;总结&lt;/h4&gt;PORTAL是一种简单而强大的框架，能够有效提升自监督学习在表格数据领域的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/modelscope/facechain&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The field of face recognition (FR) has undergone significant advancementswith the rise of deep learning. Recently, the success of unsupervised learningand graph neural networks has demonstrated the effectiveness of data structureinformation. Considering that the FR task can leverage large-scale trainingdata, which intrinsically contains significant structure information, we aim toinvestigate how to encode such critical structure information into the latentspace. As revealed from our observations, directly aligning the structureinformation between the input and latent spaces inevitably suffers from anoverfitting problem, leading to a structure collapse phenomenon in the latentspace. To address this problem, we propose TopoFR, a novel FR model thatleverages a topological structure alignment strategy called PTSA and a hardsample mining strategy named SDE. Concretely, PTSA uses persistent homology toalign the topological structures of the input and latent spaces, effectivelypreserving the structure information and improving the generalizationperformance of FR model. To mitigate the impact of hard samples on the latentspace structure, SDE accurately identifies hard samples by automaticallycomputing structure damage score (SDS) for each sample, and directs the modelto prioritize optimizing these samples. Experimental results on popular facebenchmarks demonstrate the superiority of our TopoFR over the state-of-the-artmethods. Code and models are available at:https://github.com/modelscope/facechain/tree/main/face_module/TopoFR.</description>
      <author>example@mail.com (Jun Dan, Yang Liu, Jiankang Deng, Haoyu Xie, Siyuan Li, Baigui Sun, Shan Luo)</author>
      <guid isPermaLink="false">2410.10587v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>PORTAL: Scalable Tabular Foundation Models via Content-Specific Tokenization</title>
      <link>http://arxiv.org/abs/2410.13516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Table Representation Learning Workshop at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督学习在ormers是基础模型的核心架构，领域特定的分词器帮助其适应各种领域。图形变换器（GTs）最近在几何深度学习中表现突出，超越了图神经网络（GNNs）。&lt;h4&gt;目的&lt;/h4&gt;解决图形分词器发展滞后于其他模态的问题。&lt;h4&gt;方法&lt;/h4&gt;提出GQT（图量化分词器），通过多任务图自监督学习将分词器训练与Transformer训练解耦，利用残差向量量化（RVQ）学习层次离散标记。&lt;h4&gt;主要发现&lt;/h4&gt;GQT显著减少了内存需求，改善了通用化能力，并结合分词调制使Transformer编码器在18个基准测试中实现了16个的最佳性能。&lt;h4&gt;结论&lt;/h4&gt;GQT展示了在图学习任务中的有效性，推动了图分词器的发展。&lt;h4&gt;总结&lt;/h4&gt;GQT的引入为图形领域的深度学习提供了新的突破，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning on tabular data seeks to apply advances from naturallanguage and image domains to the diverse domain of tables. However, currenttechniques often struggle with integrating multi-domain data and require datacleaning or specific structural requirements, limiting the scalability ofpre-training datasets. We introduce PORTAL (Pretraining One-Row-at-a-Time forAll tabLes), a framework that handles various data modalities without the needfor cleaning or preprocessing. This simple yet powerful approach can beeffectively pre-trained on online-collected datasets and fine-tuned to matchstate-of-the-art methods on complex classification and regression tasks. Thiswork offers a practical advancement in self-supervised learning for large-scaletabular data.</description>
      <author>example@mail.com (Marco Spinaci, Marek Polewczyk, Johannes Hoffart, Markus C. Kohler, Sam Thelin, Tassilo Klein)</author>
      <guid isPermaLink="false">2410.13516v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Learning Graph Quantized Tokenizers for Transformers</title>
      <link>http://arxiv.org/abs/2410.13798v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;监督对比学习已被探索用于多标签分类，但在多标签场景中确定正样本仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;引入五种不同的多标签样本之间的关系，并提出一种相似性-不相似性损失用于多标签分类。&lt;h4&gt;方法&lt;/h4&gt;提出的损失函数通过计算正样本与给定锚点之间的相似性和不相似性，动态调整对比损失函数中的权重。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC数据集上进行的多标签文本分类实验表明，所提损失在所有编码器上有效提高了性能。&lt;h4&gt;结论&lt;/h4&gt;提出的损失函数在监督对比学习范式下展现了有效性和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;通过引入不同的样本关系，改进了多标签分类任务中的正样本识别，提升了模型表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/limei0307/graph-tokenizer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers serve as the backbone architectures of Foundational Models,where a domain-specific tokenizer helps them adapt to various domains. GraphTransformers (GTs) have recently emerged as a leading model in geometric deeplearning, outperforming Graph Neural Networks (GNNs) in various graph learningtasks. However, the development of tokenizers for graphs has lagged behindother modalities, with existing approaches relying on heuristics or GNNsco-trained with Transformers. To address this, we introduce GQT (\textbf{G}raph\textbf{Q}uantized \textbf{T}okenizer), which decouples tokenizer training fromTransformer training by leveraging multi-task graph self-supervised learning,yielding robust and generalizable graph tokens. Furthermore, the GQT utilizesResidual Vector Quantization (RVQ) to learn hierarchical discrete tokens,resulting in significantly reduced memory requirements and improvedgeneralization capabilities. By combining the GQT with token modulation, aTransformer encoder achieves state-of-the-art performance on 16 out of 18benchmarks, including large-scale homophilic and heterophilic datasets. Thecode is available at: https://github.com/limei0307/graph-tokenizer</description>
      <author>example@mail.com (Limei Wang, Kaveh Hassani, Si Zhang, Dongqi Fu, Baichuan Yuan, Weilin Cong, Zhigang Hua, Hao Wu, Ning Yao, Bo Long)</author>
      <guid isPermaLink="false">2410.13798v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Similarity-Dissimilarity Loss with Supervised Contrastive Learning for Multi-label Classification</title>
      <link>http://arxiv.org/abs/2410.13439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;监督对比学习已被探索用于多标签操作一直是机器人研究者的目标，但自主操作主要受到可推广技能获取的限制。&lt;h4&gt;目的&lt;/h4&gt;扩展人形机器人在不同环境中的自主操作能力。&lt;h4&gt;方法&lt;/h4&gt;提出改进的3D扩散策略（iDP3），通过利用自我中心的3D视觉表示来消除对相机校准和点云分割的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;iDP3使全尺寸人形机器人能够在多种真实场景中自主执行技能，仅使用在实验室收集的数据。&lt;h4&gt;结论&lt;/h4&gt;iDP3展现了在更广泛环境中提升人形机器人操作能力的潜力。&lt;h4&gt;总结&lt;/h4&gt;研究表明，通过改进的视觉策略，人形机器人能够更有效地执行复杂操作，推动其在实际应用中的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Supervised contrastive learning has been explored in making use of labelinformation for multi-label classification, but determining positive samples inmulti-label scenario remains challenging. Previous studies have examinedstrategies for identifying positive samples, considering label overlapproportion between anchors and samples. However, they ignore various relationsbetween given anchors and samples, as well as how to dynamically adjust theweights in contrastive loss functions based on different relations, leading togreat ambiguity. In this paper, we introduce five distinct relations betweenmulti-label samples and propose a Similarity-Dissimilarity Loss withcontrastive learning for multi-label classification. Our loss functionre-weights the loss by computing the similarity and dissimilarity betweenpositive samples and a given anchor based on the introduced relations. Wemainly conduct experiments for multi-label text classification on MIMICdatasets, then further extend the evaluation on MS-COCO. The Experimentalresults show that our proposed loss effectively improves the performance on allencoders under supervised contrastive learning paradigm, demonstrating itseffectiveness and robustness.</description>
      <author>example@mail.com (Guangming Huang, Yunfei Long, Cunjin Luo, Sheng Liu)</author>
      <guid isPermaLink="false">2410.13439v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Generalizable Humanoid Manipulation with Improved 3D Diffusion Policies</title>
      <link>http://arxiv.org/abs/2410.10803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://humanoid-manipulation.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;复杂系统的计算模拟成本高，成为科学进步的一个关键瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型，利用已有的相关系统数据来有效训练目标系统的代理模型。&lt;h4&gt;方法&lt;/h4&gt;提出LOcal transfer Learning Gaussian Process（LOL-GP）模型，通过设计的高斯过程转移信息进行代理建模。&lt;h4&gt;主要发现&lt;/h4&gt;LOL-GP模型通过潜在正则化模型识别何时转移信息，改善了现有转移学习模型中的负转移问题。&lt;h4&gt;结论&lt;/h4&gt;LOL-GP在多源和多保真度转移设置下，能够高效地进行后验预测采样，并在数值实验和喷气发动机设计应用中展现出优越的代理性能。&lt;h4&gt;总结&lt;/h4&gt;LOL-GP模型有效解决了复杂系统中的代理模型训练问题，提供了更准确的模拟与不确定性量化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/YanjieZe/Improved-3D-Diffusion-Policy&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoid robots capable of autonomous operation in diverse environments havelong been a goal for roboticists. However, autonomous manipulation by humanoidrobots has largely been restricted to one specific scene, primarily due to thedifficulty of acquiring generalizable skills. Recent advances in 3D visuomotorpolicies, such as the 3D Diffusion Policy (DP3), have shown promise inextending these capabilities to wilder environments. However, 3D visuomotorpolicies often rely on camera calibration and point-cloud segmentation, whichpresent challenges for deployment on mobile robots like humanoids. In thiswork, we introduce the Improved 3D Diffusion Policy (iDP3), a novel 3Dvisuomotor policy that eliminates these constraints by leveraging egocentric 3Dvisual representations. We demonstrate that iDP3 enables a full-sized humanoidrobot to autonomously perform skills in diverse real-world scenarios, usingonly data collected in the lab. Videos are available at:https://humanoid-manipulation.github.io</description>
      <author>example@mail.com (Yanjie Ze, Zixuan Chen, Wenhao Wang, Tianyi Chen, Xialin He, Ying Yuan, Xue Bin Peng, Jiajun Wu)</author>
      <guid isPermaLink="false">2410.10803v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Local transfer learning Gaussian process modeling, with applications to surrogate modeling of expensive computer simulators</title>
      <link>http://arxiv.org/abs/2410.12690v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;复杂系统的计算模拟成本高，成为科学进步的一个关键瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型，利用已有的相关系统数据来有效训练目标系统的代理模型。&lt;h4&gt;方法&lt;/h4&gt;提出LOcal transfer Learning Gaussian Process（，并定义训练目标来确保关系提供有效的不确定性量化指标。&lt;h4&gt;主要发现&lt;/h4&gt;Cocoon在正常和挑战条件下，表现优于现有的静态和自适应方法，包括自然和人工干扰情况下。&lt;h4&gt;结论&lt;/h4&gt;我们的不确定性度量在不同数据集上显示出有效性和效率。&lt;h4&gt;总结&lt;/h4&gt;Cocoon通过不确定性量化提升了多模态融合的性能，为3D物体检测提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A critical bottleneck for scientific progress is the costly nature ofcomputer simulations for complex systems. Surrogate models provide an appealingsolution: such models are trained on simulator evaluations, then used toemulate and quantify uncertainty on the expensive simulator at unexploredinputs. In many applications, one often has available data on related systems.For example, in designing a new jet turbine, there may be existing studies onturbines with similar configurations. A key question is how information fromsuch "source" systems can be transferred for effective surrogate training onthe "target" system of interest. We thus propose a new LOcal transfer LearningGaussian Process (LOL-GP) model, which leverages a carefully-designed Gaussianprocess to transfer such information for surrogate modeling. The key novelty ofthe LOL-GP is a latent regularization model, which identifies regions wheretransfer should be performed and regions where it should be avoided. This"local transfer" property is desirable in scientific systems: at certainparameters, such systems may behave similarly and thus transfer is beneficial;at other parameters, they may behave differently and thus transfer isdetrimental. By accounting for local transfer, the LOL-GP can rectify acritical limitation of "negative transfer" in existing transfer learningmodels, where the transfer of information worsens predictive performance. Wederive a Gibbs sampling algorithm for efficient posterior predictive samplingon the LOL-GP, for both the multi-source and multi-fidelity transfer settings.We then show, via a suite of numerical experiments and an application for jetturbine design, the improved surrogate performance of the LOL-GP over existingmethods.</description>
      <author>example@mail.com (Xinming Wang, Simon Mak, John Miller, Jianguo Wu)</author>
      <guid isPermaLink="false">2410.12690v2</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Cocoon: Robust Multi-Modal Perception with Uncertainty-Aware Sensor Fusion</title>
      <link>http://arxiv.org/abs/2410.12592v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;LiDAR里程计对许多机器人应用至关重要，包括3D地图制作、导航和同时定位与地图构建。&lt;h4&gt;目的&lt;/h4&gt;提出一种专注于轮式移动机器人并考虑运动学模型的LiDAR里程计系统。&lt;h4&gt;方法&lt;/h4&gt;引入运动学约束到传统的点对点迭代最近点方法中，以优化点云对齐。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在大型仓库和户外环境中表现出色，精度优于轮式里程计和常见的LiDAR里程计系统。&lt;h4&gt;结论&lt;/h4&gt;Kinematic-ICP系统已在Dexory机器人车队中成功部署，能够在现实世界中与完整的导航系统一起运行。&lt;h4&gt;总结&lt;/h4&gt;Kinematic-ICP通过动态调整LiDAR测量和轮式里程计的影响，实现了在特征稀少场景中的有效应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An important paradigm in 3D object detection is the use of multiplemodalities to enhance accuracy in both normal and challenging conditions,particularly for long-tail scenarios. To address this, recent studies haveexplored two directions of adaptive approaches: MoE-based adaptive fusion,which struggles with uncertainties arising from distinct object configurations,and late fusion for output-level adaptive fusion, which relies on separatedetection pipelines and limits comprehensive understanding. In this work, weintroduce Cocoon, an object- and feature-level uncertainty-aware fusionframework. The key innovation lies in uncertainty quantification forheterogeneous representations, enabling fair comparison across modalitiesthrough the introduction of a feature aligner and a learnable surrogate groundtruth, termed feature impression. We also define a training objective to ensurethat their relationship provides a valid metric for uncertainty quantification.Cocoon consistently outperforms existing static and adaptive methods in bothnormal and challenging conditions, including those with natural and artificialcorruptions. Furthermore, we show the validity and efficacy of our uncertaintymetric across diverse datasets.</description>
      <author>example@mail.com (Minkyoung Cho, Yulong Cao, Jiachen Sun, Qingzhao Zhang, Marco Pavone, Jeong Joon Park, Heng Yang, Z. Morley Mao)</author>
      <guid isPermaLink="false">2410.12592v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Kinematic-ICP: Enhancing LiDAR Odometry with Kinematic Constraints for Wheeled Mobile Robots Moving on Planar Surfaces</title>
      <link>http://arxiv.org/abs/2410.10277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉基础模型在大量视觉数据上训练，展现出在开放世界环境中的推理和规划能力。&lt;h4&gt;目的&lt;/h4&gt;解决视觉数据与动作数据之间的模态差距，推动其在机器人任务中的应用。&lt;h4&gt;方法&lt;/h4&gt;引入可微机器人渲染方法，使机器人外观与控制参数直接可微分，结合运动学感知的可变形模型和高斯点云技术。&lt;h4&gt;主要发现&lt;/h4&gt;该模型适用于各种机器人形态和自由度，能够从图像重建机器人姿态，并通过视觉语言模型控制机器人。&lt;h4&gt;结论&lt;/h4&gt;可微渲染模型直接从像素提供有效的梯度，奠定了视觉基础模型在机器人领域未来应用的基础。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了如何将视觉基础模型有效地应用于机器人控制，克服了视觉与动作之间的模态鸿沟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR odometry is essential for many robotics applications, including 3Dmapping, navigation, and simultaneous localization and mapping. LiDAR odometrysystems are usually based on some form of point cloud registration to computethe ego-motion of a mobile robot. Yet, few of today's LiDAR odometry systemsconsider the domain-specific knowledge and the kinematic model of the mobileplatform during the point cloud alignment. In this paper, we presentKinematic-ICP, a LiDAR odometry system that focuses on wheeled mobile robotsequipped with a 3D LiDAR and moving on a planar surface, which is a commonassumption for warehouses, offices, hospitals, etc. Our approach introduceskinematic constraints within the optimization of a traditional point-to-pointiterative closest point scheme. In this way, the resulting motion follows thekinematic constraints of the platform, effectively exploiting the robot's wheelodometry and the 3D LiDAR observations. We dynamically adjust the influence ofLiDAR measurements and wheel odometry in our optimization scheme, allowing thesystem to handle degenerate scenarios such as feature-poor corridors. Weevaluate our approach on robots operating in large-scale warehouseenvironments, but also outdoors. The experiments show that our approachachieves top performances and is more accurate than wheel odometry and commonLiDAR odometry systems. Kinematic-ICP has been recently deployed in the Dexoryfleet of robots operating in warehouses worldwide at their customers' sites,showing that our method can run in the real world alongside a completenavigation stack.</description>
      <author>example@mail.com (Tiziano Guadagnino, Benedikt Mersch, Ignacio Vizzo, Saurabh Gupta, Meher V. R. Malladi, Luca Lobefaro, Guillaume Doisy, Cyrill Stachniss)</author>
      <guid isPermaLink="false">2410.10277v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Differentiable Robot Rendering</title>
      <link>http://arxiv.org/abs/2410.13851v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://drrobot.cs.columbia.edu/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉基础模型在大量视觉数据上训练，展现出在开放世界环境中的推理和规划能力。&lt;h4&gt;目的&lt;/h4&gt;解决视觉数据与动作数据之间的模态差距，推动其在机器人任务中的应用。&lt;h4&gt;方法&lt;/h4&gt;引入可微机器人渲染方法，使机器人外观与控制参数直接可微分，结合运动学感知的可变形模型和高斯点云技术。&lt;h4&gt;主要发现&lt;/h4&gt;该模型适用于各种机器人形态和自由度，能够从图像重建机器人姿态，并通过视觉语言模型控制机器人。&lt;h4&gt;结论&lt;/h4&gt;可微渲染模型直接从像素提供有效的梯度，奠定了视觉基础模型在机器人领域未来应用的基础。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了如何将视觉基础模型有效地应用于机器人控制，克服了视觉与动作之间的模态鸿沟。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision foundation models trained on massive amounts of visual data have shownunprecedented reasoning and planning skills in open-world settings. A keychallenge in applying them to robotic tasks is the modality gap between visualdata and action data. We introduce differentiable robot rendering, a methodallowing the visual appearance of a robot body to be directly differentiablewith respect to its control parameters. Our model integrates a kinematics-awaredeformable model and Gaussians Splatting and is compatible with any robot formfactors and degrees of freedom. We demonstrate its capability and usage inapplications including reconstruction of robot poses from images andcontrolling robots through vision language models. Quantitative and qualitativeresults show that our differentiable rendering model provides effectivegradients for robotic control directly from pixels, setting the foundation forthe future applications of vision foundation models in robotics.</description>
      <author>example@mail.com (Ruoshi Liu, Alper Canberk, Shuran Song, Carl Vondrick)</author>
      <guid isPermaLink="false">2410.13851v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Ornstein-Uhlenbeck Adaptation as a Mechanism for Learning in Brains and Machines</title>
      <link>http://arxiv.org/abs/2410.13563v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;学习是智能系统的基本特性，存在于生物有机体和工程系统中。&lt;h4&gt;目的&lt;/h4&gt;探索不依赖精确梯度的替代学习机制，以解决在生物和神经形态系统中实现学习的挑战。&lt;h4&gt;方法&lt;/h4&gt;引入一种新方法，利用系统参数中的噪声和全局强化信号，通过自适应动态的Ornstein-Uhlenbeck过程平衡学习中的探索与利用。&lt;h4&gt;主要发现&lt;/h4&gt;OUA方法在多种任务中有效，包括监督学习和前馈、递归系统中的强化学习，并能够进行自动超参数调整的元学习。&lt;h4&gt;结论&lt;/h4&gt;OUA为传统的基于梯度的方法提供了可行的替代方案，具备在神经形态计算中的应用潜力，并可能揭示大脑中基于噪声的学习机制。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，OUA方法在动态、时间演变环境中的学习表现出色，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning is a fundamental property of intelligent systems, observed acrossbiological organisms and engineered systems. While modern intelligent systemstypically rely on gradient descent for learning, the need for exact gradientsand complex information flow makes its implementation in biological andneuromorphic systems challenging. This has motivated the exploration ofalternative learning mechanisms that can operate locally and do not rely onexact gradients. In this work, we introduce a novel approach that leveragesnoise in the parameters of the system and global reinforcement signals. Usingan Ornstein-Uhlenbeck process with adaptive dynamics, our method balancesexploration and exploitation during learning, driven by deviations from errorpredictions, akin to reward prediction error. Operating in continuous time,Orstein-Uhlenbeck adaptation (OUA) is proposed as a general mechanism forlearning dynamic, time-evolving environments. We validate our approach acrossdiverse tasks, including supervised learning and reinforcement learning infeedforward and recurrent systems. Additionally, we demonstrate that it canperform meta-learning, adjusting hyper-parameters autonomously. Our resultsindicate that OUA provides a viable alternative to traditional gradient-basedmethods, with potential applications in neuromorphic computing. It also hintsat a possible mechanism for noise-driven learning in the brain, wherestochastic neurotransmitter release may guide synaptic adjustments.</description>
      <author>example@mail.com (Jesus Garcia Fernandez, Nasir Ahmad, Marcel van Gerven)</author>
      <guid isPermaLink="false">2410.13563v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>VLM-Grounder: A VLM Agent for Zero-Shot 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2410.13860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CoRL 2024 Camera Ready. 25 pages. A novel zero-shot 3D visual
  grounding framework based solely on 2D images&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D视觉定位对机器人至关重要，需要自然语言与3D场景理解的结合。传统方法依赖于有监督学习和3D点云，但受限于数据集稀缺。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架VLM-Grounder，旨在基于2D图像实现零样本3D视觉定位。&lt;h4&gt;方法&lt;/h4&gt;VLM-Grounder动态拼接图像序列，采用定位和反馈机制寻找目标对象，并使用多视角集成投影准确估计3D边界框。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanRefer和Nr3D数据集上的实验表明，VLM-Grounder优于以前的零样本方法，ScanRefer上实现51.6%的Acc@0.25，Nr3D上实现48.0%的Acc，且不依赖3D几何或对象先验。&lt;h4&gt;结论&lt;/h4&gt;VLM-Grounder通过仅使用2D图像实现了有效的3D视觉定位，显示出在数据稀缺情况下的潜力。&lt;h4&gt;总结&lt;/h4&gt;VLM-Grounder为解决3D视觉定位中的数据问题提供了新的思路，展现了基于视觉语言模型的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/openrobotlab/vlm-grounder&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D visual grounding is crucial for robots, requiring integration of naturallanguage and 3D scene understanding. Traditional methods depending onsupervised learning with 3D point clouds are limited by scarce datasets.Recently zero-shot methods leveraging LLMs have been proposed to address thedata issue. While effective, these methods only use object-centric information,limiting their ability to handle complex queries. In this work, we presentVLM-Grounder, a novel framework using vision-language models (VLMs) forzero-shot 3D visual grounding based solely on 2D images. VLM-Grounderdynamically stitches image sequences, employs a grounding and feedback schemeto find the target object, and uses a multi-view ensemble projection toaccurately estimate 3D bounding boxes. Experiments on ScanRefer and Nr3Ddatasets show VLM-Grounder outperforms previous zero-shot methods, achieving51.6% Acc@0.25 on ScanRefer and 48.0% Acc on Nr3D, without relying on 3Dgeometry or object priors. Codes are available athttps://github.com/OpenRobotLab/VLM-Grounder .</description>
      <author>example@mail.com (Runsen Xu, Zhiwei Huang, Tai Wang, Yilun Chen, Jiangmiao Pang, Dahua Lin)</author>
      <guid isPermaLink="false">2410.13860v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Normalizing self-supervised learning for provably reliable Change Point Detection</title>
      <link>http://arxiv.org/abs/2410.13637v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;变更点检测（CPD）方法旨在识别输入数据流分布中的突变。准确的估计器在各种现实场景中至关重要。&lt;h4&gt;目的&lt;/h4&gt;旨在克服传统无监督CPD技术的局限性，提供更灵活和复杂的数据捕捉能力。&lt;h4&gt;方法&lt;/h4&gt;将表示学习的表达能力与传统CPD技术的扎实性相结合，采用谱归一化（SN）进行深度表示学习，并证明SN后的嵌入对CPD具有高度信息性。&lt;h4&gt;主要发现&lt;/h4&gt;我们的方法在通过三个标准CPD数据集的全面评估中显著优于当前的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;结合表示学习和传统CPD技术的方法能够提高变更点检测的准确性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;本研究填补了表示学习在CPD领域理论基础不足的空白，展示了其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Change point detection (CPD) methods aim to identify abrupt shifts in thedistribution of input data streams. Accurate estimators for this task arecrucial across various real-world scenarios. Yet, traditional unsupervised CPDtechniques face significant limitations, often relying on strong assumptions orsuffering from low expressive power due to inherent model simplicity. Incontrast, representation learning methods overcome these drawbacks by offeringflexibility and the ability to capture the full complexity of the data withoutimposing restrictive assumptions. However, these approaches are still emergingin the CPD field and lack robust theoretical foundations to ensure theirreliability. Our work addresses this gap by integrating the expressive power ofrepresentation learning with the groundedness of traditional CPD techniques. Weadopt spectral normalization (SN) for deep representation learning in CPD tasksand prove that the embeddings after SN are highly informative for CPD. Ourmethod significantly outperforms current state-of-the-art methods during thecomprehensive evaluation via three standard CPD datasets.</description>
      <author>example@mail.com (Alexandra Bazarova, Evgenia Romanenkova, Alexey Zaytsev)</author>
      <guid isPermaLink="false">2410.13637v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing universal machine learning potentials with polarizable long-range interactions</title>
      <link>http://arxiv.org/abs/2410.13820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;长程相互作用在化学系统的行为中至关重要，影响物理和化学现象的准确预测。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，以增强机器学习原子势的预测能力，通过引入显式极化长程相互作用。&lt;h4&gt;方法&lt;/h4&gt;结合等变图神经网络的短程势，构建一个适用于整个周期表的预训练通用模型。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够达到第一性原理的准确性，并已广泛应用于机械性能、固态电解质中离子扩散、铁电性及界面反应的研究。&lt;h4&gt;结论&lt;/h4&gt;该模型展示了其广泛的适用性和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;研究表明，改进的模型在多个领域的研究中具有显著的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-range interactions are crucial in determining the behavior of chemicalsystems in various environments. Accurate predictions of physical and chemicalphenomena at the atomic level hinge on accurate modeling of these interactions.Here, we present a framework that substantially enhances the predictive powerof machine learning interatomic potentials by incorporating explicitpolarizable long-range interactions with an equivariant graph neural networkshort-range potential. The pretrained universal model, applicable across theentire periodic table, can achieve first-principles accuracy. This versatilemodel has been further applied to diverse areas of research, including thestudy of mechanical properties, ionic diffusivity in solid-state electrolytes,ferroelectricity, and interfacial reactions, demonstrating its broadapplicability and robustness.</description>
      <author>example@mail.com (Rongzhi Gao, ChiYung Yam, Jianjun Mao, Shuguang Chen, GuanHua Chen, Ziyang Hu)</author>
      <guid isPermaLink="false">2410.13820v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>SiamSeg: Self-Training with Contrastive Learning for Unsupervised Domain Adaptation in Remote Sensing</title>
      <link>http://arxiv.org/abs/2410.13471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;遥感图像的语义分割是一项具有挑战性的任务，广泛应用于多个领域。深度学习，特别是使用大规模标注数据集的监督学习，推动了该领域的发展。&lt;h4&gt;目的&lt;/h4&gt;探讨如何解决高质量标注数据获取的高成本和时间消耗问题，以及数据集之间的领域偏移对模型性能的影响。&lt;h4&gt;方法&lt;/h4&gt;提出无监督领域适应（UDA）作为一种解决方案，使模型能够在标注源域数据的同时，从未标注的目标域数据中学习。&lt;h4&gt;主要发现&lt;/h4&gt;自监督学习通过伪标签生成的进展显示出在减轻领域差异方面的潜力。结合源域和目标域图像及其真实和伪标签进行自监督训练的策略有效地处理了领域偏差。&lt;h4&gt;结论&lt;/h4&gt;尽管计算机视觉领域取得了进展，伪标签方法在遥感图像分割中的应用仍然较少探索。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了无监督领域适应和伪标签生成在遥感图像语义分割中的重要性和潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/woldier/siamseg&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic segmentation of remote sensing (RS) images is a challenging taskwith significant potential across various applications. Deep learning,especially supervised learning with large-scale labeled datasets, has greatlyadvanced this field. However, acquiring high-quality labeled data is expensiveand time-consuming. Moreover, variations in ground sampling distance (GSD),imaging equipment, and geographic diversity contribute to domain shifts betweendatasets, which pose significant challenges to models trained solely on sourcedomain data, leading to poor cross-domain performance. Domain shift iswell-known for undermining a model's generalization ability in the targetdomain. To address this, unsupervised domain adaptation (UDA) has emerged as apromising solution, enabling models to learn from unlabeled target domain datawhile training on labeled source domain data. Recent advancements, particularlyin self-supervised learning via pseudo-label generation, have shown potentialin mitigating domain discrepancies. Strategies combining source and targetdomain images with their true and pseudo labels for self-supervised traininghave been effective in addressing domain bias. Despite progress in computervision, the application of pseudo-labeling methods to RS image segmentationremains underexplored.</description>
      <author>example@mail.com (Bin Wang, Fei Deng, Shuang Wang, Wen Luo, Zhixuan Zhang)</author>
      <guid isPermaLink="false">2410.13471v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>MambaBEV: An efficient 3D detection model with Mamba2</title>
      <link>http://arxiv.org/abs/2410.12673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于BEV范式的稳定3D目标检测模型对自动驾驶系统非常重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于mamba2的BEV 3D目标检测模型MambaBEV。&lt;h4&gt;方法&lt;/h4&gt;适应端到端的自动驾驶范式来测试模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;在nucences数据集上，基础版本达到了51.7%的NDS。&lt;h4&gt;结论&lt;/h4&gt;MambaBEV模型表现良好，具有潜力。&lt;h4&gt;未来工作&lt;/h4&gt;代码将很快公开，供进一步研究使用。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的MambaBEV模型在3D目标检测中展现了优异性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A stable 3D object detection model based on BEV paradigm with temporalinformation is very important for autonomous driving systems. However, currenttemporal fusion model use convolutional layer or deformable self-attention isnot conducive to the exchange of global information of BEV space and has morecomputational cost. Recently, a newly proposed based model specialized inprocessing sequence called mamba has shown great potential in multipledownstream task. In this work, we proposed a mamba2-based BEV 3D objectdetection model named MambaBEV. We also adapt an end to end self drivingparadigm to test the performance of the model. Our work performs pretty goodresults on nucences datasets:Our base version achieves 51.7% NDS. Our code willbe available soon.</description>
      <author>example@mail.com (Zihan You, Hao Wang, Qichao Zhao, Jinxiang Wang)</author>
      <guid isPermaLink="false">2410.12673v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2410.10295v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024 as poster&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于深度学习的特征匹配在没有姿态先验的点云配准中表现出色，但现有方法在粗匹配时往往稀疏且松散，缺乏几何一致性。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在粗匹配阶段的效率和一致性问题，以便更好地应用于实时任务，如机器人里程计。&lt;h4&gt;方法&lt;/h4&gt;设计了一种一致性感知的点导向Transformer (CAST)，包括点导向交叉注意力模块和一致性感知自注意力模块，以提高几何一致性匹配能力，并提供轻量级的精细匹配模块。&lt;h4&gt;主要发现&lt;/h4&gt;CAST在户外LiDAR点云数据集和室内RGBD点云数据集上的实验表明，其在准确性、效率和鲁棒性方面达到了先进水平。&lt;h4&gt;结论&lt;/h4&gt;CAST方法有效提高了点云配准的性能，适用于实时应用。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新颖的点导向Transformer架构，显著提升了点云的匹配效果，解决了传统方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/renlanghuang/cast&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based feature matching has shown great superiority for pointcloud registration in the absence of pose priors. Although coarse-to-finematching approaches are prevalent, the coarse matching of existing methods istypically sparse and loose without consideration of geometric consistency,which makes the subsequent fine matching rely on ineffective optimal transportand hypothesis-and-selection methods for consistency. Therefore, these methodsare neither efficient nor scalable for real-time applications such as odometryin robotics. To address these issues, we design a consistency-aware spot-guidedTransformer (CAST), which incorporates a spot-guided cross-attention module toavoid interfering with irrelevant areas, and a consistency-aware self-attentionmodule to enhance matching capabilities with geometrically consistentcorrespondences. Furthermore, a lightweight fine matching module for bothsparse keypoints and dense features can estimate the transformation accurately.Extensive experiments on both outdoor LiDAR point cloud datasets and indoorRGBD point cloud datasets demonstrate that our method achieves state-of-the-artaccuracy, efficiency, and robustness.</description>
      <author>example@mail.com (Renlang Huang, Yufan Tang, Jiming Chen, Liang Li)</author>
      <guid isPermaLink="false">2410.10295v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>PUMA: Empowering Unified MLLM with Multi-granular Visual Generation</title>
      <link>http://arxiv.org/abs/2410.13861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://rongyaofang.github.io/puma/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，多模态基础模型在视觉语言理解方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;探索多模态大型语言模型（MLLMs）在视觉内容生成中的潜力。&lt;h4&gt;方法&lt;/h4&gt;提出PUMA，通过统一多粒度视觉特征作为MLLMs的输入和输出，解决不同图像生成任务的粒度需求。&lt;h4&gt;主要发现&lt;/h4&gt;PUMA在多模态预训练和任务特定指令调优后，展示了在多种多模态任务中的能力。&lt;h4&gt;结论&lt;/h4&gt;PUMA是实现真正统一的MLLM的重要一步，能够适应不同视觉任务的粒度需求。&lt;h4&gt;代码和模型&lt;/h4&gt;将在https://github.com/rongyaofang/PUMA发布。&lt;h4&gt;总结&lt;/h4&gt;本研究为多模态大语言模型的发展提供了新的思路，特别是在图像生成领域的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/rongyaofang/puma&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multimodal foundation models have yielded significantprogress in vision-language understanding. Initial attempts have also exploredthe potential of multimodal large language models (MLLMs) for visual contentgeneration. However, existing works have insufficiently addressed the varyinggranularity demands of different image generation tasks within a unified MLLMparadigm - from the diversity required in text-to-image generation to theprecise controllability needed in image manipulation. In this work, we proposePUMA, emPowering Unified MLLM with Multi-grAnular visual generation. PUMAunifies multi-granular visual features as both inputs and outputs of MLLMs,elegantly addressing the different granularity requirements of various imagegeneration tasks within a unified MLLM framework. Following multimodalpretraining and task-specific instruction tuning, PUMA demonstrates proficiencyin a wide range of multimodal tasks. This work represents a significant steptowards a truly unified MLLM capable of adapting to the granularity demands ofvarious visual tasks. The code and model will be released inhttps://github.com/rongyaofang/PUMA.</description>
      <author>example@mail.com (Rongyao Fang, Chengqi Duan, Kun Wang, Hao Li, Hao Tian, Xingyu Zeng, Rui Zhao, Jifeng Dai, Hongsheng Li, Xihui Liu)</author>
      <guid isPermaLink="false">2410.13861v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>Sample Compression Hypernetworks: From Generalization Bounds to Meta-Learning</title>
      <link>http://arxiv.org/abs/2410.13577v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the NeurIPS 2024 workshop on Compression in Machine
  Learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;重建函数在样本压缩理论中至关重要，是推导紧致泛化界限的框架。&lt;h4&gt;目的&lt;/h4&gt;提出学习重建函数，以优化和增加信息流的表现力。&lt;h4&gt;方法&lt;/h4&gt;推导一种新的样本压缩泛化界限，适用于实值信息流，并提出一种新的超网络架构。&lt;h4&gt;主要发现&lt;/h4&gt;新架构能够输出具有紧致泛化保证的预测器，并在原始元学习框架下进行训练。&lt;h4&gt;结论&lt;/h4&gt;通过初步实验结果显示，新方法具有潜力。&lt;h4&gt;总结&lt;/h4&gt;研究展示了重建函数的学习与优化在样本压缩中的重要性，并提出了新的理论和架构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstruction functions are pivotal in sample compression theory, aframework for deriving tight generalization bounds. From a small sample of thetraining set (the compression set) and an optional stream of information (themessage), they recover a predictor previously learned from the whole trainingset. While usually fixed, we propose to learn reconstruction functions. Tofacilitate the optimization and increase the expressiveness of the message, wederive a new sample compression generalization bound for real-valued messages.From this theoretical analysis, we then present a new hypernetwork architecturethat outputs predictors with tight generalization guarantees when trained usingan original meta-learning framework. The results of promising preliminaryexperiments are then reported.</description>
      <author>example@mail.com (Benjamin Leblanc, Mathieu Bazinet, Nathaniel D'Amours, Alexandre Drouin, Pascal Germain)</author>
      <guid isPermaLink="false">2410.13577v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
    <item>
      <title>FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning</title>
      <link>http://arxiv.org/abs/2410.13045v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;迁移学习（TL）的性能依赖于有效的预训练，这需要大规模的数据集和大量的计算资源，给模型开发者带来挑战。&lt;h4&gt;目的&lt;/h4&gt;解决迁移学习中的数据集大小和计算资源问题，同时保持隐私。&lt;h4&gt;方法&lt;/h4&gt;提出两个增强策略：1) 引入客户端-服务器交换协议，利用跨客户端雅可比（梯度）范数提升迁移能力；2) 在服务器上增加客户端的平均雅可比范数，作为局部正则化器以减少跨客户端的雅可比方差。&lt;h4&gt;主要发现&lt;/h4&gt;提出的FedGTST算法在多个数据集上表现优越，尤其是在LeNet作为主干网络时，FedGTST在CIFAR10到SVHN的数据对上比FedSR提高了9.8%的准确率。&lt;h4&gt;结论&lt;/h4&gt;通过增加平均雅可比和减少其方差，可以更好地控制目标损失，从而在源损失和源-目标域差异的基础上提供目标损失的上界。&lt;h4&gt;总结&lt;/h4&gt;FedGTST算法在迁移学习中展示了通过联邦学习增强迁移能力的有效性，解决了现有方法中的关键挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The performance of Transfer Learning (TL) heavily relies on effectivepretraining, which demands large datasets and substantial computationalresources. As a result, executing TL is often challenging for individual modeldevelopers. Federated Learning (FL) addresses these issues by facilitatingcollaborations among clients, expanding the dataset indirectly, distributingcomputational costs, and preserving privacy. However, key challenges remainunresolved. First, existing FL methods tend to optimize transferability onlywithin local domains, neglecting the global learning domain. Second, mostapproaches rely on indirect transferability metrics, which do not accuratelyreflect the final target loss or true degree of transferability. To addressthese gaps, we propose two enhancements to FL. First, we introduce aclient-server exchange protocol that leverages cross-client Jacobian (gradient)norms to boost transferability. Second, we increase the average Jacobian normacross clients at the server, using this as a local regularizer to reducecross-client Jacobian variance. Our transferable federated algorithm, termedFedGTST (Federated Global Transferability via Statistics Tuning), demonstratesthat increasing the average Jacobian and reducing its variance allows fortighter control of the target loss. This leads to an upper bound on the targetloss in terms of the source loss and source-target domain discrepancy.Extensive experiments on datasets such as MNIST to MNIST-M and CIFAR10 to SVHNshow that FedGTST outperforms relevant baselines, including FedSR. On thesecond dataset pair, FedGTST improves accuracy by 9.8% over FedSR and 7.6% overFedIIR when LeNet is used as the backbone.</description>
      <author>example@mail.com (Evelyn Ma, Chao Pan, Rasoul Etesami, Han Zhao, Olgica Milenkovic)</author>
      <guid isPermaLink="false">2410.13045v1</guid>
      <pubDate>Fri, 18 Oct 2024 23:02:27 +0800</pubDate>
    </item>
  </channel>
</rss>
