<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
<<<<<<< HEAD
    <lastBuildDate>Sat, 02 Nov 2024 08:43:59 +0800</lastBuildDate>
    <item>
      <title>Analyzing Neural Network Robustness Using Graph Curvature</title>
      <link>http://arxiv.org/abs/2410.19607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文从图论分析的角度探讨神经网络的鲁棒性问题，特别是图曲率。&lt;h4&gt;目的&lt;/h4&gt;定义神经Ricci曲率，以识别在神经网络中用于“传输数据”的瓶颈边。&lt;h4&gt;方法&lt;/h4&gt;通过对MNIST数据集的评估，分析瓶颈边在神经网络中的出现频率。&lt;h4&gt;主要发现&lt;/h4&gt;在神经网络鲁棒性较差的输入情况下，瓶颈边的出现频率更高。&lt;h4&gt;结论&lt;/h4&gt;这些结果为通过最小化瓶颈边数量提供了一种替代的鲁棒训练方法。&lt;h4&gt;总结&lt;/h4&gt;研究表明，图曲率分析能够有效识别神经网络中的瓶颈，进而提升鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a new look at the neural network (NN) robustness problem,from the point of view of graph theory analysis, specifically graph curvature.Graph curvature (e.g., Ricci curvature) has been used to analyze systemdynamics and identify bottlenecks in many domains, including road trafficanalysis and internet routing. We define the notion of neural Ricci curvatureand use it to identify bottleneck NN edges that are heavily used to ``transportdata" to the NN outputs. We provide an evaluation on MNIST that illustratesthat such edges indeed occur more frequently for inputs where NNs are lessrobust. These results will serve as the basis for an alternative method ofrobust training, by minimizing the number of bottleneck edges.</description>
      <author>example@mail.com (Shuhang Tan, Jayson Sia, Paul Bogdan, Radoslav Ivanov)</author>
      <guid isPermaLink="false">2410.19607v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Planning-Aware Diffusion Networks for Enhanced Motion Forecasting in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.19639v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CoRL Workshop Leap 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主驾驶技术取得了显著进展，但现有模型无法充分捕捉多智能体环境的复杂性，动态智能体之间的交互至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出规划集成预测模型（PIFM），以改善多智能体环境下的预测精度和可解释性。&lt;h4&gt;方法&lt;/h4&gt;PIFM灵感来源于大脑中决策和多智能体协调的神经机制，利用丰富的上下文信息，集成道路结构、交通规则和周围车辆的行为，采用基于扩散的架构进行预测。&lt;h4&gt;主要发现&lt;/h4&gt;PIFM能够预测场景中所有智能体的未来轨迹，增强了模型的透明度，与大脑基于外部刺激和其他智能体行为动态调整预测的方法相似。&lt;h4&gt;结论&lt;/h4&gt;大量实验证明，PIFM提供了可解释的、基于神经科学的解决方案，能够实现更安全和高效的自主驾驶系统，并且参数数量极少。&lt;h4&gt;总结&lt;/h4&gt;PIFM是一个创新框架，旨在通过整合多方面信息，提升自主驾驶中的预测能力和透明度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous driving technology has seen significant advancements, but existingmodels often fail to fully capture the complexity of multi-agent environments,where interactions between dynamic agents are critical. To address this, wepropose the Planning-Integrated Forecasting Model (PIFM), a novel frameworkinspired by neural mechanisms governing decision-making and multi-agentcoordination in the brain. PIFM leverages rich contextual information,integrating road structures, traffic rules, and the behavior of surroundingvehicles to improve both the accuracy and interpretability of predictions. Byadopting a diffusion-based architecture, akin to neural diffusion processesinvolved in predicting and planning, PIFM is able to forecast futuretrajectories of all agents within a scenario. This architecture enhances modeltransparency, as it parallels the brain's method of dynamically adjustingpredictions based on external stimuli and other agents'behaviors. Extensiveexperiments validate PIFM's capacity to provide interpretable,neuroscience-driven solutions for safer and more efficient autonomous drivingsystems, with an extremely low number of parameters.</description>
      <author>example@mail.com (Liu Yunhao, Ding Hong, Zhang Ziming, Wang Huixin, Liu Jinzhao, Xi Suyang)</author>
      <guid isPermaLink="false">2410.19639v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Resilience and Scalability in Travel Booking Systems: A Microservices Approach to Fault Tolerance, Load Balancing, and Service Discovery</title>
      <link>http://arxiv.org/abs/2410.19701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统入侵检测系统（IDS）通常依赖于网络流量或进程数据，单一来源的方法可能无法捕捉到跨多个层次的复杂攻击模式。&lt;h4&gt;目的&lt;/h4&gt;研究结合网络和进程数据是否能提高工业控制系统（ICS）环境中的攻击检测能力。&lt;h4&gt;方法&lt;/h4&gt;利用SWaT数据集，评估多种机器学习模型对单一和组合数据源的表现。&lt;h4&gt;主要发现&lt;/h4&gt;整合网络流量和操作过程数据可以增强检测能力，提升网络攻击分类的召回率。&lt;h4&gt;结论&lt;/h4&gt;在有限的测试环境中，这项研究证明了通过多源数据方法推进ICS入侵检测的可行性。&lt;h4&gt;未来工作&lt;/h4&gt;尽管结果令人鼓舞，但仍需在不同数据集和改进方法论的基础上进行进一步研究。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了多源数据在提高ICS入侵检测中的潜力，但结果仍处于初步阶段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the inclusion of microservices architecture in thedevelopment of scalable and reliable airline reservation systems. Most of thetraditional reservation systems are very rigid and centralized which makes themprone to bottlenecks and a single point of failure. As such, systems do notmeet the requirements of modern airlines which are dynamic. Microservices offerbetter resiliency and scalability because the services do not depend on oneanother and can be deployed independently. The approach is grounded on theCircuit Breaker Pattern to maintain fault tolerance while consuming foreignresources such as flight APIs and payment systems. This avoided the failurepropagation to the systems by 60% enabling the systems to function underexternal failures. Traffic rerouting also bolstered this with a guarantee ofabove 99.95% uptime in systems where high availability was demanded. To addressthis, load balancing was used, particularly the Round-Robin method whichmanaged to enhance performance by 35% through the equal distribution of userrequests among the service instances. Health checks, as well as monitoring inreal-time, helped as well with failure management as they helped to containfailures before the users of the system were affected. The results suggest thatthe use of microservices led to a 40% increase in system scalability, a 50%decrease in downtime and a support for 30% more concurrent users than the useof monolithic architectures. These findings affirm the capability ofmicroservices in the development of robust and flexible airline ticket bookingsystems that are responsive to change and recover from external systemunavailability.</description>
      <author>example@mail.com (Biman Barua, M. Shamim Kaiser)</author>
      <guid isPermaLink="false">2410.19701v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhanced Anomaly Detection in Industrial Control Systems aided by Machine Learning</title>
      <link>http://arxiv.org/abs/2410.19717v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, Norwegian Information Security Conference, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统入侵检测系统（IDS）通常依赖于网络流量或进程数据，单一来源的方法可能无法捕捉到跨多个层次的复杂攻击模式。&lt;h4&gt;目的&lt;/h4&gt;研究结合网络和进程数据是否能提高工业控制系统（ICS）环境中的攻击检测能力。&lt;h4&gt;方法&lt;/h4&gt;利用SWaT数据集，评估多种机器学习模型对单一和组合数据源的表现。&lt;h4&gt;主要发现&lt;/h4&gt;整合网络流量和操作过程数据可以增强检测能力，提升网络攻击分类的召回率。&lt;h4&gt;结论&lt;/h4&gt;在有限的测试环境中，这项研究证明了通过多源数据方法推进ICS入侵检测的可行性。&lt;h4&gt;未来工作&lt;/h4&gt;尽管结果令人鼓舞，但仍需在不同数据集和改进方法论的基础上进行进一步研究。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了多源数据在提高ICS入侵检测中的潜力，但结果仍处于初步阶段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional intrusion detection systems (IDSs) often rely on either networktraffic or process data, but this single-source approach may miss complexattack patterns that span multiple layers within industrial control systems(ICSs) or persistent threats that target different layers of operationaltechnology systems. This study investigates whether combining both network andprocess data can improve attack detection in ICSs environments. Leveraging theSWaT dataset, we evaluate various machine learning models on individual andcombined data sources. Our findings suggest that integrating network trafficwith operational process data can enhance detection capabilities, evidenced byimproved recall rates for cyber attack classification. Serving as aproof-of-concept within a limited testing environment, this research exploresthe feasibility of advancing intrusion detection through a multi-source dataapproach in ICSs. Although the results are promising, they are preliminary andhighlight the need for further studies across diverse datasets and refinedmethodologies.</description>
      <author>example@mail.com (Vegard Berge, Chunlei Li)</author>
      <guid isPermaLink="false">2410.19717v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Deep Recurrent Stochastic Configuration Networks for Modelling Nonlinear Dynamic Systems</title>
      <link>http://arxiv.org/abs/2410.20904v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习技术在多个领域应用中展现出潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的深度水库计算框架，称为深度递归随机配置网络（DeepRSCN），用于建模非线性动态系统。&lt;h4&gt;方法&lt;/h4&gt;DeepRSCN逐步构建，所有水库节点直接连接到最终输出。随机参数根据监督机制分配，以确保模型的通用逼近特性。使用投影算法在线更新输出权重，以应对未知动态。&lt;h4&gt;主要发现&lt;/h4&gt;通过一组训练样本，DeepRSCN能够快速生成学习表示，这些表示由随机基函数和级联输入及读取权重组成。实验结果显示，DeepRSCN在时间序列预测、非线性系统识别和工业数据预测分析中，在建模效率、学习能力和泛化性能上优于单层网络。&lt;h4&gt;结论&lt;/h4&gt;DeepRSCN在多个应用场景中表现优越，有望提升非线性动态系统的建模效率和预测能力。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的DeepRSCN框架是对深度学习技术在动态系统建模中的一种有效补充。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning techniques have shown promise in many domain applications. Thispaper proposes a novel deep reservoir computing framework, termed deeprecurrent stochastic configuration network (DeepRSCN) for modelling nonlineardynamic systems. DeepRSCNs are incrementally constructed, with all reservoirnodes directly linked to the final output. The random parameters are assignedin the light of a supervisory mechanism, ensuring the universal approximationproperty of the built model. The output weights are updated online using theprojection algorithm to handle the unknown dynamics. Given a set of trainingsamples, DeepRSCNs can quickly generate learning representations, which consistof random basis functions with cascaded input and readout weights. Experimentalresults over a time series prediction, a nonlinear system identificationproblem, and two industrial data predictive analyses demonstrate that theproposed DeepRSCN outperforms the single-layer network in terms of modellingefficiency, learning capability, and generalization performance.</description>
      <author>example@mail.com (Gang Dang, Dianhui Wang)</author>
      <guid isPermaLink="false">2410.20904v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Urban Mobility: AI, ODE-Based Modeling, and Scenario Planning</title>
      <link>http://arxiv.org/abs/2410.19915v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;城市化和技术进步正在重新塑造城市交通的未来，带来了挑战和机遇。&lt;h4&gt;目的&lt;/h4&gt;探讨人工智能驱动的技术如何改变交通系统。&lt;h4&gt;方法&lt;/h4&gt;结合前瞻性研究、情景规划和使用常微分方程（ODE）进行数学建模。&lt;h4&gt;主要发现&lt;/h4&gt;通过Python模拟的ODE模型量化了AI创新（如自动驾驶车辆和智能交通管理）在不同监管条件下对缓解交通拥堵的影响。&lt;h4&gt;结论&lt;/h4&gt;ODE模型揭示了AI采纳率与交通拥堵之间的动态关系，为未来情景提供了定量见解。&lt;h4&gt;应用&lt;/h4&gt;通过行业合作和案例研究，为企业和政策制定者提供在这一不断变化的环境中导航的战略指导。&lt;h4&gt;总结&lt;/h4&gt;本研究有助于理解如何通过AI采纳促进更加高效、可持续和宜居城市的策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urbanization and technological advancements are reshaping the future of urbanmobility, presenting both challenges and opportunities. This paper combinesforesight and scenario planning with mathematical modeling using OrdinaryDifferential Equations (ODEs) to explore how Artificial Intelligence(AI)-driven technologies can transform transportation systems. By simulatingODE-based models in Python, we quantify the impact of AI innovations, such asautonomous vehicles and intelligent traffic management, on reducing trafficcongestion under different regulatory conditions.  Our ODE models capture the dynamic relationship between AI adoption rates andtraffic congestion, providing quantitative insights into how future scenariosmight unfold. By incorporating industry collaborations and case studies, weoffer strategic guidance for businesses and policymakers navigating thisevolving landscape. This study contributes to understanding how foresight,scenario planning, and ODE modeling can inform strategies for creating moreefficient, sustainable, and livable cities through AI adoption.</description>
      <author>example@mail.com (Katsiaryna Bahamazava)</author>
      <guid isPermaLink="false">2410.19915v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Less is More: Efficient Time Series Dataset Condensation via Two-fold Modal Matching--Extended Version</title>
      <link>http://arxiv.org/abs/2410.20905v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by PVLDB 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社会各个领域中传感器的扩展使得时间序列数据大量增加，这为交通基础设施和电网等重要应用提供了可能。&lt;h4&gt;目的&lt;/h4&gt;减少从时间序列数据中提取价值所需的计算和存储成本。&lt;h4&gt;方法&lt;/h4&gt;提出了一种时间序列数据集压缩框架TimeDC，采用双重模式匹配，包括频率匹配和训练轨迹匹配。&lt;h4&gt;主要发现&lt;/h4&gt;TimeDC通过特征提取和分解驱动的频率匹配，保留了压缩时间序列中的复杂时间依赖性。&lt;h4&gt;结论&lt;/h4&gt;TimeDC通过课程训练轨迹匹配确保了有效和通用的时间序列数据集压缩，并通过专家缓冲区避免内存溢出。&lt;h4&gt;总结&lt;/h4&gt;对真实数据的广泛实验展示了所提解决方案的有效性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The expanding instrumentation of processes throughout society with sensorsyields a proliferation of time series data that may in turn enable importantapplications, e.g., related to transportation infrastructures or power grids.Machine-learning based methods are increasingly being used to extract valuefrom such data. We provide means of reducing the resulting considerablecomputational and data storage costs. We achieve this by providing means ofcondensing large time series datasets such that models trained on the condenseddata achieve performance comparable to those trained on the original, largedata. Specifically, we propose a time series dataset condensation framework,TimeDC, that employs two-fold modal matching, encompassing frequency matchingand training trajectory matching. Thus, TimeDC performs time series featureextraction and decomposition-driven frequency matching to preserve complextemporal dependencies in the reduced time series. Further, TimeDC employscurriculum training trajectory matching to ensure effective and generalizedtime series dataset condensation. To avoid memory overflow and to reduce thecost of dataset condensation, the framework includes an expert buffer storingpre-computed expert trajectories. Extensive experiments on real data offerinsight into the effectiveness and efficiency of the proposed solutions.</description>
      <author>example@mail.com (Hao Miao, Ziqiao Liu, Yan Zhao, Chenjuan Guo, Bin Yang, Kai Zheng, Christian S. Jensen)</author>
      <guid isPermaLink="false">2410.20905v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SFTrack: A Robust Scale and Motion Adaptive Algorithm for Tracking Small and Fast Moving Objects</title>
      <link>http://arxiv.org/abs/2410.20079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IROS 2024 selected Oral&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文讨论了无人机视频中的多目标跟踪问题，该问题在交通监控和实时嫌疑人追踪等无人机应用中至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单但更有效的方法来克服无人机跟踪中的挑战。&lt;h4&gt;方法&lt;/h4&gt;引入新的跟踪策略，从低置信度检测开始跟踪目标，并改进传统基于外观的匹配算法以提高低置信度检测的关联性。&lt;h4&gt;主要发现&lt;/h4&gt;在两个无人机特定数据集（VisDrone2019、UAVDT）和一个通用目标跟踪数据集（MOT17）上进行基准评估，结果表明该方法优于现有的先进技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在多种跟踪环境中展现了较高的鲁棒性和适应性。&lt;h4&gt;数据集改进&lt;/h4&gt;改善了UAVDT数据集的标注，修正了原始标注中的错误和遗漏，并将提供改进后的数据集以促进更好的基准测试。&lt;h4&gt;总结&lt;/h4&gt;本文提出的多目标跟踪方法在无人机监控应用中表现优异，为相关领域的研究提供了新的数据支持和参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the problem of multi-object tracking in Unmanned AerialVehicle (UAV) footage. It plays a critical role in various UAV applications,including traffic monitoring systems and real-time suspect tracking by thepolice. However, this task is highly challenging due to the fast motion ofUAVs, as well as the small size of target objects in the videos caused by thehigh-altitude and wide angle views of drones. In this study, we thus introducea simple yet more effective method compared to previous work to overcome thesechallenges. Our approach involves a new tracking strategy, which initiates thetracking of target objects from low-confidence detections commonly encounteredin UAV application scenarios. Additionally, we propose revisiting traditionalappearance-based matching algorithms to improve the association oflow-confidence detections. To evaluate the effectiveness of our method, weconducted benchmark evaluations on two UAV-specific datasets (VisDrone2019,UAVDT) and one general object tracking dataset (MOT17). The results demonstratethat our approach surpasses current state-of-the art methodologies,highlighting its robustness and adaptability in diverse tracking environments.Furthermore, we have improved the annotation of the UAVDT dataset by rectifyingseveral errors and addressing omissions found in the original annotations. Wewill provide this refined version of the dataset to facilitate betterbenchmarking in the field.</description>
      <author>example@mail.com (InPyo Song, Jangwon Lee)</author>
      <guid isPermaLink="false">2410.20079v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FACTS: A Factored State-Space Framework For World Modelling</title>
      <link>http://arxiv.org/abs/2410.20922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code released in https://github.com/NanboLi/FACTS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;世界建模对于理解和预测复杂系统的动态至关重要，需要学习空间和时间的依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的递归框架FACTS模型，以解决现有框架在高维序列建模中的局限性。&lt;h4&gt;方法&lt;/h4&gt;FACTS模型构建了一个图结构的记忆，通过路由机制学习可排列的记忆表示，并通过选择性状态空间传播进行适应。&lt;h4&gt;主要发现&lt;/h4&gt;FACTS在多元时间序列预测和以对象为中心的世界建模等多种任务中表现优异，始终超越或匹配专用的最先进模型。&lt;h4&gt;结论&lt;/h4&gt;尽管FACTS是一个通用的世界建模设计，但其性能在多样化任务中表现出色。&lt;h4&gt;总结&lt;/h4&gt;FACTS模型有效解决了长时间高维序列建模的挑战，展示了其在复杂系统建模中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nanboli/facts&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; World modelling is essential for understanding and predicting the dynamics ofcomplex systems by learning both spatial and temporal dependencies. However,current frameworks, such as Transformers and selective state-space models likeMambas, exhibit limitations in efficiently encoding spatial and temporalstructures, particularly in scenarios requiring long-term high-dimensionalsequence modelling. To address these issues, we propose a novel recurrentframework, the \textbf{FACT}ored \textbf{S}tate-space (\textbf{FACTS}) model,for spatial-temporal world modelling. The FACTS framework constructs agraph-structured memory with a routing mechanism that learns permutable memoryrepresentations, ensuring invariance to input permutations while adaptingthrough selective state-space propagation. Furthermore, FACTS supports parallelcomputation of high-dimensional sequences. We empirically evaluate FACTS acrossdiverse tasks, including multivariate time series forecasting andobject-centric world modelling, demonstrating that it consistently outperformsor matches specialised state-of-the-art models, despite its general-purposeworld modelling design.</description>
      <author>example@mail.com (Li Nanbo, Firas Laakom, Yucheng Xu, Wenyi Wang, Jürgen Schmidhuber)</author>
      <guid isPermaLink="false">2410.20922v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SmartX Intelligent Sec: A Security Framework Based on Machine Learning and eBPF/XDP</title>
      <link>http://arxiv.org/abs/2410.20244v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;信息与通信技术基础设施日益复杂，面临众多挑战，尤其是在支持最新网络范式方面。&lt;h4&gt;目的&lt;/h4&gt;提出一种创新的智能安全框架SmartX Intelligent Sec，以应对当前网络安全挑战。&lt;h4&gt;方法&lt;/h4&gt;SmartX Intelligent Sec结合轻量级扩展伯克利数据包过滤器/eXpress DataPath (eBPF/XDP)进行高效的网络数据包捕获和恶意网络流量过滤，并使用双向长短期记忆（BiLSTM）分类器进行网络威胁检测。&lt;h4&gt;主要发现&lt;/h4&gt;实时原型展示了SmartX Intelligent Sec的全面自动化特性，能够持续捕获网络数据包，有效检测网络威胁，并高效过滤恶意网络流量。&lt;h4&gt;结论&lt;/h4&gt;该框架确保了现代信息与通信技术基础设施的安全性和操作效率。&lt;h4&gt;总结&lt;/h4&gt;SmartX Intelligent Sec是一个创新的智能安全解决方案，能够提升网络安全和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Information and Communication Technologies (ICT) infrastructures are becomingincreasingly complex day by day, facing numerous challenges to support thelatest networking paradigms. Security is undeniably a critical component forthe effective functioning of these advanced ICT infrastructures. By consideringthe current network security challenges, we propose SmartX Intelligent Sec, aninnovative intelligent security framework. SmartX Intelligent Sec leverages acombination of the lightweight extended Berkeley Packet Filter/eXpress DataPath (eBPF/XDP) for efficient network packet capturing and filtering maliciousnetwork traffic, and a Bidirectional Long Short-Term Memory (BiLSTM) classifierfor network threat detection. Our real-time prototype demonstrates that SmartXIntelligent Sec offers comprehensive automation features, enabling continuousnetwork packet capturing, effective network threat detection, and efficientfiltering of malicious network traffic. This framework ensures enhancedsecurity and operational efficiency for modern ICT infrastructures.</description>
      <author>example@mail.com (Talaya Farasat, JongWon Kim, Joachim Posegga)</author>
      <guid isPermaLink="false">2410.20244v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SoftCTRL: Soft conservative KL-control of Transformer Reinforcement Learning for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.22752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to IEEE Open Journal of Intelligent Transportation Systems&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，城市自驾车的运动规划成为一个热门问题，涉及道路组件的复杂交互。&lt;h4&gt;目的&lt;/h4&gt;解决运动规划中的安全性和可靠性问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种结合模仿学习（IL）和强化学习（RL）的方法，通过隐式熵-KL控制来减少IL的过度保守特性。&lt;h4&gt;主要发现&lt;/h4&gt;在未见数据集的不同挑战性城市模拟场景中，虽然IL在模仿任务中表现良好，但提出的方法显著提高了鲁棒性（失败率减少超过17%）并生成了类人驾驶行为。&lt;h4&gt;结论&lt;/h4&gt;结合IL与RL的方法有效改善了自驾车的运动规划能力，提升了安全性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种有效的运动规划解决方案，克服了纯IL方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, motion planning for urban self-driving cars (SDV) has becomea popular problem due to its complex interaction of road components. To tacklethis, many methods have relied on large-scale, human-sampled data processedthrough Imitation learning (IL). Although effective, IL alone cannot adequatelyhandle safety and reliability concerns. Combining IL with Reinforcementlearning (RL) by adding KL divergence between RL and IL policy to the RL losscan alleviate IL's weakness but suffer from over-conservation caused bycovariate shift of IL. To address this limitation, we introduce a method thatcombines IL with RL using an implicit entropy-KL control that offers a simpleway to reduce the over-conservation characteristic. In particular, we validatedifferent challenging simulated urban scenarios from the unseen dataset,indicating that although IL can perform well in imitation tasks, our proposedmethod significantly improves robustness (over 17\% reduction in failures) andgenerates human-like driving behavior.</description>
      <author>example@mail.com (Minh Tri Huynh, Duc Dung Nguyen)</author>
      <guid isPermaLink="false">2410.22752v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Federated Time Series Generation on Feature and Temporally Misaligned Data</title>
      <link>http://arxiv.org/abs/2410.21072v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;分布式时间序列数据在联邦学习中面临挑战，因客户端特征集不同且时间步对齐不一致。&lt;h4&gt;目的&lt;/h4&gt;提出FedTDD，一种新颖的联邦时间序列扩散模型，旨在跨客户端联合学习合成器。&lt;h4&gt;方法&lt;/h4&gt;FedTDD采用新型数据蒸馏与聚合框架，通过填补不对齐的时间步和特征来调和客户端之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;FedTDD通过交换本地合成输出而非模型参数来学习客户端时间序列之间的相关性，实验结果显示其在五个数据集上的有效性。&lt;h4&gt;结论&lt;/h4&gt;FedTDD在Context-FID和相关性分数上相较于本地训练分别提高了79.4%和62.8%的性能。&lt;h4&gt;总结&lt;/h4&gt;FedTDD有效地通过共享合成输出实现了本地时间序列知识的转移，提升了客户端的本地数据填补质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed time series data presents a challenge for federated learning, asclients often possess different feature sets and have misaligned time steps.Existing federated time series models are limited by the assumption of perfecttemporal or feature alignment across clients. In this paper, we propose FedTDD,a novel federated time series diffusion model that jointly learns a synthesizeracross clients. At the core of FedTDD is a novel data distillation andaggregation framework that reconciles the differences between clients byimputing the misaligned timesteps and features. In contrast to traditionalfederated learning, FedTDD learns the correlation across clients' time seriesthrough the exchange of local synthetic outputs instead of model parameters. Acoordinator iteratively improves a global distiller network by leveragingshared knowledge from clients through the exchange of synthetic data. As thedistiller becomes more refined over time, it subsequently enhances the qualityof the clients' local feature estimates, allowing each client to then improveits local imputations for missing data using the latest, more accuratedistiller. Experimental results on five datasets demonstrate FedTDD'seffectiveness compared to centralized training, and the effectiveness ofsharing synthetic outputs to transfer knowledge of local time series. Notably,FedTDD achieves 79.4% and 62.8% improvement over local training in Context-FIDand Correlational scores.</description>
      <author>example@mail.com (Chenrui Fan, Zhi Wen Soi, Aditya Shankar, Abele Mălan, Lydia Y. Chen)</author>
      <guid isPermaLink="false">2410.21072v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Who is Responsible? Explaining Safety Violations in Multi-Agent Cyber-Physical Systems</title>
      <link>http://arxiv.org/abs/2410.20288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多智能体网络物理系统在多种应用中存在，智能体决策可能因不确定的动态操作环境或错误行为受到影响。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化程序，以原则性方式将安全违规的责任分配给单个智能体的行为。&lt;h4&gt;方法&lt;/h4&gt;基于道路安全中的安全违规推理，使用反事实推理创建替代场景，介绍每个智能体的责任度（DoR）指标，并利用Shapley值量化各智能体对安全违规的贡献。&lt;h4&gt;主要发现&lt;/h4&gt;责任度（DoR）提高了决策的可解释性和智能体行为及其后果的问责性。&lt;h4&gt;结论&lt;/h4&gt;自动化责任分配策略显著减少了人力劳动和认知负担，并在智能体数量增加时通过启发式技术和方法提高了可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自动化方法来评估智能体在安全违规中的责任，能够有效提升决策的透明度和责任感。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-agent cyber-physical systems are present in a variety of applications.Agent decision-making can be affected due to errors induced by uncertain,dynamic operating environments or due to incorrect actions taken by an agent.When an erroneous decision that leads to a violation of safety is identified,assigning responsibility to individual agents is a key step toward preventingfuture accidents. Current approaches to carrying out such investigationsrequire human labor or high degree of familiarity with operating environments.Automated strategies to assign responsibility can achieve a significantreduction in human effort and associated cognitive burden. In this paper, wedevelop an automated procedure to assign responsibility for safety violationsto actions of any single agent in a principled manner. We base our approach onreasoning about safety violations in road safety. Given a safety violation, weuse counterfactual reasoning to create alternative scenarios, showing howdifferent outcomes could have occurred if certain actions had been replaced byothers. We introduce the degree of responsibility (DoR) metric for each agent.The DoR, using the Shapley value, quantifies each agent's contribution to thesafety violation, providing a basis to explain and justify decisions. We alsodevelop heuristic techniques and methods based on agent interaction structuresto improve scalability as agent numbers grow. We examine three safety violationcases from the National Highway Traffic Safety Administration (NHTSA). We runexperiments using CARLA urban driving simulator. Results show the DoR improvesthe explainability of decisions and accountability for agent actions and theirconsequences.</description>
      <author>example@mail.com (Luyao Niu, Hongchao Zhang, Dinuka Sahabandu, Bhaskar Ramasubramanian, Andrew Clark, Radha Poovendran)</author>
      <guid isPermaLink="false">2410.20288v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Tool Manipulation of An Aerial Vehicle with A Dynamically Displacing Center-of-Mass</title>
      <link>http://arxiv.org/abs/2410.22816v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2404.01110&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着航空机器人在工业应用中的普及，增强其物理交互能力的需求日益增加。&lt;h4&gt;目的&lt;/h4&gt;提高航空机器人在推动任务中的力生成能力，以支持更复杂的工业应用。&lt;h4&gt;方法&lt;/h4&gt;基于之前的工作，提出了一种优化重心位置的创新方法，以增强交互过程中的力生成。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟验证了所提方法的有效性，显示该系统在实际环境中进行高级航空操作的潜力。&lt;h4&gt;结论&lt;/h4&gt;该系统的设计能够支持更高自由度的操作，并有效执行工具基础的任务。&lt;h4&gt;总结&lt;/h4&gt;优化重心位置的策略为航空操控提供了新的可能性，适用于工业领域的多种复杂任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As aerial robots gain traction in industrial applications, there is growinginterest in enhancing their physical interaction capabilities. Pushing tasksperformed by aerial manipulators have been successfully demonstrated incontact-based inspections. However, more complex industrial applicationsrequire these systems to support higher-DoF (Degree of Freedom) manipulatorsand generate larger forces while pushing (e.g., drilling, grinding). This paperbuilds on our previous work, where we introduced an aerial vehicle with adynamically displacing CoM (Center of Mass) to improve force exertion duringinteractions. We propose a novel approach to further enhance this system'sforce generation by optimizing its CoM location during interactions.Additionally, we study the case of this aerial vehicle equipped with a 2-DoFmanipulation arm to extend the system's functionality in tool-based tasks. Theeffectiveness of the proposed methods is validated through simulations,demonstrating the potential of this system for advanced aerial manipulation inpractical settings.</description>
      <author>example@mail.com (Tong Hui, Matteo Fumagalli)</author>
      <guid isPermaLink="false">2410.22816v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Trajectory Flow Matching with Applications to Clinical Time Series Modeling</title>
      <link>http://arxiv.org/abs/2410.21154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Spotlight&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;建模随机和不规则采样的时间序列是一项具有挑战性的任务，广泛应用于医学等领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来训练神经随机微分方程（Neural SDEs），以解决当前算法的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出轨迹流匹配（Trajectory Flow Matching，TFM）方法，以无模拟的方式训练Neural SDE，避免通过动态回传。&lt;h4&gt;主要发现&lt;/h4&gt;TFM能够有效学习时间序列数据，并通过重参数化技巧提高训练稳定性，在临床时间序列设置中表现出色。&lt;h4&gt;结论&lt;/h4&gt;TFM在三个临床时间序列数据集上显示了改进的性能和不确定性预测能力。&lt;h4&gt;总结&lt;/h4&gt;TFM为处理随机和不规则采样的时间序列提供了一种新的有效方法，具有重要的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nzhangx/trajectoryflowmatching&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling stochastic and irregularly sampled time series is a challengingproblem found in a wide range of applications, especially in medicine. Neuralstochastic differential equations (Neural SDEs) are an attractive modelingtechnique for this problem, which parameterize the drift and diffusion terms ofan SDE with neural networks. However, current algorithms for training NeuralSDEs require backpropagation through the SDE dynamics, greatly limiting theirscalability and stability. To address this, we propose Trajectory Flow Matching(TFM), which trains a Neural SDE in a simulation-free manner, bypassingbackpropagation through the dynamics. TFM leverages the flow matching techniquefrom generative modeling to model time series. In this work we first establishnecessary conditions for TFM to learn time series data. Next, we present areparameterization trick which improves training stability. Finally, we adaptTFM to the clinical time series setting, demonstrating improved performance onthree clinical time series datasets both in terms of absolute performance anduncertainty prediction.</description>
      <author>example@mail.com (Xi Zhang, Yuan Pu, Yuki Kawamura, Andrew Loza, Yoshua Bengio, Dennis L. Shung, Alexander Tong)</author>
      <guid isPermaLink="false">2410.21154v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Sebica: Lightweight Spatial and Efficient Bidirectional Channel Attention Super Resolution Network</title>
      <link>http://arxiv.org/abs/2410.20546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures, 26 conferences&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;单幅图像超分辨率(SISR)是提高低分辨率图像视觉质量的重要技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种轻量级网络Sebica，以解决资源有限或时间敏感环境下的计算挑战。&lt;h4&gt;方法&lt;/h4&gt;Sebica结合空间和高效的双向通道注意机制，旨在降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;Sebica在Div2K和Flickr2K数据集上的PSNR/SSIM分别为28.29/0.7976和30.18/0.8330，超越大多数基线轻量级模型，且与最高性能模型相当，但参数和GFLOPs分别仅为17%和15%。&lt;h4&gt;结论&lt;/h4&gt;Sebica的小版本仅有7.9K参数和0.41 GFLOPS，分别为最高性能模型参数和GFLOPs的3%，在Flickr2K数据集上仍能达到28.12/0.7931和0.3009/0.8317的PSNR和SSIM指标。&lt;h4&gt;应用&lt;/h4&gt;Sebica在实际应用中显示了显著改进，特别是在交通视频场景的目标检测任务中，提高了检测准确性。&lt;h4&gt;总结&lt;/h4&gt;Sebica是一种高效的超分辨率网络，适合于计算资源有限的环境，同时在多个指标上表现优异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/idiosyncracies/Sebica&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Single Image Super-Resolution (SISR) is a vital technique for improving thevisual quality of low-resolution images. While recent deep learning models havemade significant advancements in SISR, they often encounter computationalchallenges that hinder their deployment in resource-limited or time-sensitiveenvironments. To overcome these issues, we present Sebica, a lightweightnetwork that incorporates spatial and efficient bidirectional channel attentionmechanisms. Sebica significantly reduces computational costs while maintaininghigh reconstruction quality, achieving PSNR/SSIM scores of 28.29/0.7976 and30.18/0.8330 on the Div2K and Flickr2K datasets, respectively. These resultssurpass most baseline lightweight models and are comparable to thehighest-performing model, but with only 17% and 15% of the parameters andGFLOPs. Additionally, our small version of Sebica has only 7.9K parameters and0.41 GFLOPS, representing just 3% of the parameters and GFLOPs of thehighest-performing model, while still achieving PSNR and SSIM metrics of28.12/0.7931 and 0.3009/0.8317, on the Flickr2K dataset respectively. Inaddition, Sebica demonstrates significant improvements in real-worldapplications, specifically in object detection tasks, where it enhancesdetection accuracy in traffic video scenarios.</description>
      <author>example@mail.com (Chongxiao Liu)</author>
      <guid isPermaLink="false">2410.20546v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Grasping Force Estimation for Markerless Visuotactile Sensors</title>
      <link>http://arxiv.org/abs/2410.22825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;触觉传感器在力估计方面的应用日益增多，尤其是基于视觉的触觉传感器（VBTS），因其高空间分辨率和低成本而成为新趋势。&lt;h4&gt;目的&lt;/h4&gt;设计和实施多种方法，通过不同的无标记视觉触觉表现来估计正常抓取力。&lt;h4&gt;方法&lt;/h4&gt;通过对比分析在机器人抓取任务中的性能，确定最合适的视觉触觉表现。使用了DIGIT传感器和GelSight Mini传感器生成的数据集进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;RGB视觉触觉表现比深度图像或两者组合更适合估计正常抓取力。RGBmod在10个未见过的日常物体上测试表现良好，平均相对误差为0.125 ± 0.153。&lt;h4&gt;结论&lt;/h4&gt;我们的方案在使用RGB和深度信息进行相同任务的文献中表现优越。&lt;h4&gt;总结&lt;/h4&gt;本研究显示RGB视觉触觉表现的优势，以及RGBmod在实际场景中的良好泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/JSEN.2024.3489052&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tactile sensors have been used for force estimation in the past, especiallyVision-Based Tactile Sensors (VBTS) have recently become a new trend due totheir high spatial resolution and low cost. In this work, we have designed andimplemented several approaches to estimate the normal grasping force usingdifferent types of markerless visuotactile representations obtained from VBTS.Our main goal is to determine the most appropriate visuotactile representation,based on a performance analysis during robotic grasping tasks. Our proposal hasbeen tested on the dataset generated with our DIGIT sensors and another oneobtained using GelSight Mini sensors from another state-of-the-art work. Wehave also tested the generalization capabilities of our best approach, calledRGBmod. The results led to two main conclusions. First, the RGB visuotactilerepresentation is a better input option than the depth image or a combinationof the two for estimating normal grasping forces. Second, RGBmod achieved agood performance when tested on 10 unseen everyday objects in real-worldscenarios, achieving an average relative error of 0.125 +- 0.153. Furthermore,we show that our proposal outperforms other works in the literature that useRGB and depth information for the same task.</description>
      <author>example@mail.com (Julio Castaño-Amoros, Pablo Gil)</author>
      <guid isPermaLink="false">2410.22825v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SeriesGAN: Time Series Generation via Adversarial and Autoregressive Learning</title>
      <link>http://arxiv.org/abs/2410.21203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted at BigData 2024 on October 26, 2024, as a
  regular paper for oral presentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前基于生成对抗网络（GAN）的时间序列生成方法面临收敛不佳、嵌入空间信息损失和不稳定性等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种先进框架，以克服上述挑战，结合自编码器生成的嵌入空间优势和GAN的对抗训练动态。&lt;h4&gt;方法&lt;/h4&gt;该方法采用两个判别器，一个专门指导生成器，另一个用于优化自编码器和生成器的输出。同时，引入了一种新型自编码器基础损失函数和教师强制监督网络，捕捉数据的逐步条件分布。&lt;h4&gt;主要发现&lt;/h4&gt;生成器在潜在空间中操作，而两个判别器分别在潜在和特征空间中工作，提供关键反馈，最小化嵌入空间的信息损失。&lt;h4&gt;结论&lt;/h4&gt;通过联合训练，该框架在生成高保真时间序列数据方面表现出色，在多种真实和合成的多变量时间序列数据集上，定性和定量地超越现有的最先进基准。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的框架有效解决了GAN在时间序列生成中的主要问题，显著提升了生成数据的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/samresume/seriesgan&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current Generative Adversarial Network (GAN)-based approaches for time seriesgeneration face challenges such as suboptimal convergence, information loss inembedding spaces, and instability. To overcome these challenges, we introducean advanced framework that integrates the advantages of anautoencoder-generated embedding space with the adversarial training dynamics ofGANs. This method employs two discriminators: one to specifically guide thegenerator and another to refine both the autoencoder's and generator's output.Additionally, our framework incorporates a novel autoencoder-based lossfunction and supervision from a teacher-forcing supervisor network, whichcaptures the stepwise conditional distributions of the data. The generatoroperates within the latent space, while the two discriminators work on latentand feature spaces separately, providing crucial feedback to both the generatorand the autoencoder. By leveraging this dual-discriminator approach, weminimize information loss in the embedding space. Through joint training, ourframework excels at generating high-fidelity time series data, consistentlyoutperforming existing state-of-the-art benchmarks both qualitatively andquantitatively across a range of real and synthetic multivariate time seriesdatasets.</description>
      <author>example@mail.com (MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi)</author>
      <guid isPermaLink="false">2410.21203v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Non-contact Dexterous Micromanipulation with Multiple Optoelectronic Robots</title>
      <link>http://arxiv.org/abs/2410.22848v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;微操控系统利用自动化和机器人技术提高微观任务的精度、重复性和效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的非接触微操控方法，以克服当前方法在特定对象或任务上的局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法基于光电技术，利用光电场中产生的排斥性介电泳力驱动微型机器人，实现目标物体的非接触操控。&lt;h4&gt;主要发现&lt;/h4&gt;非接触特性降低了潜在损害、污染或粘附的风险，同时显著提高了操控的灵活性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法为多种微观对象和任务提供了一种通用且灵活的解决方案，减少了对专用工具的需求。&lt;h4&gt;实验&lt;/h4&gt;进行了非接触轨迹跟踪、避障以及多微型机器人间相互避让的模拟和实验证明该方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种创新的微操控技术，具有广泛应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Micromanipulation systems leverage automation and robotic technologies toimprove the precision, repeatability, and efficiency of various tasks at themicroscale. However, current approaches are typically limited to specificobjects or tasks, which necessitates the use of custom tools and specializedgrasping methods. This paper proposes a novel non-contact micromanipulationmethod based on optoelectronic technologies. The proposed method utilizesrepulsive dielectrophoretic forces generated in the optoelectronic field todrive a microrobot, enabling the microrobot to push the target object in acluttered environment without physical contact. The non-contact feature canminimize the risks of potential damage, contamination, or adhesion whilelargely improving the flexibility of manipulation. The feature enables the useof a general tool for indirect object manipulation, eliminating the need forspecialized tools. A series of simulation studies and real-world experiments --including non-contact trajectory tracking, obstacle avoidance, and reciprocalavoidance between multiple microrobots -- are conducted to validate theperformance of the proposed method. The proposed formulation provides a generaland dexterous solution for a range of objects and tasks at the micro scale.</description>
      <author>example@mail.com (Yongyi Jia, Shu Miao, Ao Wang, Caiding Ni, Lin Feng, Xiaowo Wang, Xiang Li)</author>
      <guid isPermaLink="false">2410.22848v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Neural Operators for Adaptive Control of Freeway Traffic</title>
      <link>http://arxiv.org/abs/2410.20708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类驾驶行为中的不确定性和反应延迟导致高速公路上的停走交通拥堵。&lt;h4&gt;目的&lt;/h4&gt;提出基于神经算子的自适应边界控制设计，以解决具有不确定空间变化系数和边界参数的耦合2x2双曲系统的自适应交通控制问题。&lt;h4&gt;方法&lt;/h4&gt;采用DeepONet进行算子学习，学习系统参数与核函数之间的映射，从而克服传统PDE自适应控制中在线求解反步核的高计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;DeepONet在生成核函数方面比传统PDE求解器快近两个数量级，同时保持损失在$10^{-3}$的数量级。&lt;h4&gt;结论&lt;/h4&gt;DeepONet在近似PDE反步设计中表现出强大的潜力，能够有效提高计算效率。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了使用DeepONet进行高速公路交通控制的有效性，为解决交通拥堵问题提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Uncertainty and delayed reactions in human driving behavior lead tostop-and-go traffic congestion on freeways. The freeway traffic dynamics aregoverned by the Aw-Rascle-Zhang (ARZ) traffic Partial Differential Equation(PDE) models with unknown relaxation time. Motivated by the adaptive trafficcontrol problem, this paper presents a neural operator (NO) based adaptiveboundary control design for the coupled 2$\times$2 hyperbolic systems withuncertain spatially varying in-domain coefficients and boundary parameter. Intraditional adaptive control for PDEs, solving backstepping kernel online iscomputationally intensive, as it requires significant resources at each timestep to update the estimation of coefficients. To address this challenge, weuse operator learning, i.e. DeepONet, to learn the mapping from systemparameters to the kernels functions. DeepONet, a class of deep neural networksdesigned for approximating operators, has shown strong potential forapproximating PDE backstepping designs in recent studies. Unlike previous worksthat focus on approximating single kernel equation associated with the scalarPDE system, we extend this framework to approximate PDE kernels for a class ofthe first-order coupled 2$\times$2 hyperbolic kernel equations. Our approachdemonstrates that DeepONet is nearly two orders of magnitude faster thantraditional PDE solvers for generating kernel functions, while maintaining aloss on the order of $10^{-3}$.</description>
      <author>example@mail.com (Kaijing Lv, Junmin Wang, Yihuai Zhang, Huan Yu)</author>
      <guid isPermaLink="false">2410.20708v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Reconstructing dynamics from sparse observations with no training on target system</title>
      <link>http://arxiv.org/abs/2410.21222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 21 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;系统可能面临前所未有的情况，仅能进行稀疏观察。&lt;h4&gt;目的&lt;/h4&gt;探讨如何在没有训练数据的情况下，从有限的观察中重建系统的动态。&lt;h4&gt;方法&lt;/h4&gt;开发了一种混合变换器和水库计算的机器学习方案，利用已知混沌系统的合成数据训练变换器。&lt;h4&gt;主要发现&lt;/h4&gt;即使可用数据仅为所需的20%，也能高精度重建复杂和非线性动态。&lt;h4&gt;结论&lt;/h4&gt;提出的混合机器学习框架为在缺乏训练数据和稀疏观察的极端情况下重建复杂动态提供了新思路。&lt;h4&gt;总结&lt;/h4&gt;该方法有效应对传统非线性时间序列分析及机器学习方法无法解决的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In applications, an anticipated situation is where the system of interest hasnever been encountered before and sparse observations can be made only once.Can the dynamics be faithfully reconstructed from the limited observationswithout any training data? This problem defies any known traditional methods ofnonlinear time-series analysis as well as existing machine-learning methodsthat typically require extensive data from the target system for training. Weaddress this challenge by developing a hybrid transformer andreservoir-computing machine-learning scheme. The key idea is that, for acomplex and nonlinear target system, the training of the transformer can beconducted not using any data from the target system, but with essentiallyunlimited synthetic data from known chaotic systems. The trained transformer isthen tested with the sparse data from the target system. The output of thetransformer is further fed into a reservoir computer for predicting thelong-term dynamics or the attractor of the target system. The power of theproposed hybrid machine-learning framework is demonstrated using a large numberof prototypical nonlinear dynamical systems, with high reconstruction accuracyeven when the available data is only 20% of that required to faithfullyrepresent the dynamical behavior of the underlying system. The frameworkprovides a paradigm of reconstructing complex and nonlinear dynamics in theextreme situation where training data does not exist and the observations arerandom and sparse.</description>
      <author>example@mail.com (Zheng-Meng Zhai, Jun-Yin Huang, Benjamin D. Stern, Ying-Cheng Lai)</author>
      <guid isPermaLink="false">2410.21222v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Human-inspired Grasping Strategies of Fresh Fruits and Vegetables Applied to Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2410.22893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  *Authors contributed equally&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新鲜水果和蔬菜的机器人操作，尤其是抓取多个松散物品，具有较强的工业需求，但仍然是一个具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;本文旨在概述人类在挑选松散水果和蔬菜时使用的独特操作策略，以更好地将其应用于机器人对多种物品的操作。&lt;h4&gt;方法&lt;/h4&gt;提出了一种首个版本的机器人系统，旨在抓取不同的单个或多个新鲜物品，配备多指顺应性机器人抓手。&lt;h4&gt;主要发现&lt;/h4&gt;从工业关键绩效指标（KPIs）的角度分析了人类抓取策略，并使用相同的KPIs对机器人系统进行了验证，考虑了人类的表现和策略。&lt;h4&gt;结论&lt;/h4&gt;本文为未来新鲜水果和蔬菜智能操作的机器人演示器的发展奠定了基础，并指出了处理任务复杂性所需的通用方法。&lt;h4&gt;总结&lt;/h4&gt;人类的抓取策略和机器人系统的设计相结合，为提高机器人操作效率提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic manipulation of fresh fruits and vegetables, including the graspingof multiple loose items, has a strong industrial need but it still is achallenging task for robotic manipulation. This paper outlines the distinctivemanipulation strategies used by humans to pick loose fruits and vegetables withthe aim to better adopt them for robotic manipulation of diverse items. In thiswork we present a first version of a robotic setup designed to pick differentsingle or multiple fresh items, featuring multi-fingered compliant roboticgripper. We analyse human grasping strategies from the perspective ofindustrial Key Performance Indicators (KPIs) used in the logistic sector. Therobotic system was validated using the same KPIs, as well as taking intoaccount human performance and strategies. This paper lays the foundation forfuture development of the robotic demonstrator for fresh fruit and vegetableintelligent manipulation, and outlines the need for generic approaches tohandle the complexity of the task.</description>
      <author>example@mail.com (Romeo Orsolino, Mykhaylo Marfeychuk, Mariana de Paula Assis Fonseca, Mario Baggetta, Wesley Wimshurst, Francesco Porta, Morgan Clarke, Giovanni Berselli, Jelizaveta Konstantinova)</author>
      <guid isPermaLink="false">2410.22893v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Interaction Modeling With Reduced Accumulated Error for Multi-Agent Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2410.21342v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, accepted by IEEE TNNLS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;动态复杂系统由交互的异质代理组成，广泛存在于城市交通系统和社交网络中。&lt;h4&gt;目的&lt;/h4&gt;理解和预测复杂系统的动态，特别是城市中交通参与者的轨迹预测。&lt;h4&gt;方法&lt;/h4&gt;提出了异质交互建模，旨在减少多代理轨迹预测中的累积误差。基于历史轨迹，推断代理之间的动态交互图，并定义异质注意机制来聚合来自异质邻居的影响。&lt;h4&gt;主要发现&lt;/h4&gt;通过分析空间和时间角度的误差来源，引入图熵和混合训练策略分别减少两种误差。&lt;h4&gt;结论&lt;/h4&gt;在三个包含异质代理的真实数据集上进行实验，结果验证了该方法的优越性。&lt;h4&gt;总结&lt;/h4&gt;该研究为复杂系统中的异质交互建模提供了新的方法，改善了轨迹预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TNNLS.2022.3224007&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamical complex systems composed of interactive heterogeneous agents areprevalent in the world, including urban traffic systems and social networks.Modeling the interactions among agents is the key to understanding andpredicting the dynamics of the complex system, e.g., predicting thetrajectories of traffic participants in the city. Compared with interactionmodeling in homogeneous systems such as pedestrians in a crowded scene,heterogeneous interaction modeling is less explored. Worse still, the erroraccumulation problem becomes more severe since the interactions are morecomplex. To tackle the two problems, this paper proposes heterogeneousinteraction modeling with reduced accumulated error for multi-agent trajectoryprediction. Based on the historical trajectories, our method infers the dynamicinteraction graphs among agents, featured by directed interacting relations andinteracting effects. A heterogeneous attention mechanism is defined on theinteraction graphs for aggregating the influence from heterogeneous neighborsto the target agent. To alleviate the error accumulation problem, this paperanalyzes the error sources from the spatial and temporal perspectives, andproposes to introduce the graph entropy and the mixup training strategy forreducing the two types of errors respectively. Our method is examined on threereal-world datasets containing heterogeneous agents, and the experimentalresults validate the superiority of our method.</description>
      <author>example@mail.com (Siyuan Chen, Jiahai Wang)</author>
      <guid isPermaLink="false">2410.21342v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>An Efficient Representation of Whole-body Model Predictive Control for Online Compliant Dual-arm Mobile Manipulation</title>
      <link>http://arxiv.org/abs/2410.22910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review for IEEE Transactions on Robotics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;双臂移动操控器能够使用简单的末端执行器运输和操控大型物体，需在动态环境中满足严格的安全性和合规性要求。&lt;h4&gt;目的&lt;/h4&gt;解决在高度冗余的移动操控器中，在线实现满足各种硬约束的全身运动规划的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种高效的全身运动轨迹表示方式，结合双层模型预测控制（MPC）框架，利用Bézier曲线参数化表示优化的无碰撞轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在首次MPC中快速实现面向对象的长时间运动规划，并在第二次MPC中生成全身运动，满足硬约束。&lt;h4&gt;结论&lt;/h4&gt;该表示方法使两个MPC具备连续性，避免了现有MPC中不准确的模型状态转变和密集的决策变量设置，提高了高维空间中双层MPC框架的在线执行能力。&lt;h4&gt;应用&lt;/h4&gt;通过在多种场景下的模拟比较和实际实验，验证了该方法在静态和动态障碍物避免及与操控物体和外部干扰的合规交互控制中的效率和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;该研究为双臂移动操控器在复杂环境中的安全高效操作提供了新方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dual-arm mobile manipulators can transport and manipulate large-size objectswith simple end-effectors. To interact with dynamic environments with strictsafety and compliance requirements, achieving whole-body motion planning onlinewhile meeting various hard constraints for such highly redundant mobilemanipulators poses a significant challenge. We tackle this challenge bypresenting an efficient representation of whole-body motion trajectories withinour bilevel model-based predictive control (MPC) framework. We utilizeB\'ezier-curve parameterization to represent the optimized collision-freetrajectories of two collaborating end-effectors in the first MPC, facilitatingfast long-horizon object-oriented motion planning in SE(3) while consideringapproximated feasibility constraints. This approach is further applied toparameterize whole-body trajectories in the second MPC for whole-body motiongeneration with predictive admittance control in a relatively short horizonwhile satisfying whole-body hard constraints. This representation enables twoMPCs with continuous properties, thereby avoiding inaccurate model-statetransition and dense decision-variable settings in existing MPCs using thediscretization method. It strengthens the online execution of the bilevel MPCframework in high-dimensional space and facilitates the generation ofconsistent commands for our hybrid position/velocity-controlled robot. Thesimulation comparisons and real-world experiments demonstrate the efficiencyand robustness of this approach in various scenarios for static and dynamicobstacle avoidance, and compliant interaction control with the manipulatedobject and external disturbances.</description>
      <author>example@mail.com (Wenqian Du, Ran Long, João Moura, Jiayi Wang, Saeid Samadi, Sethu Vijayakumar)</author>
      <guid isPermaLink="false">2410.22910v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Strada-LLM: Graph LLM for traffic prediction</title>
      <link>http://arxiv.org/abs/2410.20856v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;交通预测是智能交通系统的重要组成部分，需要在时空维度上推理交通模式以提供准确的预测。&lt;h4&gt;目的&lt;/h4&gt;解决不同交通条件下数据分布多样性带来的挑战，提升交通预测的准确性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;提出一种图感知的LLM（大语言模型）进行交通预测，考虑邻近节点的交通信息作为协变量，并采用轻量级方法进行高效的领域适应。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在处理新数据分布时表现优越，超越了传统的时间序列LLM和GNN（图神经网络）监督方法。&lt;h4&gt;结论&lt;/h4&gt;Strada-LLM能够轻松适应不同的LLM骨干网络，且性能下降不明显，显示出其广泛的适用性。&lt;h4&gt;总结&lt;/h4&gt;通过提出一种新的图感知LLM，能够有效应对交通预测中的数据分布挑战，提升预测效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic prediction is a vital component of intelligent transportationsystems. By reasoning about traffic patterns in both the spatial and temporaldimensions, accurate and interpretable predictions can be provided. Aconsiderable challenge in traffic prediction lies in handling the diverse datadistributions caused by vastly different traffic conditions occurring atdifferent locations. LLMs have been a dominant solution due to their remarkablecapacity to adapt to new datasets with very few labeled data samples, i.e.,few-shot adaptability. However, existing forecasting techniques mainly focus onextracting local graph information and forming a text-like prompt, leaving LLM-based traffic prediction an open problem. This work presents a probabilisticLLM for traffic forecasting with three highlights. We propose a graph-aware LLMfor traffic prediction that considers proximal traffic information.Specifically, by considering the traffic of neighboring nodes as covariates,our model outperforms the corresponding time-series LLM. Furthermore, we adopta lightweight approach for efficient domain adaptation when facing new datadistributions in few-shot fashion. The comparative experiment demonstrates theproposed method outperforms the state-of-the-art LLM-based methods and thetraditional GNN- based supervised approaches. Furthermore, Strada-LLM can beeasily adapted to different LLM backbones without a noticeable performancedrop.</description>
      <author>example@mail.com (Seyed Mohamad Moghadas, Yangxintong Lyu, Bruno Cornelis, Alexandre Alahi, Adrian Munteanu)</author>
      <guid isPermaLink="false">2410.20856v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Temporal Linear Network for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.21448v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近期研究质疑了复杂深度学习架构在时间序列预测中的必要性，表明简单线性模型往往优于复杂方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种新架构——时间线性网络（TLN），扩展线性模型的能力，同时保持可解释性和计算效率。&lt;h4&gt;方法&lt;/h4&gt;TLN设计用于有效捕捉多变量时间序列数据中的时间依赖性和特征依赖性，其为TSMixer的变体，保持严格线性结构。&lt;h4&gt;主要发现&lt;/h4&gt;TLN通过去除激活函数、引入专门的内核初始化和稀疏卷积处理不同时间尺度，同时保留模型的线性特性。&lt;h4&gt;结论&lt;/h4&gt;TLN显式保留和利用输入数据的时间结构，能够计算等效线性模型，提供更高的可解释性，便于在TLN模型和线性等效模型间无缝转换。&lt;h4&gt;总结&lt;/h4&gt;TLN架构结合了线性模型的优势和复杂模型的灵活性，为时间序列预测提供了一种高效且可解释的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/remigenet/TLN&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent research has challenged the necessity of complex deep learningarchitectures for time series forecasting, demonstrating that simple linearmodels can often outperform sophisticated approaches. Building upon thisinsight, we introduce a novel architecture the Temporal Linear Net (TLN), thatextends the capabilities of linear models while maintaining interpretabilityand computational efficiency. TLN is designed to effectively capture bothtemporal and feature-wise dependencies in multivariate time series data. Ourapproach is a variant of TSMixer that maintains strict linearity throughout itsarchitecture. TSMixer removes activation functions, introduces specializedkernel initializations, and incorporates dilated convolutions to handle varioustime scales, while preserving the linear nature of the model. Unliketransformer-based models that may lose temporal information due to theirpermutation-invariant nature, TLN explicitly preserves and leverages thetemporal structure of the input data. A key innovation of TLN is its ability tocompute an equivalent linear model, offering a level of interpretability notfound in more complex architectures such as TSMixer. This feature allows forseamless conversion between the full TLN model and its linear equivalent,facilitating both training flexibility and inference optimization.</description>
      <author>example@mail.com (Remi Genet, Hugo Inzirillo)</author>
      <guid isPermaLink="false">2410.21448v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>GPTR: Gaussian Process Trajectory Representation for Continuous-Time Motion Estimation</title>
      <link>http://arxiv.org/abs/2410.22931v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The source code has been released. All feedbacks are welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;连续时间轨迹表示在近年来变得越来越受欢迎，能够融合更多传感器和感知方式，克服传统离散时间框架的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出一种高斯过程轨迹表示（GPTR）框架，用于连续时间运动估计（CTME）任务，以促进连续时间范式的采用。&lt;h4&gt;方法&lt;/h4&gt;采用三阶随机抖动模型，提供旋转和平移状态导数的闭式表达式，以实现平滑的连续轨迹表示。&lt;h4&gt;主要发现&lt;/h4&gt;GP基础的轨迹表示在多种运动估计任务中显示出有效性和效率，提供了优化示例，包括LiDAR、相机、IMU、UWB因子及闭式解析雅可比。&lt;h4&gt;结论&lt;/h4&gt;GPTR可以帮助研究人员快速开发未来应用，如批量优化、校准、传感器融合和轨迹规划等。&lt;h4&gt;资源&lt;/h4&gt;GPTR源代码作为轻量级头文件库可用，易于集成，无需大量代码修改。&lt;h4&gt;总结&lt;/h4&gt;该项目旨在支持更广泛的机器人和计算机视觉社区，提升连续时间轨迹表示的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuous-time trajectory representation has gained significant popularityin recent years, as it offers an elegant formulation that allows the fusion ofa larger number of sensors and sensing modalities, overcoming limitations oftraditional discrete-time frameworks. To bolster the adoption of thecontinuous-time paradigm, we propose a so-called Gaussian Process TrajectoryRepresentation (GPTR) framework for continuous-time motion estimation (CTME)tasks. Our approach stands out by employing a third-order random jerk model,featuring closed-form expressions for both rotational and translational statederivatives. This model provides smooth, continuous trajectory representationsthat are crucial for precise estimation of complex motion. To support the widerrobotics and computer vision communities, we have made the source code for GPTRavailable as a light-weight header-only library. This format was chosen for itsease of integration, allowing developers to incorporate GPTR into existingsystems without needing extensive code modifications. Moreover, we also providea set of optimization examples with LiDAR, camera, IMU, UWB factors, andclosed-form analytical Jacobians under the proposed GP framework. Ourexperiments demonstrate the efficacy and efficiency of GP-based trajectoryrepresentation in various motion estimation tasks, and the examples can serveas the prototype to help researchers quickly develop future applications suchas batch optimization, calibration, sensor fusion, trajectory planning, etc.,with continuous-time trajectory representation. Our project is accessible athttps://github.com/brytsknguyen/gptr .</description>
      <author>example@mail.com (Thien-Minh Nguyen, Ziyu Cao, Kailai Li, Shenghai Yuan, Lihua Xie)</author>
      <guid isPermaLink="false">2410.22931v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fakeium: A Dynamic Execution Environment for JavaScript Program Analysis</title>
      <link>http://arxiv.org/abs/2410.20862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;JavaScript作为一种简单的Web脚本语言，现已广泛应用于桌面、移动和服务器应用程序，增加了被恶意行为者利用的风险。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的动态分析工具，以检测JavaScript程序中的恶意模式。&lt;h4&gt;方法&lt;/h4&gt;提出Fakeium，一个基于V8引擎的开源轻量级执行环境，支持大规模动态分析。&lt;h4&gt;主要发现&lt;/h4&gt;Fakeium在执行开销极小的情况下，能够检测到隐藏的API调用，特别是在混淆代码中。&lt;h4&gt;结论&lt;/h4&gt;Fakeium为安全分析师提供了一种有效工具，可以在不依赖资源密集型浏览器或合成用户输入的情况下，识别JavaScript中的恶意行为。&lt;h4&gt;总结&lt;/h4&gt;Fakeium的灵活性和高度可定制性使其成为动态分析JavaScript程序的有价值工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The JavaScript programming language, which began as a simple scriptinglanguage for the Web, has become ubiquitous, spanning desktop, mobile, andserver applications. This increase in usage has made JavaScript an attractivetarget for nefarious actors, resulting in the proliferation of maliciousbrowser extensions that steal user information and supply chain attacks thattarget the official Node.js package registry. To combat these threats,researchers have developed specialized tools and frameworks for analyzing thebehavior of JavaScript programs to detect malicious patterns. Static analysistools typically struggle with the highly dynamic nature of the language andfail to process obfuscated sources, while dynamic analysis pipelines takeseveral minutes to run and require more resources per program, making themunfeasible for large-scale analyses. In this paper, we present Fakeium, anovel, open source, and lightweight execution environment designed forefficient, large-scale dynamic analysis of JavaScript programs. Built on top ofthe popular V8 engine, Fakeium complements traditional static analysis byproviding additional API calls and string literals that would otherwise gounnoticed without the need for resource-intensive instrumented browsers orsynthetic user input. Besides its negligible execution overhead, our tool ishighly customizable and supports hooks for advanced analysis scenarios such asnetwork traffic emulation. Fakeium's flexibility and ability to detect hiddenAPI calls, especially in obfuscated sources, highlights its potential as avaluable tool for security analysts to detect malicious behavior.</description>
      <author>example@mail.com (José Miguel Moreno, Narseo Vallina-Rodriguez, Juan Tapiador)</author>
      <guid isPermaLink="false">2410.20862v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Quantum Phase Estimation without Controlled Unitaries</title>
      <link>http://arxiv.org/abs/2410.21517v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  35 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究展示了如何使用适应的经典相位恢复算法进行无控制的量子相位估计。&lt;h4&gt;目的&lt;/h4&gt;消除常规方法中成本高昂的控制时间演化和Hadamard测试，以获取重建光谱所需的复杂时间序列。&lt;h4&gt;方法&lt;/h4&gt;通过扩展待解决的问题至具有更大输入信号集的形式，同时利用信号和/或光谱的自然约束，采用经典信号处理中的算法，具体使用了向量相位恢复和二维相位恢复两种互补方法。&lt;h4&gt;主要发现&lt;/h4&gt;数值研究表明这两种方法在估计费米-哈伯模型的光谱方面的可行性，并讨论了它们对固有统计噪声的韧性。&lt;h4&gt;结论&lt;/h4&gt;显著减少了所需的相干控制操作数量，降低了电路深度，简化了在近期期设备中实施统计量子相位估计的复杂性。&lt;h4&gt;总结&lt;/h4&gt;本研究为无控制的量子相位估计提供了一种新的方法，展示了经典算法在量子计算中的潜在应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work we demonstrate the use of adapted classical phase retrievalalgorithms to perform control-free quantum phase estimation. We eliminate thecostly controlled time evolution and Hadamard test commonly required to accessthe complex time-series needed to reconstruct the spectrum. This significantreduction of the number of coherent controlled-operations lowers the circuitdepth and considerably simplifies the implementation of statistical quantumphase estimation in near-term devices. This seemingly impossible task can beachieved by extending the problem that one wishes to solve to one with a largerset of input signals while exploiting natural constraints on the signal and/orthe spectrum. We leverage well-established algorithms that are widely used inthe context of classical signal processing, demonstrating two complementarymethods to do this, vectorial phase retrieval and two-dimensional phaseretrieval. We numerically investigate the feasibility of both approaches forestimating the spectrum of the Fermi-Hubbard model and discuss their resilienceto inherent statistical noise.</description>
      <author>example@mail.com (Laura Clinton, Toby S. Cubitt, Raul Garcia-Patron, Ashley Montanaro, Stasja Stanisic, Maarten Stroeks)</author>
      <guid isPermaLink="false">2410.21517v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>From 5G to 6G: A Survey on Security, Privacy, and Standardization Pathways</title>
      <link>http://arxiv.org/abs/2410.21986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;6G的愿景是提升网络能力，提供更快的数据传输速率、近乎零延迟和更高的容量。&lt;h4&gt;目的&lt;/h4&gt;支持更多连接设备，并在智能数字生态系统中实现无缝体验，人工智能在网络管理和数据分析中发挥关键作用。&lt;h4&gt;方法&lt;/h4&gt;对6G协议进行全面概述，重点关注安全和隐私，识别风险并提出缓解策略。&lt;h4&gt;主要发现&lt;/h4&gt;6G的扩展引发了严重的安全和隐私问题，包括未经授权的访问和数据泄露。&lt;h4&gt;结论&lt;/h4&gt;需要定制的6G解决方案，以应对物联网设备、边缘计算和AI驱动分析的集成带来的挑战。&lt;h4&gt;行业展望&lt;/h4&gt;讨论行业愿景、政府项目及标准化努力，以平衡技术创新与安全隐私措施。&lt;h4&gt;总结&lt;/h4&gt;本论文强调了在推进6G技术的同时，必须加强安全和隐私的保障。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The vision for 6G aims to enhance network capabilities with faster datarates, near-zero latency, and higher capacity, supporting more connecteddevices and seamless experiences within an intelligent digital ecosystem whereartificial intelligence (AI) plays a crucial role in network management anddata analysis. This advancement seeks to enable immersive mixed-realityexperiences, holographic communications, and smart city infrastructures.However, the expansion of 6G raises critical security and privacy concerns,such as unauthorized access and data breaches. This is due to the increasedintegration of IoT devices, edge computing, and AI-driven analytics. This paperprovides a comprehensive overview of 6G protocols, focusing on security andprivacy, identifying risks, and presenting mitigation strategies. The surveyexamines current risk assessment frameworks and advocates for tailored 6Gsolutions. We further discuss industry visions, government projects, andstandardization efforts to balance technological innovation with robustsecurity and privacy measures.</description>
      <author>example@mail.com (Mengmeng Yang, Youyang Qu, Thilina Ranbaduge, Chandra Thapa, Nazatul Sultan, Ming Ding, Hajime Suzuki, Wei Ni, Sharif Abuadbba, David Smith, Paul Tyler, Josef Pieprzyk, Thierry Rakotoarivelo, Xinlong Guan, Sirine M'rabet)</author>
      <guid isPermaLink="false">2410.21986v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>VISTA-SSM: Varying and Irregular Sampling Time-series Analysis via State Space Models</title>
      <link>http://arxiv.org/abs/2410.21527v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种用于多变量和不规则采样时间序列的聚类方法，称为VISTA，基于参数状态空间混合模型。&lt;h4&gt;目的&lt;/h4&gt;旨在无监督地识别来自医疗和心理学数据集中的群体，这些数据集常常存在采样问题。&lt;h4&gt;方法&lt;/h4&gt;采用线性高斯状态空间模型（LGSSMs）构建灵活的参数框架，以适应多种时间序列动态，并假设人群可以表示为给定数量的LGSSMs混合。使用显式推导的对数似然函数，开发期望最大化方案来拟合模型参数。&lt;h4&gt;主要发现&lt;/h4&gt;VISTA能够处理具有大幅度采样率变化和不规则采样的多变量时间序列，其在模拟和真实数据集上的评估显示其在多种应用场景中的表现优于大多数标准时间序列聚类方法。&lt;h4&gt;结论&lt;/h4&gt;VISTA提供了一个开源的Python实现，证明了其在处理不规则时间序列数据方面的有效性和准确性。&lt;h4&gt;总结&lt;/h4&gt;VISTA是一种创新的聚类方法，适用于医疗和心理学领域中的复杂时间序列数据，展示了其优越的性能和灵活性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce VISTA, a clustering approach for multivariate and irregularlysampled time series based on a parametric state space mixture model. VISTA isspecifically designed for the unsupervised identification of groups in datasetsoriginating from healthcare and psychology where such sampling issues arecommonplace. Our approach adapts linear Gaussian state space models (LGSSMs) toprovide a flexible parametric framework for fitting a wide range of time seriesdynamics. The clustering approach itself is based on the assumption that thepopulation can be represented as a mixture of a given number of LGSSMs. VISTA'smodel formulation allows for an explicit derivation of the log-likelihoodfunction, from which we develop an expectation-maximization scheme for fittingmodel parameters to the observed data samples. Our algorithmic implementationis designed to handle populations of multivariate time series that can exhibitlarge changes in sampling rate as well as irregular sampling. We evaluate theversatility and accuracy of our approach on simulated and real-world datasets,including demographic trends, wearable sensor data, epidemiological timeseries, and ecological momentary assessments. Our results indicate that VISTAoutperforms most comparable standard times series clustering methods. Weprovide an open-source implementation of VISTA in Python.</description>
      <author>example@mail.com (Benjamin Brindle, Thomas Derrick Hull, Matteo Malgaroli, Nicolas Charon)</author>
      <guid isPermaLink="false">2410.21527v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PDSR: Efficient UAV Deployment for Swift and Accurate Post-Disaster Search and Rescue</title>
      <link>http://arxiv.org/abs/2410.22982v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is currently under review at IEEE IoT Magazine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了一种全面的灾后搜索与救援（PDSR）框架，旨在利用无人机优化搜索和救援操作。&lt;h4&gt;目的&lt;/h4&gt;提高在各种灾害场景下的传感能力的精确性和可用性。&lt;h4&gt;方法&lt;/h4&gt;快速部署装备有多种传感、通信和智能能力的无人机群，作为集成系统，结合多种技术与方法进行高效检测。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够显著快于传统方法实现对受损区域的全面覆盖。&lt;h4&gt;结论&lt;/h4&gt;通过与机器学习结合的多模态传感数据融合，可以提高检测准确性，确保精确识别幸存者。&lt;h4&gt;挑战&lt;/h4&gt;提出了架构解决方案并解决了相关挑战，以确保在实际灾害场景中的最佳性能。&lt;h4&gt;总结&lt;/h4&gt;该框架通过多层次无人机群架构与数据融合技术，优化了灾后搜索与救援效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a comprehensive framework for Post-Disaster Search andRescue (PDSR), aiming to optimize search and rescue operations leveragingUnmanned Aerial Vehicles (UAVs). The primary goal is to improve the precisionand availability of sensing capabilities, particularly in various catastrophicscenarios. Central to this concept is the rapid deployment of UAV swarmsequipped with diverse sensing, communication, and intelligence capabilities,functioning as an integrated system that incorporates multiple technologies andapproaches for efficient detection of individuals buried beneath rubble ordebris following a disaster. Within this framework, we propose architecturalsolution and address associated challenges to ensure optimal performance inreal-world disaster scenarios. The proposed framework aims to achieve completecoverage of damaged areas significantly faster than traditional methods using amulti-tier swarm architecture. Furthermore, integrating multi-modal sensingdata with machine learning for data fusion could enhance detection accuracy,ensuring precise identification of survivors.</description>
      <author>example@mail.com (Alaa Awad Abdellatif, Ali Elmancy, Amr Mohamed, Ahmed Massoud, Wadha Lebda, Khalid K. Naji)</author>
      <guid isPermaLink="false">2410.22982v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FairStream: Fair Multimedia Streaming Benchmark for Reinforcement Learning Agents</title>
      <link>http://arxiv.org/abs/2410.21029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多媒体流媒体占据了当前互联网流量的大部分。&lt;h4&gt;目的&lt;/h4&gt;探讨如何在波动的网络条件下优化多媒体流的比特率，以提升播放流畅性和用户体验（QoE）。&lt;h4&gt;方法&lt;/h4&gt;研究者训练了强化学习（RL）代理，考虑了多种挑战，如部分可观测性、多目标、代理异质性和异步性，提出了一种新的多代理环境。&lt;h4&gt;主要发现&lt;/h4&gt;通过对五种不同流量类别的基线方法进行分析，发现常用的近端策略优化（PPO）算法不如简单的贪婪启发式方法表现优越。&lt;h4&gt;结论&lt;/h4&gt;未来的工作将包括多代理RL算法的适应以及环境的进一步扩展。&lt;h4&gt;总结&lt;/h4&gt;本研究为多媒体流的公平性及其在复杂环境中的表现提供了新的见解，强调了算法选择的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jw3il/fairstream&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimedia streaming accounts for the majority of traffic in today'sinternet. Mechanisms like adaptive bitrate streaming control the bitrate of astream based on the estimated bandwidth, ideally resulting in smooth playbackand a good Quality of Experience (QoE). However, selecting the optimal bitrateis challenging under volatile network conditions. This motivated researchers totrain Reinforcement Learning (RL) agents for multimedia streaming. Theconsidered training environments are often simplified, leading to promisingresults with limited applicability. Additionally, the QoE fairness acrossmultiple streams is seldom considered by recent RL approaches. With this work,we propose a novel multi-agent environment that comprises multiple challengesof fair multimedia streaming: partial observability, multiple objectives, agentheterogeneity and asynchronicity. We provide and analyze baseline approachesacross five different traffic classes to gain detailed insights into thebehavior of the considered agents, and show that the commonly used ProximalPolicy Optimization (PPO) algorithm is outperformed by a simple greedyheuristic. Future work includes the adaptation of multi-agent RL algorithms andfurther expansions of the environment.</description>
      <author>example@mail.com (Jannis Weil, Jonas Ringsdorf, Julian Barthel, Yi-Ping Phoebe Chen, Tobias Meuser)</author>
      <guid isPermaLink="false">2410.21029v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Reconstructing East Asian Temperatures from 1368 to 1911 Using Historical Documents, Climate Models, and Data Assimilation</title>
      <link>http://arxiv.org/abs/2410.21790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 15 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在1368年至1911年间，东亚缺乏仪器数据，导致理解过去气候条件面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;重建东亚的年度温度，利用重建的东亚气候历史编码系列(REACHES)。&lt;h4&gt;方法&lt;/h4&gt;采用三层统计框架，包括克里金插值法、定量映射和贝叶斯数据同化方法，整合历史文献和现代气候模型。&lt;h4&gt;主要发现&lt;/h4&gt;克里金法处理缺失信息，定量映射将REACHES数据校准至摄氏温度，贝叶斯方法提高重建精度。&lt;h4&gt;结论&lt;/h4&gt;通过综合历史文献、现代气候模型和先进统计方法，显著改善了历史温度重建的准确性，成为未来环境和气候研究的重要资源。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种有效的历史温度重建方法，填补了东亚地区气候数据的空白，为相关研究提供了重要基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a novel approach for reconstructing annual temperatures in EastAsia from 1368 to 1911, leveraging the Reconstructed East Asian ClimateHistorical Encoded Series (REACHES). The lack of instrumental data during thisperiod poses significant challenges to understanding past climate conditions.REACHES digitizes historical documents from the Ming and Qing dynasties ofChina, converting qualitative descriptions into a four-level ordinaltemperature scale. However, these index-based data are biased toward abnormalor extreme weather phenomena, leading to data gaps that likely correspond tonormal conditions. To address this bias and reconstruct historical temperaturesat any point within East Asia, including locations without direct historicaldata, we employ a three-tiered statistical framework. First, we perform krigingto interpolate temperature data across East Asia, adopting a zero-meanassumption to handle missing information. Next, we utilize the Last MillenniumEnsemble (LME) reanalysis data and apply quantile mapping to calibrate thekriged REACHES data to Celsius temperature scales. Finally, we introduce anovel Bayesian data assimilation method that integrates the kriged Celsius datawith LME simulations to enhance reconstruction accuracy. We model the LME dataat each geographic location using a flexible nonstationary autoregressive timeseries model and employ regularized maximum likelihood estimation with a fusedlasso penalty. The resulting dynamic distribution serves as a prior, which isrefined via Kalman filtering by incorporating the kriged Celsius REACHES datato yield posterior temperature estimates. This comprehensive integration ofhistorical documentation, contemporary climate models, and advanced statisticalmethods improves the accuracy of historical temperature reconstructions andprovides a crucial resource for future environmental and climate studies.</description>
      <author>example@mail.com (Eric Sun, Kuan-hui Elaine Lin, Wan-Ling Tseng, Pao K. Wang, Hsin-Cheng Huang)</author>
      <guid isPermaLink="false">2410.21790v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Comparison of Prompt Engineering Techniques for Task Planning and Execution in Service Robotics</title>
      <link>http://arxiv.org/abs/2410.22997v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 figures, 2 tables, to be published in the 2024 IEEE-RAS
  International Conference on Humanoid Robots, We make our code, including all
  prompts, available at https://github.com/AIS-Bonn/Prompt_Engineering&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;最近大型语言模型（LLM）的进展在自主机器人控制和人机交互中发挥了重要作用，利用其广泛的知识和理解能力。&lt;h4&gt;目的&lt;/h4&gt;比较不同的提示工程技术及其组合在服务机器人高层任务规划和执行中的应用。&lt;h4&gt;方法&lt;/h4&gt;定义一组多样化的任务和简单的功能集，在仿真环境中测量多个先进模型的任务完成准确性和执行时间。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比不同的提示工程技术，评估它们在任务规划和执行中的表现。&lt;h4&gt;结论&lt;/h4&gt;提示工程技术的有效性对服务机器人在高层任务执行中的性能有显著影响。&lt;h4&gt;总结&lt;/h4&gt;本研究为提升服务机器人的任务执行能力提供了实证依据，并为未来的研究方向指明了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ais-bonn/prompt_engineering&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in LLM have been instrumental in autonomous robot control andhuman-robot interaction by leveraging their vast general knowledge andcapabilities to understand and reason across a wide range of tasks andscenarios. Previous works have investigated various prompt engineeringtechniques for improving the performance of \glspl{LLM} to accomplish tasks,while others have proposed methods that utilize LLMs to plan and execute tasksbased on the available functionalities of a given robot platform. In this work,we consider both lines of research by comparing prompt engineering techniquesand combinations thereof within the application of high-level task planning andexecution in service robotics. We define a diverse set of tasks and a simpleset of functionalities in simulation, and measure task completion accuracy andexecution time for several state-of-the-art models.</description>
      <author>example@mail.com (Jonas Bode, Bastian Pätzold, Raphael Memmesheimer, Sven Behnke)</author>
      <guid isPermaLink="false">2410.22997v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.21086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全球交通安全面临重大挑战，交通事故每年导致约135万人死亡，主要原因是人为错误。&lt;h4&gt;目的&lt;/h4&gt;开发一种有效的驾驶员监测系统（DMS），以评估SAE 2/3级自动驾驶环境中的认知负荷和困倦。&lt;h4&gt;方法&lt;/h4&gt;提出一种新型的多任务DMS，称为VDMoE，利用RGB视频输入非侵入性地监测驾驶员状态，结合远程光电容积描记法（rPPG）获取生理信息。&lt;h4&gt;主要发现&lt;/h4&gt;VDMoE在监测驾驶员状态方面有效，提高了检测准确性并保持了效率，且优化了专家混合框架以处理多模态输入。&lt;h4&gt;结论&lt;/h4&gt;VDMoE为提高自动驾驶系统的安全性做出了贡献，代码和数据将在后续发布。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过先进的监测系统提高驾驶安全性的潜力，尤其是在驾驶员可能分心或疲劳的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Road safety remains a critical challenge worldwide, with approximately 1.35million fatalities annually attributed to traffic accidents, often due to humanerrors. As we advance towards higher levels of vehicle automation, challengesstill exist, as driving with automation can cognitively over-demand drivers ifthey engage in non-driving-related tasks (NDRTs), or lead to drowsiness ifdriving was the sole task. This calls for the urgent need for an effectiveDriver Monitoring System (DMS) that can evaluate cognitive load and drowsinessin SAE Level-2/3 autonomous driving contexts. In this study, we propose a novelmulti-task DMS, termed VDMoE, which leverages RGB video input to monitor driverstates non-invasively. By utilizing key facial features to minimizecomputational load and integrating remote Photoplethysmography (rPPG) forphysiological insights, our approach enhances detection accuracy whilemaintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE)framework to accommodate multi-modal inputs and improve performance acrossdifferent tasks. A novel prior-inclusive regularization method is introduced toalign model outputs with statistical priors, thus accelerating convergence andmitigating overfitting risks. We validate our method with the creation of a newdataset (MCDD), which comprises RGB video and physiological indicators from 42participants, and two public datasets. Our findings demonstrate theeffectiveness of VDMoE in monitoring driver states, contributing to saferautonomous driving systems. The code and data will be released.</description>
      <author>example@mail.com (Jiyao Wang, Xiao Yang, Zhenyu Wang, Ximeng Wei, Ange Wang, Dengbo He, Kaishun Wu)</author>
      <guid isPermaLink="false">2410.21086v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fingerprinting Browsers in Encrypted Communications</title>
      <link>http://arxiv.org/abs/2410.21101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  3 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;浏览器指纹识别是通过捕获浏览器与服务器之间通信的网络流量来识别浏览器。&lt;h4&gt;目的&lt;/h4&gt;讨论基于TLS 1.3协议的HTTPS下的浏览器指纹识别方法。&lt;h4&gt;方法&lt;/h4&gt;建立一个使用UTM虚拟机管理程序的网络，设置一个虚拟机作为服务器，另一个虚拟机使用不同的浏览器进行通信。&lt;h4&gt;主要发现&lt;/h4&gt;不同浏览器与服务器通信时使用的消息数量不同，消息长度也存在差异。&lt;h4&gt;结论&lt;/h4&gt;不同浏览器的行为存在30%-35%的不相似性。&lt;h4&gt;总结&lt;/h4&gt;浏览器指纹识别可以通过分析HTTPS协议传输中的消息特征来实现，具有显著的浏览器间差异性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Browser fingerprinting is the identification of a browser through the networktraffic captured during communication between the browser and server. This canbe done using the HTTP protocol, browser extensions, and other methods. Thispaper discusses browser fingerprinting using the HTTPS over TLS 1.3 protocol.The study observed that different browsers use a different number of messagesto communicate with the server, and the length of messages also varies. Toconduct the study, a network was set up using a UTM hypervisor with one virtualmachine as the server and another as a VM with a different browser. Thecommunication was captured, and it was found that there was a 30\%-35\%dissimilarity in the behavior of different browsers.</description>
      <author>example@mail.com (Sandhya Aneja, Nagender Aneja)</author>
      <guid isPermaLink="false">2410.21101v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DexGraspNet 2.0: Learning Generative Dexterous Grasping in Large-scale Synthetic Cluttered Scenes</title>
      <link>http://arxiv.org/abs/2410.23004v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在杂乱场景中，灵巧手的抓取仍然非常具有挑战性，因为数据稀缺。&lt;h4&gt;目的&lt;/h4&gt;提出一个大规模的合成基准，解决抓取数据不足的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的两阶段抓取方法，利用条件在局部几何上的扩散模型高效学习数据。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的生成方法在模拟实验中优于所有基线。&lt;h4&gt;结论&lt;/h4&gt;通过测试时深度恢复，方法实现了零样本的模拟到真实转移，在杂乱场景中达到了90.7%的真实世界灵巧抓取成功率。&lt;h4&gt;总结&lt;/h4&gt;通过创新的基准和方法，显著提升了灵巧手在复杂环境中的抓取能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping in cluttered scenes remains highly challenging for dexterous handsdue to the scarcity of data. To address this problem, we present a large-scalesynthetic benchmark, encompassing 1319 objects, 8270 scenes, and 427 milliongrasps. Beyond benchmarking, we also propose a novel two-stage grasping methodthat learns efficiently from data by using a diffusion model that conditions onlocal geometry. Our proposed generative method outperforms all baselines insimulation experiments. Furthermore, with the aid of test-time-depthrestoration, our method demonstrates zero-shot sim-to-real transfer, attaining90.7% real-world dexterous grasping success rate in cluttered scenes.</description>
      <author>example@mail.com (Jialiang Zhang, Haoran Liu, Danshi Li, Xinqiang Yu, Haoran Geng, Yufei Ding, Jiayi Chen, He Wang)</author>
      <guid isPermaLink="false">2410.23004v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Individualised recovery trajectories of patients with impeded mobility, using distance between probability distributions of learnt graphs</title>
      <link>http://arxiv.org/abs/2410.21983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;患者在进行身体康复时，依赖于可靠评估其累计表现的反馈。&lt;h4&gt;目的&lt;/h4&gt;提供一种方法，以学习患者在身体治疗中恢复运动能力的轨迹。&lt;h4&gt;方法&lt;/h4&gt;使用时间序列数据记录20个关节位置，通过贝叶斯学习的随机图计算运动恢复评分（MRS），并绘制恢复轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;患者在进行相同运动时的MRS差异可以通过统计距离/发散度来描述。&lt;h4&gt;结论&lt;/h4&gt;基于恢复学习结果，提出针对不同运动损伤程度患者的最佳运动方案建议。&lt;h4&gt;总结&lt;/h4&gt;本研究为身体康复提供了一种基于数据驱动的方法，帮助优化患者的恢复过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.artmed.2024.103005.&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patients who are undergoing physical rehabilitation, benefit from feedbackthat follows from reliable assessment of their cumulative performance attainedat a given time. In this paper, we provide a method for the learning of therecovery trajectory of an individual patient, as they undertake exercises aspart of their physical therapy towards recovery of their loss of movementability, following a critical illness. The difference between the MovementRecovery Scores (MRSs) attained by a patient, when undertaking a given exerciseroutine on successive instances, is given by a statistical distance/divergencebetween the (posterior) probabilities of random graphs that are Bayesianlylearnt using time series data on locations of 20 of the patient's joints,recorded on an e-platform as the patient exercises. This allows for thecomputation of the MRS on every occasion the patient undertakes this exercise,using which, the recovery trajectory is drawn. We learn each graph as a RandomGeometric Graph drawn in a probabilistic metric space, and identify theclosed-form marginal posterior of any edge of the graph, given the correlationstructure of the multivariate time series data on joint locations. On the basisof our recovery learning, we offer recommendations on the optimal exerciseroutines for patients with given level of mobility impairment.</description>
      <author>example@mail.com (Chuqiao Zhang, Crina Grosan, Dalia Chakrabarty)</author>
      <guid isPermaLink="false">2410.21983v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Host-SSD Collaborative Write Accelerator for LSM-Tree-Based Key-Value Stores</title>
      <link>http://arxiv.org/abs/2410.21760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 14 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Log-Structured Merge (LSM)树基于的键值存储（KVS）在写密集型环境中表现出色，但在压缩过程中常出现写停滞，导致性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出KVACCEL，一个新颖的硬件-软件协同设计框架，消除写停滞。&lt;h4&gt;方法&lt;/h4&gt;利用双接口SSD分配逻辑NAND闪存空间，支持块接口和键值接口，在写停滞期间使用键值接口作为临时写缓冲区。&lt;h4&gt;主要发现&lt;/h4&gt;KVACCEL在写密集型工作负载中，吞吐量比ADOC提高了最高1.17倍，性能与CPU利用效率优化显著。&lt;h4&gt;结论&lt;/h4&gt;对于混合读写工作负载，KVACCEL与ADOC表现相当。&lt;h4&gt;总结&lt;/h4&gt;KVACCEL通过优化资源使用和确保主机与设备之间的一致性，有效减少了写停滞现象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Log-Structured Merge (LSM) tree-based Key-Value Stores (KVSs) are widelyadopted for their high performance in write-intensive environments, but theyoften face performance degradation due to write stalls during compaction. Priorsolutions, such as regulating I/O traffic or using multiple compaction threads,can cause unexpected drops in throughput or increase host CPU usage, whilehardware-based approaches using FPGA, GPU, and DPU aimed at reducing compactionduration introduce additional hardware costs. In this study, we proposeKVACCEL, a novel hardware-software co-design framework that eliminates writestalls by leveraging a dual-interface SSD. KVACCEL allocates logical NAND flashspace to support both block and key-value interfaces, using the key-valueinterface as a temporary write buffer during write stalls. This strategysignificantly reduces write stalls, optimizes resource usage, and ensuresconsistency between the host and device by implementing an in-device LSM-basedwrite buffer with an iterator-based range scan mechanism. Our extensiveevaluation shows that for write-intensive workloads, KVACCEL outperforms ADOCby up to 1.17x in terms of throughput and performance-to-CPU-utilizationefficiency. For mixed read-write workloads, both demonstrate comparableperformance.</description>
      <author>example@mail.com (KiHwan Kim, Hyunsun Chung, Seonghoon Ahn, Junhyeok Park, Safdar Jamil, Hongsu Byun, Myungcheol Lee, Jinchun Choi, Youngjae Kim)</author>
      <guid isPermaLink="false">2410.21760v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback</title>
      <link>http://arxiv.org/abs/2410.23022v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动从自然语言描述中合成密集奖励是一种有前景的强化学习范式，适用于稀疏奖励问题、开放式探索和层次技能设计。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法的限制，提升强化学习中的奖励合成能力。&lt;h4&gt;方法&lt;/h4&gt;提出ONI分布式架构，同时学习强化学习策略和内在奖励函数，利用大型语言模型（LLM）反馈，通过异步LLM服务器标注代理的经验，进而提炼成内在奖励模型。&lt;h4&gt;主要发现&lt;/h4&gt;探索了多种奖励建模的算法选择，包括哈希、分类和排序模型，并研究了它们的相对权衡。&lt;h4&gt;结论&lt;/h4&gt;该方法在NetHack学习环境中的一系列挑战性稀疏奖励任务上实现了最先进的性能，完全依赖于代理收集的经验，无需外部数据集或源代码。&lt;h4&gt;总结&lt;/h4&gt;研究展示了利用LLM反馈来改进强化学习奖励合成的潜力，提供了一种统一的简单过程来处理稀疏奖励问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatically synthesizing dense rewards from natural language descriptionsis a promising paradigm in reinforcement learning (RL), with applications tosparse reward problems, open-ended exploration, and hierarchical skill design.Recent works have made promising steps by exploiting the prior knowledge oflarge language models (LLMs). However, these approaches suffer from importantlimitations: they are either not scalable to problems requiring billions ofenvironment samples; or are limited to reward functions expressible by compactcode, which may require source code and have difficulty capturing nuancedsemantics; or require a diverse offline dataset, which may not exist or beimpossible to collect. In this work, we address these limitations through acombination of algorithmic and systems-level contributions. We propose ONI, adistributed architecture that simultaneously learns an RL policy and anintrinsic reward function using LLM feedback. Our approach annotates theagent's collected experience via an asynchronous LLM server, which is thendistilled into an intrinsic reward model. We explore a range of algorithmicchoices for reward modeling with varying complexity, including hashing,classification, and ranking models. By studying their relative tradeoffs, weshed light on questions regarding intrinsic reward design for sparse rewardproblems. Our approach achieves state-of-the-art performance across a range ofchallenging, sparse reward tasks from the NetHack Learning Environment in asimple unified process, solely using the agent's gathered experience, withoutrequiring external datasets nor source code. We make our code available at\url{URL} (coming soon).</description>
      <author>example@mail.com (Qinqing Zheng, Mikael Henaff, Amy Zhang, Aditya Grover, Brandon Amos)</author>
      <guid isPermaLink="false">2410.23022v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Infrared photometry with InGaAs detectors: First light with SPECULOOS</title>
      <link>http://arxiv.org/abs/2410.22140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SPIE Astronomical Telescopes + Instrumentation 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了SPIRIT的光度性能，该仪器是一种基于InGaAs CMOS的地面近红外设备，具有1280x1024像素和12微米的像素间距。&lt;h4&gt;目的&lt;/h4&gt;SPIRIT旨在优化对晚期M型和L型恒星的时间序列光度精度。&lt;h4&gt;方法&lt;/h4&gt;使用定制的宽通滤光器（0.81 - 1.33微米，zYJ），以减少大气可降水水汽（PWV）变动对差分光度的影响，并且设计为免维护，无需液氮冷却。&lt;h4&gt;主要发现&lt;/h4&gt;SPIRIT在观察L型及更冷恒星时表现出比传统CCD仪器（2048x2048像素，I+z'滤光器）更好的光度噪声性能。定制滤光器显著减少了由PWV变动引入的红噪声。&lt;h4&gt;结论&lt;/h4&gt;在SPIRIT的观测中，探测器的读出噪声是主要限制因素，但在某些情况下，缺乏比较恒星也限制了性能。&lt;h4&gt;总结&lt;/h4&gt;SPIRIT展现了优越的光度性能，尤其是在对晚期恒星的观测中，表明其在天文观测中的潜在应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1117/12.3018320&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present the photometric performance of SPIRIT, a ground-basednear-infrared InGaAs CMOS-based instrument (1280 by 1024 pixels, 12 micronpitch), using on-sky results from the SPECULOOS-Southern Observatory during2022 - 2023. SPIRIT was specifically designed to optimise time-seriesphotometric precision for observing late M and L type stars. To achieve this, acustom wide-pass filter (0.81 - 1.33 microns, zYJ ) was used, which was alsodesigned to minimise the effects of atmospheric precipitable water vapour (PWV)variability on differential photometry. Additionally, SPIRIT was designed to bemaintenance-free by eliminating the need for liquid nitrogen for cooling. Wecompared SPIRIT's performance with a deeply-depleted (2048 by 2048 pixels, 13.5micron pitch) CCD-based instrument (using an I+z' filter, 0.7 - 1.1 microns)through simultaneous observations. For L type stars and cooler, SPIRITexhibited better photometric noise performance compared to the CCD-basedinstrument. The custom filter also significantly minimised red noise in theobserved light curves typically introduced by atmospheric PWV variability. InSPIRIT observations, the detector's read noise was the dominant limitation,although in some cases, we were limited by the lack of comparison stars.</description>
      <author>example@mail.com (Peter P. Pedersen, Didier Queloz, Lionel Garcia, Yannick Schacke, Laetitia Delrez, Brice-Olivier Demory, Elsa Ducrot, Georgina Dransfield, Michael Gillon, Matthew J. Hooton, Clàudia Janó-Muñoz, Emmanuël Jehin, Daniel Sebastian, Mathilde Timmermans, Samantha Thompson, Amaury H. M. J. Triaud, Julien de Wit, Sebastián Zúñiga-Fernández)</author>
      <guid isPermaLink="false">2410.22140v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Data streaming platform for crowd-sourced vehicle dataset generation</title>
      <link>http://arxiv.org/abs/2410.21934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages. To be published in IEEE Transactions on Intelligent
  Vehicles&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;车辆是复杂的机器，配备了传感器以提供实时数据用于驾驶辅助系统。由于交通、道路和天气条件的多样性，系统的持续增强至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一个边缘-云数据平台，以连接汽车数据生产者与多种异构服务，解决数据空间中的关键挑战。&lt;h4&gt;方法&lt;/h4&gt;评估数据平台在文本、图像和视频数据工作负载下的性能限制，考察连接技术的影响，并评估延迟。&lt;h4&gt;主要发现&lt;/h4&gt;使用5G连接时，数据传输到边缘托管的应用程序的延迟降至33毫秒，而跨越边缘和云处理基础设施时约为77毫秒。&lt;h4&gt;结论&lt;/h4&gt;结果为避免汽车数据平台中的瓶颈提供了必要的处理资产指导。&lt;h4&gt;总结&lt;/h4&gt;该研究促进了数据驱动的互联和创新数据经济的发展，强调了边缘和云基础设施的协同作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TIV.2024.3486926&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicles are sophisticated machines equipped with sensors that providereal-time data for onboard driving assistance systems. Due to the wide varietyof traffic, road, and weather conditions, continuous system enhancements areessential. Connectivity allows vehicles to transmit previously unknown data,expanding datasets and accelerating the development of new data models. Thisenables faster identification and integration of novel data, improving systemreliability and reducing time to market. Data Spaces aim to create adata-driven, interconnected, and innovative data economy, where edge and cloudinfrastructures support a virtualised IoT platform that connects data sourcesand development servers. This paper proposes an edge-cloud data platform toconnect car data producers with multiple and heterogeneous services, addressingkey challenges in Data Spaces, such as data sovereignty, governance,interoperability, and privacy. The paper also evaluates the data platform'sperformance limits for text, image, and video data workloads, examines theimpact of connectivity technologies, and assesses latencies. The results showthat latencies drop to 33ms with 5G connectivity when pipelining data toconsuming applications hosted at the edge, compared to around 77ms whencrossing both edge and cloud processing infrastructures. The results offerguidance on the necessary processing assets to avoid bottlenecks in car dataplatforms.</description>
      <author>example@mail.com (Felipe Mogollon, Zaloa Fernandez, Angel Martin, Juan Diego Ortega, Gorka Velez)</author>
      <guid isPermaLink="false">2410.21934v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Camber-changing flapping hydrofoils for efficient and environmental-safe water propulsion system</title>
      <link>http://arxiv.org/abs/2410.23032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Peer-reviewed and accepted in Ubiquitous Robots 2024, New York City&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究介绍了一种新型的基于水翼的推进框架，灵感来源于某些水生物种的波动运动。&lt;h4&gt;目的&lt;/h4&gt;提高无人水下机器人在水中的推进效率。&lt;h4&gt;方法&lt;/h4&gt;采用动态仿真验证了调节弯度的水翼与对称水翼的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;调节弯度的水翼在水平推力方面显著优于对称设计，显示了弯度调节方法的潜力。&lt;h4&gt;结论&lt;/h4&gt;所提出的原型设计能够有效提供水上推进，并在水上飞机起飞时产生垂直力。&lt;h4&gt;应用&lt;/h4&gt;设计旨在利用波浪能，推动替代能源的探索。&lt;h4&gt;意义&lt;/h4&gt;该研究推进了水下机器人的仿生振荡原理的理解，为未来环保且灵活的水下探测发展奠定基础。&lt;h4&gt;总结&lt;/h4&gt;本研究为无人水下机器人的推进效率提升提供了新的思路和设计基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research introduces a novel hydrofoil-based propulsion framework forunmanned aquatic robots, inspired by the undulating locomotion observed inselect aquatic species. The proposed system incorporates a camber-modulatingmechanism to enhance hydrofoil propulsive force generation and eventuallyefficiency. Through dynamic simulations, we validate the effectiveness of thecamber-adjusting hydrofoil compared to a symmetric counterpart. The resultsdemonstrate a significant improvement in horizontal thrust, emphasizing thepotential of the cambering approach to enhance propulsive performance.Additionally, a prototype flipper design is presented, featuring individualcontrol of heave and pitch motions, as well as a camber-adjustment mechanism.The integrated system not only provides efficient water-based propulsion butalso offers the capacity for generating vertical forces during take-offmaneuvers for seaplanes. The design is tailored to harness wave energy,contributing to the exploration of alternative energy resources. This workadvances the understanding of bionic oscillatory principles for aquatic robotsand provides a foundation for future developments in environmentally safe andagile underwater exploration.</description>
      <author>example@mail.com (Luca Romanello, Leonard Hohaus, David-Marian Schmitt, Mirko Kovac, Sophie F. Armanini)</author>
      <guid isPermaLink="false">2410.23032v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Pulsar timing methods for evaluating dispersion measure time series</title>
      <link>http://arxiv.org/abs/2410.22170v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;射电脉冲星研究电离星际介质及其色散效应，这对利用脉冲星进行引力波搜索的噪声源有重要影响。&lt;h4&gt;目的&lt;/h4&gt;比较三种常用方案在测量脉冲星定时数据中星际传播效应的时间变化方面的功能和可靠性。&lt;h4&gt;方法&lt;/h4&gt;在低观察频率（100-200 MHz）下进行广泛模拟，注入长期相关噪声过程及白噪声，评估三种去噪方法：逐epoch（EW）测量星际色散、DMX方法的分段拟合、以及通过贝叶斯分析的DMGP模型。&lt;h4&gt;主要发现&lt;/h4&gt;所有方法在建模色散时表现良好，DMGP方法精度最高，其次是DMX和EW；EW方法最准确，其次是DMX和DMGP。&lt;h4&gt;结论&lt;/h4&gt;EW被认为是研究银河系电离介质的最可靠方法，未来的研究应通过更现实的模拟来确认这一结果。&lt;h4&gt;其他发现&lt;/h4&gt;DMGP和DMX在去除长期相关噪声方面表现优异，适合引力波研究，但需进行完整的脉冲星定时阵列实验模拟以支持该解释。&lt;h4&gt;总结&lt;/h4&gt;研究表明，EW方法在可靠性上优于其他方法，而DMGP和DMX在噪声去除方面表现突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Radio pulsars allow the study of the ionised interstellar medium and itsdispersive effects, a major noise source in gravitational wave searches usingpulsars. In this paper, we compare the functionality and reliability of threecommonly used schemes to measure temporal variations in interstellarpropagation effects in pulsar-timing data. We carry out extensive simulationsat low observing frequencies (100-200 MHz) by injecting long-term correlatednoise processes with power-law spectra and white noise, to evaluate therobustness, accuracy and precision of the following three mitigation methods:epoch-wise (EW) measurements of interstellar dispersion; the DMX method ofsimultaneous, piece-wise fits to interstellar dispersion; and DMGP, whichmodels dispersion variations through Gaussian processes using a Bayesiananalysis method. We then evaluate how reliably the input signals arereconstructed and how the various methods react to the presence of achromaticlong-period noise. All the methods perform well, provided the achromaticlong-period noise is modeled for DMX and DMGP. The most precise method is DMGP,followed by DMX and EW, while the most accurate is EW, followed by DMX andDMGP. We also test different scenarios including simulations of L-band ToAs andrealistic DM injection, with no significant variation in the obtained results.Given the nature of our simulations and our scope, we deem that EW is the mostreliable method to study the Galactic ionized media. Future works should beconducted to confirm this result via more realistic simulations. We note thatDM GP and DMX seem to be the most performing techniques in removing long-termcorrelated noise, and hence for gravitational wave studies. However, fullsimulations of pulsar timing array experiments are needed to support thisinterpretation.</description>
      <author>example@mail.com (F. Iraci, A. Chalumeau, C. Tiburzi, J. P. W. Verbiest, A. Possenti, G. M. Shaifullah, S. C. Susarla, M. A. Krishnakumar, M. T. Lam, H. T. Cromartie, M. Kerr, Jean-Mathias Grießmeier)</author>
      <guid isPermaLink="false">2410.22170v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>GRINNs: Godunov-Riemann Informed Neural Networks for Learning Hyperbolic Conservation Laws</title>
      <link>http://arxiv.org/abs/2410.22193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出GRINNs：一种基于数值分析的神经网络，旨在解决非线性守恒定律系统的反问题。&lt;h4&gt;目的&lt;/h4&gt;开发高分辨率的神经网络方法，以提高对超波动偏微分方程的求解能力。&lt;h4&gt;方法&lt;/h4&gt;GRINNs基于高分辨率的Godunov方案解决黎曼问题，学习物理通量函数而非数值通量。&lt;h4&gt;主要发现&lt;/h4&gt;在四个基准问题（Burgers'、浅水、Lighthill-Whitham-Richards及Payne-Whitham交通流模型）中，GRINNs在光滑和不连续区域均表现出极高的准确性。&lt;h4&gt;结论&lt;/h4&gt;GRINNs提供了一种可解释的守恒方案，能够有效学习满足Rankine-Hugoniot条件的解算子。&lt;h4&gt;总结&lt;/h4&gt;GRINNs是一种创新的神经网络方法，能够高效解决涉及冲击波和稀疏区域的复杂问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present GRINNs: numerical analysis-informed neural networks for thesolution of inverse problems of non-linear systems of conservation laws. GRINNsare based on high-resolution Godunov schemes for the solution of the Riemannproblem in hyperbolic Partial Differential Equations (PDEs). In contrast toother existing machine learning methods that learn the numerical fluxes ofconservative Finite Volume methods, GRINNs learn the physical flux function perse. Due to their structure, GRINNs provide interpretable, conservative schemes,that learn the solution operator on the basis of approximate Riemann solversthat satisfy the Rankine-Hugoniot condition. The performance of GRINNs isassessed via four benchmark problems, namely the Burgers', the Shallow Water,the Lighthill-Whitham-Richards and the Payne-Whitham traffic flow models. Thesolution profiles of these PDEs exhibit shock waves, rarefactions and/orcontact discontinuities at finite times. We demonstrate that GRINNs provide avery high accuracy both in the smooth and discontinuous regions.</description>
      <author>example@mail.com (Dimitrios G. Patsatzis, Mario di Bernardo, Lucia Russo, Constantinos Siettos)</author>
      <guid isPermaLink="false">2410.22193v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Potential of Multi-modal Sensing Framework for Forest Ecology</title>
      <link>http://arxiv.org/abs/2410.23033v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Peer-reviewed and accepted in IEEE ICRA 2024 Workshop RUNE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;森林为人类提供重要资源和服务，但保护和恢复森林面临挑战，特别是在难以到达的区域，如森林树冠，缺乏可操作的数据。&lt;h4&gt;目的&lt;/h4&gt;探讨使用机器人技术改善森林数据收集，特别是通过无人机和其他方法获取树冠数据。&lt;h4&gt;方法&lt;/h4&gt;利用无人机群体展示自主导航，通过树冠灵活操控，避免树木碰撞，以进行区域映射和数据收集。&lt;h4&gt;主要发现&lt;/h4&gt;单靠自由飞行的无人机不足以满足数据收集需求，飞行过程中产生的噪音扰动动物，可能会影响数据的准确性。商业无人机在需要灵活操作的任务中自主性有限，进一步复杂化数据采集工作。&lt;h4&gt;结论&lt;/h4&gt;虽然生物滑翔机和传感器发射等方法在下层树冠的数据收集中表现有效，但在数据和传感器的回收上仍面临挑战，通常需要人工干预。&lt;h4&gt;总结&lt;/h4&gt;综合来看，森林数据收集领域亟需更有效的技术手段，以减少对生物学家的干扰和提高数据采集的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forests offer essential resources and services to humanity, yet preservingand restoring them presents challenges, particularly due to the limitedavailability of actionable data, especially in hard-to-reach areas like forestcanopies. Accessibility continues to pose a challenge for biologists collectingdata in forest environments, often requiring them to invest significant timeand energy in climbing trees to place sensors. This operation not only consumesresources but also exposes them to danger. Efforts in robotics have beendirected towards accessing the tree canopy using robots. A swarm of drones hasshowcased autonomous navigation through the canopy, maneuvering with agilityand evading tree collisions, all aimed at mapping the area and collecting data.However, relying solely on free-flying drones has proven insufficient for datacollection. Flying drones within the canopy generates loud noise, disturbinganimals and potentially corrupting the data. Additionally, commercial dronesoften have limited autonomy for dexterous tasks where aerial physicalinteraction could be required, further complicating data acquisition efforts.Aerial deployed sensor placement methods such as bio-gliders and sensorshooting have proven effective for data collection within the lower canopy.However, these methods face challenges related to retrieving the data andsensors, often necessitating human intervention.</description>
      <author>example@mail.com (Luca Romanello, Tian Lan, Mirko Kovac, Sophie F. Armanini, Basaran Bahadir Kocer)</author>
      <guid isPermaLink="false">2410.23033v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Hypergraph-based multi-scale spatio-temporal graph convolution network for Time-Series anomaly detection</title>
      <link>http://arxiv.org/abs/2410.22256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列异常检测技术在航空航天、水处理、云服务等多个领域中发挥重要作用。&lt;h4&gt;目的&lt;/h4&gt;提高工作效率，避免重大经济损失。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于超图的时空图卷积神经网络模型STGCN_Hyper，通过超图动态图结构学习模块捕获多个变量之间的高阶、多跳相关性，并利用多尺度TCN扩张卷积模块捕获时间维度上不同尺度的特征依赖。&lt;h4&gt;主要发现&lt;/h4&gt;STGCN_Hyper模型能够灵活学习多尺度时间序列特征及特征间的依赖关系，且在异常检测任务中在精确度、召回率和F1-score等指标上优于大多数现有基线模型。&lt;h4&gt;结论&lt;/h4&gt;本模型有效地实现了无监督的异常检测，并在多个时间序列数据集上取得了良好的实验结果。&lt;h4&gt;总结&lt;/h4&gt;STGCN_Hyper模型通过先进的技术手段提升了高维复杂数据集中的异常检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series anomaly detection technology plays an important rolein many fields including aerospace, water treatment, cloud service providers,etc. Excellent anomaly detection models can greatly improve work efficiency andavoid major economic losses. However, with the development of technology, theincreasing size and complexity of data, and the lack of labels for relevantabnormal data, it is becoming increasingly challenging to perform effective andaccurate anomaly detection in high-dimensional and complex data sets. In thispaper, we propose a hypergraph based spatiotemporal graph convolutional neuralnetwork model STGCN_Hyper, which explicitly captures high-order, multi-hopcorrelations between multiple variables through a hypergraph based dynamicgraph structure learning module. On this basis, we further use the hypergraphbased spatiotemporal graph convolutional network to utilize the learnedhypergraph structure to effectively propagate and aggregate one-hop andmulti-hop related node information in the convolutional network, therebyobtaining rich spatial information. Furthermore, through the multi-scale TCNdilated convolution module, the STGCN_hyper model can also capture thedependencies of features at different scales in the temporal dimension. Anunsupervised anomaly detector based on PCA and GMM is also integrated into theSTGCN_hyper model. Through the anomaly score of the detector, the model candetect the anomalies in an unsupervised way. Experimental results on multipletime series datasets show that our model can flexibly learn the multi-scaletime series features in the data and the dependencies between features, andoutperforms most existing baseline models in terms of precision, recall,F1-score on anomaly detection tasks. Our code is available on:https://git.ecdf.ed.ac.uk/msc-23-24/s2044819</description>
      <author>example@mail.com (Hongyi Xu)</author>
      <guid isPermaLink="false">2410.22256v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Cora: Accelerating Stateful Network Applications with SmartNICs</title>
      <link>http://arxiv.org/abs/2410.22229v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着网络应用性能要求的提高，越来越多的状态ful网络应用被转移到SmartNICs，以提升性能并降低总体拥有成本。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的方法来卸载状态ful网络应用，以应对状态操作复杂性和资源消耗问题。&lt;h4&gt;方法&lt;/h4&gt;提出Cora编译器和运行时，Cora编译器为每个SmartNIC引入准确的性能模型，并使用高效的编译算法搜索卸载计划，Cora运行时监控流量动态并进行适应性调整。&lt;h4&gt;主要发现&lt;/h4&gt;Cora可以在相同的吞吐量目标下，提出节省高达94.0% CPU核心的分区方案，相比基线方案提升1.9倍；在相同资源约束下，Cora能够加速网络功能44.9%-82.3%。&lt;h4&gt;结论&lt;/h4&gt;Cora运行时能够适应流量变化，保持较低的CPU使用率。&lt;h4&gt;总结&lt;/h4&gt;Cora是一种有效的解决方案，能够显著提高状态ful网络应用的性能并降低资源使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing performance requirements on networked applications, there isa new trend of offloading stateful network applications to SmartNICs to improveperformance and reduce the total cost of ownership. However, offloadingstateful network applications is non-trivial due to state operation complexity,state resource consumption, and the complicated relationship between trafficand state. Naively partitioning the program by state or traffic can result in asuboptimal partition plan with higher CPU usage or even packet drops. In thispaper, we propose Cora, a compiler and runtime that offloads stateful networkapplications to SmartNIC-accelerated hosts. Cora compiler introduces anaccurate performance model for each SmartNIC and employs an efficient compilingalgorithm to search the offloading plan. Cora runtime can monitor trafficdynamics and adapt to minimize CPU usage. Cora is built atop Netronome Agilioand BlueField 2 SmartNICs. Our evaluation shows that for the same throughputtarget, Cora can propose partition plans saving up to 94.0% CPU cores, 1.9times more than baseline solutions. Under the same resource constraint, Coracan accelerate network functions by 44.9%-82.3%. Cora runtime can adapt totraffic changes and keep CPU usage low.</description>
      <author>example@mail.com (Shaoke Xi, Jiaqi Gao, Mengqi Liu, Jiamin Cao, Fuliang Li, Kai Bu, Kui Ren, Minlan Yu, Dennis Cai, Ennan Zhai)</author>
      <guid isPermaLink="false">2410.22229v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Neural Attention Field: Emerging Point Relevance in 3D Scenes for One-Shot Dexterous Grasping</title>
      <link>http://arxiv.org/abs/2410.23039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在具有物体和上下文变化的新场景中，一次性转移灵巧抓取一直是一个具有挑战性的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种神经注意力场，以表示3D空间中语义感知的密集特征场。&lt;h4&gt;方法&lt;/h4&gt;使用变压器解码器计算任意3D查询点与所有场景点之间的跨注意力，并提供基于注意力的聚合。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过鼓励末端效应器关注任务相关的场景区域，显著提高了真实机器人上的成功率。&lt;h4&gt;结论&lt;/h4&gt;与基于特征场的方法相比，所提出的方法在优化效果上表现更好。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了如何通过自监督框架在少量3D点云上训练变压器解码器，从而实现一次性演示下的语义感知灵巧抓取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; One-shot transfer of dexterous grasps to novel scenes with object and contextvariations has been a challenging problem. While distilled feature fields fromlarge vision models have enabled semantic correspondences across 3D scenes,their features are point-based and restricted to object surfaces, limitingtheir capability of modeling complex semantic feature distributions forhand-object interactions. In this work, we propose the \textit{neural attentionfield} for representing semantic-aware dense feature fields in the 3D space bymodeling inter-point relevance instead of individual point features. Core to itis a transformer decoder that computes the cross-attention between any 3D querypoint with all the scene points, and provides the query point feature with anattention-based aggregation. We further propose a self-supervised framework fortraining the transformer decoder from only a few 3D pointclouds without handdemonstrations. Post-training, the attention field can be applied to novelscenes for semantics-aware dexterous grasping from one-shot demonstration.Experiments show that our method provides better optimization landscapes byencouraging the end-effector to focus on task-relevant scene regions, resultingin significant improvements in success rates on real robots compared with thefeature-field-based methods.</description>
      <author>example@mail.com (Qianxu Wang, Congyue Deng, Tyler Ga Wei Lum, Yuanpei Chen, Yaodong Yang, Jeannette Bohg, Yixin Zhu, Leonidas Guibas)</author>
      <guid isPermaLink="false">2410.23039v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Stochastic Flow Matching for Resolving Small-Scale Physics</title>
      <link>http://arxiv.org/abs/2410.19814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;条件扩散和流模型在自然图像中对于超分辨小尺度细节效果显著，但在物理科学（如天气）中面临挑战。&lt;h4&gt;目的&lt;/h4&gt;解决小尺度细节超分辨问题，尤其是在天气数据处理中。&lt;h4&gt;方法&lt;/h4&gt;通过将输入编码为更接近目标分布的潜在基础分布，随后进行流匹配生成小尺度物理细节。编码器捕捉确定性成分，流匹配则添加随机小尺度细节。&lt;h4&gt;主要发现&lt;/h4&gt;提出的随机流匹配（SFM）框架在实际CWA天气数据集和基于PDE的Kolmogorov数据集上的实验结果显示，优于现有的条件扩散和流方法。&lt;h4&gt;结论&lt;/h4&gt;SFM框架在超分辨天气变量（从25公里到2公里尺度）任务中表现卓越，显著提高了小尺度细节的模拟精度。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，成功应对了天气数据处理中小尺度细节超分辨的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conditioning diffusion and flow models have proven effective forsuper-resolving small-scale details in natural images.However, in physicalsciences such as weather, super-resolving small-scale details poses significantchallenges due to: (i) misalignment between input and output distributions(i.e., solutions to distinct partial differential equations (PDEs) followdifferent trajectories), (ii) multi-scale dynamics, deterministic dynamics atlarge scales vs. stochastic at small scales, and (iii) limited data, increasingthe risk of overfitting. To address these challenges, we propose encoding theinputs to a latent base distribution that is closer to the target distribution,followed by flow matching to generate small-scale physics. The encoder capturesthe deterministic components, while flow matching adds stochastic small-scaledetails. To account for uncertainty in the deterministic part, we inject noiseinto the encoder output using an adaptive noise scaling mechanism, which isdynamically adjusted based on maximum-likelihood estimates of the encoderpredictions. We conduct extensive experiments on both the real-world CWAweather dataset and the PDE-based Kolmogorov dataset, with the CWA taskinvolving super-resolving the weather variables for the region of Taiwan from25 km to 2 km scales. Our results show that the proposed stochastic flowmatching (SFM) framework significantly outperforms existing methods such asconditional diffusion and flows.</description>
      <author>example@mail.com (Stathi Fotiadis, Noah Brenowitz, Tomas Geffner, Yair Cohen, Michael Pritchard, Arash Vahdat, Morteza Mardani)</author>
      <guid isPermaLink="false">2410.19814v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Pedestrian crash causation analysis near bus stops: Insights from random parameters NB-Lindley models</title>
      <link>http://arxiv.org/abs/2410.22253v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  27 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;公交车站附近的行人安全日益受到关注，伤害和死亡人数上升，强调了降低事故风险和鼓励城市交通中的公共交通的必要性。&lt;h4&gt;目的&lt;/h4&gt;填补现有研究中对暴露特征和公交车站设计元素对行人-车辆碰撞影响的忽视，开发数据驱动的干预措施。&lt;h4&gt;方法&lt;/h4&gt;使用随机参数负二项-林德利模型（RPNB-L）量化德克萨斯州沃斯堡市各种特征（如公交车站设计、交通、乘客活动和道路环境等）与行人-车辆碰撞之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;分析覆盖596个公交车站点，结果显示RPNB-L模型在捕捉各站点变异性方面优于传统的负二项（NB）和固定系数NB-L模型。影响行人KABCO碰撞频率的显著预测因素包括平均年度日交通量（AADT）、公交乘客上下车率、位于交叉口近侧的车站、混合用途区域以及缺乏中央分隔带、人行道或斑马线。另外，照明差、高中数量多和较低的速度限制（如35 mph）也增加了碰撞频率。&lt;h4&gt;结论&lt;/h4&gt;研究应用安全改善潜力（PSI）指标识别高风险地点，并优先考虑关键走廊进行干预。&lt;h4&gt;总结&lt;/h4&gt;本研究通过量化公交车站设计与行人安全之间的关系，为公共交通安全干预措施提供了重要数据支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pedestrian safety near bus stops is a growing concern due to rising injuriesand fatalities, underscoring the need to mitigate crash risks and encourageactive travel through public transportation in urban corridors. However,existing research has often overlooked the effects of exposure characteristicsand bus stop design elements on pedestrian-vehicle crashes, limiting thedevelopment of data-driven interventions. This study aims to fill that gap byquantifying the relationship between various features (e.g., bus stop design,traffic, and passenger activity, roadway environment, etc.) andvehicle-pedestrian crashes in Fort Worth, Texas, using the Random ParametersNegative Binomial-Lindley (RPNB-L) model to address the unobservedheterogeneity. By accounting for site-specific variability, the RPNB-L modeloffers a more nuanced understanding of the factors influencing crash frequency.The analysis covers 596 bus stop sites, integrating crash data from 2018 to2022 with roadway network and stop design characteristics. Results show thatthe RPNB-L model outperforms traditional Negative Binomial (NB) andfixed-coefficient NB-L models in capturing variability across sites.Significant predictors of higher pedestrian KABCO crash frequencies includeaverage annual daily traffic (AADT), bus passenger boarding rates, stopslocated near-side of intersections, mixed-use areas, and the absence ofmedians, sidewalks, or crosswalks. Additional factors, such as poor lighting,high school numbers, and lower speed limits (e.g., 35 mph), also increase crashfrequency. The study applies the Potential for Safety Improvement (PSI) metricto identify high-risk sites and prioritize key corridors for intervention.</description>
      <author>example@mail.com (Mohammad Anis, Srinivas R. Geedipally, Dominique Lord)</author>
      <guid isPermaLink="false">2410.22253v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>TumblerBots: Tumbling Robotic sensors for Minimally-invasive Benthic Monitoring</title>
      <link>http://arxiv.org/abs/2410.23049v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Robosoft 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人系统在水环境监测应用中具有重要潜力，包括水质监测、污染映射和生物多样性数据收集。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖框架，以减少对脆弱生态系统的干扰，并准确收集水下数据。&lt;h4&gt;方法&lt;/h4&gt;采用轻量化的翻转器系统，通过无人机部署，翻转器在水面上释放感应单元以进行非侵入性数据收集。&lt;h4&gt;主要发现&lt;/h4&gt;翻转器以0.8到2.5米每秒的低速率下降，减少了对生态系统的干扰，且在户外测试中表现出良好的抗风能力。&lt;h4&gt;结论&lt;/h4&gt;该系统在中到强风条件下表现稳健，验证了整体框架的有效性。&lt;h4&gt;总结&lt;/h4&gt;新的框架和设计理念能够在保护生态环境的同时，实现高效的水环境监测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic systems show significant promise for water environmental sensingapplications such as water quality monitoring, pollution mapping andbiodiversity data collection.  Conventional deployment methods often disrupt fragile ecosystems, preventingdepiction of the undisturbed environmental condition. In response to thischallenge, we propose a novel framework utilizing a lightweight tumbler systemequipped with a sensing unit, deployed via a drone. This design minimizesdisruption to the water habitat by maintaining a slow descent. The sensing unitis detached once on the water surface, enabling precise and non-invasive datacollection from the benthic zone.  The tumbler is designed to be lightweight and compact, enabling deploymentvia a drone. The sensing pod, which detaches from the tumbler and descends tothe bottom of the water body, is equipped with temperature and pressuresensors, as well as a buoyancy system. The later, activated upon taskcompletion, utilizes a silicon membrane inflated via a chemical reaction. Thereaction generates a pressure of 70 kPa, causing the silicon membrane to expandby 30\%, which exceeds the 5.7\% volume increase required for positivebuoyancy. The tumblers, made from ecofriendly materials to minimizeenvironmental impact when lost during the mission, were tested for theirgliding ratio and descent rate. They exhibit a low descent rate, in the rangeof 0.8 to 2.5 meters per seconds, which minimizes disturbance to the ecosystemupon water landing. Additionally, the system demonstrated robustness inmoderate to strong wind conditions during outdoor tests, validating the overallframework.</description>
      <author>example@mail.com (L. Romanello, A. Teboul, F. Wiesemuller, P. H. Nguyen, M. Kovac, S. F. Armanini)</author>
      <guid isPermaLink="false">2410.23049v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Log Heston Model for Monthly Average VIX</title>
      <link>http://arxiv.org/abs/2410.22471v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures, 17 graphs. Keywords: autoregression, volatility,
  Hill estimator, variance-gamma distribution, stationary Markov chain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;我们对VIX（每月平均）和每月股指收益率的时间序列进行建模。&lt;h4&gt;目的&lt;/h4&gt;探讨如何通过模型化VIX与股指收益率的关系来提高收益率分布的独立性。&lt;h4&gt;方法&lt;/h4&gt;使用对数Heston模型，将VIX的对数建模为一阶自回归。&lt;h4&gt;主要发现&lt;/h4&gt;标准化的每月股指收益率（除以VIX）更接近独立同分布的高斯分布。&lt;h4&gt;结论&lt;/h4&gt;所得到的模型是均值回归型，创新项为非高斯分布，适用于小型和大型股指，并能捕捉真实股市收益的帕累托型尾部特性。&lt;h4&gt;总结&lt;/h4&gt;结合随机波动模型表现良好，适用于价格和总收益的分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We model time series of VIX (monthly average) and monthly stock indexreturns. We use log-Heston model: logarithm of VIX is modeled as anautoregression of order 1. Our main insight is that normalizing monthly stockindex returns (dividing them by VIX) makes them much closer to independentidentically distributed Gaussian. The resulting model is mean-reverting, andthe innovations are non-Gaussian. The combined stochastic volatility model fitswell, and captures Pareto-like tails of real-world stock market returns. Thisworks for small and large stock indices, for both price and total returns.</description>
      <author>example@mail.com (Jihyun Park, Andrey Sarantsev)</author>
      <guid isPermaLink="false">2410.22471v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Communication Characterization of AI Workloads for Large-scale Multi-chiplet Accelerators</title>
      <link>http://arxiv.org/abs/2410.22262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 Pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;下一代人工智能（AI）工作负载在执行时间方面面临可扩展性和鲁棒性的挑战，主要由于其数据密集型特性。&lt;h4&gt;目的&lt;/h4&gt;分析AI工作负载在由多个芯片组成的扩展加速器架构中，由数据传输特性引起的潜在瓶颈。&lt;h4&gt;方法&lt;/h4&gt;捕捉一组AI工作负载的单播和多播通信流量，评估通信所花费的时间和多播消息的数量，随所用芯片数量的变化。&lt;h4&gt;主要发现&lt;/h4&gt;某些AI工作负载可能受到通信，尤其是多播流量的主导影响，这可能成为性能瓶颈并限制其可扩展性。&lt;h4&gt;结论&lt;/h4&gt;工作负载分析建议在芯片级别架构灵活的互连解决方案，以提高下一代AI加速器的性能、效率和可扩展性。&lt;h4&gt;总结&lt;/h4&gt;研究强调了在设计AI加速器时考虑数据传输特性的重要性，以优化性能和扩展能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next-generation artificial intelligence (AI) workloads are posing challengesof scalability and robustness in terms of execution time due to their intrinsicevolving data-intensive characteristics. In this paper, we aim to analyse thepotential bottlenecks caused due to data movement characteristics of AIworkloads on scale-out accelerator architectures composed of multiple chiplets.Our methodology captures the unicast and multicast communication traffic of aset of AI workloads and assesses aspects such as the time spent in suchcommunications and the amount of multicast messages as a function of the numberof employed chiplets. Our studies reveal that some AI workloads are potentiallyvulnerable to the dominant effects of communication, especially multicasttraffic, which can become a performance bottleneck and limit their scalability.Workload profiling insights suggest to architect a flexible interconnectsolution at chiplet level in order to improve the performance, efficiency andscalability of next-generation AI accelerators.</description>
      <author>example@mail.com (Mariam Musavi, Emmanuel Irabor, Abhijit Das, Eduard Alarcon, Sergi Abadal)</author>
      <guid isPermaLink="false">2410.22262v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>The VIX as Stochastic Volatility for Corporate Bonds</title>
      <link>http://arxiv.org/abs/2410.22498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures, 8 graphs. Keywords: stochastic volatility,
  autoregression, kurtosis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;经典的随机波动率模型假设波动率是不可观察的。&lt;h4&gt;目的&lt;/h4&gt;将VIX视为可观察的波动率，并将其应用于企业债券市场。&lt;h4&gt;方法&lt;/h4&gt;对企业债券与10年期国债之间的利差进行时间序列模型拟合，并用VIX对残差进行除法处理。&lt;h4&gt;主要发现&lt;/h4&gt;这种除法处理使得残差更接近理想的高斯白噪声，尽管残差和VIX来自不同市场领域。&lt;h4&gt;结论&lt;/h4&gt;分析了这些模型的长期行为。&lt;h4&gt;总结&lt;/h4&gt;研究表明，将可观察的波动率引入企业债券市场可以改善模型的残差特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classic stochastic volatility models assume volatility is unobservable. Weuse the VIX for consider it observable, and use the Volatility Index: S\&amp;P 500VIX. This index was designed to measure volatility of S\&amp;P 500. We apply it toa different segment: Corporate bond markets. We fit time series models forspreads between corporate and 10-year Treasury bonds. Next, we divide residualsby VIX. Our main idea is such division makes residuals closer to the ideal caseof a Gaussian white noise. This is remarkable, since these residuals and VIXcome from separate market segments. We conclude with the analysis of long-termbehavior of these models.</description>
      <author>example@mail.com (Jihyun Park, Andrey Sarantsev)</author>
      <guid isPermaLink="false">2410.22498v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Structure Preservation Learning</title>
      <link>http://arxiv.org/abs/2410.22520v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在构建机器学习模型时，数据选择的可用性、获取成本和区分能力等因素至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过结合不同数据模态的结构，增强数据的实用性。&lt;h4&gt;方法&lt;/h4&gt;提出多模态结构保持学习（MSPL），利用一种数据模态提供的聚类结构来提升另一种模态的数据实用性。&lt;h4&gt;主要发现&lt;/h4&gt;MSPL在合成时间序列数据中揭示潜在结构，并从全基因组测序和抗菌药物抗性数据中恢复聚类。&lt;h4&gt;结论&lt;/h4&gt;MSPL能够将学习到的特征与外部结构结合，促进不同数据模态之间的协同效应。&lt;h4&gt;总结&lt;/h4&gt;MSPL是一种有效的方法，可以改善多模态数据在流行病学应用中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When selecting data to build machine learning models in practicalapplications, factors such as availability, acquisition cost, anddiscriminatory power are crucial considerations. Different data modalitiesoften capture unique aspects of the underlying phenomenon, making theirutilities complementary. On the other hand, some sources of data hoststructural information that is key to their value. Hence, the utility of onedata type can sometimes be enhanced by matching the structure of another. Wepropose Multimodal Structure Preservation Learning (MSPL) as a novel method oflearning data representations that leverages the clustering structure providedby one data modality to enhance the utility of data from another modality. Wedemonstrate the effectiveness of MSPL in uncovering latent structures insynthetic time series data and recovering clusters from whole genome sequencingand antimicrobial resistance data using mass spectrometry data in support ofepidemiology applications. The results show that MSPL can imbue the learnedfeatures with external structures and help reap the beneficial synergiesoccurring across disparate data modalities.</description>
      <author>example@mail.com (Chang Liu, Jieshi Chen, Lee H. Harrison, Artur Dubrawski)</author>
      <guid isPermaLink="false">2410.22520v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Analysis of Classifier Training on Synthetic Data for Cross-Domain Datasets</title>
      <link>http://arxiv.org/abs/2410.22748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习的主要挑战之一是需要收集大量的训练数据，缺乏足够大的数据集常常会限制其应用。&lt;h4&gt;目的&lt;/h4&gt;探讨合成数据驱动的训练在智能交通系统中的潜力，尤其是在基于摄像头的交通标志识别应用中。&lt;h4&gt;方法&lt;/h4&gt;提出一种合成数据集的增强流程，包括结构化阴影和高斯镜面高光等新颖的增强过程，并使用半监督错误引导方法生成合成图像。&lt;h4&gt;主要发现&lt;/h4&gt;在跨域测试数据集上，合成图像驱动的训练方法在大多数情况下优于真实图像训练方法，例如在GTSRB数据集上提高了10%的精度。&lt;h4&gt;结论&lt;/h4&gt;合成图像训练能够提高模型的泛化能力，降低获取图像的成本。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，合成数据结合真实数据能够有效提升深度学习模型在智能交通系统中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TITS.2020.3009186&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A major challenges of deep learning (DL) is the necessity to collect hugeamounts of training data. Often, the lack of a sufficiently large datasetdiscourages the use of DL in certain applications. Typically, acquiring therequired amounts of data costs considerable time, material and effort. Tomitigate this problem, the use of synthetic images combined with real data is apopular approach, widely adopted in the scientific community to effectivelytrain various detectors. In this study, we examined the potential of syntheticdata-based training in the field of intelligent transportation systems. Ourfocus is on camera-based traffic sign recognition applications for advanceddriver assistance systems and autonomous driving. The proposed augmentationpipeline of synthetic datasets includes novel augmentation processes such asstructured shadows and gaussian specular highlights. A well-known DL model wastrained with different datasets to compare the performance of synthetic andreal image-based trained models. Additionally, a new, detailed method toobjectively compare these models is proposed. Synthetic images are generatedusing a semi-supervised errors-guide method which is also described. Ourexperiments showed that a synthetic image-based approach outperforms in mostcases real image-based training when applied to cross-domain test datasets(+10% precision for GTSRB dataset) and consequently, the generalization of themodel is improved decreasing the cost of acquiring images.</description>
      <author>example@mail.com (Andoni Cortés, Clemente Rodríguez, Gorka Velez, Javier Barandiarán, Marcos Nieto)</author>
      <guid isPermaLink="false">2410.22748v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Bayesian Inference for Relational Graph in a Causal Vector Autoregressive Time Series</title>
      <link>http://arxiv.org/abs/2410.22617v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在高维向量自回归过程（VAR）中，同时估计图结构和自相关结构是一个重要问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来同时估计因果高维VAR过程的图结构和自相关结构。&lt;h4&gt;方法&lt;/h4&gt;使用贝叶斯框架估计平稳精度矩阵，引入一种新参数化方法，便于联合估计精度矩阵和自协方差矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;该方法保持过程的因果性，并提供了一种快速计算高维高斯VAR的降秩似然的方法。&lt;h4&gt;结论&lt;/h4&gt;在新参数化下，利用稀疏先验和似然函数获得图形参数和时间参数的后验分布，并开发了高效的马尔可夫链蒙特卡洛（MCMC）算法用于后验计算。&lt;h4&gt;理论结果&lt;/h4&gt;建立了高维后验的一致性性质。&lt;h4&gt;应用效果&lt;/h4&gt;该方法在模拟和实际数据应用中表现出色。&lt;h4&gt;总结&lt;/h4&gt;提出的估计方法在理论和实践中均显示出优越性，适用于高维VAR模型的分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a method for simultaneously estimating a contemporaneous graphstructure and autocorrelation structure for a causal high-dimensional vectorautoregressive process (VAR). The graph is estimated by estimating thestationary precision matrix using a Bayesian framework. We introduce a novelparameterization that is convenient for jointly estimating the precision matrixand the autocovariance matrices. The methodology based on the newparameterization has several desirable properties. A key feature of theproposed methodology is that it maintains causality of the process in itsestimates and also provides a fast feasible way for computing the reduced ranklikelihood for a high-dimensional Gaussian VAR. We use sparse priors along withthe likelihood under the new parameterization to obtain the posterior of thegraphical parameters as well as that of the temporal parameters. An efficientMarkov Chain Monte Carlo (MCMC) algorithm is developed for posteriorcomputation. We also establish theoretical consistency properties for thehigh-dimensional posterior. The proposed methodology shows excellentperformance in simulations and real data applications.</description>
      <author>example@mail.com (Arkaprava Roy, Anindya Roy, Subhashis Ghosal)</author>
      <guid isPermaLink="false">2410.22617v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Modelling vehicle and pedestrian collective dynamics: Challenges and advancements</title>
      <link>http://arxiv.org/abs/2410.22896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在城市化社会中，交通和行人流动的管理与调节对公共安全、经济发展和环境保护具有重要意义。&lt;h4&gt;目的&lt;/h4&gt;审视经典建模方法在集体行为中的适用性和局限性。&lt;h4&gt;方法&lt;/h4&gt;通过四个集体行为的案例进行回顾：交通流中的停走波、车道形成、长期回避行为和行人动态中的负载平衡。&lt;h4&gt;主要发现&lt;/h4&gt;停走动态和车道形成可以通过基本的反应模型处理，而后两者需要群体层面的预判和协调。&lt;h4&gt;结论&lt;/h4&gt;经典基于力的模型存在局限性，需要长远的预判机制和多尺度建模方法。&lt;h4&gt;总结&lt;/h4&gt;评估新发展和建模概念以应对交通和行人流的复杂性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In our urbanised societies, the management and regulation of traffic andpedestrian flows is of considerable interest for public safety, economicdevelopment, and the conservation of the environment. However, modelling andcontrolling the collective dynamics of vehicles and pedestrians raises severalchallenges. Not only are the individual entities self-propelled and hard todescribe, but their complex nonlinear physical and social interactions makesthe multi-agent problem of crowd and traffic flow even more involved. In thischapter, we purport to review the suitability and limitations of classicalmodelling approaches through four examples of collective behaviour: stop-and-gowaves in traffic flow, lane formation, long-term avoidance behaviour, and loadbalancing in pedestrian dynamics. While stop-and-go dynamics and lane formationcan both be addressed by basic reactive models (at least to some extent), thelatter two require anticipation and/or coordination at the level of the group.The results highlight the limitations of classical force-based models, but alsothe need for long-term anticipation mechanisms and multiscale modellingapproaches. In response, we review new developments and modelling concepts.</description>
      <author>example@mail.com (Cécile Appert-Rolland, Alexandre Nicolas, Armin Seyfried, Antoine Tordeux, Denis Ullmo)</author>
      <guid isPermaLink="false">2410.22896v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>When Circular Economy Meets the Smart City Ecosystem: Defining the Smart and Circular City</title>
      <link>http://arxiv.org/abs/2410.22012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint submitted to the 10th IEEE International Smart Cities
  Conference 2024 (ISC2 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能城市在过去20年中成为活跃的研究领域，适应技术进步，关注可持续性和气候变化。&lt;h4&gt;目的&lt;/h4&gt;扩展智能城市的定义，将循环经济作为核心支柱，提出“智能与循环城市”的概念。&lt;h4&gt;方法&lt;/h4&gt;讨论智能与循环城市如何在可持续性和智能性方面相互融合，同时促进新商业活动和模式。&lt;h4&gt;主要发现&lt;/h4&gt;智能与循环城市有助于将公民置于智能城市的核心，推动更广泛的循环经济活动。&lt;h4&gt;结论&lt;/h4&gt;以前的智能城市和技术研究为在城市中实施循环经济活动提供了基础，超越传统方法。&lt;h4&gt;挑战&lt;/h4&gt;概述当前在这一领域的开放挑战和仍需解决的研究问题。&lt;h4&gt;总结&lt;/h4&gt;智能与循环城市的概念促进了可持续性和智能发展的结合，并为未来的研究提供了方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Smart cities have been a very active research area in the past 20 years,while continuously adapting to new technological advancements and keeping upwith the times regarding sustainability and climate change. In this context,there have been numerous proposals to expand the scope of smart cities,focusing on resilience and sustainability, among other aspects, resulting interms like smart sustainable cities. At the same time, there is an ongoingdiscussion regarding the degree in which smart cities put people at theircentre. In this work, we argue toward expanding the current smart citydefinition by integrating the circular economy as one of its central pillarsand adopting the term smart (and) circular city. We discuss the ways a smartand circular city encompasses both sustainability and smartness in an integralmanner, while also being well-positioned to foster novel business activity andmodels and helping to place citizens at the heart of the smart city. In thissense, we also argue that previous research in smart cities and technologies,such as those related to Industry 4.0, can serve as a cornerstone to implementcircular economy activities within cities, at a scale that exceeds currentactivities that are based on more conventional approaches. We also outlinecurrent open challenges in this domain and research questions that still needto be addressed.</description>
      <author>example@mail.com (Georgios Mylonas, Athanasios Kalogeras, Sobah Abbas Petersen, Luis Muñoz, Ioannis Chatzigiannakis)</author>
      <guid isPermaLink="false">2410.22012v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Leader-Follower 3D Formation for Underwater Robots</title>
      <link>http://arxiv.org/abs/2410.23128v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at DARS 2024 (The 17th International Symposium on
  Distributed Autonomous Robotic Systems)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;鱼群的行为被假设为能带来多种生存优势，包括觅食成功、躲避掠食者的安全性，以及通过水动力相互作用节省能量。&lt;h4&gt;目的&lt;/h4&gt;探讨水下机器人集体如何通过形成控制实现类似的生存优势，特别是在环境监测中的有效空间采样。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于领导者-跟随者策略的水下形成控制方法，仅依靠视觉感知和低计算量的反应控制算法，实现复杂的3D队形。&lt;h4&gt;主要发现&lt;/h4&gt;首次通过物理平台BlueSwarm成功演示了直线、并排和错列游泳的3D队形，同时在物理基础模拟器中研究了更复杂的队形，提供了关于水下惯性/阻力条件下队形收敛性和稳定性的新的见解。&lt;h4&gt;结论&lt;/h4&gt;研究为未来水下机器人群体在水域环境中进行最小通信的应用奠定了基础。&lt;h4&gt;总结&lt;/h4&gt;通过水下机器人集体的形成控制，能够有效模拟鱼群行为，以提高环境监测的效率和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The schooling behavior of fish is hypothesized to confer many survivalbenefits, including foraging success, safety from predators, and energy savingsthrough hydrodynamic interactions when swimming in formation. Underwater robotcollectives may be able to achieve similar benefits in future applications,e.g. using formation control to achieve efficient spatial sampling forenvironmental monitoring. Although many theoretical algorithms exist formulti-robot formation control, they have not been tested in the underwaterdomain due to the fundamental challenges in underwater communication. Here weintroduce a leader-follower strategy for underwater formation control thatallows us to realize complex 3D formations, using purely vision-basedperception and a reactive control algorithm that is low computation. We use aphysical platform, BlueSwarm, to demonstrate for the first time an experimentalrealization of inline, side-by-side, and staggered swimming 3D formations. Morecomplex formations are studied in a physics-based simulator, providing newinsights into the convergence and stability of formations given underwaterinertial/drag conditions. Our findings lay the groundwork for futureapplications of underwater robot swarms in aquatic environments with minimalcommunication.</description>
      <author>example@mail.com (Di Ni, Hungtang Ko, Radhika Nagpal)</author>
      <guid isPermaLink="false">2410.23128v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>WaveRoRA: Wavelet Rotary Route Attention for Multivariate Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.22649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is coming soon! For sure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，基于Transformer的模型在多变量时间序列预测中取得了显著成功，但以往的研究主要集中在时间域或频率域提取特征，无法充分捕捉趋势和周期特征。&lt;h4&gt;目的&lt;/h4&gt;提出一种小波学习框架，以建模时间序列数据的复杂时间依赖性。&lt;h4&gt;方法&lt;/h4&gt;小波域集成时间和频率信息，分析信号在不同尺度上的局部特征。同时，提出了一种新颖的注意力机制：旋转路由注意力（RoRA），具有线性复杂度，解决了传统Softmax注意力的高计算成本问题。&lt;h4&gt;主要发现&lt;/h4&gt;WaveRoRA在小波域中捕捉时间序列间的依赖性，并在八个真实世界数据集上进行了广泛实验，结果表明其在性能上优于现有的最先进模型，同时保持了较低的计算成本。&lt;h4&gt;结论&lt;/h4&gt;WaveRoRA模型有效地解决了多变量时间序列预测中的长期依赖性问题，展现出更好的性能和效率。&lt;h4&gt;总结&lt;/h4&gt;该研究提出的新方法在多变量时间序列预测中显示出优越性，为未来的研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, Transformer-based models (Transformers) have achievedsignificant success in multivariate time series forecasting (MTSF). However,previous works focus on extracting features either from the time domain or thefrequency domain, which inadequately captures the trends and periodiccharacteristics. To address this issue, we propose a wavelet learning frameworkto model complex temporal dependencies of the time series data. The waveletdomain integrates both time and frequency information, allowing for theanalysis of local characteristics of signals at different scales. Additionally,the Softmax self-attention mechanism used by Transformers has quadraticcomplexity, which leads to excessive computational costs when capturinglong-term dependencies. Therefore, we propose a novel attention mechanism:Rotary Route Attention (RoRA). Unlike Softmax attention, RoRA utilizes rotaryposition embeddings to inject relative positional information to sequencetokens and introduces a small number of routing tokens $r$ to aggregateinformation from the $KV$ matrices and redistribute it to the $Q$ matrix,offering linear complexity. We further propose WaveRoRA, which leverages RoRAto capture inter-series dependencies in the wavelet domain. We conductextensive experiments on eight real-world datasets. The results indicate thatWaveRoRA outperforms existing state-of-the-art models while maintaining lowercomputational costs.</description>
      <author>example@mail.com (Aobo Liang, Yan Sun)</author>
      <guid isPermaLink="false">2410.22649v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Resilient-By-Design: A Resiliency Framework for Future Wireless Networks</title>
      <link>http://arxiv.org/abs/2410.23203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Communications Magazine&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;未来社会将越来越数字化、超连接和全球数据驱动，6G及后续无线网络预计将连接数字世界与物理世界。&lt;h4&gt;目的&lt;/h4&gt;为了给不同行业（如工业、智慧城市、电子健康和自主交通）提供无线连接作为服务，增强社会对无线网络的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出一个以韧性为设计理念的框架，概述干扰环境，详细阐述主要特征，并描述预测、预防、保护和进步四个关键步骤。&lt;h4&gt;主要发现&lt;/h4&gt;通过初步的模拟结果展示了该框架在应对网络中断时的潜在优势和效率。&lt;h4&gt;结论&lt;/h4&gt;6G及后续网络不仅要提供近乎即时和几乎无限的连接，还要具备抵御内部和外部干扰的能力。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种综合的方法来应对未来无线网络的挑战，确保其在各种干扰情况下的韧性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Our future society will be increasingly digitalised, hyper-connected andglobally data driven. The sixth generation (6G) and beyond 6G wireless networksare expected to bridge the digital and physical worlds by providing wirelessconnectivity as a service to different vertical sectors, including industries,smart cities, eHealth and autonomous transportation. Such far reachingintegration will render the society increasingly reliant on wireless networks.While this has the potential to greatly enhance our quality and ease of life,any disruption to these networks would also have significant impact withoverreaching consequences. Disruptions can happen due to a variety of reasons,including planned outages, failures due to the nature of wireless propagation,natural disasters, and deliberate cybersecurity attacks. Hence, 6G and beyond6G networks should not only provide near instant and virtually unlimitedconnectivity, but also be resilient against internal and external disruptions.This paper proposes a resilient-by-design framework towards this end. First, weprovide an overview of the disruption landscape. Thereafter, we comprehensivelyoutline the main features of the proposed concept. Finally, we detail the fourkey steps of the framework, namely predict, preempt, protect and progress. Asimple but illustrative preliminary simulation result is also presented tohighlight the potential advantages and efficiency of the proposed approach inaddressing outages.</description>
      <author>example@mail.com (Nurul Huda Mahmood, Sumudu Samarakoon, Pawani Porambage, Mehdi Bennis, Matti Latva-aho)</author>
      <guid isPermaLink="false">2410.23203v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>YOLOv11 for Vehicle Detection: Advancements, Performance, and Applications in Intelligent Transportation Systems</title>
      <link>http://arxiv.org/abs/2410.22898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的车辆检测对于智能交通系统、自动驾驶和交通监测的发展至关重要。&lt;h4&gt;目的&lt;/h4&gt;分析YOLO11在车辆检测任务中的最新进展。&lt;h4&gt;方法&lt;/h4&gt;基于多种车辆类型的综合数据集，评估YOLO11的表现，使用精度、召回率、F1分数和平均平均精度（mAP）等指标。&lt;h4&gt;主要发现&lt;/h4&gt;YOLO11在检测较小和被遮挡车辆方面超越了YOLOv8和YOLOv10，同时保持竞争力的推理时间。&lt;h4&gt;结论&lt;/h4&gt;YOLO11在复杂环境中展示了更高的检测速度、准确性和鲁棒性，适合实时应用。&lt;h4&gt;应用价值&lt;/h4&gt;YOLO11有潜力提升自动驾驶性能和交通监测系统，提供未来发展的思路。&lt;h4&gt;总结&lt;/h4&gt;YOLO11的架构改进进一步推动了高效、可扩展的车辆检测系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate vehicle detection is essential for the development of intelligenttransportation systems, autonomous driving, and traffic monitoring. This paperpresents a detailed analysis of YOLO11, the latest advancement in the YOLOseries of deep learning models, focusing exclusively on vehicle detectiontasks. Building upon the success of its predecessors, YOLO11 introducesarchitectural improvements designed to enhance detection speed, accuracy, androbustness in complex environments. Using a comprehensive dataset comprisingmultiple vehicle types-cars, trucks, buses, motorcycles, and bicycles weevaluate YOLO11's performance using metrics such as precision, recall, F1score, and mean average precision (mAP). Our findings demonstrate that YOLO11surpasses previous versions (YOLOv8 and YOLOv10) in detecting smaller and moreoccluded vehicles while maintaining a competitive inference time, making itwell-suited for real-time applications. Comparative analysis shows significantimprovements in the detection of complex vehicle geometries, furthercontributing to the development of efficient and scalable vehicle detectionsystems. This research highlights YOLO11's potential to enhance autonomousvehicle performance and traffic monitoring systems, offering insights forfuture developments in the field.</description>
      <author>example@mail.com (Mujadded Al Rabbani Alif)</author>
      <guid isPermaLink="false">2410.22898v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Robust and Efficient Visual-Inertial Initialization with Probabilistic Normal Epipolar Constraint</title>
      <link>http://arxiv.org/abs/2410.19473v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确且稳健的初始化对于视觉惯性里程计（VIO）至关重要，差的初始化会严重影响位姿精度。&lt;h4&gt;目的&lt;/h4&gt;估计加速度计偏置、陀螺仪偏置、初始速度和重力等参数。&lt;h4&gt;方法&lt;/h4&gt;扩展旋转-位移-解耦框架，加入新的不确定性参数和优化模块；采用概率正常极线约束的陀螺仪偏置优化器；融合IMU和视觉测量以高效求解速度、重力和尺度；设计附加的精细化模块以减少重力和尺度误差。&lt;h4&gt;主要发现&lt;/h4&gt;在EuRoC数据集上进行的广泛初始化测试表明，该方法将陀螺仪偏置和旋转估计误差平均减少了16%和4%；重力误差平均减少了29%。&lt;h4&gt;结论&lt;/h4&gt;该方法显著提高了VIO的初始化精度，尤其是在快速运动或退化场景下。&lt;h4&gt;总结&lt;/h4&gt;通过改进的初始化方法，显著提升了视觉惯性里程计的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and robust initialization is essential for Visual-Inertial Odometry(VIO), as poor initialization can severely degrade pose accuracy. Duringinitialization, it is crucial to estimate parameters such as accelerometerbias, gyroscope bias, initial velocity, and gravity, etc. The IMU sensorrequires precise estimation of gyroscope bias because gyroscope bias affectsrotation, velocity and position. Most existing VIO initialization methods adoptStructure from Motion (SfM) to solve for gyroscope bias. However, SfM is notstable and efficient enough in fast motion or degenerate scenes. To overcomethese limitations, we extended the rotation-translation-decoupling framework byadding new uncertainty parameters and optimization modules. First, we adopt agyroscope bias optimizer that incorporates probabilistic normal epipolarconstraints. Second, we fuse IMU and visual measurements to solve for velocity,gravity, and scale efficiently. Finally, we design an additional refinementmodule that effectively diminishes gravity and scale errors. Extensiveinitialization tests on the EuRoC dataset show that our method reduces thegyroscope bias and rotation estimation error by an average of 16% and 4%respectively. It also significantly reduces the gravity error, with an averagereduction of 29%.</description>
      <author>example@mail.com (Changshi Mu, Daquan Feng, Qi Zheng, Yuan Zhuang)</author>
      <guid isPermaLink="false">2410.19473v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Persistent Homology for MCI Classification: A Comparative Analysis between Graph and Vietoris-Rips Filtrations</title>
      <link>http://arxiv.org/abs/2410.22681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;轻度认知障碍（MCI）通常与早期神经退行性变有关，表现为细微的认知下降和大脑连接性中断。&lt;h4&gt;目的&lt;/h4&gt;分析与MCI相关的拓扑变化，重点研究早期MCI和晚期MCI两种亚型。&lt;h4&gt;方法&lt;/h4&gt;使用来自两个人群的fMRI时间序列数据，分别为公开的ADNI数据集（西方队列）和内部TLSA数据集（印度城市队列）。采用持久同调这一拓扑数据分析方法，使用Vietoris-Rips和图过滤两种不同的过滤技术进行MCI亚型分类。&lt;h4&gt;主要发现&lt;/h4&gt;Vietoris-Rips过滤方法在捕捉大脑连接性微小变化方面显著优于图过滤，分类准确率为85.7%，而图过滤的最高准确率为71.4%。&lt;h4&gt;结论&lt;/h4&gt;持久同调方法，特别是结合Wasserstein距离，显示出在早期诊断和精确分类认知障碍方面的潜力，为MCI的大脑连接性变化提供了重要见解。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了Vietoris-Rips过滤在检测与神经退行性变相关的复杂拓扑特征方面的敏感性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mild cognitive impairment (MCI), often linked to early neurodegeneration, ischaracterized by subtle cognitive declines and disruptions in brainconnectivity. The present study offers a detailed analysis of topologicalchanges associated with MCI, focusing on two subtypes: Early MCI and Late MCI.This analysis utilizes fMRI time series data from two distinct populations: thepublicly available ADNI dataset (Western cohort) and the in-house TLSA dataset(Indian Urban cohort). Persistent Homology, a topological data analysis method,is employed with two distinct filtration techniques - Vietoris-Rips and graphfiltration-for classifying MCI subtypes. For Vietoris-Rips filtration,inter-ROI Wasserstein distance matrices between persistent diagrams are usedfor classification, while graph filtration relies on the top ten mostpersistent homology features. Comparative analysis shows that the Vietoris-Ripsfiltration significantly outperforms graph filtration, capturing subtlevariations in brain connectivity with greater accuracy. The Vietoris-Ripsfiltration method achieved the highest classification accuracy of 85.7\% fordistinguishing between age and gender matched healthy controls and MCI, whereasgraph filtration reached a maximum accuracy of 71.4\% for the same task. Thissuperior performance highlights the sensitivity of Vietoris-Rips filtration indetecting intricate topological features associated with neurodegeneration. Thefindings underscore the potential of persistent homology, particularly whencombined with the Wasserstein distance, as a powerful tool for early diagnosisand precise classification of cognitive impairments, offering valuable insightsinto brain connectivity changes in MCI.</description>
      <author>example@mail.com (Debanjali Bhattacharya, Rajneet Kaur, Ninad Aithal, Neelam Sinha, Thomas Gregor Issac)</author>
      <guid isPermaLink="false">2410.22681v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning</title>
      <link>http://arxiv.org/abs/2410.23156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;广泛智能体应形成任务特定的抽象，选择性地暴露任务的基本元素，同时抽象掉原始传感器运动空间的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合符号和神经知识表示优势的首次抽象语言——神经符号谓词。&lt;h4&gt;方法&lt;/h4&gt;概述了一种在线算法，用于发明这些谓词并学习抽象世界模型。&lt;h4&gt;主要发现&lt;/h4&gt;与层次强化学习、视觉-语言模型规划和符号谓词发明方法相比，本方法在五个模拟机器人领域的任务中表现出更好的样本复杂度、更强的跨分布泛化能力和更好的可解释性。&lt;h4&gt;结论&lt;/h4&gt;我们的研究表明，神经符号谓词方法在多个方面优于现有技术。&lt;h4&gt;总结&lt;/h4&gt;该研究为智能体的任务抽象提供了新的视角和方法，有助于提升其在复杂环境中的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Broadly intelligent agents should form task-specific abstractions thatselectively expose the essential elements of a task, while abstracting away thecomplexity of the raw sensorimotor space. In this work, we presentNeuro-Symbolic Predicates, a first-order abstraction language that combines thestrengths of symbolic and neural knowledge representations. We outline anonline algorithm for inventing such predicates and learning abstract worldmodels. We compare our approach to hierarchical reinforcement learning,vision-language model planning, and symbolic predicate invention approaches, onboth in- and out-of-distribution tasks across five simulated robotic domains.Results show that our approach offers better sample complexity, strongerout-of-distribution generalization, and improved interpretability.</description>
      <author>example@mail.com (Yichao Liang, Nishanth Kumar, Hao Tang, Adrian Weller, Joshua B. Tenenbaum, Tom Silver, João F. Henriques, Kevin Ellis)</author>
      <guid isPermaLink="false">2410.23156v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Context-Based Visual-Language Place Recognition</title>
      <link>http://arxiv.org/abs/2410.19341v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉基础的机器人定位和SLAM中，视觉地点识别（VPR）至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决给定查询图像对应位置的准确识别问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的VPR方法，通过零样本、语言驱动的语义分割模型提取像素级嵌入，构建语义图像描述符，无需额外训练。&lt;h4&gt;主要发现&lt;/h4&gt;在挑战性地点识别场景中，所提出的方法优于非学习的图像表示技术和现成的卷积神经网络（CNN）描述符。&lt;h4&gt;结论&lt;/h4&gt;该方法在场景变化中保持稳健性，且不需要大量标记数据进行训练。&lt;h4&gt;代码链接&lt;/h4&gt;我们的代码可在 https://github.com/woo-soojin/context-based-vlpr 获取。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，能够有效应对视觉地点识别中的外观变化问题，提升了识别准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/woo-soojin/context-based-vlpr&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In vision-based robot localization and SLAM, Visual Place Recognition (VPR)is essential. This paper addresses the problem of VPR, which involvesaccurately recognizing the location corresponding to a given query image. Apopular approach to vision-based place recognition relies on low-level visualfeatures. Despite significant progress in recent years, place recognition basedon low-level visual features is challenging when there are changes in sceneappearance. To address this, end-to-end training approaches have been proposedto overcome the limitations of hand-crafted features. However, these approachesstill fail under drastic changes and require large amounts of labeled data totrain models, presenting a significant limitation. Methods that leveragehigh-level semantic information, such as objects or categories, have beenproposed to handle variations in appearance. In this paper, we introduce anovel VPR approach that remains robust to scene changes and does not requireadditional training. Our method constructs semantic image descriptors byextracting pixel-level embeddings using a zero-shot, language-driven semanticsegmentation model. We validate our approach in challenging place recognitionscenarios using real-world public dataset. The experiments demonstrate that ourmethod outperforms non-learned image representation techniques andoff-the-shelf convolutional neural network (CNN) descriptors. Our code isavailable at https: //github.com/woo-soojin/context-based-vlpr.</description>
      <author>example@mail.com (Soojin Woo, Seong-Woo Kim)</author>
      <guid isPermaLink="false">2410.19341v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data</title>
      <link>http://arxiv.org/abs/2410.22938v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;强化学习在交通信号控制（TSC）中的应用已被广泛研究，取得了显著成就。然而，大多数现有研究假设所有周边交叉口的交通数据通过传感器完全持续可用。&lt;h4&gt;目的&lt;/h4&gt;针对现实应用中由于传感器故障或数据丢失导致的交通信号控制中的数据缺失问题，提出DiffLight模型。&lt;h4&gt;方法&lt;/h4&gt;引入条件扩散模型DiffLight，结合交通数据插补和决策制定，采用部分奖励条件扩散（PRCD）模型来防止缺失奖励干扰学习过程，同时设计空间-时间变换器（STFormer）架构以捕捉交叉口间的空间-时间依赖性，并提出扩散通信机制（DCM）以提升在数据缺失情境下的通信与控制性能。&lt;h4&gt;主要发现&lt;/h4&gt;在五个不同数据缺失情境下的广泛实验表明，DiffLight有效地解决了缺失数据下的交通信号控制问题。&lt;h4&gt;结论&lt;/h4&gt;DiffLight是一种有效的控制器，能够应对交通信号控制中的数据缺失挑战，其代码已在GitHub上发布。&lt;h4&gt;总结&lt;/h4&gt;DiffLight模型通过创新的方法应对交通信号控制中的数据缺失问题，显示出其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lokol5579/DiffLight-release&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The application of reinforcement learning in traffic signal control (TSC) hasbeen extensively researched and yielded notable achievements. However, mostexisting works for TSC assume that traffic data from all surroundingintersections is fully and continuously available through sensors. Inreal-world applications, this assumption often fails due to sensor malfunctionsor data loss, making TSC with missing data a critical challenge. To meet theneeds of practical applications, we introduce DiffLight, a novel conditionaldiffusion model for TSC under data-missing scenarios in the offline setting.Specifically, we integrate two essential sub-tasks, i.e., traffic dataimputation and decision-making, by leveraging a Partial Rewards ConditionedDiffusion (PRCD) model to prevent missing rewards from interfering with thelearning process. Meanwhile, to effectively capture the spatial-temporaldependencies among intersections, we design a Spatial-Temporal transFormer(STFormer) architecture. In addition, we propose a Diffusion CommunicationMechanism (DCM) to promote better communication and control performance underdata-missing scenarios. Extensive experiments on five datasets with variousdata-missing scenarios demonstrate that DiffLight is an effective controller toaddress TSC with missing data. The code of DiffLight is released athttps://github.com/lokol5579/DiffLight-release.</description>
      <author>example@mail.com (Hanyang Chen, Yang Jiang, Shengnan Guo, Xiaowei Mao, Youfang Lin, Huaiyu Wan)</author>
      <guid isPermaLink="false">2410.22938v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Community search signatures as foundation features for human-centered geospatial modeling</title>
      <link>http://arxiv.org/abs/2410.22721v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures, presented at the DMLR workshop at ICML 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;聚合的相对搜索频率提供了反映人们习惯、关注点、兴趣、意图和一般信息需求的独特信号，这些信号在其他现成数据集中无法找到。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，以生成聚合和匿名的搜索兴趣表示，作为社区级别地理空间建模的基础特征。&lt;h4&gt;方法&lt;/h4&gt;使用跨多个领域的空间数据集对这些特征进行基准测试，并在覆盖95%以上美国大陆人口的邮政编码中进行建模。&lt;h4&gt;主要发现&lt;/h4&gt;在3000人以上的邮政编码中，针对20%保留县的缺失值预测模型在21个健康变量上平均$R^2$得分为0.74，在6个人口和环境变量上为0.80。&lt;h4&gt;结论&lt;/h4&gt;这些搜索特征可以用于空间预测而无需严格的时间对齐，且所得到的模型优于空间插值和使用卫星图像特征的先进方法。&lt;h4&gt;总结&lt;/h4&gt;研究表明，聚合搜索数据在地理空间建模中具有重要应用潜力，能够提升预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Aggregated relative search frequencies offer a unique composite signalreflecting people's habits, concerns, interests, intents, and generalinformation needs, which are not found in other readily available datasets.Temporal search trends have been successfully used in time series modelingacross a variety of domains such as infectious diseases, unemployment rates,and retail sales. However, most existing applications require curatingspecialized datasets of individual keywords, queries, or query clusters, andthe search data need to be temporally aligned with the outcome variable ofinterest. We propose a novel approach for generating an aggregated andanonymized representation of search interest as foundation features at thecommunity level for geospatial modeling. We benchmark these features usingspatial datasets across multiple domains. In zip codes with a populationgreater than 3000 that cover over 95% of the contiguous US population, ourmodels for predicting missing values in a 20% set of holdout counties achievean average $R^2$ score of 0.74 across 21 health variables, and 0.80 across 6demographic and environmental variables. Our results demonstrate that thesesearch features can be used for spatial predictions without strict temporalalignment, and that the resulting models outperform spatial interpolation andstate of the art methods using satellite imagery features.</description>
      <author>example@mail.com (Mimi Sun, Chaitanya Kamath, Mohit Agarwal, Arbaaz Muslim, Hector Yee, David Schottlander, Shailesh Bavadekar, Niv Efron, Shravya Shetty, Gautam Prasad)</author>
      <guid isPermaLink="false">2410.22721v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>V2X-Assisted Distributed Computing and Control Framework for Connected and Automated Vehicles under Ramp Merging Scenario</title>
      <link>http://arxiv.org/abs/2410.22987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been submitted to IEEE Journal. The source code has
  been released at:
  https://github.com/qiongwu86/V2X-Assisted-Distributed-Computing-and-Control-Framework-for-Connected-and-Automated-Vehicles.git&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究连接与自动化车辆（CAVs）在匝道合并场景下的分布式计算与协作控制。&lt;h4&gt;目的&lt;/h4&gt;制定集中式协作轨迹规划问题，优化车辆轨迹以满足安全约束和交通性能。&lt;h4&gt;方法&lt;/h4&gt;提出通过车联网（V2X）通信实现的分布式解决方案，减少对中央控制器的依赖并降低计算时间。&lt;h4&gt;主要发现&lt;/h4&gt;提出的分布式合作迭代模型预测控制（DCIMPC）方法能有效分解高维、集中且非凸的问题，利用车辆的计算资源快速求解。&lt;h4&gt;结论&lt;/h4&gt;该框架在收敛性、安全性和求解速度方面表现良好，DCIMPC显著提高了计算速度而不损害系统性能。&lt;h4&gt;总结&lt;/h4&gt;本研究为V2X辅助的分布式计算与控制提供了系统框架，验证了其有效性和优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/qiongwu86/v2x-assisted-distributed-computing-and-control-framework-for-connected-and-automated-vehicles&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates distributed computing and cooperative control ofconnected and automated vehicles (CAVs) in ramp merging scenario undertransportation cyber-physical system. Firstly, a centralized cooperativetrajectory planning problem is formulated subject to the safely constraints andtraffic performance in ramp merging scenario, where the trajectories of allvehicles are jointly optimized. To get rid of the reliance on a centralcontroller and reduce computation time, a distributed solution to this problemimplemented among CAVs through Vehicles-to-Everything (V2X) communication isproposed. Unlike existing method, our method can distribute the computationaltask among CAVs and carry out parallel solving through V2X communication. Then,a multi-vehicles model predictive control (MPC) problem aimed at maximizingsystem stability and minimizing control input is formulated based on thesolution of the first problem subject to strict safety constants and inputlimits. Due to these complex constraints, this problem becomeshigh-dimensional, centralized, and non-convex. To solve it in a short time, adecomposition and convex reformulation method, namely distributed cooperativeiterative model predictive control (DCIMPC), is proposed. This method leveragesthe communication capability of CAVs to decompose the problem, making full useof the computational resources on vehicles to achieve fast solutions anddistributed control. The two above problems with their corresponding solvingmethods form the systemic framework of the V2X assisted distributed computingand control. Simulations have been conducted to evaluate the framework'sconvergence, safety, and solving speed. Additionally, extra experiments areconducted to validate the performance of DCIMPC. The results show that ourmethod can greatly improve computation speed without sacrificing systemperformance.</description>
      <author>example@mail.com (Qiong Wu, Jiahou Chu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief)</author>
      <guid isPermaLink="false">2410.22987v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>RopeTP: Global Human Motion Recovery via Integrating Robust Pose Estimation with Diffusion Trajectory Prior</title>
      <link>http://arxiv.org/abs/2410.20358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by WACV 2025 (Round 1)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了RopeTP框架，结合了稳健的姿态估计和扩散轨迹先验，用于从视频中重建全球人类运动。&lt;h4&gt;目的&lt;/h4&gt;重建精确、稳定的全球人类运动轨迹，特别是在遮挡情况下。&lt;h4&gt;方法&lt;/h4&gt;采用分层注意机制，提高上下文感知，利用可见解剖结构的关系改善局部姿态估计的准确性，并通过扩散轨迹模型从局部姿态序列预测现实的人类运动。&lt;h4&gt;主要发现&lt;/h4&gt;RopeTP在两个基准数据集上超越了现有方法，尤其在遮挡场景中表现优异，且比依赖SLAM的初始相机估计和优化的方法更准确。&lt;h4&gt;结论&lt;/h4&gt;RopeTP提供了更准确和现实的轨迹重建，确保生成的轨迹与观察到的局部动作一致，并自然展开。&lt;h4&gt;总结&lt;/h4&gt;RopeTP是一个新颖的框架，通过改进局部姿态估计和引入扩散模型，实现了高效的3D人类运动重建。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present RopeTP, a novel framework that combines Robust pose estimationwith a diffusion Trajectory Prior to reconstruct global human motion fromvideos. At the heart of RopeTP is a hierarchical attention mechanism thatsignificantly improves context awareness, which is essential for accuratelyinferring the posture of occluded body parts. This is achieved by exploitingthe relationships with visible anatomical structures, enhancing the accuracy oflocal pose estimations. The improved robustness of these local estimationsallows for the reconstruction of precise and stable global trajectories.Additionally, RopeTP incorporates a diffusion trajectory model that predictsrealistic human motion from local pose sequences. This model ensures that thegenerated trajectories are not only consistent with observed local actions butalso unfold naturally over time, thereby improving the realism and stability of3D human motion reconstruction. Extensive experimental validation shows thatRopeTP surpasses current methods on two benchmark datasets, particularlyexcelling in scenarios with occlusions. It also outperforms methods that relyon SLAM for initial camera estimates and extensive optimization, deliveringmore accurate and realistic trajectories.</description>
      <author>example@mail.com (Mingjiang Liang, Yongkang Cheng, Hualin Liang, Shaoli Huang, Wei Liu)</author>
      <guid isPermaLink="false">2410.20358v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks</title>
      <link>http://arxiv.org/abs/2410.23208v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The first two authors contributed equally. Project page located at:
  https://kinetix-env.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型模型在离线数据集上通过自监督学习取得了出色的文本和图像处理能力，但在顺序决策问题中的应用仍然是一个开放性挑战。&lt;h4&gt;目的&lt;/h4&gt;通过生成大量基于物理的2D任务，训练一个通用的强化学习（RL）代理，以提高其在物理控制方面的能力。&lt;h4&gt;方法&lt;/h4&gt;引入Kinetix，一个开放的物理基础RL环境空间，涵盖从机器人运动和抓取到视频游戏和经典RL环境的任务，并使用新型硬件加速物理引擎Jax2D进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;训练后的代理展现出强大的物理推理能力，能够零-shot解决未见过的人类设计的环境。对感兴趣任务进行微调的代理性能显著优于从头开始训练的RL代理。&lt;h4&gt;结论&lt;/h4&gt;这一研究表明大规模、混合质量的预训练对于在线RL是可行的，Kinetix有望成为进一步研究的有用框架。&lt;h4&gt;总结&lt;/h4&gt;Kinetix为物理控制的强化学习提供了新的训练环境，展示了在复杂任务中提升代理能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While large models trained with self-supervised learning on offline datasetshave shown remarkable capabilities in text and image domains, achieving thesame generalisation for agents that act in sequential decision problems remainsan open challenge. In this work, we take a step towards this goal byprocedurally generating tens of millions of 2D physics-based tasks and usingthese to train a general reinforcement learning (RL) agent for physicalcontrol. To this end, we introduce Kinetix: an open-ended space ofphysics-based RL environments that can represent tasks ranging from roboticlocomotion and grasping to video games and classic RL environments, all withina unified framework. Kinetix makes use of our novel hardware-acceleratedphysics engine Jax2D that allows us to cheaply simulate billions of environmentsteps during training. Our trained agent exhibits strong physical reasoningcapabilities, being able to zero-shot solve unseen human-designed environments.Furthermore, fine-tuning this general agent on tasks of interest showssignificantly stronger performance than training an RL agent *tabula rasa*.This includes solving some environments that standard RL training completelyfails at. We believe this demonstrates the feasibility of large scale,mixed-quality pre-training for online RL and we hope that Kinetix will serve asa useful framework to investigate this further.</description>
      <author>example@mail.com (Michael Matthews, Michael Beukman, Chris Lu, Jakob Foerster)</author>
      <guid isPermaLink="false">2410.23208v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Cascade Approach for APT Campaign Attribution in System Event Logs: Technique Hunting and Subgraph Matching</title>
      <link>http://arxiv.org/abs/2410.22602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着高级持续性威胁（APTs）日益复杂，对有效检测方法的需求不断增加。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过系统事件日志识别APT攻击活动。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为SFM的级联方法，结合了技术猎捕和APT活动归属。&lt;h4&gt;主要发现&lt;/h4&gt;在五个真实APT活动的评估中，所提方法表现出可靠的性能。&lt;h4&gt;结论&lt;/h4&gt;通过将检测到的技术与已知攻击序列对齐，可以更准确地确定最可能的APT活动。&lt;h4&gt;总结&lt;/h4&gt;本研究为识别APT攻击提供了一种有效的检测方法，具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As Advanced Persistent Threats (APTs) grow increasingly sophisticated, thedemand for effective detection methods has intensified. This study addressesthe challenge of identifying APT campaign attacks through system event logs. Acascading approach, name SFM, combines Technique hunting and APT campaignattribution. Our approach assumes that real-world system event logs contain avast majority of normal events interspersed with few suspiciously maliciousones and that these logs are annotated with Techniques of MITRE ATT&amp;CKframework for attack pattern recognition. Then, we attribute APT campaignattacks by aligning detected Techniques with known attack sequences todetermine the most likely APT campaign. Evaluations on five real-world APTcampaigns indicate that the proposed approach demonstrates reliableperformance.</description>
      <author>example@mail.com (Yi-Ting Huang, Ying-Ren Guo, Guo-Wei Wong, Meng Chang Chen)</author>
      <guid isPermaLink="false">2410.22602v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MIXAD: Memory-Induced Explainable Time Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2410.22735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICPR 2024 (oral paper)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代工业应用中，准确检测和诊断多变量时间序列数据中的异常至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种可解释的异常检测模型，弥补现有方法在解释性与检测性能之间的短板。&lt;h4&gt;方法&lt;/h4&gt;MIXAD（基于记忆的可解释时间序列异常检测）结合记忆网络和时空处理单元，理解传感器关系中的复杂动态和拓扑结构。&lt;h4&gt;主要发现&lt;/h4&gt;提出的新异常评分方法能够检测到记忆激活模式中的显著变化，并在可解释性指标上超越现有最佳基准34.30%和34.51%。&lt;h4&gt;结论&lt;/h4&gt;MIXAD不仅确保了良好的检测性能，同时提升了模型的可解释性。&lt;h4&gt;总结&lt;/h4&gt;MIXAD为多变量时间序列数据的异常检测提供了一种有效且可解释的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; For modern industrial applications, accurately detecting and diagnosinganomalies in multivariate time series data is essential. Despite such need,most state-of-the-art methods often prioritize detection performance over modelinterpretability. Addressing this gap, we introduce MIXAD (Memory-InducedExplainable Time Series Anomaly Detection), a model designed for interpretableanomaly detection. MIXAD leverages a memory network alongside spatiotemporalprocessing units to understand the intricate dynamics and topologicalstructures inherent in sensor relationships. We also introduce a novel anomalyscoring method that detects significant shifts in memory activation patternsduring anomalies. Our approach not only ensures decent detection performancebut also outperforms state-of-the-art baselines by 34.30% and 34.51% ininterpretability metrics.</description>
      <author>example@mail.com (Minha Kim, Kishor Kumar Bhaumik, Amin Ahsan Ali, Simon S. Woo)</author>
      <guid isPermaLink="false">2410.22735v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Levels of explanation -- implementation and evaluation of what and when for different time-sensitive tasks</title>
      <link>http://arxiv.org/abs/2410.23215v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究集中于人机交互中的解释级别构建与评估。&lt;h4&gt;目的&lt;/h4&gt;确定机器人应向用户传达何种信息，以及何时传达这些信息。&lt;h4&gt;方法&lt;/h4&gt;定义了两个术语：详细程度（高、低）和解释模式（动态、静态），并基于这些参数构建了三种不同的解释级别（高、中、低），在用户研究中进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;在没有时间限制的条件下，高解释级别在解释充分性、碰撞数、错误移动数和澄清次数上表现最佳。高和中解释级别在完成时间、流畅性和对机器人的信任上没有显著差异。在有时间限制的条件下，高和中解释级别的任务表现更好，并在多个指标上优于低解释级别。&lt;h4&gt;结论&lt;/h4&gt;高和中解释级别在时间敏感的任务中更受欢迎，未来将讨论提升解释级别的方向。&lt;h4&gt;总结&lt;/h4&gt;研究表明，解释级别的构建与评估对提高人机交互的有效性至关重要。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we focused on constructing and evaluating levels ofexplanation(LOE) that address two basic aspect of HRI: 1. What informationshould be communicated to the user by the robot? 2. When should the robotcommunicate this information? For constructing the LOE, we defined two terms,verbosity and explanation patterns, each with two levels (verbosity -- high andlow, explanation patterns -- dynamic and static). Based on these parameters,three different LOE (high, medium, and low) were constructed and evaluated in auser study with a telepresence robot. The user study was conducted for asimulated telerobotic healthcare task with two different conditions related totime sensitivity, as evaluated by two different user groups -- one thatperformed the task within a time limit and the other with no time limit. Wefound that the high LOE was preferred in terms of adequacy of explanation,number of collisions, number of incorrect movements, and number ofclarifications when users performed the experiment in the without time limitcondition. We also found that both high and medium LOE did not have significantdifferences in completion time, the fluency of HRI, and trust in the robot.When users performed the experiment in the with time limit condition, high andmedium LOE had better task performances and were preferred to the low LOE interms of completion time, fluency, adequacy of explanation, trust, number ofcollisions, number of incorrect movements and number of clarifications. Futuredirections for advancing LOE are discussed.</description>
      <author>example@mail.com (Shikhar Kumar, Omer Keidar, Yael Edan)</author>
      <guid isPermaLink="false">2410.23215v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>coVoxSLAM: GPU Accelerated Globally Consistent Dense SLAM</title>
      <link>http://arxiv.org/abs/2410.21149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;密集SLAM系统对移动机器人至关重要，提供定位、导航、路径规划、障碍物规避和决策能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的GPU加速体积SLAM系统，利用GPU的并行处理能力在大规模环境中构建全球一致的地图。&lt;h4&gt;方法&lt;/h4&gt;开发coVoxSLAM系统，并在不同平台（离散和嵌入式GPU）上进行部署与比较。&lt;h4&gt;主要发现&lt;/h4&gt;使用公共数据集的结果表明，coVoxSLAM在执行时间上显著提升，同时保持准确的定位。&lt;h4&gt;结论&lt;/h4&gt;该系统作为开源项目可在GitHub上获取，推动了密集SLAM技术的发展。&lt;h4&gt;总结&lt;/h4&gt;coVoxSLAM利用GPU加速，提升了密集SLAM的性能，是移动机器人领域的一个重要进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A dense SLAM system is essential for mobile robots, as it provideslocalization and allows navigation, path planning, obstacle avoidance, anddecision-making in unstructured environments. Due to increasing computationaldemands the use of GPUs in dense SLAM is expanding. In this work, we presentcoVoxSLAM, a novel GPU-accelerated volumetric SLAM system that takes fulladvantage of the parallel processing power of the GPU to build globallyconsistent maps even in large-scale environments. It was deployed on differentplatforms (discrete and embedded GPU) and compared with the state of the art.The results obtained using public datasets show that coVoxSLAM delivers asignificant performance improvement considering execution times whilemaintaining accurate localization. The presented system is available asopen-source on GitHub https://github.com/lrse-uba/coVoxSLAM.</description>
      <author>example@mail.com (Emiliano Höss, Pablo De Cristóforis)</author>
      <guid isPermaLink="false">2410.21149v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DisenTS: Disentangled Channel Evolving Pattern Modeling for Multivariate Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.22981v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多变量时间序列预测在各种实际应用中起着至关重要的作用，现有方法通常使用单一模型来捕捉通道间的复杂依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提出DisenTS框架，以解耦的方式建模多变量时间序列中的通道演变模式。&lt;h4&gt;方法&lt;/h4&gt;框架采用多个独立的预测模型，每个模型负责揭示独特的演变模式，并引入Forecaster Aware Gate (FAG)模块生成自适应路由信号。&lt;h4&gt;主要发现&lt;/h4&gt;利用线性权重近似（LWA）策略量化深度神经网络，并通过相似性约束（SC）来引导模型专注于潜在模式。&lt;h4&gt;结论&lt;/h4&gt;DisenTS框架通过解耦建模方式，能更好地捕捉多变量时间序列中各通道的动态变化，提升预测准确性。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新颖的方法，通过多个专门的模型和自适应机制，优化了多变量时间序列预测的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series forecasting plays a crucial role in variousreal-world applications. Significant efforts have been made to integrateadvanced network architectures and training strategies that enhance the captureof temporal dependencies, thereby improving forecasting accuracy. On the otherhand, mainstream approaches typically utilize a single unified model withsimplistic channel-mixing embedding or cross-channel attention operations toaccount for the critical intricate inter-channel dependencies. Moreover, somemethods even trade capacity for robust prediction based on thechannel-independent assumption. Nonetheless, as time series data may displaydistinct evolving patterns due to the unique characteristics of each channel(including multiple strong seasonalities and trend changes), the unifiedmodeling methods could yield suboptimal results. To this end, we proposeDisenTS, a tailored framework for modeling disentangled channel evolvingpatterns in general multivariate time series forecasting. The central idea ofDisenTS is to model the potential diverse patterns within the multivariate timeseries data in a decoupled manner. Technically, the framework employs multipledistinct forecasting models, each tasked with uncovering a unique evolvingpattern. To guide the learning process without supervision of patternpartition, we introduce a novel Forecaster Aware Gate (FAG) module thatgenerates the routing signals adaptively according to both the forecasters'states and input series' characteristics. The forecasters' states are derivedfrom the Linear Weight Approximation (LWA) strategy, which quantizes thecomplex deep neural networks into compact matrices. Additionally, theSimilarity Constraint (SC) is further proposed to guide each model tospecialize in an underlying pattern by minimizing the mutual informationbetween the representations.</description>
      <author>example@mail.com (Zhiding Liu, Jiqian Yang, Qingyang Mao, Yuze Zhao, Mingyue Cheng, Zhi Li, Qi Liu, Enhong Chen)</author>
      <guid isPermaLink="false">2410.22981v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning</title>
      <link>http://arxiv.org/abs/2410.23234v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;该论文介绍了一个名为EMOTION的框架，旨在为类人机器人生成表达情感的动作序列，增强其进行人类非语言交流的能力。&lt;h4&gt;目的&lt;/h4&gt;提升机器人在非语言交流中的能力，特别是面部表情、手势和身体动作等关键非语言线索。&lt;h4&gt;方法&lt;/h4&gt;利用大型语言模型（LLMs）的上下文学习能力，动态生成适合人类-机器人互动的社交手势动作序列，并与人类反馈版本EMOTION++进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;通过在线用户研究，结果显示EMOTION生成的动作在自然性和可理解性方面与人类表现相当，甚至在某些情况下超过人类表现。&lt;h4&gt;结论&lt;/h4&gt;该方法在生成可理解和自然的机器人动作方面具有潜力，并为未来研究提供了设计启示，考虑生成表达性机器人手势时的多种变量。&lt;h4&gt;总结&lt;/h4&gt;EMOTION框架在提升机器人非语言交流能力方面具有显著优势，建议进一步研究以优化手势生成的多样性与细腻度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a framework, called EMOTION, for generating expressivemotion sequences in humanoid robots, enhancing their ability to engage inhumanlike non-verbal communication. Non-verbal cues such as facial expressions,gestures, and body movements play a crucial role in effective interpersonalinteractions. Despite the advancements in robotic behaviors, existing methodsoften fall short in mimicking the diversity and subtlety of human non-verbalcommunication. To address this gap, our approach leverages the in-contextlearning capability of large language models (LLMs) to dynamically generatesocially appropriate gesture motion sequences for human-robot interaction. Weuse this framework to generate 10 different expressive gestures and conductonline user studies comparing the naturalness and understandability of themotions generated by EMOTION and its human-feedback version, EMOTION++, againstthose by human operators. The results demonstrate that our approach eithermatches or surpasses human performance in generating understandable and naturalrobot motions under certain scenarios. We also provide design implications forfuture research to consider a set of variables when generating expressiverobotic gestures.</description>
      <author>example@mail.com (Peide Huang, Yuhan Hu, Nataliya Nechyporenko, Daehwa Kim, Walter Talbott, Jian Zhang)</author>
      <guid isPermaLink="false">2410.23234v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense</title>
      <link>http://arxiv.org/abs/2410.23091v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管持续努力保护神经分类器免受对抗攻击，但它们仍然易受攻击，尤其是对未见过的攻击。&lt;h4&gt;目的&lt;/h4&gt;模拟标签生成，通过识别标签的因果因素和非因果因素来辅助数据生成。&lt;h4&gt;方法&lt;/h4&gt;提出了一种因果扩散模型（CausalDiff），适应扩散模型用于条件数据生成，并通过学习新颖的因果信息瓶颈目标来解耦两种因果因素。&lt;h4&gt;主要发现&lt;/h4&gt;CausalDiff在各种未见攻击上显著优于最先进的防御方法，CIFAR-10的平均鲁棒性为86.39%（+4.01%），CIFAR-100为56.25%（+3.13%），GTSRB为82.62%（+4.93%）。&lt;h4&gt;结论&lt;/h4&gt;CausalDiff有效提高了神经分类器对抗未见攻击的鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;本研究通过因果模型提升了神经网络的防御能力，为对抗攻击的防御提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite ongoing efforts to defend neural classifiers from adversarialattacks, they remain vulnerable, especially to unseen attacks. In contrast,humans are difficult to be cheated by subtle manipulations, since we makejudgments only based on essential factors. Inspired by this observation, weattempt to model label generation with essential label-causative factors andincorporate label-non-causative factors to assist data generation. For anadversarial example, we aim to discriminate the perturbations as non-causativefactors and make predictions only based on the label-causative factors.Concretely, we propose a casual diffusion model (CausalDiff) that adaptsdiffusion models for conditional data generation and disentangles the two typesof casual factors by learning towards a novel casual information bottleneckobjective. Empirically, CausalDiff has significantly outperformedstate-of-the-art defense methods on various unseen attacks, achieving anaverage robustness of 86.39% (+4.01%) on CIFAR-10, 56.25% (+3.13%) onCIFAR-100, and 82.62% (+4.93%) on GTSRB (German Traffic Sign RecognitionBenchmark).</description>
      <author>example@mail.com (Mingkun Zhang, Keping Bi, Wei Chen, Quanrun Chen, Jiafeng Guo, Xueqi Cheng)</author>
      <guid isPermaLink="false">2410.23091v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>NYC-Event-VPR: A Large-Scale High-Resolution Event-Based Visual Place Recognition Dataset in Dense Urban Environments</title>
      <link>http://arxiv.org/abs/2410.21615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉场所识别（VPR）使自主机器人能够识别之前访问过的位置，对同时定位与地图构建（SLAM）任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;介绍NYC-Event-VPR数据集，以填补基于事件的VPR数据缺口。&lt;h4&gt;方法&lt;/h4&gt;使用Prophesee IMX636 HD事件传感器与RGB摄像头和GPS模块结合，收集数据。&lt;h4&gt;主要发现&lt;/h4&gt;数据集包含超过13小时的地理标记事件数据，覆盖260公里的纽约市，涵盖多种光照和天气条件，昼夜场景，以及多次访问不同位置。&lt;h4&gt;结论&lt;/h4&gt;事件相机具有高时间分辨率、超低延迟和高动态范围，适用于解决VPR面临的挑战，但数据集稀缺限制了应用。&lt;h4&gt;总结&lt;/h4&gt;通过三种框架进行泛化性能评估，推动事件基础VPR的创新及其在机器人应用中的整合。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual place recognition (VPR) enables autonomous robots to identifypreviously visited locations, which contributes to tasks like simultaneouslocalization and mapping (SLAM). VPR faces challenges such as accurate imageneighbor retrieval and appearance change in scenery. Event cameras, also knownas dynamic vision sensors, are a new sensor modality for VPR and offer apromising solution to the challenges with their unique attributes: hightemporal resolution (1MHz clock), ultra-low latency (in {\mu}s), and highdynamic range (&gt;120dB). These attributes make event cameras less susceptible tomotion blur and more robust in variable lighting conditions, making themsuitable for addressing VPR challenges. However, the scarcity of event-basedVPR datasets, partly due to the novelty and cost of event cameras, hamperstheir adoption. To fill this data gap, our paper introduces the NYC-Event-VPRdataset to the robotics and computer vision communities, featuring theProphesee IMX636 HD event sensor (1280x720 resolution), combined with RGBcamera and GPS module. It encompasses over 13 hours of geotagged event data,spanning 260 kilometers across New York City, covering diverse lighting andweather conditions, day/night scenarios, and multiple visits to variouslocations. Furthermore, our paper employs three frameworks to conductgeneralization performance assessments, promoting innovation in event-based VPRand its integration into robotics applications.</description>
      <author>example@mail.com (Taiyi Pan, Junyang He, Chao Chen, Yiming Li, Chen Feng)</author>
      <guid isPermaLink="false">2410.21615v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Keypoint Abstraction using Large Models for Object-Relative Imitation Learning</title>
      <link>http://arxiv.org/abs/2410.23254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  CoRL LangRob Workshop, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在机器人技术中，适应新物体配置和实例的能力是一个重要挑战。基于关键点的表示方法在捕捉物体特征和行动预测中有效，但手动设计和依赖额外人类标签限制了其扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出KALM框架，以利用大型预训练的视觉-语言模型自动生成任务相关和跨实例一致的关键点。&lt;h4&gt;方法&lt;/h4&gt;KALM通过使用语言模型生成提案，提炼出在不同视角和物体之间稳健一致的关键点，并通过小规模机器人演示数据验证这些关键点。&lt;h4&gt;主要发现&lt;/h4&gt;基于生成的关键点，我们可以训练关键点条件的策略模型，预测在关键点中心帧中的动作，使机器人能够有效地在不同物体姿势、相机视角和相似功能形状的物体实例间进行泛化。&lt;h4&gt;结论&lt;/h4&gt;该方法在现实世界中表现出色，能够从少量演示中适应不同任务和环境，无需额外标签。&lt;h4&gt;总结&lt;/h4&gt;KALM框架通过自动生成关键点，提升了机器人在各种任务和环境中的适应性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalization to novel object configurations and instances across diversetasks and environments is a critical challenge in robotics. Keypoint-basedrepresentations have been proven effective as a succinct representation forcapturing essential object features, and for establishing a reference frame inaction prediction, enabling data-efficient learning of robot skills. However,their manual design nature and reliance on additional human labels limit theirscalability. In this paper, we propose KALM, a framework that leverages largepre-trained vision-language models (LMs) to automatically generatetask-relevant and cross-instance consistent keypoints. KALM distills robust andconsistent keypoints across views and objects by generating proposals using LMsand verifies them against a small set of robot demonstration data. Based on thegenerated keypoints, we can train keypoint-conditioned policy models thatpredict actions in keypoint-centric frames, enabling robots to generalizeeffectively across varying object poses, camera views, and object instanceswith similar functional shapes. Our method demonstrates strong performance inthe real world, adapting to different tasks and environments from only ahandful of demonstrations while requiring no additional labels. Website:https://kalm-il.github.io/</description>
      <author>example@mail.com (Xiaolin Fang, Bo-Ruei Huang, Jiayuan Mao, Jasmine Shone, Joshua B. Tenenbaum, Tomás Lozano-Pérez, Leslie Pack Kaelbling)</author>
      <guid isPermaLink="false">2410.23254v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>EnvoDat: A Large-Scale Multisensory Dataset for Robotic Spatial Awareness and Semantic Reasoning in Heterogeneous Environments</title>
      <link>http://arxiv.org/abs/2410.22200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;为了确保机器人在多样化真实世界条件下的自主效率，需要高质量的异构数据集来评估操作算法的性能和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;填补当前基准测试在城市地形上的不足，特别是针对地下隧道、自然田野和现代室内空间等环境的代表性。&lt;h4&gt;方法&lt;/h4&gt;引入EnvoDat，这是一个在多种环境和条件下收集的大规模多模态数据集，包括高亮度、雾、雨和零能见度等不同时间的情况。&lt;h4&gt;主要发现&lt;/h4&gt;EnvoDat包含来自13个场景的26个序列，10种传感模态，超过1.9TB的数据，以及超过89K个针对82个对象和地形类别的细粒度多边形注释。&lt;h4&gt;结论&lt;/h4&gt;通过不同格式的后处理，EnvoDat支持SLAM基准测试和监督学习算法的评估，以及多模态视觉模型的微调。&lt;h4&gt;总结&lt;/h4&gt;EnvoDat为在极具挑战性的环境中实现环境适应性机器人自主提供了重要的贡献，数据集和其他相关资源可通过指定链接访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To ensure the efficiency of robot autonomy under diverse real-worldconditions, a high-quality heterogeneous dataset is essential to benchmark theoperating algorithms' performance and robustness. Current benchmarkspredominantly focus on urban terrains, specifically for on-road autonomousdriving, leaving multi-degraded, densely vegetated, dynamic and feature-sparseenvironments, such as underground tunnels, natural fields, and modern indoorspaces underrepresented. To fill this gap, we introduce EnvoDat, a large-scale,multi-modal dataset collected in diverse environments and conditions, includinghigh illumination, fog, rain, and zero visibility at different times of theday. Overall, EnvoDat contains 26 sequences from 13 scenes, 10 sensingmodalities, over 1.9TB of data, and over 89K fine-grained polygon-basedannotations for more than 82 object and terrain classes. We post-processedEnvoDat in different formats that support benchmarking SLAM and supervisedlearning algorithms, and fine-tuning multimodal vision models. With EnvoDat, wecontribute to environment-resilient robotic autonomy in areas where theconditions are extremely challenging. The datasets and other relevant resourcescan be accessed through https://linusnep.github.io/EnvoDat/.</description>
      <author>example@mail.com (Linus Nwankwo, Bjoern Ellensohn, Vedant Dave, Peter Hofer, Jan Forstner, Marlene Villneuve, Robert Galler, Elmar Rueckert)</author>
      <guid isPermaLink="false">2410.22200v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SCRREAM : SCan, Register, REnder And Map:A Framework for Annotating Accurate and Dense 3D Indoor Scenes with a Benchmark</title>
      <link>http://arxiv.org/abs/2410.22715v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的3D室内数据集通常优先考虑规模而非真实准确性，这导致在进行深度渲染等密集几何任务时出现问题。&lt;h4&gt;目的&lt;/h4&gt;提出SCRREAM数据集注释框架，以便对场景中的物体进行完全密集网格的注释，并在真实图像序列上注册相机姿态，从而提供准确的真实值。&lt;h4&gt;方法&lt;/h4&gt;展示数据集注释流程，并展示从该框架中获得的四种可能的数据集变体，包括室内重建、SLAM、场景编辑与物体移除、人类重建和6D姿态估计。&lt;h4&gt;主要发现&lt;/h4&gt;与之前的室内数据集相比，SCRREAM设计允许在11个样本场景上评估密集几何任务，并与准确渲染的真实深度图进行比较。&lt;h4&gt;结论&lt;/h4&gt;SCRREAM为密集几何任务提供了新的基准，能够有效解决传统数据集在真实值评估中的不足。&lt;h4&gt;总结&lt;/h4&gt;SCRREAM框架通过提供准确的注释和真实值，推动了室内重建和SLAM等领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditionally, 3d indoor datasets have generally prioritized scale overground-truth accuracy in order to obtain improved generalization. However,using these datasets to evaluate dense geometry tasks, such as depth rendering,can be problematic as the meshes of the dataset are often incomplete and mayproduce wrong ground truth to evaluate the details. In this paper, we proposeSCRREAM, a dataset annotation framework that allows annotation of fully densemeshes of objects in the scene and registers camera poses on the real imagesequence, which can produce accurate ground truth for both sparse 3D as well asdense 3D tasks. We show the details of the dataset annotation pipeline andshowcase four possible variants of datasets that can be obtained from ourframework with example scenes, such as indoor reconstruction and SLAM, sceneediting &amp; object removal, human reconstruction and 6d pose estimation. Recentpipelines for indoor reconstruction and SLAM serve as new benchmarks. Incontrast to previous indoor dataset, our design allows to evaluate densegeometry tasks on eleven sample scenes against accurately rendered ground truthdepth maps.</description>
      <author>example@mail.com (HyunJun Jung, Weihang Li, Shun-Cheng Wu, William Bittner, Nikolas Brasch, Jifei Song, Eduardo Pérez-Pellitero, Zhensong Zhang, Arthur Moreau, Nassir Navab, Benjamin Busam)</author>
      <guid isPermaLink="false">2410.22715v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation</title>
      <link>http://arxiv.org/abs/2410.23277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类具备互补的学习系统，结合了对世界动态的慢学习与对新经验的快速存储。&lt;h4&gt;目的&lt;/h4&gt;提出SlowFast-VGen，一种用于动作驱动的长视频生成的双速学习系统。&lt;h4&gt;方法&lt;/h4&gt;结合掩码条件视频扩散模型进行世界动态的慢学习，并在推理时采用基于时间的LoRA模块进行快速学习。&lt;h4&gt;主要发现&lt;/h4&gt;SlowFast-VGen在各种指标上超越基线，生成的长视频保持一致性，FVD评分为514，场景切换平均为0.37。&lt;h4&gt;结论&lt;/h4&gt;慢-快学习循环算法显著提升了长时间规划任务的表现。&lt;h4&gt;总结&lt;/h4&gt;通过收集20万段带语言动作注释的视频数据，支持慢学习的世界模型，有效提升了动作驱动视频生成的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human beings are endowed with a complementary learning system, which bridgesthe slow learning of general world dynamics with fast storage of episodicmemory from a new experience. Previous video generation models, however,primarily focus on slow learning by pre-training on vast amounts of data,overlooking the fast learning phase crucial for episodic memory storage. Thisoversight leads to inconsistencies across temporally distant frames whengenerating longer videos, as these frames fall beyond the model's contextwindow. To this end, we introduce SlowFast-VGen, a novel dual-speed learningsystem for action-driven long video generation. Our approach incorporates amasked conditional video diffusion model for the slow learning of worlddynamics, alongside an inference-time fast learning strategy based on atemporal LoRA module. Specifically, the fast learning process updates itstemporal LoRA parameters based on local inputs and outputs, thereby efficientlystoring episodic memory in its parameters. We further propose a slow-fastlearning loop algorithm that seamlessly integrates the inner fast learning loopinto the outer slow learning loop, enabling the recall of prior multi-episodeexperiences for context-aware skill learning. To facilitate the slow learningof an approximate world model, we collect a large-scale dataset of 200k videoswith language action annotations, covering a wide range of scenarios. Extensiveexperiments show that SlowFast-VGen outperforms baselines across variousmetrics for action-driven video generation, achieving an FVD score of 514compared to 782, and maintaining consistency in longer videos, with an averageof 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithmsignificantly enhances performances on long-horizon planning tasks as well.Project Website: https://slowfast-vgen.github.io</description>
      <author>example@mail.com (Yining Hong, Beide Liu, Maxine Wu, Yuanhao Zhai, Kai-Wei Chang, Lingjie Li, Kevin Lin, Chung-Ching Lin, Jianfeng Wang, Zhengyuan Yang, Yingnian Wu, Lijuan Wang)</author>
      <guid isPermaLink="false">2410.23277v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DisCo: Distributed Contact-Rich Trajectory Optimization for Forceful Multi-Robot Collaboration</title>
      <link>http://arxiv.org/abs/2410.23283v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了DisCo，一种用于接触丰富的多机器人任务的分布式算法。&lt;h4&gt;目的&lt;/h4&gt;优化机器人在多个任务中的接触力和轨迹，以实现协作操作、团队运动和模块化机器人运动。&lt;h4&gt;方法&lt;/h4&gt;基于交替方向乘子法(ADMM)的变体，每个机器人独立计算接触力，通过无线网与其他机器人协作，确保一致性约束。&lt;h4&gt;主要发现&lt;/h4&gt;DisCo在协作操作、多机器人团队运动和模块化机器人运动中表现出色，成功率提高3倍，计算速度提升2.5到5倍。&lt;h4&gt;结论&lt;/h4&gt;分布式方法提高了计算效率并保护了机器人的隐私，同时在硬件实验中证明了有效性。&lt;h4&gt;总结&lt;/h4&gt;DisCo算法通过分布式优化实现机器人之间的高效协作，适用于多种复杂任务场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present DisCo, a distributed algorithm for contact-rich, multi-robottasks. DisCo is a distributed contact-implicit trajectory optimizationalgorithm, which allows a group of robots to optimize a time sequence of forcesto objects and to their environment to accomplish tasks such as collaborativemanipulation, robot team sports, and modular robot locomotion. We build ouralgorithm on a variant of the Alternating Direction Method of Multipliers(ADMM), where each robot computes its own contact forces and contact-switchingevents from a smaller single-robot, contact-implicit trajectory optimizationproblem, while cooperating with other robots through dual variables, enforcingconstraints between robots. Each robot iterates between solving its localproblem, and communicating over a wireless mesh network to enforce theseconsistency constraints with its neighbors, ultimately converging to acoordinated plan for the group. The local problems solved by each robot aresignificantly less challenging than a centralized problem with all robots'contact forces and switching events, improving the computational efficiency,while also preserving the privacy of some aspects of each robot's operation. Wedemonstrate the effectiveness of our algorithm in simulations of collaborativemanipulation, multi-robot team sports scenarios, and in modular robotlocomotion, where DisCo achieves $3$x higher success rates with a 2.5x to 5xfaster computation time. Further, we provide results of hardware experiments ona modular truss robot, with three collaborating truss nodes planningindividually while working together to produce a punctuated rolling-gate motionof the composite structure. Videos are available on the project page:https://disco-opt.github.io.</description>
      <author>example@mail.com (Ola Shorinwa, Matthew Devlin, Elliot W. Hawkes, Mac Schwager)</author>
      <guid isPermaLink="false">2410.23283v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ISAC Prototype System for Multi-Domain Cooperative Communication Networks</title>
      <link>http://arxiv.org/abs/2410.22956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures, accepted by IEEE Wireless Communications Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;未来无线网络将转变为集成感知与通信（ISAC）网络，开启数字双胞胎等创新服务。&lt;h4&gt;目的&lt;/h4&gt;验证ISAC网络的感知能力及其在提升通信中的作用。&lt;h4&gt;方法&lt;/h4&gt;开发了一种先进的ISAC原型系统，支持单静态、双静态和网络感知模式，进行多模态数据收集与同步。&lt;h4&gt;主要发现&lt;/h4&gt;该系统在感知辅助波束追踪和实时高清晰度视频传输方面表现出色，提供精确的角度和距离测量，以及实时成像和基于无线的同时定位与地图构建（SLAM）。&lt;h4&gt;结论&lt;/h4&gt;原型系统符合5G新无线标准，支持最多16个用户设备（UE）上行传输和10个下行传输，实际测试显示角度估计的均方根误差为2.3度，距离估计为0.3米，实时无线SLAM的多模态辅助估计误差为0.25米和0.8米。&lt;h4&gt;总结&lt;/h4&gt;该ISAC原型系统展示了在感知与通信领域的高精度和高效能，具有重要的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Future wireless networks are poised to transform into integrated sensing andcommunication (ISAC) networks, unlocking groundbreaking services such asdigital twinning. To harness the full potential of ISAC networks, it isessential to experimentally validate their sensing capabilities and the role ofsensing in boosting communication. However, current prototype systems fallshort in supporting multiple sensing functions or validating sensing-assistedcommunication. In response, we have developed an advanced ISAC prototype systemthat incorporates monostatic, bistatic, and network sensing modes. This systemsupports multimodal data collection and synchronization, ensuring comprehensiveexperimental validation. On the communication front, it excels in sensing-aidedbeam tracking and real-time high-definition video transmission. For sensingapplications, it provides precise angle and range measurements, real-timeangle-range imaging, and radio-based simultaneous localization and mapping(SLAM). Our prototype aligns with the 5G New Radio standard, offeringscalability for up to 16 user equipments (UEs) in uplink transmission and 10UEs in downlink transmission. Real-world tests showcase the system's superioraccuracy, with root mean square errors of 2.3 degrees for angle estimation and0.3 meters (m) for range estimation. Additionally, the estimation errors formultimodal-aided real-time radio SLAM localization and mapping are 0.25 m and0.8 m, respectively.</description>
      <author>example@mail.com (Jie Yang, Hang Que, Tao Du, Le Liang, Xiao Li, Chao-Kai Wen, Shi Jin)</author>
      <guid isPermaLink="false">2410.22956v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards</title>
      <link>http://arxiv.org/abs/2410.23289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;直接从人类视频训练机器人是在机器人技术和计算机视觉领域的新兴方向。&lt;h4&gt;目的&lt;/h4&gt;解决多指机器人手自主任务学习的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出HuDOR技术，通过直接从人类视频计算奖励进行在线微调，使用基于对象的轨迹构建奖励函数。&lt;h4&gt;主要发现&lt;/h4&gt;HuDOR能够在视觉和形态差异的情况下，提供有意义的学习信号，四指Allegro手在仅有一小时在线交互的情况下学习任务。&lt;h4&gt;结论&lt;/h4&gt;HuDOR在四个任务上的实验中表现出比基线高出4倍的改进。&lt;h4&gt;总结&lt;/h4&gt;代码和视频可在我们的网站上找到，展示了HuDOR的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training robots directly from human videos is an emerging area in roboticsand computer vision. While there has been notable progress with two-fingeredgrippers, learning autonomous tasks for multi-fingered robot hands in this wayremains challenging. A key reason for this difficulty is that a policy trainedon human hands may not directly transfer to a robot hand due to morphologydifferences. In this work, we present HuDOR, a technique that enables onlinefine-tuning of policies by directly computing rewards from human videos.Importantly, this reward function is built using object-oriented trajectoriesderived from off-the-shelf point trackers, providing meaningful learningsignals despite the morphology gap and visual differences between human androbot hands. Given a single video of a human solving a task, such as gentlyopening a music box, HuDOR enables our four-fingered Allegro hand to learn thetask with just an hour of online interaction. Our experiments across four tasksshow that HuDOR achieves a 4x improvement over baselines. Code and videos areavailable on our website, https://object-rewards.github.io.</description>
      <author>example@mail.com (Irmak Guzey, Yinlong Dai, Georgy Savva, Raunaq Bhirangi, Lerrel Pinto)</author>
      <guid isPermaLink="false">2410.23289v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>LGU-SLAM: Learnable Gaussian Uncertainty Matching with Deformable Correlation Sampling for Deep Visual SLAM</title>
      <link>http://arxiv.org/abs/2410.23231v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度视觉同步定位与地图构建(SLAM)技术如DROID，通过深度视觉里程计和密集光流场取得了显著进展，但依赖全局视觉相似性匹配。&lt;h4&gt;目的&lt;/h4&gt;解决不确定区域中的模糊相似性干扰导致的噪声问题，从而提高SLAM的几何建模准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种可学习的高斯不确定性(LGU)匹配，设计了一个学习型的2D高斯不确定性模型，用于匹配帧对的关联，同时采用多尺度可变形相关采样策略和KAN偏差GRU组件。&lt;h4&gt;主要发现&lt;/h4&gt;通过对真实和合成数据集的广泛实验验证了该方法的有效性和优越性。&lt;h4&gt;结论&lt;/h4&gt;所提方法在精确对应构建和时空建模方面表现出色，能够有效减少噪声干扰，提高SLAM性能。&lt;h4&gt;总结&lt;/h4&gt;该研究通过引入可学习的高斯不确定性和改进的采样策略，显著提升了深度视觉SLAM的准确性和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/uestc-nnlab/lgu-slam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep visual Simultaneous Localization and Mapping (SLAM) techniques, e.g.,DROID, have made significant advancements by leveraging deep visual odometry ondense flow fields. In general, they heavily rely on global visual similaritymatching. However, the ambiguous similarity interference in uncertain regionscould often lead to excessive noise in correspondences, ultimately misleadingSLAM in geometric modeling. To address this issue, we propose a LearnableGaussian Uncertainty (LGU) matching. It mainly focuses on precisecorrespondence construction. In our scheme, a learnable 2D Gaussian uncertaintymodel is designed to associate matching-frame pairs. It could generateinput-dependent Gaussian distributions for each correspondence map.Additionally, a multi-scale deformable correlation sampling strategy is devisedto adaptively fine-tune the sampling of each direction by a priori look-upranges, enabling reliable correlation construction. Furthermore, a KAN-bias GRUcomponent is adopted to improve a temporal iterative enhancement foraccomplishing sophisticated spatio-temporal modeling with limited parameters.The extensive experiments on real-world and synthetic datasets are conducted tovalidate the effectiveness and superiority of our method.</description>
      <author>example@mail.com (Yucheng Huang, Luping Ji, Hudong Liu, Mao Ye)</author>
      <guid isPermaLink="false">2410.23231v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>CLAP. I. Resolving miscalibration for deep learning-based galaxy photometric redshift estimation</title>
      <link>http://arxiv.org/abs/2410.19390v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 + 6 pages, 9 + 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;获取未进行光谱测量的星系的光度红移概率密度仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新方法，称为对比学习和自适应KNN用于光度红移（CLAP），以解决模型输出与真实红移分布之间的误校准问题。&lt;h4&gt;方法&lt;/h4&gt;结合监督对比学习（SCL）和K近邻（KNN）构建和校准原始概率密度估计，并实施重拟合程序以准备大规模成像数据的最终估计。&lt;h4&gt;主要发现&lt;/h4&gt;CLAP利用深度学习和KNN的优势，在概率密度估计的校准上优于基准方法，同时保持高准确性和计算效率。&lt;h4&gt;结论&lt;/h4&gt;误校准对方法引起的数据实例之间的过度相关性特别敏感，常规深度学习方法难以消除这种误校准，而CLAP则能够克服此问题。&lt;h4&gt;总结&lt;/h4&gt;CLAP在获取天文学和宇宙学应用所需的光度红移概率密度方面表现出色。这是关于CLAP系列的第一篇论文。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1051/0004-6361/202449113&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/QiufanLin/CLAP-I&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Obtaining well-calibrated photometric redshift probability densities forgalaxies without a spectroscopic measurement remains a challenge. Deep learningdiscriminative models, typically fed with multi-band galaxy images, can produceoutputs that mimic probability densities and achieve state-of-the-art accuracy.However, such models may be affected by miscalibration that would result indiscrepancies between the model outputs and the actual distributions of trueredshifts. Our work develops a novel method called the Contrastive Learning andAdaptive KNN for Photometric Redshift (CLAP) that resolves this issue. Itleverages supervised contrastive learning (SCL) and k-nearest neighbours (KNN)to construct and calibrate raw probability density estimates, and implements arefitting procedure to resume end-to-end discriminative models ready to producefinal estimates for large-scale imaging data. The harmonic mean is adopted tocombine an ensemble of estimates from multiple realisations for improvingaccuracy. Our experiments demonstrate that CLAP takes advantage of both deeplearning and KNN, outperforming benchmark methods on the calibration ofprobability density estimates and retaining high accuracy and computationalefficiency. With reference to CLAP, we point out that miscalibration isparticularly sensitive to the method-induced excessive correlations among datainstances in addition to the unaccounted-for epistemic uncertainties. Reducingthe uncertainties may not guarantee the removal of miscalibration due to thepresence of such excessive correlations, yet this is a problem for conventionaldeep learning methods rather than CLAP. These discussions underscore therobustness of CLAP for obtaining photometric redshift probability densitiesrequired by astrophysical and cosmological applications. This is the firstpaper in our series on CLAP.</description>
      <author>example@mail.com (Qiufan Lin, Hengxin Ruan, Dominique Fouchez, Shupei Chen, Rui Li, Paulo Montero-Camacho, Nicola R. Napolitano, Yuan-Sen Ting, Wei Zhang)</author>
      <guid isPermaLink="false">2410.19390v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework</title>
      <link>http://arxiv.org/abs/2410.19453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管利用多语言数据微调大型语言模型（LLMs）可以迅速提升其多语言能力，但在主导语言（如英语）与非主导语言之间仍存在性能差距，原因在于训练数据的不平衡。&lt;h4&gt;目的&lt;/h4&gt;进一步提升非主导语言的性能。&lt;h4&gt;方法&lt;/h4&gt;提出ShifCon，一种基于Shift的对比框架，将非主导语言的表示对齐到主导语言，允许访问模型参数中相对丰富的信息，并在生成前将表示移回原语言子空间。&lt;h4&gt;主要发现&lt;/h4&gt;ShifCon框架显著提升了非主导语言的性能，尤其是资源稀缺的语言。&lt;h4&gt;结论&lt;/h4&gt;进一步分析提供了额外的见解，以验证ShifCon的有效性并推动未来的研究。&lt;h4&gt;总结&lt;/h4&gt;ShifCon通过有效的表示对齐和多语言对比学习，显著改善了非主导语言的表现，为低资源语言提供了新的提升方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/rattlesnakey/ShifCon&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although fine-tuning Large Language Models (LLMs) with multilingual data canrapidly enhance the multilingual capabilities of LLMs, they still exhibit aperformance gap between the dominant language (e.g., English) and non-dominantones due to the imbalance of training data across languages. To further enhancethe performance of non-dominant languages, we propose ShifCon, a Shift-basedContrastive framework that aligns the internal forward process of otherlanguages toward that of the dominant one. Specifically, it shifts therepresentations of non-dominant languages into the dominant language subspace,allowing them to access relatively rich information encoded in the modelparameters. The enriched representations are then shifted back into theiroriginal language subspace before generation. Moreover, we introduce a subspacedistance metric to pinpoint the optimal layer area for shifting representationsand employ multilingual contrastive learning to further enhance the alignmentof representations within this area. Experiments demonstrate that our ShifConframework significantly enhances the performance of non-dominant languages,particularly for low-resource ones. Further analysis offers extra insights toverify the effectiveness of ShifCon and propel future research</description>
      <author>example@mail.com (Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei)</author>
      <guid isPermaLink="false">2410.19453v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Bio2Token: All-atom tokenization of any biomolecular structure with Mamba</title>
      <link>http://arxiv.org/abs/2410.19110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高保真度的大型3D分子结构的有效编码和表示对生物分子设计应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发能够学习完整蛋白质、RNA和小分子结构的原子级标记的量化自编码器。&lt;h4&gt;方法&lt;/h4&gt;使用Mamba状态空间模型架构，以较少的训练数据和参数，实现接近1埃的重构精度。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够高效地扩展至近100,000个原子的系统，且训练效率高。&lt;h4&gt;结论&lt;/h4&gt;学习到的生物结构标记可作为未来全原子语言模型的输入。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，解决了大规模生物分子表示学习中的精度和效率问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient encoding and representation of large 3D molecular structures withhigh fidelity is critical for biomolecular design applications. Despite this,many representation learning approaches restrict themselves to modeling smallersystems or use coarse-grained approximations of the systems, for examplemodeling proteins at the resolution of amino acid residues rather than at thelevel of individual atoms. To address this, we develop quantized auto-encodersthat learn atom-level tokenizations of complete proteins, RNA and smallmolecule structures with reconstruction accuracies below and around 1 Angstrom.We demonstrate that the Mamba state space model architecture employed iscomparatively efficient, requiring a fraction of the training data, parametersand compute needed to reach competitive accuracies and can scale to systemswith almost 100,000 atoms. The learned structure tokens of bio2token may serveas the input for all-atom language models in the future.</description>
      <author>example@mail.com (Andrew Liu, Axel Elaldi, Nathan Russell, Olivia Viessmann)</author>
      <guid isPermaLink="false">2410.19110v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MatExpert: Decomposing Materials Discovery by Mimicking Human Experts</title>
      <link>http://arxiv.org/abs/2410.21317v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;材料发现是一个关键的研究领域，对多个行业有深远的影响。&lt;h4&gt;目的&lt;/h4&gt;介绍MatExpert框架，以加速新固态材料的发现与设计。&lt;h4&gt;方法&lt;/h4&gt;MatExpert结合大型语言模型和对比学习，模拟人类材料设计专家的工作流程，分为检索、过渡和生成三个阶段。&lt;h4&gt;主要发现&lt;/h4&gt;MatExpert在材料生成任务中优于现有最先进的方法，在有效性、分布性和稳定性等多个指标上表现出色。&lt;h4&gt;结论&lt;/h4&gt;MatExpert在基于语言的生成模型中代表了计算材料发现的重大进展。&lt;h4&gt;总结&lt;/h4&gt;MatExpert框架通过三个关键阶段提高了新材料的发现效率，推动了材料科学的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Material discovery is a critical research area with profound implications forvarious industries. In this work, we introduce MatExpert, a novel frameworkthat leverages Large Language Models (LLMs) and contrastive learning toaccelerate the discovery and design of new solid-state materials. Inspired bythe workflow of human materials design experts, our approach integrates threekey stages: retrieval, transition, and generation. First, in the retrievalstage, MatExpert identifies an existing material that closely matches thedesired criteria. Second, in the transition stage, MatExpert outlines thenecessary modifications to transform this material formulation to meet specificrequirements outlined by the initial user query. Third, in the generationstate, MatExpert performs detailed computations and structural generation tocreate new materials based on the provided information. Our experimentalresults demonstrate that MatExpert outperforms state-of-the-art methods inmaterial generation tasks, achieving superior performance across variousmetrics including validity, distribution, and stability. As such, MatExpertrepresents a meaningful advancement in computational material discovery usinglangauge-based generative models.</description>
      <author>example@mail.com (Qianggang Ding, Santiago Miret, Bang Liu)</author>
      <guid isPermaLink="false">2410.21317v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Indication Finding: a novel use case for representation learning</title>
      <link>http://arxiv.org/abs/2410.19174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多疗法在治疗多种疾病方面有效。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，利用自然语言处理和真实世界数据来优先考虑潜在的新适应症。&lt;h4&gt;方法&lt;/h4&gt;使用表示学习生成适应症的嵌入，并根据其与已知适应症的接近度进行优先排序。&lt;h4&gt;主要发现&lt;/h4&gt;成功应用该方法于抗IL-17A，并使用SPPMI生成的嵌入进行评估。&lt;h4&gt;结论&lt;/h4&gt;展示了一个评估框架，用于确定适应症发现结果和生成的嵌入的质量。&lt;h4&gt;总结&lt;/h4&gt;该方法为优先考虑新适应症提供了一种有效的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many therapies are effective in treating multiple diseases. We present anapproach that leverages methods developed in natural language processing andreal-world data to prioritize potential, new indications for a mechanism ofaction (MoA). We specifically use representation learning to generateembeddings of indications and prioritize them based on their proximity to theindications with the strongest available evidence for the MoA. We demonstratethe successful deployment of our approach for anti-IL-17A using embeddingsgenerated with SPPMI and present an evaluation framework to determine thequality of indication finding results and the derived embeddings.</description>
      <author>example@mail.com (Maren Eckhoff, Valmir Selimi, Alexander Aranovitch, Ian Lyons, Emily Briggs, Jennifer Hou, Alex Devereson, Matej Macak, David Champagne, Chris Anagnostopoulos)</author>
      <guid isPermaLink="false">2410.19174v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Human-Object Interaction Detection Collaborated with Large Relation-driven Diffusion Models</title>
      <link>http://arxiv.org/abs/2410.20155v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类-物体交互检测方法通常依赖大规模视觉-语言模型来识别涉及人类和物体的事件。&lt;h4&gt;目的&lt;/h4&gt;提出DIFFUSIONHOI，一种新的人类-物体交互检测器，利用文本到图像的扩散模型。&lt;h4&gt;方法&lt;/h4&gt;采用基于反演的策略学习人类与物体之间关系模式的表达，将学习到的关系嵌入作为文本提示，引导扩散模型生成特定交互的图像，并从中提取相关线索。&lt;h4&gt;主要发现&lt;/h4&gt;DIFFUSIONHOI在三种数据集上，在常规和零样本设置下都达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;扩散模型在识别中/低级视觉概念和处理新概念的组合性方面表现优越，能够有效提取人类-物体交互的相关信息。&lt;h4&gt;总结&lt;/h4&gt;DIFFUSIONHOI为人类-物体交互检测提供了一种新的思路，改善了传统模型的局限性，取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prevalent human-object interaction (HOI) detection approaches typicallyleverage large-scale visual-linguistic models to help recognize eventsinvolving humans and objects. Though promising, models trained via contrastivelearning on text-image pairs often neglect mid/low-level visual cues andstruggle at compositional reasoning. In response, we introduce DIFFUSIONHOI, anew HOI detector shedding light on text-to-image diffusion models. Unlike theaforementioned models, diffusion models excel in discerning mid/low-levelvisual concepts as generative models, and possess strong compositionality tohandle novel concepts expressed in text inputs. Considering diffusion modelsusually emphasize instance objects, we first devise an inversion-based strategyto learn the expression of relation patterns between humans and objects inembedding space. These learned relation embeddings then serve as textualprompts, to steer diffusion models generate images that depict specificinteractions, and extract HOI-relevant cues from images without heavyfine-tuning. Benefited from above, DIFFUSIONHOI achieves SOTA performance onthree datasets under both regular and zero-shot setups.</description>
      <author>example@mail.com (Liulei Li, Wenguan Wang, Yi Yang)</author>
      <guid isPermaLink="false">2410.20155v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Exploring the Reliability of Foundation Model-Based Frontier Selection in Zero-Shot Object Goal Navigation</title>
      <link>http://arxiv.org/abs/2410.21037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 5 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了一种新的方法，用于在零样本目标导航（ZS-OGN）中进行可靠的边界选择，旨在增强机器人导航系统的常识推理能力。&lt;h4&gt;目的&lt;/h4&gt;提高室内环境中机器人导航系统的性能，解决基础模型中常见的无意义或不相关推理问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一个多专家决策框架，包括两个关键组件：多样化专家边界分析（DEFA）和共识决策（CDM）。DEFA利用三种专家模型：家具布局、房间类型分析和视觉场景推理；CDM则聚合这些模型的输出，优先考虑一致或多数共识。&lt;h4&gt;主要发现&lt;/h4&gt;在RoboTHOR和HM3D数据集上表现出色，能够有效导航至未训练的物体或目标，超越了多种基线方法，显示出在动态现实条件下的适应性和卓越的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法展示了在零样本目标导航中提升机器人导航性能的潜力，强调了多专家系统在复杂环境中的重要性。&lt;h4&gt;总结&lt;/h4&gt;通过引入多专家决策框架，本文的方法在室内导航中实现了更高的可靠性和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a novel method for reliable frontier selection inZero-Shot Object Goal Navigation (ZS-OGN), enhancing robotic navigation systemswith foundation models to improve commonsense reasoning in indoor environments.Our approach introduces a multi-expert decision framework to address thenonsensical or irrelevant reasoning often seen in foundation model-basedsystems. The method comprises two key components: Diversified Expert FrontierAnalysis (DEFA) and Consensus Decision Making (CDM). DEFA utilizes three expertmodels: furniture arrangement, room type analysis, and visual scene reasoning,while CDM aggregates their outputs, prioritizing unanimous or majorityconsensus for more reliable decisions. Demonstrating state-of-the-artperformance on the RoboTHOR and HM3D datasets, our method excels at navigatingtowards untrained objects or goals and outperforms various baselines,showcasing its adaptability to dynamic real-world conditions and superiorgeneralization capabilities.</description>
      <author>example@mail.com (Shuaihang Yuan, Halil Utku Unlu, Hao Huang, Congcong Wen, Anthony Tzes, Yi Fang)</author>
      <guid isPermaLink="false">2410.21037v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Perturbation-based Graph Active Learning for Weakly-Supervised Belief Representation Learning</title>
      <link>http://arxiv.org/abs/2410.19176v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;该论文解决了在社交网络中优化标签资源分配的问题，尤其是在半监督信念表示学习方面。&lt;h4&gt;目的&lt;/h4&gt;旨在在有限预算内，战略性地识别社交媒体图中值得标记的有价值信息，从而最大化任务性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于图数据增强的扰动主动学习策略（PerbALGraph），根据自动估计器逐步选择待标记信息，无需人工指导。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提策略在信念表示学习任务中表现出色，能够有效提升性能。&lt;h4&gt;结论&lt;/h4&gt;通过对网络中对结构特征敏感的信息进行识别，该方法显著提高了半监督过程的有效性。&lt;h4&gt;总结&lt;/h4&gt;在标签资源有限的情况下，优化标签分配是关键研究问题，所提出的方法提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the problem of optimizing the allocation of labelingresources for semi-supervised belief representation learning in socialnetworks. The objective is to strategically identify valuable messages onsocial media graphs that are worth labeling within a constrained budget,ultimately maximizing the task's performance. Despite the progress inunsupervised or semi-supervised methods in advancing belief and ideologyrepresentation learning on social networks and the remarkable efficacy of graphlearning techniques, the availability of high-quality curated labeled socialdata can greatly benefit and further improve performances. Consequently,allocating labeling efforts is a critical research problem in scenarios wherelabeling resources are limited. This paper proposes a graph dataaugmentation-inspired perturbation-based active learning strategy (PerbALGraph)that progressively selects messages for labeling according to an automaticestimator, obviating human guidance. This estimator is based on the principlethat messages in the network that exhibit heightened sensitivity to structuralfeatures of the observational data indicate landmark quality that significantlyinfluences semi-supervision processes. We design the estimator to be theprediction variance under a set of designed graph perturbations, which ismodel-agnostic and application-independent. Extensive experiment resultsdemonstrate the effectiveness of the proposed strategy for beliefrepresentation learning tasks.</description>
      <author>example@mail.com (Dachun Sun, Ruijie Wang, Jinning Li, Ruipeng Han, Xinyi Liu, You Lyu, Tarek Abdelzaher)</author>
      <guid isPermaLink="false">2410.19176v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media</title>
      <link>http://arxiv.org/abs/2410.19193v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社交媒体上的虚假信息带来了社会和技术方面的挑战。&lt;h4&gt;目的&lt;/h4&gt;研究将文本特征融入图神经网络(GNNs)以提高假新闻检测的效果。&lt;h4&gt;方法&lt;/h4&gt;通过实验探讨使用基于Transformer的语言模型生成高质量的上下文文本表示。&lt;h4&gt;主要发现&lt;/h4&gt;上下文表示在Macro F1上比静态表示提高了9.3%，比没有文本特征的GNNs提高了33.8%。&lt;h4&gt;结论&lt;/h4&gt;噪声数据增强会降低性能并增加不稳定性，期望该方法能为进一步研究开辟新的方向。&lt;h4&gt;总结&lt;/h4&gt;所有代码已公开，以供进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Disinformation on social media poses both societal and technical challenges.While previous studies have integrated textual information into propagationnetworks, they have yet to fully leverage the advancements in Transformer-basedlanguage models for high-quality contextual text representations. This workinvestigates the impact of incorporating textual features into Graph NeuralNetworks (GNNs) for fake news detection. Our experiments demonstrate thatcontextual representations improve performance by 9.3% in Macro F1 over staticones and 33.8% over GNNs without textual features. However, noisy dataaugmentation degrades performance and increases instability. We expect ourmethodology to open avenues for further research, and all code is made publiclyavailable.</description>
      <author>example@mail.com (Bruno Croso Cunha da Silva, Thomas Palmeira Ferraz, Roseli De Deus Lopes)</author>
      <guid isPermaLink="false">2410.19193v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision</title>
      <link>http://arxiv.org/abs/2410.19115v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://wangrc.site/MoGePage/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出MoGe模型，用于从单目开放域图像中恢复3D几何结构。&lt;h4&gt;目的&lt;/h4&gt;直接预测捕获场景的3D点图，使用与仿射不变的表示，避免真实全局尺度和位移的影响。&lt;h4&gt;方法&lt;/h4&gt;新表示方法消除了训练中的歧义监督，并促进了有效的几何学习。提出了一系列新的全局和局部几何监督，增强模型学习高质量几何的能力。&lt;h4&gt;主要发现&lt;/h4&gt;包括一个稳健、优化和高效的点云对齐求解器，用于准确的全局形状学习，以及促进精确局部几何监督的多尺度局部几何损失。&lt;h4&gt;结论&lt;/h4&gt;在大型混合数据集上训练模型，展示出强大的泛化能力和高准确性。&lt;h4&gt;总结&lt;/h4&gt;在对多样的未见数据集的全面评估中，模型在所有任务上显著优于最先进的方法，包括单目3D点图、深度图和相机视场的估计。代码和模型将在项目页面发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present MoGe, a powerful model for recovering 3D geometry from monocularopen-domain images. Given a single image, our model directly predicts a 3Dpoint map of the captured scene with an affine-invariant representation, whichis agnostic to true global scale and shift. This new representation precludesambiguous supervision in training and facilitate effective geometry learning.Furthermore, we propose a set of novel global and local geometry supervisionsthat empower the model to learn high-quality geometry. These include a robust,optimal, and efficient point cloud alignment solver for accurate global shapelearning, and a multi-scale local geometry loss promoting precise localgeometry supervision. We train our model on a large, mixed dataset anddemonstrate its strong generalizability and high accuracy. In our comprehensiveevaluation on diverse unseen datasets, our model significantly outperformsstate-of-the-art methods across all tasks, including monocular estimation of 3Dpoint map, depth map, and camera field of view. Code and models will bereleased on our project page.</description>
      <author>example@mail.com (Ruicheng Wang, Sicheng Xu, Cassie Dai, Jianfeng Xiang, Yu Deng, Xin Tong, Jiaolong Yang)</author>
      <guid isPermaLink="false">2410.19115v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Pseudo-Label Enhanced Prototypical Contrastive Learning for Uniformed Intent Discovery</title>
      <link>http://arxiv.org/abs/2410.20219v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by EMNLP 2024 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新意图发现对任务导向对话系统至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种统一的意图发现方法以提高知识传递效果。&lt;h4&gt;方法&lt;/h4&gt;提出伪标签增强的原型对比学习（PLPCL）模型，通过迭代利用伪标签探索潜在的正负样本，并设计整合IND和OOD样本的监督和伪信号的原型学习方法。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在发现新意图的两种不同设置中证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;在三个基准数据集和两种任务设置上的实验结果表明，我们的方法有效。&lt;h4&gt;总结&lt;/h4&gt;PLPCL模型通过结合伪标签和原型学习，缩小了意图表示与聚类过程之间的差距，提升了意图发现的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/dymanne123/PLPCL&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; New intent discovery is a crucial capability for task-oriented dialoguesystems. Existing methods focus on transferring in-domain (IND) prior knowledgeto out-of-domain (OOD) data through pre-training and clustering stages. Theyeither handle the two processes in a pipeline manner, which exhibits a gapbetween intent representation and clustering process or use typical contrastiveclustering that overlooks the potential supervised signals from the whole data.Besides, they often individually deal with open intent discovery or OODsettings. To this end, we propose a Pseudo-Label enhanced PrototypicalContrastive Learning (PLPCL) model for uniformed intent discovery. Weiteratively utilize pseudo-labels to explore potential positive/negativesamples for contrastive learning and bridge the gap between representation andclustering. To enable better knowledge transfer, we design a prototype learningmethod integrating the supervised and pseudo signals from IND and OOD samples.In addition, our method has been proven effective in two different settings ofdiscovering new intents. Experiments on three benchmark datasets and two tasksettings demonstrate the effectiveness of our approach.</description>
      <author>example@mail.com (Yimin Deng, Yuxia Wu, Guoshuai Zhao, Li Zhu, Xueming Qian)</author>
      <guid isPermaLink="false">2410.20219v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>KA$^2$ER: Knowledge Adaptive Amalgamation of ExpeRts for Medical Images Segmentation</title>
      <link>http://arxiv.org/abs/2410.21085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted to MICCAI2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近期发布了多种用于医学图像分析的基础模型，如MedSAM和SwinUNETR，这些模型在多个任务中证明了其有效性。&lt;h4&gt;目的&lt;/h4&gt;针对现实世界医学数据的异质性和非均匀性，提出一种自适应融合知识框架，以提高模型在特定医学图像分割任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;首先为每个任务训练基于nnUNet的专家模型，并重用预训练的SwinUNETR作为目标基础模型。接着将输入数据编码到基础模型和专家模型中，并将其主干特征共同投影到自适应融合层。&lt;h4&gt;主要发现&lt;/h4&gt;通过设计层次注意机制，实现目标模型与所有专家的隐藏层特征知识的自适应融合，有效减少了因任务间差异引起的领域转移。&lt;h4&gt;结论&lt;/h4&gt;在多个挑战性任务上进行的广泛实验表明，该基础模型在现实世界医学图像分割中具有良好的有效性和适应性。&lt;h4&gt;总结&lt;/h4&gt;提出的自适应融合知识框架能够有效应对医学图像分割中的领域转移问题，提升模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, many foundation models for medical image analysis such as MedSAM,SwinUNETR have been released and proven to be useful in multiple tasks.However, considering the inherent heterogeneity and inhomogeneity of real-worldmedical data, directly applying these models to specific medical imagesegmentation tasks often leads to negative domain shift effects, which canseverely weaken the model's segmentation capabilities. To this end, we proposean adaptive amalgamation knowledge framework that aims to train a versatilefoundation model to handle the joint goals of multiple expert models, eachspecialized for a distinct task. Specifically, we first train an nnUNet-basedexpert model for each task, and reuse the pre-trained SwinUNTER as the targetfoundation model. Then, the input data for all challenging tasks are encoded inthe foundation model and the expert models, respectively, and their backbonefeatures are jointly projected into the adaptive amalgamation layer. Within thehidden layer, the hierarchical attention mechanisms are designed to achieveadaptive merging of the target model to the hidden layer feature knowledge ofall experts, which significantly reduces the domain shift arising from theinter-task differences. Finally, the gold amalgamated features and the promptfeatures are fed into the mask decoder to obtain the segmentation results.Extensive experiments conducted in these challenging tasks demonstrate theeffectiveness and adaptability of our foundation model for real-world medicalimage segmentation.</description>
      <author>example@mail.com (Shangde Gao, Yichao Fu, Ke Liu, Hongxia Xu, Jian Wu)</author>
      <guid isPermaLink="false">2410.21085v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Can Self Supervision Rejuvenate Similarity-Based Link Prediction?</title>
      <link>http://arxiv.org/abs/2410.19183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管基于端到端学习的链接预测方法取得了显著进展，但在没有已知链接标签的无监督场景中，传统的基于相似性的链接预测方法仍然重要。&lt;h4&gt;目的&lt;/h4&gt;解决在基于相似性的链接预测中选择节点特征的挑战，以提高性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新方法：自监督相似性链接预测（3SLP），该方法结合了自监督图学习技术，适用于无监督条件下的相似性链接预测。&lt;h4&gt;主要发现&lt;/h4&gt;3SLP引入了双视图对比节点表示学习（DCNRL），通过数据增强和节点表示学习开发更具信息量的节点表示，实验结果表明3SLP在基准数据集上表现优异，AUC比传统方法提高了最多21.2%。&lt;h4&gt;结论&lt;/h4&gt;3SLP在无监督情况下显著提升了基于相似性的链接预测性能，验证了自监督学习在此领域的有效性。&lt;h4&gt;总结&lt;/h4&gt;自监督相似性链接预测方法（3SLP）通过改进节点表示学习，克服了传统方法的局限性，展现出更好的链接预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although recent advancements in end-to-end learning-based link prediction(LP) methods have shown remarkable capabilities, the significance oftraditional similarity-based LP methods persists in unsupervised scenarioswhere there are no known link labels. However, the selection of node featuresfor similarity computation in similarity-based LP can be challenging. Lessinformative node features can result in suboptimal LP performance. To addressthese challenges, we integrate self-supervised graph learning techniques intosimilarity-based LP and propose a novel method: Self-SupervisedSimilarity-based LP (3SLP). 3SLP is suitable for the unsupervised condition ofsimilarity-based LP without the assistance of known link labels. Specifically,3SLP introduces a dual-view contrastive node representation learning (DCNRL)with crafted data augmentation and node representation learning. DCNRL isdedicated to developing more informative node representations, replacing thenode attributes as inputs in the similarity-based LP backbone. Extensiveexperiments over benchmark datasets demonstrate the salient improvement of3SLP, outperforming the baseline of traditional similarity-based LP by up to21.2% (AUC).</description>
      <author>example@mail.com (Chenhan Zhang, Weiqi Wang, Zhiyi Tian, James Jianqiao Yu, Mohamed Ali Kaafar, An Liu, Shui Yu)</author>
      <guid isPermaLink="false">2410.19183v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Double Difference Earthquake Location with Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.19323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;双差地震重定位是许多地震目录开发工作流程中的重要组成部分。该技术通过最小化来自附近源波到达时间的差异测量，实现事件之间的高分辨率相对重定位，提升了对断层的解析度和地震活动的解读。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于图神经网络的双差重定位框架，旨在最小化目录的双差残差以定位地震。&lt;h4&gt;方法&lt;/h4&gt;采用Graph Neural Network (GNN) 处理地震数据，通过批处理和采样方法，使其能够扩展到任意大的目录。架构使用一个图表示站点，另一个图表示源，并创建两个图之间的笛卡尔积图，以捕捉站点和源之间的关系。&lt;h4&gt;主要发现&lt;/h4&gt;在北加州、土耳其和北智利的多种测试案例中获得了高分辨率的重定位结果，显示出模型对多种损失函数和定位目标的适应性，包括学习站点修正和映射到不同目录的参考框架。&lt;h4&gt;结论&lt;/h4&gt;GNN方法在双差重定位方面展现出良好的前景，能够扩展到非常大的目录，并为重定位问题提供新的见解。&lt;h4&gt;总结&lt;/h4&gt;GraphDD框架通过图神经网络实现了高效的双差重定位，具备良好的扩展性和适应性，为地震研究提供了新的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Double difference earthquake relocation is an essential component of manyearthquake catalog development workflows. This technique produceshigh-resolution relative relocations between events by minimizing differentialmeasurements of the arrival times of waves from nearby sources, whichhighlights the resolution of faults and improves interpretation of seismicactivity. The inverse problem is typically solved iteratively usingconjugate-gradient minimization, however the cost scales significantly with thetotal number of sources and stations considered. Here we propose a Graph NeuralNetwork (GNN) based earthquake double-difference relocation framework, GraphDouble Difference (GraphDD), that is trained to minimize the double-differenceresiduals of a catalog to locate earthquakes. Through batching and sampling themethod can scale to arbitrarily large catalogs. Our architecture uses one graphto represent the stations, a second graph to represent the sources, and createsthe Cartesian product graph between the two graphs to capture the relationshipsbetween the stations and sources (e.g., the residuals and travel time partialderivatives). This key feature allows a natural architecture that can be usedto minimize the double-difference residuals. We implement our model on severaldistinct test cases including seismicity from northern California, Turkiye, andnorthern Chile, which have highly variable data quality, and station and sourcedistributions. We obtain high resolution relocations in these tests, and ourmodel shows adaptability to variable types of loss functions and locationobjectives, including learning station corrections and mapping into thereference frame of a different catalog. Our results suggest that a GNN approachto double-difference relocation is a promising direction for scaling to verylarge catalogs and gaining new insights into the relocation problem.</description>
      <author>example@mail.com (Ian W. McBrearty, Gregory C. Beroza)</author>
      <guid isPermaLink="false">2410.19323v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fusion-then-Distillation: Toward Cross-modal Positive Distillation for Domain Adaptive 3D Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.19446v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在跨模态无监督领域适应中，模型在源领域数据（如合成数据）上训练，并适应目标领域数据（如真实世界数据），而不访问目标注释。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的融合-再蒸馏（FtD++）方法，以探索源领域和目标领域的跨模态正向蒸馏，用于3D语义分割。&lt;h4&gt;方法&lt;/h4&gt;FtD++实现了输出分布的一致性，不仅在2D图像和3D点云之间，也在源领域和增强领域之间。该方法包括三个关键成分：1) 模型无关的特征融合模块，用于生成交叉模态融合表示；2) 跨模态正向蒸馏，结合源领域的语义内容和目标领域的风格；3) 跨模态去偏伪标签，通过自我训练方式建模伪标签的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验报告了在无监督和半监督设置下的多个领域适应场景中的最先进结果。&lt;h4&gt;结论&lt;/h4&gt;该研究展示了新的FtD++方法在跨模态无监督领域适应中的有效性，促进了源领域与目标领域之间的对齐。&lt;h4&gt;总结&lt;/h4&gt;通过融合和蒸馏策略，FtD++在3D语义分割任务中展现了优越的表现，推动了跨模态学习的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/barcaaaa/ftd-plusplus&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In cross-modal unsupervised domain adaptation, a model trained onsource-domain data (e.g., synthetic) is adapted to target-domain data (e.g.,real-world) without access to target annotation. Previous methods seek tomutually mimic cross-modal outputs in each domain, which enforces a classprobability distribution that is agreeable in different domains. However, theyoverlook the complementarity brought by the heterogeneous fusion in cross-modallearning. In light of this, we propose a novel fusion-then-distillation (FtD++)method to explore cross-modal positive distillation of the source and targetdomains for 3D semantic segmentation. FtD++ realizes distribution consistencybetween outputs not only for 2D images and 3D point clouds but also forsource-domain and augment-domain. Specially, our method contains three keyingredients. First, we present a model-agnostic feature fusion module togenerate the cross-modal fusion representation for establishing a latent space.In this space, two modalities are enforced maximum correlation andcomplementarity. Second, the proposed cross-modal positive distillationpreserves the complete information of multi-modal input and combines thesemantic content of the source domain with the style of the target domain,thereby achieving domain-modality alignment. Finally, cross-modal debiasedpseudo-labeling is devised to model the uncertainty of pseudo-labels via aself-training manner. Extensive experiments report state-of-the-art results onseveral domain adaptive scenarios under unsupervised and semi-supervisedsettings. Code is available at https://github.com/Barcaaaa/FtD-PlusPlus.</description>
      <author>example@mail.com (Yao Wu, Mingwei Xing, Yachao Zhang, Yuan Xie, Yanyun Qu)</author>
      <guid isPermaLink="false">2410.19446v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ANOMIX: A Simple yet Effective Hard Negative Generation via Mixing for Graph Anomaly Detection</title>
      <link>http://arxiv.org/abs/2410.20310v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）通常需要大量样本。&lt;h4&gt;目的&lt;/h4&gt;提出一种减少样本数量的方法，利用困难负样本（如Mixup）来改善图异常检测（GAD）。&lt;h4&gt;方法&lt;/h4&gt;提出ANOMIX框架，包含新颖的图混合方法ANOMIX-M和多层次对比，用于GAD。&lt;h4&gt;主要发现&lt;/h4&gt;ANOMIX-M能够有效混合输入图中的异常和正常数据，生成对GCL有重要作用的困难负样本。&lt;h4&gt;结论&lt;/h4&gt;ANOMIX是首个尝试通过图混合生成GAD任务的困难负样本的方法，且在准确性和效率上表现优异。具体表现为AUC提高最多5.49%，速度提升1.76%；同时样本数量减少近80%。&lt;h4&gt;总结&lt;/h4&gt;ANOMIX框架通过创新的方法显著提升了图异常检测的性能，代码可在指定链接获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/missinghwan/anomix&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph contrastive learning (GCL) generally requires a large number ofsamples. The one of the effective ways to reduce the number of samples is usinghard negatives (e.g., Mixup). Designing mixing-based approach for GAD can bedifficult due to imbalanced data or limited number of anomalies. We proposeANOMIX, a framework that consists of a novel graph mixing approach, ANOMIX-M,and multi-level contrasts for GAD. ANOMIX-M can effectively mix abnormality andnormality from input graph to generate hard negatives, which are important forefficient GCL. ANOMIX is (a) A first mixing approach: firstly attempting graphmixing to generate hard negatives for GAD task and node- and subgraph-levelcontrasts to distinguish underlying anomalies. (b) Accurate: winning thehighest AUC, up to 5.49% higher and 1.76% faster. (c) Effective: reducing thenumber of samples nearly 80% in GCL. Code is available athttps://github.com/missinghwan/ANOMIX.</description>
      <author>example@mail.com (Hwan Kim, Junghoon Kim, Sungsu Lim)</author>
      <guid isPermaLink="false">2410.20310v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal AI for comprehensive breast cancer prognostication</title>
      <link>http://arxiv.org/abs/2410.21256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;乳腺癌的治疗选择受分子亚型和临床特征的指导，复发风险评估对个性化治疗至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种基于数字病理和临床特征的乳腺癌患者分层测试，以提高治疗选择的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用基于视觉变换器的全癌症基础模型，结合自监督学习，从数字化的H&amp;E染色切片中提取特征，并与临床数据整合，形成多模态AI测试。&lt;h4&gt;主要发现&lt;/h4&gt;该测试在来自七个国家的8,161名乳腺癌患者的数据中开发和评估，主要终点（无病生存期）的预测C-index为0.71，AI测试在准确性上优于标准的Oncotype DX检测。&lt;h4&gt;结论&lt;/h4&gt;该AI测试在所有主要乳腺癌亚型中表现出稳健的准确性，尤其是在目前临床指南未推荐的TNBC中，表明其可以改善准确性，扩大适用范围，并增强治疗选择工具的可及性。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了AI测试在乳腺癌治疗选择中的潜力，尤其是在提高复发预测准确性方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Treatment selection in breast cancer is guided by molecular subtypes andclinical characteristics. Recurrence risk assessment plays a crucial role inpersonalizing treatment. Current methods, including genomic assays, havelimited accuracy and clinical utility, leading to suboptimal decisions for manypatients. We developed a test for breast cancer patient stratification based ondigital pathology and clinical characteristics using novel AI methods.Specifically, we utilized a vision transformer-based pan-cancer foundationmodel trained with self-supervised learning to extract features from digitizedH&amp;E-stained slides. These features were integrated with clinical data to form amulti-modal AI test predicting cancer recurrence and death. The test wasdeveloped and evaluated using data from a total of 8,161 breast cancer patientsacross 15 cohorts originating from seven countries. Of these, 3,502 patientsfrom five cohorts were used exclusively for evaluation, while the remainingpatients were used for training. Our test accurately predicted our primaryendpoint, disease-free interval, in the five external cohorts (C-index: 0.71[0.68-0.75], HR: 3.63 [3.02-4.37, p&lt;0.01]). In a direct comparison (N=858), theAI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay,with a C-index of 0.67 [0.61-0.74] versus 0.61 [0.49-0.73], respectively.Additionally, the AI test added independent information to Oncotype DX in amultivariate analysis (HR: 3.11 [1.91-5.09, p&lt;0.01)]). The test demonstratedrobust accuracy across all major breast cancer subtypes, including TNBC(C-index: 0.71 [0.62-0.81], HR: 3.81 [2.35-6.17, p=0.02]), where no diagnostictools are currently recommended by clinical guidelines. These results suggestthat our AI test can improve accuracy, extend applicability to a wider range ofpatients, and enhance access to treatment selection tools.</description>
      <author>example@mail.com (Jan Witowski, Ken Zeng, Joseph Cappadona, Jailan Elayoubi, Elena Diana Chiru, Nancy Chan, Young-Joon Kang, Frederick Howard, Irina Ostrovnaya, Carlos Fernandez-Granda, Freya Schnabel, Ugur Ozerdem, Kangning Liu, Zoe Steinsnyder, Nitya Thakore, Mohammad Sadic, Frank Yeung, Elisa Liu, Theodore Hill, Benjamin Swett, Danielle Rigau, Andrew Clayburn, Valerie Speirs, Marcus Vetter, Lina Sojak, Simone Muenst Soysal, Daniel Baumhoer, Khalil Choucair, Yu Zong, Lina Daoud, Anas Saad, Waleed Abdulsattar, Rafic Beydoun, Jia-Wern Pan, Haslina Makmur, Soo-Hwang Teo, Linda Ma Pak, Victor Angel, Dovile Zilenaite-Petrulaitiene, Arvydas Laurinavicius, Natalie Klar, Brian D. Piening, Carlo Bifulco, Sun-Young Jun, Jae Pak Yi, Su Hyun Lim, Adam Brufsky, Francisco J. Esteva, Lajos Pusztai, Yann LeCun, Krzysztof J. Geras)</author>
      <guid isPermaLink="false">2410.21256v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ST-NeRP: Spatial-Temporal Neural Representation Learning with Prior Embedding for Patient-specific Imaging Study</title>
      <link>http://arxiv.org/abs/2410.19283v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages with 10 figures and 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在治疗过程中，影像学常用于监测疾病进展和评估治疗反应，但可靠捕捉和预测患者特定图像序列的时空解剖变化是一项重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个计算框架，以满足多种实际应用的需求。&lt;h4&gt;方法&lt;/h4&gt;提出了一种空间-时间神经表示学习的策略（ST-NeRP），利用隐式神经表示网络（INR）将参考时间点的图像编码为先验嵌入，并学习一个时空连续变形函数。&lt;h4&gt;主要发现&lt;/h4&gt;ST-NeRP模型在多种序列图像系列（如4D CT和纵向CT数据集）中的应用显示出良好的效果。&lt;h4&gt;结论&lt;/h4&gt;ST-NeRP模型在监测患者治疗过程中的解剖变化方面具有显著潜力。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种新的方法来提高患者特定成像研究的准确性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; During and after a course of therapy, imaging is routinely used to monitorthe disease progression and assess the treatment responses. Despite of itssignificance, reliably capturing and predicting the spatial-temporal anatomicchanges from a sequence of patient-specific image series presents aconsiderable challenge. Thus, the development of a computational frameworkbecomes highly desirable for a multitude of practical applications. In thiscontext, we propose a strategy of Spatial-Temporal Neural Representationlearning with Prior embedding (ST-NeRP) for patient-specific imaging study. Ourstrategy involves leveraging an Implicit Neural Representation (INR) network toencode the image at the reference time point into a prior embedding.Subsequently, a spatial-temporally continuous deformation function is learnedthrough another INR network. This network is trained using the wholepatient-specific image sequence, enabling the prediction of deformation fieldsat various target time points. The efficacy of the ST-NeRP model isdemonstrated through its application to diverse sequential image series,including 4D CT and longitudinal CT datasets within thoracic and abdominalimaging. The proposed ST-NeRP model exhibits substantial potential in enablingthe monitoring of anatomical changes within a patient throughout thetherapeutic journey.</description>
      <author>example@mail.com (Liang Qiu, Liyue Shen, Lianli Liu, Junyan Liu, Yizheng Chen, Lei Xing)</author>
      <guid isPermaLink="false">2410.19283v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>An Enhanced Hierarchical Planning Framework for Multi-Robot Autonomous Exploration</title>
      <link>http://arxiv.org/abs/2410.19373v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多机器人系统的自主环境探索在救援任务、探索活动等方面具有广泛应用。&lt;h4&gt;目的&lt;/h4&gt;解决当前方法在短视性、忽视长期影响及高维学习空间收敛困难等方面的局限。&lt;h4&gt;方法&lt;/h4&gt;提出一种创新的集成策略，将基于边界的方法的低维动作空间效率与基于深度强化学习（DRL）的方法的长远性和最优性相结合，构建三层规划框架。&lt;h4&gt;主要发现&lt;/h4&gt;与基线方法相比，该框架在环境探索中所需时间步骤更少，数据传输减少超过30%。&lt;h4&gt;结论&lt;/h4&gt;所提方法在效率和性能方面优于传统方法，能够有效提升多机器人系统的环境探索能力。&lt;h4&gt;总结&lt;/h4&gt;通过综合利用边界识别、图神经网络和局部路径规划，显著提高了多机器人系统的探索效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The autonomous exploration of environments by multi-robot systems is acritical task with broad applications in rescue missions, explorationendeavors, and beyond. Current approaches often rely on either greedy frontierselection or end-to-end deep reinforcement learning (DRL) methods, yet thesemethods are frequently hampered by limitations such as short-sightedness,overlooking long-term implications, and convergence difficulties stemming fromthe intricate high-dimensional learning space. To address these challenges,this paper introduces an innovative integration strategy that combines thelow-dimensional action space efficiency of frontier-based methods with thefar-sightedness and optimality of DRL-based approaches. We propose athree-tiered planning framework that first identifies frontiers in free space,creating a sparse map representation that lightens data transmission burdensand reduces the DRL action space's dimensionality. Subsequently, we develop amulti-graph neural network (mGNN) that incorporates states of potential targetsand robots, leveraging policy-based reinforcement learning to computeaffinities, thereby superseding traditional heuristic utility values. Lastly,we implement local routing planning through subsequence search, which avoidsexhaustive sequence traversal. Extensive validation across diverse scenariosand comprehensive simulation results demonstrate the effectiveness of ourproposed method. Compared to baseline approaches, our framework achievesenvironmental exploration with fewer time steps and a notable reduction of over30% in data transmission, showcasing its superiority in terms of efficiency andperformance.</description>
      <author>example@mail.com (Gengyuan Cai, Luosong Guo, Xiangmao Chang)</author>
      <guid isPermaLink="false">2410.19373v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FastPCI: Motion-Structure Guided Fast Point Cloud Frame Interpolation</title>
      <link>http://arxiv.org/abs/2410.19573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in ECCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云帧插值是一项挑战性任务，涉及准确的场景流估计和几何结构的保持。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法以提高点云帧插值的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;引入Pyramid Convolution-Transformer架构，通过混合卷积-变换器改善局部和长程特征学习，并采用金字塔网络以提供多层次特征，减少计算量。同时提出双向运动结构块以提高场景流估计的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;FastPCI在KITTI数据集中相较于现有技术PointINet和NeuralPCI显著提高了插值精度（例如，Chamfer距离分别减少26.6%和18.3%），并且速度提升超过10倍和600倍。&lt;h4&gt;结论&lt;/h4&gt;FastPCI在点云帧插值任务中表现出色，具有高效率和高准确性，代码可在GitHub上获取。&lt;h4&gt;总结&lt;/h4&gt;FastPCI通过创新的架构和方法，显著提升了点云帧插值的性能，解决了传统方法的不足。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/genuszty/fastpci&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud frame interpolation is a challenging task that involves accuratescene flow estimation across frames and maintaining the geometry structure.Prevailing techniques often rely on pre-trained motion estimators or intensivetesting-time optimization, resulting in compromised interpolation accuracy orprolonged inference. This work presents FastPCI that introduces PyramidConvolution-Transformer architecture for point cloud frame interpolation. Ourhybrid Convolution-Transformer improves the local and long-range featurelearning, while the pyramid network offers multilevel features and reduces thecomputation. In addition, FastPCI proposes a unique Dual-DirectionMotion-Structure block for more accurate scene flow estimation. Our design ismotivated by two facts: (1) accurate scene flow preserves 3D structure, and (2)point cloud at the previous timestep should be reconstructable using reversemotion from future timestep. Extensive experiments show that FastPCIsignificantly outperforms the state-of-the-art PointINet and NeuralPCI withnotable gains (e.g. 26.6% and 18.3% reduction in Chamfer Distance in KITTI),while being more than 10x and 600x faster, respectively. Code is available athttps://github.com/genuszty/FastPCI</description>
      <author>example@mail.com (Tianyu Zhang, Guocheng Qian, Jin Xie, Jian Yang)</author>
      <guid isPermaLink="false">2410.19573v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference</title>
      <link>http://arxiv.org/abs/2410.21262v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模基础模型在语言和视觉任务中表现优异，但其密集的矩阵-向量运算在推理过程中面临显著的计算挑战。&lt;h4&gt;目的&lt;/h4&gt;提出Block-Level Adaptive Structured (BLAST)矩阵，以学习和利用深度学习模型线性层权重矩阵中的高效结构。&lt;h4&gt;方法&lt;/h4&gt;BLAST矩阵相比于现有的结构化矩阵提供了更大的灵活性，可以表示从数据中学习或从已有权重矩阵计算出的各种结构。&lt;h4&gt;主要发现&lt;/h4&gt;{'中型模型': {'模型名': ['ViT', 'GPT-2'], '性能提升': '训练使用BLAST权重后，复杂度分别降低70%和40%。'}, '大型模型': {'模型名': ['Llama-7B', 'DiT-XL'], '压缩效果': '实现2倍压缩，且性能下降幅度在所有测试的结构化矩阵中最低。'}}&lt;h4&gt;结论&lt;/h4&gt;BLAST矩阵在语言和视觉任务的压缩中展现了显著的效率与灵活性。&lt;h4&gt;总结&lt;/h4&gt;BLAST矩阵为深度学习模型提供了一种高效的结构化权重表示方式，有助于在性能与计算复杂度之间取得良好平衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/changwoolee/blast&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale foundation models have demonstrated exceptional performance inlanguage and vision tasks. However, the numerous dense matrix-vector operationsinvolved in these large networks pose significant computational challengesduring inference. To address these challenges, we introduce the Block-LevelAdaptive STructured (BLAST) matrix, designed to learn and leverage efficientstructures prevalent in the weight matrices of linear layers within deeplearning models. Compared to existing structured matrices, the BLAST matrixoffers substantial flexibility, as it can represent various types of structuresthat are either learned from data or computed from pre-existing weightmatrices. We demonstrate the efficiency of using the BLAST matrix forcompressing both language and vision tasks, showing that (i) for medium-sizedmodels such as ViT and GPT-2, training with BLAST weights boosts performancewhile reducing complexity by 70% and 40%, respectively; and (ii) for largefoundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2xcompression while exhibiting the lowest performance degradation among alltested structured matrices. Our code is available athttps://github.com/changwoolee/BLAST.</description>
      <author>example@mail.com (Changwoo Lee, Soo Min Kwon, Qing Qu, Hun-Seok Kim)</author>
      <guid isPermaLink="false">2410.21262v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Balancing the Scales: Enhancing Fairness in Facial Expression Recognition with Latent Alignment</title>
      <link>http://arxiv.org/abs/2410.19444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动识别情感意图的面部表情已在计算机视觉领域得到深入研究。&lt;h4&gt;目的&lt;/h4&gt;探讨如何减轻面部表情识别系统中的偏见，提高模型的公平性和准确性。&lt;h4&gt;方法&lt;/h4&gt;利用基于潜在空间的表示学习来缓解面部表情识别中的偏见。&lt;h4&gt;主要发现&lt;/h4&gt;现有数据集大多采用人工标注，容易引入个体人口统计偏见，且缺乏对各种社会文化人口群体的公平代表。&lt;h4&gt;结论&lt;/h4&gt;在面部表情识别领域，偏见分析和缓解是相对较少探索的领域，但本研究通过新方法提升了模型的表现。&lt;h4&gt;总结&lt;/h4&gt;本研究强调对面部表情识别数据集中的偏见进行深入分析和解决，以促进公平性和准确性的提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatically recognizing emotional intent using facial expression has been athoroughly investigated topic in the realm of computer vision. FacialExpression Recognition (FER), being a supervised learning task, relies heavilyon substantially large data exemplifying various socio-cultural demographicattributes. Over the past decade, several real-world in-the-wild FER datasetsthat have been proposed were collected through crowd-sourcing or web-scraping.However, most of these practically used datasets employ a manual annotationmethodology for labeling emotional intent, which inherently propagatesindividual demographic biases. Moreover, these datasets also lack an equitablerepresentation of various socio-cultural demographic groups, thereby inducing aclass imbalance. Bias analysis and its mitigation have been investigated acrossmultiple domains and problem settings, however, in the FER domain, this is arelatively lesser explored area. This work leverages representation learningbased on latent spaces to mitigate bias in facial expression recognitionsystems, thereby enhancing a deep learning model's fairness and overallaccuracy.</description>
      <author>example@mail.com (Syed Sameen Ahmad Rizvi, Aryan Seth, Pratik Narang)</author>
      <guid isPermaLink="false">2410.19444v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DeMuVGN: Effective Software Defect Prediction Model by Learning Multi-view Software Dependency via Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.19550v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;软件缺陷预测(SDP)旨在识别软件开发中的高风险缺陷模块，以优化资源分配。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的缺陷预测模型，以更好地捕捉与缺陷相关的信息，尤其是开发者因素。&lt;h4&gt;方法&lt;/h4&gt;提出DeMuVGN模型，通过图神经网络学习多视图软件依赖关系，使用综合数据、调用和开发者依赖的多视图软件依赖图(MSDG)，并采用SMOTE技术解决类别不平衡问题。&lt;h4&gt;主要发现&lt;/h4&gt;在对八个开源项目的案例研究中，DeMuVGN显示出显著改进：i) 多视图图模型的F1分数比单视图模型提高11.1%到12.1%；ii) DeMuVGN在项目内上下文中的F1分数提高17.4%到45.8%，在跨项目上下文中提高17.9%到41.0%。&lt;h4&gt;结论&lt;/h4&gt;DeMuVGN在软件演化方面表现出色，后期软件版本的改进更为显著，其在不同项目中的强大表现突显了其通用性。&lt;h4&gt;未来建议&lt;/h4&gt;建议未来研究关注多视图依赖图在成熟及新开发项目中的缺陷预测应用。&lt;h4&gt;总结&lt;/h4&gt;DeMuVGN模型通过综合依赖关系和先进的样本平衡技术，在缺陷预测中展示了较好的性能和广泛适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Software defect prediction (SDP) aims to identify high-risk defect modules insoftware development, optimizing resource allocation. While previous studiesshow that dependency network metrics improve defect prediction, most methodsfocus on code-based dependency graphs, overlooking developer factors. Currentmetrics, based on handcrafted features like ego and global network metrics,fail to fully capture defect-related information. To address this, we proposeDeMuVGN, a defect prediction model that learns multi-view software dependencyvia graph neural networks. We introduce a Multi-view Software Dependency Graph(MSDG) that integrates data, call, and developer dependencies. DeMuVGN alsoleverages the Synthetic Minority Oversampling Technique (SMOTE) to addressclass imbalance and enhance defect module identification. In a case study ofeight open-source projects across 20 versions, DeMuVGN demonstrates significantimprovements: i) models based on multi-view graphs improve F1 scores by 11.1%to 12.1% over single-view models; ii) DeMuVGN improves F1 scores by 17.4% to45.8% in within-project contexts and by 17.9% to 41.0% in cross-projectcontexts. Additionally, DeMuVGN excels in software evolution, showing moreimprovement in later-stage software versions. Its strong performance acrossdifferent projects highlights its generalizability. We recommend futureresearch focus on multi-view dependency graphs for defect prediction in bothmature and newly developed projects.</description>
      <author>example@mail.com (Yu Qiao, Lina Gong, Yu Zhao, Yongwei Wang, Mingqiang Wei)</author>
      <guid isPermaLink="false">2410.19550v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors</title>
      <link>http://arxiv.org/abs/2410.19680v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurlPS 2024. Project page:
  https://chenchao15.github.io/LocalN2NM/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在许多计算机视觉应用中，从点云中准确估计有符号距离函数（SDF）非常重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，结合数据驱动和过拟合方法的优点，以提高神经SDF学习的泛化能力、推理速度和准确性。&lt;h4&gt;方法&lt;/h4&gt;引入一种新颖的统计推理算法，能够在局部区域内微调基于数据驱动的先验，而无需有符号距离监督、干净的点云或点法线。&lt;h4&gt;主要发现&lt;/h4&gt;与最新方法的数值和视觉比较显示，在表面重建和点云去噪方面，该方法优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法能够更快地收敛，并在初始化阶段提供良好的起始点，适用于高噪声点云等挑战性场景。&lt;h4&gt;代码&lt;/h4&gt;代码可在https://github.com/chenchao15/LocalN2NM获取。&lt;h4&gt;总结&lt;/h4&gt;本研究通过新算法的引入，解决了现有方法在泛化能力和推理速度上的局限，展示了在多个基准测试上的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; It is important to estimate an accurate signed distance function (SDF) from apoint cloud in many computer vision applications. The latest methods learnneural SDFs using either a data-driven based or an overfitting-based strategy.However, these two kinds of methods are with either poor generalization or slowconvergence, which limits their capability under challenging scenarios likehighly noisy point clouds. To resolve this issue, we propose a method topromote pros of both data-driven based and overfitting-based methods for bettergeneralization, faster inference, and higher accuracy in learning neural SDFs.We introduce a novel statistical reasoning algorithm in local regions which isable to finetune data-driven based priors without signed distance supervision,clean point cloud, or point normals. This helps our method start with a goodinitialization, and converge to a minimum in a much faster way. Our numericaland visual comparisons with the state-of-the-art methods show our superiorityover these methods in surface reconstruction and point cloud denoising onwidely used shape and scene benchmarks. The code is available athttps://github.com/chenchao15/LocalN2NM.</description>
      <author>example@mail.com (Chao Chen, Yu-Shen Liu, Zhizhong Han)</author>
      <guid isPermaLink="false">2410.19680v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SocialGPT: Prompting LLMs for Social Relation Reasoning via Greedy Segment Optimization</title>
      <link>http://arxiv.org/abs/2410.21411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024. Project page:
  https://mengzibin.github.io/SocialGPT.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;社会关系推理旨在从图像中识别朋友、配偶和同事等关系类别。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在可推广性和可解释性方面的局限。&lt;h4&gt;方法&lt;/h4&gt;提出一个名为{name}的框架，结合视觉基础模型（VFM）和大型语言模型（LLM）的能力，通过模块化框架实现社会关系识别。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在两个数据库上实现了具有竞争力的零样本结果，并能生成可解释的回答，LLM能够提供基于语言的解释。&lt;h4&gt;结论&lt;/h4&gt;提出的贪婪段落提示优化（GSPO）方法显著提升了性能，并且该方法能够适应不同的图像风格。&lt;h4&gt;总结&lt;/h4&gt;该研究通过将视觉分类任务转化为LLM的生成任务，引入了系统设计原则，推动了社会关系识别的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mengzibin/socialgpt&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social relation reasoning aims to identify relation categories such asfriends, spouses, and colleagues from images. While current methods adopt theparadigm of training a dedicated network end-to-end using labeled image data,they are limited in terms of generalizability and interpretability. To addressthese issues, we first present a simple yet well-crafted framework named{\name}, which combines the perception capability of Vision Foundation Models(VFMs) and the reasoning capability of Large Language Models (LLMs) within amodular framework, providing a strong baseline for social relation recognition.Specifically, we instruct VFMs to translate image content into a textual socialstory, and then utilize LLMs for text-based reasoning. {\name} introducessystematic design principles to adapt VFMs and LLMs separately and bridge theirgaps. Without additional model training, it achieves competitive zero-shotresults on two databases while offering interpretable answers, as LLMs cangenerate language-based explanations for the decisions. The manual promptdesign process for LLMs at the reasoning phase is tedious and an automatedprompt optimization method is desired. As we essentially convert a visualclassification task into a generative task of LLMs, automatic promptoptimization encounters a unique long prompt optimization issue. To addressthis issue, we further propose the Greedy Segment Prompt Optimization (GSPO),which performs a greedy search by utilizing gradient information at the segmentlevel. Experimental results show that GSPO significantly improves performance,and our method also generalizes to different image styles. The code isavailable at https://github.com/Mengzibin/SocialGPT.</description>
      <author>example@mail.com (Wanhua Li, Zibin Meng, Jiawei Zhou, Donglai Wei, Chuang Gan, Hanspeter Pfister)</author>
      <guid isPermaLink="false">2410.21411v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning</title>
      <link>http://arxiv.org/abs/2410.19560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在无监督视觉表示学习的最新进展中，联合嵌入预测架构（JEPA）成为了一种重要的方法，通过创新的掩码策略从未标记的图像中提取视觉特征。&lt;h4&gt;目的&lt;/h4&gt;解决JEPA存在的两个主要限制：I-JEPA的指数移动平均（EMA）无法有效防止整体崩溃，以及I-JEPA预测不准确地学习补丁表示的均值。&lt;h4&gt;方法&lt;/h4&gt;本研究提出了一种新框架，即对比JEPA（C-JEPA），将基于图像的联合嵌入预测架构与方差-不变性-协方差正则化（VICReg）策略结合，旨在有效学习方差/协方差，防止整体崩溃并确保增强视图均值的不变性。&lt;h4&gt;主要发现&lt;/h4&gt;通过实证和理论评估，C-JEPA显著提升了视觉表示学习的稳定性和质量。&lt;h4&gt;结论&lt;/h4&gt;在ImageNet-1K数据集上进行预训练时，C-JEPA在线性探测和微调性能指标上表现出快速和显著的收敛。&lt;h4&gt;总结&lt;/h4&gt;C-JEPA通过整合新策略，克服了JEPA的局限性，提升了无监督视觉表示学习的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent advancements in unsupervised visual representation learning, theJoint-Embedding Predictive Architecture (JEPA) has emerged as a significantmethod for extracting visual features from unlabeled imagery through aninnovative masking strategy. Despite its success, two primary limitations havebeen identified: the inefficacy of Exponential Moving Average (EMA) from I-JEPAin preventing entire collapse and the inadequacy of I-JEPA prediction inaccurately learning the mean of patch representations. Addressing thesechallenges, this study introduces a novel framework, namely C-JEPA(Contrastive-JEPA), which integrates the Image-based Joint-Embedding PredictiveArchitecture with the Variance-Invariance-Covariance Regularization (VICReg)strategy. This integration is designed to effectively learn thevariance/covariance for preventing entire collapse and ensuring invariance inthe mean of augmented views, thereby overcoming the identified limitations.Through empirical and theoretical evaluations, our work demonstrates thatC-JEPA significantly enhances the stability and quality of visualrepresentation learning. When pre-trained on the ImageNet-1K dataset, C-JEPAexhibits rapid and improved convergence in both linear probing and fine-tuningperformance metrics.</description>
      <author>example@mail.com (Shentong Mo, Shengbang Tong)</author>
      <guid isPermaLink="false">2410.19560v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Convolution-based Hybrid Model Approach with Representation Learning for Real-Time Acoustic Anomaly Detection</title>
      <link>http://arxiv.org/abs/2410.19722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 10 figures, ICMLC2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;早期检测工业机械组件的潜在故障对于确保操作的可靠性和安全性至关重要，从而维护机器状态监测（MCM）。&lt;h4&gt;目的&lt;/h4&gt;引入一种创新的方法来进行实时声学异常检测。&lt;h4&gt;方法&lt;/h4&gt;结合半监督时间卷积、表征学习和时间卷积网络（TCN）的混合模型策略，有效处理声学数据中的各种复杂异常模式。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在性能上优于该领域的已建立研究，并通过定量证据和可视化表示（如t-SNE图）进一步验证其有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法展示了在声学异常检测中的有效性，证明了其在工业应用中的潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种有效的声学异常检测方法，能够提升工业机械的故障检测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3651671.3651693&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The early detection of potential failures in industrial machinery componentsis paramount for ensuring the reliability and safety of operations, therebypreserving Machine Condition Monitoring (MCM). This research addresses thisimperative by introducing an innovative approach to Real-Time Acoustic AnomalyDetection. Our method combines semi-supervised temporal convolution withrepresentation learning and a hybrid model strategy with Temporal ConvolutionalNetworks (TCN) to handle various intricate anomaly patterns found in acousticdata effectively. The proposed model demonstrates superior performance comparedto established research in the field, underscoring the effectiveness of thisapproach. Not only do we present quantitative evidence of its superiority, butwe also employ visual representations, such as t-SNE plots, to furthersubstantiate the model's efficacy.</description>
      <author>example@mail.com (Sahan Dissanayaka, Manjusri Wickramasinghe, Pasindu Marasinghe)</author>
      <guid isPermaLink="false">2410.19722v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Foundation Model for Chemical Design and Property Prediction</title>
      <link>http://arxiv.org/abs/2410.21422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能在计算化学研究中取得了显著进展，但传统AI方法通常依赖于特定任务的模型设计和训练，限制了模型规模的可扩展性和跨任务的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;介绍ChemFM，一个专门为化学开发的大规模基础模型。&lt;h4&gt;方法&lt;/h4&gt;ChemFM包含多达30亿个参数，在1.78亿个分子上进行自监督因果语言建模的预训练，以提取可泛化的分子表示。可以通过全参数和参数高效的微调方法适应不同的化学应用。&lt;h4&gt;主要发现&lt;/h4&gt;ChemFM在多个化学任务中始终优于最先进的方法。在34个属性预测基准中提升了67.48%的性能，在条件分子生成任务中减少了33.31%的生成分子条件属性与实际属性之间的平均绝对偏差，在4个反应预测数据集中提高了3.7%的Top-1准确率。&lt;h4&gt;结论&lt;/h4&gt;ChemFM在预测抗生素活性和细胞毒性方面表现出色，显示出其在新型抗生素发现中的潜力。预计ChemFM将通过提供一个能够有效泛化到广泛任务的基础模型，显著推动化学研究。&lt;h4&gt;总结&lt;/h4&gt;ChemFM是为化学领域开发的强大基础模型，具有广泛的应用潜力和良好的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence (AI) has significantly advanced computationalchemistry research. However, traditional AI methods often rely on task-specificmodel designs and training, which constrain both the scalability of model sizeand generalization across different tasks. Here, we introduce ChemFM, alarge-scale foundation model specifically developed for chemistry, comprisingup to 3 billion parameters. ChemFM is pre-trained on 178 million moleculesusing self-supervised causal language modeling to extract generalizablemolecular representations. This model can be adapted to diverse downstreamchemical applications using both full-parameter and parameter-efficientfine-tuning methods. ChemFM consistently outperforms state-of-the-artapproaches across multiple chemical tasks. Notably, it achieves up to 67.48%performance improvement across 34 property prediction benchmarks, up to 33.31%reduction in mean average deviation between conditioned and actual propertiesof generated molecules in conditional molecular generation tasks, and up to3.7% top-1 accuracy improvement across 4 reaction prediction datasets.Moreover, ChemFM demonstrates superior performance in predicting antibioticactivity and cytotoxicity, highlighting its potential to advance the discoveryof novel antibiotics. We anticipate that ChemFM will significantly advancechemistry research by providing a foundation model capable of effectivelygeneralizing across a broad range of tasks with minimal additional training.</description>
      <author>example@mail.com (Feiyang Cai, Tianyu Zhu, Tzuen-Rong Tzeng, Yongping Duan, Ling Liu, Srikanth Pilla, Gang Li, Feng Luo)</author>
      <guid isPermaLink="false">2410.21422v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multi-modal Image and Radio Frequency Fusion for Optimizing Vehicle Positioning</title>
      <link>http://arxiv.org/abs/2410.19788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文设计了一个多模态车辆定位框架，结合信道状态信息（CSI）和图像进行车辆定位。&lt;h4&gt;目的&lt;/h4&gt;在户外场景中，考虑每辆车只能与一个基站（BS）通信，并上传其估计的CSI。&lt;h4&gt;方法&lt;/h4&gt;使用元学习的硬期望最大化（EM）算法，处理标记和未标记的CSI数据及相应的图像。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入加权损失函数，减少标签噪声，提高模型收敛性。&lt;h4&gt;结论&lt;/h4&gt;与仅使用CSI指纹的基线方法相比，提出的方法可以将定位误差减少多达61%。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的多模态车辆定位方法，显著提升了定位精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, a multi-modal vehicle positioning framework that jointlylocalizes vehicles with channel state information (CSI) and images is designed.In particular, we consider an outdoor scenario where each vehicle cancommunicate with only one BS, and hence, it can upload its estimated CSI toonly its associated BS. Each BS is equipped with a set of cameras, such that itcan collect a small number of labeled CSI, a large number of unlabeled CSI, andthe images taken by cameras. To exploit the unlabeled CSI data and positionlabels obtained from images, we design an meta-learning based hardexpectation-maximization (EM) algorithm. Specifically, since we do not know thecorresponding relationship between unlabeled CSI and the multiple vehiclelocations in images, we formulate the calculation of the training objective asa minimum matching problem. To reduce the impact of label noises caused byincorrect matching between unlabeled CSI and vehicle locations obtained fromimages and achieve better convergence, we introduce a weighted loss function onthe unlabeled datasets, and study the use of a meta-learning algorithm forcomputing the weighted loss. Subsequently, the model parameters are updatedaccording to the weighted loss function of unlabeled CSI samples and theirmatched position labels obtained from images. Simulation results show that theproposed method can reduce the positioning error by up to 61% compared to abaseline that does not use images and uses only CSI fingerprint for vehiclepositioning.</description>
      <author>example@mail.com (Ouwen Huan, Tao Luo, Mingzhe Chen)</author>
      <guid isPermaLink="false">2410.19788v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Global Graph Counterfactual Explanation: A Subgraph Mapping Approach</title>
      <link>http://arxiv.org/abs/2410.19978v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在各种实际应用中得到了广泛部署，但大多数GNNs是黑箱模型，缺乏解释。&lt;h4&gt;目的&lt;/h4&gt;通过对抗性解释来揭示GNN的决策过程，寻找输入图的最小扰动以改变GNN的预测。&lt;h4&gt;方法&lt;/h4&gt;提出GlobalGCE，一种新的全局级图对抗性解释方法，旨在识别一组子图映射规则作为目标GNN的对抗性解释。&lt;h4&gt;主要发现&lt;/h4&gt;通过这些规则，用某些重要子图替换其对抗性子图可以在大多数图上改变GNN预测至所需类别，达到最大覆盖。&lt;h4&gt;结论&lt;/h4&gt;GlobalGCE在现有基准之上表现优越，能够有效生成子图和规则。&lt;h4&gt;总结&lt;/h4&gt;GlobalGCE提供了一种新的思路来解释GNN模型，解决了信息过载和跨图关系不足的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have been widely deployed in various real-worldapplications. However, most GNNs are black-box models that lack explanations.One strategy to explain GNNs is through counterfactual explanation, which aimsto find minimum perturbations on input graphs that change the GNN predictions.Existing works on GNN counterfactual explanations primarily concentrate on thelocal-level perspective (i.e., generating counterfactuals for each individualgraph), which suffers from information overload and lacks insights into thebroader cross-graph relationships. To address such issues, we proposeGlobalGCE, a novel global-level graph counterfactual explanation method.GlobalGCE aims to identify a collection of subgraph mapping rules ascounterfactual explanations for the target GNN. According to these rules,substituting certain significant subgraphs with their counterfactual subgraphswill change the GNN prediction to the desired class for most graphs (i.e.,maximum coverage). Methodologically, we design a significant subgraph generatorand a counterfactual subgraph autoencoder in our GlobalGCE, where the subgraphsand the rules can be effectively generated. Extensive experiments demonstratethe superiority of our GlobalGCE compared to existing baselines. Our code canbe found at https://anonymous.4open.science/r/GlobalGCE-92E8.</description>
      <author>example@mail.com (Yinhan He, Wendy Zheng, Yaochen Zhu, Jing Ma, Saumitra Mishra, Natraj Raman, Ninghao Liu, Jundong Li)</author>
      <guid isPermaLink="false">2410.19978v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>LLMs Can Evolve Continually on Modality for X-Modal Reasoning</title>
      <link>http://arxiv.org/abs/2410.20178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态大语言模型（MLLMs）因其在多模态理解方面的出色能力而受到广泛关注，但现有方法在扩展新模态时面临计算负担。&lt;h4&gt;目的&lt;/h4&gt;提出PathWeave，一个灵活且可扩展的框架，支持模态切换和扩展，促进MLLMs在多模态推理方面的持续发展。&lt;h4&gt;方法&lt;/h4&gt;采用持续学习的概念，开发增量训练策略，基于预训练的MLLMs扩展新模态，利用单模态数据，无需执行联合模态预训练。引入新颖的Adapter-in-Adapter（AnA）框架，实现单模态和跨模态适配器的无缝整合，并在两种适配器之间应用MoE基础的门控模块，增强多模态交互。&lt;h4&gt;主要发现&lt;/h4&gt;通过建立名为持续学习模态（MCL）的基准，展示提出的AnA框架在学习灵活性和记忆稳定性方面的有效性。PathWeave在性能上与最先进的MLLMs相当，同时将参数训练负担减少了98.73%。&lt;h4&gt;结论&lt;/h4&gt;PathWeave为MLLMs的模态扩展和持续学习提供了高效的解决方案，降低了计算复杂度。&lt;h4&gt;总结&lt;/h4&gt;本文提出的PathWeave框架在多模态理解中具有显著优势，有助于未来多模态模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jiazuoyu/pathweave&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have gained significant attentiondue to their impressive capabilities in multimodal understanding. However,existing methods rely heavily on extensive modal-specific pretraining andjoint-modal tuning, leading to significant computational burdens when expandingto new modalities. In this paper, we propose PathWeave, a flexible and scalableframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMsto continually EVolve on modalities for $\mathbb{X}$-modal reasoning. Weleverage the concept of Continual Learning and develop an incremental trainingstrategy atop pre-trained MLLMs, enabling their expansion to new modalitiesusing uni-modal data, without executing joint-modal pretraining. In detail, anovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal andcross-modal adapters are seamlessly integrated to facilitate efficient modalityalignment and collaboration. Additionally, an MoE-based gating module isapplied between two types of adapters to further enhance the multimodalinteraction. To investigate the proposed method, we establish a challengingbenchmark called Continual Learning of Modality (MCL), which consists ofhigh-quality QA data from five distinct modalities: image, video, audio, depthand point cloud. Extensive experiments demonstrate the effectiveness of theproposed AnA framework on learning plasticity and memory stability duringcontinual learning. Furthermore, PathWeave performs comparably tostate-of-the-art MLLMs while concurrently reducing parameter training burdensby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave</description>
      <author>example@mail.com (Jiazuo Yu, Haomiao Xiong, Lu Zhang, Haiwen Diao, Yunzhi Zhuge, Lanqing Hong, Dong Wang, Huchuan Lu, You He, Long Chen)</author>
      <guid isPermaLink="false">2410.20178v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Transferring Knowledge from High-Quality to Low-Quality MRI for Adult Glioma Diagnosis</title>
      <link>http://arxiv.org/abs/2410.18698v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report, MICCAI 2024 BraTS-SSA Challenge Runner Up&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;胶质瘤是一种常见且致命的脑肿瘤，需要早期诊断以改善预后，但撒哈拉以南非洲的低质量磁共振成像技术阻碍了准确诊断。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过BraTS挑战赛，提升撒哈拉以南非洲成人胶质瘤的诊断能力。&lt;h4&gt;方法&lt;/h4&gt;采用BraTS-GLI 2021获胜解决方案的模型，使用三种训练策略：1）在BraTS-GLI 2021数据集上初始训练，并在BraTS-Africa数据集上微调；2）仅在BraTS-Africa数据集上训练；3）仅在BraTS-Africa数据集上进行2倍超分辨率增强的训练。&lt;h4&gt;主要发现&lt;/h4&gt;初始在BraTS-GLI 2021数据集训练后，微调BraTS-Africa数据集的策略效果最佳。模型在验证阶段的Dice分数分别为0.882、0.840和0.926，Hausdorff距离（95%）分数为15.324、37.518和13.971，针对增强肿瘤、肿瘤核心和整个肿瘤。&lt;h4&gt;结论&lt;/h4&gt;在比赛的最终阶段，我们的做法成功获得第二名，反映了模型和训练策略的强大和有效性。该研究为改善撒哈拉以南非洲胶质瘤的诊断提供了见解，展示了深度学习在资源有限环境中的潜力以及从高质量数据集中迁移学习的重要性。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了高质量数据集在训练中的先验知识的重要性，并展示了深度学习在低资源环境下改善胶质瘤诊断的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Glioma, a common and deadly brain tumor, requires early diagnosis forimproved prognosis. However, low-quality Magnetic Resonance Imaging (MRI)technology in Sub-Saharan Africa (SSA) hinders accurate diagnosis. This paperpresents our work in the BraTS Challenge on SSA Adult Glioma. We adopt themodel from the BraTS-GLI 2021 winning solution and utilize it with threetraining strategies: (1) initially training on the BraTS-GLI 2021 dataset withfine-tuning on the BraTS-Africa dataset, (2) training solely on theBraTS-Africa dataset, and (3) training solely on the BraTS-Africa dataset with2x super-resolution enhancement. Results show that initial training on theBraTS-GLI 2021 dataset followed by fine-tuning on the BraTS-Africa dataset hasyielded the best results. This suggests the importance of high-quality datasetsin providing prior knowledge during training. Our top-performing model achievesDice scores of 0.882, 0.840, and 0.926, and Hausdorff Distance (95%) scores of15.324, 37.518, and 13.971 for enhancing tumor, tumor core, and whole tumor,respectively, in the validation phase. In the final phase of the competition,our approach successfully secured second place overall, reflecting the strengthand effectiveness of our model and training strategies. Our approach providesinsights into improving glioma diagnosis in SSA, showing the potential of deeplearning in resource-limited settings and the importance of transfer learningfrom high-quality datasets.</description>
      <author>example@mail.com (Yanguang Zhao, Long Bai, Zhaoxi Zhang, Yanan Wu, Mobarakol Islam, Hongliang Ren)</author>
      <guid isPermaLink="false">2410.18698v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Prototypical Extreme Multi-label Classification with a Dynamic Margin Loss</title>
      <link>http://arxiv.org/abs/2410.20401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;极端多标签分类(XMC)方法在极大的标签空间中预测相关标签。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效且性能卓越的XMC方法，克服计算开销和高效解决方案之间的权衡。&lt;h4&gt;方法&lt;/h4&gt;提出PRIME方法，采用原型对比学习技术，将XMC视为数据到原型的预测任务，使用浅层变换器编码器和标签原型网络来增强标签表示。&lt;h4&gt;主要发现&lt;/h4&gt;PRIME在多个公共基准测试中取得了最先进的结果，同时保持模型的高效性。&lt;h4&gt;结论&lt;/h4&gt;PRIME方法有效地改善了极端标签空间中的分类性能，并在效率和性能之间达到了良好的平衡。&lt;h4&gt;总结&lt;/h4&gt;PRIME方法通过对比学习和标签原型网络提高了极端多标签分类的效率和表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extreme Multi-label Classification (XMC) methods predict relevant labels fora given query in an extremely large label space. Recent works in XMC addressthis problem using deep encoders that project text descriptions to an embeddingspace suitable for recovering the closest labels. However, learning deep modelscan be computationally expensive in large output spaces, resulting in atrade-off between high performing brute-force approaches and efficientsolutions. In this paper, we propose PRIME, a XMC method that employs a novelprototypical contrastive learning technique to reconcile efficiency andperformance surpassing brute-force approaches. We frame XMC as adata-to-prototype prediction task where label prototypes aggregate informationfrom related queries. More precisely, we use a shallow transformer encoder thatwe coin as Label Prototype Network, which enriches label representations byaggregating text-based embeddings, label centroids and learnable free vectors.We jointly train a deep encoder and the Label Prototype Network using anadaptive triplet loss objective that better adapts to the high granularity andambiguity of extreme label spaces. PRIME achieves state-of-the-art results inseveral public benchmarks of different sizes and domains, while keeping themodel efficient.</description>
      <author>example@mail.com (Kunal Dahiya, Diego Ortego, David Jiménez)</author>
      <guid isPermaLink="false">2410.20401v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Sparse Decomposition of Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.19723v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在图表示学习中表现优越，但推理成本较高，主要由于聚合操作需要为大量节点进行内存提取，这成为在线预测应用的主要障碍。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，减少聚合过程中包含的节点数量，以应对动态节点特征的在线预测需求。&lt;h4&gt;方法&lt;/h4&gt;通过稀疏分解，学习使用经过线性变换的特征的加权和来近似节点表示，从而选择扩展邻域中的特定子集节点，达到线性复杂度。&lt;h4&gt;主要发现&lt;/h4&gt;提出的算法计算稀疏分解的最佳参数，确保对原始GNN模型的准确近似，并通过有效策略减少训练时间，提高学习过程。&lt;h4&gt;结论&lt;/h4&gt;通过大量实验表明，该方法在推理加速方面优于其他基线模型，在节点分类和时空预测任务中实现了显著的准确性提升，同时推理时间相当。&lt;h4&gt;总结&lt;/h4&gt;该研究为图神经网络的在线预测提供了有效的解决方案，能够在保证准确性的基础上显著降低推理成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNN) exhibit superior performance in graphrepresentation learning, but their inference cost can be high, due to anaggregation operation that can require a memory fetch for a very large numberof nodes. This inference cost is the major obstacle to deploying GNN modelswith \emph{online prediction} to reflect the potentially dynamic node features.To address this, we propose an approach to reduce the number of nodes that areincluded during aggregation. We achieve this through a sparse decomposition,learning to approximate node representations using a weighted sum of linearlytransformed features of a carefully selected subset of nodes within theextended neighbourhood. The approach achieves linear complexity with respect tothe average node degree and the number of layers in the graph neural network.We introduce an algorithm to compute the optimal parameters for the sparsedecomposition, ensuring an accurate approximation of the original GNN model,and present effective strategies to reduce the training time and improve thelearning process. We demonstrate via extensive experiments that our methodoutperforms other baselines designed for inference speedup, achievingsignificant accuracy gains with comparable inference times for both nodeclassification and spatio-temporal forecasting tasks.</description>
      <author>example@mail.com (Yaochen Hu, Mai Zeng, Ge Zhang, Pavel Rumiantsev, Liheng Ma, Yingxue Zhang, Mark Coates)</author>
      <guid isPermaLink="false">2410.19723v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>UFT: Unifying Fine-Tuning of SFT and RLHF/DPO/UNA through a Generalized Implicit Reward Function</title>
      <link>http://arxiv.org/abs/2410.21438v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;通过对数万亿个标记进行预训练，LLM获得了文本生成的能力。&lt;h4&gt;目的&lt;/h4&gt;为了增强模型的实用性并减少潜在的危害，依次应用SFT和对齐。&lt;h4&gt;方法&lt;/h4&gt;引入统一微调（UFT），将SFT和对齐整合为一个训练阶段，使用相同的目标和损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;UFT在仅使用指令调优数据时优于SFT，并且在结合指令调优数据和对齐数据时有效防止了灾难性遗忘。&lt;h4&gt;结论&lt;/h4&gt;UFT在指令跟随的ifeval任务和事实性truthful-qa任务中表现出明显改善，建立了有效的预训练-UFT范式。&lt;h4&gt;总结&lt;/h4&gt;UFT提供了一种有效且高效的微调框架，提升了LLM训练的整体效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; By pretraining on trillions of tokens, an LLM gains the capability of textgeneration. However, to enhance its utility and reduce potential harm, SFT andalignment are applied sequentially to the pretrained model. Due to thediffering nature and objective functions of SFT and alignment, catastrophicforgetting has become a significant issue. To address this, we introduceUnified Fine-Tuning (UFT), which integrates SFT and alignment into a singletraining stage using the same objective and loss functions through an implicitreward function. Our experimental results demonstrate that UFT outperforms SFTon instruction-tuning data alone. Moreover, when combining instruction-tuningdata with alignment data, UFT effectively prevents catastrophic forgettingacross these two stages and shows a clear advantage over sequentially applyingSFT and alignment. This is evident in the significant improvements observed inthe \textbf{ifeval} task for instruction-following and the \textbf{truthful-qa}task for factuality. The proposed general fine-tuning framework UFT establishesan effective and efficient pretraining-UFT paradigm for LLM training.</description>
      <author>example@mail.com (Zhichao Wang, Bin Bi, Zixu Zhu, Xiangbo Mao, Jun Wang, Shiyu Wang)</author>
      <guid isPermaLink="false">2410.21438v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>GraphLSS: Integrating Lexical, Structural, and Semantic Features for Long Document Extractive Summarization</title>
      <link>http://arxiv.org/abs/2410.21315v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Short paper submitted to ACL ARR November cycle&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;异构图神经网络在长文档摘要中受到关注，将提取建模为节点分类任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的异构图构建方法GraphLSS，用于长文档的抽取式摘要。&lt;h4&gt;方法&lt;/h4&gt;GraphLSS结合词汇、结构和语义特征，定义两个信息层次（词和句子）以及四种边类型（句子语义相似度、句子出现顺序、句子中的词和词语义相似度），不需要辅助学习模型。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准数据集上的实验表明，GraphLSS与顶尖图基方法具有竞争力，且优于近期的非图模型。&lt;h4&gt;结论&lt;/h4&gt;GraphLSS提供了一种更简单、直观的长文档摘要解决方案。&lt;h4&gt;总结&lt;/h4&gt;我们在GitHub上发布了代码，推动该领域的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Heterogeneous graph neural networks have recently gained attention for longdocument summarization, modeling the extraction as a node classification task.Although effective, these models often require external tools or additionalmachine learning models to define graph components, producing highly complexand less intuitive structures. We present GraphLSS, a heterogeneous graphconstruction for long document extractive summarization, incorporating Lexical,Structural, and Semantic features. It defines two levels of information (wordsand sentences) and four types of edges (sentence semantic similarity, sentenceoccurrence order, word in sentence, and word semantic similarity) without anyneed for auxiliary learning models. Experiments on two benchmark datasets showthat GraphLSS is competitive with top-performing graph-based methods,outperforming recent non-graph models. We release our code on GitHub.</description>
      <author>example@mail.com (Margarita Bugueño, Hazem Abou Hamdan, Gerard de Melo)</author>
      <guid isPermaLink="false">2410.21315v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Point-PRC: A Prompt Learning Based Regulation Framework for Generalizable Point Cloud Analysis</title>
      <link>http://arxiv.org/abs/2410.20406v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;最近的研究表明，通过参数高效的提示调优可以显著提升3D点云识别性能，但在下游任务上实现的提升伴随着3D领域泛化能力的严重下降。&lt;h4&gt;目的&lt;/h4&gt;解决大规模3D模型在3D领域泛化能力下降的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一个综合调节框架，允许可学习提示与大型3D模型中已学习的通用知识进行积极互动，保持良好的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的框架通过最大化任务特定预测与任务无关知识之间的相互一致性，对提示学习轨迹施加多个显式约束，能够持续提升泛化能力，并在各种3DDG基准上增强任务特定的3D识别性能。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅提高了泛化能力，还在多个3DDG基准上以明显的幅度增强了任务特定的3D识别性能。&lt;h4&gt;新贡献&lt;/h4&gt;创建了三个新的基准（基础到新、跨数据集和少样本泛化基准）以丰富该领域并激励未来研究。&lt;h4&gt;总结&lt;/h4&gt;代码和基准可在指定链接获取，旨在促进3D领域泛化能力的进一步研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/auniquesun/point-prc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the 3D domain generalization (3DDG) ability of large3D models based on prevalent prompt learning. Recent works demonstrate theperformances of 3D point cloud recognition can be boosted remarkably byparameter-efficient prompt tuning. However, we observe that the improvement ondownstream tasks comes at the expense of a severe drop in 3D domaingeneralization. To resolve this challenge, we present a comprehensiveregulation framework that allows the learnable prompts to actively interactwith the well-learned general knowledge in large 3D models to maintain goodgeneralization. Specifically, the proposed framework imposes multiple explicitconstraints on the prompt learning trajectory by maximizing the mutualagreement between task-specific predictions and task-agnostic knowledge. Wedesign the regulation framework as a plug-and-play module to embed intoexisting representative large 3D models. Surprisingly, our method not onlyrealizes consistently increasing generalization ability but also enhancestask-specific 3D recognition performances across various 3DDG benchmarks by aclear margin. Considering the lack of study and evaluation on 3DDG, we alsocreate three new benchmarks, namely base-to-new, cross-dataset and few-shotgeneralization benchmarks, to enrich the field and inspire future research.Code and benchmarks are available at\url{https://github.com/auniquesun/Point-PRC}.</description>
      <author>example@mail.com (Hongyu Sun, Qiuhong Ke, Yongcai Wang, Wang Chen, Kang Yang, Deying Li, Jianfei Cai)</author>
      <guid isPermaLink="false">2410.20406v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Learning the Regularization Strength for Deep Fine-Tuning via a Data-Emphasized Variational Objective</title>
      <link>http://arxiv.org/abs/2410.19675v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多流行的迁移学习方法依赖于网格搜索来选择控制过拟合的正则化超参数。&lt;h4&gt;目的&lt;/h4&gt;提出一种替代网格搜索的方法，以直接学习正则化超参数。&lt;h4&gt;方法&lt;/h4&gt;通过基于变分方法的证据下界（ELBo）目标，使用模型选择技术在完整训练集上学习正则化超参数。&lt;h4&gt;主要发现&lt;/h4&gt;修改后的ELBo在深度神经网络中增强了数据似然相对于先验的影响，同时仍然有效用于贝叶斯模型选择。&lt;h4&gt;结论&lt;/h4&gt;所提技术克服了网格搜索的三个主要缺点，并在多个数据集的图像分类任务中表现出有效性，计算时间显著减少。&lt;h4&gt;总结&lt;/h4&gt;所提出的方法在保持准确性的同时，显著提高了计算效率，是对传统网格搜索的有效替代。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/tufts-ml/data-emphasized-ELBo&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A number of popular transfer learning methods rely on grid search to selectregularization hyperparameters that control over-fitting. This grid searchrequirement has several key disadvantages: the search is computationallyexpensive, requires carving out a validation set that reduces the size ofavailable data for model training, and requires practitioners to specifycandidate values. In this paper, we propose an alternative to grid search:directly learning regularization hyperparameters on the full training set viamodel selection techniques based on the evidence lower bound ("ELBo") objectivefrom variational methods. For deep neural networks with millions of parameters,we specifically recommend a modified ELBo that upweights the influence of thedata likelihood relative to the prior while remaining a valid bound on theevidence for Bayesian model selection. Our proposed technique overcomes allthree disadvantages of grid search. We demonstrate effectiveness on imageclassification tasks on several datasets, yielding heldout accuracy comparableto existing approaches with far less compute time.</description>
      <author>example@mail.com (Ethan Harvey, Mikhail Petrov, Michael C. Hughes)</author>
      <guid isPermaLink="false">2410.19675v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Language Agents Meet Causality -- Bridging LLMs and Causal World Models</title>
      <link>http://arxiv.org/abs/2410.19923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://j0hngou.github.io/LLMCWM/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在规划和推理应用中显示出良好前景，但这些任务需要强大的系统，要求对环境有因果理解。&lt;h4&gt;目的&lt;/h4&gt;提出一个将因果表示学习（CRL）与LLMs整合的框架，以实现因果意识的推理和规划。&lt;h4&gt;方法&lt;/h4&gt;该框架学习一个因果世界模型，将因果变量与自然语言表达关联，为LLMs提供灵活的接口，以文本形式处理和生成动作及状态描述。&lt;h4&gt;主要发现&lt;/h4&gt;在时间尺度和环境复杂性不同的因果推断和规划任务中，该方法的效果优于基于LLM的推理器，特别是在较长规划周期中表现更佳。&lt;h4&gt;结论&lt;/h4&gt;整合CRL与LLMs的框架有效提升了因果意识的推理和规划能力，展示了该方法的优势。&lt;h4&gt;总结&lt;/h4&gt;通过因果世界模型，LLMs能够更好地理解和描述环境中的因果关系，增强其在复杂任务中的应用能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/j0hngou/LLMCWM&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have recently shown great promise in planningand reasoning applications. These tasks demand robust systems, which arguablyrequire a causal understanding of the environment. While LLMs can acquire andreflect common sense causal knowledge from their pretraining data, thisinformation is often incomplete, incorrect, or inapplicable to a specificenvironment. In contrast, causal representation learning (CRL) focuses onidentifying the underlying causal structure within a given environment. Wepropose a framework that integrates CRLs with LLMs to enable causally-awarereasoning and planning. This framework learns a causal world model, with causalvariables linked to natural language expressions. This mapping provides LLMswith a flexible interface to process and generate descriptions of actions andstates in text form. Effectively, the causal world model acts as a simulatorthat the LLM can query and interact with. We evaluate the framework on causalinference and planning tasks across temporal scales and environmentalcomplexities. Our experiments demonstrate the effectiveness of the approach,with the causally-aware method outperforming LLM-based reasoners, especiallyfor longer planning horizons.</description>
      <author>example@mail.com (John Gkountouras, Matthias Lindemann, Phillip Lippe, Efstratios Gavves, Ivan Titov)</author>
      <guid isPermaLink="false">2410.19923v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FedSSP: Federated Graph Learning with Spectral Knowledge and Personalized Preference</title>
      <link>http://arxiv.org/abs/2410.20105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;个性化联邦图学习（pFGL）在不妨碍隐私的情况下，促进了图神经网络（GNN）的去中心化训练，满足非独立同分布（non-IID）参与者的个性化需求。&lt;h4&gt;目的&lt;/h4&gt;解决跨域场景中结构异质性对pFGL的重大挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了FedSSP框架，通过共享通用谱知识，克服领域结构变化，同时引入个性化偏好模块。&lt;h4&gt;主要发现&lt;/h4&gt;谱特性能有效反映固有的领域结构变化，且传统的pFGL方法在共享非通用知识方面存在问题。&lt;h4&gt;结论&lt;/h4&gt;FedSSP框架在跨数据集和跨领域设置下表现优越，展示了其在个性化联邦图学习中的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究通过创新方法提升了pFGL的性能，提供了可在GitHub上获取的代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/oakleytan/fedssp&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Personalized Federated Graph Learning (pFGL) facilitates the decentralizedtraining of Graph Neural Networks (GNNs) without compromising privacy whileaccommodating personalized requirements for non-IID participants. Incross-domain scenarios, structural heterogeneity poses significant challengesfor pFGL. Nevertheless, previous pFGL methods incorrectly share non-genericknowledge globally and fail to tailor personalized solutions locally underdomain structural shift. We innovatively reveal that the spectral nature ofgraphs can well reflect inherent domain structural shifts. Correspondingly, ourmethod overcomes it by sharing generic spectral knowledge. Moreover, weindicate the biased message-passing schemes for graph structures and proposethe personalized preference module. Combining both strategies, we propose ourpFGL framework FedSSP which Shares generic Spectral knowledge while satisfyinggraph Preferences. Furthermore, We perform extensive experiments oncross-dataset and cross-domain settings to demonstrate the superiority of ourframework. The code is available at https://github.com/OakleyTan/FedSSP.</description>
      <author>example@mail.com (Zihan Tan, Guancheng Wan, Wenke Huang, Mang Ye)</author>
      <guid isPermaLink="false">2410.20105v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MAMMAL -- Molecular Aligned Multi-Modal Architecture and Language</title>
      <link>http://arxiv.org/abs/2410.22367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;药物发现通常包括多个步骤，如识别与疾病病因相关的靶蛋白、验证与该靶点的相互作用能否防止症状或治愈疾病等。&lt;h4&gt;目的&lt;/h4&gt;提出MAMMAL（分子对齐多模态架构和语言），用于处理药物发现中的多任务学习。&lt;h4&gt;方法&lt;/h4&gt;MAMMAL方法应用于创建一个多功能基础模型，利用大规模生物数据集（20亿样本），支持多种分类、回归和生成任务。&lt;h4&gt;主要发现&lt;/h4&gt;模型在11个不同下游任务的评估中，9个任务达到新的最先进水平（SOTA），2个任务表现与最先进水平相当。&lt;h4&gt;结论&lt;/h4&gt;该模型在所有任务中使用统一架构，与传统的针对特定任务的架构相比，性能表现更佳。&lt;h4&gt;模型可用性&lt;/h4&gt;模型代码和预训练权重公开可用，链接为https://github.com/BiomedSciAI/biomed-multi-alignment和https://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m。&lt;h4&gt;总结&lt;/h4&gt;MAMMAL提供了一种新的方法，通过多模态学习优化药物发现过程，展示了广泛的应用潜力和优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/biomedsciai/biomed-multi-alignment&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Drug discovery typically consists of multiple steps, including identifying atarget protein key to a disease's etiology, validating that interacting withthis target could prevent symptoms or cure the disease, discovering a smallmolecule or biologic therapeutic to interact with it, and optimizing thecandidate molecule through a complex landscape of required properties. Drugdiscovery related tasks often involve prediction and generation whileconsidering multiple entities that potentially interact, which poses achallenge for typical AI models. For this purpose we present MAMMAL - MolecularAligned Multi-Modal Architecture and Language - a method that we applied tocreate a versatile multi-task foundation modelibm/biomed.omics.bl.sm.ma-ted-458m that learns from large-scale biologicaldatasets (2 billion samples) across diverse modalities, including proteins,small molecules, and genes. We introduce a prompt syntax that supports a widerange of classification, regression, and generation tasks. It allows combiningdifferent modalities and entity types as inputs and/or outputs. Our modelhandles combinations of tokens and scalars and enables the generation of smallmolecules and proteins, property prediction, and transcriptomic lab testpredictions. We evaluated the model on 11 diverse downstream tasks spanningdifferent steps within a typical drug discovery pipeline, where it reaches newSOTA in 9 tasks and is comparable to SOTA in 2 tasks. This performance isachieved while using a unified architecture serving all tasks, in contrast tothe original SOTA performance achieved using tailored architectures.  The model code and pretrained weights are publicly available athttps://github.com/BiomedSciAI/biomed-multi-alignment andhttps://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m.</description>
      <author>example@mail.com (Yoel Shoshan, Moshiko Raboh, Michal Ozery-Flato, Vadim Ratner, Alex Golts, Jeffrey K. Weber, Ella Barkan, Simona Rabinovici-Cohen, Sagi Polaczek, Ido Amos, Ben Shapira, Liam Hazan, Matan Ninio, Sivan Ravid, Michael M. Danziger, Joseph A. Morrone, Parthasarathy Suryanarayanan, Michal Rosen-Zvi, Efrat Hexter)</author>
      <guid isPermaLink="false">2410.22367v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Augmentation Invariance Pretraining</title>
      <link>http://arxiv.org/abs/2410.22364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习方法在视觉变换器（ViTs）预训练中的计算挑战。&lt;h4&gt;目的&lt;/h4&gt;解决对比学习训练中所需的高计算资源问题，以促进其实际应用。&lt;h4&gt;方法&lt;/h4&gt;提出加速框架，利用ViT对不同序列长度输入的泛化能力，采用随机 token 随机丢弃和灵活的补丁缩放等序列压缩策略以减少梯度估计成本并加速收敛。&lt;h4&gt;主要发现&lt;/h4&gt;对不同加速策略的梯度估计误差及其对下游任务的影响进行了深入分析，提供了加速与性能之间的权衡见解。&lt;h4&gt;结论&lt;/h4&gt;提出了一种新的优化加速调度程序，根据训练进度调整序列压缩比，以确保高效训练而不牺牲下游性能。&lt;h4&gt;总结&lt;/h4&gt;在大规模数据集上，显著降低了各种自监督学习算法的计算开销。在ImageNet上，MoCo速度提高4倍，SimCLR提高3.3倍，DINO提高2.5倍，显示出显著的效率提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Our work tackles the computational challenges of contrastive learningmethods, particularly for the pretraining of Vision Transformers (ViTs).Despite the effectiveness of contrastive learning, the substantialcomputational resources required for training often hinder their practicalapplication. To mitigate this issue, we propose an acceleration framework,leveraging ViT's unique ability to generalize across inputs of varying sequencelengths. Our method employs a mix of sequence compression strategies, includingrandomized token dropout and flexible patch scaling, to reduce the cost ofgradient estimation and accelerate convergence. We further provide an in-depthanalysis of the gradient estimation error of various acceleration strategies aswell as their impact on downstream tasks, offering valuable insights into thetrade-offs between acceleration and performance.  We also propose a novel procedure to identify an optimal accelerationschedule to adjust the sequence compression ratios to the training progress,ensuring efficient training without sacrificing downstream performance. Ourapproach significantly reduces computational overhead across variousself-supervised learning algorithms on large-scale datasets. In ImageNet, ourmethod achieves speedups of 4$\times$ in MoCo, 3.3$\times$ in SimCLR, and2.5$\times$ in DINO, demonstrating substantial efficiency gains.</description>
      <author>example@mail.com (Jinhong Lin, Cheng-En Wu, Yibing Wei, Pedro Morgado)</author>
      <guid isPermaLink="false">2410.22364v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Deep Concept Identification for Generative Design</title>
      <link>http://arxiv.org/abs/2410.20061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于拓扑优化的生成设计提供了多样化的替代方案，但设计师在选择最合适方案时面临认知负担增加的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一个基于深度学习的概念识别框架，以帮助结构化生成的设计替代方案。&lt;h4&gt;方法&lt;/h4&gt;利用深度学习技术进行深度概念识别，自动学习几何属性与结构性能之间的映射关系。&lt;h4&gt;主要发现&lt;/h4&gt;框架通过生成设计技术生成多样化替代方案，利用深度学习对其进行聚类，并通过分类模型进行排序以供设计实践使用。&lt;h4&gt;结论&lt;/h4&gt;实施变分深嵌入和逻辑回归模型验证了框架的基本能力，尽管设计师需设定概念数量，但框架能以决策树形式展示识别的概念及其关系。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种有效的方法，通过深度学习支持的概念识别和分类，减轻设计师的认知负担，并提高生成设计的实用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A generative design based on topology optimization provides diversealternatives as entities in a computational model with a high design degree.However, as the diversity of the generated alternatives increases, thecognitive burden on designers to select the most appropriate alternatives alsoincreases. Whereas the concept identification approach, which finds variouscategories of entities, is an effective means to structure alternatives,evaluation of their similarities is challenging due to shape diversity. Toaddress this challenge, this study proposes a concept identification frameworkfor generative design using deep learning (DL) techniques. One of the keyabilities of DL is the automatic learning of different representations of aspecific task. Deep concept identification finds various categories thatprovide insights into the mapping relationships between geometric propertiesand structural performance through representation learning using DL. Theproposed framework generates diverse alternatives using a generative designtechnique, clusters the alternatives into several categories using a DLtechnique, and arranges these categories for design practice using aclassification model. This study demonstrates its fundamental capabilities byimplementing variational deep embedding, a generative and clustering modelbased on the DL paradigm, and logistic regression as a classification model. Asimplified design problem of a two-dimensional bridge structure is applied as acase study to validate the proposed framework. Although designers are requiredto determine the viewing aspect level by setting the number of concepts, thisimplementation presents the identified concepts and their relationships in theform of a decision tree based on a specified level.</description>
      <author>example@mail.com (Ryo Tsumoto, Kentaro Yaji, Yutaka Nomaguchi, Kikuo Fujita)</author>
      <guid isPermaLink="false">2410.20061v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Going Beyond H&amp;E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?</title>
      <link>http://arxiv.org/abs/2410.21560v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Workshop on Advancements In Medical Foundation Models
  (NeurIPS 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究评估了最先进的组织病理学基础模型在多染色自身免疫免疫组化数据集上的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;比较13种特征提取模型在类风湿性关节炎亚型划分和干燥综合症检测任务上的表现。&lt;h4&gt;方法&lt;/h4&gt;使用简单的基于注意力的多实例学习分类器，评估从癌症H&amp;E图像到自身免疫IHC图像的学习表示的可转移性。&lt;h4&gt;主要发现&lt;/h4&gt;组织病理学预训练模型的表现没有显著优于ImageNet预训练模型，且存在自身免疫特征误解和特征重要性偏差的证据。&lt;h4&gt;结论&lt;/h4&gt;从癌症到自身免疫组织病理学知识的转移面临挑战，需要对AI模型在不同组织病理学任务上的表现进行仔细评估。&lt;h4&gt;代码&lt;/h4&gt;基准测试的代码可在https://github.com/AmayaGS/ImmunoHistoBench找到。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了在自身免疫病理学领域应用AI模型时需谨慎评估其适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/amayags/immunohistobench&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study evaluates the generalisation capabilities of state-of-the-arthistopathology foundation models on out-of-distribution multi-stain autoimmuneImmunohistochemistry datasets. We compare 13 feature extractor models,including ImageNet-pretrained networks, and histopathology foundation modelstrained on both public and proprietary data, on Rheumatoid Arthritis subtypingand Sjogren's Disease detection tasks. Using a simple Attention-Based MultipleInstance Learning classifier, we assess the transferability of learnedrepresentations from cancer H&amp;E images to autoimmune IHC images. Contrary toexpectations, histopathology-pretrained models did not significantly outperformImageNet-pretrained models. Furthermore, there was evidence of both autoimmunefeature misinterpretation and biased feature importance. Our findings highlightthe challenges in transferring knowledge from cancer to autoimmunehistopathology and emphasise the need for careful evaluation of AI modelsacross diverse histopathological tasks. The code to run this benchmark isavailable at https://github.com/AmayaGS/ImmunoHistoBench.</description>
      <author>example@mail.com (Amaya Gallagher-Syed, Elena Pontarini, Myles J. Lewis, Michael R. Barnes, Gregory Slabaugh)</author>
      <guid isPermaLink="false">2410.21560v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Transformer-Based Tooth Alignment Prediction With Occlusion And Collision Constraints</title>
      <link>http://arxiv.org/abs/2410.20806v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  add key words and email information&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数字正畸治疗规划需要牙齿对齐，这一过程耗时耗力且依赖临床经验。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Swin-transformer的轻量化牙齿对齐神经网络。&lt;h4&gt;方法&lt;/h4&gt;重组3D点云，基于虚拟弓线转换为有序多通道纹理；设计两种新的咬合损失函数，定量评估上下颌关系；收集包含591个临床案例的大型数字正畸数据集，并提出两种新的数据集增强方法。&lt;h4&gt;主要发现&lt;/h4&gt;在使用新咬合损失函数后，预测准确性显著提高。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在高预测准确性方面表现优异，并且数据集的发布将对社区产生积极影响。&lt;h4&gt;总结&lt;/h4&gt;研究为数字正畸治疗提供了一种高效的工具，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The planning of digital orthodontic treatment requires providing toothalignment, which not only consumes a lot of time and labor to determinemanually but also relays clinical experiences heavily. In this work, weproposed a lightweight tooth alignment neural network based onSwin-transformer. We first re-organized 3D point clouds based on virtual archlines and converted them into order-sorted multi-channel textures, whichimproves the accuracy and efficiency simultaneously. We then designed two newocclusal loss functions that quantitatively evaluate the occlusal relationshipbetween the upper and lower jaws. They are important clinical constraints,first introduced to the best of our knowledge, and lead to cutting-edgeprediction accuracy. To train our network, we collected a large digitalorthodontic dataset that has 591 clinical cases, including various complexclinical cases. This dataset will benefit the community after its release sincethere is no open dataset so far. Furthermore, we also proposed two neworthodontic dataset augmentation methods considering tooth spatial distributionand occlusion. We evaluated our method with this dataset and extensiveexperiments, including comparisons with STAT methods and ablation studies, anddemonstrate the high prediction accuracy of our method.</description>
      <author>example@mail.com (ZhenXing Dong, JiaZhou Chen, YangHui Xu)</author>
      <guid isPermaLink="false">2410.20806v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PepDoRA: A Unified Peptide Language Model via Weight-Decomposed Low-Rank Adaptation</title>
      <link>http://arxiv.org/abs/2410.20667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;肽类治疗药物，包括大环肽、肽抑制剂和生物活性线性肽，由于其独特的物理化学性质，在治疗开发中发挥着关键作用。预测这些性质仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出PepDoRA，一个统一的肽表示模型，以弥补现有模型在肽的预测能力上的不足。&lt;h4&gt;方法&lt;/h4&gt;利用Weight-Decomposed Low-Rank Adaptation (DoRA)，PepDoRA对ChemBERTa-77M-MLM进行高效微调，通过掩蔽语言模型目标生成优化的嵌入，适用于修改和未修改肽的性质预测任务。&lt;h4&gt;主要发现&lt;/h4&gt;通过在100,000个修改后的生物活性和结合肽上进行调优，PepDoRA嵌入能够捕捉输入肽的功能特性，准确预测膜渗透性、抗污染性和溶血倾向，以及通过对比学习实现靶蛋白特异性结合。&lt;h4&gt;结论&lt;/h4&gt;PepDoRA为化学和生物多样性的肽提供了统一的表示，成为功能和活性预测的多用途工具，推动肽类治疗药物的广泛应用。&lt;h4&gt;总结&lt;/h4&gt;PepDoRA模型在肽的性质预测中显示出良好的适应性，有助于肽类药物的开发。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Peptide therapeutics, including macrocycles, peptide inhibitors, andbioactive linear peptides, play a crucial role in therapeutic development dueto their unique physicochemical properties. However, predicting theseproperties remains challenging. While structure-based models primarily focus onlocal interactions, language models are capable of capturing global therapeuticproperties of both modified and linear peptides. Protein language models likeESM-2, though effective for natural peptides, cannot however encode chemicalmodifications. Conversely, pre-trained chemical language models excel inrepresenting small molecule properties but are not optimized for peptides. Tobridge this gap, we introduce PepDoRA, a unified peptide representation model.Leveraging Weight-Decomposed Low-Rank Adaptation (DoRA), PepDoRA efficientlyfine-tunes the ChemBERTa-77M-MLM on a masked language model objective togenerate optimized embeddings for downstream property prediction tasksinvolving both modified and unmodified peptides. By tuning on a diverse andexperimentally valid set of 100,000 modified, bioactive, and binding peptides,we show that PepDoRA embeddings capture functional properties of inputpeptides, enabling the accurate prediction of membrane permeability,non-fouling and hemolysis propensity, and via contrastive learning, targetprotein-specific binding. Overall, by providing a unified representation forchemically and biologically diverse peptides, PepDoRA serves as a versatiletool for function and activity prediction, facilitating the development ofpeptide therapeutics across a broad spectrum of applications.</description>
      <author>example@mail.com (Leyao Wang, Rishab Pulugurta, Pranay Vure, Yinuo Zhang, Aastha Pal, Pranam Chatterjee)</author>
      <guid isPermaLink="false">2410.20667v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Discovering Robotic Interaction Modes with Discrete Representation Learning</title>
      <link>http://arxiv.org/abs/2410.20258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类操作关节物体的行为可以被分类为不同的交互模式，但传统机器人学习方法缺乏对这些模式的离散表示。&lt;h4&gt;目的&lt;/h4&gt;提出ActAIM2，学习机器人操作交互模式的离散表示，采用无监督方式，不依赖专家标签或模拟器信息。&lt;h4&gt;方法&lt;/h4&gt;使用新颖的数据收集方法，包括模拟器回放，ActAIM2包含交互模式选择器和低级动作预测器，前者生成潜在交互模式的离散表示，后者输出相应的动作轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;通过操作关节物体的成功率和从离散表示中采样有意义动作的鲁棒性验证了该方法。&lt;h4&gt;结论&lt;/h4&gt;ActAIM2在提高可操控性和泛化能力方面显著优于基线和消融研究。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了无监督学习在机器人操作中的潜力，并提供了有效的交互模式学习方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human actions manipulating articulated objects, such as opening and closing adrawer, can be categorized into multiple modalities we define as interactionmodes. Traditional robot learning approaches lack discrete representations ofthese modes, which are crucial for empirical sampling and grounding. In thispaper, we present ActAIM2, which learns a discrete representation of robotmanipulation interaction modes in a purely unsupervised fashion, without theuse of expert labels or simulator-based privileged information. Utilizing noveldata collection methods involving simulator rollouts, ActAIM2 consists of aninteraction mode selector and a low-level action predictor. The selectorgenerates discrete representations of potential interaction modes withself-supervision, while the predictor outputs corresponding actiontrajectories. Our method is validated through its success rate in manipulatingarticulated objects and its robustness in sampling meaningful actions from thediscrete representation. Extensive experiments demonstrate ActAIM2'seffectiveness in enhancing manipulability and generalizability over baselinesand ablation studies. For videos and additional results, see our website:https://actaim2.github.io/.</description>
      <author>example@mail.com (Liquan Wang, Ankit Goyal, Haoping Xu, Animesh Garg)</author>
      <guid isPermaLink="false">2410.20258v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Just Propagate: Unifying Matrix Factorization, Network Embedding, and LightGCN for Link Prediction</title>
      <link>http://arxiv.org/abs/2410.21325v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;链接预测是图分析中的一个基础任务。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的框架，以涵盖矩阵分解、网络嵌入和图神经网络方法进行链接预测。&lt;h4&gt;方法&lt;/h4&gt;分析不同模型的设计因素，并进行初步的方法论和实证分析。&lt;h4&gt;主要发现&lt;/h4&gt;基于统一框架揭示了几个关键的设计因素。&lt;h4&gt;结论&lt;/h4&gt;研究结果有助于加深对链接预测的理解，并激发新的链接预测方法的设计。&lt;h4&gt;总结&lt;/h4&gt;提出的统一框架为链接预测提供了新的视角和方法论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a fundamental task in graph analysis. Despite the successof various graph-based machine learning models for link prediction, there lacksa general understanding of different models. In this paper, we propose aunified framework for link prediction that covers matrix factorization andrepresentative network embedding and graph neural network methods. Ourpreliminary methodological and empirical analyses further reveal several keydesign factors based on our unified framework. We believe our results coulddeepen our understanding and inspire novel designs for link prediction methods.</description>
      <author>example@mail.com (Haoxin Liu)</author>
      <guid isPermaLink="false">2410.21325v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ImageNet-RIB Benchmark: Large Pre-Training Datasets Don't Guarantee Robustness after Fine-Tuning</title>
      <link>http://arxiv.org/abs/2410.21582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型预训练模型在学习专业任务方面提供了有价值的基础，通过微调模型以适应特定任务。&lt;h4&gt;目的&lt;/h4&gt;在保持模型鲁棒性的同时，实现针对目标任务的专业化。&lt;h4&gt;方法&lt;/h4&gt;引入新的鲁棒性微调基准，ImageNet-RIB，包括一组相关但不同的专门任务，评估微调后模型对离散样本的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;持续学习方法EWC和LwF在微调后保持鲁棒性，但微调通常降低了模型在相关下游任务上的性能。预训练在大型丰富数据集上的模型初始鲁棒性较高，但在微调过程中表现出明显退化。预训练和下游数据集之间的距离可预测性能退化。&lt;h4&gt;结论&lt;/h4&gt;微调后模型的鲁棒性在预训练数据集最丰富和多样化时最差，表明以最强基础模型开始并不一定是专业任务性能的最佳方法。&lt;h4&gt;总结&lt;/h4&gt;该基准为开发更具韧性的微调策略和构建鲁棒的机器学习模型提供了关键见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Highly performant large-scale pre-trained models promise to also provide avaluable foundation for learning specialized tasks, by fine-tuning the model tothe desired task. By starting from a good general-purpose model, the goal is toachieve both specialization in the target task and maintain robustness. Toassess the robustness of models to out-of-distribution samples afterfine-tuning on downstream datasets, we introduce a new robust fine-tuningbenchmark, ImageNet-RIB (Robustness Inheritance Benchmark). The benchmarkconsists of a set of related but distinct specialized (downstream) tasks;pre-trained models are fine-tuned on one task in the set and their robustnessis assessed on the rest, iterating across all tasks for fine-tuning andassessment. We find that the continual learning methods, EWC and LwF maintainrobustness after fine-tuning though fine-tuning generally does reduceperformance on generalization to related downstream tasks across models. Notsurprisingly, models pre-trained on large and rich datasets exhibit higherinitial robustness across datasets and suffer more pronounced degradationduring fine-tuning. The distance between the pre-training and downstreamdatasets, measured by optimal transport, predicts this performance degradationon the pre-training dataset. However, counterintuitively, model robustnessafter fine-tuning on related downstream tasks is the worst when thepre-training dataset is the richest and the most diverse. This suggests thatstarting with the strongest foundation model is not necessarily the bestapproach for performance on specialist tasks. The benchmark thus offers keyinsights for developing more resilient fine-tuning strategies and buildingrobust machine learning models. https://jd730.github.io/projects/ImageNet-RIB</description>
      <author>example@mail.com (Jaedong Hwang, Brian Cheung, Zhang-Wei Hong, Akhilan Boopathy, Pulkit Agrawal, Ila Fiete)</author>
      <guid isPermaLink="false">2410.21582v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Relation-based Counterfactual Data Augmentation and Contrastive Learning for Robustifying Natural Language Inference Models</title>
      <link>http://arxiv.org/abs/2410.20710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted at INTERSPEECH 2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预训练语言模型在各种自然语言处理任务中表现良好，但往往依赖非因果特征和模式来决定结果。&lt;h4&gt;目的&lt;/h4&gt;提高自然语言推理任务中模型对反事实修订数据的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;采用基于标记和基于句子的增强方法生成反事实句子对，并应用对比学习帮助模型识别不同类别的句子对之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;在经过反事实修订的数据集和一般NLI数据集上的评估结果显示，所提方法能够提高NLI模型的性能和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习和数据增强，模型在自然语言推理任务中的表现得到了显著改善。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的方法有效提升了自然语言推理模型在面临反事实数据时的学习能力和稳定性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although pre-trained language models show good performance on various naturallanguage processing tasks, they often rely on non-causal features and patternsto determine the outcome. For natural language inference tasks, previousresults have shown that even a model trained on a large number of data fails toperform well on counterfactually revised data, indicating that the model is notrobustly learning the semantics of the classes. In this paper, we propose amethod in which we use token-based and sentence-based augmentation methods togenerate counterfactual sentence pairs that belong to each class, and applycontrastive learning to help the model learn the difference between sentencepairs of different classes with similar contexts. Evaluation results withcounterfactually-revised dataset and general NLI datasets show that theproposed method can improve the performance and robustness of the NLI model.</description>
      <author>example@mail.com (Heerin Yang, Sseung-won Hwang, Jungmin So)</author>
      <guid isPermaLink="false">2410.20710v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>UTSRMorph: A Unified Transformer and Superresolution Network for Unsupervised Medical Image Registration</title>
      <link>http://arxiv.org/abs/2410.20348v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13pages,10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;复杂的图像配准是医学图像分析中的关键问题，基于深度学习的方法比传统方法取得了更好的结果。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无监督图像配准方法，称为统一变换器和超分辨率网络（UTSRMorph），以增强特征表示学习和生成详细的位移场。&lt;h4&gt;方法&lt;/h4&gt;提出了融合注意力块，将基于卷积网络的通道注意力模块与多头自注意力模块相结合，并使用重叠窗口的交叉注意力方法，以获得丰富的配对图像相关信息。&lt;h4&gt;主要发现&lt;/h4&gt;UTSRMorph在3D脑部MR（OASIS, IXI）和MR-CT数据集上的性能优于最新的注册方法，定性和定量结果显示其相对更好的表现。&lt;h4&gt;结论&lt;/h4&gt;UTSRMorph有效克服了卷积网络和变换器在图像配准中的局限性，提供了更好的特征表示和位移场生成。&lt;h4&gt;代码和数据集&lt;/h4&gt;代码和数据集公开可用，链接为：https://github.com/Runshi-Zhang/UTSRMorph。&lt;h4&gt;总结&lt;/h4&gt;UTSRMorph通过结合卷积网络和变换器的优势，提出了一种新的无监督图像配准方法，显著提升了医学图像分析的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TMI.2024.3467919&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/runshi-zhang/utsrmorph&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complicated image registration is a key issue in medical image analysis, anddeep learning-based methods have achieved better results than traditionalmethods. The methods include ConvNet-based and Transformer-based methods.Although ConvNets can effectively utilize local information to reduceredundancy via small neighborhood convolution, the limited receptive fieldresults in the inability to capture global dependencies. Transformers canestablish long-distance dependencies via a self-attention mechanism; however,the intense calculation of the relationships among all tokens leads to highredundancy. We propose a novel unsupervised image registration method named theunified Transformer and superresolution (UTSRMorph) network, which can enhancefeature representation learning in the encoder and generate detaileddisplacement fields in the decoder to overcome these problems. We first proposea fusion attention block to integrate the advantages of ConvNets andTransformers, which inserts a ConvNet-based channel attention module into amultihead self-attention module. The overlapping attention block, a novelcross-attention method, uses overlapping windows to obtain abundantcorrelations with match information of a pair of images. Then, the blocks areflexibly stacked into a new powerful encoder. The decoder generation process ofa high-resolution deformation displacement field from low-resolution featuresis considered as a superresolution process. Specifically, the superresolutionmodule was employed to replace interpolation upsampling, which can overcomefeature degradation. UTSRMorph was compared to state-of-the-art registrationmethods in the 3D brain MR (OASIS, IXI) and MR-CT datasets. The qualitative andquantitative results indicate that UTSRMorph achieves relatively betterperformance. The code and datasets are publicly available athttps://github.com/Runshi-Zhang/UTSRMorph.</description>
      <author>example@mail.com (Runshi Zhang, Hao Mo, Junchen Wang, Bimeng Jie, Yang He, Nenghao Jin, Liang Zhu)</author>
      <guid isPermaLink="false">2410.20348v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DeCaf: A Causal Decoupling Framework for OOD Generalization on Node Classification</title>
      <link>http://arxiv.org/abs/2410.20295v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）容易受到分布变化的影响，这在关键领域中造成了脆弱性和安全问题。&lt;h4&gt;目的&lt;/h4&gt;迫切需要增强GNNs在分布外（OOD）测试数据上的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入了更现实的图数据生成模型，使用结构因果模型（SCMs），重新定义分布变化并确定其起源。提出了一个因果解耦框架DeCaf，独立学习无偏特征-标签和结构-标签映射。&lt;h4&gt;主要发现&lt;/h4&gt;通过详细的理论框架，展示了该方法如何有效减轻各种分布变化的影响。&lt;h4&gt;结论&lt;/h4&gt;在不同模式变化的真实和合成数据集上评估DeCaf，验证了其增强GNNs泛化能力的有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种新的方法来应对GNNs在分布变化中的挑战，推动了其在实际应用中的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) are susceptible to distribution shifts, creatingvulnerability and security issues in critical domains. There is a pressing needto enhance the generalizability of GNNs on out-of-distribution (OOD) test data.Existing methods that target learning an invariant (feature, structure)-labelmapping often depend on oversimplified assumptions about the data generationprocess, which do not adequately reflect the actual dynamics of distributionshifts in graphs. In this paper, we introduce a more realistic graph datageneration model using Structural Causal Models (SCMs), allowing us to redefinedistribution shifts by pinpointing their origins within the generation process.Building on this, we propose a casual decoupling framework, DeCaf, thatindependently learns unbiased feature-label and structure-label mappings. Weprovide a detailed theoretical framework that shows how our approach caneffectively mitigate the impact of various distribution shifts. We evaluateDeCaf across both real-world and synthetic datasets that demonstrate differentpatterns of shifts, confirming its efficacy in enhancing the generalizabilityof GNNs.</description>
      <author>example@mail.com (Xiaoxue Han, Huzefa Rangwala, Yue Ning)</author>
      <guid isPermaLink="false">2410.20295v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Review of Deep Learning Approaches for Non-Invasive Cognitive Impairment Detection</title>
      <link>http://arxiv.org/abs/2410.19898v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文回顾了深度学习在非侵入性认知障碍检测中的最新进展。&lt;h4&gt;目的&lt;/h4&gt;探讨非侵入性认知衰退的各种指标，包括语言、面部和运动能力。&lt;h4&gt;方法&lt;/h4&gt;分析相关数据集、特征提取技术和应用于该领域的深度学习架构。&lt;h4&gt;主要发现&lt;/h4&gt;基于语言和语音的方法通常具备最高的检测性能，结合声学和语言特征的方法优于单一模态的研究，面部分析方法在视觉模态上显示出潜力，但研究相对较少。&lt;h4&gt;结论&lt;/h4&gt;大多数研究集中于二分类问题，针对多分类或回归任务的研究较少。转移学习和预训练语言模型在语言分析中表现出色，但仍面临数据标准化、模型可解释性等挑战。&lt;h4&gt;未来研究方向&lt;/h4&gt;建议研究语言无关的语音分析方法、开发多模态诊断系统，并关注AI辅助医疗中的伦理问题。&lt;h4&gt;总结&lt;/h4&gt;通过总结当前趋势和识别关键障碍，本文旨在指导深度学习基础的认知障碍检测系统的发展，以改善早期诊断和患者结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This review paper explores recent advances in deep learning approaches fornon-invasive cognitive impairment detection. We examine various non-invasiveindicators of cognitive decline, including speech and language, facial, andmotoric mobility. The paper provides an overview of relevant datasets,feature-extracting techniques, and deep-learning architectures applied to thisdomain. We have analyzed the performance of different methods across modalitiesand observed that speech and language-based methods generally achieved thehighest detection performance. Studies combining acoustic and linguisticfeatures tended to outperform those using a single modality. Facial analysismethods showed promise for visual modalities but were less extensively studied.Most papers focused on binary classification (impaired vs. non-impaired), withfewer addressing multi-class or regression tasks. Transfer learning andpre-trained language models emerged as popular and effective techniques,especially for linguistic analysis. Despite significant progress, severalchallenges remain, including data standardization and accessibility, modelexplainability, longitudinal analysis limitations, and clinical adaptation.Lastly, we propose future research directions, such as investigatinglanguage-agnostic speech analysis methods, developing multi-modal diagnosticsystems, and addressing ethical considerations in AI-assisted healthcare. Bysynthesizing current trends and identifying key obstacles, this review aims toguide further development of deep learning-based cognitive impairment detectionsystems to improve early diagnosis and ultimately patient outcomes.</description>
      <author>example@mail.com (Muath Alsuhaibani, Ali Pourramezan Fard, Jian Sun, Farida Far Poor, Peter S. Pressman, Mohammad H. Mahoor)</author>
      <guid isPermaLink="false">2410.19898v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>AdaptGCD: Multi-Expert Adapter Tuning for Generalized Category Discovery</title>
      <link>http://arxiv.org/abs/2410.21705v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的半监督学习受限于封闭世界假设，而广义类别发现（GCD）认为无标签数据集中包含未出现在标签集中的新类别。&lt;h4&gt;目的&lt;/h4&gt;不仅对旧类别进行分类，还要在无标签数据中发现新类别。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的基于适配器调优的方法AdaptGCD，首次将适配器调优引入GCD任务，并设计了多专家适配器结构，以便将旧类和新类的数据分组处理。&lt;h4&gt;主要发现&lt;/h4&gt;在7个广泛使用的数据集上进行了大量实验，显著提高了性能，证明了所提方案的有效性。&lt;h4&gt;结论&lt;/h4&gt;AdaptGCD方法在GCD任务中实现了预训练模型的通用知识与任务适应性的良好平衡，对未来研究具有启示意义。&lt;h4&gt;总结&lt;/h4&gt;本研究为广义类别发现提供了新的视角和方法，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Different from the traditional semi-supervised learning paradigm that isconstrained by the close-world assumption, Generalized Category Discovery (GCD)presumes that the unlabeled dataset contains new categories not appearing inthe labeled set, and aims to not only classify old categories but also discovernew categories in the unlabeled data. Existing studies on GCD typically devoteto transferring the general knowledge from the self-supervised pretrained modelto the target GCD task via some fine-tuning strategies, such as partial tuningand prompt learning. Nevertheless, these fine-tuning methods fail to make asound balance between the generalization capacity of pretrained backbone andthe adaptability to the GCD task. To fill this gap, in this paper, we propose anovel adapter-tuning-based method named AdaptGCD, which is the first work tointroduce the adapter tuning into the GCD task and provides some key insightsexpected to enlighten future research. Furthermore, considering the discrepancyof supervision information between the old and new classes, a multi-expertadapter structure equipped with a route assignment constraint is elaboratelydevised, such that the data from old and new classes are separated intodifferent expert groups. Extensive experiments are conducted on 7 widely-useddatasets. The remarkable improvements in performance highlight theeffectiveness of our proposals.</description>
      <author>example@mail.com (Yuxun Qu, Yongqiang Tang, Chenyang Zhang, Wensheng Zhang)</author>
      <guid isPermaLink="false">2410.21705v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Positive History: Re-ranking with List-level Hybrid Feedback</title>
      <link>http://arxiv.org/abs/2410.20778v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;重排序作为推荐系统的最后阶段，旨在生成符合用户偏好的重新排序列表。以往的研究主要关注于项目级的正反馈，忽视了用户在整个列表上提供的正负反馈。&lt;h4&gt;目的&lt;/h4&gt;探索列表级混合反馈如何揭示用户的整体偏好及其在列表中的比较行为模式，从而改进重排序。&lt;h4&gt;方法&lt;/h4&gt;提出了名为RELIFE的重排序方法，采用三个模块：去耦兴趣挖掘器、序列偏好混合器和比较感知模式提取器，以捕捉用户的偏好和行为模式。&lt;h4&gt;主要发现&lt;/h4&gt;RELIFE在整合用户偏好和行为模式方面显著优于现有的重排序基线模型。&lt;h4&gt;结论&lt;/h4&gt;通过对候选列表和历史列表的行为模式进行对比学习，RELIFE有效提升了重排序的性能。&lt;h4&gt;总结&lt;/h4&gt;RELIFE方法通过利用列表级混合反馈，显著改善了推荐系统的重排序效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the last stage of recommender systems, re-ranking generates a re-orderedlist that aligns with the user's preference. However, previous works generallyfocus on item-level positive feedback as history (e.g., only clicked items) andignore that users provide positive or negative feedback on items in the entirelist. This list-level hybrid feedback can reveal users' holistic preferencesand reflect users' comparison behavior patterns manifesting within a list. Suchpatterns could predict user behaviors on candidate lists, thus aiding betterre-ranking. Despite appealing benefits, extracting and integrating preferencesand behavior patterns from list-level hybrid feedback into re-ranking multipleitems remains challenging. To this end, we propose Re-ranking with List-levelHybrid Feedback (dubbed RELIFE). It captures user's preferences and behaviorpatterns with three modules: a Disentangled Interest Miner to disentangle theuser's preferences into interests and disinterests, a Sequential PreferenceMixer to learn users' entangled preferences considering the context offeedback, and a Comparison-aware Pattern Extractor to capture user's behaviorpatterns within each list. Moreover, for better integration of patterns,contrastive learning is adopted to align the behavior patterns of candidate andhistorical lists. Extensive experiments show that RELIFE significantlyoutperforms SOTA re-ranking baselines.</description>
      <author>example@mail.com (Muyan Weng, Yunjia Xi, Weiwen Liu, Bo Chen, Jianghao Lin, Ruiming Tang, Weinan Zhang, Yong Yu)</author>
      <guid isPermaLink="false">2410.20778v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Idempotent Unsupervised Representation Learning for Skeleton-Based Action Recognition</title>
      <link>http://arxiv.org/abs/2410.20349v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成模型作为一种强大的生成技术，逐渐成为识别任务的重要工具。然而，现有的预训练生成方法在骨架动作识别中获得的特征包含与识别无关的冗余信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于骨架的幂等生成模型（IGM），用于无监督表示学习，以解决现有方法的不足。&lt;h4&gt;方法&lt;/h4&gt;首先理论上证明生成模型与最大熵编码之间的等价性，通过引入对比学习使生成模型的特征更加紧凑。同时，引入幂等性约束，在特征空间中形成更强的一致性正则化，只保留动作语义的关键信息。&lt;h4&gt;主要发现&lt;/h4&gt;在基准数据集NTU RGB+D和PKUMMD上的广泛实验表明，所提方法的有效性。在NTU 60x子数据集上，性能从84.6%提升到86.2%。&lt;h4&gt;结论&lt;/h4&gt;在零-shot适应场景中，模型在之前无法识别的情况下表现出显著的有效性，取得了良好的结果。&lt;h4&gt;总结&lt;/h4&gt;本项目的代码可在GitHub上找到，链接为：https://github.com/LanglandsLin/IGM。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative models, as a powerful technique for generation, also graduallybecome a critical tool for recognition tasks. However, in skeleton-based actionrecognition, the features obtained from existing pre-trained generative methodscontain redundant information unrelated to recognition, which contradicts thenature of the skeleton's spatially sparse and temporally consistent properties,leading to undesirable performance. To address this challenge, we make effortsto bridge the gap in theory and methodology and propose a novel skeleton-basedidempotent generative model (IGM) for unsupervised representation learning.More specifically, we first theoretically demonstrate the equivalence betweengenerative models and maximum entropy coding, which demonstrates a potentialroute that makes the features of generative models more compact by introducingcontrastive learning. To this end, we introduce the idempotency constraint toform a stronger consistency regularization in the feature space, to push thefeatures only to maintain the critical information of motion semantics for therecognition task. Our extensive experiments on benchmark datasets, NTU RGB+Dand PKUMMD, demonstrate the effectiveness of our proposed method. On the NTU 60xsub dataset, we observe a performance improvement from 84.6$\%$ to 86.2$\%$.Furthermore, in zero-shot adaptation scenarios, our model demonstratessignificant efficacy by achieving promising results in cases that werepreviously unrecognizable. Our project is available at\url{https://github.com/LanglandsLin/IGM}.</description>
      <author>example@mail.com (Lilang Lin, Lehong Wu, Jiahang Zhang, Jiaying Liu)</author>
      <guid isPermaLink="false">2410.20349v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>The Galaxy Zoo Catalogs for the Galaxy And Mass Assembly (GAMA) Survey</title>
      <link>http://arxiv.org/abs/2410.19985v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 22 figures, 8 tables, accepted for publication in PASA&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "Galaxy Zoo是一个在线项目，用于通过公众投票对额外星系成像调查的形态特征进行分类。",
    "目的": "比较在不同调查（DESI成像调查和部分KiDS调查）中进行的分类，以进行交叉验证。",
    "方法": "对比不同成像质量和深度下的分类结果，分析投票一致性。",
    "主要发现": "整体投票结果一致，但个别星系存在显著差异。DESI+\rev{{\sc zoobot}}分类中，'平滑'星系的投票比例较高，主要是由于成像深度的差异。",
    "结论": "DESI成像比KiDS更浅且分辨率略低，导致Galaxy Zoo图像未显示出盘面特征。与专家视觉分类进行对比后，KiDS基础的Galaxy Zoo投票结果一致性良好。经过红移校正后，DESI和KiDS的Galaxy Zoo分类在种群属性上也表现出良好一致性。",
    "总结": "zoobot的交叉验证增强了其补充Galaxy Zoo分类及跨调查转移学习的能力的信心。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Galaxy Zoo is an online project to classify morphological features inextra-galactic imaging surveys with public voting. In this paper, we comparethe classifications made for two different surveys, the Dark EnergySpectroscopic Instrument (DESI) imaging survey and a part of the Kilo-DegreeSurvey (KiDS), in the equatorial fields of the Galaxy And Mass Assembly (GAMA)survey. Our aim is to cross-validate and compare the classifications based ondifferent imaging quality and depth.  We find that generally the voting agrees globally but with substantialscatter i.e. substantial differences for individual galaxies. There is anotable higher voting fraction in favor of ``smooth'' galaxies in theDESI+\rev{{\sc zoobot}} classifications, most likely due to the differencebetween imaging depth. DESI imaging is shallower and slightly lower resolutionthan KiDS and the Galaxy Zoo images do not reveal details such as disk features\rev{and thus are missed in the {\sc zoobot} training sample}. \rev{We checkagainst expert visual classifications and find good agreement with KiDS-basedGalaxy Zoo voting.}  We reproduce the results from Porter-Temple+ (2022), on the dependence ofstellar mass, star-formation, and specific star-formation on the number ofspiral arms. This shows that once corrected for redshift, the DESI Galaxy Zooand KiDS Galaxy Zoo classifications agree well on population properties. Thezoobot cross-validation increases confidence in its ability to complimentGalaxy Zoo classifications and its ability for transfer learning acrosssurveys.</description>
      <author>example@mail.com (Benne W. Holwerda, Clayton Robertson, Kyle Cook, Kevin A. Pimbblet, Sarah Casura, Anne E. Sansom, Divya Patel, Trevor Butrum, David H. W. Glass, Lee Kelvin, Ivan K. Baldry, Roberto De Propris, Steven Bamford, Karen Masters, Maria Stone, Tim Hardin, Mike Walmsley, Jochen Liske, S M Rafee Adnan)</author>
      <guid isPermaLink="false">2410.19985v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Quality Analysis of the Coding Bitrate Tradeoff Between Geometry and Attributes for Colored Point Clouds</title>
      <link>http://arxiv.org/abs/2410.21613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云编码通常对几何信息和属性（如RGB颜色组件）分配相似的比特率。&lt;h4&gt;目的&lt;/h4&gt;研究几何和属性编码之间不同比特率权衡对点云质量的影响。&lt;h4&gt;方法&lt;/h4&gt;使用MPEG标准的几何点云压缩（G-PCC）编码五种不同特征和类型的点云，采用八叉树编码几何信息，使用区域自适应层次变换和预测提升变换编码属性。同时测试JPEG Pleno点云验证模型。&lt;h4&gt;主要发现&lt;/h4&gt;考虑了五种不同的属性/几何比特率权衡，结果显示属性编码的比特率分配较高时通常效果更好。&lt;h4&gt;结论&lt;/h4&gt;较高的属性编码比特率分配通常会带来稍微更好的重建结果。&lt;h4&gt;总结&lt;/h4&gt;该研究为点云编码提供了不同比特率权衡的质量评估，指出属性编码的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Typically, point cloud encoders allocate a similar bitrate for geometry andattributes (usually RGB color components) information coding. This paperreports a quality study considering different coding bitrate tradeoff betweengeometry and attributes. A set of five point clouds, representing differentcharacteristics and types of content was encoded with the MPEG standardGeometry Point Cloud Compression (G-PCC), using octree to encode geometryinformation, and both the Region Adaptive Hierarchical Transform and thePrediction Lifting transform for attributes. Furthermore, the JPEG Pleno PointCloud Verification Model was also tested. Five different attributes/geometrybitrate tradeoffs were considered, notably 70%/30%, 60%/40%, 50%/50%, 40%/60%,30%/70%. Three point cloud objective metrics were selected to assess thequality of the reconstructed point clouds, notably the PSNR YUV, the PointCloud Quality Metric, and GraphSIM. Furthermore, for each encoder, theBjonteegaard Deltas were computed for each tradeoff, using the 50%/50% tradeoffas a reference. The reported results indicate that using a higher bitrateallocation for attribute encoding usually yields slightly better results.</description>
      <author>example@mail.com (Joao Prazeres, Rafael Rodrigues, Manuela Pereira, Antonio M. G. Pinheiro)</author>
      <guid isPermaLink="false">2410.21613v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Improving In-Context Learning with Small Language Model Ensembles</title>
      <link>http://arxiv.org/abs/2410.21868v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024 Workshop on Adaptive Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在多种任务中表现出色，但在特定领域任务上的表现仍有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，提升ICL在特定领域任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;提出Ensemble SuperICL，通过利用多个微调的小型语言模型（SLMs）的专业知识来增强ICL。&lt;h4&gt;主要发现&lt;/h4&gt;Ensemble SuperICL在多个自然语言理解基准上达到了最先进的结果，并在医学领域的标注任务中表现优异。&lt;h4&gt;结论&lt;/h4&gt;Ensemble SuperICL为LLMs提供了一种成本低效高的领域专业化方法，适合实际应用。&lt;h4&gt;总结&lt;/h4&gt;本研究满足了对高效领域专业化方法的需求，为从业者提供了一种经济有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mehdimojarradi/Ensemble-SuperICL&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) have shown impressive capabilities acrossvarious tasks, but their performance on domain-specific tasks remains limited.While methods like retrieval augmented generation and fine-tuning can help toaddress this, they require significant resources. In-context learning (ICL) isa cheap and efficient alternative but cannot match the accuracies of advancedmethods. We present Ensemble SuperICL, a novel approach that enhances ICL byleveraging the expertise of multiple fine-tuned small language models (SLMs).Ensemble SuperICL achieves state of the art (SoTA) results on several naturallanguage understanding benchmarks. Additionally, we test it on a medical-domainlabelling task and showcase its practicality by using off-the-shelf SLMsfine-tuned on a general language task, achieving superior accuracy inlarge-scale data labelling compared to all baselines. Finally, we conduct anablation study and sensitivity analyses to elucidate the underlying mechanismof Ensemble SuperICL. Our research contributes to the growing demand forefficient domain specialisation methods in LLMs, offering a cheap and effectivemethod for practitioners.</description>
      <author>example@mail.com (M. Mehdi Mojarradi, Lingyi Yang, Robert McCraith, Adam Mahdi)</author>
      <guid isPermaLink="false">2410.21868v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fidelity-Imposed Displacement Editing for the Learn2Reg 2024 SHG-BF Challenge</title>
      <link>http://arxiv.org/abs/2410.20812v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;二次谐波生成(SHG)与明场(BF)显微镜的联合检查可以区分组织成分和胶原纤维，帮助分析人类乳腺癌和胰腺癌组织。&lt;h4&gt;目的&lt;/h4&gt;解决SHG和BF图像之间的大差异，以提高当前基于学习的注册模型在对齐SHG与BF图像时的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型的多模态注册框架，采用忠实性强加位移编辑，结合批量对比学习、特征预对齐和实例级优化。&lt;h4&gt;主要发现&lt;/h4&gt;在Learn2Reg COMULISglobe SHG-BF挑战赛中，实验结果验证了该方法的有效性，并在在线排行榜上获得第一名。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架有效解决了SHG和BF图像对齐的问题，显示出在多模态图像注册中的潜力。&lt;h4&gt;总结&lt;/h4&gt;通过创新的方法提高了二次谐波生成与明场显微镜图像的注册精度，推动了癌症组织分析的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Co-examination of second-harmonic generation (SHG) and bright-field (BF)microscopy enables the differentiation of tissue components and collagenfibers, aiding the analysis of human breast and pancreatic cancer tissues.However, large discrepancies between SHG and BF images pose challenges forcurrent learning-based registration models in aligning SHG to BF. In thispaper, we propose a novel multi-modal registration framework that employsfidelity-imposed displacement editing to address these challenges. Theframework integrates batch-wise contrastive learning, feature-basedpre-alignment, and instance-level optimization. Experimental results from theLearn2Reg COMULISglobe SHG-BF Challenge validate the effectiveness of ourmethod, securing the 1st place on the online leaderboard.</description>
      <author>example@mail.com (Jiacheng Wang, Xiang Chen, Renjiu Hu, Rongguang Wang, Min Liu, Yaonan Wang, Jiazheng Wang, Hao Li, Hang Zhang)</author>
      <guid isPermaLink="false">2410.20812v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PaPaGei: Open Foundation Models for Optical Physiological Signals</title>
      <link>http://arxiv.org/abs/2410.20542v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code and models:
  https://github.com/nokia-bell-labs/papagei-foundation-model&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;光电容积描记法（PPG）是监测生物信号和心血管健康最广泛使用的非侵入性技术，应用于临床和可穿戴设备的消费者健康。&lt;h4&gt;目的&lt;/h4&gt;提出PaPaGei，这是第一个针对PPG信号的开放基础模型，以解决现有模型缺乏通用性的问题。&lt;h4&gt;方法&lt;/h4&gt;PaPaGei在超过57,000小时的2000万个未标记PPG信号段上进行预训练，使用公开数据集，并在20个任务和10个多样化数据集上进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;PaPaGei在至少14个任务中相比其他竞争时间序列基础模型的分类和回归性能分别提高了6.3%和2.9%。&lt;h4&gt;结论&lt;/h4&gt;PaPaGei比其他基础模型或方法更有效，能够在不同肤色下保持稳健性，为未来模型的偏差评估建立了基准。&lt;h4&gt;应用&lt;/h4&gt;PaPaGei可以作为特征提取器和其他多模态模型的编码器，开辟了多模态健康监测的新机会。&lt;h4&gt;总结&lt;/h4&gt;PaPaGei模型展示了在PPG信号处理中的创新与优势，推动了生物信号监测技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nokia-bell-labs/papagei-foundation-model&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Photoplethysmography (PPG) is the most widely used non-invasive technique formonitoring biosignals and cardiovascular health, with applications in bothclinical settings and consumer health through wearable devices. Current machinelearning models trained on PPG signals are mostly task-specific and lackgeneralizability. Previous works often used single-device datasets, did notexplore out-of-domain generalization, or did not release their models,hindering reproducibility and further research. We introduce PaPaGei, the firstopen foundation model for PPG signals. PaPaGei is pre-trained on more than57,000 hours of 20 million unlabeled segments of PPG signals using publiclyavailable datasets exclusively. We evaluate against popular time-seriesfoundation models and other benchmarks on 20 tasks of 10 diverse datasetsspanning cardiovascular health, sleep disorders, pregnancy monitoring, andwellbeing assessment. Our architecture incorporates novel representationlearning approaches that leverage differences in PPG signal morphology acrossindividuals, enabling it to capture richer representations than traditionalcontrastive learning methods. Across 20 tasks, PaPaGei improves classificationand regression performance by an average of 6.3% and 2.9%, respectively,compared to other competitive time-series foundation models in at least 14tasks. PaPaGei is more data- and parameter-efficient than other foundationmodels or methods, as it outperforms 70x larger models. Beyond accuracy, wealso investigate robustness against different skin tones, establishing abenchmark for bias evaluations of future models. Notably, PaPaGei can be usedout of the box as both a feature extractor and an encoder for other multimodalmodels, opening up new opportunities for multimodal health monitoring</description>
      <author>example@mail.com (Arvind Pillai, Dimitris Spathis, Fahim Kawsar, Mohammad Malekzadeh)</author>
      <guid isPermaLink="false">2410.20542v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks on Discriminative Graphs of Words</title>
      <link>http://arxiv.org/abs/2410.20469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在复杂数据结构推断中的成功促使许多研究将其应用于文本分类任务。&lt;h4&gt;目的&lt;/h4&gt;探索一种新的判别图词图神经网络（DGoW-GNN）方法，用于文本分类。&lt;h4&gt;方法&lt;/h4&gt;构建仅包含词节点的图，不使用文档节点，根据标签将训练语料分成不相连的子图，边的权重由表示词的点互信息决定。将文本分类任务重新表述为游走分类任务，并提出结合GNN和序列模型的新模型。&lt;h4&gt;主要发现&lt;/h4&gt;在七个基准数据集上的评估中，DGoW-GNN的表现不及多个最先进的基线模型。&lt;h4&gt;结论&lt;/h4&gt;分析了性能差异的原因，并假设在何种条件下DGoW-GNN的表现可能改善。&lt;h4&gt;总结&lt;/h4&gt;DGoW-GNN提供了一种新的视角来处理文本分类，但仍需改进以提升其性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/abbahaddou/DGOW&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In light of the recent success of Graph Neural Networks (GNNs) and theirability to perform inference on complex data structures, many studies applyGNNs to the task of text classification. In most previous methods, aheterogeneous graph, containing both word and document nodes, is constructedusing the entire corpus and a GNN is used to classify document nodes. In thiswork, we explore a new Discriminative Graph of Words Graph Neural Network(DGoW-GNN) approach encapsulating both a novel discriminative graphconstruction and model to classify text. In our graph construction, containingonly word nodes and no document nodes, we split the training corpus intodisconnected subgraphs according to their labels and weight edges by thepointwise mutual information of the represented words. Our graph construction,for which we provide theoretical motivation, allows us to reformulate the taskof text classification as the task of walk classification. We also propose anew model for the graph-based classification of text, which combines a GNN anda sequence model. We evaluate our approach on seven benchmark datasets and findthat it is outperformed by several state-of-the-art baseline models. We analysereasons for this performance difference and hypothesise under which conditionsit is likely to change.</description>
      <author>example@mail.com (Yassine Abbahaddou, Johannes F. Lutzeyer, Michalis Vazirgiannis)</author>
      <guid isPermaLink="false">2410.20469v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models</title>
      <link>http://arxiv.org/abs/2410.20008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to EMNLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;微调预训练的大型语言模型（LLMs）已成为解决各种自然语言处理（NLP）任务的常用方法。&lt;h4&gt;目的&lt;/h4&gt;研究预训练LLMs中编码的任务特定信息及指令微调对其表示的影响。&lt;h4&gt;方法&lt;/h4&gt;使用矩阵分析工具，比较预训练和指令微调的LLMs在存储任务特定信息方面的差异。&lt;h4&gt;主要发现&lt;/h4&gt;部分任务已在预训练LLMs中编码，而另一些任务则从指令微调中获益显著。&lt;h4&gt;结论&lt;/h4&gt;确定了模型从高层次通用表示转向更任务导向表示的层次，这加深了对LLMs工作机制的理解，并有助于未来在高效迁移学习和多任务学习领域的研究。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了LLMs在不同任务中的表现差异及其潜在改进方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-tuning pre-trained large language models (LLMs) on a diverse array oftasks has become a common approach for building models that can solve variousnatural language processing (NLP) tasks. However, where and to what extentthese models retain task-specific knowledge remains largely unexplored. Thisstudy investigates the task-specific information encoded in pre-trained LLMsand the effects of instruction tuning on their representations across a diverseset of over 60 NLP tasks. We use a set of matrix analysis tools to examine thedifferences between the way pre-trained and instruction-tuned LLMs storetask-specific information. Our findings reveal that while some tasks arealready encoded within the pre-trained LLMs, others greatly benefit frominstruction tuning. Additionally, we pinpointed the layers in which the modeltransitions from high-level general representations to more task-orientedrepresentations. This finding extends our understanding of the governingmechanisms of LLMs and facilitates future research in the fields ofparameter-efficient transfer learning and multi-task learning.</description>
      <author>example@mail.com (Zheng Zhao, Yftah Ziser, Shay B. Cohen)</author>
      <guid isPermaLink="false">2410.20008v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Standardization Trends on Safety and Trustworthiness Technology for Advanced AI</title>
      <link>http://arxiv.org/abs/2410.22151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 2 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人工智能（AI）在过去十年迅速发展，特别是在语言理解、图像和视频识别、编程和科学推理等领域。&lt;h4&gt;目的&lt;/h4&gt;分析先进人工智能的安全性和可信性标准化的国际趋势，支持安全和可信的AI发展。&lt;h4&gt;方法&lt;/h4&gt;识别标准化的关键领域，提出未来的方向和策略，并讨论政策影响。&lt;h4&gt;主要发现&lt;/h4&gt;基于大型语言模型和基础模型的AI技术正在接近或超越人工通用智能，表现出在复杂问题解决和多领域任务中的优越性能。&lt;h4&gt;结论&lt;/h4&gt;尽管AI的进步可能变革科学、工业、医疗和教育等领域，但也引发了关于其安全性和可信性的担忧。&lt;h4&gt;风险&lt;/h4&gt;包括不受控性、伦理冲突、长期社会经济影响和安全保障等相关风险。&lt;h4&gt;标准化努力&lt;/h4&gt;正在制定国际公认的标准，以确保AI的安全性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;有效的标准化有助于提升国际竞争力，促进先进AI的安全和可信发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.22648/ETRI.2024.J.390511&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial Intelligence (AI) has rapidly evolved over the past decade and hasadvanced in areas such as language comprehension, image and video recognition,programming, and scientific reasoning. Recent AI technologies based on largelanguage models and foundation models are approaching or surpassing artificialgeneral intelligence. These systems demonstrate superior performance in complexproblem solving, natural language processing, and multi-domain tasks, and canpotentially transform fields such as science, industry, healthcare, andeducation. However, these advancements have raised concerns regarding thesafety and trustworthiness of advanced AI, including risks related touncontrollability, ethical conflicts, long-term socioeconomic impacts, andsafety assurance. Efforts are being expended to develop internationallyagreed-upon standards to ensure the safety and reliability of AI. This studyanalyzes international trends in safety and trustworthiness standardization foradvanced AI, identifies key areas for standardization, proposes futuredirections and strategies, and draws policy implications. The goal is tosupport the safe and trustworthy development of advanced AI and enhanceinternational competitiveness through effective standardization.</description>
      <author>example@mail.com (Jonghong Jeon)</author>
      <guid isPermaLink="false">2410.22151v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.20964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in NeurIPS 2024. Code is available at
  https://github.com/heyongxin233/DeTeCtive&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前检测AI生成文本的技术主要依赖手动特征提取和监督二分类方法，这些方法在性能上存在瓶颈，且通用性不佳。&lt;h4&gt;目的&lt;/h4&gt;重新审视AI生成文本检测任务，强调区分不同作者的写作风格，而不仅仅是将文本分类为人类写作或AI生成。&lt;h4&gt;方法&lt;/h4&gt;提出DeTeCtive，一个多任务辅助、多层次对比学习框架，以促进学习不同的写作风格，并结合密集信息检索管道进行AI生成文本检测。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验，证明该方法提升了各种文本编码器在多个基准测试中检测AI生成文本的能力，并在OOD零-shot评估中大幅超越现有方法。该方法还具备对OOD数据的训练无关增量适应（TFIA）能力，进一步增强了其在OOD检测场景中的有效性。&lt;h4&gt;结论&lt;/h4&gt;希望通过开源代码和模型，激发AI生成文本检测领域的新思路，确保大型语言模型的安全应用并增强合规性。&lt;h4&gt;总结&lt;/h4&gt;DeTeCtive框架在AI生成文本检测方面表现优异，为未来的研究提供了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current techniques for detecting AI-generated text are largely confined tomanual feature crafting and supervised binary classification paradigms. Thesemethodologies typically lead to performance bottlenecks and unsatisfactorygeneralizability. Consequently, these methods are often inapplicable forout-of-distribution (OOD) data and newly emerged large language models (LLMs).In this paper, we revisit the task of AI-generated text detection. We arguethat the key to accomplishing this task lies in distinguishing writing stylesof different authors, rather than simply classifying the text intohuman-written or AI-generated text. To this end, we propose DeTeCtive, amulti-task auxiliary, multi-level contrastive learning framework. DeTeCtive isdesigned to facilitate the learning of distinct writing styles, combined with adense information retrieval pipeline for AI-generated text detection. Ourmethod is compatible with a range of text encoders. Extensive experimentsdemonstrate that our method enhances the ability of various text encoders indetecting AI-generated text across multiple benchmarks and achievesstate-of-the-art results. Notably, in OOD zero-shot evaluation, our methodoutperforms existing approaches by a large margin. Moreover, we find our methodboasts a Training-Free Incremental Adaptation (TFIA) capability towards OODdata, further enhancing its efficacy in OOD detection scenarios. We willopen-source our code and models in hopes that our work will spark new thoughtsin the field of AI-generated text detection, ensuring safe application of LLMsand enhancing compliance. Our code is available athttps://github.com/heyongxin233/DeTeCtive.</description>
      <author>example@mail.com (Xun Guo, Shan Zhang, Yongxin He, Ting Zhang, Wanquan Feng, Haibin Huang, Chongyang Ma)</author>
      <guid isPermaLink="false">2410.20964v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DHPrep: Deep Hawkes Process based Dynamic Network Representation</title>
      <link>http://arxiv.org/abs/2410.20627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;网络表示旨在将顶点编码到低维空间，同时保留原始网络结构和属性。大多数现有方法集中在静态网络结构上，未考虑时间动态性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够捕捉动态网络时间动态的算法，特别用于预测动态网络行为。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于深度霍克斯过程的动态网络表示算法（DHPrep），结合结构信息和时间动态来学习顶点表示。&lt;h4&gt;主要发现&lt;/h4&gt;DHPrep算法在多项任务（包括链接预测和顶点推荐）中，表现优于现有的最先进基准方法。&lt;h4&gt;结论&lt;/h4&gt;DHPrep有效捕捉动态网络的时间动态，确保表示随时间平滑演变。&lt;h4&gt;总结&lt;/h4&gt;本研究通过实验验证了DHPrep在动态网络表示学习中的优势，强调了时间动态在网络表示中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Networks representation aims to encode vertices into a low-dimensional space,while preserving the original network structures and properties. Most existingmethods focus on static network structure without considering temporaldynamics. However, in real world, most networks (e.g., social and biologicalnetworks) are dynamic in nature and are constantly evolving over time. Suchtemporal dynamics are critical in representations learning, especially forpredicting dynamic networks behaviors. To this end, a Deep Hawkes Process basedDynamic Networks Representation algorithm (DHPrep) is proposed in this paper,which is capable of capturing temporal dynamics of dynamic networks.Specifically, DHPrep incorporates both structural information and temporaldynamics to learn vertices representations that can model the edge formationprocess for a vertex pair, where the structural information is used to capturethe historical impact from their neighborhood, and the temporal dynamicsutilize this historical information and apply Hawkes point process to model theedges formation process. Moreover, a temporal smoother is further imposed toensure the representations evolve smoothly over time. To evaluate theeffectiveness of DHPrep, extensive experiments are carried out using fourreal-world datasets. Experimental results reveal that our DHPrep algorithmoutperforms state-of-the-art baseline methods in various tasks including linkprediction and vertices recommendation.</description>
      <author>example@mail.com (Ruixuan Han, Hongxiang Li, Bin Xie)</author>
      <guid isPermaLink="false">2410.20627v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Cosmic-Scale Benchmark for Symmetry-Preserving Data Processing</title>
      <link>http://arxiv.org/abs/2410.20516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 3 figures; To appear at the NeurReps Workshop @ NeurIPS
  2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高效处理结构化点云数据并保留多尺度信息是各领域面临的关键挑战。&lt;h4&gt;目的&lt;/h4&gt;基准测试图神经网络在捕捉局部聚类环境和长距离关联能力方面的表现。&lt;h4&gt;方法&lt;/h4&gt;使用模拟星系位置和属性的数据集，评估$E(3)$-等变图神经网络的性能。&lt;h4&gt;主要发现&lt;/h4&gt;对称性强的宇宙数据中，$E(3)$-等变网络在下游性能和模拟效率上优于非等变网络及特定领域信息提取技术。&lt;h4&gt;结论&lt;/h4&gt;当前架构在捕捉长距离关联信息方面不如领域特定基线，未来需要优化架构以更好地提取长距离信息。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了图神经网络在处理对称性数据中的潜力，同时指出了改进提取长距离信息的必要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently processing structured point cloud data while preservingmultiscale information is a key challenge across domains, from graphics toatomistic modeling. Using a curated dataset of simulated galaxy positions andproperties, represented as point clouds, we benchmark the ability of graphneural networks to simultaneously capture local clustering environments andlong-range correlations. Given the homogeneous and isotropic nature of theUniverse, the data exhibits a high degree of symmetry. We therefore focus onevaluating the performance of Euclidean symmetry-preserving($E(3)$-equivariant) graph neural networks, showing that they can outperformnon-equivariant counterparts and domain-specific information extractiontechniques in downstream performance as well as simulation-efficiency. However,we find that current architectures fail to capture information from long-rangecorrelations as effectively as domain-specific baselines, motivating futurework on architectures better suited for extracting long-range information.</description>
      <author>example@mail.com (Julia Balla, Siddharth Mishra-Sharma, Carolina Cuesta-Lazaro, Tommi Jaakkola, Tess Smidt)</author>
      <guid isPermaLink="false">2410.20516v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DOFS: A Real-world 3D Deformable Object Dataset with Full Spatial Information for Dynamics Model Learning</title>
      <link>http://arxiv.org/abs/2410.21758v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 6 figures, 2024 CoRL Workshop on Learning Robot Fine and
  Dexterous Manipulation: Perception and Control&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一个名为DOFS的3D可变形物体（DOs）数据集，包含完整的空间信息。&lt;h4&gt;目的&lt;/h4&gt;利用新颖且低成本的数据收集平台，获取3D可变形物体的多视角信息。&lt;h4&gt;方法&lt;/h4&gt;使用透明操作平面，结合捏合策略和双指夹具进行主动操作，收集RGB-D图像、点云和3D变形网格等数据。&lt;h4&gt;主要发现&lt;/h4&gt;数据集中包含多视角的RGB-D图像、注册良好的点云、3D占用信息及其语义。&lt;h4&gt;结论&lt;/h4&gt;训练了一个神经网络，以低分辨率的3D占用和动作作为输入，建模弹塑性物体的动态特性。&lt;h4&gt;未来工作&lt;/h4&gt;数据集及数据收集系统的所有CAD将很快在我们的网站上发布。&lt;h4&gt;总结&lt;/h4&gt;DOFS数据集为研究3D可变形物体的动态提供了重要的基础数据和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work proposes DOFS, a pilot dataset of 3D deformable objects (DOs)(e.g., elasto-plastic objects) with full spatial information (i.e., top, side,and bottom information) using a novel and low-cost data collection platformwith a transparent operating plane. The dataset consists of active manipulationaction, multi-view RGB-D images, well-registered point clouds, 3D deformedmesh, and 3D occupancy with semantics, using a pinching strategy with atwo-parallel-finger gripper. In addition, we trained a neural network with thedown-sampled 3D occupancy and action as input to model the dynamics of anelasto-plastic object. Our dataset and all CADs of the data collection systemwill be released soon on our website.</description>
      <author>example@mail.com (Zhen Zhang, Xiangyu Chu, Yunxi Tang, K. W. Samuel Au)</author>
      <guid isPermaLink="false">2410.21758v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Towards Unifying Understanding and Generation in the Era of Vision Foundation Models: A Survey from the Autoregression Perspective</title>
      <link>http://arxiv.org/abs/2410.22217v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 1 table, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自回归在大型语言模型中展现了良好的可扩展性，将所有语言任务统一为下一个标记预测的范式。&lt;h4&gt;目的&lt;/h4&gt;探讨将自回归模型的成功扩展到视觉基础模型的可能性。&lt;h4&gt;方法&lt;/h4&gt;回顾近期的进展，分析现有视觉基础模型的局限性，并提出自回归的正式定义及其优势。&lt;h4&gt;主要发现&lt;/h4&gt;展示了下一代视觉基础模型的趋势，即将理解和生成统一于视觉任务中，并对自回归视觉基础模型进行分类。&lt;h4&gt;结论&lt;/h4&gt;这是首次全面总结自回归视觉基础模型在理解与生成统一趋势下的研究。&lt;h4&gt;挑战&lt;/h4&gt;讨论了多个有前景的研究挑战和方向。&lt;h4&gt;资源&lt;/h4&gt;提供了相关资源链接，供进一步研究使用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autoregression in large language models (LLMs) has shown impressivescalability by unifying all language tasks into the next token predictionparadigm. Recently, there is a growing interest in extending this success tovision foundation models. In this survey, we review the recent advances anddiscuss future directions for autoregressive vision foundation models. First,we present the trend for next generation of vision foundation models, i.e.,unifying both understanding and generation in vision tasks. We then analyze thelimitations of existing vision foundation models, and present a formaldefinition of autoregression with its advantages. Later, we categorizeautoregressive vision foundation models from their vision tokenizers andautoregression backbones. Finally, we discuss several promising researchchallenges and directions. To the best of our knowledge, this is the firstsurvey to comprehensively summarize autoregressive vision foundation modelsunder the trend of unifying understanding and generation. A collection ofrelated resources is available at https://github.com/EmmaSRH/ARVFM.</description>
      <author>example@mail.com (Shenghao Xie, Wenqiang Zu, Mingyang Zhao, Duo Su, Shilong Liu, Ruohua Shi, Guoqi Li, Shanghang Zhang, Lei Ma)</author>
      <guid isPermaLink="false">2410.22217v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Sensor2Text: Enabling Natural Language Interactions for Daily Activity Tracking Using Wearable Sensors</title>
      <link>http://arxiv.org/abs/2410.20034v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉问答技术可以根据图像和自然语言问题生成文本响应，已在日常活动跟踪和医疗监测中取得显著进展，尤其对老年患者和记忆障碍者至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出Sensor2Text模型，以利用可穿戴传感器追踪日常活动并进行对话。&lt;h4&gt;方法&lt;/h4&gt;通过转移学习和师生网络克服可穿戴传感器数据的信息密度低、单一传感器识别活动的不足，以及模型在问答和互动对话中的能力限制，设计了一个编码-解码神经网络模型来联合处理语言和传感器数据。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够识别人体活动，并利用不同的可穿戴传感器进行问答对话，在字幕生成和对话任务上表现与现有视觉语言模型相当或更好。&lt;h4&gt;结论&lt;/h4&gt;这是首个能够就可穿戴传感器数据进行对话的模型，提供了一种创新的方法来跟踪日常活动，解决了当前基于视觉解决方案的隐私和视野限制问题。&lt;h4&gt;总结&lt;/h4&gt;Sensor2Text模型为日常活动监测提供了一种新颖的解决方案，兼顾隐私和信息获取的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Question-Answering, a technology that generates textual responses froman image and natural language question, has progressed significantly. Notably,it can aid in tracking and inquiring about daily activities, crucial inhealthcare monitoring, especially for elderly patients or those with memorydisabilities. However, video poses privacy concerns and has a limited field ofview. This paper presents Sensor2Text, a model proficient in tracking dailyactivities and engaging in conversations using wearable sensors. The approachoutlined here tackles several challenges, including low information density inwearable sensor data, insufficiency of single wearable sensors in humanactivities recognition, and model's limited capacity for Question-Answering andinteractive conversations. To resolve these obstacles, transfer learning andstudent-teacher networks are utilized to leverage knowledge fromvisual-language models. Additionally, an encoder-decoder neural network modelis devised to jointly process language and sensor data for conversationalpurposes. Furthermore, Large Language Models are also utilized to enableinteractive capabilities. The model showcases the ability to identify humanactivities and engage in Q\&amp;A dialogues using various wearable sensormodalities. It performs comparably to or better than existing visual-languagemodels in both captioning and conversational tasks. To our knowledge, thisrepresents the first model capable of conversing about wearable sensor data,offering an innovative approach to daily activity tracking that addressesprivacy and field-of-view limitations associated with current vision-basedsolutions.</description>
      <author>example@mail.com (Wenqiang Chen, Jiaxuan Cheng, Leyao Wang, Wei Zhao, Wojciech Matusik)</author>
      <guid isPermaLink="false">2410.20034v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>BEVPose: Unveiling Scene Semantics through Pose-Guided Multi-Modal BEV Alignment</title>
      <link>http://arxiv.org/abs/2410.20969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the IEEE/RSJ International Conference on
  Intelligent Robots and Systems (IROS), 2024. Project page:
  https://m80hz.github.io/bevpose/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在自动驾驶和移动机器人领域，鸟瞰视图（BEV）表示方法发生了显著变化，主要使用变换器和融合来自不同视觉传感器（如激光雷达和相机）的测量数据。&lt;h4&gt;目的&lt;/h4&gt;提出BEVPose框架，集成来自相机和激光雷达的数据的BEV表示，减少对大量标注数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;通过利用传感器姿态作为指导信号，对多模态传感器输入进行对齐和融合，以学习捕捉环境几何和语义特征的潜在BEV嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;预训练方法在BEV地图分割任务中表现出色，超越了完全监督的最新方法，仅需极少量标注数据。&lt;h4&gt;结论&lt;/h4&gt;该研究不仅解决了BEV表示学习中数据效率的问题，还拓宽了这些技术在各种领域（包括越野和室内环境）的潜力。&lt;h4&gt;总结&lt;/h4&gt;BEVPose框架通过有效利用传感器姿态信息，在实现高效学习的同时，降低了对标注数据的需求，展示了在多种环境中应用的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of autonomous driving and mobile robotics, there has been asignificant shift in the methods used to create Bird's Eye View (BEV)representations. This shift is characterised by using transformers and learningto fuse measurements from disparate vision sensors, mainly lidar and cameras,into a 2D planar ground-based representation. However, these learning-basedmethods for creating such maps often rely heavily on extensive annotated data,presenting notable challenges, particularly in diverse or non-urbanenvironments where large-scale datasets are scarce. In this work, we presentBEVPose, a framework that integrates BEV representations from camera and lidardata, using sensor pose as a guiding supervisory signal. This method notablyreduces the dependence on costly annotated data. By leveraging poseinformation, we align and fuse multi-modal sensory inputs, facilitating thelearning of latent BEV embeddings that capture both geometric and semanticaspects of the environment. Our pretraining approach demonstrates promisingperformance in BEV map segmentation tasks, outperforming fully-supervisedstate-of-the-art methods, while necessitating only a minimal amount ofannotated data. This development not only confronts the challenge of dataefficiency in BEV representation learning but also broadens the potential forsuch techniques in a variety of domains, including off-road and indoorenvironments.</description>
      <author>example@mail.com (Mehdi Hosseinzadeh, Ian Reid)</author>
      <guid isPermaLink="false">2410.20969v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SEG:Seeds-Enhanced Iterative Refinement Graph Neural Network for Entity Alignment</title>
      <link>http://arxiv.org/abs/2410.20733v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;实体对齐对于合并知识图谱至关重要，因为它匹配具有相同语义的实体。&lt;h4&gt;目的&lt;/h4&gt;解决由于多样化数据源导致的非同构邻域结构所带来的对齐困难，特别是对于不常见和稀疏连接的实体。&lt;h4&gt;方法&lt;/h4&gt;提出了一种软标签传播框架，整合多源数据和迭代种子增强，处理大规模数据集的可扩展性挑战。&lt;h4&gt;主要发现&lt;/h4&gt;该框架使用种子进行锚定，选择最佳关系对，创建富含邻域特征和语义关系数据的软标签。&lt;h4&gt;结论&lt;/h4&gt;实现了双向加权联合损失函数，缩小正样本之间的距离，并差异化处理负样本，考虑非同构邻域结构。&lt;h4&gt;总结&lt;/h4&gt;我们的方法在多个数据集上优于现有的半监督方法，显著提高了实体对齐的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Entity alignment is crucial for merging knowledge across knowledge graphs, asit matches entities with identical semantics. The standard method matches theseentities based on their embedding similarities using semi-supervised learning.However, diverse data sources lead to non-isomorphic neighborhood structuresfor aligned entities, complicating alignment, especially for less common andsparsely connected entities. This paper presents a soft label propagationframework that integrates multi-source data and iterative seed enhancement,addressing scalability challenges in handling extensive datasets where scalecomputing excels. The framework uses seeds for anchoring and selects optimalrelationship pairs to create soft labels rich in neighborhood features andsemantic relationship data. A bidirectional weighted joint loss function isimplemented, which reduces the distance between positive samples anddifferentially processes negative samples, taking into account thenon-isomorphic neighborhood structures. Our method outperforms existingsemi-supervised approaches, as evidenced by superior results on multipledatasets, significantly improving the quality of entity alignment.</description>
      <author>example@mail.com (Wei Ai, Yinghui Gao, Jianbin Li, Jiayi Du, Tao Meng, Yuntao Shou, Keqin Li)</author>
      <guid isPermaLink="false">2410.20733v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Detection-Guided Deep Learning-Based Model with Spatial Regularization for Lung Nodule Segmentation</title>
      <link>http://arxiv.org/abs/2410.20154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;肺癌是全球癌症诊断的主要原因，也是癌症相关死亡的首要原因。早期检测肺结节对改善患者预后至关重要。&lt;h4&gt;目的&lt;/h4&gt;提高肺结节的分割精度，以帮助医生区分恶性和良性病变。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新型模型，利用深度学习框架将分割和分类过程整合，采用特征组合块以促进信息共享，并结合空间正则化技术提升精度。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的模型在捕捉目标结节的准确性上优于其他常用模型，通过迁移学习进一步提升性能，敏感性得分为0.885，Dice得分为0.814。&lt;h4&gt;结论&lt;/h4&gt;新模型在CT图像中对肺结节的分割性能显著提升，为肺癌早期诊断提供了有效工具。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了深度学习在医疗影像分析中的潜力，尤其是在肺癌的早期检测和治疗中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lung cancer ranks as one of the leading causes of cancer diagnosis and is theforemost cause of cancer-related mortality worldwide. The early detection oflung nodules plays a pivotal role in improving outcomes for patients, as itenables timely and effective treatment interventions. The segmentation of lungnodules plays a critical role in aiding physicians in distinguishing betweenmalignant and benign lesions. However, this task remains challenging due to thesubstantial variation in the shapes and sizes of lung nodules, and theirfrequent proximity to lung tissues, which complicates clear delineation. Inthis study, we introduce a novel model for segmenting lung nodules in computedtomography (CT) images, leveraging a deep learning framework that integratessegmentation and classification processes. This model is distinguished by itsuse of feature combination blocks, which facilitate the sharing of informationbetween the segmentation and classification components. Additionally, we employthe classification outcomes as priors to refine the size estimation of thepredicted nodules, integrating these with a spatial regularization technique toenhance precision. Furthermore, recognizing the challenges posed by limitedtraining datasets, we have developed an optimal transfer learning strategy thatfreezes certain layers to further improve performance. The results show thatour proposed model can capture the target nodules more accurately compared toother commonly used models. By applying transfer learning, the performance canbe further improved, achieving a sensitivity score of 0.885 and a Dice score of0.814.</description>
      <author>example@mail.com (Jiasen Zhang, Mingrui Yang, Weihong Guo, Brian A. Xavier, Michael Bolen, Xiaojuan Li)</author>
      <guid isPermaLink="false">2410.20154v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Disentangled and Self-Explainable Node Representation Learning</title>
      <link>http://arxiv.org/abs/2410.21043v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;节点表示或嵌入是捕捉节点属性的低维向量，通常通过无监督结构相似性目标或监督任务进行学习，但无监督节点嵌入的可解释性研究较少。&lt;h4&gt;目的&lt;/h4&gt;提出DiSeNE框架，生成自解释的节点嵌入，填补无监督节点嵌入可解释性研究的空白。&lt;h4&gt;方法&lt;/h4&gt;采用解耦表示学习，生成维度可解释的嵌入，每个维度与图的不同拓扑结构对齐，同时优化可解释性和解耦性的新目标函数。&lt;h4&gt;主要发现&lt;/h4&gt;通过多个基准数据集的广泛实验，验证了所提出方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;DiSeNE框架有效地实现了自解释的节点嵌入，为无监督学习提供了新的视角和方法。&lt;h4&gt;总结&lt;/h4&gt;该研究推动了节点嵌入的可解释性研究，提出了新的评估指标，丰富了图模型的理解和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Node representations, or embeddings, are low-dimensional vectors that capturenode properties, typically learned through unsupervised structural similarityobjectives or supervised tasks. While recent efforts have focused on explaininggraph model decisions, the interpretability of unsupervised node embeddingsremains underexplored. To bridge this gap, we introduce DiSeNE (Disentangledand Self-Explainable Node Embedding), a framework that generatesself-explainable embeddings in an unsupervised manner. Our method employsdisentangled representation learning to produce dimension-wise interpretableembeddings, where each dimension is aligned with distinct topological structureof the graph. We formalize novel desiderata for disentangled and interpretableembeddings, which drive our new objective functions, optimizing simultaneouslyfor both interpretability and disentanglement. Additionally, we propose severalnew metrics to evaluate representation quality and human interpretability.Extensive experiments across multiple benchmark datasets demonstrate theeffectiveness of our approach.</description>
      <author>example@mail.com (Simone Piaggesi, André Panisson, Megha Khosla)</author>
      <guid isPermaLink="false">2410.21043v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Review of Graph-Powered Data Quality Applications for IoT Monitoring Sensor Networks</title>
      <link>http://arxiv.org/abs/2410.21006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper submitted to Journal of Network and Computer Applications&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物联网技术的发展促使监测网络在智能城市、环境监测和精密农业等多种应用中得到广泛采用。&lt;h4&gt;目的&lt;/h4&gt;研究基于图的技术，以提高传感器网络数据的质量，这对于决策过程、数字双胞胎等应用至关重要。&lt;h4&gt;方法&lt;/h4&gt;强调机器学习和信号处理技术在图上的应用，利用图拓扑结构的优势。&lt;h4&gt;主要发现&lt;/h4&gt;图信号处理（GSP）和图神经网络（GNN）等技术被广泛应用于数据质量增强任务。&lt;h4&gt;结论&lt;/h4&gt;重点讨论监测传感器网络中数据质量控制的图模型，并探讨缺失值填补、异常值检测和虚拟传感等技术细节。&lt;h4&gt;未来趋势&lt;/h4&gt;识别未来的趋势和挑战，如数字双胞胎的图模型或模型的可迁移性和泛化能力。&lt;h4&gt;总结&lt;/h4&gt;基于图的解决方案在传感器网络的数据质量任务中具有重要应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of Internet of Things (IoT) technologies has led to thewidespread adoption of monitoring networks for a wide variety of applications,such as smart cities, environmental monitoring, and precision agriculture. Amajor research focus in recent years has been the development of graph-basedtechniques to improve the quality of data from sensor networks, a key aspectfor the use of sensed data in decision-making processes, digital twins, andother applications. Emphasis has been placed on the development of machinelearning and signal processing techniques over graphs, taking advantage of thebenefits provided by the use of structured data through a graph topology. Manytechnologies such as the graph signal processing (GSP) or the successful graphneural networks (GNNs) have been used for data quality enhancement tasks. Inthis survey, we focus on graph-based models for data quality control inmonitoring sensor networks. Furthermore, we delve into the technical detailsthat are commonly leveraged for providing powerful graph-based solutions fordata quality tasks in sensor networks, including missing value imputation,outlier detection, or virtual sensing. To conclude, we have identified futuretrends and challenges such as graph-based models for digital twins or modeltransferability and generalization.</description>
      <author>example@mail.com (Pau Ferrer-Cid, Jose M. Barcelo-Ordinas, Jorge Garcia-Vidal)</author>
      <guid isPermaLink="false">2410.21006v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Uncovering Capabilities of Model Pruning in Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.20356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MM' 24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图对比学习在无真实标签的情况下成功地预训练了图神经网络，但现有方法依赖于随机生成的增强视图，可能导致语义改变。&lt;h4&gt;目的&lt;/h4&gt;通过不同模型版本的对比，而非依赖增强视图，重新构建图对比学习问题。&lt;h4&gt;方法&lt;/h4&gt;理论上揭示模型剪枝在对比学习中的优势；实际中使用原始图作为输入，动态生成一个经过剪枝的图编码器与原始编码器对比。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方法在处理困难负样本时，通过局部对比损失提高了节点嵌入的完整性。&lt;h4&gt;结论&lt;/h4&gt;在多种图分类基准上进行广泛验证，该方法在无监督和迁移学习中相较于最先进的工作表现更佳。&lt;h4&gt;总结&lt;/h4&gt;该研究通过模型剪枝改进了图对比学习，增强了性能和一般化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph contrastive learning has achieved great success in pre-training graphneural networks without ground-truth labels. Leading graph contrastive learningfollows the classical scheme of contrastive learning, forcing model to identifythe essential information from augmented views. However, general augmentedviews are produced via random corruption or learning, which inevitably leads tosemantics alteration. Although domain knowledge guided augmentations alleviatethis issue, the generated views are domain specific and undermine thegeneralization. In this work, motivated by the firm representation ability ofsparse model from pruning, we reformulate the problem of graph contrastivelearning via contrasting different model versions rather than augmented views.We first theoretically reveal the superiority of model pruning in contrast todata augmentations. In practice, we take original graph as input anddynamically generate a perturbed graph encoder to contrast with the originalencoder by pruning its transformation weights. Furthermore, considering theintegrity of node embedding in our method, we are capable of developing a localcontrastive loss to tackle the hard negative samples that disturb the modeltraining. We extensively validate our method on various benchmarks regardinggraph classification via unsupervised and transfer learning. Compared to thestate-of-the-art (SOTA) works, better performance can always be obtained by theproposed method.</description>
      <author>example@mail.com (Wu Junran, Chen Xueyuan, Li Shangzhe)</author>
      <guid isPermaLink="false">2410.20356v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Quantum Circuits, Feature Maps, and Expanded Pseudo-Entropy: A Categorical Theoretic Analysis of Encoding Real-World Data into a Quantum Computer</title>
      <link>http://arxiv.org/abs/2410.22084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，量子机器学习的发展促进了将机器学习转化为量子电路的研究，尤其关注如何在编码真实世界数据时不丢失信息和避免噪声。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的数值方法，以确定编码方案在将真实世界数据映射到量子电路中的有效性。&lt;h4&gt;方法&lt;/h4&gt;通过计算点云数据中每个数据点的香农熵，并在嵌入流形上进行采样，计算应用于各自量子算子的扩展伪熵概念，而非密度算符。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的伪熵方法能够推广现有的表达性和表达能力方法，并且可以推广对称量子特征图。&lt;h4&gt;结论&lt;/h4&gt;该方法为理解量子特征图之间的联系提供了合理依据，但仍需更深入的数学分析来支持这些论点。&lt;h4&gt;总结&lt;/h4&gt;新方法为量子机器学习中的数据编码问题提供了新的视角，具有潜在的推广能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This manuscripts proposes a new and novel numerical method to the determinethe efficacy of an encoding scheme to map real-world data into a quantumcircuit. The method calculates the Shannon entropy of each of the data pointsfrom a point-cloud, hence, samples from an embedded manifold, and calculatesthe expanded concept of pseudo-entropy applied to each respective quantumoperator that comes from a given quantum feature map, and not the densityoperator. In the recent decade, there has been a continuous advancement oftranslating machine learning into a quantum circuit with many promisingresults. For quantum machine learning, a major underlying question is how toencode real-world data into a quantum circuit without losing information andadding noise. A few notable methods derived are expressibility, where thedistribution of the output of states from the circuit are compared against theHaar probability measure with information theoretic techniques, andexpressivity, a method that maps the expectation of a quantum circuit to thespace of complex functions via a partial Fourier series, noting that moreintricate the function the more expressive, and using the symmetry embeddedwithin the data to derive a quantum feature map. The proposed pseudo-entropymethod is discussed to and empirically shown to generalize these methods.Furthermore, this method is argued to also generalize symmetric quantum featuremaps. The discussions and arguments are a reasonable basis for understandingthe connections but require deeper mathematical analysis.</description>
      <author>example@mail.com (Andrew Vlasic)</author>
      <guid isPermaLink="false">2410.22084v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Fourier Head: Helping Large Language Models Learn Complex Probability Distributions</title>
      <link>http://arxiv.org/abs/2410.22269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page and code are at https://nategillman.com/fourier-head&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型的质量提升引发了对其在非语言标记建模中的应用兴趣，例如将决策转换器用于建模离散动作空间。&lt;h4&gt;目的&lt;/h4&gt;探讨在非语言领域中，softmax是否能捕捉标记的连续结构和复杂分布，以提高标记生成质量。&lt;h4&gt;方法&lt;/h4&gt;引入基于傅里叶级数构建的神经网络层，可替代任意线性层，以实现更连续的输出结构，并在合成数据集和实际决策、时间序列预测任务中进行广泛分析。&lt;h4&gt;主要发现&lt;/h4&gt;该傅里叶头在具有自然连续结构的数据分布场景下表现出色，提升了决策转换器在Atari Seaquest游戏中的回报46%，并在20个未见基准上提高了时间序列预测模型的性能3.5%。&lt;h4&gt;结论&lt;/h4&gt;傅里叶头能够更好地学习数据中的信号，同时忽略高频噪声，支持其在复杂数据分布场景中的有效性。&lt;h4&gt;总结&lt;/h4&gt;引入傅里叶级数的神经网络层提升了非语言标记建模的效果，特别是在决策和时间序列任务中表现显著。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the quality of large language models has improved, there has beenincreased interest in using them to model non-linguistic tokens. For example,the Decision Transformer recasts agentic decision making as a sequence modelingproblem, using a decoder-only LLM to model the distribution over the discreteaction space for an Atari agent. However, when adapting LLMs to non-linguisticdomains, it remains unclear if softmax over discrete bins captures thecontinuous structure of the tokens and the potentially complex distributionsneeded for high quality token generation. We introduce a neural network layer,constructed using Fourier series, which we can easily substitute for any linearlayer if we want the outputs to have a more continuous structure. We performextensive analysis on synthetic datasets, as well as on large-scale decisionmaking and time series forecasting tasks. We also provide theoretical evidencethat this layer can better learn signal from data while ignoring high-frequencynoise. All of our results support the effectiveness of our proposed Fourierhead in scenarios where the underlying data distribution has a naturalcontinuous structure. For example, the Fourier head improves a DecisionTransformer agent's returns by 46% on the Atari Seaquest game, and increases astate-of-the-art times series foundation model's forecasting performance by3.5% across 20 benchmarks unseen during training.</description>
      <author>example@mail.com (Nate Gillman, Daksh Aggarwal, Michael Freeman, Saurabh Singh, Chen Sun)</author>
      <guid isPermaLink="false">2410.22269v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SandboxAQ's submission to MRL 2024 Shared Task on Multi-lingual Multi-task Information Retrieval</title>
      <link>http://arxiv.org/abs/2410.21501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MRL 2024 Shared Task on Multi-lingual Multi-task Information
  Retrieval; 4th Multilingual Representation Learning (MRL) Workshop; EMNLP
  2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文探讨了五种不同语言中的问答（QA）和命名实体识别（NER）问题。&lt;h4&gt;目的&lt;/h4&gt;评估五种大型语言模型在不同提示方法下的表现。&lt;h4&gt;方法&lt;/h4&gt;使用零-shot、链式推理和翻译技术对模型进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;部分模型在某些任务上表现优于其他模型，但其有效性在任务和语言间差异显著。&lt;h4&gt;结论&lt;/h4&gt;高级提示技术通常提高了QA的表现，但对NER的效果则不一而足；不同任务之间的语言难度模式存在差异。&lt;h4&gt;建议&lt;/h4&gt;强调在多语言自然语言处理中的任务特定方法的必要性，现有模型可能在不同任务中发展出不同的语言能力。&lt;h4&gt;总结&lt;/h4&gt;研究结果揭示了多语言NLP中任务特定方法的重要性，并指出模型在不同任务上可能具备不同的语言能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the problems of Question Answering (QA) and Named EntityRecognition (NER) in five diverse languages. We tested five Large LanguageModels with various prompting methods, including zero-shot, chain-of-thoughtreasoning, and translation techniques. Our results show that while some modelsconsistently outperform others, their effectiveness varies significantly acrosstasks and languages. We saw that advanced prompting techniques generallyimproved QA performance but had mixed results for NER; and we observed thatlanguage difficulty patterns differed between tasks. Our findings highlight theneed for task-specific approaches in multilingual NLP and suggest that currentmodels may develop different linguistic competencies for different tasks.</description>
      <author>example@mail.com (Isidora Chara Tourni, Sayontan Ghosh, Brenda Miao, Constantijn van der Poel)</author>
      <guid isPermaLink="false">2410.21501v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Graph Based Traffic Analysis and Delay Prediction</title>
      <link>http://arxiv.org/abs/2410.21028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;马耳他是欧盟人口最密集的国家，人口密度约为每平方公里1672人。该地区车辆增长迅速，6个月内增加约11,000辆。&lt;h4&gt;目的&lt;/h4&gt;研究交通拥堵问题，并提供准确全面的数据收集方法以应对马耳他波动的交通状况。&lt;h4&gt;方法&lt;/h4&gt;构建了一个名为MalTra的全面交通数据集，包含公众在200天内的真实出行数据，并采用ARIMA模型和两种图神经网络（STGCN和DCRNN）进行分析和比较。&lt;h4&gt;主要发现&lt;/h4&gt;DCRNN模型的表现优于STGCN，MAE为3.98（STGCN为6.65），RMSE为7.78（STGCN为12.73）。&lt;h4&gt;结论&lt;/h4&gt;DCRNN模型在交通数据分析中更为有效，能够更好地应对马耳他交通拥堵问题。&lt;h4&gt;总结&lt;/h4&gt;本研究通过构建全面的数据集和有效的分析模型，为马耳他的交通管理提供了重要的数据支持和理论依据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research is focused on traffic congestion in the small island of Maltawhich is the most densely populated country in the EU with about 1,672inhabitants per square kilometre (4,331 inhabitants/sq mi). Furthermore, Maltahas a rapid vehicle growth. Based on our research, the number of vehiclesincreased by around 11,000 in a little more than 6 months, which shows howimportant it is to have an accurate and comprehensive means of collecting datato tackle the issue of fluctuating traffic in Malta. In this paper, we firstpresent the newly built comprehensive traffic dataset, called MalTra. Thisdataset includes realistic trips made by members of the public across theisland over a period of 200 days. We then describe the methodology we adoptedto generate syntactic data to complete our data set as much as possible. In ourresearch, we consider both MalTra and the Q-Traffic dataset, which has beenused in several other research studies. The statistical ARIMA model and twograph neural networks, the spatial temporal graph convolutional network (STGCN)and the diffusion convolutional recurrent network (DCRNN) were used to analyseand compare the results with existing research. From the evaluation, we foundthat the DCRNN model outperforms the STGCN with the former resulting in MAE of3.98 (6.65 in the case of the latter) and a RMSE of 7.78 (against 12.73 of thelatter).</description>
      <author>example@mail.com (Gabriele Borg, Charlie Abela)</author>
      <guid isPermaLink="false">2410.21028v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Causal Modeling in Multi-Context Systems: Distinguishing Multiple Context-Specific Causal Graphs which Account for Observational Support</title>
      <link>http://arxiv.org/abs/2410.20405v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多上下文数据的因果结构学习面临机遇与挑战。机遇来自共享与特定上下文的因果图，使得因果知识可以在不同上下文中推广和转移。&lt;h4&gt;目的&lt;/h4&gt;研究不同观察支持对因果图可识别性的影响，这是文献中当前尚未深入探讨的挑战。&lt;h4&gt;方法&lt;/h4&gt;详细研究新引入的因果图对象，这些对象捕捉因果机制和数据支持，允许分析更大类的上下文特定变化，更精确地表征分布变化。&lt;h4&gt;主要发现&lt;/h4&gt;扩展了对上下文特定因果结构可识别性的结果，提出了一种在结构因果模型中建模上下文特定独立性（CSI）的框架，可以探索这些图对象不同的情形。&lt;h4&gt;结论&lt;/h4&gt;该框架有助于解释异常现象或极端事件，其中因果机制在不同条件下变化或似乎变化。研究结果为理解多上下文系统中的因果关系提供了理论基础，对推广、迁移学习和异常检测具有重要意义。&lt;h4&gt;总结&lt;/h4&gt;未来的工作可能将这种方法扩展到更复杂的数据类型，如时间序列。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Causal structure learning with data from multiple contexts carries bothopportunities and challenges. Opportunities arise from considering shared andcontext-specific causal graphs enabling to generalize and transfer causalknowledge across contexts. However, a challenge that is currently understudiedin the literature is the impact of differing observational support betweencontexts on the identifiability of causal graphs. Here we study in detailrecently introduced [6] causal graph objects that capture both causalmechanisms and data support, allowing for the analysis of a larger class ofcontext-specific changes, characterizing distribution shifts more precisely. Wethereby extend results on the identifiability of context-specific causalstructures and propose a framework to model context-specific independence (CSI)within structural causal models (SCMs) in a refined way that allows to explorescenarios where these graph objects differ. We demonstrate how this frameworkcan help explaining phenomena like anomalies or extreme events, where causalmechanisms change or appear to change under different conditions. Our resultscontribute to the theoretical foundations for understanding causal relations inmulti-context systems, with implications for generalization, transfer learning,and anomaly detection. Future work may extend this approach to more complexdata types, such as time-series.</description>
      <author>example@mail.com (Martin Rabel, Wiebke Günther, Jakob Runge, Andreas Gerhardus)</author>
      <guid isPermaLink="false">2410.20405v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Local Policies Enable Zero-shot Long-horizon Manipulation</title>
      <link>http://arxiv.org/abs/2410.22332v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main paper 7 pages, 3 tables, 3 figures. Appendix 6 pages, 2 figures,
  6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在机器人操作中，sim2real（从模拟到现实）的转移面临复杂接触模拟和生成现实任务分布的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出ManipGen以解决生成现实任务分布的问题。&lt;h4&gt;方法&lt;/h4&gt;引入局部策略（local policies），结合视觉、语言和运动规划的基础模型，实现sim2real转移。&lt;h4&gt;主要发现&lt;/h4&gt;在Robosuite基准任务中，ManipGen在模拟中的零-shot性能达到97%。局部策略能够解决未见过的长时域操作任务，表现出显著的姿态、物体和场景配置变化。&lt;h4&gt;结论&lt;/h4&gt;ManipGen在50个现实操作任务中优于现有最先进的方法，分别提升36%、76%、62%和60%。&lt;h4&gt;总结&lt;/h4&gt;ManipGen通过局部策略实现了更有效的机器人操作，从模拟到现实的转移效果显著。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sim2real for robotic manipulation is difficult due to the challenges ofsimulating complex contacts and generating realistic task distributions. Totackle the latter problem, we introduce ManipGen, which leverages a new classof policies for sim2real transfer: local policies. Locality enables a varietyof appealing properties including invariances to absolute robot and objectpose, skill ordering, and global scene configuration. We combine these policieswith foundation models for vision, language and motion planning and demonstrateSOTA zero-shot performance of our method to Robosuite benchmark tasks insimulation (97%). We transfer our local policies from simulation to reality andobserve they can solve unseen long-horizon manipulation tasks with up to 8stages with significant pose, object and scene configuration variation.ManipGen outperforms SOTA approaches such as SayCan, OpenVLA, LLMTrajGen andVoxPoser across 50 real-world manipulation tasks by 36%, 76%, 62% and 60%respectively. Video results at https://mihdalal.github.io/manipgen/</description>
      <author>example@mail.com (Murtaza Dalal, Min Liu, Walter Talbott, Chen Chen, Deepak Pathak, Jian Zhang, Ruslan Salakhutdinov)</author>
      <guid isPermaLink="false">2410.22332v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds</title>
      <link>http://arxiv.org/abs/2410.22099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures, 4 tables. This work has been submitted to the
  IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;脑成像研究表明，扩散MRI轨迹几何形状描述符可以帮助研究大脑白质通路及其与大脑功能的关系。&lt;h4&gt;目的&lt;/h4&gt;探讨利用深度学习模型计算大脑白质连接的形状度量的可能性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新框架TractShapeNet，利用点云表示法计算五个形状度量：长度、跨度、体积、总表面积和不规则性。&lt;h4&gt;主要发现&lt;/h4&gt;在1065名健康年轻成年人的大型数据集中，TractShapeNet在皮尔逊相关系数和标准化误差指标上优于其他基于点云的神经网络模型。&lt;h4&gt;结论&lt;/h4&gt;深度学习方法能够更快、更高效地计算形状度量，其在两个下游语言认知预测任务中的表现与DSI-Studio计算的形状度量相似。&lt;h4&gt;总结&lt;/h4&gt;我们的代码将公开在：https://github.com/SlicerDMRI/TractShapeNet&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain imaging studies have demonstrated that diffusion MRI tractographygeometric shape descriptors can inform the study of the brain's white matterpathways and their relationship to brain function. In this work, we investigatethe possibility of utilizing a deep learning model to compute shape measures ofthe brain's white matter connections. We introduce a novel framework,TractShapeNet, that leverages a point cloud representation of tractography tocompute five shape measures: length, span, volume, total surface area, andirregularity. We assess the performance of the method on a large datasetincluding 1065 healthy young adults. Experiments for shape measure computationdemonstrate that our proposed TractShapeNet outperforms other point cloud-basedneural network models in both the Pearson correlation coefficient andnormalized error metrics. We compare the inference runtime results with theconventional shape computation tool DSI-Studio. Our results demonstrate that adeep learning approach enables faster and more efficient shape measurecomputation. We also conduct experiments on two downstream language cognitionprediction tasks, showing that shape measures from TractShapeNet performsimilarly to those computed by DSI-Studio. Our code will be available at:https://github.com/SlicerDMRI/TractShapeNet.</description>
      <author>example@mail.com (Yui Lo, Yuqian Chen, Dongnan Liu, Jon Haitz Legarreta, Leo Zekelman, Fan Zhang, Jarrett Rushmore, Yogesh Rathi, Nikos Makris, Alexandra J. Golby, Weidong Cai, Lauren J. O'Donnell)</author>
      <guid isPermaLink="false">2410.22099v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing CTR Prediction in Recommendation Domain with Search Query Representation</title>
      <link>http://arxiv.org/abs/2410.21487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CIKM 2024 Full Research Track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多平台（如电子商务网站）同时提供搜索和推荐服务，以更好地满足用户的多样化需求。&lt;h4&gt;目的&lt;/h4&gt;通过利用搜索领域提取的用户偏好，增强推荐领域的推荐服务。&lt;h4&gt;方法&lt;/h4&gt;提出一个框架，从用户搜索查询嵌入中学习，预测用户在推荐领域的点击项目，采用对比学习探讨查询与项目的关系，并结合扩散模型解决数据稀疏问题。&lt;h4&gt;主要发现&lt;/h4&gt;我们的模型在推荐领域的性能优于现有的最先进模型。&lt;h4&gt;结论&lt;/h4&gt;通过有效提取用户搜索信息，并将其整合入点击率预测中，可以显著提升推荐系统的效果。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的方法通过学习用户搜索行为，改善了推荐系统的准确性，显示出潜在的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3627673.3679849&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many platforms, such as e-commerce websites, offer both search andrecommendation services simultaneously to better meet users' diverse needs.Recommendation services suggest items based on user preferences, while searchservices allow users to search for items before providing recommendations.Since users and items are often shared between the search and recommendationdomains, there is a valuable opportunity to enhance the recommendation domainby leveraging user preferences extracted from the search domain. Existingapproaches either overlook the shift in user intention between these domains orfail to capture the significant impact of learning from users' search querieson understanding their interests.  In this paper, we propose a framework that learns from user search queryembeddings within the context of user preferences in the recommendation domain.Specifically, user search query sequences from the search domain are used topredict the items users will click at the next time point in the recommendationdomain. Additionally, the relationship between queries and items is exploredthrough contrastive learning. To address issues of data sparsity, the diffusionmodel is incorporated to infer positive items the user will select aftersearching with certain queries in a denoising manner, which is particularlyeffective in preventing false positives. Effectively extracting thisinformation, the queries are integrated into click-through rate prediction inthe recommendation domain. Experimental analysis demonstrates that our modeloutperforms state-of-the-art models in the recommendation domain.</description>
      <author>example@mail.com (Yuening Wang, Man Chen, Yaochen Hu, Wei Guo, Yingxue Zhang, Huifeng Guo, Yong Liu, Mark Coates)</author>
      <guid isPermaLink="false">2410.21487v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Graph Sparsification for Enhanced Conformal Prediction in Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.21618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Conformal Prediction 是一个可靠的框架，确保机器学习任务中的可靠覆盖。&lt;h4&gt;目的&lt;/h4&gt;探讨在训练阶段改进 conformal prediction 的方法。&lt;h4&gt;方法&lt;/h4&gt;提出 SparGCP，通过引入图稀疏化和 conformal prediction 特定目标，改善图神经网络的训练。&lt;h4&gt;主要发现&lt;/h4&gt;SparGCP 通过参数化图稀疏化模块过滤无关边缘，显著提高了 conformal prediction 的效率。&lt;h4&gt;结论&lt;/h4&gt;SparGCP 在真实世界的图数据集上表现优越，平均减少了 32% 的预测集大小，并能无缝扩展到大型网络。&lt;h4&gt;总结&lt;/h4&gt;本研究通过 SparGCP 方法有效提升了图神经网络训练阶段的 conformal prediction 效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conformal Prediction is a robust framework that ensures reliable coverageacross machine learning tasks. Although recent studies have applied conformalprediction to graph neural networks, they have largely emphasized post-hocprediction set generation. Improving conformal prediction during the trainingstage remains unaddressed. In this work, we tackle this challenge from adenoising perspective by introducing SparGCP, which incorporates graphsparsification and a conformal prediction-specific objective into GNN training.SparGCP employs a parameterized graph sparsification module to filter outtask-irrelevant edges, thereby improving conformal prediction efficiency.Extensive experiments on real-world graph datasets demonstrate that SparGCPoutperforms existing methods, reducing prediction set sizes by an average of32\% and scaling seamlessly to large networks on commodity GPUs.</description>
      <author>example@mail.com (Yuntian He, Pranav Maneriker, Anutam Srinivasan, Aditya T. Vadlamani, Srinivasan Parthasarathy)</author>
      <guid isPermaLink="false">2410.21618v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>KANsformer for Scalable Beamforming</title>
      <link>http://arxiv.org/abs/2410.20690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着移动通信系统的发展，需要提高能量效率的波束成形技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督深度学习方法，整合变换器和Kolmogorov-Arnold网络，以实现可扩展的波束成形。&lt;h4&gt;方法&lt;/h4&gt;KANsformer通过多头自注意力机制提取隐含特征，并利用KAN进行波束成形设计。&lt;h4&gt;主要发现&lt;/h4&gt;KANsformer在泛化性能、迁移学习和消融实验中表现优越。&lt;h4&gt;结论&lt;/h4&gt;KANsformer优于现有的基准深度学习方法，能够适应移动用户数量的变化，实现实时和近似最优的推理。&lt;h4&gt;总结&lt;/h4&gt;该研究为移动通信系统的波束成形提供了一种新颖的深度学习解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an unsupervised deep-learning (DL) approach byintegrating transformer and Kolmogorov-Arnold networks (KAN) termed KANsformerto realize scalable beamforming for mobile communication systems. Specifically,we consider a classic multi-input-single-output energy efficiency maximizationproblem subject to the total power budget. The proposed KANsformer firstextracts hidden features via a multi-head self-attention mechanism and thenreads out the desired beamforming design via KAN. Numerical results areprovided to evaluate the KANsformer in terms of generalization performance,transfer learning and ablation experiment. Overall, the KANsformer outperformsexisting benchmark DL approaches, and is adaptable to the change in the numberof mobile users with real-time and near-optimal inference.</description>
      <author>example@mail.com (Xinke Xie, Yang Lu, Chong-Yung Chi, Wei Chen, Bo Ai, Dusit Niyato)</author>
      <guid isPermaLink="false">2410.20690v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>SimSiam Naming Game: A Unified Approach for Representation Learning and Emergent Communication</title>
      <link>http://arxiv.org/abs/2410.21803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;新兴通信由生成模型驱动，使智能体能通过交互发展出共同语言来描述对同一对象的不同看法。&lt;h4&gt;目的&lt;/h4&gt;提出SimSiam+VAE，作为统一的表征学习和新兴通信的方法。&lt;h4&gt;方法&lt;/h4&gt;在SimSiam网络的预测器中集成变分自编码器（VAE），以增强表征学习并捕捉不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;SimSiam+VAE的实验结果优于SimSiam和VI-SimSiam。&lt;h4&gt;结论&lt;/h4&gt;SSNG展示了与参考游戏相当的性能，并稍微优于Metropolis-Hastings命名游戏。&lt;h4&gt;总结&lt;/h4&gt;通过将生成和贝叶斯方法结合，SSNG促进了智能体之间的相互理解，表明其在动态角色交替中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Emergent communication, driven by generative models, enables agents todevelop a shared language for describing their individual views of the sameobjects through interactions. Meanwhile, self-supervised learning (SSL),particularly SimSiam, uses discriminative representation learning to makerepresentations of augmented views of the same data point closer in therepresentation space. Building on the prior work of VI-SimSiam, whichincorporates a generative and Bayesian perspective into the SimSiam frameworkvia variational inference (VI) interpretation, we propose SimSiam+VAE, aunified approach for both representation learning and emergent communication.SimSiam+VAE integrates a variational autoencoder (VAE) into the predictor ofthe SimSiam network to enhance representation learning and capture uncertainty.Experimental results show that SimSiam+VAE outperforms both SimSiam andVI-SimSiam. We further extend this model into a communication framework calledthe SimSiam Naming Game (SSNG), which applies the generative and Bayesianapproach based on VI to develop internal representations and emergent language,while utilizing the discriminative process of SimSiam to facilitate mutualunderstanding between agents. In experiments with established models, despitethe dynamic alternation of agent roles during interactions, SSNG demonstratescomparable performance to the referential game and slightly outperforms theMetropolis-Hastings naming game.</description>
      <author>example@mail.com (Nguyen Le Hoang, Tadahiro Taniguchi, Fang Tianwei, Akira Taniguchi)</author>
      <guid isPermaLink="false">2410.21803v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Surface reconstruction from point cloud using a semi-Lagrangian scheme with local interpolator</title>
      <link>http://arxiv.org/abs/2410.22205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种水平集方法，用于从点云重建未知表面，而不假设点之间的连接已知。&lt;h4&gt;目的&lt;/h4&gt;通过变分公式和曲率约束，最小化表面面积，权衡表面与点云之间的距离。&lt;h4&gt;方法&lt;/h4&gt;解决一个等效的对流-扩散方程，描述由水平集函数隐式定义的初始表面演化。采用半拉格朗日方案，并与局部插值器耦合以降低计算成本。&lt;h4&gt;主要发现&lt;/h4&gt;使用多线性插值器和加权本质非振荡插值器提高重建的准确性，且方法具有局部化特性和快速并行算法，显著加快重建速度。&lt;h4&gt;结论&lt;/h4&gt;提出了一种点云数据的预处理方法，以设置算法参数，并通过二维和三维的数值测试评估近似解的质量和算法的计算效率。&lt;h4&gt;总结&lt;/h4&gt;该方法有效地重建未知表面，提供了高效且准确的解决方案，适用于各种计算场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a level set method to reconstruct unknown surfaces from pointclouds, without assuming that the connections between points are known. Weconsider a variational formulation with a curvature constraint that minimizesthe surface area weighted by the distance of the surface from the point cloud.More precisely we solve an equivalent advection-diffusion equation that governsthe evolution of an initial surface described implicitly by a level setfunction. Among all the possible representations, we aim to compute the signeddistance function at least in the vicinity of the reconstructed surface. Thenumerical method for the approximation of the solution is based on asemi-Lagrangian scheme whose main novelty consists in its coupling with a localinterpolator instead of a global one, with the aim of saving computationalcosts. In particular, we resort to a multi-linear interpolator and to aWeighted Essentially Non-oscillatory one, to improve the accuracy of thereconstruction. Special attention has been paid to the localization of themethod and to the development of fast algorithms that run in parallel,resulting in faster reconstruction and thus the opportunity to easily improvethe resolution. A preprocessing of the point cloud data is also proposed to setthe parameters of the method. Numerical tests in two and three dimensions arepresented to evaluate the quality of the approximated solution and theefficiency of the algorithm in terms of computational time.</description>
      <author>example@mail.com (Silvia Preda, Matteo Semplice)</author>
      <guid isPermaLink="false">2410.22205v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting Multi-Granularity Representation via Group Contrastive Learning for Unsupervised Vehicle Re-identification</title>
      <link>http://arxiv.org/abs/2410.21667v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;车辆重识别（Vehicle ReID）旨在从不同监控摄像头视角中检索车辆图像。&lt;h4&gt;目的&lt;/h4&gt;解决现有模型在大规模真实场景中由于源数据集与目标之间显著领域差异而导致的性能下降问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种无监督车辆重识别框架（MGR-GCL），结合多粒度CNN表示和对比学习模块，以实现高效的领域适应。&lt;h4&gt;主要发现&lt;/h4&gt;通过在标记源数据集上训练的多粒度表示（MGR），生成目标数据集的伪标签，促进领域适应过程，实验结果显示该方法优于现有的最先进技术。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架有效提升了车辆重识别的性能，解决了领域不匹配带来的挑战。&lt;h4&gt;总结&lt;/h4&gt;MGR-GCL框架通过无监督学习策略，实现了车辆重识别的领域适应，展现出良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vehicle re-identification (Vehicle ReID) aims at retrieving vehicle imagesacross disjoint surveillance camera views. The majority of vehicle ReIDresearch is heavily reliant upon supervisory labels from specifichuman-collected datasets for training. When applied to the large-scalereal-world scenario, these models will experience dreadful performance declinesdue to the notable domain discrepancy between the source dataset and thetarget. To address this challenge, in this paper, we propose an unsupervisedvehicle ReID framework (MGR-GCL). It integrates a multi-granularity CNNrepresentation for learning discriminative transferable features and acontrastive learning module responsible for efficient domain adaptation in theunlabeled target domain. Specifically, after training the proposedMulti-Granularity Representation (MGR) on the labeled source dataset, wepropose a group contrastive learning module (GCL) to generate pseudo labels forthe target dataset, facilitating the domain adaptation process. We conductedextensive experiments and the results demonstrated our superiority againstexisting state-of-the-art methods.</description>
      <author>example@mail.com (Zhigang Chang, Shibao Zheng)</author>
      <guid isPermaLink="false">2410.21667v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Breccia and basalt classification of thin sections of Apollo rocks with deep learning</title>
      <link>http://arxiv.org/abs/2410.21024v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类预计将在下一个十年内重新探索月球，这是自阿波罗计划以来的首次活动。&lt;h4&gt;目的&lt;/h4&gt;重返月球的主要目标之一是继续采集地质样本，特别是高质量标本，以最大化科学回报。&lt;h4&gt;方法&lt;/h4&gt;提出了一种分类月球岩石薄片的框架，利用阿波罗任务的岩石薄片图像，应用对比学习方法分析这些图像并提取有意义的特征。&lt;h4&gt;主要发现&lt;/h4&gt;经过对预训练的Inception-Resnet-v2网络进行微调，能够有效提取阿波罗岩石薄片图像的基本特征，训练的二分类器在分离破碎岩和玄武岩时达到了98.44%的准确率。&lt;h4&gt;结论&lt;/h4&gt;开发的岩石分类工具可以帮助宇航员更好地分析月球岩石样本，从而提高未来月球任务的科学价值。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了机器学习在月球样本分析中的应用潜力，为未来的月球探索提供了重要的技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human exploration of the moon is expected to resume in the next decade,following the last such activities in the Apollo programme time. One of themajor objectives of returning to the Moon is to continue retrieving geologicalsamples, with a focus on collecting high-quality specimens to maximizescientific return. Tools that assist astronauts in making informed decisionsabout sample collection activities can maximize the scientific value of futurelunar missions. A lunar rock classifier is a tool that can potentially providethe necessary information for astronauts to analyze lunar rock samples,allowing them to augment in-situ value identification of samples. Towardsdemonstrating the value of such a tool, in this paper, we introduce a frameworkfor classifying rock types in thin sections of lunar rocks. We leverage thevast collection of petrographic thin-section images from the Apollo missions,captured under plane-polarized light (PPL), cross-polarised light (XPL), andreflected light at varying magnifications. Advanced machine learning methods,including contrastive learning, are applied to analyze these images and extractmeaningful features. The contrastive learning approach fine-tunes a pre-trainedInception-Resnet-v2 network with the SimCLR loss function. The fine-tunedInception-Resnet-v2 network can then extract essential features effectivelyfrom the thin-section images of Apollo rocks. A simple binary classifier istrained using transfer learning from the fine-tuned Inception-ResNet-v2 to98.44\% ($\pm$1.47) accuracy in separating breccias from basalts.</description>
      <author>example@mail.com (Freja Thoresen, Aidan Cowley, Romeo Haak, Jonas Lewe, Clara Moriceau, Piotr Knapczyk, Victoria S. Engelschiøn)</author>
      <guid isPermaLink="false">2410.21024v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Enhance Hyperbolic Representation Learning via Second-order Pooling</title>
      <link>http://arxiv.org/abs/2410.22026v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;超曲率表示学习因其捕捉层次信息的能力而广为人知，但不同层次类别之间的样本距离往往需要较大。&lt;h4&gt;目的&lt;/h4&gt;解决超曲率判别目标导致的Lipschitz常数增大问题，以充分利用主干网络的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入二阶池化到超曲率表示学习中，自然增加样本间距离而不影响输入特征的泛化能力，并提出核近似正则化以解决低维双线性特征在超曲率表示学习中的应用问题。&lt;h4&gt;主要发现&lt;/h4&gt;二阶池化能够有效增加样本间距离，同时保持主干网络的泛化能力，而核近似正则化有助于低维特征良好近似核函数。&lt;h4&gt;结论&lt;/h4&gt;所提方法在图结构数据集上的广泛实验表明其有效性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，通过二阶池化和核近似正则化，改善超曲率表示学习的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperbolic representation learning is well known for its ability to capturehierarchical information. However, the distance between samples from differentlevels of hierarchical classes can be required large. We reveal that thehyperbolic discriminant objective forces the backbone to capture thishierarchical information, which may inevitably increase the Lipschitz constantof the backbone. This can hinder the full utilization of the backbone'sgeneralization ability. To address this issue, we introduce second-orderpooling into hyperbolic representation learning, as it naturally increases thedistance between samples without compromising the generalization ability of theinput features. In this way, the Lipschitz constant of the backbone does notnecessarily need to be large. However, current off-the-shelf low-dimensionalbilinear pooling methods cannot be directly employed in hyperbolicrepresentation learning because they inevitably reduce the distance expansioncapability. To solve this problem, we propose a kernel approximationregularization, which enables the low-dimensional bilinear features toapproximate the kernel function well in low-dimensional space. Finally, weconduct extensive experiments on graph-structured datasets to demonstrate theeffectiveness of the proposed method.</description>
      <author>example@mail.com (Kun Song, Ruben Solozabal, Li hao, Lu Ren, Moloud Abdar, Qing Li, Fakhri Karray, Martin Takac)</author>
      <guid isPermaLink="false">2410.22026v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>LiVisSfM: Accurate and Robust Structure-from-Motion with LiDAR and Visual Cues</title>
      <link>http://arxiv.org/abs/2410.22213v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 9 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种名为LiVisSfM的准确且稳健的运动结构重建系统，结合了激光雷达（LiDAR）和视觉线索。&lt;h4&gt;目的&lt;/h4&gt;开发一种不依赖于惯性测量单元（IMU）的LiDAR-视觉SfM方法，以实现准确的LiDAR位姿估计。&lt;h4&gt;方法&lt;/h4&gt;采用激光雷达帧注册到LiDAR体素地图，使用点到高斯残差度量，并结合LiDAR-视觉的束优化和显式回环闭合。&lt;h4&gt;主要发现&lt;/h4&gt;LiVisSfM框架在LiDAR位姿恢复和稠密点云重建方面，表现优于现有的LiDAR惯性里程计（LIO）和LiDAR-视觉里程计（LIVO）方法。&lt;h4&gt;结论&lt;/h4&gt;LiVisSfM在KITTI基准和多种自采集数据集上的实验结果显示出其更高的准确性和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;LiVisSfM通过创新的框架和方法，提升了LiDAR和视觉信息结合的效率和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an accurate and robust Structure-from-Motion (SfM)pipeline named LiVisSfM, which is an SfM-based reconstruction system that fullycombines LiDAR and visual cues. Unlike most existing LiDAR-inertial odometry(LIO) and LiDAR-inertial-visual odometry (LIVO) methods relying heavily onLiDAR registration coupled with Inertial Measurement Unit (IMU), we propose aLiDAR-visual SfM method which innovatively carries out LiDAR frame registrationto LiDAR voxel map in a Point-to-Gaussian residual metrics, combined with aLiDAR-visual BA and explicit loop closure in a bundle optimization way toachieve accurate and robust LiDAR pose estimation without dependence on IMUincorporation. Besides, we propose an incremental voxel updating strategy forefficient voxel map updating during the process of LiDAR frame registration andLiDAR-visual BA optimization. Experiments demonstrate the superioreffectiveness of our LiVisSfM framework over state-of-the-art LIO and LIVOworks on more accurate and robust LiDAR pose recovery and dense point cloudreconstruction of both public KITTI benchmark and a variety of self-captureddataset.</description>
      <author>example@mail.com (Hanqing Jiang, Liyang Zhou, Zhuang Zhang, Yihao Yu, Guofeng Zhang)</author>
      <guid isPermaLink="false">2410.22213v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>UnCLe: Unsupervised Continual Learning of Depth Completion</title>
      <link>http://arxiv.org/abs/2410.18074v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度补全任务旨在从同步的RGB图像和稀疏深度图推断出密集深度图。现有方法通常在静态数据集上训练，但在适应新的非静态分布时，容易出现'灾难性遗忘'。&lt;h4&gt;目的&lt;/h4&gt;提出UnCLe，一个标准化基准，用于无监督持续学习的多模态深度估计任务。&lt;h4&gt;方法&lt;/h4&gt;通过适应深度补全模型于包含来自不同域的多样场景的数据集序列，模拟非静态分布，采用持续学习范式中的代表性方法以实现无监督持续学习。&lt;h4&gt;主要发现&lt;/h4&gt;通过标准定量指标评估模型在室内和室外场景的表现，发现无监督持续学习的深度补全仍是一个开放问题。&lt;h4&gt;结论&lt;/h4&gt;引入模型反演质量作为额外的遗忘度量，邀请研究人员利用UnCLe作为开发平台。&lt;h4&gt;总结&lt;/h4&gt;UnCLe为发展无监督持续学习的深度补全提供了一个重要的基准和研究平台。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose UnCLe, a standardized benchmark for Unsupervised ContinualLearning of a multimodal depth estimation task: Depth completion aims to infera dense depth map from a pair of synchronized RGB image and sparse depth map.We benchmark depth completion models under the practical scenario ofunsupervised learning over continuous streams of data. Existing methods aretypically trained on a static, or stationary, dataset. However, when adaptingto novel non-stationary distributions, they "catastrophically forget"previously learned information. UnCLe simulates these non-stationarydistributions by adapting depth completion models to sequences of datasetscontaining diverse scenes captured from distinct domains using different visualand range sensors. We adopt representative methods from continual learningparadigms and translate them to enable unsupervised continual learning of depthcompletion. We benchmark these models for indoor and outdoor and investigatethe degree of catastrophic forgetting through standard quantitative metrics.Furthermore, we introduce model inversion quality as an additional measure offorgetting. We find that unsupervised continual learning of depth completion isan open problem, and we invite researchers to leverage UnCLe as a developmentplatform.</description>
      <author>example@mail.com (Suchisrit Gangopadhyay, Xien Chen, Michael Chu, Patrick Rim, Hyoungseob Park, Alex Wong)</author>
      <guid isPermaLink="false">2410.18074v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Fresh Look at Generalized Category Discovery through Non-negative Matrix Factorization</title>
      <link>http://arxiv.org/abs/2410.21807v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;一般化类别发现（GCD）旨在使用标记的基础数据对基础和新颖图像进行分类，目前的方法未能充分优化基于余弦相似度的共现矩阵。&lt;h4&gt;目的&lt;/h4&gt;解决当前方法在基础-新颖区域的零化和基础与新颖领域的稀疏性不足问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种非负一般化类别发现（NN-GCD）框架，使用对称非负矩阵分解（SNMF）证明最优K-means与最优SNMF的等价性，并将优化问题重新构建为非负对比学习（NCL）优化问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，NN-GCD在GCD基准测试中表现优于现有的最先进方法，在语义转移基准上平均准确率达到66.1%，比之前的方法提高了4.7%。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效解决了GCD中的稀疏性和优化问题，为进一步研究提供了新的思路和方法。&lt;h4&gt;总结&lt;/h4&gt;NN-GCD框架通过理论等价和新的激活函数与损失函数，显著提升了GCD模型的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized Category Discovery (GCD) aims to classify both base and novelimages using labeled base data. However, current approaches inadequatelyaddress the intrinsic optimization of the co-occurrence matrix $\bar{A}$ basedon cosine similarity, failing to achieve zero base-novel regions and adequatesparsity in base and novel domains. To address these deficiencies, we propose aNon-Negative Generalized Category Discovery (NN-GCD) framework. It employsSymmetric Non-negative Matrix Factorization (SNMF) as a mathematical medium toprove the equivalence of optimal K-means with optimal SNMF, and the equivalenceof SNMF solver with non-negative contrastive learning (NCL) optimization.Utilizing these theoretical equivalences, it reframes the optimization of$\bar{A}$ and K-means clustering as an NCL optimization problem. Moreover, tosatisfy the non-negative constraints and make a GCD model converge to anear-optimal region, we propose a GELU activation function and an NMF NCE loss.To transition $\bar{A}$ from a suboptimal state to the desired $\bar{A}^*$, weintroduce a hybrid sparse regularization approach to impose sparsityconstraints. Experimental results show NN-GCD outperforms state-of-the-artmethods on GCD benchmarks, achieving an average accuracy of 66.1\% on theSemantic Shift Benchmark, surpassing prior counterparts by 4.7\%.</description>
      <author>example@mail.com (Zhong Ji, Shuo Yang, Jingren Liu, Yanwei Pang, Jungong Han)</author>
      <guid isPermaLink="false">2410.21807v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Transfer Clustering: A Unified Framework</title>
      <link>http://arxiv.org/abs/2410.21263v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  52 pages, 8 figures; typos corrected, table edited&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一个用于聚类的通用迁移学习框架，涉及主要数据集和辅助数据集，这两个数据集可能反映出相似但不同的潜在分组结构。&lt;h4&gt;目的&lt;/h4&gt;设计一种自适应迁移聚类（ATC）算法，以在未知差异存在的情况下自动利用数据的共性。&lt;h4&gt;方法&lt;/h4&gt;通过优化估计的偏差-方差分解来实现迁移聚类，适用于包括高斯混合模型、随机块模型和潜在类别模型在内的广泛统计模型。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析证明了ATC在高斯混合模型下的最优性，并明确量化了迁移的好处。&lt;h4&gt;结论&lt;/h4&gt;通过大量仿真和真实数据实验，验证了该方法在各种场景下的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究为聚类问题提供了新的迁移学习视角，并展示了ATC算法的实用性和优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhongyuanlyu/atc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a general transfer learning framework for clustering given a maindataset and an auxiliary one about the same subjects. The two datasets mayreflect similar but different latent grouping structures of the subjects. Wepropose an adaptive transfer clustering (ATC) algorithm that automaticallyleverages the commonality in the presence of unknown discrepancy, by optimizingan estimated bias-variance decomposition. It applies to a broad class ofstatistical models including Gaussian mixture models, stochastic block models,and latent class models. A theoretical analysis proves the optimality of ATCunder the Gaussian mixture model and explicitly quantifies the benefit oftransfer. Extensive simulations and real data experiments confirm our method'seffectiveness in various scenarios.</description>
      <author>example@mail.com (Yuqi Gu, Zhongyuan Lyu, Kaizheng Wang)</author>
      <guid isPermaLink="false">2410.21263v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Orb: A Fast, Scalable Neural Network Potential</title>
      <link>http://arxiv.org/abs/2410.22570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;介绍了Orb，一种用于材料原子级建模的通用原子间势。&lt;h4&gt;目的&lt;/h4&gt;开发一种比现有通用势更快、更稳定的模型。&lt;h4&gt;方法&lt;/h4&gt;评估Orb在几何优化、Monte Carlo和分子动力学模拟中的表现，并探索材料基础模型开发的多个方面，重点关注扩散预训练。&lt;h4&gt;主要发现&lt;/h4&gt;Orb模型的速度比现有通用势快3-6倍，并在多种非分布材料的模拟中保持稳定。&lt;h4&gt;结论&lt;/h4&gt;Orb在Matbench Discovery基准测试中，错误率比其他方法减少了31%。&lt;h4&gt;总结&lt;/h4&gt;Orb提供了一种新的高效且准确的材料建模方法，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Orb, a family of universal interatomic potentials for atomisticmodelling of materials. Orb models are 3-6 times faster than existing universalpotentials, stable under simulation for a range of out of distributionmaterials and, upon release, represented a 31% reduction in error over othermethods on the Matbench Discovery benchmark. We explore several aspects offoundation model development for materials, with a focus on diffusionpretraining. We evaluate Orb as a model for geometry optimization, Monte Carloand molecular dynamics simulations.</description>
      <author>example@mail.com (Mark Neumann, James Gin, Benjamin Rhodes, Steven Bennett, Zhiyi Li, Hitarth Choubisa, Arthur Hussey, Jonathan Godwin)</author>
      <guid isPermaLink="false">2410.22570v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Hypergraph Neural Networks Reveal Spatial Domains from Single-cell Transcriptomics Data</title>
      <link>http://arxiv.org/abs/2410.19868v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;空间转录组数据的聚类任务至关重要，能够将组织样本分类为多种细胞亚群，进而分析聚类的生物功能、组织重建和细胞间相互作用。&lt;h4&gt;目的&lt;/h4&gt;提高空间转录组数据的聚类准确性，克服传统图神经网络(GNN)在捕捉细胞间隐含连接方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;使用超图神经网络(HGNN)，通过超边连接多个节点，捕捉更丰富的结构信息，同时利用自编码器进行无监督学习。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在iLISI评分上取得了1.843的最高分，显示出识别细胞类型的多样性。此外，在下游聚类中，模型的ARI值为0.51，Leiden评分为0.60，均优于其他方法。&lt;h4&gt;结论&lt;/h4&gt;HGNN模型在空间转录组数据的聚类中展示了卓越的性能，能够更好地识别细胞亚群和其多样性。&lt;h4&gt;总结&lt;/h4&gt;HGNN通过捕捉细胞间复杂的连接关系，显著提升了空间转录组数据的聚类效果，具有重要的研究和应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The task of spatial clustering of transcriptomics data is of paramountimportance. It enables the classification of tissue samples into diversesubpopulations of cells, which, in turn, facilitates the analysis of thebiological functions of clusters, tissue reconstruction, and cell-cellinteractions. Many approaches leverage gene expressions, spatial locations, andhistological images to detect spatial domains; however, Graph Neural Networks(GNNs) as state of the art models suffer from a limitation in the assumption ofpairwise connections between nodes. In the case of domain detection in spatialtranscriptomics, some cells are found to be not directly related. Still, theyare grouped as the same domain, which shows the incapability of GNNs forcapturing implicit connections among the cells.  While graph edges connect only two nodes, hyperedges connect an arbitrarynumber of nodes along their edges, which lets Hypergraph Neural Networks(HGNNs) capture and utilize richer and more complex structural information thantraditional GNNs. We use autoencoders to address the limitation of not havingthe actual labels, which are well-suited for unsupervised learning. Our modelhas demonstrated exceptional performance, achieving the highest iLISI score of1.843 compared to other methods. This score indicates the greatest diversity ofcell types identified by our method. Furthermore, our model outperforms othermethods in downstream clustering, achieving the highest ARI values of 0.51 andLeiden score of 0.60.</description>
      <author>example@mail.com (Mehrad Soltani, Luis Rueda)</author>
      <guid isPermaLink="false">2410.19868v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Domain Transfer Learning Method for Thermal Adaptive Behavior Recognition with WiFi</title>
      <link>http://arxiv.org/abs/2410.21827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;可靠的舒适模型对于提高居住者满意度和减少建筑能耗至关重要。&lt;h4&gt;目的&lt;/h4&gt;通过精确识别穿衣和脱衣两种常见的热适应行为，提高热舒适预测的支持效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种跨域迁移学习方法，利用WiFi信号识别人类穿衣和脱衣的适应性行为。首先通过计算去噪WiFi信号的滑动方差确定活动区间，然后进行短时傅里叶变换和离散小波变换以提取时频分析的动作信息，最后集成高效的预训练1D CNN模型与SVM算法作为混合模型以增强在新场景下的识别鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;基于迁移学习的混合模型在适应性行为的识别中表现更为准确，在两个案例中分别达到了96.9%和94.9%的准确率。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了对目标对象适应性行为的预测准确性。&lt;h4&gt;总结&lt;/h4&gt;本研究为热舒适预测提供了一种新的解决方案，利用WiFi信号和迁移学习技术克服了传统活动识别的隐私、成本和性能问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A reliable comfort model is essential to improve occupant satisfaction andreduce building energy consumption. As two types of the most common andintuitive thermal adaptive behaviors, precise recognition of dressing andundressing can effectively support thermal comfort prediction. However,traditional activity recognition suffers from shortcomings in privacy, cost,and performance. To address the above issues, this study proposes across-domain transfer learning method for human dressing and undressingadaptive behavior recognition with WiFi. First, we determine the activityinterval by calculating the sliding variance for denoised WiFi signals.Subsequently, short-time Fourier transform and discrete wavelet transform areperformed to extract action information on the basis of time-frequencyanalysis. Ultimately, an efficient 1D CNN pre-trained model is integrated withthe SVM algorithm as a hybrid model to enhance the identification robustness innew scenarios. Experiment results show that the hybrid model based on transferlearning provides a more accurate prediction for the adaptative behavior oftarget subjects, achieving 96.9% and 94.9% accuracy in two cases, respectively.</description>
      <author>example@mail.com (Zhaohe Lv, Guoliang Zhao, Zhanbo Xu, Jiang Wu, Yadong Zhou, Kun Liu)</author>
      <guid isPermaLink="false">2410.21827v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>CrossEarth: Geospatial Vision Foundation Model for Domain Generalizable Remote Sensing Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.22629v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The codes and models will be available at
  https://github.com/Cuzyoung/CrossEarth&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;遥感领域的领域泛化（RSDG）研究尚处于初期，关注于在不同场景中有效泛化的模型。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的遥感语义分割的视觉基础模型CrossEarth，旨在克服当前模型在未知领域中的表现不足。&lt;h4&gt;方法&lt;/h4&gt;CrossEarth采用了数据层面的Earth-Style Injection管道和模型层面的多任务训练管道，增强跨领域泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;CrossEarth在28个跨领域设置的基准测试中显示出优于现有最先进方法的表现。&lt;h4&gt;结论&lt;/h4&gt;CrossEarth为未来的RSDG模型提供了一个全面的测试框架，展示了其在遥感领域的广泛适用性。&lt;h4&gt;总结&lt;/h4&gt;本研究填补了RSDG领域的研究空白，推动了语义分割任务的进展，并为相关研究提供了基准和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cuzyoung/crossearth&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The field of Remote Sensing Domain Generalization (RSDG) has emerged as acritical and valuable research frontier, focusing on developing models thatgeneralize effectively across diverse scenarios. Despite the substantial domaingaps in RS images that are characterized by variabilities such as location,wavelength, and sensor type, research in this area remains underexplored: (1)Current cross-domain methods primarily focus on Domain Adaptation (DA), whichadapts models to predefined domains rather than to unseen ones; (2) Few studiestargeting the RSDG issue, especially for semantic segmentation tasks, whereexisting models are developed for specific unknown domains, struggling withissues of underfitting on other unknown scenarios; (3) Existing RS foundationmodels tend to prioritize in-domain performance over cross-domaingeneralization. To this end, we introduce the first vision foundation model forRSDG semantic segmentation, CrossEarth. CrossEarth demonstrates strongcross-domain generalization through a specially designed data-level Earth-StyleInjection pipeline and a model-level Multi-Task Training pipeline. In addition,for the semantic segmentation task, we have curated an RSDG benchmarkcomprising 28 cross-domain settings across various regions, spectral bands,platforms, and climates, providing a comprehensive framework for testing thegeneralizability of future RSDG models. Extensive experiments on this benchmarkdemonstrate the superiority of CrossEarth over existing state-of-the-artmethods.</description>
      <author>example@mail.com (Ziyang Gong, Zhixiang Wei, Di Wang, Xianzheng Ma, Hongruixuan Chen, Yuru Jia, Yupeng Deng, Zhenming Ji, Xiangwei Zhu, Naoto Yokoya, Jing Zhang, Bo Du, Liangpei Zhang)</author>
      <guid isPermaLink="false">2410.22629v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation</title>
      <link>http://arxiv.org/abs/2410.22658v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;持续模仿学习（CiL）旨在从多个阶段和任务的演示中提取和积累任务知识，以实现多任务策略。&lt;h4&gt;目的&lt;/h4&gt;解决现有适配器基础的CiL方法在知识共享方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;提出IsCiL框架，通过逐步学习不同演示中的可共享技能，支持在非平稳CiL环境中进行样本高效的任务适应。&lt;h4&gt;主要发现&lt;/h4&gt;在Franka-Kitchen和Meta-World的复杂任务实验中，IsCiL在任务适应性和样本效率上表现出色。&lt;h4&gt;结论&lt;/h4&gt;IsCiL不仅能有效适应任务，还可以扩展至任务遗忘场景。&lt;h4&gt;总结&lt;/h4&gt;IsCiL通过增强知识共享能力，提升了持续模仿学习的性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continual Imitation Learning (CiL) involves extracting and accumulating taskknowledge from demonstrations across multiple stages and tasks to achieve amulti-task policy. With recent advancements in foundation models, there hasbeen a growing interest in adapter-based CiL approaches, where adapters areestablished parameter-efficiently for tasks newly demonstrated. While theseapproaches isolate parameters for specific tasks and tend to mitigatecatastrophic forgetting, they limit knowledge sharing among differentdemonstrations. We introduce IsCiL, an adapter-based CiL framework thataddresses this limitation of knowledge sharing by incrementally learningshareable skills from different demonstrations, thus enabling sample-efficienttask adaptation using the skills particularly in non-stationary CiLenvironments. In IsCiL, demonstrations are mapped into the state embeddingspace, where proper skills can be retrieved upon input states throughprototype-based memory. These retrievable skills are incrementally learned ontheir corresponding adapters. Our CiL experiments with complex tasks inFranka-Kitchen and Meta-World demonstrate robust performance of IsCiL in bothtask adaptation and sample-efficiency. We also show a simple extension of IsCiLfor task unlearning scenarios.</description>
      <author>example@mail.com (Daehee Lee, Minjong Yoo, Woo Kyung Kim, Wonje Choi, Honguk Woo)</author>
      <guid isPermaLink="false">2410.22658v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Systematic Literature Review of Spatio-Temporal Graph Neural Network Models for Time Series Forecasting and Classification</title>
      <link>http://arxiv.org/abs/2410.22377v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，时空图神经网络（GNNs）在时间序列分析领域受到广泛关注，因其能捕捉变量之间及时间点之间的依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提供GNNs在时间序列分类和预测中的建模方法和应用领域的全面概述。&lt;h4&gt;方法&lt;/h4&gt;进行了数据库搜索，选择了150多篇期刊论文，对该领域的现状进行了详细审查。&lt;h4&gt;主要发现&lt;/h4&gt;提供了各种模型的汇总、相关源代码链接、可用数据集、基准模型和拟合结果。&lt;h4&gt;结论&lt;/h4&gt;希望这些信息能为研究人员的未来研究提供帮助，这是首个系统性文献综述，详细比较了不同领域中当前时空GNN模型的结果。&lt;h4&gt;挑战&lt;/h4&gt;讨论了时空GNNs应用中的当前限制和挑战，如可比性、可重复性、可解释性、信息容量不足和可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本综述为研究人员提供了一个全面的模型和应用参考，同时指出了未来研究中需要克服的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, spatio-temporal graph neural networks (GNNs) have attractedconsiderable interest in the field of time series analysis, due to theirability to capture dependencies among variables and across time points. Theobjective of the presented systematic literature review is hence to provide acomprehensive overview of the various modeling approaches and applicationdomains of GNNs for time series classification and forecasting. A databasesearch was conducted, and over 150 journal papers were selected for a detailedexamination of the current state-of-the-art in the field. This examination isintended to offer to the reader a comprehensive collection of proposed models,links to related source code, available datasets, benchmark models, and fittingresults. All this information is hoped to assist researchers in future studies.To the best of our knowledge, this is the first systematic literature reviewpresenting a detailed comparison of the results of current spatio-temporal GNNmodels in different domains. In addition, in its final part this reviewdiscusses current limitations and challenges in the application ofspatio-temporal GNNs, such as comparability, reproducibility, explainability,poor information capacity, and scalability.</description>
      <author>example@mail.com (Flavio Corradini, Marco Gori, Carlo Lucheroni, Marco Piangerelli, Martina Zannotti)</author>
      <guid isPermaLink="false">2410.22377v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>A Graph-Based Model for Vehicle-Centric Data Sharing Ecosystem</title>
      <link>http://arxiv.org/abs/2410.22897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper was accepted and presented at 2024 IEEE 27th International
  Conference on Intelligent Transportation Systems (ITSC 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;技术的发展促使汽车行业发生范式转变，越来越关注连接服务和自动驾驶能力。&lt;h4&gt;目的&lt;/h4&gt;理解现代汽车数据收集和共享的生态系统。&lt;h4&gt;方法&lt;/h4&gt;采用本体论101方法，结合隐私政策分析、文献综述和现有本体，开发高层概念图模型。&lt;h4&gt;主要发现&lt;/h4&gt;现代汽车在数据交换中处理不同方之间的信息，提供隐私相关的数据共享见解。&lt;h4&gt;结论&lt;/h4&gt;提出了基础模型，具备灵活性和可扩展性，以进一步分析不同背景下的数据共享实践。&lt;h4&gt;未来研究方向&lt;/h4&gt;探索高级本体语言进行推理任务，支持拓扑分析以发现数据隐私风险，开发比较分析工具。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了汽车数据共享生态系统的复杂性，并建议进一步研究以增强对隐私问题的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The development of technologies has prompted a paradigm shift in theautomotive industry, with an increasing focus on connected services andautonomous driving capabilities. This transformation allows vehicles to collectand share vast amounts of vehicle-specific and personal data. While thesetechnological advancements offer enhanced user experiences, they also raiseprivacy concerns. To understand the ecosystem of data collection and sharing inmodern vehicles, we adopted the ontology 101 methodology to incorporateinformation extracted from different sources, including analysis of privacypolicies using GPT-4, a small-scale systematic literature review, and anexisting ontology, to develop a high-level conceptual graph-based model, aimingto get insights into how modern vehicles handle data exchange among differentparties. This serves as a foundational model with the flexibility andscalability to further expand for modelling and analysing data sharingpractices across diverse contexts. Two realistic examples were developed todemonstrate the usefulness and effectiveness of discovering insights intoprivacy regarding vehicle-related data sharing. We also recommend severalfuture research directions, such as exploring advanced ontology languages forreasoning tasks, supporting topological analysis for discovering data privacyrisks/concerns, and developing useful tools for comparative analysis, tostrengthen the understanding of the vehicle-centric data sharing ecosystem.</description>
      <author>example@mail.com (Haiyue Yuan, Ali Raza, Nikolay Matyunin, Jibesh Patra, Shujun Li)</author>
      <guid isPermaLink="false">2410.22897v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Robots Pre-train Robots: Manipulation-Centric Robotic Representation from Large-Scale Robot Datasets</title>
      <link>http://arxiv.org/abs/2410.22325v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉表示的预训练提高了机器人学习的效率，但缺乏大规模的领域内机器人数据集。&lt;h4&gt;目的&lt;/h4&gt;利用人类视频进行机器人视觉表示的预训练，克服数据不足的问题。&lt;h4&gt;方法&lt;/h4&gt;评估各种预训练表示与下游机器人操作任务的相关性；提出操作中心表示（MCR）框架，捕捉视觉特征和动态信息。&lt;h4&gt;主要发现&lt;/h4&gt;发现操作中心性是下游任务成功率的强指标，MCR在四个仿真领域的20个任务中超越最强基线方法14.8%。&lt;h4&gt;结论&lt;/h4&gt;MCR在现实世界的三项任务中提升了数据高效学习的性能76.9%。&lt;h4&gt;总结&lt;/h4&gt;MCR通过对视觉观察与机器人状态-动作动态进行对齐，显著提升了机器人操作的效率与效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The pre-training of visual representations has enhanced the efficiency ofrobot learning. Due to the lack of large-scale in-domain robotic datasets,prior works utilize in-the-wild human videos to pre-train robotic visualrepresentation. Despite their promising results, representations from humanvideos are inevitably subject to distribution shifts and lack the dynamicsinformation crucial for task completion. We first evaluate various pre-trainedrepresentations in terms of their correlation to the downstream roboticmanipulation tasks (i.e., manipulation centricity). Interestingly, we find thatthe "manipulation centricity" is a strong indicator of success rates whenapplied to downstream tasks. Drawing from these findings, we proposeManipulation Centric Representation (MCR), a foundation representation learningframework capturing both visual features and the dynamics information such asactions and proprioceptions of manipulation tasks to improve manipulationcentricity. Specifically, we pre-train a visual encoder on the DROID roboticdataset and leverage motion-relevant data such as robot proprioceptive statesand actions. We introduce a novel contrastive loss that aligns visualobservations with the robot's proprioceptive state-action dynamics, combinedwith a behavior cloning (BC)-like actor loss to predict actions duringpre-training, along with a time contrastive loss. Empirical results across 4simulation domains with 20 tasks verify that MCR outperforms the strongestbaseline method by 14.8%. Moreover, MCR boosts the performance ofdata-efficient learning with a UR5e arm on 3 real-world tasks by 76.9%. Projectwebsite: https://robots-pretrain-robots.github.io/.</description>
      <author>example@mail.com (Guangqi Jiang, Yifei Sun, Tao Huang, Huanyu Li, Yongyuan Liang, Huazhe Xu)</author>
      <guid isPermaLink="false">2410.22325v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multi-Object 3D Grounding with Dynamic Modules and Language-Informed Spatial Attention</title>
      <link>http://arxiv.org/abs/2410.22306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多目标3D定位涉及根据点云中的查询短语定位3D框，是一项具有挑战性和重要性的任务，广泛应用于视觉理解、人机交互和机器人技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决多目标3D定位挑战的方法。&lt;h4&gt;方法&lt;/h4&gt;引入D-LISA，两阶段方法，包含三个创新：1）动态视觉模块，允许可变和可学习数量的框提议；2）动态相机定位，为每个提议提取特征；3）语言知情的空间注意模块，更好地对提议进行推理，输出最终预测。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，D-LISA在多目标3D定位任务上比现有最先进的方法提高了12.8%的绝对精度，并且在单目标3D定位上也表现出竞争力。&lt;h4&gt;结论&lt;/h4&gt;D-LISA方法在多目标和单目标3D定位任务中均表现出色，验证了其有效性。&lt;h4&gt;总结&lt;/h4&gt;D-LISA通过创新模块显著提升了多目标3D定位的性能，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-object 3D Grounding involves locating 3D boxes based on a given queryphrase from a point cloud. It is a challenging and significant task withnumerous applications in visual understanding, human-computer interaction, androbotics. To tackle this challenge, we introduce D-LISA, a two-stage approachincorporating three innovations. First, a dynamic vision module that enables avariable and learnable number of box proposals. Second, a dynamic camerapositioning that extracts features for each proposal. Third, alanguage-informed spatial attention module that better reasons over theproposals to output the final prediction. Empirically, experiments show thatour method outperforms the state-of-the-art methods on multi-object 3Dgrounding by 12.8% (absolute) and is competitive in single-object 3D grounding.</description>
      <author>example@mail.com (Haomeng Zhang, Chiao-An Yang, Raymond A. Yeh)</author>
      <guid isPermaLink="false">2410.22306v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Emotion-Guided Image to Music Generation</title>
      <link>http://arxiv.org/abs/2410.22299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2024 6th Asian Digital Image Processing Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从图像生成音乐可以提升多种应用，包括照片幻灯片的背景音乐、社交媒体体验和视频创作。&lt;h4&gt;目的&lt;/h4&gt;提出一种情感引导的图像到音乐生成框架，使生成的音乐与给定图像的情感基调相一致。&lt;h4&gt;方法&lt;/h4&gt;采用基于情感的Valence-Arousal (VA)空间，直接整合VA损失函数以实现准确的情感对齐，模型使用CNN-Transformer架构。&lt;h4&gt;主要发现&lt;/h4&gt;在新创建的情感配对图像-MIDI数据集上的实验结果表明，所提出模型在多音率、音高熵、节奏一致性和损失收敛等指标上表现优越。&lt;h4&gt;结论&lt;/h4&gt;该模型能够生成在音乐和情感上都具有一致性的MIDI序列，超越了以往依赖对比学习的模型。&lt;h4&gt;总结&lt;/h4&gt;论文展示了一种新的图像到音乐生成方法，强调情感一致性，具有良好的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating music from images can enhance various applications, includingbackground music for photo slideshows, social media experiences, and videocreation. This paper presents an emotion-guided image-to-music generationframework that leverages the Valence-Arousal (VA) emotional space to producemusic that aligns with the emotional tone of a given image. Unlike previousmodels that rely on contrastive learning for emotional consistency, theproposed approach directly integrates a VA loss function to enable accurateemotional alignment. The model employs a CNN-Transformer architecture,featuring pre-trained CNN image feature extractors and three Transformerencoders to capture complex, high-level emotional features from MIDI music.Three Transformer decoders refine these features to generate musically andemotionally consistent MIDI sequences. Experimental results on a newly curatedemotionally paired image-MIDI dataset demonstrate the proposed model's superiorperformance across metrics such as Polyphony Rate, Pitch Entropy, GrooveConsistency, and loss convergence.</description>
      <author>example@mail.com (Souraja Kundu, Saket Singh, Yuji Iwahori)</author>
      <guid isPermaLink="false">2410.22299v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>LogSHIELD: A Graph-based Real-time Anomaly Detection Framework using Frequency Analysis</title>
      <link>http://arxiv.org/abs/2410.21936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于异常的网络威胁检测在深度学习领域日益受到关注，旨在检测新型网络攻击和取证。&lt;h4&gt;目的&lt;/h4&gt;提出一个高效、实时的威胁检测模型，以满足大规模企业网络中的高准确率和高通量需求。&lt;h4&gt;方法&lt;/h4&gt;提出LogSHIELD模型，采用基于图的异常检测，利用来源图的频域分析进行实时威胁检测。&lt;h4&gt;主要发现&lt;/h4&gt;LogSHIELD能够提取日志之间的上下文和因果关系，有效检测隐秘和复杂的攻击，平均AUC和F1分数超过98%。&lt;h4&gt;结论&lt;/h4&gt;LogSHIELD显著提高了检测吞吐量，平均检测延迟为0.13秒，检测时间优于现有模型。&lt;h4&gt;总结&lt;/h4&gt;LogSHIELD是一种先进的图基异常检测模型，适用于实时网络威胁监测，具备高效的性能表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly-based cyber threat detection using deep learning is on a constantgrowth in popularity for novel cyber-attack detection and forensics. A robust,efficient, and real-time threat detector in a large-scale operationalenterprise network requires high accuracy, high fidelity, and a high throughputmodel to detect malicious activities. Traditional anomaly-based detectionmodels, however, suffer from high computational overhead and low detectionaccuracy, making them unsuitable for real-time threat detection. In this work,we propose LogSHIELD, a highly effective graph-based anomaly detection model inhost data. We present a real-time threat detection approach usingfrequency-domain analysis of provenance graphs. To demonstrate the significanceof graph-based frequency analysis we proposed two approaches. Approach-I uses aGraph Neural Network (GNN) LogGNN and approach-II performs frequency domainanalysis on graph node samples for graph embedding. Both approaches use astatistical clustering algorithm for anomaly detection. The proposed models areevaluated using a large host log dataset consisting of 774M benign logs and375K malware logs. LogSHIELD explores the provenance graph to extractcontextual and causal relationships among logs, exposing abnormal activities.It can detect stealthy and sophisticated attacks with over 98% average AUC andF1 scores. It significantly improves throughput, achieves an average detectionlatency of 0.13 seconds, and outperforms state-of-the-art models in detectiontime.</description>
      <author>example@mail.com (Krishna Chandra Roy, Qian Chen)</author>
      <guid isPermaLink="false">2410.21936v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>HelloMeme: Integrating Spatial Knitting Attentions to Embed High-Level and Fidelity-Rich Conditions in Diffusion Models</title>
      <link>http://arxiv.org/abs/2410.22901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 7 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出一种有效的方法，在文本到图像的基础模型中插入适配器。&lt;h4&gt;目的&lt;/h4&gt;执行复杂的下游任务，同时保持基础模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;优化与2D特征图相关的注意力机制，以增强适配器的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在生成表情视频的任务中验证了该方法，并取得了显著成果。&lt;h4&gt;结论&lt;/h4&gt;该方法为大型文本到图像模型的后训练任务提供了见解，并与SD1.5衍生模型兼容，具备开源社区的价值。&lt;h4&gt;总结&lt;/h4&gt;相关代码将被发布，为进一步研究提供支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/HelloVision/HelloMeme&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose an effective method for inserting adapters into text-to-imagefoundation models, which enables the execution of complex downstream taskswhile preserving the generalization ability of the base model. The core idea ofthis method is to optimize the attention mechanism related to 2D feature maps,which enhances the performance of the adapter. This approach was validated onthe task of meme video generation and achieved significant results. We hopethis work can provide insights for post-training tasks of large text-to-imagemodels. Additionally, as this method demonstrates good compatibility with SD1.5derivative models, it holds certain value for the open-source community.Therefore, we will release the related code(\url{https://songkey.github.io/hellomeme}).</description>
      <author>example@mail.com (Shengkai Zhang, Nianhong Jiao, Tian Li, Chaojie Yang, Chenhui Xue, Boya Niu, Jun Gao)</author>
      <guid isPermaLink="false">2410.22901v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Point cloud-based diffusion models for the Electron-Ion Collider</title>
      <link>http://arxiv.org/abs/2410.22421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高能对撞机实验中，生成模型可用于快速探测器模拟、反折叠、超越标准模型的物理搜索及推断任务。&lt;h4&gt;目的&lt;/h4&gt;扩展先前的生成模型，生成包括所有粒子种类及完整动力学信息的整体对撞事件。&lt;h4&gt;方法&lt;/h4&gt;使用点云和结合图边创建的变换器模块的新的架构，称为点边变换器。还调整基础模型OmniLearn以生成完整的对撞事件。&lt;h4&gt;主要发现&lt;/h4&gt;模型能够很好地学习事件整体约束，如动量守恒和离散量子数，并且在未来的电子-离子对撞机事件中表现良好。&lt;h4&gt;结论&lt;/h4&gt;这种方法可能表明向适应和微调基础模型以满足下游任务的转变，而不是从头开始训练新的模型。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了生成模型在高能对撞机实验中的潜力，尤其是在提高样本生成的精度和效率方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; At high-energy collider experiments, generative models can be used for a widerange of tasks, including fast detector simulations, unfolding, searches ofphysics beyond the Standard Model, and inference tasks. In particular, it hasbeen demonstrated that score-based diffusion models can generate high-fidelityand accurate samples of jets or collider events. This work expands on previousgenerative models in three distinct ways. First, our model is trained togenerate entire collider events, including all particle species with completekinematic information. We quantify how well the model learns event-wideconstraints such as the conservation of momentum and discrete quantum numbers.We focus on the events at the future Electron-Ion Collider, but we expect thatour results can be extended to proton-proton and heavy-ion collisions. Second,previous generative models often relied on image-based techniques. The sparsityof the data can negatively affect the fidelity and sampling time of the model.We address these issues using point clouds and a novel architecture combiningedge creation with transformer modules called Point Edge Transformers. Third,we adapt the foundation model OmniLearn, to generate full collider events. Thisapproach may indicate a transition toward adapting and fine-tuning foundationmodels for downstream tasks instead of training new models from scratch.</description>
      <author>example@mail.com (Jack Y. Araz, Vinicius Mikuni, Felix Ringer, Nobuo Sato, Fernando Torales Acosta, Richard Whitehill)</author>
      <guid isPermaLink="false">2410.22421v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DECRL: A Deep Evolutionary Clustering Jointed Temporal Knowledge Graph Representation Learning Approach</title>
      <link>http://arxiv.org/abs/2410.22631v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024, 17 pages, and 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间知识图谱（TKG）表示学习旨在将随时间演变的实体和关系映射到连续低维向量空间中的嵌入表示。&lt;h4&gt;目的&lt;/h4&gt;提出一种深度演化聚类联合时间知识图谱表示学习的方法（DECRL），以捕捉TKG中高阶相关性的时间演变。&lt;h4&gt;方法&lt;/h4&gt;引入深度演化聚类模块来捕捉实体之间的高阶相关性；采用聚类感知的无监督对齐机制，确保跨时间戳的软重叠聚类的精确一对一对齐；引入隐式相关编码器，捕捉在全局图引导下任意两组聚类之间的潜在相关性。&lt;h4&gt;主要发现&lt;/h4&gt;在七个真实世界数据集上的广泛实验表明，DECRL在平均上在MRR、Hits@1、Hits@3和Hits@10方面比最佳基线分别提高了9.53%、12.98%、10.42%和14.68%。&lt;h4&gt;结论&lt;/h4&gt;DECRL在时间知识图谱表示学习中实现了最先进的性能，有效捕捉了高阶相关性的时间演变。&lt;h4&gt;总结&lt;/h4&gt;DECRL方法在处理TKG的时间演变方面具有显著优势，展示了其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Temporal Knowledge Graph (TKG) representation learning aims to map temporalevolving entities and relations to embedded representations in a continuouslow-dimensional vector space. However, existing approaches cannot capture thetemporal evolution of high-order correlations in TKGs. To this end, we proposea Deep Evolutionary Clustering jointed temporal knowledge graph RepresentationLearning approach (DECRL). Specifically, a deep evolutionary clustering moduleis proposed to capture the temporal evolution of high-order correlations amongentities. Furthermore, a cluster-aware unsupervised alignment mechanism isintroduced to ensure the precise one-to-one alignment of soft overlappingclusters across timestamps, thereby maintaining the temporal smoothness ofclusters. In addition, an implicit correlation encoder is introduced to capturelatent correlations between any pair of clusters under the guidance of a globalgraph. Extensive experiments on seven real-world datasets demonstrate thatDECRL achieves the state-of-the-art performances, outperforming the bestbaseline by an average of 9.53%, 12.98%, 10.42%, and 14.68% in MRR, Hits@1,Hits@3, and Hits@10, respectively.</description>
      <author>example@mail.com (Qian Chen, Ling Chen)</author>
      <guid isPermaLink="false">2410.22631v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning</title>
      <link>http://arxiv.org/abs/2410.21872v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;早期准确诊断脑肿瘤对提高患者生存率至关重要，但由于脑肿瘤类型多样和形态特征复杂，检测与分类具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;研究预训练模型在脑肿瘤分类中的应用，特别关注Mamba模型的部署。&lt;h4&gt;方法&lt;/h4&gt;微调多个主流迁移学习模型，并将其应用于脑肿瘤的多类分类，与从头训练的模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;Vim模型在独立测试集上实现了100%的分类准确率，展示了迁移学习在医学影像领域的显著优势。&lt;h4&gt;结论&lt;/h4&gt;Vim模型相比现有的先进模型更轻量、高效且准确，为临床应用提供了新视角，且所提出的框架可广泛应用于其他医学影像分类问题。&lt;h4&gt;总结&lt;/h4&gt;本研究强调迁移学习在脑肿瘤分类中的有效性，展示了新模型的潜力和广泛适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Early and accurate diagnosis of brain tumors is crucial for improving patientsurvival rates. However, the detection and classification of brain tumors arechallenging due to their diverse types and complex morphologicalcharacteristics. This study investigates the application of pre-trained modelsfor brain tumor classification, with a particular focus on deploying the Mambamodel. We fine-tuned several mainstream transfer learning models and appliedthem to the multi-class classification of brain tumors. By comparing thesemodels to those trained from scratch, we demonstrated the significantadvantages of transfer learning, especially in the medical imaging field, whereannotated data is often limited. Notably, we introduced the Vision Mamba (Vim),a novel network architecture, and applied it for the first time in brain tumorclassification, achieving exceptional classification accuracy. Experimentalresults indicate that the Vim model achieved 100% classification accuracy on anindependent test set, emphasizing its potential for tumor classification tasks.These findings underscore the effectiveness of transfer learning in brain tumorclassification and reveal that, compared to existing state-of-the-art models,the Vim model is lightweight, efficient, and highly accurate, offering a newperspective for clinical applications. Furthermore, the framework proposed inthis study for brain tumor classification, based on transfer learning and theVision Mamba model, is broadly applicable to other medical imagingclassification problems.</description>
      <author>example@mail.com (Yinyi Lai, Anbo Cao, Yuan Gao, Jiaqi Shang, Zongyu Li, Jia Guo)</author>
      <guid isPermaLink="false">2410.21872v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ERGO-ML: A continuous organization of the X-ray galaxy cluster population in TNG-Cluster with contrastive learning</title>
      <link>http://arxiv.org/abs/2410.22416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Please see more results from TNG-Cluster on astro-ph this week from
  Rohr+ and Prunier+&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;星系团的物理特性反映了潜在引力场、合并及与其它光晕和卫星星系的强相互作用，以及来自超新星和超大质量黑洞的星系反馈。&lt;h4&gt;目的&lt;/h4&gt;考虑ICM的X射线发射图像中的全部信息内容，而不仅仅是传统的总结统计。&lt;h4&gt;方法&lt;/h4&gt;使用最近邻对比学习(NNCLR)识别并填充低维表示空间，以352个星系团的理想化X射线图像为基础，生成约8000幅图像。&lt;h4&gt;主要发现&lt;/h4&gt;表示空间形成了从放松到合并物体的连续分布，并显示出与红移、光晕质量、气体质量、恒星质量和超大质量黑洞质量等的明显趋势。&lt;h4&gt;结论&lt;/h4&gt;8维表示可以用于预测星系团的多种属性、寻找类比并识别物理属性之间的相关性，暗示因果关系。&lt;h4&gt;总结&lt;/h4&gt;对比学习是一个强大的工具，能够仅凭图像特征表征星系团，并推导出它们的物理特性和形成历史的约束。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The physical properties of the intracluster medium (ICM) reflect signaturesof the underlying gravitational potential, mergers and strong interactions withother halos and satellite galaxies, as well as galactic feedback fromsupernovae and supermassive black holes (SMBHs). Traditionally, clusters havebeen characterized in terms of summary statistics, such as halo mass, X-rayluminosity, cool-core state, luminosity of AGN, and number of mergingcomponents. In this paper of the Extracting Reality from Galaxy Observableswith Machine Learning series (ERGO-ML), we instead consider the fullinformation content available in maps of X-ray emission from the ICM. We employNearest Neighbour Contrastive Learning (NNCLR) to identify and populate alow-dimensional representation space of such images. Using idealized X-ray mapsof the 352 clusters of the TNG-Cluster cosmological magnetohydrodynamicalsimulation suite, we take three orthogonal projections of each cluster at eightsnapshots within the redshift range $0\leq z&lt;1$, resulting in a dataset of$\sim$8,000 images. Our findings reveal that this representation space forms acontinuous distribution from relaxed to merging objects, and fromcentrally-peaked to flat emission profiles. The representation also exhibitsclear trends with redshift, with halo, gas, stellar, and SMBH mass, with timesince a last major merger, and with indicators of dynamical state. We show thatan 8-dimensional representation can be used to predict a variety of clusterproperties, find analogs, and identify correlations between physicalproperties, thereby suggesting causal relationships. Our analysis demonstratesthat contrastive learning is a powerful tool for characterizing galaxy clustersfrom their images alone, allowing us to derive constraints on their physicalproperties and formation histories using cosmological hydrodynamical galaxysimulations.</description>
      <author>example@mail.com (Urmila Chadayammuri, Lukas Eisert, Annalisa Pillepich, Katrin Lehle, Mohammadreza Ayromlou, Dylan Nelson)</author>
      <guid isPermaLink="false">2410.22416v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>CopRA: A Progressive LoRA Training Strategy</title>
      <link>http://arxiv.org/abs/2410.22911v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in UniReps Workshop (Extended Abstract Track), NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;低秩适应（LoRA）是一种高效的参数微调基础模型的技术。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的渐进训练策略，以解决LoRA在合并和剪枝任务中的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入随机层丢弃的训练策略，并优化每层LoRA参数的Shapley值，将每层视为合作游戏中的参与者，称之为合作LoRA（CopRA）。&lt;h4&gt;主要发现&lt;/h4&gt;使用CopRA训练的参数展现出线性模式连接性，支持高效的模型合并。&lt;h4&gt;结论&lt;/h4&gt;CopRA为联邦学习和多任务学习开辟了新途径，同时在剪枝任务中表现优越。&lt;h4&gt;总结&lt;/h4&gt;CopRA通过优化模型训练过程，改善了LoRA在特定任务中的表现，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) is a parameter-efficient technique for rapidlyfine-tuning foundation models. In standard LoRA training dynamics, models tendto quickly converge to a local optimum near the initialization. However, thislocal optimum may not be ideal for out-of-distribution data or tasks such asmerging and pruning. In this work, we propose a novel progressive trainingstrategy for LoRA with random layer dropping. This strategy also optimizes theShapley value of LoRA parameters in each layer, treating each layer as a playerin a cooperative game. We refer to this method as Cooperative LoRA (CopRA). Ourexperimental results demonstrate that parameters trained with CopRA exhibitlinear mode connectivity, which enables efficient model merging. This alsopaves the way for federated learning and multi-task learning via LoRA merging.Additionally, by optimizing the Shapley value, CopRA shows superior performancein pruning tasks.</description>
      <author>example@mail.com (Zhan Zhuang, Xiequn Wang, Yulong Zhang, Wei Li, Yu Zhang, Ying Wei)</author>
      <guid isPermaLink="false">2410.22911v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Feature distribution Adaptation Network for Speech Emotion Recognition</title>
      <link>http://arxiv.org/abs/2410.22023v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态语音情感识别问题具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的深度归纳迁移学习框架，称为特征分布适应网络，以提升语音情感识别的表现。&lt;h4&gt;方法&lt;/h4&gt;利用预训练的ResNet-34进行面部表情图像和声学梅尔谱特征提取，采用交叉注意力机制建模多模态特征的内在相似性，并通过前馈网络高效执行多模态特征分布适应，扩展使用局部最大均值差损失。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基准数据集上的实验结果表明，该模型相比现有方法具有优秀的性能。&lt;h4&gt;结论&lt;/h4&gt;所提方法有效改善了多模态语音情感识别的效果。&lt;h4&gt;总结&lt;/h4&gt;通过深度迁移学习策略，成功对齐视觉和音频特征分布，实现情感的一致性表示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shaokai1209/fdan&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose a novel deep inductive transfer learning framework,named feature distribution adaptation network, to tackle the challengingmulti-modal speech emotion recognition problem. Our method aims to use deeptransfer learning strategies to align visual and audio feature distributions toobtain consistent representation of emotion, thereby improving the performanceof speech emotion recognition. In our model, the pre-trained ResNet-34 isutilized for feature extraction for facial expression images and acoustic Melspectrograms, respectively. Then, the cross-attention mechanism is introducedto model the intrinsic similarity relationships of multi-modal features.Finally, the multi-modal feature distribution adaptation is performedefficiently with feed-forward network, which is extended using the localmaximum mean discrepancy loss. Experiments are carried out on two benchmarkdatasets, and the results demonstrate that our model can achieve excellentperformance compared with existing ones.</description>
      <author>example@mail.com (Shaokai Li, Yixuan Ji, Peng Song, Haoqin Sun, Wenming Zheng)</author>
      <guid isPermaLink="false">2410.22023v2</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Few-shot Open Relation Extraction with Gaussian Prototype and Adaptive Margin</title>
      <link>http://arxiv.org/abs/2410.20320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  30 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Few-shot relation extraction with none-of-the-above (FsRE with NOTA) 旨在处理未知类别的少样本场景，这比传统的少样本关系提取任务更具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，解决少样本过拟合和NOTA边界混淆问题，提高分类准确性。&lt;h4&gt;方法&lt;/h4&gt;提出基于高斯原型和自适应边距的GPAM框架，包含三个模块：半真实表示、GMM原型度量学习和决策边界学习。&lt;h4&gt;主要发现&lt;/h4&gt;GPAM通过去偏信息增强和高斯空间距离测量，获得了更好的表示，并通过自适应边距和负采样学习了更准确的分类边界。&lt;h4&gt;结论&lt;/h4&gt;GPAM在FewRel数据集上的实验结果表明，超越了之前的原型方法，实现了最先进的性能。&lt;h4&gt;总结&lt;/h4&gt;GPAM框架有效解决了FsRE with NOTA中的挑战，展示了其在少样本关系提取中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot relation extraction with none-of-the-above (FsRE with NOTA) aims atpredicting labels in few-shot scenarios with unknown classes. FsRE with NOTA ismore challenging than the conventional few-shot relation extraction task, sincethe boundaries of unknown classes are complex and difficult to learn.Meta-learning based methods, especially prototype-based methods, are themainstream solutions to this task. They obtain the classification boundary bylearning the sample distribution of each class. However, their performance islimited because few-shot overfitting and NOTA boundary confusion lead tomisclassification between known and unknown classes. To this end, we propose anovel framework based on Gaussian prototype and adaptive margin named GPAM forFsRE with NOTA, which includes three modules, semi-factual representation,GMM-prototype metric learning and decision boundary learning. The first twomodules obtain better representations to solve the few-shot problem throughdebiased information enhancement and Gaussian space distance measurement. Thethird module learns more accurate classification boundaries and prototypesthrough adaptive margin and negative sampling. In the training procedure ofGPAM, we use contrastive learning loss to comprehensively consider the effectsof range and margin on the classification of known and unknown classes toensure the model's stability and robustness. Sufficient experiments andablations on the FewRel dataset show that GPAM surpasses previous prototypemethods and achieves state-of-the-art performance.</description>
      <author>example@mail.com (Tianlin Guo, Lingling Zhang, Jiaxin Wang, Yuokuo Lei, Yifei Li, Haofen Wang, Jun Liu)</author>
      <guid isPermaLink="false">2410.20320v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms</title>
      <link>http://arxiv.org/abs/2410.23144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://source.plus/pd12m&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;PD12M是一个包含1240万张高质量公共领域和CC0许可图像的数据集。&lt;h4&gt;目的&lt;/h4&gt;旨在为文本到图像模型的训练提供足够的数据。&lt;h4&gt;方法&lt;/h4&gt;通过Source.Plus平台引入社区驱动的数据集治理机制。&lt;h4&gt;主要发现&lt;/h4&gt;PD12M是迄今为止最大的公共领域图像文本数据集，能够有效训练基础模型，同时减少版权问题。&lt;h4&gt;结论&lt;/h4&gt;这种数据集的设计有助于长期支持可重复性和减少潜在伤害。&lt;h4&gt;总结&lt;/h4&gt;PD12M为文本到图像模型的研究提供了重要资源，并促进了数据集的治理和可持续发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Public Domain 12M (PD12M), a dataset of 12.4 million high-qualitypublic domain and CC0-licensed images with synthetic captions, designed fortraining text-to-image models. PD12M is the largest public domain image-textdataset to date, with sufficient size to train foundation models whileminimizing copyright concerns. Through the Source.Plus platform, we alsointroduce novel, community-driven dataset governance mechanisms that reduceharm and support reproducibility over time.</description>
      <author>example@mail.com (Jordan Meyer, Nick Padgett, Cullen Miller, Laura Exline)</author>
      <guid isPermaLink="false">2410.23144v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>The PV-ALE Dataset: Enhancing Apple Leaf Disease Classification Through Transfer Learning with Convolutional Neural Networks</title>
      <link>http://arxiv.org/abs/2410.22490v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  To appear in th Sixth International Conference on Soft Computing and
  its Engineering Applications (icSoftComp2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全球食品安全形势不断变化，准确可靠的作物疾病诊断需求日益迫切。&lt;h4&gt;目的&lt;/h4&gt;扩展广泛使用的PlantVillage数据集，增加苹果叶病害类别，以增强多样性和复杂性。&lt;h4&gt;方法&lt;/h4&gt;在原始和扩展数据集上进行实验评估，检验现有模型的表现。&lt;h4&gt;主要发现&lt;/h4&gt;现有模型在新增加的类别上表现不佳，凸显了对更强大和可推广的计算机视觉模型的需求。&lt;h4&gt;结论&lt;/h4&gt;在原始和扩展数据集上分别获得了99.63%和97.87%的测试F1分数，提供了更具挑战性和多样化的基准。&lt;h4&gt;总结&lt;/h4&gt;扩展数据集可用于未来研究，推动准确可靠的苹果叶病害识别模型的发展，数据集可在Kaggle上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As the global food security landscape continues to evolve, the need foraccurate and reliable crop disease diagnosis has never been more pressing. Toaddress global food security concerns, we extend the widely used PlantVillagedataset with additional apple leaf disease classes, enhancing diversity andcomplexity. Experimental evaluations on both original and extended datasetsreveal that existing models struggle with the new additions, highlighting theneed for more robust and generalizable computer vision models. Test F1 scoresof 99.63% and 97.87% were obtained on the original and extended datasets,respectively. Our study provides a more challenging and diverse benchmark,paving the way for the development of accurate and reliable models foridentifying apple leaf diseases under varying imaging conditions. The expandeddataset is available athttps://www.kaggle.com/datasets/akinyemijoseph/apple-leaf-disease-dataset-6-classes-v2enabling future research to build upon our findings.</description>
      <author>example@mail.com (Joseph Damilola Akinyemi, Kolawole John Adebayo)</author>
      <guid isPermaLink="false">2410.22490v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FISC: Federated Domain Generalization via Interpolative Style Transfer and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.22622v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联邦学习（FL）在保护隐私和促进协作学习方面显示出潜力，但大多数现有解决方案仅关注来自单一领域的私有数据。&lt;h4&gt;目的&lt;/h4&gt;解决客户端数据来自不同领域（领域转移）时导致的性能下降问题。&lt;h4&gt;方法&lt;/h4&gt;引入FISC，一种新的FL领域泛化范式，通过提取局部风格的插值风格并采用对比学习，处理更复杂的领域分布。&lt;h4&gt;主要发现&lt;/h4&gt;FISC在多个数据集（包括PACS、Office-Home和IWildCam）上的实验结果显示，其性能超越了现有的最先进方法，未见领域的准确率提高范围为3.64%至57.22%。&lt;h4&gt;结论&lt;/h4&gt;FISC能够有效处理领域异质性和客户端采样问题，提供多领域表示和无偏收敛目标。&lt;h4&gt;总结&lt;/h4&gt;FISC是一种创新的方法，提升了联邦学习在不同领域数据上的性能，代码可在指定链接获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Learning (FL) shows promise in preserving privacy and enablingcollaborative learning. However, most current solutions focus on private datacollected from a single domain. A significant challenge arises when client datacomes from diverse domains (i.e., domain shift), leading to poor performance onunseen domains. Existing Federated Domain Generalization approaches addressthis problem but assume each client holds data for an entire domain, limitingtheir practicality in real-world scenarios with domain-based heterogeneity andclient sampling.  To overcome this, we introduce FISC, a novel FL domain generalizationparadigm that handles more complex domain distributions across clients. FISCenables learning across domains by extracting an interpolative style from localstyles and employing contrastive learning. This strategy gives clientsmulti-domain representations and unbiased convergent targets. Empirical resultson multiple datasets, including PACS, Office-Home, and IWildCam, show FISCoutperforms state-of-the-art (SOTA) methods. Our method achieves accuracyimprovements ranging from 3.64% to 57.22% on unseen domains. Our code isavailable at https://anonymous.4open.science/r/FISC-AAAI-16107.</description>
      <author>example@mail.com (Dung Thuy Nguyen, Taylor T. Johnson, Kevin Leach)</author>
      <guid isPermaLink="false">2410.22622v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Machine Learning for Detecting and Locating Human-Made Objects in 3D Point Cloud</title>
      <link>http://arxiv.org/abs/2410.20006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D点云是由航空LiDAR系统收集的非结构化、稀疏和不规则的数据集，包含每个点的经度、纬度和高程信息。&lt;h4&gt;目的&lt;/h4&gt;检测和识别自然树木结构中的人造物体。&lt;h4&gt;方法&lt;/h4&gt;研究分为三个阶段：地面过滤、局部信息提取（LIE）和聚类。地面过滤使用一种称为单侧回归（OSR）的统计方法，LIE阶段采用基于Hessian矩阵的核方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的地面过滤方法优于先前的技术，LIE方法成功区分树木和人造物体的点。&lt;h4&gt;结论&lt;/h4&gt;Hessian矩阵有效捕捉了树木和人造物体之间的区别，LiDAR点的三维分布与人造物体的二维分布相对应。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新的方法来提高在复杂地形中对点云数据中人造物体的检测和识别能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A 3D point cloud is an unstructured, sparse, and irregular dataset, typicallycollected by airborne LiDAR systems over a geological region. Laser pulsesemitted from these systems reflect off objects both on and above the ground,resulting in a dataset containing the longitude, latitude, and elevation ofeach point, as well as information about the corresponding laser pulsestrengths. A widely studied research problem, addressed in many previous works,is ground filtering, which involves partitioning the points into ground andnon-ground subsets. This research introduces a novel task: detecting andidentifying human-made objects amidst natural tree structures. This task isperformed on the subset of non-ground points derived from the ground filteringstage. Marked Point Fields (MPFs) are used as models well-suited to thesetasks. The proposed methodology consists of three stages: ground filtering,local information extraction (LIE), and clustering. In the ground filteringstage, a statistical method called One-Sided Regression (OSR) is introduced,addressing the limitations of prior ground filtering methods on uneventerrains. In the LIE stage, unsupervised learning methods are lacking. Tomitigate this, a kernel-based method for the Hessian matrix of the MPF isdeveloped. In the clustering stage, the Gaussian Mixture Model (GMM) is appliedto the results of the LIE stage to partition the non-ground points into treesand human-made objects. The underlying assumption is that LiDAR points fromtrees exhibit a three-dimensional distribution, while those from human-madeobjects follow a two-dimensional distribution. The Hessian matrix of the MPFeffectively captures this distinction. Experimental results demonstrate thatthe proposed ground filtering method outperforms previous techniques, and theLIE method successfully distinguishes between points representing trees andhuman-made objects.</description>
      <author>example@mail.com (Hong Zhao, Huyunting Huang, Tonglin Zhang, Baijian Yang, Jin Wei-Kocsis, Songlin Fei)</author>
      <guid isPermaLink="false">2410.20006v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Vision Paper: Designing Graph Neural Networks in Compliance with the European Artificial Intelligence Act</title>
      <link>http://arxiv.org/abs/2410.22120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;欧盟人工智能法案为人工智能和机器学习系统的发展与监管提供了全面的指导，尤其对图神经网络（GNNs）有重大影响。&lt;h4&gt;目的&lt;/h4&gt;探讨人工智能法案对图神经网络所带来的独特挑战，并提出相应的应对策略。&lt;h4&gt;方法&lt;/h4&gt;分析法案对数据管理、数据治理、鲁棒性、人类监督和隐私的要求，并研究这些要求对GNN训练的影响。&lt;h4&gt;主要发现&lt;/h4&gt;强调了在GNN中公平采样策略和有效可解释性技术的重要性，分析了偏见、鲁棒性、可解释性和隐私的相关问题。&lt;h4&gt;结论&lt;/h4&gt;为GNN在新立法框架下提供了具体指导，填补了研究空白，并识别了未来研究的开放问题。&lt;h4&gt;总结&lt;/h4&gt;本研究为GNN的合规性提出了方法，并指出了在新的法律要求下的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The European Union's Artificial Intelligence Act (AI Act) introducescomprehensive guidelines for the development and oversight of ArtificialIntelligence (AI) and Machine Learning (ML) systems, with significantimplications for Graph Neural Networks (GNNs). This paper addresses the uniquechallenges posed by the AI Act for GNNs, which operate on complexgraph-structured data. The legislation's requirements for data management, datagovernance, robustness, human oversight, and privacy necessitate tailoredstrategies for GNNs. Our study explores the impact of these requirements on GNNtraining and proposes methods to ensure compliance. We provide an in-depthanalysis of bias, robustness, explainability, and privacy in the context ofGNNs, highlighting the need for fair sampling strategies and effectiveinterpretability techniques. Our contributions fill the research gap byoffering specific guidance for GNNs under the new legislative framework andidentifying open questions and future research directions.</description>
      <author>example@mail.com (Barbara Hoffmann, Jana Vatter, Ruben Mayer)</author>
      <guid isPermaLink="false">2410.22120v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Auxiliary Task Relevance for Enhanced Industrial Fault Diagnosis through Curriculum Meta-learning</title>
      <link>http://arxiv.org/abs/2410.20351v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器故障的准确诊断对智能制造的操作安全至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决深度学习在设备故障实例中标注训练数据稀缺的问题，从而提升故障诊断的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种相关任务意识课程元学习（RT-ACM）框架，灵感来源于人类认知学习过程，考虑辅助工作条件的相关性，并采用“先易后难”的课程采样原则。&lt;h4&gt;主要发现&lt;/h4&gt;RT-ACM框架在两个真实数据集上的实验结果表明其优越性。&lt;h4&gt;结论&lt;/h4&gt;RT-ACM框架显著改善了故障诊断模型的收敛状态，有助于克服现有方法在变动工作条件下的不足。&lt;h4&gt;总结&lt;/h4&gt;通过引入RT-ACM框架，可以更有效地进行机器故障诊断，提升智能制造的安全性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The accurate diagnosis of machine breakdowns is crucial for maintainingoperational safety in smart manufacturing. Despite the promise shown by deeplearning in automating fault identification, the scarcity of labeled trainingdata, particularly for equipment failure instances, poses a significantchallenge. This limitation hampers the development of robust classificationmodels. Existing methods like model-agnostic meta-learning (MAML) do notadequately address variable working conditions, affecting knowledge transfer.To address these challenges, a Related Task Aware Curriculum Meta-learning(RT-ACM) enhanced fault diagnosis framework is proposed in this paper, inspiredby human cognitive learning processes. RT-ACM improves training by consideringthe relevance of auxiliary working conditions, adhering to the principle of``paying more attention to more relevant knowledge", and focusing on ``easierfirst, harder later" curriculum sampling. This approach aids the meta-learnerin achieving a superior convergence state. Extensive experiments on tworeal-world datasets demonstrate the superiority of RT-ACM framework.</description>
      <author>example@mail.com (Jinze Wang, Tiehua Zhang, Boon Xian Chai, Adriano Di Pietro, Dimitrios Georgakopoulos, Jiong Jin)</author>
      <guid isPermaLink="false">2410.20351v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DECADE: Towards Designing Efficient-yet-Accurate Distance Estimation Modules for Collision Avoidance in Mobile Advanced Driver Assistance Systems</title>
      <link>http://arxiv.org/abs/2410.19336v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 17 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能手机和移动设备的普及为每个人提供了使用低成本机器学习/深度学习模型的高级驾驶辅助系统（ADAS）应用的机会，以增强道路安全。&lt;h4&gt;目的&lt;/h4&gt;针对移动ADAS中的碰撞避免的关键功能，提出一种轻量级的距离估计模型DECADE。&lt;h4&gt;方法&lt;/h4&gt;DECADE处理每个检测器输出，而不是构建逐像素的深度/视差图，并提出一个姿态估计DNN来估计检测的自我中心方向，以辅助距离估计DNN进行预测。&lt;h4&gt;主要发现&lt;/h4&gt;与YOLO目标检测器结合并在KITTI 3D目标检测数据集上进行微调后，提出的模块在距离范围0-150米内实现了1.38米的平均绝对误差和7.3%的平均相对误差，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该评估方案不仅评估了类别性能，还特别在0-70米的关键范围内评估了距离准确性。&lt;h4&gt;总结&lt;/h4&gt;DECADE模型通过快速距离估计扩展了对象检测的能力，提高了移动ADAS的实时应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of smartphones and other mobile devices provides a uniqueopportunity to make Advanced Driver Assistance Systems (ADAS) accessible toeveryone in the form of an application empowered by low-cost Machine/DeepLearning (ML/DL) models to enhance road safety. For the critical feature ofCollision Avoidance in Mobile ADAS, lightweight Deep Neural Networks (DNN) forobject detection exist, but conventional pixel-wise depth/distance estimationDNNs are vastly more computationally expensive making them unsuitable for areal-time application on resource-constrained devices. In this paper, wepresent a distance estimation model, DECADE, that processes each detectoroutput instead of constructing pixel-wise depth/disparity maps. In it, wepropose a pose estimation DNN to estimate allocentric orientation of detectionsto supplement the distance estimation DNN in its prediction of distance usingbounding box features. We demonstrate that these modules can be attached to anydetector to extend object detection with fast distance estimation. Evaluationof the proposed modules with attachment to and fine-tuning on the outputs ofthe YOLO object detector on the KITTI 3D Object Detection dataset achievesstate-of-the-art performance with 1.38 meters in Mean Absolute Error and 7.3%in Mean Relative Error in the distance range of 0-150 meters. Our extensiveevaluation scheme not only evaluates class-wise performance, but also evaluatesrange-wise accuracy especially in the critical range of 0-70m.</description>
      <author>example@mail.com (Muhammad Zaeem Shahzad, Muhammad Abdullah Hanif, Muhammad Shafique)</author>
      <guid isPermaLink="false">2410.19336v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Towards Neural-Network-based optical temperature sensing of Semiconductor Membrane External Cavity Laser</title>
      <link>http://arxiv.org/abs/2410.22528v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种基于机器学习的非接触方法，用于通过激光发射确定激光增益介质的温度。&lt;h4&gt;目的&lt;/h4&gt;利用训练好的少层神经网络模型预测激光设备的特性，仅依赖光谱数据。&lt;h4&gt;方法&lt;/h4&gt;采用前馈神经网络训练，通过可见光/近红外光微型光谱仪记录的数据进行预测，并使用光纤光谱仪获取大量标记的强度数据。&lt;h4&gt;主要发现&lt;/h4&gt;预训练的深度神经网络实现了快速、可靠且简单的激光系统温度推断，且不需要额外的光学诊断或温度传感器。&lt;h4&gt;结论&lt;/h4&gt;通过微型移动光谱仪和远程检测能力，温度推断能力可以通过迁移学习方法适用于各种激光二极管，同时在不同应用场景下通过减少网络深度来节省计算成本。&lt;h4&gt;总结&lt;/h4&gt;该方法达到了亚百分比精度的温度推断，同时在准确性与计算成本之间取得了平衡。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A machine-learning non-contact method to determine the temperature of a lasergain medium via its laser emission with a trained few-layer neural net model ispresented. The training of the feed-forward Neural Network (NN) enables theprediction of the device's properties solely from spectral data, here recordedby visible-/nearinfrared-light compact micro-spectrometers for both a diodepump laser and optically-pumped gain membrane of a semiconductor disk laser.Fiber spectrometers are used for the acquisition of large quantities oflabelled intensity data, which can afterwards be used for the predictionprocess. Such pretrained deep NNs enable a fast, reliable and easy way to inferthe temperature of a laser system such as our Membrane External Cavity Laser,at a later monitoring stage without the need of additional optical diagnosticsor read-out temperature sensors. With the miniature mobile spectrometer and theremote detection ability, the temperature inference capability can be adaptedfor various laser diodes using transfer learning methods with pretrainedmodels. Here, mean-square-error values for the temperature inferencecorresponding to sub-percent accuracy of our sensor scheme are reached, whilecomputational cost can be saved by reducing the network depth at the heredisplayed cost of accuracy, as appropriate for different application scenarios.</description>
      <author>example@mail.com (Jakob Mannstadt, Arash Rahimi-Iman)</author>
      <guid isPermaLink="false">2410.22528v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning and Adversarial Disentanglement for Privacy-Preserving Task-Oriented Semantic Communications</title>
      <link>http://arxiv.org/abs/2410.22784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to EEE Journal on Selected Areas in Communications (JSAC):
  Intelligent Communications for Real-Time Computer Vision (Comm4CV)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;任务导向的语义通信系统在高效智能数据传输方面表现出色，但现有方法难以完全区分任务相关和无关的信息，导致隐私问题和性能不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种信息瓶颈方法CLAD，以提高任务相关信息的传输效率。&lt;h4&gt;方法&lt;/h4&gt;CLAD结合对比学习来捕捉任务相关特征，并采用对抗解耦来丢弃任务无关信息。同时，引入信息保留指数（IRI）来评估编码特征的最小性和信息量。&lt;h4&gt;主要发现&lt;/h4&gt;CLAD在任务表现、隐私保护和IRI方面优于现有最先进的方法，预测性能提高约2.5-3%，IRI减少77-90%，对抗准确率降低57-76%。&lt;h4&gt;结论&lt;/h4&gt;CLAD有效提升了任务导向语义通信系统的性能，同时增强了隐私保护。&lt;h4&gt;总结&lt;/h4&gt;CLAD方法通过有效解耦和对比学习，在任务相关信息传输中取得了显著进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/omarerak/clad&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Task-oriented semantic communication systems have emerged as a promisingapproach to achieving efficient and intelligent data transmission, where onlyinformation relevant to a specific task is communicated. However, existingmethods struggle to fully disentangle task-relevant and task-irrelevantinformation, leading to privacy concerns and subpar performance. To addressthis, we propose an information-bottleneck method, named CLAD (contrastivelearning and adversarial disentanglement). CLAD leverages contrastive learningto effectively capture task-relevant features while employing adversarialdisentanglement to discard task-irrelevant information. Additionally, due tothe lack of reliable and reproducible methods to gain insight into theinformativeness and minimality of the encoded feature vectors, we introduce anew technique to compute the information retention index (IRI), a comparativemetric used as a proxy for the mutual information between the encoded featuresand the input, reflecting the minimality of the encoded features. The IRIquantifies the minimality and informativeness of the encoded feature vectorsacross different task-oriented communication techniques. Our extensiveexperiments demonstrate that CLAD outperforms state-of-the-art baselines interms of task performance, privacy preservation, and IRI. CLAD achieves apredictive performance improvement of around 2.5-3%, along with a 77-90%reduction in IRI and a 57-76% decrease in adversarial accuracy.</description>
      <author>example@mail.com (Omar Erak, Omar Alhussein, Wen Tong)</author>
      <guid isPermaLink="false">2410.22784v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning Approaches for Improving Detection of Unseen Speech Deepfakes</title>
      <link>http://arxiv.org/abs/2410.20578v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, accepted to the IEEE Spoken Language Technology Workshop
  (SLT) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的语音深伪检测方法对已知攻击表现良好，但对未见攻击的泛化仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发能够对未见攻击进行泛化的系统，以应对社交媒体上语音深伪的日益增长。&lt;h4&gt;方法&lt;/h4&gt;采用元学习的视角，旨在学习攻击不变特征，以适应仅有少量样本的未见攻击。&lt;h4&gt;主要发现&lt;/h4&gt;在InTheWild数据集上，使用仅96个未见样本，EER从21.67%改善至10.42%。&lt;h4&gt;结论&lt;/h4&gt;持续的少量样本适应确保系统保持最新状态。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了元学习在语音深伪检测中的应用潜力，尤其是在面对未见攻击时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current speech deepfake detection approaches perform satisfactorily againstknown adversaries; however, generalization to unseen attacks remains an openchallenge. The proliferation of speech deepfakes on social media underscoresthe need for systems that can generalize to unseen attacks not observed duringtraining. We address this problem from the perspective of meta-learning, aimingto learn attack-invariant features to adapt to unseen attacks with very fewsamples available. This approach is promising since generating of a high-scaletraining dataset is often expensive or infeasible. Our experiments demonstratedan improvement in the Equal Error Rate (EER) from 21.67% to 10.42% on theInTheWild dataset, using just 96 samples from the unseen dataset. Continuousfew-shot adaptation ensures that the system remains up-to-date.</description>
      <author>example@mail.com (Ivan Kukanov, Janne Laakkonen, Tomi Kinnunen, Ville Hautamäki)</author>
      <guid isPermaLink="false">2410.20578v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Age of Information-Oriented Probabilistic Link Scheduling for Device-to-Device Networks</title>
      <link>http://arxiv.org/abs/2410.20196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 7 figures, accepted by IEEE WiOpt24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;论文关注于通过年龄感知的链路调度优化设备间（D2D）网络中的信息长期平均年龄（AoI）。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来应对所有D2D链路的AoI动态交织问题，寻找最佳调度策略。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于年龄感知的静态随机策略，通过链路的AoI和信道状态信息计算每个时间槽的调度概率，并采用Lyapunov优化框架来最小化每个时间槽的Lyapunov漂移。&lt;h4&gt;主要发现&lt;/h4&gt;针对每个时间槽的最小化问题由于链路间干扰是非凸的，使用消息传递神经网络（MPNN）来优化该问题，并展示了该方法的优越性能。&lt;h4&gt;结论&lt;/h4&gt;提出的年龄感知静态随机策略在仿真中表现优于基准方法，验证了该方法的可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本论文通过新颖的策略和优化方法，提升了D2D网络中信息更新的效率，为未来的研究提供了参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper focuses on optimizing the long-term average age of information(AoI) in device-to-device (D2D) networks through age-aware link scheduling. Theproblem is naturally formulated as a Markov decision process (MDP). However,finding the optimal policy for the formulated MDP in its original form ischallenging due to the intertwined AoI dynamics of all D2D links. To addressthis, we propose an age-aware stationary randomized policy that determines theprobability of scheduling each link in each time slot based on the AoI of alllinks and the statistical channel state information among all transceivers. Byemploying the Lyapunov optimization framework, our policy aims to minimize theLyapunov drift in every time slot. Nonetheless, this per-slot minimizationproblem is nonconvex due to cross-link interference in D2D networks, posingsignificant challenges for real-time decision-making. After analyzing thepermutation equivariance property of the optimal solutions to the per-slotproblem, we apply a message passing neural network (MPNN), a type of graphneural network that also exhibits permutation equivariance, to optimize theper-slot problem in an unsupervised learning manner. Simulation resultsdemonstrate the superior performance of the proposed age-aware stationaryrandomized policy over baselines and validate the scalability of our method.</description>
      <author>example@mail.com (Lixin Wang, Qian Wang, He, Chen, Shidong Zhou)</author>
      <guid isPermaLink="false">2410.20196v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Subgraph Aggregation for Out-of-Distribution Generalization on Graphs</title>
      <link>http://arxiv.org/abs/2410.22228v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）中的分布外（OOD）泛化受到了广泛关注，因为它在现实世界的基于图的预测中至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决依赖单一因果子图所带来的脆弱性问题，并学习图数据背后的不变模式。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新框架——子图聚合（SuGAr），旨在学习对OOD泛化至关重要的多样化子图。该框架使用定制的子图采样器和多样性正则化器来提取不变子图，并通过平均其表示进行聚合。&lt;h4&gt;主要发现&lt;/h4&gt;SuGAr显著丰富了子图信号，提高了潜在因果结构的覆盖，从而提高了OOD泛化能力。&lt;h4&gt;结论&lt;/h4&gt;在合成和真实数据集上的广泛实验表明，SuGAr在图的OOD泛化上相较于现有最先进的方法提高了最多24%。这是首次通过学习多个不变子图来研究图的OOD泛化。&lt;h4&gt;总结&lt;/h4&gt;SuGAr框架为图神经网络的OOD泛化提供了新的思路，强调了多样化子图的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) generalization in Graph Neural Networks (GNNs) hasgained significant attention due to its critical importance in graph-basedpredictions in real-world scenarios. Existing methods primarily focus onextracting a single causal subgraph from the input graph to achievegeneralizable predictions. However, relying on a single subgraph can lead tosusceptibility to spurious correlations and is insufficient for learninginvariant patterns behind graph data. Moreover, in many real-worldapplications, such as molecular property prediction, multiple criticalsubgraphs may influence the target label property. To address these challenges,we propose a novel framework, SubGraph Aggregation (SuGAr), designed to learn adiverse set of subgraphs that are crucial for OOD generalization on graphs.Specifically, SuGAr employs a tailored subgraph sampler and diversityregularizer to extract a diverse set of invariant subgraphs. These invariantsubgraphs are then aggregated by averaging their representations, whichenriches the subgraph signals and enhances coverage of the underlying causalstructures, thereby improving OOD generalization. Extensive experiments on bothsynthetic and real-world datasets demonstrate that \ours outperformsstate-of-the-art methods, achieving up to a 24% improvement in OODgeneralization on graphs. To the best of our knowledge, this is the first workto study graph OOD generalization by learning multiple invariant subgraphs.</description>
      <author>example@mail.com (Bowen Liu, Haoyang Li, Shuning Wang, Shuo Nie, Shanghang Zhang)</author>
      <guid isPermaLink="false">2410.22228v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Dual Contrastive Transformer for Hierarchical Preference Modeling in Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2410.22790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;顺序推荐系统(SRS)旨在通过全面建模用户在用户-项目交互序列中的复杂偏好，预测用户可能感兴趣的后续项目。&lt;h4&gt;目的&lt;/h4&gt;提出现有SRS模型忽视高层次偏好及丰富的项目间语义关系的问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的层次偏好建模框架，使用双变换器模块和双对比学习方案，强化低层次和高层次偏好的学习，并设计语义增强的上下文嵌入模块以改善推荐性能。&lt;h4&gt;主要发现&lt;/h4&gt;在六个真实数据集上的广泛实验表明，所提出的方法在性能上优于现有的最先进方法，并且设计合理。&lt;h4&gt;结论&lt;/h4&gt;通过综合考虑低层次和高层次偏好动态，显著提高了顺序推荐的准确性。&lt;h4&gt;总结&lt;/h4&gt;该框架有效整合了用户的多维偏好信息，推动了顺序推荐系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential recommender systems (SRSs) aim to predict the subsequent itemswhich may interest users via comprehensively modeling users' complex preferenceembedded in the sequence of user-item interactions. However, most of existingSRSs often model users' single low-level preference based on item IDinformation while ignoring the high-level preference revealed by item attributeinformation, such as item category. Furthermore, they often utilize limitedsequence context information to predict the next item while overlooking richerinter-item semantic relations. To this end, in this paper, we proposed a novelhierarchical preference modeling framework to substantially model the complexlow- and high-level preference dynamics for accurate sequential recommendation.Specifically, in the framework, a novel dual-transformer module and a noveldual contrastive learning scheme have been designed to discriminatively learnusers' low- and high-level preference and to effectively enhance both low- andhigh-level preference learning respectively. In addition, a novelsemantics-enhanced context embedding module has been devised to generate moreinformative context embedding for further improving the recommendationperformance. Extensive experiments on six real-world datasets have demonstratedboth the superiority of our proposed method over the state-of-the-art ones andthe rationality of our design.</description>
      <author>example@mail.com (Chengkai Huang, Shoujin Wang, Xianzhi Wang, Lina Yao)</author>
      <guid isPermaLink="false">2410.22790v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Robotic State Recognition with Image-to-Text Retrieval Task of Pre-Trained Vision-Language Model and Black-Box Optimization</title>
      <link>http://arxiv.org/abs/2410.22707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Humanoids2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种重叠区域采样方法，以降低内存使用同时保持准确性。&lt;h4&gt;方法&lt;/h4&gt;通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。&lt;h4&gt;主要发现&lt;/h4&gt;在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。&lt;h4&gt;结论&lt;/h4&gt;对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。&lt;h4&gt;总结&lt;/h4&gt;该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State recognition of the environment and objects, such as the open/closedstate of doors and the on/off of lights, is indispensable for robots thatperform daily life support and security tasks. Until now, state recognitionmethods have been based on training neural networks from manual annotations,preparing special sensors for the recognition, or manually programming toextract features from point clouds or raw images. In contrast, we propose arobotic state recognition method using a pre-trained vision-language model,which is capable of Image-to-Text Retrieval (ITR) tasks. We prepare severalkinds of language prompts in advance, calculate the similarity between theseprompts and the current image by ITR, and perform state recognition. Byapplying the optimal weighting to each prompt using black-box optimization,state recognition can be performed with higher accuracy. Experiments show thatthis theory enables a variety of state recognitions by simply preparingmultiple prompts without retraining neural networks or manual programming. Inaddition, since only prompts and their weights need to be prepared for eachrecognizer, there is no need to prepare multiple models, which facilitatesresource management. It is possible to recognize the open/closed state oftransparent doors, the state of whether water is running or not from a faucet,and even the qualitative state of whether a kitchen is clean or not, which havebeen challenging so far, through language.</description>
      <author>example@mail.com (Kento Kawaharazuka, Yoshiki Obinata, Naoaki Kanazawa, Kei Okada, Masayuki Inaba)</author>
      <guid isPermaLink="false">2410.22707v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PV-VTT: A Privacy-Centric Dataset for Mission-Specific Anomaly Detection and Natural Language Interpretation</title>
      <link>http://arxiv.org/abs/2410.22623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视频犯罪检测是计算机视觉和人工智能的重要应用，但现有数据集主要关注严重犯罪，忽视了可能预防这些犯罪的前兆活动（如隐私侵犯）。&lt;h4&gt;目的&lt;/h4&gt;提出PV-VTT（隐私侵犯视频到文本），一个独特的多模态数据集，旨在识别隐私侵犯行为集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。&lt;h4&gt;主要发现&lt;/h4&gt;在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。&lt;h4&gt;结论&lt;/h4&gt;对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。&lt;h4&gt;总结&lt;/h4&gt;该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video crime detection is a significant application of computer vision andartificial intelligence. However, existing datasets primarily focus ondetecting severe crimes by analyzing entire video clips, often neglecting theprecursor activities (i.e., privacy violations) that could potentially preventthese crimes. To address this limitation, we present PV-VTT (Privacy ViolationVideo To Text), a unique multimodal dataset aimed at identifying privacyviolations. PV-VTT provides detailed annotations for both video and text inscenarios. To ensure the privacy of individuals in the videos, we only providevideo feature vectors, avoiding the release of any raw video data. Thisprivacy-focused approach allows researchers to use the dataset while protectingparticipant confidentiality. Recognizing that privacy violations are oftenambiguous and context-dependent, we propose a Graph Neural Network (GNN)-basedvideo description model. Our model generates a GNN-based prompt with image forLarge Language Model (LLM), which deliver cost-effective and high-quality videodescriptions. By leveraging a single video frame along with relevant text, ourmethod reduces the number of input tokens required, maintaining descriptivequality while optimizing LLM API-usage. Extensive experiments validate theeffectiveness and interpretability of our approach in video description tasksand flexibility of our PV-VTT dataset.</description>
      <author>example@mail.com (Ryozo Masukawa, Sanggeon Yun, Yoshiki Yamaguchi, Mohsen Imani)</author>
      <guid isPermaLink="false">2410.22623v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments</title>
      <link>http://arxiv.org/abs/2410.21340v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模模型（如大语言模型和复杂图像生成系统）的部署需要大量计算资源，导致高成本。&lt;h4&gt;目的&lt;/h4&gt;降低成本，解决可扩展性和数据安全性相关的挑战，推动向去中心化系统的转变。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于元学习的框架，自动选择去中心化系统中的最佳加速方法，通过历史性能数据学习不同任务上各种加速技术的表现。&lt;h4&gt;主要发现&lt;/h4&gt;该元学习框架系统地识别每个任务的最佳加速策略，显著提高了决策效率和系统性能，超越了传统方法。&lt;h4&gt;结论&lt;/h4&gt;元学习有潜力革命性地改变去中心化人工智能系统中的推理加速，提供更加民主和经济可行的人工智能解决方案。&lt;h4&gt;总结&lt;/h4&gt;通过自动化选择最佳加速方法，本文为去中心化AI系统的推理效率提升提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The deployment of large-scale models, such as large language models (LLMs)and sophisticated image generation systems, incurs substantial costs due totheir computational demands. To mitigate these costs and address challengesrelated to scalability and data security, there is a growing shift towardsdecentralized systems for deploying such models. In these decentralizedenvironments, efficient inference acceleration becomes crucial to managecomputational resources effectively and enhance system responsiveness. In thiswork, we address the challenge of selecting optimal acceleration methods indecentralized systems by introducing a meta-learning-based framework. Thisframework automates the selection process by learning from historicalperformance data of various acceleration techniques across different tasks.Unlike traditional methods that rely on random selection or expert intuition,our approach systematically identifies the best acceleration strategies basedon the specific characteristics of each task. We demonstrate that ourmeta-learning framework not only streamlines the decision-making process butalso consistently outperforms conventional methods in terms of efficiency andperformance. Our results highlight the potential of meta-learning torevolutionize inference acceleration in decentralized AI systems, offering apath towards more democratic and economically feasible artificial intelligencesolutions.</description>
      <author>example@mail.com (Yuzhe Yang, Yipeng Du, Ahmad Farhan, Claudio Angione, Yue Zhao, Harry Yang, Fielding Johnston, James Buban, Patrick Colangelo)</author>
      <guid isPermaLink="false">2410.21340v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Feature Selection Algorithm Based on Dual Manifold Re-ranking</title>
      <link>http://arxiv.org/abs/2410.20388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  in Chinese language&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。```json
{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。"
```json
{
    "背景": "高维数据在许多数据分析任务中常见，特征选择技术旨在从原始高维数据中识别最具代表性的特征。",
    "目的": "提出一种基于双流形重排序（DMRR）的无监督特征选择算法，以解决无。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。"
}
征之间的流形结构，通过变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时保持高准确性并显著降低内存需求。"
}
进行流形重排序。",
    "主要发现": "DMRR与三种原始无监督特征选择算法和两种无监督特征选择后处理算法的比较实验结果表明，样本的重要性信息及样本与特征之间的双重关系对更好的特征选择有益。",
    "结论": "考虑样本的重要性和样本与特征之间的相互关系可以显著改善无监督特征选择的效果。",
    "总结": "DMRR算法有效捕捉了数据的内部结构，提供了改进无监督特征选择的新方法。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.11896/jsjkx.221000143&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-dimensional data is commonly encountered in numerous data analysistasks. Feature selection techniques aim to identify the most representativefeatures from the original high-dimensional data. Due to the absence of classlabel information, it is significantly more challenging to select appropriatefeatures in unsupervised learning scenarios compared to supervised ones.Traditional unsupervised feature selection methods typically score the featuresof samples based on certain criteria, treating samples indiscriminately.However, these approaches fail to fully capture the internal structure of thedata. The importance of different samples should vary, and there is a dualrelationship between the weight of samples and features that will influenceeach other. Therefore, an unsupervised feature selection algorithm based ondual manifold re-ranking (DMRR) is proposed in this paper. Different similaritymatrices are constructed to depict the manifold structures among samples,between samples and features, and among features themselves. Then, manifoldre-ranking is performed by combining the initial scores of samples andfeatures. By comparing DMRR with three original unsupervised feature selectionalgorithms and two unsupervised feature selection post-processing algorithms,experimental results confirm that the importance information of differentsamples and the dual relationship between sample and feature are beneficial forachieving better feature selection.</description>
      <author>example@mail.com (Yunhui Liang, Jianwen Gan, Yan Chen, Peng Zhou, Liang Du)</author>
      <guid isPermaLink="false">2410.20388v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities</title>
      <link>http://arxiv.org/abs/2410.23160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "近年来，针对多领域时间序列预测的基础模型开发受到广泛关注。",
    "目的": "提出FlexTSF，一个通用的时间序列预测模型，以处理区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在资源受限的环境中高效进行大规模点云配准，同时    "方法": "FlexTSF以自回归方式生成预测，包含三种新设计：VT-Norm用于消除数据领域障碍，IVP Patcher用于学习灵活结构的时间序列表示，LED attention用于整合这两者并在预测中考虑领域和时间信息。",
    "主要发现": "在12个数据集上的实验表明，FlexTSF在常规和不规则时间序列预测上均优于现有最先进模型。",
    "结论": "经过自监督预训练后，FlexTSF在零样本和少样本设置下均展现出卓越的时间序列预测性能。",
方法能够在资源受限的环境中高效进行大规模点云配准，同时保持TSF模型有效应对了时间序列数据中的缺失值、不数据中的缺失值、不等序列长度和不规则时间间隔等问题，具有更好的泛化能力。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing a foundation model for time series forecasting across diversedomains has attracted significant attention in recent years. Existing workstypically assume regularly sampled, well-structured data, limiting theirapplicability to more generalized scenarios where time series often containmissing values, unequal sequence lengths, and irregular time intervals betweenmeasurements. To cover diverse domains and handle variable regularities, wepropose FlexTSF, a universal time series forecasting model that possessesbetter generalization and natively support both regular and irregular timeseries. FlexTSF produces forecasts in an autoregressive manner and incorporatesthree novel designs: VT-Norm, a normalization strategy to ablate data domainbarriers, IVP Patcher, a patching module to learn representations from flexiblystructured time series, and LED attention, an attention mechanism to seamlesslyintegrate these two and propagate forecasts with awareness of domain and timeinformation. Experiments on 12 datasets show that FlexTSF outperformsstate-of-the-art forecasting models respectively designed for regular andirregular time series. Furthermore, after self-supervised pre-training, FlexTSFshows exceptional performance in both zero-shot and few-show settings for timeseries forecasting.</description>
      <author>example@mail.com (Jingge Xiao, Yile Chen, Gao Cong, Wolfgang Nejdl, Simon Gottschalk)</author>
      <guid isPermaLink="false">2410.23160v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MassiveGNN: Efficient Training via Prefetching for Massively Connected Distributed Graphs</title>
      <link>http://arxiv.org/abs/2410.22697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In Proc. of the IEEE International Conference on Cluster Computing
  (CLUSTER), 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在图结构数据学习中不可或缺，但在大规模连接图上，其计算成本不断上升，导致执行性能面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;解决在大规模图上执行GNN时的计算成本和性能问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于参数化的连续预取和驱逐方案，结合最新的Amazon DistDGL分布式GNN框架，以改善分布式图上的采样和通信开销。&lt;h4&gt;主要发现&lt;/h4&gt;在NERSC的Perlmutter超级计算机上，对各种OGB数据集的端到端训练性能提升了约15%到40%。&lt;h4&gt;结论&lt;/h4&gt;通过优化采样和通信策略，能够有效提升分布式GNN的训练性能。&lt;h4&gt;总结&lt;/h4&gt;本文提供了一种有效的解决方案，旨在克服大规模图数据学习中的性能瓶颈。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNN) are indispensable in learning fromgraph-structured data, yet their rising computational costs, especially onmassively connected graphs, pose significant challenges in terms of executionperformance. To tackle this, distributed-memory solutions such as partitioningthe graph to concurrently train multiple replicas of GNNs are in practice.However, approaches requiring a partitioned graph usually suffer fromcommunication overhead and load imbalance, even under optimal partitioning andcommunication strategies due to irregularities in the neighborhood minibatchsampling.  This paper proposes practical trade-offs for improving the sampling andcommunication overheads for representation learning on distributed graphs(using popular GraphSAGE architecture) by developing a parameterized continuousprefetch and eviction scheme on top of the state-of-the-art Amazon DistDGLdistributed GNN framework, demonstrating about 15-40% improvement in end-to-endtraining performance on the National Energy Research Scientific ComputingCenter's (NERSC) Perlmutter supercomputer for various OGB datasets.</description>
      <author>example@mail.com (Aishwarya Sarkar, Sayan Ghosh, Nathan R. Tallent, Ali Jannesari)</author>
      <guid isPermaLink="false">2410.22697v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Real birational implicitization for statistical models</title>
      <link>http://arxiv.org/abs/2410.23102v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法{
    "背景": "研究半代数集在非理想映射下的隐式描述，前提是映射的分母在集合上为正。",
    "目的": "为全球理性可识别的统计模型提供模型定义约束，以促进模型成员测试、表示学习和模型等价性性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够    "方法": "通过推导隐式方程，展示其在样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出更大的优势。",
    "总结": "该方法能够在其他相关框架中的适用性。",
    "主要发现": "隐式方程恢复了经典图模型的马尔可夫性质以及如Verma约束等其他知名方程，并扩展到彩色或干预图模型、分阶段树和Lyapunov模型等一般化框架。",
    "结论": "在进一步的温和假设下，隐式方程生成模型的消失理想，推广了Geiger等人的先前结果。",
    "总结": "本研究为统计模型的理论提供了重要的约束和工具，促进了模型的理解与应用。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We derive an implicit description of the image of a semialgebraic set under abirational map, provided that the denominators of the map are positive on theset. For statistical models which are globally rationally identifiable, thisyields model-defining constraints which facilitate model membership testing,representation learning, and model equivalence tests. Many examples illustratethe applicability of our results. The implicit equations recover well-knownMarkov properties of classical graphical models, as well as other well-studiedequations such as the Verma constraint. They also provide Markov properties forgeneralizations of these frameworks, such as colored or interventionalgraphical models, staged trees, and the recently introduced Lyapunov models.Under a further mild assumption, we show that our implicit equations generatethe vanishing ideal of the model up to a saturation, generalizing previousresults of Geiger, Meek and Sturmfels, Duarte and G\"orgen, Sullivant, andothers.</description>
      <author>example@mail.com (Tobias Boege, Liam Solus)</author>
      <guid isPermaLink="false">2410.23102v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling and Zero-Shot Transfer</title>
      <link>http://arxiv.org/abs/2410.21683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures, supporting information appended&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "构建可转移的描述符用于分子和生物系统的构象表示，在药物发现、基于学习的分子动力学和蛋白质机制分析中有广泛应用。",
    "目的": "探索域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLoMatch中展现出几何图神经网络（Geom-GNNs）作为可转移和高效的几何描述符，以改善域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用，在3DLo    "方法": "研究Geom-GNNs在自监督预训练、监督和无监督学习设置下的表现能力，分析不同架构的可表达能力以及其在预训练任务上的缩放行为。",
    "主要发现": "Geom-GNNs在预训练任务上不遵循幂律缩放，且在重要的量子化学标签监督任务上缺乏可预测的缩放行为。不同架构在预训练任务上的表现能力存在差异。",
    "结论": "全原子图嵌入可以与其他神经网络架构有机结合，以增强表达能力，同时低维潜在空间的投影与传统几何描述符有良好的一致性。",
    "总结": "研究显示预训练的Geom-GNNs在提高分子建模泛化能力方面具有潜力，且与其他模型结合能够提升其表现。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Constructing transferable descriptors for conformation representation ofmolecular and biological systems finds numerous applications in drug discovery,learning-based molecular dynamics, and protein mechanism analysis. Geometricgraph neural networks (Geom-GNNs) with all-atom information have transformedatomistic simulations by serving as a general learnable geometric descriptorsfor downstream tasks including prediction of interatomic potential andmolecular properties. However, common practices involve supervising Geom-GNNson specific downstream tasks, which suffer from the lack of high-quality dataand inaccurate labels leading to poor generalization and performancedegradation on out-of-distribution (OOD) scenarios. In this work, we exploredthe possibility of using pre-trained Geom-GNNs as transferable and highlyeffective geometric descriptors for improved generalization. To explore theirrepresentation power, we studied the scaling behaviors of Geom-GNNs underself-supervised pre-training, supervised and unsupervised learning setups. Wefind that the expressive power of different architectures can differ on thepre-training task. Interestingly, Geom-GNNs do not follow the power-law scalingon the pre-training task, and universally lack predictable scaling behavior onthe supervised tasks with quantum chemical labels important for screening anddesign of novel molecules. More importantly, we demonstrate how all-atom graphembedding can be organically combined with other neural architectures toenhance the expressive power. Meanwhile, the low-dimensional projection of thelatent space shows excellent agreement with conventional geometricaldescriptors.</description>
      <author>example@mail.com (Zihan Pengmei, Zhengyuan Shen, Zichen Wang, Marcus Collins, Huzefa Rangwala)</author>
      <guid isPermaLink="false">2410.21683v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning-Driven Microstructure Characterization and Vickers Hardness Prediction of Mg-Gd Alloys</title>
      <link>http://arxiv.org/abs/2410.20402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。",
    "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内```json
{
    "背景": "材料科学领域长期以来关注成分、微观结构与性能之间的关系。",
    "目的": "分析和预测Gd含量、树枝状结构及二次相对固溶Mg-Gd合金机械性能的影响。",
    "方法": "提出基于图像处理和深度学习技术的多模态融合学习框架，结合元素成分和微观结构特征，准确预测Vickers硬度。",
    "主要发现": "Transformer模型在预测准确性方面表现最佳，R²值达到0.9；SHAP分析识别出四个影响Vickers硬度的关键特征值。",
    "结论": "这些发现 "结论": "对于3DMatch，我们实现了94%的召回率，同时减少了33%的内存使用金性能的理解，还为未来材料设计和优化提供了理论支持。",
    "总结": "本研究为Mg-Gd合金的性能预测提供了新的方法和思路，"本研究为Mg-Gd合金的性能预测提供了新的方法和思路，促进了材料科学的发展。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the field of materials science, exploring the relationship betweencomposition, microstructure, and properties has long been a critical researchfocus. The mechanical performance of solid-solution Mg-Gd alloys issignificantly influenced by Gd content, dendritic structures, and the presenceof secondary phases. To better analyze and predict the impact of these factors,this study proposes a multimodal fusion learning framework based on imageprocessing and deep learning techniques. This framework integrates bothelemental composition and microstructural features to accurately predict theVickers hardness of solid-solution Mg-Gd alloys. Initially, deep learningmethods were employed to extract microstructural information from a variety ofsolid-solution Mg-Gd alloy images obtained from literature and experiments.This provided precise grain size and secondary phase microstructural featuresfor performance prediction tasks. Subsequently, these quantitative analysisresults were combined with Gd content information to construct a performanceprediction dataset. Finally, a regression model based on the Transformerarchitecture was used to predict the Vickers hardness of Mg-Gd alloys. Theexperimental results indicate that the Transformer model performs best in termsof prediction accuracy, achieving an R^2 value of 0.9. Additionally, SHAPanalysis identified critical values for four key features affecting the Vickershardness of Mg-Gd alloys, providing valuable guidance for alloy design. Thesefindings not only enhance the understanding of alloy performance but also offertheoretical support for future material design and optimization.</description>
      <author>example@mail.com (Lu Wang, Hongchan Chen, Bing Wang, Qian Li, Qun Luo, Yuexing Han)</author>
      <guid isPermaLink="false">2410.20402v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MonoDGP: Monocular 3D Object Detection with Decoupled-Query and Geometry-Error Priors</title>
      <link>http://arxiv.org/abs/2410.19590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Transformer的单目3D物体检测方法MonoDGP，以解决现有方法中深度误差对边界框高度表示的影响。&lt;h4&gt;方法&lt;/h4&gt;采用透视不变几何误差来修改投影公式，讨论几何误差的机制和效果，同时解耦深度引导解码器，并构建仅依赖视觉特征的估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下。&lt;h4&gt;主要发现&lt;/h4&gt;MonoDGP通过引入区域分割头（RSH），生成增强特征和分割嵌入，优化和微调Transformer解码器的输入令牌。&lt;h4&gt;结论&lt;/h4&gt;在不增加额外数据的情况下，MonoDGP在KITTI基准测试上表现出最先进的性能。&lt;h4&gt;代码链接&lt;/h4&gt;https://github.com/PuFanqi23/MonoDGP&lt;h4&gt;总结&lt;/h4&gt;MonoDGP提供了一种简单有效的替代多深度预测的方法，在单目3D物体检测中展示了优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perspective projection has been extensively utilized in monocular 3D objectdetection methods. It introduces geometric priors from 2D bounding boxes and 3Dobject dimensions to reduce the uncertainty of depth estimation. However, dueto depth errors originating from the object's visual surface, the height of thebounding box often fails to represent the actual projected central height,which undermines the effectiveness of geometric depth. Direct prediction forthe projected height unavoidably results in a loss of 2D priors, whilemulti-depth prediction with complex branches does not fully leverage geometricdepth. This paper presents a Transformer-based monocular 3D object detectionmethod called MonoDGP, which adopts perspective-invariant geometry errors tomodify the projection formula. We also try to systematically discuss andexplain the mechanisms and efficacy behind geometry errors, which serve as asimple but effective alternative to multi-depth prediction. Additionally,MonoDGP decouples the depth-guided decoder and constructs a 2D decoder onlydependent on visual features, providing 2D priors and initializing objectqueries without the disturbance of 3D detection. To further optimize andfine-tune input tokens of the transformer decoder, we also introduce a RegionSegment Head (RSH) that generates enhanced features and segment embeddings. Ourmonocular method demonstrates state-of-the-art performance on the KITTIbenchmark without extra data. Code is available athttps://github.com/PuFanqi23/MonoDGP.</description>
      <author>example@mail.com (Fanqi Pu, Yifan Wang, Jiru Deng, Wenming Yang)</author>
      <guid isPermaLink="false">2410.19590v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Efficient End-to-End 6-Dof Grasp Detection Framework for Edge Devices with Hierarchical Heatmaps and Feature Propagation</title>
      <link>http://arxiv.org/abs/2410.22980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平```json
{
    "背景": "6-DoF抓取检测对智能嵌入式系统的发展至关重要，因为它为物体抓取提供可行的机器人姿态。",
    "目的": "提出一种高效的6-DoF抓取检测网络，以便在复杂环境中实现抓取。",
    "方法": "采用层次热图表示的域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他采样方法，尤其是在较低的GPU内存水平下网络（E3GNet），从RGBD或点云数据中提取3D几何特征。",
    "主要发现": "E3GNet能够在杂乱的真实环境中有效识别高质量和多样化的抓取方式，且在模型推理效率上超过了以往的方法。",
    "结论": "通过我们的端到端方法和高效网络设计，E3GNet实现了在边缘设备上的实时6-DoF抓取检测，并在真实世界实验中达到了94%的物体抓取成功率。",
    "总结": "E3GNet为移动机器人平台上的6-DoF抓取检测提供了一种高效且有效的解决方案。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 6-DoF grasp detection is critically important for the advancement ofintelligent embodied systems, as it provides feasible robot poses for objectgrasping. Various methods have been proposed to detect 6-DoF grasps through theextraction of 3D geometric features from RGBD or point cloud data. However,most of these approaches encounter challenges during real robot deployment dueto their significant computational demands, which can be particularlyproblematic for mobile robot platforms, especially those reliant on edgecomputing devices. This paper presents an Efficient End-to-End Grasp DetectionNetwork (E3GNet) for 6-DoF grasp detection utilizing hierarchical heatmaprepresentations. E3GNet effectively identifies high-quality and diverse graspsin cluttered real-world environments. Benefiting from our end-to-endmethodology and efficient network design, our approach surpasses previousmethods in model inference efficiency and achieves real-time 6-Dof graspdetection on edge devices. Furthermore, real-world experiments validate theeffectiveness of our method, achieving a satisfactory 94% object graspingsuccess rate.</description>
      <author>example@mail.com (Kaiqin Yang. Yixiang Dai, Guijin Wang, Siang Chen)</author>
      <guid isPermaLink="false">2410.22980v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Dual-Optimized Adaptive Graph Reconstruction for Multi-View Graph Clustering</title>
      <link>http://arxiv.org/abs/2410.22983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACM MM 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上```json
{
    "背景": "多视角聚类是针对多媒体数据的重要机器学习任务，涉及图像、视频和文本等多个领域。随着图数据的日益丰富，多视角    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优MVGC）的重要性愈加明显。",
    "目的": "提出一种新的多视角图聚类方法，旨在解决异质图问题，同时保留传统图神经网络（GNN）的优点。",
    "方法": "提出了基于双重优化自适应图重构的多视
    "主要发现": "在3DMatch和3DLoMatch数据集上的评估显示，该方法在注册召回率上优于其他方法DOAGC，首先开发了一种考虑节点关联和原始结构信息的自适应图重构机制，并设计了双重优化策略。",
,
    "主要发现": "通过大量实验，DOAG   "主要发现": "通过大量实验，DOAGC有效缓解了异质图问题，展示了优化策略的可行性。",
    "结论": "DOAGC在保持传统GNN简洁性、可解释性和效率的同时，成功应对了异质图的挑战。",
    "总结": "本研究提出的DOAGC方法为处理异质图提供了新的思路，并在实验中验证了  "主要发现": "通过大量实验，DOAGC有效缓解了异质图问题，展示了优化策略的可行性。",
    "结论": "DOAGC在保持传统GNN简洁性、可解释性和效率的同时，成功应对了异质图的挑战。",
    "总结": "本研究提出的DOAGC方法为处理异质图提供了新的思路，并在实验中验证了其有效性。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3664647.3680677&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view clustering is an important machine learning task for multi-mediadata, encompassing various domains such as images, videos, and texts. Moreover,with the growing abundance of graph data, the significance of multi-view graphclustering (MVGC) has become evident. Most existing methods focus on graphneural networks (GNNs) to extract information from both graph structure andfeature data to learn distinguishable node representations. However,traditional GNNs are designed with the assumption of homophilous graphs, makingthem unsuitable for widely prevalent heterophilous graphs. Several techniqueshave been introduced to enhance GNNs for heterophilous graphs. While thesemethods partially mitigate the heterophilous graph issue, they often neglectthe advantages of traditional GNNs, such as their simplicity, interpretability,and efficiency. In this paper, we propose a novel multi-view graph clusteringmethod based on dual-optimized adaptive graph reconstruction, named DOAGC. Itmainly aims to reconstruct the graph structure adapted to traditional GNNs todeal with heterophilous graph issues while maintaining the advantages oftraditional GNNs. Specifically, we first develop an adaptive graphreconstruction mechanism that accounts for node correlation and originalstructural information. To further optimize the reconstruction graph, we designa dual optimization strategy and demonstrate the feasibility of ouroptimization strategy through mutual information theory. Numerous experimentsdemonstrate that DOAGC effectively mitigates the heterophilous graph problem.</description>
      <author>example@mail.com (Zichen Wen, Tianyi Wu, Yazhou Ren, Yawen Ling, Chenhang Cui, Xiaorong Pu, Lifang He)</author>
      <guid isPermaLink="false">2410.22983v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Self-Driving Car Racing: Application of Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2410.22766v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "深度学习在3D点云配准方面的进展提高了准确性，但同时增加了GPU内存使用，常需预先采样以减少准确性。",
    "目的": "提出一种重叠区域采样方法，以降低内存使用同时保持准确性。",
    "方法": "通过估计重叠区域并进行密集采样，使用基于k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch```json
{
    "背景": "本研究探讨深度强化学习在自主驾驶赛车领域的应用，受到AI驱动的移动性和自主赛车赛事的推动。",
    "目的": "开发一个能够在OpenAI Gymnasium CarRacing环境中高效驾驶模拟汽车的AI代理。",
    "方法": "研究多k近邻(kNN)的点压缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集上的缩机制，结合多层感知器(MLP)和变换器架构。",
    "主要发现": "在3DMatch和3DLoMatch数据集DQN）、近端策略优化（PPO），以及结合迁移学习和递归神经网络（RNN）的新适应算法。",
    "主要发现": "DQN为策略学习提供了强有力的基线，而集成ResNet和LSTM模型显著提升了代理捕捉复杂空间和时间动态的能力。PPO在连续行动空间中表现出色，但仍面临策略崩溃等挑战。",
    "结论": "比较了不同方法的性能，并提出未来研究方向，集中于提高计算效率和 "DQN为策略学习提供了强有力的基线，而集成ResNet和LSTM模型显著提升了代理捕捉复杂空间和时间动态的能力。PPO在连续行动空间中表现出色，但仍面临策略崩溃等挑战。",
    "结论": "比较了不同方法的性能，并提出未来研究方向，集中于提高计算效率和解决模型稳定性问题。研究成果对自主驾驶和相关控制任务的AI系统发展作出贡献。",
    "总结": "本论文为深度强化学习在自主驾驶领域的应用提供"DQN为策略学习提供了强有力的基线，而集成ResNet和LSTM模型显著提升了代理捕捉复杂空间和时间动态的能力。PPO在连续行动空间中表现出色，但仍面临策略崩溃等挑战。",
    "结论": "比较了不同方法的性能，并提出未来研究方向，集中于提高计算效率和解决模型稳定性问题。研究成果对自主驾驶和相关控制任务的AI系统发展作出贡献。",
    "总结": "本论文为深度强化学习在自主驾驶领域的应用提供了新的见解和研究方向。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the application of deep reinforcement learning (RL)techniques in the domain of autonomous self-driving car racing. Motivated bythe rise of AI-driven mobility and autonomous racing events, the project aimsto develop an AI agent that efficiently drives a simulated car in the OpenAIGymnasium CarRacing environment. We investigate various RL algorithms,including Deep Q-Network (DQN), Proximal Policy Optimization (PPO), and noveladaptations that incorporate transfer learning and recurrent neural networks(RNNs) for enhanced performance. The project demonstrates that while DQNprovides a strong baseline for policy learning, integrating ResNet and LSTMmodels significantly improves the agent's ability to capture complex spatialand temporal dynamics. PPO, particularly in continuous action spaces, showspromising results for fine control, although challenges such as policy collapseremain. We compare the performance of these approaches and outline futureresearch directions focused on improving computational efficiency andaddressing model stability. Our findings contribute to the ongoing developmentof AI systems in autonomous driving and related control tasks.</description>
      <author>example@mail.com (Florentiana Yuwono, Gan Pang Yen, Jason Christopher)</author>
      <guid isPermaLink="false">2410.22766v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>IndraEye: Infrared Electro-Optical UAV-based Perception Dataset for Robust Downstream Tasks</title>
      <link>http://arxiv.org/abs/2410.20953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。&lt;h4&gt;目的&lt;/h4&gt;提高声音事件检测的性能，尤其是在标注数据不足的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。&lt;h4&gt;主要发现&lt;/h4&gt;在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。&lt;h4&gt;结论&lt;/h4&gt;通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。&lt;h4&gt;总结&lt;/h4&gt;本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks (DNNs) have shown exceptional performance when trainedon well-illuminated images captured by Electro-Optical (EO) cameras, whichprovide rich texture details. However, in critical applications like aerialperception, it is essential for DNNs to maintain consistent reliability acrossall conditions, including low-light scenarios where EO cameras often struggleto capture sufficient detail. Additionally, UAV-based aerial object detectionfaces significant challenges due to scale variability from varying altitudesand slant angles, adding another layer of complexity. Existing methodstypically address only illumination changes or style variations as domainshifts, but in aerial perception, correlation shifts also impact DNNperformance. In this paper, we introduce the IndraEye dataset, a multi-sensor(EO-IR) dataset designed for various tasks. It includes 5,612 images with145,666 instances, encompassing multiple viewing angles, altitudes, sevenbackgrounds, and different times of the day across the Indian subcontinent. Thedataset opens up several research opportunities, such as multimodal learning,domain adaptation for object detection and segmentation, and exploration ofsensor-specific strengths and weaknesses. IndraEye aims to advance the field bysupporting the development of more robust and accurate aerial perceptionsystems, particularly in challenging conditions. IndraEye dataset isbenchmarked with object detection and semantic segmentation tasks. Dataset andsource codes are available at https://bit.ly/indraeye.</description>
      <author>example@mail.com (Manjunath D, Prajwal Gurunath, Sumanth Udupa, Aditya Gandhamal, Shrikar Madhu, Aniruddh Sikdar, Suresh Sundaram)</author>
      <guid isPermaLink="false">2410.20953v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Memory-Efficient Point Cloud Registration via Overlapping Region Sampling</title>
      <link>http://arxiv.org/abs/2410.21753v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted for IEEE International Conference on Visual Communications
  and Image Processing 2024 (VCIP2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接 "本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
本文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "文讨论了使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在D使用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE202用第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3第一阶环境声学（FOA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，的进展OA）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未）麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注麦克风捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音性捕获的空间音频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频同时增加频录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音录音进行声音事件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD使用件定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误定位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差位和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分和检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从检测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36测（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4（SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至SELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.ELD）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9D）。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
。",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结   "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论":",
    "目的": "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习: "提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法"提高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效高声音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升音事件检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位检测的性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，性能，尤其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其方法其是在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在在标注数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标数据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注内存据不足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据足的情况下。",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下保持准确",
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
,
    "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "  "方法": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结    "": "提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结":":提出了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "了一种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预种新颖的自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法计重叠自监督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为督预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件预训练方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种方法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的法，通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案通过使用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频用虚拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合拟现实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的实内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜内容中的空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力空间音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。"
NN)的音频-视觉录音来共同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。"
压缩机制，结合多同训练音频和视觉编码器，采用对比学习使同一录音的音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。"
}
```感知器(MLP)和变换器器架构。",
。",
    "音频和视觉嵌入更接近。",
    "主要发现": "在DCASE2022任务3数据集上，使用100小时的未标注音频-视觉录音，将SELD的误差得分从36.4降至34.9。",
    "结论": "通过自监督学习方法，可以有效提升声音事件的定位和检测性能，尤其是在缺乏标注数据的情况下。",
    "总结": "本文提出的自监督预训练方法为声音事件检测提供了一种有效的解决方案，展示了音频与视觉信息联合训练的潜力。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in deep learning have improved 3D point cloud registrationbut increased graphics processing unit (GPU) memory usage, often requiringpreliminary sampling that reduces accuracy. We propose an overlapping regionsampling method to reduce memory usage while maintaining accuracy. Our approachestimates the overlapping region and intensively samples from it, using ak-nearest-neighbor (kNN) based point compression mechanism with multi layerperceptron (MLP) and transformer architectures. Evaluations on 3DMatch and3DLoMatch datasets show our method outperforms other sampling methods inregistration recall, especially at lower GPU memory levels. For 3DMatch, weachieve 94% recall with 33% reduced memory usage, with greater advantages in3DLoMatch. Our method enables efficient large-scale point cloud registration inresource-constrained environments, maintaining high accuracy whilesignificantly reducing memory requirements.</description>
      <author>example@mail.com (Tomoyasu Shimada, Kazuhiko Murasaki, Shogo Sato, Toshihiko Nishimura, Taiga Yoshida, Ryuichi Tanida)</author>
      <guid isPermaLink="false">2410.21753v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>NASM: Neural Anisotropic Surface Meshing</title>
      <link>http://arxiv.org/abs/2410.23109v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  SIGGRAPH Asia 2024 (Conference Track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获```json
{
    "背景": "本文讨论了使用第一阶环境声学（FOA）麦克风捕获了一种基于学习的新学（FOA）麦克风捕获的性表面网格化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几面网格化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘网格化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征格化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何化。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验,
    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验": "在Thingi10K数据集上的大量表面模型上进行评估，并在Multi-Garment Network数据集和FAUST人类数据集上进行了广泛的未见3D形状测试。",
    "总结": "新方法在各向异性表面网    "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验": "在Thingi10K数据集上的大量表面模型上进行评估，并在Multi-Garment Network数据集和FAUST人类数据集上进行了广泛的未见3D形状测试。",
    "总结": "新方法在各向异性表面网格化领域表现出优越性，具有良好的  "目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验": "在Thingi10K数据集上的大量表面模型上进行评估，并在Multi-Garment Network数据集和FAUST人类数据集上进行了广泛的未见3D形状测试。",
    "总结": "新方法在各向异性表面网格化领域表现出优越性，具有良好的可扩展性和对几何特征的保留能力。"
}
```和目的": "提出一种图神经网络，将输入网格嵌入高维欧几里得空间，以保留基于曲率的各向异性度量。",
    "方法": "使用高维边缘向量之间的点积损失来减少计算时间并提高可扩展性；同时，在生成的高维嵌入上进行特征敏感的重网格化，自动捕捉锐利的几何特征。",
    "主要发现": "定义了一种高维法向度量，并推导出高维中心Voronoi剖分优化的自动微分，以同时保留几何特征和曲率各向异性。",
    "结论": "这是首次提出深度学习框架和大型数据集用于构建3D各向异性表面网格化的高维欧几里得嵌入空间。",
    "实验": "在Thingi10K数据集上的大量表面模型上进行评估，并在Multi-Garment Network数据集和FAUST人类数据集上进行了广泛的未见3D形状测试。",
    "总结": "新方法在各向异性表面网格化领域表现出优越性，具有良好的可扩展性和对几何特征的保留能力。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3680528.3687700&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a new learning-based method, NASM, for anisotropicsurface meshing. Our key idea is to propose a graph neural network to embed aninput mesh into a high-dimensional (high-d) Euclidean embedding space topreserve curvature-based anisotropic metric by using a dot product loss betweenhigh-d edge vectors. This can dramatically reduce the computational time andincrease the scalability. Then, we propose a novel feature-sensitive remeshingon the generated high-d embedding to automatically capture sharp geometricfeatures. We define a high-d normal metric, and then derive an automaticdifferentiation on a high-d centroidal Voronoi tessellation (CVT) optimizationwith the normal metric to simultaneously preserve geometric features andcurvature anisotropy that exhibit in the original 3D shapes. To our knowledge,this is the first time that a deep learning framework and a large dataset areproposed to construct a high-d Euclidean embedding space for 3D anisotropicsurface meshing. Experimental results are evaluated and compared with thestate-of-the-art in anisotropic surface meshing on a large number of surfacemodels from Thingi10K dataset as well as tested on extensive unseen 3D shapesfrom Multi-Garment Network dataset and FAUST human dataset.</description>
      <author>example@mail.com (Hongbo Li, Haikuan Zhu, Sikai Zhong, Ningna Wang, Cheng Lin, Xiaohu Guo, Shiqing Xin, Wenping Wang, Jing Hua, Zichun Zhong)</author>
      <guid isPermaLink="false">2410.23109v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MutaPLM: Protein Language Modeling for Mutation Explanation and Engineering</title>
      <link>http://arxiv.org/abs/2410.22949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 poster&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景```json
{
    "背景": "研究蛋白质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "研究蛋白质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "目的": "提出MutaPLM框架，以更好地解释和导航蛋白质突变。",
    "方法": "MutaPLM引入了蛋白质增量网络，捕获突变的明确表示，并使用链式思维的迁移学习策略，从生物医学文本中提取突变知识。同时构建了首个大规模蛋白质突变数据集MutaDescribe，提供丰富的文本注释。",
    "主要蛋白质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "目的": "提出MutaPLM框架，以更好地解释和导航蛋白质突变。",
    "方法": "MutaPLM引入了蛋白质增量网络，捕获突变的明确表示，并使用链式思维的迁移学习策略，从生物医学文本中提取突变知识。同时构建了首个大规模蛋白质突变数据集MutaDescribe，提供丰富的文本注释。",
    "主要发现": "MutaPLM能够提供易于理解的突变效应解释，并优先考虑具有良好特性的新的突变。",
    "结论": "MutaPLM在突变解释和优先级排序方面表现优异，所有代码、模型和数据已在GitHub上开源。",
    "总结": "MutaPLM为蛋白质突变的研究提供了一种统一的解释框架，增强质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "目的": "提出MutaPLM框架，以更好地解释和导航蛋白质突变。",
    "方法": "MutaPLM引入了蛋白质增量网络，捕获突变的明确表示，并使用链式思维的迁移学习策略，从生物医学文本中提取突变知识。同时构建了首个大规模蛋白质突变数据集MutaDescribe，提供丰富的文本注释。",
    "主要发现": "MutaPLM能够提供易于理解的突变效应解释，并优先考虑具有良好特性的新的突变。",
    "结论": "MutaPLM在突变解释和优先级排序方面表现优异，所有代码、模型和数据已在GitHub上开源。",
    "总结": "MutaPLM为蛋白质突变的研究提供了一种统一的解释框架，增强了蛋白质语言模型在实际应用中的可解释质序列中的突变在生命科学中具有重要意义，现有的蛋白质语言模型在生物应用中表现出较强的能力，但由于架构设计和缺乏监督，无法有效解释突变。",
    "目的": "提出MutaPLM框架，以更好地解释和导航蛋白质突变。",
    "方法": "MutaPLM引入了蛋白质增量网络，捕获突变的明确表示，并使用链式思维的迁移学习策略，从生物医学文本中提取突变知识。同时构建了首个大规模蛋白质突变数据集MutaDescribe，提供丰富的文本注释。",
    "主要发现": "MutaPLM能够提供易于理解的突变效应解释，并优先考虑具有良好特性的新的突变。",
    "结论": "MutaPLM在突变解释和优先级排序方面表现优异，所有代码、模型和数据已在GitHub上开源。",
    "总结": "MutaPLM为蛋白质突变的研究提供了一种统一的解释框架，增强了蛋白质语言模型在实际应用中的可解释性和工程化能力。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Studying protein mutations within amino acid sequences holds tremendoussignificance in life sciences. Protein language models (PLMs) have demonstratedstrong capabilities in broad biological applications. However, due toarchitectural design and lack of supervision, PLMs model mutations implicitlywith evolutionary plausibility, which is not satisfactory to serve asexplainable and engineerable tools in real-world studies. To address theseissues, we present MutaPLM, a unified framework for interpreting and navigatingprotein mutations with protein language models. MutaPLM introduces a proteindelta network that captures explicit protein mutation representations within aunified feature space, and a transfer learning pipeline with a chain-of-thought(CoT) strategy to harvest protein mutation knowledge from biomedical texts. Wealso construct MutaDescribe, the first large-scale protein mutation datasetwith rich textual annotations, which provides cross-modal supervision signals.Through comprehensive experiments, we demonstrate that MutaPLM excels atproviding human-understandable explanations for mutational effects andprioritizing novel mutations with desirable properties. Our code, model, anddata are open-sourced at https://github.com/PharMolix/MutaPLM.</description>
      <author>example@mail.com (Yizhen Luo, Zikun Nie, Massimo Hong, Suyuan Zhao, Hao Zhou, Zaiqing Nie)</author>
      <guid isPermaLink="false">2410.22949v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>DOA-Aware Audio-Visual Self-Supervised Learning for Sound Event Localization and Detection</title>
      <link>http://arxiv.org/abs/2410.22803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to APSIPA2023&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云分割是3D理解中的一个重要主题，传统上使用CNN或Transformer进行处理。&lt;h4&gt;目的&lt;/h4&gt;解决Mamba在点云分割中未能超越最佳CNN和Transformer方法的性能问题。&lt;h4&gt;方法&lt;/h4&gt;识别有效和高效的点云分割架构的关键组成部分，并增强标准Mamba以适应点云分割。&lt;h4&gt;主要发现&lt;/h4&gt;{'空间局部性和稳健的上下文理解': '对强性能至关重要。', 'Mamba的线性计算复杂度': '提供了比Transformer更优的数据和推理效率，同时保持强大的上下文理解能力。', 'Mamba的缺点': ['强制因果性不适合处理无依赖的点云。', '单向扫描策略导致方向性偏差，限制了捕捉无序点云的全部上下文能力。']}&lt;h4&gt;改进措施&lt;/h4&gt;去除因果卷积，引入新的双向跨步SSM，以增强模型捕捉空间关系的能力。&lt;h4&gt;结论&lt;/h4&gt;开发了名为MEEPO的新架构，有效整合CNN和Mamba的优势，显著超越之前的最佳方法PTv3，提升了性能和效率。&lt;h4&gt;性能提升&lt;/h4&gt;MEEPO在多个关键基准数据集上比PTv3提高了最多0.8 mIoU，同时速度提高了42.1%，内存效率提高了5.53倍。&lt;h4&gt;总结&lt;/h4&gt;通过综合不同模型的优势，MEEPO在点云分割领域实现了显著的性能突破。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper describes sound event localization and detection (SELD) forspatial audio recordings captured by firstorder ambisonics (FOA) microphones.In this task, one may train a deep neural network (DNN) using FOA dataannotated with the classes and directions of arrival (DOAs) of sound events.However, the performance of this approach is severely bounded by the amount ofannotated data. To overcome this limitation, we propose a novel method ofpretraining the feature extraction part of the DNN in a self-supervised manner.We use spatial audio-visual recordings abundantly available as virtual realitycontents. Assuming that sound objects are concurrently observed by the FOAmicrophones and the omni-directional camera, we jointly train audio and visualencoders with contrastive learning such that the audio and visual embeddings ofthe same recording and DOA are made close. A key feature of our method is thatthe DOA-wise audio embeddings are jointly extracted from the raw audio data,while the DOA-wise visual embeddings are separately extracted from the localvisual crops centered on the corresponding DOA. This encourages the latentfeatures of the audio encoder to represent both the classes and DOAs of soundevents. The experiment using the DCASE2022 Task 3 dataset of 20 hours showsnon-annotated audio-visual recordings of 100 hours reduced the error score ofSELD from 36.4 pts to 34.9 pts.</description>
      <author>example@mail.com (Yoto Fujita, Yoshiaki Bando, Keisuke Imoto, Masaki Onishi, Kazuyoshi Yoshii)</author>
      <guid isPermaLink="false">2410.22803v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Exploring contextual modeling with linear complexity for point cloud segmentation</title>
      <link>http://arxiv.org/abs/2410.21211v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）的强大在于其能够学习高度表达性的表示，适用于广泛的任务，但预训练模型需要多阶段微调才能有效应用于下游任务。&lt;h4&gt;目的&lt;/h4&gt;引入一个带有参数高效微调（PEFT）方案的元学习框架，以解决模型重训练和微调阶段独立性带来的性能问题。&lt;h4&gt;方法&lt;/h4&gt;在中间重训练阶段，使用元学习框架和低秩适应方法对线性模型进行理论分析，以学习易于适应未见任务的模型。&lt;h4&gt;主要发现&lt;/h4&gt;标准重训练在寻找可适应参数集方面存在次优性，而我们的方法能够恢复最佳可适应参数。&lt;h4&gt;结论&lt;/h4&gt;在ConvAI2数据集中对RoBERTa模型进行重训练时，使用提议的元学习方案相较于传统方法观察到显著的性能提升。&lt;h4&gt;总结&lt;/h4&gt;通过元学习框架优化重训练过程，可以提高基础模型的适应性和性能，尤其在低资源下游任务中表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud segmentation is an important topic in 3D understanding that hastraditionally has been tackled using either the CNN or Transformer. Recently,Mamba has emerged as a promising alternative, offering efficient long-rangecontextual modeling capabilities without the quadratic complexity associatedwith Transformer's attention mechanisms. However, despite Mamba's potential,early efforts have all failed to achieve better performance than the bestCNN-based and Transformer-based methods. In this work, we address thischallenge by identifying the key components of an effective and efficient pointcloud segmentation architecture. Specifically, we show that: 1) Spatiallocality and robust contextual understanding are critical for strongperformance, and 2) Mamba features linear computational complexity, offeringsuperior data and inference efficiency compared to Transformers, while stillbeing capable of delivering strong contextual understanding. Additionally, wefurther enhance the standard Mamba specifically for point cloud segmentation byidentifying its two key shortcomings. First, the enforced causality in theoriginal Mamba is unsuitable for processing point clouds that have no suchdependencies. Second, its unidirectional scanning strategy imposes adirectional bias, hampering its ability to capture the full context ofunordered point clouds in a single pass. To address these issues, we carefullyremove the causal convolutions and introduce a novel Strided Bidirectional SSMto enhance the model's capability to capture spatial relationships. Our effortsculminate in the development of a novel architecture named MEEPO, whicheffectively integrates the strengths of CNN and Mamba. MEEPO surpasses theprevious state-of-the-art method, PTv3, by up to +0.8 mIoU on multiple keybenchmark datasets, while being 42.1% faster and 5.53x more memory efficient.</description>
      <author>example@mail.com (Yong Xien Chng, Xuchong Qiu, Yizeng Han, Yifan Pu, Jiewei Cao, Gao Huang)</author>
      <guid isPermaLink="false">2410.21211v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning Adaptable Foundation Models</title>
      <link>http://arxiv.org/abs/2410.22264v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）的强大在于其能够学习高度表达性的表示，适用于广泛的任务，但预训练模型需要多阶段微调才能有效应用于下游任务。&lt;h4&gt;目的&lt;/h4&gt;引入一个带有参数高效微调（PEFT）方案的元学习框架，以解决模型重训练和微调阶段独立性带来的性能问题。&lt;h4&gt;方法&lt;/h4&gt;在中间重训练阶段，使用元学习框架和低秩适应方法对线性模型进行理论分析，以学习易于适应未见任务的模型。&lt;h4&gt;主要发现&lt;/h4&gt;标准重训练在寻找可适应参数集方面存在次优性，而我们的方法能够恢复最佳可适应参数。&lt;h4&gt;结论&lt;/h4&gt;在ConvAI2数据集中对RoBERTa模型进行重训练时，使用提议的元学习方案相较于传统方法观察到显著的性能提升。&lt;h4&gt;总结&lt;/h4&gt;通过元学习框架优化重训练过程，可以提高基础模型的适应性和性能，尤其在低资源下游任务中表现更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The power of foundation models (FMs) lies in their capacity to learn highlyexpressive representations that can be adapted to a broad spectrum of tasks.However, these pretrained models require multiple stages of fine-tuning tobecome effective for downstream applications. Conventionally, the model isfirst retrained on the aggregate of a diverse set of tasks of interest and thenadapted to specific low-resource downstream tasks by utilizing aparameter-efficient fine-tuning (PEFT) scheme. While this two-phase procedureseems reasonable, the independence of the retraining and fine-tuning phasescauses a major issue, as there is no guarantee the retrained model will achievegood performance post-fine-tuning. To explicitly address this issue, weintroduce a meta-learning framework infused with PEFT in this intermediateretraining stage to learn a model that can be easily adapted to unseen tasks.For our theoretical results, we focus on linear models using low-rankadaptations. In this setting, we demonstrate the suboptimality of standardretraining for finding an adaptable set of parameters. Further, we prove thatour method recovers the optimally adaptable parameters. We then apply thesetheoretical insights to retraining the RoBERTa model to predict thecontinuation of conversations between different personas within the ConvAI2dataset. Empirically, we observe significant performance benefits using ourproposed meta-learning scheme during retraining relative to the conventionalapproach.</description>
      <author>example@mail.com (Jacob L. Block, Sundararajan Srinivasan, Liam Collins, Aryan Mokhtari, Sanjay Shakkottai)</author>
      <guid isPermaLink="false">2410.22264v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters</title>
      <link>http://arxiv.org/abs/2410.23168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Transformers已成为基础模型的主要架构，因其在多个领域表现优异，但大规模扩展的成本仍然是一个重要问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的架构，解决模型扩展过程中的高计算成本。&lt;h4&gt;方法&lt;/h4&gt;引入TokenFormer架构，利用注意力机制处理输入token与模型参数之间的交互，增强架构灵活性。&lt;h4&gt;主要发现&lt;/h4&gt;通过将模型参数视为token，替代传统的线性投影，实现逐步高效的扩展，避免从头开始重新训练。&lt;h4&gt;结论&lt;/h4&gt;TokenFormer模型在参数从124M扩展到1.4B时，性能与从头训练的Transformers相当，同时大幅降低了训练成本。&lt;h4&gt;总结&lt;/h4&gt;TokenFormer提供了一种新方法，允许在不重训的情况下高效扩展Transformers，具有良好的性能和较低的计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/haiyang-w/tokenformer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transformers have become the predominant architecture in foundation modelsdue to their excellent performance across various domains. However, thesubstantial cost of scaling these models remains a significant concern. Thisproblem arises primarily from their dependence on a fixed number of parameterswithin linear projections. When architectural modifications (e.g., channeldimensions) are introduced, the entire model typically requires retraining fromscratch. As model sizes continue growing, this strategy results in increasinglyhigh computational costs and becomes unsustainable. To overcome this problem,we introduce TokenFormer, a natively scalable architecture that leverages theattention mechanism not only for computations among input tokens but also forinteractions between tokens and model parameters, thereby enhancingarchitectural flexibility. By treating model parameters as tokens, we replaceall the linear projections in Transformers with our token-parameter attentionlayer, where input tokens act as queries and model parameters as keys andvalues. This reformulation allows for progressive and efficient scaling withoutnecessitating retraining from scratch. Our model scales from 124M to 1.4Bparameters by incrementally adding new key-value parameter pairs, achievingperformance comparable to Transformers trained from scratch while greatlyreducing training costs. Code and models are available at\url{https://github.com/Haiyang-W/TokenFormer}.</description>
      <author>example@mail.com (Haiyang Wang, Yue Fan, Muhammad Ferjad Naeem, Yongqin Xian, Jan Eric Lenssen, Liwei Wang, Federico Tombari, Bernt Schiele)</author>
      <guid isPermaLink="false">2410.23168v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Don't Just Pay Attention, PLANT It: Transfer L2R Models to Fine-tune Attention in Extreme Multi-Label Text Classification</title>
      <link>http://arxiv.org/abs/2410.23066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的极端多标签文本分类（XMTC）模型依赖多标签注意力层来关注输入文本中的关键标记，但获取最佳注意力权重具有挑战性且资源密集。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的迁移学习策略PLANT（预训练和利用的注意力），以优化XMTC解码器的微调。&lt;h4&gt;方法&lt;/h4&gt;PLANT通过利用预训练的学习排名模型作为植入的注意力层，结合互信息增益增强注意力，引入无注意力机制，并实施状态解码器以保持上下文。&lt;h4&gt;主要发现&lt;/h4&gt;PLANT在多个数据集（mimicfull, mimicfifty, mimicfour, eurlex, wikiten）上超越了现有的最先进方法，尤其在小样本场景中表现优异，F1分数在mimicrare和mimicfew上分别提高超过50和36个百分点。&lt;h4&gt;结论&lt;/h4&gt;PLANT在处理稀有代码方面展现出卓越能力，并在小样本场景中以显著更少的数据实现与传统模型相当的精度。&lt;h4&gt;总结&lt;/h4&gt;通过关键技术创新，PLANT不仅提高了模型性能，还在小样本情况下展现出显著的数据效率，综合消融研究验证了这些贡献的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State-of-the-art Extreme Multi-Label Text Classification (XMTC) models relyheavily on multi-label attention layers to focus on key tokens in input text,but obtaining optimal attention weights is challenging and resource-intensive.To address this, we introduce PLANT -- Pretrained and Leveraged AtteNTion -- anovel transfer learning strategy for fine-tuning XMTC decoders. PLANT surpassesexisting state-of-the-art methods across all metrics on mimicfull, mimicfifty,mimicfour, eurlex, and wikiten datasets. It particularly excels in few-shotscenarios, outperforming previous models specifically designed for few-shotscenarios by over 50 percentage points in F1 scores on mimicrare and by over 36percentage points on mimicfew, demonstrating its superior capability inhandling rare codes. PLANT also shows remarkable data efficiency in few-shotscenarios, achieving precision comparable to traditional models withsignificantly less data. These results are achieved through key technicalinnovations: leveraging a pretrained Learning-to-Rank model as the plantedattention layer, integrating mutual-information gain to enhance attention,introducing an inattention mechanism, and implementing a stateful-decoder tomaintain context. Comprehensive ablation studies validate the importance ofthese contributions in realizing the performance gains.</description>
      <author>example@mail.com (Debjyoti Saharoy, Javed A. Aslam, Virgil Pavlu)</author>
      <guid isPermaLink="false">2410.23066v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Multimodality Helps Few-Shot 3D Point Cloud Semantic Segmentation</title>
      <link>http://arxiv.org/abs/2410.22489v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;少样本3D点云分割（FS-PCS）旨在以最少的标注支持样本对新类别进行模型泛化。&lt;h4&gt;目的&lt;/h4&gt;解决现有FS-PCS方法主要集中于单模态点云输入，忽视了利用多模态信息的潜在好处。&lt;h4&gt;方法&lt;/h4&gt;提出了一种无成本的多模态FS-PCS设置，使用文本标签和可用的2D图像模态，开发了MultiModal Few-Shot SegNet (MM-FSS)模型。&lt;h4&gt;主要发现&lt;/h4&gt;MM-FSS通过共享骨干网络提取跨模态和单模态视觉特征，采用预训练文本编码器生成文本嵌入。引入多模态关联融合（MCF）模块和多模态语义融合（MSF）模块以优化多模态信息利用，并提出了测试时自适应跨模态校准（TACC）技术来减轻训练偏差。&lt;h4&gt;结论&lt;/h4&gt;在S3DIS和ScanNet数据集上的实验结果显示，该方法显著提高了性能，表明利用常被忽视的自由模态对FS-PCS的益处，为未来研究提供了宝贵的见解。&lt;h4&gt;总结&lt;/h4&gt;代码可在https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Few-shot 3D point cloud segmentation (FS-PCS) aims at generalizing models tosegment novel categories with minimal annotated support samples. While existingFS-PCS methods have shown promise, they primarily focus on unimodal point cloudinputs, overlooking the potential benefits of leveraging multimodalinformation. In this paper, we address this gap by introducing a cost-freemultimodal FS-PCS setup, utilizing textual labels and the potentially available2D image modality. Under this easy-to-achieve setup, we present the MultiModalFew-Shot SegNet (MM-FSS), a model effectively harnessing complementaryinformation from multiple modalities. MM-FSS employs a shared backbone with twoheads to extract intermodal and unimodal visual features, and a pretrained textencoder to generate text embeddings. To fully exploit the multimodalinformation, we propose a Multimodal Correlation Fusion (MCF) module togenerate multimodal correlations, and a Multimodal Semantic Fusion (MSF) moduleto refine the correlations using text-aware semantic guidance. Additionally, wepropose a simple yet effective Test-time Adaptive Cross-modal Calibration(TACC) technique to mitigate training bias, further improving generalization.Experimental results on S3DIS and ScanNet datasets demonstrate significantperformance improvements achieved by our method. The efficacy of our approachindicates the benefits of leveraging commonly-ignored free modalities forFS-PCS, providing valuable insights for future research. The code is availableat https://github.com/ZhaochongAn/Multimodality-3D-Few-Shot .</description>
      <author>example@mail.com (Zhaochong An, Guolei Sun, Yun Liu, Runjia Li, Min Wu, Ming-Ming Cheng, Ender Konukoglu, Serge Belongie)</author>
      <guid isPermaLink="false">2410.22489v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Representational learning for an anomalous sound detection system with source separation model</title>
      <link>http://arxiv.org/abs/2410.21797v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  DCASE 2024 workshop published&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;检测机械操作中的异常声音面临显著挑战，主要由于难以概括异常声学模式。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的训练方法，以改善异常声音检测系统的性能。&lt;h4&gt;方法&lt;/h4&gt;基于源分离模型（CMGAN）的方法，旨在从目标和非目标声学信号的混合中分离出非目标机器声音。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在性能上优于传统的自编码器训练方法和专注于隔离目标机器信号的源分离技术。&lt;h4&gt;结论&lt;/h4&gt;随着非目标数据量的增加，该方法展示了增强表征学习的潜力，同时保持目标类数据的恒定数量。&lt;h4&gt;总结&lt;/h4&gt;通过有效利用多样化的机器声音，CMGAN方法可以在样本量有限的情况下训练复杂的神经网络架构，提高异常声音检测的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The detection of anomalous sounds in machinery operation presents asignificant challenge due to the difficulty in generalizing anomalous acousticpatterns. This task is typically approached as an unsupervised learning ornovelty detection problem, given the complexities associated with theacquisition of comprehensive anomalous acoustic data. Conventionalmethodologies for training anomalous sound detection systems primarily employauto-encoder architectures or representational learning with auxiliary tasks.However, both approaches have inherent limitations. Auto-encoder structures areconstrained to utilizing only the target machine's operational sounds, whiletraining with auxiliary tasks, although capable of incorporating diverseacoustic inputs, may yield representations that lack correlation with thecharacteristic acoustic signatures of anomalous conditions. We propose atraining method based on the source separation model (CMGAN) that aims toisolate non-target machine sounds from a mixture of target and non-target classacoustic signals. This approach enables the effective utilization of diversemachine sounds and facilitates the training of complex neural networkarchitectures with limited sample sizes. Our experimental results demonstratethat the proposed method yields better performance compared to bothconventional auto-encoder training approaches and source separation techniquesthat focus on isolating target machine signals. Moreover, our experimentalresults demonstrate that the proposed method exhibits the potential forenhanced representation learning as the quantity of non-target data increases,even while maintaining a constant volume of target class data.</description>
      <author>example@mail.com (Seunghyeon Shin, Seokjin Lee)</author>
      <guid isPermaLink="false">2410.21797v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes</title>
      <link>http://arxiv.org/abs/2410.23126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究现代Hopfield模型和核化Hopfield模型(KHMs)的最佳记忆容量。&lt;h4&gt;目的&lt;/h4&gt;分析KHMs的记忆配置与信息论中的球形码之间的关系。&lt;h4&gt;方法&lt;/h4&gt;将KHMs的记忆问题视为超球面上的点排列问题，通过建立球形码的专门化。&lt;h4&gt;主要发现&lt;/h4&gt;{'1': 'KHMs的最佳容量发生在特征空间允许记忆形成最佳球形码时。', '2': '提出了分析KHMs如何实现最佳记忆容量，并识别相应的必要条件。', '3': '建立了一个匹配文献中已知指数下界的上限容量界限。', '4': '开发了一个子线性时间算法U-Hop+以达到KHMs的最佳容量。', '5': '分析了所需特征维度相对于存储记忆数量的扩展行为。'}&lt;h4&gt;结论&lt;/h4&gt;这些发现改善了KHMs的检索能力和相应变换器的表示学习。&lt;h4&gt;实验结果&lt;/h4&gt;通过详尽的数值结果支持理论发现。&lt;h4&gt;总结&lt;/h4&gt;研究为现代Hopfield模型提供了首个紧凑且最佳的渐近记忆容量分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the optimal memorization capacity of modern Hopfield models andKernelized Hopfield Models (KHMs), a transformer-compatible class of DenseAssociative Memories. We present a tight analysis by establishing a connectionbetween the memory configuration of KHMs and spherical codes from informationtheory. Specifically, we treat the stored memory set as a specialized sphericalcode. This enables us to cast the memorization problem in KHMs into a pointarrangement problem on a hypersphere. We show that the optimal capacity of KHMsoccurs when the feature space allows memories to form an optimal sphericalcode. This unique perspective leads to: (i) An analysis of how KHMs achieveoptimal memory capacity, and identify corresponding necessary conditions.Importantly, we establish an upper capacity bound that matches the well-knownexponential lower bound in the literature. This provides the first tight andoptimal asymptotic memory capacity for modern Hopfield models. (ii) Asub-linear time algorithm $\mathtt{U}\text{-}\mathtt{Hop}$+ to reach KHMs'optimal capacity. (iii) An analysis of the scaling behavior of the requiredfeature dimension relative to the number of stored memories. These effortsimprove both the retrieval capability of KHMs and the representation learningof corresponding transformers. Experimentally, we provide thorough numericalresults to back up theoretical findings.</description>
      <author>example@mail.com (Jerry Yao-Chieh Hu, Dennis Wu, Han Liu)</author>
      <guid isPermaLink="false">2410.23126v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>MVSDet: Multi-View Indoor 3D Object Detection via Efficient Plane Sweeps</title>
      <link>http://arxiv.org/abs/2410.21566v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多视角室内3D物体检测的关键挑战是从图像中推断准确的几何信息以实现精确的3D检测。&lt;h4&gt;目的&lt;/h4&gt;提出MVSDet，利用平面扫描进行几何感知的3D物体检测。&lt;h4&gt;方法&lt;/h4&gt;设计了一种概率采样和软加权机制，以决定像素特征在3D体积中的放置，选择概率体中得分最高的多个位置，并用概率分数表示置信度。&lt;h4&gt;主要发现&lt;/h4&gt;通过应用像素对齐的高斯溅射技术来规范化深度预测，并在计算开销较小的情况下提高检测性能。&lt;h4&gt;结论&lt;/h4&gt;在ScanNet和ARKIT Scenes数据集上的广泛实验显示了模型的优越性。&lt;h4&gt;代码&lt;/h4&gt;我们的代码可在https://github.com/Pixie8888/MVSDet获取。&lt;h4&gt;总结&lt;/h4&gt;MVSDet通过新的方法改善了多视角3D物体检测的性能，解决了以往方法中几何信息不准确的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/pixie8888/mvsdet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The key challenge of multi-view indoor 3D object detection is to inferaccurate geometry information from images for precise 3D detection. Previousmethod relies on NeRF for geometry reasoning. However, the geometry extractedfrom NeRF is generally inaccurate, which leads to sub-optimal detectionperformance. In this paper, we propose MVSDet which utilizes plane sweep forgeometry-aware 3D object detection. To circumvent the requirement for a largenumber of depth planes for accurate depth prediction, we design a probabilisticsampling and soft weighting mechanism to decide the placement of pixel featureson the 3D volume. We select multiple locations that score top in theprobability volume for each pixel and use their probability score to indicatethe confidence. We further apply recent pixel-aligned Gaussian Splatting toregularize depth prediction and improve detection performance with littlecomputation overhead. Extensive experiments on ScanNet and ARKitScenes datasetsare conducted to show the superiority of our model. Our code is available athttps://github.com/Pixie8888/MVSDet.</description>
      <author>example@mail.com (Yating Xu, Chen Li, Gim Hee Lee)</author>
      <guid isPermaLink="false">2410.21566v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Aligning Audio-Visual Joint Representations with an Agentic Workflow</title>
      <link>http://arxiv.org/abs/2410.23230v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉内容与伴随音频信号自然形成联合表示，以改善音视频相关应用。&lt;h4&gt;目的&lt;/h4&gt;提高音视频联合表示的质量，强调音频与视频数据的对齐重要性。&lt;h4&gt;方法&lt;/h4&gt;提出一种由名为AVAgent的基于大语言模型的助手控制的工作流程，通过将音频信号对齐到视觉数据来改善联合表示。&lt;h4&gt;主要发现&lt;/h4&gt;AVAgent利用多模态大语言模型将音频和视觉数据分别转换为语言描述，并评估其对齐情况，必要时编辑音频信号。&lt;h4&gt;结论&lt;/h4&gt;通过工具使用、规划和反思的循环步骤，音频信号逐渐与视觉内容对齐，现有方法可以直接利用对齐的音视频数据以改善联合表示。&lt;h4&gt;总结&lt;/h4&gt;实验结果全面展示了所提出方法在多种下游任务中优于以往基线的最新性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual content and accompanied audio signals naturally formulate a jointrepresentation to improve audio-visual (AV) related applications. While studiesdevelop various AV representation learning frameworks, the importance of AVdata alignment is usually undermined for achieving high-quality representation.We observe that an audio signal may contain background noise interference.Also, non-synchronization may appear between audio and video streams. Thesenon-strict data alignment limits representation quality and downgradeapplication performance. In this paper, we propose to improve AV jointrepresentations from a data-centric perspective by aligning audio signals tovisual data. Our alignment is conducted in an agentic workflow controlled by anLLM-based assistant named AVAgent. For each input AV data pair, our AVAgentuses a multi-modal LLM to convert audio and visual data into languagedescriptions separately (i.e., tool use). Then, AVAgent reasons whether thispaired data is aligned well and plans to edit the audio signal if needed (i.e.,planning). The audio editing is executed by predefined actions that filternoise or augment data. Moreover, we use a VLM to evaluate how modified audiosignals match the visual content and provide feedback to AVAgent (i.e.,reflection). The tool use, planning, and reflection steps operate cyclically tobecome an agentic workflow where audio signals are gradually aligned to visualcontent. To this end, existing methods can directly leverage the aligned AVdata via our agentic workflow to improve AV joint representations. Theexperimental results comprehensively demonstrate the state-of-the-artperformance of the proposed approach against previous baselines in diversedownstream tasks.</description>
      <author>example@mail.com (Shentong Mo, Yibing Song)</author>
      <guid isPermaLink="false">2410.23230v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Multimodal Fusion of In-process Sensor Data for Advanced Manufacturing Process Monitoring</title>
      <link>http://arxiv.org/abs/2410.22558v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;有效监控制造过程对保持产品质量和运营效率至关重要，现代制造环境生成大量多模态数据。&lt;h4&gt;目的&lt;/h4&gt;提出一种新型的多模态传感器数据融合方法，以应对高维数据的解读挑战，尤其是在缺乏标签数据的情况下。&lt;h4&gt;方法&lt;/h4&gt;采用对比学习技术，关联不同数据模态，开发了五种独特模态的编码器，包括视觉图像、音频信号、激光位置和激光功率测量。&lt;h4&gt;主要发现&lt;/h4&gt;通过将高维数据集压缩为低维表示空间，该方法提高了流程控制、异常检测和质量保证等下游任务的效率。&lt;h4&gt;结论&lt;/h4&gt;研究展示了该方法在先进制造系统中增强过程监控能力的潜力，并为智能制造提供了灵活、可扩展的多模态数据融合框架。&lt;h4&gt;总结&lt;/h4&gt;本研究为适应多样化的制造环境和传感器配置提供了有效的解决方案，推动了智能制造的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective monitoring of manufacturing processes is crucial for maintainingproduct quality and operational efficiency. Modern manufacturing environmentsgenerate vast amounts of multimodal data, including visual imagery from variousperspectives and resolutions, hyperspectral data, and machine health monitoringinformation such as actuator positions, accelerometer readings, and temperaturemeasurements. However, interpreting this complex, high-dimensional datapresents significant challenges, particularly when labeled datasets areunavailable. This paper presents a novel approach to multimodal sensor datafusion in manufacturing processes, inspired by the Contrastive Language-ImagePre-training (CLIP) model. We leverage contrastive learning techniques tocorrelate different data modalities without the need for labeled data,developing encoders for five distinct modalities: visual imagery, audiosignals, laser position (x and y coordinates), and laser power measurements. Bycompressing these high-dimensional datasets into low-dimensionalrepresentational spaces, our approach facilitates downstream tasks such asprocess control, anomaly detection, and quality assurance. We evaluate theeffectiveness of our approach through experiments, demonstrating its potentialto enhance process monitoring capabilities in advanced manufacturing systems.This research contributes to smart manufacturing by providing a flexible,scalable framework for multimodal data fusion that can adapt to diversemanufacturing environments and sensor configurations.</description>
      <author>example@mail.com (Matthew McKinney, Anthony Garland, Dale Cillessen, Jesse Adamczyk, Dan Bolintineanu, Michael Heiden, Elliott Fowler, Brad L. Boyce)</author>
      <guid isPermaLink="false">2410.22558v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Unified Domain Generalization and Adaptation for Multi-View 3D Object Detection</title>
      <link>http://arxiv.org/abs/2410.22461v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D物体检测在多视角摄像头的应用中取得了进展，但监督学习方法在面对未见和未标记的数据集时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出统一领域泛化与适应（UDGA）方法，以解决3D物体检测中的几何失配和标注资源不足的问题。&lt;h4&gt;方法&lt;/h4&gt;提出多视角重叠深度约束，利用多视角之间的强关联性，减少因视角变化带来的几何差距；同时引入标签高效的领域适应方法，使用极少的标签进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;UDGA框架在源域和目标域中均能实现稳定的检测性能，有效弥合领域差距，并减少对标注的需求。&lt;h4&gt;结论&lt;/h4&gt;UDGA在大规模基准测试（如nuScenes、Lyft和Waymo）中展示了其鲁棒性，优于现有的最先进方法。&lt;h4&gt;总结&lt;/h4&gt;UDGA方法通过创新的约束和适应策略，提升了3D物体检测的有效性和效率，尤其在资源有限的情况下表现突出。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in 3D object detection leveraging multi-view cameras havedemonstrated their practical and economical value in various challenging visiontasks. However, typical supervised learning approaches face challenges inachieving satisfactory adaptation toward unseen and unlabeled target datasets(\ie, direct transfer) due to the inevitable geometric misalignment between thesource and target domains. In practice, we also encounter constraints onresources for training models and collecting annotations for the successfuldeployment of 3D object detectors. In this paper, we propose Unified DomainGeneralization and Adaptation (UDGA), a practical solution to mitigate thosedrawbacks. We first propose Multi-view Overlap Depth Constraint that leveragesthe strong association between multi-view, significantly alleviating geometricgaps due to perspective view changes. Then, we present a Label-Efficient DomainAdaptation approach to handle unfamiliar targets with significantly feweramounts of labels (\ie, 1$\%$ and 5$\%)$, while preserving well-defined sourceknowledge for training efficiency. Overall, UDGA framework enables stabledetection performance in both source and target domains, effectively bridginginevitable domain gaps, while demanding fewer annotations. We demonstrate therobustness of UDGA with large-scale benchmarks: nuScenes, Lyft, and Waymo,where our framework outperforms the current state-of-the-art methods.</description>
      <author>example@mail.com (Gyusam Chang, Jiwon Lee, Donghyun Kim, Jinkyu Kim, Dongwook Lee, Daehyun Ji, Sujin Jang, Sangpil Kim)</author>
      <guid isPermaLink="false">2410.22461v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Conditional Forecasting of Margin Calls using Dynamic Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2410.23275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新颖的动态图神经网络（DGNN）架构，用于解决时间金融网络中的条件性m步预测问题。&lt;h4&gt;目的&lt;/h4&gt;验证DGNN在模拟数据上的有效性，特别是在利率互换（IRS）交易网络中的应用。&lt;h4&gt;方法&lt;/h4&gt;使用从时间金融网络模型中模拟的数据，捕捉利率互换交易网络的典型特征。&lt;h4&gt;主要发现&lt;/h4&gt;DGNN能够在预定的压力测试场景下，准确预测净变动保证金，时间跨度可达21天。&lt;h4&gt;结论&lt;/h4&gt;网络动态可以成功融入压力测试实践，为监管者和决策者提供重要的系统性风险监测工具。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了DGNN在金融网络预测中的潜力，尤其是在动态环境下的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel Dynamic Graph Neural Network (DGNN) architecture forsolving conditional $m$-steps ahead forecasting problems in temporal financialnetworks. The proposed DGNN is validated on simulated data from a temporalfinancial network model capturing stylized features of Interest Rate Swaps(IRSs) transaction networks, where financial entities trade swap contractsdynamically and the network topology evolves conditionally on a reference rate.The proposed model is able to produce accurate conditional forecasts of netvariation margins up to a $21$-day horizon by leveraging conditionalinformation under pre-determined stress test scenarios. Our work shows that thenetwork dynamics can be successfully incorporated into stress-testingpractices, thus providing regulators and policymakers with a crucial tool forsystemic risk monitoring.</description>
      <author>example@mail.com (Matteo Citterio, Marco D'Errico, Gabriele Visentin)</author>
      <guid isPermaLink="false">2410.23275v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Method of Moments for Estimation of Noisy Curves</title>
      <link>http://arxiv.org/abs/2410.23220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "研究从高噪声的高斯点云中恢复高维分段线性曲线的问题。",
    "目的": "确定恢复曲线所需的样本复杂度，以及提出有效的恢复方法。",
    "方法": "基于第三阶矩张量的拟合，采用精确的初始化策略进行曲线恢复。",
    "主要发现": "恢复曲线所需的样本复杂度至少与噪声的六次方成正比，且$O(\sigma^6)$的样本量是足够的。",
    "结论": "所提出的方法能有效地从高噪声数据中恢复出分段线性曲线，相关代码已公开于GitHub。",
    "总结": "本文提供了从高噪声点云中恢复高维分段线性曲线的理论基础和实践方法，并验证了其有效性。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we study the problem of recovering a ground truth highdimensional piecewise linear curve $C^*(t):[0, 1]\to\mathbb{R}^d$ from a highnoise Gaussian point cloud with covariance $\sigma^2I$ centered around thecurve. We establish that the sample complexity of recovering $C^*$ from datascales with order at least $\sigma^6$. We then show that recovery of apiecewise linear curve from the third moment is locally well-posed, and hence$O(\sigma^6)$ samples is also sufficient for recovery. We propose methods torecover a curve from data based on a fitting to the third moment tensor with acareful initialization strategy and conduct some numerical experimentsverifying the ability of our methods to recover curves. All code for ournumerical experiments is publicly available on GitHub.</description>
      <author>example@mail.com (Phillip Lo, Yuehaw Khoo)</author>
      <guid isPermaLink="false">2410.23220v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Micro-Structures Graph-Based Point Cloud Registration for Balancing Efficiency and Accuracy</title>
      <link>http://arxiv.org/abs/2410.21857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云配准（PCR）是摄影测量和遥感中的一个基本且重要的问题，旨在寻找点集之间的最佳刚性变换。&lt;h4&gt;目的&lt;/h4&gt;实现高效且精确的点云配准面临着重大挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的基于微结构图的全局点云配准方法，包括两个阶段：1) 粗配准（CR）：通过图形整合微结构，采用高效的图形层次策略去除异常值以获得最大共识集，并提出了基于Lie代数空间的鲁棒GNC-Welsch估计器进行优化；2) 精细配准（FR）：使用八叉树方法自适应搜索微结构中的平面特征，通过最小化点到平面的距离获得更精确的局部对齐，并将其视为平面调整算法结合安德森加速优化（PA-AA）。&lt;h4&gt;主要发现&lt;/h4&gt;在真实数据上的广泛实验表明，所提出的方法在3DMatch和ETH数据集上表现良好，相比于最先进的方法，具有更高的精度指标，并且时间成本减少至少三分之一。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在点云配准任务中表现出色，能够有效提高配准的准确性和效率。&lt;h4&gt;总结&lt;/h4&gt;本研究为点云配准提供了一种新的方法论，具有重要的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TGRS.2024.3488502&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point Cloud Registration (PCR) is a fundamental and significant issue inphotogrammetry and remote sensing, aiming to seek the optimal rigidtransformation between sets of points. Achieving efficient and precise PCRposes a considerable challenge. We propose a novel micro-structures graph-basedglobal point cloud registration method. The overall method is comprised of twostages. 1) Coarse registration (CR): We develop a graph incorporatingmicro-structures, employing an efficient graph-based hierarchical strategy toremove outliers for obtaining the maximal consensus set. We propose a robustGNC-Welsch estimator for optimization derived from a robust estimator to theoutlier process in the Lie algebra space, achieving fast and robust alignment.2) Fine registration (FR): To refine local alignment further, we use the octreeapproach to adaptive search plane features in the micro-structures. Byminimizing the distance from the point-to-plane, we can obtain a more preciselocal alignment, and the process will also be addressed effectively by beingtreated as a planar adjustment algorithm combined with Anderson acceleratedoptimization (PA-AA). After extensive experiments on real data, our proposedmethod performs well on the 3DMatch and ETH datasets compared to the mostadvanced methods, achieving higher accuracy metrics and reducing the time costby at least one-third.</description>
      <author>example@mail.com (Rongling Zhang, Li Yan, Pengcheng Wei, Hong Xie, Pinzhuo Wang, Binbing Wang)</author>
      <guid isPermaLink="false">2410.21857v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Paradigm Synergy: Can a Cross-Paradigm Objective Enhance Long-Tailed Learning?</title>
      <link>http://arxiv.org/abs/2410.22883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督学习(SSL)在多个计算机视觉任务中取得了显著成果，但在长尾分布的真实数据集上的表现较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来弥补自监督学习在处理类不平衡时的不足。&lt;h4&gt;方法&lt;/h4&gt;引入自适应范式协同(APS)，重新审视对比学习，从空间结构的角度动态调整潜在空间结构的均匀性，并结合监督学习的重加权策略。&lt;h4&gt;主要发现&lt;/h4&gt;在常用的长尾数据集上进行的广泛实验表明，APS有效且高效地提升了性能。&lt;h4&gt;结论&lt;/h4&gt;发现监督学习与自监督学习之间可以更深入地整合，为处理真实世界类不平衡问题提供了可能的解决方案。&lt;h4&gt;总结&lt;/h4&gt;APS方法展示了自监督学习与监督学习结合的潜力，有助于构建更强大的模型以应对类不平衡挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has achieved impressive results across severalcomputer vision tasks, even rivaling supervised methods. However, itsperformance degrades on real-world datasets with long-tailed distributions dueto difficulties in capturing inherent class imbalances. Although supervisedlong-tailed learning offers significant insights, the absence of labels in SSLprevents direct transfer of these strategies.To bridge this gap, we introduceAdaptive Paradigm Synergy (APS), a cross-paradigm objective that seeks to unifythe strengths of both paradigms. Our approach reexamines contrastive learningfrom a spatial structure perspective, dynamically adjusting the uniformity oflatent space structure through adaptive temperature tuning. Furthermore, wedraw on a re-weighting strategy from supervised learning to compensate for theshortcomings of temperature adjustment in explicit quantityperception.Extensive experiments on commonly used long-tailed datasetsdemonstrate that APS improves performance effectively and efficiently. Ourfindings reveal the potential for deeper integration between supervised andself-supervised learning, paving the way for robust models that handlereal-world class imbalance.</description>
      <author>example@mail.com (Haowen Xiao, Guanghui Liu, Xinyi Gao, Yang Li, Fengmao Lv, Jielei Chu)</author>
      <guid isPermaLink="false">2410.22883v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>S3PT: Scene Semantics and Structure Guided Clustering to Boost Self-Supervised Pre-Training for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.23085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for WACV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，自监督聚类预训练技术如DINO和Cribo在下游检测和分割任务中表现出色，但在实际应用中（如自动驾驶）面临物体类别和尺寸分布不平衡以及复杂场景几何形状的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出S3PT，一种新颖的场景语义与结构引导聚类方法，以提供更一致的自监督训练目标。&lt;h4&gt;方法&lt;/h4&gt;三方面贡献：1. 引入语义分布一致的聚类，提升稀有类别（如摩托车和动物）的表示；2. 采用物体多样性一致的空间聚类，处理不平衡和多样的物体尺寸；3. 提出基于深度的空间聚类，以几何信息正则化学习，进一步细化特征层面的区域分离。&lt;h4&gt;主要发现&lt;/h4&gt;在nuScenes、nuImages和Cityscapes数据集上，所学表示显著提升了下游语义分割和3D物体检测任务的性能，并展示了良好的领域迁移特性。&lt;h4&gt;结论&lt;/h4&gt;S3PT方法通过场景一致的目标和几何信息的引导，改善了自监督学习的效果，尤其对不平衡和稀有类别的处理具有积极影响。&lt;h4&gt;总结&lt;/h4&gt;本研究通过S3PT方法应对现实应用中的挑战，显著提升了物体检测和分割的表现，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent self-supervised clustering-based pre-training techniques like DINO andCribo have shown impressive results for downstream detection and segmentationtasks. However, real-world applications such as autonomous driving facechallenges with imbalanced object class and size distributions and complexscene geometries. In this paper, we propose S3PT a novel scene semantics andstructure guided clustering to provide more scene-consistent objectives forself-supervised training. Specifically, our contributions are threefold: First,we incorporate semantic distribution consistent clustering to encourage betterrepresentation of rare classes such as motorcycles or animals. Second, weintroduce object diversity consistent spatial clustering, to handle imbalancedand diverse object sizes, ranging from large background areas to small objectssuch as pedestrians and traffic signs. Third, we propose a depth-guided spatialclustering to regularize learning based on geometric information of the scene,thus further refining region separation on the feature level. Our learnedrepresentations significantly improve performance in downstream semanticsegmentation and 3D object detection tasks on the nuScenes, nuImages, andCityscapes datasets and show promising domain translation properties.</description>
      <author>example@mail.com (Maciej K. Wozniak, Hariprasath Govindarajan, Marvin Klingner, Camille Maurice, Ravi Kiran, Senthil Yogamani)</author>
      <guid isPermaLink="false">2410.23085v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Theoretical Investigations and Practical Enhancements on Tail Task Risk Minimization in Meta Learning</title>
      <link>http://arxiv.org/abs/2410.22788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;元学习在大型模型和任务分布鲁棒性时代中变得越来越重要，现实场景中任务分布鲁棒性是不可或缺的考虑因素。&lt;h4&gt;目的&lt;/h4&gt;探讨尾部任务风险最小化在快速适应鲁棒性提升中的有效性，并进行理论和实践方面的改进。&lt;h4&gt;方法&lt;/h4&gt;将分布鲁棒策略简化为一个最大-最小优化问题，构建斯塔克尔堡均衡作为解决方案概念，并估计收敛速度。&lt;h4&gt;主要发现&lt;/h4&gt;在存在尾部风险的情况下，推导出泛化界限，建立与估计分位数的联系，并在实践中改进所研究的策略。&lt;h4&gt;结论&lt;/h4&gt;通过广泛的评估，证明了该提案的意义及其在促进多模态大型模型鲁棒性方面的可扩展性。&lt;h4&gt;总结&lt;/h4&gt;本研究为元学习领域提供了理论支持和实践改进，强调了尾部风险管理在任务适应性中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Meta learning is a promising paradigm in the era of large models and taskdistributional robustness has become an indispensable consideration inreal-world scenarios. Recent advances have examined the effectiveness of tailtask risk minimization in fast adaptation robustness improvement\citep{wang2023simple}. This work contributes to more theoreticalinvestigations and practical enhancements in the field. Specifically, we reducethe distributionally robust strategy to a max-min optimization problem,constitute the Stackelberg equilibrium as the solution concept, and estimatethe convergence rate. In the presence of tail risk, we further derive thegeneralization bound, establish connections with estimated quantiles, andpractically improve the studied strategy. Accordingly, extensive evaluationsdemonstrate the significance of our proposal and its scalability to multimodallarge models in boosting robustness.</description>
      <author>example@mail.com (Yiqin Lv, Qi Wang, Dong Liang, Zheng Xie)</author>
      <guid isPermaLink="false">2410.22788v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Partial Channel Dependence with Channel Masks for Time Series Foundation Models</title>
      <link>http://arxiv.org/abs/2410.23222v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS Workshop on Time Series in the Age of Large Models, 2024.
  Oral presentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型在时间序列领域的应用随着大规模时间序列数据集的出现而取得了成功，但之前的研究主要关注模型架构的设计，忽视了通道间的隐性异质性。&lt;h4&gt;目的&lt;/h4&gt;引入部分通道依赖（PCD）概念，以更复杂地调整基于数据集特定信息的通道依赖性。&lt;h4&gt;方法&lt;/h4&gt;提出一种通道掩码，通过两个关键组件实现PCD：1) 编码通道间相对依赖关系的相关矩阵，2) 学习每个数据集特定的绝对依赖关系的领域参数，进而优化相关矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;在包括预测、分类、填补和异常检测等四个时间序列任务中，验证了PCD的有效性，适用于少样本和零样本场景，适用于基础时间序列模型和单任务模型。&lt;h4&gt;结论&lt;/h4&gt;部分通道依赖的引入显著提升了时间序列任务的处理效果。&lt;h4&gt;总结&lt;/h4&gt;本研究为时间序列模型设计提供了新的思路，强调了通道间隐性依赖的处理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in foundation models have been successfully extended tothe time series (TS) domain, facilitated by the emergence of large-scale TSdatasets. However, previous efforts have primarily focused on designing modelarchitectures to address explicit heterogeneity among datasets such as variousnumbers of channels, while often overlooking implicit heterogeneity such asvarying dependencies between channels. In this work, we introduce the conceptof partial channel dependence (PCD), which enables a more sophisticatedadjustment of channel dependencies based on dataset-specific information. Toachieve PCD, we propose a channel mask that captures the relationships betweenchannels within a dataset using two key components: 1) a correlation matrixthat encodes relative dependencies between channels, and 2) domain parametersthat learn the absolute dependencies specific to each dataset, refining thecorrelation matrix. We validate the effectiveness of PCD across four tasks inTS including forecasting, classification, imputation, and anomaly detection,under diverse settings, including few-shot and zero-shot scenarios with both TSfoundation models and single-task models. Code is available athttps://github.com/seunghan96/CM.</description>
      <author>example@mail.com (Seunghan Lee, Taeyoung Park, Kibok Lee)</author>
      <guid isPermaLink="false">2410.23222v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Nested ResNet: A Vision-Based Method for Detecting the Sensing Area of a Drop-in Gamma Probe</title>
      <link>http://arxiv.org/abs/2410.23154v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;目前，临床上广泛使用的滴入伽马探头在机器人辅助手术中用于淋巴结检测，但仅提供音频反馈，缺乏必要的视觉反馈。&lt;h4&gt;目的&lt;/h4&gt;改进基于深度学习的回归方法，以提高探头感应区域的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;引入三分支深度学习框架，主要分支使用立体腹腔镜图像作为输入，采用Nested ResNet架构，并通过迁移学习进行深度估计，同时通过探头轴采样提供方向指导，结合各分支特征以提高预测准确性。&lt;h4&gt;主要发现&lt;/h4&gt;在公开数据集上评估后，方法表现优于以往，2D均值误差减少了22.10%，3D均值误差减少了41.67%。定性比较也进一步证明了方法的精度提升。&lt;h4&gt;结论&lt;/h4&gt;经过广泛评估，解决方案显著提高了感应区域预测的准确性和可靠性，为外科手术中滴入伽马探头的使用提供了更准确的视觉反馈。&lt;h4&gt;总结&lt;/h4&gt;该研究的进展为外科医生提供了更加准确和可靠的定位，提升了手术的安全性和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Purpose: Drop-in gamma probes are widely used in robotic-assisted minimallyinvasive surgery (RAMIS) for lymph node detection. However, these devices onlyprovide audio feedback on signal intensity, lacking the visual feedbacknecessary for precise localisation. Previous work attempted to predict thesensing area location using laparoscopic images, but the prediction accuracywas unsatisfactory. Improvements are needed in the deep learning-basedregression approach.  Methods: We introduce a three-branch deep learning framework to predict thesensing area of the probe. Specifically, we utilise the stereo laparoscopicimages as input for the main branch and develop a Nested ResNet architecture.The framework also incorporates depth estimation via transfer learning andorientation guidance through probe axis sampling. The combined features fromeach branch enhanced the accuracy of the prediction.  Results: Our approach has been evaluated on a publicly available dataset,demonstrating superior performance over previous methods. In particular, ourmethod resulted in a 22.10\% decrease in 2D mean error and a 41.67\% reductionin 3D mean error. Additionally, qualitative comparisons further demonstratedthe improved precision of our approach.  Conclusion: With extensive evaluation, our solution significantly enhancesthe accuracy and reliability of sensing area predictions. This advancementenables visual feedback during the use of the drop-in gamma probe in surgery,providing surgeons with more accurate and reliable localisation.}</description>
      <author>example@mail.com (Songyu Xu, Yicheng Hu, Jionglong Su, Daniel Elson, Baoru Huang)</author>
      <guid isPermaLink="false">2410.23154v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Automated Image-Based Identification and Consistent Classification of Fire Patterns with Quantitative Shape Analysis and Spatial Location Identification</title>
      <link>http://arxiv.org/abs/2410.23105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;火灾模式通常通过调查者的视觉观察进行分类，这导致了主观解释。&lt;h4&gt;目的&lt;/h4&gt;提出一个量化的火灾模式分类框架，以支持火灾调查员，实现一致性和准确性。&lt;h4&gt;方法&lt;/h4&gt;该框架整合了四个组件，包括人机交互提取火灾模式、基于长宽比的随机森林模型分类、火灾现场点云分割以及火灾模式与室内元素的空间关系分析。&lt;h4&gt;主要发现&lt;/h4&gt;该框架的分类结果在合成数据上达到93%的精确度，在真实火灾模式上达到83%。&lt;h4&gt;结论&lt;/h4&gt;该框架综合了定性和定量数据，为火灾模式分析提供了一种新方法。&lt;h4&gt;总结&lt;/h4&gt;该研究为火灾调查提供了一种更为客观和准确的分析工具，有助于提高调查结果的可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fire patterns, consisting of fire effects that offer insights into firebehavior and origin, are traditionally classified based on investigators'visual observations, leading to subjective interpretations. This study proposesa framework for quantitative fire pattern classification to support fireinvestigators, aiming for consistency and accuracy. The framework integratesfour components. First, it leverages human-computer interaction to extract firepatterns from surfaces, combining investigator expertise with computationalanalysis. Second, it employs an aspect ratio-based random forest model toclassify fire pattern shapes. Third, fire scene point cloud segmentationenables precise identification of fire-affected areas and the mapping of 2Dfire patterns to 3D scenes. Lastly, spatial relationships between fire patternsand indoor elements support an interpretation of the fire scene. Thesecomponents provide a method for fire pattern analysis that synthesizesqualitative and quantitative data. The framework's classification resultsachieve 93% precision on synthetic data and 83% on real fire patterns.</description>
      <author>example@mail.com (Pengkun Liu, Shuna Ni, Stanislav I. Stoliarov, Pingbo Tang)</author>
      <guid isPermaLink="false">2410.23105v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>EMMA: End-to-End Multimodal Model for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2410.23262v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Blog post: https://waymo.com/blog/2024/10/introducing-emma/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出EMMA，一个用于自动驾驶的端到端多模态模型。&lt;h4&gt;目的&lt;/h4&gt;将原始相机传感器数据直接映射到多种驾驶特定输出。&lt;h4&gt;方法&lt;/h4&gt;基于多模态大语言模型，使用自然语言文本表示所有非传感器输入和输出。&lt;h4&gt;主要发现&lt;/h4&gt;EMMA在nuScenes的运动规划上表现出色，并在Waymo Open Motion Dataset和Waymo Open Dataset上取得竞争性结果。&lt;h4&gt;结论&lt;/h4&gt;联合训练EMMA的规划轨迹、物体检测和道路图任务在所有三个领域均有所提升，表明其作为通用模型的潜力。&lt;h4&gt;局限性&lt;/h4&gt;处理的图像帧数量有限，不支持准确的3D传感器（如LiDAR或雷达），且计算成本高。&lt;h4&gt;总结&lt;/h4&gt;希望我们的研究结果能激励进一步研究，以缓解这些问题并推动自动驾驶模型架构的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.Built on a multi-modal large language model foundation, EMMA directly maps rawcamera sensor data into various driving-specific outputs, including plannertrajectories, perception objects, and road graph elements. EMMA maximizes theutility of world knowledge from the pre-trained large language models, byrepresenting all non-sensor inputs (e.g. navigation instructions and egovehicle status) and outputs (e.g. trajectories and 3D locations) as naturallanguage text. This approach allows EMMA to jointly process various drivingtasks in a unified language space, and generate the outputs for each task usingtask-specific prompts. Empirically, we demonstrate EMMA's effectiveness byachieving state-of-the-art performance in motion planning on nuScenes as wellas competitive results on the Waymo Open Motion Dataset (WOMD). EMMA alsoyields competitive results for camera-primary 3D object detection on the WaymoOpen Dataset (WOD). We show that co-training EMMA with planner trajectories,object detection, and road graph tasks yields improvements across all threedomains, highlighting EMMA's potential as a generalist model for autonomousdriving applications. However, EMMA also exhibits certain limitations: it canprocess only a small amount of image frames, does not incorporate accurate 3Dsensing modalities like LiDAR or radar and is computationally expensive. Wehope that our results will inspire further research to mitigate these issuesand to further evolve the state of the art in autonomous driving modelarchitectures.</description>
      <author>example@mail.com (Jyh-Jing Hwang, Runsheng Xu, Hubert Lin, Wei-Chih Hung, Jingwei Ji, Kristy Choi, Di Huang, Tong He, Paul Covington, Benjamin Sapp, James Guo, Dragomir Anguelov, Mingxing Tan)</author>
      <guid isPermaLink="false">2410.23262v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Threshold-based Two-layer Online Unsupervised Anomaly Detector</title>
      <link>http://arxiv.org/abs/2410.22967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物联网（IoT）的普及增加了网络威胁的脆弱性，迫切需要开发能够适应新型攻击的异常检测系统（ADSs）。&lt;h4&gt;目的&lt;/h4&gt;提出一种综合框架，增强和解释安全领域中的在线无监督异常检测。&lt;h4&gt;方法&lt;/h4&gt;引入可解释的双层异常检测方法，生成可靠的高置信度伪标签，并结合在线学习机制，通过创新的阈值调整方法更新Adaptive NAD以应对新威胁。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Adaptive NAD在CIC-Darknet2020和CIC-DoHBrw-2020数据集上分别提高了超过5.4%和23.0%的SPAUC，超越了现有的最先进解决方案。&lt;h4&gt;结论&lt;/h4&gt;Adaptive NAD提供了一种有效的异常检测解决方案，具备更好的适应性和可解释性，适合实际应用。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了Adaptive NAD在应对网络安全威胁中的潜力，并且其代码公开可用，促进了研究界的进一步探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mylearncodespace/adaptive-nad&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The proliferation of the Internet of Things (IoT) has heightened thevulnerability to cyber threats, making it imperative to develop AnomalyDetection Systems (ADSs) capable of adapting to emerging or novel attacks.Prior research has predominantly concentrated on offline unsupervised learningtechniques to protect ADSs, which are impractical for real-world applications.Furthermore, these studies often rely heavily on the assumption of knownlegitimate behaviors and fall short of meeting the interpretabilityrequirements in security contexts, thereby hindering their practical adoption.In response, this paper introduces Adaptive NAD, a comprehensive frameworkaimed at enhancing and interpreting online unsupervised anomaly detectionwithin security domains. We propose an interpretable two-layer anomalydetection approach that generates dependable, high-confidence pseudo-labels.Subsequently, we incorporate an online learning mechanism that updates AdaptiveNAD using an innovative threshold adjustment method to accommodate new threats.Experimental findings reveal that Adaptive NAD surpasses state-of-the-artsolutions by achieving improvements of over 5.4% and 23.0% in SPAUC on theCIC-Darknet2020 and CIC-DoHBrw-2020 datasets, respectively. The code forAdaptive NAD is publicly available athttps://github.com/MyLearnCodeSpace/Adaptive-NAD.</description>
      <author>example@mail.com (Yachao Yuan, Yu Huang, Yali Yuan, Jin Wang)</author>
      <guid isPermaLink="false">2410.22967v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Hyperparameter Optimization in Machine Learning</title>
      <link>http://arxiv.org/abs/2410.22854v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;超参数是控制机器学习算法行为的配置变量，广泛应用于机器学习和人工智能中。&lt;h4&gt;目的&lt;/h4&gt;探讨超参数优化的统一处理方法，提供最新的例子和见解。&lt;h4&gt;方法&lt;/h4&gt;涵盖随机搜索、准随机搜索、基于带子的、模型的和梯度的超参数搜索技术。&lt;h4&gt;主要发现&lt;/h4&gt;自动化超参数搜索可以减轻研究人员和从业者通过试错法寻找合适超参数的负担。&lt;h4&gt;结论&lt;/h4&gt;讨论了在线、约束和多目标形式的扩展，及其与元学习和神经架构搜索等其他领域的联系。&lt;h4&gt;未来研究&lt;/h4&gt;提出了未解决的问题和未来的研究方向。&lt;h4&gt;总结&lt;/h4&gt;自动化超参数优化是实现机器学习自动化的重要步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hyperparameters are configuration variables controlling the behavior ofmachine learning algorithms. They are ubiquitous in machine learning andartificial intelligence and the choice of their values determine theeffectiveness of systems based on these technologies. Manual hyperparametersearch is often unsatisfactory and becomes unfeasible when the number ofhyperparameters is large. Automating the search is an important step towardsautomating machine learning, freeing researchers and practitioners alike fromthe burden of finding a good set of hyperparameters by trial and error. In thissurvey, we present a unified treatment of hyperparameter optimization,providing the reader with examples and insights into the state-of-the-art. Wecover the main families of techniques to automate hyperparameter search, oftenreferred to as hyperparameter optimization or tuning, including random andquasi-random search, bandit-, model- and gradient- based approaches. We furtherdiscuss extensions, including online, constrained, and multi-objectiveformulations, touch upon connections with other fields such as meta-learningand neural architecture search, and conclude with open questions and futureresearch directions.</description>
      <author>example@mail.com (Luca Franceschi, Michele Donini, Valerio Perrone, Aaron Klein, Cédric Archambeau, Matthias Seeger, Massimiliano Pontil, Paolo Frasconi)</author>
      <guid isPermaLink="false">2410.22854v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>ReferEverything: Towards Segmenting Everything We Can Speak of in Videos</title>
      <link>http://arxiv.org/abs/2410.23287v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page at
  https://miccooper9.github.io/projects/ReferEverything/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出REM框架，用于通过自然语言对视频中的各种概念进行分割。&lt;h4&gt;目的&lt;/h4&gt;实现对稀有和未见对象的准确分割与跟踪。&lt;h4&gt;方法&lt;/h4&gt;利用在互联网规模数据集上学习的视觉语言表示，通过微调在特定领域的对象分割数据集上进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;REM可以准确分割和跟踪稀有对象，并能够推广到非对象动态概念，如海浪。&lt;h4&gt;结论&lt;/h4&gt;在Ref-DAVIS等领域数据集上，REM的表现与先进方法相当，并在外域数据上的区域相似度方面超越它们。&lt;h4&gt;总结&lt;/h4&gt;REM利用互联网规模的预训练，展现了优越的分割能力，适用于广泛的概念和动态场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present REM, a framework for segmenting a wide range of concepts in videothat can be described through natural language. Our method capitalizes onvisual-language representations learned by video diffusion models onInternet-scale datasets. A key insight of our approach is preserving as much ofthe generative model's original representation as possible, while fine-tuningit on narrow-domain Referral Object Segmentation datasets. As a result, ourframework can accurately segment and track rare and unseen objects, despitebeing trained on object masks from a limited set of categories. Additionally,it can generalize to non-object dynamic concepts, such as waves crashing in theocean, as demonstrated in our newly introduced benchmark for Referral VideoProcess Segmentation (Ref-VPS). Our experiments show that REM performs on parwith state-of-the-art approaches on in-domain datasets, like Ref-DAVIS, whileoutperforming them by up to twelve points in terms of region similarity onout-of-domain data, leveraging the power of Internet-scale pre-training.</description>
      <author>example@mail.com (Anurag Bagchi, Zhipeng Bao, Yu-Xiong Wang, Pavel Tokmakov, Martial Hebert)</author>
      <guid isPermaLink="false">2410.23287v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>PointRecon: Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching</title>
      <link>http://arxiv.org/abs/2410.23245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新颖的在线点基3D重建方法，从姿态单目RGB视频中进行重建。&lt;h4&gt;目的&lt;/h4&gt;旨在持续更新场景的全局点云表示，随着新图像的观察更新点的特征和三维位置。&lt;h4&gt;方法&lt;/h4&gt;通过新颖的基于光线的2D-3D特征匹配技术，实现点云更新和新点的深度预测，该方法对之前点位置预测中的错误具有鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够扩展点云，添加新检测到的点，同时谨慎地去除冗余点，且处理无限长度的序列，提供实时更新。&lt;h4&gt;结论&lt;/h4&gt;与离线方法相比，该方法不受预定义分辨率或场景大小限制，其统一的全局表示确保了视角间的一致性。&lt;h4&gt;实验结果&lt;/h4&gt;在ScanNet数据集上的实验表明，该方法在在线多视图立体视觉（MVS）方法中达到了最先进的质量。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种有效的在线3D重建技术，具有实时更新和高质量重建的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel online, point-based 3D reconstruction method from posedmonocular RGB videos. Our model maintains a global point cloud representationof the scene, continuously updating the features and 3D locations of points asnew images are observed. It expands the point cloud with newly detected pointswhile carefully removing redundancies. The point cloud updates and depthpredictions for new points are achieved through a novel ray-based 2D-3D featurematching technique, which is robust against errors in previous point positionpredictions. In contrast to offline methods, our approach processesinfinite-length sequences and provides real-time updates. Additionally, thepoint cloud imposes no pre-defined resolution or scene size constraints, andits unified global representation ensures view consistency across perspectives.Experiments on the ScanNet dataset show that our method achievesstate-of-the-art quality among online MVS approaches. Project page:https://arthurhero.github.io/projects/pointrecon</description>
      <author>example@mail.com (Chen Ziwen, Zexiang Xu, Li Fuxin)</author>
      <guid isPermaLink="false">2410.23245v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Higher-order Cross-structural Embedding Model for Time Series Analysis</title>
      <link>http://arxiv.org/abs/2410.22984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列分析在医疗、金融和传感网络等多个领域受到广泛关注，因其重要应用。&lt;h4&gt;目的&lt;/h4&gt;解决当前方法在建模时间序列高阶交互方面的不足，提升下游任务性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架High-TS，结合多尺度Transformer和拓扑深度学习(TDL)同时建模时间和空间视角，并利用对比学习整合这两种结构。&lt;h4&gt;主要发现&lt;/h4&gt;High-TS在多种时间序列任务中超越了现有的最先进方法，强调了高阶交叉结构信息在提升模型性能中的重要性。&lt;h4&gt;结论&lt;/h4&gt;高阶交叉结构信息对时间序列分析的模型性能提升具有显著影响。&lt;h4&gt;总结&lt;/h4&gt;High-TS框架通过整合多种学习方法，提供了一种有效的解决方案，促进了时间序列分析的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series analysis has gained significant attention due to its criticalapplications in diverse fields such as healthcare, finance, and sensornetworks. The complexity and non-stationarity of time series make itchallenging to capture the interaction patterns across different timestamps.Current approaches struggle to model higher-order interactions within timeseries, and focus on learning temporal or spatial dependencies separately,which limits performance in downstream tasks. To address these gaps, we proposeHigher-order Cross-structural Embedding Model for Time Series (High-TS), anovel framework that jointly models both temporal and spatial perspectives bycombining multiscale Transformer with Topological Deep Learning (TDL).Meanwhile, High-TS utilizes contrastive learning to integrate these twostructures for generating robust and discriminative representations. Extensiveexperiments show that High-TS outperforms state-of-the-art methods in varioustime series tasks and demonstrate the importance of higher-ordercross-structural information in improving model performance.</description>
      <author>example@mail.com (Guancen Lin, Cong Shen, Aijing Lin)</author>
      <guid isPermaLink="false">2410.22984v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>UniRiT: Towards Few-Shot Non-Rigid Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2410.22909v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 14 figures, under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;非刚性点云配准是3D场景理解中的一个关键挑战，尤其在外科导航中尤为重要。现有方法在训练于大规模高质量数据集时表现优秀，但这些数据集收集和标注成本高昂，特别是在真实医疗场景中。&lt;h4&gt;目的&lt;/h4&gt;解决少量样本的非刚性点云配准问题。&lt;h4&gt;方法&lt;/h4&gt;提出UniRiT框架，通过将复杂的非刚性变换模式分解为刚性和小的非刚性变换，采用两步配准策略，首先对齐源点云和目标点云的质心，然后通过非刚性变换进行精细化配准，以降低问题复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;引入新的数据集MedMatch3D，包含真实人类器官并展现高样本分布变异性。UniRiT在MedMatch3D上表现出色，相较于现有最佳方法提升了94.22%。&lt;h4&gt;结论&lt;/h4&gt;UniRiT在少样本非刚性点云配准任务中具有先进的表现，展示了该框架的有效性和潜力。&lt;h4&gt;总结&lt;/h4&gt;通过创新的方法和新数据集，UniRiT显著改善了非刚性点云配准的性能，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Non-rigid point cloud registration is a critical challenge in 3D sceneunderstanding, particularly in surgical navigation. Although existing methodsachieve excellent performance when trained on large-scale, high-qualitydatasets, these datasets are prohibitively expensive to collect and annotate,e.g., organ data in authentic medical scenarios. With insufficient trainingsamples and data noise, existing methods degrade significantly since non-rigidpatterns are more flexible and complicated than rigid ones, and thedistributions across samples are more distinct, leading to higher difficulty inrepresentation learning with few data. In this work, we aim to deal with thischallenging few-shot non-rigid point cloud registration problem. Based on theobservation that complex non-rigid transformation patterns can be decomposedinto rigid and small non-rigid transformations, we propose a novel andeffective framework, UniRiT. UniRiT adopts a two-step registration strategythat first aligns the centroids of the source and target point clouds and thenrefines the registration with non-rigid transformations, thereby significantlyreducing the problem complexity. To validate the performance of UniRiT onreal-world datasets, we introduce a new dataset, MedMatch3D, which consists ofreal human organs and exhibits high variability in sample distribution. Wefurther establish a new challenging benchmark for few-shot non-rigidregistration. Extensive empirical results demonstrate that UniRiT achievesstate-of-the-art performance on MedMatch3D, improving the existing bestapproach by 94.22%.</description>
      <author>example@mail.com (Geng Li, Haozhi Cao, Mingyang Liu, Chenxi Jiang, Jianfei Yang)</author>
      <guid isPermaLink="false">2410.22909v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models</title>
      <link>http://arxiv.org/abs/2410.23266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有基准测试强调了多模态基础模型（MFM）在利用时间上下文进行视频理解方面的杰出表现，但模型在视觉时间推理方面的真实表现如何尚不清楚。&lt;h4&gt;目的&lt;/h4&gt;系统性检查当前视觉时间推理任务，提出评估MFMs时间推理能力的新标准。&lt;h4&gt;方法&lt;/h4&gt;提出三个原则及相应指标：多帧增益、帧顺序敏感性和帧信息差异，并引入新的基准TOMATO，包含1484个经过人工标注的问题，涵盖六个任务，应用于1417个视频。&lt;h4&gt;主要发现&lt;/h4&gt;评估显示最佳模型与人类之间存在57.3%的性能差距，分析揭示MFMs在连续序列解释方面存在根本性局限。&lt;h4&gt;结论&lt;/h4&gt;虽然MFMs能够准确识别孤立帧中的事件，但无法将这些帧作为连续序列进行解释，TOMATO将成为评估下一代MFMs的关键测试平台，并呼吁社区开发能够理解视频中人类世界动态的AI系统。&lt;h4&gt;总结&lt;/h4&gt;当前MFMs在视觉时间推理方面的能力被高估了，需要进一步研究和改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/yale-nlp/TOMATO&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing benchmarks often highlight the remarkable performance achieved bystate-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporalcontext for video understanding. However, how well do the models truly performvisual temporal reasoning? Our study of existing benchmarks shows that thiscapability of MFMs is likely overestimated as many questions can be solved byusing a single, few, or out-of-order frames. To systematically examine currentvisual temporal reasoning tasks, we propose three principles with correspondingmetrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) FrameInformation Disparity. Following these principles, we introduce TOMATO,Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted torigorously assess MFMs' temporal reasoning capabilities in video understanding.TOMATO comprises 1,484 carefully curated, human-annotated questions spanningsix tasks (i.e., action count, direction, rotation, shape &amp; trend, velocity &amp;frequency, and visual cues), applied to 1,417 videos, including 805self-recorded and -generated videos, that encompass human-centric, real-world,and simulated scenarios. Our comprehensive evaluation reveals a human-modelperformance gap of 57.3% with the best-performing model. Moreover, our in-depthanalysis uncovers more fundamental limitations beyond this gap in current MFMs.While they can accurately recognize events in isolated frames, they fail tointerpret these frames as a continuous sequence. We believe TOMATO will serveas a crucial testbed for evaluating the next-generation MFMs and as a call tothe community to develop AI systems capable of comprehending human worlddynamics through the video modality.</description>
      <author>example@mail.com (Ziyao Shangguan, Chuhan Li, Yuxuan Ding, Yanan Zheng, Yilun Zhao, Tesca Fitzgerald, Arman Cohan)</author>
      <guid isPermaLink="false">2410.23266v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
    </item>
    <item>
      <title>Evaluating the Robustness of LiDAR Point Cloud Tracking Against Adversarial Attack</title>
      <link>http://arxiv.org/abs/2410.20893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究探讨基于神经网络的LiDAR点云跟踪模型在对抗攻击下的鲁棒性，这是一个常被忽视但至关重要的方面。&lt;h4&gt;目的&lt;/h4&gt;关注跟踪模型在对抗攻击威胁下的鲁棒性，填补性能增强与鲁棒性之间的空白。&lt;h4&gt;方法&lt;/h4&gt;建立统一框架进行3D物体跟踪中的对抗攻击，详细研究白盒和黑盒攻击策略；针对白盒攻击，定制特定损失函数并扩展现有方法如FGSM、C&amp;W和PGD；针对黑盒攻击，引入新颖的目标感知扰动生成(TAPG)算法。&lt;h4&gt;主要发现&lt;/h4&gt;高级跟踪方法在白盒和黑盒攻击下表现出显著脆弱性，强调在LiDAR点云跟踪模型设计中融入对抗攻击鲁棒性的必要性。&lt;h4&gt;结论&lt;/h4&gt;TAPG方法在攻击效果和扰动隐蔽性之间达成最佳平衡，相较于现有方法表现更佳。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了对抗攻击对LiDAR点云跟踪模型的影响，并提出了增强鲁棒性的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we delve into the robustness of neural network-based LiDARpoint cloud tracking models under adversarial attacks, a critical aspect oftenoverlooked in favor of performance enhancement. These models, despiteincorporating advanced architectures like Transformer or Bird's Eye View (BEV),tend to neglect robustness in the face of challenges such as adversarialattacks, domain shifts, or data corruption. We instead focus on the robustnessof the tracking models under the threat of adversarial attacks. We begin byestablishing a unified framework for conducting adversarial attacks within thecontext of 3D object tracking, which allows us to thoroughly investigate bothwhite-box and black-box attack strategies. For white-box attacks, we tailorspecific loss functions to accommodate various tracking paradigms and extendexisting methods such as FGSM, C\&amp;W, and PGD to the point cloud domain. Inaddressing black-box attack scenarios, we introduce a novel transfer-basedapproach, the Target-aware Perturbation Generation (TAPG) algorithm, with thedual objectives of achieving high attack performance and maintaining lowperceptibility. This method employs a heuristic strategy to enforce sparseattack constraints and utilizes random sub-vector factorization to bolstertransferability. Our experimental findings reveal a significant vulnerabilityin advanced tracking methods when subjected to both black-box and white-boxattacks, underscoring the necessity for incorporating robustness againstadversarial attacks into the design of LiDAR point cloud tracking models.Notably, compared to existing methods, the TAPG also strikes an optimal balancebetween the effectiveness of the attack and the concealment of theperturbations.</description>
      <author>example@mail.com (Shengjing Tian, Yinan Han, Xiantong Zhao, Bin Liu, Xiuping Liu)</author>
      <guid isPermaLink="false">2410.20893v1</guid>
      <pubDate>Sat, 02 Nov 2024 08:43:59 +0800</pubDate>
=======
    <lastBuildDate>Fri, 25 Oct 2024 18:27:50 +0800</lastBuildDate>
    <item>
      <title>Towards Efficient Collaboration via Graph Modeling in Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2410.15841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在多智能体强化学习中，常见的范式是集中训练与分散执行。然而，分散执行由于局部观察的限制，限制了协调策略的发展。&lt;h4&gt;目的&lt;/h4&gt;考虑邻近智能体在执行过程中的合作，并将它们的交互形式化为图结构。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖的编码-解码架构，称为基于因子的多智能体变换器（$f$-MAT），利用变换器实现邻近智能体在训练与执行过程中的通信。&lt;h4&gt;主要发现&lt;/h4&gt;$f$-MAT通过将智能体划分为不同的重叠组并用因子表示，每个组之间实现高效的信息传递，表现出优于强基线的性能。&lt;h4&gt;结论&lt;/h4&gt;在网络化系统（如交通调度和功率控制）上的实证结果表明，$f$-MAT为处理复杂的协作问题铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;本研究为多智能体强化学习中的协作策略提供了一种有效的新方法，展示了其在实际应用中的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In multi-agent reinforcement learning, a commonly considered paradigm iscentralized training with decentralized execution. However, in this framework,decentralized execution restricts the development of coordinated policies dueto the local observation limitation. In this paper, we consider the cooperationamong neighboring agents during execution and formulate their interactions as agraph. Thus, we introduce a novel encoder-decoder architecture namedFactor-based Multi-Agent Transformer ($f$-MAT) that utilizes a transformer toenable the communication between neighboring agents during both training andexecution. By dividing agents into different overlapping groups andrepresenting each group with a factor, $f$-MAT fulfills efficient messagepassing among agents through factor-based attention layers. Empirical resultson networked systems such as traffic scheduling and power control demonstratethat $f$-MAT achieves superior performance compared to strong baselines,thereby paving the way for handling complex collaborative problems.</description>
      <author>example@mail.com (Wenzhe Fan, Zishun Yu, Chengdong Ma, Changye Li, Yaodong Yang, Xinhua Zhang)</author>
      <guid isPermaLink="false">2410.15841v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>QIXAI: A Quantum-Inspired Framework for Enhancing Classical and Quantum Model Transparency and Understanding</title>
      <link>http://arxiv.org/abs/2410.16537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习模型，特别是卷积神经网络（CNN），在可解释性方面存在不足，使其成为“黑箱”，在医疗、金融和自主系统等关键领域引发信任和责任问题。&lt;h4&gt;目的&lt;/h4&gt;提出QIXAI框架（量子启发式可解释人工智能），旨在通过量子启发技术增强神经网络的可解释性。&lt;h4&gt;方法&lt;/h4&gt;利用量子力学原理（如希尔伯特空间、叠加、纠缠和特征值分解）揭示神经网络不同层如何处理和组合特征以做出决策。&lt;h4&gt;主要发现&lt;/h4&gt;评估了模型无关的方法（如SHAP和LIME）及层级相关传播（LRP）技术，指出它们在提供神经网络操作的全面视图方面的局限性；QIXAI框架通过提供更深的特征重要性、层间依赖性和信息传播的见解，克服了这些局限。&lt;h4&gt;结论&lt;/h4&gt;通过使用针对疟疾寄生虫检测的CNN案例，展示了量子启发方法（如奇异值分解、主成分分析和互信息）如何提供模型行为的可解释性，并探讨了QIXAI在其他架构（如RNN、LSTM、Transformer、NLP模型）及生成模型和时间序列分析中的扩展应用。&lt;h4&gt;总结&lt;/h4&gt;QIXAI框架适用于量子和经典系统，展现了提高各种模型可解释性和透明性的潜力，推动开发值得信赖的人工智能系统的更广泛目标。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The impressive performance of deep learning models, particularlyConvolutional Neural Networks (CNNs), is often hindered by their lack ofinterpretability, rendering them "black boxes." This opacity raises concerns incritical areas like healthcare, finance, and autonomous systems, where trustand accountability are crucial. This paper introduces the QIXAI Framework(Quantum-Inspired Explainable AI), a novel approach for enhancing neuralnetwork interpretability through quantum-inspired techniques. By utilizingprinciples from quantum mechanics, such as Hilbert spaces, superposition,entanglement, and eigenvalue decomposition, the QIXAI framework reveals howdifferent layers of neural networks process and combine features to makedecisions.  We critically assess model-agnostic methods like SHAP and LIME, as well astechniques like Layer-wise Relevance Propagation (LRP), highlighting theirlimitations in providing a comprehensive view of neural network operations. TheQIXAI framework overcomes these limitations by offering deeper insights intofeature importance, inter-layer dependencies, and information propagation. ACNN for malaria parasite detection is used as a case study to demonstrate howquantum-inspired methods like Singular Value Decomposition (SVD), PrincipalComponent Analysis (PCA), and Mutual Information (MI) provide interpretableexplanations of model behavior. Additionally, we explore the extension of QIXAIto other architectures, including Recurrent Neural Networks (RNNs), LongShort-Term Memory (LSTM) networks, Transformers, and Natural LanguageProcessing (NLP) models, and its application to generative models andtime-series analysis. The framework applies to both quantum and classicalsystems, demonstrating its potential to improve interpretability andtransparency across a range of models, advancing the broader goal of developingtrustworthy AI systems.</description>
      <author>example@mail.com (John M. Willis)</author>
      <guid isPermaLink="false">2410.16537v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Modelling Concurrent RTP Flows for End-to-end Predictions of QoS in Real Time Communications</title>
      <link>http://arxiv.org/abs/2410.15846v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于实时传输协议(RTP)的实时通信应用，如视频会议，近年来迅速发展和普及。&lt;h4&gt;目的&lt;/h4&gt;优化实时通信应用的性能，特别是预测服务质量(QoS)指标，以增强网络监控和主动解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的深度学习框架Packet-to-Prediction (P2P)，基于原始数据包同时处理多个RTP流，并进行多项QoS指标的端到端预测。&lt;h4&gt;主要发现&lt;/h4&gt;采用无长度限制的Transformer架构结合交叉和邻域注意力机制，能够处理无限数量的RTP流，并在一次性预测中实现四个关键指标。&lt;h4&gt;结论&lt;/h4&gt;P2P在预测性能和时间效率上优于现有比较模型，基于真实视频通话收集的广泛流量数据支持了这一结论。&lt;h4&gt;总结&lt;/h4&gt;P2P框架展示了在实时通信领域中通过高效的深度学习方法提升QoS预测能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Real-time Transport Protocol (RTP)-based real-time communications (RTC)applications, exemplified by video conferencing, have experienced anunparalleled surge in popularity and development in recent years. In pursuit ofoptimizing their performance, the prediction of Quality of Service (QoS)metrics emerges as a pivotal endeavor, bolstering network monitoring andproactive solutions. However, contemporary approaches are confined toindividual RTP flows and metrics, falling short in relationship capture andcomputational efficiency. To this end, we propose Packet-to-Prediction (P2P), anovel deep learning (DL) framework that hinges on raw packets to simultaneouslyprocess concurrent RTP flows and perform end-to-end prediction of multiple QoSmetrics. Specifically, we implement a streamlined architecture, namelylength-free Transformer with cross and neighbourhood attention, capable ofhandling an unlimited number of RTP flows, and employ a multi-task learningparadigm to forecast four key metrics in a single shot. Our work is based onextensive traffic collected during real video calls, and conclusively, P2Pexcels comparative models in both prediction performance and temporalefficiency.</description>
      <author>example@mail.com (Tailai Song, Paolo Garza, Michela Meo, Maurizio Matteo Munafò)</author>
      <guid isPermaLink="false">2410.15846v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Generative AI for Overall Mission Effectiveness at the Habitable Worlds Observatory</title>
      <link>http://arxiv.org/abs/2410.16609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 4 figures, in preparation for submission to RASTI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文讨论了生成性人工智能（Gen AI）在天文学未来的系统工程和认知知识管理中的应用，基于NASA适居世界天文台（HWO）科学技术架构评审小组（START）AI/ML工作组的会议和演示成果。&lt;h4&gt;目的&lt;/h4&gt;探索人类在日益强大和自主的Gen AI系统中的角色，强调道德应用，旨在减轻人类工作中的繁重任务，同时增加人类的创造力和创新机会。&lt;h4&gt;方法&lt;/h4&gt;通过对不同数据类型（文本、时间序列/光谱和图像数据）应用生成模型，涵盖科学和工程的广泛应用，包括任务开发加速、数据分析与解释、成像能力增强等。&lt;h4&gt;主要发现&lt;/h4&gt;通过对模拟外行星群科学数据集的敏感性分析，可以逆向工程HWO仪器的测量不确定性要求，从而生成能够限制群体模型的数据，进而指导HWO设计要求。&lt;h4&gt;结论&lt;/h4&gt;提出的HWO设计策略确保其在未来保持AI准备状态，通过结合前瞻性理念与已验证的应用案例，支持HWO的长期AI发展战略。&lt;h4&gt;总结&lt;/h4&gt;生成性人工智能在HWO的应用将推动科学和工程的发展，提高任务效率与创新能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Here we present several use cases for using Generative AI (Gen AI) to improvesystems engineering and cognitive knowledge management related to the future ofastronomy from a culmination of working meetings and presentations as part ofthe Gen AI Task Group for the NASA Habitable Worlds Observatory (HWO) Scienceand Technology Architecture Review Team (START) AI/ML Working Group.Collectively, our group mission statement is "Where is the Human-in-the-loop asGen AI systems become more powerful and autonomous?" with an emphasis on theethical applications of Gen AI, guided by using these systems to removedrudgery from human work while simultaneously increasing opportunities forhumans to experience more collective creativity and innovation. The HWO missionstands to benefit dramatically from generative models for different data typesincluding text, time series/spectra, and image data. These cover a wide rangeof applications in science and engineering for HWO, including: missiondevelopment acceleration, data analysis and interpretation, enhancing imagingcapabilities, anomaly detection, predictive modeling and simulation, dataaugmentation for machine learning, instrument calibration and optimization,public engagement and education, and assisting in mission planning. As anexample, through sensitivity analysis of simulated exoplanet population sciencedata sets of various generative model complexity, we can reverse engineer themeasurement uncertainty requirements for HWO instruments to produce data thatcan constrain population models and thus inform HWO design requirements. Thisapproach to HWO design is one example of a strategy that can ensure that HWOremains AI-ready. Through presenting herein a combination of visionary ideasbalanced with grounded validated use case examples, we aim to support thedevelopment of a long-term strategy to keep HWO AI-ready as it moves forward.</description>
      <author>example@mail.com (Megan Shabram, Ryan McClelland, John Wu, Hamsa Shwetha Venkataram, Heidi Segars, Bruce Dean, Christine Ye, Aquib Moin, Megan Ansdell, Mark Moussa, Umaa Rebbapragada, Hamed Valizadegan, Dominick Perini, Glenn Ko, Victoria Da Poian, Sam Gharib-Nezhad, Giuseppe Cataldo)</author>
      <guid isPermaLink="false">2410.16609v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense Traffic with Micro-Interactive Vehicles</title>
      <link>http://arxiv.org/abs/2410.15912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 7 figures, IEEE international conference on robotics and
  automation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动驾驶技术迅速发展，但在密集交通中并线仍然是重大挑战，现有的运动规划方法难以评估。&lt;h4&gt;目的&lt;/h4&gt;提出一个闭环评估基准，以评估在并线场景中的运动规划能力。&lt;h4&gt;方法&lt;/h4&gt;使用经过大型数据集训练的其他车辆，增加复杂性和多样性，并重构评估机制，利用大语言模型评估每辆自动驾驶车辆的并线表现。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛实验证明了该评估基准的先进性，并评估了现有方法，识别出常见问题。&lt;h4&gt;结论&lt;/h4&gt;设计的环境和车辆运动规划模型可以在特定链接中访问，提供了对现有方法的评估。&lt;h4&gt;总结&lt;/h4&gt;该研究为评估自动驾驶在密集交通中并线能力提供了新的基准，推动了相关技术的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While the capabilities of autonomous driving have advanced rapidly, merginginto dense traffic remains a significant challenge, many motion planningmethods for this scenario have been proposed but it is hard to evaluate them.Most existing closed-loop simulators rely on rule-based controls for othervehicles, which results in a lack of diversity and randomness, thus failing toaccurately assess the motion planning capabilities in highly interactivescenarios. Moreover, traditional evaluation metrics are insufficient forcomprehensively evaluating the performance of merging in dense traffic. Inresponse, we proposed a closed-loop evaluation benchmark for assessing motionplanning capabilities in merging scenarios. Our approach involves othervehicles trained in large scale datasets with micro-behavioral characteristicsthat significantly enhance the complexity and diversity. Additionally, we haverestructured the evaluation mechanism by leveraging large language models toassess each autonomous vehicle merging onto the main road. Extensiveexperiments have demonstrated the advanced nature of this evaluation benchmark.Through this benchmark, we have obtained an evaluation of existing methods andidentified common issues. The environment and vehicle motion planning models wehave designed can be accessed athttps://anonymous.4open.science/r/Bench4Merge-EB5D</description>
      <author>example@mail.com (Zhengming Wang, Junli Wang, Pengfei Li, Zhaohan Li, Peng Li, Yilun Chen)</author>
      <guid isPermaLink="false">2410.15912v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Sensing-Communication-Computing-Control Closed-Loop Optimization for 6G Unmanned Robotic Systems</title>
      <link>http://arxiv.org/abs/2410.18382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无人机器人系统在第六代（6G）时代有望替代人类执行危险任务。&lt;h4&gt;目的&lt;/h4&gt;研究一个由多功能无人机、传感器和执行器组成的无人机器人系统。&lt;h4&gt;方法&lt;/h4&gt;将无人机作为边缘信息中心（EIH），设计集成的感知-通信-计算-控制（SC³）闭环，提出目标导向的闭环优化方案。&lt;h4&gt;主要发现&lt;/h4&gt;提出的方案联合优化上下行通信和计算，以最小化总线性二次调节器（LQR）成本。&lt;h4&gt;结论&lt;/h4&gt;在充足的CPU频率条件下，得到了闭环带宽分配的近似闭式解，仿真结果表明该方案能实现SC³闭环内外的双层任务平衡。&lt;h4&gt;总结&lt;/h4&gt;整体方案优化了无人机器人系统的性能，增强了其在执行复杂任务时的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rapid advancements in field robots have brought a new kind of cyber physicalsystem (CPS)--unmanned robotic system--under the spotlight. In the upcomingsixth-generation (6G) era, these systems hold great potential to replace humansin hazardous tasks. This paper investigates an unmanned robotic systemcomprising a multi-functional unmanned aerial vehicle (UAV), sensors, andactuators. The UAV carries communication and computing modules, acting as anedge information hub (EIH) that transfers and processes information. During thetask execution, the EIH gathers sensing data, calculates control commands, andtransmits commands to actuators--leading to reflex-arc-likesensing-communication-computing-control ($\mathbf{SC}^3$) loops. Unlikeexisting studies that design $\mathbf{SC}^3$ loop components separately, wetake each $\mathbf{SC}^3$ loop as an integrated structure and propose agoal-oriented closed-loop optimization scheme. This scheme jointly optimizesuplink and downlink (UL&amp;DL) communication and computing within and across the$\mathbf{SC}^3$ loops to minimize the total linear quadratic regulator (LQR)cost. We derive optimal closed-form solutions for intra-loop allocation andpropose an efficient iterative algorithm for inter-loop optimization. Under thecondition of adequate CPU frequency availability, we derive an approximateclosed-form solution for inter-loop bandwidth allocation. Simulation resultsdemonstrate that the proposed scheme achieves a two-tier task-level balancewithin and across $\mathbf{SC}^3$ loops.</description>
      <author>example@mail.com (Xinran Fang, Chengleyang Lei, Wei Feng, Yunfei Chen, Ming Xiao, Ning Ge, Chengxiang Wang)</author>
      <guid isPermaLink="false">2410.18382v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Governing equation discovery of a complex system from snapshots</title>
      <link>http://arxiv.org/abs/2410.16694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;复杂系统在物理、化学和生物学中普遍存在，其演化过程具有固有的随机性，通常用随机微分方程（SDEs）描述。&lt;h4&gt;目的&lt;/h4&gt;确定复杂系统的控制方程，基于快照数据进行研究。&lt;h4&gt;方法&lt;/h4&gt;提出一种数据驱动的无模拟框架，称为快照下的微分方程稀疏识别（SpIDES），利用先进的机器学习技术进行概率流重构、概率密度估计和贝叶斯稀疏识别。&lt;h4&gt;主要发现&lt;/h4&gt;成功识别了一个过阻尼兰金系统在两个势阱中的控制方程，并提取了解释性的漂移和扩散项。&lt;h4&gt;结论&lt;/h4&gt;SpIDES框架提供了对系统动态的深入洞察，增强了预测准确性，并促进了更有效的随机系统管理和模拟策略。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了如何通过新方法从快照数据中提取复杂系统的控制方程，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complex systems in physics, chemistry, and biology that evolve over time withinherent randomness are typically described by stochastic differentialequations (SDEs). A fundamental challenge in science and engineering is todetermine the governing equations of a complex system from snapshot data.Traditional equation discovery methods often rely on stringent assumptions,such as the availability of the trajectory information or time-series data, andthe presumption that the underlying system is deterministic. In this work, weintroduce a data-driven, simulation-free framework, called SparseIdentification of Differential Equations from Snapshots (SpIDES), thatdiscovers the governing equations of a complex system from snapshots byutilizing the advanced machine learning techniques to perform three essentialsteps: probability flow reconstruction, probability density estimation, andBayesian sparse identification. We validate the effectiveness and robustness ofSpIDES by successfully identifying the governing equation of an over-dampedLangevin system confined within two potential wells. By extractinginterpretable drift and diffusion terms from the SDEs, our framework providesdeeper insights into system dynamics, enhances predictive accuracy, andfacilitates more effective strategies for managing and simulating stochasticsystems.</description>
      <author>example@mail.com (Qunxi Zhu, Bolin Zhao, Jingdong Zhang, Peiyang Li, Wei Lin)</author>
      <guid isPermaLink="false">2410.16694v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Analyzing Closed-loop Training Techniques for Realistic Traffic Agent Models in Autonomous Highway Driving Simulations</title>
      <link>http://arxiv.org/abs/2410.15987v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 6 figures, 4 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;仿真在自主车辆的快速发展和安全部署中发挥着关键作用。现实的交通代理模型对于弥合仿真与现实世界之间的差距至关重要。&lt;h4&gt;目的&lt;/h4&gt;提供关于现实交通代理建模的广泛理解，特别关注高速公路驾驶仿真的闭环方法。&lt;h4&gt;方法&lt;/h4&gt;进行了对不同训练原则的广泛比较分析，实验比较了开放环与闭环多代理训练、对抗性与确定性监督训练、强化损失的影响，以及与日志重放代理共同训练的影响。&lt;h4&gt;主要发现&lt;/h4&gt;识别出适合现实代理建模的有效训练技术，以及不同闭环训练方法的有前景组合。&lt;h4&gt;结论&lt;/h4&gt;通过比较不同的训练策略，为交通代理模型的现实性提供了新的见解。&lt;h4&gt;总结&lt;/h4&gt;本文为理解和应用闭环训练方法在高速公路仿真中的有效性提供了重要的实验依据和理论支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulation plays a crucial role in the rapid development and safe deploymentof autonomous vehicles. Realistic traffic agent models are indispensable forbridging the gap between simulation and the real world. Many existingapproaches for imitating human behavior are based on learning fromdemonstration. However, these approaches are often constrained by focusing onindividual training strategies. Therefore, to foster a broader understanding ofrealistic traffic agent modeling, in this paper, we provide an extensivecomparative analysis of different training principles, with a focus onclosed-loop methods for highway driving simulation. We experimentally compare(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.deterministic supervised training, (iii) the impact of reinforcement losses,and (iv) the impact of training alongside log-replayed agents to identifysuitable training techniques for realistic agent modeling. Furthermore, weidentify promising combinations of different closed-loop training methods.</description>
      <author>example@mail.com (Matthias Bitzer, Reinis Cimurs, Benjamin Coors, Johannes Goth, Sebastian Ziesche, Philipp Geiger, Maximilian Naumann)</author>
      <guid isPermaLink="false">2410.15987v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Visual Localization in 3D Maps: Comparing Point Cloud, Mesh, and NeRF Representations</title>
      <link>http://arxiv.org/abs/2408.11966v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，映射技术的进步使得在机器人任务中创建高精度的密集3D地图成为可能，这些地图包括点云、网格或基于NeRF的表示。&lt;h4&gt;目的&lt;/h4&gt;提出一个统一的视觉定位系统，能够在不同的3D地图表示中准确定位单幅相机图像。&lt;h4&gt;方法&lt;/h4&gt;系统通过合成新视角生成数据库，创建RGB和深度图像对，自动定义渲染姿态，减少数据库图像数量，同时保持检索性能。&lt;h4&gt;主要发现&lt;/h4&gt;在各种环境中，所有三种地图表示的定位成功率均达到55%以上；NeRF合成图像的平均成功率为72%。&lt;h4&gt;结论&lt;/h4&gt;与传统的基于结构的运动(SfM)定位方法相比，本系统在未见过的逆向行驶方向上也能进行定位，展示了合成数据库的优势。&lt;h4&gt;系统性能&lt;/h4&gt;该系统在配备GPU的移动笔记本上实时运行，处理速率达到1Hz。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了一个高效的全球视觉定位系统，能够在多种3D地图表示中实现可靠的定位，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-08-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in mapping techniques have enabled the creation of highlyaccurate dense 3D maps during robotic missions, such as point clouds, meshes,or NeRF-based representations. These developments present new opportunities forreusing these maps for localization. However, there remains a lack of a unifiedapproach that can operate seamlessly across different map representations. Thispaper presents and evaluates a global visual localization system capable oflocalizing a single camera image across various 3D map representations builtusing both visual and lidar sensing. Our system generates a database bysynthesizing novel views of the scene, creating RGB and depth image pairs.Leveraging the precise 3D geometric map, our method automatically definesrendering poses, reducing the number of database images while preservingretrieval performance. To bridge the domain gap between real query cameraimages and synthetic database images, our approach utilizes learning-baseddescriptors and feature detectors. We evaluate the system's performance throughextensive real-world experiments conducted in both indoor and outdoor settings,assessing the effectiveness of each map representation and demonstrating itsadvantages over traditional structure-from-motion (SfM) localizationapproaches. The results show that all three map representations can achieveconsistent localization success rates of 55% and higher across variousenvironments. NeRF synthesized images show superior performance, localizingquery images at an average success rate of 72%. Furthermore, we demonstrate anadvantage over SfM-based approaches that our synthesized database enableslocalization in the reverse travel direction which is unseen during the mappingprocess. Our system, operating in real-time on a mobile laptop equipped with aGPU, achieves a processing rate of 1Hz.</description>
      <author>example@mail.com (Lintong Zhang, Yifu Tao, Jiarong Lin, Fu Zhang, Maurice Fallon)</author>
      <guid isPermaLink="false">2408.11966v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>SkiLD: Unsupervised Skill Discovery Guided by Factor Interactions</title>
      <link>http://arxiv.org/abs/2410.18416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无监督技能发现允许智能体通过自主、无奖励的环境交互学习可重用技能。&lt;h4&gt;目的&lt;/h4&gt;提出Skild方法，通过状态因子化引导技能学习过程，解决复杂环境中技能学习的挑战。&lt;h4&gt;方法&lt;/h4&gt;Skild开发了一种新颖的技能学习目标，明确鼓励在环境中有效诱导不同交互的技能掌握。&lt;h4&gt;主要发现&lt;/h4&gt;Skild在多个具有挑战性的长时程稀疏奖励任务中表现优越，成功学习出具有明确语义的技能。&lt;h4&gt;结论&lt;/h4&gt;与现有的仅最大化状态覆盖的无监督强化学习方法相比，Skild展示了更好的性能。&lt;h4&gt;总结&lt;/h4&gt;Skild通过促进状态因子之间的多样化交互，提升了技能学习的有效性，更适合解决下游任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised skill discovery carries the promise that an intelligent agentcan learn reusable skills through autonomous, reward-free environmentinteraction. Existing unsupervised skill discovery methods learn skills byencouraging distinguishable behaviors that cover diverse states. However, incomplex environments with many state factors (e.g., household environments withmany objects), learning skills that cover all possible states is impossible,and naively encouraging state diversity often leads to simple skills that arenot ideal for solving downstream tasks. This work introduces Skill Discoveryfrom Local Dependencies (Skild), which leverages state factorization as anatural inductive bias to guide the skill learning process. The key intuitionguiding Skild is that skills that induce &lt;b&gt;diverse interactions&lt;/b&gt; betweenstate factors are often more valuable for solving downstream tasks. To thisend, Skild develops a novel skill learning objective that explicitly encouragesthe mastering of skills that effectively induce different interactions withinan environment. We evaluate Skild in several domains with challenging,long-horizon sparse reward tasks including a realistic simulated householdrobot domain, where Skild successfully learns skills with clear semanticmeaning and shows superior performance compared to existing unsupervisedreinforcement learning methods that only maximize state coverage.</description>
      <author>example@mail.com (Zizhao Wang, Jiaheng Hu, Caleb Chuck, Stephen Chen, Roberto Martín-Martín, Amy Zhang, Scott Niekum, Peter Stone)</author>
      <guid isPermaLink="false">2410.18416v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Estimating Body and Hand Motion in an Ego-sensed World</title>
      <link>http://arxiv.org/abs/2410.03665v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  v2: fixed figures for Safari, typos&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了EgoAllo系统，用于从头戴设备中估计人类运动。&lt;h4&gt;目的&lt;/h4&gt;通过使用自我中心的SLAM姿势和图像，估计3D身体姿态、高度和手部参数，以捕捉佩戴者在场景中的动作。&lt;h4&gt;方法&lt;/h4&gt;提出空间和时间不变性标准以改善模型性能，导出头部运动条件参数化，从而提高估计准确性。&lt;h4&gt;主要发现&lt;/h4&gt;使用EgoAllo系统估计的身体姿态可以显著改善手部估计，导致手部估计误差降低超过40%。&lt;h4&gt;结论&lt;/h4&gt;通过关键的表示方法，估计精度提高了18%，并且系统在处理手部运动时表现更佳。&lt;h4&gt;总结&lt;/h4&gt;EgoAllo系统展示了如何利用头戴设备实现更准确的运动估计，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present EgoAllo, a system for human motion estimation from a head-mounteddevice. Using only egocentric SLAM poses and images, EgoAllo guides samplingfrom a conditional diffusion model to estimate 3D body pose, height, and handparameters that capture the wearer's actions in the allocentric coordinateframe of the scene. To achieve this, our key insight is in representation: wepropose spatial and temporal invariance criteria for improving modelperformance, from which we derive a head motion conditioning parameterizationthat improves estimation by up to 18%. We also show how the bodies estimated byour system can improve the hands: the resulting kinematic and temporalconstraints result in over 40% lower hand estimation errors compared to noisymonocular estimates. Project page: https://egoallo.github.io/</description>
      <author>example@mail.com (Brent Yi, Vickie Ye, Maya Zheng, Lea Müller, Georgios Pavlakos, Yi Ma, Jitendra Malik, Angjoo Kanazawa)</author>
      <guid isPermaLink="false">2410.03665v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Massimo: Public Queue Monitoring and Management using Mass-Spring Model</title>
      <link>http://arxiv.org/abs/2410.16012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures, 3 algorithms, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;公共场所的队列控制和管理系统非常重要，以避免交通拥堵并提高客户满意度。&lt;h4&gt;目的&lt;/h4&gt;提供一个基于智能系统合并的高效队列管理系统的详细方案。&lt;h4&gt;方法&lt;/h4&gt;利用计算机视觉、机器学习算法和深度学习等不同技术。&lt;h4&gt;主要发现&lt;/h4&gt;系统能够准确提供公共场所是否拥挤的信息及需采取的必要措施。&lt;h4&gt;结论&lt;/h4&gt;通过智能技术的应用，可以有效改善公共空间的排队管理。&lt;h4&gt;总结&lt;/h4&gt;该研究为公共场所的队列管理提供了创新的解决方案，促进了客户体验的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An efficient system of a queue control and regulation in public spaces isvery important in order to avoid the traffic jams and to improve the customersatisfaction. This article offers a detailed road map based on a merger ofintelligent systems and creating an efficient systems of queues in publicplaces. Through the utilization of different technologies i.e. computer vision,machine learning algorithms, deep learning our system provide accurateinformation about the place is crowded or not and the necessary efforts to betaken.</description>
      <author>example@mail.com (Abhijeet Kumar, Unnati Singh, Rajdeep Chatterjee, Tathagata Bandyopadhyay)</author>
      <guid isPermaLink="false">2410.16012v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Learn 2 Rage: Experiencing The Emotional Roller Coaster That Is Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2410.18462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "本研究介绍了我们团队在2022年AIcrowd举办的Learn To Race自主赛车虚拟挑战中的实验和解决方案。",
    "目的": "该竞赛旨在推动自主技术的边界，特别关注自主驾驶的安全性。",
    "方法": "我们集中精力实现了Soft Actor Critic (SAC)的变体，通过视觉和几何特征直接映射像素到控制动作。",
    "主要发现": "通过适当修改奖励策略，促进平稳的转向和加速控制，我们的系统在比赛中表现优异，超越了其他所有代理。",
    "结论": "尽管采用更传统的视觉处理方法不如像素到动作的方法在学术上"吸引"，但其训练需求更低、可解释性更强、泛化能力更好，且易于调优。",
    "总结": "我们的系统在实时仿真中表现出色，验证了基于规则的控制器的有效性。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents the experiments and solution outline for our teams winningsubmission in the Learn To Race Autonomous Racing Virtual Challenge 2022 hostedby AIcrowd. The objective of the Learn-to-Race competition is to push theboundary of autonomous technology, with a focus on achieving the safetybenefits of autonomous driving. In the description the competition is framed asa reinforcement learning (RL) challenge. We focused our initial efforts onimplementation of Soft Actor Critic (SAC) variants. Our goal was to learnnon-trivial control of the race car exclusively from visual and geometricfeatures, directly mapping pixels to control actions. We made suitablemodifications to the default reward policy aiming to promote smooth steeringand acceleration control. The framework for the competition provided real timesimulation, meaning a single episode (learning experience) is measured inminutes. Instead of pursuing parallelisation of episodes we opted to explore amore traditional approach in which the visual perception was processed (vialearned operators) and fed into rule-based controllers. Such a system, whilenot as academically "attractive" as a pixels-to-actions approach, results in asystem that requires less training, is more explainable, generalises better andis easily tuned and ultimately out-performed all other agents in thecompetition by a large margin.</description>
      <author>example@mail.com (Lachlan Mares, Stefan Podgorski, Ian Reid)</author>
      <guid isPermaLink="false">2410.18462v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>xLSTM-Mixer: Multivariate Time Series Forecasting by Mixing via Scalar Memories</title>
      <link>http://arxiv.org/abs/2410.16928v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列数据在多个领域广泛存在，需要开发强大且准确的预测模型。&lt;h4&gt;目的&lt;/h4&gt;有效整合时间序列、联合时间-变量信息及多个视角，以实现稳健的预测。&lt;h4&gt;方法&lt;/h4&gt;提出xLSTM-Mixer模型，采用线性预测与xLSTM模块相结合，建模复杂的时间序列动态。&lt;h4&gt;主要发现&lt;/h4&gt;xLSTM-Mixer在长期预测性能上优于最近的先进方法。&lt;h4&gt;结论&lt;/h4&gt;该模型增强了循环模型在时间序列预测中的应用，提供了关键组件的深入分析，确认了其稳健性和有效性。&lt;h4&gt;总结&lt;/h4&gt;xLSTM-Mixer为时间序列预测领域的模型复兴做出了贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mauricekraus/xlstm-mixer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series data is prevalent across numerous fields, necessitating thedevelopment of robust and accurate forecasting models. Capturing patterns bothwithin and between temporal and multivariate components is crucial for reliablepredictions. We introduce xLSTM-Mixer, a model designed to effectivelyintegrate temporal sequences, joint time-variate information, and multipleperspectives for robust forecasting. Our approach begins with a linear forecastshared across variates, which is then refined by xLSTM blocks. These blocksserve as key elements for modeling the complex dynamics of challenging timeseries data. xLSTM-Mixer ultimately reconciles two distinct views to producethe final forecast. Our extensive evaluations demonstrate xLSTM-Mixer'ssuperior long-term forecasting performance compared to recent state-of-the-artmethods. A thorough model analysis provides further insights into its keycomponents and confirms its robustness and effectiveness. This work contributesto the resurgence of recurrent models in time series forecasting.</description>
      <author>example@mail.com (Maurice Kraus, Felix Divo, Devendra Singh Dhami, Kristian Kersting)</author>
      <guid isPermaLink="false">2410.16928v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Improving the Multi-label Atomic Activity Recognition by Robust Visual Feature and Advanced Attention @ ROAD++ Atomic Activity Recognition 2024</title>
      <link>http://arxiv.org/abs/2410.16037v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Road++ Track3提出了一个多标签原子活动识别任务，标准化为64类多标签视频动作识别任务。&lt;h4&gt;目的&lt;/h4&gt;解决视觉特征提取的鲁棒性问题，以提高模型性能和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;{'数据处理': '选择适当的分辨率和视频采样策略，并在验证和测试集中设置固定采样策略。', '模型': '选择多种视觉骨干网络进行特征提取，引入动作槽模型，在训练和验证集上训练，在测试集上推理。', '后处理': '结合不同模型的优势与劣势进行加权融合。'}&lt;h4&gt;主要发现&lt;/h4&gt;最终在测试集上的mAP为58%，比挑战基线高出4%。&lt;h4&gt;结论&lt;/h4&gt;通过优化数据处理、模型选择和后处理策略，显著提升了多标签活动识别的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的方法有效提高了多标签视频动作识别的准确性，展示了在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Road++ Track3 proposes a multi-label atomic activity recognition task intraffic scenarios, which can be standardized as a 64-class multi-label videoaction recognition task. In the multi-label atomic activity recognition task,the robustness of visual feature extraction remains a key challenge, whichdirectly affects the model performance and generalization ability. To cope withthese issues, our team optimized three aspects: data processing, model andpost-processing. Firstly, the appropriate resolution and video samplingstrategy are selected, and a fixed sampling strategy is set on the validationand test sets. Secondly, in terms of model training, the team selects a varietyof visual backbone networks for feature extraction, and then introduces theaction-slot model, which is trained on the training and validation sets, andreasoned on the test set. Finally, for post-processing, the team combined thestrengths and weaknesses of different models for weighted fusion, and the finalmAP on the test set was 58%, which is 4% higher than the challenge baseline.</description>
      <author>example@mail.com (Jiamin Cao, Lingqi Wang, Kexin Zhang, Yuting Yang, Licheng Jiao, Yuwei Guo)</author>
      <guid isPermaLink="false">2410.16037v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>LLM as a code generator in Agile Model Driven Development</title>
      <link>http://arxiv.org/abs/2410.18489v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;利用大型语言模型（LLM）如GPT4进行代码自动生成是一项重要的进展，但也面临诸多挑战，尤其是自然语言描述中的模糊性。&lt;h4&gt;目的&lt;/h4&gt;本研究倡导模型驱动开发（MDD）作为克服这些挑战的有效策略，提出一种敏捷模型驱动开发（AMDD）方法，使用GPT4作为代码生成器。&lt;h4&gt;方法&lt;/h4&gt;通过使用统一建模语言（UML）建模多智能体无人机车队（UVF）系统，结合对象约束语言（OCL）和FIPA本体语言，减少模型模糊性。&lt;h4&gt;主要发现&lt;/h4&gt;应用GPT4的自动生成能力生成的Java和Python代码与JADE和PADE框架兼容，并验证了生成代码与预期行为的一致性，同时识别出智能体交互的增强。&lt;h4&gt;结论&lt;/h4&gt;结构上，评估了仅受OCL元模型约束的代码复杂性与受OCL和FIPA本体元模型共同影响的代码复杂性，结果表明本体约束的元模型生成的代码固有更复杂，但其圈复杂度仍在可管理范围内，暗示可以在不超过高风险阈值的情况下引入更多元模型约束。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了使用AMDD和GPT4有效解决代码自动生成中的模糊性挑战，并证明了在模型约束下生成高质量代码的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging Large Language Models (LLM) like GPT4 in the auto generation ofcode represents a significant advancement, yet it is not without itschallenges. The ambiguity inherent in natural language descriptions of softwareposes substantial obstacles to generating deployable, structured artifacts.This research champions Model Driven Development (MDD) as a viable strategy toovercome these challenges, proposing an Agile Model Driven Development (AMDD)approach that employs GPT4 as a code generator. This approach enhances theflexibility and scalability of the code auto generation process and offersagility that allows seamless adaptation to changes in models or deploymentenvironments. We illustrate this by modeling a multi agent Unmanned VehicleFleet (UVF) system using the Unified Modeling Language (UML), significantlyreducing model ambiguity by integrating the Object Constraint Language (OCL)for code structure meta modeling, and the FIPA ontology language forcommunication semantics meta modeling. Applying GPT4 auto generationcapabilities yields Java and Python code that is compatible with the JADE andPADE frameworks, respectively. Our thorough evaluation of the auto generatedcode verifies its alignment with expected behaviors and identifies enhancementsin agent interactions. Structurally, we assessed the complexity of code derivedfrom a model constrained solely by OCL meta models, against that influenced byboth OCL and FIPA ontology meta models. The results indicate that the ontologyconstrained meta model produces inherently more complex code, yet itscyclomatic complexity remains within manageable levels, suggesting thatadditional meta model constraints can be incorporated without exceeding thehigh risk threshold for complexity.</description>
      <author>example@mail.com (Ahmed R. Sadik, Sebastian Brulin, Markus Olhofer, Antonello Ceravola, Frank Joublin)</author>
      <guid isPermaLink="false">2410.18489v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Evaluation of a Data Annotation Platform for Large, Time-Series Datasets in Intensive Care: Mixed Methods Study</title>
      <link>http://arxiv.org/abs/2410.16959v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;重症监护病房是复杂且数据丰富的环境，为重症患者提供治疗。&lt;h4&gt;目的&lt;/h4&gt;评估一种定制工具，以注释大规模临床时间序列数据集。&lt;h4&gt;方法&lt;/h4&gt;研究分为两个阶段，涉及28名注释员使用50个临床参数进行注释，包含个别住院病例注释和生成规则集的半自动注释。&lt;h4&gt;主要发现&lt;/h4&gt;在招募和参与方面面临重大挑战，但通过干预措施提高了参与度；半自动注释中观察到对不同参数类型的偏好以及参与者间的相对一致性。&lt;h4&gt;结论&lt;/h4&gt;定制工具在提高临床数据注释的效率和质量方面具有潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了在重症监护环境中注释时间序列数据的复杂性及相应的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intensive Care Units are complex, data-rich environments where critically illpatients are treated using variety of clinical equipment. The data collectedusing this equipment can be used clinical staff to gain insight into thecondition of the patients and provide adequate treatment, but it also providesample opportunity for applications in machine learning and data science. Whilethis data can frequently be used directly, complex problems may requireadditional annotations to provide context and meaning before it could be usedto train the machine learning models. Annotating time-series datasets inclinical setting is a complex problem due to a large volume and complexity ofthe data, time-consuming nature of the process and the fact that clinicians'time is in both high demand and short supply. In this study, we present anevaluation of a bespoke tool designed to annotate large, clinical time-seriesdatasets with staff from intensive care units. The software incorporates twomodes for annotation: by annotating individual admissions and by generatingrulesets which are applied to the entire dataset. Our study was split into twostages focusing on individual and semi-automated annotation and included 28annotators across both stages who utilised 50 clinical parameters to guidetheir annotations. We experienced significant challenges in recruitment andengagement of the participants in the annotation activities and developedinterventions which improved the participation over the course of the study.During the semi-automated annotation, we observed preferences for differentparameter types (measured vs. observed), as well as relative agreement ofparticipants across shared admissions to the decision-tree model trained usingtheir rulesets.</description>
      <author>example@mail.com (Marceli Wac, Raul Santos-Rodriguez, Chris McWilliams, Christopher Bourdeaux)</author>
      <guid isPermaLink="false">2410.16959v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>LASER: Script Execution by Autonomous Agents for On-demand Traffic Simulation</title>
      <link>http://arxiv.org/abs/2410.16197v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主驾驶系统（ADS）需要多样且安全关键的交通场景进行有效的训练和测试，但现有的数据生成方法在灵活性和可扩展性方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架LASER，以提升ADS训练和测试数据生成的能力。&lt;h4&gt;方法&lt;/h4&gt;LASER利用大型语言模型（LLMs）根据自然语言输入进行交通仿真，分为两个阶段：首先生成用户提供描述的脚本，然后实时执行这些脚本。&lt;h4&gt;主要发现&lt;/h4&gt;在CARLA模拟器中验证，LASER成功生成复杂的按需驾驶场景，显著提高了ADS训练和测试数据的生成效率。&lt;h4&gt;结论&lt;/h4&gt;LASER框架为自主驾驶系统的数据生成提供了一种灵活和可扩展的解决方案。&lt;h4&gt;总结&lt;/h4&gt;LASER框架通过自然语言处理和实时仿真，优化了自主驾驶系统的训练和测试过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous Driving Systems (ADS) require diverse and safety-critical trafficscenarios for effective training and testing, but the existing data generationmethods struggle to provide flexibility and scalability. We propose LASER, anovel frame-work that leverage large language models (LLMs) to conduct trafficsimulations based on natural language inputs. The framework operates in twostages: it first generates scripts from user-provided descriptions and thenexecutes them using autonomous agents in real time. Validated in the CARLAsimulator, LASER successfully generates complex, on-demand driving scenarios,significantly improving ADS training and testing data generation.</description>
      <author>example@mail.com (Hao Gao, Jingyue Wang, Wenyang Fang, Jingwei Xu, Yunpeng Huang, Taolue Chen, Xiaoxing Ma)</author>
      <guid isPermaLink="false">2410.16197v3</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Multi-UAV Behavior-based Formation with Static and Dynamic Obstacles Avoidance via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2410.18495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多无人机（UAV）编队控制对实际应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决行为驱动的无人机编队任务，同时避开静态和动态障碍物。&lt;h4&gt;方法&lt;/h4&gt;提出了一个两阶段的强化学习训练流程，首先在简化场景中搜索线性效用函数，然后在复杂场景中应用该函数，利用课程学习应对大探索空间。&lt;h4&gt;主要发现&lt;/h4&gt;使用基于注意力的观察编码器增强了编队维护能力，并能有效管理不同数量的障碍物。&lt;h4&gt;结论&lt;/h4&gt;在静态、动态和混合障碍物场景中，我们的方法在无碰撞率和编队维护方面优于基于规划和基于强化学习的基线。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的强化学习方法有效地解决了无人机编队中的多目标优化和障碍物避让问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Formation control of multiple Unmanned Aerial Vehicles (UAVs) is vital forpractical applications. This paper tackles the task of behavior-based UAVformation while avoiding static and dynamic obstacles during directed flight.We present a two-stage reinforcement learning (RL) training pipeline to tacklethe challenge of multi-objective optimization, large exploration spaces, andthe sim-to-real gap. The first stage searches in a simplified scenario for alinear utility function that balances all task objectives simultaneously,whereas the second stage applies the utility function in complex scenarios,utilizing curriculum learning to navigate large exploration spaces.Additionally, we apply an attention-based observation encoder to enhanceformation maintenance and manage varying obstacle quantity. Experiments insimulation and real world demonstrate that our method outperformsplanning-based and RL-based baselines regarding collision-free rate andformation maintenance in scenarios with static, dynamic, and mixed obstacles.</description>
      <author>example@mail.com (Yuqing Xie, Chao Yu, Hongzhi Zang, Feng Gao, Wenhao Tang, Jingyi Huang, Jiayu Chen, Botian Xu, Yi Wu, Yu Wang)</author>
      <guid isPermaLink="false">2410.18495v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>LiNo: Advancing Recursive Residual Decomposition of Linear and Nonlinear Patterns for Robust Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.17159v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在数据驱动的世界中，时间序列数据庞大且复杂，包含多种线性和非线性模式。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的递归残差分解方法，以更好地提取线性和非线性模式。&lt;h4&gt;方法&lt;/h4&gt;引入LiNo框架，通过Li块提取线性模式和No块提取非线性模式，交替和递归地进行提取。&lt;h4&gt;主要发现&lt;/h4&gt;LiNo在十三个真实世界基准测试中，在单变量和多变量预测场景下都取得了最先进的成绩。&lt;h4&gt;结论&lt;/h4&gt;通过这种先进的递归残差分解方法，当前的预测模型可以提供更稳健和精确的结果。&lt;h4&gt;总结&lt;/h4&gt;希望本研究能够为设计更有效的预测模型提供新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/levi-ackman/lino&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting models are pivotal in a data-driven world with vast volumes oftime series data that appear as a compound of vast Linear and Nonlinearpatterns. Recent deep time series forecasting models struggle to utilizeseasonal and trend decomposition to separate the entangled components. Such astrategy only explicitly extracts simple linear patterns like trends, leavingthe other linear modes and vast unexplored nonlinear patterns to the residual.Their flawed linear and nonlinear feature extraction models and shallow-leveldecomposition limit their adaptation to the diverse patterns present inreal-world scenarios. Given this, we innovate Recursive Residual Decompositionby introducing explicit extraction of both linear and nonlinear patterns. Thisdeeper-level decomposition framework, which is named LiNo, captures linearpatterns using a Li block which can be a moving average kernel, and modelsnonlinear patterns using a No block which can be a Transformer encoder. Theextraction of these two patterns is performed alternatively and recursively. Toachieve the full potential of LiNo, we develop the current simple linearpattern extractor to a general learnable autoregressive model, and design anovel No block that can handle all essential nonlinear patterns. Remarkably,the proposed LiNo achieves state-of-the-art on thirteen real-world benchmarksunder univariate and multivariate forecasting scenarios. Experiments show thatcurrent forecasting models can deliver more robust and precise results throughthis advanced Recursive Residual Decomposition. We hope this work could offerinsight into designing more effective forecasting models. Code is available atthis Repository: https://github.com/Levi-Ackman/LiNo.</description>
      <author>example@mail.com (Guoqi Yu, Yaoming Li, Xiaoyu Guo, Dayu Wang, Zirui Liu, Shujun Wang, Tong Yang)</author>
      <guid isPermaLink="false">2410.17159v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Secure Computation and Trustless Data Intermediaries in Data Spaces</title>
      <link>http://arxiv.org/abs/2410.16442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着数据经济的发展，安全和可信的数据共享变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;探讨先进密码技术在数据空间中的整合，以实现安全计算。&lt;h4&gt;方法&lt;/h4&gt;利用安全多方计算（MPC）和完全同态加密（FHE）等安全计算方法，分析数据中介的角色及其在EU数据治理法中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;提出无信任中介的概念，这些中介不访问用户数据，并讨论安全性优势。&lt;h4&gt;挑战&lt;/h4&gt;识别并解决身份管理、政策执行、节点选择和访问控制等关键挑战。&lt;h4&gt;应用&lt;/h4&gt;通过实际案例（如空中交通管理、制造业和二次数据使用）展示解决方案。&lt;h4&gt;框架&lt;/h4&gt;提出了一个全面的框架，以实现和标准化动态、无信任数据环境中的安全计算技术。&lt;h4&gt;总结&lt;/h4&gt;为未来的安全和互操作性数据生态系统的研究与发展铺平道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the integration of advanced cryptographic techniques forsecure computation in data spaces to enable secure and trusted data sharing,which is essential for the evolving data economy. In addition, the paperexamines the role of data intermediaries, as outlined in the EU Data GovernanceAct, in data spaces and specifically introduces the idea of trustlessintermediaries that do not have access to their users' data. Therefore, weexploit the introduced secure computation methods, i.e. Secure Multi-PartyComputation (MPC) and Fully Homomorphic Encryption (FHE), and discuss thesecurity benefits. Overall, we identify and address key challenges forintegration, focusing on areas such as identity management, policy enforcement,node selection, and access control, and present solutions through real-worlduse cases, including air traffic management, manufacturing, and secondary datause. Furthermore, through the analysis of practical applications, this workproposes a comprehensive framework for the implementation and standardizationof secure computing technologies in dynamic, trustless data environments,paving the way for future research and development of a secure andinteroperable data ecosystem.</description>
      <author>example@mail.com (Christoph Fabianek, Stephan Krenn, Thomas Loruenser, Veronika Siska)</author>
      <guid isPermaLink="false">2410.16442v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Ubiquitous Field Transportation Robots with Robust Wheel-Leg Transformable Modules</title>
      <link>http://arxiv.org/abs/2410.18507v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19pages, 17figures, submitted to IEEE ACCESS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文介绍了两种场地运输机器人，分别具备可变形的轮腿模块。&lt;h4&gt;目的&lt;/h4&gt;研究机器人在各种复杂地形中的工作性能和优化方法。&lt;h4&gt;方法&lt;/h4&gt;通过推导数学模型和简化运动学模型，分析轮腿模块在不同地形参数下的操作。&lt;h4&gt;主要发现&lt;/h4&gt;SWhegPro在不平坦户外地形中能有效运输负载，而SWhegPro3在室内场景中具有良好的爬楼梯性能。&lt;h4&gt;结论&lt;/h4&gt;所设计的模块化轮子在高负载下能够准确稳定地切换操作模式，显著提升了机器人在腿模式下的负载能力。&lt;h4&gt;总结&lt;/h4&gt;通过仿真和现场实验验证了设计与控制策略，提出了优化机器人参数和结构的有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces two field transportation robots. Both robots areequipped with transformable wheel-leg modules, which can smoothly switchbetween operation modes and can work in various challenging terrains. SWhegPro,with six S-shaped legs, enables transporting loads in challenging unevenoutdoor terrains. SWhegPro3, featuring four three-impeller wheels, hassurprising stair-climbing performance in indoor scenarios. Different fromordinary gear-driven transformable mechanisms, the modular wheels we designeddriven by self-locking electric push rods can switch modes accurately andstably with high loads, significantly improving the load capacity of the robotin leg mode. This study analyzes the robot's wheel-leg module operation whenthe terrain parameters change. Through the derivation of mathematical modelsand calculations based on simplified kinematic models, a method for optimizingthe robot parameters and wheel-leg structure parameters is finally proposed.Thedesign and control strategy are then verified through simulations and fieldexperiments in various complex terrains, and the working performance of the twofield transportation robots is calculated and analyzed by recording sensor dataand proposing evaluation methods.</description>
      <author>example@mail.com (Haoran Wang, Cunxi Dai, Siyuan Wang, Ximan Zhang, Zheng Zhu, Xiaohan Liu, Jianxiang Zhou, Zhengtao Liu, Zhenzhong Jia)</author>
      <guid isPermaLink="false">2410.18507v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Neuroevolution Neural Architecture Search for Evolving RNNs in Stock Return Prediction and Portfolio Trading</title>
      <link>http://arxiv.org/abs/2410.17212v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;股票回报预测是众多金融应用中的重要组成部分。&lt;h4&gt;目的&lt;/h4&gt;将预测的股票回报纳入投资组合交易算法，以做出更明智的买卖决策，从而优化回报。&lt;h4&gt;方法&lt;/h4&gt;提出使用演化增强记忆模型（EXAMM）算法，逐步演化递归神经网络（RNN）用于股票回报预测。&lt;h4&gt;主要发现&lt;/h4&gt;对每只股票独立演化的RNN能够基于预测的股票回报做出投资组合交易决策。&lt;h4&gt;结论&lt;/h4&gt;使用演化后的RNN和简单的日常多空策略在2022年和2023年均能生成高于道琼斯指数和标准普尔500指数的回报。&lt;h4&gt;总结&lt;/h4&gt;演化RNN模型在不同市场环境下表现出色，证明了其在股票回报预测中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stock return forecasting is a major component of numerous financeapplications. Predicted stock returns can be incorporated into portfoliotrading algorithms to make informed buy or sell decisions which can optimizereturns. In such portfolio trading applications, the predictive performance ofa time series forecasting model is crucial. In this work, we propose the use ofthe Evolutionary eXploration of Augmenting Memory Models (EXAMM) algorithm toprogressively evolve recurrent neural networks (RNNs) for stock returnpredictions. RNNs are evolved independently for each stocks and portfoliotrading decisions are made based on the predicted stock returns. The portfolioused for testing consists of the 30 companies in the Dow-Jones Index (DJI) witheach stock have the same weight. Results show that using these evolved RNNs anda simple daily long-short strategy can generate higher returns than both theDJI index and the S&amp;P 500 Index for both 2022 (bear market) and 2023 (bullmarket).</description>
      <author>example@mail.com (Zimeng Lyu, Amulya Saxena, Rohaan Nadeem, Hao Zhang, Travis Desell)</author>
      <guid isPermaLink="false">2410.17212v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>A Non-Conservative, Non-Local Approximation of the Burgers Equation</title>
      <link>http://arxiv.org/abs/2410.16743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;非局部正则化的标量守恒定律分析是一个活跃的研究领域，应用于交通流等物理现象的建模。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的无粘性非局部正则化方法，采用非发散形式。&lt;h4&gt;方法&lt;/h4&gt;通过我们的方法，可以在总变差和上确界范数上获得尖锐的先验估计，并证明在灾难发生前的辛格极限。&lt;h4&gt;主要发现&lt;/h4&gt;对于一般的守恒定律，当初始数据具有简单不连续性时，结果是尖锐的，即可以证明不收敛。&lt;h4&gt;结论&lt;/h4&gt;对于具有线性通量导数的守恒定律（如Burges方程），在存在不连续性时表现更好，因此特别关注Burges方程在简单不连续初始数据下的非局部解的极限行为。&lt;h4&gt;总结&lt;/h4&gt;本研究为理解非局部正则化在标量守恒定律中的应用提供了重要的理论支持和新的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The analysis of non-local regularisations of scalar conservation laws is anactive research program. Applications of such equations are found in themodelling of physical phenomena such as traffic flow. In this paper, we proposea novel inviscid, non-local regularisation in non-divergence form. The salientfeature of our approach is that we can obtain sharp a priori estimates on thetotal variation and supremum norm, and justify the singular limit for Lipschitzinitial data up to the time of catastrophe. For generic conservation laws, thisresult is sharp, since we can demonstrate non-convergence when the initial datafeatures simple discontinuities. Conservation laws with linear flux derivative,such as the Burgers equation, behave better in the presence of discontinuities.Hence, we devote special attention to the limiting behaviour of non-localsolutions with respect to the Burgers equation for a simple class ofdiscontinuous initial data.</description>
      <author>example@mail.com (Shyam Sundar Ghoshal, Parasuram Venkatesh, Emil Wiedemann)</author>
      <guid isPermaLink="false">2410.16743v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Towards Reinforcement Learning Controllers for Soft Robots using Learned Environments</title>
      <link>http://arxiv.org/abs/2410.18519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  soft manipulator, reinforcement learning, learned controllers&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;软体机器人由于其柔性和可变形的结构，提供了操作上的优势，但其固有的非线性动态带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的软体机器人控制方法，利用先进的策略梯度方法在可并行化的合成环境中进行学习。&lt;h4&gt;方法&lt;/h4&gt;通过级联更新和加权随机性，提出一种安全导向的激励空间探索协议，并利用物理安全的均值回归随机游走生成训练数据集，学习递归前向动态模型。&lt;h4&gt;主要发现&lt;/h4&gt;采用先进的演员-评论家方法进行强化学习，实现闭环控制，能够有效学习长期的高性能行为。&lt;h4&gt;结论&lt;/h4&gt;该方法不需要任何关于机器人操作或能力的先验知识，并为软体机器人控制提供了全面的基准测试工具。&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新方法，通过学习和探索，推动了软体机器人控制的发展，解决了传统方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/RoboSoft60065.2024.10522003&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/uljad/SoRoLEX&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Soft robotic manipulators offer operational advantage due to their compliantand deformable structures. However, their inherently nonlinear dynamicspresents substantial challenges. Traditional analytical methods often depend onsimplifying assumptions, while learning-based techniques can be computationallydemanding and limit the control policies to existing data. This paperintroduces a novel approach to soft robotic control, leveragingstate-of-the-art policy gradient methods within parallelizable syntheticenvironments learned from data. We also propose a safety oriented actuationspace exploration protocol via cascaded updates and weighted randomness.Specifically, our recurrent forward dynamics model is learned by generating atraining dataset from a physically safe \textit{mean reverting} random walk inactuation space to explore the partially-observed state-space. We demonstrate areinforcement learning approach towards closed-loop control throughstate-of-the-art actor-critic methods, which efficiently learn high-performancebehaviour over long horizons. This approach removes the need for any knowledgeregarding the robot's operation or capabilities and sets the stage for acomprehensive benchmarking tool in soft robotics control.</description>
      <author>example@mail.com (Uljad Berdica, Matthew Jackson, Niccolò Enrico Veronese, Jakob Foerster, Perla Maiolino)</author>
      <guid isPermaLink="false">2410.18519v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation</title>
      <link>http://arxiv.org/abs/2410.17462v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 9 figures, 24 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列数据在制造、金融和医疗等多个领域普遍存在。&lt;h4&gt;目的&lt;/h4&gt;提出TESSA，一个多智能体系统，旨在自动生成时间序列数据的通用和领域特定注释。&lt;h4&gt;方法&lt;/h4&gt;TESSA引入两个智能体：通用注释智能体和领域特定注释智能体。通用智能体捕捉多个源领域的共性模式，利用时间序列和文本特征生成通用注释；领域特定智能体则利用目标领域的有限注释学习领域特定术语并生成针对性的注释。&lt;h4&gt;主要发现&lt;/h4&gt;在多个合成和真实世界数据集上的大量实验表明，TESSA有效生成高质量注释，性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;TESSA是一个有效的工具，能够提升时间序列数据的注释质量，尤其在关键任务领域具有重要意义。&lt;h4&gt;总结&lt;/h4&gt;TESSA通过多智能体系统实现了时间序列数据注释的自动化，推动了相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series data is ubiquitous across various domains, includingmanufacturing, finance, and healthcare. High-quality annotations are essentialfor effectively understanding time series and facilitating downstream tasks;however, obtaining such annotations is challenging, particularly inmission-critical domains. In this paper, we propose TESSA, a multi-agent systemdesigned to automatically generate both general and domain-specific annotationsfor time series data. TESSA introduces two agents: a general annotation agentand a domain-specific annotation agent. The general agent captures commonpatterns and knowledge across multiple source domains, leveraging bothtime-series-wise and text-wise features to generate general annotations.Meanwhile, the domain-specific agent utilizes limited annotations from thetarget domain to learn domain-specific terminology and generate targetedannotations. Extensive experiments on multiple synthetic and real-worlddatasets demonstrate that TESSA effectively generates high-quality annotations,outperforming existing methods.</description>
      <author>example@mail.com (Minhua Lin, Zhengzhang Chen, Yanchi Liu, Xujiang Zhao, Zongyu Wu, Junxiang Wang, Xiang Zhang, Suhang Wang, Haifeng Chen)</author>
      <guid isPermaLink="false">2410.17462v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Traj-Explainer: An Explainable and Robust Multi-modal Trajectory Prediction Approach</title>
      <link>http://arxiv.org/abs/2410.16795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能技术的进步显著提升了自动驾驶车辆在复杂交通环境中的环境感知和轨迹预测能力，但现有研究通常忽视场景代理的联合推理，并且轨迹预测模型缺乏可解释性。&lt;h4&gt;目的&lt;/h4&gt;设计一种以可解释性为导向的轨迹预测模型，名为Traj-Explainer，以检索预测影响因素并帮助理解预测的内在机制。&lt;h4&gt;方法&lt;/h4&gt;Traj-Explainer采用了修改后的条件扩散方法，以捕捉场景的多模态轨迹模式，同时组装了修改后的Shapley值模型，以合理学习全局和场景特征的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;通过多个轨迹预测数据集（包括Waymo、NGSIM、HighD和MoCAD）进行的数值实验表明，识别的输入因素与人类驾驶经验一致，表明该模型能够适当地学习预测。&lt;h4&gt;结论&lt;/h4&gt;所提出的模型在轨迹预测中具有良好的可解释性和实用性，能够为实际应用提供支持。&lt;h4&gt;总结&lt;/h4&gt;该研究通过Traj-Explainer模型提升了轨迹预测的可解释性，有助于理解预测机制，并验证了模型的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Navigating complex traffic environments has been significantly enhanced byadvancements in intelligent technologies, enabling accurate environmentperception and trajectory prediction for automated vehicles. However, existingresearch often neglects the consideration of the joint reasoning of scenarioagents and lacks interpretability in trajectory prediction models, therebylimiting their practical application in real-world scenarios. To this purpose,an explainability-oriented trajectory prediction model is designed in thiswork, named Explainable Conditional Diffusion based Multimodal TrajectoryPrediction Traj-Explainer, to retrieve the influencing factors of predictionand help understand the intrinsic mechanism of prediction. In Traj-Explainer, amodified conditional diffusion is well designed to capture the scenariomultimodal trajectory pattern, and meanwhile, a modified Shapley Value model isassembled to rationally learn the importance of the global and scenariofeatures. Numerical experiments are carried out by several trajectoryprediction datasets, including Waymo, NGSIM, HighD, and MoCAD datasets.Furthermore, we evaluate the identified input factors which indicates that theyare in agreement with the human driving experience, indicating the capabilityof the proposed model in appropriately learning the prediction. Code availablein our open-source repository:\url{https://anonymous.4open.science/r/Interpretable-Prediction}.</description>
      <author>example@mail.com (Pei Liu, Haipeng Liu, Yiqun Li, Tianyu Shi, Meixin Zhu, Ziyuan Pu)</author>
      <guid isPermaLink="false">2410.16795v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Zero-shot Object Navigation with Vision-Language Models Reasoning</title>
      <link>http://arxiv.org/abs/2410.18570v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by the International Conference on Pattern Recognition
  (ICPR) for Oral presentation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;物体导航对机器人至关重要，但传统方法需要大量训练数据，且无法泛化到未知环境。&lt;h4&gt;目的&lt;/h4&gt;提出一种零样本物体导航（ZSON）的方法，使机器人能够与未知物体交互，而无需特定的训练数据。&lt;h4&gt;方法&lt;/h4&gt;引入语言驱动的零样本物体导航（L-ZSON），采用一种新颖的视觉语言模型与思维树网络（VLTNet），包括视觉语言模型理解、语义映射、思维树推理与探索、目标识别等四个主要模块。&lt;h4&gt;主要发现&lt;/h4&gt;思维树（ToT）推理与探索模块作为核心组件，通过推理框架创新性地进行导航前沿选择，增强了决策的准确性。&lt;h4&gt;结论&lt;/h4&gt;与传统的前沿选择方法相比，利用ToT推理的导航过程涉及多路径推理和必要时的回溯，从而实现更高的全局决策精度。&lt;h4&gt;总结&lt;/h4&gt;在PASTURE和RoboTHOR基准测试中的实验结果表明，该模型在L-ZSON方面表现出色，特别是在复杂自然语言指令的场景中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object navigation is crucial for robots, but traditional methods requiresubstantial training data and cannot be generalized to unknown environments.Zero-shot object navigation (ZSON) aims to address this challenge, allowingrobots to interact with unknown objects without specific training data.Language-driven zero-shot object navigation (L-ZSON) is an extension of ZSONthat incorporates natural language instructions to guide robot navigation andinteraction with objects. In this paper, we propose a novel Vision Languagemodel with a Tree-of-thought Network (VLTNet) for L-ZSON. VLTNet comprises fourmain modules: vision language model understanding, semantic mapping,tree-of-thought reasoning and exploration, and goal identification. Among thesemodules, Tree-of-Thought (ToT) reasoning and exploration module serves as acore component, innovatively using the ToT reasoning framework for navigationfrontier selection during robot exploration. Compared to conventional frontierselection without reasoning, navigation using ToT reasoning involves multi-pathreasoning processes and backtracking when necessary, enabling globally informeddecision-making with higher accuracy. Experimental results on PASTURE andRoboTHOR benchmarks demonstrate the outstanding performance of our model inLZSON, particularly in scenarios involving complex natural language as targetinstructions.</description>
      <author>example@mail.com (Congcong Wen, Yisiyuan Huang, Hao Huang, Yanjia Huang, Shuaihang Yuan, Yu Hao, Hui Lin, Yu-Shen Liu, Yi Fang)</author>
      <guid isPermaLink="false">2410.18570v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>PerspectiveNet: Multi-View Perception for Dynamic Scene Understanding</title>
      <link>http://arxiv.org/abs/2410.16824v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从多个摄像头和视角生成详细描述具有挑战性，因为视觉数据复杂且不一致。&lt;h4&gt;目的&lt;/h4&gt;介绍一种轻量且高效的模型PerspectiveNet，用于跨多个摄像头视角生成长描述。&lt;h4&gt;方法&lt;/h4&gt;采用视觉编码器和紧凑的连接模块，将视觉特征转换为固定大小的张量，并利用大型语言模型（LLMs）进行自然语言生成。&lt;h4&gt;主要发现&lt;/h4&gt;连接模块的设计包含三个主要目标：将视觉特征映射到LLM嵌入、强调描述生成所需的关键信息、生成固定大小的特征矩阵。&lt;h4&gt;结论&lt;/h4&gt;通过引入次要任务（正确帧序列检测），模型能够搜索生成描述所需的正确帧序列。最终将连接模块、次要任务、LLM和视觉特征提取模型整合为一个架构，专注于交通安全描述和分析任务，生成多摄像头视角下的详细事件描述。&lt;h4&gt;总结&lt;/h4&gt;所提出的模型轻量化，确保了高效的训练与推理，同时表现出高度的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating detailed descriptions from multiple cameras and viewpoints ischallenging due to the complex and inconsistent nature of visual data. In thispaper, we introduce PerspectiveNet, a lightweight yet efficient model forgenerating long descriptions across multiple camera views. Our approachutilizes a vision encoder, a compact connector module to convert visualfeatures into a fixed-size tensor, and large language models (LLMs) to harnessthe strong natural language generation capabilities of LLMs. The connectormodule is designed with three main goals: mapping visual features onto LLMembeddings, emphasizing key information needed for description generation, andproducing a fixed-size feature matrix. Additionally, we augment our solutionwith a secondary task, the correct frame sequence detection, enabling the modelto search for the correct sequence of frames to generate descriptions. Finally,we integrate the connector module, the secondary task, the LLM, and a visualfeature extraction model into a single architecture, which is trained for theTraffic Safety Description and Analysis task. This task requires generatingdetailed, fine-grained descriptions of events from multiple cameras andviewpoints. The resulting model is lightweight, ensuring efficient training andinference, while remaining highly effective.</description>
      <author>example@mail.com (Vinh Nguyen)</author>
      <guid isPermaLink="false">2410.16824v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>On Model-Free Re-ranking for Visual Place Recognition with Deep Learned Local Features</title>
      <link>http://arxiv.org/abs/2410.18573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;重排名是视觉位置识别任务的第二阶段，系统从预选的候选图像中选择最佳匹配图像。&lt;h4&gt;目的&lt;/h4&gt;研究基于标准局部视觉特征的无模型重排名方法及其在长期自主系统中的适用性。&lt;h4&gt;方法&lt;/h4&gt;提出三种新的无模型重排名方法，主要针对深度学习的局部视觉特征设计。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在各种外观变化中表现出较高的鲁棒性，适合长期自主系统使用。&lt;h4&gt;结论&lt;/h4&gt;实验结果与当前最先进的方法相当，表明无模型方法是长期视觉位置识别的可行且值得探索的路径。&lt;h4&gt;总结&lt;/h4&gt;本文介绍的无模型重排名方法为视觉位置识别提供了有效的解决方案，尤其适用于长期应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Re-ranking is the second stage of a visual place recognition task, in whichthe system chooses the best-matching images from a pre-selected subset ofcandidates. Model-free approaches compute the image pair similarity based on aspatial comparison of corresponding local visual features, eliminating the needfor computationally expensive estimation of a model describing transformationbetween images. The article focuses on model-free re-ranking based on standardlocal visual features and their applicability in long-term autonomy systems. Itintroduces three new model-free re-ranking methods that were designed primarilyfor deep-learned local visual features. These features evince high robustnessto various appearance changes, which stands as a crucial property for use withlong-term autonomy systems. All the introduced methods were employed in a newvisual place recognition system together with the D2-net feature detector(Dusmanu, 2019) and experimentally tested with diverse, challenging publicdatasets. The obtained results are on par with current state-of-the-artmethods, affirming that model-free approaches are a viable and worthwhile pathfor long-term visual place recognition.</description>
      <author>example@mail.com (Tomáš Pivoňka, Libor Přeučil)</author>
      <guid isPermaLink="false">2410.18573v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Predicting Company Growth by Econophysics informed Machine Learning</title>
      <link>http://arxiv.org/abs/2410.17587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预测公司增长对战略调整、运营决策、风险评估和贷款资格审查至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于机器学习的公司增长预测框架。&lt;h4&gt;方法&lt;/h4&gt;将经济物理学模型与机器学习结合，捕捉公司内在的增长机制和随机因素的影响。&lt;h4&gt;主要发现&lt;/h4&gt;相比于单纯依赖时间序列技术的方法，本模型在预测性能上表现更优，特别是在长时间范围的预测任务中。&lt;h4&gt;结论&lt;/h4&gt;通过明确建模基线增长和波动成分，本模型在可解释性上更具优势。&lt;h4&gt;总结&lt;/h4&gt;该模型为公司增长预测提供了更准确和可解释的工具，弥补了传统方法的不足。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting company growth is crucial for strategic adjustment, operationaldecision-making, risk assessment, and loan eligibility reviews. Traditionalmodels for company growth often focus too much on theory, overlooking practicalforecasting, or they rely solely on time series forecasting techniques,ignoring interpretability and the inherent mechanisms of company growth. Inthis paper, we propose a machine learning-based prediction framework thatincorporates an econophysics model for company growth. Our model captures boththe intrinsic growth mechanisms of companies led by scaling laws and thefluctuations influenced by random factors and individual decisions,demonstrating superior predictive performance compared with methods that usetime series techniques alone. Its advantages are more pronounced in long-rangeprediction tasks. By explicitly modeling the baseline growth and volatilitycomponents, our model is more interpretable.</description>
      <author>example@mail.com (Ruyi Tao, Kaiwei Liu, Xu Jing, Jiang Zhang)</author>
      <guid isPermaLink="false">2410.17587v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>IncEventGS: Pose-Free Gaussian Splatting from a Single Event Camera</title>
      <link>http://arxiv.org/abs/2410.08107v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code Page: https://github.com/wu-cvgl/IncEventGS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;隐式神经表示和显式的3D高斯点云技术在基于帧的摄像机（如RGB和RGB-D摄像机）上取得了显著进展。与之相比，生物启发的事件摄像机在高时间分辨率、高动态范围、低功耗和低延迟方面具有优势。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的增量3D高斯点云重建算法IncEventGS，专门针对单个事件摄像机。&lt;h4&gt;方法&lt;/h4&gt;利用传统SLAM管道的跟踪和映射范式，逐步恢复3D场景表示。跟踪器根据先前重建的3D-GS场景表示估计相机初始运动，映射器则基于跟踪器估计的运动轨迹共同优化3D场景表示和相机运动。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，IncEventGS在性能上优于先前的NeRF-based方法和其他相关基线，即使没有真实的相机位姿数据。&lt;h4&gt;结论&lt;/h4&gt;该方法在相机运动估计方面也优于最先进的事件视觉测距方法，证明了其有效性。&lt;h4&gt;代码链接&lt;/h4&gt;https://github.com/wu-cvgl/IncEventGS&lt;h4&gt;总结&lt;/h4&gt;IncEventGS展示了在事件摄像机上进行增量3D重建的潜力，超越了多种现有技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/wu-cvgl/inceventgs&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit neural representation and explicit 3D Gaussian Splatting (3D-GS) fornovel view synthesis have achieved remarkable progress with frame-based camera(e.g. RGB and RGB-D cameras) recently. Compared to frame-based camera, a noveltype of bio-inspired visual sensor, i.e. event camera, has demonstratedadvantages in high temporal resolution, high dynamic range, low powerconsumption and low latency. Due to its unique asynchronous and irregular datacapturing process, limited work has been proposed to apply neuralrepresentation or 3D Gaussian splatting for an event camera. In this work, wepresent IncEventGS, an incremental 3D Gaussian Splatting reconstructionalgorithm with a single event camera. To recover the 3D scene representationincrementally, we exploit the tracking and mapping paradigm of conventionalSLAM pipelines for IncEventGS. Given the incoming event stream, the trackerfirstly estimates an initial camera motion based on prior reconstructed 3D-GSscene representation. The mapper then jointly refines both the 3D scenerepresentation and camera motion based on the previously estimated motiontrajectory from the tracker. The experimental results demonstrate thatIncEventGS delivers superior performance compared to prior NeRF-based methodsand other related baselines, even we do not have the ground-truth camera poses.Furthermore, our method can also deliver better performance compared tostate-of-the-art event visual odometry methods in terms of camera motionestimation. Code is publicly available at:https://github.com/wu-cvgl/IncEventGS.</description>
      <author>example@mail.com (Jian Huang, Chengrui Dong, Peidong Liu)</author>
      <guid isPermaLink="false">2410.08107v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant</title>
      <link>http://arxiv.org/abs/2410.18603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数字代理能够自动化复杂计算任务，提升人机交互的潜力受到广泛关注，但现有代理方法在泛化和专业化能力上存在不足，尤其是在处理现实环境中开放式计算任务时。&lt;h4&gt;目的&lt;/h4&gt;提出AgentStore，一个可扩展的平台，旨在动态集成异构代理以自动化计算任务。&lt;h4&gt;方法&lt;/h4&gt;AgentStore允许用户集成第三方代理，并引入了一种新核心MetaAgent与AgentToken策略，以高效管理多样化代理，利用它们的专业和通用能力。&lt;h4&gt;主要发现&lt;/h4&gt;在三个具有挑战性的基准测试中，AgentStore超越了以往系统的局限性，尤其是在OSWorld基准测试中，性能从11.21%显著提升至23.85%，超过了之前的结果。&lt;h4&gt;结论&lt;/h4&gt;AgentStore在泛化和专业化方面增强了代理系统，显示出开发专业通用计算助手的潜力。&lt;h4&gt;总结&lt;/h4&gt;所有代码将公开发布在https://chengyou-jia.github.io/AgentStore-Home。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Digital agents capable of automating complex computer tasks have attractedconsiderable attention due to their immense potential to enhance human-computerinteraction. However, existing agent methods exhibit deficiencies in theirgeneralization and specialization capabilities, especially in handlingopen-ended computer tasks in real-world environments. Inspired by the richfunctionality of the App store, we present AgentStore, a scalable platformdesigned to dynamically integrate heterogeneous agents for automating computertasks. AgentStore empowers users to integrate third-party agents, allowing thesystem to continuously enrich its capabilities and adapt to rapidly evolvingoperating systems. Additionally, we propose a novel core \textbf{MetaAgent}with the \textbf{AgentToken} strategy to efficiently manage diverse agents andutilize their specialized and generalist abilities for both domain-specific andsystem-wide tasks. Extensive experiments on three challenging benchmarksdemonstrate that AgentStore surpasses the limitations of previous systems withnarrow capabilities, particularly achieving a significant improvement from11.21\% to 23.85\% on the OSWorld benchmark, more than doubling the previousresults. Comprehensive quantitative and qualitative results further demonstrateAgentStore's ability to enhance agent systems in both generalization andspecialization, underscoring its potential for developing the specializedgeneralist computer assistant. All our codes will be made publicly available inhttps://chengyou-jia.github.io/AgentStore-Home.</description>
      <author>example@mail.com (Chengyou Jia, Minnan Luo, Zhuohang Dang, Qiushi Sun, Fangzhi Xu, Junlin Hu, Tianbao Xie, Zhiyong Wu)</author>
      <guid isPermaLink="false">2410.18603v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Signature-based IaaS Performance Change Detection</title>
      <link>http://arxiv.org/abs/2410.17623v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted in ACM transaction on Internet Technology in October 2024.
  arXiv admin note: text overlap with arXiv:2007.11705&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新颖的变化检测框架，用于识别IaaS服务长期性能行为的变化。&lt;h4&gt;目的&lt;/h4&gt;通过IaaS性能特征来表示IaaS服务的长期性能行为。&lt;h4&gt;方法&lt;/h4&gt;利用时间序列相似性度量和滑动窗口技术来检测IaaS性能特征的变化，并引入新的IaaS性能噪声模型。&lt;h4&gt;主要发现&lt;/h4&gt;该框架能够区分性能噪声和实际性能变化，且在有先前噪声知识的情况下，采用基于信噪比(SNR)的新方法检测变化。&lt;h4&gt;结论&lt;/h4&gt;通过使用真实世界数据集进行的一系列实验，证明了所提出的变化检测框架的有效性。&lt;h4&gt;总结&lt;/h4&gt;此框架为IaaS服务性能监测提供了一种有效手段，能够更准确地识别性能变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel change detection framework to identify changes in thelong-term performance behavior of an IaaS service. An IaaS service's long-termperformance behavior is represented by an IaaS performance signature. Theproposed framework leverages time series similarity measures and a slidingwindow technique to detect changes in IaaS performance signatures. We introducea new IaaS performance noise model that enables the proposed framework todistinguish between performance noise and actual changes in performance. Theproposed framework utilizes a novel Signal-to-Noise Ratio (SNR) based approachto detect changes when prior knowledge about performance noise is available. Aset of experiments is conducted using real-world datasets to demonstrate theeffectiveness of the proposed change detection framework.</description>
      <author>example@mail.com (Sheik Mohammad Mostakim Fattah, Athman Bouguettaya)</author>
      <guid isPermaLink="false">2410.17623v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>AGSENet: A Robust Road Ponding Detection Method for Proactive Traffic Safety</title>
      <link>http://arxiv.org/abs/2410.16999v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;道路积水是一种普遍的交通隐患，严重威胁道路安全，导致车辆失控和事故，从轻微的剐蹭到严重碰撞。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，称为基于自注意力的全局显著性增强网络（AGSENet），以主动检测道路积水并改善交通安全。&lt;h4&gt;方法&lt;/h4&gt;AGSENet结合了显著性检测技术，通过通道显著性信息聚焦（CSIF）和空间显著性信息增强（SSIE）模块实现。&lt;h4&gt;主要发现&lt;/h4&gt;AGSENet在Puddle-1000、Foggy-Puddle和Night-Puddle数据集上的IoU分别提高了2.03%、0.62%和1.06%，超越了现有方法，设置了该领域的新状态。&lt;h4&gt;结论&lt;/h4&gt;验证了该算法在边缘计算设备上的可靠性，为道路交通安全中的主动预警研究提供了重要参考。&lt;h4&gt;总结&lt;/h4&gt;AGSENet通过改进的特征融合和噪声减少方法，有效提升了道路积水的检测能力，为交通安全提供了新的解决思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Road ponding, a prevalent traffic hazard, poses a serious threat to roadsafety by causing vehicles to lose control and leading to accidents rangingfrom minor fender benders to severe collisions. Existing technologies struggleto accurately identify road ponding due to complex road textures and variableponding coloration influenced by reflection characteristics. To address thischallenge, we propose a novel approach called Self-Attention-based GlobalSaliency-Enhanced Network (AGSENet) for proactive road ponding detection andtraffic safety improvement. AGSENet incorporates saliency detection techniquesthrough the Channel Saliency Information Focus (CSIF) and Spatial SaliencyInformation Enhancement (SSIE) modules. The CSIF module, integrated into theencoder, employs self-attention to highlight similar features by fusing spatialand channel information. The SSIE module, embedded in the decoder, refines edgefeatures and reduces noise by leveraging correlations across different featurelevels. To ensure accurate and reliable evaluation, we corrected significantmislabeling and missing annotations in the Puddle-1000 dataset. Additionally,we constructed the Foggy-Puddle and Night-Puddle datasets for road pondingdetection in low-light and foggy conditions, respectively. Experimental resultsdemonstrate that AGSENet outperforms existing methods, achieving IoUimprovements of 2.03\%, 0.62\%, and 1.06\% on the Puddle-1000, Foggy-Puddle,and Night-Puddle datasets, respectively, setting a new state-of-the-art in thisfield. Finally, we verified the algorithm's reliability on edge computingdevices. This work provides a valuable reference for proactive warning researchin road traffic safety.</description>
      <author>example@mail.com (Ronghui Zhang, Shangyu Yang, Dakang Lyu, Zihan Wang, Junzhou Chen, Yilong Ren, Bolin Gao, Zhihan Lv)</author>
      <guid isPermaLink="false">2410.16999v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Learning Transparent Reward Models via Unsupervised Feature Selection</title>
      <link>http://arxiv.org/abs/2410.18608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在复杂的现实任务中，如机器人操作和自动驾驶，收集专家示范通常比指定精确的学习目标和任务描述更简单。&lt;h4&gt;目的&lt;/h4&gt;通过学习专家数据来提高机器人和自动驾驶系统的性能。&lt;h4&gt;方法&lt;/h4&gt;提出一种新方法，通过自动选择的状态特征构建紧凑且透明的奖励模型，并使用逆强化学习进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;所提奖励模型具有明确的形式，能够使学习的策略与专家行为紧密匹配。&lt;h4&gt;结论&lt;/h4&gt;该方法在具有连续和高维状态空间的各种机器人环境中有效验证了其性能。&lt;h4&gt;总结&lt;/h4&gt;通过透明的奖励模型和逆强化学习，能够更有效地从专家示范中学习，从而提升机器人和自动驾驶系统的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In complex real-world tasks such as robotic manipulation and autonomousdriving, collecting expert demonstrations is often more straightforward thanspecifying precise learning objectives and task descriptions. Learning fromexpert data can be achieved through behavioral cloning or by learning a rewardfunction, i.e., inverse reinforcement learning. The latter allows for trainingwith additional data outside the training distribution, guided by the inferredreward function. We propose a novel approach to construct compact andtransparent reward models from automatically selected state features. Theseinferred rewards have an explicit form and enable the learning of policies thatclosely match expert behavior by training standard reinforcement learningalgorithms from scratch. We validate our method's performance in variousrobotic environments with continuous and high-dimensional state spaces.Webpage: \url{https://sites.google.com/view/transparent-reward}.</description>
      <author>example@mail.com (Daulet Baimukashev, Gokhan Alcan, Kevin Sebastian Luck, Ville Kyrki)</author>
      <guid isPermaLink="false">2410.18608v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>FlowTracer: A Tool for Uncovering Network Path Usage Imbalance in AI Training Clusters</title>
      <link>http://arxiv.org/abs/2410.17078v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted for peer reviewing in IEEE ICC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;AI工作负载的复杂性日益增加，尤其是分布式大型语言模型（LLM）训练，对并行数据中心和超级计算系统的网络基础设施造成了显著压力。&lt;h4&gt;目的&lt;/h4&gt;提出FlowTracer工具，以分析网络路径利用率并评估不同的路由策略。&lt;h4&gt;方法&lt;/h4&gt;FlowTracer通过提供流量分布的详细可见性，帮助调试网络低效问题，识别性能下降的根本原因，如哈希冲突导致的问题。&lt;h4&gt;主要发现&lt;/h4&gt;在使用RoCEv2启用的集群和16个400-Gbps节点的情况下，FlowTracer能够比较ECMP路由与静态配置网络的流量不平衡，展示出30%的不平衡减少。&lt;h4&gt;结论&lt;/h4&gt;通过提供流级别的见解，FlowTracer使系统操作员能够优化路由、减少拥塞，并提升分布式AI工作负载的性能。&lt;h4&gt;总结&lt;/h4&gt;FlowTracer为网络性能优化提供了一种有效工具，尤其在处理复杂AI工作负载时具有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The increasing complexity of AI workloads, especially distributed LargeLanguage Model (LLM) training, places significant strain on the networkinginfrastructure of parallel data centers and supercomputing systems. WhileEqual-Cost Multi- Path (ECMP) routing distributes traffic over parallel paths,hash collisions often lead to imbalanced network resource utilization andperformance bottlenecks. This paper presents FlowTracer, a tool designed toanalyze network path utilization and evaluate different routing strategies.FlowTracer aids in debugging network inefficiencies by providing detailedvisibility into traffic distribution and helping to identify the root causes ofperformance degradation, such as issues caused by hash collisions. By offeringflow-level insights, FlowTracer enables system operators to optimize routing,reduce congestion, and improve the performance of distributed AI workloads. Weuse a RoCEv2-enabled cluster with a leaf-spine network and 16 400-Gbps nodes todemonstrate how FlowTracer can be used to compare the flow imbalances of ECMProuting against a statically configured network. The example showcases a 30%reduction in imbalance, as measured by a new metric we introduce.</description>
      <author>example@mail.com (Hasibul Jamil, Abdul Alim, Laurent Schares, Pavlos Maniotis, Liran Schour, Ali Sydney, Abdullah Kayi, Tevfik Kosar, Bengi Karacali)</author>
      <guid isPermaLink="false">2410.17078v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Deep Learning for Time Series Extrinsic Regression in predicting photometric metallicity of Fundamental-mode RR Lyrae Stars</title>
      <link>http://arxiv.org/abs/2410.17906v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Sensors 2024, 24(16), 5203; (23 pages)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;天文学正进入一个前所未有的大数据科学时代，ESA的盖亚望远镜旨在三维绘制银河系。&lt;h4&gt;目的&lt;/h4&gt;开发一种新方法，利用深度学习技术从盖亚光学G波段的光变曲线中估计基本模式（ab型）RR Lyrae星的金属丰度。&lt;h4&gt;方法&lt;/h4&gt;采用深度学习技术，特别是先进的神经网络架构，进行时间序列数据的光度金属丰度预测。&lt;h4&gt;主要发现&lt;/h4&gt;深度学习模型表现出显著的预测性能，平均绝对误差（MAE）为0.0565，均方根误差（RMSE）为0.0765，回归性能的$R^2$值为0.9401。&lt;h4&gt;结论&lt;/h4&gt;我们的研究展示了深度学习在天文研究中的重要性，尤其是在处理盖亚等任务的大数据集时。&lt;h4&gt;总结&lt;/h4&gt;通过利用深度学习方法，我们能够在分析大型数据集时提供精确度，为复杂天文现象提供更精确和全面的洞察。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.3390/s24165203&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lorenzomonti/metallicity_rrls&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Astronomy is entering an unprecedented era of Big Data science, driven bymissions like the ESA's Gaia telescope, which aims to map the Milky Way inthree dimensions. Gaia's vast dataset presents a monumental challenge fortraditional analysis methods. The sheer scale of this data exceeds thecapabilities of manual exploration, necessitating the utilization of advancedcomputational techniques. In response to this challenge, we developed a novelapproach leveraging deep learning to estimate the metallicity of fundamentalmode (ab-type) RR Lyrae stars from their light curves in the Gaia opticalG-band. Our study explores applying deep learning techniques, particularlyadvanced neural network architectures, in predicting photometric metallicityfrom time-series data. Our deep learning models demonstrated notable predictiveperformance, with a low mean absolute error (MAE) of 0.0565, the root meansquare error (RMSE) achieved is 0.0765 and a high $R^2$ regression performanceof 0.9401 measured by cross-validation. The weighted mean absolute error (wMAE)is 0.0563, while the weighted root mean square error (wRMSE) is 0.0763. Theseresults showcase the effectiveness of our approach in accurately estimatingmetallicity values. Our work underscores the importance of deep learning inastronomical research, particularly with large datasets from missions likeGaia. By harnessing the power of deep learning methods, we can provideprecision in analyzing vast datasets, contributing to more precise andcomprehensive insights into complex astronomical phenomena.</description>
      <author>example@mail.com (Lorenzo Monti, Tatiana Muraveva, Gisella Clementini, Alessia Garofalo)</author>
      <guid isPermaLink="false">2410.17906v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>A Cranial-Feature-Based Registration Scheme for Robotic Micromanipulation Using a Microscopic Stereo Camera System</title>
      <link>http://arxiv.org/abs/2410.18630v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Advanced Robotics, Vol. 38, Issue 21&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生物样本在大小和形状上存在显著变化，给自主机器人操作带来挑战。&lt;h4&gt;目的&lt;/h4&gt;聚焦于小鼠颅骨窗口创建任务，以说明这些挑战。&lt;h4&gt;方法&lt;/h4&gt;引入微观立体相机系统（MSCS），并通过线性模型增强深度感知。同时，开发了基于CNN的约束和彩色配准策略，用于部分暴露的小鼠颅面。&lt;h4&gt;主要发现&lt;/h4&gt;MSCS在步高实验中表现出高精度，测得精度为0.10mm ± 0.02 mm，3D重建实时性能达到30 FPS。配准方案的平移误差为1.13 mm ± 0.31 mm，旋转误差为3.38° ± 0.89°，在105帧连续测试中，平均速度为1.60 FPS。&lt;h4&gt;结论&lt;/h4&gt;本研究展示了MSCS及新颖的配准方案在提高科学和外科设置中机器微操作的精度与准确性方面的应用。&lt;h4&gt;总结&lt;/h4&gt;所提出的创新为微观操作中的挑战提供了自动化方法，为各领域的微创手术和科学研究铺平了更准确、高效和更少侵入性的程序道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1080/01691864.2024.2415092&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Biological specimens exhibit significant variations in size and shape,challenging autonomous robotic manipulation. We focus on the mouse skull windowcreation task to illustrate these challenges. The study introduces amicroscopic stereo camera system (MSCS) enhanced by the linear model for depthperception. Alongside this, a precise registration scheme is developed for thepartially exposed mouse cranial surface, employing a CNN-based constrained andcolorized registration strategy. These methods are integrated with the MSCS forrobotic micromanipulation tasks. The MSCS demonstrated a high precision of 0.10mm $\pm$ 0.02 mm measured in a step height experiment and real-time performanceof 30 FPS in 3D reconstruction. The registration scheme proved its precision,with a translational error of 1.13 mm $\pm$ 0.31 mm and a rotational error of3.38$^{\circ}$ $\pm$ 0.89$^{\circ}$ tested on 105 continuous frames with anaverage speed of 1.60 FPS. This study presents the application of a MSCS and anovel registration scheme in enhancing the precision and accuracy of roboticmicromanipulation in scientific and surgical settings. The innovationspresented here offer automation methodology in handling the challenges ofmicroscopic manipulation, paving the way for more accurate, efficient, and lessinvasive procedures in various fields of microsurgery and scientific research.</description>
      <author>example@mail.com (Xiaofeng Lin, Saúl Alexis Heredia Pérez, Kanako Harada)</author>
      <guid isPermaLink="false">2410.18630v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Nonequilibrium Fluctuation-Response Relations: From Identities to Bounds</title>
      <link>http://arxiv.org/abs/2410.17140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在非平衡稳态的Markov跳跃过程中，研究波动-响应关系（FRRs）。&lt;h4&gt;目的&lt;/h4&gt;推导FRRs，以便在远离平衡的情况下推广波动-耗散定理。&lt;h4&gt;方法&lt;/h4&gt;考虑速率的对称部分的扰动，演示FRRs如何推导出热力学界限。&lt;h4&gt;主要发现&lt;/h4&gt;{'热力学界限': 'FRRs暗示了热力学界限的层次结构。', '约束关系': '证明了最近猜测的响应热力学不确定性关系（R-TUR），它限制了任何电流的响应与其方差的比率。', '增强界限': '通过部分熵产生率（EPR）和伪EPR两种方式增强了该界限。', '交通约束': '对于速率的反对称部分的扰动，电流响应与方差的比率受交通限制。'}&lt;h4&gt;结论&lt;/h4&gt;FRRs可以解释在Coulomb阻塞系统中观察到的电流之间的正相关性。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了FRRs的确切形式，揭示了与非平衡态相关的热力学性质，强化了对电流响应的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In nonequilibrium steady states of Markov jump processes, we derive exactFluctuation-Response Relations (FRRs) that express the covariance between anypair of currents in terms of static responses in a notably simple form, thusgeneralizing the fluctuation-dissipation theorem far from equilibrium. We beginby considering perturbations in the symmetric part of the rates. We demonstratethat FRRs imply a hierarchy of thermodynamic bounds. These latter prove therecently conjectured Response Thermodynamic Uncertainty Relation (R-TUR), whichbounds the ratio between any current's response and its variance by the entropyproduction rate (EPR). We furthermore strengthen this bound in two distinctways, using partial EPR in one case and pseudo-EPR in the other. Forperturbations in the antisymmetric part of the rates, we show that the ratiobetween any current's response and its variance is bounded by traffic, a metricrepresenting the total number of transitions per unit time in the system. As anapplication, we use FRRs to explain the origin of positive correlations betweencurrents in Coulomb-blockaded systems previously observed in experiments.</description>
      <author>example@mail.com (Timur Aslyamov, Krzysztof Ptaszyński, Massimiliano Esposito)</author>
      <guid isPermaLink="false">2410.17140v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Embodied Manipulation with Past and Future Morphologies through an Open Parametric Hand Design</title>
      <link>http://arxiv.org/abs/2410.18633v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  44 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人形机器人手提供了无与伦比的多功能性和精细的运动技能，能够以精确、强大和稳健的方式执行广泛任务。&lt;h4&gt;目的&lt;/h4&gt;理解手的形态设计空间及其产生的行为，以帮助理解灵巧操作及其演化，并优化设计，达到并超越人类能力。&lt;h4&gt;方法&lt;/h4&gt;引入开放参数化设计，集成简化定制、制造和控制的技术，并设计特征以最大化行为多样性。&lt;h4&gt;主要发现&lt;/h4&gt;采用非线性滚动关节、解剖学肌腱路径和低自由度调节驱动系统，快速生产单件3D打印手而不妨碍灵巧行为，展示了可变刚度的低级行为范围和稳定性。&lt;h4&gt;结论&lt;/h4&gt;制造了三种手设计（人手、镜像人手和艾耶艾耶手），通过操作测试评估了每种手处理不同物体的能力，展示了每种设计独特的涌现行为。&lt;h4&gt;总结&lt;/h4&gt;揭示了机器人手的新设计可能性，提供了比较和对比不同手形态和结构的设计空间，并分享了探索具身操作的实用开源设计。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A human-shaped robotic hand offers unparalleled versatility and fine motorskills, enabling it to perform a broad spectrum of tasks with precision, powerand robustness. Across the paleontological record and animal kingdom we see awide range of alternative hand and actuation designs. Understanding themorphological design space and the resulting emergent behaviors can not onlyaid our understanding of dexterous manipulation and its evolution, but alsoassist design optimization, achieving, and eventually surpassing humancapabilities. Exploration of hand embodiment has to date been limited byinaccessibility of customizable hands in the real-world, and by the reality gapin simulation of complex interactions. We introduce an open parametric designwhich integrates techniques for simplified customization, fabrication, andcontrol with design features to maximize behavioral diversity. Non-linearrolling joints, anatomical tendon routing, and a low degree-of-freedom,modulating, actuation system, enable rapid production of single-piece 3Dprintable hands without compromising dexterous behaviors. To demonstrate this,we evaluated the design's low-level behavior range and stability, showingvariable stiffness over two orders of magnitude. Additionally, we fabricatedthree hand designs: human, mirrored human with two thumbs, and aye-aye hands.Manipulation tests evaluate the variation in each hand's proficiency athandling diverse objects, and demonstrate emergent behaviors unique to eachdesign. Overall, we shed light on new possible designs for robotic hands,provide a design space to compare and contrast different hand morphologies andstructures, and share a practical and open-source design for exploring embodiedmanipulation.</description>
      <author>example@mail.com (Kieran Gilday, Chapa Sirithunge, Fumiya Iida, Josie Hughes)</author>
      <guid isPermaLink="false">2410.18633v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>YOLO-TS: Real-Time Traffic Sign Detection with Enhanced Accuracy Using Optimized Receptive Fields and Anchor-Free Fusion</title>
      <link>http://arxiv.org/abs/2410.17144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 9 figures and 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;确保自动驾驶和高级驾驶辅助系统的安全性依赖于高效的交通标志识别技术。&lt;h4&gt;目的&lt;/h4&gt;解决当前方法在速度和准确性之间的妥协问题。&lt;h4&gt;方法&lt;/h4&gt;提出一种新型实时高效的道路标志检测网络YOLO-TS，通过优化多尺度特征图的感受野与交通标志的大小分布相匹配，采用创新的特征融合策略，利用无锚点方法实现高分辨率特征图的多尺度物体检测。&lt;h4&gt;主要发现&lt;/h4&gt;YOLO-TS在准确性和速度上显著优于现有的最先进方法，特别是在处理小物体检测时，通过独特模块减轻了扩张卷积造成的网格效应。&lt;h4&gt;结论&lt;/h4&gt;在TT100K和CCTSDB2021等具有挑战性的公共数据集上的评估表明，YOLO-TS在准确性和速度上都超过了现有方法。&lt;h4&gt;代码&lt;/h4&gt;我们的方法的代码将会公开提供。&lt;h4&gt;总结&lt;/h4&gt;YOLO-TS通过优化特征图的感受野和引入新模块，显著提升了交通标志检测的效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring safety in both autonomous driving and advanced driver-assistancesystems (ADAS) depends critically on the efficient deployment of traffic signrecognition technology. While current methods show effectiveness, they oftencompromise between speed and accuracy. To address this issue, we present anovel real-time and efficient road sign detection network, YOLO-TS. Thisnetwork significantly improves performance by optimizing the receptive fieldsof multi-scale feature maps to align more closely with the size distribution oftraffic signs in various datasets. Moreover, our innovative feature-fusionstrategy, leveraging the flexibility of Anchor-Free methods, allows formulti-scale object detection on a high-resolution feature map abundant incontextual information, achieving remarkable enhancements in both accuracy andspeed. To mitigate the adverse effects of the grid pattern caused by dilatedconvolutions on the detection of smaller objects, we have devised a uniquemodule that not only mitigates this grid effect but also widens the receptivefield to encompass an extensive range of spatial contextual information, thusboosting the efficiency of information usage. Evaluation on challenging publicdatasets, TT100K and CCTSDB2021, demonstrates that YOLO-TS surpasses existingstate-of-the-art methods in terms of both accuracy and speed. The code for ourmethod will be available.</description>
      <author>example@mail.com (Junzhou Chen, Heqiang Huang, Ronghui Zhang, Nengchao Lyu, Yanyong Guo, Hong-Ning Dai, Hong Yan)</author>
      <guid isPermaLink="false">2410.17144v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Zeitenwenden: Detecting changes in the German political discourse</title>
      <link>http://arxiv.org/abs/2410.17960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;德国政治格局自1871年国家成立以来经历了君主制、民主制、独裁制，再回归民主制的不断变化。&lt;h4&gt;目的&lt;/h4&gt;分析德国联邦议院的会议记录，探讨哪些事件对政治话语产生了持久影响，以及政治主题如何随时间变化。&lt;h4&gt;方法&lt;/h4&gt;使用时间序列变体的主题模型LDA分析会议记录文本。&lt;h4&gt;主要发现&lt;/h4&gt;通过分析，可以检测到政治话语中词频的变化，从而识别关键讨论点。&lt;h4&gt;结论&lt;/h4&gt;时间序列分析揭示了政治主题的演变及其与重大事件的关系。&lt;h4&gt;总结&lt;/h4&gt;研究为理解德国政治话语的动态变化提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; From a monarchy to a democracy, to a dictatorship and back to a democracy --the German political landscape has been constantly changing ever since thefirst German national state was formed in 1871. After World War II, the FederalRepublic of Germany was formed in 1949. Since then every plenary session of theGerman Bundestag was logged and even has been digitized over the course of thelast few years. We analyze these texts using a time series variant of the topicmodel LDA to investigate which events had a lasting effect on the politicaldiscourse and how the political topics changed over time. This allows us todetect changes in word frequency (and thus key discussion points) in politicaldiscourse.</description>
      <author>example@mail.com (Kai-Robin Lange, Jonas Rieger, Niklas Benner, Carsten Jentsch)</author>
      <guid isPermaLink="false">2410.17960v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Remote Timing Attacks on Efficient Language Model Inference</title>
      <link>http://arxiv.org/abs/2410.17175v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;语言模型的规模扩大显著提高了其能力，但更大的模型运行速度更慢。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用语言模型生成过程中的时间差异进行时序攻击。&lt;h4&gt;方法&lt;/h4&gt;通过监控受害者用户与远程语言模型之间的加密网络流量，分析响应时间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;在开源系统中，可以以90%以上的精确度判断用户对话的主题；在生产系统如OpenAI的ChatGPT和Anthropic的Claude中，可以区分具体消息或推断用户的语言。&lt;h4&gt;结论&lt;/h4&gt;主动攻击者可以通过增强攻击恢复消息中的个人身份信息（PII），如电话号码或信用卡号码，并探讨潜在的防御措施和未来研究方向。&lt;h4&gt;总结&lt;/h4&gt;大型语言模型的效率提升带来了新的安全隐患，通过时序攻击可以泄露用户隐私，需关注防御策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scaling up language models has significantly increased their capabilities.But larger models are slower models, and so there is now an extensive body ofwork (e.g., speculative sampling or parallel decoding) that improves the(average case) efficiency of language model generation. But these techniquesintroduce data-dependent timing characteristics. We show it is possible toexploit these timing differences to mount a timing attack. By monitoring the(encrypted) network traffic between a victim user and a remote language model,we can learn information about the content of messages by noting when responsesare faster or slower. With complete black-box access, on open source systems weshow how it is possible to learn the topic of a user's conversation (e.g.,medical advice vs. coding assistance) with 90%+ precision, and on productionsystems like OpenAI's ChatGPT and Anthropic's Claude we can distinguish betweenspecific messages or infer the user's language. We further show that an activeadversary can leverage a boosting attack to recover PII placed in messages(e.g., phone numbers or credit card numbers) for open source systems. Weconclude with potential defenses and directions for future work.</description>
      <author>example@mail.com (Nicholas Carlini, Milad Nasr)</author>
      <guid isPermaLink="false">2410.17175v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Data Scaling Laws in Imitation Learning for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2410.18647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数据缩放在自然语言处理和计算机视觉等领域带来了显著的进展，提高了模型的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;研究机器人领域，特别是机器人操作中是否存在类似的数据缩放规律，以及适当的数据缩放是否能使机器人政策在零-shot情况下适用于同一类别的任何对象。&lt;h4&gt;方法&lt;/h4&gt;进行全面的实证研究，收集不同环境和对象的数据，研究政策的泛化性能如何随训练环境、对象和示范数量的变化而变化。&lt;h4&gt;主要发现&lt;/h4&gt;1) 政策的泛化性能与环境和对象数量呈现大致的幂律关系。2) 环境和对象的多样性比示范的绝对数量更为重要；当每个环境或对象的示范数量达到一定阈值后，额外的示范对效果的影响很小。&lt;h4&gt;结论&lt;/h4&gt;提出了一种高效的数据收集策略，通过四个数据收集器一个下午的工作，收集足够的数据使两项任务的政策在新环境中对未见对象的成功率接近90%。&lt;h4&gt;总结&lt;/h4&gt;数据缩放在机器人操作中具有重要意义，环境和对象的多样性是提高泛化性能的关键。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Data scaling has revolutionized fields like natural language processing andcomputer vision, providing models with remarkable generalization capabilities.In this paper, we investigate whether similar data scaling laws exist inrobotics, particularly in robotic manipulation, and whether appropriate datascaling can yield single-task robot policies that can be deployed zero-shot forany object within the same category in any environment. To this end, we conducta comprehensive empirical study on data scaling in imitation learning. Bycollecting data across numerous environments and objects, we study how apolicy's generalization performance changes with the number of trainingenvironments, objects, and demonstrations. Throughout our research, we collectover 40,000 demonstrations and execute more than 15,000 real-world robotrollouts under a rigorous evaluation protocol. Our findings reveal severalintriguing results: the generalization performance of the policy follows aroughly power-law relationship with the number of environments and objects. Thediversity of environments and objects is far more important than the absolutenumber of demonstrations; once the number of demonstrations per environment orobject reaches a certain threshold, additional demonstrations have minimaleffect. Based on these insights, we propose an efficient data collectionstrategy. With four data collectors working for one afternoon, we collectsufficient data to enable the policies for two tasks to achieve approximately90% success rates in novel environments with unseen objects.</description>
      <author>example@mail.com (Fanqi Lin, Yingdong Hu, Pingyue Sheng, Chuan Wen, Jiacheng You, Yang Gao)</author>
      <guid isPermaLink="false">2410.18647v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Experimental Designs for Optimizing Last-Mile Delivery</title>
      <link>http://arxiv.org/abs/2410.17392v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 Pages, 2 Figures with 4 subfigure panels each, To be submitted to
  Quality Engineering&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;亚马逊和UPS等公司在最后一公里配送问题上投入巨大。&lt;h4&gt;目的&lt;/h4&gt;优化最后一公里配送操作，以降低成本并带来更广泛的社会和环境效益。&lt;h4&gt;方法&lt;/h4&gt;将最后一公里配送问题建模为旅行推销员问题（TSP），采用贝叶斯D-optimal实验设计结合回归模型来估计未知的运输成本。&lt;h4&gt;主要发现&lt;/h4&gt;考虑了运输成本的随机性，提出的框架可有效寻找TSP的高效解决方案，并能扩展到无人机等新兴技术的应用。&lt;h4&gt;结论&lt;/h4&gt;创新的最后一公里配送方法能够改善配送服务并减少空气污染和温室气体排放。&lt;h4&gt;总结&lt;/h4&gt;通过优化最后一公里配送，企业可以实现成本节约，同时促进社会和环境的可持续发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Companies like Amazon and UPS are heavily invested in last-mile deliveryproblems. Optimizing last-delivery operations not only creates tremendous costsavings for these companies but also generate broader societal andenvironmental benefits in terms of better delivery service and reduced airpollutants and greenhouse gas emissions. Last-mile delivery is readilyformulated as the Travelling Salesman Problem (TSP), where a salesperson mustvisit several cities and return to the origin with the least cost. A solutionto this problem is a Hamiltonian circuit in an undirected graph. Many methodsexist for solving the TSP, but they often assume the travel costs are fixed. Inpractice, travel costs between delivery zones are random quantities, as theyare subject to variation from traffic, weather, and other factors. Innovationssuch as truck-drone last-mile delivery creates even more uncertainties due toscarce data. A Bayesian D-optimal experimental design in conjunction with aregression model are proposed to estimate these unknown travel costs, andsubsequently search for a highly efficient solution to the TSP. This frameworkcan naturally be extended to incorporate the use of drones and any otheremerging technology that has use in last-mile delivery.</description>
      <author>example@mail.com (Nicholas Rios, Jie Xu)</author>
      <guid isPermaLink="false">2410.17392v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Real time anomalies detection on video</title>
      <link>http://arxiv.org/abs/2410.18051v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多地方使用监控摄像头，但在事件发生时，这些技术主要用于回放过去的事件。&lt;h4&gt;目的&lt;/h4&gt;提出一种深度学习方法，解决监控摄像头作为威慑工具而非检测工具的问题。&lt;h4&gt;方法&lt;/h4&gt;使用卷积神经网络（CNN）提取视频图像的相关特征，这些特征将形成时间序列，随后由LSTM/GRU模型进行分析。&lt;h4&gt;主要发现&lt;/h4&gt;利用深度学习模型可以更有效地分析监控视频，提高事件检测能力。&lt;h4&gt;结论&lt;/h4&gt;深度学习方法有潜力改善监控技术的功能，使其不仅限于事后回顾。&lt;h4&gt;总结&lt;/h4&gt;本文提出的深度学习框架可以为安全监控领域带来新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nowadays, many places use security cameras. Unfortunately, when an incidentoccurs, these technologies are used to show past events. So it can beconsidered as a deterrence tool than a detection tool. In this article, we willpropose a deep learning approach trying to solve this problematic. Thisapproach uses convolutional models (CNN) to extract relevant characteristicslinked to the video images, theses characteristics will form times series to beanalyzed by LSTM / GRU models.</description>
      <author>example@mail.com (Fabien Poirier)</author>
      <guid isPermaLink="false">2410.18051v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Learning dissipative Hamiltonian dynamics with reproducing kernel Hilbert spaces and random Fourier features</title>
      <link>http://arxiv.org/abs/2410.18656v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文提出了一种从有限且噪声数据集中学习耗散哈密顿动力学的新方法。&lt;h4&gt;目的&lt;/h4&gt;旨在提高对耗散哈密顿系统的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法使用Helmholtz分解，将向量场学习为辛向量场和耗散向量场的和。两个向量场通过定义为辛和无旋核的再生核希尔伯特空间进行学习，核被特殊化以强制奇对称性。使用随机傅里叶特征来近似这些核，以降低优化问题的维度。&lt;h4&gt;主要发现&lt;/h4&gt;在两个耗散哈密顿系统的仿真中验证了该方法的性能，结果显示与使用高斯可分核的方法相比，该方法显著提高了预测准确性。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在处理有限且噪声数据时，能够有效学习耗散哈密顿动力学，并显著改善预测效果。&lt;h4&gt;总结&lt;/h4&gt;该研究为学习耗散哈密顿动力学提供了一种新颖且有效的方法，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a new method for learning dissipative Hamiltoniandynamics from a limited and noisy dataset. The method uses the Helmholtzdecomposition to learn a vector field as the sum of a symplectic and adissipative vector field. The two vector fields are learned using tworeproducing kernel Hilbert spaces, defined by a symplectic and a curl-freekernel, where the kernels are specialized to enforce odd symmetry. RandomFourier features are used to approximate the kernels to reduce the dimension ofthe optimization problem. The performance of the method is validated insimulations for two dissipative Hamiltonian systems, and it is shown that themethod improves predictive accuracy significantly compared to a method where aGaussian separable kernel is used.</description>
      <author>example@mail.com (Torbjørn Smith, Olav Egeland)</author>
      <guid isPermaLink="false">2410.18656v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>How host mobility patterns shape antigenic escape during viral-immune co-evolution</title>
      <link>http://arxiv.org/abs/2410.17418v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;流感等病毒与宿主免疫系统长期共同进化，逐渐影响这些病原体的演化轨迹。&lt;h4&gt;目的&lt;/h4&gt;研究抗原逃逸与迁移如何影响新兴病毒的生存和传播。&lt;h4&gt;方法&lt;/h4&gt;将抗原逃逸和宿主迁移视为同等重要的过程，进行分析。&lt;h4&gt;主要发现&lt;/h4&gt;在短时间尺度上，适中的宿主迁移率通过抗原逃逸提高病毒的生存概率；而更强连接的迁移网络则降低病毒的生存概率。&lt;h4&gt;结论&lt;/h4&gt;当前的人类迁移率有利于病毒的生存，尤其是基于高流量机场的数据支持这一观点。&lt;h4&gt;总结&lt;/h4&gt;病毒与宿主免疫系统的相互作用及人类迁移对病毒生存的影响是理解病毒传播的重要因素。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Viruses like influenza have long coevolved with host immune systems,gradually shaping the evolutionary trajectory of these pathogens. Host immunesystems develop immunity against circulating strains, which in turn avoidextinction by exploiting antigenic escape mutations that render new strainsimmune from existing antibodies in the host population. Infected hosts are alsomobile, which can spread the virus to regions without developed host immunity,offering additional reservoirs for viral growth. While the effects of migrationon long term stability have been investigated, we know little about howantigenic escape coupled with migration changes the survival and spread ofemerging viruses. By considering the two processes on equal footing, we showthat on short timescales an intermediate host mobility rate increases thesurvival probability of the virus through antigenic escape. We show that morestrongly connected migratory networks decrease the survival probability of thevirus. Using data from high traffic airports we argue that current humanmigration rates are beneficial for viral survival.</description>
      <author>example@mail.com (Natalie Blot, Caelan Brooks, Daniel W. Swartz, Eslam Abdelaleem, Martin Garic, Andrea Iglesias-Ramas, Michael Pasek, Thierry Mora, Aleksandra M. Walczak)</author>
      <guid isPermaLink="false">2410.17418v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Learning for Time Series: A Review &amp; Critique of FITS</title>
      <link>http://arxiv.org/abs/2410.18318v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv:2307.03756v3 45 pages, 36 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;准确的时间序列预测在多个行业中具有重要价值。&lt;h4&gt;目的&lt;/h4&gt;探讨FITS模型在时间序列预测中的表现及其与其他模型的比较。&lt;h4&gt;方法&lt;/h4&gt;通过在复杂频域中训练单层神经网络，复制FITS模型的结果，并结合DLinear提出两种新的混合方法。&lt;h4&gt;主要发现&lt;/h4&gt;FITS在捕捉周期性和季节性模式方面表现出色，但在处理趋势性、非周期性或随机行为时存在困难。&lt;h4&gt;结论&lt;/h4&gt;通过结合FITS与DLinear，我们在多元回归中取得最佳结果，并在价格数据集的多重/线性回归中表现出良好效果，显著超过FITS的单独表现。&lt;h4&gt;总结&lt;/h4&gt;FITS模型在某些方面具有优势，但结合其他方法能够进一步提升预测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate time series forecasting is a highly valuable endeavour withapplications across many industries. Despite recent deep learning advancements,increased model complexity, and larger model sizes, many state-of-the-artmodels often perform worse or on par with simpler models. One of those cases isa recently proposed model, FITS, claiming competitive performance withsignificantly reduced parameter counts. By training a one-layer neural networkin the complex frequency domain, we are able to replicate these results. Ourexperiments on a wide range of real-world datasets further reveal that FITSespecially excels at capturing periodic and seasonal patterns, but struggleswith trending, non-periodic, or random-resembling behavior. With our two novelhybrid approaches, where we attempt to remedy the weaknesses of FITS bycombining it with DLinear, we achieve the best results of any known open-sourcemodel on multivariate regression and promising results in multiple/linearregression on price datasets, on top of vastly improving upon what FITSachieves as a standalone model.</description>
      <author>example@mail.com (Andreas Løvendahl Eefsen, Nicholas Erup Larsen, Oliver Glozmann Bork Hansen, Thor Højhus Avenstrup)</author>
      <guid isPermaLink="false">2410.18318v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Rigid Single-Slice-in-Volume registration via rotation-equivariant 2D/3D feature matching</title>
      <link>http://arxiv.org/abs/2410.18683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;2D到3D配准在诊断、手术导航、环境理解、机器人导航、自动化系统和增强现实等任务中至关重要。&lt;h4&gt;目的&lt;/h4&gt;将2D图像放置在3D体积观察中，特别是在医学成像中。&lt;h4&gt;方法&lt;/h4&gt;提出一种自监督的2D/3D配准方法，将单个2D切片与相应的3D体积匹配，使用群体等变卷积神经网络提取旋转等变特征。&lt;h4&gt;主要发现&lt;/h4&gt;在NSCLC-Radiomics CT和KIRBY21 MRI数据集上，所提出的方法在切片-体积配准中表现出强大的鲁棒性，绝对中位角误差小于2度，匹配特征的平均准确率为89%，容忍度为3像素。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地解决了没有解剖先验的情况下2D和3D之间的维度差异问题。&lt;h4&gt;总结&lt;/h4&gt;自监督的2D/3D配准方法在医学影像中显示出良好的应用潜力，尤其在处理肿瘤图像时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-73480-9_22&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 2D to 3D registration is essential in tasks such as diagnosis, surgicalnavigation, environmental understanding, navigation in robotics, autonomoussystems, or augmented reality. In medical imaging, the aim is often to place a2D image in a 3D volumetric observation to w. Current approaches for rigidsingle slice in volume registration are limited by requirements such as poseinitialization, stacks of adjacent slices, or reliable anatomical landmarks.Here, we propose a self-supervised 2D/3D registration approach to match asingle 2D slice to the corresponding 3D volume. The method works in datawithout anatomical priors such as images of tumors. It addresses thedimensionality disparity and establishes correspondences between 2D in-planeand 3D out-of-plane rotation-equivariant features by using group equivariantCNNs. These rotation-equivariant features are extracted from the 2D query sliceand aligned with their 3D counterparts. Results demonstrate the robustness ofthe proposed slice-in-volume registration on the NSCLC-Radiomics CT and KIRBY21MRI datasets, attaining an absolute median angle error of less than 2 degreesand a mean-matching feature accuracy of 89% at a tolerance of 3 pixels.</description>
      <author>example@mail.com (Stefan Brandstätter, Philipp Seeböck, Christoph Fürböck, Svitlana Pochepnia, Helmut Prosch, Georg Langs)</author>
      <guid isPermaLink="false">2410.18683v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Joint Modeling of Quasar Variability and Accretion Disk Reprocessing using Latent Stochastic Differential Equation</title>
      <link>http://arxiv.org/abs/2410.18423v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages, 19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;类星体是由超大质量黑洞周围物质吸积驱动的明亮活跃星系核，其亮度变化依赖于吸积盘和黑洞的物理特性。&lt;h4&gt;目的&lt;/h4&gt;利用即将进行的鲁宾天文台时间和空间遗产调查（LSST）观察数千万个类星体，需要高效的数据处理技术，如机器学习。&lt;h4&gt;方法&lt;/h4&gt;首次引入了吸积盘和重处理的自动微分模拟，将其作为神经网络的直接组成部分，以联合建模驱动变异性和重处理，拟合LSST 10年类星体光曲线。&lt;h4&gt;主要发现&lt;/h4&gt;使用潜在随机微分方程重建驱动变异性，这是一种物理驱动的生成深度学习方法，可建模连续时间的随机动态。&lt;h4&gt;结论&lt;/h4&gt;通过将这些物理过程嵌入网络中，我们实现了一个更稳健且可解释的模型，并使用变换器将模型扩展到数千万个参数。&lt;h4&gt;总结&lt;/h4&gt;该方法优于高斯过程回归基线，能够推断吸积盘参数和波段之间的时间延迟，适用于不规则取样的多元时间序列的其他逆问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quasars are bright active galactic nuclei powered by the accretion of matteraround supermassive black holes at the center of galaxies. Their stochasticbrightness variability depends on the physical properties of the accretion diskand black hole. The upcoming Rubin Observatory Legacy Survey of Space and Time(LSST) is expected to observe tens of millions of quasars, so there is a needfor efficient techniques like machine learning that can handle the large volumeof data. Quasar variability is believed to be driven by an X-ray corona, whichis reprocessed by the accretion disk and emitted as UV/optical variability. Weare the first to introduce an auto-differentiable simulation of the accretiondisk and reprocessing. We use the simulation as a direct component of ourneural network to jointly model the driving variability and reprocessing to fitsimulated LSST 10-year quasar light curves. The driving variability isreconstructed using a latent stochastic differential equation, a physicallymotivated, generative deep learning method that can model continuous-timestochastic dynamics. By embedding these physical processes into our network, weachieve a model that is more robust and interpretable. We also use transformersto scale our model to tens of millions of parameters. We demonstrate how ourmodel outperforms a Gaussian process regression baseline and can inferaccretion disk parameters and time delays between wavebands, even forout-of-distribution driving signals. Our approach provides a powerful andscalable framework that can be adapted to solve other inverse problems inmultivariate time series with irregular sampling.</description>
      <author>example@mail.com (Joshua Fagin, James Hung-Hsu Chan, Henry Best, Matthew O'Dowd)</author>
      <guid isPermaLink="false">2410.18423v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Nonequilibrium Force-Flow Relations in Networks</title>
      <link>http://arxiv.org/abs/2410.17495v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究非平衡网络力和流动的理论。&lt;h4&gt;目的&lt;/h4&gt;建立一种全面的非平衡网络力流动理论，称为能力力理论（CFT）。&lt;h4&gt;方法&lt;/h4&gt;遵循平衡热力学的“两条法则”结构，构建一个关于系统状态的预测工具。&lt;h4&gt;主要发现&lt;/h4&gt;['CFT定义了三种独立的动态量的力：节点分布、边缘流量和循环通量。', 'CFT不局限于近似或假设，适用于远离平衡的情况。', '发现基尔霍夫电流和电压定律是不完整的，存在第三个定律适用于重要波动的情况。']&lt;h4&gt;结论&lt;/h4&gt;CFT提供了一种处理复杂网络中相互矛盾约束的有效工具。&lt;h4&gt;总结&lt;/h4&gt;该理论为非平衡系统的研究提供了新的视角和预测能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this and a companion paper [arXiv:2410.09277], we give a general andcomprehensive theory for nonequilibrium (NEQ) network forces and flows (CaliberForce Theory, CFT). It follows the "Two Laws" structure of EquilibriumThermodynamics, where a First Law asserts conservation constraints and a SecondLaw is a variational predictor of a system's status, that, when taken together,give a rich set of prediction tools. The novel results for network flows hereare that: (1) CFT defines forces, in this case for the three independentdynamic quantities: node distribution, edge traffic, and cycle flux, allowingfor treating complex nets with conflicting constraints, actions, costs andbenefits. (2) CFT is not limited to approximations and assumptions aboutnearness to equilibria, Local Detailed Balance or heat baths. (3) CFT showsthat Kirchhoff current and voltage laws are an incomplete set; we find that athird such law applies when fluctuations are important.</description>
      <author>example@mail.com (Ying-Jen Yang, Ken A. Dill)</author>
      <guid isPermaLink="false">2410.17495v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Breaking Down the Barriers: Investigating Non-Expert User Experiences in Robotic Teleoperation in UK and Japan</title>
      <link>http://arxiv.org/abs/2410.18727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;每年都有机器人被创造出来，旨在融入我们的日常生活，因此对人类对机器人的信任进行评估的研究引起了关注。&lt;h4&gt;目的&lt;/h4&gt;创建TELESIM，一个模块化即插即用的框架，以减少非专家用户操作机器人手臂时的压力，并评估用户对机器人的信任。&lt;h4&gt;方法&lt;/h4&gt;进行了一项在英国的用户调查，参与者为37人，并在日本进行了一项类似条件的用户调查，通过VR控制器与UR5e机器人接口以验证之前方法的局限性。&lt;h4&gt;主要发现&lt;/h4&gt;UR5e机器人的构建塔数量较多，且其认知压力最低；而Senseglove与UR3的组合则导致用户身体负担最大并引发更多挫败感。&lt;h4&gt;结论&lt;/h4&gt;日本用户似乎对机器人表现出比英国用户更高的信任。&lt;h4&gt;总结&lt;/h4&gt;通过用户调查，我们验证了TELESIM框架的有效性，并揭示了不同机器人配置对用户信任和压力的影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robots are being created each year with the goal of integrating them into ourdaily lives. As such, there is an interest in research in evaluating the trustof humans toward robots. In addition, teleoperating robotic arms can bechallenging for non-experts. In order to reduce the strain put on the user, wecreated TELESIM, a modular and plug-and-play framework that enables directteleoperation of any robotic arm using a digital twin as the interface betweenusers and the robotic system. However, analysis of the strain put on the userand its ability to trust robots was omitted. This paper addresses theseomissions by presenting the additional results of our user survey of 37participants carried out in UK. In addition, we present the results of anadditional user survey, under similar conditions performed in Japan, with thegoal of addressing the limitations of our previous approach, by interfacing aVR controller with a UR5e. Our experimental results show that the UR5e has ahigher number of towers built. Additionally, the UR5e gives the least amount ofcognitive stress, while the combination of Senseglove and UR3 gives the userthe highest physical strain and causes the user to feel more frustrated.Finally, Japanese seems more trusting towards robots than British.</description>
      <author>example@mail.com (Florent P Audonnet, Andrew Hamilton, Yakiyasu Domae, Ixchel G Ramirez-Alpizar, Gerardo Aragon-Camarasa)</author>
      <guid isPermaLink="false">2410.18727v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Forecasting Australian fertility by age, region, and birthplace</title>
      <link>http://arxiv.org/abs/2410.18435v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  34 pages, 6 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;澳大利亚女性的生育差异受城市与乡村居住及出生地影响，显著影响子国家层面的人口组成。&lt;h4&gt;目的&lt;/h4&gt;提供关于澳大利亚女性的生育率预测，按照年龄、地区和出生地进行分类。&lt;h4&gt;方法&lt;/h4&gt;使用1981-2011年间的普查数据，通过分组功能时间序列方法对国家和子国家层面的年龄特定生育率进行联合建模和预测。&lt;h4&gt;主要发现&lt;/h4&gt;各地区和出生地的生育率预测结果经过选择的层级进行协调，确保不同分解水平的结果与国家总数一致。&lt;h4&gt;结论&lt;/h4&gt;结合居住地区的分解结构与追踪最小化协调方法，得出最准确的点和区间预测，且根据女性出生地分解的年龄特定生育率显示出显著的异质性，支持分组预测方法的应用。&lt;h4&gt;总结&lt;/h4&gt;本研究通过综合分析不同地区和出生地女性的生育率，提供了更为精确的生育预测，为政策制定提供了数据支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fertility differentials by urban-rural residence and nativity of women inAustralia significantly impact population composition at sub-national levels.We aim to provide consistent fertility forecasts for Australian womencharacterized by age, region, and birthplace. Age-specific fertility rates atthe national and sub-national levels obtained from census data between1981-2011 are jointly modeled and forecast by the grouped functional timeseries method. Forecasts for women of each region and birthplace are reconciledfollowing the chosen hierarchies to ensure that results at variousdisaggregation levels consistently sum up to the respective national total.Coupling the region of residence disaggregation structure with the traceminimization reconciliation method produces the most accurate point andinterval forecasts. In addition, age-specific fertility rates disaggregated bythe birthplace of women show significant heterogeneity that supports theapplication of the grouped forecasting method.</description>
      <author>example@mail.com (Yang Yang, Han Lin Shang, James Raymer)</author>
      <guid isPermaLink="false">2410.18435v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Real-time Vehicle-to-Vehicle Communication Based Network Cooperative Control System through Distributed Database and Multimodal Perception: Demonstrated in Crossroads</title>
      <link>http://arxiv.org/abs/2410.17576v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICICT 2024, 18 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动驾驶行业迅速发展，车与车(V2V)通信系统成为提高道路安全和交通效率的关键组成部分。&lt;h4&gt;目的&lt;/h4&gt;介绍一种新型的基于实时车与车通信的网络协同控制系统(VVCCS)，旨在革新宏观交通规划和碰撞避免。&lt;h4&gt;方法&lt;/h4&gt;在Quanser Car (Qcar)硬件平台上实施系统，将分布式数据库集成到各个自动驾驶车辆中，并提供可选的中央服务器。&lt;h4&gt;主要发现&lt;/h4&gt;开发了一套全面的多模态感知系统，具备多目标跟踪和雷达感应能力，并在物理交叉路口环境中进行了演示。&lt;h4&gt;结论&lt;/h4&gt;该系统展示了在拥堵和复杂城市环境中应用的潜力。&lt;h4&gt;总结&lt;/h4&gt;VVCCS系统通过V2V通信提升了自动驾驶的安全性和效率，具有广泛的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The autonomous driving industry is rapidly advancing, with Vehicle-to-Vehicle(V2V) communication systems highlighting as a key component of enhanced roadsafety and traffic efficiency. This paper introduces a novel Real-timeVehicle-to-Vehicle Communication Based Network Cooperative Control System(VVCCS), designed to revolutionize macro-scope traffic planning and collisionavoidance in autonomous driving. Implemented on Quanser Car (Qcar) hardwareplatform, our system integrates the distributed databases into individualautonomous vehicles and an optional central server. We also developed acomprehensive multi-modal perception system with multi-objective tracking andradar sensing. Through a demonstration within a physical crossroad environment,our system showcases its potential to be applied in congested and complex urbanenvironments.</description>
      <author>example@mail.com (Xinwen Zhu, Zihao Li, Yuxuan Jiang, Jiazhen Xu, Jie Wang, Xuyang Bai)</author>
      <guid isPermaLink="false">2410.17576v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Online path planning for kinematic-constrained UAVs in a dynamic environment based on a Differential Evolution algorithm</title>
      <link>http://arxiv.org/abs/2410.18777v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the 40th Anniversary of the IEEE Conference on Robotics
  and Automation (ICRA@40)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究无人机（UAV）在动态障碍物环境中的路径规划。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理动态障碍物和无人机运动约束的在线路径规划器。&lt;h4&gt;方法&lt;/h4&gt;使用NURBS路径表示和差分进化算法，并结合速度障碍方法的概念作为约束函数。&lt;h4&gt;主要发现&lt;/h4&gt;初步结果表明该方法是可行的。&lt;h4&gt;结论&lt;/h4&gt;为未来在三维（3D）环境中的扩展奠定了基础。&lt;h4&gt;总结&lt;/h4&gt;该研究为无人机的动态路径规划提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research presents an online path planner for Unmanned Aerial Vehicles(UAVs) that can handle dynamic obstacles and UAV motion constraints, includingmaximum curvature and desired orientations. Our proposed planner uses a NURBSpath representation and a Differential Evolution algorithm, incorporatingconcepts from the Velocity Obstacle approach in a constraint function. Initialresults show that our approach is feasible and provides a foundation for futureextensions to three-dimensional (3D) environments.</description>
      <author>example@mail.com (Elias J. R. Freitas, Miri Weiss Cohen, Frederico G. Guimarães, Luciano C. A. Pimenta)</author>
      <guid isPermaLink="false">2410.18777v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Observer-Based Event-Triggered Secure Consensus Control for Multi-Agent Systems</title>
      <link>http://arxiv.org/abs/2410.18440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究探讨多智能体系统（MAS）在面对欺骗攻击和随机切换拓扑的环境中所遇到的复杂挑战，特别是在事件触发的安全共识控制背景下。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的基于观察者的分布式事件触发控制方案，以解决上述复杂性。&lt;h4&gt;方法&lt;/h4&gt;该方案利用局部信息动态调整触发条件，从而提高网络资源的利用率，并设计了分布式的观察者基础安全共识控制器。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的事件触发机制理论上避免了触发时间序列中出现Zeno行为，并通过仿真实验验证了该方法的优越性。&lt;h4&gt;结论&lt;/h4&gt;与现有技术相比，所提方法在多智能体系统的事件触发安全共识控制中显示出有效性和适用性。&lt;h4&gt;总结&lt;/h4&gt;本研究为多智能体系统在复杂环境中的安全共识控制提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study delves into the intricate challenges encountered by multi-agentsystems (MASs) operating within environments that are subject to deceptionattacks and Markovian randomly switching topologies, particularly in thecontext of event-triggered secure consensus control. To address thesecomplexities, a novel observer-based distributed event-triggered control schemeis introduced. This approach uses local information to dynamically adjust itstriggered conditions, thereby enhancing the utilization of network resources.Additionally, the design of the observer based secure consensus controller isdistributed, leveraging the local information of each individual agent.Furthermore, our event-triggered mechanism theoretically precludes theoccurrence of Zeno behavior in the triggering time series. Finally, simulationresults underscore the superiority of our proposed method when compared toexisting techniques, thereby validating its effectiveness and applicability inthe event-triggered secure consensus control of MASs.</description>
      <author>example@mail.com (Jingyao Wang, Zeqin Zeng, Jinghua Guo, Zhisheng Duan)</author>
      <guid isPermaLink="false">2410.18440v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Arcus: SLO Management for Accelerators in the Cloud with Traffic Shaping</title>
      <link>http://arxiv.org/abs/2410.17577v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;云服务器使用加速器来提高CPU/GPU效率和整体性能，但用户的服务水平目标（SLO）可能因加速器相关的争用而受到影响。&lt;h4&gt;目的&lt;/h4&gt;重新思考在加速器丰富系统中满足服务水平目标的策略。&lt;h4&gt;方法&lt;/h4&gt;将加速器SLO管理视为流量管理，采用主动流量整形的方法，并开发了一个SLO感知协议与支持精确和可扩展流量整形的架构相结合。&lt;h4&gt;主要发现&lt;/h4&gt;在各种情况下，保证加速器的SLO，实现了高达45%的尾延迟减少和低于1%的吞吐量方差。&lt;h4&gt;结论&lt;/h4&gt;现有解决方案忽视了通信相关资源的争用，提出的新方法能够有效管理加速器的服务水平目标，解决了通信引起的多种挑战。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了在加速器系统中考虑流量管理的重要性，以确保用户的服务水平目标得到满足。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cloud servers use accelerators for common tasks (e.g., encryption,compression, hashing) to improve CPU/GPU efficiency and overall performance.However, users' Service-level Objectives (SLOs) can be violated due toaccelerator-related contention. The root cause is that existing solutions foraccelerators only focus on isolation or fair allocation of compute and memoryresources; they overlook the contention for communication-related resources.Specifically, three communication-induced challenges drive us to re-think theproblem: (1) Accelerator traffic patterns are diverse, hard to predict, andmixed across users, (2) communication-related components lack effectivelow-level isolation mechanism to configure, and (3) computational heterogeneityof accelerators lead to unique relationships between the traffic mixture andthe corresponding accelerator performance. The focus of this work is meetingSLOs in accelerator-rich systems. We present \design{}, treating acceleratorSLO management as traffic management with proactive traffic shaping. We developan SLO-aware protocol coupled with an offloaded interface on an architecturethat supports precise and scalable traffic shaping. We guarantee acceleratorSLO for various circumstances, with up to 45% tail latency reduction and lessthan 1% throughput variance.</description>
      <author>example@mail.com (Jiechen Zhao, Ran Shu, Katie Lim, Zewen Fan, Thomas Anderson, Mingyu Gao, Natalie Enright Jerger)</author>
      <guid isPermaLink="false">2410.17577v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>LiteVLoc: Map-Lite Visual Localization for Image Goal Navigation</title>
      <link>http://arxiv.org/abs/2410.04419v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种名为LiteVLoc的层次视觉定位框架，使用轻量级的拓扑-度量地图来表示环境。&lt;h4&gt;目的&lt;/h4&gt;旨在以粗到细的方式估计相机姿态，减小存储开销。&lt;h4&gt;方法&lt;/h4&gt;该方法由三个顺序模块组成，利用基于学习的特征匹配和几何解算器进行度量姿态估计。&lt;h4&gt;主要发现&lt;/h4&gt;引入了一种新的无地图重定位任务的数据集，系统在模拟和真实场景中的定位和导航实验验证了性能。&lt;h4&gt;结论&lt;/h4&gt;LiteVLoc在大规模部署中显示出精确性和效率，代码和数据将公开发布。&lt;h4&gt;总结&lt;/h4&gt;LiteVLoc通过轻量化设计在视觉定位中实现了高效和准确的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-06&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents LiteVLoc, a hierarchical visual localization frameworkthat uses a lightweight topo-metric map to represent the environment. Themethod consists of three sequential modules that estimate camera poses in acoarse-to-fine manner. Unlike mainstream approaches relying on detailed 3Drepresentations, LiteVLoc reduces storage overhead by leveraging learning-basedfeature matching and geometric solvers for metric pose estimation. A noveldataset for the map-free relocalization task is also introduced. Extensiveexperiments including localization and navigation in both simulated andreal-world scenarios have validate the system's performance and demonstratedits precision and efficiency for large-scale deployment. Code and data will bemade publicly available.</description>
      <author>example@mail.com (Jianhao Jiao, Jinhao He, Changkun Liu, Sebastian Aegidius, Xiangcheng Hu, Tristan Braud, Dimitrios Kanoulas)</author>
      <guid isPermaLink="false">2410.04419v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Inferring Latent Graphs from Stationary Signals Using a Graphical Autoregressive Model</title>
      <link>http://arxiv.org/abs/2410.18445v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图是一种直观的方式，用于表示金融和神经科学等领域中变量之间的关系，但这些图通常需要从数据中推断得出。&lt;h4&gt;目的&lt;/h4&gt;提出一个新框架，通过将观察到的多维数据视为图参考的平稳信号，推断潜在图。&lt;h4&gt;方法&lt;/h4&gt;引入图自回归模型（GAR），将观察信号的逆协方差矩阵表示为潜在图的归一化图拉普拉斯的二阶多项式，扩展了时间序列分析中的自回归模型至一般无向图。&lt;h4&gt;主要发现&lt;/h4&gt;GAR模型在拟合观察数据时优于高斯图模型，尤其在对S&amp;P 500股票价格数据的应用中表现突出。&lt;h4&gt;结论&lt;/h4&gt;GAR模型为推断潜在图提供了一个有前景的新方向，适用于多种应用。&lt;h4&gt;总结&lt;/h4&gt;通过理论分析和数值实验，开发了一种基于惩罚最大似然的三步估计程序，支持模型的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are an intuitive way to represent relationships between variables infields such as finance and neuroscience. However, these graphs often need to beinferred from data. In this paper, we propose a novel framework to infer alatent graph by treating the observed multidimensional data as graph-referencedstationary signals. Specifically, we introduce the graphical autoregressivemodel (GAR), where the inverse covariance matrix of the observed signals isexpressed as a second-order polynomial of the normalized graph Laplacian of thelatent graph. The GAR model extends the autoregressive model from time seriesanalysis to general undirected graphs, offering a new approach to graphinference. To estimate the latent graph, we develop a three-step procedurebased on penalized maximum likelihood, supported by theoretical analysis andnumerical experiments. Simulation studies and an application to S&amp;P 500 stockprice data show that the GAR model can outperform Gaussian graphical modelswhen it fits the observed data well. Our results suggest that the GAR modeloffers a promising new direction for inferring latent graphs across diverseapplications. Codes and example scripts are available athttps://github.com/jed-harwood/SGM .</description>
      <author>example@mail.com (Jedidiah Harwood, Debashis Paul, Jie Peng)</author>
      <guid isPermaLink="false">2410.18445v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Spatio-Temporal 3D Point Clouds from WiFi-CSI Data via Transformer Networks</title>
      <link>http://arxiv.org/abs/2410.16303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 5 figures, 1 table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联合通信与感知（JC&amp;S）正成为5G和6G网络中的关键组成部分，能够动态适应环境变化并增强上下文意识，以优化通信。&lt;h4&gt;目的&lt;/h4&gt;利用实时环境数据改善资源分配，降低延迟，提高能效，同时支持模拟和预测建模。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于变换器的架构，处理时间频道状态信息（CSI）数据，具体包括幅度和相位，用于生成室内环境的3D点云。&lt;h4&gt;主要发现&lt;/h4&gt;模型利用多头注意力机制捕捉CSI数据中的复杂时空关系，并适应不同的CSI配置。系统在MM-Fi数据集上进行评估，使用两种不同协议捕捉室内环境中的人类存在。&lt;h4&gt;结论&lt;/h4&gt;该系统在准确的3D重建方面表现出强大的潜力，能够有效区分近距离和远距离物体，推动JC&amp;S在未来无线网络中的空间感知应用。&lt;h4&gt;总结&lt;/h4&gt;JC&amp;S技术在智能城市、医疗保健和工业5.0等领域具有变革性潜力，能够实现环境事件的实时响应，提升实时决策能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Joint communication and sensing (JC\&amp;S) is emerging as a key component in 5Gand 6G networks, enabling dynamic adaptation to environmental changes andenhancing contextual awareness for optimized communication. By leveragingreal-time environmental data, JC\&amp;S improves resource allocation, reduceslatency, and enhances power efficiency, while also supporting simulations andpredictive modeling. This makes it a key technology for reactive systems anddigital twins. These systems can respond to environmental events in real-time,offering transformative potential in sectors like smart cities, healthcare, andIndustry 5.0, where adaptive and multimodal interaction is critical to enhancereal-time decision-making. In this work, we present a transformer-basedarchitecture that processes temporal Channel State Information (CSI) data,specifically amplitude and phase, to generate 3D point clouds of indoorenvironments. The model utilizes a multi-head attention to capture complexspatio-temporal relationships in CSI data and is adaptable to different CSIconfigurations. We evaluate the architecture on the MM-Fi dataset, using twodifferent protocols to capture human presence in indoor environments. Thesystem demonstrates strong potential for accurate 3D reconstructions andeffectively distinguishes between close and distant objects, advancing JC\&amp;Sapplications for spatial sensing in future wireless networks.</description>
      <author>example@mail.com (Tuomas Määttä, Sasan Sharifipour, Miguel Bordallo López, Constantino Álvarez Casado)</author>
      <guid isPermaLink="false">2410.16303v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>V2V Path Loss Modeling at 26 GHz Based on Real-Traffic Measurements</title>
      <link>http://arxiv.org/abs/2410.17618v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究单斜率路径损失模型及其在车辆通信中的阴影效应。&lt;h4&gt;目的&lt;/h4&gt;探讨不同条件下的路径损失模型。&lt;h4&gt;方法&lt;/h4&gt;基于在26.555 GHz频段进行的车辆间传输的广泛测量活动，主要在高速公路进行真实交通实验。&lt;h4&gt;主要发现&lt;/h4&gt;分析了天线特性（全向与定向）、环境（城市与乡村）及其在车辆上的安装位置（车顶、保险杠、车底）的影响。&lt;h4&gt;结论&lt;/h4&gt;讨论了信号导管效应及阻挡车辆数量的影响，以及去相关时间的相关性。&lt;h4&gt;总结&lt;/h4&gt;该研究为理解车辆通信中的路径损失提供了重要的数据支持和理论基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LWC.2024.3484312&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this letter, we investigate single-slope path loss models complementedwith shadowing effects in the context of vehicular communications. We presentseveral models obtained based on extensive measurement campaigns withinter-vehicle transmission conducted at 26.555 GHz in real-traffic experiments,mainly along high-speed roads. Particular attention has been put on the impactof aerial characteristics (omnidirectional versus directional), surroundingenvironment (e.g., urban versus rural), and their mounting point on cars (atthe rooftop, on the bumper, and below the car chassis). Finally, the effect ofsignal ducting and of the number of blocking cars has been analyzed and thedecorrelation time has been discussed</description>
      <author>example@mail.com (Pawel Kryszkiewicz, Adrian Kliks, Pawel Sroka, Michal Sybis)</author>
      <guid isPermaLink="false">2410.17618v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>A generic approach for reactive stateful mitigation of application failures in distributed robotics systems deployed with Kubernetes</title>
      <link>http://arxiv.org/abs/2410.18825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;将计算密集型算法卸载到边缘或云端可以解决机器人系统在计算和能量资源方面的限制。&lt;h4&gt;目的&lt;/h4&gt;确保云原生应用在Kubernetes中对各种类型故障的弹性。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的监控和状态反应故障缓解方法，适用于使用Kubernetes和ROS2部署的分布式机器人系统。&lt;h4&gt;主要发现&lt;/h4&gt;采用行为树的通用结构，我们的方法适用于任何机器人工作负载，并支持复杂的监控与故障缓解策略。&lt;h4&gt;结论&lt;/h4&gt;在自主移动机器人导航和机器人操作的模拟环境中验证了我们方法的有效性和应用无关性。&lt;h4&gt;总结&lt;/h4&gt;本文提出的监控和故障缓解方法为分布式机器人系统提供了新的解决方案，适应复杂的物理交互挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Offloading computationally expensive algorithms to the edge or even cloudoffers an attractive option to tackle limitations regarding on-boardcomputational and energy resources of robotic systems. In cloud-nativeapplications deployed with the container management system Kubernetes (K8s),one key problem is ensuring resilience against various types of failures.However, complex robotic systems interacting with the physical world pose avery specific set of challenges and requirements that are not yet covered byfailure mitigation approaches from the cloud-native domain. In this paper, wetherefore propose a novel approach for robotic system monitoring and stateful,reactive failure mitigation for distributed robotic systems deployed usingKubernetes (K8s) and the Robot Operating System (ROS2). By employing thegeneric substrate of Behaviour Trees, our approach can be applied to anyrobotic workload and supports arbitrarily complex monitoring and failuremitigation strategies. We demonstrate the effectiveness andapplication-agnosticism of our approach on two example applications, namelyAutonomous Mobile Robot (AMR) navigation and robotic manipulation in asimulated environment.</description>
      <author>example@mail.com (Florian Mirus, Frederik Pasch, Nikhil Singhal, Kay-Ulrich Scholl)</author>
      <guid isPermaLink="false">2410.18825v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Graph Attention Neural Network Performance for Marijuana Consumption Classification through Large-scale Augmented Granger Causality (lsAGC) Analysis of Functional MR Images</title>
      <link>http://arxiv.org/abs/2410.18506v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;使用静息态功能性磁共振成像（fMRI）研究大麻消费与大脑网络连接的变化。&lt;h4&gt;目的&lt;/h4&gt;探讨大规模增强Granger因果关系（lsAGC）在区分大麻用户与典型对照组中的有效性。&lt;h4&gt;方法&lt;/h4&gt;结合降维和源时间序列的增强，利用lsAGC模型预测时间序列，估计fMRI时间序列之间的定向因果关系。&lt;h4&gt;主要发现&lt;/h4&gt;使用lsAGC方法的平均准确率为61.47%，显著高于相关系数方法的52.98%。&lt;h4&gt;结论&lt;/h4&gt;lsAGC方法提升了基于神经成像分类的知识体系，强调在研究大麻对大脑影响时需考虑定向因果关系。&lt;h4&gt;总结&lt;/h4&gt;该研究为理解大麻消费对大脑网络的影响提供了新的视角和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the present research, the effectiveness of large-scale Augmented GrangerCausality (lsAGC) as a tool for gauging brain network connectivity was examinedto differentiate between marijuana users and typical controls by utilizingresting-state functional Magnetic Resonance Imaging (fMRI). The relationshipbetween marijuana consumption and alterations in brain network connectivity isa recognized fact in scientific literature. This study probes how lsAGC canaccurately discern these changes. The technique used integrates dimensionreduction with the augmentation of source time-series in a model that predictstime-series, which helps in estimating the directed causal relationships amongfMRI time-series. As a multivariate approach, lsAGC uncovers the connection ofthe inherent dynamic system while considering all other time-series. A datasetof 60 adults with an ADHD diagnosis during childhood, drawn from the AddictionConnectome Preprocessed Initiative (ACPI), was used in the study. The brainconnections assessed by lsAGC were utilized as classification attributes. AGraph Attention Neural Network (GAT) was chosen to carry out the classificationtask, particularly for its ability to harness graph-based data and recognizeintricate interactions between brain regions, making it appropriate forfMRI-based brain connectivity data. The performance was analyzed using afive-fold cross-validation system. The average accuracy achieved by thecorrelation coefficient method was roughly 52.98%, with a 1.65 standarddeviation, whereas the lsAGC approach yielded an average accuracy of 61.47%,with a standard deviation of 1.44. The suggested method enhances the body ofknowledge in the field of neuroimaging-based classification and emphasizes thenecessity to consider directed causal connections in brain network connectivityanalysis when studying marijuana's effects on the brain.</description>
      <author>example@mail.com (Ali Vosoughi, Akhil Kasturi, Axel Wismueller)</author>
      <guid isPermaLink="false">2410.18506v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Optimizing Parking Space Classification: Distilling Ensembles into Lightweight Classifiers</title>
      <link>http://arxiv.org/abs/2410.14705v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at the International Conference on Machine
  Learning and Applications (ICMLA) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在智能城市应用中，部署大规模机器学习模型时，数据通常需要发送到中央服务器进行分类，尤其在基于图像的停车场监控中。&lt;h4&gt;目的&lt;/h4&gt;解决图像应用需要传输大量数据所带来的基础设施挑战。&lt;h4&gt;方法&lt;/h4&gt;提出创建一个强大的分类器集合作为教师模型，并将其知识蒸馏到轻量化的学生模型上，这些学生模型可以直接部署在边缘设备上。&lt;h4&gt;主要发现&lt;/h4&gt;学生模型参数数量比教师模型少26倍，且在目标测试数据集上的平均准确率达到96.6%，超过了教师模型的95.3%。&lt;h4&gt;结论&lt;/h4&gt;通过蒸馏技术，学生模型在性能上优于教师模型，适合在边缘设备上部署。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种有效的方法来优化智能城市中基于图像的停车空间分类，提升了模型的效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-07&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When deploying large-scale machine learning models for smart cityapplications, such as image-based parking lot monitoring, data often must besent to a central server to perform classification tasks. This is challengingfor the city's infrastructure, where image-based applications requiretransmitting large volumes of data, necessitating complex network and hardwareinfrastructures to process the data. To address this issue in image-basedparking space classification, we propose creating a robust ensemble ofclassifiers to serve as Teacher models. These Teacher models are distilled intolightweight and specialized Student models that can be deployed directly onedge devices. The knowledge is distilled to the Student models throughpseudo-labeled samples generated by the Teacher model, which are utilized tofine-tune the Student models on the target scenario. Our results show that theStudent models, with 26 times fewer parameters than the Teacher models,achieved an average accuracy of 96.6% on the target test datasets, surpassingthe Teacher models, which attained an average accuracy of 95.3%.</description>
      <author>example@mail.com (Paulo Luza Alves, André Hochuli, Luiz Eduardo de Oliveira, Paulo Lisboa de Almeida)</author>
      <guid isPermaLink="false">2410.14705v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Digital Network Twins for Next-generation Wireless: Creation, Optimization, and Challenges</title>
      <link>http://arxiv.org/abs/2410.18002v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数字网络双胞胎（DNTs）通过使用虚拟模型代表物理网络，为下一代通信基础设施提供了显著的好处。&lt;h4&gt;目的&lt;/h4&gt;深入研究DNTs的全生命周期，特别关注创建、实时适应、资源高效部署和安全保护等方面。&lt;h4&gt;方法&lt;/h4&gt;探讨DNTs在网络和通信中的具体集成，涵盖基本设计、紧急应用和多个维度的关键挑战。&lt;h4&gt;主要发现&lt;/h4&gt;提供了两个详细案例研究，展示DNTs在实际场景中的应用，如无线流量预测和边缘缓存。&lt;h4&gt;结论&lt;/h4&gt;提出了前瞻性的研究机会，以应对DNTs的挑战，旨在充分发挥DNTs在下一代网络中的优势。&lt;h4&gt;总结&lt;/h4&gt;DNTs为网络发展带来新机遇，但仍需深入研究其生命周期的各个方面，以实现全面应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Digital network twins (DNTs), by representing a physical network using avirtual model, offer significant benefits such as streamlined networkdevelopment, enhanced productivity, and cost reduction for next-generation(nextG) communication infrastructure. Existing works mainly describe thedeployment of DNT technologies in various service sections.The full life cycleof DNTs for telecommunication has not yet been comprehensively studied,particularly in the aspects of fine-grained creation, real-time adaptation,resource-efficient deployment, and security protection. This article presentsan in-depth overview of DNTs, exploring their concrete integration intonetworks and communication, covering the fundamental designs, the emergentapplications, and critical challenges in multiple dimensions. We also includetwo detailed case studies to illustrate how DNTs can be applied in real-worldscenarios such as wireless traffic forecasting and edge caching. Additionally,a forward-looking vision of the research opportunities in tackling thechallenges of DNTs is provided, aiming to fully maximize the benefits of DNTsin nextG networks.</description>
      <author>example@mail.com (Yuchen Liu, Zhiyuan Peng, Zifan Zhang, Hanzhi Yu, Mingzhe Chen)</author>
      <guid isPermaLink="false">2410.18002v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>MazeNet: An Accurate, Fast, and Scalable Deep Learning Solution for Steiner Minimum Trees</title>
      <link>http://arxiv.org/abs/2410.18832v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 15 figures. Submitted to ICLR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;OARSMT问题寻求在避免障碍的情况下，在直线平面中连接给定数量的终端，是集成电路设计、网络优化和机器人路径规划中的关键任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的解决OARSMT问题的方法。&lt;h4&gt;方法&lt;/h4&gt;开发了MazeNet，一种基于深度学习的方法，将OARSMT重新框架为迷宫求解任务，使用递归卷积神经网络（RCNN）进行处理。&lt;h4&gt;主要发现&lt;/h4&gt;MazeNet在广泛的实验中实现了完美的OARSMT求解准确性，显著减少了运行时间，并且能够处理比现有近似算法更多的终端。&lt;h4&gt;结论&lt;/h4&gt;MazeNet的可扩展性使得仅需在小规模迷宫上训练RCNN模块，就能解决更大规模的迷宫问题。&lt;h4&gt;总结&lt;/h4&gt;MazeNet提供了一个高效且准确的解决OARSMT问题的新方法，突破了传统精确算法在大规模问题上的限制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Obstacle Avoiding Rectilinear Steiner Minimum Tree (OARSMT) problem,which seeks the shortest interconnection of a given number of terminals in arectilinear plane while avoiding obstacles, is a critical task in integratedcircuit design, network optimization, and robot path planning. Since OARSMT isNP-hard, exact algorithms scale poorly with the number of terminals, leadingpractical solvers to sacrifice accuracy for large problems. We propose MazeNet,a deep learning-based method that learns to solve the OARSMT from data. MazeNetreframes OARSMT as a maze-solving task that can be addressed with a recurrentconvolutional neural network (RCNN). A key hallmark of MazeNet is itsscalability: we only need to train the RCNN blocks on mazes with a small numberof terminals; larger mazes can be solved by replicating the same pre-trainedblocks to create a larger network. Across a wide range of experiments, MazeNetachieves perfect OARSMT-solving accuracy, significantly reduces runtimecompared to classical exact algorithms, and can handle more terminals thanstate-of-the-art approximate algorithms.</description>
      <author>example@mail.com (Gabriel Díaz Ramos, Toros Arikan, Richard G. Baraniuk)</author>
      <guid isPermaLink="false">2410.18832v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>TripCast: Pre-training of Masked 2D Transformers for Trip Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.18612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICONIP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习和预训练模型在时间序列预测中取得了显著成功，但旅游行业的时间序列数据常常表现出领先时间特性，形成二维结构，给预测带来了独特挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的建模范式TripCast，以处理旅游行业的时间序列数据。&lt;h4&gt;方法&lt;/h4&gt;将旅行时间序列视为二维数据，通过掩蔽和重构过程学习表示，并在大规模真实数据上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;TripCast在领域内预测场景中显著优于其他最先进的基线，并在领域外预测场景中展现出强大的可扩展性和迁移性。&lt;h4&gt;结论&lt;/h4&gt;TripCast为旅游行业的时间序列预测提供了一种有效的解决方案，能够应对独特的数据结构和挑战。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的TripCast模型在时间序列预测中展现出优越性能，尤其适用于旅游行业。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning and pre-trained models have shown great success in time seriesforecasting. However, in the tourism industry, time series data often exhibit aleading time property, presenting a 2D structure. This introduces uniquechallenges for forecasting in this sector. In this study, we propose a novelmodelling paradigm, TripCast, which treats trip time series as 2D data andlearns representations through masking and reconstruction processes.Pre-trained on large-scale real-world data, TripCast notably outperforms otherstate-of-the-art baselines in in-domain forecasting scenarios and demonstratesstrong scalability and transferability in out-domain forecasting scenarios.</description>
      <author>example@mail.com (Yuhua Liao, Zetian Wang, Peng Wei, Qiangqiang Nie, Zhenhua Zhang)</author>
      <guid isPermaLink="false">2410.18612v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>PyTSC: A Unified Platform for Multi-Agent Reinforcement Learning in Traffic Signal Control</title>
      <link>http://arxiv.org/abs/2410.18202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多智能体强化学习（MARL）为解决城市环境中的交通信号控制（TSC）复杂性提供了有前景的方法。&lt;h4&gt;目的&lt;/h4&gt;解决现有MARL基础的TSC研究平台面临的挑战，如模拟速度慢和代码维护困难。&lt;h4&gt;方法&lt;/h4&gt;引入PyTSC，一个强大且灵活的模拟环境，支持MARL算法的训练和评估，集成多个模拟器（如SUMO和CityFlow），并提供简化的API。&lt;h4&gt;主要发现&lt;/h4&gt;PyTSC使得研究人员能够高效探索多种MARL方法，促进了实验的加速。&lt;h4&gt;结论&lt;/h4&gt;PyTSC为推进智能交通管理系统在现实应用中的发展提供了新的机会。&lt;h4&gt;总结&lt;/h4&gt;PyTSC为MARL在交通信号控制中的应用提供了改进的研究平台，解决了现有的主要问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/rbokade/pytsc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-Agent Reinforcement Learning (MARL) presents a promising approach foraddressing the complexity of Traffic Signal Control (TSC) in urbanenvironments. However, existing platforms for MARL-based TSC research facechallenges such as slow simulation speeds and convoluted, difficult-to-maintaincodebases. To address these limitations, we introduce PyTSC, a robust andflexible simulation environment that facilitates the training and evaluation ofMARL algorithms for TSC. PyTSC integrates multiple simulators, such as SUMO andCityFlow, and offers a streamlined API, empowering researchers to explore abroad spectrum of MARL approaches efficiently. PyTSC acceleratesexperimentation and provides new opportunities for advancing intelligenttraffic management systems in real-world applications.</description>
      <author>example@mail.com (Rohit Bokade, Xiaoning Jin)</author>
      <guid isPermaLink="false">2410.18202v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>PAPL-SLAM: Principal Axis-Anchored Monocular Point-Line SLAM</title>
      <link>http://arxiv.org/abs/2410.12324v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在点线SLAM系统中，线结构信息的利用和线的优化是两个重要问题。&lt;h4&gt;目的&lt;/h4&gt;解决线结构信息与优化之间的约束信息丢失问题。&lt;h4&gt;方法&lt;/h4&gt;将方向相似的线锚定到主轴，通过$n+2$参数优化$n$条线，同时考虑场景结构信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法显著减少了需要优化的线参数数量，提高了映射和跟踪的速度与准确性。&lt;h4&gt;结论&lt;/h4&gt;通过轴的概率数据关联模型，增强了系统的鲁棒性，并提供了轴的创建、更新与优化的算法。&lt;h4&gt;额外发现&lt;/h4&gt;基于垂直先验和消失点的结构线检测策略适应大多数现实场景。&lt;h4&gt;总结&lt;/h4&gt;实验结果和消融研究表明该系统在各种室内和室外数据集上表现有效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In point-line SLAM systems, the utilization of line structural informationand the optimization of lines are two significant problems. The former isusually addressed through structural regularities, while the latter typicallyinvolves using minimal parameter representations of lines in optimization.However, separating these two steps leads to the loss of constraint informationto each other. We anchor lines with similar directions to a principal axis andoptimize them with $n+2$ parameters for $n$ lines, solving both problemstogether. Our method considers scene structural information, which can beeasily extended to different world hypotheses while significantly reducing thenumber of line parameters to be optimized, enabling rapid and accurate mappingand tracking. To further enhance the system's robustness and avoid mismatch, wehave modeled the line-axis probabilistic data association and provided thealgorithm for axis creation, updating, and optimization. Additionally,considering that most real-world scenes conform to the Atlanta Worldhypothesis, we provide a structural line detection strategy based on verticalpriors and vanishing points. Experimental results and ablation studies onvarious indoor and outdoor datasets demonstrate the effectiveness of oursystem.</description>
      <author>example@mail.com (Guanghao Li, Yu Cao, Qi Chen, Yifan Yang, Jian Pu)</author>
      <guid isPermaLink="false">2410.12324v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Diffusion for Multi-Embodiment Grasping</title>
      <link>http://arxiv.org/abs/2410.18835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;抓取是机器人技术中的基本技能，广泛应用于医疗、工业和家庭领域。&lt;h4&gt;目的&lt;/h4&gt;解决当前抓取预测方法受限于特定夹具设计的问题，提高其适用性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于等变扩散的方法，实现了与夹具无关的场景编码和夹具感知的抓取姿势解码，将夹具几何信息集成到模型中。&lt;h4&gt;主要发现&lt;/h4&gt;在不同物体数据集上的实验评估表明，该方法在各种夹具架构中具有良好的通用性，优于单夹具和多夹具的现有最先进方法。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效支持不同设计的夹具之间的抓取策略转移，提升了抓取合成方法的训练效果。&lt;h4&gt;总结&lt;/h4&gt;通过新的数据集生成框架和改进的抓取策略，本研究推动了抓取技术的进步，适用于多种夹具设计。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grasping is a fundamental skill in robotics with diverse applications acrossmedical, industrial, and domestic domains. However, current approaches forpredicting valid grasps are often tailored to specific grippers, limiting theirapplicability when gripper designs change. To address this limitation, weexplore the transfer of grasping strategies between various gripper designs,enabling the use of data from diverse sources. In this work, we present anapproach based on equivariant diffusion that facilitates gripper-agnosticencoding of scenes containing graspable objects and gripper-aware decoding ofgrasp poses by integrating gripper geometry into the model. We also develop adataset generation framework that produces cluttered scenes with variable-sizedobject heaps, improving the training of grasp synthesis methods. Experimentalevaluation on diverse object datasets demonstrates the generalizability of ourapproach across gripper architectures, ranging from simple parallel-jawgrippers to humanoid hands, outperforming both single-gripper and multi-gripperstate-of-the-art methods.</description>
      <author>example@mail.com (Roman Freiberg, Alexander Qualmann, Ngo Anh Vien, Gerhard Neumann)</author>
      <guid isPermaLink="false">2410.18835v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>TIMBER: On supporting data pipelines in Mobile Cloud Environments</title>
      <link>http://arxiv.org/abs/2410.18106v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;移动计算和物联网技术的进步促成了智能城市应用的发展，这些应用能够生成原始或预处理数据，帮助城市更好地感知环境。&lt;h4&gt;目的&lt;/h4&gt;旨在通过移动边缘云（MEC）基础设施解决城市系统应用面临的空间和时间动态挑战，并提供可扩展性和按需计算能力。&lt;h4&gt;方法&lt;/h4&gt;提出了TIMBER框架，旨在高效支持移动云环境中的数据处理管道，解决实时执行中的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果显示，该方法平均降低了运营成本66.245%，并在无关工作负载下实现了高达96.4%的相似吞吐量性能。&lt;h4&gt;结论&lt;/h4&gt;TIMBER框架有效应对了移动边缘云环境中的资源限制和请求不确定性问题。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了TIMBER在智能城市应用中的潜在价值，提供了一种新的解决方案来改善移动数据处理效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The radical advances in mobile computing, the IoT technological evolutionalong with cyberphysical components (e.g., sensors, actuators, control centers)have led to the development of smart city applications that generate raw orpre-processed data, enabling workflows involving the city to better sense theurban environment and support citizens' everyday lives. Recently, a new era ofMobile Edge Cloud (MEC) infrastructures has emerged to support smart cityapplications that aim to address the challenges raised due to thespatio-temporal dynamics of the urban crowd as well as bring scalability andon-demand computing capacity to urban system applications for timely response.In these, resource capabilities are distributed at the edge of the network andin close proximity to end-users, making it possible to perform computation anddata processing at the network edge. However, there are important challengesrelated to real-time execution, not only due to the highly dynamic andtransient crowd, the bursty and highly unpredictable amount of requests butalso due to the resource constraints imposed by the Mobile Edge Cloudenvironment. In this paper, we present TIMBER, our framework for efficientlysupporting mobile daTa processing pIpelines in MoBile cloud EnviRonments thateffectively addresses the aforementioned challenges. Our detailed experimentalresults illustrate that our approach can reduce the operating costs by 66.245%on average and achieve up to 96.4% similar throughput performance for agnosticworkloads.</description>
      <author>example@mail.com (Dimitrios Tomaras, Michail Tsenos, Vana Kalogeraki, Dimitrios Gunopulos)</author>
      <guid isPermaLink="false">2410.18106v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Multimodal LLMs with Semantic Space Alignment for Enhanced Time Series Classification</title>
      <link>http://arxiv.org/abs/2410.18686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在时间序列分类中引起了越来越多的关注，但现有方法常常忽视时间序列数据中固有的动态时间信息，并面临与文本语义对齐的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出HiTime，一个层次化的多模态模型，将时间信息无缝整合到LLMs中，以实现多元时间序列分类（MTSC）。&lt;h4&gt;方法&lt;/h4&gt;模型采用层次化特征编码器，通过数据特定和任务特定的嵌入捕获时间序列数据的多样性；引入双视角对比对齐模块以实现时间序列与文本之间的语义空间对齐；采用混合提示策略以高效微调预训练的LLM。&lt;h4&gt;主要发现&lt;/h4&gt;HiTime有效结合动态时间特征并确保语义对齐，使LLMs能够处理连续时间序列数据，并通过文本生成实现了最先进的分类性能。&lt;h4&gt;结论&lt;/h4&gt;在基准数据集上的广泛实验表明，HiTime显著提高了时间序列分类的准确性，超过大多数竞争基线方法，显示了将时间特征整合进LLMs的潜力，为高级时间序列分析铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;我们的代码公开可用，供进一步研究和验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging large language models (LLMs) has garnered increasing attention andintroduced novel perspectives in time series classification. However, existingapproaches often overlook the crucial dynamic temporal information inherent intime series data and face challenges in aligning this data with textualsemantics. To address these limitations, we propose HiTime, a hierarchicalmulti-modal model that seamlessly integrates temporal information into LLMs formultivariate time series classification (MTSC). Our model employs ahierarchical feature encoder to capture diverse aspects of time series datathrough both data-specific and task-specific embeddings. To facilitate semanticspace alignment between time series and text, we introduce a dual-viewcontrastive alignment module that bridges the gap between modalities.Additionally, we adopt a hybrid prompting strategy to fine-tune the pre-trainedLLM in a parameter-efficient manner. By effectively incorporating dynamictemporal features and ensuring semantic alignment, HiTime enables LLMs toprocess continuous time series data and achieves state-of-the-artclassification performance through text generation. Extensive experiments onbenchmark datasets demonstrate that HiTime significantly enhances time seriesclassification accuracy compared to most competitive baseline methods. Ourfindings highlight the potential of integrating temporal features into LLMs,paving the way for advanced time series analysis. The code is publiclyavailable for further research and validation. Our codes are publiclyavailable1.</description>
      <author>example@mail.com (Xiaoyu Tao, Tingyue Pan, Mingyue Cheng, Yucong Luo)</author>
      <guid isPermaLink="false">2410.18686v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Advancing Network Security: A Comprehensive Testbed and Dataset for Machine Learning-Based Intrusion Detection</title>
      <link>http://arxiv.org/abs/2410.18332v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本论文介绍了一种用于生成网络流量的测试平台。&lt;h4&gt;目的&lt;/h4&gt;为机器学习基础的网络实验提供一个先进的平台。&lt;h4&gt;方法&lt;/h4&gt;利用容器、Kubernetes和eBPF/XDP技术构建测试平台。&lt;h4&gt;主要发现&lt;/h4&gt;通过该测试平台，公开了一个满足真实数据特性的恶意网络流量数据集。&lt;h4&gt;结论&lt;/h4&gt;测试平台有效支持网络流量生成，并为相关实验提供了可靠的数据。&lt;h4&gt;总结&lt;/h4&gt;该研究为网络流量生成和机器学习实验提供了重要的技术基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a Testbed designed for generating network traffic,leveraging the capabilities of containers, Kubernetes, and eBPF/XDPtechnologies. Our Testbed serves as an advanced platform for producing networktraffic for machine learning based network experiments. By utilizing thisTestbed, we offer small malicious network traffic dataset publically thatsatisfy ground truth property completely.</description>
      <author>example@mail.com (Talaya Farasat, JongWon Kim, Joachim Posegga)</author>
      <guid isPermaLink="false">2410.18332v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Creating and Repairing Robot Programs in Open-World Domains</title>
      <link>http://arxiv.org/abs/2410.18893v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review at ACL Rolling Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;使用大型语言模型（LLMs）生成机器人程序可以使机器人系统完成更多样化的任务。&lt;h4&gt;目的&lt;/h4&gt;提出RoboRepair系统，以便在程序出错时进行有效的恢复。&lt;h4&gt;方法&lt;/h4&gt;RoboRepair系统追踪程序执行直到错误，并运行LLM生成的恢复程序，以最小化重复的操作。&lt;h4&gt;主要发现&lt;/h4&gt;通过创建包含十一项任务的基准，评估恢复程序的效率，并与具有未来错误预知能力的计划进行比较。&lt;h4&gt;结论&lt;/h4&gt;RoboRepair系统能有效应对机器人程序中的错误，提高任务完成的效率。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了如何利用LLM生成的程序和恢复机制，提升机器人在面对不确定性时的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Using Large Language Models (LLMs) to produce robot programs from naturallanguage has allowed for robot systems that can complete a higher diversity oftasks. However, LLM-generated programs may be faulty, either due to ambiguityin instructions, misinterpretation of the desired task, or missing informationabout the world state. As these programs run, the state of the world changesand they gather new information. When a failure occurs, it is important thatthey recover from the current world state and avoid repeating steps that theythey previously completed successfully. We propose RoboRepair, a system whichtraces the execution of a program up until error, and then runs an LLM-producedrecovery program that minimizes repeated actions.  To evaluate the efficacy of our system, we create a benchmark consisting ofeleven tasks with various error conditions that require the generation of arecovery program. We compare the efficiency of the recovery program to a planbuilt with an oracle that has foreknowledge of future errors.</description>
      <author>example@mail.com (Claire Schlesinger, Arjun Guha, Joydeep Biswas)</author>
      <guid isPermaLink="false">2410.18893v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Neural Active Structure-from-Motion in Dark and Textureless Environment</title>
      <link>http://arxiv.org/abs/2410.15378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in Asian Conference on Computer Vision 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;主动3D测量，特别是结构光技术，因其在低光照和无纹理表面下的鲁棒性而广泛应用于各个领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种从图像集中同时进行形状重建和位姿估计的技术，特别是在缺乏场景纹理信息的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于神经签名距离场（Neural-SDF）的全优化框架，用于结构光系统，以重建场景形状并估计系统每次运动的位姿。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提方法能够在仅观察到投影模式的图像中实现准确的形状重建和位姿估计。&lt;h4&gt;结论&lt;/h4&gt;该方法有效克服了传统技术在无纹理环境下的局限性，提供了一种新的解决方案。&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种创新的方法，结合了形状重建和位姿估计，为结构光系统在缺乏纹理信息的环境下的应用提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Active 3D measurement, especially structured light (SL) has been widely usedin various fields for its robustness against textureless or equivalent surfacesby low light illumination. In addition, reconstruction of large scenes bymoving the SL system has become popular, however, there have been few practicaltechniques to obtain the system's precise pose information only from images,since most conventional techniques are based on image features, which cannot beretrieved under textureless environments. In this paper, we propose asimultaneous shape reconstruction and pose estimation technique for SL systemsfrom an image set where sparsely projected patterns onto the scene are observed(i.e. no scene texture information), which we call Active SfM. To achieve this,we propose a full optimization framework of the volumetric shape that employsneural signed distance fields (Neural-SDF) for SL with the goal of not onlyreconstructing the scene shape but also estimating the poses for each motion ofthe system. Experimental results show that the proposed method is able toachieve accurate shape reconstruction as well as pose estimation from imageswhere only projected patterns are observed.</description>
      <author>example@mail.com (Kazuto Ichimaru, Diego Thomas, Takafumi Iwaguchi, Hiroshi Kawasaki)</author>
      <guid isPermaLink="false">2410.15378v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Retrieval-Augmented Diffusion Models for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.18712v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列扩散模型受到广泛关注，但现有模型性能不稳定。&lt;h4&gt;目的&lt;/h4&gt;提出一种检索增强时间序列扩散模型（RATD），以解决时间序列数据集不足和缺乏指导的问题。&lt;h4&gt;方法&lt;/h4&gt;RATD框架包括两个部分：基于嵌入的检索过程和参考引导的扩散模型。第一部分从数据库中检索与历史时间序列最相关的时间序列作为参考，第二部分利用这些参考指导去噪过程。&lt;h4&gt;主要发现&lt;/h4&gt;通过从数据库中有效利用有意义的样本，我们的方法在复杂预测任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;参考引导机制补偿了现有时间序列扩散模型在指导方面的不足，实验和可视化结果证明了该方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;RATD模型提供了一种新的方式来提高时间序列扩散模型的性能，特别是在复杂的预测任务中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While time series diffusion models have received considerable focus from manyrecent works, the performance of existing models remains highly unstable.Factors limiting time series diffusion models include insufficient time seriesdatasets and the absence of guidance. To address these limitations, we proposea Retrieval- Augmented Time series Diffusion model (RATD). The framework ofRATD consists of two parts: an embedding-based retrieval process and areference-guided diffusion model. In the first part, RATD retrieves the timeseries that are most relevant to historical time series from the database asreferences. The references are utilized to guide the denoising process in thesecond part. Our approach allows leveraging meaningful samples within thedatabase to aid in sampling, thus maximizing the utilization of datasets.Meanwhile, this reference-guided mechanism also compensates for thedeficiencies of existing time series diffusion models in terms of guidance.Experiments and visualizations on multiple datasets demonstrate theeffectiveness of our approach, particularly in complicated prediction tasks.</description>
      <author>example@mail.com (Jingwei Liu, Ling Yang, Hongyan Li, Shenda Hong)</author>
      <guid isPermaLink="false">2410.18712v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>SkillMimicGen: Automated Demonstration Generation for Efficient Skill Learning and Deployment</title>
      <link>http://arxiv.org/abs/2410.18907v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模仿学习在人类演示中的应用对于机器人操作有效，但获取大量数据集成本高且资源密集，特别是对于长时间任务。&lt;h4&gt;目的&lt;/h4&gt;提出SkillMimicGen (SkillGen)，一个自动化系统，从少量人类演示生成演示数据集。&lt;h4&gt;方法&lt;/h4&gt;SkillGen将人类演示分段为操作技能，适应这些技能到新环境，并通过自由空间的过渡和转移运动将其连接。&lt;h4&gt;主要发现&lt;/h4&gt;SkillGen在数据生成和策略学习性能上显著优于最先进的数据生成框架，能够为大场景变体生成数据，包括杂乱环境，并使代理成功率提高24%。&lt;h4&gt;结论&lt;/h4&gt;SkillGen在模拟中从60个人类演示生成超过24K个演示，训练出熟练的HSP代理，并在三个真实世界操作任务中有效应用，展示了零-shot的模拟到真实转移能力。&lt;h4&gt;总结&lt;/h4&gt;SkillGen大幅提高了机器人操作任务中数据生成的效率和策略学习的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imitation learning from human demonstrations is an effective paradigm forrobot manipulation, but acquiring large datasets is costly andresource-intensive, especially for long-horizon tasks. To address this issue,we propose SkillMimicGen (SkillGen), an automated system for generatingdemonstration datasets from a few human demos. SkillGen segments human demosinto manipulation skills, adapts these skills to new contexts, and stitchesthem together through free-space transit and transfer motion. We also propose aHybrid Skill Policy (HSP) framework for learning skill initiation, control, andtermination components from SkillGen datasets, enabling skills to be sequencedusing motion planning at test-time. We demonstrate that SkillGen greatlyimproves data generation and policy learning performance over astate-of-the-art data generation framework, resulting in the capability toproduce data for large scene variations, including clutter, and agents that areon average 24% more successful. We demonstrate the efficacy of SkillGen bygenerating over 24K demonstrations across 18 task variants in simulation fromjust 60 human demonstrations, and training proficient, often near-perfect, HSPagents. Finally, we apply SkillGen to 3 real-world manipulation tasks and alsodemonstrate zero-shot sim-to-real transfer on a long-horizon assembly task.Videos, and more at https://skillgen.github.io.</description>
      <author>example@mail.com (Caelan Garrett, Ajay Mandlekar, Bowen Wen, Dieter Fox)</author>
      <guid isPermaLink="false">2410.18907v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval</title>
      <link>http://arxiv.org/abs/2410.18385v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at EMNLP 2024 Main Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管信息检索（IR）有了最新发展，但零-shot IR仍然是一个重大挑战，特别是在处理新领域、语言和缺乏历史查询流量的新用例时。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的通用文档链接（UDL）算法，以增强合成查询生成，适用于具有不同特征的多个数据集。&lt;h4&gt;方法&lt;/h4&gt;UDL算法通过链接相似文档来生成合成查询，利用熵选择相似性模型，并使用命名实体识别（NER）基于相似性分数进行文档链接决策。&lt;h4&gt;主要发现&lt;/h4&gt;UDL在多个数据集和IR模型中表现出有效性和通用性，超越了当前最先进的方法，特别是在零-shot情况下。&lt;h4&gt;结论&lt;/h4&gt;UDL算法有效提升了合成查询的生成能力，并且在不同环境下均表现优异。&lt;h4&gt;总结&lt;/h4&gt;研究表明UDL算法在零-shot IR场景中具有广泛适用性，相关代码已在GitHub上发布以便复现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the recent advancements in information retrieval (IR), zero-shot IRremains a significant challenge, especially when dealing with new domains,languages, and newly-released use cases that lack historical query traffic fromexisting users. For such cases, it is common to use query augmentationsfollowed by fine-tuning pre-trained models on the document data paired withsynthetic queries. In this work, we propose a novel Universal Document Linking(UDL) algorithm, which links similar documents to enhance synthetic querygeneration across multiple datasets with different characteristics. UDLleverages entropy for the choice of similarity models and named entityrecognition (NER) for the link decision of documents using similarity scores.Our empirical studies demonstrate the effectiveness and universality of the UDLacross diverse datasets and IR models, surpassing state-of-the-art methods inzero-shot cases. The developed code for reproducibility is included inhttps://github.com/eoduself/UDL</description>
      <author>example@mail.com (Dae Yon Hwang, Bilal Taha, Harshit Pande, Yaroslav Nechaev)</author>
      <guid isPermaLink="false">2410.18385v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>PLGS: Robust Panoptic Lifting with 3D Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2410.17505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;以往的方法利用神经辐射场（NeRF）进行全景提升，但训练和渲染速度不理想。3D高斯点云（3DGS）因其快速的训练和渲染速度而受到关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法PLGS，使3DGS能够从嘈杂的2D分割掩模中生成一致的全景分割掩模，同时保持比NeRF方法更高的效率。&lt;h4&gt;方法&lt;/h4&gt;构建一个全景感知的结构化3D高斯模型，引入平滑性并设计有效的噪声减少策略；使用可靠的语义锚点初始化3D高斯，并在训练过程中作为平滑正则化；采用自我训练方法，利用合成标签增强PLGS的鲁棒性；将2D实例掩模投影到3D空间，生成跨视图一致的实例掩模进行监督。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，PLGS在分割质量和速度上超越了以往的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;PLGS方法在处理嘈杂2D掩模时，能够有效提高分割的一致性和质量，同时提升效率。&lt;h4&gt;总结&lt;/h4&gt;PLGS结合了快速渲染技术和稳健的分割策略，为全景分割提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Previous methods utilize the Neural Radiance Field (NeRF) for panopticlifting, while their training and rendering speed are unsatisfactory. Incontrast, 3D Gaussian Splatting (3DGS) has emerged as a prominent technique dueto its rapid training and rendering speed. However, unlike NeRF, theconventional 3DGS may not satisfy the basic smoothness assumption as it doesnot rely on any parameterized structures to render (e.g., MLPs). Consequently,the conventional 3DGS is, in nature, more susceptible to noisy 2D masksupervision. In this paper, we propose a new method called PLGS that enables3DGS to generate consistent panoptic segmentation masks from noisy 2Dsegmentation masks while maintaining superior efficiency compared to NeRF-basedmethods. Specifically, we build a panoptic-aware structured 3D Gaussian modelto introduce smoothness and design effective noise reduction strategies. Forthe semantic field, instead of initialization with structure from motion, weconstruct reliable semantic anchor points to initialize the 3D Gaussians. Wethen use these anchor points as smooth regularization during training.Additionally, we present a self-training approach using pseudo labels generatedby merging the rendered masks with the noisy masks to enhance the robustness ofPLGS. For the instance field, we project the 2D instance masks into 3D spaceand match them with oriented bounding boxes to generate cross-view consistentinstance masks for supervision. Experiments on various benchmarks demonstratethat our method outperforms previous state-of-the-art methods in terms of bothsegmentation quality and speed.</description>
      <author>example@mail.com (Yu Wang, Xiaobao Wei, Ming Lu, Guoliang Kang)</author>
      <guid isPermaLink="false">2410.17505v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Slice: Dedicated Wireless Network Slicing for Large Language Models</title>
      <link>http://arxiv.org/abs/2410.18499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模语言模型（LLMs）的快速应用对现有网络架构提出了新的挑战，导致了显著的峰值流量和高通信不确定性。&lt;h4&gt;目的&lt;/h4&gt;提出LLM-Slice，首个在无线网络环境中为LLMs提供专用通信切片的系统。&lt;h4&gt;方法&lt;/h4&gt;通过创建LLM特定的网络切片，LLM-Slice有效地将服务与通信资源绑定，基于用户设备请求和权限数据库注册特定切片。&lt;h4&gt;主要发现&lt;/h4&gt;系统集成下行资源控制模块，优化响应速度，提高资源利用率，减少断连。&lt;h4&gt;结论&lt;/h4&gt;在真实的用户设备-基站-核心网环境中部署和验证，数值结果表明LLM-Slice显著提高了响应速度和资源效率，为无线网络中快速和可控的LLM访问提供了新解决方案。&lt;h4&gt;总结&lt;/h4&gt;LLM-Slice通过专用切片技术解决了大规模语言模型在无线网络中的通信效率问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid adoption of large language models (LLMs) presents new challengesfor existing network architectures due to significant peak traffic and highcommunication uncertainty. Traditional wireless networks struggle to supportefficiently, leading to intolerable response delays, disconnections, andresource wastage. To address these issues, we propose LLM-Slice, the firstsystem to provide dedicated communication slices for LLMs within a wirelessnetwork environment. By creating LLM-specific network slices, LLM-Sliceefficiently binds services with communication resources. Based on userequipment (UE) requests and a permissions database, the system registersspecific slices to offer controllable LLM services, integrating a downlinkresource control module to optimize response speed, enhance resourceutilization, and reduce disconnections. By deploying and validating in a realUE-gNB-CN environment, numerical results demonstrate that LLM-Slicesignificantly improves response speed and resource efficiency, providing anovel solution for fast and controllable LLM access in wireless networks.</description>
      <author>example@mail.com (Boyi Liu, Jingwen Tong, Jun Zhang)</author>
      <guid isPermaLink="false">2410.18499v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Limit Theorems for the Symbolic Correlation Integral and the Renyi-2 Entropy under Short-range Dependence</title>
      <link>http://arxiv.org/abs/2410.18726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  36 pages, 1 figure, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;符号相关积分提供了一种测量时间序列和动态系统复杂性的方法。&lt;h4&gt;目的&lt;/h4&gt;证明基于U统计量的这一量的估计量的极限结果，假设存在短程依赖性。&lt;h4&gt;方法&lt;/h4&gt;略微推广经典极限结果，基于1-近似函数的框架进行分析，同时仔细分析极限方差。&lt;h4&gt;主要发现&lt;/h4&gt;进行了ARMA和ARCH时间序列的模拟研究，并提供了一个实际数据示例。&lt;h4&gt;结论&lt;/h4&gt;展示了该方法如何用于分析癫痫发作中的EEG数据。&lt;h4&gt;总结&lt;/h4&gt;本文探讨了符号相关积分的复杂性测量及其在时间序列分析中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The symbolic correlation integral provides a way to measure the complexity oftime series and dynamical systems. In the present article we prove limitresults for an estimator of this quantity which is based on U-statistics underthe assumption of short-range dependence. To this end, we slightly generalizeclassical limit results in the framework of 1-approximating functionals.Furthermore, we carefully analyze the limit variance. A simulation study withARMA and ARCH time series as well as a real world data example are alsoprovided. In the latter we show how our method could be used to analyze EEGdata in the context of epileptic seizures.</description>
      <author>example@mail.com (Alexander Schnurr, Angelika Silbernagel, Manuel Ruiz Marin)</author>
      <guid isPermaLink="false">2410.18726v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>CO-CAVITY project: Molecular gas and star formation in void galaxies</title>
      <link>http://arxiv.org/abs/2410.18078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 9 figures. Accepted for publication in A&amp;A&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;宇宙空洞因其低密度环境，为研究宇宙环境与星系形成和演化过程提供了独特机会。&lt;h4&gt;目的&lt;/h4&gt;研究空洞星系中的分子气体含量和特性，比较其与密集结构中星系的可能差异。&lt;h4&gt;方法&lt;/h4&gt;使用IRAM 30米望远镜观察106个来自CAVITY调查的空洞星系的CO(1-0)和CO(2-1)发射，结合文献数据，获得200个空洞星系的CO数据样本。&lt;h4&gt;主要发现&lt;/h4&gt;空洞星系与比较样本在分子气体分数方面没有显著差异，但空洞星系的星形成效率在各质量区间内保持恒定，而比较样本呈下降趋势。&lt;h4&gt;结论&lt;/h4&gt;空洞星系的分子气体特性与密集环境的星系相似，空洞星系中恒定的星形成效率的物理来源尚不明确，需要进一步研究和更高分辨率的数据。&lt;h4&gt;总结&lt;/h4&gt;本研究表明，空洞星系的分子气体特性与密集环境相比差异不大，但在星形成效率上存在显著不同，值得进一步探讨。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cosmic voids, distinguished by their low-density environment, provide aunique opportunity to explore the interplay between the cosmic environment andthe processes of galaxy formation and evolution. Data on the molecular gas hasbeen scarce so far. In this paper, we continue previous research done in theCO-CAVITY pilot project to study the molecular gas content and properties invoid galaxies to search for possible differences compared to galaxies thatinhabit denser structures. We observed at the IRAM 30 m telescope the CO(1-0)and CO(2-1) emission of 106 void galaxies selected from the CAVITY survey.Together with data from the literature, we obtained a sample of 200 voidgalaxies with CO data. We conducted a comprehensive comparison of the specificstar formation rate (sSFR = SFR/M$_*$), the molecular gas fraction(MH$_2$/M$_*$), and the star formation efficiency (SFE = SFR/MH$_2$) betweenthe void galaxies and a comparison sample of galaxies in filaments and walls,selected from the xCOLD GASS survey. We found no statistically significantdifference between void galaxies and the comparison sample in the molecular gasfraction as a function of stellar mass for galaxies on the star-forming mainsequence (SFMS). However, for void galaxies, the SFE was found to be constantacross all stellar mass bins, while there is a decreasing trend with M$_*$ forthe comparison sample. Finally, we found some indications for a smallerdynamical range in the molecular gas fraction as a function of distance to theSFMS in void galaxies. Overall, our analysis finds that the molecular gasproperties of void galaxies are not very different from denser environments.The physical origin of the most significant difference that we found - aconstant SFE as a function of stellar mass in void galaxies - is unclear andrequires further investigation and higher-resolution data.</description>
      <author>example@mail.com (M. I. Rodríguez, U. Lisenfeld, S. Duarte Puertas, D. Espada, J. Domínguez-Gómez, M. Sánchez-Portal, A. Bongiovanni, M. Alcázar-Laynez, M. Argudo-Fernández, B. Bidaran, S. B. De Daniloff, J. Falcón-Barroso, E. Florido, R. García-Benito, A. Jimenez, K. Kreckel, R. F. Peletier, I. Pérez, T. Ruiz-Lara, L. Sánchez-Menguiano, G. Torres-Ríos, P. Villalba-González, S. Verley, A. Zurita)</author>
      <guid isPermaLink="false">2410.18078v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Complexity Control</title>
      <link>http://arxiv.org/abs/2410.18752v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出一个动态模型，用于控制系统之间的复杂性，该模型通过时间序列和不同的时间复杂性度量表示。&lt;h4&gt;目的&lt;/h4&gt;基于模型的缩放度量与人脑经验复杂性度量的相似性，形成假设。&lt;h4&gt;方法&lt;/h4&gt;使用逆幂律指数（IPL）来表征时间序列的复杂性，并分析复杂性控制（CC）现象。&lt;h4&gt;主要发现&lt;/h4&gt;CC模型能够有效描述最近的实验结果，如走路时手挽手的康复和复杂性同步效应。&lt;h4&gt;结论&lt;/h4&gt;CC效应可用于设计互适应信号，以恢复不适应的器官网络的复杂性，或干扰恶意系统的复杂性，降低其智能行为。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的CC模型为理解和应用复杂性控制提供了新视角，对生物系统和恶意系统均有重要意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a dynamic model for complexity control (CC) between systems,represented by time series characterized by different temporal complexitymeasures, as indicated by their respective inverse power law (IPL) indices.Given the apparent straightforward character of the model and the generality ofthe result, we formulate a hypothesis based on the closeness of the scalingmeasures of the model to the empirical complexity measures of the human brain.CC is a proper model for describing the recent experimental results, such asthe rehabilitation in walking arm in arm and the complexity synchronizationeffect. The CC effect can lead to the design of mutual-adaptive signals torestore the misaligned complexity of maladjusted organ networks or, on theother hand, to disrupt the complexity of a malicious system and lower itsintelligent behavior.</description>
      <author>example@mail.com (Korosh Mahmoodi, Scott E. Kerick, Piotr J. Franaszczuk, Paolo Grigolini, Bruce J. West)</author>
      <guid isPermaLink="false">2410.18752v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Swarm manipulation: An efficient and accurate technique for multi-object manipulation in virtual reality</title>
      <link>http://arxiv.org/abs/2410.18924v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, accepted at Computers &amp; Graphics&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;群体控制理论在控制多个对象方面表现出潜力，但由于硬件和基础设施等成本限制，规模化受到阻碍。&lt;h4&gt;目的&lt;/h4&gt;研究虚拟现实(VR)中群体交互的可能性，并介绍一种新颖的群体操作交互技术。&lt;h4&gt;方法&lt;/h4&gt;将群体操作与两种基线技术（虚拟手和控制器）进行比较，进行了用户研究（N = 12），涉及选择、旋转和调整大小三个任务，在五种条件下进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;群体操作在大多数条件下表现出显著更快的速度，尤其在调整大小任务中显著减少了偏差，但在旋转任务中存在速度与准确性的权衡。&lt;h4&gt;结论&lt;/h4&gt;群体操作技术在VR中的可用性和用户体验上优于传统操控技术，未来研究将探讨通过内部群体粒子合作来改善群体交互。&lt;h4&gt;总结&lt;/h4&gt;群体操作技术展示了在复杂VR场景中改善用户交互和体验的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The theory of swarm control shows promise for controlling multiple objects,however, scalability is hindered by cost constraints, such as hardware andinfrastructure. Virtual Reality (VR) can overcome these limitations, butresearch on swarm interaction in VR is limited. This paper introduces a novelSwarm Manipulation interaction technique and compares it with two baselinetechniques: Virtual Hand and Controller (ray-casting). We evaluated thesetechniques in a user study ($N$ = 12) in three tasks (selection, rotation, andresizing) across five conditions. Our results indicate that Swarm Manipulationyielded superior performance, with significantly faster speeds in mostconditions across the three tasks. It notably reduced resizing size deviationsbut introduced a trade-off between speed and accuracy in the rotation task.Additionally, we conducted a follow-up user study ($N$ = 6) using SwarmManipulation in two complex VR scenarios and obtained insights throughsemi-structured interviews, shedding light on optimized swarm controlmechanisms and perceptual changes induced by this interaction paradigm. Theseresults demonstrate the potential of the Swarm Manipulation technique toenhance the usability and user experience in VR compared to conventionalmanipulation techniques. In future studies, we aim to understand and improveswarm interaction via internal swarm particle cooperation.</description>
      <author>example@mail.com (Xiang Li, Jin-Du Wang, John J. Dudley, Per Ola Kristensson)</author>
      <guid isPermaLink="false">2410.18924v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>EndoMetric: Near-light metric scale monocular SLAM</title>
      <link>http://arxiv.org/abs/2410.15065v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICRA 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，内窥镜图像的几何重建和SLAM技术取得了显著进展。大多数医学领域使用的内窥镜为单目设备，所用算法通常是为外部环境设计的扩展，导致3D重建存在未知的比例因子。&lt;h4&gt;目的&lt;/h4&gt;利用标准内窥镜近光源的位置，实现精确的单目重建，提供准确的度量尺度。&lt;h4&gt;方法&lt;/h4&gt;通过利用光衰减的反平方定律，首次实现了具有准确度量尺度的单目重建。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法使得任何内窥镜都能转变为具有度量功能的设备。&lt;h4&gt;结论&lt;/h4&gt;这一进展对实际应用至关重要，如测量息肉、狭窄或受病变影响的组织范围。&lt;h4&gt;总结&lt;/h4&gt;该研究为内窥镜在医学中的应用提供了新的可能性，促进了更精确的疾病诊断和治疗。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometric reconstruction and SLAM with endoscopic images have seensignificant advancements in recent years. In most medical specialties, theendoscopes used are monocular, and the algorithms applied are typicallyextensions of those designed for external environments, resulting in 3Dreconstructions up to an unknown scale factor.  In this paper, we take advantage of the fact that standard endoscopes areequipped with near-light sources positioned at a small but non-zero baselinefrom the camera. By leveraging the inverse-square law of light decay, weenable, for the first time, monocular reconstructions with accurate metricscale. This paves the way to transform any endoscope into a metric device,which is essential for practical applications such as measuring polyps,stenosis, or the extent of tissue affected by disease.</description>
      <author>example@mail.com (Raúl Iranzo, Víctor M. Batlle, Juan D. Tardós, José M. M. Montiel)</author>
      <guid isPermaLink="false">2410.15065v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>A framework for GNSS-based solutions performance analysis in an ERTMS context</title>
      <link>http://arxiv.org/abs/2410.18510v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;全球导航卫星系统（GNSS）在铁路应用中的进展，旨在减少交通碳足迹。&lt;h4&gt;目的&lt;/h4&gt;提高铁路运输的吸引力和可靠性，降低资本支出和运营成本。&lt;h4&gt;方法&lt;/h4&gt;结合GNSS与车载定位解决方案，开发新的移动块、虚拟耦合和自动化概念。&lt;h4&gt;主要发现&lt;/h4&gt;GNSS在ERTMS中被视为重要的变革者，但环境条件影响定位性能，尤其在隧道和城市密集地区。&lt;h4&gt;结论&lt;/h4&gt;尽管已有进展，但在动态环境中评估性能、确保所有配置测试及故障影响仍需解决。&lt;h4&gt;总结&lt;/h4&gt;R2DATO项目正在研究这些问题，以推动GNSS在铁路中的应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Context Progresses in GNSS-based solution introduction in rail applicationsGNSS (Global Navigation Satellite System) is now used in most of our travelsand each of our smartphone apps. Most of the usages are not safety-critical.But Europe identified GNSS for more applications and to be integrated in railin general as part of the toolset to help railway to contribute to reducetransport carbon footprint. To increase the use of trains in Europeantransports, railways must improve their attractiveness for passengers andfreight, but also increase reliability, availability and efficiency by reducingcapital expenditure and operational costs. GNSS is part of the globaldigitalization scheme of freight that aims to offer added value to the clientsknowledge of accurate time of arrival, continuous monitoring of transportconditions (temperature, humidity...). But a major challenge will be to reachstringent applications and in particular, GNSS is today seen as a realistic andserious game changer for the future of the ERTMS (European Rail TrafficManagement System). The localisation function is today performed with bothodometry and balises. Odometer provides a continuous train position in timefrom a reference point. But as the distance delivered by the odometer shows agrowing bias with distance, due to wear and wheel sliding, the use of on-trackbalises allows to reduce this error. Future systems will be based on on-boardlocalisation solutions with GNSS receivers. It will allow the development ofnew concepts for moving blocks, virtual coupling and automation. Its use fortrain integrity is also investigated. But the environmental conditions of trackand surroundings configuration, i.e, tunnels, dense urban areas or vegetationoften degrade positioning performance and thus its efficiency and safety.Indeed, GNSS satellites are moving and their visibility (availability andrelative position from the receiver) vary with time. Moreover, for optimalperformance, the system requires open sky environments, which are the cases ofmost of the aeronautical uses but not of train uses. Trains often circulate inareas where signal reception can be disturbed (multipath, intentional orunintentional interferences) and thus, performances degraded. If manyprogresses have been made in the past years to develop more robust receivers[Puccitelli, 2022], multi-sensor solutions [CLUG website] or missing tools suchas Digital Maps [Crespillo, 2023], in projects such as the Shift2Rail ProjectX2Rail-5 or CLUG, some questions remain and in particular related toperformance evaluation. How can we evaluate performances in a dynamicenvironment (train, satellite, obstacles)? How can we be sure that everyconfiguration has been tested? What is the impact of a failure (inaccuracy,missed detection) on operation? Some of these issues are addressed in theon-going R2DATO project funded by Europe's rail.</description>
      <author>example@mail.com (Juliette Marais, Quentin Mayolle, Martin Fasquelle, Vincent Tardif, Emilie Chéneau-Grehalle)</author>
      <guid isPermaLink="false">2410.18510v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Large Spatial Model: End-to-end Unposed Images to Semantic 3D</title>
      <link>http://arxiv.org/abs/2410.18956v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Website: https://largespatialmodel.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从有限数量的图像重建和理解3D结构是计算机视觉中的一个成熟问题，传统方法通常将这一任务拆分为多个子任务，涉及复杂的数据表示转换。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，旨在简化3D重建过程，提高处理效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;引入大型空间模型（LSM），直接将未定位的RGB图像处理为语义辐射场，同时通过Transformer架构集成全局几何信息，并结合局部上下文聚合和多尺度融合。&lt;h4&gt;主要发现&lt;/h4&gt;LSM能够在单一前馈操作中同时估计几何形状、外观和语义，并通过与语言互动生成多样的标签图。&lt;h4&gt;结论&lt;/h4&gt;LSM统一了多个3D视觉任务，实现了首次基于未定位图像的实时语义3D重建，显示出其在场景操控和数据稀缺情况下的有效性。&lt;h4&gt;总结&lt;/h4&gt;LSM通过简化处理流程和提高准确性，推动了3D重建技术的发展，具有较大的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing and understanding 3D structures from a limited number ofimages is a well-established problem in computer vision. Traditional methodsusually break this task into multiple subtasks, each requiring complextransformations between different data representations. For instance, densereconstruction through Structure-from-Motion (SfM) involves converting imagesinto key points, optimizing camera parameters, and estimating structures.Afterward, accurate sparse reconstructions are required for further densemodeling, which is subsequently fed into task-specific neural networks. Thismulti-step process results in considerable processing time and increasedengineering complexity.  In this work, we present the Large Spatial Model (LSM), which processesunposed RGB images directly into semantic radiance fields. LSM simultaneouslyestimates geometry, appearance, and semantics in a single feed-forwardoperation, and it can generate versatile label maps by interacting withlanguage at novel viewpoints. Leveraging a Transformer-based architecture, LSMintegrates global geometry through pixel-aligned point maps. To enhance spatialattribute regression, we incorporate local context aggregation with multi-scalefusion, improving the accuracy of fine local details. To tackle the scarcity oflabeled 3D semantic data and enable natural language-driven scene manipulation,we incorporate a pre-trained 2D language-based segmentation model into a3D-consistent semantic feature field. An efficient decoder then parameterizes aset of semantic anisotropic Gaussians, facilitating supervised end-to-endlearning. Extensive experiments across various tasks show that LSM unifiesmultiple 3D vision tasks directly from unposed images, achieving real-timesemantic 3D reconstruction for the first time.</description>
      <author>example@mail.com (Zhiwen Fan, Jian Zhang, Wenyan Cong, Peihao Wang, Renjie Li, Kairun Wen, Shijie Zhou, Achuta Kadambi, Zhangyang Wang, Danfei Xu, Boris Ivanovic, Marco Pavone, Yue Wang)</author>
      <guid isPermaLink="false">2410.18956v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Generation of synthetic financial time series by diffusion models</title>
      <link>http://arxiv.org/abs/2410.18897v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;生成现实的合成金融时间序列具有重要的实际意义，但由于统计特性（如肥尾、波动聚类和季节性模式），这一过程面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来生成合成金融时间序列，以满足已知的统计特性。&lt;h4&gt;方法&lt;/h4&gt;使用去噪扩散概率模型（DDPMs），结合小波变换将多个时间序列（如股票价格、交易量和价差）转换为图像。&lt;h4&gt;主要发现&lt;/h4&gt;通过逆小波变换，模型能够生成可以转化为现实时间序列的图像，并且满足统计特性。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法有效地解决了合成金融时间序列生成中的挑战，并能够满足重要的统计特性。&lt;h4&gt;总结&lt;/h4&gt;利用去噪扩散模型和小波变换的结合，为生成合成金融时间序列提供了一种新的有效途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite its practical significance, generating realistic synthetic financialtime series is challenging due to statistical properties known as stylizedfacts, such as fat tails, volatility clustering, and seasonality patterns.Various generative models, including generative adversarial networks (GANs) andvariational autoencoders (VAEs), have been employed to address this challenge,although no model yet satisfies all the stylized facts. We alternativelypropose utilizing diffusion models, specifically denoising diffusionprobabilistic models (DDPMs), to generate synthetic financial time series. Thisapproach employs wavelet transformation to convert multiple time series (intoimages), such as stock prices, trading volumes, and spreads. Given theseconverted images, the model gains the ability to generate images that can betransformed back into realistic time series by inverse wavelet transformation.We demonstrate that our proposed approach satisfies stylized facts.</description>
      <author>example@mail.com (Tomonori Takahashi, Takayuki Mizuno)</author>
      <guid isPermaLink="false">2410.18897v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>ANAVI: Audio Noise Awareness using Visuals of Indoor environments for NAVIgation</title>
      <link>http://arxiv.org/abs/2410.18932v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8th Conference on Robot Learning (CoRL) 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类对自身产生的噪音及其对周围环境的影响有自然意识，而机器人目前缺乏这种意识。&lt;h4&gt;目的&lt;/h4&gt;提高机器人在路径规划中对噪音的感知能力，使其能够在安静的环境中导航。&lt;h4&gt;方法&lt;/h4&gt;通过室内环境的视觉观察训练机器人被动感知噪音的响度，生成不同听众位置的声音数据，并训练声学噪声预测器（ANP）。&lt;h4&gt;主要发现&lt;/h4&gt;结合ANP与动作声学后，展示了在不同环境噪音约束下的实验结果，使用了轮式和腿式机器人（Hello Robot Stretch和Unitree Go2）。&lt;h4&gt;结论&lt;/h4&gt;通过视觉信息，机器人能够更好地遵循环境中的噪音限制，从而实现更安静的导航。&lt;h4&gt;总结&lt;/h4&gt;本研究为机器人在室内环境中实现噪音意识提供了一种新方法，提升了其在复杂环境中的适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Audio Noise Awareness using Visuals of Indoors for NAVIgation forquieter robot path planning. While humans are naturally aware of the noise theymake and its impact on those around them, robots currently lack this awareness.A key challenge in achieving audio awareness for robots is estimating how loudwill the robot's actions be at a listener's location? Since sound depends uponthe geometry and material composition of rooms, we train the robot to passivelyperceive loudness using visual observations of indoor environments. To thisend, we generate data on how loud an 'impulse' sounds at different listenerlocations in simulated homes, and train our Acoustic Noise Predictor (ANP).Next, we collect acoustic profiles corresponding to different actions fornavigation. Unifying ANP with action acoustics, we demonstrate experiments withwheeled (Hello Robot Stretch) and legged (Unitree Go2) robots so that theserobots adhere to the noise constraints of the environment. See code and data athttps://anavi-corl24.github.io/</description>
      <author>example@mail.com (Vidhi Jain, Rishi Veerapaneni, Yonatan Bisk)</author>
      <guid isPermaLink="false">2410.18932v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Impact of 3D LiDAR Resolution in Graph-based SLAM Approaches: A Comparative Study</title>
      <link>http://arxiv.org/abs/2410.17171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been accepted for publication in ROBOT24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;SLAM是自主系统在复杂环境中可靠定位的关键组件，主要依赖于相机或LiDAR技术。&lt;h4&gt;目的&lt;/h4&gt;调查城市环境中基于3D LiDAR的Graph-SLAM方法，比较它们的优缺点和局限性。&lt;h4&gt;方法&lt;/h4&gt;评估SC-LeGO-LOAM、SC-LIO-SAM、Cartographer和HDL-Graph在真实城市环境中的表现，使用KITTI里程计数据集和AUTONOMOS-LABS新数据集。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果通过定量指标和定性地图进行报告，评估了不同LiDAR分辨率（64与128通道）的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;现代3D LiDAR方法在城市环境中表现出色，但仍存在局限性，需要进一步研究和改进。&lt;h4&gt;总结&lt;/h4&gt;本研究为3D LiDAR-based SLAM方法提供了系统的比较分析，强调了其在城市环境中的应用潜力及相关挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous Localization and Mapping (SLAM) is a key component of autonomoussystems operating in environments that require a consistent map for reliablelocalization. SLAM has been a widely studied topic for decades with most of thesolutions being camera or LiDAR based. Early LiDAR-based approaches primarilyrelied on 2D data, whereas more recent frameworks use 3D data. In this work, wesurvey recent 3D LiDAR-based Graph-SLAM methods in urban environments, aimingto compare their strengths, weaknesses, and limitations. Additionally, weevaluate their robustness regarding the LiDAR resolution namely 64 $vs$ 128channels. Regarding SLAM methods, we evaluate SC-LeGO-LOAM, SC-LIO-SAM,Cartographer, and HDL-Graph on real-world urban environments using the KITTIodometry dataset (a LiDAR with 64-channels only) and a new dataset(AUTONOMOS-LABS). The latter dataset, collected using instrumented vehiclesdriving in Berlin suburban area, comprises both 64 and 128 LiDARs. Theexperimental results are reported in terms of quantitative `metrics' andcomplemented by qualitative maps.</description>
      <author>example@mail.com (J. Jorge, T. Barros, C. Premebida, M. Aleksandrov, D. Goehring, U. J. Nunes)</author>
      <guid isPermaLink="false">2410.17171v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>DMVC: Multi-Camera Video Compression Network aimed at Improving Deep Learning Accuracy</title>
      <link>http://arxiv.org/abs/2410.18400v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在视频数据普遍存在的时代，传统视频压缩方法主要关注人类视觉感知。&lt;h4&gt;目的&lt;/h4&gt;开发一种创新的视频压缩框架，以服务于机器学习应用，重点保留深度学习所需的语义信息。&lt;h4&gt;方法&lt;/h4&gt;该框架采用批处理方式，能够同时处理多个视频流，并具备轻量级和高精度两种重建模式。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该框架在不同数据集上（如城市监控和自动驾驶导航）保持或提高了机器学习任务的准确性，同时实现了显著的数据压缩。&lt;h4&gt;结论&lt;/h4&gt;该突破性技术为更智能、可扩展的视频分析系统铺平了道路，具有广泛的应用潜力，从智慧城市基础设施到自主系统，建立了视频压缩与机器学习集成的新基准。&lt;h4&gt;总结&lt;/h4&gt;该视频压缩框架在提升机器学习效率的同时，优化了数据处理，具有重要的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a cutting-edge video compression framework tailored for the ageof ubiquitous video data, uniquely designed to serve machine learningapplications. Unlike traditional compression methods that prioritize humanvisual perception, our innovative approach focuses on preserving semanticinformation critical for deep learning accuracy, while efficiently reducingdata size. The framework operates on a batch basis, capable of handlingmultiple video streams simultaneously, thereby enhancing scalability andprocessing efficiency. It features a dual reconstruction mode: lightweight forreal-time applications requiring swift responses, and high-precision forscenarios where accuracy is crucial. Based on a designed deep learningalgorithms, it adeptly segregates essential information from redundancy,ensuring machine learning tasks are fed with data of the highest relevance. Ourexperimental results, derived from diverse datasets including urbansurveillance and autonomous vehicle navigation, showcase DMVC's superiority inmaintaining or improving machine learning task accuracy, while achievingsignificant data compression. This breakthrough paves the way for smarter,scalable video analysis systems, promising immense potential across variousapplications from smart city infrastructure to autonomous systems, establishinga new benchmark for integrating video compression with machine learning.</description>
      <author>example@mail.com (Huan Cui, Qing Li, Hanling Wang, Yong jiang)</author>
      <guid isPermaLink="false">2410.18400v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Applying Neural Monte Carlo Tree Search to Unsignalized Multi-intersection Scheduling for Autonomous Vehicles</title>
      <link>http://arxiv.org/abs/2410.18786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;动态调度自主系统对共享资源的访问是一项具有挑战性的问题，属于NP难题。&lt;h4&gt;目的&lt;/h4&gt;解决在高度动态系统中，如何在强安全和时间约束下调度车辆通过无信号交叉口的访问。&lt;h4&gt;方法&lt;/h4&gt;应用神经蒙特卡洛树搜索（NMCTS）来调度穿越无信号交叉口的车辆队列，同时引入转换模型将潜在冲突的道路空间预留请求映射为类似棋盘游戏的问题。&lt;h4&gt;主要发现&lt;/h4&gt;在繁忙的单个四路无信号交叉口仿真中，PNMCTS解决了95%的未见场景，轻交通情况下交叉时间减少了43%，重交通情况下减少了52%。&lt;h4&gt;结论&lt;/h4&gt;在3x3多交叉口网络中，PNMCTS保持了轻交通下的自由流动，并在重交通情况下，平均旅行时间比现有基于RL的交通信号控制器短74.5%，总通行能力提高了16%。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了PNMCTS在复杂交通调度中的有效性，显著提升了交叉口的通行效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic scheduling of access to shared resources by autonomous systems is achallenging problem, characterized as being NP-hard. The complexity of thistask leads to a combinatorial explosion of possibilities in highly dynamicsystems where arriving requests must be continuously scheduled subject tostrong safety and time constraints. An example of such a system is anunsignalized intersection, where automated vehicles' access to potentialconflict zones must be dynamically scheduled. In this paper, we apply NeuralMonte Carlo Tree Search (NMCTS) to the challenging task of scheduling platoonsof vehicles crossing unsignalized intersections. Crucially, we introduce atransformation model that maps successive sequences of potentially conflictingroad-space reservation requests from platoons of vehicles into a series ofboard-game-like problems and use NMCTS to search for solutions representingoptimal road-space allocation schedules in the context of past allocations. Tooptimize search, we incorporate a prioritized re-sampling method with parallelNMCTS (PNMCTS) to improve the quality of training data. To optimize training, acurriculum learning strategy is used to train the agent to scheduleprogressively more complex boards culminating in overlapping boards thatrepresent busy intersections. In a busy single four-way unsignalizedintersection simulation, PNMCTS solved 95\% of unseen scenarios, reducingcrossing time by 43\% in light and 52\% in heavy traffic versus first-in,first-out control. In a 3x3 multi-intersection network, the proposed methodmaintained free-flow in light traffic when all intersections are under controlof PNMCTS and outperformed state-of-the-art RL-based traffic-light controllersin average travel time by 74.5\% and total throughput by 16\% in heavy traffic.</description>
      <author>example@mail.com (Yucheng Shi, Wenlong Wang, Xiaowen Tao, Ivana Dusparic, Vinny Cahill)</author>
      <guid isPermaLink="false">2410.18786v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Learning to Look: Seeking Information for Decision Making via Policy Factorization</title>
      <link>http://arxiv.org/abs/2410.18964v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Website: https://robin-lab.cs.utexas.edu/learning2look/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多机器人操作任务需要主动或互动探索行为才能成功完成，这在身体化领域中尤为普遍。&lt;h4&gt;目的&lt;/h4&gt;识别并解决需要信息搜索的任务，提出新的问题类型：因子化上下文马尔可夫决策过程。&lt;h4&gt;方法&lt;/h4&gt;提出DISaM，一种双策略解决方案，包含信息搜索策略和信息接收策略，分别用于探索环境和利用上下文实现操作目标。&lt;h4&gt;主要发现&lt;/h4&gt;DISaM在五个需要信息搜索行为的操作任务中表现优异，超越现有方法，验证了其在仿真和现实世界中的能力。&lt;h4&gt;结论&lt;/h4&gt;DISaM有效平衡了探索和利用，能够根据操作策略的不确定性调整行为。&lt;h4&gt;总结&lt;/h4&gt;该研究展示了通过因子化上下文马尔可夫决策过程改进机器人操作任务的信息搜索能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many robot manipulation tasks require active or interactive explorationbehavior in order to be performed successfully. Such tasks are ubiquitous inembodied domains, where agents must actively search for the informationnecessary for each stage of a task, e.g., moving the head of the robot to findinformation relevant to manipulation, or in multi-robot domains, where onescout robot may search for the information that another robot needs to makeinformed decisions. We identify these tasks with a new type of problem,factorized Contextual Markov Decision Processes, and propose DISaM, adual-policy solution composed of an information-seeking policy that exploresthe environment to find the relevant contextual information and aninformation-receiving policy that exploits the context to achieve themanipulation goal. This factorization allows us to train both policiesseparately, using the information-receiving one to provide reward to train theinformation-seeking policy. At test time, the dual agent balances explorationand exploitation based on the uncertainty the manipulation policy has on whatthe next best action is. We demonstrate the capabilities of our dual policysolution in five manipulation tasks that require information-seeking behaviors,both in simulation and in the real-world, where DISaM significantly outperformsexisting methods. More information athttps://robin-lab.cs.utexas.edu/learning2look/.</description>
      <author>example@mail.com (Shivin Dass, Jiaheng Hu, Ben Abbatematteo, Peter Stone, Roberto Martín-Martín)</author>
      <guid isPermaLink="false">2410.18964v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>AG-SLAM: Active Gaussian Splatting SLAM</title>
      <link>http://arxiv.org/abs/2410.17422v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，辐射场场景表示（包括3D Gaussian Splatting）在SLAM和探索中得到广泛应用，但主动规划机器人探索的轨迹仍未被充分研究。&lt;h4&gt;目的&lt;/h4&gt;提出AG-SLAM，这是第一个利用3D Gaussian Splatting进行在线场景重建的主动SLAM系统。&lt;h4&gt;方法&lt;/h4&gt;该方法利用Fisher信息来平衡最大化环境信息增益和最小化定位误差成本的双重目标。&lt;h4&gt;主要发现&lt;/h4&gt;在Gibson和Habitat-Matterport 3D数据集上的实验表明，该方法实现了最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;AG-SLAM有效降低了SLAM系统在真实世界应用中的相机跟踪失败风险。&lt;h4&gt;总结&lt;/h4&gt;AG-SLAM通过创新的处理方法提升了机器人在复杂环境中的探索能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present AG-SLAM, the first active SLAM system utilizing 3D GaussianSplatting (3DGS) for online scene reconstruction. In recent years, radiancefield scene representations, including 3DGS have been widely used in SLAM andexploration, but actively planning trajectories for robotic exploration isstill unvisited. In particular, many exploration methods assume preciselocalization and thus do not mitigate the significant risk of constructing atrajectory, which is difficult for a SLAM system to operate on. This can causecamera tracking failure and lead to failures in real-world roboticapplications. Our method leverages Fisher Information to balance the dualobjectives of maximizing the information gain for the environment whileminimizing the cost of localization errors. Experiments conducted on the Gibsonand Habitat-Matterport 3D datasets demonstrate state-of-the-art results of theproposed method.</description>
      <author>example@mail.com (Wen Jiang, Boshu Lei, Katrina Ashton, Kostas Daniilidis)</author>
      <guid isPermaLink="false">2410.17422v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Self-Improving Autonomous Underwater Manipulation</title>
      <link>http://arxiv.org/abs/2410.18969v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://aquabot.cs.columbia.edu/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;水下机器人操作面临复杂流体动力学和非结构化环境的挑战，导致大多数操作系统依赖人类遥控。&lt;h4&gt;目的&lt;/h4&gt;介绍AquaBot，一个结合人类示范行为克隆与自我学习优化的完全自主操控系统，旨在提升操作性能。&lt;h4&gt;方法&lt;/h4&gt;通过大量实地实验，展示AquaBot在各种操作任务中的多样性，包括物体抓取、垃圾分类和救援检索。&lt;h4&gt;主要发现&lt;/h4&gt;AquaBot的自我优化策略在速度上比人类操作员提高了41%。&lt;h4&gt;结论&lt;/h4&gt;AquaBot是向自主和自我改进水下操作系统迈出的重要一步。&lt;h4&gt;总结&lt;/h4&gt;我们开源了AquaBot的硬件和软件实现细节。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Underwater robotic manipulation faces significant challenges due to complexfluid dynamics and unstructured environments, causing most manipulation systemsto rely heavily on human teleoperation. In this paper, we introduce AquaBot, afully autonomous manipulation system that combines behavior cloning from humandemonstrations with self-learning optimization to improve beyond humanteleoperation performance. With extensive real-world experiments, wedemonstrate AquaBot's versatility across diverse manipulation tasks, includingobject grasping, trash sorting, and rescue retrieval. Our real-worldexperiments show that AquaBot's self-optimized policy outperforms a humanoperator by 41% in speed. AquaBot represents a promising step towardsautonomous and self-improving underwater manipulation systems. We open-sourceboth hardware and software implementation details.</description>
      <author>example@mail.com (Ruoshi Liu, Huy Ha, Mengxue Hou, Shuran Song, Carl Vondrick)</author>
      <guid isPermaLink="false">2410.18969v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>CAST: Corpus-Aware Self-similarity Enhanced Topic modelling</title>
      <link>http://arxiv.org/abs/2410.15136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;主题建模是一种重要的无监督机器学习技术，用于从大型文档集合中提取有价值的见解。&lt;h4&gt;目的&lt;/h4&gt;解决现有神经主题建模方法忽视候选中心词上下文细节的问题，减少主题词选择的不准确性。&lt;h4&gt;方法&lt;/h4&gt;提出CAST：基于语料库的自相似性增强主题建模，通过对候选中心词嵌入进行上下文化，并引入自相似性过滤无意义的标记。&lt;h4&gt;主要发现&lt;/h4&gt;自相似性在不同上下文中功能词嵌入的相似度显著低于主题词，表明自相似性是防止功能词作为候选主题词的有效指标。&lt;h4&gt;结论&lt;/h4&gt;该方法显著提高了生成主题的连贯性和多样性，以及处理噪声数据的能力。&lt;h4&gt;实验结果&lt;/h4&gt;在新闻基准数据集和一个Twitter数据集上的实验表明，该方法在生成连贯、多样化主题以及处理噪声数据方面优于强基线模型。&lt;h4&gt;总结&lt;/h4&gt;CAST方法为主题建模提供了新的思路，克服了现有方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Topic modelling is a pivotal unsupervised machine learning technique forextracting valuable insights from large document collections. Existing neuraltopic modelling methods often encode contextual information of documents, whileignoring contextual details of candidate centroid words, leading to theinaccurate selection of topic words due to the contextualization gap. Inparallel, it is found that functional words are frequently selected overtopical words. To address these limitations, we introduce CAST: Corpus-AwareSelf-similarity Enhanced Topic modelling, a novel topic modelling method thatbuilds upon candidate centroid word embeddings contextualized on the dataset,and a novel self-similarity-based method to filter out less meaningful tokens.Inspired by findings in contrastive learning that self-similarities offunctional token embeddings in different contexts are much lower than topicaltokens, we find self-similarity to be an effective metric to prevent functionalwords from acting as candidate topic words. Our approach significantly enhancesthe coherence and diversity of generated topics, as well as the topic model'sability to handle noisy data. Experiments on news benchmark datasets and oneTwitter dataset demonstrate the method's superiority in generating coherent,diverse topics, and handling noisy data, outperforming strong baselines.</description>
      <author>example@mail.com (Yanan Ma, Chenghao Xiao, Chenhan Yuan, Sabine N van der Veer, Lamiece Hassan, Chenghua Lin, Goran Nenadic)</author>
      <guid isPermaLink="false">2410.15136v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>EPIC: A Lightweight LiDAR-Based UAV Exploration Framework for Large-Scale Scenarios</title>
      <link>http://arxiv.org/abs/2410.14203v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主探索是无人机应用中的一个基本问题，尤其是基于LiDAR的探索因其生成高精度点云地图的能力而受到关注。&lt;h4&gt;目的&lt;/h4&gt;提出EPIC框架，以解决现有探索方法对额外环境表示的依赖，简化无人机在大规模环境中的探索过程。&lt;h4&gt;方法&lt;/h4&gt;EPIC框架直接利用点云数据，采用新颖的观察地图，消除对全球占用网格地图的需求，并提出基于点云的增量拓扑图构建方法，实现实时路径规划。&lt;h4&gt;主要发现&lt;/h4&gt;EPIC框架在进行探索时，相比于现有方法显著减少了内存消耗和计算时间，并且实现了更快速的探索。&lt;h4&gt;结论&lt;/h4&gt;EPIC在大规模环境下提供了灵活且节能的轨迹生成，展现出优于现有尖端方法的性能。&lt;h4&gt;总结&lt;/h4&gt;EPIC是一个轻量级的LiDAR无人机探索框架，能够高效地进行自主探索，减少资源消耗。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous exploration is a fundamental problem for various applications ofunmanned aerial vehicles (UAVs). Recently, LiDAR-based exploration has gainedsignificant attention due to its ability to generate high-precision point cloudmaps of large-scale environments. While the point clouds are inherentlyinformative for navigation, many existing exploration methods still rely onadditional, often expensive, environmental representations. This reliance stemsfrom two main reasons: the need for frontier detection or information gaincomputation, which typically depends on memory-intensive occupancy grid maps,and the high computational complexity of path planning directly on pointclouds, primarily due to costly collision checking. To address theselimitations, we present EPIC, a lightweight LiDAR-based UAV explorationframework that directly exploits point cloud data to explore large-scaleenvironments. EPIC introduces a novel observation map derived directly from thequality of point clouds, eliminating the need for global occupancy grid mapswhile preserving comprehensive exploration capabilities. We also propose anincremental topological graph construction method operating directly on pointclouds, enabling real-time path planning in large-scale environments.Leveraging these components, we build a hierarchical planning framework thatgenerates agile and energy-efficient trajectories, achieving significantlyreduced memory consumption and computation time compared to most existingmethods. Extensive simulations and real-world experiments demonstrate that EPICachieves faster exploration while significantly reducing memory consumptioncompared to state-of-the-art methods.</description>
      <author>example@mail.com (Shuang Geng, Zelin Ning, Fu Zhang, Boyu Zhou)</author>
      <guid isPermaLink="false">2410.14203v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>PReP: Efficient context-based shape retrieval for missing parts</title>
      <link>http://arxiv.org/abs/2410.14245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;研究点云领域中形状部分检索的问题。&lt;h4&gt;目的&lt;/h4&gt;探索在缺少查询对象时如何进行形状部分检索。&lt;h4&gt;方法&lt;/h4&gt;提出了形状部分检索管道（PReP），结合度量学习技术和训练分类模型，从数据库中评估潜在替换部件的适用性。&lt;h4&gt;主要发现&lt;/h4&gt;通过创新的逐步训练程序，该方法能够仅依靠形状上下文识别合适的部件，且具有低参数量和计算要求。&lt;h4&gt;结论&lt;/h4&gt;PReP可以在几秒钟内处理潜在数万件备件，适用于循环经济的应用场景。&lt;h4&gt;挑战&lt;/h4&gt;详细记录了与此任务相关的独特挑战，并识别了解决这些挑战的设计选择。&lt;h4&gt;总结&lt;/h4&gt;PReP提供了一种高效的方式来进行形状部分检索，推动了相关领域的研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper we study the problem of shape part retrieval in the point clouddomain. Shape retrieval methods in the literature rely on the presence of anexisting query object, but what if the part we are looking for is notavailable? We present Part Retrieval Pipeline (PReP), a pipeline thatcreatively utilizes metric learning techniques along with a trainedclassification model to measure the suitability of potential replacement partsfrom a database, as part of an application scenario targeting circular economy.Through an innovative training procedure with increasing difficulty, it is ableto learn to recognize suitable parts relying only on shape context. Thanks toits low parameter size and computational requirements, it can be used to sortthrough a warehouse of potentially tens of thousand of spare parts in just afew seconds. We also establish an alternative baseline approach to compareagainst, and extensively document the unique challenges associated with thistask, as well as identify the design choices to solve them.</description>
      <author>example@mail.com (Vlassis Fotis, Ioannis Romanelis, Georgios Mylonas, Athanasios Kalogeras, Konstantinos Moustakas)</author>
      <guid isPermaLink="false">2410.14245v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>LAC: Graph Contrastive Learning with Learnable Augmentation in Continuous Space</title>
      <link>http://arxiv.org/abs/2410.15355v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图对比学习框架在生成高质量节点表示方面取得了成功，但现有的高效数据增强方法和理想预训练任务的研究仍然有限，导致无监督情况下节点表示的效果不佳。&lt;h4&gt;目的&lt;/h4&gt;提出LAC，一个具有可学习数据增强的图对比学习框架。&lt;h4&gt;方法&lt;/h4&gt;引入一种连续视图增强器，应用掩蔽拓扑增强模块和跨通道特征增强模块，以适应性地增强拓扑信息和特征信息，且确保增强过程避免维度崩溃。&lt;h4&gt;主要发现&lt;/h4&gt;通过信息论原理InfoBal和相应的预训练任务，增强器能够在不同视图中保持代表性信息的一致性，同时最大化视图间的多样性。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，LAC显著优于现有的最先进框架。&lt;h4&gt;总结&lt;/h4&gt;LAC通过改进的数据增强和预训练任务，提升了图对比学习在无监督设置下的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Contrastive Learning frameworks have demonstrated success in generatinghigh-quality node representations.  The existing research on efficient data augmentation methods and idealpretext tasks for graph contrastive learning remains limited, resulting insuboptimal node representation in the unsupervised setting.  In this paper, we introduce LAC, a graph contrastive learning framework withlearnable data augmentation in an orthogonal continuous space. To capture therepresentative information in the graph data during augmentation, we introducea continuous view augmenter, that applies both a masked topology augmentationmodule and a cross-channel feature augmentation module to adaptively augmentthe topological information and the feature information within an orthogonalcontinuous space, respectively. The orthogonal nature of continuous spaceensures that the augmentation process avoids dimension collapse.  To enhance the effectiveness of pretext tasks, we propose aninformation-theoretic principle named InfoBal and introduce correspondingpretext tasks. These tasks enable the continuous view augmenter to maintainconsistency in the representative information across views while maximizingdiversity between views, and allow the encoder to fully utilize therepresentative information in the unsupervised setting. Our experimentalresults show that LAC significantly outperforms the state-of-the-artframeworks.</description>
      <author>example@mail.com (Zhenyu Lin, Hongzheng Li, Yingxia Shao, Guanhua Ye, Yawen Li, Quanqing Xu)</author>
      <guid isPermaLink="false">2410.15355v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Sim2real Cattle Joint Estimation in 3D point clouds</title>
      <link>http://arxiv.org/abs/2410.14419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;了解牛的福祉在农业中至关重要，牛的体型和关节活动提供了关于其福利的重要信息。&lt;h4&gt;目的&lt;/h4&gt;构建一个专门为牛设计的3D体态估计数据集。&lt;h4&gt;方法&lt;/h4&gt;利用数字艺术家的专业知识，使用单一动画3D模型表示多种牛的姿势，并通过增强模型形状来缩小虚拟与现实之间的差距。&lt;h4&gt;主要发现&lt;/h4&gt;使用注释模型训练深度学习框架，能够仅基于外部表面曲率估计内部关节，并通过比较实际牛群的链接长度验证关节提取的稳健性。&lt;h4&gt;结论&lt;/h4&gt;利用估计的关节预测实际牛群的髋部高度，扩展了该方法在改善牛监测实践中的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究通过构建数据集和深度学习模型，为牛的福祉监测提供了一种新方法，具有实际应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding the well-being of cattle is crucial in various agriculturalcontexts. Cattle's body shape and joint articulation carry significantinformation about their welfare, yet acquiring comprehensive datasets for 3Dbody pose estimation presents a formidable challenge. This study delves intothe construction of such a dataset specifically tailored for cattle. Leveragingthe expertise of digital artists, we use a single animated 3D model torepresent diverse cattle postures. To address the disparity between virtual andreal-world data, we augment the 3D model's shape to encompass a range ofpotential body appearances, thereby narrowing the "sim2real" gap. We use theseannotated models to train a deep-learning framework capable of estimatinginternal joints solely based on external surface curvature. Our contribution isspecifically the use of geodesic distance over the surface manifold, coupledwith multilateration to extract joints in a semantic keypoint detectionencoder-decoder architecture. We demonstrate the robustness of joint extractionby comparing the link lengths extracted on real cattle mobbing and walkingwithin a race. Furthermore, inspired by the established allometric relationshipbetween bone length and the overall height of mammals, we utilise the estimatedjoints to predict hip height within a real cattle dataset, extending theutility of our approach to offer insights into improving cattle monitoringpractices.</description>
      <author>example@mail.com (Okour Mohammad, Falque Raphael, Alempijevic Alen)</author>
      <guid isPermaLink="false">2410.14419v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Conditional Uncertainty Quantification for Tensorized Topological Neural Networks</title>
      <link>http://arxiv.org/abs/2410.15241v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2401.12007&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）已成为分析图结构数据的标准，利用消息传递技术捕捉结构和节点特征信息。&lt;h4&gt;目的&lt;/h4&gt;解决GNNs在不交换的图结构数据中产生的不确定性估计的统计可靠性问题，同时减少图分类任务中的标签预测集大小。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新方法——合规化张量拓扑神经网络（CF-T2NN），通过张量分解和拓扑知识学习来处理决策过程中的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;CF-T2NN在10个真实数据集上的实证验证显示，其在多个图基准测试中优于多种最先进方法。&lt;h4&gt;结论&lt;/h4&gt;本研究不仅增强了GNN框架的鲁棒性和不确定性量化能力，还为图结构数据分析设定了新的可靠性和精确性标准。&lt;h4&gt;总结&lt;/h4&gt;CF-T2NN提供了一种更细致的理解和处理预测不确定性的方法，提高了神经网络结果的可靠性和可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have become the de facto standard for analyzinggraph-structured data, leveraging message-passing techniques to capture bothstructural and node feature information. However, recent studies have raisedconcerns about the statistical reliability of uncertainty estimates produced byGNNs. This paper addresses this crucial challenge by introducing a noveltechnique for quantifying uncertainty in non-exchangeable graph-structureddata, while simultaneously reducing the size of label prediction sets in graphclassification tasks. We propose Conformalized Tensor-based Topological NeuralNetworks (CF-T2NN), a new approach for rigorous prediction inference overgraphs. CF-T2NN employs tensor decomposition and topological knowledge learningto navigate and interpret the inherent uncertainty in decision-makingprocesses. This method enables a more nuanced understanding and handling ofprediction uncertainties, enhancing the reliability and interpretability ofneural network outcomes. Our empirical validation, conducted across 10real-world datasets, demonstrates the superiority of CF-T2NN over a wide arrayof state-of-the-art methods on various graph benchmarks. This work not onlyenhances the GNN framework with robust uncertainty quantification capabilitiesbut also sets a new standard for reliability and precision in graph-structureddata analysis.</description>
      <author>example@mail.com (Yujia Wu, Bo Yang, Yang Zhao, Elynn Chen, Yuzhou Chen, Zheshi Zheng)</author>
      <guid isPermaLink="false">2410.15241v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Graph Optimality-Aware Stochastic LiDAR Bundle Adjustment with Progressive Spatial Smoothing</title>
      <link>http://arxiv.org/abs/2410.14565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大规模LiDAR束调整（LBA）是提高传感器方向和点云精度的基础任务，特别是在复杂场景中使用低成本3D传感器进行3D建图的情况下。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，以克服现有LBA方法在鲁棒性、效率和可扩展性方面的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种图最优性感知的随机优化方案与渐进空间平滑相结合的PSS-GOSO方法，包括鲁棒LiDAR特征关联和图的稀疏化等步骤。&lt;h4&gt;主要发现&lt;/h4&gt;PSS-GOSO在各种场景中表现优越，相较于现有方法具有更好的鲁棒性和效率。&lt;h4&gt;结论&lt;/h4&gt;PSS-GOSO有效解决了低成本传感器在初始姿态估计不可靠时的精确度问题，适用于大规模LBA。&lt;h4&gt;总结&lt;/h4&gt;通过验证PSS-GOSO在不同平台捕获的多样场景，展示了其优越的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale LiDAR Bundle Adjustment (LBA) for refining sensor orientation andpoint cloud accuracy simultaneously is a fundamental task in photogrammetry androbotics, particularly as low-cost 3D sensors are increasingly used for 3Dmapping in complex scenes. Unlike pose-graph-based methods that rely solely onpairwise relationships between LiDAR frames, LBA leverages raw LiDARcorrespondences to achieve more precise results, especially when initial poseestimates are unreliable for low-cost sensors. However, existing LBA methodsface challenges such as simplistic planar correspondences, extensiveobservations, and dense normal matrices in the least-squares problem, whichlimit robustness, efficiency, and scalability. To address these issues, wepropose a Graph Optimality-aware Stochastic Optimization scheme withProgressive Spatial Smoothing, namely PSS-GOSO, to achieve \textit{robust},\textit{efficient}, and \textit{scalable} LBA. The Progressive SpatialSmoothing (PSS) module extracts \textit{robust} LiDAR feature associationexploiting the prior structure information obtained by the polynomial smoothkernel. The Graph Optimality-aware Stochastic Optimization (GOSO) module firstsparsifies the graph according to optimality for an \textit{efficient}optimization. GOSO then utilizes stochastic clustering and graphmarginalization to solve the large-scale state estimation problem for a\textit{scalable} LBA. We validate PSS-GOSO across diverse scenes captured byvarious platforms, demonstrating its superior performance compared to existingmethods.</description>
      <author>example@mail.com (Jianping Li, Thien-Minh Nguyen, Muqing Cao, Shenghai Yuan, Tzu-Yi Hung, Lihua Xie)</author>
      <guid isPermaLink="false">2410.14565v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Generative Design of Functional Metal Complexes Utilizing the Internal Knowledge of Large Language Models</title>
      <link>http://arxiv.org/abs/2410.18136v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;设计功能性过渡金属复合物（TMCs）面临金属和配体的广泛搜索空间，需有效的优化策略。&lt;h4&gt;目的&lt;/h4&gt;将大语言模型（LLMs）集成到进化优化框架中，应用于单目标和多目标优化。&lt;h4&gt;方法&lt;/h4&gt;采用LLM-EO框架，利用LLMs在预训练期间获得的化学知识进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;LLM-EO在性能上超过传统遗传算法，能够识别出20个具有最大HOMO-LUMO间隙的TMCs中的8个，仅提议200个候选者。&lt;h4&gt;结论&lt;/h4&gt;LLMs通过结合内部知识和外部化学数据提出新的配体和TMCs，显示出在化学和材料设计中的广泛应用潜力。&lt;h4&gt;总结&lt;/h4&gt;LLM-EO提供了前所未有的灵活性，简化了多目标优化过程，预示着LLM在化学领域的广泛应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Designing functional transition metal complexes (TMCs) faces challenges dueto the vast search space of metals and ligands, requiring efficientoptimization strategies. Traditional genetic algorithms (GAs) are commonlyused, employing random mutations and crossovers driven by explicit mathematicalobjectives to explore this space. Transferring knowledge between different GAtasks, however, is difficult. We integrate large language models (LLMs) intothe evolutionary optimization framework (LLM-EO) and apply it in both single-and multi-objective optimization for TMCs. We find that LLM-EO surpassestraditional GAs by leveraging the chemical knowledge of LLMs gained duringtheir extensive pretraining. Remarkably, without supervised fine-tuning, LLMsutilize the full historical data from optimization processes, outperformingthose focusing only on top-performing TMCs. LLM-EO successfully identifieseight of the top-20 TMCs with the largest HOMO-LUMO gaps by proposing only 200candidates out of a 1.37 million TMCs space. Through prompt engineering usingnatural language, LLM-EO introduces unparalleled flexibility intomulti-objective optimizations, thereby circumventing the necessity forintricate mathematical formulations. As generative models, LLMs can suggest newligands and TMCs with unique properties by merging both internal knowledge andexternal chemistry data, thus combining the benefits of efficient optimizationand molecular generation. With increasing potential of LLMs as pretrainedfoundational models and new post-training inference strategies, we foreseebroad applications of LLM-based evolutionary optimization in chemistry andmaterials design.</description>
      <author>example@mail.com (Jieyu Lu, Zhangde Song, Qiyuan Zhao, Yuanqi Du, Yirui Cao, Haojun Jia, Chenru Duan)</author>
      <guid isPermaLink="false">2410.18136v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Tensor-Fused Multi-View Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.15247v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图对比学习（GCL）是一种有前景的方法，用于提高图神经网络（GNN）从无标签图结构数据中学习丰富表示的能力。&lt;h4&gt;目的&lt;/h4&gt;解决现有GCL模型在计算需求和特征利用方面的挑战，以更好地捕捉复杂的拓扑特征。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架——张量融合多视图图对比学习（TensorMV-GCL），整合了扩展持久同调（EPH）与GCL表示，促进多尺度特征提取。&lt;h4&gt;主要发现&lt;/h4&gt;TensorMV-GCL在分子、生物信息学和社交网络数据集上的实验中表现优越，在11个基准中，图分类任务超过了15种最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;TensorMV-GCL通过减少计算开销和增强拓扑特征的质量，提升了模型的鲁棒性，效果显著。&lt;h4&gt;总结&lt;/h4&gt;TensorMV-GCL为图对比学习提供了一种有效的解决方案，能够更全面地捕捉图的复杂特性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph contrastive learning (GCL) has emerged as a promising approach toenhance graph neural networks' (GNNs) ability to learn rich representationsfrom unlabeled graph-structured data. However, current GCL models facechallenges with computational demands and limited feature utilization, oftenrelying only on basic graph properties like node degrees and edge attributes.This constrains their capacity to fully capture the complex topologicalcharacteristics of real-world phenomena represented by graphs. To address theselimitations, we propose Tensor-Fused Multi-View Graph Contrastive Learning(TensorMV-GCL), a novel framework that integrates extended persistent homology(EPH) with GCL representations and facilitates multi-scale feature extraction.Our approach uniquely employs tensor aggregation and compression to fuseinformation from graph and topological features obtained from multipleaugmented views of the same graph. By incorporating tensor concatenation andcontraction modules, we reduce computational overhead by separating featuretensor aggregation and transformation. Furthermore, we enhance the quality oflearned topological features and model robustness through noise-injected EPH.Experiments on molecular, bioinformatic, and social network datasetsdemonstrate TensorMV-GCL's superiority, outperforming 15 state-of-the-artmethods in graph classification tasks across 9 out of 11 benchmarks whileachieving comparable results on the remaining two. The code for this paper ispublicly available at https://github.com/CS-SAIL/Tensor-MV-GCL.git.</description>
      <author>example@mail.com (Yujia Wu, Junyi Mo, Elynn Chen, Yuzhou Chen)</author>
      <guid isPermaLink="false">2410.15247v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Remote Sensing and Earth Observation: A Survey</title>
      <link>http://arxiv.org/abs/2410.16602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;遥感技术在地球观测、监测和解释中至关重要，广泛应用于地球科学、经济学和人道主义等领域。&lt;h4&gt;目的&lt;/h4&gt;开发更智能的遥感系统，解决复杂的地球环境和多样的传感器模态带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;系统性评审遥感基础模型（RSFMs）的新兴领域，包括其动机、基础概念、现有研究的分类和技术贡献。&lt;h4&gt;主要发现&lt;/h4&gt;大规模基础模型（FMs）在自然数据上表现优异，但在不同非光学模态的遥感数据上性能下降，激发了对RSFMs的兴趣。&lt;h4&gt;结论&lt;/h4&gt;需要进一步研究和开发RSFMs，以应对地球观测任务的复杂需求，涵盖地表、气氛和海洋。&lt;h4&gt;挑战&lt;/h4&gt;现有RSFM面临的数据集和技术贡献的局限性，需解决性能下降的问题。&lt;h4&gt;未来方向&lt;/h4&gt;提出未来的研究方向，以推动快速发展的遥感基础模型领域。&lt;h4&gt;总结&lt;/h4&gt;本调查系统地回顾了RSFMs领域，强调其在遥感技术中的重要性和发展潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote Sensing (RS) is a crucial technology for observing, monitoring, andinterpreting our planet, with broad applications across geoscience, economics,humanitarian fields, etc. While artificial intelligence (AI), particularly deeplearning, has achieved significant advances in RS, unique challenges persist indeveloping more intelligent RS systems, including the complexity of Earth'senvironments, diverse sensor modalities, distinctive feature patterns, varyingspatial and spectral resolutions, and temporal dynamics. Meanwhile, recentbreakthroughs in large Foundation Models (FMs) have expanded AI's potentialacross many domains due to their exceptional generalizability and zero-shottransfer capabilities. However, their success has largely been confined tonatural data like images and video, with degraded performance and even failuresfor RS data of various non-optical modalities. This has inspired growinginterest in developing Remote Sensing Foundation Models (RSFMs) to address thecomplex demands of Earth Observation (EO) tasks, spanning the surface,atmosphere, and oceans. This survey systematically reviews the emerging fieldof RSFMs. It begins with an outline of their motivation and background,followed by an introduction of their foundational concepts. It then categorizesand reviews existing RSFM studies including their datasets and technicalcontributions across Visual Foundation Models (VFMs), Visual-Language Models(VLMs), Large Language Models (LLMs), and beyond. In addition, we benchmarkthese models against publicly available datasets, discuss existing challenges,and propose future research directions in this rapidly evolving field.</description>
      <author>example@mail.com (Aoran Xiao, Weihao Xuan, Junjue Wang, Jiaxing Huang, Dacheng Tao, Shijian Lu, Naoto Yokoya)</author>
      <guid isPermaLink="false">2410.16602v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>JAMUN: Transferable Molecular Conformational Ensemble Generation with Walk-Jump Sampling</title>
      <link>http://arxiv.org/abs/2410.14621v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;蛋白质构象集对理解蛋白质功能和药物发现至关重要，尤其是在新型靶点如隐秘口袋的研究中。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的蛋白质Boltzmann分布采样方法。&lt;h4&gt;方法&lt;/h4&gt;介绍Walk-Jump加速分子集成方法与通用噪声（JAMUN），通过将Walk-Jump采样扩展到点云，显著提高采样速度。&lt;h4&gt;主要发现&lt;/h4&gt;JAMUN能够以传统分子动力学或最先进机器学习方法的数个数量级的速度生成集合，并能预测训练中未见的小肽稳定基。&lt;h4&gt;结论&lt;/h4&gt;JAMUN为高效采样蛋白质构象提供了一种新的方法，有助于药物发现。&lt;h4&gt;总结&lt;/h4&gt;JAMUN是一种突破性的工具，能够快速有效地生成蛋白质构象集，为理解蛋白质功能和药物研发提供支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conformational ensembles of protein structures are immensely important bothto understanding protein function, and for drug discovery in novel modalitiessuch as cryptic pockets. Current techniques for sampling ensembles arecomputationally inefficient, or do not transfer to systems outside theirtraining data. We present walk-Jump Accelerated Molecular ensembles withUniversal Noise (JAMUN), a step towards the goal of efficiently sampling theBoltzmann distribution of arbitrary proteins. By extending Walk-Jump Samplingto point clouds, JAMUN enables ensemble generation at orders of magnitudefaster rates than traditional molecular dynamics or state-of-the-art MLmethods. Further, JAMUN is able to predict the stable basins of small peptidesthat were not seen during training.</description>
      <author>example@mail.com (Ameya Daigavane, Bodhi P. Vani, Saeed Saremi, Joseph Kleinhenz, Joshua Rackers)</author>
      <guid isPermaLink="false">2410.14621v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Self-supervised contrastive learning performs non-linear system identification</title>
      <link>http://arxiv.org/abs/2410.14673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督学习（SSL）方法在多个任务和领域取得了巨大的成功。&lt;h4&gt;目的&lt;/h4&gt;探讨SSL与可识别表示学习之间的联系，并展示SSL在潜在空间中的系统识别能力。&lt;h4&gt;方法&lt;/h4&gt;提出DynCL框架，用于揭示线性、开关线性和非线性动态，在非线性观察模型下进行研究，并提供理论保证及实证验证。&lt;h4&gt;主要发现&lt;/h4&gt;SSL能够有效识别潜在空间中的动态系统，涵盖不同类型的动态特征。&lt;h4&gt;结论&lt;/h4&gt;SSL与潜在表示的真实生成因素之间存在联系，能够用于系统识别。&lt;h4&gt;总结&lt;/h4&gt;本研究深化了自监督学习与表示学习的关系，提供了一种新的方法框架DynCL，具备理论和实证支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/dynamical-inference/dyncl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) approaches have brought tremendous successacross many tasks and domains. It has been argued that these successes can beattributed to a link between SSL and identifiable representation learning:Temporal structure and auxiliary variables ensure that latent representationsare related to the true underlying generative factors of the data. Here, wedeepen this connection and show that SSL can perform system identification inlatent space. We propose DynCL, a framework to uncover linear, switching linearand non-linear dynamics under a non-linear observation model, give theoreticalguarantees and validate them empirically.</description>
      <author>example@mail.com (Rodrigo González Laiz, Tobias Schmidt, Steffen Schneider)</author>
      <guid isPermaLink="false">2410.14673v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>DNA Language Model and Interpretable Graph Neural Network Identify Genes and Pathways Involved in Rare Diseases</title>
      <link>http://arxiv.org/abs/2410.15367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;识别致病基因和通路是理解罕见疾病遗传基础的重要步骤。&lt;h4&gt;目的&lt;/h4&gt;提出新的基因优先级排序和通路识别方法。&lt;h4&gt;方法&lt;/h4&gt;使用DNA语言模型、图神经网络和遗传算法，生成动态基因嵌入以反映有害变异引起的变化。&lt;h4&gt;主要发现&lt;/h4&gt;在部分已知遗传诊断的罕见疾病患者队列中验证了该方法，重新识别了已知的致病基因和通路，并检测到新的候选基因。&lt;h4&gt;结论&lt;/h4&gt;这些发现对罕见疾病的预防和治疗具有重要意义，能够针对性地识别新的药物靶点和治疗通路。&lt;h4&gt;总结&lt;/h4&gt;本研究为罕见疾病的基因和通路识别提供了新的方法和思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Identification of causal genes and pathways is a critical step forunderstanding the genetic underpinnings of rare diseases. We propose novelapproaches to gene prioritization and pathway identification using DNA languagemodel, graph neural networks, and genetic algorithm. Using HyenaDNA, along-range genomic foundation model, we generated dynamic gene embeddings thatreflect changes caused by deleterious variants. These gene embeddings were thenutilized to identify candidate genes and pathways. We validated our method on acohort of rare disease patients with partially known genetic diagnosis,demonstrating the re-identification of known causal genes and pathways and thedetection of novel candidates. These findings have implications for theprevention and treatment of rare diseases by enabling targeted identificationof new drug targets and therapeutic pathways.</description>
      <author>example@mail.com (Ali Saadat, Jacques Fellay)</author>
      <guid isPermaLink="false">2410.15367v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance</title>
      <link>http://arxiv.org/abs/2410.15805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by EMNLP 2024 Industry Track&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着对IT运维和维护的问答系统需求不断增加，迫切需要一个高效且可监督的微调框架，以确保数据安全、私有部署和持续升级。&lt;h4&gt;目的&lt;/h4&gt;提出一个通用且全面的框架，以支持IT运维和维护的问答系统建立。&lt;h4&gt;方法&lt;/h4&gt;基于检索增强生成（RAG）方法，框架分为两个主要阶段：1) 模型微调与数据向量化，2) 在线问答系统流程。在第一阶段，采用对比学习方法和两种负采样策略对嵌入模型进行微调，并设计指令模板对大型语言模型进行检索增强微调。在第二阶段，建立高效的问答系统流程。&lt;h4&gt;主要发现&lt;/h4&gt;通过收集云计算领域的企业专属语料，实验表明该方法在两类问答任务上取得了优于其他方法的效果。&lt;h4&gt;结论&lt;/h4&gt;RAG4ITOps方法在实际企业级应用中具有较好的适用性，并展示了其在真实世界场景下的有效性。&lt;h4&gt;总结&lt;/h4&gt;本文提出的RAG4ITOps框架为IT运维和维护的问答系统提供了高效的解决方案，促进了行业应用的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the ever-increasing demands on Question Answering (QA) systems for IToperations and maintenance, an efficient and supervised fine-tunable frameworkis necessary to ensure the data security, private deployment and continuousupgrading. Although Large Language Models (LLMs) have notably improved theopen-domain QA's performance, how to efficiently handle enterprise-exclusivecorpora and build domain-specific QA systems are still less-studied forindustrial applications. In this paper, we propose a general and comprehensiveframework based on Retrieval Augmented Generation (RAG) and facilitate thewhole business process of establishing QA systems for IT operations andmaintenance. In accordance with the prevailing RAG method, our proposedframework, named with RAG4ITOps, composes of two major stages: (1) ModelsFine-tuning \&amp; Data Vectorization, and (2) Online QA System Process. At theStage 1, we leverage a contrastive learning method with two negative samplingstrategies to fine-tune the embedding model, and design the instructiontemplates to fine-tune the LLM with a Retrieval Augmented Fine-Tuning method.At the Stage 2, an efficient process of QA system is built for serving. Wecollect enterprise-exclusive corpora from the domain of cloud computing, andthe extensive experiments show that our method achieves superior results thancounterparts on two kinds of QA tasks. Our experiment also provide a case forapplying the RAG4ITOps to real-world enterprise-level applications.</description>
      <author>example@mail.com (Tianyang Zhang, Zhuoxuan Jiang, Shengguang Bai, Tianrui Zhang, Lin Lin, Yang Liu, Jiawei Ren)</author>
      <guid isPermaLink="false">2410.15805v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>CoPS: Empowering LLM Agents with Provable Cross-Task Experience Sharing</title>
      <link>http://arxiv.org/abs/2410.16670v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 5 tables, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的代理系统中的顺序推理受到大型语言模型（LLMs）的显著推动，但现有方法存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出CoPS（跨任务经验共享），一种可推广的算法，以通过跨任务经验共享和选择来增强顺序推理。&lt;h4&gt;方法&lt;/h4&gt;CoPS利用代理在先前任务上的经验，通过可证明的悲观策略选择分布匹配的经验，以最大化效用并最小化分布偏移带来的风险。&lt;h4&gt;主要发现&lt;/h4&gt;在Alfworld、Webshop和HotPotQA等基准测试中，CoPS的表现始终优于最先进的基线，并且在资源受限的场景中具有更好的样本效率。&lt;h4&gt;结论&lt;/h4&gt;算法的性能依赖于预训练LLM的质量以及代理的任务相关试验分布与LLM生成的分布之间的匹配。&lt;h4&gt;总结&lt;/h4&gt;本研究弥合了现有顺序推理范式之间的差距，验证了利用跨任务经验的有效性，揭示了提高代理在多样任务中泛化和适应能力的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/uclaml/cops&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential reasoning in agent systems has been significantly advanced bylarge language models (LLMs), yet existing approaches face limitations.Reflection-driven reasoning relies solely on knowledge in pretrained models,limiting performance in novel scenarios, while experience-assisted reasoningoften depends on external experiences and lacks clear principles for selectingrepresentative experiences. We address these limitations by proposing CoPS(Cross-Task Experience Sharing), a generalizable algorithm that enhancessequential reasoning by cross-task experience sharing and selection. In detail,CoPS leverages agents' experiences on previous tasks, selectingdistribution-matched experiences via a provable pessimism-based strategy tomaximize utility while minimizing risks from distribution shifts. Extensiveexperimental results on benchmarks like Alfworld, Webshop, and HotPotQAdemonstrate that CoPS consistently outperforms state-of-the-art baselines, withsuperior sample efficiency suitable for resource-constrained scenarios.Theoretically, we show that the performance of our algorithm depends on boththe quality of the pretrained LLM and the matching between the agent'stask-dependent trial distribution and that generated by the LLM. Our workbridges the gap between existing sequential reasoning paradigms and validatesthe effectiveness of leveraging cross-task experiences, shedding light on thepotential to improve agents' generalization and adaptability across diversetasks. Our codes are available at$\href{https://github.com/uclaml/COPS}{\text{https://github.com/uclaml/COPS}}$.</description>
      <author>example@mail.com (Chen Yang, Chenyang Zhao, Quanquan Gu, Dongruo Zhou)</author>
      <guid isPermaLink="false">2410.16670v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Convergence of Manifold Filter-Combine Networks</title>
      <link>http://arxiv.org/abs/2410.14639v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to NeurIPS Workshop on Symmetry and Geometry in Neural
  Representations (Extended Abstract Track)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;为了更好地理解流形神经网络（MNNs），我们引入了流形滤波-组合网络（MFCNs）。&lt;h4&gt;目的&lt;/h4&gt;建立一个与图神经网络（GNNs）相似的滤波-组合框架，以探索多种有趣的MNN家族。&lt;h4&gt;方法&lt;/h4&gt;提出了一种在高维点云上实现MFCNs的方法，该方法依赖于通过稀疏图来近似流形。&lt;h4&gt;主要发现&lt;/h4&gt;证明了该方法在数据点数量趋向无穷时收敛到一个连续极限。&lt;h4&gt;结论&lt;/h4&gt;MFCNs可以被视为各种流行GNN的流形类比，具有一致性和有效性。&lt;h4&gt;总结&lt;/h4&gt;通过MFCNs，我们为流形神经网络的研究提供了新的视角和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/dj408/mfcn&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In order to better understand manifold neural networks (MNNs), we introduceManifold Filter-Combine Networks (MFCNs). The filter-combine frameworkparallels the popular aggregate-combine paradigm for graph neural networks(GNNs) and naturally suggests many interesting families of MNNs which can beinterpreted as the manifold analog of various popular GNNs. We then propose amethod for implementing MFCNs on high-dimensional point clouds that relies onapproximating the manifold by a sparse graph. We prove that our method isconsistent in the sense that it converges to a continuum limit as the number ofdata points tends to infinity.</description>
      <author>example@mail.com (David R. Johnson, Joyce Chew, Siddharth Viswanath, Edward De Brouwer, Deanna Needell, Smita Krishnaswamy, Michael Perlmutter)</author>
      <guid isPermaLink="false">2410.14639v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Beyond Causal Discovery for Astronomy: Learning Meaningful Representations with Independent Component Analysis</title>
      <link>http://arxiv.org/abs/2410.14775v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024 Causal Representation Learning Workshop.
  arXiv admin note: substantial text overlap with arXiv:2410.00965&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;我们首次将因果表示学习应用于天文学，解决了超大质量黑洞(SMBH)质量与其宿主星系特性之间因果关系的方向性问题。&lt;h4&gt;目的&lt;/h4&gt;明确超大质量黑洞质量与宿主星系属性之间的因果关系。&lt;h4&gt;方法&lt;/h4&gt;采用基于评分的因果发现方法，进行精确后验计算，并通过独立成分分析(ICA)进一步澄清因果关系。&lt;h4&gt;主要发现&lt;/h4&gt;星系属性与超大质量黑洞质量之间的因果关系随星系形态而变化。在椭圆星系中，星系属性决定SMBH质量，而在螺旋星系中则相反。&lt;h4&gt;结论&lt;/h4&gt;这一发现解决了长期存在的争论，并与我们对星系演化的理论理解相符。&lt;h4&gt;总结&lt;/h4&gt;独立成分分析显示，从椭圆星系到螺旋星系，有效独立成分(ICs)的数量逐渐减少，表明在螺旋星系中仅有一个IC与SMBH质量相关，而在椭圆星系中则有多个IC与之相关，进一步确认了因果关系的差异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present the first steps toward applying causal representation learning toastronomy. Following up on previous work that introduced causal discovery tothe field for the first time, here we solve a long standing conundrum byidentifying the direction of the causal relation between supermassive blackhole (SMBH) mass and their host galaxy properties. This leverages a score-basedcausal discovery approach with an exact posterior calculation. Causal relationsbetween SMBHs and their host galaxies are further clarified by IndependentComponent Analysis (ICA). The astrophysical problem we focus on is one of themost important open issues in the field and one that has not seen a definitiveresolution in decades. We consider the space of six physical properties ofgalaxies, subdivided by morphology: elliptical, lenticular, and spiral, plusSMBH mass. We calculate an exact posterior over the space of directed acyclicgraphs for these variables based on a flat prior and the Bayesian Gaussianequivalent score. The nature of the causal relation between galaxy propertiesand SMBH mass is found to vary smoothly with morphology, with galaxy propertiesdetermining SMBH mass in ellipticals and vice versa in spirals. This settles along-standing debate and is compatible with our theoretical understanding ofgalaxy evolution. ICA reveals a decreasing number of meaningful IndependentComponents (ICs) from ellipticals and lenticular to spiral. Moreover, we findthat only one IC correlates with SMBH mass in spirals while multiple ones do inellipticals, further confirming our finding that SMBH mass causes galaxyproperties in spirals, but the reverse holds in ellipticals.</description>
      <author>example@mail.com (Zehao Jin, Mario Pasquato, Benjamin L. Davis, Andrea V. Macciò, Yashar Hezaveh)</author>
      <guid isPermaLink="false">2410.14775v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Gradient Rewiring for Editable Graph Neural Network Training</title>
      <link>http://arxiv.org/abs/2410.15556v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度神经网络广泛应用于计算机视觉、自然语言处理和图分析等领域，但在部署后可能会因环境变化而产生预测错误。&lt;h4&gt;目的&lt;/h4&gt;研究如何在图神经网络中进行可编辑训练，以更新基础模型并纠正预测错误。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为GRE（Gradient Rewiring）的简单有效方法，主要通过存储训练节点的锚梯度来保持局部性，并重新连接目标节点的损失梯度，以保护训练节点的性能。&lt;h4&gt;主要发现&lt;/h4&gt;发现目标节点与训练节点之间的交叉熵损失梯度存在显著不一致性，直接微调基础模型会导致训练节点性能下降。&lt;h4&gt;结论&lt;/h4&gt;GRE方法在各种模型架构和图数据集上展示了其在多种编辑情况下的有效性。&lt;h4&gt;源码链接&lt;/h4&gt;https://github.com/zhimengj0326/Gradient_rewiring_editing&lt;h4&gt;总结&lt;/h4&gt;本研究为图神经网络的可编辑训练提供了新思路，有助于提升模型在动态环境中的适应能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/zhimengj0326/gradient_rewiring_editing&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep neural networks are ubiquitously adopted in many applications, such ascomputer vision, natural language processing, and graph analytics. However,well-trained neural networks can make prediction errors after deployment as theworld changes. \textit{Model editing} involves updating the base model tocorrect prediction errors with less accessible training data and computationalresources. Despite recent advances in model editors in computer vision andnatural language processing, editable training in graph neural networks (GNNs)is rarely explored. The challenge with editable GNN training lies in theinherent information aggregation across neighbors, which can lead model editorsto affect the predictions of other nodes unintentionally. In this paper, wefirst observe the gradient of cross-entropy loss for the target node andtraining nodes with significant inconsistency, which indicates that directlyfine-tuning the base model using the loss on the target node deteriorates theperformance on training nodes. Motivated by the gradient inconsistencyobservation, we propose a simple yet effective \underline{G}radient\underline{R}ewiring method for \underline{E}ditable graph neural networktraining, named \textbf{GRE}. Specifically, we first store the anchor gradientof the loss on training nodes to preserve the locality. Subsequently, we rewirethe gradient of the loss on the target node to preserve performance on thetraining node using anchor gradient. Experiments demonstrate the effectivenessof GRE on various model architectures and graph datasets in terms of multipleediting situations. The source code is available at\url{https://github.com/zhimengj0326/Gradient_rewiring_editing}</description>
      <author>example@mail.com (Zhimeng Jiang, Zirui Liu, Xiaotian Han, Qizhang Feng, Hongye Jin, Qiaoyu Tan, Kaixiong Zhou, Na Zou, Xia Hu)</author>
      <guid isPermaLink="false">2410.15556v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>MultiRC: Joint Learning for Time Series Anomaly Prediction and Detection with Multi-scale Reconstructive Contrast</title>
      <link>http://arxiv.org/abs/2410.15997v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多无监督时间序列异常检测方法已被提出，尽管取得了一定进展，但预测未来异常的研究仍相对稀缺。&lt;h4&gt;目的&lt;/h4&gt;解决预测异常时反应时间多样性和缺乏标记数据的问题。&lt;h4&gt;方法&lt;/h4&gt;提出MultiRC，结合重构学习和对比学习，进行异常预测和检测的联合学习，采用多尺度结构和自适应主周期掩码来应对多样化反应时间，同时生成负样本以提供训练动量。&lt;h4&gt;主要发现&lt;/h4&gt;在七个不同领域的基准数据集上，MultiRC在异常预测和检测任务中均优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;MultiRC有效提高了异常预测和检测的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的方法为无监督时间序列异常检测提供了新的视角，展示了其在实际应用中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many methods have been proposed for unsupervised time series anomalydetection. Despite some progress, research on predicting future anomalies isstill relatively scarce. Predicting anomalies is particularly challenging dueto the diverse reaction time and the lack of labeled data. To address thesechallenges, we propose MultiRC to integrate reconstructive and contrastivelearning for joint learning of anomaly prediction and detection, withmulti-scale structure and adaptive dominant period mask to deal with thediverse reaction time. MultiRC also generates negative samples to provideessential training momentum for the anomaly prediction tasks and prevent modeldegradation. We evaluate seven benchmark datasets from different fields. Forboth anomaly prediction and detection tasks, MultiRC outperforms existingstate-of-the-art methods.</description>
      <author>example@mail.com (Shiyan Hu, Kai Zhao, Xiangfei Qiu, Yang Shu, Jilin Hu, Bin Yang, Chenjuan Guo)</author>
      <guid isPermaLink="false">2410.15997v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>ClimaQA: An Automated Evaluation Framework for Climate Foundation Models</title>
      <link>http://arxiv.org/abs/2410.16701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;气候科学中对基础模型的使用最近引起了显著关注。&lt;h4&gt;目的&lt;/h4&gt;解决缺乏全面评估框架的问题，以评估模型输出的质量和科学有效性。&lt;h4&gt;方法&lt;/h4&gt;开发ClimaGen（气候质量生成器），一个自动化算法框架，从研究生教材中生成问答对，并邀请气候科学家参与。&lt;h4&gt;主要发现&lt;/h4&gt;推出ClimaQA-Gold，一个专家注释的基准数据集，以及ClimaQA-Silver，一个大规模、综合的气候科学合成问答数据集。&lt;h4&gt;结论&lt;/h4&gt;开发评估策略并比较不同的大型语言模型（LLMs）在基准上的表现，提供了增强气候基础模型的多种新见解。&lt;h4&gt;总结&lt;/h4&gt;研究为气候科学中的基础模型评估和改进提供了重要的框架和数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The use of foundation models in climate science has recently gainedsignificant attention. However, a critical issue remains: the lack of acomprehensive evaluation framework capable of assessing the quality andscientific validity of model outputs. To address this issue, we developClimaGen (Climate QA Generator), an automated algorithmic framework thatgenerates question-answer pairs from graduate textbooks with climate scientistsin the loop. As a result, we present ClimaQA-Gold, an expert-annotatedbenchmark dataset alongside ClimaQA-Silver, a large-scale, comprehensivesynthetic QA dataset for climate science. Finally, we develop evaluationstrategies and compare different Large Language Models (LLMs) on ourbenchmarks. Our results offer novel insights into various approaches used toenhance climate foundation models.</description>
      <author>example@mail.com (Veeramakali Vignesh Manivannan, Yasaman Jafari, Srikar Eranky, Spencer Ho, Rose Yu, Duncan Watson-Parris, Yian Ma, Leon Bergen, Taylor Berg-Kirkpatrick)</author>
      <guid isPermaLink="false">2410.16701v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Explainability of Point Cloud Neural Networks Using SMILE: Statistical Model-Agnostic Interpretability with Local Explanations</title>
      <link>http://arxiv.org/abs/2410.15374v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在机器人和点云应用中，可解释人工智能（XAI）的重要性日益增加，缺乏决策透明度可能带来安全风险，特别是在自主系统中。&lt;h4&gt;目的&lt;/h4&gt;确保模型决策可解释且可信，从而提高操作的可靠性和安全性。&lt;h4&gt;方法&lt;/h4&gt;研究了SMILE，一种新颖的可解释性方法，最初为深度神经网络设计，应用于基于点云的模型。SMILE通过引入经验累积分布函数（ECDF）统计距离，增强了鲁棒性和可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;SMILE在忠实度损失、R2分数和鲁棒性方面表现优异，适用于不同的核宽度、扰动次数和聚类配置。同时，使用Jaccard指数对点云数据进行稳定性分析，建立了新基准。&lt;h4&gt;结论&lt;/h4&gt;研究识别了‘人’类别分类中的数据集偏差，强调了在安全关键应用（如自动驾驶和机器人技术）中需要更全面的数据集。结果显示先进可解释性模型的潜力，并指出未来研究方向，包括替代模型和可解释性技术在点云数据中的应用。&lt;h4&gt;总结&lt;/h4&gt;本研究为点云模型的可解释性提供了新方法和基准，强调了数据集的全面性在安全关键应用中的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Dependable-Intelligent-Systems-Lab/xwhy/tree/main/examples/Point%20Cloud%20Examples&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In today's world, the significance of explainable AI (XAI) is growing inrobotics and point cloud applications, as the lack of transparency indecision-making can pose considerable safety risks, particularly in autonomoussystems. As these technologies are integrated into real-world environments,ensuring that model decisions are interpretable and trustworthy is vital foroperational reliability and safety assurance. This study explores theimplementation of SMILE, a novel explainability method originally designed fordeep neural networks, on point cloud-based models. SMILE builds on LIME byincorporating Empirical Cumulative Distribution Function (ECDF) statisticaldistances, offering enhanced robustness and interpretability, particularly whenthe Anderson-Darling distance is used. The approach demonstrates superiorperformance in terms of fidelity loss, R2 scores, and robustness across variouskernel widths, perturbation numbers, and clustering configurations. Moreover,this study introduces a stability analysis for point cloud data using theJaccard index, establishing a new benchmark and baseline for model stability inthis field. The study further identifies dataset biases in the classificationof the 'person' category, emphasizing the necessity for more comprehensivedatasets in safety-critical applications like autonomous driving and robotics.The results underscore the potential of advanced explainability models andhighlight areas for future research, including the application of alternativesurrogate models and explainability techniques in point cloud data.</description>
      <author>example@mail.com (Seyed Mohammad Ahmadi, Koorosh Aslansefat, Ruben Valcarce-Dineiro, Joshua Barnfather)</author>
      <guid isPermaLink="false">2410.15374v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models</title>
      <link>http://arxiv.org/abs/2410.15268v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;文本属性图（TAG）的表示学习因其在推荐系统和社交网络等领域的应用而受到广泛关注。&lt;h4&gt;目的&lt;/h4&gt;提出TAGExplainer，首个为TAG学习生成自然语言解释的方法。&lt;h4&gt;方法&lt;/h4&gt;TAGExplainer使用生成语言模型，将输入输出对映射为反映模型决策过程的解释，并通过伪标签生成和专家迭代训练提升解释质量。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实验验证了TAGExplainer在生成真实且简洁的自然语言解释方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;TAGExplainer能够有效解决现有TAG表示学习模型的可解释性挑战。&lt;h4&gt;总结&lt;/h4&gt;本文提出的TAGExplainer为文本属性图的学习提供了一种新的自然语言解释生成方法，提升了模型的可解释性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning of Text-Attributed Graphs (TAGs) has garneredsignificant attention due to its applications in various domains, includingrecommendation systems and social networks. Despite advancements in TAGlearning methodologies, challenges remain in explainability due to theblack-box nature of existing TAG representation learning models. This paperpresents TAGExplainer, the first method designed to generate natural languageexplanations for TAG learning. TAGExplainer employs a generative language modelthat maps input-output pairs to explanations reflecting the model'sdecision-making process. To address the lack of annotated ground truthexplanations in real-world scenarios, we propose first generating pseudo-labelsthat capture the model's decisions from saliency-based explanations, then thepseudo-label generator is iteratively trained based on three trainingobjectives focusing on faithfulness and brevity via Expert Iteration, toimprove the quality of generated pseudo-labels. The high-quality pseudo-labelsare finally utilized to train an end-to-end explanation generator model.Extensive experiments are conducted to demonstrate the effectiveness ofTAGExplainer in producing faithful and concise natural language explanations.</description>
      <author>example@mail.com (Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Liang Zhao)</author>
      <guid isPermaLink="false">2410.15268v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Deep Graph Attention Networks</title>
      <link>http://arxiv.org/abs/2410.15640v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图用于表示各种现实世界对象，但图神经网络（GNN）容易出现过平滑问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，构建有效的图注意力网络（GAT），避免需要长时间调试层数。&lt;h4&gt;方法&lt;/h4&gt;引入名为“DeepGAT”的方法，预测节点所属类别，确保不同类别的节点在每层中不相似。&lt;h4&gt;主要发现&lt;/h4&gt;使用DeepGAT构建的15层网络性能与2层GAT相似，注意力系数相近。&lt;h4&gt;结论&lt;/h4&gt;DeepGAT有效防止过平滑，无需调节层数，节省时间，提高GNN性能。&lt;h4&gt;总结&lt;/h4&gt;DeepGAT为训练大型网络提供了新的思路，保持了与少层网络相似的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are useful for representing various realworld objects. However, graphneural networks (GNNs) tend to suffer from over-smoothing, where therepresentations of nodes of different classes become similar as the number oflayers increases, leading to performance degradation. A method that does notrequire protracted tuning of the number of layers is needed to effectivelyconstruct a graph attention network (GAT), a type of GNN. Therefore, weintroduce a method called "DeepGAT" for predicting the class to which nodesbelong in a deep GAT. It avoids over-smoothing in a GAT by ensuring that nodesin different classes are not similar at each layer. Using DeepGAT to predictclass labels, a 15-layer network is constructed without the need to tune thenumber of layers. DeepGAT prevented over-smoothing and achieved a 15-layer GATwith similar performance to a 2-layer GAT, as indicated by the similarattention coefficients. DeepGAT enables the training of a large network toacquire similar attention coefficients to a network with few layers. It avoidsthe over-smoothing problem and obviates the need to tune the number of layers,thus saving time and enhancing GNN performance.</description>
      <author>example@mail.com (Jun Kato, Airi Mita, Keita Gobara, Akihiro Inokuchi)</author>
      <guid isPermaLink="false">2410.15640v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots</title>
      <link>http://arxiv.org/abs/2410.16804v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人在生活支持中越来越有前景，预计将接管或协助完成诸如地面清洁、餐桌摆放和物品取回等家务。&lt;h4&gt;目的&lt;/h4&gt;探讨大语言模型（LLMs）在机器人执行“取物”任务中的优势，这些任务通常基于模糊的指令。&lt;h4&gt;方法&lt;/h4&gt;通过将大语言模型与本体数据结合，提升处理模糊性的信息能力，减少用户干预的需求。&lt;h4&gt;主要发现&lt;/h4&gt;集成大语言模型可以提供额外的常识知识，从而改善系统的可用性并减少幻觉现象。&lt;h4&gt;结论&lt;/h4&gt;该系统有效地结合了知识库，旨在为用户提供更无缝和高效的机器人辅助体验。&lt;h4&gt;总结&lt;/h4&gt;通过整合大语言模型和本体数据，提升了机器人在处理模糊指令时的能力，改善了用户体验。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifestyle support through robotics is an increasingly promising field, withexpectations for robots to take over or assist with chores like floor cleaning,table setting and clearing, and fetching items. The growth of AI, particularlyfoundation models, such as large language models (LLMs) and visual languagemodels (VLMs), is significantly shaping this sector. LLMs, by facilitatingnatural interactions and providing vast general knowledge, are provinginvaluable for robotic tasks. This paper zeroes in on the benefits of LLMs for"bring-me" tasks, where robots fetch specific items for users, often based onvague instructions. Our previous efforts utilized an ontology extended tohandle environmental data to decipher such vagueness, but faced limitationswhen unresolvable ambiguities required user intervention for clarity. Here, weenhance our approach by integrating LLMs for providing additional commonsenseknowledge, pairing it with ontological data to mitigate the issue ofhallucinations and reduce the need for user queries, thus improving systemusability. We present a system that merges these knowledge bases and assess itsefficacy on "bring-me" tasks, aiming to provide a more seamless and efficientrobotic assistance experience.</description>
      <author>example@mail.com (Haru Nakajima, Jun Miura)</author>
      <guid isPermaLink="false">2410.16804v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Contrastive Learning for Time Series Representation</title>
      <link>http://arxiv.org/abs/2410.15416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;理解时间序列中的事件在多种场景中是重要的任务，但人工分析和标注成本高且耗时。&lt;h4&gt;目的&lt;/h4&gt;提出一种无监督的方式来学习时间序列中的瞬时嵌入，以提高分类或检测任务的性能。&lt;h4&gt;方法&lt;/h4&gt;提出动态对比学习（DynaCL）框架，通过时间相邻步骤定义正样本对，采用N-pair损失动态处理批次中的所有样本，解决复杂的正样本采样问题。&lt;h4&gt;主要发现&lt;/h4&gt;DynaCL能将时间序列实例嵌入到语义上有意义的聚类中，在多个公共时间序列数据集的下游任务中表现优越。&lt;h4&gt;结论&lt;/h4&gt;高的无监督聚类指标评分并不保证表示在下游任务中有用。&lt;h4&gt;总结&lt;/h4&gt;DynaCL框架为时间序列的无监督表示学习提供了有效的方法，显著提升了下游任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding events in time series is an important task in a variety ofcontexts. However, human analysis and labeling are expensive andtime-consuming. Therefore, it is advantageous to learn embeddings for momentsin time series in an unsupervised way, which allows for good performance inclassification or detection tasks after later minimal human labeling. In thispaper, we propose dynamic contrastive learning (DynaCL), an unsupervisedcontrastive representation learning framework for time series that usestemporal adjacent steps to define positive pairs. DynaCL adopts N-pair loss todynamically treat all samples in a batch as positive or negative pairs,enabling efficient training and addressing the challenges of complicatedsampling of positives. We demonstrate that DynaCL embeds instances from timeseries into semantically meaningful clusters, which allows superior performanceon downstream tasks on a variety of public time series datasets. Our findingsalso reveal that high scores on unsupervised clustering metrics do notguarantee that the representations are useful in downstream tasks.</description>
      <author>example@mail.com (Abdul-Kazeem Shamba, Kerstin Bach, Gavin Taylor)</author>
      <guid isPermaLink="false">2410.15416v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Joint Top-Down and Bottom-Up Frameworks for 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2410.15615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICPR2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D视觉定位任务的挑战性，旨在根据文本描述定位3D点云场景中的特定物体。&lt;h4&gt;目的&lt;/h4&gt;提出一种联合的自上而下和自下而上的框架，以提高性能和效率。&lt;h4&gt;方法&lt;/h4&gt;第一阶段使用基于自下而上的提案生成模块，利用轻量神经网络高效回归和聚类粗略物体提案；第二阶段引入基于自上而下的提案整合模块，利用图设计有效聚合和传播与查询相关的物体上下文进行进一步细化。&lt;h4&gt;主要发现&lt;/h4&gt;通过联合训练这两个模块，避免了自上而下框架复杂提案和自下而下框架粗糙提案的固有缺陷。&lt;h4&gt;结论&lt;/h4&gt;在ScanRefer基准测试中的实验结果表明，该框架能够实现最先进的性能。&lt;h4&gt;总结&lt;/h4&gt;提出的联合框架有效结合了自上而下和自下而上的方法，提升了3D视觉定位的效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper tackles the challenging task of 3D visual grounding-locating aspecific object in a 3D point cloud scene based on text descriptions. Existingmethods fall into two categories: top-down and bottom-up methods. Top-downmethods rely on a pre-trained 3D detector to generate and select the bestbounding box, resulting in time-consuming processes. Bottom-up methods directlyregress object bounding boxes with coarse-grained features, producing worseresults. To combine their strengths while addressing their limitations, wepropose a joint top-down and bottom-up framework, aiming to enhance theperformance while improving the efficiency. Specifically, in the first stage,we propose a bottom-up based proposal generation module, which utilizeslightweight neural layers to efficiently regress and cluster several coarseobject proposals instead of using a complex 3D detector. Then, in the secondstage, we introduce a top-down based proposal consolidation module, whichutilizes graph design to effectively aggregate and propagate the query-relatedobject contexts among the generated proposals for further refinement. Byjointly training these two modules, we can avoid the inherent drawbacks of thecomplex proposals in the top-down framework and the coarse proposals in thebottom-up framework. Experimental results on the ScanRefer benchmark show thatour framework is able to achieve the state-of-the-art performance.</description>
      <author>example@mail.com (Yang Liu, Daizong Liu, Wei Hu)</author>
      <guid isPermaLink="false">2410.15615v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Focus Where It Matters: Graph Selective State Focused Attention Networks</title>
      <link>http://arxiv.org/abs/2410.15849v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的图神经网络（GNN）在可扩展性方面存在不足，并且由于过平滑现象，容易丢失个体节点特征，尤其是在更深的网络中。&lt;h4&gt;目的&lt;/h4&gt;提出Graph Selective States Focused Attention Networks（GSAN）以解决GNN的局限性，特别是在动态变化图的任务中。&lt;h4&gt;方法&lt;/h4&gt;GSAN采用多头掩蔽自注意力（MHMSA）和选择状态空间建模（S3M）层，以增强对关键节点连接的动态强调，并适应不断变化的节点状态。&lt;h4&gt;主要发现&lt;/h4&gt;GSAN在多个基准数据集上（如Cora、Citeseer、Pubmed和蛋白质相互作用数据集）进行了比较实验，分类准确率分别提高了1.56%、8.94%、0.37%和1.54%。&lt;h4&gt;结论&lt;/h4&gt;GSAN有效克服了传统GNN面临的问题，在归纳和传导任务中表现优越，并提升了对未见结构的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;通过引入MHMSA和S3M，GSAN在处理动态图结构数据时展现出更强的性能和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional graph neural networks (GNNs) lack scalability and lose individualnode characteristics due to over-smoothing, especially in the case of deepernetworks. This results in sub-optimal feature representation, affecting themodel's performance on tasks involving dynamically changing graphs. To addressthis issue, we present Graph Selective States Focused Attention Networks(GSANs) based neural network architecture for graph-structured data. The GSANis enabled by multi-head masked self-attention (MHMSA) and selective statespace modeling (S3M) layers to overcome the limitations of GNNs. In GSAN, theMHMSA allows GSAN to dynamically emphasize crucial node connections,particularly in evolving graph environments. The S3M layer enables the networkto adjust dynamically in changing node states and improving predictions of nodebehavior in varying contexts without needing primary knowledge of the graphstructure. Furthermore, the S3M layer enhances the generalization of unseenstructures and interprets how node states influence link importance. With this,GSAN effectively outperforms inductive and transductive tasks and overcomes theissues that traditional GNNs experience. To analyze the performance behavior ofGSAN, a set of state-of-the-art comparative experiments are conducted on graphsbenchmark datasets, including $Cora$, $Citeseer$, $Pubmed$ network citation,and $protein-protein-interaction$ datasets, as an outcome, GSAN improved theclassification accuracy by $1.56\%$, $8.94\%$, $0.37\%$, and $1.54\%$ on$F1-score$ respectively.</description>
      <author>example@mail.com (Shikhar Vashistha, Neetesh Kumar)</author>
      <guid isPermaLink="false">2410.15849v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Assessment of Transformer-Based Encoder-Decoder Model for Human-Like Summarization</title>
      <link>http://arxiv.org/abs/2410.16842v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Pre-print&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从大量文本中提取有价值的信息正在取得显著进展，尤其是在社交媒体时代，人们期望快速获取信息。&lt;h4&gt;目的&lt;/h4&gt;自动文本摘要旨在将大文本精简为更易管理的摘要，以帮助决策。&lt;h4&gt;方法&lt;/h4&gt;利用基于变换器的BART模型进行人类般的摘要，采用编码器-解码器框架进行训练和微调，并通过多样的样本文章进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;微调后的模型在评估指标（如ROUGE和BERTScore）上表现优于基线预训练模型，但在对话摘要中需要领域适应以提高表现。&lt;h4&gt;结论&lt;/h4&gt;常用评估指标对事实错误不敏感，使用新的事实一致性评估指标（如WeCheck和SummaC）进行更深入的调查，发现人类撰写的金标准摘要在事实一致性上比微调模型生成的摘要高出17%。&lt;h4&gt;总结&lt;/h4&gt;本研究揭示了自动摘要模型在事实一致性方面的不足，强调了域适应和新评估指标的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent times, extracting valuable information from large text is makingsignificant progress. Especially in the current era of social media, peopleexpect quick bites of information. Automatic text summarization seeks to tacklethis by slimming large texts down into more manageable summaries. Thisimportant research area can aid in decision-making by digging out salientcontent from large text. With the progress in deep learning models, significantwork in language models has emerged. The encoder-decoder framework in deeplearning has become the central approach for automatic text summarization. Thiswork leverages transformer-based BART model for human-like summarization whichis an open-ended problem with many challenges. On training and fine-tuning theencoder-decoder model, it is tested with diverse sample articles and thequality of summaries of diverse samples is assessed based on human evaluationparameters. Further, the finetuned model performance is compared with thebaseline pretrained model based on evaluation metrics like ROUGE score andBERTScore. Additionally, domain adaptation of the model is required forimproved performance of abstractive summarization of dialogues betweeninterlocutors. On investigating, the above popular evaluation metrics are foundto be insensitive to factual errors. Further investigation of the summariesgenerated by finetuned model is done using the contemporary evaluation metricsof factual consistency like WeCheck and SummaC. Empirical results on BBC Newsarticles highlight that the gold standard summaries written by humans are morefactually consistent by 17% than the abstractive summaries generated byfinetuned model.</description>
      <author>example@mail.com (Sindhu Nair, Y. S. Rao, Radha Shankarmani)</author>
      <guid isPermaLink="false">2410.16842v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Structural Causality-based Generalizable Concept Discovery Models</title>
      <link>http://arxiv.org/abs/2410.15491v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对可解释的深度神经网络架构的需求不断增加，语义概念被用作可解释单元。&lt;h4&gt;目的&lt;/h4&gt;提出一种解耦机制，利用变分自编码器（VAE）学习互相独立的生成因子，并使用结构因果模型（SCM）学习任务特定的概念。&lt;h4&gt;方法&lt;/h4&gt;假设生成因子和概念形成一个二分图，生成因子到概念之间存在有向因果边。&lt;h4&gt;主要发现&lt;/h4&gt;在已知生成因子的D-sprites和Shapes3D数据集上进行实验，成功学习了任务特定的概念，并通过因果边很好地解释了这些概念。&lt;h4&gt;结论&lt;/h4&gt;该方法与当前的因果概念发现方法不同，具有可扩展性，适用于任意数量的概念和灵活的下游任务。&lt;h4&gt;总结&lt;/h4&gt;本文提出的方法在解耦学习和任务特定概念发现中表现出良好的效果，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rising need for explainable deep neural network architectures hasutilized semantic concepts as explainable units. Several approaches utilizingdisentangled representation learning estimate the generative factors andutilize them as concepts for explaining DNNs. However, even though thegenerative factors for a dataset remain fixed, concepts are not fixed entitiesand vary based on downstream tasks. In this paper, we propose a disentanglementmechanism utilizing a variational autoencoder (VAE) for learning mutuallyindependent generative factors for a given dataset and subsequently learningtask-specific concepts using a structural causal model (SCM). Our methodassumes generative factors and concepts to form a bipartite graph, withdirected causal edges from generative factors to concepts. Experiments areconducted on datasets with known generative factors: D-sprites and Shapes3D. Onspecific downstream tasks, our proposed method successfully learnstask-specific concepts which are explained well by the causal edges from thegenerative factors. Lastly, separate from current causal concept discoverymethods, our methodology is generalizable to an arbitrary number of conceptsand flexible to any downstream tasks.</description>
      <author>example@mail.com (Sanchit Sinha, Guangzhi Xiong, Aidong Zhang)</author>
      <guid isPermaLink="false">2410.15491v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Resilient Temporal GCN for Smart Grid State Estimation Under Topology Inaccuracies</title>
      <link>http://arxiv.org/abs/2410.16008v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;状态估计是电力系统中的一个重要任务。图神经网络在电力系统的状态估计中显示出显著的潜力。&lt;h4&gt;目的&lt;/h4&gt;研究拓扑不确定性对时间图卷积网络（TGCN）在电力系统状态估计中的性能影响。&lt;h4&gt;方法&lt;/h4&gt;提出了对TGCN模型的修改，以纳入基于测量数据生成的知识图，该知识图支持不确定的系统图。&lt;h4&gt;主要发现&lt;/h4&gt;两种TGCN架构变体的性能被评估和比较，结果表明它们在拓扑不确定性下都能改善状态估计的性能。&lt;h4&gt;结论&lt;/h4&gt;尽管两种架构的表现不同，但都增强了TGCN在拓扑不确定性下的状态估计能力。&lt;h4&gt;总结&lt;/h4&gt;本研究为电力系统中的状态估计提供了在拓扑不确定性情况下的改进方法，展示了知识图的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State Estimation is a crucial task in power systems. Graph Neural Networkshave demonstrated significant potential in state estimation for power systemsby effectively analyzing measurement data and capturing the complexinteractions and interrelations among the measurements through the system'sgraph structure. However, the information about the system's graph structuremay be inaccurate due to noise, attack or lack of accurate information aboutthe topology of the system. This paper studies these scenarios under topologyuncertainties and evaluates the impact of the topology uncertainties on theperformance of a Temporal Graph Convolutional Network (TGCN) for stateestimation in power systems. In order to make the model resilient to topologyuncertainties, modifications in the TGCN model are proposed to incorporate aknowledge graph, generated based on the measurement data. This knowledge graphsupports the assumed uncertain system graph. Two variations of the TGCNarchitecture are introduced to integrate the knowledge graph, and theirperformances are evaluated and compared to demonstrate improved resilienceagainst topology uncertainties. The evaluation results indicate that while thetwo proposed architecture show different performance, they both improve theperformance of the TGCN state estimation under topology uncertainties.</description>
      <author>example@mail.com (Seyed Hamed Haghshenas, Mia Naeini)</author>
      <guid isPermaLink="false">2410.16008v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Multimodal Affective Analysis with Learned Live Comment Features</title>
      <link>http://arxiv.org/abs/2410.16407v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;直播评论（弹幕）是与视频内容同步的用户生成信息，实时捕捉观众情感与反应。&lt;h4&gt;目的&lt;/h4&gt;构建一个包含多种情感的直播评论数据集，以提升情感分析的效果。&lt;h4&gt;方法&lt;/h4&gt;构建了Live Comment for Affective Analysis (LCAffect)数据集，并使用对比学习训练视频编码器，生成合成直播评论特征。&lt;h4&gt;主要发现&lt;/h4&gt;在多种情感分析任务中，合成的直播评论特征显著提高了性能，优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;合成直播评论特征能有效增强多模态情感内容分析的能力。&lt;h4&gt;总结&lt;/h4&gt;该研究通过构建数据集和创新方法，推进了基于直播评论的情感分析领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Live comments, also known as Danmaku, are user-generated messages that aresynchronized with video content. These comments overlay directly onto streamingvideos, capturing viewer emotions and reactions in real-time. While prior workhas leveraged live comments in affective analysis, its use has been limited dueto the relative rarity of live comments across different video platforms. Toaddress this, we first construct the Live Comment for Affective Analysis(LCAffect) dataset which contains live comments for English and Chinese videosspanning diverse genres that elicit a wide spectrum of emotions. Then, usingthis dataset, we use contrastive learning to train a video encoder to producesynthetic live comment features for enhanced multimodal affective contentanalysis. Through comprehensive experimentation on a wide range of affectiveanalysis tasks (sentiment, emotion recognition, and sarcasm detection) in bothEnglish and Chinese, we demonstrate that these synthetic live comment featuressignificantly improve performance over state-of-the-art methods.</description>
      <author>example@mail.com (Zhaoyuan Deng, Amith Ananthram, Kathleen McKeown)</author>
      <guid isPermaLink="false">2410.16407v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>LIMIS: Towards Language-based Interactive Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2410.16939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究介绍了LIMIS，这是第一个纯语言基础的交互式医学图像分割模型。&lt;h4&gt;目的&lt;/h4&gt;旨在允许放射科医师将其知识纳入分割过程。&lt;h4&gt;方法&lt;/h4&gt;通过将Grounded SAM适应于医学领域，并设计语言基础的模型交互策略，实现高质量的初始分割掩膜。&lt;h4&gt;主要发现&lt;/h4&gt;LIMIS利用医学基础模型生成高质量的初始分割掩膜，并允许用户仅通过语言调整分割掩膜。&lt;h4&gt;结论&lt;/h4&gt;LIMIS在三个公开的医学数据集上进行了评估，结果显示其高质量的分割掩膜和良好的交互可用性得到了医学领域专家的确认。&lt;h4&gt;总结&lt;/h4&gt;LIMIS为在需要双手进行其他任务的场景下的交互式分割提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Within this work, we introduce LIMIS: The first purely language-basedinteractive medical image segmentation model. We achieve this by adaptingGrounded SAM to the medical domain and designing a language-based modelinteraction strategy that allows radiologists to incorporate their knowledgeinto the segmentation process. LIMIS produces high-quality initial segmentationmasks by leveraging medical foundation models and allows users to adaptsegmentation masks using only language, opening up interactive segmentation toscenarios where physicians require using their hands for other tasks. Weevaluate LIMIS on three publicly available medical datasets in terms ofperformance and usability with experts from the medical domain confirming itshigh-quality segmentation masks and its interactive usability.</description>
      <author>example@mail.com (Lena Heinemann, Alexander Jaus, Zdravko Marinov, Moon Kim, Maria Francesca Spadea, Jens Kleesiek, Rainer Stiefelhagen)</author>
      <guid isPermaLink="false">2410.16939v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Stronger Transformer Representation Learning for Occluded Person Re-Identification</title>
      <link>http://arxiv.org/abs/2410.15613v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;由于遮挡、姿态变化和多样的摄像头视角等复杂因素，行人重识别中的特征表示提取仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的自监督与监督相结合的基于变换器的行人重识别框架SSSC-TransReID。&lt;h4&gt;方法&lt;/h4&gt;设计了一个自监督对比学习分支，增强行人重识别的特征表示，且不需要负样本或额外的预训练；同时提出了一种新颖的随机矩形遮挡策略，以模拟真实场景中的遮挡。&lt;h4&gt;主要发现&lt;/h4&gt;通过联合训练损失函数，将有ID标签的监督学习与无负样本的自监督对比学习优势结合，显著增强了模型挖掘强判别特征的能力，尤其是在遮挡情况下。&lt;h4&gt;结论&lt;/h4&gt;在多个基准数据集上，所提模型在平均准确率(mAP)和Rank-1准确率上 consistently 超越了最先进的行人重识别方法。&lt;h4&gt;总结&lt;/h4&gt;SSSC-TransReID框架有效提升了行人重识别的性能，尤其在复杂场景下表现优异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to some complex factors (e.g., occlusion, pose variation and diversecamera perspectives), extracting stronger feature representation in personre-identification remains a challenging task. In this paper, we proposed anovel self-supervision and supervision combining transformer-based personre-identification framework, namely SSSC-TransReID. Different from the generaltransformer-based person re-identification models, we designed aself-supervised contrastive learning branch, which can enhance the featurerepresentation for person re-identification without negative samples oradditional pre-training. In order to train the contrastive learning branch, wealso proposed a novel random rectangle mask strategy to simulate the occlusionin real scenes, so as to enhance the feature representation for occlusion.Finally, we utilized the joint-training loss function to integrate theadvantages of supervised learning with ID tags and self-supervised contrastivelearning without negative samples, which can reinforce the ability of our modelto excavate stronger discriminative features, especially for occlusion.Extensive experimental results on several benchmark datasets show our proposedmodel obtains superior Re-ID performance consistently and outperforms thestate-of-the-art ReID methods by large margins on the mean average accuracy(mAP) and Rank-1 accuracy.</description>
      <author>example@mail.com (Zhangjian Ji, Donglin Cheng, Kai Feng)</author>
      <guid isPermaLink="false">2410.15613v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>ST-MoE-BERT: A Spatial-Temporal Mixture-of-Experts Framework for Long-Term Cross-City Mobility Prediction</title>
      <link>http://arxiv.org/abs/2410.14099v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  2nd ACM SIGSPATIAL International Workshop on the Human Mobility
  Prediction Challenge&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在人口迁移预测中，由于不同城市的空间-时间动态复杂多样，存在显著挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为ST-MoE-BERT的人类迁移模式预测方法。&lt;h4&gt;方法&lt;/h4&gt;将预测任务框定为空间-时间分类问题，结合Mixture-of-Experts架构与BERT模型，捕捉复杂的迁移动态，并进行迁移学习以应对跨城市预测中的数据稀缺问题。&lt;h4&gt;主要发现&lt;/h4&gt;在GEO-BLEU和DTW指标上，ST-MoE-BERT与多种先进方法比较，平均提升了8.29%。&lt;h4&gt;结论&lt;/h4&gt;ST-MoE-BERT有效提高了人类迁移模式的预测精度。&lt;h4&gt;总结&lt;/h4&gt;该研究提供了一种新颖的模型，能够更好地处理复杂城市环境中的人类迁移预测问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/he-h/HuMob&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Predicting human mobility across multiple cities presents significantchallenges due to the complex and diverse spatial-temporal dynamics inherent indifferent urban environments. In this study, we propose a robust approach topredict human mobility patterns called ST-MoE-BERT. Compared to existingmethods, our approach frames the prediction task as a spatial-temporalclassification problem. Our methodology integrates the Mixture-of-Expertsarchitecture with BERT model to capture complex mobility dynamics and performthe downstream human mobility prediction task. Additionally, transfer learningis integrated to solve the challenge of data scarcity in cross-city prediction.We demonstrate the effectiveness of the proposed model on GEO-BLEU and DTW,comparing it to several state-of-the-art methods. Notably, ST-MoE-BERT achievesan average improvement of 8.29%.</description>
      <author>example@mail.com (Haoyu He, Haozheng Luo, Qi R. Wang)</author>
      <guid isPermaLink="false">2410.14099v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Gradient-based Jailbreak Images for Multimodal Fusion Models</title>
      <link>http://arxiv.org/abs/2410.03489v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;增强语言模型与图像输入结合可能更有效地进行越狱攻击，因其可以进行连续优化，而文本输入需要离散优化。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来克服当前多模态融合模型中由于不可微分函数导致的攻击困难。&lt;h4&gt;方法&lt;/h4&gt;引入一种称为tokenizer shortcut的技术，用连续函数近似标记化，从而实现连续优化，并创造出首个端到端的梯度图像攻击。&lt;h4&gt;主要发现&lt;/h4&gt;在Chameleon模型上评估攻击后，发现越狱图像能够对72.5%的提示引发有害信息。越狱图像的效果优于使用相同目标优化的文本越狱，并且优化50倍输入标记所需的计算预算低3倍。&lt;h4&gt;结论&lt;/h4&gt;针对文本攻击训练的防御机制（如Circuit Breakers）能有效迁移至对抗图像输入的防御。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新颖的攻击方法，展示了图像输入在越狱攻击中的潜力，并指出现有防御机制的有效性可以转移到图像攻击上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-04&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/facebookresearch/multimodal-fusion-jailbreaks&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Augmenting language models with image inputs may enable more effectivejailbreak attacks through continuous optimization, unlike text inputs thatrequire discrete optimization. However, new multimodal fusion models tokenizeall input modalities using non-differentiable functions, which hindersstraightforward attacks. In this work, we introduce the notion of a tokenizershortcut that approximates tokenization with a continuous function and enablescontinuous optimization. We use tokenizer shortcuts to create the firstend-to-end gradient image attacks against multimodal fusion models. We evaluateour attacks on Chameleon models and obtain jailbreak images that elicit harmfulinformation for 72.5% of prompts. Jailbreak images outperform text jailbreaksoptimized with the same objective and require 3x lower compute budget tooptimize 50x more input tokens. Finally, we find that representationengineering defenses, like Circuit Breakers, trained only on text attacks caneffectively transfer to adversarial image inputs.</description>
      <author>example@mail.com (Javier Rando, Hannah Korevaar, Erik Brinkman, Ivan Evtimov, Florian Tramèr)</author>
      <guid isPermaLink="false">2410.03489v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating Discovery of Extreme Lattice Thermal Conductivity by Crystal Attention Graph Neural Network (CATGNN) Using Chemical Bonding Intuitive Descriptors</title>
      <link>http://arxiv.org/abs/2410.16066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26+13S pages, 7+5S figures, 3+2S tables. S denotes Supplemental
  Information (SI)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;寻找具有理想热传导性质的晶体材料需要对原子间相互作用的电子层面理解和化学直觉，以揭示隐含的结构-性质关系。&lt;h4&gt;目的&lt;/h4&gt;提出两种化学键描述符，旨在探究其与晶格热导率（LTC）和均方位移（MSD）之间的关系。&lt;h4&gt;方法&lt;/h4&gt;引入负归一化积分晶体轨道哈密顿人口（normalized -ICOHP）和归一化积分晶体轨道键指数（normalized ICOBI），并使用超过4500种材料的第一性原理数据集进行测试。&lt;h4&gt;主要发现&lt;/h4&gt;这两个描述符与LTC的皮尔逊相关性显著高于传统的平均质量简单规则；筛选出367种低LTC和533种高LTC材料进行第一性原理验证，发现106种动态稳定材料的LTC低于5 W/mK。&lt;h4&gt;结论&lt;/h4&gt;提出的描述符为LTC和MSD提供了基于化学键原理的深入见解，且具有较低的计算成本，为新型极端LTC晶体材料的高通量筛选提供了可靠的快速途径。&lt;h4&gt;总结&lt;/h4&gt;这项研究为热电材料和电子冷却应用中的新型晶体材料的开发奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Searching for technologically promising crystalline materials with desiredthermal transport properties requires an electronic level comprehension ofinteratomic interactions and chemical intuition to uncover the hiddenstructure-property relationship. Here, we propose two chemical bondingdescriptors, namely negative normalized integrated crystal orbital Hamiltonpopulation (normalized -ICOHP) and normalized integrated crystal orbital bondindex (normalized ICOBI) and unravel their strong correlation to both latticethermal conductivity (LTC) and rattling effect characterized by mean squareddisplacement (MSD). Our new descriptors outperform empirical models and thesole -ICOHP quantity in closely relating to extreme LTCs by testing on afirst-principles dataset of over 4,500 materials with 62 distinct species. ThePearson correlation of both descriptors with LTC are significantly higher inmagnitude compared with the traditional simple rule of average mass. We furtherdevelop crystal attention graph neural networks (CATGNN) model and predict ourproposed descriptors of ~200,000 materials from existing databases to screenpotentially ultralow and high LTC materials. We select 367 (533) with low(high) normalized -ICOHP and ICOBI for first-principles validation. Thevalidation shows that 106 dynamically stable materials with low normalized-ICOHP and ICOBI have LTC less than 5 W/mK, among which 68% are less than 2W/mK, while 13 stable materials with high normalized -ICOHP and ICOBI possessLTC higher than 100 W/mK. The proposed normalized -ICOHP and normalized ICOBIdescriptors offer deep insights into LTC and MSD from chemical bondingprinciples. Considering the cheap computational cost, these descriptors offer anew reliable and fast route for high-throughput screening of novel crystallinematerials with extreme LTCs for applications such as thermoelectrics andelectronic cooling.</description>
      <author>example@mail.com (Mohammed Al-Fahdi, Riccardo Rurali, Jianjun Hu, Christopher Wolverton, Ming Hu)</author>
      <guid isPermaLink="false">2410.16066v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Promoting cross-modal representations to improve multimodal foundation models for physiological signals</title>
      <link>http://arxiv.org/abs/2410.16424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 AIM-FM Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多医疗应用本质上是多模态的，涉及多种生理信号，传感器的普及使得改进多模态医疗数据的机器学习方法变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;探索在医疗领域开发基础模型的有效预训练策略，以应对多模态健康数据的挑战。&lt;h4&gt;方法&lt;/h4&gt;使用PhysioNet 2018数据集，采用掩蔽自编码目标进行多模态模型的预训练。&lt;h4&gt;主要发现&lt;/h4&gt;模型能够学习到适用于多种下游任务的表示，交叉模态重建目标对成功的多模态训练至关重要，输入空间的模态丢弃提高了下游任务的性能。&lt;h4&gt;结论&lt;/h4&gt;显式的跨模态诱导方法可能增强多模态预训练策略，模型的表示在注意力权重上变得更加跨模态和时间对齐，学习到的嵌入在各模态的分布上也更为广泛。&lt;h4&gt;总结&lt;/h4&gt;我们的研究展示了多模态基础模型在健康数据中的有效性，尤其是在多样的生理数据源之间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many healthcare applications are inherently multimodal, involving severalphysiological signals. As sensors for these signals become more common,improving machine learning methods for multimodal healthcare data is crucial.Pretraining foundation models is a promising avenue for success. However,methods for developing foundation models in healthcare are still in earlyexploration and it is unclear which pretraining strategies are most effectivegiven the diversity of physiological signals. This is partly due to challengesin multimodal health data: obtaining data across many patients is difficult andcostly, there is a lot of inter-subject variability, and modalities are oftenheterogeneously informative across downstream tasks. Here, we explore thesechallenges in the PhysioNet 2018 dataset. We use a masked autoencodingobjective to pretrain a multimodal model. We show that the model learnsrepresentations that can be linearly probed for a diverse set of downstreamtasks. We hypothesize that cross-modal reconstruction objectives are importantfor successful multimodal training, as they encourage the model to integrateinformation across modalities. We demonstrate that modality dropout in theinput space improves performance across downstream tasks. We also find thatlate-fusion models pretrained with contrastive learning objectives are lesseffective across multiple tasks. Finally, we analyze the model'srepresentations, showing that attention weights become more cross-modal andtemporally aligned with our pretraining strategy. The learned embeddings alsobecome more distributed in terms of the modalities encoded by each unit.Overall, our work demonstrates the utility of multimodal foundation models withhealth data, even across diverse physiological data sources. We further arguethat explicit methods for inducing cross-modality may enhance multimodalpretraining strategies.</description>
      <author>example@mail.com (Ching Fang, Christopher Sandino, Behrooz Mahasseni, Juri Minxha, Hadi Pouransari, Erdrin Azemi, Ali Moin, Ellen Zippi)</author>
      <guid isPermaLink="false">2410.16424v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Aligning Large Language Models via Self-Steering Optimization</title>
      <link>http://arxiv.org/abs/2410.17131v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自动化对齐系统的开发旨在减少人工干预，关键在于提供可学习和准确的偏好信号，而无需人工标注。&lt;h4&gt;目的&lt;/h4&gt;引入自我引导优化（SSO）算法，自动生成高质量的偏好信号，消除手动标注的需求。&lt;h4&gt;方法&lt;/h4&gt;SSO算法在迭代训练过程中基于预定义原则自主生成信号，保持选择和拒绝响应之间的一致差距，并确保信号符合当前政策模型的学习能力。&lt;h4&gt;主要发现&lt;/h4&gt;通过对Qwen2和Llama3.1两个基础模型的验证，SSO在迭代训练中提供了准确的、符合政策的偏好信号，显著提升了六个主观或客观基准的性能。&lt;h4&gt;结论&lt;/h4&gt;SSO在没有任何人工标注或外部模型的情况下，能够有效提升奖励模型在Rewardbench上的表现，展示了一种可扩展的偏好优化方法，为更高效的自动化对齐铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种高效的自动化对齐方法，通过自我引导优化提升了偏好信号的生成和模型训练的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/icip-cas/sso&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated alignment develops alignment systems with minimal humanintervention. The key to automated alignment lies in providing learnable andaccurate preference signals for preference learning without human annotation.In this paper, we introduce Self-Steering Optimization ($SSO$), an algorithmthat autonomously generates high-quality preference signals based on predefinedprinciples during iterative training, eliminating the need for manualannotation. $SSO$ maintains the accuracy of signals by ensuring a consistentgap between chosen and rejected responses while keeping them both on-policy tosuit the current policy model's learning capacity. $SSO$ can benefit the onlineand offline training of the policy model, as well as enhance the training ofreward models. We validate the effectiveness of $SSO$ with two foundationmodels, Qwen2 and Llama3.1, indicating that it provides accurate, on-policypreference signals throughout iterative training. Without any manual annotationor external models, $SSO$ leads to significant performance improvements acrosssix subjective or objective benchmarks. Besides, the preference data generatedby $SSO$ significantly enhanced the performance of the reward model onRewardbench. Our work presents a scalable approach to preference optimization,paving the way for more efficient and effective automated alignment.</description>
      <author>example@mail.com (Hao Xiang, Bowen Yu, Hongyu Lin, Keming Lu, Yaojie Lu, Xianpei Han, Le Sun, Jingren Zhou, Junyang Lin)</author>
      <guid isPermaLink="false">2410.17131v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Federated Learning with MMD-based Early Stopping for Adaptive GNSS Interference Classification</title>
      <link>http://arxiv.org/abs/2410.15681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联邦学习（FL）允许多个设备在不共享数据的情况下协同训练全局模型。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合少样本学习和模型权重聚合的FL方法，以应对设备间新颖且不平衡的数据特征分布问题。&lt;h4&gt;方法&lt;/h4&gt;引入动态早停方法，通过表示学习平衡分布外类，利用局部和全局模型特征嵌入之间的最大均值差异。&lt;h4&gt;主要发现&lt;/h4&gt;在使用GNSS接收器的干扰分类任务中，所提FL方法在适应新干扰类和多路径场景方面超过了现有技术。&lt;h4&gt;结论&lt;/h4&gt;通过在真实高速公路和受控环境中的四个GNSS数据集进行广泛实验，验证了所提方法的有效性。&lt;h4&gt;总结&lt;/h4&gt;该研究为联邦学习在新颖干扰分类中的应用提供了新思路，展示了其在复杂场景下的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning (FL) enables multiple devices to collaboratively train aglobal model while maintaining data on local servers. Each device trains themodel on its local server and shares only the model updates (i.e., gradientweights) during the aggregation step. A significant challenge in FL is managingthe feature distribution of novel, unbalanced data across devices. In thispaper, we propose an FL approach using few-shot learning and aggregation of themodel weights on a global server. We introduce a dynamic early stopping methodto balance out-of-distribution classes based on representation learning,specifically utilizing the maximum mean discrepancy of feature embeddingsbetween local and global models. An exemplary application of FL isorchestrating machine learning models along highways for interferenceclassification based on snapshots from global navigation satellite system(GNSS) receivers. Extensive experiments on four GNSS datasets from tworeal-world highways and controlled environments demonstrate that our FL methodsurpasses state-of-the-art techniques in adapting to both novel interferenceclasses and multipath scenarios.</description>
      <author>example@mail.com (Nishant S. Gaikwad, Lucas Heublein, Nisha L. Raichur, Tobias Feigl, Christopher Mutschler, Felix Ott)</author>
      <guid isPermaLink="false">2410.15681v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning on Transformers for Building Energy Consumption Forecasting -- A Comparative Study</title>
      <link>http://arxiv.org/abs/2410.14107v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究探讨了迁移学习（TL）在变压器架构中的应用，以增强建筑能源消费预测。&lt;h4&gt;目的&lt;/h4&gt;评估不同的TL策略在建筑能源消费预测中的有效性。&lt;h4&gt;方法&lt;/h4&gt;进行了广泛的实证研究，分析了六种不同的TL策略在不同特征空间下的表现，使用了16个数据集。&lt;h4&gt;主要发现&lt;/h4&gt;TL通常是有益的，尤其是在目标领域没有数据时，但需要仔细选择具体的TL策略以获得最大收益。PatchTST在性能上优于其他两种变压器变体。&lt;h4&gt;结论&lt;/h4&gt;研究结果将帮助研究人员在建筑能源消费预测中做出明智的TL和变压器架构选择。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了对迁移学习在建筑能源消费预测中应用的深入理解，强调了策略选择的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates the application of Transfer Learning (TL) onTransformer architectures to enhance building energy consumption forecasting.Transformers are a relatively new deep learning architecture, which has servedas the foundation for groundbreaking technologies such as ChatGPT. While TL hasbeen studied in the past, these studies considered either one TL strategy orused older deep learning models such as Recurrent Neural Networks orConvolutional Neural Networks. Here, we carry out an extensive empirical studyon six different TL strategies and analyse their performance under varyingfeature spaces. In addition to the vanilla Transformer architecture, we alsoexperiment with Informer and PatchTST, specifically designed for time seriesforecasting. We use 16 datasets from the Building Data Genome Project 2 tocreate building energy consumption forecasting models. Experiment resultsreveal that while TL is generally beneficial, especially when the target domainhas no data, careful selection of the exact TL strategy should be made to gainthe maximum benefit. This decision largely depends on the feature spaceproperties such as the recorded weather features. We also note that PatchTSToutperforms the other two Transformer variants (vanilla Transformer andInformer). We believe our findings would assist researchers in making informeddecision in using TL and transformer architectures for building energyconsumption forecasting.</description>
      <author>example@mail.com (Robert Spencer, Surangika Ranathunga, Mikael Boulic, Andries, van Heerden, Teo Susnjak)</author>
      <guid isPermaLink="false">2410.14107v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Fully Explicit Dynamic Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2410.15629v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting在静态场景中显示出快速且高质量的渲染效果，但在动态运动的新视图合成中存在局限。&lt;h4&gt;目的&lt;/h4&gt;设计一种显式的4D Gaussian Splatting（Ex4DGS），以解决动态场景中的渲染问题。&lt;h4&gt;方法&lt;/h4&gt;在训练过程中，将静态和动态高斯分开，并在稀疏时间戳上显式采样动态高斯的位置和旋转，随后进行插值以表示对象的空间和时间连续运动。同时引入逐步训练方案和点回溯技术以改善收敛性。&lt;h4&gt;主要发现&lt;/h4&gt;Ex4DGS在短时间戳下初步训练，并逐步延长时间戳，能够在少量点云的情况下良好运行；点回溯用于量化每个高斯随时间的累积误差，从而检测和移除动态场景中的错误高斯。&lt;h4&gt;结论&lt;/h4&gt;在各类场景上的综合实验表明，该方法实现了最先进的渲染质量，在单个2080Ti GPU上达到62帧每秒的快速渲染效果。&lt;h4&gt;总结&lt;/h4&gt;Ex4DGS通过分离静态和动态高斯并优化训练过程，有效提升了动态场景中的渲染效率和质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting has shown fast and high-quality rendering results instatic scenes by leveraging dense 3D prior and explicit representations.Unfortunately, the benefits of the prior and representation do not involvenovel view synthesis for dynamic motions. Ironically, this is because the mainbarrier is the reliance on them, which requires increasing training andrendering times to account for dynamic motions. In this paper, we design aExplicit 4D Gaussian Splatting(Ex4DGS). Our key idea is to firstly separatestatic and dynamic Gaussians during training, and to explicitly samplepositions and rotations of the dynamic Gaussians at sparse timestamps. Thesampled positions and rotations are then interpolated to represent bothspatially and temporally continuous motions of objects in dynamic scenes aswell as reducing computational cost. Additionally, we introduce a progressivetraining scheme and a point-backtracking technique that improves Ex4DGS'sconvergence. We initially train Ex4DGS using short timestamps and progressivelyextend timestamps, which makes it work well with a few point clouds. Thepoint-backtracking is used to quantify the cumulative error of each Gaussianover time, enabling the detection and removal of erroneous Gaussians in dynamicscenes. Comprehensive experiments on various scenes demonstrate thestate-of-the-art rendering quality from our method, achieving fast rendering of62 fps on a single 2080Ti GPU.</description>
      <author>example@mail.com (Junoh Lee, Chang-Yeon Won, Hyunjun Jung, Inhwan Bae, Hae-Gon Jeon)</author>
      <guid isPermaLink="false">2410.15629v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Do Audio-Language Models Understand Linguistic Variations?</title>
      <link>http://arxiv.org/abs/2410.16505v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;开放词汇音频语言模型（ALMs），如对比语言音频预训练（CLAP），为使用自然语言查询进行音频-文本检索提供了新的范式。&lt;h4&gt;目的&lt;/h4&gt;展示现有ALMs在处理文本查询的语言变异性时的泛化能力不足。&lt;h4&gt;方法&lt;/h4&gt;提出RobustCLAP，一种新颖且计算效率高的技术，通过引入多视角对比学习目标来改进CLAP的对比损失，将同一音频场景的不同释义视为不同视角进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;RobustCLAP提升了CLAP在音频检索任务中的性能，增幅为0.8%-13%，并增强了对语言变异的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;RobustCLAP有效解决了现有ALMs在处理语言变异时的局限性，提升了音频-文本检索的效果。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新方法，改进了音频语言模型在多样化语言查询中的表现，具有重要的应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary audio language models (ALMs), like Contrastive Language AudioPretraining (CLAP), represent a promising new paradigm for audio-text retrievalusing natural language queries. In this paper, for the first time, we performcontrolled experiments on various benchmarks to show that existing ALMsstruggle to generalize to linguistic variations in textual queries. To addressthis issue, we propose RobustCLAP, a novel and compute-efficient technique tolearn audio-language representations agnostic to linguistic variations.Specifically, we reformulate the contrastive loss used in CLAP architectures byintroducing a multi-view contrastive learning objective, where paraphrases aretreated as different views of the same audio scene and use this for training.Our proposed approach improves the text-to-audio retrieval performance of CLAPby 0.8%-13% across benchmarks and enhances robustness to linguistic variation.</description>
      <author>example@mail.com (Ramaneswaran Selvakumar, Sonal Kumar, Hemant Kumar Giri, Nishit Anand, Ashish Seth, Sreyan Ghosh, Dinesh Manocha)</author>
      <guid isPermaLink="false">2410.16505v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Are Visual-Language Models Effective in Action Recognition? A Comparative Study</title>
      <link>http://arxiv.org/abs/2410.17149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的视觉语言基础模型，如CLIP，在各种下游任务中表现出了显著的性能提升。&lt;h4&gt;目的&lt;/h4&gt;探讨这些基础模型是否显著改善更复杂的细粒度动作识别任务，并为人类行为分析的未来研究方向提供见解。&lt;h4&gt;方法&lt;/h4&gt;通过对当前最先进的视觉基础模型进行大规模研究，比较它们在零样本和逐帧动作识别任务上的可迁移性。&lt;h4&gt;主要发现&lt;/h4&gt;在近期的细粒度人类中心动作识别数据集（如Toyota Smarthome、Penn Action、UAV-Human、TSU、Charades）上进行了广泛的实验，包括动作分类和分割。&lt;h4&gt;结论&lt;/h4&gt;基础模型的有效性在复杂动作识别任务中的表现仍需进一步研究。&lt;h4&gt;总结&lt;/h4&gt;本研究为理解视觉语言模型在实际应用中的潜力提供了重要的实验数据和分析。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current vision-language foundation models, such as CLIP, have recently shownsignificant improvement in performance across various downstream tasks.However, whether such foundation models significantly improve more complexfine-grained action recognition tasks is still an open question. To answer thisquestion and better find out the future research direction on human behavioranalysis in-the-wild, this paper provides a large-scale study and insight oncurrent state-of-the-art vision foundation models by comparing their transferability onto zero-shot and frame-wise action recognition tasks. Extensiveexperiments are conducted on recent fine-grained, human-centric actionrecognition datasets (e.g., Toyota Smarthome, Penn Action, UAV-Human, TSU,Charades) including action classification and segmentation.</description>
      <author>example@mail.com (Mahmoud Ali, Di Yang, François Brémond)</author>
      <guid isPermaLink="false">2410.17149v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>MI-VisionShot: Few-shot adaptation of vision-language models for slide-level classification of histopathological images</title>
      <link>http://arxiv.org/abs/2410.15881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript accepted for oral presentation at KES-InnovationInMedicine
  2024 held on Madeira, Portugal&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;视觉语言监督在从文本指导中学习视觉表征方面取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的训练无关的适应方法MI-VisionShot，以在少量学习场景中预测幻灯片级标签。&lt;h4&gt;方法&lt;/h4&gt;MI-VisionShot基于视觉语言模型（VLM），通过原型学习创建基于原型的分类器，并在多实例设置下检索每个幻灯片中最具区分性的补丁。&lt;h4&gt;主要发现&lt;/h4&gt;MI-VisionShot在不同设置下的实验表明，其在低-shot场景下能以较低的可变性超越零-shot迁移。&lt;h4&gt;结论&lt;/h4&gt;MI-VisionShot展示了在少量学习中的有效性，能够更好地处理幻灯片级预测。&lt;h4&gt;总结&lt;/h4&gt;该研究为数字病理学中的视觉语言模型适应提供了一种新方法，结合了强大的表征学习和原型学习的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language supervision has made remarkable strides in learning visualrepresentations from textual guidance. In digital pathology, vision-languagemodels (VLM), pre-trained on curated datasets of histological image-captions,have been adapted to downstream tasks, such as region of interestclassification. Zero-shot transfer for slide-level prediction has beenformulated by MI-Zero, but it exhibits high variability depending on thetextual prompts. Inspired by prototypical learning, we propose MI-VisionShot, atraining-free adaptation method on top of VLMs to predict slide-level labels infew-shot learning scenarios. Our framework takes advantage of the excellentrepresentation learning of VLM to create prototype-based classifiers under amultiple-instance setting by retrieving the most discriminative patches withineach slide. Experimentation through different settings shows the ability ofMI-VisionShot to surpass zero-shot transfer with lower variability, even inlow-shot scenarios. Code coming soon atthttps://github.com/cvblab/MIVisionShot.</description>
      <author>example@mail.com (Pablo Meseguer, Rocío del Amor, Valery Naranjo)</author>
      <guid isPermaLink="false">2410.15881v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Predicting the trajectory of intracranial pressure in patients with traumatic brain injury: evaluation of a foundation model for time series</title>
      <link>http://arxiv.org/abs/2410.14333v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;创伤性脑损伤(TBI)患者常出现颅内压(IICP)病理性升高，导致颅内高压(tIH)的发生，这是常见且严重的并发症。&lt;h4&gt;目的&lt;/h4&gt;早期预警颅内压升高，以改善患者预后，促进临床干预。&lt;h4&gt;方法&lt;/h4&gt;研究基础模型，通过迁移学习探讨其在可靠预测模型开发中的潜力。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型可能为颅内压升高的预测提供有效解决方案。&lt;h4&gt;结论&lt;/h4&gt;基础模型的应用值得进一步探索，以应对患者数据的不足问题。&lt;h4&gt;总结&lt;/h4&gt;本研究旨在利用基础模型提高对颅内压升高的预测能力，从而改善创伤性脑损伤患者的临床结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patients with traumatic brain injury (TBI) often experience pathologicalincreases in intracranial pressure (ICP), leading to intracranial hypertension(tIH), a common and serious complication. Early warning of an impending rise inICP could potentially improve patient outcomes by enabling preemptive clinicalintervention. However, the limited availability of patient data poses achallenge in developing reliable prediction models. In this study, we aim todetermine whether foundation models, which leverage transfer learning, mayoffer a promising solution.</description>
      <author>example@mail.com (Florian D. van Leeuwen, Shubhayu Bhattacharyay, Alex Carriero, Ethan Jacob Moyer, Richard Moberg)</author>
      <guid isPermaLink="false">2410.14333v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Graph Sampling for Scalable and Expressive Graph Neural Networks on Homophilic Graphs</title>
      <link>http://arxiv.org/abs/2410.16593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）在许多图机器学习任务中表现优异，但在扩展到大规模网络时面临挑战。&lt;h4&gt;目的&lt;/h4&gt;研究GNN的可转移性，以便在较小的图上训练模型并将其应用于更大的图。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的图采样算法，利用特征同质性来保留图结构，通过最小化数据相关矩阵的迹，优于随机采样。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在保留图拉普拉斯的秩方面表现更好，且复杂度低于谱方法，与随机采样相比，在引用网络上的实验显示出更好的性能。&lt;h4&gt;结论&lt;/h4&gt;新算法有效地提高了GNN的可转移性，并在图的秩保存方面取得了显著改善。&lt;h4&gt;总结&lt;/h4&gt;通过特征同质性的方法，提升了大规模图的GNN训练和应用效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) excel in many graph machine learning tasks butface challenges when scaling to large networks. GNN transferability allowstraining on smaller graphs and applying the model to larger ones, but existingmethods often rely on random subsampling, leading to disconnected subgraphs andreduced model expressivity. We propose a novel graph sampling algorithm thatleverages feature homophily to preserve graph structure. By minimizing thetrace of the data correlation matrix, our method better preserves the graphLaplacian's rank than random sampling while achieving lower complexity thanspectral methods. Experiments on citation networks show improved performance inpreserving graph rank and GNN transferability compared to random sampling.</description>
      <author>example@mail.com (Haolin Li, Luana Ruiz)</author>
      <guid isPermaLink="false">2410.16593v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Progressive Compositionality In Text-to-Image Generative Models</title>
      <link>http://arxiv.org/abs/2410.16719v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管扩散模型在文本到图像（T2I）合成方面表现出色，但在复杂环境中理解对象与属性之间的组合关系时常面临挑战。&lt;h4&gt;目的&lt;/h4&gt;探索是否可以生成高质量的复杂对比图像，以便扩散模型能够直接通过视觉表示进行区分。&lt;h4&gt;方法&lt;/h4&gt;利用大型语言模型（LLMs）创建现实且复杂的场景，并结合视觉问答（VQA）系统与扩散模型自动策划对比数据集ConPair，包含15,000对高质量对比图像。&lt;h4&gt;主要发现&lt;/h4&gt;这些对比图像在视觉上差异最小，涵盖广泛的属性类别，特别是复杂和自然场景。&lt;h4&gt;结论&lt;/h4&gt;提出EvoGen，一个新的多阶段课程，用于扩散模型的对比学习，展示了在各种组合场景下的有效性。&lt;h4&gt;总结&lt;/h4&gt;通过广泛的实验验证了所提出的框架在组合T2I基准上的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the impressive text-to-image (T2I) synthesis capabilities ofdiffusion models, they often struggle to understand compositional relationshipsbetween objects and attributes, especially in complex settings. Existingsolutions have tackled these challenges by optimizing the cross-attentionmechanism or learning from the caption pairs with minimal semantic changes.However, can we generate high-quality complex contrastive images that diffusionmodels can directly discriminate based on visual representations? In this work,we leverage large-language models (LLMs) to compose realistic, complexscenarios and harness Visual-Question Answering (VQA) systems alongsidediffusion models to automatically curate a contrastive dataset, ConPair,consisting of 15k pairs of high-quality contrastive images. These pairs featureminimal visual discrepancies and cover a wide range of attribute categories,especially complex and natural scenarios. To learn effectively from these errorcases, i.e., hard negative images, we propose EvoGen, a new multi-stagecurriculum for contrastive learning of diffusion models. Through extensiveexperiments across a wide range of compositional scenarios, we showcase theeffectiveness of our proposed framework on compositional T2I benchmarks.</description>
      <author>example@mail.com (Xu Han, Linghao Jin, Xiaofeng Liu, Paul Pu Liang)</author>
      <guid isPermaLink="false">2410.16719v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Towards Reliable Evaluation of Behavior Steering Interventions in LLMs</title>
      <link>http://arxiv.org/abs/2410.17245v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the NeurIPS 2024 - Workshop on Foundation Model
  Interventions&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;表示工程方法在有效引导模型行为方面显示出潜力，但评估流程主要依赖主观演示，而非定量、客观的指标。&lt;h4&gt;目的&lt;/h4&gt;解决当前评估中缺失的四个属性，以提高评估的有效性和客观性。&lt;h4&gt;方法&lt;/h4&gt;提出一个基于四个评估属性的评估流程，提供定量和可视化分析。&lt;h4&gt;主要发现&lt;/h4&gt;在评估两种表示工程方法时，发现某些干预措施的有效性低于先前报告的结果。&lt;h4&gt;结论&lt;/h4&gt;引入的评估流程能够更准确地评估模型行为的引导效果。&lt;h4&gt;总结&lt;/h4&gt;通过改进评估流程，能够更客观地分析表示工程方法的有效性，推动该领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation engineering methods have recently shown promise for enablingefficient steering of model behavior. However, evaluation pipelines for thesemethods have primarily relied on subjective demonstrations, instead ofquantitative, objective metrics. We aim to take a step towards addressing thisissue by advocating for four properties missing from current evaluations: (i)contexts sufficiently similar to downstream tasks should be used for assessingintervention quality; (ii) model likelihoods should be accounted for; (iii)evaluations should allow for standardized comparisons across different targetbehaviors; and (iv) baseline comparisons should be offered. We introduce anevaluation pipeline grounded in these criteria, offering both a quantitativeand visual analysis of how effectively a given method works. We use thispipeline to evaluate two representation engineering methods on how effectivelythey can steer behaviors such as truthfulness and corrigibility, finding thatsome interventions are less effective than previously reported.</description>
      <author>example@mail.com (Itamar Pres, Laura Ruis, Ekdeep Singh Lubana, David Krueger)</author>
      <guid isPermaLink="false">2410.17245v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Learning Quadrotor Control From Visual Features Using Differentiable Simulation</title>
      <link>http://arxiv.org/abs/2410.15979v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Submission&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;强化学习在机器人技术中的样本效率低下仍然是一个重要挑战，尤其是在视觉控制任务中，可靠的状态估计难以获得。&lt;h4&gt;目的&lt;/h4&gt;探索可微仿真在学习四旋翼控制中的潜力。&lt;h4&gt;方法&lt;/h4&gt;采用可微仿真技术，通过动力学模型进行梯度反向传播，提供低方差的分析政策梯度，从而提高样本效率。&lt;h4&gt;主要发现&lt;/h4&gt;在可微仿真中训练显著优于无模型强化学习，无论在样本效率还是训练时间上，四旋翼可以在几秒内恢复状态。&lt;h4&gt;结论&lt;/h4&gt;可微仿真为现实世界的机器人任务提供了一个有前途的替代方案，尤其是在仅依赖视觉特征的情况下。&lt;h4&gt;方法细节&lt;/h4&gt;使用简单的替代模型加速梯度计算，并结合状态表示学习与策略学习，提升收敛速度。&lt;h4&gt;总结&lt;/h4&gt;可微仿真技术在机器人控制中展示了其高效性，为传统强化学习方法提供了有力的替代选择。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The sample inefficiency of reinforcement learning (RL) remains a significantchallenge in robotics. RL requires large-scale simulation and, still, can causelong training times, slowing down research and innovation. This issue isparticularly pronounced in vision-based control tasks where reliable stateestimates are not accessible. Differentiable simulation offers an alternativeby enabling gradient back-propagation through the dynamics model, providinglow-variance analytical policy gradients and, hence, higher sample efficiency.However, its usage for real-world robotic tasks has yet been limited. This workdemonstrates the great potential of differentiable simulation for learningquadrotor control. We show that training in differentiable simulationsignificantly outperforms model-free RL in terms of both sample efficiency andtraining time, allowing a policy to learn to recover a quadrotor in secondswhen providing vehicle state and in minutes when relying solely on visualfeatures. The key to our success is two-fold. First, the use of a simplesurrogate model for gradient computation greatly accelerates training withoutsacrificing control performance. Second, combining state representationlearning with policy learning enhances convergence speed in tasks where onlyvisual features are observable. These findings highlight the potential ofdifferentiable simulation for real-world robotics and offer a compellingalternative to conventional RL approaches.</description>
      <author>example@mail.com (Johannes Heeg, Yunlong Song, Davide Scaramuzza)</author>
      <guid isPermaLink="false">2410.15979v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Reinforcement Learning in Heterogeneous Action Spaces using Subgoal Mapping</title>
      <link>http://arxiv.org/abs/2410.14484v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本文考虑了一种转移强化学习问题，涉及具有不同动作空间的智能体。&lt;h4&gt;目的&lt;/h4&gt;针对任何新的未见任务，目标是利用专家智能体在其动作空间中的成功示范，帮助学习者智能体在不同的动作空间中学习最优策略，同时减少样本需求。&lt;h4&gt;方法&lt;/h4&gt;提出了一种方法，通过训练长短期记忆网络（LSTM）学习专家智能体政策与学习者智能体政策之间的子目标映射。&lt;h4&gt;主要发现&lt;/h4&gt;通过数值实验，证明了所提学习方案能够有效找到给定任务分布下的子目标映射。&lt;h4&gt;结论&lt;/h4&gt;让学习者智能体模仿专家智能体的政策，利用学习到的子目标映射，可以显著提高学习者在未见新任务中的样本效率和训练时间。&lt;h4&gt;总结&lt;/h4&gt;本文提出的方法在不同动作空间下的转移学习中有效提高了学习效率，减少了对样本的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we consider a transfer reinforcement learning probleminvolving agents with different action spaces. Specifically, for any new unseentask, the goal is to use a successful demonstration of this task by an expertagent in its action space to enable a learner agent learn an optimal policy inits own different action space with fewer samples than those required if thelearner was learning on its own. Existing transfer learning methods acrossdifferent action spaces either require handcrafted mappings between thoseaction spaces provided by human experts, which can induce bias in the learningprocedure, or require the expert agent to share its policy parameters with thelearner agent, which does not generalize well to unseen tasks. In this work, wepropose a method that learns a subgoal mapping between the expert agent policyand the learner agent policy. Since the expert agent and the learner agent havedifferent action spaces, their optimal policies can have different subgoaltrajectories. We learn this subgoal mapping by training a Long Short TermMemory (LSTM) network for a distribution of tasks and then use this mapping topredict the learner subgoal sequence for unseen tasks, thereby improving thespeed of learning by biasing the agent's policy towards the predicted learnersubgoal sequence. Through numerical experiments, we demonstrate that theproposed learning scheme can effectively find the subgoal mapping underlyingthe given distribution of tasks. Moreover, letting the learner agent imitatethe expert agent's policy with the learnt subgoal mapping can significantlyimprove the sample efficiency and training time of the learner agent in unseennew tasks.</description>
      <author>example@mail.com (Kavinayan P. Sivakumar, Yan Zhang, Zachary Bell, Scott Nivison, Michael M. Zavlanos)</author>
      <guid isPermaLink="false">2410.14484v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>GALA: Graph Diffusion-based Alignment with Jigsaw for Source-free Domain Adaptation</title>
      <link>http://arxiv.org/abs/2410.16606v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE TPAMI&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;源无关领域适应是机器学习中的一个重要话题，尤其涉及数据隐私的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法GALA，用于源无关图领域适应。&lt;h4&gt;方法&lt;/h4&gt;GALA使用图扩散模型从目标数据重建源风格图，通过随机微分方程引入扰动，并利用课程学习生成准确的伪标签。&lt;h4&gt;主要发现&lt;/h4&gt;GALA在基准数据集上的实验验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;GALA提高了图神经网络在源无关适应场景中的表现，并增强了泛化能力和鲁棒性。&lt;h4&gt;总结&lt;/h4&gt;本研究为源无关图领域适应提供了一种新颖的方法，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TPAMI.2024.3416372&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/luo-junyu/gala&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Source-free domain adaptation is a crucial machine learning topic, as itcontains numerous applications in the real world, particularly with respect todata privacy. Existing approaches predominantly focus on Euclidean data, suchas images and videos, while the exploration of non-Euclidean graph data remainsscarce. Recent graph neural network (GNN) approaches can suffer from seriousperformance decline due to domain shift and label scarcity in source-freeadaptation scenarios. In this study, we propose a novel method named GraphDiffusion-based Alignment with Jigsaw (GALA), tailored for source-free graphdomain adaptation. To achieve domain alignment, GALA employs a graph diffusionmodel to reconstruct source-style graphs from target data. Specifically, ascore-based graph diffusion model is trained using source graphs to learn thegenerative source styles. Then, we introduce perturbations to target graphs viaa stochastic differential equation instead of sampling from a prior, followedby the reverse process to reconstruct source-style graphs. We feed thesource-style graphs into an off-the-shelf GNN and introduce class-specificthresholds with curriculum learning, which can generate accurate and unbiasedpseudo-labels for target graphs. Moreover, we develop a simple yet effectivegraph-mixing strategy named graph jigsaw to combine confident graphs andunconfident graphs, which can enhance generalization capabilities androbustness via consistency learning. Extensive experiments on benchmarkdatasets validate the effectiveness of GALA.</description>
      <author>example@mail.com (Junyu Luo, Yiyang Gu, Xiao Luo, Wei Ju, Zhiping Xiao, Yusheng Zhao, Jingyang Yuan, Ming Zhang)</author>
      <guid isPermaLink="false">2410.16606v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>MSGField: A Unified Scene Representation Integrating Motion, Semantics, and Geometry for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2410.15730v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;结合准确的几何形状与丰富的语义信息被证明对语言引导的机器人操作非常有效。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法MSGField，以提高动态场景下的实时更新能力，克服现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;使用一组2D高斯分布进行高质量重建，并通过运动基的组合来紧凑表示运动场，利用可微分的实时渲染实现快速优化。&lt;h4&gt;主要发现&lt;/h4&gt;在挑战性数据集中，该方法在静态环境中的成功率为79.2%，动态环境为63.3%；对于特定物体抓取，成功率达到90%。&lt;h4&gt;结论&lt;/h4&gt;MSGField在语言引导的操作中表现出色，具有良好的实时性能和高成功率，与基于点云的方法相当。&lt;h4&gt;总结&lt;/h4&gt;该方法有效整合了几何与语义信息，为机器人操控提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Combining accurate geometry with rich semantics has been proven to be highlyeffective for language-guided robotic manipulation. Existing methods fordynamic scenes either fail to update in real-time or rely on additional depthsensors for simple scene editing, limiting their applicability in real-world.In this paper, we introduce MSGField, a representation that uses a collectionof 2D Gaussians for high-quality reconstruction, further enhanced withattributes to encode semantic and motion information. Specially, we representthe motion field compactly by decomposing each primitive's motion into acombination of a limited set of motion bases. Leveraging the differentiablereal-time rendering of Gaussian splatting, we can quickly optimize objectmotion, even for complex non-rigid motions, with image supervision from onlytwo camera views. Additionally, we designed a pipeline that utilizes objectpriors to efficiently obtain well-defined semantics. In our challengingdataset, which includes flexible and extremely small objects, our methodachieve a success rate of 79.2% in static and 63.3% in dynamic environments forlanguage-guided manipulation. For specified object grasping, we achieve asuccess rate of 90%, on par with point cloud-based methods. Code and datasetwill be released at:https://shengyu724.github.io/MSGField.github.io.</description>
      <author>example@mail.com (Yu Sheng, Runfeng Lin, Lidian Wang, Quecheng Qiu, YanYong Zhang, Yu Zhang, Bei Hua, Jianmin Ji)</author>
      <guid isPermaLink="false">2410.15730v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Bridging the Modality Gap: Dimension Information Alignment and Sparse Spatial Constraint for Image-Text Matching</title>
      <link>http://arxiv.org/abs/2410.16853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多基于对比学习的模型在图像-文本匹配任务中取得了先进的性能，这些模型的关键在于分析图像-文本对之间的相关性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法DIAS，以弥补不同模态之间的差距。&lt;h4&gt;方法&lt;/h4&gt;{'信息对齐': '对不同模态的嵌入信息进行对齐，以确保相关性计算基于相似信息的交互。', '空间约束': '引入跨模态和内模态未匹配对的空间约束，确保模型的语义对齐有效。', '稀疏相关算法': '提出稀疏相关算法，选择强相关的空间关系，以便模型学习更显著的特征，避免被弱相关性误导。'}&lt;h4&gt;主要发现&lt;/h4&gt;DIAS在Flickr30k和MSCOCO基准测试中实现了4.3%-10.2%的rSum提升，显示出其优越性。&lt;h4&gt;结论&lt;/h4&gt;DIAS方法有效地弥补了模态差距，提高了图像-文本匹配的性能。&lt;h4&gt;总结&lt;/h4&gt;通过信息对齐和引入空间约束，DIAS在对比学习模型中展示了更强的相关性捕捉能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many contrastive learning based models have achieved advanced performance inimage-text matching tasks. The key of these models lies in analyzing thecorrelation between image-text pairs, which involves cross-modal interaction ofembeddings in corresponding dimensions. However, the embeddings of differentmodalities are from different models or modules, and there is a significantmodality gap. Directly interacting such embeddings lacks rationality and maycapture inaccurate correlation. Therefore, we propose a novel method calledDIAS to bridge the modality gap from two aspects: (1) We align the informationrepresentation of embeddings from different modalities in correspondingdimension to ensure the correlation calculation is based on interactions ofsimilar information. (2) The spatial constraints of inter- and intra-modalitiesunmatched pairs are introduced to ensure the effectiveness of semanticalignment of the model. Besides, a sparse correlation algorithm is proposed toselect strong correlated spatial relationships, enabling the model to learnmore significant features and avoid being misled by weak correlation. Extensiveexperiments demonstrate the superiority of DIAS, achieving 4.3\%-10.2\% rSumimprovements on Flickr30k and MSCOCO benchmarks.</description>
      <author>example@mail.com (Xiang Ma, Xuemei Li, Lexin Fang, Caiming Zhang)</author>
      <guid isPermaLink="false">2410.16853v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Captions Speak Louder than Images (CASLIE): Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data</title>
      <link>http://arxiv.org/abs/2410.17337v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Xinyi Ling and Bo Peng contributed equally to this paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态数据在电子商务应用中的突破性进展受到研究界的关注，但存在显著的挑战。&lt;h4&gt;目的&lt;/h4&gt;解决多模态电子商务数据的使用障碍，特别是数据集和信息整合方法的缺乏。&lt;h4&gt;方法&lt;/h4&gt;提出MMECInstruct，这是首个大规模高质量的电子商务多模态指令数据集，并开发了轻量级框架CASLIE用于信息集成。&lt;h4&gt;主要发现&lt;/h4&gt;CASLIE模型在领域内评估中显著优于五类先进基线模型，并在领域外设置中表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;MMECInstruct和CASLIE模型已公开可用，推动电子商务领域的多模态研究。&lt;h4&gt;总结&lt;/h4&gt;研究提出了新的数据集和模型框架，有助于提升多模态电子商务应用的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging multimodal data to drive breakthroughs in e-commerce applicationsthrough Multimodal Foundation Models (MFMs) is gaining increasing attentionfrom the research community. However, there are significant challenges thathinder the optimal use of multimodal e-commerce data by foundation models: (1)the scarcity of large-scale, high-quality multimodal benchmark datasets; and(2) the lack of effective multimodal information integration methods. Toaddress these challenges, in this paper, we introduce MMECInstruct, thefirst-ever, large-scale, and high-quality multimodal instruction dataset fore-commerce. We also develop CASLIE, a simple, lightweight, yet effectiveframework for integrating multimodal information for e-commerce. LeveragingMMECInstruct, we fine-tune a series of e-commerce MFMs within CASLIE, denotedas CASLIE models. Our comprehensive evaluation demonstrates that CASLIE modelssubstantially outperform 5 categories of advanced baseline models in thein-domain evaluation. Moreover, CASLIE models show strong generalizability toout-of-domain settings. MMECInstruct and CASLIE models are publicly accessiblethrough https://ninglab.github.io/CASLIE/.</description>
      <author>example@mail.com (Xinyi Ling, Bo Peng, Hanwen Du, Zhihui Zhu, Xia Ning)</author>
      <guid isPermaLink="false">2410.17337v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Granularity Matters in Long-Tail Learning</title>
      <link>http://arxiv.org/abs/2410.15980v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习中，长尾数据分布的训练平衡一直是一个长期挑战，尽管重加权和重抽样等方法有所帮助，但样本多样性不足仍阻碍模型学习稳健和可泛化的特征表示，尤其是对尾类。&lt;h4&gt;目的&lt;/h4&gt;探讨数据集粒度对长尾学习的影响，并提出通过类别外推增加数据集粒度的方法。&lt;h4&gt;方法&lt;/h4&gt;引入开放集辅助类，这些类在视觉上与现有类相似，以增强头类和尾类的表示学习。同时，利用大语言模型作为知识库，通过网络爬虫搜索和检索辅助类别的相关图像。&lt;h4&gt;主要发现&lt;/h4&gt;数据集粒度增加能够增强尾类特征的泛化能力，实验和消融研究表明，所提方法明显优于使用相同数据量的强基线方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效解决了长尾数据学习中的不平衡问题，相关代码将公开发布。&lt;h4&gt;总结&lt;/h4&gt;通过细粒度数据集和邻居静音损失，改进了长尾学习的模型性能，展示了新方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Balancing training on long-tail data distributions remains a long-standingchallenge in deep learning. While methods such as re-weighting and re-samplinghelp alleviate the imbalance issue, limited sample diversity continues tohinder models from learning robust and generalizable feature representations,particularly for tail classes. In contrast to existing methods, we offer anovel perspective on long-tail learning, inspired by an observation: datasetswith finer granularity tend to be less affected by data imbalance. In thispaper, we investigate this phenomenon through both quantitative and qualitativestudies, showing that increased granularity enhances the generalization oflearned features in tail categories. Motivated by these findings, we propose amethod to increase dataset granularity through category extrapolation.Specifically, we introduce open-set auxiliary classes that are visually similarto existing ones, aiming to enhance representation learning for both head andtail classes. This forms the core contribution and insight of our approach. Toautomate the curation of auxiliary data, we leverage large language models(LLMs) as knowledge bases to search for auxiliary categories and retrieverelevant images through web crawling. To prevent the overwhelming presence ofauxiliary classes from disrupting training, we introduce a neighbor-silencingloss that encourages the model to focus on class discrimination within thetarget dataset. During inference, the classifier weights for auxiliarycategories are masked out, leaving only the target class weights for use.Extensive experiments and ablation studies on three standard long-tailbenchmarks demonstrate the effectiveness of our approach, notably outperformingstrong baseline methods that use the same amount of data. The code will be madepublicly available.</description>
      <author>example@mail.com (Shizhen Zhao, Xin Wen, Jiahui Liu, Chuofan Ma, Chunfeng Yuan, Xiaojuan Qi)</author>
      <guid isPermaLink="false">2410.15980v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>How Does Data Diversity Shape the Weight Landscape of Neural Networks?</title>
      <link>http://arxiv.org/abs/2410.14602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;为了增强机器学习模型对未见数据的泛化能力，常用技术包括dropout、权重衰减（$L_2$正则化）和噪声增强。&lt;h4&gt;目的&lt;/h4&gt;研究这些技术对神经网络参数空间的影响，理解它们如何在迁移学习场景中改变权重分布。&lt;h4&gt;方法&lt;/h4&gt;采用随机矩阵理论分析预训练模型的特征值分布，这些模型经过不同数据多样性水平的微调，针对相同的下游任务。&lt;h4&gt;主要发现&lt;/h4&gt;多样化的数据影响权重分布，类似于dropout的效果。同时，将常用数据增强方法与生成模型创建的合成数据进行比较。&lt;h4&gt;结论&lt;/h4&gt;合成数据能够为真实输入数据带来更多多样性，从而在分布外测试实例中提高性能。&lt;h4&gt;总结&lt;/h4&gt;本文探讨了不同正则化和数据增强技术对模型性能的影响，强调合成数据在提高模型泛化能力方面的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; To enhance the generalization of machine learning models to unseen data,techniques such as dropout, weight decay ($L_2$ regularization), and noiseaugmentation are commonly employed. While regularization methods (i.e., dropoutand weight decay) are geared toward adjusting model parameters to preventoverfitting, data augmentation increases the diversity of the input trainingset, a method purported to improve accuracy and calibration error. In thispaper, we investigate the impact of each of these techniques on the parameterspace of neural networks, with the goal of understanding how they alter theweight landscape in transfer learning scenarios. To accomplish this, we employRandom Matrix Theory to analyze the eigenvalue distributions of pre-trainedmodels, fine-tuned using these techniques but using different levels of datadiversity, for the same downstream tasks. We observe that diverse datainfluences the weight landscape in a similar fashion as dropout. Additionally,we compare commonly used data augmentation methods with synthetic data createdby generative models. We conclude that synthetic data can bring more diversityinto real input data, resulting in a better performance on out-of-distributiontest instances.</description>
      <author>example@mail.com (Yang Ba, Michelle V. Mancenido, Rong Pan)</author>
      <guid isPermaLink="false">2410.14602v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Can Large Language Models Act as Ensembler for Multi-GNNs?</title>
      <link>http://arxiv.org/abs/2410.16822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在图结构数据学习中表现出色，但缺乏对丰富文本节点属性的内在语义理解能力，限制了其在应用中的有效性。&lt;h4&gt;目的&lt;/h4&gt;研究大型语言模型（LLMs）是否可以作为多种GNN的集成器，并提出LensGNN模型。&lt;h4&gt;方法&lt;/h4&gt;LensGNN模型首先对多个GNN进行对齐，将不同GNN的表示映射到同一空间。然后，通过LoRA微调，将GNN与LLM之间的空间对齐，注入图令牌和文本信息。&lt;h4&gt;主要发现&lt;/h4&gt;LensGNN能够整合多个GNN，并利用LLM的优势，从而实现更好的性能。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，LensGNN超越了现有模型，为文本属性图的集成学习提供了一种强大而优越的解决方案。&lt;h4&gt;总结&lt;/h4&gt;本研究推动了文本属性图的集成学习，并提供了代码和数据链接。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have emerged as powerful models for learningfrom graph-structured data. However, GNNs lack the inherent semanticunderstanding capability of rich textual nodesattributes, limiting theireffectiveness in applications. On the other hand, we empirically observe thatfor existing GNN models, no one can consistently outperforms others acrossdiverse datasets. In this paper, we study whether LLMs can act as an ensemblerfor multi-GNNs and propose the LensGNN model. The model first aligns multipleGNNs, mapping the representations of different GNNs into the same space. Then,through LoRA fine-tuning, it aligns the space between the GNN and the LLM,injecting graph tokens and textual information into LLMs. This allows LensGNNto integrate multiple GNNs and leverage LLM's strengths, resulting in betterperformance. Experimental results show that LensGNN outperforms existingmodels. This research advances text-attributed graph ensemble learning byproviding a robust, superior solution for integrating semantic and structuralinformation. We provide our code and data here:https://anonymous.4open.science/r/EnsemGNN-E267/.</description>
      <author>example@mail.com (Hanqi Duan, Yao Cheng, Jianxiang Yu, Xiang Li)</author>
      <guid isPermaLink="false">2410.16822v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>WildOcc: A Benchmark for Off-Road 3D Semantic Occupancy Prediction</title>
      <link>http://arxiv.org/abs/2410.15792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D语义占用预测是自动驾驶的重要组成部分，特别关注场景的几何细节。&lt;h4&gt;目的&lt;/h4&gt;针对缺乏相关数据集和基准的离路环境，填补3D语义占用预测的研究空白。&lt;h4&gt;方法&lt;/h4&gt;引入WildOcc基准，提供离路3D语义占用预测任务的密集占用标注；提出从粗到细的真实生成管道，并引入多模态3D语义占用预测框架，结合多帧图像和点云的时空信息。&lt;h4&gt;主要发现&lt;/h4&gt;提出的跨模态蒸馏功能能够将点云的几何知识转移到图像特征中。&lt;h4&gt;结论&lt;/h4&gt;WildOcc为离路3D语义占用预测提供了首个基准，有助于提高在复杂环境中的预测精度。&lt;h4&gt;总结&lt;/h4&gt;本研究通过引入新基准和框架，推动了离路3D语义占用预测的研究进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D semantic occupancy prediction is an essential part of autonomous driving,focusing on capturing the geometric details of scenes. Off-road environmentsare rich in geometric information, therefore it is suitable for 3D semanticoccupancy prediction tasks to reconstruct such scenes. However, most ofresearches concentrate on on-road environments, and few methods are designedfor off-road 3D semantic occupancy prediction due to the lack of relevantdatasets and benchmarks. In response to this gap, we introduce WildOcc, to ourknowledge, the first benchmark to provide dense occupancy annotations foroff-road 3D semantic occupancy prediction tasks. A ground truth generationpipeline is proposed in this paper, which employs a coarse-to-finereconstruction to achieve a more realistic result. Moreover, we introduce amulti-modal 3D semantic occupancy prediction framework, which fusesspatio-temporal information from multi-frame images and point clouds at voxellevel. In addition, a cross-modality distillation function is introduced, whichtransfers geometric knowledge from point clouds to image features.</description>
      <author>example@mail.com (Heng Zhai, Jilin Mei, Chen Min, Liang Chen, Fangzhou Zhao, Yu Hu)</author>
      <guid isPermaLink="false">2410.15792v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Time Series Anomaly Prediction with Importance-based Generative Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.16888v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列异常预测在环境保护和网络物理系统的及时维护等实际场景中扮演着重要角色。&lt;h4&gt;目的&lt;/h4&gt;研究无监督时间序列异常预测的问题，解决现有方法依赖大量手动标记数据的不足。&lt;h4&gt;方法&lt;/h4&gt;提出了基于重要性的生成对比学习（IGCL），通过异常前兆模式生成模块区分正常和异常前兆，并通过记忆库存储具有重要性评分的代表性异常前兆。&lt;h4&gt;主要发现&lt;/h4&gt;在七个基准数据集上的大量实验表明，所提方法在无监督时间序列异常预测问题上优于现有的最先进基线。&lt;h4&gt;结论&lt;/h4&gt;IGCL有效解决了无监督时间序列异常预测中的挑战，能够处理潜在复杂的异常前兆组合。&lt;h4&gt;总结&lt;/h4&gt;本研究为无监督时间序列异常预测提供了一种新的方法，并在实验中验证了其优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series anomaly prediction plays an essential role in many real-worldscenarios, such as environmental prevention and prompt maintenance ofcyber-physical systems. However, existing time series anomaly predictionmethods mainly require supervised training with plenty of manually labeleddata, which are difficult to obtain in practice. Besides, unseen anomalies canoccur during inference, which could differ from the labeled training data andmake these models fail to predict such new anomalies. In this paper, we study anovel problem of unsupervised time series anomaly prediction. We provide atheoretical analysis and propose Importance-based Generative ContrastiveLearning (IGCL) to address the aforementioned problems. IGCL distinguishesbetween normal and anomaly precursors, which are generated by our anomalyprecursor pattern generation module. To address the efficiency issues caused bythe potential complex anomaly precursor combinations, we propose a memory bankwith importance-based scores to adaptively store representative anomalyprecursors and generate more complicated anomaly precursors. Extensiveexperiments on seven benchmark datasets show our method outperformsstate-of-the-art baselines on unsupervised time series anomaly predictionproblems.</description>
      <author>example@mail.com (Kai Zhao, Zhihao Zhuang, Chenjuan Guo, Hao Miao, Yunyao Cheng, Bin Yang)</author>
      <guid isPermaLink="false">2410.16888v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>FairLoRA: Unpacking Bias Mitigation in Vision Models with Fairness-Driven Low-Rank Adaptation</title>
      <link>http://arxiv.org/abs/2410.17358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，参数高效微调方法（如低秩适应LoRA）因其有效地将大型基础模型适应于各种下游任务而受到广泛关注。&lt;h4&gt;目的&lt;/h4&gt;提出FairLoRA，一种针对公平性的LoRA正则化方法，旨在通过最小化每类损失的方差来减少数据子组之间的性能差异。&lt;h4&gt;方法&lt;/h4&gt;系统评估FairLoRA在多个视觉模型（如ViT、DiNO和CLIP）中的表现，尤其是在涉及分布变化的场景中。&lt;h4&gt;主要发现&lt;/h4&gt;减轻偏见所需的更高秩并非普遍适用，而是依赖于预训练模型、数据集和任务等因素。&lt;h4&gt;结论&lt;/h4&gt;强调使用多种公平性指标进行全面评估的重要性，而不是仅依赖于训练过程中优化的指标。&lt;h4&gt;总结&lt;/h4&gt;FairLoRA为公平性微调提供了一种新方法，并在不同模型中展示了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in parameter-efficient fine-tuning methods, such as Low RankAdaptation (LoRA), have gained significant attention for their ability toefficiently adapt large foundational models to various downstream tasks. Thesemethods are appreciated for achieving performance comparable to fullfine-tuning on aggregate-level metrics, while significantly reducingcomputational costs. To systematically address fairness in LLMs previousstudies fine-tune on fairness specific data using a larger LoRA rank thantypically used. In this paper, we introduce FairLoRA, a novel fairness-specificregularizer for LoRA aimed at reducing performance disparities across datasubgroups by minimizing per-class variance in loss. To the best of ourknowledge, we are the first to introduce a fairness based finetuning throughLoRA. Our results demonstrate that the need for higher ranks to mitigate biasis not universal; it depends on factors such as the pre-trained model, dataset,and task. More importantly, we systematically evaluate FairLoRA across variousvision models, including ViT, DiNO, and CLIP, in scenarios involvingdistribution shifts. We further emphasize the necessity of using multiplefairness metrics to obtain a holistic assessment of fairness, rather thanrelying solely on the metric optimized during training.</description>
      <author>example@mail.com (Rohan Sukumaran, Aarash Feizi, Adriana Romero-Sorian, Golnoosh Farnadi)</author>
      <guid isPermaLink="false">2410.17358v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Visual Representation Learning Guided By Multi-modal Prior Knowledge</title>
      <link>http://arxiv.org/abs/2410.15981v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度神经网络在计算机视觉中的成功，但在训练和测试数据分布变化时性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于知识引导的视觉表示学习方法，以提高在分布变化下的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;利用多模态先验知识，包括知识图谱和合成图像，生成嵌入并在共同潜在空间中对齐。&lt;h4&gt;主要发现&lt;/h4&gt;KGV在不同图像分类任务中，尤其是在存在分布变化的情况下，表现出比基线更高的准确率和数据效率。&lt;h4&gt;结论&lt;/h4&gt;结合多模态先验知识有助于更规律化地学习图像表示，从而提高模型在不同数据分布下的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;KGV方法在多个数据集的图像分类任务中表现出色，验证了其在应对分布变化时的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite the remarkable success of deep neural networks (DNNs) in computervision, they fail to remain high-performing when facing distribution shiftsbetween training and testing data. In this paper, we propose Knowledge-GuidedVisual representation learning (KGV), a distribution-based learning approachleveraging multi-modal prior knowledge, to improve generalization underdistribution shift. We use prior knowledge from two distinct modalities: 1) aknowledge graph (KG) with hierarchical and association relationships; and 2)generated synthetic images of visual elements semantically represented in theKG. The respective embeddings are generated from the given modalities in acommon latent space, i.e., visual embeddings from original and synthetic imagesas well as knowledge graph embeddings (KGEs). These embeddings are aligned viaa novel variant of translation-based KGE methods, where the node and relationembeddings of the KG are modeled as Gaussian distributions and translationsrespectively. We claim that incorporating multi-model prior knowledge enablesmore regularized learning of image representations. Thus, the models are ableto better generalize across different data distributions. We evaluate KGV ondifferent image classification tasks with major or minor distribution shifts,namely road sign classification across datasets from Germany, China, andRussia, image classification with the mini-ImageNet dataset and its variants,as well as the DVM-CAR dataset. The results demonstrate that KGV consistentlyexhibits higher accuracy and data efficiency than the baselines across allexperiments.</description>
      <author>example@mail.com (Hongkuan Zhou, Lavdim Halilaj, Sebastian Monka, Stefan Schmid, Yuqicheng Zhu, Bo Xiong, Steffen Staab)</author>
      <guid isPermaLink="false">2410.15981v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Effects of Soft-Domain Transfer and Named Entity Information on Deception Detection</title>
      <link>http://arxiv.org/abs/2410.14814v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代社会中，大量交流发生在网上，识别真实与虚假的信息变得困难。&lt;h4&gt;目的&lt;/h4&gt;研究在线欺骗行为的检测，尤其是在缺乏面对面互动的情况下。&lt;h4&gt;方法&lt;/h4&gt;使用来自不同领域的八个数据集，通过微调的BERT模型进行迁移学习，并利用中间层连接来评估分类器性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;结合迁移学习后，分类器的准确性较基线有所提升，并且Jensen-Shannon距离与迁移学习性能中等相关。&lt;h4&gt;结论&lt;/h4&gt;通过引入命名实体等多种方法，文本数据集中的附加信息显著提升了BERT模型的准确性，提升幅度达到11.2%。&lt;h4&gt;总结&lt;/h4&gt;本研究通过多数据集的结合和迁移学习，提升了在线欺骗检测的准确性，为未来研究提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the modern age an enormous amount of communication occurs online, and itis difficult to know when something written is genuine or deceitful. There aremany reasons for someone to deceive online (e.g., monetary gain, politicalgain) and detecting this behavior without any physical interaction is adifficult task. Additionally, deception occurs in several text-only domains andit is unclear if these various sources can be leveraged to improve detection.To address this, eight datasets were utilized from various domains to evaluatetheir effect on classifier performance when combined with transfer learning viaintermediate layer concatenation of fine-tuned BERT models. We findimprovements in accuracy over the baseline. Furthermore, we evaluate multipledistance measurements between datasets and find that Jensen-Shannon distancecorrelates moderately with transfer learning performance. Finally, the impactwas evaluated of multiple methods, which produce additional information in adataset's text via named entities, on BERT performance and we find notableimprovement in accuracy of up to 11.2%.</description>
      <author>example@mail.com (Steven Triplett, Simon Minami, Rakesh Verma)</author>
      <guid isPermaLink="false">2410.14814v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Fast Graph Sharpness-Aware Minimization for Enhancing and Accelerating Few-Shot Node Classification</title>
      <link>http://arxiv.org/abs/2410.16845v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS24; The first two authors contributed equally to this work&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在节点分类方面表现优越，但在少样本节点分类（FSNC）任务中表现不佳，需要强大的泛化能力以对未见类别进行准确预测。&lt;h4&gt;目的&lt;/h4&gt;提出将Sharpness-Aware Minimization（SAM）技术整合到GNN训练中，以提高模型的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入一种新算法，快速图形Sharpness-Aware Minimization（FGSAM），结合多层感知器（MLPs）的快速训练与GNN的优越性能，利用GNN进行参数扰动，MLPs最小化扰动损失，从而更高效地找到平坦的最小值。&lt;h4&gt;主要发现&lt;/h4&gt;FGSAM在FSNC任务中表现优于标准SAM，且计算成本更低，FGSAM+作为SAM变体在大多数情况下提供比基础优化器更快的优化。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在FSNC任务及异质图的标准节点分类任务中均展现出竞争力，具有广泛的适用性。&lt;h4&gt;总结&lt;/h4&gt;代码可在https://github.com/draym28/FGSAM_NeurIPS24获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/draym28/fgsam_neurips24&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown superior performance in nodeclassification. However, GNNs perform poorly in the Few-Shot NodeClassification (FSNC) task that requires robust generalization to make accuratepredictions for unseen classes with limited labels. To tackle the challenge, wepropose the integration of Sharpness-Aware Minimization (SAM)--a techniquedesigned to enhance model generalization by finding a flat minimum of the losslandscape--into GNN training. The standard SAM approach, however, consists oftwo forward-backward steps in each training iteration, doubling thecomputational cost compared to the base optimizer (e.g., Adam). To mitigatethis drawback, we introduce a novel algorithm, Fast Graph Sharpness-AwareMinimization (FGSAM), that integrates the rapid training of Multi-LayerPerceptrons (MLPs) with the superior performance of GNNs. Specifically, weutilize GNNs for parameter perturbation while employing MLPs to minimize theperturbed loss so that we can find a flat minimum with good generalization moreefficiently. Moreover, our method reutilizes the gradient from the perturbationphase to incorporate graph topology into the minimization process at almostzero additional cost. To further enhance training efficiency, we develop FGSAM+that executes exact perturbations periodically. Extensive experimentsdemonstrate that our proposed algorithm outperforms the standard SAM with lowercomputational costs in FSNC tasks. In particular, our FGSAM+ as a SAM variantoffers a faster optimization than the base optimizer in most cases. In additionto FSNC, our proposed methods also demonstrate competitive performance in thestandard node classification task for heterophilic graphs, highlighting thebroad applicability. The code is available athttps://github.com/draym28/FGSAM_NeurIPS24.</description>
      <author>example@mail.com (Yihong Luo, Yuhan Chen, Siya Qiu, Yiwei Wang, Chen Zhang, Yan Zhou, Xiaochun Cao, Jing Tang)</author>
      <guid isPermaLink="false">2410.16845v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>LiOn-XA: Unsupervised Domain Adaptation via LiDAR-Only Cross-Modal Adversarial Training</title>
      <link>http://arxiv.org/abs/2410.15833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint, Paper has been accepted at IROS2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的无监督领域适应（UDA）方法通常依赖于多种数据模态，如点云和RGB图像，而在某些情况下RGB图像可能不可用。&lt;h4&gt;目的&lt;/h4&gt;提出LiOn-XA方法，以解决由于环境和传感器设置变化导致的领域差距。&lt;h4&gt;方法&lt;/h4&gt;结合LiDAR仅跨模态学习与对抗训练，利用3D体素化点云和2D投影范围图像进行特征对齐。&lt;h4&gt;主要发现&lt;/h4&gt;通过对抗训练，3D和2D神经网络的特征和预测能够相互学习，从而提高UDA效果。&lt;h4&gt;结论&lt;/h4&gt;在三个真实领域适应场景中的实验表明，LiOn-XA方法在性能上超越了以往的单模态和多模态UDA方法。&lt;h4&gt;总结&lt;/h4&gt;LiOn-XA为无监督领域适应提供了一种新的方法，尤其在缺乏RGB图像的情况下，仍能有效进行3D LiDAR点云语义分割。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/jensle97/lion-xa&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose LiOn-XA, an unsupervised domain adaptation (UDA)approach that combines LiDAR-Only Cross-Modal (X) learning with Adversarialtraining for 3D LiDAR point cloud semantic segmentation to bridge the domaingap arising from environmental and sensor setup changes. Unlike existing worksthat exploit multiple data modalities like point clouds and RGB image data, weaddress UDA in scenarios where RGB images might not be available and show thattwo distinct LiDAR data representations can learn from each other for UDA. Morespecifically, we leverage 3D voxelized point clouds to preserve importantgeometric structure in combination with 2D projection-based range images thatprovide information such as object orientations or surfaces. To further alignthe feature space between both domains, we apply adversarial training usingboth features and predictions of both 2D and 3D neural networks. Ourexperiments on 3 real-to-real adaptation scenarios demonstrate theeffectiveness of our approach, achieving new state-of-the-art performance whencompared to previous uni- and multi-model UDA methods. Our source code ispublicly available at https://github.com/JensLe97/lion-xa.</description>
      <author>example@mail.com (Thomas Kreutz, Jens Lemke, Max Mühlhäuser, Alejandro Sanchez Guinea)</author>
      <guid isPermaLink="false">2410.15833v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Prototype and Instance Contrastive Learning for Unsupervised Domain Adaptation in Speaker Verification</title>
      <link>http://arxiv.org/abs/2410.17033v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ISCSLP 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;传统的说话人验证系统在不同领域应用时常出现性能下降。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法以提高在不同领域间的说话人验证性能。&lt;h4&gt;方法&lt;/h4&gt;提出原型和实例对比学习（PICL），通过双层对比学习进行无监督领域适应。&lt;h4&gt;主要发现&lt;/h4&gt;利用聚类生成伪标签，动态更新原型表示；最小化同一实例不同视图的距离，增强模型对噪声等变化的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个数据集上评估，取得了目前的最优性能，证明了其良好的泛化能力。&lt;h4&gt;总结&lt;/h4&gt;PICL方法通过双层对比学习有效提升了说话人验证模型的鲁棒性与泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speaker verification system trained on one domain usually suffers performancedegradation when applied to another domain. To address this challenge,researchers commonly use feature distribution matching-based methods inunsupervised domain adaptation scenarios where some unlabeled target domaindata is available. However, these methods often have limited performanceimprovement and lack generalization in various mismatch situations. In thispaper, we propose Prototype and Instance Contrastive Learning (PICL), a novelmethod for unsupervised domain adaptation in speaker verification throughdual-level contrastive learning. For prototype contrastive learning, wegenerate pseudo labels via clustering to create dynamically updated prototyperepresentations, aligning instances with their corresponding class or clusterprototypes. For instance contrastive learning, we minimize the distance betweendifferent views or augmentations of the same instance, ensuring robust andinvariant representations resilient to variations like noise. This dual-levelapproach provides both high-level and low-level supervision, leading toimproved generalization and robustness of the speaker verification model.Unlike previous studies that only evaluated mismatches in one situation, wehave conducted relevant explorations on various datasets and achievedstate-of-the-art performance currently, which also proves the generalization ofour method.</description>
      <author>example@mail.com (Wen Huang, Bing Han, Zhengyang Chen, Shuai Wang, Yanmin Qian)</author>
      <guid isPermaLink="false">2410.17033v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>A novel approach towards the classification of Bone Fracture from Musculoskeletal Radiography images using Attention Based Transfer Learning</title>
      <link>http://arxiv.org/abs/2410.14833v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 3 tables, 4 figures, submitted to 27th International
  Conference on Computer and Information Technology (ICCIT) to be held during
  20-22 December, 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;计算机辅助诊断（CAD）在生物图像分类和分割等领域被视为重要工具，计算机视觉算法和深度学习方法的突破显著提高了医疗图像中兴趣区域的识别和定位的有效性和精度。&lt;h4&gt;目的&lt;/h4&gt;研究骨折分类，利用FracAtlas数据集对骨骼肌肉放射图像进行分析。&lt;h4&gt;方法&lt;/h4&gt;应用基于注意力机制的迁移学习模型来检测X光扫描中的骨折，同时结合了InceptionV3和DenseNet121深度学习模型。&lt;h4&gt;主要发现&lt;/h4&gt;经过严格优化，模型在骨折分类中达到了超过90%的先进准确率。&lt;h4&gt;结论&lt;/h4&gt;本研究为迁移学习在医疗影像，特别是X光处理中的应用提供了新的研究成果，并强调了该领域进一步探索的潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了深度学习和迁移学习在医学图像分析中的重要性，特别是在骨折检测方面的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computer-aided diagnosis (CAD) is today considered a vital tool in the fieldof biological image categorization, segmentation, and other related tasks. Thecurrent breakthrough in computer vision algorithms and deep learning approacheshas substantially enhanced the effectiveness and precision of apps built torecognize and locate regions of interest inside medical photographs. Among thedifferent disciplines of medical image analysis, bone fracture detection, andclassification have exhibited exceptional potential. Although numerous imagingmodalities are applied in medical diagnostics, X-rays are particularlysignificant in this sector due to their broad availability, ease of use, andextensive information extraction capabilities. This research studies bonefracture categorization using the FracAtlas dataset, which comprises 4,083musculoskeletal radiography pictures. Given the transformational development intransfer learning, particularly its efficacy in medical image processing, wedeploy an attention-based transfer learning model to detect bone fractures inX-ray scans. Though the popular InceptionV3 and DenseNet121 deep learningmodels have been widely used, they still have the potential to be employed incrucial jobs. In this research, alongside transfer learning, a separateattention mechanism is also applied to boost the capabilities of transferlearning techniques. Through rigorous optimization, our model achieves astate-of-the-art accuracy of more than 90\% in fracture classification. Thiswork contributes to the expanding corpus of research focused on the applicationof transfer learning to medical imaging, notably in the context of X-rayprocessing, and emphasizes the promise for additional exploration in thisdomain.</description>
      <author>example@mail.com (Sayeda Sanzida Ferdous Ruhi, Fokrun Nahar, Adnan Ferdous Ashrafi)</author>
      <guid isPermaLink="false">2410.14833v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic graph neural networks for enhanced volatility prediction in financial markets</title>
      <link>http://arxiv.org/abs/2410.16858v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;波动性预测对金融市场的风险管理和决策至关重要。传统模型如GARCH能够有效捕捉波动聚集，但难以建模多个指数之间复杂的非线性依赖关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，利用图神经网络（GNNs）将全球金融市场表示为动态图，从而改善波动性预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;采用时间图注意网络（Temporal GAT），结合图卷积网络（GCNs）和图注意网络（GATs），以捕捉波动溢出的时间和结构动态。&lt;h4&gt;主要发现&lt;/h4&gt;基于相关性和波动溢出指数构建的定向图，Temporal GAT在对八个主要全球指数的15年实证研究中表现优于传统GARCH模型和其他机器学习方法，尤其在短期至中期预测中。&lt;h4&gt;结论&lt;/h4&gt;敏感性和基于情境的分析进一步验证了所提技术的重要性，强调了GNNs在建模复杂市场行为中的潜力，为金融分析师和投资者提供了有价值的见解。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了图神经网络在金融波动性预测中的应用潜力，能够为市场参与者提供更准确的决策支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Volatility forecasting is essential for risk management and decision-makingin financial markets. Traditional models like Generalized AutoregressiveConditional Heteroskedasticity (GARCH) effectively capture volatilityclustering but often fail to model complex, non-linear interdependenciesbetween multiple indices. This paper proposes a novel approach using GraphNeural Networks (GNNs) to represent global financial markets as dynamic graphs.The Temporal Graph Attention Network (Temporal GAT) combines GraphConvolutional Networks (GCNs) and Graph Attention Networks (GATs) to capturethe temporal and structural dynamics of volatility spillovers. By utilizingcorrelation-based and volatility spillover indices, the Temporal GAT constructsdirected graphs that enhance the accuracy of volatility predictions. Empiricalresults from a 15-year study of eight major global indices show that theTemporal GAT outperforms traditional GARCH models and other machine learningmethods, particularly in short- to mid-term forecasts. The sensitivity andscenario-based analysis over a range of parameters and hyperparameters furtherdemonstrate the significance of the proposed technique. Hence, this workhighlights the potential of GNNs in modeling complex market behaviors,providing valuable insights for financial analysts and investors.</description>
      <author>example@mail.com (Pulikandala Nithish Kumar, Nneka Umeorah, Alex Alochukwu)</author>
      <guid isPermaLink="false">2410.16858v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Triplane Grasping: Efficient 6-DoF Grasping with Single RGB Images</title>
      <link>http://arxiv.org/abs/2410.15879v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;可靠的物体抓取是机器人技术中的基本任务，但基于单图像输入确定抓取姿态一直面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种快速的抓取决策方法Triplane Grasping，旨在仅依靠单个RGB图像进行抓取。&lt;h4&gt;方法&lt;/h4&gt;Triplane Grasping通过点解码器和三平面解码器创建混合的三平面高斯3D表示，生成高效高质量的物体重建，并使用端到端网络从点云中的3D点直接生成6自由度平行夹爪抓取分布。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法实现了日常物体的快速建模和抓取姿态决策，并在零样本场景中展示了高抓取成功率。&lt;h4&gt;结论&lt;/h4&gt;Triplane Grasping方法能够满足实时抓取需求，且在复杂环境中表现优异。&lt;h4&gt;总结&lt;/h4&gt;该研究为基于单张图像的物体抓取提供了一种有效的新方法，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable object grasping is one of the fundamental tasks in robotics.However, determining grasping pose based on single-image input has long been achallenge due to limited visual information and the complexity of real-worldobjects. In this paper, we propose Triplane Grasping, a fast graspingdecision-making method that relies solely on a single RGB-only image as input.Triplane Grasping creates a hybrid Triplane-Gaussian 3D representation througha point decoder and a triplane decoder, which produce an efficient andhigh-quality reconstruction of the object to be grasped to meet real-timegrasping requirements. We propose to use an end-to-end network to generate6-DoF parallel-jaw grasp distributions directly from 3D points in the pointcloud as potential grasp contacts and anchor the grasp pose in the observeddata. Experiments demonstrate that our method achieves rapid modeling andgrasping pose decision-making for daily objects, and exhibits a high graspingsuccess rate in zero-shot scenarios.</description>
      <author>example@mail.com (Yiming Li, Hanchi Ren, Jingjing Deng, Xianghua Xie)</author>
      <guid isPermaLink="false">2410.15879v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Securing Federated Learning Against Novel and Classic Backdoor Threats During Foundation Model Integration</title>
      <link>http://arxiv.org/abs/2410.17573v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;联邦学习（FL）能够实现去中心化的模型训练，同时保护隐私。&lt;h4&gt;目的&lt;/h4&gt;探讨将基础模型（FM）集成到FL中对性能的提升及其带来的新型后门攻击机制。&lt;h4&gt;方法&lt;/h4&gt;提出一种新颖的数据无关防御策略，通过在服务器的模型聚合过程中约束隐藏特征空间中的异常激活。&lt;h4&gt;主要发现&lt;/h4&gt;这种激活约束能够有效缓解后门攻击，同时几乎不影响模型性能，因为参数保持不变。&lt;h4&gt;结论&lt;/h4&gt;经过广泛实验验证，该方法在抵御新型和经典后门攻击方面表现优越，超越了现有防御方法，同时保持模型性能。&lt;h4&gt;总结&lt;/h4&gt;本研究为联邦学习中的后门攻击提供了一种新颖的防御策略，显示了其有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning (FL) enables decentralized model training while preservingprivacy. Recently, integrating Foundation Models (FMs) into FL has boostedperformance but also introduced a novel backdoor attack mechanism. Attackerscan exploit the FM's capabilities to embed backdoors into synthetic datagenerated by FMs used for model fusion, subsequently infecting all clientmodels through knowledge sharing without involvement in the long-lasting FLprocess. These novel attacks render existing FL backdoor defenses ineffective,as they primarily detect anomalies among client updates, which may appearuniformly malicious under this attack. Our work proposes a novel data-freedefense strategy by constraining abnormal activations in the hidden featurespace during model aggregation on the server. The activation constraints,optimized using synthetic data alongside FL training, mitigate the attack whilebarely affecting model performance, as the parameters remain untouched.Extensive experiments demonstrate its effectiveness against both novel andclassic backdoor attacks, outperforming existing defenses while maintainingmodel performance.</description>
      <author>example@mail.com (Xiaohuan Bi, Xi Li)</author>
      <guid isPermaLink="false">2410.17573v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Theoretical Insights into Line Graph Transformation on Graph Learning</title>
      <link>http://arxiv.org/abs/2410.16138v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, code available at
  https://github.com/lukeyf/graphs-and-lines&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;线图变换在图论中广泛研究，其中线图的每个节点对应于原始图中的一条边。&lt;h4&gt;目的&lt;/h4&gt;研究线图变换如何影响图神经网络(GNN)模型的表达能力。&lt;h4&gt;方法&lt;/h4&gt;关注两类对Weisfeiler-Leman (WL)测试具有挑战性的图，即Cai-F"urer-Immerman (CFI)图和强正则图，并展示线图变换如何排除这些挑战性图的属性。&lt;h4&gt;主要发现&lt;/h4&gt;线图变换有助于WL测试区分这些图，并通过实验验证了图同构测试和GNN在变换图与原始图上的准确性和效率。&lt;h4&gt;结论&lt;/h4&gt;线图变换能增强GNN在处理复杂图结构时的表现。&lt;h4&gt;总结&lt;/h4&gt;本研究为图神经网络在特定图结构上的应用提供了理论支持，并展示了线图变换的潜在优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/lukeyf/graphs-and-lines&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Line graph transformation has been widely studied in graph theory, where eachnode in a line graph corresponds to an edge in the original graph. This hasinspired a series of graph neural networks (GNNs) applied to transformed linegraphs, which have proven effective in various graph representation learningtasks. However, there is limited theoretical study on how line graphtransformation affects the expressivity of GNN models. In this study, we focuson two types of graphs known to be challenging to the Weisfeiler-Leman (WL)tests: Cai-F\"urer-Immerman (CFI) graphs and strongly regular graphs, and showthat applying line graph transformation helps exclude these challenging graphproperties, thus potentially assist WL tests in distinguishing these graphs. Weempirically validate our findings by conducting a series of experiments thatcompare the accuracy and efficiency of graph isomorphism tests and GNNs on bothline-transformed and original graphs across these graph structure types.</description>
      <author>example@mail.com (Fan Yang, Xingyue Huang)</author>
      <guid isPermaLink="false">2410.16138v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks for Edge Signals: Orientation Equivariance and Invariance</title>
      <link>http://arxiv.org/abs/2410.16935v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多交通、土木工程或电气工程应用涉及边缘级信号，这些信号可分为固有定向信号和无定向信号。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法无法处理无定向信号及无法区分定向和无定向边缘的问题。&lt;h4&gt;方法&lt;/h4&gt;修订方向等变性的概念以支持方向感知的拓扑模型，并提出方向不变性作为描述无固有方向信号的额外要求，开发EIGN架构，使用新型方向感知的边缘级图移位算子。&lt;h4&gt;主要发现&lt;/h4&gt;EIGN是首个通用的拓扑图神经网络，能够同时建模定向和无定向信号，并区分两者。它在边缘级任务中表现优于之前的工作，在流量仿真任务中RMSE提升达43.5%。&lt;h4&gt;结论&lt;/h4&gt;EIGN有效解决了边缘级信号建模中的定向和无定向信号问题，具有较高的应用潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的EIGN架构在边缘级信号建模中显著优于现有方法，能够处理复杂的信号类型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many applications in traffic, civil engineering, or electrical engineeringrevolve around edge-level signals. Such signals can be categorized asinherently directed, for example, the water flow in a pipe network, andundirected, like the diameter of a pipe. Topological methods model edge signalswith inherent direction by representing them relative to a so-calledorientation assigned to each edge. These approaches can neither modelundirected edge signals nor distinguish if an edge itself is directed orundirected. We address these shortcomings by (i) revising the notion oforientation equivariance to enable edge direction-aware topological models,(ii) proposing orientation invariance as an additional requirement to describesignals without inherent direction, and (iii) developing EIGN, an architecturecomposed of novel direction-aware edge-level graph shift operators, thatprovably fulfills the aforementioned desiderata. It is the firstgeneral-purpose topological GNN for edge-level signals that can model directedand undirected signals while distinguishing between directed and undirectededges. A comprehensive evaluation shows that EIGN outperforms prior work inedge-level tasks, for example, improving in RMSE on flow simulation tasks by upto 43.5%.</description>
      <author>example@mail.com (Dominik Fuchsgruber, Tim Poštuvan, Stephan Günnemann, Simon Geisler)</author>
      <guid isPermaLink="false">2410.16935v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Water quality polluted by total suspended solids classified within an Artificial Neural Network approach</title>
      <link>http://arxiv.org/abs/2410.14929v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  42 pages, 8 figures and 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;悬浮固体导致的水污染对环境和健康构成重大风险，传统评估方法耗时且资源密集。&lt;h4&gt;目的&lt;/h4&gt;开发一种模型，以准确预测水中悬浮固体浓度导致的低、中、高污染水平。&lt;h4&gt;方法&lt;/h4&gt;采用卷积神经网络，通过迁移学习方法训练，使用综合水质数据集进行分析。&lt;h4&gt;主要发现&lt;/h4&gt;模型具有高预测准确性，在速度和可靠性上优于传统统计方法。&lt;h4&gt;结论&lt;/h4&gt;人工神经网络框架可以有效用于水污染的实时监测和管理，有助于主动决策和政策制定。&lt;h4&gt;总结&lt;/h4&gt;本研究强调了机器学习技术在环境科学中的潜力，提升了对污染动态的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study investigates the application of an artificial neural networkframework for analysing water pollution caused by solids. Water pollution bysuspended solids poses significant environmental and health risks. Traditionalmethods for assessing and predicting pollution levels are often time-consumingand resource-intensive. To address these challenges, we developed a model thatleverages a comprehensive dataset of water quality from total suspended solids.A convolutional neural network was trained under a transfer learning approachusing data corresponding to different total suspended solids concentrations,with the goal of accurately predicting low, medium and high pollution levelsbased on various input variables. Our model demonstrated high predictiveaccuracy, outperforming conventional statistical methods in terms of both speedand reliability. The results suggest that the artificial neural networkframework can serve as an effective tool for real-time monitoring andmanagement of water pollution, facilitating proactive decision-making andpolicy formulation. This approach not only enhances our understanding ofpollution dynamics but also underscores the potential of machine learningtechniques in environmental science.</description>
      <author>example@mail.com (I. Luviano Soto, Y. Concha Sánchez, A. Raya)</author>
      <guid isPermaLink="false">2410.14929v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>SigCLR: Sigmoid Contrastive Learning of Visual Representations</title>
      <link>http://arxiv.org/abs/2410.17427v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Neurips 2024 SSL Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出SigCLR： sigmoid对比学习的视觉表示。&lt;h4&gt;目的&lt;/h4&gt;探索一种新的损失函数，以替代SimCLR中的交叉熵损失。&lt;h4&gt;方法&lt;/h4&gt;SigCLR利用仅对成对数据操作的逻辑损失，不需要全局视图。&lt;h4&gt;主要发现&lt;/h4&gt;在CIFAR-10、CIFAR-100和Tiny-IN数据集上，逻辑损失表现出竞争力。&lt;h4&gt;结论&lt;/h4&gt;学习偏置的重要性得到了验证，但需要固定温度以达到最佳效果。&lt;h4&gt;意义&lt;/h4&gt;SigCLR是SimCLR的有希望的替代方案，在多个领域表现出色。&lt;h4&gt;总结&lt;/h4&gt;SigCLR展示了新的对比学习方法，具有潜在的广泛应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose SigCLR: Sigmoid Contrastive Learning of Visual Representations.SigCLR utilizes the logistic loss that only operates on pairs and does notrequire a global view as in the cross-entropy loss used in SimCLR. We show thatlogistic loss shows competitive performance on CIFAR-10, CIFAR-100, and Tiny-INcompared to other established SSL objectives. Our findings verify theimportance of learnable bias as in the case of SigLUP, however, it requires afixed temperature as in the SimCLR to excel. Overall, SigCLR is a promisingreplacement for the SimCLR which is ubiquitous and has shown tremendous successin various domains.</description>
      <author>example@mail.com (Ömer Veysel Çağatan)</author>
      <guid isPermaLink="false">2410.17427v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>MBPU: A Plug-and-Play State Space Model for Point Cloud Upsamping with Fast Point Rendering</title>
      <link>http://arxiv.org/abs/2410.15941v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云上采样（PCU）任务旨在从稀疏的3D传感器捕获的数据生成密集且均匀的点云，具有潜在应用，但仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于Mamba架构的网络MBPU，以提高大规模点云上采样的性能。&lt;h4&gt;方法&lt;/h4&gt;MBPU在长序列建模中表现良好，采用任意规模的上采样框架，同时预测3D位置偏移和1D点对点距离，使用快速可微渲染器提升点云的真实感。&lt;h4&gt;主要发现&lt;/h4&gt;MBPU在点云上采样质量上显著优于其他现成方法，尤其是在处理大规模点云时。&lt;h4&gt;结论&lt;/h4&gt;通过高效消除表面噪声，MBPU能够生成高质量的上采样点云，且收敛速度快。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了MBPU在点云上采样领域的优势，特别是在处理复杂和大规模数据集时的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The task of point cloud upsampling (PCU) is to generate dense and uniformpoint clouds from sparse input captured by 3D sensors like LiDAR, holdingpotential applications in real yet is still a challenging task. Existing deeplearning-based methods have shown significant achievements in this field.However, they still face limitations in effectively handling long sequences andaddressing the issue of shrinkage artifacts around the surface of the pointcloud. Inspired by the newly proposed Mamba, in this paper, we introduce anetwork named MBPU built on top of the Mamba architecture, which performs wellin long sequence modeling, especially for large-scale point cloud upsampling,and achieves fast convergence speed. Moreover, MBPU is an arbitrary-scaleupsampling framework as the predictor of point distance in the point refinementphase. At the same time, we simultaneously predict the 3D position shift and 1Dpoint-to-point distance as regression quantities to constrain the globalfeatures while ensuring the accuracy of local details. We also introduce a fastdifferentiable renderer to further enhance the fidelity of the upsampled pointcloud and reduce artifacts. It is noted that, by the merits of our fast pointrendering, MBPU yields high-quality upsampled point clouds by effectivelyeliminating surface noise. Extensive experiments have demonstrated that ourMBPU outperforms other off-the-shelf methods in terms of point cloudupsampling, especially for large-scale point clouds.</description>
      <author>example@mail.com (Jiayi Song, Weidong Yang, Zhijun Li, Wen-Ming Chen, Ben Fei)</author>
      <guid isPermaLink="false">2410.15941v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>CogSteer: Cognition-Inspired Selective Layer Intervention for Efficient Semantic Steering in Large Language Models</title>
      <link>http://arxiv.org/abs/2410.17714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）具有强大的能力，但缺乏可解释性，且可能生成有毒内容。&lt;h4&gt;目的&lt;/h4&gt;基于对LLM行为的深入理解，提出高效的方法来改善其可解释性和安全性。&lt;h4&gt;方法&lt;/h4&gt;使用眼动测量来解释LLM在不同层次的行为，并引入启发式层选择，应用于层干预方法的微调和推理。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs在各层次上展现出与人类注视相似的模式，不同层次的功能各异。&lt;h4&gt;结论&lt;/h4&gt;CogSteer方法在降低有毒性评分方面表现更佳，同时节省了97%的计算资源和60%的训练时间。&lt;h4&gt;应用&lt;/h4&gt;该模型无关的方法可应用于各种LLMs，提升其可解释性，促进安全部署的可信度。&lt;h4&gt;总结&lt;/h4&gt;通过对LLM行为的分析和优化，提升了模型的安全性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite their impressive capabilities, large language models (LLMs) oftenlack interpretability and can generate toxic content. While using LLMs asfoundation models and applying semantic steering methods are widely practiced,we believe that efficient methods should be based on a thorough understandingof LLM behavior. To this end, we propose using eye movement measures tointerpret LLM behavior across layers. We find that LLMs exhibit patternssimilar to human gaze across layers and different layers function differently.Inspired by these findings, we introduce a heuristic steering layer selectionand apply it to layer intervention methods via fine-tuning and inference. Usinglanguage toxification and detoxification as test beds, we demonstrate that ourproposed CogSteer methods achieve better results in terms of toxicity scoreswhile efficiently saving 97% of the computational resources and 60% of thetraining time. Our model-agnostic approach can be adopted into various LLMs,contributing to their interpretability and promoting trustworthiness for safedeployment.</description>
      <author>example@mail.com (Xintong Wang, Jingheng Pan, Longqin Jiang, Liang Ding, Xingshan Li, Chris Biemann)</author>
      <guid isPermaLink="false">2410.17714v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Integrating Reinforcement Learning with Foundation Models for Autonomous Robotics: Methods and Perspectives</title>
      <link>http://arxiv.org/abs/2410.16411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted for publication to the Special Issue on Foundation Models
  and Neural-Symbolic AI for Robotics in The International Journal of Robotics
  Research (IJRR)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）是预训练于大量未标记数据集的大型深度学习模型，具有理解复杂模式和生成复杂输出的强大能力，但在特定任务上适应性不足。&lt;h4&gt;目的&lt;/h4&gt;探索基础模型与强化学习（RL）的结合，以提升模型在特定任务上的表现和适应能力，推动机器人智能的发展。&lt;h4&gt;方法&lt;/h4&gt;综合研究基础模型作为行动规划者、开发机器人特定的基础模型，并分析FMs与RL结合的互惠效益，提出多种集成方法的分类。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型能够为机器人提供丰富的知识和归纳能力，而强化学习通过现实世界的交互促进学习和适应，二者结合在机器人领域产生了革命性的影响。&lt;h4&gt;结论&lt;/h4&gt;通过整合基础模型与强化学习，可以显著提升机器人的推理和控制能力，促进未来的研究方向。&lt;h4&gt;总结&lt;/h4&gt;本调研论文综合现有研究，强调基础模型和强化学习的集成面临的关键挑战，并提供相关文献的更新汇总，旨在激发进一步的研究探索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/clmoro/robotics-rl-fms-integration&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs), large deep learning models pre-trained on vast,unlabeled datasets, exhibit powerful capabilities in understanding complexpatterns and generating sophisticated outputs. However, they often struggle toadapt to specific tasks. Reinforcement learning (RL), which allows agents tolearn through interaction and feedback, offers a compelling solution.Integrating RL with FMs enables these models to achieve desired outcomes andexcel at particular tasks. Additionally, RL can be enhanced by leveraging thereasoning and generalization capabilities of FMs. This synergy isrevolutionizing various fields, including robotics. FMs, rich in knowledge andgeneralization, provide robots with valuable information, while RL facilitateslearning and adaptation through real-world interactions.  This survey paper comprehensively explores this exciting intersection,examining how these paradigms can be integrated to advance roboticintelligence. We analyze the use of foundation models as action planners, thedevelopment of robotics-specific foundation models, and the mutual benefits ofcombining FMs with RL. Furthermore, we present a taxonomy of integrationapproaches, including large language models, vision-language models, diffusionmodels, and transformer-based RL models. We also explore how RL can utilizeworld representations learned from FMs to enhance robotic task execution.  Our survey aims to synthesize current research and highlight key challengesin robotic reasoning and control, particularly in the context of integratingFMs and RL--two rapidly evolving technologies. By doing so, we seek to sparkfuture research and emphasize critical areas that require further investigationto enhance robotics. We provide an updated collection of papers based on ourtaxonomy, accessible on our open-source project website at:https://github.com/clmoro/Robotics-RL-FMs-Integration.</description>
      <author>example@mail.com (Angelo Moroncelli, Vishal Soni, Asad Ali Shahid, Marco Maccarini, Marco Forgione, Dario Piga, Blerina Spahiu, Loris Roveda)</author>
      <guid isPermaLink="false">2410.16411v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks</title>
      <link>http://arxiv.org/abs/2410.17118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;混合光纤（LiFi）和无线网络（WiFi）网络是异构网络（HetNet）的有前景的范式，因其光谱和射频的互补物理特性。&lt;h4&gt;目的&lt;/h4&gt;解决现有传输控制协议（TCP）对用户设备（UE）连接单个接入点（AP）的限制，推动多路径TCP（MPTCP）的应用。&lt;h4&gt;方法&lt;/h4&gt;提出基于图神经网络（GNN）的模型，解决MPTCP支持的HetNet中的负载均衡（LB）问题，形成部分网格拓扑。&lt;h4&gt;主要发现&lt;/h4&gt;与传统优化方法相比，所提学习模型在接近最优吞吐量的情况下，推理时间减少了四个数量级，吞吐量提高了21.7%。&lt;h4&gt;结论&lt;/h4&gt;GNN模型在处理复杂网络拓扑和不同数量的AP和UE方面表现优越，显著改善了网络性能。&lt;h4&gt;总结&lt;/h4&gt;基于GNN的负载均衡模型为MPTCP支持的异构网络提供了有效的解决方案，具有良好的性能和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hanji-ucd/gnn-hetnet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are apromising paradigm of heterogeneous network (HetNet), attributed to thecomplementary physical properties of optical spectra and radio frequency.However, the current development of such HetNets is mostly bottlenecked by theexisting transmission control protocol (TCP), which restricts the userequipment (UE) to connecting one access point (AP) at a time. While the ongoinginvestigation on multipath TCP (MPTCP) can bring significant benefits, itcomplicates the network topology of HetNets, making the existing load balancing(LB) learning models less effective. Driven by this, we propose a graph neuralnetwork (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets,which results in a partial mesh topology. Such a topology can be modeled as agraph, with the channel state information and data rate requirement embedded asnode features, while the LB solutions are deemed as edge labels. Compared tothe conventional deep neural network (DNN), the proposed GNN-based modelexhibits two key strengths: i) it can better interpret a complex networktopology; and ii) it can handle various numbers of APs and UEs with a singletrained model. Simulation results show that against the traditionaloptimisation method, the proposed learning model can achieve near-optimalthroughput within a gap of 11.5%, while reducing the inference time by 4 ordersof magnitude. In contrast to the DNN model, the new method can improve thenetwork throughput by up to 21.7%, at a similar inference time level.</description>
      <author>example@mail.com (Han Ji, Xiping Wu, Zhihong Zeng, Chen Chen)</author>
      <guid isPermaLink="false">2410.17118v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Generalizable Prediction Model of Molten Salt Mixture Density with Chemistry-Informed Transfer Learning</title>
      <link>http://arxiv.org/abs/2410.15120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Manuscript contains 25 pages including references and other
  information. Manuscript contains 4 figures and 3 tables. To be submitted to
  ACS Journal of Chemical Theory and Computation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;优化熔盐应用设计需要了解其热物理性质，但现有数据库不完整，实验也具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法以提高熔盐密度的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;采用深度神经网络（DNN）进行迁移学习，结合Redlich-Kister模型、实验数据和首性性质。&lt;h4&gt;主要发现&lt;/h4&gt;该方法以高准确性预测熔盐密度，$r^{2}$ &gt; 0.99，MAPE &lt; 1%，优于其他替代方案。&lt;h4&gt;结论&lt;/h4&gt;深度学习方法在熔盐密度预测中表现出色，解决了传统模型的局限性。&lt;h4&gt;总结&lt;/h4&gt;通过深度学习的方法可以有效提高熔盐热物理性质的预测精度，推动相关领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimally designing molten salt applications requires knowledge of theirthermophysical properties, but existing databases are incomplete, andexperiments are challenging. Ideal mixing and Redlich-Kister models arecomputationally cheap but lack either accuracy or generality. To address this,a transfer learning approach using deep neural networks (DNNs) is proposed,combining Redlich-Kister models, experimental data, and ab initio properties.The approach predicts molten salt density with high accuracy ($r^{2}$ &gt; 0.99,MAPE &lt; 1%), outperforming the alternatives.</description>
      <author>example@mail.com (Julian Barra, Shayan Shahbazi, Anthony Birri, Rajni Chahal, Ibrahim Isah, Muhammad Nouman Anwar, Tyler Starkus, Prasanna Balaprakash, Stephen Lam)</author>
      <guid isPermaLink="false">2410.15120v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Implicit Contact Diffuser: Sequential Contact Reasoning with Latent Point Cloud Diffusion</title>
      <link>http://arxiv.org/abs/2410.16571v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  In submussion&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;长时间接触丰富的操作一直是一个具有挑战性的问题，需要对离散接触模式和连续物体运动进行推理。&lt;h4&gt;目的&lt;/h4&gt;提出Implicit Contact Diffuser (ICD)模型，以生成一系列神经描述符，指定物体与环境之间的接触关系。&lt;h4&gt;方法&lt;/h4&gt;使用扩散模型生成接触关系序列，并将其作为模型预测控制（MPC）方法的指导，以完成特定任务。&lt;h4&gt;主要发现&lt;/h4&gt;ICD在复杂的、长时间的接触丰富操作任务（如电缆布线和笔记本折叠）中表现优于基线方法。&lt;h4&gt;结论&lt;/h4&gt;ICD能够将目标接触关系推广到不同的环境中，提供更相关的任务指导，帮助避免局部最小值。&lt;h4&gt;总结&lt;/h4&gt;ICD模型通过提供有效的接触关系指导，提升了接触丰富操作的性能，并展示了良好的推广能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-horizon contact-rich manipulation has long been a challenging problem,as it requires reasoning over both discrete contact modes and continuous objectmotion. We introduce Implicit Contact Diffuser (ICD), a diffusion-based modelthat generates a sequence of neural descriptors that specify a series ofcontact relationships between the object and the environment. This sequence isthen used as guidance for an MPC method to accomplish a given task. The keyadvantage of this approach is that the latent descriptors provide moretask-relevant guidance to MPC, helping to avoid local minima for contact-richmanipulation tasks. Our experiments demonstrate that ICD outperforms baselineson complex, long-horizon, contact-rich manipulation tasks, such as cablerouting and notebook folding. Additionally, our experiments also indicate that\methodshort can generalize a target contact relationship to a differentenvironment. More visualizations can be found on our website$\href{https://implicit-contact-diffuser.github.io/}{https://implicit-contact-diffuser.github.io}$</description>
      <author>example@mail.com (Zixuan Huang, Yinong He, Yating Lin, Dmitry Berenson)</author>
      <guid isPermaLink="false">2410.16571v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Robot Policy Learning via Zero-Shot Labeling with Foundation Models</title>
      <link>http://arxiv.org/abs/2410.17772v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Website at https://robottasklabeling.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;开发能够将人类语言与其感知和动作关联的机器人面临自然语言注释稀缺的挑战，尤其是在多样化的机器人数据集中。&lt;h4&gt;目的&lt;/h4&gt;介绍NILS：自然语言指令标签系统，旨在实现可扩展的自动标注。&lt;h4&gt;方法&lt;/h4&gt;NILS以零-shot的方式自动标注未整理的长时间机器人数据，结合预训练的视觉-语言基础模型来检测场景中的物体、识别物体中心的变化、从未标记的交互数据中分割任务，并最终标注行为数据集。&lt;h4&gt;主要发现&lt;/h4&gt;在BridgeV2、Fractal和厨房游戏数据集上的评估表明，NILS能够自主注释多样化的机器人演示，缓解众包人类注释的低数据质量和多样性等问题。&lt;h4&gt;结论&lt;/h4&gt;NILS成功标注超过115,000条轨迹，处理了430小时的机器人数据，并将自动标注代码和生成的注释开源。&lt;h4&gt;总结&lt;/h4&gt;NILS为机器人领域的自然语言指令处理提供了一种高效的自动标注解决方案，推动了数据质量和多样性的提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A central challenge towards developing robots that can relate human languageto their perception and actions is the scarcity of natural language annotationsin diverse robot datasets. Moreover, robot policies that follow naturallanguage instructions are typically trained on either templated language orexpensive human-labeled instructions, hindering their scalability. To this end,we introduce NILS: Natural language Instruction Labeling for Scalability. NILSautomatically labels uncurated, long-horizon robot data at scale in a zero-shotmanner without any human intervention. NILS combines pretrained vision-languagefoundation models in order to detect objects in a scene, detect object-centricchanges, segment tasks from large datasets of unlabelled interaction data andultimately label behavior datasets. Evaluations on BridgeV2, Fractal, and akitchen play dataset show that NILS can autonomously annotate diverse robotdemonstrations of unlabeled and unstructured datasets while alleviating severalshortcomings of crowdsourced human annotations, such as low data quality anddiversity. We use NILS to label over 115k trajectories obtained from over 430hours of robot data. We open-source our auto-labeling code and generatedannotations on our website: http://robottasklabeling.github.io.</description>
      <author>example@mail.com (Nils Blank, Moritz Reuss, Marcel Rühle, Ömer Erdinç Yağmurlu, Fabian Wenzel, Oier Mees, Rudolf Lioutikov)</author>
      <guid isPermaLink="false">2410.17772v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>TIPS: Text-Image Pretraining with Spatial Awareness</title>
      <link>http://arxiv.org/abs/2410.16512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图像-文本表示学习近年来变得非常流行，但现有模型往往缺乏空间意识，难以直接应用于密集理解任务。&lt;h4&gt;目的&lt;/h4&gt;弥合图像-文本学习与自监督学习之间的差距，提出一种通用的图像-文本模型，适用于密集和全局视觉任务。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为TIPS（具有空间意识的文本-图像预训练）的方法，结合文本监督和对比学习技术。&lt;h4&gt;主要发现&lt;/h4&gt;用合成生成的文本描述替换噪声较大的网络图像标题显著提升了密集理解性能，同时结合对比学习和自监督图像建模技术增强了空间一致性。&lt;h4&gt;结论&lt;/h4&gt;在8个任务和16个数据集上的实验显示，模型在多种图像和图像-文本任务中具有强大的即用性能。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新颖的图像-文本模型，通过改进文本监督和学习技术，提升了密集和全局理解能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While image-text representation learning has become very popular in recentyears, existing models tend to lack spatial awareness and have limited directapplicability for dense understanding tasks. For this reason, self-supervisedimage-only pretraining is still the go-to method for many dense visionapplications (e.g. depth estimation, semantic segmentation), despite the lackof explicit supervisory signals. In this paper, we close this gap betweenimage-text and self-supervised learning, by proposing a novel general-purposeimage-text model, which can be effectively used off-the-shelf for dense andglobal vision tasks. Our method, which we refer to as Text-Image Pretrainingwith Spatial awareness (TIPS), leverages two simple and effective insights.First, on textual supervision: we reveal that replacing noisy web imagecaptions by synthetically generated textual descriptions boosts denseunderstanding performance significantly, due to a much richer signal forlearning spatially aware representations. We propose an adapted training methodthat combines noisy and synthetic captions, resulting in improvements acrossboth dense and global understanding tasks. Second, on the learning technique:we propose to combine contrastive image-text learning with self-supervisedmasked image modeling, to encourage spatial coherence, unlocking substantialenhancements for downstream applications. Building on these two ideas, we scaleour model using the transformer architecture, trained on a curated set ofpublic images. Our experiments are conducted on 8 tasks involving 16 datasetsin total, demonstrating strong off-the-shelf performance on both dense andglobal understanding, for several image-only and image-text tasks.</description>
      <author>example@mail.com (Kevis-Kokitsi Maninis, Kaifeng Chen, Soham Ghosh, Arjun Karpur, Koert Chen, Ye Xia, Bingyi Cao, Daniel Salz, Guangxing Han, Jan Dlabal, Dan Gnanapragasam, Mojtaba Seyedhosseini, Howard Zhou, Andre Araujo)</author>
      <guid isPermaLink="false">2410.16512v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Graph Neural Network Modeling of Human Interactions in Crowded Environments</title>
      <link>http://arxiv.org/abs/2410.17409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  \c{opyright} 2024 the authors. This work has been accepted to IFAC
  for publication under a Creative Commons Licence CC-BY-NC-ND&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在人群环境中建模人类轨迹面临挑战，因为行人行为和互动的复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出一种几何图神经网络（GNN）架构，以整合心理学研究的领域知识，建模行人互动并预测未来轨迹。&lt;h4&gt;方法&lt;/h4&gt;与以往使用完整图不同，我们定义了基于行人视野、运动方向和距离的核函数的互动邻域，构建人群的图表示。&lt;h4&gt;主要发现&lt;/h4&gt;在多个数据集的评估中，通过减少平均和最终位移误差指标，提高了预测准确性。&lt;h4&gt;结论&lt;/h4&gt;我们的研究强调了将领域知识与数据驱动方法结合的重要性，以有效建模人群中的人类互动。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了几何图神经网络在复杂人群环境中预测行人轨迹的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling human trajectories in crowded environments is challenging due to thecomplex nature of pedestrian behavior and interactions. This paper proposes ageometric graph neural network (GNN) architecture that integrates domainknowledge from psychological studies to model pedestrian interactions andpredict future trajectories. Unlike prior studies using complete graphs, wedefine interaction neighborhoods using pedestrians' field of view, motiondirection, and distance-based kernel functions to construct graphrepresentations of crowds. Evaluations across multiple datasets demonstrateimproved prediction accuracy through reduced average and final displacementerror metrics. Our findings underscore the importance of integrating domainknowledge with data-driven approaches for effective modeling of humaninteractions in crowds.</description>
      <author>example@mail.com (Sara Honarvar, Yancy Diaz-Mercado)</author>
      <guid isPermaLink="false">2410.17409v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning</title>
      <link>http://arxiv.org/abs/2410.15148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  EMNLP 2024 Main Conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;中间任务迁移学习可以显著提高模型性能。&lt;h4&gt;目的&lt;/h4&gt;研究在情感检测领域选择适合的迁移学习任务。&lt;h4&gt;方法&lt;/h4&gt;引入嵌入空间映射（ESMs），这是一种轻量级神经网络，能够近似迁移学习的效果。&lt;h4&gt;主要发现&lt;/h4&gt;在12000个源-目标对的研究中，使用ESMs的方法将执行时间和磁盘空间使用分别减少了10倍和278倍，同时保持了高选择性能（平均regret@5分数为2.95）。&lt;h4&gt;结论&lt;/h4&gt;ESMs在选择迁移学习任务时表现出色，能够有效降低资源消耗。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了ESMs在NLP任务迁移性和任务选择中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/davidschulte/hf-dataset-selector&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Intermediate task transfer learning can greatly improve model performance.If, for example, one has little training data for emotion detection, firstfine-tuning a language model on a sentiment classification dataset may improveperformance strongly. But which task to choose for transfer learning? Priormethods producing useful task rankings are infeasible for large source pools,as they require forward passes through all source language models. We overcomethis by introducing Embedding Space Maps (ESMs), light-weight neural networksthat approximate the effect of fine-tuning a language model. We conduct thelargest study on NLP task transferability and task selection with 12ksource-target pairs. We find that applying ESMs on a prior method reducesexecution time and disk space usage by factors of 10 and 278, respectively,while retaining high selection performance (avg. regret@5 score of 2.95).</description>
      <author>example@mail.com (David Schulte, Felix Hamborg, Alan Akbik)</author>
      <guid isPermaLink="false">2410.15148v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>E-3DGS: Gaussian Splatting with Exposure and Motion Events</title>
      <link>http://arxiv.org/abs/2410.16995v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The source code and dataset will be available at
  https://github.com/MasterHow/E-3DGS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在视觉领域，已广泛探讨从最佳条件下捕获的图像估计神经辐射场（NeRF）。&lt;h4&gt;目的&lt;/h4&gt;解决机器人应用中由于运动模糊、光照不足和高计算开销等挑战，影响导航、检查和场景可视化等下游任务。&lt;h4&gt;方法&lt;/h4&gt;提出E-3DGS，一种基于事件的方法，将事件划分为运动事件和曝光事件，利用运动事件处理快速运动场景，使用曝光事件重建灰度图像以优化事件基础的3D高斯点云（3DGS）。&lt;h4&gt;主要发现&lt;/h4&gt;E-3DGS可以仅使用运动事件进行3D重建，或通过曝光事件增强质量，或采用混合模式在初始曝光事件和高速运动事件之间进行优化。&lt;h4&gt;结论&lt;/h4&gt;E-3DGS在具有挑战性的条件下，提供比基于事件的NeRF更快、更高质量的重建，同时在成本上优于结合事件和RGB数据的NeRF方法，且对硬件需求较低。&lt;h4&gt;数据集&lt;/h4&gt;引入EME-3D，一个包含曝光事件、运动事件、相机标定参数和稀疏点云的真实世界3D数据集。&lt;h4&gt;总结&lt;/h4&gt;通过结合运动和曝光事件，E-3DGS为基于事件的3D重建设定了新的基准，表现出稳健的性能和较低的硬件需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating Neural Radiance Fields (NeRFs) from images captured under optimalconditions has been extensively explored in the vision community. However,robotic applications often face challenges such as motion blur, insufficientillumination, and high computational overhead, which adversely affectdownstream tasks like navigation, inspection, and scene visualization. Toaddress these challenges, we propose E-3DGS, a novel event-based approach thatpartitions events into motion (from camera or object movement) and exposure(from camera exposure), using the former to handle fast-motion scenes and usingthe latter to reconstruct grayscale images for high-quality training andoptimization of event-based 3D Gaussian Splatting (3DGS). We introduce a novelintegration of 3DGS with exposure events for high-quality reconstruction ofexplicit scene representations. Our versatile framework can operate on motionevents alone for 3D reconstruction, enhance quality using exposure events, oradopt a hybrid mode that balances quality and effectiveness by optimizing withinitial exposure events followed by high-speed motion events. We also introduceEME-3D, a real-world 3D dataset with exposure events, motion events, cameracalibration parameters, and sparse point clouds. Our method is faster anddelivers better reconstruction quality than event-based NeRF while being morecost-effective than NeRF methods that combine event and RGB data by using asingle event sensor. By combining motion and exposure events, E-3DGS sets a newbenchmark for event-based 3D reconstruction with robust performance inchallenging conditions and lower hardware demands. The source code and datasetwill be available at https://github.com/MasterHow/E-3DGS.</description>
      <author>example@mail.com (Xiaoting Yin, Hao Shi, Yuhan Bao, Zhenshan Bing, Yiyi Liao, Kailun Yang, Kaiwei Wang)</author>
      <guid isPermaLink="false">2410.16995v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>AdaRankGrad: Adaptive Gradient-Rank and Moments for Memory-Efficient LLMs Training and Fine-Tuning</title>
      <link>http://arxiv.org/abs/2410.17881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;训练和微调大型语言模型（LLMs）面临内存和计算需求的挑战，因模型权重和优化器状态的增大。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，以克服低秩适应（LoRA）等方法在参数搜索限制方面的不足。&lt;h4&gt;方法&lt;/h4&gt;通过逐步降低梯度的秩，在Adam优化步骤中采用自适应的低秩梯度更新，结合高效的在线更新低秩投影规则和随机SVD方案来找到投影矩阵。&lt;h4&gt;主要发现&lt;/h4&gt;所提方法在训练过程中显著减少了内存需求，并提高了模型在预训练和微调中的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在训练和微调语言及生物基础模型中表现出良好的收敛性和优势。&lt;h4&gt;总结&lt;/h4&gt;通过自适应低秩梯度更新，优化了大型语言模型的训练过程，降低了内存需求，同时提升了模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training and fine-tuning large language models (LLMs) come with challengesrelated to memory and computational requirements due to the increasing size ofthe model weights and the optimizer states. Various techniques have beendeveloped to tackle these challenges, such as low-rank adaptation (LoRA), whichinvolves introducing a parallel trainable low-rank matrix to the fixedpre-trained weights at each layer. However, these methods often fall shortcompared to the full-rank weight training approach, as they restrict theparameter search to a low-rank subspace. This limitation can disrupt trainingdynamics and require a full-rank warm start to mitigate the impact. In thispaper, we introduce a new method inspired by a phenomenon we formally prove: astraining progresses, the rank of the estimated layer gradients graduallydecreases, and asymptotically approaches rank one. Leveraging this, ourapproach involves adaptively reducing the rank of the gradients during Adamoptimization steps, using an efficient online-updating low-rank projectionsrule. We further present a randomized SVD scheme for efficiently finding theprojection matrix. Our technique enables full-parameter fine-tuning withadaptive low-rank gradient updates, significantly reducing overall memoryrequirements during training compared to state-of-the-art methods whileimproving model performance in both pretraining and fine-tuning. Finally, weprovide a convergence analysis of our method and demonstrate its merits fortraining and fine-tuning language and biological foundation models.</description>
      <author>example@mail.com (Yehonathan Refael, Jonathan Svirsky, Boris Shustin, Wasim Huleihel, Ofir Lindenbaum)</author>
      <guid isPermaLink="false">2410.17881v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Time and Frequency Synergy for Source-Free Time-Series Domain Adaptations</title>
      <link>http://arxiv.org/abs/2410.17511v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;源无关时间序列领域适应问题仍然缺乏研究关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法来解决源无关时间序列领域适应问题。&lt;h4&gt;方法&lt;/h4&gt;开发时间频率领域适应（TFDA）方法，采用双分支网络结构，利用时间和频率特征进行最终预测。&lt;h4&gt;主要发现&lt;/h4&gt;通过邻域概念生成伪标签，并在时间和频率域中进行对比学习，结合自我蒸馏和不确定性减少策略，有效应对领域转移问题。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，TFDA方法在基准问题上显著优于现有技术。&lt;h4&gt;总结&lt;/h4&gt;TFDA方法通过综合时间和频率特征，改进了源无关时间序列领域适应的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The issue of source-free time-series domain adaptations still gains scarceresearch attentions. On the other hand, existing approaches rely solely ontime-domain features ignoring frequency components providing complementaryinformation. This paper proposes Time Frequency Domain Adaptation (TFDA), amethod to cope with the source-free time-series domain adaptation problems.TFDA is developed with a dual branch network structure fully utilizing bothtime and frequency features in delivering final predictions. It inducespseudo-labels based on a neighborhood concept where predictions of a samplegroup are aggregated to generate reliable pseudo labels. The concept ofcontrastive learning is carried out in both time and frequency domains withpseudo label information and a negative pair exclusion strategy to make validneighborhood assumptions. In addition, the time-frequency consistency techniqueis proposed using the self-distillation strategy while the uncertaintyreduction strategy is implemented to alleviate uncertainties due to the domainshift problem. Last but not least, the curriculum learning strategy isintegrated to combat noisy pseudo labels. Our experiments demonstrate theadvantage of our approach over prior arts with noticeable margins in benchmarkproblems.</description>
      <author>example@mail.com (Muhammad Tanzil Furqon, Mahardhika Pratama, Ary Mazharuddin Shiddiqi, Lin Liu, Habibullah Habibullah, Kutluyil Dogancay)</author>
      <guid isPermaLink="false">2410.17511v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>IdenBAT: Disentangled Representation Learning for Identity-Preserved Brain Age Transformation</title>
      <link>http://arxiv.org/abs/2410.16945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 8 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;脑龄转换旨在将参考脑图像转换为能够准确反映目标年龄组特征的合成图像。&lt;h4&gt;目的&lt;/h4&gt;修改参考图像的年龄相关属性，同时保留所有其他与年龄无关的属性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新架构，称为IdenBAT，采用解耦表示学习，以实现身份保留的脑龄转换。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过分解图像特征，确保个体特征的保留，同时选择性地转换与年龄相关的特征。&lt;h4&gt;结论&lt;/h4&gt;通过在2D和全尺寸3D脑数据集上的全面实验，证明了该方法在准确保留个体特征的同时，能够有效地将输入图像转换为目标年龄，并且在性能保真度上优于现有最先进技术。&lt;h4&gt;总结&lt;/h4&gt;IdenBAT为脑龄转换提供了一种有效的方法，解决了图像特征之间的相互纠缠问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/ku-milab/idenbat&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain age transformation aims to convert reference brain images intosynthesized images that accurately reflect the age-specific features of atarget age group. The primary objective of this task is to modify only theage-related attributes of the reference image while preserving all otherage-irrelevant attributes. However, achieving this goal poses substantialchallenges due to the inherent entanglement of various image attributes withinfeatures extracted from a backbone encoder, resulting in simultaneousalterations during the image generation. To address this challenge, we proposea novel architecture that employs disentangled representation learning foridentity-preserved brain age transformation called IdenBAT. This approachfacilitates the decomposition of image features, ensuring the preservation ofindividual traits while selectively transforming age-related characteristics tomatch those of the target age group. Through comprehensive experimentsconducted on both 2D and full-size 3D brain datasets, our method adeptlyconverts input images to target age while retaining individual characteristicsaccurately. Furthermore, our approach demonstrates superiority over existingstate-of-the-art regarding performance fidelity.</description>
      <author>example@mail.com (Junyeong Maeng, Kwanseok Oh, Wonsik Jung, Heung-Il Suk)</author>
      <guid isPermaLink="false">2410.16945v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Network-Accelerated Network-Reconfigured Optimal Power Flow</title>
      <link>http://arxiv.org/abs/2410.17460v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;最优潮流（OPF）在实时电网操作中被广泛使用，动态拓扑的灵活性能够提高电网效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于机器学习的方法，加速混合整数线性规划的网络重构最优潮流（NR-OPF）问题的解决过程。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络（GNN）进行离线训练，以预测最佳拓扑，并引入离线预处理的机器学习过滤层和在线后处理的机器学习选择层。&lt;h4&gt;主要发现&lt;/h4&gt;通过案例研究，验证了所提出的基于GNN的加速NR-OPF方法的优越性能，结合预处理和后处理层显著提升了模型的准确性和效率。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法有效降低了计算时间，提升了NR-OPF问题的求解效率，具有良好的应用前景。&lt;h4&gt;总结&lt;/h4&gt;结合机器学习和图神经网络的创新方法为电网优化提供了新的解决思路，显著提高了实时操作的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimal power flow (OPF) has been used for real-time grid operations. Priorefforts demonstrated that utilizing flexibility from dynamic topologies willimprove grid efficiency. However, this will convert the linear OPF into amixed-integer linear programming network-reconfigured OPF (NR-OPF) problem,substantially increasing the computing time. Thus, a machine learning(ML)-based approach, particularly utilizing graph neural network (GNN), isproposed to accelerate the solution process. The GNN model is trained offlineto predict the best topology before entering the optimization stage. Inaddition, this paper proposes an offline pre-ML filter layer to reduce GNNmodel size and training time while improving its accuracy. A fast onlinepost-ML selection layer is also proposed to analyze GNN predictions and thenselect a subset of predicted NR solutions with high confidence. Case studieshave demonstrated superior performance of the proposed GNN-accelerated NR-OPFmethod augmented with the proposed pre-ML and post-ML layers.</description>
      <author>example@mail.com (Thuan Pham, Xingpeng Li)</author>
      <guid isPermaLink="false">2410.17460v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>FoMo: A Foundation Model for Mobile Traffic Forecasting with Diffusion Model</title>
      <link>http://arxiv.org/abs/2410.15322v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;移动流量预测能够帮助运营商提前预判网络动态和性能，提升服务质量和用户体验。但现有模型通常任务导向且使用特定数据训练，限制了在不同移动网络任务中的有效性。&lt;h4&gt;目的&lt;/h4&gt;提出一种创新的基础模型FoMo，用于移动流量预测，旨在处理短期和长期预测及多个城市的分布生成，从而支持网络规划和优化。&lt;h4&gt;方法&lt;/h4&gt;FoMo结合扩散模型和变换器，提出多种时空掩码，使其能够学习不同任务的内在特征，并开发对比学习策略捕捉移动流量与城市环境之间的关联，提高迁移学习能力。&lt;h4&gt;主要发现&lt;/h4&gt;在9个真实世界数据集上的广泛实验表明，FoMo在多样化预测任务和零/少样本学习方面优于现有模型，展示出强大的普适性。&lt;h4&gt;结论&lt;/h4&gt;FoMo在中国移动的JiuTian优化平台上部署，利用预测的移动数据制定网络规划和优化应用，包括基站部署、资源块调度和基站睡眠控制。&lt;h4&gt;总结&lt;/h4&gt;FoMo模型通过多任务适应和学习能力的提升，为移动流量预测提供了新的思路，具有广泛应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile traffic forecasting allows operators to anticipate network dynamicsand performance in advance, offering substantial potential for enhancingservice quality and improving user experience. However, existing models areoften task-oriented and are trained with tailored data, which limits theireffectiveness in diverse mobile network tasks of Base Station (BS) deployment,resource allocation, energy optimization, etc. and hinders generalizationacross different urban environments. Foundation models have made remarkablestrides across various domains of NLP and CV due to their multi-taskingadaption and zero/few-shot learning capabilities. In this paper, we propose aninnovative Foundation model for Mo}bile traffic forecasting (FoMo), aiming tohandle diverse forecasting tasks of short/long-term predictions anddistribution generation across multiple cities to support network planning andoptimization. FoMo combines diffusion models and transformers, where variousspatio-temporal masks are proposed to enable FoMo to learn intrinsic featuresof different tasks, and a contrastive learning strategy is developed to capturethe correlations between mobile traffic and urban contexts, thereby improvingits transfer learning capability. Extensive experiments on 9 real-worlddatasets demonstrate that FoMo outperforms current models concerning diverseforecasting tasks and zero/few-shot learning, showcasing a strong universality.We further deploy the FoMo on the JiuTian optimization platform of ChinaMobile, where we use the predicted mobile data to formulate network planningand optimization applications, including BS deployment, resource blockscheduling, and BS sleep control.</description>
      <author>example@mail.com (Haoye Chai, Shiyuan Zhang, Xiaoqian Qi, Yong Li)</author>
      <guid isPermaLink="false">2410.15322v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating the Backdoor Effect for Multi-Task Model Merging via Safety-Aware Subspace</title>
      <link>http://arxiv.org/abs/2410.13910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages,8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;模型合并作为一种成本效益高的方法，旨在将多个单任务微调模型整合为一个能够在多个任务上表现良好的统一模型。&lt;h4&gt;目的&lt;/h4&gt;研究现有模型合并方法在对抗后门攻击时的脆弱性，并提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的防御感知合并方法（DAM），通过基于元学习的优化方法和双重掩码来识别共享和安全的子空间进行模型合并。&lt;h4&gt;主要发现&lt;/h4&gt;DAM方法相比于现有的合并方法，在性能和安全性之间取得了更好的平衡，攻击成功率降低了2-10个百分点，准确度只降低约1%。&lt;h4&gt;结论&lt;/h4&gt;DAM在多种后门攻击类型及合并过程中涉及的被攻击模型数量上表现出强大的性能和广泛的适用性，未来将发布相关代码和模型。&lt;h4&gt;总结&lt;/h4&gt;本研究通过引入防御感知合并方法，解决了模型合并中存在的安全威胁问题，提升了模型的安全性和性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Model merging has gained significant attention as a cost-effective approachto integrate multiple single-task fine-tuned models into a unified one that canperform well on multiple tasks. However, existing model merging techniquesprimarily focus on resolving conflicts between task-specific models, they oftenoverlook potential security threats, particularly the risk of backdoor attacksin the open-source model ecosystem. In this paper, we first investigate thevulnerabilities of existing model merging methods to backdoor attacks,identifying two critical challenges: backdoor succession and backdoor transfer.To address these issues, we propose a novel Defense-Aware Merging (DAM)approach that simultaneously mitigates task interference and backdoorvulnerabilities. Specifically, DAM employs a meta-learning-based optimizationmethod with dual masks to identify a shared and safety-aware subspace for modelmerging. These masks are alternately optimized: the Task-Shared mask identifiescommon beneficial parameters across tasks, aiming to preserve task-specificknowledge while reducing interference, while the Backdoor-Detection maskisolates potentially harmful parameters to neutralize security threats. Thisdual-mask design allows us to carefully balance the preservation of usefulknowledge and the removal of potential vulnerabilities. Compared to existingmerging methods, DAM achieves a more favorable balance between performance andsecurity, reducing the attack success rate by 2-10 percentage points whilesacrificing only about 1% in accuracy. Furthermore, DAM exhibits robustperformance and broad applicability across various types of backdoor attacksand the number of compromised models involved in the merging process. We willrelease the codes and models soon.</description>
      <author>example@mail.com (Jinluan Yang, Anke Tang, Didi Zhu, Zhengyu Chen, Li Shen, Fei Wu)</author>
      <guid isPermaLink="false">2410.13910v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Joint Point Cloud Upsampling and Cleaning with Octree-based CNNs</title>
      <link>http://arxiv.org/abs/2410.17001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by Computational Visual Media&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从稀疏或噪声数据中恢复密集且均匀分布的点云仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单而高效的方法，联合进行点云的上采样和清理。&lt;h4&gt;方法&lt;/h4&gt;采用经过小幅修改的八叉树基础3D U-Net（OUNet），在单个网络中实现上采样和清理。&lt;h4&gt;主要发现&lt;/h4&gt;该网络直接处理整个输入点云，而非逐片处理，显著简化了实现，并使推理速度提高至少47倍。&lt;h4&gt;结论&lt;/h4&gt;在多个基准测试中，该方法在效率优势下实现了最先进的性能，期望为点云上采样和清理的研究提供简单的基线。&lt;h4&gt;总结&lt;/h4&gt;该方法的提出旨在激励研究者重新思考点云处理方法的设计。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/octree-nn/upsample-clean&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering dense and uniformly distributed point clouds from sparse or noisydata remains a significant challenge. Recently, great progress has been made onthese tasks, but usually at the cost of increasingly intricate modules orcomplicated network architectures, leading to long inference time and hugeresource consumption. Instead, we embrace simplicity and present a simple yetefficient method for jointly upsampling and cleaning point clouds. Our methodleverages an off-the-shelf octree-based 3D U-Net (OUNet) with minormodifications, enabling the upsampling and cleaning tasks within a singlenetwork. Our network directly processes each input point cloud as a wholeinstead of processing each point cloud patch as in previous works, whichsignificantly eases the implementation and brings at least 47 times fasterinference. Extensive experiments demonstrate that our method achievesstate-of-the-art performances under huge efficiency advantages on a series ofbenchmarks. We expect our method to serve simple baselines and inspireresearchers to rethink the method design on point cloud upsampling andcleaning.</description>
      <author>example@mail.com (Jihe Li, Bo Pang, Peng-Shuai Wang)</author>
      <guid isPermaLink="false">2410.17001v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Lightweight Neural App Control</title>
      <link>http://arxiv.org/abs/2410.17883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新的移动电话控制架构，称为'appagents'，用于高效地与各种Android应用进行交互和控制。&lt;h4&gt;目的&lt;/h4&gt;开发一种轻量级的多模态应用控制方法（LiMAC），以实现基于文本目标和过去移动观察序列的精确动作生成。&lt;h4&gt;方法&lt;/h4&gt;LiMAC利用小型的Action Transformer（AcT）和微调的视觉语言模型（VLM）实现实时决策和任务执行。&lt;h4&gt;主要发现&lt;/h4&gt;在两个开源移动控制数据集上的评估表明，LiMAC在小型化设计方面的表现优于微调的开源VLM，如Florence2和Qwen2-VL，且在动作准确性上提高了19%至42%。&lt;h4&gt;结论&lt;/h4&gt;LiMAC显著优于使用闭源基础模型（如GPT-4o）的提示工程基线，展示了其在移动设备上的有效性和性能优势。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了LiMAC在移动应用控制中的潜力，强调了其在准确性和效率上的显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces a novel mobile phone control architecture, termed ``appagents", for efficient interactions and controls across various Android apps.The proposed Lightweight Multi-modal App Control (LiMAC) takes as input atextual goal and a sequence of past mobile observations, such as screenshotsand corresponding UI trees, to generate precise actions. To address thecomputational constraints inherent to smartphones, within LiMAC, we introduce asmall Action Transformer (AcT) integrated with a fine-tuned vision-languagemodel (VLM) for real-time decision-making and task execution. We evaluate LiMACon two open-source mobile control datasets, demonstrating the superiorperformance of our small-form-factor approach against fine-tuned versions ofopen-source VLMs, such as Florence2 and Qwen2-VL. It also significantlyoutperforms prompt engineering baselines utilising closed-source foundationmodels like GPT-4o. More specifically, LiMAC increases the overall actionaccuracy by up to 19% compared to fine-tuned VLMs, and up to 42% compared toprompt-engineering baselines.</description>
      <author>example@mail.com (Filippos Christianos, Georgios Papoudakis, Thomas Coste, Jianye Hao, Jun Wang, Kun Shao)</author>
      <guid isPermaLink="false">2410.17883v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>PathMoCo: A Novel Framework to Improve Feature Embedding in Self-supervised Contrastive Learning for Histopathological Images</title>
      <link>http://arxiv.org/abs/2410.17514v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自监督对比学习已成为多个领域的重要基础，特别是在组织病理图像分析中。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的组织病理学特定图像增强方法，以改善自监督对比学习的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种称为污渍重建增强（SRA）的图像增强方法，并将其与自监督对比学习中的领先模型MoCov3结合，形成新模型PathMoCo。&lt;h4&gt;主要发现&lt;/h4&gt;PathMoCo在各种下游任务中始终优于标准的MoCo v3，并且在与其他在更大组织病理数据集上预训练的基础模型相比时，表现出可比或更优的性能。&lt;h4&gt;结论&lt;/h4&gt;通过SRA和PathMoCo的结合，可以显著提升组织病理图像的自监督对比学习效果。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的PathMoCo模型在组织病理图像分析中具有重要的应用潜力，证明了特定领域图像增强方法的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised contrastive learning has become a cornerstone in variousareas, particularly histopathological image analysis. Image augmentation playsa crucial role in self-supervised contrastive learning, as it generatesvariations in image samples. However, traditional image augmentation techniquesoften overlook the unique characteristics of histopathological images. In thispaper, we propose a new histopathology-specific image augmentation methodcalled stain reconstruction augmentation (SRA). We integrate our SRA with MoCov3, a leading model in self-supervised contrastive learning, along with ouradditional contrastive loss terms, and call the new model PathMoCo. Wedemonstrate that our PathMoCo always outperforms the standard MoCo v3 acrossvarious downstream tasks and achieves comparable or superior performance toother foundation models pre-trained on significantly larger histopathologydatasets.</description>
      <author>example@mail.com (Hamid Manoochehri, Bodong Zhang, Beatrice S. Knudsen, Tolga Tasdizen)</author>
      <guid isPermaLink="false">2410.17514v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Breaking the Memory Barrier: Near Infinite Batch Size Scaling for Contrastive Loss</title>
      <link>http://arxiv.org/abs/2410.17243v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比损失是一种强大的表示学习方法，较大的批量大小通过提供更多负样本来提高性能，帮助更好地区分相似与不相似的数据。&lt;h4&gt;目的&lt;/h4&gt;解决在扩展批量大小时，GPU内存消耗因相似度矩阵的完全实例化而受限的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于块的计算策略，将对比损失的计算划分为任意小的块，避免完全实现相似度矩阵。同时，引入多级分块策略，利用分布式系统的层次结构，在GPU级别采用环形通信来优化同步，并在CUDA核心级别融合内核以减少I/O开销。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提方法可以将批量大小扩展到前所未有的水平，例如，使用8或32个A800 80GB的情况下，能够以4M或12M的批量大小训练CLIP-ViT-L/14模型而不牺牲准确性。&lt;h4&gt;结论&lt;/h4&gt;与最先进的内存高效解决方案相比，该方法在保持相似速度的同时，实现了两个数量级的内存减少。&lt;h4&gt;总结&lt;/h4&gt;代码将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/damo-nlp-sg/inf-clip&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive loss is a powerful approach for representation learning, wherelarger batch sizes enhance performance by providing more negative samples tobetter distinguish between similar and dissimilar data. However, scaling batchsizes is constrained by the quadratic growth in GPU memory consumption,primarily due to the full instantiation of the similarity matrix. To addressthis, we propose a tile-based computation strategy that partitions thecontrastive loss calculation into arbitrary small blocks, avoiding fullmaterialization of the similarity matrix. Furthermore, we introduce amulti-level tiling strategy to leverage the hierarchical structure ofdistributed systems, employing ring-based communication at the GPU level tooptimize synchronization and fused kernels at the CUDA core level to reduce I/Ooverhead. Experimental results show that the proposed method scales batch sizesto unprecedented levels. For instance, it enables contrastive training of aCLIP-ViT-L/14 model with a batch size of 4M or 12M using 8 or 32 A800 80GBwithout sacrificing any accuracy. Compared to SOTA memory-efficient solutions,it achieves a two-order-of-magnitude reduction in memory while maintainingcomparable speed. The code will be made publicly available.</description>
      <author>example@mail.com (Zesen Cheng, Hang Zhang, Kehan Li, Sicong Leng, Zhiqiang Hu, Fei Wu, Deli Zhao, Xin Li, Lidong Bing)</author>
      <guid isPermaLink="false">2410.17243v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Improving 3D Medical Image Segmentation at Boundary Regions using Local Self-attention and Global Volume Mixing</title>
      <link>http://arxiv.org/abs/2410.15360v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;体积医学图像分割是医学图像分析中的基本问题，目标是以体素级精度准确分类三维体积医学图像。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的基于层次编码器-解码器框架，旨在明确捕捉体积3D医学图像分割的局部和全局依赖关系。&lt;h4&gt;方法&lt;/h4&gt;该框架利用局部体积自注意力编码高分辨率的局部依赖，并引入新型体积MLP-mixer捕捉低分辨率特征表示的全局依赖。&lt;h4&gt;主要发现&lt;/h4&gt;在三个不同的数据集上进行的广泛实验表明，所提出的方法相比于最先进的方法表现优越。特别是在具有挑战性的Synapse多脏器数据集中，该方法在HD95评估指标上实现了3.82%的绝对提升。&lt;h4&gt;结论&lt;/h4&gt;所提出的体积MLP-mixer能够更好地学习体积特征表示之间的关联，提升了器官形状边界特征的学习效果。实验还显示该模型在ZebraFish 3D细胞膜数据集上的迁移学习能力卓越，能够有效区分细胞实例。&lt;h4&gt;总结&lt;/h4&gt;提出的框架在3D医学图像分割领域展现出良好的性能，尤其在处理有限训练数据的情况时，能够实现准确边界预测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Daniyanaj/vMixer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Volumetric medical image segmentation is a fundamental problem in medicalimage analysis where the objective is to accurately classify a given 3Dvolumetric medical image with voxel-level precision. In this work, we propose anovel hierarchical encoder-decoder-based framework that strives to explicitlycapture the local and global dependencies for volumetric 3D medical imagesegmentation. The proposed framework exploits local volume-based self-attentionto encode the local dependencies at high resolution and introduces a novelvolumetric MLP-mixer to capture the global dependencies at low-resolutionfeature representations, respectively. The proposed volumetric MLP-mixer learnsbetter associations among volumetric feature representations. These explicitlocal and global feature representations contribute to better learning of theshape-boundary characteristics of the organs. Extensive experiments on threedifferent datasets reveal that the proposed method achieves favorableperformance compared to state-of-the-art approaches. On the challenging SynapseMulti-organ dataset, the proposed method achieves an absolute 3.82\% gain overthe state-of-the-art approaches in terms of HD95 evaluation metrics {while asimilar improvement pattern is exhibited in MSD Liver and Pancreas tumordatasets}. We also provide a detailed comparison between recent architecturaldesign choices in the 2D computer vision literature by adapting them for theproblem of 3D medical image segmentation. Finally, our experiments on theZebraFish 3D cell membrane dataset having limited training data demonstrate thesuperior transfer learning capabilities of the proposed vMixer model on thechallenging 3D cell instance segmentation task, where accurate boundaryprediction plays a vital role in distinguishing individual cell instances.</description>
      <author>example@mail.com (Daniya Najiha Abdul Kareem, Mustansar Fiaz, Noa Novershtern, Jacob Hanna, Hisham Cholakkal)</author>
      <guid isPermaLink="false">2410.15360v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Ornstein-Uhlenbeck Adaptation as a Mechanism for Learning in Brains and Machines</title>
      <link>http://arxiv.org/abs/2410.13563v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;学习是智能系统的基本属性，广泛存在于生物体和工程系统中。&lt;h4&gt;目的&lt;/h4&gt;探索不依赖于精确梯度的替代学习机制，解决生物和神经形态系统中的学习挑战。&lt;h4&gt;方法&lt;/h4&gt;引入一种新方法，利用系统参数中的噪声和全局强化信号，使用自适应动态的Ornstein-Uhlenbeck过程来平衡学习中的探索与利用。&lt;h4&gt;主要发现&lt;/h4&gt;OUA在多种任务中有效，包括前馈和递归系统中的监督学习和强化学习，并且能够自主调整超参数，实现元学习。&lt;h4&gt;结论&lt;/h4&gt;OUA为传统基于梯度的方法提供了可行的替代方案，具有在神经形态计算中的潜在应用，且暗示了大脑中噪声驱动学习的可能机制。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的OUA方法展示了在动态、时间演变环境中学习的有效性，可能与生物神经系统中的突触调整机制相关。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning is a fundamental property of intelligent systems, observed acrossbiological organisms and engineered systems. While modern intelligent systemstypically rely on gradient descent for learning, the need for exact gradientsand complex information flow makes its implementation in biological andneuromorphic systems challenging. This has motivated the exploration ofalternative learning mechanisms that can operate locally and do not rely onexact gradients. In this work, we introduce a novel approach that leveragesnoise in the parameters of the system and global reinforcement signals. Usingan Ornstein-Uhlenbeck process with adaptive dynamics, our method balancesexploration and exploitation during learning, driven by deviations from errorpredictions, akin to reward prediction error. Operating in continuous time,Orstein-Uhlenbeck adaptation (OUA) is proposed as a general mechanism forlearning dynamic, time-evolving environments. We validate our approach acrossdiverse tasks, including supervised learning and reinforcement learning infeedforward and recurrent systems. Additionally, we demonstrate that it canperform meta-learning, adjusting hyper-parameters autonomously. Our resultsindicate that OUA provides a viable alternative to traditional gradient-basedmethods, with potential applications in neuromorphic computing. It also hintsat a possible mechanism for noise-driven learning in the brain, wherestochastic neurotransmitter release may guide synaptic adjustments.</description>
      <author>example@mail.com (Jesus Garcia Fernandez, Nasir Ahmad, Marcel van Gerven)</author>
      <guid isPermaLink="false">2410.13563v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>EPContrast: Effective Point-level Contrastive Learning for Large-scale Point Cloud Understanding</title>
      <link>http://arxiv.org/abs/2410.17207v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云预训练中，通过点级对比学习获取归纳偏置具有重要意义，但点云规模的平方增长导致计算需求大幅增加。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为EPContrast的有效点级对比学习方法，以解决大规模点云理解中的计算挑战。&lt;h4&gt;方法&lt;/h4&gt;EPContrast由AGContrast和ChannelContrast组成，AGContrast基于不对称粒度嵌入构建正负对，ChannelContrast在通道特征图之间施加对比监督。&lt;h4&gt;主要发现&lt;/h4&gt;EPContrast提供点级对比损失，同时减轻计算资源负担，经过S3DIS和ScanNetV2的全面验证，涵盖语义分割、实例分割和物体检测等任务。&lt;h4&gt;结论&lt;/h4&gt;丰富的消融实验表明，在标签效率高和单次训练周期下，EPContrast展现出卓越的偏置诱导能力。&lt;h4&gt;总结&lt;/h4&gt;EPContrast方法有效提升了大规模点云理解的效率和效果，具有良好的应用前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The acquisition of inductive bias through point-level contrastive learningholds paramount significance in point cloud pre-training. However, the squaregrowth in computational requirements with the scale of the point cloud poses asubstantial impediment to the practical deployment and execution. To addressthis challenge, this paper proposes an Effective Point-level ContrastiveLearning method for large-scale point cloud understanding dubbed\textbf{EPContrast}, which consists of AGContrast and ChannelContrast. Inpractice, AGContrast constructs positive and negative pairs based on asymmetricgranularity embedding, while ChannelContrast imposes contrastive supervisionbetween channel feature maps. EPContrast offers point-level contrastive losswhile concurrently mitigating the computational resource burden. The efficacyof EPContrast is substantiated through comprehensive validation on S3DIS andScanNetV2, encompassing tasks such as semantic segmentation, instancesegmentation, and object detection. In addition, rich ablation experimentsdemonstrate remarkable bias induction capabilities under label-efficient andone-epoch training settings.</description>
      <author>example@mail.com (Zhiyi Pan, Guoqing Liu, Wei Gao, Thomas H. Li)</author>
      <guid isPermaLink="false">2410.17207v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Toward path-invariant embeddings for local distance source characterization</title>
      <link>http://arxiv.org/abs/2410.17937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究基于最近在语言和图像领域的基础模型进展，探索类似的方法用于地震源特征化。&lt;h4&gt;目的&lt;/h4&gt;适应一种名为Barlow Twins的架构，以学习地震事件时间序列中的路径不变性。&lt;h4&gt;方法&lt;/h4&gt;将Barlow Twins架构从人类视觉皮层系统的理解中借用，并进行适应。&lt;h4&gt;主要发现&lt;/h4&gt;模型在事件特征化任务（如源分类）上的表现提高了10-12%，并提供了更可靠的预测不确定性估计。&lt;h4&gt;结论&lt;/h4&gt;数据集的规模和多样性比架构更可能决定当前性能的上限。&lt;h4&gt;分析工具&lt;/h4&gt;利用决策树、线性模型和可视化手段理解学习表示中的依赖关系。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过适应基础模型架构来提高地震源特征化任务的性能和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work builds on recent advances in foundation models in the language andimage domains to explore similar approaches for seismic sourcecharacterization. We rely on an architecture called Barlow Twins, borrowed froman understanding of the human visual cortical system and originally envisionedfor the image domain and adapt it for learning path invariance in seismic eventtime series. Our model improves the performance on event characterization taskssuch as source discrimination across catalogs by 10-12% and provides morereliable predictive uncertainty estimates. We suggest that dataset scale anddiversity more than architecture may determine aspects of the current ceilingon performance. We leverage decision trees, linear models, and visualization tounderstanding the dependencies in learned representations.</description>
      <author>example@mail.com (Lisa Linville, Chengping Chai, Nathan Marthindale, Jacob Smith, Scott Stewart, Asmeret Naugle)</author>
      <guid isPermaLink="false">2410.17937v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>FairDgcl: Fairness-aware Recommendation with Dynamic Graph Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.17555v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, submitted to TKDE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着可信AI的进步，推荐系统中的公平性问题受到越来越多的关注。推荐系统在基于用户敏感属性（如年龄、性别）对不同用户组产生不平等结果时被视为不公平。&lt;h4&gt;目的&lt;/h4&gt;研究如何实施高质量的数据增强，以提高推荐系统的公平性。&lt;h4&gt;方法&lt;/h4&gt;提出FairDgcl，一种动态图对抗性对比学习框架，旨在以对抗方式生成公平的增强策略，并通过两个动态可学习模型在对比学习框架内生成对比视图。&lt;h4&gt;主要发现&lt;/h4&gt;FairDgcl能够同时生成具有公平性和准确性的增强表示。&lt;h4&gt;结论&lt;/h4&gt;在四个真实世界数据集上的综合实验表明，所提出的FairDgcl框架有效提升了推荐系统的公平性。&lt;h4&gt;总结&lt;/h4&gt;FairDgcl通过对抗性学习和动态增强策略，解决了推荐系统中的公平性问题，展示了良好的实用性和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/cwei01/fairdgcl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As trustworthy AI continues to advance, the fairness issue in recommendationshas received increasing attention. A recommender system is considered unfairwhen it produces unequal outcomes for different user groups based onuser-sensitive attributes (e.g., age, gender). Some researchers have proposeddata augmentation-based methods aiming at alleviating user-level unfairness byaltering the skewed distribution of training data among various user groups.Despite yielding promising results, they often rely on fairness-relatedassumptions that may not align with reality, potentially reducing the dataquality and negatively affecting model effectiveness. To tackle this issue, inthis paper, we study how to implement high-quality data augmentation to improverecommendation fairness. Specifically, we propose FairDgcl, a dynamic graphadversarial contrastive learning framework aiming at improving fairness inrecommender system. First, FairDgcl develops an adversarial contrastive networkwith a view generator and a view discriminator to learn generating fairaugmentation strategies in an adversarial style. Then, we propose two dynamic,learnable models to generate contrastive views within contrastive learningframework, which automatically fine-tune the augmentation strategies.Meanwhile, we theoretically show that FairDgcl can simultaneously generateenhanced representations that possess both fairness and accuracy. Lastly,comprehensive experiments conducted on four real-world datasets demonstrate theeffectiveness of the proposed FairDgcl.</description>
      <author>example@mail.com (Wei Chen, Meng Yuan, Zhao Zhang, Ruobing Xie, Fuzhen Zhuang, Deqing Wang, Rui Liu)</author>
      <guid isPermaLink="false">2410.17555v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Deep Autoencoder with SVD-Like Convergence and Flat Minima</title>
      <link>http://arxiv.org/abs/2410.18148v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;高维复杂物理系统的表示学习旨在识别低维内在潜在空间，这对降阶建模和模态分析至关重要。&lt;h4&gt;目的&lt;/h4&gt;克服著名的科尔莫戈罗夫屏障，提高深度自编码器在潜在空间维度增加时的收敛性。&lt;h4&gt;方法&lt;/h4&gt;提出了可学习加权混合自编码器，结合奇异值分解（SVD）与深度自编码器的优点，通过可学习的加权框架实现。&lt;h4&gt;主要发现&lt;/h4&gt;引入可学习的权重参数是关键，缺少这些参数可能导致模型退化为标准的POD，或无法达到期望的收敛性。训练后的模型与其他模型相比，锐度小了数千倍。&lt;h4&gt;结论&lt;/h4&gt;在经典混沌偏微分方程系统上进行的实验表明，该方法在泛化性能上显著优于多种竞争方法，为高维复杂物理系统的稳健表示学习铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的自编码器模型，有效改善了高维物理系统的表示学习效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning for high-dimensional, complex physical systems aimsto identify a low-dimensional intrinsic latent space, which is crucial forreduced-order modeling and modal analysis. To overcome the well-knownKolmogorov barrier, deep autoencoders (AEs) have been introduced in recentyears, but they often suffer from poor convergence behavior as the rank of thelatent space increases. To address this issue, we propose the learnableweighted hybrid autoencoder, a hybrid approach that combines the strengths ofsingular value decomposition (SVD) with deep autoencoders through a learnableweighted framework. We find that the introduction of learnable weightingparameters is essential - without them, the resulting model would eithercollapse into a standard POD or fail to exhibit the desired convergencebehavior. Additionally, we empirically find that our trained model has asharpness thousands of times smaller compared to other models. Our experimentson classical chaotic PDE systems, including the 1D Kuramoto-Sivashinsky andforced isotropic turbulence datasets, demonstrate that our approachsignificantly improves generalization performance compared to several competingmethods, paving the way for robust representation learning of high-dimensional,complex physical systems.</description>
      <author>example@mail.com (Nithin Somasekharan, Shaowu Pan)</author>
      <guid isPermaLink="false">2410.18148v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Topology meets Machine Learning: An Introduction using the Euler Characteristic Transform</title>
      <link>http://arxiv.org/abs/2410.17760v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;拓扑概念可以丰富机器学习研究。&lt;h4&gt;目的&lt;/h4&gt;展示拓扑概念在机器学习中的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;以欧拉特征变换（ECT）为例，探讨在点云、图和网格分析中的不同应用案例。&lt;h4&gt;主要发现&lt;/h4&gt;使用拓扑概念可构建更高效的分析模型。&lt;h4&gt;结论&lt;/h4&gt;拓扑概念的未来应用包括学习拓扑空间上的函数、构建融合拓扑知识的混合模型，以及分析神经网络的定性特性。&lt;h4&gt;总结&lt;/h4&gt;本文为这一新兴研究领域提供了介绍和邀请，当前研究已在某些方面展开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This overview article makes the case for how topological concepts can enrichresearch in machine learning. Using the Euler Characteristic Transform (ECT), ageometrical-topological invariant, as a running example, I present differentuse cases that result in more efficient models for analyzing point clouds,graphs, and meshes. Moreover, I outline a vision for how topological conceptscould be used in the future, comprising (1) the learning of functions ontopological spaces, (2) the building of hybrid models that imbue neuralnetworks with knowledge about the topological information in data, and (3) theanalysis of qualitative properties of neural networks. With current researchalready addressing some of these aspects, this article thus serves as anintroduction and invitation to this nascent area of research.</description>
      <author>example@mail.com (Bastian Rieck)</author>
      <guid isPermaLink="false">2410.17760v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Double Banking on Knowledge: Customized Modulation and Prototypes for Multi-Modality Semi-supervised Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2410.17565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多模态半监督学习在医学图像分割中受到越来越多的关注，能够利用多模态数据并减少对标记图像的依赖。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的多模态半监督学习方法，解决当前方法面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了双银行双一致性(DBDC)方法，设计了一个能够处理任意数量模态的全模态分割网络，以及两个可学习的插件库来捕获模态不变和模态特定的知识，并引入了动态加权机制和双一致性策略。&lt;h4&gt;主要发现&lt;/h4&gt;在使用三个开源数据集进行2到4模态分割任务的评估中，所提出的方法在性能上优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;DBDC方法有效解决了多模态半监督学习中的多项挑战，推动了医学图像分割的进展。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的DBDC方法通过创新的网络结构和学习机制，显著提升了多模态医学图像分割的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modality (MM) semi-supervised learning (SSL) based medical imagesegmentation has recently gained increasing attention for its ability toutilize MM data and reduce reliance on labeled images. However, current methodsface several challenges: (1) Complex network designs hinder scalability toscenarios with more than two modalities. (2) Focusing solely onmodality-invariant representation while neglecting modality-specific features,leads to incomplete MM learning. (3) Leveraging unlabeled data with generativemethods can be unreliable for SSL. To address these problems, we propose DoubleBank Dual Consistency (DBDC), a novel MM-SSL approach for medical imagesegmentation. To address challenge (1), we propose a modality all-in-onesegmentation network that accommodates data from any number of modalities,removing the limitation on modality count. To address challenge (2), we designtwo learnable plug-in banks, Modality-Level Modulation bank (MLMB) andModality-Level Prototype (MLPB) bank, to capture both modality-invariant andmodality-specific knowledge. These banks are updated using our proposedModality Prototype Contrastive Learning (MPCL). Additionally, we designModality Adaptive Weighting (MAW) to dynamically adjust learning weights foreach modality, ensuring balanced MM learning as different modalities learn atdifferent rates. Finally, to address challenge (3), we introduce a DualConsistency (DC) strategy that enforces consistency at both the image andfeature levels without relying on generative methods. We evaluate our method ona 2-to-4 modality segmentation task using three open-source datasets, andextensive experiments show that our method outperforms state-of-the-artapproaches.</description>
      <author>example@mail.com (Yingyu Chen, Ziyuan Yang, Ming Yan, Zhongzhou Zhang, Hui Yu, Yan Liu, Yi Zhang)</author>
      <guid isPermaLink="false">2410.17565v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Foundation Models on Exceptional Cases: Dataset Creation and Validation</title>
      <link>http://arxiv.org/abs/2410.18001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  EMNLP 2024 Workshop
  Genbench(https://genbench.org/workshop_programme/)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）在各类任务中取得了显著成功，但在特殊场景下的表现研究较少。&lt;h4&gt;目的&lt;/h4&gt;首次探讨FMs在分布外（OOD）推理任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;开发了一种新数据集，用于评估FMs在多种模态下的表现，包括图画小说、书法、新闻文章和歌词，并设计了实例分类、角色识别、标记预测和文本生成等任务。&lt;h4&gt;主要发现&lt;/h4&gt;通过各种方法验证FMs的表现，发现应用提示工程技术（如链式思维和链式思维+少量示例）可以提高性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为FMs在特殊场景下的评估提供了新的思路和工具。&lt;h4&gt;总结&lt;/h4&gt;本论文为基础模型的特殊场景应用提供了重要的基准和方法支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/mlai-yonsei/exceptionalbenchmark&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) have achieved significant success across varioustasks, leading to research on benchmarks for reasoning abilities. However,there is a lack of studies on FMs performance in exceptional scenarios, whichwe define as out-of-distribution (OOD) reasoning tasks. This paper is the firstto address these cases, developing a novel dataset for evaluation of FMs acrossmultiple modalities, including graphic novels, calligraphy, news articles, andlyrics. It includes tasks for instance classification, character recognition,token prediction, and text generation. The paper also proposes promptengineering techniques like Chain-of-Thought (CoT) and CoT+Few-Shot to enhanceperformance. Validation of FMs using various methods revealed improvements. Thecode repository is accessible at:https://github.com/MLAI-Yonsei/ExceptionalBenchmark</description>
      <author>example@mail.com (Suho Kang, Jungyang Park, Joonseo Ha, SoMin Kim, JinHyeong Kim, Subeen Park, Kyungwoo Song)</author>
      <guid isPermaLink="false">2410.18001v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Multimodal Medical Image Classification using Cross-Graph Modal Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.17494v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;医学图像分类在疾病诊断中至关重要，传统方法通常专注于单一模式的医学图像数据，忽视了多样化的非图像患者数据的整合。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的跨图模式对比学习框架（CGMCL）用于多模态医学图像分类。&lt;h4&gt;方法&lt;/h4&gt;模型通过构建跨模态图和利用对比学习，将图像和非图像数据有效整合在共享潜在空间中。同时，采用跨模态特征缩放模块优化表示学习过程，缩小异构模态之间的差距。&lt;h4&gt;主要发现&lt;/h4&gt;在帕金森病数据集和公共黑色素瘤数据集上的评估结果表明，CGMCL在准确性、可解释性和早期疾病预测方面优于传统的单模态方法，且在多类别黑色素瘤分类中表现出色。&lt;h4&gt;结论&lt;/h4&gt;CGMCL框架为医学图像分类提供了有价值的见解，同时改善了疾病的可解释性和预测能力。&lt;h4&gt;总结&lt;/h4&gt;该研究强调了整合多模态数据在医学图像分类中的重要性，并展示了CGMCL的优越性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The classification of medical images is a pivotal aspect of diseasediagnosis, often enhanced by deep learning techniques. However, traditionalapproaches typically focus on unimodal medical image data, neglecting theintegration of diverse non-image patient data. This paper proposes a novelCross-Graph Modal Contrastive Learning (CGMCL) framework for multimodal medicalimage classification. The model effectively integrates both image and non-imagedata by constructing cross-modality graphs and leveraging contrastive learningto align multimodal features in a shared latent space. An inter-modalityfeature scaling module further optimizes the representation learning process byreducing the gap between heterogeneous modalities. The proposed approach isevaluated on two datasets: a Parkinson's disease (PD) dataset and a publicmelanoma dataset. Results demonstrate that CGMCL outperforms conventionalunimodal methods in accuracy, interpretability, and early disease prediction.Additionally, the method shows superior performance in multi-class melanomaclassification. The CGMCL framework provides valuable insights into medicalimage classification while offering improved disease interpretability andpredictive capabilities.</description>
      <author>example@mail.com (Jun-En Ding, Chien-Chin Hsu, Feng Liu)</author>
      <guid isPermaLink="false">2410.17494v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Towards Optimal Adapter Placement for Efficient Transfer Learning</title>
      <link>http://arxiv.org/abs/2410.15858v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;参数有效的迁移学习（PETL）旨在在适应预训练模型到新任务时，最小化微调参数的数量。&lt;h4&gt;目的&lt;/h4&gt;研究适配器在网络中的放置位置与其性能之间的关系。&lt;h4&gt;方法&lt;/h4&gt;引入扩展的适配器连接搜索空间，包括长程和递归适配器，观察不同放置的效果。&lt;h4&gt;主要发现&lt;/h4&gt;适配器在网络中的位置显著影响其有效性，最佳放置依赖于具体任务。即使随机选择的适配器位置也能带来改进，高性能放置通常与高梯度秩相关。&lt;h4&gt;结论&lt;/h4&gt;少量战略性放置的适配器可以与在每个模块中添加适配器的常见基线相匹配或超越，为优化适配器放置策略的研究开辟了新途径。&lt;h4&gt;总结&lt;/h4&gt;适配器的放置策略是影响性能的关键因素，优化放置可以提高模型在迁移学习中的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parameter-efficient transfer learning (PETL) aims to adapt pre-trained modelsto new downstream tasks while minimizing the number of fine-tuned parameters.Adapters, a popular approach in PETL, inject additional capacity into existingnetworks by incorporating low-rank projections, achieving performancecomparable to full fine-tuning with significantly fewer parameters. This paperinvestigates the relationship between the placement of an adapter and itsperformance. We observe that adapter location within a network significantlyimpacts its effectiveness, and that the optimal placement is task-dependent. Toexploit this observation, we introduce an extended search space of adapterconnections, including long-range and recurrent adapters. We demonstrate thateven randomly selected adapter placements from this expanded space yieldimproved results, and that high-performing placements often correlate with highgradient rank. Our findings reveal that a small number of strategically placedadapters can match or exceed the performance of the common baseline of addingadapters in every block, opening a new avenue for research into optimal adapterplacement strategies.</description>
      <author>example@mail.com (Aleksandra I. Nowak, Otniel-Bogdan Mercea, Anurag Arnab, Jonas Pfeiffer, Yann Dauphin, Utku Evci)</author>
      <guid isPermaLink="false">2410.15858v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>A Communication and Computation Efficient Fully First-order Method for Decentralized Bilevel Optimization</title>
      <link>http://arxiv.org/abs/2410.14115v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 Pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "双层优化在超参数调优、元学习和强化学习中至关重要，但在去中心化学习范式（如去中心化联邦学习）中仍然较少探索。",
    "目的": "提出一种完全一阶去中心化方法，解决去中心化双层优化中的计算和通信效率问题。",
    "方法": "引入$\text{C}^2$DFB方法，每个学习节点优化一个最小-最大问题，仅使用梯度信息来近似超梯度，并采用轻量级通信协议传输本地参数的压缩残差。",
    "主要发现": "$\text{C}^2$DFB在多种类型和异构数据分布上，在超参数调优和超表示任务中展现出优越性。",
    "结论": "通过严格的理论分析确保算法的收敛性，证明一阶oracle调用的复杂度为$\tilde{\mathcal{O}}(\epsilon^{-4})$。",
    "总结": "$\text{C}^2$DFB方法在去中心化双层优化中具有计算和通信的高效性，适用于不同的学习任务。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bilevel optimization, crucial for hyperparameter tuning, meta-learning andreinforcement learning, remains less explored in the decentralized learningparadigm, such as decentralized federated learning (DFL). Typically,decentralized bilevel methods rely on both gradients and Hessian matrices toapproximate hypergradients of upper-level models. However, acquiring andsharing the second-order oracle is compute and communication intensive. % andsharing this information incurs heavy communication overhead. To overcome thesechallenges, this paper introduces a fully first-order decentralized method fordecentralized Bilevel optimization, $\text{C}^2$DFB which is both compute- andcommunicate-efficient. In $\text{C}^2$DFB, each learning node optimizes amin-min-max problem to approximate hypergradient by exclusively using gradientsinformation. To reduce the traffic load at the inner-loop of solving thelower-level problem, $\text{C}^2$DFB incorporates a lightweight communicationprotocol for efficiently transmitting compressed residuals of local parameters.% during the inner loops. Rigorous theoretical analysis ensures its convergence% of the algorithm, indicating a first-order oracle calls of$\tilde{\mathcal{O}}(\epsilon^{-4})$. Experiments on hyperparameter tuning andhyper-representation tasks validate the superiority of $\text{C}^2$DFB acrossvarious typologies and heterogeneous data distributions.</description>
      <author>example@mail.com (Min Wen, Chengchang Liu, Ahmed Abdelmoniem, Yipeng Zhou, Yuedong Xu)</author>
      <guid isPermaLink="false">2410.14115v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Quasi-Medial Distance Field (Q-MDF): A Robust Method for Approximating and Discretizing Neural Medial Axis</title>
      <link>http://arxiv.org/abs/2410.17774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;中轴线作为一种低维形状描述符，在数字几何处理领域中具有重要作用，但从多样化输入（尤其是缺陷点云）中稳健计算中轴线变换仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的隐式方法，以应对中轴线计算中的挑战，特别是针对缺陷点云的情况。&lt;h4&gt;方法&lt;/h4&gt;通过将中轴线计算公式化为隐式重建问题，利用修改的双重覆盖方法提取中轴线作为无符号距离场的零水平集。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，该方法在从复杂网格和点云学习紧凑中轴线变换方面显示出更高的准确性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;提出的隐式方法有效解决了多样化输入下的中轴线计算问题，具有更好的性能。&lt;h4&gt;总结&lt;/h4&gt;本研究为中轴线的稳健计算提供了新的思路和方法，推动了数字几何处理的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The medial axis, a lower-dimensional shape descriptor, plays an importantrole in the field of digital geometry processing. Despite its importance,robust computation of the medial axis transform from diverse inputs, especiallypoint clouds with defects, remains a significant challenge. In this paper, wetackle the challenge by proposing a new implicit method that diverges frommainstream explicit medial axis computation techniques. Our key technicalinsight is the difference between the signed distance field (SDF) and themedial field (MF) of a solid shape is the unsigned distance field (UDF) of theshape's medial axis. This allows for formulating medial axis computation as animplicit reconstruction problem. Utilizing a modified double covering method,we extract the medial axis as the zero level-set of the UDF. Extensiveexperiments show that our method has enhanced accuracy and robustness inlearning compact medial axis transform from thorny meshes and point cloudscompared to existing methods.</description>
      <author>example@mail.com (Jiayi Kong, Chen Zong, Jun Luo, Shiqing Xin, Fei Hou, Hanqing Jiang, Chen Qian, Ying He)</author>
      <guid isPermaLink="false">2410.17774v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Implicit Graphon Learning</title>
      <link>http://arxiv.org/abs/2410.17464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Graphons 是表示图结构的连续模型，允许生成不同大小的图。&lt;h4&gt;目的&lt;/h4&gt;提出可扩展的隐式 Graphon 学习 (SIGL) 方法，从观察到的图中估计 Graphon。&lt;h4&gt;方法&lt;/h4&gt;SIGL 结合了隐式神经表示 (INRs) 和图神经网络 (GNNs)，学习在任意分辨率下的连续 Graphon，并利用 GNN 确定正确的节点排序以改善图对齐。&lt;h4&gt;主要发现&lt;/h4&gt;SIGL 的估计器具有渐近一致性，更具表现力的 INRs 和 GNNs 导致一致的估计器。&lt;h4&gt;结论&lt;/h4&gt;SIGL 在合成和真实世界的图上表现优于现有方法，并有效扩展到更大的图，适用于图数据增强等任务。&lt;h4&gt;总结&lt;/h4&gt;SIGL 是一种新方法，克服了现有方法的限制，具有良好的扩展性和一致性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphons are continuous models that represent the structure of graphs andallow the generation of graphs of varying sizes. We propose Scalable ImplicitGraphon Learning (SIGL), a scalable method that combines implicit neuralrepresentations (INRs) and graph neural networks (GNNs) to estimate a graphonfrom observed graphs. Unlike existing methods, which face important limitationslike fixed resolution and scalability issues, SIGL learns a continuous graphonat arbitrary resolutions. GNNs are used to determine the correct node ordering,improving graph alignment. Furthermore, we characterize the asymptoticconsistency of our estimator, showing that more expressive INRs and GNNs leadto consistent estimators. We evaluate SIGL in synthetic and real-world graphs,showing that it outperforms existing methods and scales effectively to largergraphs, making it ideal for tasks like graph data augmentation.</description>
      <author>example@mail.com (Ali Azizpour, Nicolas Zilberstein, Santiago Segarra)</author>
      <guid isPermaLink="false">2410.17464v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Can Uncertainty Quantification Enable Better Learning-based Index Tuning?</title>
      <link>http://arxiv.org/abs/2410.17748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;索引调优对于通过选择最佳索引来优化数据库性能至关重要，关键在于准确高效的收益估计器。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过量化学习模型结果中的不确定性，结合传统与学习方法的优点，以实现可靠的索引调优。&lt;h4&gt;方法&lt;/h4&gt;采用名为Beauty的不确定性感知框架，结合AutoEncoder与Monte Carlo Dropout方法，共同量化不确定性，并使用what-if工具作为补充机制。&lt;h4&gt;主要发现&lt;/h4&gt;在涉及十六个模型的实验中，该方法在大多数情况下超越了现有的不确定性量化方法，并在六个数据集上进行了索引调优测试。&lt;h4&gt;结论&lt;/h4&gt;通过Beauty框架，我们消除了最坏情况的发生，并使最佳情况的发生次数增加了三倍以上。&lt;h4&gt;总结&lt;/h4&gt;本研究提出了一种新颖的框架，通过量化不确定性，改善了学习模型的可靠性和管理复杂性，从而有效提升了数据库索引调优的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Index tuning is crucial for optimizing database performance by selectingoptimal indexes based on workload. The key to this process lies in an accurateand efficient benefit estimator. Traditional methods relying on what-if toolsoften suffer from inefficiency and inaccuracy. In contrast, learning-basedmodels provide a promising alternative but face challenges such as instability,lack of interpretability, and complex management. To overcome theselimitations, we adopt a novel approach: quantifying the uncertainty inlearning-based models' results, thereby combining the strengths of bothtraditional and learning-based methods for reliable index tuning. We proposeBeauty, the first uncertainty-aware framework that enhances learning-basedmodels with uncertainty quantification and uses what-if tools as acomplementary mechanism to improve reliability and reduce managementcomplexity. Specifically, we introduce a novel method that combines AutoEncoderand Monte Carlo Dropout to jointly quantify uncertainty, tailored to thecharacteristics of benefit estimation tasks. In experiments involving sixteenmodels, our approach outperformed existing uncertainty quantification methodsin the majority of cases. We also conducted index tuning tests on six datasets.By applying the Beauty framework, we eliminated worst-case scenarios and morethan tripled the occurrence of best-case scenarios.</description>
      <author>example@mail.com (Tao Yu, Zhaonian Zou, Hao Xiong)</author>
      <guid isPermaLink="false">2410.17748v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>TabDPT: Scaling Tabular Foundation Models</title>
      <link>http://arxiv.org/abs/2410.18164v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Minimal TabDPT interface to provide predictions on new datasets
  available at the following link: https://github.com/layer6ai-labs/TabDPT&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;神经网络在处理表格数据时面临挑战，影响了表格基础模型的发展。&lt;h4&gt;目的&lt;/h4&gt;探讨利用上下文学习（ICL）技术在表格数据上的应用，以实现动态适应未见数据。&lt;h4&gt;方法&lt;/h4&gt;通过自监督学习和检索，训练针对表格数据的ICL架构，结合真实数据的优势。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的Tabular Discriminative Pre-trained Transformer (TabDPT) 在CC18（分类）和CTR23（回归）基准上实现了最先进的性能，无需任务特定微调。&lt;h4&gt;结论&lt;/h4&gt;TabDPT展示了ICL的适应性和速度，随着模型规模和可用数据量的增加，其性能也得到增强，未来可通过更大规模的表格预训练数据集和更大的模型进行改进。&lt;h4&gt;总结&lt;/h4&gt;利用ICL技术和自监督学习，TabDPT有效解决了表格数据处理中的挑战，展现出良好的扩展性和高效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/layer6ai-labs/TabDPT&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The challenges faced by neural networks on tabular data are well-documentedand have hampered the progress of tabular foundation models. Techniquesleveraging in-context learning (ICL) have shown promise here, allowing fordynamic adaptation to unseen data. ICL can provide predictions for entirely newdatasets without further training or hyperparameter tuning, therefore providingvery fast inference when encountering a novel task. However, scaling ICL fortabular data remains an issue: approaches based on large language models cannotefficiently process numeric tables, and tabular-specific techniques have notbeen able to effectively harness the power of real data to improve performanceand generalization. We are able to overcome these challenges by trainingtabular-specific ICL-based architectures on real data with self-supervisedlearning and retrieval, combining the best of both worlds. Our resulting model-- the Tabular Discriminative Pre-trained Transformer (TabDPT) -- achievesstate-of-the-art performance on the CC18 (classification) and CTR23(regression) benchmarks with no task-specific fine-tuning, demonstrating theadapatability and speed of ICL once the model is pre-trained. TabDPT alsodemonstrates strong scaling as both model size and amount of available dataincrease, pointing towards future improvements simply through the curation oflarger tabular pre-training datasets and training larger models.</description>
      <author>example@mail.com (Junwei Ma, Valentin Thomas, Rasa Hosseinzadeh, Hamidreza Kamkari, Alex Labach, Jesse C. Cresswell, Keyvan Golestan, Guangwei Yu, Maksims Volkovs, Anthony L. Caterini)</author>
      <guid isPermaLink="false">2410.18164v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Information Bottleneck for Deep Reinforcement Learning with Multiple Sensors</title>
      <link>http://arxiv.org/abs/2410.17551v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  31 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;强化学习在机器人控制任务中取得了良好效果，但在有效利用多种感知模态的信息方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出一个多模态信息瓶颈模型，以学习与任务相关的联合表示。&lt;h4&gt;方法&lt;/h4&gt;通过压缩和保留多模态观察中的预测信息，融合视觉和本体反馈的互补信息，同时过滤掉与任务无关的信息。&lt;h4&gt;主要发现&lt;/h4&gt;在多个具有挑战性的 locomotion 任务上，提出的方法在样本效率和对未见白噪声的零-shot 鲁棒性方面优于领先的基线。&lt;h4&gt;结论&lt;/h4&gt;利用来自自我中心图像和本体感知的信息比仅使用单一模态在学习 locomotion 任务的策略上更有帮助。&lt;h4&gt;总结&lt;/h4&gt;该研究通过多模态信息瓶颈模型提升了强化学习在机器人控制中的表现，显示了多模态信息整合的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1016/j.neunet.2024.106347&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning has achieved promising results on robotic controltasks but struggles to leverage information effectively from multiple sensorymodalities that differ in many characteristics. Recent works constructauxiliary losses based on reconstruction or mutual information to extract jointrepresentations from multiple sensory inputs to improve the sample efficiencyand performance of reinforcement learning algorithms. However, therepresentations learned by these methods could capture information irrelevantto learning a policy and may degrade the performance. We argue that compressinginformation in the learned joint representations about raw multimodalobservations is helpful, and propose a multimodal information bottleneck modelto learn task-relevant joint representations from egocentric images andproprioception. Our model compresses and retains the predictive information inmultimodal observations for learning a compressed joint representation, whichfuses complementary information from visual and proprioceptive feedback andmeanwhile filters out task-irrelevant information in raw multimodalobservations. We propose to minimize the upper bound of our multimodalinformation bottleneck objective for computationally tractable optimization.Experimental evaluations on several challenging locomotion tasks withegocentric images and proprioception show that our method achieves bettersample efficiency and zero-shot robustness to unseen white noise than leadingbaselines. We also empirically demonstrate that leveraging information fromegocentric images and proprioception is more helpful for learning policies onlocomotion tasks than solely using one single modality.</description>
      <author>example@mail.com (Bang You, Huaping Liu)</author>
      <guid isPermaLink="false">2410.17551v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Pointer: An Energy-Efficient ReRAM-based Point Cloud Recognition Accelerator with Inter-layer and Intra-layer Optimizations</title>
      <link>http://arxiv.org/abs/2410.17782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in ASPDAC'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;点云是一种重要的数据结构，广泛应用于机器人技术、增强现实/虚拟现实和自动驾驶等领域。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的点云识别加速器，以满足快速处理的需求。&lt;h4&gt;方法&lt;/h4&gt;提出Pointer，一个基于电阻随机存取内存（ReRAM）的点云识别加速器，采用层间和层内优化技术。&lt;h4&gt;主要发现&lt;/h4&gt;Pointer通过三种技术加速点云处理：1) 采用ReRAM架构显著加速特征计算中的多层感知器（MLP）；2) 通过层间协调减少DRAM访问；3) 通过拓扑感知的层内重排序改善数据局部性。&lt;h4&gt;结论&lt;/h4&gt;Pointer相较于之前的加速器实现了40倍至393倍的速度提升和22倍至163倍的能效提升，且没有精度损失。&lt;h4&gt;总结&lt;/h4&gt;Pointer加速器显著提升了点云处理的速度和能效，适用于对速度要求高的应用，如自动驾驶。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud is an important data structure for a wide range of applications,including robotics, AR/VR, and autonomous driving. To process the point cloud,many deep-learning-based point cloud recognition algorithms have been proposed.However, to meet the requirement of applications like autonomous driving, thealgorithm must be fast enough, rendering accelerators necessary at theinference stage. But existing point cloud accelerators are still inefficientdue to two challenges. First, the multi-layer perceptron (MLP) during featurecomputation is the performance bottleneck. Second, the feature vector fetchingoperation incurs heavy DRAM access.  In this paper, we propose Pointer, an efficient Resistive Random AccessMemory (ReRAM)-based point cloud recognition accelerator with inter- andintra-layer optimizations. It proposes three techniques for point cloudacceleration. First, Pointer adopts ReRAM-based architecture to significantlyaccelerate the MLP in feature computation. Second, to reduce DRAM access,Pointer proposes inter-layer coordination. It schedules the next layer to fetchthe results of the previous layer as soon as they are available, which allowson-chip fetching thus reduces DRAM access. Third, Pointer proposestopology-aware intra-layer reordering, which improves the execution order forbetter data locality. Pointer proves to achieve 40x to 393x speedup and 22x to163x energy efficiency over prior accelerators without any accuracy loss.</description>
      <author>example@mail.com (Qijun Zhang, Zhiyao Xie)</author>
      <guid isPermaLink="false">2410.17782v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>GDDA: Semantic OOD Detection on Graphs under Covariate Shift via Score-Based Diffusion Models</title>
      <link>http://arxiv.org/abs/2410.17526v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在开放世界场景中的分布外（OOD）检测面临重大挑战，尤其是在分布变化多样的情况下。&lt;h4&gt;目的&lt;/h4&gt;同时解决语义转移和协变量转移对图形的影响，提出图级语义OOD检测的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出一种新的两阶段框架，称为图解耦扩散增强（GDDA），第一阶段解耦图表示，第二阶段引入分布转移控制的生成扩散模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的实证研究，GDDA方法在三个基准数据集上优于现有的最先进基线。&lt;h4&gt;结论&lt;/h4&gt;提出的方法有效提高了图形的OOD检测能力，尤其是在同时存在协变量和语义转移的情况下。&lt;h4&gt;总结&lt;/h4&gt;本研究为图神经网络的OOD检测提供了新的思路和方法，显著提升了检测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) detection poses a significant challenge for GraphNeural Networks (GNNs), particularly in open-world scenarios with varyingdistribution shifts. Most existing OOD detection methods on graphs primarilyfocus on identifying instances in test data domains caused by either semanticshifts (changes in data classes) or covariate shifts (changes in datafeatures), while leaving the simultaneous occurrence of both distributionshifts under-explored. In this work, we address both types of shiftssimultaneously and introduce a novel challenge for OOD detection on graphs:graph-level semantic OOD detection under covariate shift. In this scenario,variations between the training and test domains result from the concurrentpresence of both covariate and semantic shifts, where only graphs associatedwith unknown classes are identified as OOD samples (OODs). To tackle thischallenge, we propose a novel two-phase framework called Graph DisentangledDiffusion Augmentation (GDDA). The first phase focuses on disentangling graphrepresentations into domain-invariant semantic factors and domain-specificstyle factors. In the second phase, we introduce a noveldistribution-shift-controlled score-based generative diffusion model thatgenerates latent factors outside the training semantic and style spaces.Additionally, auxiliary pseudo-in-distribution (InD) and pseudo-OOD graphrepresentations are employed to enhance the effectiveness of the energy-basedsemantic OOD detector. Extensive empirical studies on three benchmark datasetsdemonstrate that our approach outperforms state-of-the-art baselines.</description>
      <author>example@mail.com (Zhixia He, Chen Zhao, Minglai Shao, Yujie Lin, Dong Li, Qin Tian)</author>
      <guid isPermaLink="false">2410.17526v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Countering Autonomous Cyber Threats</title>
      <link>http://arxiv.org/abs/2410.18312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  76 pages, MPhil Thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型具备生成流畅自然语言和代码的能力，在网络领域引发双重使用的担忧。&lt;h4&gt;目的&lt;/h4&gt;评估下载模型作为攻击性网络代理的能力，并研究防御机制以抵御AI驱动的攻击。&lt;h4&gt;方法&lt;/h4&gt;评估多种先进的基础模型在孤立网络中对机器的攻击能力，并测试防御机制。&lt;h4&gt;主要发现&lt;/h4&gt;最新发布的下载模型在执行简单网络攻击时，与领先的专有模型表现相当，能够利用常见黑客工具针对已知漏洞进行攻击。&lt;h4&gt;结论&lt;/h4&gt;防御性提示注入（DPI）有效干扰恶意网络代理的工作流程，揭示了AI安全和网络安全治理的潜在影响。&lt;h4&gt;总结&lt;/h4&gt;理解可下载模型作为攻击性网络代理的能力至关重要，以便更好地管理和防止其滥用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the capability to write convincing and fluent natural language andgenerate code, Foundation Models present dual-use concerns broadly and withinthe cyber domain specifically. Generative AI has already begun to impactcyberspace through a broad illicit marketplace for assisting malwaredevelopment and social engineering attacks through hundreds ofmalicious-AI-as-a-services tools. More alarming is that recent research hasshown the potential for these advanced models to inform or independentlyexecute offensive cyberspace operations. However, these previous investigationsprimarily focused on the threats posed by proprietary models due to the untilrecent lack of strong open-weight model and additionally leave the impacts ofnetwork defenses or potential countermeasures unexplored. Critically,understanding the aptitude of downloadable models to function as offensivecyber agents is vital given that they are far more difficult to govern andprevent their misuse. As such, this work evaluates several state-of-the-art FMson their ability to compromise machines in an isolated network and investigatesdefensive mechanisms to defeat such AI-powered attacks. Using target machinesfrom a commercial provider, the most recently released downloadable models arefound to be on par with a leading proprietary model at conducting simple cyberattacks with common hacking tools against known vulnerabilities. To mitigatesuch LLM-powered threats, defensive prompt injection (DPI) payloads fordisrupting the malicious cyber agent's workflow are demonstrated to beeffective. From these results, the implications for AI safety and governancewith respect to cybersecurity is analyzed.</description>
      <author>example@mail.com (Kade M. Heckel, Adrian Weller)</author>
      <guid isPermaLink="false">2410.18312v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>DisenGCD: A Meta Multigraph-assisted Disentangled Graph Learning Framework for Cognitive Diagnosis</title>
      <link>http://arxiv.org/abs/2410.17564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, Accepted by NeurIPS 2024 as a poster&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有基于图学习的认知诊断方法在结果上表现良好，但在学生、习题和概念的表示学习上存在不足，导致对学生交互的噪声鲁棒性差。&lt;h4&gt;目的&lt;/h4&gt;提出一个元多图辅助的解耦图学习框架（DisenGCD），以改善学生、习题和概念的表示学习效果。&lt;h4&gt;方法&lt;/h4&gt;通过三个解耦图学习三种表示：学生-习题-概念交互图、习题-概念关系图和概念依赖图。利用元多图学习模块从交互图中学习学生表示，并通过图注意力模块在关系图和依赖图上学习习题和概念表示。&lt;h4&gt;主要发现&lt;/h4&gt;DisenGCD在性能和鲁棒性上优于现有最先进的认知诊断方法，验证了解耦学习框架和元多图模块的有效性。&lt;h4&gt;结论&lt;/h4&gt;DisenGCD框架提供了更有效和鲁棒的学生表示学习方式，改进了认知诊断的准确性和可靠性。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的DisenGCD框架显著提升了认知诊断的表现，源代码可在GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bimk/intelligent-education&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing graph learning-based cognitive diagnosis (CD) methods have maderelatively good results, but their student, exercise, and conceptrepresentations are learned and exchanged in an implicit unified graph, whichmakes the interaction-agnostic exercise and concept representations be learnedpoorly, failing to provide high robustness against noise in students'interactions. Besides, lower-order exercise latent representations obtained inshallow layers are not well explored when learning the student representation.To tackle the issues, this paper suggests a meta multigraph-assisteddisentangled graph learning framework for CD (DisenGCD), which learns threetypes of representations on three disentangled graphs: student-exercise-conceptinteraction, exercise-concept relation, and concept dependency graphs,respectively. Specifically, the latter two graphs are first disentangled fromthe interaction graph. Then, the student representation is learned from theinteraction graph by a devised meta multigraph learning module; multiplelearnable propagation paths in this module enable current student latentrepresentation to access lower-order exercise latent representations, which canlead to more effective nad robust student representations learned; the exerciseand concept representations are learned on the relation and dependency graphsby graph attention modules. Finally, a novel diagnostic function is devised tohandle three disentangled representations for prediction. Experiments showbetter performance and robustness of DisenGCD than state-of-the-art CD methodsand demonstrate the effectiveness of the disentangled learning framework andmeta multigraph module. The source code is available at\textcolor{red}{\url{https://github.com/BIMK/Intelligent-Education/tree/main/DisenGCD}}.</description>
      <author>example@mail.com (Shangshang Yang, Mingyang Chen, Ziwen Wang, Xiaoshan Yu, Panpan Zhang, Haiping Ma, Xingyi Zhang)</author>
      <guid isPermaLink="false">2410.17564v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Att2CPC: Attention-Guided Lossy Attribute Compression of Point Clouds</title>
      <link>http://arxiv.org/abs/2410.17823v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;3D传感和采集技术的进步导致点云数据量大幅增加，迫切需要高效的点云压缩方法。&lt;h4&gt;目的&lt;/h4&gt;研究学习型有损点云属性压缩（PCAC）任务。&lt;h4&gt;方法&lt;/h4&gt;提出一种基于注意力机制的高效有损点云属性压缩方法，利用自编码器架构进行编码和解码。&lt;h4&gt;主要发现&lt;/h4&gt;在编码阶段，采用多次下采样来充分利用局部属性模式，设计了有效的外部交叉注意力（ECA）来层次聚合特征。在解码阶段，基于多尺度表示和零填充上采样策略逐步重建点云属性。&lt;h4&gt;结论&lt;/h4&gt;这是首次将注意力机制引入基于点的有损PCAC任务。实验结果显示，与最先进的点基方法Deep-PCAC相比，本方法在Y通道和YUV通道的BD-PSNR上分别提高了1.15 dB和2.13 dB。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了一种新颖的点云属性压缩方法，显著提高了压缩效率，代码可在GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/i2-multimedia-lab/att2cpc&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the great progress of 3D sensing and acquisition technology, the volumeof point cloud data has grown dramatically, which urges the development ofefficient point cloud compression methods. In this paper, we focus on the taskof learned lossy point cloud attribute compression (PCAC). We propose anefficient attention-based method for lossy compression of point cloudattributes leveraging on an autoencoder architecture. Specifically, at theencoding side, we conduct multiple downsampling to best exploit the localattribute patterns, in which effective External Cross Attention (ECA) isdevised to hierarchically aggregate features by intergrating attributes andgeometry contexts. At the decoding side, the attributes of the point cloud areprogressively reconstructed based on the multi-scale representation and thezero-padding upsampling tactic. To the best of our knowledge, this is the firstapproach to introduce attention mechanism to point-based lossy PCAC task. Weverify the compression efficiency of our model on various sequences, includinghuman body frames, sparse objects, and large-scale point cloud scenes.Experiments show that our method achieves an average improvement of 1.15 dB and2.13 dB in BD-PSNR of Y channel and YUV channel, respectively, when comparingwith the state-of-the-art point-based method Deep-PCAC. Codes of this paper areavailable at https://github.com/I2-Multimedia-Lab/Att2CPC.</description>
      <author>example@mail.com (Kai Liu, Kang You, Pan Gao, Manoranjan Paul)</author>
      <guid isPermaLink="false">2410.17823v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>FedBaF: Federated Learning Aggregation Biased by a Foundation Model</title>
      <link>http://arxiv.org/abs/2410.18352v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基础模型因其在多种任务上的泛化能力而受到主要技术组织的关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，旨在动态集成预训练基础模型权重，以保护模型和信息安全。&lt;h4&gt;方法&lt;/h4&gt;引入了联邦学习聚合偏置于基础模型（FedBaF）的方法，在FL聚合阶段集成预训练基础模型权重。&lt;h4&gt;主要发现&lt;/h4&gt;FedBaF在IID条件下的测试准确率比传统权重初始化方法高出11.4%，在非IID条件下高出15.8%。&lt;h4&gt;结论&lt;/h4&gt;FedBaF不仅保留了基础模型的机密性，还在准确性上优于传统方法，并在基于Transformer的语言模型中显著降低了困惑度，最大减少达39.2%。&lt;h4&gt;总结&lt;/h4&gt;FedBaF是一种有效的联邦学习方法，能够在保护隐私的同时提升模型性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are now a major focus of leading technology organizationsdue to their ability to generalize across diverse tasks. Existing approachesfor adapting foundation models to new applications often rely on FederatedLearning (FL) and disclose the foundation model weights to clients when usingit to initialize the global model. While these methods ensure client dataprivacy, they compromise model and information security. In this paper, weintroduce Federated Learning Aggregation Biased by a Foundation Model (FedBaF),a novel method for dynamically integrating pre-trained foundation model weightsduring the FL aggregation phase. Unlike conventional methods, FedBaF preservesthe confidentiality of the foundation model while still leveraging its power totrain more accurate models, especially in non-IID and adversarial scenarios.Our comprehensive experiments use Pre-ResNet and foundation models like VisionTransformer to demonstrate that FedBaF not only matches, but often surpassesthe test accuracy of traditional weight initialization methods by up to 11.4\%in IID and up to 15.8\% in non-IID settings. Additionally, FedBaF applied to aTransformer-based language model significantly reduced perplexity by up to39.2\%.</description>
      <author>example@mail.com (Jong-Ik Park, Srinivasa Pranav, José M. F. Moura, Carlee Joe-Wong)</author>
      <guid isPermaLink="false">2410.18352v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Graph Neural Networks for Enhanced Feature Extraction in Heterogeneous Information Networks</title>
      <link>http://arxiv.org/abs/2410.17617v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着互联网的快速发展，复杂图数据的处理面临许多应用和挑战。&lt;h4&gt;目的&lt;/h4&gt;探讨图神经网络（GNN）在处理复杂图数据中的应用及其面临的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于自监督学习框架的图神经网络模型，灵活结合图及其节点的不同类型的附加信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过引入自监督机制，有望提高现有模型对图数据多样性和复杂性的适应能力。&lt;h4&gt;结论&lt;/h4&gt;改进后的模型将提升对复杂关系和模式的模拟能力，从而提高整体性能。&lt;h4&gt;总结&lt;/h4&gt;该研究为图神经网络在复杂图数据处理中的应用提供了新的思路和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper explores the applications and challenges of graph neural networks(GNNs) in processing complex graph data brought about by the rapid developmentof the Internet. Given the heterogeneity and redundancy problems that graphdata often have, traditional GNN methods may be overly dependent on the initialstructure and attribute information of the graph, which limits their ability toaccurately simulate more complex relationships and patterns in the graph.Therefore, this study proposes a graph neural network model under aself-supervised learning framework, which can flexibly combine different typesof additional information of the attribute graph and its nodes, so as to bettermine the deep features in the graph data. By introducing a self-supervisorymechanism, it is expected to improve the adaptability of existing models to thediversity and complexity of graph data and improve the overall performance ofthe model.</description>
      <author>example@mail.com (Jianjun Wei, Yue Liu, Xin Huang, Xin Zhang, Wenyi Liu, Xu Yan)</author>
      <guid isPermaLink="false">2410.17617v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Towards Active Participant-Centric Vertical Federated Learning: Some Representations May Be All You Need</title>
      <link>http://arxiv.org/abs/2410.17648v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;垂直联邦学习（VFL）可以在不同参与者之间进行协作模型训练，保护数据隐私。&lt;h4&gt;目的&lt;/h4&gt;提出一种简化的VFL方法，减少通信成本和操作复杂性。&lt;h4&gt;方法&lt;/h4&gt;引入主动参与者中心的VFL（APC-VFL），只需一次通信轮次，并允许主动参与者非协作推断。&lt;h4&gt;主要发现&lt;/h4&gt;APC-VFL结合无监督表示学习和知识蒸馏，准确性可与传统VFL方法相媲美，通信轮次减少高达4200倍。&lt;h4&gt;结论&lt;/h4&gt;APC-VFL在与非联邦本地模型和类似VFL方法（如VFedTrans）比较时，展示了更高的效率和灵活性。&lt;h4&gt;总结&lt;/h4&gt;APC-VFL提供了一种高效灵活的协作学习解决方案，适用于现实数据分区场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vertical Federated Learning (VFL) enables collaborative model training acrossdifferent participants with distinct features and common samples, whilepreserving data privacy. Existing VFL methodologies often struggle withrealistic data partitions, typically incurring high communication costs andsignificant operational complexity. In this work, we introduce a novelsimplified approach to VFL, Active Participant-Centric VFL (APC-VFL), that, tothe best of our knowledge, is the first to require only a single communicationround between participants, and allows the active participant to do inferencein a non collaborative fashion. This method integrates unsupervisedrepresentation learning with knowledge distillation to achieve comparableaccuracy to traditional VFL methods based on vertical split learning inclassical settings, reducing required communication rounds by up to$4200\times$, while being more flexible. Our approach also shows improvementscompared to non-federated local models, as well as a comparable VFL proposal,VFedTrans, offering an efficient and flexible solution for collaborativelearning.</description>
      <author>example@mail.com (Jon Irureta, Jon Imaz, Aizea Lojo, Marco González, Iñigo Perona)</author>
      <guid isPermaLink="false">2410.17648v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Two-Player Performance Through Single-Player Knowledge Transfer: An Empirical Study on Atari 2600 Games</title>
      <link>http://arxiv.org/abs/2410.16653v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;使用强化学习和自我对弈进行双人游戏训练面临挑战，尤其是双人环境的复杂性和训练过程的不稳定性。&lt;h4&gt;目的&lt;/h4&gt;提出一种强化学习算法，利用单人游戏的知识，提高双人游戏的训练效率和表现。&lt;h4&gt;方法&lt;/h4&gt;在十个不同的Atari 2600环境中，使用Atari 2600的RAM作为输入状态进行实验。&lt;h4&gt;主要发现&lt;/h4&gt;使用单人训练过程的迁移学习相比于从头开始在双人环境中训练，能够减少训练时间并提高平均总奖励。&lt;h4&gt;结论&lt;/h4&gt;迁移学习能够有效提升双人游戏中的强化学习性能，值得进一步研究。&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了单人游戏的知识如何促进双人游戏训练，并分析了RAM复杂性与性能之间的关系。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/justkim/two-player-atari-rl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Playing two-player games using reinforcement learning and self-play can bechallenging due to the complexity of two-player environments and the possibleinstability in the training process. We propose that a reinforcement learningalgorithm can train more efficiently and achieve improved performance in atwo-player game if it leverages the knowledge from the single-player version ofthe same game. This study examines the proposed idea in ten different Atari2600 environments using the Atari 2600 RAM as the input state. We discuss theadvantages of using transfer learning from a single-player training processover training in a two-player setting from scratch, and demonstrate our resultsin a few measures such as training time and average total reward. We alsodiscuss a method of calculating RAM complexity and its relationship toperformance.</description>
      <author>example@mail.com (Kimiya Saadat, Richard Zhao)</author>
      <guid isPermaLink="false">2410.16653v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Exploring structure diversity in atomic resolution microscopy with graph neural networks</title>
      <link>http://arxiv.org/abs/2410.17631v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度学习的出现为原子分辨率微观图像的高通量分析提供了重大机遇，但固定大小图像块训练的深度学习模型在处理多样化原子结构时效率和灵活性不足。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于等变图神经网络的少样本学习框架，以分析各种原子结构的库。&lt;h4&gt;方法&lt;/h4&gt;使用等变图神经网络（EGNN）进行分析，相比于传统图像驱动的深度学习模型，显著提高了鲁棒性，并将计算参数减少了三个数量级。&lt;h4&gt;主要发现&lt;/h4&gt;该框架特别适用于聚集的空位线和灵活的晶格畸变，能够批量提取原子尺度结构特征，并揭示电子束辐照下的空位线自组装动态。&lt;h4&gt;结论&lt;/h4&gt;通过整合EGNN子模型建立了一个多功能模型工具包，以任务链的形式处理包含不同配置的图像，发现了具有优越电催化性能的新型掺杂配置。&lt;h4&gt;总结&lt;/h4&gt;该研究为快速、准确和智能地探索结构多样性提供了强有力的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The emergence of deep learning (DL) has provided great opportunities for thehigh-throughput analysis of atomic-resolution micrographs. However, the DLmodels trained by image patches in fixed size generally lack efficiency andflexibility when processing micrographs containing diversified atomicconfigurations. Herein, inspired by the similarity between the atomicstructures and graphs, we describe a few-shot learning framework based on anequivariant graph neural network (EGNN) to analyze a library of atomicstructures (e.g., vacancies, phases, grain boundaries, doping, etc.), showingsignificantly promoted robustness and three orders of magnitude reducedcomputing parameters compared to the image-driven DL models, which isespecially evident for those aggregated vacancy lines with flexible latticedistortion. Besides, the intuitiveness of graphs enables quantitative andstraightforward extraction of the atomic-scale structural features in batches,thus statistically unveiling the self-assembly dynamics of vacancy lines underelectron beam irradiation. A versatile model toolkit is established byintegrating EGNN sub-models for single structure recognition to process imagesinvolving varied configurations in the form of a task chain, leading to thediscovery of novel doping configurations with superior electrocatalyticproperties for hydrogen evolution reactions. This work provides a powerful toolto explore structure diversity in a fast, accurate, and intelligent manner.</description>
      <author>example@mail.com (Zheng Luo, Ming Feng, Zijian Gao, Jinyang Yu, Liang Hu, Tao Wang, Shenao Xue, Shen Zhou, Fangping Ouyang, Dawei Feng, Kele Xu, Shanshan Wang)</author>
      <guid isPermaLink="false">2410.17631v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Position-Aided Semantic Communication for Efficient Image Transmission: Design, Implementation, and Experimental Results</title>
      <link>http://arxiv.org/abs/2410.18364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;语义通信结合知识库(KB)能显著降低传输开销并增强抗错误能力，但现有方法主要依赖端到端训练构建KB，未能充分利用通信设备的丰富信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的位置辅助语义通信(PASC)框架，集成定位信息以优化语义传输。&lt;h4&gt;方法&lt;/h4&gt;该框架特别设计用于基于位置的图像通信，利用位置信息检索相应地图，并通过先进的基础模型驱动的视图生成器合成与目标图像相似的图像。&lt;h4&gt;主要发现&lt;/h4&gt;PASC框架利用基础模型融合合成图像与真实图像的偏差，增强语义重构，且具备高度灵活性，能够适应动态内容和波动的信道条件。&lt;h4&gt;结论&lt;/h4&gt;通过开发硬件测试平台来验证框架，仿真和现实测试表明，PASC方法显著提高了传输效率，并在多样化和不断变化的传输场景中保持了稳健性。&lt;h4&gt;总结&lt;/h4&gt;PASC框架为位置基础的实时图像上传提供了一种高效、灵活的解决方案，有助于提升语义通信的实际应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic communication, augmented by knowledge bases (KBs), offerssubstantial reductions in transmission overhead and resilience to errors.However, existing methods predominantly rely on end-to-end training toconstruct KBs, often failing to fully capitalize on the rich informationavailable at communication devices. Motivated by the growing convergence ofsensing and communication, we introduce a novel Position-Aided SemanticCommunication (PASC) framework, which integrates localization into semantictransmission. This framework is particularly designed for position-based imagecommunication, such as real-time uploading of outdoor camera-view images. Byutilizing the position, the framework retrieves corresponding maps, and then anadvanced foundation model (FM)-driven view generator is employed to synthesizeimages closely resembling the target images. The PASC framework furtherleverages the FM to fuse the synthesized image with deviations from the realone, enhancing semantic reconstruction. Notably, the framework is highlyflexible, capable of adapting to dynamic content and fluctuating channelconditions through a novel FM-based parameter optimization strategy.Additionally, the challenges of real-time deployment are addressed, with thedevelopment of a hardware testbed to validate the framework. Simulations andreal-world tests demonstrate that the proposed PASC approach not onlysignificantly boosts transmission efficiency, but also remains robust indiverse and evolving transmission scenarios.</description>
      <author>example@mail.com (Peiwen Jiang, Chao-Kai Wen, Shi Jin, Jun Zhang)</author>
      <guid isPermaLink="false">2410.18364v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Electrocardiogram-Language Model for Few-Shot Question Answering with Meta Learning</title>
      <link>http://arxiv.org/abs/2410.14464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;心电图（ECG）解读需要专业知识，常常涉及将ECG信号与自然语言中复杂的临床查询结合起来。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的多模态元学习方法，用于少量样本的心电图问答，解决有限标注数据的挑战。&lt;h4&gt;方法&lt;/h4&gt;采用一种与大型语言模型（LLMs）无关的方法，将预训练的ECG编码器与冻结的LLM（如LLaMA和Gemma）通过可训练的融合模块结合。&lt;h4&gt;主要发现&lt;/h4&gt;在5-way 5-shot设置下，使用LLaMA-3.1-8B的方法在单一验证、选择和查询问题类型上分别达到了84.6%、77.3%和69.6%的准确率。&lt;h4&gt;结论&lt;/h4&gt;该方法通过结合信号处理与LLMs的语言理解能力，增强了临床心电图解读的潜力，尤其是在数据受限的情况下。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了在有限标注数据条件下，利用大型语言模型提升心电图诊断系统的有效性和适应性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electrocardiogram (ECG) interpretation requires specialized expertise, ofteninvolving synthesizing insights from ECG signals with complex clinical queriesposed in natural language. The scarcity of labeled ECG data coupled with thediverse nature of clinical inquiries presents a significant challenge fordeveloping robust and adaptable ECG diagnostic systems. This work introduces anovel multimodal meta-learning method for few-shot ECG question answering,addressing the challenge of limited labeled data while leveraging the richknowledge encoded within large language models (LLMs). Our LLM-agnosticapproach integrates a pre-trained ECG encoder with a frozen LLM (e.g., LLaMAand Gemma) via a trainable fusion module, enabling the language model to reasonabout ECG data and generate clinically meaningful answers. Extensiveexperiments demonstrate superior generalization to unseen diagnostic taskscompared to supervised baselines, achieving notable performance even withlimited ECG leads. For instance, in a 5-way 5-shot setting, our method usingLLaMA-3.1-8B achieves accuracy of 84.6%, 77.3%, and 69.6% on single verify,choose and query question types, respectively. These results highlight thepotential of our method to enhance clinical ECG interpretation by combiningsignal processing with the nuanced language understanding capabilities of LLMs,particularly in data-constrained scenarios.</description>
      <author>example@mail.com (Jialu Tang, Tong Xia, Yuan Lu, Cecilia Mascolo, Aaqib Saeed)</author>
      <guid isPermaLink="false">2410.14464v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>EntityCLIP: Entity-Centric Image-Text Matching via Multimodal Attentive Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.17810v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图像-文本匹配领域的最近进展显著，但现有模型主要适用于广泛查询，难以满足细粒度查询意图。&lt;h4&gt;目的&lt;/h4&gt;提出以实体为中心的图像-文本匹配（EITM），处理与特定实体相关的信息。&lt;h4&gt;方法&lt;/h4&gt;基于CLIP构建多模态注意对比学习框架，开发名为EntityCLIP的模型，并利用大型语言模型生成解释性文本以缩小语义差距。&lt;h4&gt;主要发现&lt;/h4&gt;通过从大型语言模型提取的解释性文本与图像和文本结合，使用多模态注意专家模块（MMAE）有效整合特征，显著提升匹配效果。&lt;h4&gt;结论&lt;/h4&gt;在N24News、VisualNews和GoodNews等三项社交媒体新闻基准上，所提方法明显优于其他竞争方法。&lt;h4&gt;总结&lt;/h4&gt;通过多模态学习和解释性文本的引入，EntityCLIP在实体中心图像-文本匹配任务中取得了显著进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in image-text matching have been notable, yet prevailingmodels predominantly cater to broad queries and struggle with accommodatingfine-grained query intention. In this paper, we work towards the\textbf{E}ntity-centric \textbf{I}mage-\textbf{T}ext \textbf{M}atching (EITM),a task that the text and image involve specific entity-related information. Thechallenge of this task mainly lies in the larger semantic gap in entityassociation modeling, comparing with the general image-text matching problem.Tonarrow the huge semantic gap between the entity-centric text and the images, wetake the fundamental CLIP as the backbone and devise a multimodal attentivecontrastive learning framework to tam CLIP to adapt EITM problem, developing amodel named EntityCLIP. The key of our multimodal attentive contrastivelearning is to generate interpretive explanation text using Large LanguageModels (LLMs) as the bridge clues. In specific, we proceed by extractingexplanatory text from off-the-shelf LLMs. This explanation text, coupled withthe image and text, is then input into our specially crafted MultimodalAttentive Experts (MMAE) module, which effectively integrates explanation textsto narrow the gap of the entity-related text and image in a shared semanticspace. Building on the enriched features derived from MMAE, we further designan effective Gated Integrative Image-text Matching (GI-ITM) strategy. TheGI-ITM employs an adaptive gating mechanism to aggregate MMAE's features,subsequently applying image-text matching constraints to steer the alignmentbetween the text and the image. Extensive experiments are conducted on threesocial media news benchmarks including N24News, VisualNews, and GoodNews, theresults shows that our method surpasses the competition methods with a clearmargin.</description>
      <author>example@mail.com (Yaxiong Wang, Yaxiong Wang, Lianwei Wu, Lechao Cheng, Zhun Zhong, Meng Wang)</author>
      <guid isPermaLink="false">2410.17810v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Proteome-wide prediction of mode of inheritance and molecular mechanism underlying genetic diseases using structural interactomics</title>
      <link>http://arxiv.org/abs/2410.17708v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;遗传疾病可以根据遗传方式和分子机制进行分类。&lt;h4&gt;目的&lt;/h4&gt;预测由常染色体基因变异引起的疾病的遗传方式，并根据功能效应对与显性相关的蛋白质进行分类。&lt;h4&gt;方法&lt;/h4&gt;采用图-图方法，利用蛋白质-蛋白质相互作用网络和高分辨率蛋白质结构，结合图神经网络、结构互作组学和拓扑网络特征。&lt;h4&gt;主要发现&lt;/h4&gt;该方法提供了全蛋白组的预测，能够识别不同遗传疾病的机制。&lt;h4&gt;结论&lt;/h4&gt;提出了一种可扩展的方法，有助于理解遗传疾病的机制。&lt;h4&gt;总结&lt;/h4&gt;本研究为遗传疾病的分类和机制理解提供了新的思路和工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Genetic diseases can be classified according to their modes of inheritanceand their underlying molecular mechanisms. Autosomal dominant disorders oftenresult from DNA variants that cause loss-of-function, gain-of-function, ordominant-negative effects, while autosomal recessive diseases are primarilylinked to loss-of-function variants. In this study, we introduce agraph-of-graphs approach that leverages protein-protein interaction networksand high-resolution protein structures to predict the mode of inheritance ofdiseases caused by variants in autosomal genes, and to classifydominant-associated proteins based on their functional effect. Our approachintegrates graph neural networks, structural interactomics and topologicalnetwork features to provide proteome-wide predictions, thus offering a scalablemethod for understanding genetic disease mechanisms.</description>
      <author>example@mail.com (Ali Saadat, Jacques Fellay)</author>
      <guid isPermaLink="false">2410.17708v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Amortized Probabilistic Conditioning for Optimization, Simulation and Inference</title>
      <link>http://arxiv.org/abs/2410.15320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 21 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于预训练的摊销元学习方法在自然语言处理和视觉等领域取得了显著进展。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的元学习模型，旨在灵活注入和提取概率潜在信息。&lt;h4&gt;方法&lt;/h4&gt;引入摊销条件引擎（ACE），一种基于Transformer的元学习模型，明确表示感兴趣的潜在变量。&lt;h4&gt;主要发现&lt;/h4&gt;ACE支持对观察数据和可解释潜在变量的条件处理，以及在运行时包含先验信息，能够输出离散和连续数据的预测分布。&lt;h4&gt;结论&lt;/h4&gt;ACE在图像补全、分类、贝叶斯优化和基于模拟的推断等多种任务中展现了建模灵活性和优越性能。&lt;h4&gt;总结&lt;/h4&gt;ACE为元学习提供了一种新的方法，增强了对潜在变量的处理能力，推动了相关任务的进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Amortized meta-learning methods based on pre-training have propelled fieldslike natural language processing and vision. Transformer-based neural processesand their variants are leading models for probabilistic meta-learning with atractable objective. Often trained on synthetic data, these models implicitlycapture essential latent information in the data-generation process. However,existing methods do not allow users to flexibly inject (condition on) andextract (predict) this probabilistic latent information at runtime, which iskey to many tasks. We introduce the Amortized Conditioning Engine (ACE), a newtransformer-based meta-learning model that explicitly represents latentvariables of interest. ACE affords conditioning on both observed data andinterpretable latent variables, the inclusion of priors at runtime, and outputspredictive distributions for discrete and continuous data and latents. We showACE's modeling flexibility and performance in diverse tasks such as imagecompletion and classification, Bayesian optimization, and simulation-basedinference.</description>
      <author>example@mail.com (Paul E. Chang, Nasrulloh Loka, Daolang Huang, Ulpu Remes, Samuel Kaski, Luigi Acerbi)</author>
      <guid isPermaLink="false">2410.15320v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>HeightFormer: A Semantic Alignment Monocular 3D Object Detection Method from Roadside Perspective</title>
      <link>http://arxiv.org/abs/2410.07758v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;车载3D物体检测技术是自动驾驶的重要技术，但关于路边传感器在3D交通物体检测中的应用研究较少。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的3D物体检测框架，以增强基于高度估计的2D到3D投影。&lt;h4&gt;方法&lt;/h4&gt;集成Spatial Former和Voxel Pooling Former，进行高度估计和特征提取。&lt;h4&gt;主要发现&lt;/h4&gt;在Rope3D和DAIR-V2X-I数据集上进行的广泛实验表明，所提算法在车辆和骑行者检测中表现优异。&lt;h4&gt;结论&lt;/h4&gt;提高路边3D物体检测的准确性有助于构建安全可靠的智能交通系统，促进自动驾驶的广泛应用。&lt;h4&gt;代码和模型&lt;/h4&gt;代码和预训练模型将在https://anonymous.4open.science/r/HeightFormer发布。&lt;h4&gt;总结&lt;/h4&gt;该研究为3D物体检测提供了新的方法，具有较强的鲁棒性和广泛的适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The on-board 3D object detection technology has received extensive attentionas a critical technology for autonomous driving, while few studies have focusedon applying roadside sensors in 3D traffic object detection. Existing studiesachieve the projection of 2D image features to 3D features through heightestimation based on the frustum. However, they did not consider the heightalignment and the extraction efficiency of bird's-eye-view features. We proposea novel 3D object detection framework integrating Spatial Former and VoxelPooling Former to enhance 2D-to-3D projection based on height estimation.Extensive experiments were conducted using the Rope3D and DAIR-V2X-I dataset,and the results demonstrated the outperformance of the proposed algorithm inthe detection of both vehicles and cyclists. These results indicate that thealgorithm is robust and generalized under various detection scenarios.Improving the accuracy of 3D object detection on the roadside is conducive tobuilding a safe and trustworthy intelligent transportation system ofvehicle-road coordination and promoting the large-scale application ofautonomous driving. The code and pre-trained models will be released onhttps://anonymous.4open.science/r/HeightFormer.</description>
      <author>example@mail.com (Pei Liu, Zihao Zhang, Haipeng Liu, Nanfang Zheng, Meixin Zhu, Ziyuan Pu)</author>
      <guid isPermaLink="false">2410.07758v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis</title>
      <link>http://arxiv.org/abs/2410.18822v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024. Project page:
  https://hanl2010.github.io/Binocular3DGS/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从稀疏输入合成新视角是3D计算机视觉中的一个重要而具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过高斯喷洒技术从稀疏视角合成新视角，而无需外部先验作为监督。&lt;h4&gt;方法&lt;/h4&gt;利用双目图像之间的自我监督，并引入高斯不透明度约束来正则化高斯位置，避免高斯冗余，提高从稀疏视角推断3D高斯的稳健性和效率。&lt;h4&gt;主要发现&lt;/h4&gt;在LLFF、DTU和Blender数据集上的广泛实验表明，该方法显著优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;该方法在质量和效率上表现出色，解决了从稀疏输入合成新视角的挑战。&lt;h4&gt;总结&lt;/h4&gt;通过探索自我监督和引入新约束，本研究提供了一种高效的3D视角合成方法，推动了该领域的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Novel view synthesis from sparse inputs is a vital yet challenging task in 3Dcomputer vision. Previous methods explore 3D Gaussian Splatting with neuralpriors (e.g. depth priors) as an additional supervision, demonstratingpromising quality and efficiency compared to the NeRF based methods. However,the neural priors from 2D pretrained models are often noisy and blurry, whichstruggle to precisely guide the learning of radiance fields. In this paper, Wepropose a novel method for synthesizing novel views from sparse views withGaussian Splatting that does not require external prior as supervision. Our keyidea lies in exploring the self-supervisions inherent in the binocular stereoconsistency between each pair of binocular images constructed withdisparity-guided image warping. To this end, we additionally introduce aGaussian opacity constraint which regularizes the Gaussian locations and avoidsGaussian redundancy for improving the robustness and efficiency of inferring 3DGaussians from sparse views. Extensive experiments on the LLFF, DTU, andBlender datasets demonstrate that our method significantly outperforms thestate-of-the-art methods.</description>
      <author>example@mail.com (Liang Han, Junsheng Zhou, Yu-Shen Liu, Zhizhong Han)</author>
      <guid isPermaLink="false">2410.18822v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>TopoQA: a topological deep learning-based approach for protein complex structure interface quality assessment</title>
      <link>http://arxiv.org/abs/2410.17815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;尽管AlphaFold-Multimer和AlphaFold3在蛋白质复合体结构预测上取得了显著进展，但其准确性仍不及单体结构预测。&lt;h4&gt;目的&lt;/h4&gt;开发有效的质量评估模型，以评估预测的蛋白质复合体的质量，而无需了解其真实结构。&lt;h4&gt;方法&lt;/h4&gt;利用持久同调捕捉残基周围的原子级拓扑信息，设计基于拓扑深度学习的质量评估方法TopoQA，并将其与图神经网络结合。&lt;h4&gt;主要发现&lt;/h4&gt;TopoQA在DBM55-AF2和HAF2数据集上表现优于AF-Multimer基础的AF2Rank，并在近一半目标上超过AF3。&lt;h4&gt;结论&lt;/h4&gt;TopoQA在DBM55-AF2数据集上实现了比AF-Multimer基础的AF2Rank低73.6%的排名损失，并在多项比较中表现出最高的Top 10命中率和最低的排名损失。&lt;h4&gt;总结&lt;/h4&gt;TopoQA显著提升了模型性能，为蛋白质结构表示学习提供了新的范式。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Even with the significant advances of AlphaFold-Multimer (AF-Multimer) andAlphaFold3 (AF3) in protein complex structure prediction, their accuracy isstill not comparable with monomer structure prediction. Efficient qualityassessment (QA) or estimation of model accuracy (EMA) models that can evaluatethe quality of the predicted protein-complexes without knowing their nativestructures, are of key importance for protein structure generation and modelselection. In this paper, we leverage persistent homology (PH) to capture theatomic-level topological information around residues and design a topologicaldeep learning-based QA method, TopoQA, to assess the accuracy of proteincomplex interfaces. We integrate PH from topological data analysis into graphneural networks (GNNs) to characterize complex higher-order structures thatGNNs might overlook, enhancing the learning of the relationship between thetopological structure of complex interfaces and quality scores. Our TopoQAmodel is extensively validated based on the two most-widely used datasets,DBM55-AF2 and HAF2, along with our newly constructed ABAG-AF3 dataset tofacilitate comparisons with AF3. For all three datasets, TopoQA outperformsAF-Multimer-based AF2Rank and shows an advantage over AF3 in nearly half of thetargets. In particular, in the DBM55-AF2 dataset, a ranking loss of 73.6% lowerthan AF-Multimer-based AF2Rank is obtained. Further, other than AF-Multimer andAF3, we have also extensively compared with nearly-all the state-of-the-artmodels (as far as we know), it has been found that our TopoQA can achieve thehighest Top 10 Hit-rate on the DBM55-AF2 dataset and the lowest ranking loss onthe HAF2 dataset. Ablation experiments show that our topological featuressignificantly improve the model performance. At the same time, our method alsoprovides a new paradigm for protein structure representation learning.</description>
      <author>example@mail.com (Bingqing Han, Yipeng Zhang, Longlong Li, Xinqi Gong, Kelin Xia)</author>
      <guid isPermaLink="false">2410.17815v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>SSMT: Few-Shot Traffic Forecasting with Single Source Meta-Transfer</title>
      <link>http://arxiv.org/abs/2410.15589v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICPR 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;智能交通系统（ITS）中的交通预测对智能交通预测至关重要，但某些城市缺乏必要的智能设备和基础设施。&lt;h4&gt;目的&lt;/h4&gt;提出一种仅依赖单一来源城市进行交通预测的方法，以解决数据稀缺城市的预测问题。&lt;h4&gt;方法&lt;/h4&gt;引入单源元迁移学习（SSMT），使用记忆增强注意力来存储和回忆源城市的异构空间知识，并扩展正弦位置编码以建立元学习任务。&lt;h4&gt;主要发现&lt;/h4&gt;在五个真实世界基准数据集上的实验表明，该方法在时间序列交通预测中优于多种现有方法。&lt;h4&gt;结论&lt;/h4&gt;SSMT有效地利用单一来源城市的数据，能够实现少量样本的交通预测，适用于数据稀缺的目标城市。&lt;h4&gt;总结&lt;/h4&gt;本研究为解决智能交通预测中的数据稀缺问题提供了一种新颖的方法，具有良好的实用性和效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traffic forecasting in Intelligent Transportation Systems (ITS) is vital forintelligent traffic prediction. Yet, ITS often relies on data from trafficsensors or vehicle devices, where certain cities might not have all those smartdevices or enabling infrastructures. Also, recent studies have employedmeta-learning to generalize spatial-temporal traffic networks, utilizing datafrom multiple cities for effective traffic forecasting for data-scarce targetcities. However, collecting data from multiple cities can be costly andtime-consuming. To tackle this challenge, we introduce Single SourceMeta-Transfer Learning (SSMT) which relies only on a single source city fortraffic prediction. Our method harnesses this transferred knowledge to enablefew-shot traffic forecasting, particularly when the target city possesseslimited data. Specifically, we use memory-augmented attention to store theheterogeneous spatial knowledge from the source city and selectively recallthem for the data-scarce target city. We extend the idea of sinusoidalpositional encoding to establish meta-learning tasks by leveraging diversetemporal traffic patterns from the source city. Moreover, to capture a moregeneralized representation of the positions we introduced a meta-positionalencoding that learns the most optimal representation of the temporal patternacross all the tasks. We experiment on five real-world benchmark datasets todemonstrate that our method outperforms several existing methods in time seriestraffic prediction.</description>
      <author>example@mail.com (Kishor Kumar Bhaumik, Minha Kim, Fahim Faisal Niloy, Amin Ahsan Ali, Simon S. Woo)</author>
      <guid isPermaLink="false">2410.15589v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Gaussian Process Distance Fields Obstacle and Ground Constraints for Safe Navigation</title>
      <link>http://arxiv.org/abs/2410.17831v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在杂乱环境中导航对任何移动系统来说都是一项挑战，现有方法主要集中于小型轮式机器人，这些机器人在悬垂障碍物面前面临最小限制，但无法处理台阶等问题，导致问题基本上是二维的。&lt;h4&gt;目的&lt;/h4&gt;提出一个适用于任何地面移动机器人（无论是轮式还是腿式）以及人类辅助的安全导航方法。&lt;h4&gt;方法&lt;/h4&gt;结合定制的场景表示和先进的轨迹优化算法，使用3D点云和地面与非地面点的分割，构建两个高斯过程距离场，以确保无碰撞路径并维持与地面的距离约束。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能有效处理不平坦地形、台阶和悬垂物体，通过创新使用四叉树结构，构建自由空间的多分辨率地图及其连通性图。&lt;h4&gt;结论&lt;/h4&gt;通过对合成和真实世界数据集的评估，证明该方法能够提供安全、平滑的路径，适应各种地面移动系统。&lt;h4&gt;总结&lt;/h4&gt;本文提出的3D导航方法为地面移动机器人提供了更高效的导航解决方案，克服了传统方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Navigating cluttered environments is a challenging task for any mobilesystem. Existing approaches for ground-based mobile systems primarily focus onsmall wheeled robots, which face minimal constraints with overhanging obstaclesand cannot manage steps or stairs, making the problem effectively 2D. However,navigation for legged robots (or even humans) has to consider an extradimension. This paper proposes a tailored scene representation coupled with anadvanced trajectory optimisation algorithm to enable safe navigation. Our 3Dnavigation approach is suitable for any ground-based mobile robot, whetherwheeled or legged, as well as for human assistance. Given a 3D point cloud ofthe scene and the segmentation of the ground and non-ground points, weformulate two Gaussian Process distance fields to ensure a collision-free pathand maintain distance to the ground constraints. Our method adeptly handlesuneven terrain, steps, and overhanging objects through an innovative use of aquadtree structure, constructing a multi-resolution map of the free space andits connectivity graph based on a 2D projection of the relevant scene.Evaluations with both synthetic and real-world datasets demonstrate that thisapproach provides safe and smooth paths, accommodating a wide range ofground-based mobile systems.</description>
      <author>example@mail.com (Monisha Mushtary Uttsha, Cedric Le Gentil, Lan Wu, Teresa Vidal-Calleja)</author>
      <guid isPermaLink="false">2410.17831v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking Positive Pairs in Contrastive Learning</title>
      <link>http://arxiv.org/abs/2410.18200v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习是一种流行的表征学习方法，通常假设正样本对是紧密相关的样本，而负样本对是不同的样本。&lt;h4&gt;目的&lt;/h4&gt;挑战传统假设，提出从任意样本对中学习的框架，使任何样本对都可以视为正样本。&lt;h4&gt;方法&lt;/h4&gt;提出特征过滤器，通过门向量选择性地激活或去激活维度，以创建必要的子空间，并在传统对比学习机制中通过梯度下降进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;在IN1K数据集上验证了该方法，尽管样本对大多数是不同的，Hydra在这一挑战性设置下表现优异。&lt;h4&gt;结论&lt;/h4&gt;该方法能够防止维度崩溃，发现类别关系，强调了从任意样本对中学习共同特征的价值，可能扩展对比学习技术在弱关系样本对的适用性。&lt;h4&gt;总结&lt;/h4&gt;Hydra是一个通用的对比学习框架，能够处理任意样本对，提升了对比学习在视觉表征中的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning, a prominent approach to representation learning,traditionally assumes positive pairs are closely related samples (the sameimage or class) and negative pairs are distinct samples. We challenge thisassumption by proposing to learn from arbitrary pairs, allowing any pair ofsamples to be positive within our framework.The primary challenge of theproposed approach lies in applying contrastive learning to disparate pairswhich are semantically distant. Motivated by the discovery that SimCLR canseparate given arbitrary pairs (e.g., garter snake and table lamp) in asubspace, we propose a feature filter in the condition of class pairs thatcreates the requisite subspaces by gate vectors selectively activating ordeactivating dimensions. This filter can be optimized through gradient descentwithin a conventional contrastive learning mechanism.  We present Hydra, a universal contrastive learning framework for visualrepresentations that extends conventional contrastive learning to accommodatearbitrary pairs. Our approach is validated using IN1K, where 1K diverse classescompose 500,500 pairs, most of them being distinct. Surprisingly, Hydraachieves superior performance in this challenging setting. Additional benefitsinclude the prevention of dimensional collapse and the discovery of classrelationships. Our work highlights the value of learning common features ofarbitrary pairs and potentially broadens the applicability of contrastivelearning techniques on the sample pairs with weak relationships.</description>
      <author>example@mail.com (Jiantao Wu, Shentong Mo, Zhenhua Feng, Sara Atito, Josef Kitler, Muhammad Awais)</author>
      <guid isPermaLink="false">2410.18200v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>A class of kernel-based scalable algorithms for data science</title>
      <link>http://arxiv.org/abs/2410.14323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;RKHS（再生核希尔伯特空间）方法论在数据科学、统计和科学计算中被广泛应用，能够产生高效和稳健的算法。&lt;h4&gt;目的&lt;/h4&gt;提出可扩展的生成和预测算法，解决标准实现难以处理大数据集的问题。&lt;h4&gt;方法&lt;/h4&gt;引入一种简单而稳健的分治方法，适用于大规模数据集，依赖于适当公式化的基于核的算法，并区分外推、插值和最优传输步骤。&lt;h4&gt;主要发现&lt;/h4&gt;通过性能标准的反馈，选择特定应用中的最佳算法，解决工业应用中的挑战性问题，例如高效数值模拟的网格生成、条件分布生成器的设计和统计或随机应用的转移概率矩阵。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法适用于监督学习、无监督学习、生成方法和强化学习，对人工智能社区的多种任务具有重要意义。&lt;h4&gt;总结&lt;/h4&gt;研究展示了RKHS基于方法论的算法在处理大规模数据集中的有效性，强调了其在多种应用中的广泛适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present several generative and predictive algorithms based on the RKHS(reproducing kernel Hilbert spaces) methodology, which most importantly arescalable in the following sense. It is well recognized that the RKHSmethodology leads one to efficient and robust algorithms for numerous tasks indata science, statistics, and scientific computations.However, the standardimplementations remain difficult to scale to encompass large data sets. In thispaper, we introduce a simple and robust, divide-and-conquer approach whichapplies to large scale data sets and relies on suitably formulated,kernel-based algorithms: we distinguish between extrapolation, interpolation,and optimal transport steps. We explain how to select the best algorithms inspecific applications thanks to some feedback, mainly consisting of perfomancecriteria. Our main focus for the applications and challenging problems arisingin industrial applications, such as the generation of mesh for efficientnumerical simulations, the design of generators of conditional distributions,the transition probability matrix for statistic or stochastic applications, aswell as various tasks of interest to the artificial intelligence community.Indeed, the proposed algorithms are relevant for supervised or unsupervisedlearning, generative methods, and reinforcement learning.</description>
      <author>example@mail.com (Philippe G. LeFloch, Jean-Marc Mercier, Shohruh Miryusupov)</author>
      <guid isPermaLink="false">2410.14323v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Spiking Graph Neural Network on Riemannian Manifolds</title>
      <link>http://arxiv.org/abs/2410.17941v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS 2024, 30 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）已成为学习图结构的主要解决方案，但传统GNNs在计算和能耗上存在较高成本。&lt;h4&gt;目的&lt;/h4&gt;探索在黎曼流形上的脉冲图神经网络（Spiking GNN），以提高能效并解决传统方法的局限。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于黎曼流形的新型脉冲图神经网络（MSG），设计了适用于测地完全流形的新型脉冲神经元，采用流形微分替代时间反向传播。&lt;h4&gt;主要发现&lt;/h4&gt;MSG在常见图上进行的广泛实验表明，其性能优于之前的脉冲GNNs，并在能效上超越传统GNNs。&lt;h4&gt;结论&lt;/h4&gt;MSG有效解决了流形几何结构的考虑，提升了脉冲图神经网络的性能和能效。&lt;h4&gt;总结&lt;/h4&gt;该研究为脉冲图神经网络的发展提供了新的思路，结合了流形理论以优化图学习过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have become the dominant solution for learningon graphs, the typical non-Euclidean structures. Conventional GNNs, constructedwith the Artificial Neuron Network (ANN), have achieved impressive performanceat the cost of high computation and energy consumption. In parallel, spikingGNNs with brain-like spiking neurons are drawing increasing research attentionowing to the energy efficiency. So far, existing spiking GNNs consider graphsin Euclidean space, ignoring the structural geometry, and suffer from the highlatency issue due to Back-Propagation-Through-Time (BPTT) with the surrogategradient. In light of the aforementioned issues, we are devoted to exploringspiking GNN on Riemannian manifolds, and present a Manifold-valued Spiking GNN(MSG). In particular, we design a new spiking neuron on geodesically completemanifolds with the diffeomorphism, so that BPTT regarding the spikes isreplaced by the proposed differentiation via manifold. Theoretically, we showthat MSG approximates a solver of the manifold ordinary differential equation.Extensive experiments on common graphs show the proposed MSG achieves superiorperformance to previous spiking GNNs and energy efficiency to conventionalGNNs.</description>
      <author>example@mail.com (Li Sun, Zhenhao Huang, Qiqi Wan, Hao Peng, Philip S. Yu)</author>
      <guid isPermaLink="false">2410.17941v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Integrated Image-Text Based on Semi-supervised Learning for Small Sample Instance Segmentation</title>
      <link>http://arxiv.org/abs/2410.16063v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;小样本实例分割是一项非常具有挑战性的任务，现有许多方法采用元学习的训练策略，在支持集上预训练模型，并在查询集上进行微调。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的小样本实例分割解决方案，旨在最大化现有信息的利用，同时不增加标注负担和训练成本。&lt;h4&gt;方法&lt;/h4&gt;设计两个模块来解决小样本实例分割中遇到的问题：一是通过学习生成伪标签充分利用未标记数据，增加可用样本数量；二是通过整合文本和图像特征，获得更准确的分类结果。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，整合图像-文本特征可以校正分类置信度，而伪标签帮助模型获得更精确的掩膜。&lt;h4&gt;结论&lt;/h4&gt;所提方法不仅提高了小样本实例分割的性能，还大大减少了对预训练的依赖。&lt;h4&gt;总结&lt;/h4&gt;在陆地、水下和显微镜下的三个不同场景的数据集上进行的实验证实了该方法的有效性和优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small sample instance segmentation is a very challenging task, and manyexisting methods follow the training strategy of meta-learning which pre-trainmodels on support set and fine-tune on query set. The pre-training phase, whichis highly task related, requires a significant amount of additional trainingtime and the selection of datasets with close proximity to ensureeffectiveness. The article proposes a novel small sample instance segmentationsolution from the perspective of maximizing the utilization of existinginformation without increasing annotation burden and training costs. Theproposed method designs two modules to address the problems encountered insmall sample instance segmentation. First, it helps the model fully utilizeunlabeled data by learning to generate pseudo labels, increasing the number ofavailable samples. Second, by integrating the features of text and image, moreaccurate classification results can be obtained. These two modules are suitablefor box-free and box-dependent frameworks. In the way, the proposed method notonly improves the performance of small sample instance segmentation, but alsogreatly reduce reliance on pre-training. We have conducted experiments in threedatasets from different scenes: on land, underwater and under microscope. Asevidenced by our experiments, integrated image-text corrects the confidence ofclassification, and pseudo labels help the model obtain preciser masks. All theresults demonstrate the effectiveness and superiority of our method.</description>
      <author>example@mail.com (Ruting Chi, Zhiyi Huang, Yuexing Han)</author>
      <guid isPermaLink="false">2410.16063v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>A Pipeline for Segmenting and Structuring RGB-D Data for Robotics Applications</title>
      <link>http://arxiv.org/abs/2410.17988v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现有的RGB-D数据处理流程主要集中在提取几何信息上。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的管道，以实现对RGB-D数据的分割和结构化。&lt;h4&gt;方法&lt;/h4&gt;该管道能够将RGB-D数据分割成准确的语义掩码，并将原始捕获的点云融合成语义分离的点云。&lt;h4&gt;主要发现&lt;/h4&gt;使用Universal Scene Description (USD)文件格式存储信息，方便后续机器人的查询和可视化。&lt;h4&gt;结论&lt;/h4&gt;这种方法有助于更先进的机器人导航和操作算法的发展，增强了对环境的语义理解。&lt;h4&gt;总结&lt;/h4&gt;提出的管道能够提高RGB-D数据的处理效率，使其在机器人领域的应用更加广泛。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a novel pipeline for segmenting and structuring color and depth(RGB-D) data. Existing processing pipelines for RGB-D data have focused onextracting geometric information alone. This approach precludes the developmentof more advanced robotic navigation and manipulation algorithms, which benefitfrom a semantic understanding of their environment. Our pipeline can segmentRGB-D data into accurate semantic masks. These masks are then used to fuse rawcaptured point clouds into semantically separated point clouds. We store thisinformation using the Universal Scene Description (USD) file format, a formatsuitable for easy querying by downstream robotics algorithms, human-friendlyvisualization, and robotics simulation.</description>
      <author>example@mail.com (Zhiwu Zheng, Lauren Mentzer, Berk Iskender, Michael Price, Colm Prendergast, Audren Cloitre)</author>
      <guid isPermaLink="false">2410.17988v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction</title>
      <link>http://arxiv.org/abs/2410.18481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to EMNLP 2024 main conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;从未标注的对话中有效推导结构化工作流仍是一项未被充分探索的挑战。&lt;h4&gt;目的&lt;/h4&gt;实现对话到工作流的自动化转换，以加速新领域的手动工作流设计。&lt;h4&gt;方法&lt;/h4&gt;引入Dialog2Flow (D2F) 嵌入，通过将发言映射到一个潜在空间，根据其交际和信息功能进行分组。通过聚类D2F嵌入，将对话转换为区域/动作ID序列。&lt;h4&gt;主要发现&lt;/h4&gt;D2F在不同领域中相比于传统句子嵌入，展示了更优质的定性和定量结果。&lt;h4&gt;结论&lt;/h4&gt;D2F的预训练方法和新的软对比损失有效地提升了表示学习过程的性能。&lt;h4&gt;总结&lt;/h4&gt;D2F嵌入为对话建模提供了新的视角，促进了对话与结构化工作流的转换。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficiently deriving structured workflows from unannotated dialogs remains anunderexplored and formidable challenge in computational linguistics. Automatingthis process could significantly accelerate the manual design of workflows innew domains and enable the grounding of large language models indomain-specific flowcharts, enhancing transparency and controllability. In thispaper, we introduce Dialog2Flow (D2F) embeddings, which differ fromconventional sentence embeddings by mapping utterances to a latent space wherethey are grouped according to their communicative and informative functions(i.e., the actions they represent). D2F allows for modeling dialogs ascontinuous trajectories in a latent space with distinct action-related regions.By clustering D2F embeddings, the latent space is quantized, and dialogs can beconverted into sequences of region/action IDs, facilitating the extraction ofthe underlying workflow. To pre-train D2F, we build a comprehensive dataset byunifying twenty task-oriented dialog datasets with normalized per-turn actionannotations. We also introduce a novel soft contrastive loss that leverages thesemantic information of these actions to guide the representation learningprocess, showing superior performance compared to standard supervisedcontrastive loss. Evaluation against various sentence embeddings, includingdialog-specific ones, demonstrates that D2F yields superior qualitative andquantitative results across diverse domains.</description>
      <author>example@mail.com (Sergio Burdisso, Srikanth Madikeri, Petr Motlicek)</author>
      <guid isPermaLink="false">2410.18481v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Development of CNN Architectures using Transfer Learning Methods for Medical Image Classification</title>
      <link>http://arxiv.org/abs/2410.16711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，基于深度学习的架构应用取得了显著增长，尤其是在医疗图像分类领域。&lt;h4&gt;目的&lt;/h4&gt;研究利用迁移学习技术发展卷积神经网络(CNN)架构，以解决医疗图像分类中的关键挑战。&lt;h4&gt;方法&lt;/h4&gt;采用时间线映射模型来分析和改进医疗图像分类与分割中的CNN架构。&lt;h4&gt;主要发现&lt;/h4&gt;研究结果有助于在选择最佳和最先进的CNN架构时做出明智的决策。&lt;h4&gt;结论&lt;/h4&gt;迁移学习成为提高深度学习模型效率和准确性的一个重要工具。&lt;h4&gt;总结&lt;/h4&gt;本论文探讨了深度学习在医疗图像分类中的应用，特别是通过迁移学习提升CNN性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The application of deep learning-based architecture has seen a tremendousrise in recent years. For example, medical image classification using deeplearning achieved breakthrough results. Convolutional Neural Networks (CNNs)are implemented predominantly in medical image classification and segmentation.On the other hand, transfer learning has emerged as a prominent supporting toolfor enhancing the efficiency and accuracy of deep learning models. This paperinvestigates the development of CNN architectures using transfer learningtechniques in the field of medical image classification using a timelinemapping model for key image classification challenges. Our findings help makean informed decision while selecting the optimum and state-of-the-art CNNarchitectures.</description>
      <author>example@mail.com (Ganga Prasad Basyal, David Zeng, Bhaskar Pm Rimal)</author>
      <guid isPermaLink="false">2410.16711v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Generalized Multimodal Fusion via Poisson-Nernst-Planck Equation</title>
      <link>http://arxiv.org/abs/2410.15475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  NeurIPS 2024 Rejected paper, 28 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;以往研究强调了多模态融合的重要进展，但存在特征提取效能、数据完整性、特征维度一致性和适应性等挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种通过泊松-纳恩斯特-普朗克（PNP）方程的通用多模态融合方法（GMF），解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;理论上，通过整合信息熵和梯度反向流动，重新定义传统多模态任务的优化目标，并应用PNP方程进行特征融合，借助物理中带电粒子的框架进行重新思考和控制特征的运动。&lt;h4&gt;主要发现&lt;/h4&gt;GMF将通过单模态特征提取器提取的特征分解为模态特定和模态不变的子空间，降低互信息和下游任务的熵。&lt;h4&gt;结论&lt;/h4&gt;特征来源的可识别性使得该方法可以独立作为前端，与简单的拼接后端无缝集成，或作为其他模块的前提条件。实验结果表明，GMF在多个下游任务中性能接近最先进水平（SOTA），且使用更少的参数和计算资源。&lt;h4&gt;总结&lt;/h4&gt;通过将GMF与先进的融合方法结合，我们超越了SOTA结果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Previous studies have highlighted significant advancements in multimodalfusion. Nevertheless, such methods often encounter challenges regarding theefficacy of feature extraction, data integrity, consistency of featuredimensions, and adaptability across various downstream tasks. This paperproposes a generalized multimodal fusion method (GMF) via thePoisson-Nernst-Planck (PNP) equation, which adeptly addresses theaforementioned issues. Theoretically, the optimization objective fortraditional multimodal tasks is formulated and redefined by integratinginformation entropy and the flow of gradient backward step. Leveraging thesetheoretical insights, the PNP equation is applied to feature fusion, rethinkingmultimodal features through the framework of charged particles in physics andcontrolling their movement through dissociation, concentration, andreconstruction. Building on these theoretical foundations, GMF disassociatedfeatures which extracted by the unimodal feature extractor intomodality-specific and modality-invariant subspaces, thereby reducing mutualinformation and subsequently lowering the entropy of downstream tasks. Theidentifiability of the feature's origin enables our approach to functionindependently as a frontend, seamlessly integrated with a simple concatenationbackend, or serve as a prerequisite for other modules. Experimental results onmultiple downstream tasks show that the proposed GMF achieves performance closeto the state-of-the-art (SOTA) accuracy while utilizing fewer parameters andcomputational resources. Furthermore, by integrating GMF with advanced fusionmethods, we surpass the SOTA results.</description>
      <author>example@mail.com (Jiayu Xiong, Jing Wang, Hengjing Xiang, Jun Xue, Chen Xu, Zhouqiang Jiang)</author>
      <guid isPermaLink="false">2410.15475v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration</title>
      <link>http://arxiv.org/abs/2410.18032v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图在现实场景中广泛用于建模关系数据，如社交网络和城市计算。&lt;h4&gt;目的&lt;/h4&gt;解决现有基于大型语言模型（LLM）的图分析方法的局限性，提高性能。&lt;h4&gt;方法&lt;/h4&gt;提出一个基于LLM的多智能体系统GraphTeam，模拟人类问题解决策略，包括类比和协作。&lt;h4&gt;主要发现&lt;/h4&gt;GraphTeam在六个图分析基准上的实验结果显示，平均准确率比最佳基线提高了25.85%。&lt;h4&gt;结论&lt;/h4&gt;GraphTeam在图分析任务中达到了最先进的性能，代码和数据可在GitHub上获取。&lt;h4&gt;总结&lt;/h4&gt;本研究通过多智能体协作和外部知识利用，提升了图分析的效果和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/bupt-gamma/graphteam&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graphs are widely used for modeling relational data in real-world scenarios,such as social networks and urban computing. Existing LLM-based graph analysisapproaches either integrate graph neural networks (GNNs) for specific machinelearning tasks, limiting their transferability, or rely solely on LLMs'internal reasoning ability, resulting in suboptimal performance. To addressthese limitations, we take advantage of recent advances in LLM-based agents,which have shown capabilities of utilizing external knowledge or tools forproblem solving. By simulating human problem-solving strategies such as analogyand collaboration, we propose a multi-agent system based on LLMs namedGraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents fromthree modules, and the agents with different specialities can collaborate witheach other to address complex problems. Specifically, (1) input-outputnormalization module: the question agent extracts and refines four keyarguments from the original question, facilitating the problem understanding,and the answer agent organizes the results to meet the output requirement; (2)external knowledge retrieval module: we first build a knowledge base consistingof relevant documentation and experience information, and then the search agentretrieves the most relevant entries for each question. (3) problem-solvingmodule: given the retrieved information from search agent, the coding agentuses established algorithms via programming to generate solutions, and in casethe coding agent does not work, the reasoning agent will directly compute theresults without programming. Extensive experiments on six graph analysisbenchmarks demonstrate that GraphTeam achieves state-of-the-art performancewith an average 25.85% improvement over the best baseline in terms of accuracy.The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.</description>
      <author>example@mail.com (Xin Li, Qizhi Chu, Yubin Chen, Yang Liu, Yaoqi Liu, Zekai Yu, Weize Chen, Chen Qian, Chuan Shi, Cheng Yang)</author>
      <guid isPermaLink="false">2410.18032v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Understanding Transfer Learning via Mean-field Analysis</title>
      <link>http://arxiv.org/abs/2410.17128v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "研究转移学习中的泛化误差，采用概率测度上的微积分视角。",
    "目的": "探讨不同转移学习场景下的泛化误差与人口风险收敛速率。",
    "方法": "考虑两个主要的转移学习场景：$\alpha$-ERM和带有KL正则化的经验风险最小化。",
    "主要发现": "在适当的可积性和正则性假设下，使用单隐层神经网络的转移学习在均场范围内具有优势。",
    "结论": "确定了转移学习的泛化误差和人口风险收敛速率的通用条件。",
    "总结": "本研究为理解转移学习的理论基础提供了新的框架和见解。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose a novel framework for exploring generalization errors of transferlearning through the lens of differential calculus on the space of probabilitymeasures. In particular, we consider two main transfer learning scenarios,$\alpha$-ERM and fine-tuning with the KL-regularized empirical riskminimization and establish generic conditions under which the generalizationerror and the population risk convergence rates for these scenarios arestudied. Based on our theoretical results, we show the benefits of transferlearning with a one-hidden-layer neural network in the mean-field regime undersome suitable integrability and regularity assumptions on the loss andactivation functions.</description>
      <author>example@mail.com (Gholamali Aminian, Łukasz Szpruch, Samuel N. Cohen)</author>
      <guid isPermaLink="false">2410.17128v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>A contrastive-learning approach for auditory attention detection</title>
      <link>http://arxiv.org/abs/2410.18395v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在多声音环境中进行对话是一项具有挑战性的任务，因为声音在时间和频率上重叠，使得理解单一声源变得困难。&lt;h4&gt;目的&lt;/h4&gt;提出一种通过解码脑电图（EEG）来识别注意音源的方法，以帮助隔离所关注的语音信号。&lt;h4&gt;方法&lt;/h4&gt;采用自监督学习的方法，最小化所关注语音信号与相应EEG信号的潜在表示之间的差异，并针对听觉注意分类任务进一步微调网络。&lt;h4&gt;主要发现&lt;/h4&gt;与先前公布的方法相比，所提方法在验证集上达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;自监督学习能够有效处理有限数据的情况，为多声音环境中的语音信号隔离提供了更稳健的解决方案。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了利用自监督学习改进EEG解码的方法，解决了多声音环境中注意力定位的问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Carrying conversations in multi-sound environments is one of the morechallenging tasks, since the sounds overlap across time and frequency making itdifficult to understand a single sound source. One proposed approach to helpisolate an attended speech source is through decoding the electroencephalogram(EEG) and identifying the attended audio source using statistical or machinelearning techniques. However, the limited amount of data in comparison to othermachine learning problems and the distributional shift between different EEGrecordings emphasizes the need for a self supervised approach that works withlimited data to achieve a more robust solution. In this paper, we propose amethod based on self supervised learning to minimize the difference between thelatent representations of an attended speech signal and the corresponding EEGsignal. This network is further finetuned for the auditory attentionclassification task. We compare our results with previously published methodsand achieve state-of-the-art performance on the validation set.</description>
      <author>example@mail.com (Seyed Ali Alavi Bajestan, Mark Pitt, Donald S. Williamson)</author>
      <guid isPermaLink="false">2410.18395v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Learning for Embryo Viability Prediction in Clinical IVF</title>
      <link>http://arxiv.org/abs/2410.15581v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to MICCAI 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在临床体外受精（IVF）中，识别最具生命力的胚胎对于提高成功怀孕的可能性至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个多模态模型，以预测胚胎的生命力。&lt;h4&gt;方法&lt;/h4&gt;结合时间延迟视频数据和电子健康记录（EHR），分析不同的输入和集成方法。&lt;h4&gt;主要发现&lt;/h4&gt;手动评估胚胎的静态形态特征既耗时又昂贵，且具有主观性，导致选择过程中的变异性。&lt;h4&gt;结论&lt;/h4&gt;该方法将能够快速且自动化地进行胚胎生命力预测，适用于临床IVF。&lt;h4&gt;总结&lt;/h4&gt;通过多模态模型的开发，能够提高IVF胚胎评估的效率和准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In clinical In-Vitro Fertilization (IVF), identifying the most viable embryofor transfer is important to increasing the likelihood of a successfulpregnancy. Traditionally, this process involves embryologists manuallyassessing embryos' static morphological features at specific intervals usinglight microscopy. This manual evaluation is not only time-intensive and costly,due to the need for expert analysis, but also inherently subjective, leading tovariability in the selection process. To address these challenges, we develop amultimodal model that leverages both time-lapse video data and ElectronicHealth Records (EHRs) to predict embryo viability. One of the primarychallenges of our research is to effectively combine time-lapse video and EHRdata, owing to their inherent differences in modality. We comprehensivelyanalyze our multimodal model with various modality inputs and integrationapproaches. Our approach will enable fast and automated embryo viabilitypredictions in scale for clinical IVF.</description>
      <author>example@mail.com (Junsik Kim, Zhiyi Shi, Davin Jeong, Johannes Knittel, Helen Y. Yang, Yonghyun Song, Wanhua Li, Yicong Li, Dalit Ben-Yosef, Daniel Needleman, Hanspeter Pfister)</author>
      <guid isPermaLink="false">2410.15581v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Context is Key: A Benchmark for Forecasting with Essential Textual Information</title>
      <link>http://arxiv.org/abs/2410.18959v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint; under review. First two authors contributed equally&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;预测在各个领域的决策中至关重要，但仅依赖数值数据往往缺乏必要的上下文信息。&lt;h4&gt;目的&lt;/h4&gt;提出一个新的时间序列预测基准，旨在有效整合数值数据与文本上下文。&lt;h4&gt;方法&lt;/h4&gt;引入了CiK基准，评估多种方法，包括统计模型、时间序列基础模型和基于大型语言模型(LLM)的预测模型，并提出了一种有效的LLM提示方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，结合上下文信息可以显著提升预测性能，LLM模型表现出惊人的效果，但也存在一些关键的不足。&lt;h4&gt;结论&lt;/h4&gt;通过建立这个基准，推动多模态预测的发展，使模型对不同技术背景的决策者更加准确且易于访问。&lt;h4&gt;总结&lt;/h4&gt;CiK基准展示了在预测中整合文本上下文的重要性，并为未来的多模态模型研究提供了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/servicenow/context-is-key-forecasting&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting is a critical task in decision making across various domains.While numerical data provides a foundation, it often lacks crucial contextnecessary for accurate predictions. Human forecasters frequently rely onadditional information, such as background knowledge or constraints, which canbe efficiently communicated through natural language. However, the ability ofexisting forecasting models to effectively integrate this textual informationremains an open question. To address this, we introduce "Context is Key" (CiK),a time series forecasting benchmark that pairs numerical data with diversetypes of carefully crafted textual context, requiring models to integrate bothmodalities. We evaluate a range of approaches, including statistical models,time series foundation models, and LLM-based forecasters, and propose a simpleyet effective LLM prompting method that outperforms all other tested methods onour benchmark. Our experiments highlight the importance of incorporatingcontextual information, demonstrate surprising performance when using LLM-basedforecasting models, and also reveal some of their critical shortcomings. Bypresenting this benchmark, we aim to advance multimodal forecasting, promotingmodels that are both accurate and accessible to decision-makers with variedtechnical expertise. The benchmark can be visualized athttps://servicenow.github.io/context-is-key-forecasting/v0/ .</description>
      <author>example@mail.com (Andrew Robert Williams, Arjun Ashok, Étienne Marcotte, Valentina Zantedeschi, Jithendaraa Subramanian, Roland Riachi, James Requeima, Alexandre Lacoste, Irina Rish, Nicolas Chapados, Alexandre Drouin)</author>
      <guid isPermaLink="false">2410.18959v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>AMPLE: Emotion-Aware Multimodal Fusion Prompt Learning for Fake News Detection</title>
      <link>http://arxiv.org/abs/2410.15591v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;检测假新闻在大数据集中具有挑战性，传统方法常常侧重于文本特征，而未充分利用语义和情感元素。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架以解决假新闻检测中面临的多样性和复杂性问题。&lt;h4&gt;方法&lt;/h4&gt;引入情感感知多模态融合提示学习框架（AMPLE），结合文本情感分析和多模态数据，使用混合提示模板。&lt;h4&gt;主要发现&lt;/h4&gt;AMPLE框架在两个公共数据集上表现出色，适用于少量样本和数据丰富的环境，显示情感因素在假新闻检测中的潜力。&lt;h4&gt;结论&lt;/h4&gt;进一步探讨了将大型语言模型与该方法结合进行文本情感提取的影响，发现有显著的提升空间。&lt;h4&gt;代码链接&lt;/h4&gt;https://github.com/xxm1215/MMM2025_few-shot/&lt;h4&gt;总结&lt;/h4&gt;该研究展示了情感分析在假新闻检测中的重要性，并提出了有效的框架和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/xxm1215/mmm2025_few-shot&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting fake news in large datasets is challenging due to its diversity andcomplexity, with traditional approaches often focusing on textual featureswhile underutilizing semantic and emotional elements. Current methods also relyheavily on large annotated datasets, limiting their effectiveness in morenuanced analysis. To address these challenges, this paper introducesEmotion-\textbf{A}ware \textbf{M}ultimodal Fusion \textbf{P}rompt\textbf{L}\textbf{E}arning (\textbf{AMPLE}) framework to address the aboveissue by combining text sentiment analysis with multimodal data and hybridprompt templates. This framework extracts emotional elements from texts byleveraging sentiment analysis tools. It then employs Multi-Head Cross-Attention(MCA) mechanisms and similarity-aware fusion methods to integrate multimodaldata. The proposed AMPLE framework demonstrates strong performance on twopublic datasets in both few-shot and data-rich settings, with resultsindicating the potential of emotional aspects in fake news detection.Furthermore, the study explores the impact of integrating large language modelswith this method for text sentiment extraction, revealing substantial room forfurther improvement. The code can be found at:\url{https://github.com/xxm1215/MMM2025_few-shot/</description>
      <author>example@mail.com (Xiaoman Xu, Xiangrun Li, Taihang Wang, Ye Jiang)</author>
      <guid isPermaLink="false">2410.15591v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Classifying extended, localized and critical states in quasiperiodic lattices via unsupervised learning</title>
      <link>http://arxiv.org/abs/2410.15061v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;量子相的分类是凝聚态物理研究中的重要领域。&lt;h4&gt;目的&lt;/h4&gt;通过无监督学习获取一维准周期模型的相图。&lt;h4&gt;方法&lt;/h4&gt;采用两种先进的无监督学习算法：DBSCAN和OPTICS，探索Aubry-André-Harper模型和准周期p波模型的不同相。&lt;h4&gt;主要发现&lt;/h4&gt;无监督学习结果与传统数值对角化结果匹配良好。&lt;h4&gt;结论&lt;/h4&gt;无监督学习算法与传统算法的结果相似性超过98%。&lt;h4&gt;总结&lt;/h4&gt;本研究为无监督学习在相分类中的应用提供了新的视角。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classification of quantum phases is one of the most important areas ofresearch in condensed matter physics. In this work, we obtain the phase diagramof one-dimensional quasiperiodic models via unsupervised learning. Firstly, wechoose two advanced unsupervised learning algorithms, Density-Based SpatialClustering of Applications with Noise (DBSCAN) and Ordering Points To Identifythe Clustering Structure (OPTICS), to explore the distinct phases ofAubry-Andr\'{e}-Harper model and quasiperiodic p-wave model. The unsupervisedlearning results match well with traditional numerical diagonalization.Finally, we compare the similarity of different algorithms and find that thehighest similarity between the results of unsupervised learning algorithms andthose of traditional algorithms has exceeded 98\%. Our work sheds light onapplications of unsupervised learning for phase classification.</description>
      <author>example@mail.com (Bohan Zheng, Siyu Zhu, Xingping Zhou, Tong Liu)</author>
      <guid isPermaLink="false">2410.15061v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>On the Crucial Role of Initialization for Matrix Factorization</title>
      <link>http://arxiv.org/abs/2410.18965v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;重新审视经典的低秩矩阵分解问题，强调初始化在非凸和非光滑优化收敛率中的关键作用。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的初始化方法以提高矩阵分解的全局收敛性。&lt;h4&gt;方法&lt;/h4&gt;引入Nystrom初始化，改善Scaled Gradient Descent（ScaledGD）的表现，适用于对称和非对称矩阵分解任务。&lt;h4&gt;主要发现&lt;/h4&gt;证明了使用Nystrom初始化的ScaledGD在某些情况下实现了二次收敛，而之前仅知线性收敛。&lt;h4&gt;结论&lt;/h4&gt;将该初始化方法扩展到常用于基础模型微调的低秩适配器（LoRA），提出NoRA方法，在不同下游任务和模型规模上表现优越。&lt;h4&gt;总结&lt;/h4&gt;Nystrom初始化显著提升了矩阵分解和模型微调的收敛性，适用于参数从10亿到70亿的模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work revisits the classical low-rank matrix factorization problem andunveils the critical role of initialization in shaping convergence rates forsuch nonconvex and nonsmooth optimization. We introduce Nystrom initialization,which significantly improves the global convergence of Scaled Gradient Descent(ScaledGD) in both symmetric and asymmetric matrix factorization tasks.Specifically, we prove that ScaledGD with Nystrom initialization achievesquadratic convergence in cases where only linear rates were previously known.Furthermore, we extend this initialization to low-rank adapters (LoRA) commonlyused for finetuning foundation models. Our approach, NoRA, i.e., LoRA withNystrom initialization, demonstrates superior performance across variousdownstream tasks and model scales, from 1B to 7B parameters, in large languageand diffusion models.</description>
      <author>example@mail.com (Bingcong Li, Liang Zhang, Aryan Mokhtari, Niao He)</author>
      <guid isPermaLink="false">2410.18965v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>OMLog: Online Log Anomaly Detection for Evolving System with Meta-learning</title>
      <link>http://arxiv.org/abs/2410.16612v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;日志异常检测（LAD）对确保软件系统的安全和稳定运行至关重要。&lt;h4&gt;目的&lt;/h4&gt;构建一个实时可靠的在线日志异常检测模型，以应对日志事件类型和频率变化带来的分布转移问题。&lt;h4&gt;方法&lt;/h4&gt;提出OMLog，一种半监督在线元学习方法，利用基于最大均值差异的分布转移检测方法识别未见日志序列中的分布变化。&lt;h4&gt;主要发现&lt;/h4&gt;在仅使用正常日志序列训练时，OMLog在HDFS和BGL两个公开日志数据集上分别达到了93.7%和64.9%的F1分数，超越了现有的先进LAD方法，展示了更高的检测效率。&lt;h4&gt;结论&lt;/h4&gt;OMLog在处理不断演变的数据时，增强了模型的泛化能力，证明了其在实时日志异常检测中的有效性。&lt;h4&gt;总结&lt;/h4&gt;OMLog方法有效解决了日志异常检测中的分布转移与检测效率问题，具有广泛应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Log anomaly detection (LAD) is essential to ensure safe and stable operationof software systems. Although current LAD methods exhibit significant potentialin addressing challenges posed by unstable log events and temporal sequencepatterns, their limitations in detection efficiency and generalization abilitypresent a formidable challenge when dealing with evolving systems. To constructa real-time and reliable online log anomaly detection model, we propose OMLog,a semi-supervised online meta-learning method, to effectively tackle thedistribution shift issue caused by changes in log event types and frequencies.Specifically, we introduce a maximum mean discrepancy-based distribution shiftdetection method to identify distribution changes in unseen log sequences.Depending on the identified distribution gap, the method can automaticallytrigger online fine-grained detection or offline fast inference. Furthermore,we design an online learning mechanism based on meta-learning, which caneffectively learn the highly repetitive patterns of log sequences in thefeature space, thereby enhancing the generalization ability of the model toevolving data. Extensive experiments conducted on two publicly available logdatasets, HDFS and BGL, validate the effectiveness of the OMLog approach. Whentrained using only normal log sequences, the proposed approach achieves theF1-Score of 93.7\% and 64.9\%, respectively, surpassing the performance of thestate-of-the-art (SOTA) LAD methods and demonstrating superior detectionefficiency.</description>
      <author>example@mail.com (Jiyu Tian, Mingchu Li, Zumin Wang, Liming Chen, Jing Qin, Runfa Zhang)</author>
      <guid isPermaLink="false">2410.16612v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Monge-Ampere Regularization for Learning Arbitrary Shapes from Point Clouds</title>
      <link>http://arxiv.org/abs/2410.18477v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;已广泛使用的隐式几何表示法中，带符号距离函数（SDF）仅限于建模密闭形状，而未带符号距离函数（UDF）能够表示各种表面。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的隐式表面表示方法，称为缩放平方距离函数（S²DF），以建模任意表面类型。&lt;h4&gt;方法&lt;/h4&gt;S²DF不区分内外区域，有效解决了UDF在零水平集的不可微性问题，并满足Monge-Ampère类型的二阶偏微分方程，通过一种新的Monge-Ampère正则化直接从未标记的点云中学习S²DF。&lt;h4&gt;主要发现&lt;/h4&gt;通过在多个数据集上的广泛实验，S²DF显著优于要求真实表面信息作为训练监督的最新监督方法。&lt;h4&gt;结论&lt;/h4&gt;S²DF提供了一种有效的隐式表面表示方法，能够在没有地面真实S²DF值的情况下进行学习。&lt;h4&gt;总结&lt;/h4&gt;研究提出的S²DF方法在建模任意表面类型方面表现优越，代码将公开发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As commonly used implicit geometry representations, the signed distancefunction (SDF) is limited to modeling watertight shapes, while the unsigneddistance function (UDF) is capable of representing various surfaces. However,its inherent theoretical shortcoming, i.e., the non-differentiability at thezero level set, would result in sub-optimal reconstruction quality. In thispaper, we propose the scaled-squared distance function (S$^{2}$DF), a novelimplicit surface representation for modeling arbitrary surface types. S$^{2}$DFdoes not distinguish between inside and outside regions while effectivelyaddressing the non-differentiability issue of UDF at the zero level set. Wedemonstrate that S$^{2}$DF satisfies a second-order partial differentialequation of Monge-Ampere-type, allowing us to develop a learning pipeline thatleverages a novel Monge-Ampere regularization to directly learn S$^{2}$DF fromraw unoriented point clouds without supervision from ground-truth S$^{2}$DFvalues. Extensive experiments across multiple datasets show that our methodsignificantly outperforms state-of-the-art supervised approaches that requireground-truth surface information as supervision for training. The code will bepublicly available at https://github.com/chuanxiang-yang/S2DF.</description>
      <author>example@mail.com (Chuanxiang Yang, Yuanfeng Zhou, Guangshun Wei, Long Ma, Junhui Hou, Yuan Liu, Wenping Wang)</author>
      <guid isPermaLink="false">2410.18477v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Representation Learning from Videos using Nonlinear Priors</title>
      <link>http://arxiv.org/abs/2410.18539v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to BMVC 2024 (Oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;学习可解释的视觉数据表示是一个重要的挑战，旨在使机器的决策对人类可理解，并提升模型在训练分布之外的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一个深度学习框架，允许为视频指定非线性先验，以便模型学习可解释的潜变量，并生成在训练时未观察到的假设场景视频。&lt;h4&gt;方法&lt;/h4&gt;将变分自编码器（VAE）先验从简单的各向同性高斯扩展为任意非线性时间加性噪声模型（ANM），并提出一种新的线性化方法，构建高斯混合模型（GMM）以近似先验。&lt;h4&gt;主要发现&lt;/h4&gt;通过对不同真实世界物理视频的验证，模型能够学习到正确的物理变量，并在训练后对模型进行干预以生成物理上正确的假设场景视频。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个物理实验中有效，证明了模型可以通过改变不同物理变量生成未观察到的场景视频。&lt;h4&gt;总结&lt;/h4&gt;提出的深度学习框架通过指定物理先验，能够有效学习和生成解释性强的视觉数据，提升了机器决策的可理解性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning interpretable representations of visual data is an importantchallenge, to make machines' decisions understandable to humans and to improvegeneralisation outside of the training distribution. To this end, we propose adeep learning framework where one can specify nonlinear priors for videos (e.g.of Newtonian physics) that allow the model to learn interpretable latentvariables and use these to generate videos of hypothetical scenarios notobserved at training time. We do this by extending the Variational Auto-Encoder(VAE) prior from a simple isotropic Gaussian to an arbitrary nonlinear temporalAdditive Noise Model (ANM), which can describe a large number of processes(e.g. Newtonian physics). We propose a novel linearization method thatconstructs a Gaussian Mixture Model (GMM) approximating the prior, and derive anumerically stable Monte Carlo estimate of the KL divergence between theposterior and prior GMMs. We validate the method on different real-worldphysics videos including a pendulum, a mass on a spring, a falling object and apulsar (rotating neutron star). We specify a physical prior for each experimentand show that the correct variables are learned. Once a model is trained, weintervene on it to change different physical variables (such as oscillationamplitude or adding air drag) to generate physically correct videos ofhypothetical scenarios that were not observed previously.</description>
      <author>example@mail.com (Marian Longa, João F. Henriques)</author>
      <guid isPermaLink="false">2410.18539v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Deep Multimodal Representation Learning for Stellar Spectra</title>
      <link>http://arxiv.org/abs/2410.16081v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to the Machine Learning and the Physical Sciences Workshop,
  NeurIPS 2024&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;对比学习（CL）是一种主要用于自然语言处理和计算机视觉的技术，最近被用于训练星系光谱和图像的自监督表示空间。&lt;h4&gt;目的&lt;/h4&gt;将对比学习应用于银河系中的恒星，以处理大量异构数据。&lt;h4&gt;方法&lt;/h4&gt;研究Gaia XP系数和RVS光谱，通过对比学习实现数据聚合。&lt;h4&gt;主要发现&lt;/h4&gt;对比学习生成的表示空间结构良好，具有明确的物理意义。&lt;h4&gt;结论&lt;/h4&gt;使用该表示空间进行跨模态生成和恒星标签回归表现出色，生成样本质量高，标签预测准确。&lt;h4&gt;总结&lt;/h4&gt;本研究为多模态数据的知识聚合奠定了基础，支持后续任务如跨模态生成和恒星参数估计。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, contrastive learning (CL), a technique most prominently used innatural language and computer vision, has been used to train informativerepresentation spaces for galaxy spectra and images in a self-supervisedmanner. Following this idea, we implement CL for stars in the Milky Way, forwhich recent astronomical surveys have produced a huge amount of heterogeneousdata. Specifically, we investigate Gaia XP coefficients and RVS spectra. Thus,the methods presented in this work lay the foundation for aggregating theknowledge implicitly contained in the multimodal data to enable downstreamtasks like cross-modal generation or fused stellar parameter estimation. Wefind that CL results in a highly structured representation space that exhibitsexplicit physical meaning. Evaluating Using this representation space toperform cross-modal generation and stellar label regression results inexcellent performance with high-quality generated samples as well as accurateand precise label predictions.</description>
      <author>example@mail.com (Tobias Buck, Christian Schwarz)</author>
      <guid isPermaLink="false">2410.16081v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>UnCLe: Unsupervised Continual Learning of Depth Completion</title>
      <link>http://arxiv.org/abs/2410.18074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;深度补全任务旨在从同步的RGB图像和稀疏深度图中推断出稠密的深度图。&lt;h4&gt;目的&lt;/h4&gt;提出UnCLe，一个标准化的基准，用于无监督持续学习的多模态深度估计任务。&lt;h4&gt;方法&lt;/h4&gt;通过适应不同领域的多样化场景数据序列来模拟非静态分布，评估深度补全模型。&lt;h4&gt;主要发现&lt;/h4&gt;无监督持续学习的深度补全问题仍然是一个未解决的问题，现有方法在非静态分布上会导致严重的遗忘。&lt;h4&gt;结论&lt;/h4&gt;研究人员应利用UnCLe作为开发平台，推动无监督持续学习的发展。&lt;h4&gt;总结&lt;/h4&gt;UnCLe为无监督持续学习的深度补全任务提供了一个新的基准，鼓励对模型遗忘程度的深入研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose UnCLe, a standardized benchmark for Unsupervised ContinualLearning of a multimodal depth estimation task: Depth completion aims to infera dense depth map from a pair of synchronized RGB image and sparse depth map.We benchmark depth completion models under the practical scenario ofunsupervised learning over continuous streams of data. Existing methods aretypically trained on a static, or stationary, dataset. However, when adaptingto novel non-stationary distributions, they "catastrophically forget"previously learned information. UnCLe simulates these non-stationarydistributions by adapting depth completion models to sequences of datasetscontaining diverse scenes captured from distinct domains using different visualand range sensors. We adopt representative methods from continual learningparadigms and translate them to enable unsupervised continual learning of depthcompletion. We benchmark these models for indoor and outdoor and investigatethe degree of catastrophic forgetting through standard quantitative metrics.Furthermore, we introduce model inversion quality as an additional measure offorgetting. We find that unsupervised continual learning of depth completion isan open problem, and we invite researchers to leverage UnCLe as a developmentplatform.</description>
      <author>example@mail.com (Suchisrit Gangopadhyay, Xien Chen, Michael Chu, Patrick Rim, Hyoungseob Park, Alex Wong)</author>
      <guid isPermaLink="false">2410.18074v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Graph Pre-Training Models Are Strong Anomaly Detectors</title>
      <link>http://arxiv.org/abs/2410.18487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;图形异常检测（GAD）是一个具有挑战性和实际意义的研究主题，图神经网络（GNNs）在此领域最近表现出良好的效果。&lt;h4&gt;目的&lt;/h4&gt;探讨图预训练在图形异常检测中的作用及其影响。&lt;h4&gt;方法&lt;/h4&gt;比较现有的GNN在GAD中的表现，特别是图预训练模型与传统的端到端训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;图预训练模型在图形异常检测中表现优异，尤其是在有限监督情况下显著超过最先进的端到端训练模型。&lt;h4&gt;结论&lt;/h4&gt;预训练能够增强对遥远、代表性不足且未标记的异常的检测能力，这一发现揭示了其在GAD中的优势。&lt;h4&gt;后续研究&lt;/h4&gt;本研究旨在刺激对预训练在图形异常检测角色的重新评估，并为未来研究提供有价值的见解。&lt;h4&gt;总结&lt;/h4&gt;图预训练在图形异常检测中显示出强大的潜力，值得进一步探讨和研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Anomaly Detection (GAD) is a challenging and practical research topicwhere Graph Neural Networks (GNNs) have recently shown promising results. Theeffectiveness of existing GNNs in GAD has been mainly attributed to thesimultaneous learning of node representations and the classifier in anend-to-end manner. Meanwhile, graph pre-training, the two-stage learningparadigm such as DGI and GraphMAE, has shown potential in leveraging unlabeledgraph data to enhance downstream tasks, yet its impact on GAD remainsunder-explored. In this work, we show that graph pre-training models are stronggraph anomaly detectors. Specifically, we demonstrate that pre-training ishighly competitive, markedly outperforming the state-of-the-art end-to-endtraining models when faced with limited supervision. To understand thisphenomenon, we further uncover pre-training enhances the detection of distant,under-represented, unlabeled anomalies that go beyond 2-hop neighborhoods ofknown anomalies, shedding light on its superior performance against end-to-endmodels. Moreover, we extend our examination to the potential of pre-training ingraph-level anomaly detection. We envision this work to stimulate are-evaluation of pre-training's role in GAD and offer valuable insights forfuture research.</description>
      <author>example@mail.com (Jiashun Cheng, Zinan Zheng, Yang Liu, Jianheng Tang, Hongwei Wang, Yu Rong, Jia Li, Fugee Tsung)</author>
      <guid isPermaLink="false">2410.18487v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Meta Stackelberg Game: Robust Federated Learning against Adaptive and Mixed Poisoning Attacks</title>
      <link>http://arxiv.org/abs/2410.17431v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;要点总结&lt;/h4&gt;{
    "背景": "联邦学习（FL）面临多种安全威胁，现有防御机制通常缺乏适应性，无法有效应对多种不确定、未知和自适应的攻击。",
    "目的": "提出一种新的防御机制以应对多种攻击类型，提升联邦学习的安全性。",
    "方法": "将对抗性联邦学习建模为贝叶斯斯塔克尔博克（Stackelberg）马尔可夫博弈，设计元斯塔克尔博克防御，包括预训练和在线适应。",
    "主要发现": "元学习算法能够在有限的迭代次数内收敛到一阶$\varepsilon$-元均衡点，并且在实验中对强模型污染和后门攻击表现出色。",
    "结论": "所提的元斯塔克尔博克框架在面对不确定和未知类型的强攻击时，展现了强大的鲁棒性和适应性。",
    "总结": "通过强化学习模拟攻击行为并设计元RL防御，提出了一种有效的联邦学习防御机制，提升了安全性。"
}&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning (FL) is susceptible to a range of security threats.Although various defense mechanisms have been proposed, they are typicallynon-adaptive and tailored to specific types of attacks, leaving theminsufficient in the face of multiple uncertain, unknown, and adaptive attacksemploying diverse strategies. This work formulates adversarial federatedlearning under a mixture of various attacks as a Bayesian Stackelberg Markovgame, based on which we propose the meta-Stackelberg defense composed ofpre-training and online adaptation. {The gist is to simulate strong attackbehavior using reinforcement learning (RL-based attacks) in pre-training andthen design meta-RL-based defense to combat diverse and adaptive attacks.} Wedevelop an efficient meta-learning approach to solve the game, leading to arobust and adaptive FL defense. Theoretically, our meta-learning algorithm,meta-Stackelberg learning, provably converges to the first-order$\varepsilon$-meta-equilibrium point in $O(\varepsilon^{-2})$ gradientiterations with $O(\varepsilon^{-4})$ samples per iteration. Experiments showthat our meta-Stackelberg framework performs superbly against strong modelpoisoning and backdoor attacks of uncertain and unknown types.</description>
      <author>example@mail.com (Tao Li, Henger Li, Yunian Pan, Tianyi Xu, Zizhan Zheng, Quanyan Zhu)</author>
      <guid isPermaLink="false">2410.17431v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised semantic segmentation of urban high-density multispectral point clouds</title>
      <link>http://arxiv.org/abs/2410.18520v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22 pages, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;未来城市空气激光扫描（ALS）数据的可用性将迅速增加，尤其是在获取成本降低的情况下，如使用无人机。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在对新的高密度多光谱ALS数据进行语义分割，解决当前数据处理中的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于无监督深度聚类方法GroupSP的地面感知语义分割，通过将场景划分为超点进行预处理，并使用聚类结果作为伪标签进行神经网络的迭代训练。&lt;h4&gt;主要发现&lt;/h4&gt;GroupSP的整体准确率（oAcc）为97%，均值交并比（mIoU）为80%。与其他无监督语义分割方法相比，GroupSP优于GrowSP和非深度K均值，但被监督随机森林分类器超越。&lt;h4&gt;结论&lt;/h4&gt;GroupSP能够使用仅0.004%的标注点对七种城市类别进行语义分割，oAcc为95%，mIoU为75%。增加每个新光谱通道提高了mIoU，回声偏差在区分地面类时特别有价值。&lt;h4&gt;总结&lt;/h4&gt;本研究展示了通过无监督深度聚类方法对高密度多光谱ALS数据进行有效的语义分割的潜力，为城市环境的点云语义理解提供了新思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The availability of highly accurate urban airborne laser scanning (ALS) datawill increase rapidly in the future, especially as acquisition costs decrease,for example through the use of drones. Current challenges in data processingare related to the limited spectral information and low point density of mostALS datasets. Another challenge will be the growing need for annotated trainingdata, frequently produced by manual processes, to enable semanticinterpretation of point clouds. This study proposes to semantically segment newhigh-density (1200 points per square metre on average) multispectral ALS datawith an unsupervised ground-aware deep clustering method GroupSP inspired bythe unsupervised GrowSP algorithm. GroupSP divides the scene into superpointsas a preprocessing step. The neural network is trained iteratively by groupingthe superpoints and using the grouping assignments as pseudo-labels. Thepredictions for the unseen data are given by over-segmenting the test set andmapping the predicted classes into ground truth classes manually or withautomated majority voting. GroupSP obtained an overall accuracy (oAcc) of 97%and a mean intersection over union (mIoU) of 80%. When compared to otherunsupervised semantic segmentation methods, GroupSP outperformed GrowSP andnon-deep K-means. However, a supervised random forest classifier outperformedGroupSP. The labelling efforts in GroupSP can be minimal; it was shown, thatthe GroupSP can semantically segment seven urban classes (building, highvegetation, low vegetation, asphalt, rock, football field, and gravel) withoAcc of 95% and mIoU of 75% using only 0.004% of the available annotated pointsin the mapping assignment. Finally, the multispectral information was examined;adding each new spectral channel improved the mIoU. Additionally, echodeviation was valuable, especially when distinguishing ground-level classes.</description>
      <author>example@mail.com (Oona Oinonen, Lassi Ruoppa, Josef Taher, Matti Lehtomäki, Leena Matikainen, Kirsi Karila, Teemu Hakala, Antero Kukko, Harri Kaartinen, Juha Hyyppä)</author>
      <guid isPermaLink="false">2410.18520v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>New Insight in Cervical Cancer Diagnosis Using Convolution Neural Network Architecture</title>
      <link>http://arxiv.org/abs/2410.17735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;Pap涂片是早期宫颈癌诊断的筛查方法。&lt;h4&gt;目的&lt;/h4&gt;研究不同优化器在卷积神经网络（CNN）模型中的影响，特别是在宫颈癌Pap涂片图像分类中。&lt;h4&gt;方法&lt;/h4&gt;使用SGD、RMSprop、Adam、AdaGrad、AdaDelta、Adamax和Nadam优化器，对SipakMed数据集中的宫颈癌Pap涂片图像进行分类，采用Resnet-18、Resnet-34和VGG-16架构，并利用迁移学习模型。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习模型在所有CNN和优化技术中表现更佳，优化对模型训练影响较小。Adamax在VGG-16和Resnet-18架构的准确率分别为72.8%和66.8%，而Resnet-34为54.0%。&lt;h4&gt;结论&lt;/h4&gt;Adamax是Resnet-18、Resnet-34和VGG-16架构中适合用于宫颈癌分类的优化器。本研究为Pap涂片图像分析中的CNN模型配置提供了新见解。&lt;h4&gt;总结&lt;/h4&gt;通过不同优化器的比较，确认了迁移学习模型的有效性及Adamax优化器在宫颈癌图像分类中的优越性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.11591/ijai.v13.i3.pp3092-3100&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Pap smear is a screening method for early cervical cancer diagnosis. Theselection of the right optimizer in the convolutional neural network (CNN)model is key to the success of the CNN in image classification, including theclassification of cervical cancer Pap smear images. In this study, stochasticgradient descent (SGD), RMSprop, Adam, AdaGrad, AdaDelta, Adamax, and Nadamoptimizers were used to classify cervical cancer Pap smear images from theSipakMed dataset. Resnet-18, Resnet-34, and VGG-16 are the CNN architecturesused in this study, and each architecture uses a transfer-learning model. Basedon the test results, we conclude that the transfer learning model performsbetter on all CNNs and optimization techniques and that in the transferlearning model, the optimization has little influence on the training of themodel. Adamax, with accuracy values of 72.8% and 66.8%, had the best accuracyfor the VGG-16 and Resnet-18 architectures, respectively. Resnet-34 had 54.0%.This is 0.034% lower than Nadam. Overall, Adamax is a suitable optimizer forCNN in cervical cancer classification on Resnet-18, Resnet-34, and VGG-16architectures. This study provides new insights into the configuration of CNNmodels for Pap smear image analysis.</description>
      <author>example@mail.com (Ach. Khozaimi, Wayan Firdaus Mahmudy)</author>
      <guid isPermaLink="false">2410.17735v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Continuous Dynamic Modeling via Neural ODEs for Popularity Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2410.18742v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;信息传播的受欢迎程度预测在舆论监测和广告推荐等多个领域具有重要应用。&lt;h4&gt;目的&lt;/h4&gt;预测受欢迎程度的整个轨迹，以更好地理解受欢迎程度的动态变化特性。&lt;h4&gt;方法&lt;/h4&gt;提出NODEPT，通过神经常微分方程（ODE）建模信息传播系统的连续动态，使用编码器初始化潜在状态表示，并引入ODE生成模块学习潜在空间中的动态。&lt;h4&gt;主要发现&lt;/h4&gt;NODEPT在三个真实数据集上的实验结果表明，其性能优于传统方法，合理性得到了验证。&lt;h4&gt;结论&lt;/h4&gt;NODEPT提供了一种更有效的方法来预测信息传播的受欢迎程度轨迹，克服了传统方法的局限性。&lt;h4&gt;总结&lt;/h4&gt;通过建模受欢迎程度的动态特性，NODEPT为信息传播的预测提供了新的视角和方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Popularity prediction for information cascades has significant applicationsacross various domains, including opinion monitoring and advertisingrecommendations. While most existing methods consider this as a discreteproblem, popularity actually evolves continuously, exhibiting rich dynamicproperties such as change rates and growth patterns. In this paper, we arguethat popularity trajectory prediction is more practical, as it aims to forecastthe entire trajectory of how popularity unfolds over arbitrary future time.This approach offers insights into both instantaneous popularity and theunderlying dynamic properties. However, traditional methods for popularitytrajectory prediction primarily rely on specific diffusion mechanismassumptions, which may not align well with real-world dynamics and compromisetheir performance. To address these limitations, we propose NODEPT, a novelapproach based on neural ordinary differential equations (ODEs) for popularitytrajectory prediction. NODEPT models the continuous dynamics of the underlyingdiffusion system using neural ODEs. We first employ an encoder to initializethe latent state representations of information cascades, consisting of tworepresentation learning modules that capture the co-evolution structuralcharacteristics and temporal patterns of cascades from different perspectives.More importantly, we then introduce an ODE-based generative module that learnsthe dynamics of the diffusion system in the latent space. Finally, a decodertransforms the latent state into the prediction of the future popularitytrajectory. Our experimental results on three real-world datasets demonstratethe superiority and rationality of the proposed NODEPT method.</description>
      <author>example@mail.com (Songbo Yang, Ziwei Zhao, Zihang Chen, Haotian Zhang, Tong Xu, Mengxiao Zhu)</author>
      <guid isPermaLink="false">2410.18742v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report</title>
      <link>http://arxiv.org/abs/2410.16239v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 5 figures, 9 tables. Supplementary detail in Appendix. Code
  made available in Github for reproducibility&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;提出了一种新颖的多模态对比预训练框架，结合了X光、心电图（ECG）和放射/心脏病报告。&lt;h4&gt;目的&lt;/h4&gt;提升诊断准确性，促进全面的患者评估。&lt;h4&gt;方法&lt;/h4&gt;利用变压器编码不同模态到统一表示空间，采用LoRA-Peft减少可训练参数，并在视觉变压器中应用线性注意力丢弃策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比损失，MoRE有效地将特定模态特征对齐到一致的嵌入，支持零样本分类和多模态检索等下游任务。&lt;h4&gt;结论&lt;/h4&gt;在Mimic-IV、CheXpert、Edema Severity和PtbXl数据集上实现了最先进的性能，超越了现有的多模态方法，展示了对复杂模态间关系的捕捉能力及医疗诊断的稳健性。&lt;h4&gt;总结&lt;/h4&gt;该框架为未来在医疗领域的多模态学习研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/svthapa/more&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a novel Multi-Modal Contrastive Pre-trainingFramework that synergistically combines X-rays, electrocardiograms (ECGs), andradiology/cardiology reports. Our approach leverages transformers to encodethese diverse modalities into a unified representation space, aiming to enhancediagnostic accuracy and facilitate comprehensive patient assessments. Weutilize LoRA-Peft to significantly reduce trainable parameters in the LLM andincorporate recent linear attention dropping strategy in the VisionTransformer(ViT) for smoother attention. Furthermore, we provide novelmultimodal attention explanations and retrieval for our model. To the best ofour knowledge, we are the first to propose an integrated model that combinesX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizingcontrastive loss, MoRE effectively aligns modality-specific features into acoherent embedding, which supports various downstream tasks such as zero-shotclassification and multimodal retrieval. Employing our proposed methodology, weachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, andPtbXl downstream datasets, surpassing existing multimodal approaches. Ourproposed framework shows significant improvements in capturing intricateinter-modal relationships and its robustness in medical diagnosis thatestablishes a framework for future research in multimodal learning in thehealthcare sector.</description>
      <author>example@mail.com (Samrajya Thapa, Koushik Howlader, Subhankar Bhattacharjee, Wei le)</author>
      <guid isPermaLink="false">2410.16239v2</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Information Diffusion Prediction by Addressing Noise in Social Connection Data</title>
      <link>http://arxiv.org/abs/2410.18492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着在线社交媒体平台的普及，信息传播成为一种常见现象，信息传播预测（IDP）对各种应用变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;解决社交连接数据中的噪声问题，以提高信息传播预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的社交连接去噪框架DIDP，包括图学习编码模块和去噪扩散模块，通过多步噪声注入与去除，学习鲁棒的嵌入表示。&lt;h4&gt;主要发现&lt;/h4&gt;DIDP在信息传播预测任务中显著优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;DIDP能够有效去除社交嵌入中的噪声，并通过跨域对比学习促进知识转移，从而增强预测性能。&lt;h4&gt;总结&lt;/h4&gt;DIDP提供了一种创新的方法来提高信息传播预测的准确性，解决了社交连接数据中的噪声问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the increasing use of online social media platforms, informationdiffusion has become a prevalent phenomenon, making Information DiffusionPrediction (IDP) critical for various applications. Many studies utilize socialconnection data to improve prediction performance. However, previous researchhas largely overlooked the issue of noise within social connection data, whichoften contains irrelevant or misleading connections due to the diversity ofsocial relationships and the presence of weak ties. Such noise can lead toinaccurate learning of user preferences and negatively affect predictionoutcomes. To address this issue, we propose DIDP, a novel social connectiondenoising framework for information diffusion prediction. First, we introduce agraph learning encoder module that encodes the information diffusion hypergraphand social graph to obtain latent diffusion embeddings and social embeddings.Next, DIDP integrates a denoising diffusion module to adaptively removedifferent types of noise from the learned social embeddings in the latentspace. Through multi-step noise injection and removal, the framework enhancesthe ability to learn robust embeddings. Additionally, we introduce across-domain contrastive learning module that maximizes the mutual informationbetween the diffusion embeddings and the denoised social embeddings of the sameuser. This module guides the denoising process and facilitates cross-domainknowledge transfer. Experimental results show that DIDP significantlyoutperforms state-of-the-art methods in the information diffusion predictiontask.</description>
      <author>example@mail.com (Songbo Yang, Zihang Chen, Mengxiao Zhu)</author>
      <guid isPermaLink="false">2410.18492v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Moving Object Segmentation in Point Cloud Data using Hidden Markov Models</title>
      <link>http://arxiv.org/abs/2410.18638v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to the IEEE IROS 2024 workshop on Long-Term Perception for
  Autonomy in Dynamic Human-shared Environments: What Do Robots Need?&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;自主代理需要识别环境中的动态物体，以确保安全的规划和导航。&lt;h4&gt;目的&lt;/h4&gt;解决动态检测中的不完整和错误问题，以提高任务完成能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于隐马尔可夫模型（HMM）的无学习方法，用于从点云数据中分割移动物体，并通过HMM滤波器将信念概率地整合到地图中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在基准数据集上的测试结果优于或与现有最先进的方法持平，具有强大的泛化性能，适应不同传感器特性和环境。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法在动态物体检测方面表现出色，具有较好的应用前景。&lt;h4&gt;总结&lt;/h4&gt;该方法已开源，地址为 https://github.com/vb44/HMM-MOS。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/vb44/hmm-mos&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous agents require the capability to identify dynamic objects in theirenvironment for safe planning and navigation. Incomplete and erroneous dynamicdetections jeopardize the agent's ability to accomplish its task. Dynamicdetection is a challenging problem due to the numerous sources of uncertaintyinherent in the problem's inputs and the wide variety of applications, whichoften lead to use-case-tailored solutions. We propose a robust learning-freeapproach to segment moving objects in point cloud data. The foundation of theapproach lies in modelling each voxel using a hidden Markov model (HMM), andprobabilistically integrating beliefs into a map using an HMM filter. Theproposed approach is tested on benchmark datasets and consistently performsbetter than or as well as state-of-the-art methods with strong generalizedperformance across sensor characteristics and environments. The approach isopen-sourced at https://github.com/vb44/HMM-MOS.</description>
      <author>example@mail.com (Vedant Bhandari, Jasmin James, Tyson Phillips, P. Ross McAree)</author>
      <guid isPermaLink="false">2410.18638v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Gradient-Based Meta Learning for Uplink RSMA with Beyond Diagonal RIS</title>
      <link>http://arxiv.org/abs/2410.17896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;超对角可重构智能表面（BD-RIS）是一种创新的广义RIS框架，提供了更大的波形操控灵活性和增强的覆盖范围。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法以最大化系统的总速率，并联合优化基站的接收波束形成向量、BD-RIS的散射矩阵和用户设备的传输功率。&lt;h4&gt;方法&lt;/h4&gt;采用一种基于梯度的元学习算法，该算法无需预训练，能够解决大规模优化问题。&lt;h4&gt;主要发现&lt;/h4&gt;与传统RIS RSMA框架相比，所提出的方案在性能上提高了22.5%。&lt;h4&gt;结论&lt;/h4&gt;这是首次在上行速率分裂多接入（RSMA）通信中考虑联合优化的研究。&lt;h4&gt;总结&lt;/h4&gt;BD-RIS提供了更高的灵活性和性能，提出的算法有效解决了大规模优化的复杂性问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Beyond diagonal reconfigurable intelligent surface (BD-RIS) has emerged as aninnovative and generalized RIS framework that provides greater flexibility inwave manipulation and enhanced coverage. In comparison to conventional RIS,optimization of BD-RIS is more challenging due to the large number ofoptimization variables associated with it. Typically, optimization oflarge-scale optimization problems utilizing traditional optimization methodsresults in high complexity. To tackle this issue, we propose a gradient-basedmeta learning algorithm which works without pre-training and is able to solvelarge-scale optimization problems. With the objective to maximize the sum rateof the system, to the best of our knowledge, this is the first work consideringjoint optimization of receiving beamforming vectors at the base station (BS),scattering matrix of BD-RIS and transmission power of users equipment (UEs) inuplink rate-splitting multiple access (RSMA) communication. Numerical resultsdemonstrate that our proposed scheme can outperform the conventional RIS RSMAframework by 22.5$\%$.</description>
      <author>example@mail.com (Shreya Khisa, Ali Amhaz, Mohamed Elhattab, Chadi Assi, Sanaa Sharafeddine)</author>
      <guid isPermaLink="false">2410.17896v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Unsupervised Point Cloud Completion through Unbalanced Optimal Transport</title>
      <link>http://arxiv.org/abs/2410.02671v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;无配对点云补全研究学习如何从无配对的不完整和完整点云数据中生成补全图。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，使用不平衡最优传输图进行无配对点云补全。&lt;h4&gt;方法&lt;/h4&gt;将无配对点云补全视为最优传输问题，引入不平衡最优传输方法以解决类不平衡问题，分析适合无配对补全任务的成本函数。&lt;h4&gt;主要发现&lt;/h4&gt;InfoCD成本函数特别适合无配对点云补全任务。模型在单类别和多类别数据集上取得了竞争性或优越的结果。&lt;h4&gt;结论&lt;/h4&gt;模型在类不平衡的情况下尤其有效，适用于不完整和完整点云数据集之间类别比例不同的情境。&lt;h4&gt;总结&lt;/h4&gt;首次将不平衡最优传输用于无配对点云补全，展示了其在处理类不平衡问题中的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unpaired point cloud completion explores methods for learning a completionmap from unpaired incomplete and complete point cloud data. In this paper, wepropose a novel approach for unpaired point cloud completion using theunbalanced optimal transport map, called Unbalanced Optimal Transport Map forUnpaired Point Cloud Completion (UOT-UPC). We demonstrate that the unpairedpoint cloud completion can be naturally interpreted as the Optimal Transport(OT) problem and introduce the Unbalanced Optimal Transport (UOT) approach toaddress the class imbalance problem, which is prevalent in unpaired point cloudcompletion datasets. Moreover, we analyze the appropriate cost function forunpaired completion tasks. This analysis shows that the InfoCD cost function isparticularly well-suited for this task. Our model is the first attempt toleverage UOT for unpaired point cloud completion, achieving competitive orsuperior results on both single-category and multi-category datasets. Inparticular, our model is especially effective in scenarios with classimbalance, where the proportions of categories are different between theincomplete and complete point cloud datasets.</description>
      <author>example@mail.com (Taekyung Lee, Jaemoo Choi, Jaewoong Choi, Myungjoo Kang)</author>
      <guid isPermaLink="false">2410.02671v3</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>YOLO-Vehicle-Pro: A Cloud-Edge Collaborative Framework for Object Detection in Autonomous Driving under Adverse Weather Conditions</title>
      <link>http://arxiv.org/abs/2410.17734v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着自动驾驶技术的迅速发展，高效且准确的目标检测能力成为确保自动驾驶系统安全可靠的关键因素。&lt;h4&gt;目的&lt;/h4&gt;解决传统目标检测算法在低能见度环境中性能显著下降的问题，满足自动驾驶的需求。&lt;h4&gt;方法&lt;/h4&gt;提出两种创新的深度学习模型：YOLO-Vehicle和YOLO-Vehicle-Pro。YOLO-Vehicle专门针对自动驾驶场景，使用多模态融合技术结合图像和文本信息；YOLO-Vehicle-Pro在此基础上引入了改进的图像去雾算法。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI数据集上，YOLO-Vehicle-v1s模型实现了92.1%的准确率，检测速度为226 FPS，推理时间为12ms；处理雾霾图像时，YOLO-Vehicle-Pro模型在FoggyCityscapes数据集上达到了82.3%的mAP@50的高准确率，检测速度为43 FPS。&lt;h4&gt;结论&lt;/h4&gt;所提出的模型和云边协同目标检测系统在复杂情况下有效提升了目标检测性能，满足了自动驾驶的实时需求。&lt;h4&gt;总结&lt;/h4&gt;本文提出的YOLO-Vehicle和YOLO-Vehicle-Pro模型及其应用证明了在低能见度环境中自动驾驶的可行性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rapid advancement of autonomous driving technology, efficient andaccurate object detection capabilities have become crucial factors in ensuringthe safety and reliability of autonomous driving systems. However, inlow-visibility environments such as hazy conditions, the performance oftraditional object detection algorithms often degrades significantly, failingto meet the demands of autonomous driving. To address this challenge, thispaper proposes two innovative deep learning models: YOLO-Vehicle andYOLO-Vehicle-Pro. YOLO-Vehicle is an object detection model tailoredspecifically for autonomous driving scenarios, employing multimodal fusiontechniques to combine image and textual information for object detection.YOLO-Vehicle-Pro builds upon this foundation by introducing an improved imagedehazing algorithm, enhancing detection performance in low-visibilityenvironments. In addition to model innovation, this paper also designs andimplements a cloud-edge collaborative object detection system, deploying modelson edge devices and offloading partial computational tasks to the cloud incomplex situations. Experimental results demonstrate that on the KITTI dataset,the YOLO-Vehicle-v1s model achieved 92.1% accuracy while maintaining adetection speed of 226 FPS and an inference time of 12ms, meeting the real-timerequirements of autonomous driving. When processing hazy images, theYOLO-Vehicle-Pro model achieved a high accuracy of 82.3% mAP@50 on the FoggyCityscapes dataset while maintaining a detection speed of 43 FPS.</description>
      <author>example@mail.com (Xiguang Li, Jiafu Chen, Yunhe Sun, Na Lin, Ammar Hawbani, Liang Zhao)</author>
      <guid isPermaLink="false">2410.17734v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Binary Code Similarity Detection via Graph Contrastive Learning on Intermediate Representations</title>
      <link>http://arxiv.org/abs/2410.18561v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;二进制代码相似性检测（BCSD）在漏洞检测、恶意软件分析和代码重用识别等多个领域中发挥重要作用。&lt;h4&gt;目的&lt;/h4&gt;针对物联网设备的异构硬件架构和复杂编译环境，提出更高效的BCSD方法。&lt;h4&gt;方法&lt;/h4&gt;提出IRBinDiff，利用LLVM-IR的高级语义抽象来缓解编译差异，并结合预训练语言模型与图神经网络，从多个角度捕获语义和结构信息。引入动量对比学习，提升大规模候选函数集的检索能力。&lt;h4&gt;主要发现&lt;/h4&gt;IRBinDiff在不同编译设置下的广泛实验中，表现优于其他领先的BCSD方法，既在一对一比较中，也在一对多搜索场景中。&lt;h4&gt;结论&lt;/h4&gt;IRBinDiff有效区分细微的函数相似性与差异，满足了大规模函数检索的需求。&lt;h4&gt;总结&lt;/h4&gt;IRBinDiff是一种创新的BCSD方法，解决了物联网环境中编译差异带来的挑战，具有较强的实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Binary Code Similarity Detection (BCSD) plays a crucial role in numerousfields, including vulnerability detection, malware analysis, and code reuseidentification. As IoT devices proliferate and rapidly evolve, their highlyheterogeneous hardware architectures and complex compilation settings, coupledwith the demand for large-scale function retrieval in practical applications,put forward higher requirements for BCSD methods. In this paper, we proposeIRBinDiff, which mitigates compilation differences by leveraging LLVM-IR withhigher-level semantic abstraction, and integrates a pre-trained language modelwith a graph neural network to capture both semantic and structural informationfrom different perspectives. By introducing momentum contrastive learning, iteffectively enhances retrieval capabilities in large-scale candidate functionsets, distinguishing between subtle function similarities and differences. Ourextensive experiments, conducted under varied compilation settings, demonstratethat IRBinDiff outperforms other leading BCSD methods in both One-to-onecomparison and One-to-many search scenarios.</description>
      <author>example@mail.com (Xiuwei Shang, Li Hu, Shaoyin Cheng, Guoqiang Chen, Benlong Wu, Weiming Zhang, Nenghai Yu)</author>
      <guid isPermaLink="false">2410.18561v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>DL-Polycube: Deep learning enhanced polycube method for high-quality hexahedral mesh generation and volumetric spline construction</title>
      <link>http://arxiv.org/abs/2410.18852v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;随着对高质量六面体网格的需求增加，现有方法在生成六面体网格时存在一些挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的算法DL-Polycube，结合深度学习与多胞体方法，生成高质量的六面体网格。&lt;h4&gt;方法&lt;/h4&gt;通过建立表面三角网格与多胞体结构之间的联系，使用深度神经网络对三角网格进行分类，并结合无监督学习进行表面分割，最终生成六面体网格。&lt;h4&gt;主要发现&lt;/h4&gt;采用八叉树细分、参数映射和质量改善技术生成的六面体网格质量显著提高，深度学习和无监督学习的结合加速了网格生成过程。&lt;h4&gt;结论&lt;/h4&gt;在生成的六面体网格上构建截断层次B样条，并提取三元Bézier元素，直接应用于等几何分析，展示了DL-Polycube算法的有效性。&lt;h4&gt;总结&lt;/h4&gt;DL-Polycube算法通过创新的深度学习和无监督学习方法，有效提升了六面体网格的生成质量和效率，具有广泛的应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present a novel algorithm that integrates deep learningwith the polycube method (DL-Polycube) to generate high-quality hexahedral(hex) meshes, which are then used to construct volumetric splines forisogeometric analysis. Our DL-Polycube algorithm begins by establishing aconnection between surface triangular meshes and polycube structures. We employdeep neural network to classify surface triangular meshes into theircorresponding polycube structures. Following this, we combine the acquiredpolycube structural information with unsupervised learning to perform surfacesegmentation of triangular meshes. This step addresses the issue ofsegmentation not corresponding to a polycube while reducing manualintervention. Quality hex meshes are then generated from the polycubestructures, with employing octree subdivision, parametric mapping and qualityimprovement techniques. The incorporation of deep learning for creatingpolycube structures, combined with unsupervised learning for segmentation ofsurface triangular meshes, substantially accelerates hex mesh generation.Finally, truncated hierarchical B-splines are constructed on the generated hexmeshes. We extract trivariate B\'ezier elements from these splines and applythem directly in isogeometric analysis. We offer several examples todemonstrate the robustness of our DL-Polycube algorithm.</description>
      <author>example@mail.com (Yuxuan Yu, Yuzhuo Fang, Hua Tong, Yongjie Jessica Zhang)</author>
      <guid isPermaLink="false">2410.18852v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>ADEM-VL: Adaptive and Embedded Fusion for Efficient Vision-Language Tuning</title>
      <link>http://arxiv.org/abs/2410.17779v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;近年来，多模态融合的进展使视觉-语言（VL）模型在图像描述和视觉问答等多种多模态应用中表现出色，但构建VL模型需要大量硬件资源。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的视觉-语言方法，解决VL模型在计算和内存复杂性方面的挑战。&lt;h4&gt;方法&lt;/h4&gt;我们提出ADEM-VL，通过无参数的交叉注意机制对预训练的大型语言模型进行调优，仅需将视觉特征嵌入语言空间，从而减少可训练参数数量并加快训练和推理速度。引入高效的多尺度特征生成方案，且使用自适应融合方案动态丢弃与文本标记相关性较低的视觉信息。&lt;h4&gt;主要发现&lt;/h4&gt;在视觉问答、图像描述和指令跟随等多项任务中，ADEM-VL框架优于现有方法。在ScienceQA数据集上，平均准确率提升0.77%，同时减少了训练和推理延迟。&lt;h4&gt;结论&lt;/h4&gt;ADEM-VL展示了其在多模态融合任务中的优越性，代码可在GitHub上获取。&lt;h4&gt;总结&lt;/h4&gt;ADEM-VL通过高效的特征融合和动态信息筛选，提升了视觉-语言模型的性能和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hao840/adem-vl&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in multimodal fusion have witnessed the remarkablesuccess of vision-language (VL) models, which excel in various multimodalapplications such as image captioning and visual question answering. However,building VL models requires substantial hardware resources, where efficiency isrestricted by two key factors: the extended input sequence of the languagemodel with vision features demands more computational operations, and a largenumber of additional learnable parameters increase memory complexity. Thesechallenges significantly restrict the broader applicability of such models. Tobridge this gap, we propose ADEM-VL, an efficient vision-language method thattunes VL models based on pretrained large language models (LLMs) by adopting aparameter-free cross-attention mechanism for similarity measurements inmultimodal fusion. This approach only requires embedding vision features intothe language space, significantly reducing the number of trainable parametersand accelerating both training and inference speeds. To enhance representationlearning in fusion module, we introduce an efficient multiscale featuregeneration scheme that requires only a single forward pass through the visionencoder. Moreover, we propose an adaptive fusion scheme that dynamicallydiscards less relevant visual information for each text token based on itsattention score. This ensures that the fusion process prioritizes the mostpertinent visual features. With experiments on various tasks including visualquestion answering, image captioning, and instruction-following, we demonstratethat our framework outperforms existing approaches. Specifically, our methodsurpasses existing methods by an average accuracy of 0.77% on ScienceQAdataset, with reduced training and inference latency, demonstrating thesuperiority of our framework. The code is available athttps://github.com/Hao840/ADEM-VL.</description>
      <author>example@mail.com (Zhiwei Hao, Jianyuan Guo, Li Shen, Yong Luo, Han Hu, Yonggang Wen)</author>
      <guid isPermaLink="false">2410.17779v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>ConceptDrift: Uncovering Biases through the Lens of Foundational Models</title>
      <link>http://arxiv.org/abs/2410.18970v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;数据集和预训练模型存在内在偏见。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法ConceptDrift，分析模型权重以识别偏见。&lt;h4&gt;方法&lt;/h4&gt;通过线性探针的权重更新轨迹，从文本类的嵌入开始，识别潜在的隐藏偏见。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够准确定位数据集中的不必要相关性，并显著提高了零-shot性能。&lt;h4&gt;结论&lt;/h4&gt;ConceptDrift不仅限于单一模态，实验涵盖了图像和文本数据集。&lt;h4&gt;总结&lt;/h4&gt;本研究提供了一种有效工具，帮助识别和缓解模型中的偏见。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Datasets and pre-trained models come with intrinsic biases. Most methods relyon spotting them by analysing misclassified samples, in a semi-automatedhuman-computer validation. In contrast, we propose ConceptDrift, a method whichanalyzes the weights of a linear probe, learned on top a foundational model. Wecapitalize on the weight update trajectory, which starts from the embedding ofthe textual representation of the class, and proceeds to drift towardsembeddings that disclose hidden biases. Different from prior work, with thisapproach we can pin-point unwanted correlations from a dataset, providing morethan just possible explanations for the wrong predictions. We empirically provethe efficacy of our method, by significantly improving zero-shot performancewith biased-augmented prompting. Our method is not bounded to a singlemodality, and we experiment in this work with both image (Waterbirds, CelebA,Nico++) and text datasets (CivilComments).</description>
      <author>example@mail.com (Cristian Daniel Păduraru, Antonio Bărbălau, Radu Filipescu, Andrei Liviu Nicolicioiu, Elena Burceanu)</author>
      <guid isPermaLink="false">2410.18970v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Addressing Asynchronicity in Clinical Multimodal Fusion via Individualized Chest X-ray Generation</title>
      <link>http://arxiv.org/abs/2410.17918v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by NeurIPS-24&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;整合多模态临床数据（如电子健康记录和胸部X光图像）对临床预测任务特别有益，但在时间序列环境中，这些数据往往是异步的。&lt;h4&gt;目的&lt;/h4&gt;解决由于胸部X光图像更新滞后导致的临床预测不准确问题。&lt;h4&gt;方法&lt;/h4&gt;提出DDL-CXR方法，动态生成个性化的胸部X光图像的最新潜在表示，利用潜在扩散模型，根据之前的X光图像和电子健康记录时间序列进行条件生成。&lt;h4&gt;主要发现&lt;/h4&gt;实验使用MIMIC数据集表明，该模型有效解决了多模态融合中的异步性问题，并且在性能上持续超越现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过潜在生成过程更好地捕捉多模态之间的交互，最终提高了临床预测的准确性。&lt;h4&gt;总结&lt;/h4&gt;DDL-CXR方法为处理异步多模态数据提供了一种有效的解决方案，显著改进了临床预测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Integrating multi-modal clinical data, such as electronic health records(EHR) and chest X-ray images (CXR), is particularly beneficial for clinicalprediction tasks. However, in a temporal setting, multi-modal data are ofteninherently asynchronous. EHR can be continuously collected but CXR is generallytaken with a much longer interval due to its high cost and radiation dose. Whenclinical prediction is needed, the last available CXR image might have beenoutdated, leading to suboptimal predictions. To address this challenge, wepropose DDL-CXR, a method that dynamically generates an up-to-date latentrepresentation of the individualized CXR images. Our approach leverages latentdiffusion models for patient-specific generation strategically conditioned on aprevious CXR image and EHR time series, providing information regardinganatomical structures and disease progressions, respectively. In this way, theinteraction across modalities could be better captured by the latent CXRgeneration process, ultimately improving the prediction performance.Experiments using MIMIC datasets show that the proposed model could effectivelyaddress asynchronicity in multimodal fusion and consistently outperformexisting methods.</description>
      <author>example@mail.com (Wenfang Yao, Chen Liu, Kejing Yin, William K. Cheung, Jing Qin)</author>
      <guid isPermaLink="false">2410.17918v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Deep learning for model correction of dynamical systems with data scarcity</title>
      <link>http://arxiv.org/abs/2410.17913v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;在许多实际情况下，低保真模型能够合理捕捉动态，但由于模型的固有限制和物理复杂性，缺乏高分辨率。&lt;h4&gt;目的&lt;/h4&gt;寻求模型修正，以提高模型预测的分辨率，尤其是在高保真数据稀缺的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种模型修正方法，该方法只需稀缺的高保真数据集。我们首先使用深度神经网络（DNN）模型来近似现有的低保真模型，然后通过迁移学习（TL）修正该DNN模型。&lt;h4&gt;主要发现&lt;/h4&gt;经过迁移学习后，获得了一个具有高预测精度的改进DNN模型，能够更好地反映基础动态。&lt;h4&gt;结论&lt;/h4&gt;该方法的一个显著特点是，它不假设特定的模型修正项，而是通过迁移学习向低保真模型提供内在修正。&lt;h4&gt;总结&lt;/h4&gt;通过一系列数值示例展示了所提方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a deep learning framework for correcting existing dynamical systemmodels utilizing only a scarce high-fidelity data set. In many practicalsituations, one has a low-fidelity model that can capture the dynamicsreasonably well but lacks high resolution, due to the inherent limitation ofthe model and the complexity of the underlying physics. When high resolutiondata become available, it is natural to seek model correction to improve theresolution of the model predictions. We focus on the case when the amount ofhigh-fidelity data is so small that most of the existing data driven modelingmethods cannot be applied. In this paper, we address these challenges with amodel-correction method which only requires a scarce high-fidelity data set.Our method first seeks a deep neural network (DNN) model to approximate theexisting low-fidelity model. By using the scarce high-fidelity data, the methodthen corrects the DNN model via transfer learning (TL). After TL, an improvedDNN model with high prediction accuracy to the underlying dynamics is obtained.One distinct feature of the propose method is that it does not assume aspecific form of the model correction terms. Instead, it offers an inherentcorrection to the low-fidelity model via TL. A set of numerical examples arepresented to demonstrate the effectiveness of the proposed method.</description>
      <author>example@mail.com (Caroline Tatsuoka, Dongbin Xiu)</author>
      <guid isPermaLink="false">2410.17913v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Graph Neural Networks and Multi-Agent Reinforcement Learning for Inventory Control in Supply Chains</title>
      <link>http://arxiv.org/abs/2410.18631v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;现代供应链中的库存控制因面临众多干扰性冲击及复杂动态而备受关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种新方法，以应对传统方法在变化环境中的适应性不足。&lt;h4&gt;方法&lt;/h4&gt;采用多智能体强化学习（MARL）框架与图神经网络（GNN）结合，重新定义行动空间，以适应动态参数调整的启发式库存控制策略。&lt;h4&gt;主要发现&lt;/h4&gt;新框架利用供应链的图结构，使智能体能够学习系统拓扑，并通过集中学习、分散执行的方式实现协作学习，克服信息共享限制。&lt;h4&gt;结论&lt;/h4&gt;提出的MARL-GNN框架可有效改善复杂去中心化供应链环境中的库存管理。&lt;h4&gt;总结&lt;/h4&gt;本研究为在复杂供应链环境中应用MARL-GNN框架提供了理论基础和实践指导。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inventory control in modern supply chains has attracted significant attentiondue to the increasing number of disruptive shocks and the challenges posed bycomplex dynamics, uncertainties, and limited collaboration. Traditionalmethods, which often rely on static parameters, struggle to adapt to changingenvironments. This paper proposes a Multi-Agent Reinforcement Learning (MARL)framework with Graph Neural Networks (GNNs) for state representation to addressthese limitations.  Our approach redefines the action space by parameterizing heuristic inventorycontrol policies, making it adaptive as the parameters dynamically adjust basedon system conditions. By leveraging the inherent graph structure of supplychains, our framework enables agents to learn the system's topology, and weemploy a centralized learning, decentralized execution scheme that allowsagents to learn collaboratively while overcoming information-sharingconstraints. Additionally, we incorporate global mean pooling andregularization techniques to enhance performance.  We test the capabilities of our proposed approach on four different supplychain configurations and conduct a sensitivity analysis. This work paves theway for utilizing MARL-GNN frameworks to improve inventory management incomplex, decentralized supply chain environments.</description>
      <author>example@mail.com (Niki Kotecha, Antonio del Rio Chanona)</author>
      <guid isPermaLink="false">2410.18631v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>PointPatchRL -- Masked Reconstruction Improves Reinforcement Learning on Point Clouds</title>
      <link>http://arxiv.org/abs/2410.18800v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 15 figures, accepted for publication at the 8th Conference
  on Robot Learning (CoRL 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;通过摄像头感知环境对机器人中的强化学习至关重要，但图像在提取几何细节时常常变得复杂，尤其是在几何形状变化或可变形物体的情况下。&lt;h4&gt;目的&lt;/h4&gt;研究点云在强化学习中的应用，克服图像表示带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;提出PointPatchRL (PPRL)方法，采用将点云划分为重叠补丁、对其进行标记并使用变压器处理这些标记的常见范式。&lt;h4&gt;主要发现&lt;/h4&gt;PPRL在点云处理架构中显著优于先前用于强化学习的其他方法，尤其是在复杂操控任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;PPRL结合了掩蔽重建的表示学习，超越了强大的无模型和基于模型的基准测试，成功处理可变形物体和目标物体几何变化。&lt;h4&gt;总结&lt;/h4&gt;点云在强化学习中的应用尚待深入研究，PPRL方法展示了其潜力，并提供了有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perceiving the environment via cameras is crucial for Reinforcement Learning(RL) in robotics. While images are a convenient form of representation, theyoften complicate extracting important geometric details, especially withvarying geometries or deformable objects. In contrast, point clouds naturallyrepresent this geometry and easily integrate color and positional data frommultiple camera views. However, while deep learning on point clouds has seenmany recent successes, RL on point clouds is under-researched, with only thesimplest encoder architecture considered in the literature. We introducePointPatchRL (PPRL), a method for RL on point clouds that builds on the commonparadigm of dividing point clouds into overlapping patches, tokenizing them,and processing the tokens with transformers. PPRL provides significantimprovements compared with other point-cloud processing architecturespreviously used for RL. We then complement PPRL with masked reconstruction forrepresentation learning and show that our method outperforms strong model-freeand model-based baselines on image observations in complex manipulation taskscontaining deformable objects and variations in target object geometry. Videosand code are available at https://alrhub.github.io/pprl-website</description>
      <author>example@mail.com (Balázs Gyenes, Nikolai Franke, Philipp Becker, Gerhard Neumann)</author>
      <guid isPermaLink="false">2410.18800v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Learning Global Object-Centric Representations via Disentangled Slot Attention</title>
      <link>http://arxiv.org/abs/2410.18809v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Global Object-Centric Representations, Object Identification,
  Unsupervised Learning, Disentangled Learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;人类能够识别对象的场景独立特征，在不同环境中迅速识别对象，尽管存在光照、视角、大小和位置等变化。&lt;h4&gt;目的&lt;/h4&gt;提出一种新颖的对象中心学习方法，使AI系统具备人类在不同场景中识别对象的能力，并能够生成包含特定对象的多样场景。&lt;h4&gt;方法&lt;/h4&gt;设计了一个解耦槽注意力模块，将场景特征转化为场景依赖属性（如尺度、位置和方向）和场景独立表示（如外观和形状），以学习全局对象中心表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果验证了该方法的有效性，在全球对象中心表示学习、对象识别、特定对象的场景生成和场景分解等方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法显著提升了AI系统在复杂场景中的对象识别和生成能力，接近人类的识别水平。&lt;h4&gt;总结&lt;/h4&gt;该研究为AI在场景变化条件下的对象识别和生成提供了新的思路，推动了对象中心学习的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans can discern scene-independent features of objects across variousenvironments, allowing them to swiftly identify objects amidst changing factorssuch as lighting, perspective, size, and position and imagine the completeimages of the same object in diverse settings. Existing object-centric learningmethods only extract scene-dependent object-centric representations, lackingthe ability to identify the same object across scenes as humans. Moreover, someexisting methods discard the individual object generation capabilities tohandle complex scenes. This paper introduces a novel object-centric learningmethod to empower AI systems with human-like capabilities to identify objectsacross scenes and generate diverse scenes containing specific objects bylearning a set of global object-centric representations. To learn the globalobject-centric representations that encapsulate globally invariant attributesof objects (i.e., the complete appearance and shape), this paper designs aDisentangled Slot Attention module to convert the scene features intoscene-dependent attributes (such as scale, position and orientation) andscene-independent representations (i.e., appearance and shape). Experimentalresults substantiate the efficacy of the proposed method, demonstratingremarkable proficiency in global object-centric representation learning, objectidentification, scene generation with specific objects and scene decomposition.</description>
      <author>example@mail.com (Tonglin Chen, Yinxuan Huang, Zhimeng Shen, Jinghao Huang, Bin Li, Xiangyang Xue)</author>
      <guid isPermaLink="false">2410.18809v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Transferring Knowledge from High-Quality to Low-Quality MRI for Adult Glioma Diagnosis</title>
      <link>http://arxiv.org/abs/2410.18698v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report, MICCAI 2024 BraTS-SSA Challenge Runner Up&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;胶质瘤是一种常见且致命的脑肿瘤，早期诊断对于改善预后至关重要，但撒哈拉以南非洲的低质量磁共振成像技术阻碍了准确诊断。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在提高对撒哈拉以南非洲成人胶质瘤的诊断效果。&lt;h4&gt;方法&lt;/h4&gt;采用BraTS-GLI 2021获胜模型，结合三种训练策略：1. 在BraTS-GLI 2021数据集上初步训练，然后在BraTS-Africa数据集上微调；2. 仅在BraTS-Africa数据集上训练；3. 在BraTS-Africa数据集上训练，并使用2倍超分辨率增强。&lt;h4&gt;主要发现&lt;/h4&gt;初步在BraTS-GLI 2021数据集上训练，然后微调BraTS-Africa数据集的策略效果最佳。我们的模型在验证阶段的Dice分数分别为0.882、0.840和0.926，Hausdorff距离（95%）得分分别为15.324、37.518和13.971。&lt;h4&gt;结论&lt;/h4&gt;该方法在比赛的最终阶段成功获得第二名，显示了模型和训练策略的有效性。研究表明高质量数据集在训练中提供先前知识的重要性，并展示了深度学习在资源有限环境中的潜力。&lt;h4&gt;总结&lt;/h4&gt;本研究为改善撒哈拉以南非洲的胶质瘤诊断提供了见解，强调了从高质量数据集中进行迁移学习的重要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Glioma, a common and deadly brain tumor, requires early diagnosis forimproved prognosis. However, low-quality Magnetic Resonance Imaging (MRI)technology in Sub-Saharan Africa (SSA) hinders accurate diagnosis. This paperpresents our work in the BraTS Challenge on SSA Adult Glioma. We adopt themodel from the BraTS-GLI 2021 winning solution and utilize it with threetraining strategies: (1) initially training on the BraTS-GLI 2021 dataset withfine-tuning on the BraTS-Africa dataset, (2) training solely on theBraTS-Africa dataset, and (3) training solely on the BraTS-Africa dataset with2x super-resolution enhancement. Results show that initial training on theBraTS-GLI 2021 dataset followed by fine-tuning on the BraTS-Africa dataset hasyielded the best results. This suggests the importance of high-quality datasetsin providing prior knowledge during training. Our top-performing model achievesDice scores of 0.882, 0.840, and 0.926, and Hausdorff Distance (95%) scores of15.324, 37.518, and 13.971 for enhancing tumor, tumor core, and whole tumor,respectively, in the validation phase. In the final phase of the competition,our approach successfully secured second place overall, reflecting the strengthand effectiveness of our model and training strategies. Our approach providesinsights into improving glioma diagnosis in SSA, showing the potential of deeplearning in resource-limited settings and the importance of transfer learningfrom high-quality datasets.</description>
      <author>example@mail.com (Yanguang Zhao, Long Bai, Zhaoxi Zhang, Yanan Wu, Mobarakol Islam, Hongliang Ren)</author>
      <guid isPermaLink="false">2410.18698v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Meta-Learning with Heterogeneous Tasks</title>
      <link>http://arxiv.org/abs/2410.18894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;元学习是一种普遍的方法，使机器学习模型能够应对少量样本的多任务场景。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的元学习方法，以有效管理异构任务。&lt;h4&gt;方法&lt;/h4&gt;引入基于排名的任务级学习目标的异构任务鲁棒元学习方法（HeTRoM）。&lt;h4&gt;主要发现&lt;/h4&gt;HeTRoM能够有效处理异构任务，防止简单任务压倒元学习者。&lt;h4&gt;结论&lt;/h4&gt;该方法通过双层优化的高效迭代优化算法和统计指导的整合，提升了元学习者的整体性能。&lt;h4&gt;总结&lt;/h4&gt;实验结果表明，HeTRoM提供了灵活性，使用户能够适应多样的任务设置，并增强了元学习者的表现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Meta-learning is a general approach to equip machine learning models with theability to handle few-shot scenarios when dealing with many tasks. Mostexisting meta-learning methods work based on the assumption that all tasks areof equal importance. However, real-world applications often presentheterogeneous tasks characterized by varying difficulty levels, noise intraining samples, or being distinctively different from most other tasks. Inthis paper, we introduce a novel meta-learning method designed to effectivelymanage such heterogeneous tasks by employing rank-based task-level learningobjectives, Heterogeneous Tasks Robust Meta-learning (HeTRoM). HeTRoM isproficient in handling heterogeneous tasks, and it prevents easy tasks fromoverwhelming the meta-learner. The approach allows for an efficient iterativeoptimization algorithm based on bi-level optimization, which is then improvedby integrating statistical guidance. Our experimental results demonstrate thatour method provides flexibility, enabling users to adapt to diverse tasksettings and enhancing the meta-learner's overall performance.</description>
      <author>example@mail.com (Zhaofeng Si, Shu Hu, Kaiyi Ji, Siwei Lyu)</author>
      <guid isPermaLink="false">2410.18894v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>RANSAC Back to SOTA: A Two-stage Consensus Filtering for Real-time 3D Registration</title>
      <link>http://arxiv.org/abs/2410.15682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;基于对应关系的点云配准在机器人技术和计算机视觉中扮演重要角色，但面临传感器噪声、物体遮挡和描述子限制等挑战，导致大量异常值产生。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法以提高RANSAC的速度和准确性。&lt;h4&gt;方法&lt;/h4&gt;提出两阶段共识滤波（TCF），首先通过单点RANSAC基于长度一致性获取共识集，然后通过双点RANSAC和角度一致性进行精细化，最后使用三点RANSAC计算粗略姿态并去除异常值，最终应用迭代加权最小二乘法（IRLS）获得最优姿态。&lt;h4&gt;主要发现&lt;/h4&gt;在KITTI和ETH大规模数据集上的实验表明，该方法相比于MAC在速度上提升了三个数量级，同时保持了配准的准确性和召回率。&lt;h4&gt;结论&lt;/h4&gt;TCF方法显著提高了点云配准的效率和准确性，提供了有效的异常值去除方案。&lt;h4&gt;总结&lt;/h4&gt;本研究提出的TCF方法在点云配准中实现了速度和准确性的重大突破，代码可在GitHub上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/shipc-ai/tcf&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Correspondence-based point cloud registration (PCR) plays a key role inrobotics and computer vision. However, challenges like sensor noises, objectocclusions, and descriptor limitations inevitably result in numerous outliers.RANSAC family is the most popular outlier removal solution. However, therequisite iterations escalate exponentially with the outlier ratio, renderingit far inferior to existing methods (SC2PCR [1], MAC [2], etc.) in terms ofaccuracy or speed. Thus, we propose a two-stage consensus filtering (TCF) thatelevates RANSAC to state-of-the-art (SOTA) speed and accuracy. Firstly,one-point RANSAC obtains a consensus set based on length consistency.Subsequently, two-point RANSAC refines the set via angle consistency. Then,three-point RANSAC computes a coarse pose and removes outliers based ontransformed correspondence's distances. Drawing on optimizations from one-pointand two-point RANSAC, three-point RANSAC requires only a few iterations.Eventually, an iterative reweighted least squares (IRLS) is applied to yieldthe optimal pose. Experiments on the large-scale KITTI and ETH datasetsdemonstrate our method achieves up to three-orders-of-magnitude speedupcompared to MAC while maintaining registration accuracy and recall. Our code isavailable at https://github.com/ShiPC-AI/TCF.</description>
      <author>example@mail.com (Pengcheng Shi, Shaocheng Yan, Yilin Xiao, Xinyi Liu, Yongjun Zhang, Jiayuan Li)</author>
      <guid isPermaLink="false">2410.15682v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing pretraining efficiency for medical image segmentation via transferability metrics</title>
      <link>http://arxiv.org/abs/2410.18677v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;医学图像分割任务中，标记训练数据稀缺对深度神经网络训练构成重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究在医学图像分割数据集上，使用ImageNet预训练模型的各种训练设置。&lt;h4&gt;方法&lt;/h4&gt;通过检查超过300种模型、数据集和训练方法的组合，分析预训练对下游任务的影响。&lt;h4&gt;主要发现&lt;/h4&gt;较短的预训练时间通常能在下游任务上取得更好的结果，表明ImageNet上的准确性不一定能预测下游性能。&lt;h4&gt;结论&lt;/h4&gt;提出了一种基于对比学习的新型可转移性度量，能够有效评估预训练模型在目标数据上的表现能力。&lt;h4&gt;应用&lt;/h4&gt;通过在预训练阶段测量可鲁棒性分数，指示何时模型权重最适合下游转移，从而减少预训练时间并提高目标任务的结果。&lt;h4&gt;总结&lt;/h4&gt;研究揭示了预训练与下游任务性能之间的复杂关系，并提供了一种新的评估方法，以优化医学图像分割的训练过程。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/aielte-research/MedSegPretrainImageNet&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In medical image segmentation tasks, the scarcity of labeled training dataposes a significant challenge when training deep neural networks. When usingU-Net-style architectures, it is common practice to address this problem bypretraining the encoder part on a large general-purpose dataset like ImageNet.However, these methods are resource-intensive and do not guarantee improvedperformance on the downstream task. In this paper we investigate a variety oftraining setups on medical image segmentation datasets, usingImageNet-pretrained models. By examining over 300 combinations of models,datasets, and training methods, we find that shorter pretraining often leads tobetter results on the downstream task, providing additional proof to thewell-known fact that the accuracy of the model on ImageNet is a poor indicatorfor downstream performance. As our main contribution, we introduce a noveltransferability metric, based on contrastive learning, that measures howrobustly a pretrained model is able to represent the target data. In contrastto other transferability scores, our method is applicable to the case oftransferring from ImageNet classification to medical image segmentation. Weapply our robustness score by measuring it throughout the pretraining phase toindicate when the model weights are optimal for downstream transfer. Thisreduces pretraining time and improves results on the target task.</description>
      <author>example@mail.com (Gábor Hidy, Bence Bakos, András Lukács)</author>
      <guid isPermaLink="false">2410.18677v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Learning Structured Compressed Sensing with Automatic Resource Allocation</title>
      <link>http://arxiv.org/abs/2410.18954v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Unsupervised Learning, Information Theory, Compressed Sensing,
  Subsampling&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;多维数据采集通常需要大量时间，并对硬件和软件在数据存储和处理方面提出重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决传统压缩感知中的单一压缩矩阵设计问题，并优化资源分配。&lt;h4&gt;方法&lt;/h4&gt;引入结构化压缩感知与自动资源分配（SCOSARA），采用基于信息理论的无监督学习策略，适应性地在采样维度间分配样本。&lt;h4&gt;主要发现&lt;/h4&gt;SCOSARA在超声定位案例中，与最先进的机器学习算法和贪心搜索算法相比，能够生成高质量的子采样矩阵，达到比基线更低的Cramér-Rao界限值。&lt;h4&gt;结论&lt;/h4&gt;SCOSARA在可训练参数数量、计算复杂度和内存需求方面优于其他基于机器学习的算法，同时自动选择每个轴的样本数量。&lt;h4&gt;总结&lt;/h4&gt;SCOSARA通过优化采样资源分配，提高了多维数据采集的效率，展现出良好的性能优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multidimensional data acquisition often requires extensive time and posessignificant challenges for hardware and software regarding data storage andprocessing. Rather than designing a single compression matrix as inconventional compressed sensing, structured compressed sensing yieldsdimension-specific compression matrices, reducing the number of optimizableparameters. Recent advances in machine learning (ML) have enabled task-basedsupervised learning of subsampling matrices, albeit at the expense of complexdownstream models. Additionally, the sampling resource allocation acrossdimensions is often determined in advance through heuristics. To address thesechallenges, we introduce Structured COmpressed Sensing with Automatic ResourceAllocation (SCOSARA) with an information theory-based unsupervised learningstrategy. SCOSARA adaptively distributes samples across sampling dimensionswhile maximizing Fisher information content. Using ultrasound localization as acase study, we compare SCOSARA to state-of-the-art ML-based and greedy searchalgorithms. Simulation results demonstrate that SCOSARA can producehigh-quality subsampling matrices that achieve lower Cram\'er-Rao Bound valuesthan the baselines. In addition, SCOSARA outperforms other ML-based algorithmsin terms of the number of trainable parameters, computational complexity, andmemory requirements while automatically choosing the number of samples peraxis.</description>
      <author>example@mail.com (Han Wang, Eduardo Pérez, Iris A. M. Huijben, Hans van Gorp, Ruud van Sloun, Florian Römer)</author>
      <guid isPermaLink="false">2410.18954v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling</title>
      <link>http://arxiv.org/abs/2410.18912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://gs-dynamics.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;机器人的视频与物体交互录制了丰富的物体动态信息，但现有的视频预测方法通常未明确考虑视频中的三维信息，限制了其在实际机器人应用中的使用。&lt;h4&gt;目的&lt;/h4&gt;提出一个框架，通过显式考虑机器人动作轨迹及其对场景动态的影响，从多视角RGB视频中直接学习物体动态。&lt;h4&gt;方法&lt;/h4&gt;利用3D高斯表示法的3D高斯喷涂（3DGS）技术，通过图神经网络训练基于粒子的动态模型，该模型在从密集跟踪的3D高斯重建中下采样的稀疏控制粒子上运行。&lt;h4&gt;主要发现&lt;/h4&gt;通过在离线机器人交互数据上学习神经动态模型，我们的方法能够在不同初始配置和未见过的机器人动作下预测物体运动。&lt;h4&gt;结论&lt;/h4&gt;高斯的3D变换可以从控制粒子的运动中进行插值，从而实现预测未来物体状态的渲染，并实现基于动作的视频预测。该动态模型还可应用于物体操作任务的基于模型的规划框架。&lt;h4&gt;实验结果&lt;/h4&gt;在多种可变形材料（如绳子、衣物和毛绒玩具）上进行实验，证明了框架建模复杂形状和动态的能力。&lt;h4&gt;总结&lt;/h4&gt;该研究为机器人与物体交互的视频分析提供了一种新的动态建模方法，能够有效处理复杂的物体行为和形状变化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Videos of robots interacting with objects encode rich information about theobjects' dynamics. However, existing video prediction approaches typically donot explicitly account for the 3D information from videos, such as robotactions and objects' 3D states, limiting their use in real-world roboticapplications. In this work, we introduce a framework to learn object dynamicsdirectly from multi-view RGB videos by explicitly considering the robot'saction trajectories and their effects on scene dynamics. We utilize the 3DGaussian representation of 3D Gaussian Splatting (3DGS) to train aparticle-based dynamics model using Graph Neural Networks. This model operateson sparse control particles downsampled from the densely tracked 3D Gaussianreconstructions. By learning the neural dynamics model on offline robotinteraction data, our method can predict object motions under varying initialconfigurations and unseen robot actions. The 3D transformations of Gaussianscan be interpolated from the motions of control particles, enabling therendering of predicted future object states and achieving action-conditionedvideo prediction. The dynamics model can also be applied to model-basedplanning frameworks for object manipulation tasks. We conduct experiments onvarious kinds of deformable materials, including ropes, clothes, and stuffedanimals, demonstrating our framework's ability to model complex shapes anddynamics. Our project page is available at https://gs-dynamics.github.io.</description>
      <author>example@mail.com (Mingtong Zhang, Kaifeng Zhang, Yunzhu Li)</author>
      <guid isPermaLink="false">2410.18912v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques</title>
      <link>http://arxiv.org/abs/2410.18972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;认知衰退是衰老的自然部分，常导致认知能力下降，某些情况下因阿尔茨海默病等疾病导致更明显的衰退。&lt;h4&gt;目的&lt;/h4&gt;早期检测异常认知衰退，以便进行及时的专业干预。&lt;h4&gt;方法&lt;/h4&gt;采用非侵入性技术，如语音或书写分析，结合深度学习技术自动化认知衰退评估，包括音频、文本和视觉处理。&lt;h4&gt;主要发现&lt;/h4&gt;文本模态在大多数情况下取得最佳结果，并且在检测认知衰退方面最为相关。多模态模型通过结合不同模态的方法，普遍提升了表现。&lt;h4&gt;结论&lt;/h4&gt;结合不同模态的方法能够在几乎所有场景中持续增强性能。&lt;h4&gt;总结&lt;/h4&gt;通过综述相关方法和数据集，强调了深度学习在认知衰退自动评估中的重要性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cognitive decline is a natural part of aging, often resulting in reducedcognitive abilities. In some cases, however, this decline is more pronounced,typically due to disorders such as Alzheimer's disease. Early detection ofanomalous cognitive decline is crucial, as it can facilitate timelyprofessional intervention. While medical data can help in this detection, itoften involves invasive procedures. An alternative approach is to employnon-intrusive techniques such as speech or handwriting analysis, which do notnecessarily affect daily activities. This survey reviews the most relevantmethodologies that use deep learning techniques to automate the cognitivedecline estimation task, including audio, text, and visual processing. Wediscuss the key features and advantages of each modality and methodology,including state-of-the-art approaches like Transformer architecture andfoundation models. In addition, we present works that integrate differentmodalities to develop multimodal models. We also highlight the most significantdatasets and the quantitative results from studies using these resources. Fromthis review, several conclusions emerge. In most cases, the textual modalityachieves the best results and is the most relevant for detecting cognitivedecline. Moreover, combining various approaches from individual modalities intoa multimodal model consistently enhances performance across nearly allscenarios.</description>
      <author>example@mail.com (David Ortiz-Perez, Manuel Benavent-Lledo, Jose Garcia-Rodriguez, David Tomás, M. Flores Vizcaya-Moreno)</author>
      <guid isPermaLink="false">2410.18972v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Cooperative nonlinear distributed model predictive control with dissimilar control horizons</title>
      <link>http://arxiv.org/abs/2410.10428v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;当前的非线性分布式模型预测控制(DMPC)方案存在控制视野不一致和时间变化的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的DMPC算法，允许代理之间具有不同的和时间变化的控制视野。&lt;h4&gt;方法&lt;/h4&gt;考虑具有不同计算能力和操作目标的合作代理，每个代理在每个时间步管理不同数量的优化变量。&lt;h4&gt;主要发现&lt;/h4&gt;证明了所提算法的递归可行性和最优成本的非递增演变。通过对三个代理的系统进行数值仿真，展示了该方法有效地接近传统DMPC的性能，同时减少了优化变量的数量。&lt;h4&gt;结论&lt;/h4&gt;该进展为在电力系统和交通管理等各类应用中实现更去中心化但协调的控制策略铺平了道路。&lt;h4&gt;总结&lt;/h4&gt;新的DMPC算法解决了现有方案的限制，提高了控制的灵活性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a nonlinear distributed model predictive control(DMPC) algorithm, which allows for dissimilar and time-varying control horizonsamong agents, thereby addressing a common limitation in current DMPC schemes.We consider cooperative agents with varying computational capabilities andoperational objectives, each willing to manage varying numbers of optimizationvariables at each time step. Recursive feasibility and a non-increasingevolution of the optimal cost are proven for the proposed algorithm. Throughnumerical simulations on systems with three agents, we show that our approacheffectively approximates the performance of traditional DMPC, while reducingthe number of variables to be optimized. This advancement paves the way for amore decentralized yet coordinated control strategy in various applications,including power systems and traffic management.</description>
      <author>example@mail.com (Paula Chanfreut, José M. Maestre, Quanyan Zhu, W. P. M. H. Heemels)</author>
      <guid isPermaLink="false">2410.10428v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting</title>
      <link>http://arxiv.org/abs/2410.11674v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Time series forecasting using LLMs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;时间序列预测是一项具有挑战性的任务，尤其是在复杂多尺度时间模式的上下文中。&lt;h4&gt;目的&lt;/h4&gt;本研究提出LLM-Mixer框架，旨在通过结合多尺度时间序列分解与预训练的大型语言模型（LLMs）来提高预测准确性。&lt;h4&gt;方法&lt;/h4&gt;LLM-Mixer通过将数据分解为多个时间分辨率，捕捉短期波动和长期趋势，并使用一个冻结的LLM，辅以专为时间序列数据设计的文本提示进行处理。&lt;h4&gt;主要发现&lt;/h4&gt;在多变量和单变量数据集上进行的广泛实验表明，LLM-Mixer在各种预测时间范围内的表现优于最近的最先进模型。&lt;h4&gt;结论&lt;/h4&gt;本研究强调了结合多尺度分析与LLMs在有效且可扩展的时间序列预测中的潜力。&lt;h4&gt;总结&lt;/h4&gt;LLM-Mixer框架为时间序列预测提供了一种新的方法，通过多尺度分析和语言模型的结合，显著提升了预测性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/Kowsher/LLMMixer&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting remains a challenging task, particularly in thecontext of complex multiscale temporal patterns. This study presents LLM-Mixer,a framework that improves forecasting accuracy through the combination ofmultiscale time-series decomposition with pre-trained LLMs (Large LanguageModels). LLM-Mixer captures both short-term fluctuations and long-term trendsby decomposing the data into multiple temporal resolutions and processing themwith a frozen LLM, guided by a textual prompt specifically designed fortime-series data. Extensive experiments conducted on multivariate andunivariate datasets demonstrate that LLM-Mixer achieves competitiveperformance, outperforming recent state-of-the-art models across variousforecasting horizons. This work highlights the potential of combiningmultiscale analysis and LLMs for effective and scalable time-seriesforecasting.</description>
      <author>example@mail.com (Md Kowsher, Md. Shohanur Islam Sobuj, Nusrat Jahan Prottasha, E. Alejandro Alanis, Ozlem Ozmen Garibay, Niloofar Yousefi)</author>
      <guid isPermaLink="false">2410.11674v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Routing on Sparse Graphs with Non-metric Costs for the Prize-collecting Travelling Salesperson Problem</title>
      <link>http://arxiv.org/abs/2410.10440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ATT'24: Workshop Agents in Traffic and Transportation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;许多现实世界的路由问题涉及到优化稀疏图，如不满足三角不等式的交通网络。&lt;h4&gt;目的&lt;/h4&gt;研究在非度量成本的稀疏图上寻找最小化跑步者空气污染暴露的足够长的行驶路线。&lt;h4&gt;方法&lt;/h4&gt;研究奖赏收集旅行商问题（Pc-TSP），提出针对稀疏图的启发式算法，并开发一种新的分支切割算法，称为不相交路径成本覆盖（DPCC）切割。&lt;h4&gt;主要发现&lt;/h4&gt;实验证明，提出的启发式算法在两个数据集上能以低于文献中最先进的启发式算法的成本产生可行解。DPCC在非度量成本的数据集中比基线切割算法解决更多问题至最优解。&lt;h4&gt;结论&lt;/h4&gt;所提出的算法在处理稀疏图及非度量成本的旅行问题上表现出色，提供了有效的解决方案。&lt;h4&gt;总结&lt;/h4&gt;本研究为稀疏图的优化问题提供了新的算法思路和实证支持，特别是在非度量成本的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many real-world routing problems, decision makers must optimise oversparse graphs such as transportation networks with non-metric costs on theedges that do not obey the triangle inequality. Motivated by finding asufficiently long running route in a city that minimises the air pollutionexposure of the runner, we study the Prize-collecting Travelling SalespersonProblem (Pc-TSP) on sparse graphs with non-metric costs. Given an undirectedgraph with a cost function on the edges and a prize function on the vertices,the goal of Pc-TSP is to find a tour rooted at the origin that minimises thetotal cost such that the total prize is at least some quota. First, weintroduce heuristics designed for sparse graphs with non-metric cost functionswhere previous work dealt with either a complete graph or a metric costfunction. Next, we develop a branch &amp; cut algorithm that employs a new cut wecall the disjoint-paths cost-cover (DPCC) cut. Empirical experiments on twodatasets show that our heuristics can produce a feasible solution with lesscost than a state-of-the-art heuristic from the literature. On datasets withnon-metric cost functions, DPCC is found to solve more instances to optimalitythan the baseline cutting algorithm we compare against.</description>
      <author>example@mail.com (Patrick O'Hara, M. S. Ramanujan, Theodoros Damoulas)</author>
      <guid isPermaLink="false">2410.10440v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
    </item>
    <item>
      <title>Time-Series Foundation Model for Value-at-Risk</title>
      <link>http://arxiv.org/abs/2410.11773v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  None&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;背景&lt;/h4&gt;本研究首次探讨了时间序列基础模型在VaR估计中的应用。&lt;h4&gt;目的&lt;/h4&gt;比较Google的TimesFM模型与传统参数和非参数模型在VaR估计中的表现。&lt;h4&gt;方法&lt;/h4&gt;使用S&amp;P 100指数及其成分股的每日收益数据，对TimesFM、GARCH、GAS和经验分位数估计进行回测。&lt;h4&gt;主要发现&lt;/h4&gt;经过微调的TimesFM模型在实际与预期比率方面始终优于传统方法，且在分位数损失函数上与最佳计量经济学方法GAS模型表现相当。&lt;h4&gt;结论&lt;/h4&gt;基础模型在0.01、0.025、0.05和0.1 VaR水平的预测中要么是最佳，要么是顶尖表现者；微调显著改善结果，模型不应在零-shot设置中使用。&lt;h4&gt;挑战&lt;/h4&gt;基础模型提供了与传统计量经济方法完全不同的方法，但仍然存在需解决的挑战。&lt;h4&gt;总结&lt;/h4&gt;基础模型在VaR预测中展现出良好性能，未来有望替代传统方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2024-10-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; None&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/anubha0812/timesfm-for-value-at-risk&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study is the first to explore the application of a time-seriesfoundation model for VaR estimation. Foundation models, pre-trained on vast andvaried datasets, can be used in a zero-shot setting with relatively minimaldata or further improved through finetuning. We compare the performance ofGoogle's model, called TimesFM, against conventional parametric andnon-parametric models, including GARCH, Generalized Autoregressive Score (GAS),and empirical quantile estimates, using daily returns from the S\&amp;P 100 indexand its constituents over 19 years. Our backtesting results indicate that, interms of the actual-over-expected ratio, the fine-tuned TimesFM modelconsistently outperforms traditional methods. Regarding the quantile score lossfunction, it achieves performance comparable to the best econometric approach,the GAS model. Overall, the foundation model is either the best or among thetop performers in forecasting VaR across the 0.01, 0.025, 0.05, and 0.1 VaRlevels. We also found that fine-tuning significantly improves the results, andthe model should not be used in zero-shot settings. Overall, foundation modelscan provide completely alternative approaches to traditional econometricmethods, yet there are challenges to be tackled.</description>
      <author>example@mail.com (Anubha Goel, Puneet Pasricha, Juho Kanniainen)</author>
      <guid isPermaLink="false">2410.11773v1</guid>
      <pubDate>Fri, 25 Oct 2024 18:27:50 +0800</pubDate>
>>>>>>> a1ed6ea7a9bdf8f268580b63b47c5db98fe52dd2
    </item>
  </channel>
</rss>
