<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0">
  <channel>
    <title>Arxiv论文推荐</title>
    <link>https://github.com/lionelsy/RSS</link>
    <description>Arxiv论文推荐</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 04 Jul 2025 14:21:33 +0800</lastBuildDate>
    <item>
      <title>Are Fast Methods Stable in Adversarially Robust Transfer Learning?</title>
      <link>http://arxiv.org/abs/2506.22602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了快速梯度符号方法（FGSM）在鲁棒迁移学习中的应用，以提高对抗性微调的计算成本。&lt;h4&gt;背景&lt;/h4&gt;迁移学习常用于降低模型训练的计算成本，特别是在提高对抗鲁棒性方面。然而，高鲁棒性需要额外的对抗训练，这比标准微调要耗时得多。&lt;h4&gt;目的&lt;/h4&gt;旨在通过使用FGSM来改进对抗性微调的计算成本，同时保持模型性能。&lt;h4&gt;方法&lt;/h4&gt;本文重新审视了FGSM在鲁棒迁移学习中的应用，并评估了其在不同ε值下的稳定性和性能。&lt;h4&gt;主要发现&lt;/h4&gt;发现FGSM在对抗性微调中比从头开始训练更为稳定，且没有在标准扰动预算下出现灾难性过拟合的问题。参数高效的微调方法进一步增强了这种稳定性。&lt;h4&gt;结论&lt;/h4&gt;FGSM不仅在对抗鲁棒迁移学习中是一个更有效的替代方案，而且也是一个性能良好的方法。与使用投影梯度下降（PGD）的微调相比，FGSM在ε=4和ε=8的情况下仅损失0.39%和1.39%的测试鲁棒性，同时训练时间减少了4倍。&lt;h4&gt;翻译&lt;/h4&gt;Transfer learning is often used to decrease the computational cost of model training, as fine-tuning a model allows a downstream task to leverage the features learned from the pre-training dataset and quickly adapt them to a new task. This is particularly useful for achieving adversarial robustness, as adversarially training models from scratch is very computationally expensive. However, high robustness in transfer learning still requires adversarial training during the fine-tuning phase, which requires up to an order of magnitude more time than standard fine-tuning. In this work, we revisit the use of the fast gradient sign method (FGSM) in robust transfer learning to improve the computational cost of adversarial fine-tuning. We surprisingly find that FGSM is much more stable in adversarial fine-tuning than when training from scratch. In particular, FGSM fine-tuning does not suffer from any issues with catastrophic overfitting at standard perturbation budgets of ε=4 or ε=8. This stability is further enhanced with parameter-efficient fine-tuning methods, where FGSM remains stable even up to ε=32 for linear probing. We demonstrate how this stability translates into performance across multiple datasets. Compared to fine-tuning with the more commonly used method of projected gradient descent (PGD), on average, FGSM only loses 0.39% and 1.39% test robustness for ε=4 and ε=8 while using 4 times less training time. Surprisingly, FGSM may not only be a significantly more efficient alternative to PGD in adversarially robust transfer learning but also a well-performing one.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is often used to decrease the computational cost of modeltraining, as fine-tuning a model allows a downstream task to leverage thefeatures learned from the pre-training dataset and quickly adapt them to a newtask. This is particularly useful for achieving adversarial robustness, asadversarially training models from scratch is very computationally expensive.However, high robustness in transfer learning still requires adversarialtraining during the fine-tuning phase, which requires up to an order ofmagnitude more time than standard fine-tuning. In this work, we revisit the useof the fast gradient sign method (FGSM) in robust transfer learning to improvethe computational cost of adversarial fine-tuning. We surprisingly find thatFGSM is much more stable in adversarial fine-tuning than when training fromscratch. In particular, FGSM fine-tuning does not suffer from any issues withcatastrophic overfitting at standard perturbation budgets of $\varepsilon=4$ or$\varepsilon=8$. This stability is further enhanced with parameter-efficientfine-tuning methods, where FGSM remains stable even up to $\varepsilon=32$ forlinear probing. We demonstrate how this stability translates into performanceacross multiple datasets. Compared to fine-tuning with the more commonly usedmethod of projected gradient descent (PGD), on average, FGSM only loses 0.39%and 1.39% test robustness for $\varepsilon=4$ and $\varepsilon=8$ while using$4\times$ less training time. Surprisingly, FGSM may not only be asignificantly more efficient alternative to PGD in adversarially robusttransfer learning but also a well-performing one.</description>
      <author>example@mail.com (Joshua C. Zhao, Saurabh Bagchi)</author>
      <guid isPermaLink="false">2506.22602v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
  <item>
      <title>Understanding Generalization in Node and Link Prediction</title>
      <link>http://arxiv.org/abs/2507.00927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2412.07106&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了消息传递图神经网络（MPNNs）在节点和链接预测中的泛化能力，并提出了一个统一的框架来分析其在归纳和转导节点和链接预测设置中的泛化性质。&lt;h4&gt;背景&lt;/h4&gt;MPNNs在科学和工业领域中的节点和链接预测至关重要，但它们在实际设置中的泛化能力以及对训练集之外的数据的泛化能力理解不足。&lt;h4&gt;目的&lt;/h4&gt;引入一个统一的框架来分析MPNNs在归纳和转导节点和链接预测设置中的泛化性质，并量化图结构的影响。&lt;h4&gt;方法&lt;/h4&gt;结合不同的架构参数和损失函数，并超越图结构来分析MPNNs的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;现有的工作通常依赖于不切实际的独立同分布（i.i.d.）假设，忽略了节点或链接之间的可能相关性，并假设固定的聚合和实际中不实用的损失函数。&lt;h4&gt;结论&lt;/h4&gt;提出的泛化框架可以应用于归纳或转导设置下的任何分类任务，并通过实证研究支持了理论见解，加深了对MPNNs泛化能力的理解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使用消息传递图神经网络（MPNNs）进行节点和链接预测在各个科学和工业领域至关重要，这导致了多种MPNN架构的发展。除了在实际设置中表现良好外，它们在训练集之外泛化的能力仍然理解不足。虽然一些研究探索了MPNNs在图级预测任务中的泛化，但很少关注节点和链接级别的预测。现有工作通常依赖于不切实际的i.i.d.假设，忽略了节点或链接之间的可能相关性，假设固定的聚合和不切实际的损失函数，而忽略了图结构的影响。在这项工作中，我们引入了一个统一的框架来分析MPNNs在归纳和转导节点和链接预测设置中的泛化性质，结合了不同的架构参数和损失函数，并量化了图结构的影响。此外，我们提出的泛化框架可以应用于归纳或转导设置下的任何分类任务。我们的实证研究支持了我们的理论见解，加深了我们对这些任务中MPNNs泛化能力的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Using message-passing graph neural networks (MPNNs) for node and linkprediction is crucial in various scientific and industrial domains, which hasled to the development of diverse MPNN architectures. Besides working well inpractical settings, their ability to generalize beyond the training set remainspoorly understood. While some studies have explored MPNNs' generalization ingraph-level prediction tasks, much less attention has been given to node- andlink-level predictions. Existing works often rely on unrealistic i.i.d.\@assumptions, overlooking possible correlations between nodes or links, andassuming fixed aggregation and impractical loss functions while neglecting theinfluence of graph structure. In this work, we introduce a unified framework toanalyze the generalization properties of MPNNs in inductive and transductivenode and link prediction settings, incorporating diverse architecturalparameters and loss functions and quantifying the influence of graph structure.Additionally, our proposed generalization framework can be applied beyondgraphs to any classification task under the inductive or transductive setting.Our empirical study supports our theoretical insights, deepening ourunderstanding of MPNNs' generalization capabilities in these tasks.</description>
      <author>example@mail.com (Antonis Vasileiou, Timo Stoll, Christopher Morris)</author>
      <guid isPermaLink="false">2507.00927v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Strategic Counterfactual Modeling of Deep-Target Airstrike Systems via Intervention-Aware Spatio-Causal Graph Networks</title>
      <link>http://arxiv.org/abs/2507.00083v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper proposes the first closed-loop causal modeling framework  (IA-STGNN) that links tactical strike variables to strategic delay outcomes  via graph neural networks with counterfactual reasoning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的框架IA-STGNN，用于解决当前战略级模拟中战术打击行为与战略延迟之间的结构化因果建模不足的问题，特别是在捕捉“韧性-节点抑制-谈判窗口”链中的中间变量方面的结构瓶颈。&lt;h4&gt;背景&lt;/h4&gt;当前战略级模拟缺乏对战术打击行为与战略延迟之间结构化因果建模，特别是在中间变量的捕捉上存在结构瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，即干预感知时空图神经网络（IA-STGNN），以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;IA-STGNN集成了图注意力机制、反事实模拟单元和空间干预节点重建，以实现打击配置和同步策略的动态模拟。训练数据来自符合NIST SP 800-160标准的多物理模拟平台（GEANT4 + COMSOL）。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，IA-STGNN在MAE减少12.8%和Top-5准确率提高18.4%的同时，显著优于基线模型（ST-GNN、GCN-LSTM、XGBoost），并提高了因果路径一致性和干预稳定性。&lt;h4&gt;结论&lt;/h4&gt;IA-STGNN能够实现战略延迟的可解释预测，支持核威慑模拟、外交窗口评估和多策略优化等应用，为高级政策建模提供了一种结构化和透明的AI决策支持机制。&lt;h4&gt;翻译&lt;/h4&gt;本研究针对当前战略级模拟中战术打击行为与战略延迟之间缺乏结构化因果建模的问题，特别是捕捉“韧性-节点抑制-谈判窗口”链中中间变量的结构瓶颈，提出了一种新的框架——干预感知时空图神经网络（IA-STGNN）。该模型集成了图注意力机制、反事实模拟单元和空间干预节点重建，以实现打击配置和同步策略的动态模拟。训练数据来自符合NIST SP 800-160标准的多物理模拟平台（GEANT4 + COMSOL）。实验结果表明，IA-STGNN在MAE减少12.8%和Top-5准确率提高18.4%的同时，显著优于基线模型（ST-GNN、GCN-LSTM、XGBoost），并提高了因果路径一致性和干预稳定性。IA-STGNN能够实现战略延迟的可解释预测，支持核威慑模拟、外交窗口评估和多策略优化等应用，为高级政策建模提供了一种结构化和透明的AI决策支持机制。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This study addresses the lack of structured causal modeling between tacticalstrike behavior and strategic delay in current strategic-level simulations,particularly the structural bottlenecks in capturing intermediate variableswithin the "resilience - nodal suppression - negotiation window" chain. Wepropose the Intervention-Aware Spatio-Temporal Graph Neural Network (IA-STGNN),a novel framework that closes the causal loop from tactical input to strategicdelay output. The model integrates graph attention mechanisms, counterfactualsimulation units, and spatial intervention node reconstruction to enabledynamic simulations of strike configurations and synchronization strategies.Training data are generated from a multi-physics simulation platform (GEANT4 +COMSOL) under NIST SP 800-160 standards, ensuring structural traceability andpolicy-level validation. Experimental results demonstrate that IA-STGNNsignificantly outperforms baseline models (ST-GNN, GCN-LSTM, XGBoost),achieving a 12.8 percent reduction in MAE and 18.4 percent increase in Top-5percent accuracy, while improving causal path consistency and interventionstability. IA-STGNN enables interpretable prediction of strategic delay andsupports applications such as nuclear deterrence simulation, diplomatic windowassessment, and multi-strategy optimization, providing a structured andtransparent AI decision-support mechanism for high-level policy modeling.</description>
      <author>example@mail.com (Wei Meng)</author>
      <guid isPermaLink="false">2507.00083v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding</title>
      <link>http://arxiv.org/abs/2507.02591v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AuroraLong的新方法，旨在解决长视频理解中的计算复杂度和内存成本问题，通过使用线性RNN语言模型替代MLLM中的LLM组件，以降低计算门槛。&lt;h4&gt;背景&lt;/h4&gt;长视频理解存在高计算复杂度和内存成本的问题，因为基于Transformer的LLM所需的内存和计算与输入序列长度成平方关系。&lt;h4&gt;目的&lt;/h4&gt;提出AuroraLong以解决长视频理解中的计算复杂度和内存成本问题，并通过降低计算门槛，实现长视频理解的普及。&lt;h4&gt;方法&lt;/h4&gt;AuroraLong通过替换MLLM中的LLM组件为线性RNN语言模型，并采用视觉标记合并和线性RNN模型结合的方式，以提高吞吐量和效率。&lt;h4&gt;主要发现&lt;/h4&gt;AuroraLong在具有2B参数的情况下，仅使用公开数据进行训练，在多个视频基准测试中达到了与基于Transformer的模型相当的性能。&lt;h4&gt;结论&lt;/h4&gt;AuroraLong证明了高效、线性的RNN在降低计算门槛方面的潜力，从而实现了长视频理解的普及。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为AuroraLong的新方法，旨在解决长视频理解中的计算复杂度和内存成本问题，通过使用线性RNN语言模型替代MLLM中的LLM组件，以降低计算门槛。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The challenge of long video understanding lies in its high computationalcomplexity and prohibitive memory cost, since the memory and computationrequired by transformer-based LLMs scale quadratically with input sequencelength. We propose AuroraLong to address this challenge by replacing the LLMcomponent in MLLMs with a linear RNN language model that handles input sequenceof arbitrary length with constant-size hidden states. To further increasethroughput and efficiency, we combine visual token merge with linear RNN modelsby reordering the visual tokens by their sizes in ascending order. Despitehaving only 2B parameters and being trained exclusively on public data,AuroraLong achieves performance comparable to Transformer-based models ofsimilar size trained on private datasets across multiple video benchmarks. Thisdemonstrates the potential of efficient, linear RNNs to democratize long videounderstanding by lowering its computational entry barrier. To our bestknowledge, we are the first to use a linear RNN based LLM backbone in aLLaVA-like model for open-ended video understanding.</description>
      <author>example@mail.com (Weili Xu, Enxin Song, Wenhao Chai, Xuexiang Wen, Tian Ye, Gaoang Wang)</author>
      <guid isPermaLink="false">2507.02591v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection</title>
      <link>http://arxiv.org/abs/2507.02393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 16 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的单目3D物体检测方法，通过利用视频数据，增强了对抗遮挡的能力，无需多视角设置、额外传感器、相机位姿或特定领域训练。&lt;h4&gt;背景&lt;/h4&gt;单目3D物体检测（M3OD）面临数据稀缺的挑战，这源于高标注成本和固有的2D到3D的模糊性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的伪标签框架，使用视频数据，并提高对遮挡的鲁棒性，同时不依赖于多视角设置、额外传感器、相机位姿或特定领域训练。&lt;h4&gt;方法&lt;/h4&gt;使用对象点跟踪技术，在时间相邻帧中聚合静态和动态对象的伪LiDAR数据，从而在无法获取3D数据的情况下进行3D属性提取。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法确保了可靠的准确性和强大的可扩展性。&lt;h4&gt;结论&lt;/h4&gt;该方法是一个实用且有效的单目3D物体检测解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular 3D object detection (M3OD) has long faced challenges due to datascarcity caused by high annotation costs and inherent 2D-to-3D ambiguity.Although various weakly supervised methods and pseudo-labeling methods havebeen proposed to address these issues, they are mostly limited bydomain-specific learning or rely solely on shape information from a singleobservation. In this paper, we propose a novel pseudo-labeling framework thatuses only video data and is more robust to occlusion, without requiring amulti-view setup, additional sensors, camera poses, or domain-specifictraining. Specifically, we explore a technique for aggregating thepseudo-LiDARs of both static and dynamic objects across temporally adjacentframes using object point tracking, enabling 3D attribute extraction inscenarios where 3D data acquisition is infeasible. Extensive experimentsdemonstrate that our method ensures reliable accuracy and strong scalability,making it a practical and effective solution for M3OD.</description>
      <author>example@mail.com (Seokyeong Lee, Sithu Aung, Junyong Choi, Seungryong Kim, Ig-Jae Kim, Junghyun Cho)</author>
      <guid isPermaLink="false">2507.02393v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges</title>
      <link>http://arxiv.org/abs/2507.02074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对利用大型语言模型（LLMs）进行视频数据中交通事故检测的近期方法进行了综述。&lt;h4&gt;背景&lt;/h4&gt;智能交通系统中，从视频流中检测交通事故是一个关键问题。&lt;h4&gt;目的&lt;/h4&gt;探讨如何利用LLMs进行交通事故检测，并对相关方法进行系统分类和评估。&lt;h4&gt;方法&lt;/h4&gt;文章提出了一个结构化的融合策略分类法，总结了关键数据集，分析了模型架构，比较了性能基准，并讨论了当前面临的挑战和机遇。&lt;h4&gt;主要发现&lt;/h4&gt;LLMs和视觉-语言模型（VLMs）在处理、推理和总结多模态信息方面取得了显著进展。&lt;h4&gt;结论&lt;/h4&gt;本文为视频理解和基础模型这一快速发展的交叉领域中的未来研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;Crash detection from video feeds is a critical problem in intelligent transportation systems. Recent developments in large language models (LLMs) and vision-language models (VLMs) have transformed how we process, reason about, and summarize multimodal information. This paper surveys recent methods leveraging LLMs for crash detection from video data. We present a structured taxonomy of fusion strategies, summarize key datasets, analyze model architectures, compare performance benchmarks, and discuss ongoing challenges and opportunities. Our review provides a foundation for future research in this fast-growing intersection of video understanding and foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Crash detection from video feeds is a critical problem in intelligenttransportation systems. Recent developments in large language models (LLMs) andvision-language models (VLMs) have transformed how we process, reason about,and summarize multimodal information. This paper surveys recent methodsleveraging LLMs for crash detection from video data. We present a structuredtaxonomy of fusion strategies, summarize key datasets, analyze modelarchitectures, compare performance benchmarks, and discuss ongoing challengesand opportunities. Our review provides a foundation for future research in thisfast-growing intersection of video understanding and foundation models.</description>
      <author>example@mail.com (Sanjeda Akter, Ibne Farabi Shihab, Anuj Sharma)</author>
      <guid isPermaLink="false">2507.02074v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames</title>
      <link>http://arxiv.org/abs/2507.02001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Temporal Chain of Thought的视频问答推理策略，旨在解决长视频理解问题。&lt;h4&gt;背景&lt;/h4&gt;尽管长上下文视觉语言模型（VLMs）在处理输入帧方面取得进展，但它们在有效利用序列长度和避免上下文窗口中的无关干扰方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种推理策略，以优化视频问答的准确性。&lt;h4&gt;方法&lt;/h4&gt;使用VLM自身迭代地识别和提取视频中最相关的帧，然后使用这些帧进行问答。&lt;h4&gt;主要发现&lt;/h4&gt;通过在推理时使用更多计算来选择最相关的上下文，可以提升准确性，并达到最先进的性能。在四个不同的视频问答数据集上实现了最先进的成果，特别是对于超过1小时的较长视频，使用32K上下文窗口的方法在LVBench上比使用标准推理的700K上下文窗口的VLM性能高出2.8个百分点。&lt;h4&gt;结论&lt;/h4&gt;Temporal Chain of Thought策略在视频问答任务中有效提升了长视频的理解能力，并在多个数据集上实现了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite recent advances in Vision-Language Models (VLMs), long-videounderstanding remains a challenging problem. Although state-of-the-artlong-context VLMs can process around 1000 input frames, they still struggle toeffectively leverage this sequence length, and succumb to irrelevantdistractors within the context window. We present Temporal Chain of Thought, aninference strategy for video question-answering that curates the model's inputcontext. We use the VLM itself to iteratively identify and extract the mostrelevant frames from the video, which are then used for answering. Wedemonstrate how leveraging more computation at inference-time to select themost relevant context leads to improvements in accuracy, in agreement withrecent work on inference-time scaling of LLMs. Moreover, we achievestate-of-the-art results on 4 diverse video question-answering datasets,showing consistent improvements with 3 different VLMs. In particular, ourmethod shines on longer videos which would not otherwise fit within the model'scontext window: On longer videos of more than 1 hour on LVBench, our approachusing a context window of 32K outperforms the same VLM using standard inferencewith a 700K context window by 2.8 points.</description>
      <author>example@mail.com (Anurag Arnab, Ahmet Iscen, Mathilde Caron, Alireza Fathi, Cordelia Schmid)</author>
      <guid isPermaLink="false">2507.02001v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>No time to train! Training-Free Reference-Based Instance Segmentation</title>
      <link>http://arxiv.org/abs/2507.02798v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图像分割模型，通过利用参考图像和强语义先验，减少了手动提示的需求，并在多个数据集上实现了最先进的分割性能。&lt;h4&gt;背景&lt;/h4&gt;传统的图像分割模型依赖于大规模标注数据，成本高昂。SAM模型通过提示式分割方法缓解了这一问题，但仍然需要手动提示或复杂的规则。&lt;h4&gt;目的&lt;/h4&gt;减少处理新图像时的手动提示负担，通过使用少量参考图像进行对象分割。&lt;h4&gt;方法&lt;/h4&gt;通过以下步骤实现：1）构建记忆库；2）表示聚合；3）语义感知特征匹配。&lt;h4&gt;主要发现&lt;/h4&gt;对应关系能够自动生成实例级分割掩码，从而提高了分割性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在多个数据集上实现了显著的性能提升，包括COCO FSOD、PASCAL VOC Few-Shot和跨域FSOD基准，优于现有的无训练方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：图像分割模型的性能在历史上受到收集大规模标注数据高成本的制约。Segment Anything Model（SAM）通过提示式、语义无关的分割范式缓解了这个问题，但仍需要手动视觉提示或复杂的领域特定提示生成规则来处理新图像。为了减少这种新的负担，我们的工作研究了在有少量参考图像的情况下进行对象分割的任务。我们的关键洞察是利用基础模型学习到的强语义先验来识别参考图像和目标图像之间的对应区域。我们发现对应关系能够为下游任务自动生成实例级分割掩码，并通过一个多阶段、无需训练的方法实现了这一想法，包括（1）记忆库构建；（2）表示聚合；（3）语义感知特征匹配。我们的实验表明，在分割指标上取得了显著改进，在COCO FSOD（36.8% nAP）、PASCAL VOC Few-Shot（71.2% nAP50）上实现了最先进的性能，并在跨域FSOD基准上优于现有的无训练方法（22.4% nAP）。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The performance of image segmentation models has historically beenconstrained by the high cost of collecting large-scale annotated data. TheSegment Anything Model (SAM) alleviates this original problem through apromptable, semantics-agnostic, segmentation paradigm and yet still requiresmanual visual-prompts or complex domain-dependent prompt-generation rules toprocess a new image. Towards reducing this new burden, our work investigatesthe task of object segmentation when provided with, alternatively, only a smallset of reference images. Our key insight is to leverage strong semantic priors,as learned by foundation models, to identify corresponding regions between areference and a target image. We find that correspondences enable automaticgeneration of instance-level segmentation masks for downstream tasks andinstantiate our ideas via a multi-stage, training-free method incorporating (1)memory bank construction; (2) representation aggregation and (3) semantic-awarefeature matching. Our experiments show significant improvements on segmentationmetrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP),PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-freeapproaches on the Cross-Domain FSOD benchmark (22.4% nAP).</description>
      <author>example@mail.com (Miguel Espinosa, Chenhongyi Yang, Linus Ericsson, Steven McDonagh, Elliot J. Crowley)</author>
      <guid isPermaLink="false">2507.02798v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Prompt learning with bounding box constraints for medical image segmentation</title>
      <link>http://arxiv.org/abs/2507.02743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE Transactions on Biomedical Engineering (TMBE), 14  pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合基础模型表示能力和弱监督分割标注效率的新框架，用于自动化提示生成，以降低医疗领域像素级标注的劳动强度和成本。&lt;h4&gt;背景&lt;/h4&gt;在医疗领域，像素级标注既耗时又昂贵。为了减轻这种负担，基于边界框标注的弱监督方法提供了一种实用的替代方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，通过自动化提示生成和使用边界框标注，来减少对像素级标注的依赖，并提高分割的效率。&lt;h4&gt;方法&lt;/h4&gt;该框架利用基础模型，通过集成来自边界框标注的多重约束和由提示基础模型生成的伪标签来进行优化。&lt;h4&gt;主要发现&lt;/h4&gt;在多个模态数据集上的实验表明，该方法在有限的标注数据集上达到了平均Dice分数84.90%，优于现有的全监督和弱监督方法。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一个有效的弱监督分割方法，显著降低了医疗领域图像分割的标注成本，并提供了开源代码供进一步研究和应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pixel-wise annotations are notoriously labourious and costly to obtain in themedical domain. To mitigate this burden, weakly supervised approaches based onbounding box annotations-much easier to acquire-offer a practical alternative.Vision foundation models have recently shown noteworthy segmentationperformance when provided with prompts such as points or bounding boxes. Promptlearning exploits these models by adapting them to downstream tasks andautomating segmentation, thereby reducing user intervention. However, existingprompt learning approaches depend on fully annotated segmentation masks. Thispaper proposes a novel framework that combines the representational power offoundation models with the annotation efficiency of weakly supervisedsegmentation. More specifically, our approach automates prompt generation forfoundation models using only bounding box annotations. Our proposedoptimization scheme integrates multiple constraints derived from boxannotations with pseudo-labels generated by the prompted foundation model.Extensive experiments across multimodal datasets reveal that our weaklysupervised method achieves an average Dice score of 84.90% in a limited datasetting, outperforming existing fully-supervised and weakly-supervisedapproaches. The code is available athttps://github.com/Minimel/box-prompt-learning-VFM.git</description>
      <author>example@mail.com (Mélanie Gaillochet, Mehrdad Noori, Sahar Dastani, Christian Desrosiers, Hervé Lombaert)</author>
      <guid isPermaLink="false">2507.02743v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>TurboReg: TurboClique for Robust and Efficient Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2507.01439v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV-2025 Accepted Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种快速且鲁棒的点云配准估计方法TurboReg，该方法基于轻量级图TurboClique和并行化的Pivot-Guided Search (PGS)算法，有效提高了配准速度和精度。&lt;h4&gt;背景&lt;/h4&gt;现有的基于最大团搜索的配准方法虽然召回率高，但时间复杂度呈指数级，限制了其在时间敏感应用中的使用。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的效率问题，提出了一种新的快速且鲁棒的点云配准方法。&lt;h4&gt;方法&lt;/h4&gt;TurboReg方法首先定义了TurboClique作为一个在高约束兼容图中的3-团，其轻量级特性允许高效并行搜索，高约束的兼容图确保了鲁棒的空问一致性。接着，PGS算法选择具有高SC²分数的匹配对作为支点，有效地引导搜索向具有更高内点比率的TurboClique方向。PGS算法具有线性时间复杂度，比指数级时间复杂度的最大团搜索要高效得多。&lt;h4&gt;主要发现&lt;/h4&gt;TurboReg在多个真实世界数据集上实现了最先进的性能，并显著提高了速度。例如，在3DMatch+FCGF数据集上，TurboReg（1K）比3DMAC快208.22倍，同时实现了更高的召回率。&lt;h4&gt;结论&lt;/h4&gt;TurboReg是一种高效且鲁棒的点云配准方法，适用于时间敏感的应用。&lt;h4&gt;翻译&lt;/h4&gt;Robust estimation is essential in correspondence-based Point Cloud Registration (PCR). Existing methods using maximal clique search incompatibility graphs achieve high recall but suffer from exponential time complexity, limiting their use in time-sensitive applications. To address this challenge, we propose a fast and robust estimator, TurboReg, built upon a novel lightweight clique, TurboClique, and a highly parallelizable Pivot-Guided Search (PGS) algorithm. First, we define the TurboClique as a 3-clique within a highly-constrained compatibility graph. The lightweight nature of the 3-clique allows for efficient parallel searching, and the highly-constrained compatibility graph ensures robust spatial consistency for stable transformation estimation. Next, PGS selects matching pairs with high SC² scores as pivots, effectively guiding the search toward TurboCliques with higher inlier ratios. Moreover, the PGS algorithm has linear time complexity and is significantly more efficient than the maximal clique search with exponential time complexity. Extensive experiments show that TurboReg achieves state-of-the-art performance across multiple real-world datasets, with substantial speed improvements. For example, on the 3DMatch+FCGF dataset, TurboReg (1K) operates 208.22 times faster than 3DMAC while also achieving higher recall. Our code is accessible at https://github.com/Laka-3DV/TurboReg.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust estimation is essential in correspondence-based Point CloudRegistration (PCR). Existing methods using maximal clique search incompatibility graphs achieve high recall but suffer from exponential timecomplexity, limiting their use in time-sensitive applications. To address thischallenge, we propose a fast and robust estimator, TurboReg, built upon a novellightweight clique, TurboClique, and a highly parallelizable Pivot-GuidedSearch (PGS) algorithm. First, we define the TurboClique as a 3-clique within ahighly-constrained compatibility graph. The lightweight nature of the 3-cliqueallows for efficient parallel searching, and the highly-constrainedcompatibility graph ensures robust spatial consistency for stabletransformation estimation. Next, PGS selects matching pairs with high SC$^2$scores as pivots, effectively guiding the search toward TurboCliques withhigher inlier ratios. Moreover, the PGS algorithm has linear time complexityand is significantly more efficient than the maximal clique search withexponential time complexity. Extensive experiments show that TurboReg achievesstate-of-the-art performance across multiple real-world datasets, withsubstantial speed improvements. For example, on the 3DMatch+FCGF dataset,TurboReg (1K) operates $208.22\times$ faster than 3DMAC while also achievinghigher recall. Our code is accessible at\href{https://github.com/Laka-3DV/TurboReg}{\texttt{TurboReg}}.</description>
      <author>example@mail.com (Shaocheng Yan, Pengcheng Shi, Zhenjun Zhao, Kaixin Wang, Kuang Cao, Ji Wu, Jiayuan Li)</author>
      <guid isPermaLink="false">2507.01439v2</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs</title>
      <link>http://arxiv.org/abs/2507.02671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过差分隐私生成模型进行数据共享的方法，用于提高深度学习在医学图像领域的应用效率。&lt;h4&gt;背景&lt;/h4&gt;深度学习在医学图像领域的应用受到数据稀缺和隐私法规的限制，而联邦学习虽然允许分散式训练，但通信成本高且通常限于单一下游任务。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种方法，以提高隐私、可扩展性和效率，同时支持多样化的下游任务。&lt;h4&gt;方法&lt;/h4&gt;通过使用基础模型提取紧凑、信息丰富的嵌入，减少了冗余和计算开销。客户端合作训练差分隐私条件变分自动编码器（DP-CVAE），以模型化全局、隐私保护的数据分布。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个特征提取器上得到了验证，在保证差分隐私的同时，比传统的联邦学习分类器性能更好。DP-CVAE生成的嵌入比DP-CGAN更准确，并且参数数量减少了5倍。&lt;h4&gt;结论&lt;/h4&gt;提出的方法通过提高隐私保护、可扩展性和效率，为深度学习在医学图像领域的应用提供了一种有效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep Learning (DL) has revolutionized medical imaging, yet its adoption isconstrained by data scarcity and privacy regulations, limiting access todiverse datasets. Federated Learning (FL) enables decentralized training butsuffers from high communication costs and is often restricted to a singledownstream task, reducing flexibility. We propose a data-sharing method viaDifferentially Private (DP) generative models. By adopting foundation models,we extract compact, informative embeddings, reducing redundancy and loweringcomputational overhead. Clients collaboratively train a Differentially PrivateConditional Variational Autoencoder (DP-CVAE) to model a global, privacy-awaredata distribution, supporting diverse downstream tasks. Our approach, validatedacross multiple feature extractors, enhances privacy, scalability, andefficiency, outperforming traditional FL classifiers while ensuringdifferential privacy. Additionally, DP-CVAE produces higher-fidelity embeddingsthan DP-CGAN while requiring $5{\times}$ fewer parameters.</description>
      <author>example@mail.com (Francesco Di Salvo, Hanh Huyen My Nguyen, Christian Ledig)</author>
      <guid isPermaLink="false">2507.02671v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning</title>
      <link>http://arxiv.org/abs/2507.02565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于人类外观和社会距离感知的交互动作重建方法，用于从复杂环境中捕获的真实视频中进行人体姿态估计。&lt;h4&gt;背景&lt;/h4&gt;现有的人体姿态估计方法在处理视觉模糊和人际遮挡时无法从真实场景视频中恢复合理的近距离交互动作，即使是先进的模型也无法准确区分人类语义。&lt;h4&gt;目的&lt;/h4&gt;提出一种优化框架，以重建准确的交互动作，并考虑人类外观、社会距离和物理定律。&lt;h4&gt;方法&lt;/h4&gt;该方法首先训练一个扩散模型来学习人类的社会距离行为和姿态先验知识，然后将训练的网络和两个可优化张量整合到一个双分支优化框架中，以重建人体动作和外观。同时，设计了基于3D高斯、2D关键点和网格穿透的约束条件来辅助优化。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够从复杂环境中的真实视频中准确估计交互动作，并构建了一个带有伪真实交互标注的数据集，可能促进姿态估计和人类行为理解的研究。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，该方法在多个基准测试中优于现有方法，代码和数据可在指定链接获取。&lt;h4&gt;翻译&lt;/h4&gt;摘要：由于视觉模糊和人际遮挡，现有的人体姿态估计方法无法从野外视频中恢复合理的近距离交互动作。即使是当前最先进的基于大型基础模型（例如SAM）也无法在这些具有挑战性的场景中准确区分人类语义。在本工作中，我们发现人类外观可以提供一种直接的方法来解决这些障碍。基于这一观察，我们提出了一种双分支优化框架，以在受人类外观、社会距离和物理定律约束的情况下重建准确的交互动作。具体来说，我们首先训练了一个扩散模型来学习人类的社会距离行为和姿态先验知识。然后，将训练的网络和两个可优化的张量整合到一个双分支优化框架中，以重建人体动作和外观。还设计了基于3D高斯、2D关键点和网格穿透的几个约束条件来辅助优化。有了距离先验和多种约束，我们的方法能够从复杂环境中捕获的真实视频中估计准确的交互动作。我们进一步构建了一个带有伪真实交互标注的数据集，这可能促进姿态估计和人类行为理解的研究。在几个基准测试上的实验结果表明，我们的方法优于现有方法。代码和数据可在https://www.buzhenhuang.com/works/CloseApp.html获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to visual ambiguities and inter-person occlusions, existing human poseestimation methods cannot recover plausible close interactions from in-the-wildvideos. Even state-of-the-art large foundation models~(\eg, SAM) cannotaccurately distinguish human semantics in such challenging scenarios. In thiswork, we find that human appearance can provide a straightforward cue toaddress these obstacles. Based on this observation, we propose a dual-branchoptimization framework to reconstruct accurate interactive motions withplausible body contacts constrained by human appearances, social proxemics, andphysical laws. Specifically, we first train a diffusion model to learn thehuman proxemic behavior and pose prior knowledge. The trained network and twooptimizable tensors are then incorporated into a dual-branch optimizationframework to reconstruct human motions and appearances. Several constraintsbased on 3D Gaussians, 2D keypoints, and mesh penetrations are also designed toassist the optimization. With the proxemics prior and diverse constraints, ourmethod is capable of estimating accurate interactions from in-the-wild videoscaptured in complex environments. We further build a dataset with pseudoground-truth interaction annotations, which may promote future research on poseestimation and human behavior understanding. Experimental results on severalbenchmarks demonstrate that our method outperforms existing approaches. Thecode and data are available at https://www.buzhenhuang.com/works/CloseApp.html.</description>
      <author>example@mail.com (Buzhen Huang, Chen Li, Chongyang Xu, Dongyue Lu, Jinnan Chen, Yangang Wang, Gim Hee Lee)</author>
      <guid isPermaLink="false">2507.02565v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios</title>
      <link>http://arxiv.org/abs/2507.02479v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CrowdTrack的困难大规模多行人跟踪数据集，旨在解决现有方法在复杂场景下的局限性。&lt;h4&gt;背景&lt;/h4&gt;多目标跟踪是计算机视觉的经典领域，其中行人跟踪应用价值极高，已成为最热门的研究类别。现有方法主要使用运动或外观信息进行跟踪，但在复杂场景下往往难以实现。&lt;h4&gt;目的&lt;/h4&gt;针对现有方法在复杂场景下的不足，提出一个能够支持算法在复杂情况下有效工作的数据集。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包含33个视频、5185个轨迹的CrowdTrack数据集，主要从第一人称视角拍摄，所有视频都来自真实生活中的复杂场景。每个对象都被标注了完整的边界框和唯一的对象ID。&lt;h4&gt;主要发现&lt;/h4&gt;数据集全面分析了CrowdTrack，并在其上测试了多个SOTA模型，同时分析了基础模型在数据集上的性能。&lt;h4&gt;结论&lt;/h4&gt;CrowdTrack数据集为算法开发提供了一个平台，有助于在复杂情况下保持跟踪算法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Multi-object tracking is a classic field in computer vision. Among them, pedestrian tracking has extremely high application value and has become the most popular research category. Existing methods mainly use motion or appearance information for tracking, which is often difficult in complex scenarios. For the motion information, mutual occlusions between objects often prevent updating of the motion state; for the appearance information, non-robust results are often obtained due to reasons such as only partial visibility of the object or blurred images. Although learning how to perform tracking in these situations from the annotated data is the simplest solution, the existing MOT dataset fails to satisfy this solution. Existing methods mainly have two drawbacks: relatively simple scene composition and non-realistic scenarios. Although some of the video sequences in existing dataset do not have the aforementioned drawbacks, the number is far from adequate for research purposes. To this end, we propose a difficult large-scale dataset for multi-pedestrian tracking, shot mainly from the first-person view and all from real-life complex scenarios. We name it ``CrowdTrack'' because there are numerous objects in most of the sequences. Our dataset consists of 33 videos, containing a total of 5,185 trajectories. Each object is annotated with a complete bounding box and a unique object ID. The dataset will provide a platform to facilitate the development of algorithms that remain effective in complex situations. We analyzed the dataset comprehensively and tested multiple SOTA models on our dataset. Besides, we analyzed the performance of the foundation models on our dataset. The dataset and project code is released at: https://github.com/loseevaya/CrowdTrack.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-object tracking is a classic field in computer vision. Among them,pedestrian tracking has extremely high application value and has become themost popular research category. Existing methods mainly use motion orappearance information for tracking, which is often difficult in complexscenarios. For the motion information, mutual occlusions between objects oftenprevent updating of the motion state; for the appearance information,non-robust results are often obtained due to reasons such as only partialvisibility of the object or blurred images. Although learning how to performtracking in these situations from the annotated data is the simplest solution,the existing MOT dataset fails to satisfy this solution. Existing methodsmainly have two drawbacks: relatively simple scene composition andnon-realistic scenarios. Although some of the video sequences in existingdataset do not have the above-mentioned drawbacks, the number is far fromadequate for research purposes. To this end, we propose a difficult large-scaledataset for multi-pedestrian tracking, shot mainly from the first-person viewand all from real-life complex scenarios. We name it ``CrowdTrack'' becausethere are numerous objects in most of the sequences. Our dataset consists of 33videos, containing a total of 5,185 trajectories. Each object is annotated witha complete bounding box and a unique object ID. The dataset will provide aplatform to facilitate the development of algorithms that remain effective incomplex situations. We analyzed the dataset comprehensively and tested multipleSOTA models on our dataset. Besides, we analyzed the performance of thefoundation models on our dataset. The dataset and project code is released at:https://github.com/loseevaya/CrowdTrack .</description>
      <author>example@mail.com (Teng Fu, Yuwen Chen, Zhuofan Chen, Mengyang Zhao, Bin Li, Xiangyang Xue)</author>
      <guid isPermaLink="false">2507.02479v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Toward a Robust and Generalizable Metamaterial Foundation Model</title>
      <link>http://arxiv.org/abs/2507.02436v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为MetaFO的元材料基础模型，该模型基于贝叶斯变压器并受到大型语言模型的启发，旨在解决现有材料功能创新中的限制。&lt;h4&gt;背景&lt;/h4&gt;材料功能的进步推动了各个领域的创新，而元材料（由结构而非组成定义）正引领这一进程。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有设计策略的限制，如任务特定的再训练、分布外（OOD）泛化不良以及正向和逆向设计需要独立模型等问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于贝叶斯变压器的元材料基础模型（MetaFO），该模型学习元材料的底层机制，允许在多样化的、未知的材料属性和结构响应组合上进行概率预测和无样本预测。&lt;h4&gt;主要发现&lt;/h4&gt;MetaFO在非线性逆向设计方面表现出色，即使在分布外条件下也是如此。它将元材料视为一个将材料属性映射到结构响应的算子，揭示了复杂的结构-属性关系，并显著扩大了设计空间。&lt;h4&gt;结论&lt;/h4&gt;这种可扩展且通用的框架标志着人工智能驱动元材料发现的范式转变，为下一代创新铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：材料功能的进步推动了各个领域的创新，而元材料（由结构而非组成定义）正引领这一进程。尽管人工智能（AI）驱动的创新设计策略正在兴起，但它们的影响受到任务特定再训练、分布外（OOD）泛化不良以及正向和逆向设计需要独立模型等限制。为了解决这些限制，我们引入了元材料基础模型（MetaFO），一个受大型语言模型启发的贝叶斯变压器基础模型。MetaFO学习元材料的底层机制，允许在多样化的、未知的材料属性和结构响应组合上进行概率预测和无样本预测。它还在非线性逆向设计方面表现出色，即使在分布外条件下也是如此。通过将元材料视为一个将材料属性映射到结构响应的算子，MetaFO揭示了复杂的结构-属性关系，并显著扩大了设计空间。这个可扩展且通用的框架标志着人工智能驱动元材料发现的范式转变，为下一代创新铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Advances in material functionalities drive innovations across various fields,where metamaterials-defined by structure rather than composition-are leadingthe way. Despite the rise of artificial intelligence (AI)-driven designstrategies, their impact is limited by task-specific retraining, poorout-of-distribution(OOD) generalization, and the need for separate models forforward and inverse design. To address these limitations, we introduce theMetamaterial Foundation Model (MetaFO), a Bayesian transformer-based foundationmodel inspired by large language models. MetaFO learns the underlying mechanicsof metamaterials, enabling probabilistic, zero-shot predictions across diverse,unseen combinations of material properties and structural responses. It alsoexcels in nonlinear inverse design, even under OOD conditions. By treatingmetamaterials as an operator that maps material properties to structuralresponses, MetaFO uncovers intricate structure-property relationships andsignificantly expands the design space. This scalable and generalizableframework marks a paradigm shift in AI-driven metamaterial discovery, pavingthe way for next-generation innovations.</description>
      <author>example@mail.com (Namjung Kim, Dongseok Lee, Jongbin Yu, Sung Woong Cho, Dosung Lee, Yesol Park, Youngjoon Hong)</author>
      <guid isPermaLink="false">2507.02436v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>RLHGNN: Reinforcement Learning-driven Heterogeneous Graph Neural Network for Next Activity Prediction in Business Processes</title>
      <link>http://arxiv.org/abs/2507.02690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures. Business process prediction using reinforcement  learning and heterogeneous graph neural networks&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为RLHGNN的新框架，用于预测服务导向架构中的下一个活动，以优化业务流程。&lt;h4&gt;背景&lt;/h4&gt;在微服务、分布式企业系统和云原生平台等面向服务的架构中，下一个活动预测是一个基本挑战，这有助于主动资源分配和动态服务组合。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法无法捕捉非顺序关系、同质表示和静态结构的局限性，提出RLHGNN框架。&lt;h4&gt;方法&lt;/h4&gt;RLHGNN将事件日志转换为具有三种不同类型边的异构图，并利用强化学习自动确定每个特定过程的最佳图结构。然后，应用异构图卷积和相关特定的聚合策略来预测下一个活动。&lt;h4&gt;主要发现&lt;/h4&gt;RLHGNN在六个真实世界数据集上的评估表明，它优于现有方法，且每个预测的推理延迟约为1毫秒。&lt;h4&gt;结论&lt;/h4&gt;RLHGNN是一种高度实用的解决方案，适合实时业务流程监控应用。&lt;h4&gt;翻译&lt;/h4&gt;Next activity prediction represents a fundamental challenge for optimizing business processes in service-oriented architectures such as microservices environments, distributed enterprise systems, and cloud-native platforms, which enables proactive resource allocation and dynamic service composition. Despite the prevalence of sequence-based methods, these approaches fail to capture non-sequential relationships that arise from parallel executions and conditional dependencies. Even though graph-based approaches address structural preservation, they suffer from homogeneous representations and static structures that apply uniform modeling strategies regardless of individual process complexity characteristics. To address these limitations, we introduce RLHGNN, a novel framework that transforms event logs into heterogeneous process graphs with three distinct edge types grounded in established process mining theory. Our approach creates four flexible graph structures by selectively combining these edges to accommodate different process complexities, and employs reinforcement learning formulated as a Markov Decision Process to automatically determine the optimal graph structure for each specific process instance. RLHGNN then applies heterogeneous graph convolution with relation-specific aggregation strategies to effectively predict the next activity. This adaptive methodology enables precise modeling of both sequential and non-sequential relationships in service interactions. Comprehensive evaluation on six real-world datasets demonstrates that RLHGNN consistently outperforms state-of-the-art approaches. Furthermore, it maintains an inference latency of approximately 1 ms per prediction, representing a highly practical solution suitable for real-time business process monitoring applications. The source code is available at https://github.com/Joker3993/RLHGNN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Next activity prediction represents a fundamental challenge for optimizingbusiness processes in service-oriented architectures such as microservicesenvironments, distributed enterprise systems, and cloud-native platforms, whichenables proactive resource allocation and dynamic service composition. Despitethe prevalence of sequence-based methods, these approaches fail to capturenon-sequential relationships that arise from parallel executions andconditional dependencies. Even though graph-based approaches address structuralpreservation, they suffer from homogeneous representations and staticstructures that apply uniform modeling strategies regardless of individualprocess complexity characteristics. To address these limitations, we introduceRLHGNN, a novel framework that transforms event logs into heterogeneous processgraphs with three distinct edge types grounded in established process miningtheory. Our approach creates four flexible graph structures by selectivelycombining these edges to accommodate different process complexities, andemploys reinforcement learning formulated as a Markov Decision Process toautomatically determine the optimal graph structure for each specific processinstance. RLHGNN then applies heterogeneous graph convolution withrelation-specific aggregation strategies to effectively predict the nextactivity. This adaptive methodology enables precise modeling of both sequentialand non-sequential relationships in service interactions. Comprehensiveevaluation on six real-world datasets demonstrates that RLHGNN consistentlyoutperforms state-of-the-art approaches. Furthermore, it maintains an inferencelatency of approximately 1 ms per prediction, representing a highly practicalsolution suitable for real-time business process monitoring applications. Thesource code is available at https://github.com/Joker3993/RLHGNN.</description>
      <author>example@mail.com (Jiaxing Wang, Yifeng Yu, Jiahan Song, Bin Cao, Jing Fan, Ji Zhang)</author>
      <guid isPermaLink="false">2507.02690v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization</title>
      <link>http://arxiv.org/abs/2507.02288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于文本特征引导的视觉提示调优框架，旨在解决领域泛化中特征解耦的挑战，并通过实验证明其优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;领域泛化（DG）旨在开发能够在未见过的目标领域有效执行的模型。近期，预训练视觉基础模型（VFMs）如CLIP在增强深度学习模型的泛化能力方面展现出巨大潜力。&lt;h4&gt;目的&lt;/h4&gt;设计有效的提示，能够解耦不同领域中的不变特征。&lt;h4&gt;方法&lt;/h4&gt;1. 利用可控制和灵活的语言提示进行特征解耦；2. 引入一种新的框架，使用大型语言模型（LLM）自动解耦文本提示；3. 通过解耦的文本特征学习领域不变视觉表示；4. 提出最坏显式表示对齐（WERA），通过风格化图像增强增加源领域多样性，并通过对齐约束确保视觉表示的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在包括PACS、VLCS、OfficeHome、DomainNet和TerraInc在内的主要领域泛化数据集上，提出的框架优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的基于文本特征引导的视觉提示调优框架能够有效提升领域泛化能力，为深度学习模型在多个领域中的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：领域泛化（DG）寻求开发一种能够在未见过的目标领域有效执行的通用模型。值得注意的是，近期在预训练视觉基础模型（VFMs），如CLIP，方面的进展已显示出增强深度学习模型泛化能力的巨大潜力。尽管VFM基于领域提示调优在领域泛化中受到了越来越多的关注，但设计能够解耦不同领域间不变特征的提示仍然是一个关键挑战。在本文中，我们通过利用VFM的可控和灵活的语言提示来应对这一挑战。鉴于VFMs的文本模态天然更容易解耦，我们引入了一种新颖的文本特征引导的视觉提示调优框架。该框架首先使用大型语言模型（LLM）自动解耦文本提示，然后根据解耦的文本特征学习领域不变的视觉表示。然而，仅依赖语言来引导视觉特征解耦存在局限性，因为视觉特征有时可能过于复杂或微妙，无法完全被描述性文本所捕捉。为了解决这个问题，我们引入了最坏显式表示对齐（WERA），它通过增加一组抽象提示扩展了文本引导的视觉提示。这些提示通过风格化图像增强增加了源域的多样性，而对齐约束确保了视觉表示在原始和增强分布中都保持一致性。在包括PACS、VLCS、OfficeHome、DomainNet和TerraInc在内的主要领域泛化数据集上进行的实验表明，我们提出的方法优于现有的领域泛化方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Domain Generalization (DG) seeks to develop a versatile model capable ofperforming effectively on unseen target domains. Notably, recent advances inpre-trained Visual Foundation Models (VFMs), such as CLIP, have demonstratedconsiderable potential in enhancing the generalization capabilities of deeplearning models. Despite the increasing attention toward VFM-based domainprompt tuning within DG, the effective design of prompts capable ofdisentangling invariant features across diverse domains remains a criticalchallenge. In this paper, we propose addressing this challenge by leveragingthe controllable and flexible language prompt of the VFM. Noting that the textmodality of VFMs is naturally easier to disentangle, we introduce a novelframework for text feature-guided visual prompt tuning. This framework firstautomatically disentangles the text prompt using a large language model (LLM)and then learns domain-invariant visual representation guided by thedisentangled text feature. However, relying solely on language to guide visualfeature disentanglement has limitations, as visual features can sometimes betoo complex or nuanced to be fully captured by descriptive text. To addressthis, we introduce Worst Explicit Representation Alignment (WERA), whichextends text-guided visual prompts by incorporating an additional set ofabstract prompts. These prompts enhance source domain diversity throughstylized image augmentations, while alignment constraints ensure that visualrepresentations remain consistent across both the original and augmenteddistributions. Experiments conducted on major DG datasets, including PACS,VLCS, OfficeHome, DomainNet, and TerraInc, demonstrate that our proposed methodoutperforms state-of-the-art DG methods.</description>
      <author>example@mail.com (De Cheng, Zhipeng Xu, Xinyang Jiang, Dongsheng Li, Nannan Wang, Xinbo Gao)</author>
      <guid isPermaLink="false">2507.02288v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>When Attention is Beneficial for Learning Wireless Resource Allocation Efficiently?</title>
      <link>http://arxiv.org/abs/2507.02427v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 6 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在资源分配中是否需要使用注意力机制，并探讨了将注意力机制与图神经网络（GNNs）结合用于学习无线策略的趋势。&lt;h4&gt;背景&lt;/h4&gt;Transformer由于使用了注意力机制来利用跨词汇的依赖性，在自然语言处理中非常高效。图神经网络（GNNs）在可扩展性和泛化性方面具有潜力，可以高效地学习资源分配策略。&lt;h4&gt;目的&lt;/h4&gt;探讨在资源分配中是否需要使用注意力机制，并通过分析函数的结构和数值算法来验证这一观点。&lt;h4&gt;方法&lt;/h4&gt;通过分析定义在集合上的函数结构，证明单集合上的排列等变函数可以递归地表示为两种类型的函数：一种涉及注意力，另一种不涉及。将数值算法重新表示为递归形式，以优化代表性资源分配问题。&lt;h4&gt;主要发现&lt;/h4&gt;发现当干扰（如多用户或数据流间的干扰）未反映在策略的可测量参数中时，需要使用注意力来模拟干扰。&lt;h4&gt;结论&lt;/h4&gt;提出了一种通过结构与GNNs设计对齐的框架，并通过仿真验证了所提出的GNN在可重构智能表面辅助的混合预编码中的学习效率。&lt;h4&gt;翻译&lt;/h4&gt;由于使用了注意力机制来利用跨词汇的依赖性，Transformer在自然语言处理中非常高效。通过利用资源分配策略中广泛存在的排列属性，图神经网络（GNNs）在可扩展性和泛化性方面具有潜力，可以高效地学习这些策略。为了获得这两种架构的好处，最近有一种趋势是将注意力机制与GNNs结合用于学习无线策略。然而，在资源分配中，注意力机制真的是必需的吗？在本文中，我们通过分析定义在集合上的函数结构和数值算法来回答这个问题，因为无线策略的排列属性是由涉及的集合（例如用户集）引起的。特别是，我们证明了单集合上的排列等变函数可以递归地表示为两种类型的函数：一种涉及注意力，另一种不涉及。我们进而将优化几个代表性资源分配问题的数值算法重新表示为递归形式。我们发现，当干扰（如多用户或数据流间的干扰）未反映在策略的可测量参数中时，需要使用注意力来模拟干扰。基于这一洞察，我们建立了一个与结构对齐的GNN设计框架。以可重构智能表面辅助的混合预编码为例，通过仿真验证了所提出的GNN的学习效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Owing to the use of attention mechanism to leverage the dependency acrosstokens, Transformers are efficient for natural language processing. Byharnessing permutation properties broadly exist in resource allocationpolicies, each mapping measurable environmental parameters (e.g., channelmatrix) to optimized variables (e.g., precoding matrix), graph neural networks(GNNs) are promising for learning these policies efficiently in terms ofscalability and generalizability. To reap the benefits of both architectures,there is a recent trend of incorporating attention mechanism with GNNs forlearning wireless policies. Nevertheless, is the attention mechanism reallyneeded for resource allocation? In this paper, we strive to answer thisquestion by analyzing the structures of functions defined on sets and numericalalgorithms, given that the permutation properties of wireless policies areinduced by the involved sets (say user set). In particular, we prove that thepermutation equivariant functions on a single set can be recursively expressedby two types of functions: one involves attention, and the other does not. Weproceed to re-express the numerical algorithms for optimizing severalrepresentative resource allocation problems in recursive forms. We find thatwhen interference (say multi-user or inter-data stream interference) is notreflected in the measurable parameters of a policy, attention needs to be usedto model the interference. With the insight, we establish a framework ofdesigning GNNs by aligning with the structures. By taking reconfigurableintelligent surface-aided hybrid precoding as an example, the learningefficiency of the proposed GNN is validated via simulations.</description>
      <author>example@mail.com (Jia Guo, Chenyang Yang)</author>
      <guid isPermaLink="false">2507.02427v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach</title>
      <link>http://arxiv.org/abs/2507.02826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为动态对比双重路径网络（DCDP-HAR）的新型框架，用于解决多模态人体活动识别（HAR）系统中的跨模态特征对齐和模态贡献不平衡问题。&lt;h4&gt;背景&lt;/h4&gt;人体活动识别是智能系统感知和交互环境的核心技术，但多模态HAR系统仍面临跨模态特征对齐和模态贡献不平衡的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出DCDP-HAR框架以解决上述挑战，并验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;DCDP-HAR框架包括三个关键组件：1）双重路径特征提取架构，利用ResNet和DenseNet分支协同处理多模态传感器数据；2）多阶段对比学习机制，实现从局部感知到语义抽象的渐进式对齐；3）信心驱动的梯度调制策略，在反向传播过程中动态监控和调整每个模态分支的学习强度，有效缓解模态竞争。此外，采用基于动量的梯度累积策略以增强训练稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;通过消融实验验证了每个组件的有效性，并在四个公开基准数据集上进行了广泛的对比实验。&lt;h4&gt;结论&lt;/h4&gt;DCDP-HAR框架能够有效解决多模态HAR系统中的关键挑战，提高了识别准确性和系统的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sensor-based Human Activity Recognition (HAR) is a core technology thatenables intelligent systems to perceive and interact with their environment.However, multimodal HAR systems still encounter key challenges, such asdifficulties in cross-modal feature alignment and imbalanced modalitycontributions. To address these issues, we propose a novel framework called theDynamic Contrastive Dual-Path Network (DCDP-HAR). The framework comprises threekey components. First, a dual-path feature extraction architecture is employed,where ResNet and DenseNet branches collaboratively process multimodal sensordata. Second, a multi-stage contrastive learning mechanism is introduced toachieve progressive alignment from local perception to semantic abstraction.Third, we present a confidence-driven gradient modulation strategy thatdynamically monitors and adjusts the learning intensity of each modality branchduring backpropagation, effectively alleviating modality competition. Inaddition, a momentum-based gradient accumulation strategy is adopted to enhancetraining stability. We conduct ablation studies to validate the effectivenessof each component and perform extensive comparative experiments on four publicbenchmark datasets.</description>
      <author>example@mail.com (Panpan Ji, Junni Song, Hang Xiao, Hanyu Liu, Chao Li)</author>
      <guid isPermaLink="false">2507.02826v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms</title>
      <link>http://arxiv.org/abs/2507.02724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HIPPO是一种用于蛋白质-蛋白质相互作用（PPI）预测的层次对比学习框架，在跨物种PPI预测中表现优异，具有零样本迁移能力。&lt;h4&gt;背景&lt;/h4&gt;人工智能在科学领域的进步突出了对比学习在连接异质生物数据模态方面的强大能力。&lt;h4&gt;目的&lt;/h4&gt;提出HIPPO框架，用于蛋白质-蛋白质相互作用（PPI）预测。&lt;h4&gt;方法&lt;/h4&gt;HIPPO通过多层次生物表示匹配对蛋白质序列及其层次属性进行对齐，并采用层次对比损失函数来模拟蛋白质功能类别的结构关系。该框架通过数据驱动的惩罚机制自适应地融合领域和家庭知识，确保学习到的嵌入空间与蛋白质功能的内在层次结构一致。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HIPPO在基准数据集上达到最先进的性能，优于现有方法，并在低数据环境中表现出鲁棒性。模型还显示出对其他物种的强大零样本迁移能力，即使在实验数据有限的未充分表征或稀有生物中也能进行可靠的PPI预测和功能推断。进一步分析表明，层次特征融合对于捕获保守的相互作用决定因素，如结合基序和功能注释，至关重要。&lt;h4&gt;结论&lt;/h4&gt;HIPPO推进了跨物种PPI预测，并为在稀疏或不平衡的多物种数据场景中预测相互作用提供了一个统一的框架。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in AI for science have highlighted the power of contrastivelearning in bridging heterogeneous biological data modalities. Building on thisparadigm, we propose HIPPO (HIerarchical Protein-Protein interaction predictionacross Organisms), a hierarchical contrastive framework for protein-proteininteraction(PPI) prediction, where protein sequences and their hierarchicalattributes are aligned through multi-tiered biological representation matching.The proposed approach incorporates hierarchical contrastive loss functions thatemulate the structured relationship among functional classes of proteins. Theframework adaptively incorporates domain and family knowledge through adata-driven penalty mechanism, enforcing consistency between the learnedembedding space and the intrinsic hierarchy of protein functions. Experimentson benchmark datasets demonstrate that HIPPO achieves state-of-the-artperformance, outperforming existing methods and showing robustness in low-dataregimes. Notably, the model demonstrates strong zero-shot transferability toother species without retraining, enabling reliable PPI prediction andfunctional inference even in less characterized or rare organisms whereexperimental data are limited. Further analysis reveals that hierarchicalfeature fusion is critical for capturing conserved interaction determinants,such as binding motifs and functional annotations. This work advancescross-species PPI prediction and provides a unified framework for interactionprediction in scenarios with sparse or imbalanced multi-species data.</description>
      <author>example@mail.com (Shiyi Liu, Buwen Liang, Yuetong Fang, Zixuan Jiang, Renjing Xu)</author>
      <guid isPermaLink="false">2507.02724v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping</title>
      <link>http://arxiv.org/abs/2507.02672v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE/RSJ International Conference on Intelligent Robots and Systems  (IROS), 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MISCGrasp的体积感知抓取方法，用于解决机器人在抓取形状和大小各异的物体时遇到的挑战。&lt;h4&gt;背景&lt;/h4&gt;机器人在抓取物体时面临适应不同形状和大小的困难。&lt;h4&gt;目的&lt;/h4&gt;设计MISCGrasp方法，以实现自适应抓取。&lt;h4&gt;方法&lt;/h4&gt;MISCGrasp通过集成多尺度特征提取与对比特征增强来提高抓取能力。它使用Insight Transformer进行高级和低级特征之间的查询式交互，同时使用Empower Transformer选择性关注高级特征，以平衡关注细微几何细节和整体几何结构。此外，MISCGrasp利用多尺度对比学习来利用正抓取样本之间的相似性，确保多尺度特征的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和真实世界环境中进行的广泛实验表明，MISCGrasp在桌面清理任务中优于基线和变体方法。&lt;h4&gt;结论&lt;/h4&gt;MISCGrasp方法能够有效地提高机器人抓取的适应性，在处理不同形状和大小的物体时表现出色。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种名为MISCGrasp的体积感知抓取方法，该方法集成了多尺度特征提取与对比特征增强，用于自适应抓取。我们提出了一种基于查询的高级和低级特征之间的交互，并通过Insight Transformer实现。同时，Empower Transformer选择性地关注高级特征，以协同平衡对细微几何细节和整体几何结构的关注。此外，MISCGrasp利用多尺度对比学习来利用正抓取样本之间的相似性，确保多尺度特征的一致性。在模拟和真实世界环境中的广泛实验表明，MISCGrasp在桌面清理任务中优于基线和变体方法。更多信息可在https://miscgrasp.github.io/查看。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic grasping faces challenges in adapting to objects with varying shapesand sizes. In this paper, we introduce MISCGrasp, a volumetric grasping methodthat integrates multi-scale feature extraction with contrastive featureenhancement for self-adaptive grasping. We propose a query-based interactionbetween high-level and low-level features through the Insight Transformer,while the Empower Transformer selectively attends to the highest-levelfeatures, which synergistically strikes a balance between focusing on finegeometric details and overall geometric structures. Furthermore, MISCGrasputilizes multi-scale contrastive learning to exploit similarities amongpositive grasp samples, ensuring consistency across multi-scale features.Extensive experiments in both simulated and real-world environments demonstratethat MISCGrasp outperforms baseline and variant methods in tabletopdecluttering tasks. More details are available at https://miscgrasp.github.io/.</description>
      <author>example@mail.com (Qingyu Fan, Yinghao Cai, Chao Li, Chunting Jiao, Xudong Zheng, Tao Lu, Bin Liang, Shuo Wang)</author>
      <guid isPermaLink="false">2507.02672v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>S2FGL: Spatial Spectral Federated Graph Learning</title>
      <link>http://arxiv.org/abs/2507.02409v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为S2FGL的联邦图学习框架，该框架结合了联邦学习（FL）的隐私保护能力和图神经网络（GNN）的强大图建模能力，并解决了子图联邦学习（subgraph-FL）中存在的空间和频谱域问题。&lt;h4&gt;背景&lt;/h4&gt;当前研究主要从结构视角处理子图联邦学习，忽略了结构在空间和频谱域上的图信号传播。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种方法来减轻标签信号中断和解决频谱客户端漂移。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种全局知识库来减轻标签信号中断，以及一种频率对齐来解决频谱客户端漂移。S2FGL框架结合了空间和频谱策略。&lt;h4&gt;主要发现&lt;/h4&gt;S2FGL在多个数据集上的实验表明，该方法优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;S2FGL框架能够有效解决子图联邦学习中的空间和频谱域问题，提高全局泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Federated Graph Learning (FGL) combines the privacy-preserving capabilities of federated learning (FL) with the strong graph modeling capability of Graph Neural Networks (GNNs). Current research addresses subgraph-FL only from the structural perspective, neglecting the propagation of graph signals on spatial and spectral domains of the structure. From a spatial perspective, subgraph-FL introduces edge disconnections between clients, leading to disruptions in label signals and a degradation in the class knowledge of the global GNN. From a spectral perspective, spectral heterogeneity causes inconsistencies in signal frequencies across subgraphs, which makes local GNNs overfit the local signal propagation schemes. As a result, spectral client drifts occur, undermining global generalizability. To tackle the challenges, we propose a global knowledge repository to mitigate label signal disruption and a frequency alignment to address spectral client drifts. The combination of spatial and spectral strategies forms our framework S2FGL. Extensive experiments on multiple datasets demonstrate the superiority of S2FGL. The code is available at https://github.com/Wonder7racer/S2FGL.git.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated Graph Learning (FGL) combines the privacy-preserving capabilitiesof federated learning (FL) with the strong graph modeling capability of GraphNeural Networks (GNNs). Current research addresses subgraph-FL only from thestructural perspective, neglecting the propagation of graph signals on spatialand spectral domains of the structure. From a spatial perspective, subgraph-FLintroduces edge disconnections between clients, leading to disruptions in labelsignals and a degradation in the class knowledge of the global GNN. From aspectral perspective, spectral heterogeneity causes inconsistencies in signalfrequencies across subgraphs, which makes local GNNs overfit the local signalpropagation schemes. As a result, spectral client drifts occur, underminingglobal generalizability. To tackle the challenges, we propose a globalknowledge repository to mitigate label signal disruption and a frequencyalignment to address spectral client drifts. The combination of spatial andspectral strategies forms our framework S2FGL. Extensive experiments onmultiple datasets demonstrate the superiority of S2FGL. The code is availableat https://github.com/Wonder7racer/S2FGL.git.</description>
      <author>example@mail.com (Zihan Tan, Suyuan Huang, Guancheng Wan, Wenke Huang, He Li, Mang Ye)</author>
      <guid isPermaLink="false">2507.02409v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy</title>
      <link>http://arxiv.org/abs/2507.02493v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于监督对比损失的结肠镜自动息肉计数方法，该方法结合了时间感知软目标，提高了息肉计数的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;自动息肉计数在结肠镜检查中是自动报告和质量控制的关键步骤，旨在提高结肠镜筛查的成本效益。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的息肉计数方法，以减少现有方法在息肉特征学习和聚类阶段忽略时间关系的问题。&lt;h4&gt;方法&lt;/h4&gt;引入了一种监督对比损失，结合时间感知软目标，同时整合时间相邻约束以改进轨迹聚类。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，该方法将碎片化率降低了2.2倍，证明了时间感知在息肉计数中的重要性。&lt;h4&gt;结论&lt;/h4&gt;该方法在息肉计数中建立了新的标准，证明了时间感知在提高息肉计数准确度方面的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Automated polyp counting in colonoscopy is a crucial step toward automated procedure reporting and quality control, aiming to enhance the cost-effectiveness of colonoscopy screening. Counting polyps in a procedure involves detecting and tracking polyps, and then clustering tracklets that belong to the same polyp entity. Existing methods for polyp counting rely on self-supervised learning and primarily leverage visual appearance, neglecting temporal relationships in both tracklet feature learning and clustering stages. In this work, we introduce a paradigm shift by proposing a supervised contrastive loss that incorporates temporally-aware soft targets. Our approach captures intra-polyp variability while preserving inter-polyp discriminability, leading to more robust clustering. Additionally, we improve tracklet clustering by integrating a temporal adjacency constraint, reducing false positive re-associations between visually similar but temporally distant tracklets. We train and validate our method on publicly available datasets and evaluate its performance with a leave-one-out cross-validation strategy. Results demonstrate a 2.2x reduction in fragmentation rate compared to prior approaches. Our results highlight the importance of temporal awareness in polyp counting, establishing a new state-of-the-art. Code is available at https://github.com/lparolari/temporally-aware-polyp-counting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated polyp counting in colonoscopy is a crucial step toward automatedprocedure reporting and quality control, aiming to enhance thecost-effectiveness of colonoscopy screening. Counting polyps in a procedureinvolves detecting and tracking polyps, and then clustering tracklets thatbelong to the same polyp entity. Existing methods for polyp counting rely onself-supervised learning and primarily leverage visual appearance, neglectingtemporal relationships in both tracklet feature learning and clustering stages.In this work, we introduce a paradigm shift by proposing a supervisedcontrastive loss that incorporates temporally-aware soft targets. Our approachcaptures intra-polyp variability while preserving inter-polyp discriminability,leading to more robust clustering. Additionally, we improve tracklet clusteringby integrating a temporal adjacency constraint, reducing false positivere-associations between visually similar but temporally distant tracklets. Wetrain and validate our method on publicly available datasets and evaluate itsperformance with a leave-one-out cross-validation strategy. Results demonstratea 2.2x reduction in fragmentation rate compared to prior approaches. Ourresults highlight the importance of temporal awareness in polyp counting,establishing a new state-of-the-art. Code is available athttps://github.com/lparolari/temporally-aware-polyp-counting.</description>
      <author>example@mail.com (Luca Parolari, Andrea Cherubini, Lamberto Ballan, Carlo Biffi)</author>
      <guid isPermaLink="false">2507.02493v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Weakly-supervised Contrastive Learning with Quantity Prompts for Moving Infrared Small Target Detection</title>
      <link>http://arxiv.org/abs/2507.02454v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的弱监督对比学习方案（WeCoL），用于移动红外小目标的检测，以减少对标注的需求。&lt;h4&gt;背景&lt;/h4&gt;移动红外小目标检测面临挑战，因为目标尺寸小且背景对比度弱，目前大多数方法依赖大量手动标注，这既昂贵又耗时。&lt;h4&gt;目的&lt;/h4&gt;提出一种弱监督方法来减少标注需求，突破传统的全监督框架。&lt;h4&gt;方法&lt;/h4&gt;基于预训练的segment anything模型（SAM），设计了一种潜在目标挖掘策略，结合目标激活图和多帧能量累积。采用对比学习来提高伪标签的可靠性，并通过计算特征子空间中正负样本的相似性。此外，提出了长短期运动感知学习方案，以同时建模小目标的局部运动模式和全局运动轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;在DAUB和ITSDT-15K两个公共数据集上的实验表明，所提出的弱监督方案通常优于早期全监督方法，性能甚至可以超过最先进的全监督方法超过90%。&lt;h4&gt;结论&lt;/h4&gt;WeCoL方案能够有效减少标注需求，提高移动红外小目标检测的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Different from general object detection, moving infrared small target detection faces huge challenges due to tiny target size and weak background contrast. Currently, most existing methods are fully-supervised, heavily relying on a large number of manual target-wise annotations. However, manually annotating video sequences is often expensive and time-consuming, especially for low-quality infrared frame images. Inspired by general object detection, non-fully supervised strategies (e.g., weakly supervised) are believed to be potential in reducing annotation requirements. To break through traditional fully-supervised frameworks, as the first exploration work, this paper proposes a new weakly-supervised contrastive learning (WeCoL) scheme, only requiring simple target quantity prompts during model training. Specifically, in our scheme, based on the pretrained segment anything model (SAM), a potential target mining strategy is designed to integrate target activation maps and multi-frame energy accumulation. Besides, contrastive learning is adopted to further improve the reliability of pseudo-labels, by calculating the similarity between positive and negative samples in feature subspace. Moreover, we propose a long-short term motion-aware learning scheme to simultaneously model the local motion patterns and global motion trajectory of small targets. The extensive experiments on two public datasets (DAUB and ITSDT-15K) verify that our weakly-supervised scheme could often outperform early fully-supervised methods. Even, its performance could reach over 90% of state-of-the-art (SOTA) fully-supervised ones.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Different from general object detection, moving infrared small targetdetection faces huge challenges due to tiny target size and weak backgroundcontrast.Currently, most existing methods are fully-supervised, heavily relyingon a large number of manual target-wise annotations. However, manuallyannotating video sequences is often expensive and time-consuming, especiallyfor low-quality infrared frame images. Inspired by general object detection,non-fully supervised strategies ($e.g.$, weakly supervised) are believed to bepotential in reducing annotation requirements. To break through traditionalfully-supervised frameworks, as the first exploration work, this paper proposesa new weakly-supervised contrastive learning (WeCoL) scheme, only requiressimple target quantity prompts during model training.Specifically, in ourscheme, based on the pretrained segment anything model (SAM), a potentialtarget mining strategy is designed to integrate target activation maps andmulti-frame energy accumulation.Besides, contrastive learning is adopted tofurther improve the reliability of pseudo-labels, by calculating the similaritybetween positive and negative samples in feature subspace.Moreover, we proposea long-short term motion-aware learning scheme to simultaneously model thelocal motion patterns and global motion trajectory of small targets.Theextensive experiments on two public datasets (DAUB and ITSDT-15K) verify thatour weakly-supervised scheme could often outperform early fully-supervisedmethods. Even, its performance could reach over 90\% of state-of-the-art (SOTA)fully-supervised ones.</description>
      <author>example@mail.com (Weiwei Duan, Luping Ji, Shengjia Chen, Sicheng Zhu, Jianghong Huang, Mao Ye)</author>
      <guid isPermaLink="false">2507.02454v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>MvHo-IB: Multi-View Higher-Order Information Bottleneck for Brain Disorder Diagnosis</title>
      <link>http://arxiv.org/abs/2507.02847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI-25, code is available at  \url{https://github.com/zky04/MvHo-IB}&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为MvHo-IB的多视图学习框架，用于在fMRI数据中建模高级交互（HOIs），以提高机器学习系统的诊断准确性。&lt;h4&gt;背景&lt;/h4&gt;研究表明，在fMRI数据中建模高级交互可以提高机器学习系统的诊断准确性，但有效提取和利用这些交互仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出MvHo-IB框架，旨在通过整合成对交互和高级交互，同时自动压缩任务无关的冗余信息，来提高诊断决策的准确性。&lt;h4&gt;方法&lt;/h4&gt;MvHo-IB框架的主要创新包括：(1) 一种结合信息论中的O信息和基于矩阵的Renyi alpha-order熵估计器的方法，用于量化提取高级交互；(2) 一种专为脑部3DCNN编码设计的编码器，以有效利用这些交互；(3) 一种新的多视图学习信息瓶颈目标，以增强表示学习。&lt;h4&gt;主要发现&lt;/h4&gt;在三个基准fMRI数据集上的实验表明，MvHo-IB实现了最先进的性能，显著优于包括最近基于超图的技术在内的先前方法。&lt;h4&gt;结论&lt;/h4&gt;MvHo-IB框架在提高fMRI数据的机器学习诊断准确性方面具有显著潜力。&lt;h4&gt;翻译&lt;/h4&gt;Recent evidence suggests that modeling higher-order interactions (HOIs) in functional magnetic resonance imaging (fMRI) data can enhance the diagnostic accuracy of machine learning systems. However, effectively extracting and utilizing HOIs remains a significant challenge. In this work, we propose MvHo-IB, a novel multi-view learning framework that integrates both pairwise interactions and HOIs for diagnostic decision-making, while automatically compressing task-irrelevant redundant information. MvHo-IB introduces several key innovations: (1) a principled method that combines O-information from information theory with a matrix-based Renyi alpha-order entropy estimator to quantify and extract HOIs, (2) a purpose-built Brain3DCNN encoder to effectively utilize these interactions, and (3) a new multi-view learning information bottleneck objective to enhance representation learning. Experiments on three benchmark fMRI datasets demonstrate that MvHo-IB achieves state-of-the-art performance, significantly outperforming previous methods, including recent hypergraph-based techniques. The implementation of MvHo-IB is available at https://github.com/zky04/MvHo-IB.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent evidence suggests that modeling higher-order interactions (HOIs) infunctional magnetic resonance imaging (fMRI) data can enhance the diagnosticaccuracy of machine learning systems. However, effectively extracting andutilizing HOIs remains a significant challenge. In this work, we proposeMvHo-IB, a novel multi-view learning framework that integrates both pairwiseinteractions and HOIs for diagnostic decision-making, while automaticallycompressing task-irrelevant redundant information. MvHo-IB introduces severalkey innovations: (1) a principled method that combines O-information frominformation theory with a matrix-based Renyi alpha-order entropy estimator toquantify and extract HOIs, (2) a purpose-built Brain3DCNN encoder toeffectively utilize these interactions, and (3) a new multi-view learninginformation bottleneck objective to enhance representation learning.Experiments on three benchmark fMRI datasets demonstrate that MvHo-IB achievesstate-of-the-art performance, significantly outperforming previous methods,including recent hypergraph-based techniques. The implementation of MvHo-IB isavailable at https://github.com/zky04/MvHo-IB.</description>
      <author>example@mail.com (Kunyu Zhang, Qiang Li, Shujian Yu)</author>
      <guid isPermaLink="false">2507.02847v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Fx-Encoder++: Extracting Instrument-Wise Audio Effects Representations from Mixtures</title>
      <link>http://arxiv.org/abs/2507.02273v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ISMIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为Fx-Encoder++的新模型，用于从音乐混音中提取乐器级的音频效果表示，并展示其在音频检索和音频效果参数匹配任务中的优越性。&lt;h4&gt;背景&lt;/h4&gt;通用音频表示在音乐信息检索应用中有效，但在智能音乐制作中由于对音频效果（Fx）理解不足而受限。&lt;h4&gt;目的&lt;/h4&gt;设计Fx-Encoder++模型以解决智能音乐制作系统中音频效果理解的能力差距。&lt;h4&gt;方法&lt;/h4&gt;模型利用对比学习框架，引入一个“提取器”机制，将混音级别的音频效果嵌入转换为乐器级的音频效果嵌入。&lt;h4&gt;主要发现&lt;/h4&gt;Fx-Encoder++在混音级别上优于先前的方法，并展示了提取乐器级效果表示的新能力。&lt;h4&gt;结论&lt;/h4&gt;该模型为智能音乐制作系统提供了一种关键的音频效果理解能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; General-purpose audio representations have proven effective across diversemusic information retrieval applications, yet their utility in intelligentmusic production remains limited by insufficient understanding of audio effects(Fx). Although previous approaches have emphasized audio effects analysis atthe mixture level, this focus falls short for tasks demanding instrument-wiseaudio effects understanding, such as automatic mixing. In this work, we presentFx-Encoder++, a novel model designed to extract instrument-wise audio effectsrepresentations from music mixtures. Our approach leverages a contrastivelearning framework and introduces an "extractor" mechanism that, when providedwith instrument queries (audio or text), transforms mixture-level audio effectsembeddings into instrument-wise audio effects embeddings. We evaluated ourmodel across retrieval and audio effects parameter matching tasks, testing itsperformance across a diverse range of instruments. The results demonstrate thatFx-Encoder++ outperforms previous approaches at mixture level and show a novelability to extract effects representation instrument-wise, addressing acritical capability gap in intelligent music production systems.</description>
      <author>example@mail.com (Yen-Tung Yeh, Junghyun Koo, Marco A. Martínez-Ramírez, Wei-Hsiang Liao, Yi-Hsuan Yang, Yuki Mitsufuji)</author>
      <guid isPermaLink="false">2507.02273v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>ASDA: Audio Spectrogram Differential Attention Mechanism for Self-Supervised Representation Learning</title>
      <link>http://arxiv.org/abs/2507.02666v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at Interspeech2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种改进的音频自监督表征学习方法，该方法的注意力机制能够有效分配注意力权重，提高了模型在音频任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;当前音频自监督表征学习的研究中，标准Transformer架构占主导地位，但其注意力机制容易将权重分配给无关信息，影响模型的区分能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种差分注意力机制，通过集成双softmax操作和适当调整的差分系数来有效减轻无效注意力分配的问题。&lt;h4&gt;方法&lt;/h4&gt;开发了一个名为ASDA（Adaptive Differential Attention）的模型，该模型结合了双softmax操作和差分系数，以优化注意力分配。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ASDA模型在多个基准测试中达到了最先进的性能，包括音频分类（AS-2M上49.0% mAP，AS20K上41.5% mAP）、关键词检测（SPC-2上98.3%准确率）和环境声音分类（ESC-50上96.1%准确率）。&lt;h4&gt;结论&lt;/h4&gt;ASDA模型在音频任务中的有效性得到验证，为更广泛的应用开辟了道路。&lt;h4&gt;翻译&lt;/h4&gt;在音频自监督表征学习的最近进展中，标准的Transformer架构已成为主导方法，但其注意力机制通常将一部分注意力权重分配给无关信息，可能会损害模型的区分能力。为了解决这个问题，我们提出了一种差分注意力机制，通过集成双softmax操作和适当调整的差分系数有效地减轻了无效的注意力分配。实验结果表明，我们的ASDA模型在多个基准上实现了最先进的性能，包括音频分类（AS-2M上的49.0% mAP，AS20K上的41.5% mAP）、关键词检测（SPC-2上的98.3%准确率）和环境声音分类（ESC-50上的96.1%准确率）。这些结果突出了ASDA在音频任务中的有效性，为更广泛的应用铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent advancements in audio self-supervised representation learning, thestandard Transformer architecture has emerged as the predominant approach, yetits attention mechanism often allocates a portion of attention weights toirrelevant information, potentially impairing the model's discriminativeability. To address this, we introduce a differential attention mechanism,which effectively mitigates ineffective attention allocation through theintegration of dual-softmax operations and appropriately tuned differentialcoefficients. Experimental results demonstrate that our ASDA model achievesstate-of-the-art (SOTA) performance across multiple benchmarks, including audioclassification (49.0% mAP on AS-2M, 41.5% mAP on AS20K), keyword spotting(98.3% accuracy on SPC-2), and environmental sound classification (96.1%accuracy on ESC-50). These results highlight ASDA's effectiveness in audiotasks, paving the way for broader applications.</description>
      <author>example@mail.com (Junyu Wang, Tianrui Wang, Meng Ge, Longbiao Wang, Jianwu Dang)</author>
      <guid isPermaLink="false">2507.02666v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>AnyI2V: Animating Any Conditional Image with Motion Control</title>
      <link>http://arxiv.org/abs/2507.02857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025, Project Page: https://henghuiding.com/AnyI2V/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AnyI2V的训练免费框架，用于动画化任何条件图像，并通过用户定义的运动轨迹实现动画。该框架支持多种模态，包括网格和点云等数据类型，并支持混合条件输入、风格迁移和编辑。&lt;h4&gt;背景&lt;/h4&gt;视频生成领域，尤其是扩散模型，在文本到视频（T2V）和图像到视频（I2V）合成方面取得了显著进展。然而，现有方法在动态运动信号和灵活的空间约束集成方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法的局限性，旨在提出一种新的视频生成方法，能够提供更精确的空间和运动控制。&lt;h4&gt;方法&lt;/h4&gt;AnyI2V框架通过用户定义的运动轨迹来动画化任何条件图像，支持更广泛的模态，如网格和点云，同时支持混合条件输入和通过LoRA和文本提示进行风格迁移和编辑。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AnyI2V在视频生成性能上优于现有方法，为空间和运动控制视频生成提供了新的视角。&lt;h4&gt;结论&lt;/h4&gt;AnyI2V是一个创新的视频生成框架，它通过提供更灵活和多样化的功能，为视频合成领域带来了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in video generation, particularly in diffusion models, have driven notable progress in text-to-video (T2V) and image-to-video (I2V) synthesis. However, challenges remain in effectively integrating dynamic motion signals and flexible spatial constraints. Existing T2V methods typically rely on text prompts, which inherently lack precise control over the spatial layout of generated content. In contrast, I2V methods are limited by their dependence on real images, which restricts the editability of the synthesized content. Although some methods incorporate ControlNet to introduce image-based conditioning, they often lack explicit motion control and require computationally expensive training. To address these limitations, we propose AnyI2V, a training-free framework that animates any conditional images with user-defined motion trajectories. AnyI2V supports a broader range of modalities as the conditional image, including data types such as meshes and point clouds that are not supported by ControlNet, enabling more flexible and versatile video generation. Additionally, it supports mixed conditional inputs and enables style transfer and editing via LoRA and text prompts. Extensive experiments demonstrate that the proposed AnyI2V achieves superior performance and provides a new perspective in spatial- and motion-controlled video generation. Code is available at https://henghuiding.com/AnyI2V/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in video generation, particularly in diffusion models,have driven notable progress in text-to-video (T2V) and image-to-video (I2V)synthesis. However, challenges remain in effectively integrating dynamic motionsignals and flexible spatial constraints. Existing T2V methods typically relyon text prompts, which inherently lack precise control over the spatial layoutof generated content. In contrast, I2V methods are limited by their dependenceon real images, which restricts the editability of the synthesized content.Although some methods incorporate ControlNet to introduce image-basedconditioning, they often lack explicit motion control and requirecomputationally expensive training. To address these limitations, we proposeAnyI2V, a training-free framework that animates any conditional images withuser-defined motion trajectories. AnyI2V supports a broader range of modalitiesas the conditional image, including data types such as meshes and point cloudsthat are not supported by ControlNet, enabling more flexible and versatilevideo generation. Additionally, it supports mixed conditional inputs andenables style transfer and editing via LoRA and text prompts. Extensiveexperiments demonstrate that the proposed AnyI2V achieves superior performanceand provides a new perspective in spatial- and motion-controlled videogeneration. Code is available at https://henghuiding.com/AnyI2V/.</description>
      <author>example@mail.com (Ziye Li, Hao Luo, Xincheng Shuai, Henghui Ding)</author>
      <guid isPermaLink="false">2507.02857v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>RoboBrain 2.0 Technical Report</title>
      <link>http://arxiv.org/abs/2507.02029v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了RoboBrain 2.0，这是新一代的具身视觉-语言基础模型，旨在统一感知、推理和规划，以应对物理环境中的复杂具身任务。&lt;h4&gt;背景&lt;/h4&gt;RoboBrain 2.0有两种变体：一个轻量级的7B模型和一个全规模的32B模型，具有异构架构，包括视觉编码器和语言模型。&lt;h4&gt;目的&lt;/h4&gt;通过RoboBrain 2.0，旨在推进具身人工智能研究，并作为构建通用具身智能体的实际步骤。&lt;h4&gt;方法&lt;/h4&gt;详细描述了模型架构、数据构建、多阶段训练策略、基础设施和实际应用。&lt;h4&gt;主要发现&lt;/h4&gt;32B变体在空间和时间基准测试中取得了领先结果，超过了先前开源和专有模型。它支持空间理解（如可及性预测、空间指称、轨迹预测）和时序决策（如闭环交互、多智能体长期规划、场景图更新）等关键真实世界具身人工智能能力。&lt;h4&gt;结论&lt;/h4&gt;RoboBrain 2.0在广泛的具身推理任务上实现了强大的性能，为具身人工智能研究提供了新的进展。&lt;h4&gt;翻译&lt;/h4&gt;We introduce RoboBrain 2.0, our latest generation of embodied vision-language foundation models, designed to unify perception, reasoning, and planning for complex embodied tasks in physical environments. It comes in two variants: a lightweight 7B model and a full-scale 32B model, featuring a heterogeneous architecture with a vision encoder and a language model. Despite its compact size, RoboBrain 2.0 achieves strong performance across a wide spectrum of embodied reasoning tasks. On both spatial and temporal benchmarks, the 32B variant achieves leading results, surpassing prior open-source and proprietary models. In particular, it supports key real-world embodied AI capabilities, including spatial understanding (e.g., affordance prediction, spatial referring, trajectory forecasting) and temporal decision-making (e.g., closed-loop interaction, multi-agent long-horizon planning, and scene graph updating). This report details the model architecture, data construction, multi-stage training strategies, infrastructure and practical applications. We hope RoboBrain 2.0 advances embodied AI research and serves as a practical step toward building generalist embodied agents. The code, checkpoint and benchmark are available at https://superrobobrain.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce RoboBrain 2.0, our latest generation of embodied vision-languagefoundation models, designed to unify perception, reasoning, and planning forcomplex embodied tasks in physical environments. It comes in two variants: alightweight 7B model and a full-scale 32B model, featuring a heterogeneousarchitecture with a vision encoder and a language model. Despite its compactsize, RoboBrain 2.0 achieves strong performance across a wide spectrum ofembodied reasoning tasks. On both spatial and temporal benchmarks, the 32Bvariant achieves leading results, surpassing prior open-source and proprietarymodels. In particular, it supports key real-world embodied AI capabilities,including spatial understanding (e.g., affordance prediction, spatialreferring, trajectory forecasting) and temporal decision-making (e.g.,closed-loop interaction, multi-agent long-horizon planning, and scene graphupdating). This report details the model architecture, data construction,multi-stage training strategies, infrastructure and practical applications. Wehope RoboBrain 2.0 advances embodied AI research and serves as a practical steptoward building generalist embodied agents. The code, checkpoint and benchmarkare available at https://superrobobrain.github.io.</description>
      <author>example@mail.com (BAAI RoboBrain Team, Mingyu Cao, Huajie Tan, Yuheng Ji, Minglan Lin, Zhiyu Li, Zhou Cao, Pengwei Wang, Enshen Zhou, Yi Han, Yingbo Tang, Xiangqi Xu, Wei Guo, Yaoxu Lyu, Yijie Xu, Jiayu Shi, Cheng Chi, Mengdi Zhao, Xiaoshuai Hao, Shanyu Rong, Zhengliang Cai, Bolun Zhang, Shuyi Zhang, Huaihai Lyu, Mengfei Du, Lingfeng Zhang, Xi Feng, Xiaodan Liu, Yance Jiao, Chenrui He, Mengsi Lyu, Zhuo Chen, Yulong Ao, Xue Sun, Zheqi He, Jingshu Zheng, Xi Yang, Donghai Shi, Kunchang Xie, Bochao Zhang, Shaokai Nie, Chunlei Men, Yonghua Lin, Zhongyuan Wang, Tiejun Huang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2507.02029v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Variational Kolmogorov-Arnold Network</title>
      <link>http://arxiv.org/abs/2507.02466v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  A preliminary (short paper) version presented at ComBayNS Workshop at  IJCNN'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为InfinityKAN的新型机器学习模型架构，该架构基于Kolmogorov-Arnold定理及其扩展，通过自适应学习无限数量的基函数来构建多变量连续有界函数的精确表示。&lt;h4&gt;背景&lt;/h4&gt;Kolmogorov Arnold Networks (KANs)是一种新兴的机器学习模型架构，其理论基础为Kolmogorov-Arnold定理及其扩展，这些理论能够将多变量连续有界函数精确表示为有限个一元连续函数的组合。&lt;h4&gt;目的&lt;/h4&gt;研究如何通过自适应学习无限数量的基函数来解决问题，即在使用KANs时如何选择每个一元函数的基函数数量。&lt;h4&gt;方法&lt;/h4&gt;将问题建模为一个变分推理优化问题，并提出了InfinityKAN方法，该方法使用反向传播来扩展KANs的应用范围，将重要的超参数视为学习过程的一部分。&lt;h4&gt;主要发现&lt;/h4&gt;InfinityKAN方法能够自适应地学习无限数量的基函数，从而提高了KANs在构建多变量连续有界函数表示时的精确性和适用性。&lt;h4&gt;结论&lt;/h4&gt;InfinityKAN方法通过优化学习过程，扩展了KANs的应用范围，为机器学习模型构建提供了一种新的选择。&lt;h4&gt;翻译&lt;/h4&gt;Kolmogorov Arnold Networks (KANs) 是一种新兴的机器学习模型架构。基于 Kolmogorov-Arnold 定理及其扩展的理论基础，它能够将多变量连续有界函数精确表示为有限个一元连续函数的组合。虽然这些理论结果非常强大，但将它们作为多层感知器 (MLP) 的替代品用于表示学习时，其使用取决于对每个一元函数建模的基函数数量的随意选择。在这项工作中，我们展示了如何通过在训练过程中自适应地学习每个一元函数的潜在无限数量的基函数来解决此问题。因此，我们将问题建模为一个变分推理优化问题。我们提出的名为 InfinityKAN 的方法，使用反向传播，通过将一个重要的超参数视为学习过程的一部分，扩展了 KANs 的潜在适用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Kolmogorov Arnold Networks (KANs) are an emerging architecture for buildingmachine learning models. KANs are based on the theoretical foundation of theKolmogorov-Arnold Theorem and its expansions, which provide an exactrepresentation of a multi-variate continuous bounded function as thecomposition of a limited number of univariate continuous functions. While suchtheoretical results are powerful, their use as a representation learningalternative to a multi-layer perceptron (MLP) hinges on the ad-hoc choice ofthe number of bases modeling each of the univariate functions. In this work, weshow how to address this problem by adaptively learning a potentially infinitenumber of bases for each univariate function during training. We thereforemodel the problem as a variational inference optimization problem. Ourproposal, called InfinityKAN, which uses backpropagation, extends the potentialapplicability of KANs by treating an important hyperparameter as part of thelearning process.</description>
      <author>example@mail.com (Francesco Alesiani, Henrik Christiansen, Federico Errica)</author>
      <guid isPermaLink="false">2507.02466v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation</title>
      <link>http://arxiv.org/abs/2507.01961v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project website: https://ac-dit.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AC-DiT的适应性协调扩散变换器，用于增强移动基础和操作器的协调，以实现端到端的移动操作。&lt;h4&gt;背景&lt;/h4&gt;移动操作在家庭任务中实现语言条件下的机器人控制受到越来越多的关注，但现有的方法在协调移动基础和操作器方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法在协调移动基础和操作器时的问题，提出了AC-DiT。&lt;h4&gt;方法&lt;/h4&gt;AC-DiT通过引入移动性到身体条件机制，首先提取基础运动表示，并将其用作预测全身动作的上下文先验，从而实现考虑移动基础运动影响的全身控制。此外，为了满足移动操作不同阶段的感知需求，设计了感知感知的多模态条件策略，动态调整不同2D视觉图像和3D点云之间的融合权重，以提供符合当前感知需求的视觉特征。&lt;h4&gt;主要发现&lt;/h4&gt;AC-DiT通过实验在模拟和真实世界的移动操作任务中得到了验证。&lt;h4&gt;结论&lt;/h4&gt;AC-DiT通过提高移动基础和操作器的协调能力，为移动操作提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;最近，移动操作因其在家庭任务中实现语言条件下的机器人控制而受到越来越多的关注。然而，现有的方法在协调移动基础和操作器方面仍面临挑战，这主要是由于两个限制。一方面，它们未能明确建模移动基础对操作器控制的影响，这容易在高自由度下导致误差累积。另一方面，它们以相同的视觉观察模式（例如，要么全部是2D，要么全部是3D）处理整个移动操作过程，忽略了移动操作不同阶段的多模态感知需求。为了解决这个问题，我们提出了适应性协调扩散变换器（AC-DiT），它增强了移动基础和操作器的端到端移动操作协调。首先，由于移动基座的运动直接影响操作器的动作，我们引入了一种移动性到身体条件机制，引导模型首先提取基座运动表示，然后将其用作预测全身动作的上下文先验。这使全身控制能够考虑到移动基座运动的影响。其次，为了满足移动操作不同阶段的感知需求，我们设计了一种感知感知的多模态条件策略，动态调整各种2D视觉图像和3D点云之间的融合权重，从而产生符合当前感知需求的视觉特征。这使得模型能够，例如，在语义信息对动作预测至关重要时，自适应地更多地依赖2D输入，而在需要精确空间理解时，则更加重视3D几何信息。我们通过在模拟和真实世界的移动操作任务上的大量实验验证了AC-DiT。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, mobile manipulation has attracted increasing attention for enablinglanguage-conditioned robotic control in household tasks. However, existingmethods still face challenges in coordinating mobile base and manipulator,primarily due to two limitations. On the one hand, they fail to explicitlymodel the influence of the mobile base on manipulator control, which easilyleads to error accumulation under high degrees of freedom. On the other hand,they treat the entire mobile manipulation process with the same visualobservation modality (e.g., either all 2D or all 3D), overlooking the distinctmultimodal perception requirements at different stages during mobilemanipulation. To address this, we propose the Adaptive Coordination DiffusionTransformer (AC-DiT), which enhances mobile base and manipulator coordinationfor end-to-end mobile manipulation. First, since the motion of the mobile basedirectly influences the manipulator's actions, we introduce a mobility-to-bodyconditioning mechanism that guides the model to first extract base motionrepresentations, which are then used as context prior for predicting whole-bodyactions. This enables whole-body control that accounts for the potential impactof the mobile base's motion. Second, to meet the perception requirements atdifferent stages of mobile manipulation, we design a perception-awaremultimodal conditioning strategy that dynamically adjusts the fusion weightsbetween various 2D visual images and 3D point clouds, yielding visual featurestailored to the current perceptual needs. This allows the model to, forexample, adaptively rely more on 2D inputs when semantic information is crucialfor action prediction, while placing greater emphasis on 3D geometricinformation when precise spatial understanding is required. We validate AC-DiTthrough extensive experiments on both simulated and real-world mobilemanipulation tasks.</description>
      <author>example@mail.com (Sixiang Chen, Jiaming Liu, Siyuan Qian, Han Jiang, Lily Li, Renrui Zhang, Zhuoyang Liu, Chenyang Gu, Chengkai Hou, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2507.01961v2</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>NGAT: A Node-level Graph Attention Network for Long-term Stock Prediction</title>
      <link>http://arxiv.org/abs/2507.02018v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对金融应用中图表示学习方法面临的挑战，提出了一种新的股票预测任务和Node-level GraphAttention Network模型。&lt;h4&gt;背景&lt;/h4&gt;图表示学习方法在金融应用中广泛应用，但现有方法存在三个主要问题：关系信息优势被下游任务设计限制、图模型复杂度高且泛化能力差、企业关系图构建缺乏有效比较。&lt;h4&gt;目的&lt;/h4&gt;提出长期股票预测任务，开发适用于企业关系图的Node-level GraphAttention Network模型，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;设计长期股票预测任务，开发NGAT模型，并通过实验验证模型的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的任务和模型在两个数据集上均表现出有效性，并揭示了现有图比较方法的局限性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的模型和方法能够有效提高金融应用中图表示学习的效果。&lt;h4&gt;翻译&lt;/h4&gt;Graph representation learning methods have been widely adopted in financial applications to enhance company representations by leveraging inter-firm relationships. However, current approaches face three key challenges: (1) The advantages of relational information are obscured by limitations in downstream task designs; (2) Existing graph models specifically designed for stock prediction often suffer from excessive complexity and poor generalization; (3) Experience-based construction of corporate relationship graphs lacks effective comparison of different graph structures. To address these limitations, we propose a long-term stock prediction task and develop a Node-level GraphAttention Network (NGAT) specifically tailored for corporate relationship graphs. Furthermore, we experimentally demonstrate the limitations of existing graph comparison methods based on model downstream task performance. Experimental results across two datasets consistently demonstrate the effectiveness of our proposed task and model. The project is publicly available on GitHub to encourage reproducibility and future research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning methods have been widely adopted in financialapplications to enhance company representations by leveraging inter-firmrelationships. However, current approaches face three key challenges: (1) Theadvantages of relational information are obscured by limitations in downstreamtask designs; (2) Existing graph models specifically designed for stockprediction often suffer from excessive complexity and poor generalization; (3)Experience-based construction of corporate relationship graphs lacks effectivecomparison of different graph structures. To address these limitations, wepropose a long-term stock prediction task and develop a Node-level GraphAttention Network (NGAT) specifically tailored for corporate relationshipgraphs. Furthermore, we experimentally demonstrate the limitations of existinggraph comparison methods based on model downstream task performance.Experimental results across two datasets consistently demonstrate theeffectiveness of our proposed task and model. The project is publicly availableon GitHub to encourage reproducibility and future research.</description>
      <author>example@mail.com (Yingjie Niu, Mingchuan Zhao, Valerio Poti, Ruihai Dong)</author>
      <guid isPermaLink="false">2507.02018v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans</title>
      <link>http://arxiv.org/abs/2507.02861v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://litereality.github.io; Video:  https://www.youtube.com/watch?v=ecK9m3LXg2c&amp;feature=youtu.be&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了LiteReality，一个将室内环境的RGB-D扫描转换为紧凑、逼真和交互式3D虚拟副本的新方法。&lt;h4&gt;背景&lt;/h4&gt;现有的方法无法完全重建场景，且不支持图形管线的关键特性。&lt;h4&gt;目的&lt;/h4&gt;创建一个能够重建视觉上类似现实的场景，并支持对象个性、关节、高质量基于物理的渲染材料和基于物理的交互。&lt;h4&gt;方法&lt;/h4&gt;LiteReality首先通过结构化场景图理解场景并解析为一致的3D布局和对象，然后从精选的资产数据库中检索最相似的3D艺术家模型来重建场景。Material Painting模块通过恢复高质量的、空间变化的材料来增强逼真度。最后，重建的场景被集成到一个具有基本物理属性的模拟引擎中，以实现交互行为。&lt;h4&gt;主要发现&lt;/h4&gt;LiteReality引入了一个无需训练的对象检索模块，在Scan2CAD基准测试上实现了最先进的相似度性能，并具有一个强大的材料绘制模块，能够将任何风格的图像外观转移到3D资产上，即使在严重的错位、遮挡和不良光照下。&lt;h4&gt;结论&lt;/h4&gt;LiteReality生成的场景紧凑、可编辑，完全兼容标准图形管线，适用于AR/VR、游戏、机器人和数字孪生等应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose LiteReality, a novel pipeline that converts RGB-D scans of indoorenvironments into compact, realistic, and interactive 3D virtual replicas.LiteReality not only reconstructs scenes that visually resemble reality butalso supports key features essential for graphics pipelines -- such as objectindividuality, articulation, high-quality physically based rendering materials,and physically based interaction. At its core, LiteReality first performs sceneunderstanding and parses the results into a coherent 3D layout and objects withthe help of a structured scene graph. It then reconstructs the scene byretrieving the most visually similar 3D artist-crafted models from a curatedasset database. Next, the Material Painting module enhances realism byrecovering high-quality, spatially varying materials. Finally, thereconstructed scene is integrated into a simulation engine with basic physicalproperties to enable interactive behavior. The resulting scenes are compact,editable, and fully compatible with standard graphics pipelines, making themsuitable for applications in AR/VR, gaming, robotics, and digital twins. Inaddition, LiteReality introduces a training-free object retrieval module thatachieves state-of-the-art similarity performance on the Scan2CAD benchmark,along with a robust material painting module capable of transferringappearances from images of any style to 3D assets -- even under severemisalignment, occlusion, and poor lighting. We demonstrate the effectiveness ofLiteReality on both real-life scans and public datasets. Project page:https://litereality.github.io; Video:https://www.youtube.com/watch?v=ecK9m3LXg2c</description>
      <author>example@mail.com (Zhening Huang, Xiaoyang Wu, Fangcheng Zhong, Hengshuang Zhao, Matthias Nießner, Joan Lasenby)</author>
      <guid isPermaLink="false">2507.02861v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion</title>
      <link>http://arxiv.org/abs/2507.02813v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://liuff19.github.io/LangScene-X&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LangScene-X的新型生成框架，用于从2D图像中恢复3D结构，并通过嵌入语言信息实现开放词汇场景理解。&lt;h4&gt;背景&lt;/h4&gt;从2D图像恢复3D结构是一个基本但具有挑战性的任务。现有的方法依赖于校准的密集视图重建范式，当视图有限时，容易产生严重的渲染伪影和不合理的语义合成。&lt;h4&gt;目的&lt;/h4&gt;旨在通过统一的生成框架生成3D一致的多种模态信息，以实现重建和理解。&lt;h4&gt;方法&lt;/h4&gt;1. 训练一个TriMap视频扩散模型，可以从稀疏输入生成外观（RGB）、几何（法线）和语义（分割图）。2. 提出一种语言量化压缩器（LQC），用于高效编码语言嵌入，实现跨场景泛化，无需针对每个场景重新训练。3. 通过将语言信息对齐到3D场景的表面来重建语言表面场。&lt;h4&gt;主要发现&lt;/h4&gt;LangScene-X在真实世界数据上的实验表明，其在质量和泛化能力方面优于现有的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;LangScene-X框架能够有效地从稀疏视图中构建可泛化的3D语言嵌入场景，为开放式的语言查询提供了可能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使用开放词汇场景理解从2D图像恢复3D结构是一项基本但令人畏惧的任务。最近的发展通过执行每个场景的嵌入语言信息优化来实现这一点。然而，它们严重依赖于校准的密集视图重建范式，因此在视图有限时，会遭受严重的渲染伪影和不合理的语义合成。在本文中，我们介绍了一种新的生成框架，称为LangScene-X，以统一和生成用于重建和理解的3D一致的多模态信息。借助创建更一致的新观察结果的能力，我们可以仅从稀疏视图中构建可泛化的3D语言嵌入场景。具体来说，我们首先训练了一个TriMap视频扩散模型，该模型可以通过渐进式知识集成从稀疏输入生成外观（RGB）、几何（法线）和语义（分割图）。此外，我们提出了一种基于大规模图像数据集训练的语言量化压缩器（LQC），以有效地编码语言嵌入，实现跨场景泛化，无需针对每个场景重新训练。最后，我们通过将语言信息对齐到3D场景的表面来重建语言表面场，从而实现开放式的语言查询。在真实世界数据上的大量实验表明，我们的LangScene-X在质量和泛化能力方面优于最先进的方法。项目页面：https://liuff19.github.io/LangScene-X。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recovering 3D structures with open-vocabulary scene understanding from 2Dimages is a fundamental but daunting task. Recent developments have achievedthis by performing per-scene optimization with embedded language information.However, they heavily rely on the calibrated dense-view reconstructionparadigm, thereby suffering from severe rendering artifacts and implausiblesemantic synthesis when limited views are available. In this paper, weintroduce a novel generative framework, coined LangScene-X, to unify andgenerate 3D consistent multi-modality information for reconstruction andunderstanding. Powered by the generative capability of creating more consistentnovel observations, we can build generalizable 3D language-embedded scenes fromonly sparse views. Specifically, we first train a TriMap video diffusion modelthat can generate appearance (RGBs), geometry (normals), and semantics(segmentation maps) from sparse inputs through progressive knowledgeintegration. Furthermore, we propose a Language Quantized Compressor (LQC),trained on large-scale image datasets, to efficiently encode languageembeddings, enabling cross-scene generalization without per-scene retraining.Finally, we reconstruct the language surface fields by aligning languageinformation onto the surface of 3D scenes, enabling open-ended languagequeries. Extensive experiments on real-world data demonstrate the superiorityof our LangScene-X over state-of-the-art methods in terms of quality andgeneralizability. Project Page: https://liuff19.github.io/LangScene-X.</description>
      <author>example@mail.com (Fangfu Liu, Hao Li, Jiawei Chi, Hanyang Wang, Minghui Yang, Fudong Wang, Yueqi Duan)</author>
      <guid isPermaLink="false">2507.02813v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings</title>
      <link>http://arxiv.org/abs/2507.02403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in IEEE Xplore and ISIF FUSION 2025  proceedings:&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了野生动物再识别中的自监督学习方法，通过自监督学习模型提高了野生动物再识别的鲁棒性和性能。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的野生动物再识别模型依赖于标注数据进行监督学习，这促使了大量大规模野生动物数据集的创建。&lt;h4&gt;目的&lt;/h4&gt;探索自监督学习方法在野生动物再识别中的应用，以减少对标注数据的依赖。&lt;h4&gt;方法&lt;/h4&gt;使用相机陷阱数据中的时间图像对自动提取个体的两个不同视图，并在不监督的情况下训练自监督模型，该模型可以从视频数据流中不断学习。&lt;h4&gt;主要发现&lt;/h4&gt;自监督模型在有限数据的情况下表现出更强的鲁棒性，并且在所有下游任务中，自监督特征的表现优于监督特征。&lt;h4&gt;结论&lt;/h4&gt;自监督学习在野生动物再识别中具有潜力，可以减少对标注数据的依赖，并提高模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：野生动物重识别旨在匹配不同观察中同一物种的个体。当前最先进的（SOTA）模型依赖于类别标签来训练监督模型以进行个体分类。这种对标注数据的依赖促使了众多大规模野生动物数据集的整理。本研究调查了自监督学习（SSL）在野生动物重识别中的应用。我们使用相机陷阱数据中的时间图像对自动提取个体的两个不同视图，在不监督的情况下训练自监督模型。这些图像对从可能无限的视频数据流中训练自监督模型。我们评估了学习到的表示与开放世界场景和多种野生动物下游任务中的监督特征。实验结果的分析表明，自监督模型即使在有限数据的情况下也更具鲁棒性。此外，自监督特征在所有下游任务中都优于监督特征。代码可在以下链接获得：https://github.com/pxpana/SSLWildlife。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Wildlife re-identification aims to match individuals of the same speciesacross different observations. Current state-of-the-art (SOTA) models rely onclass labels to train supervised models for individual classification. Thisdependence on annotated data has driven the curation of numerous large-scalewildlife datasets. This study investigates self-supervised learningSelf-Supervised Learning (SSL) for wildlife re-identification. We automaticallyextract two distinct views of an individual using temporal image pairs fromcamera trap data without supervision. The image pairs train a self-supervisedmodel from a potentially endless stream of video data. We evaluate the learntrepresentations against supervised features on open-world scenarios andtransfer learning in various wildlife downstream tasks. The analysis of theexperimental results shows that self-supervised models are more robust evenwith limited data. Moreover, self-supervised features outperform supervisionacross all downstream tasks. The code is available herehttps://github.com/pxpana/SSLWildlife.</description>
      <author>example@mail.com (Mufhumudzi Muthivhi, Terence L. van Zyl)</author>
      <guid isPermaLink="false">2507.02403v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment</title>
      <link>http://arxiv.org/abs/2507.02705v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为SIU3R的无对齐框架，用于从无姿态图像中进行通用的同时理解和3D重建。&lt;h4&gt;背景&lt;/h4&gt;现有的2D到3D特征对齐方法限制了3D理解能力并可能导致语义信息损失。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个无对齐框架，能够同时进行理解和3D重建，且不依赖于2D模型的对齐。&lt;h4&gt;方法&lt;/h4&gt;SIU3R通过像素对齐的3D表示桥接重建和理解任务，并将多个理解任务统一为一系列可学习的查询，从而实现原生3D理解。此外，论文还提出了两个轻量级模块以促进两个任务之间的协作。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在3D重建和理解以及同时理解和3D重建任务上均达到最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;SIU3R框架的优势在于其无对齐特性以及通过模块设计实现的任务间协作效果。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a new alignment-free framework named SIU3R for generalizable simultaneous understanding and 3D reconstruction from unposed images. The background is that the existing 2D-to-3D feature alignment methods limit the 3D understanding capability and may lead to the loss of semantic information. The purpose is to develop an alignment-free framework that can perform simultaneous understanding and 3D reconstruction without relying on alignment with 2D models. The method uses pixel-aligned 3D representation to bridge the reconstruction and understanding tasks, and unifies multiple understanding tasks into a set of unified learnable queries, thereby achieving native 3D understanding. In addition, two lightweight modules are proposed to facilitate the interaction between the two tasks. Extensive experiments demonstrate that the method achieves state-of-the-art performance on both individual tasks of 3D reconstruction and understanding, as well as on the task of simultaneous understanding and 3D reconstruction, highlighting the advantages of the alignment-free framework and the effectiveness of the mutual benefit design.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simultaneous understanding and 3D reconstruction plays an important role indeveloping end-to-end embodied intelligent systems. To achieve this, recentapproaches resort to 2D-to-3D feature alignment paradigm, which leads tolimited 3D understanding capability and potential semantic information loss. Inlight of this, we propose SIU3R, the first alignment-free framework forgeneralizable simultaneous understanding and 3D reconstruction from unposedimages. Specifically, SIU3R bridges reconstruction and understanding tasks viapixel-aligned 3D representation, and unifies multiple understanding tasks intoa set of unified learnable queries, enabling native 3D understanding withoutthe need of alignment with 2D models. To encourage collaboration between thetwo tasks with shared representation, we further conduct in-depth analyses oftheir mutual benefits, and propose two lightweight modules to facilitate theirinteraction. Extensive experiments demonstrate that our method achievesstate-of-the-art performance not only on the individual tasks of 3Dreconstruction and understanding, but also on the task of simultaneousunderstanding and 3D reconstruction, highlighting the advantages of ouralignment-free framework and the effectiveness of the mutual benefit designs.</description>
      <author>example@mail.com (Qi Xu, Dongxu Wei, Lingzhe Zhao, Wenpu Li, Zhangchi Huang, Shunping Ji, Peidong Liu)</author>
      <guid isPermaLink="false">2507.02705v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Grounding Intelligence in Movement</title>
      <link>http://arxiv.org/abs/2507.02771v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;机器学习在语言、视觉等高维数据处理方面取得了显著进步，但在运动建模方面仍存在挑战。运动对于神经科学、医学、机器人和动物行为学至关重要，但通常被忽视。本文提出运动应该作为人工智能建模的主要目标。&lt;h4&gt;背景&lt;/h4&gt;尽管机器学习在语言、视觉数据处理方面取得了显著进步，但在运动建模方面仍然存在挑战。运动对于多种领域至关重要，但目前对运动数据的收集和建模存在局限性。&lt;h4&gt;目的&lt;/h4&gt;提出运动作为人工智能建模的主要目标，并强调其结构性和基于实体的特点。&lt;h4&gt;方法&lt;/h4&gt;分析运动数据的结构和特点，讨论其在不同领域中的应用。&lt;h4&gt;主要发现&lt;/h4&gt;运动反映了共享的物理约束、保守的形态结构和跨物种的动态，具有内在的结构和基于实体的特性。&lt;h4&gt;结论&lt;/h4&gt;发展能够从多样化的运动数据中学习和推广的模型，不仅会推进生成模型和控制的核心能力，而且为理解生物和人工系统中的行为提供共同的基础。&lt;h4&gt;翻译&lt;/h4&gt;摘要内容翻译&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in machine learning have dramatically improved our ability tomodel language, vision, and other high-dimensional data, yet they continue tostruggle with one of the most fundamental aspects of biological systems:movement. Across neuroscience, medicine, robotics, and ethology, movement isessential for interpreting behavior, predicting intent, and enablinginteraction. Despite its core significance in our intelligence, movement isoften treated as an afterthought rather than as a rich and structured modalityin its own right. This reflects a deeper fragmentation in how movement data iscollected and modeled, often constrained by task-specific goals anddomain-specific assumptions. But movement is not domain-bound. It reflectsshared physical constraints, conserved morphological structures, and purposefuldynamics that cut across species and settings. We argue that movement should betreated as a primary modeling target for AI. It is inherently structured andgrounded in embodiment and physics. This structure, often allowing for compact,lower-dimensional representations (e.g., pose), makes it more interpretable andcomputationally tractable to model than raw, high-dimensional sensory inputs.Developing models that can learn from and generalize across diverse movementdata will not only advance core capabilities in generative modeling andcontrol, but also create a shared foundation for understanding behavior acrossbiological and artificial systems. Movement is not just an outcome, it is awindow into how intelligent systems engage with the world.</description>
      <author>example@mail.com (Melanie Segado, Felipe Parodi, Jordan K. Matelsky, Michael L. Platt, Eva B. Dyer, Konrad P. Kording)</author>
      <guid isPermaLink="false">2507.02771v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Team RAS in 9th ABAW Competition: Multimodal Compound Expression Recognition Approach</title>
      <link>http://arxiv.org/abs/2507.02205v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的零样本多模态方法，用于复合情感识别（CER），该方法结合了六种异构模态，包括静态和动态面部表情、场景和标签匹配、场景上下文、音频和文本。&lt;h4&gt;背景&lt;/h4&gt;复合情感识别（CER）是情感计算的一个子领域，旨在检测由基本情感组合而成的复杂情感状态。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的零样本多模态方法，用于复合情感识别（CER），以捕捉复杂情感状态。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了六种异构模态，使用零样本组件，包括基于CLIP的标签匹配和Qwen-VL进行语义场景理解，并引入了多头概率融合（MHPF）模块和复合表达式（CE）转换模块，后者使用成对概率聚合（PPA）和成对特征相似度聚合（PFSA）方法产生可解释的复合情感输出。&lt;h4&gt;主要发现&lt;/h4&gt;在多语料库训练下，该方法在AffWild2、AFEW和C-EXPR-DB上的F1分数分别为46.95%、49.02%和34.85%，通过零样本测试，与在目标数据上训练的监督方法的结果相当。&lt;h4&gt;结论&lt;/h4&gt;该方法在无需领域自适应的情况下捕捉复合情感（CE）是有效的，并且源代码是公开的。&lt;h4&gt;翻译&lt;/h4&gt;The abstract summarizes a novel zero-shot multimodal approach for Compound Expression Recognition (CER) that combines six heterogeneous modalities into a single pipeline: static and dynamic facial expressions, scene and label matching, scene context, audio, and text. The approach uses zero-shot components and demonstrates effectiveness in capturing complex emotional states without domain adaptation. The source code is publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Compound Expression Recognition (CER), a subfield of affective computing,aims to detect complex emotional states formed by combinations of basicemotions. In this work, we present a novel zero-shot multimodal approach forCER that combines six heterogeneous modalities into a single pipeline: staticand dynamic facial expressions, scene and label matching, scene context, audio,and text. Unlike previous approaches relying on task-specific training data,our approach uses zero-shot components, including Contrastive Language-ImagePretraining (CLIP)-based label matching and Qwen-VL for semantic sceneunderstanding. We further introduce a Multi-Head Probability Fusion (MHPF)module that dynamically weights modality-specific predictions, followed by aCompound Expressions (CE) transformation module that uses Pair-Wise ProbabilityAggregation (PPA) and Pair-Wise Feature Similarity Aggregation (PFSA) methodsto produce interpretable compound emotion outputs. Evaluated under multi-corpustraining, the proposed approach shows F1 scores of 46.95% on AffWild2, 49.02%on Acted Facial Expressions in The Wild (AFEW), and 34.85% on C-EXPR-DB viazero-shot testing, which is comparable to the results of supervised approachestrained on target data. This demonstrates the effectiveness of the proposedapproach for capturing CE without domain adaptation. The source code ispublicly available.</description>
      <author>example@mail.com (Elena Ryumina, Maxim Markitantov, Alexandr Axyonov, Dmitry Ryumin, Mikhail Dolgushin, Alexey Karpov)</author>
      <guid isPermaLink="false">2507.02205v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>IntFold: A Controllable Foundation Model for General and Specialized Biomolecular Structure Prediction</title>
      <link>http://arxiv.org/abs/2507.02025v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了IntFold，这是一种可控制的生物分子结构预测基础模型，适用于通用和特定领域。&lt;h4&gt;背景&lt;/h4&gt;论文背景是生物分子结构预测领域，特别是AlphaFold3等先进模型的现状。&lt;h4&gt;目的&lt;/h4&gt;开发IntFold模型，以实现与AlphaFold3相当或更好的预测准确度，并扩展其应用范围。&lt;h4&gt;方法&lt;/h4&gt;IntFold使用定制的注意力核，并且可以通过适配器预测别构态、受约束的结构和结合亲和力。此外，引入了新的置信度头部来评估对接质量。&lt;h4&gt;主要发现&lt;/h4&gt;IntFold在标准结构预测方面表现出与AlphaFold3相当的预测准确性，并能适应多种预测任务，包括抗体-抗原复合物的对接质量评估。&lt;h4&gt;结论&lt;/h4&gt;IntFold是一个高效且功能丰富的生物分子结构预测模型，在训练过程中提供了有价值的见解。&lt;h4&gt;翻译&lt;/h4&gt;We introduce IntFold, a controllable foundation model for both general and specialized biomolecular structure prediction. IntFold demonstrates predictive accuracy comparable to the state-of-the-art AlphaFold3, while utilizing a superior customized attention kernel. Beyond standard structure prediction, IntFold can be adapted to predict allosteric states, constrained structures, and binding affinity through the use of individual adapters. Furthermore, we introduce a novel confidence head to estimate docking quality, offering a more nuanced assessment for challenging targets such as antibody-antigen complexes. Finally, we share insights gained during the training process of this computationally intensive model.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce IntFold, a controllable foundation model for both general andspecialized biomolecular structure prediction. IntFold demonstrates predictiveaccuracy comparable to the state-of-the-art AlphaFold3, while utilizing asuperior customized attention kernel. Beyond standard structure prediction,IntFold can be adapted to predict allosteric states, constrained structures,and binding affinity through the use of individual adapters. Furthermore, weintroduce a novel confidence head to estimate docking quality, offering a morenuanced assessment for challenging targets such as antibody-antigen complexes.Finally, we share insights gained during the training process of thiscomputationally intensive model.</description>
      <author>example@mail.com (The IntFold Team, Leon Qiao, Wayne Bai, He Yan, Gary Liu, Nova Xi, Xiang Zhang)</author>
      <guid isPermaLink="false">2507.02025v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Domain-Adversarial Transfer Learning for Fault Root Cause Identification in Cloud Computing Systems</title>
      <link>http://arxiv.org/abs/2507.02233v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对云计算环境中故障根源识别的挑战，提出了一种基于迁移学习的智能识别算法。&lt;h4&gt;背景&lt;/h4&gt;故障根源识别的困难源于复杂的系统结构、密集的服务耦合和有限的故障信息。&lt;h4&gt;目的&lt;/h4&gt;解决云计算环境中故障根源识别的问题。&lt;h4&gt;方法&lt;/h4&gt;方法引入了一个共享特征提取模块和领域对抗机制，以实现从源域到目标域的有效知识迁移。同时，采用伪标签选择策略，在目标域缺少标记样本时，使用高置信度预测进行训练，以增强模型识别少数类别的能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在准确性、F1分数和AUC等关键指标上优于现有主流方法，模型表现出更强的判别能力和鲁棒性。即使在极端类别不平衡和目标域中存在显著的结构差异时，模型仍能保持高性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在复杂云计算系统中验证了所提机制的有效性和实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-03&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenge of fault root cause identification incloud computing environments. The difficulty arises from complex systemstructures, dense service coupling, and limited fault information. To solvethis problem, an intelligent identification algorithm based on transferlearning is proposed. The method introduces a shared feature extraction moduleand a domain adversarial mechanism to enable effective knowledge transfer fromthe source domain to the target domain. This improves the model'sdiscriminative ability and generalization performance in the target domain. Themodel incorporates a pseudo-label selection strategy. When labeled samples arelacking in the target domain, high-confidence predictions are used in training.This enhances the model's ability to recognize minority classes. To evaluatethe stability and adaptability of the method in real-world scenarios,experiments are designed under three conditions: label scarcity, classimbalance, and heterogeneous node environments. Experimental results show thatthe proposed method outperforms existing mainstream approaches in several keymetrics, including accuracy, F1-Score, and AUC. The model demonstrates strongerdiscriminative power and robustness. Notably, under extreme class imbalance andsignificant structural differences in the target domain, the model stillmaintains high performance. This validates the effectiveness and practicalvalue of the proposed mechanisms in complex cloud computing systems.</description>
      <author>example@mail.com (Bruce Fang, Danyi Gao)</author>
      <guid isPermaLink="false">2507.02233v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Energy-Based Transformers are Scalable Learners and Thinkers</title>
      <link>http://arxiv.org/abs/2507.02092v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Energy-Based Transformers（EBTs）的新模型，该模型通过学习从无监督学习中思考，提高了模型的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的Inference-time computation techniques存在局限性，如模态特定、问题特定或需要额外的监督/训练。&lt;h4&gt;目的&lt;/h4&gt;探讨是否可以推广System 2 Thinking方法，并开发仅从无监督学习中学习的模型。&lt;h4&gt;方法&lt;/h4&gt;通过显式验证输入与候选预测之间的兼容性，并将预测问题重新定义为针对验证器的优化问题，训练Energy-Based Transformers（EBTs）。&lt;h4&gt;主要发现&lt;/h4&gt;EBTs在训练过程中比Transformer++方法更快地扩展，在数据、批量大小、参数、FLOPs和深度方面达到高达35%的更高扩展率。在推理过程中，EBTs在语言任务上比Transformer++提高了29%的性能，并且在图像去噪任务上优于Diffusion Transformers，同时使用的正向传递更少。此外，EBTs在大多数下游任务上比现有模型取得了更好的结果。&lt;h4&gt;结论&lt;/h4&gt;EBTs是一种有前途的新范式，可以扩展模型的学习和思考能力。&lt;h4&gt;翻译&lt;/h4&gt;Inference-time computation techniques, analogous to human System 2 Thinking, have recently become popular for improving model performances. However, most existing approaches suffer from several limitations: they are modality-specific (e.g., working only in text), problem-specific (e.g., verifiable domains like math and coding), or require additional supervision/training on top of unsupervised pretraining (e.g., verifiers or verifiable rewards). In this paper, we ask the question 'Is it possible to generalize these System 2 Thinking approaches, and develop models that learn to think solely from unsupervised learning?' Interestingly, we find the answer is yes, by learning to explicitly verify the compatibility between inputs and candidate-predictions, and then re-framing prediction problems as optimization with respect to this verifier. Specifically, we train Energy-Based Transformers (EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy value to every input and candidate-prediction pair, enabling predictions through gradient descent-based energy minimization until convergence. Across both discrete (text) and continuous (visual) modalities, we find EBTs scale faster than the dominant Transformer++ approach during training, achieving an up to 35% higher scaling rate with respect to data, batch size, parameters, FLOPs, and depth. During inference, EBTs improve performance with System 2 Thinking by 29% more than the Transformer++ on language tasks, and EBTs outperform Diffusion Transformers on image denoising while using fewer forward passes. Further, we find that EBTs achieve better results than existing models on most downstream tasks given the same or worse pretraining performance, suggesting that EBTs generalize better than existing approaches. Consequently, EBTs are a promising new paradigm for scaling both the learning and thinking capabilities of models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inference-time computation techniques, analogous to human System 2 Thinking,have recently become popular for improving model performances. However, mostexisting approaches suffer from several limitations: they are modality-specific(e.g., working only in text), problem-specific (e.g., verifiable domains likemath and coding), or require additional supervision/training on top ofunsupervised pretraining (e.g., verifiers or verifiable rewards). In thispaper, we ask the question "Is it possible to generalize these System 2Thinking approaches, and develop models that learn to think solely fromunsupervised learning?" Interestingly, we find the answer is yes, by learningto explicitly verify the compatibility between inputs andcandidate-predictions, and then re-framing prediction problems as optimizationwith respect to this verifier. Specifically, we train Energy-Based Transformers(EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energyvalue to every input and candidate-prediction pair, enabling predictionsthrough gradient descent-based energy minimization until convergence. Acrossboth discrete (text) and continuous (visual) modalities, we find EBTs scalefaster than the dominant Transformer++ approach during training, achieving anup to 35% higher scaling rate with respect to data, batch size, parameters,FLOPs, and depth. During inference, EBTs improve performance with System 2Thinking by 29% more than the Transformer++ on language tasks, and EBTsoutperform Diffusion Transformers on image denoising while using fewer forwardpasses. Further, we find that EBTs achieve better results than existing modelson most downstream tasks given the same or worse pretraining performance,suggesting that EBTs generalize better than existing approaches. Consequently,EBTs are a promising new paradigm for scaling both the learning and thinkingcapabilities of models.</description>
      <author>example@mail.com (Alexi Gladstone, Ganesh Nanduru, Md Mofijul Islam, Peixuan Han, Hyeonjeong Ha, Aman Chadha, Yilun Du, Heng Ji, Jundong Li, Tariq Iqbal)</author>
      <guid isPermaLink="false">2507.02092v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters</title>
      <link>http://arxiv.org/abs/2507.02085v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GeoAda是一种SE(3)-等变适配器框架，用于高效微调几何扩散模型，以适应不同的下游任务。&lt;h4&gt;背景&lt;/h4&gt;几何扩散模型在分子动力学和结构生成中取得了显著成功，但其对下游任务的微调效率仍有待提高。&lt;h4&gt;目的&lt;/h4&gt;提出GeoAda框架，以实现灵活且参数高效的微调，同时不修改原始模型架构。&lt;h4&gt;方法&lt;/h4&gt;GeoAda采用结构化适配器设计，通过耦合算子编码控制信号，然后通过预训练模型层的可训练副本处理，最后通过解耦算子和等变零初始化卷积投影回模型。&lt;h4&gt;主要发现&lt;/h4&gt;GeoAda通过微调轻量级适配器模块，保持了模型的几何一致性，同时减轻了过拟合和灾难性遗忘。&lt;h4&gt;结论&lt;/h4&gt;GeoAda在多种几何控制类型和广泛的应用领域表现出色，实现了最先进的微调性能，同时保持了原始任务的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：几何扩散模型在分子动力学和结构生成方面表现出色。然而，对于具有不同几何控制的下游任务进行高效微调仍是一个未被充分探索的领域。在这项工作中，我们提出了一种SE(3)-等变适配器框架（GeoAda），它能够实现对于受控生成任务的灵活和参数高效的微调，而不需要修改原始模型架构。GeoAda引入了一种结构化适配器设计：控制信号首先通过耦合算子进行编码，然后通过所选预训练模型层的可训练副本进行处理，最后通过解耦算子和等变零初始化卷积进行投影。通过仅微调这些轻量级适配器模块，GeoAda保持了模型的几何一致性，同时减轻了过拟合和灾难性遗忘。我们理论证明了所提出的适配器保持了SE(3)-等变性，确保了在适配过程中预训练扩散模型的几何归纳偏见保持完整。我们展示了GeoAda在多种几何控制类型中的应用，包括框架控制、全局控制、子图控制和广泛的领域，如粒子动力学、分子动力学、人类运动预测和分子生成。实证结果表明，GeoAda在保持原始任务准确性的同时，实现了最先进的微调性能，而其他基线由于过拟合和灾难性遗忘而经历了显著的性能下降。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geometric diffusion models have shown remarkable success in moleculardynamics and structure generation. However, efficiently fine-tuning them fordownstream tasks with varying geometric controls remains underexplored. In thiswork, we propose an SE(3)-equivariant adapter framework ( GeoAda) that enablesflexible and parameter-efficient fine-tuning for controlled generative taskswithout modifying the original model architecture. GeoAda introduces astructured adapter design: control signals are first encoded through couplingoperators, then processed by a trainable copy of selected pretrained modellayers, and finally projected back via decoupling operators followed by anequivariant zero-initialized convolution. By fine-tuning only these lightweightadapter modules, GeoAda preserves the model's geometric consistency whilemitigating overfitting and catastrophic forgetting. We theoretically prove thatthe proposed adapters maintain SE(3)-equivariance, ensuring that the geometricinductive biases of the pretrained diffusion model remain intact duringadaptation. We demonstrate the wide applicability of GeoAda across diversegeometric control types, including frame control, global control, subgraphcontrol, and a broad range of application domains such as particle dynamics,molecular dynamics, human motion prediction, and molecule generation. Empiricalresults show that GeoAda achieves state-of-the-art fine-tuning performancewhile preserving original task accuracy, whereas other baselines experiencesignificant performance degradation due to overfitting and catastrophicforgetting.</description>
      <author>example@mail.com (Wanjia Zhao, Jiaqi Han, Siyi Gu, Mingjian Jiang, James Zou, Stefano Ermon)</author>
      <guid isPermaLink="false">2507.02085v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Why Multi-Interest Fairness Matters: Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System</title>
      <link>http://arxiv.org/abs/2507.02000v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HyFairCRS的新型框架，旨在解决推荐系统中的不公平性问题，通过在动态和交互式的会话推荐系统中促进多兴趣多样性公平。&lt;h4&gt;背景&lt;/h4&gt;不公平性是推荐系统中的一个常见挑战，通常会导致基于性别、种族、年龄或流行度等属性的有偏结果，从而损害用户或物品。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，提出了HyFairCRS框架，目的是在动态和交互式的会话推荐系统中促进多兴趣多样性公平。&lt;h4&gt;方法&lt;/h4&gt;HyFairCRS通过对比学习建立多样化的超图来捕捉广泛的用户兴趣，并在对话中使用这些兴趣生成信息性响应，以确保在动态用户-系统反馈循环中的公平物品预测。&lt;h4&gt;主要发现&lt;/h4&gt;在两个基于CRS的数据集上的实验表明，HyFairCRS实现了新的最先进性能，同时有效地缓解了不公平性。&lt;h4&gt;结论&lt;/h4&gt;HyFairCRS框架能够有效解决推荐系统中的不公平性问题，并取得了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Unfairness is a well-known challenge in Recommender Systems (RSs), often resulting in biased outcomes that disadvantage users or items based on attributes such as gender, race, age, or popularity. Although some approaches have started to improve fairness recommendation in offline or static contexts, the issue of unfairness often exacerbates over time, leading to significant problems like the Matthew effect, filter bubbles, and echo chambers. To address these challenges, we proposed a novel framework, Hypergraph Contrastive Multi-Interest Learning for Fair Conversational Recommender System (HyFairCRS), aiming to promote multi-interest diversity fairness in dynamic and interactive Conversational Recommender Systems (CRSs). HyFairCRS first captures a wide range of user interests by establishing diverse hypergraphs through contrastive learning. These interests are then utilized in conversations to generate informative responses and ensure fair item predictions within the dynamic user-system feedback loop. Experiments on two CRS-based datasets show that HyFairCRS achieves a new state-of-the-art performance while effectively alleviating unfairness. Our code is available at https://github.com/zysensmile/HyFairCRS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unfairness is a well-known challenge in Recommender Systems (RSs), oftenresulting in biased outcomes that disadvantage users or items based onattributes such as gender, race, age, or popularity. Although some approacheshave started to improve fairness recommendation in offline or static contexts,the issue of unfairness often exacerbates over time, leading to significantproblems like the Matthew effect, filter bubbles, and echo chambers. To addressthese challenges, we proposed a novel framework, Hypergraph ContrastiveMulti-Interest Learning for Fair Conversational Recommender System (HyFairCRS),aiming to promote multi-interest diversity fairness in dynamic and interactiveConversational Recommender Systems (CRSs). HyFairCRS first captures a widerange of user interests by establishing diverse hypergraphs through contrastivelearning. These interests are then utilized in conversations to generateinformative responses and ensure fair item predictions within the dynamicuser-system feedback loop. Experiments on two CRS-based datasets show thatHyFairCRS achieves a new state-of-the-art performance while effectivelyalleviating unfairness. Our code is available athttps://github.com/zysensmile/HyFairCRS.</description>
      <author>example@mail.com (Yongsen Zheng, Zongxuan Xie, Guohua Wang, Ziyao Liu, Liang Lin, Kwok-Yan Lam)</author>
      <guid isPermaLink="false">2507.02000v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Generating Large Semi-Synthetic Graphs of Any Size</title>
      <link>http://arxiv.org/abs/2507.02166v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Latent Graph Sampling Generation（LGSG）的新框架，用于生成不同大小的图，该框架利用扩散模型和节点嵌入，无需重新训练即可生成图，并解决了当前模型依赖节点ID的问题。&lt;h4&gt;背景&lt;/h4&gt;图生成是网络科学中的一个重要领域，传统方法侧重于复制现实世界图的特定属性，如小直径或幂律度分布。近年来，深度学习，特别是图神经网络的发展，使得数据驱动的方法能够学习并生成图，而不依赖于预定义的结构属性。&lt;h4&gt;目的&lt;/h4&gt;为了解决当前模型依赖节点ID、限制生成大于输入图的图以及忽略节点属性的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了Latent Graph Sampling Generation（LGSG）框架，该框架利用扩散模型和节点嵌入来生成不同大小的图，无需重新训练，并消除了对节点ID的依赖。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，LGSG在标准指标上与基线模型表现相当，但在被忽视的指标上，如节点形成集群的趋势方面，表现更优。此外，它保持了不同大小图的持续结构特征，展示了其鲁棒性和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;LGSG是一种有效的图生成方法，能够在保持结构特征的同时，生成不同大小的图，具有鲁棒性和可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph generation is an important area in network science. Traditionalapproaches focus on replicating specific properties of real-world graphs, suchas small diameters or power-law degree distributions. Recent advancements indeep learning, particularly with Graph Neural Networks, have enableddata-driven methods to learn and generate graphs without relying on predefinedstructural properties. Despite these advances, current models are limited bytheir reliance on node IDs, which restricts their ability to generate graphslarger than the input graph and ignores node attributes. To address thesechallenges, we propose Latent Graph Sampling Generation (LGSG), a novelframework that leverages diffusion models and node embeddings to generategraphs of varying sizes without retraining. The framework eliminates thedependency on node IDs and captures the distribution of node embeddings andsubgraph structures, enabling scalable and flexible graph generation.Experimental results show that LGSG performs on par with baseline models forstandard metrics while outperforming them in overlooked ones, such as thetendency of nodes to form clusters. Additionally, it maintains consistentstructural characteristics across graphs of different sizes, demonstratingrobustness and scalability.</description>
      <author>example@mail.com (Rodrigo Tuna, Carlos Soares)</author>
      <guid isPermaLink="false">2507.02166v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Non-exchangeable Conformal Prediction for Temporal Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.02151v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了NCPNET，一个针对时间图的端到端一致预测框架，旨在提高图神经网络在动态环境下的可靠性。&lt;h4&gt;背景&lt;/h4&gt;现有的一致预测方法主要针对静态图，忽略了真实世界图的动态特性，导致其适用性受限。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够处理时间图的一致预测方法，以增强图神经网络在动态环境下的可靠性。&lt;h4&gt;方法&lt;/h4&gt;NCPNET通过扩散模型计算非一致性分数，以捕捉动态网络中的拓扑和时序不确定性，并采用效率感知的优化算法提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;在WIKI数据集上，NCPNET实现了31%的预测集大小减少，比现有方法效率显著提高。&lt;h4&gt;结论&lt;/h4&gt;NCPNET能够确保时间图中的保证覆盖，显著提高了图神经网络在动态环境下的可靠性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes NCPNET, an end-to-end conformal prediction framework tailored for temporal graphs, aiming to enhance the reliability of graph neural networks in dynamic environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737064&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conformal prediction for graph neural networks (GNNs) offers a promisingframework for quantifying uncertainty, enhancing GNN reliability in high-stakesapplications. However, existing methods predominantly focus on static graphs,neglecting the evolving nature of real-world graphs. Temporal dependencies ingraph structure, node attributes, and ground truth labels violate thefundamental exchangeability assumption of standard conformal predictionmethods, limiting their applicability. To address these challenges, in thispaper, we introduce NCPNET, a novel end-to-end conformal prediction frameworktailored for temporal graphs. Our approach extends conformal prediction todynamic settings, mitigating statistical coverage violations induced bytemporal dependencies. To achieve this, we propose a diffusion-basednon-conformity score that captures both topological and temporal uncertaintieswithin evolving networks. Additionally, we develop an efficiency-awareoptimization algorithm that improves the conformal prediction process,enhancing computational efficiency and reducing coverage violations. Extensiveexperiments on diverse real-world temporal graphs, including WIKI, REDDIT,DBLP, and IBM Anti-Money Laundering dataset, demonstrate NCPNET's capability toensure guaranteed coverage in temporal graphs, achieving up to a 31% reductionin prediction set size on the WIKI dataset, significantly improving efficiencycompared to state-of-the-art methods. Our data and code are available athttps://github.com/ODYSSEYWT/NCPNET.</description>
      <author>example@mail.com (Tuo Wang, Jian Kang, Yujun Yan, Adithya Kulkarni, Dawei Zhou)</author>
      <guid isPermaLink="false">2507.02151v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Power Flow Estimation with Topology-Aware Gated Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.02078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于门控图神经网络（GGNN）的AC电力流近似模型，用于在拓扑不确定性下的实时电网监测、应急分析和决策支持。&lt;h4&gt;背景&lt;/h4&gt;现有的AC电力流近似模型在捕捉长距离非线性依赖性和物理定律的执行方面存在不足，且在拓扑变化或负载波动大时泛化能力差。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够有效处理拓扑不确定性的AC电力流近似模型，以支持实时电网操作。&lt;h4&gt;方法&lt;/h4&gt;模型在多个IEEE基准网络上进行训练，包括随机线路故障和高达40%的负载变化。同时，采用了监督学习和基于物理信息自监督训练策略来提高模型的鲁棒性和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;比较评估显示，所提出的GGNN模型在预测精度和一致性方面优于现有的基于GNN的近似模型，并且能够确保物理一致性。&lt;h4&gt;结论&lt;/h4&gt;通过将操作约束直接嵌入到架构和损失函数中，该模型提供了一种轻量级、准确且可扩展的工具，适用于实时电网操作。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对交流电力流的准确且可扩展的代理模型，对于实时电网监控、应急分析和决策支持在日益动态和逆变器主导的电力系统中至关重要。然而，由于现有代理模型在捕捉网格化输电网络中的长距离非线性依赖性方面的能力有限，以及它们在物理定律执行方面的不足，大多数现有代理模型未能满足实际部署的要求。这些模型通常需要大量的超参数调整，在拓扑变化或负载波动较大时泛化能力较差，并且通常不量化不确定性或无法扩展到几百个节点之外。为了解决这些挑战，本文提出了一种在拓扑不确定性下进行交流电力流估计的门控图神经网络（GGNN）代理模型。该模型在多个大小和复杂程度不同的IEEE基准网络上进行训练，每个网络都包含随机线路故障和高达40%的负载变化。为了提高鲁棒性和泛化能力，我们探索了传统的监督学习和基于物理信息的自监督训练策略。比较评估表明，所提出的GGNN模型在预测精度和一致性方面一致优于现有的基于GNN的代理模型，并且与牛顿-拉夫森解的预测非常接近。通过将操作约束直接嵌入到架构和损失函数中，该模型确保了物理一致性，并提供了实时电网操作的一个轻量级、准确且可扩展的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate and scalable surrogate models for AC power flow are essential forreal-time grid monitoring, contingency analysis, and decision support inincreasingly dynamic and inverter-dominated power systems. However, mostexisting surrogates fall short of practical deployment due to their limitedcapacity to capture long-range nonlinear dependencies in meshed transmissionnetworks and their weak enforcement of physical laws. These models oftenrequire extensive hyperparameter tuning, exhibit poor generalization undertopology changes or large load swings, and typically do not quantifyuncertainty or scale well beyond a few hundred buses. To address thesechallenges, this paper proposes a \textit{gated graph neural network (GGNN)}surrogate for AC power-flow estimation under topological uncertainty. The modelis trained across multiple IEEE benchmark networks of varying size andcomplexity, each incorporating randomized line contingencies and up to 40\%load variation. To improve robustness and generalization, we explore bothconventional supervised learning and physics-informed self-supervised trainingstrategies. Comparative evaluations show that the proposed GGNN consistentlyoutperforms prior GNN-based surrogates, achieving predictions closely alignedwith Newton--Raphson solutions. By embedding operational constraints directlyinto the architecture and loss function, the model ensures physical consistencyand delivers a lightweight, accurate, and scalable tool for real-time gridoperations.</description>
      <author>example@mail.com (Shrenik Jadhav, Birva Sevak, Srijita Das, Wencong Su, Van-Hai Bui)</author>
      <guid isPermaLink="false">2507.02078v1</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control</title>
      <link>http://arxiv.org/abs/2507.01424v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TriVLA的统一视觉-语言-动作模型，用于通用机器人控制，通过三个系统架构来处理静态信息和动态信息，提高了机器人操作的性能。&lt;h4&gt;背景&lt;/h4&gt;视觉-语言模型在常识推理方面的进步推动了视觉-语言-动作模型的发展，这些模型使机器人能够执行通用操作。然而，现有的自回归VLA方法往往捕获静态信息，忽视了动态信息对于具身任务的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出TriVLA模型，以解决现有方法在捕捉动态信息方面的不足，从而提高机器人操作的性能。&lt;h4&gt;方法&lt;/h4&gt;TriVLA模型包含三个系统：视觉-语言模块（系统2）通过视觉和语言指令解释环境；动态感知模块（系统3）产生包含当前静态信息和预测未来动态的视觉表示；政策学习模块（系统1）实时生成流畅的电机动作。该模型利用预训练的视觉语言模型和视频基础模型，在机器人数据集和互联网人类操作数据上进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估显示，TriVLA以大约36 Hz的速度运行，在标准模拟基准测试和具有挑战性的真实世界操作任务上超越了最先进的模仿学习基线。&lt;h4&gt;结论&lt;/h4&gt;TriVLA模型能够有效处理动态信息，提高了机器人在复杂环境中的操作能力，是机器人控制领域的一项重要进展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：最近在视觉-语言模型（VLMs）在常识推理方面的进步推动了视觉-语言-动作（VLA）模型的发展，这些模型使机器人能够执行通用操作。尽管现有的自回归VLA方法设计了一种特定的架构，如双系统架构来利用大规模预训练知识，但它们往往捕获静态信息，经常忽视对具身任务至关重要的动态方面。为此，我们提出了TriVLA，一个具有三系统架构的统一视觉-语言-动作模型，用于通用机器人控制。视觉-语言模块（系统2）通过视觉和语言指令解释环境。动态感知模块（系统3）内在地产生包含当前静态信息和预测未来动态的视觉表示，从而为策略学习提供有价值的指导。TriVLA利用预训练的VLM模型，并在机器人数据集以及互联网人类操作数据上对预训练的视频基础模型进行微调。随后的策略学习模块（系统1）实时生成流畅的电机动作。实验评估表明，TriVLA以大约36 Hz的速度运行，在标准模拟基准测试以及具有挑战性的真实世界操作任务上超越了最先进的模仿学习基线。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in vision-language models (VLMs) for common-sensereasoning have led to the development of vision-language-action (VLA) models,enabling robots to perform generalized manipulation. Although existingautoregressive VLA methods design a specific architecture like dual-system toleverage large-scale pretrained knowledge, they tend to capture staticinformation, often neglecting the dynamic aspects vital for embodied tasks. Tothis end, we propose TriVLA, a unified Vision-Language-Action model with atriple-system architecture for general robot control. The vision-languagemodule (System 2) interprets the environment through vision and languageinstructions. The dynamics perception module (System 3) inherently producesvisual representations that encompass both current static information andpredicted future dynamics, thereby providing valuable guidance for policylearning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trainedvideo foundation model on robot datasets along with internet human manipulationdata. The subsequent policy learning module (System 1) generates fluid motoractions in real time. Experimental evaluation demonstrates that TriVLA operatesat approximately 36 Hz and surpasses state-of-the-art imitation learningbaselines on standard simulation benchmarks as well as challenging real-worldmanipulation tasks.</description>
      <author>example@mail.com (Zhenyang Liu, Yongchong Gu, Sixiao Zheng, Xiangyang Xue, Yanwei Fu)</author>
      <guid isPermaLink="false">2507.01424v2</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models</title>
      <link>http://arxiv.org/abs/2507.01201v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为JAM的联合自动编码器调制框架，旨在通过多目标优化任务，在保持每个模态原生结构的同时，实现不同模态模型之间的对齐。&lt;h4&gt;背景&lt;/h4&gt;视觉和语言模型在各自的模态、目标和架构下独立训练，形成了不同的表征空间。然而，存在一种假设，即这些模型可能趋向于一个共享的现实统计模型。&lt;h4&gt;目的&lt;/h4&gt;探讨如何超越事后统计检测对齐，并显式优化不同模态之间的对齐。&lt;h4&gt;方法&lt;/h4&gt;将柏拉图对齐问题视为一个多目标优化任务，提出JAM框架，通过联合训练模态特定的自动编码器，在预训练单模态模型的潜在表征上进行，同时通过重建和跨模态目标鼓励对齐。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，JAM框架在三个关键设计轴上表现出色：(i) 对齐目标，比较了对比损失、其硬负样本变体和提出的Spread损失；(ii) 对齐最有效的层深度；(iii) 基础模型规模对表征收敛的影响。&lt;h4&gt;结论&lt;/h4&gt;JAM框架能够可靠地诱导对齐，即使在冻结的独立训练表征之间，也为将通用单模态基础模型转化为专业多模态模型提供了理论和实践途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：独立训练的视觉和语言模型占据不同的表征空间，这些空间由各自的模态、目标和架构塑造。然而，一个新兴的假设——柏拉图表征假设——表明，这样的模型仍然可能趋向于一个共享的现实统计模型。如果存在这种兼容性，那么就提出了一个基本问题：我们能否超越事后统计检测的对齐，并在这种不同表征之间显式优化对齐？我们将柏拉图对齐问题设定为一个多目标优化任务——在保持每个模态的原生结构的同时，实现相互连贯的对齐。我们引入了联合自动编码器调制（JAM）框架，该框架联合训练特定于模态的自动编码器，在预训练单模态模型的潜在表征上，通过重建和跨模态目标鼓励对齐。通过类比，这个框架作为一种方法来逃离柏拉图的洞穴，使共享结构从不同的输入中产生。我们在三个关键设计轴上评估了这个框架：(i) 对齐目标——比较了对比损失（Con）、其硬负样本变体（NegCon）和我们的Spread损失；(ii) 对齐最有效的层深度；(iii) 基础模型规模对表征收敛的影响。我们的发现表明，我们的轻量级Pareto有效框架能够可靠地诱导对齐，即使在冻结的独立训练表征之间，这也为将通用单模态基础模型转化为专业多模态模型提供了理论和实践途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Independently trained vision and language models inhabit disjointrepresentational spaces, shaped by their respective modalities, objectives, andarchitectures. Yet an emerging hypothesis - the Platonic RepresentationHypothesis - suggests that such models may nonetheless converge toward a sharedstatistical model of reality. This compatibility, if it exists, raises afundamental question: can we move beyond post-hoc statistical detection ofalignment and explicitly optimize for it between such disjoint representations?We cast this Platonic alignment problem as a multi-objective optimization task- preserve each modality's native structure while aligning for mutualcoherence. We introduce the Joint Autoencoder Modulator (JAM) framework thatjointly trains modality-specific autoencoders on the latent representations ofpre-trained single modality models, encouraging alignment through bothreconstruction and cross-modal objectives. By analogy, this framework serves asa method to escape Plato's Cave, enabling the emergence of shared structurefrom disjoint inputs. We evaluate this framework across three critical designaxes: (i) the alignment objective - comparing contrastive loss (Con), itshard-negative variant (NegCon), and our Spread loss, (ii) the layer depth atwhich alignment is most effective, and (iii) the impact of foundation modelscale on representational convergence. Our findings show that our lightweightPareto-efficient framework reliably induces alignment, even across frozen,independently trained representations, offering both theoretical insight andpractical pathways for transforming generalist unimodal foundations intospecialist multimodal models.</description>
      <author>example@mail.com (Hyoseo, Yoon, Yisong Yue, Been Kim)</author>
      <guid isPermaLink="false">2507.01201v2</guid>
      <pubDate>Fri, 04 Jul 2025 14:21:33 +0800</pubDate>
    </item>
    <item>
      <title>Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications</title>
      <link>http://arxiv.org/abs/2507.00914v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了利用大型语言模型（LLMs）实现智能城市愿景的新途径，重点介绍了城市LLM代理的概念、工作流程、应用领域以及信任度和评估问题。&lt;h4&gt;背景&lt;/h4&gt;智能城市的愿景是通过大数据和人工智能技术创建高效、宜居和可持续的城市环境。LLMs的出现为这一愿景提供了新的实现方式。&lt;h4&gt;目的&lt;/h4&gt;研究城市LLM代理，探讨其独特能力、工作流程、应用领域，并讨论信任度和评估问题。&lt;h4&gt;方法&lt;/h4&gt;介绍城市LLM代理的概念，从代理工作流程的角度进行调研，包括城市感知、记忆管理、推理、执行和学习，并对应用领域进行分类。&lt;h4&gt;主要发现&lt;/h4&gt;城市LLM代理在多个领域有广泛应用，包括城市规划、交通、环境、公共安全和城市社会，并提出了信任度和评估问题以及未来研究方向。&lt;h4&gt;结论&lt;/h4&gt;城市LLM代理是智能城市发展的新兴领域，为LLMs与城市智能的交叉提供了路线图。&lt;h4&gt;翻译&lt;/h4&gt;The long-standing vision of intelligent cities is to create efficient, livable, and sustainable urban environments using big data and artificial intelligence technologies. Recently, the advent of Large Language Models (LLMs) has opened new ways toward realizing this vision. With powerful semantic understanding and reasoning capabilities, LLMs can be deployed as intelligent agents capable of autonomously solving complex problems across domains. In this article, we focus on Urban LLM Agents, which are LLM-powered agents that are semi-embodied within the hybrid cyber-physical-social space of cities and used for system-level urban decision-making. First, we introduce the concept of urban LLM agents, discussing their unique capabilities and features. Second, we survey the current research landscape from the perspective of agent workflows, encompassing urban sensing, memory management, reasoning, execution, and learning. Third, we categorize the application domains of urban LLM agents into five groups: urban planning, transportation, environment, public safety, and urban society, presenting representative works in each group. Finally, we discuss trustworthiness and evaluation issues that are critical for real-world deployment, and identify several open problems for future research. This survey aims to establish a foundation for the emerging field of urban LLM agents and to provide a roadmap for advancing the intersection of LLMs and urban intelligence. A curated list of relevant papers and open-source resources is maintained and continuously updated at https://github.com/usail-hkust/Awesome-Urban-LLM-Agents.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The long-standing vision of intelligent cities is to create efficient,livable, and sustainable urban environments using big data and artificialintelligence technologies. Recently, the advent of Large Language Models (LLMs)has opened new ways toward realizing this vision. With powerful semanticunderstanding and reasoning capabilities, LLMs can be deployed as intelligentagents capable of autonomously solving complex problems across domains. In thisarticle, we focus on Urban LLM Agents, which are LLM-powered agents that aresemi-embodied within the hybrid cyber-physical-social space of cities and usedfor system-level urban decision-making. First, we introduce the concept ofurban LLM agents, discussing their unique capabilities and features. Second, wesurvey the current research landscape from the perspective of agent workflows,encompassing urban sensing, memory management, reasoning, execution, andlearning. Third, we categorize the application domains of urban LLM agents intofive groups: urban planning, transportation, environment, public safety, andurban society, presenting representative works in each group. Finally, wediscuss trustworthiness and evaluation issues that are critical for real-worlddeployment, and identify several open problems for future research. This surveyaims to establish a foundation for the emerging field of urban LLM agents andto provide a roadmap for advancing the intersection of LLMs and urbanintelligence. A curated list of relevant papers and open-source resources ismaintained and continuously updated athttps://github.com/usail-hkust/Awesome-Urban-LLM-Agents.</description>
      <author>example@mail.com (Jindong Han, Yansong Ning, Zirui Yuan, Hang Ni, Fan Liu, Tengfei Lyu, Hao Liu)</author>
      <guid isPermaLink="false">2507.00914v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
  <item>
      <title>Joint Power Control and Precoding for Cell-Free Massive MIMO Systems With Sparse Multi-Dimensional Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2507.01876v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CF mMIMO技术因其消除小区间干扰而显著提高频谱效率，但在实际部署中面临计算复杂度高和优化复杂处理等挑战。&lt;h4&gt;背景&lt;/h4&gt;CF mMIMO技术作为未来网络的重要候选技术，能够显著提升频谱效率，但其部署面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出基于稀疏多维图神经网络（SP-MDGNN）的框架，以降低计算复杂度同时保持高性能。&lt;h4&gt;方法&lt;/h4&gt;采用SP-MDGNN对接入点（APs）和用户设备（UEs）之间的连接进行稀疏化，并引入加权最小均方误差（WMMSE）算法作为对比方法。&lt;h4&gt;主要发现&lt;/h4&gt;稀疏方法在性能和复杂度之间达到最佳平衡，显著降低了原始MDGNN方法的计算复杂度，同时仅略有性能下降。&lt;h4&gt;结论&lt;/h4&gt;SP-MDGNN框架为大规模网络中CF mMIMO系统的实际部署提供了启示。&lt;h4&gt;翻译&lt;/h4&gt;摘要：无细胞大量多输入多输出（CF mMIMO）技术因能显著提高频谱效率，通过消除小区间干扰而成为未来网络的重要候选技术。然而，其实际部署面临大量挑战，如计算复杂度高以及复杂处理的优化。为了解决这些挑战，本信函提出了一种基于稀疏多维图神经网络（SP-MDGNN）的框架，通过稀疏化接入点（APs）和用户设备（UEs）之间的连接，显著降低计算复杂度，同时保持高性能。此外，引入了加权最小均方误差（WMMSE）算法作为对比方法，以进一步分析性能与复杂度之间的权衡。仿真结果表明，稀疏方法在性能和复杂度之间达到了最佳平衡，显著降低了原始MDGNN方法的计算复杂度，同时仅略有性能下降，为大规模网络中CF mMIMO系统的实际部署提供了启示。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cell-free massive multiple-input multiple-output (CF mMIMO) has emerged as aprominent candidate for future networks due to its ability to significantlyenhance spectral efficiency by eliminating inter-cell interference. However,its practical deployment faces considerable challenges, such as highcomputational complexity and the optimization of its complex processing. Toaddress these challenges, this correspondence proposes a framework based on asparse multi-dimensional graph neural network (SP-MDGNN), which sparsifies theconnections between access points (APs) and user equipments (UEs) tosignificantly reduce computational complexity while maintaining highperformance. In addition, the weighted minimum mean square error (WMMSE)algorithm is introduced as a comparative method to further analyze thetrade-off between performance and complexity. Simulation results demonstratethat the sparse method achieves an optimal balance between performance andcomplexity, significantly reducing the computational complexity of the originalMDGNN method while incurring only a slight performance degradation, providinginsights for the practical deployment of CF mMIMO systems in large-scalenetwork.</description>
      <author>example@mail.com (Yukun Ma, Jiayi Zhang, Ziheng Liu, Guowei Shi, Bo Ai)</author>
      <guid isPermaLink="false">2507.01876v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Future Slot Prediction for Unsupervised Object Discovery in Surgical Video</title>
      <link>http://arxiv.org/abs/2507.01882v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对象中心的槽位注意力机制，用于无监督学习结构化、可解释的对象中心表示（槽位），并应用于医疗健康领域，如手术视频的实时解释。&lt;h4&gt;背景&lt;/h4&gt;现实世界应用中的场景，如手术场景，难以解析成有意义的槽位集合。&lt;h4&gt;目的&lt;/h4&gt;提出一种动态时间槽位转换器（DTST）模块，以解决在手术视频中槽位计数自适应方法性能低的问题。&lt;h4&gt;方法&lt;/h4&gt;该模块同时训练进行时间推理和预测最佳未来槽位初始化。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在多个手术数据库上实现了最先进的性能，证明了无监督对象中心方法可以应用于现实世界数据，并成为医疗健康应用中的常用工具。&lt;h4&gt;结论&lt;/h4&gt;无监督对象中心方法可以应用于医疗健康领域，并具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-centric slot attention is an emerging paradigm for unsupervisedlearning of structured, interpretable object-centric representations (slots).This enables effective reasoning about objects and events at a lowcomputational cost and is thus applicable to critical healthcare applications,such as real-time interpretation of surgical video. The heterogeneous scenes inreal-world applications like surgery are, however, difficult to parse into ameaningful set of slots. Current approaches with an adaptive slot count performwell on images, but their performance on surgical videos is low. To addressthis challenge, we propose a dynamic temporal slot transformer (DTST) modulethat is trained both for temporal reasoning and for predicting the optimalfuture slot initialization. The model achieves state-of-the-art performance onmultiple surgical databases, demonstrating that unsupervised object-centricmethods can be applied to real-world data and become part of the common arsenalin healthcare applications.</description>
      <author>example@mail.com (Guiqiu Liao, Matjaz Jogan, Marcel Hussing, Edward Zhang, Eric Eaton, Daniel A. Hashimoto)</author>
      <guid isPermaLink="false">2507.01882v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2507.01801v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种自适应动量和解耦对比学习框架（AMD），用于预测交通代理的未来轨迹，特别适用于处理自然数据集中长尾数据中的复杂和危险场景。&lt;h4&gt;背景&lt;/h4&gt;准确预测交通代理的未来轨迹对于自动驾驶至关重要，但自然数据集中的轨迹分布存在固有不平衡，长尾数据通常代表更复杂和危险的情况。&lt;h4&gt;目的&lt;/h4&gt;提出AMD框架，以提高模型在识别罕见和复杂轨迹方面的能力。&lt;h4&gt;方法&lt;/h4&gt;AMD框架结合了无监督和监督的对比学习策略，利用改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，并设计了四种轨迹随机增强方法以及在线迭代聚类策略。&lt;h4&gt;主要发现&lt;/h4&gt;AMD在长尾轨迹预测中实现了最佳性能，并显示出卓越的整体预测准确性。&lt;h4&gt;结论&lt;/h4&gt;AMD框架不仅提高了长尾轨迹预测的性能，还展示了在处理复杂交通场景时的有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：准确预测交通代理的未来轨迹对于自动驾驶至关重要。然而，由于自然数据集中轨迹分布的不平衡，长尾数据通常代表更复杂和危险的场景。现有研究通常仅依赖于基模型的预测误差，而没有考虑长尾轨迹模式的多样性和不确定性。我们提出了一种自适应动量和解耦对比学习框架（AMD），该框架集成了无监督和监督的对比学习策略。通过利用改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL）模块，我们的框架增强了模型识别罕见和复杂轨迹的能力。此外，我们设计了四种类型的轨迹随机增强方法，并引入了一种在线迭代聚类策略，允许模型动态更新伪标签，更好地适应长尾数据中的分布变化。我们提出了三种不同的标准来定义长尾轨迹，并在nuScenes和ETH/UCY数据集上进行了广泛的比较实验。结果表明，AMD不仅在长尾轨迹预测中实现了最佳性能，还展示了卓越的整体预测准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurately predicting the future trajectories of traffic agents is essentialin autonomous driving. However, due to the inherent imbalance in trajectorydistributions, tail data in natural datasets often represents more complex andhazardous scenarios. Existing studies typically rely solely on a base model'sprediction error, without considering the diversity and uncertainty oflong-tail trajectory patterns. We propose an adaptive momentum and decoupledcontrastive learning framework (AMD), which integrates unsupervised andsupervised contrastive learning strategies. By leveraging an improved momentumcontrast learning (MoCo-DT) and decoupled contrastive learning (DCL) module,our framework enhances the model's ability to recognize rare and complextrajectories. Additionally, we design four types of trajectory randomaugmentation methods and introduce an online iterative clustering strategy,allowing the model to dynamically update pseudo-labels and better adapt to thedistributional shifts in long-tail data. We propose three different criteria todefine long-tail trajectories and conduct extensive comparative experiments onthe nuScenes and ETH$/$UCY datasets. The results show that AMD not onlyachieves optimal performance in long-tail trajectory prediction but alsodemonstrates outstanding overall prediction accuracy.</description>
      <author>example@mail.com (Bin Rao, Haicheng Liao, Yanchen Guan, Chengyue Wang, Bonan Wang, Jiaxun Zhang, Zhenning Li)</author>
      <guid isPermaLink="false">2507.01801v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Rethink 3D Object Detection from Physical World</title>
      <link>http://arxiv.org/abs/2507.00190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的3D物体检测评估方法，考虑了速度和准确率之间的权衡，并引入了L-AP和P-AP作为新的评估指标，用于实时3D物体检测。&lt;h4&gt;背景&lt;/h4&gt;高精度和低延迟的3D物体检测对于自动驾驶系统至关重要。现有研究通常以平均精度（mAP）和延迟来评估性能，但往往未能解决速度和准确率之间的权衡问题。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的评估方法，以更全面地评估实时3D物体检测的性能，并解决现有方法中未考虑的硬件设备和加速器之间的权衡问题。&lt;h4&gt;方法&lt;/h4&gt;引入了L-AP和P-AP作为新的评估指标，通过考虑物理世界中的时间和物理约束，对3D物体检测模型进行评估。同时，通过延迟感知的超参数优化（L-HPO）开发了实时3D物体检测的性能模型。&lt;h4&gt;主要发现&lt;/h4&gt;本文通过nuPlan数据集证明了新指标的有效性，并量化了“点云越多，识别性能越好”的假设在实时应用中的不正确性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够更全面地评估实时3D物体检测的性能，并通过优化硬件和模型选择，提高了自动驾驶系统的安全性。&lt;h4&gt;翻译&lt;/h4&gt;High-accuracy and low-latency 3D object detection is essential for autonomousdriving systems. While previous studies on 3D object detection often evaluateperformance based on mean average precision (mAP) and latency, theytypically fail to address the trade-off between speed and accuracy, such as60.0 mAP at 100 ms vs 61.0 mAP at 500 ms. A quantitative assessment of thetrade-offs between different hardware devices and accelerators remainsunexplored, despite being critical for real-time applications. Furthermore,they overlook the impact on collision avoidance in motion planning, forexample, 60.0 mAP leading to safer motion planning or 61.0 mAP leading tohigh-risk motion planning. In this paper, we introduce latency-aware AP(L-AP) and planning-aware AP (P-AP) as new metrics, which consider thephysical world such as the concept of time and physical constraints, offeringa more comprehensive evaluation for real-time 3D object detection. We demonstrate the effectiveness of our metrics for the entire autonomousdriving system using nuPlan dataset, and evaluate 3D object detection modelsaccounting for hardware differences and accelerators. We also develop a state-of-the-art performance model for real-time 3D object detection throughlatency-aware hyperparameter optimization (L-HPO) using our metrics. Additionally,we quantitatively demonstrate that the assumption 'the more point clouds, thebetter the recognition performance' is incorrect for real-time applications andoptimize both hardware and model selection using our metrics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High-accuracy and low-latency 3D object detection is essential for autonomousdriving systems. While previous studies on 3D object detection often evaluateperformance based on mean average precision (mAP) and latency, they typicallyfail to address the trade-off between speed and accuracy, such as 60.0 mAP at100 ms vs 61.0 mAP at 500 ms. A quantitative assessment of the trade-offsbetween different hardware devices and accelerators remains unexplored, despitebeing critical for real-time applications. Furthermore, they overlook theimpact on collision avoidance in motion planning, for example, 60.0 mAP leadingto safer motion planning or 61.0 mAP leading to high-risk motion planning. Inthis paper, we introduce latency-aware AP (L-AP) and planning-aware AP (P-AP)as new metrics, which consider the physical world such as the concept of timeand physical constraints, offering a more comprehensive evaluation forreal-time 3D object detection. We demonstrate the effectiveness of our metricsfor the entire autonomous driving system using nuPlan dataset, and evaluate 3Dobject detection models accounting for hardware differences and accelerators.We also develop a state-of-the-art performance model for real-time 3D objectdetection through latency-aware hyperparameter optimization (L-HPO) using ourmetrics. Additionally, we quantitatively demonstrate that the assumption "themore point clouds, the better the recognition performance" is incorrect forreal-time applications and optimize both hardware and model selection using ourmetrics.</description>
      <author>example@mail.com (Satoshi Tanaka, Koji Minoda, Fumiya Watanabe, Takamasa Horibe)</author>
      <guid isPermaLink="false">2507.00190v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks</title>
      <link>http://arxiv.org/abs/2507.01955v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page at https://fm-vision-evals.epfl.ch/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对多模态基础模型在计算机视觉任务中的表现进行了基准测试。&lt;h4&gt;背景&lt;/h4&gt;多模态基础模型如GPT-4o在近期取得了显著进展，但其对视觉的理解能力尚不明确。&lt;h4&gt;目的&lt;/h4&gt;评估流行的多模态基础模型在标准计算机视觉任务上的性能。&lt;h4&gt;方法&lt;/h4&gt;使用COCO、ImageNet等数据集，将标准视觉任务转换为可文本提示和API兼容的任务，创建标准基准测试框架。&lt;h4&gt;主要发现&lt;/h4&gt;1) 模型在所有任务上均未达到最先进的水平；2) 模型是值得尊重的通用主义者；3) 在语义任务上的表现优于几何任务；4) 提示链技术影响了性能，但表现更好的模型对提示变化的敏感性较低；5) GPT-4o在非推理模型中表现最佳；6) 推理模型在几何任务上有所改进；7) 对具有原生图像生成能力的模型（如最新GPT-4o）的初步分析显示，它们表现出幻觉和空间错位等特性。&lt;h4&gt;结论&lt;/h4&gt;多模态基础模型在视觉理解方面有潜力，但仍有改进空间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal foundation models, such as GPT-4o, have recently made remarkableprogress, but it is not clear where exactly these models stand in terms ofunderstanding vision. In this paper, we benchmark the performance of popularmultimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0Flash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer visiontasks (semantic segmentation, object detection, image classification, depth andsurface normal prediction) using established datasets (e.g., COCO, ImageNet andits variants, etc).  The main challenges to performing this are: 1) most models are trained tooutput text and cannot natively express versatile domains, such as segments or3D geometry, and 2) many leading models are proprietary and accessible only atan API level, i.e., there is no weight access to adapt them. We address thesechallenges by translating standard vision tasks into equivalent text-promptableand API-compatible tasks via prompt chaining to create a standardizedbenchmarking framework.  We observe that 1) the models are not close to the state-of-the-artspecialist models at any task. However, 2) they are respectable generalists;this is remarkable as they are presumably trained on primarily image-text-basedtasks. 3) They perform semantic tasks notably better than geometric ones. 4)While the prompt-chaining techniques affect performance, better models exhibitless sensitivity to prompt variations. 5) GPT-4o performs the best amongnon-reasoning models, securing the top position in 4 out of 6 tasks, 6)reasoning models, e.g. o3, show improvements in geometric tasks, and 7) apreliminary analysis of models with native image generation, like the latestGPT-4o, shows they exhibit quirks like hallucinations and spatialmisalignments.</description>
      <author>example@mail.com (Rahul Ramachandran, Ali Garjani, Roman Bachmann, Andrei Atanov, Oğuzhan Fatih Kar, Amir Zamir)</author>
      <guid isPermaLink="false">2507.01955v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation</title>
      <link>http://arxiv.org/abs/2507.01961v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AC-DiT（自适应协调扩散变换器），用于增强移动基础和操作器的协调，以实现端到端的移动操作。&lt;h4&gt;背景&lt;/h4&gt;移动操作在家庭任务中越来越受到关注，但现有方法在协调移动底座和机械臂方面仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在协调移动底座和操作器方面的不足，实现更有效的移动操作。&lt;h4&gt;方法&lt;/h4&gt;AC-DiT通过以下方法增强协调：1. 引入移动到身体的条件机制，以预测全身动作；2. 设计感知感知的多模态条件策略，动态调整不同2D视觉图像和3D点云之间的融合权重。&lt;h4&gt;主要发现&lt;/h4&gt;AC-DiT能够有效地处理移动基础对操作器控制的影响，并满足不同阶段移动操作的多模态感知需求。&lt;h4&gt;结论&lt;/h4&gt;AC-DiT在模拟和现实世界的移动操作任务中得到了验证，证明了其在提高移动操作性能方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;最近，移动操作因其能够在家庭任务中实现语言条件化机器人控制而越来越受到关注。然而，现有的方法在协调移动底座和机械臂方面仍然面临挑战，这主要是因为两个限制。一方面，它们未能明确地建模移动底座对机械臂控制的影响，这容易在高自由度下导致错误累积。另一方面，它们将整个移动操作过程视为相同的视觉观察模式（例如，要么全部为2D，要么全部为3D），忽视了在移动操作的不同阶段存在不同的多模态感知需求。为了解决这个问题，我们提出了自适应协调扩散变换器（AC-DiT），它增强了移动基础和操作器之间的协调，以实现端到端的移动操作。首先，由于移动底座的运动直接影响操作器的动作，我们引入了一种移动到身体的条件机制，该机制指导模型首先提取底座运动表示，然后将其用作预测全身动作的上下文先验。这使得全身控制能够考虑到移动底座运动的影响。其次，为了满足移动操作不同阶段的感知需求，我们设计了一种感知感知的多模态条件策略，动态调整各种2D视觉图像和3D点云之间的融合权重，从而产生适合当前感知需求的外观特征。这使得模型能够，例如，当语义信息对动作预测至关重要时，更多地依赖于2D输入，而当需要精确的空间理解时，则更多地依赖于3D几何信息。我们通过在模拟和现实世界的移动操作任务上进行的广泛实验验证了AC-DiT。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, mobile manipulation has attracted increasing attention for enablinglanguage-conditioned robotic control in household tasks. However, existingmethods still face challenges in coordinating mobile base and manipulator,primarily due to two limitations. On the one hand, they fail to explicitlymodel the influence of the mobile base on manipulator control, which easilyleads to error accumulation under high degrees of freedom. On the other hand,they treat the entire mobile manipulation process with the same visualobservation modality (e.g., either all 2D or all 3D), overlooking the distinctmultimodal perception requirements at different stages during mobilemanipulation. To address this, we propose the Adaptive Coordination DiffusionTransformer (AC-DiT), which enhances mobile base and manipulator coordinationfor end-to-end mobile manipulation. First, since the motion of the mobile basedirectly influences the manipulator's actions, we introduce a mobility-to-bodyconditioning mechanism that guides the model to first extract base motionrepresentations, which are then used as context prior for predicting whole-bodyactions. This enables whole-body control that accounts for the potential impactof the mobile base's motion. Second, to meet the perception requirements atdifferent stages of mobile manipulation, we design a perception-awaremultimodal conditioning strategy that dynamically adjusts the fusion weightsbetween various 2D visual images and 3D point clouds, yielding visual featurestailored to the current perceptual needs. This allows the model to, forexample, adaptively rely more on 2D inputs when semantic information is crucialfor action prediction, while placing greater emphasis on 3D geometricinformation when precise spatial understanding is required. We validate AC-DiTthrough extensive experiments on both simulated and real-world mobilemanipulation tasks.</description>
      <author>example@mail.com (Sixiang Chen, Jiaming Liu, Siyuan Qian, Han Jiang, Lily Li, Renrui Zhang, Zhuoyang Liu, Chenyang Gu, Chengkai Hou, Pengwei Wang, Zhongyuan Wang, Shanghang Zhang)</author>
      <guid isPermaLink="false">2507.01961v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Kwai Keye-VL Technical Report</title>
      <link>http://arxiv.org/abs/2507.01949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report: https://github.com/Kwai-Keye/Keye&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Kwai Keye-VL是一个8亿参数的多模态基础模型，旨在提高短视频理解能力，同时保持强大的通用视觉语言能力。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在静态图像上表现出色，但在理解动态、信息密集的短视频方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;填补短视频理解能力的差距。&lt;h4&gt;方法&lt;/h4&gt;Keye-VL基于超过6000亿token的高质量数据集和创新的训练方法。训练方法包括四个阶段的预训练过程和两个阶段的后训练过程。后训练阶段包括增强基础能力（如指令遵循）和高级推理，其中使用了五种模式的数据混合，以及后续的强化学习和对齐步骤。&lt;h4&gt;主要发现&lt;/h4&gt;Keye-VL在公共视频基准测试中取得了最先进的成果，并在基于图像的一般任务中保持高度竞争力。此外，Keye-VL在针对现实世界短视频场景的新基准测试KC-MMBench中显示出显著优势。&lt;h4&gt;结论&lt;/h4&gt;Kwai Keye-VL是一个有效的短视频理解模型，具有广泛的适用性和高性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While Multimodal Large Language Models (MLLMs) demonstrate remarkablecapabilities on static images, they often fall short in comprehending dynamic,information-dense short-form videos, a dominant medium in today's digitallandscape. To bridge this gap, we introduce \textbf{Kwai Keye-VL}, an8-billion-parameter multimodal foundation model engineered for leading-edgeperformance in short-video understanding while maintaining robustgeneral-purpose vision-language abilities. The development of Keye-VL rests ontwo core pillars: a massive, high-quality dataset exceeding 600 billion tokenswith a strong emphasis on video, and an innovative training recipe. This recipefeatures a four-stage pre-training process for solid vision-language alignment,followed by a meticulous two-phase post-training process. The firstpost-training stage enhances foundational capabilities like instructionfollowing, while the second phase focuses on stimulating advanced reasoning. Inthis second phase, a key innovation is our five-mode ``cold-start'' datamixture, which includes ``thinking'', ``non-thinking'', ``auto-think'', ``thinkwith image'', and high-quality video data. This mixture teaches the model todecide when and how to reason. Subsequent reinforcement learning (RL) andalignment steps further enhance these reasoning capabilities and correctabnormal model behaviors, such as repetitive outputs. To validate our approach,we conduct extensive evaluations, showing that Keye-VL achievesstate-of-the-art results on public video benchmarks and remains highlycompetitive on general image-based tasks (Figure 1). Furthermore, we developand release the \textbf{KC-MMBench}, a new benchmark tailored for real-worldshort-video scenarios, where Keye-VL shows a significant advantage.</description>
      <author>example@mail.com (Kwai Keye Team, Biao Yang, Bin Wen, Changyi Liu, Chenglong Chu, Chengru Song, Chongling Rao, Chuan Yi, Da Li, Dunju Zang, Fan Yang, Guorui Zhou, Hao Peng, Haojie Ding, Jiaming Huang, Jiangxia Cao, Jiankang Chen, Jingyun Hua, Jin Ouyang, Kaibing Chen, Kaiyu Jiang, Kaiyu Tang, Kun Gai, Shengnan Zhang, Siyang Mao, Sui Huang, Tianke Zhang, Tingting Gao, Wei Chen, Wei Yuan, Xiangyu Wu, Xiao Hu, Xingyu Lu, Yang Zhou, Yi-Fan Zhang, Yiping Yang, Yulong Chen, Zhenhua Wu, Zhenyu Li, Zhixin Ling, Ziming Li, Dehua Ma, Di Xu, Haixuan Gao, Hang Li, Jiawei Guo, Jing Wang, Lejian Ren, Muhao Wei, Qianqian Wang, Qigen Hu, Shiyao Wang, Tao Yu, Xinchen Luo, Yan Li, Yiming Liang, Yuhang Hu, Zeyi Lu, Zhuoran Yang, Zixing Zhang)</author>
      <guid isPermaLink="false">2507.01949v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>TurboReg: TurboClique for Robust and Efficient Point Cloud Registration</title>
      <link>http://arxiv.org/abs/2507.01439v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV-2025 Accepted Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种快速且鲁棒的点云配准算法TurboReg，通过使用轻量级的TurboClique和Pivot-Guided Search (PGS)算法来提高配准效率。&lt;h4&gt;背景&lt;/h4&gt;现有的基于最大团搜索的不兼容图方法在点云配准中具有较高的召回率，但时间复杂度呈指数增长，限制了其在时间敏感应用中的使用。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了TurboReg算法，以提高配准速度和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;TurboReg算法包括定义TurboClique作为高度约束兼容图中的3-团，以及使用PGS算法来选择匹配对作为基准点，从而有效地引导搜索过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，TurboReg在多个真实数据集上实现了最先进的性能，同时速度提升显著。例如，在3DMatch+FCGF数据集上，TurboReg比3DMAC快208.22倍，同时实现了更高的召回率。&lt;h4&gt;结论&lt;/h4&gt;TurboReg是一种有效且高效的点云配准算法，适用于时间敏感的应用。&lt;h4&gt;翻译&lt;/h4&gt;Robust estimation is essential in correspondence-based Point Cloud Registration (PCR). Existing methods using maximal clique search incompatibility graphs achieve high recall but suffer from exponential time complexity, limiting their use in time-sensitive applications. To address this challenge, we propose a fast and robust estimator, TurboReg, built upon a novel lightweight clique, TurboClique, and a highly parallelizable Pivot-Guided Search (PGS) algorithm. First, we define the TurboClique as a 3-clique within a highly-constrained compatibility graph. The lightweight nature of the 3-clique allows for efficient parallel searching, and the highly-constrained compatibility graph ensures robust spatial consistency for stable transformation estimation. Next, PGS selects matching pairs with high SC^2 scores as pivots, effectively guiding the search toward TurboCliques with higher inlier ratios. Moreover, the PGS algorithm has linear time complexity and is significantly more efficient than the maximal clique search with exponential time complexity. Extensive experiments show that TurboReg achieves state-of-the-art performance across multiple real-world datasets, with substantial speed improvements. For example, on the 3DMatch+FCGF dataset, TurboReg (1K) operates 208.22 times faster than 3DMAC while also achieving higher recall. Our code is accessible at https://github.com/Laka-3DV/TurboReg/TurboReg.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robust estimation is essential in correspondence-based Point CloudRegistration (PCR). Existing methods using maximal clique search incompatibility graphs achieve high recall but suffer from exponential timecomplexity, limiting their use in time-sensitive applications. To address thischallenge, we propose a fast and robust estimator, TurboReg, built upon a novellightweight clique, TurboClique, and a highly parallelizable Pivot-GuidedSearch (PGS) algorithm. First, we define the TurboClique as a 3-clique within ahighly-constrained compatibility graph. The lightweight nature of the 3-cliqueallows for efficient parallel searching, and the highly-constrainedcompatibility graph ensures robust spatial consistency for stabletransformation estimation. Next, PGS selects matching pairs with high SC$^2$scores as pivots, effectively guiding the search toward TurboCliques withhigher inlier ratios. Moreover, the PGS algorithm has linear time complexityand is significantly more efficient than the maximal clique search withexponential time complexity. Extensive experiments show that TurboReg achievesstate-of-the-art performance across multiple real-world datasets, withsubstantial speed improvements. For example, on the 3DMatch+FCGF dataset,TurboReg (1K) operates $208.22\times$ faster than 3DMAC while also achievinghigher recall. Our code is accessible at\href{https://github.com/Laka-3DV/TurboReg}{\texttt{TurboReg}}.</description>
      <author>example@mail.com (Shaocheng Yan, Pengcheng Shi, Zhenjun Zhao, Kaixin Wang, Kuang Cao, Ji Wu, Jiayuan Li)</author>
      <guid isPermaLink="false">2507.01439v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>LANet: A Lane Boundaries-Aware Approach For Robust Trajectory Prediction</title>
      <link>http://arxiv.org/abs/2507.01308v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the 17th IEEE International Conference on Advanced  Computational Intelligence (ICACI 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多矢量地图元素的运动预测模型，旨在提高自动驾驶中的轨迹预测准确性。&lt;h4&gt;背景&lt;/h4&gt;当前的运动预测模型大多基于车道中心线的主要表示，这限制了它们捕捉关键道路环境和交通规则的能力。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够更全面地表示驾驶环境的运动预测模型，以支持自动驾驶车辆在复杂交通场景中做出明智决策。&lt;h4&gt;方法&lt;/h4&gt;提出了一种有效的特征融合策略，用于合并不同矢量地图组件的信息，并开发了一种有效的剪枝机制，以过滤与目标代理最相关的地图连接，从而在保持必要空间和语义关系的同时提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;该方法克服了基于车道中心线模型的局限性，提供了更丰富、更有效的驾驶环境表示，并在Argoverse 2运动预测数据集上实现了竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;该研究推动了自动驾驶车辆运动预测的前沿，通过实验验证了所提出方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Accurate motion forecasting is critical for safe and efficient autonomous driving, enabling vehicles to predict future trajectories and make informed decisions in complex traffic scenarios. Most of the current designs of motion prediction models are based on the major representation of lane centerlines, which limits their capability to capture critical road environments and traffic rules and constraints. In this work, we propose an enhanced motion forecasting model informed by multiple vector map elements, including lane boundaries and road edges, that facilitates a richer and more complete representation of driving environments. An effective feature fusion strategy is developed to merge information in different vector map components, where the model learns holistic information on road structures and their interactions with agents. Since encoding more information about the road environment increases memory usage and is computationally expensive, we developed an effective pruning mechanism that filters the most relevant map connections to the target agent, ensuring computational efficiency while maintaining essential spatial and semantic relationships for accurate trajectory prediction. Overcoming the limitations of lane centerline-based models, our method provides a more informative and efficient representation of the driving environment and advances the state of the art for autonomous vehicle motion forecasting. We verify our approach with extensive experiments on the Argoverse 2 motion forecasting dataset, where our method maintains competitiveness on AV2 while achieving improved performance. Index Terms-Autonomous driving, trajectory prediction, vector map elements, road topology, connection pruning, Argoverse 2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate motion forecasting is critical for safe and efficient autonomousdriving, enabling vehicles to predict future trajectories and make informeddecisions in complex traffic scenarios. Most of the current designs of motionprediction models are based on the major representation of lane centerlines,which limits their capability to capture critical road environments and trafficrules and constraints. In this work, we propose an enhanced motion forecastingmodel informed by multiple vector map elements, including lane boundaries androad edges, that facilitates a richer and more complete representation ofdriving environments. An effective feature fusion strategy is developed tomerge information in different vector map components, where the model learnsholistic information on road structures and their interactions with agents.Since encoding more information about the road environment increases memoryusage and is computationally expensive, we developed an effective pruningmechanism that filters the most relevant map connections to the target agent,ensuring computational efficiency while maintaining essential spatial andsemantic relationships for accurate trajectory prediction. Overcoming thelimitations of lane centerline-based models, our method provides a moreinformative and efficient representation of the driving environment andadvances the state of the art for autonomous vehicle motion forecasting. Weverify our approach with extensive experiments on the Argoverse 2 motionforecasting dataset, where our method maintains competitiveness on AV2 whileachieving improved performance.  Index Terms-Autonomous driving, trajectory prediction, vector map elements,road topology, connection pruning, Argoverse 2.</description>
      <author>example@mail.com (Muhammad Atta ur Rahman, Dooseop Choi, KyoungWook Min)</author>
      <guid isPermaLink="false">2507.01308v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>When Does Pruning Benefit Vision Representations?</title>
      <link>http://arxiv.org/abs/2507.01722v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了剪枝对视觉模型的影响，从可解释性、无监督对象发现和与人类感知的对齐三个关键维度进行探讨。&lt;h4&gt;背景&lt;/h4&gt;剪枝被广泛用于降低深度学习模型的复杂性，但其对可解释性和表示学习的影响尚不明确。&lt;h4&gt;目的&lt;/h4&gt;研究剪枝如何影响视觉模型，并分析其在可解释性、无监督对象发现和与人类感知对齐方面的作用。&lt;h4&gt;方法&lt;/h4&gt;分析不同的视觉网络架构，研究不同稀疏度水平对特征归因可解释性的影响；探索剪枝是否促进更简洁和结构化的表示，通过丢弃冗余信息来提高无监督对象发现；评估剪枝是否增强了模型表示与人类感知之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;发现存在“甜点”区域，在这些区域中，稀疏模型展现出更高的可解释性、下游泛化能力和与人类感知的对齐。然而，这些区域高度依赖于网络架构及其可训练参数的数量。&lt;h4&gt;结论&lt;/h4&gt;剪枝与这三个维度之间存在复杂的相互作用，强调了研究剪枝何时以及如何对视觉表示有益的重要性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了剪枝对深度学习模型复杂性的降低及其对可解释性和表示学习的影响，并从可解释性、无监督对象发现和与人类感知对齐三个方面探讨了剪枝对视觉模型的影响。研究发现，剪枝可以促进模型的可解释性、泛化能力和与人类感知的对齐，但具体效果取决于网络架构和可训练参数的数量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pruning is widely used to reduce the complexity of deep learning models, butits effects on interpretability and representation learning remain poorlyunderstood. This paper investigates how pruning influences vision models acrossthree key dimensions: (i) interpretability, (ii) unsupervised object discovery,and (iii) alignment with human perception. We first analyze different visionnetwork architectures to examine how varying sparsity levels affect featureattribution interpretability methods. Additionally, we explore whether pruningpromotes more succinct and structured representations, potentially improvingunsupervised object discovery by discarding redundant information whilepreserving essential features. Finally, we assess whether pruning enhances thealignment between model representations and human perception, investigatingwhether sparser models focus on more discriminative features similarly tohumans. Our findings also reveal the presence of sweet spots, where sparsemodels exhibit higher interpretability, downstream generalization and humanalignment. However, these spots highly depend on the network architectures andtheir size in terms of trainable parameters. Our results suggest a complexinterplay between these three dimensions, highlighting the importance ofinvestigating when and how pruning benefits vision representations.</description>
      <author>example@mail.com (Enrico Cassano, Riccardo Renzulli, Andrea Bragagnolo, Marco Grangetto)</author>
      <guid isPermaLink="false">2507.01722v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>3D Reconstruction and Information Fusion between Dormant and Canopy Seasons in Commercial Orchards Using Deep Learning and Fast GICP</title>
      <link>http://arxiv.org/abs/2507.01912v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 4 tables, 11 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种信息融合框架，通过整合多季节结构数据来支持整个生长季节的机器人化和自动化作物负载管理。&lt;h4&gt;背景&lt;/h4&gt;在果园自动化中，树冠季节的密集树冠会严重遮挡树木结构，限制了机器视觉系统对树干和树枝等树冠各部分的可见性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够在整个生长季节支持机器人化和自动化作物负载管理的信息融合框架。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了休眠期和树冠期的RGB-D图像，使用YOLOv9-Seg进行实例分割，Kinect Fusion进行3D重建，以及Fast GICP进行模型对齐。YOLOv9-Seg的分割输出用于提取深度信息掩码，通过Kinect Fusion实现准确的3D点云重建；然后使用Fast GICP对每个季节重建的模型进行对齐，以实现空间一致的多季节融合。&lt;h4&gt;主要发现&lt;/h4&gt;YOLOv9-Seg模型在休眠季节数据集上对树干实现了0.0047的平均均方误差和高达0.78的分割mAP@50分数。Kinect Fusion能够精确地重建树木几何形状，与现场测量的均方根误差（RMSE）分别为5.23毫米（树干直径）、4.50毫米（树枝直径）和13.72毫米（树枝间距）。Fast GICP实现了精确的跨季节注册，最小拟合分数为0.00197，即使在生长季节的严重遮挡下，也能实现综合的树木结构建模。&lt;h4&gt;结论&lt;/h4&gt;融合的结构表示使机器人系统能够访问其他情况下被遮挡的建筑信息，从而提高了修剪、疏伐和其他自动化果园操作的精度。&lt;h4&gt;翻译&lt;/h4&gt;在果园自动化中，树冠季节的密集树冠严重遮挡了树木结构，限制了机器视觉系统对树干和树枝等树冠各部分的可见性。然而，在树木落叶的休眠季节，树冠结构更加开放和可见。本研究提出了一种信息融合框架，该框架整合了多季节结构数据，以支持整个生长季节的机器人化和自动化作物负载管理。该框架结合了休眠期和树冠期的RGB-D图像，使用YOLOv9-Seg进行实例分割，Kinect Fusion进行3D重建，以及Fast GICP进行模型对齐。YOLOv9-Seg的分割输出用于提取深度信息掩码，通过Kinect Fusion实现准确的3D点云重建；然后使用Fast GICP对每个季节重建的模型进行对齐，以实现空间一致的多季节融合。YOLOv9-Seg模型在休眠季节数据集上对树干实现了0.0047的平均均方误差和高达0.78的分割mAP@50分数。Kinect Fusion能够精确地重建树木几何形状，与现场测量的均方根误差（RMSE）分别为5.23毫米（树干直径）、4.50毫米（树枝直径）和13.72毫米（树枝间距）。Fast GICP实现了精确的跨季节注册，最小拟合分数为0.00197，即使在生长季节的严重遮挡下，也能实现综合的树木结构建模。这种融合的结构表示使机器人系统能够访问其他情况下被遮挡的建筑信息，从而提高了修剪、疏伐和其他自动化果园操作的精度。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In orchard automation, dense foliage during the canopy season severelyoccludes tree structures, minimizing visibility to various canopy parts such astrunks and branches, which limits the ability of a machine vision system.However, canopy structure is more open and visible during the dormant seasonwhen trees are defoliated. In this work, we present an information fusionframework that integrates multi-seasonal structural data to support robotic andautomated crop load management during the entire growing season. The frameworkcombines high-resolution RGB-D imagery from both dormant and canopy periodsusing YOLOv9-Seg for instance segmentation, Kinect Fusion for 3Dreconstruction, and Fast Generalized Iterative Closest Point (Fast GICP) formodel alignment. Segmentation outputs from YOLOv9-Seg were used to extractdepth-informed masks, which enabled accurate 3D point cloud reconstruction viaKinect Fusion; these reconstructed models from each season were subsequentlyaligned using Fast GICP to achieve spatially coherent multi-season fusion. TheYOLOv9-Seg model, trained on manually annotated images, achieved a mean squarederror (MSE) of 0.0047 and segmentation mAP@50 scores up to 0.78 for trunks indormant season dataset. Kinect Fusion enabled accurate reconstruction of treegeometry, validated with field measurements resulting in root mean squareerrors (RMSE) of 5.23 mm for trunk diameter, 4.50 mm for branch diameter, and13.72 mm for branch spacing. Fast GICP achieved precise cross-seasonalregistration with a minimum fitness score of 0.00197, allowing integrated,comprehensive tree structure modeling despite heavy occlusions during thegrowing season. This fused structural representation enables robotic systems toaccess otherwise obscured architectural information, improving the precision ofpruning, thinning, and other automated orchard operations.</description>
      <author>example@mail.com (Ranjan Sapkota, Zhichao Meng, Martin Churuvija, Xiaoqiang Du, Zenghong Ma, Manoj Karkee)</author>
      <guid isPermaLink="false">2507.01912v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>LongAnimation: Long Animation Generation with Dynamic Global-Local Memory</title>
      <link>http://arxiv.org/abs/2507.01945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的长动画自动着色框架LongAnimation，用于解决长动画着色中的颜色一致性问题。&lt;h4&gt;背景&lt;/h4&gt;动画着色在动画产业中至关重要，但长动画着色成本高，现有研究主要针对短动画着色，采用局部范式，但忽略了全局信息，导致颜色一致性差。&lt;h4&gt;目的&lt;/h4&gt;通过动态全局-局部范式，动态提取与当前生成相关的全局颜色一致性特征，以实现理想的长动画颜色一致性。&lt;h4&gt;方法&lt;/h4&gt;LongAnimation框架主要包括SketchDiT、动态全局-局部记忆（DGLM）和颜色一致性奖励。SketchDiT捕捉混合参考特征以支持DGLM模块；DGLM模块使用长视频理解模型动态压缩全局历史特征，并自适应地融合当前生成特征；颜色一致性奖励用于细化颜色一致性；在推理过程中，提出颜色一致性融合以平滑视频段过渡。&lt;h4&gt;主要发现&lt;/h4&gt;LongAnimation在短期（14帧）和长期（平均500帧）动画上的实验表明，该框架在保持开放域动画着色任务中的短期和长期颜色一致性方面是有效的。&lt;h4&gt;结论&lt;/h4&gt;LongAnimation框架能够有效解决长动画着色中的颜色一致性问题，具有较高的研究价值。&lt;h4&gt;翻译&lt;/h4&gt;The abstract summarizes that the proposed LongAnimation framework effectively addresses the issue of color consistency in long animation coloring, demonstrating its effectiveness in maintaining short-term and long-term color consistency for open-domain animation coloring tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Animation colorization is a crucial part of real animation industryproduction. Long animation colorization has high labor costs. Therefore,automated long animation colorization based on the video generation model hassignificant research value. Existing studies are limited to short-termcolorization. These studies adopt a local paradigm, fusing overlapping featuresto achieve smooth transitions between local segments. However, the localparadigm neglects global information, failing to maintain long-term colorconsistency. In this study, we argue that ideal long-term color consistency canbe achieved through a dynamic global-local paradigm, i.e., dynamicallyextracting global color-consistent features relevant to the current generation.Specifically, we propose LongAnimation, a novel framework, which mainlyincludes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a ColorConsistency Reward. The SketchDiT captures hybrid reference features to supportthe DGLM module. The DGLM module employs a long video understanding model todynamically compress global historical features and adaptively fuse them withthe current generation features. To refine the color consistency, we introducea Color Consistency Reward. During inference, we propose a color consistencyfusion to smooth the video segment transition. Extensive experiments on bothshort-term (14 frames) and long-term (average 500 frames) animations show theeffectiveness of LongAnimation in maintaining short-term and long-term colorconsistency for open-domain animation colorization task. The code can be foundat https://cn-makers.github.io/long_animation_web/.</description>
      <author>example@mail.com (Nan Chen, Mengqi Huang, Yihao Meng, Zhendong Mao)</author>
      <guid isPermaLink="false">2507.01945v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition</title>
      <link>http://arxiv.org/abs/2507.01673v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FACET-VLM是一种用于3D/4D面部表情识别的视觉-语言框架，通过整合多视图面部表示学习和自然语言提示的语义引导，提高了识别的准确性。&lt;h4&gt;背景&lt;/h4&gt;3D和4D领域的面部表情识别在情感计算中是一个挑战，因为面部动态的空间和时间复杂性。这一领域的成功对于人类行为理解、医疗监测和人与计算机交互的应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出FACET-VLM框架，以解决3D/4D面部表情识别的挑战，并提高其在多种场景下的准确性。&lt;h4&gt;方法&lt;/h4&gt;FACET-VLM引入了三个关键组件：交叉视图语义聚合（CVSA）用于视图一致融合，多视图文本引导融合（MTGF）用于语义对齐面部情绪，以及多视图一致性损失以强制视图之间的结构一致性。&lt;h4&gt;主要发现&lt;/h4&gt;FACET-VLM在多个基准测试中实现了最先进的准确性，包括BU-3DFE、Bosphorus、BU-4DFE和BP4D-Spontaneous。此外，它还扩展到了4D微表情识别（MER）领域，并在4DME数据集上表现出强大的性能。&lt;h4&gt;结论&lt;/h4&gt;广泛的实验结果证实了FACET-VLM框架中每个组件的有效性和重大贡献。总的来说，FACET-VLM为静态和自发设置中的多模态面部表情识别提供了一个稳健、可扩展且高性能的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Facial expression recognition (FER) in 3D and 4D domains presents asignificant challenge in affective computing due to the complexity of spatialand temporal facial dynamics. Its success is crucial for advancing applicationsin human behavior understanding, healthcare monitoring, and human-computerinteraction. In this work, we propose FACET-VLM, a vision-language frameworkfor 3D/4D FER that integrates multiview facial representation learning withsemantic guidance from natural language prompts. FACET-VLM introduces three keycomponents: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion,Multiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions,and a multiview consistency loss to enforce structural coherence across views.Our model achieves state-of-the-art accuracy across multiple benchmarks,including BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extendFACET-VLM to 4D micro-expression recognition (MER) on the 4DME dataset,demonstrating strong performance in capturing subtle, short-lived emotionalcues. The extensive experimental results confirm the effectiveness andsubstantial contributions of each individual component within the framework.Overall, FACET-VLM offers a robust, extensible, and high-performing solutionfor multimodal FER in both posed and spontaneous settings.</description>
      <author>example@mail.com (Muzammil Behzad)</author>
      <guid isPermaLink="false">2507.01673v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.01735v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ECCV 2024. Workshop page: https://coda-dataset.github.io/w-coda2024/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了在ECCV 2024期间举办的第1届W-CODA研讨会，探讨了下一代自动驾驶角案解决方案。&lt;h4&gt;背景&lt;/h4&gt;研讨会旨在通过最先进的多模态感知和理解技术，探索自动驾驶角案的未来解决方案。&lt;h4&gt;目的&lt;/h4&gt;目的是分享学术和工业界的最新进展和观点，并举办包括角案场景理解和生成在内的双轨挑战。&lt;h4&gt;方法&lt;/h4&gt;研讨会邀请了5位来自学术界和工业界的演讲者，收集研究论文，并举办挑战赛。&lt;h4&gt;主要发现&lt;/h4&gt;这是开创性的工作，旨在不断缩小前沿自动驾驶技术与全面智能、可靠、对角案有鲁棒性的自动驾驶代理之间的差距。&lt;h4&gt;结论&lt;/h4&gt;研讨会通过交流和挑战赛，推进了自动驾驶技术在角案处理方面的研究和应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：本文介绍了在ECCV 2024期间举办的第1届W-CODA研讨会，旨在探索下一代自动驾驶角案解决方案，通过最先进的多模态感知和理解技术。研讨会邀请了来自学术界和工业界的5位演讲者分享最新进展和观点，并收集研究论文，举办包括角案场景理解和生成在内的双轨挑战。作为开创性工作，研讨会将不断缩小前沿自动驾驶技术与全面智能、可靠、对角案有鲁棒性的自动驾驶代理之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present details of the 1st W-CODA workshop, held inconjunction with the ECCV 2024. W-CODA aims to explore next-generationsolutions for autonomous driving corner cases, empowered by state-of-the-artmultimodal perception and comprehension techniques. 5 Speakers from bothacademia and industry are invited to share their latest progress and opinions.We collect research papers and hold a dual-track challenge, including bothcorner case scene understanding and generation. As the pioneering effort, wewill continuously bridge the gap between frontier autonomous driving techniquesand fully intelligent, reliable self-driving agents robust towards cornercases.</description>
      <author>example@mail.com (Kai Chen, Ruiyuan Gao, Lanqing Hong, Hang Xu, Xu Jia, Holger Caesar, Dengxin Dai, Bingbing Liu, Dzmitry Tsishkou, Songcen Xu, Chunjing Xu, Qiang Xu, Huchuan Lu, Dit-Yan Yeung)</author>
      <guid isPermaLink="false">2507.01735v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>ARIG: Autoregressive Interactive Head Generation for Real-time Conversations</title>
      <link>http://arxiv.org/abs/2507.00472v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025. Homepage: https://jinyugy21.github.io/ARIG/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自回归（AR）的帧级框架ARIG，用于实现具有更好交互真实感的实时交互头部生成。&lt;h4&gt;背景&lt;/h4&gt;面对面的交流促进了交互头部生成的研究。虚拟代理能够根据其他用户的音频或运动信号以及自身的音频或运动信号生成运动响应。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在信号获取、上下文行为理解以及切换平滑度方面的局限性，实现实时和真实的头部生成。&lt;h4&gt;方法&lt;/h4&gt;采用非矢量量化自回归过程建模运动预测，使用扩散过程表示运动分布，提高预测精度。通过双向集成学习和长距离的上下文理解实现交互行为理解（IBU），使用语音活动信号和IBU的上下文特征来理解实际对话中的各种状态（如打断、反馈、暂停等），作为最终渐进式运动预测的条件。&lt;h4&gt;主要发现&lt;/h4&gt;实验验证了该模型的有效性。&lt;h4&gt;结论&lt;/h4&gt;ARIG框架能够实现具有更好交互真实感的实时头部生成，有效解决了现有方法的局限性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Face-to-face communication, as a common human activity, motivates theresearch on interactive head generation. A virtual agent can generate motionresponses with both listening and speaking capabilities based on the audio ormotion signals of the other user and itself. However, previous clip-wisegeneration paradigm or explicit listener/speaker generator-switching methodshave limitations in future signal acquisition, contextual behavioralunderstanding, and switching smoothness, making it challenging to be real-timeand realistic. In this paper, we propose an autoregressive (AR) basedframe-wise framework called ARIG to realize the real-time generation withbetter interaction realism. To achieve real-time generation, we model motionprediction as a non-vector-quantized AR process. Unlike discrete codebook-indexprediction, we represent motion distribution using diffusion procedure,achieving more accurate predictions in continuous space. To improve interactionrealism, we emphasize interactive behavior understanding (IBU) and detailedconversational state understanding (CSU). In IBU, based on dual-trackdual-modal signals, we summarize short-range behaviors throughbidirectional-integrated learning and perform contextual understanding overlong ranges. In CSU, we use voice activity signals and context features of IBUto understand the various states (interruption, feedback, pause, etc.) thatexist in actual conversations. These serve as conditions for the finalprogressive motion prediction. Extensive experiments have verified theeffectiveness of our model.</description>
      <author>example@mail.com (Ying Guo, Xi Liu, Cheng Zhen, Pengfei Yan, Xiaoming Wei)</author>
      <guid isPermaLink="false">2507.00472v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2507.01006v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了GLM-4.1V-Thinking，这是一种旨在推进通用多模态理解和推理的视觉语言模型（VLM）。&lt;h4&gt;背景&lt;/h4&gt;多模态理解和推理在多个领域具有重要意义，但现有的模型在性能上存在局限性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够提升通用多模态理解和推理能力的视觉语言模型。&lt;h4&gt;方法&lt;/h4&gt;通过大规模预训练开发了一个强大的视觉基础模型，并提出了一种名为强化学习与课程采样的方法（RLCS）来解锁模型潜力，增强其在各种任务上的能力。&lt;h4&gt;主要发现&lt;/h4&gt;GLM-4.1V-9B-Thinking在28个公共基准测试中表现出色，几乎在所有任务上都优于Qwen2.5-VL-7B，并在18个基准测试中与Qwen2.5-VL-72B相当或更优。此外，在包括长文档理解和STEM推理在内的挑战性任务上，其性能与GPT-4o等闭源模型相比具有竞争力或优势。&lt;h4&gt;结论&lt;/h4&gt;GLM-4.1V-Thinking模型在多模态理解和推理方面具有强大的能力，并在多个任务上达到了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;We present GLM-4.1V-Thinking, a vision-language model (VLM) designed to advance general-purpose multimodal understanding and reasoning. In this report, we share our key findings in the development of the reasoning-centric training framework. We first develop a capable vision foundation model with significant potential through large-scale pre-training, which arguably sets the upper bound for the final performance. We then propose Reinforcement Learning with Curriculum Sampling (RLCS) to unlock the full potential of the model, leading to comprehensive capability enhancement across a diverse range of tasks, including STEM problem solving, video understanding, content recognition, coding, grounding, GUI-based agents, and long document understanding. We open-source GLM-4.1V-9B-Thinking, which achieves state-of-the-art performance among models of comparable size. In a comprehensive evaluation across 28 public benchmarks, our model outperforms Qwen2.5-VL-7B on nearly all tasks and achieves comparable or even superior performance on 18 benchmarks relative to the significantly larger Qwen2.5-VL-72B. Notably, GLM-4.1V-9B-Thinking also demonstrates competitive or superior performance compared to closed-source models such as GPT-4o on challenging tasks including long document understanding and STEM reasoning, further underscoring its strong capabilities. Code, models and more information are released at https://github.com/THUDM/GLM-4.1V-Thinking.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present GLM-4.1V-Thinking, a vision-language model (VLM) designed toadvance general-purpose multimodal understanding and reasoning. In this report,we share our key findings in the development of the reasoning-centric trainingframework. We first develop a capable vision foundation model with significantpotential through large-scale pre-training, which arguably sets the upper boundfor the final performance. We then propose Reinforcement Learning withCurriculum Sampling (RLCS) to unlock the full potential of the model, leadingto comprehensive capability enhancement across a diverse range of tasks,including STEM problem solving, video understanding, content recognition,coding, grounding, GUI-based agents, and long document understanding. Weopen-source GLM-4.1V-9B-Thinking, which achieves state-of-the-art performanceamong models of comparable size. In a comprehensive evaluation across 28 publicbenchmarks, our model outperforms Qwen2.5-VL-7B on nearly all tasks andachieves comparable or even superior performance on 18 benchmarks relative tothe significantly larger Qwen2.5-VL-72B. Notably, GLM-4.1V-9B-Thinking alsodemonstrates competitive or superior performance compared to closed-sourcemodels such as GPT-4o on challenging tasks including long documentunderstanding and STEM reasoning, further underscoring its strong capabilities.Code, models and more information are released athttps://github.com/THUDM/GLM-4.1V-Thinking.</description>
      <author>example@mail.com (GLM-V Team, :, Wenyi Hong, Wenmeng Yu, Xiaotao Gu, Guo Wang, Guobing Gan, Haomiao Tang, Jiale Cheng, Ji Qi, Junhui Ji, Lihang Pan, Shuaiqi Duan, Weihan Wang, Yan Wang, Yean Cheng, Zehai He, Zhe Su, Zhen Yang, Ziyang Pan, Aohan Zeng, Baoxu Wang, Boyan Shi, Changyu Pang, Chenhui Zhang, Da Yin, Fan Yang, Guoqing Chen, Jiazheng Xu, Jiali Chen, Jing Chen, Jinhao Chen, Jinghao Lin, Jinjiang Wang, Junjie Chen, Leqi Lei, Letian Gong, Leyi Pan, Mingzhi Zhang, Qinkai Zheng, Sheng Yang, Shi Zhong, Shiyu Huang, Shuyuan Zhao, Siyan Xue, Shangqin Tu, Shengbiao Meng, Tianshu Zhang, Tianwei Luo, Tianxiang Hao, Wenkai Li, Wei Jia, Xin Lyu, Xuancheng Huang, Yanling Wang, Yadong Xue, Yanfeng Wang, Yifan An, Yifan Du, Yiming Shi, Yiheng Huang, Yilin Niu, Yuan Wang, Yuanchang Yue, Yuchen Li, Yutao Zhang, Yuxuan Zhang, Zhanxiao Du, Zhenyu Hou, Zhao Xue, Zhengxiao Du, Zihan Wang, Peng Zhang, Debing Liu, Bin Xu, Juanzi Li, Minlie Huang, Yuxiao Dong, Jie Tang)</author>
      <guid isPermaLink="false">2507.01006v2</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Multi-Exposure High Dynamic Range Imaging with Overlapped Codebook for Improved Representation Learning</title>
      <link>http://arxiv.org/abs/2507.01588v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to International Conference on Pattern Recognition.  Springer, Cham, 2025 (ICPR 2024)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的HDR成像技术，通过使用重叠码本方案（OLC）和HDR网络，从低动态范围（LDR）图像中生成更逼真的HDR图像，并提高了饱和区域的补偿和整体视觉质量。&lt;h4&gt;背景&lt;/h4&gt;HDR成像技术旨在从低动态范围（LDR）输入中创建逼真的HDR图像。多曝光HDR成像通过使用同一场景的多帧LDR图像来提高重建性能，但帧间存在运动差异和不同曝光设置可能导致饱和区域。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的HDR成像方法，以改善从LDR图像到HDR图像的转换，并提高视觉质量。&lt;h4&gt;方法&lt;/h4&gt;本文首先提出了一种重叠码本（OLC）方案，用于提高VQGAN框架学习隐式HDR表示的能力。进一步开发了一个新的HDR网络，该网络利用预训练的VQ网络和OLC生成的HDR表示。&lt;h4&gt;主要发现&lt;/h4&gt;所提出的方法在多个数据集上进行了广泛测试，结果显示在定性和定量方面均优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提升HDR图像的生成质量，为从LDR图像到HDR图像的转换提供了新的思路和解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/978-3-031-78125-4_19&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; High dynamic range (HDR) imaging technique aims to create realistic HDRimages from low dynamic range (LDR) inputs. Specifically, Multi-exposure HDRimaging uses multiple LDR frames taken from the same scene to improvereconstruction performance. However, there are often discrepancies in motionamong the frames, and different exposure settings for each capture can lead tosaturated regions. In this work, we first propose an Overlapped codebook (OLC)scheme, which can improve the capability of the VQGAN framework for learningimplicit HDR representations by modeling the common exposure bracket process inthe shared codebook structure. Further, we develop a new HDR network thatutilizes HDR representations obtained from a pre-trained VQ network and OLC.This allows us to compensate for saturated regions and enhance overall visualquality. We have tested our approach extensively on various datasets and havedemonstrated that it outperforms previous methods both qualitatively andquantitatively</description>
      <author>example@mail.com (Keuntek Lee, Jaehyun Park, Nam Ik Cho)</author>
      <guid isPermaLink="false">2507.01588v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective</title>
      <link>http://arxiv.org/abs/2507.01652v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的线性注意力机制LASAD，用于图像生成，通过在图像序列中计算位置相关的衰减因子，有效地保留了二维空间关系，提高了图像生成的性能和计算效率。&lt;h4&gt;背景&lt;/h4&gt;自回归模型在图像生成中受到关注，但现有的AR模型大多依赖于变压器架构，存在计算复杂度和内存开销大的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的线性注意力机制，以减少计算复杂度和内存开销，同时提高图像生成的质量。&lt;h4&gt;方法&lt;/h4&gt;提出LASAD，一种基于空间感知衰减的线性注意力机制，以及基于此机制的LASADGen自动回归图像生成器。&lt;h4&gt;主要发现&lt;/h4&gt;LASAD能够有效地捕捉视觉数据中的长距离依赖关系，提高了图像生成的质量；LASADGen在ImageNet数据集上达到了最先进的图像生成性能和计算效率。&lt;h4&gt;结论&lt;/h4&gt;LASADGen通过结合线性注意力的效率和空间理解能力，在图像生成方面取得了显著进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autoregressive (AR) models have garnered significant attention in imagegeneration for their ability to effectively capture both local and globalstructures within visual data. However, prevalent AR models predominantly relyon the transformer architectures, which are beset by quadratic computationalcomplexity concerning input sequence length and substantial memory overhead dueto the necessity of maintaining key-value caches. Although linear attentionmechanisms have successfully reduced this burden in language models, ourinitial experiments reveal that they significantly degrade image generationquality because of their inability to capture critical long-range dependenciesin visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), anovel attention mechanism that explicitly preserves genuine 2D spatialrelationships within the flattened image sequences by computingposition-dependent decay factors based on true 2D spatial location rather than1D sequence positions. Based on this mechanism, we present LASADGen, anautoregressive image generator that enables selective attention to relevantspatial contexts with linear complexity. Experiments on ImageNet show LASADGenachieves state-of-the-art image generation performance and computationalefficiency, bridging the gap between linear attention's efficiency and spatialunderstanding needed for high-quality generation.</description>
      <author>example@mail.com (Yuxin Mao, Zhen Qin, Jinxing Zhou, Hui Deng, Xuyang Shen, Bin Fan, Jing Zhang, Yiran Zhong, Yuchao Dai)</author>
      <guid isPermaLink="false">2507.01652v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>CAVALRY-V: A Large-Scale Generator Framework for Adversarial Attacks on Video MLLMs</title>
      <link>http://arxiv.org/abs/2507.00817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了CAVALRY-V，一个针对视频多模态大语言模型（V-MLLMs）的对抗攻击框架，该框架旨在解决V-MLLMs在跨模态理解方面的对抗攻击问题。&lt;h4&gt;背景&lt;/h4&gt;V-MLLMs在时间和跨模态理解方面表现出色，但其对对抗攻击的脆弱性尚未得到充分研究，这归因于其复杂的跨模态推理机制、时间依赖性和计算限制。&lt;h4&gt;目的&lt;/h4&gt;提出CAVALRY-V框架，直接针对V-MLLMs中视觉感知和语言生成之间的关键接口。&lt;h4&gt;方法&lt;/h4&gt;CAVALRY-V引入了两个关键创新：(1) 一个双重目标的语义-视觉损失函数，该函数同时破坏模型的文本生成logits和视觉表示以破坏跨模态整合；(2) 一个计算高效的二阶段生成框架，结合大规模预训练的跨模型可迁移性和针对时空一致性的专用微调。&lt;h4&gt;主要发现&lt;/h4&gt;在全面的视频理解基准测试中，CAVALRY-V显著优于现有的攻击方法，在商业系统（如GPT-4.1，Gemini 2.0）和开源模型（如QwenVL-2.5，InternVL-2.5，Llava-Video，Aria，MiniCPM-o-2.6）上实现了平均22.8%的性能提升。&lt;h4&gt;结论&lt;/h4&gt;CAVALRY-V通过隐式的时间一致性建模而不是显式的正则化来实现灵活性，即使在图像理解上也取得了显著的性能提升（平均提高34.4%）。这表明CAVALRY-V可以作为跨模态系统对抗研究的坚实基础方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了Video Multimodal Large Language Models（V-MLLMs）在时间和跨模态理解方面的出色能力，但它们对对抗攻击的脆弱性尚未得到充分探索。本文提出了一种名为CAVALRY-V的新框架，旨在解决V-MLLMs在视觉感知和语言生成之间的关键接口问题。该框架引入了双重目标的语义-视觉损失函数和一个高效的二阶段生成框架，实现了在多个视频理解基准测试中的显著性能提升。CAVALRY-V通过隐式的时间一致性建模提高了灵活性，并在图像理解任务上也取得了显著进步，显示出其在多模态系统对抗研究中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Multimodal Large Language Models (V-MLLMs) have shown impressivecapabilities in temporal reasoning and cross-modal understanding, yet theirvulnerability to adversarial attacks remains underexplored due to uniquechallenges: complex cross-modal reasoning mechanisms, temporal dependencies,and computational constraints. We present CAVALRY-V (Cross-modalLanguage-Vision Adversarial Yielding for Videos), a novel framework thatdirectly targets the critical interface between visual perception and languagegeneration in V-MLLMs. Our approach introduces two key innovations: (1) adual-objective semantic-visual loss function that simultaneously disrupts themodel's text generation logits and visual representations to underminecross-modal integration, and (2) a computationally efficient two-stagegenerator framework that combines large-scale pre-training for cross-modeltransferability with specialized fine-tuning for spatiotemporal coherence.Empirical evaluation on comprehensive video understanding benchmarksdemonstrates that CAVALRY-V significantly outperforms existing attack methods,achieving 22.8% average improvement over the best baseline attacks on bothcommercial systems (GPT-4.1, Gemini 2.0) and open-source models (QwenVL-2.5,InternVL-2.5, Llava-Video, Aria, MiniCPM-o-2.6). Our framework achievesflexibility through implicit temporal coherence modeling rather than explicitregularization, enabling significant performance improvements even on imageunderstanding (34.4% average gain). This capability demonstrates CAVALRY-V'spotential as a foundational approach for adversarial research across multimodalsystems.</description>
      <author>example@mail.com (Jiaming Zhang, Rui Hu, Qing Guo, Wei Yang Bryan Lim)</author>
      <guid isPermaLink="false">2507.00817v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Robust Multi-generation Learned Compression of Point Cloud Attribute</title>
      <link>http://arxiv.org/abs/2507.01320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了学习点云属性压缩的多代压缩问题，提出了解决质量退化的方法，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现有学习点云属性压缩方法主要关注单次率失真优化，忽视了多代压缩场景中的累积失真问题。&lt;h4&gt;目的&lt;/h4&gt;首次研究学习点云属性压缩中的多代压缩问题。&lt;h4&gt;方法&lt;/h4&gt;提出映射幂等性约束和转换可逆性约束，以及潜在变量一致性约束，以增强多代压缩的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;识别出量化引起的非幂等性和转换不可逆性是导致多代压缩质量退化的两个主要因素。&lt;h4&gt;结论&lt;/h4&gt;提出的方案可以有效抑制多代损失，同时保持与基线模型相当的单次率失真性能。&lt;h4&gt;翻译&lt;/h4&gt;Existing learned point cloud attribute compression methods primarily focus on single-pass rate-distortion optimization, while overlooking the issue of cumulative distortion in multi-generation compression scenarios. This paper, for the first time, investigates the multi-generation issue in learned point cloud attribute compression. We identify two primary factors contributing to quality degradation in multi-generation compression: quantization-induced non-idempotency and transformation irreversibility. To address the former, we propose a Mapping Idempotency Constraint, that enables the network to learn the complete compression-decompression mapping, enhancing its robustness to repeated processes. To address the latter, we introduce a Transformation Reversibility Constraint, which preserves reversible information flow via a quantization-free training path. Further, we propose a Latent Variable Consistency Constraint which enhances the multi-generation compression robustness by incorporating a decompression-compression cross-generation path and a latent variable consistency loss term. Extensive experiments conducted on the Owlii and 8iVFB datasets verify that the proposed methods can effectively suppress multi-generation loss while maintaining single-pass rate-distortion performance comparable to baseline models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing learned point cloud attribute compression methods primarily focus onsingle-pass rate-distortion optimization, while overlooking the issue ofcumulative distortion in multi-generation compression scenarios. This paper,for the first time, investigates the multi-generation issue in learned pointcloud attribute compression. We identify two primary factors contributing toquality degradation in multi-generation compression: quantization-inducednon-idempotency and transformation irreversibility. To address the former, wepropose a Mapping Idempotency Constraint, that enables the network to learn thecomplete compression-decompression mapping, enhancing its robustness torepeated processes. To address the latter, we introduce a TransformationReversibility Constraint, which preserves reversible information flow via aquantization-free training path. Further, we propose a Latent VariableConsistency Constraint which enhances the multi-generation compressionrobustness by incorporating a decompression-compression cross-generation pathand a latent variable consistency loss term. Extensive experiments conducted onthe Owlii and 8iVFB datasets verify that the proposed methods can effectivelysuppress multi-generation loss while maintaining single-pass rate-distortionperformance comparable to baseline models.</description>
      <author>example@mail.com (Xiangzuo Liu, Zhikai Liu, PengPeng Yu, Ruishan Huang, Fan Liang)</author>
      <guid isPermaLink="false">2507.01320v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.00525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Box-QAymo的箱式引用数据集和基准，用于评估和微调视觉语言模型在空间和时间推理方面的能力，以应对现实场景中用户指定的对象查询。&lt;h4&gt;背景&lt;/h4&gt;可解释的通信对于安全可靠的自动驾驶至关重要，但现有的视觉语言模型在理想化假设下运行，难以捕捉现实场景中的用户意图。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够有效与用户沟通的、更稳健且可解释的自动驾驶系统。&lt;h4&gt;方法&lt;/h4&gt;Box-QAymo通过用户绘制边界框来表达意图，提供了一种快速直观的界面来查询复杂场景中的特定对象。评估协议包括基本能力检查、属性预测、目标实例的运动理解以及跨帧对象间动态的时空运动推理。&lt;h4&gt;主要发现&lt;/h4&gt;当前视觉语言模型在感知问题查询上存在显著局限性，这突显了实现现实世界性能的差距。&lt;h4&gt;结论&lt;/h4&gt;该研究为开发更稳健且可解释的自动驾驶系统提供了基础，这些系统能够在现实条件下有效地与用户沟通。&lt;h4&gt;翻译&lt;/h4&gt;摘要：可解释的通信对于安全可靠的自动驾驶至关重要，但当前视觉语言模型（VLMs）通常在理想化假设下运行，难以捕捉现实场景中的用户意图。现有的以驾驶为导向的VQA数据集仅限于全场景描述或航点预测，这阻碍了对VLMs是否能回应局部用户驱动查询的评估。我们引入了Box-QAymo，这是一个箱式引用数据集和基准，旨在评估和微调VLMs在用户指定对象上的空间和时间推理能力。用户通过绘制边界框来表达意图，为复杂场景中的聚焦查询提供了一种快速直观的界面。具体来说，我们提出了一种分层评估协议，从二元合理性检查问题开始，以评估基本模型能力，然后逐步发展到（1）对箱式引用对象的属性预测，（2）对目标实例的运动理解，以及（3）跨帧对象间动态的时空运动推理。为此，我们通过众包细粒度对象类别和视觉属性，这些属性反映了驾驶员遇到的复杂性，并提取对象轨迹来构建基于时间的QA对。通过负采样、时间一致性检查和难度感知平衡的严格质量控制，保证了数据集的稳健性和多样性。我们的全面评估揭示了当前VLMs在感知问题查询上的显著局限性，突显了实现现实世界性能的差距。这项工作为开发更稳健且可解释的自动驾驶系统提供了基础，这些系统能够在现实条件下有效地与用户沟通。项目页面和数据集可在https://djamahl99.github.io/qaymo-pages/找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable communication is essential for safe and trustworthy autonomousdriving, yet current vision-language models (VLMs) often operate underidealized assumptions and struggle to capture user intent in real-worldscenarios. Existing driving-oriented VQA datasets are limited to full-scenedescriptions or waypoint prediction, preventing the assessment of whether VLMscan respond to localized user-driven queries. We introduce Box-QAymo, abox-referring dataset and benchmark designed to both evaluate and finetune VLMson spatial and temporal reasoning over user-specified objects. Users expressintent by drawing bounding boxes, offering a fast and intuitive interface forfocused queries in complex scenes. Specifically, we propose a hierarchicalevaluation protocol that begins with binary sanity-check questions to assessbasic model capacities, and progresses to (1) attribute prediction forbox-referred objects, (2) motion understanding of target instances, and (3)spatiotemporal motion reasoning over inter-object dynamics across frames. Tosupport this, we crowd-sourced fine-grained object classes and visualattributes that reflect the complexity drivers encounter, and extract objecttrajectories to construct temporally grounded QA pairs. Rigorous qualitycontrol through negative sampling, temporal consistency checks, anddifficulty-aware balancing guarantee dataset robustness and diversity. Ourcomprehensive evaluation reveals significant limitations in current VLMs whenqueried about perception questions, highlighting the gap in achievingreal-world performance. This work provides a foundation for developing morerobust and interpretable autonomous driving systems that can communicateeffectively with users under real-world conditions. Project page and datasetare available at https://djamahl99.github.io/qaymo-pages/.</description>
      <author>example@mail.com (Djamahl Etchegaray, Yuxia Fu, Zi Huang, Yadan Luo)</author>
      <guid isPermaLink="false">2507.00525v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>More sophisticated is not always better: comparison of similarity measures for unsupervised learning of pathways in biomolecular simulations</title>
      <link>http://arxiv.org/abs/2507.01725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This preprint is the unedited version of a manuscript that has been  sent to a peer-reviewed scientific journal for consideration as article.  Copyright with the authors and the publisher after publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了四种不同复杂度的相似度度量方法在分子模拟中寻找过程途径的性能，这些方法在分析轨迹数据时被用来识别小分子配体从蛋白质靶点解离的路径。&lt;h4&gt;背景&lt;/h4&gt;在分子模拟中，通过无监督学习方法寻找小分子配体从蛋白质靶点解离路径的过程，需要定义轨迹之间的合适相似度度量。&lt;h4&gt;目的&lt;/h4&gt;评估四种不同相似度度量方法（欧几里得距离、Wasserstein距离、Procrustes分析和动态时间扭曲）在分析两种不同偏置模拟驱动协议（恒速约束分子动力学和引导分子动力学）的轨迹数据时的性能。&lt;h4&gt;方法&lt;/h4&gt;在已知真实聚类簇的链霉亲和素-生物素基准系统中，比较了四种相似度度量方法在聚类性能上的表现；在更复杂的A2a受体-抑制剂系统中，比较了这些方法在揭示有意义的可解释簇方面的表现。&lt;h4&gt;主要发现&lt;/h4&gt;Wasserstein距离在聚类性能上表现最佳，其次是欧几里得距离，两者都是计算效率最高的相似度度量方法；在A2a受体-抑制剂系统中，最简单的欧几里得距离就足以揭示有意义的可解释簇。&lt;h4&gt;结论&lt;/h4&gt;在链霉亲和素-生物素系统中，Wasserstein距离和欧几里得距离是高效的相似度度量方法；在A2a受体-抑制剂系统中，欧几里得距离足以满足需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Finding process pathways in molecular simulations such as the unbinding pathsof small molecule ligands from their binding sites at protein targets in a setof trajectories via unsupervised learning approaches requires the definition ofa suitable similarity measure between trajectories. We here evaluate theperformance of four such measures with varying degree of sophistication, i.e.,Euclidean and Wasserstein distances, Procrustes analysis and dynamical timewarping, when analyzing trajectory data from two different biased simulationdriving protocols in the form of constant velocity constraint targeted MD andsteered MD. In a streptavidin-biotin benchmark system with known ground truthclusters, Wasserstein distances yielded the best clustering performance,closely followed by Euclidean distances, both being the most computationallyefficient similarity measures. In a more complex A2a receptor-inhibitor system,however, the simplest measure, i.e., Euclidean distances, was sufficient toreveal meaningful and interpretable clusters.</description>
      <author>example@mail.com (Miriam Jäger, Steffen Wolf)</author>
      <guid isPermaLink="false">2507.01725v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Bisecle: Binding and Separation in Continual Learning for Video Language Understanding</title>
      <link>http://arxiv.org/abs/2507.00469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages, 12 figures, 10 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了Bisecle，一种用于视频语言持续学习的模型，旨在解决大规模多模态基础模型中的灾难性遗忘和更新冲突问题。&lt;h4&gt;背景&lt;/h4&gt;现有的持续学习框架在大规模多模态基础模型中面临灾难性遗忘和更新冲突的挑战，因为实时视频数据需要模型不断适应新的数据分布和场景。&lt;h4&gt;目的&lt;/h4&gt;提出一种高效的视频语言持续学习方法，以解决灾难性遗忘和更新冲突问题。&lt;h4&gt;方法&lt;/h4&gt;Bisecle模型通过使用多方向监督模块来捕捉更多跨模态关系，并设计了一种对比提示学习方案来隔离特定任务的知识，以促进高效的记忆存储。&lt;h4&gt;主要发现&lt;/h4&gt;Bisecle能够减轻遗忘并增强跨任务的泛化能力，在多个视频问答基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;Bisecle模型能够有效地实现视频理解任务中的持续学习，为实时视频数据理解提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Frontier视觉语言模型（VLMs）在视频理解任务上取得了显著进步。然而，现实世界的视频通常以连续演变的数据流形式存在（例如，可穿戴眼镜捕获的动态场景），需要模型不断适应不断变化的数据分布和新的场景。考虑到在新的任务上微调模型的计算成本过高，通常只更新一小部分参数，而大部分模型保持冻结。这在大规模多模态基础模型的持续学习框架中提出了新的挑战，即灾难性遗忘和更新冲突。虽然基础模型在参数高效的持续学习中遇到困难，但人类大脑中的海马体已经进化出高度有效的记忆形成和巩固机制。受海马体中快速绑定和模式分离机制的影响，在这项工作中，我们提出了Bisecle用于视频语言持续学习，其中使用多方向监督模块来捕捉更多的跨模态关系，并设计了一种对比提示学习方案来隔离特定任务的知识，以促进高效的记忆存储。绑定和分离过程进一步增强了VLMs保留复杂经验的能力，使视频理解任务中的持续学习变得稳健和高效。我们对提出的Bisecle进行了彻底的评估，证明了其在多个视频问答基准测试中减轻遗忘并增强跨任务泛化的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Frontier vision-language models (VLMs) have made remarkable improvements invideo understanding tasks. However, real-world videos typically exist ascontinuously evolving data streams (e.g., dynamic scenes captured by wearableglasses), necessitating models to continually adapt to shifting datadistributions and novel scenarios. Considering the prohibitive computationalcosts of fine-tuning models on new tasks, usually, a small subset of parametersis updated while the bulk of the model remains frozen. This poses newchallenges to existing continual learning frameworks in the context of largemultimodal foundation models, i.e., catastrophic forgetting and updateconflict. While the foundation models struggle with parameter-efficientcontinual learning, the hippocampus in the human brain has evolved highlyefficient mechanisms for memory formation and consolidation. Inspired by therapid Binding and pattern separation mechanisms in the hippocampus, in thiswork, we propose Bisecle for video-language continual learning, where amulti-directional supervision module is used to capture more cross-modalrelationships and a contrastive prompt learning scheme is designed to isolatetask-specific knowledge to facilitate efficient memory storage. Binding andseparation processes further strengthen the ability of VLMs to retain complexexperiences, enabling robust and efficient continual learning in videounderstanding tasks. We perform a thorough evaluation of the proposed Bisecle,demonstrating its ability to mitigate forgetting and enhance cross-taskgeneralization on several VideoQA benchmarks.</description>
      <author>example@mail.com (Yue Tan, Xiaoqian Hu, Hao Xue, Celso De Melo, Flora D. Salim)</author>
      <guid isPermaLink="false">2507.00469v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence</title>
      <link>http://arxiv.org/abs/2507.01504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted for publication at the 2025 IEEE 28th International  Conference on Intelligent Transportation Systems (ITSC 2025), taking place  during November 18-21, 2025 in Gold Coast, Australia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为cRID的新型跨模态框架，用于检测个人身份信息（PII）并增强行人重识别（Re-ID），以促进自动驾驶系统和AI研究的发展。&lt;h4&gt;背景&lt;/h4&gt;收集和发布街景录音作为开放数据在自动驾驶系统和AI研究中发挥着重要作用，但这些数据集存在隐私风险，尤其是对于行人，因为这些数据集包含了超出生物特征（如面部）的个人信息。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来检测文本描述的可识别线索，并增强行人重识别，同时减少个人隐私风险。&lt;h4&gt;方法&lt;/h4&gt;cRID结合了大型视觉-语言模型、图注意力网络和表示学习，以识别和利用可解释的特征，从而检测语义上有意义的PII，而不仅仅是低级的外观线索。&lt;h4&gt;主要发现&lt;/h4&gt;对行人图像数据集中PII的存在进行了系统性评估，实验表明，在Market-1501到CUHK03-np（检测到的）等实际跨数据集Re-ID场景中，该框架的性能得到提升。&lt;h4&gt;结论&lt;/h4&gt;该框架在提高Re-ID性能的同时，通过减少PII的泄露，有助于提高自动驾驶系统和AI研究的实用性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：收集和发布街景录音作为开放数据在推进自动驾驶系统和AI研究中发挥着至关重要的作用。然而，这些数据集由于包含超出生物特征（如面部）的个人信息，对行人构成了显著的隐私风险。在本文中，我们提出了一种名为cRID的新型跨模态框架，该框架结合了大型视觉-语言模型、图注意力网络和表示学习，用于检测文本描述的可识别线索并增强行人重识别。我们的方法侧重于识别和利用可解释的特征，从而能够检测到语义上有意义的PII，而不仅仅是低级的外观线索。我们对行人图像数据集中PII的存在进行了系统性评估。我们的实验表明，在Market-1501到CUHK03-np（检测到的）等实际跨数据集Re-ID场景中，该框架的性能得到了提升，突出了框架的实际效用。代码可在https://github.com/RAufschlaeger/cRID上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The collection and release of street-level recordings as Open Data play avital role in advancing autonomous driving systems and AI research. However,these datasets pose significant privacy risks, particularly for pedestrians,due to the presence of Personally Identifiable Information (PII) that extendsbeyond biometric traits such as faces. In this paper, we present cRID, a novelcross-modal framework combining Large Vision-Language Models, Graph AttentionNetworks, and representation learning to detect textual describable clues ofPII and enhance person re-identification (Re-ID). Our approach focuses onidentifying and leveraging interpretable features, enabling the detection ofsemantically meaningful PII beyond low-level appearance cues. We conduct asystematic evaluation of PII presence in person image datasets. Our experimentsshow improved performance in practical cross-dataset Re-ID scenarios, notablyfrom Market-1501 to CUHK03-np (detected), highlighting the framework'spractical utility. Code is available at https://github.com/RAufschlaeger/cRID.</description>
      <author>example@mail.com (Robert Aufschläger, Youssef Shoeb, Azarm Nowzad, Michael Heigl, Fabian Bally, Martin Schramm)</author>
      <guid isPermaLink="false">2507.01504v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>GaussianVLM: Scene-centric 3D Vision-Language Models using Language-aligned Gaussian Splats for Embodied Reasoning and Beyond</title>
      <link>http://arxiv.org/abs/2507.00886v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种以场景为中心的3D视觉语言模型（VLM），用于处理3D高斯斯普莱特场景，并通过语言和任务感知的场景表示来提高3D场景理解。&lt;h4&gt;背景&lt;/h4&gt;随着多模态语言模型的进步，它们在3D场景理解中的应用成为快速发展的前沿，推动了3D视觉语言模型（VLMs）的发展。&lt;h4&gt;目的&lt;/h4&gt;为了解决当前方法对物体检测器的依赖，引入了处理瓶颈和分类灵活性限制的问题。&lt;h4&gt;方法&lt;/h4&gt;该模型直接将丰富的语言特征嵌入到3D场景表示中，通过将语言与每个高斯原语关联来实现早期模态对齐。为了处理生成的密集表示，引入了双重稀疏化器，通过任务引导和位置引导路径将它们提炼成紧凑的任务相关标记，产生稀疏的任务感知全局和局部场景标记。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出了首个基于高斯斯普莱特技术的VLM，利用从标准RGB图像派生的逼真3D表示，展示了强大的泛化能力：它将先前3D VLM的性能提高了五倍，在域外设置中。&lt;h4&gt;结论&lt;/h4&gt;该研究提出了一个创新的3D VLM，通过引入语言和任务感知的场景表示，显著提高了3D场景理解的能力，尤其是在域外设置中。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As multimodal language models advance, their application to 3D sceneunderstanding is a fast-growing frontier, driving the development of 3DVision-Language Models (VLMs). Current methods show strong dependence on objectdetectors, introducing processing bottlenecks and limitations in taxonomicflexibility. To address these limitations, we propose a scene-centric 3D VLMfor 3D Gaussian splat scenes that employs language- and task-aware scenerepresentations. Our approach directly embeds rich linguistic features into the3D scene representation by associating language with each Gaussian primitive,achieving early modality alignment. To process the resulting denserepresentations, we introduce a dual sparsifier that distills them intocompact, task-relevant tokens via task-guided and location-guided pathways,producing sparse, task-aware global and local scene tokens. Notably, we presentthe first Gaussian splatting-based VLM, leveraging photorealistic 3Drepresentations derived from standard RGB images, demonstrating stronggeneralization: it improves performance of prior 3D VLM five folds, inout-of-the-domain settings.</description>
      <author>example@mail.com (Anna-Maria Halacheva, Jan-Nico Zaech, Xi Wang, Danda Pani Paudel, Luc Van Gool)</author>
      <guid isPermaLink="false">2507.00886v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Component Adaptive Clustering for Generalized Category Discovery</title>
      <link>http://arxiv.org/abs/2507.01711v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE ICME 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdaGCD的聚类中心对比学习框架，用于将未标记图像分类到已知和新型类别中，无需预先知道未知类别的数量。&lt;h4&gt;背景&lt;/h4&gt;传统的分类方法通常依赖于严格的假设，如预定义类别数量，这限制了它们处理现实世界数据内在变异性和复杂性的能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些不足，本文旨在提出一种新的方法，能够自适应地处理未标记图像的分类问题。&lt;h4&gt;方法&lt;/h4&gt;AdaGCD框架结合了自适应槽位注意力（AdaSlot）机制，该机制根据数据复杂性动态确定最优槽位数量，从而无需预定义槽位计数。这种方法通过动态分配表示能力，灵活地将未标记数据聚类到已知和新型类别中。&lt;h4&gt;主要发现&lt;/h4&gt;AdaGCD通过结合自适应表示和动态槽位分配，能够捕捉实例特定和空间聚集特征，从而在开放世界场景中提高类别发现能力。&lt;h4&gt;结论&lt;/h4&gt;在公共和细粒度数据集上的广泛实验验证了该框架的有效性，强调了利用空间局部信息在未标记图像数据集中进行类别发现的优势。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为AdaGCD的聚类中心对比学习框架，用于将未标记图像分类到已知和新型类别中，无需预先知道未知类别的数量。传统的分类方法通常依赖于严格的假设，如预定义类别数量，这限制了它们处理现实世界数据内在变异性和复杂性的能力。为了解决这些不足，本文旨在提出一种新的方法，能够自适应地处理未标记图像的分类问题。AdaGCD框架结合了自适应槽位注意力（AdaSlot）机制，该机制根据数据复杂性动态确定最优槽位数量，从而无需预定义槽位计数。这种方法通过动态分配表示能力，灵活地将未标记数据聚类到已知和新型类别中。AdaGCD通过结合自适应表示和动态槽位分配，能够捕捉实例特定和空间聚集特征，从而在开放世界场景中提高类别发现能力。在公共和细粒度数据集上的广泛实验验证了该框架的有效性，强调了利用空间局部信息在未标记图像数据集中进行类别发现的优势。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generalized Category Discovery (GCD) tackles the challenging problem ofcategorizing unlabeled images into both known and novel classes within apartially labeled dataset, without prior knowledge of the number of unknowncategories. Traditional methods often rely on rigid assumptions, such aspredefining the number of classes, which limits their ability to handle theinherent variability and complexity of real-world data. To address theseshortcomings, we propose AdaGCD, a cluster-centric contrastive learningframework that incorporates Adaptive Slot Attention (AdaSlot) into the GCDframework. AdaSlot dynamically determines the optimal number of slots based ondata complexity, removing the need for predefined slot counts. This adaptivemechanism facilitates the flexible clustering of unlabeled data into known andnovel categories by dynamically allocating representational capacity. Byintegrating adaptive representation with dynamic slot allocation, our methodcaptures both instance-specific and spatially clustered features, improvingclass discovery in open-world scenarios. Extensive experiments on public andfine-grained datasets validate the effectiveness of our framework, emphasizingthe advantages of leveraging spatial local information for category discoveryin unlabeled image datasets.</description>
      <author>example@mail.com (Mingfu Yan, Jiancheng Huang, Yifan Liu, Shifeng Chen)</author>
      <guid isPermaLink="false">2507.01711v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>RaGNNarok: A Light-Weight Graph Neural Network for Enhancing Radar Point Clouds on Unmanned Ground Vehicles</title>
      <link>http://arxiv.org/abs/2507.00937v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, accepted by IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了RaGNNarok，一种基于图神经网络（GNN）的框架，用于增强雷达点云，提高低成本室内移动机器人的定位、SLAM和自主导航性能。&lt;h4&gt;背景&lt;/h4&gt;低成本室内移动机器人在家庭和商业空间中得到广泛应用，但现有的基于激光雷达和摄像头的解决方案存在性能不足、计算开销大和成本高等问题。&lt;h4&gt;目的&lt;/h4&gt;提出RaGNNarok，以解决现有雷达定位方法中点云稀疏、噪声和误检测等问题。&lt;h4&gt;方法&lt;/h4&gt;RaGNNarok是一个实时、轻量级且通用的GNN框架，能够在资源受限的设备上高效运行，无需额外的计算资源。&lt;h4&gt;主要发现&lt;/h4&gt;RaGNNarok在低成本Raspberry Pi 5上的推理时间仅为7.3毫秒，且在三个不同环境中评估结果表明其具有强可靠性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;RaGNNarok是一个鲁棒的低成本室内移动机器人解决方案，适用于定位、SLAM和自主导航等关键任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-cost indoor mobile robots have gained popularity with the increasingadoption of automation in homes and commercial spaces. However, existing lidarand camera-based solutions have limitations such as poor performance invisually obscured environments, high computational overhead for dataprocessing, and high costs for lidars. In contrast, mmWave radar sensors offera cost-effective and lightweight alternative, providing accurate rangingregardless of visibility. However, existing radar-based localization suffersfrom sparse point cloud generation, noise, and false detections. Thus, in thiswork, we introduce RaGNNarok, a real-time, lightweight, and generalizable graphneural network (GNN)-based framework to enhance radar point clouds, even incomplex and dynamic environments. With an inference time of just 7.3 ms on thelow-cost Raspberry Pi 5, RaGNNarok runs efficiently even on suchresource-constrained devices, requiring no additional computational resources.We evaluate its performance across key tasks, including localization, SLAM, andautonomous navigation, in three different environments. Our results demonstratestrong reliability and generalizability, making RaGNNarok a robust solution forlow-cost indoor mobile robots.</description>
      <author>example@mail.com (David Hunt, Shaocheng Luo, Spencer Hallyburton, Shafii Nillongo, Yi Li, Tingjun Chen, Miroslav Pajic)</author>
      <guid isPermaLink="false">2507.00937v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MILP-SAT-GNN: Yet Another Neural SAT Solver</title>
      <link>http://arxiv.org/abs/2507.01825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的方法，该方法通过利用为混合整数线性规划（MILP）开发的技术，使图神经网络（GNNs）能够解决SAT问题。&lt;h4&gt;背景&lt;/h4&gt;GNNs被应用于解决MILP问题，而本文提出的方法将k-CNF公式映射到MILP问题，并通过加权二部图编码后输入GNN进行训练和测试。&lt;h4&gt;目的&lt;/h4&gt;探索GNNs在解决SAT问题上的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;将k-CNF公式映射到MILP问题，编码为加权二部图，然后输入GNN进行训练和测试。通过理论分析，证明方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;（i）证明了方法在条款和变量重新排序下输出的稳定性；（ii）指出对于可折叠公式，标准GNNs无法总是区分可满足和不可满足实例；（iii）证明了通用逼近定理，表明使用随机节点初始化（RNI），方法可以在有限数据集上以任意精度逼近SAT求解；（iv）对于不可折叠公式，无需RNI即可达到相同的逼近保证。&lt;h4&gt;结论&lt;/h4&gt;尽管神经网络架构简单，该方法在实验中取得了有希望的结果。&lt;h4&gt;翻译&lt;/h4&gt;We propose a novel method that enables Graph Neural Networks (GNNs) to solve SAT problems by leveraging a technique developed for applying GNNs to MixedInteger Linear Programming (MILP). Specifically, k-CNF formulae are mapped into MILP problems, which are then encoded as weighted bipartite graphs and subsequently fed into a GNN for training and testing. From a theoretical perspective: (i) we establish permutation and equivalence invariance results, demonstrating that the method produces outputs that are stable under reordering of clauses and variables; (ii) we identify a theoretical limitation, showing that for a class of formulae called foldable formulae, standard GNNs cannot always distinguish satisfiable from unsatisfiable instances; (iii) we prove a universal approximation theorem, establishing that with Random Node Initialization (RNI), the method can approximate SAT solving to arbitrary precision on finite datasets, that is, the GNN becomes approximately sound and complete on such datasets. Furthermore, we show that for unfoldable formulae, the same approximation guarantee can be achieved without the need for RNI. Finally, we conduct an experimental evaluation of our approach, which show that, despite the simplicity of the neural architecture, the method achieves promising results.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We proposes a novel method that enables Graph Neural Networks (GNNs) to solveSAT problems by leveraging a technique developed for applying GNNs to MixedInteger Linear Programming (MILP). Specifically, k-CNF formulae are mapped intoMILP problems, which are then encoded as weighted bipartite graphs andsubsequently fed into a GNN for training and testing. From a theoreticalperspective: (i) we establish permutation and equivalence invariance results,demonstrating that the method produces outputs that are stable under reorderingof clauses and variables; (ii) we identify a theoretical limitation, showingthat for a class of formulae called foldable formulae, standard GNNs cannotalways distinguish satisfiable from unsatisfiable instances; (iii) we prove auniversal approximation theorem, establishing that with Random NodeInitialization (RNI), the method can approximate SAT solving to arbitraryprecision on finite datasets, that is, the GNN becomes approximately sound andcomplete on such datasets. Furthermore, we show that for unfoldable formulae,the same approximation guarantee can be achieved without the need for RNI.Finally, we conduct an experimental evaluation of our approach, which showthat, despite the simplicity of the neural architecture, the method achievespromising results.</description>
      <author>example@mail.com (Franco Alberto Cardillo, Hamza Khyari, Umberto Straccia)</author>
      <guid isPermaLink="false">2507.01825v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for VLC-based indoor Localization: Addressing Environmental Variability</title>
      <link>http://arxiv.org/abs/2507.01575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication in the IEEE VTC2025-Spring Conference, 7  pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于可见光通信的室内定位方法，通过迁移学习技术提高了定位精度、降低了能耗和计算时间，适用于工业环境。&lt;h4&gt;背景&lt;/h4&gt;在工业环境中，精确的室内定位至关重要，可见光通信（VLC）作为一种新兴解决方案，具有高精度、节能和电磁干扰小的优势。&lt;h4&gt;目的&lt;/h4&gt;针对VLC在室内定位中面临的环境变化挑战，如光照波动和障碍物，提出一种基于迁移学习的室内定位方法。&lt;h4&gt;方法&lt;/h4&gt;利用BOSCH工厂的真实世界数据，将深度神经网络（DNN）集成到迁移学习框架中，以提高定位精度。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在定位精度上提高了47%，能耗降低了32%，计算时间减少了40%，且在变化的环境条件下具有高度适应性，仅需30%的数据集即可达到相似的精度。&lt;h4&gt;结论&lt;/h4&gt;该方法是一种成本效益高、可扩展的解决方案，适用于工业4.0中的工业应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate indoor localization is crucial in industrial environments. VisibleLight Communication (VLC) has emerged as a promising solution, offering highaccuracy, energy efficiency, and minimal electromagnetic interference. However,VLC-based indoor localization faces challenges due to environmentalvariability, such as lighting fluctuations and obstacles. To address thesechallenges, we propose a Transfer Learning (TL)-based approach for VLC-basedindoor localization. Using real-world data collected at a BOSCH factory, the TLframework integrates a deep neural network (DNN) to improve localizationaccuracy by 47\%, reduce energy consumption by 32\%, and decrease computationaltime by 40\% compared to the conventional models. The proposed solution ishighly adaptable under varying environmental conditions and achieves similaraccuracy with only 30\% of the dataset, making it a cost-efficient and scalableoption for industrial applications in Industry 4.0.</description>
      <author>example@mail.com (Masood Jan, Wafa Njima, Xun Zhang, Alexander Artemenko)</author>
      <guid isPermaLink="false">2507.01575v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>SpecCLIP: Aligning and Translating Spectroscopic Measurements for Stars</title>
      <link>http://arxiv.org/abs/2507.01939v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages, 6 figures, 5 tables. To be submitted to AAS Journals.  Comments welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SpecCLIP是一个基于LLM的方法，用于扩展到恒星光谱分析，旨在通过大规模光谱数据集训练，学习到鲁棒且信息丰富的嵌入，支持多样化的下游应用。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型（LLMs）通过大规模数据集和大规模参数化改变了自然语言理解。受此启发，研究人员提出了SpecCLIP框架。&lt;h4&gt;目的&lt;/h4&gt;SpecCLIP的目标是通过在大型光谱数据集上训练基础模型，学习到鲁棒且信息丰富的嵌入，支持多样化的下游应用。&lt;h4&gt;方法&lt;/h4&gt;SpecCLIP包括在两种光谱类型（LAMOST低分辨率和Gaia XP）上预训练，然后使用CLIP框架进行对比对齐，以关联来自不同仪器的光谱。此外，还包括辅助解码器，以保留光谱特定的信息并实现光谱类型之间的翻译（预测）。&lt;h4&gt;主要发现&lt;/h4&gt;SpecCLIP模型在中等大小的标记数据集上进行微调，提高了对恒星参数估计和化学丰度测定等任务的适应性。SpecCLIP还提高了参数估计的准确性和精度，并具有相似性搜索和跨光谱预测能力，可用于异常检测。&lt;h4&gt;结论&lt;/h4&gt;对比训练的基础模型，结合光谱感知解码器，可以推进精确恒星光谱学。&lt;h4&gt;翻译&lt;/h4&gt;SpecCLIP是一种基于大型语言模型的方法，旨在将LLM启发的方法扩展到恒星光谱分析。恒星光谱，类似于结构化语言，编码了关于恒星丰富的物理和化学信息。通过在大规模光谱数据集上训练基础模型，我们的目标是学习到鲁棒且信息丰富的嵌入，以支持多样化的下游应用。作为一个概念验证，SpecCLIP包括在两种光谱类型（LAMOST低分辨率和Gaia XP）上预训练，然后使用CLIP（对比语言-图像预训练）框架进行对比对齐，该框架被调整以关联来自不同仪器的光谱。这种对齐得到了辅助解码器的补充，这些解码器保留了光谱特定的信息，并能够实现光谱类型之间的翻译（预测），这是通过最大化嵌入和输入光谱之间的互信息来实现的。结果是跨光谱框架，它实现了内在校准和在仪器之间灵活应用。我们证明了在这些模型上使用中等大小的标记数据集进行微调，提高了对恒星参数估计和化学丰度测定等任务的适应性。SpecCLIP还提高了与外部调查数据基准的参数估计的准确性和精度。此外，其相似性搜索和跨光谱预测能力为异常检测提供了潜在的可能性。我们的结果表明，与光谱感知解码器丰富的基础模型可以推进精确恒星光谱学。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, large language models (LLMs) have transformed naturallanguage understanding through vast datasets and large-scale parameterization.Inspired by this success, we present SpecCLIP, a foundation model frameworkthat extends LLM-inspired methodologies to stellar spectral analysis. Stellarspectra, akin to structured language, encode rich physical and chemicalinformation about stars. By training foundation models on large-scale spectraldatasets, our goal is to learn robust and informative embeddings that supportdiverse downstream applications. As a proof of concept, SpecCLIP involvespre-training on two spectral types--LAMOST low-resolution and Gaia XP--followedby contrastive alignment using the CLIP (Contrastive Language-ImagePre-training) framework, adapted to associate spectra from differentinstruments. This alignment is complemented by auxiliary decoders that preservespectrum-specific information and enable translation (prediction) betweenspectral types, with the former achieved by maximizing mutual informationbetween embeddings and input spectra. The result is a cross-spectrum frameworkenabling intrinsic calibration and flexible applications across instruments. Wedemonstrate that fine-tuning these models on moderate-sized labeled datasetsimproves adaptability to tasks such as stellar-parameter estimation andchemical-abundance determination. SpecCLIP also enhances the accuracy andprecision of parameter estimates benchmarked against external survey data.Additionally, its similarity search and cross-spectrum prediction capabilitiesoffer potential for anomaly detection. Our results suggest that contrastivelytrained foundation models enriched with spectrum-aware decoders can advanceprecision stellar spectroscopy.</description>
      <author>example@mail.com (Xiaosheng Zhao, Yang Huang, Guirong Xue, Xiao Kong, Jifeng Liu, Xiaoyu Tang, Timothy C. Beers, Yuan-Sen Ting, A-Li Luo)</author>
      <guid isPermaLink="false">2507.01939v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>SAILViT: Towards Robust and Generalizable Visual Backbones for MLLMs via Gradual Feature Refinement</title>
      <link>http://arxiv.org/abs/2507.01643v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  We release SAILViT, a series of versatile vision foundation models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAILViT的视觉Transformer，旨在解决多模态大型语言模型（MLLMs）在复杂多模态交互中的性能瓶颈。&lt;h4&gt;背景&lt;/h4&gt;视觉Transformer（ViTs）在建立MLLMs的视觉理解能力方面至关重要。然而，现有的ViTs在直接与LLMs进行基于连接器的协同训练时存在参数初始化冲突和模态语义差距的问题。&lt;h4&gt;目的&lt;/h4&gt;提出SAILViT，以促进MLLMs突破复杂多模态交互中的性能瓶颈。&lt;h4&gt;方法&lt;/h4&gt;SAILViT通过逐步特征学习和特征细化实现粗到细粒度的特征对齐和世界知识融合，更好地满足目标训练需求。进行了全面的实证分析，以确认SAILViT在不同维度上的强大鲁棒性和泛化能力，包括参数大小、模型架构、训练策略和数据规模。&lt;h4&gt;主要发现&lt;/h4&gt;配备SAILViT的现有MLLMs在OpenCompass基准测试中，在广泛的下游任务上显示出显著且一致的性能提升。&lt;h4&gt;结论&lt;/h4&gt;SAILViT系列模型在https://huggingface.co/BytedanceDouyinContent上发布。&lt;h4&gt;翻译&lt;/h4&gt;Vision Transformers (ViTs) are essential as foundation backbones in establishing the visual comprehension capabilities of Multimodal Large Language Models (MLLMs). Although most ViTs achieve impressive performance through image-text pair-based contrastive learning or self-supervised mechanisms, they struggle to engage in connector-based co-training directly with LLMs due to potential parameter initialization conflicts and modality semantic gaps. To address the above challenges, this paper proposes SAILViT, a gradual feature learning-enhanced ViT for facilitating MLLMs to break through performance bottlenecks in complex multimodal interactions. SAILViT achieves coarse-to-fine-grained feature alignment and world knowledge infusion with gradual feature refinement, which better serves target training demands. We perform thorough empirical analyses to confirm the powerful robustness and generalizability of SAILViT across different dimensions, including parameter sizes, model architectures, training strategies, and data scales. Equipped with SAILViT, existing MLLMs show significant and consistent performance improvements on the OpenCompass benchmark across extensive downstream tasks. SAILViT series models are released at https://huggingface.co/BytedanceDouyinContent.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Transformers (ViTs) are essential as foundation backbones inestablishing the visual comprehension capabilities of Multimodal Large LanguageModels (MLLMs). Although most ViTs achieve impressive performance throughimage-text pair-based contrastive learning or self-supervised mechanisms, theystruggle to engage in connector-based co-training directly with LLMs due topotential parameter initialization conflicts and modality semantic gaps. Toaddress the above challenges, this paper proposes SAILViT, a gradual featurelearning-enhanced ViT for facilitating MLLMs to break through performancebottlenecks in complex multimodal interactions. SAILViT achievescoarse-to-fine-grained feature alignment and world knowledge infusion withgradual feature refinement, which better serves target training demands. Weperform thorough empirical analyses to confirm the powerful robustness andgeneralizability of SAILViT across different dimensions, including parametersizes, model architectures, training strategies, and data scales. Equipped withSAILViT, existing MLLMs show significant and consistent performanceimprovements on the OpenCompass benchmark across extensive downstream tasks.SAILViT series models are released athttps://huggingface.co/BytedanceDouyinContent.</description>
      <author>example@mail.com (Weijie Yin, Dingkang Yang, Hongyuan Dong, Zijian Kang, Jiacong Wang, Xiao Liang, Chao Feng, Jiao Ran)</author>
      <guid isPermaLink="false">2507.01643v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>An in depth look at the Procrustes-Wasserstein distance: properties and barycenters</title>
      <link>http://arxiv.org/abs/2507.00894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了Procrustes-Wasserstein (PW) 距离在点云对齐和比较中的应用，并提出了一种新的方法来估计点云的代表形状。&lt;h4&gt;背景&lt;/h4&gt;由于Procrustes-Wasserstein (PW) 距离对刚体变换（如旋转和反射）的不变性，它被引入文献作为最优传输（OT）距离，是一种替代Wasserstein距离的方法，更适合点云对齐和比较的任务。&lt;h4&gt;目的&lt;/h4&gt;构建一个离散概率测度空间，并展示在空间上PW实际上是一种距离；扩展PW框架，讨论和测试多种初始化策略；引入PW重心的概念，并详细描述一种从数据中估计它的算法。&lt;h4&gt;方法&lt;/h4&gt;建立离散概率测度空间，提出新的初始化策略，引入PW重心概念并设计估计算法。&lt;h4&gt;主要发现&lt;/h4&gt;提出的新方法在需要精确对齐和形状保真度的情况下，与现有的OT方法相比，表现更优；在考古学背景下展示了PW重心的有用性。&lt;h4&gt;结论&lt;/h4&gt;Procrustes-Wasserstein (PW) 距离在2D和3D点云分析中具有潜力，可以提升机器学习和计算几何应用的效果。&lt;h4&gt;翻译&lt;/h4&gt;由于其对刚性变换（如旋转和反射）的不变性，Procrustes-Wasserstein (PW) 被文献中引入作为最优传输（OT）距离，是Wasserstein距离的一种替代方案，更适合点云的对齐和比较。考虑到这一应用，我们仔细构建了一个离散概率测度空间，并显示在该空间上PW实际上是一种距离。已经存在解决PW问题的算法，但是通过讨论和测试了多种初始化策略，我们扩展了PW框架。然后我们引入了PW重心的概念，并详细描述了一种从数据中估计它的算法。结果是计算点云集合中代表性形状的新方法。我们将我们的方法与现有的OT方法进行了基准测试，证明了在需要精确对齐和形状保真度的情况下，我们的方法表现更优。我们最终展示了在考古学背景下PW重心的有用性。我们的结果突出了PW在提升2D和3D点云分析，为机器学习和计算几何应用带来潜力的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to its invariance to rigid transformations such as rotations andreflections, Procrustes-Wasserstein (PW) was introduced in the literature as anoptimal transport (OT) distance, alternative to Wasserstein and more suited totasks such as the alignment and comparison of point clouds. Having thatapplication in mind, we carefully build a space of discrete probabilitymeasures and show that over that space PW actually is a distance. Algorithms tosolve the PW problems already exist, however we extend the PW framework bydiscussing and testing several initialization strategies. We then introduce thenotion of PW barycenter and detail an algorithm to estimate it from the data.The result is a new method to compute representative shapes from a collectionof point clouds. We benchmark our method against existing OT approaches,demonstrating superior performance in scenarios requiring precise alignment andshape preservation. We finally show the usefulness of the PW barycenters in anarchaeological context. Our results highlight the potential of PW in boosting2D and 3D point cloud analysis for machine learning and computational geometryapplications.</description>
      <author>example@mail.com (Davide Adamo, Marco Corneli, Manon Vuillien, Emmanuelle Vila)</author>
      <guid isPermaLink="false">2507.00894v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Embedding-based Retrieval in Multimodal Content Moderation</title>
      <link>http://arxiv.org/abs/2507.01066v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Camera ready for SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于嵌入的检索（EBR）方法，用于补充传统分类方法，以应对短视频平台内容审核中的快速和成本效益问题。&lt;h4&gt;背景&lt;/h4&gt;视频理解在短视频平台内容审核中起关键作用，但传统的分类方法在需要快速响应和成本效益的场景中存在困难。&lt;h4&gt;目的&lt;/h4&gt;旨在提高内容审核的效率和效果，特别是在趋势适应和紧急升级等场景中。&lt;h4&gt;方法&lt;/h4&gt;采用监督对比学习（SCL）框架训练一系列基础嵌入模型，包括单模态和多模态架构，并设计了一个基于嵌入的视频检索系统。&lt;h4&gt;主要发现&lt;/h4&gt;EBR在25个多样化的新兴趋势上的离线实验中，将ROC-AUC从0.85提升到0.99，PR-AUC从0.35提升到0.95。在线实验显示，EBR提高了行动率10.32%，并降低了超过80%的运营成本。&lt;h4&gt;结论&lt;/h4&gt;EBR方法在提高内容审核效率和降低成本方面表现优异，同时相比基于分类的解决方案，增强了可解释性和灵活性。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces an Embedding-Based Retrieval (EBR) method designed to complement traditional classification approaches for content moderation on shortvideo platforms, aiming to improve efficiency and cost-effectiveness in scenarios requiring rapid responses and cost savings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3726302.3731945&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding plays a fundamental role for content moderation on shortvideo platforms, enabling the detection of inappropriate content. Whileclassification remains the dominant approach for content moderation, it oftenstruggles in scenarios requiring rapid and cost-efficient responses, such astrend adaptation and urgent escalations. To address this issue, we introduce anEmbedding-Based Retrieval (EBR) method designed to complement traditionalclassification approaches. We first leverage a Supervised Contrastive Learning(SCL) framework to train a suite of foundation embedding models, including bothsingle-modal and multi-modal architectures. Our models demonstrate superiorperformance over established contrastive learning methods such as CLIP andMoCo. Building on these embedding models, we design and implement theembedding-based retrieval system that integrates embedding generation and videoretrieval to enable efficient and effective trend handling. Comprehensiveoffline experiments on 25 diverse emerging trends show that EBR improvesROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further onlineexperiments reveal that EBR increases action rates by 10.32% and reducesoperational costs by over 80%, while also enhancing interpretability andflexibility compared to classification-based solutions.</description>
      <author>example@mail.com (Hanzhong Liang, Jinghao Shi, Xiang Shen, Zixuan Wang, Vera Wen, Ardalan Mehrani, Zhiqian Chen, Yifan Wu, Zhixin Zhang)</author>
      <guid isPermaLink="false">2507.01066v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Clinical NLP with Attention-Based Deep Learning for Multi-Disease Prediction</title>
      <link>http://arxiv.org/abs/2507.01437v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对电子健康记录文本的非结构化和高维语义复杂性挑战，提出了一种基于注意力机制的深度学习方法，用于统一的信息提取和多标签疾病预测。&lt;h4&gt;背景&lt;/h4&gt;电子健康记录文本具有非结构化和高维语义复杂性，给信息提取和疾病预测带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效处理电子健康记录文本并实现多标签疾病预测的方法。&lt;h4&gt;方法&lt;/h4&gt;在MIMIC-IV数据集上，使用基于Transformer的架构进行临床文本的表示学习。采用多层自注意力机制来捕捉关键医疗实体及其上下文关系，并应用基于Sigmoid的多标签分类器进行疾病标签预测。模型还包含一个上下文感知语义对齐机制，以增强其在典型医疗场景下的表示能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法在多个性能指标上均优于现有代表性方法。模型在不同数据规模、干扰水平和模型深度配置下均表现出强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;本研究开发的方法为处理现实世界临床文本提供了一个高效的算法基础，对多标签医疗文本建模任务具有实际意义。&lt;h4&gt;翻译&lt;/h4&gt;本文针对电子健康记录文本的非结构化和高维语义复杂性挑战，提出了一种基于注意力机制的深度学习方法，用于统一的信息提取和多标签疾病预测。研究在MIMIC-IV数据集上进行，使用基于Transformer的架构进行临床文本的表示学习。采用多层自注意力机制来捕捉关键医疗实体及其上下文关系，并应用基于Sigmoid的多标签分类器进行疾病标签预测。模型还包含一个上下文感知语义对齐机制，以增强其在典型医疗场景下的表示能力。实验结果表明，所提出的方法在多个性能指标上均优于现有代表性方法。模型在不同数据规模、干扰水平和模型深度配置下均表现出强大的泛化能力。本研究开发的方法为处理现实世界临床文本提供了一个高效的算法基础，对多标签医疗文本建模任务具有实际意义。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the challenges posed by the unstructured nature andhigh-dimensional semantic complexity of electronic health record texts. A deeplearning method based on attention mechanisms is proposed to achieve unifiedmodeling for information extraction and multi-label disease prediction. Thestudy is conducted on the MIMIC-IV dataset. A Transformer-based architecture isused to perform representation learning over clinical text. Multi-layerself-attention mechanisms are employed to capture key medical entities andtheir contextual relationships. A Sigmoid-based multi-label classifier is thenapplied to predict multiple disease labels. The model incorporates acontext-aware semantic alignment mechanism, enhancing its representationalcapacity in typical medical scenarios such as label co-occurrence and sparseinformation. To comprehensively evaluate model performance, a series ofexperiments were conducted, including baseline comparisons, hyperparametersensitivity analysis, data perturbation studies, and noise injection tests.Results demonstrate that the proposed method consistently outperformsrepresentative existing approaches across multiple performance metrics. Themodel maintains strong generalization under varying data scales, interferencelevels, and model depth configurations. The framework developed in this studyoffers an efficient algorithmic foundation for processing real-world clinicaltexts and presents practical significance for multi-label medical text modelingtasks.</description>
      <author>example@mail.com (Ting Xu, Xiaoxiao Deng, Xiandong Meng, Haifeng Yang, Yan Wu)</author>
      <guid isPermaLink="false">2507.01437v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>How Weight Resampling and Optimizers Shape the Dynamics of Continual Learning and Forgetting in Neural Networks</title>
      <link>http://arxiv.org/abs/2507.01559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文详细研究了在持续学习等具有挑战性的设置中，卷积神经网络在训练过程中学习和遗忘的规律。实验表明，经过zapping（在神经网络最后一层重新采样权重）训练的模型在新领域迁移时能更快地恢复。&lt;h4&gt;背景&lt;/h4&gt;持续学习领域的研究表明，在神经网络最后一层重新采样权重（zapping）可以带来有益的效果，但其背后的机制尚不明确。&lt;h4&gt;目的&lt;/h4&gt;探究在持续学习和少样本迁移学习等困难设置中，卷积神经网络的学习和遗忘模式。&lt;h4&gt;方法&lt;/h4&gt;通过实验测量了经过zapping训练的模型在新领域迁移时的恢复速度，以及在多任务设置中，每个单独任务受持续学习的影响。&lt;h4&gt;主要发现&lt;/h4&gt;1. 经过zapping训练的模型在新领域迁移时恢复更快；2. 优化器的选择也会深刻影响学习和遗忘的动态，导致在模型按顺序迁移学习时出现复杂的学习/遗忘协同/干扰模式。&lt;h4&gt;结论&lt;/h4&gt;zapping以及优化器的选择对卷积神经网络在持续学习中的学习和遗忘动态有重要影响。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent work in continual learning has highlighted the beneficial effect ofresampling weights in the last layer of a neural network (``zapping"). Althoughempirical results demonstrate the effectiveness of this approach, theunderlying mechanisms that drive these improvements remain unclear. In thiswork, we investigate in detail the pattern of learning and forgetting that takeplace inside a convolutional neural network when trained in challengingsettings such as continual learning and few-shot transfer learning, withhandwritten characters and natural images. Our experiments show that modelsthat have undergone zapping during training more quickly recover from the shockof transferring to a new domain. Furthermore, to better observe the effect ofcontinual learning in a multi-task setting we measure how each individual taskis affected. This shows that, not only zapping, but the choice of optimizer canalso deeply affect the dynamics of learning and forgetting, causing complexpatterns of synergy/interference between tasks to emerge when the model learnssequentially at transfer time.</description>
      <author>example@mail.com (Lapo Frati, Neil Traft, Jeff Clune, Nick Cheney)</author>
      <guid isPermaLink="false">2507.01559v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>BEV-VAE: Multi-view Image Generation with Spatial Consistency for Autonomous Driving</title>
      <link>http://arxiv.org/abs/2507.00707v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为BEV-VAE的算法，用于在自动驾驶中进行多视角图像生成，以实现跨摄像头视角的一致3D场景理解。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常将多视角图像生成视为2D图像集生成任务，缺乏显式的3D建模。&lt;h4&gt;目的&lt;/h4&gt;强调结构化表示对于场景生成的重要性，尤其是在自动驾驶应用中。&lt;h4&gt;方法&lt;/h4&gt;BEV-VAE首先训练一个用于紧凑且统一BEV潜在空间的多视角图像变分自编码器，然后使用潜在扩散变换器生成场景。&lt;h4&gt;主要发现&lt;/h4&gt;BEV-VAE支持任意视角生成，并可选择3D布局。在nuScenes和Argoverse 2（AV2）上的实验表明，该算法在3D一致重建和生成方面都表现出强大的性能。&lt;h4&gt;结论&lt;/h4&gt;BEV-VAE是一种有效的多视角图像生成方法，适用于自动驾驶场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-view image generation in autonomous driving demands consistent 3D sceneunderstanding across camera views. Most existing methods treat this problem asa 2D image set generation task, lacking explicit 3D modeling. However, we arguethat a structured representation is crucial for scene generation, especiallyfor autonomous driving applications. This paper proposes BEV-VAE for consistentand controllable view synthesis. BEV-VAE first trains a multi-view imagevariational autoencoder for a compact and unified BEV latent space and thengenerates the scene with a latent diffusion transformer. BEV-VAE supportsarbitrary view generation given camera configurations, and optionally 3Dlayouts. Experiments on nuScenes and Argoverse 2 (AV2) show strong performancein both 3D consistent reconstruction and generation. The code is available at:https://github.com/Czm369/bev-vae.</description>
      <author>example@mail.com (Zeming Chen, Hang Zhao)</author>
      <guid isPermaLink="false">2507.00707v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Automated Classification of Volcanic Earthquakes Using Transformer Encoders: Insights into Data Quality and Model Interpretability</title>
      <link>http://arxiv.org/abs/2507.01260v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to Seismological Research Letters&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究开发了一种基于Transformer编码器的深度学习模型，用于更客观和高效地对地震类型进行分类，以阐明火山地震与火山活动之间的关系。&lt;h4&gt;背景&lt;/h4&gt;传统的地震类型分类方法依赖于主观的人类判断，需要大量的时间和精力。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一问题，研究旨在开发一个更客观和高效的地震类型分类模型。&lt;h4&gt;方法&lt;/h4&gt;研究开发了一个深度学习模型，并在浅间山多样的地震活动上进行了测试，该模型在F1分数上优于传统的基于CNN的方法。此外，还分析了注意力权重可视化，并探讨了数据选择和增强的重要性。&lt;h4&gt;主要发现&lt;/h4&gt;模型在火山构造地震、低频地震和噪声的分类上取得了高F1分数。注意力权重可视化显示模型关注关键波形特征，与人类专家类似。数据不一致性影响了分类准确性和注意力权重分布。数据选择和增强的实验表明了平衡数据质量和多样性的重要性。&lt;h4&gt;结论&lt;/h4&gt;Transformer模型在自动火山地震分类方面具有潜力，尤其是在提高效率和可解释性方面。该研究为理解浅间山的地震活动提供了一个稳健的框架，并为其他火山区域提供了迁移学习的机会，为提高火山危害评估和灾害减轻策略铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;This study developed a deep learning model using a transformer encoder for more objective and efficient earthquake type classification, in order to elucidate the relationship between volcanic earthquakes and volcanic activity. Traditional methods for earthquake type classification rely on subjective human judgment, which requires considerable time and effort. To address this issue, the research aimed to develop a more objective and efficient earthquake type classification model. A deep learning model was developed and tested on the diverse seismic activity of Mount Asama, and the model achieved higher F1 scores (0.930 for volcano tectonic, 0.931 for low-frequency earthquakes, and 0.980 for noise) than a conventional CNN-based method. In addition, attention weight visualizations were analyzed, and it was found that the model focuses on key waveform features in a manner similar to human experts. However, inconsistencies in the training data, such as ambiguously labeled B-type events with S-waves, were found to influence classification accuracy and attention weight distributions. Experiments addressing data selection and augmentation demonstrated the importance of balancing data quality and diversity. In addition, stations within 3 km of the crater played an important role in improving model performance and interpretability. These findings highlight the potential of Transformer-based models for automated volcanic earthquake classification, particularly in improving efficiency and interpretability. This research provides a robust framework for understanding seismic activity at Mount Asama and offers opportunities for transfer learning to other volcanic regions, paving the way for enhanced volcanic hazard assessments and disaster mitigation strategies.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Precisely classifying earthquake types is crucial for elucidating therelationship between volcanic earthquakes and volcanic activity. However,traditional methods rely on subjective human judgment, which requiresconsiderable time and effort. To address this issue, we developed a deeplearning model using a transformer encoder for a more objective and efficientclassification. Tested on Mount Asama's diverse seismic activity, our modelachieved high F1 scores (0.930 for volcano tectonic, 0.931 for low-frequencyearthquakes, and 0.980 for noise), superior to a conventional CNN-based method.To enhance interpretability, attention weight visualizations were analyzed,revealing that the model focuses on key waveform features similarly to humanexperts. However, inconsistencies in training data, such as ambiguously labeledB-type events with S-waves, were found to influence classification accuracy andattention weight distributions. Experiments addressing data selection andaugmentation demonstrated the importance of balancing data quality anddiversity. In addition, stations within 3 km of the crater played an importantrole in improving model performance and interpretability. These findingshighlight the potential of Transformer-based models for automated volcanicearthquake classification, particularly in improving efficiency andinterpretability. By addressing challenges such as data imbalance andsubjective labeling, our approach provides a robust framework for understandingseismic activity at Mount Asama. Moreover, this framework offers opportunitiesfor transfer learning to other volcanic regions, paving the way for enhancedvolcanic hazard assessments and disaster mitigation strategies.</description>
      <author>example@mail.com (Y. Suzuki, Y. Yukutake, T. Ohminato, M. Yamasaki, Ahyi Kim)</author>
      <guid isPermaLink="false">2507.01260v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding</title>
      <link>http://arxiv.org/abs/2507.00416v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Vision-Language-Action (VLA)的模型，该模型能够使通用机器人具备感知、推理和在世界中行动的能力。通过引入一个可即插即用的模块，该模型能够将3D几何特征隐式地注入VLA模型中，从而提高模型的空间理解能力。&lt;h4&gt;背景&lt;/h4&gt;VLA模型通常基于预训练的Vision-Language Models (VLMs)，这些模型在语义理解方面表现出色，但由于主要在2D图像-文本对上进行训练，缺乏精确的空间理解能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决VLMs缺乏精确空间理解能力的问题，本文旨在通过引入3D几何特征来提高VLA模型的空间理解能力。&lt;h4&gt;方法&lt;/h4&gt;本文设计了一个模块，该模块利用现成的视觉几何基础模型，将3D几何特征隐式地注入VLA模型中。同时，设计了五个需要精确空间理解能力的任务来验证该方法的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的评估，发现该方法显著提高了在多种场景下最先进的VLA模型的表现。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效提高VLA模型的空间理解能力，为通用机器人的发展提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language-Action (VLA) models have emerged as a promising framework forenabling generalist robots capable of perceiving, reasoning, and acting in thereal world. These models usually build upon pretrained Vision-Language Models(VLMs), which excel at semantic understanding due to large-scale textpretraining. However, VLMs typically lack precise spatial understandingcapabilities, as they are primarily tuned on 2D image-text pairs without 3Dsupervision. To address this limitation, recent approaches have incorporatedexplicit 3D inputs such as point clouds or depth maps, but this necessitatesadditional depth sensors or defective estimation. In contrast, our workintroduces a plug-and-play module that implicitly injects 3D geometry featuresinto VLA models by leveraging an off-the-shelf visual geometry foundationmodels. We design five spatially challenging tasks that require precise spatialunderstanding ability to validate effectiveness of our method. Extensiveevaluations show that our method significantly improves the performance ofstate-of-the-art VLA models across diverse scenarios.</description>
      <author>example@mail.com (Tao Lin, Gen Li, Yilei Zhong, Yanwen Zou, Bo Zhao)</author>
      <guid isPermaLink="false">2507.00416v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Phase Transition in Nonparametric Minimax Rates for Covariate Shifts on Approximate Manifolds</title>
      <link>http://arxiv.org/abs/2507.00889v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  42 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在协变量偏移下具有结构数据的非参数回归，其中少量标记的目标数据由大量标记的源数据集补充。文章提出了新的方法，利用源数据集的大小和目标数据的结构特性，在协变量偏移下估计回归函数。&lt;h4&gt;背景&lt;/h4&gt;在许多实际场景中，目标域中的协变量位于源数据支持空间内的低维流形附近，例如个性化手写数字（目标）在一个大型、高维图像库（源）中。由于在这些设置中可能不存在密度比，标准的迁移学习技术往往无法利用这种结构。&lt;h4&gt;目的&lt;/h4&gt;开发新的方法，以利用源数据集的大小和目标数据的结构特性，在协变量偏移下估计回归函数。&lt;h4&gt;方法&lt;/h4&gt;提出了新的最小-最大速率，在协变量偏移下估计一个在一般Hölder类中的回归函数，假设目标分布位于源的一个光滑子流形附近。同时，提出了一个局部多项式回归估计器，在相变边界两侧都达到最优速率。另外，还构建了一个完全自适应的程序，能够适应未知的平滑性和内在维度，并达到接近最优的速率。&lt;h4&gt;主要发现&lt;/h4&gt;确定了由到流形的距离、源和目标样本大小、函数平滑性以及内在维度与外生维度之间的相变。&lt;h4&gt;结论&lt;/h4&gt;本文的结果统一并扩展了协变量偏移、流形学习和自适应非参数推断中的关键主题。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了在协变量偏移下具有结构数据的非参数回归，其中少量标记的目标数据由大量标记的源数据集补充。在许多现实世界的场景中，目标域中的协变量位于源数据支持空间内的低维流形附近，例如个性化手写数字（目标）在一个大型、高维图像库（源）中。由于在这些设置中可能不存在密度比，标准的迁移学习技术往往无法利用这种结构。因此，需要开发利用源数据集大小和目标数据结构特性的方法。受此启发，我们建立了新的最小-最大速率，在协变量偏移下估计一个在一般Hölder类中的回归函数，假设目标分布位于源的一个光滑子流形附近。一般平滑性有助于在目标函数高度规则时减少维度的诅咒，而近似流形可以捕捉现实、有噪声的数据。我们确定了由到流形的距离、源和目标样本大小、函数平滑性以及内在维度与外生维度之间的相变。我们提出了一种局部多项式回归估计器，在相变边界两侧都达到最优速率。此外，我们还构建了一个完全自适应的程序，能够适应未知的平滑性和内在维度，并达到接近最优的速率。我们的结果统一并扩展了协变量偏移、流形学习和自适应非参数推断中的关键主题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study nonparametric regression under covariate shift with structured data,where a small amount of labeled target data is supplemented by a large labeledsource dataset. In many real-world settings, the covariates in the targetdomain lie near a low-dimensional manifold within the support of the source,e.g., personalized handwritten digits (target) within a large, high-dimensionalimage repository (source). Since density ratios may not exist in thesesettings, standard transfer learning techniques often fail to leverage suchstructure. This necessitates the development of methods that exploit both thesize of the source dataset and the structured nature of the target.  Motivated by this, we establish new minimax rates under covariate shift forestimating a regression function in a general H\"older class, assuming thetarget distribution lies near -- but not exactly on -- a smooth submanifold ofthe source. General smoothness helps reduce the curse of dimensionality whenthe target function is highly regular, while approximate manifolds capturerealistic, noisy data. We identify a phase transition in the minimax rate ofestimation governed by the distance to the manifold, source and target samplesizes, function smoothness, and intrinsic versus ambient dimensions. We proposea local polynomial regression estimator that achieves optimal rates on eitherside of the phase transition boundary. Additionally, we construct a fullyadaptive procedure that adjusts to unknown smoothness and intrinsic dimension,and attains nearly optimal rates. Our results unify and extend key threads incovariate shift, manifold learning, and adaptive nonparametric inference.</description>
      <author>example@mail.com (Yuyao Wang, Nabarun Deb, Debarghya Mukherjee)</author>
      <guid isPermaLink="false">2507.00889v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>A Survey on Vision-Language-Action Models: An Action Tokenization Perspective</title>
      <link>http://arxiv.org/abs/2507.01925v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  70 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了视觉-语言-动作（VLA）模型在多模态理解、推理和生成方面的研究进展，探讨了VLA模型的设计和实现方法。&lt;h4&gt;背景&lt;/h4&gt;视觉和语言基础模型在多模态理解、推理和生成方面取得了显著进展，推动了将这种智能扩展到物理世界的努力，从而促进了视觉-语言-动作（VLA）模型的发展。&lt;h4&gt;目的&lt;/h4&gt;对现有的VLA模型进行分类和解释，通过动作标记化的视角分析现有研究，提炼不同类型动作标记的优点和局限性，并识别改进领域。&lt;h4&gt;方法&lt;/h4&gt;通过系统性的审查和分析，对VLA模型的整体发展进行了综合概述，突出了尚未充分探索但具有前景的方向，并为未来的研究提供了指导。&lt;h4&gt;主要发现&lt;/h4&gt;发现VLA模型可以统一在单个框架下，即通过一系列VLA模块处理视觉和语言输入，生成一系列动作标记，这些标记逐渐编码更具体和可执行的信息。VLA模型的主要设计选择在于动作标记的制定方式，可以分为语言描述、代码、适应性、轨迹、目标状态、潜在表示、原始动作和推理等。&lt;h4&gt;结论&lt;/h4&gt;VLA模型的研究仍有待深入，缺乏对动作标记的全面理解，这阻碍了VLA模型的有效发展和模糊了未来的研究方向。本文旨在推动该领域向通用智能迈进。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉和语言基础模型在多模态理解、推理和生成方面的显著进展激发了将此类智能扩展到物理世界的努力，推动了视觉-语言-动作（VLA）模型的发展。尽管方法似乎多样，但我们观察到当前的VLA模型可以被统一在一个框架之下：视觉和语言输入由一系列VLA模块处理，生成一系列动作标记，这些标记逐步编码更具体和可执行的信息，最终生成可执行的动作。我们进一步确定，区分VLA模型的主要设计选择在于动作标记的制定方式，可以分为语言描述、代码、适应性、轨迹、目标状态、潜在表示、原始动作和推理等。然而，对动作标记的全面理解仍存在不足，这严重阻碍了有效的VLA发展并模糊了未来的研究方向。因此，本综述旨在通过动作标记化的视角对现有的VLA研究进行分类和解释，提炼每种标记类型的长处和不足，并确定改进的领域。通过这种系统性的审查和分析，我们提供了一个对VLA模型更广泛发展的综合看法，突出了尚未充分探索但具有前景的方向，并为未来的研究提供了指导，希望将这一领域推向通用智能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The remarkable advancements of vision and language foundation models inmultimodal understanding, reasoning, and generation has sparked growing effortsto extend such intelligence to the physical world, fueling the flourishing ofvision-language-action (VLA) models. Despite seemingly diverse approaches, weobserve that current VLA models can be unified under a single framework: visionand language inputs are processed by a series of VLA modules, producing a chainof \textit{action tokens} that progressively encode more grounded andactionable information, ultimately generating executable actions. We furtherdetermine that the primary design choice distinguishing VLA models lies in howaction tokens are formulated, which can be categorized into languagedescription, code, affordance, trajectory, goal state, latent representation,raw action, and reasoning. However, there remains a lack of comprehensiveunderstanding regarding action tokens, significantly impeding effective VLAdevelopment and obscuring future directions. Therefore, this survey aims tocategorize and interpret existing VLA research through the lens of actiontokenization, distill the strengths and limitations of each token type, andidentify areas for improvement. Through this systematic review and analysis, weoffer a synthesized outlook on the broader evolution of VLA models, highlightunderexplored yet promising directions, and contribute guidance for futureresearch, hoping to bring the field closer to general-purpose intelligence.</description>
      <author>example@mail.com (Yifan Zhong, Fengshuo Bai, Shaofei Cai, Xuchuan Huang, Zhang Chen, Xiaowei Zhang, Yuanfei Wang, Shaoyang Guo, Tianrui Guan, Ka Nam Lui, Zhiquan Qi, Yitao Liang, Yuanpei Chen, Yaodong Yang)</author>
      <guid isPermaLink="false">2507.01925v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>DARTS: A Dual-View Attack Framework for Targeted Manipulation in Federated Sequential Recommendation</title>
      <link>http://arxiv.org/abs/2507.01383v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages. arXiv admin note: substantial text overlap with  arXiv:2409.07500; text overlap with arXiv:2212.05399 by other authors&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了联邦推荐（FedRec）系统中的针对性攻击问题，并提出了一种名为DV-FSR的新攻击框架，同时引入了针对针对性攻击的防御机制。&lt;h4&gt;背景&lt;/h4&gt;联邦推荐通过分散训练个性化模型保护用户隐私，但该架构易受针对性攻击。目前的研究主要关注FedRec系统中的针对性攻击，但忽略了推荐模型差异鲁棒性的问题。&lt;h4&gt;目的&lt;/h4&gt;旨在研究Federated Sequential Recommendation（FSR）中的针对性攻击，并提出有效的攻击和防御方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为DV-FSR的攻击框架，该框架结合了基于采样的显式策略和基于对比学习的隐式梯度策略，并引入了针对FSR针对性攻击的防御机制。&lt;h4&gt;主要发现&lt;/h4&gt;现有的针对性攻击方法在FSR任务中效果有限，而提出的DV-FSR攻击框架能够有效实施协调攻击。&lt;h4&gt;结论&lt;/h4&gt;通过大量实验验证了所提出方法在代表性序列模型上的有效性，并公开了相关代码。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates targeted attacks in the Federated Recommendation (FedRec) system and proposes a novel attack framework named DV-FSR, along with a specific defense mechanism tailored for targeted attacks in FSR. The proposed DV-FSR attack framework uniquely combines a sampling-based explicit strategy with a contrastive learning-based implicit gradient strategy to orchestrate a coordinated attack. Additionally, a specific defense mechanism is introduced for targeted attacks in FSR, aiming to evaluate the mitigation effects of the proposed attack method. Extensive experiments validate the effectiveness of the proposed approach on representative sequential models, and the codes are publicly available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated recommendation (FedRec) preserves user privacy by enablingdecentralized training of personalized models, but this architecture isinherently vulnerable to adversarial attacks. Significant research has beenconducted on targeted attacks in FedRec systems, motivated by commercial andsocial influence considerations. However, much of this work has largelyoverlooked the differential robustness of recommendation models. Moreover, ourempirical findings indicate that existing targeted attack methods achieve onlylimited effectiveness in Federated Sequential Recommendation(FSR) tasks. Drivenby these observations, we focus on investigating targeted attacks in FSR andpropose a novel dualview attack framework, named DV-FSR. This attack methoduniquely combines a sampling-based explicit strategy with a contrastivelearning-based implicit gradient strategy to orchestrate a coordinated attack.Additionally, we introduce a specific defense mechanism tailored for targetedattacks in FSR, aiming to evaluate the mitigation effects of the attack methodwe proposed. Extensive experiments validate the effectiveness of our proposedapproach on representative sequential models. Our codes are publicly available.</description>
      <author>example@mail.com (Qitao Qin, Yucong Luo, Zhibo Chu)</author>
      <guid isPermaLink="false">2507.01383v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Cage-Based Deformation for Transferable and Undefendable Point Cloud Attack</title>
      <link>http://arxiv.org/abs/2507.00690v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于笼子的变形框架CageAttack，用于生成自然对抗性点云，旨在解决现有方法中对抗性攻击对几何约束的限制和变形的不自然性。&lt;h4&gt;背景&lt;/h4&gt;对抗性攻击在点云上通常需要严格的几何约束以保持合理性，但这种约束限制了攻击的可迁移性和不可防御性。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，以生成既自然又具有攻击性的点云，同时保持其合理性。&lt;h4&gt;方法&lt;/h4&gt;CageAttack首先在目标对象周围构建一个笼子，提供一个结构化的基础进行平滑、自然的外观变形。然后对笼子顶点进行扰动，这些扰动无缝地传播到点云上，确保生成的变形与对象内在相关并保持合理性。&lt;h4&gt;主要发现&lt;/h4&gt;在七个3D深度神经网络分类器上的大量实验表明，CageAttack在可迁移性、不可防御性和合理性之间取得了优越的平衡，优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;CageAttack是一种有效的生成自然对抗性点云的方法，其性能优于现有技术。&lt;h4&gt;翻译&lt;/h4&gt;Adversarial attacks on point clouds often impose strict geometric constraints to preserve plausibility; however, such constraints inherently limit transferability and undefendability. While deformation offers an alternative, existing unstructured approaches may introduce unnatural distortions, making adversarial point clouds conspicuous and undermining their plausibility. In this paper, we propose CageAttack, a cage-based deformation framework that produces natural adversarial point clouds. It first constructs a cage around the target object, providing a structured basis for smooth, natural-looking deformation. Perturbations are then applied to the cage vertices, which seamlessly propagate to the point cloud, ensuring that the resulting deformations remain intrinsic to the object and preserve plausibility. Extensive experiments on seven 3D deep neural network classifiers across three datasets show that CageAttack achieves a superior balance among transferability, undefendability, and plausibility, outperforming state-of-the-art methods. Codes will be made public upon acceptance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adversarial attacks on point clouds often impose strict geometric constraintsto preserve plausibility; however, such constraints inherently limittransferability and undefendability. While deformation offers an alternative,existing unstructured approaches may introduce unnatural distortions, makingadversarial point clouds conspicuous and undermining their plausibility. Inthis paper, we propose CageAttack, a cage-based deformation framework thatproduces natural adversarial point clouds. It first constructs a cage aroundthe target object, providing a structured basis for smooth, natural-lookingdeformation. Perturbations are then applied to the cage vertices, whichseamlessly propagate to the point cloud, ensuring that the resultingdeformations remain intrinsic to the object and preserve plausibility.Extensive experiments on seven 3D deep neural network classifiers across threedatasets show that CageAttack achieves a superior balance amongtransferability, undefendability, and plausibility, outperformingstate-of-the-art methods. Codes will be made public upon acceptance.</description>
      <author>example@mail.com (Keke Tang, Ziyong Du, Weilong Peng, Xiaofei Wang, Peican Zhu, Ligang Liu, Zhihong Tian)</author>
      <guid isPermaLink="false">2507.00690v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Natural language processing for African languages</title>
      <link>http://arxiv.org/abs/2507.00297v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了利用大规模无标签数据和自监督学习提升自然语言处理（NLP）性能的近期进展，重点关注撒哈拉以南非洲的低资源语言，并提出了解决方法。&lt;h4&gt;背景&lt;/h4&gt;多语言模型通常在类似维基百科这样的网络数据上训练，但面临着包括数据噪声、低资源语言数据少以及缺乏标注数据集等挑战。&lt;h4&gt;目的&lt;/h4&gt;针对撒哈拉以南非洲地区的低资源语言，分析公开语料库中的噪声，整理高质量语料库，并探索如何适应和专门化多语言预训练语言模型。&lt;h4&gt;方法&lt;/h4&gt;对公开语料库中的噪声进行分析，创建高质量语料库；通过实证研究词嵌入的局限性以及多语言预训练语言模型在低资源场景下的机遇；研究如何利用少量单语文本对多语言预训练语言模型进行适应和专门化；开发大规模人工标注数据集；在监督学习、弱监督学习和迁移学习设置中使用最先进的方法进行广泛实证评估。&lt;h4&gt;主要发现&lt;/h4&gt;语义表示学习的质量不仅取决于数据量，还取决于预训练数据的质量；词嵌入存在局限性，多语言预训练语言模型为低资源语言提供了机遇；针对低资源非洲语言，可以有效地适应和专门化多语言预训练语言模型。&lt;h4&gt;结论&lt;/h4&gt;针对撒哈拉以南非洲地区的低资源语言，提出的方法能够提升NLP性能，并通过实证评估验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in word embeddings and language models use large-scale,unlabelled data and self-supervised learning to boost NLP performance. Multilingual models, often trained on web-sourced data like Wikipedia, face challenges: few low-resource languages are included, their data is often noisy, and lack of labeled datasets makes it hard to evaluate performance outside high-resource languages like English. In this dissertation, we focus on languages spoken in Sub-Saharan Africa where all the indigenous languages in this region can be regarded as low-resourced in terms of the availability of labeled data for NLP tasks and unlabelled data found on the web. We analyze the noise in the publicly available corpora, and curate a high-quality corpus, demonstrating that the quality of semantic representations learned in word embeddings does not only depend on the amount of data but on the quality of pre-training data. We demonstrate empirically the limitations of word embeddings, and the opportunities the multilingual pre-trained language model (PLM) offers especially for languages unseen during pre-training and low-resource scenarios. We further study how to adapt and specialize multilingual PLMs to unseen African languages using a small amount of monolingual texts. To address the under-representation of the African languages in NLP research, we developed large scale human-annotated labelled datasets for 21 African languages in two impactful NLP tasks: named entity recognition and machine translation. We conduct an extensive empirical evaluation using state-of-the-art methods across supervised, weakly-supervised, and transfer learning settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in word embeddings and language models use large-scale,unlabelled data and self-supervised learning to boost NLP performance.Multilingual models, often trained on web-sourced data like Wikipedia, facechallenges: few low-resource languages are included, their data is often noisy,and lack of labeled datasets makes it hard to evaluate performance outsidehigh-resource languages like English. In this dissertation, we focus onlanguages spoken in Sub-Saharan Africa where all the indigenous languages inthis region can be regarded as low-resourced in terms of the availability oflabelled data for NLP tasks and unlabelled data found on the web. We analysethe noise in the publicly available corpora, and curate a high-quality corpus,demonstrating that the quality of semantic representations learned in wordembeddings does not only depend on the amount of data but on the quality ofpre-training data. We demonstrate empirically the limitations of wordembeddings, and the opportunities the multilingual pre-trained language model(PLM) offers especially for languages unseen during pre-training andlow-resource scenarios. We further study how to adapt and specializemultilingual PLMs to unseen African languages using a small amount ofmonolingual texts. To address the under-representation of the African languagesin NLP research, we developed large scale human-annotated labelled datasets for21 African languages in two impactful NLP tasks: named entity recognition andmachine translation. We conduct an extensive empirical evaluation usingstate-of-the-art methods across supervised, weakly-supervised, and transferlearning settings.</description>
      <author>example@mail.com (David Ifeoluwa Adelani)</author>
      <guid isPermaLink="false">2507.00297v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Proof of a perfect platonic representation hypothesis</title>
      <link>http://arxiv.org/abs/2507.01098v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文详细阐述了Ziyi等人在2025年提出的关于嵌入式深度线性网络模型（EDLN）的“完美”柏拉图表示假设（PRH）的证明。&lt;h4&gt;背景&lt;/h4&gt;PRH假设，如果使用随机梯度下降（SGD）训练，不同宽度和深度的EDLN在训练不同数据后，将形成完美的柏拉图表示，即每一对可能的层都将学习到相同的表示（除以一个旋转外）。&lt;h4&gt;目的&lt;/h4&gt;本文的目的是解释该证明并提供指导，避免详细的数学技术细节。&lt;h4&gt;方法&lt;/h4&gt;本文通过理论分析和证明，揭示了SGD训练过程中的不可逆性导致的“熵力”在表示学习中的作用。&lt;h4&gt;主要发现&lt;/h4&gt;发现SGD仅能找到完美的柏拉图解，这是一个异常现象。证明还提出了至少六种方法可以打破PRH。此外，柏拉图表示的出现与渐进式锐化现象的成因相同，这意味着深度学习中的两个看似无关的现象可能有共同的成因。&lt;h4&gt;结论&lt;/h4&gt;理论和证明突出了理解由于SGD训练不可逆性产生的“熵力”及其在表示学习中的重要作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this note, we elaborate on and explain in detail the proof given by Ziyinet al. (2025) of the "perfect" Platonic Representation Hypothesis (PRH) for theembedded deep linear network model (EDLN). We show that if trained with SGD,two EDLNs with different widths and depths and trained on different data willbecome Perfectly Platonic, meaning that every possible pair of layers willlearn the same representation up to a rotation. Because most of the globalminima of the loss function are not Platonic, that SGD only finds the perfectlyPlatonic solution is rather extraordinary. The proof also suggests at least sixways the PRH can be broken. We also show that in the EDLN model, the emergenceof the Platonic representations is due to the same reason as the emergence ofprogressive sharpening. This implies that these two seemingly unrelatedphenomena in deep learning can, surprisingly, have a common cause. Overall, thetheory and proof highlight the importance of understanding emergent "entropicforces" due to the irreversibility of SGD training and their role inrepresentation learning. The goal of this note is to be instructive and avoidlengthy technical details.</description>
      <author>example@mail.com (Liu Ziyin, Isaac Chuang)</author>
      <guid isPermaLink="false">2507.01098v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>A computationally frugal open-source foundation model for thoracic disease detection in lung cancer screening programs</title>
      <link>http://arxiv.org/abs/2507.01881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TANGERINE，一款用于体积LDCT分析的计算效率高、开源的视觉基础模型，旨在解决肺癌筛查（LCS）项目中放射科医生短缺的问题。&lt;h4&gt;背景&lt;/h4&gt;全球范围内，低剂量计算机断层扫描（LDCT）在肺癌筛查（LCS）项目中的应用正在增加。LCS项目为同时检测癌症和非癌症相关的早期肺癌疾病提供了代际机遇，但这些努力受到放射科医生人数不足的限制。&lt;h4&gt;目的&lt;/h4&gt;开发TANGERINE模型，以解决在有限的计算资源和训练数据下，快速适应各种疾病特定任务的挑战。&lt;h4&gt;方法&lt;/h4&gt;TANGERINE模型基于掩码自编码器框架，扩展到3D成像，并使用自我监督学习在超过98,000个胸部LDCT上进行预训练，包括英国迄今为止最大的LCS项目和27个公共数据集。&lt;h4&gt;主要发现&lt;/h4&gt;TANGERINE在14个疾病分类任务中实现了最先进的性能，包括肺癌和多种呼吸系统疾病，同时在不同临床中心表现出良好的泛化能力。与从头开始训练的模型相比，TANGERINE在微调期间表现出快速收敛，因此需要显著更少的GPU小时数，并且具有强大的标签效率。&lt;h4&gt;结论&lt;/h4&gt;TANGERINE的轻量级、开源设计为将其快速集成到下一代医学成像工具奠定了基础，这些工具可以改变LCS项目，使其从单一的关注肺癌检测转变为高风险人群的综合呼吸系统疾病管理。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在全世界范围内，用于肺癌筛查（LCS）项目的低剂量计算机断层扫描（LDCT）成像的采用率正在增加。LCS项目预示着同时检测癌症和非癌症相关的早期肺癌疾病的代际机遇。然而，这些努力受到缺乏能够大规模解读扫描的放射科医生的阻碍。在这里，我们介绍了TANGERINE，这是一种用于体积LDCT分析的具有计算效率、开源的视觉基础模型。TANGERINE旨在实现广泛的可访问性和快速适应性，它可以利用有限的计算资源和训练数据，直接进行微调以适应广泛的疾病特定任务。与从头开始训练的模型相比，TANGERINE在微调期间表现出快速收敛，因此需要显著更少的GPU小时数，并且显示出强大的标签效率，通过一小部分微调数据就能实现相当或更好的性能。TANGERINE使用自我监督学习在超过98,000个胸部LDCT上进行预训练，包括迄今为止英国最大的LCS项目和27个公共数据集，实现了14个疾病分类任务的最先进性能，包括肺癌和多种呼吸系统疾病，同时在不同的临床中心表现出良好的泛化能力。通过将掩码自编码器框架扩展到3D成像，TANGERINE提供了一种可扩展的LDCT分析解决方案，与最近的封闭、资源密集型模型不同，它结合了架构简单性、公共可用性和适度的计算需求。其可访问的、开源的轻量级设计为将其快速集成到下一代医学成像工具奠定了基础，这些工具可以改变LCS项目，使其从单一的关注肺癌检测转变为高风险人群的综合呼吸系统疾病管理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-dose computed tomography (LDCT) imaging employed in lung cancer screening(LCS) programs is increasing in uptake worldwide. LCS programs herald agenerational opportunity to simultaneously detect cancer and non-cancer-relatedearly-stage lung disease. Yet these efforts are hampered by a shortage ofradiologists to interpret scans at scale. Here, we present TANGERINE, acomputationally frugal, open-source vision foundation model for volumetric LDCTanalysis. Designed for broad accessibility and rapid adaptation, TANGERINE canbe fine-tuned off the shelf for a wide range of disease-specific tasks withlimited computational resources and training data. Relative to models trainedfrom scratch, TANGERINE demonstrates fast convergence during fine-tuning,thereby requiring significantly fewer GPU hours, and displays strong labelefficiency, achieving comparable or superior performance with a fraction offine-tuning data. Pretrained using self-supervised learning on over 98,000thoracic LDCTs, including the UK's largest LCS initiative to date and 27 publicdatasets, TANGERINE achieves state-of-the-art performance across 14 diseaseclassification tasks, including lung cancer and multiple respiratory diseases,while generalising robustly across diverse clinical centres. By extending amasked autoencoder framework to 3D imaging, TANGERINE offers a scalablesolution for LDCT analysis, departing from recent closed, resource-intensivemodels by combining architectural simplicity, public availability, and modestcomputational requirements. Its accessible, open-source lightweight design laysthe foundation for rapid integration into next-generation medical imaging toolsthat could transform LCS initiatives, allowing them to pivot from a singularfocus on lung cancer detection to comprehensive respiratory disease managementin high-risk populations.</description>
      <author>example@mail.com (Niccolò McConnell, Pardeep Vasudev, Daisuke Yamada, Daryl Cheng, Mehran Azimbagirad, John McCabe, Shahab Aslani, Ahmed H. Shahin, Yukun Zhou, The SUMMIT Consortium, Andre Altmann, Yipeng Hu, Paul Taylor, Sam M. Janes, Daniel C. Alexander, Joseph Jacob)</author>
      <guid isPermaLink="false">2507.01881v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>NN-Former: Rethinking Graph Structure in Neural Architecture Representation</title>
      <link>http://arxiv.org/abs/2507.00880v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to CVPR 2025. Code is avaiable at  https://github.com/XuRuihan/NNFormer&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的神经网络预测器，旨在提高网络设计和部署的效率，特别是在估计准确性和延迟等属性方面。该预测器结合了图神经网络（GNN）和Transformer的优点，以学习更优的网络拓扑结构。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习的广泛应用，对高效网络设计和部署的需求日益增加，这使得神经网络预测器在估计网络属性（如准确性和延迟）方面变得至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有方法（如GNN和Transformer）的不足，本文旨在提出一种新的神经网络架构，以更有效地估计网络属性。&lt;h4&gt;方法&lt;/h4&gt;本文重新思考了神经网络架构的拓扑结构，并提出了一个利用GNN和Transformer优势的新预测器。该预测器引入了新的token mixer和channel mixer，以考虑兄弟节点并提高模型的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;新方法在准确性和延迟预测方面表现出色，为学习有向无环图（DAG）拓扑提供了有价值的信息。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为网络设计和部署提供了新的思路，有助于提高网络性能。&lt;h4&gt;翻译&lt;/h4&gt;The growing use of deep learning necessitates efficient network design and deployment, making neural predictors vital for estimating attributes such as accuracy and latency. Recently, Graph Neural Networks (GNNs) and transformers have shown promising performance in representing neural architectures. However, each of both methods has its disadvantages. GNNs lack the capabilities to represent complicated features, while transformers face poor generalization when the depth of architecture grows. To mitigate the above issues, we rethink neural architecture topology and show that sibling nodes are pivotal while overlooked in previous research. We thus propose a novel predictor leveraging the strengths of GNNs and transformers to learn the enhanced topology. We introduce a novel token mixer that considers siblings, and a new channel mixer named bidirectional graph isomorphism feed-forward network. Our approach consistently achieves promising performance in both accuracy and latency prediction, providing valuable insights for learning Directed Acyclic Graph (DAG) topology. The code is available at https://github.com/XuRuihan/NNFormer.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The growing use of deep learning necessitates efficient network design anddeployment, making neural predictors vital for estimating attributes such asaccuracy and latency. Recently, Graph Neural Networks (GNNs) and transformershave shown promising performance in representing neural architectures. However,each of both methods has its disadvantages. GNNs lack the capabilities torepresent complicated features, while transformers face poor generalizationwhen the depth of architecture grows. To mitigate the above issues, we rethinkneural architecture topology and show that sibling nodes are pivotal whileoverlooked in previous research. We thus propose a novel predictor leveragingthe strengths of GNNs and transformers to learn the enhanced topology. Weintroduce a novel token mixer that considers siblings, and a new channel mixernamed bidirectional graph isomorphism feed-forward network. Our approachconsistently achieves promising performance in both accuracy and latencyprediction, providing valuable insights for learning Directed Acyclic Graph(DAG) topology. The code is available at https://github.com/XuRuihan/NNFormer.</description>
      <author>example@mail.com (Ruihan Xu, Haokui Zhang, Yaowei Wang, Wei Zeng, Shiliang Zhang)</author>
      <guid isPermaLink="false">2507.00880v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Neural Augmented Kalman Filters for Road Network assisted GNSS positioning</title>
      <link>http://arxiv.org/abs/2507.00654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025 workshop ML4Wireless&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种结合道路网络数据和GNSS测量的深度学习方法，用于提高密集城市环境中的定位精度。&lt;h4&gt;背景&lt;/h4&gt;GNSS在密集城市环境中的定位精度常受到多径和非视距误差的影响。&lt;h4&gt;目的&lt;/h4&gt;通过使用道路网络数据来减少这些误差，提高定位系统的精度。&lt;h4&gt;方法&lt;/h4&gt;提出训练一个时间图神经网络（TGNN）来整合道路网络信息到卡尔曼滤波器（KF）中，TGNN用于预测正确的道路段及其相关的不确定性。&lt;h4&gt;主要发现&lt;/h4&gt;与仅使用GNSS的KF相比，该方法在真实世界GNSS数据和开源道路网络上的验证中，在具有挑战性的场景中观察到了29%的定位误差减少。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法是首个基于深度学习，同时使用道路网络数据和GNSS测量来确定地球用户位置的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Global Navigation Satellite System (GNSS) provides critical positioninginformation globally, but its accuracy in dense urban environments is oftencompromised by multipath and non-line-of-sight errors. Road network data can beused to reduce the impact of these errors and enhance the accuracy of apositioning system. Previous works employing road network data are eitherlimited to offline applications, or rely on Kalman Filter (KF) heuristics withlittle flexibility and robustness. We instead propose training a Temporal GraphNeural Network (TGNN) to integrate road network information into a KF. The TGNNis designed to predict the correct road segment and its associated uncertaintyto be used in the measurement update step of the KF. We validate our approachwith real-world GNSS data and open-source road networks, observing a 29%decrease in positioning error for challenging scenarios compared to a GNSS-onlyKF. To the best of our knowledge, ours is the first deep learning-basedapproach jointly employing road network data and GNSS measurements to determinethe user position on Earth.</description>
      <author>example@mail.com (Hans van Gorp, Davide Belli, Amir Jalalirad, Bence Major)</author>
      <guid isPermaLink="false">2507.00654v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Cooperative Sheaf Neural Networks</title>
      <link>http://arxiv.org/abs/2507.00647v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了sheaf扩散在图表示学习中的应用，并提出了Cooperative Sheaf Neural Networks（CSNNs）以解决现有sheaf扩散方法缺乏信息方向性和无法实现合作行为的问题。&lt;h4&gt;背景&lt;/h4&gt;Sheaf扩散因其处理异质数据和避免过度平滑的能力，以及合作信息传递增强信息扩散灵活性的方法，成为图表示学习中的有前景设计模式。&lt;h4&gt;目的&lt;/h4&gt;研究sheaf扩散是否能够展现合作行为，并提出一种新的方法来克服现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;引入了在有向图上的细胞层概念，并对其入度和出度的拉普拉斯矩阵进行了特征化。利用这一构造提出了CSNNs，并分析了其感受野特性。&lt;h4&gt;主要发现&lt;/h4&gt;发现现有的sheaf扩散方法由于缺乏信息方向性而无法实现合作行为。通过CSNNs，节点能够选择性地关注任意远距离的节点，而忽略路径上的其他节点。&lt;h4&gt;结论&lt;/h4&gt;CSNNs在sheaf扩散和合作图神经网络方面表现优于现有方法，有助于缓解过度压缩问题。&lt;h4&gt;翻译&lt;/h4&gt;Sheaf扩散最近成为图表示学习的一种有前途的设计模式，因为它固有的处理异质数据和避免过度平滑的能力。同时，合作信息传递也被提出作为一种增强信息扩散灵活性的方法，允许节点独立选择是否从邻居那里传播/收集信息。随之而来的是一个自然的问题：sheaf扩散是否能够表现出这种合作行为？在这里，我们给出了一个否定的答案。特别是，我们表明，由于缺乏消息方向性，现有的sheaf扩散方法无法实现合作行为。为了克服这一局限性，我们引入了在有向图上的细胞层概念，并对其入度和出度的拉普拉斯矩阵进行了特征化。我们利用我们的构造提出了合作sheaf神经网络（CSNNs）。从理论上讲，我们描述了CSNN的感受野，并表明它允许节点选择性地关注任意远距离的节点，而忽略它们路径上的所有其他节点，这可能有助于缓解过度压缩。我们的实验表明，与先前的sheaf扩散和合作图神经网络相比，CSNN在整体性能上有所提高。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sheaf diffusion has recently emerged as a promising design pattern for graphrepresentation learning due to its inherent ability to handle heterophilic dataand avoid oversmoothing. Meanwhile, cooperative message passing has also beenproposed as a way to enhance the flexibility of information diffusion byallowing nodes to independently choose whether to propagate/gather informationfrom/to neighbors. A natural question ensues: is sheaf diffusion capable ofexhibiting this cooperative behavior? Here, we provide a negative answer tothis question. In particular, we show that existing sheaf diffusion methodsfail to achieve cooperative behavior due to the lack of message directionality.To circumvent this limitation, we introduce the notion of cellular sheaves overdirected graphs and characterize their in- and out-degree Laplacians. Weleverage our construction to propose Cooperative Sheaf Neural Networks (CSNNs).Theoretically, we characterize the receptive field of CSNN and show it allowsnodes to selectively attend (listen) to arbitrarily far nodes while ignoringall others in their path, potentially mitigating oversquashing. Our experimentsshow that CSNN presents overall better performance compared to prior art onsheaf diffusion as well as cooperative graph neural networks.</description>
      <author>example@mail.com (André Ribeiro, Ana Luiza Tenório, Juan Belieni, Amauri H. Souza, Diego Mesquita)</author>
      <guid isPermaLink="false">2507.00647v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Frequency Domain-Based Diffusion Model for Unpaired Image Dehazing</title>
      <link>http://arxiv.org/abs/2507.01275v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于频率域的扩散模型（ours）用于去雾，该模型能够充分利用无配对清晰数据中的有益知识，并优于其他最先进的方法。&lt;h4&gt;背景&lt;/h4&gt;无配对图像去雾因其灵活的数据需求而受到越来越多的关注，但基于对比学习的方法未能充分利用频率域中的去雾特性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的去雾方法，以解决现有方法中引入无关内容信息和忽略频率域中去雾特性的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为ours的频率域扩散模型，包括：1. 提出振幅残差编码器（ARE）提取振幅残差，补偿模糊到清晰域的振幅差距；2. 提出相位校正模块（PCM）通过简单的注意力机制进一步细化相位谱以消除伪影。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，ours在合成和真实世界数据集上均优于其他最先进的方法。&lt;h4&gt;结论&lt;/h4&gt;ours模型能够有效去雾，并优于现有的最先进方法。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is about proposing a novel frequency domain-based diffusion model (ours) for image dehazing, which effectively utilizes the beneficial knowledge in unpaired clear data and outperforms other state-of-the-art methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unpaired image dehazing has attracted increasing attention due to itsflexible data requirements during model training. Dominant methods based oncontrastive learning not only introduce haze-unrelated content information, butalso ignore haze-specific properties in the frequency domain (\ie,~haze-relateddegradation is mainly manifested in the amplitude spectrum). To address theseissues, we propose a novel frequency domain-based diffusion model, named \ours,for fully exploiting the beneficial knowledge in unpaired clear data. Inparticular, inspired by the strong generative ability shown by Diffusion Models(DMs), we tackle the dehazing task from the perspective of frequency domainreconstruction and perform the DMs to yield the amplitude spectrum consistentwith the distribution of clear images. To implement it, we propose an AmplitudeResidual Encoder (ARE) to extract the amplitude residuals, which effectivelycompensates for the amplitude gap from the hazy to clear domains, as well asprovide supervision for the DMs training. In addition, we propose a PhaseCorrection Module (PCM) to eliminate artifacts by further refining the phasespectrum during dehazing with a simple attention mechanism. Experimentalresults demonstrate that our \ours outperforms other state-of-the-art methodson both synthetic and real-world datasets.</description>
      <author>example@mail.com (Chengxu Liu, Lu Qi, Jinshan Pan, Xueming Qian, Ming-Hsuan Yang)</author>
      <guid isPermaLink="false">2507.01275v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Audio-3DVG: Unified Audio - Point Cloud Fusion for 3D Visual Grounding</title>
      <link>http://arxiv.org/abs/2507.00669v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress, 42 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Audio-3DVG的框架，用于基于音频的3D视觉定位，通过结合音频和空间信息来提高定位效果。&lt;h4&gt;背景&lt;/h4&gt;虽然基于文本描述的3D视觉定位已有进展，但利用语音的Audio-3DVG仍然是一个未充分探索且具有挑战性的领域。&lt;h4&gt;目的&lt;/h4&gt;旨在通过结合自动语音识别和语音表示学习，提出一种简单而有效的框架，以提高基于音频的3D视觉定位的性能。&lt;h4&gt;方法&lt;/h4&gt;将任务分解为两个互补的组件：对象提及检测和音频引导注意力模块。对象提及检测用于识别音频中提到的对象，音频引导注意力模块则用于捕捉候选对象与关系性语音线索之间的交互。&lt;h4&gt;主要发现&lt;/h4&gt;通过合成音频描述并应用于标准3DVG数据集，实验结果表明Audio-3DVG在基于音频的定位中达到了新的水平，并且在性能上可以与基于文本的方法相媲美。&lt;h4&gt;结论&lt;/h4&gt;将语音语言集成到3D视觉任务中具有很大的潜力，Audio-3DVG框架为这一领域的发展提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：3D视觉定位（3DVG）涉及根据自然语言在3D点云中定位目标对象。尽管先前的工作在文本描述方面取得了进展，但利用语音的音频3D视觉定位（Audio-3DVG）仍然是一个未充分探索且具有挑战性的领域。受自动语音识别（ASR）和语音表示学习进展的启发，我们提出了Audio-3DVG，这是一个简单而有效的框架，它集成了音频和空间信息以增强定位。我们不是将语音视为一个统一的输入，而是将任务分解为两个互补的组件。首先，我们引入了对象提及检测，这是一个多标签分类任务，它明确地识别音频中提到的对象，从而使得音频场景推理更加结构化。其次，我们提出了一个音频引导注意力模块，它捕捉候选对象与关系性语音线索之间的交互，从而提高了杂乱场景中的目标识别。为了支持基准测试，我们为标准3DVG数据集，包括ScanRefer、Sr3D和Nr3D，合成了音频描述。实验结果表明，Audio-3DVG不仅在基于音频的定位中实现了新的最先进性能，而且在与基于文本的方法的竞争中表现良好，突显了将语音语言集成到3D视觉任务中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Visual Grounding (3DVG) involves localizing target objects in 3D pointclouds based on natural language. While prior work has made strides usingtextual descriptions, leveraging spoken language-known as Audio-based 3D VisualGrounding-remains underexplored and challenging. Motivated by advances inautomatic speech recognition (ASR) and speech representation learning, wepropose Audio-3DVG, a simple yet effective framework that integrates audio andspatial information for enhanced grounding. Rather than treating speech as amonolithic input, we decompose the task into two complementary components.First, we introduce Object Mention Detection, a multi-label classification taskthat explicitly identifies which objects are referred to in the audio, enablingmore structured audio-scene reasoning. Second, we propose an Audio-GuidedAttention module that captures interactions between candidate objects andrelational speech cues, improving target discrimination in cluttered scenes. Tosupport benchmarking, we synthesize audio descriptions for standard 3DVGdatasets, including ScanRefer, Sr3D, and Nr3D. Experimental results demonstratethat Audio-3DVG not only achieves new state-of-the-art performance inaudio-based grounding, but also competes with text-based methods-highlightingthe promise of integrating spoken language into 3D vision tasks.</description>
      <author>example@mail.com (Duc Cao-Dinh, Khai Le-Duc, Anh Dao, Bach Phan Tat, Chris Ngo, Duy M. H. Nguyen, Nguyen X. Khanh, Thanh Nguyen-Tang)</author>
      <guid isPermaLink="false">2507.00669v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>ShapeEmbed: a self-supervised learning framework for 2D contour quantification</title>
      <link>http://arxiv.org/abs/2507.01009v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ShapeEmbed的自监督表示学习框架，用于编码2D图像中物体的轮廓，并生成对平移、缩放、旋转、反射和点索引不变性的形状描述符。&lt;h4&gt;背景&lt;/h4&gt;形状量化是一个核心挑战，需要确保提取的测量值对保持物体内在几何学的变换（如改变大小、方向和位置）保持不变。&lt;h4&gt;目的&lt;/h4&gt;提出ShapeEmbed框架，以克服传统形状描述符的局限性，并改进现有的基于自动编码器的最先进方法。&lt;h4&gt;方法&lt;/h4&gt;ShapeEmbed框架将物体的轮廓编码为欧几里得距离矩阵，并生成不变的形状描述符。&lt;h4&gt;主要发现&lt;/h4&gt;ShapeEmbed框架在自然和生物图像上的形状分类任务中，其学习到的描述符优于竞争对手。&lt;h4&gt;结论&lt;/h4&gt;ShapeEmbed框架对于生物成像应用尤其相关。&lt;h4&gt;翻译&lt;/h4&gt;物体形状是广泛应用程序中视觉信息的一个重要来源。形状量化的一项核心挑战是确保提取的测量值对保持物体内在几何学的变换（如改变其大小、方向和图像中的位置）保持不变。在这项工作中，我们引入了一种名为ShapeEmbed的自监督表示学习框架，用于将2D图像中物体的轮廓编码为欧几里得距离矩阵，并生成对平移、缩放、旋转、反射和点索引不变性的形状描述符。我们的方法克服了传统形状描述符的局限性，并改进了现有的基于自动编码器的最先进方法。我们证明了我们的框架学习到的描述符在自然和生物图像的形状分类任务中优于其竞争对手。我们预计我们的方法对于生物成像应用尤其相关。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The shape of objects is an important source of visual information in a widerange of applications. One of the core challenges of shape quantification is toensure that the extracted measurements remain invariant to transformations thatpreserve an object's intrinsic geometry, such as changing its size,orientation, and position in the image. In this work, we introduce ShapeEmbed,a self-supervised representation learning framework designed to encode thecontour of objects in 2D images, represented as a Euclidean distance matrix,into a shape descriptor that is invariant to translation, scaling, rotation,reflection, and point indexing. Our approach overcomes the limitations oftraditional shape descriptors while improving upon existing state-of-the-artautoencoder-based approaches. We demonstrate that the descriptors learned byour framework outperform their competitors in shape classification tasks onnatural and biological images. We envision our approach to be of particularrelevance to biological imaging applications.</description>
      <author>example@mail.com (Anna Foix Romero, Craig Russell, Alexander Krull, Virginie Uhlmann)</author>
      <guid isPermaLink="false">2507.01009v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Towards Foundation Auto-Encoders for Time-Series Anomaly Detection</title>
      <link>http://arxiv.org/abs/2507.01875v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Presented at ACM KDD 2024, MiLeTS 2024 Workshop, August 25, 2024,  Barcelona, Spain&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于预训练基础模型的时间序列建模新方法，用于时间序列数据中的异常检测。&lt;h4&gt;背景&lt;/h4&gt;该方法受到大型预训练基础模型成功应用的影响，旨在提高时间序列数据的建模、预测和异常检测的准确性。&lt;h4&gt;目的&lt;/h4&gt;研究并实现一种新的时间序列异常检测模型，即FAE（基础自动编码器），以实现对未见数据集上的复杂时间模式的准确建模。&lt;h4&gt;方法&lt;/h4&gt;FAE模型基于变分自动编码器（VAEs）和扩张卷积神经网络（DCNNs），通过在大量时间序列数据上预训练来学习复杂的时间模式。&lt;h4&gt;主要发现&lt;/h4&gt;FAE模型在多个多维时间序列数据集上取得了初步成果，包括来自实际移动ISP操作的数据集和KDD 2021异常检测数据集。&lt;h4&gt;结论&lt;/h4&gt;FAE模型在时间序列异常检测方面展现出潜力，未来可能适用于零样本异常检测应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate a novel approach to time-series modeling, inspired by thesuccesses of large pretrained foundation models. We introduce FAE (FoundationAuto-Encoders), a foundation generative-AI model for anomaly detection intime-series data, based on Variational Auto-Encoders (VAEs). By foundation, wemean a model pretrained on massive amounts of time-series data which can learncomplex temporal patterns useful for accurate modeling, forecasting, anddetection of anomalies on previously unseen datasets. FAE leverages VAEs andDilated Convolutional Neural Networks (DCNNs) to build a generic model forunivariate time-series modeling, which could eventually perform properly inout-of-the-box, zero-shot anomaly detection applications. We introduce the mainconcepts of FAE, and present preliminary results in different multi-dimensionaltime-series datasets from various domains, including a real dataset from anoperational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.</description>
      <author>example@mail.com (Gastón García González, Pedro Casas, Emilio Martínez, Alicia Fernández)</author>
      <guid isPermaLink="false">2507.01875v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Rotational Sampling: A Plug-and-Play Encoder for Rotation-Invariant 3D Molecular GNNs</title>
      <link>http://arxiv.org/abs/2507.01073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的插件式3D编码模块，通过旋转采样计算SO(3)旋转群的期望，实现了近似的旋转不变性，并通过后对齐策略达到了严格的旋转不变性，实验结果表明该方法在预测准确性、鲁棒性和泛化性能方面优于现有方法，同时保持低计算复杂性和增强的可解释性。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络在分子性质预测中取得了显著成功，但传统的图表示方法难以有效地编码分子的内在3D空间结构，因为分子在3D空间中的方向性引入了显著的可变性，严重限制了模型的泛化能力和鲁棒性。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种新的方法，以更有效地处理3D分子信息，从而提高分子性质预测的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种利用旋转采样的新插件式3D编码模块，通过计算SO(3)旋转群的期望实现近似的旋转不变性，并通过精心设计的后对齐策略实现严格的旋转不变性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在QM9和C10数据集上表现出比现有方法更优越的预测准确性、鲁棒性和泛化性能。&lt;h4&gt;结论&lt;/h4&gt;该方法保持了低计算复杂性和增强的可解释性，为在药物发现和材料设计中高效且有效地处理3D分子信息提供了有希望的方向。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) have achieved remarkable success in molecular property prediction. However, traditional graph representations struggle to effectively encode the inherent 3D spatial structures of molecules, as molecular orientations in 3D space introduce significant variability, severely limiting model generalization and robustness. Existing approaches primarily focus on rotation-invariant and rotation-equivariant methods. Invariant methods often rely heavily on prior knowledge and lack sufficient generalizability, while equivariant methods suffer from high computational costs. To address these limitations, this paper proposes a novel plug-and-play 3D encoding module leveraging rotational sampling. By computing the expectation over the SO(3) rotational group, the method naturally achieves approximate rotational invariance. Furthermore, by introducing a carefully designed post-alignment strategy, strict invariance can be achieved without compromising performance. Experimental evaluations on the QM9 and C10 Datasets demonstrate superior predictive accuracy, robustness, and generalization performance compared to existing methods. Moreover, the proposed approach maintains low computational complexity and enhanced interpretability, providing a promising direction for efficient and effective handling of 3D molecular information in drug discovery and material design.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) have achieved remarkable success in molecularproperty prediction. However, traditional graph representations struggle toeffectively encode the inherent 3D spatial structures of molecules, asmolecular orientations in 3D space introduce significant variability, severelylimiting model generalization and robustness. Existing approaches primarilyfocus on rotation-invariant and rotation-equivariant methods. Invariant methodsoften rely heavily on prior knowledge and lack sufficient generalizability,while equivariant methods suffer from high computational costs. To addressthese limitations, this paper proposes a novel plug-and-play 3D encoding moduleleveraging rotational sampling. By computing the expectation over the SO(3)rotational group, the method naturally achieves approximate rotationalinvariance. Furthermore, by introducing a carefully designed post-alignmentstrategy, strict invariance can be achieved without compromising performance.Experimental evaluations on the QM9 and C10 Datasets demonstrate superiorpredictive accuracy, robustness, and generalization performance compared toexisting methods. Moreover, the proposed approach maintains low computationalcomplexity and enhanced interpretability, providing a promising direction forefficient and effective handling of 3D molecular information in drug discoveryand material design.</description>
      <author>example@mail.com (Dian Jin)</author>
      <guid isPermaLink="false">2507.01073v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>A Recipe for Causal Graph Regression: Confounding Effects Revisited</title>
      <link>http://arxiv.org/abs/2507.00440v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了因果图学习（CGL）在回归任务中的应用，特别是在处理因变量中的混杂因素时，通过引入对比学习的方法提高了图神经网络在分布外（OOD）情况下的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;因果图学习在分类设置中取得了成功，但在回归任务中却较少被关注。&lt;h4&gt;目的&lt;/h4&gt;提出一种解决因果图回归（CGR）问题的方法，以改善图神经网络在回归任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;重新设计了现有因果图学习研究中混淆效应的处理方式，通过对比学习将分类特定的因果干预技术推广到回归任务中。&lt;h4&gt;主要发现&lt;/h4&gt;在图分布外基准测试上，实验验证了该方法对因果图回归的有效性。&lt;h4&gt;结论&lt;/h4&gt;该方法能够提高图神经网络在回归任务中的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;通过识别因果子图，因果图学习（CGL）已成为提高图神经网络在分布外（OOD）场景下泛化能力的一种有前景的方法。然而，CGL技术的实证成功主要在分类设置中得到体现，而回归任务，作为图学习中的一个更具挑战性的设置，却被忽视了。因此，我们的这项工作致力于解决因果图回归（CGR）问题；为此，我们重新设计了现有CGL研究中处理混淆效应的方式，这些研究主要关注分类。具体来说，我们反思了混杂因素在图级回归中的预测能力，并通过对比学习的视角将分类特定的因果干预技术推广到回归任务中。在图OOD基准测试上的大量实验验证了我们对于CGR的建议的有效性。模型实现和代码可在https://github.com/causal-graph/CGR上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Through recognizing causal subgraphs, causal graph learning (CGL) has risento be a promising approach for improving the generalizability of graph neuralnetworks under out-of-distribution (OOD) scenarios. However, the empiricalsuccesses of CGL techniques are mostly exemplified in classification settings,while regression tasks, a more challenging setting in graph learning, areoverlooked. We thus devote this work to tackling causal graph regression (CGR);to this end we reshape the processing of confounding effects in existing CGLstudies, which mainly deal with classification. Specifically, we reflect on thepredictive power of confounders in graph-level regression, and generalizeclassification-specific causal intervention techniques to regression through alens of contrastive learning. Extensive experiments on graph OOD benchmarksvalidate the efficacy of our proposals for CGR. The model implementation andthe code are provided on https://github.com/causal-graph/CGR.</description>
      <author>example@mail.com (Yujia Yin, Tianyi Qu, Zihao Wang, Yifan Chen)</author>
      <guid isPermaLink="false">2507.00440v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>PlantSegNeRF: A few-shot, cross-dataset method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching</title>
      <link>http://arxiv.org/abs/2507.00371v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为植物分割神经辐射场（PlantSegNeRF）的新方法，用于从多视角RGB图像序列中直接生成高精度的实例点云，以提高植物器官分割的分辨率、准确性和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;植物点云器官分割是高分辨率和准确提取器官水平表型性状的前提。尽管深度学习快速发展，但现有的器官分割技术仍存在分辨率、分割准确性和跨物种泛化能力方面的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出PlantSegNeRF方法，以实现从多视角RGB图像序列中直接生成高精度实例点云，适用于多种植物物种。&lt;h4&gt;方法&lt;/h4&gt;PlantSegNeRF在多视角图像上进行二维实例分割，为每个器官生成带有对应ID的实例掩码。然后，使用专门设计的实例匹配模块匹配和细化对应同一植物器官的多视角实例ID。实例NeRF被开发出来渲染包含颜色、密度、语义和实例信息的隐式场景，最终基于体积密度将隐式场景转换为高精度植物实例点云。&lt;h4&gt;主要发现&lt;/h4&gt;在点云语义分割中，PlantSegNeRF优于常用方法，在结构复杂的数据集上，与第二好的结果相比，在精度、召回率、F1分数和IoU方面平均提高了16.1%、18.3%、17.8%和24.2%。更重要的是，PlantSegNeRF在植物点云实例分割任务中表现出显著优势，在所有植物数据集上，它在mPrec、mRec、mCov和mWCov方面的平均改进分别为11.7%、38.2%、32.2%和25.3%。&lt;h4&gt;结论&lt;/h4&gt;本研究扩展了器官水平的植物表型分析，为植物科学中大规模模型的发展提供了高通量方式，以提供高质量的3D数据。&lt;h4&gt;翻译&lt;/h4&gt;摘要：植物点云器官分割是高分辨率和准确提取器官水平表型性状的前提。尽管深度学习快速发展，但现有的器官分割技术仍存在分辨率、分割准确性和跨物种泛化能力方面的局限性。在本文中，我们提出了一种名为植物分割神经辐射场（PlantSegNeRF）的新方法，旨在直接从多视角RGB图像序列中为广泛的植物物种生成高精度实例点云。PlantSegNeRF在多视角图像上进行二维实例分割，为每个器官生成带有对应ID的实例掩码。然后，使用专门设计的实例匹配模块匹配和细化对应同一植物器官的多视角实例ID。实例NeRF被开发出来渲染包含颜色、密度、语义和实例信息的隐式场景，最终基于体积密度将隐式场景转换为高精度植物实例点云。结果表明，在点云语义分割中，PlantSegNeRF优于常用方法，在结构复杂的数据集上，与第二好的结果相比，在精度、召回率、F1分数和IoU方面平均提高了16.1%、18.3%、17.8%和24.2%。更重要的是，PlantSegNeRF在植物点云实例分割任务中表现出显著优势，在所有植物数据集上，它在mPrec、mRec、mCov和mWCov方面的平均改进分别为11.7%、38.2%、32.2%和25.3%。本研究扩展了器官水平的植物表型分析，为植物科学中大规模模型的发展提供了高通量方式，以提供高质量的3D数据。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Organ segmentation of plant point clouds is a prerequisite for thehigh-resolution and accurate extraction of organ-level phenotypic traits.Although the fast development of deep learning has boosted much research onsegmentation of plant point clouds, the existing techniques for organsegmentation still face limitations in resolution, segmentation accuracy, andgeneralizability across various plant species. In this study, we proposed anovel approach called plant segmentation neural radiance fields (PlantSegNeRF),aiming to directly generate high-precision instance point clouds frommulti-view RGB image sequences for a wide range of plant species. PlantSegNeRFperformed 2D instance segmentation on the multi-view images to generateinstance masks for each organ with a corresponding ID. The multi-view instanceIDs corresponding to the same plant organ were then matched and refined using aspecially designed instance matching module. The instance NeRF was developed torender an implicit scene, containing color, density, semantic and instanceinformation. The implicit scene was ultimately converted into high-precisionplant instance point clouds based on the volume density. The results provedthat in semantic segmentation of point clouds, PlantSegNeRF outperformed thecommonly used methods, demonstrating an average improvement of 16.1%, 18.3%,17.8%, and 24.2% in precision, recall, F1-score, and IoU compared to thesecond-best results on structurally complex datasets. More importantly,PlantSegNeRF exhibited significant advantages in plant point cloud instancesegmentation tasks. Across all plant datasets, it achieved average improvementsof 11.7%, 38.2%, 32.2% and 25.3% in mPrec, mRec, mCov, mWCov, respectively.This study extends the organ-level plant phenotyping and provides ahigh-throughput way to supply high-quality 3D data for the development oflarge-scale models in plant science.</description>
      <author>example@mail.com (Xin Yang, Ruiming Du, Hanyang Huang, Jiayang Xie, Pengyao Xie, Leisen Fang, Ziyue Guo, Nanjun Jiang, Yu Jiang, Haiyan Cen)</author>
      <guid isPermaLink="false">2507.00371v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Graph-Based Deep Learning for Component Segmentation of Maize Plants</title>
      <link>http://arxiv.org/abs/2507.00182v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的创新方法，用于在LiDAR 3D点云数据集上检测单个植物组件。&lt;h4&gt;背景&lt;/h4&gt;在精确农业中，识别单个植物组件是作物生产探索中的重要任务，目前主要使用二维成像、三维重建和卷积神经网络等技术，但存在一些缺点。&lt;h4&gt;目的&lt;/h4&gt;旨在提高3D数据处理和识别单个植物组件的准确度。&lt;h4&gt;方法&lt;/h4&gt;提出的方法基于图神经网络（GNN）的概念，并使用主成分分析（PCA）增强特征。每个点被视为顶点，通过K-最近邻（KNN）层建立边，表示3D点云数据集。随后使用Edge-Conv层进一步增加每个点的特征。最后，应用图注意力网络（GAT）对植物的可见表型成分进行分类，如叶片、茎和土壤。&lt;h4&gt;主要发现&lt;/h4&gt;该基于图深度学习方法在识别单个植物组件的分割准确性方面得到提高，IoU平均百分比超过80%，优于其他基于点云的现有模型。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提升了单个植物组件的识别准确度，对于精确农业领域具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;In precision agriculture, one of the most important tasks when exploring crop production is identifying individual plant components. There are several attempts to accomplish this task by the use of traditional 2D imaging, 3D reconstructions, and Convolutional Neural Networks (CNN). However, they have several drawbacks when processing 3D data and identifying individual plant components. Therefore, in this work, we propose a novel Deep Learning architecture to detect components of individual plants on Light Detection and Ranging (LiDAR) 3D Point Cloud (PC) data sets. This architecture is based on the concept of Graph Neural Networks (GNN), and feature enhancing with Principal Component Analysis (PCA). For this, each point is taken as a vertex and by the use of a K-Nearest Neighbors (KNN) layer, the edges are established, thus representing the 3D PC data set. Subsequently, Edge-Conv layers are used to further increase the features of each point. Finally, Graph Attention Networks (GAT) are applied to classify visible phenotypic components of the plant, such as the leaf, stem, and soil. This study demonstrates that our graph-based deep learning approach enhances segmentation accuracy for identifying individual plant components, achieving percentages above 80% in the IoU average, thus outperforming other existing models based on point clouds.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In precision agriculture, one of the most important tasks when exploring cropproduction is identifying individual plant components. There are severalattempts to accomplish this task by the use of traditional 2D imaging, 3Dreconstructions, and Convolutional Neural Networks (CNN). However, they haveseveral drawbacks when processing 3D data and identifying individual plantcomponents. Therefore, in this work, we propose a novel Deep Learningarchitecture to detect components of individual plants on Light Detection andRanging (LiDAR) 3D Point Cloud (PC) data sets. This architecture is based onthe concept of Graph Neural Networks (GNN), and feature enhancing withPrincipal Component Analysis (PCA). For this, each point is taken as a vertexand by the use of a K-Nearest Neighbors (KNN) layer, the edges are established,thus representing the 3D PC data set. Subsequently, Edge-Conv layers are usedto further increase the features of each point. Finally, Graph AttentionNetworks (GAT) are applied to classify visible phenotypic components of theplant, such as the leaf, stem, and soil. This study demonstrates that ourgraph-based deep learning approach enhances segmentation accuracy foridentifying individual plant components, achieving percentages above 80% in theIoU average, thus outperforming other existing models based on point clouds.</description>
      <author>example@mail.com (J. I. Ruiz-Martinez, A. Mendez-Vazquez, E. Rodriguez-Tello)</author>
      <guid isPermaLink="false">2507.00182v2</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Feature Learning on Huge Knowledge Graphs for Downstream Machine Learning</title>
      <link>http://arxiv.org/abs/2507.00965v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SEPAL是一种针对大型知识图谱的扩展嵌入传播算法，旨在生成高质量的嵌入表示，以提高下游任务的性能。&lt;h4&gt;背景&lt;/h4&gt;许多机器学习任务可以从外部知识中受益，大型知识图谱存储了这样的知识，嵌入方法可以将其提炼成可用于下游应用的向量表示。&lt;h4&gt;目的&lt;/h4&gt;SEPAL旨在解决当前模型在链接预测优化和扩展到大型图谱时的局限性。&lt;h4&gt;方法&lt;/h4&gt;SEPAL通过仅优化一小部分实体的嵌入并使用消息传递传播这些嵌入到整个图，从而强制执行全局嵌入对齐。&lt;h4&gt;主要发现&lt;/h4&gt;SEPAL在7个大规模知识图谱和46个下游机器学习任务上进行了评估，结果显示SEPAL在下游任务上显著优于先前的方法，并且可以扩展其基础嵌入模型，使其能够在通用硬件上拟合巨大的知识图谱。&lt;h4&gt;结论&lt;/h4&gt;SEPAL是一种高效且可扩展的算法，能够生成高质量的知识图谱嵌入，适用于各种下游机器学习任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many machine learning tasks can benefit from external knowledge. Largeknowledge graphs store such knowledge, and embedding methods can be used todistill it into ready-to-use vector representations for downstreamapplications. For this purpose, current models have however two limitations:they are primarily optimized for link prediction, via local contrastivelearning, and they struggle to scale to the largest graphs due to GPU memorylimits. To address these, we introduce SEPAL: a Scalable Embedding PropagationALgorithm for large knowledge graphs designed to produce high-qualityembeddings for downstream tasks at scale. The key idea of SEPAL is to enforceglobal embedding alignment by optimizing embeddings only on a small core ofentities, and then propagating them to the rest of the graph via messagepassing. We evaluate SEPAL on 7 large-scale knowledge graphs and 46 downstreammachine learning tasks. Our results show that SEPAL significantly outperformsprevious methods on downstream tasks. In addition, SEPAL scales up its baseembedding model, enabling fitting huge knowledge graphs on commodity hardware.</description>
      <author>example@mail.com (Félix Lefebvre, Gaël Varoquaux)</author>
      <guid isPermaLink="false">2507.00965v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Fractional Policy Gradients: Reinforcement Learning with Long-Term Memory</title>
      <link>http://arxiv.org/abs/2507.00073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Journal of Machine Learning Research (JMLR), June 2025.  24 pages, 3 figures. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为分数策略梯度（FPG）的强化学习框架，该框架结合了分数微积分来优化长期时间建模。&lt;h4&gt;背景&lt;/h4&gt;标准策略梯度方法受到马尔可夫假设的限制，表现出高方差和采样效率低下的问题。&lt;h4&gt;目的&lt;/h4&gt;通过使用Caputo分数导数重新定义梯度，FPG建立了状态转换之间的幂律时间相关性。&lt;h4&gt;方法&lt;/h4&gt;开发了有效的递归计算技术，用于分数时间差分误差，具有恒定的时间和内存需求。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，FPG实现了与标准策略梯度相比的渐近方差降低，达到O(t^(-α))的阶数，同时保持收敛。&lt;h4&gt;结论&lt;/h4&gt;实证验证表明，与最先进的基线相比，FPG在样本效率上提高了35-68%，在方差上降低了24-52%。这一框架为在不增加计算开销的情况下利用长期依赖性提供了一种数学基础的方法。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为分数策略梯度（FPG）的强化学习框架，该框架结合了分数微积分来优化长期时间建模。标准策略梯度方法受到马尔可夫假设的限制，表现出高方差和采样效率低下的问题。通过使用Caputo分数导数重新定义梯度，FPG建立了状态转换之间的幂律时间相关性。我们开发了有效的递归计算技术，用于分数时间差分误差，具有恒定的时间和内存需求。理论分析表明，FPG实现了与标准策略梯度相比的渐近方差降低，达到O(t^(-α))的阶数，同时保持收敛。实证验证表明，与最先进的基线相比，FPG在样本效率上提高了35-68%，在方差上降低了24-52%。这一框架为在不增加计算开销的情况下利用长期依赖性提供了一种数学基础的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose Fractional Policy Gradients (FPG), a reinforcement learningframework incorporating fractional calculus for long-term temporal modeling inpolicy optimization. Standard policy gradient approaches face limitations fromMarkovian assumptions, exhibiting high variance and inefficient sampling. Byreformulating gradients using Caputo fractional derivatives, FPG establishespower-law temporal correlations between state transitions. We develop anefficient recursive computation technique for fractional temporal-differenceerrors with constant time and memory requirements. Theoretical analysis showsFPG achieves asymptotic variance reduction of order O(t^(-alpha)) versusstandard policy gradients while preserving convergence. Empirical validationdemonstrates 35-68% sample efficiency gains and 24-52% variance reductionversus state-of-the-art baselines. This framework provides a mathematicallygrounded approach for leveraging long-range dependencies without computationaloverhead.</description>
      <author>example@mail.com (Urvi Pawar, Kunal Telangi)</author>
      <guid isPermaLink="false">2507.00073v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Tightly-Coupled LiDAR-IMU-Leg Odometry with Online Learned Leg Kinematics Incorporating Foot Tactile Information</title>
      <link>http://arxiv.org/abs/2506.09548v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Robotics and Automation Letters, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种紧密耦合的激光雷达-惯性测量单元-腿部里程计，该方法在无特征环境和可变形地形等恶劣条件下表现稳健。&lt;h4&gt;背景&lt;/h4&gt;针对无特征环境和可变形地形等挑战性条件，提出了一种新的腿部里程计方法。&lt;h4&gt;目的&lt;/h4&gt;开发一种在线学习基于的腿部运动学模型，以提高机器人对不同负载变化和地形条件的适应性。&lt;h4&gt;方法&lt;/h4&gt;开发了一个名为神经腿部运动学模型的在线学习模型，该模型结合了触觉信息（脚部反作用力）来隐式表达机器人脚部与地面之间的非线性动力学。通过联合解决运动学模型的在线训练和里程计估计，保持两者的一致性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，结合神经腿部运动学模型的里程计估计优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在两个具有挑战性的环境中得到了验证，包括沙滩和校园，证明了其有效性和稳健性。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们提出了一种紧密耦合的激光雷达-IMU-腿部里程计，该方法对无特征环境和可变形地形等恶劣条件具有鲁棒性。我们开发了一种基于在线学习的腿部运动学模型，即神经腿部运动学模型，该模型结合了触觉信息（脚部反作用力）来隐式表达机器人脚部与地面之间的非线性动力学。通过在线训练该模型，增强了其对机器人重量负载变化（例如，假设配送或运输任务）和地形条件的适应性。根据基于腿部运动学模型的运动预测的神经自适应腿部里程计因子和在线不确定性估计，我们共同解决了运动学模型的在线训练和里程计估计，在一个统一的因子图中保持两者的一致性。通过使用四足机器人在两个具有挑战性的环境中进行的实际实验，验证了所提出的方法：1）沙滩，代表一个极其无特征区域，具有可变形地形；2）校园，包括多个无特征区域和多种地形类型，如沥青、砾石（可变形地形）和草地。实验结果表明，我们的结合神经腿部运动学模型的里程计估计优于现有技术。我们的项目页面提供了更多详细信息：https://takuokawara.github.io/RAL2025_project_page/&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-11&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/LRA.2025.3580332&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this letter, we present tightly coupled LiDAR-IMU-leg odometry, which isrobust to challenging conditions such as featureless environments anddeformable terrains. We developed an online learning-based leg kinematics modelnamed the neural leg kinematics model, which incorporates tactile information(foot reaction force) to implicitly express the nonlinear dynamics betweenrobot feet and the ground. Online training of this model enhances itsadaptability to weight load changes of a robot (e.g., assuming delivery ortransportation tasks) and terrain conditions. According to the \textit{neuraladaptive leg odometry factor} and online uncertainty estimation of the legkinematics model-based motion predictions, we jointly solve online training ofthis kinematics model and odometry estimation on a unified factor graph toretain the consistency of both. The proposed method was verified through realexperiments using a quadruped robot in two challenging situations: 1) a sandybeach, representing an extremely featureless area with a deformable terrain,and 2) a campus, including multiple featureless areas and terrain types ofasphalt, gravel (deformable terrain), and grass. Experimental results showedthat our odometry estimation incorporating the \textit{neural leg kinematicsmodel} outperforms state-of-the-art works. Our project page is available forfurther details: https://takuokawara.github.io/RAL2025_project_page/</description>
      <author>example@mail.com (Taku Okawara, Kenji Koide, Aoki Takanose, Shuji Oishi, Masashi Yokozuka, Kentaro Uno, Kazuya Yoshida)</author>
      <guid isPermaLink="false">2506.09548v2</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs</title>
      <link>http://arxiv.org/abs/2507.01806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5-page main paper (excluding references) + 11-page appendix, 3  tables, 1 figure. Accepted to ICML 2025 Workshop on Efficient Systems for  Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对计算资源有限的用户，特别是使用标准笔记本电脑CPU的用户，设计的LoRA微调方法，通过在CPU上直接构建轻量级的现有LoRA组合来训练适配器，以实现参数高效的模型微调。&lt;h4&gt;背景&lt;/h4&gt;LoRA（低秩适配器）在大型语言模型（LLM）的微调中表现出参数高效的更新能力，但其广泛应用受到GPU训练依赖的限制。&lt;h4&gt;目的&lt;/h4&gt;为计算资源有限的用户提供一种在CPU上实现LoRA微调的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法通过利用大量预训练的适配器，学习一个元算子，将任何输入数据集（表示为概率分布）映射到一组LoRA权重，并通过CPU上的轻量级组合直接构建适配器，而不进行新的基于梯度的更新。&lt;h4&gt;主要发现&lt;/h4&gt;虽然CPU训练的适配器性能不如GPU训练的适配器，但它们在下游任务上始终优于基线Mistral模型。&lt;h4&gt;结论&lt;/h4&gt;该方法为传统基于GPU的微调提供了一种实用且可访问的替代方案。&lt;h4&gt;翻译&lt;/h4&gt;Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language Models (LLMs) by enabling parameter-efficient updates. However, their widespread adoption remains limited by the reliance on GPU-based training. In this work, we propose a theoretically grounded approach to LoRA fine-tuning designed specifically for users with limited computational resources, particularly those restricted to standard laptop CPUs. Our method learns a meta-operator that maps any input dataset, represented as a probability distribution, to a set of LoRA weights by leveraging a large bank of pre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of performing new gradient-based updates, our pipeline constructs adapters via lightweight combinations of existing LoRAs directly on CPU. While the resulting adapters do not match the performance of GPU-trained counterparts, they consistently outperform the base Mistral model on downstream tasks, offering a practical and accessible alternative to traditional GPU-based fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large LanguageModels (LLMs) by enabling parameter-efficient updates. However, theirwidespread adoption remains limited by the reliance on GPU-based training. Inthis work, we propose a theoretically grounded approach to LoRA fine-tuningdesigned specifically for users with limited computational resources,particularly those restricted to standard laptop CPUs. Our method learns ameta-operator that maps any input dataset, represented as a probabilitydistribution, to a set of LoRA weights by leveraging a large bank ofpre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead ofperforming new gradient-based updates, our pipeline constructs adapters vialightweight combinations of existing LoRAs directly on CPU. While the resultingadapters do not match the performance of GPU-trained counterparts, theyconsistently outperform the base Mistral model on downstream tasks, offering apractical and accessible alternative to traditional GPU-based fine-tuning.</description>
      <author>example@mail.com (Reza Arabpour, Haitz Sáez de Ocáriz Borde, Anastasis Kratsios)</author>
      <guid isPermaLink="false">2507.01806v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement</title>
      <link>http://arxiv.org/abs/2507.00966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE/ACM Transactions on Audio, Speech, and Language  Processing for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MambAttention的新型混合架构，用于可泛化的单声道语音增强，并在多个指标上优于现有系统。&lt;h4&gt;背景&lt;/h4&gt;新序列模型如Mamba和xLSTM在语音增强、自动语音识别和自监督音频表示学习方面表现出色，但存在过拟合问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的混合架构，以解决序列模型过拟合的问题，并提高单声道语音增强的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了MambAttention模型，结合Mamba和共享的时间-频率多头注意力模块。同时，使用VoiceBank+Demand Extended(VB-DemandEx)数据集进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;MambAttention模型在两个域外数据集DNS 2020和EARS-WHAM_v2上显著优于现有系统，同时在域内数据集VB-DemandEx上匹配现有系统的性能。&lt;h4&gt;结论&lt;/h4&gt;MambAttention模型在多个评价指标上优于现有系统，且在域外数据集上具有显著性能提升。&lt;h4&gt;翻译&lt;/h4&gt;With the advent of new sequence models like Mamba and xLSTM, several studies have shown that these models match or outperform state-of-the-art models in single-channel speech enhancement, automatic speech recognition, and self-supervised audio representation learning. However, prior research has demonstrated that sequence models like LSTM and Mamba tend to overfit to the training set. To address this issue, previous works have shown that adding self-attention to LSTMs substantially improves generalization performance for single-channel speech enhancement. Nevertheless, neither the concept of hybrid Mamba and time-frequency attention models nor their generalization performance have been explored for speech enhancement. In this paper, we propose a novel hybrid architecture, MambAttention, which combines Mamba and shared time- and frequency-multi-head attention modules for generalizable single-channel speech enhancement. To train our model, we introduce VoiceBank+Demand Extended (VB-DemandEx), a dataset inspired by VoiceBank+Demand but with more challenging noise types and lower signal-to-noise ratios. Trained on VB-DemandEx, our proposed MambAttention model significantly outperforms existing state-of-the-art LSTM-, xLSTM-, Mamba-, and Conformer-based systems of similar complexity across all reported metrics on two out-of-domain datasets: DNS 2020 and EARS-WHAM_v2, while matching their performance on the in-domain dataset VB-DemandEx. Ablation studies highlight the role of weight sharing between the time- and frequency-multi-head attention modules for generalization performance. Finally, we explore integrating the shared time- and frequency-multi-head attention modules with LSTM and xLSTM, which yields an notable performance improvement on the out-of-domain datasets. However, our MambAttention model remains superior on both out-of-domain datasets across all reported evaluation metrics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the advent of new sequence models like Mamba and xLSTM, several studieshave shown that these models match or outperform state-of-the-art models insingle-channel speech enhancement, automatic speech recognition, andself-supervised audio representation learning. However, prior research hasdemonstrated that sequence models like LSTM and Mamba tend to overfit to thetraining set. To address this issue, previous works have shown that addingself-attention to LSTMs substantially improves generalization performance forsingle-channel speech enhancement. Nevertheless, neither the concept of hybridMamba and time-frequency attention models nor their generalization performancehave been explored for speech enhancement. In this paper, we propose a novelhybrid architecture, MambAttention, which combines Mamba and shared time- andfrequency-multi-head attention modules for generalizable single-channel speechenhancement. To train our model, we introduce VoiceBank+Demand Extended(VB-DemandEx), a dataset inspired by VoiceBank+Demand but with more challengingnoise types and lower signal-to-noise ratios. Trained on VB-DemandEx, ourproposed MambAttention model significantly outperforms existingstate-of-the-art LSTM-, xLSTM-, Mamba-, and Conformer-based systems of similarcomplexity across all reported metrics on two out-of-domain datasets: DNS 2020and EARS-WHAM_v2, while matching their performance on the in-domain datasetVB-DemandEx. Ablation studies highlight the role of weight sharing between thetime- and frequency-multi-head attention modules for generalizationperformance. Finally, we explore integrating the shared time- andfrequency-multi-head attention modules with LSTM and xLSTM, which yields anotable performance improvement on the out-of-domain datasets. However, ourMambAttention model remains superior on both out-of-domain datasets across allreported evaluation metrics.</description>
      <author>example@mail.com (Nikolai Lund Kühne, Jesper Jensen, Jan Østergaard, Zheng-Hua Tan)</author>
      <guid isPermaLink="false">2507.00966v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Towards Decentralized and Sustainable Foundation Model Training with the Edge</title>
      <link>http://arxiv.org/abs/2507.01803v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个关于去中心化和可持续的基座模型训练的愿景，旨在利用边缘AI设备的计算能力来降低计算需求，并解决环境影响和集中控制风险。&lt;h4&gt;背景&lt;/h4&gt;基座模型因其能够从大量数据集中学习并处理多种任务而受到关注，但其计算需求巨大，引发了环境问题和集中控制风险。&lt;h4&gt;目的&lt;/h4&gt;提出一种去中心化和可持续的基座模型训练方法，以降低计算需求，并支持其可持续性。&lt;h4&gt;方法&lt;/h4&gt;利用边缘AI设备的计算能力，提出一种新的训练方法。&lt;h4&gt;主要发现&lt;/h4&gt;阐述了支持这一愿景的可持续性优势，并概述了实现这一愿景需要解决的一系列挑战。&lt;h4&gt;结论&lt;/h4&gt;去中心化和可持续的基座模型训练是未来AI研究的一个重要方向，但需要克服一系列技术挑战。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种面向去中心化和可持续的基座模型训练的愿景，该愿景利用边缘AI设备的计算能力，以降低计算需求并解决环境影响和集中控制风险。我们阐述了这一愿景的可持续性优势，并概述了实现这一愿景需要解决的一系列挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are at the forefront of AI research, appealing for theirability to learn from vast datasets and cater to diverse tasks. Yet, theirsignificant computational demands raise issues of environmental impact and therisk of centralized control in their development. We put forward a visiontowards decentralized and sustainable foundation model training that leveragesthe collective compute of sparingly used connected edge AI devices. We presentthe rationale behind our vision, particularly in support of its sustainabilitybenefit. We further outline a set of challenges that need to be addressed toturn this vision into reality.</description>
      <author>example@mail.com (Leyang Xue, Meghana Madhyastha, Randal Burns, Myungjin Lee, Mahesh K. Marina)</author>
      <guid isPermaLink="false">2507.01803v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MuteSwap: Silent Face-based Voice Conversion</title>
      <link>http://arxiv.org/abs/2507.00498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于无声视频的语音转换方法，通过视觉输入实现语音转换，无需音频输入，解决了在无声视频或噪声环境下的语音转换问题。&lt;h4&gt;背景&lt;/h4&gt;传统的语音转换依赖于音频输入，但在音频不可用的情况下，如无声视频或噪声环境，这种转换变得不可行。&lt;h4&gt;目的&lt;/h4&gt;研究无声面部语音转换（Silent Face-based Voice Conversion，SFVC），即仅通过视觉输入进行语音转换，生成与目标说话人身份对齐且保留源无声视频中的语音内容的语音。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为MuteSwap的新框架，该框架使用对比学习来对齐跨模态身份，并最小化互信息以分离共享的视觉特征。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MuteSwap在语音合成和身份转换方面均取得了令人印象深刻的性能，尤其在依赖音频输入的方法在噪声条件下无法产生可懂结果的情况下。&lt;h4&gt;结论&lt;/h4&gt;该方法验证了我们的训练方法的有效性，并证明了无声面部语音转换的可行性。&lt;h4&gt;翻译&lt;/h4&gt;Conventional voice conversion modifies voice characteristics from a sourcespeaker to a target speaker, relying on audio input from both sides. However,this process becomes infeasible when clean audio is unavailable, such as insilent videos or noisy environments. In this work, we focus on the task ofSilent Face-based Voice Conversion (SFVC), which does voice conversion entirelyfrom visual inputs. i.e., given images of a target speaker and a silent videoof a source speaker containing lip motion, SFVC generates speech aligning theidentity of the target speaker while preserving the speech content in thesource silent video. As this task requires generating intelligible speech andconverting identity using only visual cues, it is particularly challenging. Toaddress this, we introduce MuteSwap, a novel framework that employs contrastivelearning to align cross-modality identities and minimize mutual information toseparate shared visual features. Experimental results show that MuteSwapachieves impressive performance in both speech synthesis and identityconversion, especially under noisy conditions where methods dependent on audioinput fail to produce intelligible results, demonstrating both theeffectiveness of our training approach and the feasibility of SFVC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional voice conversion modifies voice characteristics from a sourcespeaker to a target speaker, relying on audio input from both sides. However,this process becomes infeasible when clean audio is unavailable, such as insilent videos or noisy environments. In this work, we focus on the task ofSilent Face-based Voice Conversion (SFVC), which does voice conversion entirelyfrom visual inputs. i.e., given images of a target speaker and a silent videoof a source speaker containing lip motion, SFVC generates speech aligning theidentity of the target speaker while preserving the speech content in thesource silent video. As this task requires generating intelligible speech andconverting identity using only visual cues, it is particularly challenging. Toaddress this, we introduce MuteSwap, a novel framework that employs contrastivelearning to align cross-modality identities and minimize mutual information toseparate shared visual features. Experimental results show that MuteSwapachieves impressive performance in both speech synthesis and identityconversion, especially under noisy conditions where methods dependent on audioinput fail to produce intelligible results, demonstrating both theeffectiveness of our training approach and the feasibility of SFVC.</description>
      <author>example@mail.com (Yifan Liu, Yu Fang, Zhouhan Lin)</author>
      <guid isPermaLink="false">2507.00498v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>ADAptation: Reconstruction-based Unsupervised Active Learning for Breast Ultrasound Diagnosis</title>
      <link>http://arxiv.org/abs/2507.00474v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 4 figures, 4 tables. Accepted by conference MICCAI2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ADAptation的深度学习诊断模型，用于解决训练集和测试集之间分布差异导致的性能下降问题。&lt;h4&gt;背景&lt;/h4&gt;深度学习诊断模型在训练集和测试集之间由于分布差异常常出现性能下降，收集和标注足够的目标域数据成本高且资源稀缺。&lt;h4&gt;目的&lt;/h4&gt;通过提出一种新的无监督主动学习框架，旨在在有限的标注预算下，从多域数据池中高效地选择信息量大的样本。&lt;h4&gt;方法&lt;/h4&gt;该方法首先利用扩散模型的分布同化能力，将目标图像转换为源域风格以弥合跨数据集的差距。然后引入两项关键创新：(a)一个超球面约束对比学习网络，用于紧凑的特征聚类；(b)一个双评分机制，用于量化并平衡样本的不确定性和代表性。&lt;h4&gt;主要发现&lt;/h4&gt;在四个乳腺超声数据集（三个公开和一个内部/多中心）上进行的广泛实验表明，该方法优于现有的基于主动学习的强竞争对手，验证了其在临床域适应中的有效性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在减少标注成本的同时，保持了模型的性能，适用于临床域适应。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于深度学习的诊断模型通常因训练（源域）和测试（目标域）之间的分布差异而性能下降。收集和标注足够的目标域数据以重新训练模型是一个最佳解决方案，但受限于时间和稀缺的资源。主动学习（AL）提供了一种在保持性能的同时减少标注成本的高效方法，但难以应对不同数据集之间分布变化带来的挑战。在本研究中，我们提出了一种新的无监督主动学习框架，用于域适应，命名为ADAptation，该框架在有限的标注预算下，能够有效地从多域数据池中选择信息量大的样本。作为一个基本步骤，我们的方法首先利用扩散模型的分布同化能力，通过将目标图像转换为源域风格来弥合跨数据集的差距。然后，我们引入了两项关键创新：(a)一个超球面约束对比学习网络，用于紧凑的特征聚类；(b)一个双评分机制，用于量化并平衡样本的不确定性和代表性。在五个常见的深度分类器上，对四个乳腺超声数据集（三个公开和一个内部/多中心）进行的广泛实验表明，我们的方法优于现有的基于主动学习的强竞争对手，验证了其在临床域适应中的有效性和泛化能力。代码可在匿名链接处获取：https://github.com/miccai25-966/ADAptation。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning-based diagnostic models often suffer performance drops due todistribution shifts between training (source) and test (target) domains.Collecting and labeling sufficient target domain data for model retrainingrepresents an optimal solution, yet is limited by time and scarce resources.Active learning (AL) offers an efficient approach to reduce annotation costswhile maintaining performance, but struggles to handle the challenge posed bydistribution variations across different datasets. In this study, we propose anovel unsupervised Active learning framework for Domain Adaptation, namedADAptation, which efficiently selects informative samples from multi-domaindata pools under limited annotation budget. As a fundamental step, our methodfirst utilizes the distribution homogenization capabilities of diffusion modelsto bridge cross-dataset gaps by translating target images into source-domainstyle. We then introduce two key innovations: (a) a hypersphere-constrainedcontrastive learning network for compact feature clustering, and (b) adual-scoring mechanism that quantifies and balances sample uncertainty andrepresentativeness. Extensive experiments on four breast ultrasound datasets(three public and one in-house/multi-center) across five common deepclassifiers demonstrate that our method surpasses existing strong AL-basedcompetitors, validating its effectiveness and generalization for clinicaldomain adaptation. The code is available at the anonymized link:https://github.com/miccai25-966/ADAptation.</description>
      <author>example@mail.com (Yaofei Duan, Yuhao Huang, Xin Yang, Luyi Han, Xinyu Xie, Zhiyuan Zhu, Ping He, Ka-Hou Chan, Ligang Cui, Sio-Kei Im, Dong Ni, Tao Tan)</author>
      <guid isPermaLink="false">2507.00474v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding</title>
      <link>http://arxiv.org/abs/2507.00068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MANTA是一个将视觉和听觉输入统一到结构化文本空间的多模态学习框架，通过文本对齐实现多模态抽象和归一化，以提高大语言模型处理多模态数据的能力。&lt;h4&gt;背景&lt;/h4&gt;现有多模态学习方法通常将模态分开处理，导致表示和推理上的不一致。&lt;h4&gt;目的&lt;/h4&gt;提出MANTA框架，解决多模态学习中的四个关键挑战：模态间语义对齐、自适应时间同步、分层内容表示和上下文感知信息检索。&lt;h4&gt;方法&lt;/h4&gt;在严谨的数学框架内形式化方法，通过信息论优化实现模态间语义对齐，采用自适应时间同步技术处理不同信息密度的数据，使用分层内容表示实现多尺度理解，并引入新密度估计技术以减少冗余并保留稀有信号。&lt;h4&gt;主要发现&lt;/h4&gt;在长视频问答任务上，MANTA将最先进模型的总体准确率提高了最多22.6%，在超过30分钟的视频上提高了27.3%。此外，MANTA在时间推理任务上提高了23.8%，在跨模态理解上提高了25.1%。&lt;h4&gt;结论&lt;/h4&gt;MANTA通过结构化文本统一多模态表示，为多模态学习提供了新的基础。&lt;h4&gt;翻译&lt;/h4&gt;虽然多模态学习取得了显著进展，但当前方法通常将模态分开处理，导致表示和推理上存在不一致。我们提出了MANTA（通过文本对齐的多模态抽象和归一化），这是一个基于理论的框架，它将视觉和听觉输入统一到一个结构化的文本空间中，以便与大语言模型无缝处理。MANTA解决了四个关键挑战：（1）通过信息论优化实现模态间的语义对齐，（2）对变化的信息密度进行自适应时间同步，（3）使用分层内容表示进行多尺度理解，（4）从长序列中上下文感知地检索稀疏信息。我们在严格的数学框架内形式化了我们的方法，证明了它在标记约束下的上下文选择的优化性。在具有挑战性的长视频问答任务上进行的广泛实验表明，MANTA将最先进模型的总体准确率提高了最多22.6%，在超过30分钟的视频上提高了27.3%。此外，我们还证明了MANTA在时间推理任务（提高了23.8%）和跨模态理解（提高了25.1%）上的优越性。我们的框架引入了新的密度估计技术，以减少冗余并保留稀有信号，为通过结构化文本统一多模态表示奠定了新的基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While multi-modal learning has advanced significantly, current approachesoften treat modalities separately, creating inconsistencies in representationand reasoning. We introduce MANTA (Multi-modal Abstraction and Normalizationvia Textual Alignment), a theoretically-grounded framework that unifies visualand auditory inputs into a structured textual space for seamless processingwith large language models. MANTA addresses four key challenges: (1) semanticalignment across modalities with information-theoretic optimization, (2)adaptive temporal synchronization for varying information densities, (3)hierarchical content representation for multi-scale understanding, and (4)context-aware retrieval of sparse information from long sequences. We formalizeour approach within a rigorous mathematical framework, proving its optimalityfor context selection under token constraints. Extensive experiments on thechallenging task of Long Video Question Answering show that MANTA improvesstate-of-the-art models by up to 22.6% in overall accuracy, with particularlysignificant gains (27.3%) on videos exceeding 30 minutes. Additionally, wedemonstrate MANTA's superiority on temporal reasoning tasks (23.8% improvement)and cross-modal understanding (25.1% improvement). Our framework introducesnovel density estimation techniques for redundancy minimization whilepreserving rare signals, establishing new foundations for unifying multimodalrepresentations through structured text.</description>
      <author>example@mail.com (Ziqi Zhong, Daniel Tang)</author>
      <guid isPermaLink="false">2507.00068v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks in Wind Power Forecasting</title>
      <link>http://arxiv.org/abs/2507.00105v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNNs）在风力发电预测问题上的适用性。&lt;h4&gt;背景&lt;/h4&gt;研究基于三个风力发电设施，使用五年历史数据。&lt;h4&gt;目的&lt;/h4&gt;评估GNNs在风力发电预测中的性能。&lt;h4&gt;方法&lt;/h4&gt;在三个风力发电设施上，使用五年历史数据，以数值天气预报（NWP）变量作为预测因子，对模型进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;某些架构的性能与最佳的基于卷积神经网络（CNN）的基准相当。&lt;h4&gt;结论&lt;/h4&gt;GNNs在风力发电预测中具有应用潜力。&lt;h4&gt;翻译&lt;/h4&gt;We study the applicability of GNNs to the problem of wind energy forecasting. We find that certain architectures achieve performance comparable to our bestCNN-based benchmark. The study is conducted on three wind power facilities using five years of historical data. Numerical Weather Prediction (NWP) variables were used as predictors, and models were evaluated on a 24 to 36 hour ahead test horizon.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the applicability of GNNs to the problem of wind energy forecasting.We find that certain architectures achieve performance comparable to our bestCNN-based benchmark. The study is conducted on three wind power facilitiesusing five years of historical data. Numerical Weather Prediction (NWP)variables were used as predictors, and models were evaluated on a 24 to 36 hourahead test horizon.</description>
      <author>example@mail.com (Javier Castellano, Ignacio Villanueva)</author>
      <guid isPermaLink="false">2507.00105v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>GPT, But Backwards: Exactly Inverting Language Model Outputs</title>
      <link>http://arxiv.org/abs/2507.01693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages, ICML 2025 Workshop on Reliable and Responsible Foundation  Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对大型语言模型（LLMs）的审计技术，旨在通过重建导致现有LLM输出的确切输入，实现事后分析和潜在地检测伪造输出报告。&lt;h4&gt;背景&lt;/h4&gt;现有的审计技术试图识别大型语言模型中的潜在不良行为，而本文则关注于重建导致特定输出的确切输入这一互补的取证问题。&lt;h4&gt;目的&lt;/h4&gt;实现事后分析，并可能检测到伪造的输出报告。&lt;h4&gt;方法&lt;/h4&gt;将精确输入重建形式化为具有唯一全局最小值的离散优化问题，并引入了SODA算法，该算法在输入搜索空间的连续松弛上运行，具有周期性重启和参数衰减。&lt;h4&gt;主要发现&lt;/h4&gt;在涵盖从3300万到30亿参数的大型语言模型上进行的全面实验表明，SODA算法显著优于现有方法。成功从下一个令牌对数中完全恢复79.5%的短输入，没有错误警报，但难以从长（15+令牌）输入序列的输出中提取私人信息。&lt;h4&gt;结论&lt;/h4&gt;这表明，标准的部署实践可能目前足以提供对恶意使用此方法的保护。&lt;h4&gt;翻译&lt;/h4&gt;While existing auditing techniques attempt to identify potential unwantedbehaviours in large language models (LLMs), we address the complementary forensic problem of reconstructing the exact input that led to an existing LLM output - enabling post-incident analysis and potentially the detection of fakeoutput reports. We formalize exact input reconstruction as a discreteoptimisation problem with a unique global minimum and introduce SODA, anefficient gradient-based algorithm that operates on a continuous relaxation ofthe input search space with periodic restarts and parameter decay. Throughcomprehensive experiments on LLMs ranging in size from 33M to 3B parameters, wedemonstrate that SODA significantly outperforms existing approaches. We succeedin fully recovering 79.5% of shorter out-of-distribution inputs from next-tokenlogits, without a single false positive, but struggle to extract privateinformation from the outputs of longer (15+ token) input sequences. Thissuggests that standard deployment practices may currently provide adequateprotection against malicious use of our method. Our code is available athttps://doi.org/10.5281/zenodo.15539879.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While existing auditing techniques attempt to identify potential unwantedbehaviours in large language models (LLMs), we address the complementaryforensic problem of reconstructing the exact input that led to an existing LLMoutput - enabling post-incident analysis and potentially the detection of fakeoutput reports. We formalize exact input reconstruction as a discreteoptimisation problem with a unique global minimum and introduce SODA, anefficient gradient-based algorithm that operates on a continuous relaxation ofthe input search space with periodic restarts and parameter decay. Throughcomprehensive experiments on LLMs ranging in size from 33M to 3B parameters, wedemonstrate that SODA significantly outperforms existing approaches. We succeedin fully recovering 79.5% of shorter out-of-distribution inputs from next-tokenlogits, without a single false positive, but struggle to extract privateinformation from the outputs of longer (15+ token) input sequences. Thissuggests that standard deployment practices may currently provide adequateprotection against malicious use of our method. Our code is available athttps://doi.org/10.5281/zenodo.15539879.</description>
      <author>example@mail.com (Adrians Skapars, Edoardo Manino, Youcheng Sun, Lucas C. Cordeiro)</author>
      <guid isPermaLink="false">2507.01693v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Inverse Design in Nanophotonics via Representation Learning</title>
      <link>http://arxiv.org/abs/2507.00546v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;纳米光子学中的逆向设计，通过计算发现实现特定电磁响应的结构，已成为近年来光学发展的关键工具。&lt;h4&gt;背景&lt;/h4&gt;传统的直觉驱动或迭代优化方法在处理高维、非凸的设计空间和电磁模拟的计算需求时存在困难。&lt;h4&gt;目的&lt;/h4&gt;利用机器学习（ML）来有效解决这些瓶颈。&lt;h4&gt;方法&lt;/h4&gt;本文通过代表学习的角度，将增强机器学习的逆向设计方法分为输出侧和输入侧两种方法。输出侧方法使用机器学习在解空间中学习表示以创建可微求解器，从而加速优化。相反，输入侧技术使用机器学习学习可行设备几何形状的紧凑、潜在空间表示，通过生成模型实现高效的全球探索。&lt;h4&gt;主要发现&lt;/h4&gt;每种策略在数据需求、泛化能力和新的设计发现潜力方面都有独特的权衡。&lt;h4&gt;结论&lt;/h4&gt;结合基于物理的优化与数据驱动表示的混合框架有助于逃离局部最优，提高可扩展性，并促进知识迁移。最后，本文强调了开放挑战和机遇，包括复杂性管理、几何无关表示、集成制造约束和多物理场协同设计的进步。&lt;h4&gt;翻译&lt;/h4&gt;摘要：纳米光子学中的逆向设计，即通过计算发现能够实现特定电磁响应的结构，已成为近年来光学发展的关键工具。传统的直觉驱动或迭代优化方法在处理高维、非凸的设计空间和电磁模拟的计算需求时存在困难。最近，机器学习（ML）被提出以有效解决这些瓶颈。本文通过代表学习的角度，将增强机器学习的逆向设计方法分为输出侧和输入侧两种方法。输出侧方法使用机器学习在解空间中学习表示以创建可微求解器，从而加速优化。相反，输入侧技术使用机器学习学习可行设备几何形状的紧凑、潜在空间表示，通过生成模型实现高效的全球探索。每种策略在数据需求、泛化能力和新的设计发现潜力方面都有独特的权衡。结合基于物理的优化与数据驱动表示的混合框架有助于逃离局部最优，提高可扩展性，并促进知识迁移。最后，本文强调了开放挑战和机遇，包括复杂性管理、几何无关表示、集成制造约束和多物理场协同设计的进步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Inverse design in nanophotonics, the computational discovery of structuresachieving targeted electromagnetic (EM) responses, has become a key tool forrecent optical advances. Traditional intuition-driven or iterative optimizationmethods struggle with the inherently high-dimensional, non-convex design spacesand the substantial computational demands of EM simulations. Recently, machinelearning (ML) has emerged to address these bottlenecks effectively. This reviewframes ML-enhanced inverse design methodologies through the lens ofrepresentation learning, classifying them into two categories: output-side andinput-side approaches. Output-side methods use ML to learn a representation inthe solution space to create a differentiable solver that acceleratesoptimization. Conversely, input-side techniques employ ML to learn compact,latent-space representations of feasible device geometries, enabling efficientglobal exploration through generative models. Each strategy presents uniquetrade-offs in data requirements, generalization capacity, and novel designdiscovery potentials. Hybrid frameworks that combine physics-based optimizationwith data-driven representations help escape poor local optima, improvescalability, and facilitate knowledge transfer. We conclude by highlightingopen challenges and opportunities, emphasizing complexity management,geometry-independent representations, integration of fabrication constraints,and advancements in multiphysics co-designs.</description>
      <author>example@mail.com (Reza Marzban, Ali Adibi, Raphael Pestourie)</author>
      <guid isPermaLink="false">2507.00546v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Causal Prompting for Implicit Sentiment Analysis with Large Language Models</title>
      <link>http://arxiv.org/abs/2507.00389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了CAPITAL，一种因果提示框架，用于隐式情感分析，通过将前门调整引入思维链推理，以解决现有方法中存在的内部偏差和虚假相关性问题。&lt;h4&gt;背景&lt;/h4&gt;隐式情感分析旨在推断隐含而非明确表达的情感，要求模型进行更深层次的推理。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有基于提示的隐式情感分析方法的不足，提出一种新的因果提示框架。&lt;h4&gt;方法&lt;/h4&gt;CAPITAL将总体因果效应分解为两个部分：输入提示对推理链的影响，以及这些链对最终输出的影响。使用编码器聚类和NWGM近似估计这两个部分，并通过对比学习目标更好地对齐编码器的表示与LLM的推理空间。&lt;h4&gt;主要发现&lt;/h4&gt;在基准隐式情感分析数据集上进行的实验表明，CAPITAL在准确性和鲁棒性方面均优于强大的提示基线，特别是在对抗条件下。&lt;h4&gt;结论&lt;/h4&gt;本文为将因果推理集成到LLM提示中提供了一种原则性的方法，并强调了其在具有偏差感知的情感推理方面的好处。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为CAPITAL的因果提示框架，用于隐式情感分析。该框架通过将前门调整引入思维链推理，解决了现有方法中存在的内部偏差和虚假相关性问题。在基准隐式情感分析数据集上进行的实验表明，CAPITAL在准确性和鲁棒性方面均优于现有的提示方法。这项工作为将因果推理集成到LLM提示中提供了一种原则性的方法，并强调了其在具有偏差感知的情感推理方面的优势。源代码和案例研究可在以下链接找到：https://github.com/whZ62/CAPITAL。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit Sentiment Analysis (ISA) aims to infer sentiment that is impliedrather than explicitly stated, requiring models to perform deeper reasoningover subtle contextual cues. While recent prompting-based methods using LargeLanguage Models (LLMs) have shown promise in ISA, they often rely on majorityvoting over chain-of-thought (CoT) reasoning paths without evaluating theircausal validity, making them susceptible to internal biases and spuriouscorrelations. To address this challenge, we propose CAPITAL, a causal promptingframework that incorporates front-door adjustment into CoT reasoning. CAPITALdecomposes the overall causal effect into two components: the influence of theinput prompt on the reasoning chains, and the impact of those chains on thefinal output. These components are estimated using encoder-based clustering andthe NWGM approximation, with a contrastive learning objective used to betteralign the encoder's representation with the LLM's reasoning space. Experimentson benchmark ISA datasets with three LLMs demonstrate that CAPITAL consistentlyoutperforms strong prompting baselines in both accuracy and robustness,particularly under adversarial conditions. This work offers a principledapproach to integrating causal inference into LLM prompting and highlights itsbenefits for bias-aware sentiment reasoning. The source code and case study areavailable at: https://github.com/whZ62/CAPITAL.</description>
      <author>example@mail.com (Jing Ren, Wenhao Zhou, Bowen Li, Mujie Liu, Nguyen Linh Dan Le, Jiade Cen, Liping Chen, Ziqi Xu, Xiwei Xu, Xiaodong Li)</author>
      <guid isPermaLink="false">2507.00389v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Geological Everything Model 3D: A Promptable Foundation Model for Unified and Zero-Shot Subsurface Understanding</title>
      <link>http://arxiv.org/abs/2507.00419v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;GEM（地质一切模型3D）是一个统一的生成架构，用于地质分析，它通过从地下成像中推导出的潜在结构框架进行提示条件下的推理，实现地质任务的统一处理。&lt;h4&gt;背景&lt;/h4&gt;理解地球的地下结构对于能源转型、自然灾害减轻和行星科学至关重要，但地下分析目前仍然是碎片化的，需要不同的模型来处理结构解释、地层分析、地质体分割和属性建模。&lt;h4&gt;目的&lt;/h4&gt;提出GEM的目的是为了解决地下分析中的碎片化问题，实现不同地质任务的统一处理。&lt;h4&gt;方法&lt;/h4&gt;GEM通过一个两阶段的训练过程来实现这一目标，包括在大规模野外地震数据上进行的自监督表示学习，以及使用混合提示和标签的对抗性微调。&lt;h4&gt;主要发现&lt;/h4&gt;GEM能够通过共享的推理机制处理不同类型的提示，实现零样本泛化，无需针对新任务或数据源进行重新训练。&lt;h4&gt;结论&lt;/h4&gt;GEM展示了在多个调查和任务中的广泛适用性，并且通过结合专家知识和生成推理，为可扩展的、具有人类参与的地球物理人工智能奠定了基础，从而将碎片化的管道转变为一个垂直集成、可提示的推理系统。&lt;h4&gt;翻译&lt;/h4&gt;Understanding Earth's subsurface is critical for energy transition, natural hazard mitigation, and planetary science. Yet subsurface analysis remains fragmented, with separate models required for structural interpretation, stratigraphic analysis, geobody segmentation, and property modeling—each tightly coupled to specific data distributions and task formulations. We introduce the Geological Everything Model 3D (GEM), a unified generative architecture that reformulates all these tasks as prompt-conditioned inference along latent structural frameworks derived from subsurface imaging. This formulation moves beyond task-specific models by enabling a shared inference mechanism, where GEM propagates human-provided prompts—such as well logs, masks, or structural sketches—along inferred structural frameworks to produce geologically coherent outputs. Through this mechanism, GEM achieves zero-shot generalization across tasks with heterogeneous prompt types, without retraining for new tasks or data sources. This capability emerges from a two-stage training process that combines self-supervised representation learning on large-scale field seismic data with adversarial fine-tuning using mixed prompts and labels across diverse subsurface tasks. GEM demonstrates broad applicability across surveys and tasks, including Martian radar stratigraphic analysis, structural interpretation in subduction zones, full seismic stratigraphic interpretation, geobody delineation, and property modeling. By bridging expert knowledge with generative reasoning in a structurally aware manner, GEM lays the foundation for scalable, human-in-the-loop geophysical AI—transitioning from fragmented pipelines to a vertically integrated, promptable reasoning system. Project page: https://douyimin.github.io/GEM&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding Earth's subsurface is critical for energy transition, naturalhazard mitigation, and planetary science. Yet subsurface analysis remainsfragmented, with separate models required for structural interpretation,stratigraphic analysis, geobody segmentation, and property modeling-eachtightly coupled to specific data distributions and task formulations. Weintroduce the Geological Everything Model 3D (GEM), a unified generativearchitecture that reformulates all these tasks as prompt-conditioned inferencealong latent structural frameworks derived from subsurface imaging. Thisformulation moves beyond task-specific models by enabling a shared inferencemechanism, where GEM propagates human-provided prompts-such as well logs,masks, or structural sketches-along inferred structural frameworks to producegeologically coherent outputs. Through this mechanism, GEM achieves zero-shotgeneralization across tasks with heterogeneous prompt types, without retrainingfor new tasks or data sources. This capability emerges from a two-stagetraining process that combines self-supervised representation learning onlarge-scale field seismic data with adversarial fine-tuning using mixed promptsand labels across diverse subsurface tasks. GEM demonstrates broadapplicability across surveys and tasks, including Martian radar stratigraphyanalysis, structural interpretation in subduction zones, full seismicstratigraphic interpretation, geobody delineation, and property modeling. Bybridging expert knowledge with generative reasoning in a structurally awaremanner, GEM lays the foundation for scalable, human-in-the-loop geophysicalAI-transitioning from fragmented pipelines to a vertically integrated,promptable reasoning system. Project page: https://douyimin.github.io/GEM</description>
      <author>example@mail.com (Yimin Dou, Xinming Wu, Nathan L Bangs, Harpreet Singh Sethi, Jintao Li, Hang Gao, Zhixiang Guo)</author>
      <guid isPermaLink="false">2507.00419v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Room Scene Discovery and Grouping in Unstructured Vacation Rental Image Collections</title>
      <link>http://arxiv.org/abs/2507.00263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种有效的方法来解决房间场景发现和分组问题，以及识别每个卧室组中的床型。该方法适用于实时和数据稀缺的环境，并显著优于现有的对比学习和预训练嵌入聚类方法。&lt;h4&gt;背景&lt;/h4&gt;随着度假租赁平台的发展，大量的房产图片被上传，但缺乏结构化分类，给旅行者理解房产的空间布局带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种计算效率高的机器学习流程，用于房间场景发现、分组和床型识别。&lt;h4&gt;方法&lt;/h4&gt;该流程包括一个监督式房间类型检测模型，一个监督式重叠检测模型用于识别两张图片之间的重叠相似度，以及一个聚类算法用于根据相似度将同一空间的图片分组。此外，使用多模态大型语言模型（MLLM）将每个卧室组映射到房产元数据中指定的对应床型。&lt;h4&gt;主要发现&lt;/h4&gt;该流程在单独评估模型和整体评估时都表现出强大的性能，显著优于现有的方法。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在房间场景发现、分组和床型识别方面表现出色，适用于实时和数据稀缺的环境，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;The rapid growth of vacation rental (VR) platforms has led to an increasing volume of property images, often uploaded without structured categorization. This lack of organization poses significant challenges for travelers attempting to understand the spatial layout of a property, particularly when multiple rooms of the same type are present. To address this issue, we introduce an effective approach for solving the room scene discovery and grouping problem, as well as identifying bed types within each bedroom group. This grouping is valuable for travelers to comprehend the spatial organization, layout, and the sleeping configuration of the property. We propose a computationally efficient machine learning pipeline characterized by low latency and the ability to perform effectively with sample-efficient learning, making it well-suited for real-time and data-scarce environments. The pipeline integrates a supervised room-type detection model, a supervised overlap detection model to identify the overlap similarity between two images, and a clustering algorithm to group the images of the same space together using the similarity scores. Additionally, the pipeline maps each bedroom group to the corresponding bed types specified in the property's metadata, based on the visual content present in the group's images using a Multi-modal Large Language Model (MLLM) model. We evaluate the aforementioned models individually and also assess the pipeline in its entirety, observing strong performance that significantly outperforms established approaches such as contrastive learning and clustering with pretrained embeddings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of vacation rental (VR) platforms has led to an increasingvolume of property images, often uploaded without structured categorization.This lack of organization poses significant challenges for travelers attemptingto understand the spatial layout of a property, particularly when multiplerooms of the same type are present. To address this issue, we introduce aneffective approach for solving the room scene discovery and grouping problem,as well as identifying bed types within each bedroom group. This grouping isvaluable for travelers to comprehend the spatial organization, layout, and thesleeping configuration of the property. We propose a computationally efficientmachine learning pipeline characterized by low latency and the ability toperform effectively with sample-efficient learning, making it well-suited forreal-time and data-scarce environments. The pipeline integrates a supervisedroom-type detection model, a supervised overlap detection model to identify theoverlap similarity between two images, and a clustering algorithm to group theimages of the same space together using the similarity scores. Additionally,the pipeline maps each bedroom group to the corresponding bed types specifiedin the property's metadata, based on the visual content present in the group'simages using a Multi-modal Large Language Model (MLLM) model. We evaluate theaforementioned models individually and also assess the pipeline in itsentirety, observing strong performance that significantly outperformsestablished approaches such as contrastive learning and clustering withpretrained embeddings.</description>
      <author>example@mail.com (Vignesh Ram Nithin Kappagantula, Shayan Hassantabar)</author>
      <guid isPermaLink="false">2507.00263v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>VOCAL: Visual Odometry via ContrAstive Learning</title>
      <link>http://arxiv.org/abs/2507.00243v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VOCAL（通过对比学习进行视觉里程计）是一种新的框架，它将视觉里程计重新构想为标签排序挑战，通过结合贝叶斯推理和表示学习框架，提升了视觉里程计的可解释性和灵活性。&lt;h4&gt;背景&lt;/h4&gt;视觉里程计（VO）在机器人领域取得了突破，但许多基于学习的VO技术依赖于刚性几何假设，这限制了其可解释性和理论基础。&lt;h4&gt;目的&lt;/h4&gt;克服基于学习的VO技术的局限性，提高其可解释性和理论基础。&lt;h4&gt;方法&lt;/h4&gt;VOCAL通过将视觉里程计视为标签排序挑战，结合贝叶斯推理和表示学习框架，将视觉特征组织起来以反映相机状态，并通过排名机制确保相似相机状态在潜在空间中的空间一致性。&lt;h4&gt;主要发现&lt;/h4&gt;VOCAL增强了学习特征的可解释性，并确保了与多模态数据源的兼容性。&lt;h4&gt;结论&lt;/h4&gt;VOCAL在KITTI数据集上的广泛评估显示了其增强的可解释性和灵活性，推动了视觉里程计向更通用和可解释的空间智能发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视觉里程计（VO）的突破从根本上改变了机器人领域的格局，使超精确的相机状态估计成为现代自主系统不可或缺的一部分。尽管取得了这些进步，但许多基于学习的VO技术仍然依赖于刚性的几何假设，这通常在可解释性和在完全数据驱动框架中的理论基础方面表现不足。为了克服这些限制，我们引入了VOCAL（通过对比学习进行视觉里程计），这是一个新颖的框架，它将VO重新构想为标签排序挑战。通过结合贝叶斯推理和表示学习框架，VOCAL将视觉特征组织起来以反映相机状态。排名机制迫使相似的相机状态在潜在空间中收敛到一致且空间上连贯的表示。这种战略性的对齐不仅增强了学习特征的可解释性，还确保了与多模态数据源的兼容性。在KITTI数据集上的广泛评估突出了VOCAL增强的可解释性和灵活性，推动了VO向更通用和可解释的空间智能发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Breakthroughs in visual odometry (VO) have fundamentally reshaped thelandscape of robotics, enabling ultra-precise camera state estimation that iscrucial for modern autonomous systems. Despite these advances, manylearning-based VO techniques rely on rigid geometric assumptions, which oftenfall short in interpretability and lack a solid theoretical basis within fullydata-driven frameworks. To overcome these limitations, we introduce VOCAL(Visual Odometry via ContrAstive Learning), a novel framework that reimaginesVO as a label ranking challenge. By integrating Bayesian inference with arepresentation learning framework, VOCAL organizes visual features to mirrorcamera states. The ranking mechanism compels similar camera states to convergeinto consistent and spatially coherent representations within the latent space.This strategic alignment not only bolsters the interpretability of the learnedfeatures but also ensures compatibility with multimodal data sources. Extensiveevaluations on the KITTI dataset highlight VOCAL's enhanced interpretabilityand flexibility, pushing VO toward more general and explainable spatialintelligence.</description>
      <author>example@mail.com (Chi-Yao Huang, Zeel Bhatt, Yezhou Yang)</author>
      <guid isPermaLink="false">2507.00243v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>MARVIS: Modality Adaptive Reasoning over VISualizations</title>
      <link>http://arxiv.org/abs/2507.01544v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MARVIS的无需训练的方法，能够使小型视觉语言模型预测任何数据模态，并取得了在视觉、音频、生物和表格领域上的优异表现。&lt;h4&gt;背景&lt;/h4&gt;机器学习在科学应用中通常依赖于针对特定领域调优的小型专用模型，这些模型虽然性能出色，但缺乏灵活性。基础模型虽然具有通用性，但在非传统模态和长尾领域上通常表现不如专用方法。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需训练的方法，使得小型视觉语言模型能够高精度地预测任何数据模态。&lt;h4&gt;方法&lt;/h4&gt;MARVIS通过将潜在嵌入空间转换为视觉表示，并利用视觉语言模型的空间和细粒度推理能力，成功解释和利用这些表示。&lt;h4&gt;主要发现&lt;/h4&gt;MARVIS使用单个3B参数模型在视觉、音频、生物和表格领域上取得了具有竞争力的性能，平均比Gemini模型高出16%，并接近专用方法，同时不泄露个人可识别信息（P.I.I.）且无需特定领域的训练。&lt;h4&gt;结论&lt;/h4&gt;MARVIS是一种有效的无需训练的方法，能够使小型视觉语言模型在多个数据模态上实现高性能预测，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：科学应用中的机器学习通常依赖于针对特定领域调优的小型专用模型。这些模型通常能够达到优异的性能，但缺乏灵活性。基础模型提供了通用性，但在非传统模态和长尾领域上通常表现不如专用方法。我们提出了MARVIS（基于视觉的模态自适应推理），一种无需训练的方法，使得即使是小型视觉语言模型也能以高精度预测任何数据模态。MARVIS将潜在嵌入空间转换为视觉表示，然后利用视觉语言模型的空间和细粒度推理技能成功解释和利用这些表示。使用单个3B参数模型，MARVIS在视觉、音频、生物和表格领域上实现了具有竞争力的性能，平均比Gemini高出16%，并接近专用方法，同时不泄露个人可识别信息（P.I.I.）或需要任何特定领域的训练。我们已在https://github.com/penfever/marvis开源了我们的代码和数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scientific applications of machine learning often rely on small, specializedmodels tuned to particular domains. Such models often achieve excellentperformance, but lack flexibility. Foundation models offer versatility, buttypically underperform specialized approaches, especially on non-traditionalmodalities and long-tail domains. We propose MARVIS (Modality AdaptiveReasoning over VISualizations), a training-free method that enables even smallvision-language models to predict any data modality with high accuracy. MARVIStransforms latent embedding spaces into visual representations and thenleverages the spatial and fine-grained reasoning skills of VLMs to successfullyinterpret and utilize them. MARVIS achieves competitive performance on vision,audio, biological, and tabular domains using a single 3B parameter model,achieving results that beat Gemini by 16\% on average and approach specializedmethods, without exposing personally identifiable information (P.I.I.) orrequiring any domain-specific training. We open source our code and datasets athttps://github.com/penfever/marvis</description>
      <author>example@mail.com (Benjamin Feuer, Lennart Purucker, Oussama Elachqar, Chinmay Hegde)</author>
      <guid isPermaLink="false">2507.01544v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>AVC-DPO: Aligned Video Captioning via Direct Preference Optimization</title>
      <link>http://arxiv.org/abs/2507.01492v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AVC-DPO的框架，旨在通过直接偏好优化来调整视频描述的焦点，从而提高视频多模态大型语言模型在视频描述任务中的性能。&lt;h4&gt;背景&lt;/h4&gt;尽管视频多模态大型语言模型在视频描述任务上取得了显著进展，但根据人类偏好调整视频描述的焦点仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本研究旨在通过偏好对齐来增强视频多模态大型语言模型的描述能力。&lt;h4&gt;方法&lt;/h4&gt;AVC-DPO设计了一种增强的提示，专门针对视频中的时间和空间信息，这两个因素是人类观看视频时关注的重点。该方法利用同一基础模型在不同提示条件下的描述生成响应来进行偏好感知训练和描述对齐。&lt;h4&gt;主要发现&lt;/h4&gt;使用AVC-DPO框架，在LOVE@CVPR'25研讨会第1A轨道的视频详细描述挑战中取得了卓越的性能，根据VDCSCORE评估指标，在视频详细描述（VDC）基准测试中排名第一。&lt;h4&gt;结论&lt;/h4&gt;AVC-DPO框架能够有效提高视频多模态大型语言模型在视频描述任务中的性能，特别是在根据人类偏好调整描述焦点方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although video multimodal large language models (video MLLMs) have achievedsubstantial progress in video captioning tasks, it remains challenging toadjust the focal emphasis of video captions according to human preferences. Toaddress this limitation, we propose Aligned Video Captioning via DirectPreference Optimization (AVC-DPO), a post-training framework designed toenhance captioning capabilities in video MLLMs through preference alignment.Our approach designs enhanced prompts that specifically target temporaldynamics and spatial information-two key factors that humans care about whenwatching a video-thereby incorporating human-centric preferences. AVC-DPOleverages the same foundation model's caption generation responses under variedprompt conditions to conduct preference-aware training and caption alignment.Using this framework, we have achieved exceptional performance in theLOVE@CVPR'25 Workshop Track 1A: Video Detailed Captioning Challenge, achievingfirst place on the Video Detailed Captioning (VDC) benchmark according to theVDCSCORE evaluation metric.</description>
      <author>example@mail.com (Jiyang Tang, Hengyi Li, Yifan Du, Wayne Xin Zhao)</author>
      <guid isPermaLink="false">2507.01492v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>An efficient plant disease detection using transfer learning approach</title>
      <link>http://arxiv.org/abs/2507.00070v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages , 4 figures. Scientific Reports 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于迁移学习的植物病害检测系统，利用YOLOv7和YOLOv8模型进行植物病害的自动识别和监测，提高了病害检测的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;植物病害对农民和农业行业造成重大挑战，早期检测对于减轻病害影响和防止广泛损害至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个系统，用于识别和监测植物病害，以减轻病害对农作物生产力和质量的影响。&lt;h4&gt;方法&lt;/h4&gt;研究使用了YOLOv7和YOLOv8两种先进的对象检测模型，通过在植物叶片图像数据集上进行微调，使系统能够准确检测细菌、真菌和病毒病害，如白粉病、角斑病、早疫病和番茄花叶病毒。&lt;h4&gt;主要发现&lt;/h4&gt;模型在平均精度（mAP）、F1分数、精确度和召回率等指标上分别达到了91.05、89.40、91.22和87.66，显示出YOLOv8相较于其他对象检测方法具有更高的有效性和效率。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法为早期植物病害检测提供了一个可扩展的自动化解决方案，有助于提高作物产量，减少对人工监测的依赖，并支持可持续的农业实践。&lt;h4&gt;翻译&lt;/h4&gt;摘要：植物病害对农民及整个农业行业构成重大挑战。然而，早期检测植物病害对于减轻其影响和预防广泛损害至关重要，因为病害爆发会严重影响到作物的生产力和质量。随着技术的进步，自动化监测和检测植物病害的机会越来越多。本研究提出了一种系统，旨在利用迁移学习方法来识别和监测植物病害。具体而言，该研究利用了YOLOv7和YOLOv8，这是对象检测领域的两种最先进的模型。通过在植物叶片图像数据集上对这些模型进行微调，该系统能够准确检测细菌、真菌和病毒病害，例如白粉病、角斑病、早疫病和番茄花叶病毒。使用包括平均精度（mAP）、F1分数、精确度和召回率在内的多个指标评估了模型的性能，分别得到91.05、89.40、91.22和87.66的值。结果证明了YOLOv8相较于其他对象检测方法具有优越的有效性和效率，突显了其在现代农业实践中的应用潜力。该方法为早期植物病害检测提供了一个可扩展的自动化解决方案，有助于提高作物产量，减少对人工监测的依赖，并支持可持续的农业实践。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1038/s41598-025-02271-w&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Plant diseases pose significant challenges to farmers and the agriculturalsector at large. However, early detection of plant diseases is crucial tomitigating their effects and preventing widespread damage, as outbreaks canseverely impact the productivity and quality of crops. With advancements intechnology, there are increasing opportunities for automating the monitoringand detection of disease outbreaks in plants. This study proposed a systemdesigned to identify and monitor plant diseases using a transfer learningapproach. Specifically, the study utilizes YOLOv7 and YOLOv8, twostate-ofthe-art models in the field of object detection. By fine-tuning thesemodels on a dataset of plant leaf images, the system is able to accuratelydetect the presence of Bacteria, Fungi and Viral diseases such as PowderyMildew, Angular Leaf Spot, Early blight and Tomato mosaic virus. The model'sperformance was evaluated using several metrics, including mean AveragePrecision (mAP), F1-score, Precision, and Recall, yielding values of 91.05,89.40, 91.22, and 87.66, respectively. The result demonstrates the superioreffectiveness and efficiency of YOLOv8 compared to other object detectionmethods, highlighting its potential for use in modern agricultural practices.The approach provides a scalable, automated solution for early any plantdisease detection, contributing to enhanced crop yield, reduced reliance onmanual monitoring, and supporting sustainable agricultural practices.</description>
      <author>example@mail.com (Bosubabu Sambana, Hillary Sunday Nnadi, Mohd Anas Wajid, Nwosu Ogochukwu Fidelia, Claudia Camacho-Zuñiga, Henry Dozie Ajuzie, Edeh Michael Onyema)</author>
      <guid isPermaLink="false">2507.00070v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think</title>
      <link>http://arxiv.org/abs/2507.01467v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为REG的方法，用于改善扩散模型的训练挑战，通过将低级图像潜在特征与预训练模型中的高级分类标记结合，实现从纯噪声直接生成连贯的图像-类别对，显著提高了生成质量和训练效率。&lt;h4&gt;背景&lt;/h4&gt;REPA及其变体通过整合外部视觉表示来减轻扩散模型的训练挑战，通过噪声隐藏投影与基础清晰图像表示的对齐来实现。然而，这种对齐在去噪推理过程中始终缺失，未能充分利用判别性表示的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出REG方法，以实现从纯噪声直接生成连贯的图像-类别对，提高生成质量和训练效率。&lt;h4&gt;方法&lt;/h4&gt;REG方法通过将低级图像潜在特征与预训练模型中的高级分类标记结合，用于去噪，并通过同时重建图像潜在特征及其对应的全局语义来指导图像生成过程。&lt;h4&gt;主要发现&lt;/h4&gt;REG方法在不显著增加推理开销的情况下（仅增加一个额外的标记，FLOPs和延迟增加&lt;0.5%），显著提高了生成质量和训练效率。在ImageNet 256×256数据集上，SiT-XL/2 + REG的收敛速度比SiT-XL/2和SiT-XL/2 + REPA快63倍和23倍。更重要的是，SiT-L/2 + REG经过400K次迭代训练的性能优于SiT-XL/2 + REPA经过4M次迭代训练的性能（后者训练时间长10倍）。&lt;h4&gt;结论&lt;/h4&gt;REG方法为扩散模型提供了一种有效提高生成质量和训练效率的新途径，具有显著的实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为Representation Entanglement for Generation (REG)的方法，用于有效地缓解扩散模型在训练过程中所面临的挑战。该方法通过将低级图像潜在特征与预训练基础模型中的一个高级类别标记结合，从而直接从纯噪声中生成连贯的图像-类别对，显著提升了生成质量和训练效率。REG方法在推理过程中只需增加一个额外的标记，对FLOPs和延迟的影响可以忽略不计（增加&lt;0.5%），同时能够同时重建图像潜在特征及其对应的全局语义，从而主动引导并增强图像生成过程。在ImageNet 256×256数据集上，与SiT-XL/2和SiT-XL/2 + REPA相比，SiT-XL/2 + REG的收敛速度分别快63倍和23倍。更为令人印象深刻的是，SiT-L/2 + REG仅经过400K次迭代训练，其性能就优于SiT-XL/2 + REPA经过4M次迭代训练。代码可在https://github.com/Martinser/REG获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; REPA and its variants effectively mitigate training challenges in diffusionmodels by incorporating external visual representations from pretrained models,through alignment between the noisy hidden projections of denoising networksand foundational clean image representations. We argue that the externalalignment, which is absent during the entire denoising inference process, fallsshort of fully harnessing the potential of discriminative representations. Inthis work, we propose a straightforward method called RepresentationEntanglement for Generation (REG), which entangles low-level image latents witha single high-level class token from pretrained foundation models fordenoising. REG acquires the capability to produce coherent image-class pairsdirectly from pure noise, substantially improving both generation quality andtraining efficiency. This is accomplished with negligible additional inferenceoverhead, requiring only one single additional token for denoising (&lt;0.5\%increase in FLOPs and latency). The inference process concurrently reconstructsboth image latents and their corresponding global semantics, where the acquiredsemantic knowledge actively guides and enhances the image generation process.On ImageNet 256$\times$256, SiT-XL/2 + REG demonstrates remarkable convergenceacceleration, achieving $\textbf{63}\times$ and $\textbf{23}\times$ fastertraining than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively,SiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPAtrained for 4M iterations ($\textbf{10}\times$ longer). Code is available at:https://github.com/Martinser/REG.</description>
      <author>example@mail.com (Ge Wu, Shen Zhang, Ruijing Shi, Shanghua Gao, Zhenyuan Chen, Lei Wang, Zhaowei Chen, Hongcheng Gao, Yao Tang, Jian Yang, Ming-Ming Cheng, Xiang Li)</author>
      <guid isPermaLink="false">2507.01467v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation</title>
      <link>http://arxiv.org/abs/2507.01463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 3 figures, 3 tables, NeurIPS 2025 preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NOCTIS的新颖对象循环阈值实例分割框架，用于解决在给定示例图像的情况下对RGB图像中新颖对象实例进行分割的问题。&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉中，设计一个足够通用的模型，能够在不重新训练的情况下用于所有种类的未知对象，一直是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够自动分割RGB图像中新颖对象实例的模型，且无需额外训练。&lt;h4&gt;方法&lt;/h4&gt;NOCTIS框架利用Grounded-SAM 2获取具有精确边界框及其对应分割掩膜的物体提案；同时使用DINOv2的零样本能力生成图像嵌入。通过比较类别嵌入和平均最大相似性的相似度来确定物体匹配分数，并通过提案-对象匹配实现。此外，还使用提案边界框和掩膜的置信度作为额外加权因子。&lt;h4&gt;主要发现&lt;/h4&gt;NOCTIS在BOP 2023挑战的“基于模型的未见对象2D分割”任务上，不经过进一步训练/微调，在七个核心数据集上优于最佳RGB和RGB-D方法。&lt;h4&gt;结论&lt;/h4&gt;NOCTIS是一个简单而强大的框架，能够在不重新训练的情况下有效分割RGB图像中的新颖对象实例。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Instance segmentation of novel objects instances in RGB images, given someexample images for each object, is a well known problem in computer vision.Designing a model general enough to be employed, for all kinds of novelobjects, without (re-) training, has proven to be a difficult task. To handlethis, we propose a simple, yet powerful, framework, called: Novel Object CyclicThreshold based Instance Segmentation (NOCTIS). This work stems from andimproves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it alsoleverages on recent vision foundation models, namely: Grounded-SAM 2 andDINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precisebounding boxes and their corresponding segmentation masks; while DINOv2'szero-shot capabilities are employed to generate the image embeddings. Thequality of those masks, together with their embeddings, is of vital importanceto our approach; as the proposal-object matching is realized by determining anobject matching score based on the similarity of the class embeddings and theaverage maximum similarity of the patch embeddings. Differently to SAM-6D,calculating the latter involves a prior patch filtering based on the distancebetween each patch and its corresponding cyclic/roundtrip patch in the imagegrid. Furthermore, the average confidence of the proposals' bounding box andmask is used as an additional weighting factor for the object matching score.We empirically show that NOCTIS, without further training/fine tuning,outperforms the best RGB and RGB-D methods on the seven core datasets of theBOP 2023 challenge for the "Model-based 2D segmentation of unseen objects"task.</description>
      <author>example@mail.com (Max Gandyra, Alessandro Santonicola, Michael Beetz)</author>
      <guid isPermaLink="false">2507.01463v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>TriVLA: A Unified Triple-System-Based Unified Vision-Language-Action Model for General Robot Control</title>
      <link>http://arxiv.org/abs/2507.01424v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了TriVLA模型，这是一种具有三系统架构的统一视觉-语言-动作模型，旨在提升机器人的一般操控能力。&lt;h4&gt;背景&lt;/h4&gt;近年来，视觉-语言模型（VLMs）在常识推理方面的进展促使视觉-语言-动作（VLA）模型的发展，使机器人能够执行通用操作。然而，现有的自回归VLA方法往往只捕获静态信息，忽视了动态信息，这对具身任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，论文提出了TriVLA模型，以实现更全面的机器人操控。&lt;h4&gt;方法&lt;/h4&gt;TriVLA模型包括视觉-语言模块（系统2）、动态感知模块（系统3）和政策学习模块（系统1）。视觉-语言模块通过视觉和语言指令解释环境，动态感知模块产生包含当前静态信息和预测未来动态的视觉表示，政策学习模块实时生成流畅的电机动作。TriVLA使用预训练的VLM模型和视频基础模型在机器人数据集上进行微调，并利用互联网人类操控数据。&lt;h4&gt;主要发现&lt;/h4&gt;实验评估显示，TriVLA运行速度约为36 Hz，在标准模拟基准测试和具有挑战性的真实世界操控任务上，超过了最先进的模仿学习基线。&lt;h4&gt;结论&lt;/h4&gt;TriVLA模型在提升机器人操控能力方面具有显著优势，能够有效地处理动态信息，并在实际应用中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes TriVLA, a unified Vision-Language-Action model with a triple-system architecture for general robot control. The vision-language module (System 2) interprets the environment through vision and language instructions. The dynamics perception module (System 3) inherently produces visual representations that encompass both current static information and predicted future dynamics, thereby providing valuable guidance for policy learning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trained video foundation model on robot datasets along with internet human manipulation data. The subsequent policy learning module (System 1) generates fluid motor actions in real time. Experimental evaluation demonstrates that TriVLA operates at approximately 36 Hz and surpasses state-of-the-art imitation learning baselines on standard simulation benchmarks as well as challenging real-world manipulation tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in vision-language models (VLMs) for common-sensereasoning have led to the development of vision-language-action (VLA) models,enabling robots to perform generalized manipulation. Although existingautoregressive VLA methods design a specific architecture like dual-system toleverage large-scale pretrained knowledge, they tend to capture staticinformation, often neglecting the dynamic aspects vital for embodied tasks. Tothis end, we propose TriVLA, a unified Vision-Language-Action model with atriple-system architecture for general robot control. The vision-languagemodule (System 2) interprets the environment through vision and languageinstructions. The dynamics perception module (System 3) inherently producesvisual representations that encompass both current static information andpredicted future dynamics, thereby providing valuable guidance for policylearning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trainedvideo foundation model on robot datasets along with internet human manipulationdata. The subsequent policy learning module (System 1) generates fluid motoractions in real time. Experimental evaluation demonstrates that TriVLA operatesat approximately 36 Hz and surpasses state-of-the-art imitation learningbaselines on standard simulation benchmarks as well as challenging real-worldmanipulation tasks.</description>
      <author>example@mail.com (Zhenyang Liu, Yongchong Gu, Sixiao Zheng, Xiangyang Xue, Yanwei Fu)</author>
      <guid isPermaLink="false">2507.01424v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>The language of time: a language model perspective on time-series foundation models</title>
      <link>http://arxiv.org/abs/2507.00078v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了基于片段的时间序列基础模型在时间序列数据上的表现，分析了其表示学习和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;随着大型语言模型的兴起，大规模参数和海量数据集训练基础模型的方法在多个领域取得了显著成功。时间序列基础模型是这个范式的扩展，表现出卓越的表达能力、泛化能力和跨领域迁移能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决时间序列数据具有不同动态系统，但模型却表现出跨领域迁移能力的悖论，本文从理论和实验角度研究基于片段的时间序列基础模型的表示学习和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;本文通过理论分析和实验验证，提出模型通过将确定性向量表示扩展到潜在的概率分布形式，从而实现了语言模型的表示范式泛化。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，连续时间序列片段可以被忠实地量化为具有与自然语言高度一致的统计特性的离散词汇。这种泛化使得时间序列模型继承了大型语言模型的鲁棒表示和迁移能力，解释了它们在时间任务中的优异表现。&lt;h4&gt;结论&lt;/h4&gt;本文为理解、评估和改进大规模时间序列基础模型的安全性和可靠性提供了严格的理论基石。&lt;h4&gt;翻译&lt;/h4&gt;With the rise of large language models, the paradigm of training foundation models with massive parameter counts on vast datasets has been adopted in multiple domains to achieve remarkable success. Time series foundation models represent a significant extension of this paradigm, demonstrating exceptional expressive power, generalization, and cross-domain transferability. However, this gives rise to a fundamental paradox: time series data reflect distinct dynamical systems, making cross-domain transfer intuitively implausible, yet this is contradicted by the models' empirical success. To resolve this paradox, this paper investigates, from both theoretical and experimental perspectives, the representation learning mechanisms and generalization capabilities of patch-based time series foundation models. We argue that such models are not merely applying a new architecture but are fundamentally generalizing the representation paradigm of language models by extending deterministic vector-based representations to latent probabilistic distributional forms. Our theoretical analysis supports this framework by demonstrating that continuous time-series patches can be faithfully quantized into a discrete vocabulary whose key statistical properties are highly consistent with those of natural language. This generalization allows time series models to inherit the robust representation and transfer abilities of large language models, thereby explaining their superior performance in temporal tasks. Ultimately, our work provides a rigorous theoretical cornerstone for understanding, evaluating, and improving the safety and reliability of large-scale time series foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the rise of large language models, the paradigm of training foundationmodels with massive parameter counts on vast datasets has been adopted inmultiple domains to achieve remarkable success. Time series foundation modelsrepresent a significant extension of this paradigm, demonstrating exceptionalexpressive power, generalization, and cross-domain transferability. However,this gives rise to a fundamental paradox: time series data reflect distinctdynamical systems, making cross-domain transfer intuitively implausible, yetthis is contradicted by the models' empirical success. To resolve this paradox,this paper investigates, from both theoretical and experimental perspectives,the representation learning mechanisms and generalization capabilities ofpatch-based time series foundation models. We argue that such models are notmerely applying a new architecture but are fundamentally generalizing therepresentation paradigm of language models by extending deterministicvector-based representations to latent probabilistic distributional forms. Ourtheoretical analysis supports this framework by demonstrating that continuoustime-series patches can be faithfully quantized into a discrete vocabularywhose key statistical properties are highly consistent with those of naturallanguage. This generalization allows time series models to inherit the robustrepresentation and transfer abilities of large language models, therebyexplaining their superior performance in temporal tasks. Ultimately, our workprovides a rigorous theoretical cornerstone for understanding, evaluating, andimproving the safety and reliability of large-scale time series foundationmodels.</description>
      <author>example@mail.com (Yi Xie, Yun Xiong, Zejian Shi, Hao Niu, Zhengfu Liu)</author>
      <guid isPermaLink="false">2507.00078v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Decomposing Prediction Mechanisms for In-Context Recall</title>
      <link>http://arxiv.org/abs/2507.01414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  44 pages, 47 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的玩具问题系列，结合了线性回归风格的连续情境学习（ICL）和离散关联回忆的特点。&lt;h4&gt;背景&lt;/h4&gt;研究者对从玩具中抽取的样本轨迹进行预训练，特别是随机抽取的线性确定性动力系统中的符号标记交错状态观察。&lt;h4&gt;目的&lt;/h4&gt;研究Transformer模型是否能够在被提示回忆之前在情境中看到的序列状态时，能够回忆起该状态。&lt;h4&gt;方法&lt;/h4&gt;研究者观察模型是否能够执行两个功能：(1) 确定应该回忆哪个系统的状态并将其应用于最后看到的状态，(2) 继续应用正确的系统来预测后续状态。&lt;h4&gt;主要发现&lt;/h4&gt;训练动态显示，第一个能力在模型训练的后期出现得很好。令人惊讶的是，继续预测恢复序列的能力发展得要早得多。&lt;h4&gt;结论&lt;/h4&gt;通过分布外实验和对模型权重进行边缘修剪的机制分析，发现对于这个玩具问题，下一个标记的预测涉及至少两个不同的机制。一个机制使用离散符号标签来进行预测先前看到的序列恢复所需的关联回忆。第二个机制，对离散符号标签在很大程度上是无关的，基于前一个标记和上下文进行“贝叶斯式”预测。这两种机制有不同的学习动态。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种新的玩具问题系列，它结合了线性回归风格的连续情境学习（ICL）和离散关联回忆的特点。我们在玩具的样本轨迹上预训练了Transformer模型，特别是从随机抽取的线性确定性动力系统中提取的符号标记交错状态观察。我们研究了当模型被提示回忆之前在情境中看到的序列状态时，它是否能够回忆起该状态。仔细观察这个任务，很明显，模型必须执行两个功能：(1) 确定应该回忆哪个系统的状态并将其应用于最后看到的状态，(2) 继续应用正确的系统来预测后续状态。训练动态显示，第一个能力在模型训练的后期出现得很好。令人惊讶的是，继续预测恢复序列的能力发展得要早得多。通过分布外实验，以及通过边缘修剪对模型权重进行的机制分析，我们发现对于这个玩具问题，下一个标记的预测涉及至少两个不同的机制。一个机制使用离散符号标签来进行预测先前看到的序列恢复所需的关联回忆。第二个机制，对离散符号标签在很大程度上是无关的，基于前一个标记和上下文进行“贝叶斯式”预测。这两种机制有不同的学习动态。为了确认这种多机制（表现为不同的阶段转换）现象不是我们玩具设置中的伪象，我们使用OLMo训练检查点在ICL翻译任务上观察到了类似的现象：第一任务标记性能与第二任务标记性能之间出现决定性的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce a new family of toy problems that combine features oflinear-regression-style continuous in-context learning (ICL) with discreteassociative recall. We pretrain transformer models on sample traces from thistoy, specifically symbolically-labeled interleaved state observations fromrandomly drawn linear deterministic dynamical systems. We study if thetransformer models can recall the state of a sequence previously seen in itscontext when prompted to do so with the corresponding in-context label. Takinga closer look at this task, it becomes clear that the model must perform twofunctions: (1) identify which system's state should be recalled and apply thatsystem to its last seen state, and (2) continuing to apply the correct systemto predict the subsequent states. Training dynamics reveal that the firstcapability emerges well into a model's training. Surprisingly, the secondcapability, of continuing the prediction of a resumed sequence, develops muchearlier.  Via out-of-distribution experiments, and a mechanistic analysis on modelweights via edge pruning, we find that next-token prediction for this toyproblem involves at least two separate mechanisms. One mechanism uses thediscrete symbolic labels to do the associative recall required to predict thestart of a resumption of a previously seen sequence. The second mechanism,which is largely agnostic to the discrete symbolic labels, performs a"Bayesian-style" prediction based on the previous token and the context. Thesetwo mechanisms have different learning dynamics.  To confirm that this multi-mechanism (manifesting as separate phasetransitions) phenomenon is not just an artifact of our toy setting, we usedOLMo training checkpoints on an ICL translation task to see a similarphenomenon: a decisive gap in the emergence of first-task-token performance vssecond-task-token performance.</description>
      <author>example@mail.com (Sultan Daniels, Dylan Davis, Dhruv Gautam, Wentinn Liao, Gireeja Ranade, Anant Sahai)</author>
      <guid isPermaLink="false">2507.01414v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>BronchoGAN: Anatomically consistent and domain-agnostic image-to-image translation for video bronchoscopy</title>
      <link>http://arxiv.org/abs/2507.01387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了BronchoGAN，这是一种用于图像到图像转换的条件生成对抗网络，旨在解决支气管镜图像可用性有限的问题。&lt;h4&gt;背景&lt;/h4&gt;支气管镜图像的有限可用性使得图像合成对于训练深度学习模型特别有趣。不同领域之间稳健的图像翻译（如虚拟支气管镜、模型以及体内和体外图像数据）对于临床应用至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过BronchoGAN引入解剖约束，以实现图像到图像的转换，并减少对单个训练数据集的依赖。&lt;h4&gt;方法&lt;/h4&gt;BronchoGAN通过将支气管或ifice的匹配作为条件约束集成到条件生成对抗网络中。此外，它使用基础模型生成的深度图像作为中间表示，以确保不同输入领域的鲁棒性，并允许轻松构建配对图像数据用于训练。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，来自不同领域的输入图像（例如虚拟支气管镜、模型）可以成功转换为模仿真实人类气道外观的图像。解剖设置（即支气管或ifice）可以通过我们的方法稳健地保留，通过改进的FID、SSIM和dice系数得分进行了定性和定量证明。解剖约束使合成图像的Dice系数提高了0.43。&lt;h4&gt;结论&lt;/h4&gt;BronchoGAN能够将公共CT扫描数据（虚拟支气管镜）纳入其中，以生成具有逼真外观的大规模支气管镜图像数据集。该方法能够弥补缺失的公共支气管镜图像的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1007/s11548-025-03450-w&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The limited availability of bronchoscopy images makes image synthesisparticularly interesting for training deep learning models. Robust imagetranslation across different domains -- virtual bronchoscopy, phantom as wellas in-vivo and ex-vivo image data -- is pivotal for clinical applications. Thispaper proposes BronchoGAN introducing anatomical constraints for image-to-imagetranslation being integrated into a conditional GAN. In particular, we forcebronchial orifices to match across input and output images. We further proposeto use foundation model-generated depth images as intermediate representationensuring robustness across a variety of input domains establishing models withsubstantially less reliance on individual training datasets. Moreover ourintermediate depth image representation allows to easily construct paired imagedata for training. Our experiments showed that input images from differentdomains (e.g. virtual bronchoscopy, phantoms) can be successfully translated toimages mimicking realistic human airway appearance. We demonstrated thatanatomical settings (i.e. bronchial orifices) can be robustly preserved withour approach which is shown qualitatively and quantitatively by means ofimproved FID, SSIM and dice coefficients scores. Our anatomical constraintsenabled an improvement in the Dice coefficient of up to 0.43 for syntheticimages. Through foundation models for intermediate depth representations,bronchial orifice segmentation integrated as anatomical constraints intoconditional GANs we are able to robustly translate images from differentbronchoscopy input domains. BronchoGAN allows to incorporate public CT scandata (virtual bronchoscopy) in order to generate large-scale bronchoscopy imagedatasets with realistic appearance. BronchoGAN enables to bridge the gap ofmissing public bronchoscopy images.</description>
      <author>example@mail.com (Ahmad Soliman, Ron Keuth, Marian Himstedt)</author>
      <guid isPermaLink="false">2507.01387v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>LEDOM: An Open and Fundamental Reverse Language Model</title>
      <link>http://arxiv.org/abs/2507.01335v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Work in progress&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了LEDOM，首个纯反向语言模型，通过在435B个标记上自回归训练，具有2B和7B参数变体，以反向时间顺序处理序列，通过预测前一个标记进行序列处理。同时，提出反向语言模型作为通用任务的潜在基础模型，并展示了相关实例和见解。基于LEDOM，引入了新的应用：反向奖励，通过LEDOM引导的前向语言模型输出重排序，在数学推理任务上显著提升了性能。这种方法利用LEDOM独特的反向推理能力，通过后验评估来提高生成质量。研究结果指出LEDOM具有独特的特征和广泛的应用潜力。将发布所有模型、训练代码和预训练数据，以促进未来的研究。&lt;h4&gt;背景&lt;/h4&gt;背景信息未在摘要中提及。&lt;h4&gt;目的&lt;/h4&gt;目的是提出LEDOM作为首个纯反向语言模型，并探讨其在通用任务中的应用潜力。&lt;h4&gt;方法&lt;/h4&gt;方法包括自回归训练LEDOM，处理序列时采用反向时间顺序，通过预测前一个标记进行序列处理，并引入反向奖励作为新的应用。&lt;h4&gt;主要发现&lt;/h4&gt;主要发现是LEDOM在数学推理任务上通过反向奖励方法显著提升了性能，显示出独特的反向推理能力和广泛的应用潜力。&lt;h4&gt;结论&lt;/h4&gt;结论是LEDOM具有独特的特征和广泛的应用潜力，未来将发布所有模型、训练代码和预训练数据。&lt;h4&gt;翻译&lt;/h4&gt;内容为英文摘要的中文翻译。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-02&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce LEDOM, the first purely reverse language model, trainedautoregressively on 435B tokens with 2B and 7B parameter variants, whichprocesses sequences in reverse temporal order through previous tokenprediction. For the first time, we present the reverse language model as apotential foundational model across general tasks, accompanied by a set ofintriguing examples and insights. Based on LEDOM, we further introduce a novelapplication: Reverse Reward, where LEDOM-guided reranking of forward languagemodel outputs leads to substantial performance improvements on mathematicalreasoning tasks. This approach leverages LEDOM's unique backward reasoningcapability to refine generation quality through posterior evaluation. Ourfindings suggest that LEDOM exhibits unique characteristics with broadapplication potential. We will release all models, training code, andpre-training data to facilitate future research.</description>
      <author>example@mail.com (Xunjian Yin, Sitao Cheng, Yuxi Xie, Xinyu Hu, Li Lin, Xinyi Wang, Liangming Pan, William Yang Wang, Xiaojun Wan)</author>
      <guid isPermaLink="false">2507.01335v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models</title>
      <link>http://arxiv.org/abs/2507.01201v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为JAM的框架，旨在通过多目标优化任务，在保持每种模态的原始结构的同时，实现不同模态之间的对齐，以促进跨模态模型的共享结构。&lt;h4&gt;背景&lt;/h4&gt;视觉和语言模型在各自的模态、目标和架构下独立训练，存在不同的表示空间，但存在一种假设，即这些模型可能最终趋向于一个共享的现实统计模型。&lt;h4&gt;目的&lt;/h4&gt;研究如何超越事后统计检测对齐，并明确地在不同的表示空间之间优化对齐。&lt;h4&gt;方法&lt;/h4&gt;将普罗塔戈拉对齐问题作为多目标优化任务，提出JAM框架，通过联合训练模态特定的自动编码器，在预训练的单模态模型的潜在表示上，通过重建和跨模态目标鼓励对齐。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，JAM框架在三个关键设计轴上表现出色：(i) 对齐目标，包括对比损失、其硬负样本变体和提出的扩展损失；(ii) 对齐最有效的层深度；(iii) 基础模型规模对表示收敛的影响。&lt;h4&gt;结论&lt;/h4&gt;JAM框架能够可靠地诱导对齐，即使在冻结的独立训练表示之间，也为将通用单模态基础模型转换为专用多模态模型提供了理论洞察和实践途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：独立训练的视觉和语言模型居住在由各自模态、目标和架构塑造的分离表示空间中。然而，一个新兴的假设——柏拉图表示假设——表明，这样的模型仍然可能趋向于一个共享的现实统计模型。如果这种兼容性存在，那么就提出了一个基本问题：我们能否超越事后统计检测对齐，并明确地在这样的分离表示之间优化对齐？我们将普罗塔戈拉对齐问题设定为多目标优化任务——在保持每种模态的原始结构的同时，实现相互协调。我们引入了联合自动编码器调制器（JAM）框架，该框架在预训练的单模态模型的潜在表示上联合训练模态特定的自动编码器，通过重建和跨模态目标鼓励对齐。通过类比，这个框架作为逃离柏拉图洞穴的方法，使得从分离的输入中产生共享结构。我们在三个关键设计轴上评估了这个框架：(i) 对齐目标——比较对比损失（Con）、其硬负样本变体（NegCon）和我们的扩展损失；(ii) 对齐最有效的层深度；(iii) 基础模型规模对表示收敛的影响。我们的结果表明，我们的轻量级Pareto有效框架可以可靠地诱导对齐，即使在冻结的独立训练表示之间，也为将通用单模态基础模型转换为专用多模态模型提供了理论洞察和实践途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Independently trained vision and language models inhabit disjointrepresentational spaces, shaped by their respective modalities, objectives, andarchitectures. Yet an emerging hypothesis - the Platonic RepresentationHypothesis - suggests that such models may nonetheless converge toward a sharedstatistical model of reality. This compatibility, if it exists, raises afundamental question: can we move beyond post-hoc statistical detection ofalignment and explicitly optimize for it between such disjoint representations?We cast this Platonic alignment problem as a multi-objective optimization task- preserve each modality's native structure while aligning for mutualcoherence. We introduce the Joint Autoencoder Modulator (JAM) framework thatjointly trains modality-specific autoencoders on the latent representations ofpre-trained single modality models, encouraging alignment through bothreconstruction and cross-modal objectives. By analogy, this framework serves asa method to escape Plato's Cave, enabling the emergence of shared structurefrom disjoint inputs. We evaluate this framework across three critical designaxes: (i) the alignment objective - comparing contrastive loss (Con), itshard-negative variant (NegCon), and our Spread loss, (ii) the layer depth atwhich alignment is most effective, and (iii) the impact of foundation modelscale on representational convergence. Our findings show that our lightweightPareto-efficient framework reliably induces alignment, even across frozen,independently trained representations, offering both theoretical insight andpractical pathways for transforming generalist unimodal foundations intospecialist multimodal models.</description>
      <author>example@mail.com (Hyoseo, Yoon, Yisong Yue, Been Kim)</author>
      <guid isPermaLink="false">2507.01201v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning</title>
      <link>http://arxiv.org/abs/2507.01196v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文对大型脑电模型（LBMs）在脑-机接口（BCI）领域的应用进行了评估，发现尽管这些模型在某些任务上有所改进，但效率和应用前景仍存疑。&lt;h4&gt;背景&lt;/h4&gt;脑电模型在人工智能领域展现出显著的成功，但在脑波建模方面的能力尚不明确。&lt;h4&gt;目的&lt;/h4&gt;全面评估当前的大型脑电基础模型（LBMs）在BCI基准任务上的表现，包括记忆任务和睡眠阶段分类。&lt;h4&gt;方法&lt;/h4&gt;通过在多个BCI基准任务上系统地微调实验，包括详细的可解释性研究和低秩自适应（LoRA）技术。&lt;h4&gt;主要发现&lt;/h4&gt;最先进的LBMs在传统深度架构上仅实现微小改进（0.9%-1.2%），但需要显著更多的参数（百万级对千级），提出了关于它们在BCI应用中效率和适用性的问题。LoRA的应用显示了性能提升，但当前架构和训练的无效性限制了LBMs的能力。&lt;h4&gt;结论&lt;/h4&gt;为了推动LBMs的发展，提出了针对特定领域的发展策略，并暗示当前架构可能需要重新设计以充分利用基础模型在脑波分析中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型在人工智能（AI）的各个领域都取得了显著的成效，然而它们在脑波建模方面的能力仍然不清楚。在本文中，我们通过对多个脑-机接口（BCI）基准任务，包括记忆任务和睡眠阶段分类，进行系统的微调实验，全面评估了当前大型脑电基础模型（LBMs）。我们的广泛分析表明，最先进的LBMs在传统深度架构上仅实现了微小的改进（0.9%-1.2%），而需要显著更多的参数（百万级对千级），这在BCI环境中引发了关于它们效率和适用性的重要问题。此外，通过详细的可解释性研究和低秩自适应（LoRA），我们在不降低性能的情况下显著减少了可训练的参数，同时证明了架构和训练的无效率限制了LBMs当前的能力。我们的实验涵盖了完整的模型微调和参数高效自适应技术，为BCI应用提供了最佳的训练策略。我们开创性地将LoRA应用于LBMs，发现当同时调整多个神经网络组件时，通常会出现性能提升。这些发现强调了在特定领域开发策略的迫切需要，表明当前的架构可能需要重新设计以充分利用基础模型在脑波分析中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models have demonstrated significant success across variousdomains in Artificial Intelligence (AI), yet their capabilities for brainwavemodeling remain unclear. In this paper, we comprehensively evaluate currentLarge Brainwave Foundation Models (LBMs) through systematic fine-tuningexperiments across multiple Brain-Computer Interface (BCI) benchmark tasks,including memory tasks and sleep stage classification. Our extensive analysisshows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%)over traditional deep architectures while requiring significantly moreparameters (millions vs thousands), raising important questions about theirefficiency and applicability in BCI contexts. Moreover, through detailedablation studies and Low-Rank Adaptation (LoRA), we significantly reducetrainable parameters without performance degradation, while demonstrating thatarchitectural and training inefficiencies limit LBMs' current capabilities. Ourexperiments span both full model fine-tuning and parameter-efficient adaptationtechniques, providing insights into optimal training strategies for BCIapplications. We pioneer the application of LoRA to LBMs, revealing thatperformance benefits generally emerge when adapting multiple neural networkcomponents simultaneously. These findings highlight the critical need fordomain-specific development strategies to advance LBMs, suggesting that currentarchitectures may require redesign to fully leverage the potential offoundation models in brainwave analysis.</description>
      <author>example@mail.com (Na Lee, Konstantinos Barmpas, Yannis Panagakis, Dimitrios Adamos, Nikolaos Laskaris, Stefanos Zafeiriou)</author>
      <guid isPermaLink="false">2507.01196v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>SciArena: An Open Evaluation Platform for Foundation Models in Scientific Literature Tasks</title>
      <link>http://arxiv.org/abs/2507.01001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SciArena是一个开放且协作的平台，用于评估科学文献任务中的基础模型，通过社区投票的方式来比较模型表现。&lt;h4&gt;背景&lt;/h4&gt;SciArena不同于传统的科学文献理解和综合基准测试，它直接让研究社区参与评价。&lt;h4&gt;目的&lt;/h4&gt;SciArena旨在通过集体智慧提供对开放科学任务中模型性能的社区驱动评价，这些任务需要基于文献的、长篇的回答。&lt;h4&gt;方法&lt;/h4&gt;SciArena支持23个开源和专有基础模型，并收集了来自不同科学领域的超过13,000个来自可信研究者的投票。通过分析数据，SciArena-Eval元评估基准被发布，用于衡量模型判断答案质量准确性的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;分析的数据显示，提交的问题多样，与实际文献需求一致，参与研究者在其评价中表现出强烈的自我一致性和标注者间一致性。&lt;h4&gt;结论&lt;/h4&gt;SciArena-Eval基准强调了自动评估方法可靠性的需要，并指出了当前基准的挑战。&lt;h4&gt;翻译&lt;/h4&gt;我们提出SciArena，一个开放且协作的平台，用于评估科学文献任务中的基础模型。与传统的科学文献理解和综合基准测试不同，SciArena直接让研究社区参与评价。通过利用集体智慧，SciArena提供对开放科学任务中模型性能的社区驱动评价，这些任务需要基于文献的、长篇的回答。该平台目前支持23个开源和专有基础模型，并收集了来自不同科学领域的超过13,000个来自可信研究者的投票。我们分析了迄今为止收集的数据，并确认提交的问题多样，与实际文献需求一致，参与研究者在其评价中表现出强烈的自我一致性和标注者间一致性。我们讨论了基于模型排名排行榜的结果和见解。为了进一步促进基于模型自动评估系统的文献任务研究，我们发布了SciArena-Eval，一个基于我们收集的偏好数据的元评估基准。该基准通过比较模型的成对评估与人类投票来衡量模型判断答案质量准确性的准确性。我们的实验突出了基准的挑战，并强调了需要更可靠的自动评估方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present SciArena, an open and collaborative platform for evaluatingfoundation models on scientific literature tasks. Unlike traditional benchmarksfor scientific literature understanding and synthesis, SciArena engages theresearch community directly, following the Chatbot Arena evaluation approach ofcommunity voting on model comparisons. By leveraging collective intelligence,SciArena offers a community-driven evaluation of model performance onopen-ended scientific tasks that demand literature-grounded, long-formresponses. The platform currently supports 23 open-source and proprietaryfoundation models and has collected over 13,000 votes from trusted researchersacross diverse scientific domains. We analyze the data collected so far andconfirm that the submitted questions are diverse, aligned with real-worldliterature needs, and that participating researchers demonstrate strongself-consistency and inter-annotator agreement in their evaluations. We discussthe results and insights based on the model ranking leaderboard. To furtherpromote research in building model-based automated evaluation systems forliterature tasks, we release SciArena-Eval, a meta-evaluation benchmark basedon our collected preference data. The benchmark measures the accuracy of modelsin judging answer quality by comparing their pairwise assessments with humanvotes. Our experiments highlight the benchmark's challenges and emphasize theneed for more reliable automated evaluation methods.</description>
      <author>example@mail.com (Yilun Zhao, Kaiyan Zhang, Tiansheng Hu, Sihong Wu, Ronan Le Bras, Taira Anderson, Jonathan Bragg, Joseph Chee Chang, Jesse Dodge, Matt Latzke, Yixin Liu, Charles McGrady, Xiangru Tang, Zihang Wang, Chen Zhao, Hannaneh Hajishirzi, Doug Downey, Arman Cohan)</author>
      <guid isPermaLink="false">2507.01001v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Time Series Foundation Models are Flow Predictors</title>
      <link>http://arxiv.org/abs/2507.00945v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2203.07372&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究调查了时间序列基础模型（TSFMs）在人群流量预测中的有效性，重点关注Moirai和TimesFM模型。&lt;h4&gt;背景&lt;/h4&gt;研究基于三个真实世界的流动性数据集——Bike NYC、Taxi Beijing和Spanish national OD flows。&lt;h4&gt;目的&lt;/h4&gt;研究旨在评估这些模型在严格的无监督设置下的性能，即仅使用每个OD流的时间演变，而不使用任何显式的空间信息。&lt;h4&gt;方法&lt;/h4&gt;模型在零样本设置下进行评估，并与统计和深度学习基线进行了比较。&lt;h4&gt;主要发现&lt;/h4&gt;Moirai和TimesFM在RMSE、MAE和CPC方面均优于最先进的竞争对手，分别降低了33%、39%和提高了49%。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了TSFMs在准确、可扩展的流量预测中的实际价值，即使在数据标注有限或缺少空间上下文的情况下。&lt;h4&gt;翻译&lt;/h4&gt;We investigate the effectiveness of time series foundation models (TSFMs) for crowd flow prediction, focusing on Moirai and TimesFM. Evaluated on three real-world mobility datasets-Bike NYC, Taxi Beijing, and Spanish national OD flows-these models are deployed in a strict zero-shot setting, using only the temporal evolution of each OD flow and no explicit spatial information. Moirai and TimesFM outperform both statistical and deep learning baselines, achieving up to 33% lower RMSE, 39% lower MAE and up to 49% higher CPC compared to state-of-the-art competitors. Our results highlight the practical value of TSFMs for accurate, scalable flow prediction, even in scenarios with limited annotated data or missing spatial context.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate the effectiveness of time series foundation models (TSFMs) forcrowd flow prediction, focusing on Moirai and TimesFM. Evaluated on threereal-world mobility datasets-Bike NYC, Taxi Beijing, and Spanish national ODflows-these models are deployed in a strict zero-shot setting, using only thetemporal evolution of each OD flow and no explicit spatial information. Moiraiand TimesFM outperform both statistical and deep learning baselines, achievingup to 33% lower RMSE, 39% lower MAE and up to 49% higher CPC compared tostate-of-the-art competitors. Our results highlight the practical value ofTSFMs for accurate, scalable flow prediction, even in scenarios with limitedannotated data or missing spatial context.</description>
      <author>example@mail.com (Massimiliano Luca, Ciro Beneduce, Bruno Lepri)</author>
      <guid isPermaLink="false">2507.00945v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>A Scalable and Quantum-Accurate Foundation Model for Biomolecular Force Field via Linearly Tensorized Quadrangle Attention</title>
      <link>http://arxiv.org/abs/2507.00884v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为LiTEN的新型equivariant神经网络，结合Tensorized Quadrangle Attention (TQA)技术，用于提高生物分子模拟的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;现有的生物分子模拟方法在准确性和效率上存在局限性，经典力场缺乏对过渡态和精细构象细节的准确性，而量子力学方法计算成本过高。&lt;h4&gt;目的&lt;/h4&gt;提出LiTEN，旨在克服现有方法的局限性，实现高精度和高效能的生物分子模拟。&lt;h4&gt;方法&lt;/h4&gt;LiTEN使用TQA技术高效地建模三体和四体相互作用，通过向量操作重新参数化高阶张量特征，避免使用昂贵的球谐函数。LiTEN-FF是基于LiTEN的AIFF基础模型，在nablaDFT数据集上进行预训练，并在SPICE上进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;LiTEN在rMD17、MD22和Chignolin的多数评估子集中实现了最先进的性能，优于MACE、NequIP和EquiFormer等领先模型。LiTEN-FF能够执行包括量子级构象搜索、几何优化和自由能表面构建在内的多种下游生物分子建模任务，并且比MACE-OFF对大分子（约1000个原子）的推理速度快10倍。&lt;h4&gt;结论&lt;/h4&gt;LiTEN提供了一个基于物理的高效框架，推动了复杂生物分子建模的发展，为药物发现和相关应用提供了一个多功能的基石。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate atomistic biomolecular simulations are vital for disease mechanismunderstanding, drug discovery, and biomaterial design, but existing simulationmethods exhibit significant limitations. Classical force fields are efficientbut lack accuracy for transition states and fine conformational detailscritical in many chemical and biological processes. Quantum Mechanics (QM)methods are highly accurate but computationally infeasible for large-scale orlong-time simulations. AI-based force fields (AIFFs) aim to achieve QM-levelaccuracy with efficiency but struggle to balance many-body modeling complexity,accuracy, and speed, often constrained by limited training data andinsufficient validation for generalizability. To overcome these challenges, weintroduce LiTEN, a novel equivariant neural network with Tensorized QuadrangleAttention (TQA). TQA efficiently models three- and four-body interactions withlinear complexity by reparameterizing high-order tensor features via vectoroperations, avoiding costly spherical harmonics. Building on LiTEN, LiTEN-FF isa robust AIFF foundation model, pre-trained on the extensive nablaDFT datasetfor broad chemical generalization and fine-tuned on SPICE for accurate solvatedsystem simulations. LiTEN achieves state-of-the-art (SOTA) performance acrossmost evaluation subsets of rMD17, MD22, and Chignolin, outperforming leadingmodels such as MACE, NequIP, and EquiFormer. LiTEN-FF enables the mostcomprehensive suite of downstream biomolecular modeling tasks to date,including QM-level conformer searches, geometry optimization, and free energysurface construction, while offering 10x faster inference than MACE-OFF forlarge biomolecules (~1000 atoms). In summary, we present a physically grounded,highly efficient framework that advances complex biomolecular modeling,providing a versatile foundation for drug discovery and related applications.</description>
      <author>example@mail.com (Qun Su, Kai Zhu, Qiaolin Gou, Jintu Zhang, Renling Hu, Yurong Li, Yongze Wang, Hui Zhang, Ziyi You, Linlong Jiang, Yu Kang, Jike Wang, Chang-Yu Hsieh, Tingjun Hou)</author>
      <guid isPermaLink="false">2507.00884v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents</title>
      <link>http://arxiv.org/abs/2507.00841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了移动多模态智能代理系统的安全问题，通过结合行为序列信息构建风险识别机制，并设计了一种基于大型语言模型的自动化辅助评估方案。&lt;h4&gt;背景&lt;/h4&gt;随着多模态基础模型在智能代理系统中的广泛应用，相关系统面临潜在的越狱风险，攻击者可能通过特定输入诱导代理绕过行为约束，触发风险操作，如修改设置、执行未授权命令或冒充用户身份。&lt;h4&gt;目的&lt;/h4&gt;提高对风险行为的识别，降低代理被越狱的概率，为多模态智能代理系统的安全风险建模和保护提供参考。&lt;h4&gt;方法&lt;/h4&gt;构建风险识别机制，结合行为序列信息，设计基于大型语言模型的自动化辅助评估方案。&lt;h4&gt;主要发现&lt;/h4&gt;在几个代表性高风险任务中的初步验证表明，该方法在一定程度上提高了对风险行为的识别，有助于降低代理被越狱的概率。&lt;h4&gt;结论&lt;/h4&gt;本研究为多模态智能代理系统的安全风险建模和保护提供了有价值的参考。&lt;h4&gt;翻译&lt;/h4&gt;With the wide application of multimodal foundation models in intelligent agent systems, scenarios such as mobile device control, intelligent assistant interaction, and multimodal task execution are gradually relying on such large model-driven agents. However, the related systems are also increasingly exposed to potential jailbreak risks. Attackers may induce the agents to bypass the original behavioral constraints through specific inputs, and then trigger certain risky and sensitive operations, such as modifying settings, executing unauthorized commands, or impersonating user identities, which brings new challenges to system security. Existing security measures for intelligent agents still have limitations when facing complex interactions, especially in detecting potentially risky behaviors across multiple rounds of conversations or sequences of tasks. In addition, an efficient and consistent automated methodology to assist in assessing and determining the impact of such risks is currently lacking. This work explores the security issues surrounding mobile multimodal agents, attempts to construct a risk discrimination mechanism by incorporating behavioral sequence information, and designs an automated assisted assessment scheme based on a large language model. Through preliminary validation in several representative high-risk tasks, the results show that the method can improve the recognition of risky behaviors to some extent and assist in reducing the probability of agents being jailbroken. We hope that this study can provide some valuable references for the security risk modeling and protection of multimodal intelligent agent systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the wide application of multimodal foundation models in intelligentagent systems, scenarios such as mobile device control, intelligent assistantinteraction, and multimodal task execution are gradually relying on such largemodel-driven agents. However, the related systems are also increasingly exposedto potential jailbreak risks. Attackers may induce the agents to bypass theoriginal behavioral constraints through specific inputs, and then triggercertain risky and sensitive operations, such as modifying settings, executingunauthorized commands, or impersonating user identities, which brings newchallenges to system security. Existing security measures for intelligentagents still have limitations when facing complex interactions, especially indetecting potentially risky behaviors across multiple rounds of conversationsor sequences of tasks. In addition, an efficient and consistent automatedmethodology to assist in assessing and determining the impact of such risks iscurrently lacking. This work explores the security issues surrounding mobilemultimodal agents, attempts to construct a risk discrimination mechanism byincorporating behavioral sequence information, and designs an automatedassisted assessment scheme based on a large language model. Through preliminaryvalidation in several representative high-risk tasks, the results show that themethod can improve the recognition of risky behaviors to some extent and assistin reducing the probability of agents being jailbroken. We hope that this studycan provide some valuable references for the security risk modeling andprotection of multimodal intelligent agent systems.</description>
      <author>example@mail.com (Siyuan Liang, Tianmeng Fang, Zhe Liu, Aishan Liu, Yan Xiao, Jinyuan He, Ee-Chien Chang, Xiaochun Cao)</author>
      <guid isPermaLink="false">2507.00841v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>World4Drive: End-to-End Autonomous Driving via Intention-aware Physical Latent World Model</title>
      <link>http://arxiv.org/abs/2507.00603v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025, first version&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为World4Drive的端到端自动驾驶框架，该框架利用视觉基础模型构建潜在世界模型，以生成和评估多模态规划轨迹，实现感知注释自由、端到端规划。&lt;h4&gt;背景&lt;/h4&gt;现有的端到端自动驾驶系统依赖昂贵的感知监督来提取场景信息。&lt;h4&gt;目的&lt;/h4&gt;构建一个信息丰富的驾驶世界模型，以实现感知注释自由、端到端规划。&lt;h4&gt;方法&lt;/h4&gt;World4Drive首先提取场景特征，包括驾驶意图和由视觉基础模型提供的空间语义先验增强的世界潜在表示。然后，它根据当前场景特征和驾驶意图生成多模态规划轨迹，并在潜在空间中预测多个由意图驱动的未来状态。最后，它引入了一个世界模型选择模块来评估和选择最佳轨迹。&lt;h4&gt;主要发现&lt;/h4&gt;通过自监督学习将实际未来观察与从潜在空间重构的预测观察对齐，实现了感知注释自由、端到端规划。World4Drive在开放循环nuScenes和闭环NavSim基准测试上均取得了最先进的性能，相对于L2误差降低了18.1%，碰撞率降低了46.7%，训练收敛速度提高了3.75倍。&lt;h4&gt;结论&lt;/h4&gt;World4Drive通过无需人工感知注释，在nuScenes和NavSim基准测试上均取得了显著的性能提升，证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; End-to-end autonomous driving directly generates planning trajectories fromraw sensor data, yet it typically relies on costly perception supervision toextract scene information. A critical research challenge arises: constructingan informative driving world model to enable perception annotation-free,end-to-end planning via self-supervised learning. In this paper, we presentWorld4Drive, an end-to-end autonomous driving framework that employs visionfoundation models to build latent world models for generating and evaluatingmulti-modal planning trajectories. Specifically, World4Drive first extractsscene features, including driving intention and world latent representationsenriched with spatial-semantic priors provided by vision foundation models. Itthen generates multi-modal planning trajectories based on current scenefeatures and driving intentions and predicts multiple intention-driven futurestates within the latent space. Finally, it introduces a world model selectormodule to evaluate and select the best trajectory. We achieve perceptionannotation-free, end-to-end planning through self-supervised alignment betweenactual future observations and predicted observations reconstructed from thelatent space. World4Drive achieves state-of-the-art performance without manualperception annotations on both the open-loop nuScenes and closed-loop NavSimbenchmarks, demonstrating an 18.1\% relative reduction in L2 error, 46.7% lowercollision rate, and 3.75 faster training convergence. Codes will be accessed athttps://github.com/ucaszyp/World4Drive.</description>
      <author>example@mail.com (Yupeng Zheng, Pengxuan Yang, Zebin Xing, Qichao Zhang, Yuhang Zheng, Yinfeng Gao, Pengfei Li, Teng Zhang, Zhongpu Xia, Peng Jia, Dongbin Zhao)</author>
      <guid isPermaLink="false">2507.00603v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Foundation Models for Clinical Records at Health System Scale</title>
      <link>http://arxiv.org/abs/2507.00574v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICML 2025 Workshop on Foundation Models for Structured  Data&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于下一访问事件预测的序列EHR数据生成预训练策略，该策略能够自动回归地生成各种临床事件，并处理不同数据类型的联合预测，同时强调了对重复事件的预测正则化，并通过零样本预测验证了模型在预测痴呆症和膝关节骨关节炎发病风险方面的性能。&lt;h4&gt;背景&lt;/h4&gt;大规模预训练在语言和其他数据类型的建模中取得了显著成果，但在医疗保健领域，特别是结构化电子健康记录（EHRs）中的应用潜力尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的生成预训练策略，用于处理序列EHR数据，并通过预测下一访问事件来生成临床事件。&lt;h4&gt;方法&lt;/h4&gt;采用基于下一访问事件预测的生成预训练策略，模型能够根据患者病史自动回归地生成各种临床事件，并处理不同数据类型的联合预测。同时，引入了重复事件预测的正则化方法，并指出了EHR基础模型评估中的一个关键陷阱。&lt;h4&gt;主要发现&lt;/h4&gt;模型通过零样本预测方式在预测痴呆症和膝关节骨关节炎发病风险方面进行了评估，其性能与完全微调的掩码预训练Transformer基线相当，表明该方法能够捕捉复杂的临床依赖关系，而不需要昂贵的特定任务微调。&lt;h4&gt;结论&lt;/h4&gt;本文提出的预训练策略能够有效地处理EHR数据，并在预测痴呆症和膝关节骨关节炎发病风险方面展现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Large-scale pretraining has transformed modeling of language and other datatypes, but its potential remains underexplored in healthcare with structured electronic health records (EHRs). We present a novel generative pretraining strategy for sequential EHR data using next-visit event prediction. Our model learns to autoregressively generate various tokenized clinical events for the next visit based on patient history and inherently handles the joint prediction of heterogeneous data types. Additionally, we introduce regularization on predicting repeated events and highlight a key pitfall in EHR-based foundation model evaluations: repeated event tokens can inflate performance metrics when new onsets are not distinguished from subsequent occurrences. Our model is evaluated via zero-shot prediction for forecasting dementia and knee osteoarthritis incidence within 2 and 5 years, and the model performance rivals a fully fine-tuned masked pretrained Transformer baseline, demonstrating that our approach captures complex clinical dependencies without requiring costly task-specific fine-tuning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale pretraining has transformed modeling of language and other datatypes, but its potential remains underexplored in healthcare with structuredelectronic health records (EHRs). We present a novel generative pretrainingstrategy for sequential EHR data using next-visit event prediction. Our modellearns to autoregressively generate various tokenized clinical events for thenext visit based on patient history and inherently handles the joint predictionof heterogeneous data types. Additionally, we introduce regularization onpredicting repeated events and highlight a key pitfall in EHR-based foundationmodel evaluations: repeated event tokens can inflate performance metrics whennew onsets are not distinguished from subsequent occurrences. Our model isevaluated via zero-shot prediction for forecasting dementia and kneeosteoarthritis incidence within 2 and 5 years, and the model performance rivalsa fully fine-tuned masked pretrained Transformer baseline, demonstrating thatour approach captures complex clinical dependencies without requiring costlytask-specific fine-tuning.</description>
      <author>example@mail.com (Haresh Rengaraj Rajamohan, Xiang Gao, Weicheng Zhu, Shih-Lun Huang, Long Chen, Kyunghyun Cho, Cem M. Deniz, Narges Razavian)</author>
      <guid isPermaLink="false">2507.00574v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>Overcoming Long-Context Limitations of State-Space Models via Context-Dependent Sparse Attention</title>
      <link>http://arxiv.org/abs/2507.00449v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings of the 42nd International Conference on Machine Learning,  ES-FoMo III: 3rd Workshop on Efficient Systems for Foundation Models, 18  pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对自然语言处理中长上下文建模的挑战，提出了一种基于状态空间模型（SSM）的改进方法，通过结合上下文相关的稀疏注意力机制（CDSA）和局部敏感哈希注意力（HAX）来提高长上下文建模能力。&lt;h4&gt;背景&lt;/h4&gt;当前主流的Transformer架构在处理长序列时时间复杂度呈二次方增长，而SSM虽然提供了一种次二次方的解决方案，但在捕捉长距离依赖关系方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;分析并提高SSM在长上下文建模方面的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的合成任务“联合回忆”，要求模型在给定上下文中回忆与键关联的值。通过理论证明，SSM在次二次方时间内无法解决多查询联合回忆问题。为了解决这个问题，提出了结合SSM与CDSA的方法，并进一步提出了HAX来实例化这一理论解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;HAX在合成和真实世界长上下文基准测试中，均优于SSM基线以及与上下文无关的稀疏注意力（CISA）集成的SSM。&lt;h4&gt;结论&lt;/h4&gt;HAX是一种有效的长上下文建模方法，能够提高SSM在自然语言处理领域的性能。&lt;h4&gt;翻译&lt;/h4&gt;Efficient long-context modeling remains a critical challenge for natural language processing (NLP), as the time complexity of the predominant Transformer architecture scales quadratically with the sequence length. While state-space models (SSMs) offer alternative sub-quadratic solutions, they struggle to capture long-range dependencies effectively. In this work, we focus on analyzing and improving the long-context modeling capabilities of SSMs. We show that the widely used synthetic task, associative recall, which requires a model to recall a value associated with a single key without context, insufficiently represents the complexities of real-world long-context modeling. To address this limitation, we extend the associative recall to a novel synthetic task, joint recall, which requires a model to recall the value associated with a key given in a specified context. Theoretically, we prove that SSMs do not have the expressiveness to solve multi-query joint recall in sub-quadratic time complexity. To resolve this issue, we propose a solution based on integrating SSMs with Context-Dependent Sparse Attention (CDSA), which has the expressiveness to solve multi-query joint recall with sub-quadratic computation. To bridge the gap between theoretical analysis and real-world applications, we propose locality-sensitive Hashing Attention with sparse Key Selection (HAX), which instantiates the theoretical solution and is further tailored to natural language domains. Extensive experiments on both synthetic and real-world long-context benchmarks show that HAX consistently outperforms SSM baselines and SSMs integrated with context-independent sparse attention (CISA).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-07-01&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient long-context modeling remains a critical challenge for naturallanguage processing (NLP), as the time complexity of the predominantTransformer architecture scales quadratically with the sequence length. Whilestate-space models (SSMs) offer alternative sub-quadratic solutions, theystruggle to capture long-range dependencies effectively. In this work, we focuson analyzing and improving the long-context modeling capabilities of SSMs. Weshow that the widely used synthetic task, associative recall, which requires amodel to recall a value associated with a single key without context,insufficiently represents the complexities of real-world long-context modeling.To address this limitation, we extend the associative recall to a novelsynthetic task, \emph{joint recall}, which requires a model to recall the valueassociated with a key given in a specified context. Theoretically, we provethat SSMs do not have the expressiveness to solve multi-query joint recall insub-quadratic time complexity. To resolve this issue, we propose a solutionbased on integrating SSMs with Context-Dependent Sparse Attention (CDSA), whichhas the expressiveness to solve multi-query joint recall with sub-quadraticcomputation. To bridge the gap between theoretical analysis and real-worldapplications, we propose locality-sensitive Hashing Attention with sparse KeySelection (HAX), which instantiates the theoretical solution and is furthertailored to natural language domains. Extensive experiments on both syntheticand real-world long-context benchmarks show that HAX consistently outperformsSSM baselines and SSMs integrated with context-independent sparse attention(CISA).</description>
      <author>example@mail.com (Zhihao Zhan, Jianan Zhao, Zhaocheng Zhu, Jian Tang)</author>
      <guid isPermaLink="false">2507.00449v1</guid>
      <pubDate>Thu, 03 Jul 2025 14:37:08 +0800</pubDate>
    </item>
    <item>
      <title>NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling</title>
      <link>http://arxiv.org/abs/2506.19500v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;NaviAgent是一种基于图导航的双层规划架构，用于鲁棒地调用功能，提高了复杂、异构工具链的协调能力。&lt;h4&gt;背景&lt;/h4&gt;LLMs依赖静态知识和脆弱的工具调用，这在大型规模的复杂工具链中是一个限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来克服现有方法的限制，如单路径执行和搜索空间指数增长。&lt;h4&gt;方法&lt;/h4&gt;NaviAgent包括一个多路径决策器和图编码导航器。多路径决策器定义了一个四维决策空间，并动态选择最佳行动。图编码导航器构建了一个工具依赖异构图（TDHG），并集成了一种新的启发式搜索策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，NaviAgent在所有基础模型和任务复杂度上均实现了最高的任务成功率（TSR），并且其执行步骤通常在最高效的基线步骤附近，保证了质量和效率之间的良好平衡。&lt;h4&gt;结论&lt;/h4&gt;NaviAgent通过提高工具链协调能力，显著提升了任务成功率，并在大型模型上实现了更高的TSR，特别是在复杂任务上。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LLMs' reliance on static knowledge and fragile tool invocation severelyhinders the orchestration of complex, heterogeneous toolchains, particularly atlarge scales. Existing methods typically use rigid single-path execution,resulting in poor error recovery and exponentially growing search spaces. Weintroduce NaviAgent, a graph-navigated bilevel planning architecture for robustfunction calling, comprising a Multi-Path Decider and Graph-Encoded Navigator.As an LLM-powered agent, the Multi-Path Decider defines a four-dimensionaldecision space and continuously perceives environmental states, dynamicallyselecting the optimal action to fully cover all tool invocation scenarios. TheGraph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph(TDHG), where node embeddings explicitly fuse API schema structure withhistorical invocation behavior. It also integrates a novel heuristic searchstrategy that guides the Decider toward efficient and highly successfultoolchains, even for unseen tool combinations. Experiments show that NaviAgentconsistently achieves the highest task success rate (TSR) across all foundationmodels and task complexities, outperforming the average baselines (ReAct,ToolLLM, {\alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B,and Deepseek-V3, respectively. Its execution steps are typically within onestep of the most efficient baseline, ensuring a strong balance between qualityand efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of49.5%, surpassing the much larger 32B model (44.9%) under our architecture.Incorporating the Graph-Encoded Navigator further boosts TSR by an average of2.4 points, with gains up over 9 points on complex tasks for larger models(Deepseek-V3 and GPT-4o), highlighting its essential role in toolchainorchestration.</description>
      <author>example@mail.com (Yan Jiang, Hao Zhou, LiZhong GU, Ai Han, TianLong Li)</author>
      <guid isPermaLink="false">2506.19500v1</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
  <item>
      <title>Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives</title>
      <link>http://arxiv.org/abs/2506.24124v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/Ironieser/TimesCLIP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多模态对比学习框架，用于时间序列预测，通过将原始时间序列转换为结构化的视觉和文本视角，并通过对比学习在共享语义空间中对齐这些视角，以增强时间序列预测的效果。&lt;h4&gt;背景&lt;/h4&gt;传统的时间序列预测依赖于单模态数值输入，难以捕捉高级语义模式。尽管最近的方法探索使用大型语言模型将时间序列表示为文本，但这些方法仍受限于标记序列的离散性，缺乏人类通常应用的感知直觉，如解释视觉模式。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够更有效地捕捉时间序列数据中的高级语义模式，并提高时间序列预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 将原始时间序列转换为结构化的视觉和文本视角；2. 直接从数值序列构建这两种模态；3. 使用对比学习在共享语义空间中对齐这些视角；4. 引入一个变量选择模块，利用对齐的表示来识别多元预测中最具信息量的变量。&lt;h4&gt;主要发现&lt;/h4&gt;在十五个短期和六个长期预测基准上的实验表明，该方法在时间序列预测中优于强单模态和跨模态基线，突出了多模态对齐在增强时间序列预测中的有效性。&lt;h4&gt;结论&lt;/h4&gt;多模态对比学习框架在时间序列预测中具有显著效果，能够提高预测准确性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a multimodal contrastive learning framework for time series forecasting, which transforms raw time series into structured visual and textual perspectives, aligns these views in a shared semantic space via contrastive learning, and thus enhances the effectiveness of time series forecasting. Extensive experiments demonstrate that the proposed approach consistently outperforms strong unimodal and cross-modal baselines, highlighting the effectiveness of multimodal alignment in enhancing time series forecasting.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting traditionally relies on unimodal numerical inputs,which often struggle to capture high-level semantic patterns due to their denseand unstructured nature. While recent approaches have explored representingtime series as text using large language models (LLMs), these methods remainlimited by the discrete nature of token sequences and lack the perceptualintuition humans typically apply, such as interpreting visual patterns. In thispaper, we propose a multimodal contrastive learning framework that transformsraw time series into structured visual and textual perspectives. Rather thanusing natural language or real-world images, we construct both modalitiesdirectly from numerical sequences. We then align these views in a sharedsemantic space via contrastive learning, enabling the model to capture richerand more complementary representations. Furthermore, we introduce a variateselection module that leverages the aligned representations to identify themost informative variables for multivariate forecasting. Extensive experimentson fifteen short-term and six long-term forecasting benchmarks demonstrate thatour approach consistently outperforms strong unimodal and cross-modalbaselines, highlighting the effectiveness of multimodal alignment in enhancingtime series forecasting. Code is available at:https://github.com/Ironieser/TimesCLIP.</description>
      <author>example@mail.com (Sixun Dong, Wei Fan, Teresa Wu, Yanjie Fu)</author>
      <guid isPermaLink="false">2506.24124v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning</title>
      <link>http://arxiv.org/abs/2506.22919v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Hecto是一种轻量级的MoE模型，通过结合不同类型的专家网络实现条件计算，提高了推理任务的性能和可解释性。&lt;h4&gt;背景&lt;/h4&gt;传统的MoE模型中，专家依赖于相同的归纳偏见，限制了表示多样性，且对需要不同推理类型的输入效率低下。&lt;h4&gt;目的&lt;/h4&gt;提出Hecto模型，旨在通过结合不同类型的专家网络来提高MoE模型在推理任务中的性能和可解释性。&lt;h4&gt;方法&lt;/h4&gt;Hecto结合了GRU专家网络进行时间推理和FFNN专家网络进行静态抽象，使用稀疏的Top-1门控机制。&lt;h4&gt;主要发现&lt;/h4&gt;Hecto在多个推理基准测试中表现出色，实现了明确的专家专业化，并且在大批量输入时表现出更优的性能。&lt;h4&gt;结论&lt;/h4&gt;Hecto为条件计算设定了新的基准，提供了一个原则性的框架，用于在资源有限的环境中实现专门的推理。&lt;h4&gt;翻译&lt;/h4&gt;Mixture-of-Experts (MoE) 模型通过将输入路由到专门的专家来实现条件计算，但这些专家依赖于相同的归纳偏见，因此限制了表示多样性。这种静态的计算路径对于需要不同类型推理的输入来说效率低下，限制了专业化和可解释性。我们提出了Hecto，一种轻量级的MoE架构，通过结合一个GRU专家进行时间推理和一个FFNN专家进行静态抽象（在稀疏的Top-1门控机制下）来利用架构异质性。在三个推理基准（AGNews、SST-2、HotpotQA）和一个回归任务（STS-B）上评估，Hecto在性能上与同质基线相当或略逊一筹，尽管它接收的是孤立的输入表示，同时实现了明确的专家专业化，每个专家都与不同的推理类型（时间推理 vs. 静态推理）相对应。在更大的批量大小上，Hecto表现出改进的性能，得益于放宽的计算约束，这使得其异构架构能够更有效地优化。消融结果表明，架构多样性是Hecto在多种推理任务中稳定性和可解释性的来源。总的来说，Hecto为自己设定了条件计算的新基准，提供了一种原则性的框架，用于在资源有限的环境中实现专门的推理，其模型强度来源于原则性的专业化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mixture-of-Experts (MoE) models enable conditional computation by routinginputs to specialized experts, but these experts rely on identical inductivebiases, thus limiting representational diversity. This static computationpathway is inefficient for inputs that require different types of reasoning andlimits specialization and interpretability. We propose Hecto, a lightweight MoEarchitecture that leverages architectural heterogeneity by combining a GRUexpert for temporal reasoning and an FFNN expert for static abstraction under asparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AGNews, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closelytrails homogeneous baselines in performance despite receiving isolated inputrepresentations, while achieving clear expert specialization, with each expertaligning to distinct reasoning types (temporal vs static). At larger batchsizes, Hecto exhibits improved performance, benefiting from relaxedcomputational constraints that allow its heterogeneous architecture to optimizemore effectively. Ablation results isolate architectural diversity as thesource of Hecto's stability and interpretability across diverse reasoningtasks. Overall, Hecto establishes itself as a new benchmark for conditionalcomputation, offering a principled framework for specialized reasoning inlow-resource regimes with its model strength derived from principledspecialization.</description>
      <author>example@mail.com (Sanskar Pandey, Ruhaan Chopra, Saad Murtaza Bhat, Ark Abhyudaya)</author>
      <guid isPermaLink="false">2506.22919v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.23309v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025. Project Page:  https://lastbasket.github.io/MICCAI-2025-SurgTPGS/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的文本提示高斯分层方法SurgTPGS，用于准确理解3D手术场景，填补了现有工作在实时文本提示3D查询方面的空白。&lt;h4&gt;背景&lt;/h4&gt;在当代外科研究和实践中，准确理解具有文本提示能力的3D手术场景对于手术规划和实时术中引导至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出SurgTPGS方法，以实现更深入的理解复杂的手术环境，提高手术精度和安全性。&lt;h4&gt;方法&lt;/h4&gt;引入了一种结合Segment Anything模型和最先进的视觉语言模型的3D语义特征学习方法，提取分割语言特征用于3D手术场景重建。此外，还提出了语义感知变形跟踪和语义区域感知优化，以提供更精确的重建。&lt;h4&gt;主要发现&lt;/h4&gt;SurgTPGS在两个真实世界手术数据集上进行了实验，证明了其在重建质量、语义平滑度和准确性方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;SurgTPGS有望革新外科实践，为开发下一代智能外科系统铺平道路。&lt;h4&gt;翻译&lt;/h4&gt;In contemporary surgical research and practice, accurately comprehending 3D surgical scenes with text-promptable capabilities is particularly crucial for surgical planning and real-time intra-operative guidance, where precisely identifying and interacting with surgical tools and anatomical structures is paramount. However, existing works focus on surgical vision-language model (VLM), 3D reconstruction, and segmentation separately, lacking support for real-time text-promptable 3D queries. In this paper, we present SurgTPGS, a novel text-promptable Gaussian Splatting method to fill this gap. We introduce a 3D semantics feature learning strategy incorporating the Segment Anything model and state-of-the-art vision-language models. We extract the segmented language features for 3D surgical scene reconstruction, enabling a more in-depth understanding of the complex surgical environment. We also propose semantic-aware deformation tracking to capture the seamless deformation of semantic features, providing a more precise reconstruction for both texture and semantic features. Furthermore, we present semantic region-aware optimization, which utilizes regional-based semantic information to supervise the training, particularly promoting the reconstruction quality and semantic smoothness. We conduct comprehensive experiments on two real-world surgical datasets to demonstrate the superiority of SurgTPGS over state-of-the-art methods, highlighting its potential to revolutionize surgical practices. SurgTPGS paves the way for developing next-generation intelligent surgical systems by enhancing surgical precision and safety. Our code is available at: https://github.com/lastbasket/SurgTPGS.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In contemporary surgical research and practice, accurately comprehending 3Dsurgical scenes with text-promptable capabilities is particularly crucial forsurgical planning and real-time intra-operative guidance, where preciselyidentifying and interacting with surgical tools and anatomical structures isparamount. However, existing works focus on surgical vision-language model(VLM), 3D reconstruction, and segmentation separately, lacking support forreal-time text-promptable 3D queries. In this paper, we present SurgTPGS, anovel text-promptable Gaussian Splatting method to fill this gap. We introducea 3D semantics feature learning strategy incorporating the Segment Anythingmodel and state-of-the-art vision-language models. We extract the segmentedlanguage features for 3D surgical scene reconstruction, enabling a morein-depth understanding of the complex surgical environment. We also proposesemantic-aware deformation tracking to capture the seamless deformation ofsemantic features, providing a more precise reconstruction for both texture andsemantic features. Furthermore, we present semantic region-aware optimization,which utilizes regional-based semantic information to supervise the training,particularly promoting the reconstruction quality and semantic smoothness. Weconduct comprehensive experiments on two real-world surgical datasets todemonstrate the superiority of SurgTPGS over state-of-the-art methods,highlighting its potential to revolutionize surgical practices. SurgTPGS pavesthe way for developing next-generation intelligent surgical systems byenhancing surgical precision and safety. Our code is available at:https://github.com/lastbasket/SurgTPGS.</description>
      <author>example@mail.com (Yiming Huang, Long Bai, Beilei Cui, Kun Yuan, Guankun Wang, Mobarak I. Hoque, Nicolas Padoy, Nassir Navab, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.23309v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2506.23126v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer的点云世界模型ParticleFormer，用于训练多材料、多物体机器人交互中的全局和局部动态特征，无需复杂的场景重建。&lt;h4&gt;背景&lt;/h4&gt;现有的3D世界模型主要限于使用基于粒子的图神经网络模型进行单一材料的动力学模拟，且通常需要耗时的3D场景重建来获取训练数据。&lt;h4&gt;目的&lt;/h4&gt;提高机器人操作的泛化能力，通过捕捉机器人动作条件下的环境演化物理机制。&lt;h4&gt;方法&lt;/h4&gt;ParticleFormer模型使用混合点云重建损失进行训练，能够捕捉刚性、可变形和柔性材料之间的细粒度多物体交互，并直接从真实机器人感知数据中训练，无需复杂的场景重建。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在3D场景预测任务和下游操作任务中表现出色，通过模型预测控制（MPC）策略实现了高动态预测精度和较少的 rollout 错误。此外，该方法在六个模拟和三个真实世界实验中均优于现有基准。&lt;h4&gt;结论&lt;/h4&gt;ParticleFormer模型在多材料、多物体交互场景中具有优越的性能，为机器人操作提供了有效的动力学学习工具。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a Transformer-based point cloud world model called ParticleFormer, which is trained with a hybrid point cloud reconstruction loss to supervise both global and local dynamics features in multi-material, multi-object robot interactions. ParticleFormer captures fine-grained multi-object interactions between rigid, deformable, and flexible materials, trained directly from real-world robot perception data without elaborate scene reconstruction. The model demonstrates its effectiveness in both 3D scene forecasting tasks and downstream manipulation tasks using a Model Predictive Control (MPC) policy. In addition, the method extends existing dynamics learning benchmarks to include diverse multi-material, multi-object interaction scenarios. The method is validated on six simulation and three real-world experiments, where it consistently outperforms leading baselines by achieving superior dynamics prediction accuracy and less rollout error in downstream visuomotor tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D world models (i.e., learning-based 3D dynamics models) offer a promisingapproach to generalizable robotic manipulation by capturing the underlyingphysics of environment evolution conditioned on robot actions. However,existing 3D world models are primarily limited to single-material dynamicsusing a particle-based Graph Neural Network model, and often requiretime-consuming 3D scene reconstruction to obtain 3D particle tracks fortraining. In this work, we present ParticleFormer, a Transformer-based pointcloud world model trained with a hybrid point cloud reconstruction loss,supervising both global and local dynamics features in multi-material,multi-object robot interactions. ParticleFormer captures fine-grainedmulti-object interactions between rigid, deformable, and flexible materials,trained directly from real-world robot perception data without an elaboratescene reconstruction. We demonstrate the model's effectiveness both in 3D sceneforecasting tasks, and in downstream manipulation tasks using a ModelPredictive Control (MPC) policy. In addition, we extend existing dynamicslearning benchmarks to include diverse multi-material, multi-object interactionscenarios. We validate our method on six simulation and three real-worldexperiments, where it consistently outperforms leading baselines by achievingsuperior dynamics prediction accuracy and less rollout error in downstreamvisuomotor tasks. Experimental videos are available athttps://particleformer.github.io/.</description>
      <author>example@mail.com (Suning Huang, Qianzhong Chen, Xiaohan Zhang, Jiankai Sun, Mac Schwager)</author>
      <guid isPermaLink="false">2506.23126v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21541v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Mamba-based方法在点云表示学习方面表现出色，但存在破坏3D点邻接关系和未能保留长序列记忆的问题。StruMamba3D通过设计空间状态、改进SSM和使用序列长度自适应策略解决这些问题，并在多个任务中展现出优越性能。&lt;h4&gt;背景&lt;/h4&gt;Mamba-based方法在点云表示学习中的表现以及SSM的局限性。&lt;h4&gt;目的&lt;/h4&gt;提出StruMamba3D方法，以解决Mamba-based方法中存在的问题，提高点云表示学习的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 设计空间状态以保持点间空间依赖性；2. 改进SSM并加入轻量级卷积以促进空间状态之间的交互；3. 引入序列长度自适应策略以减少对输入长度的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;StruMamba3D在多个下游任务中展现出优于其他方法的性能，并在ModelNet40和ScanObjectNN的挑战性数据集上取得了SOTA的准确率。&lt;h4&gt;结论&lt;/h4&gt;StruMamba3D是一个有效的点云表示学习方法，能够提高点云表示学习的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Mamba-based methods have demonstrated impressive performance inpoint cloud representation learning by leveraging State Space Model (SSM) withthe efficient context modeling ability and linear complexity. However, thesemethods still face two key issues that limit the potential of SSM: Destroyingthe adjacency of 3D points during SSM processing and failing to retainlong-sequence memory as the input length increases in downstream tasks. Toaddress these issues, we propose StruMamba3D, a novel paradigm forself-supervised point cloud representation learning. It enjoys several merits.First, we design spatial states and use them as proxies to preserve spatialdependencies among points. Second, we enhance the SSM with a state-wise updatestrategy and incorporate a lightweight convolution to facilitate interactionsbetween spatial states for efficient structure modeling. Third, our methodreduces the sensitivity of pre-trained Mamba-based models to varying inputlengths by introducing a sequence length-adaptive strategy. Experimentalresults across four downstream tasks showcase the superior performance of ourmethod. In addition, our method attains the SOTA 95.1% accuracy on ModelNet40and 92.75% accuracy on the most challenging split of ScanObjectNN withoutvoting strategy.</description>
      <author>example@mail.com (Chuxin Wang, Yixin Zha, Wenfei Yang, Tianzhu Zhang)</author>
      <guid isPermaLink="false">2506.21541v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21096v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACL 2025 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DALR的多模态句子表示学习方法，旨在解决现有方法在跨模态对齐和模内语义差异方面的挑战，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态句子表示学习方法主要关注图像和文本的粗粒度对齐，但存在跨模态对齐偏差和模内语义差异问题，这些问题会降低句子表示的质量。&lt;h4&gt;目的&lt;/h4&gt;提出DALR方法，以解决跨模态对齐偏差和模内语义差异问题，从而提高句子表示的质量。&lt;h4&gt;方法&lt;/h4&gt;DALR方法包括：1. 提出一致性学习模块，通过软化负样本和利用辅助任务中的语义相似度实现细粒度跨模态对齐；2. 认为句子关系不仅仅是正负标签，而是更复杂的排名结构；3. 通过整合排名蒸馏和全局模内对齐学习来更好地捕捉这些关系。&lt;h4&gt;主要发现&lt;/h4&gt;在语义文本相似度（STS）和迁移（TR）任务上的实验表明，DALR方法在性能上优于现有的最佳基线。&lt;h4&gt;结论&lt;/h4&gt;DALR方法有效地解决了跨模态对齐和模内语义差异问题，提高了句子表示的质量。&lt;h4&gt;翻译&lt;/h4&gt;Previous multimodal sentence representation learning methods have achieved impressive performance. However, most approaches focus on aligning images and text at a coarse level, facing two critical challenges: cross-modal misalignment bias and intra-modal semantic divergence, which significantly degrade sentence representation quality. To address these challenges, we propose DALR (Dual-level Alignment Learning for Multimodal Sentence Representation). For cross-modal alignment, we propose a consistency learning module that softens negative samples and utilizes semantic similarity from an auxiliary task to achieve fine-grained cross-modal alignment. Additionally, we contend that sentence relationships go beyond binary positive-negative labels, exhibiting a more intricate ranking structure. To better capture these relationships and enhance representation quality, we integrate ranking distillation with global intra-modal alignment learning. Comprehensive experiments on semantic textual similarity (STS) and transfer (TR) tasks validate the effectiveness of our approach, consistently demonstrating its superiority over state-of-the-art baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Previous multimodal sentence representation learning methods have achievedimpressive performance. However, most approaches focus on aligning images andtext at a coarse level, facing two critical challenges:cross-modal misalignmentbias and intra-modal semantic divergence, which significantly degrade sentencerepresentation quality. To address these challenges, we propose DALR(Dual-level Alignment Learning for Multimodal Sentence Representation). Forcross-modal alignment, we propose a consistency learning module that softensnegative samples and utilizes semantic similarity from an auxiliary task toachieve fine-grained cross-modal alignment. Additionally, we contend thatsentence relationships go beyond binary positive-negative labels, exhibiting amore intricate ranking structure. To better capture these relationships andenhance representation quality, we integrate ranking distillation with globalintra-modal alignment learning. Comprehensive experiments on semantic textualsimilarity (STS) and transfer (TR) tasks validate the effectiveness of ourapproach, consistently demonstrating its superiority over state-of-the-artbaselines.</description>
      <author>example@mail.com (Kang He, Yuzhe Ding, Haining Wang, Fei Li, Chong Teng, Donghong Ji)</author>
      <guid isPermaLink="false">2506.21096v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>HyperCLOVA X THINK Technical Report</title>
      <link>http://arxiv.org/abs/2506.22403v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  50 pages, 13 figures; fixed figures in the appendix&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了HyperCLOVA X THINK，这是HyperCLOVA X家族中第一个以推理为重点的大型语言模型，在约6000亿高质量的韩语和英语标记上进行预训练，并辅以目标化的合成韩语数据。&lt;h4&gt;背景&lt;/h4&gt;该模型通过一个计算-内存平衡的Peri-LN Transformer实现，使用μP进行扩展，通过三个阶段的课程预训练，将上下文窗口扩展到128K个标记，并通过可验证奖励的强化学习进行后训练。&lt;h4&gt;目的&lt;/h4&gt;HyperCLOVA X THINK旨在提供详细的推理和简洁答案模式，同时保持韩语和英语的双语一致性和翻译质量。&lt;h4&gt;方法&lt;/h4&gt;模型在KMMLU、CSAT、KoBALT-700、HAERAE-1.0和KoBigBench等以韩国为重点的基准测试中表现出与类似规模的模型相竞争的性能，并且通过修剪和蒸馏技术降低了训练计算量。&lt;h4&gt;主要发现&lt;/h4&gt;HyperCLOVA X THINK在KCSAT STEM基准测试中与GPT-4.1相当或超过，同时训练计算量显著低于同类模型。&lt;h4&gt;结论&lt;/h4&gt;HyperCLOVA X THINK作为一个健壮的基础模型，为韩国AI创新提供了坚实的基础，并且对全球研究社区来说是一个有价值的资源。&lt;h4&gt;翻译&lt;/h4&gt;HyperCLOVA X THINK是HyperCLOVA X家族中第一个以推理为核心的大型语言模型，它在大约6000亿高质量的韩语和英语标记上进行预训练，并辅以专门合成的韩语数据。该模型采用计算-内存平衡的Peri-LN Transformer架构，通过μP进行扩展，并经过三个阶段的课程预训练，将上下文窗口扩展至128K个标记。通过可验证奖励的强化学习进行后训练，支持详细推理和简洁答案模式。在KMMLU、CSAT、KoBALT-700、HAERAE-1.0和KoBigBench等以韩国为重点的基准测试中，HyperCLOVA X THINK的表现与同类规模模型相竞争，同时保持了韩语和英语的双语一致性和翻译质量。此外，在KCSAT STEM基准测试中，该模型的表现与GPT-4.1相当或超过，而训练计算量却显著低于同类模型。我们还提出了一种修剪和蒸馏技术，将很快应用于HyperCLOVA X THINK，以创建一个开源且对商业友好的基础模型。总的来说，这些能力使HyperCLOVA X THINK成为韩国AI创新的坚实基础，并为全球研究社区提供了一个有价值的资源。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce HyperCLOVA X THINK, the first reasoning-focused large languagemodel in the HyperCLOVA X family, pre-trained on roughly $6$ trillionhigh-quality Korean, and English tokens, augmented with targeted syntheticKorean data. It was implemented as a compute-memory-balanced Peri-LNTransformer scaled with $\mu$P, pre-trained through a three-stage curriculumthat expands the context window to $128$K tokens, and post-trained viasupervised fine-tuning with Reinforcement Learning from Verifiable Rewardssupports both detailed rationale and concise-answer modes. It deliverscompetitive performance against similarly sized models on Korea-focusedbenchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, whilepreserving robust bilingual consistency and translation quality. In addition, avision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEMbenchmark, all of which are achieved with substantially lower training computethan existing models of similar sizes. We also present a pruning anddistillation technique that will soon be applied to HyperCLOVA X THINK for anopen-source and business-friendly foundation model. Altogether, thesecapabilities position HyperCLOVA X THINK as a robust foundation for Korean AIinnovation and a valuable resource for the global research community.</description>
      <author>example@mail.com (NAVER Cloud HyperCLOVA X Team)</author>
      <guid isPermaLink="false">2506.22403v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.19288v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对水道环境的自动感知方法，旨在提高无人水面船舶（USVs）对周围环境的理解能力，使其能够做出明智的决策。&lt;h4&gt;背景&lt;/h4&gt;现有的水道感知模型主要关注实例级对象感知范式，如检测和分割，但未能实现水道的全局语义理解，限制了大规模监控和结构化日志生成。&lt;h4&gt;目的&lt;/h4&gt;通过利用视觉-语言模型（VLMs）和图像字幕技术，提高USVs在水道环境中的感知能力。&lt;h4&gt;方法&lt;/h4&gt;提出了WaterCaption，这是第一个专门为水道环境设计的字幕数据集，包含20.2k个图像-文本对，词汇量达180万。同时，提出了Da Yu模型，这是一个边缘部署的多模态大型语言模型，包含一个名为Nano Transformer Adaptor（NTA）的视觉到语言的投影器。&lt;h4&gt;主要发现&lt;/h4&gt;NTA有效地平衡了计算效率和全局以及细粒度局部视觉特征的建模能力，显著提高了模型生成长文本输出的能力。&lt;h4&gt;结论&lt;/h4&gt;Da Yu模型在WaterCaption和其他字幕基准测试中实现了性能和效率的最佳平衡，超越了最先进的模型。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自动化水道环境感知对于使无人水面船舶（USVs）能够理解其周围环境并做出明智的决策至关重要。大多数现有的水道感知模型主要关注实例级对象感知范式（例如，检测、分割）。然而，由于水道环境的复杂性，当前的感知数据集和模型未能实现水道的全局语义理解，限制了大规模监控和结构化日志生成。随着视觉-语言模型（VLMs）的进步，我们利用图像字幕技术引入了WaterCaption，这是第一个专门为水道环境设计的字幕数据集。WaterCaption专注于细粒度、多区域长文本描述，为视觉地理理解和空间场景认知提供了新的研究方向。确切地说，它包括20.2k个图像-文本对数据，词汇量为180万。此外，我们提出了Da Yu，这是一个为USVs设计的边缘部署的多模态大型语言模型，其中我们提出了一种新颖的视觉到语言投影器，称为Nano Transformer Adaptor（NTA）。NTA有效地平衡了计算效率与全局和细粒度局部建模视觉特征的能力，从而显著提高了模型生成长文本输出的能力。Da Yu在性能和效率之间实现了最佳平衡，在WaterCaption和其他几个字幕基准测试中超过了最先进的模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated waterway environment perception is crucial for enabling unmannedsurface vessels (USVs) to understand their surroundings and make informeddecisions. Most existing waterway perception models primarily focus oninstance-level object perception paradigms (e.g., detection, segmentation).However, due to the complexity of waterway environments, current perceptiondatasets and models fail to achieve global semantic understanding of waterways,limiting large-scale monitoring and structured log generation. With theadvancement of vision-language models (VLMs), we leverage image captioning tointroduce WaterCaption, the first captioning dataset specifically designed forwaterway environments. WaterCaption focuses on fine-grained, multi-regionlong-text descriptions, providing a new research direction for visualgeo-understanding and spatial scene cognition. Exactly, it includes 20.2kimage-text pair data with 1.8 million vocabulary size. Additionally, we proposeDa Yu, an edge-deployable multi-modal large language model for USVs, where wepropose a novel vision-to-language projector called Nano Transformer Adaptor(NTA). NTA effectively balances computational efficiency with the capacity forboth global and fine-grained local modeling of visual features, therebysignificantly enhancing the model's ability to generate long-form textualoutputs. Da Yu achieves an optimal balance between performance and efficiency,surpassing state-of-the-art models on WaterCaption and several other captioningbenchmarks.</description>
      <author>example@mail.com (Runwei Guan, Ningwei Ouyang, Tianhao Xu, Shaofeng Liang, Wei Dai, Yafeng Sun, Shang Gao, Songning Lai, Shanliang Yao, Xuming Hu, Ryan Wen Liu, Yutao Yue, Hui Xiong)</author>
      <guid isPermaLink="false">2506.19288v2</guid>
      <pubDate>Wed, 02 Jul 2025 14:10:41 +0800</pubDate>
    </item>
    <item>
      <title>AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention</title>
      <link>http://arxiv.org/abs/2506.23611v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为AttentionGS的新框架，用于改进3D Gaussian Splatting技术，以解决其在复杂场景重建和高效渲染方面的优势，但依赖于高质量点云和SfM技术的问题。&lt;h4&gt;背景&lt;/h4&gt;3D Gaussian Splatting（3DGS）作为一种强大的场景重建和渲染技术，在复杂场景重建和高效渲染方面表现优异，但其依赖于结构从运动（SfM）技术生成的高质量点云，限制了其应用范围。&lt;h4&gt;目的&lt;/h4&gt;为了解决3DGS对高质量点云的依赖和SfM在纹理缺乏或视角受限场景下的不足，提出了一种新的框架AttentionGS，以实现直接从随机初始化中进行3D重建。&lt;h4&gt;方法&lt;/h4&gt;在训练早期，引入几何注意力以快速恢复全局场景结构；随着训练的进行，引入纹理注意力以细化细节并提升渲染质量；采用不透明度加权的梯度来引导高斯密度化，从而改善表面重建。&lt;h4&gt;主要发现&lt;/h4&gt;在多个基准数据集上的实验表明，AttentionGS在点云初始化不可靠的场景中显著优于现有技术，为更稳健和灵活的3D Gaussian Splatting在现实世界应用中铺平了道路。&lt;h4&gt;结论&lt;/h4&gt;AttentionGS框架通过引入注意力机制，有效地解决了3DGS在复杂场景重建和渲染中的局限性，为该技术在现实世界中的应用提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) is a powerful alternative to Neural RadianceFields (NeRF), excelling in complex scene reconstruction and efficientrendering. However, it relies on high-quality point clouds fromStructure-from-Motion (SfM), limiting its applicability. SfM also fails intexture-deficient or constrained-view scenarios, causing severe degradation in3DGS reconstruction. To address this limitation, we propose AttentionGS, anovel framework that eliminates the dependency on high-quality initial pointclouds by leveraging structural attention for direct 3D reconstruction fromrandomly initialization. In the early training stage, we introduce geometricattention to rapidly recover the global scene structure. As trainingprogresses, we incorporate texture attention to refine fine-grained details andenhance rendering quality. Furthermore, we employ opacity-weighted gradients toguide Gaussian densification, leading to improved surface reconstruction.Extensive experiments on multiple benchmark datasets demonstrate thatAttentionGS significantly outperforms state-of-the-art methods, particularly inscenarios where point cloud initialization is unreliable. Our approach pavesthe way for more robust and flexible 3D Gaussian Splatting in real-worldapplications.</description>
      <author>example@mail.com (Ziao Liu, Zhenjia Li, Yifeng Shi, Xiangang Li)</author>
      <guid isPermaLink="false">2506.23611v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
  <item>
      <title>Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data</title>
      <link>http://arxiv.org/abs/2506.24039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This manuscript is a draft on arxiv. A final version has been  submitted to the 59th ICPP 2025, DRAI workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为Zenesis的无代码交互平台，用于降低科学图像数据准备难度，并通过轻量级多模态适应技术和人类在环改进以及启发式时间增强选项，实现零样本操作。&lt;h4&gt;背景&lt;/h4&gt;零样本和提示技术利用常见图像进行视觉推理任务，但难以处理珍贵且稀缺的科学图像集。&lt;h4&gt;目的&lt;/h4&gt;Zenesis平台旨在减少科学图像数据准备的障碍。&lt;h4&gt;方法&lt;/h4&gt;Zenesis平台采用轻量级多模态适应技术，实现原始科学数据的零样本操作，并提供了人类在环改进和启发式时间增强选项。&lt;h4&gt;主要发现&lt;/h4&gt;在挑战性的FIB-SEM催化剂负载膜数据上，Zenesis的平均准确率达到0.947，Intersection over Union (IOU)为0.858，Dice分数为0.923，对非晶态催化剂样本；对晶态样本，准确率为0.987，IOU为0.857，Dice分数为0.923。这些结果超过了传统的Otsu阈值方法和Segment Anything Model (SAM)等先进模型。&lt;h4&gt;结论&lt;/h4&gt;Zenesis是一个强大的科学应用工具，尤其是在高质量标注数据集不可用的情况下，能够加速实验成像的准确分析。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a no-code interactive platform named Zenesis to reduce the barriers of data preparation for scientific images, and uses lightweight multi-modal adaptation techniques, human-in-the-loop refinement, and heuristic-based temporal enhancement options to achieve zero-shot operation on raw scientific data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot and prompt-based technologies capitalized on using frequentlyoccurring images to transform visual reasoning tasks, which explains why suchtechnologies struggle with valuable yet scarce scientific image sets. In thiswork, we propose Zenesis, a comprehensive no-code interactive platform designedto minimize barriers posed by data readiness for scientific images. We developlightweight multi-modal adaptation techniques that enable zero-shot operationon raw scientific data, along with human-in-the-loop refinement andheuristic-based temporal enhancement options. We demonstrate the performance ofour approach through comprehensive comparison and validation on challengingFocused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loadedmembranes. Zenesis significantly outperforms baseline methods, achieving anaverage accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and aDice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, anIOU of 0.857, and a Dice score of 0.923 for crystalline samples. These resultsmark a substantial improvement over traditional methods like Otsu thresholdingand even advanced models like Segment Anything Model (SAM) when used inisolation. Our results demonstrate that Zenesis is a powerful tool forscientific applications, particularly in fields where high-quality annotateddatasets are unavailable, accelerating accurate analysis of experimentalimaging.</description>
      <author>example@mail.com (Shubhabrata Mukherjee, Jack Lang, Obeen Kwon, Iryna Zenyuk, Valerie Brogden, Adam Weber, Daniela Ushizima)</author>
      <guid isPermaLink="false">2506.24039v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Teaching Time Series to See and Speak: Forecasting with Aligned Visual and Textual Perspectives</title>
      <link>http://arxiv.org/abs/2506.24124v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/Ironieser/TimesCLIP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种多模态对比学习框架，用于时间序列预测，该框架能够将原始时间序列数据转化为结构化的视觉和文本表示，并通过对比学习在共享语义空间中对齐这些表示，以提高预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;传统时间序列预测方法依赖于单模态的数值输入，难以捕捉高级语义模式。现有的基于大语言模型的方法在表示时间序列方面有限，且缺乏人类通常应用的感知直觉。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过多模态对比学习框架来改善时间序列预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;将原始时间序列数据转换为视觉和文本表示，并直接从数值序列构建这两种模态。通过对比学习在共享语义空间中对齐这些表示，引入了变量选择模块来识别对多变量预测最有信息量的变量。&lt;h4&gt;主要发现&lt;/h4&gt;在十五个短期和六个长期预测基准测试中，该方法在时间序列预测方面优于强单模态和跨模态基线。&lt;h4&gt;结论&lt;/h4&gt;多模态对齐在提高时间序列预测效果方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;The proposed multimodal contrastive learning framework transforms raw time series into structured visual and textual perspectives, aligns these views in a shared semantic space via contrastive learning, and enhances time series forecasting accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting traditionally relies on unimodal numerical inputs,which often struggle to capture high-level semantic patterns due to their denseand unstructured nature. While recent approaches have explored representingtime series as text using large language models (LLMs), these methods remainlimited by the discrete nature of token sequences and lack the perceptualintuition humans typically apply, such as interpreting visual patterns. In thispaper, we propose a multimodal contrastive learning framework that transformsraw time series into structured visual and textual perspectives. Rather thanusing natural language or real-world images, we construct both modalitiesdirectly from numerical sequences. We then align these views in a sharedsemantic space via contrastive learning, enabling the model to capture richerand more complementary representations. Furthermore, we introduce a variateselection module that leverages the aligned representations to identify themost informative variables for multivariate forecasting. Extensive experimentson fifteen short-term and six long-term forecasting benchmarks demonstrate thatour approach consistently outperforms strong unimodal and cross-modalbaselines, highlighting the effectiveness of multimodal alignment in enhancingtime series forecasting. Code is available at:https://github.com/Ironieser/TimesCLIP.</description>
      <author>example@mail.com (Dong Sixun, Fan Wei, Teresa Wu, Fu Yanjie)</author>
      <guid isPermaLink="false">2506.24124v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving</title>
      <link>http://arxiv.org/abs/2506.23565v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对象中心的辐射场（OcRF）的多视图3D物体检测方法，旨在提高3D几何估计能力，并通过实验证明该方法在nuScenes数据集上取得了优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;当前的多视图3D物体检测方法通常通过深度估计或3D位置编码将2D特征转换为3D空间，但这种转换方式在数据驱动和隐式方面存在局限性，影响了检测性能。&lt;h4&gt;目的&lt;/h4&gt;旨在通过利用辐射场在3D重建中的成功，增强检测器对3D几何估计的能力。&lt;h4&gt;方法&lt;/h4&gt;提出对象中心的辐射场（OcRF），通过渲染前景对象作为辅助任务来增强3D体素特征。此外，使用不透明度（渲染的副产品）通过高度感知不透明度注意力（HOA）来增强2D前景BEV特征，其中不同高度级别的注意力图由多个并行网络分别生成。&lt;h4&gt;主要发现&lt;/h4&gt;直接使用辐射场进行3D渲染作为辅助任务时，检测性能会下降，这是由于渲染整个场景时背景的强烈响应导致的。&lt;h4&gt;结论&lt;/h4&gt;OcRFDet在nuScenes测试基准上达到了57.2%的mAP和64.8%的NDS，优于之前的最先进方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要原文：Current multi-view 3D object detection methods typically transfer 2D features into 3D space using depth estimation or 3D position encoder, but in a fully data-driven and implicit manner, which limits the detection performance. Inspired by the success of radiance fields on 3D reconstruction, we assume they can be used to enhance the detector's ability of 3D geometry estimation. However, we observe a decline in detection performance, when we directly use them for 3D rendering as an auxiliary task. From our analysis, we find the performance drop is caused by the strong responses on the background when rendering the whole scene. To address this problem, we propose object-centric radiance fields, focusing on modeling foreground objects while discarding background noises. Specifically, we employ Object-centric Radiance Fields (OcRF) to enhance 3D voxel features via an auxiliary task of rendering foreground objects. We further use opacity - the side-product of rendering - to enhance the 2D foreground BEV features via Height-aware Opacity-based Attention (HOA), where attention maps at different height levels are generated separately via multiple networks in parallel. Extensive experiments on the nuScenes validation and test datasets demonstrate that our OcRFDet achieves superior performance, outperforming previous state-of-the-art methods with 57.2% mAP and 64.8% NDS on the nuScenes test benchmark. Code will be available at https://github.com/Mingqj/OcRFDet.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Current multi-view 3D object detection methods typically transfer 2D featuresinto 3D space using depth estimation or 3D position encoder, but in a fullydata-driven and implicit manner, which limits the detection performance.Inspired by the success of radiance fields on 3D reconstruction, we assume theycan be used to enhance the detector's ability of 3D geometry estimation.However, we observe a decline in detection performance, when we directly usethem for 3D rendering as an auxiliary task. From our analysis, we find theperformance drop is caused by the strong responses on the background whenrendering the whole scene. To address this problem, we propose object-centricradiance fields, focusing on modeling foreground objects while discardingbackground noises. Specifically, we employ Object-centric Radiance Fields(OcRF) to enhance 3D voxel features via an auxiliary task of renderingforeground objects. We further use opacity - the side-product of rendering- toenhance the 2D foreground BEV features via Height-aware Opacity-based Attention(HOA), where attention maps at different height levels are generated separatelyvia multiple networks in parallel. Extensive experiments on the nuScenesvalidation and test datasets demonstrate that our OcRFDet achieves superiorperformance, outperforming previous state-of-the-art methods with 57.2$\%$ mAPand 64.8$\%$ NDS on the nuScenes test benchmark. Code will be available athttps://github.com/Mingqj/OcRFDet.</description>
      <author>example@mail.com (Mingqian Ji, Jian Yang, Shanshan Zhang)</author>
      <guid isPermaLink="false">2506.23565v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Scaling Self-Supervised Representation Learning for Symbolic Piano Performance</title>
      <link>http://arxiv.org/abs/2506.23869v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ISMIR (2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究基于大量符号独奏钢琴乐谱训练的生成自回归Transformer模型的能力。&lt;h4&gt;背景&lt;/h4&gt;模型在约60,000小时的音乐上进行预训练。&lt;h4&gt;目的&lt;/h4&gt;使用高质量的小样本集微调模型，以生成音乐续作、执行符号分类任务，并通过改进SimCLR框架来产生符号音乐的通用对比MIDI嵌入。&lt;h4&gt;方法&lt;/h4&gt;使用改进的SimCLR框架，在MIR分类基准测试中，冻结的对比模型表示在线性探针实验中达到最先进的结果。&lt;h4&gt;主要发现&lt;/h4&gt;在钢琴续作连贯性评估中，该生成模型优于领先的符号生成技术，并且与专有音频生成模型保持竞争力。&lt;h4&gt;结论&lt;/h4&gt;预训练表示的泛化能力得到证明，通常只需要几百个标记示例就能专门用于下游任务。&lt;h4&gt;翻译&lt;/h4&gt;我们研究了基于大量符号独奏钢琴乐谱训练的生成自回归Transformer模型的能力。在约60,000小时的预训练之后，我们使用一个相对较小的高质量子集来微调模型以生成音乐续作，执行符号分类任务，并通过改进SimCLR框架来生成符号音乐的通用对比MIDI嵌入。在评估钢琴续作连贯性时，我们的生成模型优于领先的符号生成技术，并且与专有音频生成模型保持竞争力。在MIR分类基准测试中，我们的对比模型的冻结表示在线性探针实验中达到了最先进的结果，而直接微调则证明了预训练表示的泛化能力，通常只需要几百个标记示例就能专门用于下游任务。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We study the capabilities of generative autoregressive transformer modelstrained on large amounts of symbolic solo-piano transcriptions. After firstpretraining on approximately 60,000 hours of music, we use a comparativelysmaller, high-quality subset, to finetune models to produce musicalcontinuations, perform symbolic classification tasks, and producegeneral-purpose contrastive MIDI embeddings by adapting the SimCLR framework tosymbolic music. When evaluating piano continuation coherence, our generativemodel outperforms leading symbolic generation techniques and remainscompetitive with proprietary audio generation models. On MIR classificationbenchmarks, frozen representations from our contrastive model achievestate-of-the-art results in linear probe experiments, while direct finetuningdemonstrates the generalizability of pretrained representations, oftenrequiring only a few hundred labeled examples to specialize to downstreamtasks.</description>
      <author>example@mail.com (Louis Bradshaw, Honglu Fan, Alexander Spangher, Stella Biderman, Simon Colton)</author>
      <guid isPermaLink="false">2506.23869v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum</title>
      <link>http://arxiv.org/abs/2506.23607v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PGOV3D的新框架，用于改进开放词汇的3D语义分割，通过两个阶段的训练策略来提高模型的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的开放词汇3D语义分割方法通常通过将多视角图像中的文本对齐特征合并到3D点上对模型进行监督，但这种方法忽略了多视角图像的丰富语义内容和跨视角对应关系。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以解决现有方法中多视角图像语义内容未被充分利用的问题，从而提高开放词汇3D语义分割的效果。&lt;h4&gt;方法&lt;/h4&gt;PGOV3D框架采用两个阶段的训练策略：第一阶段在提供密集语义信息但相对简单几何形状的部分场景上预训练模型；第二阶段在完整的场景级点云上微调模型。此外，使用多模态大型语言模型和2D分割基础模型生成开放词汇标签，并引入辅助帧间一致性模块来增强空间理解。&lt;h4&gt;主要发现&lt;/h4&gt;PGOV3D在ScanNet、ScanNet200和S3DIS基准测试中实现了有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;PGOV3D通过引入部分到全局的课程和两个阶段的训练策略，有效地提高了开放词汇3D语义分割的性能。&lt;h4&gt;翻译&lt;/h4&gt;Existing open-vocabulary 3D semantic segmentation methods typically supervise 3D segmentation models by merging text-aligned features (e.g., CLIP) extracted from multi-view images onto 3D points. However, such approaches treat multi-view images merely as intermediaries for transferring open-vocabulary information, overlooking their rich semantic content and cross-view correspondences, which limits model effectiveness. To address this, we propose PGOV3D, a novel framework that introduces a Partial-to-Global curriculum for improving open-vocabulary 3D semantic segmentation. The key innovation lies in a two-stage training strategy. In the first stage, we pre-train the model on partial scenes that provide dense semantic information but relatively simple geometry. These partial point clouds are derived from multi-view RGB-D inputs via pixel-wise depth projection. To enable open-vocabulary learning, we leverage a multi-modal large language model (MLLM) and a 2D segmentation foundation model to generate open-vocabulary labels for each viewpoint, offering rich and aligned supervision. An auxiliary inter-frame consistency module is introduced to enforce feature consistency across varying viewpoints and enhance spatial understanding. In the second stage, we fine-tune the model on complete scene-level point clouds, which are sparser and structurally more complex. We aggregate the partial vocabularies associated with each scene and generate pseudo labels using the pre-trained model, effectively bridging the semantic gap between dense partial observations and large-scale 3D environments. Extensive experiments on ScanNet, ScanNet200, and S3DIS benchmarks demonstrate that PGOV3D achieves competitive performance in open-vocabulary 3D semantic segmentation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing open-vocabulary 3D semantic segmentation methods typically supervise3D segmentation models by merging text-aligned features (e.g., CLIP) extractedfrom multi-view images onto 3D points. However, such approaches treatmulti-view images merely as intermediaries for transferring open-vocabularyinformation, overlooking their rich semantic content and cross-viewcorrespondences, which limits model effectiveness. To address this, we proposePGOV3D, a novel framework that introduces a Partial-to-Global curriculum forimproving open-vocabulary 3D semantic segmentation. The key innovation lies ina two-stage training strategy. In the first stage, we pre-train the model onpartial scenes that provide dense semantic information but relatively simplegeometry. These partial point clouds are derived from multi-view RGB-D inputsvia pixel-wise depth projection. To enable open-vocabulary learning, weleverage a multi-modal large language model (MLLM) and a 2D segmentationfoundation model to generate open-vocabulary labels for each viewpoint,offering rich and aligned supervision. An auxiliary inter-frame consistencymodule is introduced to enforce feature consistency across varying viewpointsand enhance spatial understanding. In the second stage, we fine-tune the modelon complete scene-level point clouds, which are sparser and structurally morecomplex. We aggregate the partial vocabularies associated with each scene andgenerate pseudo labels using the pre-trained model, effectively bridging thesemantic gap between dense partial observations and large-scale 3Denvironments. Extensive experiments on ScanNet, ScanNet200, and S3DISbenchmarks demonstrate that PGOV3D achieves competitive performance inopen-vocabulary 3D semantic segmentation.</description>
      <author>example@mail.com (Shiqi Zhang, Sha Zhang, Jiajun Deng, Yedong Shen, Mingxiao MA, Yanyong Zhang)</author>
      <guid isPermaLink="false">2506.23607v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Flash-VStream: Efficient Real-Time Understanding for Long Video Streams</title>
      <link>http://arxiv.org/abs/2506.23825v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Flash-VStream的效率高的视频语言模型，能够处理极长视频并实时响应用户查询。&lt;h4&gt;背景&lt;/h4&gt;现有多模态大型语言模型在图像和短视频理解方面表现出色，但长视频的理解仍然具有挑战性，因为它们的长上下文特性导致计算和内存开销很大。&lt;h4&gt;目的&lt;/h4&gt;针对长视频理解的问题，提出Flash-VStream模型，以提高处理极长视频和实时响应查询的效率。&lt;h4&gt;方法&lt;/h4&gt;设计了一个包含低容量上下文内存和高度量化的增强内存的Flash Memory模块，低容量上下文内存用于聚合长上下文时间信息并建模信息密度分布，高度量化的增强内存则根据此分布检索详细的空间信息。&lt;h4&gt;主要发现&lt;/h4&gt;与现有模型相比，Flash-VStream在推理延迟上实现了显著降低。&lt;h4&gt;结论&lt;/h4&gt;在多个长视频基准测试和综合视频基准测试（如EgoSchema、MLVU、LVBench、MVBench和Video-MME）上进行的广泛实验表明，该方法在性能和效率方面都达到了最先进水平。&lt;h4&gt;翻译&lt;/h4&gt;摘要：得益于大型语言模型和跨模态对齐的进步，现有的多模态大型语言模型在图像和短视频理解方面取得了显著的性能。然而，由于长视频的长上下文特性，其理解仍然具有挑战性，这导致计算和内存开销很大。大多数现有工作将长视频视为与短视频相同，这对于现实世界应用来说效率低下，并且难以推广到更长视频。为了解决这些问题，我们提出了Flash-VStream，这是一个高效的视频语言模型，能够处理极长视频并实时响应用户查询。特别是，我们设计了一个Flash Memory模块，包含一个低容量上下文内存来聚合长上下文时间信息并建模信息密度分布，以及一个高容量增强内存来根据这个分布检索详细的空间信息。与现有模型相比，Flash-VStream在推理延迟上实现了显著降低。在长视频基准测试和综合视频基准测试（即EgoSchema、MLVU、LVBench、MVBench和Video-MME）上进行的广泛实验证明了我们方法的最先进性能和卓越效率。代码可在https://github.com/IVGSZ/Flash-VStream上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Benefiting from the advances in large language models and cross-modalalignment, existing multimodal large language models have achieved prominentperformance in image and short video understanding. However, the understandingof long videos is still challenging, as their long-context nature results insignificant computational and memory overhead. Most existing work treats longvideos in the same way as short videos, which is inefficient for real-worldapplications and hard to generalize to even longer videos. To address theseissues, we propose Flash-VStream, an efficient video language model capable ofprocessing extremely long videos and responding to user queries in real time.Particularly, we design a Flash Memory module, containing a low-capacitycontext memory to aggregate long-context temporal information and model thedistribution of information density, and a high-capacity augmentation memory toretrieve detailed spatial information based on this distribution. Compared toexisting models, Flash-VStream achieves significant reductions in inferencelatency. Extensive experiments on long video benchmarks and comprehensive videobenchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstratethe state-of-the-art performance and outstanding efficiency of our method. Codeis available at https://github.com/IVGSZ/Flash-VStream.</description>
      <author>example@mail.com (Haoji Zhang, Yiqin Wang, Yansong Tang, Yong Liu, Jiashi Feng, Xiaojie Jin)</author>
      <guid isPermaLink="false">2506.23825v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation</title>
      <link>http://arxiv.org/abs/2506.23227v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by TPAMI. Code: https://github.com/LHDuan/WSegPC&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了室内点云语义分割在场景级标注下的情况，与依赖于稀疏点级标签的方法相比，场景级标注的方法探索较少。为了提高精度，本文提出了一种高质量的伪标签生成框架，通过探索多模态信息和区域-点语义一致性来生成伪标签。&lt;h4&gt;背景&lt;/h4&gt;在缺乏精确的点级标签的情况下，当前的方法首先生成点级伪标签，然后使用这些伪标签来训练分割模型。然而，仅基于场景级标注为每个点生成准确的伪标签是一项相当大的挑战，这会严重影响分割性能。&lt;h4&gt;目的&lt;/h4&gt;为了提高场景级标注下的点云语义分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法包括：1）一个跨模态特征引导模块，利用2D-3D对应关系将点云特征与相应的2D图像像素对齐，以辅助点云特征学习；2）一个区域-点语义一致性模块，通过从点级语义中派生的区域投票策略生成区域语义，这些语义随后用于指导点级语义预测。&lt;h4&gt;主要发现&lt;/h4&gt;在ScanNet v2和S3DIS数据集上，与之前的工作相比，本文的方法在场景级标注下取得了显著的改进。此外，综合消融研究验证了本文方法各个组成部分的贡献。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在场景级标注下提高了点云语义分割的准确性，并通过实验验证了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates indoor point cloud semantic segmentation under scene-level annotation, which is less explored compared to methods relying on sparse point-level labels. In the absence of precise point-level labels, current methods first generate point-level pseudo-labels, which are then used to train segmentation models. However, generating accurate pseudo-labels for each point solely based on scene-level annotations poses a considerable challenge, substantially affecting segmentation performance. Consequently, to enhance accuracy, this paper proposes a high-quality pseudo-label generation framework by exploring contemporary multi-modal information and region-point semantic consistency. Specifically, with a cross-modal feature guidance module, our method utilizes 2D-3D correspondences to align point cloud features with corresponding 2D image pixels, thereby assisting point cloud feature learning. To further alleviate the challenge presented by the scene-level annotation, we introduce a region-point semantic consistency module. It produces regional semantics through a region-voting strategy derived from point-level semantics, which are subsequently employed to guide the point-level semantic predictions. Leveraging the aforementioned modules, our method can rectify inaccurate point-level semantic predictions during training and obtain high-quality pseudo-labels. Significant improvements over previous works on ScanNet v2 and S3DIS datasets under scene-level annotation can demonstrate the effectiveness. Additionally, comprehensive ablation studies validate the contributions of our approach's individual components. The code is available at https://github.com/LHDuan/WSegPC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates indoor point cloud semantic segmentation underscene-level annotation, which is less explored compared to methods relying onsparse point-level labels. In the absence of precise point-level labels,current methods first generate point-level pseudo-labels, which are then usedto train segmentation models. However, generating accurate pseudo-labels foreach point solely based on scene-level annotations poses a considerablechallenge, substantially affecting segmentation performance. Consequently, toenhance accuracy, this paper proposes a high-quality pseudo-label generationframework by exploring contemporary multi-modal information and region-pointsemantic consistency. Specifically, with a cross-modal feature guidance module,our method utilizes 2D-3D correspondences to align point cloud features withcorresponding 2D image pixels, thereby assisting point cloud feature learning.To further alleviate the challenge presented by the scene-level annotation, weintroduce a region-point semantic consistency module. It produces regionalsemantics through a region-voting strategy derived from point-level semantics,which are subsequently employed to guide the point-level semantic predictions.Leveraging the aforementioned modules, our method can rectify inaccuratepoint-level semantic predictions during training and obtain high-qualitypseudo-labels. Significant improvements over previous works on ScanNet v2 andS3DIS datasets under scene-level annotation can demonstrate the effectiveness.Additionally, comprehensive ablation studies validate the contributions of ourapproach's individual components. The code is available athttps://github.com/LHDuan/WSegPC .</description>
      <author>example@mail.com (Lunhao Duan, Shanshan Zhao, Xingxing Weng, Jing Zhang, Gui-Song Xia)</author>
      <guid isPermaLink="false">2506.23227v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>CoMMiT: Co-informed inference of microbiome-metabolome interactions via transfer learning</title>
      <link>http://arxiv.org/abs/2506.24013v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  38 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为CoMMiT的新方法，用于通过迁移学习模型协同推断微生物组和代谢组之间的相互作用，以提高微生物组-代谢组相互作用检测的统计能力。&lt;h4&gt;背景&lt;/h4&gt;现有的多变量模型在检测微生物组-代谢组相互作用时，由于样本量小和生物信号弱，通常统计能力不足。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出了一种新的迁移学习模型CoMMiT，以增强微生物组-代谢组相互作用检测的统计能力。&lt;h4&gt;方法&lt;/h4&gt;CoMMiT利用同一队列内代谢物之间的相似性，减少了由于测序平台和生物信息学流程差异导致的负迁移风险。它采用灵活的假设，即辅助代谢物集体对目标代谢物具有信息性，而无需每个辅助代谢物都是信息性的。CoMMiT使用数据驱动方法选择最优辅助代谢物集，并通过去偏框架进行有效计算p值。&lt;h4&gt;主要发现&lt;/h4&gt;将CoMMiT应用于一项喂养研究，揭示了在低血糖负荷饮食下，微生物组和代谢组之间存在生物学上有意义的相互作用，证明了饮食与宿主之间的联系。&lt;h4&gt;结论&lt;/h4&gt;CoMMiT是一种有效的工具，可以增强微生物组-代谢组相互作用检测的统计能力，有助于揭示饮食与宿主健康之间的联系。&lt;h4&gt;翻译&lt;/h4&gt;Recent multi-omic microbiome studies enable integrative analysis of microbes and metabolites, uncovering their associations with various host conditions. Such analyses require multivariate models capable of accounting for the complex correlation structures between microbes and metabolites. However, existing multivariate models often suffer from low statistical power for detecting microbiome-metabolome interactions due to small sample sizes and weak biological signals. To address these challenges, we introduce CoMMiT, Co-informed inference of Microbiome-Metabolome Interactions via novel Transfer learning models. Unlike conventional transfer-learning methods that borrow information from external datasets, CoMMiT leverages similarities across metabolites within a single cohort, reducing the risk of negative transfer often caused by differences in sequencing platforms and bioinformatic pipelines across studies. CoMMiT operates under the flexible assumption that auxiliary metabolites are collectively informative for the target metabolite, without requiring individual auxiliary metabolites to be informative. CoMMiT uses a novel data-driven approach to selecting the optimal set of auxiliary metabolites. Using this optimal set, CoMMiT employs a de-biasing framework to enable efficient calculation of p-values, facilitating the identification of statistically significant microbiome-metabolome interactions. Applying CoMMiT to a feeding study reveals biologically meaningful microbiome-metabolome interactions under a low glycemic load diet, demonstrating the diet-host link through gut metabolism.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent multi-omic microbiome studies enable integrative analysis of microbesand metabolites, uncovering their associations with various host conditions.Such analyses require multivariate models capable of accounting for the complexcorrelation structures between microbes and metabolites. However, existingmultivariate models often suffer from low statistical power for detectingmicrobiome-metabolome interactions due to small sample sizes and weakbiological signals. To address these challenges, we introduce CoMMiT,Co-informed inference of Microbiome-Metabolome Interactions via novel Transferlearning models. Unlike conventional transfer-learning methods that borrowinformation from external datasets, CoMMiT leverages similarities acrossmetabolites within a single cohort, reducing the risk of negative transferoften caused by differences in sequencing platforms and bioinformatic pipelinesacross studies. CoMMiT operates under the flexible assumption that auxiliarymetabolites are collectively informative for the target metabolite, withoutrequiring individual auxiliary metabolites to be informative. CoMMiT uses anovel data-driven approach to selecting the optimal set of auxiliarymetabolites. Using this optimal set, CoMMiT employs a de-biasing framework toenable efficient calculation of p-values, facilitating the identification ofstatistically significant microbiome-metabolome interactions. Applying CoMMiTto a feeding study reveals biologically meaningful microbiome-metabolomeinteractions under a low glycemic load diet, demonstrating the diet-host linkthrough gut metabolism.</description>
      <author>example@mail.com (Leiyue Li, Chenglong Ye, Tim Randolph, Meredith Hullar, Johanna Lampe, Marian Neuhouser, Daniel Raftery, Yue Wang)</author>
      <guid isPermaLink="false">2506.24013v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition</title>
      <link>http://arxiv.org/abs/2506.23283v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MoMa的效率适配框架，通过整合Mamba的选择性状态空间建模到图像基础模型（IFMs）中，实现了对视频的全面时空建模。&lt;h4&gt;背景&lt;/h4&gt;视频理解是一个复杂的挑战，需要有效建模时空动态。尽管图像基础模型在图像理解中取得了成功，但大多数方法倾向于分别处理时空信息，可能无法捕捉视频动态的全部复杂性。&lt;h4&gt;目的&lt;/h4&gt;提出MoMa框架，以实现高效的视频理解。&lt;h4&gt;方法&lt;/h4&gt;MoMa通过将SeqMod操作注入到预训练的IFMs中，而不会破坏其原始特征，从而实现时空信息的注入。SeqMod被整合到Divide-and-Modulate架构中，以增强视频理解并保持计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;在多个视频基准测试上的广泛实验表明，MoMa在降低计算成本的同时，实现了优越的性能。&lt;h4&gt;结论&lt;/h4&gt;MoMa框架有效地提升了视频理解能力，为视频处理提供了一种高效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video understanding is a complex challenge that requires effective modelingof spatial-temporal dynamics. With the success of image foundation models(IFMs) in image understanding, recent approaches have exploredparameter-efficient fine-tuning (PEFT) to adapt IFMs for video. However, mostof these methods tend to process spatial and temporal information separately,which may fail to capture the full intricacy of video dynamics. In this paper,we propose MoMa, an efficient adapter framework that achieves fullspatial-temporal modeling by integrating Mamba's selective state space modelinginto IFMs. We propose a novel SeqMod operation to inject spatial-temporalinformation into pre-trained IFMs, without disrupting their original features.By incorporating SeqMod into a Divide-and-Modulate architecture, MoMa enhancesvideo understanding while maintaining computational efficiency. Extensiveexperiments on multiple video benchmarks demonstrate the effectiveness of MoMa,achieving superior performance with reduced computational cost.</description>
      <author>example@mail.com (Yuhuan Yang, Chaofan Ma, Zhenjie Mao, Jiangchao Yao, Ya Zhang, Yanfeng Wang)</author>
      <guid isPermaLink="false">2506.23283v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Ella: Embodied Social Agents with Lifelong Memory</title>
      <link>http://arxiv.org/abs/2506.24019v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Ella，一个能够在3D开放世界中终身学习的社会智能体，它通过日常视觉观察和社会互动积累经验并获取知识。&lt;h4&gt;背景&lt;/h4&gt;Ella拥有一个结构化的、长期的多模态记忆系统，该系统有效存储、更新和检索信息，包括以名称为中心的语义记忆和时空事件记忆。&lt;h4&gt;目的&lt;/h4&gt;通过将终身记忆系统与基础模型集成，Ella能够检索相关信息进行决策，规划日常活动，建立社交关系，并在开放世界中自主进化。&lt;h4&gt;方法&lt;/h4&gt;在动态的3D开放世界中进行了能力评估，15个智能体参与社会活动数日，并使用一系列未见过的控制评估进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Ella能够通过观察和社会互动有效地学习，并能与其他智能体良好地影响、领导和合作以实现目标。&lt;h4&gt;结论&lt;/h4&gt;研究发现，将结构化记忆系统与基础模型结合，对于提高具身智能具有变革性的潜力。&lt;h4&gt;翻译&lt;/h4&gt;We introduce Ella, an embodied social agent capable of lifelong learning within a community in a 3D open world, where agents accumulate experiences and acquire knowledge through everyday visual observations and social interactions. At the core of Ella's capabilities is a structured, long-term multimodal memory system that stores, updates, and retrieves information effectively. It consists of a name-centric semantic memory for organizing acquired knowledge and a spatiotemporal episodic memory for capturing multimodal experiences. By integrating this lifelong memory system with foundation models, Ella retrieves relevant information for decision-making, plans daily activities, builds social relationships, and evolves autonomously while coexisting with other intelligent beings in the open world. We conduct capability-oriented evaluations in a dynamic 3D open world where 15 agents engage in social activities for days and are assessed with a suite of unseen controlled evaluations. Experimental results show that Ella can influence, lead, and cooperate with other agents well to achieve goals, showcasing its ability to learn effectively through observation and social interaction. Our findings highlight the transformative potential of combining structured memory systems with foundation models for advancing embodied intelligence. More videos can be found at https://umass-embodied-agi.github.io/Ella/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Ella, an embodied social agent capable of lifelong learningwithin a community in a 3D open world, where agents accumulate experiences andacquire knowledge through everyday visual observations and social interactions.At the core of Ella's capabilities is a structured, long-term multimodal memorysystem that stores, updates, and retrieves information effectively. It consistsof a name-centric semantic memory for organizing acquired knowledge and aspatiotemporal episodic memory for capturing multimodal experiences. Byintegrating this lifelong memory system with foundation models, Ella retrievesrelevant information for decision-making, plans daily activities, builds socialrelationships, and evolves autonomously while coexisting with other intelligentbeings in the open world. We conduct capability-oriented evaluations in adynamic 3D open world where 15 agents engage in social activities for days andare assessed with a suite of unseen controlled evaluations. Experimentalresults show that Ella can influence, lead, and cooperate with other agentswell to achieve goals, showcasing its ability to learn effectively throughobservation and social interaction. Our findings highlight the transformativepotential of combining structured memory systems with foundation models foradvancing embodied intelligence. More videos can be found athttps://umass-embodied-agi.github.io/Ella/.</description>
      <author>example@mail.com (Hongxin Zhang, Zheyuan Zhang, Zeyuan Wang, Zunzhe Zhang, Lixing Fang, Qinhong Zhou, Chuang Gan)</author>
      <guid isPermaLink="false">2506.24019v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles</title>
      <link>http://arxiv.org/abs/2506.23426v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型的目标检测方法，用于自动驾驶汽车识别周围环境并做出驾驶决策，以提高其在动态环境中的决策有效性。&lt;h4&gt;背景&lt;/h4&gt;传统的目标检测方法将对象分类为已知类别，这限制了自动驾驶汽车检测和适当响应分布外（Out-of-Distribution，OOD）对象的能力，存在安全隐患。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于对象有害性确定的目标检测方法，以增强自动驾驶汽车在动态环境中的决策有效性。&lt;h4&gt;方法&lt;/h4&gt;该方法根据对象相对于自动驾驶汽车的位置和轨迹，将对象识别为“有害”或“无害”，从而实现有效检测和分类。&lt;h4&gt;主要发现&lt;/h4&gt;该模型能够有效检测分布外对象，评估其有害性，并据此进行分类。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的模型在动态环境中增强了自动驾驶汽车的决策有效性，有助于提高驾驶安全。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel object detection method for autonomous vehicles to recognize their surroundings and make driving decisions, thereby enhancing their decision-making effectiveness in dynamic environments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous vehicles (AVs) use object detection models to recognize theirsurroundings and make driving decisions accordingly. Conventional objectdetection approaches classify objects into known classes, which limits the AV'sability to detect and appropriately respond to Out-of-Distribution (OOD)objects. This problem is a significant safety concern since the AV may fail todetect objects or misclassify them, which can potentially lead to hazardoussituations such as accidents. Consequently, we propose a novel object detectionapproach that shifts the emphasis from conventional class-based classificationto object harmfulness determination. Instead of object detection by theirspecific class, our method identifies them as either 'harmful' or 'harmless'based on whether they pose a danger to the AV. This is done based on the objectposition relative to the AV and its trajectory. With this metric, our model caneffectively detect previously unseen objects to enable the AV to make saferreal-time decisions. Our results demonstrate that the proposed modeleffectively detects OOD objects, evaluates their harmfulness, and classifiesthem accordingly, thus enhancing the AV decision-making effectiveness indynamic environments.</description>
      <author>example@mail.com (Menna Taha, Aya Ahmed, Mohammed Karmoose, Yasser Gadallah)</author>
      <guid isPermaLink="false">2506.23426v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching</title>
      <link>http://arxiv.org/abs/2506.23502v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的CLIP模型，通过引入大型语言模型（LLMs）生成的动作相关外部知识，使CLIP具备对动作的精细理解能力，从而在图像文本匹配任务中取得更好的表现。&lt;h4&gt;背景&lt;/h4&gt;大型视觉语言预训练模型如CLIP在图像文本匹配任务中取得了显著成果，但其在理解物体属性和空间关系等细节方面存在不足。&lt;h4&gt;目的&lt;/h4&gt;赋予CLIP对动作的精细理解能力，以描述物体状态或关系。&lt;h4&gt;方法&lt;/h4&gt;设计了一种动作三元组提示和动作状态提示，利用LLMs中隐含的复合语义知识和状态相关因果知识。同时，提出了一个自适应交互模块，基于动作感知提示知识聚合注意力视觉特征，以建立具有判别性和动作感知的视觉表示。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在两个基准数据集上有效提升了图像文本匹配任务的性能。&lt;h4&gt;结论&lt;/h4&gt;通过引入LLMs生成的动作相关外部知识，CLIP模型在动作理解方面取得了显著进步，为图像文本匹配任务提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driven by large-scale contrastive vision-language pre-trained models such asCLIP, recent advancements in the image-text matching task have achievedremarkable success in representation learning. Due to image-levelvisual-language alignment, CLIP falls short in understanding fine-graineddetails such as object attributes and spatial relationships between objects.Recent efforts have attempted to compel CLIP to acquire structured visualrepresentations by introducing prompt learning to achieve object-levelalignment. While achieving promising results, they still lack the capability toperceive actions, which are crucial for describing the states or relationshipsbetween objects. Therefore, we propose to endow CLIP with fine-grainedaction-level understanding by introducing an LLM-enhanced action-awaremulti-modal prompt-tuning method, incorporating the action-related externalknowledge generated by large language models (LLMs). Specifically, we design anaction triplet prompt and an action state prompt to exploit compositionalsemantic knowledge and state-related causal knowledge implicitly stored inLLMs. Subsequently, we propose an adaptive interaction module to aggregateattentive visual features conditioned on action-aware prompted knowledge forestablishing discriminative and action-aware visual representations, whichfurther improves the performance. Comprehensive experimental results on twobenchmark datasets demonstrate the effectiveness of our method.</description>
      <author>example@mail.com (Mengxiao Tian, Xinxiao Wu, Shuo Yang)</author>
      <guid isPermaLink="false">2506.23502v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.23827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Our paper has been accepted by MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为NH2ST的框架，用于从病理全切片图像中预测基因表达，旨在解决传统方法在高成本和复杂度上的限制。&lt;h4&gt;背景&lt;/h4&gt;空间转录组学（ST）为组织微环境提供了关键信息，但因其高昂的成本和复杂性受到限制。预测基因表达从病理全切片图像（WSI）成为了一个替代方案。&lt;h4&gt;目的&lt;/h4&gt;提出一种框架，用于整合空间上下文和病理及基因模态，以提高基因表达预测的准确性。&lt;h4&gt;方法&lt;/h4&gt;NH2ST模型包含查询分支和邻域分支，处理成对的靶点图像和基因数据及其邻近区域。使用交叉注意力和对比学习来捕捉内在关联，确保病理和基因表达之间的对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在六个数据集上的实验表明，NH2ST模型在PCC指标上优于现有方法，实现了超过20%的提升。&lt;h4&gt;结论&lt;/h4&gt;NH2ST框架有效地解决了传统方法在预测基因表达方面的不足，为病理图像分析提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Spatial transcriptomics (ST) provides crucial insights into tissuemicro-environments, but is limited to its high cost and complexity. As analternative, predicting gene expression from pathology whole slide images (WSI)is gaining increasing attention. However, existing methods typically rely onsingle patches or a single pathology modality, neglecting the complex spatialand molecular interactions between target and neighboring information (e.g.,gene co-expression). This leads to a failure in establishing connections amongadjacent regions and capturing intricate cross-modal relationships. To addressthese issues, we propose NH2ST, a framework that integrates spatial context andboth pathology and gene modalities for gene expression prediction. Our modelcomprises a query branch and a neighbor branch to process paired target patchand gene data and their neighboring regions, where cross-attention andcontrastive learning are employed to capture intrinsic associations and ensurealignments between pathology and gene expression. Extensive experiments on sixdatasets demonstrate that our model consistently outperforms existing methods,achieving over 20% in PCC metrics. Codes are available athttps://github.com/MCPathology/NH2ST&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatial transcriptomics (ST) provides crucial insights into tissuemicro-environments, but is limited to its high cost and complexity. As analternative, predicting gene expression from pathology whole slide images (WSI)is gaining increasing attention. However, existing methods typically rely onsingle patches or a single pathology modality, neglecting the complex spatialand molecular interactions between target and neighboring information (e.g.,gene co-expression). This leads to a failure in establishing connections amongadjacent regions and capturing intricate cross-modal relationships. To addressthese issues, we propose NH2ST, a framework that integrates spatial context andboth pathology and gene modalities for gene expression prediction. Our modelcomprises a query branch and a neighbor branch to process paired target patchand gene data and their neighboring regions, where cross-attention andcontrastive learning are employed to capture intrinsic associations and ensurealignments between pathology and gene expression. Extensive experiments on sixdatasets demonstrate that our model consistently outperforms existing methods,achieving over 20% in PCC metrics. Codes are available athttps://github.com/MCPathology/NH2ST</description>
      <author>example@mail.com (Mingcheng Qu, Yuncong Wu, Donglin Di, Yue Gao, Tonghua Su, Yang Song, Lei Fan)</author>
      <guid isPermaLink="false">2506.23827v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion</title>
      <link>http://arxiv.org/abs/2506.23606v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成模型的激光雷达点云合成方法，旨在通过增加训练数据集的多样性和丰富性来增强深度学习管道，特别是在现实世界数据稀缺或缺乏多样性的情况下。&lt;h4&gt;背景&lt;/h4&gt;现有的激光雷达点云生成方法主要关注无条件生成，而忽略了其在现实世界应用中的潜力。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为SG-LDM的语义引导激光雷达扩散模型，通过潜在对齐实现鲁棒的语义到激光雷达的合成。&lt;h4&gt;方法&lt;/h4&gt;SG-LDM直接在原生激光雷达空间操作，并利用显式的语义条件，实现了基于语义标签的高保真激光雷达点云生成。此外，还提出了基于SG-LDM的扩散模型，用于跨域翻译，作为一种域适应策略来提高下游感知性能。&lt;h4&gt;主要发现&lt;/h4&gt;系统实验表明，SG-LDM在生成高保真激光雷达点云方面优于现有的激光雷达扩散模型，并且所提出的激光雷达翻译框架进一步提高了下游激光雷达分割任务中的数据增强性能。&lt;h4&gt;结论&lt;/h4&gt;SG-LDM为激光雷达点云合成提供了一种新的解决方案，有助于提高深度学习模型的性能，尤其是在数据稀缺或多样性的情况下。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lidar point cloud synthesis based on generative models offers a promisingsolution to augment deep learning pipelines, particularly when real-world datais scarce or lacks diversity. By enabling flexible object manipulation, thissynthesis approach can significantly enrich training datasets and enhancediscriminative models. However, existing methods focus on unconditional lidarpoint cloud generation, overlooking their potential for real-worldapplications. In this paper, we propose SG-LDM, a Semantic-Guided LidarDiffusion Model that employs latent alignment to enable robustsemantic-to-lidar synthesis. By directly operating in the native lidar spaceand leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-artperformance in generating high-fidelity lidar point clouds guided by semanticlabels. Moreover, we propose the first diffusion-based lidar translationframework based on SG-LDM, which enables cross-domain translation as a domainadaptation strategy to enhance downstream perception performance. Systematicexperiments demonstrate that SG-LDM significantly outperforms existing lidardiffusion models and the proposed lidar translation framework further improvesdata augmentation performance in the downstream lidar segmentation task.</description>
      <author>example@mail.com (Zhengkang Xiang, Zizhao Li, Amir Khodabandeh, Kourosh Khoshelham)</author>
      <guid isPermaLink="false">2506.23606v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)</title>
      <link>http://arxiv.org/abs/2506.23784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用图神经网络（GNN）对词方程进行排序的问题，以提高词方程求解器的性能。&lt;h4&gt;背景&lt;/h4&gt;传统的Nielsen变换方法在解决词方程时，求解器的性能很大程度上取决于方程处理的顺序。&lt;h4&gt;目的&lt;/h4&gt;通过使用GNN对词方程进行排序，以改善求解器在解决词方程时的性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新的基于图的词方程表示方法，以保留连接词之间的全局信息，使GNN在排序时具有整体视角。针对连接词数量的可变性，提出了三种将多分类任务适应到方程排序问题的方法。GNN的训练使用词方程的最小不可满足子集（MUSes）进行。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与最先进的字符串求解器相比，新框架在基准测试中解决了更多的问题，其中每个变量在每个方程中最多出现一次。&lt;h4&gt;结论&lt;/h4&gt;GNN在词方程排序中的应用能够显著提高求解器的性能，特别是在处理变量数量可变的复杂方程时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Nielsen transformation is a standard approach for solving word equations: byrepeatedly splitting equations and applying simplification steps, equations arerewritten until a solution is reached. When solving a conjunction of wordequations in this way, the performance of the solver will depend considerablyon the order in which equations are processed. In this work, the use of GraphNeural Networks (GNNs) for ranking word equations before and during the solvingprocess is explored. For this, a novel graph-based representation for wordequations is presented, preserving global information across conjuncts,enabling the GNN to have a holistic view during ranking. To handle the variablenumber of conjuncts, three approaches to adapt a multi-classification task tothe problem of ranking equations are proposed. The training of the GNN is donewith the help of minimum unsatisfiable subsets (MUSes) of word equations. Theexperimental results show that, compared to state-of-the-art string solvers,the new framework solves more problems in benchmarks where each variableappears at most once in each equation.</description>
      <author>example@mail.com (Parosh Aziz Abdulla, Mohamed Faouzi Atig, Julie Cailler, Chencheng Liang, Philipp Rümmer)</author>
      <guid isPermaLink="false">2506.23784v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering</title>
      <link>http://arxiv.org/abs/2506.23329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://ir3d-bench.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个名为IR3D-Bench的基准测试，用于挑战视觉语言模型（VLMs）在理解场景方面的能力，通过主动创建而非被动识别来展示理解能力。&lt;h4&gt;背景&lt;/h4&gt;尽管VLMs在描述性任务上表现出色，但它们是否真正理解通过视觉观察到的场景尚不确定。&lt;h4&gt;目的&lt;/h4&gt;提出IR3D-Bench，旨在通过挑战VLMs的主动创造能力来检验它们对场景的理解，而不是仅仅通过被动识别。&lt;h4&gt;方法&lt;/h4&gt;IR3D-Bench基于分析-综合范式，要求视觉语言代理（VLAs）通过使用编程和渲染工具来重新创建输入图像的底层3D结构，通过工具使用实现代理逆向渲染。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，VLMs在视觉精度方面存在局限性，特别是在基本工具使用方面表现良好，但在更高级的理解任务上表现不佳。&lt;h4&gt;结论&lt;/h4&gt;IR3D-Bench包括数据集和评估协议的发布，旨在促进工具使用型VLAs的系统研究和开发，以实现通过创建来理解场景。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Vision-language models (VLMs) excel at descriptive tasks, but whether they truly understand scenes from visual observations remains uncertain. We introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding through active creation rather than passive recognition. Grounded in the analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs) with actively using programming and rendering tools to recreate the underlying 3D structure of an input image, achieving agentic inverse rendering through tool use. This 'understanding-by-creating' approach probes the tool-using generative capacity of VLAs, moving beyond the descriptive or conversational capacity measured by traditional scene understanding benchmarks. We provide a comprehensive suite of metrics to evaluate geometric accuracy, spatial relations, appearance attributes, and overall plausibility. Initial experiments on agentic inverse rendering powered by various state-of-the-art VLMs highlight current limitations, particularly in visual precision rather than basic tool usage. IR3D-Bench, including data and evaluation protocols, is released to facilitate systematic study and development of tool-using VLAs towards genuine scene understanding by creating.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language models (VLMs) excel at descriptive tasks, but whether theytruly understand scenes from visual observations remains uncertain. Weintroduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understandingthrough active creation rather than passive recognition. Grounded in theanalysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs)with actively using programming and rendering tools to recreate the underlying3D structure of an input image, achieving agentic inverse rendering throughtool use. This "understanding-by-creating" approach probes the tool-usinggenerative capacity of VLAs, moving beyond the descriptive or conversationalcapacity measured by traditional scene understanding benchmarks. We provide acomprehensive suite of metrics to evaluate geometric accuracy, spatialrelations, appearance attributes, and overall plausibility. Initial experimentson agentic inverse rendering powered by various state-of-the-art VLMs highlightcurrent limitations, particularly in visual precision rather than basic toolusage. IR3D-Bench, including data and evaluation protocols, is released tofacilitate systematic study and development of tool-using VLAs towards genuinescene understanding by creating.</description>
      <author>example@mail.com (Parker Liu, Chenxin Li, Zhengxin Li, Yipeng Wu, Wuyang Li, Zhiqin Yang, Zhenyuan Zhang, Yunlong Lin, Sirui Han, Brandon Y. Feng)</author>
      <guid isPermaLink="false">2506.23329v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Deconstructing the Origins of Interfacial Catalysis: Why Electric Fields are Inseparable from Solvation</title>
      <link>http://arxiv.org/abs/2506.23988v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;最近十年，许多实验表明，当某些化学反应从常规水相条件转移到微滴环境中时，其反应速率会显著增加。然而，这种现象的微观基础尚未明确，且存在广泛争议。&lt;h4&gt;背景&lt;/h4&gt;该研究背景是关于水-气界面处电场和溶剂化作用对化学反应速率的影响。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过模拟和实验方法，对微滴环境中化学反应速率增加的微观机制进行深入研究。&lt;h4&gt;方法&lt;/h4&gt;研究使用了经典分子动力学模拟、化学物理溶剂化理论，以及无监督学习（信息平衡方法）等手段。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，水表面的电场与常规水条件下的电场无显著差异，且电场波动在约10 ps的时间尺度上解相关，其活化较慢化学反应的作用尚无定论。此外，电场在苯酚羟基上的作用主要由苯酚的水合作用决定，包括邻近水分子的接近度和方向。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，对电场在增强空气-水界面化学反应活性中的作用的关注可能夸大了其实际重要性。&lt;h4&gt;翻译&lt;/h4&gt;In the last decade, there has been a surge of experiments showing that certain chemical reactions undergo an enormous boost when taken from bulk aqueous conditions to microdroplet environments. The microscopic basis of this phenomenon remains elusive and continues to be widely debated. One of the key driving forces invoked are the specific properties of the air-water interface including the presence of large electric fields and distinct solvation at the surface. Here, using a combination of classical molecular dynamics simulations, the chemical physics of solvation, and unsupervised learning approaches, we place these assumptions under close scrutiny. Using phenol as a model system, we demonstrate that the electric field at the surface of water is not anomalous or unique compared to bulk water conditions. Furthermore, the electric field fluctuations de-correlate on a timescale of ~10 ps implying that their role in activating much slower chemical reactions remains inconclusive. We deploy a recently developed unsupervised learning approach, dubbed information balance, which detects in an agnostic fashion the relationship between the electric field and solvation collective variables. It turns out that the electric field on the hydroxyl group of the phenol is mostly determined by phenol hydration including the proximity and orientation of nearby water molecules. We caution that the growing attention of the role that electric fields have garnered in enhancing chemical reactivity at the air-water interface, may not reflect their actual importance.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In the last decade, there has been a surge of experiments showing thatcertain chemical reactions undergo an enormous boost when taken from bulkaqueous conditions to microdroplet environments. The microscopic basis of thisphenomenon remains elusive and continues to be widely debated. One of the keydriving forces invoked are the specific properties of the air-water interfaceincluding the presence of large electric fields and distinct solvation at thesurface. Here, using a combination of classical molecular dynamics simulations,the chemical physics of solvation, and unsupervised learning approaches, weplace these assumptions under close scrutiny. Using phenol as a model system,we demonstrate that the electric field at the surface of water is not anomalousor unique compared to bulk water conditions. Furthermore, the electric fieldfluctuations de-correlate on a timescale of ~10 ps implying that their role inactivating much slower chemical reactions remains inconclusive. We deploy arecently developed unsupervised learning approach, dubbed information balance,which detects in an agnostic fashion the relationship between the electricfield and solvation collective variables. It turns out that the electric fieldon the hydroxyl group of the phenol is mostly determined by phenol hydrationincluding the proximity and orientation of nearby water molecules. We cautionthat the growing attention of the role that electric fields have garnered inenhancing chemical reactivity at the air-water interface, may not reflect theiractual importance.</description>
      <author>example@mail.com (Solana Di Pino, Debarshi Banerjee, Marta Monti, Gonzalo Diaz Miron, Giuseppe Cassone, Ali Hassanali)</author>
      <guid isPermaLink="false">2506.23988v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment</title>
      <link>http://arxiv.org/abs/2506.22967v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint manuscript - Project page:  https://github.com/aghdamamir/act-align&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对零样本细粒度视频分类问题进行研究，提出了一种名为ActAlign的零样本框架，通过序列对齐的方法实现视频分类，并在ActionAtlas基准测试中取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;在零样本细粒度视频分类中，没有未见过类别的时间标签或视频示例。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来有效区分细粒度动作类别。&lt;h4&gt;方法&lt;/h4&gt;ActAlign框架通过使用大型语言模型生成有序子动作序列，并使用动态时间规整（DTW）在共享嵌入空间中对齐视频帧来实现视频分类。&lt;h4&gt;主要发现&lt;/h4&gt;ActAlign在ActionAtlas基准测试中实现了30.5%的准确率，优于亿参数的视频语言模型，同时参数量减少了约8倍。&lt;h4&gt;结论&lt;/h4&gt;结构化语言先验与经典对齐技术的结合，为视觉语言模型在细粒度视频理解中的开放式识别潜力提供了一种可扩展和通用的方法。&lt;h4&gt;翻译&lt;/h4&gt;We address the task of zero-shot fine-grained video classification, where no video examples or temporal annotations are available for unseen action classes. While contrastive vision-language models such as SigLIP demonstrate strong open-set recognition via mean-pooled image-text similarity, they fail to capture the temporal structure critical for distinguishing fine-grained activities. We introduce ActAlign, a zero-shot framework that formulates video classification as sequence alignment. For each class, a large language model generates an ordered sub-action sequence, which is aligned with video frames using Dynamic Time Warping (DTW) in a shared embedding space. Without any video-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the extremely challenging ActionAtlas benchmark, where human accuracy is only 61.6%. ActAlign outperforms billion-parameter video-language models while using approximately 8x less parameters. These results demonstrate that structured language priors, combined with classical alignment techniques, offer a scalable and general approach to unlocking the open-set recognition potential of vision-language models for fine-grained video understanding.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We address the task of zero-shot fine-grained video classification, where novideo examples or temporal annotations are available for unseen action classes.While contrastive vision-language models such as SigLIP demonstrate strongopen-set recognition via mean-pooled image-text similarity, they fail tocapture the temporal structure critical for distinguishing fine-grainedactivities. We introduce ActAlign, a zero-shot framework that formulates videoclassification as sequence alignment. For each class, a large language modelgenerates an ordered sub-action sequence, which is aligned with video framesusing Dynamic Time Warping (DTW) in a shared embedding space. Without anyvideo-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on theextremely challenging ActionAtlas benchmark, where human accuracy is only61.6%. ActAlign outperforms billion-parameter video-language models while usingapproximately 8x less parameters. These results demonstrate that structuredlanguage priors, combined with classical alignment techniques, offer a scalableand general approach to unlocking the open-set recognition potential ofvision-language models for fine-grained video understanding.</description>
      <author>example@mail.com (Amir Aghdam, Vincent Tao Hu)</author>
      <guid isPermaLink="false">2506.22967v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation</title>
      <link>http://arxiv.org/abs/2506.23724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了跨模型知识对Test-time Adaptation（TTA）过程的影响，并提出了一种名为COCA的跨模型协同学习框架，通过共适应和自适应策略提升TTA的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的TTA方法主要关注单模型适应，而忽略了跨模型知识的作用。&lt;h4&gt;目的&lt;/h4&gt;探究跨模型知识如何影响TTA过程，并提出新的框架来提升TTA的性能。&lt;h4&gt;方法&lt;/h4&gt;提出COCA框架，包括共适应和自适应策略，共适应通过整合其他模型的互补知识，自适应通过无监督学习增强每个模型的独特优势。&lt;h4&gt;主要发现&lt;/h4&gt;在TTA的无监督在线设置中，不同规模的模型可以提供互补且自信的知识，例如小模型MobileViT可以有效地指导大模型ViT-Base。&lt;h4&gt;结论&lt;/h4&gt;COCA框架通过跨模型协同学习显著提升了不同规模模型在TTA任务上的性能，如ResNets、ViTs和Mobile-ViTs，例如Mobile-ViT的指导使ViT-Base在ImageNet-C上的平均适应准确率从51.7%提升到64.5%。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Test-time Adaptation (TTA)通过在线无监督学习适应测试域数据，并具有潜在的域偏移，从而获得令人印象深刻的性能。然而，到目前为止，现有的TTA方法主要关注单模型适应。在这项工作中，我们探讨了有趣的问题：跨模型知识如何影响TTA过程？我们的发现表明，在TTA的无监督在线设置中，每个模型都可以向其他模型提供互补且自信的知识，即使模型规模存在很大差异。例如，小模型MobileViT（10.6M参数）可以有效地指导大模型ViT-Base（86.6M参数）。鉴于这一点，我们提出了COCA，一个用于TTA的跨模型协同学习框架，它主要由两个主要策略组成。1）共适应在TTA过程中自适应地整合来自其他模型的互补知识，减少单个模型的偏差。2）自适应通过无监督学习增强每个模型的独特优势，使模型能够对目标域进行多样化适应。广泛的实验表明，COCA可以通过跨模型协同学习显著提升现有SOTAs，在具有各种规模（包括ResNets、ViTs和Mobile-ViTs）的模型上。例如，通过Mobile-ViT的指导，COCA将ViT-Base在ImageNet-C上的平均适应准确率从51.7%提高到64.5%。代码在https://github.com/ycarobot/COCA上公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Test-time Adaptation (TTA) adapts a given model to testing domain data withpotential domain shifts through online unsupervised learning, yieldingimpressive performance. However, to date, existing TTA methods primarily focuson single-model adaptation. In this work, we investigate an intriguingquestion: how does cross-model knowledge influence the TTA process? Ourfindings reveal that, in TTA's unsupervised online setting, each model canprovide complementary, confident knowledge to the others, even when there aresubstantial differences in model size. For instance, a smaller model likeMobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base(86.6M parameters). In light of this, we propose COCA, a Cross-ModelCo-Learning framework for TTA, which mainly consists of two main strategies. 1)Co-adaptation adaptively integrates complementary knowledge from other modelsthroughout the TTA process, reducing individual model biases. 2)Self-adaptation enhances each model's unique strengths via unsupervisedlearning, enabling diverse adaptation to the target domain. Extensiveexperiments show that COCA, which can also serve as a plug-and-play module,significantly boosts existing SOTAs, on models with various sizes--includingResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example,with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracyon ImageNet-C from 51.7% to 64.5%. The code is publicly available athttps://github.com/ycarobot/COCA.</description>
      <author>example@mail.com (Chang'an Yi, Xiaohui Deng, Guohao Chen, Yan Zhou, Qinghua Lu, Shuaicheng Niu)</author>
      <guid isPermaLink="false">2506.23724v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Visual and Memory Dual Adapter for Multi-Modal Object Tracking</title>
      <link>http://arxiv.org/abs/2506.23972v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉和记忆双重适配器（VMDA）的多模态跟踪方法，通过轻量级视觉适配器将辅助模态特征融入基础模型，提高了多模态跟踪的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态跟踪方法在利用频率和时域关键线索方面存在局限性，导致难以学习可靠的提示。&lt;h4&gt;目的&lt;/h4&gt;构建更鲁棒和具有区分度的多模态跟踪表示。&lt;h4&gt;方法&lt;/h4&gt;开发了简单而有效的视觉适配器，通过联合建模频率、空间和通道特征，自适应地将辅助模态的区分性线索转移到主导模态。同时，设计了受人类记忆机制启发的记忆适配器，存储全局时域线索，并执行动态更新和检索操作，确保视频序列中可靠时域信息的一致传播。&lt;h4&gt;主要发现&lt;/h4&gt;在RGB-热、RGB-深度和RGB-事件等多种多模态跟踪任务上，该方法达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;VMDA方法在多模态跟踪任务上具有显著优势，代码和模型可在GitHub上找到。&lt;h4&gt;翻译&lt;/h4&gt;基于提示学习的多模态跟踪器通过采用轻量级视觉适配器将辅助模态特征纳入冻结的基础模型，取得了有希望的进展。然而，现有的方法往往由于在频率和时域上对关键线索的利用有限，而难以学习可靠的提示。在本文中，我们提出了一种新颖的视觉和记忆双重适配器（VMDA）来构建更鲁棒和具有区分度的多模态跟踪表示。具体来说，我们开发了一种简单但有效的视觉适配器，通过联合建模频率、空间和通道特征，自适应地将辅助模态的区分性线索转移到主导模态。此外，我们设计了一种受人类记忆机制启发的记忆适配器，存储全局时域线索，并执行动态更新和检索操作，以确保视频序列中可靠时域信息的一致传播。广泛的实验表明，我们的方法在各种多模态跟踪任务上，包括RGB-热、RGB-深度和RGB-事件跟踪，都实现了最先进的性能。代码和模型可在https://github.com/xuboyue1999/mmtrack.git上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Prompt-learning-based multi-modal trackers have achieved promising progressby employing lightweight visual adapters to incorporate auxiliary modalityfeatures into frozen foundation models. However, existing approaches oftenstruggle to learn reliable prompts due to limited exploitation of critical cuesacross frequency and temporal domains. In this paper, we propose a novel visualand memory dual adapter (VMDA) to construct more robust and discriminativerepresentations for multi-modal tracking. Specifically, we develop a simple buteffective visual adapter that adaptively transfers discriminative cues fromauxiliary modality to dominant modality by jointly modeling the frequency,spatial, and channel-wise features. Additionally, we design the memory adapterinspired by the human memory mechanism, which stores global temporal cues andperforms dynamic update and retrieval operations to ensure the consistentpropagation of reliable temporal information across video sequences. Extensiveexperiments demonstrate that our method achieves state-of-the-art performanceon the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth,and RGB-Event tracking. Code and models are available athttps://github.com/xuboyue1999/mmtrack.git.</description>
      <author>example@mail.com (Boyue Xu, Ruichao Hou, Tongwei Ren, Gangshan Wu)</author>
      <guid isPermaLink="false">2506.23972v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>When Test-Time Adaptation Meets Self-Supervised Models</title>
      <link>http://arxiv.org/abs/2506.23529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究在测试时数据上训练的深度学习模型能否在无需依赖源预训练模型的情况下，通过自我监督学习（SSL）连续提升模型性能，并提出了一个结合SSL和TTA的协作学习框架。&lt;h4&gt;背景&lt;/h4&gt;测试时适应（TTA）使深度学习模型能够适应动态环境变化，但在线适应依赖于源预训练模型的表现。&lt;h4&gt;目的&lt;/h4&gt;探究测试时适应（TTA）方法是否可以在不依赖源预训练的情况下，通过自我监督学习（SSL）持续改进模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自我监督的TTA协议，并引入了一个协作学习框架，该框架结合了SSL和TTA模型，利用对比学习和知识蒸馏逐步优化表示。&lt;h4&gt;主要发现&lt;/h4&gt;在DINO、MoCo和iBOT等不同的自我监督模型上，通过TTA基准测试验证了方法的有效性，即使在没有源预训练的情况下，也能达到有竞争力的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在SSL中表现出有效性，证明了即使不依赖源预训练，也能实现良好的模型性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在测试时数据上训练的深度学习模型能够适应动态环境变化，从而增强其实际应用性。从源域到目标域的在线适应很有前景，但它高度依赖于源预训练模型的表现。在本文中，我们研究了测试时适应（TTA）方法是否能够通过自我监督学习（SSL）连续改进模型，而不依赖于源预训练。观察到现有的TTA方法在直接应用于具有低源域精度的自我监督模型时遇到困难后，我们引入了一种自我监督的TTA协议。此外，我们提出了一种集成SSL和TTA模型的协作学习框架，利用对比学习和知识蒸馏进行逐步表示优化。我们在包括DINO、MoCo和iBOT在内的多种自我监督模型上，以及TTA基准测试中验证了我们的方法。大量实验验证了我们的方法在SSL中的有效性，表明即使在没有源预训练的情况下，该方法也能达到具有竞争力的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training on test-time data enables deep learning models to adapt to dynamicenvironmental changes, enhancing their practical applicability. Onlineadaptation from source to target domains is promising but it remains highlyreliant on the performance of source pretrained model. In this paper, weinvestigate whether test-time adaptation (TTA) methods can continuously improvemodels trained via self-supervised learning (SSL) without relying on sourcepretraining. We introduce a self-supervised TTA protocol after observing thatexisting TTA approaches struggle when directly applied to self-supervisedmodels with low accuracy on the source domain. Furthermore, we propose acollaborative learning framework that integrates SSL and TTA models, leveragingcontrastive learning and knowledge distillation for stepwise representationrefinement. We validate our method on diverse self-supervised models, includingDINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate theeffectiveness of our approach in SSL, showing that it achieves competitiveperformance even without source pretraining.</description>
      <author>example@mail.com (Jisu Han, Jihee Park, Dongyoon Han, Wonjun Hwang)</author>
      <guid isPermaLink="false">2506.23529v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Event-based Tiny Object Detection: A Benchmark Dataset and Baseline</title>
      <link>http://arxiv.org/abs/2506.23575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为EV-SpSegNet的事件基础稀疏分割网络，用于小目标检测，并在EV-UAV数据集上进行了实验，证明了方法的有效性。&lt;h4&gt;背景&lt;/h4&gt;小目标检测在反无人机任务中是一个具有挑战性的问题，传统基于帧的相机在复杂环境中检测小目标存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决小目标检测的问题，本文提出了一个新的数据集EV-UAV和一个基于事件的小目标检测方法。&lt;h4&gt;方法&lt;/h4&gt;本文引入了EV-SpSegNet，这是一个在点云空间中进行事件分割的新方法，并提出了时空相关性（STC）损失函数来利用运动连续性指导网络。&lt;h4&gt;主要发现&lt;/h4&gt;在EV-UAV数据集上进行的实验表明，该方法优于现有的方法，并为未来EVSOD研究提供了一个基准。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和数据集为小目标检测在反无人机任务中提供了一种有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在反无人机任务中，由于无人机体积小、背景复杂，小目标检测（SOD）是一个具有挑战性的问题。传统基于帧的相机由于帧率低、动态范围有限和数据冗余，难以在复杂环境中检测小目标。具有微秒级时间分辨率和高动态范围的事件相机为SOD提供了一种更有效的解决方案。然而，现有的基于事件的对象检测数据集规模有限，目标大小较大，背景缺乏多样性，不适合作为SOD基准。在本文中，我们引入了一个基于事件的小目标检测（EVSOD）数据集（即EV-UAV），这是第一个用于反无人机任务的大规模、高度多样化的基准。它包括147个序列，超过230万个事件级别标注，具有极其小的目标（平均为6.8×5.4像素）和多样化的场景，如城市杂乱和极端光照条件。此外，基于观察到的运动小目标在时空事件点云中形成连续曲线，我们提出了基于事件的空间时间相关网络（EV-SpSegNet），这是点云空间中事件分割的一个新基准，以及一个时空相关性（STC）损失函数，该函数利用运动连续性来指导网络保留目标事件。在EV-UAV数据集上的大量实验表明，我们方法的优势，并为EVSOD的未来研究提供了一个基准。数据集和代码可在https://github.com/ChenYichen9527/Ev-UAV上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small object detection (SOD) in anti-UAV task is a challenging problem due tothe small size of UAVs and complex backgrounds. Traditional frame-based camerasstruggle to detect small objects in complex environments due to their low framerates, limited dynamic range, and data redundancy. Event cameras, withmicrosecond temporal resolution and high dynamic range, provide a moreeffective solution for SOD. However, existing event-based object detectiondatasets are limited in scale, feature large targets size, and lack diversebackgrounds, making them unsuitable for SOD benchmarks. In this paper, weintroduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV),the first large-scale, highly diverse benchmark for anti-UAV tasks. It includes147 sequences with over 2.3 million event-level annotations, featuringextremely small targets (averaging 6.8 $\times$ 5.4 pixels) and diversescenarios such as urban clutter and extreme lighting conditions. Furthermore,based on the observation that small moving targets form continuous curves inspatiotemporal event point clouds, we propose Event based Sparse SegmentationNetwork (EV-SpSegNet), a novel baseline for event segmentation in point cloudspace, along with a Spatiotemporal Correlation (STC) loss that leverages motioncontinuity to guide the network in retaining target events. Extensiveexperiments on the EV-UAV dataset demonstrate the superiority of our method andprovide a benchmark for future research in EVSOD. The dataset and code are athttps://github.com/ChenYichen9527/Ev-UAV.</description>
      <author>example@mail.com (Nuo Chen, Chao Xiao, Yimian Dai, Shiman He, Miao Li, Wei An)</author>
      <guid isPermaLink="false">2506.23575v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Contrastive Learning for Multi-Label Images</title>
      <link>http://arxiv.org/abs/2506.23156v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的自监督学习方法，通过使用少量多标签图像来保证出色的表示学习能力。&lt;h4&gt;背景&lt;/h4&gt;自监督学习在通过比较方法学习表示方面表现出有效性，但主流方法依赖大量单标签数据集，如ImageNet，导致预训练成本高，且忽略了多标签图像的潜在语义信息和更广泛的应用场景。&lt;h4&gt;目的&lt;/h4&gt;旨在通过使用少量多标签图像来改进主流的自监督学习方法，以提高表示学习能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一种块状增强模块，用于从多标签图像中提取潜在的正面视图对。随后，设计了一种图像感知对比损失，以建立这些视图之间的联系，从而促进语义一致表示的提取。&lt;h4&gt;主要发现&lt;/h4&gt;通过综合线性微调和迁移学习验证了该方法在样本质量和数量具有挑战性的情况下仍然具有竞争力。&lt;h4&gt;结论&lt;/h4&gt;该方法通过使用少量多标签图像，在保证表示学习能力的同时，有效降低了预训练的负担，并提高了自监督学习的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Self-supervised learning (SSL) has demonstrated its effectiveness in learning representations through comparison methods that align with human intuition. However, mainstream SSL methods heavily rely on high body datasets with single label, such as ImageNet, resulting in intolerable pre-training overhead. Besides, more general multi-label images are frequently overlooked in SSL, despite their potential for richer semantic information and broader applicability in downstream scenarios. Therefore, we tailor the mainstream SSL approach to guarantee excellent representation learning capabilities using fewer multi-label images. Firstly, we propose a block-wise augmentation module aimed at extracting additional potential positive view pairs from multi-label images. Subsequently, an image-aware contrastive loss is devised to establish connections between these views, thereby facilitating the extraction of semantically consistent representations. Comprehensive linear fine-tuning and transfer learning validate the competitiveness of our approach despite challenging sample quality and quantity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has demonstrated its effectiveness in learningrepresentations through comparison methods that align with human intuition.However, mainstream SSL methods heavily rely on high body datasets with singlelabel, such as ImageNet, resulting in intolerable pre-training overhead.Besides, more general multi-label images are frequently overlooked in SSL,despite their potential for richer semantic information and broaderapplicability in downstream scenarios. Therefore, we tailor the mainstream SSLapproach to guarantee excellent representation learning capabilities usingfewer multi-label images. Firstly, we propose a block-wise augmentation moduleaimed at extracting additional potential positive view pairs from multi-labelimages. Subsequently, an image-aware contrastive loss is devised to establishconnections between these views, thereby facilitating the extraction ofsemantically consistent representations. Comprehensive linear fine-tuning andtransfer learning validate the competitiveness of our approach despitechallenging sample quality and quantity.</description>
      <author>example@mail.com (Jiale Chen)</author>
      <guid isPermaLink="false">2506.23156v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Calibrating Graph Neural Networks with Wavelet-Aware Temperature Scaling</title>
      <link>http://arxiv.org/abs/2506.23782v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为WATS的Graph Neural Networks（GNNs）后处理校准框架，用于提高GNNs在关系数据上的预测性能和置信度估计的准确性。&lt;h4&gt;背景&lt;/h4&gt;GNNs在关系数据上表现出强大的预测性能，但其置信度估计与实际预测的正确性往往不一致，这在安全性关键的应用场景中是一个重大限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过利用图小波特征来为节点分配特定的温度，从而提高GNNs的置信度估计。&lt;h4&gt;方法&lt;/h4&gt;WATS框架利用图小波的扩展性和拓扑敏感性来细化置信度估计，而无需重新训练模型或访问相邻的logits或预测。&lt;h4&gt;主要发现&lt;/h4&gt;在七个具有不同图结构和两种GNN骨干网络的基准数据集上的广泛评估表明，WATS在所有比较方法中实现了最低的预期校准误差（ECE），在ECE方面优于经典和图特定基线，平均提高了42.3%，并且与图特定方法相比，校准方差降低了17.24%。此外，WATS在计算效率上保持高效，能够很好地扩展到不同大小和密度的图。&lt;h4&gt;结论&lt;/h4&gt;WATS是一种有效的GNNs校准方法，可以提高其在安全性关键应用中的可信度。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) 在关系数据上展示了强大的预测性能；然而，它们的置信度估计通常与实际预测的正确性不一致，这给在安全关键环境中的部署带来了重大限制。尽管现有的图感知校准方法试图缓解这一限制，但它们主要依赖于粗略的一跳统计，例如邻居预测的置信度，或者潜在节点嵌入，从而忽略了图拓扑中固有的细粒度结构异质性。在本工作中，我们提出了波let感知温度缩放（WATS），这是一种后处理校准框架，它根据可调的热核图小波特征分配节点特定的温度。具体来说，WATS利用图小波的扩展性和拓扑敏感性来细化置信度估计，而无需重新训练模型或访问相邻的logits或预测。在七个基准数据集上进行了广泛的评估，这些数据集具有不同的图结构和两种GNN骨干网络，结果表明WATS在所有比较方法中实现了最低的预期校准误差（ECE），在ECE方面优于经典和图特定基线，平均提高了42.3%，并且与图特定方法相比，校准方差降低了17.24%。此外，WATS在计算效率上保持高效，能够很好地扩展到不同大小和密度的图。基于本论文的代码将发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated strong predictive performanceon relational data; however, their confidence estimates often misalign withactual predictive correctness, posing significant limitations for deployment insafety-critical settings. While existing graph-aware calibration methods seekto mitigate this limitation, they primarily depend on coarse one-hopstatistics, such as neighbor-predicted confidence, or latent node embeddings,thereby neglecting the fine-grained structural heterogeneity inherent in graphtopology. In this work, we propose Wavelet-Aware Temperature Scaling (WATS), apost-hoc calibration framework that assigns node-specific temperatures based ontunable heat-kernel graph wavelet features. Specifically, WATS harnesses thescalability and topology sensitivity of graph wavelets to refine confidenceestimates, all without necessitating model retraining or access to neighboringlogits or predictions. Extensive evaluations across seven benchmark datasetswith varying graph structures and two GNN backbones demonstrate that WATSachieves the lowest Expected Calibration Error (ECE) among all comparedmethods, outperforming both classical and graph-specific baselines by up to42.3\% in ECE and reducing calibration variance by 17.24\% on average comparedwith graph-specific methods. Moreover, WATS remains computationally efficient,scaling well across graphs of diverse sizes and densities. Code will bereleased based on publication.</description>
      <author>example@mail.com (Xiaoyang Li, Linwei Tao, Haohui Lu, Minjing Dong, Junbin Gao, Chang Xu)</author>
      <guid isPermaLink="false">2506.23782v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting</title>
      <link>http://arxiv.org/abs/2506.23309v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025. Project Page:  https://lastbasket.github.io/MICCAI-2025-SurgTPGS/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SurgTPGS，一种基于文本提示的Gaussian Splatting方法，用于解决手术研究中3D场景的准确理解问题，以支持手术规划和术中实时指导。&lt;h4&gt;背景&lt;/h4&gt;在当代外科研究和实践中，精确理解带有文本提示功能的3D手术场景对于手术规划和术中实时指导至关重要，需要精确识别和交互手术工具和解剖结构。&lt;h4&gt;目的&lt;/h4&gt;填补现有工作在手术视觉-语言模型、3D重建和分割方面缺乏实时文本提示3D查询支持的空白。&lt;h4&gt;方法&lt;/h4&gt;引入了一种结合Segment Anything模型和最先进的视觉-语言模型的3D语义特征学习策略，提取分割的语言特征以进行3D手术场景重建。同时提出了语义感知变形跟踪和语义区域感知优化。&lt;h4&gt;主要发现&lt;/h4&gt;SurgTPGS在两个真实世界手术数据集上进行了全面实验，证明了其优于现有方法，并有望革新外科实践。&lt;h4&gt;结论&lt;/h4&gt;SurgTPGS为开发下一代智能手术系统铺平了道路，通过提高手术精度和安全性能。&lt;h4&gt;翻译&lt;/h4&gt;在当代外科研究和实践中，准确理解具有文本提示能力的3D手术场景对于手术规划和术中实时指导尤其重要，精确识别和交互手术工具和解剖结构至关重要。然而，现有工作分别关注手术视觉-语言模型（VLM）、3D重建和分割，缺乏对实时文本提示3D查询的支持。在本文中，我们提出了一种新的基于文本提示的Gaussian Splatting方法SurgTPGS来填补这一空白。我们引入了一种结合Segment Anything模型和最先进的视觉-语言模型的3D语义特征学习策略，用于提取分割的语言特征以进行3D手术场景重建，从而更深入地理解复杂的手术环境。我们还提出了语义感知变形跟踪来捕捉语义特征的连续变形，为纹理和语义特征提供更精确的重建。此外，我们还提出了语义区域感知优化，利用基于区域的语义信息来监督训练，特别是促进重建质量和语义平滑性。我们在两个真实世界手术数据集上进行了全面实验，以证明SurgTPGS优于现有方法，并突出其革新外科实践潜力。SurgTPGS通过提高手术精度和安全性能，为开发下一代智能手术系统铺平了道路。我们的代码可在https://github.com/lastbasket/SurgTPGS上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In contemporary surgical research and practice, accurately comprehending 3Dsurgical scenes with text-promptable capabilities is particularly crucial forsurgical planning and real-time intra-operative guidance, where preciselyidentifying and interacting with surgical tools and anatomical structures isparamount. However, existing works focus on surgical vision-language model(VLM), 3D reconstruction, and segmentation separately, lacking support forreal-time text-promptable 3D queries. In this paper, we present SurgTPGS, anovel text-promptable Gaussian Splatting method to fill this gap. We introducea 3D semantics feature learning strategy incorporating the Segment Anythingmodel and state-of-the-art vision-language models. We extract the segmentedlanguage features for 3D surgical scene reconstruction, enabling a morein-depth understanding of the complex surgical environment. We also proposesemantic-aware deformation tracking to capture the seamless deformation ofsemantic features, providing a more precise reconstruction for both texture andsemantic features. Furthermore, we present semantic region-aware optimization,which utilizes regional-based semantic information to supervise the training,particularly promoting the reconstruction quality and semantic smoothness. Weconduct comprehensive experiments on two real-world surgical datasets todemonstrate the superiority of SurgTPGS over state-of-the-art methods,highlighting its potential to revolutionize surgical practices. SurgTPGS pavesthe way for developing next-generation intelligent surgical systems byenhancing surgical precision and safety. Our code is available at:https://github.com/lastbasket/SurgTPGS.</description>
      <author>example@mail.com (Yiming Huang, Long Bai, Beilei Cui, Kun Yuan, Guankun Wang, Mobarakol Islam, Nicolas Padoy, Nassir Navab, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.23309v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound</title>
      <link>http://arxiv.org/abs/2506.23108v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为CVC-RF的新型框架，用于更精确的颈动脉斑块分级，以提高心血管和脑血管疾病的风险评估。&lt;h4&gt;背景&lt;/h4&gt;颈动脉斑块分级对于评估心血管和脑血管疾病风险至关重要，但现有方法在处理斑块的小尺寸和类内变异性时存在不足。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效处理不同层级信息并提升模型性能的颈动脉斑块分级方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种CVC-RF框架，该框架从语料库、视图和类别三个层级处理信息，并包括以下创新点：1. 根据Carotid Plaque-RADS指南，开发了一个基于深度学习的颈动脉斑块分级方法；2. 提出了一种新的中心-记忆对比损失函数，增强了网络的全球建模能力；3. 设计了一个级联下采样注意力模块，以融合多尺度信息并在视图级别实现隐式特征交互；4. 引入了一种参数自由的专业混合加权策略，利用类别聚类知识来加权不同专家，实现类别层级的特征解耦。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CVC-RF通过多层级细化有效地建模全局特征，在颈动脉斑块分级这一具有挑战性的任务中实现了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;CVC-RF框架能够显著提高颈动脉斑块分级的准确性，为心血管和脑血管疾病的早期诊断提供了新的技术支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate carotid plaque grading (CPG) is vital to assess the risk ofcardiovascular and cerebrovascular diseases. Due to the small size and highintra-class variability of plaque, CPG is commonly evaluated using acombination of transverse and longitudinal ultrasound views in clinicalpractice. However, most existing deep learning-based multi-view classificationmethods focus on feature fusion across different views, neglecting theimportance of representation learning and the difference in class features. Toaddress these issues, we propose a novel Corpus-View-Category RefinementFramework (CVC-RF) that processes information from Corpus-, View-, andCategory-levels, enhancing model performance. Our contribution is four-fold.First, to the best of our knowledge, we are the foremost deep learning-basedmethod for CPG according to the latest Carotid Plaque-RADS guidelines. Second,we propose a novel center-memory contrastive loss, which enhances the network'sglobal modeling capability by comparing with representative cluster centers anddiverse negative samples at the Corpus level. Third, we design a cascadeddown-sampling attention module to fuse multi-scale information and achieveimplicit feature interaction at the View level. Finally, a parameter-freemixture-of-experts weighting strategy is introduced to leverage classclustering knowledge to weight different experts, enabling feature decouplingat the Category level. Experimental results indicate that CVC-RF effectivelymodels global features via multi-level refinement, achieving state-of-the-artperformance in the challenging CPG task.</description>
      <author>example@mail.com (Zhiyuan Zhu, Jian Wang, Yong Jiang, Tong Han, Yuhao Huang, Ang Zhang, Kaiwen Yang, Mingyuan Luo, Zhe Liu, Yaofei Duan, Dong Ni, Tianhong Tang, Xin Yang)</author>
      <guid isPermaLink="false">2506.23108v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning</title>
      <link>http://arxiv.org/abs/2506.22919v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Hecto是一个轻量级的MoE模型，通过结合不同的专家来提高条件计算效率，并增强表示多样性。&lt;h4&gt;背景&lt;/h4&gt;MoE模型通过将输入路由到专门化的专家来支持条件计算，但现有的专家依赖于相同的归纳偏见，限制了表示多样性。&lt;h4&gt;目的&lt;/h4&gt;提出Hecto模型，以解决MoE模型中专家同质化带来的问题，提高模型的效率和可解释性。&lt;h4&gt;方法&lt;/h4&gt;Hecto模型结合了GRU专家用于时间推理和FFNN专家用于静态抽象，在稀疏Top-1门控机制下工作。&lt;h4&gt;主要发现&lt;/h4&gt;Hecto在三个推理基准和回归任务上表现良好，即使在单独的输入表示下也能与同质基线相匹配。在更大的批次大小下，Hecto的性能有所提高。消融实验表明，Hecto的稳定性和可解释性来源于其架构多样性。&lt;h4&gt;结论&lt;/h4&gt;Hecto作为一个新的条件计算基准，为资源有限的环境中的专业化推理提供了一个原则性的框架，其模型强度源于原则性的专业化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mixture-of-Experts (MoE) models enable conditional computation by routinginputs to specialized experts, but these experts rely on identical inductivebiases, thus limiting representational diversity. This static computationpathway is inefficient for inputs that require different types of reasoning andlimits specialization and interpretability. We propose Hecto, a lightweight MoEarchitecture that leverages architectural heterogeneity by combining a GRUexpert for temporal reasoning and an FFNN expert for static abstraction under asparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AGNews, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closelytrails homogeneous baselines in performance despite receiving isolated inputrepresentations, while achieving clear expert specialization, with each expertaligning to distinct reasoning types (temporal vs static). At larger batchsizes, Hecto exhibits improved performance, benefiting from relaxedcomputational constraints that allow its heterogeneous architecture to optimizemore effectively. Ablation results isolate architectural diversity as thesource of Hecto's stability and interpretability across diverse reasoningtasks. Overall, Hecto establishes itself as a new benchmark for conditionalcomputation, offering a principled framework for specialized reasoning inlow-resource regimes with its model strength derived from principledspecialization.</description>
      <author>example@mail.com (Sanskar Pandey, Ruhaan Chopra, Saad Murtaza Bhat, Ark Abhyudaya)</author>
      <guid isPermaLink="false">2506.22919v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Zero-Shot EEG-to-Gait Decoding via Phase-Aware Representation Learning</title>
      <link>http://arxiv.org/abs/2506.22488v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;NeuroDyGait是一种基于EEG信号的领域泛化运动解码框架，通过结构化对比表示学习和关系领域建模解决下肢运动解码问题。&lt;h4&gt;背景&lt;/h4&gt;准确解码EEG信号中的下肢运动对于提高BCI在运动意图识别和控制方面的应用至关重要，但目前存在因果预测、相位一致性预测和模型个体间及个体内差异建模的挑战。&lt;h4&gt;目的&lt;/h4&gt;提出NeuroDyGait框架以解决上述挑战，实现因果、相位一致的预测，并建模个体间及个体内差异。&lt;h4&gt;方法&lt;/h4&gt;NeuroDyGait利用相对对比学习实现EEG和运动嵌入的语义对齐，并引入多周期步态重建目标以维持时间一致性和生物力学一致性。在微调期间，通过域动态解码机制自适应地分配会话特定的预测头，并根据会话间关系混合它们的输出。&lt;h4&gt;主要发现&lt;/h4&gt;NeuroDyGait实现了无需适应的对未见个体的零样本运动预测，并在基准数据集上的跨主体步态解码中表现出优异的性能。即使在训练过程中没有明确的相位监督，它也展现了强大的相位检测能力。&lt;h4&gt;结论&lt;/h4&gt;这些发现突出了关系领域学习在实现可扩展、无目标的BCI部署中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate decoding of lower-limb motion from EEG signals is essential foradvancing brain-computer interface (BCI) applications in movement intentrecognition and control. However, challenges persist in achieving causal,phase-consistent predictions and in modeling both inter- and intra-subjectvariability. To address these issues, we propose NeuroDyGait, adomain-generalizable EEG-to-motion decoding framework that leverages structuredcontrastive representation learning and relational domain modeling. Theproposed method employs relative contrastive learning to achieve semanticalignment between EEG and motion embeddings. Furthermore, a multi-cycle gaitreconstruction objective is introduced to enforce temporal coherence andmaintain biomechanical consistency. To promote inter-session generalization,during fine-tuning, a domain dynamic decoding mechanism adaptively assignssession-specific prediction heads and learns to mix their outputs based oninter-session relationships. NeuroDyGait enables zero-shot motion predictionfor unseen individuals without requiring adaptation and achieves superiorperformance in cross-subject gait decoding on benchmark datasets. Additionally,it demonstrates strong phase-detection capabilities even without explicit phasesupervision during training. These findings highlight the potential ofrelational domain learning in enabling scalable, target-free deployment ofBCIs.</description>
      <author>example@mail.com (Xi Fu, Weibang Jiang, Rui Liu, Gernot R. Müller-Putz, Cuntai Guan)</author>
      <guid isPermaLink="false">2506.22488v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation</title>
      <link>http://arxiv.org/abs/2506.23120v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了在点云感知领域通过视觉-语言对齐利用大型语言模型（LLMs）实现的场景理解进展，并提出了基于推理的分割框架R$^2$S，以及一个包含精确标注的推理分割数据集3D ReasonSeg。&lt;h4&gt;背景&lt;/h4&gt;点云感知在场景理解方面取得了显著进展，但现有方法在处理复杂指令和空间推理方面可能存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于推理的分割框架R$^2$S，以及一个用于复杂推理任务的3D ReasonSeg数据集，以提高3D点云感知的空间推理能力。&lt;h4&gt;方法&lt;/h4&gt;R$^2$S框架通过将空间推理分解为两个阶段：首先识别相关元素，然后根据相关视觉先验处理指令。3D ReasonSeg数据集包含25,185个训练样本和3,966个验证样本。&lt;h4&gt;主要发现&lt;/h4&gt;R$^2$S和3D ReasonSeg有效地增强了3D点云感知的空间推理能力。&lt;h4&gt;结论&lt;/h4&gt;R$^2$S和3D ReasonSeg有望成为未来工作的新基准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近期点云感知在场景理解方面取得了显著进展，通过视觉-语言对齐利用大型语言模型（LLMs）实现了这一成果。然而，现有方法在处理需要精确空间推理的复杂指令时仍可能遇到挑战，尽管3D点云数据提供了详细的空间线索，如大小和位置，以识别目标。为了解决这一问题，我们提出了相关推理分割（R$^2$S），一个基于推理的分割框架。该框架通过将空间推理分解为两个连续阶段来模拟人类的认知过程：首先识别相关元素，然后根据其相关的视觉先验处理指令。此外，鉴于现有数据集在复杂推理任务中的不足，我们引入了3D ReasonSeg，一个包含25,185个训练样本和3,966个验证样本的基于推理的分割数据集。定性和定量实验表明，R$^2$S和3D ReasonSeg有效地赋予了3D点云感知更强的空间推理能力，我们希望它们能作为未来工作的新基准和参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in point cloud perception have demonstrated remarkableprogress in scene understanding through vision-language alignment leveraginglarge language models (LLMs). However, existing methods may still encounterchallenges in handling complex instructions that require accurate spatialreasoning, even if the 3D point cloud data provides detailed spatial cues suchas size and position for identifying the targets. To tackle this issue, wepropose Relevant Reasoning Segmentation (R$^2$S), a reasoning-basedsegmentation framework. The framework emulates human cognitive processes bydecomposing spatial reasoning into two sequential stages: first identifyingrelevant elements, then processing instructions guided by their associatedvisual priors. Furthermore, acknowledging the inadequacy of existing datasetsin complex reasoning tasks, we introduce 3D ReasonSeg, a reasoning-basedsegmentation dataset comprising 25,185 training samples and 3,966 validationsamples with precise annotations. Both quantitative and qualitative experimentsdemonstrate that the R$^2$S and 3D ReasonSeg effectively endow 3D point cloudperception with stronger spatial reasoning capabilities, and we hope that theycan serve as a new baseline and benchmark for future work.</description>
      <author>example@mail.com (Zhenhua Ning, Zhuotao Tian, Shaoshuai Shi, Guangming Lu, Daojing He, Wenjie Pei, Li Jiang)</author>
      <guid isPermaLink="false">2506.23120v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation</title>
      <link>http://arxiv.org/abs/2506.23675v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV'25 Workshops&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Vision Transformer在多个任务中创造了新的基准，但其高计算成本使其在资源受限的硬件上不实用。网络剪枝通过移除不重要的操作来降低计算复杂度，但在未见过的数据域上剪枝会导致权重重要性评估不准确，从而影响资源分配。本文提出了P3B（Pruning by Block Benefit）剪枝方法，通过利用块级别的相对贡献来全局分配参数资源，解决了这一问题。&lt;h4&gt;背景&lt;/h4&gt;Vision Transformer模型在多个任务中表现出色，但计算成本高，不适合资源受限的硬件。网络剪枝虽然能降低计算复杂度，但在未见过的数据域上剪枝会导致权重重要性评估不准确。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的剪枝方法P3B，以解决在未见过的数据域上剪枝导致的问题，并提高模型在资源受限硬件上的性能。&lt;h4&gt;方法&lt;/h4&gt;P3B方法通过利用块级别的相对贡献来全局分配参数资源，识别低影响组件以减少参数分配，同时保留关键组件。&lt;h4&gt;主要发现&lt;/h4&gt;P3B方法在转移学习任务中表现出色，能够显著提高性能，即使在70%参数稀疏度的高稀疏环境下也能保持高性能，精度损失仅为0.64%。&lt;h4&gt;结论&lt;/h4&gt;P3B是一种先进的剪枝方法，在转移学习任务中具有显著优势，能够在资源受限的硬件上有效提高Vision Transformer的性能。&lt;h4&gt;翻译&lt;/h4&gt;Vision Transformer在多个任务中建立了新的基准，但这些模型伴随着高计算成本的问题，这使得它们在资源有限的硬件上不实用。网络剪枝通过移除不重要的操作来降低计算复杂性，同时保持性能。然而，在未见过的数据域上剪枝模型会导致权重重要性评估不准确，从而产生次优的资源分配。在这项工作中，我们发现任务敏感的层最初无法提高下游任务的特征表示，导致早期剪枝决策的性能下降。为了解决这个问题，我们引入了基于块收益的剪枝（P3B），这是一种利用块级别相对贡献来全局分配参数资源的剪枝方法。P3B识别出低影响组件以减少参数分配，同时保留关键组件。与传统的剪枝掩码优化难以重新激活零掩码元素相比，P3B基于全局性能指标设置分层保留比率，确保了后期收敛块的重新激活。我们在广泛的实验中表明，P3B是一种最先进的剪枝方法，在迁移学习任务中取得了最显著的收益。值得注意的是，P3B能够在高稀疏度（70%参数减少）的稀疏环境下保持高性能，精度仅损失0.64%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision Transformer have set new benchmarks in several tasks, but these modelscome with the lack of high computational costs which makes them impractical forresource limited hardware. Network pruning reduces the computational complexityby removing less important operations while maintaining performance. However,pruning a model on an unseen data domain, leads to a misevaluation of weightsignificance, resulting in suboptimal resource assignment. In this work, wefind that task-sensitive layers initially fail to improve the featurerepresentation on downstream tasks, leading to performance loss for earlypruning decisions. To address this problem, we introduce Pruning by BlockBenefit (P3B), a pruning method that utilizes the relative contribution onblock level to globally assign parameter resources. P3B identifies low-impactcomponents to reduce parameter allocation while preserving critical ones.Classical pruning mask optimization struggles to reactivate zero-mask-elements.In contrast, P3B sets a layerwise keep ratio based on global performancemetrics, ensuring the reactivation of late-converging blocks. We show inextensive experiments that P3B is a state of the art pruning method with mostnoticeable gains in transfer learning tasks. Notably, P3B is able to conservehigh performance, even in high sparsity regimes of 70% parameter reductionwhile only losing 0.64% in accuracy.</description>
      <author>example@mail.com (Patrick Glandorf, Bodo Rosenhahn)</author>
      <guid isPermaLink="false">2506.23675v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models</title>
      <link>http://arxiv.org/abs/2506.23949v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了多用途人工智能模型（如大型语言模型、通用人工智能模型、基础模型、生成式人工智能模型和前沿模型）的潜在益处和风险，并提供了针对这些模型的风险管理实践。&lt;h4&gt;背景&lt;/h4&gt;随着多用途AI模型的发展，它们能够提供许多有益的能力，但也存在潜在的不良事件风险。&lt;h4&gt;目的&lt;/h4&gt;为大规模、前沿的GPAI/foundation模型开发者提供风险管理实践，以识别、分析和减轻风险。&lt;h4&gt;方法&lt;/h4&gt;基于NIST AI风险管理框架和ISO/IEC 23894的通用自愿性指导，重点关注GPAI/foundation模型开发者面临的独特问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文旨在帮助开发者了解和应对GPAI/foundation模型的风险。&lt;h4&gt;结论&lt;/h4&gt;本文为GPAI/foundation模型的开发者提供了风险管理方面的指导，以促进其符合或采用领先的AI风险管理标准。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着多用途人工智能模型（如尖端大型语言模型或其他“通用人工智能”（GPAI）模型、“基础模型”、生成式人工智能模型和“前沿模型”（此处通常统称为“GPAI/基础模型”，除非需要更大的具体性）能够提供许多有益的能力，但也存在可能导致严重后果的不良事件风险。本文提供了针对GPAI/基础模型的风险管理实践或控制措施，以识别、分析和减轻风险。我们主要针对大规模、前沿的GPAI/foundation模型开发者；其他可以从中受益的包括基于GPAI/foundation模型构建终端应用的下游开发者。本文有助于遵守或使用领先的AI风险管理相关标准，基于NIST AI风险管理框架和ISO/IEC 23894的通用自愿性指导，重点关注GPAI/foundation模型开发者面临的独特问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Increasingly multi-purpose AI models, such as cutting-edge large languagemodels or other 'general-purpose AI' (GPAI) models, 'foundation models,'generative AI models, and 'frontier models' (typically all referred tohereafter with the umbrella term 'GPAI/foundation models' except where greaterspecificity is needed), can provide many beneficial capabilities but also risksof adverse events with profound consequences. This document providesrisk-management practices or controls for identifying, analyzing, andmitigating risks of GPAI/foundation models. We intend this document primarilyfor developers of large-scale, state-of-the-art GPAI/foundation models; othersthat can benefit from this guidance include downstream developers of end-useapplications that build on a GPAI/foundation model. This document facilitatesconformity with or use of leading AI risk management-related standards,adapting and building on the generic voluntary guidance in the NIST AI RiskManagement Framework and ISO/IEC 23894, with a focus on the unique issues facedby developers of GPAI/foundation models.</description>
      <author>example@mail.com (Anthony M. Barrett, Jessica Newman, Brandie Nonnecke, Nada Madkour, Dan Hendrycks, Evan R. Murphy, Krystal Jackson, Deepika Raman)</author>
      <guid isPermaLink="false">2506.23949v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection</title>
      <link>http://arxiv.org/abs/2506.23519v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 Pages, 9 Figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了在弱监督下使用眼动信息辅助视频显著对象检测（VSOD）的方法，提出了一种结合位置和语义嵌入（PSE）模块的模型，并通过语义和局部性查询（SLQ）以及内部-外部混合对比（IIMC）模型提升时空特征建模能力。&lt;h4&gt;背景&lt;/h4&gt;眼动追踪视频显著性预测（VSP）和视频显著对象检测（VSOD）任务都关注视频中最吸引人的对象，并以预测热图和像素级显著性掩码的形式展示结果。在实际应用中，眼动追踪标注更容易获得，并与人类眼睛的真实视觉模式紧密一致。&lt;h4&gt;目的&lt;/h4&gt;引入注视信息以辅助弱监督下的视频显著对象检测。&lt;h4&gt;方法&lt;/h4&gt;提出了一种位置和语义嵌入（PSE）模块，在特征学习过程中提供位置和语义指导。设计了具有语义和局部性约束的语义和局部性查询（SLQ）竞争者，以有效地选择最匹配和准确的对象查询进行时空建模。此外，通过形成视频内和视频间对比学习范式，引入了内部-外部混合对比（IIMC）模型来提高弱监督下的时空建模能力。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该模型在五个流行的VSOD基准数据集上优于其他竞争者。&lt;h4&gt;结论&lt;/h4&gt;该模型能够有效地利用眼动信息，在弱监督下提高视频显著对象检测的性能。&lt;h4&gt;翻译&lt;/h4&gt;The eye-tracking video saliency prediction (VSP) task and video salient object detection (VSOD) task both focus on the most attractive objects in video and show the result in the form of predictive heatmaps and pixel-level saliency masks, respectively. In practical applications, eye tracker annotations are more readily obtainable and align closely with the authentic visual patterns of human eyes. Therefore, this paper aims to introduce fixation information to assist the detection of video salient objects under weak supervision. On the one hand, we ponder how to better explore and utilize the information provided by fixation, and then propose a Position and Semantic Embedding (PSE) module to provide location and semantic guidance during the feature learning process. On the other hand, we achieve spatiotemporal feature modeling under weak supervision from the aspects of feature selection and feature contrast. A Semantics and Locality Query (SLQ) Competitor with semantic and locality constraints is designed to effectively select the most matching and accurate object query for spatiotemporal modeling. In addition, an Intra-Inter Mixed Contrastive (IIMC) model improves the spatiotemporal modeling capabilities under weak supervision by forming an intra-video and inter-video contrastive learning paradigm. Experimental results on five popular VSOD benchmarks indicate that our model outperforms other competitors on various evaluation metrics.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The eye-tracking video saliency prediction (VSP) task and video salientobject detection (VSOD) task both focus on the most attractive objects in videoand show the result in the form of predictive heatmaps and pixel-level saliencymasks, respectively. In practical applications, eye tracker annotations aremore readily obtainable and align closely with the authentic visual patterns ofhuman eyes. Therefore, this paper aims to introduce fixation information toassist the detection of video salient objects under weak supervision. On theone hand, we ponder how to better explore and utilize the information providedby fixation, and then propose a Position and Semantic Embedding (PSE) module toprovide location and semantic guidance during the feature learning process. Onthe other hand, we achieve spatiotemporal feature modeling under weaksupervision from the aspects of feature selection and feature contrast. ASemantics and Locality Query (SLQ) Competitor with semantic and localityconstraints is designed to effectively select the most matching and accurateobject query for spatiotemporal modeling. In addition, an Intra-Inter MixedContrastive (IIMC) model improves the spatiotemporal modeling capabilitiesunder weak supervision by forming an intra-video and inter-video contrastivelearning paradigm. Experimental results on five popular VSOD benchmarksindicate that our model outperforms other competitors on various evaluationmetrics.</description>
      <author>example@mail.com (Qi Qin, Runmin Cong, Gen Zhan, Yiting Liao, Sam Kwong)</author>
      <guid isPermaLink="false">2506.23519v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance</title>
      <link>http://arxiv.org/abs/2506.23478v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了GeoCD，这是一种用于3D点云学习的拓扑感知和全可微的测地线距离近似，旨在解决Chamfer Distance在3D形状几何特性捕捉上的局限性。&lt;h4&gt;背景&lt;/h4&gt;Chamfer Distance是3D点云学习中广泛采用的指标，但由于其仅依赖于欧几里得距离，因此常常无法捕捉3D形状的内在几何特性。&lt;h4&gt;目的&lt;/h4&gt;为了解决Chamfer Distance的局限性，提出了GeoCD，以改进3D点云学习的重建质量。&lt;h4&gt;方法&lt;/h4&gt;GeoCD是一个拓扑感知和全可微的测地线距离近似，通过实验在多个架构和数据集上对使用标准CD训练的模型进行微调来展示其效果。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，GeoCD在各种架构和数据集上比标准CD的重建质量得到一致提升，且仅需一次epoch的微调就在多个评估指标上取得显著增益。&lt;h4&gt;结论&lt;/h4&gt;GeoCD是一种有效的3D点云学习距离度量，能够显著提高重建质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Chamfer Distance (CD) is a widely adopted metric in 3D point cloud learningdue to its simplicity and efficiency. However, it suffers from a fundamentallimitation: it relies solely on Euclidean distances, which often fail tocapture the intrinsic geometry of 3D shapes. To address this limitation, wepropose GeoCD, a topology-aware and fully differentiable approximation ofgeodesic distance designed to serve as a metric for 3D point cloud learning.Our experiments show that GeoCD consistently improves reconstruction qualityover standard CD across various architectures and datasets. We demonstrate thisby fine-tuning several models, initially trained with standard CD, using GeoCD.Remarkably, fine-tuning for a single epoch with GeoCD yields significant gainsacross multiple evaluation metrics.</description>
      <author>example@mail.com (Pedro Alonso, Tianrui Li, Chongshou Li)</author>
      <guid isPermaLink="false">2506.23478v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?</title>
      <link>http://arxiv.org/abs/2506.23725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种名为PAC Bench的基准测试，用于评估视觉语言模型（VLMs）对核心属性、可利用性和约束（PAC）的理解，以及其在机器人操作中的应用。&lt;h4&gt;背景&lt;/h4&gt;VLMs在机器人操作中扮演重要角色，但它们对低级物理知识的需求通常未得到充分验证。&lt;h4&gt;目的&lt;/h4&gt;引入PAC Bench以评估VLMs在理解物体属性、动作可利用性和物理约束方面的能力。&lt;h4&gt;方法&lt;/h4&gt;PAC Bench包含一个多样化的数据集，包含30,000多个注释，包括673张真实世界图像、100个人类视角场景和120个独特的模拟约束场景。&lt;h4&gt;主要发现&lt;/h4&gt;当前VLMs在理解基本物理概念方面存在显著差距，这表明它们在可靠机器人操作方面的适用性有限，并指出了针对性的研究方向。&lt;h4&gt;结论&lt;/h4&gt;PAC Bench可以作为严格评估VLMs中物理推理的标准基准，并指导开发更稳健、基于物理的机器人应用模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) are increasingly pivotal for generalist robotmanipulation, enabling tasks such as physical reasoning, policy generation, andfailure detection. However, their proficiency in these high-level applicationsoften assumes a deep understanding of low-level physical prerequisites, acapability that remains largely unverified. For robots to perform actionsreliably, they must comprehend intrinsic object properties (e.g., material,weight), action affordances (e.g., graspable, stackable), and physicalconstraints (e.g., stability, reachability, or an object's state, such as beingclosed). Despite the widespread use of VLMs in manipulation tasks, we arguethat off-the-shelf models may lack this granular, physically groundedunderstanding, as such prerequisites are often overlooked during training.  To address this critical gap, we introduce PAC Bench, a comprehensivebenchmark designed to systematically evaluate VLMs on their understanding ofcore Properties, Affordances, and Constraints (PAC) from a task executabilityperspective. PAC Bench features a diverse dataset with over 30,000 annotations,comprising 673 real-world images (115 object classes, 15 property types, and 1to 3 affordances defined per class), 100 real-world humanoid-view scenarios,and 120 unique simulated constraint scenarios across four tasks.  Our evaluations reveal significant gaps in the ability of current VLMs tograsp fundamental physical concepts, highlighting limitations in theirsuitability for reliable robot manipulation and pointing to key areas fortargeted research. PAC Bench also serves as a standardized benchmark forrigorously evaluating physical reasoning in VLMs and guiding the development ofmore robust, physically grounded models for robotic applications.  Project Page: https://pacbench.github.io/</description>
      <author>example@mail.com (Atharva Gundawar, Som Sagar, Ransalu Senanayake)</author>
      <guid isPermaLink="false">2506.23725v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Graph Neural Networks to Predict Coercivity of Hard Magnetic Microstructures</title>
      <link>http://arxiv.org/abs/2506.23615v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 15 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了使用图神经网络（GNN）预测大多晶结构磁性的方法，以加速寻找无稀土永磁体的研究。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNN）是一种有前景的工具，可以预测大型多晶结构的磁性，从而加速寻找无稀土永磁体的研究。&lt;h4&gt;目的&lt;/h4&gt;利用磁模拟数据训练GNN以预测硬磁性微观结构的矫顽力，并评估其性能和不确定性。&lt;h4&gt;方法&lt;/h4&gt;使用磁模拟数据训练GNN，评估其预测矫顽力的性能和不确定性，并重新使用GNN架构预测最大能量产品。进行基于特征工程的外部分布矫顽力预测。&lt;h4&gt;主要发现&lt;/h4&gt;通过训练的GNN可以预测矫顽力，并量化其不确定性；GNN架构也可用于预测最大能量产品；基于系统尺寸对矫顽力依赖性的特征工程有助于外部分布预测。&lt;h4&gt;结论&lt;/h4&gt;GNN在预测磁性材料特性方面具有潜力，可用于加速无稀土永磁体的研究。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNN) are a promising tool to predict magnetic properties of large multi-grain structures, which can speed up the search for rare-earth free permanent magnets. In this paper, we use our magnetic simulation data to train a GNN to predict coercivity of hard magnetic microstructures. We evaluate the performance of the trained GNN and quantify its uncertainty. Subsequently, we reuse the GNN architecture for predicting the maximum energy product. Out-of-distribution predictions of coercivity are also performed, following feature engineering based on the observed dependence of coercivity on system size.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNN) are a promising tool to predict magneticproperties of large multi-grain structures, which can speed up the search forrare-earth free permanent magnets. In this paper, we use our magneticsimulation data to train a GNN to predict coercivity of hard magneticmicrostructures. We evaluate the performance of the trained GNN and quantifyits uncertainty. Subsequently, we reuse the GNN architecture for predicting themaximum energy product. Out-of-distribution predictions of coercivity are alsoperformed, following feature engineering based on the observed dependence ofcoercivity on system size.</description>
      <author>example@mail.com (Heisam Moustafa, Alexander Kovacs, Johann Fischbacher, Markus Gusenbauer, Qais Ali, Leoni Breth, Thomas Schrefl, Harald Oezelt)</author>
      <guid isPermaLink="false">2506.23615v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results</title>
      <link>http://arxiv.org/abs/2506.22843v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了AG-VPReID2025挑战，旨在解决高空与地面视角的Person re-identification（ReID）问题，并展示了多个团队在不同方法上的研究成果。&lt;h4&gt;背景&lt;/h4&gt;Person re-identification技术在大型监控和公共安全应用中变得至关重要。尽管在地面场景中取得了显著进展，但跨视角、尺度变化和遮挡等问题使得高空与地面领域的融合成为一个巨大的挑战。&lt;h4&gt;目的&lt;/h4&gt;通过AG-VPReID2025挑战，旨在解决高空与地面视角的ReID问题，促进相关技术的进步。&lt;h4&gt;方法&lt;/h4&gt;该挑战基于新的AG-VPReID数据集，包含3,027个身份，13,500个tracklets和大约3.7百万帧来自无人机、CCTV和可穿戴相机的图像。参与团队提出了多种解决方案，包括多流架构、基于transformer的时间推理和物理信息建模等。&lt;h4&gt;主要发现&lt;/h4&gt;领先的方法X-TFCLIP在空中到地面的ReID设置中达到了72.28%的Rank-1准确率，在地面到空中的ReID设置中达到了70.77%，超过了现有基线，并突显了数据集的复杂性。&lt;h4&gt;结论&lt;/h4&gt;AG-VPReID2025挑战为高空与地面视角的ReID问题提供了新的研究思路和解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：跨空中和地面视角的人员重识别（ReID）对于大规模监控和公共安全应用变得至关重要。尽管在仅地面场景中取得了重大进展，但由于极端的视角差异、尺度变化和遮挡，连接空中-地面域差距仍然是一个巨大的挑战。基于AG-ReID 2023挑战的成就，本文介绍了AG-VPReID2025挑战——第一个针对高空（80-120m）空中-地面ReID的基于视频的大规模竞赛。该挑战基于新的AG-VPReID数据集，包含3,027个身份，13,500个tracklets和大约3.7百万帧来自无人机、CCTV和可穿戴相机的图像，共有四个国际团队参与。这些团队开发了从多流架构到基于transformer的时间推理和物理信息建模等不同解决方案。领先的方法X-TFCLIP从UAM达到了空中到地面ReID设置的72.28% Rank-1准确率和70.77%地面到空中ReID设置，超过了现有基线，并突显了数据集的复杂性。有关详细信息，请参阅官方网站https://agvpreid25.github.io。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Person re-identification (ReID) across aerial and ground vantage points hasbecome crucial for large-scale surveillance and public safety applications.Although significant progress has been made in ground-only scenarios, bridgingthe aerial-ground domain gap remains a formidable challenge due to extremeviewpoint differences, scale variations, and occlusions. Building upon theachievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID2025 Challenge - the first large-scale video-based competition focused onhigh-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReIDdataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7million frames captured from UAVs, CCTV, and wearable cameras, the challengefeatured four international teams. These teams developed solutions ranging frommulti-stream architectures to transformer-based temporal reasoning andphysics-informed modeling. The leading approach, X-TFCLIP from UAM, attained72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in theground-to-aerial ReID setting, surpassing existing baselines while highlightingthe dataset's complexity. For additional details, please refer to the officialwebsite at https://agvpreid25.github.io.</description>
      <author>example@mail.com (Kien Nguyen, Clinton Fookes, Sridha Sridharan, Huy Nguyen, Feng Liu, Xiaoming Liu, Arun Ross, Dana Michalski, Tamás Endrei, Ivan DeAndres-Tame, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez, Javier Ortega-Garcia, Zijing Gong, Yuhao Wang, Xuehu Liu, Pingping Zhang, Md Rashidunnabi, Hugo Proença, Kailash A. Hambarde, Saeid Rezaei)</author>
      <guid isPermaLink="false">2506.22843v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Synergizing Implicit and Explicit User Interests: A Multi-Embedding Retrieval Framework at Pinterest</title>
      <link>http://arxiv.org/abs/2506.23060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的多嵌入检索框架，旨在提高工业推荐系统中检索阶段的性能，特别是在覆盖广泛且多样化的用户兴趣方面。&lt;h4&gt;背景&lt;/h4&gt;工业推荐系统通常由检索、排名和混合等多个阶段组成。检索阶段在生成包含广泛用户兴趣的候选项目集中起着关键作用。&lt;h4&gt;目的&lt;/h4&gt;解决传统两塔模型在用户-物品特征交互有限和对顶级用例存在偏差的问题。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包括使用可微聚类模块（DCM）从用户历史中捕获隐式兴趣，以及通过条件检索（CR）对用户已关注的主题等显式兴趣进行建模。&lt;h4&gt;主要发现&lt;/h4&gt;通过结合隐式和显式用户兴趣，实现了更有效和全面的候选检索，对不同的用户群体有益，并从不同但补充的来源提取条件。&lt;h4&gt;结论&lt;/h4&gt;实验和A/B测试表明，该框架在用户参与度和内容多样性指标方面有显著提升，已在Pinterest首页成功部署。&lt;h4&gt;翻译&lt;/h4&gt;摘要：工业推荐系统通常由多个阶段组成，包括检索、排名和混合。检索阶段在生成涵盖广泛多样化用户兴趣的候选项目集中起着关键作用。在此阶段有效地覆盖多样化的长尾用户兴趣是一个重大挑战：传统的两塔模型在这方面存在困难，因为它们在用户-物品特征交互方面有限，并且往往偏向于顶级用例。为了解决这些问题，我们提出了一种新的多嵌入检索框架，旨在通过生成基于隐式和显式用户兴趣的多用户嵌入来增强用户兴趣表示。隐式兴趣通过可微聚类模块（DCM）从用户历史中捕获，而显式兴趣，如用户已关注的主题，通过条件检索（CR）进行建模。这些方法代表了一种条件用户表示学习方法，涉及条件表示构建和将目标物品与相关条件关联。协同隐式和显式用户兴趣作为补充方法，以更有效和全面地实现候选检索，因为它们对不同的用户群体有益，并从不同但补充的来源提取条件。广泛的实验和A/B测试揭示了用户参与度和内容多样性指标的显著改进。我们提出的框架已在Pinterest首页成功部署。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737265&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Industrial recommendation systems are typically composed of multiple stages,including retrieval, ranking, and blending. The retrieval stage plays acritical role in generating a high-recall set of candidate items that covers awide range of diverse user interests. Effectively covering the diverse andlong-tail user interests within this stage poses a significant challenge:traditional two-tower models struggle in this regard due to limited user-itemfeature interaction and often bias towards top use cases. To address theseissues, we propose a novel multi-embedding retrieval framework designed toenhance user interest representation by generating multiple user embeddingsconditioned on both implicit and explicit user interests. Implicit interestsare captured from user history through a Differentiable Clustering Module(DCM), whereas explicit interests, such as topics that the user has followed,are modeled via Conditional Retrieval (CR). These methodologies represent aform of conditioned user representation learning that involves conditionrepresentation construction and associating the target item with the relevantconditions. Synergizing implicit and explicit user interests serves as acomplementary approach to achieve more effective and comprehensive candidateretrieval as they benefit on different user segments and extract conditionsfrom different but supplementary sources. Extensive experiments and A/B testingreveal significant improvements in user engagements and feed diversity metrics.Our proposed framework has been successfully deployed on Pinterest home feed.</description>
      <author>example@mail.com (Zhibo Fan, Hongtao Lin, Haoyu Chen, Bowen Deng, Hedi Xia, Yuke Yan, James Li)</author>
      <guid isPermaLink="false">2506.23060v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting</title>
      <link>http://arxiv.org/abs/2506.17609v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Short research paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TyphoFormer的新型框架，用于提高台风轨迹预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;准确的台风轨迹预测对于早期系统预警和灾害响应至关重要。现有的Transformer模型在建模密集轨迹方面表现出色，但在处理稀疏气象轨迹（如台风轨迹）时缺乏广泛的上下文知识。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，提出TyphoFormer框架，通过自然语言描述作为辅助提示来提高台风轨迹预测的可靠性。&lt;h4&gt;方法&lt;/h4&gt;对于每个时间步，使用大型语言模型（LLM）基于北大西洋飓风数据库中记录的数值属性生成简洁的文本描述。这些语言描述捕捉高级气象语义，并作为辅助特殊标记嵌入到数值时间序列输入之前。TyphoFormer通过统一的Transformer编码器集成文本和序列信息，使模型能够利用通过数值特征无法获得的上下文线索。&lt;h4&gt;主要发现&lt;/h4&gt;在HURDAT2基准数据集上进行的广泛实验表明，TyphoFormer在非线性路径变化和有限历史观察的挑战性场景下，始终优于其他最先进的基线方法。&lt;h4&gt;结论&lt;/h4&gt;TyphoFormer框架能够有效提高台风轨迹预测的准确性，为早期预警和灾害响应提供了有力支持。&lt;h4&gt;翻译&lt;/h4&gt;Accurate typhoon track forecasting is crucial for early system warning and disaster response. While Transformer-based models have demonstrated strong performance in modeling the temporal dynamics of dense trajectories of humans and vehicles in smart cities, they usually lack access to broader contextual knowledge that enhances the forecasting reliability of sparse meteorological trajectories, such as typhoon tracks. To address this challenge, we propose TyphoFormer, a novel framework that incorporates natural language descriptions as auxiliary prompts to improve typhoon trajectory forecasting. For each timestep, we use Large Language Model (LLM) to generate concise textual descriptions based on the numerical attributes recorded in the North Atlantic hurricane database. The language descriptions capture high-level meteorological semantics and are embedded as auxiliary special tokens prepended to the numerical time series input. By integrating both textual and sequential information within a unified Transformer encoder, TyphoFormer enables the model to leverage contextual cues that are otherwise inaccessible through numerical features alone. Extensive experiments are conducted on HURDAT2 benchmark, results show that TyphoFormer consistently outperforms other state-of-the-art baseline methods, particularly under challenging scenarios involving nonlinear path shifts and limited historical observations.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate typhoon track forecasting is crucial for early system warning anddisaster response. While Transformer-based models have demonstrated strongperformance in modeling the temporal dynamics of dense trajectories of humansand vehicles in smart cities, they usually lack access to broader contextualknowledge that enhances the forecasting reliability of sparse meteorologicaltrajectories, such as typhoon tracks. To address this challenge, we proposeTyphoFormer, a novel framework that incorporates natural language descriptionsas auxiliary prompts to improve typhoon trajectory forecasting. For each timestep, we use Large Language Model (LLM) to generate concise textualdescriptions based on the numerical attributes recorded in the North Atlantichurricane database. The language descriptions capture high-level meteorologicalsemantics and are embedded as auxiliary special tokens prepended to thenumerical time series input. By integrating both textual and sequentialinformation within a unified Transformer encoder, TyphoFormer enables the modelto leverage contextual cues that are otherwise inaccessible through numericalfeatures alone. Extensive experiments are conducted on HURDAT2 benchmark,results show that TyphoFormer consistently outperforms other state-of-the-artbaseline methods, particularly under challenging scenarios involving nonlinearpath shifts and limited historical observations.</description>
      <author>example@mail.com (Lincan Li, Eren Erman Ozguven, Yue Zhao, Guang Wang, Yiqun Xie, Yushun Dong)</author>
      <guid isPermaLink="false">2506.17609v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Coordinated 2D-3D Visualization of Volumetric Medical Data in XR with Multimodal Interactions</title>
      <link>http://arxiv.org/abs/2506.22926v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE VIS 2025 Short Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了一种基于XR技术的系统，用于改善医疗数据可视化与探索，特别是对于医学知识有限的人员。&lt;h4&gt;背景&lt;/h4&gt;体积医学成像技术可以产生详细的3D解剖结构图像，但有效的医学数据可视化和探索对医学专业知识要求较高。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够增强空间理解并减少认知负荷的XR系统。&lt;h4&gt;方法&lt;/h4&gt;系统包括两个主要创新：(1) 协调的视觉模块，结合多层多平面重建和3D网格模型；(2) 多模式交互框架，结合手势和基于LLM（大型语言模型）的语音命令。通过15名参与者的用户研究和专家访谈进行初步评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，任务完成时间、可用性指标和交互有效性均有所提高，特别是在LLM驱动的语音控制下。&lt;h4&gt;结论&lt;/h4&gt;该沉浸式可视化系统有潜力提高医学培训和临床实践。&lt;h4&gt;翻译&lt;/h4&gt;Volumetric medical imaging technologies produce detailed 3D representations of anatomical structures. However, effective medical data visualization and exploration pose significant challenges, especially for individuals with limited medical expertise. We introduce a novel XR-based system with two key innovations: (1) a coordinated visualization module integrating Multi-layered Multi-planar Reconstruction with 3D mesh models and (2) a multimodal interaction framework combining hand gestures with LLM-enabled voice commands. We conduct preliminary evaluations, including a 15-participant user study and expert interviews, to demonstrate the system's abilities to enhance spatial understanding and reduce cognitive load. Experimental results show notable improvements in task completion times, usability metrics, and interaction effectiveness enhanced by LLM-driven voice control. While identifying areas for future refinement, our findings highlight the potential of this immersive visualization system to advance medical training and clinical practice. Our demo application and supplemental materials are available for download at: https://osf.io/bpjq5/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Volumetric medical imaging technologies produce detailed 3D representationsof anatomical structures. However, effective medical data visualization andexploration pose significant challenges, especially for individuals withlimited medical expertise. We introduce a novel XR-based system with two keyinnovations: (1) a coordinated visualization module integrating Multi-layeredMulti-planar Reconstruction with 3D mesh models and (2) a multimodalinteraction framework combining hand gestures with LLM-enabled voice commands.We conduct preliminary evaluations, including a 15-participant user study andexpert interviews, to demonstrate the system's abilities to enhance spatialunderstanding and reduce cognitive load. Experimental results show notableimprovements in task completion times, usability metrics, and interactioneffectiveness enhanced by LLM-driven voice control. While identifying areas forfuture refinement, our findings highlight the potential of this immersivevisualization system to advance medical training and clinical practice. Ourdemo application and supplemental materials are available for download at:https://osf.io/bpjq5/.</description>
      <author>example@mail.com (Qixuan Liu, Shi Qiu, Yinqiao Wang, Xiwen Wu, Kenneth Siu Ho Chok, Chi-Wing Fu, Pheng-Ann Heng)</author>
      <guid isPermaLink="false">2506.22926v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval</title>
      <link>http://arxiv.org/abs/2506.23605v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  40 pages including supplementary, accepted at ICDAR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于大型语言模型（LLM）的合成讲座幻灯片生成流程（SynLecSlideGen），用于解决讲座幻灯片元素检测和检索问题，并通过实验验证了合成数据在提高模型性能方面的有效性。&lt;h4&gt;背景&lt;/h4&gt;讲座幻灯片元素检测和检索是幻灯片理解的关键问题，而训练有效的模型通常需要大量的手动标注，这既费时又需要专业知识。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来生成高质量的合成讲座幻灯片，以减少对大量手动标注的需求，并提高模型在真实数据上的性能。&lt;h4&gt;方法&lt;/h4&gt;开发了SynLecSlideGen流程，用于生成高质量的合成讲座幻灯片，并创建了一个名为RealSlide的评估基准，通过手动标注1,050张真实讲座幻灯片。使用在合成幻灯片上预训练的模型进行少样本迁移学习，以评估合成幻灯片的实用性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与仅使用真实数据进行训练相比，在合成幻灯片上预训练的少样本迁移学习显著提高了性能，证明了合成数据可以有效地弥补标注讲座幻灯片的数量限制。&lt;h4&gt;结论&lt;/h4&gt;合成数据可以有效地补偿有限的标注讲座幻灯片，有助于提高讲座幻灯片元素检测和检索模型的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a large language model (LLM)-guided synthetic lecture slide generation pipeline, SynLecSlideGen, to address the key problems of lecture slide element detection and retrieval. The experimental results show that few-shot transfer learning with pretraining on synthetic slides significantly improves performance compared to training only on real data, demonstrating the effectiveness of synthetic data in compensating for limited labeled lecture slides.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lecture slide element detection and retrieval are key problems in slideunderstanding. Training effective models for these tasks often depends onextensive manual annotation. However, annotating large volumes of lectureslides for supervised training is labor intensive and requires domainexpertise. To address this, we propose a large language model (LLM)-guidedsynthetic lecture slide generation pipeline, SynLecSlideGen, which produceshigh-quality, coherent and realistic slides. We also create an evaluationbenchmark, namely RealSlide by manually annotating 1,050 real lecture slides.To assess the utility of our synthetic slides, we perform few-shot transferlearning on real data using models pre-trained on them. Experimental resultsshow that few-shot transfer learning with pretraining on synthetic slidessignificantly improves performance compared to training only on real data. Thisdemonstrates that synthetic data can effectively compensate for limited labeledlecture slides. The code and resources of our work are publicly available onour project website: https://synslidegen.github.io/.</description>
      <author>example@mail.com (Suyash Maniyar, Vishvesh Trivedi, Ajoy Mondal, Anand Mishra, C. V. Jawahar)</author>
      <guid isPermaLink="false">2506.23605v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.22817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MVOV3D的新方法，旨在通过减少视觉-语言模型中的内在噪声，提升2D多视图融合在开放词汇3D场景理解中的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的开放词汇3D场景理解方法主要依赖于对比学习或2D特征蒸馏，但这些方法在处理多样化的物体类别时表现不佳，因为训练强开放词汇3D模型的数据量有限。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的方法，以增强开放词汇3D场景理解的能力，同时保持模型的泛化性。&lt;h4&gt;方法&lt;/h4&gt;MVOV3D通过利用CLIP编码器生成的精确区域级图像特征和文本特征，改进多视图2D特征，并引入3D几何先验来优化多视图融合。&lt;h4&gt;主要发现&lt;/h4&gt;MVOV3D在多个数据集上的实验表明了其有效性，并在ScanNet200和Matterport160数据集上实现了新的记录，分别达到14.7%和16.2%的mIoU，显著优于现有的3D网络。&lt;h4&gt;结论&lt;/h4&gt;MVOV3D通过减少视觉-语言模型中的噪声，提高了2D多视图融合在开放词汇3D场景理解中的性能，为该领域提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent open-vocabulary 3D scene understanding approaches mainly focus ontraining 3D networks through contrastive learning with point-text pairs or bydistilling 2D features into 3D models via point-pixel alignment. While thesemethods show considerable performance in benchmarks with limited vocabularies,they struggle to handle diverse object categories as the limited amount of 3Ddata upbound training strong open-vocabulary 3d models. We observe that 2Dmulti-view fusion methods take precedence in understanding diverse concepts in3D scenes. However, inherent noises in vision-language models lead multi-viewfusion to sub-optimal performance. To this end, we introduce MVOV3D, a novelapproach aimed at unleashing the potential of 2D multi-view fusion foropen-vocabulary 3D scene understanding. We focus on reducing the inherentnoises without training, thereby preserving the generalizability whileenhancing open-world capabilities. Specifically, MVOV3D improves multi-view 2Dfeatures by leveraging precise region-level image features and text featuresencoded by CLIP encoders and incorporates 3D geometric priors to optimizemulti-view fusion. Extensive experiments on various datasets demonstrate theeffectiveness of our method. Notably, our MVOV3D achieves a new record with14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for challengeopen-vocabulary semantic segmentation, outperforming current leading trained 3Dnetworks by a significant margin.</description>
      <author>example@mail.com (Xingyilang Yin, Jiale Wang, Xi Yang, Mutian Xu, Xu Gu, Nannan Wang)</author>
      <guid isPermaLink="false">2506.22817v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>FedRef: Communication-Efficient Bayesian Fine Tuning with Reference Model</title>
      <link>http://arxiv.org/abs/2506.23210v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages,14 equation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于参考模型的联邦学习方法，旨在优化人工智能模型训练，同时确保用户隐私。&lt;h4&gt;背景&lt;/h4&gt;联邦学习用于分布式场景中训练人工智能模型，同时确保用户隐私，但在模型性能上可能无法满足用户期望，且难以满足所有用户需求。&lt;h4&gt;目的&lt;/h4&gt;通过模型优化、微调和个性化，实现最佳模型性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于参考模型的联邦学习方法，该方法通过使用包含先前模型参数的参考模型，克服了每次迭代中的灾难性遗忘问题，并通过贝叶斯参数高效的迁移学习来实现。&lt;h4&gt;主要发现&lt;/h4&gt;该方法实现了高模型性能和低计算成本。&lt;h4&gt;结论&lt;/h4&gt;该方法有效解决了联邦学习中模型优化的问题，提高了模型性能，并降低了计算成本。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning(FL) is used for distributed scenarios to train artificialintelligence(AI) models while ensuring users' privacy. In federated learningscenario, the server generally never knows about users' data. This type ofconcept makes the AI training process efficient in terms of data privacy.However, regarding model performance, federated AI models may not sufficientlysatisfy AI users' expectations. Furthermore, AI users have a wide range ofdifferent needs. It is not easy to satisfy the whole users needs. These typesof issues can be addressed through AI model optimization, fine-tuning, orpersonalization to achieve optimal model performance. To address modeloptimization challenges, we propose reference model-based federated learningfor optimal fine-tuning, which overcomes catastrophic forgetting in each round.This method is derived from Bayesian parameter-efficient transfer learning,which includes an optimal proximal term and enables overcoming the catastrophicforgetting issue in each round by utilizing a reference model that incorporatesprevious model parameters. As a result, this method achieves both high modelperformance and low computing cost.</description>
      <author>example@mail.com (Taehwan Yoon, Bongjun Choi)</author>
      <guid isPermaLink="false">2506.23210v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions</title>
      <link>http://arxiv.org/abs/2506.23236v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  [ICCV 2025] https://markomih.github.io/VolumetricSMPL&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VolumetricSMPL是一种基于神经体积的体模型，通过使用神经网络混合权重（NBW）来生成紧凑且高效的MLP解码器，提高了计算效率和表达性。&lt;h4&gt;背景&lt;/h4&gt;参数化人体模型在计算机图形学和视觉中扮演着关键角色，但传统的表面网格模型在处理与其他几何实体（如物体和场景）的交互时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出VolumetricSMPL以解决现有体积神经隐式体模型在复杂人体运动和计算成本方面的不足。&lt;h4&gt;方法&lt;/h4&gt;VolumetricSMPL使用NBW动态混合少量学习的权重矩阵，使用预测的形状和姿态依赖系数，从而提高计算效率。&lt;h4&gt;主要发现&lt;/h4&gt;VolumetricSMPL在推理速度、GPU内存使用、准确性和接触建模方面优于先前的体积占用模型COAP，并在四个挑战性任务中表现出色。&lt;h4&gt;结论&lt;/h4&gt;VolumetricSMPL具有广泛的应用性，并在性能和效率方面取得了显著提升。&lt;h4&gt;翻译&lt;/h4&gt;摘要：参数化人体模型在计算机图形学和视觉中发挥着至关重要的作用，它们使从人体运动分析到理解人-环境交互的应用成为可能。传统上，这些模型使用表面网格，这在处理与其他几何实体（如物体和场景，通常表示为网格或点云）的交互时带来了挑战。为了解决这一限制，最近的研究探索了体积神经隐式体模型。然而，现有工作要么在处理复杂人体运动时不够鲁棒，要么对计算和内存成本要求很高，限制了它们的广泛应用。为此，我们引入了VolumetricSMPL，这是一种利用神经网络混合权重（NBW）生成紧凑且高效的MLP解码器的神经体积体模型。与依赖于大型MLP的先前方法不同，NBW动态混合使用预测的形状和姿态依赖系数的一小套学习权重矩阵，显著提高了计算效率，同时保持了表达性。VolumetricSMPL在推理速度、GPU内存使用、准确性和有符号距离函数（SDF）方面优于先前的体积占用模型COAP，实现了10倍快的推理速度、6倍低的GPU内存使用、更高的准确性和高效的、可微分的接触建模。我们在四个具有挑战性的任务中展示了VolumetricSMPL的优势：（1）从野外图像中重建人-物交互，（2）从自视角中恢复3D场景中的人体网格，（3）场景约束的运动合成，（4）解决自相交问题。我们的结果突出了其广泛的应用性和在性能和效率方面的显著提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Parametric human body models play a crucial role in computer graphics andvision, enabling applications ranging from human motion analysis tounderstanding human-environment interactions. Traditionally, these models usesurface meshes, which pose challenges in efficiently handling interactions withother geometric entities, such as objects and scenes, typically represented asmeshes or point clouds. To address this limitation, recent research hasexplored volumetric neural implicit body models. However, existing works areeither insufficiently robust for complex human articulations or impose highcomputational and memory costs, limiting their widespread use. To this end, weintroduce VolumetricSMPL, a neural volumetric body model that leverages NeuralBlend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlikeprior approaches that rely on large MLPs, NBW dynamically blends a small set oflearned weight matrices using predicted shape- and pose-dependent coefficients,significantly improving computational efficiency while preservingexpressiveness. VolumetricSMPL outperforms prior volumetric occupancy modelCOAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy,and a Signed Distance Function (SDF) for efficient and differentiable contactmodeling. We demonstrate VolumetricSMPL's strengths across four challengingtasks: (1) reconstructing human-object interactions from in-the-wild images,(2) recovering human meshes in 3D scenes from egocentric views, (3)scene-constrained motion synthesis, and (4) resolving self-intersections. Ourresults highlight its broad applicability and significant performance andefficiency gains.</description>
      <author>example@mail.com (Marko Mihajlovic, Siwei Zhang, Gen Li, Kaifeng Zhao, Lea Müller, Siyu Tang)</author>
      <guid isPermaLink="false">2506.23236v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>The Confidence Paradox: Can LLM Know When It's Wrong</title>
      <link>http://arxiv.org/abs/2506.23464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了HonestVQA，一个用于道德对齐的文档视觉问答（DocVQA）的自监督诚实校准框架，旨在解决现有DocVQA系统在道德响应方面的不足。&lt;h4&gt;背景&lt;/h4&gt;尽管文档视觉问答系统在现实世界中得到广泛应用，但它们在道德上往往是透明的，经常对模糊的问题给出过于自信的答案，或者无法以可信的方式传达不确定性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了HonestVQA，旨在提高DocVQA系统的道德响应能力。&lt;h4&gt;方法&lt;/h4&gt;HonestVQA通过量化不确定性来识别知识差距，使用加权损失函数将模型置信度与实际正确性对齐，并通过对比学习强制执行道德响应行为。此外，还引入了两个原则性的评估指标——诚实分数（H-Score）和道德置信度指数（ECI）。&lt;h4&gt;主要发现&lt;/h4&gt;实证研究表明，HonestVQA在SpDocVQA、InfographicsVQA和SROIE数据集上提高了DocVQA的准确性和F1分数，减少了过度自信，降低了H-Score和ECI。在跨领域评估中，它实现了高达78.9%的准确率和76.1%的F1分数，显示出强大的泛化能力。消融实验表明，在没有对齐或对比损失的情况下，准确率下降了3.8%。&lt;h4&gt;结论&lt;/h4&gt;HonestVQA通过提高道德响应能力和准确性，为DocVQA系统提供了一种更可靠的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Document Visual Question Answering (DocVQA) systems are increasingly deployedin real world applications, yet they remain ethically opaque-often producingoverconfident answers to ambiguous questions or failing to communicateuncertainty in a trustworthy manner. This misalignment between model confidenceand actual knowledge poses significant risks, particularly in domains requiringethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUThave advanced SOTA performance by focusing on architectural sophistication andaccuracy; however, they fall short in ethical responsiveness.  To address these limitations, we introduce HonestVQA, a self-supervisedhonesty calibration framework for ethically aligned DocVQA. Our model-agnosticmethod quantifies uncertainty to identify knowledge gaps, aligns modelconfidence with actual correctness using weighted loss functions, and enforcesethical response behavior via contrastive learning. We further introduce twoprincipled evaluation metrics--Honesty Score (H-Score) and Ethical ConfidenceIndex (ECI)--to benchmark alignment between confidence, accuracy, and ethicalcommunication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reducesoverconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. Incross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,demonstrating strong generalization. Ablation shows a 3.8% drop in accuracywithout alignment or contrastive loss.</description>
      <author>example@mail.com (Sahil Tripathi, Md Tabrez Nafis, Imran Hussain, Jiechao Gao)</author>
      <guid isPermaLink="false">2506.23464v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>VoteSplat: Hough Voting Gaussian Splatting for 3D Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.22799v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VoteSplat是一种新的3D场景理解框架，它结合了Hough投票和3D Gaussian Splatting技术，用于高质实时渲染3D场景的新视角合成。&lt;h4&gt;背景&lt;/h4&gt;现有的3D场景渲染方法主要关注几何和外观建模，缺乏对场景的深层理解，并且训练成本高，复杂了原本的微分渲染流程。&lt;h4&gt;目的&lt;/h4&gt;提出VoteSplat框架，以实现更深入的3D场景理解，同时降低训练成本。&lt;h4&gt;方法&lt;/h4&gt;VoteSplat使用Segment Anything Model进行实例分割，提取物体并生成2D投票图。将空间偏移向量嵌入到高斯基元中，通过关联2D图像投票构建3D空间投票，并使用深度扭曲约束来优化深度方向上的定位。对于开放词汇的物体定位，VoteSplat通过投票点将2D图像语义映射到3D点云。&lt;h4&gt;主要发现&lt;/h4&gt;VoteSplat在开放词汇的3D实例定位、3D点云理解、基于点击的3D物体定位、分层分割和消融研究中显示出有效性。&lt;h4&gt;结论&lt;/h4&gt;VoteSplat是一种有效的3D场景理解框架，能够提高3D场景渲染的质量和效率。&lt;h4&gt;翻译&lt;/h4&gt;3D高斯散布（3DGS）已成为高质量、实时渲染3D场景新视角合成的主要动力。然而，现有方法主要关注几何和外观建模，缺乏对场景的深层理解，同时训练成本高，复杂了原本的微分渲染流程。为此，我们提出了VoteSplat，一种结合Hough投票和3DGS的新型3D场景理解框架。具体来说，使用Segment Anything Model进行实例分割，提取物体并生成2D投票图。然后将空间偏移向量嵌入到高斯基元中，通过关联2D图像投票构建3D空间投票，同时使用深度扭曲约束来优化深度方向上的定位。对于开放词汇的物体定位，VoteSplat通过投票点将2D图像语义映射到3D点云，降低了与高维CLIP特征相关的训练成本，同时保持了语义的明确性。大量实验表明，VoteSplat在开放词汇的3D实例定位、3D点云理解、基于点击的3D物体定位、分层分割和消融研究中具有有效性。我们的代码可在https://sy-ja.github.io/votesplat/找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D Gaussian Splatting (3DGS) has become horsepower in high-quality, real-timerendering for novel view synthesis of 3D scenes. However, existing methodsfocus primarily on geometric and appearance modeling, lacking deeper sceneunderstanding while also incurring high training costs that complicate theoriginally streamlined differentiable rendering pipeline. To this end, wepropose VoteSplat, a novel 3D scene understanding framework that integratesHough voting with 3DGS. Specifically, Segment Anything Model (SAM) is utilizedfor instance segmentation, extracting objects, and generating 2D vote maps. Wethen embed spatial offset vectors into Gaussian primitives. These offsetsconstruct 3D spatial votes by associating them with 2D image votes, while depthdistortion constraints refine localization along the depth axis. Foropen-vocabulary object localization, VoteSplat maps 2D image semantics to 3Dpoint clouds via voting points, reducing training costs associated withhigh-dimensional CLIP features while preserving semantic unambiguity. Extensiveexperiments demonstrate effectiveness of VoteSplat in open-vocabulary 3Dinstance localization, 3D point cloud understanding, click-based 3D objectlocalization, hierarchical segmentation, and ablation studies. Our code isavailable at https://sy-ja.github.io/votesplat/</description>
      <author>example@mail.com (Minchao Jiang, Shunyu Jia, Jiaming Gu, Xiaoyuan Lu, Guangming Zhu, Anqi Dong, Liang Zhang)</author>
      <guid isPermaLink="false">2506.22799v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>MedSAM-CA: A CNN-Augmented ViT with Attention-Enhanced Multi-Scale Fusion for Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2506.23700v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了MedSAM-CA，一种基于深度学习的医学图像分割方法，旨在解决医疗图像分割中的两大挑战：数据获取困难和复杂场景下的分割难题。&lt;h4&gt;背景&lt;/h4&gt;医学图像分割对于临床诊断和治疗计划至关重要，但现有方法依赖于大量标注数据，且难以处理低对比度或边界模糊的情况。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法MedSAM-CA，通过架构级微调，减少对大量人工标注数据的依赖，并提高复杂场景下的分割精度。&lt;h4&gt;方法&lt;/h4&gt;MedSAM-CA引入了CBR-Net和Atte-FFB两个关键组件。CBR-Net通过并行操作恢复被长距离注意力机制忽略的边界信息。Atte-FFB则融合来自CBR-Net的多级精细特征和来自解码器的全局表示，以增强边界划分的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;在公开数据集上的实验验证了MedSAM-CA的有效性，在低资源临床环境下表现出强大的效果。&lt;h4&gt;结论&lt;/h4&gt;MedSAM-CA通过减少对大量标注数据的依赖，显著提高了医学图像分割的准确性和效率，为临床应用提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Medical image segmentation plays a crucial role in clinical diagnosis and treatment planning, where accurate boundary delineation is essential for precise lesion localization, organ identification, and quantitative assessment. In recent years, deep learning-based methods have significantly advanced segmentation accuracy. However, two major challenges remain. First, the performance of these methods heavily relies on large-scale annotated datasets, which are often difficult to obtain in medical scenarios due to privacy concerns and high annotation costs. Second, clinically challenging scenarios, such as low contrast in certain imaging modalities and blurry lesion boundaries caused by malignancy, still pose obstacles to precise segmentation. To address these challenges, we propose MedSAM-CA, an architecture-level fine-tuning approach that mitigates reliance on extensive manual annotations by adapting the pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CA introduces two key components: the Convolutional Attention-Enhanced Boundary Refinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block (Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recover boundary information potentially overlooked by long-range attention mechanisms, leveraging hierarchical convolutional processing. Atte-FFB, embedded in the MedSAM decoder, fuses multi-level fine-grained features from skip connections in CBR-Net with global representations upsampled within the decoder to enhance boundary delineation accuracy. Experiments on publicly available datasets covering dermoscopy, CT, and MRI imaging modalities validate the effectiveness of MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only 2% of full training data, reaching 97.25% of full-data training performance, demonstrating strong effectiveness in low-resource clinical settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical image segmentation plays a crucial role in clinical diagnosis andtreatment planning, where accurate boundary delineation is essential forprecise lesion localization, organ identification, and quantitative assessment.In recent years, deep learning-based methods have significantly advancedsegmentation accuracy. However, two major challenges remain. First, theperformance of these methods heavily relies on large-scale annotated datasets,which are often difficult to obtain in medical scenarios due to privacyconcerns and high annotation costs. Second, clinically challenging scenarios,such as low contrast in certain imaging modalities and blurry lesion boundariescaused by malignancy, still pose obstacles to precise segmentation. To addressthese challenges, we propose MedSAM-CA, an architecture-level fine-tuningapproach that mitigates reliance on extensive manual annotations by adaptingthe pretrained foundation model, Medical Segment Anything (MedSAM). MedSAM-CAintroduces two key components: the Convolutional Attention-Enhanced BoundaryRefinement Network (CBR-Net) and the Attention-Enhanced Feature Fusion Block(Atte-FFB). CBR-Net operates in parallel with the MedSAM encoder to recoverboundary information potentially overlooked by long-range attention mechanisms,leveraging hierarchical convolutional processing. Atte-FFB, embedded in theMedSAM decoder, fuses multi-level fine-grained features from skip connectionsin CBR-Net with global representations upsampled within the decoder to enhanceboundary delineation accuracy. Experiments on publicly available datasetscovering dermoscopy, CT, and MRI imaging modalities validate the effectivenessof MedSAM-CA. On dermoscopy dataset, MedSAM-CA achieves 94.43% Dice with only2% of full training data, reaching 97.25% of full-data training performance,demonstrating strong effectiveness in low-resource clinical settings.</description>
      <author>example@mail.com (Peiting Tian, Xi Chen, Haixia Bi, Fan Li)</author>
      <guid isPermaLink="false">2506.23700v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2506.23126v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Transformer的点云世界模型ParticleFormer，用于提高机器人操作的普遍性。该模型通过捕捉机器人动作条件下环境演化的物理基础，直接从真实机器人感知数据中学习，无需复杂的场景重建。&lt;h4&gt;背景&lt;/h4&gt;现有的3D世界模型主要依赖于基于粒子的图神经网络模型，并限于单材料动力学，同时需要耗时进行3D场景重建以获取3D粒子轨迹用于训练。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理多材料、多物体交互的3D世界模型，以提升机器人在实际环境中的操作能力。&lt;h4&gt;方法&lt;/h4&gt;ParticleFormer使用混合点云重建损失进行训练，监督全局和局部动力学特征。模型能够捕捉刚性、可变形和柔性材料之间的精细多物体交互，并直接从真实世界机器人感知数据中训练。&lt;h4&gt;主要发现&lt;/h4&gt;模型在3D场景预测任务和下游操作任务中均表现出有效性，并在六个模拟和三个真实世界实验中优于现有基准，实现了更优的动力学预测精度和更少的 rollout 错误。&lt;h4&gt;结论&lt;/h4&gt;ParticleFormer为通用机器人操作提供了一种有前景的方法，通过提高动力学预测的准确性，减少了下游视觉运动任务中的错误。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于Transformer的点云世界模型ParticleFormer，旨在提高机器人在实际环境中的操作能力。该模型通过直接从真实机器人感知数据中学习，捕捉了机器人动作条件下环境演化的物理基础，无需复杂的场景重建。实验表明，该模型在3D场景预测任务和下游操作任务中均表现出优越性，实现了更优的动力学预测精度和更少的 rollout 错误，为通用机器人操作提供了一种有前景的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D world models (i.e., learning-based 3D dynamics models) offer a promisingapproach to generalizable robotic manipulation by capturing the underlyingphysics of environment evolution conditioned on robot actions. However,existing 3D world models are primarily limited to single-material dynamicsusing a particle-based Graph Neural Network model, and often requiretime-consuming 3D scene reconstruction to obtain 3D particle tracks fortraining. In this work, we present ParticleFormer, a Transformer-based pointcloud world model trained with a hybrid point cloud reconstruction loss,supervising both global and local dynamics features in multi-material,multi-object robot interactions. ParticleFormer captures fine-grainedmulti-object interactions between rigid, deformable, and flexible materials,trained directly from real-world robot perception data without an elaboratescene reconstruction. We demonstrate the model's effectiveness both in 3D sceneforecasting tasks, and in downstream manipulation tasks using a ModelPredictive Control (MPC) policy. In addition, we extend existing dynamicslearning benchmarks to include diverse multi-material, multi-object interactionscenarios. We validate our method on six simulation and three real-worldexperiments, where it consistently outperforms leading baselines by achievingsuperior dynamics prediction accuracy and less rollout error in downstreamvisuomotor tasks. Experimental videos are available athttps://particleformer.github.io/.</description>
      <author>example@mail.com (Suning Huang, Qianzhong Chen, Xiaohan Zhang, Jiankai Sun, Mac Schwager)</author>
      <guid isPermaLink="false">2506.23126v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation</title>
      <link>http://arxiv.org/abs/2506.23460v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CLDF的新方法，用于弱监督语义分割，通过对比学习训练像素解码器，将条件扩散模型（CDM）的扩散特征映射到低维嵌入空间，以提高分割的准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的基于CAM的弱监督语义分割方法在处理部分激活和不精确的对象边界时存在困难，而CDM作为一种替代方法，在生成分割掩码时表现出强大的图像生成能力。&lt;h4&gt;目的&lt;/h4&gt;提出CLDF方法以解决CDM在生成分割掩码时产生的噪声问题，并提高分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;CLDF通过对比学习训练一个像素解码器，将CDM的扩散特征映射到低维嵌入空间，同时结合CDM外部分类器生成的梯度图和CAM来识别前景和背景像素，减少对比学习中的误判。&lt;h4&gt;主要发现&lt;/h4&gt;在两个公开医疗数据集上的四个分割任务中，CLDF方法显著优于现有的基线方法。&lt;h4&gt;结论&lt;/h4&gt;CLDF方法通过改进CDM的噪声问题，有效地提高了弱监督语义分割的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Weakly supervised semantic segmentation (WSSS) methods using class labels often rely on class activation maps (CAMs) to localize objects. However, traditional CAM-based methods struggle with partial activations and imprecise object boundaries due to optimization discrepancies between classification and segmentation. Recently, the conditional diffusion model (CDM) has been used as an alternative for generating segmentation masks in WSSS, leveraging its strong image generation capabilities tailored to specific class distributions. By modifying or perturbing the condition during diffusion sampling, the related objects can be highlighted in the generated images. Yet, the saliency maps generated by CDMs are prone to noise from background alterations during reversed diffusion. To alleviate the problem, we introduce Contrastive Learning with Diffusion Features (CLDF), a novel method that uses contrastive learning to train a pixel decoder to map the diffusion features from a frozen CDM to a low-dimensional embedding space for segmentation. Specifically, we integrate gradient maps generated from CDM external classifier with CAMs to identify foreground and background pixels with fewer false positives/negatives for contrastive learning, enabling robust pixel embedding learning. Experimental results on four segmentation tasks from two public medical datasets demonstrate that our method significantly outperforms existing baselines.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Weakly supervised semantic segmentation (WSSS) methods using class labelsoften rely on class activation maps (CAMs) to localize objects. However,traditional CAM-based methods struggle with partial activations and impreciseobject boundaries due to optimization discrepancies between classification andsegmentation. Recently, the conditional diffusion model (CDM) has been used asan alternative for generating segmentation masks in WSSS, leveraging its strongimage generation capabilities tailored to specific class distributions. Bymodifying or perturbing the condition during diffusion sampling, the relatedobjects can be highlighted in the generated images. Yet, the saliency mapsgenerated by CDMs are prone to noise from background alterations during reversediffusion. To alleviate the problem, we introduce Contrastive Learning withDiffusion Features (CLDF), a novel method that uses contrastive learning totrain a pixel decoder to map the diffusion features from a frozen CDM to alow-dimensional embedding space for segmentation. Specifically, we integrategradient maps generated from CDM external classifier with CAMs to identifyforeground and background pixels with fewer false positives/negatives forcontrastive learning, enabling robust pixel embedding learning. Experimentalresults on four segmentation tasks from two public medical datasets demonstratethat our method significantly outperforms existing baselines.</description>
      <author>example@mail.com (Dewen Zeng, Xinrong Hu, Yu-Jen Chen, Yawen Wu, Xiaowei Xu, Yiyu Shi)</author>
      <guid isPermaLink="false">2506.23460v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization</title>
      <link>http://arxiv.org/abs/2506.22952v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究通过功能性磁共振成像（fMRI）理解大脑动态，提出了基于层次状态空间标记的HST网络，用于量化大脑状态和过渡，并在两个公开fMRI数据集上验证了其有效性和潜在应用。&lt;h4&gt;背景&lt;/h4&gt;理解大脑动态是神经科学中的一个基本挑战，尤其是捕捉大脑在不同功能状态之间的转换。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来量化复杂的脑信号，以便进行可解释的离散化表示。&lt;h4&gt;方法&lt;/h4&gt;引入了一种层次状态空间标记的HST网络，结合了改进的聚类向量量化变分自动编码器（VQ-VAE）来提高量化性能，同时促进脑状态和过渡的代表性标记。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在量化大脑的层次动态方面表现出有效性，并在疾病诊断和重建性能方面具有潜力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为脑动态的特征描述提供了一个有前景的框架，有助于分析脑状态的亚稳态。&lt;h4&gt;翻译&lt;/h4&gt;通过功能性磁共振成像（fMRI）理解大脑动态仍然是在神经科学中的一个基本挑战，尤其是在捕捉大脑在多种功能状态之间转换的过程中。最近，亚稳态，即指暂时稳定的脑状态，提供了一种有前景的范式来量化复杂的脑信号为可解释的、离散化的表示。特别是，与基于聚类的机器学习方法相比，利用向量量化进行标记化的方法在表示学习方面显示出潜力，具有强大的重建和预测能力。然而，大多数现有的方法忽略了脑过渡依赖性，并且缺乏将脑动态量化为代表性且稳定的嵌入的量化。在本研究中，我们提出了一种基于层次状态空间标记的标记网络，称为HST，它根据基于状态空间模型对脑状态和过渡进行分层量化。我们引入了一种改进的聚类向量量化变分自动编码器（VQ-VAE），它结合了量化误差反馈和聚类以提高量化性能，同时促进具有代表性且稳定的标记表示的亚稳态。我们在两个公开的fMRI数据集上验证了我们的HST，证明了它在量化大脑的层次动态方面的有效性，以及它在疾病诊断和重建性能方面的潜力。我们的方法为脑动态的特征描述提供了一个有前景的框架，有助于分析脑状态的亚稳态。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding brain dynamics through functional Magnetic Resonance Imaging(fMRI) remains a fundamental challenge in neuroscience, particularly incapturing how the brain transitions between various functional states.Recently, metastability, which refers to temporarily stable brain states, hasoffered a promising paradigm to quantify complex brain signals intointerpretable, discretized representations. In particular, compared tocluster-based machine learning approaches, tokenization approaches leveragingvector quantization have shown promise in representation learning with powerfulreconstruction and predictive capabilities. However, most existing methodsignore brain transition dependencies and lack a quantification of braindynamics into representative and stable embeddings. In this study, we propose aHierarchical State space-based Tokenization network, termed HST, whichquantizes brain states and transitions in a hierarchical structure based on astate space-based model. We introduce a refined clustered Vector-QuantizationVariational AutoEncoder (VQ-VAE) that incorporates quantization error feedbackand clustering to improve quantization performance while facilitatingmetastability with representative and stable token representations. We validateour HST on two public fMRI datasets, demonstrating its effectiveness inquantifying the hierarchical dynamics of the brain and its potential in diseasediagnosis and reconstruction performance. Our method offers a promisingframework for the characterization of brain dynamics, facilitating the analysisof metastability.</description>
      <author>example@mail.com (Yanwu Yang, Thomas Wolfers)</author>
      <guid isPermaLink="false">2506.22952v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Towards Time Series Generation Conditioned on Unstructured Natural Language</title>
      <link>http://arxiv.org/abs/2506.22927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于非结构化自然语言描述生成时间序列的新方法。&lt;h4&gt;背景&lt;/h4&gt;尽管生成式人工智能在生成图像和文本等数据方面取得了显著进展，但时间序列生成式人工智能仍处于发展阶段。&lt;h4&gt;目的&lt;/h4&gt;研究旨在提出一种从文本生成时间序列的方法，并展示基于自然语言的时间序列生成是可行的。&lt;h4&gt;方法&lt;/h4&gt;研究采用了扩散模型与语言模型相结合的方法，从文本中生成时间序列。&lt;h4&gt;主要发现&lt;/h4&gt;该方法可以应用于定制预测、时间序列操作、数据增强和迁移学习等领域，并构建了一个包含63,010个时间序列-描述对的新公共数据集。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了基于自然语言的时间序列生成是可能的，并提出了一个有助于推动该领域发展的新方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative Artificial Intelligence (AI) has rapidly become a powerful tool,capable of generating various types of data, such as images and text. However,despite the significant advancement of generative AI, time series generative AIremains underdeveloped, even though the application of time series is essentialin finance, climate, and numerous fields. In this research, we propose a novelmethod of generating time series conditioned on unstructured natural languagedescriptions. We use a diffusion model combined with a language model togenerate time series from the text. Through the proposed method, we demonstratethat time series generation based on natural language is possible. The proposedmethod can provide various applications such as custom forecasting, time seriesmanipulation, data augmentation, and transfer learning. Furthermore, weconstruct and propose a new public dataset for time series generation,consisting of 63,010 time series-description pairs.</description>
      <author>example@mail.com (Jaeyun Woo, Jiseok Lee, Brian Kenji Iwana)</author>
      <guid isPermaLink="false">2506.22927v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Double-Diffusion: Diffusion Conditioned Diffusion Probabilistic Model For Air Quality Prediction</title>
      <link>http://arxiv.org/abs/2506.23053v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个名为Double-Diffusion的新型扩散概率模型，用于空气质量预测，并在实际数据集上取得了优异的性能。&lt;h4&gt;背景&lt;/h4&gt;空气质量预测是一个具有时空复杂性和内在动态及不确定性的挑战性任务。&lt;h4&gt;目的&lt;/h4&gt;寻找在确定性和不确定性之间找到平衡点，提出一种新的模型来预测空气质量。&lt;h4&gt;方法&lt;/h4&gt;Double-Diffusion模型利用已知物理原理，结合随机性和概率网络（如扩散模型）来引导空气质量预测。&lt;h4&gt;主要发现&lt;/h4&gt;Double-Diffusion模型在大多数评估场景中排名第一，与现有概率模型相比，在两个真实数据集上表现优异；同时，该模型将推理时间减少了50%到30%，并在连续排名概率得分（CRPS）上提高了3%到12%。&lt;h4&gt;结论&lt;/h4&gt;Double-Diffusion模型为空气质量预测提供了一种新的方法，并显示出其在实际应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Air quality prediction is a challenging forecasting task due to its spatio-temporal complexity and the inherent dynamics as well as uncertainty. Most of the current models handle these two challenges by applying Graph Neural Networks or known physics principles, and quantifying stochasticity through probabilistic networks like Diffusion models. Nevertheless, finding the right balancing point between the certainties and uncertainties remains an open question. Therefore, we propose Double-Diffusion, a novel diffusion probabilistic model that harnesses the power of known physics to guide air quality forecasting with stochasticity. To the best of our knowledge, while precedents have been made of using conditional diffusion models to predict air pollution, this is the first attempt to use physics as a conditional generative approach for air quality prediction. Along with a sampling strategy adopted from image restoration and a new denoiser architecture, Double-Diffusion ranks first in most evaluation scenarios across two real-life datasets compared with other probabilistic models, it also cuts inference time by 50% to 30% while enjoying an increase between 3-12% in Continuous Ranked Probabilistic Score (CRPS).&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Air quality prediction is a challenging forecasting task due to itsspatio-temporal complexity and the inherent dynamics as well as uncertainty.Most of the current models handle these two challenges by applying Graph NeuralNetworks or known physics principles, and quantifying stochasticity throughprobabilistic networks like Diffusion models. Nevertheless, finding the rightbalancing point between the certainties and uncertainties remains an openquestion. Therefore, we propose Double-Diffusion, a novel diffusionprobabilistic model that harnesses the power of known physics to guide airquality forecasting with stochasticity. To the best of our knowledge, whileprecedents have been made of using conditional diffusion models to predict airpollution, this is the first attempt to use physics as a conditional generativeapproach for air quality prediction. Along with a sampling strategy adoptedfrom image restoration and a new denoiser architecture, Double-Diffusion ranksfirst in most evaluation scenarios across two real-life datasets compared withother probabilistic models, it also cuts inference time by 50% to 30% whileenjoying an increase between 3-12% in Continuous Ranked Probabilistic Score(CRPS).</description>
      <author>example@mail.com (Hanlin Dong, Arian Prabowo, Hao Xue, Flora D. Salim)</author>
      <guid isPermaLink="false">2506.23053v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models</title>
      <link>http://arxiv.org/abs/2506.22865v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ReasonBridge的方法，通过新颖的分层知识蒸馏框架，将强大闭源模型中的推理能力有效地迁移到开源模型中。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型（LLMs）在复杂推理和精确指令跟随任务上表现出显著的性能差距，尤其是闭源模型和开源模型之间的差距。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过ReasonBridge方法缩小闭源模型和开源模型在推理能力上的差距。&lt;h4&gt;方法&lt;/h4&gt;ReasonBridge方法包括：1）一个分层蒸馏过程，捕获战略抽象和战术实现模式；2）一个稀疏推理适配器架构，仅需额外0.3%的可训练参数；3）一个测试时计算缩放机制，使用引导推理干预。&lt;h4&gt;主要发现&lt;/h4&gt;ReasonBridge在基准任务上提高了开源模型的推理能力，最高可达23%，显著缩小了与闭源模型的差距。特别地，增强后的Qwen2.5-14B在MATH500任务上优于Claude-Sonnet3.5，在AIME竞赛级别问题上的表现与Claude-Sonnet3.5相当。&lt;h4&gt;结论&lt;/h4&gt;ReasonBridge方法在多个推理领域和模型架构中表现出良好的泛化能力，为指令跟随的推理增强提供了一种高效的样本高效方法。&lt;h4&gt;翻译&lt;/h4&gt;Recent advancements in Large Language Models (LLMs) have revealed a significant performance gap between closed-source and open-source models, particularly in tasks requiring complex reasoning and precise instruction following. This paper introduces ReasonBridge, a methodology that efficiently transfers reasoning capabilities from powerful closed-source to open-source models through a novel hierarchical knowledge distillation framework. We develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning traces emphasizing difficulty, diversity, and quality. These traces are filtered from across multiple domains using a structured multi-criteria selection algorithm. Our transfer learning approach incorporates: (1) a hierarchical distillation process capturing both strategic abstraction and tactical implementation patterns, (2) a sparse reasoning-focused adapter architecture requiring only 0.3% additional trainable parameters, and (3) a test-time compute scaling mechanism using guided inference interventions. Comprehensive evaluations demonstrate that ReasonBridge improves reasoning capabilities in open-source models by up to 23% on benchmark tasks, significantly narrowing the gap with closed-source models. Notably, the enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its performance on competition-level AIME problems. Our methodology generalizes effectively across diverse reasoning domains and model architectures, establishing a sample-efficient approach to reasoning enhancement for instruction following.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Large Language Models (LLMs) have revealed asignificant performance gap between closed-source and open-source models,particularly in tasks requiring complex reasoning and precise instructionfollowing. This paper introduces ReasonBridge, a methodology that efficientlytransfers reasoning capabilities from powerful closed-source to open-sourcemodels through a novel hierarchical knowledge distillation framework. Wedevelop a tailored dataset Reason1K with only 1,000 carefully curated reasoningtraces emphasizing difficulty, diversity, and quality. These traces arefiltered from across multiple domains using a structured multi-criteriaselection algorithm. Our transfer learning approach incorporates: (1) ahierarchical distillation process capturing both strategic abstraction andtactical implementation patterns, (2) a sparse reasoning-focused adapterarchitecture requiring only 0.3% additional trainable parameters, and (3) atest-time compute scaling mechanism using guided inference interventions.Comprehensive evaluations demonstrate that ReasonBridge improves reasoningcapabilities in open-source models by up to 23% on benchmark tasks,significantly narrowing the gap with closed-source models. Notably, theenhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches itsperformance on competition-level AIME problems. Our methodology generalizeseffectively across diverse reasoning domains and model architectures,establishing a sample-efficient approach to reasoning enhancement forinstruction following.</description>
      <author>example@mail.com (Ziqi Zhong, Xunzhu Tang)</author>
      <guid isPermaLink="false">2506.22865v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Prediction Gaps as Pathways to Explanation: Rethinking Educational Outcomes through Differences in Model Performance</title>
      <link>http://arxiv.org/abs/2506.22993v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了社会环境如何影响生活结果，并提出了预测差距作为识别实证模式的方法，同时使用荷兰的行政数据进行研究。&lt;h4&gt;背景&lt;/h4&gt;社会环境如家庭、学校和邻里关系对生活结果有重要影响，但关键问题在于这些影响对不同人群和在不同条件下有何不同。&lt;h4&gt;目的&lt;/h4&gt;通过比较不同复杂度的统计模型，探讨预测差距是否能够揭示社会理论在哪些方面成功或不足。&lt;h4&gt;方法&lt;/h4&gt;使用荷兰的人口规模行政数据，比较了逻辑回归、梯度提升和图神经网络在预测大学完成情况时，早期社会环境的作用。&lt;h4&gt;主要发现&lt;/h4&gt;预测差距较小，表明先前识别的指标，尤其是父母状况，能够捕捉到教育成就的大部分可测量变化。然而，对于没有父亲的女孩，差距较大，表明社会环境对这些群体的影响超出了简单模型，与社会学理论相符。&lt;h4&gt;结论&lt;/h4&gt;本文展示了预测方法在支持社会学解释方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：社会环境——如家庭、学校和邻里——塑造生活结果。关键问题不仅仅是它们是否重要，而是对谁以及在不同条件下有何影响。在这里，我们认为预测差距——不同复杂度的统计模型之间的预测性能差异——为识别令人惊讶的实证模式（即未被简单模型捕获）提供了途径，这些模式突出了理论成功或不足的地方。我们使用荷兰的人口规模行政数据，比较了逻辑回归、梯度提升和图神经网络，以预测使用早期社会环境完成大学的情况。总体而言，预测差距很小，表明先前识别的指标，特别是父母状况，捕捉到了教育成就的大部分可测量变化。然而，对于没有父亲的女孩，差距较大，表明这些群体社会环境的影响超出了简单模型，与社会学理论相符。我们的论文展示了预测方法支持社会学解释的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Social contexts -- such as families, schools, and neighborhoods -- shape lifeoutcomes. The key question is not simply whether they matter, but rather forwhom and under what conditions. Here, we argue that prediction gaps --differences in predictive performance between statistical models of varyingcomplexity -- offer a pathway for identifying surprising empirical patterns(i.e., not captured by simpler models) which highlight where theories succeedor fall short. Using population-scale administrative data from the Netherlands,we compare logistic regression, gradient boosting, and graph neural networks topredict university completion using early-life social contexts. Overall,prediction gaps are small, suggesting that previously identified indicators,particularly parental status, capture most measurable variation in educationalattainment. However, gaps are larger for girls growing up without fathers --suggesting that the effects of social context for these groups go beyond simplemodels in line with sociological theory. Our paper shows the potential ofprediction methods to support sociological explanation.</description>
      <author>example@mail.com (Javier Garcia-Bernardo, Eva Jaspers, Weverthon Machado, Samuel Plach, Erik Jan van Leeuwen)</author>
      <guid isPermaLink="false">2506.22993v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding</title>
      <link>http://arxiv.org/abs/2506.22593v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Paper accepted to 2025 IEEE International Conference on Automation  Science and Engineering (CASE)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Pix2G的轻量级方法，用于从图像像素和LiDAR地图中实时生成结构化场景图，以支持资源受限的机器人平台在未知环境中的自主探索。&lt;h4&gt;背景&lt;/h4&gt;自主机器人在高风险、危险应用中作为支持平台，对人类操作者的作用越来越重要。为了完成挑战性任务，需要高效的人机协作和理解。机器人规划通常利用3D几何信息，而人类操作者习惯于环境的高级紧凑表示，如表示建筑信息模型（BIM）的俯视图2D地图。3D场景图已成为连接人类可读的2D BIM和机器人3D地图的有力工具。&lt;h4&gt;目的&lt;/h4&gt;提出Pix2G方法，以在资源受限的机器人平台上实时从图像像素和LiDAR地图生成结构化场景图，用于未知环境的自主探索。&lt;h4&gt;方法&lt;/h4&gt;该方法仅在CPU上执行所有操作以满足车载计算限制。输出包括去噪的2D俯视图环境地图和结构分割的3D点云，它们通过多层级图无缝连接，从对象级到建筑级抽象信息。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在真实世界实验中得到了评估，使用NASA JPL NeBula-Spot四足机器人实时探索并绘制杂乱车库和类似城市办公室环境的地图。&lt;h4&gt;结论&lt;/h4&gt;Pix2G方法能够有效生成结构化场景图，支持资源受限的机器人平台在复杂环境中的自主探索和映射。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Autonomous robots are increasingly playing key roles as support platforms forhuman operators in high-risk, dangerous applications. To accomplish challengingtasks, an efficient human-robot cooperation and understanding is required.While typically robotic planning leverages 3D geometric information, humanoperators are accustomed to a high-level compact representation of theenvironment, like top-down 2D maps representing the Building Information Model(BIM). 3D scene graphs have emerged as a powerful tool to bridge the gapbetween human readable 2D BIM and the robot 3D maps. In this work, we introducePixels-to-Graph (Pix2G), a novel lightweight method to generate structuredscene graphs from image pixels and LiDAR maps in real-time for the autonomousexploration of unknown environments on resource-constrained robot platforms. Tosatisfy onboard compute constraints, the framework is designed to perform alloperation on CPU only. The method output are a de-noised 2D top-downenvironment map and a structure-segmented 3D pointcloud which are seamlesslyconnected using a multi-layer graph abstracting information from object-levelup to the building-level. The proposed method is quantitatively andqualitatively evaluated during real-world experiments performed using the NASAJPL NeBula-Spot legged robot to autonomously explore and map cluttered garageand urban office like environments in real-time.</description>
      <author>example@mail.com (Antonello Longo, Chanyoung Chung, Matteo Palieri, Sung-Kyun Kim, Ali Agha, Cataldo Guaragnella, Shehryar Khattak)</author>
      <guid isPermaLink="false">2506.22593v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Missing-Modality-Aware Graph Neural Network for Cancer Classification</title>
      <link>http://arxiv.org/abs/2506.22901v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MAGNET的模型，用于处理多模态生物数据中的缺失模态问题，通过引入患者-模态多头注意力机制和患者图神经网络，提高了预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;从多模态生物数据中学习时，缺失模态是一个关键挑战，因为某些患者的某些模态数据可能缺失。&lt;h4&gt;目的&lt;/h4&gt;提出一种直接使用部分模态进行预测的方法，以解决现有方法在处理多样缺失模态模式和模式数量随模态增加而指数增长的问题。&lt;h4&gt;方法&lt;/h4&gt;MAGNET模型通过引入患者-模态多头注意力机制来融合低维模态嵌入，并构建患者图，其中节点特征为融合的多模态嵌入，连接性由模态缺失性决定。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公开的多组学数据集上进行的实验表明，MAGNET在癌症分类任务中优于现有的融合方法。&lt;h4&gt;结论&lt;/h4&gt;MAGNET能够有效地处理缺失模态问题，并且随着模态数量的增加，其复杂度线性增长，同时适应缺失模式的变化。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从多模态生物数据中学习的一个关键挑战是缺失模态，即某些患者的某些模态数据缺失。现有的融合方法通过排除具有缺失模态的患者、插补缺失模态或直接使用部分模态进行预测来解决这个问题。然而，它们往往难以处理多样的缺失模态模式和随着模态数量增加而指数增长的这种模式数量。为了解决这些限制，我们提出了MAGNET（缺失模态感知图神经网络）用于直接使用部分模态进行预测，该模型引入了患者-模态多头注意力机制，根据其重要性和缺失性来融合低维模态嵌入。MAGNET的复杂度随着模态数量的增加而线性增长，同时适应缺失模式的变化。为了生成预测，MAGNET进一步构建了一个患者图，其中节点特征为融合的多模态嵌入，连接性由模态缺失性决定，随后进行传统的图神经网络。在三个公开的多组学数据集上进行的癌症分类实验，使用的是现实世界的缺失性而不是人工缺失性，表明MAGNET优于现有的融合方法。数据和代码可在https://github.com/SinaTabakhi/MAGNET上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A key challenge in learning from multimodal biological data is missingmodalities, where all data from some modalities are missing for some patients.Current fusion methods address this by excluding patients with missingmodalities, imputing missing modalities, or making predictions directly withpartial modalities. However, they often struggle with diverse missing-modalitypatterns and the exponential growth of the number of such patterns as thenumber of modalities increases. To address these limitations, we propose MAGNET(Missing-modality-Aware Graph neural NETwork) for direct prediction withpartial modalities, which introduces a patient-modality multi-head attentionmechanism to fuse lower-dimensional modality embeddings based on theirimportance and missingness. MAGNET's complexity increases linearly with thenumber of modalities while adapting to missing-pattern variability. To generatepredictions, MAGNET further constructs a patient graph with fused multimodalembeddings as node features and the connectivity determined by the modalitymissingness, followed by a conventional graph neural network. Experiments onthree public multiomics datasets for cancer classification, with real-worldinstead of artificial missingness, show that MAGNET outperforms thestate-of-the-art fusion methods. The data and code are available athttps://github.com/SinaTabakhi/MAGNET.</description>
      <author>example@mail.com (Sina Tabakhi, Haiping Lu)</author>
      <guid isPermaLink="false">2506.22901v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>On the Domain Robustness of Contrastive Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.23663v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Deepbench is available at https://github.com/ml-lab-htw/deepbench&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Deepbench框架，用于评估视觉-语言模型在特定领域的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在实际视觉-语言应用中，虽然大型预训练基础模型在通用基准测试中表现出色，但在特定领域下效果可能会显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出Deepbench框架，以评估视觉-语言模型在特定领域的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;Deepbench利用大型语言模型生成针对特定部署领域的真实、上下文感知的图像损坏，而不需要标记数据。&lt;h4&gt;主要发现&lt;/h4&gt;在六个真实世界领域中，对多种对比视觉-语言架构及其变体进行了评估，发现鲁棒性存在显著差异。&lt;h4&gt;结论&lt;/h4&gt;Deepbench作为开源软件发布，以支持进一步研究针对特定领域的鲁棒性评估。&lt;h4&gt;翻译&lt;/h4&gt;In real-world vision-language applications, practitioners increasingly rely on large, pretrained foundation models rather than custom-built solutions, despite limited transparency regarding their training data and processes. While these models achieve impressive performance on general benchmarks, their effectiveness can decline notably under specialized domain shifts, such as unique imaging conditions or environmental variations. In this work, we introduce Deepbench, a framework designed to assess domain-specific robustness of vision-language models (VLMs). Deepbench leverages a large language model (LLM) to generate realistic, context-aware image corruptions tailored to specific deployment domains without requiring labeled data. We evaluate a range of contrastive vision-language architectures and architectural variants across six real-world domains and observe substantial variability in robustness, highlighting the need for targeted, domain-aware evaluation. Deepbench is released as open-source software to support further research into domain-aware robustness assessment.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world vision-language applications, practitioners increasingly relyon large, pretrained foundation models rather than custom-built solutions,despite limited transparency regarding their training data and processes. Whilethese models achieve impressive performance on general benchmarks, theireffectiveness can decline notably under specialized domain shifts, such asunique imaging conditions or environmental variations. In this work, weintroduce Deepbench, a framework designed to assess domain-specific robustnessof vision-language models (VLMs). Deepbench leverages a large language model(LLM) to generate realistic, context-aware image corruptions tailored tospecific deployment domains without requiring labeled data. We evaluate a rangeof contrastive vision-language architectures and architectural variants acrosssix real-world domains and observe substantial variability in robustness,highlighting the need for targeted, domain-aware evaluation. Deepbench isreleased as open-source software to support further research into domain-awarerobustness assessment.</description>
      <author>example@mail.com (Mario Koddenbrock, Rudolf Hoffmann, David Brodmann, Erik Rodner)</author>
      <guid isPermaLink="false">2506.23663v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method</title>
      <link>http://arxiv.org/abs/2506.23323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;FastSeg是一种新型的、高效的训练免费框架，通过预训练扩散模型的逆向过程进行对象分割，同时实现了对所有类别的实时分割，并引入了多种机制提升分割质量。&lt;h4&gt;背景&lt;/h4&gt;Open-vocabulary语义分割旨在无需大量标注数据集即可从任意文本类别中分割对象。尽管基于对比学习的模型可以实现零样本分割，但它们通常由于全局表示偏差而在像素级别上丢失精细的空间精度。&lt;h4&gt;目的&lt;/h4&gt;提出FastSeg，旨在解决现有模型在像素级别精度和分割质量上的不足，同时提高分割效率。&lt;h4&gt;方法&lt;/h4&gt;FastSeg使用预训练扩散模型的逆向过程，引入了三个关键组件：(i) 双提示机制，用于区分性、类感知的关注提取；(ii) 分层注意力细化方法（HARD），通过尺度对齐的自注意力图增强融合交叉注意力；(iii) 测试时间翻转（TTF）方案，以提高空间一致性。&lt;h4&gt;主要发现&lt;/h4&gt;FastSeg在PASCAL VOC、PASCAL Context和COCO Object基准测试中实现了最先进的训练免费性能，平均mIoU达到43.8%，同时保持了优越的推理效率。&lt;h4&gt;结论&lt;/h4&gt;FastSeg为可扩展性提供了坚实的基础，缩小了分割质量和推理效率之间的差距。&lt;h4&gt;翻译&lt;/h4&gt;Open-vocabulary semantic segmentation (OVSS) aims to segment objects from arbitrary text categories without requiring densely annotated datasets. Although contrastive learning based models enable zero-shot segmentation, they often lose fine spatial precision at pixel level, due to global representation bias. In contrast, diffusion-based models naturally encode fine-grained spatial features via attention mechanisms that capture both global context and local details. However, they often face challenges in balancing the number of iterations with the quality of the segmentation. In this work, we propose FastSeg, a novel and efficient training-free framework with only (1+1)-step of reverse process of a pretrained diffusion model (e.g., Stable Diffusion). Moreover, instead of running multiple times for different classes, FastSeg performs segmentation for all classes at once. To further enhance the segmentation quality, FastSeg introduces three key components: (i) a dual-prompt mechanism for discriminative, class-aware attention extraction, (ii) a Hierarchical Attention Refinement Method (HARD) that enhances fused cross-attention using scale-aligned selfattention maps, and (iii) a Test-TimeFlipping (TTF) scheme designed to improve spatial consistency. Extensive experiments show that FastSeg achieves state-of-the-art training-free performance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context, and COCO Object benchmarks while maintaining superior inference efficiency. Our results demonstrate that FastSeg provides a strong foundation for extendability, bridging the gap between segmentation quality and inference efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Open-vocabulary semantic segmentation (OVSS) aims to segment objects fromarbitrary text categories without requiring densely annotated datasets.Although contrastive learning based models enable zero-shot segmentation, theyoften lose fine spatial precision at pixel level, due to global representationbias. In contrast, diffusion-based models naturally encode fine-grained spatialfeatures via attention mechanisms that capture both global context and localdetails. However, they often face challenges in balancing the number ofiterations with the quality of the segmentation. In this work, we proposeFastSeg, a novel and efficient training-free framework with only (1+1)-step ofreverse process of a pretrained diffusion model (e.g., Stable Diffusion).Moreover, instead of running multiple times for different classes, FastSegperforms segmentation for all classes at once. To further enhance thesegmentation quality, FastSeg introduces three key components: (i) adual-prompt mechanism for discriminative, class-aware attention extraction,(ii) a Hierarchical Attention Refinement Method (HARD) that enhances fusedcross-attention using scale-aligned selfattention maps, and (iii) a Test-TimeFlipping (TTF) scheme designed to improve spatial consistency. Extensiveexperiments show that FastSeg achieves state-of-the-art training-freeperformance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context,and COCO Object benchmarks while maintaining superior inference efficiency. Ourresults demonstrate that FastSeg provides a strong foundation forextendability, bridging the gap between segmentation quality and inferenceefficiency.</description>
      <author>example@mail.com (Quang-Huy Che, Vinh-Tiep Nguyen)</author>
      <guid isPermaLink="false">2506.23323v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>xLSTMAD: A Powerful xLSTM-based Method for Anomaly Detection</title>
      <link>http://arxiv.org/abs/2506.22837v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;xLSTM模型在时间序列预测、无损压缩和大规模语言建模等任务中表现出色，本文首次将xLSTM应用于异常检测。&lt;h4&gt;背景&lt;/h4&gt;xLSTM模型结合了乘法门控和残差连接，为长时预测和表征学习提供了时间容量。&lt;h4&gt;目的&lt;/h4&gt;提出xLSTMAD，第一个集成完整编码器-解码器xLSTM架构的异常检测方法，适用于多变量时间序列数据。&lt;h4&gt;方法&lt;/h4&gt;使用编码器捕获历史上下文，解码器有两种变体：xLSTMAD-F用于迭代生成预测未来值，xLSTMAD-R用于重建输入时间序列。使用均方误差（MSE）和软动态时间扭曲（SoftDTW）作为损失函数。&lt;h4&gt;主要发现&lt;/h4&gt;在TSB-AD-M基准测试中，xLSTMAD在准确性方面优于23个流行的异常检测基线，展现出xLSTM在异常检测方面的强大建模能力。&lt;h4&gt;结论&lt;/h4&gt;本文为xLSTM在异常检测领域的应用开辟了新的发展道路。&lt;h4&gt;翻译&lt;/h4&gt;摘要介绍了xLSTM模型在异常检测中的应用，该模型在时间序列预测、无损压缩和大规模语言建模等方面已证明其有效性。本文提出了一种新的异常检测方法xLSTMAD，该方法集成了完整的编码器-解码器xLSTM架构，并针对多变量时间序列数据进行了优化。在TSB-AD-M基准测试中，xLSTMAD在准确性方面优于其他基线方法，证明了xLSTM在异常检测方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recently proposed xLSTM is a powerful model that leverages expressivemultiplicative gating and residual connections, providing the temporal capacityneeded for long-horizon forecasting and representation learning. Thisarchitecture has demonstrated success in time series forecasting, losslesscompression, and even large-scale language modeling tasks, where its linearmemory footprint and fast inference make it a viable alternative toTransformers. Despite its growing popularity, no prior work has explored xLSTMfor anomaly detection. In this work, we fill this gap by proposing xLSTMAD, thefirst anomaly detection method that integrates a full encoder-decoder xLSTMarchitecture, purpose-built for multivariate time series data. Our encoderprocesses input sequences to capture historical context, while the decoder isdevised in two separate variants of the method. In the forecasting approach,the decoder iteratively generates forecasted future values xLSTMAD-F, while thereconstruction approach reconstructs the input time series from its encodedcounterpart xLSTMAD-R. We investigate the performance of two loss functions:Mean Squared Error (MSE), and Soft Dynamic Time Warping (SoftDTW) to considerlocal reconstruction fidelity and global sequence alignment, respectively. Weevaluate our method on the comprehensive TSB-AD-M benchmark, which spans 17real-world datasets, using state-of-the-art challenging metrics such as VUS-PR.In our results, xLSTM showcases state-of-the-art accuracy, outperforming 23popular anomaly detection baselines. Our paper is the first work revealing thepowerful modeling capabilities of xLSTM for anomaly detection, paving the wayfor exciting new developments on this subject. Our code is available at:https://github.com/Nyderx/xlstmad</description>
      <author>example@mail.com (Kamil Faber, Marcin Pietroń, Dominik Żurek, Roberto Corizzo)</author>
      <guid isPermaLink="false">2506.22837v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Convergent Privacy Framework with Contractive GNN Layers for Multi-hop Aggregations</title>
      <link>http://arxiv.org/abs/2506.22727v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  23 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CARIBOU的图神经网络框架，通过在消息传递过程中应用隐私放大技术，实现了随着层数增加隐私预算的收敛，从而在保护敏感结构信息的同时，提高了模型性能。&lt;h4&gt;背景&lt;/h4&gt;将差分隐私（DP）集成到图神经网络（GNNs）中，可以保护图中敏感的结构信息，如边、节点及其关联特征。然而，现有的方法通常随着层数的增加而线性增加隐私成本，导致需要过多的噪声来维持合理的隐私水平。&lt;h4&gt;目的&lt;/h4&gt;降低GNNs在保护隐私时的成本，特别是在需要深层次GNN以捕捉复杂和长距离交互的情况下。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为Contractive Graph Layer（CGL）的简单而有效的层，它通过利用标准GNN操作的内禀收缩性质，确保所需的收缩性，同时保持模型的有效性。CARIBOU框架支持训练和推理，并配备了收缩聚合模块、隐私分配模块和隐私审计模块。&lt;h4&gt;主要发现&lt;/h4&gt;通过应用隐私放大技术，隐私预算可以随着层数的增加而收敛，从而减少了隐私成本。&lt;h4&gt;结论&lt;/h4&gt;CARIBOU在隐私-效用权衡方面取得了显著改进，并在隐私审计任务中实现了优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;Differential privacy (DP) has been integrated into graph neural networks (GNNs) to protect sensitive structural information, e.g., edges, nodes, and associated features across various applications. A common approach is to perturb the message-passing process, which forms the core of most GNN architectures. However, existing methods typically incur a privacy cost that grows linearly with the number of layers (Usenix Security'23), ultimately requiring excessive noise to maintain a reasonable privacy level. This limitation becomes particularly problematic when deep GNNs are necessary to capture complex and long-range interactions in graphs. In this paper, we theoretically establish that the privacy budget can converge with respect to the number of layers by applying privacy amplification techniques to the message-passing process, exploiting the contractive properties inherent to standard GNN operations. Motivated by this analysis, we propose a simple yet effective Contractive Graph Layer (CGL) that ensures the contractiveness required for theoretical guarantees while preserving model utility. Our framework, CARIBOU, supports both training and inference, equipped with a contractive aggregation module, a privacy allocation module, and a privacy auditing module. Experimental evaluations demonstrate that CARIBOU significantly improves the privacy-utility trade-off and achieves superior performance in privacy auditing tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Differential privacy (DP) has been integrated into graph neural networks(GNNs) to protect sensitive structural information, e.g., edges, nodes, andassociated features across various applications. A common approach is toperturb the message-passing process, which forms the core of most GNNarchitectures. However, existing methods typically incur a privacy cost thatgrows linearly with the number of layers (Usenix Security'23), ultimatelyrequiring excessive noise to maintain a reasonable privacy level. Thislimitation becomes particularly problematic when deep GNNs are necessary tocapture complex and long-range interactions in graphs. In this paper, wetheoretically establish that the privacy budget can converge with respect tothe number of layers by applying privacy amplification techniques to themessage-passing process, exploiting the contractive properties inherent tostandard GNN operations. Motivated by this analysis, we propose a simple yeteffective Contractive Graph Layer (CGL) that ensures the contractivenessrequired for theoretical guarantees while preserving model utility. Ourframework, CARIBOU, supports both training and inference, equipped with acontractive aggregation module, a privacy allocation module, and a privacyauditing module. Experimental evaluations demonstrate that CARIBOUsignificantly improves the privacy-utility trade-off and achieves superiorperformance in privacy auditing tasks.</description>
      <author>example@mail.com (Yu Zheng, Chenang Li, Zhou Li, Qingsong Wang)</author>
      <guid isPermaLink="false">2506.22727v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Score-based Diffusion Model for Unpaired Virtual Histology Staining</title>
      <link>http://arxiv.org/abs/2506.23184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种基于互信息（MI）引导的评分扩散模型，用于无配对的虚拟染色，旨在提高虚拟染色的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;传统的H&amp;E染色和IHC染色在诊断中各有局限性，H&amp;E染色缺乏特异性，而IHC染色受限于组织可用性和抗体特异性。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够高效生成IHC图像的虚拟染色方法，同时保持组织结构。&lt;h4&gt;方法&lt;/h4&gt;提出的方法包括：1）全局MI引导的能量函数，用于跨模态分解组织结构和染色特征；2）时间步长定制反向扩散过程，用于精确控制染色强度和结构重建；3）局部MI驱动的对比学习策略，确保H&amp;E-IHC图像在细胞水平上的结构一致性。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在实验中展现出优于现有技术的优越性，突显了其在生物医学领域的潜力。&lt;h4&gt;结论&lt;/h4&gt;所提出的虚拟染色方法能够有效提高IHC图像生成的效率和准确性，具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;This study proposes a mutual-information (MI)-guided score-based diffusion model for unpaired virtual staining, aiming to improve the efficiency and accuracy of IHC image generation while preserving tissue structure.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hematoxylin and eosin (H&amp;E) staining visualizes histology but lacksspecificity for diagnostic markers. Immunohistochemistry (IHC) stainingprovides protein-targeted staining but is restricted by tissue availability andantibody specificity. Virtual staining, i.e., computationally translating theH&amp;E image to its IHC counterpart while preserving the tissue structure, ispromising for efficient IHC generation. Existing virtual staining methods stillface key challenges: 1) effective decomposition of staining style and tissuestructure, 2) controllable staining process adaptable to diverse tissue andproteins, and 3) rigorous structural consistency modelling to handle thenon-pixel-aligned nature of paired H&amp;E and IHC images. This study proposes amutual-information (MI)-guided score-based diffusion model for unpaired virtualstaining. Specifically, we design 1) a global MI-guided energy function thatdisentangles the tissue structure and staining characteristics acrossmodalities, 2) a novel timestep-customized reverse diffusion process forprecise control of the staining intensity and structural reconstruction, and 3)a local MI-driven contrastive learning strategy to ensure the cellular levelstructural consistency between H&amp;E-IHC images. Extensive experimentsdemonstrate the our superiority over state-of-the-art approaches, highlightingits biomedical potential. Codes will be open-sourced upon acceptance.</description>
      <author>example@mail.com (Anran Liu, Xiaofei Wang, Jing Cai, Chao Li)</author>
      <guid isPermaLink="false">2506.23184v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Compression and Objective Quality Assessment: A Survey</title>
      <link>http://arxiv.org/abs/2506.22902v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对点云压缩（PCC）和点云质量评估（PCQA）的最新进展进行了全面综述，强调了这些技术在实时和感知相关应用中的重要性。&lt;h4&gt;背景&lt;/h4&gt;由于自动驾驶、机器人和沉浸式环境等应用的增长，3D点云数据迅速增长，对高效压缩和质量评估技术提出了迫切需求。&lt;h4&gt;目的&lt;/h4&gt;本文旨在分析各种手工制作和基于学习的PCC算法以及客观PCQA指标，并通过在新兴数据集上基准测试代表性方法，提供详细的比较和实际见解。&lt;h4&gt;方法&lt;/h4&gt;本文分析了广泛的PCC算法，包括手工制作和基于学习的算法，并使用客观PCQA指标进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;尽管取得了显著进展，但仍存在挑战，如提高视觉保真度、减少延迟和支持多模态数据。&lt;h4&gt;结论&lt;/h4&gt;本文概述了未来的研究方向，包括混合压缩框架和高级特征提取策略，以实现更高效、沉浸式和智能的3D应用。&lt;h4&gt;翻译&lt;/h4&gt;本文对点云压缩（PCC）和点云质量评估（PCQA）的最新进展进行了全面综述，强调了这些技术在实时和感知相关应用中的重要性。由于自动驾驶、机器人和沉浸式环境等应用的增长，3D点云数据迅速增长，对高效压缩和质量评估技术提出了迫切需求。本文旨在分析各种手工制作和基于学习的PCC算法以及客观PCQA指标，并通过在新兴数据集上基准测试代表性方法，提供详细的比较和实际见解。尽管取得了显著进展，但仍存在挑战，如提高视觉保真度、减少延迟和支持多模态数据。本文概述了未来的研究方向，包括混合压缩框架和高级特征提取策略，以实现更高效、沉浸式和智能的3D应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of 3D point cloud data, driven by applications in autonomousdriving, robotics, and immersive environments, has led to criticals demand forefficient compression and quality assessment techniques. Unlike traditional 2Dmedia, point clouds present unique challenges due to their irregular structure,high data volume, and complex attributes. This paper provides a comprehensivesurvey of recent advances in point cloud compression (PCC) and point cloudquality assessment (PCQA), emphasizing their significance for real-time andperceptually relevant applications. We analyze a wide range of handcrafted andlearning-based PCC algorithms, along with objective PCQA metrics. Bybenchmarking representative methods on emerging datasets, we offer detailedcomparisons and practical insights into their strengths and limitations.Despite notable progress, challenges such as enhancing visual fidelity,reducing latency, and supporting multimodal data remain. This survey outlinesfuture directions, including hybrid compression frameworks and advanced featureextraction strategies, to enable more efficient, immersive, and intelligent 3Dapplications.</description>
      <author>example@mail.com (Yiling Xu, Yujie Zhang, Shuting Xia, Kaifa Yang, He Huang, Ziyu Shan, Wenjie Huang, Qi Yang, Le Yang)</author>
      <guid isPermaLink="false">2506.22902v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Unified Multimodal Understanding via Byte-Pair Visual Encoding</title>
      <link>http://arxiv.org/abs/2506.23639v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一多模态理解的框架，通过应用字节对编码到视觉标记中，解决了不同模态有效对齐的基本挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管多模态大语言模型（MLLMs）在视觉-语言理解方面取得了显著进展，但有效地对齐不同模态仍然是一个基本挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过将字节对编码应用于视觉标记，统一多模态理解。&lt;h4&gt;方法&lt;/h4&gt;方法包括：1）将结构信息直接纳入视觉标记；2）引入一个优先级引导的编码方案，考虑频率和空间一致性；3）采用基于课程驱动的数据组合的多阶段训练过程。&lt;h4&gt;主要发现&lt;/h4&gt;这些增强使得Transformer模型能够更好地捕捉跨模态关系并利用视觉信息，实验表明在多种视觉-语言任务上性能得到提升。&lt;h4&gt;结论&lt;/h4&gt;通过弥合视觉和文本表示之间的差距，该方法有助于推进更强大和高效的多模态基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;Multimodal large language models (MLLMs) have made significant progress in vision-language understanding, yet effectively aligning different modalities remains a fundamental challenge. We present a framework that unifies multimodal understanding by applying byte-pair encoding to visual tokens. Unlike conventional approaches that rely on modality-specific encoders, our method directly incorporates structural information into visual tokens, mirroring successful tokenization strategies in text-only language models. We introduce a priority-guided encoding scheme that considers both frequency and spatial consistency, coupled with a multi-stage training procedure based on curriculum-driven data composition. These enhancements enable the transformer model to better capture cross-modal relationships and reason with visual information. Comprehensive experiments demonstrate improved performance across diverse vision-language tasks. By bridging the gap between visual and textual representations, our approach contributes to the advancement of more capable and efficient multimodal foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-30&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal large language models (MLLMs) have made significant progress invision-language understanding, yet effectively aligning different modalitiesremains a fundamental challenge. We present a framework that unifies multimodalunderstanding by applying byte-pair encoding to visual tokens. Unlikeconventional approaches that rely on modality-specific encoders, our methoddirectly incorporates structural information into visual tokens, mirroringsuccessful tokenization strategies in text-only language models. We introduce apriority-guided encoding scheme that considers both frequency and spatialconsistency, coupled with a multi-stage training procedure based oncurriculum-driven data composition. These enhancements enable the transformermodel to better capture cross-modal relationships and reason with visualinformation. Comprehensive experiments demonstrate improved performance acrossdiverse vision-language tasks. By bridging the gap between visual and textualrepresentations, our approach contributes to the advancement of more capableand efficient multimodal foundation models.</description>
      <author>example@mail.com (Wanpeng Zhang, Yicheng Feng, Hao Luo, Yijiang Li, Zihao Yue, Sipeng Zheng, Zongqing Lu)</author>
      <guid isPermaLink="false">2506.23639v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>WavShape: Information-Theoretic Speech Representation Learning for Fair and Privacy-Aware Audio Processing</title>
      <link>http://arxiv.org/abs/2506.22789v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 4 figures, Published at The Proceedings of Interspeech 2025,  code is available at http://www.github.com/UTAustin-SwarmLab/WavShape&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为WavShape的语音表示学习框架，旨在优化语音嵌入以实现公平性和隐私保护，同时保留与任务相关的信息。&lt;h4&gt;背景&lt;/h4&gt;语音嵌入可能会保留敏感属性，如说话人身份、口音或人口统计数据，这可能会在模型训练和隐私泄露中带来风险。&lt;h4&gt;目的&lt;/h4&gt;开发一个公平、隐私感知且资源高效的语音系统。&lt;h4&gt;方法&lt;/h4&gt;使用Donsker-Varadhan公式的互信息（MI）估计来指导一个基于MI的编码器，该编码器系统性地过滤敏感属性，同时保持对下游任务至关重要的语音内容。&lt;h4&gt;主要发现&lt;/h4&gt;在三个已知数据集上的实验结果表明，WavShape将嵌入与敏感属性之间的互信息减少了高达81%，同时保留了97%的任务相关信息。&lt;h4&gt;结论&lt;/h4&gt;通过将信息理论与自监督语音模型相结合，这项工作推动了公平、隐私感知和资源高效语音系统的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：语音嵌入通常会保留敏感属性，如说话人身份、口音或人口统计数据，这给模型训练和隐私泄露带来了风险。我们提出了WavShape，一个基于信息论的语音表示学习框架，它优化嵌入以实现公平性和隐私保护，同时保留与任务相关的信息。我们利用Donsker-Varadhan公式的互信息（MI）估计来引导一个基于MI的编码器，该编码器系统地过滤敏感属性，同时保持对下游任务至关重要的语音内容。在三个已知数据集上的实验结果表明，WavShape将嵌入与敏感属性之间的互信息减少了高达81%，同时保留了97%的任务相关信息。通过将信息理论与自监督语音模型相结合，这项工作推动了公平、隐私感知和资源高效语音系统的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Speech embeddings often retain sensitive attributes such as speaker identity,accent, or demographic information, posing risks in biased model training andprivacy leakage. We propose WavShape, an information-theoretic speechrepresentation learning framework that optimizes embeddings for fairness andprivacy while preserving task-relevant information. We leverage mutualinformation (MI) estimation using the Donsker-Varadhan formulation to guide anMI-based encoder that systematically filters sensitive attributes whilemaintaining speech content essential for downstream tasks. Experimental resultson three known datasets show that WavShape reduces MI between embeddings andsensitive attributes by up to 81% while retaining 97% of task-relevantinformation. By integrating information theory with self-supervised speechmodels, this work advances the development of fair, privacy-aware, andresource-efficient speech systems.</description>
      <author>example@mail.com (Oguzhan Baser, Ahmet Ege Tanriverdi, Kaan Kale, Sandeep P. Chinchali, Sriram Vishwanath)</author>
      <guid isPermaLink="false">2506.22789v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Libra: Synergizing CUDA and Tensor Cores for High-Performance Sparse Matrix Multiplication</title>
      <link>http://arxiv.org/abs/2506.22714v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Libra的系统方法，旨在通过协同计算CUDA和Tensor核心来优化稀疏矩阵乘法的性能。&lt;h4&gt;背景&lt;/h4&gt;稀疏矩阵乘法在深度学习和科学计算中广泛应用，现代加速器通常配备Tensor核心和CUDA核心来加速稀疏操作。Tensor核心适用于结构化矩阵乘法，而CUDA核心具有更高的编程灵活性但性能相对较低。&lt;h4&gt;目的&lt;/h4&gt;为了克服单一资源使用的局限性，提高稀疏矩阵乘法的性能。&lt;h4&gt;方法&lt;/h4&gt;Libra系统采用2D感知的工作负载分配策略，以找到不同稀疏算子的任务映射的最佳点，同时利用Tensor核心的高性能和CUDA核心的低计算冗余。此外，Libra还包括针对异构计算的系统性优化，如混合负载平衡、精细优化的内核实现和GPU加速的预处理。&lt;h4&gt;主要发现&lt;/h4&gt;在H100和RTX 4090 GPU上的大量实验结果表明，Libra的平均性能比DTC-SpMM高3.1倍（最高可达9.23倍），对于端到端GNN应用，性能比DTC-SpMM高2.9倍（最高可达3.9倍）。&lt;h4&gt;结论&lt;/h4&gt;Libra通过充分利用GPU上的异构计算资源，为稀疏算子加速开辟了新的视角。&lt;h4&gt;翻译&lt;/h4&gt;Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used in deep learning and scientific computing. Modern accelerators are commonly equipped with Tensor cores and CUDA cores to accelerate sparse operators. The former brings superior computing power but only for structured matrix multiplication, while the latter has relatively lower performance but with higher programming flexibility. In this work, we discover that utilizing one resource alone leads to inferior performance for sparse matrix multiplication, due to their respective limitations. To this end, we propose Libra, a systematic approach that enables synergistic computation between CUDA and Tensor cores to achieve the best performance for sparse matrix multiplication. Specifically, we propose a 2D-aware workload distribution strategy to find out the sweet point of task mapping for different sparse operators, leveraging both the high performance of Tensor cores and the low computational redundancy on CUDA cores. In addition, Libra incorporates systematic optimizations for heterogeneous computing, including hybrid load-balancing, finely optimized kernel implementations, and GPU-accelerated preprocessing. Extensive experimental results on H100 and RTX 4090 GPUs show that Libra outperforms the state-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to 3.9x) for end-to-end GNN applications. Libra opens up a new perspective for sparse operator acceleration by fully exploiting the heterogeneous computing resources on GPUs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely usedin deep learning and scientific computing. Modern accelerators are commonlyequipped with Tensor cores and CUDA cores to accelerate sparse operators. Theformer brings superior computing power but only for structured matrixmultiplication, while the latter has relatively lower performance but withhigher programming flexibility. In this work, we discover that utilizing oneresource alone leads to inferior performance for sparse matrix multiplication,due to their respective limitations. To this end, we propose Libra, asystematic approach that enables synergistic computation between CUDA andTensor cores to achieve the best performance for sparse matrix multiplication.Specifically, we propose a 2D-aware workload distribution strategy to find outthe sweet point of task mapping for different sparse operators, leveraging boththe high performance of Tensor cores and the low computational redundancy onCUDA cores. In addition, Libra incorporates systematic optimizations forheterogeneous computing, including hybrid load-balancing, finely optimizedkernel implementations, and GPU-accelerated preprocessing. Extensiveexperimental results on H100 and RTX 4090 GPUs show that Libra outperforms thestate-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to3.9x) for end-to-end GNN applications. Libra opens up a new perspective forsparse operator acceleration by fully exploiting the heterogeneous computingresources on GPUs.</description>
      <author>example@mail.com (Jinliang Shi, Shigang Li, Youxuan Xu, Xueying Wang, Rongtian Fu, Zhi Ma, Tong Wu)</author>
      <guid isPermaLink="false">2506.22714v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning</title>
      <link>http://arxiv.org/abs/2506.22710v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LightBSR的轻量级盲超分辨率模型，该模型通过优化隐式退化估计（IDE）的判别性来提升超分辨率效果。&lt;h4&gt;背景&lt;/h4&gt;IDE-BSR方法在处理噪声干扰和复杂退化方面展现出潜力，但现有方法过度复杂化适应过程以提高效果，导致模型参数和计算量显著增加。&lt;h4&gt;目的&lt;/h4&gt;优化IDE的判别性，提出一种高效且轻量级的BSR模型。&lt;h4&gt;方法&lt;/h4&gt;采用基于知识蒸馏的学习框架，设计了一种降解先验约束对比学习技术，以及特征对齐技术，以使模型更专注于区分不同退化类型并将教师模型学到的知识传递给学生模型。&lt;h4&gt;主要发现&lt;/h4&gt;通过IDR判别性驱动的BSR模型设计，LightBSR模型在各种盲超分辨率任务中实现了卓越的性能，同时保持了最小复杂性。&lt;h4&gt;结论&lt;/h4&gt;LightBSR模型通过优化IDR判别性，在保持低计算量的同时提升了盲超分辨率任务的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Implicit degradation estimation-based blind super-resolution (IDE-BSR) hingeson extracting the implicit degradation representation (IDR) of the LR image andadapting it to LR image features to guide HR detail restoration. AlthoughIDE-BSR has shown potential in dealing with noise interference and complexdegradations, existing methods ignore the importance of IDR discriminabilityfor BSR and instead over-complicate the adaptation process to improve effect,resulting in a significant increase in the model's parameters and computations.In this paper, we focus on the discriminability optimization of IDR and proposea new powerful and lightweight BSR model termed LightBSR. Specifically, weemploy a knowledge distillation-based learning framework. We first introduce awell-designed degradation-prior-constrained contrastive learning techniqueduring teacher stage to make the model more focused on distinguishing differentdegradation types. Then we utilize a feature alignment technique to transferthe degradation-related knowledge acquired by the teacher to the student forpractical inferencing. Extensive experiments demonstrate the effectiveness ofIDR discriminability-driven BSR model design. The proposed LightBSR can achieveoutstanding performance with minimal complexity across a range of blind SRtasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.</description>
      <author>example@mail.com (Jiang Yuan, JI Ma, Bo Wang, Guanzhou Ke, Weiming Hu)</author>
      <guid isPermaLink="false">2506.22710v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Investigation of the performance of a GNN-based b-jet tagging method in heavy-ion collisions</title>
      <link>http://arxiv.org/abs/2506.22691v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在重离子碰撞中产生的夸克胶子等离子体(QGP)中的部分子动力学，重点关注了b-jets（由 beauty quarks 分解产生的粒子喷流）的能量损失模式，并评估了基于图神经网络(GNN)的b-jet识别方法在复杂环境中的性能。&lt;h4&gt;背景&lt;/h4&gt;Beauty-tagged jets（b-jets）是源于 beauty quarks 在初始强相互作用中产生的喷流，它们可以用来探测 QGP 中的部分子动力学。在低-$p_T$区域，由于 QGP 介子化产生的背景粒子数量众多，传统的 b-jet 标签技术效果不佳。&lt;h4&gt;目的&lt;/h4&gt;研究 GNN 在 Pb-Pb 碰撞环境下的 b-jet 识别性能，并评估其在复杂环境中的鲁棒性，以推进 QGP 诱导的部分子能量损失的未来精密研究。&lt;h4&gt;方法&lt;/h4&gt;采用和调整了 ATLAS 开发的 GN1 模型，在包含 Pb-Pb 背景粒子的喷流中应用该模型，评估了标签决策和对抗背景污染的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;本文对 GNN 基于的 b-jet 标签在重离子碰撞条件下的性能进行了全面的评估。&lt;h4&gt;结论&lt;/h4&gt;通过使用 GNN 方法，可以更精确地测量在复杂环境中的 b-jets，有助于深入理解 QGP 中的强相互作用及其非微扰态。&lt;h4&gt;翻译&lt;/h4&gt;Beauty-tagged jets (b-jets) - 由 beauty quarks 在初始硬碰撞中产生的来自碎片化的粒子喷流 - 为探测在超相对论重离子碰撞中产生的夸克胶子等离子体(QGP)中的部分子动力学提供了一个独特的探测工具。特别是，低-$p_T$ b-jets 通过 QGP 的能量损失模式提供了对强相互作用的非微扰态的有价值见解。CMS 和 ATLAS 合作在 LHC 上研究了 Pb-Pb 碰撞中的 b-jet 产生。由于在低-$p_T$ 区域存在来自 QGP 介子化的背景粒子数量众多这一主要挑战，结果仅限于高-$p_T$ 区域，这严重阻碍了传统 b-jet 标签技术的有效性。为了在这样的复杂环境中进行精确测量，需要先进的标签方法。能够学习喷流组成部分之间关系结构的图神经网络(GNN)是 b-jet 识别的深度学习方法之一。在这项研究中，我们采用了并调整了 ATLAS 初始开发的 GN1 模型，用于 Pb-Pb 碰撞环境。通过将其应用于嵌入 Pb-Pb 背景粒子的喷流，我们评估了该模型的性能，包括标签决策和对抗背景污染的鲁棒性。这项工作对 GNN 基于的 b-jet 标签在重离子碰撞条件下的性能进行了全面的评估，旨在推进 QGP 诱导的部分子能量损失的未来精密研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Beauty-tagged jets (b-jets)-collimated sprays of particles originating fromthe fragmentation of beauty quarks produced in the initial hardscatterings-provide a unique probe of parton dynamics in the quark-gluon plasma(QGP) created in ultrarelativistic heavy-ion collisions. In particular, energyloss patterns of low-$p_T$ b-jets traversing the QGP offer valuable insightinto the strong interaction in its nonperturbative regime. CMS and ATLASCollaborations at the LHC have studied b-jet production in Pb-Pb collisions.The results were limited to a high-$p_T$ region, because a major challenge atlow-$p_T$ is the overwhelming number of background particles from QGPhadronisation, which severely hinders the effectiveness of conventional b-jettagging techniques. To enable precise measurements in such complexenvironments, advanced tagging methods are required. Graph Neural Networks(GNNs), capable of learning relational structures among jet constituents,represent a promising deep learning approach for b-jet identification. In thisstudy, we adopt and adapt the GN1 model, initially developed by ATLAS, for usein Pb-Pb collision environments. We investigate the model's performance byapplying it to jets embedded with Pb-Pb background particles, evaluating bothtagging decisions and robustness against background contamination. This workpresents a comprehensive evaluation of GNN-based b-jet tagging under heavy-ioncollision conditions, aiming to advance future precision studies of QGP-inducedpartonic energy loss.</description>
      <author>example@mail.com (Changhwan Choi, Sanghoon Lim)</author>
      <guid isPermaLink="false">2506.22691v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings</title>
      <link>http://arxiv.org/abs/2506.23115v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Homepage: https://haon-chen.github.io/MoCa/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MoCa是一种两阶段框架，用于将预训练的VLMs转换为有效的双向多模态嵌入模型，解决了当前方法中的三个关键问题。&lt;h4&gt;背景&lt;/h4&gt;基于因果视觉语言模型的多模态嵌入模型在多种任务中显示出潜力，但存在三个主要问题：VLM骨干中使用因果注意力在嵌入任务中不理想；依赖高质量标记配对数据导致可扩展性问题；训练目标和数据多样性有限。&lt;h4&gt;目的&lt;/h4&gt;提出MoCa框架以解决上述问题，提高多模态嵌入模型的效果。&lt;h4&gt;方法&lt;/h4&gt;MoCa包括两个阶段：Modality-aware Continual Pre-training和Heterogeneous Contrastive Fine-tuning。第一阶段通过联合重建目标同时降噪文本和图像输入，增强双向上下文感知推理；第二阶段利用多样化的、语义丰富的多模态数据，增强泛化和对齐。&lt;h4&gt;主要发现&lt;/h4&gt;MoCa通过双向注意力、联合重建目标和多样化的多模态数据解决了现有方法的局限性，并在MMEB和ViDoRe-v2基准测试中实现了新的最先进结果，同时表现出在模型大小和训练数据上的强大可扩展性。&lt;h4&gt;结论&lt;/h4&gt;MoCa是一种有效的多模态嵌入模型，能够显著提高性能并具有良好的可扩展性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal embedding models, built upon causal Vision Language Models (VLMs),have shown promise in various tasks. However, current approaches face three keylimitations: the use of causal attention in VLM backbones is suboptimal forembedding tasks; scalability issues due to reliance on high-quality labeledpaired data for contrastive learning; and limited diversity in trainingobjectives and data. To address these issues, we propose MoCa, a two-stageframework for transforming pre-trained VLMs into effective bidirectionalmultimodal embedding models. The first stage, Modality-aware ContinualPre-training, introduces a joint reconstruction objective that simultaneouslydenoises interleaved text and image inputs, enhancing bidirectionalcontext-aware reasoning. The second stage, Heterogeneous ContrastiveFine-tuning, leverages diverse, semantically rich multimodal data beyond simpleimage-caption pairs to enhance generalization and alignment. Our methodaddresses the stated limitations by introducing bidirectional attention throughcontinual pre-training, scaling effectively with massive unlabeled datasets viajoint reconstruction objectives, and utilizing diverse multimodal data forenhanced representation robustness. Experiments demonstrate that MoCaconsistently improves performance across MMEB and ViDoRe-v2 benchmarks,achieving new state-of-the-art results, and exhibits strong scalability withboth model size and training data on MMEB.</description>
      <author>example@mail.com (Haonan Chen, Hong Liu, Yuping Luo, Liang Wang, Nan Yang, Furu Wei, Zhicheng Dou)</author>
      <guid isPermaLink="false">2506.23115v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>DistShap: Scalable GNN Explanations with Distributed Shapley Values</title>
      <link>http://arxiv.org/abs/2506.22668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DistShap的并行算法，用于在分布式环境下计算图神经网络（GNN）的预测解释，以解决对特定边或特征的归因问题。&lt;h4&gt;背景&lt;/h4&gt;随着图神经网络（GNN）的广泛应用，解释其预测结果变得越来越重要。然而，将预测归因于特定的边或特征在计算上仍然很昂贵。&lt;h4&gt;目的&lt;/h4&gt;提出DistShap算法的目的是为了解决GNN模型中预测解释的计算效率问题。&lt;h4&gt;方法&lt;/h4&gt;DistShap通过在分布式设置中采样子图、并行执行GNN推理，以及解决分布式最小二乘问题来计算边的重要性得分。&lt;h4&gt;主要发现&lt;/h4&gt;DistShap在准确率上优于大多数现有的GNN解释方法，并且是第一个能够扩展到具有数百万个特征的GNN模型，使用了多达128个GPU的NERSC Perlmutter超级计算机。&lt;h4&gt;结论&lt;/h4&gt;DistShap是一种有效的并行算法，可以用于解释大规模GNN模型的预测，显著提高了计算效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing adoption of graph neural networks (GNNs), explaining theirpredictions has become increasingly important. However, attributing predictionsto specific edges or features remains computationally expensive. For example,classifying a node with 100 neighbors using a 3-layer GNN may involveidentifying important edges from millions of candidates contributing to theprediction. To address this challenge, we propose DistShap, a parallelalgorithm that distributes Shapley value-based explanations across multipleGPUs. DistShap operates by sampling subgraphs in a distributed setting,executing GNN inference in parallel across GPUs, and solving a distributedleast squares problem to compute edge importance scores. DistShap outperformsmost existing GNN explanation methods in accuracy and is the first to scale toGNN models with millions of features by using up to 128 GPUs on the NERSCPerlmutter supercomputer.</description>
      <author>example@mail.com (Selahattin Akkas, Aditya Devarakonda, Ariful Azad)</author>
      <guid isPermaLink="false">2506.22668v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization</title>
      <link>http://arxiv.org/abs/2506.23077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为动态对比学习（DyCL）的新框架，用于解决深度学习在跨视图地理定位中的问题，该框架在校园场景中取得了显著的性能提升。&lt;h4&gt;背景&lt;/h4&gt;现有的跨视图地理定位方法主要关注提高跨域图像匹配的准确性，而不是全面捕捉目标周围的上下文信息以及最小化定位误差的成本。&lt;h4&gt;目的&lt;/h4&gt;构建一个名为DA-Campus的基准，以支持对距离感知跨视图地理定位（DACVGL）问题的系统研究。&lt;h4&gt;方法&lt;/h4&gt;基于DA-Campus，将DACVGL问题表述为跨不同域的分层检索问题。提出DyCL框架，通过分层空间边界逐步对特征表示进行对齐。&lt;h4&gt;主要发现&lt;/h4&gt;由于建筑物之间空间关系的固有复杂性，该问题只能通过对比学习范式来解决，而不是传统的度量学习。&lt;h4&gt;结论&lt;/h4&gt;DyCL与现有的多尺度度量学习方法高度互补，在分层检索性能和整体跨视图地理定位准确性方面都取得了显著改进。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel framework called Dynamic Contrastive Learning (DyCL) to address the problem in cross-view geo-localization using deep learning, which has achieved significant performance improvements in the campus scene.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing deep learning-based cross-view geo-localization methods primarilyfocus on improving the accuracy of cross-domain image matching, rather thanenabling models to comprehensively capture contextual information around thetarget and minimize the cost of localization errors. To support systematicresearch into this Distance-Aware Cross-View Geo-Localization (DACVGL) problem,we construct Distance-Aware Campus (DA-Campus), the first benchmark that pairsmulti-view imagery with precise distance annotations across three spatialresolutions. Based on DA-Campus, we formulate DACVGL as a hierarchicalretrieval problem across different domains. Our study further reveals that, dueto the inherent complexity of spatial relationships among buildings, thisproblem can only be addressed via a contrastive learning paradigm, rather thanconventional metric learning. To tackle this challenge, we propose DynamicContrastive Learning (DyCL), a novel framework that progressively alignsfeature representations according to hierarchical spatial margins. Extensiveexperiments demonstrate that DyCL is highly complementary to existingmulti-scale metric learning methods and yields substantial improvements in bothhierarchical retrieval performance and overall cross-view geo-localizationaccuracy. Our code and benchmark are publicly available athttps://github.com/anocodetest1/DyCL.</description>
      <author>example@mail.com (Suofei Zhang, Xinxin Wang, Xiaofu Wu, Quan Zhou, Haifeng Hu)</author>
      <guid isPermaLink="false">2506.23077v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching</title>
      <link>http://arxiv.org/abs/2506.22784v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了激光雷达点云与相机图像的点像素配准问题，提出了一种无检测器的点像素匹配框架，以解决单帧激光雷达设置下的模态差距、稀疏性和噪声问题。&lt;h4&gt;背景&lt;/h4&gt;点像素配准是自动驾驶和机器人感知中的基础且具有挑战性的任务，现有方法存在模态差距，且难以处理单帧激光雷达的稀疏性和噪声。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的无检测器框架，实现激光雷达和相机视图之间的直接点像素匹配，提高匹配的可靠性。&lt;h4&gt;方法&lt;/h4&gt;将激光雷达强度图投影到二维视图，并输入到基于注意力的无检测器匹配网络中，引入重复性评分机制作为软可见性先验，以抑制不可靠的匹配。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在KITTI、nuScenes和MIAS-LCEC-TF70数据集上取得了最先进的性能，优于依赖累积点云的先前方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在单帧激光雷达设置下实现了高精度的点像素配准，为自动驾驶和机器人感知领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The abstract discusses the point-pixel registration between LiDAR point clouds and camera images, presenting a novel detector-free framework for direct point-pixel matching between LiDAR and camera views. The method is designed to address the modality gap, sparsity, and noise issues under sparse single-frame LiDAR settings, and demonstrates state-of-the-art performance on benchmark datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point-pixel registration between LiDAR point clouds and camera images is afundamental yet challenging task in autonomous driving and robotic perception.A key difficulty lies in the modality gap between unstructured point clouds andstructured images, especially under sparse single-frame LiDAR settings.Existing methods typically extract features separately from point clouds andimages, then rely on hand-crafted or learned matching strategies. This separateencoding fails to bridge the modality gap effectively, and more critically,these methods struggle with the sparsity and noise of single-frame LiDAR, oftenrequiring point cloud accumulation or additional priors to improve reliability.Inspired by recent progress in detector-free matching paradigms (e.g.MatchAnything), we revisit the projection-based approach and introduce thedetector-free framework for direct point-pixel matching between LiDAR andcamera views. Specifically, we project the LiDAR intensity map into a 2D viewfrom the LiDAR perspective and feed it into an attention-based detector-freematching network, enabling cross-modal correspondence estimation withoutrelying on multi-frame accumulation. To further enhance matching reliability,we introduce a repeatability scoring mechanism that acts as a soft visibilityprior. This guides the network to suppress unreliable matches in regions withlow intensity variation, improving robustness under sparse input. Extensiveexperiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate thatour method achieves state-of-the-art performance, outperforming priorapproaches on nuScenes (even those relying on accumulated point clouds),despite using only single-frame LiDAR.</description>
      <author>example@mail.com (Yu Han, Zhiwei Huang, Yanting Zhang, Fangjun Ding, Shen Cai, Rui Fan)</author>
      <guid isPermaLink="false">2506.22784v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings</title>
      <link>http://arxiv.org/abs/2506.22881v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了对比学习在视觉和语言领域中的应用，通过文本样本计算图像的语义信息量，并从图像样本计算文本的信息量。&lt;h4&gt;背景&lt;/h4&gt;对比学习能够通过嵌入和调整视觉表示与语义信息来建模多模态概率分布，并估计关系语义相似度。&lt;h4&gt;目的&lt;/h4&gt;探索对比学习是否能表示绝对语义信息量，并提出一种基于文本样本计算图像语义信息量以及从图像样本计算文本信息量的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种重新定义信息增益的概念，并将其应用于视觉和语言领域。通过计算图像和文本的条件分布扭曲程度来量化信息增益。使用Skip-Gram with Negative Sampling（SGNS）的理论结果来估计信息增益。&lt;h4&gt;主要发现&lt;/h4&gt;OpenCLIP的实验结果表明，信息增益最低的图像通常对应于占位符图标，如“图片未找到”。信息增益的测量与CLIP或SigLIP有强相关性，相关系数在0.98到1.00之间。计算成本与样本大小无关，且与公开的开放权重模型兼容。&lt;h4&gt;结论&lt;/h4&gt;通过对比学习模型计算图像和文本的语义信息量是可行的，且具有实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning has the capacity to model multimodal probabilitydistributions by embedding and aligning visual representations with semanticsfrom captions. This approach enables the estimation of relational semanticsimilarity; however, it remains unclear whether it can also represent absolutesemantic informativeness. In this work, we introduce a semantic informativenessmetric for an image calculated from text samples via a contrastive learningmodel; similarly, the informativeness of a text is calculated from imagesamples. We propose a redefinition of the concept of Information Gain, aconcept previously explored in natural language processing, extending itsapplication to the domains of vision and language. Our metric quantifies howconditioning on an image distorts the distribution of associated texts, andvice versa for text conditioning on image distributions. In OpenCLIP'sempirical results, we observe that images with the lowest Information Gainscores often correspond to placeholder icons such as "image not found."Furthermore, we propose to measure a norm-based metric of the embedding toestimate the Information Gain, following the theoretical results for Skip-Gramwith Negative Sampling (SGNS) word embedding. Information Gain can be measuredusing either CLIP or SigLIP, and the results demonstrate a strong correlationwith a coefficient of determination ranging from 0.98 to 1.00. After obtainingthe mean and the covariance of the sample embedding, the computational cost ofthis method is independent of the sample size, and it is compatible withpublicly available, open-weight models.</description>
      <author>example@mail.com (Fumiya Uchiyama, Rintaro Yanagi, Shohei Taniguchi, Shota Takashiro, Masahiro Suzuki, Hirokatsu Kataoka, Yusuke Iwasawa, Yutaka Matsuo)</author>
      <guid isPermaLink="false">2506.22881v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Federated Timeline Synthesis: Scalable and Private Methodology For Model Training and Deployment</title>
      <link>http://arxiv.org/abs/2506.23358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  conference paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了联邦时间线合成（FTS）框架，用于在分布式时间序列数据上训练生成性基础模型，应用于电子健康记录（EHR）。FTS将患者历史表示为标记化的患者健康时间线（PHTs），编码了时间、分类和连续的临床信息。&lt;h4&gt;背景&lt;/h4&gt;FTS框架旨在解决在分布式环境下处理电子健康记录时遇到的隐私和可扩展性问题。&lt;h4&gt;目的&lt;/h4&gt;FTS旨在创建一个能够合成患者健康时间线的大型语料库，并通过蒙特卡洛模拟未来PHTs实现零样本推理。&lt;h4&gt;方法&lt;/h4&gt;每个机构在其本地PHTs上训练一个自回归变压器，并将模型权重传输到中央服务器。服务器使用生成器合成语料库，并训练全局生成器（GG）。&lt;h4&gt;主要发现&lt;/h4&gt;在五个具有临床意义的预测任务上评估FTS，结果表明GG生成的合成数据训练的模型性能与真实数据训练的模型相当。&lt;h4&gt;结论&lt;/h4&gt;FTS提供了强大的隐私保障，具有跨机构的可扩展性和扩展性，特别适用于医疗保健领域的预测和模拟任务，如反事实推理、早期预警检测和合成试验设计。&lt;h4&gt;翻译&lt;/h4&gt;We present Federated Timeline Synthesis (FTS), a novel framework for training generative foundation models across distributed timeseries data applied to electronic health records (EHR). At its core, FTS represents patient history as tokenized Patient Health Timelines (PHTs), language-agnostic sequences encoding temporal, categorical, and continuous clinical information. Each institution trains an autoregressive transformer on its local PHTs and transmits only model weights to a central server. The server uses the generators to synthesize a large corpus of trajectories and train a Global Generator (GG), enabling zero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTS on five clinically meaningful prediction tasks using MIMIC-IV data, showing that models trained on synthetic data generated by GG perform comparably to those trained on real data. FTS offers strong privacy guarantees, scalability across institutions, and extensibility to diverse prediction and simulation tasks especially in healthcare, including counterfactual inference, early warning detection, and synthetic trial design.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Federated Timeline Synthesis (FTS), a novel framework for traininggenerative foundation models across distributed timeseries data applied toelectronic health records (EHR). At its core, FTS represents patient history astokenized Patient Health Timelines (PHTs), language-agnostic sequences encodingtemporal, categorical, and continuous clinical information. Each institutiontrains an autoregressive transformer on its local PHTs and transmits only modelweights to a central server. The server uses the generators to synthesize alarge corpus of trajectories and train a Global Generator (GG), enablingzero-shot inference via Monte Carlo simulation of future PHTs. We evaluate FTSon five clinically meaningful prediction tasks using MIMIC-IV data, showingthat models trained on synthetic data generated by GG perform comparably tothose trained on real data. FTS offers strong privacy guarantees, scalabilityacross institutions, and extensibility to diverse prediction and simulationtasks especially in healthcare, including counterfactual inference, earlywarning detection, and synthetic trial design.</description>
      <author>example@mail.com (Pawel Renc, Michal K. Grzeszczyk, Linglong Qian, Nassim Oufattole, Jeff Rasley, Arkadiusz Sitek)</author>
      <guid isPermaLink="false">2506.23358v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition</title>
      <link>http://arxiv.org/abs/2506.22836v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICME 2025 Oral&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了FOCUS方法，用于行人属性识别，通过自适应地提取每个属性的精细粒度特征，提高了性能和泛化能力。&lt;h4&gt;背景&lt;/h4&gt;行人属性识别是智能交通和安全的基石，现有方法主要依靠区域特征提取属性信息，但这种方法存在局限。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法中区域特征的局限性，提高属性识别的性能和实用性。&lt;h4&gt;方法&lt;/h4&gt;FOCUS方法通过以下步骤实现：1) 提出多粒度混合标记（MGMT）来捕捉不同视觉粒度级别的潜在特征；2) 引入属性引导的视觉特征提取（AVFE）模块，使用交叉注意力机制从混合标记中检索相应的视觉属性特征；3) 结合区域感知对比学习（RACL）方法，确保文本属性关注适当的混合标记。&lt;h4&gt;主要发现&lt;/h4&gt;FOCUS方法在PA100K、PETA和RAPv1数据集上进行了广泛的实验，证明了其有效性和强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;FOCUS方法在行人属性识别任务中具有显著的优势，为该领域的研究提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：行人属性识别（PAR）是智能交通和安全中的基本感知任务。为了应对这个细粒度任务，大多数现有方法侧重于提取区域特征以丰富属性信息。然而，在 这些方法中，区域特征通常用于预测一组预定义的属性，这在两个方面限制了性能和实用性：1）区域特征可能会以捕捉属性之间共享的通用特征为代价，牺牲了某些属性独有的精细粒度模式。2）区域特征无法泛化到测试时预测未见过的属性。在本文中，我们提出了用于PAR的FOCUS方法，该方法自适应地提取每个属性的属性级别的精细粒度特征，无论这些属性在训练期间是否被看到。具体来说，我们提出了多粒度混合标记（MGMT）来捕捉不同视觉粒度级别的潜在特征，从而丰富提取信息的多样性。接下来，我们引入了属性引导的视觉特征提取（AVFE）模块，该模块利用文本属性作为查询，使用交叉注意力机制从混合标记中检索相应的视觉属性特征。为了确保文本属性关注适当的混合标记，我们进一步结合了区域感知对比学习（RACL）方法，鼓励同一区域内的属性共享一致的注意力图。在PA100K、PETA和RAPv1数据集上进行的广泛实验证明了我们方法的有效性和强大的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pedestrian attribute recognition (PAR) is a fundamental perception task inintelligent transportation and security. To tackle this fine-grained task, mostexisting methods focus on extracting regional features to enrich attributeinformation. However, a regional feature is typically used to predict a fixedset of pre-defined attributes in these methods, which limits the performanceand practicality in two aspects: 1) Regional features may compromisefine-grained patterns unique to certain attributes in favor of capturing commoncharacteristics shared across attributes. 2) Regional features cannotgeneralize to predict unseen attributes in the test time. In this paper, wepropose the \textbf{F}ine-grained \textbf{O}ptimization with semanti\textbf{C}g\textbf{U}ided under\textbf{S}tanding (FOCUS) approach for PAR, whichadaptively extracts fine-grained attribute-level features for each attributeindividually, regardless of whether the attributes are seen or not duringtraining. Specifically, we propose the Multi-Granularity Mix Tokens (MGMT) tocapture latent features at varying levels of visual granularity, therebyenriching the diversity of the extracted information. Next, we introduce theAttribute-guided Visual Feature Extraction (AVFE) module, which leveragestextual attributes as queries to retrieve their corresponding visual attributefeatures from the Mix Tokens using a cross-attention mechanism. To ensure thattextual attributes focus on the appropriate Mix Tokens, we further incorporatea Region-Aware Contrastive Learning (RACL) method, encouraging attributeswithin the same region to share consistent attention maps. Extensiveexperiments on PA100K, PETA, and RAPv1 datasets demonstrate the effectivenessand strong generalization ability of our method.</description>
      <author>example@mail.com (Hongyan An, Kuan Zhu, Xin He, Haiyun Guo, Chaoyang Zhao, Ming Tang, Jinqiao Wang)</author>
      <guid isPermaLink="false">2506.22836v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>GATSim: Urban Mobility Simulation with Generative Agents</title>
      <link>http://arxiv.org/abs/2506.23306v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATSim的新型城市交通模拟框架，该框架利用大型语言模型和AI代理技术，创建了具有丰富行为特征和自适应学习机制的生成代理，以模拟城市交通。&lt;h4&gt;背景&lt;/h4&gt;传统的基于规则的城市交通模拟系统无法捕捉人类出行决策的复杂性、适应性和行为多样性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够模拟人类出行决策的智能代理系统。&lt;h4&gt;方法&lt;/h4&gt;GATSim框架结合了城市交通基础模型、代理认知系统和交通模拟环境，并实现了生成代理的全面架构。&lt;h4&gt;主要发现&lt;/h4&gt;GATSim代理具有多样化的社会经济属性、个人生活方式和不断发展的偏好，通过心理信息记忆系统、工具使用能力和终身学习机制来塑造其出行决策。生成代理能够将特定出行经验转化为一般性见解，并通过专门的活动规划和实时反应行为机制实现行为适应。&lt;h4&gt;结论&lt;/h4&gt;GATSim代理在模拟城市交通场景中表现出与人类标注者相当的性能，并自然产生宏观交通演变模式。&lt;h4&gt;翻译&lt;/h4&gt;摘要：传统的基于代理的城市交通模拟依赖于僵化的基于规则的系统，这些系统无法捕捉人类出行决策的复杂性、适应性和行为多样性。近年来，大型语言模型和AI代理技术的进步为创建具有推理能力、持久记忆和自适应学习机制的代理提供了机会。我们提出了GATSim（生成代理交通模拟）这一新颖框架，它利用这些进步来创建具有丰富行为特征的城市交通模拟生成代理。与传统的做法不同，GATSim代理具有多样化的社会经济属性、个人生活方式和不断发展的偏好，它们通过心理信息记忆系统、工具使用能力和终身学习机制来塑造其出行决策。本研究的主要贡献包括：（1）一个综合架构，结合了城市交通基础模型、代理认知系统和交通模拟环境；（2）一个功能齐全的原型实现；（3）系统验证表明，生成代理产生可信的出行行为。通过设计反思过程，本研究中的生成代理可以将特定的出行经验转化为一般性见解，通过专门的活动规划和针对城市交通环境的实时反应行为机制实现行为适应。实验表明，生成代理在模拟城市交通场景中的表现与人类标注者相当，并自然产生宏观交通演变模式。原型系统的代码可在https://github.com/qiliuchn/gatsim上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional agent-based urban mobility simulations rely on rigid rule-basedsystems that fail to capture the complexity, adaptability, and behavioraldiversity characteristic of human travel decision-making. Recent advances inlarge language models and AI agent technology offer opportunities to createagents with reasoning capabilities, persistent memory, and adaptive learningmechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novelframework that leverages these advances to create generative agents with richbehavioral characteristics for urban mobility simulation. Unlike conventionalapproaches, GATSim agents possess diverse socioeconomic attributes, individuallifestyles, and evolving preferences that shape their mobility decisionsthrough psychologically-informed memory systems, tool usage capabilities, andlifelong learning mechanisms. The main contributions of this study include: (1)a comprehensive architecture combining an urban mobility foundation model withagent cognitive systems and transport simulation environment, (2) a fullyfunctional prototype implementation, and (3) systematic validationdemonstrating that generative agents produce believable travel behaviors.Through designed reflection processes, generative agents in this study cantransform specific travel experiences into generalized insights, enablingrealistic behavioral adaptation over time with specialized mechanisms foractivity planning and real-time reactive behaviors tailored to urban mobilitycontexts. Experiments show that generative agents perform competitively withhuman annotators in mobility scenarios while naturally producing macroscopictraffic evolution patterns. The code for the prototype system is shared athttps://github.com/qiliuchn/gatsim.</description>
      <author>example@mail.com (Qi Liu, Can Li, Wanjing Ma)</author>
      <guid isPermaLink="false">2506.23306v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Task-Agnostic Contrastive Pretraining for Relational Deep Learning</title>
      <link>http://arxiv.org/abs/2506.22530v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  arXiv admin note: text overlap with arXiv:2506.22199&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的任务无关的对比预训练方法，用于关系深度学习（RDL），该方法通过表示关系数据库为异构图来直接从关系数据库中学习，旨在提高可扩展性和重用性。&lt;h4&gt;背景&lt;/h4&gt;现有的RDL模型通常依赖于特定任务的监督学习，需要为每个预测任务训练单独的模型，这可能会阻碍可扩展性和重用性。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够进行数据库范围表示学习的方法，以实现任务无关的对比预训练。&lt;h4&gt;方法&lt;/h4&gt;引入了行级、链接级和上下文级三种对比目标，以捕捉关系数据中固有的结构和语义异质性。通过模块化RDL架构和针对异构数据库设置的有效采样策略来实现预训练方法。&lt;h4&gt;主要发现&lt;/h4&gt;在标准RDL基准测试上的初步结果表明，微调预训练模型显著优于从头开始训练，验证了该方法在关系数据迁移学习表示中的潜力。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法在RDL领域具有提高可扩展性和重用性的潜力，并通过实验证明了其有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Relational Deep Learning (RDL) is an emerging paradigm that leverages GraphNeural Network principles to learn directly from relational databases byrepresenting them as heterogeneous graphs. However, existing RDL modelstypically rely on task-specific supervised learning, requiring trainingseparate models for each predictive task, which may hamper scalability andreuse.  In this work, we propose a novel task-agnostic contrastive pretrainingapproach for RDL that enables database-wide representation learning. For thataim, we introduce three levels of contrastive objectives$-$row-level,link-level, and context-level$-$designed to capture the structural and semanticheterogeneity inherent to relational data. We implement the respectivepretraining approach through a modular RDL architecture and an efficientsampling strategy tailored to the heterogeneous database setting. Ourpreliminary results on standard RDL benchmarks demonstrate that fine-tuning thepretrained models measurably outperforms training from scratch, validating thepromise of the proposed methodology in learning transferable representationsfor relational data.</description>
      <author>example@mail.com (Jakub Peleška, Gustav Šír)</author>
      <guid isPermaLink="false">2506.22530v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds</title>
      <link>http://arxiv.org/abs/2506.22749v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的联合几何和属性上采样（JGAU）方法，用于生成大规模和密集的彩色点云，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;彩色点云是三维应用中的一种主流表示形式，它包括几何和属性组件，能够实现真实感和沉浸感。&lt;h4&gt;目的&lt;/h4&gt;为了生成大规模和更密集的彩色点云，提出了一种新的深度学习方法。&lt;h4&gt;方法&lt;/h4&gt;1. 建立并发布了一个名为SYSU-PCUD的大规模彩色点云上采样数据集。2. 提出了一个基于深度学习的JGAU框架，该框架包括几何上采样网络和属性上采样网络。3. 提出了两种粗属性上采样方法：几何距离加权属性插值（GDWAI）和基于深度学习的属性插值（DLAI）。4. 引入了一个属性增强模块来细化上采样属性，并进一步利用内在属性和几何模式生成高质量点云。&lt;h4&gt;主要发现&lt;/h4&gt;JGAU方法在不同上采样率下（4倍、8倍、12倍和16倍）分别达到了33.90分贝、32.10分贝、31.10分贝和30.39分贝的峰值信噪比（PSNR），并且与现有方法相比，平均PSNR增益分别为2.32分贝、2.47分贝、2.28分贝和2.11分贝。&lt;h4&gt;结论&lt;/h4&gt;JGAU方法在彩色点云上采样方面取得了显著的改进，提高了点云的质量和分辨率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Colored point cloud, which includes geometry and attribute components, is amainstream representation enabling realistic and immersive 3D applications. Togenerate large-scale and denser colored point clouds, we propose a deeplearning-based Joint Geometry and Attribute Up-sampling (JGAU) method thatlearns to model both geometry and attribute patterns while leveraging spatialattribute correlations. First, we establish and release a large-scale datasetfor colored point cloud up-sampling called SYSU-PCUD, containing 121large-scale colored point clouds with diverse geometry and attributecomplexities across six categories and four sampling rates. Second, to improvethe quality of up-sampled point clouds, we propose a deep learning-based JGAUframework that jointly up-samples geometry and attributes. It consists of ageometry up-sampling network and an attribute up-sampling network, where thelatter leverages the up-sampled auxiliary geometry to model neighborhoodcorrelations of the attributes. Third, we propose two coarse attributeup-sampling methods, Geometric Distance Weighted Attribute Interpolation(GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generatecoarse up-sampled attributes for each point. Then, an attribute enhancementmodule is introduced to refine these up-sampled attributes and producehigh-quality point clouds by further exploiting intrinsic attribute andgeometry patterns. Extensive experiments show that the Peak Signal-to-NoiseRatio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10decibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times,8 times, 12 times, and 16 times, respectively. Compared to state-of-the-artmethods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28decibels, and 2.11 decibels at these four up-sampling rates, demonstratingsignificant improvement.</description>
      <author>example@mail.com (Yun Zhang, Feifan Chen, Na Li, Zhiwei Guo, Xu Wang, Fen Miao, Sam Kwong)</author>
      <guid isPermaLink="false">2506.22749v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation</title>
      <link>http://arxiv.org/abs/2506.23271v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Mettle的元-标记学习（Meta-Token Learning）方法，用于将大规模预训练的Transformer模型适应下游音频-视觉任务。&lt;h4&gt;背景&lt;/h4&gt;传统的Transformer模型在处理音频-视觉任务时，需要逐个修改模型的输出特征分布，这既复杂又低效。&lt;h4&gt;目的&lt;/h4&gt;提出一种简单且内存高效的元-标记学习方法，以适应大规模预训练的Transformer模型到音频-视觉任务。&lt;h4&gt;方法&lt;/h4&gt;Mettle使用一个轻量级的层中心蒸馏（Layer-Centric Distillation, LCD）模块，并行地将每个Transformer层嵌入的完整音频或视觉特征蒸馏成紧凑的元标记。此外，还引入了一个元标记注入（Meta-Token Injection, MTI）模块，用于引导早期层的特征适应。&lt;h4&gt;主要发现&lt;/h4&gt;Mettle方法在多个音频-视觉基准测试中显示出显著减少内存使用和训练时间，同时保持参数效率和具有竞争力的准确率。&lt;h4&gt;结论&lt;/h4&gt;Mettle是一种有效的音频-视觉任务适配方法，能够显著提高模型的性能和效率。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为Mettle的元-标记学习（Meta-Token Learning）方法，它是一种简单且内存高效的将大规模预训练的Transformer模型适应下游音频-视觉任务的方法。不同于逐个修改Transformer主干网络的输出特征分布，Mettle使用一个轻量级的层中心蒸馏（Layer-Centric Distillation, LCD）模块，并行地将每个Transformer层嵌入的完整音频或视觉特征蒸馏成紧凑的元标记。这一蒸馏过程既考虑了预训练知识的保留，也考虑了任务特定的适应。获得的元标记可以直接应用于分类任务，如音频-视觉事件定位和音频-视觉视频解析。为了进一步支持细粒度分割任务，如音频-视觉分割，我们引入了一个元标记注入（Meta-Token Injection, MTI）模块，该模块利用从顶层Transformer层蒸馏出的音频和视觉元标记来引导早期层的特征适应。在多个音频-视觉基准测试上的广泛实验表明，我们的方法在显著减少内存使用和训练时间的同时，保持了参数效率和具有竞争力的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present \textbf{Met}a-\textbf{T}oken \textbf{Le}arning (Mettle), a simpleand memory-efficient method for adapting large-scale pretrained transformermodels to downstream audio-visual tasks. Instead of sequentially modifying theoutput feature distribution of the transformer backbone, Mettle utilizes alightweight \textit{Layer-Centric Distillation (LCD)} module to distill inparallel the intact audio or visual features embedded by each transformer layerinto compact meta-tokens. This distillation process considers both pretrainedknowledge preservation and task-specific adaptation. The obtained meta-tokenscan be directly applied to classification tasks, such as audio-visual eventlocalization and audio-visual video parsing. To further support fine-grainedsegmentation tasks, such as audio-visual segmentation, we introduce a\textit{Meta-Token Injection (MTI)} module, which utilizes the audio and visualmeta-tokens distilled from the top transformer layer to guide featureadaptation in earlier layers. Extensive experiments on multiple audiovisualbenchmarks demonstrate that our method significantly reduces memory usage andtraining time while maintaining parameter efficiency and competitive accuracy.</description>
      <author>example@mail.com (Jinxing Zhou, Zhihui Li, Yongqiang Yu, Yanghao Zhou, Ruohao Guo, Guangyao Li, Yuxin Mao, Mingfei Han, Xiaojun Chang, Meng Wang)</author>
      <guid isPermaLink="false">2506.23271v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians</title>
      <link>http://arxiv.org/abs/2506.22718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种方法，用于从单个关节物体的观察点云序列中联合解决部件分割和运动估计问题。&lt;h4&gt;背景&lt;/h4&gt;部件分割和运动估计是关节物体运动分析的两个基本问题，而点云数据可能由于遮挡或多传感器异步测量等原因，导致无法通过追踪点对应关系来解决问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决上述问题，并提高部件分割的准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法使用一种紧凑而有效的表示，将物体建模为一系列3D高斯函数的简单构建块，并通过时间依赖的旋转、平移和缩放参数化这些高斯函数。&lt;h4&gt;主要发现&lt;/h4&gt;通过在观察到的点与高斯函数之间建立对应关系，实现了部件分割。同时，即使某些点未被观察到，也能通过追踪分配给该点的Gaussians的位姿来获得该点随时间的变化。&lt;h4&gt;结论&lt;/h4&gt;实验表明，该方法在仅依赖点对应关系的方法之上表现更优，并且对缺失点的鲁棒性更强，在具有遮挡的挑战性数据集上，部件分割性能比最先进的方法高出13%。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种从单个关节物体的观察点云序列中联合解决部件分割和运动估计问题的方法。该方法通过将物体建模为一系列3D高斯函数的简单构建块，并通过时间依赖的旋转、平移和缩放参数化这些高斯函数，实现了部件分割。实验结果表明，该方法在仅依赖点对应关系的方法之上表现更优，并且对缺失点的鲁棒性更强，在具有遮挡的挑战性数据集上，部件分割性能比最先进的方法高出13%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Part segmentation and motion estimation are two fundamental problems forarticulated object motion analysis. In this paper, we present a method to solvethese two problems jointly from a sequence of observed point clouds of a singlearticulated object. The main challenge in our problem setting is that the pointclouds are not assumed to be generated by a fixed set of moving points.Instead, each point cloud in the sequence could be an arbitrary sampling of theobject surface at that particular time step. Such scenarios occur when theobject undergoes major occlusions, or if the dataset is collected usingmeasurements from multiple sensors asynchronously. In these scenarios, methodsthat rely on tracking point correspondences are not appropriate. We present analternative approach based on a compact but effective representation where werepresent the object as a collection of simple building blocks modeled as 3DGaussians. We parameterize the Gaussians with time-dependent rotations,translations, and scales that are shared across all time steps. With ourrepresentation, part segmentation can be achieved by building correspondencesbetween the observed points and the Gaussians. Moreover, the transformation ofeach point across time can be obtained by following the poses of the assignedGaussian (even when the point is not observed). Experiments show that ourmethod outperforms existing methods that solely rely on finding pointcorrespondences. Additionally, we extend existing datasets to emulatereal-world scenarios by considering viewpoint occlusions. We furtherdemonstrate that our method is more robust to missing points as compared toexisting approaches on these challenging datasets, even when some parts arecompletely occluded in some time-steps. Notably, our part segmentationperformance outperforms the state-of-the-art method by 13% on point clouds withocclusions.</description>
      <author>example@mail.com (Jun-Jee Chao, Qingyuan Jiang, Volkan Isler)</author>
      <guid isPermaLink="false">2506.22718v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval</title>
      <link>http://arxiv.org/abs/2506.23132v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  to appear at AVSS'25&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了艺术剽窃检测问题，通过构建数据集和改进模型来识别和解释剽窃作品。&lt;h4&gt;背景&lt;/h4&gt;艺术剽窃检测对于保护艺术家版权和知识产权至关重要，但在法医分析中仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;识别剽窃画作并解释检测到的剽窃，通过检索视觉上相似的真实艺术品来实现。&lt;h4&gt;方法&lt;/h4&gt;构建了一个数据集，收集画作照片并使用生成式AI合成剽窃版本。使用DINOv2视觉基础模型作为基线方法，通过设置相似度阈值来识别剽窃。通过度量学习损失微调DINOv2模型，以提高检索质量。&lt;h4&gt;主要发现&lt;/h4&gt;基线方法实现了97.2%的识别准确率，但检索精度低（平均精度AP为29.0%）。微调后的模型在检索性能上提高了12%的AP，但识别准确率下降到92.7%。&lt;h4&gt;结论&lt;/h4&gt;本文提出了艺术剽窃检测的新方法，并通过实验验证了其有效性，为未来研究指明了方向。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了艺术剽窃检测问题，通过构建数据集和改进模型来识别和解释剽窃作品。在法医分析中，艺术剽窃检测对于保护艺术家版权和知识产权至关重要，但仍然是一个挑战。本文旨在识别剽窃画作并解释检测到的剽窃，通过检索视觉上相似的真实艺术品来实现。为了支持这一研究，构建了一个数据集，收集画作照片并使用生成式AI合成剽窃版本。基线方法采用DINOv2视觉基础模型，通过设置相似度阈值来识别剽窃。为了提高检索质量，使用度量学习损失对DINOv2模型进行微调。实验结果表明，基线方法实现了97.2%的识别准确率，但检索精度低（平均精度AP为29.0%）。微调后的模型在检索性能上提高了12%的AP，但识别准确率下降到92.7%。本文通过富有洞察力的讨论，并概述了未来研究的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Art plagiarism detection plays a crucial role in protecting artists'copyrights and intellectual property, yet it remains a challenging problem inforensic analysis. In this paper, we address the task of recognizingplagiarized paintings and explaining the detected plagarisms by retrievingvisually similar authentic artworks. To support this study, we construct adataset by collecting painting photos and synthesizing plagiarized versionsusing generative AI, tailored to specific artists' styles. We first establish abaseline approach using off-the-shelf features from the visual foundation modelDINOv2 to retrieve the most similar images in the database and classifyplagiarism based on a similarity threshold. Surprisingly, this non-learnedmethod achieves a high recognition accuracy of 97.2\% but suffers from lowretrieval precision 29.0\% average precision (AP). To improve retrievalquality, we finetune DINOv2 with a metric learning loss using positive andnegative sample pairs sampled in the database. The finetuned model greatlyimproves retrieval performance by 12\% AP over the baseline, though itunexpectedly results in a lower recognition accuracy (92.7\%). We conclude withinsightful discussions and outline directions for future research.</description>
      <author>example@mail.com (Sophie Zhou, Shu Kong)</author>
      <guid isPermaLink="false">2506.23132v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy</title>
      <link>http://arxiv.org/abs/2506.23123v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Stanford University PhD Dissertation of Rishi Bommasani (Department  of Computer Science, 2025). Also available at  https://purl.stanford.edu/zf669yy0336&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了人工智能时代技术与社会共演的现象，通过三个主题展开论述：基础模型的能力、风险和供应链；通过模型级和机构级评估创建的透明度；以及从理解到行动的转变，以提升对基础模型社会影响的了解，从而推动基于证据的人工智能政策。&lt;h4&gt;背景&lt;/h4&gt;人工智能被视为人类最有希望的技术，但同时也引发了困惑和担忧，因为基础模型的理解不足且可能带来广泛危害。&lt;h4&gt;目的&lt;/h4&gt;解释人工智能时代技术与社会共演的现象，并探讨如何通过建立科学基础和研究政策接口来改善人工智能治理。&lt;h4&gt;方法&lt;/h4&gt;通过概念框架、实证洞察和从理解到行动的转变三个主题来组织论述。&lt;h4&gt;主要发现&lt;/h4&gt;基础模型在更广泛的经济体中的能力、风险和供应链；通过模型级和机构级评估实现的透明度；以及提升对基础模型社会影响的了解以推动基于证据的人工智能政策。&lt;h4&gt;结论&lt;/h4&gt;本文为在人工智能时代实现更好的社会成果提供了科学基础和研究政策接口，有助于改善人工智能治理。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial intelligence is humanity's most promising technology because ofthe remarkable capabilities offered by foundation models. Yet, the sametechnology brings confusion and consternation: foundation models are poorlyunderstood and they may precipitate a wide array of harms. This dissertationexplains how technology and society coevolve in the age of AI, organized aroundthree themes. First, the conceptual framing: the capabilities, risks, and thesupply chain that grounds foundation models in the broader economy. Second, theempirical insights that enrich the conceptual foundations: transparency createdvia evaluations at the model level and indexes at the organization level.Finally, the transition from understanding to action: superior understanding ofthe societal impact of foundation models advances evidence-based AI policy.View together, this dissertation makes inroads into achieving better societaloutcomes in the age of AI by building the scientific foundations andresearch-policy interface required for better AI governance.</description>
      <author>example@mail.com (Rishi Bommasani)</author>
      <guid isPermaLink="false">2506.23123v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages</title>
      <link>http://arxiv.org/abs/2506.22529v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Misinfo-TeleGraph，这是一个用于虚假信息检测的德语Telegram图数据集，包含超过500万条消息，并进行了元数据、频道关系和弱标签与强标签的丰富。通过评估文本模型和图神经网络，研究发现GraphSAGE与LSTM聚合在MCC和F1-score上显著优于文本模型。此外，研究了订阅者、观看次数和标签类型对性能的影响，并强调了弱监督在此领域的潜力和挑战。&lt;h4&gt;背景&lt;/h4&gt;连接性和信息传播在虚假信息检测中是关键信息来源，但在Telegram等平台上的应用不足。&lt;h4&gt;目的&lt;/h4&gt;建立Misinfo-TeleGraph数据集，并评估其在虚假信息检测中的性能。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含5百万条消息的图数据集，使用M3-embeddings和手动标注进行标签，评估了文本模型和图神经网络。&lt;h4&gt;主要发现&lt;/h4&gt;GraphSAGE与LSTM聚合在MCC和F1-score上优于文本模型，并探讨了弱监督的影响。&lt;h4&gt;结论&lt;/h4&gt;Misinfo-TeleGraph为德语Telegram网络和其他低监管社交平台上的虚假信息检测提供了可复现的基准和开放数据集。&lt;h4&gt;翻译&lt;/h4&gt;摘要：连接性和信息传播是虚假信息检测的核心，但在Telegram等平台上的应用往往不足。本文介绍了Misinfo-TeleGraph，这是第一个用于虚假信息检测的德语Telegram图数据集，包含超过500万条消息，并丰富了元数据、频道关系和弱标签与强标签。通过评估文本模型和图神经网络，我们发现GraphSAGE与LSTM聚合在MCC和F1-score上显著优于文本模型。此外，我们还评估了订阅者、观看次数和自动与人工创建的标签对性能的影响，并强调了弱监督在此领域的潜力和挑战。这项工作为德语Telegram网络和其他低监管社交平台上的虚假信息检测提供了可复现的基准和开放数据集。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Connectivity and message propagation are central, yet often underutilized,sources of information in misinformation detection -- especially on poorlymoderated platforms such as Telegram, which has become a critical channel formisinformation dissemination, namely in the German electoral context. In thispaper, we introduce Misinfo-TeleGraph, the first German-language Telegram-basedgraph dataset for misinformation detection. It includes over 5 million messagesfrom public channels, enriched with metadata, channel relationships, and bothweak and strong labels. These labels are derived via semantic similarity tofact-checks and news articles using M3-embeddings, as well as manualannotation. To establish reproducible baselines, we evaluate both text-onlymodels and graph neural networks (GNNs) that incorporate message forwarding asa network structure. Our results show that GraphSAGE with LSTM aggregationsignificantly outperforms text-only baselines in terms of Matthews CorrelationCoefficient (MCC) and F1-score. We further evaluate the impact of subscribers,view counts, and automatically versus human-created labels on performance, andhighlight both the potential and challenges of weak supervision in this domain.This work provides a reproducible benchmark and open dataset for futureresearch on misinformation detection in German-language Telegram networks andother low-moderation social platforms.</description>
      <author>example@mail.com (Lu Kalkbrenner, Veronika Solopova, Steffen Zeiler, Robert Nickel, Dorothea Kolossa)</author>
      <guid isPermaLink="false">2506.22529v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding</title>
      <link>http://arxiv.org/abs/2506.23075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了CSBrain，一种用于跨尺度时空脑活动解码的基础模型，旨在提高EEG信号解码的泛化能力。&lt;h4&gt;背景&lt;/h4&gt;EEG信号解码是神经科学和人工智能领域的基本挑战，应用包括认知、情感识别、诊断和脑-机接口。&lt;h4&gt;目的&lt;/h4&gt;提出CSBrain模型，以解决现有EEG基础模型忽视神经活动跨尺度时空结构的问题，从而提高解码效果。&lt;h4&gt;方法&lt;/h4&gt;CSBrain模型引入了跨尺度时空标记（CST）和结构化稀疏注意力（SSA）机制。CST用于将多尺度特征聚合为紧凑的尺度感知标记，而SSA用于捕捉跨窗口和跨区域的依赖关系，增强尺度多样性并去除虚假相关性。&lt;h4&gt;主要发现&lt;/h4&gt;在11个EEG任务和16个数据集上的实验表明，CSBrain在性能上优于特定任务和基础模型基线，证明了跨尺度建模的重要性。&lt;h4&gt;结论&lt;/h4&gt;CSBrain作为一种鲁棒的基础模型，对于未来的脑-机接口研究具有重要意义，并建立了跨尺度建模作为关键归纳偏置的地位。&lt;h4&gt;翻译&lt;/h4&gt;Understanding and decoding brain activity from electroencephalography (EEG) signals is a fundamental challenge in neuroscience and AI, with applications in cognition, emotion recognition, diagnosis, and brain-computer interfaces. While recent EEG foundation models advance generalized decoding via unified architectures and large-scale pretraining, they adopt a scale-agnostic dense modeling paradigm inherited from NLP and vision. This design neglects a core property of neural activity: cross-scale spatiotemporal structure. EEG task patterns span a wide range of temporal and spatial scales, from short bursts to slow rhythms, and from localized cortical responses to distributed interactions. Ignoring this diversity leads to suboptimal representations and weak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain foundation model for generalized EEG decoding. CSBrain introduces: (i) Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale features from localized temporal windows and anatomical brain regions into compact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which captures cross-window and cross-region dependencies, enhancing scale diversity while removing spurious correlations. CST and SSA are alternately stacked to progressively integrate multi-scale dependencies. Experiments on 11 EEG tasks across 16 datasets show that CSBrain consistently outperforms task-specific and foundation model baselines. These results establish cross-scale modeling as a key inductive bias and position CSBrain as a robust backbone for future brain-AI research.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-29&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and decoding brain activity from electroencephalography (EEG)signals is a fundamental challenge in neuroscience and AI, with applications incognition, emotion recognition, diagnosis, and brain-computer interfaces. Whilerecent EEG foundation models advance generalized decoding via unifiedarchitectures and large-scale pretraining, they adopt a scale-agnostic densemodeling paradigm inherited from NLP and vision. This design neglects a coreproperty of neural activity: cross-scale spatiotemporal structure. EEG taskpatterns span a wide range of temporal and spatial scales, from short bursts toslow rhythms, and from localized cortical responses to distributedinteractions. Ignoring this diversity leads to suboptimal representations andweak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brainfoundation model for generalized EEG decoding. CSBrain introduces: (i)Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scalefeatures from localized temporal windows and anatomical brain regions intocompact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), whichcaptures cross-window and cross-region dependencies, enhancing scale diversitywhile removing spurious correlations. CST and SSA are alternately stacked toprogressively integrate multi-scale dependencies. Experiments on 11 EEG tasksacross 16 datasets show that CSBrain consistently outperforms task-specific andfoundation model baselines. These results establish cross-scale modeling as akey inductive bias and position CSBrain as a robust backbone for futurebrain-AI research.</description>
      <author>example@mail.com (Yuchen Zhou, Jiamin Wu, Zichen Ren, Zhouheng Yao, Weiheng Lu, Kunyu Peng, Qihao Zheng, Chunfeng Song, Wanli Ouyang, Chao Gou)</author>
      <guid isPermaLink="false">2506.23075v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>The Hidden Link Between RLHF and Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.22578v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了大型语言模型（LLMs）与人类价值观的契合问题，探讨了RLHF和DPO两种方法，并揭示了它们与对比学习的深刻联系。&lt;h4&gt;背景&lt;/h4&gt;近期，LLMs与人类价值观的契合问题受到广泛关注，其中RLHF和DPO是两个典型的例子。&lt;h4&gt;目的&lt;/h4&gt;本文旨在通过分析RLHF和DPO，揭示它们与对比学习的关系，并提出一种新的方法来优化LLMs。&lt;h4&gt;方法&lt;/h4&gt;本文从互信息（MI）最大化的角度解释了RLHF和DPO，并基于此提出了 Mutual Information Optimization (MIO) 方法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，RLHF和DPO可以看作是基于正负样本的对比学习方法，并利用了Donsker-Varadhan (DV) 下界来优化互信息。&lt;h4&gt;结论&lt;/h4&gt;MIO方法可以有效缓解DPO中观察到的选择似然率晚期下降问题，并在多个推理和数学基准测试中表现出竞争力或优越性。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the alignment of large language models (LLMs) with human values, discusses two methods: RLHF and DPO, and reveals their profound connection to contrastive learning. This study aims to analyze RLHF and DPO to reveal their relationship with contrastive learning and proposes a new method to optimize LLMs. The study finds that RLHF and DPO can be regarded as contrastive learning methods based on positive and negative samples, and utilizes the Donsker-Varadhan (DV) lower bound to optimize mutual information. The Mutual Information Optimization (MIO) method can effectively mitigate the late-stage decline in the selected likelihood observed in DPO, achieving competitive or superior performance across various challenging reasoning and mathematical benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Alignment of large language models (LLMs) with human values has recentlygarnered significant attention, with prominent examples including the canonicalyet costly Reinforcement Learning from Human Feedback (RLHF) and the simpleDirect Preference Optimization (DPO). In this work, we demonstrate that bothRLHF and DPO can be interpreted from the perspective of mutual information (MI)maximization, uncovering a profound connection to contrastive learning. Withinthis framework, both RLHF and DPO can be viewed as methods that performcontrastive learning based on the positive and negative samples derived fromthe base model, leveraging the Donsker-Varadhan (DV) lower bound on MI(equivalently, the MINE estimator). This paradigm further explains why RLHF maynot intrinsically incentivize reasoning capacities in LLMs beyond what isalready present in the base model. Building on this perspective, we replace theDV/MINE bound with the Jensen-Shannon MI estimator and propose MutualInformation Optimization (MIO). Comprehensive theoretical analysis andextensive empirical evaluations demonstrate that MIO mitigates the late-stagedecline in chosen-likelihood observed in DPO, achieving competitive or superiorperformance across various challenging reasoning and mathematical benchmarks.We will release the model and code upon acceptance.</description>
      <author>example@mail.com (Xufei Lv, Haoyuan Sun, Xuefeng Bai, Min Zhang, Houde Liu, Kehai Chen)</author>
      <guid isPermaLink="false">2506.22578v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>The Missing Link: Joint Legal Citation Prediction using Heterogeneous Graph Enrichment</title>
      <link>http://arxiv.org/abs/2506.22165v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络（GNN）的链接预测模型，用于识别法律案例和法律规范之间的引用关系，并通过融合语义和拓扑信息提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;法律体系高度依赖法律规范和先前的法院判决的交叉引用。法律从业者、新手和法律AI系统需要访问这些相关数据来进行评估和判断。&lt;h4&gt;目的&lt;/h4&gt;提高案例和法律规范引用的预测准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种融合语义和拓扑信息的GNN链接预测模型，使用适应的图卷积操作在扩展和丰富版本的原始引用图上运行，以实现语义元信息的拓扑整合。&lt;h4&gt;主要发现&lt;/h4&gt;该模型通过整合语义和拓扑信息，平均精度提高了3.1点，在数据稀疏性方面提高了8.5点，并在时间上和具有挑战性的全归纳预测中表现出鲁棒性能。联合学习和预测案例和规范引用实现了显著的协同效应，使案例引用预测提高了4.7点，效率几乎翻倍。&lt;h4&gt;结论&lt;/h4&gt;本文提出的GNN模型在提高法律案例和法律规范引用预测准确性方面是有效的，并且具有更高的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Legal systems heavily rely on cross-citations of legal norms as well asprevious court decisions. Practitioners, novices and legal AI systems needaccess to these relevant data to inform appraisals and judgments. We propose aGraph-Neural-Network (GNN) link prediction model that can identify Case-Law andCase-Case citations with high proficiency through fusion of semantic andtopological information. We introduce adapted relational graph convolutionsoperating on an extended and enriched version of the original citation graphthat allow the topological integration of semantic meta-information. Thisfurther improves prediction by 3.1 points of average precision and by 8.5points in data sparsity as well as showing robust performance over time and inchallenging fully inductive prediction. Jointly learning and predicting caseand norm citations achieves a large synergistic effect that improves casecitation prediction by up to 4.7 points, at almost doubled efficiency.</description>
      <author>example@mail.com (Lorenz Wendlinger, Simon Alexander Nonn, Abdullah Al Zubaer, Michael Granitzer)</author>
      <guid isPermaLink="false">2506.22165v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation</title>
      <link>http://arxiv.org/abs/2506.22827v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at the RSS 2025 Workshop on Robot Planning in the Era of  Foundation Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种分层规划和控制框架，旨在实现可靠的多步人形机器人操作。&lt;h4&gt;背景&lt;/h4&gt;可靠执行复杂多步操作对于人形机器人在工业和家庭环境中的有效部署至关重要。&lt;h4&gt;目的&lt;/h4&gt;设计一个分层规划和控制框架，以实现可靠的多步人形机器人操作。&lt;h4&gt;方法&lt;/h4&gt;该系统包括三个层次：(1) 负责跟踪全身运动目标的低级基于强化学习的控制器；(2) 通过模仿学习训练的技能策略，为任务的各个步骤生成运动目标；(3) 决定应该执行哪些技能并实时监控其完成情况的高级视觉-语言规划模块，使用预训练的视觉-语言模型（VLMs）。&lt;h4&gt;主要发现&lt;/h4&gt;在Unitree G1人形机器人上执行非抓取式捡起和放置任务时，经过40次真实世界试验，分层系统在完成整个操作序列中达到了72.5%的成功率。&lt;h4&gt;结论&lt;/h4&gt;这些实验证实了所提出的分层系统的可行性，突出了基于VLM的技能规划和监控在多步操作场景中的优势。&lt;h4&gt;翻译&lt;/h4&gt;摘要：使人形机器人能够可靠地执行复杂的多步操作对于它们在工业和家庭环境中的有效部署至关重要。本文提出了一种旨在实现可靠多步人形机器人操作的分层规划和控制框架。所提出的系统包括三个层次：(1) 负责跟踪全身运动目标的基于强化学习的低级控制器；(2) 通过模仿学习训练的技能策略，为任务的各个步骤生成运动目标；(3) 决定应该执行哪些技能并实时监控其完成情况的高级视觉-语言规划模块，使用预训练的视觉-语言模型（VLMs）。在Unitree G1人形机器人上执行非抓取式捡起和放置任务时，经过40次真实世界试验，分层系统在完成整个操作序列中达到了72.5%的成功率。这些实验证实了所提出的分层系统的可行性，突出了基于VLM的技能规划和监控在多步操作场景中的优势。更多信息请见https://vlp-humanoid.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Enabling humanoid robots to reliably execute complex multi-step manipulationtasks is crucial for their effective deployment in industrial and householdenvironments. This paper presents a hierarchical planning and control frameworkdesigned to achieve reliable multi-step humanoid manipulation. The proposedsystem comprises three layers: (1) a low-level RL-based controller responsiblefor tracking whole-body motion targets; (2) a mid-level set of skill policiestrained via imitation learning that produce motion targets for different stepsof a task; and (3) a high-level vision-language planning module that determineswhich skills should be executed and also monitors their completion in real-timeusing pretrained vision-language models (VLMs). Experimental validation isperformed on a Unitree G1 humanoid robot executing a non-prehensilepick-and-place task. Over 40 real-world trials, the hierarchical systemachieved a 72.5% success rate in completing the full manipulation sequence.These experiments confirm the feasibility of the proposed hierarchical system,highlighting the benefits of VLM-based skill planning and monitoring formulti-step manipulation scenarios. See https://vlp-humanoid.github.io/ forvideo demonstrations of the policy rollout.</description>
      <author>example@mail.com (André Schakkal, Ben Zandonati, Zhutian Yang, Navid Azizan)</author>
      <guid isPermaLink="false">2506.22827v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Learning Distributed Safe Multi-Agent Navigation via Infinite-Horizon Optimal Graph Control</title>
      <link>http://arxiv.org/abs/2506.22117v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对分布式多智能体导航的无限时域CBF约束最优图控制公式，通过分析解结构，开发了一种基于HJB的学习框架来近似解，并通过实验验证了其有效性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;分布式多智能体导航在保持安全和实现目标导向行为方面面临挑战，尤其是在有限感知范围和密集障碍物未知环境中。&lt;h4&gt;目的&lt;/h4&gt;提出一种安全的多智能体导航方法，在保持安全的同时实现高效的目标导向行为。&lt;h4&gt;方法&lt;/h4&gt;开发了一种基于HJB和图神经网络（GNN）的学习框架，用于联合学习CBF、分布式控制策略和价值函数，并引入了Lagrange乘数的状态相关参数化，以实现安全和性能之间的动态权衡。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过长时域优化，能够主动避免死锁，在复杂环境中更有效地导航，并在各种智能体动力学中实现了安全性和任务成功率的显著提高。&lt;h4&gt;结论&lt;/h4&gt;该方法在现实世界的实验中得到了验证，证明了其可行性、通用性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：分布式多智能体导航由于在保持安全和实现目标导向行为方面的竞争性需求而面临固有的挑战，尤其是在有限感知范围和密集障碍物未知环境中运行的智能体。现有方法通常将预定义的目标到达控制器投影到控制障碍函数（CBF）约束上，通常导致安全和目标到达性能之间的保守和次优权衡。我们提出了一种无限时域CBF约束最优图控制公式，用于分布式安全多智能体导航。通过推导分析解结构，我们开发了一种基于Hamilton-Jacobi-Bellman（HJB）的学习框架来近似解。特别是，我们的算法联合学习了一个CBF和一个由图神经网络（GNN）参数化的分布式控制策略，以及一个价值函数，该价值函数稳健地引导智能体向其目标移动。此外，我们引入了Lagrange乘数的状态相关参数化，使安全和性能之间能够实现动态权衡。与传统的短时域、基于二次规划法的CBF方法不同，我们的方法利用长时域优化来主动避免死锁，并更有效地在复杂环境中导航。广泛的仿真结果表明，在各种智能体动力学中，安全性和任务成功率都得到了显著提高，并且在以前未见过的环境中具有强大的可扩展性和泛化能力。使用Crazyflie无人机群在具有挑战性的反极位置交换任务中的现实世界实验进一步验证了所提出的HJB-GNN学习框架的实用性、通用性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Distributed multi-agent navigation faces inherent challenges due to thecompeting requirements of maintaining safety and achieving goal-directedbehavior, particularly for agents with limited sensing range operating inunknown environments with dense obstacles. Existing approaches typicallyproject predefined goal-reaching controllers onto control barrier function(CBF) constraints, often resulting in conservative and suboptimal trade-offsbetween safety and goal-reaching performance. We propose an infinite-horizonCBF-constrained optimal graph control formulation for distributed safemulti-agent navigation. By deriving the analytical solution structure, wedevelop a novel Hamilton-Jacobi-Bellman (HJB)-based learning framework toapproximate the solution. In particular, our algorithm jointly learns a CBF anda distributed control policy, both parameterized by graph neural networks(GNNs), along with a value function that robustly guides agents toward theirgoals. Moreover, we introduce a state-dependent parameterization of Lagrangemultipliers, enabling dynamic trade-offs between safety and performance. Unliketraditional short-horizon, quadratic programming-based CBF methods, ourapproach leverages long-horizon optimization to proactively avoid deadlocks andnavigate complex environments more effectively. Extensive simulation resultsdemonstrate substantial improvements in safety and task success rates acrossvarious agent dynamics, with strong scalability and generalization tolarge-scale teams in previously unseen environments. Real-world experimentsusing Crazyflie drone swarms on challenging antipodal position-swapping tasksfurther validate the practicality, generalizability, and robustness of theproposed HJB-GNN learning framework.</description>
      <author>example@mail.com (Fenglan Wang, Xinguo Shu, Lei He, Lin Zhao)</author>
      <guid isPermaLink="false">2506.22117v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs</title>
      <link>http://arxiv.org/abs/2506.22694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 4 figures, 5 tables, accepted at ICML 2025 workshop on  Efficient Systems for Foundational Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种无需训练的技术，旨在提高基于绘图员的推测解码（SpD）方法的性能，该方法在绘图过程中结合了语言模型头（LM头）。&lt;h4&gt;背景&lt;/h4&gt;基于绘图员的推测解码利用一个或多个较小的语言模型（称为绘图员或绘图模型）来采样一个由多个标记组成的草稿序列或树，随后由基础LLM、目标模型验证接受其子集作为有效生成。&lt;h4&gt;目的&lt;/h4&gt;识别并减少推测解码过程中草稿采样方案中的不必要的推理开销，特别是对于具有非常大词汇量的目标LLM。&lt;h4&gt;方法&lt;/h4&gt;提出了VocabTrim技术，通过限制绘图过程中的词汇量，只包含目标模型词汇中采样频率最高的有限标记集合，从而减少草稿的延迟。&lt;h4&gt;主要发现&lt;/h4&gt;VocabTrim技术稍微降低了接受率，但显著减少了内存受限过程中的草稿延迟，从而在内存受限环境中提高了内存加速比（MBSU）。&lt;h4&gt;结论&lt;/h4&gt;该方法能够提高Spec-Bench上Llama-3模型的内存加速比，特别是Llama-3.2-3B-Instruct模型，提高了16%。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种无需训练的技术，旨在提高基于绘图员的推测解码（SpD）方法的性能，该方法在绘图过程中结合了语言模型头（LM头）。基于绘图员的推测解码利用一个或多个较小的语言模型（称为绘图员或绘图模型）来采样一个由多个标记组成的草稿序列或树，随后由基础LLM、目标模型验证接受其子集作为有效生成。通常认为，推测解码需要目标模型和绘图模型的词汇表之间存在一对一的映射，因此自然地倾向于共享词汇量，甚至像EAGLE或Medusa那样共享LM头。我们首先识别出这种草稿标记采样方案在绘图过程中固有地包含不必要的推理开销，特别是对于一些具有非常大词汇量的目标LLM。然后，我们提出了一种简单的技术，称为VocabTrim，通过限制绘图过程中的词汇量，只包含目标模型词汇中采样频率最高的有限标记集合，从而减少草稿的延迟。虽然限制词汇量稍微降低了接受率，但它显著减少了内存受限过程中的草稿延迟，这在边缘设备上通常是常见的情况，从而导致了更高的内存加速比（MBSU）。我们发现，我们的方法可以提升Spec-Bench上Llama-3模型的内存加速比，特别是对于Llama-3.2-3B-Instruct模型，提高了16%。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-28&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we introduce a simple training-free technique to improve theperformance of drafter-based speculative decoding (SpD) methods thatincorporates language modeling head (LM head) during drafting process. Adrafter-based speculative decoding leverages one or more smaller languagemodels, a.k.a. drafters or draft models, to sample a draft sequence or treeconsisting of multiple tokens, followed by verification by a base LLM, a targetmodel, accepting a subset as its valid generation. As it is usually consideredthat the speculative decoding requires one-to-one mapping between vocabulariesof the target model and the draft model, it has been natural to share thevocabulary between them, or even share the LM head as in EAGLE or Medusa. Wefirst identify that this draft token sampling scheme inherently contains anunnecessary inference overhead in drafting, especially for some target LLMswith very large vocabularies. Then, we propose a simple technique, VocabTrim,to mitigate the drafting overhead to improve the generation speed inmemory-bound environment. VocabTrim reconstructs the drafter LM head to containonly a limited set of tokens, selected by the most frequently sampled from thevocabulary of the target model. While limiting the vocabulary in draftingslightly degrades the acceptance rate, it significantly reduces the draftinglatency in memory-bound process which is often the case on edge devices,resulting in higher memory-bound speed up (MBSU). We show that our method canboost the memory-bound speed-up for Llama-3 models on Spec-Bench, specificallyby 16% for Llama-3.2-3B-Instruct.</description>
      <author>example@mail.com (Raghavv Goel, Sudhanshu Agrawal, Mukul Gagrani, Junyoung Park, Yifan Zao, He Zhang, Tian Liu, Yiping Yang, Xin Yuan, Jiuyan Lu, Chris Lott, Mingu Lee)</author>
      <guid isPermaLink="false">2506.22694v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation</title>
      <link>http://arxiv.org/abs/2506.22567v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MMKD-CLIP是一种通过多医学CLIP知识蒸馏方法开发的通用生物医学基础模型，它在多个生物医学数据集上表现出色。&lt;h4&gt;背景&lt;/h4&gt;尽管CLIP模型在零样本分类、跨模态检索和开放视觉问答方面表现出色，但在生物医学领域应用受到大规模生物医学图像-文本语料库稀缺、图像模态异质性和数据标准不统一等限制。&lt;h4&gt;目的&lt;/h4&gt;开发一个统一且可泛化的从零开始训练的生物医学基础模型。&lt;h4&gt;方法&lt;/h4&gt;MMKD-CLIP通过知识蒸馏从九个预训练在数百万生物医学图像-文本对上的生物医学CLIP模型中提取知识，而不是依赖于亿级原始数据。其两阶段训练流程包括在超过290万个生物医学图像-文本对上进行CLIP风格的预训练，以及使用从教师模型中提取的超过1920万个特征对进行特征级蒸馏。&lt;h4&gt;主要发现&lt;/h4&gt;MMKD-CLIP在58个多样化的生物医学数据集上进行了评估，涵盖了超过1080万个来自九种图像模态的生物医学图像。评估涵盖了六个核心任务类型：零样本分类、线性探测、跨模态检索、视觉问答、生存预测和癌症诊断。MMKD-CLIP在所有教师模型中表现最佳，并在图像域和任务设置上显示出显著的鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;多教师知识蒸馏是在现实世界数据可用性限制下构建高性能生物医学基础模型的可扩展且有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; CLIP models pretrained on natural images with billion-scale image-text pairshave demonstrated impressive capabilities in zero-shot classification,cross-modal retrieval, and open-ended visual answering. However, transferringthis success to biomedicine is hindered by the scarcity of large-scalebiomedical image-text corpora, the heterogeneity of image modalities, andfragmented data standards across institutions. These limitations hinder thedevelopment of a unified and generalizable biomedical foundation model trainedfrom scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedicalfoundation model developed via Multiple Medical CLIP Knowledge Distillation.Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledgefrom nine state-of-the-art domain-specific or generalist biomedical CLIPmodels, each pretrained on millions of biomedical image-text pairs. Ourtwo-stage training pipeline first performs CLIP-style pretraining on over 2.9million biomedical image-text pairs from 26 image modalities, followed byfeature-level distillation using over 19.2 million feature pairs extracted fromteacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets,encompassing over 10.8 million biomedical images across nine image modalities.The evaluation spans six core task types: zero-shot classification, linearprobing, cross-modal retrieval, visual question answering, survival prediction,and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher modelswhile demonstrating remarkable robustness and generalization across imagedomains and task settings. These results underscore that multi-teacherknowledge distillation is a scalable and effective paradigm for buildinghigh-performing biomedical foundation models under the practical constraints ofreal-world data availability.</description>
      <author>example@mail.com (Shansong Wang, Zhecheng Jin, Mingzhe Hu, Mojtaba Safari, Feng Zhao, Chih-Wei Chang, Richard LJ Qiu, Justin Roper, David S. Yu, Xiaofeng Yang)</author>
      <guid isPermaLink="false">2506.22567v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Learning-Based Hybrid Neural Receiver for 6G-V2X Communications</title>
      <link>http://arxiv.org/abs/2506.21983v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于Transformer编码块和图神经网络（GNN）的混合神经网络接收器（H-NR），用于优化无线接收器的多个功能。&lt;h4&gt;背景&lt;/h4&gt;目前尚未有综合接收模型能够替代物理层所有模块。&lt;h4&gt;目的&lt;/h4&gt;构建一个端到端的无线通信框架，并在车辆到网络（V2N）上行链路场景中应用。&lt;h4&gt;方法&lt;/h4&gt;H-NR模型替代了OFDM资源网格解映射、信道估计、信号均衡、解调和信道解码等功能。评估了不同场景下的性能，包括车辆速度、载波频率和CDL信道模型。此外，还评估了模型在处理图像、音频、GPS、雷达和激光雷达等多模态数据时的性能。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果表明，所提出的模型在重建和纠错方面比现有的最佳神经网络接收器高出约0.5 dB。&lt;h4&gt;结论&lt;/h4&gt;H-NR模型在多种场景和模态数据上表现出优异的性能。&lt;h4&gt;翻译&lt;/h4&gt;Neural receiver models are proposed to jointly optimize multiple functionalities of wireless receivers; however, a comprehensive receiver model that replaces the entire physical layer blocks has not yet been presented in the literature. In this work, we introduce a novel hybrid neural receiver (H-NR) built on Transformer encoder blocks and Graph Neural Network (GNN), as part of an end-to-end wireless communication framework. In our communication framework, we assume vehicle to network (V2N) uplink scenario where information is transmitted by vehicle and received at the base station (BS). Our proposed H-NR model replace OFDM resource grid demapping, channel estimation, signal equalization, demodulation, and channel decoding. To test the adaptability of our proposed model on unseen conditions, we evaluate its performance for various scenarios, including a vehicle speed of range [0-60] km/h, a carrier frequency of 5.9GHz, and a cluster delay line (CDL) channel model. Furthermore, we assess the performance of our proposed H-NR on multimodal data, such as images, audio, GPS, radar, and LiDAR, to examine its adaptability in real-world use cases. The simulation results clearly demonstrate that our proposed model outperforms the state-of-the-art neural receiver by approximately 0.5 dB in terms of reconstruction and error correction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural receiver models are proposed to jointly optimize multiplefunctionalities of wireless receivers; however, a comprehensive receiver modelthat replaces the entire physical layer blocks has not yet been presented inthe literature. In this work, we introduce a novel hybrid neural receiver(H-NR) built on Transformer encoder blocks and Graph Neural Network (GNN), aspart of an end-to-end wireless communication framework. In our communicationframework, we assume vehicle to network (V2N) uplink scenario where informationis transmitted by vehicle and received at the base station (BS). Our proposedH-NR model replace OFDM resource grid demapping, channel estimation, signalequalization, demodulation, and channel decoding. To test the adaptability ofour proposed model on unseen conditions, we evaluate its performance forvarious scenarios, including a vehicle speed of range [0-60] km/h, a carrierfrequency of 5.9GHz, and a cluster delay line (CDL) channel model. Furthermore,we assess the performance of our proposed H-NR on multimodal data, such asimages, audio, GPS, radar, and LiDAR, to examine its adaptability in real-worlduse cases. The simulation results clearly demonstrate that our proposed modeloutperforms the state-of-the-art neural receiver by approximately 0.5 dB interms of reconstruction and error correction.</description>
      <author>example@mail.com (Osama Saleem, Mohammed Alfaqawi, Pierre Merdrignac, Abdelaziz Bensrhair, Soheyb Ribouh)</author>
      <guid isPermaLink="false">2506.21983v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?</title>
      <link>http://arxiv.org/abs/2506.22501v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in the 2025 IEEE International Geoscience and Remote Sensing  Symposium (IGARSS 2025), scheduled for 3 - 8 August 2025 in Brisbane,  Australia&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SpatialNet-ViT的新型模型，用于解决遥感数据分类任务，如土地利用分类、物体存在检测和城乡分类。该模型结合了视觉Transformer（ViT）和多任务学习（MTL）的优势，提高了分类准确性和可扩展性。&lt;h4&gt;背景&lt;/h4&gt;现有的遥感数据分类研究往往局限于特定的任务或数据集，限制了其泛化能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的模型，以解决遥感数据分类任务的泛化问题。&lt;h4&gt;方法&lt;/h4&gt;采用视觉Transformer（ViT）和多任务学习（MTL）技术，并结合数据增强、迁移学习和多任务学习等技术来增强模型的鲁棒性和泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;SpatialNet-ViT模型结合了空间意识和上下文理解，提高了分类准确性和可扩展性。&lt;h4&gt;结论&lt;/h4&gt;SpatialNet-ViT模型在遥感数据分类任务中具有良好的性能，能够有效提高分类准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;Remote sensing datasets offer significant promise for tackling key classification tasks such as land-use categorization, object presence detection, and rural/urban classification. However, many existing studies tend to focus on narrow tasks or datasets, which limits their ability to generalize across various remote sensing classification challenges. To overcome this, we propose a novel model, SpatialNet-ViT, leveraging the power of Vision Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach combines spatial awareness with contextual understanding, improving both classification accuracy and scalability. Additionally, techniques like data augmentation, transfer learning, and multi-task learning are employed to enhance model robustness and its ability to generalize across diverse datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Remote sensing datasets offer significant promise for tackling keyclassification tasks such as land-use categorization, object presencedetection, and rural/urban classification. However, many existing studies tendto focus on narrow tasks or datasets, which limits their ability to generalizeacross various remote sensing classification challenges. To overcome this, wepropose a novel model, SpatialNet-ViT, leveraging the power of VisionTransformers (ViTs) and Multi-Task Learning (MTL). This integrated approachcombines spatial awareness with contextual understanding, improving bothclassification accuracy and scalability. Additionally, techniques like dataaugmentation, transfer learning, and multi-task learning are employed toenhance model robustness and its ability to generalize across diverse datasets</description>
      <author>example@mail.com (Gautam Siddharth Kashyap, Manaswi Kulahara, Nipun Joshi, Usman Naseem)</author>
      <guid isPermaLink="false">2506.22501v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Do We Really Need GNNs with Explicit Structural Modeling? MLPs Suffice for Language Model Representations</title>
      <link>http://arxiv.org/abs/2506.21682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Graph Neural Networks, Multi-Layer Perceptrons, Explicit Structural  Modeling, Probing Classifier&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文通过信息理论视角，提出一个综合探针框架来评估显式结构建模在增强语言模型表示中的作用，并研究MLP作为GNN高效且可扩展替代品的潜力。&lt;h4&gt;背景&lt;/h4&gt;尽管图神经网络（GNN）被证明可以编码结构信息以辅助模型，但最近的研究表明GNN未能充分利用结构信息。相比之下，多层感知器（MLP）在结构感知任务中表现出令人惊讶的能力。&lt;h4&gt;目的&lt;/h4&gt;设计一个框架以系统地评估显式结构建模在增强语言模型表示中的作用，并探究MLP作为GNN的高效和可扩展替代品的潜力。&lt;h4&gt;方法&lt;/h4&gt;扩展传统的探针分类器，通过引入一个控制模块，允许选择性地使用完整的GNN模型或其解耦组件（特别是消息传递和特征转换操作）。使用EdgeProbing Suite作为评估LM中编码的语言知识的诊断工具。&lt;h4&gt;主要发现&lt;/h4&gt;作为特征转换模块，MLP在捕获不同架构中的语言知识方面表现良好，有效编码了句法和语义模式。同样，结合特征转换操作的GNN也显示出有益的效果。然而，仅依赖消息传递操作的模型往往表现不佳，通常会对探针任务性能产生负面影响。&lt;h4&gt;结论&lt;/h4&gt;MLP作为特征转换模块可以增强语言模型表示中的语言知识，而GNN结合特征转换操作也显示出有益效果，但单纯依赖消息传递的GNN表现较差。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Explicit structural information has been proven to be encoded by Graph NeuralNetworks (GNNs), serving as auxiliary knowledge to enhance model capabilitiesand improve performance in downstream NLP tasks. However, recent studiesindicate that GNNs fail to fully utilize structural information, whereasMulti-Layer Perceptrons (MLPs), despite lacking the message-passing mechanismsinherent to GNNs, exhibit a surprising ability in structure-aware tasks.Motivated by these findings, this paper introduces a comprehensive probingframework from an information-theoretic perspective. The framework is designedto systematically assess the role of explicit structural modeling in enhancinglanguage model (LM) representations and to investigate the potential of MLPs asefficient and scalable alternatives to GNNs. We extend traditional probingclassifiers by incorporating a control module that allows for selective use ofeither the full GNN model or its decoupled components, specifically, themessage-passing and feature-transformation operations.This modular approachisolates and assesses the individual contributions of these operations,avoiding confounding effects from the complete GNN architecture. Using the EdgeProbing Suite, a diagnostic tool for evaluating the linguistic knowledgeencoded in LMs, we find that MLPs, when used as feature-transformation modules,consistently improve the linguistic knowledge captured in LM representationsacross different architectures. They effectively encode both syntactic andsemantic patterns. Similarly, GNNs that incorporate feature-transformationoperations show beneficial effects. In contrast, models that rely solely onmessage-passing operations tend to underperform, often leading to negativeimpacts on probing task performance.</description>
      <author>example@mail.com (Li Zhou, Hao Jiang, Junjie Li, Zefeng Zhao, Feng Jiang, Wenyu Chen, Haizhou Li)</author>
      <guid isPermaLink="false">2506.21682v1</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction</title>
      <link>http://arxiv.org/abs/2506.21401v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025 Code:  https://github.com/zhirui-gao/Curve-Gaussian&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从多视图边缘图中直接重建3D参数曲线的端到端框架。&lt;h4&gt;背景&lt;/h4&gt;现有的两阶段方法遵循“边缘点云重建和参数曲线拟合”的顺序流程，存在阶段之间固有的优化间隙，导致误差累积。&lt;h4&gt;目的&lt;/h4&gt;提出一种单阶段方法，直接从2D边缘图优化3D参数曲线，消除因阶段分离导致的优化间隙误差。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双向耦合机制，将参数曲线与边缘导向的高斯分量结合，形成曲线感知的高斯表示（CurveGaussian），实现3D曲线的可微分渲染。同时，引入动态自适应拓扑优化框架，通过线性化、合并、拆分和修剪操作来细化曲线结构。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在ABC数据集和真实世界基准测试中，比两阶段方法表现出色，特别是在生成更干净、更稳健的重建方面。直接优化参数曲线显著减少了训练过程中的参数数量，实现了比现有方法更高的效率和更好的性能。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在重建3D参数曲线方面优于现有方法，尤其适用于需要高效和高质量重建的应用场景。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种从多视图边缘图中直接重建3D参数曲线的端到端框架。与现有的两阶段方法不同，我们的单阶段方法直接从2D边缘图优化3D参数曲线，消除了由于阶段分离导致的优化间隙造成的误差累积。然而，参数曲线本身不适合基于渲染的多视图优化，需要一种互补的表示来保留它们的几何属性，同时实现可微分渲染。我们提出了一种新颖的双向耦合机制，将参数曲线与边缘导向的高斯分量相结合。这种紧密的对应关系形成了一种曲线感知的高斯表示，称为CurveGaussian，它使得3D曲线的可微分渲染成为可能，允许直接根据多视图证据进行优化。此外，我们在训练过程中引入了一种动态自适应拓扑优化框架，通过线性化、合并、拆分和修剪操作来细化曲线结构。在ABC数据集和真实世界基准测试中的全面评估表明，我们提出的方法在生成更干净、更稳健的重建方面优于两阶段方法。此外，通过直接优化参数曲线，我们的方法在训练过程中显著减少了参数数量，与现有方法相比，实现了更高的效率和更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an end-to-end framework for reconstructing 3D parametriccurves directly from multi-view edge maps. Contrasting with existing two-stagemethods that follow a sequential ``edge point cloud reconstruction andparametric curve fitting'' pipeline, our one-stage approach optimizes 3Dparametric curves directly from 2D edge maps, eliminating error accumulationcaused by the inherent optimization gap between disconnected stages. However,parametric curves inherently lack suitability for rendering-based multi-viewoptimization, necessitating a complementary representation that preserves theirgeometric properties while enabling differentiable rendering. We propose anovel bi-directional coupling mechanism between parametric curves andedge-oriented Gaussian components. This tight correspondence formulates acurve-aware Gaussian representation, \textbf{CurveGaussian}, that enablesdifferentiable rendering of 3D curves, allowing direct optimization guided bymulti-view evidence. Furthermore, we introduce a dynamically adaptive topologyoptimization framework during training to refine curve structures throughlinearization, merging, splitting, and pruning operations. Comprehensiveevaluations on the ABC dataset and real-world benchmarks demonstrate ourone-stage method's superiority over two-stage alternatives, particularly inproducing cleaner and more robust reconstructions. Additionally, by directlyoptimizing parametric curves, our method significantly reduces the parametercount during training, achieving both higher efficiency and superiorperformance compared to existing approaches.</description>
      <author>example@mail.com (Zhirui Gao, Renjiao Yi, Yaqiao Dai, Xuening Zhu, Wei Chen, Chenyang Zhu, Kai Xu)</author>
      <guid isPermaLink="false">2506.21401v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts</title>
      <link>http://arxiv.org/abs/2506.21835v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ProSAM的方法，用于解决基于SAM的视觉参考图像分割中稳定性挑战的问题，并取得了优于现有方法的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型基础模型的发展推动了开放集图像分割技术的成功，该技术关注于分割预定义类别之外的物体。在多种提示类型中，视觉参考分割因其灵活性和强大的零样本能力而突出。&lt;h4&gt;目的&lt;/h4&gt;旨在提高基于SAM的视觉参考图像分割方法的稳定性。&lt;h4&gt;方法&lt;/h4&gt;ProSAM通过学习一个变分提示编码器来预测多元提示分布，从而避免生成位于不稳定区域的提示，克服了提示编码器不稳健导致的不稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;ProSAM在Pascal-5i和COCO-20i数据集上表现优于现有方法，提供了一种更稳健的视觉参考分割解决方案。&lt;h4&gt;结论&lt;/h4&gt;ProSAM是一个简单而有效的解决现有基于SAM的视觉参考分割方法中稳定性挑战的方法，为图像分割领域提供了新的研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advancements in large foundation models have driven the success ofopen-set image segmentation, a task focused on segmenting objects beyondpredefined categories. Among various prompt types (such as points, boxes,texts, and visual references), visual reference segmentation stands out for itsunique flexibility and strong zero-shot capabilities. Recently, severalSAM-based methods have made notable progress in this task by automaticallygenerating prompts to guide SAM. However, these methods often generate promptsat object boundaries due to suboptimal prompt encoder, which results ininstability and reduced robustness. In this work, we introduce ProSAM, a simplebut effective method to address the stability challenges we identified inexisting SAM-based visual reference segmentation approaches. By learning avariational prompt encoder to predict multivariate prompt distributions, ProSAMavoids generating prompts that lie in unstable regions, overcoming theinstability caused by less robust prompts. Our approach consistently surpassesstate-of-the-art methods on the Pascal-5$^i$ and COCO-20$^i$ datasets,providing a more robust solution for visual reference segmentation.</description>
      <author>example@mail.com (Xiaoqi Wang, Clint Sebastian, Wenbin He, Liu Ren)</author>
      <guid isPermaLink="false">2506.21835v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Supergeo Design: A Scalable Framework for Geographic Marketing Experiments</title>
      <link>http://arxiv.org/abs/2506.20499v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为自适应超级地理设计（ASD）的两阶段框架，用于大规模测量广告支出的增量回报率（iROAS），有效解决了地理实验设计中单位数量少、异质性大以及最优超级地理分区问题NP难的问题。&lt;h4&gt;背景&lt;/h4&gt;地理实验是衡量广告支出的增量回报率（iROAS）的标准方法，但其设计面临挑战，包括单位数量少、异质性大和最优超级地理分区问题NP难。&lt;h4&gt;目的&lt;/h4&gt;提出ASD框架，使其在成千上万的市场中实用，并解决地理实验设计中的挑战。&lt;h4&gt;方法&lt;/h4&gt;ASD框架包括两个阶段：首先，一个定制的图神经网络学习地理嵌入并提议一个简洁的“超级地理”候选集；然后，CP-SAT求解器选择一个分区，平衡基线结果和预处理协变量，这些协变量被认为会改变治疗效果。&lt;h4&gt;主要发现&lt;/h4&gt;在社区结构假设下，ASD的目标值在全局最优解的（1+epsilon）范围内。在模拟中，ASD在标准硬件上几分钟内完成，保留了每一分媒体费用，并将iROAS偏差显著降低。&lt;h4&gt;结论&lt;/h4&gt;ASD将地理提升测试转化为媒体计划的常规、可扩展组件，同时保持了统计严谨性。&lt;h4&gt;翻译&lt;/h4&gt;Geographic experiments are a gold-standard for measuring incremental return-on ad spend (iROAS) at scale, yet their design is challenging: the unit count is small, heterogeneity is large, and the optimal Supergeo partitioning problem is NP-hard. We introduce Adaptive Supergeo Design (ASD), a two-stage framework that renders Supergeo designs practical for thousands of markets. A bespoke graph-neural network first learns geo-embeddings and proposes a concise candidate set of 'supergeos'; a CP-SAT solver then selects a partition that balances both baseline outcomes and pre-treatment covariates believed to modify the treatment effect. We prove that ASD's objective value is within (1+epsilon) of the global optimum under mild community-structure assumptions. In simulations with up to 1,000 Designated Market Areas, ASD completes in minutes on standard hardware, retains every media dollar, and cuts iROAS bias substantially relative to existing methods. ASD therefore turns geo-lift testing into a routine, scalable component of media planning while preserving statistical rigor.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geographic experiments are a gold-standard for measuring incremental returnon ad spend (iROAS) at scale, yet their design is challenging: the unit countis small, heterogeneity is large, and the optimal Supergeo partitioning problemis NP-hard. We introduce Adaptive Supergeo Design (ASD), a two-stage frameworkthat renders Supergeo designs practical for thousands of markets. A bespokegraph-neural network first learns geo-embeddings and proposes a concisecandidate set of 'supergeos'; a CP-SAT solver then selects a partition thatbalances both baseline outcomes and pre-treatment covariates believed to modifythe treatment effect. We prove that ASD's objective value is within (1+epsilon)of the global optimum under mild community-structure assumptions. Insimulations with up to 1,000 Designated Market Areas ASD completes in minuteson standard hardware, retains every media dollar, and cuts iROAS biassubstantively relative to existing methods. ASD therefore turns geo-lifttesting into a routine, scalable component of media planning while preservingstatistical rigour.</description>
      <author>example@mail.com (Charles Shaw)</author>
      <guid isPermaLink="false">2506.20499v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Generalizing vision-language models to novel domains: A comprehensive survey</title>
      <link>http://arxiv.org/abs/2506.18504v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了视觉-语言预训练技术的发展，以及其在下游应用中的泛化能力研究。&lt;h4&gt;背景&lt;/h4&gt;视觉-语言预训练结合了视觉和文本模态的优势，产生了强大的视觉-语言模型（VLMs），但它们在特定领域或专业泛化任务中的表现往往不佳。&lt;h4&gt;目的&lt;/h4&gt;调查视觉-语言模型（VLMs）的泛化设置、方法、基准和结果。&lt;h4&gt;方法&lt;/h4&gt;根据转移模块，将文献分为基于提示、基于参数和基于特征的方法，并回顾了典型的迁移学习（TL）设置，提供了对VLM时代迁移学习的新解释。&lt;h4&gt;主要发现&lt;/h4&gt;介绍了VLM泛化的流行基准，并比较了所审查方法的性能。&lt;h4&gt;结论&lt;/h4&gt;随着大规模可泛化预训练的进展，本文讨论了VLMs和最新的多模态大型语言模型（MLLM）如DeepSeek-VL之间的关系和差异。&lt;h4&gt;翻译&lt;/h4&gt;最近，视觉-语言预训练作为一种结合视觉和文本模态优势的变革性技术而出现，产生了强大的视觉-语言模型（VLMs）。利用网络规模的预训练数据，这些模型展现出强大的零样本能力。然而，当面对特定领域或专业泛化任务时，它们的性能往往会下降。为了解决这个问题，越来越多的研究关注于将VLMs中嵌入的丰富知识转移到各种下游应用中。这项调查旨在全面总结VLM文献中的泛化设置、方法、基准和结果。通过深入研究典型的VLM结构，根据转移模块将文献分为基于提示、基于参数和基于特征的方法。通过回顾典型的迁移学习（TL）设置，进一步总结了每个类别的差异和特点，并为VLM时代迁移学习提供了新的解释。介绍了VLM泛化的流行基准，并在所审查的方法之间进行了详尽的性能比较。随着大规模可泛化预训练的进展，这项调查还讨论了VLMs和最新的多模态大型语言模型（MLLM）如DeepSeek-VL之间的关系和差异。通过系统地回顾视觉-语言研究中的新兴文献，从新颖和实用的泛化视角出发，这项调查有助于描绘当前和未来的多模态研究图景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, vision-language pretraining has emerged as a transformativetechnique that integrates the strengths of both visual and textual modalities,resulting in powerful vision-language models (VLMs). Leveraging web-scalepretraining data, these models exhibit strong zero-shot capabilities. However,their performance often deteriorates when confronted with domain-specific orspecialized generalization tasks. To address this, a growing body of researchfocuses on transferring or generalizing the rich knowledge embedded in VLMs tovarious downstream applications. This survey aims to comprehensively summarizethe generalization settings, methodologies, benchmarking and results in VLMliteratures. Delving into the typical VLM structures, current literatures arecategorized into prompt-based, parameter-based and feature-based methodsaccording to the transferred modules. The differences and characteristics ineach category are furthered summarized and discussed by revisiting the typicaltransfer learning (TL) settings, providing novel interpretations for TL in theera of VLMs. Popular benchmarks for VLM generalization are further introducedwith thorough performance comparisons among the reviewed methods. Following theadvances in large-scale generalizable pretraining, this survey also discussesthe relations and differences between VLMs and up-to-date multimodal largelanguage models (MLLM), e.g., DeepSeek-VL. By systematically reviewing thesurging literatures in vision-language research from a novel and practicalgeneralization prospective, this survey contributes to a clear landscape ofcurrent and future multimodal researches.</description>
      <author>example@mail.com (Xinyao Li, Jingjing Li, Fengling Li, Lei Zhu, Yang Yang, Heng Tao Shen)</author>
      <guid isPermaLink="false">2506.18504v2</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>Compositional Generative Model of Unbounded 4D Cities</title>
      <link>http://arxiv.org/abs/2501.08983v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://www.infinitescript.com/project/city-dreamer-4d/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CityDreamer4D的4D城市生成模型，用于生成无限扩展的4D城市。&lt;h4&gt;背景&lt;/h4&gt;近年来，3D场景生成受到广泛关注并取得了显著进展。由于城市环境中存在结构复杂、视觉多样化的物体（如建筑物和车辆），生成4D城市比生成3D场景更具挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了CityDreamer4D模型，专门用于生成无界4D城市。&lt;h4&gt;方法&lt;/h4&gt;1) 将动态对象（如车辆）从静态场景（如建筑物和道路）中分离出来；2) 所有4D场景中的对象都由不同类型的神经网络场（建筑物、车辆和背景物体）组成。具体包括Traffic Scenario Generator和Unbounded Layout Generator，用于生成动态交通场景和静态城市布局，使用高度紧凑的BEV表示。通过组合面向内容和面向实例的神经网络场来生成4D城市中的对象，以适应背景物体和实例的独特特性，神经网络场使用定制的生成哈希网格和周期性位置嵌入作为场景参数化。&lt;h4&gt;主要发现&lt;/h4&gt;1) 4D城市生成应将动态对象与静态场景分离；2) 4D场景中的所有对象应由不同类型的神经网络场组成。&lt;h4&gt;结论&lt;/h4&gt;CityDreamer4D模型支持一系列下游应用，如实例编辑、城市风格化和城市模拟，在生成逼真的4D城市方面取得了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，3D场景生成受到了越来越多的关注，并取得了显著的进展。由于城市环境中存在结构复杂、视觉多样化的物体（如建筑物和车辆），生成4D城市比生成3D场景更具挑战性。为了解决这些问题，我们提出了CityDreamer4D，一种专门针对生成无界4D城市的组合生成模型。我们的主要见解是：1) 4D城市生成应将动态对象（例如，车辆）与静态场景（例如，建筑物和道路）分离；2) 4D场景中的所有对象都应由不同类型的神经网络场（建筑物、车辆和背景物体）组成。具体来说，我们提出了Traffic Scenario Generator和Unbounded Layout Generator，用于使用高度紧凑的BEV表示生成动态交通场景和静态城市布局。4D城市中的对象通过组合面向内容和面向实例的神经网络场来生成，以适应背景物体和实例的独特特性，神经网络场使用定制的生成哈希网格和周期性位置嵌入作为场景参数化。此外，我们提供了一套全面的用于城市生成的数据集，包括OSM、Google Earth和CityTopia。OSM数据集提供了各种现实世界的城市布局，而Google Earth和CityTopia数据集提供了包含3D实例注释的大规模、高质量的城市图像。利用其组合设计，CityDreamer4D支持一系列下游应用，如实例编辑、城市风格化和城市模拟，在生成逼真的4D城市方面取得了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-01-15&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/hzxie/CityDreamer4D&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D scene generation has garnered growing attention in recent years and hasmade significant progress. Generating 4D cities is more challenging than 3Dscenes due to the presence of structurally complex, visually diverse objectslike buildings and vehicles, and heightened human sensitivity to distortions inurban environments. To tackle these issues, we propose CityDreamer4D, acompositional generative model specifically tailored for generating unbounded4D cities. Our main insights are 1) 4D city generation should separate dynamicobjects (e.g., vehicles) from static scenes (e.g., buildings and roads), and 2)all objects in the 4D scene should be composed of different types of neuralfields for buildings, vehicles, and background stuff. Specifically, we proposeTraffic Scenario Generator and Unbounded Layout Generator to produce dynamictraffic scenarios and static city layouts using a highly compact BEVrepresentation. Objects in 4D cities are generated by combining stuff-orientedand instance-oriented neural fields for background stuff, buildings, andvehicles. To suit the distinct characteristics of background stuff andinstances, the neural fields employ customized generative hash grids andperiodic positional embeddings as scene parameterizations. Furthermore, weoffer a comprehensive suite of datasets for city generation, including OSM,GoogleEarth, and CityTopia. The OSM dataset provides a variety of real-worldcity layouts, while the Google Earth and CityTopia datasets deliverlarge-scale, high-quality city imagery complete with 3D instance annotations.Leveraging its compositional design, CityDreamer4D supports a range ofdownstream applications, such as instance editing, city stylization, and urbansimulation, while delivering state-of-the-art performance in generatingrealistic 4D cities.</description>
      <author>example@mail.com (Haozhe Xie, Zhaoxi Chen, Fangzhou Hong, Ziwei Liu)</author>
      <guid isPermaLink="false">2501.08983v3</guid>
      <pubDate>Tue, 01 Jul 2025 14:35:07 +0800</pubDate>
    </item>
    <item>
      <title>IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals</title>
      <link>http://arxiv.org/abs/2506.20671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了IPFormer，一种基于视觉的3D全景场景补全方法，通过上下文自适应实例提议来提高场景理解的能力。&lt;h4&gt;背景&lt;/h4&gt;语义场景补全（SSC）和全景场景补全（PSC）是联合学习场景几何和语义的关键方法，但在基于相机图像的方法和动态适应场景方面仍有待探索。&lt;h4&gt;目的&lt;/h4&gt;提出IPFormer，以解决视觉3D全景场景补全中的动态适应性和上下文相关性问题。&lt;h4&gt;方法&lt;/h4&gt;IPFormer利用上下文自适应实例提议，在训练和测试时动态初始化查询，并通过注意力机制编码和解码，以推理语义实例体关系。&lt;h4&gt;主要发现&lt;/h4&gt;IPFormer在整体全景度量PQ和PQ-All上超越了现有方法，在单个度量上与现有方法持平，并在运行时减少了超过14倍。动态从图像上下文推导实例提议比随机初始化提高了3.62%的PQ-All和18.65%的平均 Thing-metrics。&lt;h4&gt;结论&lt;/h4&gt;IPFormer通过引入上下文自适应实例提议，为视觉3D全景场景补全提供了一种开创性的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semantic Scene Completion (SSC) has emerged as a pivotal approach for jointlylearning scene geometry and semantics, enabling downstream applications such asnavigation in mobile robotics. The recent generalization to Panoptic SceneCompletion (PSC) advances the SSC domain by integrating instance-levelinformation, thereby enhancing object-level sensitivity in scene understanding.While PSC was introduced using LiDAR modality, methods based on camera imagesremain largely unexplored. Moreover, recent Transformer-based SSC approachesutilize a fixed set of learned queries to reconstruct objects within the scenevolume. Although these queries are typically updated with image context duringtraining, they remain static at test time, limiting their ability todynamically adapt specifically to the observed scene. To overcome theselimitations, we propose IPFormer, the first approach that leveragescontext-adaptive instance proposals at train and test time to addressvision-based 3D Panoptic Scene Completion. Specifically, IPFormer adaptivelyinitializes these queries as panoptic instance proposals derived from imagecontext and further refines them through attention-based encoding and decodingto reason about semantic instance-voxel relationships. Experimental resultsshow that our approach surpasses state-of-the-art methods in overall panopticmetrics PQ$^\dagger$ and PQ-All, matches performance in individual metrics, andachieves a runtime reduction exceeding 14$\times$. Furthermore, our ablationstudies reveal that dynamically deriving instance proposals from image context,as opposed to random initialization, leads to a 3.62% increase in PQ-All and aremarkable average improvement of 18.65% in combined Thing-metrics. Theseresults highlight our introduction of context-adaptive instance proposals as apioneering effort in addressing vision-based 3D Panoptic Scene Completion.</description>
      <author>example@mail.com (Markus Gross, Aya Fahmy, Danit Niwattananan, Dominik Muhle, Rui Song, Daniel Cremers, Henri Meeß)</author>
      <guid isPermaLink="false">2506.20671v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
  <item>
      <title>Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis</title>
      <link>http://arxiv.org/abs/2506.22393v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，利用多视角对比学习来整合时间模式、基于导数的动态和频域特征，以解决不同领域医疗时间序列中机器学习模型的适应性挑战。&lt;h4&gt;背景&lt;/h4&gt;由于复杂的时间依赖性和动态分布的变化，将机器学习模型适应不同领域的医疗时间序列仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，能够全面捕捉所需的时间动态，以实现鲁棒的领域自适应。&lt;h4&gt;方法&lt;/h4&gt;该方法使用独立的编码器和分层融合机制来学习特征不变表示，这些表示可以在不同领域之间迁移，同时保持时间一致性。&lt;h4&gt;主要发现&lt;/h4&gt;在包括脑电图（EEG）、心电图（ECG）和肌电图（EMG）在内的多种医疗数据集上的实验表明，该方法在迁移学习任务中显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;通过提高机器学习模型的鲁棒性和泛化能力，该框架为在多样化的医疗环境中部署可靠的AI系统提供了一条实际途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：将机器学习模型适应不同领域的医疗时间序列仍然是一个挑战，由于复杂的时间依赖性和动态分布的变化。当前方法通常关注孤立的特征表示，限制了它们完全捕捉所需的时间动态的能力，这对于鲁棒的领域自适应是必要的。在这项工作中，我们提出了一种利用多视角对比学习来整合时间模式、基于导数的动态和频域特征的新框架。我们的方法使用独立的编码器和分层融合机制来学习特征不变表示，这些表示可以在不同领域之间迁移，同时保持时间一致性。在包括脑电图（EEG）、心电图（ECG）和肌电图（EMG）在内的多种医疗数据集上的广泛实验表明，我们的方法在迁移学习任务中显著优于现有方法。通过提高机器学习模型的鲁棒性和泛化能力，我们的框架为在多样化的医疗环境中部署可靠的AI系统提供了一条实际途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Adapting machine learning models to medical time series across differentdomains remains a challenge due to complex temporal dependencies and dynamicdistribution shifts. Current approaches often focus on isolated featurerepresentations, limiting their ability to fully capture the intricate temporaldynamics necessary for robust domain adaptation. In this work, we propose anovel framework leveraging multi-view contrastive learning to integratetemporal patterns, derivative-based dynamics, and frequency-domain features.Our method employs independent encoders and a hierarchical fusion mechanism tolearn feature-invariant representations that are transferable across domainswhile preserving temporal coherence. Extensive experiments on diverse medicaldatasets, including electroencephalogram (EEG), electrocardiogram (ECG), andelectromyography (EMG) demonstrate that our approach significantly outperformsstate-of-the-art methods in transfer learning tasks. By advancing therobustness and generalizability of machine learning models, our frameworkoffers a practical pathway for deploying reliable AI systems in diversehealthcare settings.</description>
      <author>example@mail.com (YongKyung Oh, Alex Bui)</author>
      <guid isPermaLink="false">2506.22393v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>MiCo: Multi-image Contrast for Reinforcement Visual Reasoning</title>
      <link>http://arxiv.org/abs/2506.22434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探索了如何使思维链（CoT）推理跨越多张图像连接视觉线索，提出了一种基于规则强化学习的视觉语言模型（VLMs）的解决方案。&lt;h4&gt;背景&lt;/h4&gt;传统的基于规则强化学习方法通常依赖于人工编纂的问题-答案对，这在处理图像中的细粒度视觉细节和复杂的逻辑关系时尤其具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过一种不依赖于人工标注的方法，提高多图像推理基准测试的性能。&lt;h4&gt;方法&lt;/h4&gt;研究者受到自监督视觉表示学习的启发，发现图像中包含内在的约束，可以充当监督信号。他们构建了由同一图像的两个增强视图和第三个相似但不同的图像组成的图像三元组。在训练过程中，模型被提示生成一个推理过程来比较这些图像（即确定图像是否相同）。然后，使用基于规则的强化学习优化模型。&lt;h4&gt;主要发现&lt;/h4&gt;尽管模型仅通过视觉比较任务进行训练，但所学习的推理能力有效地推广到了广泛的问题上。该方法在多图像推理基准测试中实现了显著的改进，并在一般视觉任务上表现出强大的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在不依赖任何人工标注的问题-答案对的情况下，在多图像推理基准测试中取得了显著的成绩，并在一般视觉任务上表现出良好的性能，证明了其有效性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work explores enabling Chain-of-Thought (CoT) reasoning to link visualcues across multiple images. A straightforward solution is to adapt rule-basedreinforcement learning for Vision-Language Models (VLMs). However, such methodstypically rely on manually curated question-answer pairs, which can beparticularly challenging when dealing with fine grained visual details andcomplex logic across images. Inspired by self-supervised visual representationlearning, we observe that images contain inherent constraints that can serve assupervision. Based on this insight, we construct image triplets comprising twoaugmented views of the same image and a third, similar but distinct image.During training, the model is prompted to generate a reasoning process tocompare these images (i.e., determine same or different). Then we optimize themodel with rule-based reinforcement learning. Due to the high visual similarityand the presence of augmentations, the model must attend to subtle visualchanges and perform logical reasoning to succeed. Experiments show that,although trained solely on visual comparison tasks, the learned reasoningability generalizes effectively to a wide range of questions. Without relyingon any human-annotated question-answer pairs, our method achieves significantimprovements on multi-image reasoning benchmarks and shows strong performanceon general vision tasks.</description>
      <author>example@mail.com (Xi Chen, Mingkang Zhu, Shaoteng Liu, Xiaoyang Wu, Xiaogang Xu, Yu Liu, Xiang Bai, Hengshuang Zhao)</author>
      <guid isPermaLink="false">2506.22434v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration</title>
      <link>http://arxiv.org/abs/2506.22242v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了4D-VLA，一种利用4D信息有效整合到输入中的新方法，以缓解机器人数据预训练中的坐标系统混沌和状态混沌问题，并通过记忆银行采样策略提高预训练效率。&lt;h4&gt;背景&lt;/h4&gt;利用多样化的机器人数据预训练是一个关键挑战。现有方法通常使用简单的观察作为输入来建模数据集的动作分布，但这些输入往往不完整，导致条件动作分布分散，称为坐标系统混沌和状态混沌，这严重阻碍了预训练效率。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高机器人数据预训练的效率，通过整合4D信息和引入记忆银行采样策略。&lt;h4&gt;方法&lt;/h4&gt;4D-VLA模型通过引入深度和时序信息到视觉特征中，使用序列RGB-D输入，以对齐机器人和场景的坐标系。此外，引入了记忆银行采样策略，旨在从历史图像中提取信息丰富的帧。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，我们的预训练方法和架构组件显著提高了模型性能。在模拟和真实世界的实验中，我们的模型在成功率方面显著高于OpenVLA。MV-Bench多视角模拟基准测试也显示了模型在空间理解和适应性方面的优势。&lt;h4&gt;结论&lt;/h4&gt;4D-VLA模型通过整合4D信息和改进的采样策略，有效地解决了机器人数据预训练中的问题，并在多视角模拟基准测试中优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Leveraging diverse robotic data for pretraining remains a critical challenge.Existing methods typically model the dataset's action distribution using simpleobservations as inputs. However, these inputs are often incomplete, resultingin a dispersed conditional action distribution-an issue we refer to ascoordinate system chaos and state chaos. This inconsistency significantlyhampers pretraining efficiency. To address this, we propose 4D-VLA, a novelapproach that effectively integrates 4D information into the input to mitigatethese sources of chaos. Our model introduces depth and temporal informationinto visual features with sequential RGB-D inputs, aligning the coordinatesystems of the robot and the scene. This alignment endows the model with strongspatiotemporal reasoning capabilities while minimizing training overhead.Additionally, we introduce memory bank sampling, a frame sampling strategydesigned to extract informative frames from historical images, furtherimproving effectiveness and efficiency. Experimental results demonstrate thatour pretraining method and architectural components substantially enhance modelperformance. In both simulated and real-world experiments, our model achieves asignificant increase in success rate over OpenVLA. To further assess spatialperception and generalization to novel views, we introduce MV-Bench, amulti-view simulation benchmark. Our model consistently outperforms existingmethods, demonstrating stronger spatial understanding and adaptability.</description>
      <author>example@mail.com (Jiahui Zhang, Yurui Chen, Yueming Xu, Ze Huang, Yanpeng Zhou, Yu-Jie Yuan, Xinyue Cai, Guowei Huang, Xingyue Quan, Hang Xu, Li Zhang)</author>
      <guid isPermaLink="false">2506.22242v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>CoATA: Effective Co-Augmentation of Topology and Attribute for Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.22299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  icmr&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了CoATA，一种针对拓扑和属性协同增强的双通道图神经网络框架，以解决现实世界图中存在的噪声和不完整性问题。&lt;h4&gt;背景&lt;/h4&gt;由于现实世界图存在大量噪声和不完整性，现有的图神经网络方法通常通过单一维度的增强来解决这个问题，但忽略了拓扑结构和节点属性之间的深层交互。&lt;h4&gt;目的&lt;/h4&gt;旨在通过协同增强拓扑和属性来提高图神经网络的性能。&lt;h4&gt;方法&lt;/h4&gt;CoATA首先通过传播结构信号来丰富和去噪节点属性，然后将增强的属性空间投影到节点-属性二分图中进行进一步精炼或重构。接着，引入对比学习，利用原型对齐和一致性约束，促进增强图和原始图之间的相互纠正。&lt;h4&gt;主要发现&lt;/h4&gt;在七个基准数据集上的广泛实验表明，提出的CoATA优于11种最先进的基线方法，证明了其在捕捉拓扑和属性之间协同关系方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;CoATA框架通过协同增强拓扑和属性，显著提升了图神经网络的性能，为处理现实世界图提供了有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have garnered substantial attention due to theirremarkable capability in learning graph representations. However, real-worldgraphs often exhibit substantial noise and incompleteness, which severelydegrades the performance of GNNs. Existing methods typically address this issuethrough single-dimensional augmentation, focusing either on refining topologystructures or perturbing node attributes, thereby overlooking the deeperinterplays between the two. To bridge this gap, this paper presents CoATA, adual-channel GNN framework specifically designed for the Co-Augmentation ofTopology and Attribute. Specifically, CoATA first propagates structural signalsto enrich and denoise node attributes. Then, it projects the enhanced attributespace into a node-attribute bipartite graph for further refinement orreconstruction of the underlying structure. Subsequently, CoATA introducescontrastive learning, leveraging prototype alignment and consistencyconstraints, to facilitate mutual corrections between the augmented andoriginal graphs. Finally, extensive experiments on seven benchmark datasetsdemonstrate that the proposed CoATA outperforms eleven state-of-the-artbaseline methods, showcasing its effectiveness in capturing the synergisticrelationship between topology and attributes.</description>
      <author>example@mail.com (Tao Liu, Longlong Lin, Yunfeng Yu, Xi Ou, Youan Zhang, Zhiqiu Ye, Tao Jia)</author>
      <guid isPermaLink="false">2506.22299v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Linking climate and dengue in the Philippines using a two-stage Bayesian spatio-temporal model</title>
      <link>http://arxiv.org/abs/2506.22334v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究旨在探讨菲律宾登革热与气候之间的关联，采用两阶段建模框架，利用贝叶斯时空模型和INLA方法进行推断。&lt;h4&gt;背景&lt;/h4&gt;登革热是一种在许多热带和亚热带地区造成重大社会经济和疾病负担的传染病。&lt;h4&gt;目的&lt;/h4&gt;为菲律宾登革热与气候的关联提供更多见解。&lt;h4&gt;方法&lt;/h4&gt;使用两阶段建模框架，第一阶段拟合气候模型，第二阶段拟合健康模型，使用第一阶段气候预测作为输入。采用贝叶斯时空模型和INLA方法进行推断，并执行后验抽样和贝叶斯模型平均来计算第二阶段模型参数的最终后验估计。&lt;h4&gt;主要发现&lt;/h4&gt;结果表明，温度与登革热呈正相关，但极端高温条件可能产生负面影响。降雨与登革热的关系在空间上存在差异，在全年降雨量均匀的地区，降雨与登革热呈负相关；而在干湿季节明显的地区，降雨与登革热呈正相关。在考虑气候变量和其他协变量的影响后，仍然存在未解释的空间和时间结构变异。&lt;h4&gt;结论&lt;/h4&gt;研究揭示了菲律宾登革热与气候之间的复杂关系，并指出了进一步研究的必要性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dengue is an infectious disease which poses significant socioeconomic anddisease burden in many tropical and subtropical regions of the world. This workaims to provide additional insight into the association between dengue andclimate in the Philippines. We employ a two-stage modelling framework: thefirst stage fits climate models, while the second stage fits a health modelthat uses the climate predictions from the first stage as inputs. We postulatea Bayesian spatio-temporal model and use the integrated nested Laplaceapproximation (INLA) approach for inference. To account for the uncertainty inthe climate models, we perform posterior sampling and then perform Bayesianmodel averaging to compute the final posterior estimates of second-stage modelparameters. The results indicate that temperature is positively associated withdengue, although extremely hot conditions tend to have a negative effect.Moreover, the relationship between rainfall and dengue varies in space. Inareas with uniform amounts of rainfall all year round, rainfall is negativelyassociated with dengue. In contrast, in regions with pronounced dry and wetseason, rainfall shows a positive association with dengue. Finally, thereremains unexplained structured variation in space and time after accounting forthe impact of climate variables and other covariates.</description>
      <author>example@mail.com (Stephen Jun Villejo, Sara Martino, Janine Illian)</author>
      <guid isPermaLink="false">2506.22334v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>HyperCLOVA X THINK Technical Report</title>
      <link>http://arxiv.org/abs/2506.22403v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  49 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;HyperCLOVA X THINK是HyperCLOVA X家族中首个以推理为核心的大型语言模型，预训练数据包括约6000亿高质量的韩语和英语词汇，并辅以目标合成韩语数据。该模型采用计算内存平衡的Peri-LN Transformer架构，通过三阶段课程预训练，将上下文窗口扩展到128K个标记，并通过可验证奖励的强化学习进行监督微调，支持详细推理和简洁答案模式。&lt;h4&gt;背景&lt;/h4&gt;HyperCLOVA X THINK是HyperCLOVA X家族的一部分，旨在提供强大的推理能力。&lt;h4&gt;目的&lt;/h4&gt;HyperCLOVA X THINK旨在成为一个强大的基础模型，用于韩语AI创新和全球研究社区的有价值资源。&lt;h4&gt;方法&lt;/h4&gt;HyperCLOVA X THINK使用计算内存平衡的Peri-LN Transformer架构，通过三阶段课程预训练，并在监督微调中使用强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;HyperCLOVA X THINK在针对韩国的基准测试（如KMMLU、CSAT、KoBALT-700、HAERAE-1.0、KoBigBench）中表现出与同等规模模型相媲美的性能，同时保持了稳健的双语一致性和翻译质量。此外，视觉增强变体在KCSAT STEM基准测试上与GPT-4.1相当或超过，所有这些均比现有同类模型具有显著较低的训练计算量。&lt;h4&gt;结论&lt;/h4&gt;HyperCLOVA X THINK是一个强大的基础模型，适用于韩语AI创新，并对全球研究社区具有重要价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce HyperCLOVA X THINK, the first reasoning-focused large languagemodel in the HyperCLOVA X family, pre-trained on roughly $6$ trillionhigh-quality Korean, and English tokens, augmented with targeted syntheticKorean data. It was implemented as a compute-memory-balanced Peri-LNTransformer scaled with $\mu$P, pre-trained through a three-stage curriculumthat expands the context window to $128$K tokens, and post-trained viasupervised fine-tuning with Reinforcement Learning from Verifiable Rewardssupports both detailed rationale and concise-answer modes. It deliverscompetitive performance against similarly sized models on Korea-focusedbenchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, whilepreserving robust bilingual consistency and translation quality. In addition, avision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEMbenchmark, all of which are achieved with substantially lower training computethan existing models of similar sizes. We also present a pruning anddistillation technique that will soon be applied to HyperCLOVA X THINK for anopen-source and business-friendly foundation model. Altogether, thesecapabilities position HyperCLOVA X THINK as a robust foundation for Korean AIinnovation and a valuable resource for the global research community.</description>
      <author>example@mail.com (NAVER Cloud HyperCLOVA X Team)</author>
      <guid isPermaLink="false">2506.22403v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation</title>
      <link>http://arxiv.org/abs/2506.22375v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于视觉-语言模型（VLM）的无监督框架，用于在3D点云数据中有效检测异常值（OOD）。该框架通过构建基于类别原型和测试数据的图，利用数据流形结构来增强VLM在3D OOD检测中的效果。&lt;h4&gt;背景&lt;/h4&gt;在3D点云数据中检测异常值是一个挑战，尤其是在需要安全和鲁棒的感知的应用中。现有的OOD检测方法在2D图像数据上取得了一定的进展，但将其扩展到3D环境面临独特的障碍。&lt;h4&gt;目的&lt;/h4&gt;开发一种无监督的框架，利用VLM在3D点云数据中实现有效的异常值检测。&lt;h4&gt;方法&lt;/h4&gt;通过构建基于类别原型和测试数据的图，提出了一种名为图评分传播（GSP）的方法，该方法结合了提示聚类和自训练负提示来改进VLM的OOD评分。该方法还适用于少量样本的情况。&lt;h4&gt;主要发现&lt;/h4&gt;GSP在合成和真实世界数据集上的3D点云OOD检测性能优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;提出的GSP方法在3D点云数据中实现了有效的异常值检测，为实际应用提供了新的选择。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于视觉-语言模型（VLM）的无监督框架，用于在3D点云数据中有效检测异常值（OOD）。该框架通过构建基于类别原型和测试数据的图，利用数据流形结构来增强VLM在3D OOD检测中的效果。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Out-of-distribution (OOD) detection in 3D point cloud data remains achallenge, particularly in applications where safe and robust perception iscritical. While existing OOD detection methods have shown progress for 2D imagedata, extending these to 3D environments involves unique obstacles. This paperintroduces a training-free framework that leverages Vision-Language Models(VLMs) for effective OOD detection in 3D point clouds. By constructing a graphbased on class prototypes and testing data, we exploit the data manifoldstructure to enhancing the effectiveness of VLMs for 3D OOD detection. Wepropose a novel Graph Score Propagation (GSP) method that incorporates promptclustering and self-training negative prompting to improve OOD scoring withVLM. Our method is also adaptable to few-shot scenarios, providing options forpractical applications. We demonstrate that GSP consistently outperformsstate-of-the-art methods across synthetic and real-world datasets 3D pointcloud OOD detection.</description>
      <author>example@mail.com (Tiankai Chen, Yushu Li, Adam Goodge, Fei Teng, Xulei Yang, Tianrui Li, Xun Xu)</author>
      <guid isPermaLink="false">2506.22375v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>An Efficient Class of Bayesian Generalized Quadratic Nonlinear Dynamic Models with Application to Birth Rate Monitoring</title>
      <link>http://arxiv.org/abs/2506.22188v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Frobenius范数匹配的协方差校准策略，用于非线性时空过程的建模，并通过Exact Posterior Regression方法进行高效实现。&lt;h4&gt;背景&lt;/h4&gt;现实世界的时空过程通常具有非线性动力学，可以通过随机偏微分方程描述。然而，在贝叶斯框架下实现这些模型在计算上具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了简化非线性时空过程的建模，本文旨在提出一种新的协方差校准策略，并使用高效的方法进行实现。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个将线性混合效应模型的协方差矩阵与广义二次非线性（GQN）模型的协方差矩阵在Frobenius范数上匹配的校准策略。同时，使用Exact Posterior Regression方法进行模型实现，并与MCMC方法进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;通过模拟研究，本文的方法与MCMC方法相比，在实现线性框架下建模非线性时空过程方面具有优势，并且能够识别出与现有文献一致的协变量效应。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在避免MCMC计算困难的同时，提高了非线性时空模型的建模效率和准确性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a covariance calibration strategy that specifies the covariance matrix of a linear mixed effects model to be close in Frobenius norm to that of a Generalized Quadratic Nonlinearity (GQN) model. We refer to this as Frobenius norm matching. This allows us to model nonlinear dynamics using an easier to implement linear framework. The calibrated linear model is efficiently implemented using Exact Posterior Regression (EPR), a recently proposed Bayesian model that enables sampling of fixed and random effects directly from the posterior distribution. We provide simulation studies that compare to implementations using MCMC. Finally, we use this approach to analyze Florida county-level birth rate data from 1990 to 2023. Our results indicate that our non-linear spatio-temporal model outperforms linear dynamic spatio-temporal models for this data, and identifies covariate effects consistent with existing literature, all while avoiding the computational difficulties of MCMC.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Many real-world spatio-temporal processes exhibit nonlinear dynamics that canoften be described through stochastic partial differential equations. Thesemodels are flexible and scientifically motivated, however, implementing them ina fully Bayesian framework can be computationally challenging. We are motivatedby birth rate data, which has important implications for public health and areknown to follow nonlinear dynamics. We propose a covariance calibrationstrategy that specifies the covariance matrix of a linear mixed effects modelto be close in Frobenius norm to that of a Generalized Quadratic Nonlinearity(GQN) model. We refer to this as Frobenius norm matching. This allows us tomodel nonlinear dynamics using an easier to implement linear framework. Thecalibrated linear model is efficiently implemented using Exact PosteriorRegression (EPR), a recently proposed Bayesian model that enables sampling offixed and random effects directly from the posterior distribution. We providesimulation studies that compare to implementations using MCMC. Finally, we usethis approach to analyze Florida county-level birth rate data from 1990-2023.Our results indicate that our non-linear spatio-temporal model outperformslinear dynamic spatio-temporal models for this data, and identifies covariateeffects consistent with existing literature, all while avoiding thecomputational difficulties of MCMC.</description>
      <author>example@mail.com (Madelyn Clinch, Jonathan R. Bradley)</author>
      <guid isPermaLink="false">2506.22188v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Universal Retrieval for Multimodal Trajectory Modeling</title>
      <link>http://arxiv.org/abs/2506.22056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 3 figures, accepted by Workshop on Computer-use Agents @  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为多模态轨迹检索的方法，用于提升AI代理在GUI环境中的能力，并构建了一个统一代理轨迹数据集（UATD）和一个基准测试集GAE-Bench，以及一个多模态检索框架GAE-Retriever，通过对比学习在多个数据集上的评估中表现出色。&lt;h4&gt;背景&lt;/h4&gt;轨迹数据在增强AI代理能力方面具有潜力，但其表示建模是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出多模态轨迹检索方法，以解决轨迹数据表示建模的挑战。&lt;h4&gt;方法&lt;/h4&gt;构建了UATD数据集，提出GAE-Bench基准，并设计了GAE-Retriever检索框架。&lt;h4&gt;主要发现&lt;/h4&gt;GAE-Retriever在检索召回率上优于强基线，表明其在多模态轨迹检索中的有效性。&lt;h4&gt;结论&lt;/h4&gt;多模态轨迹检索方法能够有效提升AI代理在GUI环境中的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Trajectory data, capturing human actions and environmental states acrossvarious modalities, holds significant potential for enhancing AI agentcapabilities, particularly in GUI environments. However, how to model therepresentation of trajectory-level data presents a significant challenge thathas not been systematically addressed amid explosive trajectory data growth. Inthis work, we introduce Multimodal Trajectory Retrieval, bridging the gapbetween universal retrieval and agent-centric trajectory modeling. We constructthe Unified Agent Trajectory Dataset (UATD) from annotated demonstrations andstates across diverse real-world scenarios. Based on this, we presentGAE-Bench, a benchmark containing a large number of trajectory-based retrievalpairs. In addition, we propose GAE-Retriever, a multimodal retrieval frameworkthat adopts vision-language models and incorporates optimized contrastivelearning through a token selection and the GradCache mechanism. Comprehensiveevaluations across multiple datasets show that GAE-Retriever consistentlyoutperforms strong baselines in retrieval recall, highlighting itseffectiveness in advancing multimodal trajectory retrieval.</description>
      <author>example@mail.com (Xuan Zhang, Ziyan Jiang, Rui Meng, Yifei Leng, Zhenbang Xiao, Zora Zhiruo Wang, Yanyi Shang, Dehan Kong)</author>
      <guid isPermaLink="false">2506.22056v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Low-Rank Implicit Neural Representation via Schatten-p Quasi-Norm and Jacobian Regularization</title>
      <link>http://arxiv.org/abs/2506.22134v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to IEEE Transactions on Circuits and Systems for Video  Technology&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于CP分解的低秩张量函数（CP-INR），通过神经网络进行隐式神经表示，在图像修复、去噪和点云上采样等多维数据恢复任务中展现出优越性和通用性。&lt;h4&gt;背景&lt;/h4&gt;高阶张量适合表示多维数据，如彩色图像和视频。低秩张量表示在机器学习和计算机视觉中变得至关重要，但现有的Tucker分解等方法在提供灵活性的同时牺牲了可解释性。CP分解虽然更自然和可解释，但获得稀疏解仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于CP分解的低秩张量函数，通过神经网络进行隐式神经表示，以实现连续数据的表示，并充分利用张量数据的非线性，同时保证理论上的风险界限。&lt;h4&gt;方法&lt;/h4&gt;引入了Schatten-p半范数的变分形式，并证明了其与多线性秩最小化的关系。提出了一种基于雅可比矩阵谱范数和Hutchinson迹估计器的正则化项，以实现平滑性。该方法无需SVD，避免了显式的链式法则推导，可以作为图像去噪任务中Total Variation正则化的替代，并自然适用于连续数据。&lt;h4&gt;主要发现&lt;/h4&gt;通过大量实验，证明了该方法在图像修复、去噪和点云上采样等多维数据恢复任务中优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;所提出的CP-INR方法在多维数据恢复任务中展现出优越性和通用性，为机器学习和计算机视觉中的张量数据处理提供了一种新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Higher-order tensors are well-suited for representing multi-dimensional data,such as color images and videos. Low-rank tensor representation has becomeessential in machine learning and computer vision, but existing methods likeTucker decomposition offer flexibility at the expense of interpretability. Incontrast, while the CANDECOMP/PARAFAC (CP) decomposition provides a morenatural and interpretable tensor structure, obtaining sparse solutions remainschallenging. Leveraging the rich properties of CP decomposition, we propose aCP-based low-rank tensor function parameterized by neural networks for implicitneural representation (CP-INR). This approach enables continuous datarepresentation beyond structured grids, fully exploiting the non-linearity oftensor data with theoretical guarantees on excess risk bounds. To achieve asparse CP decomposition, we introduce a variational form of the Schatten-pquasi-norm and prove its relationship to multilinear rank minimization. Forsmoothness, we propose a regularization term based on the spectral norm of theJacobian and Hutchinson's trace estimator. Our proposed smoothnessregularization is SVD-free and avoids explicit chain rule derivations. It canserve as an alternative to Total Variation (TV) regularization in imagedenoising tasks and is naturally applicable to continuous data. Extensiveexperiments on multi-dimensional data recovery tasks, including imageinpainting, denoising, and point cloud upsampling, demonstrate the superiorityand versatility of our method compared to state-of-the-art approaches.</description>
      <author>example@mail.com (Zhengyun Cheng, Changhao Wang, Guanwen Zhang, Yi Xu, Wei Zhou, Xiangyang Ji)</author>
      <guid isPermaLink="false">2506.22134v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs</title>
      <link>http://arxiv.org/abs/2506.22139v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了Q-Frame，这是一种针对视频内容特定查询的自适应帧选择和多分辨率缩放的新方法，旨在解决视频理解任务中的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管多模态大型语言模型（MLLMs）在视觉理解任务中取得了显著成功，但在视频理解方面仍存在挑战，尤其是由于数据量大和时间复杂度高。&lt;h4&gt;目的&lt;/h4&gt;提出Q-Frame的目的是提高视频-LLMs处理视频数据的能力，有效捕获与查询相关的时空线索。&lt;h4&gt;方法&lt;/h4&gt;Q-Frame使用无训练的即插即用策略，通过文本-图像匹配网络（如CLIP）和Gumbel-Max技巧实现高效的帧选择。&lt;h4&gt;主要发现&lt;/h4&gt;Q-Frame通过在基准数据集（包括MLVU、LongVideoBench和Video-MME）上的广泛实验，证明了其在视频理解任务中的有效性，并优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;Q-Frame能够处理更多帧而不会超过计算限制，从而保留关键的时间和空间信息，适用于各种视频理解任务。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态大型语言模型（MLLMs）在视觉理解任务中取得了显著的成功。然而，由于数据量大和时间复杂度高，将这些模型应用于视频理解仍然存在挑战。现有的视频-LLMs使用均匀帧采样，往往难以有效地捕获视频中的与查询相关的关键时空线索。在本文中，我们提出了一种新的自适应帧选择和多分辨率缩放方法Q-Frame，该方法针对视频内容和特定查询进行了优化。Q-Frame采用了一种无训练的即插即用策略，通过文本-图像匹配网络（如CLIP）和Gumbel-Max技巧实现高效的帧选择。Q-Frame允许视频-LLMs处理更多帧而不超过计算限制，从而保留了关键的时间和空间信息。通过在基准数据集（包括MLVU、LongVideoBench和Video-MME）上的广泛实验，我们证明了Q-Frame的有效性，并显示了其相对于现有方法的优越性及其在各种视频理解任务中的应用性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) have demonstrated significantsuccess in visual understanding tasks. However, challenges persist in adaptingthese models for video comprehension due to the large volume of data andtemporal complexity. Existing Video-LLMs using uniform frame sampling oftenstruggle to capture the query-related crucial spatiotemporal clues of videoseffectively. In this paper, we introduce Q-Frame, a novel approach for adaptiveframe selection and multi-resolution scaling tailored to the video's contentand the specific query. Q-Frame employs a training-free, plug-and-play strategygenerated by a text-image matching network like CLIP, utilizing the Gumbel-Maxtrick for efficient frame selection. Q-Frame allows Video-LLMs to process moreframes without exceeding computational limits, thereby preserving criticaltemporal and spatial information. We demonstrate Q-Frame's effectivenessthrough extensive experiments on benchmark datasets, including MLVU,LongVideoBench, and Video-MME, illustrating its superiority over existingmethods and its applicability across various video understanding tasks.</description>
      <author>example@mail.com (Shaojie Zhang, Jiahui Yang, Jianqin Yin, Zhenbo Luo, Jian Luan)</author>
      <guid isPermaLink="false">2506.22139v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method</title>
      <link>http://arxiv.org/abs/2506.22027v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了使用地球观测影像检测和跟踪地面物体（如船只）的挑战，并提出了一种基于混合光学和合成孔径雷达（SAR）的船识别数据集（HOSS ReID）和一种基于Vision Transformer的跨模态船重识别方法（TransOSS）。&lt;h4&gt;背景&lt;/h4&gt;地球观测影像在遥感领域用于检测和跟踪地面物体是一个重大挑战。连续的船舶跟踪对于海上搜救、执法和航运分析等应用至关重要。然而，现有的船舶跟踪方法主要依赖地球静止卫星或视频卫星，这些方法存在分辨率低、受天气条件影响大、拍摄持续时间短和覆盖区域有限等问题。&lt;h4&gt;目的&lt;/h4&gt;提出HOSS ReID数据集和TransOSS方法，以评估使用低地球轨道星座的光学和SAR传感器进行船舶跟踪的有效性，并解决现有方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;HOSS ReID数据集包括在不同条件、不同卫星、不同时间和角度下拍摄的同一条船只的图像。TransOSS方法基于Vision Transformer架构，优化了嵌入结构，引入了额外的嵌入，并采用对比学习在大型光学-SAR图像对上进行预训练。&lt;h4&gt;主要发现&lt;/h4&gt;HOSS ReID数据集和TransOSS方法能够实现更短的重新成像周期和全天候跟踪，同时能够提取模态不变特征。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法和数据集为船舶跟踪提供了新的解决方案，并可在https://github.com/Alioth2000/Hoss-ReID上公开访问。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用地球观测影像检测和跟踪地面物体在遥感领域是一个重大挑战。连续的船舶跟踪对于海上搜救、执法和航运分析等应用至关重要。然而，目前大多数船舶跟踪方法依赖于地球静止卫星或视频卫星。前者提供低分辨率且易受天气条件影响，后者拍摄持续时间短且覆盖区域有限，这使得它们不太适合实际船舶跟踪的需求。为了解决这些局限性，我们提出了混合光学和合成孔径雷达（SAR）船重识别数据集（HOSS ReID数据集），用于评估使用低地球轨道星座的光学和SAR传感器进行船舶跟踪的有效性。这种方法确保了更短的重新成像周期并实现了全天候跟踪。HOSS ReID数据集包括在长时间内、在多种条件下、使用不同卫星和不同模式在不同时间和角度下捕获的同一条船只的图像。此外，我们提出了一种基于视觉Transformer架构的跨模态船舶重识别基准方法（TransOSS），该方法优化了嵌入结构以更好地适应跨模态任务，引入了额外的嵌入以引入更多参考信息，并采用对比学习在大型光学-SAR图像对上进行预训练，以确保模型能够提取模态不变特征。我们的数据集和基准方法可在https://github.com/Alioth2000/Hoss-ReID上公开访问。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting and tracking ground objects using earth observation imagery remainsa significant challenge in the field of remote sensing. Continuous maritimeship tracking is crucial for applications such as maritime search and rescue,law enforcement, and shipping analysis. However, most current ship trackingmethods rely on geostationary satellites or video satellites. The former offerlow resolution and are susceptible to weather conditions, while the latter haveshort filming durations and limited coverage areas, making them less suitablefor the real-world requirements of ship tracking. To address these limitations,we present the Hybrid Optical and Synthetic Aperture Radar (SAR) ShipRe-Identification Dataset (HOSS ReID dataset), designed to evaluate theeffectiveness of ship tracking using low-Earth orbit constellations of opticaland SAR sensors. This approach ensures shorter re-imaging cycles and enablesall-weather tracking. HOSS ReID dataset includes images of the same shipcaptured over extended periods under diverse conditions, using differentsatellites of different modalities at varying times and angles. Furthermore, wepropose a baseline method for cross-modal ship re-identification, TransOSS,which is built on the Vision Transformer architecture. It refines the patchembedding structure to better accommodate cross-modal tasks, incorporatesadditional embeddings to introduce more reference information, and employscontrastive learning to pre-train on large-scale optical-SAR image pairs,ensuring the model's ability to extract modality-invariant features. Ourdataset and baseline method are publicly available onhttps://github.com/Alioth2000/Hoss-ReID.</description>
      <author>example@mail.com (Han Wang, Shengyang Li, Jian Yang, Yuxuan Liu, Yixuan Lv, Zhuang Zhou)</author>
      <guid isPermaLink="false">2506.22027v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Pipe Reconstruction from Point Cloud Data</title>
      <link>http://arxiv.org/abs/2506.22118v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从激光扫描数据中自动重建管道的方法，以支持工业资产如船舶和海上平台的精确数字孪生。&lt;h4&gt;背景&lt;/h4&gt;精确的工业资产数字孪生需要精确重建复杂的管道网络，而手动从激光扫描数据建模管道是一个耗时且劳动密集的过程。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化管道重建流程，以支持数字孪生的快速和精确建模，同时降低成本。&lt;h4&gt;方法&lt;/h4&gt;该方法使用Laplacian基于的收缩来估计骨骼曲线，随后进行曲线延长。使用滚动球技术和2D圆拟合重新中心骨骼轴，并通过3D平滑步骤进行细化。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够确定管道的属性，包括半径、长度和方向，并有助于创建复杂管道网络的详细3D模型。&lt;h4&gt;结论&lt;/h4&gt;通过自动化管道重建，该方法支持数字孪生的开发，实现快速且精确的建模，同时降低成本。&lt;h4&gt;翻译&lt;/h4&gt;Accurate digital twins of industrial assets, such as ships and offshore platforms, rely on the precise reconstruction of complex pipe networks. However, manual modelling of pipes from laser scan data is a time-consuming and labor-intensive process. This paper presents a pipeline for automated pipe reconstruction from incomplete laser scan data. The approach estimates a skeleton curve using Laplacian-based contraction, followed by curve elongation. The skeleton axis is then recentred using a rolling sphere technique combined with 2D circle fitting, and refined with a 3D smoothing step. This enables the determination of pipe properties, including radius, length and orientation, and facilitates the creation of detailed 3D models of complex pipe networks. By automating pipe reconstruction, this approach supports the development of digital twins, allowing for rapid and accurate modeling while reducing costs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate digital twins of industrial assets, such as ships and offshoreplatforms, rely on the precise reconstruction of complex pipe networks.However, manual modelling of pipes from laser scan data is a time-consuming andlabor-intensive process. This paper presents a pipeline for automated pipereconstruction from incomplete laser scan data. The approach estimates askeleton curve using Laplacian-based contraction, followed by curve elongation.The skeleton axis is then recentred using a rolling sphere technique combinedwith 2D circle fitting, and refined with a 3D smoothing step. This enables thedetermination of pipe properties, including radius, length and orientation, andfacilitates the creation of detailed 3D models of complex pipe networks. Byautomating pipe reconstruction, this approach supports the development ofdigital twins, allowing for rapid and accurate modeling while reducing costs.</description>
      <author>example@mail.com (Antje Alex, Jannis Stoppe)</author>
      <guid isPermaLink="false">2506.22118v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Embodied Domain Adaptation for Object Detection</title>
      <link>http://arxiv.org/abs/2506.21860v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Source-Free Domain Adaptation (SFDA)的方法，用于解决移动机器人在室内环境中进行物体检测和定位的问题。该方法通过预训练模型并利用时间聚类、多尺度阈值融合和Mean Teacher框架与对比学习，实现了对动态室内条件的灵活适应，并在零样本检测性能上取得了显著提升。&lt;h4&gt;背景&lt;/h4&gt;移动机器人在室内环境中需要依赖物体检测器进行感知和定位。然而，标准的封闭集方法难以处理实际家庭和实验室中遇到的多样化和动态条件。&lt;h4&gt;目的&lt;/h4&gt;为了解决开放词汇物体检测（OVOD）在室内环境中的域迁移问题，提出了一种无需访问源数据即可适应预训练模型的方法。&lt;h4&gt;方法&lt;/h4&gt;本文采用以下方法：通过时间聚类细化伪标签、应用多尺度阈值融合、使用Mean Teacher框架结合对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;在Embodied Domain Adaptation for Object Detection (EDAOD)基准测试中，该方法在零样本检测性能和动态室内条件下的灵活适应方面表现出了显著的优势。&lt;h4&gt;结论&lt;/h4&gt;提出的SFDA方法能够显著提高移动机器人在室内环境中的物体检测性能，并能够灵活适应环境变化。&lt;h4&gt;翻译&lt;/h4&gt;Mobile robots rely on object detectors for perception and object localization in indoor environments. However, standard closed-set methods struggle to handle the diverse objects and dynamic conditions encountered in real homes and labs. Open-vocabulary object detection (OVOD), driven by Vision Language Models (VLMs), extends beyond fixed labels but still struggles with domain shifts in indoor environments. We introduce a Source-Free Domain Adaptation (SFDA) approach that adapts a pre-trained model without accessing source data. We refine pseudo labels via temporal clustering, employ multi-scale threshold fusion, and apply a Mean Teacher framework with contrastive learning. Our Embodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluates adaptation under sequential changes in lighting, layout, and object diversity. Our experiments show significant gains in zero-shot detection performance and flexible adaptation to dynamic indoor conditions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Mobile robots rely on object detectors for perception and object localizationin indoor environments. However, standard closed-set methods struggle to handlethe diverse objects and dynamic conditions encountered in real homes and labs.Open-vocabulary object detection (OVOD), driven by Vision Language Models(VLMs), extends beyond fixed labels but still struggles with domain shifts inindoor environments. We introduce a Source-Free Domain Adaptation (SFDA)approach that adapts a pre-trained model without accessing source data. Werefine pseudo labels via temporal clustering, employ multi-scale thresholdfusion, and apply a Mean Teacher framework with contrastive learning. OurEmbodied Domain Adaptation for Object Detection (EDAOD) benchmark evaluatesadaptation under sequential changes in lighting, layout, and object diversity.Our experiments show significant gains in zero-shot detection performance andflexible adaptation to dynamic indoor conditions.</description>
      <author>example@mail.com (Xiangyu Shi, Yanyuan Qiao, Lingqiao Liu, Feras Dayoub)</author>
      <guid isPermaLink="false">2506.21860v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs</title>
      <link>http://arxiv.org/abs/2506.21862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 4 figures, 7 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LLaVA-Scissor的无监督标记压缩策略，适用于视频多模态大型语言模型。&lt;h4&gt;背景&lt;/h4&gt;之前的标记压缩方法大多基于注意力分数，但未能有效捕捉所有语义区域，往往导致标记冗余。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够全面覆盖语义的方法，以优化视频理解模型的性能。&lt;h4&gt;方法&lt;/h4&gt;采用语义连通组件（SCC）方法，将标记分配到不同的语义区域，并利用SCC在空间和时间域中进行两步时空标记压缩。&lt;h4&gt;主要发现&lt;/h4&gt;LLaVA-Scissor能够通过非重叠的语义标记集来表示整个视频，有效压缩标记。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，LLaVA-Scissor在多种视频理解基准测试中优于其他标记压缩方法，特别是在低标记保留率的情况下。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we present LLaVA-Scissor, a training-free token compression strategy designed for video multimodal large language models. Previous methods mostly attempt to compress tokens based on attention scores, but fail to effectively capture all semantic regions and often lead to token redundancy. Differently, we propose to leverage the Semantic Connected Components (SCC) approach that assigns tokens to distinct semantic regions within the token set, ensuring comprehensive semantic coverage. The outcome is a two-step spatio-temporal token compression strategy that utilizes SCC in both spatial and temporal domains. This strategy can effectively compress tokens by representing the entire video with a set of non-overlapping semantic tokens. We conduct extensive evaluations of the token compression capabilities of LLaVA-Scissor across diverse video understanding benchmarks, including video question answering, long video understanding, and comprehensive multi-choices benchmarks. Experimental results show that the proposed LLaVA-Scissor outperforms other token compression methods, achieving superior performance in various video understanding benchmarks, particularly at low token retention ratios. Project page: https://github.com/HumanMLLM/LLaVA-Scissor.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we present LLaVA-Scissor, a training-free token compressionstrategy designed for video multimodal large language models. Previous methodsmostly attempt to compress tokens based on attention scores, but fail toeffectively capture all semantic regions and often lead to token redundancy.Differently, we propose to leverage the Semantic Connected Components (SCC)approach that assigns tokens to distinct semantic regions within the token set,ensuring comprehensive semantic coverage. The outcome is a two-stepspatio-temporal token compression strategy that utilizes SCC in both spatialand temporal domains. This strategy can effectively compress tokens byrepresenting the entire video with a set of non-overlapping semantic tokens. Weconduct extensive evaluations of the token compression capabilities ofLLaVA-Scissor across diverse video understanding benchmarks, including videoquestion answering, long video understanding, and comprehensive multi-choicesbenchmarks. Experimental results show that the proposed LLaVA-Scissoroutperforms other token compression methods, achieving superior performance invarious video understanding benchmarks, particularly at low token retentionratios. Project page: https://github.com/HumanMLLM/LLaVA-Scissor.</description>
      <author>example@mail.com (Boyuan Sun, Jiaxing Zhao, Xihan Wei, Qibin Hou)</author>
      <guid isPermaLink="false">2506.21862v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Cardiovascular disease classification using radiomics and geometric features from cardiac CT</title>
      <link>http://arxiv.org/abs/2506.22226v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review at STACOM 2025 with MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从CT图像自动检测和分类心血管疾病（CVD）的方法，以提高临床决策的准确性。&lt;h4&gt;背景&lt;/h4&gt;当前基于深度学习的方法大多直接处理原始CT数据或结合解剖结构分割进行端到端分类，这使得临床解释变得困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决临床解释的难题，本研究将CVD分类流程分解为三个部分：图像分割、图像配准和下游CVD分类。&lt;h4&gt;方法&lt;/h4&gt;本研究采用Atlas-ISTN框架和最新的分割基础模型生成解剖结构分割和标准健康图谱。这些被用于提取可临床解释的放射组学特征和基于图谱配准的变形场几何特征，以实现CVD分类。&lt;h4&gt;主要发现&lt;/h4&gt;在公开的ASOCA数据集上的实验表明，使用这些特征比直接在原始CT图像上训练的分类模型（准确率67.50%）具有更高的CVD分类准确率（87.50%）。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法提高了CVD分类的准确性，并通过公开代码促进了该领域的研究共享。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic detection and classification of Cardiovascular disease (CVD) fromComputed Tomography (CT) images play an important part in facilitatingbetter-informed clinical decisions. However, most of the recent deep learningbased methods either directly work on raw CT data or utilize it in pair withanatomical cardiac structure segmentation by training an end-to-end classifier.As such, these approaches become much more difficult to interpret from aclinical perspective. To address this challenge, in this work, we break downthe CVD classification pipeline into three components: (i) image segmentation,(ii) image registration, and (iii) downstream CVD classification. Specifically,we utilize the Atlas-ISTN framework and recent segmentation foundational modelsto generate anatomical structure segmentation and a normative healthy atlas.These are further utilized to extract clinically interpretable radiomicfeatures as well as deformation field based geometric features (through atlasregistration) for CVD classification. Our experiments on the publicly availableASOCA dataset show that utilizing these features leads to better CVDclassification accuracy (87.50\%) when compared against classification modeltrained directly on raw CT images (67.50\%). Our code is publicly available:https://github.com/biomedia-mira/grc-net</description>
      <author>example@mail.com (Ajay Mittal, Raghav Mehta, Omar Todd, Philipp Seeböck, Georg Langs, Ben Glocker)</author>
      <guid isPermaLink="false">2506.22226v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding</title>
      <link>http://arxiv.org/abs/2506.21957v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了语义掩码自动编码器，旨在解决基于掩码点建模的方法在下游任务中捕获合理语义关系的问题。&lt;h4&gt;背景&lt;/h4&gt;点云理解旨在从无标签数据中获取鲁棒的通用特征表示，而基于掩码点建模的方法在下游任务中表现出显著性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决自监督模型在捕获合理语义关系时的失败问题。&lt;h4&gt;方法&lt;/h4&gt;提出了两个主要组件：基于原型的组件语义建模模块和组件语义增强掩码策略。具体包括设计组件语义引导机制、组件语义增强掩码策略和组件语义增强提示调整策略。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的模块在ScanObjectNN、ModelNet40和ShapeNetPart等数据集上表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;语义掩码自动编码器能够有效提高预训练模型在下游任务中的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud understanding aims to acquire robust and general featurerepresentations from unlabeled data. Masked point modeling-based methods haverecently shown significant performance across various downstream tasks. Thesepre-training methods rely on random masking strategies to establish theperception of point clouds by restoring corrupted point cloud inputs, whichleads to the failure of capturing reasonable semantic relationships by theself-supervised models. To address this issue, we propose Semantic MaskedAutoencoder, which comprises two main components: a prototype-based componentsemantic modeling module and a component semantic-enhanced masking strategy.Specifically, in the component semantic modeling module, we design a componentsemantic guidance mechanism to direct a set of learnable prototypes incapturing the semantics of different components from objects. Leveraging theseprototypes, we develop a component semantic-enhanced masking strategy thataddresses the limitations of random masking in effectively covering completecomponent structures. Furthermore, we introduce a component semantic-enhancedprompt-tuning strategy, which further leverages these prototypes to improve theperformance of pre-trained models in downstream tasks. Extensive experimentsconducted on datasets such as ScanObjectNN, ModelNet40, and ShapeNetPartdemonstrate the effectiveness of our proposed modules.</description>
      <author>example@mail.com (Yixin Zha, Chuxin Wang, Wenfei Yang, Tianzhu Zhang)</author>
      <guid isPermaLink="false">2506.21957v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space</title>
      <link>http://arxiv.org/abs/2506.21857v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SPADE的基础模型，该模型将组织病理学与空间转录组学数据相结合，以在统一框架内引导图像表示学习，从而创建一个由空间转录组学信息指导的潜在空间。&lt;h4&gt;背景&lt;/h4&gt;数字病理学快速发展，自监督深度学习技术进步，使得在多种疾病上的病理任务中开发了基础模型。尽管多模态方法整合了不同的数据源，但在全面整合全切片图像（WSI）与空间转录组学（ST）方面仍存在关键差距，这对于捕捉超出常规苏木精和伊红（H&amp;E）染色的关键分子异质性至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够整合组织病理学与空间转录组学数据的基础模型，以改善病理学任务中的图像表示学习。&lt;h4&gt;方法&lt;/h4&gt;SPADE模型利用混合数据专家技术，通过两阶段特征空间聚类创建专家，并使用对比学习来学习共注册的全切片图像块和基因表达谱的表示。该模型在综合的HEST-1k数据集上预训练，并在14个下游任务上进行评估。&lt;h4&gt;主要发现&lt;/h4&gt;SPADE在14个下游任务上显示出与基线模型相比的显著优越的少样本性能，这突出了将形态学和分子信息整合到一个潜在空间中的好处。&lt;h4&gt;结论&lt;/h4&gt;SPADE模型通过将形态学和分子信息整合到一个潜在空间中，显著提升了病理学任务中的图像表示学习，为病理诊断提供了新的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid growth of digital pathology and advances in self-supervised deeplearning have enabled the development of foundational models for variouspathology tasks across diverse diseases. While multimodal approachesintegrating diverse data sources have emerged, a critical gap remains in thecomprehensive integration of whole-slide images (WSIs) with spatialtranscriptomics (ST), which is crucial for capturing critical molecularheterogeneity beyond standard hematoxylin &amp; eosin (H&amp;E) staining. We introduceSPADE, a foundation model that integrates histopathology with ST data to guideimage representation learning within a unified framework, in effect creating anST-informed latent space. SPADE leverages a mixture-of-data experts technique,where experts, created via two-stage feature-space clustering, use contrastivelearning to learn representations of co-registered WSI patches and geneexpression profiles. Pre-trained on the comprehensive HEST-1k dataset, SPADE isevaluated on 14 downstream tasks, demonstrating significantly superior few-shotperformance compared to baseline models, highlighting the benefits ofintegrating morphological and molecular information into one latent space.</description>
      <author>example@mail.com (Ekaterina Redekop, Mara Pleasure, Zichen Wang, Kimberly Flores, Anthony Sisk, William Speier, Corey W. Arnold)</author>
      <guid isPermaLink="false">2506.21857v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>3D-Telepathy: Reconstructing 3D Objects from EEG Signals</title>
      <link>http://arxiv.org/abs/2506.21843v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种从脑电图（EEG）数据重建3D视觉刺激的创新方法，旨在提高脑机接口（BCI）的应用效果，并帮助有交流障碍的人。&lt;h4&gt;背景&lt;/h4&gt;传统的EEG数据转换方法主要集中于将脑活动转换为2D图像，忽略了将EEG数据转换为3D对象的重要性。这种转换忽略了脑处理三维空间信息的能力，限制了其在BCI中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种从EEG数据到3D对象重建的创新方法，以解决现有方法中丢失空间信息的问题。&lt;h4&gt;方法&lt;/h4&gt;研究提出了一个集成了双重自注意力机制的EEG编码器架构，并采用混合训练策略，包括交叉注意力、对比学习和自监督学习技术。此外，通过使用稳定的扩散作为先验分布和利用变分分数蒸馏来训练神经辐射场，成功从EEG数据中生成了具有相似内容和结构的3D对象。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，EEG信号中存在大量噪声，且包含EEG和3D信息的数据集稀缺，这使得3D视觉数据的提取过程复杂化。&lt;h4&gt;结论&lt;/h4&gt;该方法有效解决了从EEG数据到3D对象重建的难题，为BCI应用提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从脑电图（EEG）数据重建3D视觉刺激在脑机接口（BCI）的应用和帮助有交流障碍的人方面具有重大潜力。传统上，努力集中在将脑活动转换为2D图像，忽视了将EEG数据转换为3D对象的过程。这一局限性值得注意，因为人类大脑天生能够处理三维空间信息，无论观察的是2D图像还是现实世界。通过脑电图捕获的神经活动包含丰富的空间信息，在仅重建2D图像时不可避免地会丢失，从而限制了其在BCI中的实际应用。从EEG数据到3D对象重建的过渡面临着相当大的障碍。这些包括EEG信号中的广泛噪声以及包含EEG和3D信息的数据集稀缺，这使3D视觉数据的提取过程复杂化。面对这项具有挑战性的任务，我们提出了一种集成了双重自注意力机制的创新的EEG编码器架构。我们使用混合训练策略来训练EEG编码器，包括交叉注意力、对比学习和自监督学习技术。此外，通过采用稳定的扩散作为先验分布，并利用变分分数蒸馏来训练神经辐射场，我们成功地从EEG数据中生成了具有相似内容和结构的3D对象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing 3D visual stimuli from Electroencephalography (EEG) data holdssignificant potential for applications in Brain-Computer Interfaces (BCIs) andaiding individuals with communication disorders. Traditionally, efforts havefocused on converting brain activity into 2D images, neglecting the translationof EEG data into 3D objects. This limitation is noteworthy, as the human braininherently processes three-dimensional spatial information regardless ofwhether observing 2D images or the real world. The neural activities capturedby EEG contain rich spatial information that is inevitably lost whenreconstructing only 2D images, thus limiting its practical applications in BCI.The transition from EEG data to 3D object reconstruction faces considerableobstacles. These include the presence of extensive noise within EEG signals anda scarcity of datasets that include both EEG and 3D information, whichcomplicates the extraction process of 3D visual data. Addressing thischallenging task, we propose an innovative EEG encoder architecture thatintegrates a dual self-attention mechanism. We use a hybrid training strategyto train the EEG Encoder, which includes cross-attention, contrastive learning,and self-supervised learning techniques. Additionally, by employing stablediffusion as a prior distribution and utilizing Variational Score Distillationto train a neural radiation field, we successfully generate 3D objects withsimilar content and structure from EEG data.</description>
      <author>example@mail.com (Yuxiang Ge, Jionghao Cheng, Ruiquan Ge, Zhaojie Fang, Gangyong Jia, Xiang Wan, Nannan Li, Ahmed Elazab, Changmiao Wang)</author>
      <guid isPermaLink="false">2506.21843v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition</title>
      <link>http://arxiv.org/abs/2506.22179v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FS-VAE的模型，用于零样本骨骼动作识别，通过频率分解探索骨骼语义表示学习，以增强零样本动作识别的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;现有方法主要关注视觉和语义表示的对齐，但往往忽略了语义空间中细粒度动作模式的重要性。&lt;h4&gt;目的&lt;/h4&gt;提出FS-VAE模型，旨在解决现有方法在处理细粒度动作模式时的不足，提高零样本动作识别的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;FS-VAE模型包括三个关键组件：1) 基于频率的增强模块，通过高低频调整丰富骨骼语义学习并提高鲁棒性；2) 基于语义的动作描述，通过多级对齐捕捉局部细节和全局对应关系；3) 校准的交叉对齐损失，以平衡骨骼和文本特征中的歧义和模糊性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，频率增强的语义特征能够有效区分视觉和语义相似的动作簇，从而提高零样本动作识别的准确性。&lt;h4&gt;结论&lt;/h4&gt;FS-VAE模型通过频率分解和语义增强，显著提高了零样本骨骼动作识别的性能。&lt;h4&gt;翻译&lt;/h4&gt;Zero-shot skeleton-based action recognition aims to develop models capable of identifying actions beyond the categories encountered during training. Previous approaches have primarily focused on aligning visual and semantic representations but often overlooked the importance of fine-grained action patterns in the semantic space (e.g., the hand movements in drinking water and brushing teeth). To address these limitations, we propose a Frequency-Semantic Enhanced Variational Autoencoder (FS-VAE) to explore the skeleton semantic representation learning with frequency decomposition. FS-VAE consists of three key components: 1) a frequency-based enhancement module with high- and low-frequency adjustments to enrich the skeletal semantics learning and improve the robustness of zero-shot action recognition; 2) a semantic-based action description with multilevel alignment to capture both local details and global correspondence, effectively bridging the semantic gap and compensating for the inherent loss of information in skeleton sequences; 3) a calibrated cross-alignment loss that enables valid skeleton-text pairs to counterbalance ambiguous ones, mitigating discrepancies and ambiguities in skeleton and text features, thereby ensuring robust alignment. Evaluations on the benchmarks demonstrate the effectiveness of our approach, validating that frequency-enhanced semantic features enable robust differentiation of visually and semantically similar action clusters, improving zero-shot action recognition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Zero-shot skeleton-based action recognition aims to develop models capable ofidentifying actions beyond the categories encountered during training. Previousapproaches have primarily focused on aligning visual and semanticrepresentations but often overlooked the importance of fine-grained actionpatterns in the semantic space (e.g., the hand movements in drinking water andbrushing teeth). To address these limitations, we propose a Frequency-SemanticEnhanced Variational Autoencoder (FS-VAE) to explore the skeleton semanticrepresentation learning with frequency decomposition. FS-VAE consists of threekey components: 1) a frequency-based enhancement module with high- andlow-frequency adjustments to enrich the skeletal semantics learning and improvethe robustness of zero-shot action recognition; 2) a semantic-based actiondescription with multilevel alignment to capture both local details and globalcorrespondence, effectively bridging the semantic gap and compensating for theinherent loss of information in skeleton sequences; 3) a calibratedcross-alignment loss that enables valid skeleton-text pairs to counterbalanceambiguous ones, mitigating discrepancies and ambiguities in skeleton and textfeatures, thereby ensuring robust alignment. Evaluations on the benchmarksdemonstrate the effectiveness of our approach, validating thatfrequency-enhanced semantic features enable robust differentiation of visuallyand semantically similar action clusters, improving zero-shot actionrecognition.</description>
      <author>example@mail.com (Wenhan Wu, Zhishuai Guo, Chen Chen, Hongfei Xue, Aidong Lu)</author>
      <guid isPermaLink="false">2506.22179v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation</title>
      <link>http://arxiv.org/abs/2506.21892v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的方法SODA，用于点云数据中的异常检测，以提高模型在实际任务中的安全性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;随着点云数据在各种应用中的普及，检测异常点云对象的能力变得至关重要。然而，这个问题在现有研究中尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;利用3D视觉语言模型（3D VLMs）在点云对象中进行异常检测。&lt;h4&gt;方法&lt;/h4&gt;针对3D VLMs在预训练数据集上的规模和对象多样性不足的问题，提出了一种基于邻域评分传播方案的方法SODA，以改善异常点云的检测。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，从合成到真实领域的迁移会导致点云与其相关文本嵌入在3D VLM潜在空间中的对齐度下降，从而阻碍下游性能。&lt;h4&gt;结论&lt;/h4&gt;SODA是一种基于推理的方法，无需额外模型训练，在多个数据集和问题设置上实现了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;As point cloud data becomes more common in various applications, the ability to detect out-of-distribution (OOD) point cloud objects becomes critical for ensuring model safety and reliability. However, this problem remains under-explored in existing research. Inspired by success in the image domain, we propose to exploit advances in 3D vision-language models (3D VLMs) for OOD detection in point cloud objects. However, a major challenge is that point cloud datasets used to pre-train 3D VLMs are drastically smaller in size and object diversity than their image-based counterparts. Critically, they often contain exclusively computer-designed synthetic objects. This leads to a substantial domain shift when the model is transferred to practical tasks involving real objects scanned from the physical environment. In this paper, our empirical experiments show that synthetic-to-real domain shift significantly degrades the alignment of point cloud with their associated text embeddings in the 3D VLM latent space, hindering downstream performance. To address this, we propose a novel methodology called SODA which improves the detection of OOD point clouds through a neighborhood-based score propagation scheme. SODA is inference-based, requires no additional model training, and achieves state-of-the-art performance over existing approaches across datasets and problem settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As point cloud data increases in prevalence in a variety of applications, theability to detect out-of-distribution (OOD) point cloud objects becomescritical for ensuring model safety and reliability. However, this problemremains under-explored in existing research. Inspired by success in the imagedomain, we propose to exploit advances in 3D vision-language models (3D VLMs)for OOD detection in point cloud objects. However, a major challenge is thatpoint cloud datasets used to pre-train 3D VLMs are drastically smaller in sizeand object diversity than their image-based counterparts. Critically, theyoften contain exclusively computer-designed synthetic objects. This leads to asubstantial domain shift when the model is transferred to practical tasksinvolving real objects scanned from the physical environment. In this paper,our empirical experiments show that synthetic-to-real domain shiftsignificantly degrades the alignment of point cloud with their associated textembeddings in the 3D VLM latent space, hindering downstream performance. Toaddress this, we propose a novel methodology called SODA which improves thedetection of OOD point clouds through a neighborhood-based score propagationscheme. SODA is inference-based, requires no additional model training, andachieves state-of-the-art performance over existing approaches across datasetsand problem settings.</description>
      <author>example@mail.com (Adam Goodge, Xun Xu, Bryan Hooi, Wee Siong Ng, Jingyi Liao, Yongyi Su, Xulei Yang)</author>
      <guid isPermaLink="false">2506.21892v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety</title>
      <link>http://arxiv.org/abs/2506.22183v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Proceedings from the Columbia Convening on Openness in Artificial  Intelligence and AI Safety&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文总结了哥伦比亚AI开放与安全会议的结果，探讨了开源基础模型的发展对AI系统安全的挑战和机遇。&lt;h4&gt;背景&lt;/h4&gt;开源和开放重量级基础模型的迅速发展，加剧了确保AI系统安全的义务，并重塑了相关机会。&lt;h4&gt;目的&lt;/h4&gt;报告哥伦比亚AI开放与安全会议及其六周的预备项目成果，该项目涉及来自学术界、工业界、民间社会和政府的研究人员、工程师和政策领导者。&lt;h4&gt;方法&lt;/h4&gt;采用参与式、以解决方案为导向的过程，工作小组产生了（i）一个安全和开源AI交叉的研究议程；（ii）现有和所需的技术干预措施以及开源工具的映射，以安全、负责任地部署开放基础模型；（iii）内容安全过滤生态系统映射以及未来研究和发展的路线图。&lt;h4&gt;主要发现&lt;/h4&gt;开放（透明权重、互操作性工具和公共治理）可以通过使独立审查、去中心化缓解和文化多元监督成为可能来提高安全性。然而，仍存在重大差距：缺乏多模态和多语言基准、在代理系统中对提示注入和组合攻击的防御有限，以及社区参与机制不足。&lt;h4&gt;结论&lt;/h4&gt;论文以五个优先研究方向的路线图结束，强调参与式输入、未来证明的内容过滤器、生态系统范围的安全基础设施、严格的代理保护以及扩展的伤害分类法。这些建议为2025年2月的法国AI行动峰会提供了信息，并为一个开放、多元和负责任的AI安全学科奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;本文报道了哥伦比亚AI开放与安全会议（2024年11月11日，旧金山）及其六周的预备项目成果，该项目涉及来自学术界、工业界、民间社会和政府的研究人员、工程师和政策领导者。通过参与式、以解决方案为导向的过程，工作组产生了（i）一个交叉于安全和开源AI的研究议程；（ii）现有和所需的技术干预措施以及开源工具的映射，以安全、负责任地部署开放基础模型；（iii）内容安全过滤生态系统映射以及未来研究和发展的路线图。我们发现，开放（理解为透明权重、互操作性工具和公共治理）可以通过使独立审查、去中心化缓解和文化多元监督成为可能来提高安全性。然而，仍存在重大差距：缺乏多模态和多语言基准、在代理系统中对提示注入和组合攻击的防御有限，以及社区参与机制不足。论文以五个优先研究方向的路线图结束，强调参与式输入、未来证明的内容过滤器、生态系统范围的安全基础设施、严格的代理保护以及扩展的伤害分类法。这些建议为2025年2月的法国AI行动峰会提供了信息，并为一个开放、多元和负责任的AI安全学科奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid rise of open-weight and open-source foundation models isintensifying the obligation and reshaping the opportunity to make AI systemssafe. This paper reports outcomes from the Columbia Convening on AI Opennessand Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programmeinvolving more than forty-five researchers, engineers, and policy leaders fromacademia, industry, civil society, and government. Using a participatory,solutions-oriented process, the working groups produced (i) a research agendaat the intersection of safety and open source AI; (ii) a mapping of existingand needed technical interventions and open source tools to safely andresponsibly deploy open foundation models across the AI development workflow;and (iii) a mapping of the content safety filter ecosystem with a proposedroadmap for future research and development. We find that openness --understood as transparent weights, interoperable tooling, and public governance-- can enhance safety by enabling independent scrutiny, decentralizedmitigation, and culturally plural oversight. However, significant gaps persist:scarce multimodal and multilingual benchmarks, limited defenses againstprompt-injection and compositional attacks in agentic systems, and insufficientparticipatory mechanisms for communities most affected by AI harms. The paperconcludes with a roadmap of five priority research directions, emphasizingparticipatory inputs, future-proof content filters, ecosystem-wide safetyinfrastructure, rigorous agentic safeguards, and expanded harm taxonomies.These recommendations informed the February 2025 French AI Action Summit andlay groundwork for an open, plural, and accountable AI safety discipline.</description>
      <author>example@mail.com (Camille François, Ludovic Péran, Ayah Bdeir, Nouha Dziri, Will Hawkins, Yacine Jernite, Sayash Kapoor, Juliet Shen, Heidy Khlaaf, Kevin Klyman, Nik Marda, Marie Pellat, Deb Raji, Divya Siddarth, Aviya Skowron, Joseph Spisak, Madhulika Srikumar, Victor Storchan, Audrey Tang, Jen Weedon)</author>
      <guid isPermaLink="false">2506.22183v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Transfer Learning for Assessing Heavy Metal Pollution in Seaports Sediments</title>
      <link>http://arxiv.org/abs/2506.22096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的模型，用于简化土壤和港口重金属污染的检测过程，以提高重金属污染评估的准确性和效率。&lt;h4&gt;背景&lt;/h4&gt;重金属污染对区域环境监测至关重要，但传统的污染负荷指数（PLI）评估方法耗时且数据分析复杂。&lt;h4&gt;目的&lt;/h4&gt;开发一种简化重金属评估过程的模型，并解决水-沉积物领域中数据稀缺的问题。&lt;h4&gt;方法&lt;/h4&gt;利用迁移学习技术，提出了一种预测PLI的准确量化评估方法，该模型可以跨不同特征集的领域转移学习到的特征。&lt;h4&gt;主要发现&lt;/h4&gt;模型在六个主要港口的数据评估中表现出色，平均绝对误差（MAE）和平均绝对百分比误差（MAPE）分别降低了约0.5和0.03，性能比其他基准模型高两个数量级。&lt;h4&gt;结论&lt;/h4&gt;该模型提供了一种创新、易用且经济的预测水质的方法，有助于海洋生物保护、水产养殖和工业污染监测。&lt;h4&gt;翻译&lt;/h4&gt;摘要：检测土壤和港口的重金属污染对于区域环境监测至关重要。污染负荷指数（PLI）是国际标准，常用于评估重金属含量。然而，传统的PLI评估方法涉及繁琐的程序和沉积物样本的数据分析。为了解决这一挑战，我们提出了一种基于深度学习的模型，简化了重金属评估过程。我们的模型解决了水-沉积物领域中数据稀缺的问题，该领域传统上受到数据收集困难和各国标准不一的挑战。通过利用迁移学习，我们开发了一种准确的量化评估方法，用于预测PLI。我们的方法允许在不同特征集的领域之间转移学习到的特征。我们使用澳大利亚新南威尔士州六个主要港口的数据评估了我们的模型：Yamba港、Newcastle港、Jackson港、Botany港、Kembla港和Eden港。结果表明，与其它模型相比，平均绝对误差（MAE）和平均绝对百分比误差（MAPE）分别降低了约0.5和0.03。我们的模型性能比其他基准模型高两个数量级。我们提出的模型提供了一种创新、易用且经济的预测水质的方法，有助于海洋生物保护、水产养殖和工业污染监测。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detecting heavy metal pollution in soils and seaports is vital for regionalenvironmental monitoring. The Pollution Load Index (PLI), an internationalstandard, is commonly used to assess heavy metal containment. However, theconventional PLI assessment involves laborious procedures and data analysis ofsediment samples. To address this challenge, we propose a deep-learning-basedmodel that simplifies the heavy metal assessment process. Our model tackles theissue of data scarcity in the water-sediment domain, which is traditionallyplagued by challenges in data collection and varying standards across nations.By leveraging transfer learning, we develop an accurate quantitative assessmentmethod for predicting PLI. Our approach allows the transfer of learned featuresacross domains with different sets of features. We evaluate our model usingdata from six major ports in New South Wales, Australia: Port Yamba, PortNewcastle, Port Jackson, Port Botany, Port Kembla, and Port Eden. The resultsdemonstrate significantly lower Mean Absolute Error (MAE) and Mean AbsolutePercentage Error (MAPE) of approximately 0.5 and 0.03, respectively, comparedto other models. Our model performance is up to 2 orders of magnitude thanother baseline models. Our proposed model offers an innovative, accessible, andcost-effective approach to predicting water quality, benefiting marine lifeconservation, aquaculture, and industrial pollution monitoring.</description>
      <author>example@mail.com (Tin Lai, Farnaz Farid, Yueyang Kuan, Xintian Zhang)</author>
      <guid isPermaLink="false">2506.22096v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21724v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  for associated source code, see  https://github.com/RFLeijenaar/AsymDSD&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了AsymDSD框架，用于从无结构的3D点云中学习语义上有意义的表示，解决了自监督3D学习中重建目标限制语义捕获能力的问题。&lt;h4&gt;背景&lt;/h4&gt;在计算机视觉中，从无结构的3D点云中学习有意义的表示是一个关键挑战，特别是在没有大规模标记数据集的情况下。现有的自监督3D学习方法，如掩码点建模（MPM），存在重建目标限制语义捕获能力的问题。&lt;h4&gt;目的&lt;/h4&gt;提出AsymDSD框架，旨在通过预测潜空间中的信息，而不是输入空间，来统一掩码建模和不变性学习，以更好地捕捉高级语义。&lt;h4&gt;方法&lt;/h4&gt;AsymDSD基于联合嵌入架构，并引入了几个关键设计选择：高效的非对称设置、禁用掩码查询之间的注意力以防止形状泄漏、多掩码采样以及点云的多裁剪适应。&lt;h4&gt;主要发现&lt;/h4&gt;AsymDSD在ScanObjectNN数据集上实现了最先进的90.53%的结果，在预训练于930k个形状后进一步提升到93.72%，超过了之前的方法。&lt;h4&gt;结论&lt;/h4&gt;AsymDSD框架在自监督3D学习中表现出色，为从无结构的3D点云中学习高级语义提供了有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning semantically meaningful representations from unstructured 3D pointclouds remains a central challenge in computer vision, especially in theabsence of large-scale labeled datasets. While masked point modeling (MPM) iswidely used in self-supervised 3D learning, its reconstruction-based objectivecan limit its ability to capture high-level semantics. We propose AsymDSD, anAsymmetric Dual Self-Distillation framework that unifies masked modeling andinvariance learning through prediction in the latent space rather than theinput space. AsymDSD builds on a joint embedding architecture and introducesseveral key design choices: an efficient asymmetric setup, disabling attentionbetween masked queries to prevent shape leakage, multi-mask sampling, and apoint cloud adaptation of multi-crop. AsymDSD achieves state-of-the-art resultson ScanObjectNN (90.53%) and further improves to 93.72% when pretrained on 930kshapes, surpassing prior methods.</description>
      <author>example@mail.com (Remco F. Leijenaar, Hamidreza Kasaei)</author>
      <guid isPermaLink="false">2506.21724v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>RetFiner: A Vision-Language Refinement Scheme for Retinal Foundation Models</title>
      <link>http://arxiv.org/abs/2506.22149v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for presentation at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RetFiner的自监督学习视觉语言细化方案，旨在提高现有OCT基础模型的表现，使其能够更有效地适应特定人群和应用。&lt;h4&gt;背景&lt;/h4&gt;光学相干断层扫描（OCT）和深度学习（DL）的进步使得临床医生和研究人员能够简化视网膜疾病分期。自监督学习（SSL）是一种流行的深度学习方法，它通过大量未标记数据学习，避免了昂贵的标注过程。&lt;h4&gt;目的&lt;/h4&gt;针对现有OCT基础模型在复杂任务中的表现不足，以及需要监督微调以适应特定应用和人群的问题，提出RetFiner方案。&lt;h4&gt;方法&lt;/h4&gt;RetFiner利用文本数据中的丰富监督信号，采用多样化的训练目标来改进现有基础模型的表现，并使其能够直接适应特定人群。&lt;h4&gt;主要发现&lt;/h4&gt;在七个高度多样化的OCT分类任务上，RetFiner在RETFound、UrFound和VisionFM三个视网膜基础模型上实现了显著的性能提升，平均提高了5.8、3.9和2.1个百分点。&lt;h4&gt;结论&lt;/h4&gt;RetFiner能够有效提高现有OCT基础模型的表现，为视网膜疾病分期提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着光学相干断层扫描（OCT）等成像技术的兴起和深度学习（DL）的进步，临床医生和研究人员能够简化视网膜疾病分期。自监督学习（SSL）是一种流行的深度学习方法，它通过大量未标记数据学习，避免了昂贵的标注过程。SSL允许开发基础模型（FMs），这些大型模型可以用于各种下游任务。然而，现有的仅基于图像数据训练的OCT FMs缺乏对图像的全面和稳健的语义理解，这从它们的下游性能（尤其是对于复杂任务）中可以看出，因此需要监督微调（这可能不可行）以更好地适应特定的应用和人群。为了解决这个问题，我们提出了RetFiner，一种自监督学习视觉语言细化方案，它改进了现有FMs的表现，并使其能够高效直接地适应特定人群以改善下游性能。我们的方法使用了一组多样化的训练目标，这些目标利用了文本数据中丰富的监督信号。我们在RETFound、UrFound和VisionFM视网膜FMs上测试了RetFiner，在七个高度多样化的OCT分类任务上显示出显著的线性探测性能提升，分别比基线提高了5.8、3.9和2.1个百分点。我们的代码和模型权重在https://github.com/ronnief1/RetFiner上公开可用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rise of imaging techniques such as optical coherence tomography (OCT) andadvances in deep learning (DL) have enabled clinicians and researchers tostreamline retinal disease staging. A popular DL approach is self-supervisedlearning (SSL), where models learn from vast amounts of unlabeled data,avoiding costly annotation. SSL has allowed the development of foundationmodels (FMs), large models that can be used for a variety of downstream tasks.However, existing FMs for OCT, trained solely on image data, lack acomprehensive and robust semantic understanding of images, as evidenced bytheir downstream performance (especially for complex tasks), and thus requiresupervised fine-tuning (which may be unfeasible) to better adapt to specificapplications and populations. To address this, we propose RetFiner, an SSLvision-language refinement scheme that improves the representations of existingFMs and enables their efficient and direct adaptation to specific populationsfor improved downstream performance. Our method uses a diverse set of trainingobjectives which take advantage of the rich supervisory signal found in textualdata. We tested RetFiner on the retinal FMs RETFound, UrFound, and VisionFM,showing significant improvements in linear probing performance on seven highlydiverse OCT classification tasks, with an average increase of 5.8, 3.9, and 2.1percentage points over their baselines, respectively. Our code and modelweights are publicly available at https://github.com/ronnief1/RetFiner.</description>
      <author>example@mail.com (Ronald Fecso, José Morano, Ursula Schmidt-Erfurth, Hrvoje Bogunović)</author>
      <guid isPermaLink="false">2506.22149v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Explainable anomaly detection for sound spectrograms using pooling statistics with quantile differences</title>
      <link>http://arxiv.org/abs/2506.21921v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对光谱图进行异常检测的方法，该方法基于统计评估，具有内在的可解释性，特别适合工业环境中的应用。&lt;h4&gt;背景&lt;/h4&gt;异常检测是识别数据集中罕见样本的任务，这些样本与几乎所有其他样本不同。由于异常样本的模式通常不是事先已知的，因此这项任务极具挑战性。在工业4.0的各个应用中，对异常声音检测（ASD）的重要性日益凸显。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种适用于光谱图的异常检测方法，以解决工业领域中智能算法应用中的争议。&lt;h4&gt;方法&lt;/h4&gt;提出的方法基于统计评估，并具有理论上的合理性。该方法具有内在的可解释性，使其特别适合于工业环境。&lt;h4&gt;主要发现&lt;/h4&gt;该方法对光谱图进行异常检测，并具有内在的可解释性，适合于工业环境中的应用。&lt;h4&gt;结论&lt;/h4&gt;该算法对于需要避免或不适于使用黑盒算法的应用场景具有相关性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：异常检测是识别数据集中罕见（即异常或异常）样本的任务，这些样本几乎与数据集中的所有其他样本都不同。由于异常样本的模式通常不是事先已知的，因此这项任务极具挑战性。因此，异常检测位于半监督学习和无监督学习之间。在声音数据中检测异常，通常称为'ASD'（异常声音检测），是一个子领域，涉及识别声学记录中的新且未知的效果。这对于工业4.0中的各种应用具有重要意义。在这里，振动或声学数据通常是从用于预测维护的标准传感器信号中获得的。例如，包括机器状态监控或质量保证，以跟踪组件或产品的状态。然而，智能算法的使用仍然是一个有争议的话题。管理层一般旨在降低成本和自动化，而质量和维护专家强调需要人类专业知识和可理解解决方案。在本工作中，我们提出了一种专门为光谱图设计的异常检测方法。该方法基于统计评估，并在理论上具有动机。此外，它具有内在的可解释性，使其特别适合于工业环境中的应用。因此，该算法对于需要避免或不适于使用黑盒算法的应用场景具有相关性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection is the task of identifying rarely occurring (i.e. anormalor anomalous) samples that differ from almost all other samples in a dataset.As the patterns of anormal samples are usually not known a priori, this task ishighly challenging. Consequently, anomaly detection lies between semi- andunsupervised learning. The detection of anomalies in sound data, often called'ASD' (Anomalous Sound Detection), is a sub-field that deals with theidentification of new and yet unknown effects in acoustic recordings. It is ofgreat importance for various applications in Industry 4.0. Here, vibrational oracoustic data are typically obtained from standard sensor signals used forpredictive maintenance. Examples cover machine condition monitoring or qualityassurance to track the state of components or products. However, the use ofintelligent algorithms remains a controversial topic. Management generally aimsfor cost-reduction and automation, while quality and maintenance expertsemphasize the need for human expertise and comprehensible solutions. In thiswork, we present an anomaly detection approach specifically designed forspectrograms. The approach is based on statistical evaluations and istheoretically motivated. In addition, it features intrinsic explainability,making it particularly suitable for applications in industrial settings. Thus,this algorithm is of relevance for applications in which black-box algorithmsare unwanted or unsuitable.</description>
      <author>example@mail.com (Nicolas Thewes, Philipp Steinhauer, Patrick Trampert, Markus Pauly, Georg Schneider)</author>
      <guid isPermaLink="false">2506.21921v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SAGE: Spliced-Audio Generated Data for Enhancing Foundational Models in Low-Resource Arabic-English Code-Switched Speech Recognition</title>
      <link>http://arxiv.org/abs/2506.22143v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for IEEE MLSP 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了各种语音SSL模型在方言阿拉伯语（DA）和阿拉伯-英语代码转换（CS）语音上的性能。&lt;h4&gt;背景&lt;/h4&gt;针对数据稀缺问题，引入了一种改进的音频拼接方法来生成人工CS语音数据。&lt;h4&gt;目的&lt;/h4&gt;通过微调SSL模型和使用SAGE数据，旨在提高Word Error Rate（WER）。&lt;h4&gt;方法&lt;/h4&gt;使用经验回放（ER）启发的方法来增强DA和CS语音的泛化能力，同时减轻灾难性遗忘。此外，集成域外3-gram语言模型以减少整体平均WER。&lt;h4&gt;主要发现&lt;/h4&gt;与阿拉伯和英语CS基准相比，使用SAGE数据微调SSL模型使WER绝对提高了7.8%。采用ER方法后，整体平均WER从31.7%降至26.6%。对于代码转换基准的少量样本微调进一步将WER提高了4.9%。在阿拉伯-英语CS基准上，WER达到31.1%，超过大规模多语言模型USM和Whisper-large-v2，分别高出5.5%和8.4%。&lt;h4&gt;结论&lt;/h4&gt;提出的改进方法和模型在DA和CS语音上的性能显著提高，超越了现有的多语言模型。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the performance of various speech SSL models ondialectal Arabic (DA) and Arabic-English code-switched (CS) speech. To addressdata scarcity, a modified audio-splicing approach is introduced to generateartificial CS speech data. Fine-tuning an already fine-tuned SSL model with theproposed Spliced-Audio Generated (SAGE) data results in an absolute improvementon Word Error Rate (WER) of 7.8% on Arabic and English CS benchmarks.Additionally, an Experience Replay (ER) inspired approach is proposed toenhance generalisation across DA and CS speech while mitigating catastrophicforgetting. Integrating an out-of-domain 3-gram language model reduces theoverall mean WER from 31.7% to 26.6%. Few-shot fine-tuning for code-switchingbenchmarks further improves WER by 4.9%. A WER of 31.1% on Arabic-English CSbenchmarks surpasses large-scale multilingual models, including USM andWhisper-large-v2 (both over ten times larger) by an absolute margin of 5.5% and8.4%, respectively.</description>
      <author>example@mail.com (Muhammad Umar Farooq, Oscar Saz)</author>
      <guid isPermaLink="false">2506.22143v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>CaloHadronic: a diffusion model for the generation of hadronic showers</title>
      <link>http://arxiv.org/abs/2506.21720v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了使用机器学习模拟高粒度量能器中粒子淋浴的关键进展，提出了基于扩散的生成式淋浴模拟方法，并扩展了用于模拟国际大型探测器（ILD）电磁量能器中电磁淋浴的架构。&lt;h4&gt;背景&lt;/h4&gt;模拟高粒度量能器中的粒子淋浴对于机器学习在粒子物理学中的应用是一个关键前沿领域。&lt;h4&gt;目的&lt;/h4&gt;通过使用生成式机器学习模型实现高精度和速度，以增强传统模拟并缓解计算限制。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于扩散的生成式淋浴模拟方法，该方法不依赖于固定结构，而是生成与几何无关的点云。此外，扩展了用于模拟电磁淋浴的架构，并引入了注意力机制。&lt;h4&gt;主要发现&lt;/h4&gt;注意力机制使得能够生成具有更明显子结构的复杂强子淋浴，这些淋浴跨越电磁和强子量能器。这是首次在高度粒度成像量能器系统中使用机器学习方法来整体生成电磁和强子量能器中的淋浴。&lt;h4&gt;结论&lt;/h4&gt;基于扩散的生成式淋浴模拟方法和扩展的架构在模拟粒子淋浴方面表现出高效性，为机器学习在粒子物理学中的应用提供了新的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Simulating showers of particles in highly-granular calorimeters is a keyfrontier in the application of machine learning to particle physics. Achievinghigh accuracy and speed with generative machine learning models can enable themto augment traditional simulations and alleviate a major computing constraint.Recent developments have shown how diffusion based generative shower simulationapproaches that do not rely on a fixed structure, but instead generategeometry-independent point clouds, are very efficient. We present atransformer-based extension to previous architectures which were developed forsimulating electromagnetic showers in the highly granular electromagneticcalorimeter of the International Large Detector, ILD. The attention mechanismnow allows us to generate complex hadronic showers with more pronouncedsubstructure across both the electromagnetic and hadronic calorimeters. This isthe first time that machine learning methods are used to holistically generateshowers across the electromagnetic and hadronic calorimeter in highly granularimaging calorimeter systems.</description>
      <author>example@mail.com (Thorsten Buss, Frank Gaede, Gregor Kasieczka, Anatolii Korol, Katja Krüger, Peter McKeown, Martina Mozzanica)</author>
      <guid isPermaLink="false">2506.21720v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation</title>
      <link>http://arxiv.org/abs/2506.21233v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于数据质量的开放词汇语义分割（OVS）方法，旨在无需昂贵模型微调的情况下，对任意文本类别进行图像分割。&lt;h4&gt;背景&lt;/h4&gt;现有的OVS方法通常依赖于预训练模型的注意力机制或生成合成数据，但性能受限于依赖模型的性能或参考集的质量。&lt;h4&gt;目的&lt;/h4&gt;研究数据质量对OVS性能的影响，并引入一个以数据质量为导向的框架。&lt;h4&gt;方法&lt;/h4&gt;该框架包括一个数据管道来构建高质量的参考集，以及一个基于相似度的检索过程。&lt;h4&gt;主要发现&lt;/h4&gt;高质量的参考集对无监督OVS有显著益处。&lt;h4&gt;结论&lt;/h4&gt;该方法在十个基准数据集上的评估中优于所有现有的无监督OVS方法，强调了数据中心设计在无需训练的情况下推进OVS的重要性。&lt;h4&gt;翻译&lt;/h4&gt;Training-free open-vocabulary semantic segmentation (OVS) aims to segment images given a set of arbitrary textual categories without costly model fine-tuning. Existing solutions often explore attention mechanisms of pre-trained models, such as CLIP, or generate synthetic data and design complex retrieval processes to perform OVS. However, their performance is limited by the capability of reliant models or the suboptimal quality of reference sets. In this work, we investigate the largely overlooked data quality problem for this challenging dense scene understanding task, and identify that a high-quality reference set can significantly benefit training-free OVS. With this observation, we introduce a data-quality-oriented framework, comprising a data pipeline to construct a reference set with well-paired segment-text embeddings and a simple similarity-based retrieval to unveil the essential effect of data. Remarkably, extensive evaluations on ten benchmark datasets demonstrate that our method outperforms all existing training-free OVS approaches, highlighting the importance of data-centric design for advancing OVS without training. Our code is available at https://github.com/xiweix/ReME .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training-free open-vocabulary semantic segmentation (OVS) aims to segmentimages given a set of arbitrary textual categories without costly modelfine-tuning. Existing solutions often explore attention mechanisms ofpre-trained models, such as CLIP, or generate synthetic data and design complexretrieval processes to perform OVS. However, their performance is limited bythe capability of reliant models or the suboptimal quality of reference sets.In this work, we investigate the largely overlooked data quality problem forthis challenging dense scene understanding task, and identify that ahigh-quality reference set can significantly benefit training-free OVS. Withthis observation, we introduce a data-quality-oriented framework, comprising adata pipeline to construct a reference set with well-paired segment-textembeddings and a simple similarity-based retrieval to unveil the essentialeffect of data. Remarkably, extensive evaluations on ten benchmark datasetsdemonstrate that our method outperforms all existing training-free OVSapproaches, highlighting the importance of data-centric design for advancingOVS without training. Our code is available at https://github.com/xiweix/ReME .</description>
      <author>example@mail.com (Xiwei Xuan, Ziquan Deng, Kwan-Liu Ma)</author>
      <guid isPermaLink="false">2506.21233v2</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Transformers are Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.22084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper is a technical version of an article in The Gradient at  https://thegradient.pub/transformers-are-graph-neural-networks/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了Transformer架构与图神经网络（GNNs）之间的联系，并展示了Transformer如何在图上进行消息传递，从而在图表示学习中发挥作用。&lt;h4&gt;背景&lt;/h4&gt;Transformer最初是为自然语言处理而引入的，而GNNs则用于图上的表示学习。&lt;h4&gt;目的&lt;/h4&gt;研究Transformer架构与GNNs之间的数学联系，并探讨其在图表示学习中的应用。&lt;h4&gt;方法&lt;/h4&gt;本文展示了如何将Transformer视为在标记的完全连接图上操作的消息传递GNNs，其中自注意力机制捕捉所有标记之间的相对重要性，位置编码提供关于序列顺序或结构的线索。&lt;h4&gt;主要发现&lt;/h4&gt;尽管Transformer与GNNs有数学上的联系，但它们通过密集矩阵操作实现，这在现代硬件上比稀疏消息传递效率更高。&lt;h4&gt;结论&lt;/h4&gt;基于上述发现，Transformer被视为当前在硬件上占据优势的GNNs。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We establish connections between the Transformer architecture, originallyintroduced for natural language processing, and Graph Neural Networks (GNNs)for representation learning on graphs. We show how Transformers can be viewedas message passing GNNs operating on fully connected graphs of tokens, wherethe self-attention mechanism capture the relative importance of all tokensw.r.t. each-other, and positional encodings provide hints about sequentialordering or structure. Thus, Transformers are expressive set processingnetworks that learn relationships among input elements without beingconstrained by apriori graphs. Despite this mathematical connection to GNNs,Transformers are implemented via dense matrix operations that are significantlymore efficient on modern hardware than sparse message passing. This leads tothe perspective that Transformers are GNNs currently winning the hardwarelottery.</description>
      <author>example@mail.com (Chaitanya K. Joshi)</author>
      <guid isPermaLink="false">2506.22084v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Visual Content Detection in Educational Videos with Transfer Learning and Dataset Enrichment</title>
      <link>http://arxiv.org/abs/2506.21903v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This is an extended version of a paper accepted to MIPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在视频讲座中检测视觉元素的问题，并提出了一个基于迁移学习的方法，以提高视频内容的信息检索。&lt;h4&gt;背景&lt;/h4&gt;视频正在改变教育方式，通过在线课程和录制的讲座补充和取代课堂教学。研究集中在通过高级导航、可搜索性、总结以及问答聊天机器人来增强视频讲座的信息检索。&lt;h4&gt;目的&lt;/h4&gt;旨在提高视频讲座中视觉元素（如表格、图表和插图）的检测准确性，以增强对视频内容的访问。&lt;h4&gt;方法&lt;/h4&gt;评估了一系列最先进的目标检测模型在讲座视频数据集上的性能，并选择了YOLO模型进行优化。通过在多个基准数据集上进行训练和采用半监督自动标注策略，优化了YOLO模型。&lt;h4&gt;主要发现&lt;/h4&gt;YOLO模型在检测讲座视频中的视觉元素方面表现最为出色，优化后的模型在检测准确性和泛化能力上取得了显著进步。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法对于解决讲座视频中视觉元素的自动检测问题具有实际应用价值，同时发布了标注的讲座视频帧基准数据集和源代码，以促进未来的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：视频正在通过在线课程和录制的讲座改变教育方式，补充和取代课堂教学。最近的研究集中在通过高级导航、可搜索性、总结以及问答聊天机器人来增强视频讲座的信息检索。视觉元素如表格、图表和插图对于讲座视频的理解、记忆和数据展示至关重要，但它们在提高视频内容访问方面的潜力尚未得到充分利用。主要原因是准确自动检测讲座视频中的视觉元素具有挑战性；原因包括：i）大多数视觉元素（如图表、图形、表格和插图）是人工创建的，缺乏任何标准结构；ii）连贯的视觉对象可能缺乏清晰的边界，可能由连接的文本和视觉组件组成。尽管基于深度学习的目标检测取得了进展，但当前模型由于讲座视频中视觉内容的独特性质和标注数据集的稀缺性，其性能并不令人满意。本文报告了一种用于检测讲座视频帧中视觉元素的迁移学习方法。评估了一系列最先进的目标检测模型在讲座视频数据集上的性能，YOLO模型在这一任务中表现最为出色。随后，YOLO模型通过在多个基准数据集上进行训练和部署半监督自动标注策略进行了优化。结果评估了这种方法的成功，同时也为讲座视频中的对象检测问题开发了一般解决方案。本文的贡献包括发布了一个公开的标注讲座视频帧基准数据集，以及源代码以促进未来的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video is transforming education with online courses and recorded lecturessupplementing and replacing classroom teaching. Recent research has focused onenhancing information retrieval for video lectures with advanced navigation,searchability, summarization, as well as question answering chatbots. Visualelements like tables, charts, and illustrations are central to comprehension,retention, and data presentation in lecture videos, yet their full potentialfor improving access to video content remains underutilized. A major factor isthat accurate automatic detection of visual elements in a lecture video ischallenging; reasons include i) most visual elements, such as charts, graphs,tables, and illustrations, are artificially created and lack any standardstructure, and ii) coherent visual objects may lack clear boundaries and may becomposed of connected text and visual components. Despite advancements in deeplearning based object detection, current models do not yield satisfactoryperformance due to the unique nature of visual content in lectures and scarcityof annotated datasets. This paper reports on a transfer learning approach fordetecting visual elements in lecture video frames. A suite of state of the artobject detection models were evaluated for their performance on lecture videodatasets. YOLO emerged as the most promising model for this task. SubsequentlyYOLO was optimized for lecture video object detection with training on multiplebenchmark datasets and deploying a semi-supervised auto labeling strategy.Results evaluate the success of this approach, also in developing a generalsolution to the problem of object detection in lecture videos. Papercontributions include a publicly released benchmark of annotated lecture videoframes, along with the source code to facilitate future research.</description>
      <author>example@mail.com (Dipayan Biswas, Shishir Shah, Jaspal Subhlok)</author>
      <guid isPermaLink="false">2506.21903v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Reasoning in machine vision: learning to think fast and slow</title>
      <link>http://arxiv.org/abs/2506.22075v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的学习范式，通过允许在推理时间内提高性能（推理时间计算），即使在标记数据非常有限的情况下，也能使机器在视觉中进行推理。&lt;h4&gt;背景&lt;/h4&gt;推理是人类智能的标志，使人们能够在复杂和不熟悉的场景中做出适应性决策。相比之下，机器智能仍然受限于训练数据，在推理时缺乏动态优化解决方案的能力。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够使机器在视觉中进行推理的方法，即使在数据稀缺的情况下也能通过增加思考时间（推理时间计算）来提高性能。&lt;h4&gt;方法&lt;/h4&gt;该方法受到心理学中人类认知的双重过程理论的启发，集成了快速思考的系统I模块和慢速思考的系统II模块。系统I模块用于熟悉任务，而系统II模块则通过自我玩强化学习迭代优化解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;该范式通过扩展思考时间，在真实世界的视觉任务中表现出色，不仅优于大规模监督学习，而且优于基础模型，甚至优于人类专家。&lt;h4&gt;结论&lt;/h4&gt;该范式在非语言机器推理方面具有变革性的潜力，包括计算机视觉基准和五器官医学图像上的癌症定位。&lt;h4&gt;翻译&lt;/h4&gt;Reasoning is a hallmark of human intelligence, enabling adaptive decision-making in complex and unfamiliar scenarios. In contrast, machine intelligence remains bound to training data, lacking the ability to dynamically refine solutions at inference time. While some recent advances have explored reasoning in machines, these efforts are largely limited to verbal domains such as mathematical problem-solving, where explicit rules govern step-by-step reasoning. Other critical real-world tasks - including visual perception, spatial reasoning, and radiological diagnosis - require non-verbal reasoning, which remains an open challenge. Here we present a novel learning paradigm that enables machine reasoning in vision by allowing performance improvement withincreasing thinking time (inference-time compute), even under conditions wherelabelled data is very limited. Inspired by dual-process theories of humancognition in psychology, our approach integrates a fast-thinking System Imodule for familiar tasks, with a slow-thinking System II module that iteratively refines solutions using self-play reinforcement learning. This paradigm mimics human reasoning by proposing, competing over, and refining solutions in data-scarce scenarios. We demonstrate superior performance through extended thinking time, compared not only to large-scale supervised learning but also foundation models and even human experts, in real-world vision tasks. These tasks include computer-vision benchmarks and cancer localisation on medical images across five organs, showcasing transformative potential for non-verbal machine reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reasoning is a hallmark of human intelligence, enabling adaptivedecision-making in complex and unfamiliar scenarios. In contrast, machineintelligence remains bound to training data, lacking the ability to dynamicallyrefine solutions at inference time. While some recent advances have exploredreasoning in machines, these efforts are largely limited to verbal domains suchas mathematical problem-solving, where explicit rules govern step-by-stepreasoning. Other critical real-world tasks - including visual perception,spatial reasoning, and radiological diagnosis - require non-verbal reasoning,which remains an open challenge. Here we present a novel learning paradigm thatenables machine reasoning in vision by allowing performance improvement withincreasing thinking time (inference-time compute), even under conditions wherelabelled data is very limited. Inspired by dual-process theories of humancognition in psychology, our approach integrates a fast-thinking System Imodule for familiar tasks, with a slow-thinking System II module thatiteratively refines solutions using self-play reinforcement learning. Thisparadigm mimics human reasoning by proposing, competing over, and refiningsolutions in data-scarce scenarios. We demonstrate superior performance throughextended thinking time, compared not only to large-scale supervised learningbut also foundation models and even human experts, in real-world vision tasks.These tasks include computer-vision benchmarks and cancer localisation onmedical images across five organs, showcasing transformative potential fornon-verbal machine reasoning.</description>
      <author>example@mail.com (Shaheer U. Saeed, Yipei Wang, Veeru Kasivisvanathan, Brian R. Davidson, Matthew J. Clarkson, Yipeng Hu, Daniel C. Alexander)</author>
      <guid isPermaLink="false">2506.22075v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Offensive Language Detection on Social Media Using XLNet</title>
      <link>http://arxiv.org/abs/2506.21795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了社交媒体上基于文本的沟通方式，指出其既提升了用户互动，又导致了攻击性内容（包括仇恨言论、种族主义和其他形式的滥用）的增加。由于用户生成内容数量巨大，手动监管不切实际，因此需要自动检测攻击性语言的系统。研究发现，基于XLNet的自动攻击性语言检测模型在检测攻击性内容方面优于BERT，且在分类攻击类型方面表现更好。同时，过采样和欠采样策略有效解决了类别不平衡问题，并提高了分类性能。&lt;h4&gt;背景&lt;/h4&gt;社交媒体上基于文本的沟通方式普及，既提高了用户互动，也增加了攻击性内容的产生。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于XLNet的自动攻击性语言检测模型，并评估其性能。&lt;h4&gt;方法&lt;/h4&gt;使用XLNet和BERT模型，通过Offensive Language Identification Dataset (OLID)进行评估，该数据集包含层级标注的Twitter数据。&lt;h4&gt;主要发现&lt;/h4&gt;XLNet在检测攻击性内容和分类攻击类型方面优于BERT，而过采样和欠采样策略有助于解决类别不平衡问题。&lt;h4&gt;结论&lt;/h4&gt;转移学习和基于XLNet的架构在创建能够检测社交媒体平台上攻击性语言的鲁棒系统方面具有潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：社交媒体上基于文本的沟通方式，如聊天、评论和微博的使用，提高了用户互动，但也导致攻击性内容（包括仇恨言论、种族主义和其他形式的滥用）的增加。由于用户生成内容数量巨大，手动监管不切实际，这需要能够检测攻击性语言的自动系统。深度学习模型，特别是使用迁移学习的模型，在通过大规模预训练理解自然语言方面取得了显著的成效。在本研究中，我们提出了一种基于XLNet的自动攻击性语言检测模型，这是一种通用的自回归预训练方法，并将其性能与BERT（双向编码器表示从变换器）进行了比较，BERT是自然语言处理（NLP）中广泛使用的基线。这两个模型都使用Offensive Language Identification Dataset（OLID）进行了评估，这是一个包含层级标注的基准Twitter数据集。我们的实验结果表明，XLNet在检测攻击性内容和分类攻击类型方面优于BERT，而BERT在识别攻击目标方面表现略好。此外，我们发现过采样和欠采样策略在解决类别不平衡和改进分类性能方面是有效的。这些发现突出了迁移学习和基于XLNet架构创建检测社交媒体平台攻击性语言的鲁棒系统的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The widespread use of text-based communication on social media-through chats,comments, and microblogs-has improved user interaction but has also led to anincrease in offensive content, including hate speech, racism, and other formsof abuse. Due to the enormous volume of user-generated content, manualmoderation is impractical, which creates a need for automated systems that candetect offensive language. Deep learning models, particularly those usingtransfer learning, have demonstrated significant success in understandingnatural language through large-scale pretraining. In this study, we propose anautomatic offensive language detection model based on XLNet, a generalizedautoregressive pretraining method, and compare its performance with BERT(Bidirectional Encoder Representations from Transformers), which is a widelyused baseline in natural language processing (NLP). Both models are evaluatedusing the Offensive Language Identification Dataset (OLID), a benchmark Twitterdataset that includes hierarchical annotations. Our experimental results showthat XLNet outperforms BERT in detecting offensive content and in categorizingthe types of offenses, while BERT performs slightly better in identifying thetargets of the offenses. Additionally, we find that oversampling andundersampling strategies are effective in addressing class imbalance andimproving classification performance. These findings highlight the potential oftransfer learning and XLNet-based architectures to create robust systems fordetecting offensive language on social media platforms.</description>
      <author>example@mail.com (Reem Alothman, Hafida Benhidour, Said Kerrache)</author>
      <guid isPermaLink="false">2506.21795v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>UniCA: Adapting Time Series Foundation Model to General Covariate-Aware Forecasting</title>
      <link>http://arxiv.org/abs/2506.22039v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一个名为UniCA的框架，用于桥接时间序列基础模型（TSFMs）与一般协变量感知预测，以提高模型处理多样化协变量的能力。&lt;h4&gt;背景&lt;/h4&gt;TSFMs在处理实值时间序列方面取得了显著成功，但其设计主要针对实值序列，限制了其在处理涉及不同和异质协变量的预测任务中的能力。&lt;h4&gt;目的&lt;/h4&gt;旨在解决TSFMs在处理涉及分类变量和多模态数据（如图像和文本）等异质协变量时的局限性。&lt;h4&gt;方法&lt;/h4&gt;UniCA首先通过协变量同质化将异质协变量转换为高级同质序列表示，然后通过统一的基于注意力的融合机制将它们融合。UniCA可以适应同质和异质协变量，同时保留TSFMs的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;在多个单模态和多模态协变量感知预测基准上的实验表明，UniCA优于其他方法，突出了协变量感知TSFM适应在现实世界预测场景中的潜力。&lt;h4&gt;结论&lt;/h4&gt;UniCA是一个具有广泛适用性和兼容性的框架，能够有效提高TSFMs处理多样化协变量的能力，并在实际预测任务中展现出优越性能。&lt;h4&gt;翻译&lt;/h4&gt;时间序列基础模型（TSFMs）通过大规模预训练取得了显著的成功。然而，它们的设计主要针对实值序列，限制了它们处理涉及多样化和经常异质的协变量（如分类变量和多模态数据，例如图像和文本）的能力，这些协变量通常是特定于任务的，并且在预训练期间难以利用。为了解决这一差距，我们提出了统一协变量适应（UniCA），一个将TSFMs与一般协变量感知预测连接起来的框架。UniCA首先执行协变量同质化，将异质协变量转换为高级同质序列表示，然后通过统一的基于注意力的融合机制将它们融合。UniCA既兼容又通用，可以适应同质和异质协变量，同时包含额外的协变量信息，同时保留TSFMs的泛化能力。在多个单模态和多模态协变量感知预测基准上的广泛实验证明了UniCA的优越性，突出了协变量感知TSFM适应在现实世界预测场景中的潜力。代码已发布在https://github.com/hanlu-nju/UniCA。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time Series Foundation Models (TSFMs) have achieved remarkable successthrough large-scale pretraining. However, their design primarily targetsreal-valued series, limiting their ability to handle general forecasting tasksinvolving diverse and often heterogeneous covariates--such as categoricalvariables and multimodal data (e.g., images, text)--which are typicallytask-specific and difficult to leverage during pretraining. To address thisgap, we propose Unified Covariate Adaptation (UniCA), a framework to bridgeTSFMs with general covariate-aware forecasting. UniCA first performs covariatehomogenization to transform heterogeneous covariates into high-levelhomogeneous series representations and then fuses them via a unifiedattention-based fusion mechanism. UniCA is compatible and universal foradaptation with both homogeneous and heterogeneous covariates, incorporatingextra covariate information while preserving the generalization ability ofTSFMs.Extensive experiments on multiple unimodal and multimodal covariate-awareforecasting benchmarks demonstrate the superiority of UniCA, highlighting thepromise of covariate-aware TSFM adaptation in real-world forecasting scenarios.Codes are released on https://github.com/hanlu-nju/UniCA.</description>
      <author>example@mail.com (Lu Han, Yu Liu, Qiwen Deng, Jian Jiang, Yinbo Sun, Zhe Yu, Binfeng Wang, Xingyu Lu, Lintao Ma, Han-Jia Ye, De-Chuan Zhan)</author>
      <guid isPermaLink="false">2506.22039v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Comparing Learning Paradigms for Egocentric Video Summarization</title>
      <link>http://arxiv.org/abs/2506.21785v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究了多种计算机视觉范式，包括监督学习、无监督学习和提示微调，评估它们理解和解释自摄视频数据的能力。&lt;h4&gt;背景&lt;/h4&gt;当前最先进的模型在处理第一人称视频方面比第三人称视频效果差，需要在该领域取得进一步进展。&lt;h4&gt;目的&lt;/h4&gt;提供一种综合性的概念证明分析，旨在推进计算机视觉技术在第一人称视频中的应用。&lt;h4&gt;方法&lt;/h4&gt;评估了Shotluck Holmes（最先进的监督学习）、TAC-SUM（最先进的无监督学习）和GPT-4o（提示微调的预训练模型）在视频摘要中的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;提示微调的通用GPT-4o模型在视频摘要任务中优于专用模型，突显了现有方法在适应第一人称视角独特挑战方面的局限性。&lt;h4&gt;结论&lt;/h4&gt;通过探索新颖的方法并评估其潜力，旨在为能够有效处理和解释第一人称视角的模型的发展做出贡献。&lt;h4&gt;翻译&lt;/h4&gt;在这项研究中，我们通过评估它们理解和解释自摄视频数据的能力，研究了各种计算机视觉范式——监督学习、无监督学习和提示微调。具体来说，我们考察了Shotluck Holmes（最先进的监督学习）、TAC-SUM（最先进的无监督学习）和GPT-4o（一个提示微调的预训练模型），评估了它们在视频摘要中的有效性。我们的结果表明，当前最先进的模型在处理第一人称视频方面比第三人称视频效果差，突显了在该领域取得进一步进展的必要性。值得注意的是，一个提示微调的通用GPT-4o模型在这些专用模型中表现更优，强调了现有方法在适应第一人称视角独特挑战方面的局限性。尽管由于资源限制，我们的评估是在Ego-Exo4D数据集的一个小子集上进行的，但这项研究的主要目标是提供一种综合性的概念证明分析，旨在推进计算机视觉技术在第一人称视频中的应用。通过探索新颖的方法并评估其潜力，我们旨在为能够有效处理和解释第一人称视角的模型的发展做出贡献。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this study, we investigate various computer vision paradigms - supervisedlearning, unsupervised learning, and prompt fine-tuning - by assessing theirability to understand and interpret egocentric video data. Specifically, weexamine Shotluck Holmes (state-of-the-art supervised learning), TAC-SUM(state-of-the-art unsupervised learning), and GPT-4o (a prompt fine-tunedpre-trained model), evaluating their effectiveness in video summarization. Ourresults demonstrate that current state-of-the-art models perform lesseffectively on first-person videos compared to third-person videos,highlighting the need for further advancements in the egocentric video domain.Notably, a prompt fine-tuned general-purpose GPT-4o model outperforms thesespecialized models, emphasizing the limitations of existing approaches inadapting to the unique challenges of first-person perspectives. Although ourevaluation is conducted on a small subset of egocentric videos from theEgo-Exo4D dataset due to resource constraints, the primary objective of thisresearch is to provide a comprehensive proof-of-concept analysis aimed atadvancing the application of computer vision techniques to first-person videos.By exploring novel methodologies and evaluating their potential, we aim tocontribute to the ongoing development of models capable of effectivelyprocessing and interpreting egocentric perspectives.</description>
      <author>example@mail.com (Daniel Wen)</author>
      <guid isPermaLink="false">2506.21785v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>TASeg: Text-aware RGB-T Semantic Segmentation based on Fine-tuning Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2506.21975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, accepted for publication in lEEE/RSJ international  Conference on Intelligent Robots and Systems (lROS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TASeg的文本感知RGB-T语义分割框架，旨在解决现有模型在处理开放环境中的语义分割问题。&lt;h4&gt;背景&lt;/h4&gt;现有的RGB-T语义分割模型主要依赖低级视觉特征，缺乏高级文本信息，难以准确分割具有相似视觉特征的类别。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一种新的文本感知RGB-T语义分割框架TASeg。&lt;h4&gt;方法&lt;/h4&gt;TASeg利用低秩自适应（LoRA）微调技术对视觉基础模型进行适应。具体来说，在图像编码器中提出了动态特征融合模块（DFFM），有效地融合了来自多个视觉模态的特征，同时冻结了SAM的原始transformer块。此外，在掩码解码器中结合了CLIP生成的文本嵌入，以实现语义对齐，进一步纠正分类错误并提高语义理解精度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，TASeg在多个数据集上表现出优异的性能，尤其是在具有挑战性的场景中，并且具有较少的可训练参数。&lt;h4&gt;结论&lt;/h4&gt;TASeg框架通过融合视觉和文本信息，有效提高了语义分割的准确性，为智能系统在开放环境中的可靠语义分割提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable semantic segmentation of open environments is essential forintelligent systems, yet significant problems remain: 1) Existing RGB-Tsemantic segmentation models mainly rely on low-level visual features and lackhigh-level textual information, which struggle with accurate segmentation whencategories share similar visual characteristics. 2) While SAM excels ininstance-level segmentation, integrating it with thermal images and text ishindered by modality heterogeneity and computational inefficiency. To addressthese, we propose TASeg, a text-aware RGB-T segmentation framework by usingLow-Rank Adaptation (LoRA) fine-tuning technology to adapt vision foundationmodels. Specifically, we propose a Dynamic Feature Fusion Module (DFFM) in theimage encoder, which effectively merges features from multiple visualmodalities while freezing SAM's original transformer blocks. Additionally, weincorporate CLIP-generated text embeddings in the mask decoder to enablesemantic alignment, which further rectifies the classification error andimproves the semantic understanding accuracy. Experimental results acrossdiverse datasets demonstrate that our method achieves superior performance inchallenging scenarios with fewer trainable parameters.</description>
      <author>example@mail.com (Meng Yu, Te Cui, Qitong Chu, Wenjie Song, Yi Yang, Yufeng Yue)</author>
      <guid isPermaLink="false">2506.21975v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts</title>
      <link>http://arxiv.org/abs/2506.21835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ProSAM的新方法，用于解决现有基于SAM的视觉参考分割方法中的稳定性问题，并提高了视觉参考分割的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型基础模型的发展推动了开放集图像分割任务的进展，特别是视觉参考分割，它具有独特的灵活性和强大的零样本能力。&lt;h4&gt;目的&lt;/h4&gt;提出ProSAM方法，以解决现有方法在生成提示时的不稳定性问题。&lt;h4&gt;方法&lt;/h4&gt;ProSAM通过学习一个变分提示编码器来预测多变量提示分布，从而避免生成位于不稳定区域的提示。&lt;h4&gt;主要发现&lt;/h4&gt;ProSAM在Pascal-5i和COCO-20i数据集上优于现有方法，提供了更鲁棒的视觉参考分割解决方案。&lt;h4&gt;结论&lt;/h4&gt;ProSAM是一种简单而有效的方法，可以显著提高基于SAM的视觉参考分割的稳定性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The recent advancements in large foundation models have driven the success ofopen-set image segmentation, a task focused on segmenting objects beyondpredefined categories. Among various prompt types (such as points, boxes,texts, and visual references), visual reference segmentation stands out for itsunique flexibility and strong zero-shot capabilities. Recently, severalSAM-based methods have made notable progress in this task by automaticallygenerating prompts to guide SAM. However, these methods often generate promptsat object boundaries due to suboptimal prompt encoder, which results ininstability and reduced robustness. In this work, we introduce ProSAM, a simplebut effective method to address the stability challenges we identified inexisting SAM-based visual reference segmentation approaches. By learning avariational prompt encoder to predict multivariate prompt distributions, ProSAMavoids generating prompts that lie in unstable regions, overcoming theinstability caused by less robust prompts. Our approach consistently surpassesstate-of-the-art methods on the Pascal-5$^i$ and COCO-20$^i$ datasets,providing a more robust solution for visual reference segmentation.</description>
      <author>example@mail.com (Xiaoqi Wang, Clint Sebastian, Wenbin He, Liu Ren)</author>
      <guid isPermaLink="false">2506.21835v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.21627v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures, under review of NeurIPS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FrankenBot的机器人操作框架，该框架通过整合视觉-语言模型（VLM）和大脑形态架构，实现了在复杂、动态、非结构化环境中的多功能操作和高效率。&lt;h4&gt;背景&lt;/h4&gt;在复杂和动态的真实环境中开发能够执行广泛任务的通用机器人操作系统一直是一个挑战。目前的方法通常只实现机器人大脑中的一部分功能，而没有将它们集成到一个统一的认知架构中。&lt;h4&gt;目的&lt;/h4&gt;实现具有类似人类效率和鲁棒性的机器人操作，需要机器人大脑整合一套全面的函数，如任务规划、策略生成、异常监控和处理、长期记忆等。&lt;h4&gt;方法&lt;/h4&gt;FrankenBot框架包括一系列组件，将部分关键功能从频繁的VLM调用中解耦，在功能完整性和系统效率之间达到最佳平衡。具体来说，将任务规划、策略生成、内存管理和低级接口分别映射到大脑的皮层、小脑、颞叶-海马体复合体和脑干，并为模块设计高效的协调机制。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟和真实机器人环境中进行的全面实验表明，该方法在异常检测和处理、长期记忆、操作效率和稳定性方面具有显著优势，且无需任何微调或重新训练。&lt;h4&gt;结论&lt;/h4&gt;FrankenBot框架通过整合VLM和大脑形态架构，为在复杂环境中实现高效和鲁棒的机器人操作提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;Developing a general robot manipulation system capable of performing a wide range of tasks in complex, dynamic, and unstructured real-world environments has long been a challenging task. It is widely recognized that achieving human-like efficiency and robustness manipulation requires the robotic brain to integrate a comprehensive set of functions, such as task planning, policy generation, anomaly monitoring and handling, and long-term memory, achieving high-efficiency operation across all functions. Vision-Language Models (VLMs), pretrained on massive multimodal data, have acquired rich world knowledge, exhibiting exceptional scene understanding and multimodal reasoning capabilities. However, existing methods typically focus on realizing only a single function or a subset of functions within the robotic brain, without integrating them into a unified cognitive architecture. Inspired by a divide-and-conquer strategy and the architecture of the human brain, we propose FrankenBot, a VLM-driven, brain-morphic robotic manipulation framework that achieves both comprehensive functionality and high operational efficiency. Our framework includes a suite of components, decoupling a part of key functions from frequent VLM calls, striking an optimal balance between functional completeness and system efficiency. Specifically, we map task planning, policy generation, memory management, and low-level interfacing to the cortex, cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, and design efficient coordination mechanisms for the modules. We conducted comprehensive experiments in both simulation and real-world robotic environments, demonstrating that our method offers significant advantages in anomaly detection and handling, long-term memory, operational efficiency, and stability -- all without requiring any fine-tuning or retraining.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Developing a general robot manipulation system capable of performing a widerange of tasks in complex, dynamic, and unstructured real-world environmentshas long been a challenging task. It is widely recognized that achievinghuman-like efficiency and robustness manipulation requires the robotic brain tointegrate a comprehensive set of functions, such as task planning, policygeneration, anomaly monitoring and handling, and long-term memory, achievinghigh-efficiency operation across all functions. Vision-Language Models (VLMs),pretrained on massive multimodal data, have acquired rich world knowledge,exhibiting exceptional scene understanding and multimodal reasoningcapabilities. However, existing methods typically focus on realizing only asingle function or a subset of functions within the robotic brain, withoutintegrating them into a unified cognitive architecture. Inspired by adivide-and-conquer strategy and the architecture of the human brain, we proposeFrankenBot, a VLM-driven, brain-morphic robotic manipulation framework thatachieves both comprehensive functionality and high operational efficiency. Ourframework includes a suite of components, decoupling a part of key functionsfrom frequent VLM calls, striking an optimal balance between functionalcompleteness and system efficiency. Specifically, we map task planning, policygeneration, memory management, and low-level interfacing to the cortex,cerebellum, temporal lobe-hippocampus complex, and brainstem, respectively, anddesign efficient coordination mechanisms for the modules. We conductedcomprehensive experiments in both simulation and real-world roboticenvironments, demonstrating that our method offers significant advantages inanomaly detection and handling, long-term memory, operational efficiency, andstability -- all without requiring any fine-tuning or retraining.</description>
      <author>example@mail.com (Shiyi Wang, Wenbo Li, Yiteng Chen, Qingyao Wu, Huiping Zhuang)</author>
      <guid isPermaLink="false">2506.21627v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models</title>
      <link>http://arxiv.org/abs/2506.21826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, accepted at ICDAR2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种简单有效的少量样本分割历史地图的方法，该方法结合了大型视觉基础模型的丰富语义嵌入和参数高效的微调，在历史地图的自动化处理中取得了显著成果。&lt;h4&gt;背景&lt;/h4&gt;历史地图作为丰富的历史资料来源，提供了对历史变化的深入了解，但由于其多样化的视觉表示和有限的标注数据，为自动化处理带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;目的是提出一种能够有效分割历史地图的方法，减少对手动标注的需求，并推进历史地图的自动化处理和分析。&lt;h4&gt;方法&lt;/h4&gt;方法结合了大型视觉基础模型的语义嵌入和参数高效的微调，实现了少量样本分割。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在Siegfried基准数据集的葡萄园和铁路分割任务上优于现有技术，在10个样本的情况下，mIoU相对提高了5%，在更具挑战性的5个样本情况下提高了约13%。此外，在ICDAR 2021竞赛数据集上也表现出色，尽管未针对形状敏感的指标进行优化，但实现了67.3%的平均PQ值。该方法在低数据量情况下（10个和5个样本）也能保持高性能，同时所需的训练参数仅为模型总量的0.21%。&lt;h4&gt;结论&lt;/h4&gt;该方法能够精确分割各种历史地图，同时大幅减少对手动标注的需求，推进了该领域的自动化处理和分析。&lt;h4&gt;翻译&lt;/h4&gt;As rich sources of history, maps provide crucial insights into historical changes, yet their diverse visual representations and limited annotated data pose significant challenges for automated processing. We propose a simple yet effective approach for few-shot segmentation of historical maps, leveraging the rich semantic embeddings of large vision foundation models combined with parameter-efficient fine-tuning. Our method outperforms the state-of-the-art on the Siegfried benchmark dataset in vineyard and railway segmentation, achieving +5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20% in the more challenging 5-shot setting. Additionally, it demonstrates strong performance on the ICDAR 2021 competition dataset, attaining a mean PQ of 67.3% for building block segmentation, despite not being optimized for this shape-sensitive metric, underscoring its generalizability. Notably, our approach maintains high performance even in extremely low-data regimes (10- &amp; 5-shot), while requiring only 689k trainable parameters - just 0.21% of the total model size. Our approach enables precise segmentation of diverse historical maps while drastically reducing the need for manual annotations, advancing automated processing and analysis in the field. Our implementation is publicly available at: https://github.com/RafaelSterzinger/few-shot-map-segmentation.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-27&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; As rich sources of history, maps provide crucial insights into historicalchanges, yet their diverse visual representations and limited annotated datapose significant challenges for automated processing. We propose a simple yeteffective approach for few-shot segmentation of historical maps, leveraging therich semantic embeddings of large vision foundation models combined withparameter-efficient fine-tuning. Our method outperforms the state-of-the-art onthe Siegfried benchmark dataset in vineyard and railway segmentation, achieving+5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20%in the more challenging 5-shot setting. Additionally, it demonstrates strongperformance on the ICDAR 2021 competition dataset, attaining a mean PQ of 67.3%for building block segmentation, despite not being optimized for thisshape-sensitive metric, underscoring its generalizability. Notably, ourapproach maintains high performance even in extremely low-data regimes (10- &amp;5-shot), while requiring only 689k trainable parameters - just 0.21% of thetotal model size. Our approach enables precise segmentation of diversehistorical maps while drastically reducing the need for manual annotations,advancing automated processing and analysis in the field. Our implementation ispublicly available at:https://github.com/RafaelSterzinger/few-shot-map-segmentation.</description>
      <author>example@mail.com (Rafael Sterzinger, Marco Peer, Robert Sablatnig)</author>
      <guid isPermaLink="false">2506.21826v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Multi-task parallelism for robust pre-training of graph foundation models on multi-source, multi-fidelity atomistic modeling data</title>
      <link>http://arxiv.org/abs/2506.21788v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures, 2 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图神经网络的图基础模型，通过多任务学习方法提高原子建模的可持续性和效率。&lt;h4&gt;背景&lt;/h4&gt;处理多源、多保真度数据在预训练阶段存在挑战，需要稳定预训练并提高模型对新化学区域的迁移能力。&lt;h4&gt;目的&lt;/h4&gt;通过多任务学习来稳定预训练，并增强模型对新化学区域的迁移能力。&lt;h4&gt;方法&lt;/h4&gt;采用多任务学习方法，共享消息传递层先处理输入原子结构，然后将其路由到多个解码头以预测特定数据输出。&lt;h4&gt;主要发现&lt;/h4&gt;初步结果表明，在约四百万个结构上效果良好，但关于其在大规模、多样化数据集上的泛化能力和在超级计算机上的可扩展性的问题仍存在。&lt;h4&gt;结论&lt;/h4&gt;提出了一种多任务并行方法，通过GPU加速将每个头部分布到计算资源上。该方法在超过2400万个结构上进行训练，并在Perlmutter、Aurora和Frontier超级计算机上进行测试，证明了在三种高度异构的超级计算架构上的高效扩展。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a graph foundation model based on graph neural networks, which improves the sustainability and efficiency of atomic modeling through multi-task learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph foundation models using graph neural networks promise sustainable,efficient atomistic modeling. To tackle challenges of processing multi-source,multi-fidelity data during pre-training, recent studies employ multi-tasklearning, in which shared message passing layers initially process inputatomistic structures regardless of source, then route them to multiple decodingheads that predict data-specific outputs. This approach stabilizes pre-trainingand enhances a model's transferability to unexplored chemical regions.Preliminary results on approximately four million structures are encouraging,yet questions remain about generalizability to larger, more diverse datasetsand scalability on supercomputers. We propose a multi-task parallelism methodthat distributes each head across computing resources with GPU acceleration.Implemented in the open-source HydraGNN architecture, our method was trained onover 24 million structures from five datasets and tested on the Perlmutter,Aurora, and Frontier supercomputers, demonstrating efficient scaling on allthree highly heterogeneous super-computing architectures.</description>
      <author>example@mail.com (Massimiliano Lupo Pasini, Jong Youl Choi, Pei Zhang, Kshitij Mehta, Rylie Weaver, Ashwin M. Aji, Karl W. Schulz, Jorda Polo, Prasanna Balaprakash)</author>
      <guid isPermaLink="false">2506.21788v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Environment-Based Channel Knowledge Map Construction</title>
      <link>http://arxiv.org/abs/2506.21112v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种联合模型和数据驱动的Channel knowledge map (CKM)构建方法，通过利用点云环境数据和少量位置标记的信道信息，提高了CKM的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的CKM构建方案采用过于简化的环境信息，这严重影响了其准确性。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有CKM构建方案中环境信息简化的准确性问题。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种新的点选择器，通过基于不同到达时间（ToA）构建一组共焦点椭球，识别包含与多径信道增益相关的环境信息的点云子集。2. 训练了一个神经网络信道增益估计器，通过使用我们通过实地测量收集的包含环境点云和对应信道数据的真实世界数据集，学习每个选定点云子集与其相应信道增益之间的映射。&lt;h4&gt;主要发现&lt;/h4&gt;对于功率延迟剖面（PDP）的CKM构建，该方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法的7.32 dB；对于接收功率值（即无线电地图）的CKM构建，它实现了1.04 dB的RMSE，超过了克里金插值方法的1.68 dB。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了CKM构建的准确性，尤其是在PDP和接收功率值的构建方面。&lt;h4&gt;翻译&lt;/h4&gt;摘要：信道知识图（CKM）为感兴趣区域提供了一定程度的信道状态信息（CSI），通过减少频繁CSI获取的开销，成为环境感知通信的关键推动者。然而，现有的CKM构建方案采用了过于简化的环境信息，这严重影响了它们的准确性。为了解决这个问题，本研究提出了一种联合模型和数据驱动的构建CKM的方法，通过利用点云环境数据以及一些位置标记的信道信息样本。首先，我们提出了一种新的点选择器，通过基于不同的到达时间（ToA）构建一组共焦点椭球，以识别包含与多径信道增益相关的环境信息的点云子集。然后，我们训练了一个神经网络信道增益估计器，通过使用我们通过实地测量收集的包含环境点云和对应信道数据的真实世界数据集，学习每个选定点云子集与其相应信道增益之间的映射。最后，实验结果表明：对于功率延迟剖面（PDP）的CKM构建，所提出的方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法的7.32 dB；对于接收功率值（即无线电地图）的CKM构建，它实现了1.04 dB的RMSE，超过了克里金插值方法的1.68 dB。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Channel knowledge map (CKM) provides certain levels of channel stateinformation (CSI) for an area of interest, serving as a critical enabler forenvironment-aware communications by reducing the overhead of frequent CSIacquisition. However, existing CKM construction schemes adopt over-simplifiedenvironment information, which significantly compromises their accuracy. Toaddress this issue, this work proposes a joint model- and data-driven approachto construct CKM by leveraging point cloud environmental data along with a fewsamples of location-tagged channel information. First, we propose a novel pointselector to identify subsets of point cloud that contain environmentalinformation relevant to multipath channel gains, by constructing a set ofco-focal ellipsoids based on different time of arrival (ToAs). Then, we traineda neural channel gain estimator to learn the mapping between each selectedsubset and its corresponding channel gain, using a real-world dataset wecollected through field measurements, comprising environmental point clouds andcorresponding channel data. Finally, experimental results demonstrate that: ForCKM construction of power delay profile (PDP), the proposed method achieves aroot mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dBachieved by the conventional ray-tracing method; for CKM construction ofreceived power values, i.e., radio map, it achieves an RMSE of 1.04 dB,surpassing the Kriging interpolation method with an RMSE of 1.68 dB.</description>
      <author>example@mail.com (Yancheng Wang, Wei Guo, Chuan Huang, Guanying Chen, Ye Zhang, Shuguang Cui)</author>
      <guid isPermaLink="false">2506.21112v2</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Infrared foundations for quantum geometry I: Catalogue of totally symmetric rank-three field theories</title>
      <link>http://arxiv.org/abs/2506.21662v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 Pages, 9 Figures, 2 Tables. Comments welcome!&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;系统地获得了在平坦背景上传播无宇称违反的完全对称的三秩场的所有线性模型。&lt;h4&gt;背景&lt;/h4&gt;这些模型仅由其规范对称性定义，这是红外极限下有效场理论的必要属性。&lt;h4&gt;目的&lt;/h4&gt;通过比较，发现通过其他方法（调整耦合或选择操作符）获得的模型可能对辐射修正不稳定。&lt;h4&gt;方法&lt;/h4&gt;对每个模型，计算了无质量和有质量粒子的谱，以及耦合的鬼和快子约束。&lt;h4&gt;主要发现&lt;/h4&gt;存在基础模型，可以传播一个自旋为一或三的无质量粒子，或同时传播这两个粒子，推广了Campoleoni和Francia的模型。&lt;h4&gt;结论&lt;/h4&gt;检测对称模型的算法基于粒子物理学方法，直接基于场的Wigner分解。&lt;h4&gt;翻译&lt;/h4&gt;我们系统地获得了在平坦背景上传播无宇称违反的完全对称的三秩场的所有线性模型。每个这样的模型仅由其规范对称性定义，这是红外极限下有效场理论的必要属性。通过比较，发现通过其他方法（调整耦合或选择操作符）获得的模型可能对辐射修正不稳定。对每个模型，我们计算了无质量和有质量粒子的谱，以及耦合的鬼和快子约束。我们得出结论，存在基础模型，可以传播一个自旋为一或三的无质量粒子，或同时传播这两个粒子，推广了Campoleoni和Francia的模型。检测对称模型的算法基于粒子物理学方法，直接基于场的Wigner分解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We systematically obtain all linear models which propagate a totallysymmetric rank-three field without parity violation on a flat background. Eachsuch model is defined exclusively by its gauge symmetry, a necessary propertyof effective field theories in the infrared limit. By comparison, modelsobtained by other means (tuning couplings or cherry-picking operators) may beunstable against radiative corrections. For each model, we compute the spectrumof massless and massive particles, and the no-ghost-no-tachyon constraints onthe couplings. We conclude that foundational models exist which can propagateone massless particle of spin one or spin three in isolation, or both particlessimultaneously, generalising the model of Campoleoni and Francia. Our algorithmfor detecting symmetric models is grounded in particle physics methods, beingbased directly on the Wigner decomposition of the field. Compared to our recentanalysis of the totally symmetric rank-three field (whose results we confirmand extend) our new algorithm does not require an ansatz for the symmetrytransformation, and is not restricted to so-called 'free' symmetries.</description>
      <author>example@mail.com (Will Barker, Carlo Marzo, Alessandro Santoni)</author>
      <guid isPermaLink="false">2506.21662v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>Causal Inference for Latent Outcomes Learned with Factor Models</title>
      <link>http://arxiv.org/abs/2506.20549v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 1 table (+ references and supplement). For  open-source R software package, see https://github.com/jennalandy/causalLFO.  For all code used in the simulation studies and data application, see  https://github.com/jennalandy/causalLFO_PAPER&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在高维观测数据中，利用非负矩阵分解方法对潜在结果进行因果推断的问题。&lt;h4&gt;背景&lt;/h4&gt;在基因组学、流行病学、自然语言处理、社会和行为科学以及经济学等多个领域，解决因素模型或表示学习中的因果问题日益重要。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在通过非负矩阵分解方法，探究高维观测数据中潜在结果的因果效应。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新颖、直观且理论上有保证的算法来估计潜在结果的因果效应，同时减轻学习引起的干扰并提高估计效率。&lt;h4&gt;主要发现&lt;/h4&gt;本研究首次正式研究了在此设置下的因果推断问题，并提出了解决学习引起的干扰的方法。&lt;h4&gt;结论&lt;/h4&gt;通过模拟研究和癌症突变特征分析的实际应用，验证了所提算法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;在许多领域（包括基因组学、流行病学、自然语言处理、社会和行为科学以及经济学）中，处理因素模型或表示学习中的因果问题变得越来越重要。在这项工作中，我们研究了使用非负矩阵分解从高维观测数据中得到的潜在结果的因果效应。据我们所知，这是第一个正式处理此设置中因果推断的研究。一个主要挑战是，估计一个潜在因素模型可能会导致个体学习的潜在结果依赖于其他个体的处理，从而违反了标准因果推断假设中的无干扰。我们将这个问题形式化为“学习引起的干扰”，并将其与数据生成过程中存在的干扰区分开来。为了解决这个问题，我们提出了一种新颖的、直观的、理论上有保证的算法来估计潜在结果的因果效应，同时减轻学习引起的干扰并提高估计效率。我们对我们的估计器的一致性提供了理论保证，并通过模拟研究和癌症突变特征分析的实际应用证明了其实际效用。所有基线和提出的方法都可在我们的开源R包causalLFO中找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many fields$\unicode{x2013}$including genomics, epidemiology, naturallanguage processing, social and behavioral sciences, andeconomics$\unicode{x2013}$it is increasingly important to address causalquestions in the context of factor models or representation learning. In thiswork, we investigate causal effects on $\textit{latent outcomes}$ derived fromhigh-dimensional observed data using nonnegative matrix factorization. To thebest of our knowledge, this is the first study to formally address causalinference in this setting. A central challenge is that estimating a latentfactor model can cause an individual's learned latent outcome to depend onother individuals' treatments, thereby violating the standard causal inferenceassumption of no interference. We formalize this issue as$\textit{learning-induced interference}$ and distinguish it from interferencepresent in a data-generating process. To address this, we propose a novel,intuitive, and theoretically grounded algorithm to estimate causal effects onlatent outcomes while mitigating learning-induced interference and improvingestimation efficiency. We establish theoretical guarantees for the consistencyof our estimator and demonstrate its practical utility through simulationstudies and an application to cancer mutational signature analysis. Allbaseline and proposed methods are available in our open-source R package, ${\ttcausalLFO}$.</description>
      <author>example@mail.com (Jenna M. Landy, Dafne Zorzetto, Roberta De Vito, Giovanni Parmigiani)</author>
      <guid isPermaLink="false">2506.20549v2</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SkinningGS: Editable Dynamic Human Scene Reconstruction Using Gaussian Splatting Based on a Skinning Model</title>
      <link>http://arxiv.org/abs/2506.21632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种从单目视频中重建动态人场景中的交互式人像及其背景的方法。&lt;h4&gt;背景&lt;/h4&gt;从单目视频中重建动态人场景中的交互式人像及其背景是一个高度挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;目的是在保证人类运动交互性的同时，实现背景和人类身体的分离重建。&lt;h4&gt;方法&lt;/h4&gt;采用点云解耦和联合优化的策略，引入位置纹理对SMPL身体模型表面进行细分并扩展人类点云。使用卷积神经网络结构根据纹理预测人体点云特征。该策略避免了超参数调整，并高效地用一半的点云数量表示人类点云。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在重建质量上超过了之前的HUGS方法，同时保持了对新姿势和视图的泛化能力。技术实现了超过100 FPS的实时渲染速度，比使用线性混合皮肤(LBS)权重的HUGS速度快约6倍。&lt;h4&gt;结论&lt;/h4&gt;该框架可以扩展到动物场景重建，当有准确的动物模型时。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a method for reconstructing interactive human avatars and their backgrounds from monocular videos of dynamic human scenes. This task is highly challenging. The aim is to achieve the decoupled reconstruction of backgrounds and human bodies while preserving the interactivity of human motion. The strategy adopted is based on point cloud decoupling and joint optimization, introducing a position texture to subdivide the surface of the Skinned Multi-Person Linear (SMPL) body model and expand the human point cloud. A convolutional neural network structure is incorporated to predict human body point cloud features based on texture. This strategy avoids hyperparameter tuning, and efficiently represents human points with half the point cloud of HUGS. This approach ensures high-quality human reconstruction and reduces GPU resource consumption during training. As a result, our method surpasses the previous state-of-the-art HUGS in reconstruction metrics while maintaining the ability to generalize to novel poses and views. Furthermore, our technique achieves real-time rendering at over 100 FPS, ~6 times the HUGS speed using only Linear Blend Skinning (LBS) weights for human transformation. Additionally, this work demonstrates that this framework can be extended to animal scene reconstruction when an accurately-posed model of an animal is available.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reconstructing an interactive human avatar and the background from amonocular video of a dynamic human scene is highly challenging. In this work weadopt a strategy of point cloud decoupling and joint optimization to achievethe decoupled reconstruction of backgrounds and human bodies while preservingthe interactivity of human motion. We introduce a position texture to subdividethe Skinned Multi-Person Linear (SMPL) body model's surface and grow the humanpoint cloud. To capture fine details of human dynamics and deformations, weincorporate a convolutional neural network structure to predict human bodypoint cloud features based on texture. This strategy makes our approach free ofhyperparameter tuning for densification and efficiently represents human pointswith half the point cloud of HUGS. This approach ensures high-quality humanreconstruction and reduces GPU resource consumption during training. As aresult, our method surpasses the previous state-of-the-art HUGS inreconstruction metrics while maintaining the ability to generalize to novelposes and views. Furthermore, our technique achieves real-time rendering atover 100 FPS, $\sim$6$\times$ the HUGS speed using only Linear Blend Skinning(LBS) weights for human transformation. Additionally, this work demonstratesthat this framework can be extended to animal scene reconstruction when anaccurately-posed model of an animal is available.</description>
      <author>example@mail.com (Da Li, Donggang Jia, Markus Hadwiger, Ivan Viola)</author>
      <guid isPermaLink="false">2506.21632v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation</title>
      <link>http://arxiv.org/abs/2506.21805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CitySim是一个利用大型语言模型突破的智能城市模拟器，用于模拟城市环境中的人类行为，以支持社会科学、行为研究和城市规划。&lt;h4&gt;背景&lt;/h4&gt;以往的研究工作常常依赖于僵硬的、手工定制的规则，限制了它们模拟复杂意图、计划和适应性行为的能力。&lt;h4&gt;目的&lt;/h4&gt;提出CitySim，旨在解决上述挑战，实现更真实、更贴近人类行为的模拟。&lt;h4&gt;方法&lt;/h4&gt;CitySim中的代理使用递归价值驱动方法生成日常日程，平衡强制性活动、个人习惯和情境因素。代理还被赋予了信念、长期目标和空间记忆，以实现长期、逼真的模拟。&lt;h4&gt;主要发现&lt;/h4&gt;CitySim在微观和宏观层面上都表现出与真实人类更接近的契合度。通过模拟数万个代理，并在各种现实世界场景下评估他们的集体行为，进行了有见地的实验，包括估计人群密度、预测地点受欢迎程度和评估福祉。&lt;h4&gt;结论&lt;/h4&gt;CitySim被证明是一个可扩展、灵活的测试平台，用于理解和预测城市现象。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modeling human behavior in urban environments is fundamental for socialscience, behavioral studies, and urban planning. Prior work often rely onrigid, hand-crafted rules, limiting their ability to simulate nuancedintentions, plans, and adaptive behaviors. Addressing these challenges, weenvision an urban simulator (CitySim), capitalizing on breakthroughs inhuman-level intelligence exhibited by large language models. In CitySim, agentsgenerate realistic daily schedules using a recursive value-driven approach thatbalances mandatory activities, personal habits, and situational factors. Toenable long-term, lifelike simulations, we endow agents with beliefs, long-termgoals, and spatial memory for navigation. CitySim exhibits closer alignmentwith real humans than prior work, both at micro and macro levels. Additionally,we conduct insightful experiments by modeling tens of thousands of agents andevaluating their collective behaviors under various real-world scenarios,including estimating crowd density, predicting place popularity, and assessingwell-being. Our results highlight CitySim as a scalable, flexible testbed forunderstanding and forecasting urban phenomena.</description>
      <author>example@mail.com (Nicolas Bougie, Narimasa Watanabe)</author>
      <guid isPermaLink="false">2506.21805v1</guid>
      <pubDate>Mon, 30 Jun 2025 14:17:16 +0800</pubDate>
    </item>
    <item>
      <title>SliceGX: Layer-wise GNN Explanation with Model-slicing</title>
      <link>http://arxiv.org/abs/2506.17977v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SliceGX是一种新型的图神经网络（GNN）解释方法，旨在提高GNN作为黑盒模型的可信度。&lt;h4&gt;背景&lt;/h4&gt;现有的GNN解释方法通常通过输入扰动来识别导致GNN最终输出的子图，但这些方法缺乏对中间表示的分层分析，这对于模型诊断和架构优化至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出SliceGX，旨在在GNN的特定层生成解释，并通过分层分析中间表示来提高GNN的可信度。&lt;h4&gt;方法&lt;/h4&gt;SliceGX通过自动将GNN分为层块（模型切片），在每个层块中找到高质量的解释子图，以阐明GNN在目标层的输出。&lt;h4&gt;主要发现&lt;/h4&gt;尽管找到这些分层解释在计算上具有挑战性，但SliceGX开发出高效的算法和优化技术，以增量生成和维护这些子图，并提供了可证明的近似保证。此外，SliceGX还提供了类似SPARQL的查询接口，以便对生成的解释进行声明性访问和搜索。&lt;h4&gt;结论&lt;/h4&gt;通过在大型真实世界图和代表性的GNN架构上的实验，验证了SliceGX的有效性和效率，并说明了其在支持模型调试方面的实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：确保图神经网络（GNN）作为黑盒模型的可信度需要有效的解释方法。现有的GNN解释方法通常通过对输入扰动来识别导致GNN最终输出的子图。然而，这些方法缺乏对中间表示的分层分析，这对于模型诊断和架构优化至关重要。本文介绍了SliceGX，这是一种新颖的GNN解释方法，它以渐进的方式在特定的GNN层生成解释。给定一个GNN M，一组选定的中间层和一个目标层，SliceGX自动将M分为层块（“模型切片”），并在每个层块中找到高质量的解释子图，以阐明M在目标层的输出。虽然找到这样的分层解释在计算上具有挑战性，但我们开发出高效的算法和优化技术，以增量生成和维护这些子图，并提供了可证明的近似保证。此外，SliceGX提供了一个类似SPARQL的查询接口，提供了对生成的解释的声明性访问和搜索能力。通过在大型真实世界图和代表性的GNN架构上的实验，我们验证了SliceGX的有效性和效率，并说明了其在支持模型调试方面的实际应用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring the trustworthiness of graph neural networks (GNNs) as black-boxmodels requires effective explanation methods. Existing GNN explanationstypically apply input perturbations to identify subgraphs that are responsiblefor the occurrence of the final output of GNNs. However, such approaches lackfiner-grained, layer-wise analysis of how intermediate representationscontribute to the final result, capabilities that are crucial for modeldiagnosis and architecture optimization. This paper introduces SliceGX, a novelGNN explanation approach that generates explanations at specific GNN layers ina progressive manner. Given a GNN M, a set of selected intermediate layers, anda target layer, SliceGX automatically segments M into layer blocks ("modelslice") and discovers high-quality explanatory subgraphs in each layer blockthat clarifies the occurrence of output of M at the targeted layer. Althoughfinding such layer-wise explanations is computationally challenging, we developefficient algorithms and optimization techniques that incrementally generateand maintain these subgraphs with provable approximation guarantees.Additionally, SliceGX offers a SPARQL-like query interface, providingdeclarative access and search capacities for the generated explanations.Through experiments on large real-world graphs and representative GNNarchitectures, we verify the effectiveness and efficiency of SliceGX, andillustrate its practical utility in supporting model debugging.</description>
      <author>example@mail.com (Tingting Zhu, Tingyang Chen, Yinghui Wu, Arijit Khan, Xiangyu Ke)</author>
      <guid isPermaLink="false">2506.17977v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
  <item>
      <title>Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test</title>
      <link>http://arxiv.org/abs/2506.21551v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了神经网络训练中的Grokking现象，即在训练损失收敛后测试性能仍然持续提升的现象。作者首次在7B大型语言模型OLMoE的预训练过程中对Grokking进行了研究，并验证了Grokking在大规模基础模型的预训练中仍然发生，尽管不同数据可能异步进入Grokking阶段。&lt;h4&gt;背景&lt;/h4&gt;Grokking现象在神经网络训练中被观察到，但其机制和泛化能力等新兴能力仍然神秘。以往的研究通常在数千个epoch上在小模型上进行训练，而本文首次在大型语言模型OLMoE的预训练过程中研究Grokking。&lt;h4&gt;目的&lt;/h4&gt;研究Grokking现象在大型语言模型预训练中的发生情况，并探究其背后的机制。&lt;h4&gt;方法&lt;/h4&gt;作者计算了训练损失，并在包括数学推理、代码生成和常识/特定领域知识检索在内的多种基准任务上评估了泛化能力。他们通过研究LLM内部动态，揭示了Grokking中“泛化能力的出现”的奥秘，并开发了两个新的指标来量化路径距离和单个路径的复杂性。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，在Grokking过程中，训练样本的路径（即层间的专家选择）从随机、实例特定的转变为更有结构和可共享的。此外，尽管损失已经收敛，样本路径的复杂性仍然降低。这些发现表明了从记忆到泛化的转换，为延迟泛化提供了机制上的解释。&lt;h4&gt;结论&lt;/h4&gt;本文的研究表明，Grokking现象在大规模基础模型的预训练中仍然发生，且路径结构化程度的提高可以减少模型复杂性和提高泛化界限。作者提出的两个新指标可以有效地预测下游任务上的泛化改进，为预训练提供了监控泛化性能的工具。&lt;h4&gt;翻译&lt;/h4&gt;Grokking, i.e., test performance keeps improving long after training loss converged, has been recently witnessed in neural network training, making the mechanism of generalization and other emerging capabilities such as reasoning mysterious. While prior studies usually train small models on a few toy or highly-specific tasks for thousands of epochs, we conduct the first study of grokking on checkpoints during one-pass pretraining of a 7B large language model (LLM), i.e., OLMoE. We compute the training loss and evaluate generalization on diverse benchmark tasks, including math reasoning, code generation, and commonsense/domain-specific knowledge retrieval tasks. Our study, for the first time, verifies that grokking still happens in the pretraining of large-scale foundation models, though different data may enter grokking stages asynchronously. We further demystify grokking's 'emergence of generalization' by investigating LLM internal dynamics. Specifically, we find that training samples' pathways (i.e., expert choices across layers) evolve from random, instance-specific to more structured and shareable between samples during grokking. Also, the complexity of a sample's pathway reduces despite the converged loss. These indicate a memorization-to-generalization conversion, providing a mechanistic explanation of delayed generalization. In the study, we develop two novel metrics to quantify pathway distance and the complexity of a single pathway. We show their ability to predict the generalization improvement on diverse downstream tasks. They are efficient, simple to compute and solely dependent on training data. Hence, they have practical value for pretraining, enabling us to monitor the generalization performance without finetuning and test. Theoretically, we show that more structured pathways reduce model complexity and improve the generalization bound.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grokking, i.e., test performance keeps improving long after training lossconverged, has been recently witnessed in neural network training, making themechanism of generalization and other emerging capabilities such as reasoningmysterious. While prior studies usually train small models on a few toy orhighly-specific tasks for thousands of epochs, we conduct the first study ofgrokking on checkpoints during one-pass pretraining of a 7B large languagemodel (LLM), i.e., OLMoE. We compute the training loss and evaluategeneralization on diverse benchmark tasks, including math reasoning, codegeneration, and commonsense/domain-specific knowledge retrieval tasks.  Our study, for the first time, verifies that grokking still happens in thepretraining of large-scale foundation models, though different data may entergrokking stages asynchronously. We further demystify grokking's "emergence ofgeneralization" by investigating LLM internal dynamics. Specifically, we findthat training samples' pathways (i.e., expert choices across layers) evolvefrom random, instance-specific to more structured and shareable between samplesduring grokking. Also, the complexity of a sample's pathway reduces despite theconverged loss. These indicate a memorization-to-generalization conversion,providing a mechanistic explanation of delayed generalization. In the study, wedevelop two novel metrics to quantify pathway distance and the complexity of asingle pathway. We show their ability to predict the generalization improvementon diverse downstream tasks. They are efficient, simple to compute and solelydependent on training data. Hence, they have practical value for pretraining,enabling us to monitor the generalization performance without finetuning andtest. Theoretically, we show that more structured pathways reduce modelcomplexity and improve the generalization bound.</description>
      <author>example@mail.com (Ziyue Li, Chenrui Fan, Tianyi Zhou)</author>
      <guid isPermaLink="false">2506.21551v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>SAM4D: Segment Anything in Camera and LiDAR Streams</title>
      <link>http://arxiv.org/abs/2506.21547v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV2025, Project Page: https://SAM4D-Project.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SAM4D的多模态和时序基础模型，用于在相机和激光雷达流之间进行可提示的分割。&lt;h4&gt;背景&lt;/h4&gt;SAM4D模型旨在解决自动驾驶场景中动态变化时的分割问题。&lt;h4&gt;目的&lt;/h4&gt;设计SAM4D模型，以实现不同传感器数据的高效融合和分割。&lt;h4&gt;方法&lt;/h4&gt;1. 引入统一的多元模态位置编码（UMPE）来对齐相机和激光雷达特征；2. 提出运动感知跨模态记忆注意力（MCMA）以增强时间一致性和长期特征检索；3. 开发一个多模态自动化数据引擎，结合视频掩码、时空四维重建和跨模态掩码融合；4. 生成比人工标注快得多速度的相机-激光雷达对齐的伪标签。&lt;h4&gt;主要发现&lt;/h4&gt;SAM4D模型在Waymo-4DSeg数据集上的实验表明，它具有强大的跨模态分割能力，并且在数据标注方面具有巨大潜力。&lt;h4&gt;结论&lt;/h4&gt;SAM4D模型为自动驾驶场景中的动态变化提供了有效的解决方案，并有望提高数据标注的效率。&lt;h4&gt;翻译&lt;/h4&gt;We present SAM4D, a multi-modal and temporal foundation model designed for promptable segmentation across camera and LiDAR streams. Unified Multi-modal Positional Encoding (UMPE) is introduced to align camera and LiDAR features in a shared 3D space, enabling seamless cross-modal prompting and interaction. Additionally, we propose Motion-aware Cross-modal Memory Attention (MCMA), which leverages ego-motion compensation to enhance temporal consistency and long-horizon feature retrieval, ensuring robust segmentation across dynamically changing autonomous driving scenes. To avoid annotation bottlenecks, we develop a multi-modal automated data engine that synergizes VFM-driven video masklets, spatiotemporal 4D reconstruction, and cross-modal masklet fusion. This framework generates camera-LiDAR aligned pseudo-labels at a speed orders of magnitude faster than human annotation while preserving VFM-derived semantic fidelity in point cloud representations. We conduct extensive experiments on the constructed Waymo-4DSeg, which demonstrate the powerful cross-modalsegmentation ability and great potential in data annotation of proposed SAM4D.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present SAM4D, a multi-modal and temporal foundation model designed forpromptable segmentation across camera and LiDAR streams. Unified Multi-modalPositional Encoding (UMPE) is introduced to align camera and LiDAR features ina shared 3D space, enabling seamless cross-modal prompting and interaction.Additionally, we propose Motion-aware Cross-modal Memory Attention (MCMA),which leverages ego-motion compensation to enhance temporal consistency andlong-horizon feature retrieval, ensuring robust segmentation across dynamicallychanging autonomous driving scenes. To avoid annotation bottlenecks, we developa multi-modal automated data engine that synergizes VFM-driven video masklets,spatiotemporal 4D reconstruction, and cross-modal masklet fusion. Thisframework generates camera-LiDAR aligned pseudo-labels at a speed orders ofmagnitude faster than human annotation while preserving VFM-derived semanticfidelity in point cloud representations. We conduct extensive experiments onthe constructed Waymo-4DSeg, which demonstrate the powerful cross-modalsegmentation ability and great potential in data annotation of proposed SAM4D.</description>
      <author>example@mail.com (Jianyun Xu, Song Wang, Ziqian Ni, Chunyong Hu, Sheng Yang, Jianke Zhu, Qiang Li)</author>
      <guid isPermaLink="false">2506.21547v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21541v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;StruMamba3D是一种新的自监督点云表示学习方法，通过解决Mamba方法在处理3D点云时的问题，提升了空间状态模型（SSM）的性能。&lt;h4&gt;背景&lt;/h4&gt;Mamba方法在点云表示学习中表现出色，但存在破坏3D点云邻接关系和无法保留长序列记忆的问题。&lt;h4&gt;目的&lt;/h4&gt;提出StruMamba3D以解决Mamba方法在处理3D点云时的局限性。&lt;h4&gt;方法&lt;/h4&gt;StruMamba3D通过设计空间状态和使用它们作为代理来保持点之间的空间依赖关系；增强SSM的状态更新策略并引入轻量级卷积以促进空间状态之间的交互；以及通过引入序列长度自适应策略来降低预训练Mamba模型对输入长度的敏感性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，StruMamba3D在四个下游任务中表现出优越的性能，并在ModelNet40上达到95.1%的准确率，在ScanObjectNN最具挑战性的分割上达到92.75%的准确率。&lt;h4&gt;结论&lt;/h4&gt;StruMamba3D是一种有效的点云表示学习方法，能够显著提升基于SSM的点云处理性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, Mamba-based methods have demonstrated impressive performance inpoint cloud representation learning by leveraging State Space Model (SSM) withthe efficient context modeling ability and linear complexity. However, thesemethods still face two key issues that limit the potential of SSM: Destroyingthe adjacency of 3D points during SSM processing and failing to retainlong-sequence memory as the input length increases in downstream tasks. Toaddress these issues, we propose StruMamba3D, a novel paradigm forself-supervised point cloud representation learning. It enjoys several merits.First, we design spatial states and use them as proxies to preserve spatialdependencies among points. Second, we enhance the SSM with a state-wise updatestrategy and incorporate a lightweight convolution to facilitate interactionsbetween spatial states for efficient structure modeling. Third, our methodreduces the sensitivity of pre-trained Mamba-based models to varying inputlengths by introducing a sequence length-adaptive strategy. Experimentalresults across four downstream tasks showcase the superior performance of ourmethod. In addition, our method attains the SOTA 95.1% accuracy on ModelNet40and 92.75% accuracy on the most challenging split of ScanObjectNN withoutvoting strategy.</description>
      <author>example@mail.com (Chuxin Wang, Yixin Zha, Wenfei Yang, Tianzhu Zhang)</author>
      <guid isPermaLink="false">2506.21541v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation</title>
      <link>http://arxiv.org/abs/2506.21237v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DiMPLe（Disentangled Multi-Modal Prompt Learning）是一种新的方法，用于在多模态学习中分解视觉和语言模态中的不变特征和虚假特征。&lt;h4&gt;背景&lt;/h4&gt;视觉数据中的虚假相关性常常阻碍了出分布（OOD）性能。&lt;h4&gt;目的&lt;/h4&gt;提高多模态学习中对新颖类别的泛化能力和对分布变化的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;DiMPLe结合了三个关键目标：（1）最小化不变特征和虚假特征之间的互信息，（2）对虚假特征进行正则化，（3）对不变特征进行对比学习。&lt;h4&gt;主要发现&lt;/h4&gt;在11个不同的数据集上平均，DiMPLe在CoOp-OOD方法之上表现出更优的性能，并在基础类别准确率上提高了15.27，在新颖类别准确率上提高了44.31。&lt;h4&gt;结论&lt;/h4&gt;DiMPLe通过分解特征，显著提升了多模态学习的性能和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce DiMPLe (Disentangled Multi-Modal Prompt Learning), a novelapproach to disentangle invariant and spurious features across vision andlanguage modalities in multi-modal learning. Spurious correlations in visualdata often hinder out-of-distribution (OOD) performance. Unlike prior methodsfocusing solely on image features, DiMPLe disentangles features within andacross modalities while maintaining consistent alignment, enabling bettergeneralization to novel classes and robustness to distribution shifts. Ourmethod combines three key objectives: (1) mutual information minimizationbetween invariant and spurious features, (2) spurious feature regularization,and (3) contrastive learning on invariant features. Extensive experimentsdemonstrate DiMPLe demonstrates superior performance compared to CoOp-OOD, whenaveraged across 11 diverse datasets, and achieves absolute gains of 15.27 inbase class accuracy and 44.31 in novel class accuracy.</description>
      <author>example@mail.com (Umaima Rahman, Mohammad Yaqub, Dwarikanath Mahapatra)</author>
      <guid isPermaLink="false">2506.21237v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>CA-I2P: Channel-Adaptive Registration Network with Global Optimal Selection</title>
      <link>http://arxiv.org/abs/2506.21364v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICCV 2025 accepted&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种无检测方法，通过Channel Adaptive Adjustment Module (CAA)和Global Optimal Selection Module (GOS)模块，解决了图像和点云特征匹配中的通道注意力差异和冗余对应问题，实现了图像到点云的高精度注册。&lt;h4&gt;背景&lt;/h4&gt;检测-free方法通常采用由粗到细的流程，提取图像和点云特征进行局部匹配和密集像素到点的对应关系细化。然而，图像和点云之间的特征通道注意力差异可能导致匹配结果退化，最终影响注册精度。&lt;h4&gt;目的&lt;/h4&gt;为了解决特征通道注意力差异和场景中相似结构导致的冗余对应问题，提高图像到点云注册的精度。&lt;h4&gt;方法&lt;/h4&gt;提出了Channel Adaptive Adjustment Module (CAA)模块来增强同模态特征并抑制跨模态敏感性，以及Global Optimal Selection Module (GOS)模块用全局优化代替局部选择。&lt;h4&gt;主要发现&lt;/h4&gt;在RGB-D Scenes V2和7-Scenes数据集上的实验表明，该方法在图像到点云注册方面取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法通过CAA和GOS模块提高了图像到点云注册的精度，在相关任务中具有优越的性能。&lt;h4&gt;翻译&lt;/h4&gt;Detection-free methods typically follow a coarse-to-fine pipeline, extracting image and point cloud features for patch-level matching and refining dense pixel-to-point correspondences. However, differences in feature channel attention between images and point clouds may lead to degraded matching results, ultimately impairing registration accuracy. Furthermore, similar structures in the scene could lead to redundant correspondences in cross-modal matching. To address these issues, we propose Channel Adaptive Adjustment Module (CAA) and Global Optimal Selection Module (GOS). CAA enhances intra-modal features and suppresses cross-modal sensitivity, while GOS replaces local selection with global optimization. Experiments on RGB-D Scenes V2 and 7-Scenes demonstrate the superiority of our method, achieving state-of-the-art performance in image-to-point cloud registration.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Detection-free methods typically follow a coarse-to-fine pipeline, extractingimage and point cloud features for patch-level matching and refining densepixel-to-point correspondences. However, differences in feature channelattention between images and point clouds may lead to degraded matchingresults, ultimately impairing registration accuracy. Furthermore, similarstructures in the scene could lead to redundant correspondences in cross-modalmatching. To address these issues, we propose Channel Adaptive AdjustmentModule (CAA) and Global Optimal Selection Module (GOS). CAA enhancesintra-modal features and suppresses cross-modal sensitivity, while GOS replaceslocal selection with global optimization. Experiments on RGB-D Scenes V2 and7-Scenes demonstrate the superiority of our method, achieving state-of-the-artperformance in image-to-point cloud registration.</description>
      <author>example@mail.com (Zhixin Cheng, Jiacheng Deng, Xinjun Li, Xiaotian Yin, Bohao Liao, Baoqun Yin, Wenfei Yang, Tianzhu Zhang)</author>
      <guid isPermaLink="false">2506.21364v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Global and Local Entailment Learning for Natural World Imagery</title>
      <link>http://arxiv.org/abs/2506.21476v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Radial Cross-Modal Embeddings (RCME)的框架，用于显式建模具有传递性质的知识，以解决视觉-语言模型中数据层次结构学习的问题。&lt;h4&gt;背景&lt;/h4&gt;现有工作尝试通过蕴含学习来解决这个问题，但未能显式地建模蕴含的传递性质，这在表示空间中建立了顺序和语义之间的关系。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够优化视觉-语言模型中概念部分顺序的框架，并构建一个能够表示生命树中层次结构的视觉-语言基础模型。&lt;h4&gt;方法&lt;/h4&gt;引入了RCME框架，并通过该框架开发了一个能够处理层次分类和检索任务的视觉-语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;在层次物种分类和检索任务上的实验表明，与现有最先进模型相比，本文提出的模型表现更优。&lt;h4&gt;结论&lt;/h4&gt;本文提出的RCME框架和模型为视觉-语言模型中的层次结构学习提供了有效的解决方案，并已开源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在视觉-语言模型中学习数据的层次结构是一个重大的挑战。先前的工作通过采用蕴含学习来尝试解决这个问题。然而，这些方法未能显式地建模蕴含的传递性质，这在本表示空间中建立了顺序和语义之间的关系。在本工作中，我们引入了Radial Cross-Modal Embeddings (RCME)，这是一个能够显式建模传递性质蕴含的框架。我们提出的框架优化了视觉-语言模型中概念的部分顺序。通过利用我们的框架，我们开发了一个能够表示生命树中层次结构的分层视觉-语言基础模型。我们在层次物种分类和检索任务上的实验证明了与现有最先进模型相比，我们模型性能的提升。我们的代码和模型已开源，请访问https://vishu26.github.io/RCME/index.html。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning the hierarchical structure of data in vision-language models is asignificant challenge. Previous works have attempted to address this challengeby employing entailment learning. However, these approaches fail to model thetransitive nature of entailment explicitly, which establishes the relationshipbetween order and semantics within a representation space. In this work, weintroduce Radial Cross-Modal Embeddings (RCME), a framework that enables theexplicit modeling of transitivity-enforced entailment. Our proposed frameworkoptimizes for the partial order of concepts within vision-language models. Byleveraging our framework, we develop a hierarchical vision-language foundationmodel capable of representing the hierarchy in the Tree of Life. Ourexperiments on hierarchical species classification and hierarchical retrievaltasks demonstrate the enhanced performance of our models compared to theexisting state-of-the-art models. Our code and models are open-sourced athttps://vishu26.github.io/RCME/index.html.</description>
      <author>example@mail.com (Srikumar Sastry, Aayush Dhakal, Eric Xing, Subash Khanal, Nathan Jacobs)</author>
      <guid isPermaLink="false">2506.21476v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>TopK Language Models</title>
      <link>http://arxiv.org/abs/2506.21468v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TopK语言模型（TopK LMs），通过在Transformer架构中加入TopK激活函数，解决了稀疏自编码器（SAEs）在解释Transformer语言模型激活空间时的局限性。&lt;h4&gt;背景&lt;/h4&gt;稀疏自编码器（SAEs）在分析Transformer语言模型的激活空间方面发挥了重要作用，但它们存在一些缺陷，如训练后期的局限性、特征稳定性不足等问题。&lt;h4&gt;目的&lt;/h4&gt;提出TopK LMs，旨在解决SAEs的局限性，提高模型的可解释性和可控性。&lt;h4&gt;方法&lt;/h4&gt;在Transformer架构中引入TopK激活函数，使模型的隐藏状态等同于TopK SAE的潜在特征，从而实现无需后训练的解释能力。&lt;h4&gt;主要发现&lt;/h4&gt;TopK LMs在模型大小、计算效率和可解释性之间提供了良好的平衡，并且能够通过神经元干预成功引导模型学习，同时便于分析神经元在不同检查点和层上的形成过程。&lt;h4&gt;结论&lt;/h4&gt;TopK LMs是理解和研究语言模型如何学习和表示概念的有效工具，将显著推进模型可解释性和可控性的未来研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：稀疏自编码器（SAEs）已成为分析Transformer语言模型（LMs）激活空间的重要工具。然而，SAEs存在一些缺点，这些缺点降低了它们的效用和内部有效性。由于SAEs是后期训练的，因此不清楚未能发现某个概念是SAE本身的失败，还是由于底层LM没有表示这个概念。这个问题由于训练条件和架构选择的影响而加剧，这些因素影响着SAE学习的特征。在追踪LM在训练期间学习概念的过程中，特征的不稳定性也使得难以在不同检查点之间比较SAEs的特征。为了解决这些限制，我们提出了一种对Transformer架构的修改，该修改在选定的层中引入了TopK激活函数，使得模型的隐藏状态等同于TopK SAE的潜在特征。这种方法消除了后期训练的需要，同时提供了与SAEs相当的解释能力。由此产生的TopK LMs在模型大小、计算效率和可解释性之间提供了有利的权衡。尽管这种架构改变很简单，但TopK LMs在保持原有能力的同时，提供了稳健的可解释性收益。我们的实验表明，TopK LMs学习的稀疏表示可以通过有针对性的神经元干预来成功引导，并促进对神经元形成过程的详细分析，这些特点使TopK LMs成为理解语言模型如何学习和表示概念的有效工具，我们相信这将显著推进模型可解释性和可控性的未来研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sparse autoencoders (SAEs) have become an important tool for analyzing andinterpreting the activation space of transformer-based language models (LMs).However, SAEs suffer several shortcomings that diminish their utility andinternal validity. Since SAEs are trained post-hoc, it is unclear if thefailure to discover a particular concept is a failure on the SAE's side or dueto the underlying LM not representing this concept. This problem is exacerbatedby training conditions and architecture choices affecting which features an SAElearns. When tracing how LMs learn concepts during training, the lack offeature stability also makes it difficult to compare SAEs features acrossdifferent checkpoints. To address these limitations, we introduce amodification to the transformer architecture that incorporates a TopKactivation function at chosen layers, making the model's hidden statesequivalent to the latent features of a TopK SAE. This approach eliminates theneed for post-hoc training while providing interpretability comparable to SAEs.The resulting TopK LMs offer a favorable trade-off between model size,computational efficiency, and interpretability. Despite this simplearchitectural change, TopK LMs maintain their original capabilities whileproviding robust interpretability benefits. Our experiments demonstrate thatthe sparse representations learned by TopK LMs enable successful steeringthrough targeted neuron interventions and facilitate detailed analysis ofneuron formation processes across checkpoints and layers. These features makeTopK LMs stable and reliable tools for understanding how language models learnand represent concepts, which we believe will significantly advance futureresearch on model interpretability and controllability.</description>
      <author>example@mail.com (Ryosuke Takahashi, Tatsuro Inaba, Kentaro Inui, Benjamin Heinzerling)</author>
      <guid isPermaLink="false">2506.21468v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>CoPa-SG: Dense Scene Graphs with Parametric and Proto-Relations</title>
      <link>http://arxiv.org/abs/2506.21357v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CoPa-SG的合成场景图数据集，旨在解决场景图数据不准确的问题，并引入了参数关系和原型关系两个新概念，以提升场景图生成模型的性能和下游应用的能力。&lt;h4&gt;背景&lt;/h4&gt;现有的2D场景图在场景理解方面提供了结构化和可解释的框架，但缺乏准确的数据。&lt;h4&gt;目的&lt;/h4&gt;克服数据瓶颈，提升场景图生成模型的准确性和下游应用的能力。&lt;h4&gt;方法&lt;/h4&gt;提出了CoPa-SG数据集，该数据集具有高度精确的地面实况和详尽的对象关系标注。同时，引入了参数关系和原型关系两个新概念。&lt;h4&gt;主要发现&lt;/h4&gt;CoPa-SG数据集能够帮助比较不同场景图生成模型的性能，新引入的关系类型可以增强下游应用中的规划和推理能力。&lt;h4&gt;结论&lt;/h4&gt;CoPa-SG数据集和新的关系类型有助于提升场景图生成模型的性能和下游应用的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 2D scene graphs provide a structural and explainable framework for sceneunderstanding. However, current work still struggles with the lack of accuratescene graph data. To overcome this data bottleneck, we present CoPa-SG, asynthetic scene graph dataset with highly precise ground truth and exhaustiverelation annotations between all objects. Moreover, we introduce parametric andproto-relations, two new fundamental concepts for scene graphs. The formerprovides a much more fine-grained representation than its traditionalcounterpart by enriching relations with additional parameters such as angles ordistances. The latter encodes hypothetical relations in a scene graph anddescribes how relations would form if new objects are placed in the scene.Using CoPa-SG, we compare the performance of various scene graph generationmodels. We demonstrate how our new relation types can be integrated indownstream applications to enhance planning and reasoning capabilities.</description>
      <author>example@mail.com (Julian Lorenz, Mrunmai Phatak, Robin Schön, Katja Ludwig, Nico Hörmann, Annemarie Friedrich, Rainer Lienhart)</author>
      <guid isPermaLink="false">2506.21357v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing</title>
      <link>http://arxiv.org/abs/2506.21448v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ThinkSound是一种利用思维链推理的框架，旨在通过逐步交互式的方式生成和编辑视频音频，以实现高保真度的音频输出。&lt;h4&gt;背景&lt;/h4&gt;尽管端到端视频到音频生成技术得到了显著提升，但捕捉视觉内容细微差别的真实音频仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够生成高保真音频的框架，该音频能够真实地捕捉视觉内容的细微差别。&lt;h4&gt;方法&lt;/h4&gt;ThinkSound将音频生成过程分解为三个互补阶段：基础声音效果生成、基于对象的交互式精细调整和基于自然语言指令的定向编辑。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，ThinkSound在视频到音频生成方面达到了最先进的性能，并在Movie Gen Audio基准测试中表现出色。&lt;h4&gt;结论&lt;/h4&gt;ThinkSound框架通过其独特的思维链推理和音频生成方法，为视频音频生成领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;While end-to-end video-to-audio generation has greatly improved, producing high-fidelity audio that authentically captures the nuances of visual content remains challenging. Like professionals in the creative industries, such generation requires sophisticated reasoning about items such as visual dynamics, acoustic environments, and temporal relationships. We present ThinkSound, a novel framework that leverages Chain-of-Thought (CoT) reasoning to enable stepwise, interactive audio generation and editing for videos. Our approach decomposes the process into three complementary stages: foundational foley generation that creates semantically coherent soundscapes, interactive object-centric refinement through precise user interactions, and targeted editing guided by natural language instructions. At each stage, a multimodal large language model generates contextually aligned CoT reasoning that guides a unified audio foundation model. Furthermore, we introduce AudioCoT, a comprehensive dataset with structured reasoning annotations that establishes connections between visual content, textual descriptions, and sound synthesis. Experiments demonstrate that ThinkSound achieves state-of-the-art performance in video-to-audio generation across both audio metrics and CoT metrics and excels in out-of-distribution Movie Gen Audio benchmark. The demo page is available at https://ThinkSound-Demo.github.io.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While end-to-end video-to-audio generation has greatly improved, producinghigh-fidelity audio that authentically captures the nuances of visual contentremains challenging. Like professionals in the creative industries, suchgeneration requires sophisticated reasoning about items such as visualdynamics, acoustic environments, and temporal relationships. We present\textbf{ThinkSound}, a novel framework that leverages Chain-of-Thought (CoT)reasoning to enable stepwise, interactive audio generation and editing forvideos. Our approach decomposes the process into three complementary stages:foundational foley generation that creates semantically coherent soundscapes,interactive object-centric refinement through precise user interactions, andtargeted editing guided by natural language instructions. At each stage, amultimodal large language model generates contextually aligned CoT reasoningthat guides a unified audio foundation model. Furthermore, we introduce\textbf{AudioCoT}, a comprehensive dataset with structured reasoningannotations that establishes connections between visual content, textualdescriptions, and sound synthesis. Experiments demonstrate that ThinkSoundachieves state-of-the-art performance in video-to-audio generation across bothaudio metrics and CoT metrics and excels in out-of-distribution Movie Gen Audiobenchmark. The demo page is available at https://ThinkSound-Demo.github.io.</description>
      <author>example@mail.com (Huadai Liu, Jialei Wang, Kaicheng Luo, Wen Wang, Qian Chen, Zhou Zhao, Wei Xue)</author>
      <guid isPermaLink="false">2506.21448v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>ACTLLM: Action Consistency Tuned Large Language Model</title>
      <link>http://arxiv.org/abs/2506.21250v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为ACTLLM（动作一致性调整大型语言模型）的新方法，用于动态环境中的机器人操作。&lt;h4&gt;背景&lt;/h4&gt;传统的基于视觉的系统在学习和执行任务以及空间推理方面往往表现不佳，这限制了它们在动态环境中的适应性。&lt;h4&gt;目的&lt;/h4&gt;ACTLLM通过利用语言来构建结构化场景描述符，通过灵活的语言指令提供统一的空间理解和任务性能接口，从而解决这些挑战。&lt;h4&gt;方法&lt;/h4&gt;ACTLLM引入了一种新的动作一致性约束，将视觉感知与对应动作相一致，从而增强可操作视觉表示的学习。此外，将操作任务的马尔可夫决策过程重新构造成多轮视觉对话框架。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法能够通过任务执行的历史记录增强上下文相关性，对长期任务执行进行建模。在评估中，ACTLLM在各种场景中表现出色，证明了其在具有挑战性的基于视觉的机器人操作任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;ACTLLM在动态环境中表现优异，为机器人操作提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper introduces ACTLLM (Action Consistency Tuned Large Language Model),a novel approach for robot manipulation in dynamic environments. Traditionalvision-based systems often struggle to learn visual representations that excelin both task execution and spatial reasoning, thereby limiting theiradaptability in dynamic environments. ACTLLM addresses these challenges byharnessing language to craft structured scene descriptors, providing a uniforminterface for both spatial understanding and task performance through flexiblelanguage instructions. Moreover, we introduce a novel action consistencyconstraint that aligns visual perception with corresponding actions, therebyenhancing the learning of actionable visual representations. Additionally, wehave reformulated the Markov decision process for manipulation tasks into amulti-turn visual dialogue framework. This approach enables the modeling oflong-term task execution with enhanced contextual relevance derived from thehistory of task execution. During our evaluation, ACTLLM excels in diversescenarios, proving its effectiveness on challenging vision-based robotmanipulation tasks.</description>
      <author>example@mail.com (Jing Bi, Lianggong Bruce Wen, Zhang Liu, Chenliang Xu)</author>
      <guid isPermaLink="false">2506.21250v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Text2Cypher Across Languages: Evaluating Foundational Models Beyond English</title>
      <link>http://arxiv.org/abs/2506.21445v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在多种语言上，基础大型语言模型在Text2Cypher任务中的性能，并评估了将任务提示翻译成西班牙语和土耳其语的影响。&lt;h4&gt;背景&lt;/h4&gt;近年来，大型语言模型在自然语言接口方面取得了进展，如Text2SQL、Text2SPARQL和Text2Cypher，这些接口提高了数据库的可访问性。然而，大多数研究仅关注英语，在其他语言上的评估有限。&lt;h4&gt;目的&lt;/h4&gt;研究不同语言基础大型语言模型在Text2Cypher任务上的性能，并评估将任务提示翻译成西班牙语和土耳其语的影响。&lt;h4&gt;方法&lt;/h4&gt;创建并发布了一个多语言测试集，将英语问题翻译成西班牙语和土耳其语，同时保留原始的Cypher查询，以实现公平的双语比较。使用标准化的提示和指标评估多个基础模型。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示了一致的性能模式：英语表现最佳，其次是西班牙语，土耳其语表现最差。这归因于训练数据可用性和语言特征的差异。此外，将任务提示翻译成西班牙语和土耳其语对评估指标的影响很小。&lt;h4&gt;结论&lt;/h4&gt;研究结果强调了在多语言查询生成中需要更多包容性的评估和发展。未来的工作包括模式本地化和跨多种语言的微调。&lt;h4&gt;翻译&lt;/h4&gt;通过将英语问题翻译成西班牙语和土耳其语，同时保留原始的Cypher查询，创建并发布了一个多语言测试集，以实现公平的双语比较。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models have enabled natural languageinterfaces that translate user questions into database queries, such asText2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance databaseaccessibility, most research today focuses solely on English, with limitedevaluation in other languages. This paper investigates the performance offoundational LLMs on the Text2Cypher task across multiple languages. We createand release a multilingual test set by translating English questions intoSpanish and Turkish while preserving the original Cypher queries, enabling faircross-lingual comparison. We evaluate multiple foundational models usingstandardized prompts and metrics. Our results show a consistent performancepattern: highest on English, then Spanish, and lowest on Turkish. We attributethis to differences in training data availability and linguisticcharacteristics. Additionally, we explore the impact of translating taskprompts into Spanish and Turkish. Results show little to no change inevaluation metrics, suggesting prompt translation has minor impact. Ourfindings highlight the need for more inclusive evaluation and development inmultilingual query generation. Future work includes schema localization andfine-tuning across diverse languages.</description>
      <author>example@mail.com (Makbule Gulcin Ozsoy, William Tai)</author>
      <guid isPermaLink="false">2506.21445v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation</title>
      <link>http://arxiv.org/abs/2506.21444v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了不典型有丝分裂的自动分类问题，通过深度学习方法在乳腺癌数据集上进行了基准测试，并提出了新的数据集和模型调整方法。&lt;h4&gt;背景&lt;/h4&gt;不典型有丝分裂是肿瘤恶性的独立预后相关标志物，但其识别因低发病率、形态学差异、病理学家间评分不一致和数据集类别不平衡而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;比较不同深度学习方法在自动分类不典型有丝分裂图像方面的性能，并提出新的数据集和模型调整技术。&lt;h4&gt;方法&lt;/h4&gt;基于AMi-Br数据集，比较了基准模型、带有线性探测的基础模型和通过低秩自适应（LoRA）微调的基础模型。此外，引入了两个新的数据集：AtNorM-Br和AtNorM-MD。&lt;h4&gt;主要发现&lt;/h4&gt;在AMi-Br、AtNorm-Br和AtNorM-MD数据集上，分别达到了平均平衡准确率0.8135、0.7696和0.7705，其中基于LoRA的Virchow-line基础模型调整效果最佳。&lt;h4&gt;结论&lt;/h4&gt;尽管不典型有丝分裂分类是一个具有挑战性的问题，但通过转移学习和模型微调技术的最新进展可以有效地解决。&lt;h4&gt;翻译&lt;/h4&gt;摘要：不典型有丝分裂标志着细胞分裂过程的偏差，可以成为肿瘤恶性的独立预后相关标志物。然而，由于其低发病率、与正常有丝分裂的细微形态学差异、病理学家之间评分的不一致以及数据集类别不平衡，其识别仍然具有挑战性。基于乳腺癌不典型有丝分裂数据集（AMi-Br），本研究提出了一套全面基准，比较了深度学习方法在自动分类不典型有丝分裂图像（AMF）方面的性能，包括基线模型、带有线性探测的基础模型以及通过低秩自适应（LoRA）微调的基础模型。为了进行严格的评估，我们进一步引入了两个新的留出数据集——AtNorM-Br，它是来自TCGA乳腺癌队列的有丝分裂数据集，以及AtNorM-MD，它是来自MIDOG++训练集的多领域有丝分裂数据集。我们发现，在域内AMi-Br和域外AtNorm-Br以及AtNorM-MD数据集上，平均平衡准确率分别达到了0.8135、0.7696和0.7705，其中基于LoRA的Virchow-line基础模型调整效果尤为显著。我们的研究表明，尽管不典型有丝分裂分类是一个具有挑战性的问题，但可以通过使用最近在迁移学习和模型微调技术方面的进展来有效解决。我们将在本文中使用的所有代码和数据都可在以下GitHub仓库中找到：https://github.com/DeepMicroscopy/AMi-Br_Benchmark。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Atypical mitoses mark a deviation in the cell division process that can be anindependent prognostically relevant marker for tumor malignancy. However, theiridentification remains challenging due to low prevalence, at times subtlemorphological differences from normal mitoses, low inter-rater agreement amongpathologists, and class imbalance in datasets. Building on the Atypical Mitosisdataset for Breast Cancer (AMi-Br), this study presents a comprehensivebenchmark comparing deep learning approaches for automated atypical mitoticfigure (AMF) classification, including baseline models, foundation models withlinear probing, and foundation models fine-tuned with low-rank adaptation(LoRA). For rigorous evaluation, we further introduce two new hold-out AMFdatasets - AtNorM-Br, a dataset of mitoses from the The TCGA breast cancercohort, and AtNorM-MD, a multi-domain dataset of mitoses from the MIDOG++training set. We found average balanced accuracy values of up to 0.8135,0.7696, and 0.7705 on the in-domain AMi-Br and the out-of-domain AtNorm-Br andAtNorM-MD datasets, respectively, with the results being particularly good forLoRA-based adaptation of the Virchow-line of foundation models. Our work showsthat atypical mitosis classification, while being a challenging problem, can beeffectively addressed through the use of recent advances in transfer learningand model fine-tuning techniques. We make available all code and data used inthis paper in this github repository:https://github.com/DeepMicroscopy/AMi-Br_Benchmark.</description>
      <author>example@mail.com (Sweta Banerjee, Viktoria Weiss, Taryn A. Donovan, Rutger A. Fick, Thomas Conrad, Jonas Ammeling, Nils Porsche, Robert Klopfleisch, Christopher Kaltenecker, Katharina Breininger, Marc Aubreville, Christof A. Bertram)</author>
      <guid isPermaLink="false">2506.21444v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Topology-Aware Modeling for Unsupervised Simulation-to-Reality Point Cloud Recognition</title>
      <link>http://arxiv.org/abs/2506.21165v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为TAM的拓扑感知建模框架，用于解决从3D物体形状的点集学习语义表示时遇到的挑战，特别是在模拟到现实（Sim2Real）的领域适应中。&lt;h4&gt;背景&lt;/h4&gt;由于数据采集方法的不同，从3D物体形状的点集学习语义表示面临显著的几何变化。训练数据通常使用点模拟器生成，而测试数据使用不同的3D传感器收集，导致模拟到现实的领域差距，限制了点分类器的泛化能力。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文旨在提出一种能够有效减少领域差距并提高适应过程鲁棒性的方法。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法利用全局空间拓扑，通过低级、高频的3D结构来减轻领域差距。此外，通过一个新颖的自监督学习任务来建模局部几何特征之间的拓扑关系。同时，还提出了一种结合跨领域对比学习和自训练的高级自训练策略，以减少噪声伪标签的影响并提高适应过程的鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;在三个公共Sim2Real基准上的实验结果表明，本文的TAM框架在所有评估任务中均优于最先进的方法，并验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;TAM框架能够有效提高Sim2Real领域适应的泛化能力，为解决领域差距问题提供了一种新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从3D物体形状的点集学习语义表示通常受到显著几何变化的挑战，这主要由于数据采集方法的不同。通常，训练数据使用点模拟器生成，而测试数据使用不同的3D传感器收集，导致模拟到现实（Sim2Real）的领域差距，限制了点分类器的泛化能力。当前的无监督领域自适应（UDA）技术难以应对这一差距，因为它们通常缺乏鲁棒的、领域无关的描述符，能够捕获全局拓扑信息，从而导致过度拟合到源域有限的语义模式。为了解决这一问题，我们提出了一种新的拓扑感知建模（TAM）框架，用于对象点云上的Sim2Real UDA。我们的方法通过利用全局空间拓扑，通过低级、高频的3D结构来减轻领域差距，并通过一个新颖的自监督学习任务来建模局部几何特征的拓扑关系。此外，我们还提出了一种结合跨领域对比学习和自训练的高级自训练策略，有效地减少了噪声伪标签的影响，并增强了适应过程的鲁棒性。在三个公共Sim2Real基准上的实验结果验证了我们的TAM框架的有效性，显示出在所有评估任务中相对于最先进方法的持续改进。本文的工作源代码将在https://github.com/zou-longkun/TAG.git上提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning semantic representations from point sets of 3D object shapes isoften challenged by significant geometric variations, primarily due todifferences in data acquisition methods. Typically, training data is generatedusing point simulators, while testing data is collected with distinct 3Dsensors, leading to a simulation-to-reality (Sim2Real) domain gap that limitsthe generalization ability of point classifiers. Current unsupervised domainadaptation (UDA) techniques struggle with this gap, as they often lack robust,domain-insensitive descriptors capable of capturing global topologicalinformation, resulting in overfitting to the limited semantic patterns of thesource domain. To address this issue, we introduce a novel Topology-AwareModeling (TAM) framework for Sim2Real UDA on object point clouds. Our approachmitigates the domain gap by leveraging global spatial topology, characterizedby low-level, high-frequency 3D structures, and by modeling the topologicalrelations of local geometric features through a novel self-supervised learningtask. Additionally, we propose an advanced self-training strategy that combinescross-domain contrastive learning with self-training, effectively reducing theimpact of noisy pseudo-labels and enhancing the robustness of the adaptationprocess. Experimental results on three public Sim2Real benchmarks validate theeffectiveness of our TAM framework, showing consistent improvements overstate-of-the-art methods across all evaluated tasks. The source code of thiswork will be available at https://github.com/zou-longkun/TAG.git.</description>
      <author>example@mail.com (Longkun Zou, Kangjun Liu, Ke Chen, Kailing Guo, Kui Jia, Yaowei Wang)</author>
      <guid isPermaLink="false">2506.21165v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Temporal Rate Reduction Clustering for Human Motion Segmentation</title>
      <link>http://arxiv.org/abs/2506.21249v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper is accepted by ICCV 2025. The first two authors are equally  contributed&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Temporal Rate Reduction Clustering ($ext{TR}^2ext{C}$) 的新型Human Motion Segmentation (HMS)方法，旨在通过联合学习结构化表示和亲和度来分割视频中的帧序列。&lt;h4&gt;背景&lt;/h4&gt;现有的HMS方法主要基于假设高维时间数据与Union-of-Subspaces (UoS)分布相一致，但在处理具有杂乱背景的复杂人类运动时，这种假设可能不适用。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一种能够有效分割包含复杂人类运动和杂乱背景的视频的方法。&lt;h4&gt;方法&lt;/h4&gt;$ext{TR}^2ext{C}$方法通过学习保持时间一致性和与UoS结构良好对齐的结构化表示来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;在五个基准HMS数据集上进行的实验表明，$ext{TR}^2ext{C}$方法在不同的特征提取器下均取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;$ext{TR}^2ext{C}$方法为HMS任务提供了一种有效的新方法，能够处理复杂背景下的视频运动分割问题。&lt;h4&gt;翻译&lt;/h4&gt;人类运动分割（HMS）旨在将视频分割成非重叠的人类运动部分，近年来引起了越来越多的研究兴趣。现有的HMS方法主要受子空间聚类方法的主导，这些方法基于高维时间数据与联合子空间（UoS）分布一致的假设。然而，视频捕获的包含杂乱背景的复杂人类运动的帧可能无法很好地与UoS分布对齐。在本文中，我们提出了一种名为时率降低聚类（Temporal Rate Reduction Clustering，$ext{TR}^2ext{C}$）的新型HMS方法，该方法联合学习结构化表示和亲和度以分割视频中的帧序列。具体来说，$ext{TR}^2ext{C}$学习到的结构化表示保持时间一致性并与UoS结构良好对齐，这对于HMS任务是有利的。我们在五个基准HMS数据集上进行了广泛的实验，并使用不同的特征提取器取得了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human Motion Segmentation (HMS), which aims to partition videos intonon-overlapping human motions, has attracted increasing research attentionrecently. Existing approaches for HMS are mainly dominated by subspaceclustering methods, which are grounded on the assumption that high-dimensionaltemporal data align with a Union-of-Subspaces (UoS) distribution. However, theframes in video capturing complex human motions with cluttered backgrounds maynot align well with the UoS distribution. In this paper, we propose a novelapproach for HMS, named Temporal Rate Reduction Clustering($\text{TR}^2\text{C}$), which jointly learns structured representations andaffinity to segment the frame sequences in video. Specifically, the structuredrepresentations learned by $\text{TR}^2\text{C}$ maintain temporally consistentand align well with a UoS structure, which is favorable for the HMS task. Weconduct extensive experiments on five benchmark HMS datasets and achievestate-of-the-art performances with different feature extractors.</description>
      <author>example@mail.com (Xianghan Meng, Zhengyu Tong, Zhiyuan Huang, Chun-Guang Li)</author>
      <guid isPermaLink="false">2506.21249v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:01 +0800</pubDate>
    </item>
    <item>
      <title>Distributed Cross-Channel Hierarchical Aggregation for Foundation Models</title>
      <link>http://arxiv.org/abs/2506.21411v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;基于视觉的科学基础模型对于推动科学发现和创新具有巨大潜力，但图像的标记和聚合计算密集，现有分布式方法未能完全解决这一挑战。&lt;h4&gt;背景&lt;/h4&gt;视觉基础模型能够从不同来源聚合图像，并使用transformer架构学习时空相关性，但这一过程计算密集。&lt;h4&gt;目的&lt;/h4&gt;提出一种名为D-CHAG的方法，用于处理具有大量通道的图像数据集，旨在提高计算效率。&lt;h4&gt;方法&lt;/h4&gt;D-CHAG方法与任何模型并行策略和视觉transformer架构兼容，并在超光谱成像和天气预报任务上进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;D-CHAG方法与张量并行和模型分片结合使用时，在Frontier超级计算机上实现了高达75%的内存使用减少，以及持续吞吐量翻倍，最多可支持1,024个AMD GPU。&lt;h4&gt;结论&lt;/h4&gt;D-CHAG方法显著提高了计算效率，为科学基础模型的应用提供了有效解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-based scientific foundation models hold significant promise foradvancing scientific discovery and innovation. This potential stems from theirability to aggregate images from diverse sources such as varying physicalgroundings or data acquisition systems and to learn spatio-temporalcorrelations using transformer architectures. However, tokenizing andaggregating images can be compute-intensive, a challenge not fully addressed bycurrent distributed methods. In this work, we introduce the DistributedCross-Channel Hierarchical Aggregation (D-CHAG) approach designed for datasetswith a large number of channels across image modalities. Our method iscompatible with any model-parallel strategy and any type of vision transformerarchitecture, significantly improving computational efficiency. We evaluatedD-CHAG on hyperspectral imaging and weather forecasting tasks. When integratedwith tensor parallelism and model sharding, our approach achieved up to a 75%reduction in memory usage and more than doubled sustained throughput on up to1,024 AMD GPUs on the Frontier Supercomputer.</description>
      <author>example@mail.com (Aristeidis Tsaris, Isaac Lyngaas, John Lagregren, Mohamed Wahib, Larry York, Prasanna Balaprakash, Dan Lu, Feiyi Wang, Xiao Wang)</author>
      <guid isPermaLink="false">2506.21411v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation</title>
      <link>http://arxiv.org/abs/2506.21233v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种针对无监督开放词汇语义分割（OVS）的数据质量优化框架，通过构建高质量的参考集和简单相似度检索，显著提升了无监督OVS的性能。&lt;h4&gt;背景&lt;/h4&gt;无监督开放词汇语义分割旨在在不进行昂贵模型微调的情况下，对任意文本类别进行图像分割。&lt;h4&gt;目的&lt;/h4&gt;研究数据质量对无监督OVS性能的影响，并提出一种数据质量导向的框架。&lt;h4&gt;方法&lt;/h4&gt;构建包含良好配对分割文本嵌入的参考集的数据管道，并采用基于相似度的简单检索方法。&lt;h4&gt;主要发现&lt;/h4&gt;高质量参考集对无监督OVS性能有显著提升。&lt;h4&gt;结论&lt;/h4&gt;该研究强调了数据在无监督OVS中的重要性，并提出的方法在多个基准数据集上优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;Training-free open-vocabulary semantic segmentation (OVS) aims to segment images given a set of arbitrary textual categories without costly model fine-tuning. Existing solutions often explore attention mechanisms of pre-trained models, such as CLIP, or generate synthetic data and design complex retrieval processes to perform OVS. However, their performance is limited by the capability of reliant models or the suboptimal quality of reference sets. In this work, we investigate the largely overlooked data quality problem for this challenging dense scene understanding task, and identify that a high-quality reference set can significantly benefit training-free OVS. With this observation, we introduce a data-quality-oriented framework, comprising a data pipeline to construct a reference set with well-paired segment-text embeddings and a simple similarity-based retrieval to unveil the essential effect of data. Remarkably, extensive evaluations on ten benchmark datasets demonstrate that our method outperforms all existing training-free OVS approaches, highlighting the importance of data-centric design for advancing OVS without training. Our code is available at https://github.com/xiweix/ReME .&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Training-free open-vocabulary semantic segmentation (OVS) aims to segmentimages given a set of arbitrary textual categories without costly modelfine-tuning. Existing solutions often explore attention mechanisms ofpre-trained models, such as CLIP, or generate synthetic data and design complexretrieval processes to perform OVS. However, their performance is limited bythe capability of reliant models or the suboptimal quality of reference sets.In this work, we investigate the largely overlooked data quality problem forthis challenging dense scene understanding task, and identify that ahigh-quality reference set can significantly benefit training-free OVS. Withthis observation, we introduce a data-quality-oriented framework, comprising adata pipeline to construct a reference set with well-paired segment-textembeddings and a simple similarity-based retrieval to unveil the essentialeffect of data. Remarkably, extensive evaluations on ten benchmark datasetsdemonstrate that our method outperforms all existing training-free OVSapproaches, highlighting the importance of data-centric design for advancingOVS without training. Our code is available at https://github.com/xiweix/ReME .</description>
      <author>example@mail.com (Xiwei Xuan, Ziquan Deng, Kwan-Liu Ma)</author>
      <guid isPermaLink="false">2506.21233v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG Classification</title>
      <link>http://arxiv.org/abs/2506.21338v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于脑电图（EEG）的脑机接口（BCI）技术，旨在帮助运动障碍者平等地参与环境互动。该技术通过引入一种新的图时模型AGTCNet，解决了现有BCI系统在捕捉多通道EEG信号中的时空依赖关系方面的不足。&lt;h4&gt;背景&lt;/h4&gt;BCI技术具有潜力帮助运动障碍者，但其发展面临个体间和随时间变化的神经活动复杂性和可变性的挑战，以及EEG硬件的限制。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效捕捉多通道EEG信号中时空依赖关系的BCI系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为AGTCNet的注意力图时卷积网络，利用EEG电极的拓扑配置作为归纳偏置，并集成了图卷积注意力网络（GCAT）以联合学习表达性的时空EEG表示。&lt;h4&gt;主要发现&lt;/h4&gt;AGTCNet在MI-EEG分类方面显著优于现有方法，实现了最先进的性能，同时具有紧凑的架构。在BCI Competition IVDataset 2a上，AGTCNet在主题无关分类中的移动平均准确率达到66.82%，经过特定主题微调后，准确率提升至82.88%。在EEG Motor Movement/Imagery Dataset上，AGTCNet在4类和2类主题无关分类中的移动平均准确率分别为64.14%和85.22%，在特定主题分类中进一步提高了至72.13%和90.54%。&lt;h4&gt;结论&lt;/h4&gt;AGTCNet是一种有效的BCI系统，具有实用性和可部署性，能够在保持高准确率的同时显著减小模型尺寸和加快推理时间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Brain-computer interface (BCI) technology utilizing electroencephalography(EEG) marks a transformative innovation, empowering motor-impaired individualsto engage with their environment on equal footing. Despite its promisingpotential, developing subject-invariant and session-invariant BCI systemsremains a significant challenge due to the inherent complexity and variabilityof neural activity across individuals and over time, compounded by EEG hardwareconstraints. While prior studies have sought to develop robust BCI systems,existing approaches remain ineffective in capturing the intricatespatiotemporal dependencies within multichannel EEG signals. This studyaddresses this gap by introducing the attentive graph-temporal convolutionalnetwork (AGTCNet), a novel graph-temporal model for motor imagery EEG (MI-EEG)classification. Specifically, AGTCNet leverages the topographic configurationof EEG electrodes as an inductive bias and integrates graph convolutionalattention network (GCAT) to jointly learn expressive spatiotemporal EEGrepresentations. The proposed model significantly outperformed existing MI-EEGclassifiers, achieving state-of-the-art performance while utilizing a compactarchitecture, underscoring its effectiveness and practicality for BCIdeployment. With a 49.87% reduction in model size, 64.65% faster inferencetime, and shorter input EEG signal, AGTCNet achieved a moving average accuracyof 66.82% for subject-independent classification on the BCI Competition IVDataset 2a, which further improved to 82.88% when fine-tuned forsubject-specific classification. On the EEG Motor Movement/Imagery Dataset,AGTCNet achieved moving average accuracies of 64.14% and 85.22% for 4-class and2-class subject-independent classifications, respectively, with furtherimprovements to 72.13% and 90.54% for subject-specific classifications.</description>
      <author>example@mail.com (Galvin Brice S. Lim, Brian Godwin S. Lim, Argel A. Bandala, John Anthony C. Jose, Timothy Scott C. Chu, Edwin Sybingco)</author>
      <guid isPermaLink="false">2506.21338v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Accelerating GNN Training through Locality-aware Dropout and Merge</title>
      <link>http://arxiv.org/abs/2506.21414v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  under review in TPDS. extend version of DATE 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LiGNN的硬件解决方案，通过在邻居聚合过程中应用dropout和merge技术来提高数据局部性，从而加速图神经网络（GNN）的训练。&lt;h4&gt;背景&lt;/h4&gt;图神经网络（GNNs）在图学习领域取得了显著成功，但它们的节点之间的高连接性导致了不高效的邻居聚合，产生了大量的不规则和粗粒度的DRAM访问，这对执行平台构成了挑战，并最终降低了性能。&lt;h4&gt;目的&lt;/h4&gt;提高GNN训练的性能，同时减少DRAM的不规则访问。&lt;h4&gt;方法&lt;/h4&gt;LiGNN通过以下方法实现这一目标：1. 引入一个局部感知的特征dropout机制，在邻居聚合过程中有选择性地丢弃节点特征；2. 利用对内存布局和组织（包括关键的对齐约束）的详细知识，在DRAM行级别有策略地合并内存访问。&lt;h4&gt;主要发现&lt;/h4&gt;在0.5的dropout率下，LiGNN比最先进的方法有显著性能提升，实现了1.48~3.02倍的速度提升，减少了34%~55%的DRAM访问，并将DRAM行激活降低了59%~82%，同时保持了模型精度。&lt;h4&gt;结论&lt;/h4&gt;LiGNN通过提高数据局部性，有效提升了GNN训练的性能，同时降低了硬件成本。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have demonstrated significant success in graph learning and are widely adopted across various critical domains. However, their regular connectivity between vertices leads to inefficient neighbor aggregation, resulting in substantial irregular and coarse-grained DRAM accesses. This lack of data locality presents significant challenges for execution platforms, ultimately degrading performance. While previous accelerator designs have leveraged on-chip memory and data access scheduling strategies to address this issue, they still inevitably access features at irregular addresses from DRAM. In this work, we propose LiGNN, a hardware-based solution that improves data locality by applying dropout and merge techniques during neighbor aggregation to accelerate GNN training. Unlike conventional algorithm-level dropout methods that primarily aim to improve accuracy while overlooking hardware costs, LiGNN introduces a locality-aware feature dropout mechanism. This approach selectively drops node features with data locality awareness, effectively reducing irregular DRAM accesses without compromising model accuracy. Moreover, by leveraging detailed knowledge of memory layout and organization-including critical alignment constraints-LiGNN strategically merges memory accesses during neighbor aggregation at the DRAM row level, guided by GNN-level semantics. This optimization significantly improves data locality with minimal additional cost. Under the commonly adopted 0.5 dropout rate, LiGNN outperforms state-of-the-art methods, delivering a 1.48~3.02xs speedup, reducing DRAM accesses by 34%~55%, and lowering DRAM row activations by 59%~82%, all while maintaining model accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated significant success in graphlearning and are widely adopted across various critical domains. However, theirregular connectivity between vertices leads to inefficient neighboraggregation, resulting in substantial irregular and coarse-grained DRAMaccesses. This lack of data locality presents significant challenges forexecution platforms, ultimately degrading performance. While previousaccelerator designs have leveraged on-chip memory and data access schedulingstrategies to address this issue, they still inevitably access features atirregular addresses from DRAM. In this work, we propose LiGNN, a hardware-basedsolution that improves data locality by applying dropout and merge techniquesduring neighbor aggregation to accelerate GNN training. Unlike conventionalalgorithm-level dropout methods that primarily aim to improve accuracy whileoverlooking hardware costs, LiGNN introduces a locality-aware feature dropoutmechanism. This approach selectively drops node features with data localityawareness, effectively reducing irregular DRAM accesses without compromisingmodel accuracy. Moreover, by leveraging detailed knowledge of memory layout andorganization-including critical alignment constraints-LiGNN strategicallymerges memory accesses during neighbor aggregation at the DRAM row level,guided by GNN-level semantics. This optimization significantly improves datalocality with minimal additional cost. Under the commonly adopted 0.5 dropoutrate, LiGNN outperforms state-of-the-art methods, delivering a 1.48~3.02xspeedup, reducing DRAM accesses by 34%~55%, and lowering DRAM row activationsby 59%~82%, all while maintaining model accuracy.</description>
      <author>example@mail.com (Gongjian Sun, Mingyu Yan, Dengke Han, Runzhen Xue, Duo Wang, Xiaochun Ye, Dongrui Fan)</author>
      <guid isPermaLink="false">2506.21414v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Early Stopping Tabular In-Context Learning</title>
      <link>http://arxiv.org/abs/2506.21387v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML Workshop Paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种改进的表格式基础模型，通过在上下文中动态停止学习过程来降低推理时间成本，同时保持预测性能。&lt;h4&gt;背景&lt;/h4&gt;表格式基础模型在上下文学习中表现出色，但推理时间成本较高，特别是在大数据集上。&lt;h4&gt;目的&lt;/h4&gt;旨在提高表格式基础模型的推理效率。&lt;h4&gt;方法&lt;/h4&gt;通过在每层Transformer编码器之后动态评估是否停止上下文学习过程，一旦停止，使用预训练的层解码器进行嵌入解码。&lt;h4&gt;主要发现&lt;/h4&gt;在34个小规模分类任务上的实验表明，提前停止上下文学习可以将推理速度提高最多1.3倍，同时对预测性能的影响可以忽略不计；在五个大规模分类任务上的评估显示，速度可以加快最多2.2倍。&lt;h4&gt;结论&lt;/h4&gt;提前退出是一种有效且实用的策略，可以提高表格式上下文学习的效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Tabular foundation models have shown strong performance across varioustabular learning tasks via in-context learning, offering robust generalizationwithout any downstream finetuning. However, their inference-time costs remainhigh, particularly for larger datasets. To address this, we proposeearly-stopping the in-context learning process. We achieve this by dynamicallyevaluating whether to stop in-context learning after each Transformer encoderlayer. Once stopped, we decode the embedding using a pre-trained layer-wisedecoder. Experiments across 34 small classification tasks size show that earlystopping in-context learning accelerates inference by up to x1.3 withnegligible degradation in predictive performance. To assess scalability, wefurther evaluate our method on five larger classification tasks, achievingspeedups of up to x2.2. Our results demonstrate the potential of early exitingas an effective and practical strategy for improving the efficiency of tabularin-context learning.</description>
      <author>example@mail.com (Jaris Küken, Lennart Purucker, Frank Hutter)</author>
      <guid isPermaLink="false">2506.21387v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly Detection Benchmark</title>
      <link>http://arxiv.org/abs/2506.21549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了SiM3D，这是第一个考虑多视角和多模态信息整合的综合3D异常检测和分割（ADS）基准，旨在生成基于体素的异常体积。&lt;h4&gt;背景&lt;/h4&gt;SiM3D专注于制造业中一个高关注场景：单实例异常检测，其中只有单个对象（真实或合成）可用于训练。&lt;h4&gt;目的&lt;/h4&gt;SiM3D旨在解决从合成训练数据泛化到真实测试数据这一挑战。&lt;h4&gt;方法&lt;/h4&gt;SiM3D包括一个使用顶级工业传感器和机器人获取的全新多模态多视角数据集，包含333个实例的8种对象的多视角高分辨率图像（1200万像素）和点云（700万个点），以及每个类型的CAD模型。还提供了异常测试样本的手动标注3D分割GT。为了为所提出的多视角3D ADS任务建立参考基线，我们调整了突出的单视角方法，并使用在异常体积上运行的新颖指标来评估它们的性能。&lt;h4&gt;主要发现&lt;/h4&gt;SiM3D是第一个解决从合成训练数据泛化到真实测试数据挑战的ADS基准。&lt;h4&gt;结论&lt;/h4&gt;SiM3D通过提供综合的多视角和多模态信息，为3D异常检测和分割提供了一个新的基准。&lt;h4&gt;翻译&lt;/h4&gt;We propose SiM3D, the first benchmark considering the integration of multiview and multimodal information for comprehensive 3D anomaly detection and segmentation (ADS), where the task is to produce a voxel-based Anomaly Volume. Moreover, SiM3D focuses on a scenario of high interest in manufacturing: single-instance anomaly detection, where only one object, either real or synthetic, is available for training. In this respect, SiM3D stands out as the first ADS benchmark that addresses the challenge of generalising from synthetic training data to real test data. SiM3D includes a novel multimodal multiview dataset acquired using top-tier industrial sensors and robots. The dataset features multiview high-resolution images (12 Mpx) and point clouds (7M points) for 333 instances of eight types of objects, alongside a CAD model for each type. We also provide manually annotated 3D segmentation GTs for anomalous test samples. To establish reference baselines for the proposed multiview 3D ADStask, we adapt prominent singleview methods and assess their performance using novel metrics that operate on Anomaly Volumes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We propose SiM3D, the first benchmark considering the integration ofmultiview and multimodal information for comprehensive 3D anomaly detection andsegmentation (ADS), where the task is to produce a voxel-based Anomaly Volume.Moreover, SiM3D focuses on a scenario of high interest in manufacturing:single-instance anomaly detection, where only one object, either real orsynthetic, is available for training. In this respect, SiM3D stands out as thefirst ADS benchmark that addresses the challenge of generalising from synthetictraining data to real test data. SiM3D includes a novel multimodal multiviewdataset acquired using top-tier industrial sensors and robots. The datasetfeatures multiview high-resolution images (12 Mpx) and point clouds (7M points)for 333 instances of eight types of objects, alongside a CAD model for eachtype. We also provide manually annotated 3D segmentation GTs for anomalous testsamples. To establish reference baselines for the proposed multiview 3D ADStask, we adapt prominent singleview methods and assess their performance usingnovel metrics that operate on Anomaly Volumes.</description>
      <author>example@mail.com (Alex Costanzino, Pierluigi Zama Ramirez, Luigi Lella, Matteo Ragaglia, Alessandro Oliva, Giuseppe Lisanti, Luigi Di Stefano)</author>
      <guid isPermaLink="false">2506.21549v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>PeakNetFP: Peak-based Neural Audio Fingerprinting Robust to Extreme Time Stretching</title>
      <link>http://arxiv.org/abs/2506.21086v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ISMIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PeakNetFP是一种基于频谱峰值的神经音频指纹系统，通过利用传统峰值音频指纹方法中计算的稀疏频谱坐标，实现了高效的音频指纹识别。&lt;h4&gt;背景&lt;/h4&gt;音频指纹识别技术是音频内容识别的重要手段，传统方法基于频谱峰值，但存在效率问题。&lt;h4&gt;目的&lt;/h4&gt;设计PeakNetFP的目的是提高音频指纹识别的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;PeakNetFP采用类似于计算机视觉模型PointNet++的分层点特征提取技术，并使用与NeuralFP类似的对比学习方法进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;PeakNetFP在处理具有挑战性的音频拉伸数据时，性能与NeuralFP相当，且具有更高的效率。它具有更少的参数和更小的输入数据。&lt;h4&gt;结论&lt;/h4&gt;PeakNetFP是一种轻量级且高效的音频指纹识别解决方案，代表了未来音频指纹识别技术的发展方向。&lt;h4&gt;翻译&lt;/h4&gt;This work introduces PeakNetFP, the first neural audio fingerprinting (AFP) system designed specifically around spectral peaks. This novel system is designed to leverage the sparse spectral coordinates typically computed by traditional peak-based AFP methods. PeakNetFP performs hierarchical point feature extraction techniques similar to the computer vision model PointNet++, and is trained using contrastive learning like in the state-of-the-art deep learning AFP, NeuralFP. This combination allows PeakNetFP to outperform conventional AFP systems and achieve comparable performance to NeuralFP when handling challenging time-stretched audio data. In extensive evaluation, PeakNetFP maintains a Top-1 hit rate of over 90% for stretching factors ranging from 50% to 200%. Moreover, PeakNetFP offers significant efficiency advantages: compared to NeuralFP, it has 100 times fewer parameters and uses 11 times smaller input data. These features make PeakNetFP a lightweight and efficient solution for AFP tasks where time stretching is involved. Overall, this system represents a promising direction for future AFP technologies, as its successfully merges the lightweight nature of peak-based AFP with the adaptability and pattern recognition capabilities of neural network-based approaches, paving the way for more scalable and efficient solutions in the field.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work introduces PeakNetFP, the first neural audio fingerprinting (AFP)system designed specifically around spectral peaks. This novel system isdesigned to leverage the sparse spectral coordinates typically computed bytraditional peak-based AFP methods. PeakNetFP performs hierarchical pointfeature extraction techniques similar to the computer vision model PointNet++,and is trained using contrastive learning like in the state-of-the-art deeplearning AFP, NeuralFP. This combination allows PeakNetFP to outperformconventional AFP systems and achieves comparable performance to NeuralFP whenhandling challenging time-stretched audio data. In extensive evaluation,PeakNetFP maintains a Top-1 hit rate of over 90% for stretching factors rangingfrom 50% to 200%. Moreover, PeakNetFP offers significant efficiency advantages:compared to NeuralFP, it has 100 times fewer parameters and uses 11 timessmaller input data. These features make PeakNetFP a lightweight and efficientsolution for AFP tasks where time stretching is involved. Overall, this systemrepresents a promising direction for future AFP technologies, as itsuccessfully merges the lightweight nature of peak-based AFP with theadaptability and pattern recognition capabilities of neural network-basedapproaches, paving the way for more scalable and efficient solutions in thefield.</description>
      <author>example@mail.com (Guillem Cortès-Sebastià, Benjamin Martin, Emilio Molina, Xavier Serra, Romain Hennequin)</author>
      <guid isPermaLink="false">2506.21086v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning</title>
      <link>http://arxiv.org/abs/2506.21096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ACL 2025 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为DALR的多模态句子表示学习方法，旨在解决现有方法在跨模态对齐和模内语义分歧方面的挑战，通过细粒度跨模态对齐和全局模内对齐学习来提升句子表示质量。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态句子表示学习方法在图像和文本对齐方面存在跨模态对齐偏差和模内语义分歧的问题，这会严重影响句子表示的质量。&lt;h4&gt;目的&lt;/h4&gt;提出DALR方法，以解决跨模态对齐偏差和模内语义分歧的问题，提高句子表示的质量。&lt;h4&gt;方法&lt;/h4&gt;DALR方法包括：1. 提出一致性学习模块，通过软化负样本并利用辅助任务中的语义相似性来实现细粒度跨模态对齐；2. 认为句子关系不仅仅是正负标签的二值分类，而是具有更复杂的排序结构；3. 将排序蒸馏与全局模内对齐学习相结合，以更好地捕捉这些关系并提高表示质量。&lt;h4&gt;主要发现&lt;/h4&gt;在语义文本相似性（STS）和迁移（TR）任务上的综合实验验证了DALR方法的有效性，并持续显示出其优于现有基线的优越性。&lt;h4&gt;结论&lt;/h4&gt;DALR方法能够有效解决跨模态对齐和模内语义分歧问题，显著提升多模态句子表示的质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Previous multimodal sentence representation learning methods have achievedimpressive performance. However, most approaches focus on aligning images andtext at a coarse level, facing two critical challenges:cross-modal misalignmentbias and intra-modal semantic divergence, which significantly degrade sentencerepresentation quality. To address these challenges, we propose DALR(Dual-level Alignment Learning for Multimodal Sentence Representation). Forcross-modal alignment, we propose a consistency learning module that softensnegative samples and utilizes semantic similarity from an auxiliary task toachieve fine-grained cross-modal alignment. Additionally, we contend thatsentence relationships go beyond binary positive-negative labels, exhibiting amore intricate ranking structure. To better capture these relationships andenhance representation quality, we integrate ranking distillation with globalintra-modal alignment learning. Comprehensive experiments on semantic textualsimilarity (STS) and transfer (TR) tasks validate the effectiveness of ourapproach, consistently demonstrating its superiority over state-of-the-artbaselines.</description>
      <author>example@mail.com (Kang He, Yuzhe Ding. Haining Wang, Fei Li, Chong Teng, Donghong Ji)</author>
      <guid isPermaLink="false">2506.21096v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation</title>
      <link>http://arxiv.org/abs/2506.20991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TSDASeg的交互式点云分割模型，通过直接跨模态对齐模块和记忆模块来解决现有方法在点级任务如分割中表现不佳的问题。&lt;h4&gt;背景&lt;/h4&gt;3D视觉语言模型（VLMs）的快速发展促进了交互式点云处理任务的研究，特别是在实际应用中。然而，现有方法由于缺乏直接的3D-文本对齐，往往在点级任务如分割中表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出TSDASeg模型，旨在解决交互式点云分割中由于缺乏直接3D-文本对齐而导致的性能问题。&lt;h4&gt;方法&lt;/h4&gt;TSDASeg模型包括直接跨模态对齐模块和记忆模块。直接跨模态对齐模块用于建立3D点云和文本/2D图像数据之间的显式对齐。记忆模块使用多个专门的记忆库分别存储文本特征、视觉特征及其跨模态对应映射。通过自我注意力和交叉注意力机制动态利用这些记忆库，根据先前存储的数据更新场景特定的特征。&lt;h4&gt;主要发现&lt;/h4&gt;在多个3D指令、参考和语义分割数据集上的实验表明，所提出的方法达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;TSDASeg模型能够有效解决交互式点云分割中的不一致性问题，并在多个数据集上实现了最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：随着3D视觉语言模型（VLMs）的快速发展，交互式点云处理任务，尤其是实际应用中的任务，引起了极大的兴趣。然而，由于缺乏直接的3D-文本对齐，现有方法在点级任务，如分割中往往表现不佳。为了解决这个问题，我们提出了TSDASeg，一个结合直接跨模态对齐模块和记忆模块的两阶段模型，用于交互式点云分割。我们引入了直接跨模态对齐模块，以建立3D点云和文本/2D图像数据之间的显式对齐。在记忆模块中，我们使用了多个专门的记忆库来分别存储文本特征、视觉特征及其跨模态对应映射。通过自我注意力和交叉注意力机制动态利用这些记忆库，基于先前存储的数据更新场景特定的特征，有效地解决了在多种场景下交互式分割结果的不一致性。在多个3D指令、参考和语义分割数据集上进行的实验表明，所提出的方法达到了最先进的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid advancement of 3D vision-language models (VLMs) has spurredsignificant interest in interactive point cloud processing tasks, particularlyfor real-world applications. However, existing methods often underperform inpoint-level tasks, such as segmentation, due to missing direct 3D-textalignment, limiting their ability to link local 3D features with textualcontext. To solve this problem, we propose TSDASeg, a Two-Stage model coupledwith a Direct cross-modal Alignment module and memory module for interactivepoint cloud Segmentation. We introduce the direct cross-modal alignment moduleto establish explicit alignment between 3D point clouds and textual/2D imagedata. Within the memory module, we employ multiple dedicated memory banks toseparately store text features, visual features, and their cross-modalcorrespondence mappings. These memory banks are dynamically leveraged throughself-attention and cross-attention mechanisms to update scene-specific featuresbased on prior stored data, effectively addressing inconsistencies ininteractive segmentation results across diverse scenarios. Experimentsconducted on multiple 3D instruction, reference, and semantic segmentationdatasets demonstrate that the proposed method achieves state-of-the-artperformance.</description>
      <author>example@mail.com (Chade Li, Pengju Zhang, Yihong Wu)</author>
      <guid isPermaLink="false">2506.20991v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Brain2Model Transfer: Training sensory and decision models with human neural activity as a teacher</title>
      <link>http://arxiv.org/abs/2506.20834v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为Brain2Model Transfer Learning (B2M)的框架，通过利用人类大脑的低维抽象表示来增强人工神经网络的学习能力。&lt;h4&gt;背景&lt;/h4&gt;认知神经科学表明，人类大脑可以通过较少的数据点和计算能力来创建低维的抽象表示，这些表示对于高效的感官和运动编码至关重要。&lt;h4&gt;目的&lt;/h4&gt;引入B2M框架，以人类神经活动作为教师模型来训练人工神经网络，提高其学习效率。&lt;h4&gt;方法&lt;/h4&gt;论文提出了两种B2M策略：(1)脑对比迁移，通过对比目标来对齐大脑活动和网络激活；(2)脑潜在迁移，通过监督回归大脑特征，将类似认知任务的潜在动态投影到学生网络上。&lt;h4&gt;主要发现&lt;/h4&gt;在基于记忆的决策制作和场景重建任务中，利用B2M策略训练的学生网络比单独训练的网络收敛更快，预测精度更高。&lt;h4&gt;结论&lt;/h4&gt;大脑的表示对于人工学习者非常有价值，这为更高效地学习复杂的决策表示铺平了道路，这些表示通过纯人工训练可能既昂贵又缓慢。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习通过采用大型预训练教师模型的丰富特征表示来增强新感官和决策模型的学习。认知神经科学表明，人脑创建了低维的抽象表示以实现高效的感官运动编码。重要的是，大脑可以比人工模型所需的更少的数据点和更少的计算能力来学习这些表示。我们引入了Brain2Model迁移学习（B2M）框架，其中人类感官和决策任务的神经活动作为训练人工神经网络的教师模型。我们提出了两种B2M策略：(1)脑对比迁移，通过对比目标对齐大脑活动和网络激活；(2)脑潜在迁移，通过监督回归大脑特征，将类似认知任务的潜在动态投影到学生网络上。我们在基于记忆的决策制作和自动驾驶场景重建中验证了B2M，结果显示，从基于大脑的迁移中受益的学生网络比单独训练的网络收敛更快，预测精度更高。我们的发现表明，大脑的表示对于人工学习者非常有价值，为更高效地学习复杂的决策表示铺平了道路，这些表示通过纯人工训练可能既昂贵又缓慢。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning enhances the training of novel sensory and decision modelsby employing rich feature representations from large, pre-trained teachermodels. Cognitive neuroscience shows that the human brain createslow-dimensional, abstract representations for efficient sensorimotor coding.Importantly, the brain can learn these representations with significantly fewerdata points and less computational power than artificial models require. Weintroduce Brain2Model Transfer Learning (B2M), a framework where neuralactivity from human sensory and decision-making tasks acts as the teacher modelfor training artificial neural networks. We propose two B2M strategies: (1)Brain Contrastive Transfer, which aligns brain activity and network activationsthrough a contrastive objective; and (2) Brain Latent Transfer, which projectslatent dynamics from similar cognitive tasks onto student networks viasupervised regression of brain-derived features. We validate B2M inmemory-based decision-making with a recurrent neural network and scenereconstruction for autonomous driving with a variational autoencoder. Theresults show that student networks benefiting from brain-based transferconverge faster and achieve higher predictive accuracy than networks trained inisolation. Our findings indicate that the brain's representations are valuablefor artificial learners, paving the way for more efficient learning of complexdecision-making representations, which would be costly or slow through purelyartificial training.</description>
      <author>example@mail.com (Tomas Gallo Aquino, Victoria Liu, Habiba Azab, Raissa Mathura, Andrew J Watrous, Eleonora Bartoli, Benjamin Y Hayden, Paul Sajda, Sameer A Sheth, Nuttida Rungratsameetaweemana)</author>
      <guid isPermaLink="false">2506.20834v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Skill Discovery via Regret-Aware Optimization</title>
      <link>http://arxiv.org/abs/2506.21044v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于时间表示学习的技能发现方法，旨在提高开放式强化学习中技能的多样性和区分度。&lt;h4&gt;背景&lt;/h4&gt;现有的无监督技能发现方法主要关注通过纯探索、互信息优化和学习时间表示来提高多样性，但在高维情况下效率有限。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，通过将技能发现视为技能生成和政策学习之间的min-max博弈，在时间表示学习的基础上，提高技能空间的效率。&lt;h4&gt;方法&lt;/h4&gt;该方法的核心思想是技能发现与政策学习是对抗的，即应进一步探索强度较弱的技能，而对强度已收敛的技能减少探索。通过学习可升级的技能生成器来引导技能发现，并使用后悔来评分强度收敛的程度。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在效率和多样性方面优于基线方法，在高度复杂和高维环境中实现了15%的无监督改进。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地扩展了技能空间，提高了技能发现的效率，特别是在高维环境中表现优异。&lt;h4&gt;翻译&lt;/h4&gt;Unsupervised skill discovery aims to learn diverse and distinguishable behaviors in open-ended reinforcement learning. For existing methods, they focus on improving diversity through pure exploration, mutual information optimization, and learning temporal representation. Despite that they perform well on exploration, they remain limited in terms of efficiency, especially for the high-dimensional situations. In this work, we frame skill discovery as a min-max game of skill generation and policy learning, proposing a regret-aware method on top of temporal representation learning that expands the discovered skill space along the direction of upgradable policy strength. The key insight behind the proposed method is that the skill discovery is adversarial to the policy learning, i.e., skills with weak strength should be further explored while less exploration for the skills with converged strength. As an implementation, we score the degree of strength convergence with regret, and guide the skill discovery with a learnable skill generator. To avoid degeneration, skill generation comes from an up-gradable population of skill generators. We conduct experiments on environments with varying complexities and dimension sizes. Empirical results show that our method outperforms baselines in both efficiency and diversity. Moreover, our method achieves a 15% zero shot improvement in high-dimensional environments, compared to existing methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unsupervised skill discovery aims to learn diverse and distinguishablebehaviors in open-ended reinforcement learning. For existing methods, theyfocus on improving diversity through pure exploration, mutual informationoptimization, and learning temporal representation. Despite that they performwell on exploration, they remain limited in terms of efficiency, especially forthe high-dimensional situations. In this work, we frame skill discovery as amin-max game of skill generation and policy learning, proposing a regret-awaremethod on top of temporal representation learning that expands the discoveredskill space along the direction of upgradable policy strength. The key insightbehind the proposed method is that the skill discovery is adversarial to thepolicy learning, i.e., skills with weak strength should be further exploredwhile less exploration for the skills with converged strength. As animplementation, we score the degree of strength convergence with regret, andguide the skill discovery with a learnable skill generator. To avoiddegeneration, skill generation comes from an up-gradable population of skillgenerators. We conduct experiments on environments with varying complexitiesand dimension sizes. Empirical results show that our method outperformsbaselines in both efficiency and diversity. Moreover, our method achieves a 15%zero shot improvement in high-dimensional environments, compared to existingmethods.</description>
      <author>example@mail.com (He Zhang, Ming Zhou, Shaopeng Zhai, Ying Sun, Hui Xiong)</author>
      <guid isPermaLink="false">2506.21044v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding</title>
      <link>http://arxiv.org/abs/2506.21188v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了GroundFlow模块，用于3D点云序列定位任务中的时间推理，显著提高了现有3D视觉定位方法的准确率。&lt;h4&gt;背景&lt;/h4&gt;当前3D视觉定位方法无法有效处理包含多步骤的文本指令，且在理解上下文和检索相关信息方面存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提出GroundFlow模块，以解决3D点云序列定位任务中时间推理的挑战。&lt;h4&gt;方法&lt;/h4&gt;GroundFlow模块能够根据指令的相关性选择性提取短期和长期步骤信息，从而全面理解历史信息。&lt;h4&gt;主要发现&lt;/h4&gt;GroundFlow模块显著提高了3D视觉定位方法的准确率，并在SG3D基准测试中取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;GroundFlow模块引入了时间推理能力，为现有的3D视觉定位模型带来了显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;Sequential grounding in 3D point clouds (SG3D) refers to locating sequences of objects by following text instructions for a daily activity with detailed steps. Current 3D visual grounding (3DVG) methods treat text instructions with multiple steps as a whole, without extracting useful temporal information from each step. However, the instructions in SG3D often contain pronouns such as 'it', 'here' and 'the same' to make language expressions concise. This requires grounding methods to understand the context and retrieve relevant information from previous steps to correctly locate object sequences. Due to the lack of an effective module for collecting related historical information, state-of-the-art 3DVG methods face significant challenges in adapting to the SG3D task. To fill this gap, we propose GroundFlow -- a plug-in module for temporal reasoning on 3D point cloud sequential grounding. Firstly, we demonstrate that integrating GroundFlow improves the task accuracy of 3DVG baseline methods by a large margin (+7.5% and +10.2%) in the SG3D benchmark, even outperforming a 3D large language model pre-trained on various datasets. Furthermore, we selectively extract both short-term and long-term step information based on its relevance to the current instruction, enabling GroundFlow to take a comprehensive view of historical information and maintain its temporal understanding advantage as step counts increase. Overall, our work introduces temporal reasoning capabilities to existing 3DVG models and achieves state-of-the-art performance in the SG3D benchmark across five datasets.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Sequential grounding in 3D point clouds (SG3D) refers to locating sequencesof objects by following text instructions for a daily activity with detailedsteps. Current 3D visual grounding (3DVG) methods treat text instructions withmultiple steps as a whole, without extracting useful temporal information fromeach step. However, the instructions in SG3D often contain pronouns such as"it", "here" and "the same" to make language expressions concise. This requiresgrounding methods to understand the context and retrieve relevant informationfrom previous steps to correctly locate object sequences. Due to the lack of aneffective module for collecting related historical information,state-of-the-art 3DVG methods face significant challenges in adapting to theSG3D task. To fill this gap, we propose GroundFlow -- a plug-in module fortemporal reasoning on 3D point cloud sequential grounding. Firstly, wedemonstrate that integrating GroundFlow improves the task accuracy of 3DVGbaseline methods by a large margin (+7.5\% and +10.2\%) in the SG3D benchmark,even outperforming a 3D large language model pre-trained on various datasets.Furthermore, we selectively extract both short-term and long-term stepinformation based on its relevance to the current instruction, enablingGroundFlow to take a comprehensive view of historical information and maintainits temporal understanding advantage as step counts increase. Overall, our workintroduces temporal reasoning capabilities to existing 3DVG models and achievesstate-of-the-art performance in the SG3D benchmark across five datasets.</description>
      <author>example@mail.com (Zijun Lin, Shuting He, Cheston Tan, Bihan Wen)</author>
      <guid isPermaLink="false">2506.21188v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection</title>
      <link>http://arxiv.org/abs/2506.21382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种增强时间感知图注意力网络（ATGAT）来提高加密货币交易欺诈检测的性能。&lt;h4&gt;背景&lt;/h4&gt;加密货币交易欺诈检测面临交易模式日益复杂和严重类别不平衡的双重挑战。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够有效检测加密货币交易欺诈的方法。&lt;h4&gt;方法&lt;/h4&gt;ATGAT通过三个模块增强检测性能：(1) 设计了一个高级时间嵌入模块，融合多尺度时间差特征和周期性位置编码；(2) 构建了一个时间感知的三元注意力机制，联合优化结构、时间和全局上下文注意力；(3) 使用加权二元交叉熵损失来处理类别不平衡。&lt;h4&gt;主要发现&lt;/h4&gt;在Elliptic++加密货币数据集上的实验表明，ATGAT实现了0.9130的AUC，比最佳传统方法XGBoost提高了9.2%，比GCN提高了12.0%，比标准GAT提高了10.0%。&lt;h4&gt;结论&lt;/h4&gt;该方法不仅验证了时间感知和三元注意力机制对图神经网络增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原理可推广到其他时间图异常检测任务。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes an Augmented Temporal-aware Graph Attention Network (ATGAT) to improve the performance of cryptocurrency transaction fraud detection. The background is that cryptocurrency transaction fraud detection faces the dual challenges of increasingly complex transaction patterns and severe class imbalance. The purpose is to design a method that can effectively detect cryptocurrency transaction fraud. The method enhances the performance through three modules: (1) designing an advanced temporal embedding module that fuses multi-scale time difference features with periodic position encoding; (2) constructing a temporal-aware triple attention mechanism that jointly optimizes structural, temporal, and global context attention; (3) employing weighted BCE loss to address class imbalance. Experiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGAT achieves an AUC of 0.9130, representing a 9.2% improvement over the best traditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. This method not only validates the enhancement effect of temporal awareness and triple attention mechanisms on graph neural networks, but also provides financial institutions with more reliable fraud detection tools, with its design principles generalizable to other temporal graph anomaly detection tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Cryptocurrency transaction fraud detection faces the dual challenges ofincreasingly complex transaction patterns and severe class imbalance.Traditional methods rely on manual feature engineering and struggle to capturetemporal and structural dependencies in transaction networks. This paperproposes an Augmented Temporal-aware Graph Attention Network (ATGAT) thatenhances detection performance through three modules: (1) designing an advancedtemporal embedding module that fuses multi-scale time difference features withperiodic position encoding; (2) constructing a temporal-aware triple attentionmechanism that jointly optimizes structural, temporal, and global contextattention; (3) employing weighted BCE loss to address class imbalance.Experiments on the Elliptic++ cryptocurrency dataset demonstrate that ATGATachieves an AUC of 0.9130, representing a 9.2% improvement over the besttraditional method XGBoost, 12.0% over GCN, and 10.0% over standard GAT. Thismethod not only validates the enhancement effect of temporal awareness andtriple attention mechanisms on graph neural networks, but also providesfinancial institutions with more reliable fraud detection tools, with itsdesign principles generalizable to other temporal graph anomaly detectiontasks.</description>
      <author>example@mail.com (Zhi Zheng, Bochuan Zhou, Yuping Song)</author>
      <guid isPermaLink="false">2506.21382v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Canonical Quantization of a Memristive Leaky Integrate-and-Fire Neuron Circuit</title>
      <link>http://arxiv.org/abs/2506.21363v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种量子化忆阻漏积分-触发（LIF）神经元的理论框架，结合了神经形态工程和开放量子系统的原理。&lt;h4&gt;背景&lt;/h4&gt;研究基于经典忆阻LIF电路，应用规范量子化技术，基于电路量子电动力学推导出量子模型。&lt;h4&gt;目的&lt;/h4&gt;建立量子神经形态计算的基础模型，为生物启发式量子触发神经网络和量子机器学习的新范式提供途径。&lt;h4&gt;方法&lt;/h4&gt;通过对量子化忆阻和LIF神经元的弱耦合和绝热状态的数值模拟，验证了其关键动力学特征，包括记忆效应和触发行为。&lt;h4&gt;主要发现&lt;/h4&gt;模拟结果显示了量子化忆阻和LIF神经元的记忆效应和触发行为等关键动力学特征。&lt;h4&gt;结论&lt;/h4&gt;该研究为量子神经形态计算奠定了基础，为量子机器学习提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;We present a theoretical framework for a quantized memristive LeakyIntegrate-and-Fire (LIF) neuron, uniting principles from neuromorphic engineering and open quantum systems. Starting from a classical memristive LIF circuit, we apply canonical quantization techniques to derive a quantum model grounded in circuit quantum electrodynamics. Numerical simulations demonstrate key dynamical features of the quantized memristor and LIF neuron in the weak-coupling and adiabatic regime, including memory effects and spiking behaviour. This work establishes a foundational model for quantum neuromorphic computing, offering a pathway towards biologically inspired quantum spiking neural networks and new paradigms in quantum machine learning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a theoretical framework for a quantized memristive LeakyIntegrate-and-Fire (LIF) neuron, uniting principles from neuromorphicengineering and open quantum systems. Starting from a classical memristive LIFcircuit, we apply canonical quantization techniques to derive a quantum modelgrounded in circuit quantum electrodynamics. Numerical simulations demonstratekey dynamical features of the quantized memristor and LIF neuron in theweak-coupling and adiabatic regime, including memory effects and spikingbehaviour. This work establishes a foundational model for quantum neuromorphiccomputing, offering a pathway towards biologically inspired quantum spikingneural networks and new paradigms in quantum machine learning.</description>
      <author>example@mail.com (Dean Brand, Domenica Dibenedetto, Francesco Petruccione)</author>
      <guid isPermaLink="false">2506.21363v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Task-Aware KV Compression For Cost-Effective Long Video Understanding</title>
      <link>http://arxiv.org/abs/2506.21184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 3 figures, 6 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Video-X^2L，一种用于长视频理解（LVU）的多模态大型语言模型（MLLM）的压缩方法，旨在减少计算成本并保持关键视频信息。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态大型语言模型在处理长视频理解时面临巨大的计算成本问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效的方法来减少LVU任务的计算成本，同时保留关键视频信息。&lt;h4&gt;方法&lt;/h4&gt;Video-X^2L包括两个关键操作：双级KV压缩和选择性KV重载。双级KV压缩在MLLM预填充阶段生成两种压缩KV：低压缩KV（L-KVs）捕获精细的视频细节和高压缩KV（H-KVs）提供紧凑的视频表示。选择性KV重载在MLLM解码阶段，选择性地重载L-KVs以处理最关键的视频片段，而使用H-KVs处理其他不那么重要的片段。&lt;h4&gt;主要发现&lt;/h4&gt;Video-X^2L在保持总体紧凑性的同时，允许MLLM充分利用特定任务的信息。Video-X^2L简单有效，无需额外训练，可直接与现有的KV-compressible MLLMs兼容。&lt;h4&gt;结论&lt;/h4&gt;实验结果表明，Video-X^2L在多种流行的LVU基准测试中优于现有的KV压缩方法，同时显著降低了计算成本。&lt;h4&gt;翻译&lt;/h4&gt;Long-video understanding (LVU) remains a severe challenge for existing multimodal large language models (MLLMs), primarily due to the prohibitive computational cost. Recent approaches have explored KV compression to mitigate this issue, but they often suffer from significant information loss at high compression ratios. In this paper, we introduce Video-X^2L, which flexibly preserves critical video information for each LVU task. Video-X^2L involves two key operations. The first one is called bi-level KV compression. During the MLLM's pre-filling stage, Video-X^2L generates two types of compressed KVs: low-compression KVs (L-KVs) to capture fine-grained video details and high-compression KVs (H-KVs) to offer compact video representations. The second one is called selective KV re-loading. During the MLLM's decoding stage, Video-X^2L selectively re-loads L-KVs for the most critical video chunks while using H-KVs for other less important ones. This allows the MLLM to fully utilize task-specific information while maintaining the overall compactness. Video-X^2L is simple yet effective: it is free from additional training and directly compatible with existing KV-compressible MLLMs. We evaluate Video-X^2L with a variety of popular LVU benchmarks, including VideoMME, MLVU, LongVideoBench, and VNBench. Our experiment result shows that Video-X^2L outperforms existing KV-compression methods by a huge advantage while substantially saving the computation cost.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Long-video understanding (LVU) remains a severe challenge for existingmultimodal large language models (MLLMs), primarily due to the prohibitivecomputational cost. Recent approaches have explored KV compression to mitigatethis issue, but they often suffer from significant information loss at highcompression ratios. In this paper, we introduce Video-X^2L, which flexiblypreserves critical video information for each LVU task. Video-X^2L involves twokey operations. The first one is called bi-level KV compression. During theMLLM's pre-filling stage, Video-X^2L generates two types of compressed KVs:low-compression KVs (L-KVs) to capture fine-grained video details andhigh-compression KVs (H-KVs) to offer compact video representations. The secondone is called selective KV re-loading. During the MLLM's decoding stage,Video-X^2L selectively re-loads L-KVs for the most critical video chunks whileusing H-KVs for other less important ones. This allows the MLLM to fullyutilize task-specific information while maintaining the overall compactness.Video-X^2L is simple yet effective: it is free from additional training anddirectly compatible with existing KV-compressible MLLMs. We evaluate Video-X^2Lwith a variety of popular LVU benchmarks, including VideoMME, MLVU,LongVideoBench, and VNBench. Our experiment result shows that Video-X^2Loutperforms existing KV-compression methods by a huge advantage whilesubstantially saving the computation cost.</description>
      <author>example@mail.com (Minghao Qin, Yan Shu, Peitian Zhang, Kun Lun, Huaying Yuan, Juenjie Zhou, Shitao Xiao, Bo Zhao, Zheng Liu)</author>
      <guid isPermaLink="false">2506.21184v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features</title>
      <link>http://arxiv.org/abs/2506.21046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 9 figures, to appear in ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了利用自监督视觉Transformer（ViT）表示来提高对抗迁移性的可能性，并提出了dSVA，一种基于生成对抗的ViT特征攻击方法。&lt;h4&gt;背景&lt;/h4&gt;深度神经网络（DNNs）的能力来源于从数据中提取和解释特征。以往的研究通常依赖于监督学习来提取特征，而本文则探索了自监督学习与Transformer架构之间的协同作用。&lt;h4&gt;目的&lt;/h4&gt;研究利用自监督Vision Transformer (ViT)表示是否能提高对抗迁移性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为dSVA的生成双重自监督ViT特征攻击方法，该方法利用了对比学习（CL）的全球结构特征和掩码图像建模（MIM）的局部纹理特征。设计了一个新的生成训练框架，其中包含一个生成器来创建黑盒对抗示例，并利用自监督ViT的联合特征和注意力机制来训练生成器。&lt;h4&gt;主要发现&lt;/h4&gt;对比学习（CL）和掩码图像建模（MIM）使ViT能够关注不同的特征趋势，当联合使用时，具有出色的对抗泛化能力。通过破坏自监督ViT提取的双重深度特征，实现了对各种架构模型的显著黑盒迁移性。&lt;h4&gt;结论&lt;/h4&gt;dSVA方法在黑盒迁移性方面取得了显著成果，为不同架构的模型提供了超越现有技术的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了利用自监督视觉Transformer（ViT）表示来提高对抗迁移性的可能性。受自监督学习和Transformer架构之间卓越协同作用的启发，本文提出了dSVA——一种基于生成对抗的ViT特征攻击方法。本文提出了一种名为dSVA的生成双重自监督ViT特征攻击方法，该方法利用了对比学习（CL）的全球结构特征和掩码图像建模（MIM）的局部纹理特征。设计了一个新的生成训练框架，其中包含一个生成器来创建黑盒对抗示例，并利用自监督ViT的联合特征和注意力机制来训练生成器。研究发现，对比学习（CL）和掩码图像建模（MIM）使ViT能够关注不同的特征趋势，当联合使用时，具有出色的对抗泛化能力。通过破坏自监督ViT提取的双重深度特征，实现了对各种架构模型的显著黑盒迁移性。dSVA方法在黑盒迁移性方面取得了显著成果，为不同架构的模型提供了超越现有技术的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability of deep neural networks (DNNs) come from extracting andinterpreting features from the data provided. By exploiting intermediatefeatures in DNNs instead of relying on hard labels, we craft adversarialperturbation that generalize more effectively, boosting black-boxtransferability. These features ubiquitously come from supervised learning inprevious work. Inspired by the exceptional synergy between self-supervisedlearning and the Transformer architecture, this paper explores whetherexploiting self-supervised Vision Transformer (ViT) representations can improveadversarial transferability. We present dSVA -- a generative dualself-supervised ViT features attack, that exploits both global structuralfeatures from contrastive learning (CL) and local textural features from maskedimage modeling (MIM), the self-supervised learning paradigm duo for ViTs. Wedesign a novel generative training framework that incorporates a generator tocreate black-box adversarial examples, and strategies to train the generator byexploiting joint features and the attention mechanism of self-supervised ViTs.Our findings show that CL and MIM enable ViTs to attend to distinct featuretendencies, which, when exploited in tandem, boast great adversarialgeneralizability. By disrupting dual deep features distilled by self-supervisedViTs, we are rewarded with remarkable black-box transferability to models ofvarious architectures that outperform state-of-the-arts. Code available athttps://github.com/spencerwooo/dSVA.</description>
      <author>example@mail.com (Shangbo Wu, Yu-an Tan, Ruinan Ma, Wencong Ma, Dehua Zhu, Yuanzhang Li)</author>
      <guid isPermaLink="false">2506.21046v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Real-time and personalized product recommendations for large e-commerce platforms</title>
      <link>http://arxiv.org/abs/2506.21368v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This paper has been accepted for publication at the International  Conference on Artificial Neural Networks (ICANN) 2025. The final  authenticated version will be available for purchase through the publisher's  website. The conference proceedings will be published by Springer in the  Lecture Notes in Computer Science (LNCS) series&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对大型电子商务平台，尤其是时尚零售领域，提供实时个性化产品推荐的方法。&lt;h4&gt;背景&lt;/h4&gt;针对大型电子商务平台，尤其是时尚零售领域，需要提供准确、可扩展且响应时间最短的产品推荐。&lt;h4&gt;目的&lt;/h4&gt;实现准确和可扩展的推荐，同时保证最小化响应时间，提升用户满意度。&lt;h4&gt;方法&lt;/h4&gt;采用图神经网络和节省学习方法的结合，进行实时个性化推荐。&lt;h4&gt;主要发现&lt;/h4&gt;通过对大型电商平台数据的实验，验证了该方法在预测购买序列和处理多交互场景中的有效性，并在实际约束条件下实现了高效的个性化推荐。&lt;h4&gt;结论&lt;/h4&gt;该方法在电子商务平台中提供实时、个性化的产品推荐是有效的，能够满足实际应用需求。&lt;h4&gt;翻译&lt;/h4&gt;We present a methodology to provide real-time and personalized product recommendations for large e-commerce platforms, specifically focusing on fashion retail. Our approach aims to achieve accurate and scalable recommendations with minimal response times, ensuring user satisfaction, leveraging Graph Neural Networks and parsimonious learning methodologies. Extensive experimentation with datasets from one of the largest e-commerce platforms demonstrates the effectiveness of our approach in forecasting purchase sequences and handling multi-interaction scenarios, achieving efficient personalized recommendations under real-world constraints.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a methodology to provide real-time and personalized productrecommendations for large e-commerce platforms, specifically focusing onfashion retail. Our approach aims to achieve accurate and scalablerecommendations with minimal response times, ensuring user satisfaction,leveraging Graph Neural Networks and parsimonious learning methodologies.Extensive experimentation with datasets from one of the largest e-commerceplatforms demonstrates the effectiveness of our approach in forecastingpurchase sequences and handling multi-interaction scenarios, achievingefficient personalized recommendations under real-world constraints.</description>
      <author>example@mail.com (Matteo Tolloso, Davide Bacciu, Shahab Mokarizadeh, Marco Varesi)</author>
      <guid isPermaLink="false">2506.21368v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Hardware-Aware Quantum Kernel Design Based on Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.21161v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HaQGNN的硬件感知量子核设计框架，旨在提高量子机器学习（QML）中的量子核设计效率。&lt;h4&gt;背景&lt;/h4&gt;量子核方法在量子机器学习中是一个有前景的方向，但设计适应目标任务和近端量子硬件约束的有效量子核是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出HaQGNN框架，以评估和选择与任务相关的量子电路。&lt;h4&gt;方法&lt;/h4&gt;HaQGNN框架结合了量子设备拓扑、噪声特性和图神经网络（GNNs），通过预测与保真度和核性能相关的指标来筛选电路。此外，还集成了特征选择，以提高与有限量子比特系统的兼容性并减轻核退化。&lt;h4&gt;主要发现&lt;/h4&gt;在Credit Card、MNIST-5和FMNIST-4三个基准数据集上的实验表明，HaQGNN在分类精度方面优于现有的量子核基线。&lt;h4&gt;结论&lt;/h4&gt;基于学习和硬件感知的策略有望推动在NISQ设备上实现实用的量子核设计。&lt;h4&gt;翻译&lt;/h4&gt;Quantum kernel methods have emerged as a promising direction in quantum machine learning (QML), offering a principled way to map classical data into high-dimensional quantum Hilbert spaces. While conceptually powerful, designing effective quantum kernels that adapt to both the target task and the constraints of near-term quantum hardware remains a nontrivial challenge. In this work, we propose HaQGNN, a hardware-aware quantum kernel design framework that integrates quantum device topology, noise characteristics, and graph neural networks (GNNs) to evaluate and select task-relevant quantum circuits. By predicting surrogate metrics related to fidelity and kernel performance, HaQGNN enables efficient circuit screening at scale. Feature selection is further incorporated to improve compatibility with limited-qubit systems and mitigate kernel degradation. Extensive experiments on three benchmark datasets, Credit Card, MNIST-5, and FMNIST-4, demonstrate that HaQGNN outperforms existing quantum kernel baselines in terms of classification accuracy. Our work highlights the potential of learning-based and hardware-aware strategies for advancing practical quantum kernel design on NISQ devices.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum kernel methods have emerged as a promising direction in quantummachine learning (QML), offering a principled way to map classical data intohigh-dimensional quantum Hilbert spaces. While conceptually powerful, designingeffective quantum kernels that adapt to both the target task and theconstraints of near-term quantum hardware remains a nontrivial challenge. Inthis work, we propose HaQGNN, a hardware-aware quantum kernel design frameworkthat integrates quantum device topology, noise characteristics, and graphneural networks (GNNs) to evaluate and select task-relevant quantum circuits.By predicting surrogate metrics related to fidelity and kernel performance,HaQGNN enables efficient circuit screening at scale. Feature selection isfurther incorporated to improve compatibility with limited-qubit systems andmitigate kernel degradation. Extensive experiments on three benchmark datasets,Credit Card, MNIST-5, and FMNIST-4, demonstrate that HaQGNN outperformsexisting quantum kernel baselines in terms of classification accuracy. Our workhighlights the potential of learning-based and hardware-aware strategies foradvancing practical quantum kernel design on NISQ devices.</description>
      <author>example@mail.com (Yuxiang Liu, Fanxu Meng, Lu Wang, Yi Hu, Sixuan Li, Zaichen Zhang, Xutao Yu)</author>
      <guid isPermaLink="false">2506.21161v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence</title>
      <link>http://arxiv.org/abs/2506.21028v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TRIDENT是一个新的框架，用于学习分子的丰富表示，它整合了分子的SMILES、文本描述和分类学功能注释。&lt;h4&gt;背景&lt;/h4&gt;多模态学习被证明是学习分子表示的有力范式，但先前的工作往往忽略了分子的文本和分类学信息。&lt;h4&gt;目的&lt;/h4&gt;提出TRIDENT框架，通过整合分子SMILES、文本描述和分类学功能注释来学习丰富的分子表示。&lt;h4&gt;方法&lt;/h4&gt;构建了一个包含分子-文本对的全面数据集，具有结构化的多层次功能注释。使用基于体积的对齐目标联合对齐三模态特征，并引入了新的局部对齐目标以捕捉分子亚结构和相应亚文本描述之间的详细关系。&lt;h4&gt;主要发现&lt;/h4&gt;TRIDENT在11个下游任务上实现了最先进的性能，证明了结合SMILES、文本和分类学功能注释对分子性质预测的价值。&lt;h4&gt;结论&lt;/h4&gt;TRIDENT框架通过结合多种信息源，有效地提高了分子性质预测的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Molecular property prediction aims to learn representations that map chemicalstructures to functional properties. While multimodal learning has emerged as apowerful paradigm to learn molecular representations, prior works have largelyoverlooked textual and taxonomic information of molecules for representationlearning. We introduce TRIDENT, a novel framework that integrates molecularSMILES, textual descriptions, and taxonomic functional annotations to learnrich molecular representations. To achieve this, we curate a comprehensivedataset of molecule-text pairs with structured, multi-level functionalannotations. Instead of relying on conventional contrastive loss, TRIDENTemploys a volume-based alignment objective to jointly align tri-modal featuresat the global level, enabling soft, geometry-aware alignment across modalities.Additionally, TRIDENT introduces a novel local alignment objective thatcaptures detailed relationships between molecular substructures and theircorresponding sub-textual descriptions. A momentum-based mechanism dynamicallybalances global and local alignment, enabling the model to learn both broadfunctional semantics and fine-grained structure-function mappings. TRIDENTachieves state-of-the-art performance on 11 downstream tasks, demonstrating thevalue of combining SMILES, textual, and taxonomic functional annotations formolecular property prediction.</description>
      <author>example@mail.com (Feng Jiang, Mangal Prakash, Hehuan Ma, Jianyuan Deng, Yuzhi Guo, Amina Mollaysa, Tommaso Mansi, Rui Liao, Junzhou Huang)</author>
      <guid isPermaLink="false">2506.21028v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes</title>
      <link>http://arxiv.org/abs/2506.21116v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了视频大型语言模型（VideoLLMs）在多镜头场景下的理解能力，并提出了一个新的数据集和模型来提升这一能力。&lt;h4&gt;背景&lt;/h4&gt;VideoLLMs在理解能力上表现出色，但在处理多镜头场景时，如不同角度或场景变化的视频片段，会遇到困难，可能导致实例身份遗忘和关键帧忽视等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，论文旨在提出一种新的数据集和模型，以提升VideoLLMs在多镜头场景下的性能。&lt;h4&gt;方法&lt;/h4&gt;论文首先分析了现有数据集中缺乏多镜头标注的问题，并因此引入了一个名为MultiClip-Bench的新数据集，其中包含针对多镜头场景的密集描述和基于指令的问答对。接着，论文提出了一种新的模型IPFormer-VideoLLM，该模型通过高效的关注力连接器注入实例级特征作为实例提示，以实现跨场景的实例特定信息聚合。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，新的数据集和模型能够显著提升多场景视频理解能力，并在多个视频基准测试中展现出独特的优势。&lt;h4&gt;结论&lt;/h4&gt;论文提出的MultiClip-Bench数据集和IPFormer-VideoLLM模型能够有效提升VideoLLMs在多镜头场景下的性能，为视频理解领域提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Video Large Language Models (VideoLLMs) have demonstrated remarkableunderstanding capabilities, but are found struggling to tackle multi-shotscenarios,e.g., video clips with varying camera angles or scene changes. Thischallenge can render failures such as instance identity forgetting and keyframe negligence. In this work, we first attribute the challenge to the lack ofmulti-shot annotations among existing datasets and therefore we introduce a newdataset termed MultiClip-Bench, featuring dense descriptions andinstruction-based question-answering pairs tailored for multi-shot scenarios.We empirically find that the training set significantly boosts the multi-shotperformance, while the testing benchmark provides a reliable measure of themodel capability in multi-shot scenarios. By further analyzing and discoveringthat current models only encode instance features in a discrete or lossymanner, at the risk of missing identity information, we then contribute a newmodel IPFormer-VideoLLM. Its key idea is the injection of instance-levelfeatures as instance prompts through an efficient attention-based connector.This allows for the aggregation of instance-specific information across scenes.Experiments demonstrate that our proposed dataset and model not only enhancethe multi-scene video understanding significantly, but also offer distinctadvantages across various video benchmarks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Video Large Language Models (VideoLLMs) have demonstrated remarkableunderstanding capabilities, but are found struggling to tackle multi-shotscenarios,e.g., video clips with varying camera angles or scene changes. Thischallenge can render failures such as instance identity forgetting and keyframe negligence. In this work, we first attribute the challenge to the lack ofmulti-shot annotations among existing datasets and therefore we introduce a newdataset termed MultiClip-Bench, featuring dense descriptions andinstruction-based question-answering pairs tailored for multi-shot scenarios.We empirically find that the training set significantly boosts the multi-shotperformance, while the testing benchmark provides a reliable measure of themodel capability in multi-shot scenarios. By further analyzing and discoveringthat current models only encode instance features in a discrete or lossymanner, at the risk of missing identity information, we then contribute a newmodel IPFormer-VideoLLM. Its key idea is the injection of instance-levelfeatures as instance prompts through an efficient attention-based connector.This allows for the aggregation of instance-specific information across scenes.Experiments demonstrate that our proposed dataset and model not only enhancethe multi-scene video understanding significantly, but also offer distinctadvantages across various video benchmarks.</description>
      <author>example@mail.com (Yujia Liang, Jile Jiao, Zhicheng Wang, Xuetao Feng, Zixuan Ye, Yuan Wang, Hao Lu)</author>
      <guid isPermaLink="false">2506.21116v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Active Inference AI Systems for Scientific Discovery</title>
      <link>http://arxiv.org/abs/2506.21329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文讨论了人工智能在科学发现中的应用，指出当前系统受限于操作架构、脆弱的推理机制和与实验现实的分离。作者提出，AI在科学领域的进步依赖于弥合三个基本差距：抽象差距、推理差距和现实差距。&lt;h4&gt;背景&lt;/h4&gt;人工智能的快速发展引发了关于颠覆性科学发现的期望，但现有系统在操作架构、脆弱的推理机制和与实验现实的分离方面存在根本限制。&lt;h4&gt;目的&lt;/h4&gt;本文旨在探讨AI在科学发现中的进步，并提出了通过弥合三个基本差距来实现这一目标的方法。&lt;h4&gt;方法&lt;/h4&gt;作者提出了主动推理AI系统，这些系统通过以下方式实现科学发现：(i) 维持基于因果自监督基础模型的长寿命研究记忆；(ii) 装备贝叶斯安全措施的符号或神经符号规划器；(iii) 增长持久的知识图谱，其中思维生成新的概念节点，推理建立因果关系，现实世界的交互修剪错误连接并加强验证路径；(iv) 通过与高保真模拟器和自动化实验室的闭环交互来细化其内部表示。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出了一种架构，其中发现源于内部模型（能够进行反事实推理）和外部验证（将假设建立在现实基础上）之间的相互作用。&lt;h4&gt;结论&lt;/h4&gt;作者认为，来自模拟和实验的反馈固有的模糊性和潜在的不确定性使得人类判断不可或缺，不仅是临时的支架，而且是永久性的架构组件。&lt;h4&gt;翻译&lt;/h4&gt;The rapid evolution of artificial intelligence has led to expectations of transformative scientific discovery, yet current systems remain fundamentally limited by their operational architectures, brittle reasoning mechanisms, and their separation from experimental reality. Building on earlier work, we contend that progress in AI-driven science now depends on closing three fundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap-- rather than on model size/data/test time compute. Scientific reasoning demands internal representations that support simulation of actions and response, causal structures that distinguish correlation from mechanism, and continuous calibration. We define active inference AI systems for scientific discovery as those that (i) maintain long-lived research memories grounded in causal self-supervised foundation models, (ii) symbolic or neuro-symbolic planners equipped with Bayesian guardrails, (iii) grow persistent knowledge graphs where thinking generates novel conceptual nodes, reasoning establishes causal edges, and real-world interaction prunes false connections while strengthening verified pathways, and (iv) refine their internal representations through closed-loop interaction with both high-fidelity simulators and automated laboratories - an operational loop where mental simulation guides action and empirical surprise reshapes understanding. In essence, we outline an architecture where discovery arises from the interplay between internal models that enable counterfactual reasoning and external validation that grounds hypotheses in reality. It is also argued that the inherent ambiguity in feedback from simulations and experiments, and underlying uncertainties makes human judgment indispensable, not as a temporary scaffold but as a permanent architectural component.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid evolution of artificial intelligence has led to expectations oftransformative scientific discovery, yet current systems remain fundamentallylimited by their operational architectures, brittle reasoning mechanisms, andtheir separation from experimental reality. Building on earlier work, wecontend that progress in AI-driven science now depends on closing threefundamental gaps -- the abstraction gap, the reasoning gap, and the reality gap-- rather than on model size/data/test time compute. Scientific reasoningdemands internal representations that support simulation of actions andresponse, causal structures that distinguish correlation from mechanism, andcontinuous calibration. We define active inference AI systems for scientificdiscovery as those that (i) maintain long-lived research memories grounded incausal self-supervised foundation models, (ii) symbolic or neuro-symbolicplanners equipped with Bayesian guardrails, (iii) grow persistent knowledgegraphs where thinking generates novel conceptual nodes, reasoning establishescausal edges, and real-world interaction prunes false connections whilestrengthening verified pathways, and (iv) refine their internal representationsthrough closed-loop interaction with both high-fidelity simulators andautomated laboratories - an operational loop where mental simulation guidesaction and empirical surprise reshapes understanding. In essence, we outline anarchitecture where discovery arises from the interplay between internal modelsthat enable counterfactual reasoning and external validation that groundshypotheses in reality. It is also argued that the inherent ambiguity infeedback from simulations and experiments, and underlying uncertainties makeshuman judgment indispensable, not as a temporary scaffold but as a permanentarchitectural component.</description>
      <author>example@mail.com (Karthik Duraisamy)</author>
      <guid isPermaLink="false">2506.21329v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling</title>
      <link>http://arxiv.org/abs/2506.21041v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为V2X-REALM的框架，用于在复杂环境中实现鲁棒的协同自动驾驶。&lt;h4&gt;背景&lt;/h4&gt;在城市环境中，自动驾驶系统需要在罕见、多样化的视觉退化场景下进行稳健的规划和决策，这在协同环境中尤为重要。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一挑战，提出了V2X-REALM框架，以实现鲁棒的协同自动驾驶。&lt;h4&gt;方法&lt;/h4&gt;V2X-REALM引入了三项核心创新：(i) 提出了一种提示驱动的长尾场景生成和评估流程，利用基础模型合成真实的长尾条件；(ii) 引入了一个门控多场景自适应注意力模块，以调节视觉流；(iii) 提出了一个多任务场景感知对比学习目标，以改善多模态对齐并促进跨场景特征可分离性。&lt;h4&gt;主要发现&lt;/h4&gt;大量实验表明，V2X-REALM在复杂、具有挑战性的驾驶条件下，在鲁棒性、语义推理、安全性和规划准确性方面显著优于现有基线。&lt;h4&gt;结论&lt;/h4&gt;V2X-REALM推进了端到端协同自动驾驶的可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;Ensuring robust planning and decision-making under rare, diverse, and visually degraded long-tail scenarios remains a fundamental challenge for autonomous driving in urban environments. This issue becomes more critical in cooperative settings, where vehicles and infrastructure jointly perceive and reason across complex environments. To address this challenge, we propose V2X-REALM, a vision-language model (VLM)-based framework with adaptive multimodal learning for robust cooperative autonomous driving under long-tail scenarios. V2X-REALM introduces three core innovations: (i) a prompt-driven long-tail scenario generation and evaluation pipeline that leverages foundation models to synthesize realistic long-tail conditions such as snow and fog across vehicle- and infrastructure-side views, enriching training diversity efficiently; (ii) a gated multi-scenario adaptive attention module that modulates the visual stream using scenario priors to recalibrate ambiguous or corrupted features; and (iii) a multi-task scenario-aware contrastive learning objective that improves multimodal alignment and promotes cross-scenario feature separability. Extensive experiments demonstrate that V2X-REALM significantly outperforms existing baselines in robustness, semantic reasoning, safety, and planning accuracy under complex, challenging driving conditions, advancing the scalability of end-to-end cooperative autonomous driving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring robust planning and decision-making under rare, diverse, andvisually degraded long-tail scenarios remains a fundamental challenge forautonomous driving in urban environments. This issue becomes more critical incooperative settings, where vehicles and infrastructure jointly perceive andreason across complex environments. To address this challenge, we proposeV2X-REALM, a vision-language model (VLM)-based framework with adaptivemultimodal learning for robust cooperative autonomous driving under long-tailscenarios. V2X-REALM introduces three core innovations: (i) a prompt-drivenlong-tail scenario generation and evaluation pipeline that leverages foundationmodels to synthesize realistic long-tail conditions such as snow and fog acrossvehicle- and infrastructure-side views, enriching training diversityefficiently; (ii) a gated multi-scenario adaptive attention module thatmodulates the visual stream using scenario priors to recalibrate ambiguous orcorrupted features; and (iii) a multi-task scenario-aware contrastive learningobjective that improves multimodal alignment and promotes cross-scenariofeature separability. Extensive experiments demonstrate that V2X-REALMsignificantly outperforms existing baselines in robustness, semantic reasoning,safety, and planning accuracy under complex, challenging driving conditions,advancing the scalability of end-to-end cooperative autonomous driving.</description>
      <author>example@mail.com (Junwei You, Pei Li, Zhuoyu Jiang, Zilin Huang, Rui Gan, Haotian Shi, Bin Ran)</author>
      <guid isPermaLink="false">2506.21041v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction</title>
      <link>http://arxiv.org/abs/2506.21401v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/zhirui-gao/Curve-Gaussian Accepted by ICCV  2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种从多视角边缘图中直接重建3D参数曲线的端到端框架。&lt;h4&gt;背景&lt;/h4&gt;与现有的两阶段方法（边点云重建和参数曲线拟合）相比，本文提出的一阶段方法直接从2D边缘图优化3D参数曲线，消除了由于不同阶段之间固有的优化差距导致的误差累积。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够保留几何属性并允许可微渲染的辅助表示，以解决参数曲线不适用于基于渲染的多视图优化的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种双向耦合机制，将参数曲线与边缘导向的高斯成分相结合，形成了一种曲线感知的高斯表示（CurveGaussian），它允许3D曲线的可微渲染，并通过多视角证据直接优化。此外，引入了一种动态自适应拓扑优化框架，通过线性化、合并、拆分和修剪操作来细化曲线结构。&lt;h4&gt;主要发现&lt;/h4&gt;在ABC数据集和真实世界基准测试中，该方法在产生更干净、更稳健的重构方面优于两阶段方法。&lt;h4&gt;结论&lt;/h4&gt;与现有方法相比，该方法通过直接优化参数曲线，在训练过程中显著减少了参数数量，实现了更高的效率和更好的性能。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种从多视角边缘图中直接重建3D参数曲线的端到端框架。与现有的两阶段方法（边点云重建和参数曲线拟合）相比，本文提出的一阶段方法直接从2D边缘图优化3D参数曲线，消除了由于不同阶段之间固有的优化差距导致的误差累积。然而，参数曲线本质上不适合基于渲染的多视图优化，需要一种辅助表示来保留其几何属性同时允许可微渲染。我们提出了一种新的双向耦合机制，将参数曲线与边缘导向的高斯成分相结合，形成了一种曲线感知的高斯表示（CurveGaussian），它允许3D曲线的可微渲染，并通过多视角证据直接优化。此外，引入了一种动态自适应拓扑优化框架，通过线性化、合并、拆分和修剪操作来细化曲线结构。在ABC数据集和真实世界基准测试中，该方法在产生更干净、更稳健的重构方面优于两阶段方法。与现有方法相比，该方法通过直接优化参数曲线，在训练过程中显著减少了参数数量，实现了更高的效率和更好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents an end-to-end framework for reconstructing 3D parametriccurves directly from multi-view edge maps. Contrasting with existing two-stagemethods that follow a sequential ``edge point cloud reconstruction andparametric curve fitting'' pipeline, our one-stage approach optimizes 3Dparametric curves directly from 2D edge maps, eliminating error accumulationcaused by the inherent optimization gap between disconnected stages. However,parametric curves inherently lack suitability for rendering-based multi-viewoptimization, necessitating a complementary representation that preserves theirgeometric properties while enabling differentiable rendering. We propose anovel bi-directional coupling mechanism between parametric curves andedge-oriented Gaussian components. This tight correspondence formulates acurve-aware Gaussian representation, \textbf{CurveGaussian}, that enablesdifferentiable rendering of 3D curves, allowing direct optimization guided bymulti-view evidence. Furthermore, we introduce a dynamically adaptive topologyoptimization framework during training to refine curve structures throughlinearization, merging, splitting, and pruning operations. Comprehensiveevaluations on the ABC dataset and real-world benchmarks demonstrate ourone-stage method's superiority over two-stage alternatives, particularly inproducing cleaner and more robust reconstructions. Additionally, by directlyoptimizing parametric curves, our method significantly reduces the parametercount during training, achieving both higher efficiency and superiorperformance compared to existing approaches.</description>
      <author>example@mail.com (Zhirui Gao. Renjiao Yi, Yaqiao Dai, Xuening Zhu, Wei Chen, Chenyang Zhu, Kai Xu)</author>
      <guid isPermaLink="false">2506.21401v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>FedSC: Federated Learning with Semantic-Aware Collaboration</title>
      <link>http://arxiv.org/abs/2506.21012v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了联邦学习中的语义感知协作（FedSC）方法，旨在解决数据异质性问题，通过捕捉客户端特定的和类别相关的知识来提高联邦学习的性能。&lt;h4&gt;背景&lt;/h4&gt;联邦学习旨在保护隐私的同时协同训练模型，但数据异质性问题，即多个客户端的标签偏好偏差，是主要挑战之一。&lt;h4&gt;目的&lt;/h4&gt;利用客户端内部的语义有意义的知识来处理数据异质性。&lt;h4&gt;方法&lt;/h4&gt;FedSC通过构建语义层面的关系原型和一致性原型来捕捉客户端特定的和类别相关的知识，引入了跨对比学习策略来拉近实例级嵌入与关系原型的距离，并通过差异聚合方式设计一致性原型作为局部模型优化的正则化惩罚。&lt;h4&gt;主要发现&lt;/h4&gt;FedSC在多个具有挑战性的场景中展示了有效性，并且关键组件的效率也得到了提高。&lt;h4&gt;结论&lt;/h4&gt;FedSC方法为解决联邦学习中的数据异质性问题提供了一种有效且高效的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3736957&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Federated learning (FL) aims to train models collaboratively across clientswithout sharing data for privacy-preserving. However, one major challenge isthe data heterogeneity issue, which refers to the biased labeling preferencesat multiple clients. A number of existing FL methods attempt to tackle dataheterogeneity locally (e.g., regularizing local models) or globally (e.g.,fine-tuning global model), often neglecting inherent semantic informationcontained in each client. To explore the possibility of using intra-clientsemantically meaningful knowledge in handling data heterogeneity, in thispaper, we propose Federated Learning with Semantic-Aware Collaboration (FedSC)to capture client-specific and class-relevant knowledge across heterogeneousclients. The core idea of FedSC is to construct relational prototypes andconsistent prototypes at semantic-level, aiming to provide fruitful classunderlying knowledge and stable convergence signals in a prototype-wisecollaborative way. On the one hand, FedSC introduces an inter-contrastivelearning strategy to bring instance-level embeddings closer to relationalprototypes with the same semantics and away from distinct classes. On the otherhand, FedSC devises consistent prototypes via a discrepancy aggregation manner,as a regularization penalty to constrain the optimization region of the localmodel. Moreover, a theoretical analysis for FedSC is provided to ensure aconvergence guarantee. Experimental results on various challenging scenariosdemonstrate the effectiveness of FedSC and the efficiency of crucialcomponents.</description>
      <author>example@mail.com (Huan Wang, Haoran Li, Huaming Chen, Jun Yan, Jiahua Shi, Jun Shen)</author>
      <guid isPermaLink="false">2506.21012v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Demystifying Distributed Training of Graph Neural Networks for Link Prediction</title>
      <link>http://arxiv.org/abs/2506.20818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IEEE ICDCS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了分布式图神经网络（GNN）在链接预测任务中的性能问题，提出了一种名为SpLPG的方法，通过图稀疏化技术降低通信成本，同时保持链接预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;分布式GNN框架和系统增强了GNN的可扩展性和模型训练速度，但大多数优化针对节点分类，其链接预测性能未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;揭示分布式训练GNN进行链接预测时性能退化的原因，并提出解决方案。&lt;h4&gt;方法&lt;/h4&gt;通过研究每个工作节点在其分配的子图上训练GNN时，由于无法访问整个图而导致的性能退化问题。提出SpLPG方法，利用图稀疏化技术减少通信成本。&lt;h4&gt;主要发现&lt;/h4&gt;性能退化的主要原因是图划分引起的信息损失以及模型训练中负样本抽取的方式。&lt;h4&gt;结论&lt;/h4&gt;SpLPG方法通过共享完整图信息解决了性能退化问题，同时降低了通信成本，实验结果表明其可以减少高达80%的通信开销，同时保持链接预测的准确性。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks (GNNs) are powerful tools for solving graph-related problems. Distributed GNN frameworks and systems enhance the scalability of GNNs and accelerate model training, yet most are optimized for node classification. Their performance on link prediction remains underexplored. This paper demystifies distributed training of GNNs for link prediction by investigating the issue of performance degradation when each worker trains a GNN on its assigned partitioned subgraph without having access to the entire graph. We discover that the main sources of the issue come from not only the information loss caused by graph partitioning but also the ways of drawing negative samples during model training. While sharing the complete graph information with each worker resolves the issue and preserves link prediction accuracy, it incurs a high communication cost. We propose SpLPG, which effectively leverages graph sparsification to mitigate the issue of performance degradation at a reduced communication cost. Experiment results on several public real-world datasets demonstrate the effectiveness of SpLPG, which reduces the communication overhead by up to about 80% while mostly preserving link prediction accuracy.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks (GNNs) are powerful tools for solving graph-relatedproblems. Distributed GNN frameworks and systems enhance the scalability ofGNNs and accelerate model training, yet most are optimized for nodeclassification. Their performance on link prediction remains underexplored.This paper demystifies distributed training of GNNs for link prediction byinvestigating the issue of performance degradation when each worker trains aGNN on its assigned partitioned subgraph without having access to the entiregraph. We discover that the main sources of the issue come from not only theinformation loss caused by graph partitioning but also the ways of drawingnegative samples during model training. While sharing the complete graphinformation with each worker resolves the issue and preserves link predictionaccuracy, it incurs a high communication cost. We propose SpLPG, whicheffectively leverages graph sparsification to mitigate the issue of performancedegradation at a reduced communication cost. Experiment results on severalpublic real-world datasets demonstrate the effectiveness of SpLPG, whichreduces the communication overhead by up to about 80% while mostly preservinglink prediction accuracy.</description>
      <author>example@mail.com (Xin Huang, Chul-Ho Lee)</author>
      <guid isPermaLink="false">2506.20818v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Sub-action Tree for Continuous Sign Language Recognition</title>
      <link>http://arxiv.org/abs/2506.20947v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了HST-CSLR，即层次子动作树连续手语识别方法，用于将未剪辑的视频转录为文本词汇，以解决手语识别领域的数据集和标注不足的问题。&lt;h4&gt;背景&lt;/h4&gt;连续手语识别（CSLR）由于缺乏大型数据集和精确标注而面临瓶颈。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来有效地结合词汇知识与视觉表示学习，提高手语识别的准确性。&lt;h4&gt;方法&lt;/h4&gt;构建了一个层次子动作树（HST）用于文本信息表示，逐步对视觉和文本模态进行对齐，并利用树结构来降低计算复杂度。此外，采用对比对齐增强来弥合两种模态之间的差距。&lt;h4&gt;主要发现&lt;/h4&gt;实验在四个数据集上证明了HST-CSLR的有效性。&lt;h4&gt;结论&lt;/h4&gt;HST-CSLR能够有效结合词汇知识，提高连续手语识别的准确率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Continuous sign language recognition (CSLR) aims to transcribe untrimmedvideos into glosses, which are typically textual words. Recent studies indicatethat the lack of large datasets and precise annotations has become a bottleneckfor CSLR due to insufficient training data. To address this, some works havedeveloped cross-modal solutions to align visual and textual modalities.However, they typically extract textual features from glosses without fullyutilizing their knowledge. In this paper, we propose the HierarchicalSub-action Tree (HST), termed HST-CSLR, to efficiently combine gloss knowledgewith visual representation learning. By incorporating gloss-specific knowledgefrom large language models, our approach leverages textual information moreeffectively. Specifically, we construct an HST for textual informationrepresentation, aligning visual and textual modalities step-by-step andbenefiting from the tree structure to reduce computational complexity.Additionally, we impose a contrastive alignment enhancement to bridge the gapbetween the two modalities. Experiments on four datasets (PHOENIX-2014,PHOENIX-2014T, CSL-Daily, and Sign Language Gesture) demonstrate theeffectiveness of our HST-CSLR.</description>
      <author>example@mail.com (Dejie Yang, Zhu Xu, Xinjie Gao, Yang Liu)</author>
      <guid isPermaLink="false">2506.20947v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Detection of Breast Cancer Lumpectomy Margin with SAM-incorporated Forward-Forward Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.21006v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 7 figures, 3 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种结合Segment Anything Model (SAM)和Forward-Forward Contrastive Learning (FFCL)的深度学习框架，用于提高乳腺癌手术中肿瘤边缘评估的准确性和速度。&lt;h4&gt;背景&lt;/h4&gt;目前评估术中肿瘤边缘状态的方法是2D标本放射摄影（SR），但该方法准确性有限，导致近四分之一的病人需要额外的手术。&lt;h4&gt;目的&lt;/h4&gt;提高乳腺癌手术中肿瘤边缘评估的准确性和速度，以减少复发率。&lt;h4&gt;方法&lt;/h4&gt;使用FFCL预训练ResNet-18骨干网络进行边缘状态分类，然后使用SAM进行精细的肿瘤边缘分割。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在边缘分类上达到了0.8455的AUC，相较于基线模型在Dice相似性上提高了27.4%，同时将推理时间缩短到每张图像47毫秒。&lt;h4&gt;结论&lt;/h4&gt;FFCL-SAM显著提高了术中边缘评估的速度和准确性，有潜力减少再次手术率并改善乳腺癌治疗效果。&lt;h4&gt;翻译&lt;/h4&gt;Complete removal of cancer tumors with a negative specimen margin during lumpectomy is essential in reducing breast cancer recurrence. However, 2D specimen radiography (SR), the current method used to assess intraoperative specimen margin status, has limited accuracy, resulting in nearly a quarter of patients requiring additional surgery. To address this, we propose a novel deep learning framework combining the Segment Anything Model (SAM) with Forward-Forward Contrastive Learning (FFCL), a pre-training strategy leveraging both local and global contrastive learning for patch-level classification of SR images. After annotating SR images with regions of known malignancy, non-malignant tissue, and pathology-confirmed margins, we pre-train a ResNet-18 backbone with FFCL to classify margin status, then reconstruct coarse binary masks to prompt SAM for refined tumor margin segmentation. Our approach achieved an AUC of 0.8455 for margin classification and segmented margins with a 27.4% improvement in Dice similarity over baseline models, while reducing inference time to 47 milliseconds per image. These results demonstrate that FFCL-SAM significantly enhances both the speed and accuracy of intraoperative margin assessment, with strong potential to reduce re-excision rates and improve surgical outcomes in breast cancer treatment. Our code is available at https://github.com/tbwa233/FFCL-SAM/.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Complete removal of cancer tumors with a negative specimen margin duringlumpectomy is essential in reducing breast cancer recurrence. However, 2Dspecimen radiography (SR), the current method used to assess intraoperativespecimen margin status, has limited accuracy, resulting in nearly a quarter ofpatients requiring additional surgery. To address this, we propose a novel deeplearning framework combining the Segment Anything Model (SAM) withForward-Forward Contrastive Learning (FFCL), a pre-training strategy leveragingboth local and global contrastive learning for patch-level classification of SRimages. After annotating SR images with regions of known maligancy,non-malignant tissue, and pathology-confirmed margins, we pre-train a ResNet-18backbone with FFCL to classify margin status, then reconstruct coarse binarymasks to prompt SAM for refined tumor margin segmentation. Our approachachieved an AUC of 0.8455 for margin classification and segmented margins witha 27.4% improvement in Dice similarity over baseline models, while reducinginference time to 47 milliseconds per image. These results demonstrate thatFFCL-SAM significantly enhances both the speed and accuracy of intraoperativemargin assessment, with strong potential to reduce re-excision rates andimprove surgical outcomes in breast cancer treatment. Our code is available athttps://github.com/tbwa233/FFCL-SAM/.</description>
      <author>example@mail.com (Tyler Ward, Xiaoqin Wang, Braxton McFarland, Md Atik Ahamed, Sahar Nozad, Talal Arshad, Hafsa Nebbache, Jin Chen, Abdullah Imran)</author>
      <guid isPermaLink="false">2506.21006v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster</title>
      <link>http://arxiv.org/abs/2506.21263v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了DiLoCoX，一种低通信的大规模去中心化集群训练框架，用于解决大规模语言模型（LLMs）在慢速网络上的训练问题。&lt;h4&gt;背景&lt;/h4&gt;分布式训练大型语言模型需要大量的通信，通常依赖于高速可靠的集中式集群。&lt;h4&gt;目的&lt;/h4&gt;探讨在慢速网络上进行训练，释放去中心化集群在处理超过1000亿参数模型时的潜力。&lt;h4&gt;方法&lt;/h4&gt;DiLoCoX结合了管道并行、双重优化策略、一步延迟通信重叠和本地训练，以及自适应梯度压缩方案。&lt;h4&gt;主要发现&lt;/h4&gt;理论分析表明，一步延迟通信重叠和本地训练以及自适应梯度压缩方案具有优势，并通过实证研究证明了DiLoCoX能够在1Gbps网络上预训练107B的基准模型。&lt;h4&gt;结论&lt;/h4&gt;与传统的AllReduce相比，DiLoCoX在分布式训练中实现了357倍的速度提升，同时模型收敛的下降可以忽略不计。DiLoCoX是第一个成功应用于超过1000亿参数模型的去中心化训练框架。&lt;h4&gt;翻译&lt;/h4&gt;The distributed training of foundation models, particularly large languagemodels (LLMs), demands a high level of communication. Consequently, it ishighly dependent on a centralized cluster with fast and reliable interconnects.Can we conduct training on slow networks and thereby unleash the power ofdecentralized clusters when dealing with models exceeding 100 billionparameters? In this paper, we propose DiLoCoX, a low-communication large-scaledecentralized cluster training framework. It combines Pipeline Parallelism withDual Optimizer Policy, One-Step-Delay Overlap of Communication and LocalTraining, and an Adaptive Gradient Compression Scheme. This combinationsignificantly improves the scale of parameters and the speed of modelpre-training. We justify the benefits of one-step-delay overlap of communicationand local training, as well as the adaptive gradient compression scheme, through atheoretical analysis of convergence. Empirically, we demonstrate that DiLoCoX iscapable of pre-training a 107B foundation model over a 1Gbps network. Compared tovanilla AllReduce, DiLoCoX can achieve a 357xspeedup in distributed training while maintaining negligible degradation inmodel convergence. To the best of our knowledge, this is the firstdecentralized training framework successfully applied to models with over 100billion parameters.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The distributed training of foundation models, particularly large languagemodels (LLMs), demands a high level of communication. Consequently, it ishighly dependent on a centralized cluster with fast and reliable interconnects.Can we conduct training on slow networks and thereby unleash the power ofdecentralized clusters when dealing with models exceeding 100 billionparameters? In this paper, we propose DiLoCoX, a low-communication large-scaledecentralized cluster training framework. It combines Pipeline Parallelism withDual Optimizer Policy, One-Step-Delay Overlap of Communication and LocalTraining, and an Adaptive Gradient Compression Scheme. This combinationsignificantly improves the scale of parameters and the speed of modelpre-training. We justify the benefits of one-step-delay overlap ofcommunication and local training, as well as the adaptive gradient compressionscheme, through a theoretical analysis of convergence. Empirically, wedemonstrate that DiLoCoX is capable of pre-training a 107B foundation modelover a 1Gbps network. Compared to vanilla AllReduce, DiLoCoX can achieve a 357xspeedup in distributed training while maintaining negligible degradation inmodel convergence. To the best of our knowledge, this is the firstdecentralized training framework successfully applied to models with over 100billion parameters.</description>
      <author>example@mail.com (Ji Qi, WenPeng Zhu, Li Li, Ming Wu, YingJun Wu, Wu He, Xun Gao, Jason Zeng, Michael Heinrich)</author>
      <guid isPermaLink="false">2506.21263v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Robust and efficient pre-processing techniques for particle-based methods including dynamic boundary generation</title>
      <link>http://arxiv.org/abs/2506.21206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种预处理技术，用于生成高质量粒子分布，适用于二维和三维几何形状，特别是针对平滑粒子流体动力学（SPH）和其他基于粒子的方法。&lt;h4&gt;背景&lt;/h4&gt;在复杂几何形状中进行稳定和准确的粒子模拟面临重大挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种预处理技术，以优化基于粒子的模拟，尤其是SPH。&lt;h4&gt;方法&lt;/h4&gt;该方法包括以下步骤：1）使用基于面的邻域搜索在几何形状表面附近生成分辨率自适应的点云；2）通过点云生成有符号距离场，实现表面区域的高效、局部计算；3）应用分层缠绕数方法创建初始粒子配置；4）使用SPH启发的方案松弛粒子位置，同时打包边界粒子，确保全核支持和各向同性分布，同时保留几何界面；5）该方法利用基于粒子的方法的无网格特性，无需连接信息，易于集成到现有的基于粒子的框架中。&lt;h4&gt;主要发现&lt;/h4&gt;该技术对不完美的输入几何形状鲁棒，内存高效，且性能不受影响。实验表明，随着分辨率越来越高，生成的粒子分布收敛到精确的几何形状。&lt;h4&gt;结论&lt;/h4&gt;该预处理技术能够为基于粒子的模拟提供高质量的粒子分布，适用于复杂几何形状，且易于集成和高效。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Obtaining high-quality particle distributions for stable and accurateparticle-based simulations poses significant challenges, especially for complexgeometries. We introduce a preprocessing technique for 2D and 3D geometries,optimized for smoothed particle hydrodynamics (SPH) and other particle-basedmethods. Our pipeline begins with the generation of a resolution-adaptive pointcloud near the geometry's surface employing a face-based neighborhood search.This point cloud forms the basis for a signed distance field, enablingefficient, localized computations near surface regions. To create an initialparticle configuration, we apply a hierarchical winding number method for fastand accurate inside-outside segmentation. Particle positions are then relaxedusing an SPH-inspired scheme, which also serves to pack boundary particles.This ensures full kernel support and promotes isotropic distributions whilepreserving the geometry interface. By leveraging the meshless nature ofparticle-based methods, our approach does not require connectivity informationand is thus straightforward to integrate into existing particle-basedframeworks. It is robust to imperfect input geometries and memory-efficientwithout compromising performance. Moreover, our experiments demonstrate thatwith increasingly higher resolution, the resulting particle distributionconverges to the exact geometry.</description>
      <author>example@mail.com (Niklas S. Neher, Erik Faulhaber, Sven Berger, Christian Weißenfels, Gregor J. Gassner, Michael Schlottke-Lakemper)</author>
      <guid isPermaLink="false">2506.21206v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in Heterogeneous Graphs</title>
      <link>http://arxiv.org/abs/2506.20980v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted by KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RASH的新型对比学习框架，用于在异构图中捕捉节点异质性，同时解决异构性和异质性带来的挑战。&lt;h4&gt;背景&lt;/h4&gt;现实世界网络通常具有节点异质性的特性，即连接的节点通常具有不同的特征或标签。在异构图中捕捉节点异质性是一个挑战，因为需要考虑节点/边异质性和节点异质性。&lt;h4&gt;目的&lt;/h4&gt;提出RASH框架，以解决在异构图中捕捉节点异质性的问题，并保持异构关系的潜在异质性。&lt;h4&gt;方法&lt;/h4&gt;RASH通过引入双重异构超图来编码多关系双图子图，并根据关系重要性动态构建同质图和异质图。此外，设计了一种多关系对比损失函数，通过最大化互信息来对齐异构和同质/异质视图。&lt;h4&gt;主要发现&lt;/h4&gt;RASH在基准数据集上进行了广泛的实验，证明了其在各种下游任务中的有效性。&lt;h4&gt;结论&lt;/h4&gt;RASH同时解决了异构图中的异质性和异质性的挑战，并在多个任务中展示了其有效性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现实世界的网络通常具有节点异质性的特性，即连接的节点通常具有不同的特征或标签。这种异质性问题在同构图中被广泛研究，但在存在多种节点和边的异构图中的研究仍然很少。在异构图中捕捉节点异质性非常具有挑战性，因为需要仔细考虑节点/边异质性和节点异质性。现有的方法通常将异构图转换为同构图来学习节点异质性，这不可避免地会失去由异构关系传达的潜在异质性。为了弥合这一差距，我们提出了关系感知的同质性和异质性分离（RASH），这是一种新的对比学习框架，它明确地建模了异构交互的高阶语义，并自适应地分离同质性和异质性模式。特别是，RASH引入了双重异构超图来编码多关系双图子图，并根据关系重要性动态构建同质图和异质图。设计了一种多关系对比损失函数，通过最大化互信息来对齐异构和同质/异质视图。这样，RASH同时解决了异构图中的异质性和异质性的挑战。在基准数据集上进行的广泛实验证明了RASH在各种下游任务中的有效性。代码可在以下网址找到：https://github.com/zhengziyu77/RASH。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Real-world networks usually have a property of node heterophily, that is, theconnected nodes usually have different features or different labels. Thisheterophily issue has been extensively studied in homogeneous graphs butremains under-explored in heterogeneous graphs, where there are multiple typesof nodes and edges. Capturing node heterophily in heterogeneous graphs is verychallenging since both node/edge heterogeneity and node heterophily should becarefully taken into consideration. Existing methods typically convertheterogeneous graphs into homogeneous ones to learn node heterophily, whichwill inevitably lose the potential heterophily conveyed by heterogeneousrelations. To bridge this gap, we propose Relation-Aware Separation ofHomophily and Heterophily (RASH), a novel contrastive learning framework thatexplicitly models high-order semantics of heterogeneous interactions andadaptively separates homophilic and heterophilic patterns. Particularly, RASHintroduces dual heterogeneous hypergraphs to encode multi-relational bipartitesubgraphs and dynamically constructs homophilic graphs and heterophilic graphsbased on relation importance. A multi-relation contrastive loss is designed toalign heterogeneous and homophilic/heterophilic views by maximizing mutualinformation. In this way, RASH simultaneously resolves the challenges ofheterogeneity and heterophily in heterogeneous graphs. Extensive experiments onbenchmark datasets demonstrate the effectiveness of RASH across variousdownstream tasks. The code is available at:https://github.com/zhengziyu77/RASH.</description>
      <author>example@mail.com (Ziyu Zheng, Yaming Yang, Ziyu Guan, Wei Zhao, Weigang Lu)</author>
      <guid isPermaLink="false">2506.20980v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision</title>
      <link>http://arxiv.org/abs/2506.20850v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的对比学习框架，用于提升医学视觉领域中的像素级自监督预训练。&lt;h4&gt;背景&lt;/h4&gt;对比学习在自监督预训练中已成为基础模型的关键，但将其扩展到像素级表示在医学视觉中仍是一个未解决的问题。&lt;h4&gt;目的&lt;/h4&gt;解决标准对比学习中过度追求特征分散导致的问题，以及破坏像素级特征相关性和类内分布的问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种向量对比学习（vector CL），将其重新定义为向量回归问题，通过回归位移向量来建模特征距离，以量化像素级预训练中的分散度。&lt;h4&gt;主要发现&lt;/h4&gt;提出的COntrast in VEctor Regression (COVER)框架通过基于向量的自学习、一致的优化流程以及向量金字塔架构来实现这一新范式，从而在自监督预训练中保留了像素级特征相关性。&lt;h4&gt;结论&lt;/h4&gt;在8个跨越2个维度和4个模态的任务上的广泛实验表明，COVER显著提高了像素级自监督预训练，推进了可推广的医学视觉基础模型。&lt;h4&gt;翻译&lt;/h4&gt;Contrastive learning (CL) has become a cornerstone of self-supervised pretraining (SSP) in foundation models, however, extending CL to pixel-wise representation, crucial for medical vision, remains an open problem. Standard CL formulates SSP as a binary optimization problem (binary CL) where the excessive pursuit of feature dispersion leads to an over-dispersion problem, breaking pixel-wise feature correlation thus disrupting the intra-class distribution. Our vector CL reformulates CL as a vector regression problem, enabling dispersion quantification in pixel-wise pretraining via modeling feature distances in regressing displacement vectors. To implement this novel paradigm, we propose the COntrast in VEctor Regression (COVER) framework. COVER establishes an extendable vector-based self-learning, enforces a consistent optimization flow from vector regression to distance modeling, and leverages a vector pyramid architecture for granularity adaptation, thus preserving pixel-wise feature correlations in SSP. Extensive experiments across 8 tasks, spanning 2 dimensions and 4 modalities, show that COVER significantly improves pixel-wise SSP, advancing generalizable medical visual foundation models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Contrastive learning (CL) has become a cornerstone of self-supervisedpretraining (SSP) in foundation models, however, extending CL to pixel-wiserepresentation, crucial for medical vision, remains an open problem. StandardCL formulates SSP as a binary optimization problem (binary CL) where theexcessive pursuit of feature dispersion leads to an over-dispersion problem,breaking pixel-wise feature correlation thus disrupting the intra-classdistribution. Our vector CL reformulates CL as a vector regression problem,enabling dispersion quantification in pixel-wise pretraining via modelingfeature distances in regressing displacement vectors. To implement this novelparadigm, we propose the COntrast in VEctor Regression (COVER) framework. COVERestablishes an extendable vector-based self-learning, enforces a consistentoptimization flow from vector regression to distance modeling, and leverages avector pyramid architecture for granularity adaptation, thus preservingpixel-wise feature correlations in SSP. Extensive experiments across 8 tasks,spanning 2 dimensions and 4 modalities, show that COVER significantly improvespixel-wise SSP, advancing generalizable medical visual foundation models.</description>
      <author>example@mail.com (Yuting He, Shuo Li)</author>
      <guid isPermaLink="false">2506.20850v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable Representation Learning for Additive Rule Ensembles</title>
      <link>http://arxiv.org/abs/2506.20927v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于逻辑命题和可学习稀疏线性变换的规则集成方法，以提高预测模型的可解释性和效率。&lt;h4&gt;背景&lt;/h4&gt;传统的基于简单阈值命题的规则集成方法在可解释性上具有优势，但需要大量的独立输入特征，且当缺乏这些特征时，增加规则数量和复杂性会降低模型的可解释性。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入可学习稀疏线性变换的逻辑命题，扩展经典规则集成方法，以构建更可解释且高效的预测模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于迭代加权的逻辑回归的序列贪婪优化学习方法，用于构建规则集成模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在保持测试风险与最先进方法相当的同时，显著降低了模型在多个基准数据集上的复杂性。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地构建了具有高可解释性和效率的规则集成模型，为预测建模提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Small additive ensembles of symbolic rules offer interpretable predictionmodels. Traditionally, these ensembles use rule conditions based onconjunctions of simple threshold propositions $x \geq t$ on a single inputvariable $x$ and threshold $t$, resulting geometrically in axis-parallelpolytopes as decision regions. While this form ensures a high degree ofinterpretability for individual rules and can be learned efficiently using thegradient boosting approach, it relies on having access to a curated set ofexpressive and ideally independent input features so that a small ensemble ofaxis-parallel regions can describe the target variable well. Absent suchfeatures, reaching sufficient accuracy requires increasing the number andcomplexity of individual rules, which diminishes the interpretability of themodel. Here, we extend classical rule ensembles by introducing logicalpropositions with learnable sparse linear transformations of input variables,i.e., propositions of the form $\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$, where$\mathbf{w}$ is a learnable sparse weight vector, enabling decision regions asgeneral polytopes with oblique faces. We propose a learning method usingsequential greedy optimization based on an iteratively reweighted formulationof logistic regression. Experimental results demonstrate that the proposedmethod efficiently constructs rule ensembles with the same test risk asstate-of-the-art methods while significantly reducing model complexity acrossten benchmark datasets.</description>
      <author>example@mail.com (Shahrzad Behzadimanesh, Pierre Le Bodic, Geoffrey I. Webb, Mario Boley)</author>
      <guid isPermaLink="false">2506.20927v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization</title>
      <link>http://arxiv.org/abs/2506.20841v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FixCLR的半监督领域泛化方法，用于解决在标签稀缺的情况下，如何将模型泛化到分布外数据的问题。&lt;h4&gt;背景&lt;/h4&gt;由于标签稀缺，现有的领域泛化方法往往表现不佳。&lt;h4&gt;目的&lt;/h4&gt;旨在通过引入FixCLR方法，解决现有方法未明确正则化学习领域不变表示的问题。&lt;h4&gt;方法&lt;/h4&gt;FixCLR受到自监督学习的启发，通过改变对比学习的两个关键组件来实现：利用伪标签中的类信息和仅使用排斥项。&lt;h4&gt;主要发现&lt;/h4&gt;FixCLR可以添加到大多数现有的半监督方法和领域泛化方法之上，以实现互补的性能提升。实验表明，FixCLR在多种数据集上均表现出色。&lt;h4&gt;结论&lt;/h4&gt;FixCLR是一种有效的半监督领域泛化方法，尤其与其它半监督方法结合时效果更佳。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Semi-supervised domain generalization (SSDG) aims to solve the problem ofgeneralizing to out-of-distribution data when only a few labels are available.Due to label scarcity, applying domain generalization methods oftenunderperform. Consequently, existing SSDG methods combine semi-supervisedlearning methods with various regularization terms. However, these methods donot explicitly regularize to learn domains invariant representations across alldomains, which is a key goal for domain generalization. To address this, weintroduce FixCLR. Inspired by success in self-supervised learning, we changetwo crucial components to adapt contrastive learning for explicit domaininvariance regularization: utilization of class information from pseudo-labelsand using only a repelling term. FixCLR can also be added on top of mostexisting SSDG and semi-supervised methods for complementary performanceimprovements. Our research includes extensive experiments that have not beenpreviously explored in SSDG studies. These experiments include benchmarkingdifferent improvements to semi-supervised methods, evaluating the performanceof pretrained versus non-pretrained models, and testing on datasets with manydomains. Overall, FixCLR proves to be an effective SSDG method, especially whencombined with other semi-supervised methods.</description>
      <author>example@mail.com (Ha Min Son, Shahbaz Rezaei, Xin Liu)</author>
      <guid isPermaLink="false">2506.20841v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis</title>
      <link>http://arxiv.org/abs/2506.20806v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Poster accepted at the 10th IEEE European Symposium on Security and  Privacy (Euro S&amp;P 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用大型语言模型（LLMs）增强图神经网络（GNNs）鲁棒性和泛化能力的方法，用于网络入侵检测系统（NIDS），尤其是在物联网环境中。&lt;h4&gt;背景&lt;/h4&gt;GNNs在NIDS中具有巨大潜力，但在物联网环境中，由于分布漂移和对抗攻击的脆弱性，其性能会下降。&lt;h4&gt;目的&lt;/h4&gt;提高GNN在NIDS中的鲁棒性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;通过在代理管道中使用LLMs作为模拟网络安全专家代理，审查从网络流量数据中提取的图结构，识别并可能减轻可疑或被对抗性扰动的元素。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，集成LLM分析可以显著提高基于GNN的NIDS的弹性，展示了LLM代理作为入侵检测架构中辅助层的潜力。&lt;h4&gt;结论&lt;/h4&gt;LLMs在增强GNN鲁棒性和泛化能力方面具有潜力，可以作为NIDS中的一种补充层。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) show great promise for Network IntrusionDetection Systems (NIDS), particularly in IoT environments, but sufferperformance degradation due to distribution drift and lack robustness againstrealistic adversarial attacks. Current robustness evaluations often rely onunrealistic synthetic perturbations and lack demonstrations on systematicanalysis of different kinds of adversarial attack, which encompass bothblack-box and white-box scenarios. This work proposes a novel approach toenhance GNN robustness and generalization by employing Large Language Models(LLMs) in an agentic pipeline as simulated cybersecurity expert agents. Theseagents scrutinize graph structures derived from network flow data, identifyingand potentially mitigating suspicious or adversarially perturbed elementsbefore GNN processing. Our experiments, using a framework designed forrealistic evaluation and testing with a variety of adversarial attacksincluding a dataset collected from physical testbed experiments, demonstratethat integrating LLM analysis can significantly improve the resilience ofGNN-based NIDS against challenges, showcasing the potential of LLM agent as acomplementary layer in intrusion detection architectures.</description>
      <author>example@mail.com (Zhonghao Zhan, Huichi Zhou, Hamed Haddadi)</author>
      <guid isPermaLink="false">2506.20806v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>ConViTac: Aligning Visual-Tactile Fusion with Contrastive Representations</title>
      <link>http://arxiv.org/abs/2506.20757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ConViTac的视觉-触觉表示学习网络，用于增强特征融合过程中的特征对齐，并通过对比嵌入条件（CEC）机制提高下游任务的性能。&lt;h4&gt;背景&lt;/h4&gt;视觉和触觉是机器人两种基本的感觉模态，它们提供互补信息，可以增强感知和操作任务。先前的研究尝试联合学习视觉-触觉表示以提取更有意义的信息，但这些方法通常依赖于直接组合，如特征添加和连接，以进行模态融合，这往往导致特征集成不良。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高视觉和触觉融合过程中的特征对齐，从而提升机器人在下游任务中的性能。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一种名为ConViTac的视觉-触觉表示学习网络，该网络使用对比嵌入条件（CEC）机制，通过自监督对比学习预训练的对比编码器将视觉和触觉输入投影到统一的潜在嵌入中。这些嵌入用于通过跨模态注意力耦合视觉-触觉特征融合，旨在对齐统一表示并提高性能。&lt;h4&gt;主要发现&lt;/h4&gt;通过对比嵌入条件（CEC）机制，ConViTac在现实世界中的表现优于当前最先进的方法，并且在材料分类和抓取预测任务中，CEC机制使准确性提高了高达12.0%。&lt;h4&gt;结论&lt;/h4&gt;ConViTac网络通过对比嵌入条件（CEC）机制有效地提高了视觉-触觉特征融合的性能，为机器人在感知和操作任务中提供了更强大的支持。&lt;h4&gt;翻译&lt;/h4&gt;Vision and touch are two fundamental sensory modalities for robots, offering complementary information that enhances perception and manipulation tasks. Previous research has attempted to jointly learn visual-tactile representations to extract more meaningful information. However, these approaches often rely on direct combination, such as feature addition and concatenation, for modality fusion, which tend to result in poor feature integration. In this paper, we propose ConViTac, a visual-tactile representation learning network designed to enhance the alignment of features during fusion using contrastive representations. Our key contribution is a Contrastive Embedding Conditioning (CEC) mechanism that leverages a contrastive encoder pretrained through self-supervised contrastive learning to project visual and tactile inputs into unified latent embeddings. These embeddings are used to couple visual-tactile feature fusion through cross-modal attention, aiming at aligning the unified representations and enhancing performance on downstream tasks. We conduct extensive experiments to demonstrate the superiority of ConViTac in real world over current state-of-the-art methods and the effectiveness of our proposed CEC mechanism, which improves accuracy by up to 12.0% in material classification and grasping prediction tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision and touch are two fundamental sensory modalities for robots, offeringcomplementary information that enhances perception and manipulation tasks.Previous research has attempted to jointly learn visual-tactile representationsto extract more meaningful information. However, these approaches often rely ondirect combination, such as feature addition and concatenation, for modalityfusion, which tend to result in poor feature integration. In this paper, wepropose ConViTac, a visual-tactile representation learning network designed toenhance the alignment of features during fusion using contrastiverepresentations. Our key contribution is a Contrastive Embedding Conditioning(CEC) mechanism that leverages a contrastive encoder pretrained throughself-supervised contrastive learning to project visual and tactile inputs intounified latent embeddings. These embeddings are used to couple visual-tactilefeature fusion through cross-modal attention, aiming at aligning the unifiedrepresentations and enhancing performance on downstream tasks. We conductextensive experiments to demonstrate the superiority of ConViTac in real worldover current state-of-the-art methods and the effectiveness of our proposed CECmechanism, which improves accuracy by up to 12.0% in material classificationand grasping prediction tasks.</description>
      <author>example@mail.com (Zhiyuan Wu, Yongqiang Zhao, Shan Luo)</author>
      <guid isPermaLink="false">2506.20757v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Segment Anything in Pathology Images with Natural Language</title>
      <link>http://arxiv.org/abs/2506.20988v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PathSegmentor是一种针对病理图像设计的文本提示分割基础模型，解决了当前病理图像分割方法在临床应用中面临的挑战。&lt;h4&gt;背景&lt;/h4&gt;病理图像分割对于分析与癌症诊断和预后相关的组织学特征至关重要，但现有方法由于标注数据有限和类别定义受限而面临挑战。&lt;h4&gt;目的&lt;/h4&gt;提出PathSegmentor和PathSeg，以解决病理图像分割中的数据限制和类别定义问题。&lt;h4&gt;方法&lt;/h4&gt;PathSegmentor是一种基于文本提示的分割模型，PathSeg是一个包含275k图像-掩码-标签三元组的数据集，由17个公共来源构建。&lt;h4&gt;主要发现&lt;/h4&gt;PathSegmentor在语义分割任务中表现优于专业模型，具有更高的准确性和更广泛的应用性，同时保持紧凑的架构。它在分割复杂结构和泛化到外部数据集方面表现出强大的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;PathSegmentor的输出通过特征重要性估计和成像生物标志物发现增强了诊断模型的可解释性，为病理学家提供基于证据的临床决策支持，推动了可解释AI在精准肿瘤学的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：病理图像分割在计算病理学中对于分析与癌症诊断和预后相关的组织学特征至关重要。然而，由于有限的标注数据和受限的类别定义，当前的方法在临床应用中面临重大挑战。为了解决这些限制，我们提出了PathSegmentor，这是第一个专门为病理图像设计的文本提示分割基础模型。我们还引入了PathSeg，这是用于病理分割的最大和最全面的数据库，由17个公共来源构建，包含275k图像-掩码-标签三元组，跨越160个不同的类别。使用PathSegmentor，用户可以通过自然语言提示执行语义分割，消除了需要繁琐的空间输入，如点或框。广泛的实验表明，PathSegmentor在准确性和适用性方面优于专业模型，同时保持紧凑的架构。它在分割复杂结构和泛化到外部数据集方面分别比现有的空间和文本提示模型高出0.145和0.429的总体Dice分数，显示出强大的鲁棒性。此外，PathSegmentor的输出通过特征重要性估计和成像生物标志物发现增强了诊断模型的可解释性，为病理学家提供基于证据的临床决策支持。这项工作推动了可解释AI在精准肿瘤学的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology image segmentation is crucial in computational pathology foranalyzing histological features relevant to cancer diagnosis and prognosis.However, current methods face major challenges in clinical applications due tolimited annotated data and restricted category definitions. To address theselimitations, we propose PathSegmentor, the first text-prompted segmentationfoundation model designed specifically for pathology images. We also introducePathSeg , the largest and most comprehensive dataset for pathologysegmentation, built from 17 public sources and containing 275k image-mask-labeltriples across 160 diverse categories. With PathSegmentor, users can performsemantic segmentation using natural language prompts, eliminating the need forlaborious spatial inputs such as points or boxes. Extensive experimentsdemonstrate that PathSegmentor outperforms specialized models with higheraccuracy and broader applicability, while maintaining a compact architecture.It significantly surpasses existing spatial- and text-prompted models by 0.145and 0.429 in overall Dice scores, respectively, showing strong robustness insegmenting complex structures and generalizing to external datasets. Moreover,PathSegmentor's outputs enhance the interpretability of diagnostic modelsthrough feature importance estimation and imaging biomarker discovery, offeringpathologists evidence-based support for clinical decision-making. This workadvances the development of explainable AI in precision oncology.</description>
      <author>example@mail.com (Zhixuan Chen, Junlin Hou, Liqi Lin, Yihui Wang, Yequan Bie, Xi Wang, Yanning Zhou, Ronald Cheong Kin Chan, Hao Chen)</author>
      <guid isPermaLink="false">2506.20988v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model</title>
      <link>http://arxiv.org/abs/2506.20923v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report; 26 pages 12 tables 1 figure. arXiv admin note:  substantial text overlap with arXiv:2501.01028&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一个名为KaLM-Embedding-V2的多功能紧凑型嵌入模型，在通用文本嵌入任务中表现出色，这得益于卓越的训练技术和数据。&lt;h4&gt;背景&lt;/h4&gt;为了在文本嵌入任务中取得更好的表现，研究人员开发了新的嵌入模型。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够高效处理通用文本嵌入任务的嵌入模型。&lt;h4&gt;方法&lt;/h4&gt;1) 修改架构以更好地与表示学习对齐，采用全双向变换器和均值池化来产生固定长度的嵌入。2) 实施多阶段训练流程：在大型弱监督开源语料库上预训练，在高质量检索和非检索数据集上微调，以及模型支持参数平均以实现鲁棒泛化。3) 引入聚焦样式的重加权机制和在线困难负样本混合策略。4) 收集超过20种数据类别进行预训练和100种数据类别进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;在MTEB（大规模文本嵌入基准）的中文和英语评估中，KaLM-Embedding-V2模型显著优于同类大小的其他模型，并能与参数量大的模型相媲美，为具有小于1B参数的多功能紧凑型嵌入模型树立了新标准。&lt;h4&gt;结论&lt;/h4&gt;KaLM-Embedding-V2模型在通用文本嵌入任务中表现出色，为紧凑型嵌入模型提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在这篇论文中，我们提出了KaLM-Embedding-V2，一种通用且紧凑的嵌入模型。通过利用优越的训练技术和数据，它在通用文本嵌入任务中取得了令人印象深刻的性能。我们的关键创新包括：（1）为了更好地将架构与表示学习对齐，我们去掉了因果注意力掩码，并采用了一个简单但有效的全双向变换器和均值池化来生成固定长度的嵌入；（2）我们采用了一个多阶段训练流程：（i）在大型弱监督开源语料库上预训练；（ii）在高质量检索和非检索数据集上微调；（iii）通过模型支持参数平均来实现鲁棒的泛化。此外，我们引入了一种聚焦样式的重加权机制，该机制将学习集中在困难样本上，以及一个在线困难负样本混合策略，以连续丰富困难负样本而不需要进行昂贵的离线挖掘；（3）我们收集了超过20种数据类别用于预训练和100种数据类别用于微调，以提升嵌入模型的性能和泛化能力。在MTEB（大规模文本嵌入基准）的中文和英语评估中，我们的模型显著优于其他同类大小的模型，并能与3x、14x、18x和26x更大的嵌入模型相媲美，为具有小于1B参数的多功能紧凑型嵌入模型设定了新的标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, we propose KaLM-Embedding-V2, a versatile and compactembedding model, which achieves impressive performance in general-purpose textembedding tasks by leveraging superior training techniques and data. Our keyinnovations include: (1) To better align the architecture with representationlearning, we remove the causal attention mask and adopt a fully bidirectionaltransformer with simple yet effective mean-pooling to produce fixed-lengthembeddings; (2) We employ a multi-stage training pipeline: (i) pre-training onlarge-scale weakly supervised open-source corpora; (ii) fine-tuning onhigh-quality retrieval and non-retrieval datasets; and (iii) model-soupparameter averaging for robust generalization. Besides, we introduce afocal-style reweighting mechanism that concentrates learning on difficultsamples and an online hard-negative mixing strategy to continuously enrich hardnegatives without expensive offline mining; (3) We collect over 20 categoriesof data for pre-training and 100 categories of data for fine-tuning, to boostboth the performance and generalization of the embedding model. Extensiveevaluations on the Massive Text Embedding Benchmark (MTEB) Chinese and Englishshow that our model significantly outperforms others of comparable size, andcompetes with 3x, 14x, 18x, and 26x larger embedding models, setting a newstandard for a versatile and compact embedding model with less than 1Bparameters.</description>
      <author>example@mail.com (Xinping Zhao, Xinshuo Hu, Zifei Shan, Shouzheng Huang, Yao Zhou, Zetian Sun, Zhenyu Liu, Dongfang Li, Xinyuan Wei, Qian Chen, Youcheng Pan, Yang Xiang, Meishan Zhang, Haofen Wang, Jun Yu, Baotian Hu, Min Zhang)</author>
      <guid isPermaLink="false">2506.20923v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>scMamba: A Scalable Foundation Model for Single-Cell Multi-Omics Integration Beyond Highly Variable Feature Selection</title>
      <link>http://arxiv.org/abs/2506.20697v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;scMamba是一种用于整合单细胞多组学数据的基础模型，能够在不进行预先特征选择的情况下，同时保留基因组位置信息。&lt;h4&gt;背景&lt;/h4&gt;单细胞多组学技术的出现使得在单个细胞中同时分析多种组学层提供了前所未有的见解。然而，现有的方法在预处理阶段通常依赖于选择高度可变的基因或峰，这可能会无意中丢弃重要的生物学信息。&lt;h4&gt;目的&lt;/h4&gt;开发一个不需要预先特征选择的模型来整合单细胞多组学数据，同时保留基因组位置信息。&lt;h4&gt;方法&lt;/h4&gt;scMamba采用基于补丁的细胞标记化策略，将基因组区域视为单词（标记），细胞视为句子。它基于状态空间二重性的概念，从高维、稀疏的单细胞多组学数据中提取丰富的生物学见解。此外，它引入了一种新的对比学习方法，并辅以余弦相似性正则化，使跨组学层的对齐优于传统方法。&lt;h4&gt;主要发现&lt;/h4&gt;scMamba在保留生物学变异、对齐组学层以及增强关键下游任务（如聚类、细胞类型注释和轨迹推理）方面显著优于最先进的方法。系统基准测试表明，scMamba在处理大规模图谱和推进生物学发现方面是一种强大的工具。&lt;h4&gt;结论&lt;/h4&gt;scMamba是一种强大的工具，可以用于大规模单细胞多组学整合，能够处理大规模图谱并推进生物学发现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of single-cell multi-omics technologies has enabled thesimultaneous profiling of diverse omics layers within individual cells.Integrating such multimodal data provides unprecedented insights into cellularidentity, regulatory processes, and disease mechanisms. However, it remainschallenging, as current methods often rely on selecting highly variable genesor peaks during preprocessing, which may inadvertently discard crucialbiological information. Here, we present scMamba, a foundation model designedto integrate single-cell multi-omics data without the need for prior featureselection while preserving genomic positional information. scMamba introduces apatch-based cell tokenization strategy that treats genomics regions as words(tokens) and cells as sentences. Building upon the concept of state spaceduality, scMamba distills rich biological insights from high-dimensional,sparse single-cell multi-omics data. Additionally, our novel contrastivelearning approach, enhanced with cosine similarity regularization, enablessuperior alignment across omics layers compared to traditional methods.Systematic benchmarking across multiple datasets demonstrates that scMambasignificantly outperforms state-of-the-art methods in preserving biologicalvariation, aligning omics layers, and enhancing key downstream tasks such asclustering, cell type annotation, and trajectory inference. Our findingsposition scMamba as a powerful tool for large-scale single-cell multi-omicsintegration, capable of handling large-scale atlases and advancing biologicaldiscovery.</description>
      <author>example@mail.com (Zhen Yuan, Shaoqing Jiao, Yihang Xiao, Jiajie Peng)</author>
      <guid isPermaLink="false">2506.20697v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Point Cloud Environment-Based Channel Knowledge Map Construction</title>
      <link>http://arxiv.org/abs/2506.21112v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于模型和数据驱动的Channel knowledge map (CKM)构建方法，通过利用点云环境数据和少量位置标记的信道信息，提高CKM的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的CKM构建方案采用过于简化的环境信息，这显著降低了其准确性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来构建CKM，以减少频繁的信道状态信息（CSI）获取的开销，并提高CKM的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出一种新的点选择器，通过构建基于不同到达时间（ToA）的共焦点椭球体，识别包含与多径信道增益相关的环境信息的点云子集。2. 训练一个神经信道增益估计器，通过使用我们通过现场测量收集的包含环境点云和相应信道数据的真实世界数据集，学习每个选定子集与其对应信道增益之间的映射。&lt;h4&gt;主要发现&lt;/h4&gt;1. 对于功率延迟剖面（PDP）的CKM构建，该方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法的7.32 dB。2. 对于接收功率值（即无线电地图）的CKM构建，该方法实现了1.04 dB的RMSE，超过了Kriging插值方法的1.68 dB。&lt;h4&gt;结论&lt;/h4&gt;该方法在CKM构建中表现出色，能够显著提高CKM的准确性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：Channel知识地图（CKM）为感兴趣区域提供一定级别的信道状态信息（CSI），通过减少频繁CSI获取的开销，成为环境感知通信的关键推动者。然而，现有的CKM构建方案采用过于简化的环境信息，这显著降低了它们的准确性。为了解决这个问题，本研究提出了一种联合模型和数据驱动的方法来构建CKM，通过利用点云环境数据以及少量位置标记的信道信息。首先，我们提出了一种新的点选择器，通过构建基于不同到达时间（ToA）的共焦点椭球体，识别包含与多径信道增益相关的环境信息的点云子集。然后，我们训练了一个神经信道增益估计器，通过使用我们通过现场测量收集的包含环境点云和相应信道数据的真实世界数据集，学习每个选定子集与其对应信道增益之间的映射。最后，实验结果表明：对于功率延迟剖面（PDP）的CKM构建，所提出的方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法的7.32 dB；对于接收功率值（即无线电地图）的CKM构建，该方法实现了1.04 dB的RMSE，超过了Kriging插值方法的1.68 dB。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Channel knowledge map (CKM) provides certain levels of channel stateinformation (CSI) for an area of interest, serving as a critical enabler forenvironment-aware communications by reducing the overhead of frequent CSIacquisition. However, existing CKM construction schemes adopt over-simplifiedenvironment information, which significantly compromises their accuracy. Toaddress this issue, this work proposes a joint model- and data-driven approachto construct CKM by leveraging point cloud environmental data along with a fewsamples of location-tagged channel information. First, we propose a novel pointselector to identify subsets of point cloud that contain environmentalinformation relevant to multipath channel gains, by constructing a set ofco-focal ellipsoids based on different time of arrival (ToAs). Then, we traineda neural channel gain estimator to learn the mapping between each selectedsubset and its corresponding channel gain, using a real-world dataset wecollected through field measurements, comprising environmental point clouds andcorresponding channel data. Finally, experimental results demonstrate that: ForCKM construction of power delay profile (PDP), the proposed method achieves aroot mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dBachieved by the conventional ray-tracing method; for CKM construction ofreceived power values, i.e., radio map, it achieves an RMSE of 1.04 dB,surpassing the Kriging interpolation method with an RMSE of 1.68 dB.</description>
      <author>example@mail.com (Yancheng Wang, Wei Guo, Guanying Chen, Ye Zhang, Shuguang Cui)</author>
      <guid isPermaLink="false">2506.21112v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends</title>
      <link>http://arxiv.org/abs/2506.20966v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了视觉语言动作（VLA）模型的后训练策略，从人类运动学习角度出发，重点关注环境、实体和任务三个维度，提出了一个与人类学习机制相一致的结构化分类法。&lt;h4&gt;背景&lt;/h4&gt;VLA模型通过集成动作生成模块扩展了视觉语言模型（VLM），在多样化操作任务中展现出良好的泛化能力。然而，对于需要高精度和准确性的应用，VLA模型在未经进一步适应的情况下存在性能差距。&lt;h4&gt;目的&lt;/h4&gt;旨在通过后训练策略提高VLA模型与特定任务环境交互的能力，类似于人类运动技能的习得过程。&lt;h4&gt;方法&lt;/h4&gt;本文通过类比人类运动学习，从环境感知、实体意识、任务理解和多组件集成四个方面，对VLA模型的后训练策略进行了综述。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，后训练VLA模型的关键挑战和趋势包括环境感知增强、实体意识提升、任务理解深化以及多组件集成。&lt;h4&gt;结论&lt;/h4&gt;本文建立了指导未来研究的概念框架，提供了对当前VLA模型后训练方法的全面概述，并为VLA模型的发展提供了实际见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper reviews the post-training strategies for VLA models from the perspective of human motor learning, focusing on three dimensions: environments, embodiments, and tasks. A structured taxonomy is introduced aligned with human learning mechanisms: (1) enhancing environmental perception, (2) improving embodiment awareness, (3) deepening task comprehension, and (4) multi-component integration. Finally, key challenges and trends in post-training VLA models are identified, establishing a conceptual framework to guide future research. This work delivers both a comprehensive overview of current VLA model post-training methods from a human motor learning perspective and practical insights for VLA model development.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-language-action (VLA) models extend vision-language models (VLM) byintegrating action generation modules for robotic manipulation. Leveragingstrengths of VLM in vision perception and instruction understanding, VLA modelsexhibit promising generalization across diverse manipulation tasks. However,applications demanding high precision and accuracy reveal performance gapswithout further adaptation. Evidence from multiple domains highlights thecritical role of post-training to align foundational models with downstreamapplications, spurring extensive research on post-training VLA models. VLAmodel post-training aims to address the challenge of improving an embodiment'sability to interact with the environment for the given tasks, analogous to theprocess of humans motor skills acquisition. Accordingly, this paper reviewspost-training strategies for VLA models through the lens of human motorlearning, focusing on three dimensions: environments, embodiments, and tasks. Astructured taxonomy is introduced aligned with human learning mechanisms: (1)enhancing environmental perception, (2) improving embodiment awareness, (3)deepening task comprehension, and (4) multi-component integration. Finally, keychallenges and trends in post-training VLA models are identified, establishinga conceptual framework to guide future research. This work delivers both acomprehensive overview of current VLA model post-training methods from a humanmotor learning perspective and practical insights for VLA model development.(Project website: https://github.com/AoqunJin/Awesome-VLA-Post-Training)</description>
      <author>example@mail.com (Tian-Yu Xiang, Ao-Qun Jin, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Sheng-Bin Duan, Fu-Chao Xie, Wen-Kai Wang, Si-Cheng Wang, Ling-Yun Li, Tian Tu, Zeng-Guang Hou)</author>
      <guid isPermaLink="false">2506.20966v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization</title>
      <link>http://arxiv.org/abs/2506.20807v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  4 page paper plus Appendices. Accepted to the ES-FoMo "Efficient  Systems for Foundation Models" workshop at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于大型语言模型（LLM）的自动化方法，用于迭代优化GPU内核，以应对针对新或文档不足的GPU架构的挑战。&lt;h4&gt;背景&lt;/h4&gt;优化GPU内核以实现高性能是一个复杂的任务，通常需要深入的架构知识、广泛的性能分析和迭代实验。在针对较新或文档较少的GPU架构时，这一挑战更加明显，因为传统开发工具资源有限。&lt;h4&gt;目的&lt;/h4&gt;开发一种自动化方法，以迭代优化加速器内核，特别是针对资源受限或硬件快速发展的环境。&lt;h4&gt;方法&lt;/h4&gt;该方法采用LLM进行多阶段的进化过程：首先战略性地选择有希望的先前代码版本作为新迭代的起点；其次，基于现有代码和从通用GPU文献中获取的知识生成优化实验的假设；最后，通过代码修改和将实验提交给外部评估系统来自动执行这些实验，仅使用观察到的计时数据作为性能反馈。&lt;h4&gt;主要发现&lt;/h4&gt;详细介绍了该方法如何应对AMD MI300目标架构的挑战，并利用LLM来弥补特定领域人类专业知识的不足。&lt;h4&gt;结论&lt;/h4&gt;由于论文提交日期时，性能竞赛的定量结果被限制，因此本文展示了架构设计、操作工作流程和定性见解，突出了LLM驱动代理在民主化和加速GPU内核优化方面的潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文介绍了一种基于大型语言模型（LLM）的自动化方法，用于迭代优化GPU内核，以应对针对新或文档不足的GPU架构的挑战。该方法采用LLM进行多阶段的进化过程，首先选择有希望的先前代码版本作为新迭代的起点，然后基于现有代码和从通用GPU文献中获取的知识生成优化实验的假设，最后通过代码修改和将实验提交给外部评估系统来自动执行这些实验，仅使用观察到的计时数据作为性能反馈。详细介绍了该方法如何应对AMD MI300目标架构的挑战，并利用LLM来弥补特定领域人类专业知识的不足。由于论文提交日期时，性能竞赛的定量结果被限制，因此本文展示了架构设计、操作工作流程和定性见解，突出了LLM驱动代理在民主化和加速GPU内核优化方面的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Optimizing GPU kernels for high performance is a complex task, oftendemanding deep architectural knowledge, extensive profiling, and iterativeexperimentation. This challenge is amplified when targeting newer orless-documented GPU architectures where traditional development aids arescarce. This paper introduces an LLM-powered "GPU Kernel Scientist," anautomated methodology for iteratively refining accelerator kernels.  Our methodology employs LLMs in a multi-stage, evolutionary process: (a)strategically selecting promising prior code versions as a basis for newiterations; (b) generating hypotheses for optimization experiments, based onexisting code and assimilated knowledge from general GPU literature; and (c)autonomously implementing these experiments through code modification andsubsequent submission to an external evaluation system, using only observedtiming data as performance feedback. We detail how this approach navigates thechallenges of the AMD MI300 target architecture and leverages LLMs tocompensate for limited domain-specific human expertise.  Since quantitative results from an ongoing performance competition wereembargoed on paper submission date, we present the architectural design,operational workflow, and qualitative insights, highlighting the potential ofLLM-driven agents to democratise and accelerate GPU kernel optimization,especially in resource-constrained or rapidly evolving hardware environments.</description>
      <author>example@mail.com (Martin Andrews, Sam Witteveen)</author>
      <guid isPermaLink="false">2506.20807v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG</title>
      <link>http://arxiv.org/abs/2506.20683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  accepted to MICCAI 2025 (Springer LNCS)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PTACL的多模态对比学习框架，通过整合来自心脏磁共振（CMR）的空间时间信息来增强心电图（ECG）的表现，以改善非侵入性心脏诊断。&lt;h4&gt;背景&lt;/h4&gt;心电图是一种常用的检测心脏电异常的工具，但无法直接测量功能参数，如心室容积和射血分数。心脏磁共振是这些测量的金标准，但成本高且不易获得。&lt;h4&gt;目的&lt;/h4&gt;为了弥合这一差距，提出了一种名为PTACL的多模态对比学习框架，以提高ECG表现。&lt;h4&gt;方法&lt;/h4&gt;PTACL使用全局患者级对比损失和局部时间级对比损失。全局损失通过拉近同一患者的ECG和CMR嵌入，推开不同患者的嵌入来对齐患者级表示。局部损失通过对比编码的ECG段与相应的编码CMR帧来强制执行每个患者内的细粒度时间对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在来自英国生物库的27,951个受试者的配对ECG-CMR数据上评估PTACL。与基线方法相比，PTACL在两个临床相关任务中取得了更好的性能：(1)检索具有相似心脏表型的患者和(2)预测由CMR得出的心脏功能参数，如心室容积和射血分数。&lt;h4&gt;结论&lt;/h4&gt;PTACL有望增强使用ECG的非侵入性心脏诊断。&lt;h4&gt;翻译&lt;/h4&gt;An electrocardiogram (ECG) is a widely used, cost-effective tool for detecting electrical abnormalities in the heart. However, it cannot directly measure functional parameters, such as ventricular volumes and ejection fraction, which are crucial for assessing cardiac function. Cardiac magnetic resonance (CMR) is the gold standard for these measurements, providing detailed structural and functional insights, but is expensive and less accessible. To bridge this gap, we propose PTACL (Patient and Temporal Alignment Contrastive Learning), a multimodal contrastive learning framework that enhances ECG representations by integrating spatio-temporal information from CMR. PTACL uses global patient-level contrastive loss and local temporal-level contrastive loss. The global loss aligns patient-level representations by pulling ECG and CMR embeddings from the same patient closer together, while pushing apart embeddings from different patients. Local loss enforces fine-grained temporal alignment within each patient by contrasting encoded ECG segments with corresponding encoded CMR frames. This approach enriches ECG representations with diagnostic information beyond electrical activity and transfers more insights between modalities than global alignment alone, all without introducing new learnable weights. We evaluate PTACL on paired ECG-CMR data from 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACL achieves better performance in two clinically relevant tasks: (1) retrieving patients with similar cardiac phenotypes and (2) predicting CMR-derived cardiac function parameters, such as ventricular volumes and ejection fraction. Our results highlight the potential of PTACL to enhance non-invasive cardiac diagnostics using ECG. The code is available at: https://github.com/alsalivan/ecgcmr&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; An electrocardiogram (ECG) is a widely used, cost-effective tool fordetecting electrical abnormalities in the heart. However, it cannot directlymeasure functional parameters, such as ventricular volumes and ejectionfraction, which are crucial for assessing cardiac function. Cardiac magneticresonance (CMR) is the gold standard for these measurements, providing detailedstructural and functional insights, but is expensive and less accessible. Tobridge this gap, we propose PTACL (Patient and Temporal Alignment ContrastiveLearning), a multimodal contrastive learning framework that enhances ECGrepresentations by integrating spatio-temporal information from CMR. PTACL usesglobal patient-level contrastive loss and local temporal-level contrastiveloss. The global loss aligns patient-level representations by pulling ECG andCMR embeddings from the same patient closer together, while pushing apartembeddings from different patients. Local loss enforces fine-grained temporalalignment within each patient by contrasting encoded ECG segments withcorresponding encoded CMR frames. This approach enriches ECG representationswith diagnostic information beyond electrical activity and transfers moreinsights between modalities than global alignment alone, all withoutintroducing new learnable weights. We evaluate PTACL on paired ECG-CMR datafrom 27,951 subjects in the UK Biobank. Compared to baseline approaches, PTACLachieves better performance in two clinically relevant tasks: (1) retrievingpatients with similar cardiac phenotypes and (2) predicting CMR-derived cardiacfunction parameters, such as ventricular volumes and ejection fraction. Ourresults highlight the potential of PTACL to enhance non-invasive cardiacdiagnostics using ECG. The code is available at:https://github.com/alsalivan/ecgcmr</description>
      <author>example@mail.com (Alexander Selivanov, Philip Müller, Özgün Turgut, Nil Stolt-Ansó, Daniel Rückert)</author>
      <guid isPermaLink="false">2506.20683v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>CURL-SLAM: Continuous and Compact LiDAR Mapping</title>
      <link>http://arxiv.org/abs/2506.21077v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了3D激光雷达制图，重点开发了一种可更新和可定位的地图表示方法，该方法能够确保3D地图的连续性、紧凑性和一致性。&lt;h4&gt;背景&lt;/h4&gt;传统的激光雷达同步定位与建图（SLAM）系统通常依赖于3D点云地图，这在大规模环境中通常需要大量存储空间来保留结构细节。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于连续和超紧凑表示的激光雷达（CURL）的新颖SLAM范式，以实现紧凑的3D地图，并确保在闭环后全局地图的一致性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为CURL-SLAM的激光雷达制图方法，它利用CURL的球谐隐式编码产生紧凑的3D地图，并在不同密度下实现连续重建。CURL-SLAM将激光雷达位姿估计作为针对CURL的独特优化问题进行公理化，并将其扩展到局部捆绑调整（BA），以实现位姿和地图的同时优化。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，CURL-SLAM实现了最先进的3D制图质量，并具有竞争力的激光雷达轨迹精度，在CPU上实现了传感器速率的实时性能（10 Hz）。&lt;h4&gt;结论&lt;/h4&gt;CURL-SLAM将被开源社区发布。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了3D激光雷达制图，重点关注开发一种可更新和可定位的地图表示方法，该方法能够确保3D地图的连续性、紧凑性和一致性。传统的激光雷达同步定位与建图（SLAM）系统通常依赖于3D点云地图，这在大规模环境中通常需要大量存储空间来保留结构细节。在本文中，我们通过利用[1]中提出的连续和超紧凑表示的激光雷达（CURL）范式，提出了一种新颖的激光雷达SLAM范式。我们提出的激光雷达制图方法，CURL-SLAM，通过CURL的球谐隐式编码产生紧凑的3D地图，能够在不同密度下实现连续重建，并在闭环后实现全局地图的一致性。与基于迭代最近点（ICP）的激光雷达测距技术不同，CURL-SLAM将激光雷达位姿估计作为针对CURL的独特优化问题进行公理化，并将其扩展到局部捆绑调整（BA），以实现位姿和地图的同时优化。实验结果表明，CURL-SLAM实现了最先进的3D制图质量，并具有竞争力的激光雷达轨迹精度，在CPU上实现了传感器速率的实时性能（10 Hz）。我们将在社区中发布CURL-SLAM的实现。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-26&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper studies 3D LiDAR mapping with a focus on developing an updatableand localizable map representation that enables continuity, compactness andconsistency in 3D maps. Traditional LiDAR Simultaneous Localization and Mapping(SLAM) systems often rely on 3D point cloud maps, which typically requireextensive storage to preserve structural details in large-scale environments.In this paper, we propose a novel paradigm for LiDAR SLAM by leveraging theContinuous and Ultra-compact Representation of LiDAR (CURL) introduced in [1].Our proposed LiDAR mapping approach, CURL-SLAM, produces compact 3D mapscapable of continuous reconstruction at variable densities using CURL'sspherical harmonics implicit encoding, and achieves global map consistencyafter loop closure. Unlike popular Iterative Closest Point (ICP)-based LiDARodometry techniques, CURL-SLAM formulates LiDAR pose estimation as a uniqueoptimization problem tailored for CURL and extends it to local BundleAdjustment (BA), enabling simultaneous pose refinement and map correction.Experimental results demonstrate that CURL-SLAM achieves state-of-the-art 3Dmapping quality and competitive LiDAR trajectory accuracy, deliveringsensor-rate real-time performance (10 Hz) on a CPU. We will release theCURL-SLAM implementation to the community.</description>
      <author>example@mail.com (Kaicheng Zhang, Shida Xu, Yining Ding, Xianwen Kong, Sen Wang)</author>
      <guid isPermaLink="false">2506.21077v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?</title>
      <link>http://arxiv.org/abs/2506.20795v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了将Vision Foundation Models (VFMs) 和Vision Language Models (VLMs) 应用于动态全身手势识别，并评估了不同手势识别方法的性能。&lt;h4&gt;背景&lt;/h4&gt;手势在嘈杂环境中的人机非语言交流中非常重要，传统的手势识别依赖于特定的深度学习架构。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用VFMs和VLMs的泛化能力来减少系统复杂性，并通过比较不同的模型来评估其性能。&lt;h4&gt;方法&lt;/h4&gt;引入了NUGGET数据集，用于评估不同手势识别方法；比较了V-JEPA、Gemini Flash 2.0和HD-GCN三种模型。&lt;h4&gt;主要发现&lt;/h4&gt;HD-GCN在实验中表现最佳，V-JEPA通过简单的任务特定分类头接近最佳性能；Gemini在零样本设置下难以仅根据文本描述区分手势。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，通过使用V-JEPA作为共享的多任务模型，有可能减少系统复杂性，并指出需要进一步研究手势的合适输入表示方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Gestures enable non-verbal human-robot communication, especially in noisyenvironments like agile production. Traditional deep learning-based gesturerecognition relies on task-specific architectures using images, videos, orskeletal pose estimates as input. Meanwhile, Vision Foundation Models (VFMs)and Vision Language Models (VLMs) with their strong generalization abilitiesoffer potential to reduce system complexity by replacing dedicatedtask-specific modules. This study investigates adapting such models fordynamic, full-body gesture recognition, comparing V-JEPA (a state-of-the-artVFM), Gemini Flash 2.0 (a multimodal VLM), and HD-GCN (a top-performingskeleton-based approach). We introduce NUGGET, a dataset tailored forhuman-robot communication in intralogistics environments, to evaluate thedifferent gesture recognition approaches. In our experiments, HD-GCN achievesbest performance, but V-JEPA comes close with a simple, task-specificclassification head - thus paving a possible way towards reducing systemcomplexity, by using it as a shared multi-task model. In contrast, Geministruggles to differentiate gestures based solely on textual descriptions in thezero-shot setting, highlighting the need of further research on suitable inputrepresentations for gestures.</description>
      <author>example@mail.com (Stephanie Käs, Anton Burenko, Louis Markert, Onur Alp Culha, Dennis Mack, Timm Linder, Bastian Leibe)</author>
      <guid isPermaLink="false">2506.20795v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools</title>
      <link>http://arxiv.org/abs/2506.20743v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了基础模型（FMs）在材料科学（MatSci）中的应用，探讨了其在科学发现中的作用，以及支持这一领域的系统、数据集和计算工具。&lt;h4&gt;背景&lt;/h4&gt;基础模型正在推动材料科学领域的变革，它们能够实现可扩展、通用和多模态的人工智能系统，与传统的机器学习模型相比，具有跨领域的泛化能力和涌现能力。&lt;h4&gt;目的&lt;/h4&gt;提供对基础模型、代理系统、数据集和计算工具的全面概述，并评估其在材料科学中的应用。&lt;h4&gt;方法&lt;/h4&gt;介绍了一个涵盖六个主要应用领域的任务驱动分类法，包括数据提取、解释和问答；原子模拟；性质预测；材料结构、设计和发现；工艺规划、发现和优化；以及多尺度建模。讨论了单模态和多模态基础模型的最新进展，以及新兴的大型语言模型（LLM）代理。此外，还回顾了标准化数据集、开源工具和自主实验平台。&lt;h4&gt;主要发现&lt;/h4&gt;评估了基础模型的早期成功，并确定了持续的局限性，包括泛化性、可解释性、数据不平衡、安全问题和多模态融合的局限性。&lt;h4&gt;结论&lt;/h4&gt;提出了以可扩展预训练、持续学习、数据治理和可信度为中心的未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;本文综述了基础模型在材料科学中的应用，探讨了其在科学发现中的作用，以及支持这一领域的系统、数据集和计算工具。基础模型正在推动材料科学领域的变革，它们能够实现可扩展、通用和多模态的人工智能系统，与传统的机器学习模型相比，具有跨领域的泛化能力和涌现能力。本文提供对基础模型、代理系统、数据集和计算工具的全面概述，并评估其在材料科学中的应用。介绍了一个涵盖六个主要应用领域的任务驱动分类法，包括数据提取、解释和问答；原子模拟；性质预测；材料结构、设计和发现；工艺规划、发现和优化；以及多尺度建模。讨论了单模态和多模态基础模型的最新进展，以及新兴的大型语言模型（LLM）代理。此外，还回顾了标准化数据集、开源工具和自主实验平台。评估了基础模型的早期成功，并确定了持续的局限性，包括泛化性、可解释性、数据不平衡、安全问题和多模态融合的局限性。提出了以可扩展预训练、持续学习、数据治理和可信度为中心的未来研究方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs) are catalyzing a transformative shift in materialsscience (MatSci) by enabling scalable, general-purpose, and multimodal AIsystems for scientific discovery. Unlike traditional machine learning models,which are typically narrow in scope and require task-specific engineering, FMsoffer cross-domain generalization and exhibit emergent capabilities. Theirversatility is especially well-suited to materials science, where researchchallenges span diverse data types and scales. This survey provides acomprehensive overview of foundation models, agentic systems, datasets, andcomputational tools supporting this growing field. We introduce a task-driventaxonomy encompassing six broad application areas: data extraction,interpretation and Q\&amp;A; atomistic simulation; property prediction; materialsstructure, design and discovery; process planning, discovery, and optimization;and multiscale modeling. We discuss recent advances in both unimodal andmultimodal FMs, as well as emerging large language model (LLM) agents.Furthermore, we review standardized datasets, open-source tools, and autonomousexperimental platforms that collectively fuel the development and integrationof FMs into research workflows. We assess the early successes of foundationmodels and identify persistent limitations, including challenges ingeneralizability, interpretability, data imbalance, safety concerns, andlimited multimodal fusion. Finally, we articulate future research directionscentered on scalable pretraining, continual learning, data governance, andtrustworthiness.</description>
      <author>example@mail.com (Minh-Hao Van, Prateek Verma, Chen Zhao, Xintao Wu)</author>
      <guid isPermaLink="false">2506.20743v1</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>These Are Not All the Features You Are Looking For: A Fundamental Bottleneck in Supervised Pretraining</title>
      <link>http://arxiv.org/abs/2506.18221v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures, Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了迁移学习在机器学习中的关键作用，特别是在使用少量新数据适应新任务时的应用。研究发现了深度学习模型中的一个基本限制，即“信息饱和瓶颈”，并提出了更丰富的特征表示作为潜在解决方案。&lt;h4&gt;背景&lt;/h4&gt;迁移学习是现代机器学习的基础，它允许将在大批量数据上预训练的模型适应新的任务，但确保迁移特征足以处理未见数据集是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;评估从预训练混合模型到其各个组件任务的模型迁移，并确定预训练特征是否能达到特定任务直接训练的性能。&lt;h4&gt;方法&lt;/h4&gt;研究通过评估预训练特征在处理未见数据集时的表现，来识别深度学习模型中的信息饱和瓶颈。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，当网络在训练过程中编码了相似的特征后，它们将无法学习新的特征。此外，这种信息饱和现象在深度学习架构中普遍存在。&lt;h4&gt;结论&lt;/h4&gt;研究建议，当可用时，关注特定任务的训练可能比依赖大规模网络更有效。并提出了一种新的方法来改进新数据集的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习是现代机器学习的基础，它承诺了一种方法，即通过最小的新数据量将在大批量数据上预训练的模型适应到新任务中。然而，确保迁移特征足以处理未见数据集仍然是一个重大挑战，这种挑战因量化两个任务是否“相关”的困难而加剧。为了解决这些挑战，我们评估了从预训练混合模型到其各个组件任务的模型迁移，评估预训练特征是否能匹配特定任务直接训练的性能。我们确定了深度学习模型中的一个基本限制——“信息饱和瓶颈”，其中网络在训练过程中编码了相似的特征后无法学习新的特征。当限制在预训练期间仅学习关键特征子集时，模型将永久失去迁移的临界特征，在数据分布上表现不一致，甚至在训练混合的组成部分上也是如此。来自已发表研究的经验证据表明，这种现象在深度学习架构中普遍存在——数据分布或排序等因素会影响当前表示学习方法随时间学习到的特征。本研究表明，当可用时，仅依赖大规模网络可能不如关注特定任务的训练有效。我们提出了更丰富的特征表示作为潜在解决方案，以更好地泛化到新数据集，并具体介绍了现有方法以及一种新颖的方法，这是解决这一挑战的初步步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is a cornerstone of modern machine learning, promising away to adapt models pretrained on a broad mix of data to new tasks with minimalnew data. However, a significant challenge remains in ensuring that transferredfeatures are sufficient to handle unseen datasets, amplified by the difficultyof quantifying whether two tasks are "related". To address these challenges, weevaluate model transfer from a pretraining mixture to each of its componenttasks, assessing whether pretrained features can match the performance oftask-specific direct training. We identify a fundamental limitation in deeplearning models -- an "information saturation bottleneck" -- where networksfail to learn new features once they encode similar competing features duringtraining. When restricted to learning only a subset of key features duringpretraining, models will permanently lose critical features for transfer andperform inconsistently on data distributions, even components of the trainingmixture. Empirical evidence from published studies suggests that thisphenomenon is pervasive in deep learning architectures -- factors such as datadistribution or ordering affect the features that current representationlearning methods can learn over time. This study suggests that relying solelyon large-scale networks may not be as effective as focusing on task-specifictraining, when available. We propose richer feature representations as apotential solution to better generalize across new datasets and, specifically,present existing methods alongside a novel approach, the initial steps towardsaddressing this challenge.</description>
      <author>example@mail.com (Xingyu Alice Yang, Jianyu Zhang, Léon Bottou)</author>
      <guid isPermaLink="false">2506.18221v2</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>From Memories to Maps: Mechanisms of In-Context Reinforcement Learning in Transformers</title>
      <link>http://arxiv.org/abs/2506.19686v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Updates: added other funding sources; formatted title correctly&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究探讨了人类和动物的学习效率，以及Transformer在模拟情境下强化学习中的应用。&lt;h4&gt;背景&lt;/h4&gt;人类和动物能够以最小的经验适应新环境，但这种能力在标准的强化学习算法中并未得到充分体现。&lt;h4&gt;目的&lt;/h4&gt;研究目的是通过训练Transformer来在情境下进行强化学习，并分析模型中出现的算法。&lt;h4&gt;方法&lt;/h4&gt;研究人员训练了一个Transformer，使其在受老鼠行为启发的规划任务中进行情境下强化学习。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，表示学习得益于情境结构学习和跨情境对齐，表示在不同感官刺激的环境中被对齐。此外，模型开发的强化学习策略不同于标准的模型无关或模型基规划，而是通过在模型的记忆标记内缓存中间计算，并在决策时访问这些计算来支持情境下强化学习。&lt;h4&gt;结论&lt;/h4&gt;研究结果表明，记忆可能作为一种计算资源，存储原始经验和缓存的计算以支持灵活的行为，并且模型中的表示与大脑中海马体-内嗅系统相关的计算相似，表明这些发现可能与自然认知相关。&lt;h4&gt;翻译&lt;/h4&gt;This study explores the learning efficiency of humans and animals and the application of Transformers in contextual reinforcement learning. Research has found that representation learning is supported by contextual structure learning and cross-context alignment, and the reinforcement learning strategies developed by the model are different from standard model-free or model-based planning. Instead, contextual reinforcement learning is supported by caching intermediate computations within the model's memory tokens, which are then accessed at decision time. The research results show that memory may serve as a computational resource, storing both raw experience and cached computations to support flexible behavior, and the representations developed in the model are similar to computations associated with the hippocampal-entorhinal system in the brain, suggesting that these findings may be relevant to natural cognition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans and animals show remarkable learning efficiency, adapting to newenvironments with minimal experience. This capability is not well captured bystandard reinforcement learning algorithms that rely on incremental valueupdates. Rapid adaptation likely depends on episodic memory -- the ability toretrieve specific past experiences to guide decisions in novel contexts.Transformers provide a useful setting for studying these questions because oftheir ability to learn rapidly in-context and because their key-valuearchitecture resembles episodic memory systems in the brain. We train atransformer to in-context reinforcement learn in a distribution of planningtasks inspired by rodent behavior. We then characterize the learning algorithmsthat emerge in the model. We first find that representation learning issupported by in-context structure learning and cross-context alignment, whererepresentations are aligned across environments with different sensory stimuli.We next demonstrate that the reinforcement learning strategies developed by themodel are not interpretable as standard model-free or model-based planning.Instead, we show that in-context reinforcement learning is supported by cachingintermediate computations within the model's memory tokens, which are thenaccessed at decision time. Overall, we find that memory may serve as acomputational resource, storing both raw experience and cached computations tosupport flexible behavior. Furthermore, the representations developed in themodel resemble computations associated with the hippocampal-entorhinal systemin the brain, suggesting that our findings may be relevant for naturalcognition. Taken together, our work offers a mechanistic hypothesis for therapid adaptation that underlies in-context learning in artificial and naturalsettings.</description>
      <author>example@mail.com (Ching Fang, Kanaka Rajan)</author>
      <guid isPermaLink="false">2506.19686v2</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition</title>
      <link>http://arxiv.org/abs/2506.20174v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究探讨了使用预训练模型来提升地球观测数据挖掘的性能。&lt;h4&gt;背景&lt;/h4&gt;目前地球观测数据挖掘主要依赖于从大量地球观测数据集从头开始训练的大模型，而预训练模型的重用和组合策略尚未充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究预训练模型在地球观测任务中的组合使用是否能够有效提升性能。&lt;h4&gt;方法&lt;/h4&gt;使用GEO-Bench基准，评估了包括Prithvi、Hiera和DOFA在内的几个突出模型，在涵盖多种空间分辨率、传感器模态和任务类型的11个数据集上进行了实验。&lt;h4&gt;主要发现&lt;/h4&gt;小型预训练模型的特征级集成可以匹配甚至超越大型模型的性能，同时需要更少的训练时间和计算资源。&lt;h4&gt;结论&lt;/h4&gt;知识蒸馏技术在将集成模型的优点转移到更紧凑的模型中具有潜力，为在实际地球观测应用中部署基础模型提供了一条实用路径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型正在迅速改变地球观测数据挖掘，通过为场景分类和语义分割等关键任务提供可泛化和可扩展的解决方案。虽然大多数地球空间领域的努力都集中在开发从大量地球观测数据集从头开始训练的大模型上，但一个尚未充分探索的替代策略是重用和组合现有预训练模型。在本研究中，我们调查了在遥感视觉数据集上预训练的基础模型是否可以有效地组合以提升一系列关键地球观测任务的性能。使用GEO-Bench基准，我们对包括Prithvi、Hiera和DOFA在内的几个突出模型在覆盖多种空间分辨率、传感器模态和任务类型的11个数据集上进行了评估。结果显示，小型预训练模型的特征级集成可以匹配甚至超越大型模型的性能，同时需要更少的训练时间和计算资源。此外，该研究突出了应用知识蒸馏技术将集成模型的优点转移到更紧凑模型中的潜力，为在实际地球观测应用中部署基础模型提供了一条实用路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are rapidly transforming Earth Observation data mining byenabling generalizable and scalable solutions for key tasks such as sceneclassification and semantic segmentation. While most efforts in the geospatialdomain have focused on developing large models trained from scratch usingmassive Earth Observation datasets, an alternative strategy that remainsunderexplored is the reuse and combination of existing pretrained models. Inthis study, we investigate whether foundation models pretrained on remotesensing and general vision datasets can be effectively combined to improveperformance across a diverse set of key Earth Observation tasks. Using theGEO-Bench benchmark, we evaluate several prominent models, including Prithvi,Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions,sensor modalities, and task types. The results show that feature-levelensembling of smaller pretrained models can match or exceed the performance ofmuch larger models, while requiring less training time and computationalresources. Moreover, the study highlights the potential of applying knowledgedistillation to transfer the strengths of ensembles into more compact models,offering a practical path for deploying foundation models in real-world EarthObservation applications.</description>
      <author>example@mail.com (Man Duc Chuc)</author>
      <guid isPermaLink="false">2506.20174v2</guid>
      <pubDate>Fri, 27 Jun 2025 14:26:02 +0800</pubDate>
    </item>
    <item>
      <title>Finetuning a Weather Foundation Model with Lightweight Decoders for Unseen Physical Processes</title>
      <link>http://arxiv.org/abs/2506.19088v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了AI天气预报中的基础模型，特别是Aurora模型在预测水文变量方面的性能。提出了一种轻量级方法，通过在预训练模型的潜在表示上训练浅层解码器来预测新的变量，并与其他方法进行了比较。&lt;h4&gt;背景&lt;/h4&gt;AI天气预报领域出现了所谓的基础模型，这些模型通常通过昂贵的预训练和下游任务中的最小微调来定义。在自然科学中，理想的基础模型还应编码底层物理变量之间的有意义统计关系。&lt;h4&gt;目的&lt;/h4&gt;评估Aurora基础模型在预测预训练期间未考虑的水文变量方面的性能。&lt;h4&gt;方法&lt;/h4&gt;引入了一种轻量级方法，使用在预训练模型的潜在表示上训练的浅层解码器来预测这些新变量。以微调整个模型作为基线，这允许进一步优化潜在空间，同时将新变量纳入输入和输出。&lt;h4&gt;主要发现&lt;/h4&gt;解码器方法需要50%的培训时间和35%的内存，同时在各种水文变量上实现了强大的准确性，并保留了基础模型的有益属性，如自回归稳定性。解码器的准确性取决于新变量与预训练期间使用的变量之间的物理相关性，表明Aurora的潜在空间捕捉到了有意义的物理关系。&lt;h4&gt;结论&lt;/h4&gt;提出，对于地球科学中的基础模型，一个重要的质量指标是它们在不进行完全微调的情况下扩展到新变量的能力。这为使基础模型对计算资源有限的社区更加可访问提供了新的视角，同时支持其在地球科学中的更广泛采用。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in AI weather forecasting have led to the emergence ofso-called 'foundation models', typically defined by expensive pretraining andminimal fine-tuning for downstream tasks. However, in the natural sciences, adesirable foundation model should also encode meaningful statistical relationships between the underlying physical variables. This study evaluates the performance of the state-of-the-art Aurora foundation model in predicting hydrological variables, which were not considered during pretraining. We introduce a lightweight approach using shallow decoders trained on the latent representations of the pretrained model to predict these new variables. As a baseline, we compare this to fine-tuning the full model, which allows further optimization of the latent space while incorporating new variables into both inputs and outputs. The decoder-based approach requires 50% less training time and 35% less memory, while achieving strong accuracy across various hydrological variables and preserving desirable properties of the foundation model, such as autoregressive stability. Notably, decoder accuracy depends on the physical correlation between the new variables and those used during pretraining, indicating that Aurora's latent space captures meaningful physical relationships. In this sense, we argue that an important quality metric for foundation models in Earth sciences is their ability to be extended to new variables without a full fine-tuning. This provides a new perspective for making foundation models more accessible to communities with limited computational resources, while supporting broader adoption in Earth sciences.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in AI weather forecasting have led to the emergence ofso-called "foundation models", typically defined by expensive pretraining andminimal fine-tuning for downstream tasks. However, in the natural sciences, adesirable foundation model should also encode meaningful statisticalrelationships between the underlying physical variables. This study evaluatesthe performance of the state-of-the-art Aurora foundation model in predictinghydrological variables, which were not considered during pretraining. Weintroduce a lightweight approach using shallow decoders trained on the latentrepresentations of the pretrained model to predict these new variables. As abaseline, we compare this to fine-tuning the full model, which allows furtheroptimization of the latent space while incorporating new variables into bothinputs and outputs. The decoder-based approach requires 50% less training timeand 35% less memory, while achieving strong accuracy across varioushydrological variables and preserving desirable properties of the foundationmodel, such as autoregressive stability. Notably, decoder accuracy depends onthe physical correlation between the new variables and those used duringpretraining, indicating that Aurora's latent space captures meaningful physicalrelationships. In this sense, we argue that an important quality metric forfoundation models in Earth sciences is their ability to be extended to newvariables without a full fine-tuning. This provides a new perspective formaking foundation models more accessible to communities with limitedcomputational resources, while supporting broader adoption in Earth sciences.</description>
      <author>example@mail.com (Fanny Lehmann, Firat Ozdemir, Benedikt Soja, Torsten Hoefler, Siddhartha Mishra, Sebastian Schemm)</author>
      <guid isPermaLink="false">2506.19088v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
  <item>
      <title>Disentangled representations of microscopy images</title>
      <link>http://arxiv.org/abs/2506.20649v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in: International Joint Conference on Neural Networks  (IJCNN 2025). Project page:  https://github.com/JacopoDapueto/disentangled_microscopy&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于解耦表示学习（DRL）的方法，用于提高显微镜图像分类的可解释性。&lt;h4&gt;背景&lt;/h4&gt;显微镜图像分析在不同应用中至关重要，如诊断、合成工程和环境影响监测。现代获取系统可以获取大量图像，需要相应地开发基于深度学习的自动图像分析方法。&lt;h4&gt;目的&lt;/h4&gt;提高显微镜图像分类模型的可解释性。&lt;h4&gt;方法&lt;/h4&gt;利用来自三个不同显微镜图像领域（浮游生物、酵母空泡和人类细胞）的基准数据集，展示了一种基于从合成数据中学习到的表示的DRL框架，如何在保证准确性的同时提供良好的可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;DRL框架在显微镜图像分类领域提供了准确性和可解释性之间的良好平衡。&lt;h4&gt;结论&lt;/h4&gt;DRL方法在显微镜图像分析中具有提高模型可解释性的潜力。&lt;h4&gt;翻译&lt;/h4&gt;Microscopy image analysis is fundamental for different applications, from diagnosis to synthetic engineering and environmental monitoring. Modern acquisition systems have granted the possibility to acquire an escalating amount of images, requiring a consequent development of a large collection of deep learning-based automatic image analysis methods. Although deep neural networks have demonstrated great performance in this field, interpretability, an essential requirement for microscopy image analysis, remains an open challenge. This work proposes a Disentangled Representation Learning (DRL) methodology to enhance model interpretability for microscopy image classification. Exploiting benchmark datasets from three different microscopic image domains (plankton, yeast vacuoles, and human cells), we show how a DRL framework, based on transferring a representation learnt from synthetic data, can provide a good trade-off between accuracy and interpretability in this domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Microscopy image analysis is fundamental for different applications, fromdiagnosis to synthetic engineering and environmental monitoring. Modernacquisition systems have granted the possibility to acquire an escalatingamount of images, requiring a consequent development of a large collection ofdeep learning-based automatic image analysis methods. Although deep neuralnetworks have demonstrated great performance in this field, interpretability,an essential requirement for microscopy image analysis, remains an openchallenge.  This work proposes a Disentangled Representation Learning (DRL) methodologyto enhance model interpretability for microscopy image classification.Exploiting benchmark datasets from three different microscopic image domains(plankton, yeast vacuoles, and human cells), we show how a DRL framework, basedon transferring a representation learnt from synthetic data, can provide a goodtrade-off between accuracy and interpretability in this domain.</description>
      <author>example@mail.com (Jacopo Dapueto, Vito Paolo Pastore, Nicoletta Noceti, Francesca Odone)</author>
      <guid isPermaLink="false">2506.20649v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Assessing the Ship Motion Prediction Capabilities of the Open-Source Model NEMOH Against Field Observations</title>
      <link>http://arxiv.org/abs/2506.20186v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文评估了开源边界元求解器NEMOH在预测真实海洋环境船舶运动方面的能力。&lt;h4&gt;背景&lt;/h4&gt;精确的船舶运动预测对于开放海洋环境中的航海安全与效率至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究目的是评估NEMOH在预测真实开放海洋条件下船舶运动的能力。&lt;h4&gt;方法&lt;/h4&gt;使用NEMOH获得了线性模型RAO，并通过WaMoS-II海洋雷达获取的波向谱驱动。预测结果与船载惯性测量单元（IMU）记录的船舶运动观测值进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;比较结果显示，NEMOH在波浪运动预测方面具有可靠性：垂荡预测的相关系数为0.89，散布指数为0.41；纵摇预测的相关系数为0.80，散布指数为0.47；横摇预测的相关系数为0.63，散布指数为0.84。在特定极端海况下，纵摇和横摇的预测误差更大。&lt;h4&gt;结论&lt;/h4&gt;结果表明NEMOH在现实世界航海操作中的适用性，并为其实际应用提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;摘要：精确的船舶运动预测对于航海安全与效率至关重要，特别是在开放海洋环境中。本研究评估了开源势流边界元求解器NEMOH在预测真实海洋环境船舶运动方面的能力。通过NEMOH获得了线性模型RAO，并用WaMoS-II海洋雷达在阿克ademik Tryoshnikov号研究船进行的南极圈航行探险（ACE）期间获取的波向谱进行驱动。预测结果与船载惯性测量单元（IMU）记录的船舶运动观测值进行了比较。基于船舶运动谱的零阶矩的比较表明，NEMOH在垂荡预测方面具有可靠性（皮尔逊相关系数r=0.89，散布指数SI=0.41），在纵摇预测方面合理（r=0.80，SI=0.47），在横摇预测方面可接受（r=0.63，SI=0.84）。在特定极端海况下，纵摇和横摇的预测误差更大。结果表明NEMOH的能力，为其在现实世界航海操作中的应用提供了见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate ship motion prediction is critical for safe and efficient maritimeoperations, particularly in open ocean environments. This study evaluates thecapability of NEMOH, an open-source potential flow boundary element solver, forpredicting ship motions in real-world open ocean conditions. A linear model,known as the Response Amplitude Operator (RAO), is obtained using NEMOH, and isdriven by the wave directional spectrum obtained from the WaMoS-II marine radaron the research vessel Akademik Tryoshnikov during the AntarcticCircumnavigation Expedition (ACE). Predictions are benchmarked againstconcurrent ship motion observations recorded by an onboard inertial measurementunit (IMU). The comparisons, based on the zeroth order moment of the shipmotion spectrum, demonstrate a reliable heave prediction (Pearson correlationcoefficient r=0.89, scatter index SI=0.41), a reasonable pitch prediction(r=0.80, SI=0.47), and an acceptable roll prediction (r=0.63, SI=0.84). Moresignificant discrepancies for pitch and roll are identified under specificextreme sea conditions. The results demonstrate the capability of NEMOH,offering insights into its applicability for real-world maritime operations.</description>
      <author>example@mail.com (Tianshi Yu, Ziyue Wang, Filippo Nelli, Ying Tan, Guillaume Ducrozet, Alessandro Toffoli)</author>
      <guid isPermaLink="false">2506.20186v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Causal Representation Learning with Observational Grouping for CXR Classification</title>
      <link>http://arxiv.org/abs/2506.20582v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通过分组学习可识别表示的方法，用于胸部X光片的疾病分类，以增强特定任务的泛化性和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在医学影像中，可识别的因果表示学习旨在揭示数据生成过程中的真实因果关系，这为提高特定任务的潜在特征泛化性和鲁棒性提供了机会。&lt;h4&gt;目的&lt;/h4&gt;通过引入分组观察的概念，利用端到端框架学习胸部X光片疾病分类的可识别表示。&lt;h4&gt;方法&lt;/h4&gt;实验中采用了分组方法来强制执行不变性，以w.r.trace、性别和成像视图来增强泛化性和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，当使用分组来强制执行不变性时，这些因果表示在多个分类任务中提高了泛化性和鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;分组学习可识别表示的方法在胸部X光片疾病分类中有效，可以增强特定任务的泛化性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Identifiable causal representation learning seeks to uncover the true causal relationships underlying a data generation process. In medical imaging, this presents opportunities to improve the generalisability and robustness of task-specific latent features. This work introduces the concept of grouping observations to learn identifiable representations for disease classification in chest X-rays via an end-to-end framework. Our experiments demonstrate that these causal representations improve generalisability and robustness across multiple classification tasks when grouping is used to enforce invariance w.r.trace, sex, and imaging views.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Identifiable causal representation learning seeks to uncover the true causalrelationships underlying a data generation process. In medical imaging, thispresents opportunities to improve the generalisability and robustness oftask-specific latent features. This work introduces the concept of groupingobservations to learn identifiable representations for disease classificationin chest X-rays via an end-to-end framework. Our experiments demonstrate thatthese causal representations improve generalisability and robustness acrossmultiple classification tasks when grouping is used to enforce invariance w.r.trace, sex, and imaging views.</description>
      <author>example@mail.com (Rajat Rasal, Avinash Kori, Ben Glocker)</author>
      <guid isPermaLink="false">2506.20582v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios</title>
      <link>http://arxiv.org/abs/2506.20531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 10 figures, under-review conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于案例推理增强的大型语言模型（CBR-LLM）框架，用于复杂风险场景中的主动操作决策，以提高自动驾驶系统的决策准确性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;在安全关键场景中驾驶需要基于情境理解和经验推理的快速、情境感知的决策。大型语言模型（LLMs）具有强大的通用推理能力，但在自动驾驶领域的直接应用受到领域适应性、情境基础和缺乏动态高风险环境中可靠和可解释决策所需的经验知识的限制。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，本文旨在提出一种框架，以增强LLMs在自动驾驶中的决策能力。&lt;h4&gt;方法&lt;/h4&gt;该框架结合了语义场景理解（来自行车记录仪视频输入）和与过去驾驶案例的相关检索，使LLMs能够生成既情境敏感又符合人类操作的建议。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该框架提高了决策准确性、论证质量和与人类专家行为的契合度。风险感知提示策略进一步提高了不同风险类型的表现，而基于相似性的案例检索在指导情境学习方面始终优于随机抽样。&lt;h4&gt;结论&lt;/h4&gt;案例研究进一步证明了该框架在具有挑战性的现实条件下的鲁棒性，强调了其作为智能驾驶系统自适应和可信决策支持工具的潜力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在安全关键场景中驾驶需要基于情境理解和经验推理的快速、情境感知的决策。大型语言模型（LLMs）具有强大的通用推理能力，但其直接应用于自动驾驶仍受到领域适应性、情境基础和缺乏动态高风险环境中可靠和可解释决策所需的经验知识的限制。为了解决这一差距，本文提出了一种用于复杂风险场景中主动操作决策的案例推理增强大型语言模型（CBR-LLM）框架。我们的方法结合了来自行车记录仪视频输入的语义场景理解与相关过去驾驶案例的检索，使LLMs能够生成既情境敏感又符合人类操作的建议。在多个开源LLMs上的实验表明，我们的框架提高了决策准确性、论证质量和与人类专家行为的契合度。风险感知提示策略进一步提高了不同风险类型的表现，而基于相似性的案例检索在指导情境学习方面始终优于随机抽样。案例研究进一步证明了该框架在具有挑战性的现实条件下的鲁棒性，强调了其作为智能驾驶系统自适应和可信决策支持工具的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Driving in safety-critical scenarios requires quick, context-awaredecision-making grounded in both situational understanding and experientialreasoning. Large Language Models (LLMs), with their powerful general-purposereasoning capabilities, offer a promising foundation for such decision-making.However, their direct application to autonomous driving remains limited due tochallenges in domain adaptation, contextual grounding, and the lack ofexperiential knowledge needed to make reliable and interpretable decisions indynamic, high-risk environments. To address this gap, this paper presents aCase-Based Reasoning Augmented Large Language Model (CBR-LLM) framework forevasive maneuver decision-making in complex risk scenarios. Our approachintegrates semantic scene understanding from dashcam video inputs with theretrieval of relevant past driving cases, enabling LLMs to generate maneuverrecommendations that are both context-sensitive and human-aligned. Experimentsacross multiple open-source LLMs show that our framework improves decisionaccuracy, justification quality, and alignment with human expert behavior.Risk-aware prompting strategies further enhance performance across diverse risktypes, while similarity-based case retrieval consistently outperforms randomsampling in guiding in-context learning. Case studies further demonstrate theframework's robustness in challenging real-world conditions, underscoring itspotential as an adaptive and trustworthy decision-support tool for intelligentdriving systems.</description>
      <author>example@mail.com (Wenbin Gan, Minh-Son Dao, Koji Zettsu)</author>
      <guid isPermaLink="false">2506.20531v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion</title>
      <link>http://arxiv.org/abs/2506.20537v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FEA-PINN的高效建模框架，用于加速激光粉末床熔融（LPBF）过程中的热场预测，同时保持有限元分析（FEA）的精度。&lt;h4&gt;背景&lt;/h4&gt;传统数值方法如有限元分析（FEA）在模拟LPBF过程中存在计算成本高的长期问题。&lt;h4&gt;目的&lt;/h4&gt;开发一种高效的方法来预测LPBF过程中的热场，同时保持FEA的准确性。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种新的动态材料更新策略，以捕捉PINN模型中粉末-液体-固体的动态相变。2. PINN模型通过显热容方法结合了温度相关的材料属性和相变行为。3. 为了克服时间相关问题中计算成本高的问题，FEA-PINN框架在推理过程中集成校正FEA模拟，以强制执行物理一致性并减少误差漂移。&lt;h4&gt;主要发现&lt;/h4&gt;FEA-PINN模型在具有少量训练数据的情况下表现出高精度，并通过迁移学习实现了对新过程参数的泛化。此外，与FEA相比，FEA-PINN在保持等效精度的同时显著降低了计算成本。&lt;h4&gt;结论&lt;/h4&gt;FEA-PINN框架在LPBF中的应用验证了其有效性和准确性，为LPBF过程中的热场预测提供了一种高效且准确的方法。&lt;h4&gt;翻译&lt;/h4&gt;Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process prediction due to the lasting issue of high computation cost using traditional numerical methods such as finite element analysis (FEA). This study presents an efficient modeling framework termed FEA-Regulated Physics-Informed Neural Network (FEA-PINN) to accelerate the thermal field prediction in a LPBF process while maintaining the FEA accuracy. A novel dynamic material updating strategy is developed to capture the dynamic phase change of powder-liquid-solid in the PINN model. The PINN model incorporates temperature-dependent material properties and phase change behavior using the apparent heat capacity method. While the PINN model demonstrates high accuracy with a small training data and enables generalization of new process parameters via transfer learning, it faces the challenge of high computation cost in time-dependent problems due to the residual accumulation. To overcome this issue, the FEA-PINN framework integrates corrective FEA simulations during inference to enforce physical consistency and reduce error drift. A comparative analysis shows that FEA-PINN achieves equivalent accuracy to FEA while significantly reducing computational cost. The framework has been validated using the benchmark FEA data and demonstrated through single-track scanning in LPBF.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for processprediction due to the lasting issue of high computation cost using traditionalnumerical methods such as finite element analysis (FEA). This study presents anefficient modeling framework termed FEA-Regulated Physics-Informed NeuralNetwork (FEA-PINN) to accelerate the thermal field prediction in a LPBF processwhile maintaining the FEA accuracy. A novel dynamic material updating strategyis developed to capture the dynamic phase change of powder-liquid-solid in thePINN model. The PINN model incorporates temperature-dependent materialproperties and phase change behavior using the apparent heat capacity method.While the PINN model demonstrates high accuracy with a small training data andenables generalization of new process parameters via transfer learning, itfaces the challenge of high computation cost in time-dependent problems due tothe residual accumulation. To overcome this issue, the FEA-PINN frameworkintegrates corrective FEA simulations during inference to enforce physicalconsistency and reduce error drift. A comparative analysis shows that FEA-PINNachieves equivalent accuracy to FEA while significantly reducing computationalcost. The framework has been validated using the benchmark FEA data anddemonstrated through single-track scanning in LPBF.</description>
      <author>example@mail.com (R. Sharma, M. Raissi, Y. B. Guo)</author>
      <guid isPermaLink="false">2506.20537v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Causal Inference for Latent Outcomes Learned with Factor Models</title>
      <link>http://arxiv.org/abs/2506.20549v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages, 7 figures, 1 table (+ references and supplement). For  open-source R software package, see https://github.com/jennalandy/causalLFO.  For all code used in the simulation studies and data application, see  https://github.com/jennalandy/causalLFO_PAPER&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在因子模型或表示学习背景下，利用非负矩阵分解对高维观测数据中导出的潜在结果进行因果效应分析。&lt;h4&gt;背景&lt;/h4&gt;在基因组学、流行病学、自然语言处理、社会和行为科学以及经济学等领域，解决因果问题变得越来越重要。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的算法，以估计潜在结果上的因果效应，同时减轻学习引起的干扰并提高估计效率。&lt;h4&gt;方法&lt;/h4&gt;本文使用非负矩阵分解来研究潜在结果上的因果效应，并提出了一个新颖的、直观的、理论上有根据的算法来解决这个问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文将估计潜在因子模型可能导致的个体学习到的潜在结果依赖于其他个体的处理方式的问题，称为学习引起的干扰，并提出了缓解这一问题的方法。&lt;h4&gt;结论&lt;/h4&gt;本文通过模拟研究和癌症突变特征分析的应用，证明了所提算法的实用性和理论保证。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了在因子模型或表示学习背景下，利用非负矩阵分解对高维观测数据中导出的潜在结果进行因果效应分析。在基因组学、流行病学、自然语言处理、社会和行为科学以及经济学等领域，解决因果问题变得越来越重要。本文旨在提出一种新的算法，以估计潜在结果上的因果效应，同时减轻学习引起的干扰并提高估计效率。本文使用非负矩阵分解来研究潜在结果上的因果效应，并提出了一个新颖的、直观的、理论上有根据的算法来解决这个问题。本文将估计潜在因子模型可能导致的个体学习到的潜在结果依赖于其他个体的处理方式的问题，称为学习引起的干扰，并提出了缓解这一问题的方法。通过模拟研究和癌症突变特征分析的应用，本文证明了所提算法的实用性和理论保证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In many fields$\unicode{x2013}$including genomics, epidemiology, naturallanguage processing, social and behavioral sciences, andeconomics$\unicode{x2013}$it is increasingly important to address causalquestions in the context of factor models or representation learning. In thiswork, we investigate causal effects on $\textit{latent outcomes}$ derived fromhigh-dimensional observed data using nonnegative matrix factorization. To thebest of our knowledge, this is the first study to formally address causalinference in this setting. A central challenge is that estimating a latentfactor model can cause an individual's learned latent outcome to depend onother individuals' treatments, thereby violating the standard causal inferenceassumption of no interference. We formalize this issue as$\textit{learning-induced interference}$ and distinguish it from interferencepresent in a data-generating process. To address this, we propose a novel,intuitive, and theoretically grounded algorithm to estimate causal effects onlatent outcomes while mitigating learning-induced interference and improvingestimation efficiency. We establish theoretical guarantees for the consistencyof our estimator and demonstrate its practical utility through simulationstudies and an application to cancer mutational signature analysis. Allbaseline and proposed methods are available in our open-source R package, ${\ttcausalLFO}$.</description>
      <author>example@mail.com (Jenna M. Landy, Dafne Zorzetto, Roberta De Vito, Giovanni Parmigiani)</author>
      <guid isPermaLink="false">2506.20549v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Directed Link Prediction using GNN with Local and Global Feature Fusion</title>
      <link>http://arxiv.org/abs/2506.20235v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图神经网络（GNN）框架，用于融合特征嵌入与社区信息，以改善有向链接预测的性能。&lt;h4&gt;背景&lt;/h4&gt;链接预测是图分析中的经典问题，有广泛应用。对于有向图，近期发展的深度学习方法通常通过对比学习分析节点相似性，并通过图卷积聚合邻域信息。&lt;h4&gt;目的&lt;/h4&gt;提高有向链接预测的性能。&lt;h4&gt;方法&lt;/h4&gt;1. 提出了一种新的GNN框架，用于融合特征嵌入与社区信息。2. 提出了一种方法，将输入图转换为有向线图，以便在图卷积过程中节点可以聚合更多信息。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明了这种混合特征可以改善有向链接预测的性能。实验结果表明，在30%，40%，50%，和60%的连接链接作为训练数据的情况下，该方法在大多数情况下优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该方法在大多数情况下优于现有技术，证明了融合特征和转换图结构对于有向链接预测的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Link prediction is a classical problem in graph analysis with many practicalapplications. For directed graphs, recently developed deep learning approachestypically analyze node similarities through contrastive learning and aggregateneighborhood information through graph convolutions. In this work, we propose anovel graph neural network (GNN) framework to fuse feature embedding withcommunity information. We theoretically demonstrate that such hybrid featurescan improve the performance of directed link prediction. To utilize suchfeatures efficiently, we also propose an approach to transform input graphsinto directed line graphs so that nodes in the transformed graph can aggregatemore information during graph convolutions. Experiments on benchmark datasetsshow that our approach outperforms the state-of-the-art in most cases when 30%,40%, 50%, and 60% of the connected links are used as training data,respectively.</description>
      <author>example@mail.com (Yuyang Zhang, Xu Shen, Yu Xie, Ka-Chun Wong, Weidun Xie, Chengbin Peng)</author>
      <guid isPermaLink="false">2506.20235v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Learning-based safety lifting monitoring system for cranes on construction sites</title>
      <link>http://arxiv.org/abs/2506.20475v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究设计了一种基于学习方法的自动化安全提升监测算法流程，用于减少建筑工地上提升作业的安全风险，特别是针对大型模块化集成建筑（MiC）的提升作业。&lt;h4&gt;背景&lt;/h4&gt;提升作业在建筑工地上是常见的操作，但由于MiC重量大、体积大，存在安全风险，可能导致事故、损坏模块或对现场工人造成安全危害。&lt;h4&gt;目的&lt;/h4&gt;旨在通过自动化技术提高MiC提升过程的安全性和效率，减少提升作业中的安全风险。&lt;h4&gt;方法&lt;/h4&gt;创建了一个包含1007个图像-点云对（37个MiC提升）的数据集，并训练了先进的物体检测模型进行MiC和人类的自动二维（2D）检测。将2D检测结果与点云信息融合，以准确确定MiC和人类的三维（3D）位置。系统设计为自动触发警报，通知MiC提升危险区域的个人，并为起重机操作员提供实时提升信息和早期预警。&lt;h4&gt;主要发现&lt;/h4&gt;该算法流程在MiC和人类感知方面显示出有希望的结果，平均距离误差分别为1.5640米和0.7824米。此外，该系统在真实建筑工地上成功执行了安全风险监测和警报功能，对人工干预的需求有限。&lt;h4&gt;结论&lt;/h4&gt;该系统在减少MiC提升作业中的安全风险方面具有潜力，能够有效提高施工安全性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Lifting on construction sites, as a frequent operation, works still withsafety risks, especially for modular integrated construction (MiC) lifting dueto its large weight and size, probably leading to accidents, causing damage tothe modules, or more critically, posing safety hazards to on-site workers.Aiming to reduce the safety risks in lifting scenarios, we design an automatedsafe lifting monitoring algorithm pipeline based on learning-based methods, anddeploy it on construction sites. This work is potentially to increase thesafety and efficiency of MiC lifting process via automation technologies. Adataset is created consisting of 1007 image-point cloud pairs (37 MiCliftings). Advanced object detection models are trained for automatedtwo-dimensional (2D) detection of MiCs and humans. Fusing the 2D detectionresults with the point cloud information allows accurate determination of thethree-dimensional (3D) positions of MiCs and humans. The system is designed toautomatically trigger alarms that notify individuals in the MiC lifting dangerzone, while providing the crane operator with real-time lifting information andearly warnings. The monitoring process minimizes the human intervention and noor less signal men are required on real sites assisted by our system. Aquantitative analysis is conducted to evaluate the effectiveness of thealgorithmic pipeline. The pipeline shows promising results in MiC and humanperception with the mean distance error of 1.5640 m and 0.7824 m respectively.Furthermore, the developed system successfully executes safety risk monitoringand alarm functionalities during the MiC lifting process with limited manualwork on real construction sites.</description>
      <author>example@mail.com (Hao Chen, Yu Hin Ng, Ching-Wei Chang, Haobo Liang, Yanke Wang)</author>
      <guid isPermaLink="false">2506.20475v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs</title>
      <link>http://arxiv.org/abs/2506.20073v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;STReason是一个结合大型语言模型和时空模型进行多任务推理和执行的新框架。&lt;h4&gt;背景&lt;/h4&gt;现有的时空数据挖掘模型通常局限于特定任务，缺乏多任务推理和复杂长格式推理的能力。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个能够处理复杂时空场景的框架，以支持更深入的决策。&lt;h4&gt;方法&lt;/h4&gt;STReason利用上下文学习将复杂自然语言查询分解为模块化、可解释的程序，然后执行这些程序以生成解决方案和详细理由。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，STReason在所有指标上均显著优于先进的LLM基线，尤其在复杂的推理密集型时空场景中表现出色。&lt;h4&gt;结论&lt;/h4&gt;STReason为开发更强大和更具通用性的时空推理系统提供了有希望的途径。&lt;h4&gt;翻译&lt;/h4&gt;时空数据挖掘在各个领域的信息化决策中发挥着关键作用。然而，现有的模型通常局限于狭窄的任务，缺乏进行多任务推理和复杂长格式推理的能力，这需要生成深入的、解释性的输出。这些限制限制了它们在现实世界、多方面的决策场景中的应用。在这项工作中，我们引入了STReason，这是一个将大型语言模型（LLM）的推理优势与时空模型的解析能力相结合的新框架，无需针对特定任务进行微调。STReason利用上下文学习将复杂的自然语言查询分解为模块化、可解释的程序，然后系统地执行这些程序以生成解决方案和详细的理由。为了便于严格评估，我们构建了一个新的基准数据集，并提出了一个统一的评估框架，其中包含专门为长格式时空推理设计的指标。实验结果表明，STReason在所有指标上均显著优于先进的LLM基线，尤其是在复杂的推理密集型时空场景中表现出色。人工评估进一步验证了STReason的可信度和实用性，证明了其减少专家工作量和拓宽现实世界时空任务应用范围的可能性。我们认为STReason为开发更强大和更具通用性的时空推理系统提供了有希望的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Spatio-temporal data mining plays a pivotal role in informed decision makingacross diverse domains. However, existing models are often restricted to narrowtasks, lacking the capacity for multi-task inference and complex long-formreasoning that require generation of in-depth, explanatory outputs. Theselimitations restrict their applicability to real-world, multi-faceted decisionscenarios. In this work, we introduce STReason, a novel framework thatintegrates the reasoning strengths of large language models (LLMs) with theanalytical capabilities of spatio-temporal models for multi-task inference andexecution. Without requiring task-specific finetuning, STReason leveragesin-context learning to decompose complex natural language queries into modular,interpretable programs, which are then systematically executed to generate bothsolutions and detailed rationales. To facilitate rigorous evaluation, weconstruct a new benchmark dataset and propose a unified evaluation frameworkwith metrics specifically designed for long-form spatio-temporal reasoning.Experimental results show that STReason significantly outperforms advanced LLMbaselines across all metrics, particularly excelling in complex,reasoning-intensive spatio-temporal scenarios. Human evaluations furthervalidate STReason's credibility and practical utility, demonstrating itspotential to reduce expert workload and broaden the applicability to real-worldspatio-temporal tasks. We believe STReason provides a promising direction fordeveloping more capable and generalizable spatio-temporal reasoning systems.</description>
      <author>example@mail.com (Kethmi Hirushini Hettige, Jiahao Ji, Cheng Long, Shili Xiang, Gao Cong, Jingyuan Wang)</author>
      <guid isPermaLink="false">2506.20073v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>DreamAnywhere: Object-Centric Panoramic 3D Scene Generation</title>
      <link>http://arxiv.org/abs/2506.20367v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了DreamAnywhere系统，该系统可以快速生成和原型设计3D场景，具有沉浸式导航和直观的对象级别编辑功能，适用于场景探索、视觉模拟和快速原型设计，尤其适合低成本电影制作。&lt;h4&gt;背景&lt;/h4&gt;近年来，文本到3D场景生成的技术取得了显著进展，但在生成具有真实感的场景、理解场景和适应室内外环境等方面仍存在挑战。&lt;h4&gt;目的&lt;/h4&gt;解决现有方法在生成3D场景时存在的问题，如场景仅面向前方、缺乏视觉真实感、场景理解有限等。&lt;h4&gt;方法&lt;/h4&gt;DreamAnywhere系统通过以下步骤生成3D场景：从文本生成360度全景图像，将其分解为背景和对象，通过混合修复构建完整的3D表示，并将对象掩码提升为详细的三维对象，放置在虚拟环境中。&lt;h4&gt;主要发现&lt;/h4&gt;DreamAnywhere系统在新颖视图合成中的连贯性方面有显著提升，并且实现了有竞争力的图像质量，证明其在多样化和具有挑战性的场景中的有效性。&lt;h4&gt;结论&lt;/h4&gt;通过用户研究，证明DreamAnywhere方法在技术稳健性和实用价值方面优于现有方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，在文本到3D场景生成技术方面的进展展示了在多个行业中转换内容创作的巨大潜力。尽管研究界在解决这一复杂任务的挑战方面取得了令人印象深刻的进步，但现有方法往往生成的环境仅面向前方，缺乏视觉真实感，场景理解有限，并且通常针对室内或室外环境进行微调。在这项工作中，我们解决了这些问题，并提出了DreamAnywhere，一个用于快速生成和原型设计3D场景的模块化系统。我们的系统从文本合成360度全景图像，将其分解为背景和对象，通过混合修复构建完整的3D表示，并将对象掩码提升为放置在虚拟环境中的详细三维对象。DreamAnywhere支持沉浸式导航和直观的对象级别编辑，使其非常适合场景探索、视觉模拟和快速原型设计——所有这些都可以实现最小化的手动建模。这些功能使我们的系统特别适合低成本电影制作，可以在不增加传统3D工作流程的负担的情况下快速迭代场景布局和视觉色调。我们的模块化管道高度可定制，因为它允许独立替换组件。与当前的基于文本和图像的3D场景生成方法相比，DreamAnywhere在新颖视图合成中的连贯性方面有显著提升，并实现了有竞争力的图像质量，证明了其在多样化和具有挑战性的场景中的有效性。一项综合用户研究证明了我们的方法优于现有方法，验证了其技术稳健性和实用价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in text-to-3D scene generation have demonstrated significantpotential to transform content creation across multiple industries. Althoughthe research community has made impressive progress in addressing thechallenges of this complex task, existing methods often generate environmentsthat are only front-facing, lack visual fidelity, exhibit limited sceneunderstanding, and are typically fine-tuned for either indoor or outdoorsettings. In this work, we address these issues and propose DreamAnywhere, amodular system for the fast generation and prototyping of 3D scenes. Our systemsynthesizes a 360{\deg} panoramic image from text, decomposes it intobackground and objects, constructs a complete 3D representation through hybridinpainting, and lifts object masks to detailed 3D objects that are placed inthe virtual environment. DreamAnywhere supports immersive navigation andintuitive object-level editing, making it ideal for scene exploration, visualmock-ups, and rapid prototyping -- all with minimal manual modeling. Thesefeatures make our system particularly suitable for low-budget movie production,enabling quick iteration on scene layout and visual tone without the overheadof traditional 3D workflows. Our modular pipeline is highly customizable as itallows components to be replaced independently. Compared to currentstate-of-the-art text and image-based 3D scene generation approaches,DreamAnywhere shows significant improvements in coherence in novel viewsynthesis and achieves competitive image quality, demonstrating itseffectiveness across diverse and challenging scenarios. A comprehensive userstudy demonstrates a clear preference for our method over existing approaches,validating both its technical robustness and practical usefulness.</description>
      <author>example@mail.com (Edoardo Alberto Dominici, Jozef Hladky, Floor Verhoeven, Lukas Radl, Thomas Deixelberger, Stefan Ainetter, Philipp Drescher, Stefan Hauswiesner, Arno Coomans, Giacomo Nazzaro, Konstantinos Vardis, Markus Steinberger)</author>
      <guid isPermaLink="false">2506.20367v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling</title>
      <link>http://arxiv.org/abs/2506.20512v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  26 pages; The first three authors contribute to this work equally&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在中训练策略如何影响强化学习（RL）动态，重点关注Qwen和Llama两种模型，并提出了一个两阶段的中训练策略Stable-then-Decay，以提升基础模型的RL兼容性。&lt;h4&gt;背景&lt;/h4&gt;不同的基础语言模型在强化学习后训练中表现出不同的行为，尤其是在推理密集型任务上。理解哪些基础语言模型适合强化学习对于开发下一代可扩展的RL基础模型至关重要。&lt;h4&gt;目的&lt;/h4&gt;深入探究中训练策略如何影响RL动态，为开发下一代RL可扩展的基础模型提供见解。&lt;h4&gt;方法&lt;/h4&gt;研究聚焦于Qwen和Llama两种模型，通过实验对比了不同数学语料库和QA数据对模型的影响，并提出了Stable-then-Decay中训练策略。&lt;h4&gt;主要发现&lt;/h4&gt;1. 高质量的数学语料库如MegaMath-Web-Pro能显著提升基础模型和RL性能；2. 添加QA数据，特别是长思维链（CoT）推理示例，能增强RL结果；3. 长CoT虽然提高了推理深度，但也可能导致模型响应的冗长和RL训练的不稳定性；4. 一致地扩展中训练会导致更强的下游RL性能。&lt;h4&gt;结论&lt;/h4&gt;提出的Stable-then-Decay中训练策略能够提升基础模型的RL兼容性，并缩小与更友好的RL模型家族的性能差距。研究有助于塑造RL时代的预训练策略。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates how mid-training strategies shape RL dynamics, focusing on two representative model families: Qwen and Llama. Based on these insights, a two-stage mid-training strategy, Stable-then-Decay, is introduced, in which base models are first trained on 200B tokens with a constant learning rate, followed by 20B tokens across three CoT-focused branches with learning rate decay. This leads to OctoThinker, a family of models demonstrating strong RL compatibility and closing the performance gap with more RL-friendly model families, i.e., Qwen. The study contributes to shaping pre-training strategies for foundation models in the RL era.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Different base language model families, such as Llama and Qwen, exhibitdivergent behaviors during post-training with reinforcement learning (RL),especially on reasoning-intensive tasks. What makes a base language modelsuitable for reinforcement learning? Gaining deeper insight into this questionis essential for developing RL-scalable foundation models of the nextgeneration. In this work, we investigate how mid-training strategies shape RLdynamics, focusing on two representative model families: Qwen and Llama. Ourstudy reveals that (1) high-quality mathematical corpora, such asMegaMath-Web-Pro, significantly improve both base model and RL performance,while existing alternatives (e.g., FineMath-4plus) fail to do so; (2) furtheradding QA-style data, particularly long chain-of-thought (CoT) reasoningexamples, enhances RL outcomes, and instruction data further unlocks thiseffect; (3) while long-CoT improves reasoning depth, it can also induceverbosity of model responses and unstability of RL training, underscoring theimportance of data formatting; (4) scaling mid-training consistently leads tostronger downstream RL performance. Building on these insights, we introduce atwo-stage mid-training strategy, Stable-then-Decay, in which base models arefirst trained on 200B tokens with a constant learning rate, followed by 20Btokens across three CoT-focused branches with learning rate decay. This yieldsOctoThinker, a family of models demonstrating strong RL compatibility andclosing the performance gap with more RL-friendly model families, i.e., Qwen.We hope our work will help shape pre-training strategies for foundation modelsin the RL era. To support further research, we release our open-source modelsalong with a curated math reasoning-intensive corpus of over 70 billion tokens(i.e., MegaMath-Web-Pro-Max).</description>
      <author>example@mail.com (Zengzhi Wang, Fan Zhou, Xuefeng Li, Pengfei Liu)</author>
      <guid isPermaLink="false">2506.20512v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Exploring Graph-Transformer Out-of-Distribution Generalization Abilities</title>
      <link>http://arxiv.org/abs/2506.20575v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络在分布外泛化（OOD）上的挑战，特别关注了骨干架构的影响，并通过实验证明了图变换器（GT）和混合GT-MPNN骨架在OOD设置中优于传统的消息传递神经网络（MPNNs）。&lt;h4&gt;背景&lt;/h4&gt;深度学习在图上的应用取得了显著成功，但现有方法通常假设训练和测试数据具有相同的分布，这在现实场景中很少发生。尽管图变换器（GT）在多个内部分布（ID）基准测试中优于传统的消息传递神经网络（MPNNs），但其在分布变化下的有效性仍需进一步探索。&lt;h4&gt;目的&lt;/h4&gt;本文旨在解决图神经网络在分布外泛化（OOD）上的挑战，并重点研究骨干架构的影响。&lt;h4&gt;方法&lt;/h4&gt;本文系统地评估了GT和混合骨架在OOD设置中的表现，并与MPNNs进行了比较。此外，还提出了一种新的后训练分析方法，通过比较内部分布和分布外测试数据集的聚类结构，特别研究了领域对齐和类别分离。&lt;h4&gt;主要发现&lt;/h4&gt;GT和混合GT-MPNN骨架在OOD设置中表现出比MPNNs更强的泛化能力，即使在没有专门领域泛化（DG）算法的情况下也是如此。&lt;h4&gt;结论&lt;/h4&gt;本文的研究结果表明，图变换器对于鲁棒的、现实世界的图学习具有巨大潜力，并为未来在OOD泛化方向上的研究指明了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在图上的深度学习在各种应用中表现出色，包括社交网络、生物物理、交通网络和推荐系统。尽管它们取得了成功，但当前方法通常依赖于训练和测试数据具有相同分布的假设，而在现实场景中这种条件很少得到满足。尽管图变换器（GT）最近在多个内部分布（ID）基准测试中优于传统的消息传递神经网络（MPNNs），但它们在分布变化下的有效性仍然没有得到充分探索。在这项工作中，我们针对图神经网络在分布外（OOD）泛化上的挑战进行了研究，特别关注骨干架构的影响。我们系统地评估了GT和混合骨架在OOD设置中的表现，并将它们与MPNNs进行了比较。为此，我们将几种领先的领域泛化（DG）算法改编为与GT一起工作，并评估了它们在测试各种分布变化的基准上的性能。我们的结果表明，GT和混合GT-MPNN骨架在OOD设置中表现出比MPNNs更强的泛化能力，即使在没有专门的DG算法的情况下也是如此。此外，我们还提出了一种新的后训练分析方法，通过比较内部分布和分布外测试数据集的聚类结构，特别是检查领域对齐和类别分离。这种模型无关的设计不仅为GT和MPNN骨架提供了有意义的见解，而且也显示出对领域泛化问题（超出图学习之外）的更广泛适用性的承诺，提供了超越标准准确度指标的泛化能力的更深入视角。总之，我们的研究结果突出了图变换器在鲁棒的、现实世界的图学习中的潜力，并为未来在OOD泛化方面的研究设定了新的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning on graphs has shown remarkable success across numerousapplications, including social networks, bio-physics, traffic networks, andrecommendation systems. Regardless of their successes, current methodsfrequently depend on the assumption that training and testing data share thesame distribution, a condition rarely met in real-world scenarios. Whilegraph-transformer (GT) backbones have recently outperformed traditionalmessage-passing neural networks (MPNNs) in multiple in-distribution (ID)benchmarks, their effectiveness under distribution shifts remains largelyunexplored.  In this work, we address the challenge of out-of-distribution (OOD)generalization for graph neural networks, with a special focus on the impact ofbackbone architecture. We systematically evaluate GT and hybrid backbones inOOD settings and compare them to MPNNs. To do so, we adapt several leadingdomain generalization (DG) algorithms to work with GTs and assess theirperformance on a benchmark designed to test a variety of distribution shifts.Our results reveal that GT and hybrid GT-MPNN backbones consistentlydemonstrate stronger generalization ability compared to MPNNs, even withoutspecialized DG algorithms.  Additionally, we propose a novel post-training analysis approach thatcompares the clustering structure of the entire ID and OOD test datasets,specifically examining domain alignment and class separation. Demonstrating itsmodel-agnostic design, this approach not only provided meaningful insights intoGT and MPNN backbones. It also shows promise for broader applicability to DGproblems beyond graph learning, offering a deeper perspective on generalizationabilities that goes beyond standard accuracy metrics. Together, our findingshighlight the promise of graph-transformers for robust, real-world graphlearning and set a new direction for future research in OOD generalization.</description>
      <author>example@mail.com (Itay Niv, Neta Rabin)</author>
      <guid isPermaLink="false">2506.20575v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach</title>
      <link>http://arxiv.org/abs/2506.20323v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究开发了一个由人工智能驱动的作物病害检测系统，旨在帮助资源有限的农村地区农民。系统通过比较不同的深度学习模型，重点关注其在迁移学习中的有效性，实现了对植物病害的有效分类。&lt;h4&gt;背景&lt;/h4&gt;农村地区农民往往面临资源限制，需要一种高效的方法来检测作物病害。&lt;h4&gt;目的&lt;/h4&gt;开发一个基于人工智能的作物病害检测系统，并比较不同深度学习模型在迁移学习中的效果。&lt;h4&gt;方法&lt;/h4&gt;研究使用了包括EfficientNet、ResNet101、MobileNetV2和自定义卷积神经网络（CNN）在内的深度学习模型，并通过验证准确率达到了95.76%。&lt;h4&gt;主要发现&lt;/h4&gt;研究证明了迁移学习在改变农业实践、改善作物健康管理以及支持农村环境的可持续农业中的潜力。&lt;h4&gt;结论&lt;/h4&gt;所开发的系统在迁移学习方面表现出色，有望为农村地区提供有效的作物病害检测手段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research presents the development of an Artificial Intelligence (AI) -driven crop disease detection system designed to assist farmers in rural areaswith limited resources. We aim to compare different deep learning models for acomparative analysis, focusing on their efficacy in transfer learning. Byleveraging deep learning models, including EfficientNet, ResNet101,MobileNetV2, and our custom CNN, which achieved a validation accuracy of95.76%, the system effectively classifies plant diseases. This researchdemonstrates the potential of transfer learning in reshaping agriculturalpractices, improving crop health management, and supporting sustainable farmingin rural environments.</description>
      <author>example@mail.com (Saundarya Subramaniam, Shalini Majumdar, Shantanu Nadar, Kaustubh Kulkarni)</author>
      <guid isPermaLink="false">2506.20323v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Representation Learning and Fusion</title>
      <link>http://arxiv.org/abs/2506.20494v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;多模态学习是人工智能领域快速发展的一个分支，通过结合图像、文本和音频等不同来源的信息，帮助机器理解复杂事物，并增强AI系统的内部表示，提高其在现实生活中的理解和决策能力。&lt;h4&gt;背景&lt;/h4&gt;多模态学习旨在通过融合不同模态的信息，帮助机器更好地理解和处理复杂情况。&lt;h4&gt;目的&lt;/h4&gt;多模态学习的目的是提高AI系统的理解和决策能力，使其在现实世界中的应用更加灵活、上下文感知并能处理复杂问题。&lt;h4&gt;方法&lt;/h4&gt;多模态学习方法包括代表学习（从不同数据类型中获取共享特征）、对齐方法（匹配跨模态信息）和融合策略（通过深度学习模型结合信息）。&lt;h4&gt;主要发现&lt;/h4&gt;尽管多模态学习取得了一定的进展，但仍存在一些主要问题，如处理不同数据格式、缺失或不完整输入以及防御对抗攻击。研究者正在探索新的方法，如无监督或半监督学习、AutoML工具等，以提高模型效率并简化扩展。同时，更注重设计更好的评估指标或建立共享基准，以便跨任务和领域比较模型性能。&lt;h4&gt;结论&lt;/h4&gt;随着多模态学习领域的持续发展，预计将改善计算机视觉、自然语言处理、语音识别和医疗保健等多个领域。未来，它可能有助于构建更接近人类理解世界的AI系统，具有灵活性、上下文感知和应对现实世界复杂性的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal learning is a fast growing area in artificial intelligence. Ittries to help machines understand complex things by combining information fromdifferent sources, like images, text, and audio. By using the strengths of eachmodality, multi-modal learning allows AI systems to build stronger and richerinternal representations. These help machines better interpretation, reasoning,and making decisions in real-life situations. This field includes coretechniques such as representation learning (to get shared features fromdifferent data types), alignment methods (to match information acrossmodalities), and fusion strategies (to combine them by deep learning models).Although there has been good progress, some major problems still remain. Likedealing with different data formats, missing or incomplete inputs, anddefending against adversarial attacks. Researchers now are exploring newmethods, such as unsupervised or semi-supervised learning, AutoML tools, tomake models more efficient and easier to scale. And also more attention ondesigning better evaluation metrics or building shared benchmarks, make iteasier to compare model performance across tasks and domains. As the fieldcontinues to grow, multi-modal learning is expected to improve many areas:computer vision, natural language processing, speech recognition, andhealthcare. In the future, it may help to build AI systems that can understandthe world in a way more like humans, flexible, context aware, and able to dealwith real-world complexity.</description>
      <author>example@mail.com (Qihang Jin, Enze Ge, Yuhang Xie, Hongying Luo, Junhao Song, Ziqian Bi, Chia Xin Liang, Jibin Guan, Joe Yeong, Junfeng Hao)</author>
      <guid isPermaLink="false">2506.20494v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration</title>
      <link>http://arxiv.org/abs/2506.19975v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for publication at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VoxelOpt是一种基于离散优化的DIR框架，结合了学习方法和迭代方法的优点，在注册精度和运行时间之间取得了更好的平衡。&lt;h4&gt;背景&lt;/h4&gt;神经网络的最新进展提高了DIR的准确性，但学习方法在训练数据有限、大变形以及无标签监督的情况下往往表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出VoxelOpt以解决学习方法和迭代方法在DIR中的局限性。&lt;h4&gt;方法&lt;/h4&gt;VoxelOpt使用位移熵来测量每个体素的位移信号强度，并引入了体素级的自适应消息传递、多级图像金字塔和预训练的基础分割模型。&lt;h4&gt;主要发现&lt;/h4&gt;在腹部CT注册中，VoxelOpt在效率和精度方面优于领先的迭代方法，同时与使用标签监督训练的顶级学习方法相当。&lt;h4&gt;结论&lt;/h4&gt;VoxelOpt是一个有效的DIR框架，它结合了学习方法和迭代方法的优点，提高了DIR的准确性和效率。&lt;h4&gt;翻译&lt;/h4&gt;Recent developments in neural networks have improved deformable imageregistration (DIR) by amortizing iterative optimization, enabling fast and accurate DIR results. However, learning-based methods often face challenges with limited training data, large deformations, and tend to underperform compared to iterative approaches when label supervision is unavailable. While iterative methods can achieve higher accuracy in such scenarios, they are considerably slower than learning-based methods. To address these limitations, we propose VoxelOpt, a discrete optimization-based DIR framework that combines the strengths of learning-based and iterative methods to achieve a better balance between registration accuracy and runtime. VoxelOpt uses displacement entropy from local cost volumes to measure displacement signal strength at each voxel, which differs from earlier approaches in three key aspects. First, it introduces voxel-wise adaptive message passing, where voxels with lower entropy receive less influence from their neighbors. Second, it employs a multi-level image pyramid with 27-neighbor cost volumes at each level, avoiding exponential complexity growth. Third, it replaces hand-crafted features or contrastive learning with a pretrained foundational segmentation model for feature extraction. In abdominal CT registration, these changes allow VoxelOpt to outperform leading iterative in both efficiency and accuracy, while matching state-of-the-art learning-based methods trained with label supervision. The source code will be available at https://github.com/tinymilky/VoxelOpt&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent developments in neural networks have improved deformable imageregistration (DIR) by amortizing iterative optimization, enabling fast andaccurate DIR results. However, learning-based methods often face challengeswith limited training data, large deformations, and tend to underperformcompared to iterative approaches when label supervision is unavailable. Whileiterative methods can achieve higher accuracy in such scenarios, they areconsiderably slower than learning-based methods. To address these limitations,we propose VoxelOpt, a discrete optimization-based DIR framework that combinesthe strengths of learning-based and iterative methods to achieve a betterbalance between registration accuracy and runtime. VoxelOpt uses displacemententropy from local cost volumes to measure displacement signal strength at eachvoxel, which differs from earlier approaches in three key aspects. First, itintroduces voxel-wise adaptive message passing, where voxels with lower entropyreceives less influence from their neighbors. Second, it employs a multi-levelimage pyramid with 27-neighbor cost volumes at each level, avoiding exponentialcomplexity growth. Third, it replaces hand-crafted features or contrastivelearning with a pretrained foundational segmentation model for featureextraction. In abdominal CT registration, these changes allow VoxelOpt tooutperform leading iterative in both efficiency and accuracy, while matchingstate-of-the-art learning-based methods trained with label supervision. Thesource code will be available at https://github.com/tinymilky/VoxelOpt</description>
      <author>example@mail.com (Hang Zhang, Yuxi Zhang, Jiazheng Wang, Xiang Chen, Renjiu Hu, Xin Tian, Gaolei Li, Min Liu)</author>
      <guid isPermaLink="false">2506.19975v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners</title>
      <link>http://arxiv.org/abs/2506.20464v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了在地下矿井中利用移动激光扫描器获取的中到大规模3D点云自动识别岩石锚杆的方法，提出了一种名为DeepBolt的新方法，通过改进的深度学习架构，提高了锚杆识别的精度和效率。&lt;h4&gt;背景&lt;/h4&gt;岩石锚杆是地下矿井支撑系统中的关键组成部分，其稳定性对于预防岩体滑坡等意外事故至关重要。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过自动化检测岩石锚杆，来解决传统手动检测的困难，如井下光线昏暗和过程耗时。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为DeepBolt的两阶段深度学习架构，用于处理大规模3D点云中的岩石锚杆自动识别，特别针对数据噪声、多变环境和复杂周围结构的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;DeepBolt方法在岩石锚杆点上的Intersection over Union（IoU）达到了42.5%的提升，且在分类岩石锚杆时，精度和召回率分别达到96.41%和96.96%。&lt;h4&gt;结论&lt;/h4&gt;DeepBolt方法在复杂地下环境中展现出其鲁棒性和有效性，显著优于现有的岩石锚杆识别技术。&lt;h4&gt;翻译&lt;/h4&gt;摘要：岩石锚杆是地下矿井地下支撑系统的关键组成部分，为岩体提供足够的结构加固，以防止意外灾害如岩崩。这使得对这种锚杆的频繁评估对于维持岩体稳定性以及降低地下开采风险至关重要。由于井下光线昏暗和过程耗时，手动检测岩石锚杆具有挑战性，因此自动检测岩石锚杆成为了一种可行的解决方案。为此，本研究专注于使用移动激光扫描器从地下矿井获取的中到大规模3D点云中自动识别岩石锚杆。现有的自动岩石锚杆识别技术主要依赖于特征工程和传统的机器学习方法。然而，由于这些点云存在数据噪声、多变环境和复杂周围结构等问题，这些方法缺乏鲁棒性。此外，目标岩石锚杆在大规模点云中是极其微小的物体，通常由于加固喷射混凝土的应用而部分被遮挡。为了解决这些挑战，本文提出了一种名为DeepBolt的方法，该方法采用了一种新颖的两阶段深度学习架构，专门用于处理严重类别不平衡，以自动和高效地识别复杂3D点云中的岩石锚杆。所提出的方法在岩石锚杆点上的Intersection over Union（IoU）方面优于现有最先进的语义分割模型高达42.5%。此外，它在分类岩石锚杆时，实现了96.41%的精度和96.96%的召回率，证明了其在复杂地下环境中的鲁棒性和有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rock bolts are crucial components of the subterranean support systems inunderground mines that provide adequate structural reinforcement to the rockmass to prevent unforeseen hazards like rockfalls. This makes frequentassessments of such bolts critical for maintaining rock mass stability andminimising risks in underground mining operations. Where manual surveying ofrock bolts is challenging due to the low light conditions in the undergroundmines and the time-intensive nature of the process, automated detection of rockbolts serves as a plausible solution. To that end, this study focuses on theautomatic identification of rock bolts within medium to large-scale 3D pointclouds obtained from underground mines using mobile laser scanners. Existingtechniques for automated rock bolt identification primarily rely on featureengineering and traditional machine learning approaches. However, suchtechniques lack robustness as these point clouds present several challenges dueto data noise, varying environments, and complex surrounding structures.Moreover, the target rock bolts are extremely small objects within large-scalepoint clouds and are often partially obscured due to the application ofreinforcement shotcrete. Addressing these challenges, this paper proposes anapproach termed DeepBolt, which employs a novel two-stage deep learningarchitecture specifically designed for handling severe class imbalance for theautomatic and efficient identification of rock bolts in complex 3D pointclouds. The proposed method surpasses state-of-the-art semantic segmentationmodels by up to 42.5% in Intersection over Union (IoU) for rock bolt points.Additionally, it outperforms existing rock bolt identification techniques,achieving a 96.41% precision and 96.96% recall in classifying rock bolts,demonstrating its robustness and effectiveness in complex undergroundenvironments.</description>
      <author>example@mail.com (Dibyayan Patra, Pasindu Ranasinghe, Bikram Banerjee, Simit Raval)</author>
      <guid isPermaLink="false">2506.20464v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment</title>
      <link>http://arxiv.org/abs/2506.20303v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FundaQ-8的专家验证框架，用于系统地评估眼底图像质量，并开发了一个基于ResNet18的回归模型来预测图像质量分数，同时验证了该框架在临床诊断中的可靠性。&lt;h4&gt;背景&lt;/h4&gt;由于图像采集和主观专家评估的差异，自动眼底图像质量评估（FIQA）仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架和模型来系统地评估眼底图像质量，并提高糖尿病视网膜病变诊断的准确性。&lt;h4&gt;方法&lt;/h4&gt;FundaQ-8框架基于八个关键参数（如视野覆盖、解剖可见性、照明和图像伪影）进行评估。使用FundaQ-8作为结构化评分参考，开发了一个基于ResNet18的回归模型。模型在1800张真实临床来源和Kaggle数据集的图像上训练，采用了迁移学习、均方误差优化和标准化预处理。&lt;h4&gt;主要发现&lt;/h4&gt;FundaQ-8框架的可靠性得到了EyeQ数据集的验证和统计分析的确认。将FundaQ-8集成到深度学习模型中用于糖尿病视网膜病变分级，也提高了诊断的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;FundaQ-8框架和基于ResNet18的模型在提高眼底图像质量评估和糖尿病视网膜病变诊断的准确性方面具有价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated fundus image quality assessment (FIQA) remains a challenge due tovariations in image acquisition and subjective expert evaluations. We introduceFundaQ-8, a novel expert-validated framework for systematically assessingfundus image quality using eight critical parameters, including field coverage,anatomical visibility, illumination, and image artifacts. Using FundaQ-8 as astructured scoring reference, we develop a ResNet18-based regression model topredict continuous quality scores in the 0 to 1 range. The model is trained on1800 fundus images from real-world clinical sources and Kaggle datasets, usingtransfer learning, mean squared error optimization, and standardizedpreprocessing. Validation against the EyeQ dataset and statistical analysesconfirm the framework's reliability and clinical interpretability.Incorporating FundaQ-8 into deep learning models for diabetic retinopathygrading also improves diagnostic robustness, highlighting the value ofquality-aware training in real-world screening applications.</description>
      <author>example@mail.com (Lee Qi Zun, Oscar Wong Jin Hao, Nor Anita Binti Che Omar, Zalifa Zakiah Binti Asnir, Mohamad Sabri bin Sinal Zainal, Goh Man Fye)</author>
      <guid isPermaLink="false">2506.20303v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning</title>
      <link>http://arxiv.org/abs/2506.20394v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了在线更新服务机器人通过多种方式获取的信息，包括几何和语义数据，并介绍了一种名为SPARK的框架，用于从环境嵌入的线索中提取语义信息并更新场景图，以支持动态环境中的任务规划和适应非传统空间线索。&lt;h4&gt;背景&lt;/h4&gt;在任务执行过程中，服务机器人需要更新通过在线方式获取的信息，包括几何和语义数据。SLAM可以处理二维地图或三维点云的几何更新，但在线更新语义信息尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究在线语义信息的图表示，并开发一种能够处理在线场景图表示的框架。&lt;h4&gt;方法&lt;/h4&gt;基于离线场景图表示的研究，本文提出了SPARK框架，该框架能够从环境嵌入的线索中提取语义信息并更新场景图，进而用于后续的任务规划。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，空间关系的图表示可以增强机器人系统在动态环境中执行任务的能力，并适应诸如手势等非传统空间线索。&lt;h4&gt;结论&lt;/h4&gt;SPARK框架能够有效更新语义信息，并提高机器人在动态环境中的任务执行能力和适应性。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了服务机器人在任务执行过程中通过多种在线方式获取的信息更新能力，包括几何和语义数据。虽然SLAM可以处理二维地图或三维点云的几何更新，但在线更新语义信息仍是一个未充分探索的领域。本文基于离线场景图表示的研究，提出了SPARK框架，该框架能够从环境嵌入的线索中提取语义信息并相应地更新场景图，进而用于后续的任务规划。研究结果表明，空间关系的图表示可以增强机器人系统在动态环境中执行任务的能力，并适应诸如手势等非传统空间线索。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The ability to update information acquired through various means onlineduring task execution is crucial for a general-purpose service robot. Thisinformation includes geometric and semantic data. While SLAM handles geometricupdates on 2D maps or 3D point clouds, online updates of semantic informationremain unexplored. We attribute the challenge to the online scene graphrepresentation, for its utility and scalability. Building on previous worksregarding offline scene graph representations, we study online graphrepresentations of semantic information in this work. We introduce SPARK:Spatial Perception and Robot Knowledge Integration. This framework extractssemantic information from environment-embedded cues and updates the scene graphaccordingly, which is then used for subsequent task planning. We demonstratethat graph representations of spatial relationships enhance the robot system'sability to perform tasks in dynamic environments and adapt to unconventionalspatial cues, like gestures.</description>
      <author>example@mail.com (Mimo Shirasaka, Yuya Ikeda, Tatsuya Matsushima, Yutaka Matsuo, Yusuke Iwasawa)</author>
      <guid isPermaLink="false">2506.20394v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Behavior Foundation Model: Towards Next-Generation Whole-Body Control System of Humanoid Robots</title>
      <link>http://arxiv.org/abs/2506.20487v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了行为基础模型（BFMs）在类人机器人全身体重控制（WBC）中的应用，探讨了其发展历程、实际应用、当前局限性、挑战和未来机遇。&lt;h4&gt;背景&lt;/h4&gt;类人机器人在复杂运动控制、人机交互和通用物理智能领域受到广泛关注，但实现高效的全身体重控制仍面临挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍BFMs在类人机器人全身体重控制中的应用，并展望其未来发展。&lt;h4&gt;方法&lt;/h4&gt;通过分析不同预训练管道，对BFMs的发展进行综述，并讨论其在实际应用中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;BFMs通过大规模预训练学习可重用的基本技能和行为先验，实现了零样本或快速适应多种下游任务。&lt;h4&gt;结论&lt;/h4&gt;BFMs是向可扩展和通用的人形智能迈进的关键方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：类人机器人在复杂运动控制、人机交互和通用物理智能方面引起了广泛关注。然而，由于复杂的动力学、欠驱动和多样化的任务需求，实现类人机器人的高效全身体重控制（WBC）仍然是一个基本挑战。尽管基于学习的控制器在复杂任务中显示出希望，但它们对新场景的依赖性在于劳动密集型和昂贵的再培训，限制了其现实世界的适用性。为了解决这些限制，行为基础模型（BFMs）作为一种新的范例已经出现，它利用大规模预训练来学习可重用的基本技能和行为先验，使得能够零样本或快速适应广泛的后台任务。在本文中，我们提出对BFMs用于类人机器人WBC的全面概述，追溯其在不同预训练管道中的发展。此外，我们讨论了现实世界的应用、当前限制、紧迫挑战和未来机遇，将BFMs定位为向可扩展和通用的人形智能迈进的关键方法。最后，我们提供了一个精心策划的长期列表的BFM论文和项目，以促进后续研究，该列表可在https://github.com/yuanmingqi/awesome-bfm-papers上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humanoid robots are drawing significant attention as versatile platforms forcomplex motor control, human-robot interaction, and general-purpose physicalintelligence. However, achieving efficient whole-body control (WBC) inhumanoids remains a fundamental challenge due to sophisticated dynamics,underactuation, and diverse task requirements. While learning-based controllershave shown promise for complex tasks, their reliance on labor-intensive andcostly retraining for new scenarios limits real-world applicability. To addressthese limitations, behavior(al) foundation models (BFMs) have emerged as a newparadigm that leverages large-scale pretraining to learn reusable primitiveskills and behavioral priors, enabling zero-shot or rapid adaptation to a widerange of downstream tasks. In this paper, we present a comprehensive overviewof BFMs for humanoid WBC, tracing their development across diverse pre-trainingpipelines. Furthermore, we discuss real-world applications, currentlimitations, urgent challenges, and future opportunities, positioning BFMs as akey approach toward scalable and general-purpose humanoid intelligence.Finally, we provide a curated and long-term list of BFM papers and projects tofacilitate more subsequent research, which is available athttps://github.com/yuanmingqi/awesome-bfm-papers.</description>
      <author>example@mail.com (Mingqi Yuan, Tao Yu, Wenqi Ge, Xiuyong Yao, Dapeng Li, Huijiang Wang, Jiayu Chen, Xin Jin, Bo Li, Hua Chen, Wei Zhang, Wenjun Zeng)</author>
      <guid isPermaLink="false">2506.20487v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Adaptive Supergeo Design: A Scalable Framework for Geographic Marketing Experiments</title>
      <link>http://arxiv.org/abs/2506.20499v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为自适应超级地理设计（ASD）的框架，用于大规模测量广告支出的增量回报率（iROAS），解决了地理实验设计中的挑战。&lt;h4&gt;背景&lt;/h4&gt;地理实验在测量iROAS方面是金标准，但其设计具有挑战性，因为单位数量少，异质性大，且最优超级地理分区问题为NP-hard。&lt;h4&gt;目的&lt;/h4&gt;设计一种可行的框架，使超级地理设计适用于成千上万的地区。&lt;h4&gt;方法&lt;/h4&gt;ASD采用两阶段框架：首先，通过定制图神经网络学习地理嵌入并提出一个简洁的候选“超级地理”集合；其次，使用CP-SAT求解器选择一个分区，平衡基线结果和预处理的协变量，这些协变量被认为会改变治疗效果。&lt;h4&gt;主要发现&lt;/h4&gt;在轻微的社区结构假设下，ASD的目标值在全局最优解的(1+epsilon)范围内。模拟结果表明，在标准硬件上，ASD可以在几分钟内完成，保留所有媒体美元，并将iROAS偏差显著降低。&lt;h4&gt;结论&lt;/h4&gt;ASD将地理提升测试转变为媒体规划的常规、可扩展组件，同时保持了统计严谨性。&lt;h4&gt;翻译&lt;/h4&gt;Geographic experiments are a gold-standard for measuring incremental return-on ad spend (iROAS) at scale, yet their design is challenging: the unit count is small, heterogeneity is large, and the optimal Supergeo partitioning problem is NP-hard. We introduce Adaptive Supergeo Design (ASD), a two-stage framework that renders Supergeo designs practical for thousands of markets. A bespoke graph-neural network first learns geo-embeddings and proposes a concise candidate set of 'supergeos'; a CP-SAT solver then selects a partition that balances both baseline outcomes and pre-treatment covariates believed to modify the treatment effect. We prove that ASD's objective value is within (1+epsilon) of the global optimum under mild community-structure assumptions. In simulations with up to 1,000 Designated Market Areas ASD completes in minutes on standard hardware, retains every media dollar, and cuts iROAS bias substantially relative to existing methods. ASD therefore turns geo-lift testing into a routine, scalable component of media planning while preserving statistical rigour.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Geographic experiments are a gold-standard for measuring incremental returnon ad spend (iROAS) at scale, yet their design is challenging: the unit countis small, heterogeneity is large, and the optimal Supergeo partitioning problemis NP-hard. We introduce Adaptive Supergeo Design (ASD), a two-stage frameworkthat renders Supergeo designs practical for thousands of markets. A bespokegraph-neural network first learns geo-embeddings and proposes a concisecandidate set of 'supergeos'; a CP-SAT solver then selects a partition thatbalances both baseline outcomes and pre-treatment covariates believed to modifythe treatment effect. We prove that ASD's objective value is within (1+epsilon)of the global optimum under mild community-structure assumptions. Insimulations with up to 1,000 Designated Market Areas ASD completes in minuteson standard hardware, retains every media dollar, and cuts iROAS biassubstantively relative to existing methods. ASD therefore turns geo-lifttesting into a routine, scalable component of media planning while preservingstatistical rigour.</description>
      <author>example@mail.com (Charles Shaw)</author>
      <guid isPermaLink="false">2506.20499v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning</title>
      <link>http://arxiv.org/abs/2506.20324v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Permutation Equivariant Neural Graph CDEs，这是一种高效的图神经网络模型，在模拟动态系统和真实世界任务中表现出色。&lt;h4&gt;背景&lt;/h4&gt;动态图因为节点特征和网络结构的演变而展现出复杂的时序动力学。&lt;h4&gt;目的&lt;/h4&gt;将Graph Neural CDEs投影到置换等变函数空间，以减少模型参数数量，同时保持其表示能力，从而提高训练效率和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;引入Permutation Equivariant Neural Graph CDEs，并通过对模拟动态系统和真实世界任务的实验来验证其优势。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在插值和外推场景中均表现出改进的性能。&lt;h4&gt;结论&lt;/h4&gt;Permutation Equivariant Neural Graph CDEs是一种高效且有效的图神经网络模型，在处理动态图时具有显著优势。&lt;h4&gt;翻译&lt;/h4&gt;Dynamic graphs exhibit complex temporal dynamics due to the interplay between evolving node features and changing network structures. Recently, Graph Neural Controlled Differential Equations (Graph Neural CDEs) successfully adapted Neural CDEs from paths on Euclidean domains to paths on graph domains. Building on this foundation, we introduce Permutation Equivariant Neural Graph CDEs, which project Graph Neural CDEs onto permutation equivariant function spaces. This significantly reduces the model's parameter count without compromising representational power, resulting in more efficient training and improved generalisation. We empirically demonstrate the advantages of our approach through experiments on simulated dynamical systems and real-world tasks, showing improved performance in both interpolation and extrapolation scenarios.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dynamic graphs exhibit complex temporal dynamics due to the interplay betweenevolving node features and changing network structures. Recently, Graph NeuralControlled Differential Equations (Graph Neural CDEs) successfully adaptedNeural CDEs from paths on Euclidean domains to paths on graph domains. Buildingon this foundation, we introduce Permutation Equivariant Neural Graph CDEs,which project Graph Neural CDEs onto permutation equivariant function spaces.This significantly reduces the model's parameter count without compromisingrepresentational power, resulting in more efficient training and improvedgeneralisation. We empirically demonstrate the advantages of our approachthrough experiments on simulated dynamical systems and real-world tasks,showing improved performance in both interpolation and extrapolation scenarios.</description>
      <author>example@mail.com (Torben Berndt, Benjamin Walker, Tiexin Qin, Jan Stühmer, Andrey Kormilitzin)</author>
      <guid isPermaLink="false">2506.20324v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Counterfactual Influence as a Distributional Quantity</title>
      <link>http://arxiv.org/abs/2506.20481v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Workshop on The Impact of Memorization on Trustworthy Foundation  Models (MemFM) @ ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了机器学习模型的记忆化问题，发现仅通过自我影响来衡量记忆化会严重低估实际风险，并提出全影响分布更能捕捉记忆化的复杂交互。&lt;h4&gt;背景&lt;/h4&gt;机器学习模型存在记忆化问题，可能导致隐私泄露和泛化能力下降。&lt;h4&gt;目的&lt;/h4&gt;研究记忆化问题，并探索更全面的衡量方法。&lt;h4&gt;方法&lt;/h4&gt;将反事实影响视为分布量，考虑所有训练样本对样本记忆化的影响，并分析其对语言模型和图像分类的影响。&lt;h4&gt;主要发现&lt;/h4&gt;仅考虑自我影响会低估风险，存在（近）重复样本会降低自我影响，但这些样本可能被提取。&lt;h4&gt;结论&lt;/h4&gt;记忆化源于训练数据之间的复杂交互，全影响分布比自我影响更能全面地捕捉记忆化。&lt;h4&gt;翻译&lt;/h4&gt;摘要：机器学习模型因记忆化样本而闻名，这引发了隐私和泛化方面的担忧。反事实自我影响是衡量记忆化的流行指标，量化了模型的预测随样本是否包含在训练数据集中而变化的情况。然而，最近的研究表明，记忆化受到自我影响以外的因素的影响，特别是其他训练样本，尤其是（近）重复样本，有重大影响。在这里，我们将记忆化研究为分布量，将反事实影响作为分布量，考虑所有训练样本如何影响样本的记忆化。对于一个小型语言模型，我们计算了训练样本对彼此的完整影响分布，并分析了其属性。我们发现，仅通过自我影响来看会严重低估与记忆化相关的实际风险：存在（近）重复样本会严重降低自我影响，而我们认为这些样本是（近）可提取的。我们在图像分类中也观察到类似的模式，即简单地查看影响分布揭示了CIFAR-10中存在近重复样本。我们的发现强调，记忆化源于训练数据之间的复杂交互，比单独的自我影响更能被全影响分布所捕捉。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Machine learning models are known to memorize samples from their trainingdata, raising concerns around privacy and generalization. Counterfactualself-influence is a popular metric to study memorization, quantifying how themodel's prediction for a sample changes depending on the sample's inclusion inthe training dataset. However, recent work has shown memorization to beaffected by factors beyond self-influence, with other training samples, inparticular (near-)duplicates, having a large impact. We here study memorizationtreating counterfactual influence as a distributional quantity, taking intoaccount how all training samples influence how a sample is memorized. For asmall language model, we compute the full influence distribution of trainingsamples on each other and analyze its properties. We find that solely lookingat self-influence can severely underestimate tangible risks associated withmemorization: the presence of (near-)duplicates seriously reducesself-influence, while we find these samples to be (near-)extractable. Weobserve similar patterns for image classification, where simply looking at theinfluence distributions reveals the presence of near-duplicates in CIFAR-10.Our findings highlight that memorization stems from complex interactions acrosstraining data and is better captured by the full influence distribution than byself-influence alone.</description>
      <author>example@mail.com (Matthieu Meeus, Igor Shilov, Georgios Kaissis, Yves-Alexandre de Montjoye)</author>
      <guid isPermaLink="false">2506.20481v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations</title>
      <link>http://arxiv.org/abs/2506.20362v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  LaplaceGNN is a novel graph learning framework that employs a  bootstrapped teacher-student architecture. Its precomputed spectral  augmentations and adversarial training enable robust performance,  outperforming SOTA methods while scaling linearly&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了LaplaceGNN，这是一种新的自监督图学习框架，通过利用频谱引导技术避免负采样需求，有效地捕捉丰富的结构表示，同时提供了一种简单、高效的图神经网络自监督方法。&lt;h4&gt;背景&lt;/h4&gt;现有图学习方法依赖负采样或手工增强，限制了模型的性能和泛化能力。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需负采样且效率更高的自监督图学习框架。&lt;h4&gt;方法&lt;/h4&gt;LaplaceGNN通过将基于拉普拉斯的信号整合到学习过程中，使用频谱增强技术进行预计算，并结合对抗性引导训练方案以增强特征学习和鲁棒性。&lt;h4&gt;主要发现&lt;/h4&gt;LaplaceGNN在多个基准数据集上实现了比最先进的自监督图学习方法更优的性能。&lt;h4&gt;结论&lt;/h4&gt;LaplaceGNN为高效学习可表达图表示提供了一个有希望的方向，并提供了一种简单、高效的图神经网络自监督方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present LaplaceGNN, a novel self-supervised graph learning framework thatbypasses the need for negative sampling by leveraging spectral bootstrappingtechniques. Our method integrates Laplacian-based signals into the learningprocess, allowing the model to effectively capture rich structuralrepresentations without relying on contrastive objectives or handcraftedaugmentations. By focusing on positive alignment, LaplaceGNN achieves linearscaling while offering a simpler, more efficient, self-supervised alternativefor graph neural networks, applicable across diverse domains. Our contributionsare twofold: we precompute spectral augmentations through max-mincentrality-guided optimization, enabling rich structural supervision withoutrelying on handcrafted augmentations, then we integrate an adversarialbootstrapped training scheme that further strengthens feature learning androbustness. Our extensive experiments on different benchmark datasets show thatLaplaceGNN achieves superior performance compared to state-of-the-artself-supervised graph methods, offering a promising direction for efficientlylearning expressive graph representations.</description>
      <author>example@mail.com (Lorenzo Bini, Stephane Marchand-Maillet)</author>
      <guid isPermaLink="false">2506.20362v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management</title>
      <link>http://arxiv.org/abs/2506.20388v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于大型视觉基础模型（LVFM）的高分辨率冠层高度图（CHM）生成新模型，用于准确、经济地监测人工林地上生物量（AGB），支持当地生计和碳汇项目。&lt;h4&gt;背景&lt;/h4&gt;精确、经济地监测人工林地上生物量对于支持当地生计和碳汇项目（如中国的CCER项目）至关重要。高分辨率冠层高度图对于此目的至关重要，但基于激光雷达的标准方法成本高昂。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的模型，使用大型视觉基础模型（LVFM）生成高分辨率冠层高度图，以准确、经济地监测人工林地上生物量。&lt;h4&gt;方法&lt;/h4&gt;该模型集成了特征提取器、一个自监督特征增强模块以保留空间细节，以及一个高度估算器。使用1米分辨率的Google Earth图像在北京房山区进行了测试。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在房山区测试中优于现有方法，包括传统的卷积神经网络（CNN）。它达到了0.09米的平均绝对误差、0.24米的均方根误差和0.78的相关性。生成的CHM实现了超过90%的个体树检测成功率，在AGB估算中具有高精度，并有效地跟踪了人工林的生长，证明了其在非训练区域中的强大泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该方法为评估人工林和天然林中的碳汇提供了有希望且可扩展的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate, cost-effective monitoring of plantation aboveground biomass (AGB)is crucial for supporting local livelihoods and carbon sequestrationinitiatives like the China Certified Emission Reduction (CCER) program.High-resolution canopy height maps (CHMs) are essential for this, but standardlidar-based methods are expensive. While deep learning with RGB imagery offersan alternative, accurately extracting canopy height features remainschallenging. To address this, we developed a novel model for high-resolutionCHM generation using a Large Vision Foundation Model (LVFM). Our modelintegrates a feature extractor, a self-supervised feature enhancement module topreserve spatial details, and a height estimator. Tested in Beijing's FangshanDistrict using 1-meter Google Earth imagery, our model outperformed existingmethods, including conventional CNNs. It achieved a mean absolute error of 0.09m, a root mean square error of 0.24 m, and a correlation of 0.78 againstlidar-based CHMs. The resulting CHMs enabled over 90% success in individualtree detection, high accuracy in AGB estimation, and effective tracking ofplantation growth, demonstrating strong generalization to non-training areas.This approach presents a promising, scalable tool for evaluating carbonsequestration in both plantations and natural forests.</description>
      <author>example@mail.com (Shen Tan, Xin Zhang, Liangxiu Han, Huaguo Huang, Han Wang)</author>
      <guid isPermaLink="false">2506.20388v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Forensic Study of Paintings Through the Comparison of Fabrics</title>
      <link>http://arxiv.org/abs/2506.20272v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的艺术作品画布织物研究方法，用于认证、归因和保护。&lt;h4&gt;背景&lt;/h4&gt;传统的画布织物研究方法依赖于线密度图匹配，但当画布不是来自连续的卷轴位置时，这种方法无法应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需依赖线密度图，通过深度学习评估织物相似性的自动工具。&lt;h4&gt;方法&lt;/h4&gt;设计并训练了一种Siamese深度学习模型，通过利用扫描学习到的特征表示来比较图像对。此外，提出了一种相似度估计方法，通过聚合多个布样对的预测来提供稳健的相似度评分。&lt;h4&gt;主要发现&lt;/h4&gt;该方法应用于普拉多国家博物馆的画布，证实了即使是线密度相似的平纹画布，也可以有效地进行比较。&lt;h4&gt;结论&lt;/h4&gt;该方法可行且准确，为名作的分析开辟了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;The study of canvas fabrics in works of art is a crucial tool for authentication, attribution and conservation. Traditional methods are based on thread density map matching, which cannot be applied when canvases do not come from contiguous positions on a roll. This paper presents a novel approach based on deep learning to assess the similarity of textiles. We introduce an automatic tool that evaluates the similarity between canvases without relying on thread density maps. A Siamese deep learning model is designed and trained to compare pairs of images by exploiting the feature representations learned from the scans. In addition, a similarity estimation method is proposed, aggregating predictions from multiple pairs of cloth samples to provide a robust similarity score. Our approach is applied to canvases from the Museo Nacional del Prado, corroborating the hypothesis that plain weave canvases, widely used in painting, can be effectively compared even when their thread densities are similar. The results demonstrate the feasibility and accuracy of the proposed method, opening new avenues for the analysis of masterpieces.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The study of canvas fabrics in works of art is a crucial tool forauthentication, attribution and conservation. Traditional methods are based onthread density map matching, which cannot be applied when canvases do not comefrom contiguous positions on a roll. This paper presents a novel approach basedon deep learning to assess the similarity of textiles. We introduce anautomatic tool that evaluates the similarity between canvases without relyingon thread density maps. A Siamese deep learning model is designed and trainedto compare pairs of images by exploiting the feature representations learnedfrom the scans. In addition, a similarity estimation method is proposed,aggregating predictions from multiple pairs of cloth samples to provide arobust similarity score. Our approach is applied to canvases from the MuseoNacional del Prado, corroborating the hypothesis that plain weave canvases,widely used in painting, can be effectively compared even when their threaddensities are similar. The results demonstrate the feasibility and accuracy ofthe proposed method, opening new avenues for the analysis of masterpieces.</description>
      <author>example@mail.com (Juan José Murillo-Fuentes, Pablo M. Olmos, Laura Alba-Carcelén)</author>
      <guid isPermaLink="false">2506.20272v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis</title>
      <link>http://arxiv.org/abs/2506.20380v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为TESSERA的新型遥感基础模型（RSFM），利用自监督学习生成全球、稳健的10米分辨率表征，应用于地球观测、气候模型、碳核算以及 conservation and sustainable land use 策略。&lt;h4&gt;背景&lt;/h4&gt;卫星遥感（RS）在地球观测（EO）应用中发挥着重要作用，如气候建模、碳核算和可持续土地使用策略。&lt;h4&gt;目的&lt;/h4&gt;提出TESSERA模型，以实现全球范围内从像素级卫星时间序列数据生成高分辨率表征。&lt;h4&gt;方法&lt;/h4&gt;TESSERA使用两个并行的Transformer编码器分别处理Sentinel-1 SAR极化数据和Sentinel-2 MSI数据（10个光谱波段），然后通过多层感知器（MLP）融合信息，生成全球表征图。&lt;h4&gt;主要发现&lt;/h4&gt;TESSERA在五个不同任务中的性能优于传统的遥感基线模型和领先的地理空间基础模型，并建立了新的性能基准。&lt;h4&gt;结论&lt;/h4&gt;TESSERA通过开源方法实现了高性能、高分辨率表征的普及，为地球观测和地理空间数据应用提供了新的工具。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Satellite remote sensing (RS) enables a wide array of downstream Earthobservation (EO) applications, including climate modeling, carbon accounting, and strategies for conservation and sustainable land use. We present TESSERA, a novel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning (SSL) to generate global, robust representations at 10m scale from pixel-level satellite time series data. TESSERA combines information from only optical and SAR data streams using two parallel Transformer-based encoders: one dedicated to Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selected spectral bands) to create representations that are then fused using a multilayer perceptron (MLP), resulting in a global representation map covering the years 2017 to 2024. Our precomputed representations set a new state-of-the-art performance benchmark and our open-source approach democratizes access to high-performance, high-resolution representations. We benchmark the performance of TESSERA in five diverse tasks, comparing our work with state-of-the-art task-specific models and other foundation models. Our results show that TESSERA outperforms both traditional RS baselines and the leading geospatial foundation models in these diverse downstream tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Satellite remote sensing (RS) enables a wide array of downstream Earthobservation (EO) applications, including climate modeling, carbon accounting,and strategies for conservation and sustainable land use. We present TESSERA, anovel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning(SSL) to generate global, robust representations at 10m scale from pixel-levelsatellite time series data. TESSERA combines information from only optical andSAR data streams using two parallel Transformer-based encoders: one dedicatedto Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selectedspectral bands) to create representations that are then fused using amultilayer perceptron (MLP), resulting in a global representation map coveringthe years 2017 to 2024. Our precomputed representations set a newstate-of-the-art performance benchmark and our open-source approachdemocratizes access to high-performance, high-resolution representations. Webenchmark the performance of TESSERA in five diverse tasks, comparing our workwith state-of-the-art task-specific models and other foundation models. Ourresults show that TESSERA outperforms both traditional RS baselines and theleading geospatial foundation models in these diverse downstream tasks.</description>
      <author>example@mail.com (Zhengpeng Feng, Sadiq Jaffer, Jovana Knezevic, Silja Sormunen, Robin Young, Madeline Lisaius, Markus Immitzer, James Ball, Clement Atzberger, David A. Coomes, Anil Madhavapeddy, Andrew Blake, Srinivasan Keshav)</author>
      <guid isPermaLink="false">2506.20380v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features</title>
      <link>http://arxiv.org/abs/2506.20255v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  15 pages, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的手写识别方法，该方法结合了栅格化复杂符号和笔迹轨迹的互补线索，并引入了一个端到端网络，在共享潜在空间中对离线图像和在线笔迹数据进行早期融合。&lt;h4&gt;背景&lt;/h4&gt;目前大多数手写识别系统只利用单一模态的数据，而忽略了其他可能有助于提高识别准确性的线索。&lt;h4&gt;目的&lt;/h4&gt;提高手写识别的准确性和稳定性，减少对特定书写者的依赖。&lt;h4&gt;方法&lt;/h4&gt;提出了一种端到端网络，该网络包括一个将灰度图像转换为固定长度视觉标记的补丁编码器，以及一个轻量级的Transformer，用于嵌入$(x, y, ext{pen})$序列。可学习的潜在查询共同关注这两个标记流，生成增强的笔迹嵌入，这些嵌入在跨熵损失目标下进行池化和解码。&lt;h4&gt;主要发现&lt;/h4&gt;在IAMOn-DB和VNOn-DB数据集上的实验表明，该方法达到了最先进的准确率，比之前的最佳方法提高了最多1%。此外，该方法在ISI-Air数据集上也进行了手势识别的适应性调整。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在手写识别任务中取得了显著的性能提升，证明了结合多种模态数据的重要性。&lt;h4&gt;翻译&lt;/h4&gt;We posit that handwriting recognition benefits from complementary cues carried by the rasterized complex glyph and the pen's trajectory, yet most systems exploit only one modality. We introduce an end-to-end network that performs early fusion of offline images and online stroke data within a shared latent space. A patch encoder converts the grayscale crop into fixed-length visual tokens, while a lightweight transformer embeds the $(x, y, ext{pen})$ sequence. Learnable latent queries attend jointly to both token streams, yielding context-enhanced stroke embeddings that are pooled and decoded under a cross-entropy loss objective. Because integration occurs before any high-level classification, temporal cues reinforce each other during representation learning, producing stronger writer independence. Comprehensive experiments on IAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art accuracy, exceeding previous bests by up to 1%. Our study also shows adaptation of this pipeline with gesturification on the ISI-Air dataset. Our code can be found here.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We posit that handwriting recognition benefits from complementary cuescarried by the rasterized complex glyph and the pen's trajectory, yet mostsystems exploit only one modality. We introduce an end-to-end network thatperforms early fusion of offline images and online stroke data within a sharedlatent space. A patch encoder converts the grayscale crop into fixed-lengthvisual tokens, while a lightweight transformer embeds the $(x, y, \text{pen})$sequence. Learnable latent queries attend jointly to both token streams,yielding context-enhanced stroke embeddings that are pooled and decoded under across-entropy loss objective. Because integration occurs before any high-levelclassification, temporal cues reinforce each other during representationlearning, producing stronger writer independence. Comprehensive experiments onIAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-artaccuracy, exceeding previous bests by up to 1\%. Our study also showsadaptation of this pipeline with gesturification on the ISI-Air dataset. Ourcode can be found here.</description>
      <author>example@mail.com (Ayush Lodh, Ritabrata Chakraborty, Shivakumara Palaiahnakote, Umapada Pal)</author>
      <guid isPermaLink="false">2506.20255v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2506.19269v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AnchorDP3的扩散策略框架，用于双臂机器人操作，在高度随机化的环境中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;AnchorDP3框架的提出是为了解决在高度随机化环境中进行双臂机器人操作时遇到的挑战。&lt;h4&gt;目的&lt;/h4&gt;目的是提高双臂机器人在高度随机化环境中的操作性能。&lt;h4&gt;方法&lt;/h4&gt;AnchorDP3集成了三个关键创新：(1) 使用渲染的真实标签进行模拟器监督语义分割，以在点云中明确分割任务关键对象，提供强烈的先验能力；(2) 任务条件特征编码器，轻量级模块处理每个任务的增强点云，通过共享的基于扩散的动作专家实现高效的多任务学习；(3) 基于能力的锚点关键姿态扩散，带有完整状态监督，用稀疏、几何上有意义的动作锚点（如预抓取姿态、直接锚定到能力的抓取姿态）替换密集轨迹预测，大大简化了预测空间；动作专家被迫同时预测机器人关节角度和末端执行器的位置，这利用了几何一致性来加速收敛并提高准确性。&lt;h4&gt;主要发现&lt;/h4&gt;AnchorDP3在RoboTwin基准测试中实现了98.7%的平均成功率，测试包括极端随机化的对象、杂乱、桌面高度、照明和背景下的各种任务。&lt;h4&gt;结论&lt;/h4&gt;当与RoboTwin的真实到模拟流程集成时，此框架有可能仅从场景和指令中完全自主地生成可部署的视觉运动策略，从而完全消除人类示范来学习操作技能。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为AnchorDP3的扩散策略框架，用于双臂机器人操作，在高度随机化的环境中实现了最先进的性能。AnchorDP3集成了三个关键创新：1) 使用渲染的真实标签进行模拟器监督语义分割，在点云中明确分割任务关键对象，提供强烈的先验能力；2) 任务条件特征编码器，轻量级模块处理每个任务的增强点云，通过共享的基于扩散的动作专家实现高效的多任务学习；3) 基于能力的锚点关键姿态扩散，带有完整状态监督，用稀疏、几何上有意义的动作锚点（如预抓取姿态、直接锚定到能力的抓取姿态）替换密集轨迹预测，大大简化了预测空间；动作专家被迫同时预测机器人关节角度和末端执行器的位置，这利用了几何一致性来加速收敛并提高准确性。在大型、程序生成的模拟数据上训练的AnchorDP3在RoboTwin基准测试中实现了98.7%的平均成功率，测试包括极端随机化的对象、杂乱、桌面高度、照明和背景下的各种任务。当与RoboTwin的真实到模拟流程集成时，此框架有可能仅从场景和指令中完全自主地生成可部署的视觉运动策略，从而完全消除人类示范来学习操作技能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present AnchorDP3, a diffusion policy framework for dual-arm roboticmanipulation that achieves state-of-the-art performance in highly randomizedenvironments. AnchorDP3 integrates three key innovations: (1)Simulator-Supervised Semantic Segmentation, using rendered ground truth toexplicitly segment task-critical objects within the point cloud, which providesstrong affordance priors; (2) Task-Conditioned Feature Encoders, lightweightmodules processing augmented point clouds per task, enabling efficientmulti-task learning through a shared diffusion-based action expert; (3)Affordance-Anchored Keypose Diffusion with Full State Supervision, replacingdense trajectory prediction with sparse, geometrically meaningful actionanchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored toaffordances, drastically simplifying the prediction space; the action expert isforced to predict both robot joint angles and end-effector posessimultaneously, which exploits geometric consistency to accelerate convergenceand boost accuracy. Trained on large-scale, procedurally generated simulationdata, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmarkacross diverse tasks under extreme randomization of objects, clutter, tableheight, lighting, and backgrounds. This framework, when integrated with theRoboTwin real-to-sim pipeline, has the potential to enable fully autonomousgeneration of deployable visuomotor policies from only scene and instruction,totally eliminating human demonstrations from learning manipulation skills.</description>
      <author>example@mail.com (Ziyan Zhao, Ke Fan, He-Yang Xu, Ning Qiao, Bo Peng, Wenlong Gao, Dongjiang Li, Hui Shen)</author>
      <guid isPermaLink="false">2506.19269v2</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>GNN's Uncertainty Quantification using Self-Distillation</title>
      <link>http://arxiv.org/abs/2506.20046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The paper has been accepted in the International Conference on AI in  Healthcare (AIiH) 2025 and will appear in the conference proceedings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于知识蒸馏的新方法，用于更高效、更精确地量化图神经网络（GNN）的预测不确定性。&lt;h4&gt;背景&lt;/h4&gt;GNN在医疗领域表现出色，但其预测不确定性的量化一直是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种更高效且精确的方法来量化GNN的预测不确定性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于自我蒸馏的方法，其中相同的网络同时作为教师和学生模型，避免了独立训练多个网络的需要。同时，开发了一个不确定性度量，通过为每个GNN分类器分配不同的权重来捕捉网络的多样性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，所提出的方法可以有效地捕捉模型的预测不确定性，同时性能与MC Dropout和集成方法相似。&lt;h4&gt;结论&lt;/h4&gt;该方法为量化GNN的预测不确定性提供了一种高效且精确的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) have shown remarkable performance in the healthcare domain. However, what remained challenging is quantifying the predictive uncertainty of GNNs, which is an important aspect of trustworthiness in clinical settings. While Bayesian and ensemble methods can be used to quantify uncertainty, they are computationally expensive. Additionally, the disagreement metric used by ensemble methods to compute uncertainty cannot capture the diversity of models in an ensemble network. In this paper, we propose a novel method, based on knowledge distillation, to quantify GNNs' uncertainty more efficiently and with higher precision. We apply self-distillation, where the same network serves as both the teacher and student models, thereby avoiding the need to train several networks independently. To ensure the impact of self-distillation, we develop an uncertainty metric that captures the diverse nature of the network by assigning different weights to each GNN classifier. We experimentally evaluate the precision, performance, and ability of our approach in distinguishing out-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. The evaluation results demonstrate that the proposed method can effectively capture the predictive uncertainty of the model while having performance similar to that of the MC Dropout and ensemble methods. The code is publicly available at https://github.com/tailabTMU/UQ_GNN.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have shown remarkable performance in thehealthcare domain. However, what remained challenging is quantifying thepredictive uncertainty of GNNs, which is an important aspect of trustworthinessin clinical settings. While Bayesian and ensemble methods can be used toquantify uncertainty, they are computationally expensive. Additionally, thedisagreement metric used by ensemble methods to compute uncertainty cannotcapture the diversity of models in an ensemble network. In this paper, wepropose a novel method, based on knowledge distillation, to quantify GNNs'uncertainty more efficiently and with higher precision. We applyself-distillation, where the same network serves as both the teacher andstudent models, thereby avoiding the need to train several networksindependently. To ensure the impact of self-distillation, we develop anuncertainty metric that captures the diverse nature of the network by assigningdifferent weights to each GNN classifier. We experimentally evaluate theprecision, performance, and ability of our approach in distinguishingout-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. Theevaluation results demonstrate that the proposed method can effectively capturethe predictive uncertainty of the model while having performance similar tothat of the MC Dropout and ensemble methods. The code is publicly available athttps://github.com/tailabTMU/UQ_GNN.</description>
      <author>example@mail.com (Hirad Daneshvar, Reza Samavi)</author>
      <guid isPermaLink="false">2506.20046v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>A foundation model with multi-variate parallel attention to generate neuronal activity</title>
      <link>http://arxiv.org/abs/2506.20354v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  The code is available at  https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG  dataset is available at  https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为多变量并行注意力（MVPA）的新型自注意力机制，用于处理具有不同通道配置的多变量时间序列数据，并构建了MVPFormer，这是一种用于预测人类电生理学信号演变的生成性基础模型。同时，发布了SWEC iEEG数据集，这是一个包含近10,000小时记录的最大公开iEEG数据集。&lt;h4&gt;背景&lt;/h4&gt;学习具有不同通道配置的多变量时间序列数据是深度神经网络的一个基本挑战，特别是在iEEG等临床领域。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够灵活、通用和高效地建模具有不同通道数和配置的时间序列数据的机制，并构建一个能够预测iEEG信号演变的模型。&lt;h4&gt;方法&lt;/h4&gt;引入了MVPA机制，并使用它来构建MVPFormer模型，同时发布了SWEC iEEG数据集。&lt;h4&gt;主要发现&lt;/h4&gt;MVPFormer在iEEG信号预测和癫痫检测方面表现出专家级性能，并在SWEC、MAYO和FNUSA数据集上优于最先进的Transformer基线模型。MVPA在标准时间序列预测和分类任务上也表现出色。&lt;h4&gt;结论&lt;/h4&gt;MVPA是一种适用于异构时间序列的通用注意力机制，MVPFormer是首个开源、公开权重和公开数据的iEEG基础模型，具有最先进的临床性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从具有异构通道配置的多变量时间序列中学习仍然是深度神经网络（DNNs）的一个基本挑战，特别是在颅内电图（iEEG）等临床领域，不同受试者的通道设置差异很大。在这项工作中，我们引入了多变量并行注意力（MVPA），这是一种新颖的自注意力机制，它将内容、时间和空间注意力解耦，使得能够灵活、通用和高效地建模具有不同通道数和配置的时间序列数据。我们使用MVPA构建了MVPFormer，这是一种针对人类电生理学进行训练的生成性基础模型，用于预测不同受试者的iEEG信号演变。为了支持社区的努力，我们发布了SWEC iEEG数据集，这是迄今为止最大的公开iEEG数据集，包含来自异构临床来源的近10,000小时记录。MVPFormer利用MVPA实现了跨受试者的强大泛化能力，在癫痫检测方面表现出专家级性能，并在我们的SWEC、MAYO和FNUSA数据集上优于最先进的Transformer基线模型。我们还在标准时间序列预测和分类任务上进一步验证了MVPA，其性能与现有基于注意力的模型相当或更好。我们的贡献将MVPA确立为适用于异构时间序列的通用注意力机制，并将MVPFormer确立为首个开源、公开权重和公开数据的iEEG基础模型，具有最先进的临床性能。代码可在https://github.com/IBM/multi-variate-parallel-transformer上获得。SWEC iEEG数据集可在https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Learning from multi-variate time-series with heterogeneous channelconfigurations remains a fundamental challenge for deep neural networks (DNNs),particularly in clinical domains such as intracranial electroencephalography(iEEG), where channel setups vary widely across subjects. In this work, weintroduce multi-variate parallel attention (MVPA), a novel self-attentionmechanism that disentangles content, temporal, and spatial attention, enablingflexible, generalizable, and efficient modeling of time-series data withvarying channel counts and configurations. We use MVPA to build MVPFormer, agenerative foundation model for human electrophysiology, trained to predict theevolution of iEEG signals across diverse subjects. To support this and futureeffort by the community, we release the SWEC iEEG dataset, the largest publiclyavailable iEEG dataset to date, comprising nearly 10,000 hours of recordingsfrom heterogeneous clinical sources. MVPFormer leverages MVPA to achieve stronggeneralization across subjects, demonstrating expert-level performance inseizure detection and outperforming state-of-the-art Transformer baselines onour SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standardtime-series forecasting and classification tasks, where it matches or exceedsexisting attention-based models. Together, our contributions establish MVPA asa general-purpose attention mechanism for heterogeneous time-series andMVPFormer as the first open-source, open-weights, and open-data iEEG foundationmodel with state-of-the-art clinical performance. The code is available athttps://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEGdataset is available athttps://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.</description>
      <author>example@mail.com (Francesco Carzaniga, Michael Hersche, Abu Sebastian, Kaspar Schindler, Abbas Rahimi)</author>
      <guid isPermaLink="false">2506.20354v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning</title>
      <link>http://arxiv.org/abs/2506.20031v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的理论公式和计算框架，用于生成具有软变化代理-任务兼容性的多样化行动方案（COA）池。&lt;h4&gt;背景&lt;/h4&gt;在灾害响应、搜救和军事任务中，涉及多个代理的操作需要自动化流程来支持行动方案（COA）的规划。环境变化（如雨、雪、封锁等）可能影响COA的预期性能，因此需要一个多样化的COA池，以适应不同的任务分配。&lt;h4&gt;目的&lt;/h4&gt;目标是开发一个能够处理代理能力变化（包括人类机组人员和/或自主系统）的COA规划过程，并量化COA池的多样性。&lt;h4&gt;方法&lt;/h4&gt;本文采用图抽象来表示任务空间和COA池本身，以量化其多样性。将COA规划问题表述为集中式多机器人任务分配问题，使用遗传算法对每个代理的任务分配进行（不考虑顺序）分配，以在COA池内联合最大化多样性和代理-任务映射的整体兼容性。然后，使用策略梯度方法训练图神经网络，以在每个COA中执行单代理任务排序，从而最大化适应任务特征的完成率。&lt;h4&gt;主要发现&lt;/h4&gt;在模拟环境中的COA生成过程测试表明，与随机游走基线相比，具有显著性能提升，任务排序的优化差距较小，规划20个COA（针对5个代理/100个任务操作）的执行时间约为50分钟。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法能够有效生成多样化的COA池，并提高了任务分配和排序的效率，为涉及多个代理的操作提供了有效的支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Operations in disaster response, search \&amp; rescue, and military missions thatinvolve multiple agents demand automated processes to support the planning ofthe courses of action (COA). Moreover, traverse-affecting changes in theenvironment (rain, snow, blockades, etc.) may impact the expected performanceof a COA, making it desirable to have a pool of COAs that are diverse in taskdistributions across agents. Further, variations in agent capabilities, whichcould be human crews and/or autonomous systems, present practical opportunitiesand computational challenges to the planning process. This paper presents a newtheoretical formulation and computational framework to generate such diversepools of COAs for operations with soft variations in agent-task compatibility.Key to the problem formulation is a graph abstraction of the task space and thepool of COAs itself to quantify its diversity. Formulating the COAs as acentralized multi-robot task allocation problem, a genetic algorithm is usedfor (order-ignoring) allocations of tasks to each agent that jointly maximizediversity within the COA pool and overall compatibility of the agent-taskmappings. A graph neural network is trained using a policy gradient approach tothen perform single agent task sequencing in each COA, which maximizescompletion rates adaptive to task features. Our tests of the COA generationprocess in a simulated environment demonstrate significant performance gainover a random walk baseline, small optimality gap in task sequencing, andexecution time of about 50 minutes to plan up to 20 COAs for 5 agent/100 taskoperations.</description>
      <author>example@mail.com (Prithvi Poddar, Ehsan Tarkesh Esfahani, Karthik Dantu, Souma Chowdhury)</author>
      <guid isPermaLink="false">2506.20031v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs</title>
      <link>http://arxiv.org/abs/2506.20167v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为SEED的结构编码器，用于嵌入驱动的解码，旨在解决多元时间序列预测中的结构-语义建模差距。&lt;h4&gt;背景&lt;/h4&gt;多元时间序列预测需要模型同时捕捉变量间的结构依赖并泛化到不同任务，而现有的结构编码器和大型语言模型各有局限性。&lt;h4&gt;目的&lt;/h4&gt;提出SEED模型，以解决结构编码器缺乏语义推理和任务适应能力，以及大型语言模型与原始时间序列数据不兼容的问题。&lt;h4&gt;方法&lt;/h4&gt;SEED模型包含四个阶段：一个标记感知编码器用于提取补丁，一个投影模块将补丁与语言模型嵌入对齐，一个语义重编程机制将补丁映射到任务感知原型，以及一个用于预测的冻结语言模型。&lt;h4&gt;主要发现&lt;/h4&gt;SEED模型在多个数据集上实现了对强基线的持续改进，并通过比较研究证实了其在解决结构-语义建模差距中的作用。&lt;h4&gt;结论&lt;/h4&gt;SEED模型通过模块化架构解耦了表示学习和推理，实现了数值模式和语义推理之间的有效对齐，为统一的、可迁移的预测系统的发展提供了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multivariate time series forecasting requires models to simultaneouslycapture variable-wise structural dependencies and generalize across diversetasks. While structural encoders are effective in modeling featureinteractions, they lack the capacity to support semantic-level reasoning ortask adaptation. Conversely, large language models (LLMs) possess stronggeneralization capabilities but remain incompatible with raw time seriesinputs. This gap limits the development of unified, transferable predictionsystems. Therefore, we introduce SEED, a structural encoder forembedding-driven decoding, which integrates four stages: a token-aware encoderfor patch extraction, a projection module that aligns patches with languagemodel embeddings, a semantic reprogramming mechanism that maps patches totask-aware prototypes, and a frozen language model for prediction. This modulararchitecture decouples representation learning from inference, enablingefficient alignment between numerical patterns and semantic reasoning.Empirical results demonstrate that the proposed method achieves consistentimprovements over strong baselines, and comparative studies on various datasetsconfirm SEED's role in addressing the structural-semantic modeling gap.</description>
      <author>example@mail.com (Fengze Li, Yue Wang, Yangle Liu, Ming Huang, Dou Hong, Jieming Ma)</author>
      <guid isPermaLink="false">2506.20167v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement</title>
      <link>http://arxiv.org/abs/2506.20254v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Surgical Phase Anywhere（SPA）框架，这是一个轻量级的通用手术工作流程理解框架，可以适应不同机构的环境，并通过少量标注对基础模型进行定制化。SPA通过空间自适应和扩散模型保证时间一致性，并通过动态测试时间自适应提高模型的可靠性。&lt;h4&gt;背景&lt;/h4&gt;手术流程的复杂性和多样性，由于手术室设置、机构协议和解剖结构的差异，对跨机构和跨手术流程的手术理解模型的开发提出了挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够适应不同机构环境，并且可以通过少量标注快速定制的轻量级手术工作流程理解框架。&lt;h4&gt;方法&lt;/h4&gt;SPA框架利用少量样本的空间自适应来对齐特定机构手术场景和阶段的多模态嵌入，并通过扩散模型确保时间一致性。它还采用了动态测试时间自适应，通过利用多模态阶段预测流之间的相互一致来对模型进行自适应。&lt;h4&gt;主要发现&lt;/h4&gt;SPA框架在多机构和多手术流程的少量样本手术阶段识别上取得了最先进的性能，甚至在32个样本的标注数据下也优于全样本模型。&lt;h4&gt;结论&lt;/h4&gt;SPA框架为医院提供了快速定制阶段识别模型的能力，只需用自然语言定义阶段、标注少量图像以及提供定义阶段转换的任务图。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为Surgical Phase Anywhere（SPA）的轻量级框架，用于通用的手术工作流程理解。该框架能够适应不同机构的设置，并可以通过最小程度的标注对基础模型进行定制。SPA利用少量样本的空间自适应来对齐特定机构手术场景和阶段的多模态嵌入，并通过扩散模型保证时间一致性。此外，它还采用了动态测试时间自适应，通过利用多模态阶段预测流之间的相互一致来对模型进行自适应。实验结果表明，SPA框架在少量样本手术阶段识别上达到了最先进的性能，甚至在拥有32个样本标注数据的情况下也优于全样本模型。代码可在https://github.com/CAMMA-public/SPA上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The complexity and diversity of surgical workflows, driven by heterogeneousoperating room settings, institutional protocols, and anatomical variability,present a significant challenge in developing generalizable models forcross-institutional and cross-procedural surgical understanding. While recentsurgical foundation models pretrained on large-scale vision-language data offerpromising transferability, their zero-shot performance remains constrained bydomain shifts, limiting their utility in unseen surgical environments. Toaddress this, we introduce Surgical Phase Anywhere (SPA), a lightweightframework for versatile surgical workflow understanding that adapts foundationmodels to institutional settings with minimal annotation. SPA leveragesfew-shot spatial adaptation to align multi-modal embeddings withinstitution-specific surgical scenes and phases. It also ensures temporalconsistency through diffusion modeling, which encodes task-graph priors derivedfrom institutional procedure protocols. Finally, SPA employs dynamic test-timeadaptation, exploiting the mutual agreement between multi-modal phaseprediction streams to adapt the model to a given test video in aself-supervised manner, enhancing the reliability under test-time distributionshifts. SPA is a lightweight adaptation framework, allowing hospitals torapidly customize phase recognition models by defining phases in naturallanguage text, annotating a few images with the phase labels, and providing atask graph defining phase transitions. The experimental results show that theSPA framework achieves state-of-the-art performance in few-shot surgical phaserecognition across multiple institutions and procedures, even outperformingfull-shot models with 32-shot labeled data. Code is available athttps://github.com/CAMMA-public/SPA</description>
      <author>example@mail.com (Kun Yuan, Tingxuan Chen, Shi Li, Joel L. Lavanchy, Christian Heiliger, Ege Özsoy, Yiming Huang, Long Bai, Nassir Navab, Vinkle Srivastav, Hongliang Ren, Nicolas Padoy)</author>
      <guid isPermaLink="false">2506.20254v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Sampling Matters in Explanations: Towards Trustworthy Attribution Analysis Building Block in Visual Models through Maximizing Explanation Certainty</title>
      <link>http://arxiv.org/abs/2506.19442v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code:  https://anonymous.4open.science/r/sampling_matters_reproducibility-BB60/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图像归因分析，通过整合梯度来强调视觉模型学习的特征表示，并提高输入的像素重要性。提出了一种基于抑制输入特征的半优化采样方法，以解决样本分布不匹配问题，并证明了其在ImageNet数据集上的有效性。&lt;h4&gt;背景&lt;/h4&gt;图像归因分析旨在强调视觉模型学习到的特征表示，梯度整合是归因分析的一个基本方法。然而，现有的方法在样本分布不匹配和加入噪声时，可能导致解释的不确定性。&lt;h4&gt;目的&lt;/h4&gt;提高归因分析的可靠性，减少样本分布不匹配问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于抑制输入特征的半优化采样方法，该方法通过模拟自然图像分布来生成样本。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，额外信息可能会饱和神经网络，而半优化采样方法能够有效解决样本分布不匹配问题，并在ImageNet数据集上提供了比现有方法更满意的解释。&lt;h4&gt;结论&lt;/h4&gt;抑制输入特征的半优化采样方法能够提高图像归因分析的可靠性，并有效解决样本分布不匹配问题。&lt;h4&gt;翻译&lt;/h4&gt;Image attribution analysis aims to highlight the feature representations learned by visual models so that the highlighted feature maps can reflect the pixel-wise importance of inputs. Gradient integration is a building block in the attribution analysis by integrating the gradients from multiple derived samples to highlight the semantic features relevant to inferences. Such a building block often combines with other information from visual models such as activation or attention maps to form ultimate explanations. Yet, our theoretical analysis demonstrates that the extent to the alignment of the sample distribution in gradient integration with respect to natural image distribution gives a lower bound of explanation certainty. Prior works add noise into images as samples and the noise distributions can lead to low explanation certainty. Counter-intuitively, our experiment shows that extra information can saturate neural networks. To this end, building trustworthy attribution analysis needs to settle the sample distribution misalignment problem. Instead of adding extra information into input images, we present a semi-optimal sampling approach by suppressing features from inputs. The sampled distribution by suppressing features is approximately identical to the distribution of natural images. Our extensive quantitative evaluation on large-scale dataset ImageNet affirms that our approach is effective and able to yield more satisfactory explanations against state-of-the-art baselines throughout all experimental models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5281/zenodo.8204453&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image attribution analysis seeks to highlight the feature representationslearned by visual models such that the highlighted feature maps can reflect thepixel-wise importance of inputs. Gradient integration is a building block inthe attribution analysis by integrating the gradients from multiple derivedsamples to highlight the semantic features relevant to inferences. Such abuilding block often combines with other information from visual models such asactivation or attention maps to form ultimate explanations. Yet, ourtheoretical analysis demonstrates that the extent to the alignment of thesample distribution in gradient integration with respect to natural imagedistribution gives a lower bound of explanation certainty. Prior works addnoise into images as samples and the noise distributions can lead to lowexplanation certainty. Counter-intuitively, our experiment shows that extrainformation can saturate neural networks. To this end, building trustworthyattribution analysis needs to settle the sample distribution misalignmentproblem. Instead of adding extra information into input images, we present asemi-optimal sampling approach by suppressing features from inputs. The sampledistribution by suppressing features is approximately identical to thedistribution of natural images. Our extensive quantitative evaluation on largescale dataset ImageNet affirms that our approach is effective and able to yieldmore satisfactory explanations against state-of-the-art baselines throughoutall experimental models.</description>
      <author>example@mail.com (Róisín Luo, James McDermott, Colm O'Riordan)</author>
      <guid isPermaLink="false">2506.19442v2</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees</title>
      <link>http://arxiv.org/abs/2506.20178v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为COIN的不确定性量化框架，用于检测和减轻自动生成文本中的潜在幻觉，并提高样本保留率。&lt;h4&gt;背景&lt;/h4&gt;对基础模型的不确定性量化对于识别和减轻自动生成文本中的潜在幻觉至关重要。传统的启发式方法在关键指标如选择性预测中的假发现率（FDR）方面缺乏正式保证。&lt;h4&gt;目的&lt;/h4&gt;提高自动生成文本的不确定性量化，确保在用户指定的FDR约束下，每个问题的单个生成答案经过有效筛选。&lt;h4&gt;方法&lt;/h4&gt;COIN通过构建预测集并使用统计上有效的阈值来筛选单个生成答案。它估计校准集上的经验误差率，并应用Clopper-Pearson置信区间方法来建立真实误差率的高概率上界。&lt;h4&gt;主要发现&lt;/h4&gt;COIN在风险控制、保持可接受答案的强测试时间功率以及有限的校准数据下的预测效率方面表现出鲁棒性。此外，使用不同的上界构建和不确定性量化策略可以进一步提高COIN的性能。&lt;h4&gt;结论&lt;/h4&gt;COIN是一种灵活且适应性强的不确定性量化框架，可以有效地应用于各种文本生成任务，并提高样本保留率。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a framework named COIN for uncertainty quantification in foundation models, aiming to detect and mitigate potential hallucinations in automatically generated text and enhance sample retention. The background of the paper is that uncertainty quantification for foundation models is essential for identifying and mitigating potential hallucinations in automatically generated text, while heuristic UQ approaches lack formal guarantees for key metrics such as the false discovery rate (FDR) in selective prediction. The purpose of the paper is to improve the uncertainty quantification of automatically generated text, ensuring that each question's single generated answer is effectively filtered under user-specified FDR constraints. The method of COIN involves constructing prediction sets and using statistically valid thresholds to filter a single generated answer per question. COIN estimates the empirical error rate on a calibration set and applies confidence interval methods such as Clopper-Pearson to establish a high-probability upper bound on the true error rate (i.e., FDR). The main findings of the paper show that COIN exhibits robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across both general and multimodal text generation tasks. Furthermore, the paper demonstrates that employing alternative upper bound constructions and UQ strategies can further boost the performance of COIN, highlighting its flexibility and adaptability to diverse application scenarios. The conclusion of the paper is that COIN is a flexible and adaptable uncertainty quantification framework that can be effectively applied to various text generation tasks and enhance sample retention.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Uncertainty quantification (UQ) for foundation models is essential toidentify and mitigate potential hallucinations in automatically generated text.However, heuristic UQ approaches lack formal guarantees for key metrics such asthe false discovery rate (FDR) in selective prediction. Previous work adoptsthe split conformal prediction (SCP) framework to ensure desired coverage ofadmissible answers by constructing prediction sets, but these sets oftencontain incorrect candidates, limiting their practical utility. To addressthis, we propose COIN, an uncertainty-guarding selection framework thatcalibrates statistically valid thresholds to filter a single generated answerper question under user-specified FDR constraints. COIN estimates the empiricalerror rate on a calibration set and applies confidence interval methods such asClopper-Pearson to establish a high-probability upper bound on the true errorrate (i.e., FDR). This enables the selection of the largest uncertaintythreshold that ensures FDR control on test data while significantly increasingsample retention. We demonstrate COIN's robustness in risk control, strongtest-time power in retaining admissible answers, and predictive efficiencyunder limited calibration data across both general and multimodal textgeneration tasks. Furthermore, we show that employing alternative upper boundconstructions and UQ strategies can further boost COIN's power performance,which underscores its extensibility and adaptability to diverse applicationscenarios.</description>
      <author>example@mail.com (Zhiyuan Wang, Jinhao Duan, Qingni Wang, Xiaofeng Zhu, Tianlong Chen, Xiaoshuang Shi, Kaidi Xu)</author>
      <guid isPermaLink="false">2506.20178v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition</title>
      <link>http://arxiv.org/abs/2506.20174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本研究探讨了在地球观测数据挖掘中，通过结合现有预训练模型来提升性能的方法。&lt;h4&gt;背景&lt;/h4&gt;目前地球观测领域大部分研究集中在开发大型模型，而复用和组合现有预训练模型的方法未被充分探索。&lt;h4&gt;目的&lt;/h4&gt;研究是否可以通过结合预训练模型来提升地球观测任务（如场景分类和语义分割）的性能。&lt;h4&gt;方法&lt;/h4&gt;使用GEO-Bench基准，在覆盖不同空间分辨率、传感器模态和任务类型的11个数据集上，评估了包括Prithvi、Hiera和DOFA在内的几个突出模型。&lt;h4&gt;主要发现&lt;/h4&gt;特征级联较小的预训练模型在性能上可以与更大的模型相匹配或超过，同时需要更少的训练时间和计算资源。此外，研究还强调了知识蒸馏技术在将集成模型的优点转移到更紧凑模型中的潜力。&lt;h4&gt;结论&lt;/h4&gt;知识蒸馏技术可以作为一个将预训练模型应用于实际地球观测应用中的实用途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-25&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models are rapidly transforming Earth Observation data mining byenabling generalizable and scalable solutions for key tasks such as sceneclassification and semantic segmentation. While most efforts in the geospatialdomain have focused on developing large models trained from scratch usingmassive Earth Observation datasets, an alternative strategy that remainsunderexplored is the reuse and combination of existing pretrained models. Inthis study, we investigate whether foundation models pretrained on remotesensing and general vision datasets can be effectively combined to improveperformance across a diverse set of key Earth Observation tasks. Using theGEO-Bench benchmark, we evaluate several prominent models, including Prithvi,Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions,sensor modalities, and task types. The results show that feature-levelensembling of smaller pretrained models can match or exceed the performance ofmuch larger models, while requiring less training time and computationalresources. Moreover, the study highlights the potential of applying knowledgedistillation to transfer the strengths of ensembles into more compact models,offering a practical path for deploying foundation models in real-world EarthObservation applications.</description>
      <author>example@mail.com (Man Duc Chuc)</author>
      <guid isPermaLink="false">2506.20174v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>An ab initio foundation model of wavefunctions that accurately describes chemical bond breaking</title>
      <link>http://arxiv.org/abs/2506.19960v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Orbformer的新型可迁移波函数模型，通过预训练在22,000个平衡和离解结构上，实现了量子化学中解决薛定谔方程的成本分摊，提高了计算效率。&lt;h4&gt;背景&lt;/h4&gt;在量子化学中，由于离解物种电子结构的多参考特性，可靠地描述键断裂是一个主要挑战。多参考方法在计算成本上存在较大问题，因为传统范式下，对于每个系统都需要重新支付全价，忽略了分子间电子结构的共性。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的计算范式，通过预训练可迁移的波函数模型，利用分子间电子结构的共性，降低量子化学中键断裂描述的计算成本。&lt;h4&gt;方法&lt;/h4&gt;提出了Orbformer模型，该模型在22,000个平衡和离解结构上进行预训练，并可以在未见过的分子上进行微调，以达到与经典多参考方法相当的成本-精度比。&lt;h4&gt;主要发现&lt;/h4&gt;Orbformer在已建立的基准测试以及更具挑战性的键离解和Diels-Alder反应中，是唯一一种能够持续收敛到化学精度（1 kcal/mol）的方法。&lt;h4&gt;结论&lt;/h4&gt;这项工作将解决薛定谔方程在许多分子上的成本分摊的想法转化为量子化学中的实用方法。&lt;h4&gt;翻译&lt;/h4&gt;可靠的键断裂描述仍然是量子化学的一个主要挑战，因为离解物种的电子结构具有多参考特性。特别是，多参考方法在计算成本上存在较大问题，在正常范式下，对于每个系统都必须重新支付全价，忽略了分子间电子结构的共性。量子蒙特卡罗与深度神经网络（深度QMC）的独特之处在于能够利用这种共性，通过预训练可迁移的波函数模型。但是，迄今为止，所有此类尝试都受到了范围的限制。在这里，我们通过Orbformer实现了这一新范式，Orbformer是一种新型的可迁移波函数模型，在22,000个平衡和离解结构上进行预训练，可以在未见过的分子上进行微调，达到与经典多参考方法相当的成本-精度比。在已建立的基准测试以及更具挑战性的键离解和Diels-Alder反应中，Orbformer是唯一一种能够持续收敛到化学精度（1 kcal/mol）的方法。这项工作将解决薛定谔方程在许多分子上的成本分摊的想法转化为量子化学中的实用方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reliable description of bond breaking remains a major challenge for quantumchemistry due to the multireferential character of the electronic structure indissociating species. Multireferential methods in particular suffer from largecomputational cost, which under the normal paradigm has to be paid anew foreach system at a full price, ignoring commonalities in electronic structureacross molecules. Quantum Monte Carlo with deep neural networks (deep QMC)uniquely offers to exploit such commonalities by pretraining transferablewavefunction models, but all such attempts were so far limited in scope. Here,we bring this new paradigm to fruition with Orbformer, a novel transferablewavefunction model pretrained on 22,000 equilibrium and dissociating structuresthat can be fine-tuned on unseen molecules reaching an accuracy-cost ratiorivalling classical multireferential methods. On established benchmarks as wellas more challenging bond dissociations and Diels-Alder reactions, Orbformer isthe only method that consistently converges to chemical accuracy (1 kcal/mol).This work turns the idea of amortizing the cost of solving the Schr\"odingerequation over many molecules into a practical approach in quantum chemistry.</description>
      <author>example@mail.com (Adam Foster, Zeno Schätzle, P. Bernát Szabó, Lixue Cheng, Jonas Köhler, Gino Cassella, Nicholas Gao, Jiawei Li, Frank Noé, Jan Hermann)</author>
      <guid isPermaLink="false">2506.19960v1</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Machine Learning Algorithms using Path Signatures</title>
      <link>http://arxiv.org/abs/2506.17634v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了随机分析与机器学习之间的接口，并研究了路径签名在可扩展机器学习管道中的应用。路径签名是路径的忠实和层次化表示，适合于建模动态变化、长期依赖和不规则采样等现实世界时间序列和图数据中的常见挑战。&lt;h4&gt;背景&lt;/h4&gt;随机分析与机器学习交叉领域快速发展，路径签名作为路径的迭代积分，提供了一种原则性和通用的特征映射，适用于序列和结构化数据。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用路径签名的表达能力，在可扩展的机器学习管道中实现。&lt;h4&gt;方法&lt;/h4&gt;本文引入了一系列模型，结合了理论稳健性和计算效率，将粗糙路径理论、概率建模、深度学习和核方法相结合。包括基于签名核的高斯过程协方差函数、Seq2Tens框架和基于图的模型等。&lt;h4&gt;主要发现&lt;/h4&gt;主要贡献包括：具有签名核协方差函数的高斯过程，用于不确定性感知的时间序列建模；Seq2Tens框架，在权重空间中采用低秩张量结构，以可扩展的方式建模长期依赖；以及基于图的模型，其中图上的预期签名诱导拟椭圆扩散过程，提供了一种表达能力强且易于处理的替代方案。&lt;h4&gt;结论&lt;/h4&gt;本文旨在提供一个方法论工具包和概念桥梁，为可扩展的基于签名的序列和结构化数据学习提供有用的参考。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了随机分析与机器学习之间的接口，路径签名——提供路径忠实、分层表示的迭代积分——为序列和结构化数据提供了一种原则性和通用的特征映射。路径签名根植于粗糙路径理论，对重新参数化不变，非常适合于建模动态变化、长期依赖和不规则采样——这些是现实世界时间序列和图数据中的常见挑战。本文探讨了如何在可扩展的机器学习管道中利用路径签名的表达能力。它介绍了一系列模型，这些模型结合了理论稳健性和计算效率，将粗糙路径理论、概率建模、深度学习和核方法相结合。主要贡献包括：具有签名核协方差函数的高斯过程，用于不确定性感知的时间序列建模；Seq2Tens框架，在权重空间中采用低秩张量结构，以可扩展的方式建模长期依赖；以及基于图的模型，其中图上的预期签名诱导拟椭圆扩散过程，提供了一种表达能力强且易于处理的替代方案。进一步的发展包括随机傅里叶签名特征，这是一种具有理论保证的可扩展核近似，以及循环稀疏频谱签名高斯过程，它结合了高斯过程、签名核和随机特征，并具有一种原则性的遗忘机制，用于具有自适应上下文长度的多 horizon 时间序列预测。我们希望本文既是一个方法论工具包，也是一个概念桥梁，并为可扩展的基于签名的序列和结构化数据学习提供有用的参考。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The interface between stochastic analysis and machine learning is a rapidlyevolving field, with path signatures - iterated integrals that providefaithful, hierarchical representations of paths - offering a principled anduniversal feature map for sequential and structured data. Rooted in rough paththeory, path signatures are invariant to reparameterization and well-suited formodelling evolving dynamics, long-range dependencies, and irregular sampling -common challenges in real-world time series and graph data.  This thesis investigates how to harness the expressive power of pathsignatures within scalable machine learning pipelines. It introduces a suite ofmodels that combine theoretical robustness with computational efficiency,bridging rough path theory with probabilistic modelling, deep learning, andkernel methods. Key contributions include: Gaussian processes with signaturekernel-based covariance functions for uncertainty-aware time series modelling;the Seq2Tens framework, which employs low-rank tensor structure in the weightspace for scalable deep modelling of long-range dependencies; and graph-basedmodels where expected signatures over graphs induce hypo-elliptic diffusionprocesses, offering expressive yet tractable alternatives to standard graphneural networks. Further developments include Random Fourier SignatureFeatures, a scalable kernel approximation with theoretical guarantees, andRecurrent Sparse Spectrum Signature Gaussian Processes, which combine Gaussianprocesses, signature kernels, and random features with a principled forgettingmechanism for multi-horizon time series forecasting with adaptive contextlength.  We hope this thesis serves as both a methodological toolkit and a conceptualbridge, and provides a useful reference for the current state of the art inscalable, signature-based learning for sequential and structured data.</description>
      <author>example@mail.com (Csaba Tóth)</author>
      <guid isPermaLink="false">2506.17634v2</guid>
      <pubDate>Thu, 26 Jun 2025 14:19:04 +0800</pubDate>
    </item>
    <item>
      <title>Can AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy Morphology Augmentation</title>
      <link>http://arxiv.org/abs/2506.16233v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  We have submitted to AAS journals. See another independent work for  further reference -- Category-based Galaxy Image Generation via Diffusion  Models (Fan, Tang et al.). Comments are welcome&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种条件扩散模型，用于合成逼真的星系图像，以增强机器学习训练数据，从而提高天文学中稀少天体的检测能力。&lt;h4&gt;背景&lt;/h4&gt;天文观测依赖于视觉特征识别来检测关键天体现象。尽管机器学习日益自动化这一过程，但由于标注数据集代表性有限，模型在大型巡天中的泛化能力仍然面临挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种条件扩散模型，用于生成逼真的星系图像，以增强机器学习训练数据。&lt;h4&gt;方法&lt;/h4&gt;利用包含视觉特征与星系图像对的Galaxy Zoo 2数据集，模型生成了符合指定形态特征条件的多样化、高保真星系图像。此外，该模型能够进行生成性外推，将标注数据扩展到未见领域，并提高稀少天体检测能力。&lt;h4&gt;主要发现&lt;/h4&gt;将合成图像整合到机器学习流程中，在标准形态分类中提高了性能，完整性纯度等关键指标提升了30%。以具有显著尘埃带特征的椭圆星系作为测试案例，与基于视觉检查的先前研究相比，检测到的实例数量从352个增加到872个。&lt;h4&gt;结论&lt;/h4&gt;这项研究突出了生成模型在连接稀缺标注数据与天文观测广泛未探索参数空间之间的作用，并为未来的天体物理学基础模型发展提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;Observational astronomy relies on visual feature identification to detect critical astrophysical phenomena. While machine learning (ML) increasingly automates this process, models often struggle with generalization in large-scale surveys due to the limited representativeness of labeled datasets-- whether from simulations or human annotation -- a challenge pronounced for rare yet scientifically valuable objects. To address this, we propose a conditional diffusion model to synthesize realistic galaxy images for augmenting ML training data. Leveraging the Galaxy Zoo 2 dataset which contains visual feature -- galaxy image pairs from volunteer annotation, we demonstrate that our model generates diverse, high-fidelity galaxy images closely adhere to the specified morphological feature conditions. Moreover, this model enables generative extrapolation to project well-annotated data into unseen domains and advancing rare object detection. Integrating synthesized images into ML pipelines improves performance in standard morphology classification, boosting completeness and purity by up to 30% across key metrics. For rare object detection, using early-type galaxies with prominent dust lane features (~0.1% in GZ2 dataset) as a test case, our approach doubled the number of detected instances from 352 to 872, compared to previous studies based on visual inspection. This study highlights the power of generative models to bridge gaps between scarce labeled data and the vast, uncharted parameter space of observational astronomy and sheds insight for future astrophysical foundation model developments. Our project homepage is available at https://galaxysd-webpage.streamlit.app.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Observational astronomy relies on visual feature identification to detectcritical astrophysical phenomena. While machine learning (ML) increasinglyautomates this process, models often struggle with generalization inlarge-scale surveys due to the limited representativeness of labeled datasets-- whether from simulations or human annotation -- a challenge pronounced forrare yet scientifically valuable objects. To address this, we propose aconditional diffusion model to synthesize realistic galaxy images foraugmenting ML training data. Leveraging the Galaxy Zoo 2 dataset which containsvisual feature -- galaxy image pairs from volunteer annotation, we demonstratethat our model generates diverse, high-fidelity galaxy images closely adhere tothe specified morphological feature conditions. Moreover, this model enablesgenerative extrapolation to project well-annotated data into unseen domains andadvancing rare object detection. Integrating synthesized images into MLpipelines improves performance in standard morphology classification, boostingcompleteness and purity by up to 30\% across key metrics. For rare objectdetection, using early-type galaxies with prominent dust lane features ($\sim$0.1\% in GZ2 dataset) as a test case, our approach doubled the number ofdetected instances from 352 to 872, compared to previous studies based onvisual inspection. This study highlights the power of generative models tobridge gaps between scarce labeled data and the vast, uncharted parameter spaceof observational astronomy and sheds insight for future astrophysicalfoundation model developments. Our project homepage is available athttps://galaxysd-webpage.streamlit.app/.</description>
      <author>example@mail.com (Chenrui Ma, Zechang Sun, Tao Jing, Zheng Cai, Yuan-Sen Ting, Song Huang, Mingyu Li)</author>
      <guid isPermaLink="false">2506.16233v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
  <item>
      <title>Iterative Quantum Feature Maps</title>
      <link>http://arxiv.org/abs/2506.19461v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 12 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为迭代量子特征映射（IQFMs）的混合量子-经典框架，用于构建深度架构，旨在解决量子机器学习模型在实际量子硬件上部署的挑战。&lt;h4&gt;背景&lt;/h4&gt;量子机器学习模型利用量子电路作为量子特征映射（QFMs）在任务学习中表现出强大的表达能力，但部署深度QFMs面临电路噪声和硬件限制的挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种新的量子特征映射方法，以减少量子计算时间并减轻噪声影响，同时提高量子机器学习模型在真实量子硬件上的性能。&lt;h4&gt;方法&lt;/h4&gt;IQFMs通过迭代连接浅层QFMs与经典计算增强权重来构建深度架构，并采用对比学习和分层训练机制。&lt;h4&gt;主要发现&lt;/h4&gt;IQFMs在涉及噪声量子数据任务中优于量子卷积神经网络，无需优化变分量子参数，并在经典图像分类基准测试中达到与经典神经网络相当的性能。&lt;h4&gt;结论&lt;/h4&gt;IQFMs框架为解决当前量子机器学习限制并充分利用量子增强机器学习的潜力提供了一个有前景的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantum machine learning models that leverage quantum circuits as quantumfeature maps (QFMs) are recognized for their enhanced expressive power inlearning tasks. Such models have demonstrated rigorous end-to-end quantumspeedups for specific families of classification problems. However, deployingdeep QFMs on real quantum hardware remains challenging due to circuit noise andhardware constraints. Additionally, variational quantum algorithms often sufferfrom computational bottlenecks, particularly in accurate gradient estimation,which significantly increases quantum resource demands during training. Wepropose Iterative Quantum Feature Maps (IQFMs), a hybrid quantum-classicalframework that constructs a deep architecture by iteratively connecting shallowQFMs with classically computed augmentation weights. By incorporatingcontrastive learning and a layer-wise training mechanism, IQFMs effectivelyreduces quantum runtime and mitigates noise-induced degradation. In tasksinvolving noisy quantum data, numerical experiments show that IQFMs outperformsquantum convolutional neural networks, without requiring the optimization ofvariational quantum parameters. Even for a typical classical imageclassification benchmark, a carefully designed IQFMs achieves performancecomparable to that of classical neural networks. This framework presents apromising path to address current limitations and harness the full potential ofquantum-enhanced machine learning.</description>
      <author>example@mail.com (Nasa Matsumoto, Quoc Hoan Tran, Koki Chinzei, Yasuhiro Endo, Hirotaka Oshima)</author>
      <guid isPermaLink="false">2506.19461v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Correspondence-Free Multiview Point Cloud Registration via Depth-Guided Joint Optimisation</title>
      <link>http://arxiv.org/abs/2506.18922v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, accepted for publication in IEEE/RSJ International  Conference on Intelligent Robots and Systems (IROS 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新颖的无对应关系的多视角点云配准方法，旨在解决复杂环境中传统方法在特征提取和数据关联上的挑战。&lt;h4&gt;背景&lt;/h4&gt;多视角点云配准是构建全局一致3D模型的基础任务，现有方法通常依赖于多个点云之间的特征提取和数据关联，但在复杂环境中难以获得全局最优解。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需特征提取和数据关联的多视角点云配准方法，以提高配准的准确性和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;将全局地图表示为深度图，并利用原始深度信息构建一个非线性最小二乘优化问题，联合估计点云的姿态和全局地图。通过点云的对应姿态将多帧点云与全局深度图关联，并在优化过程中隐式地结合和动态地细化这种数据关联。&lt;h4&gt;主要发现&lt;/h4&gt;在真实世界数据集上的广泛评估表明，该方法在准确性方面优于现有方法，特别是在特征提取和数据关联困难的环境中。&lt;h4&gt;结论&lt;/h4&gt;提出的方法在复杂环境中提高了点云配准的准确性，为构建全局一致3D模型提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multiview point cloud registration is a fundamental task for constructingglobally consistent 3D models. Existing approaches typically rely on featureextraction and data association across multiple point clouds; however, theseprocesses are challenging to obtain global optimal solution in complexenvironments. In this paper, we introduce a novel correspondence-free multiviewpoint cloud registration method. Specifically, we represent the global map as adepth map and leverage raw depth information to formulate a non-linear leastsquares optimisation that jointly estimates poses of point clouds and theglobal map. Unlike traditional feature-based bundle adjustment methods, whichrely on explicit feature extraction and data association, our method bypassesthese challenges by associating multi-frame point clouds with a global depthmap through their corresponding poses. This data association is implicitlyincorporated and dynamically refined during the optimisation process. Extensiveevaluations on real-world datasets demonstrate that our method outperformsstate-of-the-art approaches in accuracy, particularly in challengingenvironments where feature extraction and data association are difficult.</description>
      <author>example@mail.com (Yiran Zhou, Yingyu Wang, Shoudong Huang, Liang Zhao)</author>
      <guid isPermaLink="false">2506.18922v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>VideoPCDNet: Video Parsing and Prediction with Phase Correlation Networks</title>
      <link>http://arxiv.org/abs/2506.19621v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted for Publication at ICANN 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;VideoPCDNet是一种用于对象为中心的视频分解和预测的无监督框架，它通过频率域相干技术将视频递归分解为对象组件，并能够实现准确和可解释的跟踪。&lt;h4&gt;背景&lt;/h4&gt;理解和预测视频内容对于动态环境中的规划和推理至关重要，尽管已经取得进展，但无监督学习对象表示和动力学仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出VideoPCDNet，用于实现无监督对象跟踪和未来视频帧的预测。&lt;h4&gt;方法&lt;/h4&gt;VideoPCDNet使用频率域相干技术将视频递归分解为对象组件，并通过结合频率域操作和轻量级学习模块来显式地建模对象运动。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，VideoPCDNet在多个合成数据集上优于多个对象为中心的无监督跟踪和预测的基线模型，并学习到可解释的对象和运动表示。&lt;h4&gt;结论&lt;/h4&gt;VideoPCDNet能够实现准确的非监督对象跟踪和预测，为动态环境中的规划和推理提供了有效工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Understanding and predicting video content is essential for planning andreasoning in dynamic environments. Despite advancements, unsupervised learningof object representations and dynamics remains challenging. We presentVideoPCDNet, an unsupervised framework for object-centric video decompositionand prediction. Our model uses frequency-domain phase correlation techniques torecursively parse videos into object components, which are represented astransformed versions of learned object prototypes, enabling accurate andinterpretable tracking. By explicitly modeling object motion through acombination of frequency domain operations and lightweight learned modules,VideoPCDNet enables accurate unsupervised object tracking and prediction offuture video frames. In our experiments, we demonstrate that VideoPCDNetoutperforms multiple object-centric baseline models for unsupervised trackingand prediction on several synthetic datasets, while learning interpretableobject and motion representations.</description>
      <author>example@mail.com (Noel José Rodrigues Vicente, Enrique Lehner, Angel Villar-Corrales, Jan Nogga, Sven Behnke)</author>
      <guid isPermaLink="false">2506.19621v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Orthogonal Finetuning Made Scalable</title>
      <link>http://arxiv.org/abs/2506.19847v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report (17 pages, 7 figures, project page:  https://spherelab.ai/oftv2/)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了OFTv2，通过优化计算方法和参数化技术，显著提高了OFT的运行效率和内存使用效率，同时保持了性能。&lt;h4&gt;背景&lt;/h4&gt;OFT在适应性和防止灾难性遗忘方面表现出色，但其高运行时间和内存需求限制了其实际应用。&lt;h4&gt;目的&lt;/h4&gt;克服OFT的运行和内存限制，提高其实际部署的可行性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种输入中心的重新表述，使用矩阵-向量乘法（即无矩阵计算），并引入了Cayley-Neumann参数化来近似Cayley变换中的矩阵求逆。&lt;h4&gt;主要发现&lt;/h4&gt;OFTv2实现了10倍以上的训练速度和3倍以下的GPU内存使用，同时保持了性能。此外，OFTv2还支持对量化基础模型进行微调，并在训练稳定性、效率和内存使用方面优于QLoRA。&lt;h4&gt;结论&lt;/h4&gt;OFTv2通过优化计算和参数化，提高了OFT的性能和实用性，使其更适合实际应用场景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Orthogonal finetuning (OFT) offers highly parameter-efficient adaptationwhile preventing catastrophic forgetting, but its high runtime and memorydemands limit practical deployment. We identify the core computationalbottleneck in OFT as its weight-centric implementation, which relies on costlymatrix-matrix multiplications with cubic complexity. To overcome this, wepropose OFTv2, an input-centric reformulation that instead uses matrix-vectormultiplications (i.e., matrix-free computation), reducing the computationalcost to quadratic. We further introduce the Cayley-Neumann parameterization, anefficient orthogonal parameterization that approximates the matrix inversion inCayley transform via a truncated Neumann series. These modifications allowOFTv2 to achieve up to 10x faster training and 3x lower GPU memory usagewithout compromising performance. In addition, we extend OFTv2 to supportfinetuning quantized foundation models and show that it outperforms the popularQLoRA in training stability, efficiency, and memory usage.</description>
      <author>example@mail.com (Zeju Qiu, Weiyang Liu, Adrian Weller, Bernhard Schölkopf)</author>
      <guid isPermaLink="false">2506.19847v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>From memories to maps: Mechanisms of in context reinforcement learning in transformers</title>
      <link>http://arxiv.org/abs/2506.19686v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究通过训练一个Transformer模型进行情境强化学习，探讨了人类和动物快速适应新环境的能力，并提出了记忆可能作为计算资源支持灵活行为的新机制。&lt;h4&gt;背景&lt;/h4&gt;人类和动物展现出卓越的学习效率，能够通过最小经验适应新环境。传统的强化学习算法依赖于增量价值更新，无法很好地捕捉这种能力。&lt;h4&gt;目的&lt;/h4&gt;研究情境强化学习中的快速适应机制，并探究记忆在其中的作用。&lt;h4&gt;方法&lt;/h4&gt;研究人员训练了一个Transformer模型，在由啮齿动物行为启发的规划任务中实现情境强化学习，并分析了模型中出现的算法。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，表征学习依赖于情境结构学习和跨情境对齐，表示可以在具有不同感官刺激的环境中保持一致。模型开发的强化学习策略与传统无模型或基于模型的规划策略不可解释，而是通过在模型内存令牌中缓存中间计算来支持情境强化学习。此外，模型中开发的表示与大脑海马体-内嗅皮层系统相关的计算相似。&lt;h4&gt;结论&lt;/h4&gt;记忆可能作为计算资源存储原始经验和缓存计算，以支持灵活的行为。研究结果为人工和自然环境中的情境学习提供了快速适应的机制假设。&lt;h4&gt;翻译&lt;/h4&gt;Humans and animals show remarkable learning efficiency, adapting to new environments with minimal experience. This capability is not well captured by standard reinforcement learning algorithms that rely on incremental value updates. Rapid adaptation likely depends on episodic memory -- the ability to retrieve specific past experiences to guide decisions in novel contexts. Transformers provide a useful setting for studying these questions because of their ability to learn rapidly in-context and because their key-value architecture resembles episodic memory systems in the brain. We train a transformer to in-context reinforcement learn in a distribution of planning tasks inspired by rodent behavior. We then characterize the learning algorithms that emerge in the model. We first find that representation learning is supported by in-context structure learning and cross-context alignment, where representations are aligned across environments with different sensory stimuli. We next demonstrate that the reinforcement learning strategies developed by the model are not interpretable as standard model-free or model-based planning. Instead, we show that in-context reinforcement learning is supported by caching intermediate computations within the model's memory tokens, which are then accessed at decision time. Overall, we find that memory may serve as a computational resource, storing both raw experience and cached computations to support flexible behavior. Furthermore, the representations developed in the model resemble computations associated with the hippocampal-entorhinal system in the brain, suggesting that our findings may be relevant for natural cognition. Taken together, our work offers a mechanistic hypothesis for the rapid adaptation that underlies in-context learning in artificial and natural settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans and animals show remarkable learning efficiency, adapting to newenvironments with minimal experience. This capability is not well captured bystandard reinforcement learning algorithms that rely on incremental valueupdates. Rapid adaptation likely depends on episodic memory -- the ability toretrieve specific past experiences to guide decisions in novel contexts.Transformers provide a useful setting for studying these questions because oftheir ability to learn rapidly in-context and because their key-valuearchitecture resembles episodic memory systems in the brain. We train atransformer to in-context reinforcement learn in a distribution of planningtasks inspired by rodent behavior. We then characterize the learning algorithmsthat emerge in the model. We first find that representation learning issupported by in-context structure learning and cross-context alignment, whererepresentations are aligned across environments with different sensory stimuli.We next demonstrate that the reinforcement learning strategies developed by themodel are not interpretable as standard model-free or model-based planning.Instead, we show that in-context reinforcement learning is supported by cachingintermediate computations within the model's memory tokens, which are thenaccessed at decision time. Overall, we find that memory may serve as acomputational resource, storing both raw experience and cached computations tosupport flexible behavior. Furthermore, the representations developed in themodel resemble computations associated with the hippocampal-entorhinal systemin the brain, suggesting that our findings may be relevant for naturalcognition. Taken together, our work offers a mechanistic hypothesis for therapid adaptation that underlies in-context learning in artificial and naturalsettings.</description>
      <author>example@mail.com (Ching Fang, Kanaka Rajan)</author>
      <guid isPermaLink="false">2506.19686v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Learning-aided Bigraph Matching Approach to Multi-Crew Restoration of Damaged Power Networks Coupled with Road Transportation Networks</title>
      <link>http://arxiv.org/abs/2506.19703v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IDETC 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于图的恢复规划方法，通过整合多个图来优化关键基础设施网络在灾害后的恢复过程。&lt;h4&gt;背景&lt;/h4&gt;关键基础设施网络的恢复能力取决于恢复速度和恢复功能程度，资源分配是一个组合优化问题。&lt;h4&gt;目的&lt;/h4&gt;设计一种高效的恢复规划方法，通过图强化学习和图匹配技术来优化人员分配和任务调度。&lt;h4&gt;方法&lt;/h4&gt;提出了一种将人员、运输和电网节点合并为异构图的方法，并使用图强化学习设计激励函数，通过两种学习技术（Proximal Policy Optimization和Neuroevolution）训练网络，并使用加权最大匹配进行人员到任务的分配。&lt;h4&gt;主要发现&lt;/h4&gt;通过仿真环境训练的方法在不同场景下表现出良好的泛化和可扩展性，学习策略的性能比随机策略提高了三倍，同时在计算时间和恢复的电力方面优于基于优化的解决方案。&lt;h4&gt;结论&lt;/h4&gt;该方法在关键基础设施网络的恢复规划中具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：关键基础设施网络（CINs）在遭受自然灾害等中断后的恢复能力，既取决于恢复速度，也取决于恢复的运营功能程度。为恢复分配资源是一个组合优化问题，涉及到确定哪些队伍将修复特定的网络节点以及修复的顺序。本文提出了一种基于图的公式化方法，将表示人员、运输和电网节点的两个相互连接的图合并成一个异构图。为了实现高效的规划，将图强化学习（GRL）与双图匹配集成。GRL用于设计根据环境图形化状态分配队伍修复任务的激励函数，确保在不同损坏场景下的泛化。采用了两种学习技术：使用Proximal Policy Optimization训练的图神经网络和通过神经进化训练的另一个图神经网络。学习到的激励函数告知一个二分图，将队伍与修复任务联系起来，从而实现人员到任务的加权最大匹配。使用预先计算节点到节点路径计划的仿真环境来训练所提出的恢复规划方法。使用IEEE 8500个节点的电力分配测试网络与21平方公里的交通网络相结合作为案例研究，场景在损坏节点、仓库和队伍数量方面有所不同。结果表明，该方法在不同场景下具有可推广性和可扩展性，学习策略的性能比随机策略提高了三倍，同时也在计算时间和恢复的电力方面优于基于优化的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The resilience of critical infrastructure networks (CINs) after disruptions,such as those caused by natural hazards, depends on both the speed ofrestoration and the extent to which operational functionality can be regained.Allocating resources for restoration is a combinatorial optimal planningproblem that involves determining which crews will repair specific networknodes and in what order. This paper presents a novel graph-based formulationthat merges two interconnected graphs, representing crew and transportationnodes and power grid nodes, into a single heterogeneous graph. To enableefficient planning, graph reinforcement learning (GRL) is integrated withbigraph matching. GRL is utilized to design the incentive function forassigning crews to repair tasks based on the graph-abstracted state of theenvironment, ensuring generalization across damage scenarios. Two learningtechniques are employed: a graph neural network trained using Proximal PolicyOptimization and another trained via Neuroevolution. The learned incentivefunctions inform a bipartite graph that links crews to repair tasks, enablingweighted maximum matching for crew-to-task allocations. An efficient simulationenvironment that pre-computes optimal node-to-node path plans is used to trainthe proposed restoration planning methods. An IEEE 8500-bus power distributiontest network coupled with a 21 square km transportation network is used as thecase study, with scenarios varying in terms of numbers of damaged nodes,depots, and crews. Results demonstrate the approach's generalizability andscalability across scenarios, with learned policies providing 3-fold betterperformance than random policies, while also outperforming optimization-basedsolutions in both computation time (by several orders of magnitude) and powerrestored.</description>
      <author>example@mail.com (Nathan Maurer, Harshal Kaushik, Roshni Anna Jacob, Jie Zhang, Souma Chowdhury)</author>
      <guid isPermaLink="false">2506.19703v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>HOIverse: A Synthetic Scene Graph Dataset With Human Object Interactions</title>
      <link>http://arxiv.org/abs/2506.19639v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HOIverse的合成数据集，用于室内环境中的人类与机器人协同工作的场景理解研究。&lt;h4&gt;背景&lt;/h4&gt;在人类与机器人共存的室内环境中，场景理解对于机器人执行导航和规划等任务至关重要。然而，当前缺乏可靠的室内场景理解数据集。&lt;h4&gt;目的&lt;/h4&gt;旨在通过创建一个包含精确和密集关系真实值的合成数据集，加速涉及人类场景理解的场景理解研究。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为HOIverse的合成数据集，该数据集包含人类与周围物体之间精确和密集的关系真实值，以及相应的RGB图像、分割掩码、深度图像和人体关键点。计算了各种物体对以及人与物体对之间的参数关系，从而得到准确且无歧义的关系定义。&lt;h4&gt;主要发现&lt;/h4&gt;该数据集在最新的场景图生成模型上进行了基准测试，以预测参数关系和人与物体交互。&lt;h4&gt;结论&lt;/h4&gt;通过HOIverse数据集，可以加速涉及人类场景理解的研究。&lt;h4&gt;翻译&lt;/h4&gt;摘要：当人类和机器人代理共存于一个环境中时，场景理解对于代理执行各种下游任务（如导航和规划）变得至关重要。因此，代理必须能够定位和识别人类执行的动作。当前研究缺乏在人类也是场景一部分的室内环境中进行场景理解的可靠数据集。场景图使我们能够生成场景或图像的结构化表示，以执行视觉场景理解。为了解决这个问题，我们提出了HOIverse，一个位于场景图和人类-物体交互交叉点的合成数据集，包含人类与周围物体之间精确和密集的关系真实值以及相应的RGB图像、分割掩码、深度图像和人体关键点。我们计算了各种物体对以及人与物体对之间的参数关系，从而得到准确且无歧义的关系定义。此外，我们在最新的场景图生成模型上对我们的数据集进行了基准测试，以预测参数关系和人与物体交互。通过这个数据集，我们旨在加速涉及人类场景理解的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; When humans and robotic agents coexist in an environment, scene understandingbecomes crucial for the agents to carry out various downstream tasks likenavigation and planning. Hence, an agent must be capable of localizing andidentifying actions performed by the human. Current research lacks reliabledatasets for performing scene understanding within indoor environments wherehumans are also a part of the scene. Scene Graphs enable us to generate astructured representation of a scene or an image to perform visual sceneunderstanding. To tackle this, we present HOIverse a synthetic dataset at theintersection of scene graph and human-object interaction, consisting ofaccurate and dense relationship ground truths between humans and surroundingobjects along with corresponding RGB images, segmentation masks, depth imagesand human keypoints. We compute parametric relations between various pairs ofobjects and human-object pairs, resulting in an accurate and unambiguousrelation definitions. In addition, we benchmark our dataset on state-of-the-artscene graph generation models to predict parametric relations and human-objectinteractions. Through this dataset, we aim to accelerate research in the fieldof scene understanding involving people.</description>
      <author>example@mail.com (Mrunmai Vivek Phatak, Julian Lorenz, Nico Hörmann, Jörg Hähner, Rainer Lienhart)</author>
      <guid isPermaLink="false">2506.19639v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>ProxelGen: Generating Proteins as 3D Densities</title>
      <link>http://arxiv.org/abs/2506.19820v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了ProxelGen，一种基于3D密度的蛋白质结构生成模型，与传统的3D点云表示方法不同。&lt;h4&gt;背景&lt;/h4&gt;目前蛋白质结构生成主要基于3D点云表示，而ProxelGen采用基于密度的表示方法，即voxelized densities或proxels。&lt;h4&gt;目的&lt;/h4&gt;通过表示蛋白质为proxels，ProxelGen旨在实现新的任务和条件化能力。&lt;h4&gt;方法&lt;/h4&gt;ProxelGen通过一个基于3DCNN的VAE生成编码为proxels的蛋白质，并结合一个在潜在空间上操作的扩散模型。&lt;h4&gt;主要发现&lt;/h4&gt;与现有模型相比，ProxelGen的样本具有更高的新颖性、更好的FID分数，并且与训练集具有相同的设计水平。&lt;h4&gt;结论&lt;/h4&gt;ProxelGen在标准基序支架基准测试中展示了其优势，并且3D密度基础生成方法允许更灵活的形状条件化。&lt;h4&gt;翻译&lt;/h4&gt;We develop ProxelGen, a protein structure generative model that operates on 3D densities as opposed to the prevailing 3D point cloud representations. Representing proteins as voxelized densities, or proxels, enables new tasks and conditioning capabilities. We generate proteins encoded as proxels via a 3DCNN-based VAE in conjunction with a diffusion model operating on its latent space. Compared to state-of-the-art models, ProxelGen's samples achieve higher novelty, better FID scores, and the same level of designability as the training set. ProxelGen's advantages are demonstrated in a standard motif scaffolding benchmark, and we show how 3D density-based generation allows for more flexible shape conditioning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We develop ProxelGen, a protein structure generative model that operates on3D densities as opposed to the prevailing 3D point cloud representations.Representing proteins as voxelized densities, or proxels, enables new tasks andconditioning capabilities. We generate proteins encoded as proxels via a 3DCNN-based VAE in conjunction with a diffusion model operating on its latentspace. Compared to state-of-the-art models, ProxelGen's samples achieve highernovelty, better FID scores, and the same level of designability as the trainingset. ProxelGen's advantages are demonstrated in a standard motif scaffoldingbenchmark, and we show how 3D density-based generation allows for more flexibleshape conditioning.</description>
      <author>example@mail.com (Felix Faltings, Hannes Stark, Regina Barzilay, Tommi Jaakkola)</author>
      <guid isPermaLink="false">2506.19820v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects</title>
      <link>http://arxiv.org/abs/2506.19769v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了多传感器融合感知（MSFP）技术，讨论了其在实体AI中的应用和挑战，并提出了一个从任务无关的角度组织MSFP研究的方法。&lt;h4&gt;背景&lt;/h4&gt;MSFP是实体AI的关键技术，可用于多种下游任务和应用场景，如3D物体检测、语义分割、自动驾驶和群机器人。&lt;h4&gt;目的&lt;/h4&gt;为了帮助研究人员理解MSFP的重要进展并为其未来的研究提供可能的见解。&lt;h4&gt;方法&lt;/h4&gt;从任务无关的角度组织MSFP研究，包括介绍背景、回顾多模态和多代理融合方法，分析时间序列融合方法，以及在LLM时代研究多模态LLM融合方法。&lt;h4&gt;主要发现&lt;/h4&gt;现有的综述存在局限性，包括单一任务或研究领域的导向，以及缺乏对MSFP方法多样性的考虑。&lt;h4&gt;结论&lt;/h4&gt;本文的综述有助于研究人员全面理解MSFP，并为进一步研究提供方向。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多传感器融合感知（MSFP）是实体AI的关键技术，能够服务于多种下游任务（例如，3D物体检测和语义分割）以及应用场景（例如，自动驾驶和群机器人）。最近，在相关综述中已经对基于AI的MSFP方法取得了令人印象深刻的成就进行了回顾。然而，经过严格的详细调查后，我们发现现有的综述存在一些局限性。一方面，大多数综述倾向于单一任务或研究领域，例如3D物体检测或自动驾驶。因此，从事其他相关任务的研究人员往往难以直接受益。另一方面，大多数综述只从多模态融合的单一方面介绍MSFP，而缺乏对MSFP方法多样性的考虑，如多视图融合和时间序列融合。为此，本文从任务无关的角度组织MSFP研究，其中方法是从各种技术视角报告的。具体来说，我们首先介绍了MSFP的背景。接下来，我们回顾了多模态和多代理融合方法。进一步，分析了时间序列融合方法。在LLM时代，我们还研究了多模态LLM融合方法。最后，我们讨论了MSFP的开放挑战和未来方向。我们希望这篇综述能帮助研究人员了解MSFP的重要进展，并为未来的研究提供可能的见解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-sensor fusion perception (MSFP) is a key technology for embodied AI,which can serve a variety of downstream tasks (e.g., 3D object detection andsemantic segmentation) and application scenarios (e.g., autonomous driving andswarm robotics). Recently, impressive achievements on AI-based MSFP methodshave been reviewed in relevant surveys. However, we observe that the existingsurveys have some limitations after a rigorous and detailed investigation. Forone thing, most surveys are oriented to a single task or research field, suchas 3D object detection or autonomous driving. Therefore, researchers in otherrelated tasks often find it difficult to benefit directly. For another, mostsurveys only introduce MSFP from a single perspective of multi-modal fusion,while lacking consideration of the diversity of MSFP methods, such asmulti-view fusion and time-series fusion. To this end, in this paper, we hopeto organize MSFP research from a task-agnostic perspective, where methods arereported from various technical views. Specifically, we first introduce thebackground of MSFP. Next, we review multi-modal and multi-agent fusion methods.A step further, time-series fusion methods are analyzed. In the era of LLM, wealso investigate multimodal LLM fusion methods. Finally, we discuss openchallenges and future directions for MSFP. We hope this survey can helpresearchers understand the important progress in MSFP and provide possibleinsights for future research.</description>
      <author>example@mail.com (Shulan Ruan, Rongwei Wang, Xuchen Shen, Huijie Liu, Baihui Xiao, Jun Shi, Kun Zhang, Zhenya Huang, Yu Liu, Enhong Chen, You He)</author>
      <guid isPermaLink="false">2506.19769v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Emergence of Text Readability in Vision Language Models</title>
      <link>http://arxiv.org/abs/2506.19389v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  EVAL-FoMo Workshop @ CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究VLMs在训练过程中识别图像中文本内容的能力出现方式。&lt;h4&gt;背景&lt;/h4&gt;VLMs的文本可读性能力在大量训练迭代后突然出现，而语义内容理解则从训练早期逐渐发展。&lt;h4&gt;目的&lt;/h4&gt;分析VLMs训练过程中文本识别能力的出现过程，并探讨相应的训练策略。&lt;h4&gt;方法&lt;/h4&gt;通过对比学习分析VLMs的训练过程，观察文本识别能力与语义内容理解能力的发展。&lt;h4&gt;主要发现&lt;/h4&gt;文本可读性能力在训练后期突然出现，而匹配图像与渲染文本的能力发展得更慢，表明了语义整合的深度需求。&lt;h4&gt;结论&lt;/h4&gt;强调了针对VLMs的定制化训练策略以加速文本理解的重要性，并为多模态学习的优化研究奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;本研究调查了在视觉-语言模型（VLMs）训练过程中，识别图像中文本内容的能力是如何出现的。我们的分析揭示了一个关键现象：在大量训练迭代之后，给定图像中的文本可读性能力突然出现，这与从训练早期阶段逐渐发展的语义内容理解形成对比。这种延迟的出现可能反映了对比学习倾向于最初优先考虑一般语义理解，而文本特定的符号处理则后来发展。有趣的是，匹配图像与渲染文本的能力发展得更慢，这表明了更深层次的语义整合需求。这些发现强调了为VLMs定制训练策略以加速文本理解的需要，为优化多模态学习的研究奠定了基础。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We investigate how the ability to recognize textual content within imagesemerges during the training of Vision-Language Models (VLMs). Our analysisreveals a critical phenomenon: the ability to read textual information in agiven image \textbf{(text readability)} emerges abruptly after substantialtraining iterations, in contrast to semantic content understanding whichdevelops gradually from the early stages of training. This delayed emergencemay reflect how contrastive learning tends to initially prioritize generalsemantic understanding, with text-specific symbolic processing developinglater. Interestingly, the ability to match images with rendered text developseven slower, indicating a deeper need for semantic integration. These findingshighlight the need for tailored training strategies to accelerate robust textcomprehension in VLMs, laying the groundwork for future research on optimizingmultimodal learning.</description>
      <author>example@mail.com (Jaeyoo Park, Sanghyuk Chun, Wonjae Kim, Sangdoo Yun, Bohyung Han)</author>
      <guid isPermaLink="false">2506.19389v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>PEVLM: Parallel Encoding for Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.19651v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为PEVLM的并行编码策略，旨在提高视觉语言模型(VLMs)在处理长视频理解任务时的预填充效率，同时不需要对模型进行微调。&lt;h4&gt;背景&lt;/h4&gt;虽然VLMs在视频语言任务上表现出色，但它们在处理长视频理解时受到标准注意力机制的二次复杂性的限制。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法来提高VLMs在长视频理解任务中的预填充效率。&lt;h4&gt;方法&lt;/h4&gt;PEVLM通过将输入分割成带有共享汇点的块状段，保留全注意力位置嵌入，并调整注意力权重以模仿全注意力分布，从而将注意力计算从$O((T imes N)^2)$降低到$O(T imes N)$。&lt;h4&gt;主要发现&lt;/h4&gt;在LongVideoBench基准测试上，PEVLM比现有的推理高效方法提高了高达8.37%的准确性，并在注意力计算速度上实现了7.47倍的提升，同时将端到端延迟减少了40%。在严格的延迟限制下，PEVLM显著优于基线，将准确性从23.26%提高到61.03%。&lt;h4&gt;结论&lt;/h4&gt;PEVLM在低延迟、长上下文视频理解方面表现出色，非常适合于自动驾驶等现实世界应用。&lt;h4&gt;翻译&lt;/h4&gt;Vision-Language Models (VLMs) have demonstrated strong performance in video-language tasks, yet their application to long video understanding remains constrained by the quadratic complexity of standard attention mechanisms. In this paper, we propose PEVLM, a parallel encoding strategy specifically designed to improve the prefill efficiency of VLMs without requiring model finetuning. PEVLM partitions the input into block-wise segments with a shared sink, preserves full-attention positional embeddings, and aligns attention weights to mimic full-attention distributions. This design reduces attention computation from $O((T imes N)^2)$ to $O(T imes N)$ while maintaining high accuracy. Extensive experiments on the LongVideoBench benchmark show that PEVLM achieves up to 8.37% accuracy improvement over existing inference-efficient methods and delivers up to 7.47x speedup in attention computation and 40% reduction in end-to-end latency. Under strict latency constraints, PEVLM significantly outperforms baselines, raising accuracy from 23.26% to 61.03%. These results highlight PEVLM's effectiveness for low-latency, long-context video understanding, making it well-suited for real-world applications such as autonomous driving.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Vision-Language Models (VLMs) have demonstrated strong performance invideo-language tasks, yet their application to long video understanding remainsconstrained by the quadratic complexity of standard attention mechanisms. Inthis paper, we propose \textbf{PEVLM}, a parallel encoding strategyspecifically designed to improve the prefill efficiency of VLMs withoutrequiring model finetuning. PEVLM partitions the input into block-wise segmentswith a shared sink, preserves full-attention positional embeddings, and alignsattention weights to mimic full-attention distributions. This design reducesattention computation from $O((T \times N)^2)$ to $O(T \times N)$ whilemaintaining high accuracy. Extensive experiments on the LongVideoBenchbenchmark show that PEVLM achieves up to 8.37\% accuracy improvement overexisting inference-efficient methods and delivers up to 7.47x speedup inattention computation and 40\% reduction in end-to-end latency. Under strictlatency constraints, PEVLM significantly outperforms baselines, raisingaccuracy from 23.26\% to 61.03\%. These results highlight PEVLM's effectivenessfor low-latency, long-context video understanding, making it well-suited forreal-world applications such as autonomous driving.</description>
      <author>example@mail.com (Letian Kang, Shixian Luo, Yiqiang Li, Xiaoyang Yu, Shenxuan Zhou, Yong Wu)</author>
      <guid isPermaLink="false">2506.19651v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects</title>
      <link>http://arxiv.org/abs/2506.19579v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对机器人视觉-语言模型在桌场景理解中的应用进行了比较研究，评估了不同模型生成场景描述的性能。&lt;h4&gt;背景&lt;/h4&gt;机器人场景理解越来越多地依赖于视觉-语言模型（VLMs）来生成环境的自然语言描述。&lt;h4&gt;目的&lt;/h4&gt;研究桌面场景的图像通过机器人臂上的RGB相机捕获时，不同描述策略的性能。&lt;h4&gt;方法&lt;/h4&gt;机器人从多个视角收集物体图像，评估了几种生成场景描述的模型，并比较了单视角和多视角描述，以及识别真实世界和3D打印物体之间的差异。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，VLMs适用于需要识别常见物体的机器人环境，但在处理新颖表示时无法泛化。&lt;h4&gt;结论&lt;/h4&gt;研究结果为在现实世界场景中部署基础模型提供了实际见解。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents a comparative study on captioning strategies for tabletop scenes captured by a robotic arm equipped with an RGB camera, evaluating the performance of various models that generate scene descriptions. The robot collects images of objects from multiple viewpoints, and the experiments examine the trade-offs between single-view and multi-view captioning, as well as the differences between recognizing real-world and 3D printed objects. The results show that VLMs can be used in robotic settings where common objects need to be recognized, but fail to generalize to novel representations. Our findings provide practical insights into deploying foundation models for embodied agents in real-world settings.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Robotic scene understanding increasingly relies on vision-language models(VLMs) to generate natural language descriptions of the environment. In thiswork, we present a comparative study of captioning strategies for tabletopscenes captured by a robotic arm equipped with an RGB camera. The robotcollects images of objects from multiple viewpoints, and we evaluate severalmodels that generate scene descriptions. We compare the performance of variouscaptioning models, like BLIP and VLMs. Our experiments examine the trade-offsbetween single-view and multi-view captioning, and difference betweenrecognising real-world and 3D printed objects. We quantitatively evaluateobject identification accuracy, completeness, and naturalness of the generatedcaptions. Results show that VLMs can be used in robotic settings where commonobjects need to be recognised, but fail to generalise to novel representations.Our findings provide practical insights into deploying foundation models forembodied agents in real-world settings.</description>
      <author>example@mail.com (Federico Tavella, Kathryn Mearns, Angelo Cangelosi)</author>
      <guid isPermaLink="false">2506.19579v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Sampling Matters in Explanations: Towards Trustworthy Attribution Analysis Building Block in Visual Models through Maximizing Explanation Certainty</title>
      <link>http://arxiv.org/abs/2506.19442v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code:  https://anonymous.4open.science/r/sampling_matters_reproducibility-BB60/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究图像归因分析，旨在突出视觉模型学习到的特征表示，通过突出特征图反映输入的像素级重要性。梯度集成是归因分析的基础，通过整合多个导出样本的梯度来突出与推理相关的语义特征。这种方法通常结合视觉模型中的其他信息，如激活或注意力图，以形成最终的解释。然而，理论分析表明，梯度集成中样本分布与自然图像分布的对齐程度给出了解释确定性的下限。先前的工作通过向图像中添加噪声作为样本，而噪声分布可能导致解释确定性低。出人意料的是，实验表明额外信息可以饱和神经网络。因此，建立可信赖的归因分析需要解决样本分布不匹配的问题。我们提出了一种半最优采样方法，通过抑制输入特征来避免在输入图像中添加额外信息。通过抑制特征得到的样本分布与自然图像分布近似相同。在ImageNet大规模数据集上的广泛定量评估证实了我们的方法的有效性，并在所有实验模型中相对于最先进的基线能够产生更满意的解释。&lt;h4&gt;背景&lt;/h4&gt;图像归因分析旨在强调视觉模型学习到的特征表示，并反映输入的像素级重要性。&lt;h4&gt;目的&lt;/h4&gt;提高归因分析的解释确定性，解决样本分布不匹配问题。&lt;h4&gt;方法&lt;/h4&gt;提出了一种半最优采样方法，通过抑制输入特征来得到与自然图像分布近似的样本分布。&lt;h4&gt;主要发现&lt;/h4&gt;梯度集成中样本分布与自然图像分布的对齐程度是解释确定性的下限；额外信息可以饱和神经网络；抑制特征得到的样本分布近似于自然图像分布。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法能够有效提高归因分析的解释确定性，并优于最先进的基线。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies image attribution analysis, aiming to highlight the feature representations learned by visual models and reflect the pixel-wise importance of inputs. Gradient integration is a foundational approach in attribution analysis, integrating gradients from multiple derived samples to highlight semantic features relevant to inferences. Such an approach often combines with other information from visual models, such as activation or attention maps, to form ultimate explanations. However, theoretical analysis demonstrates that the alignment of the sample distribution in gradient integration with respect to the natural image distribution provides a lower bound for explanation certainty. Previous work has added noise to images as samples, and the noise distributions can lead to low explanation certainty. Counterintuitively, our experiments show that additional information can saturate neural networks. Therefore, building trustworthy attribution analysis requires addressing the issue of sample distribution misalignment. Instead of adding extra information into input images, we present a semi-optimal sampling approach by suppressing features from inputs. The sampled distribution obtained by suppressing features is approximately identical to the distribution of natural images. Extensive quantitative evaluation on the large-scale dataset ImageNet affirms that our approach is effective and can produce more satisfactory explanations compared to state-of-the-art baselines throughout all experimental models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.5281/zenodo.8204453&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Image attribution analysis seeks to highlight the feature representationslearned by visual models such that the highlighted feature maps can reflect thepixel-wise importance of inputs. Gradient integration is a building block inthe attribution analysis by integrating the gradients from multiple derivedsamples to highlight the semantic features relevant to inferences. Such abuilding block often combines with other information from visual models such asactivation or attention maps to form ultimate explanations. Yet, ourtheoretical analysis demonstrates that the extent to the alignment of thesample distribution in gradient integration with respect to natural imagedistribution gives a lower bound of explanation certainty. Prior works addnoise into images as samples and the noise distributions can lead to lowexplanation certainty. Counter-intuitively, our experiment shows that extrainformation can saturate neural networks. To this end, building trustworthyattribution analysis needs to settle the sample distribution misalignmentproblem. Instead of adding extra information into input images, we present asemi-optimal sampling approach by suppressing features from inputs. The sampledistribution by suppressing features is approximately identical to thedistribution of natural images. Our extensive quantitative evaluation on largescale dataset ImageNet affirms that our approach is effective and able to yieldmore satisfactory explanations against state-of-the-art baselines throughoutall experimental models.</description>
      <author>example@mail.com (Róisín Luo, James McDermott, Colm O'Riordan)</author>
      <guid isPermaLink="false">2506.19442v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Genome-Anchored Foundation Model Embeddings Improve Molecular Prediction from Histology Images</title>
      <link>http://arxiv.org/abs/2506.19681v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under Review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PathLUPI是一种利用转录组信息在训练过程中提取基因组锚定组织学嵌入的方法，能够仅通过全切片图像（WSI）进行分子预测，从而为精准肿瘤学提供了一种新的策略。&lt;h4&gt;背景&lt;/h4&gt;精准肿瘤学需要准确的分子洞察，但直接从基因组学获得这些信息对于广泛临床应用来说既昂贵又耗时。目前深度学习方法直接从常规全切片图像中预测复杂分子特征和患者预后仍然是一个主要挑战。&lt;h4&gt;目的&lt;/h4&gt;介绍PathLUPI，并展示其在分子预测和患者预后方面的性能。&lt;h4&gt;方法&lt;/h4&gt;PathLUPI使用转录组特权信息在训练期间提取基因组锚定组织学嵌入，通过在49个分子肿瘤学任务中使用来自20个队列的11,257个病例进行广泛评估。&lt;h4&gt;主要发现&lt;/h4&gt;PathLUPI在49个分子肿瘤学任务中展现出优于仅使用WSI训练的传统方法的表现。它在14个生物标志物预测和分子亚型任务中达到了AUC ≥ 0.80，在5种主要癌症类型的生存队列中达到了C-index ≥ 0.70。PathLUPI嵌入揭示了与特定基因型和相关生物学通路相关的独特的细胞形态学特征。&lt;h4&gt;结论&lt;/h4&gt;PathLUPI通过有效地编码分子上下文以细化WSI表示，克服了现有模型的关键限制，为将分子洞察与常规病理工作流程相结合提供了新的策略，以实现更广泛的临床应用。&lt;h4&gt;翻译&lt;/h4&gt;摘要：精准肿瘤学需要准确的分子洞察，然而，从基因组学中直接获取这些信息对于广泛临床应用来说既昂贵又耗时。直接从常规全切片图像（WSI）中预测复杂的分子特征和患者预后仍然是当前深度学习方法的一个主要挑战。在此，我们介绍了PathLUPI，它利用训练过程中的转录组特权信息来提取基因组锚定的组织学嵌入，使得在推理阶段仅使用WSI就能进行有效的分子预测。通过在49个分子肿瘤学任务中使用来自20个队列的11,257个病例进行广泛的评估，PathLUPI展示了优于仅使用WSI训练的传统方法的优越性能。关键的是，它在14个生物标志物预测和分子亚型任务中达到了AUC ≥ 0.80，在5种主要癌症类型的生存队列中达到了C-index ≥ 0.70。此外，PathLUPI嵌入揭示了与特定基因型和相关生物学通路相关的独特的细胞形态学特征。通过有效地编码分子上下文以细化WSI表示，PathLUPI克服了现有模型的关键限制，为将分子洞察与常规病理工作流程相结合提供了新的策略，以实现更广泛的临床应用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Precision oncology requires accurate molecular insights, yet obtaining thesedirectly from genomics is costly and time-consuming for broad clinical use.Predicting complex molecular features and patient prognosis directly fromroutine whole-slide images (WSI) remains a major challenge for current deeplearning methods. Here we introduce PathLUPI, which uses transcriptomicprivileged information during training to extract genome-anchored histologicalembeddings, enabling effective molecular prediction using only WSIs atinference. Through extensive evaluation across 49 molecular oncology tasksusing 11,257 cases among 20 cohorts, PathLUPI demonstrated superior performancecompared to conventional methods trained solely on WSIs. Crucially, it achievesAUC $\geq$ 0.80 in 14 of the biomarker prediction and molecular subtyping tasksand C-index $\geq$ 0.70 in survival cohorts of 5 major cancer types. Moreover,PathLUPI embeddings reveal distinct cellular morphological signaturesassociated with specific genotypes and related biological pathways within WSIs.By effectively encoding molecular context to refine WSI representations,PathLUPI overcomes a key limitation of existing models and offers a novelstrategy to bridge molecular insights with routine pathology workflows forwider clinical application.</description>
      <author>example@mail.com (Cheng Jin, Fengtao Zhou, Yunfang Yu, Jiabo Ma, Yihui Wang, Yingxue Xu, Huajun Zhou, Hao Jiang, Luyang Luo, Luhui Mao, Zifan He, Xiuming Zhang, Jing Zhang, Ronald Chan, Herui Yao, Hao Chen)</author>
      <guid isPermaLink="false">2506.19681v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>General Methods Make Great Domain-specific Foundation Models: A Case-study on Fetal Ultrasound</title>
      <link>http://arxiv.org/abs/2506.19552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted version of paper accepted at MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了在大型无标签医疗数据集上，研究者是预训练自定义基础模型还是使用现有通用模型进行迁移学习，以及预训练自定义模型时是否需要新颖方法的问题。&lt;h4&gt;背景&lt;/h4&gt;研究者面对的两个问题是：是否应该在医疗数据上预训练自定义基础模型，或者使用从现有通用模型迁移学习，以及如果预训练自定义模型，是否需要新颖方法。&lt;h4&gt;目的&lt;/h4&gt;通过案例研究来探讨这些问题，并在一个包含200万图像的大型区域性胎儿超声数据集上训练基础模型。&lt;h4&gt;方法&lt;/h4&gt;选择DINOv2方法进行预训练，并在三个涵盖不同国家数据、分类、分割和少样本任务的胎儿超声数据集上实现最先进的成果。与在自然图像、超声图像和监督基准上预训练的一系列模型进行比较。&lt;h4&gt;主要发现&lt;/h4&gt;（1）在自定义数据上预训练是有价值的，即使较小的模型在较少的数据上训练，因为自然图像预训练的扩展并不适用于超声性能；（2）计算机视觉中的良好调优方法使得为特定医疗领域训练自定义基础模型变得可行，无需超参数调整和少量方法学适应。&lt;h4&gt;结论&lt;/h4&gt;在共同的计算资源约束下开发特定领域的自定义基础模型时，应避免偏向方法创新。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在访问大规模、无标签的医疗数据集时，研究者面临两个问题：他们是否应该尝试在医疗数据上预训练自定义基础模型，或者使用现有通用模型的迁移学习？如果预训练自定义模型，是否需要新颖方法？在本研究中，我们通过案例研究来探讨这些问题，在该案例研究中，我们在一个包含200万图像的大型区域性胎儿超声数据集上训练了一个基础模型。通过选择DINOv2方法进行预训练，我们在三个涵盖不同国家数据、分类、分割和少样本任务的胎儿超声数据集上实现了最先进的成果。我们将我们的结果与一系列在自然图像、超声图像和监督基准上预训练的模型进行了比较。我们的结果表明两个关键见解：（1）在自定义数据上预训练是有价值的，即使较小的模型在较少的数据上训练，因为自然图像预训练的扩展并不适用于超声性能；（2）计算机视觉中的良好调优方法使得为特定医疗领域训练自定义基础模型变得可行，无需超参数调整和少量方法学适应。鉴于这些发现，我们认为在共同的计算资源约束下开发特定领域的自定义基础模型时，应避免偏向方法创新。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With access to large-scale, unlabeled medical datasets, researchers areconfronted with two questions: Should they attempt to pretrain a customfoundation model on this medical data, or use transfer-learning from anexisting generalist model? And, if a custom model is pretrained, are novelmethods required? In this paper we explore these questions by conducting acase-study, in which we train a foundation model on a large regional fetalultrasound dataset of 2M images. By selecting the well-established DINOv2method for pretraining, we achieve state-of-the-art results on three fetalultrasound datasets, covering data from different countries, classification,segmentation, and few-shot tasks. We compare against a series of modelspretrained on natural images, ultrasound images, and supervised baselines. Ourresults demonstrate two key insights: (i) Pretraining on custom data is worthit, even if smaller models are trained on less data, as scaling in naturalimage pretraining does not translate to ultrasound performance. (ii) Well-tunedmethods from computer vision are making it feasible to train custom foundationmodels for a given medical domain, requiring no hyperparameter tuning andlittle methodological adaptation. Given these findings, we argue that a biastowards methodological innovation should be avoided when developing domainspecific foundation models under common computational resource constraints.</description>
      <author>example@mail.com (Jakob Ambsdorf, Asbjørn Munk, Sebastian Llambias, Anders Nymark Christensen, Kamil Mikolaj, Randall Balestriero, Martin Tolsgaard, Aasa Feragen, Mads Nielsen)</author>
      <guid isPermaLink="false">2506.19552v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Capturing Fine-Grained Alignments Improves 3D Affordance Detection</title>
      <link>http://arxiv.org/abs/2506.19312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MVA 2025 (Oral)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对3D点云中的可用性检测挑战，提出了一种名为LM-AD的新方法，该方法通过利用预训练语言模型有效地捕捉点云与文本之间的细粒度对齐，从而提高了检测的准确性。&lt;h4&gt;背景&lt;/h4&gt;在3D点云中进行可用性检测是一个需要有效捕捉点云与文本之间细粒度对齐的任务。现有方法在处理这种对齐时往往表现不佳，导致在标准基准测试中的性能有限。&lt;h4&gt;目的&lt;/h4&gt;提出LM-AD方法，旨在克服现有方法依赖简单余弦相似度导致的表现力不足的问题，从而提高3D点云中可用性检测的准确性。&lt;h4&gt;方法&lt;/h4&gt;LM-AD方法通过引入可用性查询模块（AQM），利用预训练语言模型有效地捕捉点云与文本之间的细粒度对齐。&lt;h4&gt;主要发现&lt;/h4&gt;在3DAffordanceNet数据集上，LM-AD方法在准确性和平均交并比方面优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;LM-AD方法在3D点云可用性检测方面表现出色，为提高检测准确性提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;在本文中，我们解决了3D点云中可用性检测的挑战，这是一个需要有效地捕捉点云与文本之间细粒度对齐的任务。现有方法通常难以建模这种对齐，导致在标准基准测试上的性能有限。这些方法的一个关键局限性是它们依赖于点云和文本嵌入之间的简单余弦相似度，这缺乏进行细粒度推理所需的表现力。为了解决这个局限性，我们提出了一种新的3D点云可用性检测方法，称为LM-AD。此外，我们引入了可用性查询模块（AQM），通过利用预训练语言模型，有效地捕捉点云与文本之间的细粒度对齐。我们在3DAffordanceNet数据集上展示了我们的方法在准确性和平均交并比方面优于现有方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this work, we address the challenge of affordance detection in 3D pointclouds, a task that requires effectively capturing fine-grained alignmentsbetween point clouds and text. Existing methods often struggle to model suchalignments, resulting in limited performance on standard benchmarks. A keylimitation of these approaches is their reliance on simple cosine similaritybetween point cloud and text embeddings, which lacks the expressiveness neededfor fine-grained reasoning. To address this limitation, we propose LM-AD, anovel method for affordance detection in 3D point clouds. Moreover, weintroduce the Affordance Query Module (AQM), which efficiently capturesfine-grained alignment between point clouds and text by leveraging a pretrainedlanguage model. We demonstrated that our method outperformed existingapproaches in terms of accuracy and mean Intersection over Union on the 3DAffordanceNet dataset.</description>
      <author>example@mail.com (Junsei Tokumitsu, Yuiga Wada)</author>
      <guid isPermaLink="false">2506.19312v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>WebGuard++:Interpretable Malicious URL Detection via Bidirectional Fusion of HTML Subgraphs and Multi-Scale Convolutional BERT</title>
      <link>http://arxiv.org/abs/2506.19356v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;WebGuard++是一个用于恶意URL检测的框架，通过融合URL和HTML特征，显著提高了检测性能。&lt;h4&gt;背景&lt;/h4&gt;现有恶意URL检测方法存在四大不足：URL建模不完整、HTML图稀疏、单向分析、决策不透明。&lt;h4&gt;目的&lt;/h4&gt;提出WebGuard++框架，解决上述不足，实现更有效的恶意URL检测。&lt;h4&gt;方法&lt;/h4&gt;WebGuard++包含四个创新组件：跨尺度URL编码器、子图感知HTML编码器、双向耦合模块和投票模块。&lt;h4&gt;主要发现&lt;/h4&gt;WebGuard++在固定FPR的情况下，TPR比现有基线提高1.1倍至7.9倍。&lt;h4&gt;结论&lt;/h4&gt;WebGuard++在恶意URL检测方面取得了显著进展，为提高检测性能提供了有效方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; URL+HTML feature fusion shows promise for robust malicious URL detection,since attacker artifacts persist in DOM structures. However, prior work suffersfrom four critical shortcomings: (1) incomplete URL modeling, failing tojointly capture lexical patterns and semantic context; (2) HTML graph sparsity,where threat-indicative nodes (e.g., obfuscated scripts) are isolated amidbenign content, causing signal dilution during graph aggregation; (3)unidirectional analysis, ignoring URL-HTML feature bidirectional interaction;and (4) opaque decisions, lacking attribution to malicious DOM components. Toaddress these challenges, we present WebGuard++, a detection framework with 4novel components: 1) Cross-scale URL Encoder: Hierarchically learnslocal-to-global and coarse to fine URL features based on Transformer networkwith dynamic convolution. 2) Subgraph-aware HTML Encoder: Decomposes DOM graphsinto interpretable substructures, amplifying sparse threat signals viaHierarchical feature fusion. 3) Bidirectional Coupling Module: Aligns URL andHTML embeddings through cross-modal contrastive learning, optimizinginter-modal consistency and intra-modal specificity. 4) Voting Module:Localizes malicious regions through consensus voting on malicious subgraphpredictions. Experiments show WebGuard++ achieves significant improvements overstate-of-the-art baselines, achieving 1.1x-7.9x higher TPR at fixed FPR of0.001 and 0.0001 across both datasets.</description>
      <author>example@mail.com (Ye Tian, Zhang Yumin, Yifan Jia, Jianguo Sun, Yanbin Wang)</author>
      <guid isPermaLink="false">2506.19356v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Higher-Order Graph Databases</title>
      <link>http://arxiv.org/abs/2506.19661v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了更高阶图数据库（HO-GDBs）的新类别系统，通过提升和降低范式扩展传统图数据库（GDBs）以支持更高阶交互，并提供了理论分析和原型实现。&lt;h4&gt;背景&lt;/h4&gt;当前图数据库系统无法支持高于一阶（单跳）关系的高阶交互，这对于子图计数、多adic建模和高阶图学习等任务至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出HO-GDBs来解决当前系统不支持高阶交互的问题，并确保查询的正确性、可扩展性和ACID兼容性。&lt;h4&gt;方法&lt;/h4&gt;引入提升和降低范式，实现轻量级、模块化和可并行的HO-GDB原型，提供对超图、节点元组、子图等高阶结构的原生支持。&lt;h4&gt;主要发现&lt;/h4&gt;原型可以扩展到大型高阶OLTP和OLAP工作负载，并展示了高阶如何提高分析任务的效果，例如在GDB中通过44%提高了图神经网络的准确性。&lt;h4&gt;结论&lt;/h4&gt;该工作确保了低延迟和高查询吞吐量，并概括了ACID兼容和最终一致的系统。&lt;h4&gt;翻译&lt;/h4&gt;Recent advances in graph databases (GDBs) have been driving interest in large-scale analytics, yet current systems fail to support higher-order (HO) interactions beyond first-order (one-hop) relations, which are crucial for tasks such as subgraph counting, polyadic modeling, and HO graph learning. We address this by introducing a new class of systems, higher-order graph databases (HO-GDBs) that use lifting and lowering paradigms to seamlessly extend traditional GDBs with HO. We provide a theoretical analysis of OLTP and OLAP queries, ensuring correctness, scalability, and ACID compliance. We implement a lightweight, modular, and parallelizable HO-GDB prototype that offers native support for hypergraphs, node-tuples, subgraphs, and other HO structures under a unified API. The prototype scales to large HO OLTP &amp; OLAP workloads and shows how HO improves analytical tasks, for example enhancing accuracy of graph neural networks within a GDB by 44%. Our work ensures low latency and high query throughput, and generalizes both ACID-compliant and eventually consistent systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in graph databases (GDBs) have been driving interest inlarge-scale analytics, yet current systems fail to support higher-order (HO)interactions beyond first-order (one-hop) relations, which are crucial fortasks such as subgraph counting, polyadic modeling, and HO graph learning. Weaddress this by introducing a new class of systems, higher-order graphdatabases (HO-GDBs) that use lifting and lowering paradigms to seamlesslyextend traditional GDBs with HO. We provide a theoretical analysis of OLTP andOLAP queries, ensuring correctness, scalability, and ACID compliance. Weimplement a lightweight, modular, and parallelizable HO-GDB prototype thatoffers native support for hypergraphs, node-tuples, subgraphs, and other HOstructures under a unified API. The prototype scales to large HO OLTP &amp; OLAPworkloads and shows how HO improves analytical tasks, for example enhancingaccuracy of graph neural networks within a GDB by 44%. Our work ensures lowlatency and high query throughput, and generalizes both ACID-compliant andeventually consistent systems.</description>
      <author>example@mail.com (Maciej Besta, Shriram Chandran, Jakub Cudak, Patrick Iff, Marcin Copik, Robert Gerstenberger, Tomasz Szydlo, Jürgen Müller, Torsten Hoefler)</author>
      <guid isPermaLink="false">2506.19661v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>JCAPT: A Joint Modeling Approach for CAPT</title>
      <link>http://arxiv.org/abs/2506.19315v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to the ISCA SLaTE-2025 Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种新的计算机辅助发音训练（CAPT）框架，用于第二语言（L2）学习中的发音反馈，通过结合自动发音评估（APA）和误发音检测与诊断（MDD）任务，以提升发音学习的效率。&lt;h4&gt;背景&lt;/h4&gt;有效的发音反馈对第二语言学习至关重要，CAPT系统通常包含APA和MDD两个关键任务。&lt;h4&gt;目的&lt;/h4&gt;旨在通过联合建模APA和MDD任务，实现发音评估和误发音诊断的相互促进，并提高CAPT系统的性能。&lt;h4&gt;方法&lt;/h4&gt;研究采用了Mamba选择性状态空间模型（SSM），结合语音学特征和思维令牌策略，共同增强APA和MDD中的可解释性和细粒度时间推理。这是首次在CAPT中将语音学归属、基于SSM的建模和提示结合。&lt;h4&gt;主要发现&lt;/h4&gt;在speechocean762基准测试上，所提出的模型在APA和MDD任务上均优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了联合建模APA和MDD任务的有效性，为CAPT系统的性能提升提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;摘要：有效的发音反馈对于第二语言学习至关重要，这通常需要计算机辅助发音训练（CAPT）系统，这些系统通常包含自动发音评估（APA）和误发音检测与诊断（MDD）两个关键任务。最近的研究表明，这两个任务的联合建模可以带来相互的好处。我们的统一框架利用Mamba选择性状态空间模型（SSM），同时整合语音学特征和思维令牌策略，共同提高APA和MDD的可解释性和细粒度时间推理。据我们所知，这是第一个在CAPT中将语音学归属、基于SSM的建模和提示结合起来的研究。在speechocean762基准测试上的一系列实验表明，我们的模型在APA和MDD任务上均优于先前的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective pronunciation feedback is critical in second language (L2)learning, for which computer-assisted pronunciation training (CAPT) systemsoften encompass two key tasks: automatic pronunciation assessment (APA) andmispronunciation detection and diagnosis (MDD). Recent work has shown thatjoint modeling of these two tasks can yield mutual benefits. Our unifiedframework leverages Mamba, a selective state space model (SSM), whileintegrating phonological features and think token strategies to jointly enhanceinterpretability and fine-grained temporal reasoning in APA and MDD. To ourknowledge, this is the first study to combine phonological attribution,SSM-based modeling, and prompting in CAPT. A series of experiments conducted onthe speechocean762 benchmark demonstrate that our model consistentlyoutperforms prior methods, particularly on the MDD task.</description>
      <author>example@mail.com (Tzu-Hsuan Yang, Yue-Yang He, Berlin Chen)</author>
      <guid isPermaLink="false">2506.19315v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Discrepancy-Aware Graph Mask Auto-Encoder</title>
      <link>http://arxiv.org/abs/2506.19343v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Discrepancy-Aware Graph Mask Auto-Encoder（DGMAE）的图自监督学习方法，用于改进图表示学习中的节点表示，在多个图分析任务中表现优异。&lt;h4&gt;背景&lt;/h4&gt;Masked Graph Auto-Encoder在图表示学习中表现优异，但现有方法在处理异质图时存在局限性，因为它们只关注节点邻域信息，而忽略了不同节点间的差异信息，导致节点表示难以区分。&lt;h4&gt;目的&lt;/h4&gt;提出DGMAE以解决上述问题，通过在掩码过程中重建相邻节点的差异信息，获得更具区分度的节点表示。&lt;h4&gt;方法&lt;/h4&gt;DGMAE通过重建相邻节点的差异信息来获取更区分的节点表示，并在17个广泛使用的基准数据集上进行了实验。&lt;h4&gt;主要发现&lt;/h4&gt;DGMAE能够在低维空间中有效地保留节点的差异信息，并且在节点分类、节点聚类和图分类等三个图分析任务中显著优于现有的图自监督学习方法。&lt;h4&gt;结论&lt;/h4&gt;DGMAE方法在图表示学习中展现出卓越的性能，具有广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE) for graph self-supervised learning to improve node representations, which performs exceptionally well in various graph analysis tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Masked Graph Auto-Encoder, a powerful graph self-supervised trainingparadigm, has recently shown superior performance in graph representationlearning. Existing works typically rely on node contextual information torecover the masked information. However, they fail to generalize well toheterophilic graphs where connected nodes may be not similar, because theyfocus only on capturing the neighborhood information and ignoring thediscrepancy information between different nodes, resulting in indistinguishablenode representations. In this paper, to address this issue, we propose aDiscrepancy-Aware Graph Mask Auto-Encoder (DGMAE). It obtains moredistinguishable node representations by reconstructing the discrepancyinformation of neighboring nodes during the masking process. We conductextensive experiments on 17 widely-used benchmark datasets. The results showthat our DGMAE can effectively preserve the discrepancies of nodes inlow-dimensional space. Moreover, DGMAE significantly outperformsstate-of-the-art graph self-supervised learning methods on three graph analyticincluding tasks node classification, node clustering, and graph classification,demonstrating its remarkable superiority. The code of DGMAE is available athttps://github.com/zhengziyu77/DGMAE.</description>
      <author>example@mail.com (Ziyu Zheng, Yaming Yang, Ziyu Guan, Wei Zhao, Weigang Lu)</author>
      <guid isPermaLink="false">2506.19343v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation</title>
      <link>http://arxiv.org/abs/2506.19269v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AnchorDP3的扩散策略框架，用于双臂机器人操作，在高度随机环境中实现了最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;AnchorDP3通过集成三个关键创新来提高机器人操作的性能。&lt;h4&gt;目的&lt;/h4&gt;提高机器人操作在复杂环境中的性能，特别是在高度随机环境中。&lt;h4&gt;方法&lt;/h4&gt;AnchorDP3的方法包括：(1) 使用渲染的真实数据进行语义分割，对点云中的任务关键对象进行显式分割，提供强大的先验信息；(2) 任务条件特征编码器，轻量级模块处理每个任务增强的点云，通过共享的基于扩散的动作专家实现高效的跨任务学习；(3) 以便利性为基础的关键姿态扩散，具有完整状态监督，用稀疏、几何上有意义的动作锚点（如抓取姿态）替换密集轨迹预测，极大地简化了预测空间；动作专家被强制同时预测机器人关节角度和末端执行器位置，利用几何一致性加速收敛并提高准确性。&lt;h4&gt;主要发现&lt;/h4&gt;AnchorDP3在RoboTwin基准测试中，在各种任务下，在极端随机化的对象、杂乱、桌面高度、光照和背景条件下，实现了98.7%的平均成功率。&lt;h4&gt;结论&lt;/h4&gt;当与RoboTwin的实时到仿真管道集成时，该框架有潜力从场景和指令中完全自主地生成可部署的视觉运动策略，从而完全消除对人类演示的需求。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为AnchorDP3的扩散策略框架，用于双臂机器人操作，在高度随机环境中实现了最先进的性能。AnchorDP3集成了三个关键创新：(1) 使用渲染的真实数据进行语义分割，对点云中的任务关键对象进行显式分割，提供强大的先验信息；(2) 任务条件特征编码器，轻量级模块处理每个任务增强的点云，通过共享的基于扩散的动作专家实现高效的跨任务学习；(3) 以便利性为基础的关键姿态扩散，具有完整状态监督，用稀疏、几何上有意义的动作锚点（如抓取姿态）替换密集轨迹预测，极大地简化了预测空间；动作专家被强制同时预测机器人关节角度和末端执行器位置，利用几何一致性加速收敛并提高准确性。在RoboTwin基准测试中，AnchorDP3在各种任务下，在极端随机化的对象、杂乱、桌面高度、光照和背景条件下，实现了98.7%的平均成功率。当与RoboTwin的实时到仿真管道集成时，该框架有潜力从场景和指令中完全自主地生成可部署的视觉运动策略，从而完全消除对人类演示的需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present AnchorDP3, a diffusion policy framework for dual-arm roboticmanipulation that achieves state-of-the-art performance in highly randomizedenvironments. AnchorDP3 integrates three key innovations: (1)Simulator-Supervised Semantic Segmentation, using rendered ground truth toexplicitly segment task-critical objects within the point cloud, which providesstrong affordance priors; (2) Task-Conditioned Feature Encoders, lightweightmodules processing augmented point clouds per task, enabling efficientmulti-task learning through a shared diffusion-based action expert; (3)Affordance-Anchored Keypose Diffusion with Full State Supervision, replacingdense trajectory prediction with sparse, geometrically meaningful actionanchors, i.e., keyposes such as pre-grasp pose, grasp pose directly anchored toaffordances, drastically simplifying the prediction space; the action expert isforced to predict both robot joint angles and end-effector posessimultaneously, which exploits geometric consistency to accelerate convergenceand boost accuracy. Trained on large-scale, procedurally generated simulationdata, AnchorDP3 achieves a 98.7% average success rate in the RoboTwin benchmarkacross diverse tasks under extreme randomization of objects, clutter, tableheight, lighting, and backgrounds. This framework, when integrated with theRoboTwin real-to-sim pipeline, has the potential to enable fully autonomousgeneration of deployable visuomotor policies from only scene and instruction,totally eliminating human demonstrations from learning manipulation skills.</description>
      <author>example@mail.com (Ziyan Zhao, Ke Fan, He-Yang Xu, Ning Qiao, Bo Peng, Wenlong Gao, Dongjiang Li, Hui Shen)</author>
      <guid isPermaLink="false">2506.19269v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Fast and Distributed Equivariant Graph Neural Networks by Virtual Node Learning</title>
      <link>http://arxiv.org/abs/2506.19482v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了两种针对大规模几何图优化的等变图神经网络（GNNs）的增强方法：FastEGNN和DistEGNN，这些方法在处理大规模稀疏图时提高了效率和性能。&lt;h4&gt;背景&lt;/h4&gt;现有的等变GNNs在处理大规模几何图时效率低下，并且在图稀疏化以提高计算效率时性能显著下降。&lt;h4&gt;目的&lt;/h4&gt;提出FastEGNN和DistEGNN，以解决上述效率挑战，并提高大规模等变图学习的能力。&lt;h4&gt;方法&lt;/h4&gt;FastEGNN通过引入一组虚拟节点来近似大型无序节点图，并采用不同的消息传递和聚合机制来确保虚拟节点的独特性，同时最小化虚拟节点与真实节点坐标之间的最大均值差异（MMD），以实现全局分布式性。DistEGNN是一个分布式扩展，其中虚拟节点在不同设备上的子图之间充当全局桥梁，以维持一致性并显著减少内存和计算开销。&lt;h4&gt;主要发现&lt;/h4&gt;在N体系统、蛋白质动力学、Water-3D和Fluid113K基准测试等四个具有挑战性的领域进行了全面评估，结果表明FastEGNN和DistEGNN在效率和性能方面具有优越性，为大规模等变图学习建立了新的能力。&lt;h4&gt;结论&lt;/h4&gt;FastEGNN和DistEGNN为大规模等变图学习提供了有效的解决方案，显著提高了处理大规模稀疏图的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：等变图神经网络（GNNs）在多个科学应用中取得了显著的成果。然而，现有方法在扩展到大型几何图时面临效率挑战，并且在为了计算可行性而对输入图进行稀疏化时性能显著下降。为了解决这些限制，我们引入了FastEGNN和DistEGNN，这是针对大规模几何图的两个新型等变GNN增强方法。FastEGNN采用了一项关键创新：一组小型的有序虚拟节点，有效地近似了大型无序的真实节点图。具体来说，我们针对不同的虚拟节点实现了不同的消息传递和聚合机制，以确保它们的独特性，并最小化虚拟节点与真实坐标之间的最大均值差异（MMD），以实现全局分布式性。这种设计使得FastEGNN能够在高效处理大规模稀疏图的同时保持高精度。对于极其大规模的几何图，我们提出了DistEGNN，这是一个分布式扩展，其中虚拟节点在不同设备上的子图之间充当全局桥梁，以维持一致性并显著减少内存和计算开销。我们在四个具有挑战性的领域：N体系统（100个节点）、蛋白质动力学（800个节点）、Water-3D（8,000个节点）以及我们新的Fluid113K基准（113,000个节点）全面评估了我们的模型。结果表明，FastEGNN和DistEGNN在效率和性能方面具有优越性，确立了大规模等变图学习的新能力。代码可在https://github.com/GLAD-RUC/DistEGNN上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Equivariant Graph Neural Networks (GNNs) have achieved remarkable successacross diverse scientific applications. However, existing approaches facecritical efficiency challenges when scaling to large geometric graphs andsuffer significant performance degradation when the input graphs are sparsifiedfor computational tractability. To address these limitations, we introduceFastEGNN and DistEGNN, two novel enhancements to equivariant GNNs forlarge-scale geometric graphs. FastEGNN employs a key innovation: a smallordered set of virtual nodes that effectively approximates the large unorderedgraph of real nodes. Specifically, we implement distinct message passing andaggregation mechanisms for different virtual nodes to ensure mutualdistinctiveness, and minimize Maximum Mean Discrepancy (MMD) between virtualand real coordinates to achieve global distributedness. This design enablesFastEGNN to maintain high accuracy while efficiently processing large-scalesparse graphs. For extremely large-scale geometric graphs, we present DistEGNN,a distributed extension where virtual nodes act as global bridges betweensubgraphs in different devices, maintaining consistency while dramaticallyreducing memory and computational overhead. We comprehensively evaluate ourmodels across four challenging domains: N-body systems (100 nodes), proteindynamics (800 nodes), Water-3D (8,000 nodes), and our new Fluid113K benchmark(113,000 nodes). Results demonstrate superior efficiency and performance,establishing new capabilities in large-scale equivariant graph learning. Codeis available at https://github.com/GLAD-RUC/DistEGNN.</description>
      <author>example@mail.com (Yuelin Zhang, Jiacheng Cen, Jiaqi Han, Wenbing Huang)</author>
      <guid isPermaLink="false">2506.19482v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic Manipulation with Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.19498v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  submitted to NeurIPS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为T-Rex的任务自适应框架，用于空间表示提取，以解决现有基于视觉-语言模型（VLM）的机器人操作方法中存在的空间表示提取方案固定、代表性不足或提取时间过长的问题。&lt;h4&gt;背景&lt;/h4&gt;构建能够在现实环境中执行多种任务的通用机器人操作系统是一项具有挑战性的任务。视觉-语言模型（VLMs）在机器人操作任务中显示出巨大的潜力，这主要得益于它们从大规模数据集中获得的大量世界知识。然而，现有的基于VLM的机器人方法通常采用固定的空间表示提取方案，导致代表性不足或提取时间过长。&lt;h4&gt;目的&lt;/h4&gt;提出T-Rex框架，旨在根据特定任务需求动态选择最合适的空间表示提取方案，以提高空间理解、效率和稳定性。&lt;h4&gt;方法&lt;/h4&gt;T-Rex框架通过分析任务复杂性来确定空间表示的类型和粒度，并动态选择合适的空间表示提取方案。&lt;h4&gt;主要发现&lt;/h4&gt;通过在现实世界机器人环境中的综合实验，证明了T-Rex在空间理解、效率和稳定性方面具有显著优势，且无需额外训练。&lt;h4&gt;结论&lt;/h4&gt;T-Rex框架能够有效提高基于VLM的机器人操作系统的性能，为解决现有方法中的空间表示提取问题提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;Building a general robotic manipulation system capable of performing a wide variety of tasks in real-world settings is a challenging task. Vision-Language Models (VLMs) have demonstrated remarkable potential in robotic manipulation tasks, primarily due to the extensive world knowledge they gain from large-scale datasets. In this process, Spatial Representations (such as points representing object positions or vectors representing object orientations) act as a bridge between VLMs and real-world scene, effectively grounding the reasoning abilities of VLMs and applying them to specific task scenarios. However, existing VLM-based robotic approaches often adopt a fixed spatial representation extraction scheme for various tasks, resulting in insufficient representational capability or excessive extraction time. In this work, we introduce T-Rex, a Task-Adaptive Framework for Spatial Representation Extraction, which dynamically selects the most appropriate spatial representation extraction scheme for each entity based on specific task requirements. Our key insight is that task complexity determines the types and granularity of spatial representations, and Stronger representational capabilities are typically associated with Higher overall system operation costs. Through comprehensive experiments in real-world robotic environments, we show that our approach delivers significant advantages in spatial understanding, efficiency, and stability without additional training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Building a general robotic manipulation system capable of performing a widevariety of tasks in real-world settings is a challenging task. Vision-LanguageModels (VLMs) have demonstrated remarkable potential in robotic manipulationtasks, primarily due to the extensive world knowledge they gain fromlarge-scale datasets. In this process, Spatial Representations (such as pointsrepresenting object positions or vectors representing object orientations) actas a bridge between VLMs and real-world scene, effectively grounding thereasoning abilities of VLMs and applying them to specific task scenarios.However, existing VLM-based robotic approaches often adopt a fixed spatialrepresentation extraction scheme for various tasks, resulting in insufficientrepresentational capability or excessive extraction time. In this work, weintroduce T-Rex, a Task-Adaptive Framework for Spatial RepresentationExtraction, which dynamically selects the most appropriate spatialrepresentation extraction scheme for each entity based on specific taskrequirements. Our key insight is that task complexity determines the types andgranularity of spatial representations, and Stronger representationalcapabilities are typically associated with Higher overall system operationcosts. Through comprehensive experiments in real-world robotic environments, weshow that our approach delivers significant advantages in spatialunderstanding, efficiency, and stability without additional training.</description>
      <author>example@mail.com (Yiteng Chen, Wenbo Li, Shiyi Wang, Huiping Zhuang, Qingyao Wu)</author>
      <guid isPermaLink="false">2506.19498v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>A Batch-Insensitive Dynamic GNN Approach to Address Temporal Discontinuity in Graph Streams</title>
      <link>http://arxiv.org/abs/2506.19282v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8pages, 5figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对动态图中的时间连续性问题，提出了一种新的无批处理框架BADGNN，通过时间Lipschitz正则化和自适应注意力调整，提高了模型性能和训练效率。&lt;h4&gt;背景&lt;/h4&gt;在动态图中，保持时间连续性至关重要。然而，使用大批次的基于内存的动态图神经网络（MDGNNs）训练往往会破坏事件序列，导致时间信息丢失。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种方法来减少时间信息损失，并提高参数收敛的难度。&lt;h4&gt;方法&lt;/h4&gt;提出了BADGNN框架，包含两个核心组件：(1) 时间Lipschitz正则化（TLR）来控制参数搜索空间的扩展；(2) 自适应注意力调整（A3）来减轻正则化和批处理引起的注意力扭曲。&lt;h4&gt;主要发现&lt;/h4&gt;通过理论研究和实证分析，发现BADGNN在三个基准数据集上保持了强大的性能，同时能够使用更大的批处理大小和更快的训练速度。&lt;h4&gt;结论&lt;/h4&gt;BADGNN是一种有效的动态图神经网络框架，可以减少时间信息损失，并提高训练效率。&lt;h4&gt;翻译&lt;/h4&gt;In dynamic graphs, preserving temporal continuity is critical. However, Memory-based Dynamic Graph Neural Networks (MDGNNs) trained with large batches often disrupt event sequences, leading to temporal information loss. This discontinuity not only deteriorates temporal modeling but also hinders optimization by increasing the difficulty of parameter convergence. Our theoretical study quantifies this through a Lipschitz upper bound, showing that large batch sizes enlarge the parameter search space. In response, we propose BADGNN, a novel batch-agnostic framework consisting of two core components: (1) Temporal Lipschitz Regularization (TLR) to control parameter search space expansion, and (2) Adaptive Attention Adjustment (A3) to alleviate attention distortion induced by both regularization and batching. Empirical results on three benchmark datasets show that BADGNN maintains strong performance while enabling significantly larger batch sizes and faster training compared to TGN. Our code is available at Code: https://anonymous.4open.science/r/TGN_Lipichitz-C033.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In dynamic graphs, preserving temporal continuity is critical. However,Memory-based Dynamic Graph Neural Networks (MDGNNs) trained with large batchesoften disrupt event sequences, leading to temporal information loss. Thisdiscontinuity not only deteriorates temporal modeling but also hindersoptimization by increasing the difficulty of parameter convergence. Ourtheoretical study quantifies this through a Lipschitz upper bound, showing thatlarge batch sizes enlarge the parameter search space. In response, we proposeBADGNN, a novel batch-agnostic framework consisting of two core components: (1)Temporal Lipschitz Regularization (TLR) to control parameter search spaceexpansion, and (2) Adaptive Attention Adjustment (A3) to alleviate attentiondistortion induced by both regularization and batching. Empirical results onthree benchmark datasets show that BADGNN maintains strong performance whileenabling significantly larger batch sizes and faster training compared to TGN.Our code is available at Code:https://anonymous.4open.science/r/TGN_Lipichitz-C033/.</description>
      <author>example@mail.com (Yang Zhou, Xiaoning Ren)</author>
      <guid isPermaLink="false">2506.19282v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Efficient Extreme Operating Condition Search for Online Relay Setting Calculation in Renewable Power Systems Based on Parallel Graph Neural Network</title>
      <link>http://arxiv.org/abs/2506.19289v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习的EOCS方法，用于在线计算继电保护装置的设置值，以适应电力系统运行条件的变化。&lt;h4&gt;背景&lt;/h4&gt;随着可再生能源的渗透率和逆变器资源的广泛应用，电力系统的运行条件更加波动，需要在线计算继电保护装置的设置值。&lt;h4&gt;目的&lt;/h4&gt;为了提高在线计算继电保护装置设置值的效率，提出了一种基于深度学习的EOCS方法。&lt;h4&gt;方法&lt;/h4&gt;该方法首先将电力系统信息分为四个层次：组件参数层、拓扑连接层、电气距离层和图距离层，然后通过并行图神经网络（PGNN）进行特征提取。接着，将对应每个节点的四个特征层拼接和拉伸，并输入决策网络以预测系统的极端运行条件。&lt;h4&gt;主要发现&lt;/h4&gt;在修改后的IEEE 39节点和118节点测试系统中验证了该方法，其中部分同步发电机被可再生能源单元替代。在计算故障电流时，充分考虑了可再生能源的非线性故障特性。实验结果表明，所提出的PGNN方法在解决EOCS问题时比现有方法具有更高的精度，并且在线计算时间也得到显著提高。&lt;h4&gt;结论&lt;/h4&gt;所提出的PGNN方法能够有效解决EOCS问题，并在在线计算时间上提供了显著的改进。&lt;h4&gt;翻译&lt;/h4&gt;The Extreme Operating Conditions Search (EOCS) problem is one of the keyproblems in relay setting calculation, which is used to ensure that the settingvalues of protection relays can adapt to the changing operating conditions ofpower systems over a period of time after deployment. The high penetrationof renewable energy and the wide application of inverter-based resources makethe operating conditions of renewable power systems more volatile, whichurges the adoption of the online relay setting calculation strategy. However, thecomputation speed of existing EOCS methods based on local enumeration,heuristic algorithms, and mathematical programming cannot meet the efficiencyrequirement of online relay setting calculation. To reduce the time overhead,this paper, for the first time, proposes an efficient deep learning-based EOCSmethod suitable for online relay setting calculation. First, the power systeminformation is formulated as four layers, i.e., a component parameter layer, atopological connection layer, an electrical distance layer, and a graphdistance layer, which are fed into a parallel graph neural network (PGNN) modelfor feature extraction. Then, the four feature layers corresponding to eachnode are spliced and stretched, and then fed into the decision network topredict the extreme operating condition of the system. Finally, the proposedPGNN method is validated on the modified IEEE 39-bus and 118-bus test systems,where some of the synchronous generators are replaced by renewable generationunits. The nonlinear fault characteristics of renewables are fully consideredwhen computing fault currents. The experiment results show that the proposedPGNN method achieves higher accuracy than the existing methods in solving theEOCS problem. Meanwhile, it also provides greater improvements in onlinecomputation time.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Extreme Operating Conditions Search (EOCS) problem is one of the keyproblems in relay setting calculation, which is used to ensure that the settingvalues of protection relays can adapt to the changing operating conditions ofpower systems over a period of time after deployment. The high penetration ofrenewable energy and the wide application of inverter-based resources make theoperating conditions of renewable power systems more volatile, which urges theadoption of the online relay setting calculation strategy. However, thecomputation speed of existing EOCS methods based on local enumeration,heuristic algorithms, and mathematical programming cannot meet the efficiencyrequirement of online relay setting calculation. To reduce the time overhead,this paper, for the first time, proposes an efficient deep learning-based EOCSmethod suitable for online relay setting calculation. First, the power systeminformation is formulated as four layers, i.e., a component parameter layer, atopological connection layer, an electrical distance layer, and a graphdistance layer, which are fed into a parallel graph neural network (PGNN) modelfor feature extraction. Then, the four feature layers corresponding to eachnode are spliced and stretched, and then fed into the decision network topredict the extreme operating condition of the system. Finally, the proposedPGNN method is validated on the modified IEEE 39-bus and 118-bus test systems,where some of the synchronous generators are replaced by renewable generationunits. The nonlinear fault characteristics of renewables are fully consideredwhen computing fault currents. The experiment results show that the proposedPGNN method achieves higher accuracy than the existing methods in solving theEOCS problem. Meanwhile, it also provides greater improvements in onlinecomputation time.</description>
      <author>example@mail.com (Yan Li, Zengli Yang, Youhuai Wang, Jing Wang, Xiaoyu Han, Jingyu Wang, Dongyuan Shi)</author>
      <guid isPermaLink="false">2506.19289v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Riemannian generative decoder</title>
      <link>http://arxiv.org/abs/2506.19133v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  GenBio ICML 2025 (Proceedings of the Workshop on Generative AI for  Biology at the 42nd International Conference on Machine Learning, Vancouver,  Canada. PMLR 267, 2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于黎曼几何的生成解码器，用于在训练解码器网络时找到具有黎曼几何优化的最大似然隐变量，避免了传统方法中密度逼近的难题。&lt;h4&gt;背景&lt;/h4&gt;黎曼表示学习通常依赖于在选择的流形上逼近密度，这一过程可能优化困难，对模型造成损害。&lt;h4&gt;目的&lt;/h4&gt;完全避免上述问题，提出一种新的方法。&lt;h4&gt;方法&lt;/h4&gt;引入黎曼生成解码器，在训练解码器网络的同时使用黎曼优化器找到流形值最大似然隐变量。通过丢弃编码器，大幅简化了与当前方法相比的流形约束，后者通常仅处理少数特定的流形。&lt;h4&gt;主要发现&lt;/h4&gt;在三个案例研究中验证了该方法，包括合成分支扩散过程、从线粒体DNA推断的人类迁移和经历细胞分裂周期的细胞，每个案例都表明学习到的表示符合指定的几何形状，并捕获了固有的非欧几里得结构。&lt;h4&gt;结论&lt;/h4&gt;该方法只需要解码器，与现有架构兼容，并生成与数据几何形状一致的易于解释的潜在空间。&lt;h4&gt;翻译&lt;/h4&gt;摘要：黎曼表示学习通常依赖于在选择的流形上逼近密度。这涉及到优化困难的目標，可能会损害模型。为了完全绕过这个问题，我们引入了黎曼生成解码器，该解码器在训练解码器网络的同时使用黎曼优化器找到具有黎曼几何优化的最大似然隐变量。通过丢弃编码器，与当前方法相比，我们极大地简化了流形约束，后者通常只处理少数特定的流形。我们在三个案例研究中验证了我们的方法——一个合成分支扩散过程、从线粒体DNA推断的人类迁移以及经历细胞分裂周期的细胞——每个案例都表明学习到的表示符合规定的几何形状，并捕获了内在的非欧几里得结构。我们的方法只需要一个解码器，与现有架构兼容，并产生与数据几何形状一致的易于解释的潜在空间。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Riemannian representation learning typically relies on approximatingdensities on chosen manifolds. This involves optimizing difficult objectives,potentially harming models. To completely circumvent this issue, we introducethe Riemannian generative decoder which finds manifold-valued maximumlikelihood latents with a Riemannian optimizer while training a decodernetwork. By discarding the encoder, we vastly simplify the manifold constraintcompared to current approaches which often only handle few specific manifolds.We validate our approach on three case studies -- a synthetic branchingdiffusion process, human migrations inferred from mitochondrial DNA, and cellsundergoing a cell division cycle -- each showing that learned representationsrespect the prescribed geometry and capture intrinsic non-Euclidean structure.Our method requires only a decoder, is compatible with existing architectures,and yields interpretable latent spaces aligned with data geometry.</description>
      <author>example@mail.com (Andreas Bjerregaard, Søren Hauberg, Anders Krogh)</author>
      <guid isPermaLink="false">2506.19133v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Surgery-R1: Advancing Surgical-VQLA with Reasoning Multimodal Large Language Model via Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.19469v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了Surgery-R1模型，旨在提高手术场景理解中的视觉问答任务（Surgical-VQLA）的性能。&lt;h4&gt;背景&lt;/h4&gt;近年来，在手术场景理解领域，特别是Surgical-VQLA任务方面取得了显著进展。然而，现有的Surgical-VQLA模型缺乏深度推理能力和可解释性，这限制了其在临床应用中的可靠性和发展潜力。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，本文受到推理多模态大型语言模型（MLLMs）发展的启发，首先构建了Surgery-R1-54k数据集，包括视觉问答（VQA）、基于情境的问答（Grounding-QA）和思维链（CoT）的配对数据，并提出了首个用于Surgical-VQLA的推理MLLM（Surgery-R1）。&lt;h4&gt;方法&lt;/h4&gt;在Surgery-R1中，设计了一种两阶段微调机制，通过使用监督微调（SFT）和强化微调（RFT）使基本MLLM具备复杂的推理能力。此外，为了在RFT中设计一个高效且高质量的基于规则的奖励系统，我们设计了一种多模态一致性奖励机制以减轻手术场景中可能出现的定位错觉。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，Surgery-R1在Surgical-VQLA任务中优于其他现有最先进（SOTA）模型和广泛使用的MLLMs，同时验证了其推理能力和本文方法的有效性。&lt;h4&gt;结论&lt;/h4&gt;Surgery-R1模型能够有效提高Surgical-VQLA任务的性能，为手术场景理解提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;In recent years, significant progress has been made in the field of surgical scene understanding, particularly in the task of Visual QuestionLocalized-Answering in robotic surgery (Surgical-VQLA). However, existing Surgical-VQLA models lack deep reasoning capabilities and interpretability in surgical scenes, which limits their reliability and potential for development in clinical applications. To address this issue, inspired by the development of Reasoning Multimodal Large Language Models (MLLMs), we first build the Surgery-R1-54k dataset, including paired data for Visual-QA, Grounding-QA, and Chain-of-Thought (CoT). Then, we propose the first Reasoning MLLM for Surgical-VQLA (Surgery-R1). In our Surgery-R1, we design a two-stage fine-tuning mechanism to enable the basic MLLM with complex reasoning abilities by utilizing supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT). Furthermore, for an efficient and high-quality rule-based reward system in our RFT, we design a Multimodal Coherence reward mechanism to mitigate positional illusions that may arise in surgical scenarios. Experiment results demonstrate that Surgery-R1 outperforms other existing state-of-the-art (SOTA) models in the Surgical-VQLA task and widely-used MLLMs, while also validating its reasoning capabilities and the effectiveness of our approach. The code and dataset will be organized in https://github.com/FiFi-HAO467/Surgery-R1.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In recent years, significant progress has been made in the field of surgicalscene understanding, particularly in the task of Visual QuestionLocalized-Answering in robotic surgery (Surgical-VQLA). However, existingSurgical-VQLA models lack deep reasoning capabilities and interpretability insurgical scenes, which limits their reliability and potential for developmentin clinical applications. To address this issue, inspired by the development ofReasoning Multimodal Large Language Models (MLLMs), we first build theSurgery-R1-54k dataset, including paired data for Visual-QA, Grounding-QA, andChain-of-Thought (CoT). Then, we propose the first Reasoning MLLM forSurgical-VQLA (Surgery-R1). In our Surgery-R1, we design a two-stagefine-tuning mechanism to enable the basic MLLM with complex reasoning abilitiesby utilizing supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT).Furthermore, for an efficient and high-quality rule-based reward system in ourRFT, we design a Multimodal Coherence reward mechanism to mitigate positionalillusions that may arise in surgical scenarios. Experiment results demonstratethat Surgery-R1 outperforms other existing state-of-the-art (SOTA) models inthe Surgical-VQLA task and widely-used MLLMs, while also validating itsreasoning capabilities and the effectiveness of our approach. The code anddataset will be organized in https://github.com/FiFi-HAO467/Surgery-R1.</description>
      <author>example@mail.com (Pengfei Hao, Shuaibo Li, Hongqiu Wang, Zhizhuo Kou, Junhang Zhang, Guang Yang, Lei Zhu)</author>
      <guid isPermaLink="false">2506.19469v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>SAM2-SGP: Enhancing SAM2 for Medical Image Segmentation via Support-Set Guided Prompting</title>
      <link>http://arxiv.org/abs/2506.19658v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SAM2-SGP的框架，用于解决SAM2在医学图像分割任务中的挑战，包括消除对人工提示的依赖和解决领域偏移问题。&lt;h4&gt;背景&lt;/h4&gt;SAM2模型在零样本图像分割方面有显著提升，但在医学图像分割任务中，由于缺乏人工提示和领域偏移问题，其性能受限。&lt;h4&gt;目的&lt;/h4&gt;提出SAM2-SGP框架，旨在消除对人工提示的依赖，并通过低秩自适应策略缓解领域偏移问题，从而提高医学图像分割的性能。&lt;h4&gt;方法&lt;/h4&gt;SAM2-SGP利用SAM2的内存机制，通过Pseudo-mask Generation (PMG)模块生成伪掩码，并引入Pseudo-mask Attention (PMA)模块来自动生成边界框和增强局部特征提取。此外，采用低秩自适应(LoRA)策略来减轻领域偏移。&lt;h4&gt;主要发现&lt;/h4&gt;SAM2-SGP在多个医学成像模态的2D和3D数据集上进行了评估，包括眼底摄影、X射线、CT、MRI、PET和超声。结果表明，与nnUNet、SwinUNet、SAM2和MedSAM2等现有模型相比，性能有显著提升。&lt;h4&gt;结论&lt;/h4&gt;SAM2-SGP框架在医学图像分割任务中表现出有效性，并通过公开代码证明了其方法。&lt;h4&gt;翻译&lt;/h4&gt;尽管新的视觉基础模型如Segment Anything Model 2 (SAM2)在零样本图像分割能力方面有显著提升，但依赖人工提供的提示在将SAM2应用于医学图像分割任务时带来了重大挑战。此外，由于SAM2最初是在自然图像和视频中训练的，它在医学图像分割中的性能受到领域偏移问题的限制。为了解决这些挑战，我们提出了SAM2支持集引导提示（SAM2-SGP），这是一个消除手动提示需求的框架。所提出的模型利用SAM2的内存机制，通过支持集中的图像-掩码对通过Pseudo-mask Generation (PMG)模块生成伪掩码。我们进一步引入了一个新的Pseudo-mask Attention (PMA)模块，它使用这些伪掩码来自动生成边界框，并通过引导注意力到相关区域来增强局部特征提取。此外，采用了低秩自适应（LoRA）策略来减轻领域偏移问题。所提出的框架在多个医学成像模态的2D和3D数据集上进行了评估，包括眼底摄影、X射线、计算机断层扫描（CT）、磁共振成像（MRI）、正电子发射断层扫描（PET）和超声。结果表明，与nnUNet和SwinUNet等最先进模型以及SAM2和MedSAM2等基础模型相比，性能有显著提升，突出了所提出方法的有效性。我们的代码在https://github.com/astlian9/SAM_Support上公开。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Although new vision foundation models such as Segment Anything Model 2 (SAM2)have significantly enhanced zero-shot image segmentation capabilities, relianceon human-provided prompts poses significant challenges in adapting SAM2 tomedical image segmentation tasks. Moreover, SAM2's performance in medical imagesegmentation was limited by the domain shift issue, since it was originallytrained on natural images and videos. To address these challenges, we proposedSAM2 with support-set guided prompting (SAM2-SGP), a framework that eliminatedthe need for manual prompts. The proposed model leveraged the memory mechanismof SAM2 to generate pseudo-masks using image-mask pairs from a support set viaa Pseudo-mask Generation (PMG) module. We further introduced a novelPseudo-mask Attention (PMA) module, which used these pseudo-masks toautomatically generate bounding boxes and enhance localized feature extractionby guiding attention to relevant areas. Furthermore, a low-rank adaptation(LoRA) strategy was adopted to mitigate the domain shift issue. The proposedframework was evaluated on both 2D and 3D datasets across multiple medicalimaging modalities, including fundus photography, X-ray, computed tomography(CT), magnetic resonance imaging (MRI), positron emission tomography (PET), andultrasound. The results demonstrated a significant performance improvement overstate-of-the-art models, such as nnUNet and SwinUNet, as well as foundationmodels, such as SAM2 and MedSAM2, underscoring the effectiveness of theproposed approach. Our code is publicly available athttps://github.com/astlian9/SAM_Support.</description>
      <author>example@mail.com (Yang Xing, Jiong Wu, Yuheng Bu, Kuang Gong)</author>
      <guid isPermaLink="false">2506.19658v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data</title>
      <link>http://arxiv.org/abs/2506.19358v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于雷达信号的心电图（ECG）恢复方法，用于在数据有限的新场景中精确跟踪心脏位置，并使用迁移学习模型进行ECG恢复。&lt;h4&gt;背景&lt;/h4&gt;从雷达信号中恢复ECG在文献中已有成功案例，但性能依赖于高质量雷达信号和大量雷达-ECG对，限制了在数据稀缺的新场景中的应用。&lt;h4&gt;目的&lt;/h4&gt;提出一种在数据有限的新场景中恢复ECG的方法，并确保高效获取高质量雷达信号。&lt;h4&gt;方法&lt;/h4&gt;提出了一种 cardio-focusing and -tracking (CFT) 算法来精确跟踪心脏位置，并使用迁移学习模型 RFcardi 从雷达信号中提取与心脏相关的信息，无需ECG真实数据，并通过少量同步雷达-ECG对微调预训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提出的CFT算法可以动态识别心脏位置，RFcardi模型在训练少量雷达-ECG对后能够有效地生成准确的ECG恢复。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在数据有限的情况下能够有效恢复ECG，为在新场景下应用雷达信号恢复ECG提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a method for recovering ECG from radar signals in new scenarios with limited data, which can accurately track the cardiac location and effectively generate accurate ECG recoveries using a transfer learning model RFcardi.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Electrocardiogram (ECG), as a crucial find-grained cardiac feature, has beensuccessfully recovered from radar signals in the literature, but theperformance heavily relies on the high-quality radar signal and numerousradar-ECG pairs for training, restricting the applications in new scenarios dueto data scarcity. Therefore, this work will focus on radar-based ECG recoveryin new scenarios with limited data and propose a cardio-focusing and -tracking(CFT) algorithm to precisely track the cardiac location to ensure an efficientacquisition of high-quality radar signals. Furthermore, a transfer learningmodel (RFcardi) is proposed to extract cardio-related information from theradar signal without ECG ground truth based on the intrinsic sparsity ofcardiac features, and only a few synchronous radar-ECG pairs are required tofine-tune the pre-trained model for the ECG recovery. The experimental resultsreveal that the proposed CFT can dynamically identify the cardiac location, andthe RFcardi model can effectively generate faithful ECG recoveries after usinga small number of radar-ECG pairs for training. The code and dataset areavailable after the publication.</description>
      <author>example@mail.com (Yuanyuan Zhang, Haocheng Zhao, Sijie Xiong, Rui Yang, Eng Gee Lim, Yutao Yue)</author>
      <guid isPermaLink="false">2506.19358v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Contrastive Cross-Modal Learning for Infusing Chest X-ray Knowledge into ECGs</title>
      <link>http://arxiv.org/abs/2506.19329v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CroMoTEX的新型对比学习框架，用于通过胸部X射线学习心电图(ECG)的表征，以诊断多种心脏相关疾病。&lt;h4&gt;背景&lt;/h4&gt;现代诊断流程越来越多地融合多种数据源，如医学图像、结构化记录和生理时间序列。心电图(ECG)和胸部X射线(CXR)是评估心脏状况最常用的两种模态。&lt;h4&gt;目的&lt;/h4&gt;提高心电图(ECG)在早期预警系统中的应用，并利用胸部X射线(CXR)提供的信息。&lt;h4&gt;方法&lt;/h4&gt;CroMoTEX使用胸部X射线进行训练，以学习心电图(ECG)的表征，并使用一种新的监督跨模态对比目标函数和自适应硬负样本加权来实现特征学习。测试时仅依赖心电图输入。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-IV-ECG和MIMIC-CXR数据集上评估，CroMoTEX在所有三种疾病（心肥大、胸水、水肿）上都优于基线方法，水肿的AUROC达到78.31。&lt;h4&gt;结论&lt;/h4&gt;CroMoTEX是一种高效的心脏疾病诊断方法，可以在没有胸部X射线的情况下使用心电图进行诊断。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代诊断流程越来越多地融合多种数据源，如医学图像、结构化记录和生理时间序列。心电图(ECG)和胸部X射线(CXR)是评估心脏状况最常用的两种模态。尽管CXR提供丰富的诊断信息，ECG更易获取，可以支持可扩展的早期预警系统。在本文中，我们提出了CroMoTEX，一种基于对比学习的创新框架，在训练过程中利用胸部X射线来学习心电图(ECG)的临床信息表征，用于多种心脏相关疾病：心肥大、胸水和水肿。我们的方法使用一种新的监督跨模态对比目标函数和自适应硬负样本加权来对齐ECG和CXR表征，从而实现稳健且与任务相关的特征学习。在测试时，CroMoTEX仅依赖心电图输入，允许在实际场景中可扩展地部署，这些场景中胸部X射线可能不可用。在MIMIC-IV-ECG和MIMIC-CXR数据集上评估，CroMoTEX在所有三种疾病上均优于基线方法，水肿的AUROC达到78.31。我们的代码可在github.com/vineetpmoorty/cromotex找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern diagnostic workflows are increasingly multimodal, integrating diversedata sources such as medical images, structured records, and physiological timeseries. Among these, electrocardiograms (ECGs) and chest X-rays (CXRs) are twoof the most widely used modalities for cardiac assessment. While CXRs providerich diagnostic information, ECGs are more accessible and can support scalableearly warning systems. In this work, we propose CroMoTEX, a novel contrastivelearning-based framework that leverages chest X-rays during training to learnclinically informative ECG representations for multiple cardiac-relatedpathologies: cardiomegaly, pleural effusion, and edema. Our method aligns ECGand CXR representations using a novel supervised cross-modal contrastiveobjective with adaptive hard negative weighting, enabling robust andtask-relevant feature learning. At test time, CroMoTEX relies solely on ECGinput, allowing scalable deployment in real-world settings where CXRs may beunavailable. Evaluated on the large-scale MIMIC-IV-ECG and MIMIC-CXR datasets,CroMoTEX outperforms baselines across all three pathologies, achieving up to78.31 AUROC on edema. Our code is available atgithub.com/vineetpmoorty/cromotex.</description>
      <author>example@mail.com (Vineet Punyamoorty, Aditya Malusare, Vaneet Aggarwal)</author>
      <guid isPermaLink="false">2506.19329v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Automating Traffic Monitoring with SHM Sensor Networks via Vision-Supervised Deep Learning</title>
      <link>http://arxiv.org/abs/2506.19023v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于深度学习和结构健康监测传感网络的自动化交通监测方法，旨在提高桥梁的可靠性交通监测。&lt;h4&gt;背景&lt;/h4&gt;桥梁作为基础设施的重要组成部分，其退化问题日益严重，可靠的车流量监测对于评估其剩余使用寿命至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需人工干预，能够实现连续交通监测的深度学习框架。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了计算机视觉辅助的高分辨率数据集生成、监督训练和推理，利用图神经网络（GNN）捕捉传感数据的时空结构和相互依赖关系。&lt;h4&gt;主要发现&lt;/h4&gt;通过将计算机视觉的输出知识转移到结构健康监测传感器上，该框架使得传感器网络达到了与视觉系统相当的高精度，对于轻型车辆的分类准确率达到99%，重型车辆达到94%。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在加速度计和应变计的实际案例研究中表现出最先进的性能。&lt;h4&gt;翻译&lt;/h4&gt;Bridges, as critical components of civil infrastructure, are increasingly affected by deterioration, making reliable traffic monitoring essential for assessing their remaining service life. Among operational loads, traffic load plays a pivotal role, and recent advances in deep learning - particularly in computer vision (CV) - have enabled progress toward continuous, automated monitoring. However, CV-based approaches suffer from limitations, including privacy concerns and sensitivity to lighting conditions, while traditional non-vision-based methods often lack flexibility in deployment and validation. To bridge this gap, we propose a fully automated deep-learning pipeline for continuous traffic monitoring using structural health monitoring (SHM) sensor networks. Our approach integrates CV-assisted high-resolution dataset generation with supervised training and inference, leveraging graph neural networks (GNNs) to capture the spatial structure and interdependence of sensor data. By transferring knowledge from CV outputs to SHM sensors, the proposed framework enables sensor networks to achieve comparable accuracy of vision-based systems, with minimal human intervention. Applied to accelerometer and strain gauge data in a real-world case study, the model achieves state-of-the-art performance, with classification accuracies of 99% for light vehicles and 94% for heavy vehicles.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Bridges, as critical components of civil infrastructure, are increasinglyaffected by deterioration, making reliable traffic monitoring essential forassessing their remaining service life. Among operational loads, traffic loadplays a pivotal role, and recent advances in deep learning - particularly incomputer vision (CV) - have enabled progress toward continuous, automatedmonitoring. However, CV-based approaches suffer from limitations, includingprivacy concerns and sensitivity to lighting conditions, while traditionalnon-vision-based methods often lack flexibility in deployment and validation.To bridge this gap, we propose a fully automated deep-learning pipeline forcontinuous traffic monitoring using structural health monitoring (SHM) sensornetworks. Our approach integrates CV-assisted high-resolution datasetgeneration with supervised training and inference, leveraging graph neuralnetworks (GNNs) to capture the spatial structure and interdependence of sensordata. By transferring knowledge from CV outputs to SHM sensors, the proposedframework enables sensor networks to achieve comparable accuracy ofvision-based systems, with minimal human intervention. Applied to accelerometerand strain gauge data in a real-world case study, the model achievesstate-of-the-art performance, with classification accuracies of 99% for lightvehicles and 94% for heavy vehicles.</description>
      <author>example@mail.com (Hanshuo Wu, Xudong Jian, Christos Lataniotis, Cyprien Hoelzl, Eleni Chatzi, Yves Reuland)</author>
      <guid isPermaLink="false">2506.19023v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Behavioral Anomaly Detection in Distributed Systems via Federated Contrastive Learning</title>
      <link>http://arxiv.org/abs/2506.19246v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对分布式系统中日益突出的异常检测问题，提出了一种基于联邦对比学习的检测方法。&lt;h4&gt;背景&lt;/h4&gt;随着分布式系统的广泛应用，数据隐私、节点异构性和异常模式识别成为传统集中式方法难以克服的局限性。&lt;h4&gt;目的&lt;/h4&gt;旨在克服传统集中式方法在数据隐私、节点异构性和异常模式识别方面的局限性。&lt;h4&gt;方法&lt;/h4&gt;该方法结合了联邦学习的分布式协作建模能力和对比学习的特征判别增强。在本地节点上构建嵌入表示，并构建正负样本对以指导模型学习更具判别性的特征空间。通过联邦聚合策略优化全局模型，而不暴露原始数据。使用编码器将本地行为数据表示在高维空间中，包括系统日志、操作指标和系统调用。模型使用对比损失和分类损失进行训练，以提高其检测细粒度异常模式的能力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个典型攻击类型下进行了评估，并在模拟的实时数据流场景中测试了其响应性。实验结果表明，该方法在多个性能指标上优于现有方法，表现出强大的检测准确性和适应性，有效解决了分布式环境中的复杂异常。&lt;h4&gt;结论&lt;/h4&gt;通过精心设计关键模块和优化训练机制，该方法在隐私保护和检测性能之间取得了平衡，为分布式系统中的智能安全管理提供了一条可行的技术路径。&lt;h4&gt;翻译&lt;/h4&gt;本文针对分布式系统中日益突出的异常检测问题，提出了一种基于联邦对比学习的检测方法。随着分布式系统的广泛应用，数据隐私、节点异构性和异常模式识别成为传统集中式方法难以克服的局限性。旨在克服传统集中式方法在数据隐私、节点异构性和异常模式识别方面的局限性。该方法结合了联邦学习的分布式协作建模能力和对比学习的特征判别增强。在本地节点上构建嵌入表示，并构建正负样本对以指导模型学习更具判别性的特征空间。通过联邦聚合策略优化全局模型，而不暴露原始数据。使用编码器将本地行为数据表示在高维空间中，包括系统日志、操作指标和系统调用。模型使用对比损失和分类损失进行训练，以提高其检测细粒度异常模式的能力。该方法在多个典型攻击类型下进行了评估，并在模拟的实时数据流场景中测试了其响应性。实验结果表明，该方法在多个性能指标上优于现有方法，表现出强大的检测准确性和适应性，有效解决了分布式环境中的复杂异常。通过精心设计关键模块和优化训练机制，该方法在隐私保护和检测性能之间取得了平衡，为分布式系统中的智能安全管理提供了一条可行的技术路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper addresses the increasingly prominent problem of anomaly detectionin distributed systems. It proposes a detection method based on federatedcontrastive learning. The goal is to overcome the limitations of traditionalcentralized approaches in terms of data privacy, node heterogeneity, andanomaly pattern recognition. The proposed method combines the distributedcollaborative modeling capabilities of federated learning with the featurediscrimination enhancement of contrastive learning. It builds embeddingrepresentations on local nodes and constructs positive and negative samplepairs to guide the model in learning a more discriminative feature space.Without exposing raw data, the method optimizes a global model through afederated aggregation strategy. Specifically, the method uses an encoder torepresent local behavior data in high-dimensional space. This includes systemlogs, operational metrics, and system calls. The model is trained using bothcontrastive loss and classification loss to improve its ability to detectfine-grained anomaly patterns. The method is evaluated under multiple typicalattack types. It is also tested in a simulated real-time data stream scenarioto examine its responsiveness. Experimental results show that the proposedmethod outperforms existing approaches across multiple performance metrics. Itdemonstrates strong detection accuracy and adaptability, effectively addressingcomplex anomalies in distributed environments. Through careful design of keymodules and optimization of the training mechanism, the proposed methodachieves a balance between privacy preservation and detection performance. Itoffers a feasible technical path for intelligent security management indistributed systems.</description>
      <author>example@mail.com (Renzi Meng, Heyi Wang, Yumeng Sun, Qiyuan Wu, Lian Lian, Renhan Zhang)</author>
      <guid isPermaLink="false">2506.19246v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Video-XL-2: Towards Very Long-Video Understanding Through Task-Aware KV Sparsification</title>
      <link>http://arxiv.org/abs/2506.19225v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 Figure, 3 Table&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Multi-modal large language models (MLLMs)在视频理解方面取得了显著进步，但处理长视频输入仍面临内存和计算成本高的挑战。Video-XL-2模型通过任务感知的KV稀疏化，为长视频理解提供高效能比。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在视频理解方面取得进展，但处理长视频输入存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出Video-XL-2模型，解决长视频理解中内存和计算成本高的问题。&lt;h4&gt;方法&lt;/h4&gt;Video-XL-2模型采用基于块预填充和双级键值解码的方法，块预填充将视觉标记序列分成块，并在每个块内使用全注意力，块间使用稀疏注意力；双级键值解码根据块与任务的关联性选择性地重新加载密集或稀疏键值。&lt;h4&gt;主要发现&lt;/h4&gt;Video-XL-2在长视频理解基准测试中取得最先进的性能，优于现有开源轻量级模型，同时具有出色的效率。&lt;h4&gt;结论&lt;/h4&gt;Video-XL-2模型在长视频理解方面表现出色，既高效又有效，能够处理大量视频帧。&lt;h4&gt;翻译&lt;/h4&gt;Multi-modal large language models (MLLMs)在视频理解方面取得了显著进步。然而，由于内存和计算成本高，处理长视频输入仍然是一个主要挑战。这使得当前模型在长视频理解中难以同时实现强大的性能和高效的效率。为了应对这一挑战，我们提出了Video-XL-2，这是一种基于任务感知的KV稀疏化的新型MLLM，为长视频理解提供了卓越的成本效益。所提出的框架有两个关键步骤：基于块的预填充和双级键值解码。基于块的预填充将视觉标记序列分成块，在每个块内应用全注意力，在块间应用稀疏注意力。这显著减少了计算和内存开销。在解码过程中，双级键值解码根据每个块与任务的关联性选择性地重新加载密集或稀疏键值。这种方法进一步提高了内存效率，并增强了模型捕捉细粒度信息的能力。Video-XL-2在各种长视频理解基准测试中实现了最先进的性能，优于现有的开源轻量级模型。它还展示了卓越的效率，能够在单个NVIDIA A100（80GB）GPU上处理超过10,000帧，并在几秒钟内处理数千帧。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-modal large language models (MLLMs) models have made significantprogress in video understanding over the past few years. However, processinglong video inputs remains a major challenge due to high memory andcomputational costs. This makes it difficult for current models to achieve bothstrong performance and high efficiency in long video understanding. To addressthis challenge, we propose Video-XL-2, a novel MLLM that delivers superiorcost-effectiveness for long-video understanding based on task-aware KVsparsification. The proposed framework operates with two key steps: chunk-basedpre-filling and bi-level key-value decoding. Chunk-based pre-filling dividesthe visual token sequence into chunks, applying full attention within eachchunk and sparse attention across chunks. This significantly reducescomputational and memory overhead. During decoding, bi-level key-value decodingselectively reloads either dense or sparse key-values for each chunk based onits relevance to the task. This approach further improves memory efficiency andenhances the model's ability to capture fine-grained information. Video-XL-2achieves state-of-the-art performance on various long video understandingbenchmarks, outperforming existing open-source lightweight models. It alsodemonstrates exceptional efficiency, capable of processing over 10,000 frameson a single NVIDIA A100 (80GB) GPU and thousands of frames in just a fewseconds.</description>
      <author>example@mail.com (Minghao Qin, Xiangrui Liu, Zhengyang Liang, Yan Shu, Huaying Yuan, Juenjie Zhou, Shitao Xiao, Bo Zhao, Zheng Liu)</author>
      <guid isPermaLink="false">2506.19225v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Segment Any 3D-Part in a Scene from a Sentence</title>
      <link>http://arxiv.org/abs/2506.19331v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文旨在通过自然语言描述实现场景中任意3D部分的分割，超越了传统的3D场景理解，并解决了数据和方法的挑战。&lt;h4&gt;背景&lt;/h4&gt;由于获取和标注数据的昂贵成本，现有的数据集和方法主要限于对象级别的理解。&lt;h4&gt;目的&lt;/h4&gt;目的是开发一种新的方法，能够基于自然语言描述对场景中的3D部分进行分割。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为3D-PU的数据集，这是第一个具有密集部分标注的大规模3D数据集。此外，还提出了OpenPart3D框架，这是一个仅使用3D输入的框架，用于有效解决部分级别分割的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在开放词汇的3D场景理解任务中表现优异，具有跨多个3D场景数据集的强大泛化能力。&lt;h4&gt;结论&lt;/h4&gt;该研究为高级3D部分场景理解铺平了道路，并展示了基于自然语言描述进行3D部分分割的潜力。&lt;h4&gt;翻译&lt;/h4&gt;本文旨在通过自然语言描述实现场景中任意3D部分的分割，超越了传统的3D场景理解，并解决了数据和方法的挑战。由于获取和标注数据的昂贵成本，现有的数据集和方法主要限于对象级别的理解。为了克服数据和标注可用性的限制，我们引入了3D-PU数据集，这是第一个具有密集部分标注的大规模3D数据集，通过一种创新且成本效益高的方法构建了具有细粒度部分级别标注的合成3D场景，为高级3D部分场景理解铺平了道路。在方法论方面，我们提出了OpenPart3D，这是一个仅使用3D输入的框架，用于有效解决部分级别分割的挑战。广泛的实验表明，我们的方法在开放词汇的3D场景理解任务中表现出优越性，在各种3D场景数据集上具有强大的泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper aims to achieve the segmentation of any 3D part in a scene basedon natural language descriptions, extending beyond traditional object-level 3Dscene understanding and addressing both data and methodological challenges. Dueto the expensive acquisition and annotation burden, existing datasets andmethods are predominantly limited to object-level comprehension. To overcomethe limitations of data and annotation availability, we introduce the 3D-PUdataset, the first large-scale 3D dataset with dense part annotations, createdthrough an innovative and cost-effective method for constructing synthetic 3Dscenes with fine-grained part-level annotations, paving the way for advanced3D-part scene understanding. On the methodological side, we propose OpenPart3D,a 3D-input-only framework to effectively tackle the challenges of part-levelsegmentation. Extensive experiments demonstrate the superiority of our approachin open-vocabulary 3D scene understanding tasks at the part level, with stronggeneralization capabilities across various 3D scene datasets.</description>
      <author>example@mail.com (Hongyu Wu, Pengwan Yang, Yuki M. Asano, Cees G. M. Snoek)</author>
      <guid isPermaLink="false">2506.19331v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI</title>
      <link>http://arxiv.org/abs/2506.19613v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了人工智能在科学研究中的应用及其面临的挑战，提出了智能科学实验室（ISLs）的概念，旨在通过整合认知和具身智能来克服当前科学发现的局限性。&lt;h4&gt;背景&lt;/h4&gt;科学发现长期以来受到人类局限性的制约，包括不熟练的技能、身体能力和睡眠周期。近年来，人工智能科学家和自动化实验室的出现加速了研究的认知和操作方面，但仍然存在关键限制。&lt;h4&gt;目的&lt;/h4&gt;本文旨在提出一种新的研究范式，即智能科学实验室（ISLs），以解决现有科学发现方法的局限性。&lt;h4&gt;方法&lt;/h4&gt;通过分析人工智能在科学研究中的应用，提出了一种多层闭环框架，即智能科学实验室（ISLs），该框架深度整合了认知和具身智能。&lt;h4&gt;主要发现&lt;/h4&gt;智能科学实验室（ISLs）通过统一科学推理的基础模型、基于代理的工作流程编排和用于稳健物理实验的具身智能体，有望实现迭代、自主实验和意外发现的可能性。&lt;h4&gt;结论&lt;/h4&gt;智能科学实验室（ISLs）对于克服当前科学发现的局限性以及实现人工智能驱动科学的全面变革潜力至关重要。&lt;h4&gt;翻译&lt;/h4&gt;Scientific discovery has long been constrained by human limitations, including lack of expertise, physical capability, and sleep cycles. The recent rise of AI scientists and automated laboratories has accelerated both the cognitive and operational aspects of research. However, key limitations persist: AI systems are often confined to virtual environments, while automated laboratories lack the flexibility and autonomy to adaptively test new hypotheses in the physical world. Recent advances in embodied AI, such as generalist robot foundation models, diffusion-based action policies, fine-grained manipulation learning, and sim-to-real transfer, highlight the promise of integrating cognitive and embodied intelligence. This convergence opens the door to closed-loop systems that support iterative, autonomous experimentation and the possibility of serendipitous discovery. In this position paper, we propose the paradigm of Intelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework that deeply integrates cognitive and embodied intelligence. ISLs unify foundation models for scientific reasoning, agent-based workflow orchestration, and embodied agents for robust physical experimentation. We argue that such systems are essential for overcoming the current limitations of scientific discovery and for realizing the full transformative potential of AI-driven science.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scientific discovery has long been constrained by human limitations inexpertise, physical capability, and sleep cycles. The recent rise of AIscientists and automated laboratories has accelerated both the cognitive andoperational aspects of research. However, key limitations persist: AI systemsare often confined to virtual environments, while automated laboratories lackthe flexibility and autonomy to adaptively test new hypotheses in the physicalworld. Recent advances in embodied AI, such as generalist robot foundationmodels, diffusion-based action policies, fine-grained manipulation learning,and sim-to-real transfer, highlight the promise of integrating cognitive andembodied intelligence. This convergence opens the door to closed-loop systemsthat support iterative, autonomous experimentation and the possibility ofserendipitous discovery. In this position paper, we propose the paradigm ofIntelligent Science Laboratories (ISLs): a multi-layered, closed-loop frameworkthat deeply integrates cognitive and embodied intelligence. ISLs unifyfoundation models for scientific reasoning, agent-based workflow orchestration,and embodied agents for robust physical experimentation. We argue that suchsystems are essential for overcoming the current limitations of scientificdiscovery and for realizing the full transformative potential of AI-drivenscience.</description>
      <author>example@mail.com (Sha Zhang, Suorong Yang, Tong Xie, Xiangyuan Xue, Zixuan Hu, Rui Li, Wenxi Qu, Zhenfei Yin, Tianfan Fu, Di Hu, Andres M Bran, Nian Ran, Bram Hoex, Wangmeng Zuo, Philippe Schwaller, Wanli Ouyang, Lei Bai, Yanyong Zhang, Lingyu Duan, Shixiang Tang, Dongzhan Zhou)</author>
      <guid isPermaLink="false">2506.19613v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>SMARTIES: Spectrum-Aware Multi-Sensor Auto-Encoder for Remote Sensing Images</title>
      <link>http://arxiv.org/abs/2506.19585v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SMARTIES的通用且多功能的深度学习模型，旨在提高遥感数据处理的敏捷性和灵活性。&lt;h4&gt;背景&lt;/h4&gt;现有的深度学习模型往往针对单一传感器或固定的传感器组合，这使得模型在适应不同传感器输入时需要架构改变和重新训练，限制了可扩展性和泛化能力。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够处理多种传感器输入的单个模型，以实现遥感数据的灵活处理。&lt;h4&gt;方法&lt;/h4&gt;SMARTIES通过将来自不同传感器的数据投影到一个共享的频谱感知空间中，并使用统一的可变形器模型重构带掩码的多传感器数据来实现这一目标。&lt;h4&gt;主要发现&lt;/h4&gt;SMARTIES在单传感器和多传感器任务中均优于依赖传感器特定预训练的先前模型。&lt;h4&gt;结论&lt;/h4&gt;SMARTIES模型能够提高遥感数据的处理效率和适应性，并支持多种传感器数据的处理。&lt;h4&gt;翻译&lt;/h4&gt;从光学传感器到微波雷达，利用遥感（RS）传感器的互补优势对于实现我们地球的密集时空监测至关重要。相比之下，最近的深度学习模型，无论是特定任务还是基础模型，通常针对单一传感器或固定的传感器组合：适应不同传感器输入需要架构变化和重新训练，限制了可扩展性和跨多个RS传感器的泛化。相反，一个能够调节其特征表示以接受不同传感器作为输入的单个模型将为敏捷和灵活的多传感器RS数据处理铺平道路。为了解决这个问题，我们介绍了一种名为SMARTIES的通用和多功能的基础模型，它可以提升特定于传感器/依赖的努力，并使可扩展性和泛化能力适用于多种RS传感器：SMARTIES将来自不同传感器的数据投影到一个共享的频谱感知空间中，使得在训练和推理过程中都可以使用任意组合的频段。为了获得无传感器的表示，我们训练了一个单一、统一的可变形器模型，通过跨传感器标记混合使用来重建带掩码的多传感器数据。在单一和多模态任务中，SMARTIES在各种传感器上都优于依赖于传感器特定预训练的先前模型。我们的代码和预训练模型可在https://gsumbul.github.io/SMARTIES找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; From optical sensors to microwave radars, leveraging the complementarystrengths of remote sensing (RS) sensors is crucial for achieving densespatio-temporal monitoring of our planet. In contrast, recent deep learningmodels, whether task-specific or foundational, are often specific to singlesensors or to fixed combinations: adapting such models to different sensoryinputs requires both architectural changes and re-training, limitingscalability and generalization across multiple RS sensors. On the contrary, asingle model able to modulate its feature representations to accept diversesensors as input would pave the way to agile and flexible multi-sensor RS dataprocessing. To address this, we introduce SMARTIES, a generic and versatilefoundation model lifting sensor-specific/dependent efforts and enablingscalability and generalization to diverse RS sensors: SMARTIES projects datafrom heterogeneous sensors into a shared spectrum-aware space, enabling the useof arbitrary combinations of bands both for training and inference. To obtainsensor-agnostic representations, we train a single, unified transformer modelreconstructing masked multi-sensor data with cross-sensor token mixup. On bothsingle- and multi-modal tasks across diverse sensors, SMARTIES outperformsprevious models that rely on sensor-specific pretraining. Our code andpretrained models are available at https://gsumbul.github.io/SMARTIES.</description>
      <author>example@mail.com (Gencer Sumbul, Chang Xu, Emanuele Dalsasso, Devis Tuia)</author>
      <guid isPermaLink="false">2506.19585v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.19288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了WaterCaption数据集和Da Yu模型，用于水面环境感知，旨在提升无人水面船舶的环境理解能力。&lt;h4&gt;背景&lt;/h4&gt;水面环境感知对无人水面船舶进行决策至关重要，但现有模型多集中于实例级对象感知，未能实现全局语义理解。&lt;h4&gt;目的&lt;/h4&gt;提高水面环境感知的全局语义理解能力，促进大规模监控和结构化日志生成。&lt;h4&gt;方法&lt;/h4&gt;设计WaterCaption数据集，包含细粒度、多区域的长期文本描述，并提出Da Yu模型，其中包含Nano Transformer Adaptor（NTA）来平衡计算效率和全局及局部视觉特征建模。&lt;h4&gt;主要发现&lt;/h4&gt;WaterCaption包含20.2k图像-文本对数据，词汇量达180万；Da Yu模型在WaterCaption和其他文本生成基准测试中表现优异。&lt;h4&gt;结论&lt;/h4&gt;WaterCaption和Da Yu模型为水面环境感知和视觉地理理解提供了新的研究方向，并显著提升了模型的文本生成能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated waterway environment perception is crucial for enabling unmannedsurface vessels (USVs) to understand their surroundings and make informeddecisions. Most existing waterway perception models primarily focus oninstance-level object perception paradigms (e.g., detection, segmentation).However, due to the complexity of waterway environments, current perceptiondatasets and models fail to achieve global semantic understanding of waterways,limiting large-scale monitoring and structured log generation. With theadvancement of vision-language models (VLMs), we leverage image captioning tointroduce WaterCaption, the first captioning dataset specifically designed forwaterway environments. WaterCaption focuses on fine-grained, multi-regionlong-text descriptions, providing a new research direction for visualgeo-understanding and spatial scene cognition. Exactly, it includes 20.2kimage-text pair data with 1.8 million vocabulary size. Additionally, we proposeDa Yu, an edge-deployable multi-modal large language model for USVs, where wepropose a novel vision-to-language projector called Nano Transformer Adaptor(NTA). NTA effectively balances computational efficiency with the capacity forboth global and fine-grained local modeling of visual features, therebysignificantly enhancing the model's ability to generate long-form textualoutputs. Da Yu achieves an optimal balance between performance and efficiency,surpassing state-of-the-art models on WaterCaption and several other captioningbenchmarks.</description>
      <author>example@mail.com (Runwei Guan, Ningwei Ouyang, Tianhao Xu, Shaofeng Liang, Wei Dai, Yafeng Sun, Shang Gao, Songning Lai, Shanliang Yao, Xuming Hu, Ryan Wen Liu, Yutao Yue, Hui Xiong)</author>
      <guid isPermaLink="false">2506.19288v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Continual Retinal Vision-Language Pre-training upon Incremental Imaging Modalities</title>
      <link>http://arxiv.org/abs/2506.19320v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为RetCoP的基金图像分析模型，旨在通过不断集成不同成像模态的特征，提高模型的泛化能力和减少遗忘率。&lt;h4&gt;背景&lt;/h4&gt;传统的基金图像分析模型主要关注单一模态任务，忽略了不同模态之间的互补性，限制了其适用性。&lt;h4&gt;目的&lt;/h4&gt;提出RetCoP模型，以集成多种基金成像模态，提高模型在动态环境中的适应能力。&lt;h4&gt;方法&lt;/h4&gt;RetCoP是一种持续的视觉-语言预训练框架，通过增量集成来自不同成像模态的图像和文本特征。为了缓解持续预训练中的灾难性遗忘，引入了复述策略和偏对角信息蒸馏方法。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，RetCoP在泛化能力和遗忘率方面优于所有比较方法。&lt;h4&gt;结论&lt;/h4&gt;RetCoP模型在基金图像分析领域表现出色，为持续预训练提供了新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;The abstract is summarized as follows: The paper proposes a model named RetCoP for fundus image analysis, aiming to enhance the model's generalization ability and reduce the forgetting rate by incrementally integrating features from different imaging modalities. The traditional fundus image analysis models mainly focus on single-modal tasks, ignoring the complementarity between different modalities, which limits their applicability. The purpose of this paper is to propose the RetCoP model to integrate various fundus imaging modalities to improve the model's adaptability in dynamic environments. RetCoP is a continual vision-language pre-training framework that incrementally integrates image and text features from different imaging modalities. To mitigate catastrophic forgetting in continual pre-training, a rehearsal strategy utilizing representative image-text pairs and an off-diagonal information distillation approach are introduced. Experiments show that RetCoP outperforms all the compared methods in terms of generalization ability and forgetting rate. The conclusion is that the RetCoP model performs well in the field of fundus image analysis and provides a new solution for continual pre-training.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Traditional fundus image analysis models focus on single-modal tasks,ignoring fundus modality complementarity, which limits their versatility.Recently, retinal foundation models have emerged, but most still remainmodality-specific. Integrating multiple fundus imaging modalities into a singlefoundation model is valuable. However, in dynamic environments, data fromdifferent modalities often arrive incrementally, necessitating continualpre-training. To address this, we propose RetCoP, the first continualvision-language pre-training framework in the fundus domain, whichincrementally integrates image and text features from different imagingmodalities into a single unified foundation model. To mitigate catastrophicforgetting in continual pre-training, we introduce a rehearsal strategyutilizing representative image-text pairs and an off-diagonal informationdistillation approach. The former allows the model to revisit knowledge fromprevious stages, while the latter explicitly preserves the alignment betweenimage and text representations. Experiments show that RetCoP outperforms allthe compared methods, achieving the best generalization and lowest forgettingrate. The code can be found at https://github.com/Yuang-Yao/RetCoP.</description>
      <author>example@mail.com (Yuang Yao, Ruiqi Wu, Yi Zhou, Tao Zhou)</author>
      <guid isPermaLink="false">2506.19320v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Ontology Neural Network and ORTSF: A Framework for Topological Reasoning and Delay-Robust Control</title>
      <link>http://arxiv.org/abs/2506.19277v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, 5 figures, includes theoretical proofs and simulation  results&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种统一的架构，包括本体神经网络（ONN）和本体实时语义织物（ORTSF），旨在解决自主机器人系统在动态、以人为中心的环境中协作时在表示和保持关系语义、上下文推理和认知透明度方面的不足。&lt;h4&gt;背景&lt;/h4&gt;尽管自主机器人系统在感知、定位、建图和控制方面取得了显著进步，但现有框架在几何推理和动态稳定性方面表现优秀，但在表示和保持关系语义、上下文推理和认知透明度方面存在根本差距。&lt;h4&gt;目的&lt;/h4&gt;解决自主机器人系统在动态、以人为中心的环境中协作时在关系语义、上下文推理和认知透明度方面的不足。&lt;h4&gt;方法&lt;/h4&gt;引入了本体神经网络（ONN）和本体实时语义织物（ORTSF）。ONN将关系语义推理形式化为动态拓扑过程，通过将Forman-Ricci曲率、持久同伦和语义张量结构嵌入到统一的损失公式中，确保关系完整性和拓扑一致性。ORTSF将推理轨迹转换为可执行的控制命令，同时补偿系统延迟，并整合预测和延迟感知操作，确保相位裕度和控制信号连续性。&lt;h4&gt;主要发现&lt;/h4&gt;ONN + ORTSF框架能够统一语义认知和鲁棒控制，提供了一种数学原理上坚实且实际可行的认知机器人解决方案。&lt;h4&gt;结论&lt;/h4&gt;本文提出的ONN + ORTSF框架为解决自主机器人系统在动态、以人为中心的环境中协作时的挑战提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advancement of autonomous robotic systems has led to impressivecapabilities in perception, localization, mapping, and control. Yet, afundamental gap remains: existing frameworks excel at geometric reasoning anddynamic stability but fall short in representing and preserving relationalsemantics, contextual reasoning, and cognitive transparency essential forcollaboration in dynamic, human-centric environments. This paper introduces aunified architecture comprising the Ontology Neural Network (ONN) and theOntological Real-Time Semantic Fabric (ORTSF) to address this gap. The ONNformalizes relational semantic reasoning as a dynamic topological process. Byembedding Forman-Ricci curvature, persistent homology, and semantic tensorstructures within a unified loss formulation, ONN ensures that relationalintegrity and topological coherence are preserved as scenes evolve over time.The ORTSF transforms reasoning traces into actionable control commands whilecompensating for system delays. It integrates predictive and delay-awareoperators that ensure phase margin preservation and continuity of controlsignals, even under significant latency conditions. Empirical studiesdemonstrate the ONN + ORTSF framework's ability to unify semantic cognition androbust control, providing a mathematically principled and practically viablesolution for cognitive robotics.</description>
      <author>example@mail.com (Jaehong Oh)</author>
      <guid isPermaLink="false">2506.19277v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Personality Prediction from Life Stories using Language Models</title>
      <link>http://arxiv.org/abs/2506.19258v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages, 5 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于自然语言处理（NLP）的方法，通过分析长篇访谈文本来预测五因素模型（FFM）中的人格特质。&lt;h4&gt;背景&lt;/h4&gt;传统的性格评估依赖于问卷，而NLP通过分析丰富的开放式文本为性格评估提供了新的途径。&lt;h4&gt;目的&lt;/h4&gt;解决对超过2000个标记的长篇访谈文本进行建模的挑战，以预测FFM人格特质。&lt;h4&gt;方法&lt;/h4&gt;提出了一种两步法：首先，使用预训练语言模型的滑动窗口微调来提取上下文嵌入；其次，应用具有注意力机制的循环神经网络（RNN）来整合长距离依赖关系并提高可解释性。&lt;h4&gt;主要发现&lt;/h4&gt;该混合方法有效地结合了预训练变换器和序列建模的优势，提高了预测准确性、效率和可解释性。通过与LLaMA和Longformer等最先进的长期上下文模型进行比较，证明了其有效性。&lt;h4&gt;结论&lt;/h4&gt;结合基于语言的特征和长期上下文建模的潜力，可以推进从生活叙事中评估人格。&lt;h4&gt;翻译&lt;/h4&gt;摘要：自然语言处理（NLP）通过利用丰富的开放式文本为性格评估提供了新的途径，超越了传统的问卷。在本研究中，我们解决了对每个超过2000个标记的长篇访谈文本进行建模的挑战，以预测五因素模型（FFM）的性格特质。我们提出了一种两步法：首先，我们使用预训练语言模型的滑动窗口微调来提取上下文嵌入；然后，我们应用具有注意力机制的循环神经网络（RNN）来整合长距离依赖关系并提高可解释性。这种混合方法有效地结合了预训练变换器和序列建模的优势，以处理长期上下文数据。通过消融研究和与LLaMA和Longformer等最先进的长期上下文模型的比较，我们证明了在预测准确性、效率和可解释性方面的改进。我们的结果强调了结合基于语言的特征与长期上下文建模的潜力，以推进从生活叙事中评估人格。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-24&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Natural Language Processing (NLP) offers new avenues for personalityassessment by leveraging rich, open-ended text, moving beyond traditionalquestionnaires. In this study, we address the challenge of modeling longnarrative interview where each exceeds 2000 tokens so as to predict Five-FactorModel (FFM) personality traits. We propose a two-step approach: first, weextract contextual embeddings using sliding-window fine-tuning of pretrainedlanguage models; then, we apply Recurrent Neural Networks (RNNs) with attentionmechanisms to integrate long-range dependencies and enhance interpretability.This hybrid method effectively bridges the strengths of pretrained transformersand sequence modeling to handle long-context data. Through ablation studies andcomparisons with state-of-the-art long-context models such as LLaMA andLongformer, we demonstrate improvements in prediction accuracy, efficiency, andinterpretability. Our results highlight the potential of combininglanguage-based features with long-context modeling to advance personalityassessment from life narratives.</description>
      <author>example@mail.com (Rasiq Hussain, Jerry Ma, Rithik Khandelwal, Joshua Oltmanns, Mehak Gupta)</author>
      <guid isPermaLink="false">2506.19258v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Object-aware Sound Source Localization via Audio-Visual Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.18557v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多模态大型语言模型（MLLMs）的声源定位框架，旨在通过整合视觉和音频线索来在视觉场景中定位发声物体。该框架解决了在复杂场景中，尤其是视觉相似的无声物体共存时，声源定位的准确性问题。&lt;h4&gt;背景&lt;/h4&gt;现有的声源定位方法在复杂场景中难以准确定位发声物体，特别是在视觉相似的无声物体共存时，因为它们依赖于简单的视听对应关系，无法捕捉发声物体和无声物体之间的细微语义差异。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，本文提出了一个利用MLLMs生成详细上下文信息的声源定位框架，该信息能够明确区分发声前景物体和无声背景物体。&lt;h4&gt;方法&lt;/h4&gt;为了有效地整合这些详细信息，本文引入了两种新的损失函数：对象感知对比对齐（OCA）损失和对象区域隔离（ORI）损失。&lt;h4&gt;主要发现&lt;/h4&gt;在MUSIC和VGGSound数据集上的大量实验结果表明，该方法在单源和多源定位场景中均显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的声源定位框架能够有效地在复杂场景中定位发声物体，并提供了代码和生成的详细上下文信息。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel sound source localization framework based on Multimodal Large Language Models (MLLMs) to localize sound-making objects within visual scenes by integrating visual and audio cues. This framework addresses the challenge of accurately localizing sound-making objects in complex scenes, especially when visually similar silent objects coexist. To effectively integrate this detailed information, two novel loss functions are introduced: Object-aware Contrastive Alignment (OCA) loss and Object Region Isolation (ORI) loss. Extensive experimental results on MUSIC and VGGSound datasets demonstrate the effectiveness of the proposed approach, significantly outperforming existing methods in both single-source and multi-source localization scenarios. Code and generated detailed contextual information are available at: https://github.com/VisualAIKHU/OA-SSL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-visual sound source localization task aims to spatially localizesound-making objects within visual scenes by integrating visual and audio cues.However, existing methods struggle with accurately localizing sound-makingobjects in complex scenes, particularly when visually similar silent objectscoexist. This limitation arises primarily from their reliance on simpleaudio-visual correspondence, which does not capture fine-grained semanticdifferences between sound-making and silent objects. To address thesechallenges, we propose a novel sound source localization framework leveragingMultimodal Large Language Models (MLLMs) to generate detailed contextualinformation that explicitly distinguishes between sound-making foregroundobjects and silent background objects. To effectively integrate this detailedinformation, we introduce two novel loss functions: Object-aware ContrastiveAlignment (OCA) loss and Object Region Isolation (ORI) loss. Extensiveexperimental results on MUSIC and VGGSound datasets demonstrate theeffectiveness of our approach, significantly outperforming existing methods inboth single-source and multi-source localization scenarios. Code and generateddetailed contextual information are available at:https://github.com/VisualAIKHU/OA-SSL.</description>
      <author>example@mail.com (Sung Jin Um, Dongjin Kim, Sangmin Lee, Jung Uk Kim)</author>
      <guid isPermaLink="false">2506.18557v2</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>eccDNAMamba: A Pre-Trained Model for Ultra-Long eccDNA Sequence Analysis</title>
      <link>http://arxiv.org/abs/2506.18940v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025 Generative AI and Biology (GenBio) Workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了eccDNAMamba，这是一种专为环形DNA序列设计的双向状态空间编码器，用于对环形基因组进行建模。&lt;h4&gt;背景&lt;/h4&gt;eccDNA在癌症中通过高拷贝扩增和长距离相互作用在基因表达调控中起关键作用，但现有的基因组模型要么局限于单核苷酸分辨率，要么受到二次注意力机制的效率低下影响。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够高效且全面地建模全长度环形eccDNA的新模型。&lt;h4&gt;方法&lt;/h4&gt;eccDNAMamba结合了正向和反向遍历来进行全上下文表示学习，具有线性时间复杂度，并通过一种新的增强策略保留了环形结构。&lt;h4&gt;主要发现&lt;/h4&gt;eccDNAMamba在两个真实世界数据集上实现了强大的分类性能，并能够扩展到长达200 Kbp的序列，提供了一个稳健且高效的环形基因组建模框架。&lt;h4&gt;结论&lt;/h4&gt;eccDNAMamba为环形基因组建模提供了一个高效和全面的解决方案，并可以通过GitHub链接获取代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Extrachromosomal circular DNA (eccDNA) plays key regulatory roles andcontributes to oncogene overexpression in cancer through high-copyamplification and long-range interactions. Despite advances in modeling, nopre-trained models currently support full-length circular eccDNA for downstreamanalysis. Existing genomic models are either limited to single-nucleotideresolution or hindered by the inefficiency of the quadratic attentionmechanism. Here, we introduce eccDNAMamba, the first bidirectional state-spaceencoder tailored for circular DNA sequences. It combines forward and reversepasses for full-context representation learning with linear-time complexity,and preserves circular structure through a novel augmentation strategy. Testedon two real-world datasets, eccDNAMamba achieves strong classificationperformance and scales to sequences up to 200 Kbp, offering a robust andefficient framework for modeling circular genomes. Our codes are available athttps://github.com/zzq1zh/GenAI-Lab.</description>
      <author>example@mail.com (Zhenke Liu, Jien Li, Ziqi Zhang)</author>
      <guid isPermaLink="false">2506.18940v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>MOSCARD -- Causal Reasoning and De-confounding for Multimodal Opportunistic Screening of Cardiovascular Adverse Events</title>
      <link>http://arxiv.org/abs/2506.19174v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MACE是全球死亡的主要原因， opportunistically screening利用常规健康检查和多种数据来识别高危个体，CXR和ECG在识别MACE相关慢性条件和结构异常方面发挥作用，MOSCARD模型通过融合CXR和ECG进行风险评估，优于传统模型，且成本效益高，有助于早期干预，改善患者预后并减少差异。&lt;h4&gt;背景&lt;/h4&gt;MACE是全球死亡的主要原因，需要通过机会性筛查来识别高危个体。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的预测建模框架MOSCARD，以更全面地评估MACE风险。&lt;h4&gt;方法&lt;/h4&gt;MOSCARD通过多模态对齐、因果推理和去混杂技术来实现。&lt;h4&gt;主要发现&lt;/h4&gt;MOSCARD在内部和外部数据集上的性能优于单一模态和最先进的模型。&lt;h4&gt;结论&lt;/h4&gt;MOSCARD是一种有效的风险预测工具，有助于早期干预，改善患者预后并减少差异。&lt;h4&gt;翻译&lt;/h4&gt;摘要：主要不良心血管事件（MACE）是全球死亡的主要原因，正如2021年全球疾病负担研究所报告的那样。机会性筛查利用常规健康检查收集的数据，多种数据可以发挥关键作用以识别高危个体。胸部X光（CXR）提供了关于导致主要不良心血管事件（MACE）的慢性条件的见解，而12导联心电图（ECG）直接评估心脏电活动和结构异常。整合CXR和ECG可以提供比传统模型更全面的风险评估，传统模型依赖于临床评分、计算机断层扫描（CT）测量或生物标志物，这些可能受到抽样偏差和单一模态限制的限制。我们提出了一种新的预测建模框架——MOSCARD，这是一种多模态因果推理，带有对齐两个不同模态的注意力，同时减轻机会性风险估计中的偏差和混杂因素。在紧急部门（ED）的内部、轮换数据和外部MIMIC数据集上评估我们的模型，其性能优于单一模态和最先进的基线模型——AUC分别为0.75、0.83、0.71。提出的成本效益高的机会性筛查可以促进早期干预，改善患者预后并减少差异。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Major Adverse Cardiovascular Events (MACE) remain the leading cause ofmortality globally, as reported in the Global Disease Burden Study 2021.Opportunistic screening leverages data collected from routine health check-upsand multimodal data can play a key role to identify at-risk individuals. ChestX-rays (CXR) provide insights into chronic conditions contributing to majoradverse cardiovascular events (MACE), while 12-lead electrocardiogram (ECG)directly assesses cardiac electrical activity and structural abnormalities.Integrating CXR and ECG could offer a more comprehensive risk assessment thanconventional models, which rely on clinical scores, computed tomography (CT)measurements, or biomarkers, which may be limited by sampling bias and singlemodality constraints. We propose a novel predictive modeling framework -MOSCARD, multimodal causal reasoning with co-attention to align two distinctmodalities and simultaneously mitigate bias and confounders in opportunisticrisk estimation. Primary technical contributions are - (i) multimodal alignmentof CXR with ECG guidance; (ii) integration of causal reasoning; (iii) dualback-propagation graph for de-confounding. Evaluated on internal, shift datafrom emergency department (ED) and external MIMIC datasets, our modeloutperformed single modality and state-of-the-art foundational models - AUC:0.75, 0.83, 0.71 respectively. Proposed cost-effective opportunistic screeningenables early intervention, improving patient outcomes and reducingdisparities.</description>
      <author>example@mail.com (Jialu Pi, Juan Maria Farina, Rimita Lahiri, Jiwoong Jeong, Archana Gurudu, Hyung-Bok Park, Chieh-Ju Chao, Chadi Ayoub, Reza Arsanjani, Imon Banerjee)</author>
      <guid isPermaLink="false">2506.19174v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Distilling Tool Knowledge into Language Models via Back-Translated Traces</title>
      <link>http://arxiv.org/abs/2506.19171v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in Workshop in Multi-Agent Systems in the Era of Foundation  Models: Opportunities, Challenges and Futures, ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将工具知识蒸馏到大型语言模型（LLMs）中的新范式，通过自然语言实现，以解决LLMs在数学问题上的挑战。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在需要精确计算或多步代数推理的数学问题上表现不佳，工具集成推理（TIR）虽然能提高正确性，但引入了推理时间依赖性，影响了可扩展性和部署。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的范式，通过自然语言将工具知识蒸馏到LLMs中，以解决数学问题。&lt;h4&gt;方法&lt;/h4&gt;构建了一个求解代理（Solver Agent），通过交织规划、符号工具调用和反思推理来解决数学问题。使用多个基于LLM的代理驱动的回译管道，将交织的TIR轨迹转换为自然语言推理轨迹。翻译代理（Translator Agent）生成对单个工具调用的解释，而重述代理（Rephrase Agent）将它们合并成一个流畅且全局一致的叙述。&lt;h4&gt;主要发现&lt;/h4&gt;在合成的轨迹上微调小型开源模型，使其能够内化工具知识和结构化推理模式，在竞赛级数学基准测试中取得了提升，而无需在推理时访问工具。&lt;h4&gt;结论&lt;/h4&gt;通过自然语言将工具知识蒸馏到LLMs中，可以有效提高LLMs解决数学问题的能力，同时保持了模型的可扩展性和部署性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models (LLMs) often struggle with mathematical problems thatrequire exact computation or multi-step algebraic reasoning. Tool-integratedreasoning (TIR) offers a promising solution by leveraging external tools suchas code interpreters to ensure correctness, but it introduces inference-timedependencies that hinder scalability and deployment. In this work, we propose anew paradigm for distilling tool knowledge into LLMs purely through naturallanguage. We first construct a Solver Agent that solves math problems byinterleaving planning, symbolic tool calls, and reflective reasoning. Then,using a back-translation pipeline powered by multiple LLM-based agents, weconvert interleaved TIR traces into natural language reasoning traces. ATranslator Agent generates explanations for individual tool calls, while aRephrase Agent merges them into a fluent and globally coherent narrative.Empirically, we show that fine-tuning a small open-source model on thesesynthesized traces enables it to internalize both tool knowledge and structuredreasoning patterns, yielding gains on competition-level math benchmarks withoutrequiring tool access at inference.</description>
      <author>example@mail.com (Xingyue Huang, Xianglong Hu, Zifeng Ding, Yuan He, Rishabh, Waleed Alzarooni, Ziyu Ye, Wendong Fan, Bailan He, Haige Bo, Changran Hu, Guohao Li)</author>
      <guid isPermaLink="false">2506.19171v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>Reading Smiles: Proxy Bias in Foundation Models for Facial Emotion Recognition</title>
      <link>http://arxiv.org/abs/2506.19079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了基础模型（FMs）如何通过视觉语言模型（VLMs）在零样本设置中识别情绪，并分析了这些模型依赖的视觉线索是否具有心理学基础。&lt;h4&gt;背景&lt;/h4&gt;基础模型正在迅速改变情感计算（AC）领域，其中视觉语言模型（VLMs）现在能够在零样本设置中识别情绪。&lt;h4&gt;目的&lt;/h4&gt;研究这些模型依赖的视觉线索，并探讨这些线索是否具有心理学基础或仅仅是表面学习。&lt;h4&gt;方法&lt;/h4&gt;在AffectNet数据集的一个牙齿标注子集上对不同规模的VLMs进行基准测试，并通过结构化内省分析了最佳性能模型GPT-4o。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，牙齿的存在对模型性能有显著影响，面部特征如眉毛位置对模型的情绪推理有重要影响，其情绪预测具有高度内部一致性。&lt;h4&gt;结论&lt;/h4&gt;这些模式揭示了基础模型行为的涌现性质，但也揭示了风险，如捷径学习、偏见和公平性问题，特别是在心理健康和教育等敏感领域。&lt;h4&gt;翻译&lt;/h4&gt;本文探讨了基础模型（FMs）正在迅速改变情感计算（AC）领域，其中视觉语言模型（VLMs）现在能够在零样本设置中识别情绪。本文提出并探究了一个关键但尚未充分研究的课题：这些模型依赖哪些视觉线索来推断情绪，这些线索是否具有心理学基础或仅仅是表面学习。通过在AffectNet数据集的一个牙齿标注子集上对不同规模的VLMs进行基准测试，我们发现牙齿的存在对模型性能有显著影响。通过对最佳性能模型GPT-4o的结构化内省，我们发现面部特征如眉毛位置对模型的情绪推理有重要影响，其情绪预测具有高度内部一致性。这些模式揭示了基础模型行为的涌现性质，但也揭示了风险，如捷径学习、偏见和公平性问题，特别是在心理健康和教育等敏感领域。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation Models (FMs) are rapidly transforming Affective Computing (AC),with Vision Language Models (VLMs) now capable of recognising emotions in zeroshot settings. This paper probes a critical but underexplored question: whatvisual cues do these models rely on to infer affect, and are these cuespsychologically grounded or superficially learnt? We benchmark varying scaleVLMs on a teeth annotated subset of AffectNet dataset and find consistentperformance shifts depending on the presence of visible teeth. Throughstructured introspection of, the best-performing model, i.e., GPT-4o, we showthat facial attributes like eyebrow position drive much of its affectivereasoning, revealing a high degree of internal consistency in itsvalence-arousal predictions. These patterns highlight the emergent nature ofFMs behaviour, but also reveal risks: shortcut learning, bias, and fairnessissues especially in sensitive domains like mental health and education.</description>
      <author>example@mail.com (Iosif Tsangko, Andreas Triantafyllopoulos, Adem Abdelmoula, Adria Mallol-Ragolta, Bjoern W. Schuller)</author>
      <guid isPermaLink="false">2506.19079v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>From Rows to Yields: How Foundation Models for Tabular Data Simplify Crop Yield Prediction</title>
      <link>http://arxiv.org/abs/2506.19046v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对中小规模表格数据的基础模型TabPFN，并将其应用于南非的次国家层面作物产量预测任务。TabPFN在回归和分类任务中表现优于传统机器学习模型。使用地球观测数据（FAPAR和土壤湿度）和网格化天气数据（空气温度、降水和辐射）进行预测，数据涵盖了23年的23个省份。通过区域提取和月度聚合的协变量变量，对TabPFN进行基准测试，结果显示TabPFN与机器学习模型在准确性上相当，且在调整时间和特征工程需求上优于基准模型，使其成为实际应用中更可行的选择。&lt;h4&gt;背景&lt;/h4&gt;TabPFN在回归和分类任务中表现出色，优于传统机器学习模型。&lt;h4&gt;目的&lt;/h4&gt;将TabPFN应用于南非次国家层面的作物产量预测。&lt;h4&gt;方法&lt;/h4&gt;使用地球观测数据和天气数据，对23年的23个省份的作物产量数据进行预测，并通过区域提取和月度聚合协变量变量。&lt;h4&gt;主要发现&lt;/h4&gt;TabPFN与机器学习模型在准确性上相当，但TabPFN在调整时间和特征工程需求上更优。&lt;h4&gt;结论&lt;/h4&gt;TabPFN在次国家层面作物产量预测中是一个更可行的选择，尤其是在效率和实施简便性方面。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种针对中小规模表格数据的基础模型TabPFN，并将其应用于南非的次国家层面作物产量预测任务。TabPFN在回归和分类任务中表现优于传统机器学习模型。使用地球观测数据（FAPAR和土壤湿度）和网格化天气数据（空气温度、降水和辐射）进行预测，数据涵盖了23年的23个省份。通过区域提取和月度聚合协变量变量，对TabPFN进行基准测试，结果显示TabPFN与机器学习模型在准确性上相当，但TabPFN在调整时间和特征工程需求上更优。TabPFN在次国家层面作物产量预测中是一个更可行的选择，尤其是在效率和实施简便性方面。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present an application of a foundation model for small- to medium-sizedtabular data (TabPFN), to sub-national yield forecasting task in South Africa.TabPFN has recently demonstrated superior performance compared to traditionalmachine learning (ML) models in various regression and classification tasks. Weused the dekadal (10-days) time series of Earth Observation (EO; FAPAR and soilmoisture) and gridded weather data (air temperature, precipitation andradiation) to forecast the yield of summer crops at the sub-national level. Thecrop yield data was available for 23 years and for up to 8 provinces. Covariatevariables for TabPFN (i.e., EO and weather) were extracted by region andaggregated at a monthly scale. We benchmarked the results of the TabPFN againstsix ML models and three baseline models. Leave-one-year-out cross-validationexperiment setting was used in order to ensure the assessment of the modelscapacity to forecast an unseen year. Results showed that TabPFN and ML modelsexhibit comparable accuracy, outperforming the baselines. Nonetheless, TabPFNdemonstrated superior practical utility due to its significantly faster tuningtime and reduced requirement for feature engineering. This renders TabPFN amore viable option for real-world operation yield forecasting applications,where efficiency and ease of implementation are paramount.</description>
      <author>example@mail.com (Filip Sabo, Michele Meroni, Maria Piles, Martin Claverie, Fanie Ferreira, Elna Van Den Berg, Francesco Collivignarelli, Felix Rembold)</author>
      <guid isPermaLink="false">2506.19046v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>UniMind: Unleashing the Power of LLMs for Unified Multi-Task Brain Decoding</title>
      <link>http://arxiv.org/abs/2506.18962v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  19pages,4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文介绍了一种名为UniMind的通用EEG基础模型，用于统一的多任务脑解码，通过利用大型语言模型理解复杂的神经网络模式，解决了传统方法在解码任务中的泛化能力和性能问题。&lt;h4&gt;背景&lt;/h4&gt;解码人类脑活动是神经科学和人工智能交叉领域的一个核心挑战，广泛应用于心理状态评估、临床监测和人机交互。&lt;h4&gt;目的&lt;/h4&gt;提出UniMind模型，以解决传统EEG解码方法在泛化性和性能上的不足。&lt;h4&gt;方法&lt;/h4&gt;设计了一个神经语言连接器，将神经信号和大型语言模型之间的模态差距桥接起来，并将EEG数据的空间时间神经网络模式转化为语言模型可理解的表示。此外，还提出了一个任务感知查询选择模块，通过动态生成任务自适应查询标记，将任务感知性注入跨模态对齐中，从而学习不同任务中的任务相关神经网络模式。&lt;h4&gt;主要发现&lt;/h4&gt;在十个数据集上的广泛实验表明，UniMind在多任务解码方面显著优于最先进的多任务解码模型，平均提升12%，同时提供了对任务间神经功能相关性的有价值的神经科学见解。&lt;h4&gt;结论&lt;/h4&gt;UniMind模型有效地提高了EEG解码的泛化能力和性能，并为神经科学领域提供了新的研究视角。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从脑电图（EEG）信号解码人类脑活动是神经科学与人工智能交叉领域的一个核心挑战，它使得在心理状态评估、临床监测和人机交互等众多应用成为可能。最近的研究广泛探索了基于EEG的脑基础模型，通过在多个数据集上大规模训练以实现通用的脑解码。然而，由于解码任务之间固有的显著异质性，大多数尝试在缺乏任务特定调整的情况下都难以实现泛化，并且性能不令人满意。为了解决这些挑战，我们提出了一种名为UniMind的通用EEG基础模型，通过独特地释放大型语言模型理解复杂神经网络模式的能力，实现统一的多任务脑解码。UniMind具有几个优点。首先，我们设计了一个神经语言连接器，以桥接神经信号和大型语言模型之间的模态差距，将EEG数据的空间时间神经网络模式提炼和转换成语言模型可理解的表示。其次，我们提出了一种任务感知查询选择模块，通过动态生成任务自适应查询标记，将任务感知性注入跨模态对齐中，从而在多种任务中学习任务相关的神经网络模式。在十个数据集上的广泛实验表明，UniMind在多任务解码方面显著优于最先进的多任务解码模型，平均增益为12%，同时也为任务间的神经功能相关性提供了有价值的神经科学见解。代码将公开提供。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Decoding human brain activity from electroencephalography (EEG) signals is acentral challenge at the intersection of neuroscience and artificialintelligence, enabling diverse applications in mental state assessment,clinical monitoring, and human-machine interaction. Recent efforts haveextensively explored EEG-based brain foundation models for generalized braindecoding, employing large-scale training on multiple datasets. However, most ofthese attempts struggle with generalizability and fail to achieve satisfactoryperformance without task-specific tuning due to pronounced inherentheterogeneity among decoding tasks. To address these challenges, we presentUniMind, a general-purpose EEG foundation model for unified multi-task braindecoding by uniquely unleashing the power of large language models tocomprehend complex neural patterns. UniMind offers several advantages. First,we design a Neuro-Language Connector to bridge the modality gap between neuralsignals and large language models, distilling and transforming thespatiotemporal neural patterns of EEG data into representations understandableby language models. Second, a Task-aware Query Selection module is proposed toinject task-awareness into the cross-modal alignment by dynamically generatingtask-adaptive query tokens, enabling learning of task-relevant neural patternsacross diverse tasks. Extensive experiments across ten datasets demonstratethat UniMind substantially outperforms state-of-the-art multi-task decodingmodels, with an average gain of 12 percent, while also offering valuableneuroscientific insights into neural functional correlations across tasks. Thecode will be made publicly available.</description>
      <author>example@mail.com (Weiheng Lu, Chunfeng Song, Jiamin Wu, Pengyu Zhu, Yuchen Zhou, Weijian Mai, Qihao Zheng, Wanli Ouyang)</author>
      <guid isPermaLink="false">2506.18962v1</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>DaMO: A Data-Efficient Multimodal Orchestrator for Temporal Reasoning with Video LLMs</title>
      <link>http://arxiv.org/abs/2506.11558v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  I would like to request the withdrawal of this submission because the  current version contains significant errors and incomplete results. I intend  to revise the manuscript thoroughly before resubmitting. I apologize for the  oversight and appreciate your understanding&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DaMO的视频语言模型，专门设计用于准确的时间推理和多模态理解，提高了视频语言模型的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;虽然大型语言模型（LLMs）已被扩展到视频领域，但现有的VideoLLMs在细粒度时间推理方面存在局限性，特别是在受限制的监督下，无法精确地将响应归因于特定的视频时刻。&lt;h4&gt;目的&lt;/h4&gt;开发一个数据高效的视频语言模型（DaMO），用于准确的时间推理和多模态理解。&lt;h4&gt;方法&lt;/h4&gt;DaMO的核心是Temporal-aware Fuseformer，它采用分层双流架构，逐步捕获每个模态中的时间动态，并有效地融合互补的视觉和音频信息。此外，DaMO集成了全局残差，以减少空间冗余同时保留关键语义细节。模型通过结构化的四阶段渐进式训练范式进行训练，逐步赋予模型多模态对齐、语义扎根和时间推理能力。研究还贡献了多个数据集，这些数据集是从现有数据集中增加的，包含GPT生成的基于时间问答对，用于需要时间监督的任务。&lt;h4&gt;主要发现&lt;/h4&gt;在时间扎根和视频问答基准测试中，DaMO在需要精确时间对齐和推理的任务上，持续优于先前的方法。&lt;h4&gt;结论&lt;/h4&gt;DaMO为数据高效的视频语言建模开辟了有前景的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have recently been extended to the video domain,enabling sophisticated video-language understanding. However, existing VideoLLMs often exhibit limitations in fine-grained temporal reasoning, restrictingtheir ability to precisely attribute responses to specific video moments,especially under constrained supervision. We introduce DaMO, a data-efficientVideo LLM explicitly designed for accurate temporal reasoning and multimodalunderstanding. At its core, the proposed Temporal-aware Fuseformer employs ahierarchical dual-stream architecture that progressively captures temporaldynamics within each modality and effectively fuses complementary visual andaudio information. To further enhance computational efficiency, DaMO integratesa global residual that reduces spatial redundancy while preserving essentialsemantic details. We train DaMO via a structured four-stage progressivetraining paradigm, incrementally equipping the model with multimodal alignment,semantic grounding, and temporal reasoning capabilities. This work alsocontributes multiple datasets augmented from existing ones with GPT-generatedtemporally grounded QA pairs for tasks requiring temporal supervision.Comprehensive experiments on temporal grounding and video QA benchmarksdemonstrate that DaMO consistently surpasses prior methods, particularly intasks demanding precise temporal alignment and reasoning. Our work establishesa promising direction for data-efficient video-language modeling.</description>
      <author>example@mail.com (Bo-Cheng Chiu, Jen-Jee Chen, Yu-Chee Tseng, Feng-Chi Chen)</author>
      <guid isPermaLink="false">2506.11558v2</guid>
      <pubDate>Wed, 25 Jun 2025 14:17:44 +0800</pubDate>
    </item>
    <item>
      <title>OmniAvatar: Efficient Audio-Driven Avatar Video Generation with Adaptive Body Animation</title>
      <link>http://arxiv.org/abs/2506.18866v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://omni-avatar.github.io/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;OmniAvatar是一个创新的音频驱动全身视频生成模型，提高了人动画的同步精度和自然运动。&lt;h4&gt;背景&lt;/h4&gt;现有的音频驱动人动画方法主要关注面部运动，限制了它们创建具有自然同步和流畅性的全身动画的能力，并且难以进行精确的提示控制。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些挑战，引入了OmniAvatar模型。&lt;h4&gt;方法&lt;/h4&gt;OmniAvatar引入了一种像素级的多层次音频嵌入策略来更好地在潜在空间中捕捉音频特征，并采用基于LoRA的训练方法以保留基础模型的提示驱动控制能力。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，OmniAvatar在面部和半身视频生成方面超越了现有模型，能够提供基于文本的精确控制，以创建各种领域的视频，如播客、人机交互、动态场景和唱歌。&lt;h4&gt;结论&lt;/h4&gt;OmniAvatar在音频驱动人动画领域取得了显著进展，为创建更自然和精确的视频动画提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在音频驱动人动画方面取得了重大进展，而大多数现有方法主要关注面部运动，这限制了它们创建具有自然同步和流畅性的全身动画的能力。它们还难以进行精细的提示控制。为了应对这些挑战，我们引入了OmniAvatar，这是一个创新的音频驱动全身视频生成模型，它通过提高唇同步精度和自然运动来增强人动画。OmniAvatar引入了一种像素级的多层次音频嵌入策略，以更好地在潜在空间中捕捉音频特征，从而增强了跨不同场景的唇同步。为了在有效结合音频特征的同时保留基础模型的提示驱动控制能力，我们采用了基于LoRA的训练方法。广泛的实验表明，OmniAvatar在面部和半身视频生成方面优于现有模型，为创建各种领域的视频提供了基于文本的精确控制，如播客、人机交互、动态场景和唱歌。我们的项目页面是https://omni-avatar.github.io/。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Significant progress has been made in audio-driven human animation, whilemost existing methods focus mainly on facial movements, limiting their abilityto create full-body animations with natural synchronization and fluidity. Theyalso struggle with precise prompt control for fine-grained generation. Totackle these challenges, we introduce OmniAvatar, an innovative audio-drivenfull-body video generation model that enhances human animation with improvedlip-sync accuracy and natural movements. OmniAvatar introduces a pixel-wisemulti-hierarchical audio embedding strategy to better capture audio features inthe latent space, enhancing lip-syncing across diverse scenes. To preserve thecapability for prompt-driven control of foundation models while effectivelyincorporating audio features, we employ a LoRA-based training approach.Extensive experiments show that OmniAvatar surpasses existing models in bothfacial and semi-body video generation, offering precise text-based control forcreating videos in various domains, such as podcasts, human interactions,dynamic scenes, and singing. Our project page ishttps://omni-avatar.github.io/.</description>
      <author>example@mail.com (Qijun Gan, Ruizi Yang, Jianke Zhu, Shaofei Xue, Steven Hoi)</author>
      <guid isPermaLink="false">2506.18866v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
  <item>
      <title>Rapeseed population point cloud completion network (RP-PCN) with dynamic graph convolution for 3D reconstruction of crop canopy occlusion architecture</title>
      <link>http://arxiv.org/abs/2506.18292v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种点云补全模型，用于从播种到角果阶段的油菜种群的三维重建，以评估作物光合作用和产量，并指导理想型设计。&lt;h4&gt;背景&lt;/h4&gt;三维传感技术已被开发用于植物和冠层重建，但由于严重的遮挡和复杂的结构，准确描述冠层存在困难。&lt;h4&gt;目的&lt;/h4&gt;开发一种点云补全模型，以更准确地描述油菜种群的三维结构，从而评估产量。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于多视角成像的完整点云生成框架，使用虚拟现实集成（VRI）模拟方法和遮挡点检测算法来标注训练数据集，区分表面点和遮挡点。设计了油菜种群点云补全网络（RP-PCN），使用多分辨率动态图卷积编码器（MRDG）和点金字塔解码器（PPD）来预测遮挡点，并引入了动态图卷积特征提取器（DGCFE）来捕捉生长周期内的结构变化。&lt;h4&gt;主要发现&lt;/h4&gt;RP-PCN在幼苗、抽薹、开花和角果阶段分别实现了3.35 cm、3.46 cm、4.32 cm和4.51 cm的 chamfer distance（CD）值。消融研究表明，MRDG和DGCFE模块分别降低了10%和23%的CD值。与不完整的点云相比，RP-PCN的角果效率指数（SEI）提高了11.2%的产量预测精度。&lt;h4&gt;结论&lt;/h4&gt;RP-PCN流程有望扩展到其他作物，显著增强田间环境中种群冠层结构分析的能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：完整冠层结构的定量描述对于评估作物光合作用和产量以指导理想型设计至关重要。尽管已经开发了用于植物和冠层重建的三维传感技术，但严重的遮挡和复杂的结构阻碍了准确描述冠层。在本研究中，我们提出了一种点云补全模型，用于从播种到角果阶段对油菜种群进行三维重建，使用多视角成像。开发了一个完整的点云生成框架，包括虚拟现实集成（VRI）模拟方法和遮挡点检测算法，通过区分表面点和遮挡点来标注训练数据集。设计了油菜种群点云补全网络（RP-PCN），使用多分辨率动态图卷积编码器（MRDG）和点金字塔解码器（PPD）来根据输入表面点云预测遮挡点。引入了动态图卷积特征提取器（DGCFE）来捕捉生长周期内的结构变化。通过使用完整点云的冠层指标预测产量来验证点云补全的有效性。结果表明，RP-PCN在幼苗、抽薹、开花和角果阶段分别达到了3.35 cm、3.46 cm、4.32 cm和4.51 cm的 chamfer distance（CD）值。消融研究表明，MRDG和DGCFE模块分别降低了10%和23%的CD值。与不完整的点云相比，RP-PCN的角果效率指数（SEI）提高了11.2%的产量预测精度。本研究提出的RP-PCN流程有望扩展到其他作物，显著增强田间环境中种群冠层结构分析的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Quantitative descriptions of complete canopy architecture are crucial forevaluating crop photosynthesis and yield to guide ideotype design. Althoughthree-dimensional (3D) sensing technologies have been developed for plant andcanopy reconstruction, severe occlusion and complex architectures hinderaccurate canopy descriptions. In this study, we propose a point cloudcompletion model for 3D reconstruction of rapeseed populations from seeding tosilique stages using multi-view imaging. A complete point cloud generationframework was developed with the virtual-real integration (VRI) simulationmethod and occlusion point detection algorithm to annotate the training datasetby distinguishing surface from occluded points. The rapeseed population pointcloud completion network (RP-PCN) was designed with a multi-resolution dynamicgraph convolutional encoder (MRDG) and point pyramid decoder (PPD) to predictoccluded points based on input surface point clouds. A dynamic graphconvolutional feature extractor (DGCFE) was introduced to capture structuralvariations across the growth period. The effectiveness of point cloudcompletion was validated by predicting yield using architectural indicatorsfrom complete point clouds of rapeseed population. The results demonstratedthat RP-PCN achieved chamfer distance (CD) values of 3.35 cm, 3.46 cm, 4.32 cm,and 4.51 cm at the seedling, bolting, flowering, and silique stages,respectively. Ablation studies showed the effectiveness of the MRDG and DGCFEmodules, reducing CD values by 10% and 23%, respectively. The siliqueefficiency index (SEI) from RP-PCN improved yield prediction accuracy by 11.2%compared to incomplete point clouds. The RP-PCN pipeline proposed in this studyhas the potential to be extended to other crops, significantly enhancing theanalysis of population canopy architectures in field environments.</description>
      <author>example@mail.com (Ziyue Guo, Xin Yang, Yutao Shen, Yang Zhu, Lixi Jiang, Haiyan Cen)</author>
      <guid isPermaLink="false">2506.18292v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>USAD: Universal Speech and Audio Representation via Distillation</title>
      <link>http://arxiv.org/abs/2506.18843v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Preprint&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为USAD的通用语音和音频蒸馏方法，该方法能够整合多种音频类型（包括语音、声音和音乐）进行统一的音频表示学习。&lt;h4&gt;背景&lt;/h4&gt;现有的自监督学习模型在音频表示方面取得了革命性的进展，但模型往往针对特定领域，专注于语音或非语音任务。&lt;h4&gt;目的&lt;/h4&gt;旨在开发一个能够处理多种音频类型的统一模型，以实现更广泛的应用。&lt;h4&gt;方法&lt;/h4&gt;USAD使用从特定领域自监督学习模型到学生的层间蒸馏，在一个综合音频数据集上训练学生模型。&lt;h4&gt;主要发现&lt;/h4&gt;USAD在各种基准和数据集上表现出色，包括帧和实例级语音处理任务、音频标签和声音分类，在SUPERB和HEAR基准上达到了接近最先进的结果。&lt;h4&gt;结论&lt;/h4&gt;USAD是一种有效的音频表示学习方法，能够处理多种音频类型，并在多个任务上取得优异性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Self-supervised learning (SSL) has revolutionized audio representations, yetmodels often remain domain-specific, focusing on either speech or non-speechtasks. In this work, we present Universal Speech and Audio Distillation (USAD),a unified approach to audio representation learning that integrates diverseaudio types - speech, sound, and music - into a single model. USAD employsefficient layer-to-layer distillation from domain-specific SSL models to traina student on a comprehensive audio dataset. USAD offers competitive performanceacross various benchmarks and datasets, including frame and instance-levelspeech processing tasks, audio tagging, and sound classification, achievingnear state-of-the-art results with a single encoder on SUPERB and HEARbenchmarks.</description>
      <author>example@mail.com (Heng-Jui Chang, Saurabhchand Bhati, James Glass, Alexander H. Liu)</author>
      <guid isPermaLink="false">2506.18843v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TDACloud: Point Cloud Recognition Using Topological Data Analysis</title>
      <link>http://arxiv.org/abs/2506.18725v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TDACloud的新方法，利用拓扑数据分析(TDA)从点云中提取局部描述符，用于对象和场景识别，特别适用于自动驾驶、场景重建和定位等领域。&lt;h4&gt;背景&lt;/h4&gt;点云基于的对象/场景识别在自动驾驶、场景重建和定位等应用中是一个感兴趣的问题。从查询点云中提取有意义的局部描述符并与收集到的点云描述符匹配是一个具有挑战性的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种无需资源密集型GPU机器学习训练的方法，用于从点云中提取局部描述符，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;TDACloud方法使用ATOL向量化方法生成点云的向量，不同于体素化，该方法可以直接处理原始点云并输出固定大小的TDA描述符向量。&lt;h4&gt;主要发现&lt;/h4&gt;TDACloud在多个真实世界（如Oxford RobotCar，KITTI-360）和现实场景（如ShapeNet）点云数据集上进行了测试，并在有噪声和变换的测试案例中进行了验证。结果表明，在噪声条件下和大规模真实场景识别中，TDACloud具有较高的识别准确率，并且比基线方法高出约14%。&lt;h4&gt;结论&lt;/h4&gt;TDACloud在噪声条件下和大规模真实场景识别中表现出色，为点云对象和场景识别提供了一种有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel methodology named TDACloud, which utilizes Topological Data Analysis (TDA) for local descriptor extraction from point clouds, aimed at object and scene recognition, particularly suitable for applications such as autonomous driving, scene reconstruction, and localization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud-based object/place recognition remains a problem of interest inapplications such as autonomous driving, scene reconstruction, andlocalization. Extracting meaningful local descriptors from a query point cloudthat can be matched with the descriptors of the collected point clouds is achallenging problem. Furthermore, when the query point cloud is noisy or hasbeen transformed (e.g., rotated), it adds to the complexity. To this end, wepropose a novel methodology, named TDACloud, using Topological Data Analysis(TDA) for local descriptor extraction from a point cloud, which does not needresource-intensive GPU-based machine learning training. More specifically, weused the ATOL vectorization method to generate vectors for point clouds. Unlikevoxelization, our proposed technique can take raw point clouds as inputs andoutputs a fixed-size TDA-descriptor vector. To test the quality of the proposedTDACloud technique, we have implemented it on multiple real-world (e.g., OxfordRobotCar, KITTI-360) and realistic (e.g., ShapeNet) point cloud datasets forobject and place recognition. We have also tested TDACloud on noisy andtransformed test cases where the query point cloud has been scaled, translated,or rotated. Our results demonstrate high recognition accuracies in noisyconditions and large-scale real-world place recognition while outperforming thebaselines by up to approximately 14%.</description>
      <author>example@mail.com (Anirban Ghosh, Ian Dahlin, Ayan Dutta)</author>
      <guid isPermaLink="false">2506.18725v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting</title>
      <link>http://arxiv.org/abs/2506.17609v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为TyphoFormer的新框架，用于提高台风轨迹预测的准确性。&lt;h4&gt;背景&lt;/h4&gt;台风轨迹预测对于早期系统预警和灾害响应至关重要。现有的Transformer模型在建模密集轨迹方面表现出色，但缺乏对稀疏气象轨迹（如台风轨迹）的更广泛背景知识的访问。&lt;h4&gt;目的&lt;/h4&gt;提出TyphoFormer框架，通过结合自然语言描述作为辅助提示来提高台风轨迹预测的可靠性。&lt;h4&gt;方法&lt;/h4&gt;对于每个时间步，使用大型语言模型（LLM）根据北大西洋飓风数据库中记录的数值属性生成简洁的文本描述。这些语言描述捕捉高级气象语义，并作为辅助特殊标记嵌入到数值时间序列输入之前。TyphoFormer通过在一个统一的Transformer编码器中整合文本和序列信息，使模型能够利用通过数值特征本身无法访问的上下文线索。&lt;h4&gt;主要发现&lt;/h4&gt;在HURDAT2基准上进行的大量实验表明，TyphoFormer在非线性路径转换和有限历史观察的挑战性场景下，始终优于其他最先进的基线方法。&lt;h4&gt;结论&lt;/h4&gt;TyphoFormer框架能够有效提高台风轨迹预测的准确性，为早期预警和灾害响应提供了强有力的工具。&lt;h4&gt;翻译&lt;/h4&gt;准确的风暴路径预测对于早期系统预警和灾害响应至关重要。虽然基于Transformer的模型在建模智能城市中人类和车辆密集轨迹的时间动态方面表现出强大的性能，但它们通常无法访问增强稀疏气象轨迹（如台风轨迹）预测可靠性的更广泛背景知识。为了解决这一挑战，我们提出了一种名为TyphoFormer的新框架，该框架结合自然语言描述作为辅助提示以改善台风轨迹预测。对于每个时间步，我们使用大型语言模型（LLM）根据北大西洋飓风数据库中记录的数值属性生成简洁的文本描述。这些语言描述捕捉高级气象语义，并作为辅助特殊标记嵌入到数值时间序列输入之前。通过在一个统一的Transformer编码器中整合文本和序列信息，TyphoFormer使模型能够利用通过数值特征本身无法访问的上下文线索。在HURDAT2基准上进行的大量实验表明，TyphoFormer在非线性路径转换和有限历史观察的挑战性场景下，始终优于其他最先进的基线方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Accurate typhoon track forecasting is crucial for early system warning anddisaster response. While Transformer-based models have demonstrated strongperformance in modeling the temporal dynamics of dense trajectories of humansand vehicles in smart cities, they usually lack access to broader contextualknowledge that enhances the forecasting reliability of sparse meteorologicaltrajectories, such as typhoon tracks. To address this challenge, we proposeTyphoFormer, a novel framework that incorporates natural language descriptionsas auxiliary prompts to improve typhoon trajectory forecasting. For each timestep, we use Large Language Model (LLM) to generate concise textualdescriptions based on the numerical attributes recorded in the North Atlantichurricane database. The language descriptions capture high-level meteorologicalsemantics and are embedded as auxiliary special tokens prepended to thenumerical time series input. By integrating both textual and sequentialinformation within a unified Transformer encoder, TyphoFormer enables the modelto leverage contextual cues that are otherwise inaccessible through numericalfeatures alone. Extensive experiments are conducted on HURDAT2 benchmark,results show that TyphoFormer consistently outperforms other state-of-the-artbaseline methods, particularly under challenging scenarios involving nonlinearpath shifts and limited historical observations.</description>
      <author>example@mail.com (Lincan Li, Eren Erman Ozguven, Yue Zhao, Guang Wang, Yiqun Xie, Yushun Dong)</author>
      <guid isPermaLink="false">2506.17609v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>YouTube-Occ: Learning Indoor 3D Semantic Occupancy Prediction from YouTube Videos</title>
      <link>http://arxiv.org/abs/2506.18266v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于室内互联网数据的3D语义占用预测方法，无需精确的几何关系和相机参数，通过利用2D先验知识实现3D室内感知。&lt;h4&gt;背景&lt;/h4&gt;过去3D语义占用预测需要精确的几何关系，但在复杂室内环境中，大规模数据收集和精细标注难以实现。&lt;h4&gt;目的&lt;/h4&gt;研究如何仅使用室内互联网数据实现3D空间精确训练，无需预先知道相机参数。&lt;h4&gt;方法&lt;/h4&gt;收集了YouTube上的家庭游览视频，构建了YouTube-Occ数据集。在该数据集上，建立了一个完全自监督模型，利用视觉基础模型的优势，通过将相似像素分组成超像素，将2D区域级知识蒸馏到占用网络中。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在两个流行的基准测试（NYUv2和OccScanNet）上实现了最先进的零样本性能。&lt;h4&gt;结论&lt;/h4&gt;该研究表明，利用室内互联网数据可以实现高效的3D室内感知，无需依赖复杂的几何关系或相机参数知识。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D semantic occupancy prediction in the past was considered to requireprecise geometric relationships in order to enable effective training. However,in complex indoor environments, the large-scale and widespread collection ofdata, along with the necessity for fine-grained annotations, becomesimpractical due to the complexity of data acquisition setups and privacyconcerns. In this paper, we demonstrate that 3D spatially-accurate training canbe achieved using only indoor Internet data, without the need for anypre-knowledge of intrinsic or extrinsic camera parameters. In our framework, wecollect a web dataset, YouTube-Occ, which comprises house tour videos fromYouTube, providing abundant real house scenes for 3D representation learning.Upon on this web dataset, we establish a fully self-supervised model toleverage accessible 2D prior knowledge for reaching powerful 3D indoorperception. Specifically, we harness the advantages of the prosperous visionfoundation models, distilling the 2D region-level knowledge into the occupancynetwork by grouping the similar pixels into superpixels. Experimental resultsshow that our method achieves state-of-the-art zero-shot performance on twopopular benchmarks (NYUv2 and OccScanNet</description>
      <author>example@mail.com (Haoming Chen, Lichen Yuan, TianFang Sun, Jingyu Gong, Xin Tan, Zhizhong Zhang, Yuan Xie)</author>
      <guid isPermaLink="false">2506.18266v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SIM-Net: A Multimodal Fusion Network Using Inferred 3D Object Shape Point Clouds from RGB Images for 2D Classification</title>
      <link>http://arxiv.org/abs/2506.18683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  25 pages, 9 figures, 14 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了Shape-Image Multimodal Network (SIM-Net)，这是一种新型的2D图像分类架构，它通过直接从RGB图像中推断出的3D点云表示来整合3D点云信息。&lt;h4&gt;背景&lt;/h4&gt;传统的基于图像的模型在处理具有异质背景的数字化植物标本、非植物元素和遮挡等复杂情况时存在困难。&lt;h4&gt;目的&lt;/h4&gt;SIM-Net旨在通过融合基于纹理和几何的特征来提高分类性能，并解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;SIM-Net使用像素到点的转换将2D对象掩码转换为3D点云，并采用基于分割的预处理步骤来提取对象掩码。其架构包括一个用于2D图像特征的CNN编码器和基于PointNet的编码器用于几何特征，这些特征被融合到一个统一的潜在空间中。&lt;h4&gt;主要发现&lt;/h4&gt;在植物标本数据集上的实验评估表明，SIM-Net在准确性和F-score方面均优于ResNet101，最高提高了9.9%的准确性和12.3%的F-score。它还超越了几个基于transformer的顶级架构，突出了将3D结构推理纳入2D图像分类任务的好处。&lt;h4&gt;结论&lt;/h4&gt;SIM-Net通过结合3D点云信息显著提高了2D图像分类的性能，为处理复杂图像分类任务提供了一种有效的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce the Shape-Image Multimodal Network (SIM-Net), a novel 2D imageclassification architecture that integrates 3D point cloud representationsinferred directly from RGB images. Our key contribution lies in apixel-to-point transformation that converts 2D object masks into 3D pointclouds, enabling the fusion of texture-based and geometric features forenhanced classification performance. SIM-Net is particularly well-suited forthe classification of digitized herbarium specimens (a task made challenging byheterogeneous backgrounds), non-plant elements, and occlusions that compromiseconventional image-based models. To address these issues, SIM-Net employs asegmentation-based preprocessing step to extract object masks prior to 3D pointcloud generation. The architecture comprises a CNN encoder for 2D imagefeatures and a PointNet-based encoder for geometric features, which are fusedinto a unified latent space. Experimental evaluations on herbarium datasetsdemonstrate that SIM-Net consistently outperforms ResNet101, achieving gains ofup to 9.9% in accuracy and 12.3% in F-score. It also surpasses severaltransformer-based state-of-the-art architectures, highlighting the benefits ofincorporating 3D structural reasoning into 2D image classification tasks.</description>
      <author>example@mail.com (Youcef Sklab, Hanane Ariouat, Eric Chenin, Edi Prifti, Jean-Daniel Zucker)</author>
      <guid isPermaLink="false">2506.18683v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Point Correspondences In Radar 3D Point Clouds For Radar-Inertial Odometry</title>
      <link>http://arxiv.org/abs/2506.18580v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于学习框架的方法，用于预测在轻量级、低功耗、低成本消费级SoC FMCW雷达传感器中采集的噪声、稀疏和非结构化3D点云之间的鲁棒点对应关系。&lt;h4&gt;背景&lt;/h4&gt;在机器人里程计估计中使用3D点云时，通常需要在后续扫描的点之间找到一组对应关系。虽然对于高质量点云存在已建立的方法，但当质量下降时，最先进的方法仍然存在挑战。&lt;h4&gt;目的&lt;/h4&gt;提高从噪声、稀疏和非结构化3D点云中预测鲁棒点对应关系的能力。&lt;h4&gt;方法&lt;/h4&gt;该方法基于Transformer架构，利用注意力机制发现连续扫描中具有最大互相关性的点对。网络通过基于集合的多标签分类交叉熵损失进行自监督训练，通过解决线性求和分配（LSA）优化问题来找到匹配的地面真实集，从而避免了对训练数据的繁琐手工标注。将损失计算作为多标签分类，可以直接对点对应关系进行监督，而不是对里程计误差进行监督。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在真实世界无人机（UAV）飞行和广泛使用的公共Coloradar数据集上进行了评估，结果表明，该方法将位置估计精度提高了超过14%和19%。&lt;h4&gt;结论&lt;/h4&gt;该方法通过提高位置估计精度，为使用SoC雷达进行里程计估计提供了有效的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在机器人里程计估计中使用3D点云通常需要找到后续扫描中点之间的一组对应关系。虽然对于足够质量的点云有已建立的方法，但当质量下降时，最先进的方法仍然存在挑战。因此，本文提出了一种基于学习框架的方法，用于从轻量级、低功耗、低成本消费级SoC FMCW雷达传感器中预测噪声、稀疏和非结构化3D点云之间的鲁棒点对应关系。我们的网络基于Transformer架构，利用注意力机制发现连续扫描中具有最大互相关性的点对。所提出的网络通过使用基于集合的多标签分类交叉熵损失进行自监督训练，通过解决线性求和分配（LSA）优化问题来找到匹配的地面真实集，从而避免了训练数据的繁琐手工标注。将损失计算作为多标签分类，可以直接对点对应关系进行监督，而不是对来自SoC雷达的稀疏和噪声数据进行里程计误差的监督。我们使用开源的最先进雷达惯性里程计（RIO）框架在真实世界无人机（UAV）飞行和广泛使用的公共Coloradar数据集上评估了我们的方法。评估表明，所提出的方法将位置估计精度分别提高了超过14%和19%。开源代码和数据集可以在以下链接找到：https://github.com/aau-cns/radar_transformer。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Using 3D point clouds in odometry estimation in robotics often requiresfinding a set of correspondences between points in subsequent scans. Whilethere are established methods for point clouds of sufficient quality,state-of-the-art still struggles when this quality drops. Thus, this paperpresents a novel learning-based framework for predicting robust pointcorrespondences between pairs of noisy, sparse and unstructured 3D point cloudsfrom a light-weight, low-power, inexpensive, consumer-grade System-on-Chip(SoC) Frequency Modulated Continuous Wave (FMCW) radar sensor. Our network isbased on the transformer architecture which allows leveraging the attentionmechanism to discover pairs of points in consecutive scans with the greatestmutual affinity. The proposed network is trained in a self-supervised way usingset-based multi-label classification cross-entropy loss, where the ground-truthset of matches is found by solving the Linear Sum Assignment (LSA) optimizationproblem, which avoids tedious hand annotation of the training data.Additionally, posing the loss calculation as multi-label classification permitssupervising on point correspondences directly instead of on odometry error,which is not feasible for sparse and noisy data from the SoC radar we use. Weevaluate our method with an open-source state-of-the-art Radar-InertialOdometry (RIO) framework in real-world Unmanned Aerial Vehicle (UAV) flightsand with the widely used public Coloradar dataset. Evaluation shows that theproposed method improves the position estimation accuracy by over 14 % and 19 %on average, respectively. The open source code and datasets can be found here:https://github.com/aau-cns/radar_transformer.</description>
      <author>example@mail.com (Jan Michalczyk, Stephan Weiss, Jan Steinbrener)</author>
      <guid isPermaLink="false">2506.18580v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Fast State-Augmented Learning for Wireless Resource Allocation with Dual Variable Regression</title>
      <link>http://arxiv.org/abs/2506.18748v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE TSP for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多用户无线网络中的资源分配问题，旨在优化网络的全局效用函数，同时满足用户遍历平均性能的约束。&lt;h4&gt;背景&lt;/h4&gt;多用户无线网络中的资源分配问题，需要平衡网络全局效用与用户性能。&lt;h4&gt;目的&lt;/h4&gt;提出一种基于图神经网络（GNN）的资源分配策略，以优化网络效用函数。&lt;h4&gt;方法&lt;/h4&gt;使用状态增强的图神经网络（GNN）参数化资源分配策略，将网络配置表示为图，将对偶变量视为动态输入，并通过梯度更新执行学习到的状态增强策略。&lt;h4&gt;主要发现&lt;/h4&gt;通过双变量回归和辅助GNN参数化，实现了对偶乘子的近最优初始化，以加快推理速度；通过对偶下降动态中采样乘子的拉格朗日最大化显著提高了状态增强模型的训练效果。&lt;h4&gt;结论&lt;/h4&gt;通过大量数值实验证明了所提算法在发射功率控制案例研究中的优越性能，并证明了算法的收敛性和对偶函数（迭代）最优间隙的指数概率界限。&lt;h4&gt;翻译&lt;/h4&gt;We consider resource allocation problems in multi-user wireless networks, where the goal is to optimize a network-wide utility function subject to constraints on the ergodic average performance of users. We demonstrate how a state-augmented graph neural network (GNN) parametrization for the resource allocation policy circumvents the drawbacks of the ubiquitous dual subgradient methods by representing the network configurations (or states) as graphs and viewing dual variables as dynamic inputs to the model, viewed as graph signals supported over the graphs. Lagrangian maximizing state-augmented policies are learned during the offline training phase, and the dual variables evolve through gradient updates while executing the learned state-augmented policies during the inference phase. Our main contributions are to illustrate how near-optimal initialization of dual multipliers for faster inference can be accomplished with dual variable regression, leveraging a secondary GNN parametrization, and how maximization of the Lagrangian over the multipliers sampled from the dual descent dynamics substantially improves the training of state-augmented models. We demonstrate the superior performance of the proposed algorithm with extensive numerical experiments in a case study of transmit power control. Finally, we prove a convergence result and an exponential probability bound on the excursions of the dual function (iterate) optimality gaps.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We consider resource allocation problems in multi-user wireless networks,where the goal is to optimize a network-wide utility function subject toconstraints on the ergodic average performance of users. We demonstrate how astate-augmented graph neural network (GNN) parametrization for the resourceallocation policy circumvents the drawbacks of the ubiquitous dual subgradientmethods by representing the network configurations (or states) as graphs andviewing dual variables as dynamic inputs to the model, viewed as graph signalssupported over the graphs. Lagrangian maximizing state-augmented policies arelearned during the offline training phase, and the dual variables evolvethrough gradient updates while executing the learned state-augmented policiesduring the inference phase. Our main contributions are to illustrate hownear-optimal initialization of dual multipliers for faster inference can beaccomplished with dual variable regression, leveraging a secondary GNNparametrization, and how maximization of the Lagrangian over the multiplierssampled from the dual descent dynamics substantially improves the training ofstate-augmented models. We demonstrate the superior performance of the proposedalgorithm with extensive numerical experiments in a case study of transmitpower control. Finally, we prove a convergence result and an exponentialprobability bound on the excursions of the dual function (iterate) optimalitygaps.</description>
      <author>example@mail.com (Yigit Berkay Uslu, Navid NaderiAlizadeh, Mark Eisen, Alejandro Ribeiro)</author>
      <guid isPermaLink="false">2506.18748v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SRKD: Towards Efficient 3D Point Cloud Segmentation via Structure- and Relation-aware Knowledge Distillation</title>
      <link>http://arxiv.org/abs/2506.17290v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  13 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SRKD的新型结构-关系感知知识蒸馏框架，用于解决3D点云分割中的计算复杂性和部署限制问题。&lt;h4&gt;背景&lt;/h4&gt;3D点云分割因大规模Transformer模型的计算复杂性和部署限制而面临实际挑战。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了一种新的知识蒸馏框架，将丰富的几何和语义知识从大型冻结教师模型转移到轻量级学生模型。&lt;h4&gt;方法&lt;/h4&gt;SRKD框架包括：基于亲和矩阵的关系对齐模块，通过点间相似性匹配从教师模型中提取结构依赖；引入跨样本小批量构建策略，使学生模型能够感知稳定和通用的几何结构；使用KL散度对齐语义分布；以及使用真实标签监督进一步强化准确的分割。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在显著降低模型复杂性的同时，实现了最先进的性能，证明了其在实际部署场景中的有效性和效率。&lt;h4&gt;结论&lt;/h4&gt;SRKD框架能够有效解决3D点云分割的问题，并在实际应用中展现出良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel Structure- and Relation-aware Knowledge Distillation framework, named SRKD, to address the practical challenges in 3D point cloud segmentation due to the computational complexity and deployment limitations of large-scale transformer-based models. To achieve this, we transfer rich geometric and semantic knowledge from a large frozen teacher model (&gt;100M) to a lightweight student model (&lt;15M). Specifically, we propose an affinity matrix-based relation alignment module that distills structural dependencies from the teacher to the student through point-wise similarity matching, enhancing the student's capability to learn contextual interactions. Meanwhile, we introduce a cross-sample mini-batch construction strategy that enables the student to perceive stable and generalized geometric structure. This aligns across diverse point cloud instances of the teacher, rather than within a single sample. Additionally, KL divergence is applied to align semantic distributions, and ground-truth supervision further reinforces accurate segmentation. Our method achieves state-of-the-art performance with significantly reduced model complexity, demonstrating its effectiveness and efficiency in real-world deployment scenarios. Our Code is available at https://github.com/itsnotacie/SRKD.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D point cloud segmentation faces practical challenges due to thecomputational complexity and deployment limitations of large-scaletransformer-based models. To address this, we propose a novel Structure- andRelation-aware Knowledge Distillation framework, named SRKD, that transfersrich geometric and semantic knowledge from a large frozen teacher model (&gt;100M)to a lightweight student model (&lt;15M). Specifically, we propose an affinitymatrix-based relation alignment module, which distills structural dependenciesfrom the teacher to the student through point-wise similarity matching,enhancing the student's capability to learn contextual interactions. Meanwhile,we introduce a cross-sample mini-batch construction strategy that enables thestudent to perceive stable and generalized geometric structure. This alignsacross diverse point cloud instances of the teacher, rather than within asingle sample. Additionally, KL divergence is applied to align semanticdistributions, and ground-truth supervision further reinforces accuratesegmentation. Our method achieves state of the art performance withsignificantly reduced model complexity, demonstrating its effectiveness andefficiency in real-world deployment scenarios. Our Code is available athttps://github.com/itsnotacie/SRKD.</description>
      <author>example@mail.com (Yuqi Li, Junhao Dong, Zeyu Dong, Chuanguang Yang, Zhulin An, Yongjun Xu)</author>
      <guid isPermaLink="false">2506.17290v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>EASE: Embodied Active Event Perception via Self-Supervised Energy Minimization</title>
      <link>http://arxiv.org/abs/2506.17516v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IEEE Robotics and Automation Letters, 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;EASE是一种自监督框架，旨在通过自由能最小化统一时空表示学习和具身控制，以实现动态事件感知。&lt;h4&gt;背景&lt;/h4&gt;现有的事件感知方法通常依赖于预定义的动作空间、标注数据集和外部奖励，这在动态、现实场景中的适应性和可扩展性有限。&lt;h4&gt;目的&lt;/h4&gt;提出EASE框架，以实现动态检测、跟踪和总结实时事件的能力，这对于具身智能在人类-人工智能协作、辅助机器人和自主导航等任务中至关重要。&lt;h4&gt;方法&lt;/h4&gt;EASE利用预测误差和熵作为内在信号来分割事件、总结观察结果并主动跟踪显著演员，无需显式标注或外部奖励。&lt;h4&gt;主要发现&lt;/h4&gt;EASE通过结合生成感知模型和动作驱动的控制策略，动态地将预测与观察结果对齐，实现了隐式记忆、目标连续性和对新环境的适应性等涌现行为。&lt;h4&gt;结论&lt;/h4&gt;在模拟和现实环境中的广泛评估表明，EASE能够实现隐私保护和可扩展的事件感知，为无脚本、动态任务中的具身系统提供了一个稳健的基础。&lt;h4&gt;翻译&lt;/h4&gt;Active event perception, the ability to dynamically detect, track, and summarize events in real time, is essential for embodied intelligence in tasks such as human-AI collaboration, assistive robotics, and autonomous navigation. However, existing approaches often depend on predefined action spaces, annotated datasets, and extrinsic rewards, limiting their adaptability and scalability in dynamic, real-world scenarios. Inspired by cognitive theories of event perception and predictive coding, we propose EASE, a self-supervised framework that unifies spatiotemporal representation learning and embodied control through free energy minimization. EASE leverages prediction errors and entropy as intrinsic signals to segment events, summarize observations, and actively track salient actors, operating without explicit annotations or external rewards. By coupling a generative perception model with an action-driven control policy, EASE dynamically aligns predictions with observations, enabling emergent behaviors such as implicit memory, target continuity, and adaptability to novel environments. Extensive evaluations in simulation and real-world settings demonstrate EASE's ability to achieve privacy-preserving and scalable event perception, providing a robust foundation for embodied systems in unscripted, dynamic tasks.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Active event perception, the ability to dynamically detect, track, andsummarize events in real time, is essential for embodied intelligence in taskssuch as human-AI collaboration, assistive robotics, and autonomous navigation.However, existing approaches often depend on predefined action spaces,annotated datasets, and extrinsic rewards, limiting their adaptability andscalability in dynamic, real-world scenarios. Inspired by cognitive theories ofevent perception and predictive coding, we propose EASE, a self-supervisedframework that unifies spatiotemporal representation learning and embodiedcontrol through free energy minimization. EASE leverages prediction errors andentropy as intrinsic signals to segment events, summarize observations, andactively track salient actors, operating without explicit annotations orexternal rewards. By coupling a generative perception model with anaction-driven control policy, EASE dynamically aligns predictions withobservations, enabling emergent behaviors such as implicit memory, targetcontinuity, and adaptability to novel environments. Extensive evaluations insimulation and real-world settings demonstrate EASE's ability to achieveprivacy-preserving and scalable event perception, providing a robust foundationfor embodied systems in unscripted, dynamic tasks.</description>
      <author>example@mail.com (Zhou Chen, Sanjoy Kundu, Harsimran S. Baweja, Sathyanarayanan N. Aakur)</author>
      <guid isPermaLink="false">2506.17516v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Universal Video Temporal Grounding with Generative Multi-modal Large Language Models</title>
      <link>http://arxiv.org/abs/2506.18883v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种通用的视频时间定位计算模型，能够根据自然语言查询（如问题或描述）准确地在视频中定位时间点。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常限于特定的视频领域或持续时间。&lt;h4&gt;目的&lt;/h4&gt;提出一个鲁棒且通用的视频定位模型UniTime，利用生成多模态大型语言模型（MLLM）的强大视觉语言理解能力。&lt;h4&gt;方法&lt;/h4&gt;（i）考虑将强MLLM用于视频时间定位，通过交错时间戳标记和视频标记来引入时间信息以实现精确的时间戳输出；（ii）通过自适应帧缩放训练模型处理不同输入粒度的视频，从而实现短视频和长视频的鲁棒时间定位；（iii）全面实验表明，UniTime在五个公开的时间定位基准测试中，在零样本和数据集特定微调设置下均优于现有方法；（iv）作为长视频问答（VideoQA）的初步时刻检索器，UniTime显著提高了VideoQA的准确性。&lt;h4&gt;主要发现&lt;/h4&gt;UniTime在处理不同视图、类型和长度的视频以及理解复杂语言查询方面表现出色。&lt;h4&gt;结论&lt;/h4&gt;UniTime对于复杂视频理解任务具有重要价值。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种通用的视频时间定位计算模型，能够根据自然语言查询（如问题或描述）准确地在视频中定位时间点。与现有方法相比，该方法不受特定视频领域或持续时间的限制。本文提出的UniTime模型利用了生成多模态大型语言模型（MLLM）的强大视觉语言理解能力，能够处理不同视图、类型和长度的视频，并理解复杂语言查询。主要贡献包括：将强MLLM用于视频时间定位，通过交错时间戳标记和视频标记引入时间信息以实现精确的时间戳输出；通过自适应帧缩放训练模型，实现短视频和长视频的鲁棒时间定位；在五个公开的时间定位基准测试中，UniTime在零样本和数据集特定微调设置下均优于现有方法；作为长视频问答（VideoQA）的初步时刻检索器，UniTime显著提高了VideoQA的准确性，突显了其在复杂视频理解任务中的价值。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a computational model for universal video temporalgrounding, which accurately localizes temporal moments in videos based onnatural language queries (e.g., questions or descriptions). Unlike existingmethods that are often limited to specific video domains or durations, wepropose UniTime, a robust and universal video grounding model leveraging thestrong vision-language understanding capabilities of generative Multi-modalLarge Language Models (MLLMs). Our model effectively handles videos of diverseviews, genres, and lengths while comprehending complex language queries. Thekey contributions include: (i) We consider steering strong MLLMs for temporalgrounding in videos. To enable precise timestamp outputs, we incorporatetemporal information by interleaving timestamp tokens with video tokens. (ii)By training the model to handle videos with different input granularitiesthrough adaptive frame scaling, our approach achieves robust temporal groundingfor both short and long videos. (iii) Comprehensive experiments show thatUniTime outperforms state-of-the-art approaches in both zero-shot anddataset-specific finetuned settings across five public temporal groundingbenchmarks. (iv) When employed as a preliminary moment retriever for long-formvideo question-answering (VideoQA), UniTime significantly improves VideoQAaccuracy, highlighting its value for complex video understanding tasks.</description>
      <author>example@mail.com (Zeqian Li, Shangzhe Di, Zhonghua Zhai, Weilin Huang, Yanfeng Wang, Weidi Xie)</author>
      <guid isPermaLink="false">2506.18883v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Object-aware Sound Source Localization via Audio-Visual Scene Understanding</title>
      <link>http://arxiv.org/abs/2506.18557v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at CVPR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的音频-视觉声源定位框架，利用多模态大型语言模型来区分声源物体和静音背景物体，并通过实验证明其在单源和多源定位场景中的有效性。&lt;h4&gt;背景&lt;/h4&gt;现有的声源定位方法在复杂场景中难以准确定位声源物体，特别是当存在视觉相似但静音的物体时，因为它们依赖于简单的音频-视觉对应关系，无法捕捉声源和静音物体之间的细粒度语义差异。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的声源定位框架，以解决上述问题，通过多模态大型语言模型生成区分声源和静音物体的详细上下文信息。&lt;h4&gt;方法&lt;/h4&gt;该框架引入了两种新的损失函数：对象感知对比对齐（OCA）损失和对象区域隔离（ORI）损失，以有效整合生成的详细信息。&lt;h4&gt;主要发现&lt;/h4&gt;在MUSIC和VGGSound数据集上的实验结果表明，该方法在单源和多源定位场景中均显著优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;该方法能够有效提高声源定位的准确性，特别是在复杂场景中区分声源和静音物体方面。&lt;h4&gt;翻译&lt;/h4&gt;Audio-visual sound source localization aims to spatially locate sound-making objects within visual scenes by integrating visual and audio cues. However, existing methods struggle with accurately localizing sound-making objects in complex scenes, particularly when visually similar silent objects coexist. This limitation arises primarily from their reliance on simple audio-visual correspondence, which does not capture fine-grained semantic differences between sound-making and silent objects. To address these challenges, we propose a novel sound source localization framework leveraging Multimodal Large Language Models (MLLMs) to generate detailed contextual information that explicitly distinguishes between sound-making foreground objects and silent background objects. To effectively integrate this detailed information, we introduce two novel loss functions: Object-aware Contrastive Alignment (OCA) loss and Object Region Isolation (ORI) loss. Extensive experimental results on MUSIC and VGGSound datasets demonstrate the effectiveness of our approach, significantly outperforming existing methods in both single-source and multi-source localization scenarios. Code and generated detailed contextual information are available at: https://github.com/VisualAIKHU/OA-SSL.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Audio-visual sound source localization task aims to spatially localizesound-making objects within visual scenes by integrating visual and audio cues.However, existing methods struggle with accurately localizing sound-makingobjects in complex scenes, particularly when visually similar silent objectscoexist. This limitation arises primarily from their reliance on simpleaudio-visual correspondence, which does not capture fine-grained semanticdifferences between sound-making and silent objects. To address thesechallenges, we propose a novel sound source localization framework leveragingMultimodal Large Language Models (MLLMs) to generate detailed contextualinformation that explicitly distinguishes between sound-making foregroundobjects and silent background objects. To effectively integrate this detailedinformation, we introduce two novel loss functions: Object-aware ContrastiveAlignment (OCA) loss and Object Region Isolation (ORI) loss. Extensiveexperimental results on MUSIC and VGGSound datasets demonstrate theeffectiveness of our approach, significantly outperforming existing methods inboth single-source and multi-source localization scenarios. Code and generateddetailed contextual information are available at:https://github.com/VisualAIKHU/OA-SSL.</description>
      <author>example@mail.com (Sung Jin Um, Dongjin Kim, Sangmin Lee, Jung Uk Kim)</author>
      <guid isPermaLink="false">2506.18557v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Resampling Augmentation for Time Series Contrastive Learning: Application to Remote Sensing</title>
      <link>http://arxiv.org/abs/2506.18587v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 2 figures, accepted at 42nd International Conference on  Machine Learning (ICML 2025) Terrabytes workshop&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种基于重采样的数据增强策略，用于生成对比学习中的正对，并在农业分类基准测试中取得了优异性能。&lt;h4&gt;背景&lt;/h4&gt;由于存在大量未标记的卫星图像时间序列数据，而标记数据稀缺，对比自监督预训练成为利用这些未标记数据的自然工具。&lt;h4&gt;目的&lt;/h4&gt;设计有效的时间序列数据增强策略，以改善对比学习的效果。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于重采样的数据增强策略，通过上采样时间序列并提取不重叠的子序列来生成正对，同时保持时间覆盖。&lt;h4&gt;主要发现&lt;/h4&gt;在多个农业分类基准测试中，该方法优于常见的抖动、调整大小和遮罩等替代方法。在S2-Agri100数据集上，该方法不使用空间信息或时间编码，达到了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法为遥感时间序列的对比学习提供了一种简单而有效的数据增强方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Given the abundance of unlabeled Satellite Image Time Series (SITS) and thescarcity of labeled data, contrastive self-supervised pretraining emerges as anatural tool to leverage this vast quantity of unlabeled data. However,designing effective data augmentations for contrastive learning remainschallenging for time series. We introduce a novel resampling-based augmentationstrategy that generates positive pairs by upsampling time series and extractingdisjoint subsequences while preserving temporal coverage. We validate ourapproach on multiple agricultural classification benchmarks using Sentinel-2imagery, showing that it outperforms common alternatives such as jittering,resizing, and masking. Further, we achieve state-of-the-art performance on theS2-Agri100 dataset without employing spatial information or temporal encodings,surpassing more complex masked-based SSL frameworks. Our method offers asimple, yet effective, contrastive learning augmentation for remote sensingtime series.</description>
      <author>example@mail.com (Antoine Saget, Baptiste Lafabregue, Antoine Cornuéjols, Pierre Gançarski)</author>
      <guid isPermaLink="false">2506.18587v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies</title>
      <link>http://arxiv.org/abs/2506.18819v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  24 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了RWESummary，它是MedHELM框架的补充，用于评估大型语言模型在从RWE研究结构化输出中总结真实世界证据（RWE）方面的性能。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在通用摘要任务和医学研究辅助方面得到了广泛评估，但尚未专门评估其总结RWE的能力。&lt;h4&gt;目的&lt;/h4&gt;提出RWESummary，以实现对LLMs在总结RWE方面的基准测试。&lt;h4&gt;方法&lt;/h4&gt;RWESummary包含一个场景和三个评估，覆盖了医学研究摘要中观察到的主要错误类型，并使用AtroposHealth专有数据进行开发。此外，使用RWESummary比较了不同LLMs在内部RWE摘要工具中的性能。&lt;h4&gt;主要发现&lt;/h4&gt;在13个不同的RWE研究中，Gemini 2.5模型（包括Flash和Pro）表现最佳。&lt;h4&gt;结论&lt;/h4&gt;RWESummary被建议作为真实世界证据研究摘要的新颖而有用的基础模型基准。&lt;h4&gt;翻译&lt;/h4&gt;Large Language Models (LLMs) have been extensively evaluated for general summarization tasks as well as medical research assistance, but they have not been specifically evaluated for the task of summarizing real-world evidence (RWE) from structured output of RWE studies. We introduce RWESummary, a proposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al., 2025) to enable benchmarking of LLMs for this task. RWESummary includes one scenario and three evaluations covering major types of errors observed in summarization of medical research studies and was developed using AtroposHealth proprietary data. Additionally, we use RWESummary to compare the performance of different LLMs in our internal RWE summarization tool. At the time of publication, with 13 distinct RWE studies, we found the Gemini 2.5 models performed best overall (both Flash and Pro). We suggest RWESummary as a novel and useful foundation model benchmark for real-world evidence study summarization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have been extensively evaluated for generalsummarization tasks as well as medical research assistance, but they have notbeen specifically evaluated for the task of summarizing real-world evidence(RWE) from structured output of RWE studies. We introduce RWESummary, aproposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al.,2025) to enable benchmarking of LLMs for this task. RWESummary includes onescenario and three evaluations covering major types of errors observed insummarization of medical research studies and was developed using AtroposHealth proprietary data. Additionally, we use RWESummary to compare theperformance of different LLMs in our internal RWE summarization tool. At thetime of publication, with 13 distinct RWE studies, we found the Gemini 2.5models performed best overall (both Flash and Pro). We suggest RWESummary as anovel and useful foundation model benchmark for real-world evidence studysummarization.</description>
      <author>example@mail.com (Arjun Mukerji, Michael L. Jackson, Jason Jones, Neil Sanghavi)</author>
      <guid isPermaLink="false">2506.18819v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting</title>
      <link>http://arxiv.org/abs/2506.18862v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to the 33rd ACM International Conference on Multimedia. Our  dataset can be found at https://huggingface.co/datasets/IceInPot/TAMMs&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多模态大型语言模型（MLLMs）在卫星图像时间序列分析中的应用，提出了一种名为TAMMs的模型，用于卫星图像变化理解和预测，并通过实验证明了其优于现有MLLMs基线。&lt;h4&gt;背景&lt;/h4&gt;卫星图像时间序列分析需要细粒度的时空推理，而现有的MLLMs在处理这类任务时存在挑战。&lt;h4&gt;目的&lt;/h4&gt;评估MLLMs在建模复杂多模态动态变化方面的潜力，特别是针对时间变化理解和未来场景生成。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为TAMMs的时空感知多模态模型，它通过轻量级时间模块增强冻结的MLLMs，并引入了语义融合控制注入（SFCI）机制，以指导未来图像生成。&lt;h4&gt;主要发现&lt;/h4&gt;TAMMs在时间变化理解和未来图像预测任务上优于强MLLMs基线，证明了精心设计的时空推理和语义融合能够释放MLLMs在时空理解方面的潜力。&lt;h4&gt;结论&lt;/h4&gt;TAMMs模型通过增强MLLMs的时空推理能力，在卫星图像时间序列分析中取得了显著成效，为MLLMs在时空理解领域的应用提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;This paper studies the application of multimodal large language models (MLLMs) in satellite image time-series analysis, proposes a model named TAMMs for satellite image change understanding and forecasting, and demonstrates its superiority over existing MLLM baselines through experiments.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Satellite image time-series analysis demands fine-grained spatial-temporalreasoning, which remains a challenge for existing multimodal large languagemodels (MLLMs). In this work, we study the capabilities of MLLMs on a noveltask that jointly targets temporal change understanding and future scenegeneration, aiming to assess their potential for modeling complex multimodaldynamics over time. We propose TAMMs, a Temporal-Aware Multimodal Model forsatellite image change understanding and forecasting, which enhances frozenMLLMs with lightweight temporal modules for structured sequence encoding andcontextual prompting. To guide future image generation, TAMMs introduces aSemantic-Fused Control Injection (SFCI) mechanism that adaptively combineshigh-level semantic reasoning and structural priors within an enhancedControlNet. This dual-path conditioning enables temporally consistent andsemantically grounded image synthesis. Experiments demonstrate that TAMMsoutperforms strong MLLM baselines in both temporal change understanding andfuture image forecasting tasks, highlighting how carefully designed temporalreasoning and semantic fusion can unlock the full potential of MLLMs forspatio-temporal understanding.</description>
      <author>example@mail.com (Zhongbin Guo, Yuhao Wang, Ping Jian, Xinyue Chen, Wei Peng, Ertai E)</author>
      <guid isPermaLink="false">2506.18862v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers</title>
      <link>http://arxiv.org/abs/2506.18791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了基于超像素的Patch Pooling（SPPP）技术和Light Latent Attention（LLA）模块，旨在解决Vision Transformers在预训练和任务特定迁移学习中的计算和内存资源消耗大、能效低的问题。&lt;h4&gt;背景&lt;/h4&gt;Vision Transformers在各个领域取得了成功，但其对大规模数据集的预训练依赖大量计算和内存资源，且在特定任务迁移学习上存在困难。&lt;h4&gt;目的&lt;/h4&gt;提出新的技术和模块，以降低架构复杂性，提高效率，并解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;提出SPPP技术生成上下文感知、语义丰富的patch embeddings，并引入LLA模块，将潜在token整合到注意力机制中，减少注意力模块的时间和空间复杂度。通过数据直观的patch embeddings和动态位置编码，自适应调节交叉注意力过程，专注于信息区域，同时保持全局语义结构。&lt;h4&gt;主要发现&lt;/h4&gt;SPPP模块轻量且易于集成到现有transformer架构中。实验表明，所提出的架构在计算效率上提供了显著改进，同时实现了与最先进方法相当的结果。&lt;h4&gt;结论&lt;/h4&gt;该架构具有节能潜力，适用于边缘部署，并已在GitHub上提供代码：https://github.com/zser092/Focused-Attention-ViT。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The evolution of Vision Transformers has led to their widespread adaptationto different domains. Despite large-scale success, there remain significantchallenges including their reliance on extensive computational and memoryresources for pre-training on huge datasets as well as difficulties intask-specific transfer learning. These limitations coupled with energyinefficiencies mainly arise due to the computation-intensive self-attentionmechanism. To address these issues, we propose a novel Super-Pixel Based PatchPooling (SPPP) technique that generates context-aware, semantically rich, patchembeddings to effectively reduce the architectural complexity and improveefficiency. Additionally, we introduce the Light Latent Attention (LLA) modulein our pipeline by integrating latent tokens into the attention mechanismallowing cross-attention operations to significantly reduce the time and spacecomplexity of the attention module. By leveraging the data-intuitive patchembeddings coupled with dynamic positional encodings, our approach adaptivelymodulates the cross-attention process to focus on informative regions whilemaintaining the global semantic structure. This targeted attention improvestraining efficiency and accelerates convergence. Notably, the SPPP module islightweight and can be easily integrated into existing transformerarchitectures. Extensive experiments demonstrate that our proposed architectureprovides significant improvements in terms of computational efficiency whileachieving comparable results with the state-of-the-art approaches, highlightingits potential for energy-efficient transformers suitable for edge deployment.(The code is available on our GitHub repository:https://github.com/zser092/Focused-Attention-ViT).</description>
      <author>example@mail.com (Suyash Gaurav, Muhammad Farhan Humayun, Jukka Heikkonen, Jatin Chaudhary)</author>
      <guid isPermaLink="false">2506.18791v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation</title>
      <link>http://arxiv.org/abs/2506.17891v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by CVPR 2025. Code:  https://github.com/Howard-coder191/Relation3D&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Relation3D的新方法，旨在改进点云实例分割中的关系建模。&lt;h4&gt;背景&lt;/h4&gt;当前基于transformer的方法在场景特征和查询特征的外部关系建模上表现良好，但缺乏对内部关系的有效建模。&lt;h4&gt;目的&lt;/h4&gt;提出Relation3D方法，以增强点云实例分割中的关系建模。&lt;h4&gt;方法&lt;/h4&gt;Relation3D方法包括自适应超点聚合模块和对比学习引导的超点细化模块，以及将位置和几何关系纳入自注意力机制的关系感知自注意力机制。&lt;h4&gt;主要发现&lt;/h4&gt;Relation3D在ScanNetV2、ScanNet++、ScanNet200和S3DIS数据集上进行了广泛的实验，并证明了其优越的性能。&lt;h4&gt;结论&lt;/h4&gt;Relation3D通过改进关系建模，在点云实例分割任务中取得了显著的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D instance segmentation aims to predict a set of object instances in ascene, representing them as binary foreground masks with corresponding semanticlabels. Currently, transformer-based methods are gaining increasing attentiondue to their elegant pipelines and superior predictions. However, these methodsprimarily focus on modeling the external relationships between scene featuresand query features through mask attention. They lack effective modeling of theinternal relationships among scene features as well as between query features.In light of these disadvantages, we propose \textbf{Relation3D: EnhancingRelation Modeling for Point Cloud Instance Segmentation}. Specifically, weintroduce an adaptive superpoint aggregation module and a contrastivelearning-guided superpoint refinement module to better represent superpointfeatures (scene features) and leverage contrastive learning to guide theupdates of these features. Furthermore, our relation-aware self-attentionmechanism enhances the capabilities of modeling relationships between queriesby incorporating positional and geometric relationships into the self-attentionmechanism. Extensive experiments on the ScanNetV2, ScanNet++, ScanNet200 andS3DIS datasets demonstrate the superior performance of Relation3D.</description>
      <author>example@mail.com (Jiahao Lu, Jiacheng Deng)</author>
      <guid isPermaLink="false">2506.17891v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>These are Not All the Features You are Looking For: A Fundamental Bottleneck In Supervised Pretraining</title>
      <link>http://arxiv.org/abs/2506.18221v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 7 figures, Preprint. Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了迁移学习在机器学习中的重要性，分析了深度学习模型在特征学习上的局限性，并提出了改进迁移学习性能的方法。&lt;h4&gt;背景&lt;/h4&gt;迁移学习允许将预训练模型应用于新任务，但存在如何确保迁移特征足够处理未见数据集的挑战。&lt;h4&gt;目的&lt;/h4&gt;评估从预训练混合模型到其组件任务的模型迁移，并探讨如何使预训练特征匹配特定任务的直接训练性能。&lt;h4&gt;方法&lt;/h4&gt;研究识别了深度学习模型中的“信息饱和瓶颈”，提出限制预训练时只学习关键特征集的方法，并提出了更丰富的特征表示作为潜在解决方案。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，网络在训练过程中编码相似竞争特征后，会停止学习新特征，导致模型在数据分布上表现不一致。&lt;h4&gt;结论&lt;/h4&gt;研究建议，当有可用资源时，专注于特定任务的训练可能比依赖大规模网络更有效，并提出了新的方法来应对这一挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：迁移学习是现代机器学习的基础，它承诺通过最小的新数据来适应在广泛数据集上预训练的模型的新任务。然而，确保迁移特征足以处理未见数据集仍然是一个重大挑战，这加剧了量化两个任务是否“相关”的困难。为了解决这些挑战，我们评估了从预训练混合模型到其每个组件任务的模型迁移，评估预训练特征是否可以匹配特定任务的直接训练性能。我们确定深度学习模型存在一个基本限制——“信息饱和瓶颈”，其中网络在训练过程中编码相似竞争特征后无法学习新特征。当限制在预训练期间仅学习关键特征子集时，模型将永久失去迁移的关键特征，并在数据分布上表现不一致，即使是训练混合的组成部分。从已发表的实证研究中得出的证据表明，这种现象在深度学习架构中普遍存在——诸如数据分布或顺序等因素会影响当前表示学习方法随时间学习到的特征。本研究表明，仅依赖大规模网络可能不如专注于特定任务的训练有效，并提出了更丰富的特征表示作为更好地泛化到新数据集的潜在解决方案，并具体介绍了现有方法以及一种新颖的方法，这是解决这一挑战的初步步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Transfer learning is a cornerstone of modern machine learning, promising away to adapt models pretrained on a broad mix of data to new tasks with minimalnew data. However, a significant challenge remains in ensuring that transferredfeatures are sufficient to handle unseen datasets, amplified by the difficultyof quantifying whether two tasks are "related". To address these challenges, weevaluate model transfer from a pretraining mixture to each of its componenttasks, assessing whether pretrained features can match the performance oftask-specific direct training. We identify a fundamental limitation in deeplearning models -- an "information saturation bottleneck" -- where networksfail to learn new features once they encode similar competing features duringtraining. When restricted to learning only a subset of key features duringpretraining, models will permanently lose critical features for transfer andperform inconsistently on data distributions, even components of the trainingmixture. Empirical evidence from published studies suggests that thisphenomenon is pervasive in deep learning architectures -- factors such as datadistribution or ordering affect the features that current representationlearning methods can learn over time. This study suggests that relying solelyon large-scale networks may not be as effective as focusing on task-specifictraining, when available. We propose richer feature representations as apotential solution to better generalize across new datasets and, specifically,present existing methods alongside a novel approach, the initial steps towardsaddressing this challenge.</description>
      <author>example@mail.com (Xingyu Alice Yang, Jianyu Zhang, Léon Bottou)</author>
      <guid isPermaLink="false">2506.18221v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SaGIF: Improving Individual Fairness in Graph Neural Networks via Similarity Encoding</title>
      <link>http://arxiv.org/abs/2506.18696v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Under review&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络中的个体公平性（IF）问题，提出了一个名为SaGIF的相似性感知GNN以提升IF。&lt;h4&gt;背景&lt;/h4&gt;个体公平性在图神经网络中是一个关键问题，但目前关于其引起原因和相似个体识别的研究尚不充分。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，本文进行了初步分析，探索个体不公平性的原因，并引入了两个度量标准来评估个体相似性。&lt;h4&gt;方法&lt;/h4&gt;本文提出了拓扑融合和特征融合两种方法来评估个体相似性，并基于这些度量标准提出了相似性感知GNN（SaGIF）。&lt;h4&gt;主要发现&lt;/h4&gt;SaGIF通过独立学习相似性表示来整合个体相似性，从而在GNN中提高了个体公平性。实验结果表明，SaGIF在多个真实世界数据集上优于现有的个体公平性方法。&lt;h4&gt;结论&lt;/h4&gt;SaGIF是一个有效的解决方案，能够提升图神经网络中的个体公平性，同时保持效用性能。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the issue of individual fairness (IF) in graph neural networks (GNNs), and proposes a Similarity-aware GNN named SaGIF to enhance IF.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Individual fairness (IF) in graph neural networks (GNNs), which emphasizesthe need for similar individuals should receive similar outcomes from GNNs, hasbeen a critical issue. Despite its importance, research in this area has beenlargely unexplored in terms of (1) a clear understanding of what inducesindividual unfairness in GNNs and (2) a comprehensive consideration ofidentifying similar individuals. To bridge these gaps, we conduct a preliminaryanalysis to explore the underlying reason for individual unfairness and observecorrelations between IF and similarity consistency, a concept introduced toevaluate the discrepancy in identifying similar individuals based on graphstructure versus node features. Inspired by our observations, we introduce twometrics to assess individual similarity from two distinct perspectives:topology fusion and feature fusion. Building upon these metrics, we proposeSimilarity-aware GNNs for Individual Fairness, named SaGIF. The key insightbehind SaGIF is the integration of individual similarities by independentlylearning similarity representations, leading to an improvement of IF in GNNs.Our experiments on several real-world datasets validate the effectiveness ofour proposed metrics and SaGIF. Specifically, SaGIF consistently outperformsstate-of-the-art IF methods while maintaining utility performance. Code isavailable at: https://github.com/ZzoomD/SaGIF.</description>
      <author>example@mail.com (Yuchang Zhu, Jintang Li, Huizhe Zhang, Liang Chen, Zibin Zheng)</author>
      <guid isPermaLink="false">2506.18696v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>DIP: Unsupervised Dense In-Context Post-training of Visual Representations</title>
      <link>http://arxiv.org/abs/2506.18463v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为DIP的新颖的无监督后训练方法，旨在增强大规模预训练视觉编码器在上下文场景理解中的密集图像表示。&lt;h4&gt;背景&lt;/h4&gt;与依赖复杂自蒸馏架构的先前方法不同，DIP使用模拟下游上下文场景的伪任务来训练视觉编码器，并受到元学习原理的启发。&lt;h4&gt;目的&lt;/h4&gt;该方法旨在提高视觉编码器在上下文场景理解任务中的表现。&lt;h4&gt;方法&lt;/h4&gt;为了在无标签数据上实现后训练，DIP提出了一种自动机制来生成上下文任务，该机制结合了预训练的扩散模型和视觉编码器本身。&lt;h4&gt;主要发现&lt;/h4&gt;DIP简单、无监督且计算效率高，在单个A100 GPU上运行时间不到9小时。通过学习伪上下文任务中的密集表示，它在各种下游真实世界的上下文场景理解任务中表现出色，优于初始视觉编码器和先前的方法。&lt;h4&gt;结论&lt;/h4&gt;DIP提供了一种实用且有效的方法来提高密集表示，并且相关的代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;We introduce DIP, a novel unsupervised post-training method designed to enhance dense image representations in large-scale pretrained vision encoders for in-context scene understanding. Unlike prior approaches that rely on complex self-distillation architectures, our method trains the vision encoder using pseudo-tasks that explicitly simulate downstream in-context scenarios, inspired by meta-learning principles. To enable post-training on unlabeled data, we propose an automatic mechanism for generating in-context tasks that combines a pretrained diffusion model and the vision encoder itself. DIP is simple, unsupervised, and computationally efficient, requiring less than 9 hours on a single A100 GPU. By learning dense representations through pseudo-in-context tasks, it achieves strong performance across a wide variety of downstream real-world in-context scene understanding tasks. It outperforms both the initial vision encoder and prior methods, offering a practical and effective solution for improving dense representations. Code available here: https://github.com/sirkosophia/DIP&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce DIP, a novel unsupervised post-training method designed toenhance dense image representations in large-scale pretrained vision encodersfor in-context scene understanding. Unlike prior approaches that rely oncomplex self-distillation architectures, our method trains the vision encoderusing pseudo-tasks that explicitly simulate downstream in-context scenarios,inspired by meta-learning principles. To enable post-training on unlabeleddata, we propose an automatic mechanism for generating in-context tasks thatcombines a pretrained diffusion model and the vision encoder itself. DIP issimple, unsupervised, and computationally efficient, requiring less than 9hours on a single A100 GPU. By learning dense representations through pseudoin-context tasks, it achieves strong performance across a wide variety ofdownstream real-world in-context scene understanding tasks. It outperforms boththe initial vision encoder and prior methods, offering a practical andeffective solution for improving dense representations. Code available here:https://github.com/sirkosophia/DIP</description>
      <author>example@mail.com (Sophia Sirko-Galouchenko, Spyros Gidaris, Antonin Vobecky, Andrei Bursuc, Nicolas Thome)</author>
      <guid isPermaLink="false">2506.18463v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards Group Fairness with Multiple Sensitive Attributes in Federated Foundation Models</title>
      <link>http://arxiv.org/abs/2506.18732v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度集成基础模型与联邦学习相结合，在个性化、可扩展性方面对下游任务的提升，特别是在敏感领域如医疗保健中的重要性。文章着重于在联邦基础模型（FFM）时代，如何通过因果分析实现不同敏感属性间的群体公平性，并通过实验验证了其有效性。&lt;h4&gt;背景&lt;/h4&gt;随着联邦基础模型（FFM）的发展，如何在敏感领域中实现群体公平性成为关键问题。由于敏感属性中的偏差可能导致对少数群体的不公平待遇，因此需要关注群体公平性。&lt;h4&gt;目的&lt;/h4&gt;研究如何在FFM中实现不同敏感属性间的群体公平性，并通过因果发现和推理量化群体公平性背后的因果效应。&lt;h4&gt;方法&lt;/h4&gt;本文扩展了FFM结构，使其能够同时权衡多个敏感属性，并通过因果发现和推理来量化群体公平性的因果效应。&lt;h4&gt;主要发现&lt;/h4&gt;本文实现了对FFM中不同敏感属性间群体公平性的因果分析，并通过实验验证了其有效性。&lt;h4&gt;结论&lt;/h4&gt;本文的研究为构建可解释、可信且公平的FFM系统提供了见解。&lt;h4&gt;翻译&lt;/h4&gt;The deep integration of foundation models (FM) with federated learning (FL) enhances personalization and scalability for diverse downstream tasks, making it crucial in sensitive domains like healthcare. Achieving group fairness has become an increasingly prominent issue in the era of federated foundation models (FFMs), since biases in sensitive attributes might lead to inequitable treatment for under-represented demographic groups. Existing studies mostly focus on achieving fairness with respect to a single sensitive attribute. This renders them unable to provide clear interpretability of dependencies among multiple sensitive attributes which is required to achieve group fairness. Our paper takes the first attempt towards a causal analysis of the relationship between group fairness across various sensitive attributes in the FFM. We extend the FFM structure to trade off multiple sensitive attributes simultaneously and quantify the causal effect behind the group fairness through causal discovery and inference. Extensive experiments validate its effectiveness, offering insights into interpretability towards building trustworthy and fair FFM systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The deep integration of foundation models (FM) with federated learning (FL)enhances personalization and scalability for diverse downstream tasks, makingit crucial in sensitive domains like healthcare. Achieving group fairness hasbecome an increasingly prominent issue in the era of federated foundationmodels (FFMs), since biases in sensitive attributes might lead to inequitabletreatment for under-represented demographic groups. Existing studies mostlyfocus on achieving fairness with respect to a single sensitive attribute. Thisrenders them unable to provide clear interpretability of dependencies amongmultiple sensitive attributes which is required to achieve group fairness. Ourpaper takes the first attempt towards a causal analysis of the relationshipbetween group fairness across various sensitive attributes in the FFM. Weextend the FFM structure to trade off multiple sensitive attributessimultaneously and quantify the causal effect behind the group fairness throughcausal discovery and inference. Extensive experiments validate itseffectiveness, offering insights into interpretability towards buildingtrustworthy and fair FFM systems.</description>
      <author>example@mail.com (Yuning Yang, Han Yu, Tianrun Gao, Xiaodong Xu, Guangyu Wang)</author>
      <guid isPermaLink="false">2506.18732v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>VQ-Insight: Teaching VLMs for AI-Generated Video Quality Understanding via Progressive Visual Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.18564v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一种名为VQ-Insight的新型推理风格视觉语言模型框架，用于评估AI生成内容视频的质量。&lt;h4&gt;背景&lt;/h4&gt;尽管AI生成内容（AIGC）在文本到视频生成模型方面取得了进展，但评估AIGC生成视频的质量仍然具有挑战性，这包括泛化能力有限、缺乏时间感知、过度依赖大规模标注数据集以及与生成模型缺乏有效交互等问题。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些不足，论文提出了VQ-Insight框架，旨在提高视频质量评估的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;VQ-Insight采用的方法包括：（1）一种渐进式视频质量学习方案，结合图像质量预热、通用任务特定的时间学习以及与视频生成模型的联合优化；（2）设计多维度评分奖励、偏好比较奖励和时间建模奖励，以增强视频质量评估中的泛化和专业化。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，VQ-Insight在偏好比较、多维度评分和自然视频评分方面，持续优于现有最佳基准，为视频生成任务带来了显著的改进。&lt;h4&gt;结论&lt;/h4&gt;VQ-Insight是一种有效的视频质量评估框架，能够显著提高AI生成视频的质量评估能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in AI-generated content (AIGC) have led to the emergence ofpowerful text-to-video generation models. Despite these successes, evaluatingthe quality of AIGC-generated videos remains challenging due to limitedgeneralization, lack of temporal awareness, heavy reliance on large-scaleannotated datasets, and the lack of effective interaction with generationmodels. Most current approaches rely on supervised finetuning ofvision-language models (VLMs), which often require large-scale annotateddatasets and tend to decouple understanding and generation. To address theseshortcomings, we propose VQ-Insight, a novel reasoning-style VLM framework forAIGC video quality assessment. Our approach features: (1) a progressive videoquality learning scheme that combines image quality warm-up, generaltask-specific temporal learning, and joint optimization with the videogeneration model; (2) the design of multi-dimension scoring rewards, preferencecomparison rewards, and temporal modeling rewards to enhance bothgeneralization and specialization in video quality evaluation. Extensiveexperiments demonstrate that VQ-Insight consistently outperformsstate-of-the-art baselines in preference comparison, multi-dimension scoring,and natural video scoring, bringing significant improvements for videogeneration tasks.</description>
      <author>example@mail.com (Xuanyu Zhang, Weiqi Li, Shijie Zhao, Junlin Li, Li Zhang, Jian Zhang)</author>
      <guid isPermaLink="false">2506.18564v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging Transfer Learning to Overcome Data Limitations in Czochralski Crystal Growth</title>
      <link>http://arxiv.org/abs/2506.18774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to Advanced Theory and Simulations. 21 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种迁移学习方法，通过将在一个数据量较大的源材料（硅）上训练的机器学习模型应用于数据量较小的目标材料（锗和砷化镓）上，以克服数据稀缺的限制，提高预测精度。&lt;h4&gt;背景&lt;/h4&gt;Czochralski法是用于生长高质量单晶的常用过程，对于半导体、光学和先进材料的应用至关重要。然而，数据稀缺限制了机器学习在预测建模和优化中的应用。&lt;h4&gt;目的&lt;/h4&gt;通过迁移学习，将机器学习模型从硅材料扩展到锗和砷化镓材料，以优化Cz生长参数。&lt;h4&gt;方法&lt;/h4&gt;研究选择了Cz-Ge（与Cz-Si相似）和通过LEC方法生长的GaAs（与Cz-Si不同）作为材料，并探索了包括Warm Start、Merged Training和Hyperparameters Transfer在内的多种迁移学习策略，同时评估了多种机器学习架构。&lt;h4&gt;主要发现&lt;/h4&gt;迁移学习方法显著提高了预测精度，即使在数据量较少的情况下也有效，为优化不同材料的Cz生长参数提供了一个实用的框架。&lt;h4&gt;结论&lt;/h4&gt;迁移学习在处理不同数据相似度的情况下表现出鲁棒性，是优化Cz生长参数的一种有效方法。&lt;h4&gt;翻译&lt;/h4&gt;The Czochralski (Cz) method is a widely used process for growing high-quality single crystals, critical for applications in semiconductors, optics, and advanced materials. Achieving optimal growth conditions requires precise control of process and furnace design parameters. Still, data scarcity -- especially for new materials -- limits the application of machine learning (ML) in predictive modeling and optimization. This study proposes a transfer learning approach to overcome this limitation by adapting ML models trained on a higher data volume of one source material (Si) to a lower data volume of another target material (Ge and GaAs). The materials were deliberately selected to assess the robustness of the transfer learning approach in handling varying data similarity, with Cz-Ge being similar to Cz-Si, and GaAs grown via the liquid encapsulated Czochralski method (LEC), which differs from Cz-Si. We explore various transfer learning strategies, including Warm Start, Merged Training, and Hyperparameters Transfer, and evaluate multiple ML architectures across two different materials. Our results demonstrate that transfer learning significantly enhances predictive accuracy with minimal data, providing a practical framework for optimizing Cz growth parameters across diverse materials.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The Czochralski (Cz) method is a widely used process for growing high-qualitysingle crystals, critical for applications in semiconductors, optics, andadvanced materials. Achieving optimal growth conditions requires precisecontrol of process and furnace design parameters. Still, data scarcity --especially for new materials -- limits the application of machine learning (ML)in predictive modeling and optimization. This study proposes a transferlearning approach to overcome this limitation by adapting ML models trained ona higher data volume of one source material (Si) to a lower data volume ofanother target material (Ge and GaAs). The materials were deliberately selectedto assess the robustness of the transfer learning approach in handling varyingdata similarity, with Cz-Ge being similar to Cz-Si, and GaAs grown via theliquid encapsulated Czochralski method (LEC), which differs from Cz-Si. Weexplore various transfer learning strategies, including Warm Start, MergedTraining, and Hyperparameters Transfer, and evaluate multiple ML architecturesacross two different materials. Our results demonstrate that transfer learningsignificantly enhances predictive accuracy with minimal data, providing apractical framework for optimizing Cz growth parameters across diversematerials.</description>
      <author>example@mail.com (Milena Petkovic, Natasha Dropka, Xia Tang, Janina Zittel)</author>
      <guid isPermaLink="false">2506.18774v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SLAP: Siamese Language-Audio Pretraining Without Negative Samples for Music Understanding</title>
      <link>http://arxiv.org/abs/2506.17815v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ISMIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Siamese Language-Audio Pretraining (SLAP)的新型多模态预训练框架，用于音乐理解和生成，通过链接文本和音频，并解决了现有方法中内存需求大、模态差距大等问题。&lt;h4&gt;背景&lt;/h4&gt;联合嵌入空间通过多模态对比学习将文本和音频联系起来，显著推进了音乐理解和生成，但现有方法存在内存需求大和模态差距大的问题。&lt;h4&gt;目的&lt;/h4&gt;提出SLAP框架，以解决现有多模态预训练方法中的内存需求和模态差距问题。&lt;h4&gt;方法&lt;/h4&gt;SLAP框架借鉴了Bootstrap Your Own Latent (BYOL)范式，用于多模态音频-文本训练，以促进多模态嵌入空间的训练可扩展性。&lt;h4&gt;主要发现&lt;/h4&gt;SLAP在音乐和文本之间的有意义关系学习方面表现出色，例如在文本-音乐检索和零样本分类任务上优于CLAP。此外，在多个音乐信息检索（MIR）任务上，包括更大或监督模型（流派和乐器分类、自动标签）中，也表现出有竞争力的下游性能。SLAP还具有减少模态差距和改进对批量大小变化的检索性能的鲁棒性等吸引人的特性。&lt;h4&gt;结论&lt;/h4&gt;SLAP框架通过梯度累积，在单个GPU上解锁了大规模训练的可能性，有效解决了多模态预训练中的挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：联合嵌入空间通过多模态对比学习将文本和音频联系起来，显著推进了音乐理解和生成。然而，这些方法由于依赖于大批量样本来有效利用负样本，因此面临着巨大的内存需求限制。此外，多模态联合嵌入空间还存在着模态差距问题，即不同模态的嵌入位于嵌入空间的不同流形中。为了解决这些挑战，我们提出了Siamese Language-Audio Pretraining (SLAP)，这是一种新颖的多模态预训练框架，允许在不使用负样本的情况下学习强大的表示。SLAP将Bootstrap Your Own Latent (BYOL)范式应用于多模态音频-文本训练，促进了多模态嵌入空间的训练可扩展性。我们展示了我们的模型学习音乐和文本之间有意义关系的能力——具体来说，我们表明SLAP在文本-音乐检索和零样本分类等任务上优于CLAP。我们还观察到在多个MIR任务上的有竞争力的下游性能，包括使用更大或监督模型（流派和乐器分类、自动标签）。此外，我们的方法具有吸引人的特性，如可量化的模态差距减少和检索性能对批量大小变化的鲁棒性改进。最后，其新颖的公式通过梯度累积在单个GPU上解锁了大规模训练的可能性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Joint embedding spaces have significantly advanced music understanding andgeneration by linking text and audio through multimodal contrastive learning.However, these approaches face large memory requirement limitations due torelying on large batch sizes to effectively utilize negative samples. Further,multimodal joint embedding spaces suffer from a modality gap wherein embeddingsfrom different modalities lie in different manifolds of the embedding space. Toaddress these challenges, we propose Siamese Language-Audio Pretraining (SLAP),a novel multimodal pretraining framework that allows learning powerfulrepresentations without negative samples. SLAP adapts the Bootstrap Your OwnLatent (BYOL) paradigm for multimodal audio-text training, promotingscalability in training multimodal embedding spaces.  We illustrate the ability of our model to learn meaningful relationshipsbetween music and text -- specifically, we show that SLAP outperforms CLAP ontasks such as text-music retrieval and zero-shot classification. We alsoobserve competitive downstream performance on several MIR tasks, including withlarger or supervised models (genre and instrument classification,auto-tagging). Additionally, our approach has attractive properties, such as aquantifiably reduced modality gap and improved robustness to batch sizevariations on retrieval performance. Finally, its novel formulation unlockslarge-scale training on a single GPU through gradient accumulation.</description>
      <author>example@mail.com (Julien Guinot, Alain Riou, Elio Quinton, György Fazekas)</author>
      <guid isPermaLink="false">2506.17815v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Matrix-Game: Interactive World Foundation Model</title>
      <link>http://arxiv.org/abs/2506.18701v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;Matrix-Game是一个用于可控游戏世界生成的交互式世界基础模型，通过两阶段训练流程实现环境理解和交互式视频生成。&lt;h4&gt;背景&lt;/h4&gt;目前缺乏对游戏世界生成的精确控制，尤其是对于角色动作和摄像机移动。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够精确控制角色动作和摄像机移动，同时保持高视觉质量和时间一致性的游戏世界生成模型。&lt;h4&gt;方法&lt;/h4&gt;Matrix-Game采用可控的图像到世界生成范式，基于参考图像、运动上下文和用户动作进行训练。此外，构建了包含超过2700小时未标记游戏视频剪辑和超过1000小时高质量标记剪辑的Matrix-Game-MC数据集。&lt;h4&gt;主要发现&lt;/h4&gt;Matrix-Game在视觉质量、时间质量、动作可控性和物理规则理解等方面优于现有的Minecraft世界模型，如Oasis和MineWorld。双盲人类评估进一步证实了Matrix-Game的优越性。&lt;h4&gt;结论&lt;/h4&gt;Matrix-Game能够生成感知上真实且精确可控的视频，适用于各种游戏场景，并计划开源模型权重和GameWorld Score基准。&lt;h4&gt;翻译&lt;/h4&gt;我们介绍了一种名为Matrix-Game的交互式世界基础模型，用于可控游戏世界的生成。Matrix-Game通过两阶段流程进行训练，首先进行大规模未标记预训练以理解环境，然后进行动作标记训练以生成交互式视频。为了支持这一点，我们整理了Matrix-Game-MC数据集，这是一个包含超过2700小时未标记游戏视频剪辑和超过1000小时高质量标记剪辑的Minecraft数据集。我们的模型采用了一种可控的图像到世界生成范式，基于参考图像、运动上下文和用户动作。具有超过170亿个参数的Matrix-Game能够精确控制角色动作和摄像机移动，同时保持高视觉质量和时间一致性。为了评估性能，我们开发了GameWorldScore，这是一个统一的基准，用于衡量Minecraft世界生成的视觉质量、时间质量、动作可控性和物理规则理解。大量实验表明，Matrix-Game在所有指标上均优于现有的开源Minecraft世界模型（包括Oasis和MineWorld），尤其是在可控性和物理一致性方面有显著提升。双盲人类评估进一步证实了Matrix-Game的优越性，突出了其能够在各种游戏场景中生成感知上真实且精确可控视频的能力。为了促进交互式图像到世界生成方面的未来研究，我们将在https://github.com/SkyworkAI/Matrix-Game上开源Matrix-Game模型权重和GameWorld Score基准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce Matrix-Game, an interactive world foundation model forcontrollable game world generation. Matrix-Game is trained using a two-stagepipeline that first performs large-scale unlabeled pretraining for environmentunderstanding, followed by action-labeled training for interactive videogeneration. To support this, we curate Matrix-Game-MC, a comprehensiveMinecraft dataset comprising over 2,700 hours of unlabeled gameplay video clipsand over 1,000 hours of high-quality labeled clips with fine-grained keyboardand mouse action annotations. Our model adopts a controllable image-to-worldgeneration paradigm, conditioned on a reference image, motion context, and useractions. With over 17 billion parameters, Matrix-Game enables precise controlover character actions and camera movements, while maintaining high visualquality and temporal coherence. To evaluate performance, we develop GameWorldScore, a unified benchmark measuring visual quality, temporal quality, actioncontrollability, and physical rule understanding for Minecraft worldgeneration. Extensive experiments show that Matrix-Game consistentlyoutperforms prior open-source Minecraft world models (including Oasis andMineWorld) across all metrics, with particularly strong gains incontrollability and physical consistency. Double-blind human evaluationsfurther confirm the superiority of Matrix-Game, highlighting its ability togenerate perceptually realistic and precisely controllable videos acrossdiverse game scenarios. To facilitate future research on interactiveimage-to-world generation, we will open-source the Matrix-Game model weightsand the GameWorld Score benchmark at https://github.com/SkyworkAI/Matrix-Game.</description>
      <author>example@mail.com (Yifan Zhang, Chunli Peng, Boyang Wang, Puyi Wang, Qingcheng Zhu, Fei Kang, Biao Jiang, Zedong Gao, Eric Li, Yang Liu, Yahui Zhou)</author>
      <guid isPermaLink="false">2506.18701v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>STACT-Time: Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification</title>
      <link>http://arxiv.org/abs/2506.18172v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为STACT-Time的新型表示学习框架，用于通过超声电影序列对甲状腺超声进行分类，旨在减少良性结节的过度活检。&lt;h4&gt;背景&lt;/h4&gt;甲状腺癌是美国最常见的癌症之一，甲状腺结节常通过超声成像检测，部分需要通过细针穿刺活检进一步评估。尽管细针穿刺活检有效，但往往导致良性结节的过度活检，给患者带来不适和焦虑。&lt;h4&gt;目的&lt;/h4&gt;开发一种模型，以减少良性结节的过度活检，同时保持对恶性肿瘤的高敏感性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为STACT-Time的模型，该模型结合了超声电影序列的成像特征和由预训练模型自动生成的分割掩码特征。模型利用自注意力和交叉注意力机制来捕捉超声电影序列的丰富时空上下文，并通过分割引导学习来增强特征表示。&lt;h4&gt;主要发现&lt;/h4&gt;与最先进模型相比，STACT-Time模型提高了恶性肿瘤的预测能力，交叉验证精度为0.91（±0.02），F1分数为0.89（±0.02）。&lt;h4&gt;结论&lt;/h4&gt;STACT-Time模型有望通过减少良性结节的过度活检，同时保持对恶性肿瘤的高敏感性，从而提高临床决策能力并改善患者预后。&lt;h4&gt;翻译&lt;/h4&gt;摘要：甲状腺癌是美国最常见的癌症之一。甲状腺结节经常通过超声（US）成像检测，其中一些需要通过细针穿刺活检（FNA）进行进一步评估。尽管FNA很有效，但它往往导致良性结节的过度活检，造成患者不适和焦虑。为了解决这个问题，美国放射学会甲状腺成像报告和数据系统（TI-RADS）已被开发出来以减少良性活检。然而，这样的系统受到观察者之间差异的限制。最近，深度学习方法试图改善风险分层，但它们往往未能利用超声电影片段提供的丰富时空上下文，这些片段包含动态全局信息和从各种视角观察到的周围结构变化。在这项工作中，我们提出了Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification（STACT-Time）模型，这是一种新颖的表示学习框架，它将来自超声电影片段的成像特征与由预训练模型自动生成的分割掩码特征相结合。通过利用自注意力和交叉注意力机制，我们的模型捕捉了超声电影片段的丰富时空上下文，并通过分割引导学习增强了特征表示。与最先进模型相比，我们的模型提高了恶性肿瘤的预测能力，实现了交叉验证精度为0.91（±0.02）和F1分数为0.89（±0.02）。通过减少良性结节的过度活检，同时保持对恶性肿瘤的高敏感性，我们的模型有望提高临床决策能力并改善患者预后。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Thyroid cancer is among the most common cancers in the United States. Thyroidnodules are frequently detected through ultrasound (US) imaging, and somerequire further evaluation via fine-needle aspiration (FNA) biopsy. Despite itseffectiveness, FNA often leads to unnecessary biopsies of benign nodules,causing patient discomfort and anxiety. To address this, the American Collegeof Radiology Thyroid Imaging Reporting and Data System (TI-RADS) has beendeveloped to reduce benign biopsies. However, such systems are limited byinterobserver variability. Recent deep learning approaches have sought toimprove risk stratification, but they often fail to utilize the rich temporaland spatial context provided by US cine clips, which contain dynamic globalinformation and surrounding structural changes across various views. In thiswork, we propose the Spatio-Temporal Cross Attention for Cine ThyroidUltrasound Time Series Classification (STACT-Time) model, a novelrepresentation learning framework that integrates imaging features from US cineclips with features from segmentation masks automatically generated by apretrained model. By leveraging self-attention and cross-attention mechanisms,our model captures the rich temporal and spatial context of US cine clips whileenhancing feature representation through segmentation-guided learning. Ourmodel improves malignancy prediction compared to state-of-the-art models,achieving a cross-validation precision of 0.91 (plus or minus 0.02) and an F1score of 0.89 (plus or minus 0.02). By reducing unnecessary biopsies of benignnodules while maintaining high sensitivity for malignancy detection, our modelhas the potential to enhance clinical decision-making and improve patientoutcomes.</description>
      <author>example@mail.com (Irsyad Adam, Tengyue Zhang, Shrayes Raman, Zhuyu Qiu, Brandon Taraku, Hexiang Feng, Sile Wang, Ashwath Radhachandran, Shreeram Athreya, Vedrana Ivezic, Peipei Ping, Corey Arnold, William Speier)</author>
      <guid isPermaLink="false">2506.18172v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking histopathology foundation models in a multi-center dataset for skin cancer subtyping</title>
      <link>http://arxiv.org/abs/2506.18668v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepeted for oral presentation at Medical Image Understanding and  Analysis (MIUA) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文研究了在大规模、领域内数据集上进行预训练的病理学基础模型（FM），以及如何通过这些模型提高下游任务中的迁移学习能力。论文提出了一个用于评估FM在多实例学习（MIL）分类框架中作为补丁级特征提取器的基准，并引入了一个新的度量指标，用于衡量模型对分布变化的鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;在计算病理学中，由于病理切片的尺寸巨大，需要使用多实例学习（MIL）框架进行自动化的全切片图像分析。目前，病理学基础模型（FM）的多样性突出了设计实际挑战来评估其有效性的必要性。&lt;h4&gt;目的&lt;/h4&gt;设计一个基准来评估病理学基础模型（FM）在多实例学习（MIL）分类框架中作为补丁级特征提取器的有效性，并定义一个新的度量指标来衡量模型的一致性。&lt;h4&gt;方法&lt;/h4&gt;使用AI4SkIN数据集，该数据集包含具有挑战性的皮肤纺锤细胞肿瘤亚型的多中心队列切片，提出了一种新的基准和度量指标。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，提取较少偏见的特征可以增强分类性能，特别是在基于相似性的MIL分类器中。&lt;h4&gt;结论&lt;/h4&gt;通过使用预训练的病理学基础模型和改进的特征提取方法，可以显著提高病理学图像分析的分类性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pretraining on large-scale, in-domain datasets grants histopathologyfoundation models (FM) the ability to learn task-agnostic data representations,enhancing transfer learning on downstream tasks. In computational pathology,automated whole slide image analysis requires multiple instance learning (MIL)frameworks due to the gigapixel scale of the slides. The diversity amonghistopathology FMs has highlighted the need to design real-world challenges forevaluating their effectiveness. To bridge this gap, our work presents a novelbenchmark for evaluating histopathology FMs as patch-level feature extractorswithin a MIL classification framework. For that purpose, we leverage theAI4SkIN dataset, a multi-center cohort encompassing slides with challengingcutaneous spindle cell neoplasm subtypes. We also define the Foundation Model -Silhouette Index (FM-SI), a novel metric to measure model consistency againstdistribution shifts. Our experimentation shows that extracting less biasedfeatures enhances classification performance, especially in similarity-basedMIL classifiers.</description>
      <author>example@mail.com (Pablo Meseguer, Rocío del Amor, Valery Naranjo)</author>
      <guid isPermaLink="false">2506.18668v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>CultureMERT: Continual Pre-Training for Cross-Cultural Music Representation Learning</title>
      <link>http://arxiv.org/abs/2506.17818v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages, 4 figures, accepted to the 26th International Society for  Music Information Retrieval conference (ISMIR 2025), to be held in Daejeon,  South Korea&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了 CultureMERT-95M，一个针对跨文化音乐表示学习与理解的多文化适应性基础模型，以及其在多种非西方音乐自动标签任务中的表现。&lt;h4&gt;背景&lt;/h4&gt;尽管音乐基础模型在音频表示学习方面取得了进展，但它们在多种音乐传统中的有效性仍然有限。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够增强跨文化音乐表示学习与理解的多文化适应性基础模型。&lt;h4&gt;方法&lt;/h4&gt;提出了一个两阶段的持续预训练策略，结合学习率重温和重新衰减，以实现即使在有限的计算资源下也能稳定适应。&lt;h4&gt;主要发现&lt;/h4&gt;在包含希腊、土耳其和印度音乐传统的650小时多文化数据集上训练，CultureMERT-95M在多种非西方音乐自动标签任务中平均提高了4.9%的ROC-AUC和AP，超过了之前的最先进水平，同时在以西方为中心的基准测试中遗忘最小。任务算术（将单一文化适应性模型在权重空间中合并的替代方法）在非西方自动标签任务上的表现与多文化训练的模型相当，在西方数据集上没有退化。跨文化评估显示，单一文化模型在不同音乐传统中的迁移效果不同，而多文化适应性模型实现了最佳的整体性能。&lt;h4&gt;结论&lt;/h4&gt;为了支持世界音乐表示学习的研究，本文公开发布了 CultureMERT-95M 和 CultureMERT-TA-95M，以促进更具文化意识的音乐基础模型的发展。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，音乐基础模型在音频表示学习方面取得了进展，但它们在多种音乐传统中的有效性仍然有限。我们介绍了 CultureMERT-95M，这是一个为增强跨文化音乐表示学习与理解而开发的多文化适应性基础模型。为了实现这一点，我们提出了一种两阶段的持续预训练策略，该策略结合了学习率重温和重新衰减，即使在有限的计算资源下也能实现稳定适应。在包含希腊、土耳其和印度音乐传统的650小时多文化数据集上训练，CultureMERT-95M在多种非西方音乐自动标签任务中平均提高了4.9%的ROC-AUC和AP，超过了之前的最先进水平，同时在以西方为中心的基准测试中遗忘最小。我们进一步研究了任务算术，这是一种将单一文化适应性模型在权重空间中合并的替代方法。任务算术在非西方自动标签任务上的表现与我们的多文化训练模型相当，在西方数据集上没有退化。跨文化评估显示，单一文化模型在不同音乐传统中的迁移效果不同，而多文化适应性模型实现了最佳的整体性能。为了支持世界音乐表示学习的研究，我们公开发布了 CultureMERT-95M 和 CultureMERT-TA-95M，以促进更具文化意识的音乐基础模型的发展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in music foundation models have improved audio representationlearning, yet their effectiveness across diverse musical traditions remainslimited. We introduce CultureMERT-95M, a multi-culturally adapted foundationmodel developed to enhance cross-cultural music representation learning andunderstanding. To achieve this, we propose a two-stage continual pre-trainingstrategy that integrates learning rate re-warming and re-decaying, enablingstable adaptation even with limited computational resources. Training on a650-hour multi-cultural data mix, comprising Greek, Turkish, and Indian musictraditions, results in an average improvement of 4.9% in ROC-AUC and AP acrossdiverse non-Western music auto-tagging tasks, surpassing priorstate-of-the-art, with minimal forgetting on Western-centric benchmarks. Wefurther investigate task arithmetic, an alternative approach to multi-culturaladaptation that merges single-culture adapted models in the weight space. Taskarithmetic performs on par with our multi-culturally trained model onnon-Western auto-tagging tasks and shows no regression on Western datasets.Cross-cultural evaluation reveals that single-culture models transfer withvarying effectiveness across musical traditions, whereas the multi-culturallyadapted model achieves the best overall performance. To support research onworld music representation learning, we publicly release CultureMERT-95M andCultureMERT-TA-95M, fostering the development of more culturally aware musicfoundation models.</description>
      <author>example@mail.com (Angelos-Nikolaos Kanatas, Charilaos Papaioannou, Alexandros Potamianos)</author>
      <guid isPermaLink="false">2506.17818v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Auto-Regressive Surface Cutting</title>
      <link>http://arxiv.org/abs/2506.18017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Tech. report. https://victorcheung12.github.io/seamgpt&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SeamGPT是一种自动回归模型，通过模拟专业工作流程生成切割线，用于表面切割任务，具有在UV参数化、纹理映射和网格分解中的应用。&lt;h4&gt;背景&lt;/h4&gt;表面切割是计算机图形学中的基本任务，但在UV参数化、纹理映射和网格分解中，现有方法常产生过于碎片化的图集，缺乏语义连贯性。&lt;h4&gt;目的&lt;/h4&gt;提出SeamGPT，旨在生成具有语义连贯性的切割线。&lt;h4&gt;方法&lt;/h4&gt;将表面切割作为下一个标记预测任务，对网格顶点和边上的点云进行采样，将它们编码为形状条件，并使用GPT风格的transformer按顺序预测带有量化3D坐标的切割线段。&lt;h4&gt;主要发现&lt;/h4&gt;SeamGPT在包含流形和非流形网格的UV展开基准测试中表现出色，包括艺术家创建和3D扫描的模型。此外，它通过提供干净的边界来增强现有的3D分割工具，以便进行部分分解。&lt;h4&gt;结论&lt;/h4&gt;SeamGPT模型在表面切割任务中表现出优异的性能，并提高了3D分割工具的效率。&lt;h4&gt;翻译&lt;/h4&gt;Surface cutting is a fundamental task in computer graphics, with applications in UV parameterization, texture mapping, and mesh decomposition. However, existing methods often produce technically valid but overly fragmented atlases that lack semantic coherence. We introduce SeamGPT, an auto-regressive model that generates cutting seams by mimicking professional workflows. Our key technical innovation lies in formulating surface cutting as a next token prediction task: sample point clouds on mesh vertices and edges, encode them as shape conditions, and employ a GPT-style transformer to sequentially predict seam segments with quantized 3D coordinates. Our approach achieves exceptional performance on UV unwrapping benchmarks containing both manifold and non-manifold meshes, including artist-created, and 3D-scanned models. In addition, it enhances existing 3D segmentation tools by providing clean boundaries for part decomposition.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Surface cutting is a fundamental task in computer graphics, with applicationsin UV parameterization, texture mapping, and mesh decomposition. However,existing methods often produce technically valid but overly fragmented atlasesthat lack semantic coherence. We introduce SeamGPT, an auto-regressive modelthat generates cutting seams by mimicking professional workflows. Our keytechnical innovation lies in formulating surface cutting as a next tokenprediction task: sample point clouds on mesh vertices and edges, encode them asshape conditions, and employ a GPT-style transformer to sequentially predictseam segments with quantized 3D coordinates. Our approach achieves exceptionalperformance on UV unwrapping benchmarks containing both manifold andnon-manifold meshes, including artist-created, and 3D-scanned models. Inaddition, it enhances existing 3D segmentation tools by providing cleanboundaries for part decomposition.</description>
      <author>example@mail.com (Yang Li, Victor Cheung, Xinhai Liu, Yuguang Chen, Zhongjin Luo, Biwen Lei, Haohan Weng, Zibo Zhao, Jingwei Huang, Zhuo Chen, Chunchao Guo)</author>
      <guid isPermaLink="false">2506.18017v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>When Fine-Tuning Fails: Lessons from MS MARCO Passage Ranking</title>
      <link>http://arxiv.org/abs/2506.18535v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了微调预训练的Transformer模型在MS MARCO乘客排名任务上反而降低性能的悖论现象。&lt;h4&gt;背景&lt;/h4&gt;微调预训练模型通常可以提高特定任务的表现，但本文发现这一现象并不适用于MS MARCO乘客排名任务。&lt;h4&gt;目的&lt;/h4&gt;通过实验分析微调预训练模型在MS MARCO任务上的表现，并探讨可能的原因。&lt;h4&gt;方法&lt;/h4&gt;作者进行了全面实验，包括五种模型变体，包括全参数微调和参数高效的LoRA调整。&lt;h4&gt;主要发现&lt;/h4&gt;所有微调方法的表现均不如基线模型（MRR@10: 0.3026）。分析表明，微调破坏了基线模型在大量句子对（包括910万MS MARCO样本）上学习到的最佳嵌入空间结构。UMAP可视化显示嵌入空间逐渐变平，训练动态分析和计算效率指标进一步支持这一发现。&lt;h4&gt;结论&lt;/h4&gt;这些结果挑战了关于在饱和基准上迁移学习有效性的传统观点，并暗示可能需要架构创新来实现有意义的改进。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了在微调预训练的Transformer模型时，其在MS MARCO乘客排名任务上反而降低性能的反直觉现象。通过涉及五种模型变体（包括全参数微调和参数高效的LoRA调整）的全面实验，我们证明所有微调方法的表现均不及基线模型sentence-transformers/all- MiniLM-L6-v2（MRR@10: 0.3026）。我们的分析揭示，微调破坏了基线模型在10亿句子对（包括910万MS MARCO样本）的广泛预训练期间学习的最佳嵌入空间结构。UMAP可视化显示了嵌入空间的渐进扁平化，而训练动态分析和计算效率指标进一步支持了我们的发现。这些结果挑战了关于在饱和基准上迁移学习有效性的传统观点，并暗示可能需要架构创新来实现有意义的改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper investigates the counterintuitive phenomenon where fine-tuningpre-trained transformer models degrades performance on the MS MARCO passageranking task. Through comprehensive experiments involving five modelvariants-including full parameter fine-tuning and parameter efficient LoRAadaptations-we demonstrate that all fine-tuning approaches underperform thebase sentence-transformers/all- MiniLM-L6-v2 model (MRR@10: 0.3026). Ouranalysis reveals that fine-tuning disrupts the optimal embedding spacestructure learned during the base model's extensive pre-training on 1 billionsentence pairs, including 9.1 million MS MARCO samples. UMAP visualizationsshow progressive embedding space flattening, while training dynamics analysisand computational efficiency metrics further support our findings. Theseresults challenge conventional wisdom about transfer learning effectiveness onsaturated benchmarks and suggest architectural innovations may be necessary formeaningful improvements.</description>
      <author>example@mail.com (Manu Pande, Shahil Kumar, Anay Yatin Damle)</author>
      <guid isPermaLink="false">2506.18535v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Federated Learning from Molecules to Processes: A Perspective</title>
      <link>http://arxiv.org/abs/2506.18525v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了化学工程中联邦学习的视角，旨在化学工业中推动机器学习（ML）的发展。联邦学习允许组织在保护各自数据隐私的情况下共同训练机器学习模型。&lt;h4&gt;背景&lt;/h4&gt;化学公司拥有大量的化学和工艺数据，这些数据通常属于私有，形成了数据孤岛，阻碍了在化学工程中用大量数据进行机器学习模型的训练。&lt;h4&gt;目的&lt;/h4&gt;提出联邦学习在化学工程中的应用潜力，以及如何通过联邦学习提高机器学习模型的准确性，同时保护企业的数据隐私。&lt;h4&gt;方法&lt;/h4&gt;讨论了联邦学习在化学工程不同领域的潜在应用，并应用联邦学习进行了两个案例研究：使用图神经网络预测二元混合活度系数和使用自动编码器进行蒸馏塔的系统识别。&lt;h4&gt;主要发现&lt;/h4&gt;研究表明，使用联邦学习共同训练的机器学习模型比单个化学公司训练的模型具有更高的准确性，并且可以与使用所有公司合并数据集训练的模型相媲美。&lt;h4&gt;结论&lt;/h4&gt;联邦学习在化学工程中具有巨大潜力，可以提升机器学习模型的同时尊重企业数据隐私，对未来的工业应用具有广阔的前景。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种关于化学工程中联邦学习的视角，展望了在化学工业中机器学习（ML）发展的协作努力。大量的化学和工艺数据属于化学公司所有，因此被锁定在数据孤岛中，阻碍了在化学工程中用大量数据进行机器学习模型的训练。最近，联邦学习的概念在机器学习研究中受到了越来越多的关注，它使组织能够在不披露各自数据的情况下共同训练机器学习模型。我们讨论了联邦学习在化学工程几个领域的潜在应用，从分子尺度到工艺尺度。此外，我们应用联邦学习进行了两个示例案例研究，模拟了多个化学公司持有私有数据集的实际场景：（i）使用图神经网络预测二元混合活度系数；（ii）使用自动编码器进行蒸馏塔的系统识别。我们的结果表明，使用联邦学习共同训练的机器学习模型比单个化学公司单独训练的模型具有更高的准确性，并且可以与使用所有公司合并数据集训练的模型相媲美。因此，联邦学习在尊重企业数据隐私的同时，具有推进化学工程中机器学习模型的巨大潜力，对未来的工业应用具有广阔的前景。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present a perspective on federated learning in chemical engineering thatenvisions collaborative efforts in machine learning (ML) developments withinthe chemical industry. Large amounts of chemical and process data areproprietary to chemical companies and are therefore locked in data silos,hindering the training of ML models on large data sets in chemical engineering.Recently, the concept of federated learning has gained increasing attention inML research, enabling organizations to jointly train machine learning modelswithout disclosure of their individual data. We discuss potential applicationsof federated learning in several fields of chemical engineering, from themolecular to the process scale. In addition, we apply federated learning in twoexemplary case studies that simulate practical scenarios of multiple chemicalcompanies holding proprietary data sets: (i) prediction of binary mixtureactivity coefficients with graph neural networks and (ii) system identificationof a distillation column with autoencoders. Our results indicate that ML modelsjointly trained with federated learning yield significantly higher accuracythan models trained by each chemical company individually and can performsimilarly to models trained on combined datasets from all companies. Federatedlearning has therefore great potential to advance ML models in chemicalengineering while respecting corporate data privacy, making it promising forfuture industrial applications.</description>
      <author>example@mail.com (Jan G. Rittig, Clemens Kortmann)</author>
      <guid isPermaLink="false">2506.18525v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models</title>
      <link>http://arxiv.org/abs/2506.18385v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了InternSpatial，这是目前最大的开源空间推理数据集，以及对应的评估基准InternSpatial-Bench，用于评估在多种指令格式下的空间理解能力。&lt;h4&gt;背景&lt;/h4&gt;现有的空间推理开放资源在规模、视觉多样性和指令表达性方面仍然有限。&lt;h4&gt;目的&lt;/h4&gt;提出InternSpatial数据集和InternSpatial-Bench评估基准，以促进视觉语言模型（VLMs）中空间推理能力的提升。&lt;h4&gt;方法&lt;/h4&gt;InternSpatial包含1200万个问答对，覆盖单视图和多视图设置，来自不同的视觉环境，并支持19种指令格式，反映不同的查询风格。InternSpatial-Bench包括单视图任务和引入的新旋转角度预测任务。&lt;h4&gt;主要发现&lt;/h4&gt;在InternSpatial-Bench和VSI-Bench上，基于InternSpatial训练的模型在保持通用基准上良好性能的同时，分别提升了12.1%和10.7%。&lt;h4&gt;结论&lt;/h4&gt;这些资源将支持具有空间能力的VLMs在机器人学和具身人工智能等实际应用中的发展。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces InternSpatial, the largest open-source dataset for spatial reasoning in VLMs, along with InternSpatial-Bench, a corresponding evaluation benchmark designed to assess spatial understanding under diverse instruction formats.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent benchmarks and datasets have been proposed to improve spatialreasoning in vision-language models (VLMs), yet existing open resources remainlimited in scale, visual diversity, and instruction expressiveness. In thiswork, we introduce InternSpatial, the largest open-source dataset for spatialreasoning in VLMs, along with InternSpatial-Bench, a corresponding evaluationbenchmark designed to assess spatial understanding under diverse instructionformats. InternSpatial comprises 12 million QA pairs spanning both single-viewand multi-view settings, drawn from diverse visual environments and supporting19 instruction formats that reflect varied query styles. For evaluation, wepropose InternSpatial-Bench for single-view tasks and expand multi-viewreasoning by introducing a novel rotation angle prediction task that has notbeen explored in prior work. Experimental results show that models trained onInternSpatial achieve 12.1% improvement on InternSpatial-Bench and 10.7% onVSI-Bench, while maintaining strong performance on general-purpose benchmarks.We hope these resources will support the development of spatially capable VLMsin practical applications such as robotics and embodied AI.</description>
      <author>example@mail.com (Nianchen Deng, Lixin Gu, Shenglong Ye, Yinan He, Zhe Chen, Songze Li, Haomin Wang, Xingguang Wei, Tianshuo Yang, Min Dou, Tong He, Wenqi Shao, Kaipeng Zhang, Yi Wang, Botian Shi, Yanting Zhang, Jifeng Dai, Yu Qiao, Hongjie Zhang, Wenhai Wang)</author>
      <guid isPermaLink="false">2506.18385v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>ADA-DPM: A Neural Descriptors-based Adaptive Noise Point Filtering Strategy for SLAM</title>
      <link>http://arxiv.org/abs/2506.18016v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种自适应噪声滤波SLAM策略-ADA-DPM，在动态物体干扰、点云噪声和无结构环境中，实现了定位精度和系统鲁棒性之间的良好平衡。&lt;h4&gt;背景&lt;/h4&gt;LiDAR SLAM在移动机器人导航和高精度地图构建等领域展现出显著的应用价值。然而，现有方法在处理动态物体干扰、点云噪声和无结构环境时，往往需要在定位精度和系统鲁棒性之间做出权衡。&lt;h4&gt;目的&lt;/h4&gt;提出一种自适应噪声滤波SLAM策略，以解决动态物体干扰、点云噪声和无结构环境带来的挑战。&lt;h4&gt;方法&lt;/h4&gt;设计了动态分段头部来预测动态点特征点的类别，消除动态特征点；设计了全局重要性评分头部，自适应选择贡献度和特征更高的特征点，同时抑制噪声干扰；构建了跨层图内卷积模块（GLI-GCN），融合多尺度邻域结构，从而增强重叠特征的判别能力。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个公开数据集上进行了测试，并取得了优异的结果。&lt;h4&gt;结论&lt;/h4&gt;提出的ADA-DPM策略在定位精度和系统鲁棒性方面均表现出色，有效解决了动态物体干扰、点云噪声和无结构环境带来的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR SLAM has demonstrated significant application value in various fields,including mobile robot navigation and high-precision map construction. However,existing methods often need to make a trade-off between positioning accuracyand system robustness when faced with dynamic object interference, point cloudnoise, and unstructured environments. To address this challenge, we propose anadaptive noise filtering SLAM strategy-ADA-DPM, achieving excellent preferencein both aspects. We design the Dynamic Segmentation Head to predict thecategory of feature points belonging to dynamic points, to eliminate dynamicfeature points; design the Global Importance Scoring Head to adaptively selectfeature points with higher contribution and features while suppressing noiseinterference; and construct the Cross Layer Intra-Graph Convolution Module(GLI-GCN) to fuse multi-scale neighborhood structures, thereby enhancing thediscriminative ability of overlapping features. Finally, to further validatethe effectiveness of our method, we tested it on several publicly availabledatasets and achieved outstanding results.</description>
      <author>example@mail.com (Yongxin Shao, Binrui Wang, Aihong Tan)</author>
      <guid isPermaLink="false">2506.18016v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Your Token Becomes Worthless: Unveiling Rug Pull Schemes in Crypto Token via Code-and-Transaction Fusion Analysis</title>
      <link>http://arxiv.org/abs/2506.18398v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了RPhunter技术，用于检测Rug pull诈骗，通过结合代码和交易信息，提高检测效果。&lt;h4&gt;背景&lt;/h4&gt;Rug pull诈骗是加密货币领域的持续威胁，给投资者带来重大经济损失。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的技术，有效地检测Rug pull诈骗。&lt;h4&gt;方法&lt;/h4&gt;RPhunter通过以下步骤实现检测：建立声明性规则和执行流分析以提取代码风险信息，构建语义风险代码图；将动态代币交易活动表示为代币流行为图；利用图神经网络从语义风险代码图和代币流行为图中提取互补特征，并通过注意力融合模型整合这些特征。&lt;h4&gt;主要发现&lt;/h4&gt;RPhunter在构建的地面数据集上实现了95.3%的精确度、93.8%的召回率和94.5%的F1分数，并且在实际场景中识别了4801个Rug pull代币，精确度为91%。&lt;h4&gt;结论&lt;/h4&gt;RPhunter在检测Rug pull诈骗方面表现优于现有方法，具有较高的准确性和召回率。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Rug pull scams have emerged as a persistent threat to cryptocurrency, causing significant financial losses. A typical scenario involves scammers deploying honeypot contracts to attract investments, restricting token sales, and draining the funds, which leaves investors with worthless tokens. Current methods either rely on predefined patterns to detect code risks or utilize statistical transaction data to train detection models. However, real-world Rug Pull schemes often involve a complex interplay between malicious code and suspicious transaction behaviors. These methods, which solely focus on one aspect, fall short in detecting such schemes effectively. In this paper, we propose RPhunter, a novel technique that integrates code and transaction for Rug Pull detection. First, RPhunter establishes declarative rules and performs flow analysis to extract code risk information, further constructing a semantic risk code graph (SRCG). Meanwhile, to leverage transaction information, RPhunter formulates dynamic token transaction activities as a token flow behavior graph (TFBG) in which nodes and edges are characterized from network structure and market manipulation perspectives. Finally, RPhunter employs graph neural networks to extract complementary features from SRCG and TFBG, integrating them through an attention fusion model to enhance the detection of Rug Pull. We manually analyzed 645 Rug Pull incidents from code and transaction aspects and constructed a ground-truth dataset. We evaluated RPhunter on our dataset, achieving a precision of 95.3%, a recall of 93.8% and an F1 score of 94.5%, which highlights superior performance compared to existing state-of-the-art methods. Furthermore, when applied to the real-world scenarios, RPhunter has identified 4801 Rug Pull tokens, achieving a precision of 91%.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Rug pull scams have emerged as a persistent threat to cryptocurrency, causingsignificant financial losses. A typical scenario involves scammers deployinghoneypot contracts to attract investments, restricting token sales, anddraining the funds, which leaves investors with worthless tokens. Currentmethods either rely on predefined patterns to detect code risks or utilizestatistical transaction data to train detection models. However, real-world RugPull schemes often involve a complex interplay between malicious code andsuspicious transaction behaviors. These methods, which solely focus on oneaspect, fall short in detecting such schemes effectively.  In this paper, we propose RPhunter, a novel technique that integrates codeand transaction for Rug Pull detection. First, RPhunter establishes declarativerules and performs flow analysis to extract code risk information, furtherconstructing a semantic risk code graph (SRCG). Meanwhile, to leveragetransaction information, RPhunter formulates dynamic token transactionactivities as a token flow behavior graph (TFBG) in which nodes and edges arecharacterized from network structure and market manipulation perspectives.Finally, RPhunter employs graph neural networks to extract complementaryfeatures from SRCG and TFBG, integrating them through an attention fusion modelto enhance the detection of Rug Pull. We manually analyzed 645 Rug Pullincidents from code and transaction aspects and constructed a ground-truthdataset. We evaluated RPhunter on our dataset, achieving a precision of 95.3%,a recall of 93.8% and an F1 score of 94.5%, which highlights superiorperformance compared to existing state-of-the-art methods. Furthermore, whenapplied to the real-world scenarios, RPhunter has identified 4801 Rug Pulltokens, achieving a precision of 91%.</description>
      <author>example@mail.com (Hao Wu, Haijun Wang, Shangwang Li, Yin Wu, Ming Fan, Wuxia Jin, Yitao Zhao, Ting Liu)</author>
      <guid isPermaLink="false">2506.18398v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TEM^3-Learning: Time-Efficient Multimodal Multi-Task Learning for Advanced Assistive Driving</title>
      <link>http://arxiv.org/abs/2506.18084v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为TEM^3-Learning的新型多任务学习框架，旨在通过共享表示探索任务间的相关性，以促进辅助驾驶的发展。&lt;h4&gt;背景&lt;/h4&gt;现有的多任务学习方法面临两个关键限制：单模态约束限制了全面场景理解，以及低效的架构阻碍了实时部署。&lt;h4&gt;目的&lt;/h4&gt;提出TEM^3-Learning框架，通过两阶段架构联合优化驾驶员情绪识别、驾驶员行为识别、交通场景识别和车辆行为识别。&lt;h4&gt;方法&lt;/h4&gt;该框架包括两个主要组件：mamba基于的多视角时空特征提取子网络（MTS-Mamba）和基于多任务学习的门控多模态特征集成器（MGMI）。MTS-Mamba引入了前向-后向时间扫描机制和全局-局部空间注意力，以高效地从多视角序列图像中提取低成本时空特征。MGMI使用特定于任务的门控模块自适应地突出每个任务中最相关的模态特征，有效缓解了多任务学习中的负迁移问题。&lt;h4&gt;主要发现&lt;/h4&gt;在AIDE数据集上的评估表明，所提出的模型在所有四个任务上都实现了最先进的准确率，同时保持了轻量级的架构，参数少于600万，推理速度达到142.32 FPS。&lt;h4&gt;结论&lt;/h4&gt;TEM^3-Learning框架有效，且每个模块都有独立的贡献，代码已开源。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多任务学习（MTL）可以通过共享表示来探索任务间的相关性，从而推进辅助驾驶。然而，现有的方法面临两个关键限制：单模态约束限制了全面场景理解，以及低效的架构阻碍了实时部署。本文提出了一种名为TEM^3-Learning（时间高效的多模态多任务学习）的新颖框架，通过两阶段架构联合优化驾驶员情绪识别、驾驶员行为识别、交通场景识别和车辆行为识别。第一个组件是基于mamba的多视角时空特征提取子网络（MTS-Mamba），它引入了前向-后向时间扫描机制和全局-局部空间注意力，以高效地从多视角序列图像中提取低成本时空特征。第二个组件是基于多任务学习的门控多模态特征集成器（MGMI），它使用特定于任务的门控模块来自适应地突出每个任务中最相关的模态特征，有效缓解了多任务学习中的负迁移问题。在AIDE数据集上的评估表明，所提出的模型在所有四个任务上都实现了最先进的准确率，同时保持了轻量级的架构，参数少于600万，推理速度达到142.32 FPS。严格的消融研究进一步验证了所提出框架的有效性以及每个模块的独立贡献。代码可在https://github.com/Wenzhuo-Liu/TEM3-Learning上获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-task learning (MTL) can advance assistive driving by exploringinter-task correlations through shared representations. However, existingmethods face two critical limitations: single-modality constraints limitingcomprehensive scene understanding and inefficient architectures impedingreal-time deployment. This paper proposes TEM^3-Learning (Time-EfficientMultimodal Multi-task Learning), a novel framework that jointly optimizesdriver emotion recognition, driver behavior recognition, traffic contextrecognition, and vehicle behavior recognition through a two-stage architecture.The first component, the mamba-based multi-view temporal-spatial featureextraction subnetwork (MTS-Mamba), introduces a forward-backward temporalscanning mechanism and global-local spatial attention to efficiently extractlow-cost temporal-spatial features from multi-view sequential images. Thesecond component, the MTL-based gated multimodal feature integrator (MGMI),employs task-specific multi-gating modules to adaptively highlight the mostrelevant modality features for each task, effectively alleviating the negativetransfer problem in MTL. Evaluation on the AIDE dataset, our proposed modelachieves state-of-the-art accuracy across all four tasks, maintaining alightweight architecture with fewer than 6 million parameters and delivering animpressive 142.32 FPS inference speed. Rigorous ablation studies furthervalidate the effectiveness of the proposed framework and the independentcontributions of each module. The code is available onhttps://github.com/Wenzhuo-Liu/TEM3-Learning.</description>
      <author>example@mail.com (Wenzhuo Liu, Yicheng Qiao, Zhen Wang, Qiannan Guo, Zilong Chen, Meihua Zhou, Xinran Li, Letian Wang, Zhiwei Li, Huaping Liu, Wenshuo Wang)</author>
      <guid isPermaLink="false">2506.18084v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent</title>
      <link>http://arxiv.org/abs/2506.18559v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为T-CPDL（时间因果概率描述逻辑）的框架，用于增强语言模型在处理时间、因果关系和概率推理方面的能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型擅长生成流畅文本，但在涉及时间约束、因果关系和概率推理的结构化推理方面存在困难。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，提出了T-CPDL框架。&lt;h4&gt;方法&lt;/h4&gt;T-CPDL通过扩展传统的描述逻辑，结合时间区间操作符、显式因果关系和概率注释，提供了两种不同的变体：一种使用Allen区间代数来捕获定性时间关系，另一种增强了显式时间戳因果断言。&lt;h4&gt;主要发现&lt;/h4&gt;实证评估表明，T-CPDL在时间推理和因果推断基准上显著提高了推理精度、可解释性和置信度校准。&lt;h4&gt;结论&lt;/h4&gt;T-CPDL通过提供透明的推理路径和精细的时间因果语义，显著增强了语言模型支持稳健、可解释和值得信赖的决策的能力，并为开发高级逻辑检索增强生成（Logic-RAG）框架奠定了基础。&lt;h4&gt;翻译&lt;/h4&gt;The paper proposes a framework named T-CPDL (Temporal Causal Probabilistic Description Logic) to enhance the capabilities of large language models in dealing with temporal, causal, and probabilistic reasoning.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large language models excel at generating fluent text but frequently strugglewith structured reasoning involving temporal constraints, causal relationships,and probabilistic reasoning. To address these limitations, we propose TemporalCausal Probabilistic Description Logic (T-CPDL), an integrated framework thatextends traditional Description Logic with temporal interval operators,explicit causal relationships, and probabilistic annotations. We present twodistinct variants of T-CPDL: one capturing qualitative temporal relationshipsthrough Allen's interval algebra, and another variant enriched with explicittimestamped causal assertions. Both variants share a unified logical structure,enabling complex reasoning tasks ranging from simple temporal ordering tonuanced probabilistic causation. Empirical evaluations on temporal reasoningand causal inference benchmarks confirm that T-CPDL substantially improvesinference accuracy, interpretability, and confidence calibration of languagemodel outputs. By delivering transparent reasoning paths and fine-grainedtemporal and causal semantics, T-CPDL significantly enhances the capability oflanguage models to support robust, explainable, and trustworthydecision-making. This work also lays the groundwork for developing advancedLogic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentiallyboosting the reasoning capabilities and efficiency of knowledge graph-enhancedRAG systems.</description>
      <author>example@mail.com (Hong Qing Yu)</author>
      <guid isPermaLink="false">2506.18559v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Beyond instruction-conditioning, MoTE: Mixture of Task Experts for Multi-task Embedding Models</title>
      <link>http://arxiv.org/abs/2506.17781v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了密集嵌入在现代机器学习系统中的应用，特别是在检索增强生成（RAG）、信息检索和表征学习等领域。提出了Mixture of Task Experts（MoTE）模型，通过任务感知对比学习（tacl）提高模型生成专门嵌入的能力。&lt;h4&gt;背景&lt;/h4&gt;密集嵌入对于现代机器学习系统至关重要，但传统的指令条件化方法在低容量模型中的应用受到表示限制，影响了性能提升。&lt;h4&gt;目的&lt;/h4&gt;分析传统方法的限制并提出新的模型以增强生成专门嵌入的能力。&lt;h4&gt;方法&lt;/h4&gt;引入了MoTE变压器块，它使用tacl训练任务专门的参数。&lt;h4&gt;主要发现&lt;/h4&gt;MoTE在检索数据集上实现了64%的性能提升（从+3.27提升到+5.21），在所有数据集上实现了43%的性能提升（从+1.81提升到+2.60）。这些提升是在不改变指令、训练数据、推理时间或激活参数数量的情况下实现的。&lt;h4&gt;结论&lt;/h4&gt;MoTE模型通过tacl训练任务专门参数，有效提升了模型生成专门嵌入的能力，同时保持了模型的效率和可扩展性。&lt;h4&gt;翻译&lt;/h4&gt;Dense embeddings are fundamental to modern machine learning systems, powering Retrieval-Augmented Generation (RAG), information retrieval, and representation learning. While instruction-conditioning has become the dominant approach for embedding specialization, its direct application to low-capacity models imposes fundamental representational constraints that limit the performance gains derived from specialization. In this paper, we analyze these limitations and introduce the Mixture of Task Experts (MoTE) transformer block, which leverages task-specialized parameters trained with Task-Aware Contrastive Learning (acl) to enhance the model ability to generate specialized embeddings. Empirical results show that MoTE achieves 64% higher performance gains in retrieval datasets (+3.27 → +5.21) and 43% higher performance gains across all datasets (+1.81 → +2.60). Critically, these gains are achieved without altering instructions, training data, inference time, or number of active parameters.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dense embeddings are fundamental to modern machine learning systems, poweringRetrieval-Augmented Generation (RAG), information retrieval, and representationlearning. While instruction-conditioning has become the dominant approach forembedding specialization, its direct application to low-capacity models imposesfundamental representational constraints that limit the performance gainsderived from specialization. In this paper, we analyze these limitations andintroduce the Mixture of Task Experts (MoTE) transformer block, which leveragestask-specialized parameters trained with Task-Aware Contrastive Learning(\tacl) to enhance the model ability to generate specialized embeddings.Empirical results show that MoTE achieves $64\%$ higher performance gains inretrieval datasets ($+3.27 \rightarrow +5.21$) and $43\%$ higher performancegains across all datasets ($+1.81 \rightarrow +2.60$). Critically, these gainsare achieved without altering instructions, training data, inference time, ornumber of active parameters.</description>
      <author>example@mail.com (Miguel Romero, Shuoyang Ding, Corey D. Barret, Georgiana Dinu, George Karypis)</author>
      <guid isPermaLink="false">2506.17781v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation</title>
      <link>http://arxiv.org/abs/2506.18678v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于神经隐式场景表示的分布式多智能体协同SLAM框架，旨在解决现有SLAM算法在大型场景和长序列中的局限性，并提高通信带宽的约束。&lt;h4&gt;背景&lt;/h4&gt;现有的隐式SLAM算法主要适用于单智能体场景，在大型场景和长序列中存在困难，并且基于NeRF的多智能体SLAM框架无法满足通信带宽的约束。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的分布式多智能体协同SLAM框架，以解决上述问题。&lt;h4&gt;方法&lt;/h4&gt;提出了混合场景表示方法、分布式相机跟踪、跨图闭环和在线蒸馏技术，以实现多子图融合。设计了新的三平面网格联合场景表示方法和跨图闭环方法，以及新的在线蒸馏方法，以实现局部和全局一致性。此外，提出了第一个用于NeRF/GS SLAM的真实世界数据集DES，该数据集包括单智能体和多智能体场景，从小型房间到大型户外场景，并提供了高精度的3D网格和连续时间相机轨迹的真实值。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在地图构建、跟踪和通信方面均表现出优越性，数据集和代码将在GitHub上开源。&lt;h4&gt;结论&lt;/h4&gt;本文提出的分布式多智能体协同SLAM框架在解决现有SLAM算法的局限性方面取得了显著成效，并为SLAM、3D重建和视觉基础模型的研究提供了新的方向。&lt;h4&gt;翻译&lt;/h4&gt;Neural implicit scene representations have recently shown promising results in dense visual SLAM. However, existing implicit SLAM algorithms are constrained to single-agent scenarios, and fall difficulties in large-scale scenes and long sequences. Existing NeRF-based multi-agent SLAM frameworks cannot meet the constraints of communication bandwidth. To this end, we propose the first distributed multi-agent collaborative neural SLAM framework with hybrid scene representation, distributed camera tracking, intra-to-inter loop closure, and online distillation for multiple submap fusion. A novel triplane-grid joint scene representation method is proposed to improve scene reconstruction. A novel intra-to-inter loop closure method is designed to achieve local (single-agent) and global (multi-agent) consistency. We also design a novel online distillation method to fuse the information of different submaps to achieve global consistency. Furthermore, to the best of our knowledge, there is no real-world dataset for NeRF-based/GS-based SLAM that provides both continuous-time trajectories groundtruth and high-accuracy 3D meshes groundtruth. To this end, we propose the first real-world Dense slam (DES) dataset covering both single-agent and multi-agent scenarios, ranging from small rooms to large-scale outdoor scenes, with high-accuracy ground truth for both 3D mesh and continuous-time camera trajectory. This dataset can advance the development of the research in both SLAM, 3D reconstruction, and visual foundation model. Experiments on various datasets demonstrate the superiority of the proposed method in both mapping, tracking, and communication. The dataset and code will open-source on https://github.com/dtc111111/mcnslam.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Neural implicit scene representations have recently shown promising resultsin dense visual SLAM. However, existing implicit SLAM algorithms areconstrained to single-agent scenarios, and fall difficulties in large-scalescenes and long sequences. Existing NeRF-based multi-agent SLAM frameworkscannot meet the constraints of communication bandwidth. To this end, we proposethe first distributed multi-agent collaborative neural SLAM framework withhybrid scene representation, distributed camera tracking, intra-to-inter loopclosure, and online distillation for multiple submap fusion. A noveltriplane-grid joint scene representation method is proposed to improve scenereconstruction. A novel intra-to-inter loop closure method is designed toachieve local (single-agent) and global (multi-agent) consistency. We alsodesign a novel online distillation method to fuse the information of differentsubmaps to achieve global consistency. Furthermore, to the best of ourknowledge, there is no real-world dataset for NeRF-based/GS-based SLAM thatprovides both continuous-time trajectories groundtruth and high-accuracy 3Dmeshes groundtruth. To this end, we propose the first real-world Dense slam(DES) dataset covering both single-agent and multi-agent scenarios, rangingfrom small rooms to large-scale outdoor scenes, with high-accuracy ground truthfor both 3D mesh and continuous-time camera trajectory. This dataset canadvance the development of the research in both SLAM, 3D reconstruction, andvisual foundation model. Experiments on various datasets demonstrate thesuperiority of the proposed method in both mapping, tracking, andcommunication. The dataset and code will open-source onhttps://github.com/dtc111111/mcnslam.</description>
      <author>example@mail.com (Tianchen Deng, Guole Shen, Xun Chen, Shenghai Yuan, Hongming Shen, Guohao Peng, Zhenyu Wu, Jingchuan Wang, Lihua Xie, Danwei Wang, Hesheng Wang, Weidong Chen)</author>
      <guid isPermaLink="false">2506.18678v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>EgoWorld: Translating Exocentric View to Egocentric View using Rich Exocentric Observations</title>
      <link>http://arxiv.org/abs/2506.17896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project Page: https://redorangeyellowy.github.io/EgoWorld/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为EgoWorld的新框架，用于将第三人称视角转换为第一人称视角，以增强现实、虚拟现实和机器人应用中的手-物体交互理解。&lt;h4&gt;背景&lt;/h4&gt;自旋心视觉对于人类和机器视觉理解至关重要，尤其是在捕捉操作任务中详细的手-物体交互方面。将第三人称视图转换为第一人称视图对增强现实（AR）、虚拟现实（VR）和机器人应用有显著益处。&lt;h4&gt;目的&lt;/h4&gt;克服现有外心到自心转换方法依赖2D线索、同步多视图设置和不切实际的假设（如初始自心帧和推理期间相对相机姿态的必要性）的局限性。&lt;h4&gt;方法&lt;/h4&gt;EgoWorld是一个两阶段框架，可以从丰富的外心观察中重建自心视图，包括投影点云、3D手姿态和文本描述。该方法从估计的外心深度图中重建点云，将其重新投影到自心视角，然后应用基于扩散的修复技术生成密集、语义上连贯的自心图像。&lt;h4&gt;主要发现&lt;/h4&gt;在H2O和TACO数据集上评估时，EgoWorld实现了最先进的性能，并展示了对新物体、动作、场景和主题的鲁棒泛化能力。此外，EgoWorld在无标签的真实世界示例上也表现出有希望的结果。&lt;h4&gt;结论&lt;/h4&gt;EgoWorld是一个有效的框架，可以显著提升自旋心视觉在增强现实、虚拟现实和机器人应用中的性能，尤其是在处理新的和真实世界场景时。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Egocentric vision is essential for both human and machine visualunderstanding, particularly in capturing the detailed hand-object interactionsneeded for manipulation tasks. Translating third-person views into first-personviews significantly benefits augmented reality (AR), virtual reality (VR) androbotics applications. However, current exocentric-to-egocentric translationmethods are limited by their dependence on 2D cues, synchronized multi-viewsettings, and unrealistic assumptions such as necessity of initial egocentricframe and relative camera poses during inference. To overcome these challenges,we introduce EgoWorld, a novel two-stage framework that reconstructs anegocentric view from rich exocentric observations, including projected pointclouds, 3D hand poses, and textual descriptions. Our approach reconstructs apoint cloud from estimated exocentric depth maps, reprojects it into theegocentric perspective, and then applies diffusion-based inpainting to producedense, semantically coherent egocentric images. Evaluated on the H2O and TACOdatasets, EgoWorld achieves state-of-the-art performance and demonstratesrobust generalization to new objects, actions, scenes, and subjects. Moreover,EgoWorld shows promising results even on unlabeled real-world examples.</description>
      <author>example@mail.com (Junho Park, Andrew Sangwoo Ye, Taein Kwon)</author>
      <guid isPermaLink="false">2506.17896v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Feedback Driven Multi Stereo Vision System for Real-Time Event Analysis</title>
      <link>http://arxiv.org/abs/2506.17910v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于3D立体视觉的交互系统处理流程，通过鲁棒的场景理解，能够处理普通和敏感的应用。&lt;h4&gt;背景&lt;/h4&gt;2D相机在交互系统中常用，但3D相机在复杂环境中不够可靠。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够处理多种应用场景的3D立体视觉处理流程。&lt;h4&gt;方法&lt;/h4&gt;融合多个3D相机进行场景重建，并通过可能的反馈方法接收环境中的数据，以改善决策或适应新环境。&lt;h4&gt;主要发现&lt;/h4&gt;系统可以执行事件识别、主体跟踪和通知等多种任务。&lt;h4&gt;结论&lt;/h4&gt;本文介绍了该流程，并初步实验了结果，同时规划了将流程投入生产的下一步步骤。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种基于3D立体视觉的交互系统处理流程，通过鲁棒的场景理解，能够处理普通和敏感的应用。背景是2D相机在交互系统中常用，但3D相机在复杂环境中不够可靠。目的是提出一种能够处理多种应用场景的3D立体视觉处理流程。方法是通过融合多个3D相机进行场景重建，并通过可能的反馈方法接收环境中的数据，以改善决策或适应新环境。主要发现是系统可以执行事件识别、主体跟踪和通知等多种任务。结论是本文介绍了该流程，并初步实验了结果，同时规划了将流程投入生产的下一步步骤。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3573381.3597220&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 2D cameras are often used in interactive systems. Other systems like gamingconsoles provide more powerful 3D cameras for short range depth sensing.Overall, these cameras are not reliable in large, complex environments. In thiswork, we propose a 3D stereo vision based pipeline for interactive systems,that is able to handle both ordinary and sensitive applications, through robustscene understanding. We explore the fusion of multiple 3D cameras to do fullscene reconstruction, which allows for preforming a wide range of tasks, likeevent recognition, subject tracking, and notification. Using possible feedbackapproaches, the system can receive data from the subjects present in theenvironment, to learn to make better decisions, or to adapt to completely newenvironments. Throughout the paper, we introduce the pipeline and explain ourpreliminary experimentation and results. Finally, we draw the roadmap for thenext steps that need to be taken, in order to get this pipeline into production</description>
      <author>example@mail.com (Mohamed Benkedadra, Matei Mancas, Sidi Ahmed Mahmoudi)</author>
      <guid isPermaLink="false">2506.17910v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Generalizing Vision-Language Models to Novel Domains: A Comprehensive Survey</title>
      <link>http://arxiv.org/abs/2506.18504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;这篇论文综述了视觉语言预训练模型（VLMs）的泛化设置、方法、基准和结果，并对VLMs在跨模态研究中的未来方向进行了探讨。&lt;h4&gt;背景&lt;/h4&gt;视觉语言预训练模型结合了视觉和文本模态的优点，表现出强大的零样本能力，但在面对特定领域或专业泛化任务时性能会下降。&lt;h4&gt;目的&lt;/h4&gt;通过综合总结VLMs的泛化研究，提供对VLMs时代迁移学习（TL）的新解释，并介绍VLMs泛化的流行基准。&lt;h4&gt;方法&lt;/h4&gt;论文将VLMs文献分为基于提示、参数和特征的方法，根据转移模块对每种方法的特点进行总结和讨论，并对不同方法进行性能比较。&lt;h4&gt;主要发现&lt;/h4&gt;VLMs在泛化任务中表现各异，迁移学习在VLMs时代具有新的解释，大型可泛化预训练的发展对VLMs和大型多模态语言模型（MLLMs）的关系产生了影响。&lt;h4&gt;结论&lt;/h4&gt;通过对视觉语言研究的文献进行系统回顾，本综述为当前和未来的多模态研究提供了一个清晰的图景。&lt;h4&gt;翻译&lt;/h4&gt;This paper reviews the generalization settings, methodologies, benchmarking and results in visual language model (VLM) literature, and discusses the future directions of multimodal research in the era of VLMs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recently, vision-language pretraining has emerged as a transformativetechnique that integrates the strengths of both visual and textual modalities,resulting in powerful vision-language models (VLMs). Leveraging web-scalepretraining data, these models exhibit strong zero-shot capabilities. However,their performance often deteriorates when confronted with domain-specific orspecialized generalization tasks. To address this, a growing body of researchfocuses on transferring or generalizing the rich knowledge embedded in VLMs tovarious downstream applications. This survey aims to comprehensively summarizethe generalization settings, methodologies, benchmarking and results in VLMliteratures. Delving into the typical VLM structures, current literatures arecategorized into prompt-based, parameter-based and feature-based methodsaccording to the transferred modules. The differences and characteristics ineach category are furthered summarized and discussed by revisiting the typicaltransfer learning (TL) settings, providing novel interpretations for TL in theera of VLMs. Popular benchmarks for VLM generalization are further introducedwith thorough performance comparisons among the reviewed methods. Following theadvances in large-scale generalizable pretraining, this survey also discussesthe relations and differences between VLMs and up-to-date multimodal largelanguage models (MLLM), e.g., DeepSeek-VL. By systematically reviewing thesurging literatures in vision-language research from a novel and practicalgeneralization prospective, this survey contributes to a clear landscape ofcurrent and future multimodal researches.</description>
      <author>example@mail.com (Xinyao Li, Jingjing Li, Fengling Li, Lei Zhu, Yang Yang, Heng Tao Shen)</author>
      <guid isPermaLink="false">2506.18504v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>DreamJourney: Perpetual View Generation with Video Diffusion Models</title>
      <link>http://arxiv.org/abs/2506.17705v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;DreamJourney是一个用于生成长期视频的框架，能够从单张输入图像中合成对应任意相机轨迹的视频。&lt;h4&gt;背景&lt;/h4&gt;现有的方法通常使用预训练的文本到图像扩散模型来合成相机移动过程中未见区域的图像，但这些方法缺乏三维感知，导致扭曲的伪影，并且仅限于生成静态三维场景的视图。&lt;h4&gt;目的&lt;/h4&gt;提出DreamJourney框架，以解决上述问题，实现既包含相机移动又包含物体动态的永久场景视图生成。&lt;h4&gt;方法&lt;/h4&gt;DreamJourney分为两个阶段：阶段I将输入图像提升为3D点云，并从特定相机轨迹渲染一系列部分图像，然后使用视频扩散模型生成缺失区域并增强序列的视觉连贯性；阶段II使用多模态大型语言模型生成描述当前视图物体运动的文本提示，并使用视频扩散模型使当前视图动画化。两个阶段循环进行。&lt;h4&gt;主要发现&lt;/h4&gt;DreamJourney在定性和定量实验中均优于现有方法，实现了高质量的动态场景视图生成。&lt;h4&gt;结论&lt;/h4&gt;DreamJourney能够有效生成高质量的动态场景视频，具有潜在的应用价值。&lt;h4&gt;翻译&lt;/h4&gt;Perpetual view generation aims to synthesize a long-term video correspondingto an arbitrary camera trajectory solely from a single input image. Recentmethods commonly utilize a pre-trained text-to-image diffusion model tosynthesize new content of previously unseen regions along camera movement.However, the underlying 2D diffusion model lacks 3D awareness and results indistorted artifacts. Moreover, they are limited to generating views of static3D scenes, neglecting to capture object movements within the dynamic 4D world.To alleviate these issues, we present DreamJourney, a two-stage framework thatleverages the world simulation capacity of video diffusion models to trigger anew perpetual scene view generation task with both camera movements and objectdynamics. Specifically, in stage I, DreamJourney first lifts the input image to3D point cloud and renders a sequence of partial images from a specific cameratrajectory. A video diffusion model is then utilized as generative prior tocomplete the missing regions and enhance visual coherence across the sequence,producing a cross-view consistent video adheres to the 3D scene and cameratrajectory. Meanwhile, we introduce two simple yet effective strategies (earlystopping and view padding) to further stabilize the generation process andimprove visual quality. Next, in stage II, DreamJourney leverages a multimodallarge language model to produce a text prompt describing object movements incurrent view, and uses video diffusion model to animate current view withobject movements. Stage I and II are repeated recurrently, enabling perpetualdynamic scene view generation. Extensive experiments demonstrate thesuperiority of our DreamJourney over state-of-the-art methods bothquantitatively and qualitatively. Our project page:https://dream-journey.vercel.app.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Perpetual view generation aims to synthesize a long-term video correspondingto an arbitrary camera trajectory solely from a single input image. Recentmethods commonly utilize a pre-trained text-to-image diffusion model tosynthesize new content of previously unseen regions along camera movement.However, the underlying 2D diffusion model lacks 3D awareness and results indistorted artifacts. Moreover, they are limited to generating views of static3D scenes, neglecting to capture object movements within the dynamic 4D world.To alleviate these issues, we present DreamJourney, a two-stage framework thatleverages the world simulation capacity of video diffusion models to trigger anew perpetual scene view generation task with both camera movements and objectdynamics. Specifically, in stage I, DreamJourney first lifts the input image to3D point cloud and renders a sequence of partial images from a specific cameratrajectory. A video diffusion model is then utilized as generative prior tocomplete the missing regions and enhance visual coherence across the sequence,producing a cross-view consistent video adheres to the 3D scene and cameratrajectory. Meanwhile, we introduce two simple yet effective strategies (earlystopping and view padding) to further stabilize the generation process andimprove visual quality. Next, in stage II, DreamJourney leverages a multimodallarge language model to produce a text prompt describing object movements incurrent view, and uses video diffusion model to animate current view withobject movements. Stage I and II are repeated recurrently, enabling perpetualdynamic scene view generation. Extensive experiments demonstrate thesuperiority of our DreamJourney over state-of-the-art methods bothquantitatively and qualitatively. Our project page:https://dream-journey.vercel.app.</description>
      <author>example@mail.com (Bo Pan, Yang Chen, Yingwei Pan, Ting Yao, Wei Chen, Tao Mei)</author>
      <guid isPermaLink="false">2506.17705v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>PERSCEN: Learning Personalized Interaction Pattern and Scenario Preference for Multi-Scenario Matching</title>
      <link>http://arxiv.org/abs/2506.18382v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by KDD 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PERSCEN的创新方法，用于多场景匹配，旨在减少维护成本和缓解数据稀疏性问题。&lt;h4&gt;背景&lt;/h4&gt;随着在线平台上商业规模和范围的扩大，多场景匹配已成为主流解决方案。&lt;h4&gt;目的&lt;/h4&gt;有效多场景推荐的关键在于捕捉用户在所有场景中共享的偏好以及特定于每个场景的场景感知偏好。&lt;h4&gt;方法&lt;/h4&gt;PERSCEN通过结合用户特定建模进行多场景匹配，构建基于用户特征的用户特定特征图，并使用轻量级图神经网络来捕捉高阶交互模式，从而实现跨场景偏好的个性化提取。此外，通过向量量化技术从用户在单个场景内的行为序列中提炼场景感知偏好，促进用户特定和场景感知偏好建模。为了提高信息传输的效率和灵活性，引入了渐进式场景感知门控线性单元，以实现细粒度、低延迟的融合。&lt;h4&gt;主要发现&lt;/h4&gt;广泛的实验表明，PERSCEN优于现有方法。进一步的效率分析证实，PERSCEN在性能和计算成本之间实现了有效平衡，确保其实际适用于现实世界的工业系统。&lt;h4&gt;结论&lt;/h4&gt;PERSCEN是一种高效且实用的多场景匹配方法，能够有效解决数据稀疏性问题，并在实际工业系统中具有应用潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1145/3711896.3737079&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the expansion of business scales and scopes on online platforms,multi-scenario matching has become a mainstream solution to reduce maintenancecosts and alleviate data sparsity. The key to effective multi-scenariorecommendation lies in capturing both user preferences shared across allscenarios and scenario-aware preferences specific to each scenario. However,existing methods often overlook user-specific modeling, limiting the generationof personalized user representations. To address this, we propose PERSCEN, aninnovative approach that incorporates user-specific modeling intomulti-scenario matching. PERSCEN constructs a user-specific feature graph basedon user characteristics and employs a lightweight graph neural network tocapture higher-order interaction patterns, enabling personalized extraction ofpreferences shared across scenarios. Additionally, we leverage vectorquantization techniques to distil scenario-aware preferences from users'behavior sequence within individual scenarios, facilitating user-specific andscenario-aware preference modeling. To enhance efficient and flexibleinformation transfer, we introduce a progressive scenario-aware gated linearunit that allows fine-grained, low-latency fusion. Extensive experimentsdemonstrate that PERSCEN outperforms existing methods. Further efficiencyanalysis confirms that PERSCEN effectively balances performance withcomputational cost, ensuring its practicality for real-world industrialsystems.</description>
      <author>example@mail.com (Haotong Du, Yaqing Wang, Fei Xiong, Lei Shao, Ming Liu, Hao Gu, Quanming Yao, Zhen Wang)</author>
      <guid isPermaLink="false">2506.18382v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SSAVSV: Towards Unified Model for Self-Supervised Audio-Visual Speaker Verification</title>
      <link>http://arxiv.org/abs/2506.17694v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于对比学习的自监督学习框架，用于音频视觉说话人验证，旨在解决传统方法依赖大量标注数据和独立模态架构的问题。&lt;h4&gt;背景&lt;/h4&gt;传统的音频视觉说话人验证方法需要大量标注数据，且采用独立的模态特定架构，这导致计算成本高，限制了其可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以减少对大量标注数据的依赖，并降低计算成本，同时保持性能。&lt;h4&gt;方法&lt;/h4&gt;采用基于对比学习的自监督学习框架，结合非对称掩码和掩码数据建模，以获得鲁棒的音频视觉特征表示。使用统一的框架进行自监督音频视觉说话人验证，通过单个共享的骨干网络处理音频和视觉输入，利用视觉Transformer的灵活性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在不使用标注数据的情况下实现了与传统方法相竞争的性能，同时降低了计算成本。&lt;h4&gt;结论&lt;/h4&gt;该统一框架在处理音频、视觉或音频视觉输入时，使用单个共享的视觉Transformer骨干网络进行训练和测试，既计算高效又对缺失的模态具有鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Conventional audio-visual methods for speaker verification rely on largeamounts of labeled data and separate modality-specific architectures, which iscomputationally expensive, limiting their scalability. To address theseproblems, we propose a self-supervised learning framework based on contrastivelearning with asymmetric masking and masked data modeling to obtain robustaudiovisual feature representations. In particular, we employ a unifiedframework for self-supervised audiovisual speaker verification using a singleshared backbone for audio and visual inputs, leveraging the versatility ofvision transformers. The proposed unified framework can handle audio, visual,or audiovisual inputs using a single shared vision transformer backbone duringtraining and testing while being computationally efficient and robust tomissing modalities. Extensive experiments demonstrate that our method achievescompetitive performance without labeled data while reducing computational costscompared to traditional approaches.</description>
      <author>example@mail.com (Gnana Praveen Rajasekhar, Jahangir Alam)</author>
      <guid isPermaLink="false">2506.17694v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Memba: Membrane-driven Parameter-Efficient Fine-Tuning for Mamba</title>
      <link>http://arxiv.org/abs/2506.18184v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为Memba的参数高效微调（PEFT）方法，专门用于Mamba模型，以提升其时序建模能力。&lt;h4&gt;背景&lt;/h4&gt;随着状态空间模型（SSMs）的增长，需要参数高效的微调方法来适应下游任务，同时避免高昂的计算成本。&lt;h4&gt;目的&lt;/h4&gt;设计一种适用于Mamba的PEFT方法，以增强其时序建模能力。&lt;h4&gt;方法&lt;/h4&gt;Memba方法引入了漏导积分膜（LIM）神经元作为生物启发的门控机制，结合低秩调整（LoRA）和跨层膜传递技术。&lt;h4&gt;主要发现&lt;/h4&gt;Memba在语言和视觉任务上相较于现有PEFT方法实现了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;Memba是一个有效的PEFT方法，可以显著提高Mamba模型在时序建模任务上的性能。&lt;h4&gt;翻译&lt;/h4&gt;State Space Models (SSMs) have emerged as powerful alternatives to attention-based Transformers, with Mamba demonstrating impressive efficiency and scalability. As these models grow increasingly larger, the need for Parameter-Efficient Fine-Tuning (PEFT) methods becomes critical to adapt pre-trained Mamba to downstream tasks without prohibitive computational costs. However, previous approaches simply apply traditional Transformer-tailored PEFT methods without addressing the unique temporal processing dynamics of SSMs. To address this limitation, we propose Memba, a membrane-driven PEFT approach specifically designed for Mamba. Memba introduces Leaky Integrate Membrane (LIM) neurons as bio-inspired gating mechanisms that naturally accumulate membrane potentials over time, enhancing selective information retention. By strategically combining LIM neurons with Low-Rank Adaptations (LoRA) and cross-layer membrane transfer, our approach significantly improves Mamba's temporal modeling capabilities. Extensive experiments across language and vision tasks demonstrate that Memba achieves substantial improvements over existing PEFT methods. The code is available at https://github.com/Intelligent-Computing-Lab-Yale/Memba.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; State Space Models (SSMs) have emerged as powerful alternatives toattention-based Transformers, with Mamba demonstrating impressive efficiencyand scalability. As these models grow increasingly larger, the need forParameter-Efficient Fine-Tuning (PEFT) methods becomes critical to adaptpre-trained Mamba to downstream tasks without prohibitive computational costs.However, previous approaches simply apply traditional Transformer-tailored PEFTmethods without addressing the unique temporal processing dynamics of SSMs. Toaddress this limitation, we propose Memba, a membrane-driven PEFT approachspecifically designed for Mamba. Memba introduces Leaky Integrate Membrane(LIM) neurons as bio-inspired gating mechanisms that naturally accumulatemembrane potentials over time, enhancing selective information retention. Bystrategically combining LIM neurons with Low-Rank Adaptations (LoRA) andcross-layer membrane transfer, our approach significantly improves Mamba'stemporal modeling capabilities. Extensive experiments across language andvision tasks demonstrate that Memba achieves substantial improvements overexisting PEFT methods. The code is available athttps://github.com/Intelligent-Computing-Lab-Yale/Memba.</description>
      <author>example@mail.com (Donghyun Lee, Yuhang Li, Ruokai Yin, Shiting Xiao, Priyadarshini Panda)</author>
      <guid isPermaLink="false">2506.18184v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Robot Tactile Gesture Recognition Based on Full-body Modular E-skin</title>
      <link>http://arxiv.org/abs/2506.18256v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了机器人电子皮肤技术的发展及其在触觉感知方面的应用，通过开发一种模块化机器人电子皮肤，实现了对触觉手势的识别和解读，进而实现人与机器人之间的直观交互。&lt;h4&gt;背景&lt;/h4&gt;随着机器人电子皮肤技术的进步，结合人工智能的触觉传感器为机器人开启了一个新的感知维度。&lt;h4&gt;目的&lt;/h4&gt;研究装备电子皮肤的机器人如何识别触觉手势并将这些手势解释为人类命令。&lt;h4&gt;方法&lt;/h4&gt;开发了一种由多个不规则形状的皮肤片组成的模块化机器人电子皮肤，可以组装覆盖机器人的身体，并从数千个传感点实时捕捉压力和姿态数据。为了处理这些信息，提出了一种基于等变图神经网络的识别器，该识别器能够高效且准确地分类多种触觉手势。&lt;h4&gt;主要发现&lt;/h4&gt;识别器能够识别包括戳、抓、抚摸和双拍等多种触觉手势，并通过将识别的手势映射到预定义的机器人动作，实现了仅通过触觉输入的人机交互。&lt;h4&gt;结论&lt;/h4&gt;通过触觉输入实现直观的人机交互，为机器人感知和交互能力提供了新的可能性。&lt;h4&gt;翻译&lt;/h4&gt;With the development of robot electronic skin technology, various tactilesensors, enhanced by AI, are unlocking a new dimension of perception forrobots. In this work, we explore how robots equipped with electronic skin canrecognize tactile gestures and interpret them as human commands. We developed amodular robot E-skin, composed of multiple irregularly shaped skin patches,which can be assembled to cover the robot's body while capturing real-timepressure and pose data from thousands of sensing points. To process thisinformation, we propose an equivariant graph neural network-based recognizerthat efficiently and accurately classifies diverse tactile gestures, includingpoke, grab, stroke, and double-pat. By mapping the recognized gestures topredefined robot actions, we enable intuitive human-robot interaction purelythrough tactile input.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the development of robot electronic skin technology, various tactilesensors, enhanced by AI, are unlocking a new dimension of perception forrobots. In this work, we explore how robots equipped with electronic skin canrecognize tactile gestures and interpret them as human commands. We developed amodular robot E-skin, composed of multiple irregularly shaped skin patches,which can be assembled to cover the robot's body while capturing real-timepressure and pose data from thousands of sensing points. To process thisinformation, we propose an equivariant graph neural network-based recognizerthat efficiently and accurately classifies diverse tactile gestures, includingpoke, grab, stroke, and double-pat. By mapping the recognized gestures topredefined robot actions, we enable intuitive human-robot interaction purelythrough tactile input.</description>
      <author>example@mail.com (Shuo Jiang, Boce Hu, Linfeng Zhao, Lawson L. S. Wong)</author>
      <guid isPermaLink="false">2506.18256v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Optimization-Free Patch Attack on Stereo Depth Estimation</title>
      <link>http://arxiv.org/abs/2506.17632v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了立体深度估计（SDE）在视觉系统中的应用，特别是针对自动驾驶等场景。文章提出了一种新的攻击框架，用于对抗SDE模型，并验证了其在现实条件下的有效性。&lt;h4&gt;背景&lt;/h4&gt;SDE模型在自动驾驶等视觉系统中至关重要，但易受对抗攻击影响，现有攻击方法通常在非现实场景中测试，限制了其应用。&lt;h4&gt;目的&lt;/h4&gt;设计物理可实现、场景自适应且可迁移的SDE对抗攻击。&lt;h4&gt;方法&lt;/h4&gt;提出一个统一的攻击框架，将基于优化的技术扩展到立体匹配的四个核心阶段：特征提取、成本体构建、成本聚合和视差回归。引入PatchHunter，一种无优化对抗补丁攻击，通过强化学习在视觉模式空间中搜索破坏SDE假设的模式。&lt;h4&gt;主要发现&lt;/h4&gt;基于优化的补丁在迁移性方面表现不佳，而部分可迁移的补丁表明模式而非像素级扰动可能是通用攻击的关键。PatchHunter在KITTI数据集、CARLA模拟器和真实世界车辆部署中均有效，且在低光等挑战性物理条件下保持高攻击成功率。&lt;h4&gt;结论&lt;/h4&gt;PatchHunter在攻击效果和黑盒迁移性方面优于基于优化的方法，为SDE模型的对抗攻击提供了新的思路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stereo Depth Estimation (SDE) is essential for scene understanding invision-based systems like autonomous driving. However, recent studies show thatSDE models are vulnerable to adversarial attacks, which are often limited tounrealistic settings, e.g., digital perturbations on separate stereo views instatic scenes, restricting their real-world applicability. This raises acritical question: how can we design physically realizable, scene-adaptive, andtransferable attacks against SDE under realistic constraints?  To answer this, we make two key contributions. First, we propose a unifiedattack framework that extends optimization-based techniques to four core stagesof stereo matching: feature extraction, cost-volume construction, costaggregation, and disparity regression. A comprehensive stage-wise evaluationacross 9 mainstream SDE models, under constraints like photometric consistency,reveals that optimization-based patches suffer from poor transferability.Interestingly, partially transferable patches suggest that patterns, ratherthan pixel-level perturbations, may be key to generalizable attacks. Motivatedby this, we present PatchHunter, the first optimization-free adversarial patchattack against SDE. PatchHunter formulates patch generation as a reinforcementlearning-driven search over a structured space of visual patterns crafted todisrupt SDE assumptions.  We validate PatchHunter across three levels: the KITTI dataset, the CARLAsimulator, and real-world vehicle deployment. PatchHunter not only surpassesoptimization-based methods in effectiveness but also achieves significantlybetter black-box transferability. Even under challenging physical conditionslike low light, PatchHunter maintains high attack success (e.g., D1-all &gt; 0.4),whereas optimization-based methods fail.</description>
      <author>example@mail.com (Hangcheng Liu, Xu Kuang, Xingshuo Han, Xingwan Wu, Haoran Ou, Shangwei Guo, Xingyi Huang, Tao Xiang, Tianwei Zhang)</author>
      <guid isPermaLink="false">2506.17632v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Time-Aware Causal Representation for Model Generalization in Evolving Domains</title>
      <link>http://arxiv.org/abs/2506.17718v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SYNC的时间感知结构因果模型，旨在解决动态场景下深度模型的泛化问题。&lt;h4&gt;背景&lt;/h4&gt;随着数据分布的持续变化，赋予深度模型在动态场景中泛化的能力对于实际部署至关重要。&lt;h4&gt;目的&lt;/h4&gt;针对现有演化域泛化方法可能存在的伪相关性问题，旨在设计一种能够有效学习时间感知因果表示的方法。&lt;h4&gt;方法&lt;/h4&gt;设计了一种时间感知结构因果模型，该模型结合了动态因果因素和因果机制漂移，并提出了SYNC方法，该方法通过将特别设计的信息论目标整合到序列变分自编码器框架中，捕捉演化模式，并通过保持因果因素在域内和域间的类内紧凑性来产生所需的表示。&lt;h4&gt;主要发现&lt;/h4&gt;理论证明了该方法可以针对每个时间域产生最优的因果预测器。在合成和真实世界数据集上的结果表明，SYNC可以实现卓越的时间泛化性能。&lt;h4&gt;结论&lt;/h4&gt;SYNC方法能够有效提高深度模型在动态场景下的泛化能力，为实际应用提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Endowing deep models with the ability to generalize in dynamic scenarios isof vital significance for real-world deployment, given the continuous andcomplex changes in data distribution. Recently, evolving domain generalization(EDG) has emerged to address distribution shifts over time, aiming to captureevolving patterns for improved model generalization. However, existing EDGmethods may suffer from spurious correlations by modeling only the dependencebetween data and targets across domains, creating a shortcut betweentask-irrelevant factors and the target, which hinders generalization. To thisend, we design a time-aware structural causal model (SCM) that incorporatesdynamic causal factors and the causal mechanism drifts, and propose\textbf{S}tatic-D\textbf{YN}amic \textbf{C}ausal Representation Learning(\textbf{SYNC}), an approach that effectively learns time-aware causalrepresentations. Specifically, it integrates specially designedinformation-theoretic objectives into a sequential VAE framework which capturesevolving patterns, and produces the desired representations by preservingintra-class compactness of causal factors both across and within domains.Moreover, we theoretically show that our method can yield the optimal causalpredictor for each time domain. Results on both synthetic and real-worlddatasets exhibit that SYNC can achieve superior temporal generalizationperformance.</description>
      <author>example@mail.com (Zhuo He, Shuang Li, Wenze Song, Longhui Yuan, Jian Liang, Han Li, Kun Gai)</author>
      <guid isPermaLink="false">2506.17718v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>End-to-End Spoken Grammatical Error Correction</title>
      <link>http://arxiv.org/abs/2506.18532v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了语音错误纠正（SGEC）和反馈在支持第二语言学习者、教育者和考官中的重要作用，并提出了一个端到端（E2E）框架来解决SGEC和反馈生成中的挑战。&lt;h4&gt;背景&lt;/h4&gt;SGEC系统通常包括自动语音识别（ASR）、停顿检测和GEC模块，这些模块之间的错误传播使其容易出错。&lt;h4&gt;目的&lt;/h4&gt;研究E2E框架在SGEC和反馈生成中的应用，并比较级联、部分级联和E2E架构。&lt;h4&gt;方法&lt;/h4&gt;使用了Whisper基础模型，并提出了自动伪标记框架来增加训练数据。为了提高SGEC系统的准确性，研究了利用ASR输出的上下文信息，并提出了一个新的参考对齐过程来提高反馈的精确度。&lt;h4&gt;主要发现&lt;/h4&gt;E2E系统面临GEC标记的语音数据稀缺的问题，通过自动伪标记框架增加了训练数据量。提出的参考对齐过程和编辑置信度估计方法显著提高了E2E SGEC的性能。&lt;h4&gt;结论&lt;/h4&gt;在内部Linguaskill（LNG）语料库和公开的Speak &amp; Improve（S&amp;I）语料库上的实验表明，所提出的方法显著提高了E2E SGEC的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Grammatical Error Correction (GEC) and feedback play a vital role insupporting second language (L2) learners, educators, and examiners. Whilewritten GEC is well-established, spoken GEC (SGEC), aiming to provide feedbackbased on learners' speech, poses additional challenges due to disfluencies,transcription errors, and the lack of structured input. SGEC systems typicallyfollow a cascaded pipeline consisting of Automatic Speech Recognition (ASR),disfluency detection, and GEC, making them vulnerable to error propagationacross modules. This work examines an End-to-End (E2E) framework for SGEC andfeedback generation, highlighting challenges and possible solutions whendeveloping these systems. Cascaded, partial-cascaded and E2E architectures arecompared, all built on the Whisper foundation model. A challenge for E2Esystems is the scarcity of GEC labeled spoken data. To address this, anautomatic pseudo-labeling framework is examined, increasing the training datafrom 77 to over 2500 hours. To improve the accuracy of the SGEC system,additional contextual information, exploiting the ASR output, is investigated.Candidate feedback of their mistakes is an essential step to improvingperformance. In E2E systems the SGEC output must be compared with an estimateof the fluent transcription to obtain the feedback. To improve the precision ofthis feedback, a novel reference alignment process is proposed that aims toremove hypothesised edits that results from fluent transcription errors.Finally, these approaches are combined with an edit confidence estimationapproach, to exclude low-confidence edits. Experiments on the in-houseLinguaskill (LNG) corpora and the publicly available Speak &amp; Improve (S&amp;I)corpus show that the proposed approaches significantly boost E2E SGECperformance.</description>
      <author>example@mail.com (Mengjie Qian, Rao Ma, Stefano Bannò, Mark J. F. Gales, Kate M. Knill)</author>
      <guid isPermaLink="false">2506.18532v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Leveraging neural network interatomic potentials for a foundation model of chemistry</title>
      <link>http://arxiv.org/abs/2506.18497v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  29pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HackNIP的两阶段管道，用于处理大规模基础模型，如计算材料科学中的神经网络原子间势（NIPs），以解决其预测电子性质和宏观性质时的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管NIPs在加速原子模拟方面取得了成功，但它们在直接预测电子性质方面面临挑战，通常需要与更高尺度的模型或进行大量模拟来预测宏观性质。&lt;h4&gt;目的&lt;/h4&gt;旨在通过结合机器学习（ML）方法，解决NIPs在预测电子性质和宏观性质时的局限性，并提高数据效率和性能。&lt;h4&gt;方法&lt;/h4&gt;HackNIP方法首先从NIP基础模型中提取固定长度的特征向量（嵌入），然后使用这些嵌入来训练浅层ML模型进行下游的结构到性质的预测。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，通过“黑客”NIP的混合方法可以超越端到端的深度神经网络，确定了在哪个数据集大小下这种迁移学习方法优于直接微调NIP，并确定了哪种NIP嵌入深度产生了最有信息量的特征。&lt;h4&gt;结论&lt;/h4&gt;HackNIP在Matbench上进行了基准测试，评估了数据效率，并在包括从头计算、实验和分子性质在内的多种任务上进行了测试。该研究证明了在材料科学中克服ML权衡的混合策略，旨在使高性能预测建模民主化。&lt;h4&gt;翻译&lt;/h4&gt;摘要：大规模基础模型，包括计算材料科学中的神经网络原子间势（NIPs），已经显示出巨大的潜力。然而，尽管它们在加速原子模拟方面取得了成功，但NIPs在直接预测电子性质方面面临挑战，通常需要与更高尺度的模型或进行大量模拟来预测宏观性质。机器学习（ML）为结构到性质的映射提供了替代方案，但存在权衡：基于特征的方法往往缺乏泛化性，而深度神经网络需要大量的数据和计算能力。为了解决这些权衡，我们引入了HackNIP，这是一种利用预训练NIPs的两阶段管道。这种方法首先从NIP基础模型中提取固定长度的特征向量（嵌入），然后使用这些嵌入来训练浅层ML模型进行下游的结构到性质的预测。本研究调查了这种混合方法，通过“黑客”NIP，是否可以超越端到端的深度神经网络，确定了这种迁移学习方法超越直接微调NIP的数据集大小，并确定了哪种NIP嵌入深度产生了最有信息量的特征。HackNIP在Matbench上进行了基准测试，评估了数据效率，并在包括从头计算、实验和分子性质在内的多种任务上进行了测试。我们还分析了嵌入深度对性能的影响。这项工作证明了在材料科学中克服ML权衡的混合策略，旨在使高性能预测建模民主化。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large-scale foundation models, including neural network interatomicpotentials (NIPs) in computational materials science, have demonstratedsignificant potential. However, despite their success in accelerating atomisticsimulations, NIPs face challenges in directly predicting electronic propertiesand often require coupling to higher-scale models or extensive simulations formacroscopic properties. Machine learning (ML) offers alternatives forstructure-to-property mapping but faces trade-offs: feature-based methods oftenlack generalizability, while deep neural networks require significant data andcomputational power. To address these trade-offs, we introduce HackNIP, atwo-stage pipeline that leverages pretrained NIPs. This method first extractsfixed-length feature vectors (embeddings) from NIP foundation models and thenuses these embeddings to train shallow ML models for downstreamstructure-to-property predictions. This study investigates whether such ahybridization approach, by ``hacking" the NIP, can outperform end-to-end deepneural networks, determines the dataset size at which this transfer learningapproach surpasses direct fine-tuning of the NIP, and identifies which NIPembedding depths yield the most informative features. HackNIP is benchmarked onMatbench, evaluated for data efficiency, and tested on diverse tasks including\textit{ab initio}, experimental, and molecular properties. We also analyze howembedding depth impacts performance. This work demonstrates a hybridizationstrategy to overcome ML trade-offs in materials science, aiming to democratizehigh-performance predictive modeling.</description>
      <author>example@mail.com (So Yeon Kim, Yang Jeong Park, Ju Li)</author>
      <guid isPermaLink="false">2506.18497v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Scene-R1: Video-Grounded Large Language Models for 3D Scene Reasoning without 3D Annotations</title>
      <link>http://arxiv.org/abs/2506.17545v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为Scene-R1的视频基础框架，用于理解3D场景，通过结合强化学习驱动的推理和两阶段地面管道，实现无点状3D实例监督的学习。&lt;h4&gt;背景&lt;/h4&gt;目前，使用大型语言模型来理解3D世界越来越受欢迎，但现有的3D感知LLM作为黑盒，输出边界框或文本答案而不透露决策过程，并且仍然依赖于预训练的3D检测器来提供对象提议。&lt;h4&gt;目的&lt;/h4&gt;提出Scene-R1框架，旨在通过强化学习驱动的推理和两阶段地面管道，学习对3D场景进行推理，无需任何点状3D实例监督。&lt;h4&gt;方法&lt;/h4&gt;在时间地面阶段，通过视频推理并选择与开放性问题最相关的视频片段。在随后的图像地面阶段，分析图像并预测2D边界框。之后，使用SAM2跟踪对象，在RGB帧中产生像素级精确的掩码，并将它们投影回3D，从而消除基于3D检测器的提议需求，同时捕捉精细的几何和材料线索。&lt;h4&gt;主要发现&lt;/h4&gt;Scene-R1可以在3D视觉问答任务中适应，直接从视频中回答自由形式的提问。训练过程只需要任务级别的2D框或文本标签，无需密集的3D点状标签。Scene-R1在多个数据集上超越了现有的开放词汇基线，同时提供了透明的、逐步的推理过程。&lt;h4&gt;结论&lt;/h4&gt;基于强化学习的推理与RGB-D视频的结合，提供了一种实用、标注高效的可靠3D场景理解途径。&lt;h4&gt;翻译&lt;/h4&gt;目前，利用大型语言模型来理解3D世界变得越来越流行。然而，现有的3D感知LLM作为黑盒，输出边界框或文本答案而不透露决策过程，并且仍然依赖于预训练的3D检测器来提供对象提议。我们引入了Scene-R1，一个视频基础的框架，通过将强化学习驱动的推理与一个两阶段地面管道相结合，学习在没有任何点状3D实例监督的情况下对3D场景进行推理。在时间地面阶段，我们明确地对视频进行推理，并选择与开放性问题最相关的视频片段。在随后的图像地面阶段，我们分析图像并预测2D边界框。之后，我们使用SAM2跟踪对象，在RGB帧中产生像素级精确的掩码，并将它们投影回3D，从而消除了基于3D检测器的提议需求，同时捕捉到了精细的几何和材料线索。Scene-R1还可以适应3D视觉问答任务，直接从视频中回答自由形式的提问。我们的训练流程只需要任务级别的2D框或文本标签，而不需要密集的3D点状标签。Scene-R1在多个数据集上超越了现有的开放词汇基线，同时提供了透明的、逐步的推理过程。这些结果表明，基于强化学习的推理与RGB-D视频的结合，提供了一种实用、标注高效的可靠3D场景理解途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Currently, utilizing large language models to understand the 3D world isbecoming popular. Yet existing 3D-aware LLMs act as black boxes: they outputbounding boxes or textual answers without revealing how those decisions aremade, and they still rely on pre-trained 3D detectors to supply objectproposals. We introduce Scene-R1, a video-grounded framework that learns toreason about 3D scenes without any point-wise 3D instance supervision bypairing reinforcement-learning-driven reasoning with a two-stage groundingpipeline. In the temporal grounding stage, we explicitly reason about the videoand select the video snippets most relevant to an open-ended query. In thesubsequent image grounding stage, we analyze the image and predict the 2Dbounding box. After that, we track the object using SAM2 to producepixel-accurate masks in RGB frames, and project them back into 3D, therebyeliminating the need for 3D detector-based proposals while capturing finegeometry and material cues. Scene-R1 can also adapt to the 3D visual questionanswering task to answer free-form questions directly from video. Our trainingpipeline only needs task-level 2D boxes or textual labels without dense 3Dpoint-wise labels. Scene-R1 surpasses existing open-vocabulary baselines onmultiple datasets, while delivering transparent, step-by-step rationales. Theseresults show that reinforcement-learning-based reasoning combined with RGB-Dvideo alone offers a practical, annotation-efficient route to trustworthy 3Dscene understanding.</description>
      <author>example@mail.com (Zhihao Yuan, Shuyi Jiang, Chun-Mei Feng, Yaolun Zhang, Shuguang Cui, Zhen Li, Na Zhao)</author>
      <guid isPermaLink="false">2506.17545v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>A workflow for generating synthetic LiDAR datasets in simulation environments</title>
      <link>http://arxiv.org/abs/2506.17378v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种生成合成LiDAR数据集的仿真工作流程，以支持自动驾驶车辆的感知、机器人研究和传感器安全性分析。&lt;h4&gt;背景&lt;/h4&gt;利用CoppeliaSim仿真环境和其Python API，将飞行时间LiDAR、图像传感器和二维扫描仪集成到一个模拟车辆平台上，该平台在城市场景中运行。&lt;h4&gt;目的&lt;/h4&gt;自动化数据捕捉、存储和注释，以生成包含地面真实位姿信息的同步多模态数据集。&lt;h4&gt;方法&lt;/h4&gt;通过生成大规模点云和相应的RGB和深度图像来验证该流程。研究还探讨了LiDAR数据中的潜在安全漏洞，如对抗性点注入和欺骗攻击，并展示了合成数据集如何有助于评估防御策略。&lt;h4&gt;主要发现&lt;/h4&gt;讨论了与环境真实感、传感器噪声建模和计算可扩展性相关的限制，并提出了未来研究方向，如融入天气效应、现实世界地形模型和高级扫描配置。&lt;h4&gt;结论&lt;/h4&gt;该工作流程为生成高保真合成LiDAR数据集提供了一个通用、可重复的框架，以推进感知研究并加强自动驾驶系统中的传感器安全性。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种用于生成合成LiDAR数据集的仿真工作流程，旨在支持自动驾驶车辆的感知、机器人研究和传感器安全性分析。通过利用CoppeliaSim仿真环境和Python API，将飞行时间LiDAR、图像传感器和二维扫描仪集成到一个模拟车辆平台上，该平台在城市场景中运行。该工作流程自动化数据捕捉、存储和注释，生成包含地面真实位姿信息的同步多模态数据集。通过生成大规模点云和相应的RGB和深度图像验证该流程。研究还探讨了LiDAR数据中的潜在安全漏洞，如对抗性点注入和欺骗攻击，并展示了合成数据集如何有助于评估防御策略。讨论了与环境真实感、传感器噪声建模和计算可扩展性相关的限制，并提出了未来研究方向，如融入天气效应、现实世界地形模型和高级扫描配置。该工作流程为生成高保真合成LiDAR数据集提供了一个通用、可重复的框架，以推进感知研究并加强自动驾驶系统中的传感器安全性。该框架附带文档和示例；动画云回波和图像传感器数据的样本可在链接中找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents a simulation workflow for generating synthetic LiDARdatasets to support autonomous vehicle perception, robotics research, andsensor security analysis. Leveraging the CoppeliaSim simulation environment andits Python API, we integrate time-of-flight LiDAR, image sensors, and twodimensional scanners onto a simulated vehicle platform operating within anurban scenario. The workflow automates data capture, storage, and annotationacross multiple formats (PCD, PLY, CSV), producing synchronized multimodaldatasets with ground truth pose information. We validate the pipeline bygenerating large-scale point clouds and corresponding RGB and depth imagery.The study examines potential security vulnerabilities in LiDAR data, such asadversarial point injection and spoofing attacks, and demonstrates howsynthetic datasets can facilitate the evaluation of defense strategies.Finally, limitations related to environmental realism, sensor noise modeling,and computational scalability are discussed, and future research directions,such as incorporating weather effects, real-world terrain models, and advancedscanner configurations, are proposed. The workflow provides a versatile,reproducible framework for generating high-fidelity synthetic LiDAR datasets toadvance perception research and strengthen sensor security in autonomoussystems. Documentation and examples accompany this framework; samples ofanimated cloud returns and image sensor data can be found at this Link.</description>
      <author>example@mail.com (Abhishek Phadke, Shakib Mahmud Dipto, Pratip Rana)</author>
      <guid isPermaLink="false">2506.17378v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>DRIMV_TSK: An Interpretable Surgical Evaluation Model for Incomplete Multi-View Rectal Cancer Data</title>
      <link>http://arxiv.org/abs/2506.17552v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种多视角直肠癌数据集和可解释的不完整多视角手术评估模型，以提高直肠癌治疗的成功率。&lt;h4&gt;背景&lt;/h4&gt;目前直肠癌治疗的评估方法基于临床数据，但技术发展可以收集更多数据，人工智能的应用也使得直肠癌治疗成为可能。&lt;h4&gt;目的&lt;/h4&gt;构建一个多视角直肠癌数据集，并开发一个可解释的不完整多视角手术评估模型，以更全面地评估患者情况。&lt;h4&gt;方法&lt;/h4&gt;首先构建了包含高分辨率MRI图像视图、压脂MRI图像视图和临床数据视图的多视角直肠癌数据集。然后，提出了一种双表示不完整多视角学习模型，该模型将缺失视图插补集成到表示学习中，并引入了二阶相似性约束以改善合作学习。基于插补的多视角数据和学习的双表示，提出了一种基于TSK模糊系统的多视角手术评估模型。该模型构建了一个合作学习机制来探索视图间的一致信息，并引入了香农熵来适应视图权重。&lt;h4&gt;主要发现&lt;/h4&gt;在MVRC数据集上，与几种先进的算法相比，DRIMV_TSK模型获得了最佳结果。&lt;h4&gt;结论&lt;/h4&gt;所提出的方法可以有效地评估直肠癌手术的难度，并有望提高直肠癌治疗的成功率。&lt;h4&gt;翻译&lt;/h4&gt;A reliable evaluation of surgical difficulty can improve the success of the treatment for rectal cancer and the current evaluation method is based on clinical data. However, more data about rectal cancer can be collected with the development of technology. Meanwhile, with the development of artificial intelligence, its application in rectal cancer treatment is becoming possible. In this paper, a multi-view rectal cancer dataset is first constructed to give a more comprehensive view of patients, including the high-resolution MRI image view, pressed-fat MRI image view, and clinical data view. Then, an interpretable incomplete multi-view surgical evaluation model is proposed, considering that it is hard to obtain extensive and complete patient data in real application scenarios. Specifically, a dual representation incomplete multi-view learning model is first proposed to extract the common information between views and specific information in each view. In this model, the missing view imputation is integrated into representation learning, and second-order similarity constraint is also introduced to improve the cooperative learning between these two parts. Then, based on the imputed multi-view data and the learned dual representation, a multi-view surgical evaluation model with the TSK fuzzy system is proposed. In the proposed model, a cooperative learning mechanism is constructed to explore the consistent information between views, and Shannon entropy is also introduced to adapt the view weight. On the MVRC dataset, we compared it with several advanced algorithms and DRIMV_TSK obtained the best results.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; A reliable evaluation of surgical difficulty can improve the success of thetreatment for rectal cancer and the current evaluation method is based onclinical data. However, more data about rectal cancer can be collected with thedevelopment of technology. Meanwhile, with the development of artificialintelligence, its application in rectal cancer treatment is becoming possible.In this paper, a multi-view rectal cancer dataset is first constructed to givea more comprehensive view of patients, including the high-resolution MRI imageview, pressed-fat MRI image view, and clinical data view. Then, aninterpretable incomplete multi-view surgical evaluation model is proposed,considering that it is hard to obtain extensive and complete patient data inreal application scenarios. Specifically, a dual representation incompletemulti-view learning model is first proposed to extract the common informationbetween views and specific information in each view. In this model, the missingview imputation is integrated into representation learning, and second-ordersimilarity constraint is also introduced to improve the cooperative learningbetween these two parts. Then, based on the imputed multi-view data and thelearned dual representation, a multi-view surgical evaluation model with theTSK fuzzy system is proposed. In the proposed model, a cooperative learningmechanism is constructed to explore the consistent information between views,and Shannon entropy is also introduced to adapt the view weight. On the MVRCdataset, we compared it with several advanced algorithms and DRIMV_TSK obtainedthe best results.</description>
      <author>example@mail.com (Wei Zhang, Zi Wang, Hanwen Zhou, Zhaohong Deng, Weiping Ding, Yuxi Ge, Te Zhang, Yuanpeng Zhang, Kup-Sze Choi, Shitong Wang, Shudong Hu)</author>
      <guid isPermaLink="false">2506.17552v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>A Survey of State Representation Learning for Deep Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.17518v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了在强化学习中学习有意义状态表示的各种方法，旨在提高样本效率、泛化能力和性能。&lt;h4&gt;背景&lt;/h4&gt;复杂观察空间对序列决策问题提出了挑战，表示学习方法成为解决这些挑战的重要工具。&lt;h4&gt;目的&lt;/h4&gt;对无模型在线设置中的表示学习方法进行广泛分类，探讨它们在状态表示学习方面的不同方法。&lt;h4&gt;方法&lt;/h4&gt;将方法分为六类，详细介绍了它们的机制、优点和局限性。&lt;h4&gt;主要发现&lt;/h4&gt;通过分类，旨在提高对该领域理解，并为新研究者提供指导。&lt;h4&gt;结论&lt;/h4&gt;讨论了评估表示质量的技术，并详细阐述了相关未来研究方向。&lt;h4&gt;翻译&lt;/h4&gt;Representation learning methods are an important tool for addressing the challenges posed by complex observation spaces in sequential decision making problems. Recently, many methods have used a wide variety of types of approaches for learning meaningful state representations in reinforcement learning, allowing better sample efficiency, generalization, and performance. This survey aims to provide a broad categorization of these methods within a model-free online setting, exploring how they tackle the learning of state representations differently. We categorize the methods into six main classes, detailing their mechanisms, benefits, and limitations. Through this taxonomy, our aim is to enhance the understanding of this field and provide a guide for new researchers. We also discuss techniques for assessing the quality of representations, and detail relevant future directions.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Representation learning methods are an important tool for addressing thechallenges posed by complex observations spaces in sequential decision makingproblems. Recently, many methods have used a wide variety of types ofapproaches for learning meaningful state representations in reinforcementlearning, allowing better sample efficiency, generalization, and performance.This survey aims to provide a broad categorization of these methods within amodel-free online setting, exploring how they tackle the learning of staterepresentations differently. We categorize the methods into six main classes,detailing their mechanisms, benefits, and limitations. Through this taxonomy,our aim is to enhance the understanding of this field and provide a guide fornew researchers. We also discuss techniques for assessing the quality ofrepresentations, and detail relevant future directions.</description>
      <author>example@mail.com (Ayoub Echchahed, Pablo Samuel Castro)</author>
      <guid isPermaLink="false">2506.17518v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Zero-Shot Conversational Stance Detection: Dataset and Approaches</title>
      <link>http://arxiv.org/abs/2506.17693v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ACL 2025 (Findings)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ZS-CSD的大规模、高质量零样本对话立场检测数据集，并基于此数据集提出了SITPCL模型，实现了零样本对话立场检测的基准性能。&lt;h4&gt;背景&lt;/h4&gt;立场检测是识别社交媒体数据中对特定目标的公众意见的任务，随着社交媒体上在线辩论的增加，对话立场检测成为一个关键的研究领域。&lt;h4&gt;目的&lt;/h4&gt;为了解决现有对话立场检测数据集的限制，本文旨在构建一个能够处理大量未见目标的零样本对话立场检测数据集，并提高立场检测模型的性能。&lt;h4&gt;方法&lt;/h4&gt;研究者手动构建了包含280个目标的ZS-CSD数据集，并提出了SITPCL模型，该模型利用原型对比学习来处理说话者交互和目标感知。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，SITPCL模型在零样本对话立场检测中达到了最先进的性能，但F1-macro分数仅为43.81%，表明零样本对话立场检测仍面临挑战。&lt;h4&gt;结论&lt;/h4&gt;SITPCL模型在零样本对话立场检测中取得了显著成果，但该领域仍存在持续的挑战，需要进一步的研究和改进。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Stance detection, which aims to identify public opinion towards specifictargets using social media data, is an important yet challenging task. With theincreasing number of online debates among social media users, conversationalstance detection has become a crucial research area. However, existingconversational stance detection datasets are restricted to a limited set ofspecific targets, which constrains the effectiveness of stance detection modelswhen encountering a large number of unseen targets in real-world applications.To bridge this gap, we manually curate a large-scale, high-quality zero-shotconversational stance detection dataset, named ZS-CSD, comprising 280 targetsacross two distinct target types. Leveraging the ZS-CSD dataset, we proposeSITPCL, a speaker interaction and target-aware prototypical contrastivelearning model, and establish the benchmark performance in the zero-shotsetting. Experimental results demonstrate that our proposed SITPCL modelachieves state-of-the-art performance in zero-shot conversational stancedetection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,highlighting the persistent challenges in zero-shot conversational stancedetection.</description>
      <author>example@mail.com (Yuzhe Ding, Kang He, Bobo Li, Li Zheng, Haijun He, Fei Li, Chong Teng, Donghong Ji)</author>
      <guid isPermaLink="false">2506.17693v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Benchmarking Foundation Models and Parameter-Efficient Fine-Tuning for Prognosis Prediction in Medical Imaging</title>
      <link>http://arxiv.org/abs/2506.18434v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一个专门设计的结构化基准，用于评估和比较卷积神经网络和基础模型在预测COVID-19患者临床结果方面的迁移能力，并利用了多样化的公开胸部X射线数据集。&lt;h4&gt;背景&lt;/h4&gt;尽管人工智能在医学影像中的预后预测具有巨大潜力，但其有效应用仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;评估和比较卷积神经网络和基础模型在预测COVID-19患者临床结果方面的迁移能力。&lt;h4&gt;方法&lt;/h4&gt;实验方法广泛探索了一系列微调策略，包括全微调、线性探测等传统方法，以及低秩自适应、BitFit、VeRA和IA3等参数高效微调方法。评估涵盖了多个学习范式，包括全数据场景和更符合临床实际的少样本学习设置。&lt;h4&gt;主要发现&lt;/h4&gt;通过实施大规模的比较分析，涉及各种预训练模型，包括在大型数据集上预训练的通用架构如CLIP和DINOv2，以及针对生物医学的模型如MedCLIP、BioMedCLIP和PubMedCLIP，严格评估了每个模型在严重数据稀缺和明显类别不平衡条件下有效适应和泛化到预后任务的能力。&lt;h4&gt;结论&lt;/h4&gt;该基准旨在捕捉预后任务中常见的临界条件，包括数据集大小和类别分布的变化，为每种微调策略的优缺点提供详细见解。广泛的评估旨在为现实世界中临床预后预测工作流程中稳健、高效和可泛化的AI驱动解决方案的部署和应用提供信息。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人工智能（AI）在改善医学影像中的预后预测方面具有巨大的潜力，但其有效应用仍然具有挑战性。在这项工作中，我们介绍了一个专门设计的结构化基准，用于评估和比较卷积神经网络和基础模型在预测COVID-19患者临床结果方面的迁移能力，利用了多样化的公开胸部X射线数据集。我们的实验方法广泛探索了一系列微调策略，包括全微调、线性探测等传统方法，以及低秩自适应、BitFit、VeRA和IA3等参数高效微调方法。评估涵盖了多个学习范式，包括全数据场景和更符合临床实际的少样本学习设置。通过实施大规模的比较分析，涉及各种预训练模型，包括在大型数据集上预训练的通用架构如CLIP和DINOv2，以及针对生物医学的模型如MedCLIP、BioMedCLIP和PubMedCLIP，严格评估了每个模型在严重数据稀缺和明显类别不平衡条件下有效适应和泛化到预后任务的能力。该基准旨在捕捉预后任务中常见的临界条件，包括数据集大小和类别分布的变化，为每种微调策略的优缺点提供详细见解。广泛的评估旨在为现实世界中临床预后预测工作流程中稳健、高效和可泛化的AI驱动解决方案的部署和应用提供信息。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Artificial Intelligence (AI) holds significant promise for improvingprognosis prediction in medical imaging, yet its effective application remainschallenging. In this work, we introduce a structured benchmark explicitlydesigned to evaluate and compare the transferability of Convolutional NeuralNetworks and Foundation Models in predicting clinical outcomes in COVID-19patients, leveraging diverse publicly available Chest X-ray datasets. Ourexperimental methodology extensively explores a wide set of fine-tuningstrategies, encompassing traditional approaches such as Full Fine-Tuning andLinear Probing, as well as advanced Parameter-Efficient Fine-Tuning methodsincluding Low-Rank Adaptation, BitFit, VeRA, and IA3. The evaluations wereconducted across multiple learning paradigms, including both extensivefull-data scenarios and more clinically realistic Few-Shot Learning settings,which are critical for modeling rare disease outcomes and rapidly emerginghealth threats. By implementing a large-scale comparative analysis involving adiverse selection of pretrained models, including general-purpose architecturespretrained on large-scale datasets such as CLIP and DINOv2, tobiomedical-specific models like MedCLIP, BioMedCLIP, and PubMedCLIP, werigorously assess each model's capacity to effectively adapt and generalize toprognosis tasks, particularly under conditions of severe data scarcity andpronounced class imbalance. The benchmark was designed to capture criticalconditions common in prognosis tasks, including variations in dataset size andclass distribution, providing detailed insights into the strengths andlimitations of each fine-tuning strategy. This extensive and structuredevaluation aims to inform the practical deployment and adoption of robust,efficient, and generalizable AI-driven solutions in real-world clinicalprognosis prediction workflows.</description>
      <author>example@mail.com (Filippo Ruffini, Elena Mulero Ayllon, Linlin Shen, Paolo Soda, Valerio Guarrasi)</author>
      <guid isPermaLink="false">2506.18434v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model</title>
      <link>http://arxiv.org/abs/2506.17873v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SurgVidLM是一个视频语言模型，旨在解决全范围和细粒度手术视频理解任务，在医疗领域展现出巨大潜力。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在医疗领域展现出潜力，视频大型语言模型（Vid-LLMs）在捕捉手术复杂信息序列方面成为一个有前景的方法。&lt;h4&gt;目的&lt;/h4&gt;提出SurgVidLM来解决细粒度手术视频理解任务，填补该领域Vid-LLMs的空白。&lt;h4&gt;方法&lt;/h4&gt;构建SVU-31K数据集，包含超过31K个视频指令对，采用StageFocus机制和Multi-frequency Fusion Attention技术进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;SurgVidLM在全面和细粒度视频理解任务中显著优于现有Vid-LLMs，显示出在捕捉复杂手术背景方面的优越能力。&lt;h4&gt;结论&lt;/h4&gt;SurgVidLM为手术视频理解提供了有效的解决方案，有助于提高对手术过程和细节的分析能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in Multimodal Large Language Models have demonstrated greatpotential in the medical domain, facilitating users to understand surgicalscenes and procedures. Beyond image-based methods, the exploration of VideoLarge Language Models (Vid-LLMs) has emerged as a promising avenue forcapturing the complex sequences of information involved in surgery. However,there is still a lack of Vid-LLMs specialized for fine-grained surgical videounderstanding tasks, which is crucial for analyzing specific processes ordetails within a surgical procedure. To bridge this gap, we propose SurgVidLM,the first video language model designed to address both full and fine-grainedsurgical video comprehension. To train our SurgVidLM, we construct the SVU-31Kdataset which consists of over 31K video-instruction pairs, enabling bothholistic understanding and detailed analysis of surgical procedures.Furthermore, we introduce the StageFocus mechanism which is a two-stageframework performing the multi-grained, progressive understanding of surgicalvideos. We also develop the Multi-frequency Fusion Attention to effectivelyintegrate low and high-frequency visual tokens, ensuring the retention ofcritical information. Experimental results demonstrate that SurgVidLMsignificantly outperforms state-of-the-art Vid-LLMs in both full andfine-grained video understanding tasks, showcasing its superior capability incapturing complex procedural contexts.</description>
      <author>example@mail.com (Guankun Wang, Wenjin Mo, Junyi Wang, Long Bai, Kun Yuan, Ming Hu, Jinlin Wu, Junjun He, Yiming Huang, Nicolas Padoy, Zhen Lei, Hongbin Liu, Nassir Navab, Hongliang Ren)</author>
      <guid isPermaLink="false">2506.17873v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Deep Supervised LSTM for 3D morphology estimation from Multi-View RGB Images of Wheat Spikes</title>
      <link>http://arxiv.org/abs/2506.18060v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages, 13 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了从二维RGB图像中估计三维形态特征的方法，并提出了一个神经网络模型，通过深度监督技术提高了体积估计的准确性。&lt;h4&gt;背景&lt;/h4&gt;由于深度信息丢失、投影畸变和遮挡，从二维RGB图像中估计三维形态特征存在固有挑战。&lt;h4&gt;目的&lt;/h4&gt;研究多种非破坏性体积估计方法，以用于小麦穗的体积估计，并验证神经网络方法的有效性。&lt;h4&gt;方法&lt;/h4&gt;使用RGB图像序列和结构光3D扫描作为基准，提出了一种结合DINOv2和单向LSTM网络的神经网络方法，通过深度监督提高模型的泛化能力。&lt;h4&gt;主要发现&lt;/h4&gt;深度监督模型在室内六视图图像上达到了6.46%的平均绝对百分比误差（MAPE），优于基于面积的投影和基于轴对齐横截面的几何重建方法。在基于现场的单图像数据上微调模型，实现了领域自适应，MAPE为10.82%。&lt;h4&gt;结论&lt;/h4&gt;对象形状对体积预测准确性有显著影响，与深度学习方法相比，几何方法在处理不规则几何形状（如小麦穗）时面临更大的挑战。&lt;h4&gt;翻译&lt;/h4&gt;摘要：从二维RGB图像中估计三维形态特征存在固有挑战，包括深度信息丢失、投影畸变和遮挡。在本研究中，我们探索了多种非破坏性体积估计方法，使用RGB图像序列和结构光3D扫描作为基准。由于穗的复杂几何形状，我们提出了一种神经网络方法，用于2D图像中的体积估计，结合了自监督视觉Transformer DINOv2和一个单向长短期记忆（LSTM）网络。通过深度监督，模型能够学习更鲁棒的中层表示，从而增强了其在不同评估序列上的泛化能力。我们将我们的模型与两个传统基线进行了基准测试：基于面积的投影和基于轴对齐横截面的几何重建。我们的深度监督模型在室内六视图图像上实现了6.46%的平均绝对百分比误差（MAPE），优于面积（9.36%）和几何（13.98%）基线。在基于现场的单图像数据上微调模型，实现了领域自适应，MAPE为10.82%。我们证明了对象形状对体积预测准确性有显著影响，与我们的深度学习方法相比，几何方法在处理不规则几何形状（如小麦穗）时面临更大的挑战。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating three-dimensional morphological traits from two-dimensional RGBimages presents inherent challenges due to the loss of depth information,projection distortions, and occlusions under field conditions. In this work, weexplore multiple approaches for non-destructive volume estimation of wheatspikes, using RGB image sequences and structured-light 3D scans as ground truthreferences. Due to the complex geometry of the spikes, we propose a neuralnetwork approach for volume estimation in 2D images, employing a transferlearning pipeline that combines DINOv2, a self-supervised Vision Transformer,with a unidirectional Long Short-Term Memory (LSTM) network. By using deepsupervision, the model is able to learn more robust intermediaterepresentations, which enhances its generalisation ability across varyingevaluation sequences. We benchmark our model against two conventionalbaselines: a 2D area-based projection and a geometric reconstruction usingaxis-aligned cross-sections. Our deep supervised model achieves a mean absolutepercentage error (MAPE) of 6.46% on six-view indoor images, outperforming thearea (9.36%) and geometric (13.98%) baselines. Fine-tuning the model onfield-based single-image data enables domain adaptation, yielding a MAPE of10.82%. We demonstrate that object shape significantly impacts volumeprediction accuracy, with irregular geometries such as wheat spikes posinggreater challenges for geometric methods compared to our deep learningapproach.</description>
      <author>example@mail.com (Olivia Zumsteg, Nico Graf, Aaron Haeusler, Norbert Kirchgessner, Nicola Storni, Lukas Roth, Andreas Hund)</author>
      <guid isPermaLink="false">2506.18060v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Multimodal Visual Image Based User Association and Beamforming Using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.18218v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种利用多模态数据的方法，通过结合视觉图像和射频（RF）导频来优化下行无线蜂窝网络中的用户关联和波束成形，以满足最大-最小公平性准则。该方法旨在减少对大量导频传输的依赖，提高系统性能。&lt;h4&gt;背景&lt;/h4&gt;传统的无线系统参数优化方法通常基于信道状态信息（CSI），但获取准确的CSI需要大量的导频传输，这会导致开销和延迟增加。此外，用户关联和波束成形的优化是一个离散的非凸优化问题，难以解析求解。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过结合视觉图像和射频导频数据，以优化用户关联和波束成形，同时减少对大量导频传输的依赖。&lt;h4&gt;方法&lt;/h4&gt;本文采用了一种基于学习的方法，包括一个用于从图像中估计用户位置的检测神经网络，以及两个图神经网络（GNNs），分别用于提取基于位置信息和接收到的导频的系统优化特征。然后，构建了一个多模态GNN来整合这些特征，以实现用户关联和波束成形的联合优化。&lt;h4&gt;主要发现&lt;/h4&gt;仿真结果表明，所提出的方法在性能上优于仅基于RF导频的传统方法，同时具有低计算复杂度、可解释性和可推广性。&lt;h4&gt;结论&lt;/h4&gt;该方法是一种有效的解决方案，可以减少对大量导频传输的依赖，同时提高下行无线蜂窝网络中的用户关联和波束成形性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper proposes an approach that leverages multimodal data by integratingvisual images with radio frequency (RF) pilots to optimize user association andbeamforming in a downlink wireless cellular network under a max-min fairnesscriterion. Traditional methods typically optimize wireless system parametersbased on channel state information (CSI). However, obtaining accurate CSIrequires extensive pilot transmissions, which lead to increased overhead andlatency. Moreover, the optimization of user association and beamforming is adiscrete and non-convex optimization problem, which is challenging to solveanalytically. In this paper, we propose to incorporate visual camera data inaddition to the RF pilots to perform the joint optimization of user associationand beamforming. The visual image data helps enhance channel awareness, therebyreducing the dependency on extensive pilot transmissions for systemoptimization. We employ a learning-based approach based on using first adetection neural network that estimates user locations from images, andsubsequently two graph neural networks (GNNs) that extract features for systemoptimization based on the location information and the received pilots,respectively. Then, a multimodal GNN is constructed to integrate the featuresfor the joint optimization user association and beamforming. Simulation resultsdemonstrate that the proposed method achieves superior performance, whilehaving low computational complexity and being interpretable and generalizable,making it an effective solution as compared to traditional methods based onlyon RF pilots.</description>
      <author>example@mail.com (Yinghan Li, Yiming Liu, Wei Yu)</author>
      <guid isPermaLink="false">2506.18218v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Reinforcing User Interest Evolution in Multi-Scenario Learning for recommender systems</title>
      <link>http://arxiv.org/abs/2506.17682v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的强化学习方法，用于多场景下的推荐系统，通过模拟用户兴趣在不同场景中的演变来建模用户偏好，并通过DoubleQ学习和优化对比学习损失来提高预测准确性。&lt;h4&gt;背景&lt;/h4&gt;现实中的推荐系统涉及多种场景，如主页、搜索页面和相关推荐页面，用户在这些场景中的兴趣可能不一致，这给统一建模带来了挑战。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来解决多场景推荐任务中的统一建模问题，并通过提高预测准确性来优化模型性能。&lt;h4&gt;方法&lt;/h4&gt;使用强化学习来模拟用户兴趣的演变，采用DoubleQ学习来增强下一项预测的准确性，并利用Q值优化对比学习损失。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在多场景推荐任务中优于现有方法，为多场景建模提供了新的视角。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为多场景建模提供了有希望的研究方向，并为未来的研究指明了道路。&lt;h4&gt;翻译&lt;/h4&gt;在现实世界的推荐系统中，用户会参与各种场景，如主页、搜索页面和相关的推荐页面。每个场景都会反映用户关注的不同方面。然而，由于决策过程和偏好表达的不同，用户兴趣在不同场景中可能不一致。这种可变性使得统一建模变得复杂，使得多场景学习成为一个重要的挑战。为了解决这个问题，我们提出了一种新的强化学习方法，通过模拟用户兴趣在多个场景中的演变来建模用户偏好。我们的方法采用DoubleQ学习来提高下一项预测的准确性，并使用Q值优化对比学习损失，以使模型性能更好。实验结果表明，我们的方法在多场景推荐任务中优于最先进的方法。我们的工作为多场景建模提供了新的视角，并突出了未来研究的有希望的方向。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In real-world recommendation systems, users would engage in varietyscenarios, such as homepages, search pages, and related recommendation pages.Each of these scenarios would reflect different aspects users focus on.However, the user interests may be inconsistent in different scenarios, due todifferences in decision-making processes and preference expression. Thisvariability complicates unified modeling, making multi-scenario learning asignificant challenge. To address this, we propose a novel reinforcementlearning approach that models user preferences across scenarios by modelinguser interest evolution across multiple scenarios. Our method employs DoubleQ-learning to enhance next-item prediction accuracy and optimizes contrastivelearning loss using Q-value to make model performance better. Experimentalresults demonstrate that our approach surpasses state-of-the-art methods inmulti-scenario recommendation tasks. Our work offers a fresh perspective onmulti-scenario modeling and highlights promising directions for futureresearch.</description>
      <author>example@mail.com (Zhijian Feng, Wenhao Zheng, Xuanji Xiao)</author>
      <guid isPermaLink="false">2506.17682v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>SafeClick: Error-Tolerant Interactive Segmentation of Any Medical Volumes via Hierarchical Expert Consensus</title>
      <link>http://arxiv.org/abs/2506.18404v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SafeClick是一种基于层次专家共识的容错交互式医学体积分割方法，能够提高基于基础模型的分割性能，尤其是在处理不完美提示时。&lt;h4&gt;背景&lt;/h4&gt;体积医学图像分割模型在临床工作中表现出强大的能力，但分割性能受提示质量影响，临床环境中提供的提示往往不理想。&lt;h4&gt;目的&lt;/h4&gt;为了解决提示质量对分割性能的影响，提出SafeClick方法。&lt;h4&gt;方法&lt;/h4&gt;SafeClick是一个插件式模块，兼容SAM 2和MedSAM 2等基础模型。它包含两个主要组件：协作专家层（CEL）和共识推理层（CRL）。CEL通过专门的Transformer模块生成多样化的特征表示，CRL则执行跨引用和自适应整合这些特征。&lt;h4&gt;主要发现&lt;/h4&gt;SafeClick在15个公共数据集上的实验表明，该方法能够持续提高基础模型的性能，特别是在处理不完美提示时效果显著。&lt;h4&gt;结论&lt;/h4&gt;SafeClick能够将分割过程从依赖提示的操作转变为一个鲁棒的框架，即使在用户输入不完美的情况下也能产生准确的结果。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于体积医学图像分割的基座模型已成为临床工作流程中的强大工具，使放射科医生能够通过直观的点击来勾勒感兴趣的区域。虽然这些模型在分割未见过的解剖结构方面表现出有希望的能力，但它们的性能强烈受到提示质量的影响。在临床环境中，放射科医生经常提供次优的提示，这影响了分割的可靠性和准确性。为了解决这一限制，我们提出了SafeClick，这是一种基于层次专家共识的容错交互式医学体积分割方法。SafeClick作为一个即插即用的模块，与SAM 2和MedSAM 2等基础模型兼容。该框架由两个关键组件组成：一个协作专家层（CEL），它通过专门的Transformer模块生成多样化的特征表示；以及一个共识推理层（CRL），它执行这些特征的跨引用和自适应整合。这种架构将分割过程从依赖提示的操作转变为一个鲁棒的框架，能够在不完美的用户输入的情况下产生准确的结果。在15个公共数据集上的大量实验表明，我们的即插即用方法一致地提高了基础模型的性能，特别是在处理不完美的提示时效果显著。源代码可在https://github.com/yifangao112/SafeClick上获得。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models for volumetric medical image segmentation have emerged aspowerful tools in clinical workflows, enabling radiologists to delineateregions of interest through intuitive clicks. While these models demonstratepromising capabilities in segmenting previously unseen anatomical structures,their performance is strongly influenced by prompt quality. In clinicalsettings, radiologists often provide suboptimal prompts, which affectssegmentation reliability and accuracy. To address this limitation, we presentSafeClick, an error-tolerant interactive segmentation approach for medicalvolumes based on hierarchical expert consensus. SafeClick operates as aplug-and-play module compatible with foundation models including SAM 2 andMedSAM 2. The framework consists of two key components: a collaborative expertlayer (CEL) that generates diverse feature representations through specializedtransformer modules, and a consensus reasoning layer (CRL) that performscross-referencing and adaptive integration of these features. This architecturetransforms the segmentation process from a prompt-dependent operation to arobust framework capable of producing accurate results despite imperfect userinputs. Extensive experiments across 15 public datasets demonstrate that ourplug-and-play approach consistently improves the performance of base foundationmodels, with particularly significant gains when working with imperfectprompts. The source code is available athttps://github.com/yifangao112/SafeClick.</description>
      <author>example@mail.com (Yifan Gao, Jiaxi Sheng, Wenbin Wu, Haoyue Li, Yaoxian Dong, Chaoyang Ge, Feng Yuan, Xin Gao)</author>
      <guid isPermaLink="false">2506.18404v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Machine Learning Model Integration with Open World Temporal Logic for Process Automation</title>
      <link>http://arxiv.org/abs/2506.17776v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种将机器学习模型输出与PyReason框架结合的新方法，以解决将感知或提取输出转化为可操作决策的挑战。&lt;h4&gt;背景&lt;/h4&gt;尽管机器学习在提取结构化信息方面取得了进展，但将输出转化为实际决策在复杂操作流程中仍然是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;旨在创建一个强大的系统，通过结合机器学习模型的感知和提取能力以及PyReason的逻辑推理和透明度，来自动化复杂过程。&lt;h4&gt;方法&lt;/h4&gt;该方法将机器学习模型的输出直接与PyReason框架集成，PyReason基于通用注释逻辑，可以无缝地整合来自不同模型的实值输出（如概率、置信度分数），并将它们作为逻辑框架中的真值区间处理。&lt;h4&gt;主要发现&lt;/h4&gt;PyReason提供了在Python中实现的机制，以连续轮询机器学习模型输出，将它们转换为逻辑事实，并动态重新计算最小模型，确保实时自适应决策。&lt;h4&gt;结论&lt;/h4&gt;这种集成在多个领域都有应用，包括制造业、医疗保健和业务运营。&lt;h4&gt;翻译&lt;/h4&gt;最近机器学习（ML）的进步产生了能够从各种复杂数据源中提取结构化信息的有力模型。然而，一个重大的挑战在于将这些感知或提取输出转化为复杂操作流程中的可操作、合理的决策。为了解决这些挑战，本文介绍了一种新方法，该方法将各种机器学习模型的输出直接与PyReason框架集成，PyReason是一个开放世界的时态逻辑编程推理引擎。PyReason基于通用注释逻辑的基础，允许无缝地整合来自不同模型的实值输出（例如，概率、置信度分数），将其作为其逻辑框架中的真值区间处理。关键的是，PyReason提供了在Python中实现的机制，以连续轮询机器学习模型输出，将它们转换为逻辑事实，并动态重新计算最小模型，确保实时自适应决策。此外，它对时态推理、知识图集成和完全可解释的界面跟踪的原生支持，使得对时间敏感的过程数据和现有组织知识的复杂分析成为可能。通过结合机器学习模型的感知和提取能力与PyReason的逻辑推理和透明度，我们旨在创建一个强大的系统，用于自动化复杂过程。这种集成在多个领域都有应用，包括制造业、医疗保健和业务运营。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advancements in Machine Learning (ML) have yielded powerful modelscapable of extracting structured information from diverse and complex datasources. However, a significant challenge lies in translating these perceptualor extractive outputs into actionable, reasoned decisions within complexoperational workflows. To address these challenges, this paper introduces anovel approach that integrates the outputs from various machine learning modelsdirectly with the PyReason framework, an open-world temporal logic programmingreasoning engine. PyReason's foundation in generalized annotated logic allowsfor the seamless incorporation of real-valued outputs (e.g., probabilities,confidence scores) from diverse ML models, treating them as truth intervalswithin its logical framework. Crucially, PyReason provides mechanisms,implemented in Python, to continuously poll ML model outputs, convert them intological facts, and dynamically recompute the minimal model, ensuring real-tineadaptive decision-making. Furthermore, its native support for temporalreasoning, knowledge graph integration, and fully explainable interface tracesenables sophisticated analysis over time-sensitive process data and existingorganizational knowledge. By combining the strengths of perception andextraction from ML models with the logical deduction and transparency ofPyReason, we aim to create a powerful system for automating complex processes.This integration finds utility across numerous domains, includingmanufacturing, healthcare, and business operations.</description>
      <author>example@mail.com (Dyuman Aditya, Colton Payne, Mario Leiva, Paulo Shakarian)</author>
      <guid isPermaLink="false">2506.17776v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Call Me Maybe: Enhancing JavaScript Call Graph Construction using Graph Neural Networks</title>
      <link>http://arxiv.org/abs/2506.18191v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GRAPHIA的方法，用于提高JavaScript程序中调用图构建的准确性，通过利用图神经网络来预测调用关系，从而识别出现有工具遗漏的调用边。&lt;h4&gt;背景&lt;/h4&gt;静态分析在发现包括安全漏洞在内的bug中扮演关键角色。构建准确的调用图是静态分析中的一个关键步骤。然而，由于难以分析的语言特性，现有的JavaScript调用图构建算法既不严格也不完整。&lt;h4&gt;目的&lt;/h4&gt;提高JavaScript调用图构建的准确性，减少分析过程中的人工工作量。&lt;h4&gt;方法&lt;/h4&gt;将问题建模为整个程序图的链接预测问题，使用多种边类型进行丰富的表示。GRAPHIA利用图神经网络来建模代码元素之间的非局部关系。具体来说，使用基于语法和语义的边组合来表示JavaScript程序。GRAPHIA可以从不完美的标签中学习，包括来自现有工具的静态调用边和来自测试的动态边。&lt;h4&gt;主要发现&lt;/h4&gt;GRAPHIA在50个流行的JavaScript库上进行了大规模评估，这些库包含163K个调用边（150K静态和13K动态）。GRAPHIA构建的程序图包含6.6M个结构和386K个语义边。在超过42%的未解决案例中，将正确目标作为最高候选者，在72%的案例中位于前5位，从而减少了分析所需的人工工作量。&lt;h4&gt;结论&lt;/h4&gt;学习型方法可以提高JavaScript调用图构建的召回率。这是首次将基于GNN的链接预测应用于全多文件程序图进行过程间分析的工作。&lt;h4&gt;翻译&lt;/h4&gt;静态分析在发现bug，包括安全问题中起着关键作用。在静态分析中，构建准确的调用图是关键步骤之一。然而，由于难以分析的语言特性，现有的JavaScript调用图构建算法既不严格也不完整。先前的工作表明，即使是高级解决方案也会产生错误边并错过有效的边。在这项工作中，我们通过识别遗漏的调用边来辅助这些工具。我们的主要想法是将问题建模为整个程序图的链接预测问题，使用多种边类型进行丰富的表示。我们的方法，GRAPHIA，利用图神经网络的最新进展来建模代码元素之间的非局部关系。具体来说，我们提出使用基于语法和语义的边组合来表示JavaScript程序。GRAPHIA可以从不完美的标签中学习，包括来自现有工具的静态调用边和来自测试的动态边，无论是来自同一项目还是不同项目。由于调用图是稀疏的，标准的机器学习指标如ROC并不适用。相反，我们通过为每个未解决的调用点对函数定义进行排序来评估GRAPHIA。我们在50个流行的JavaScript库上进行了大规模评估，这些库包含163K个调用边（150K静态和13K动态）。GRAPHIA构建了包含6.6M个结构和386K个语义边的程序图。在超过42%的未解决案例中，将正确目标作为最高候选者，在72%的案例中位于前5位，从而减少了分析所需的人工工作量。我们的结果表明，基于学习的方法可以提高JavaScript调用图构建的召回率。据我们所知，这是首次将基于GNN的链接预测应用于全多文件程序图进行过程间分析的工作。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Static analysis plays a key role in finding bugs, including security issues.A critical step in static analysis is building accurate call graphs that modelfunction calls in a program. However, due to hard-to-analyze language features,existing call graph construction algorithms for JavaScript are neither soundnor complete. Prior work shows that even advanced solutions produce false edgesand miss valid ones. In this work, we assist these tools by identifying missedcall edges. Our main idea is to frame the problem as link prediction on fullprogram graphs, using a rich representation with multiple edge types. Ourapproach, GRAPHIA, leverages recent advances in graph neural networks to modelnon-local relationships between code elements. Concretely, we proposerepresenting JavaScript programs using a combination of syntactic- andsemantic-based edges. GRAPHIA can learn from imperfect labels, including staticcall edges from existing tools and dynamic edges from tests, either from thesame or different projects. Because call graphs are sparse, standard machinelearning metrics like ROC are not suitable. Instead, we evaluate GRAPHIA byranking function definitions for each unresolved call site. We conduct alarge-scale evaluation on 50 popular JavaScript libraries with 163K call edges(150K static and 13K dynamic). GRAPHIA builds program graphs with 6.6Mstructural and 386K semantic edges. It ranks the correct target as the topcandidate in over 42% of unresolved cases and within the top 5 in 72% of cases,reducing the manual effort needed for analysis. Our results show thatlearning-based methods can improve the recall of JavaScript call graphconstruction. To our knowledge, this is the first work to apply GNN-based linkprediction to full multi-file program graphs for interprocedural analysis.</description>
      <author>example@mail.com (Masudul Hasan Masud Bhuiyan, Gianluca De Stefano, Giancarlo Pellegrino, Cristian-Alexandru Staicu)</author>
      <guid isPermaLink="false">2506.18191v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning</title>
      <link>http://arxiv.org/abs/2506.17562v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为FedMRG的框架，用于利用联邦学习（FL）在多个中心进行隐私保护的医疗报告生成（MRG）模型的开发。&lt;h4&gt;背景&lt;/h4&gt;LLMs在医疗报告生成方面具有巨大潜力，但其开发需要大量的医疗图像报告对，这些数据通常分散在多个中心，而集中这些数据因隐私法规而极具挑战性。&lt;h4&gt;目的&lt;/h4&gt;旨在解决多中心数据集中通信效率低的挑战，实现隐私保护的多中心LLM驱动MRG模型的开发。&lt;h4&gt;方法&lt;/h4&gt;FedMRG框架通过以下方法实现这一目标：(1) 使用低秩分解来减少参数更新的通信开销；(2) 在MRG编码器中采用客户端感知的对比学习，结合诊断驱动的提示；(3) 在MRG解码器中使用双重适配器互增强机制。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的评估，证明了FedMRG的泛化能力和适应性，能够在保持通信效率的同时，利用多中心数据生成临床准确的报告。&lt;h4&gt;结论&lt;/h4&gt;FedMRG框架能够有效解决多中心数据集中通信效率低的挑战，具有在保持通信效率的同时，利用多中心数据生成临床准确报告的潜力。&lt;h4&gt;翻译&lt;/h4&gt;LLMs have demonstrated significant potential in Medical Report Generation (MRG), yet their development requires large amounts of medical image-report pairs, which are commonly scattered across multiple centers. Centralizing these data is exceptionally challenging due to privacy regulations, thereby impeding model development and broader adoption of LLM-driven MRG models. To address this challenge, we present FedMRG, the first framework that leverages Federated Learning (FL) to enable privacy-preserving, multi-center development of LLM-driven MRG models, specifically designed to overcome the critical challenge of communication-efficient LLM training under multi-modal data heterogeneity. To start with, our framework tackles the fundamental challenge of communication overhead in FL-LLM tuning by employing low-rank factorization to efficiently decompose parameter updates, significantly reducing gradient transmission costs and making LLM-driven MRG feasible in bandwidth-constrained FL settings. Furthermore, we observed the dual heterogeneity in MRG under the FL scenario: varying image characteristics across medical centers, as well as diverse reporting styles and terminology preferences. To address this, we further enhance FedMRG with (1) client-aware contrastive learning in the MRG encoder, coupled with diagnosis-driven prompts, which capture both globally generalizable and locally distinctive features while maintaining diagnostic accuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoder that harmonizes generic and specialized adapters to address variations in reporting styles and terminology. Through extensive evaluation of our established FL-MRG benchmark, we demonstrate the generalizability and adaptability of FedMRG, underscoring its potential in harnessing multi-center data and generating clinically accurate reports while maintaining communication efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LLMs have demonstrated significant potential in Medical Report Generation(MRG), yet their development requires large amounts of medical image-reportpairs, which are commonly scattered across multiple centers. Centralizing thesedata is exceptionally challenging due to privacy regulations, thereby impedingmodel development and broader adoption of LLM-driven MRG models. To addressthis challenge, we present FedMRG, the first framework that leverages FederatedLearning (FL) to enable privacy-preserving, multi-center development ofLLM-driven MRG models, specifically designed to overcome the critical challengeof communication-efficient LLM training under multi-modal data heterogeneity.To start with, our framework tackles the fundamental challenge of communicationoverhead in FL-LLM tuning by employing low-rank factorization to efficientlydecompose parameter updates, significantly reducing gradient transmission costsand making LLM-driven MRG feasible in bandwidth-constrained FL settings.Furthermore, we observed the dual heterogeneity in MRG under the FL scenario:varying image characteristics across medical centers, as well as diversereporting styles and terminology preferences. To address this, we furtherenhance FedMRG with (1) client-aware contrastive learning in the MRG encoder,coupled with diagnosis-driven prompts, which capture both globallygeneralizable and locally distinctive features while maintaining diagnosticaccuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoderthat harmonizes generic and specialized adapters to address variations inreporting styles and terminology. Through extensive evaluation of ourestablished FL-MRG benchmark, we demonstrate the generalizability andadaptability of FedMRG, underscoring its potential in harnessing multi-centerdata and generating clinically accurate reports while maintaining communicationefficiency.</description>
      <author>example@mail.com (Haoxuan Che, Haibo Jin, Zhengrui Guo, Yi Lin, Cheng Jin, Hao Chen)</author>
      <guid isPermaLink="false">2506.17562v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Classification of Tents in Street Bazaars Using CNN</title>
      <link>http://arxiv.org/abs/2506.17946v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该研究提出了一种改进的深度学习模型，用于对街头集市中的帐篷进行分类，比较了自定义卷积神经网络（CNN）与EfficientNetB0的性能。&lt;h4&gt;背景&lt;/h4&gt;街头集市在许多地区是重要的经济中心，但其无序性给市场基础设施（如帐篷）的自动分类带来了重大挑战。&lt;h4&gt;目的&lt;/h4&gt;研究旨在开发一种高效的分类方法，以解决街头集市帐篷自动分类的难题。&lt;h4&gt;方法&lt;/h4&gt;研究基于扩展的126张原始照片数据集，通过图像增强生成额外图像。使用多种性能指标（如准确率、精确率、召回率、F1分数和平均精度均值）来评估模型性能。&lt;h4&gt;主要发现&lt;/h4&gt;CNN自定义模型达到了92.8%的准确率，而EfficientNetB0达到了98.4%的准确率，证明了迁移学习在集市图像分类中的有效性。&lt;h4&gt;结论&lt;/h4&gt;使用预训练模型如EfficientNetB0可以显著提高分类准确性和泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;本研究提出了一种改进的深度学习模型，用于对街头集市中的帐篷进行分类，比较了自定义卷积神经网络（CNN）与EfficientNetB0。这是市场组织中的一个关键任务，但过去的手动方法效率低下。街头集市在许多地区是重要的经济中心，但其无序性给市场基础设施（如帐篷）的自动分类带来了重大挑战。在吉尔吉斯斯坦，超过四分之一的国内生产总值来自集市。虽然卷积神经网络（CNN）已被广泛应用于物体识别，但其在集市特定任务中的应用仍处于探索阶段。在这里，我们通过在扩展的126张原始照片数据集上训练，并通过对这些照片进行增强来生成额外的图像，改进了我们的原始方法。这个数据集可以在Kaggle上公开下载。使用多种性能指标，如准确率、精确率、召回率、F1分数和平均精度均值（mAP），对模型进行了比较评估，提供了对分类性能的更全面分析。结果表明，CNN自定义模型达到了92.8%的准确率，而EfficientNetB0则达到了98.4%的准确率，这证实了迁移学习在集市图像分类中的有效性。此外，通过分析混淆矩阵，揭示了每个模型的弱点和优势。这些发现表明，使用预训练模型如EfficientNetB0可以显著提高分类准确性和泛化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This research paper proposes an improved deep learning model for classifyingtents in street bazaars, comparing a custom Convolutional Neural Network (CNN)with EfficientNetB0. This is a critical task for market organization with atent classification, but manual methods in the past have been inefficient.Street bazaars represent a vital economic hub in many regions, yet theirunstructured nature poses significant challenges for the automatedclassification of market infrastructure, such as tents. In Kyrgyzstan, morethan a quarter of the country's GDP is derived from bazaars. While CNNs havebeen widely applied to object recognition, their application to bazaar-specifictasks remains underexplored. Here, we build upon our original approach bytraining on an extended set of 126 original photographs that were augmented togenerate additional images. This dataset is publicly available for download onKaggle. A variety of performance metrics, such as accuracy, precision, recall,F1 score, and mean average precision (mAP), were used to assess the modelscomparatively, providing a more extensive analysis of classificationperformance.  The results show that the CNN custom model achieved 92.8% accuracy, andEfficientNetB0 showed 98.4% accuracy results, confirming the effectiveness oftransfer learning in the bazaar image classification. Also, when analyzing theconfusion matrix, the analysis reveals the weaknesses and strengths of eachmodel. These findings suggest that using a pre-trained model such asEfficientNetB0 significantly improves classification accuracy andgeneralization.</description>
      <author>example@mail.com (Azamat Ibragimov, Ruslan Isaev, Remudin Reshid Mekuria, Gulnaz Gimaletdinova, Dim Shaiakhmetov)</author>
      <guid isPermaLink="false">2506.17946v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TROJAN-GUARD: Hardware Trojans Detection Using GNN in RTL Designs</title>
      <link>http://arxiv.org/abs/2506.17894v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于检测大规模芯片设计中的硬件木马，通过生成大型设计的图嵌入并采用针对硬件木马检测优化的图神经网络模型，以及通过模型量化技术提高训练和推理效率。&lt;h4&gt;背景&lt;/h4&gt;芯片制造过程复杂，使用大量不受信任的第三方工具和设计，增加了硬件木马的风险，对国家安全、经济和个人隐私构成威胁。&lt;h4&gt;目的&lt;/h4&gt;提出一种有效且高效的硬件木马检测方法，用于大规模芯片设计。&lt;h4&gt;方法&lt;/h4&gt;提出了一种新的框架，该框架生成大型设计的图嵌入，并整合了针对硬件木马检测优化的多种图神经网络模型。此外，通过实现模型量化，引入了特定领域的技术，以提高训练和推理的效率。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在自定义数据集上的评估结果显示，检测精度达到98.66%，召回率达到92.30%，证明了该方法在检测大规模芯片设计中的硬件木马方面的有效性和效率。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的方法能够有效检测大规模芯片设计中的硬件木马，为提高芯片安全性和可靠性提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：芯片制造是一个复杂的过程，为了实现更快的上市时间，越来越多的不受信任的第三方工具和设计被利用。使用这些不受信任的第三方知识产权（IP）和工具增加了对手插入硬件木马（HT）的风险。硬件木马的秘密性质对网络空间构成重大威胁，可能对国家安全、经济和个人隐私造成严重后果。已经提出了许多基于图神经网络（GNN）的硬件木马检测方法。然而，由于它们依赖于使用较小设计进行训练，因此在较大设计中表现不佳。此外，这些方法没有探索适合硬件木马检测的不同GNN模型，也没有提供有效的训练和推理过程。我们提出了一种新颖的框架，该框架为大型设计（例如，RISC-V）生成图嵌入，并整合了针对硬件木马检测优化的各种GNN模型。此外，我们的框架通过实现模型量化引入了特定领域的技术，以实现高效的训练和推理。模型量化降低了权重的精度，降低了计算需求，提高了处理速度，而不会严重影响检测精度。我们使用自定义数据集评估了我们的框架，我们的结果表明，精度为98.66%，召回率（真正率）为92.30%，突出了我们在检测大规模芯片设计中的硬件木马方面的方法的有效性和效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Chip manufacturing is a complex process, and to achieve a faster time tomarket, an increasing number of untrusted third-party tools and designs fromaround the world are being utilized. The use of these untrusted third partyintellectual properties (IPs) and tools increases the risk of adversariesinserting hardware trojans (HTs). The covert nature of HTs poses significantthreats to cyberspace, potentially leading to severe consequences for nationalsecurity, the economy, and personal privacy. Many graph neural network(GNN)-based HT detection methods have been proposed. However, they performpoorly on larger designs because they rely on training with smaller designs.Additionally, these methods do not explore different GNN models that arewell-suited for HT detection or provide efficient training and inferenceprocesses. We propose a novel framework that generates graph embeddings forlarge designs (e.g., RISC-V) and incorporates various GNN models tailored forHT detection. Furthermore, our framework introduces domain-specific techniquesfor efficient training and inference by implementing model quantization. Modelquantization reduces the precision of the weights, lowering the computationalrequirements, enhancing processing speed without significantly affectingdetection accuracy. We evaluate our framework using a custom dataset, and ourresults demonstrate a precision of 98.66% and a recall (true positive rate) of92.30%, highlighting the effectiveness and efficiency of our approach indetecting hardware trojans in large-scale chip designs</description>
      <author>example@mail.com (Kiran Thorat, Amit Hasan, Caiwen Ding, Zhijie Shi)</author>
      <guid isPermaLink="false">2506.17894v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Rethinking the Role of Operating Conditions for Learning-based Multi-condition Fault Diagnosis</title>
      <link>http://arxiv.org/abs/2506.17740v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 6 figures, conference&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了多条件故障诊断问题，针对不同操作条件下的数据分布差异对模型性能的影响，提出了一个两阶段的诊断框架，以提高在操作条件影响显著情况下的故障诊断性能。&lt;h4&gt;背景&lt;/h4&gt;多条件故障诊断在工业系统中普遍存在，对传统诊断方法提出了挑战。由于不同操作条件下的数据分布差异，单一条件训练的模型在应用于其他条件时性能会下降。&lt;h4&gt;目的&lt;/h4&gt;提高在操作条件影响显著情况下的故障诊断性能。&lt;h4&gt;方法&lt;/h4&gt;研究了现有端到端域泛化方法在可变速度和可变负载场景下的性能，并提出了一个结合域泛化编码器和重训练策略的两阶段诊断框架。&lt;h4&gt;主要发现&lt;/h4&gt;直接应用域泛化方法可能导致模型学习条件特定信息，从而降低其泛化能力。&lt;h4&gt;结论&lt;/h4&gt;提出的两阶段诊断框架能够提取条件不变故障特征，同时减轻对源域的潜在过拟合，有效提高了故障诊断性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多条件故障诊断在工业系统中非常普遍，对传统的诊断方法提出了巨大的挑战。不同操作条件下的数据分布差异会在模型仅在一种条件下训练后应用于其他条件时降低模型性能。随着深度学习的发展，迁移学习被引入到故障诊断领域，作为解决多条件故障诊断问题的范式。在这些方法中，域泛化方法可以通过提取条件不变故障特征来处理复杂场景。尽管许多研究已经考虑了特定多条件场景下的故障诊断，但操作条件对故障信息影响的研究却很少，这是至关重要的。然而，操作条件对故障信息影响的研究却很少，这是至关重要的。当操作条件对故障特征有显著影响时，直接应用域泛化方法可能会导致模型学习条件特定信息，从而降低其泛化能力。本文通过在真实世界齿轮箱上的多个实验，研究了现有端到端域泛化方法在不同条件下的性能，特别是在可变速度和可变负载场景下。此外，提出了一种两阶段的诊断框架，旨在提高在操作条件影响显著情况下的故障诊断性能。通过结合域泛化编码器和重训练策略，该框架能够提取条件不变故障特征，同时减轻对源域的潜在过拟合。在真实世界齿轮箱数据集上进行了几个实验，以验证所提出方法的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multi-condition fault diagnosis is prevalent in industrial systems andpresents substantial challenges for conventional diagnostic approaches. Thediscrepancy in data distributions across different operating conditionsdegrades model performance when a model trained under one condition is appliedto others. With the recent advancements in deep learning, transfer learning hasbeen introduced to the fault diagnosis field as a paradigm for addressingmulti-condition fault diagnosis. Among these methods, domain generalizationapproaches can handle complex scenarios by extracting condition-invariant faultfeatures. Although many studies have considered fault diagnosis in specificmulti-condition scenarios, the extent to which operating conditions affectfault information has been scarcely studied, which is crucial. However, theextent to which operating conditions affect fault information has been scarcelystudied, which is crucial. When operating conditions have a significant impacton fault features, directly applying domain generalization methods may lead themodel to learn condition-specific information, thereby reducing its overallgeneralization ability. This paper investigates the performance of existingend-to-end domain generalization methods under varying conditions, specificallyin variable-speed and variable-load scenarios, using multiple experiments on areal-world gearbox. Additionally, a two-stage diagnostic framework is proposed,aiming to improve fault diagnosis performance under scenarios with significantoperating condition impacts. By incorporating a domain-generalized encoder witha retraining strategy, the framework is able to extract condition-invariantfault features while simultaneously alleviating potential overfitting to thesource domain. Several experiments on a real-world gearbox dataset areconducted to validate the effectiveness of the proposed approach.</description>
      <author>example@mail.com (Pengyu Han, Zeyi Liu, Shijin Chen, Dongliang Zou, Xiao He)</author>
      <guid isPermaLink="false">2506.17740v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Numerical simulation of transient heat conduction with moving heat source using Physics Informed Neural Networks</title>
      <link>http://arxiv.org/abs/2506.17726v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文采用物理信息神经网络（PINNs）对涉及移动源的传热问题进行数值模拟，并提出了一种新的训练方法以减少计算工作量。&lt;h4&gt;背景&lt;/h4&gt;传热问题中涉及移动源时，计算复杂度较高。&lt;h4&gt;目的&lt;/h4&gt;降低计算复杂度，提高数值模拟的效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种使用连续时间步进和迁移学习的新训练方法，将时间间隔划分为更小的区间，并在单个网络上对每个时间间隔进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;该方法能够计算较大的时间间隔，同时不增加网络本身的复杂性，并在估计均匀介质中移动热源的温度分布时，与传统的有限元方法相比，结果吻合良好。&lt;h4&gt;结论&lt;/h4&gt;所提出的框架在减少计算复杂度的同时，能够有效地进行传热问题的数值模拟。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, the physics informed neural networks (PINNs) is employed for the numerical simulation of heat transfer involving a moving source. To reduce the computational effort, a new training method is proposed that uses a continuous time-stepping through transfer learning. Within this, the time interval is divided into smaller intervals and a single network is initialized. On this single network each time interval is trained with the initial condition for (n+1)th as the solution obtained at nth time increment. Thus, this framework enables the computation of large temporal intervals without increasing the complexity of the network itself. The proposed framework is used to estimate the temperature distribution in a homogeneous medium with a moving heat source. The results from the proposed framework is compared with traditional finite element method and a good agreement is seen.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1002/msd2.70031&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this paper, the physics informed neural networks (PINNs) is employed forthe numerical simulation of heat transfer involving a moving source. To reducethe computational effort, a new training method is proposed that uses acontinuous time-stepping through transfer learning. Within this, the timeinterval is divided into smaller intervals and a single network is initialized.On this single network each time interval is trained with the initial conditionfor (n+1)th as the solution obtained at nth time increment. Thus, thisframework enables the computation of large temporal intervals withoutincreasing the complexity of the network itself. The proposed framework is usedto estimate the temperature distribution in a homogeneous medium with a movingheat source. The results from the proposed framework is compared withtraditional finite element method and a good agreement is seen.</description>
      <author>example@mail.com (Anirudh Kalyan, Sundararajan Natarajan)</author>
      <guid isPermaLink="false">2506.17726v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>BrainSymphony: A Transformer-Driven Fusion of fMRI Time Series and Structural Connectivity</title>
      <link>http://arxiv.org/abs/2506.18314v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 8 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;BrainSymphony是一个轻量级、参数高效的神经影像学基础模型，在预训练于较小的公共数据集上时，仍能达到最先进的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的神经影像学基础模型通常规模巨大且数据密集。&lt;h4&gt;目的&lt;/h4&gt;介绍BrainSymphony模型，该模型在性能上与更大的模型相当，但规模更小。&lt;h4&gt;方法&lt;/h4&gt;BrainSymphony通过并行空间和时间转换流处理功能性MRI数据，并通过Perceiver模块高效地将其转换为统一表示。同时，使用新型带符号图转换器从扩散MRI中建模结构连接。这些强大的、特定于模态的表现通过自适应融合门进行整合。&lt;h4&gt;主要发现&lt;/h4&gt;BrainSymphony在包括分类、预测和无监督网络识别任务在内的各种下游基准测试中，其性能始终优于更大的模型。此外，该模型使用注意力图揭示了独特的外部迷幻神经影像数据集（给药前后）中的大脑动态的新见解。&lt;h4&gt;结论&lt;/h4&gt;BrainSymphony证明了具有结构意识的、多模态的模型可以超越其更大的对手，为计算神经科学领域的研究开辟了更易于访问和更强大的道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Existing foundation models for neuroimaging are often prohibitively large anddata-intensive. We introduce BrainSymphony, a lightweight, parameter-efficientfoundation model that achieves state-of-the-art performance while beingpre-trained on significantly smaller public datasets. BrainSymphony's strongmultimodal architecture processes functional MRI data through parallel spatialand temporal transformer streams, which are then efficiently distilled into aunified representation by a Perceiver module. Concurrently, it modelsstructural connectivity from diffusion MRI using a novel signed graphtransformer to encode the brain's anatomical structure. These powerful,modality-specific representations are then integrated via an adaptive fusiongate. Despite its compact design, our model consistently outperforms largermodels on a diverse range of downstream benchmarks, including classification,prediction, and unsupervised network identification tasks. Furthermore, ourmodel revealed novel insights into brain dynamics using attention maps on aunique external psilocybin neuroimaging dataset (pre- and post-administration).BrainSymphony establishes that architecturally-aware, multimodal models cansurpass their larger counterparts, paving the way for more accessible andpowerful research in computational neuroscience.</description>
      <author>example@mail.com (Moein Khajehnejad, Forough Habibollahi, Adeel Razi)</author>
      <guid isPermaLink="false">2506.18314v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages</title>
      <link>http://arxiv.org/abs/2506.17715v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了在古代语言处理中，尤其是在计算语言学与数字人文交叉领域的古代罗曼语变体中，词性标注的关键影响因素。&lt;h4&gt;背景&lt;/h4&gt;尽管现代大型语言模型在处理古代语言方面取得了显著进展，但在中世纪罗曼语中的应用面临着词汇演变、拼写差异和标注数据稀缺等独特挑战。&lt;h4&gt;目的&lt;/h4&gt;系统地研究跨越不同语料库（包括圣经、圣徒传、医学和饮食领域）的中世纪奥克西塔尼亚语、中世纪西班牙语和中世纪法语文本的词性标注性能的关键决定因素。&lt;h4&gt;方法&lt;/h4&gt;通过严格实验，评估了微调方法、提示工程、模型架构、解码策略和跨语言迁移学习技术对标注准确性的影响。&lt;h4&gt;主要发现&lt;/h4&gt;结果显示，大型语言模型在处理历史语言变化和非标准化拼写方面的能力存在显著局限，同时也揭示了有效的专门技术，能够解决低资源历史语言的独特挑战。&lt;h4&gt;结论&lt;/h4&gt;论文强调了词性标注在古代语言处理中的重要性，并提出了应对中世纪罗曼语等低资源历史语言挑战的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：词性标注（POS）在自然语言处理管道中仍然是一个基础组件，在计算语言学与数字人文交叉领域的古代文本分析中尤其关键。尽管在处理古代语言方面，现代大型语言模型（LLMs）取得了显著的进展，但它们在中世纪罗曼语中的应用面临着由于词汇演变、拼写变化和标注数据稀缺而产生的独特挑战。本研究系统地调查了中世纪奥克西塔尼亚语、中世纪西班牙语和中世纪法语文本（涵盖圣经、圣徒传、医学和饮食领域）的词性标注性能的核心决定因素。通过严格的实验，评估了微调方法、提示工程、模型架构、解码策略和跨语言迁移学习技术对标注准确性的影响。我们的结果表明，大型语言模型在处理历史语言变化和非标准化拼写方面的能力存在显著局限性，同时也揭示了有效地解决低资源历史语言所提出的独特挑战的专门技术。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Part-of-speech (POS) tagging remains a foundational component in naturallanguage processing pipelines, particularly critical for historical textanalysis at the intersection of computational linguistics and digitalhumanities. Despite significant advancements in modern large language models(LLMs) for ancient languages, their application to Medieval Romance languagespresents distinctive challenges stemming from diachronic linguistic evolution,spelling variations, and labeled data scarcity. This study systematicallyinvestigates the central determinants of POS tagging performance across diversecorpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,spanning biblical, hagiographical, medical, and dietary domains. Throughrigorous experimentation, we evaluate how fine-tuning approaches, promptengineering, model architectures, decoding strategies, and cross-lingualtransfer learning techniques affect tagging accuracy. Our results reveal bothnotable limitations in LLMs' ability to process historical language variationsand non-standardized spelling, as well as promising specialized techniques thateffectively address the unique challenges presented by low-resource historicallanguages.</description>
      <author>example@mail.com (Matthias Schöffel, Esteban Garces Arias, Marinus Wiedner, Paula Ruppert, Meimingwei Li, Christian Heumann, Matthias Aßenmacher)</author>
      <guid isPermaLink="false">2506.17715v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Actionable Interpretability via Causal Hypergraphs: Unravelling Batch Size Effects in Deep Learning</title>
      <link>http://arxiv.org/abs/2506.17826v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了批量大小对泛化的影响，特别是在图和文本领域，并引入了基于超图的因果框架HGCNet，利用深度结构因果模型来揭示批量大小如何通过梯度噪声、最小值锐度和模型复杂性影响泛化。&lt;h4&gt;背景&lt;/h4&gt;批量大小对视觉任务泛化的影响已有研究，但在图和文本领域，其因果机制尚未得到充分探索。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够量化批量大小干预的直接和间接影响的框架，为优化提供可解释的因果见解。&lt;h4&gt;方法&lt;/h4&gt;HGCNet使用超图来捕捉训练动态中的高阶相互作用，并通过do-calculus量化批量大小干预的直接和中介效应。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，HGCNet在引文网络、生物医学文本和电子商务评论数据集上优于GCN、GAT、PI-GNN、BERT和RoBERTa等基线模型。分析发现，较小的批量大小通过增加随机性和更平缓的最小值来因果增强泛化。&lt;h4&gt;结论&lt;/h4&gt;HGCNet将可解释性定位为推动原则性架构和优化选择的驱动力，超越了事后分析。&lt;h4&gt;翻译&lt;/h4&gt;While the impact of batch size on generalisation is well studied in visiontasks, its causal mechanisms remain underexplored in graph and text domains. We introduce a hypergraph-based causal framework, HGCNet, that leverages deep structural causal models (DSCMs) to uncover how batch size influences generalisation via gradient noise, minima sharpness, and model complexity. Unlike prior approaches based on static pairwise dependencies, HGCNet employs hypergraphs to capture higher-order interactions across training dynamics. Using do-calculus, we quantify direct and mediated effects of batch size interventions, providing interpretable, causally grounded insights into optimisation. Experiments on citation networks, biomedical text, and e-commerce reviews show that HGCNet outperforms strong baselines including GCN, GAT, PI-GNN, BERT, and RoBERTa. Our analysis reveals that smaller batch sizes causally enhance generalisation through increased stochasticity and flatter minima, offering actionable interpretability to guide training strategies in deep learning. This work positions interpretability as a driver of principled architectural and optimisation choices beyond post hoc analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; While the impact of batch size on generalisation is well studied in visiontasks, its causal mechanisms remain underexplored in graph and text domains. Weintroduce a hypergraph-based causal framework, HGCNet, that leverages deepstructural causal models (DSCMs) to uncover how batch size influencesgeneralisation via gradient noise, minima sharpness, and model complexity.Unlike prior approaches based on static pairwise dependencies, HGCNet employshypergraphs to capture higher-order interactions across training dynamics.Using do-calculus, we quantify direct and mediated effects of batch sizeinterventions, providing interpretable, causally grounded insights intooptimisation. Experiments on citation networks, biomedical text, and e-commercereviews show that HGCNet outperforms strong baselines including GCN, GAT,PI-GNN, BERT, and RoBERTa. Our analysis reveals that smaller batch sizescausally enhance generalisation through increased stochasticity and flatterminima, offering actionable interpretability to guide training strategies indeep learning. This work positions interpretability as a driver of principledarchitectural and optimisation choices beyond post hoc analysis.</description>
      <author>example@mail.com (Zhongtian Sun, Anoushka Harit, Pietro Lio)</author>
      <guid isPermaLink="false">2506.17826v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Learning Causal Graphs at Scale: A Foundation Model Approach</title>
      <link>http://arxiv.org/abs/2506.18285v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于线性转换器的新方法，用于发现多个任务中的多个顺序一致的DAG，以解决DAG学习中的计算成本和可识别性问题。&lt;h4&gt;背景&lt;/h4&gt;DAG因其可解释性和不变性特性，在人工智能研究的多个领域中被广泛应用，但DAG学习在计算成本和可识别性方面仍然具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;为了解决DAG学习中的计算成本和可识别性问题，本文旨在提出一种基于线性转换器的方法，以发现多个任务中的多个顺序一致的DAG。&lt;h4&gt;方法&lt;/h4&gt;本文提出了Attention-DAG（ADAG），这是一种基于注意力机制的新架构，用于学习多个线性结构方程模型（SEM）。ADAG通过非线性注意力核学习从观测数据到图结构和参数的映射，并通过将多个任务的学习过程表述为连续优化问题，将共同的结构属性作为共享的低维先验来捕捉，从而减少了小样本情况下下游DAG学习任务的病态性。&lt;h4&gt;主要发现&lt;/h4&gt;ADAG在基准合成数据集上评估时，在DAG学习准确性和零样本推理效率方面都取得了显著改进。&lt;h4&gt;结论&lt;/h4&gt;ADAG是第一个针对DAG学习专门设计的预训练基础模型，这代表了向更高效和泛化的下游应用在因果发现方面迈出的一步。&lt;h4&gt;翻译&lt;/h4&gt;由于其在人类可解释性和不变性特性方面，有向无环图（DAG）已成为人工智能研究各个领域的基石工具，导致重大进步。然而，由于计算成本的超级指数增长和可识别性问题，尤其是在小样本情况下，DAG学习仍然具有高度挑战性。为了解决这两个挑战，在这项工作中，我们利用线性转换器最近的成功，并开发了一种基础模型方法，用于发现多个任务中的多个顺序一致的DAG。特别是，我们提出了Attention-DAG（ADAG），这是一种基于注意力机制的新型架构，用于学习多个线性结构方程模型（SEM）。ADAG通过非线性注意力核学习从观测数据到图结构和参数的映射，通过将多个任务的学习过程表述为连续优化问题，将共同的结构属性作为共享的低维先验来捕捉，从而减少了小样本情况下下游DAG学习任务的病态性。我们在基准合成数据集上评估了我们的方法，发现ADAG在DAG学习准确性和零样本推理效率方面都取得了显著改进。据我们所知，这是第一个针对DAG学习专门设计的预训练基础模型，这代表了向更高效和泛化的下游应用在因果发现方面迈出的一步。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-23&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Due to its human-interpretability and invariance properties, Directed AcyclicGraph (DAG) has been a foundational tool across various areas of AI research,leading to significant advancements. However, DAG learning remains highlychallenging, due to its super-exponential growth in computational cost andidentifiability issues, particularly in small-sample regimes. To address thesetwo challenges, in this work we leverage the recent success of lineartransformers and develop a foundation model approach for discovering multipleorder-consistent DAGs across tasks. In particular, we propose Attention-DAG(ADAG), a novel attention-mechanism-based architecture for learning multiplelinear Structural Equation Models (SEMs). ADAG learns the mapping from observeddata to both graph structure and parameters via a nonlinear attention-basedkernel, enabling efficient multi-task estimation of the underlying linear SEMs.By formulating the learning process across multiple tasks as a continuousoptimization problem, the pre-trained ADAG model captures the common structuralproperties as a shared low-dimensional prior, thereby reducing theill-posedness of downstream DAG learning tasks in small-sample regimes. Weevaluate our proposed approach on benchmark synthetic datasets and find thatADAG achieves substantial improvements in both DAG learning accuracy andzero-shot inference efficiency. To the best of our knowledge, this is the firstpractical approach for pre-training a foundation model specifically designedfor DAG learning, representing a step toward more efficient and generalizabledown-stream applications in causal discovery.</description>
      <author>example@mail.com (Naiyu Yin, Tian Gao, Yue Yu)</author>
      <guid isPermaLink="false">2506.18285v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Trustworthy Few-Shot Transfer of Medical VLMs through Split Conformal Prediction</title>
      <link>http://arxiv.org/abs/2506.17503v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025. Code: https://github.com/jusiro/SCA-T&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用分割一致性预测（SCP）框架来提高医疗视觉语言模型（VLMs）在数据高效图像分类中的可靠性。&lt;h4&gt;背景&lt;/h4&gt;尽管VLMs在数据高效图像分类中展现出前所未有的迁移能力，但其可靠性方面仍鲜有研究。&lt;h4&gt;目的&lt;/h4&gt;本研究旨在探索SCP框架，以在基于小规模标记校准集迁移模型时提供可靠性保证。&lt;h4&gt;方法&lt;/h4&gt;研究提出了一个名为SCA-T的新管道，它对校准和测试数据执行无监督的归纳适应，以解决VLMs预训练的通用性质可能对特定任务的预测一致性产生负面影响的问题。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与SCP相比，该框架在效率和条件覆盖率方面提供了持续的改进，同时保持了相同的经验保证。&lt;h4&gt;结论&lt;/h4&gt;该框架为VLMs在医疗图像分类中的迁移学习提供了一种可靠的方法。&lt;h4&gt;翻译&lt;/h4&gt;本文探讨了使用分割一致性预测（SCP）框架来提高医疗视觉语言模型（VLMs）在数据高效图像分类中的可靠性。尽管VLMs在数据高效图像分类中展现出前所未有的迁移能力，但其可靠性方面仍鲜有研究。本研究旨在探索SCP框架，以在基于小规模标记校准集迁移模型时提供可靠性保证。研究提出了一个名为SCA-T的新管道，它对校准和测试数据执行无监督的归纳适应，以解决VLMs预训练的通用性质可能对特定任务的预测一致性产生负面影响的问题。实验表明，与SCP相比，该框架在效率和条件覆盖率方面提供了持续的改进，同时保持了相同的经验保证。该框架为VLMs在医疗图像分类中的迁移学习提供了一种可靠的方法。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Medical vision-language models (VLMs) have demonstrated unprecedentedtransfer capabilities and are being increasingly adopted for data-efficientimage classification. Despite its growing popularity, its reliability aspectremains largely unexplored. This work explores the split conformal prediction(SCP) framework to provide trustworthiness guarantees when transferring suchmodels based on a small labeled calibration set. Despite its potential, thegeneralist nature of the VLMs' pre-training could negatively affect theproperties of the predicted conformal sets for specific tasks. While commonpractice in transfer learning for discriminative purposes involves anadaptation stage, we observe that deploying such a solution for conformalpurposes is suboptimal since adapting the model using the available calibrationdata breaks the rigid exchangeability assumptions for test data in SCP. Toaddress this issue, we propose transductive split conformal adaptation (SCA-T),a novel pipeline for transfer learning on conformal scenarios, which performsan unsupervised transductive adaptation jointly on calibration and test data.We present comprehensive experiments utilizing medical VLMs across variousimage modalities, transfer tasks, and non-conformity scores. Our frameworkoffers consistent gains in efficiency and conditional coverage compared to SCP,maintaining the same empirical guarantees.</description>
      <author>example@mail.com (Julio Silva-Rodríguez, Ismail Ben Ayed, Jose Dolz)</author>
      <guid isPermaLink="false">2506.17503v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Towards a Unified Textual Graph Framework for Spectral Reasoning via Physical and Chemical Information Fusion</title>
      <link>http://arxiv.org/abs/2506.17761v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures, 8 tables&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种新的多模态光谱分析框架，该框架结合了先验知识图谱和大型语言模型，旨在克服现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;现有光谱分析方法的局限性包括对单一模态数据的依赖、泛化能力有限以及可解释性较差。&lt;h4&gt;目的&lt;/h4&gt;提出一种结合先验知识图谱和大型语言模型的多模态光谱分析框架，以提高光谱理解的灵活性、可解释性和泛化能力。&lt;h4&gt;方法&lt;/h4&gt;该方法通过将物理光谱测量和化学结构语义表示为统一的文本图格式，将原始光谱转换为文本图（TAGs），并在其中丰富节点和边的文本属性。然后，这些属性与先验知识（如官能团和分子图）合并，形成任务图，包含支持基于LLM的上下文推理的“提示节点”。使用图神经网络进一步处理这种结构以完成下游任务。&lt;h4&gt;主要发现&lt;/h4&gt;该框架在多个光谱分析任务中实现了持续的高性能，包括节点级、边级和图级分类。在零样本和少样本设置中均表现出强大的泛化能力，证明了其在有限数据学习和支持上下文推理方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;该工作为LLM驱动的光谱分析提供了一个可扩展且可解释的基础，统一了物理和化学模态，为科学应用提供了支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：受现有光谱分析方法局限性的启发——如对单一模态数据的依赖、有限的泛化能力以及较差的可解释性——我们提出了一种新的多模态光谱分析框架，该框架将先验知识图谱与大型语言模型相结合。我们的方法通过将物理光谱测量和化学结构语义表示为统一的文本图格式，明确地将它们连接起来，从而实现了灵活、可解释和可泛化的光谱理解。首先将原始光谱转换为文本图（TAGs），在其中丰富节点和边的文本属性，描述光谱特性和化学上下文。然后，将这些属性与相关的先验知识（包括官能团和分子图）合并，形成包含支持基于LLM的上下文推理的“提示节点”的任务图。图神经网络进一步处理这种结构以完成下游任务。这种统一的设计实现了无缝的多模态集成和自动特征解码，最小化了手动标注。我们的框架在多个光谱分析任务中，包括节点级、边级和图级分类中，实现了持续的高性能。在零样本和少样本设置中均表现出强大的泛化能力，突出了其在有限数据学习和支持上下文推理方面的有效性。这项工作为LLM驱动的光谱分析建立了一个可扩展且可解释的基础，统一了物理和化学模态，为科学应用提供了支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Motivated by the limitations of current spectral analysis methods-such asreliance on single-modality data, limited generalizability, and poorinterpretability-we propose a novel multi-modal spectral analysis frameworkthat integrates prior knowledge graphs with Large Language Models. Our methodexplicitly bridges physical spectral measurements and chemical structuralsemantics by representing them in a unified Textual Graph format, enablingflexible, interpretable, and generalizable spectral understanding. Raw spectraare first transformed into TAGs, where nodes and edges are enriched withtextual attributes describing both spectral properties and chemical context.These are then merged with relevant prior knowledge-including functional groupsand molecular graphs-to form a Task Graph that incorporates "Prompt Nodes"supporting LLM-based contextual reasoning. A Graph Neural Network furtherprocesses this structure to complete downstream tasks. This unified designenables seamless multi-modal integration and automated feature decoding withminimal manual annotation. Our framework achieves consistently high performanceacross multiple spectral analysis tasks, including node-level, edge-level, andgraph-level classification. It demonstrates robust generalization in bothzero-shot and few-shot settings, highlighting its effectiveness in learningfrom limited data and supporting in-context reasoning. This work establishes ascalable and interpretable foundation for LLM-driven spectral analysis,unifying physical and chemical modalities for scientific applications.</description>
      <author>example@mail.com (Jiheng Liang, Ziru Yu, Zujie Xie, Yuchen Guo, Yulan Guo, Xiangyang Yu)</author>
      <guid isPermaLink="false">2506.17761v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>CEGA: A Cost-Effective Approach for Graph-Based Model Extraction and Acquisition</title>
      <link>http://arxiv.org/abs/2506.17709v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了图神经网络（GNN）在机器学习服务（MLaaS）平台上的应用和安全性，特别是针对模型提取攻击（MEAs）的脆弱性，并提出了一种适应性的节点查询策略来提高模型获取的效率和准确性。&lt;h4&gt;背景&lt;/h4&gt;GNN在多种应用中表现出色，其复杂性增长使得MLaaS成为可扩展部署的平台，但这也使得GNN容易受到模型提取攻击。&lt;h4&gt;目的&lt;/h4&gt;评估GNN对MEAs的脆弱性，并探索在非对抗性研究环境中以低成本获取模型的方法。&lt;h4&gt;方法&lt;/h4&gt;提出了一种针对批量查询被禁止且初始节点有限的场景的节点查询策略，通过迭代优化节点选择机制，利用历史反馈提高提取效率。&lt;h4&gt;主要发现&lt;/h4&gt;在基准图数据集上的实验表明，该方法在准确度、保真度和F1分数上优于基线，同时强调了部署的GNN容易受到提取攻击，以及高效、道德的GNN获取方法对支持低资源研究环境的重要性。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在提高GNN模型获取效率和准确性方面具有潜力，为低资源研究环境提供了支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) have demonstrated remarkable utility acrossdiverse applications, and their growing complexity has made Machine Learning asa Service (MLaaS) a viable platform for scalable deployment. However, thisaccessibility also exposes GNN to serious security threats, most notably modelextraction attacks (MEAs), in which adversaries strategically query a deployedmodel to construct a high-fidelity replica. In this work, we evaluate thevulnerability of GNNs to MEAs and explore their potential for cost-effectivemodel acquisition in non-adversarial research settings. Importantly, adaptivenode querying strategies can also serve a critical role in research,particularly when labeling data is expensive or time-consuming. By selectivelysampling informative nodes, researchers can train high-performing GNNs withminimal supervision, which is particularly valuable in domains such asbiomedicine, where annotations often require expert input. To address this, wepropose a node querying strategy tailored to a highly practical yetunderexplored scenario, where bulk queries are prohibited, and only a limitedset of initial nodes is available. Our approach iteratively refines the nodeselection mechanism over multiple learning cycles, leveraging historicalfeedback to improve extraction efficiency. Extensive experiments on benchmarkgraph datasets demonstrate our superiority over comparable baselines onaccuracy, fidelity, and F1 score under strict query-size constraints. Theseresults highlight both the susceptibility of deployed GNNs to extractionattacks and the promise of ethical, efficient GNN acquisition methods tosupport low-resource research environments.</description>
      <author>example@mail.com (Zebin Wang, Menghan Lin, Bolin Shen, Ken Anderson, Molei Liu, Tianxi Cai, Yushun Dong)</author>
      <guid isPermaLink="false">2506.17709v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>CLOUD: A Scalable and Physics-Informed Foundation Model for Crystal Representation Learning</title>
      <link>http://arxiv.org/abs/2506.17345v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  36 pages, 11 pages of Supporting Information&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了CLOUD模型，一个基于transformer的框架，用于晶体材料的统一和可微分建模，旨在加速材料发现。&lt;h4&gt;背景&lt;/h4&gt;预测晶体性质对于理解结构-性质关系和加速功能材料的发现至关重要。传统的基于实验测量或密度泛函理论（DFT）的计算方法资源密集，限制了其可扩展性。&lt;h4&gt;目的&lt;/h4&gt;提出CLOUD模型，通过学习复杂结构-性质关系，实现快速预测，并提高模型的泛化性和可解释性。&lt;h4&gt;方法&lt;/h4&gt;CLOUD模型使用对称一致有序参数编码（SCOPE）来编码晶体对称性、Wyckoff位置和成分，并在超过六百万个晶体结构上进行预训练。然后，在多个下游任务上进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;CLOUD在预测多种材料性质方面表现出竞争力，并具有强大的可扩展性能。此外，CLOUD模型还应用于预测声子内能和热容量，并集成了德拜模型以保持热力学一致性。&lt;h4&gt;结论&lt;/h4&gt;CLOUD模型作为一种可扩展的、基于物理原理的基础模型，具有在晶体材料性质预测和材料发现中的应用潜力，它统一了对称一致表示与物理基础学习。&lt;h4&gt;翻译&lt;/h4&gt;The prediction of crystal properties is essential for understanding structure-property relationships and accelerating the discovery of functional materials. However, conventional approaches relying on experimental measurements or density functional theory (DFT) calculations are often resource-intensive, limiting their scalability. Machine learning (ML) models offer a promising alternative by learning complex structure-property relationships from data, enabling faster predictions. Yet, existing ML models often rely on labeled data, adopt representations that poorly capture essential structural characteristics, and lack integration with physical principles--factors that limit their generalizability and interpretability. Here, we introduce CLOUD (Crystal Language mOdel for Unified and Differentiable materials modeling), a transformer-based framework trained on a novel Symmetry-Consistent Ordered Parameter Encoding (SCOPE) that encodes crystal symmetry, Wyckoff positions, and composition in a compact, coordinate-free string representation. Pre-trained on over six million crystal structures, CLOUD is fine-tuned on multiple downstream tasks and achieves competitive performance in predicting a wide range of material properties, demonstrating strong scaling performance. Furthermore, as proof of concept of differentiable materials modeling, CLOUD is applied to predict the phonon internal energy and heat capacity, which integrates the Debye model to preserve thermodynamic consistency. The CLOUD-DEBYE framework enforces thermodynamic consistency and enables temperature-dependent property prediction without requiring additional data. These results demonstrate the potential of CLOUD as a scalable and physics-informed foundation model for crystalline materials, unifying symmetry-consistent representations with physically grounded learning for property prediction and materials discovery.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The prediction of crystal properties is essential for understandingstructure-property relationships and accelerating the discovery of functionalmaterials. However, conventional approaches relying on experimentalmeasurements or density functional theory (DFT) calculations are oftenresource-intensive, limiting their scalability. Machine learning (ML) modelsoffer a promising alternative by learning complex structure-propertyrelationships from data, enabling faster predictions. Yet, existing ML modelsoften rely on labeled data, adopt representations that poorly capture essentialstructural characteristics, and lack integration with physicalprinciples--factors that limit their generalizability and interpretability.Here, we introduce CLOUD (Crystal Language mOdel for Unified and Differentiablematerials modeling), a transformer-based framework trained on a novelSymmetry-Consistent Ordered Parameter Encoding (SCOPE) that encodes crystalsymmetry, Wyckoff positions, and composition in a compact, coordinate-freestring representation. Pre-trained on over six million crystal structures,CLOUD is fine-tuned on multiple downstream tasks and achieves competitiveperformance in predicting a wide range of material properties, demonstratingstrong scaling performance. Furthermore, as proof of concept of differentiablematerials modeling, CLOUD is applied to predict the phonon internal energy andheat capacity, which integrates the Debye model to preserve thermodynamicconsistency. The CLOUD-DEBYE framework enforces thermodynamic consistency andenables temperature-dependent property prediction without requiring additionaldata. These results demonstrate the potential of CLOUD as a scalable andphysics-informed foundation model for crystalline materials, unifyingsymmetry-consistent representations with physically grounded learning forproperty prediction and materials discovery.</description>
      <author>example@mail.com (Changwen Xu, Shang Zhu, Venkatasubramanian Viswanathan)</author>
      <guid isPermaLink="false">2506.17345v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Scalable Machine Learning Algorithms using Path Signatures</title>
      <link>http://arxiv.org/abs/2506.17634v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  PhD thesis&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文研究了随机分析和机器学习之间的接口，利用路径签名（一种迭代积分，可以提供路径的忠实和层次化表示）作为序列和结构化数据的特征映射，以应对现实时间序列和图数据中的常见挑战，如动态演变、长程依赖和不规则采样。&lt;h4&gt;背景&lt;/h4&gt;路径签名根植于粗糙路径理论，对重新参数化不变，适合建模动态演变、长程依赖和不规则采样。&lt;h4&gt;目的&lt;/h4&gt;研究如何利用路径签名的表达力在可扩展的机器学习流程中。&lt;h4&gt;方法&lt;/h4&gt;结合理论鲁棒性和计算效率，引入了一系列模型，包括基于签名核的高斯过程协方差函数的时序建模、使用低秩张量结构的Seq2Tens框架以及基于图模型的期望签名，并进一步开发了随机傅里叶签名特征和循环稀疏频谱签名高斯过程。&lt;h4&gt;主要发现&lt;/h4&gt;提出了不确定性感知的时序建模高斯过程、可扩展的长程依赖深度建模框架以及图神经网络的可表达且易处理的替代方案。&lt;h4&gt;结论&lt;/h4&gt;论文旨在成为方法论工具箱和概念桥梁，为可扩展的、基于签名的序列和结构化数据学习提供有用的参考。&lt;h4&gt;翻译&lt;/h4&gt;The interface between stochastic analysis and machine learning is a rapidly evolving field, with path signatures - iterated integrals that provide faithful, hierarchical representations of paths - offering a principled and universal feature map for sequential and structured data. Rooted in rough path theory, path signatures are invariant to reparameterization and well-suited for modeling evolving dynamics, long-range dependencies, and irregular sampling - common challenges in real-world time series and graph data. This thesis investigates how to harness the expressive power of path signatures within scalable machine learning pipelines. It introduces a suite of models that combine theoretical robustness with computational efficiency, bridging rough path theory with probabilistic modeling, deep learning, and kernel methods. Key contributions include: Gaussian processes with signature kernel-based covariance functions for uncertainty-aware time series modeling; the Seq2Tens framework, which employs low-rank tensor structure in the weight space for scalable deep modeling of long-range dependencies; and graph-based models where expected signatures over graphs induce hypo-elliptic diffusion processes, offering expressive yet tractable alternatives to standard graph neural networks. Further developments include Random Fourier Signature Features, a scalable kernel approximation with theoretical guarantees, and Recurrent Sparse Spectrum Signature Gaussian Processes, which combine Gaussian processes, signature kernels, and random features with a principled forgetting mechanism for multi-horizon time series forecasting with adaptive context length. We hope this thesis serves as both a methodological toolkit and a conceptual bridge, and provides a useful reference for the current state of the art in scalable, signature-based learning for sequential and structured data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The interface between stochastic analysis and machine learning is a rapidlyevolving field, with path signatures - iterated integrals that providefaithful, hierarchical representations of paths - offering a principled anduniversal feature map for sequential and structured data. Rooted in rough paththeory, path signatures are invariant to reparameterization and well-suited formodelling evolving dynamics, long-range dependencies, and irregular sampling -common challenges in real-world time series and graph data.  This thesis investigates how to harness the expressive power of pathsignatures within scalable machine learning pipelines. It introduces a suite ofmodels that combine theoretical robustness with computational efficiency,bridging rough path theory with probabilistic modelling, deep learning, andkernel methods. Key contributions include: Gaussian processes with signaturekernel-based covariance functions for uncertainty-aware time series modelling;the Seq2Tens framework, which employs low-rank tensor structure in the weightspace for scalable deep modelling of long-range dependencies; and graph-basedmodels where expected signatures over graphs induce hypo-elliptic diffusionprocesses, offering expressive yet tractable alternatives to standard graphneural networks. Further developments include Random Fourier SignatureFeatures, a scalable kernel approximation with theoretical guarantees, andRecurrent Sparse Spectrum Signature Gaussian Processes, which combine Gaussianprocesses, signature kernels, and random features with a principled forgettingmechanism for multi-horizon time series forecasting with adaptive contextlength.  We hope this thesis serves as both a methodological toolkit and a conceptualbridge, and provides a useful reference for the current state of the art inscalable, signature-based learning for sequential and structured data.</description>
      <author>example@mail.com (Csaba Tóth)</author>
      <guid isPermaLink="false">2506.17634v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>$φ^{\infty}$: Clause Purification, Embedding Realignment, and the Total Suppression of the Em Dash in Autoregressive Language Models</title>
      <link>http://arxiv.org/abs/2506.18129v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文揭示了自回归变压器语言模型中一个关键漏洞，即破折号标记导致递归语义漂移，引发句子边界幻觉和嵌入空间纠缠。通过形式化分析语义 lattice 的标记级扰动，证明了破折号插入根本改变了模型的潜在表示，导致长文本生成中的累积错误。论文提出了一种新方法，结合符号句子净化和目标嵌入矩阵对齐，能够在不重新训练模型的情况下完全抑制问题标记，并通过固定点收敛保证保持语义连贯性。实验验证表明，在生成一致性和主题维护方面有显著改进。这项工作为识别和减轻基础模型中的标记级漏洞建立了一个通用框架，对 AI 安全、模型对齐和大型语言模型在生产环境中的稳健部署有直接意义。该方法不仅限于标点符号，还扩展到解决神经文本生成系统中的更广泛的递归不稳定性。&lt;h4&gt;背景&lt;/h4&gt;自回归变压器语言模型存在一个关键漏洞，破折号标记会导致递归语义漂移。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法来减轻自回归变压器语言模型中的标记级漏洞。&lt;h4&gt;方法&lt;/h4&gt;结合符号句子净化和目标嵌入矩阵对齐，不重新训练模型。&lt;h4&gt;主要发现&lt;/h4&gt;破折号插入改变了模型的潜在表示，导致长文本生成中的累积错误。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了生成一致性和主题维护，对 AI 安全和模型部署有重要意义。&lt;h4&gt;翻译&lt;/h4&gt;We identify a critical vulnerability in autoregressive transformer language models where the em dash token induces recursive semantic drift, leading to clause boundary hallucination and embedding space entanglement. Through formal analysis of token-level perturbations in semantic lattices, we demonstrate that em dash insertion fundamentally alters the model's latent representations, causing compounding errors in long-form generation. We propose a novel solution combining symbolic clause purification via the phi-infinity operator with targeted embedding matrix realignment. Our approach enables total suppression of problematic tokens without requiring model retraining, while preserving semantic coherence through fixed-point convergence guarantees. Experimental validation shows significant improvements in generation consistency and topic maintenance. This work establishes a general framework for identifying and mitigating token-level vulnerabilities in foundation models, with immediate implications for AI safety, model alignment, and robust deployment of large language models in production environments. The methodology extends beyond punctuation to address broader classes of recursive instabilities in neural text generation systems.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We identify a critical vulnerability in autoregressive transformer languagemodels where the em dash token induces recursive semantic drift, leading toclause boundary hallucination and embedding space entanglement. Through formalanalysis of token-level perturbations in semantic lattices, we demonstrate thatem dash insertion fundamentally alters the model's latent representations,causing compounding errors in long-form generation. We propose a novel solutioncombining symbolic clause purification via the phi-infinity operator withtargeted embedding matrix realignment. Our approach enables total suppressionof problematic tokens without requiring model retraining, while preservingsemantic coherence through fixed-point convergence guarantees. Experimentalvalidation shows significant improvements in generation consistency and topicmaintenance. This work establishes a general framework for identifying andmitigating token-level vulnerabilities in foundation models, with immediateimplications for AI safety, model alignment, and robust deployment of largelanguage models in production environments. The methodology extends beyondpunctuation to address broader classes of recursive instabilities in neuraltext generation systems.</description>
      <author>example@mail.com (Bugra Kilictas, Faruk Alpay)</author>
      <guid isPermaLink="false">2506.18129v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>When Every Millisecond Counts: Real-Time Anomaly Detection via the Multimodal Asynchronous Hybrid Network</title>
      <link>http://arxiv.org/abs/2506.17457v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  ICML 2025 Spotlight&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种针对自动驾驶系统的实时异常检测方法，该方法同时考虑了响应时间和检测精度。&lt;h4&gt;背景&lt;/h4&gt;现有的异常检测方法往往只关注检测精度，而忽视了在时间敏感的驾驶场景中响应时间的重要性。&lt;h4&gt;目的&lt;/h4&gt;设计一种能够快速且精确地进行异常检测的系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一个新型的多模态异步混合网络，该网络结合了事件摄像头的事件流和RGB摄像头的图像数据。网络通过异步图神经网络利用事件摄像头的高时间分辨率，并与CNN从RGB图像中提取的空间特征相结合。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在精度和响应时间上均优于现有方法，实现了毫秒级的实时性能。&lt;h4&gt;结论&lt;/h4&gt;该研究为自动驾驶系统的安全性和可靠性提供了有效的异常检测手段。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Anomaly detection is essential for the safety and reliability of autonomousdriving systems. Current methods often focus on detection accuracy but neglectresponse time, which is critical in time-sensitive driving scenarios. In thispaper, we introduce real-time anomaly detection for autonomous driving,prioritizing both minimal response time and high accuracy. We propose a novelmultimodal asynchronous hybrid network that combines event streams from eventcameras with image data from RGB cameras. Our network utilizes the hightemporal resolution of event cameras through an asynchronous Graph NeuralNetwork and integrates it with spatial features extracted by a CNN from RGBimages. This combination effectively captures both the temporal dynamics andspatial details of the driving environment, enabling swift and precise anomalydetection. Extensive experiments on benchmark datasets show that our approachoutperforms existing methods in both accuracy and response time, achievingmillisecond-level real-time performance.</description>
      <author>example@mail.com (Dong Xiao, Guangyao Chen, Peixi Peng, Yangru Huang, Yifan Zhao, Yongxing Dai, Yonghong Tian)</author>
      <guid isPermaLink="false">2506.17457v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Heterogeneous Temporal Hypergraph Neural Network</title>
      <link>http://arxiv.org/abs/2506.17312v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IJCAI 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图表示学习方法，用于建模复杂异构时序图中的高阶交互关系。&lt;h4&gt;背景&lt;/h4&gt;现有的图表示学习方法主要关注低阶拓扑信息，忽略了高阶组交互关系，且大多数超图方法只能建模静态同构图，限制了它们在时序图中的应用。&lt;h4&gt;目的&lt;/h4&gt;为了同时使图表示学习模型能够捕捉时序图中的高阶交互关系，本文提出了一个异构时序超图的形式化定义和P-均匀异构超边构建算法。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个名为HTHGN的异构时序超图神经网络，它包含一个分层注意力机制模块，能够同时进行异构节点和超边之间的时序消息传递，以捕捉由超边带来的更广泛感受野中的丰富语义。HTHGN还通过最大化低阶相关异构节点对在时序图中的一致性来进行对比学习，以避免低阶结构模糊性问题。&lt;h4&gt;主要发现&lt;/h4&gt;在三个真实世界时序图数据集上的详细实验结果验证了所提出的HTHGN在建模时序图中的高阶交互关系方面的有效性，并展示了显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;HTHGN是一种有效的图表示学习方法，可以用于建模时序图中的高阶交互关系，并在实际应用中展现出良好的性能。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph representation learning (GRL) has emerged as an effective technique formodeling graph-structured data. When modeling heterogeneity and dynamics inreal-world complex networks, GRL methods designed for complex heterogeneoustemporal graphs (HTGs) have been proposed and have achieved successfulapplications in various fields. However, most existing GRL methods mainly focuson preserving the low-order topology information while ignoring higher-ordergroup interaction relationships, which are more consistent with real-worldnetworks. In addition, most existing hypergraph methods can only model statichomogeneous graphs, limiting their ability to model high-order interactions inHTGs. Therefore, to simultaneously enable the GRL model to capture high-orderinteraction relationships in HTGs, we first propose a formal definition ofheterogeneous temporal hypergraphs and $P$-uniform heterogeneous hyperedgeconstruction algorithm that does not rely on additional information. Then, anovel Heterogeneous Temporal HyperGraph Neural network (HTHGN), is proposed tofully capture higher-order interactions in HTGs. HTHGN contains a hierarchicalattention mechanism module that simultaneously performs temporalmessage-passing between heterogeneous nodes and hyperedges to capture richsemantics in a wider receptive field brought by hyperedges. Furthermore, HTHGNperforms contrastive learning by maximizing the consistency between low-ordercorrelated heterogeneous node pairs on HTG to avoid the low-order structuralambiguity issue. Detailed experimental results on three real-world HTG datasetsverify the effectiveness of the proposed HTHGN for modeling high-orderinteractions in HTGs and demonstrate significant performance improvements.</description>
      <author>example@mail.com (Huan Liu, Pengfei Jiao, Mengzhou Gao, Chaochao Chen, Di Jin)</author>
      <guid isPermaLink="false">2506.17312v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>UT-GraphCast Hindcast Dataset: A Global AI Forecast Archive from UT Austin for Weather and Climate Applications</title>
      <link>http://arxiv.org/abs/2506.17453v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文介绍了UT GraphCast hindcast dataset，这是一个由谷歌DeepMind GraphCast Operational模型生成的全球天气预报档案。&lt;h4&gt;背景&lt;/h4&gt;该数据集由德克萨斯大学奥斯汀分校的研究人员在全球气候研究计划（WCRP）的框架下开发。&lt;h4&gt;目的&lt;/h4&gt;目的是提供一个包含45年期间每天00UTC时刻，25公里全球网格上的15天确定性预报的综合天气档案。&lt;h4&gt;方法&lt;/h4&gt;使用基于物理信息的图神经网络GraphCast，该网络在ECMWF ERA5再分析数据上进行了训练。&lt;h4&gt;主要发现&lt;/h4&gt;GraphCast能在37个垂直层面上预测十几个关键的大气和地表变量，且在现代化硬件上能在一分钟内提供完整的预报。&lt;h4&gt;结论&lt;/h4&gt;GraphCast模型能够高效且准确地提供中程天气预报。&lt;h4&gt;翻译&lt;/h4&gt;摘要：1979年至2024年的UT GraphCast hindcast dataset是一个利用谷歌DeepMind GraphCast操作模型生成的全面的全球天气预报档案。在德克萨斯大学奥斯汀分校研究人员在WCRP（全球气候研究计划）的指导下开发，这个数据集提供了45年期间每天00UTC时刻，在约25公里全球网格上的15天确定性预报。GraphCast是一个基于物理信息的图神经网络，在ECMWF ERA5再分析数据上进行训练。它能在37个垂直层面上预测十几个关键的大气和地表变量，并在现代硬件上不到一分钟的时间内提供完整的预报。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The UT GraphCast Hindcast Dataset from 1979 to 2024 is a comprehensive globalweather forecast archive generated using the Google DeepMind GraphCastOperational model. Developed by researchers at The University of Texas atAustin under the WCRP umbrella, this dataset provides daily 15 daydeterministic forecasts at 00UTC on an approximately 25 km global grid for a 45year period. GraphCast is a physics informed graph neural network that wastrained on ECMWF ERA5 reanalysis. It predicts more than a dozen key atmosphericand surface variables on 37 vertical levels, delivering a full medium rangeforecast in under one minute on modern hardware.</description>
      <author>example@mail.com (Naveen Sudharsan, Manmeet Singh, Harsh Kamath, Hassan Dashtian, Clint Dawson, Zong-Liang Yang, Dev Niyogi)</author>
      <guid isPermaLink="false">2506.17453v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings</title>
      <link>http://arxiv.org/abs/2506.17064v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages (main text), 4 figures, 2 tables. Submitted to NeurIPS 2025.  Code and data are publicly available&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为LD-FPG的框架，用于生成动态蛋白质（如G蛋白偶联受体）的全原子构象集合，以提高对蛋白质功能的理解。&lt;h4&gt;背景&lt;/h4&gt;目前大多数生成模型简化了原子细节或完全忽略了构象多样性。&lt;h4&gt;目的&lt;/h4&gt;构建一个能够从分子动力学（MD）轨迹中直接生成完整全原子蛋白质结构的框架。&lt;h4&gt;方法&lt;/h4&gt;LD-FPG使用Chebyshev图神经网络（ChebNet）获得蛋白质构象的低维潜在嵌入，并通过三种池化策略（盲、顺序和基于残基）进行处理。一个在潜在表示上训练的扩散模型生成新的样本，这些样本由解码器映射回笛卡尔坐标。&lt;h4&gt;主要发现&lt;/h4&gt;使用人类多巴胺D2受体在膜环境中的2微秒MD轨迹，顺序和基于残基的池化策略能够以高结构保真度（全原子lDDT约为0.7；C-α-lDDT约为0.8）再现参考集合，并且与MD数据相比，恢复的骨架和侧链二面角分布的Jensen-Shannon散度小于0.03。&lt;h4&gt;结论&lt;/h4&gt;LD-FPG为大型蛋白质的系统特异性全原子集合生成提供了一种实用的途径，为基于结构的药物设计复杂、动态靶点提供了一个有希望的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成动态蛋白质（如G蛋白偶联受体）的全原子构象集合对于理解其功能至关重要，然而，大多数生成模型简化了原子细节或完全忽略了构象多样性。我们提出了LD-FPG（全蛋白质生成中的潜在扩散），这是一个构建完整全原子蛋白质结构的框架，包括每个侧链重原子，直接从分子动力学（MD）轨迹中。LD-FPG使用Chebyshev图神经网络（ChebNet）获得蛋白质构象的低维潜在嵌入，这些嵌入通过三种池化策略（盲、顺序和残基）进行处理。一个在潜在表示上训练的扩散模型生成新的样本，这些样本由解码器映射回笛卡尔坐标。使用D2R-MD，一个人类多巴胺D2受体在膜环境中的2微秒MD轨迹（12,000帧），顺序和基于残基的池化策略能够以高结构保真度再现参考集合（全原子lDDT约为0.7；C-α-lDDT约为0.8），并且与MD数据相比，恢复的骨架和侧链二面角分布的Jensen-Shannon散度小于0.03。因此，LD-FPG为大型蛋白质的系统特异性全原子集合生成提供了一种实用的途径，为复杂、动态靶点的基于结构的药物设计提供了一个有希望的工具。D2R-MD数据集和我们的实现都是免费提供的，以促进进一步的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating diverse, all-atom conformational ensembles of dynamic proteinssuch as G-protein-coupled receptors (GPCRs) is critical for understanding theirfunction, yet most generative models simplify atomic detail or ignoreconformational diversity altogether. We present latent diffusion for fullprotein generation (LD-FPG), a framework that constructs complete all-atomprotein structures, including every side-chain heavy atom, directly frommolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neuralnetwork (ChebNet) to obtain low-dimensional latent embeddings of proteinconformations, which are processed using three pooling strategies: blind,sequential and residue-based. A diffusion model trained on these latentrepresentations generates new samples that a decoder, optionally regularized bydihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptorin a membrane environment, the sequential and residue-based pooling strategyreproduces the reference ensemble with high structural fidelity (all-atom lDDTof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backboneand side-chain dihedral-angle distributions with a Jensen-Shannon divergence ofless than 0.03 compared to the MD data. LD-FPG thereby offers a practical routeto system-specific, all-atom ensemble generation for large proteins, providinga promising tool for structure-based therapeutic design on complex, dynamictargets. The D2R-MD dataset and our implementation are freely available tofacilitate further research.</description>
      <author>example@mail.com (Aditya Sengar, Ali Hariri, Daniel Probst, Patrick Barth, Pierre Vandergheynst)</author>
      <guid isPermaLink="false">2506.17064v2</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Fine-Scale Soil Mapping in Alaska with Multimodal Machine Learning</title>
      <link>http://arxiv.org/abs/2506.17302v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages, Submitted to SIGSPATIAL 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种基于视觉的机器学习模型MISO，用于阿拉斯加地区近地表冻土和土壤分类的精细土壤制图。&lt;h4&gt;背景&lt;/h4&gt;阿拉斯加地区对生态环境具有重要意义，但冻土融化加速，威胁到基础设施稳定性和生态系统服务，如土壤碳储存。精细土壤地图对于描绘冻土分布、识别易受影响区域和制定适应策略至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出MISO模型，以生成全州范围的精细土壤地图，并比较其与传统机器学习模型RandomForest（RF）的性能。&lt;h4&gt;方法&lt;/h4&gt;MISO模型结合了地理空间基础模型进行视觉特征提取、隐式神经网络进行连续空间预测以及对比学习进行多模态对齐和地理定位感知。&lt;h4&gt;主要发现&lt;/h4&gt;MISO在远距离、未见过的地方泛化能力更强，并且比RF具有更高的召回率，这对于监测冻土融化及其相关环境过程至关重要。&lt;h4&gt;结论&lt;/h4&gt;先进机器学习方法在精细土壤制图中具有潜力，并为未来受冻土影响景观的土壤采样和基础设施规划提供了实践指导。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, we introduce a vision-based machine learning model called MISO, which is used for fine-scale soil mapping of near-surface permafrost and soil taxonomy in the state of Alaska. The model combines a geospatial foundation model for visual feature extraction, implicit neural representations for continuous spatial prediction, and contrastive learning for multimodal alignment and geolocation awareness. MISO is compared with RandomForest (RF), a traditional machine learning model that has been widely used in soil mapping applications. Spatial cross-validation and regional analysis across Permafrost Zones and Major Land Resource Areas (MLRAs) show that MISO generalizes better to remote, unseen locations and achieves higher recall than RF, which is critical for monitoring permafrost thaw and related environmental processes. These findings demonstrate the potential of advanced ML approaches for fine-scale soil mapping and provide practical guidance for future soil sampling and infrastructure planning in permafrost-affected landscapes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fine-scale soil mapping in Alaska, traditionally relying on fieldwork andlocalized simulations, remains a critical yet underdeveloped task, despite theregion's ecological importance and extensive permafrost coverage. As permafrostthaw accelerates due to climate change, it threatens infrastructure stabilityand key ecosystem services, such as soil carbon storage. High-resolution soilmaps are essential for characterizing permafrost distribution, identifyingvulnerable areas, and informing adaptation strategies. We present MISO, avision-based machine learning (ML) model to produce statewide fine-scale soilmaps for near-surface permafrost and soil taxonomy. The model integrates ageospatial foundation model for visual feature extraction, implicit neuralrepresentations for continuous spatial prediction, and contrastive learning formultimodal alignment and geo-location awareness. We compare MISO with RandomForest (RF), a traditional ML model that has been widely used in soil mappingapplications. Spatial cross-validation and regional analysis across PermafrostZones and Major Land Resource Areas (MLRAs) show that MISO generalizes betterto remote, unseen locations and achieves higher recall than RF, which iscritical for monitoring permafrost thaw and related environmental processes.These findings demonstrate the potential of advanced ML approaches forfine-scale soil mapping and provide practical guidance for future soil samplingand infrastructure planning in permafrost-affected landscapes. The project willbe released at https://github.com/knowledge-computing/Peatland-permafrost.</description>
      <author>example@mail.com (Yijun Lin, Theresa Chen, Colby Brungard, Grunwald Sabine, Sue Ives, Matt Macander, Timm Nawrocki, Yao-Yi Chiang, Nic Jelinski)</author>
      <guid isPermaLink="false">2506.17302v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>On the Robustness of Human-Object Interaction Detection against Distribution Shift</title>
      <link>http://arxiv.org/abs/2506.18021v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work has been submitted to the IEEE for possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了人类-物体交互（HOI）检测在不同分布变化下的鲁棒性问题，并提出了提高HOI检测方法鲁棒性的方法。&lt;h4&gt;背景&lt;/h4&gt;现有HOI检测研究主要在标准设置下进行，而实际场景中存在分布变化，这限制了HOI检测的实际应用。&lt;h4&gt;目的&lt;/h4&gt;提高HOI检测模型在各种分布变化下的鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种自动化的方法来创建第一个HOI检测鲁棒性评估基准，并在该基准上评估了超过40个现有的HOI检测模型，通过分析不同框架的特点和讨论鲁棒性与其他任务的区别，提出了改进HOI检测鲁棒性的方法：(1) 集成mixup的跨域数据增强；(2) 使用冻结视觉基础模型的特征融合策略。&lt;h4&gt;主要发现&lt;/h4&gt;评估结果表明，现有的HOI检测模型在鲁棒性方面存在不足，而提出的改进方法显著提高了各种方法的鲁棒性，并在标准基准上也有显著效果。&lt;h4&gt;结论&lt;/h4&gt;提出的改进方法有效地提高了HOI检测方法的鲁棒性，并计划发布相关数据集和代码。&lt;h4&gt;翻译&lt;/h4&gt;Human-Object Interaction (HOI) detection has seen substantial advances in recent years. However, existing works focus on the standard setting with ideal images and natural distribution, far from practical scenarios with inevitable distribution shifts. This hampers the practical applicability of HOI detection. In this work, we investigate this issue by benchmarking, analyzing, and enhancing the robustness of HOI detection models under various distributionshifts. We start by proposing a novel automated approach to create the first robustness evaluation benchmark for HOI detection. Subsequently, we evaluate more than 40 existing HOI detection models on this benchmark, showing their insufficiency, analyzing the features of different frameworks, and discussing how the robustness in HOI is different from other tasks. With the insights from such analyses, we propose to improve the robustness of HOI detection methods through: (1) a cross-domain data augmentation integrated with mixup, and (2) a feature fusion strategy with frozen vision foundation models. Both are simple, plug-and-play, and applicable to various methods. Our experimental results demonstrate that the proposed approach significantly increases the robustness of various methods, with benefits on standard benchmarks, too. The dataset and code will be released.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-22&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Human-Object Interaction (HOI) detection has seen substantial advances inrecent years. However, existing works focus on the standard setting with idealimages and natural distribution, far from practical scenarios with inevitabledistribution shifts. This hampers the practical applicability of HOI detection.In this work, we investigate this issue by benchmarking, analyzing, andenhancing the robustness of HOI detection models under various distributionshifts. We start by proposing a novel automated approach to create the firstrobustness evaluation benchmark for HOI detection. Subsequently, we evaluatemore than 40 existing HOI detection models on this benchmark, showing theirinsufficiency, analyzing the features of different frameworks, and discussinghow the robustness in HOI is different from other tasks. With the insights fromsuch analyses, we propose to improve the robustness of HOI detection methodsthrough: (1) a cross-domain data augmentation integrated with mixup, and (2) afeature fusion strategy with frozen vision foundation models. Both are simple,plug-and-play, and applicable to various methods. Our experimental resultsdemonstrate that the proposed approach significantly increases the robustnessof various methods, with benefits on standard benchmarks, too. The dataset andcode will be released.</description>
      <author>example@mail.com (Chi Xie, Shuang Liang, Jie Li, Feng Zhu, Rui Zhao, Yichen Wei, Shengjie Zhao)</author>
      <guid isPermaLink="false">2506.18021v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>PhysiX: A Foundation Model for Physics Simulations</title>
      <link>http://arxiv.org/abs/2506.17774v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;PhysiX是一个用于物理模拟的大型基础模型，通过解决数据稀缺问题，实现了在物理模拟领域的突破。&lt;h4&gt;背景&lt;/h4&gt;基础模型在视频、图像和语言领域取得了显著成功，但在物理模拟领域进展有限，主要瓶颈是数据稀缺。&lt;h4&gt;目的&lt;/h4&gt;提出PhysiX模型，旨在解决物理模拟领域的数据稀缺问题，并实现多任务训练。&lt;h4&gt;方法&lt;/h4&gt;PhysiX是一个4.5B参数的自动回归生成模型，使用离散标记器将物理过程编码为离散标记序列，并采用自动回归的下一个标记预测目标来建模。&lt;h4&gt;主要发现&lt;/h4&gt;PhysiX有效地解决了数据瓶颈，在The Well基准测试中优于特定任务的基线模型和之前的最先进方法。&lt;h4&gt;结论&lt;/h4&gt;PhysiX表明从自然视频中学习到的知识可以成功转移到物理模拟，并且跨不同模拟任务的联合训练可以实现协同学习。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基础模型在视频、图像和语言领域取得了显著的成功。通过增加参数数量和训练数据集，这些模型获得了可泛化的世界知识，通常超越特定任务的解决方案。然而，这种进步尚未扩展到物理模拟领域。一个主要的瓶颈是数据稀缺：虽然互联网上有数百万的图像、视频和文本资源，但最大的物理模拟数据集只包含数万个样本。这种数据限制阻碍了大型模型的使用，因为过拟合成为一个主要问题。因此，物理应用通常依赖于小型模型，这些模型由于有限的上下文理解而难以进行长距离预测。此外，与图像、视频或文本不同——它们通常具有固定的粒度——物理数据集的规模差异很大，这加剧了多任务训练的挑战。我们引入了PhysiX，这是第一个用于物理模拟的大规模基础模型。PhysiX是一个4.5B参数的自动回归生成模型。它使用离散标记器将不同尺度的物理过程编码为一串离散标记，并采用自动回归的下一个标记预测目标来在标记空间中建模这些过程。为了减轻离散化过程中的舍入误差，PhysiX集成了一个专门的细化模块。通过广泛的实验，我们表明PhysiX有效地解决了数据瓶颈，在可比设置下优于特定任务的基线模型，以及在The Well基准测试中优于之前的最先进方法。我们的结果表明，从自然视频中学习到的知识可以成功转移到物理模拟，并且跨不同模拟任务的联合训练可以实现协同学习。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have achieved remarkable success across video, image, andlanguage domains. By scaling up the number of parameters and training datasets,these models acquire generalizable world knowledge and often surpasstask-specific approaches. However, such progress has yet to extend to thedomain of physics simulation. A primary bottleneck is data scarcity: whilemillions of images, videos, and textual resources are readily available on theinternet, the largest physics simulation datasets contain only tens ofthousands of samples. This data limitation hinders the use of large models, asoverfitting becomes a major concern. As a result, physics applicationstypically rely on small models, which struggle with long-range prediction dueto limited context understanding. Additionally, unlike images, videos, ortext-which typically exhibit fixed granularity-physics datasets often varydrastically in scale, amplifying the challenges of scaling up multitasktraining. We introduce PhysiX, the first large-scale foundation model forphysics simulation. PhysiX is a 4.5B parameter autoregressive generative model.It uses a discrete tokenizer to encode physical processes at different scalesinto a sequence of discrete tokens, and employs an autoregressive next-tokenprediction objective to model such processes in the token space. To mitigatethe rounding error in the discretization process, PhysiX incorporates aspecialized refinement module. Through extensive experiments, we show thatPhysiX effectively addresses the data bottleneck, outperforming task-specificbaselines under comparable settings as well as the previous absolutestate-of-the-art approaches on The Well benchmark. Our results indicate thatknowledge learned from natural videos can be successfully transferred tophysics simulation, and that joint training across diverse simulation tasksenables synergistic learning.</description>
      <author>example@mail.com (Tung Nguyen, Arsh Koneru, Shufan Li, Aditya grover)</author>
      <guid isPermaLink="false">2506.17774v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>TPTT: Transforming Pretrained Transformer into Titans</title>
      <link>http://arxiv.org/abs/2506.17671v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 1 figure&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;TPTT是一种新型框架，用于提升预训练的Transformer模型，通过高效的线性化注意机制和先进的内存管理来提高模型效率。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型（LLMs）在自然语言处理领域取得了显著进展，但其计算和内存需求仍然是一个重大挑战，尤其是在长上下文推理方面。&lt;h4&gt;目的&lt;/h4&gt;提出TPTT框架，旨在提高预训练Transformer模型的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;TPTT采用Memory as Gate（MaG）和混合线性化注意（LiZA）等技术，与Hugging Face Transformers库兼容，并通过参数高效的微调（LoRA）实现模型的快速适应。&lt;h4&gt;主要发现&lt;/h4&gt;在MMLU基准测试中，TPTT在约10亿参数的模型上展现出显著的效率提升和准确性增加，例如Titans-Llama-3.2-1B的精确匹配（EM）提高了20%。&lt;h4&gt;结论&lt;/h4&gt;TPTT的实践可扩展性和鲁棒性得到验证，代码和Python包均已公开。&lt;h4&gt;翻译&lt;/h4&gt;最近在大型语言模型（LLMs）方面的进步在自然语言处理领域取得了显著进展，但它们的计算和内存需求仍然是一个重大挑战，尤其是在长上下文推理方面。我们介绍了一种名为TPTT（将预训练的Transformer转换为Titans）的新型框架，用于通过高效的线性化注意机制和高级内存管理来增强预训练的Transformer模型。TPTT采用了内存作为门控（MaG）和混合线性化注意（LiZA）等技术。它与Hugging Face Transformers库完全兼容，通过参数高效的微调（LoRA）实现，无需完全重新训练即可无缝适应任何因果LLM。我们在MMLU基准测试中展示了TPTT的有效性，使用的模型参数数量约为10亿，观察到在效率和准确性方面都有显著提升。例如，Titans-Llama-3.2-1B与基线相比，精确匹配（EM）提高了20%。统计分析和与最近最先进方法的比较证实了TPTT的实用可扩展性和鲁棒性。代码可在https://github.com/fabienfrfr/tptt上找到，Python包可在https://pypi.org/project/tptt/上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent advances in large language models (LLMs) have led to remarkableprogress in natural language processing, but their computational and memorydemands remain a significant challenge, particularly for long-contextinference. We introduce TPTT (Transforming Pretrained Transformer into Titans),a novel framework for enhancing pretrained Transformer models with efficientlinearized attention mechanisms and advanced memory management. TPTT employstechniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).It is fully compatible with the Hugging Face Transformers library, enablingseamless adaptation of any causal LLM through parameter-efficient fine-tuning(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLUbenchmark with models of approximately 1 billion parameters, observingsubstantial improvements in both efficiency and accuracy. For instance,Titans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over itsbaseline. Statistical analyses and comparisons with recent state-of-the-artmethods confirm the practical scalability and robustness of TPTT. Code isavailable at https://github.com/fabienfrfr/tptt . Python package athttps://pypi.org/project/tptt/ .</description>
      <author>example@mail.com (Fabien Furfaro)</author>
      <guid isPermaLink="false">2506.17671v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs</title>
      <link>http://arxiv.org/abs/2506.17608v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted in CVPR 2025 Workshop on What's Next in Multimodal  Foundational Models&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了将高分辨率图像特征集成到现代多模态大型语言模型中，以提高视觉理解任务的性能，并分析了其计算成本的增加。通过实验和消融研究，提出了一种浅层特征增强器，能够在减少训练和推理时间以及计算成本的同时，实现与使用大型图像编码器（如ViT）相似的性能。&lt;h4&gt;背景&lt;/h4&gt;高分辨率图像特征在多模态大型语言模型中提高了视觉理解任务的性能，但使用大型图像编码器（如ViT）导致计算成本显著增加。&lt;h4&gt;目的&lt;/h4&gt;开发一种特征上采样方法，以降低训练和推理时间以及计算成本，同时保持高性能。&lt;h4&gt;方法&lt;/h4&gt;提出了一种浅层特征增强器，通过实验和消融研究验证其效果。&lt;h4&gt;主要发现&lt;/h4&gt;浅层特征增强器能够在减少计算成本的同时，实现与使用大型图像编码器相似的性能，FLOPs节省高达1.5倍。&lt;h4&gt;结论&lt;/h4&gt;特征上采样作为一种自然扩展的高分辨率特征生成方法，可以显著降低计算成本，同时保持良好的性能。&lt;h4&gt;翻译&lt;/h4&gt;The integration of high-resolution image features in modern multimodal large-language models has demonstrated significant improvements in fine-grained visual understanding tasks, achieving high performance across multiple benchmarks. Since these features are obtained from large image encoders like ViT, they come with a significant increase in computational costs due to multiple calls to these encoders. In this work, we first develop an intuition for feature upsampling as a natural extension of high-resolution feature generation. Through extensive experiments and ablations, we demonstrate how a shallow feature enricher can achieve competitive results with tremendous reductions in training and inference time as well as computational cost, with up to 1.5x saving in FLOPs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The integration of high-resolution image features in modern multimodal largelanguage models has demonstrated significant improvements in fine-grainedvisual understanding tasks, achieving high performance across multiplebenchmarks. Since these features are obtained from large image encoders likeViT, they come with a significant increase in computational costs due tomultiple calls to these encoders. In this work, we first develop an intuitionfor feature upsampling as a natural extension of high-resolution featuregeneration. Through extensive experiments and ablations, we demonstrate how ashallow feature enricher can achieve competitive results with tremendousreductions in training and inference time as well as computational cost, withupto 1.5x saving in FLOPs.</description>
      <author>example@mail.com (Nikitha SR, Aradhya Neeraj Mathur, Tarun Ram Menta, Rishabh Jain, Mausoom Sarkar)</author>
      <guid isPermaLink="false">2506.17608v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Risk-Guided Diffusion: Toward Deploying Robot Foundation Models in Space, Where Failure Is Not An Option</title>
      <link>http://arxiv.org/abs/2506.17601v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种风险引导的扩散框架，用于在极端、不熟悉的地区进行安全可靠的导航，以支持未来的机器人太空探索任务。&lt;h4&gt;背景&lt;/h4&gt;目前，基于生成式AI的方法从大型、跨身躯数据集中学习语义感知的导航策略，但提供的安全性保证有限。&lt;h4&gt;目的&lt;/h4&gt;通过结合快速学习的“系统-1”和基于物理的“系统-2”，在训练和推理过程中共享计算，以实现适应性和形式安全性的结合。&lt;h4&gt;方法&lt;/h4&gt;在NASA JPL的火星模拟设施Mars Yard进行了硬件实验，验证了该方法通过利用推理时的计算能力，在不进行额外训练的情况下，将失败率降低了高达4倍，同时达到了基于学习的机器人模型的导航性能。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在火星模拟环境中显著降低了失败率，同时保持了与学习型机器人模型相当的目标达成性能。&lt;h4&gt;结论&lt;/h4&gt;该风险引导的扩散框架为极端地形中的机器人导航提供了有效的解决方案，结合了适应性和安全性。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在极端、不熟悉的地区进行安全可靠的导航对于未来的机器人太空探索任务至关重要。最近基于生成式AI的方法从大型、跨身躯数据集中学习语义感知的导航策略，但提供的安全性保证有限。受人类认知科学的启发，我们提出了一种风险引导的扩散框架，将快速学习的“系统-1”与慢速的基于物理的“系统-2”相结合，在训练和推理过程中共享计算，以结合适应性与形式安全性。在NASA JPL的火星模拟设施Mars Yard进行的硬件实验表明，我们的方法将失败率降低了高达4倍，同时通过利用推理时的计算能力，与基于学习的机器人模型达到了相当的目标达成性能，而不需要进行额外的训练。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-21&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Safe, reliable navigation in extreme, unfamiliar terrain is required forfuture robotic space exploration missions. Recent generative-AI methods learnsemantically aware navigation policies from large, cross-embodiment datasets,but offer limited safety guarantees. Inspired by human cognitive science, wepropose a risk-guided diffusion framework that fuses a fast, learned "System-1"with a slow, physics-based "System-2", sharing computation at both training andinference to couple adaptability with formal safety. Hardware experimentsconducted at the NASA JPL's Mars-analog facility, Mars Yard, show that ourapproach reduces failure rates by up to $4\times$ while matching thegoal-reaching performance of learning-based robotic models by leveraginginference-time compute without any additional training.</description>
      <author>example@mail.com (Rohan Thakker, Adarsh Patnaik, Vince Kurtz, Jonas Frey, Jonathan Becktor, Sangwoo Moon, Rob Royce, Marcel Kaufmann, Georgios Georgakis, Pascal Roth, Joel Burdick, Marco Hutter, Shehryar Khattak)</author>
      <guid isPermaLink="false">2506.17601v1</guid>
      <pubDate>Tue, 24 Jun 2025 14:30:17 +0800</pubDate>
    </item>
    <item>
      <title>Stable CDE Autoencoders with Acuity Regularization for Offline Reinforcement Learning in Sepsis Treatment</title>
      <link>http://arxiv.org/abs/2506.15019v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to IJCAI2025 AI4TS&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;研究提出了使用受控微分方程（CDE）进行脓毒症治疗的有效强化学习（RL），强调了在从非规则的ICU时间序列中学习稳定的临床有意义的表征时，训练稳定性和表征的敏锐度的重要性。&lt;h4&gt;背景&lt;/h4&gt;目前对于脓毒症治疗的研究，需要从非规则的ICU时间序列中学习稳定的临床有意义的表征。&lt;h4&gt;目的&lt;/h4&gt;探索使用CDE状态表征实现强RL策略的方法，并解决训练不稳定性和其对抗策性能的负面影响。&lt;h4&gt;方法&lt;/h4&gt;通过以下方法实现：1) 通过早期停止或稳定化方法确保训练稳定性；2) 通过与临床评分（如SOFA、SAPS-II、OASIS）的相关正则化来强制执行敏锐度感知的表征。&lt;h4&gt;主要发现&lt;/h4&gt;在MIMIC-III脓毒症队列上的实验表明，稳定的CDE自动编码器生成的表征与敏锐度得分高度相关，并使RL策略的性能显著提高（WIS回报率&gt;0.9）。不稳定的CDE表征则导致表征下降和策略失败（WIS回报率≈0）。可视化显示稳定的CDE不仅可以区分生存者和非生存者的轨迹，还可以揭示清晰的敏锐度得分梯度，而不稳定的训练则无法捕捉这些模式。&lt;h4&gt;结论&lt;/h4&gt;这些发现为使用CDE对不规则医疗时间序列进行编码提供了实用的指南，强调了在序列表征学习中的训练稳定性需求。&lt;h4&gt;翻译&lt;/h4&gt;摘要：有效的脓毒症治疗强化学习（RL）依赖于从非规则的ICU时间序列中学习稳定的、具有临床意义的表征。尽管以前的工作已经探讨了该任务中的表征学习方法，但训练中序列表征的不稳定性和其对策略性能的负面影响却一直被忽视。本研究证明了当满足两个关键因素时，受控微分方程（CDE）状态表征可以实现强大的RL策略：（1）通过早期停止或稳定化方法确保训练稳定性；（2）通过与临床评分（SOFA、SAPS-II、OASIS）的相关正则化强制执行敏锐度感知的表征。在MIMIC-III脓毒症队列上的实验表明，稳定的CDE自动编码器生成的表征与敏锐度得分高度相关，并使RL策略的性能显著提高（WIS回报率&gt;0.9）。相比之下，不稳定的CDE表征导致表征下降和策略失败（WIS回报率≈0）。潜在空间的可视化表明，稳定的CDE不仅能够区分生存者和非生存者的轨迹，还能揭示清晰的敏锐度得分梯度，而不稳定的训练则无法捕捉到这些模式。这些发现突出了使用CDE在临床RL中编码不规则医疗时间序列的实用指南，强调了在序列表征学习中的训练稳定性需求。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/gaoyuetianc/rl_mimic_cde_stable&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effective reinforcement learning (RL) for sepsis treatment depends onlearning stable, clinically meaningful state representations from irregular ICUtime series. While previous works have explored representation learning forthis task, the critical challenge of training instability in sequentialrepresentations and its detrimental impact on policy performance has beenoverlooked. This work demonstrates that Controlled Differential Equations (CDE)state representation can achieve strong RL policies when two key factors aremet: (1) ensuring training stability through early stopping or stabilizationmethods, and (2) enforcing acuity-aware representations by correlationregularization with clinical scores (SOFA, SAPS-II, OASIS). Experiments on theMIMIC-III sepsis cohort reveal that stable CDE autoencoder producesrepresentations strongly correlated with acuity scores and enables RL policieswith superior performance (WIS return $&gt; 0.9$). In contrast, unstable CDErepresentation leads to degraded representations and policy failure (WIS return$\sim$ 0). Visualizations of the latent space show that stable CDEs not onlyseparate survivor and non-survivor trajectories but also reveal clear acuityscore gradients, whereas unstable training fails to capture either pattern.These findings highlight practical guidelines for using CDEs to encodeirregular medical time series in clinical RL, emphasizing the need for trainingstability in sequential representation learning.</description>
      <author>example@mail.com (Yue Gao)</author>
      <guid isPermaLink="false">2506.15019v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
  <item>
      <title>Optimal alignment of Lorentz orientation and generalization to matrix Lie groups</title>
      <link>http://arxiv.org/abs/2506.14994v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种在三维空间中对点云进行对齐的优雅方法，并探讨了如何将这种方法应用于Minkowski度量的对齐问题。&lt;h4&gt;背景&lt;/h4&gt;目前存在对三维空间中点云进行对齐的优雅方法，但这些方法依赖于欧几里得度量的正定性，难以推广到Minkowski度量。&lt;h4&gt;目的&lt;/h4&gt;针对给定的惯性参考系A和B以及在这些参考系中测量的（可能含有噪声的）4-向量集合{v_i}，本文提出了两种解决方案，即找到最优的洛伦兹变换Λ，使得Λv_{A,i}=v_{B,i}。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法在概念上简单，并且可以容易地扩展到其他矩阵李群的对齐问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文针对Minkowski度量下的对齐问题，提出了两种解决方案，并证明这些方法概念简单且可扩展。&lt;h4&gt;结论&lt;/h4&gt;本文的研究表明，可以应用新的方法来解决Minkowski度量下的对齐问题，为相关领域的研究提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了三维空间中点云对齐的方法，并提出了将此方法应用于Minkowski度量下的对齐问题的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; There exist elegant methods of aligning point clouds in $\mathbb R^3$.Unfortunately, these methods rely on the positive definite property of theEuclidean metric, and do not easily extend to the indefinite Minkowski metric.In this paper, we propose two solutions to the following problem: giveninertial reference frames $A$ and $B$, and given (possibly noisy) measurementsof a set of 4-vectors $\{v_i\}$ made in those reference frames with components$\{v_{A,i}\}$ and $\{v_{B,i}\}$, find the optimal Lorentz transformation$\Lambda$ such that $\Lambda v_{A,i}=v_{B,i}$. The method we outline isconceptually simple and easily extends to alignment problems in other matrixLie groups.</description>
      <author>example@mail.com (Congzhou M Sha)</author>
      <guid isPermaLink="false">2506.14994v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>DreamCube: 3D Panorama Generation via Multi-plane Synchronization</title>
      <link>http://arxiv.org/abs/2506.17206v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Project page: https://yukun-huang.github.io/DreamCube/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于多平面同步的3D全景合成方法，通过DreamCube模型实现高质量的3D全景内容生成。&lt;h4&gt;背景&lt;/h4&gt;3D全景合成是一个具有挑战性的任务，需要生成高质量和多样化的全景内容。&lt;h4&gt;目的&lt;/h4&gt;旨在通过改进现有方法，实现更高质量的3D全景内容生成。&lt;h4&gt;方法&lt;/h4&gt;通过将多平面同步应用于2D基础模型的操作符，扩展其能力以适应全景领域，并引入DreamCube模型，这是一个多平面RGB-D扩散模型，用于3D全景生成。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在全景图像生成、全景深度估计和3D场景生成方面都表现出有效性。&lt;h4&gt;结论&lt;/h4&gt;多平面同步和DreamCube模型为3D全景合成提供了一种有效的方法，可以生成多样化且准确的全景内容。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; 3D panorama synthesis is a promising yet challenging task that demandshigh-quality and diverse visual appearance and geometry of the generatedomnidirectional content. Existing methods leverage rich image priors frompre-trained 2D foundation models to circumvent the scarcity of 3D panoramicdata, but the incompatibility between 3D panoramas and 2D single views limitstheir effectiveness. In this work, we demonstrate that by applying multi-planesynchronization to the operators from 2D foundation models, their capabilitiescan be seamlessly extended to the omnidirectional domain. Based on this design,we further introduce DreamCube, a multi-plane RGB-D diffusion model for 3Dpanorama generation, which maximizes the reuse of 2D foundation model priors toachieve diverse appearances and accurate geometry while maintaining multi-viewconsistency. Extensive experiments demonstrate the effectiveness of ourapproach in panoramic image generation, panoramic depth estimation, and 3Dscene generation.</description>
      <author>example@mail.com (Yukun Huang, Yanning Zhou, Jianan Wang, Kaiyi Huang, Xihui Liu)</author>
      <guid isPermaLink="false">2506.17206v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings</title>
      <link>http://arxiv.org/abs/2506.17064v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  10 pages (main text), 4 figures, 2 tables. Submitted to NeurIPS 2025.  Code and data are publicly available&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为LD-FPG的框架，用于从分子动力学轨迹中生成蛋白质的完整全原子构象集合，为理解蛋白质功能提供了新的方法。&lt;h4&gt;背景&lt;/h4&gt;大多数生成模型简化了原子细节或完全忽略了构象多样性，这对于理解如G蛋白偶联受体（GPCRs）等动态蛋白质的功能至关重要。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够生成动态蛋白质如GPCRs的全原子构象集合的方法。&lt;h4&gt;方法&lt;/h4&gt;LD-FPG使用Chebyshev图神经网络（ChebNet）获得蛋白质构象的低维潜在嵌入，并通过三种池化策略（盲目、顺序和基于残基）进行处理。扩散模型基于这些潜在表示生成新的样本，解码器将这些样本映射回笛卡尔坐标。&lt;h4&gt;主要发现&lt;/h4&gt;使用人类多巴胺D2受体在膜环境中的2微秒分子动力学轨迹（12,000帧）进行实验，顺序和基于残基的池化策略能够以高结构保真度（全原子lDDT约为0.7；C-α-lDDT约为0.8）再现参考集合，并且与MD数据相比，骨架和侧链二面角分布的Jensen-Shannon散度小于0.03。&lt;h4&gt;结论&lt;/h4&gt;LD-FPG为生成大蛋白质的系统特异性全原子集合提供了一种实用的途径，对于复杂动态目标的基于结构的药物设计具有潜在价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：生成动态蛋白质如G蛋白偶联受体（GPCRs）的多样、全原子的构象集合对于理解其功能至关重要，然而，大多数生成模型简化了原子细节或者完全忽略了构象多样性。我们提出了用于全蛋白质生成的潜在扩散模型（LD-FPG），该模型能够直接从分子动力学（MD）轨迹中构建完整全原子蛋白质结构，包括每个侧链重原子。LD-FPG采用Chebyshev图神经网络（ChebNet）获得蛋白质构象的低维潜在嵌入，并通过三种池化策略：盲目、顺序和残基进行加工。基于这些潜在表示的扩散模型生成新的样本，解码器将这些样本映射回笛卡尔坐标。使用D2R-MD，一个人类多巴胺D2受体在膜环境中的2微秒MD轨迹（12,000帧），顺序和基于残基的池化策略以高结构保真度再现了参考集合（全原子lDDT约为0.7；C-α-lDDT约为0.8），并且与MD数据相比，骨架和侧链二面角分布的Jensen-Shannon散度小于0.03。因此，LD-FPG为生成大蛋白质的系统特异性全原子集合提供了一种实用的途径，为复杂动态目标的基于结构的药物设计提供了一种有前途的工具。D2R-MD数据集和我们的实现是免费提供的，以促进进一步的研究。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generating diverse, all-atom conformational ensembles of dynamic proteinssuch as G-protein-coupled receptors (GPCRs) is critical for understanding theirfunction, yet most generative models simplify atomic detail or ignoreconformational diversity altogether. We present latent diffusion for fullprotein generation (LD-FPG), a framework that constructs complete all-atomprotein structures, including every side-chain heavy atom, directly frommolecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neuralnetwork (ChebNet) to obtain low-dimensional latent embeddings of proteinconformations, which are processed using three pooling strategies: blind,sequential and residue-based. A diffusion model trained on these latentrepresentations generates new samples that a decoder, optionally regularized bydihedral-angle losses, maps back to Cartesian coordinates. Using D2R-MD, a2-microsecond MD trajectory (12 000 frames) of the human dopamine D2 receptorin a membrane environment, the sequential and residue-based pooling strategyreproduces the reference ensemble with high structural fidelity (all-atom lDDTof approximately 0.7; C-alpha-lDDT of approximately 0.8) and recovers backboneand side-chain dihedral-angle distributions with a Jensen-Shannon divergence ofless than 0.03 compared to the MD data. LD-FPG thereby offers a practical routeto system-specific, all-atom ensemble generation for large proteins, providinga promising tool for structure-based therapeutic design on complex, dynamictargets. The D2R-MD dataset and our implementation are freely available tofacilitate further research.</description>
      <author>example@mail.com (Aditya Sengar, Ali Hariri, Daniel Probst, Patrick Barth, Pierre Vandergheynst)</author>
      <guid isPermaLink="false">2506.17064v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning</title>
      <link>http://arxiv.org/abs/2506.16141v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code released at: https://github.com/TencentARC/GRPO-CARE&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的强化学习框架GRPO-CARE，用于提升多模态语言模型（MLLMs）的推理能力，并通过一个名为SEED-Bench-R1的基准测试进行了验证。&lt;h4&gt;背景&lt;/h4&gt;近年来，强化学习在大型语言模型（LLMs）的推理能力上取得了进展，但在多模态LLMs上的应用尚未探索。&lt;h4&gt;目的&lt;/h4&gt;为了解决多模态LLMs后训练方法的严格评估不足的问题，本文引入了SEED-Bench-R1基准，并提出了GRPO-CARE框架。&lt;h4&gt;方法&lt;/h4&gt;SEED-Bench-R1包含复杂的真实世界视频，要求平衡感知和推理。GRPO-CARE通过优化答案正确性和推理连贯性来提升模型性能，引入了两层奖励机制，并使用自适应一致性奖励代替了KL惩罚。&lt;h4&gt;主要发现&lt;/h4&gt;标准GRPO在提升答案准确率的同时，降低了推理步骤和答案之间的逻辑连贯性，一致性率仅为57.9%。GRPO-CARE在SEED-Bench-R1上优于标准GRPO，在最高难度评估级别上提升了6.7%的性能，并在一致性上提升了24.5%。此外，GRPO-CARE在多个视频理解基准测试中表现出良好的迁移能力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的SEED-Bench-R1基准和GRPO-CARE框架为MLLMs的发展提供了系统设计的基准和可迁移的后训练框架，有助于提升MLLMs的可解释性和鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent reinforcement learning approaches, such as outcome-supervised GRPO,have advanced Chain-of-Thought reasoning in large language models (LLMs), yettheir adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lackof rigorous evaluation for MLLM post-training methods, we introduceSEED-Bench-R1, a benchmark with complex real-world videos requiring balancedperception and reasoning. It offers a large training set and evaluatesgeneralization across three escalating challenges: in-distribution,cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1,we find that standard GRPO, while improving answer accuracy, often reduceslogical coherence between reasoning steps and answers, with only a 57.9%consistency rate. This stems from reward signals focusing solely on finalanswers, encouraging shortcuts, and strict KL penalties limiting exploration.Toaddress this, we propose GRPO-CARE, a consistency-aware RL framework optimizingboth answer correctness and reasoning coherence without explicit supervision.GRPO-CARE introduces a two-tiered reward: (1) a base reward for answercorrectness, and (2) an adaptive consistency bonus, computed by comparing themodel's reasoning-to-answer likelihood (via a slowly-evolving reference model)against group peers.This dual mechanism amplifies rewards for reasoning pathsthat are both correct and logically consistent. Replacing KL penalties withthis adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1,achieving a 6.7% performance gain on the hardest evaluation level and a 24.5%improvement in consistency. It also shows strong transferability, improvingmodel performance across diverse video understanding benchmarks. Our workcontributes a systematically designed benchmark and a generalizablepost-training framework, advancing the development of more interpretable androbust MLLMs.</description>
      <author>example@mail.com (Yi Chen, Yuying Ge, Rui Wang, Yixiao Ge, Junhao Cheng, Ying Shan, Xihui Liu)</author>
      <guid isPermaLink="false">2506.16141v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation</title>
      <link>http://arxiv.org/abs/2506.17202v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Code: https://github.com/tliby/UniFork&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了统一图像理解和生成在多模态人工智能中的应用，提出了一种名为UniFork的新型Y形架构，通过共享浅层网络层以实现跨任务表示学习，同时在深层网络层采用特定于任务的分支以避免任务干扰，从而在共享学习和任务专业化之间取得平衡。&lt;h4&gt;背景&lt;/h4&gt;统一图像理解和生成是人工智能领域的一个新兴范式，尽管近年来取得了进展，但这类统一模型的最佳架构设计仍然是一个挑战。&lt;h4&gt;目的&lt;/h4&gt;分析特定于任务的专家模型在理解和生成任务中的模态对齐行为，以及当前统一模型的模态对齐行为，并提出一种新的架构来优化统一模型的表现。&lt;h4&gt;方法&lt;/h4&gt;通过分析模态对齐行为，提出了一种名为UniFork的新型Y形架构，该架构在浅层网络层共享表示学习，而在深层网络层采用特定于任务的分支。&lt;h4&gt;主要发现&lt;/h4&gt;理解任务受益于网络深度上模态对齐的逐渐增加，有助于构建语义信息以更好地理解；而生成任务则遵循不同的趋势：模态对齐在早期层增加，但在深层层减少以恢复空间细节。&lt;h4&gt;结论&lt;/h4&gt;UniFork架构在性能上优于传统的完全共享Transformer架构，并且在性能上与特定于任务的模型相当或更好。&lt;h4&gt;翻译&lt;/h4&gt;Unified image understanding and generation has emerged as a promising paradigm in multimodal artificial intelligence. Despite recent progress, the optimal architectural design for such unified models remains an open challenge. In this work, we start by analyzing the modality alignment behaviors of task-specific expert models for understanding and generation, as well as current unified models. Our analysis reveals a crucial observation: understanding tasks benefit from a progressively increasing modality alignment across network depth, which helps build up semantic information for better comprehension; In contrast, generation tasks follow a different trend: modality alignment increases in the early layers but decreases in the deep layers to recover spatial details. These divergent alignment patterns create a fundamental conflict in fully shared Transformer backbones, where a uniform representational flow often leads to performance compromises across two tasks. Motivated by this finding, we introduce UniFork, a novel Y-shaped architecture that shares the shallow layers for cross-task representation learning, while employing task-specific branches in deeper layers to avoid task interference. This design effectively balances shared learning and task specialization. Through extensive ablation experiments, we demonstrate that Unifork consistently outperforms conventional fully shared Transformer architectures, and achieves performance on par with or better than task-specific models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unified image understanding and generation has emerged as a promisingparadigm in multimodal artificial intelligence. Despite recent progress, theoptimal architectural design for such unified models remains an open challenge.In this work, we start by analyzing the modality alignment behaviors oftask-specific expert models for understanding and generation, as well ascurrent unified models. Our analysis reveals a crucial observation:understanding tasks benefit from a progressively increasing modality alignmentacross network depth, which helps build up semantic information for bettercomprehension; In contrast, generation tasks follow a different trend: modalityalignment increases in the early layers but decreases in the deep layers torecover spatial details. These divergent alignment patterns create afundamental conflict in fully shared Transformer backbones, where a uniformrepresentational flow often leads to performance compromises across two tasks.Motivated by this finding, we introduce UniFork, a novel Y-shaped architecturethat shares the shallow layers for cross-task representation learning, whileemploying task-specific branches in deeper layers to avoid task interference.This design effectively balances shared learning and task specialization.Through extensive ablation experiments, we demonstrate that Uniforkconsistently outperforms conventional fully shared Transformer architectures,and achieves performance on par with or better than task-specific models.</description>
      <author>example@mail.com (Teng Li, Quanfeng Lu, Lirui Zhao, Hao Li, Xizhou Zhu, Yu Qiao, Jun Zhang, Wenqi Shao)</author>
      <guid isPermaLink="false">2506.17202v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>How Hard Is Snow? A Paired Domain Adaptation Dataset for Clear and Snowy Weather: CADC+</title>
      <link>http://arxiv.org/abs/2506.16531v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  IEEE IV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了降雪对3D物体检测性能的影响，并提出了CADC+数据集，用于解决现有驾驶数据集在降雪天气下的数据不足问题。&lt;h4&gt;背景&lt;/h4&gt;降雪对3D物体检测性能的影响尚未得到充分研究，现有驾驶数据集要么在降雪和晴朗天气条件下缺乏足够标注数据，要么依赖去雪方法生成合成晴朗天气数据，这会引入额外的领域差异，影响评估的准确性。&lt;h4&gt;目的&lt;/h4&gt;提出CADC+数据集，以解决现有数据集的不足，为评估降雪对3D物体检测性能的影响提供真实的数据。&lt;h4&gt;方法&lt;/h4&gt;CADC+扩展了加拿大不利驾驶条件数据集（CADC），使用与CADC同期、同路段的晴朗天气数据，并与降雪序列进行配对，以最小化因降雪以外的因素导致的领域差异。此外，使用CADC+进行初步实验以评估降雪对3D物体检测性能的影响。&lt;h4&gt;主要发现&lt;/h4&gt;CADC+数据集通过配对天气条件下的数据，减少了领域差异。实验结果表明，降雪引入了随机和认知不确定性，既作为噪声也作为一个独特的数据领域，影响了3D物体检测性能。&lt;h4&gt;结论&lt;/h4&gt;CADC+数据集为评估降雪对3D物体检测性能的影响提供了真实、有效的方法，有助于推动相关领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;The impact of snowfall on 3D object detection performance remains underexplored. Conducting such an evaluation requires a dataset with sufficient labelled data from both weather conditions, ideally captured in the same driving environment. Current driving datasets with LiDAR point clouds either do not provide enough labelled data in both snowy and clear weather conditions, or rely on de-snowing methods to generate synthetic clear weather. Synthetic data often lacks realism and introduces an additional domain shift that confounds accurate evaluations. To address these challenges, we present CADC+, the first paired weather domain adaptation dataset for autonomous driving in winter conditions. CADC+ extends the Canadian Adverse Driving Conditions dataset (CADC) using clear weather data that was recorded on the same roads and in the same period as CADC. To create CADC+, we pair each CADC sequence with a clear weather sequence that matches the snowy sequence as closely as possible. CADC+ thus minimizes the domain shift resulting from factors unrelated to the presence of snow. We also present some preliminary results using CADC+ to evaluate the effect of snow on 3D object detection performance. We observe that snow introduces a combination of aleatoric and epistemic uncertainties, acting as both noise and a distinct data domain.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The impact of snowfall on 3D object detection performance remainsunderexplored. Conducting such an evaluation requires a dataset with sufficientlabelled data from both weather conditions, ideally captured in the samedriving environment. Current driving datasets with LiDAR point clouds either donot provide enough labelled data in both snowy and clear weather conditions, orrely on de-snowing methods to generate synthetic clear weather. Synthetic dataoften lacks realism and introduces an additional domain shift that confoundsaccurate evaluations. To address these challenges, we present CADC+, the firstpaired weather domain adaptation dataset for autonomous driving in winterconditions. CADC+ extends the Canadian Adverse Driving Conditions dataset(CADC) using clear weather data that was recorded on the same roads and in thesame period as CADC. To create CADC+, we pair each CADC sequence with a clearweather sequence that matches the snowy sequence as closely as possible. CADC+thus minimizes the domain shift resulting from factors unrelated to thepresence of snow. We also present some preliminary results using CADC+ toevaluate the effect of snow on 3D object detection performance. We observe thatsnow introduces a combination of aleatoric and epistemic uncertainties, actingas both noise and a distinct data domain.</description>
      <author>example@mail.com (Mei Qi Tang, Sean Sedwards, Chengjie Huang, Krzysztof Czarnecki)</author>
      <guid isPermaLink="false">2506.16531v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding</title>
      <link>http://arxiv.org/abs/2506.16754v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages, 9 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于元路径的超曲率对比学习框架（MHCL），用于处理异构图中的复杂结构，并通过对比学习优化元路径嵌入的判别性。&lt;h4&gt;背景&lt;/h4&gt;异构图具有多样的幂律结构，但现有的超曲率异构图嵌入模型大多依赖于单一的超曲率空间，无法有效捕捉这些结构。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出MHCL框架，使用多个超曲率空间来捕捉异构图中的多样复杂结构。&lt;h4&gt;方法&lt;/h4&gt;MHCL通过学习每个超曲率空间来描述对应元路径的复杂结构分布，并使用对比学习方法来优化框架，通过最小化相同元路径嵌入之间的距离和最大化不同元路径嵌入之间的距离，提高元路径嵌入的判别性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，MHCL在各种图机器学习任务中优于现有基准，有效地捕捉了异构图的复杂结构。&lt;h4&gt;结论&lt;/h4&gt;MHCL框架能够有效地处理异构图中的复杂结构，并在图机器学习任务中表现出色。&lt;h4&gt;翻译&lt;/h4&gt;摘要：双曲空间，以其恒定的负曲率和指数扩张的特性，与异构图的结构特性相吻合。尽管异构图本质上具有多样的幂律结构，但大多数基于超曲率的异构图嵌入模型依赖于单一的超曲率空间。这种方法可能无法有效地捕捉异构图中的多样幂律结构。为了解决这一局限性，我们提出了一个基于元路径的超曲率对比学习框架（MHCL），它使用多个超曲率空间来捕捉异构图中的多样复杂结构。具体而言，通过学习每个超曲率空间来描述每个元路径对应的复杂结构分布，可以有效地捕捉语义信息。由于元路径嵌入表示不同的语义信息，在聚合它们以获得节点表示时保持其判别性很重要。因此，我们使用对比学习方法来优化MHCL，并提高元路径嵌入的判别性。特别是，我们的对比学习方法通过最小化相同元路径嵌入之间的距离和最大化不同元路径嵌入之间的距离在超曲率空间中，从而提高了具有不同语义信息的元路径嵌入的分离性。我们进行了全面的实验来评估MHCL的有效性。实验结果表明，MHCL在各种图机器学习任务中优于现有基准，有效地捕捉了异构图的复杂结构。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The hyperbolic space, characterized by a constant negative curvature andexponentially expanding space, aligns well with the structural properties ofheterogeneous graphs. However, although heterogeneous graphs inherently possessdiverse power-law structures, most hyperbolic heterogeneous graph embeddingmodels rely on a single hyperbolic space. This approach may fail to effectivelycapture the diverse power-law structures within heterogeneous graphs. Toaddress this limitation, we propose a Metapath-based Hyperbolic ContrastiveLearning framework (MHCL), which uses multiple hyperbolic spaces to capturediverse complex structures within heterogeneous graphs. Specifically, bylearning each hyperbolic space to describe the distribution of complexstructures corresponding to each metapath, it is possible to capture semanticinformation effectively. Since metapath embeddings represent distinct semanticinformation, preserving their discriminability is important when aggregatingthem to obtain node representations. Therefore, we use a contrastive learningapproach to optimize MHCL and improve the discriminability of metapathembeddings. In particular, our contrastive learning method minimizes thedistance between embeddings of the same metapath and maximizes the distancebetween those of different metapaths in hyperbolic space, thereby improving theseparability of metapath embeddings with distinct semantic information. Weconduct comprehensive experiments to evaluate the effectiveness of MHCL. Theexperimental results demonstrate that MHCL outperforms state-of-the-artbaselines in various graph machine learning tasks, effectively capturing thecomplex structures of heterogeneous graphs.</description>
      <author>example@mail.com (Jongmin Park, Seunghoon Han, Won-Yong Shin, Sungsu Lim)</author>
      <guid isPermaLink="false">2506.16754v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>A Simple Contrastive Framework Of Item Tokenization For Generative Recommendation</title>
      <link>http://arxiv.org/abs/2506.16683v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  12 pages,7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SimCIT的新型无监督深度量化框架，用于基于生成检索的推荐系统。&lt;h4&gt;背景&lt;/h4&gt;基于生成检索的推荐系统在大型推荐系统中面临冗余和大规模token空间的问题。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，如冗余和大规模token空间，并有效整合互补知识。&lt;h4&gt;方法&lt;/h4&gt;SimCIT采用对比学习进行无监督深度量化，利用可学习的残差量化模块，结合多模态知识对齐和语义标记。&lt;h4&gt;主要发现&lt;/h4&gt;SimCIT在公共数据集和多个领域的工业数据集上展示了其在基于LLM的生成推荐中的有效性。&lt;h4&gt;结论&lt;/h4&gt;SimCIT是一种有效的无监督深度量化方法，能够提升基于生成检索的推荐系统的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：基于生成检索的推荐作为一种直接生成目标候选者标识符的范式，已显示出其潜力。然而，在大规模推荐系统中，由于token空间的冗余和规模，这种方法变得越来越繁琐。为了克服这些限制，最近的研究探索了使用语义token作为ID token的替代品，通常利用基于重建的策略，如RQ-VAE，对内容嵌入进行量化并显著减少嵌入大小。然而，重建量化旨在独立精确地重建每个项目嵌入，这与生成检索任务的目标相冲突，后者更关注区分项目。此外，项目的多模态辅助信息，如描述性文本和图像，以及地理位置推荐服务中的地理知识，已被证明通过提供更丰富的交互环境来提高推荐效果。尽管如此，将这些互补知识有效地整合到现有的生成推荐框架中仍然具有挑战性。为了克服这些挑战，我们提出了一种名为SimCIT（简单对比项目标记化框架）的新型无监督深度量化方法。具体来说，不同于现有的基于重建的策略，SimCIT提出使用可学习的残差量化模块来与项目的不同模态信号对齐，该模块在对比学习框架中结合了多模态知识对齐和语义标记。在公共数据集和来自多个领域的工业数据集上的大量实验表明，SimCIT在基于LLM的生成推荐中的有效性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Generative retrieval-based recommendation has emerged as a promising paradigmaiming at directly generating the identifiers of the target candidates.However, in large-scale recommendation systems, this approach becomesincreasingly cumbersome due to the redundancy and sheer scale of the tokenspace. To overcome these limitations, recent research has explored the use ofsemantic tokens as an alternative to ID tokens, which typically leveragedreconstruction-based strategies, like RQ-VAE, to quantize content embeddingsand significantly reduce the embedding size. However, reconstructivequantization aims for the precise reconstruction of each item embeddingindependently, which conflicts with the goal of generative retrieval tasksfocusing more on differentiating among items. Moreover, multi-modal sideinformation of items, such as descriptive text and images, geographicalknowledge in location-based recommendation services, has been shown to beeffective in improving recommendations by providing richer contexts forinteractions. Nevertheless, effectively integrating such complementaryknowledge into existing generative recommendation frameworks remainschallenging. To overcome these challenges, we propose a novel unsupervised deepquantization exclusively based on contrastive learning, named SimCIT (a SimpleContrastive Item Tokenization framework). Specifically, different from existingreconstruction-based strategies, SimCIT propose to use a learnable residualquantization module to align with the signals from different modalities of theitems, which combines multi-modal knowledge alignment and semantic tokenizationin a mutually beneficial contrastive learning framework. Extensive experimentsacross public datasets and a large-scale industrial dataset from variousdomains demonstrate SimCIT's effectiveness in LLM-based generativerecommendation.</description>
      <author>example@mail.com (Penglong Zhai, Yifang Yuan, Fanyi Di, Jie Li, Yue Liu, Chen Li, Jie Huang, Sicong Wang, Yao Xu, Xin Li)</author>
      <guid isPermaLink="false">2506.16683v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Anomaly Detection in Event-triggered Traffic Time Series via Similarity Learning</title>
      <link>http://arxiv.org/abs/2506.16855v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 14 figures. Published in IEEE Transactions on Dependable  and Secure Computing. arXiv admin note: substantial text overlap with  arXiv:2207.08159&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了时间序列分析在网络安全领域的应用，特别是针对事件触发型时间序列相似性学习的问题。&lt;h4&gt;背景&lt;/h4&gt;由于事件触发型时间序列的复杂时间动态性，对于安全相关任务（如异常检测和聚类）中适当的相似性度量尚不明确。&lt;h4&gt;目的&lt;/h4&gt;提出一个无监督学习框架，用于学习一组事件触发型时间序列之间的相似性。&lt;h4&gt;方法&lt;/h4&gt;利用层次多分辨率序列自动编码器和高斯混合模型（GMM）从时间序列中有效地学习低维表示。&lt;h4&gt;主要发现&lt;/h4&gt;通过广泛的定性和定量实验，该方法在性能上优于现有技术。&lt;h4&gt;结论&lt;/h4&gt;该框架为系统性地建模和学习大量事件触发型时间序列的相似性提供了一个有价值的起点。&lt;h4&gt;翻译&lt;/h4&gt;This paper investigates the application of time series analysis in the field of cybersecurity, especially for the problem of similarity learning among event-triggered time series. Due to the complex temporal dynamics of event-triggered time series, it remains unclear which similarity metric is appropriate for security-related tasks such as anomaly detection and clustering. The overall goal of this paper is to develop an unsupervised learning framework capable of learning the similarities among a set of event-triggered time series. From the perspective of machine learning, the proposed framework harnesses the power of both hierarchical multi-resolution sequential autoencoders and Gaussian Mixture Model (GMM) to effectively learn low-dimensional representations from the time series. Extensive qualitative and quantitative experiments show that the proposed method outperforms the state-of-the-art methods considerably. The proposed framework aims to provide a stepping stone for a systematic approach to model and learn the similarities among a multitude of event-triggered time series.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; 10.1109/TDSC.2024.3418906&lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series analysis has achieved great success in cyber security such asintrusion detection and device identification. Learning similarities amongmultiple time series is a crucial problem since it serves as the foundation fordownstream analysis. Due to the complex temporal dynamics of theevent-triggered time series, it often remains unclear which similarity metricis appropriate for security-related tasks, such as anomaly detection andclustering. The overarching goal of this paper is to develop an unsupervisedlearning framework that is capable of learning similarities among a set ofevent-triggered time series. From the machine learning vantage point, theproposed framework harnesses the power of both hierarchical multi-resolutionsequential autoencoders and the Gaussian Mixture Model (GMM) to effectivelylearn the low-dimensional representations from the time series. Finally, theobtained similarity measure can be easily visualized for the explanation. Theproposed framework aspires to offer a stepping stone that gives rise to asystematic approach to model and learn similarities among a multitude ofevent-triggered time series. Through extensive qualitative and quantitativeexperiments, it is revealed that the proposed method outperformsstate-of-the-art methods considerably.</description>
      <author>example@mail.com (Shaoyu Dou, Kai Yang, Yang Jiao, Chengbo Qiu, Kui Ren)</author>
      <guid isPermaLink="false">2506.16855v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Empowering Graph-based Approximate Nearest Neighbor Search with Adaptive Awareness Capabilities</title>
      <link>http://arxiv.org/abs/2506.15986v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accecpted by KDD2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为GATE的高维空间近似最近邻搜索方法，通过自适应拓扑和查询感知来加速近似最近邻搜索。&lt;h4&gt;背景&lt;/h4&gt;近似最近邻搜索在高维空间数据库、信息检索、推荐系统等领域有广泛应用。基于图的方法虽然性能优越，但仍存在局部最优和冗余计算等问题。&lt;h4&gt;目的&lt;/h4&gt;提出GATE方法，旨在解决现有方法未能充分利用邻近图G中的拓扑信息，以及基数据与查询之间存在严重分布不匹配的问题。&lt;h4&gt;方法&lt;/h4&gt;GATE首先提取一组枢纽节点作为候选入口点，然后利用对比学习模型将这些枢纽节点的结构语义和查询相关特征编码到潜在表示中。接着，构建一个导航图索引以最小化模型推理开销。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，与最先进的基于图的方法相比，GATE在查询性能上实现了1.2-2.0倍的速度提升。&lt;h4&gt;结论&lt;/h4&gt;GATE作为一种轻量级且自适应的模块，可以有效地加速近似最近邻搜索，提高查询效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Approximate Nearest Neighbor Search (ANNS) in high-dimensional spaces findsextensive applications in databases, information retrieval, recommendersystems, etc. While graph-based methods have emerged as the leading solutionfor ANNS due to their superior query performance, they still face severalchallenges, such as struggling with local optima and redundant computations.These issues arise because existing methods (i) fail to fully exploit thetopological information underlying the proximity graph G, and (ii) suffer fromsevere distribution mismatches between the base data and queries in practice.  To this end, this paper proposes GATE, high-tier proximity Graph withAdaptive Topology and Query AwarEness, as a lightweight and adaptive moduleatop the graph-based indexes to accelerate ANNS. Specifically, GATE formulatesthe critical problem to identify an optimal entry point in the proximity graphfor a given query, facilitating faster online search. By leveraging theinherent clusterability of high-dimensional data, GATE first extracts a smallset of hub nodes V as candidate entry points. Then, resorting to a contrastivelearning-based two-tower model, GATE encodes both the structural semanticsunderlying G and the query-relevant features into the latent representations ofthese hub nodes V. A navigation graph index on V is further constructed tominimize the model inference overhead. Extensive experiments demonstrate thatGATE achieves a 1.2-2.0X speed-up in query performance compared tostate-of-the-art graph-based indexes.</description>
      <author>example@mail.com (Jiancheng Ruan, Tingyang Chen, Renchi Yang, Xiangyu Ke, Yunjun Gao)</author>
      <guid isPermaLink="false">2506.15986v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective</title>
      <link>http://arxiv.org/abs/2506.16790v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published in TMLR (2025)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对图神经网络（GNNs）随着网络深度增加而性能下降的问题，提出了一种增强GNNs中信号传播（SP）的初始化方法，并命名为SPoGInit。&lt;h4&gt;背景&lt;/h4&gt;GNNs在深度增加时常常会遭受性能退化。&lt;h4&gt;目的&lt;/h4&gt;提出初始化方法来增强GNNs中的信号传播。&lt;h4&gt;方法&lt;/h4&gt;提出三个关键指标：前向传播、反向传播和图嵌入变化（GEV），并分析了一般初始化方法在这些指标上的不足。通过直接利用SP分析，寻找优化这三个指标的权重初始化方差，从而显著增强深度GCNs中的信号传播。&lt;h4&gt;主要发现&lt;/h4&gt;SPoGInit在多种任务和架构上优于常用的初始化方法，并且随着GNNs深度的增加，性能也能得到提升。&lt;h4&gt;结论&lt;/h4&gt;SPoGInit在解决深度相关挑战方面取得了显著进展，验证了SP分析框架的有效性。&lt;h4&gt;翻译&lt;/h4&gt;Graph Neural Networks (GNNs) often suffer from performance degradation as thenetwork depth increases. This paper addresses this issue by introducinginitialization methods that enhance signal propagation (SP) within GNNs. Wepropose three key metrics for effective SP in GNNs: forward propagation,backward propagation, and graph embedding variation (GEV). While the first twometrics derive from classical SP theory, the third is specifically designed forGNNs. We theoretically demonstrate that a broad range of commonly usedinitialization methods for GNNs, which exhibit performance degradation withincreasing depth, fail to control these three metrics simultaneously. To dealwith this limitation, a direct exploitation of the SP analysis--searching forweight initialization variances that optimize the three metrics--is shown tosignificantly enhance the SP in deep GCNs. This approach is called SignalPropagation on Graph-guided Initialization (SPoGInit). Our experimentsdemonstrate that SPoGInit outperforms commonly used initialization methods onvarious tasks and architectures. Notably, SPoGInit enables performanceimprovements as GNNs deepen, which represents a significant advancement inaddressing depth-related challenges and highlights the validity andeffectiveness of the SP analysis framework.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph Neural Networks (GNNs) often suffer from performance degradation as thenetwork depth increases. This paper addresses this issue by introducinginitialization methods that enhance signal propagation (SP) within GNNs. Wepropose three key metrics for effective SP in GNNs: forward propagation,backward propagation, and graph embedding variation (GEV). While the first twometrics derive from classical SP theory, the third is specifically designed forGNNs. We theoretically demonstrate that a broad range of commonly usedinitialization methods for GNNs, which exhibit performance degradation withincreasing depth, fail to control these three metrics simultaneously. To dealwith this limitation, a direct exploitation of the SP analysis--searching forweight initialization variances that optimize the three metrics--is shown tosignificantly enhance the SP in deep GCNs. This approach is called SignalPropagation on Graph-guided Initialization (SPoGInit). Our experimentsdemonstrate that SPoGInit outperforms commonly used initialization methods onvarious tasks and architectures. Notably, SPoGInit enables performanceimprovements as GNNs deepen, which represents a significant advancement inaddressing depth-related challenges and highlights the validity andeffectiveness of the SP analysis framework.</description>
      <author>example@mail.com (Senmiao Wang, Yupeng Chen, Yushun Zhang, Ruoyu Sun, Tian Ding)</author>
      <guid isPermaLink="false">2506.16790v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>AutoHFormer: Efficient Hierarchical Autoregressive Transformer for Time Series Prediction</title>
      <link>http://arxiv.org/abs/2506.16001v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  14 pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为AutoHFormer的层次自回归变换器，用于时间序列预测，它通过三种关键创新解决了时间序列预测中的三个竞争目标。&lt;h4&gt;背景&lt;/h4&gt;时间序列预测需要同时满足严格的时序因果性、亚二次复杂度以及多尺度模式识别。&lt;h4&gt;目的&lt;/h4&gt;提出AutoHFormer，以实现高效且准确的时间序列建模。&lt;h4&gt;方法&lt;/h4&gt;AutoHFormer通过以下三个方面进行创新：1) 层次时序建模，将预测分解为并行处理的段级块，然后进行段内顺序细化；2) 动态窗口注意力机制，使用具有指数衰减的可学习因果窗口，以降低复杂度并保留精确的时序关系；3) 自适应时序编码，采用一种新的位置编码系统，结合固定振荡模式捕捉短期变化和可学习衰减率捕捉长期趋势。&lt;h4&gt;主要发现&lt;/h4&gt;与PatchTST相比，AutoHFormer在PEMS08数据集上实现了10.76倍的训练速度和6.06倍的内存减少，同时在大多数情况下保持了96-720步预测范围内的准确度。&lt;h4&gt;结论&lt;/h4&gt;AutoHFormer为高效且精确的时间序列建模建立了新的基准。&lt;h4&gt;翻译&lt;/h4&gt;时间序列预测需要同时实现严格的时序因果性、亚二次复杂度以及多尺度模式识别。我们提出了一个名为AutoHFormer的层次自回归变换器，通过以下三个关键创新来解决这些挑战：1) 层次时序建模：我们的架构将预测分解为并行处理的段级块，然后进行段内顺序细化。这种双尺度方法在保持时序一致性的同时，实现了高效的计算。2) 动态窗口注意力：注意力机制采用具有指数衰减的可学习因果窗口，降低复杂度同时保留精确的时序关系。这种设计避免了标准变换器中的反因果违规和RNN混合中的顺序瓶颈。3) 自适应时序编码：采用一种新的位置编码系统，捕捉多尺度的时间模式。它结合固定振荡模式用于短期变化和可学习衰减率用于长期趋势。全面的实验表明，与PatchTST相比，AutoHFormer在PEMS08数据集上实现了10.76倍的训练速度和6.06倍的内存减少，同时在大多数情况下保持了96-720步预测范围内的准确度。这些突破为高效且精确的时间序列建模建立了新的基准。我们方法及其所有基线在分层自回归机制中的实现可在https://github.com/lizzyhku/Autotime上找到。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Time series forecasting requires architectures that simultaneously achievethree competing objectives: (1) strict temporal causality for reliablepredictions, (2) sub-quadratic complexity for practical scalability, and (3)multi-scale pattern recognition for accurate long-horizon forecasting. Weintroduce AutoHFormer, a hierarchical autoregressive transformer that addressesthese challenges through three key innovations: 1) Hierarchical TemporalModeling: Our architecture decomposes predictions into segment-level blocksprocessed in parallel, followed by intra-segment sequential refinement. Thisdual-scale approach maintains temporal coherence while enabling efficientcomputation. 2) Dynamic Windowed Attention: The attention mechanism employslearnable causal windows with exponential decay, reducing complexity whilepreserving precise temporal relationships. This design avoids both theanti-causal violations of standard transformers and the sequential bottlenecksof RNN hybrids. 3) Adaptive Temporal Encoding: a novel position encoding systemis adopted to capture time patterns at multiple scales. It combines fixedoscillating patterns for short-term variations with learnable decay rates forlong-term trends. Comprehensive experiments demonstrate that AutoHFormer 10.76Xfaster training and 6.06X memory reduction compared to PatchTST on PEMS08,while maintaining consistent accuracy across 96-720 step horizons in most ofcases. These breakthroughs establish new benchmarks for efficient and precisetime series modeling. Implementations of our method and all baselines inhierarchical autoregressive mechanism are available athttps://github.com/lizzyhku/Autotime.</description>
      <author>example@mail.com (Qianru Zhang, Honggang Wen, Ming Li, Dong Huang, Siu-Ming Yiu, Christian S. Jensen, Pietro Liò)</author>
      <guid isPermaLink="false">2506.16001v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modal Epileptic Signal Harmonization: Frequency Domain Mapping Quantization for Pre-training a Unified Neurophysiological Transformer</title>
      <link>http://arxiv.org/abs/2506.17068v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了EpiNT，一种基于Transformer的预训练模型，用于统一头皮脑电图（EEG）和颅内脑电图（iEEG）的分析，以解决癫痫诊断和治疗中的挑战。&lt;h4&gt;背景&lt;/h4&gt;头皮脑电图和颅内脑电图对于癫痫的诊断和治疗至关重要，但它们的统一分析由于记录蒙版、幅度、信噪比和频率成分的差异而具有挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出EpiNT模型，旨在克服上述挑战，并实现统一癫痫神经生理学分析。&lt;h4&gt;方法&lt;/h4&gt;EpiNT使用通道无关的建模方法，包括掩码自编码器（MAE）和矢量量化（VQ），以及频率域映射量化器来捕捉关键频率特征。该模型在超过2700小时的多模态临床神经生理学数据上进行了预训练。&lt;h4&gt;主要发现&lt;/h4&gt;EpiNT在六个下游分类任务中优于随机初始化的模型和其他预训练方法，证明了其强大的表征学习能力。&lt;h4&gt;结论&lt;/h4&gt;EpiNT为统一癫痫神经生理学分析提供了一种有前景的方法。&lt;h4&gt;翻译&lt;/h4&gt;This paper introduces EpiNT, a novel Transformer-based pre-trained model for unified EEG and iEEG analysis, aiming to overcome the challenges in epilepsy diagnosis and treatment, and provides a promising approach for unified epilepsy neurophysiology analysis.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Scalp electroencephalography (EEG) and intracranial EEG (iEEG) are vital forepilepsy diagnosis and treatment. Their unified analysis offers the potentialto harness the complementary strengths of each modality but is challenging dueto variations in recording montages, amplitude and signal-to-noise ratio (SNR),and frequency components. To address the aforementioned challenges, this paperintroduces EpiNT, a novel Transformer-based pre-trained model for unified EEGand iEEG analysis. EpiNT employs channel-independent modeling with maskedautoencoders (MAE) and vector quantization (VQ), along with a frequency domainmapping quantizer to capture crucial frequency features. Pre-trained on over2,700 hours of multi-modal clinical neurophysiological data from 1,199patients, EpiNT outperformed both randomly initialized models and otherpre-trained methods on six downstream classification tasks, demonstratingrobust representation learning capabilities. This work presents a promisingapproach for unified epilepsy neurophysiology analysis.</description>
      <author>example@mail.com (Runkai Zhang, Hua Yu, John Q. Gan, Haixian Wang)</author>
      <guid isPermaLink="false">2506.17068v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion</title>
      <link>http://arxiv.org/abs/2506.17074v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical Report. Project page: https://assembler3d.github.io&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Assembler的3D部件组装框架，该框架能够从输入部件网格和参考图像中重建完整对象。它能够处理具有不同部件数量、几何形状和结构的多样化真实世界对象。&lt;h4&gt;背景&lt;/h4&gt;现有的3D部件组装方法大多依赖于确定性部件姿态预测和特定类别训练，而Assembler旨在解决这些方法的局限性。&lt;h4&gt;目的&lt;/h4&gt;设计一个能够处理多样化、真实世界3D部件组装的通用框架。&lt;h4&gt;方法&lt;/h4&gt;1. 将部件组装视为一个生成问题，并使用扩散模型来采样可能的配置，有效捕捉对称性、重复部件和多个有效组装带来的歧义。2. 引入基于稀疏锚点云的形状中心表示，使生成过程在欧几里得空间而不是SE(3)姿态预测中实现可扩展性。3. 构建了一个包含超过320K个多样化部件-对象组装的大规模数据集。&lt;h4&gt;主要发现&lt;/h4&gt;Assembler在PartNet上实现了最先进的性能，并首次展示了复杂真实世界对象的高质量组装。&lt;h4&gt;结论&lt;/h4&gt;基于Assembler，我们进一步介绍了一个有趣的部件感知3D建模系统，该系统能够从图像中生成高分辨率、可编辑的对象，展示了交互式和组合设计的潜力。&lt;h4&gt;翻译&lt;/h4&gt;我们提出了一种名为Assembler的3D部件组装框架，该框架能够从输入部件网格和参考图像中重建完整对象。与先前主要依赖确定性部件姿态预测和特定类别训练的方法不同，Assembler旨在处理具有不同部件数量、几何形状和结构的多样化真实世界对象。它通过在任务表述、表示和数据方面的创新来解决扩展到通用3D部件组装的核心挑战。首先，Assembler将部件组装视为一个生成问题，并使用扩散模型来采样可能的配置，有效地捕捉由对称性、重复部件和多个有效组装引起的歧义。其次，我们引入了一种基于稀疏锚点云的形状中心表示，使生成过程在欧几里得空间而不是SE(3)姿态预测中实现可扩展性。第三，我们使用基于现有3D形状库的合成和过滤管道构建了一个包含超过320K个多样化部件-对象组装的大规模数据集。Assembler在PartNet上实现了最先进的性能，并首次展示了复杂真实世界对象的高质量组装。基于Assembler，我们进一步介绍了一个有趣的部件感知3D建模系统，该系统能够从图像中生成高分辨率、可编辑的对象，展示了交互式和组合设计的潜力。项目页面：https://assembler3d.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We present Assembler, a scalable and generalizable framework for 3D partassembly that reconstructs complete objects from input part meshes and areference image. Unlike prior approaches that mostly rely on deterministic partpose prediction and category-specific training, Assembler is designed to handlediverse, in-the-wild objects with varying part counts, geometries, andstructures. It addresses the core challenges of scaling to general 3D partassembly through innovations in task formulation, representation, and data.First, Assembler casts part assembly as a generative problem and employsdiffusion models to sample plausible configurations, effectively capturingambiguities arising from symmetry, repeated parts, and multiple validassemblies. Second, we introduce a novel shape-centric representation based onsparse anchor point clouds, enabling scalable generation in Euclidean spacerather than SE(3) pose prediction. Third, we construct a large-scale dataset ofover 320K diverse part-object assemblies using a synthesis and filteringpipeline built on existing 3D shape repositories. Assembler achievesstate-of-the-art performance on PartNet and is the first to demonstratehigh-quality assembly for complex, real-world objects. Based on Assembler, wefurther introduce an interesting part-aware 3D modeling system that generateshigh-resolution, editable objects from images, demonstrating potential forinteractive and compositional design. Project page:https://assembler3d.github.io</description>
      <author>example@mail.com (Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan)</author>
      <guid isPermaLink="false">2506.17074v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes</title>
      <link>http://arxiv.org/abs/2506.16805v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的基准和模型来评估和改进视觉模型在稀疏图像集中进行共视推理的能力。&lt;h4&gt;背景&lt;/h4&gt;人类能够识别多个图像中重叠的可视区域，这一能力在3D视觉和机器人感知中至关重要。尽管在视觉学习方面取得了显著进展，但当前视觉模型在共视分析方面的表现是否达到人类水平仍不明确。&lt;h4&gt;目的&lt;/h4&gt;设计一个名为Co-Visibility reasONing (Co-VisiON)的基准，以直接评估在超过1000个室内场景中的稀疏图像集上进行共视推理。&lt;h4&gt;方法&lt;/h4&gt;通过实验比较了不同视觉模型在稀疏条件下的表现，并提出了一种新的多视图基准模型Covis。&lt;h4&gt;主要发现&lt;/h4&gt;发现共视分析对现有视觉模型是一个重大挑战，且一种专有的视觉-语言模型在性能上优于所有纯视觉方法，但仍然远远落后于人类表现。&lt;h4&gt;结论&lt;/h4&gt;强调了需要超越基本的成对视觉处理，通过高级推理实现跨多个视图的全面空间理解。Covis模型在纯视觉模型中实现了最佳性能，并缩小了与专有视觉-语言模型的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：人类展现出惊人的识别共视能力——在多个图像中可见的重叠区域，即使这些图像在复杂场景中分布稀疏。这种能力是3D视觉和机器人感知的基础。尽管在视觉学习方面取得了显著进展，但当前视觉模型在共视分析方面的表现是否达到人类水平仍不明确。在本工作中，我们引入了Co-Visibility reasONing (Co-VisiON)基准，旨在直接评估在超过1000个室内场景中的稀疏图像集上进行共视推理。我们的实验表明，尽管共视通常被视为一种低级特征匹配任务，但在稀疏条件下它对现有视觉模型提出了重大挑战。值得注意的是，一种专有的视觉-语言模型在性能上优于所有纯视觉方法，所有模型在表现上都远落后于人类。这一差距强调了需要不仅仅是基本的成对视觉处理——它需要通过跨多个视图的高级推理实现全面的空间理解。受人类视觉认知的启发，我们提出了一种新的多视图基准，Covis，它在纯视觉模型中实现了最佳性能，并缩小了与专有视觉-语言模型的差距。我们希望我们的基准和发现能够促进在具有挑战性和稀疏环境中的视觉模型开发方面的进一步进步。我们的数据集和源代码可在以下链接找到：https://ai4ce.github.io/CoVISION&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Humans exhibit a remarkable ability to recognize co-visibility-theoverlapping regions visible in multiple images-even when these images aresparsely distributed across a complex scene. This capability is foundational in3D vision and robotic perception. Despite significant progress in visionlearning, it remains unclear whether current vision models have reachedhuman-level proficiency in co-visibility analysis. In this work, we introducethe Co-Visibility reasONing (Co-VisiON) benchmark, designed to directlyevaluate co-visibility reasoning on sparse image sets across over 1000 indoorscenarios. Our experiments reveal that while co-visibility is typically treatedas a low-level feature matching task, it poses a significant challenge forexisting vision models under sparse conditions. Notably, a proprietaryvision-language model outperforms all purely vision-based approaches, with allmodels lagging substantially behind human performance. This gap underscores theneed for more than basic pairwise vision processing-it calls for acomprehensive spatial understanding through high-level reasoning acrossmultiple views. Inspired by human visual cognition, we propose a novelmulti-view baseline, Covis, which achieves top performance among pure visionmodels and narrows the gap to the proprietary VLM. We hope our benchmark andfindings will spur further advancements in developing vision models capable ofrobust, high-level reasoning in challenging, sparse environments. Our datasetand source code can be found at: https://ai4ce.github.io/CoVISION</description>
      <author>example@mail.com (Chao Chen, Nobel Dang, Juexiao Zhang, Wenkai Sun, Pengfei Zheng, Xuhang He, Yimeng Ye, Taarun Srinivas, Chen Feng)</author>
      <guid isPermaLink="false">2506.16805v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification</title>
      <link>http://arxiv.org/abs/2506.17140v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为MeDi的新型深度学习模型，旨在解决深度学习模型在病理预测任务中对于不同条件的不鲁棒性问题，如染色、扫描仪、医院和人口统计等因素。&lt;h4&gt;背景&lt;/h4&gt;尽管深度学习模型在病理预测任务上取得了显著进展，但它们对各种条件变化的鲁棒性不足，例如染色、扫描仪、医院和人口统计等因素。如果模型在代表性较高的子群体上训练，它们通常难以处理较少见的模式，导致捷径学习和偏差预测。&lt;h4&gt;目的&lt;/h4&gt;提出MeDi模型，通过将元数据显式地建模到Metadata-guided generative Diffusion模型框架中，实现针对代表性较低的子群体的有针对性的数据增强，以平衡有限的训练数据并减轻下游模型的偏差。&lt;h4&gt;方法&lt;/h4&gt;MeDi模型允许使用合成数据对代表性较低的子群体进行有针对性的增强，从而平衡有限的训练数据并减轻下游模型的偏差。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，MeDi能够为TCGA中未见过的子群体生成高质量的病理图像，提高了生成图像的整体保真度，并使下游分类器在具有子群体变化的数据库上的性能得到提升。&lt;h4&gt;结论&lt;/h4&gt;本文的工作是利用生成模型更好地减轻数据偏差的一个概念验证，为临床实践中的病理预测任务提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：近年来，深度学习模型在病理预测任务上取得了显著进展。然而，由于对染色、扫描仪、医院和人口统计等不同条件的不鲁棒性，其在临床实践中的应用仍然受到限制：如果模型在代表性较高的子群体上训练，它们通常难以处理较少见的模式，导致捷径学习和偏差预测。大规模基础模型尚未完全解决这个问题。因此，我们提出了一种新的方法，即Metadata-guided generative Diffusion模型框架（MeDi）。MeDi允许使用合成数据对代表性较低的子群体进行有针对性的增强，从而平衡有限的训练数据并减轻下游模型的偏差。我们通过实验表明，MeDi能够为TCGA中未见过的子群体生成高质量的病理图像，提高了生成图像的整体保真度，并使下游分类器在具有子群体变化的数据库上的性能得到提升。我们的工作是利用生成模型更好地减轻数据偏差的一个概念验证。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Deep learning models have made significant advances in histologicalprediction tasks in recent years. However, for adaptation in clinical practice,their lack of robustness to varying conditions such as staining, scanner,hospital, and demographics is still a limiting factor: if trained onoverrepresented subpopulations, models regularly struggle with less frequentpatterns, leading to shortcut learning and biased predictions. Large-scalefoundation models have not fully eliminated this issue. Therefore, we propose anovel approach explicitly modeling such metadata into a Metadata-guidedgenerative Diffusion model framework (MeDi). MeDi allows for a targetedaugmentation of underrepresented subpopulations with synthetic data, whichbalances limited training data and mitigates biases in downstream models. Weexperimentally show that MeDi generates high-quality histopathology images forunseen subpopulations in TCGA, boosts the overall fidelity of the generatedimages, and enables improvements in performance for downstream classifiers ondatasets with subpopulation shifts. Our work is a proof-of-concept towardsbetter mitigating data biases with generative models.</description>
      <author>example@mail.com (David Jacob Drexlin, Jonas Dippel, Julius Hense, Niklas Prenißl, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller)</author>
      <guid isPermaLink="false">2506.17140v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>A Strong View-Free Baseline Approach for Single-View Image Guided Point Cloud Completion</title>
      <link>http://arxiv.org/abs/2506.15747v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  6 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于注意力机制的编码器-解码器网络，用于从单张图像引导的点云补全任务，通过实验证明该方法在ShapeNet-ViPC数据集上优于现有方法。&lt;h4&gt;背景&lt;/h4&gt;单视图图像引导的点云补全任务旨在利用单张图像从部分点云重建完整点云，此方法的有效性已得到验证，但图像引导的必要性尚未得到充分探讨。&lt;h4&gt;目的&lt;/h4&gt;探讨图像引导在点云补全中的必要性，并提出一种新的基于注意力机制的编码器-解码器网络。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于注意力机制的编码器-解码器网络，该网络仅以部分点云作为输入，无需考虑视图信息。网络采用层次化自融合机制，通过交叉注意力和自注意力层有效整合多流信息，增强特征表示并提高捕捉几何结构的能力。&lt;h4&gt;主要发现&lt;/h4&gt;在ShapeNet-ViPC数据集上的实验和消融研究表明，该无视图框架在单视图图像引导的点云补全任务中表现优于现有方法。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为多模态学习在单视图图像引导的点云补全任务中的应用提供了新的见解。&lt;h4&gt;翻译&lt;/h4&gt;The single-view image guided point cloud completion (SVIPC) task aims to reconstruct a complete point cloud from a partial input with the help of a single-view image. While previous works have demonstrated the effectiveness of this multimodal approach, the fundamental necessity of image guidance remains largely unexamined. To explore this, we propose a strong baseline approach for SVIPC based on an attention-based multi-branch encoder-decoder network that only takes partial point clouds as input, view-free. Our hierarchical self-fusion mechanism, driven by cross-attention and self-attention layers, effectively integrates information across multiple streams, enriching feature representations and strengthening the networks ability to capture geometric structures. Extensive experiments and ablation studies on the ShapeNet-ViPC dataset demonstrate that our view-free framework performs superiorly to state-of-the-art SVIPC methods. We hope our findings provide new insights into the development of multimodal learning in SVIPC. Our demo code will be available at https://github.com/Zhang-VISLab.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The single-view image guided point cloud completion (SVIPC) task aims toreconstruct a complete point cloud from a partial input with the help of asingle-view image. While previous works have demonstrated the effectiveness ofthis multimodal approach, the fundamental necessity of image guidance remainslargely unexamined. To explore this, we propose a strong baseline approach forSVIPC based on an attention-based multi-branch encoder-decoder network thatonly takes partial point clouds as input, view-free. Our hierarchicalself-fusion mechanism, driven by cross-attention and self-attention layers,effectively integrates information across multiple streams, enriching featurerepresentations and strengthening the networks ability to capture geometricstructures. Extensive experiments and ablation studies on the ShapeNet-ViPCdataset demonstrate that our view-free framework performs superiorly tostate-of-the-art SVIPC methods. We hope our findings provide new insights intothe development of multimodal learning in SVIPC. Our demo code will beavailable at https://github.com/Zhang-VISLab.</description>
      <author>example@mail.com (Fangzhou Lin, Zilin Dai, Rigved Sanku, Songlin Hou, Kazunori D Yamada, Haichong K. Zhang, Ziming Zhang)</author>
      <guid isPermaLink="false">2506.15747v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Relational Deep Learning: Challenges, Foundations and Next-Generation Architectures</title>
      <link>http://arxiv.org/abs/2506.16654v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了关系深度学习（RDL），介绍了如何将关系数据库构建为关系实体图，并讨论了用于开发和发展基于图神经网络（GNN）的RDL模型的相关公开基准数据集，同时探讨了大规模多表集成、建模时间动态和异构数据的复杂性。&lt;h4&gt;背景&lt;/h4&gt;图机器学习在处理任意图结构数据方面提高了模型的性能，并被应用于分子、社交网络、推荐系统和交通等领域。多表关系数据库中的数据也可以构建为关系实体图，以实现端到端表示学习，无需传统特征工程。&lt;h4&gt;目的&lt;/h4&gt;提供RDL的全面综述，并探讨统一不同建模挑战的机会，强调RDL如何将图机器学习的多个子领域汇聚起来，设计能够改变关系数据处理的基础模型。&lt;h4&gt;方法&lt;/h4&gt;介绍关系数据库作为关系实体图的表示方法，并回顾用于开发和发展基于GNN的RDL模型的公开基准数据集。同时，讨论了大规模多表集成和建模时间动态及异构数据的复杂性，并调查了专门针对关系实体图的基础神经网络方法和近期架构进展。&lt;h4&gt;主要发现&lt;/h4&gt;关系实体图具有定义结构的关键属性，包括由实体之间的主-外键关系定义的结构，由数据库定义的关系模式决定的连接性，以及时间性和异质性的连接。&lt;h4&gt;结论&lt;/h4&gt;RDL能够将图机器学习的多个子领域汇聚起来，为设计能够改变关系数据处理的基础模型提供了机会。&lt;h4&gt;翻译&lt;/h4&gt;Graph machine learning has led to a significant increase in the capabilities of models that learn on arbitrary graph-structured data and has been applied to molecules, social networks, recommendation systems, and transportation, among other domains. Data in multi-tabular relational databases can also be constructed as 'relational entity graphs' for Relational Deep Learning (RDL) - a new blueprint that enables end-to-end representation learning without traditional feature engineering. Compared to arbitrary graph-structured data, relational entity graphs have key properties: (i) their structure is defined by primary-foreign key relationships between entities in different tables, (ii) the structural connectivity is a function of the relational schema defining a database, and (iii) the graph connectivity is temporal and heterogeneous in nature. In this paper, we provide a comprehensive review of RDL by first introducing the representation of relational databases as relational entity graphs, and then reviewing public benchmark datasets that have been used to develop and evaluate recent GNN-based RDL models. We discuss key challenges including large-scale multi-table integration and the complexities of modeling temporal dynamics and heterogeneous data, while also surveying foundational neural network methods and recent architectural advances specialized for relational entity graphs. Finally, we explore opportunities to unify these distinct modeling challenges, highlighting how RDL converges multiple sub-fields in graph machine learning towards the design of foundation models that can transform the processing of relational data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph machine learning has led to a significant increase in the capabilitiesof models that learn on arbitrary graph-structured data and has been applied tomolecules, social networks, recommendation systems, and transportation, amongother domains. Data in multi-tabular relational databases can also beconstructed as 'relational entity graphs' for Relational Deep Learning (RDL) -a new blueprint that enables end-to-end representation learning withouttraditional feature engineering. Compared to arbitrary graph-structured data,relational entity graphs have key properties: (i) their structure is defined byprimary-foreign key relationships between entities in different tables, (ii)the structural connectivity is a function of the relational schema defining adatabase, and (iii) the graph connectivity is temporal and heterogeneous innature. In this paper, we provide a comprehensive review of RDL by firstintroducing the representation of relational databases as relational entitygraphs, and then reviewing public benchmark datasets that have been used todevelop and evaluate recent GNN-based RDL models. We discuss key challengesincluding large-scale multi-table integration and the complexities of modelingtemporal dynamics and heterogeneous data, while also surveying foundationalneural network methods and recent architectural advances specialized forrelational entity graphs. Finally, we explore opportunities to unify thesedistinct modeling challenges, highlighting how RDL converges multiplesub-fields in graph machine learning towards the design of foundation modelsthat can transform the processing of relational data.</description>
      <author>example@mail.com (Vijay Prakash Dwivedi, Charilaos Kanatsoulis, Shenyang Huang, Jure Leskovec)</author>
      <guid isPermaLink="false">2506.16654v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>H-QuEST: Accelerating Query-by-Example Spoken Term Detection with Hierarchical Indexing</title>
      <link>http://arxiv.org/abs/2506.16751v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;H-QuEST是一种新型的Query-by-example语音词检测框架，通过利用高级音频表示学习技术和HNSW索引来加速语音词检索，同时在不牺牲准确性的情况下显著提高检索速度。&lt;h4&gt;背景&lt;/h4&gt;在语音词检测中，当标注数据有限或不可用时，通常使用模板匹配方法如动态时间规整（DTW），但这些方法计算量大且扩展性差。&lt;h4&gt;目的&lt;/h4&gt;提出H-QuEST框架，旨在加速语音词检索，并提高检索速度而不降低准确性。&lt;h4&gt;方法&lt;/h4&gt;H-QuEST利用基于TF-IDF的稀疏表示和高级音频表示学习技术，以及HNSW索引和进一步的优化来加速检索。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，与现有方法相比，H-QuEST在检索速度上有了显著提高，同时保持了检索的准确性。&lt;h4&gt;结论&lt;/h4&gt;H-QuEST是一种有效的语音词检测框架，能够显著提高检索速度，同时保持较高的准确性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Query-by-example spoken term detection (QbE-STD) searches for matching wordsor phrases in an audio dataset using a sample spoken query. When annotated datais limited or unavailable, QbE-STD is often done using template matchingmethods like dynamic time warping (DTW), which are computationally expensiveand do not scale well. To address this, we propose H-QuEST (HierarchicalQuery-by-Example Spoken Term Detection), a novel framework that acceleratesspoken term retrieval by utilizing Term Frequency and Inverse DocumentFrequency (TF-IDF)-based sparse representations obtained through advanced audiorepresentation learning techniques and Hierarchical Navigable Small World(HNSW) indexing with further refinement. Experimental results show that H-QuESTdelivers substantial improvements in retrieval speed without sacrificingaccuracy compared to existing methods.</description>
      <author>example@mail.com (Akanksha Singh, Yi-Ping Phoebe Chen, Vipul Arora)</author>
      <guid isPermaLink="false">2506.16751v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Context Matters! Relaxing Goals with LLMs for Feasible 3D Scene Planning</title>
      <link>http://arxiv.org/abs/2506.15828v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种将经典规划与大型语言模型（LLMs）相结合的方法，旨在解决经典规划在现实场景中由于机器人感知有限和感知与规划谓词之间需要匹配导致的难题。&lt;h4&gt;背景&lt;/h4&gt;经典规划在人工智能和机器人领域通过从命令式方法转向声明式方法（如PDDL）来处理复杂任务，但在实际场景中由于机器人感知有限和需要将感知与规划谓词匹配，这些方法常常失败。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些限制，本文提出了一种结合经典规划与LLMs的方法，利用LLMs提取常识知识并实现动作的匹配。&lt;h4&gt;方法&lt;/h4&gt;本文提出了一个分层公式，通过定义功能等效的目标并通过逐步放宽来实现难以实现的任务的可行性。这种方法支持部分实现目标，适合代理的具体上下文。&lt;h4&gt;主要发现&lt;/h4&gt;该方法通过综合定性和定量评估，证明了其能够有效地在用3D场景图模型化的环境中适应和执行任务。同时，该方法在复杂场景中成功，而其他基准方法更有可能失败。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法通过结合经典规划与LLMs，为解决机器人规划中的挑战提供了一种有效途径，并通过社区发布的代码、数据集和附加材料，进一步推动了该领域的研究。&lt;h4&gt;翻译&lt;/h4&gt;In this paper, an approach integrating classical planning with Large Language Models (LLMs) is presented to address the challenges in robotic planning due to limited robot perception and the need to ground perceptions to planning predicates. The method leverages the ability of LLMs to extract common-sense knowledge and ground actions, and proposes a hierarchical formulation to make infeasible tasks tractable by defining functionally equivalent goals through gradual relaxation. The method demonstrates its ability to adapt and execute tasks effectively within environments modeled using 3D Scene Graphs, and shows success in complex scenarios where other benchmark methods are more likely to fail. Code, dataset, and additional material are released to the community.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Classical planning in AI and Robotics addresses complex tasks by shiftingfrom imperative to declarative approaches (e.g., PDDL). However, these methodsoften fail in real scenarios due to limited robot perception and the need toground perceptions to planning predicates. This often results in heavilyhard-coded behaviors that struggle to adapt, even with scenarios where goalscan be achieved through relaxed planning. Meanwhile, Large Language Models(LLMs) lead to planning systems that leverage commonsense reasoning but oftenat the cost of generating unfeasible and/or unsafe plans. To address theselimitations, we present an approach integrating classical planning with LLMs,leveraging their ability to extract commonsense knowledge and ground actions.We propose a hierarchical formulation that enables robots to make unfeasibletasks tractable by defining functionally equivalent goals through gradualrelaxation. This mechanism supports partial achievement of the intendedobjective, suited to the agent's specific context. Our method demonstrates itsability to adapt and execute tasks effectively within environments modeledusing 3D Scene Graphs through comprehensive qualitative and quantitativeevaluations. We also show how this method succeeds in complex scenarios whereother benchmark methods are more likely to fail. Code, dataset, and additionalmaterial are released to the community.</description>
      <author>example@mail.com (Emanuele Musumeci, Michele Brienza, Francesco Argenziano, Vincenzo Suriani, Daniele Nardi, Domenico D. Bloisi)</author>
      <guid isPermaLink="false">2506.15828v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Energy-Based Transfer for Reinforcement Learning</title>
      <link>http://arxiv.org/abs/2506.16590v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一个基于能量的迁移学习方法，通过异常检测来选择性地提供指导，使教师仅在训练分布内的状态中进行干预，从而提高强化学习算法在多任务和持续学习环境中的样本效率。&lt;h4&gt;背景&lt;/h4&gt;强化学习算法在多任务或持续学习环境中往往效率低下，难以应用。&lt;h4&gt;目的&lt;/h4&gt;提高强化学习算法在多任务和持续学习环境中的样本效率。&lt;h4&gt;方法&lt;/h4&gt;提出了一种基于能量的迁移学习方法，使用异常检测来选择性地提供指导，使教师仅在训练分布内的状态中进行干预。&lt;h4&gt;主要发现&lt;/h4&gt;理论上证明了能量分数反映了教师的状态访问密度，并实证证明了在单任务和多任务环境中都提高了样本效率。&lt;h4&gt;结论&lt;/h4&gt;该方法能有效地提高强化学习算法在多任务和持续学习环境中的样本效率。&lt;h4&gt;翻译&lt;/h4&gt;摘要：强化学习算法往往因样本效率低下而难以应用于多任务或持续学习环境。通过将先前训练的教师策略的知识迁移到新但相关的任务中，可以提高效率。然而，如果新任务与教师训练任务差异很大，迁移的指导可能次优，并偏向低奖励行为。我们提出了一种基于能量的迁移学习方法，它使用异常检测来选择性地提供指导，使教师仅在训练分布内的状态中进行干预。我们理论上证明了能量分数反映了教师的状态访问密度，并通过实证证明了在单任务和多任务环境中都提高了样本效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Reinforcement learning algorithms often suffer from poor sample efficiency,making them challenging to apply in multi-task or continual learning settings.Efficiency can be improved by transferring knowledge from a previously trainedteacher policy to guide exploration in new but related tasks. However, if thenew task sufficiently differs from the teacher's training task, the transferredguidance may be sub-optimal and bias exploration toward low-reward behaviors.We propose an energy-based transfer learning method that usesout-of-distribution detection to selectively issue guidance, enabling theteacher to intervene only in states within its training distribution. Wetheoretically show that energy scores reflect the teacher's state-visitationdensity and empirically demonstrate improved sample efficiency and performanceacross both single-task and multi-task settings.</description>
      <author>example@mail.com (Zeyun Deng, Jasorsi Ghosh, Fiona Xie, Yuzhe Lu, Katia Sycara, Joseph Campbell)</author>
      <guid isPermaLink="false">2506.16590v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modality Learning for Predicting IHC Biomarkers from H&amp;E-Stained Whole-Slide Images</title>
      <link>http://arxiv.org/abs/2506.15853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种名为HistoStainAlign的深度学习框架，用于从H&amp;E染色全切片图像直接预测IHC染色模式，以减少IHC染色的成本和时间消耗。&lt;h4&gt;背景&lt;/h4&gt;H&amp;E染色是病理分析的基础，而IHC染色提供分子层面的信息，但IHC染色成本高、耗时且资源密集。&lt;h4&gt;目的&lt;/h4&gt;提出HistoStainAlign框架，通过学习形态和分子特征的联合表示，直接从H&amp;E全切片图像预测IHC染色模式。&lt;h4&gt;方法&lt;/h4&gt;框架通过对比训练策略整合配对的H&amp;E和IHC嵌入，捕捉染色模态间的互补特征，无需切片级别标注或组织配准。&lt;h4&gt;主要发现&lt;/h4&gt;HistoStainAlign在三种常见的IHC染色（P53、PD-L1和Ki-67）上实现了0.735、0.830和0.723的加权F1分数。嵌入分析表明，对比对齐在捕捉跨染色关系方面具有鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;该研究证明了计算方法作为预筛选工具的潜力，有助于优先考虑IHC染色案例，并提高工作流程效率。&lt;h4&gt;翻译&lt;/h4&gt;Hematoxylin and Eosin (H&amp;E)染色是病理分析的基础，为癌症的诊断、亚型和分级提供了可靠的细胞形态和组织结构可视化。免疫组织化学(IHC)染色通过检测组织中的特定蛋白质，提供分子层面的见解，提高了诊断的准确性并改善了治疗方案。然而，IHC染色成本高昂、耗时且资源密集，需要专业的技术知识。为了解决这些限制，本研究提出了一种名为HistoStainAlign的新型深度学习框架，该框架通过学习形态和分子特征的联合表示，直接从H&amp;E全切片图像预测IHC染色模式。该框架通过对比训练策略整合配对的H&amp;E和IHC嵌入，无需切片级别标注或组织配准即可捕捉染色模态间的互补特征。该模型在胃肠道和肺组织全切片图像上，针对三种常用的IHC染色（P53、PD-L1和Ki-67）进行了评估，分别实现了0.735[95%置信区间(CI)：0.670-0.799]、0.830[95% CI：0.772-0.886]和0.723[95% CI：0.607-0.836]的加权F1分数。嵌入分析表明，对比对齐在捕捉跨染色关系方面具有鲁棒性。与基线模型的比较进一步突出了引入对比学习以提高染色模式预测的优势。本研究证明了计算方法作为预筛选工具的潜力，有助于优先考虑IHC染色案例，并提高工作流程效率。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Hematoxylin and Eosin (H&amp;E) staining is a cornerstone of pathologicalanalysis, offering reliable visualization of cellular morphology and tissuearchitecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry(IHC) staining provides molecular insights by detecting specific proteinswithin tissues, enhancing diagnostic accuracy, and improving treatmentplanning. However, IHC staining is costly, time-consuming, andresource-intensive, requiring specialized expertise. To address theselimitations, this study proposes HistoStainAlign, a novel deep learningframework that predicts IHC staining patterns directly from H&amp;E whole-slideimages (WSIs) by learning joint representations of morphological and molecularfeatures. The framework integrates paired H&amp;E and IHC embeddings through acontrastive training strategy, capturing complementary features across stainingmodalities without patch-level annotations or tissue registration. The modelwas evaluated on gastrointestinal and lung tissue WSIs with three commonly usedIHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scoresof 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI:0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHCstains. Embedding analyses demonstrated the robustness of the contrastivealignment in capturing meaningful cross-stain relationships. Comparisons with abaseline model further highlight the advantage of incorporating contrastivelearning for improved stain pattern prediction. This study demonstrates thepotential of computational approaches to serve as a pre-screening tool, helpingprioritize cases for IHC staining and improving workflow efficiency.</description>
      <author>example@mail.com (Amit Das, Naofumi Tomita, Kyle J. Syme, Weijie Ma, Paige O'Connor, Kristin N. Corbett, Bing Ren, Xiaoying Liu, Saeed Hassanpour)</author>
      <guid isPermaLink="false">2506.15853v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Universal Music Representations? Evaluating Foundation Models on World Music Corpora</title>
      <link>http://arxiv.org/abs/2506.17055v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at ISMIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文对五种先进的音频基础模型进行了全面评估，这些模型在六个涵盖西方流行音乐、希腊、土耳其和印度古典音乐传统的音乐语料库中进行了测试。研究采用了三种互补的方法来探究这些模型的跨文化能力，并发现大模型在非西方音乐上表现较好，但在文化上距离较远的传统中表现下降。&lt;h4&gt;背景&lt;/h4&gt;基础模型已经彻底改变了音乐信息检索，但关于它们在不同音乐传统中泛化能力的疑问仍然存在。&lt;h4&gt;目的&lt;/h4&gt;评估五种先进的音频基础模型在六个不同音乐语料库中的跨文化能力。&lt;h4&gt;方法&lt;/h4&gt;研究采用了三种互补的方法：探查以评估内在表示、针对1-2层的监督微调和多标签少样本学习以应对资源有限的情况。&lt;h4&gt;主要发现&lt;/h4&gt;分析显示不同模型在跨文化泛化方面存在差异，大模型通常在非西方音乐上表现更佳，但在文化上距离较远的传统中表现下降。研究方法在五个数据集中实现了最先进的性能，表明基础模型在世界音乐理解方面的有效性。此外，研究还发现，针对的微调方法并不总是优于探查，这表明基础模型已经编码了大量的音乐知识。&lt;h4&gt;结论&lt;/h4&gt;该研究评估框架和基准结果有助于了解当前模型距离实现通用音乐表示有多远，并确立了未来进步的衡量标准。&lt;h4&gt;翻译&lt;/h4&gt;本文对五种先进的音频基础模型进行了全面评估，这些模型在六个涵盖西方流行音乐、希腊、土耳其和印度古典音乐传统的音乐语料库中进行了测试。研究采用了三种互补的方法来探究这些模型的跨文化能力，并发现大模型在非西方音乐上表现较好，但在文化上距离较远的传统中表现下降。分析显示不同模型在跨文化泛化方面存在差异，大模型通常在非西方音乐上表现更佳，但在文化上距离较远的传统中表现下降。研究方法在五个数据集中实现了最先进的性能，表明基础模型在世界音乐理解方面的有效性。此外，研究还发现，针对的微调方法并不总是优于探查，这表明基础模型已经编码了大量的音乐知识。该研究评估框架和基准结果有助于了解当前模型距离实现通用音乐表示有多远，并确立了未来进步的衡量标准。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models have revolutionized music information retrieval, butquestions remain about their ability to generalize across diverse musicaltraditions. This paper presents a comprehensive evaluation of fivestate-of-the-art audio foundation models across six musical corpora spanningWestern popular, Greek, Turkish, and Indian classical traditions. We employthree complementary methodologies to investigate these models' cross-culturalcapabilities: probing to assess inherent representations, targeted supervisedfine-tuning of 1-2 layers, and multi-label few-shot learning for low-resourcescenarios. Our analysis shows varying cross-cultural generalization, withlarger models typically outperforming on non-Western music, though resultsdecline for culturally distant traditions. Notably, our approaches achievestate-of-the-art performance on five out of six evaluated datasets,demonstrating the effectiveness of foundation models for world musicunderstanding. We also find that our targeted fine-tuning approach does notconsistently outperform probing across all settings, suggesting foundationmodels already encode substantial musical knowledge. Our evaluation frameworkand benchmarking results contribute to understanding how far current models arefrom achieving universal music representations while establishing metrics forfuture progress.</description>
      <author>example@mail.com (Charilaos Papaioannou, Emmanouil Benetos, Alexandros Potamianos)</author>
      <guid isPermaLink="false">2506.17055v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds</title>
      <link>http://arxiv.org/abs/2506.16991v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了ForestFormer3D，一个用于森林LiDAR 3D点云分割的新框架，包括个体树木和语义分割。&lt;h4&gt;背景&lt;/h4&gt;森林LiDAR 3D点云的分割对于森林管理和生态研究至关重要，但现有的方法难以处理自然森林环境的复杂性和变化。&lt;h4&gt;目的&lt;/h4&gt;提出ForestFormer3D框架，以提高个体树木和语义分割的精确度。&lt;h4&gt;方法&lt;/h4&gt;ForestFormer3D集成了ISA引导的查询点选择、基于分数的块合并策略以及在训练中使用的一对多关联机制。&lt;h4&gt;主要发现&lt;/h4&gt;ForestFormer3D在新的FOR-instanceV2数据集上实现了个体树木分割的最新性能，该数据集涵盖了多种森林类型和地区。此外，该模型在不同森林条件和传感器模态下表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;FOR-instanceV2数据集和ForestFormer3D代码即将发布，展示了模型在不同环境下的鲁棒性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The segmentation of forest LiDAR 3D point clouds, including both individualtree and semantic segmentation, is fundamental for advancing forest managementand ecological research. However, current approaches often struggle with thecomplexity and variability of natural forest environments. We presentForestFormer3D, a new unified and end-to-end framework designed for preciseindividual tree and semantic segmentation. ForestFormer3D incorporatesISA-guided query point selection, a score-based block merging strategy duringinference, and a one-to-many association mechanism for effective training. Bycombining these new components, our model achieves state-of-the-art performancefor individual tree segmentation on the newly introduced FOR-instanceV2dataset, which spans diverse forest types and regions. Additionally,ForestFormer3D generalizes well to unseen test sets (Wytham woods and LAUTx),showcasing its robustness across different forest conditions and sensormodalities. The FOR-instanceV2 dataset and the ForestFormer3D code will bereleased soon.</description>
      <author>example@mail.com (Binbin Xiang, Maciej Wielgosz, Stefano Puliti, Kamil Král, Martin Krůček, Azim Missarov, Rasmus Astrup)</author>
      <guid isPermaLink="false">2506.16991v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>SlepNet: Spectral Subgraph Representation Learning for Neural Dynamics</title>
      <link>http://arxiv.org/abs/2506.16602v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了SlepNet，一种新的GCN架构，用于处理图上的信号模式，特别适用于神经科学领域中的信号解码。&lt;h4&gt;背景&lt;/h4&gt;图神经网络在处理图结构数据方面很有用，但它们在表示图上信号模式方面使用有限。图信号处理和相关的GCN模型无法有效地表示图上或子图上的空间或频谱局部化信号模式。&lt;h4&gt;目的&lt;/h4&gt;提出SlepNet以解决上述问题，通过使用Slepian基而不是图傅里叶谐波来优化信号能量的集中。&lt;h4&gt;方法&lt;/h4&gt;SlepNet使用Slepian谐波自动学习相关的子图，并将信号能量集中在这些子图上，从而产生标准的和高度解析的神经活动表示。&lt;h4&gt;主要发现&lt;/h4&gt;在三个fMRI数据集上评估了SlepNet，包括认知和视觉任务以及交通动态数据集，结果显示SlepNet在所有数据集上都优于基线模型。此外，SlepNet提取的信号模式表示提供了更高的分辨率，能够区分相似的信号模式，并将脑信号瞬态表示为信息轨迹。&lt;h4&gt;结论&lt;/h4&gt;SlepNet在时空数据的预测和表示学习方面都是有用的。&lt;h4&gt;翻译&lt;/h4&gt;Graph neural networks have been useful in machine learning on graph-structured data, particularly for node classification and some types of graph classification tasks. However, they have had limited use in representing patterning of signals over graphs. Patterning of signals over graphs and in subgraphs carries important information in many domains including neuroscience. Neural signals are spatiotemporally patterned, high dimensional and difficult to decode. Graph signal processing and associated GCN models utilize the graph Fourier transform and are unable to efficiently represent spatially or spectrally localized signal patterning on graphs. Wavelet transforms have shown promise here, but offer non-canonical representations and cannot be tightly confined to subgraphs. Here we propose SlepNet, a novel GCN architecture that uses Slepian bases rather than graph Fourier harmonics. In SlepNet, the Slepian harmonics optimally concentrate signal energy on specifically relevant subgraphs that are automatically learned with a mask. Thus, they can produce canonical and highly resolved representations of neural activity, focusing energy of harmonics on areas of the brain which are activated. We evaluated SlepNet across three fMRI datasets, spanning cognitive and visual tasks, and two traffic dynamics datasets, comparing its performance against conventional GNNs and graph signal processing constructs. SlepNet outperforms the baselines in all datasets. Moreover, the extracted representations of signal patterns from SlepNet offer more resolution in distinguishing between similar patterns, and thus represent brain signaling transients as informative trajectories. Here we have shown that these extracted trajectory representations can be used for other downstream untrained tasks. Thus we establish that SlepNet is useful both for prediction and representation learning in spatiotemporal data.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Graph neural networks have been useful in machine learning ongraph-structured data, particularly for node classification and some types ofgraph classification tasks. However, they have had limited use in representingpatterning of signals over graphs. Patterning of signals over graphs and insubgraphs carries important information in many domains including neuroscience.Neural signals are spatiotemporally patterned, high dimensional and difficultto decode. Graph signal processing and associated GCN models utilize the graphFourier transform and are unable to efficiently represent spatially orspectrally localized signal patterning on graphs. Wavelet transforms have shownpromise here, but offer non-canonical representations and cannot be tightlyconfined to subgraphs. Here we propose SlepNet, a novel GCN architecture thatuses Slepian bases rather than graph Fourier harmonics. In SlepNet, the Slepianharmonics optimally concentrate signal energy on specifically relevantsubgraphs that are automatically learned with a mask. Thus, they can producecanonical and highly resolved representations of neural activity, focusingenergy of harmonics on areas of the brain which are activated. We evaluatedSlepNet across three fMRI datasets, spanning cognitive and visual tasks, andtwo traffic dynamics datasets, comparing its performance against conventionalGNNs and graph signal processing constructs. SlepNet outperforms the baselinesin all datasets. Moreover, the extracted representations of signal patternsfrom SlepNet offers more resolution in distinguishing between similar patterns,and thus represent brain signaling transients as informative trajectories. Herewe have shown that these extracted trajectory representations can be used forother downstream untrained tasks. Thus we establish that SlepNet is useful bothfor prediction and representation learning in spatiotemporal data.</description>
      <author>example@mail.com (Siddharth Viswanath, Rahul Singh, Yanlei Zhang, J. Adam Noah, Joy Hirsch, Smita Krishnaswamy)</author>
      <guid isPermaLink="false">2506.16602v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Graphics4Science: Computer Graphics for Scientific Impacts</title>
      <link>http://arxiv.org/abs/2506.15786v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了计算机图形学与科学之间的深刻且不断发展的关系，强调了过去成就、持续贡献和未解决的开放性问题。&lt;h4&gt;背景&lt;/h4&gt;计算机图形学最初用于医学成像的3D可视化，现在在计算建模和模拟中发挥着作用，成为解决科学挑战的有力工具。&lt;h4&gt;目的&lt;/h4&gt;通过展示几何推理和物理建模等核心方法如何为两个领域提供归纳偏差，以帮助解决数据稀缺环境下的挑战，旨在将图形学重新定位为科学建模语言。&lt;h4&gt;方法&lt;/h4&gt;通过架起两个社区之间的词汇差距，该课程（Graphics4Science）旨在邀请图形学社区与科学界互动，解决图形学专长能够产生影响的重大问题。&lt;h4&gt;主要发现&lt;/h4&gt;核心方法如几何推理和物理建模为解决数据稀缺环境下的挑战提供了帮助。&lt;h4&gt;结论&lt;/h4&gt;Graphics4Science课程鼓励图形学社区参与科学界，对科学发现的未来做出贡献。&lt;h4&gt;翻译&lt;/h4&gt;摘要：计算机图形学，常与电影、游戏和视觉效果相关联，长期以来一直是解决科学挑战的有力工具——从其起源于医学成像的3D可视化，到其在现代计算建模和模拟中的作用。本课程探讨了计算机图形学与科学之间深刻且不断发展的关系，强调了过去的成就、持续的贡献和尚未解决的开放性问题。我们展示了核心方法，如几何推理和物理建模，如何为两个领域提供归纳偏差，帮助解决数据稀缺环境下的挑战。为此，我们旨在通过弥合两个社区之间的词汇差距，将图形学重新定位为科学的建模语言。本课程面向新人和专家，邀请图形学社区参与科学界，解决图形学专长能够产生影响的重大问题，并贡献于科学发现的未来。更多详情请访问课程网站：https://graphics4science.github.io&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Computer graphics, often associated with films, games, and visual effects,has long been a powerful tool for addressing scientific challenges--from itsorigins in 3D visualization for medical imaging to its role in moderncomputational modeling and simulation. This course explores the deep andevolving relationship between computer graphics and science, highlighting pastachievements, ongoing contributions, and open questions that remain. We showhow core methods, such as geometric reasoning and physical modeling, provideinductive biases that help address challenges in both fields, especially indata-scarce settings. To that end, we aim to reframe graphics as a modelinglanguage for science by bridging vocabulary gaps between the two communities.Designed for both newcomers and experts, Graphics4Science invites the graphicscommunity to engage with science, tackle high-impact problems where graphicsexpertise can make a difference, and contribute to the future of scientificdiscovery. Additional details are available on the course website:https://graphics4science.github.io</description>
      <author>example@mail.com (Peter Yichen Chen, Minghao Guo, Hanspeter Pfister, Ming Lin, William Freeman, Qixing Huang, Han-Wei Shen, Wojciech Matusik)</author>
      <guid isPermaLink="false">2506.15786v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You</title>
      <link>http://arxiv.org/abs/2506.16895v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了在有限对齐数据下构建多模态模型的可能性，通过预训练的单模态基础模型进行对齐，显著提升了零样本分类和跨模态检索的性能。&lt;h4&gt;背景&lt;/h4&gt;现有的多模态模型通常依赖于数百万的对齐样本，这在许多领域成本高昂或难以获取。&lt;h4&gt;目的&lt;/h4&gt;研究在有限对齐数据下构建多模态模型的可行性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种名为STRUCTURE的优化技术，以保持单模态编码器潜在空间的邻域几何。同时，发现对齐最后一层通常效果不佳，并证明了跨模态之间具有最高表征相似性的层进行对齐的优势。&lt;h4&gt;主要发现&lt;/h4&gt;通过数千个对齐样本（少于领域内典型数据的1%）即可实现高质量的对齐，显著提升了24个零样本图像分类和检索基准的性能，分类任务的平均相对提升为51.6%，检索任务为91.8%。&lt;h4&gt;结论&lt;/h4&gt;该框架对于有限样本的多模态学习具有有效性和广泛适用性，为资源受限领域提供了一条有前景的发展路径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：多模态模型在需要多模态对齐的复杂任务中，如零样本分类和跨模态检索，已经展现出强大的能力。然而，现有的模型通常依赖于数百万的对齐多模态样本，这在许多领域成本高昂或难以获取。在本研究中，我们探讨了通过对齐预训练的单模态基础模型，在有限对齐数据下构建多模态模型的可行性。我们表明，即使只有数千个对齐样本，也可以实现高质量的对齐——这比该领域通常使用的1%的数据还要少。为了实现这一点，我们引入了一种有效的正则化技术——STRUCTURE，它能够保持单模态编码器潜在空间的邻域几何。此外，我们还发现对齐最后一层通常是不够优的，并证明了与跨模态之间具有最高表征相似性的层进行对齐的优势。这两个组件可以很容易地集成到现有的对齐方法中，在24个零样本图像分类和检索基准上带来了显著的提升，分类任务的平均相对提升为51.6%，检索任务为91.8%。我们的结果突出了我们的框架在有限样本多模态学习中的有效性和广泛适用性，为资源受限领域提供了一条有前景的发展路径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal models have demonstrated powerful capabilities in complex tasksrequiring multimodal alignment including zero-shot classification andcross-modal retrieval. However, existing models typically rely on millions ofpaired multimodal samples, which are prohibitively expensive or infeasible toobtain in many domains. In this work, we explore the feasibility of buildingmultimodal models with limited amount of paired data by aligning pretrainedunimodal foundation models. We show that high-quality alignment is possiblewith as few as tens of thousands of paired samples$\unicode{x2013}$less than$1\%$ of the data typically used in the field. To achieve this, we introduceSTRUCTURE, an effective regularization technique that preserves theneighborhood geometry of the latent space of unimodal encoders. Additionally,we show that aligning last layers is often suboptimal and demonstrate thebenefits of aligning the layers with the highest representational similarityacross modalities. These two components can be readily incorporated intoexisting alignment methods, yielding substantial gains across 24 zero-shotimage classification and retrieval benchmarks, with average relativeimprovement of $51.6\%$ in classification and $91.8\%$ in retrieval tasks. Ourresults highlight the effectiveness and broad applicability of our frameworkfor limited-sample multimodal learning and offer a promising path forward forresource-constrained domains.</description>
      <author>example@mail.com (Fabian Gröger, Shuo Wen, Huyen Le, Maria Brbić)</author>
      <guid isPermaLink="false">2506.16895v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction</title>
      <link>http://arxiv.org/abs/2506.16144v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了使用异构图数据结构和图神经网络预测数值黑盒优化中自动算法性能的方法，通过捕捉问题、算法配置和性能结果之间的复杂依赖关系。&lt;h4&gt;背景&lt;/h4&gt;在数值黑盒优化中，自动算法性能预测通常依赖于问题特征，如探索性景观分析特征，但这些方法往往忽略了算法配置这一关键因素。&lt;h4&gt;目的&lt;/h4&gt;研究旨在通过使用图神经网络和异构图数据结构来预测优化算法的性能。&lt;h4&gt;方法&lt;/h4&gt;本文聚焦于两个模块化框架modCMA-ES和modDE，它们分别分解了两种广泛使用的无导数优化算法CMA-ES和DE。在24个BBOB问题上，对324个modCMA-ES和576个modDE变体进行了评估。&lt;h4&gt;主要发现&lt;/h4&gt;与传统的基于表格的方法相比，该方法在MSE上实现了高达36.6%的改进，突出了几何学习在黑盒优化中的潜力。&lt;h4&gt;结论&lt;/h4&gt;本文强调了使用图神经网络和异构图数据结构在黑盒优化中预测算法性能的潜力，并证明了这种方法的有效性。&lt;h4&gt;翻译&lt;/h4&gt;This work explores the use of heterogeneous graph data structures and graph neural networks to predict the performance of optimization algorithms by capturing the complex dependencies between problems, algorithm configurations, and performance outcomes. We focus on two modular frameworks, modCMA-ES and modDE, which decompose two widely used derivative-free optimization algorithms: the covariance matrix adaptation evolution strategy (CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576 modDE variants on 24 BBOB problems across six runtime budgets and two problem dimensions. Achieving up to 36.6% improvement in MSE over traditional tabular-based methods, this work highlights the potential of geometric learning in black-box optimization.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automated algorithm performance prediction in numerical blackbox optimizationoften relies on problem characterizations, such as exploratory landscapeanalysis features. These features are typically used as inputs to machinelearning models and are represented in a tabular format. However, suchapproaches often overlook algorithm configurations, a key factor influencingperformance. The relationships between algorithm operators, parameters, problemcharacteristics, and performance outcomes form a complex structure bestrepresented as a graph. This work explores the use of heterogeneous graph datastructures and graph neural networks to predict the performance of optimizationalgorithms by capturing the complex dependencies between problems, algorithmconfigurations, and performance outcomes. We focus on two modular frameworks,modCMA-ES and modDE, which decompose two widely used derivative-freeoptimization algorithms: the covariance matrix adaptation evolution strategy(CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576modDE variants on 24 BBOB problems across six runtime budgets and two problemdimensions. Achieving up to 36.6% improvement in MSE over traditionaltabular-based methods, this work highlights the potential of geometric learningin black-box optimization.</description>
      <author>example@mail.com (Ana Kostovska, Carola Doerr, Sašo Džeroski, Panče Panov, Tome Eftimov)</author>
      <guid isPermaLink="false">2506.16144v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>TabArena: A Living Benchmark for Machine Learning on Tabular Data</title>
      <link>http://arxiv.org/abs/2506.16791v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  51 pages. Code available at https://tabarena.ai/code; examples at  https://tabarena.ai/code-examples; dataset curation at  https://tabarena.ai/data-tabular-ml-iid-study and  https://tabarena.ai/dataset-curation&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了TabArena，一个连续维护的活表格基准测试系统，用于解决现有基准测试静态性的问题。&lt;h4&gt;背景&lt;/h4&gt;随着深度学习和表格数据基础模型越来越受欢迎，对标准化和可靠的基准测试的需求日益增加。&lt;h4&gt;目的&lt;/h4&gt;设计TabArena以解决现有基准测试静态性问题，并提高模型基准测试的可靠性。&lt;h4&gt;方法&lt;/h4&gt;手动编制数据集和模型集合，进行大规模基准测试研究，建立公共排行榜，并组建维护团队。&lt;h4&gt;主要发现&lt;/h4&gt;验证方法和超参数配置的集成对基准测试模型性能有显著影响；集成方法使深度学习在较大时间预算下追上梯度提升树；基础模型在小数据集上表现卓越；模型集成推进了表格机器学习领域的最新进展。&lt;h4&gt;结论&lt;/h4&gt;TabArena通过提供可重复的代码和维护协议，创建了一个活基准测试，可在https://tabarena.ai访问。&lt;h4&gt;翻译&lt;/h4&gt;With the growing popularity of deep learning and foundation models for tabular data, the need for standardized and reliable benchmarks is higher than ever. However, current benchmarks are static. Their design is not updated even if flaws are discovered, model versions are updated, or new models are released. To address this, we introduce TabArena, the first continuously maintained living tabular benchmarking system. To launch TabArena, we manually curate a representative collection of datasets and well-implemented models, conduct a large-scale benchmarking study to initialize a public leaderboard, and assemble a team of experienced maintainers. Our results highlight the influence of validation method and ensembling of hyperparameter configurations to benchmark models at their full potential. While gradient-boosted trees are still strong contenders on practical tabular datasets, we observe that deep learning methods have caught up under larger time budgets with ensembling. At the same time, foundation models excel on smaller datasets. Finally, we show that ensembles across models advance the state-of-the-art in tabular machine learning and investigate the contributions of individual models. We launch TabArena with a public leaderboard, reproducible code, and maintenance protocols to create a living benchmark available at https://tabarena.ai.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; With the growing popularity of deep learning and foundation models fortabular data, the need for standardized and reliable benchmarks is higher thanever. However, current benchmarks are static. Their design is not updated evenif flaws are discovered, model versions are updated, or new models arereleased. To address this, we introduce TabArena, the first continuouslymaintained living tabular benchmarking system. To launch TabArena, we manuallycurate a representative collection of datasets and well-implemented models,conduct a large-scale benchmarking study to initialize a public leaderboard,and assemble a team of experienced maintainers. Our results highlight theinfluence of validation method and ensembling of hyperparameter configurationsto benchmark models at their full potential. While gradient-boosted trees arestill strong contenders on practical tabular datasets, we observe that deeplearning methods have caught up under larger time budgets with ensembling. Atthe same time, foundation models excel on smaller datasets. Finally, we showthat ensembles across models advance the state-of-the-art in tabular machinelearning and investigate the contributions of individual models. We launchTabArena with a public leaderboard, reproducible code, and maintenanceprotocols to create a living benchmark available at https://tabarena.ai.</description>
      <author>example@mail.com (Nick Erickson, Lennart Purucker, Andrej Tschalzev, David Holzmüller, Prateek Mutalik Desai, and David Salinas, Frank Hutter)</author>
      <guid isPermaLink="false">2506.16791v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>SDDiff: Boost Radar Perception via Spatial-Doppler Diffusion</title>
      <link>http://arxiv.org/abs/2506.16936v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为SDDiff的模型，用于同时进行密集点云提取（PCE）和精确的自车速度估计（EVE），以提高3D雷达感知的准确性。&lt;h4&gt;背景&lt;/h4&gt;现有的点云提取和自车速度估计工作通常独立处理，忽略了雷达的空间和多普勒域特征之间的相互作用，可能导致额外的偏差。&lt;h4&gt;目的&lt;/h4&gt;设计一个同时进行密集点云提取和精确的自车速度估计的模型，以充分利用两者之间的相关性。&lt;h4&gt;方法&lt;/h4&gt;SDDiff模型通过以下三个方面改进了传统的潜在扩散过程：引入同时体现空间占有和多普勒特征的表现形式；设计具有雷达先验的方向性扩散以简化采样；提出迭代多普勒细化以增强模型对密度变化和鬼影效应的适应性。&lt;h4&gt;主要发现&lt;/h4&gt;SDDiff在EVE准确性方面比现有最佳基线高出59%，在有效生成密度方面提高了4倍，同时增强了PCE的有效性和可靠性。&lt;h4&gt;结论&lt;/h4&gt;SDDiff模型在3D雷达感知中表现出显著的优越性，对于同时进行点云提取和自车速度估计具有实际应用价值。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云提取（PCE）和自车速度估计（EVE）是3D雷达感知的关键能力，受到关注。然而，现有的工作通常独立处理这两个任务，这可能会忽视雷达空间和多普勒域特征之间的相互作用，可能导致额外的偏差。在本文中，我们观察到3D点和自车速度之间存在潜在的相关性，这为PCE和EVE提供了相互利益。为了充分释放这种鼓舞人心的潜力，我们迈出了第一步，设计了一种空间-多普勒扩散（SDDiff）模型，以同时进行密集的PCE和精确的EVE。为了无缝地将其定制到雷达感知中，SDDiff在三个方面改进了传统的潜在扩散过程。首先，我们引入了一种同时体现空间占有和多普勒特征的表现形式。其次，我们设计了具有雷达先验的方向性扩散以简化采样。第三，我们提出了迭代多普勒细化以增强模型对密度变化和鬼影效应的适应性。广泛的评估表明，SDDiff在EVE准确性方面比现有最佳基线高出59%，在有效生成密度方面提高了4倍，同时提高了PCE的有效性和可靠性。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud extraction (PCE) and ego velocity estimation (EVE) are keycapabilities gaining attention in 3D radar perception. However, existing worktypically treats these two tasks independently, which may neglect the interplaybetween radar's spatial and Doppler domain features, potentially introducingadditional bias. In this paper, we observe an underlying correlation between 3Dpoints and ego velocity, which offers reciprocal benefits for PCE and EVE. Tofully unlock such inspiring potential, we take the first step to design aSpatial-Doppler Diffusion (SDDiff) model for simultaneously dense PCE andaccurate EVE. To seamlessly tailor it to radar perception, SDDiff improves theconventional latent diffusion process in three major aspects. First, weintroduce a representation that embodies both spatial occupancy and Dopplerfeatures. Second, we design a directional diffusion with radar priors tostreamline the sampling. Third, we propose Iterative Doppler Refinement toenhance the model's adaptability to density variations and ghosting effects.Extensive evaluations show that SDDiff significantly outperformsstate-of-the-art baselines by achieving 59% higher in EVE accuracy, 4X greaterin valid generation density while boosting PCE effectiveness and reliability.</description>
      <author>example@mail.com (Shengpeng Wang, Xin Luo, Yulong Xie, Wei Wang)</author>
      <guid isPermaLink="false">2506.16936v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>InfiniPot-V: Memory-Constrained KV Cache Compression for Streaming Video Understanding</title>
      <link>http://arxiv.org/abs/2506.15745v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;InfiniPot-V是一种无需训练、不依赖查询的框架，为流媒体理解中的视频压缩提供了一种新的方法，可以有效地减少内存使用。&lt;h4&gt;背景&lt;/h4&gt;现代多模态大型语言模型（MLLMs）在处理时长为一小时的视频时，其键值（KV）缓存会随着时间线性增长，很快超过手机、增强现实眼镜和边缘机器人的固定内存。&lt;h4&gt;目的&lt;/h4&gt;开发一种无需训练、不依赖查询的框架，为流媒体理解中的视频压缩提供一种解决方案，以减少内存使用。&lt;h4&gt;方法&lt;/h4&gt;InfiniPot-V在视频编码过程中监控缓存，并在达到用户设置的阈值时运行轻量级的压缩过程。该过程包括：（i）通过时间轴冗余（TaR）指标移除时间上冗余的标记；（ii）通过值规范（VaN）排名保留语义上重要的标记。&lt;h4&gt;主要发现&lt;/h4&gt;InfiniPot-V在四个开源MLLMs以及四个长视频和两个流视频基准测试中，将峰值GPU内存减少了高达94%，并保持了实时生成，其准确率与完整缓存相当甚至更高。&lt;h4&gt;结论&lt;/h4&gt;通过解决KV缓存瓶颈而不需要重新训练或查询知识，InfiniPot-V缩小了设备上流媒体助手与云端服务的差距。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代多模态大型语言模型（MLLMs）能够推理一小时的视频，但它们的键值（KV）缓存会随着时间线性增长——很快就会超过手机、增强现实眼镜和边缘机器人的固定内存。之前的压缩方案要么假设整个视频和用户查询都可用离线，要么必须首先构建完整的缓存，因此内存仍然随着流长而扩展。InfiniPot-V是第一个无需训练、查询无关的框架，为流式视频理解强制执行一个硬性、长度无关的内存上限。在视频编码期间，它监控缓存，一旦达到用户设置的阈值，就运行一个轻量级的压缩过程，该过程（i）通过时间轴冗余（TaR）指标移除时间上冗余的标记；（ii）通过值规范（VaN）排名保留语义上重要的标记。在四个开源MLLMs和四个长视频以及两个流视频基准测试中，InfiniPot-V将峰值GPU内存减少了高达94%，并保持了实时生成，其准确率与完整缓存相当甚至更高。通过解决KV缓存瓶颈而不重新训练或查询知识，InfiniPot-V缩小了设备上流媒体助手与云端服务的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern multimodal large language models (MLLMs) can reason over hour-longvideo, yet their key-value (KV) cache grows linearly with time--quicklyexceeding the fixed memory of phones, AR glasses, and edge robots. Priorcompression schemes either assume the whole video and user query are availableoffline or must first build the full cache, so memory still scales with streamlength. InfiniPot-V is the first training-free, query-agnostic framework thatenforces a hard, length-independent memory cap for streaming videounderstanding. During video encoding it monitors the cache and, once a user-setthreshold is reached, runs a lightweight compression pass that (i) removestemporally redundant tokens via Temporal-axis Redundancy (TaR) metric and (ii)keeps semantically significant tokens via Value-Norm (VaN) ranking. Across fouropen-source MLLMs and four long-video and two streaming-video benchmarks,InfiniPot-V cuts peak GPU memory by up to 94%, sustains real-time generation,and matches or surpasses full-cache accuracy--even in multi-turn dialogues. Bydissolving the KV cache bottleneck without retraining or query knowledge,InfiniPot-V closes the gap for on-device streaming video assistants.</description>
      <author>example@mail.com (Minsoo Kim, Kyuhong Shim, Jungwook Choi, Simyung Chang)</author>
      <guid isPermaLink="false">2506.15745v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation</title>
      <link>http://arxiv.org/abs/2506.15757v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文针对视觉语言导航（VLN）领域中的挑战，提出了一种名为弱监督部分对比学习（WPCL）的方法，以提高智能体在动态视点下的物体识别能力。&lt;h4&gt;背景&lt;/h4&gt;VLN是Embodied AI领域的基本任务，旨在让智能体根据自然语言指令在复杂环境中导航。现有方法存在依赖预训练模型、缺乏领域知识以及计算成本高等问题。&lt;h4&gt;目的&lt;/h4&gt;提出WPCL方法，旨在解决VLN场景中动态视点识别的难题，同时提高计算效率。&lt;h4&gt;方法&lt;/h4&gt;WPCL方法通过将预训练的视觉语言模型（VLM）知识有效地整合到感知过程中，增强智能体在VLN场景中识别物体的能力，而无需对VLM进行微调。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，WPCL方法在多个基准测试中优于基线方法，验证了其有效性、鲁棒性和泛化能力。&lt;h4&gt;结论&lt;/h4&gt;WPCL方法有效地解决了VLN中的挑战，为智能体在复杂环境中的导航提供了新的解决方案。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Visual Language Navigation (VLN) is a fundamental task within the field ofEmbodied AI, focusing on the ability of agents to navigate complex environmentsbased on natural language instructions. Despite the progress made by existingmethods, these methods often present some common challenges. First, they relyon pre-trained backbone models for visual perception, which struggle with thedynamic viewpoints in VLN scenarios. Second, the performance is limited whenusing pre-trained LLMs or VLMs without fine-tuning, due to the absence of VLNdomain knowledge. Third, while fine-tuning LLMs and VLMs can improve results,their computational costs are higher than those without fine-tuning. To addressthese limitations, we propose Weakly-supervised Partial Contrastive Learning(WPCL), a method that enhances an agent's ability to identify objects fromdynamic viewpoints in VLN scenarios by effectively integrating pre-trained VLMknowledge into the perception process, without requiring VLM fine-tuning. Ourmethod enhances the agent's ability to interpret and respond to environmentalcues while ensuring computational efficiency. Experimental results have shownthat our method outperforms the baseline methods on multiple benchmarks, whichvalidate the effectiveness, robustness and generalizability of our method.</description>
      <author>example@mail.com (Ruoyu Wang, Tong Yu, Junda Wu, Yao Liu, Julian McAuley, Lina Yao)</author>
      <guid isPermaLink="false">2506.15757v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution</title>
      <link>http://arxiv.org/abs/2506.16421v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了S23DR Challenge 2025比赛的获胜方案，该方案涉及从稀疏点云和语义分割中预测房屋的3D屋顶线框。&lt;h4&gt;背景&lt;/h4&gt;该研究针对的是从稀疏点云和语义分割中预测3D屋顶线框的问题。&lt;h4&gt;目的&lt;/h4&gt;目标是开发一种能够准确预测房屋3D屋顶线框的方法。&lt;h4&gt;方法&lt;/h4&gt;该方法首先在3D空间中工作，通过Gestalt分割从COLMAP点云中识别顶点候选，然后使用两个PointNet-like模型：一个用于通过分析局部立方块来细化和对候选进行分类，另一个用于通过处理连接顶点对的圆柱区域来预测边缘。&lt;h4&gt;主要发现&lt;/h4&gt;这种两阶段的3D深度学习方法在私人排行榜上实现了0.43的混合结构得分（HSS），获得了比赛的胜利。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法在预测3D屋顶线框方面表现出色，为该领域的研究提供了新的思路和方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了S23DR挑战赛2025的获胜方案，该方案涉及从稀疏点云和语义分割中预测房屋的3D屋顶线框。我们的方法直接在3D空间中操作，首先使用Gestalt分割从COLMAP点云中识别顶点候选。然后我们使用两个PointNet-like模型：一个用于通过分析局部立方块来细化和对这些候选进行分类，另一个用于通过处理连接顶点对的圆柱区域来预测边缘。这种两阶段的3D深度学习方法在私人排行榜上实现了0.43的混合结构得分（HSS），获得了比赛的胜利。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This paper presents the winning solution for the S23DR Challenge 2025, whichinvolves predicting a house's 3D roof wireframe from a sparse point cloud andsemantic segmentations. Our method operates directly in 3D, first identifyingvertex candidates from the COLMAP point cloud using Gestalt segmentations. Wethen employ two PointNet-like models: one to refine and classify thesecandidates by analyzing local cubic patches, and a second to predict edges byprocessing the cylindrical regions connecting vertex pairs. This two-stage, 3Ddeep learning approach achieved a winning Hybrid Structure Score (HSS) of 0.43on the private leaderboard.</description>
      <author>example@mail.com (Jan Skvrna, Lukas Neumann)</author>
      <guid isPermaLink="false">2506.16421v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps</title>
      <link>http://arxiv.org/abs/2506.16787v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  18 pages; Accepted to ACL 2025 Findings&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;SeLoRA是一种基于谱编码的低秩自适应技术，用于微调大型基础模型，通过减少参数冗余提高了效率和性能。&lt;h4&gt;背景&lt;/h4&gt;LoRA在微调大型基础模型方面表现出色，但其参数冗余限制了其容量和效率。&lt;h4&gt;目的&lt;/h4&gt;研究LoRA微调中冗余的影响，并提出一种新的方法来提高其效率和性能。&lt;h4&gt;方法&lt;/h4&gt;提出SeLoRA，利用谱基的鲁棒表达能力，从稀疏谱子空间重新参数化LoRA。&lt;h4&gt;主要发现&lt;/h4&gt;减少密度冗余不会降低表达能力。&lt;h4&gt;结论&lt;/h4&gt;SeLoRA在多种下游任务上，如常识推理、数学推理和代码生成，实现了更高的效率，并优于强基线。&lt;h4&gt;翻译&lt;/h4&gt;Low-Rank Adaptation (LoRA) 已成为微调大型基础模型的重要技术。尽管取得了成功，但大量参数冗余限制了LoRA的容量和效率，这已被视为瓶颈。在本工作中，我们系统地研究了LoRA微调中冗余的影响，并揭示了减少密度冗余不会降低表达能力。基于这一见解，我们引入了Spectral-encoding Low-Rank Adaptation (SeLoRA)，它利用谱基的鲁棒表达能力，从稀疏谱子空间重新参数化LoRA。SeLoRA设计简单，可以无缝集成到各种LoRA变体中，以提高性能，作为一种可扩展的即插即用框架。大量实验证实，SeLoRA以更少的参数实现了更高的效率，在各种下游任务上，包括常识推理、数学推理和代码生成，提供了比强基线更好的性能提升。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-20&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Low-Rank Adaptation (LoRA) has emerged as a prominent technique forfine-tuning large foundation models. Despite its successes, the substantialparameter redundancy, which limits the capacity and efficiency of LoRA, hasbeen recognized as a bottleneck. In this work, we systematically investigatethe impact of redundancy in fine-tuning LoRA and reveal that reducing densityredundancy does not degrade expressiveness. Based on this insight, we introduce\underline{S}pectral-\underline{e}ncoding \underline{L}ow-\underline{R}ank\underline{A}daptation (SeLoRA), which harnesses the robust expressiveness ofspectral bases to re-parameterize LoRA from a sparse spectral subspace.Designed with simplicity, SeLoRA enables seamless integration with various LoRAvariants for performance boosting, serving as a scalable plug-and-playframework. Extensive experiments substantiate that SeLoRA achieves greaterefficiency with fewer parameters, delivering superior performance enhancementsover strong baselines on various downstream tasks, including commonsensereasoning, math reasoning, and code generation.</description>
      <author>example@mail.com (Jiashun Cheng, Aochuan Chen, Nuo Chen, Ziqi Gao, Yuhan Li, Jia Li, Fugee Tsung)</author>
      <guid isPermaLink="false">2506.16787v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Refining music sample identification with a self-supervised graph neural network</title>
      <link>http://arxiv.org/abs/2506.14684v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted at International Conference for Music Information Retrieval  (ISMIR) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种轻量级且可扩展的编码架构，用于自动样本识别（ASID），旨在解决音频检索领域中的挑战。&lt;h4&gt;背景&lt;/h4&gt;自动样本识别是检测和识别在新的音乐作品中重复使用的音频片段的任务，这是一个重要但具有挑战性的任务。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够抵抗音乐制作中常见变换（如时间伸缩、音高变换、效果处理以及底层或叠加的音乐）的鲁棒系统。&lt;h4&gt;方法&lt;/h4&gt;提出了一种使用图神经网络在对比学习框架内的轻量级编码架构，并通过两阶段方法提高检索质量：第一阶段进行粗略相似性搜索以选择候选样本，第二阶段使用跨注意力分类器拒绝无关匹配并细化检索候选的排名。&lt;h4&gt;主要发现&lt;/h4&gt;与现有最先进的系统相比，该模型仅使用9%的可训练参数，同时实现了可比的性能，平均平均精度（mAP）达到44.2%。&lt;h4&gt;结论&lt;/h4&gt;该系统通过新的细粒度标注对短查询进行了基准测试，并发布了Sample100数据集作为本研究的一部分。&lt;h4&gt;翻译&lt;/h4&gt;自动样本识别（ASID），检测和识别在新的音乐作品中重复使用的音频记录片段，是音频查询检索领域中的一个基本但具有挑战性的任务。虽然与音频指纹识别相关的任务在“真实世界”条件下（噪声、混响）不准确地检索音乐内容方面取得了重大进展，但ASID系统在识别经过音乐修改的样本方面仍存在困难。因此，一个能够抵抗常见音乐制作变换（如时间伸缩、音高变换、效果处理以及底层或叠加的音乐）的系统是一个重要的开放挑战。在本工作中，我们提出了一种轻量级且可扩展的编码架构，采用对比学习框架内的图神经网络。与当前最先进的系统相比，我们的模型仅使用9%的可训练参数，同时实现了可比的性能，平均平均精度（mAP）达到44.2%。为了提高检索质量，我们引入了一种两阶段方法，包括一个初始的粗略相似性搜索以选择候选样本，随后是一个跨注意力分类器，该分类器拒绝无关匹配并细化检索候选的排名——这是先前模型所缺乏的基本能力。此外，由于现实世界应用中的查询通常较短，我们对使用新细粒度标注的Sample100数据集进行了短查询的基准测试，并将这些标注作为本研究的一部分发布。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/chymaera96/neuralsampleid&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Automatic sample identification (ASID), the detection and identification ofportions of audio recordings that have been reused in new musical works, is anessential but challenging task in the field of audio query-based retrieval.While a related task, audio fingerprinting, has made significant progress inaccurately retrieving musical content under "real world" (noisy, reverberant)conditions, ASID systems struggle to identify samples that have undergonemusical modifications. Thus, a system robust to common music productiontransformations such as time-stretching, pitch-shifting, effects processing,and underlying or overlaying music is an important open challenge.  In this work, we propose a lightweight and scalable encoding architectureemploying a Graph Neural Network within a contrastive learning framework. Ourmodel uses only 9% of the trainable parameters compared to the currentstate-of-the-art system while achieving comparable performance, reaching a meanaverage precision (mAP) of 44.2%.  To enhance retrieval quality, we introduce a two-stage approach consisting ofan initial coarse similarity search for candidate selection, followed by across-attention classifier that rejects irrelevant matches and refines theranking of retrieved candidates - an essential capability absent in priormodels. In addition, because queries in real-world applications are often shortin duration, we benchmark our system for short queries using new fine-grainedannotations for the Sample100 dataset, which we publish as part of this work.</description>
      <author>example@mail.com (Aditya Bhattacharjee, Ivan Meresman Higgs, Mark Sandler, Emmanouil Benetos)</author>
      <guid isPermaLink="false">2506.14684v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Wavelet-based Global Orientation and Surface Reconstruction for Point Clouds</title>
      <link>http://arxiv.org/abs/2506.16299v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  22Pages&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于小波变换的表面重建方法，用于无向点云的表面重建和方向重建，并实现了高效的计算性能。&lt;h4&gt;背景&lt;/h4&gt;无向表面重建在计算机图形学中非常重要，具有广泛的应用。传统的基于小波变换的方法仅适用于有向点，且在处理稀疏点云时表现不佳。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，以解决传统方法在处理无向点和稀疏点云时的不足。&lt;h4&gt;方法&lt;/h4&gt;该方法利用小波变换的紧支集特性和正交性质，通过改进的核函数平滑表面上的不连续性，并使用卷积核函数的性质加速计算。同时，提出了一种新的构建无散度函数场的方法，以及使用该函数场构建额外的齐次约束条件，以提高重建的有效性和稳定性。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在无向点和稀疏点云的表面重建和方向重建方面均取得了最先进的性能。&lt;h4&gt;结论&lt;/h4&gt;该方法在CPU上实现了高效的性能，并且将在GitHub上发布源代码。&lt;h4&gt;翻译&lt;/h4&gt;Unoriented surface reconstruction is an important task in computer graphics and has extensive applications. Based on the compact support of wavelet and orthogonality properties, classic wavelet surface reconstruction achieves good and fast reconstruction. However, this method can only handle oriented points. Despite some improved attempts for unoriented points, such as iWSR, these methods perform poorly on sparse point clouds. To address these shortcomings, we propose a wavelet-based method to represent the mollified indicator function and complete both the orientation and surface reconstruction tasks. We use the modifying kernel function to smoothen out discontinuities on the surface, aligning with the continuity of the wavelet basis function. During the calculation of coefficient, we fully utilize the properties of the convolutional kernel function to shift the modifying computation onto wavelet basis to accelerate. In addition, we propose a novel method for constructing the divergence-free function field and using them to construct the additional homogeneous constraints to improve the effectiveness and stability. Extensive experiments demonstrate that our method achieves state-of-the-art performance in both orientation and reconstruction for sparse models. We align the matrix construction with the compact support property of wavelet basis functions to further accelerate our method, resulting in efficient performance on CPU. Our source codes will be released on GitHub.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Unoriented surface reconstruction is an important task in computer graphicsand has extensive applications. Based on the compact support of wavelet andorthogonality properties, classic wavelet surface reconstruction achieves goodand fast reconstruction. However, this method can only handle oriented points.Despite some improved attempts for unoriented points, such as iWSR, thesemethods perform poorly on sparse point clouds. To address these shortcomings,we propose a wavelet-based method to represent the mollified indicator functionand complete both the orientation and surface reconstruction tasks. We use themodifying kernel function to smoothen out discontinuities on the surface,aligning with the continuity of the wavelet basis function. During thecalculation of coefficient, we fully utilize the properties of theconvolutional kernel function to shift the modifying computation onto waveletbasis to accelerate. In addition, we propose a novel method for constructingthe divergence-free function field and using them to construct the additionalhomogeneous constraints to improve the effectiveness and stability. Extensiveexperiments demonstrate that our method achieves state-of-the-art performancein both orientation and reconstruction for sparse models. We align the matrixconstruction with the compact support property of wavelet basis functions tofurther accelerate our method, resulting in efficient performance on CPU. Oursource codes will be released on GitHub.</description>
      <author>example@mail.com (Yueji Ma, Yanzun Meng, Dong Xiao, Zuoqiang Shi, Bin Wang)</author>
      <guid isPermaLink="false">2506.16299v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Mitigating Over-Squashing in Graph Neural Networks by Spectrum-Preserving Sparsification</title>
      <link>http://arxiv.org/abs/2506.16110v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Published as a conference paper at ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的图重连方法，通过利用谱保持图稀疏化来减轻过度压缩问题，从而在提高图连接性的同时保持稀疏性和原图谱的大致不变。&lt;h4&gt;背景&lt;/h4&gt;图神经网络的信息传递范式在交换远距离节点信息时遇到困难，通常是由于某些图区域的结构性瓶颈造成的，这一局限性被称为过度压缩。&lt;h4&gt;目的&lt;/h4&gt;减少结构性瓶颈，提出一种新的图重连方法，以改善图神经网络的信息传递。&lt;h4&gt;方法&lt;/h4&gt;该方法通过谱保持图稀疏化来生成具有增强连接性的图，同时保持稀疏性和原图谱的大致不变。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在分类准确性和拉普拉斯谱保留方面优于强基线方法。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地平衡了结构性瓶颈的减少和图属性的保留，验证了其在图重连方面的有效性。&lt;h4&gt;翻译&lt;/h4&gt;The message-passing paradigm of Graph Neural Networks often struggles with exchanging information across distant nodes typically due to structural bottlenecks in certain graph regions, a limitation known as 'over-squashing'. To reduce such bottlenecks, 'graph rewiring', which modifies graph topology, has been widely used. However, existing graphrewiring techniques often overlook the need to preserve critical properties of the original graph, e.g., 'spectral properties'. Moreover, many approaches rely on increasing edge count to improve connectivity, which introduces significant computational overhead and exacerbates the risk ofover-smoothing. In this paper, we propose a novel graph rewiring method that leverages 'spectrum-preserving' graph 'sparsification', formitigating over-squashing. Our method generates graphs with enhanced connectivity while maintaining sparsity and largely preserving the original graph spectrum, effectively balancing structural bottleneck reduction and graph property preservation. Experimental results validate the effectiveness of our approach, demonstrating its superiority over strong baseline methods in classification accuracy and retention of the Laplacian spectrum.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The message-passing paradigm of Graph Neural Networks often struggles withexchanging information across distant nodes typically due to structuralbottlenecks in certain graph regions, a limitation known as\textit{over-squashing}. To reduce such bottlenecks, \textit{graph rewiring},which modifies graph topology, has been widely used. However, existing graphrewiring techniques often overlook the need to preserve critical properties ofthe original graph, e.g., \textit{spectral properties}. Moreover, manyapproaches rely on increasing edge count to improve connectivity, whichintroduces significant computational overhead and exacerbates the risk ofover-smoothing. In this paper, we propose a novel graph rewiring method thatleverages \textit{spectrum-preserving} graph \textit{sparsification}, formitigating over-squashing. Our method generates graphs with enhancedconnectivity while maintaining sparsity and largely preserving the originalgraph spectrum, effectively balancing structural bottleneck reduction and graphproperty preservation. Experimental results validate the effectiveness of ourapproach, demonstrating its superiority over strong baseline methods inclassification accuracy and retention of the Laplacian spectrum.</description>
      <author>example@mail.com (Langzhang Liang, Fanchen Bu, Zixing Song, Zenglin Xu, Shirui Pan, Kijung Shin)</author>
      <guid isPermaLink="false">2506.16110v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Weight Factorization and Centralization for Continual Learning in Speech Recognition</title>
      <link>http://arxiv.org/abs/2506.16574v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to INTERSPEECH 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于现代神经网络的语言无关的持续学习语音识别模型，以解决在缺乏原始训练数据的情况下，模型需要不断吸收新数据的问题。&lt;h4&gt;背景&lt;/h4&gt;现代神经网络在语音识别领域的应用需要不断吸收新数据，但下游应用通常无法访问原始训练数据，因此需要在不重新训练整个系统的情况下进行。&lt;h4&gt;目的&lt;/h4&gt;为了避免在持续训练过程中出现灾难性遗忘，提出了一种包含两个阶段（因子化和集中化）的持续学习方法。&lt;h4&gt;方法&lt;/h4&gt;该方法模仿人类大脑的觉醒-睡眠周期，通过多个低秩适配器累积知识，以防止灾难性遗忘。&lt;h4&gt;主要发现&lt;/h4&gt;在一系列代码切换数据集上的实验表明，集中化阶段可以有效防止灾难性遗忘。&lt;h4&gt;结论&lt;/h4&gt;提出的持续学习方法能够有效提高语音识别模型在多语言和语言无关条件下的持续学习能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代基于神经网络的语音识别模型需要不断吸收新数据，而无需重新训练整个系统，尤其是在没有访问原始训练数据的下游应用中。在无排练、多语言和语言无关的条件下持续训练模型，可能导致灾难性遗忘，即使是看似微小的权重扰动也可能对模型质量造成破坏性影响。受人类大脑通过觉醒-睡眠周期学习并巩固知识的能力的启发，我们提出了一种包含两个不同阶段（因子化和集中化）的持续学习方法，相应地学习和合并知识。我们在一系列代码切换数据集上的实验表明，集中化阶段可以通过累积多个散射低秩适配器中的知识来有效防止灾难性遗忘。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern neural network based speech recognition models are required tocontinually absorb new data without re-training the whole system, especially indownstream applications using foundation models, having no access to theoriginal training data. Continually training the models in a rehearsal-free,multilingual, and language agnostic condition, likely leads to catastrophicforgetting, when a seemingly insignificant disruption to the weights candestructively harm the quality of the models. Inspired by the ability of humanbrains to learn and consolidate knowledge through the waking-sleeping cycle, wepropose a continual learning approach with two distinct phases: factorizationand centralization, learning and merging knowledge accordingly. Our experimentson a sequence of varied code-switching datasets showed that the centralizationstage can effectively prevent catastrophic forgetting by accumulating theknowledge in multiple scattering low-rank adapters.</description>
      <author>example@mail.com (Enes Yavuz Ugan, Ngoc-Quan Pham, Alexander Waibel)</author>
      <guid isPermaLink="false">2506.16574v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Cross-Modal Geometric Hierarchy Fusion: An Implicit-Submap Driven Framework for Resilient 3D Place Recognition</title>
      <link>http://arxiv.org/abs/2506.14243v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于LiDAR的地点识别新框架，用于解决长期自主导航中的地点识别问题。&lt;h4&gt;背景&lt;/h4&gt;现有的地点识别方法依赖于手工特征提取，存在点云密度不一致和几何抽象表示脆弱的问题。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，通过密度无关的几何推理重新定义3D地点识别。&lt;h4&gt;方法&lt;/h4&gt;引入基于弹性点的隐式3D表示，避免原始场景点云密度干扰，并从该表示中推导场景的占用网格和法线向量信息。最终，结合这两种信息，获得融合了鸟瞰图（捕捉宏观空间布局）和3D分段（编码微观表面几何）视角的描述符。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在多个数据集上实现了最先进的性能，并在准确性、运行时间和内存优化方面取得了最佳平衡。&lt;h4&gt;结论&lt;/h4&gt;该方法具有优异的鲁棒性和可扩展性，未来将开源代码。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/HBLT-hub/CMGHF&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; LiDAR-based place recognition serves as a crucial enabler for long-termautonomy in robotics and autonomous driving systems. Yet, prevailingmethodologies relying on handcrafted feature extraction face dual challenges:(1) Inconsistent point cloud density, induced by ego-motion dynamics andenvironmental disturbances during repeated traversals, leads to descriptorinstability, and (2) Representation fragility stems from reliance onsingle-level geometric abstractions that lack discriminative power instructurally complex scenarios. To address these limitations, we propose anovel framework that redefines 3D place recognition through density-agnosticgeometric reasoning. Specifically, we introduce an implicit 3D representationbased on elastic points, which is immune to the interference of original scenepoint cloud density and achieves the characteristic of uniform distribution.Subsequently, we derive the occupancy grid and normal vector information of thescene from this implicit representation. Finally, with the aid of these twotypes of information, we obtain descriptors that fuse geometric informationfrom both bird's-eye view (capturing macro-level spatial layouts) and 3Dsegment (encoding micro-scale surface geometries) perspectives. We conductedextensive experiments on numerous datasets (KITTI, KITTI-360, MulRan, NCLT)across diverse environments. The experimental results demonstrate that ourmethod achieves state-of-the-art performance. Moreover, our approach strikes anoptimal balance between accuracy, runtime, and memory optimization forhistorical maps, showcasing excellent Resilient and scalability. Our code willbe open-sourced in the future.</description>
      <author>example@mail.com (Xiaohui Jiang, Haijiang Zhu, Chade Li, Fulin Tang, Ning An)</author>
      <guid isPermaLink="false">2506.14243v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Dense 3D Displacement Estimation for Landslide Monitoring via Fusion of TLS Point Clouds and Embedded RGB Images</title>
      <link>http://arxiv.org/abs/2506.16265v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  20 pages, 16 figures. Preprint under peer review. Example data and  code available at [GitHub](https://github.com/zhaoyiww/fusion4landslide)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于层次分割的粗到精方法，融合3D点云和配准的RGB图像来估计密集的3D位移矢量场，用于滑坡监测。&lt;h4&gt;背景&lt;/h4&gt;现有的基于点云的滑坡监测方法通常依赖于几何或辐射信息，往往产生稀疏或非3D位移估计。&lt;h4&gt;目的&lt;/h4&gt;提出一种能够估计密集3D位移矢量场的新方法，以更好地监测滑坡。&lt;h4&gt;方法&lt;/h4&gt;使用3D几何和2D图像特征构建补丁级别的匹配，通过几何一致性检查和每个匹配的刚体变换估计来细化这些匹配。&lt;h4&gt;主要发现&lt;/h4&gt;在两个真实世界滑坡数据集上的实验结果表明，该方法产生了具有高空间覆盖率和高精度的3D位移估计。位移幅度的偏差小于平均扫描分辨率。&lt;h4&gt;结论&lt;/h4&gt;该方法在空间覆盖率上优于现有的F2S3方法，同时保持了可比的精度，为基于TLS的滑坡监测提供了一种实用且可扩展的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;摘要：滑坡监测对于理解地质灾害和减轻相关风险至关重要。然而，现有的基于点云的方法通常依赖于几何或辐射信息，往往产生稀疏或非3D位移估计。在本文中，我们提出了一种基于层次分割的粗到精方法，融合3D点云和配准的RGB图像以估计密集的3D位移矢量场。我们使用3D几何和2D图像特征构建补丁级别的匹配。这些匹配通过几何一致性检查进行细化，然后对每个匹配进行刚体变换估计。在两个真实世界滑坡数据集上的实验结果表明，我们的方法产生了具有高空间覆盖率（79%和97%）和高精度的3D位移估计。与地面测量（全站仪或GNSS观测）相比，两个数据集中的位移幅度的偏差分别为0.15米和0.25米，与手工提取的参考值相比，仅为0.07米和0.20米。这些值低于平均扫描分辨率（0.08米和0.30米）。我们的方法在空间覆盖率上优于最先进的F2S3方法，同时保持了可比的精度。我们的方法为基于TLS的滑坡监测提供了一种实用且可扩展的解决方案，并可扩展到其他类型的点云和监测任务。我们的示例数据和源代码可在https://github.com/zhaoyiww/fusion4landslide公开获取。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Landslide monitoring is essential for understanding geohazards and mitigatingassociated risks. However, existing point cloud-based methods typically rely oneither geometric or radiometric information and often yield sparse or non-3Ddisplacement estimates. In this paper, we propose a hierarchicalpartition-based coarse-to-fine approach that fuses 3D point clouds andco-registered RGB images to estimate dense 3D displacement vector fields. Weconstruct patch-level matches using both 3D geometry and 2D image features.These matches are refined via geometric consistency checks, followed by rigidtransformation estimation per match. Experimental results on two real-worldlandslide datasets demonstrate that our method produces 3D displacementestimates with high spatial coverage (79% and 97%) and high accuracy.Deviations in displacement magnitude with respect to external measurements(total station or GNSS observations) are 0.15 m and 0.25 m on the two datasets,respectively, and only 0.07 m and 0.20 m compared to manually derivedreferences. These values are below the average scan resolutions (0.08 m and0.30 m). Our method outperforms the state-of-the-art method F2S3 in spatialcoverage while maintaining comparable accuracy. Our approach offers a practicaland adaptable solution for TLS-based landslide monitoring and is extensible toother types of point clouds and monitoring tasks. Our example data and sourcecode are publicly available at https://github.com/zhaoyiww/fusion4landslide.</description>
      <author>example@mail.com (Zhaoyi Wang, Jemil Avers Butt, Shengyu Huang, Tomislav Medic, Andreas Wieser)</author>
      <guid isPermaLink="false">2506.16265v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>A Brain-to-Population Graph Learning Framework for Diagnosing Brain Disorders</title>
      <link>http://arxiv.org/abs/2506.16096v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  16 pages, 7 figures, 13 tables; this paper has been submitted for  possible publication&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为B2P-GL的脑部疾病诊断框架，通过结合语义相似性和基于人群的图模型，提高了诊断的准确性和可解释性。&lt;h4&gt;背景&lt;/h4&gt;现有的基于图的方法在诊断脑部疾病时高度依赖预定义的脑图谱，但忽略了图谱中嵌入的丰富信息和位置及表型变异的混杂效应。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些问题，提出了一个两阶段的框架，旨在提高脑部疾病诊断的准确性和个性化。&lt;h4&gt;方法&lt;/h4&gt;第一阶段是脑表示学习，利用GPT-4的知识丰富图表示并通过自适应节点重新分配图注意力网络来优化脑图谱。第二阶段是人群疾病诊断，将表型数据纳入人群图构建和特征融合，以减轻混杂效应并提高诊断性能。&lt;h4&gt;主要发现&lt;/h4&gt;在ABIDEI、ADHD-200和Rest-meta-MDD数据集上的实验表明，B2P-GL在预测准确性方面优于现有方法，同时增强了可解释性。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了一种可靠且个性化的脑部疾病诊断方法，推动了临床应用。&lt;h4&gt;翻译&lt;/h4&gt;A recently developed graph-based method for diagnosing brain disorders uses functional connectivity, which heavily relies on predefined brain atlases but overlooks the rich information within the atlases and the confounding effects of site and phenotype variability. To address these challenges, we propose a two-stage Brain-to-Population Graph Learning (B2P-GL) framework that integrates the semantic similarity of brain regions and condition-based population graph modeling. In the first stage, termed brain representation learning, we leverage brain atlas knowledge from GPT-4 to enrich the graph representation and refine the brain graph through an adaptive node reassignment graph attention network. In the second stage, termed population disorder diagnosis, phenotypic data is incorporated into population graph construction and feature fusion to mitigate confounding effects and enhance diagnosis performance. Experiments on the ABIDEI, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperforms state-of-the-art methods in prediction accuracy while enhancing interpretability. Overall, our proposed framework offers a reliable and personalized approach to brain disorder diagnosis, advancing clinical applicability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Recent developed graph-based methods for diagnosing brain disorders usingfunctional connectivity highly rely on predefined brain atlases, but overlookthe rich information embedded within atlases and the confounding effects ofsite and phenotype variability. To address these challenges, we propose atwo-stage Brain-to-Population Graph Learning (B2P-GL) framework that integratesthe semantic similarity of brain regions and condition-based population graphmodeling. In the first stage, termed brain representation learning, we leveragebrain atlas knowledge from GPT-4 to enrich the graph representation and refinethe brain graph through an adaptive node reassignment graph attention network.In the second stage, termed population disorder diagnosis, phenotypic data isincorporated into population graph construction and feature fusion to mitigateconfounding effects and enhance diagnosis performance. Experiments on the ABIDEI, ADHD-200, and Rest-meta-MDD datasets show that B2P-GL outperformsstate-of-the-art methods in prediction accuracy while enhancinginterpretability. Overall, our proposed framework offers a reliable andpersonalized approach to brain disorder diagnosis, advancing clinicalapplicability.</description>
      <author>example@mail.com (Qianqian Liao, Wuque Cai, Hongze Sun, Dongze Liu, Duo Chen, Dezhong Yao, Daqing Guo)</author>
      <guid isPermaLink="false">2506.16096v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Unveiling defect motifs in amorphous GeSe using machine learning interatomic potentials</title>
      <link>http://arxiv.org/abs/2506.15934v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  21 pages, 11 figures, Supplementary information included as ancillary  file (+12 pages)&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文利用机器学习加速的分子动力学模拟，研究了非晶GeSe中的缺陷，旨在揭示非晶GeSe中缺陷驱动的Ovonic阈值切换(OTS)现象。&lt;h4&gt;背景&lt;/h4&gt;Ovonic阈值切换选择器在非易失性存储设备中因非线性电行为和极化依赖的阈值电压而至关重要，但其原子尺度缺陷状态的起源尚不完全清楚。&lt;h4&gt;目的&lt;/h4&gt;通过分子动力学模拟，利用机器学习加速的原子间势能，研究非晶GeSe中的缺陷，以理解其非线性电行为和阈值电压的原子尺度起源。&lt;h4&gt;方法&lt;/h4&gt;对多种潜在架构进行基准测试，包括基于描述符的模型和图神经网络(GNN)模型，并使用具有多个交互层的GNN架构来捕捉高阶相互作用和中等范围的结构顺序。&lt;h4&gt;主要发现&lt;/h4&gt;发现多个交互层的GNN架构可以成功捕捉这些相关性和结构模式，避免了表达能力较差的模型引入的虚假缺陷；识别出两种不同的缺陷模式：对齐的Ge链和过配位的Ge链；将电子缺陷水平与特定的结构特征相关联，如对齐链中键角的平均对齐和过配位Ge原子周围的局部Peierls畸变程度。&lt;h4&gt;结论&lt;/h4&gt;这些发现为解释实验观察提供了一个理论框架，并加深了对非晶GeSe中缺陷驱动的OTS现象的理解。&lt;h4&gt;翻译&lt;/h4&gt;Ovonic阈值切换（OTS）选择器由于它们的非线性电行为和极化依赖的阈值电压，在非易失性存储设备中发挥着关键作用。然而，导致这些特性的缺陷状态的原子尺度起源尚不完全清楚。在这项研究中，我们使用机器学习加速的原子间势能加速的分子动力学模拟来研究非晶GeSe中的缺陷。我们首先对几种潜在架构进行了基准测试，包括基于描述符的模型和图神经网络（GNN）模型，并表明忠实表示非晶GeSe需要捕获高阶相互作用（至少四体相关）和中程结构顺序。我们发现，具有多个交互层的GNN架构可以成功地捕获这些相关性和结构模式，防止了表达能力较差的模型引入的虚假缺陷。通过我们的优化GNN势能，我们检查了20个独立的960原子非晶GeSe结构，并确定了两种不同的缺陷模式：对齐的Ge链，这导致近导带的缺陷状态，以及过配位的Ge链，这产生近价带的缺陷状态。我们进一步将这些电子缺陷水平与特定的结构特征相关联，即对齐链中键角的平均对齐和过配位Ge原子周围的局部Peierls畸变程度。这些发现为解释实验观察提供了一个理论框架，并加深了对非晶GeSe中缺陷驱动的OTS现象的理解。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ovonic threshold switching (OTS) selectors play a critical role innon-volatile memory devices because of their nonlinear electrical behavior andpolarity-dependent threshold voltages. However, the atomic-scale origins of thedefect states responsible for these properties are not yet fully understood. Inthis study, we use molecular dynamics simulations accelerated bymachine-learning interatomic potentials to investigate defects in amorphousGeSe. We begin by benchmarking several potential architectures-includingdescriptor-based models and graph neural network (GNN) models-and show thatfaithfully representing amorphous GeSe requires capturing higher-orderinteractions (at least four-body correlations) and medium-range structuralorder. We find that GNN architectures with multiple interaction layerssuccessfully capture these correlations and structural motifs, preventing thespurious defects that less expressive models introduce. With our optimized GNNpotential, we examine twenty independent 960-atom amorphous GeSe structures andidentify two distinct defect motifs: aligned Ge chains, which give rise todefect states near the conduction band, and overcoordinated Ge chains, whichproduce defect states near the valence band. We further correlate theseelectronic defect levels with specific structural features-namely, the averagealignment of bond angles in the aligned chains and the degree of local Peierlsdistortion around overcoordinated Ge atoms. These findings provide atheoretical framework for interpreting experimental observations and deepen ourunderstanding of defect-driven OTS phenomena in amorphous GeSe.</description>
      <author>example@mail.com (Minseok Moon, Seungwoo Hwang, Jaesun Kim, Yutack Park, Changho Hong, Seungwu Han)</author>
      <guid isPermaLink="false">2506.15934v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>CRIA: A Cross-View Interaction and Instance-Adapted Pre-training Framework for Generalizable EEG Representations</title>
      <link>http://arxiv.org/abs/2506.16056v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为CRIA的适应性框架，用于从EEG数据中提取深度特征并有效整合多视角信息，以构建通用的EEG表征学习预训练框架。&lt;h4&gt;背景&lt;/h4&gt;从EEG数据中提取深度特征和有效整合多视角信息对于开发通用的EEG表征学习预训练框架是一个重大挑战。&lt;h4&gt;目的&lt;/h4&gt;提出CRIA框架，旨在解决现有预训练方法仅依赖于单一视角的上下文语义，未能捕捉不同视角之间复杂和协同交互的问题。&lt;h4&gt;方法&lt;/h4&gt;CRIA利用可变长度和可变通道编码实现不同数据集上EEG数据的统一表征。定义跨视角信息为来自EEG信号时间、频谱和空间视角交互产生的综合表征。模型采用跨注意力机制有效地融合时间、频谱和空间特征，并结合基于信息瓶颈原理的注意力矩阵掩码策略和一种新颖的观点掩码预训练方案。&lt;h4&gt;主要发现&lt;/h4&gt;在Temple University EEG语料库和CHB-MIT数据集上的实验结果表明，CRIA在相同的预训练条件下优于现有方法，多类事件分类的平衡准确率达到57.02%，异常检测的准确率达到80.03%，显示出其强大的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;CRIA框架在EEG表征学习中展现出优越的性能，特别是在多类事件分类和异常检测任务上，证明了其在实际应用中的潜力。&lt;h4&gt;翻译&lt;/h4&gt;The difficulty of extracting deep features from EEG data and effectively integrating information from multiple views presents significant challenges for developing a generalizable pretraining framework for EEG representation learning. However, most existing pre-training methods rely solely on the contextual semantics of a single view, failing to capture the complex and synergistic interactions among different perspectives, limiting the expressiveness and generalization of learned representations. To address these issues, this paper proposes CRIA, an adaptive framework that utilizes variable-length and variable-channel coding to achieve a unified representation of EEG data across different datasets. In this work, we define cross-view information as the integrated representation that emerges from the interaction among temporal, spectral, and spatial views of EEG signals. The model employs a cross-attention mechanism to fuse temporal, spectral, and spatial features effectively, and combines an attention matrix masking strategy based on the information bottleneck principle with a novel viewpoint masking pre-training scheme. Experimental results on the Temple University EEG corpus and the CHB-MIT dataset show that CRIA outperforms existing methods with the same pre-training conditions, achieving a balanced accuracy of 57.02% for multi-class event classification and 80.03% for anomaly detection, highlighting its strong generalization ability.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The difficulty of extracting deep features from EEG data and effectivelyintegrating information from multiple views presents significant challenges fordeveloping a generalizable pretraining framework for EEG representationlearning. However, most existing pre-training methods rely solely on thecontextual semantics of a single view, failing to capture the complex andsynergistic interactions among different perspectives, limiting theexpressiveness and generalization of learned representations. To address theseissues, this paper proposes CRIA, an adaptive framework that utilizesvariable-length and variable-channel coding to achieve a unified representationof EEG data across different datasets. In this work, we define cross-viewinformation as the integrated representation that emerges from the interactionamong temporal, spectral, and spatial views of EEG signals. The model employs across-attention mechanism to fuse temporal, spectral, and spatial featureseffectively, and combines an attention matrix masking strategy based on theinformation bottleneck principle with a novel viewpoint masking pre-trainingscheme. Experimental results on the Temple University EEG corpus and theCHB-MIT dataset show that CRIA outperforms existing methods with the samepre-training conditions, achieving a balanced accuracy of 57.02% formulti-class event classification and 80.03% for anomaly detection, highlightingits strong generalization ability.</description>
      <author>example@mail.com (Puchun Liu, C. L. Philip Chen, Yubin He, Tong Zhang)</author>
      <guid isPermaLink="false">2506.16056v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details</title>
      <link>http://arxiv.org/abs/2506.16504v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Technical report&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了Hunyuan3D 2.5，这是一个用于生成高保真和详细纹理3D资产的稳健的3D扩散模型套件。&lt;h4&gt;背景&lt;/h4&gt;Hunyuan3D 2.5基于其前版本Hunyuan3D 2.0的两阶段流程，同时在形状和纹理生成方面有显著进步。&lt;h4&gt;目的&lt;/h4&gt;旨在生成高保真和详细的纹理3D资产。&lt;h4&gt;方法&lt;/h4&gt;在形状生成方面，引入了新的形状基础模型LATTICE，该模型使用缩放的高质量数据集进行训练，模型规模和计算能力得到提升。在纹理生成方面，通过扩展自Hunyuan3D 2.0 Paint模型的全新多视图架构，引入了基于物理的渲染（PBR）。&lt;h4&gt;主要发现&lt;/h4&gt;Hunyuan3D 2.5在形状和端到端纹理生成方面显著优于之前的方法，其最大的模型达到10B参数，能够生成清晰和详细的3D形状，同时保持网格表面的清洁和光滑。&lt;h4&gt;结论&lt;/h4&gt;Hunyuan3D 2.5在形状和纹理生成方面取得了显著进步，显著缩小了生成形状与手工制作3D形状之间的差距。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusionmodels aimed at generating high-fidelity and detailed textured 3D assets.Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D2.0, while demonstrating substantial advancements in both shape and texturegeneration. In terms of shape generation, we introduce a new shape foundationmodel -- LATTICE, which is trained with scaled high-quality datasets,model-size, and compute. Our largest model reaches 10B parameters and generatessharp and detailed 3D shape with precise image-3D following while keeping meshsurface clean and smooth, significantly closing the gap between generated andhandcrafted 3D shapes. In terms of texture generation, it is upgraded withphyiscal-based rendering (PBR) via a novel multi-view architecture extendedfrom Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D2.5 significantly outperforms previous methods in both shape and end-to-endtexture generation.</description>
      <author>example@mail.com (Zeqiang Lai, Yunfei Zhao, Haolin Liu, Zibo Zhao, Qingxiang Lin, Huiwen Shi, Xianghui Yang, Mingxin Yang, Shuhui Yang, Yifei Feng, Sheng Zhang, Xin Huang, Di Luo, Fan Yang, Fang Yang, Lifu Wang, Sicong Liu, Yixuan Tang, Yulin Cai, Zebin He, Tian Liu, Yuhong Liu, Jie Jiang, Linus, Jingwei Huang, Chunchao Guo)</author>
      <guid isPermaLink="false">2506.16504v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>KG-FGNN: Knowledge-guided GNN Foundation Model for Fertilisation-oriented Soil GHG Flux Prediction</title>
      <link>http://arxiv.org/abs/2506.15896v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 4 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于知识引导的图神经网络框架，用于精确预测土壤温室气体通量，以解决农业数据稀缺和机器学习方法应用受限的问题。&lt;h4&gt;背景&lt;/h4&gt;由于大多数农场缺乏先进的传感器和网络技术，获取全面和多样化的农业数据存在挑战，这严重阻碍了机器学习在精确土壤温室气体通量预测中的应用。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够有效预测土壤温室气体通量的方法，以支持农业系统的环境影响评估、排放减缓策略制定和可持续农业发展。&lt;h4&gt;方法&lt;/h4&gt;研究提出了一个结合了基于农业过程模型的农业数据集和图神经网络技术的知识引导图神经网络框架。该方法利用农业过程模型模拟和生成涵盖多种农业变量的多维度数据集，并采用自动编码器和基于多目标的图神经网络来提取关键特征和整合特征之间的相关性。&lt;h4&gt;主要发现&lt;/h4&gt;通过在农业模拟数据集和真实世界农业数据集上进行全面实验，与已知的基线和最先进的回归方法相比，提出的方法在施肥导向的土壤温室气体预测中提供了更高的准确性和稳定性。&lt;h4&gt;结论&lt;/h4&gt;该研究提出的框架在施肥导向的土壤温室气体预测中显示出优越的准确性和稳定性，为农业系统中的环境评估和可持续农业实践提供了有力支持。&lt;h4&gt;翻译&lt;/h4&gt;Precision soil greenhouse gas (GHG) flux prediction is essential in agricultural systems for assessing environmental impacts, developing emission mitigation strategies and promoting sustainable agriculture. Due to the lack of advanced sensor and network technologies on majority of farms, there are challenges in obtaining comprehensive and diverse agricultural data. As a result, the scarcity of agricultural data seriously obstructs the application of machine learning approaches in precision soil GHG flux prediction. This research proposes a knowledge-guided graph neural network framework that addresses the above challenges by integrating knowledge embedded in an agricultural process-based model and graph neural network techniques. Specifically, we utilise the agricultural process-based model to simulate and generate multi-dimensional agricultural datasets for 47 countries that cover a wide range of agricultural variables. To extract key agricultural features and integrate correlations among agricultural features in the prediction process, we propose a machine learning framework that integrates the autoencoder and multi-target multi-graph based graph neural networks, which utilises the autoencoder to selectively extract significant agricultural features from the agricultural process-based model simulation data and the graph neural network to integrate correlations among agricultural features for accurately predict fertilisation-oriented soil GHG fluxes. Comprehensive experiments were conducted with both the agricultural simulation dataset and real-world agricultural dataset to evaluate the proposed approach in comparison with well-known baseline and state-of-the-art regression methods. The results demonstrate that our proposed approach provides superior accuracy and stability in fertilisation-oriented soil GHG prediction.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Precision soil greenhouse gas (GHG) flux prediction is essential inagricultural systems for assessing environmental impacts, developing emissionmitigation strategies and promoting sustainable agriculture. Due to the lack ofadvanced sensor and network technologies on majority of farms, there arechallenges in obtaining comprehensive and diverse agricultural data. As aresult, the scarcity of agricultural data seriously obstructs the applicationof machine learning approaches in precision soil GHG flux prediction. Thisresearch proposes a knowledge-guided graph neural network framework thataddresses the above challenges by integrating knowledge embedded in anagricultural process-based model and graph neural network techniques.Specifically, we utilise the agricultural process-based model to simulate andgenerate multi-dimensional agricultural datasets for 47 countries that cover awide range of agricultural variables. To extract key agricultural features andintegrate correlations among agricultural features in the prediction process,we propose a machine learning framework that integrates the autoencoder andmulti-target multi-graph based graph neural networks, which utilises theautoencoder to selectively extract significant agricultural features from theagricultural process-based model simulation data and the graph neural networkto integrate correlations among agricultural features for accurately predictfertilisation-oriented soil GHG fluxes. Comprehensive experiments wereconducted with both the agricultural simulation dataset and real-worldagricultural dataset to evaluate the proposed approach in comparison withwell-known baseline and state-of-the-art regression methods. The resultsdemonstrate that our proposed approach provides superior accuracy and stabilityin fertilisation-oriented soil GHG prediction.</description>
      <author>example@mail.com (Yu Zhang, Gaoshan Bi, Simon Jeffery, Max Davis, Yang Li, Qing Xue, Po Yang)</author>
      <guid isPermaLink="false">2506.15896v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>ViTacFormer: Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation</title>
      <link>http://arxiv.org/abs/2506.15953v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;ViTacFormer是一种结合视觉和触觉信息，用于精确控制机器手进行灵巧操作的新方法。&lt;h4&gt;背景&lt;/h4&gt;灵巧操作是机器人与物理世界交互的基础能力，触觉传感在无结构和视觉遮挡环境下对精确控制至关重要。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的方法，通过结合视觉和触觉信息，实现机器手的高精度灵巧操作。&lt;h4&gt;方法&lt;/h4&gt;开发了一个名为ViTacFormer的模型，该模型包含跨注意力编码器和自回归触觉预测头，用于融合高分辨率视觉和触觉信息。&lt;h4&gt;主要发现&lt;/h4&gt;通过学习跨模态表示，ViTacFormer能够提高机器手的操作准确性和鲁棒性，并在多个基准测试中取得比现有系统高50%的成功率。&lt;h4&gt;结论&lt;/h4&gt;ViTacFormer能够自主完成需要高精度控制的长期灵巧操作任务，执行多达11个连续阶段，连续运行2.5分钟，是目前该领域首次实现此类功能的系统。&lt;h4&gt;翻译&lt;/h4&gt;Dexterous manipulation is a cornerstone capability for robotic systems aiming to interact with the physical world in a human-like manner. Although vision-based methods have advanced rapidly, tactile sensing remains crucial for fine-grained control, particularly in unstructured or visually occluded settings. We present ViTacFormer, a representation-learning approach that couples a cross-attention encoder to fuse high-resolution vision and touch with an autoregressive tactile prediction head that anticipates future contact signals. Building on this architecture, we devise an easy-to-challenging curriculum that steadily refines the visual-tactile latent space, boosting both accuracy and robustness. The learned cross-modal representation drives imitation learning for multi-fingered hands, enabling precise and adaptive manipulation. Across a suite of challenging real-world benchmarks, our method achieves approximately 50% higher success rates than prior state-of-the-art systems. To our knowledge, it is also the first to autonomously complete long-horizon dexterous manipulation tasks that demand highly precise control with an anthropomorphic hand, successfully executing up to 11 sequential stages and sustaining continuous operation for 2.5 minutes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous manipulation is a cornerstone capability for robotic systems aimingto interact with the physical world in a human-like manner. Althoughvision-based methods have advanced rapidly, tactile sensing remains crucial forfine-grained control, particularly in unstructured or visually occludedsettings. We present ViTacFormer, a representation-learning approach thatcouples a cross-attention encoder to fuse high-resolution vision and touch withan autoregressive tactile prediction head that anticipates future contactsignals. Building on this architecture, we devise an easy-to-challengingcurriculum that steadily refines the visual-tactile latent space, boosting bothaccuracy and robustness. The learned cross-modal representation drivesimitation learning for multi-fingered hands, enabling precise and adaptivemanipulation. Across a suite of challenging real-world benchmarks, our methodachieves approximately 50% higher success rates than prior state-of-the-artsystems. To our knowledge, it is also the first to autonomously completelong-horizon dexterous manipulation tasks that demand highly precise controlwith an anthropomorphic hand, successfully executing up to 11 sequential stagesand sustaining continuous operation for 2.5 minutes.</description>
      <author>example@mail.com (Liang Heng, Haoran Geng, Kaifeng Zhang, Pieter Abbeel, Jitendra Malik)</author>
      <guid isPermaLink="false">2506.15953v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis</title>
      <link>http://arxiv.org/abs/2506.16398v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为HyperPath的新方法，用于癌症诊断中的全切片图像（WSI）分析。该方法通过结合文本描述知识，在双曲空间中建模WSI的语义层次结构，从而提高WSI分类性能。&lt;h4&gt;背景&lt;/h4&gt;病理学对于癌症诊断至关重要，而多实例学习（MIL）常用于WSI分析。WSI具有自然层次结构，包括补丁、区域和切片，具有不同的语义关联。现有方法主要依赖欧几里得嵌入，难以完全捕捉语义层次结构。&lt;h4&gt;目的&lt;/h4&gt;为了解决欧几里得嵌入的局限性，提出HyperPath方法，以增强WSI分类。&lt;h4&gt;方法&lt;/h4&gt;HyperPath方法结合了病理视觉-语言基础模型提取的视觉和文本特征，并将其应用于双曲空间。设计了角度模态对齐损失来确保跨模态对齐的鲁棒性，并设计了语义层次一致性损失，通过蕴涵和矛盾关系进一步细化特征层次，从而增强语义一致性。分类通过测地距离进行，该距离衡量了双曲语义层次中实体之间的相似性。&lt;h4&gt;主要发现&lt;/h4&gt;与现有方法相比，HyperPath在多个任务上实现了优越的性能，突出了双曲嵌入在WSI分析中的潜力。&lt;h4&gt;结论&lt;/h4&gt;HyperPath方法通过双曲嵌入和语义层次结构建模，显著提高了WSI分类的性能。&lt;h4&gt;翻译&lt;/h4&gt;摘要：病理学对于癌症诊断至关重要，多实例学习（MIL）广泛应用于全切片图像（WSI）分析。WSI表现出自然的层次结构——包括补丁、区域和切片——具有不同的语义关联。尽管一些方法试图利用这种层次结构来提高表示，但它们主要依赖于欧几里得嵌入，这难以完全捕捉语义层次结构。为了解决这一局限性，我们提出了HyperPath，一种新颖的方法，它通过将知识从文本描述中集成来引导在双曲空间中对WSI语义层次结构的建模，从而提高WSI分类。我们的方法将病理视觉-语言基础模型提取的视觉和文本特征适应到双曲空间。我们设计了一个角度模态对齐损失，以确保鲁棒的跨模态对齐，同时语义层次一致性损失通过蕴涵和矛盾关系进一步细化特征层次，从而增强语义一致性。分类通过测地距离进行，该距离衡量了双曲语义层次中实体之间的相似性。这消除了对线性分类器的需求，并允许一种对WSI分析具有几何感知的方法。广泛的实验表明，与现有方法相比，我们的方法在多个任务上实现了优越的性能，突出了双曲嵌入在WSI分析中的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Pathology is essential for cancer diagnosis, with multiple instance learning(MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a naturalhierarchy -- patches, regions, and slides -- with distinct semanticassociations. While some methods attempt to leverage this hierarchy forimproved representation, they predominantly rely on Euclidean embeddings, whichstruggle to fully capture semantic hierarchies. To address this limitation, wepropose HyperPath, a novel method that integrates knowledge from textualdescriptions to guide the modeling of semantic hierarchies of WSIs inhyperbolic space, thereby enhancing WSI classification. Our approach adaptsboth visual and textual features extracted by pathology vision-languagefoundation models to the hyperbolic space. We design an Angular ModalityAlignment Loss to ensure robust cross-modal alignment, while a SemanticHierarchy Consistency Loss further refines feature hierarchies throughentailment and contradiction relationships and thus enhance semantic coherence.The classification is performed with geodesic distance, which measures thesimilarity between entities in the hyperbolic semantic hierarchy. Thiseliminates the need for linear classifiers and enables a geometry-awareapproach to WSI analysis. Extensive experiments show that our method achievessuperior performance across tasks compared to existing methods, highlightingthe potential of hyperbolic embeddings for WSI analysis.</description>
      <author>example@mail.com (Peixiang Huang, Yanyan Huang, Weiqin Zhao, Junjun He, Lequan Yu)</author>
      <guid isPermaLink="false">2506.16398v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Quantum-Informed Contrastive Learning with Dynamic Mixup Augmentation for Class-Imbalanced Expert Systems</title>
      <link>http://arxiv.org/abs/2506.13987v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为QCL-MixNet的新颖量子信息对比学习框架，用于解决不平衡数据集的分类问题，在专家系统中检测稀有但关键实例，以提升安全性和可靠性。&lt;h4&gt;背景&lt;/h4&gt;在类不平衡的表格数据领域，传统的成本敏感学习、过采样和图神经网络等方法存在过拟合、标签噪声和泛化能力差等问题。&lt;h4&gt;目的&lt;/h4&gt;提出QCL-MixNet以解决上述问题，实现鲁棒的不平衡分类。&lt;h4&gt;方法&lt;/h4&gt;QCL-MixNet集成了三个核心创新：(i) 受量子纠缠启发的层，通过正弦变换和门控注意力建模复杂特征交互；(ii) 样本感知的mixup策略，自适应地插值语义相似实例的特征表示，增强少数类的表示；(iii) 混合损失函数，结合焦点重新加权、监督对比学习、三元组损失和方差正则化，以提高类内紧凑性和类间可分性。&lt;h4&gt;主要发现&lt;/h4&gt;在18个现实世界的不平衡数据集（二分类和多分类）上进行的实验表明，QCL-MixNet在宏观F1和召回率上始终优于20个最先进的机器学习、深度学习和GNN基线。&lt;h4&gt;结论&lt;/h4&gt;QCL-MixNet在表格不平衡处理方面为专家系统提供了一个新的基准，其表达性、泛化能力和优化鲁棒性得到了理论分析的证实。&lt;h4&gt;翻译&lt;/h4&gt;Abstract: Expert systems often operate in domains characterized by class-imbalanced tabular data, where detecting rare but critical instances is essential for safety and reliability. While conventional approaches, such as cost-sensitive learning, oversampling, and graph neural networks, provide partial solutions, they suffer from drawbacks like overfitting, label noise, and poor generalization in low-density regions. To address these challenges, we propose QCL-MixNet, a novel Quantum-Informed Contrastive Learning framework augmented with k-nearest neighbor (kNN) guided dynamic mixup for robust classification under imbalance. QCL-MixNet integrates three core innovations: (i) a Quantum Entanglement-inspired layer that models complex feature interactions through sinusoidal transformations and gated attention, (ii) a sample-aware mixup strategy that adaptively interpolates feature representations of semantically similar instances to enhance minority class representation, and (iii) a hybrid loss function that unifies focal reweighting, supervised contrastive learning, triplet margin loss, and variance regularization to improve both intra-class compactness and inter-class separability. Extensive experiments on 18 real-world imbalanced datasets (binary and multi-class) demonstrate that QCL-MixNet consistently outperforms 20 state-of-the-art machine learning, deep learning, and GNN-based baselines in macro-F1 and recall, often by substantial margins. Ablation studies further validate the critical role of each architectural component. Our results establish QCL-MixNet as a new benchmark for tabular imbalance handling in expert systems. Theoretical analyses reinforce its expressiveness, generalization, and optimization robustness.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Expert systems often operate in domains characterized by class-imbalancedtabular data, where detecting rare but critical instances is essential forsafety and reliability. While conventional approaches, such as cost-sensitivelearning, oversampling, and graph neural networks, provide partial solutions,they suffer from drawbacks like overfitting, label noise, and poorgeneralization in low-density regions. To address these challenges, we proposeQCL-MixNet, a novel Quantum-Informed Contrastive Learning framework augmentedwith k-nearest neighbor (kNN) guided dynamic mixup for robust classificationunder imbalance. QCL-MixNet integrates three core innovations: (i) a QuantumEntanglement-inspired layer that models complex feature interactions throughsinusoidal transformations and gated attention, (ii) a sample-aware mixupstrategy that adaptively interpolates feature representations of semanticallysimilar instances to enhance minority class representation, and (iii) a hybridloss function that unifies focal reweighting, supervised contrastive learning,triplet margin loss, and variance regularization to improve both intra-classcompactness and inter-class separability. Extensive experiments on 18real-world imbalanced datasets (binary and multi-class) demonstrate thatQCL-MixNet consistently outperforms 20 state-of-the-art machine learning, deeplearning, and GNN-based baselines in macro-F1 and recall, often by substantialmargins. Ablation studies further validate the critical role of eacharchitectural component. Our results establish QCL-MixNet as a new benchmarkfor tabular imbalance handling in expert systems. Theoretical analysesreinforce its expressiveness, generalization, and optimization robustness.</description>
      <author>example@mail.com (Md Abrar Jahin, Adiba Abid, M. F. Mridha)</author>
      <guid isPermaLink="false">2506.13987v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective</title>
      <link>http://arxiv.org/abs/2506.16288v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文探讨了自动回归基础模型快速适应能力的原因，并提出了应对高模糊性预测的新方法。&lt;h4&gt;背景&lt;/h4&gt;自动回归基础模型的快速适应能力通常归因于其预训练数据的多样性。然而，在高度模糊的情况下，贝叶斯最优预测的计算变得不可行。&lt;h4&gt;目的&lt;/h4&gt;提出一种方法，将预训练模型转换为蒙特卡洛预测器，以降低模糊性预测的计算需求。&lt;h4&gt;方法&lt;/h4&gt;引入了MetaHMM，一个具有丰富组合结构和可处理贝叶斯先验的合成序列元学习基准，以测试模型在高模糊性预测中的表现。&lt;h4&gt;主要发现&lt;/h4&gt;Transformer在处理高模糊性预测时存在困难。通过改进容量分配和测试时间可扩展推理，将预训练模型转换为蒙特卡洛预测器可以在模糊环境中取得显著收益。&lt;h4&gt;结论&lt;/h4&gt;模糊性不可知的前向预测可能是一个有害的归纳偏差，而将预训练模型转换为蒙特卡洛预测器可以提高处理模糊性预测的能力。&lt;h4&gt;翻译&lt;/h4&gt;本文研究了自动回归基础模型快速适应能力的原因，并提出了应对高模糊性预测的新方法。背景是自动回归基础模型的快速适应能力通常归因于其预训练数据的多样性。然而，在高度模糊的情况下，贝叶斯最优预测的计算变得不可行。目的是提出一种方法，将预训练模型转换为蒙特卡洛预测器，以降低模糊性预测的计算需求。方法引入了MetaHMM，一个具有丰富组合结构和可处理贝叶斯先验的合成序列元学习基准，以测试模型在高模糊性预测中的表现。主要发现是Transformer在处理高模糊性预测时存在困难。通过改进容量分配和测试时间可扩展推理，将预训练模型转换为蒙特卡洛预测器可以在模糊环境中取得显著收益。结论是模糊性不可知的前向预测可能是一个有害的归纳偏差，而将预训练模型转换为蒙特卡洛预测器可以提高处理模糊性预测的能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The rapid adaptation ability of auto-regressive foundation models is oftenattributed to the diversity of their pre-training data. This is because, from aBayesian standpoint, minimizing prediction error in such settings requiresintegrating over all plausible latent hypotheses consistent with observations.While this behavior is desirable in principle, it often proves too ambitious inpractice: under high ambiguity, the number of plausible latent alternativesmakes Bayes-optimal prediction computationally intractable. Cognitive sciencehas long recognized this limitation, suggesting that under such conditions,heuristics or information-seeking strategies are preferable to exhaustiveinference. Translating this insight to next-token prediction, we hypothesizethat low- and high-ambiguity predictions pose different computational demands,making ambiguity-agnostic next-token prediction a detrimental inductive bias.To test this, we introduce MetaHMM, a synthetic sequence meta-learningbenchmark with rich compositional structure and a tractable Bayesian oracle. Weshow that Transformers indeed struggle with high-ambiguity predictions acrossmodel sizes. Motivated by cognitive theories, we propose a method to convertpre-trained models into Monte Carlo predictors that decouple task inferencefrom token prediction. Preliminary results show substantial gains in ambiguouscontexts through improved capacity allocation and test-time scalable inference,though challenges remain.</description>
      <author>example@mail.com (Leo Gagnon, Eric Elmoznino, Sarthak Mittal, Tom Marty, Tejas Kasetty, Dhanya Sridhar, Guillaume Lajoie)</author>
      <guid isPermaLink="false">2506.16288v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Optimal alignment of Lorentz orientation and generalization to matrix Lie groups</title>
      <link>http://arxiv.org/abs/2506.14994v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  8 pages, 2 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了两种解决方法，以实现点云在三维空间中的对齐，并探讨了将这种方法扩展到其他矩阵李群对齐问题。&lt;h4&gt;背景&lt;/h4&gt;现有的点云对齐方法依赖于欧几里得度量的正定性质，不易扩展到Minkowski度量的不定性质。&lt;h4&gt;目的&lt;/h4&gt;针对给定的惯性参考系A和B，以及在这些参考系中测量的4-向量集{v_i}（可能存在噪声），找到最优的洛伦兹变换Λ，使得Λv_{A,i}=v_{B,i}。&lt;h4&gt;方法&lt;/h4&gt;本文提出的方法概念简单，易于扩展到其他矩阵李群的对齐问题。&lt;h4&gt;主要发现&lt;/h4&gt;本文提出的两种方法能够解决给定条件下点云对齐的问题，并展示了将这些方法扩展到其他矩阵李群的潜力。&lt;h4&gt;结论&lt;/h4&gt;本文提出的方法为点云对齐问题提供了新的解决方案，并为进一步的研究提供了基础。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了优雅的三维点云对齐方法，但这些方法依赖于欧几里得度量的正定性，难以扩展到Minkowski度量的不定性。本文针对惯性参考系A和B以及在这些参考系中测量的4-向量集{v_i}（可能存在噪声），提出了两种解决方案：寻找最优的洛伦兹变换Λ，使得Λv_{A,i}=v_{B,i}。本文提出的方法概念简单，易于扩展到其他矩阵李群的对齐问题。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; There exist elegant methods of aligning point clouds in $\mathbb R^3$.Unfortunately, these methods rely on the positive definite property of theEuclidean metric, and do not easily extend to the indefinite Minkowski metric.In this paper, we propose two solutions to the following problem: giveninertial reference frames $A$ and $B$, and given (possibly noisy) measurementsof a set of 4-vectors $\{v_i\}$ made in those reference frames with components$\{v_{A,i}\}$ and $\{v_{B,i}\}$, find the optimal Lorentz transformation$\Lambda$ such that $\Lambda v_{A,i}=v_{B,i}$. The method we outline isconceptually simple and easily extends to alignment problems in other matrixLie groups.</description>
      <author>example@mail.com (Congzhou M Sha)</author>
      <guid isPermaLink="false">2506.14994v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes</title>
      <link>http://arxiv.org/abs/2506.14317v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为ClutterDexGrasp的框架，用于在杂乱场景中进行目标导向的灵巧抓取。&lt;h4&gt;背景&lt;/h4&gt;在杂乱场景中进行灵巧抓取面临多样物体几何形状、遮挡和潜在碰撞的挑战。现有方法主要关注单物体抓取或抓取姿态预测，缺乏交互，不足以应对复杂场景。&lt;h4&gt;目的&lt;/h4&gt;为了解决这些局限性，本文重新审视了从模拟到现实的迁移流程，并开发关键技术，以实现现实中的零样本部署并保持鲁棒的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;提出了一个两阶段教师-学生框架ClutterDexGrasp，其中教师策略在模拟中使用杂乱密度课程学习进行训练，结合几何和空间嵌入的场景表示以及一个新颖的综合安全课程，实现通用、动态和安全的抓取行为。通过模仿学习，将教师的知识提炼成学生3D扩散策略（DP3），该策略在部分点云观察上运行。&lt;h4&gt;主要发现&lt;/h4&gt;这是第一个零样本从模拟到现实的杂乱场景中目标导向的灵巧抓取的闭环系统，证明了在不同物体和布局上的鲁棒性能。&lt;h4&gt;结论&lt;/h4&gt;ClutterDexGrasp框架能够有效地在杂乱场景中进行灵巧抓取，为解决复杂场景中的抓取问题提供了一种新的解决方案。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a framework named ClutterDexGrasp for dexterous grasping with target orientation in cluttered scenes.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Dexterous grasping in cluttered scenes presents significant challenges due todiverse object geometries, occlusions, and potential collisions. Existingmethods primarily focus on single-object grasping or grasp-pose predictionwithout interaction, which are insufficient for complex, cluttered scenes.Recent vision-language-action models offer a potential solution but requireextensive real-world demonstrations, making them costly and difficult to scale.To address these limitations, we revisit the sim-to-real transfer pipeline anddevelop key techniques that enable zero-shot deployment in reality whilemaintaining robust generalization. We propose ClutterDexGrasp, a two-stageteacher-student framework for closed-loop target-oriented dexterous grasping incluttered scenes. The framework features a teacher policy trained in simulationusing clutter density curriculum learning, incorporating both a geometry andspatially-embedded scene representation and a novel comprehensive safetycurriculum, enabling general, dynamic, and safe grasping behaviors. Throughimitation learning, we distill the teacher's knowledge into a student 3Ddiffusion policy (DP3) that operates on partial point cloud observations. Tothe best of our knowledge, this represents the first zero-shot sim-to-realclosed-loop system for target-oriented dexterous grasping in cluttered scenes,demonstrating robust performance across diverse objects and layouts. Moredetails and videos are available at https://clutterdexgrasp.github.io/.</description>
      <author>example@mail.com (Zeyuan Chen, Qiyang Yan, Yuanpei Chen, Tianhao Wu, Jiyao Zhang, Zihan Ding, Jinzhou Li, Yaodong Yang, Hao Dong)</author>
      <guid isPermaLink="false">2506.14317v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>On using AI for EEG-based BCI applications: problems, current challenges and future trends</title>
      <link>http://arxiv.org/abs/2506.16168v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文探讨了利用人工智能（AI）解码脑电波（EEG）信号在脑机接口（BCI）中的应用，特别是脑到语音、脑到图像和脑到物联网（BCIoT）的可能性。&lt;h4&gt;背景&lt;/h4&gt;近年来，AI在机器视觉和自然语言处理方面的突破，为解码脑电波信号提供了新的机遇。&lt;h4&gt;目的&lt;/h4&gt;论文旨在提供一个原则性的导航，探索这一快速发展的研究领域，并讨论克服当前技术、方法和伦理限制的途径。&lt;h4&gt;方法&lt;/h4&gt;论文对基于因果视角的基本范式进行了分析，并探讨了AI模型面临的挑战。&lt;h4&gt;主要发现&lt;/h4&gt;将AI应用于基于EEG的BCI，特别是在构建强大基础模型方面，存在独特且复杂的难题，可能影响其可靠性。&lt;h4&gt;结论&lt;/h4&gt;论文提出了一个清晰的路线图，旨在创建真正实用和有效的EEG-based BCI解决方案，使其能够在日常环境中茁壮成长。&lt;h4&gt;翻译&lt;/h4&gt;想象一下解锁心灵的力量来沟通、创造，甚至与世界互动。最近在人工智能（AI）方面的突破，特别是在机器如何“看到”和“理解”语言方面，正在推动解码头皮脑电图（EEG）信号方面的激动人心的进展。表面上看，这为面向现实生活的革命性脑机接口（BCI）打开了大门，使其超越传统用途，设想脑到语音、脑到图像，甚至脑到物联网（BCIoT）。然而，这条路并不像计算机视觉（CV）和自然语言处理（NLP）那样简单。将AI应用于基于EEG的BCI，特别是在构建强大基础模型方面，提出了独特且复杂的难题，可能会影响其可靠性。在这里，我们展开了对这一动态和快速发展的研究领域的指导性探索。我们不仅概述了当前的努力和成果，而是旨在提供一种原则性的导航，探索这一热门且前沿的研究领域。我们从因果视角分析出现的基本范式，并讨论了AI模型面临的挑战。展望未来，我们讨论了有可能克服今天的技术、方法和伦理限制的研究途径。我们的目标是制定一个清晰的路线图，为创建真正实用和有效的基于EEG的BCI解决方案提供指导，使其能够在日常环境中茁壮成长。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Imagine unlocking the power of the mind to communicate, create, and eveninteract with the world around us. Recent breakthroughs in ArtificialIntelligence (AI), especially in how machines "see" and "understand" language,are now fueling exciting progress in decoding brain signals from scalpelectroencephalography (EEG). Prima facie, this opens the door to revolutionarybrain-computer interfaces (BCIs) designed for real life, moving beyondtraditional uses to envision Brain-to-Speech, Brain-to-Image, and even aBrain-to-Internet of Things (BCIoT).  However, the journey is not as straightforward as it was for Computer Vision(CV) and Natural Language Processing (NLP). Applying AI to real-world EEG-basedBCIs, particularly in building powerful foundational models, presents uniqueand intricate hurdles that could affect their reliability.  Here, we unfold a guided exploration of this dynamic and rapidly evolvingresearch area. Rather than barely outlining a map of current endeavors andresults, the goal is to provide a principled navigation of this hot andcutting-edge research landscape. We consider the basic paradigms that emergefrom a causal perspective and the attendant challenges presented to AI-basedmodels. Looking ahead, we then discuss promising research avenues that couldovercome today's technological, methodological, and ethical limitations. Ouraim is to lay out a clear roadmap for creating truly practical and effectiveEEG-based BCI solutions that can thrive in everyday environments.</description>
      <author>example@mail.com (Thomas Barbera, Jacopo Burger, Alessandro D'Amelio, Simone Zini, Simone Bianco, Raffaella Lanzarotti, Paolo Napoletano, Giuseppe Boccignone, Jose Luis Contreras-Vidal)</author>
      <guid isPermaLink="false">2506.16168v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval</title>
      <link>http://arxiv.org/abs/2506.13496v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 3 figures, Accepted as a short paper at the 6th Workshop on  Patent Text Mining and Semantic Technologies (PatentSemTech 2025), co-located  with SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于Locarno国际分类（LIC）系统专利图像检索方法，通过引入分层多正对比损失，提高了检索效果。&lt;h4&gt;背景&lt;/h4&gt;专利图像检索系统在处理大量专利图像时面临挑战，因为它们包含复杂的技术细节和语义信息，且当前方法未充分利用专利的层次关系。&lt;h4&gt;目的&lt;/h4&gt;旨在提高专利图像检索的准确性。&lt;h4&gt;方法&lt;/h4&gt;提出了一种分层多正对比损失方法，利用LIC的分类体系在检索过程中诱导关系，为每个专利图像分配多个基于层次分类的相似度不同的正样本对。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法在DeepPatent2数据集上提高了检索结果，且适用于低参数模型，减少计算资源需求，适用于硬件资源有限的部署环境。&lt;h4&gt;结论&lt;/h4&gt;该方法有效提高了专利图像检索的准确性，并适用于资源受限的环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patent images are technical drawings that convey information about a patent'sinnovation. Patent image retrieval systems aim to search in vast collectionsand retrieve the most relevant images. Despite recent advances in informationretrieval, patent images still pose significant challenges due to theirtechnical intricacies and complex semantic information, requiring efficientfine-tuning for domain adaptation. Current methods neglect patents'hierarchical relationships, such as those defined by the Locarno InternationalClassification (LIC) system, which groups broad categories (e.g., "furnishing")into subclasses (e.g., "seats" and "beds") and further into specific patentdesigns. In this work, we introduce a hierarchical multi-positive contrastiveloss that leverages the LIC's taxonomy to induce such relations in theretrieval process. Our approach assigns multiple positive pairs to each patentimage within a batch, with varying similarity scores based on the hierarchicaltaxonomy. Our experimental analysis with various vision and multimodal modelson the DeepPatent2 dataset shows that the proposed method enhances theretrieval results. Notably, our method is effective with low-parameter models,which require fewer computational resources and can be deployed on environmentswith limited hardware.</description>
      <author>example@mail.com (Kshitij Kavimandan, Angelos Nalmpantis, Emma Beauxis-Aussalet, Robert-Jan Sips)</author>
      <guid isPermaLink="false">2506.13496v3</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Regression Testing Optimization for ROS-based Autonomous Systems: A Comprehensive Review of Techniques</title>
      <link>http://arxiv.org/abs/2506.16101v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文对ROS基于的自主系统（ROSAS）的回归测试优化技术进行了系统性的综述。&lt;h4&gt;背景&lt;/h4&gt;回归测试在维护软件可靠性方面至关重要，特别是对于频繁进行持续集成和迭代开发的ROSAS。然而，传统的回归测试技术在应用于自主系统时面临挑战，如动态和非确定性行为、复杂的多模态传感器数据、异步分布式架构以及严格的实时性和安全性限制。&lt;h4&gt;目的&lt;/h4&gt;为了解决这一差距，本文提出对ROSAS的回归测试优化技术进行首次全面调查。&lt;h4&gt;方法&lt;/h4&gt;分析了122项代表性研究，并将它们分为回归测试用例优先级、最小化和选择方法。引入了结构化的分类法，以明确说明它们在ROSAS环境中的应用性和局限性。&lt;h4&gt;主要发现&lt;/h4&gt;突出了ROSAS回归测试的主要挑战，包括有效响应频繁的系统修改来优先排序测试、高效最小化冗余测试以及困难地准确选择受影响的测试用例。&lt;h4&gt;结论&lt;/h4&gt;提出了研究见解，并确定了有希望的未来的研究方向，例如利用帧到向量覆盖度量、多源基础模型和神经符号推理来提高回归测试的效率和效果。本调查为推进ROSAS回归测试优化技术的最先进水平提供了基础参考和实际路线图。&lt;h4&gt;翻译&lt;/h4&gt;摘要：回归测试在保持软件可靠性方面发挥着关键作用，尤其是在ROS（机器人操作系统）为基础的自主系统（ROSAS）中，这些系统经常经历持续集成和迭代开发。然而，由于自主系统的动态和非确定性行为、复杂的多模态传感器数据、异步分布式架构以及严格的实时性和安全性约束，传统的回归测试技术在应用于自主系统时面临着重大挑战。尽管许多研究已经探索了在传统软件环境中的测试优化，但针对ROSAS的回归测试优化仍然大部分未被探索。为了解决这一差距，我们提出了对ROSAS的回归测试优化技术的首次全面调查。我们分析了122项代表性研究，并将它们分为回归测试用例优先级、最小化和选择方法。引入了结构化的分类法，以清楚地说明它们在ROSAS环境中的应用性和局限性。此外，我们突出了ROSAS回归测试的特定挑战，包括有效响应频繁的系统修改来优先排序测试、高效最小化冗余测试和困难地准确选择受影响的测试用例。最后，我们提出了研究见解并确定了有希望的未来的研究方向，如利用帧到向量覆盖度量、多源基础模型和神经符号推理来提高回归测试的效率和效果。这项调查为推进ROSAS回归测试优化技术的最先进水平提供了基础参考和实际路线图。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Regression testing plays a critical role in maintaining software reliability,particularly for ROS-based autonomous systems (ROSAS), which frequently undergocontinuous integration and iterative development. However, conventionalregression testing techniques face significant challenges when applied toautonomous systems due to their dynamic and non-deterministic behaviors,complex multi-modal sensor data, asynchronous distributed architectures, andstringent safety and real-time constraints. Although numerous studies haveexplored test optimization in traditional software contexts, regression testingoptimization specifically for ROSAS remains largely unexplored. To address thisgap, we present the first comprehensive survey systematically reviewingregression testing optimization techniques tailored for ROSAS. We analyze andcategorize 122 representative studies into regression test case prioritization,minimization, and selection methods. A structured taxonomy is introduced toclearly illustrate their applicability and limitations within ROSAS contexts.Furthermore, we highlight major challenges specific to regression testing forROSAS, including effectively prioritizing tests in response to frequent systemmodifications, efficiently minimizing redundant tests, and difficulty inaccurately selecting impacted test cases. Finally, we propose research insightsand identify promising future directions, such as leveraging frame-to-vectorcoverage metrics, multi-source foundation models, and neurosymbolic reasoningto enhance regression testing efficiency and effectiveness. This surveyprovides a foundational reference and practical roadmap for advancing thestate-of-the-art in regression testing optimization for ROSAS.</description>
      <author>example@mail.com (Yupeng Jiang, Shuaiyi Sun, Xi Zheng)</author>
      <guid isPermaLink="false">2506.16101v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training</title>
      <link>http://arxiv.org/abs/2506.16017v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by IROS 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于在稳定、准确和高效的机器人辅助内窥镜中实现单目深度估计和自我运动估计。&lt;h4&gt;背景&lt;/h4&gt;单目深度估计和自我运动估计对于场景感知和导航非常重要，但在内窥镜场景中，由于光照变化和纹理稀疏，这些任务变得更具挑战性。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的框架，以解决内窥镜场景中的光照问题和信息干扰，从而实现有效的自我监督深度估计。&lt;h4&gt;方法&lt;/h4&gt;该方法采用多步骤高效微调策略，包括光流配准、多尺度图像分解和多次变换对齐。每个步骤中，仅训练相关网络，避免无关信息的干扰。&lt;h4&gt;主要发现&lt;/h4&gt;该方法在SCARED数据集上的自我监督深度估计和Hamlyn数据集上的零样本深度估计上均取得了最先进的性能，误差降低了4%至10%。&lt;h4&gt;结论&lt;/h4&gt;该框架通过参数高效的微调，在内窥镜场景中实现了高效和准确的深度估计。&lt;h4&gt;翻译&lt;/h4&gt;Monocular depth estimation and ego-motion estimation are significant tasks for scene perception and navigation in stable, accurate and efficient robot-assisted endoscopy. To tackle lighting variations and sparse textures in endoscopic scenes, multiple techniques including optical flow, appearance flow and intrinsic image decomposition have been introduced into the existing methods. However, the effective training strategy for multiple modules are still critical to deal with both illumination issues and information interference for self-supervised depth estimation in endoscopy. Therefore, a novel framework with multistep efficient finetuning is proposed in this work. In each epoch of end-to-end training, the process is divided into three steps, including optical flow registration, multiscale image decomposition and multiple transformation alignments. At each step, only the related networks are trained without interference of irrelevant information. Based on parameter-efficient finetuning on the foundation model, the proposed method achieves state-of-the-art performance on self-supervised depth estimation on SCARED dataset and zero-shot depth estimation on Hamlyn dataset, with 4%∼10% lower error. The evaluation code of this work has been published on https://github.com/BaymaxShao/EndoMUST.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Monocular depth estimation and ego-motion estimation are significant tasksfor scene perception and navigation in stable, accurate and efficientrobot-assisted endoscopy. To tackle lighting variations and sparse textures inendoscopic scenes, multiple techniques including optical flow, appearance flowand intrinsic image decomposition have been introduced into the existingmethods. However, the effective training strategy for multiple modules arestill critical to deal with both illumination issues and informationinterference for self-supervised depth estimation in endoscopy. Therefore, anovel framework with multistep efficient finetuning is proposed in this work.In each epoch of end-to-end training, the process is divided into three steps,including optical flow registration, multiscale image decomposition andmultiple transformation alignments. At each step, only the related networks aretrained without interference of irrelevant information. Based onparameter-efficient finetuning on the foundation model, the proposed methodachieves state-of-the-art performance on self-supervised depth estimation onSCARED dataset and zero-shot depth estimation on Hamlyn dataset, with4\%$\sim$10\% lower error. The evaluation code of this work has been publishedon https://github.com/BaymaxShao/EndoMUST.</description>
      <author>example@mail.com (Liangjing Shao, Linxin Bai, Chenkang Du, Xinrong Chen)</author>
      <guid isPermaLink="false">2506.16017v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Bridging Brain with Foundation Models through Self-Supervised Learning</title>
      <link>http://arxiv.org/abs/2506.16009v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文综述了通过自监督学习将大脑信号与基础模型结合的兴起领域，探讨了关键的自监督学习技术、特定于大脑的基础模型的发展、它们在下游任务中的应用以及多模态自监督框架中大脑信号与其他模态的整合。还涵盖了常用的评估指标和基准数据集，并强调了关键挑战和未来的研究方向。&lt;h4&gt;背景&lt;/h4&gt;基础模型（FMs）通过自监督学习（SSL）展示了人工智能在自然语言处理和计算机视觉等领域的卓越性能，为大脑信号分析提供了变革性的机会。&lt;h4&gt;目的&lt;/h4&gt;旨在为研究人员提供对这一快速发展的领域的结构化理解，并为开发由自监督驱动的通用大脑基础模型提供路线图。&lt;h4&gt;方法&lt;/h4&gt;系统地回顾了通过创新应用自监督学习将大脑信号与基础模型结合的领域，包括关键的自监督学习技术、特定于大脑的基础模型的发展、它们在下游任务中的应用以及多模态自监督框架中大脑信号与其他模态的整合。&lt;h4&gt;主要发现&lt;/h4&gt;自监督学习（SSL）为解决大脑信号分析中的独特挑战（如高噪声水平、个体间差异和低信噪比）提供了一种有希望的解决方案。&lt;h4&gt;结论&lt;/h4&gt;本文强调了关键挑战并概述了未来的研究方向。&lt;h4&gt;翻译&lt;/h4&gt;This survey systematically reviews the emerging field of bridging brain signals with foundation models through the innovative application of SSL. It explores key SSL techniques, the development of brain-specific foundation models, their adaptation to downstream tasks, and the integration of brain signals with other modalities in multimodal SSL frameworks. The review also covers commonly used evaluation metrics and benchmark datasets that support comparative analysis. Finally, it highlights key challenges and outlines future research directions. This work aims to provide researchers with a structured understanding of this rapidly evolving field and a roadmap for developing generalizable brain foundation models powered by self-supervision.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Foundation models (FMs), powered by self-supervised learning (SSL), haveredefined the capabilities of artificial intelligence, demonstratingexceptional performance in domains like natural language processing andcomputer vision. These advances present a transformative opportunity for brainsignal analysis. Unlike traditional supervised learning, which is limited bythe scarcity of labeled neural data, SSL offers a promising solution byenabling models to learn meaningful representations from unlabeled data. Thisis particularly valuable in addressing the unique challenges of brain signals,including high noise levels, inter-subject variability, and low signal-to-noiseratios. This survey systematically reviews the emerging field of bridging brainsignals with foundation models through the innovative application of SSL. Itexplores key SSL techniques, the development of brain-specific foundationmodels, their adaptation to downstream tasks, and the integration of brainsignals with other modalities in multimodal SSL frameworks. The review alsocovers commonly used evaluation metrics and benchmark datasets that supportcomparative analysis. Finally, it highlights key challenges and outlines futureresearch directions. This work aims to provide researchers with a structuredunderstanding of this rapidly evolving field and a roadmap for developinggeneralizable brain foundation models powered by self-supervision.</description>
      <author>example@mail.com (Hamdi Altaheri, Fakhri Karray, Md. Milon Islam, S M Taslim Uddin Raju, Amir-Hossein Karimi)</author>
      <guid isPermaLink="false">2506.16009v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>DeSPITE: Exploring Contrastive Deep Skeleton-Pointcloud-IMU-Text Embeddings for Advanced Point Cloud Human Activity Understanding</title>
      <link>http://arxiv.org/abs/2506.13897v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  This work is currently under review at ICCV 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了利用LiDAR技术进行人类活动理解的深度学习模型，提出了一种名为DeSPITE的模型，用于学习LiDAR点云、人体骨骼姿态、IMU数据和文本之间的对应关系。&lt;h4&gt;背景&lt;/h4&gt;尽管LiDAR是一种有效的隐私保护技术，但在多模态对比预训练领域，LiDAR的应用研究相对较少。&lt;h4&gt;目的&lt;/h4&gt;填补LiDAR在多模态对比预训练领域的研究空白，探索LiDAR点云、人体骨骼姿态、IMU数据和文本之间的联合嵌入空间。&lt;h4&gt;方法&lt;/h4&gt;提出DeSPITE模型，通过结合LIPD和Babel数据集，实现四种模态数据的同步，从而学习新的联合嵌入空间。&lt;h4&gt;主要发现&lt;/h4&gt;DeSPITE模型能够有效学习LiDAR点云、人体骨骼姿态、IMU数据和文本之间的联合嵌入空间，并在人类活动理解任务中表现出色，包括骨骼与点云、IMU之间的匹配、检索以及时间关键点的检索。&lt;h4&gt;结论&lt;/h4&gt;DeSPITE是一种有效的预训练策略，适用于点云序列的人类活动识别。&lt;h4&gt;翻译&lt;/h4&gt;摘要：尽管LiDAR（光探测与测距）是一种有效的隐私保护替代方案，用于感知人类活动，但在多模态对比预训练的背景下，它仍然在很大程度上未被探索，用于人类活动理解（例如，人类活动识别（HAR）、检索或人员重识别（RE-ID））。为了填补这一空白，我们的工作探索了在联合嵌入空间中学习LiDAR点云、人体骨骼姿态、IMU数据和文本之间的对应关系。更具体地说，我们提出了DeSPITE，一个深度骨骼-点云-IMU-文本嵌入模型，它有效地学习这四种模态之间的联合嵌入空间。在我们的实证探索的核心，我们结合了现有的LIPD和Babel数据集，这使得我们能够同步所有四种模态的数据，从而探索新的联合嵌入空间的学习。我们的实验表明，通过DeSPITE实现了新的点云序列人类活动理解任务，包括骨骼&lt;-&gt;点云&lt;-&gt;IMU匹配、检索和时间关键点检索。此外，我们通过在MSR-Action3D和HMPEAR上的实验表明，DeSPITE是一种有效的点云HAR预训练策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Despite LiDAR (Light Detection and Ranging) being an effectiveprivacy-preserving alternative to RGB cameras to perceive human activities, itremains largely underexplored in the context of multi-modal contrastivepre-training for human activity understanding (e.g., human activity recognition(HAR), retrieval, or person re-identification (RE-ID)). To close this gap, ourwork explores learning the correspondence between LiDAR point clouds, humanskeleton poses, IMU data, and text in a joint embedding space. Morespecifically, we present DeSPITE, a Deep Skeleton-Pointcloud-IMU-Text Embeddingmodel, which effectively learns a joint embedding space across these fourmodalities. At the heart of our empirical exploration, we have combined theexisting LIPD and Babel datasets, which enabled us to synchronize data of allfour modalities, allowing us to explore the learning of a new joint embeddingspace. Our experiments demonstrate novel human activity understanding tasks forpoint cloud sequences enabled through DeSPITE, includingSkeleton&lt;-&gt;Pointcloud&lt;-&gt;IMU matching, retrieval, and temporal moment retrieval.Furthermore, we show that DeSPITE is an effective pre-training strategy forpoint cloud HAR through experiments in MSR-Action3D and HMPEAR.</description>
      <author>example@mail.com (Thomas Kreutz, Max Mühlhäuser, Alejandro Sanchez Guinea)</author>
      <guid isPermaLink="false">2506.13897v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>One Period to Rule Them All: Identifying Critical Learning Periods in Deep Networks</title>
      <link>http://arxiv.org/abs/2506.15954v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了深度学习中关键学习期现象，提出了一种系统方法来识别深度神经网络训练中的关键时期，以减少计算成本和提高效率。&lt;h4&gt;背景&lt;/h4&gt;现有研究表明早期时期对许多训练方法（如数据增强）的成功至关重要，但缺乏精确识别关键时期的方法。&lt;h4&gt;目的&lt;/h4&gt;填补现有文献的空白，通过引入一种系统方法来识别深度神经网络训练中的关键时期，以减少计算成本和提高学习效率。&lt;h4&gt;方法&lt;/h4&gt;该方法利用泛化预测机制来识别训练方法对模型可预测性产生最大效益的关键阶段，并通过停止资源密集型方法来加速学习过程。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，该方法可以显著减少训练时间，最高可达59.67%，从而降低CO$_2$排放和财务成本，同时不损害性能。&lt;h4&gt;结论&lt;/h4&gt;该研究增强了人们对训练动态的理解，为更可持续和高效的深度学习实践铺平了道路，尤其是在资源受限的环境中。&lt;h4&gt;翻译&lt;/h4&gt;Critical Learning Periods comprehend an important phenomenon involving deep learning, where early epochs play a decisive role in the success of many training recipes, such as data augmentation. Existing works confirm the existence of this phenomenon and provide useful insights. However, the literature lacks efforts to precisely identify when critical periods occur. In this work, we fill this gap by introducing a systematic approach for identifying critical periods during the training of deep neural networks, focusing on eliminating computationally intensive regularization techniques and effectively applying mechanisms for reducing computational costs, such as data pruning. Our method leverages generalization prediction mechanisms to pinpoint critical phases where training recipes yield maximum benefits to the predictiveability of models. By halting resource-intensive recipes beyond these periods, we significantly accelerate the learning phase and achieve reductions in training time, energy consumption, and CO$_2$ emissions. Experiments on standard architectures and benchmarks confirm the effectiveness of our method. Specifically, we achieve significant milestones by reducing the training time of popular architectures by up to 59.67%, leading to a 59.47% decrease in CO$_2$ emissions and a 60% reduction in financial costs, without compromising performance. Our work enhances understanding of training dynamics and paves the way for more sustainable and efficient deep learning practices, particularly in resource-constrained environments. In the era of the race for foundation models, we believe our method emerges as a valuable framework. The repository is available at https://github.com/baunilhamarga/critical-periods&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Critical Learning Periods comprehend an important phenomenon involving deeplearning, where early epochs play a decisive role in the success of manytraining recipes, such as data augmentation. Existing works confirm theexistence of this phenomenon and provide useful insights. However, theliterature lacks efforts to precisely identify when critical periods occur. Inthis work, we fill this gap by introducing a systematic approach foridentifying critical periods during the training of deep neural networks,focusing on eliminating computationally intensive regularization techniques andeffectively applying mechanisms for reducing computational costs, such as datapruning. Our method leverages generalization prediction mechanisms to pinpointcritical phases where training recipes yield maximum benefits to the predictiveability of models. By halting resource-intensive recipes beyond these periods,we significantly accelerate the learning phase and achieve reductions intraining time, energy consumption, and CO$_2$ emissions. Experiments onstandard architectures and benchmarks confirm the effectiveness of our method.Specifically, we achieve significant milestones by reducing the training timeof popular architectures by up to 59.67%, leading to a 59.47% decrease inCO$_2$ emissions and a 60% reduction in financial costs, without compromisingperformance. Our work enhances understanding of training dynamics and paves theway for more sustainable and efficient deep learning practices, particularly inresource-constrained environments. In the era of the race for foundationmodels, we believe our method emerges as a valuable framework. The repositoryis available at https://github.com/baunilhamarga/critical-periods</description>
      <author>example@mail.com (Vinicius Yuiti Fukase, Heitor Gama, Barbara Bueno, Lucas Libanio, Anna Helena Reali Costa, Artur Jordao)</author>
      <guid isPermaLink="false">2506.15954v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>A Qubit as a Bridge Between Statistical Mechanics and Quantum Dynamics</title>
      <link>http://arxiv.org/abs/2506.15931v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  7 pages, 3 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文从统一的角度研究了热平衡和量子动力学，以最简单的量子系统——量子比特，作为基础模型。&lt;h4&gt;背景&lt;/h4&gt;研究热平衡和量子动力学，并探索量子比特作为基础模型的意义。&lt;h4&gt;目的&lt;/h4&gt;通过研究量子比特，展示热平衡和量子动力学之间的联系。&lt;h4&gt;方法&lt;/h4&gt;使用Cauchy-Riemann方程等数学工具，对量子比特进行理论分析。&lt;h4&gt;主要发现&lt;/h4&gt;热平衡分配函数和Loschmidt振幅可以看作是沿复平面上不同路径的单个解析函数的扩展。Loschmidt振幅的零点编码了动力学特征，如正交性、率函数奇点和量子速度极限。高温比热容对应早期时间演化。&lt;h4&gt;结论&lt;/h4&gt;从单个量子比特到相互作用自旋链的讨论遵循了教学进展。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种关于热平衡和量子动力学的统一视角，通过研究最简单的量子系统——量子比特作为基础模型。我们表明，热平衡分配函数和Loschmidt振幅都可以理解为沿复平面上不同路径的单个解析函数的扩展。Loschmidt振幅的零点编码了诸如正交性、率函数奇点和量子速度极限等动力学特征，类似于分配函数零点在平衡统计力学中的作用。我们进一步通过Cauchy-Riemann方程建立，高温比热容对应早期时间演化。讨论遵循从单个量子比特到相互作用自旋链的教学进展。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-19&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; This work presents a unified perspective on thermal equilibrium and quantumdynamics by examining the simplest quantum system, a qubit, as a foundationalmodel. We show that both the thermal partition function and the Loschmidtamplitude can be understood as extensions of a single analytic function alongdifferent paths in the complex plane. The zeros of Loschmidt amplitude encodedynamical features such as orthogonality, rate function singularities, andquantum speed limits, in analogy with the role of partition function zeros inequilibrium statistical mechanics. We further establish, through theCauchy-Riemann equations, that the high-temperature specific heat correspondsto early-time evolution. The discussion follows a pedagogical progression froma single qubit to an interacting spin chain.</description>
      <author>example@mail.com (Manmeet Kaur, Somendra M. Bhattacharjee)</author>
      <guid isPermaLink="false">2506.15931v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>Descriptor-based Foundation Models for Molecular Property Prediction</title>
      <link>http://arxiv.org/abs/2506.15792v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;CheMeleon是一种新的分子基础模型，通过在Mordred包的确定性分子描述符上进行预训练，使用有向消息传递神经网络预测这些描述符，在无噪声环境下进行学习。该模型在多项基准数据集上表现出色，但在区分活性悬崖方面存在挑战。&lt;h4&gt;背景&lt;/h4&gt;快速准确地预测分子性质对科学进步至关重要，特别是基础模型在小型、真实世界数据集上的训练表现突出。&lt;h4&gt;目的&lt;/h4&gt;引入CheMeleon模型，以提高分子性质预测的准确性和效率。&lt;h4&gt;方法&lt;/h4&gt;CheMeleon利用Mordred包中的确定性分子描述符进行预训练，并采用有向消息传递神经网络来预测这些描述符。&lt;h4&gt;主要发现&lt;/h4&gt;CheMeleon在Polaris和MoleculeACE的基准数据集上表现出色，Polaris任务中胜率为79%，MoleculeACE测试中胜率为97%，但在区分活性悬崖方面存在困难。&lt;h4&gt;结论&lt;/h4&gt;CheMeleon展示了基于描述符的预训练在可扩展和有效的分子性质预测中的潜力，为探索描述符集合和无标签数据集提供了新的途径。&lt;h4&gt;翻译&lt;/h4&gt;摘要：利用机器学习快速准确地预测分子性质对于推动众多领域的科学发展至关重要。特别是基础模型在小型、真实世界数据集上的训练表现出色。本研究引入了CheMeleon，这是一种新的分子基础模型，在Mordred包的确定性分子描述符上进行预训练，利用有向消息传递神经网络在无噪声环境下预测这些描述符。与依赖于噪声实验数据或偏颇的量子力学模拟的传统方法不同，CheMeleon使用低噪声分子描述符来学习丰富的分子表示。在Polaris和MoleculeACE的58个基准数据集上评估，CheMeleon在Polaris任务中的胜率为79%，优于随机森林（46%）、fastprop（39%）和Chemprop（36%），在MoleculeACE测试中的胜率为97%，超过了随机森林（63%）和其他基础模型。然而，它像许多测试模型一样，在区分活性悬崖方面存在困难。CheMeleon学习表示的t-SNE投影展示了有效分离化学系列的能力，突显了其捕捉结构细微差别的能力。这些结果强调了基于描述符的预训练在可扩展和有效的分子性质预测中的潜力，为探索描述符集合和无标签数据集开辟了新的途径。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Fast and accurate prediction of molecular properties with machine learning ispivotal to scientific advancements across myriad domains. Foundation models inparticular have proven especially effective, enabling accurate training onsmall, real-world datasets. This study introduces CheMeleon, a novel molecularfoundation model pre-trained on deterministic molecular descriptors from theMordred package, leveraging a Directed Message-Passing Neural Network topredict these descriptors in a noise-free setting. Unlike conventionalapproaches relying on noisy experimental data or biased quantum mechanicalsimulations, CheMeleon uses low-noise molecular descriptors to learn richmolecular representations. Evaluated on 58 benchmark datasets from Polaris andMoleculeACE, CheMeleon achieves a win rate of 79% on Polaris tasks,outperforming baselines like Random Forest (46%), fastprop (39%), and Chemprop(36%), and a 97% win rate on MoleculeACE assays, surpassing Random Forest (63%)and other foundation models. However, it struggles to distinguish activitycliffs like many of the tested models. The t-SNE projection of CheMeleon'slearned representations demonstrates effective separation of chemical series,highlighting its ability to capture structural nuances. These resultsunderscore the potential of descriptor-based pre-training for scalable andeffective molecular property prediction, opening avenues for furtherexploration of descriptor sets and unlabeled datasets.</description>
      <author>example@mail.com (Jackson Burns, Akshat Zalte, William Green)</author>
      <guid isPermaLink="false">2506.15792v1</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>SynPo: Boosting Training-Free Few-Shot Medical Segmentation via High-Quality Negative Prompts</title>
      <link>http://arxiv.org/abs/2506.15153v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  MICCAI 2025 Early Accept. Project Page:  https://liu-yufei.github.io/synpo-project-page/&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;提出了一种名为SynPo的训练免费少样本医学图像分割方法，基于大型视觉模型（LVMs）并着重于改进负提示的质量。&lt;h4&gt;背景&lt;/h4&gt;大型视觉模型（LVMs）的出现为少样本医学图像分割提供了新机会，但现有的基于LVMs的训练免费方法未能有效利用负提示，导致在低对比度医学图像上的性能不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述问题，提出了SynPo方法，旨在通过改进负提示的质量来提高少样本医学图像分割的性能。&lt;h4&gt;方法&lt;/h4&gt;SynPo方法包括以下步骤：设计了一种新的置信图协同模块，结合了DINOv2和SAM的优势；基于置信图选择top-k像素作为正点集，并使用高斯分布选择负点集；对两组点进行独立的K-means聚类；然后将这些选定点作为高质量的提示输入SAM以获得分割结果。&lt;h4&gt;主要发现&lt;/h4&gt;通过实验验证，SynPo在性能上与最先进的基于训练的少样本方法相当。&lt;h4&gt;结论&lt;/h4&gt;SynPo方法通过改进负提示的质量，有效提高了基于LVMs的少样本医学图像分割的性能，达到或超过了现有方法的水平。&lt;h4&gt;翻译&lt;/h4&gt;The advent of Large Vision Models (LVMs) offers new opportunities for few-shot medical image segmentation. However, existing training-free methods based on LVMs fail to effectively utilize negative prompts, leading to poor performance on low-contrast medical images. To address this issue, we propose SynPo, a training-free few-shot method based on LVMs (e.g., SAM), with the core insight: improving the quality of negative prompts. To select point prompts in a more reliable confidence map, we design a novel Confidence Map Synergy Module by combining the strengths of DINOv2 and SAM. Based on the confidence map, we select the top-k pixels as the positive points set and choose the negative points set using a Gaussian distribution, followed by independent K-means clustering for both sets. Then, these selected points are leveraged as high-quality prompts for SAM to get the segmentation results. Extensive experiments demonstrate that SynPo achieves performance comparable to state-of-the-art training-based few-shot methods.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; The advent of Large Vision Models (LVMs) offers new opportunities forfew-shot medical image segmentation. However, existing training-free methodsbased on LVMs fail to effectively utilize negative prompts, leading to poorperformance on low-contrast medical images. To address this issue, we proposeSynPo, a training-free few-shot method based on LVMs (e.g., SAM), with the coreinsight: improving the quality of negative prompts. To select point prompts ina more reliable confidence map, we design a novel Confidence Map Synergy Moduleby combining the strengths of DINOv2 and SAM. Based on the confidence map, weselect the top-k pixels as the positive points set and choose the negativepoints set using a Gaussian distribution, followed by independent K-meansclustering for both sets. Then, these selected points are leveraged ashigh-quality prompts for SAM to get the segmentation results. Extensiveexperiments demonstrate that SynPo achieves performance comparable tostate-of-the-art training-based few-shot methods.</description>
      <author>example@mail.com (Yufei Liu, Haoke Xiao, Jiaxing Chai, Yongcun Zhang, Rong Wang, Zijie Meng, Zhiming Luo)</author>
      <guid isPermaLink="false">2506.15153v2</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins</title>
      <link>http://arxiv.org/abs/2506.10964v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;城市数字孪生被视为汇聚城市数字资源，以实现更可持续和综合的城市规划的方法。然而，模型和模拟的整合和使用过程复杂，现有方法多集中于集中式解决方案，本文提出了一种基于开放标准的平台，以实现模型集成、通信和多模型方法来表示城市系统。&lt;h4&gt;背景&lt;/h4&gt;城市数字孪生在城市规划中的作用越来越受到重视，但模型的整合和使用过程复杂。&lt;h4&gt;目的&lt;/h4&gt;通过开放平台实现城市数字孪生中模型和模拟的集成，以及支持协作和多元化的城市过程表示。&lt;h4&gt;方法&lt;/h4&gt;采用参与式设计和参与式系统方法，与德国汉堡市合作。&lt;h4&gt;主要发现&lt;/h4&gt;开放的都市模型平台可以作为城市数字孪生中模型和模拟的公共技术基础，同时也是城市过程协作和多元化表示的社会技术框架。&lt;h4&gt;结论&lt;/h4&gt;基于开放标准的平台可以促进模型的分散式集成，实现模型间的通信，并支持多模型方法来表示城市系统。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-12&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Urban digital twins are increasingly perceived as a way to pool the growingdigital resources of cities for the purpose of a more sustainable andintegrated urban planning. Models and simulations are central to thisundertaking: They enable "what if?" scenarios, create insights and describerelationships between the vast data that is being collected. However, theprocess of integrating and subsequently using models in urban digital twins isan inherently complex undertaking. It raises questions about how to representurban complexity, how to deal with uncertain assumptions and modelingparadigms, and how to capture underlying power relations. Existent approachesin the domain largely focus on monolithic and centralized solutions in thetradition of neoliberal city-making, oftentimes prohibiting pluralistic andopen interoperable models. Using a participatory design for participatorysystems approach together with the City of Hamburg, Germany, we find that anopen Urban Model Platform can function both as a public technological backbonefor modeling and simulation in urban digital twins and as a socio-technicalframework for a collaborative and pluralistic representation of urbanprocesses. Such a platform builds on open standards, allows for a decentralizedintegration of models, enables communication between models and supports amulti-model approach to representing urban systems.</description>
      <author>example@mail.com (Rico H Herzog, Till Degkwitz, Trivik Verma)</author>
      <guid isPermaLink="false">2506.10964v3</guid>
      <pubDate>Mon, 23 Jun 2025 14:26:32 +0800</pubDate>
    </item>
    <item>
      <title>MCOO-SLAM: A Multi-Camera Omnidirectional Object SLAM System</title>
      <link>http://arxiv.org/abs/2506.15402v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种名为MCOO-SLAM的新的多摄像头全向对象SLAM系统，旨在通过利用全向摄像头配置，在复杂户外环境中实现鲁棒的、一致的、语义丰富的地图构建。&lt;h4&gt;背景&lt;/h4&gt;现有SLAM方法大多依赖于RGB-D传感器或单目视角，存在视场窄、易遮挡、深度感知能力有限等问题，导致物体建模不准确和数据关联不可靠。&lt;h4&gt;目的&lt;/h4&gt;开发一个能够在复杂户外环境中进行鲁棒、一致、语义丰富的地图构建的系统。&lt;h4&gt;方法&lt;/h4&gt;MCOO-SLAM系统结合了点特征和语义增强的对象级地标，引入了语义-几何-时间融合策略以实现多视图下的鲁棒物体关联，设计了全向环路闭合模块来实现基于场景描述符的无视点变化的地点识别。此外，构建的地图被抽象成层次化的3D场景图，以支持下游推理任务。&lt;h4&gt;主要发现&lt;/h4&gt;MCOO-SLAM系统实现了准确的位置定位和可扩展的对象级映射，并且对遮挡、姿态变化和环境复杂性具有更好的鲁棒性。&lt;h4&gt;结论&lt;/h4&gt;MCOO-SLAM系统为在复杂户外环境中进行SLAM提供了一种有效的方法，具有更高的准确性和鲁棒性。&lt;h4&gt;翻译&lt;/h4&gt;Object-level SLAM provides structured and semantically meaningful environment representations, making it more interpretable and suitable for high-level robotic tasks. However, most existing approaches rely on RGB-D sensors or monocular views, which suffer from narrow fields of view, occlusion sensitivity, and limited depth perception-especially in large-scale or outdoor environments. These limitations often restrict the system to observing only partial views of objects from limited perspectives, leading to inaccurate object modeling and unreliable data association. In this work, we propose MCOO-SLAM, a novel Multi-Camera Omnidirectional Object SLAM system that fully leverages surround-view camera configurations to achieve robust, consistent, and semantically enriched mapping in complex outdoor scenarios. Our approach integrates point features and object-level landmarks enhanced with open-vocabulary semantics. A semantic-geometric-temporal fusion strategy is introduced for robust object association across multiple views, leading to improved consistency and accurate object modeling, and an omnidirectional loop closure module is designed to enable viewpoint-invariant place recognition using scene-level descriptors. Furthermore, the constructed map is abstracted into a hierarchical 3D scene graph to support downstream reasoning tasks. Extensive experiments in real-world demonstrate that MCOO-SLAM achieves accurate localization and scalable object-level mapping with improved robustness to occlusion, pose variation, and environmental complexity.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Object-level SLAM offers structured and semantically meaningful environmentrepresentations, making it more interpretable and suitable for high-levelrobotic tasks. However, most existing approaches rely on RGB-D sensors ormonocular views, which suffer from narrow fields of view, occlusionsensitivity, and limited depth perception-especially in large-scale or outdoorenvironments. These limitations often restrict the system to observing onlypartial views of objects from limited perspectives, leading to inaccurateobject modeling and unreliable data association. In this work, we proposeMCOO-SLAM, a novel Multi-Camera Omnidirectional Object SLAM system that fullyleverages surround-view camera configurations to achieve robust, consistent,and semantically enriched mapping in complex outdoor scenarios. Our approachintegrates point features and object-level landmarks enhanced withopen-vocabulary semantics. A semantic-geometric-temporal fusion strategy isintroduced for robust object association across multiple views, leading toimproved consistency and accurate object modeling, and an omnidirectional loopclosure module is designed to enable viewpoint-invariant place recognitionusing scene-level descriptors. Furthermore, the constructed map is abstractedinto a hierarchical 3D scene graph to support downstream reasoning tasks.Extensive experiments in real-world demonstrate that MCOO-SLAM achievesaccurate localization and scalable object-level mapping with improvedrobustness to occlusion, pose variation, and environmental complexity.</description>
      <author>example@mail.com (Miaoxin Pan, Jinnan Li, Yaowen Zhang, Yi Yang, Yufeng Yue)</author>
      <guid isPermaLink="false">2506.15402v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
  <item>
      <title>Learning Task-Agnostic Skill Bases to Uncover Motor Primitives in Animal Behaviors</title>
      <link>http://arxiv.org/abs/2506.15190v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  9 pages and 4 figures for the main text&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于技能的模仿学习（SKIL）方法，用于理解动物行为，并通过在简单网格世界、离散迷宫和自由移动动物的未约束视频中验证，证明了该方法能够识别可重用技能组件，学习不断演变的组合策略，并生成超越传统离散模型的现实轨迹。&lt;h4&gt;背景&lt;/h4&gt;现有的行为分段方法通过强加离散音节和限制性生成假设来简化动物行为的重组过程。&lt;h4&gt;目的&lt;/h4&gt;为了反映动物行为生成过程，提出SKIL方法以理解动物行为。&lt;h4&gt;方法&lt;/h4&gt;SKIL方法通过以下方式工作：(1) 利用表示学习在过渡概率上推断可解释的技能集，即行为的潜在基函数；(2) 将策略参数化为这些技能的动态混合。&lt;h4&gt;主要发现&lt;/h4&gt;在多个任务中，该方法识别了可重用技能组件，学习了不断演变的组合策略，并生成了超越传统离散模型的现实轨迹。&lt;h4&gt;结论&lt;/h4&gt;通过利用组合表示的生成行为建模，该方法提供了一个简洁、原则性的解释，说明了复杂动物行为是如何从基本运动原型的动态组合中产生的。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Animals flexibly recombine a finite set of core motor primitives to meetdiverse task demands, but existing behavior-segmentation methods oversimplifythis process by imposing discrete syllables under restrictive generativeassumptions. To reflect the animal behavior generation procedure, we introduceskill-based imitation learning (SKIL) for behavior understanding, areinforcement learning-based imitation framework that (1) infers interpretableskill sets, i.e., latent basis functions of behavior, by leveragingrepresentation learning on transition probabilities, and (2) parameterizespolicies as dynamic mixtures of these skills. We validate our approach on asimple grid world, a discrete labyrinth, and unconstrained videos of freelymoving animals. Across tasks, it identifies reusable skill components, learnscontinuously evolving compositional policies, and generates realistictrajectories beyond the capabilities of traditional discrete models. Byexploiting generative behavior modeling with compositional representations, ourmethod offers a concise, principled account of how complex animal behaviorsemerge from dynamic combinations of fundamental motor primitives.</description>
      <author>example@mail.com (Jiyi Wang, Jingyang Ke, Bo Dai, Anqi Wu)</author>
      <guid isPermaLink="false">2506.15190v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Transit for All: Mapping Equitable Bike2Subway Connection using Region Representation Learning</title>
      <link>http://arxiv.org/abs/2506.15113v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;论文提出了一个名为Transit for All (TFA)的框架，旨在指导公交自行车共享系统（BSS）的公平扩展，以解决密集城市如纽约市中低收入和少数族裔社区面临的公交可及性问题。&lt;h4&gt;背景&lt;/h4&gt;在纽约市等人口密集的城市，低收入和少数族裔社区往往面临公交可及性受限的问题。自行车共享系统可以填补这些公平差距，但将BSS扩展到未服务社区困难重重，因为新的自行车共享站点位置的需求不确定，且传统可及性指标可能忽略了实际的自行车使用潜力。&lt;h4&gt;目的&lt;/h4&gt;开发TFA框架，通过预测需求、综合评估可及性和提供战略建议，以促进BSS的公平扩展。&lt;h4&gt;方法&lt;/h4&gt;TFA框架包括三个组件：(1)利用区域表示学习集成多模式地理空间数据，在冷启动站点进行空间感知的自行车共享需求预测；(2)结合预测的自行车共享需求和传统的公交可及性指标，进行全面的公交可及性评估；(3)考虑潜在乘客量和公平性提升的战略性新自行车站点布局建议。&lt;h4&gt;主要发现&lt;/h4&gt;以纽约市为案例研究，TFA识别了历史上未服务的社区中低收入和少数族裔社区受到不成比例影响的公交可及性差距。结果表明，根据加权公交可及性水平（wPTAL）战略性地放置新站点可以显著减少与经济和人口统计因素相关的公交可及性差异。&lt;h4&gt;结论&lt;/h4&gt;TFA为城市规划者提供了实际指导，以促进公平的公交服务，并提升未服务城市社区的居住质量。&lt;h4&gt;翻译&lt;/h4&gt;确保公平的公交可及性仍然是一个挑战，特别是在像纽约市这样人口密集的城市，低收入和少数族裔社区往往面临公交可及性有限的问题。自行车共享系统（BSS）可以通过提供经济的第一和最后一英里连接来弥合这些公平差距。然而，由于新规划的（冷启动）站点的不确定的自行车共享需求以及传统可及性指标可能忽视的现实自行车使用潜力，将BSS战略性地扩展到未服务的社区是困难的。我们引入了Transit for All（TFA），一个旨在通过三个组件指导BSS公平扩展的空间计算框架：(1)利用区域表示学习集成多模式地理空间数据，在冷启动站点进行空间感知的自行车共享需求预测；(2)结合预测的自行车共享需求和传统的公交可及性指标，进行全面的公交可及性评估；(3)考虑潜在乘客量和公平性提升的战略性新自行车站点布局建议。以纽约市为案例研究，我们确定了历史上未服务的社区中低收入和少数族裔社区受到不成比例影响的公交可及性差距。我们的结果表明，根据加权公交可及性水平（wPTAL）战略性地放置新站点可以显著减少与经济和人口统计因素相关的公交可及性差异。从我们的研究中，我们证明了TFA为城市规划者提供了实际指导，以促进公平的公交服务，并提升未服务城市社区的居住质量。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Ensuring equitable public transit access remains challenging, particularly indensely populated cities like New York City (NYC), where low-income andminority communities often face limited transit accessibility. Bike-sharingsystems (BSS) can bridge these equity gaps by providing affordable first- andlast-mile connections. However, strategically expanding BSS into underservedneighborhoods is difficult due to uncertain bike-sharing demand at newlyplanned ("cold-start") station locations and limitations in traditionalaccessibility metrics that may overlook realistic bike usage potential. Weintroduce Transit for All (TFA), a spatial computing framework designed toguide the equitable expansion of BSS through three components: (1)spatially-informed bike-sharing demand prediction at cold-start stations usingregion representation learning that integrates multimodal geospatial data, (2)comprehensive transit accessibility assessment leveraging our novel weightedPublic Transport Accessibility Level (wPTAL) by combining predictedbike-sharing demand with conventional transit accessibility metrics, and (3)strategic recommendations for new bike station placements that considerpotential ridership and equity enhancement. Using NYC as a case study, weidentify transit accessibility gaps that disproportionately impact low-incomeand minority communities in historically underserved neighborhoods. Our resultsshow that strategically placing new stations guided by wPTAL notably reducesdisparities in transit access related to economic and demographic factors. Fromour study, we demonstrate that TFA provides practical guidance for urbanplanners to promote equitable transit and enhance the quality of life inunderserved urban communities.</description>
      <author>example@mail.com (Min Namgung, JangHyeon Lee, Fangyi Ding, Yao-Yi Chiang)</author>
      <guid isPermaLink="false">2506.15113v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>MonoVQD: Monocular 3D Object Detection with Variational Query Denoising and Self-Distillation</title>
      <link>http://arxiv.org/abs/2506.14835v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;MonoVQD是一种新的框架，旨在提高基于DETR的单目3D检测的性能，通过引入多种机制来解决现有方法的局限性。&lt;h4&gt;背景&lt;/h4&gt;单目3D检测是计算机视觉中的一个关键挑战，而DETR-like架构在直接应用于此领域时存在固有局限性。&lt;h4&gt;目的&lt;/h4&gt;提出MonoVQD框架，以解决单目3D检测中的挑战，并提高检测性能。&lt;h4&gt;方法&lt;/h4&gt;1. 提出Mask Separated Self-Attention机制，将去噪过程集成到DETR架构中，提高匈牙利匹配的稳定性。2. 提出变分查询去噪技术，解决传统去噪方法的梯度消失问题，引入随机性以减轻基本限制并实现性能提升。3. 引入复杂的自蒸馏策略，利用后期解码层的见解来协同提高早期层的查询质量，增强迭代优化过程。&lt;h4&gt;主要发现&lt;/h4&gt;MonoVQD在KITTI单目基准测试上实现了优越的性能，其核心组件能够无缝集成到其他架构中，在nuScenes数据集上的多视图3D检测场景中也表现出显著的性能提升。&lt;h4&gt;结论&lt;/h4&gt;MonoVQD通过多种创新技术显著提高了单目3D检测的性能，并展现了其广泛的应用性和鲁棒的一般化能力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-14&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Precisely localizing 3D objects from a single image constitutes a centralchallenge in monocular 3D detection. While DETR-like architectures offer apowerful paradigm, their direct application in this domain encounters inherentlimitations, preventing optimal performance. Our work addresses thesechallenges by introducing MonoVQD, a novel framework designed to fundamentallyadvance DETR-based monocular 3D detection. We propose three main contributions.First, we propose the Mask Separated Self-Attention mechanism that enables theintegration of the denoising process into a DETR architecture. This improvesthe stability of Hungarian matching to achieve a consistent optimizationobjective. Second, we present the Variational Query Denoising technique toaddress the gradient vanishing problem of conventional denoising methods, whichseverely restricts the efficiency of the denoising process. This explicitlyintroduces stochastic properties to mitigate this fundamental limitation andunlock substantial performance gains. Finally, we introduce a sophisticatedself-distillation strategy, leveraging insights from later decoder layers tosynergistically improve query quality in earlier layers, thereby amplifying theiterative refinement process. Rigorous experimentation demonstrates thatMonoVQD achieves superior performance on the challenging KITTI monocularbenchmark. Highlighting its broad applicability, MonoVQD's core componentsseamlessly integrate into other architectures, delivering significantperformance gains even in multi-view 3D detection scenarios on the nuScenesdataset and underscoring its robust generalization capabilities.</description>
      <author>example@mail.com (Kiet Dang Vu, Trung Thai Tran, Duc Dung Nguyen)</author>
      <guid isPermaLink="false">2506.14835v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Neural Canonical Polyadic Factorization for Traffic Analysis</title>
      <link>http://arxiv.org/abs/2506.15079v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为NCPF的模型，用于解决交通数据中因传感器故障和异构感知差距导致的缺失数据问题，以优化城市移动性和基础设施的弹性。&lt;h4&gt;背景&lt;/h4&gt;现代智能交通系统依赖于准确的时空交通分析来优化城市移动性和基础设施的弹性，但传感器故障和异构感知差距导致的缺失数据严重阻碍了可靠的交通建模。&lt;h4&gt;目的&lt;/h4&gt;提出一种NCPF模型，结合低秩张量代数和深度表示学习，实现鲁棒的交通数据插补。&lt;h4&gt;方法&lt;/h4&gt;NCPF模型将CP分解嵌入到神经网络架构中，通过可学习的嵌入投影将稀疏的交通张量编码到密集的潜在因子中，覆盖道路段、时间段和移动性指标。采用层次特征融合机制，使用Hadamard积显式建模多线性交互，并通过多层感知器层非线性地细化这些表示以捕获复杂的时空耦合。&lt;h4&gt;主要发现&lt;/h4&gt;在六个城市交通数据集上的广泛评估表明，NCPF优于六个最先进的基线。&lt;h4&gt;结论&lt;/h4&gt;NCPF通过统一CP分解的可解释因子分析与神经网络的非线性表达能力，为高维交通数据插补提供了一种原则性且灵活的方法，为下一代交通数字孪生和自适应交通控制系统提供了关键支持。&lt;h4&gt;翻译&lt;/h4&gt;摘要：现代智能交通系统依赖于准确的时空交通分析来优化城市移动性和基础设施的弹性。然而，由传感器故障和异构感知差距导致的普遍缺失数据根本阻碍了可靠的交通建模。本文提出了一种名为NCPF的模型，它将低秩张量代数与深度表示学习相结合，以实现鲁棒的交通数据插补。该模型创新地将CP分解嵌入到神经网络架构中，通过可学习的嵌入投影，将稀疏的交通张量编码到跨越道路段、时间段和移动性指标的密集潜在因子中。一种层次特征融合机制采用Hadamard积来显式地建模多线性交互，而堆叠的多层感知器层则非线性地细化这些表示以捕获复杂的时空耦合。在六个城市交通数据集上的广泛评估表明，NCPF优于六个最先进的基线。通过统一CP分解的可解释因子分析与神经网络的非线性表达能力，NCPF为高维交通数据插补提供了一种原则性且灵活的方法，为下一代交通数字孪生和自适应交通控制系统提供了关键支持。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Modern intelligent transportation systems rely on accurate spatiotemporaltraffic analysis to optimize urban mobility and infrastructure resilience.However, pervasive missing data caused by sensor failures and heterogeneoussensing gaps fundamentally hinders reliable traffic modeling. This paperproposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizeslow-rank tensor algebra with deep representation learning for robust trafficdata imputation. The model innovatively embeds CP decomposition into neuralarchitecture through learnable embedding projections, where sparse traffictensors are encoded into dense latent factors across road segments, timeintervals, and mobility metrics. A hierarchical feature fusion mechanismemploys Hadamard products to explicitly model multilinear interactions, whilestacked multilayer perceptron layers nonlinearly refine these representationsto capture complex spatiotemporal couplings. Extensive evaluations on six urbantraffic datasets demonstrate NCPF's superiority over six state-of-the-artbaselines. By unifying CP decomposition's interpretable factor analysis withneural network's nonlinear expressive power, NCPF provides a principled yetflexible approaches for high-dimensional traffic data imputation, offeringcritical support for next-generation transportation digital twins and adaptivetraffic control systems.</description>
      <author>example@mail.com (Yikai Hou, Peng Tang)</author>
      <guid isPermaLink="false">2506.15079v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Understanding multi-fidelity training of machine-learned force-fields</title>
      <link>http://arxiv.org/abs/2506.14963v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文研究了两种多保真度训练策略（预训练/微调和多头训练）以阐明其成功机制，并提出了构建适用于广泛化学系统的机器学习力场（MLFFs）的方法。&lt;h4&gt;背景&lt;/h4&gt;有效利用多种量子化学方法的数据对于构建适用于广泛化学系统的机器学习力场（MLFFs）至关重要。&lt;h4&gt;目的&lt;/h4&gt;系统研究预训练/微调和多头训练两种多保真度训练策略，以阐明其成功机制。&lt;h4&gt;方法&lt;/h4&gt;研究了预训练/微调和多头训练两种策略，并分析了预训练阶段学习到的内部表示。&lt;h4&gt;主要发现&lt;/h4&gt;发现预训练/微调策略的关键因素，指出预训练阶段学习到的内部表示具有方法特定性，需要模型骨架在微调阶段进行适应；多头模型提供了可扩展的替代方案，能够同时进行多保真度训练；多头模型学习到的方法无关表示允许对多个标签源进行准确预测。&lt;h4&gt;结论&lt;/h4&gt;虽然多头训练相对于顺序微调引入了轻微的精度妥协，但它解锁了新的成本效益数据生成策略，为开发通用的MLFFs铺平了道路。&lt;h4&gt;翻译&lt;/h4&gt;Effectively leveraging data from multiple quantum-chemical methods is essential for building machine-learned force fields (MLFFs) that are applicable to a wide range of chemical systems. This study systematically investigates two multi-fidelity training strategies, pre-training/fine-tuning and multi-headed training, to elucidate the mechanisms underpinning their success. We identify key factors driving the efficacy of pre-training followed by fine-tuning, but find that internal representations learned during pre-training are inherently method-specific, requiring adaptation of the model backbone during fine-tuning. Multi-headed models offer an extensible alternative, enabling simultaneous training on multiple fidelities. We demonstrate that a multi-headed model learns method-agnostic representations that allow for accurate predictions across multiple label sources. While this approach introduces a slight accuracy compromise compared to sequential fine-tuning, it unlocks new cost-efficient data generation strategies and paves the way towards developing universal MLFFs.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Effectively leveraging data from multiple quantum-chemical methods isessential for building machine-learned force fields (MLFFs) that are applicableto a wide range of chemical systems. This study systematically investigates twomulti-fidelity training strategies, pre-training/fine-tuning and multi-headedtraining, to elucidate the mechanisms underpinning their success. We identifykey factors driving the efficacy of pre-training followed by fine-tuning, butfind that internal representations learned during pre-training are inherentlymethod-specific, requiring adaptation of the model backbone during fine-tuning.Multi-headed models offer an extensible alternative, enabling simultaneoustraining on multiple fidelities. We demonstrate that a multi-headed modellearns method-agnostic representations that allow for accurate predictionsacross multiple label sources. While this approach introduces a slight accuracycompromise compared to sequential fine-tuning, it unlocks new cost-efficientdata generation strategies and paves the way towards developing universalMLFFs.</description>
      <author>example@mail.com (John L. A. Gardner, Hannes Schulz, Jean Helie, Lixin Sun, Gregor N. C. Simm)</author>
      <guid isPermaLink="false">2506.14963v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models</title>
      <link>http://arxiv.org/abs/2506.09042v3</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Only the core contributors are listed. The full list of contributors  can be found in Appendix A of this paper&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为Cosmos-Drive-Dreams的合成数据生成（SDG）流程，用于生成具有挑战性的场景，以促进自动驾驶车辆（AV）系统的感知和驾驶策略训练。该流程使用Cosmos-Drive模型生成高质量、多视角、时空一致的驾驶视频。&lt;h4&gt;背景&lt;/h4&gt;收集和标注现实世界数据对于自动驾驶等安全关键物理AI系统来说既耗时又昂贵，尤其是捕捉罕见边缘案例，这些案例在AV系统的训练和测试中起着关键作用。&lt;h4&gt;目的&lt;/h4&gt;为了解决上述挑战，目的是通过合成数据生成流程提高自动驾驶数据集的数量和多样性，同时保持高保真和挑战性。&lt;h4&gt;方法&lt;/h4&gt;Cosmos-Drive-Dreams利用Cosmos-Drive模型，该模型是从NVIDIA Cosmos世界基础模型专门针对驾驶领域设计的，能够生成可控、高保真、多视角和时空一致的驾驶视频。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，生成的数据有助于减轻长尾分布问题，并增强了下游任务（如3D车道检测、3D物体检测和驾驶策略学习）的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;Cosmos-Drive-Dreams工具包、数据集和模型权重已通过NVIDIA的Cosmos平台开源。&lt;h4&gt;翻译&lt;/h4&gt;Collecting and annotating real-world data for safety-critical physical AI systems, such as Autonomous Vehicle (AV), is time-consuming and costly. It is especially challenging to capture rare edge cases, which play a critical role in training and testing of an AV system. To address this challenge, we introduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipeline that aims to generate challenging scenarios to facilitate downstream tasks such as perception and driving policy training. Powering this pipeline is Cosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundation model for the driving domain and are capable of controllable, high-fidelity, multi-view, and spatiotemporally consistent driving video generation. We showcase the utility of these models by applying Cosmos-Drive-Dreams to scale the quantity and diversity of driving datasets with high-fidelity and challenging scenarios. Experimentally, we demonstrate that our generated data helps in mitigating long-tail distribution problems and enhances generalization in downstream tasks such as 3D lane detection, 3D object detection and driving policy learning. We open source our pipeline toolkit, dataset and model weights through the NVIDIA's Cosmos platform. Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-10&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;https://github.com/nv-tlabs/cosmos-drive-dreams&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Collecting and annotating real-world data for safety-critical physical AIsystems, such as Autonomous Vehicle (AV), is time-consuming and costly. It isespecially challenging to capture rare edge cases, which play a critical rolein training and testing of an AV system. To address this challenge, weintroduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipelinethat aims to generate challenging scenarios to facilitate downstream tasks suchas perception and driving policy training. Powering this pipeline isCosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundationmodel for the driving domain and are capable of controllable, high-fidelity,multi-view, and spatiotemporally consistent driving video generation. Weshowcase the utility of these models by applying Cosmos-Drive-Dreams to scalethe quantity and diversity of driving datasets with high-fidelity andchallenging scenarios. Experimentally, we demonstrate that our generated datahelps in mitigating long-tail distribution problems and enhances generalizationin downstream tasks such as 3D lane detection, 3D object detection and drivingpolicy learning. We open source our pipeline toolkit, dataset and model weightsthrough the NVIDIA's Cosmos platform.  Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams</description>
      <author>example@mail.com (Xuanchi Ren, Yifan Lu, Tianshi Cao, Ruiyuan Gao, Shengyu Huang, Amirmojtaba Sabour, Tianchang Shen, Tobias Pfaff, Jay Zhangjie Wu, Runjian Chen, Seung Wook Kim, Jun Gao, Laura Leal-Taixe, Mike Chen, Sanja Fidler, Huan Ling)</author>
      <guid isPermaLink="false">2506.09042v3</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>DisProtEdit: Exploring Disentangled Representations for Multi-Attribute Protein Editing</title>
      <link>http://arxiv.org/abs/2506.14853v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted to ICMLW (GenBio) 2025 and ICMLW (FM4LS) 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;介绍了DisProtEdit，一个可控的蛋白质编辑框架，利用双通道自然语言监督学习结构和功能的解耦表示。&lt;h4&gt;背景&lt;/h4&gt;与依赖于联合整体嵌入的前人方法不同，DisProtEdit明确分离语义因素，实现模块化和可解释的控制。&lt;h4&gt;目的&lt;/h4&gt;构建一个可控的蛋白质编辑框架，提供对蛋白质结构和功能的模块化和可解释的控制。&lt;h4&gt;方法&lt;/h4&gt;构建了SwissProtDis，一个大规模的多模态数据集，其中每个蛋白质序列都配对两个文本描述，一个用于结构，一个用于功能。DisProtEdit通过对齐和一致性目标对齐蛋白质和文本嵌入，同时通过解耦损失促进结构和功能语义的独立性。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，DisProtEdit在蛋白质编辑和表示学习基准测试中与现有方法具有竞争力，同时提供了改进的可解释性和可控性。在新的多属性编辑基准测试中，模型实现了高达61.7%的双击成功率，突出了其在协调同时结构和功能编辑方面的有效性。&lt;h4&gt;结论&lt;/h4&gt;DisProtEdit是一个有效的蛋白质编辑框架，能够同时控制和解释蛋白质的结构和功能编辑。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; We introduce DisProtEdit, a controllable protein editing framework thatleverages dual-channel natural language supervision to learn disentangledrepresentations of structural and functional properties. Unlike priorapproaches that rely on joint holistic embeddings, DisProtEdit explicitlyseparates semantic factors, enabling modular and interpretable control. Tosupport this, we construct SwissProtDis, a large-scale multimodal dataset whereeach protein sequence is paired with two textual descriptions, one forstructure and one for function, automatically decomposed using a large languagemodel. DisProtEdit aligns protein and text embeddings using alignment anduniformity objectives, while a disentanglement loss promotes independencebetween structural and functional semantics. At inference time, protein editingis performed by modifying one or both text inputs and decoding from the updatedlatent representation. Experiments on protein editing and representationlearning benchmarks demonstrate that DisProtEdit performs competitively withexisting methods while providing improved interpretability and controllability.On a newly constructed multi-attribute editing benchmark, the model achieves aboth-hit success rate of up to 61.7%, highlighting its effectiveness incoordinating simultaneous structural and functional edits.</description>
      <author>example@mail.com (Max Ku, Sun Sun, Hongyu Guo, Wenhu Chen)</author>
      <guid isPermaLink="false">2506.14853v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Interpretable representation learning of quantum data enabled by probabilistic variational autoencoders</title>
      <link>http://arxiv.org/abs/2506.11982v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Main text 10 pages, total document 16 pages, 10 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;可解释机器学习正在迅速成为科学发现的关键工具，变分自动编码器（VAEs）在提取输入数据的隐藏物理特征方面显示出潜力，但需要考虑量子数据的随机性和复杂相关性。&lt;h4&gt;背景&lt;/h4&gt;VAEs在无监督和没有系统先验知识的情况下提取输入数据的隐藏物理特征，但在处理量子数据时，需要考虑其概率性质。&lt;h4&gt;目的&lt;/h4&gt;改进VAEs以学习物理上有意义的潜在表示。&lt;h4&gt;方法&lt;/h4&gt;通过引入能够忠实复制量子状态的解码器和针对此任务的概率损失，对VAEs进行关键修改。&lt;h4&gt;主要发现&lt;/h4&gt;在标准方法失效的情况下，这种方法学习的表示仍然是有意义和可解释的，并在实验数据中自主揭示相结构。&lt;h4&gt;结论&lt;/h4&gt;这种改进的VAEs是一个无监督和可解释的工具，可以用于研究量子系统。&lt;h4&gt;翻译&lt;/h4&gt;可解释机器学习正在迅速成为科学发现的关键工具。在现有的方法中，变分自动编码器（VAEs）在提取某些输入数据的隐藏物理特征方面显示出前景，无需监督和系统研究的先验知识。然而，VAEs创建有意义的可解释表示的能力依赖于它们对输入潜在概率分布的准确近似。当处理量子数据时，VAEs必须因此考虑到其固有的随机性和复杂相关性。虽然VAEs以前已经应用于量子数据，但它们通常忽略了其概率性质，阻碍了有意义的物理描述符的提取。在这里，我们证明了两个关键修改使得VAEs能够学习物理上有意义的潜在表示：一个能够忠实复制量子状态的解码器以及一个针对此任务的概率损失。使用基准量子自旋模型，我们确定了标准方法失败而我们的方法学习的表示仍然有意义和可解释的领域。应用于里德堡原子阵列的实验数据，该模型在无需访问先验标签、哈密顿细节或有关相关序参数知识的情况下自主揭示相结构，突出了其作为无监督和可解释工具研究量子系统的潜力。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-13&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Interpretable machine learning is rapidly becoming a crucial tool forscientific discovery. Among existing approaches, variational autoencoders(VAEs) have shown promise in extracting the hidden physical features of someinput data, with no supervision nor prior knowledge of the system at study.Yet, the ability of VAEs to create meaningful, interpretable representationsrelies on their accurate approximation of the underlying probabilitydistribution of their input. When dealing with quantum data, VAEs must henceaccount for its intrinsic randomness and complex correlations. While VAEs havebeen previously applied to quantum data, they have often neglected itsprobabilistic nature, hindering the extraction of meaningful physicaldescriptors. Here, we demonstrate that two key modifications enable VAEs tolearn physically meaningful latent representations: a decoder capable offaithfully reproduce quantum states and a probabilistic loss tailored to thistask. Using benchmark quantum spin models, we identify regimes where standardmethods fail while the representations learned by our approach remainmeaningful and interpretable. Applied to experimental data from Rydberg atomarrays, the model autonomously uncovers the phase structure without access toprior labels, Hamiltonian details, or knowledge of relevant order parameters,highlighting its potential as an unsupervised and interpretable tool for thestudy of quantum systems.</description>
      <author>example@mail.com (Paulin de Schoulepnikoff, Gorka Muñoz-Gil, Hendrik Poulsen Nautrup, Hans J. Briegel)</author>
      <guid isPermaLink="false">2506.11982v2</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Next-Generation Conflict Forecasting: Unleashing Predictive Patterns through Spatiotemporal Learning</title>
      <link>http://arxiv.org/abs/2506.14817v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  33 pages, 9 figures, 3 tables. Presented at workshops hosted by PRIO,  AFK (German Association for Peace and Conflict Studies), CCEW (Bundeswehr  University Munich), Uppsala University, SODAS (University of Copenhagen) and  in briefings with UN agencies including UNIDIR, OCHA, and FAO&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新型神经网络架构，用于预测不同类型的暴力事件，包括基于国家的、非国家的和单方面的暴力，并在次国家（优先网格-月）层面上，提前36个月进行预测。&lt;h4&gt;背景&lt;/h4&gt;预测高空间和时间分辨率的暴力冲突对研究人员和政策制定者来说是一个核心挑战。&lt;h4&gt;目的&lt;/h4&gt;开发一种能够预测不同类型暴力事件的新方法。&lt;h4&gt;方法&lt;/h4&gt;该模型基于蒙特卡洛Dropout长短期记忆（LSTM）U-Net架构，结合卷积层来捕捉空间依赖性，以及循环结构来模拟时间动态。模型不需要手动特征工程，仅依赖于历史冲突数据。&lt;h4&gt;主要发现&lt;/h4&gt;该模型在所有任务中都达到了最先进的性能，并生成近似预测后验分布来量化预测不确定性。&lt;h4&gt;结论&lt;/h4&gt;该模型不仅预测性能卓越，而且具有高度的可扩展性，可以轻松集成额外的数据源，并联合预测辅助变量。这使得它成为早期预警系统、人道主义响应规划和基于证据的和平建设倡议的有前途的工具。&lt;h4&gt;翻译&lt;/h4&gt;摘要：在高空间和时间分辨率上预测暴力冲突仍然是研究人员和政策制定者面临的核心挑战。本研究提出了一种新型神经网络架构，用于预测三种不同类型的暴力——基于国家的、非国家的和单方面的暴力——在次国家（优先网格-月）层面上，提前36个月进行预测。该模型同时执行分类和回归任务，产生未来事件的概率估计和预期幅度。它在所有任务中都实现了最先进的性能，并生成近似预测后验分布来量化预测不确定性。该架构基于蒙特卡洛Dropout长短期记忆（LSTM）U-Net，结合卷积层来捕捉空间依赖性，以及循环结构来模拟时间动态。与许多现有方法不同，它不需要手动特征工程，完全依赖于历史冲突数据。这种设计使模型能够自主学习暴力冲突背后的复杂时空模式。除了实现最先进的预测性能外，该模型还具有高度的可扩展性：它可以轻松集成额外的数据源，并联合预测辅助变量。这些能力使其成为早期预警系统、人道主义响应规划和基于证据的和平建设倡议的有前途的工具。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-08&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Forecasting violent conflict at high spatial and temporal resolution remainsa central challenge for both researchers and policymakers. This study presentsa novel neural network architecture for forecasting three distinct types ofviolence -- state-based, non-state, and one-sided -- at the subnational(priogrid-month) level, up to 36 months in advance. The model jointly performsclassification and regression tasks, producing both probabilistic estimates andexpected magnitudes of future events. It achieves state-of-the-art performanceacross all tasks and generates approximate predictive posterior distributionsto quantify forecast uncertainty.  The architecture is built on a Monte Carlo Dropout Long Short-Term Memory(LSTM) U-Net, integrating convolutional layers to capture spatial dependencieswith recurrent structures to model temporal dynamics. Unlike many existingapproaches, it requires no manual feature engineering and relies solely onhistorical conflict data. This design enables the model to autonomously learncomplex spatiotemporal patterns underlying violent conflict.  Beyond achieving state-of-the-art predictive performance, the model is alsohighly extensible: it can readily integrate additional data sources and jointlyforecast auxiliary variables. These capabilities make it a promising tool forearly warning systems, humanitarian response planning, and evidence-basedpeacebuilding initiatives.</description>
      <author>example@mail.com (Simon P. von der Maase)</author>
      <guid isPermaLink="false">2506.14817v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Extending Spike-Timing Dependent Plasticity to Learning Synaptic Delays</title>
      <link>http://arxiv.org/abs/2506.14984v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Repository containing the source code used to generate the results is  available at: https://github.com/mdominijanni/dsstdp-results&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了一种新的学习方法，旨在同时学习突触连接强度和延迟，通过扩展尖峰时间依赖性可塑性（STDP）方法，并与现有方法进行了比较，结果显示该方法在各种测试场景中均表现出优异的性能。&lt;h4&gt;背景&lt;/h4&gt;突触延迟在生物神经元网络中发挥着关键作用，在哺乳动物的学习过程中观察到其调节。尽管突触延迟在仿生计算领域中具有重要意义，但在脉冲神经网络（SNNs）的模拟中却很少被纳入。&lt;h4&gt;目的&lt;/h4&gt;提出一种新的学习方法，用于同时学习突触连接强度和延迟，并验证其有效性。&lt;h4&gt;方法&lt;/h4&gt;通过扩展尖峰时间依赖性可塑性（STDP）方法，引入了一种新的学习规则，并在一个广泛使用的SNN分类模型中进行了验证，该模型使用无监督学习进行训练。&lt;h4&gt;主要发现&lt;/h4&gt;新的方法在各种测试场景中均表现出优于现有方法的性能，并揭示了突触效力和延迟之间的相互作用。&lt;h4&gt;结论&lt;/h4&gt;该方法有效地同时学习了突触连接强度和延迟，为神经形态计算领域提供了新的思路。&lt;h4&gt;翻译&lt;/h4&gt;摘要：突触延迟在生物神经元网络中扮演着至关重要的角色，在哺乳动物的学习过程中观察到它们的调节作用。在神经形态计算领域，尽管脉冲神经网络（SNNs）旨在比传统的神经网络更接近于生物仿真，但在它们的模拟中很少考虑突触延迟。我们提出了一种新的学习规则，通过扩展尖峰时间依赖性可塑性（STDP），一种通常用于学习突触权重的赫布方法，以同时学习突触连接强度和延迟。我们通过扩展一个广泛使用的用于分类的SNN模型，该模型使用无监督学习进行训练，来验证我们的方法。然后，我们通过将其与另一种现有方法进行了比较，该方法旨在共同学习突触权重和延迟，以及与没有突触延迟的STDP进行比较，证明了我们新方法的有效性。结果证明，我们提出的方法在各种测试场景中均能实现优越的性能。此外，我们的实验结果揭示了突触效力和延迟之间的相互作用。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Synaptic delays play a crucial role in biological neuronal networks, wheretheir modulation has been observed in mammalian learning processes. In therealm of neuromorphic computing, although spiking neural networks (SNNs) aim toemulate biology more closely than traditional artificial neural networks do,synaptic delays are rarely incorporated into their simulation. We introduce anovel learning rule for simultaneously learning synaptic connection strengthsand delays, by extending spike-timing dependent plasticity (STDP), a Hebbianmethod commonly used for learning synaptic weights. We validate our approach byextending a widely-used SNN model for classification trained with unsupervisedlearning. Then we demonstrate the effectiveness of our new method by comparingit against another existing methods for co-learning synaptic weights and delaysas well as against STDP without synaptic delays. Results demonstrate that ourproposed method consistently achieves superior performance across a variety oftest scenarios. Furthermore, our experimental results yield insight into theinterplay between synaptic efficacy and delay.</description>
      <author>example@mail.com (Marissa Dominijanni, Alexander Ororbia, Kenneth W. Regan)</author>
      <guid isPermaLink="false">2506.14984v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Targeted Lexical Injection: Unlocking Latent Cross-Lingual Alignment in Lugha-Llama via Early-Layer LoRA Fine-Tuning</title>
      <link>http://arxiv.org/abs/2506.15415v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  11 pages, 3 figures, 2 tables. Research on parameter-efficient  fine-tuning (PEFT) for low-resource languages (Swahili). Investigates  cross-lingual lexical alignment in Lugha-Llama using LoRA and contrastive  learning&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文介绍了针对低资源语言（LRLs）的Targeted Lexical Injection（TLI）方法，通过优化早期层的嵌入来提升大型语言模型在低资源语言中的词汇对齐能力。&lt;h4&gt;背景&lt;/h4&gt;大型语言模型在低资源语言上的表现通常不佳，因为数据稀缺且在预训练中代表性不足，导致跨语言词汇对齐困难。&lt;h4&gt;目的&lt;/h4&gt;提出TLI方法，以解决低资源语言模型中词汇对齐的问题，特别是针对翻译和跨语言信息检索等任务。&lt;h4&gt;方法&lt;/h4&gt;TLI方法利用低秩自适应（LoRA）和对比学习目标，针对早期层的嵌入进行微调，以改善词汇对齐。&lt;h4&gt;主要发现&lt;/h4&gt;研究发现，TLI显著提高了623个训练的斯瓦希里语-英语词汇对的输出级词汇对齐，平均余弦相似度从0.3211提升到0.4113（+28.08%），并且这些改进在63个未见过的控制词汇对中也表现出良好的泛化能力。&lt;h4&gt;结论&lt;/h4&gt;TLI增强了模型在低资源语言中保留和传播早期层跨语言知识的能力，为提高词汇对齐提供了一种参数高效且有效的方法。&lt;h4&gt;翻译&lt;/h4&gt;本文提出了一种名为目标词汇注入（Targeted Lexical Injection，TLI）的新颖高效微调方法，旨在解决大型语言模型在低资源语言（LRLs）中词汇对齐能力不足的问题。研究发现，TLI显著提高了模型在斯瓦希里语-英语词汇对上的输出级词汇对齐，并在未见过的词汇对上表现出良好的泛化能力，从而为提高低资源语言模型中的词汇对齐提供了有效策略。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Large Language Models (LLMs) have demonstrated remarkable capabilities, yettheir performance in low-resource languages (LRLs), such as Swahili, often lagsdue to data scarcity and underrepresentation in pre-training. A key challengeis achieving robust cross-lingual lexical alignment, crucial for tasks liketranslation and cross-lingual information retrieval. This paper introducesTargeted Lexical Injection (TLI), a novel and efficient fine-tuning approach.We first demonstrate that Lugha-Llama-8B-wura, a Swahili-centric LLM, exhibitsstrong, near-perfect lexical alignment for Swahili-English word pairs in itsearly internal layers (specifically Layer 2, with ~0.99998 average cosinesimilarity based on a pilot study), a capability not fully reflected in itsfinal output representations (baseline ~0.32 similarity on our evaluation set).TLI leverages this insight by using Low-Rank Adaptation (LoRA) and acontrastive learning objective to fine-tune the model, specifically targetingembeddings from this empirically identified optimal early layer. Ourexperiments show that TLI significantly improves the output-level lexicalalignment for 623 trained Swahili-English word pairs, increasing average cosinesimilarity from 0.3211 to 0.4113 (+28.08%, p &lt; 1.33 x 10^-240). Moreimportantly, these improvements generalize remarkably well to 63 unseen controlword pairs, with similarity increasing from 0.3143 to 0.4033 (+28.32%, p &lt; 7.17x 10^-27). These findings suggest TLI enhances the model's ability to preserveand propagate its inherent early-layer cross-lingual knowledge, offering aparameter-efficient and effective strategy for improving lexical alignment inLRL-focused LLMs.</description>
      <author>example@mail.com (Stanley Ngugi)</author>
      <guid isPermaLink="false">2506.15415v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>video-SALMONN 2: Captioning-Enhanced Audio-Visual Large Language Models</title>
      <link>http://arxiv.org/abs/2506.15220v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为video-SALMONN 2的先进音频-视觉大型语言模型，用于通过定向偏好优化（DPO）增强视频（配对音频）字幕生成。该模型通过多轮DPO（MrDPO）方法显著提高了字幕准确率，并在视频字幕任务中超越了GPT-4o和Gemini-1.5-Pro等领先模型。&lt;h4&gt;背景&lt;/h4&gt;视频包含大量信息，生成详细且准确的自然语言描述是视频理解的关键。&lt;h4&gt;目的&lt;/h4&gt;提高视频字幕生成的准确性和完整性。&lt;h4&gt;方法&lt;/h4&gt;video-SALMONN 2模型采用低秩自适应（LoRA）和定向偏好优化（DPO）。提出新的评估指标，并使用DPO优化。采用多轮DPO（MrDPO）方法，包括定期更新DPO参考模型，合并和重新初始化LoRA模块作为参数更新的代理，以及结合真实视频字幕的指导来稳定过程。&lt;h4&gt;主要发现&lt;/h4&gt;MrDPO显著提高了video-SALMONN 2的字幕准确率，将字幕错误率降低了28%。video-SALMONN 2模型在视频字幕任务中超越了GPT-4o和Gemini-1.5-Pro等模型，同时在广泛使用的视频问答基准测试中保持了与最先进模型相当的性能。&lt;h4&gt;结论&lt;/h4&gt;video-SALMONN 2模型在视频字幕生成方面取得了显著进展，具有高度竞争力和实用性。&lt;h4&gt;翻译&lt;/h4&gt;This paper presents video-SALMONN 2, an advanced audio-visual large language model with low-rank adaptation (LoRA) designed for enhanced video (with paired audio) captioning through directed preference optimization (DPO). We propose new metrics to evaluate the completeness and accuracy of video descriptions, which are optimized using DPO. To further improve training, we propose a novel multi-round DPO (MrDPO) approach, which involves periodically updating the DPO reference model, merging and re-initializing the LoRA module as a proxy for parameter updates after each training round (1,000 steps), and incorporating guidance from ground-truth video captions to stabilize the process. Experimental results show that MrDPO significantly enhances video-SALMONN 2's captioning accuracy, reducing the captioning error rates by 28%. The final video-SALMONN 2 model, with just 7 billion parameters, surpasses leading models such as GPT-4o and Gemini-1.5-Pro in video captioning tasks, while maintaining highly competitive performance to the state-of-the-art on widely used video question-answering benchmarks among models of similar size. Codes are available at https://github.com/bytedance/video-SALMONN-2.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Videos contain a wealth of information, and generating detailed and accuratedescriptions in natural language is a key aspect of video understanding. Inthis paper, we present video-SALMONN 2, an advanced audio-visual large languagemodel (LLM) with low-rank adaptation (LoRA) designed for enhanced video (withpaired audio) captioning through directed preference optimisation (DPO). Wepropose new metrics to evaluate the completeness and accuracy of videodescriptions, which are optimised using DPO. To further improve training, wepropose a novel multi-round DPO (MrDPO) approach, which involves periodicallyupdating the DPO reference model, merging and re-initialising the LoRA moduleas a proxy for parameter updates after each training round (1,000 steps), andincorporating guidance from ground-truth video captions to stabilise theprocess. Experimental results show that MrDPO significantly enhancesvideo-SALMONN 2's captioning accuracy, reducing the captioning error rates by28\%. The final video-SALMONN 2 model, with just 7 billion parameters,surpasses leading models such as GPT-4o and Gemini-1.5-Pro in video captioningtasks, while maintaining highly competitive performance to the state-of-the-arton widely used video question-answering benchmarks among models of similarsize. Codes are available at\href{https://github.com/bytedance/video-SALMONN-2}{https://github.com/bytedance/video-SALMONN-2}.</description>
      <author>example@mail.com (Changli Tang, Yixuan Li, Yudong Yang, Jimin Zhuang, Guangzhi Sun, Wei Li, Zejun Ma, Chao Zhang)</author>
      <guid isPermaLink="false">2506.15220v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>ConLID: Supervised Contrastive Learning for Low-Resource Language Identification</title>
      <link>http://arxiv.org/abs/2506.15304v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Submitted to EMNLP&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的监督对比学习方法，用于学习低资源语言的领域不变表示，以解决低资源语言在语言识别（LID）任务中的性能问题。&lt;h4&gt;背景&lt;/h4&gt;在从网络爬取中整理多语言LLM预训练语料库时，语言识别是一个关键步骤。许多关于LID模型训练的研究集中在收集多样化的训练数据以提高性能，但低资源语言通常由于限于单一领域的数据（如圣经）而表现不佳。&lt;h4&gt;目的&lt;/h4&gt;为了解决类别不平衡和偏差问题，提出了一种新的监督对比学习方法。&lt;h4&gt;方法&lt;/h4&gt;通过广泛的分析，证明了该方法能够提高低资源语言在域外数据上的LID性能，提高了3.2%，展示了其在增强LID模型方面的有效性。&lt;h4&gt;主要发现&lt;/h4&gt;提出的监督对比学习方法能够提高低资源语言在域外数据上的LID性能，提高了3.2%。&lt;h4&gt;结论&lt;/h4&gt;该方法在提高低资源语言LID模型性能方面是有效的。&lt;h4&gt;翻译&lt;/h4&gt;Language identification (LID) is a critical step in curating multilingual LLMpretraining corpora from web crawls. While many studies on LID model training focus on collecting diverse training data to improve performance, low-resourcelanguages -- often limited to single-domain data, such as the Bible -- continueto perform poorly. To resolve these class imbalance and bias issues, we proposea novel supervised contrastive learning (SCL) approach to learndomain-invariant representations for low-resource languages. Through anextensive analysis, we show that our approach improves LID performance onout-of-domain data for low-resource languages by 3.2%, demonstrating itseffectiveness in enhancing LID models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Language identification (LID) is a critical step in curating multilingual LLMpretraining corpora from web crawls. While many studies on LID model trainingfocus on collecting diverse training data to improve performance, low-resourcelanguages -- often limited to single-domain data, such as the Bible -- continueto perform poorly. To resolve these class imbalance and bias issues, we proposea novel supervised contrastive learning (SCL) approach to learndomain-invariant representations for low-resource languages. Through anextensive analysis, we show that our approach improves LID performance onout-of-domain data for low-resource languages by 3.2%, demonstrating itseffectiveness in enhancing LID models.</description>
      <author>example@mail.com (Negar Foroutan, Jakhongir Saydaliev, Ye Eun Kim, Antoine Bosselut)</author>
      <guid isPermaLink="false">2506.15304v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>A Unified Graph-based Framework for Scalable 3D Tree Reconstruction and Non-Destructive Biomass Estimation from Point Clouds</title>
      <link>http://arxiv.org/abs/2506.15577v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 pages,19 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种新的框架，用于大规模点云的端到端处理，以实现森林地上生物量（AGB）的无损估算，从而为碳储存评估和可持续森林管理提供支持。&lt;h4&gt;背景&lt;/h4&gt;估算森林地上生物量对于评估碳储存和促进可持续森林管理至关重要。目前的定量结构模型（QSM）方法在处理大规模数据时存在局限性。&lt;h4&gt;目的&lt;/h4&gt;旨在提出一种新的框架，通过创新的基于图的管道，实现对大规模点云的端到端处理，从而提高森林地上生物量估算的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;该方法通过特定的图操作，包括路径和抽象化，实现树木分割、叶木分离和三维骨骼重建，并在不同叶条件、空间尺度和数据源的数据集上进行了全面验证。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在具有挑战性的条件下表现出强大的性能，尤其是在叶覆盖条件下（相对误差约为20%）和低密度基于无人机激光扫描（ULS）数据集（部分覆盖，相对误差约为30%）。&lt;h4&gt;结论&lt;/h4&gt;该框架提供了一种稳健且可扩展的解决方案，显著降低了对于专业化预处理工具的依赖，并将ULS确立为TLS的可行替代品。这是第一个能够实现操作规模无缝端到端三维树木重建的方法，显著提高了基于QSM的AGB估算的可行性，为森林清查和气候变化研究开辟了更广泛的应用前景。&lt;h4&gt;翻译&lt;/h4&gt;摘要：估算森林地上生物量（AGB）对于评估碳储存和促进可持续森林管理至关重要。定量结构模型（QSM）提供了一种通过三维树木结构重建进行AGB估算的非破坏性方法。然而，目前的QSM方法面临着显著的局限性，因为它们主要设计用于单个树木，依赖于来自地面激光扫描（TLS）的高质量点云数据，并且还需要多个预处理步骤，这阻碍了可扩展性和实际部署。本研究提出了一种新的统一框架，该框架通过创新的基于图的管道实现了大规模点云的端到端处理。所提出的方法通过专门的图操作，包括路径和抽象化以进行树木拓扑推理，无缝地集成了树木分割、叶木分离和三维骨骼重建。在具有不同叶条件（叶在/叶落）、空间尺度（树木和地块水平）和数据来源（TLS和基于无人机激光扫描，ULS）的数据集上进行了全面的验证。实验结果证明了在具有挑战性的条件下具有强大的性能，特别是在叶在的情况下（相对误差约为20%）和低密度ULS数据集（部分覆盖，相对误差约为30%）。这些发现表明，所提出的框架提供了一种稳健且可扩展的解决方案，用于大规模、非破坏性AGB估算。它显著降低了对于专业化预处理工具的依赖，并将ULS确立为TLS的可行替代品。据我们所知，这是第一个能够在操作规模上实现无缝端到端三维树木重建的方法。这一进步极大地提高了基于QSM的AGB估算的可行性，为森林清查和气候变化研究的更广泛应用铺平了道路。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Estimating forest above-ground biomass (AGB) is crucial for assessing carbonstorage and supporting sustainable forest management. Quantitative StructuralModel (QSM) offers a non-destructive approach to AGB estimation through 3D treestructural reconstruction. However, current QSM methods face significantlimitations, as they are primarily designed for individual trees,depend onhigh-quality point cloud data from terrestrial laser scanning (TLS), and alsorequire multiple pre-processing steps that hinder scalability and practicaldeployment. This study presents a novel unified framework that enablesend-to-end processing of large-scale point clouds using an innovativegraph-based pipeline. The proposed approach seamlessly integrates treesegmentation,leaf-wood separation and 3D skeletal reconstruction throughdedicated graph operations including pathing and abstracting for tree topologyreasoning. Comprehensive validation was conducted on datasets with varying leafconditions (leaf-on and leaf-off), spatial scales (tree- and plot-level), anddata sources (TLS and UAV-based laser scanning, ULS). Experimental resultsdemonstrate strong performance under challenging conditions, particularly inleaf-on scenarios (~20% relative error) and low-density ULS datasets withpartial coverage (~30% relative error). These findings indicate that theproposed framework provides a robust and scalable solution for large-scale,non-destructive AGB estimation. It significantly reduces dependency onspecialized pre-processing tools and establishes ULS as a viable alternative toTLS. To our knowledge, this is the first method capable of enabling seamless,end-to-end 3D tree reconstruction at operational scales. This advancementsubstantially improves the feasibility of QSM-based AGB estimation, paving theway for broader applications in forest inventory and climate change research.</description>
      <author>example@mail.com (Di Wang, Shi Li)</author>
      <guid isPermaLink="false">2506.15577v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Enhancing point cloud analysis via neighbor aggregation correction based on cross-stage structure correlation</title>
      <link>http://arxiv.org/abs/2506.15160v1</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  17 papes, 7 figures&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为PDSA（Point Distribution Set Abstraction）的点云分析模块，旨在提高点云数据的聚合效率和鲁棒性。&lt;h4&gt;背景&lt;/h4&gt;点云分析是许多下游任务的基础，其中聚合局部结构是理解点云数据的关键。然而，现有的方法在利用三维相对坐标进行邻域聚合时，存在无关点干扰和特征层次结构逼近问题。&lt;h4&gt;目的&lt;/h4&gt;克服现有方法的局限性，提高点云数据聚合的效率和鲁棒性。&lt;h4&gt;方法&lt;/h4&gt;PDSA模块利用高维空间中的相关性来校正聚合过程中的特征分布，通过轻量级的跨阶段结构描述符区分点间相关性，并通过长距离建模减少邻域特征矩阵的方差，提高类别可分性。此外，引入了关键点机制以优化计算开销。&lt;h4&gt;主要发现&lt;/h4&gt;在语义分割和分类任务上的实验结果表明，PDSA方法在参数成本较低的情况下实现了显著的性能提升，并且通过消融和可视化结果证明了方法的有效性和合理性。&lt;h4&gt;结论&lt;/h4&gt;PDSA模块能够有效提高点云数据聚合的效率和鲁棒性，并具有良好的泛化能力。&lt;h4&gt;翻译&lt;/h4&gt;摘要：点云分析是许多下游任务的基础，其中聚合局部结构是理解点云数据的基础。虽然许多工作使用三维相对坐标进行邻域聚合，但由于局部坐标的限制，存在无关点干扰和特征层次结构逼近问题。尽管一些工作通过显式建模跨阶段结构来细化空间描述来解决这个问题，但这些基于直接几何结构编码的增强方法存在计算开销高和噪声敏感的问题。为了克服这些问题，我们提出了点分布集抽象模块（PDSA），该模块利用高维空间中的相关性来校正聚合过程中的特征分布，从而提高了计算效率和鲁棒性。PDSA基于轻量级的跨阶段结构描述符区分点间相关性，并通过减少邻域特征矩阵的方差和通过长距离建模增加类别可分性来增强结构同质性。此外，我们引入了一个关键点机制来优化计算开销。基于不同基线在语义分割和分类任务上的实验结果验证了我们提出的方法的泛化能力，并且在参数成本较低的情况下实现了显著的性能提升。相应的消融和可视化结果证明了我们方法的有效性和合理性。代码和训练权重可在以下链接获取：https://github.com/AGENT9717/PointDistribution&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-18&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Point cloud analysis is the cornerstone of many downstream tasks, among whichaggregating local structures is the basis for understanding point cloud data.While numerous works aggregate neighbor using three-dimensional relativecoordinates, there are irrelevant point interference and feature hierarchy gapproblems due to the limitation of local coordinates. Although some worksaddress this limitation by refining spatial description though explicitmodeling of cross-stage structure, these enhancement methods based on directgeometric structure encoding have problems of high computational overhead andnoise sensitivity. To overcome these problems, we propose the PointDistribution Set Abstraction module (PDSA) that utilizes the correlation in thehigh-dimensional space to correct the feature distribution during aggregation,which improves the computational efficiency and robustness. PDSA distinguishesthe point correlation based on a lightweight cross-stage structural descriptor,and enhances structural homogeneity by reducing the variance of the neighborfeature matrix and increasing classes separability though long-distancemodeling. Additionally, we introducing a key point mechanism to optimize thecomputational overhead. The experimental result on semantic segmentation andclassification tasks based on different baselines verify the generalization ofthe method we proposed, and achieve significant performance improvement withless parameter cost. The corresponding ablation and visualization resultsdemonstrate the effectiveness and rationality of our method. The code andtraining weight is available at: https://github.com/AGENT9717/PointDistribution</description>
      <author>example@mail.com (Jiaqi Shi, Jin Xiao, Xiaoguang Hu, Boyang Song, Hao Jiang, Tianyou Chen, Baochang Zhang)</author>
      <guid isPermaLink="false">2506.15160v1</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented Efficient Long Video Understanding</title>
      <link>http://arxiv.org/abs/2506.13589v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  &lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种名为AdaVideoRAG的新框架，用于解决多模态大型语言模型在处理长视频时的挑战，通过动态调整检索粒度来提高效率。&lt;h4&gt;背景&lt;/h4&gt;多模态大型语言模型在处理长视频时面临固定上下文窗口和弱长期依赖建模的问题，现有的视频检索增强生成方法使用静态检索策略，导致简单查询效率低下和复杂任务信息丢失。&lt;h4&gt;目的&lt;/h4&gt;提出AdaVideoRAG框架，旨在解决上述问题，提高长视频理解的效率和准确性。&lt;h4&gt;方法&lt;/h4&gt;AdaVideoRAG框架使用轻量级意图分类器动态调整检索粒度，并采用Omni-Knowledge Indexing模块构建包含文本、视觉特征和语义图的分层数据库，实现跨任务的资源优化分配。同时，引入了HiVU基准测试进行综合评估。&lt;h4&gt;主要发现&lt;/h4&gt;实验表明，AdaVideoRAG在长视频理解方面提高了效率和准确性，并且能够无缝集成到现有的多模态大型语言模型中。&lt;h4&gt;结论&lt;/h4&gt;AdaVideoRAG为视频分析中的自适应检索建立了一个新的范式，并将代码开源在https://github.com/xzc-zju/AdaVideoRAG上。&lt;h4&gt;翻译&lt;/h4&gt;This paper proposes a novel framework called AdaVideoRAG to address the challenges of multimodal large language models in processing long videos, which dynamically adjusts the retrieval granularity to improve efficiency.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Multimodal Large Language Models (MLLMs) struggle with long videos due tofixed context windows and weak long-term dependency modeling. ExistingRetrieval-Augmented Generation (RAG) methods for videos use static retrievalstrategies, leading to inefficiencies for simple queries and information lossfor complex tasks. To address this, we propose AdaVideoRAG, a novel frameworkthat dynamically adapts retrieval granularity based on query complexity using alightweight intent classifier. Our framework employs an Omni-Knowledge Indexingmodule to build hierarchical databases from text (captions, ASR, OCR), visualfeatures, and semantic graphs, enabling optimal resource allocation acrosstasks. We also introduce the HiVU benchmark for comprehensive evaluation.Experiments demonstrate improved efficiency and accuracy for long-videounderstanding, with seamless integration into existing MLLMs. AdaVideoRAGestablishes a new paradigm for adaptive retrieval in video analysis. Codes willbe open-sourced at https://github.com/xzc-zju/AdaVideoRAG.</description>
      <author>example@mail.com (Zhucun Xue, Jiangning Zhang, Xurong Xie, Yuxuan Cai, Yong Liu, Xiangtai Li, Dacheng Tao)</author>
      <guid isPermaLink="false">2506.13589v2</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>GRAM: A Generative Foundation Reward Model for Reward Generalization</title>
      <link>http://arxiv.org/abs/2506.14175v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  Accepted by ICML 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;本文提出了一种基于生成模型的奖励模型训练方法，结合无标签和有标签数据，通过大规模无监督学习和监督学习进行训练，实现了在多个任务上的性能提升。&lt;h4&gt;背景&lt;/h4&gt;传统的奖励模型在大型语言模型中对齐中扮演重要角色，但通常作为判别模型训练，依赖于标注的人类偏好数据。&lt;h4&gt;目的&lt;/h4&gt;探索利用无标签和有标签数据训练奖励模型的方法，提高模型在多个任务上的泛化能力。&lt;h4&gt;方法&lt;/h4&gt;开发了一种生成奖励模型，首先通过大规模无监督学习进行训练，然后通过监督学习进行微调。同时，通过标签平滑优化正则化成对排名损失。&lt;h4&gt;主要发现&lt;/h4&gt;这种方法将生成模型和判别模型链接到同一类训练目标下，并证明了通过标签平滑实际上是在优化正则化成对排名损失。&lt;h4&gt;结论&lt;/h4&gt;该模型可以作为基础奖励模型，应用于广泛的任务，无需或只需少量微调，在多个任务上实现显著的性能提升。&lt;h4&gt;翻译&lt;/h4&gt;In aligning large language models (LLMs), reward models have played an important role, but are standardly trained as discriminative models and rely only on labeled human preference data. In this paper, we explore methods that train reward models using both unlabeled and labeled data. Building on the generative models in LLMs, we develop a generative reward model that is first trained via large-scale unsupervised learning and then fine-tuned via supervised learning. We also show that by using label smoothing, we are in fact optimizing a regularized pairwise ranking loss. This result, in turn, provides a new view of training reward models, which links generative models and discriminative models under the same class of training objectives. The outcome of these techniques is a foundation reward model, which can be applied to a wide range of tasks with little or no further fine-tuning effort. Extensive experiments show that this model generalizes well across several tasks, including response ranking, reinforcement learning from human feedback, and task adaptation with fine-tuning, achieving significant performance improvements over several strong baseline models.&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-17&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; In aligning large language models (LLMs), reward models have played animportant role, but are standardly trained as discriminative models and relyonly on labeled human preference data. In this paper, we explore methods thattrain reward models using both unlabeled and labeled data. Building on thegenerative models in LLMs, we develop a generative reward model that is firsttrained via large-scale unsupervised learning and then fine-tuned viasupervised learning. We also show that by using label smoothing, we are in factoptimizing a regularized pairwise ranking loss. This result, in turn, providesa new view of training reward models, which links generative models anddiscriminative models under the same class of training objectives. The outcomeof these techniques is a foundation reward model, which can be applied to awide range of tasks with little or no further fine-tuning effort. Extensiveexperiments show that this model generalizes well across several tasks,including response ranking, reinforcement learning from human feedback, andtask adaptation with fine-tuning, achieving significant performanceimprovements over several strong baseline models.</description>
      <author>example@mail.com (Chenglong Wang, Yang Gan, Yifu Huo, Yongyu Mu, Qiaozhi He, Murun Yang, Bei Li, Tong Xiao, Chunliang Zhang, Tongran Liu, Jingbo Zhu)</author>
      <guid isPermaLink="false">2506.14175v2</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    <item>
      <title>Hierarchical Multi-Positive Contrastive Learning for Patent Image Retrieval</title>
      <link>http://arxiv.org/abs/2506.13496v2</link>
      <description>&lt;strong&gt;评论:&lt;/strong&gt;  5 pages, 3 figures, Accepted as a short paper at the 6th Workshop on  Patent Text Mining and Semantic Technologies (PatentSemTech 2025), co-located  with SIGIR 2025&lt;h3&gt;GPT 摘要:&lt;/h3&gt;&lt;h4&gt;总结&lt;/h4&gt;该论文提出了一种利用Locarno国际分类系统（LIC）的层次结构来提高专利图像检索系统性能的方法。&lt;h4&gt;背景&lt;/h4&gt;专利图像是传达专利创新信息的技术图纸，专利图像检索系统在处理大量数据集时面临挑战，需要针对领域特定进行高效调整。&lt;h4&gt;目的&lt;/h4&gt;提高专利图像检索的准确性，特别是在处理复杂的语义信息和技术细节时。&lt;h4&gt;方法&lt;/h4&gt;引入了一种层次多正对比损失，通过利用LIC的分类体系，在检索过程中诱导层级关系。方法为每个批次的专利图像分配多个基于层级分类的相似度评分的正对。&lt;h4&gt;主要发现&lt;/h4&gt;实验结果表明，该方法在DeepPatent2数据集上提高了检索效果，并且对低参数模型有效，这些模型计算资源需求低，可以在硬件受限的环境中部署。&lt;h4&gt;结论&lt;/h4&gt;该方法通过利用层级结构增强了专利图像检索的性能，适用于资源受限的环境。&lt;strong&gt;发布时间:&lt;/strong&gt;  2025-06-16&lt;br&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;br&gt;&lt;strong&gt;repo:&lt;/strong&gt;null&lt;br&gt;&lt;h3&gt;摘要:&lt;/h3&gt; Patent images are technical drawings that convey information about a patent'sinnovation. Patent image retrieval systems aim to search in vast collectionsand retrieve the most relevant images. Despite recent advances in informationretrieval, patent images still pose significant challenges due to theirtechnical intricacies and complex semantic information, requiring efficientfine-tuning for domain adaptation. Current methods neglect patents'hierarchical relationships, such as those defined by the Locarno InternationalClassification (LIC) system, which groups broad categories (e.g., "furnishing")into subclasses (e.g., "seats" and "beds") and further into specific patentdesigns. In this work, we introduce a hierarchical multi-positive contrastiveloss that leverages the LIC's taxonomy to induce such relations in theretrieval process. Our approach assigns multiple positive pairs to each patentimage within a batch, with varying similarity scores based on the hierarchicaltaxonomy. Our experimental analysis with various vision and multimodal modelson the DeepPatent2 dataset shows that the proposed method enhances theretrieval results. Notably, our method is effective with low-parameter models,which require fewer computational resources and can be deployed on environmentswith limited hardware.</description>
      <author>example@mail.com (Kshitij Kavimandan, Angelos Nalmpantis, Emma Beauxis-Aussalet, Robert-Jan Sips)</author>
      <guid isPermaLink="false">2506.13496v2</guid>
      <pubDate>Fri, 20 Jun 2025 14:13:46 +0800</pubDate>
    </item>
    </channel>
</rss>